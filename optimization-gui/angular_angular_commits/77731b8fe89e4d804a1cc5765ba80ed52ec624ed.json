{
    "author": "atscott",
    "message": "Revert \"refactor(compiler): support interpolation tokens when lexing attribute values (#42062)\" (#43033)\n\nThis reverts commit c516e252fcb199f2f503db5dc6ce563a299da010.\n\nPR Close #43033",
    "sha": "77731b8fe89e4d804a1cc5765ba80ed52ec624ed",
    "files": [
        {
            "sha": "d62a54f57606b7c2fb3c17b2e1e9bfcbd9f7e829",
            "filename": "packages/compiler/src/ml_parser/lexer.ts",
            "status": "modified",
            "additions": 33,
            "deletions": 43,
            "changes": 76,
            "blob_url": "https://github.com/angular/angular/blob/77731b8fe89e4d804a1cc5765ba80ed52ec624ed/packages%2Fcompiler%2Fsrc%2Fml_parser%2Flexer.ts",
            "raw_url": "https://github.com/angular/angular/raw/77731b8fe89e4d804a1cc5765ba80ed52ec624ed/packages%2Fcompiler%2Fsrc%2Fml_parser%2Flexer.ts",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler%2Fsrc%2Fml_parser%2Flexer.ts?ref=77731b8fe89e4d804a1cc5765ba80ed52ec624ed",
            "patch": "@@ -29,8 +29,7 @@ export enum TokenType {\n   CDATA_END,\n   ATTR_NAME,\n   ATTR_QUOTE,\n-  ATTR_VALUE_TEXT,\n-  ATTR_VALUE_INTERPOLATION,\n+  ATTR_VALUE,\n   DOC_TYPE,\n   EXPANSION_FORM_START,\n   EXPANSION_CASE_VALUE,\n@@ -229,8 +228,7 @@ class _Tokenizer {\n             this._consumeTagOpen(start);\n           }\n         } else if (!(this._tokenizeIcu && this._tokenizeExpansionForm())) {\n-          this._consumeWithInterpolation(\n-              TokenType.TEXT, TokenType.INTERPOLATION, () => this._isTextEnd());\n+          this._consumeText();\n         }\n       } catch (e) {\n         this.handleError(e);\n@@ -597,25 +595,29 @@ class _Tokenizer {\n   private _consumeAttributeValue() {\n     let value: string;\n     if (this._cursor.peek() === chars.$SQ || this._cursor.peek() === chars.$DQ) {\n+      this._beginToken(TokenType.ATTR_QUOTE);\n       const quoteChar = this._cursor.peek();\n-      this._consumeQuote(quoteChar);\n-      this._consumeWithInterpolation(\n-          TokenType.ATTR_VALUE_TEXT, TokenType.ATTR_VALUE_INTERPOLATION,\n-          () => this._cursor.peek() === quoteChar);\n-      this._consumeQuote(quoteChar);\n+      this._cursor.advance();\n+      this._endToken([String.fromCodePoint(quoteChar)]);\n+      this._beginToken(TokenType.ATTR_VALUE);\n+      const parts: string[] = [];\n+      while (this._cursor.peek() !== quoteChar) {\n+        parts.push(this._readChar(true));\n+      }\n+      value = parts.join('');\n+      this._endToken([this._processCarriageReturns(value)]);\n+      this._beginToken(TokenType.ATTR_QUOTE);\n+      this._cursor.advance();\n+      this._endToken([String.fromCodePoint(quoteChar)]);\n     } else {\n-      const endPredicate = () => isNameEnd(this._cursor.peek());\n-      this._consumeWithInterpolation(\n-          TokenType.ATTR_VALUE_TEXT, TokenType.ATTR_VALUE_INTERPOLATION, endPredicate);\n+      this._beginToken(TokenType.ATTR_VALUE);\n+      const valueStart = this._cursor.clone();\n+      this._requireCharCodeUntilFn(isNameEnd, 1);\n+      value = this._cursor.getChars(valueStart);\n+      this._endToken([this._processCarriageReturns(value)]);\n     }\n   }\n \n-  private _consumeQuote(quoteChar: number) {\n-    this._beginToken(TokenType.ATTR_QUOTE);\n-    this._requireCharCode(quoteChar);\n-    this._endToken([String.fromCodePoint(quoteChar)]);\n-  }\n-\n   private _consumeTagOpenEnd() {\n     const tokenType =\n         this._attemptCharCode(chars.$SLASH) ? TokenType.TAG_OPEN_END_VOID : TokenType.TAG_OPEN_END;\n@@ -694,31 +696,21 @@ class _Tokenizer {\n     this._expansionCaseStack.pop();\n   }\n \n-  /**\n-   * Consume a string that may contain interpolation expressions.\n-   * The first token consumed will be of `tokenType` and then there will be alternating\n-   * `interpolationTokenType` and `tokenType` tokens until the `endPredicate()` returns true.\n-   *\n-   * @param textTokenType the kind of tokens to interleave around interpolation tokens.\n-   * @param interpolationTokenType the kind of tokens that contain interpolation.\n-   * @param endPredicate a function that should return true when we should stop consuming.\n-   */\n-  private _consumeWithInterpolation(\n-      textTokenType: TokenType, interpolationTokenType: TokenType, endPredicate: () => boolean) {\n-    this._beginToken(textTokenType);\n+  private _consumeText() {\n+    this._beginToken(TokenType.TEXT);\n     const parts: string[] = [];\n \n-    while (!endPredicate()) {\n+    do {\n       const current = this._cursor.clone();\n       if (this._interpolationConfig && this._attemptStr(this._interpolationConfig.start)) {\n         this._endToken([this._processCarriageReturns(parts.join(''))], current);\n-        this._consumeInterpolation(interpolationTokenType, current);\n+        this._consumeInterpolation(current);\n         parts.length = 0;\n-        this._beginToken(textTokenType);\n+        this._beginToken(TokenType.TEXT);\n       } else {\n         parts.push(this._readChar(true));\n       }\n-    }\n+    } while (!this._isTextEnd());\n \n     // It is possible that an interpolation was started but not ended inside this text token.\n     // Make sure that we reset the state of the lexer correctly.\n@@ -727,15 +719,14 @@ class _Tokenizer {\n     this._endToken([this._processCarriageReturns(parts.join(''))]);\n   }\n \n-  private _consumeInterpolation(\n-      interpolationTokenType: TokenType, interpolationStart: CharacterCursor) {\n+  private _consumeInterpolation(interpolationStart: CharacterCursor) {\n     const parts: string[] = [];\n-    this._beginToken(interpolationTokenType, interpolationStart);\n+    this._beginToken(TokenType.INTERPOLATION, interpolationStart);\n     parts.push(this._interpolationConfig.start);\n \n     // Find the end of the interpolation, ignoring content inside quotes.\n     const expressionStart = this._cursor.clone();\n-    let inQuote: number|null = null;\n+    let inQuote: string|null = null;\n     let inComment = false;\n     while (this._cursor.peek() !== chars.$EOF) {\n       const current = this._cursor.clone();\n@@ -761,15 +752,14 @@ class _Tokenizer {\n         }\n       }\n \n-      const char = this._cursor.peek();\n-      this._cursor.advance();\n-      if (char === chars.$BACKSLASH) {\n+      const char = this._readChar(true);\n+      if (char === '\\\\') {\n         // Skip the next character because it was escaped.\n-        this._cursor.advance();\n+        this._readChar(true);\n       } else if (char === inQuote) {\n         // Exiting the current quoted string\n         inQuote = null;\n-      } else if (!inComment && chars.isQuote(char)) {\n+      } else if (!inComment && /['\"`]/.test(char)) {\n         // Entering a new quoted string\n         inQuote = char;\n       }"
        },
        {
            "sha": "fd01357d437fd4b72a646dcf27f714e7b49e9631",
            "filename": "packages/compiler/src/ml_parser/parser.ts",
            "status": "modified",
            "additions": 13,
            "deletions": 35,
            "changes": 48,
            "blob_url": "https://github.com/angular/angular/blob/77731b8fe89e4d804a1cc5765ba80ed52ec624ed/packages%2Fcompiler%2Fsrc%2Fml_parser%2Fparser.ts",
            "raw_url": "https://github.com/angular/angular/raw/77731b8fe89e4d804a1cc5765ba80ed52ec624ed/packages%2Fcompiler%2Fsrc%2Fml_parser%2Fparser.ts",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler%2Fsrc%2Fml_parser%2Fparser.ts?ref=77731b8fe89e4d804a1cc5765ba80ed52ec624ed",
            "patch": "@@ -6,7 +6,7 @@\n  * found in the LICENSE file at https://angular.io/license\n  */\n \n-import {ParseError, ParseLocation, ParseSourceSpan} from '../parse_util';\n+import {ParseError, ParseSourceSpan} from '../parse_util';\n \n import * as html from './ast';\n import {NAMED_ENTITIES} from './entities';\n@@ -362,49 +362,27 @@ class _TreeBuilder {\n \n   private _consumeAttr(attrName: lex.Token): html.Attribute {\n     const fullName = mergeNsAndName(attrName.parts[0], attrName.parts[1]);\n-    let attrEnd = attrName.sourceSpan.end;\n-\n-    // Consume any quote\n+    let end = attrName.sourceSpan.end;\n+    let value = '';\n+    let valueSpan: ParseSourceSpan = undefined!;\n     if (this._peek.type === lex.TokenType.ATTR_QUOTE) {\n       this._advance();\n     }\n-\n-    // Consume the value\n-    let value = '';\n-    let valueStartSpan: ParseSourceSpan|undefined = undefined;\n-    let valueEnd: ParseLocation|undefined = undefined;\n-    if (this._peek.type === lex.TokenType.ATTR_VALUE_TEXT) {\n-      valueStartSpan = this._peek.sourceSpan;\n-      valueEnd = this._peek.sourceSpan.end;\n-      // For now we are recombining text and interpolation tokens\n-      while (this._peek.type === lex.TokenType.ATTR_VALUE_TEXT ||\n-             this._peek.type === lex.TokenType.ATTR_VALUE_INTERPOLATION) {\n-        let valueToken = this._advance();\n-        if (valueToken.type === lex.TokenType.ATTR_VALUE_INTERPOLATION) {\n-          // For backward compatibility we decode HTML entities that appear in interpolation\n-          // expressions. This is arguably a bug, but it could be a considerable breaking change to\n-          // fix it. It should be addressed in a larger project to refactor the entire parser/lexer\n-          // chain after View Engine has been removed.\n-          value += valueToken.parts.join('').replace(/&([^;]+);/g, decodeEntity);\n-        } else {\n-          value += valueToken.parts.join('');\n-        }\n-        valueEnd = attrEnd = valueToken.sourceSpan.end;\n-      }\n+    if (this._peek.type === lex.TokenType.ATTR_VALUE) {\n+      const valueToken = this._advance();\n+      value = valueToken.parts[0];\n+      end = valueToken.sourceSpan.end;\n+      valueSpan = valueToken.sourceSpan;\n     }\n-\n-    // Consume any quote\n     if (this._peek.type === lex.TokenType.ATTR_QUOTE) {\n       const quoteToken = this._advance();\n-      attrEnd = quoteToken.sourceSpan.end;\n+      end = quoteToken.sourceSpan.end;\n     }\n-\n-    const valueSpan = valueStartSpan && valueEnd &&\n-        new ParseSourceSpan(valueStartSpan.start, valueEnd, valueStartSpan.fullStart);\n+    const keySpan = new ParseSourceSpan(attrName.sourceSpan.start, attrName.sourceSpan.end);\n     return new html.Attribute(\n         fullName, value,\n-        new ParseSourceSpan(attrName.sourceSpan.start, attrEnd, attrName.sourceSpan.fullStart),\n-        attrName.sourceSpan, valueSpan);\n+        new ParseSourceSpan(attrName.sourceSpan.start, end, attrName.sourceSpan.fullStart), keySpan,\n+        valueSpan);\n   }\n \n   private _getParentElement(): html.Element|null {"
        },
        {
            "sha": "279bca60d3683b0e70ffcaec0e801dbfc42ad9ee",
            "filename": "packages/compiler/test/ml_parser/html_parser_spec.ts",
            "status": "modified",
            "additions": 0,
            "deletions": 13,
            "changes": 13,
            "blob_url": "https://github.com/angular/angular/blob/77731b8fe89e4d804a1cc5765ba80ed52ec624ed/packages%2Fcompiler%2Ftest%2Fml_parser%2Fhtml_parser_spec.ts",
            "raw_url": "https://github.com/angular/angular/raw/77731b8fe89e4d804a1cc5765ba80ed52ec624ed/packages%2Fcompiler%2Ftest%2Fml_parser%2Fhtml_parser_spec.ts",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler%2Ftest%2Fml_parser%2Fhtml_parser_spec.ts?ref=77731b8fe89e4d804a1cc5765ba80ed52ec624ed",
            "patch": "@@ -250,19 +250,6 @@ import {humanizeDom, humanizeDomSourceSpans, humanizeLineColumn, humanizeNodes}\n           ]);\n         });\n \n-        it('should decode HTML entities in interpolated attributes', () => {\n-          // Note that the detail of decoding corner-cases is tested in the\n-          // \"should decode HTML entities in interpolations\" spec.\n-          expect(humanizeDomSourceSpans(parser.parse('<div foo=\"{{&amp;}}\"></div>', 'TestComp')))\n-              .toEqual([\n-                [\n-                  html.Element, 'div', 0, '<div foo=\"{{&amp;}}\"></div>', '<div foo=\"{{&amp;}}\">',\n-                  '</div>'\n-                ],\n-                [html.Attribute, 'foo', '{{&}}', 'foo=\"{{&amp;}}\"']\n-              ]);\n-        });\n-\n         it('should normalize line endings within attribute values', () => {\n           const result =\n               parser.parse('<div key=\"  \\r\\n line 1 \\r\\n   line 2  \"></div>', 'TestComp');"
        },
        {
            "sha": "54005b28bad77162160ca5e87f76912241856836",
            "filename": "packages/compiler/test/ml_parser/lexer_spec.ts",
            "status": "modified",
            "additions": 22,
            "deletions": 52,
            "changes": 74,
            "blob_url": "https://github.com/angular/angular/blob/77731b8fe89e4d804a1cc5765ba80ed52ec624ed/packages%2Fcompiler%2Ftest%2Fml_parser%2Flexer_spec.ts",
            "raw_url": "https://github.com/angular/angular/raw/77731b8fe89e4d804a1cc5765ba80ed52ec624ed/packages%2Fcompiler%2Ftest%2Fml_parser%2Flexer_spec.ts",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler%2Ftest%2Fml_parser%2Flexer_spec.ts?ref=77731b8fe89e4d804a1cc5765ba80ed52ec624ed",
            "patch": "@@ -257,7 +257,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n             [lex.TokenType.INCOMPLETE_TAG_OPEN, '<div'],\n             [lex.TokenType.ATTR_NAME, 'class'],\n             [lex.TokenType.ATTR_QUOTE, '\"'],\n-            [lex.TokenType.ATTR_VALUE_TEXT, 'hi'],\n+            [lex.TokenType.ATTR_VALUE, 'hi'],\n             [lex.TokenType.ATTR_QUOTE, '\"'],\n             [lex.TokenType.ATTR_NAME, 'sty'],\n             [lex.TokenType.TAG_OPEN_START, '<span'],\n@@ -295,21 +295,15 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'a'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n-          [lex.TokenType.ATTR_VALUE_INTERPOLATION, '{{', 'v', '}}'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n+          [lex.TokenType.ATTR_VALUE, '{{v}}'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n           [lex.TokenType.ATTR_NAME, '', 'b'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 's'],\n-          [lex.TokenType.ATTR_VALUE_INTERPOLATION, '{{', 'm', '}}'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'e'],\n+          [lex.TokenType.ATTR_VALUE, 's{{m}}e'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n           [lex.TokenType.ATTR_NAME, '', 'c'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 's'],\n-          [lex.TokenType.ATTR_VALUE_INTERPOLATION, '{{', 'm//c', '}}'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'e'],\n+          [lex.TokenType.ATTR_VALUE, 's{{m//c}}e'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.EOF],\n@@ -339,7 +333,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'a'],\n           [lex.TokenType.ATTR_QUOTE, '\\''],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'b'],\n+          [lex.TokenType.ATTR_VALUE, 'b'],\n           [lex.TokenType.ATTR_QUOTE, '\\''],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.EOF],\n@@ -351,7 +345,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'a'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'b'],\n+          [lex.TokenType.ATTR_VALUE, 'b'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.EOF],\n@@ -362,31 +356,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n         expect(tokenizeAndHumanizeParts('<t a=b>')).toEqual([\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'a'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'b'],\n-          [lex.TokenType.TAG_OPEN_END],\n-          [lex.TokenType.EOF],\n-        ]);\n-      });\n-\n-      it('should parse attributes with unquoted interpolation value', () => {\n-        expect(tokenizeAndHumanizeParts('<a a={{link.text}}>')).toEqual([\n-          [lex.TokenType.TAG_OPEN_START, '', 'a'],\n-          [lex.TokenType.ATTR_NAME, '', 'a'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n-          [lex.TokenType.ATTR_VALUE_INTERPOLATION, '{{', 'link.text', '}}'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n-          [lex.TokenType.TAG_OPEN_END],\n-          [lex.TokenType.EOF],\n-        ]);\n-      });\n-\n-      it('should parse attributes with empty quoted value', () => {\n-        expect(tokenizeAndHumanizeParts('<t a=\"\">')).toEqual([\n-          [lex.TokenType.TAG_OPEN_START, '', 't'],\n-          [lex.TokenType.ATTR_NAME, '', 'a'],\n-          [lex.TokenType.ATTR_QUOTE, '\"'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n-          [lex.TokenType.ATTR_QUOTE, '\"'],\n+          [lex.TokenType.ATTR_VALUE, 'b'],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.EOF],\n         ]);\n@@ -396,7 +366,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n         expect(tokenizeAndHumanizeParts('<t a = b >')).toEqual([\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'a'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'b'],\n+          [lex.TokenType.ATTR_VALUE, 'b'],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.EOF],\n         ]);\n@@ -407,7 +377,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'a'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'AA'],\n+          [lex.TokenType.ATTR_VALUE, 'AA'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.EOF],\n@@ -419,11 +389,11 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'a'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, '&amp'],\n+          [lex.TokenType.ATTR_VALUE, '&amp'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n           [lex.TokenType.ATTR_NAME, '', 'b'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'c&&d'],\n+          [lex.TokenType.ATTR_VALUE, 'c&&d'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.EOF],\n@@ -435,7 +405,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'a'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'b && c &'],\n+          [lex.TokenType.ATTR_VALUE, 'b && c &'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.EOF],\n@@ -447,7 +417,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'a'],\n           [lex.TokenType.ATTR_QUOTE, '\\''],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 't\\ne\\ns\\nt'],\n+          [lex.TokenType.ATTR_VALUE, 't\\ne\\ns\\nt'],\n           [lex.TokenType.ATTR_QUOTE, '\\''],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.EOF],\n@@ -458,21 +428,21 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n         expect(tokenizeAndHumanizeSourceSpans('<t a=b>')).toEqual([\n           [lex.TokenType.TAG_OPEN_START, '<t'],\n           [lex.TokenType.ATTR_NAME, 'a'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'b'],\n+          [lex.TokenType.ATTR_VALUE, 'b'],\n           [lex.TokenType.TAG_OPEN_END, '>'],\n           [lex.TokenType.EOF, ''],\n         ]);\n       });\n \n       it('should report missing closing single quote', () => {\n         expect(tokenizeAndHumanizeErrors('<t a=\\'b>')).toEqual([\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'Unexpected character \"EOF\"', '0:8'],\n+          [lex.TokenType.ATTR_VALUE, 'Unexpected character \"EOF\"', '0:8'],\n         ]);\n       });\n \n       it('should report missing closing double quote', () => {\n         expect(tokenizeAndHumanizeErrors('<t a=\"b>')).toEqual([\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'Unexpected character \"EOF\"', '0:8'],\n+          [lex.TokenType.ATTR_VALUE, 'Unexpected character \"EOF\"', '0:8'],\n         ]);\n       });\n     });\n@@ -765,7 +735,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n              [lex.TokenType.INCOMPLETE_TAG_OPEN, '', 't'],\n              [lex.TokenType.ATTR_NAME, '', 'a'],\n              [lex.TokenType.ATTR_QUOTE, '\"'],\n-             [lex.TokenType.ATTR_VALUE_TEXT, 'b'],\n+             [lex.TokenType.ATTR_VALUE, 'b'],\n              [lex.TokenType.ATTR_QUOTE, '\"'],\n              // TODO(ayazhafiz): the \" symbol should be a synthetic attribute,\n              // allowing us to complete the opening tag correctly.\n@@ -777,7 +747,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n              [lex.TokenType.INCOMPLETE_TAG_OPEN, '', 't'],\n              [lex.TokenType.ATTR_NAME, '', 'a'],\n              [lex.TokenType.ATTR_QUOTE, '\\''],\n-             [lex.TokenType.ATTR_VALUE_TEXT, 'b'],\n+             [lex.TokenType.ATTR_VALUE, 'b'],\n              [lex.TokenType.ATTR_QUOTE, '\\''],\n              // TODO(ayazhafiz): the ' symbol should be a synthetic attribute,\n              // allowing us to complete the opening tag correctly.\n@@ -1568,11 +1538,11 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n               [lex.TokenType.TAG_OPEN_START, '', 't'],\n               [lex.TokenType.ATTR_NAME, '', 'a'],\n               [lex.TokenType.ATTR_QUOTE, '\"'],\n-              [lex.TokenType.ATTR_VALUE_TEXT, 'b'],\n+              [lex.TokenType.ATTR_VALUE, 'b'],\n               [lex.TokenType.ATTR_QUOTE, '\"'],\n               [lex.TokenType.ATTR_NAME, '', 'c'],\n               [lex.TokenType.ATTR_QUOTE, '\\''],\n-              [lex.TokenType.ATTR_VALUE_TEXT, 'd'],\n+              [lex.TokenType.ATTR_VALUE, 'd'],\n               [lex.TokenType.ATTR_QUOTE, '\\''],\n               [lex.TokenType.TAG_OPEN_END],\n               [lex.TokenType.EOF],\n@@ -1621,7 +1591,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'd'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'e'],\n+          [lex.TokenType.ATTR_VALUE, 'e'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.TAG_CLOSE, '', 't'],\n@@ -1634,7 +1604,7 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n         expect(tokenizeAndHumanizeParts(text, {escapedString: true})).toEqual([\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'a'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'b'],\n+          [lex.TokenType.ATTR_VALUE, 'b'],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.TAG_CLOSE, '', 't'],\n           [lex.TokenType.EOF],"
        }
    ],
    "stats": {
        "total": 211,
        "additions": 68,
        "deletions": 143
    }
}