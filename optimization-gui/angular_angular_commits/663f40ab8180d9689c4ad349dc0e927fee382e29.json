{
    "author": "petebacondarwin",
    "message": "refactor(compiler): support encoded entity tokens when lexing markup (#43132)\n\nThe lexer now splits encoded entity tokens out from text and attribute value tokens.\n\nPreviously encoded entities would be decoded and the decoded value would be\nincluded as part of the text token of the surrounding text. Now the entities\nhave their own tokens. There are two scenarios: text and attribute values.\n\nPreviously the contents of `<div>Hello &amp; goodbye</div>` would be a single\nTEXT token. Now it will be three tokens:\n\n```\nTEXT: \"Hello \"\nENCODED_ENTITY: \"&\", \"&amp;\"\nTEXT: \" goodbye\"\n```\n\nPreviously the attribute value in `<div title=\"Hello &amp; goodbye\">` would be\na single text token. Now it will be three tokens:\n\n```\nATTR_VALUE_TEXT: \"Hello \"\nENCODED_ENTITY: \"&\", \"&amp;\"\nATTR_VALUE_TEXT: \" goodbye\"\n```\n\n- ENCODED_ENTITY tokens have two parts: \"decoded\" and \"encoded\".\n- ENCODED_ENTITY tokens are always preceded and followed by either TEXT tokens\n  or ATTR_VALUE_TEXT tokens, depending upon the context, even if they represent\n  an empty string.\n\nThe HTML parser has been modified to recombine these tokens to allow this\nrefactoring to have limited effect in this commit. Further refactorings\nto use these new tokens will follow in subsequent commits.\n\nPR Close #43132",
    "sha": "663f40ab8180d9689c4ad349dc0e927fee382e29",
    "files": [
        {
            "sha": "37a59af4fbc9d1ce1ebdc3ba670988f312205809",
            "filename": "packages/compiler-cli/test/compliance/test_cases/source_mapping/inline_templates/GOLDEN_PARTIAL.js",
            "status": "modified",
            "additions": 72,
            "deletions": 0,
            "changes": 72,
            "blob_url": "https://github.com/angular/angular/blob/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2FGOLDEN_PARTIAL.js",
            "raw_url": "https://github.com/angular/angular/raw/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2FGOLDEN_PARTIAL.js",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2FGOLDEN_PARTIAL.js?ref=663f40ab8180d9689c4ad349dc0e927fee382e29",
            "patch": "@@ -1652,6 +1652,78 @@ export declare class TestCmp {\n     static ɵcmp: i0.ɵɵComponentDeclaration<TestCmp, \"test-cmp\", never, {}, {}, never, never>;\n }\n \n+/****************************************************************************************************\n+ * PARTIAL FILE: i18n_message_placeholder_entities.js\n+ ****************************************************************************************************/\n+import { Component } from '@angular/core';\n+import * as i0 from \"@angular/core\";\n+export class TestCmp {\n+    constructor() {\n+        this.one = 1;\n+        this.two = 2;\n+    }\n+}\n+TestCmp.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: \"12.0.0\", version: \"0.0.0-PLACEHOLDER\", ngImport: i0, type: TestCmp, deps: [], target: i0.ɵɵFactoryTarget.Component });\n+TestCmp.ɵcmp = i0.ɵɵngDeclareComponent({ minVersion: \"12.0.0\", version: \"0.0.0-PLACEHOLDER\", type: TestCmp, selector: \"test-cmp\", ngImport: i0, template: '<div i18n>Interpolation: {{ one }}&nbsp;Interpolation: {{ two }}</div>', isInline: true });\n+i0.ɵɵngDeclareClassMetadata({ minVersion: \"12.0.0\", version: \"0.0.0-PLACEHOLDER\", ngImport: i0, type: TestCmp, decorators: [{\n+            type: Component,\n+            args: [{\n+                    selector: 'test-cmp',\n+                    template: '<div i18n>Interpolation: {{ one }}&nbsp;Interpolation: {{ two }}</div>',\n+                }]\n+        }] });\n+//# sourceMappingURL=i18n_message_placeholder_entities.js.map\n+/****************************************************************************************************\n+ * PARTIAL FILE: i18n_message_placeholder_entities.js.map\n+ ****************************************************************************************************/\n+{\"version\":3,\"file\":\"i18n_message_placeholder_entities.js\",\"sourceRoot\":\"\",\"sources\":[\"../i18n_message_placeholder_entities.ts\"],\"names\":[],\"mappings\":\"AAAA,OAAO,EAAC,SAAS,EAAC,MAAM,eAAe,CAAC;;AAMxC,MAAM,OAAO,OAAO;IAJpB;QAKE,QAAG,GAAG,CAAC,CAAC;QACR,QAAG,GAAG,CAAC,CAAC;KACT;;+GAHY,OAAO;mGAAP,OAAO,gDAFR,wEAAwE;sGAEvE,OAAO;kBAJnB,SAAS;mBAAC;oBACT,QAAQ,EAAE,UAAU;oBACpB,QAAQ,EAAE,wEAAwE;iBACnF\"}\n+/****************************************************************************************************\n+ * PARTIAL FILE: i18n_message_placeholder_entities.d.ts\n+ ****************************************************************************************************/\n+import * as i0 from \"@angular/core\";\n+export declare class TestCmp {\n+    one: number;\n+    two: number;\n+    static ɵfac: i0.ɵɵFactoryDeclaration<TestCmp, never>;\n+    static ɵcmp: i0.ɵɵComponentDeclaration<TestCmp, \"test-cmp\", never, {}, {}, never, never>;\n+}\n+\n+/****************************************************************************************************\n+ * PARTIAL FILE: i18n_message_placeholder_entities.js\n+ ****************************************************************************************************/\n+import { Component } from '@angular/core';\n+import * as i0 from \"@angular/core\";\n+export class TestCmp {\n+    constructor() {\n+        this.one = 1;\n+        this.two = 2;\n+    }\n+}\n+TestCmp.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: \"12.0.0\", version: \"0.0.0-PLACEHOLDER\", ngImport: i0, type: TestCmp, deps: [], target: i0.ɵɵFactoryTarget.Component });\n+TestCmp.ɵcmp = i0.ɵɵngDeclareComponent({ minVersion: \"12.0.0\", version: \"0.0.0-PLACEHOLDER\", type: TestCmp, selector: \"test-cmp\", ngImport: i0, template: '<div i18n>Interpolation: {{ one }}&nbsp;Interpolation: {{ two }}</div>', isInline: true });\n+i0.ɵɵngDeclareClassMetadata({ minVersion: \"12.0.0\", version: \"0.0.0-PLACEHOLDER\", ngImport: i0, type: TestCmp, decorators: [{\n+            type: Component,\n+            args: [{\n+                    selector: 'test-cmp',\n+                    template: '<div i18n>Interpolation: {{ one }}&nbsp;Interpolation: {{ two }}</div>',\n+                }]\n+        }] });\n+//# sourceMappingURL=i18n_message_placeholder_entities.js.map\n+/****************************************************************************************************\n+ * PARTIAL FILE: i18n_message_placeholder_entities.js.map\n+ ****************************************************************************************************/\n+{\"version\":3,\"file\":\"i18n_message_placeholder_entities.js\",\"sourceRoot\":\"\",\"sources\":[\"../i18n_message_placeholder_entities.ts\"],\"names\":[],\"mappings\":\"AAAA,OAAO,EAAC,SAAS,EAAC,MAAM,eAAe,CAAC;;AAMxC,MAAM,OAAO,OAAO;IAJpB;QAKE,QAAG,GAAG,CAAC,CAAC;QACR,QAAG,GAAG,CAAC,CAAC;KACT;;+GAHY,OAAO;mGAAP,OAAO,gDAFR,wEAAwE;sGAEvE,OAAO;kBAJnB,SAAS;mBAAC;oBACT,QAAQ,EAAE,UAAU;oBACpB,QAAQ,EAAE,wEAAwE;iBACnF\"}\n+/****************************************************************************************************\n+ * PARTIAL FILE: i18n_message_placeholder_entities.d.ts\n+ ****************************************************************************************************/\n+import * as i0 from \"@angular/core\";\n+export declare class TestCmp {\n+    one: number;\n+    two: number;\n+    static ɵfac: i0.ɵɵFactoryDeclaration<TestCmp, never>;\n+    static ɵcmp: i0.ɵɵComponentDeclaration<TestCmp, \"test-cmp\", never, {}, {}, never, never>;\n+}\n+\n /****************************************************************************************************\n  * PARTIAL FILE: i18n_message_interpolation_whitespace.js\n  ****************************************************************************************************/"
        },
        {
            "sha": "65f597bec5db5875c59a79a86f676c71ba7a8de6",
            "filename": "packages/compiler-cli/test/compliance/test_cases/source_mapping/inline_templates/TEST_CASES.json",
            "status": "modified",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/angular/angular/blob/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2FTEST_CASES.json",
            "raw_url": "https://github.com/angular/angular/raw/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2FTEST_CASES.json",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2FTEST_CASES.json?ref=663f40ab8180d9689c4ad349dc0e927fee382e29",
            "patch": "@@ -749,6 +749,40 @@\n         \"sourceMap\": true\n       }\n     },\n+    {\n+      \"description\": \"should handle encoded entities in i18n message source-mappings (full compile)\",\n+      \"inputFiles\": [\n+        \"i18n_message_placeholder_entities.ts\"\n+      ],\n+      \"compilationModeFilter\": [\n+        \"full compile\"\n+      ],\n+      \"compilerOptions\": {\n+        \"sourceMap\": true\n+      }\n+    },\n+    {\n+      \"description\": \"should handle encoded entities in i18n message source-mappings (partial compile)\",\n+      \"inputFiles\": [\n+        \"i18n_message_placeholder_entities.ts\"\n+      ],\n+      \"expectations\": [\n+        {\n+          \"files\": [\n+            {\n+              \"generated\": \"i18n_message_placeholder_entities.js\",\n+              \"expected\": \"i18n_message_placeholder_entities_partial.js\"\n+            }\n+          ]\n+        }\n+      ],\n+      \"compilationModeFilter\": [\n+        \"linked compile\"\n+      ],\n+      \"compilerOptions\": {\n+        \"sourceMap\": true\n+      }\n+    },\n     {\n       \"description\": \"should correctly handle collapsed whitespace in interpolation placeholder i18n message source-mappings (full compile)\",\n       \"inputFiles\": ["
        },
        {
            "sha": "288aa5d216201c1014d7c1f7220dd2287405a222",
            "filename": "packages/compiler-cli/test/compliance/test_cases/source_mapping/inline_templates/i18n_message_placeholder_entities.js",
            "status": "added",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/angular/angular/blob/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2Fi18n_message_placeholder_entities.js",
            "raw_url": "https://github.com/angular/angular/raw/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2Fi18n_message_placeholder_entities.js",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2Fi18n_message_placeholder_entities.js?ref=663f40ab8180d9689c4ad349dc0e927fee382e29",
            "patch": "@@ -0,0 +1,9 @@\n+`Interpolation: ${ // SOURCE: \"/i18n_message_placeholder_entities.ts\" \"Interpolation: \"\n+…\n+\"\\uFFFD0\\uFFFD\" // SOURCE: \"/i18n_message_placeholder_entities.ts\" \"{{ one }}\"\n+…\n+}:INTERPOLATION: Interpolation: ${ // SOURCE: \"/i18n_message_placeholder_entities.ts\" \"&nbsp;Interpolation: \"\n+…\n+\"\\uFFFD1\\uFFFD\" // SOURCE: \"/i18n_message_placeholder_entities.ts\" \"{{ two }}\"\n+…\n+}:INTERPOLATION_1:` // SOURCE: \"/i18n_message_placeholder_entities.ts\" \"</div>\""
        },
        {
            "sha": "df517b7f48b9ba756144d35e910a254448605e18",
            "filename": "packages/compiler-cli/test/compliance/test_cases/source_mapping/inline_templates/i18n_message_placeholder_entities.ts",
            "status": "added",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/angular/angular/blob/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2Fi18n_message_placeholder_entities.ts",
            "raw_url": "https://github.com/angular/angular/raw/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2Fi18n_message_placeholder_entities.ts",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2Fi18n_message_placeholder_entities.ts?ref=663f40ab8180d9689c4ad349dc0e927fee382e29",
            "patch": "@@ -0,0 +1,10 @@\n+import {Component} from '@angular/core';\n+\n+@Component({\n+  selector: 'test-cmp',\n+  template: '<div i18n>Interpolation: {{ one }}&nbsp;Interpolation: {{ two }}</div>',\n+})\n+export class TestCmp {\n+  one = 1;\n+  two = 2;\n+}"
        },
        {
            "sha": "1002ce6fcd13afb87d408570fa3dd97e0e151eb8",
            "filename": "packages/compiler-cli/test/compliance/test_cases/source_mapping/inline_templates/i18n_message_placeholder_entities_partial.js",
            "status": "added",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/angular/angular/blob/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2Fi18n_message_placeholder_entities_partial.js",
            "raw_url": "https://github.com/angular/angular/raw/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2Fi18n_message_placeholder_entities_partial.js",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler-cli%2Ftest%2Fcompliance%2Ftest_cases%2Fsource_mapping%2Finline_templates%2Fi18n_message_placeholder_entities_partial.js?ref=663f40ab8180d9689c4ad349dc0e927fee382e29",
            "patch": "@@ -0,0 +1,9 @@\n+$localize`Interpolation: ${ // SOURCE: \"/i18n_message_placeholder_entities.ts\" \"Interpolation: \"\n+…\n+\"\\uFFFD0\\uFFFD\" // SOURCE: \"/i18n_message_placeholder_entities.ts\" \"{{ one }}\"\n+…\n+}:INTERPOLATION: Interpolation: ${ // SOURCE: \"/i18n_message_placeholder_entities.ts\" \"&nbsp;Interpolation: \"\n+…\n+\"\\uFFFD1\\uFFFD\" // SOURCE: \"/i18n_message_placeholder_entities.ts\" \"{{ two }}\"\n+…\n+}:INTERPOLATION_1:` // SOURCE: \"/i18n_message_placeholder_entities.ts\" \"</div>'\""
        },
        {
            "sha": "8c9977b424deea3e0262a1025137dd2a895e6acc",
            "filename": "packages/compiler/src/ml_parser/lexer.ts",
            "status": "modified",
            "additions": 44,
            "deletions": 28,
            "changes": 72,
            "blob_url": "https://github.com/angular/angular/blob/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler%2Fsrc%2Fml_parser%2Flexer.ts",
            "raw_url": "https://github.com/angular/angular/raw/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler%2Fsrc%2Fml_parser%2Flexer.ts",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler%2Fsrc%2Fml_parser%2Flexer.ts?ref=663f40ab8180d9689c4ad349dc0e927fee382e29",
            "patch": "@@ -23,6 +23,7 @@ export enum TokenType {\n   ESCAPABLE_RAW_TEXT,\n   RAW_TEXT,\n   INTERPOLATION,\n+  ENCODED_ENTITY,\n   COMMENT_START,\n   COMMENT_END,\n   CDATA_START,\n@@ -398,19 +399,16 @@ class _Tokenizer {\n     }\n   }\n \n-  private _readChar(decodeEntities: boolean): string {\n-    if (decodeEntities && this._cursor.peek() === chars.$AMPERSAND) {\n-      return this._decodeEntity();\n-    } else {\n-      // Don't rely upon reading directly from `_input` as the actual char value\n-      // may have been generated from an escape sequence.\n-      const char = String.fromCodePoint(this._cursor.peek());\n-      this._cursor.advance();\n-      return char;\n-    }\n+  private _readChar(): string {\n+    // Don't rely upon reading directly from `_input` as the actual char value\n+    // may have been generated from an escape sequence.\n+    const char = String.fromCodePoint(this._cursor.peek());\n+    this._cursor.advance();\n+    return char;\n   }\n \n-  private _decodeEntity(): string {\n+  private _consumeEntity(textTokenType: TokenType): void {\n+    this._beginToken(TokenType.ENCODED_ENTITY);\n     const start = this._cursor.clone();\n     this._cursor.advance();\n     if (this._attemptCharCode(chars.$HASH)) {\n@@ -430,7 +428,7 @@ class _Tokenizer {\n       this._cursor.advance();\n       try {\n         const charCode = parseInt(strNum, isHex ? 16 : 10);\n-        return String.fromCharCode(charCode);\n+        this._endToken([String.fromCharCode(charCode), this._cursor.getChars(start)]);\n       } catch {\n         throw this._createError(\n             _unknownEntityErrorMsg(this._cursor.getChars(start)), this._cursor.getSpan());\n@@ -439,21 +437,25 @@ class _Tokenizer {\n       const nameStart = this._cursor.clone();\n       this._attemptCharCodeUntilFn(isNamedEntityEnd);\n       if (this._cursor.peek() != chars.$SEMICOLON) {\n+        // No semicolon was found so abort the encoded entity token that was in progress, and treat\n+        // this as a text token\n+        this._beginToken(textTokenType, start);\n         this._cursor = nameStart;\n-        return '&';\n-      }\n-      const name = this._cursor.getChars(nameStart);\n-      this._cursor.advance();\n-      const char = NAMED_ENTITIES[name];\n-      if (!char) {\n-        throw this._createError(_unknownEntityErrorMsg(name), this._cursor.getSpan(start));\n+        this._endToken(['&']);\n+      } else {\n+        const name = this._cursor.getChars(nameStart);\n+        this._cursor.advance();\n+        const char = NAMED_ENTITIES[name];\n+        if (!char) {\n+          throw this._createError(_unknownEntityErrorMsg(name), this._cursor.getSpan(start));\n+        }\n+        this._endToken([char, `&${name};`]);\n       }\n-      return char;\n     }\n   }\n \n-  private _consumeRawText(decodeEntities: boolean, endMarkerPredicate: () => boolean): Token {\n-    this._beginToken(decodeEntities ? TokenType.ESCAPABLE_RAW_TEXT : TokenType.RAW_TEXT);\n+  private _consumeRawText(consumeEntities: boolean, endMarkerPredicate: () => boolean): void {\n+    this._beginToken(consumeEntities ? TokenType.ESCAPABLE_RAW_TEXT : TokenType.RAW_TEXT);\n     const parts: string[] = [];\n     while (true) {\n       const tagCloseStart = this._cursor.clone();\n@@ -462,9 +464,16 @@ class _Tokenizer {\n       if (foundEndMarker) {\n         break;\n       }\n-      parts.push(this._readChar(decodeEntities));\n+      if (consumeEntities && this._cursor.peek() === chars.$AMPERSAND) {\n+        this._endToken([this._processCarriageReturns(parts.join(''))]);\n+        parts.length = 0;\n+        this._consumeEntity(TokenType.ESCAPABLE_RAW_TEXT);\n+        this._beginToken(TokenType.ESCAPABLE_RAW_TEXT);\n+      } else {\n+        parts.push(this._readChar());\n+      }\n     }\n-    return this._endToken([this._processCarriageReturns(parts.join(''))]);\n+    this._endToken([this._processCarriageReturns(parts.join(''))]);\n   }\n \n   private _consumeComment(start: CharacterCursor) {\n@@ -566,8 +575,8 @@ class _Tokenizer {\n     }\n   }\n \n-  private _consumeRawTextWithTagClose(prefix: string, tagName: string, decodeEntities: boolean) {\n-    this._consumeRawText(decodeEntities, () => {\n+  private _consumeRawTextWithTagClose(prefix: string, tagName: string, consumeEntities: boolean) {\n+    this._consumeRawText(consumeEntities, () => {\n       if (!this._attemptCharCode(chars.$LT)) return false;\n       if (!this._attemptCharCode(chars.$SLASH)) return false;\n       this._attemptCharCodeUntilFn(isNotWhitespace);\n@@ -725,11 +734,16 @@ class _Tokenizer {\n       const current = this._cursor.clone();\n       if (this._interpolationConfig && this._attemptStr(this._interpolationConfig.start)) {\n         this._endToken([this._processCarriageReturns(parts.join(''))], current);\n+        parts.length = 0;\n         this._consumeInterpolation(interpolationTokenType, current, endInterpolation);\n+        this._beginToken(textTokenType);\n+      } else if (this._cursor.peek() === chars.$AMPERSAND) {\n+        this._endToken([this._processCarriageReturns(parts.join(''))]);\n         parts.length = 0;\n+        this._consumeEntity(textTokenType);\n         this._beginToken(textTokenType);\n       } else {\n-        parts.push(this._readChar(true));\n+        parts.push(this._readChar());\n       }\n     }\n \n@@ -918,7 +932,9 @@ function mergeTextTokens(srcTokens: Token[]): Token[] {\n   let lastDstToken: Token|undefined = undefined;\n   for (let i = 0; i < srcTokens.length; i++) {\n     const token = srcTokens[i];\n-    if (lastDstToken && lastDstToken.type === TokenType.TEXT && token.type === TokenType.TEXT) {\n+    if ((lastDstToken && lastDstToken.type === TokenType.TEXT && token.type === TokenType.TEXT) ||\n+        (lastDstToken && lastDstToken.type === TokenType.ATTR_VALUE_TEXT &&\n+         token.type === TokenType.ATTR_VALUE_TEXT)) {\n       lastDstToken.parts[0]! += token.parts[0];\n       lastDstToken.sourceSpan.end = token.sourceSpan.end;\n     } else {"
        },
        {
            "sha": "960ba80654fde92dbd2b3d4794e11564d19083ba",
            "filename": "packages/compiler/src/ml_parser/parser.ts",
            "status": "modified",
            "additions": 21,
            "deletions": 17,
            "changes": 38,
            "blob_url": "https://github.com/angular/angular/blob/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler%2Fsrc%2Fml_parser%2Fparser.ts",
            "raw_url": "https://github.com/angular/angular/raw/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler%2Fsrc%2Fml_parser%2Fparser.ts",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler%2Fsrc%2Fml_parser%2Fparser.ts?ref=663f40ab8180d9689c4ad349dc0e927fee382e29",
            "patch": "@@ -226,20 +226,21 @@ class _TreeBuilder {\n       }\n     }\n \n-    // For now recombine text and interpolation tokens\n-    if (this._peek.type === lex.TokenType.INTERPOLATION) {\n-      while (this._peek.type === lex.TokenType.INTERPOLATION ||\n-             this._peek.type === lex.TokenType.TEXT) {\n-        token = this._advance();\n-        if (token.type === lex.TokenType.INTERPOLATION) {\n-          // For backward compatibility we decode HTML entities that appear in interpolation\n-          // expressions. This is arguably a bug, but it could be a considerable breaking change to\n-          // fix it. It should be addressed in a larger project to refactor the entire parser/lexer\n-          // chain after View Engine has been removed.\n-          text += token.parts.join('').replace(/&([^;]+);/g, decodeEntity);\n-        } else {\n-          text += token.parts.join('');\n-        }\n+    // For now recombine text, interpolation and entity tokens\n+    while (this._peek.type === lex.TokenType.INTERPOLATION ||\n+           this._peek.type === lex.TokenType.TEXT ||\n+           this._peek.type === lex.TokenType.ENCODED_ENTITY) {\n+      token = this._advance();\n+      if (token.type === lex.TokenType.INTERPOLATION) {\n+        // For backward compatibility we decode HTML entities that appear in interpolation\n+        // expressions. This is arguably a bug, but it could be a considerable breaking change to\n+        // fix it. It should be addressed in a larger project to refactor the entire parser/lexer\n+        // chain after View Engine has been removed.\n+        text += token.parts.join('').replace(/&([^;]+);/g, decodeEntity);\n+      } else if (token.type === lex.TokenType.ENCODED_ENTITY) {\n+        text += token.parts[0];\n+      } else {\n+        text += token.parts.join('');\n       }\n     }\n \n@@ -369,23 +370,26 @@ class _TreeBuilder {\n       this._advance();\n     }\n \n-    // Consume the value\n+    // Consume the attribute value\n     let value = '';\n     let valueStartSpan: ParseSourceSpan|undefined = undefined;\n     let valueEnd: ParseLocation|undefined = undefined;\n     if (this._peek.type === lex.TokenType.ATTR_VALUE_TEXT) {\n       valueStartSpan = this._peek.sourceSpan;\n       valueEnd = this._peek.sourceSpan.end;\n-      // For now we are recombining text and interpolation tokens\n+      // For now recombine text, interpolation and entity tokens\n       while (this._peek.type === lex.TokenType.ATTR_VALUE_TEXT ||\n-             this._peek.type === lex.TokenType.ATTR_VALUE_INTERPOLATION) {\n+             this._peek.type === lex.TokenType.ATTR_VALUE_INTERPOLATION ||\n+             this._peek.type === lex.TokenType.ENCODED_ENTITY) {\n         let valueToken = this._advance();\n         if (valueToken.type === lex.TokenType.ATTR_VALUE_INTERPOLATION) {\n           // For backward compatibility we decode HTML entities that appear in interpolation\n           // expressions. This is arguably a bug, but it could be a considerable breaking change to\n           // fix it. It should be addressed in a larger project to refactor the entire parser/lexer\n           // chain after View Engine has been removed.\n           value += valueToken.parts.join('').replace(/&([^;]+);/g, decodeEntity);\n+        } else if (valueToken.type === lex.TokenType.ENCODED_ENTITY) {\n+          value += valueToken.parts[0];\n         } else {\n           value += valueToken.parts.join('');\n         }"
        },
        {
            "sha": "082c5d001a68797babd6fbe40277a3d69b763d6c",
            "filename": "packages/compiler/test/ml_parser/html_parser_spec.ts",
            "status": "modified",
            "additions": 9,
            "deletions": 5,
            "changes": 14,
            "blob_url": "https://github.com/angular/angular/blob/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler%2Ftest%2Fml_parser%2Fhtml_parser_spec.ts",
            "raw_url": "https://github.com/angular/angular/raw/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler%2Ftest%2Fml_parser%2Fhtml_parser_spec.ts",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler%2Ftest%2Fml_parser%2Fhtml_parser_spec.ts?ref=663f40ab8180d9689c4ad349dc0e927fee382e29",
            "patch": "@@ -249,9 +249,9 @@ import {humanizeDom, humanizeDomSourceSpans, humanizeLineColumn, humanizeNodes}\n               '<div>', '</div>'\n             ],\n             [html.Element, 'span', 1, '<span>x {{ expr }<!---->} y</span>', '<span>', '</span>'],\n-            [html.Text, 'x {{ expr }', 2, 'x {{ expr }'],\n+            [html.Text, 'x {{ expr }', 2, ['x '], ['{{', ' expr }'], [''], 'x {{ expr }'],\n             [html.Comment, '', 2, '<!--'],\n-            [html.Text, '} y', 2, '} y'],\n+            [html.Text, '} y', 2, ['} y'], '} y'],\n             [html.Element, 'div', 1, '<div></div>', '<div>', '</div>'],\n           ]);\n           expect(errors).toEqual([]);\n@@ -269,7 +269,8 @@ import {humanizeDom, humanizeDomSourceSpans, humanizeLineColumn, humanizeNodes}\n \n         it('should parse attributes containing unquoted interpolation', () => {\n           expect(humanizeDom(parser.parse('<div foo={{message}}></div>', 'TestComp'))).toEqual([\n-            [html.Element, 'div', 0], [html.Attribute, 'foo', '{{message}}']\n+            [html.Element, 'div', 0],\n+            [html.Attribute, 'foo', '{{message}}', [''], ['{{', 'message', '}}'], ['']]\n           ]);\n         });\n \n@@ -285,7 +286,10 @@ import {humanizeDom, humanizeDomSourceSpans, humanizeLineColumn, humanizeNodes}\n                 [\n                   html.Attribute, '[attr]', `[\n                         {text: 'some text',url:'//www.google.com'},\n-                        {text:'other text',url:'//www.google.com'}]`\n+                        {text:'other text',url:'//www.google.com'}]`,\n+                  [`[\n+                        {text: 'some text',url:'//www.google.com'},\n+                        {text:'other text',url:'//www.google.com'}]`]\n                 ],\n               ]);\n         });\n@@ -346,7 +350,7 @@ import {humanizeDom, humanizeDomSourceSpans, humanizeLineColumn, humanizeNodes}\n           const {errors, rootNodes} = parser.parse('<div p=\"{{ abc\"><span></span>', 'TestComp');\n           expect(humanizeNodes(rootNodes, true)).toEqual([\n             [html.Element, 'div', 0, '<div p=\"{{ abc\">', '<div p=\"{{ abc\">', null],\n-            [html.Attribute, 'p', '{{ abc', 'p=\"{{ abc\"'],\n+            [html.Attribute, 'p', '{{ abc', [''], ['{{', ' abc'], [''], 'p=\"{{ abc\"'],\n             [html.Element, 'span', 1, '<span></span>', '<span>', '</span>'],\n           ]);\n           expect(humanizeErrors(errors)).toEqual([]);"
        },
        {
            "sha": "e8c7b7b8ccfe840e2ac3ac8e57159e573c69cd5b",
            "filename": "packages/compiler/test/ml_parser/lexer_spec.ts",
            "status": "modified",
            "additions": 73,
            "deletions": 14,
            "changes": 87,
            "blob_url": "https://github.com/angular/angular/blob/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler%2Ftest%2Fml_parser%2Flexer_spec.ts",
            "raw_url": "https://github.com/angular/angular/raw/663f40ab8180d9689c4ad349dc0e927fee382e29/packages%2Fcompiler%2Ftest%2Fml_parser%2Flexer_spec.ts",
            "contents_url": "https://api.github.com/repos/angular/angular/contents/packages%2Fcompiler%2Ftest%2Fml_parser%2Flexer_spec.ts?ref=663f40ab8180d9689c4ad349dc0e927fee382e29",
            "patch": "@@ -316,6 +316,32 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n         ]);\n       });\n \n+      it('should end interpolation on an unescaped matching quote', () => {\n+        expect(tokenizeAndHumanizeParts('<t a=\"{{ a \\\\\" \\' b \">')).toEqual([\n+          [lex.TokenType.TAG_OPEN_START, '', 't'],\n+          [lex.TokenType.ATTR_NAME, '', 'a'],\n+          [lex.TokenType.ATTR_QUOTE, '\"'],\n+          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n+          [lex.TokenType.ATTR_VALUE_INTERPOLATION, '{{', ' a \\\\\" \\' b '],\n+          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n+          [lex.TokenType.ATTR_QUOTE, '\"'],\n+          [lex.TokenType.TAG_OPEN_END],\n+          [lex.TokenType.EOF],\n+        ]);\n+\n+        expect(tokenizeAndHumanizeParts('<t a=\\'{{ a \" \\\\\\' b \\'>')).toEqual([\n+          [lex.TokenType.TAG_OPEN_START, '', 't'],\n+          [lex.TokenType.ATTR_NAME, '', 'a'],\n+          [lex.TokenType.ATTR_QUOTE, '\\''],\n+          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n+          [lex.TokenType.ATTR_VALUE_INTERPOLATION, '{{', ' a \" \\\\\\' b '],\n+          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n+          [lex.TokenType.ATTR_QUOTE, '\\''],\n+          [lex.TokenType.TAG_OPEN_END],\n+          [lex.TokenType.EOF],\n+        ]);\n+      });\n+\n       it('should parse attributes with prefix', () => {\n         expect(tokenizeAndHumanizeParts('<t ns1:a>')).toEqual([\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n@@ -428,7 +454,11 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n           [lex.TokenType.TAG_OPEN_START, '', 't'],\n           [lex.TokenType.ATTR_NAME, '', 'a'],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n-          [lex.TokenType.ATTR_VALUE_TEXT, 'AA'],\n+          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n+          [lex.TokenType.ENCODED_ENTITY, 'A', '&#65;'],\n+          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n+          [lex.TokenType.ENCODED_ENTITY, 'A', '&#x41;'],\n+          [lex.TokenType.ATTR_VALUE_TEXT, ''],\n           [lex.TokenType.ATTR_QUOTE, '\"'],\n           [lex.TokenType.TAG_OPEN_END],\n           [lex.TokenType.EOF],\n@@ -543,50 +573,60 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n     describe('entities', () => {\n       it('should parse named entities', () => {\n         expect(tokenizeAndHumanizeParts('a&amp;b')).toEqual([\n-          [lex.TokenType.TEXT, 'a&b'],\n+          [lex.TokenType.TEXT, 'a'],\n+          [lex.TokenType.ENCODED_ENTITY, '&', '&amp;'],\n+          [lex.TokenType.TEXT, 'b'],\n           [lex.TokenType.EOF],\n         ]);\n       });\n \n       it('should parse hexadecimal entities', () => {\n         expect(tokenizeAndHumanizeParts('&#x41;&#X41;')).toEqual([\n-          [lex.TokenType.TEXT, 'AA'],\n+          [lex.TokenType.TEXT, ''],\n+          [lex.TokenType.ENCODED_ENTITY, 'A', '&#x41;'],\n+          [lex.TokenType.TEXT, ''],\n+          [lex.TokenType.ENCODED_ENTITY, 'A', '&#X41;'],\n+          [lex.TokenType.TEXT, ''],\n           [lex.TokenType.EOF],\n         ]);\n       });\n \n       it('should parse decimal entities', () => {\n         expect(tokenizeAndHumanizeParts('&#65;')).toEqual([\n-          [lex.TokenType.TEXT, 'A'],\n+          [lex.TokenType.TEXT, ''],\n+          [lex.TokenType.ENCODED_ENTITY, 'A', '&#65;'],\n+          [lex.TokenType.TEXT, ''],\n           [lex.TokenType.EOF],\n         ]);\n       });\n \n       it('should store the locations', () => {\n         expect(tokenizeAndHumanizeSourceSpans('a&amp;b')).toEqual([\n-          [lex.TokenType.TEXT, 'a&amp;b'],\n+          [lex.TokenType.TEXT, 'a'],\n+          [lex.TokenType.ENCODED_ENTITY, '&amp;'],\n+          [lex.TokenType.TEXT, 'b'],\n           [lex.TokenType.EOF, ''],\n         ]);\n       });\n \n       it('should report malformed/unknown entities', () => {\n         expect(tokenizeAndHumanizeErrors('&tbo;')).toEqual([[\n-          lex.TokenType.TEXT,\n+          lex.TokenType.ENCODED_ENTITY,\n           'Unknown entity \"tbo\" - use the \"&#<decimal>;\" or  \"&#x<hex>;\" syntax', '0:0'\n         ]]);\n         expect(tokenizeAndHumanizeErrors('&#3sdf;')).toEqual([[\n-          lex.TokenType.TEXT,\n+          lex.TokenType.ENCODED_ENTITY,\n           'Unable to parse entity \"&#3s\" - decimal character reference entities must end with \";\"',\n           '0:4'\n         ]]);\n         expect(tokenizeAndHumanizeErrors('&#xasdf;')).toEqual([[\n-          lex.TokenType.TEXT,\n+          lex.TokenType.ENCODED_ENTITY,\n           'Unable to parse entity \"&#xas\" - hexadecimal character reference entities must end with \";\"',\n           '0:5'\n         ]]);\n \n         expect(tokenizeAndHumanizeErrors('&#xABC')).toEqual([\n-          [lex.TokenType.TEXT, 'Unexpected character \"EOF\"', '0:6']\n+          [lex.TokenType.ENCODED_ENTITY, 'Unexpected character \"EOF\"', '0:6']\n         ]);\n       });\n     });\n@@ -600,14 +640,15 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n       });\n \n       it('should parse interpolation', () => {\n-        expect(tokenizeAndHumanizeParts('{{ a }}b{{ c // comment }}d{{ e \"}}\" f }}g{{ h // \" i }}'))\n+        expect(tokenizeAndHumanizeParts(\n+                   '{{ a }}b{{ c // comment }}d{{ e \"}} \\' \" f }}g{{ h // \" i }}'))\n             .toEqual([\n               [lex.TokenType.TEXT, ''],\n               [lex.TokenType.INTERPOLATION, '{{', ' a ', '}}'],\n               [lex.TokenType.TEXT, 'b'],\n               [lex.TokenType.INTERPOLATION, '{{', ' c // comment ', '}}'],\n               [lex.TokenType.TEXT, 'd'],\n-              [lex.TokenType.INTERPOLATION, '{{', ' e \"}}\" f ', '}}'],\n+              [lex.TokenType.INTERPOLATION, '{{', ' e \"}} \\' \" f ', '}}'],\n               [lex.TokenType.TEXT, 'g'],\n               [lex.TokenType.INTERPOLATION, '{{', ' h // \" i ', '}}'],\n               [lex.TokenType.TEXT, ''],\n@@ -664,12 +705,16 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n \n       it('should parse entities', () => {\n         expect(tokenizeAndHumanizeParts('a&amp;b')).toEqual([\n-          [lex.TokenType.TEXT, 'a&b'],\n+          [lex.TokenType.TEXT, 'a'],\n+          [lex.TokenType.ENCODED_ENTITY, '&', '&amp;'],\n+          [lex.TokenType.TEXT, 'b'],\n           [lex.TokenType.EOF],\n         ]);\n \n         expect(tokenizeAndHumanizeSourceSpans('a&amp;b')).toEqual([\n-          [lex.TokenType.TEXT, 'a&amp;b'],\n+          [lex.TokenType.TEXT, 'a'],\n+          [lex.TokenType.ENCODED_ENTITY, '&amp;'],\n+          [lex.TokenType.TEXT, 'b'],\n           [lex.TokenType.EOF, ''],\n         ]);\n       });\n@@ -738,6 +783,18 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n         ]);\n       });\n \n+      it('should end interpolation on a valid closing tag', () => {\n+        expect(tokenizeAndHumanizeParts('<p>{{ a </p>')).toEqual([\n+          [lex.TokenType.TAG_OPEN_START, '', 'p'],\n+          [lex.TokenType.TAG_OPEN_END],\n+          [lex.TokenType.TEXT, ''],\n+          [lex.TokenType.INTERPOLATION, '{{', ' a '],\n+          [lex.TokenType.TEXT, ''],\n+          [lex.TokenType.TAG_CLOSE, '', 'p'],\n+          [lex.TokenType.EOF],\n+        ]);\n+      });\n+\n       it('should break out of interpolation in text token on valid CDATA', () => {\n         expect(tokenizeAndHumanizeParts('{{ a }<![CDATA[]]>}')).toEqual([\n           [lex.TokenType.TEXT, ''],\n@@ -915,7 +972,9 @@ import {ParseLocation, ParseSourceFile, ParseSourceSpan} from '../../src/parse_u\n         expect(tokenizeAndHumanizeParts(`<title>&amp;</title>`)).toEqual([\n           [lex.TokenType.TAG_OPEN_START, '', 'title'],\n           [lex.TokenType.TAG_OPEN_END],\n-          [lex.TokenType.ESCAPABLE_RAW_TEXT, '&'],\n+          [lex.TokenType.ESCAPABLE_RAW_TEXT, ''],\n+          [lex.TokenType.ENCODED_ENTITY, '&', '&amp;'],\n+          [lex.TokenType.ESCAPABLE_RAW_TEXT, ''],\n           [lex.TokenType.TAG_CLOSE, '', 'title'],\n           [lex.TokenType.EOF],\n         ]);"
        }
    ],
    "stats": {
        "total": 345,
        "additions": 281,
        "deletions": 64
    }
}