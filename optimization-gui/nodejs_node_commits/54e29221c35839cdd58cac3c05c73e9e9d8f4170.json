{
    "author": "Trott",
    "message": "doc: fix minor text issues in stream.md\n\nImplement several minor grammar, punctuation, and style fixes in\nstream.md.\n\nPR-URL: https://github.com/nodejs/node/pull/24116\nReviewed-By: Richard Lau <riclau@uk.ibm.com>\nReviewed-By: Daniel Bevenius <daniel.bevenius@gmail.com>",
    "sha": "54e29221c35839cdd58cac3c05c73e9e9d8f4170",
    "files": [
        {
            "sha": "2f35ec30b5bde862402224932c6b654ebecf3bc6",
            "filename": "doc/api/stream.md",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/nodejs/node/blob/54e29221c35839cdd58cac3c05c73e9e9d8f4170/doc%2Fapi%2Fstream.md",
            "raw_url": "https://github.com/nodejs/node/raw/54e29221c35839cdd58cac3c05c73e9e9d8f4170/doc%2Fapi%2Fstream.md",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/doc%2Fapi%2Fstream.md?ref=54e29221c35839cdd58cac3c05c73e9e9d8f4170",
            "patch": "@@ -46,7 +46,7 @@ There are four fundamental stream types within Node.js:\n * [`Transform`][] - `Duplex` streams that can modify or transform the data as it\n   is written and read (for example, [`zlib.createDeflate()`][]).\n \n-Additionally this module includes the utility functions [pipeline][] and\n+Additionally, this module includes the utility functions [pipeline][] and\n [finished][].\n \n ### Object Mode\n@@ -97,7 +97,7 @@ is to limit the buffering of data to acceptable levels such that sources and\n destinations of differing speeds will not overwhelm the available memory.\n \n Because [`Duplex`][] and [`Transform`][] streams are both `Readable` and\n-`Writable`, each maintain *two* separate internal buffers used for reading and\n+`Writable`, each maintains *two* separate internal buffers used for reading and\n writing, allowing each side to operate independently of the other while\n maintaining an appropriate and efficient flow of data. For example,\n [`net.Socket`][] instances are [`Duplex`][] streams whose `Readable` side allows\n@@ -388,7 +388,7 @@ changes:\n   not operating in object mode, `chunk` must be a string, `Buffer` or\n   `Uint8Array`. For object mode streams, `chunk` may be any JavaScript value\n   other than `null`.\n-* `encoding` {string} The encoding, if `chunk` is a string\n+* `encoding` {string} The encoding if `chunk` is a string\n * `callback` {Function} Optional callback for when the stream is finished\n * Returns: {this}\n \n@@ -531,7 +531,7 @@ not draining may lead to a remotely exploitable vulnerability.\n \n Writing data while the stream is not draining is particularly\n problematic for a [`Transform`][], because the `Transform` streams are paused\n-by default until they are piped or an `'data'` or `'readable'` event handler\n+by default until they are piped or a `'data'` or `'readable'` event handler\n is added.\n \n If the data to be written can be generated or fetched on demand, it is\n@@ -610,7 +610,7 @@ until a mechanism for either consuming or ignoring that data is provided. If\n the consuming mechanism is disabled or taken away, the `Readable` will *attempt*\n to stop generating the data.\n \n-For backwards compatibility reasons, removing [`'data'`][] event handlers will\n+For backward compatibility reasons, removing [`'data'`][] event handlers will\n **not** automatically pause the stream. Also, if there are piped destinations,\n then calling [`stream.pause()`][stream-pause] will not guarantee that the\n stream will *remain* paused once those destinations drain and ask for more data.\n@@ -1351,7 +1351,7 @@ Especially useful in error handling scenarios where a stream is destroyed\n prematurely (like an aborted HTTP request), and will not emit `'end'`\n or `'finish'`.\n \n-The `finished` API is promisify'able as well;\n+The `finished` API is promisify-able as well;\n \n ```js\n const finished = util.promisify(stream.finished);\n@@ -1403,7 +1403,7 @@ pipeline(\n );\n ```\n \n-The `pipeline` API is promisify'able as well:\n+The `pipeline` API is promisify-able as well:\n \n ```js\n const pipeline = util.promisify(stream.pipeline);\n@@ -1892,7 +1892,7 @@ changes:\n   any JavaScript value.\n * `encoding` {string} Encoding of string chunks. Must be a valid\n   `Buffer` encoding, such as `'utf8'` or `'ascii'`.\n-* Returns: {boolean} `true` if additional chunks of data may continued to be\n+* Returns: {boolean} `true` if additional chunks of data may continue to be\n   pushed; `false` otherwise.\n \n When `chunk` is a `Buffer`, `Uint8Array` or `string`, the `chunk` of data will\n@@ -2305,7 +2305,7 @@ The `callback` function must be called only when the current chunk is completely\n consumed. The first argument passed to the `callback` must be an `Error` object\n if an error occurred while processing the input or `null` otherwise. If a second\n argument is passed to the `callback`, it will be forwarded on to the\n-`readable.push()` method. In other words the following are equivalent:\n+`readable.push()` method. In other words, the following are equivalent:\n \n ```js\n transform.prototype._transform = function(data, encoding, callback) {\n@@ -2352,7 +2352,7 @@ less powerful and less useful.\n   guaranteed. This meant that it was still necessary to be prepared to receive\n   [`'data'`][] events *even when the stream was in a paused state*.\n \n-In Node.js 0.10, the [`Readable`][] class was added. For backwards\n+In Node.js 0.10, the [`Readable`][] class was added. For backward\n compatibility with older Node.js programs, `Readable` streams switch into\n \"flowing mode\" when a [`'data'`][] event handler is added, or when the\n [`stream.resume()`][stream-resume] method is called. The effect is that, even"
        }
    ],
    "stats": {
        "total": 20,
        "additions": 10,
        "deletions": 10
    }
}