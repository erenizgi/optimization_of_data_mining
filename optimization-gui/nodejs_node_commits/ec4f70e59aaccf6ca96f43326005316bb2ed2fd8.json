{
    "author": "refack",
    "message": "tools,test: cleanup and dedup code\n\n* Hoist common code to base class\n  (`GetTestStatus`, and the `section` property to `TestConfiguration`)\n* Replace ListSet with the built in set\n* Remove ClassifiedTest\n* Inline PrintReport\n* How cases_to_run are filtered\n\nPR-URL: https://github.com/nodejs/node/pull/23251\nReviewed-By: Rich Trott <rtrott@gmail.com>",
    "sha": "ec4f70e59aaccf6ca96f43326005316bb2ed2fd8",
    "files": [
        {
            "sha": "7e8d73bb39acd7eaca3d33f81075f2f7bacdddb8",
            "filename": "test/message/testcfg.py",
            "status": "modified",
            "additions": 1,
            "deletions": 10,
            "changes": 11,
            "blob_url": "https://github.com/nodejs/node/blob/ec4f70e59aaccf6ca96f43326005316bb2ed2fd8/test%2Fmessage%2Ftestcfg.py",
            "raw_url": "https://github.com/nodejs/node/raw/ec4f70e59aaccf6ca96f43326005316bb2ed2fd8/test%2Fmessage%2Ftestcfg.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/test%2Fmessage%2Ftestcfg.py?ref=ec4f70e59aaccf6ca96f43326005316bb2ed2fd8",
            "patch": "@@ -108,10 +108,6 @@ def GetSource(self):\n \n \n class MessageTestConfiguration(test.TestConfiguration):\n-\n-  def __init__(self, context, root):\n-    super(MessageTestConfiguration, self).__init__(context, root)\n-\n   def Ls(self, path):\n     if isdir(path):\n       return [f for f in os.listdir(path)\n@@ -135,11 +131,6 @@ def ListTests(self, current_path, path, arch, mode):\n   def GetBuildRequirements(self):\n     return ['sample', 'sample=shell']\n \n-  def GetTestStatus(self, sections, defs):\n-    status_file = join(self.root, 'message.status')\n-    if exists(status_file):\n-      test.ReadConfigurationInto(status_file, sections, defs)\n-\n \n def GetConfiguration(context, root):\n-  return MessageTestConfiguration(context, root)\n+  return MessageTestConfiguration(context, root, 'message')"
        },
        {
            "sha": "a5b7917bc05a464be0b1011332679211f45be72f",
            "filename": "test/pseudo-tty/testcfg.py",
            "status": "modified",
            "additions": 1,
            "deletions": 10,
            "changes": 11,
            "blob_url": "https://github.com/nodejs/node/blob/ec4f70e59aaccf6ca96f43326005316bb2ed2fd8/test%2Fpseudo-tty%2Ftestcfg.py",
            "raw_url": "https://github.com/nodejs/node/raw/ec4f70e59aaccf6ca96f43326005316bb2ed2fd8/test%2Fpseudo-tty%2Ftestcfg.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/test%2Fpseudo-tty%2Ftestcfg.py?ref=ec4f70e59aaccf6ca96f43326005316bb2ed2fd8",
            "patch": "@@ -122,10 +122,6 @@ def RunCommand(self, command, env):\n \n \n class TTYTestConfiguration(test.TestConfiguration):\n-\n-  def __init__(self, context, root):\n-    super(TTYTestConfiguration, self).__init__(context, root)\n-\n   def Ls(self, path):\n     if isdir(path):\n         return [f[:-3] for f in os.listdir(path) if f.endswith('.js')]\n@@ -155,11 +151,6 @@ def ListTests(self, current_path, path, arch, mode):\n   def GetBuildRequirements(self):\n     return ['sample', 'sample=shell']\n \n-  def GetTestStatus(self, sections, defs):\n-    status_file = join(self.root, 'pseudo-tty.status')\n-    if exists(status_file):\n-      test.ReadConfigurationInto(status_file, sections, defs)\n-\n \n def GetConfiguration(context, root):\n-  return TTYTestConfiguration(context, root)\n+  return TTYTestConfiguration(context, root, 'pseudo-tty')"
        },
        {
            "sha": "27d7124bf2ed16bd4e0913ec557dee1a7fc0456e",
            "filename": "test/testpy/__init__.py",
            "status": "modified",
            "additions": 2,
            "deletions": 8,
            "changes": 10,
            "blob_url": "https://github.com/nodejs/node/blob/ec4f70e59aaccf6ca96f43326005316bb2ed2fd8/test%2Ftestpy%2F__init__.py",
            "raw_url": "https://github.com/nodejs/node/raw/ec4f70e59aaccf6ca96f43326005316bb2ed2fd8/test%2Ftestpy%2F__init__.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/test%2Ftestpy%2F__init__.py?ref=ec4f70e59aaccf6ca96f43326005316bb2ed2fd8",
            "patch": "@@ -95,11 +95,10 @@ def GetCommand(self):\n   def GetSource(self):\n     return open(self.file).read()\n \n-class SimpleTestConfiguration(test.TestConfiguration):\n \n+class SimpleTestConfiguration(test.TestConfiguration):\n   def __init__(self, context, root, section, additional=None):\n-    super(SimpleTestConfiguration, self).__init__(context, root)\n-    self.section = section\n+    super(SimpleTestConfiguration, self).__init__(context, root, section)\n     if additional is not None:\n       self.additional_flags = additional\n     else:\n@@ -122,11 +121,6 @@ def ListTests(self, current_path, path, arch, mode):\n   def GetBuildRequirements(self):\n     return ['sample', 'sample=shell']\n \n-  def GetTestStatus(self, sections, defs):\n-    status_file = join(self.root, '%s.status' % (self.section))\n-    if exists(status_file):\n-      test.ReadConfigurationInto(status_file, sections, defs)\n-\n class ParallelTestConfiguration(SimpleTestConfiguration):\n   def __init__(self, context, root, section, additional=None):\n     super(ParallelTestConfiguration, self).__init__(context, root, section,"
        },
        {
            "sha": "3d62eedd1631e2627357cb324ebd6828f9e69c4f",
            "filename": "tools/test.py",
            "status": "modified",
            "additions": 54,
            "deletions": 96,
            "changes": 150,
            "blob_url": "https://github.com/nodejs/node/blob/ec4f70e59aaccf6ca96f43326005316bb2ed2fd8/tools%2Ftest.py",
            "raw_url": "https://github.com/nodejs/node/raw/ec4f70e59aaccf6ca96f43326005316bb2ed2fd8/tools%2Ftest.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Ftest.py?ref=ec4f70e59aaccf6ca96f43326005316bb2ed2fd8",
            "patch": "@@ -131,7 +131,7 @@ def RunSingle(self, parallel, thread_id):\n           test = self.sequential_queue.get_nowait()\n         except Empty:\n           return\n-      case = test.case\n+      case = test\n       case.thread_id = thread_id\n       self.lock.acquire()\n       self.AboutToRun(case)\n@@ -780,10 +780,10 @@ def CarCdr(path):\n \n \n class TestConfiguration(object):\n-\n-  def __init__(self, context, root):\n+  def __init__(self, context, root, section):\n     self.context = context\n     self.root = root\n+    self.section = section\n \n   def Contains(self, path, file):\n     if len(path) > len(file):\n@@ -794,7 +794,9 @@ def Contains(self, path, file):\n     return True\n \n   def GetTestStatus(self, sections, defs):\n-    pass\n+    status_file = join(self.root, '%s.status' % self.section)\n+    if exists(status_file):\n+      ReadConfigurationInto(status_file, sections, defs)\n \n \n class TestSuite(object):\n@@ -934,6 +936,7 @@ def RunTestCases(cases_to_run, progress, tasks, flaky_tests_mode):\n # -------------------------------------------\n \n \n+RUN = 'run'\n SKIP = 'skip'\n FAIL = 'fail'\n PASS = 'pass'\n@@ -963,8 +966,8 @@ def __init__(self, name):\n     self.name = name\n \n   def GetOutcomes(self, env, defs):\n-    if self.name in env: return ListSet([env[self.name]])\n-    else: return Nothing()\n+    if self.name in env: return set([env[self.name]])\n+    else: return set()\n \n \n class Outcome(Expression):\n@@ -976,45 +979,7 @@ def GetOutcomes(self, env, defs):\n     if self.name in defs:\n       return defs[self.name].GetOutcomes(env, defs)\n     else:\n-      return ListSet([self.name])\n-\n-\n-class Set(object):\n-  pass\n-\n-\n-class ListSet(Set):\n-\n-  def __init__(self, elms):\n-    self.elms = elms\n-\n-  def __str__(self):\n-    return \"ListSet%s\" % str(self.elms)\n-\n-  def Intersect(self, that):\n-    if not isinstance(that, ListSet):\n-      return that.Intersect(self)\n-    return ListSet([ x for x in self.elms if x in that.elms ])\n-\n-  def Union(self, that):\n-    if not isinstance(that, ListSet):\n-      return that.Union(self)\n-    return ListSet(self.elms + [ x for x in that.elms if x not in self.elms ])\n-\n-  def IsEmpty(self):\n-    return len(self.elms) == 0\n-\n-\n-class Nothing(Set):\n-\n-  def Intersect(self, that):\n-    return self\n-\n-  def Union(self, that):\n-    return that\n-\n-  def IsEmpty(self):\n-    return True\n+      return set([self.name])\n \n \n class Operation(Expression):\n@@ -1030,21 +995,23 @@ def Evaluate(self, env, defs):\n     elif self.op == 'if':\n       return False\n     elif self.op == '==':\n-      inter = self.left.GetOutcomes(env, defs).Intersect(self.right.GetOutcomes(env, defs))\n-      return not inter.IsEmpty()\n+      inter = self.left.GetOutcomes(env, defs) & self.right.GetOutcomes(env, defs)\n+      return bool(inter)\n     else:\n       assert self.op == '&&'\n       return self.left.Evaluate(env, defs) and self.right.Evaluate(env, defs)\n \n   def GetOutcomes(self, env, defs):\n     if self.op == '||' or self.op == ',':\n-      return self.left.GetOutcomes(env, defs).Union(self.right.GetOutcomes(env, defs))\n+      return self.left.GetOutcomes(env, defs) | self.right.GetOutcomes(env, defs)\n     elif self.op == 'if':\n-      if self.right.Evaluate(env, defs): return self.left.GetOutcomes(env, defs)\n-      else: return Nothing()\n+      if self.right.Evaluate(env, defs):\n+        return self.left.GetOutcomes(env, defs)\n+      else:\n+        return set()\n     else:\n       assert self.op == '&&'\n-      return self.left.GetOutcomes(env, defs).Intersect(self.right.GetOutcomes(env, defs))\n+      return self.left.GetOutcomes(env, defs) & self.right.GetOutcomes(env, defs)\n \n \n def IsAlpha(str):\n@@ -1223,15 +1190,6 @@ def ParseCondition(expr):\n   return ast\n \n \n-class ClassifiedTest(object):\n-\n-  def __init__(self, case, outcomes):\n-    self.case = case\n-    self.outcomes = outcomes\n-    self.parallel = self.case.parallel\n-    self.disable_core_files = self.case.disable_core_files\n-\n-\n class Configuration(object):\n   \"\"\"The parsed contents of a configuration file\"\"\"\n \n@@ -1281,9 +1239,7 @@ def __init__(self, raw_path, path, value):\n     self.value = value\n \n   def GetOutcomes(self, env, defs):\n-    set = self.value.GetOutcomes(env, defs)\n-    assert isinstance(set, ListSet)\n-    return set.elms\n+    return self.value.GetOutcomes(env, defs)\n \n   def Contains(self, path):\n     if len(self.path) > len(path):\n@@ -1428,6 +1384,7 @@ def ProcessOptions(options):\n   options.mode = options.mode.split(',')\n   options.run = options.run.split(',')\n   options.skip_tests = options.skip_tests.split(',')\n+  options.skip_tests.remove(\"\")\n   if options.run == [\"\"]:\n     options.run = None\n   elif len(options.run) != 2:\n@@ -1450,7 +1407,7 @@ def ProcessOptions(options):\n     # tends to exaggerate the number of available cpus/cores.\n     cores = os.environ.get('JOBS')\n     options.j = int(cores) if cores is not None else multiprocessing.cpu_count()\n-  if options.flaky_tests not in [\"run\", \"skip\", \"dontcare\"]:\n+  if options.flaky_tests not in [RUN, SKIP, DONTCARE]:\n     print \"Unknown flaky-tests mode %s\" % options.flaky_tests\n     return False\n   return True\n@@ -1464,18 +1421,6 @@ def ProcessOptions(options):\n  * %(fail)4d tests are expected to fail that we should fix\\\n \"\"\"\n \n-def PrintReport(cases):\n-  def IsFailOk(o):\n-    return (len(o) == 2) and (FAIL in o) and (OKAY in o)\n-  unskipped = [c for c in cases if not SKIP in c.outcomes]\n-  print REPORT_TEMPLATE % {\n-    'total': len(cases),\n-    'skipped': len(cases) - len(unskipped),\n-    'pass': len([t for t in unskipped if list(t.outcomes) == [PASS]]),\n-    'fail_ok': len([t for t in unskipped if IsFailOk(t.outcomes)]),\n-    'fail': len([t for t in unskipped if list(t.outcomes) == [FAIL]])\n-  }\n-\n \n class Pattern(object):\n \n@@ -1534,6 +1479,14 @@ def FormatTime(d):\n   return time.strftime(\"%M:%S.\", time.gmtime(d)) + (\"%03i\" % millis)\n \n \n+def FormatTimedelta(td):\n+  if hasattr(td.total, 'total_seconds'):\n+    d = td.total_seconds()\n+  else: # python2.6 compat\n+    d =  td.seconds + (td.microseconds / 10.0**6)\n+  return FormatTime(d)\n+\n+\n def PrintCrashed(code):\n   if utils.IsWindows():\n     return \"CRASHED\"\n@@ -1713,25 +1666,32 @@ def Main():\n         print \"Could not create the temporary directory\", options.temp_dir\n         sys.exit(1)\n \n-  if options.report:\n-    PrintReport(all_cases)\n-\n-  result = None\n-  def DoSkip(case):\n-    # A list of tests that should be skipped can be provided. This is\n-    # useful for tests that fail in some environments, e.g., under coverage.\n-    if options.skip_tests != [\"\"]:\n-        if [ st for st in options.skip_tests if st in case.case.file ]:\n-            return True\n-    if SKIP in case.outcomes or SLOW in case.outcomes:\n+  def should_keep(case):\n+    if any((s in case.file) for s in options.skip_tests):\n+      return False\n+    elif SKIP in case.outcomes:\n+      return False\n+    elif (options.flaky_tests == SKIP) and (set([FLAKY]) & case.outcomes):\n+      return False\n+    else:\n       return True\n-    return FLAKY in case.outcomes and options.flaky_tests == SKIP\n-  cases_to_run = [ c for c in all_cases if not DoSkip(c) ]\n+\n+  cases_to_run = filter(should_keep, all_cases)\n+\n+  if options.report:\n+    print(REPORT_TEMPLATE % {\n+      'total': len(all_cases),\n+      'skipped': len(all_cases) - len(cases_to_run),\n+      'pass': len([t for t in cases_to_run if PASS in t.outcomes]),\n+      'fail_ok': len([t for t in cases_to_run if t.outcomes == set([FAIL, OKAY])]),\n+      'fail': len([t for t in cases_to_run if t.outcomes == set([FAIL])])\n+    })\n+\n   if options.run is not None:\n     # Must ensure the list of tests is sorted before selecting, to avoid\n     # silent errors if this file is changed to list the tests in a way that\n     # can be different in different machines\n-    cases_to_run.sort(key=lambda c: (c.case.arch, c.case.mode, c.case.file))\n+    cases_to_run.sort(key=lambda c: (c.arch, c.mode, c.file))\n     cases_to_run = [ cases_to_run[i] for i\n                      in xrange(options.run[0],\n                                len(cases_to_run),\n@@ -1756,13 +1716,11 @@ def DoSkip(case):\n     # test output.\n     print\n     sys.stderr.write(\"--- Total time: %s ---\\n\" % FormatTime(duration))\n-    timed_tests = [ t.case for t in cases_to_run if not t.case.duration is None ]\n+    timed_tests = [ t for t in cases_to_run if not t.duration is None ]\n     timed_tests.sort(lambda a, b: a.CompareTime(b))\n-    index = 1\n-    for entry in timed_tests[:20]:\n-      t = FormatTime(entry.duration.total_seconds())\n-      sys.stderr.write(\"%4i (%s) %s\\n\" % (index, t, entry.GetLabel()))\n-      index += 1\n+    for i, entry in enumerate(timed_tests[:20], start=1):\n+      t = FormatTimedelta(entry.duration)\n+      sys.stderr.write(\"%4i (%s) %s\\n\" % (i, t, entry.GetLabel()))\n \n   return result\n "
        }
    ],
    "stats": {
        "total": 182,
        "additions": 58,
        "deletions": 124
    }
}