{
    "author": "mafintosh",
    "message": "stream: add pipeline and finished\n\nPR-URL: https://github.com/nodejs/node/pull/19828\nReviewed-By: Matteo Collina <matteo.collina@gmail.com>\nReviewed-By: James M Snell <jasnell@gmail.com>",
    "sha": "f64bebf2059d35299da58cf9c5ca22d68035d617",
    "files": [
        {
            "sha": "00d30193df7d33a05173592e30c2ca34309afc61",
            "filename": "doc/api/errors.md",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/nodejs/node/blob/f64bebf2059d35299da58cf9c5ca22d68035d617/doc%2Fapi%2Ferrors.md",
            "raw_url": "https://github.com/nodejs/node/raw/f64bebf2059d35299da58cf9c5ca22d68035d617/doc%2Fapi%2Ferrors.md",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/doc%2Fapi%2Ferrors.md?ref=f64bebf2059d35299da58cf9c5ca22d68035d617",
            "patch": "@@ -1431,6 +1431,12 @@ An attempt was made to call [`stream.pipe()`][] on a [`Writable`][] stream.\n \n An attempt was made to call [`stream.write()`][] with a `null` chunk.\n \n+<a id=\"ERR_STREAM_PREMATURE_CLOSE\"></a>\n+### ERR_STREAM_PREMATURE_CLOSE\n+\n+An error returned by `stream.finished()` and `stream.pipeline()`, when a stream\n+or a pipeline ends non gracefully with no explicit error.\n+\n <a id=\"ERR_STREAM_PUSH_AFTER_EOF\"></a>\n ### ERR_STREAM_PUSH_AFTER_EOF\n "
        },
        {
            "sha": "705b58a31c5ce9487ad289900d407b16c9625603",
            "filename": "doc/api/stream.md",
            "status": "modified",
            "additions": 106,
            "deletions": 0,
            "changes": 106,
            "blob_url": "https://github.com/nodejs/node/blob/f64bebf2059d35299da58cf9c5ca22d68035d617/doc%2Fapi%2Fstream.md",
            "raw_url": "https://github.com/nodejs/node/raw/f64bebf2059d35299da58cf9c5ca22d68035d617/doc%2Fapi%2Fstream.md",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/doc%2Fapi%2Fstream.md?ref=f64bebf2059d35299da58cf9c5ca22d68035d617",
            "patch": "@@ -46,6 +46,9 @@ There are four fundamental stream types within Node.js:\n * [Transform][] - Duplex streams that can modify or transform the data as it\n   is written and read (for example [`zlib.createDeflate()`][]).\n \n+Additionally this module includes the utility functions [pipeline][] and\n+[finished][].\n+\n ### Object Mode\n \n All streams created by Node.js APIs operate exclusively on strings and `Buffer`\n@@ -1287,6 +1290,107 @@ implementors should not override this method, but instead implement\n [`readable._destroy()`][readable-_destroy].\n The default implementation of `_destroy()` for `Transform` also emit `'close'`.\n \n+### stream.finished(stream, callback)\n+<!-- YAML\n+added: REPLACEME\n+-->\n+\n+* `stream` {Stream} A readable and/or writable stream.\n+* `callback` {Function} A callback function that takes an optional error\n+  argument.\n+\n+A function to get notified when a stream is no longer readable, writable\n+or has experienced an error or a premature close event.\n+\n+```js\n+const { finished } = require('stream');\n+\n+const rs = fs.createReadStream('archive.tar');\n+\n+finished(rs, (err) => {\n+  if (err) {\n+    console.error('Stream failed', err);\n+  } else {\n+    console.log('Stream is done reading');\n+  }\n+});\n+\n+rs.resume(); // drain the stream\n+```\n+\n+Especially useful in error handling scenarios where a stream is destroyed\n+prematurely (like an aborted HTTP request), and will not emit `'end'`\n+or `'finish'`.\n+\n+The `finished` API is promisify'able as well;\n+\n+```js\n+const finished = util.promisify(stream.finished);\n+\n+const rs = fs.createReadStream('archive.tar');\n+\n+async function run() {\n+  await finished(rs);\n+  console.log('Stream is done reading');\n+}\n+\n+run().catch(console.error);\n+rs.resume(); // drain the stream\n+```\n+\n+### stream.pipeline(...streams[, callback])\n+<!-- YAML\n+added: REPLACEME\n+-->\n+\n+* `...streams` {Stream} Two or more streams to pipe between.\n+* `callback` {Function} A callback function that takes an optional error\n+  argument.\n+\n+A module method to pipe between streams forwarding errors and properly cleaning\n+up and provide a callback when the pipeline is complete.\n+\n+```js\n+const { pipeline } = require('stream');\n+const fs = require('fs');\n+const zlib = require('zlib');\n+\n+// Use the pipeline API to easily pipe a series of streams\n+// together and get notified when the pipeline is fully done.\n+\n+// A pipeline to gzip a potentially huge tar file efficiently:\n+\n+pipeline(\n+  fs.createReadStream('archive.tar'),\n+  zlib.createGzip(),\n+  fs.createWriteStream('archive.tar.gz'),\n+  (err) => {\n+    if (err) {\n+      console.error('Pipeline failed', err);\n+    } else {\n+      console.log('Pipeline succeeded');\n+    }\n+  }\n+);\n+```\n+\n+The `pipeline` API is promisify'able as well:\n+\n+```js\n+const pipeline = util.promisify(stream.pipeline);\n+\n+async function run() {\n+  await pipeline(\n+    fs.createReadStream('archive.tar'),\n+    zlib.createGzip(),\n+    fs.createWriteStream('archive.tar.gz')\n+  );\n+  console.log('Pipeline succeeded');\n+}\n+\n+run().catch(console.error);\n+```\n+\n ## API for Stream Implementers\n \n <!--type=misc-->\n@@ -2397,6 +2501,8 @@ contain multi-byte characters.\n [http-incoming-message]: http.html#http_class_http_incomingmessage\n [zlib]: zlib.html\n [hwm-gotcha]: #stream_highwatermark_discrepancy_after_calling_readable_setencoding\n+[pipeline]: #stream_stream_pipeline_streams_callback\n+[finished]: #stream_stream_finished_stream_callback\n [stream-_flush]: #stream_transform_flush_callback\n [stream-_read]: #stream_readable_read_size_1\n [stream-_transform]: #stream_transform_transform_chunk_encoding_callback"
        },
        {
            "sha": "2bc2c7bce57af556dca6df9bdde6ce401699f8df",
            "filename": "lib/internal/errors.js",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/nodejs/node/blob/f64bebf2059d35299da58cf9c5ca22d68035d617/lib%2Finternal%2Ferrors.js",
            "raw_url": "https://github.com/nodejs/node/raw/f64bebf2059d35299da58cf9c5ca22d68035d617/lib%2Finternal%2Ferrors.js",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/lib%2Finternal%2Ferrors.js?ref=f64bebf2059d35299da58cf9c5ca22d68035d617",
            "patch": "@@ -961,6 +961,7 @@ E('ERR_STDOUT_CLOSE', 'process.stdout cannot be closed', Error);\n E('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable', Error);\n E('ERR_STREAM_DESTROYED', 'Cannot call %s after a stream was destroyed', Error);\n E('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);\n+E('ERR_STREAM_PREMATURE_CLOSE', 'Premature close', Error);\n E('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF', Error);\n E('ERR_STREAM_UNSHIFT_AFTER_END_EVENT',\n   'stream.unshift() after end event', Error);"
        },
        {
            "sha": "eeb8a61456a730f58da5b17f371211df5638357b",
            "filename": "lib/internal/streams/end-of-stream.js",
            "status": "added",
            "additions": 96,
            "deletions": 0,
            "changes": 96,
            "blob_url": "https://github.com/nodejs/node/blob/f64bebf2059d35299da58cf9c5ca22d68035d617/lib%2Finternal%2Fstreams%2Fend-of-stream.js",
            "raw_url": "https://github.com/nodejs/node/raw/f64bebf2059d35299da58cf9c5ca22d68035d617/lib%2Finternal%2Fstreams%2Fend-of-stream.js",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/lib%2Finternal%2Fstreams%2Fend-of-stream.js?ref=f64bebf2059d35299da58cf9c5ca22d68035d617",
            "patch": "@@ -0,0 +1,96 @@\n+// Ported from https://github.com/mafintosh/end-of-stream with\n+// permission from the author, Mathias Buus (@mafintosh).\n+\n+'use strict';\n+\n+const {\n+  ERR_STREAM_PREMATURE_CLOSE\n+} = require('internal/errors').codes;\n+\n+function noop() {}\n+\n+function isRequest(stream) {\n+  return stream.setHeader && typeof stream.abort === 'function';\n+}\n+\n+function once(callback) {\n+  let called = false;\n+  return function(err) {\n+    if (called) return;\n+    called = true;\n+    callback.call(this, err);\n+  };\n+}\n+\n+function eos(stream, opts, callback) {\n+  if (typeof opts === 'function') return eos(stream, null, opts);\n+  if (!opts) opts = {};\n+\n+  callback = once(callback || noop);\n+\n+  const ws = stream._writableState;\n+  const rs = stream._readableState;\n+  let readable = opts.readable || (opts.readable !== false && stream.readable);\n+  let writable = opts.writable || (opts.writable !== false && stream.writable);\n+\n+  const onlegacyfinish = () => {\n+    if (!stream.writable) onfinish();\n+  };\n+\n+  const onfinish = () => {\n+    writable = false;\n+    if (!readable) callback.call(stream);\n+  };\n+\n+  const onend = () => {\n+    readable = false;\n+    if (!writable) callback.call(stream);\n+  };\n+\n+  const onerror = (err) => {\n+    callback.call(stream, err);\n+  };\n+\n+  const onclose = () => {\n+    if (readable && !(rs && rs.ended)) {\n+      return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE());\n+    }\n+    if (writable && !(ws && ws.ended)) {\n+      return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE());\n+    }\n+  };\n+\n+  const onrequest = () => {\n+    stream.req.on('finish', onfinish);\n+  };\n+\n+  if (isRequest(stream)) {\n+    stream.on('complete', onfinish);\n+    stream.on('abort', onclose);\n+    if (stream.req) onrequest();\n+    else stream.on('request', onrequest);\n+  } else if (writable && !ws) { // legacy streams\n+    stream.on('end', onlegacyfinish);\n+    stream.on('close', onlegacyfinish);\n+  }\n+\n+  stream.on('end', onend);\n+  stream.on('finish', onfinish);\n+  if (opts.error !== false) stream.on('error', onerror);\n+  stream.on('close', onclose);\n+\n+  return function() {\n+    stream.removeListener('complete', onfinish);\n+    stream.removeListener('abort', onclose);\n+    stream.removeListener('request', onrequest);\n+    if (stream.req) stream.req.removeListener('finish', onfinish);\n+    stream.removeListener('end', onlegacyfinish);\n+    stream.removeListener('close', onlegacyfinish);\n+    stream.removeListener('finish', onfinish);\n+    stream.removeListener('end', onend);\n+    stream.removeListener('error', onerror);\n+    stream.removeListener('close', onclose);\n+  };\n+}\n+\n+module.exports = eos;"
        },
        {
            "sha": "7e87210a774c5f91b20a53d22ef4fb73ebc97dd9",
            "filename": "lib/internal/streams/pipeline.js",
            "status": "added",
            "additions": 95,
            "deletions": 0,
            "changes": 95,
            "blob_url": "https://github.com/nodejs/node/blob/f64bebf2059d35299da58cf9c5ca22d68035d617/lib%2Finternal%2Fstreams%2Fpipeline.js",
            "raw_url": "https://github.com/nodejs/node/raw/f64bebf2059d35299da58cf9c5ca22d68035d617/lib%2Finternal%2Fstreams%2Fpipeline.js",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/lib%2Finternal%2Fstreams%2Fpipeline.js?ref=f64bebf2059d35299da58cf9c5ca22d68035d617",
            "patch": "@@ -0,0 +1,95 @@\n+// Ported from https://github.com/mafintosh/pump with\n+// permission from the author, Mathias Buus (@mafintosh).\n+\n+'use strict';\n+\n+const eos = require('internal/streams/end-of-stream');\n+\n+const {\n+  ERR_MISSING_ARGS,\n+  ERR_STREAM_DESTROYED\n+} = require('internal/errors').codes;\n+\n+function once(callback) {\n+  let called = false;\n+  return function(err) {\n+    if (called) return;\n+    called = true;\n+    callback(err);\n+  };\n+}\n+\n+function noop() {}\n+\n+function isRequest(stream) {\n+  return stream.setHeader && typeof stream.abort === 'function';\n+}\n+\n+function destroyer(stream, reading, writing, callback) {\n+  callback = once(callback);\n+\n+  let closed = false;\n+  stream.on('close', () => {\n+    closed = true;\n+  });\n+\n+  eos(stream, { readable: reading, writable: writing }, (err) => {\n+    if (err) return callback(err);\n+    closed = true;\n+    callback();\n+  });\n+\n+  let destroyed = false;\n+  return (err) => {\n+    if (closed) return;\n+    if (destroyed) return;\n+    destroyed = true;\n+\n+    // request.destroy just do .end - .abort is what we want\n+    if (isRequest(stream)) return stream.abort();\n+    if (typeof stream.destroy === 'function') return stream.destroy();\n+\n+    callback(err || new ERR_STREAM_DESTROYED('pipe'));\n+  };\n+}\n+\n+function call(fn) {\n+  fn();\n+}\n+\n+function pipe(from, to) {\n+  return from.pipe(to);\n+}\n+\n+function popCallback(streams) {\n+  if (!streams.length) return noop;\n+  if (typeof streams[streams.length - 1] !== 'function') return noop;\n+  return streams.pop();\n+}\n+\n+function pipeline(...streams) {\n+  const callback = popCallback(streams);\n+\n+  if (Array.isArray(streams[0])) streams = streams[0];\n+\n+  if (streams.length < 2) {\n+    throw new ERR_MISSING_ARGS('streams');\n+  }\n+\n+  let error;\n+  const destroys = streams.map(function(stream, i) {\n+    const reading = i < streams.length - 1;\n+    const writing = i > 0;\n+    return destroyer(stream, reading, writing, function(err) {\n+      if (!error) error = err;\n+      if (err) destroys.forEach(call);\n+      if (reading) return;\n+      destroys.forEach(call);\n+      callback(error);\n+    });\n+  });\n+\n+  return streams.reduce(pipe);\n+}\n+\n+module.exports = pipeline;"
        },
        {
            "sha": "7c235108c072562f4ce492896fe623415f273d42",
            "filename": "lib/stream.js",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/nodejs/node/blob/f64bebf2059d35299da58cf9c5ca22d68035d617/lib%2Fstream.js",
            "raw_url": "https://github.com/nodejs/node/raw/f64bebf2059d35299da58cf9c5ca22d68035d617/lib%2Fstream.js",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/lib%2Fstream.js?ref=f64bebf2059d35299da58cf9c5ca22d68035d617",
            "patch": "@@ -22,6 +22,8 @@\n 'use strict';\n \n const { Buffer } = require('buffer');\n+const pipeline = require('internal/streams/pipeline');\n+const eos = require('internal/streams/end-of-stream');\n \n // Note: export Stream before Readable/Writable/Duplex/...\n // to avoid a cross-reference(require) issues\n@@ -33,6 +35,9 @@ Stream.Duplex = require('_stream_duplex');\n Stream.Transform = require('_stream_transform');\n Stream.PassThrough = require('_stream_passthrough');\n \n+Stream.pipeline = pipeline;\n+Stream.finished = eos;\n+\n // Backwards-compat with node 0.4.x\n Stream.Stream = Stream;\n "
        },
        {
            "sha": "7ca158c25f04c8f95f9c980daf5d3503ca674726",
            "filename": "node.gyp",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/nodejs/node/blob/f64bebf2059d35299da58cf9c5ca22d68035d617/node.gyp",
            "raw_url": "https://github.com/nodejs/node/raw/f64bebf2059d35299da58cf9c5ca22d68035d617/node.gyp",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/node.gyp?ref=f64bebf2059d35299da58cf9c5ca22d68035d617",
            "patch": "@@ -154,6 +154,8 @@\n       'lib/internal/streams/legacy.js',\n       'lib/internal/streams/destroy.js',\n       'lib/internal/streams/state.js',\n+      'lib/internal/streams/pipeline.js',\n+      'lib/internal/streams/end-of-stream.js',\n       'lib/internal/wrap_js_stream.js',\n       'deps/v8/tools/splaytree.js',\n       'deps/v8/tools/codemap.js',"
        },
        {
            "sha": "2b0c156eb0684588596d3bff99ac3b5717cb42c1",
            "filename": "test/parallel/test-stream-finished.js",
            "status": "added",
            "additions": 123,
            "deletions": 0,
            "changes": 123,
            "blob_url": "https://github.com/nodejs/node/blob/f64bebf2059d35299da58cf9c5ca22d68035d617/test%2Fparallel%2Ftest-stream-finished.js",
            "raw_url": "https://github.com/nodejs/node/raw/f64bebf2059d35299da58cf9c5ca22d68035d617/test%2Fparallel%2Ftest-stream-finished.js",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/test%2Fparallel%2Ftest-stream-finished.js?ref=f64bebf2059d35299da58cf9c5ca22d68035d617",
            "patch": "@@ -0,0 +1,123 @@\n+'use strict';\n+\n+const common = require('../common');\n+const { Writable, Readable, Transform, finished } = require('stream');\n+const assert = require('assert');\n+const fs = require('fs');\n+const { promisify } = require('util');\n+\n+common.crashOnUnhandledRejection();\n+\n+{\n+  const rs = new Readable({\n+    read() {}\n+  });\n+\n+  finished(rs, common.mustCall((err) => {\n+    assert(!err, 'no error');\n+  }));\n+\n+  rs.push(null);\n+  rs.resume();\n+}\n+\n+{\n+  const ws = new Writable({\n+    write(data, enc, cb) {\n+      cb();\n+    }\n+  });\n+\n+  finished(ws, common.mustCall((err) => {\n+    assert(!err, 'no error');\n+  }));\n+\n+  ws.end();\n+}\n+\n+{\n+  const tr = new Transform({\n+    transform(data, enc, cb) {\n+      cb();\n+    }\n+  });\n+\n+  let finish = false;\n+  let ended = false;\n+\n+  tr.on('end', () => {\n+    ended = true;\n+  });\n+\n+  tr.on('finish', () => {\n+    finish = true;\n+  });\n+\n+  finished(tr, common.mustCall((err) => {\n+    assert(!err, 'no error');\n+    assert(finish);\n+    assert(ended);\n+  }));\n+\n+  tr.end();\n+  tr.resume();\n+}\n+\n+{\n+  const rs = fs.createReadStream(__filename);\n+\n+  rs.resume();\n+  finished(rs, common.mustCall());\n+}\n+\n+{\n+  const finishedPromise = promisify(finished);\n+\n+  async function run() {\n+    const rs = fs.createReadStream(__filename);\n+    const done = common.mustCall();\n+\n+    let ended = false;\n+    rs.resume();\n+    rs.on('end', () => {\n+      ended = true;\n+    });\n+    await finishedPromise(rs);\n+    assert(ended);\n+    done();\n+  }\n+\n+  run();\n+}\n+\n+{\n+  const rs = fs.createReadStream('file-does-not-exist');\n+\n+  finished(rs, common.mustCall((err) => {\n+    assert.strictEqual(err.code, 'ENOENT');\n+  }));\n+}\n+\n+{\n+  const rs = new Readable();\n+\n+  finished(rs, common.mustCall((err) => {\n+    assert(!err, 'no error');\n+  }));\n+\n+  rs.push(null);\n+  rs.emit('close'); // should not trigger an error\n+  rs.resume();\n+}\n+\n+{\n+  const rs = new Readable();\n+\n+  finished(rs, common.mustCall((err) => {\n+    assert(err, 'premature close error');\n+  }));\n+\n+  rs.emit('close'); // should trigger error\n+  rs.push(null);\n+  rs.resume();\n+}"
        },
        {
            "sha": "e63ee2ed11767920fa8dff11669f0fb4d650de9e",
            "filename": "test/parallel/test-stream-pipeline.js",
            "status": "added",
            "additions": 483,
            "deletions": 0,
            "changes": 483,
            "blob_url": "https://github.com/nodejs/node/blob/f64bebf2059d35299da58cf9c5ca22d68035d617/test%2Fparallel%2Ftest-stream-pipeline.js",
            "raw_url": "https://github.com/nodejs/node/raw/f64bebf2059d35299da58cf9c5ca22d68035d617/test%2Fparallel%2Ftest-stream-pipeline.js",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/test%2Fparallel%2Ftest-stream-pipeline.js?ref=f64bebf2059d35299da58cf9c5ca22d68035d617",
            "patch": "@@ -0,0 +1,483 @@\n+'use strict';\n+\n+const common = require('../common');\n+if (!common.hasCrypto)\n+  common.skip('missing crypto');\n+const { Stream, Writable, Readable, Transform, pipeline } = require('stream');\n+const assert = require('assert');\n+const http = require('http');\n+const http2 = require('http2');\n+const { promisify } = require('util');\n+\n+common.crashOnUnhandledRejection();\n+\n+{\n+  let finished = false;\n+  const processed = [];\n+  const expected = [\n+    Buffer.from('a'),\n+    Buffer.from('b'),\n+    Buffer.from('c')\n+  ];\n+\n+  const read = new Readable({\n+    read() {}\n+  });\n+\n+  const write = new Writable({\n+    write(data, enc, cb) {\n+      processed.push(data);\n+      cb();\n+    }\n+  });\n+\n+  write.on('finish', () => {\n+    finished = true;\n+  });\n+\n+  for (let i = 0; i < expected.length; i++) {\n+    read.push(expected[i]);\n+  }\n+  read.push(null);\n+\n+  pipeline(read, write, common.mustCall((err) => {\n+    assert.ok(!err, 'no error');\n+    assert.ok(finished);\n+    assert.deepStrictEqual(processed, expected);\n+  }));\n+}\n+\n+{\n+  const read = new Readable({\n+    read() {}\n+  });\n+\n+  assert.throws(() => {\n+    pipeline(read, () => {});\n+  }, /ERR_MISSING_ARGS/);\n+  assert.throws(() => {\n+    pipeline(() => {});\n+  }, /ERR_MISSING_ARGS/);\n+  assert.throws(() => {\n+    pipeline();\n+  }, /ERR_MISSING_ARGS/);\n+}\n+\n+{\n+  const read = new Readable({\n+    read() {}\n+  });\n+\n+  const write = new Writable({\n+    write(data, enc, cb) {\n+      cb();\n+    }\n+  });\n+\n+  read.push('data');\n+  setImmediate(() => read.destroy());\n+\n+  pipeline(read, write, common.mustCall((err) => {\n+    assert.ok(err, 'should have an error');\n+  }));\n+}\n+\n+{\n+  const read = new Readable({\n+    read() {}\n+  });\n+\n+  const write = new Writable({\n+    write(data, enc, cb) {\n+      cb();\n+    }\n+  });\n+\n+  read.push('data');\n+  setImmediate(() => read.destroy(new Error('kaboom')));\n+\n+  const dst = pipeline(read, write, common.mustCall((err) => {\n+    assert.deepStrictEqual(err, new Error('kaboom'));\n+  }));\n+\n+  assert.strictEqual(dst, write);\n+}\n+\n+{\n+  const read = new Readable({\n+    read() {}\n+  });\n+\n+  const transform = new Transform({\n+    transform(data, enc, cb) {\n+      cb(new Error('kaboom'));\n+    }\n+  });\n+\n+  const write = new Writable({\n+    write(data, enc, cb) {\n+      cb();\n+    }\n+  });\n+\n+  read.on('close', common.mustCall());\n+  transform.on('close', common.mustCall());\n+  write.on('close', common.mustCall());\n+\n+  const dst = pipeline(read, transform, write, common.mustCall((err) => {\n+    assert.deepStrictEqual(err, new Error('kaboom'));\n+  }));\n+\n+  assert.strictEqual(dst, write);\n+\n+  read.push('hello');\n+}\n+\n+{\n+  const server = http.createServer((req, res) => {\n+    const rs = new Readable({\n+      read() {\n+        rs.push('hello');\n+        rs.push(null);\n+      }\n+    });\n+\n+    pipeline(rs, res);\n+  });\n+\n+  server.listen(0, () => {\n+    const req = http.request({\n+      port: server.address().port\n+    });\n+\n+    req.end();\n+    req.on('response', (res) => {\n+      const buf = [];\n+      res.on('data', (data) => buf.push(data));\n+      res.on('end', common.mustCall(() => {\n+        assert.deepStrictEqual(\n+          Buffer.concat(buf),\n+          Buffer.from('hello')\n+        );\n+        server.close();\n+      }));\n+    });\n+  });\n+}\n+\n+{\n+  const server = http.createServer((req, res) => {\n+    const rs = new Readable({\n+      read() {\n+        rs.push('hello');\n+      },\n+      destroy: common.mustCall((err, cb) => {\n+        // prevents fd leaks by destroying http pipelines\n+        cb();\n+      })\n+    });\n+\n+    pipeline(rs, res);\n+  });\n+\n+  server.listen(0, () => {\n+    const req = http.request({\n+      port: server.address().port\n+    });\n+\n+    req.end();\n+    req.on('response', (res) => {\n+      setImmediate(() => {\n+        res.destroy();\n+        server.close();\n+      });\n+    });\n+  });\n+}\n+\n+{\n+  const server = http.createServer((req, res) => {\n+    const rs = new Readable({\n+      read() {\n+        rs.push('hello');\n+      },\n+      destroy: common.mustCall((err, cb) => {\n+        cb();\n+      })\n+    });\n+\n+    pipeline(rs, res);\n+  });\n+\n+  let cnt = 10;\n+\n+  const badSink = new Writable({\n+    write(data, enc, cb) {\n+      cnt--;\n+      if (cnt === 0) cb(new Error('kaboom'));\n+      else cb();\n+    }\n+  });\n+\n+  server.listen(0, () => {\n+    const req = http.request({\n+      port: server.address().port\n+    });\n+\n+    req.end();\n+    req.on('response', (res) => {\n+      pipeline(res, badSink, common.mustCall((err) => {\n+        assert.deepStrictEqual(err, new Error('kaboom'));\n+        server.close();\n+      }));\n+    });\n+  });\n+}\n+\n+{\n+  const server = http.createServer((req, res) => {\n+    pipeline(req, res, common.mustCall());\n+  });\n+\n+  server.listen(0, () => {\n+    const req = http.request({\n+      port: server.address().port\n+    });\n+\n+    const rs = new Readable({\n+      read() {\n+        rs.push('hello');\n+      }\n+    });\n+\n+    pipeline(rs, req, common.mustCall(() => {\n+      server.close();\n+    }));\n+\n+    req.on('response', (res) => {\n+      let cnt = 10;\n+      res.on('data', () => {\n+        cnt--;\n+        if (cnt === 0) rs.destroy();\n+      });\n+    });\n+  });\n+}\n+\n+{\n+  const server = http2.createServer((req, res) => {\n+    pipeline(req, res, common.mustCall());\n+  });\n+\n+  server.listen(0, () => {\n+    const url = `http://localhost:${server.address().port}`;\n+    const client = http2.connect(url);\n+    const req = client.request({ ':method': 'POST' });\n+\n+    const rs = new Readable({\n+      read() {\n+        rs.push('hello');\n+      }\n+    });\n+\n+    pipeline(rs, req, common.mustCall((err) => {\n+      // TODO: this is working around an http2 bug\n+      // where the client keeps the event loop going\n+      // (replacing the rs.destroy() with req.end()\n+      // exits it so seems to be a destroy bug there\n+      client.unref();\n+\n+      server.close();\n+      client.close();\n+    }));\n+\n+    let cnt = 10;\n+    req.on('data', (data) => {\n+      cnt--;\n+      if (cnt === 0) rs.destroy();\n+    });\n+  });\n+}\n+\n+{\n+  const makeTransform = () => {\n+    const tr = new Transform({\n+      transform(data, enc, cb) {\n+        cb(null, data);\n+      }\n+    });\n+\n+    tr.on('close', common.mustCall());\n+    return tr;\n+  };\n+\n+  const rs = new Readable({\n+    read() {\n+      rs.push('hello');\n+    }\n+  });\n+\n+  let cnt = 10;\n+\n+  const ws = new Writable({\n+    write(data, enc, cb) {\n+      cnt--;\n+      if (cnt === 0) return cb(new Error('kaboom'));\n+      cb();\n+    }\n+  });\n+\n+  rs.on('close', common.mustCall());\n+  ws.on('close', common.mustCall());\n+\n+  pipeline(\n+    rs,\n+    makeTransform(),\n+    makeTransform(),\n+    makeTransform(),\n+    makeTransform(),\n+    makeTransform(),\n+    makeTransform(),\n+    ws,\n+    common.mustCall((err) => {\n+      assert.deepStrictEqual(err, new Error('kaboom'));\n+    })\n+  );\n+}\n+\n+{\n+  const oldStream = new Stream();\n+\n+  oldStream.pause = oldStream.resume = () => {};\n+  oldStream.write = (data) => {\n+    oldStream.emit('data', data);\n+    return true;\n+  };\n+  oldStream.end = () => {\n+    oldStream.emit('end');\n+  };\n+\n+  const expected = [\n+    Buffer.from('hello'),\n+    Buffer.from('world')\n+  ];\n+\n+  const rs = new Readable({\n+    read() {\n+      for (let i = 0; i < expected.length; i++) {\n+        rs.push(expected[i]);\n+      }\n+      rs.push(null);\n+    }\n+  });\n+\n+  const ws = new Writable({\n+    write(data, enc, cb) {\n+      assert.deepStrictEqual(data, expected.shift());\n+      cb();\n+    }\n+  });\n+\n+  let finished = false;\n+\n+  ws.on('finish', () => {\n+    finished = true;\n+  });\n+\n+  pipeline(\n+    rs,\n+    oldStream,\n+    ws,\n+    common.mustCall((err) => {\n+      assert(!err, 'no error');\n+      assert(finished, 'last stream finished');\n+    })\n+  );\n+}\n+\n+{\n+  const oldStream = new Stream();\n+\n+  oldStream.pause = oldStream.resume = () => {};\n+  oldStream.write = (data) => {\n+    oldStream.emit('data', data);\n+    return true;\n+  };\n+  oldStream.end = () => {\n+    oldStream.emit('end');\n+  };\n+\n+  const destroyableOldStream = new Stream();\n+\n+  destroyableOldStream.pause = destroyableOldStream.resume = () => {};\n+  destroyableOldStream.destroy = common.mustCall(() => {\n+    destroyableOldStream.emit('close');\n+  });\n+  destroyableOldStream.write = (data) => {\n+    destroyableOldStream.emit('data', data);\n+    return true;\n+  };\n+  destroyableOldStream.end = () => {\n+    destroyableOldStream.emit('end');\n+  };\n+\n+  const rs = new Readable({\n+    read() {\n+      rs.destroy(new Error('stop'));\n+    }\n+  });\n+\n+  const ws = new Writable({\n+    write(data, enc, cb) {\n+      cb();\n+    }\n+  });\n+\n+  let finished = false;\n+\n+  ws.on('finish', () => {\n+    finished = true;\n+  });\n+\n+  pipeline(\n+    rs,\n+    oldStream,\n+    destroyableOldStream,\n+    ws,\n+    common.mustCall((err) => {\n+      assert.deepStrictEqual(err, new Error('stop'));\n+      assert(!finished, 'should not finish');\n+    })\n+  );\n+}\n+\n+{\n+  const pipelinePromise = promisify(pipeline);\n+\n+  async function run() {\n+    const read = new Readable({\n+      read() {}\n+    });\n+\n+    const write = new Writable({\n+      write(data, enc, cb) {\n+        cb();\n+      }\n+    });\n+\n+    read.push('data');\n+    read.push(null);\n+\n+    let finished = false;\n+\n+    write.on('finish', () => {\n+      finished = true;\n+    });\n+\n+    await pipelinePromise(read, write);\n+\n+    assert(finished);\n+  }\n+\n+  run();\n+}"
        }
    ],
    "stats": {
        "total": 917,
        "additions": 917,
        "deletions": 0
    }
}