{
    "author": "refack",
    "message": "tools: bump cpplint.py to 3d8f6f876d\n\nPR-URL: https://github.com/nodejs/node/pull/25771\nFixes: https://github.com/nodejs/node/issues/25760\nRefs: https://github.com/cpplint/cpplint/blob/3d8f6f876dd6e3918e5641483298dbc82e65f358/cpplint.py\nReviewed-By: Sakthipriyan Vairamani <thechargingvolcano@gmail.com>\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>",
    "sha": "3dca9e0a577992c07052da21fde976d305880cdb",
    "files": [
        {
            "sha": "8ca6471179b070a84e501b56cfd29b11b700ae34",
            "filename": "tools/cpplint.py",
            "status": "modified",
            "additions": 117,
            "deletions": 158,
            "changes": 275,
            "blob_url": "https://github.com/nodejs/node/blob/3dca9e0a577992c07052da21fde976d305880cdb/tools%2Fcpplint.py",
            "raw_url": "https://github.com/nodejs/node/raw/3dca9e0a577992c07052da21fde976d305880cdb/tools%2Fcpplint.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fcpplint.py?ref=3dca9e0a577992c07052da21fde976d305880cdb",
            "patch": "@@ -45,7 +45,6 @@\n import copy\n import getopt\n import glob\n-import logging\n import itertools\n import math  # for log\n import os\n@@ -56,10 +55,6 @@\n import unicodedata\n import xml.etree.ElementTree\n \n-try:\n-  xrange\n-except NameError:\n-  xrange = range\n # if empty, use defaults\n _header_extensions = set([])\n \n@@ -73,7 +68,7 @@\n # option (also supported in CPPLINT.cfg)\n def GetHeaderExtensions():\n   if not _header_extensions:\n-    return set(['h', 'hpp', 'hxx', 'h++', 'cuh'])\n+    return set(['h', 'hh', 'hpp', 'hxx', 'h++', 'cuh'])\n   return _header_extensions\n \n # The allowed extensions for file names\n@@ -85,7 +80,6 @@ def GetAllExtensions():\n \n def GetNonHeaderExtensions():\n   return GetAllExtensions().difference(GetHeaderExtensions())\n-logger = logging.getLogger('testrunner')\n \n \n _USAGE = \"\"\"\n@@ -95,7 +89,6 @@ def GetNonHeaderExtensions():\n                    [--root=subdir] [--linelength=digits] [--recursive]\n                    [--exclude=path]\n                    [--headers=ext1,ext2]\n-                   [--logfile=filename]\n                    [--extensions=hpp,cpp,...]\n         <file> [file] ...\n \n@@ -129,7 +122,7 @@ def GetNonHeaderExtensions():\n       likely to be false positives.\n \n     quiet\n-      Suppress output other than linting errors, such as information about\n+      Supress output other than linting errors, such as information about\n       which files have been processed and excluded.\n \n     filter=-x,+y,...\n@@ -289,6 +282,7 @@ def GetNonHeaderExtensions():\n     'build/forward_decl',\n     'build/header_guard',\n     'build/include',\n+    'build/include_subdir',\n     'build/include_alpha',\n     'build/include_order',\n     'build/include_what_you_use',\n@@ -359,13 +353,7 @@ def GetNonHeaderExtensions():\n # flag. By default all errors are on, so only add here categories that should be\n # off by default (i.e., categories that must be enabled by the --filter= flags).\n # All entries here should start with a '-' or '+', as in the --filter= flag.\n-_DEFAULT_FILTERS = [\n-    '-build/include',\n-    '-build/include_alpha',\n-    '-build/include_order',\n-    '-build/include_subdir',\n-    '-legal/copyright',\n-    ]\n+_DEFAULT_FILTERS = ['-build/include_alpha']\n \n # The default list of categories suppressed for C (not C++) files.\n _DEFAULT_C_SUPPRESSED_CATEGORIES = [\n@@ -489,6 +477,18 @@ def GetNonHeaderExtensions():\n     'utility',\n     'valarray',\n     'vector',\n+    # 17.6.1.2 C++14 headers\n+    'shared_mutex',\n+    # 17.6.1.2 C++17 headers\n+    'any',\n+    'charconv',\n+    'codecvt',\n+    'execution',\n+    'filesystem',\n+    'memory_resource',\n+    'optional',\n+    'string_view',\n+    'variant',\n     # 17.6.1.2 C++ headers for C library facilities\n     'cassert',\n     'ccomplex',\n@@ -626,12 +626,6 @@ def GetNonHeaderExtensions():\n # Match string that indicates we're working on a Linux Kernel file.\n _SEARCH_KERNEL_FILE = re.compile(r'\\b(?:LINT_KERNEL_FILE)')\n \n-_NULL_TOKEN_PATTERN = re.compile(r'\\bNULL\\b')\n-\n-_RIGHT_LEANING_POINTER_PATTERN = re.compile(r'[^=|(,\\s><);&?:}]'\n-                                            r'(?<!(sizeof|return))'\n-                                            r'\\s\\*[a-zA-z_][0-9a-zA-z_]*')\n-\n _regexp_compile_cache = {}\n \n # {str, set(int)}: a map from error categories to sets of linenumbers\n@@ -650,7 +644,7 @@ def GetNonHeaderExtensions():\n # Files to exclude from linting. This is set by the --exclude flag.\n _excludes = None\n \n-# Whether to suppress PrintInfo messages\n+# Whether to supress PrintInfo messages\n _quiet = False\n \n # The allowed line length of files.\n@@ -696,6 +690,8 @@ def unicode_escape_decode(x):\n _global_error_suppressions = {}\n \n \n+\n+\n def ParseNolintSuppressions(filename, raw_line, linenum, error):\n   \"\"\"Updates the global list of line error-suppressions.\n \n@@ -1278,7 +1274,7 @@ def FullName(self):\n     return os.path.abspath(self._filename).replace('\\\\', '/')\n \n   def RepositoryName(self):\n-    \"\"\"FullName after removing the local path to the repository.\n+    r\"\"\"FullName after removing the local path to the repository.\n \n     If we have a real absolute path name here we can try to do something smart:\n     detecting the root of the checkout and truncating /path/to/checkout from\n@@ -1288,11 +1284,54 @@ def RepositoryName(self):\n     locations won't see bogus errors.\n     \"\"\"\n     fullname = self.FullName()\n-    # XXX(bnoordhuis) Expects that cpplint.py lives in the tools/ directory.\n-    toplevel = os.path.abspath(os.path.join(os.path.dirname(__file__), '..')) \\\n-    .replace('\\\\', '/').decode('utf-8')\n-    prefix = os.path.commonprefix([fullname, toplevel])\n-    return fullname[len(prefix) + 1:]\n+\n+    if os.path.exists(fullname):\n+      project_dir = os.path.dirname(fullname)\n+\n+      # If the user specified a repository path, it exists, and the file is\n+      # contained in it, use the specified repository path\n+      if _repository:\n+        repo = FileInfo(_repository).FullName()\n+        root_dir = project_dir\n+        while os.path.exists(root_dir):\n+          # allow case insensitive compare on Windows\n+          if os.path.normcase(root_dir) == os.path.normcase(repo):\n+            return os.path.relpath(fullname, root_dir).replace('\\\\', '/')\n+          one_up_dir = os.path.dirname(root_dir)\n+          if one_up_dir == root_dir:\n+            break\n+          root_dir = one_up_dir\n+\n+      if os.path.exists(os.path.join(project_dir, \".svn\")):\n+        # If there's a .svn file in the current directory, we recursively look\n+        # up the directory tree for the top of the SVN checkout\n+        root_dir = project_dir\n+        one_up_dir = os.path.dirname(root_dir)\n+        while os.path.exists(os.path.join(one_up_dir, \".svn\")):\n+          root_dir = os.path.dirname(root_dir)\n+          one_up_dir = os.path.dirname(one_up_dir)\n+\n+        prefix = os.path.commonprefix([root_dir, project_dir])\n+        return fullname[len(prefix) + 1:]\n+\n+      # Not SVN <= 1.6? Try to find a git, hg, or svn top level directory by\n+      # searching up from the current path.\n+      root_dir = current_dir = os.path.dirname(fullname)\n+      while current_dir != os.path.dirname(current_dir):\n+        if (os.path.exists(os.path.join(current_dir, \".git\")) or\n+            os.path.exists(os.path.join(current_dir, \".hg\")) or\n+            os.path.exists(os.path.join(current_dir, \".svn\"))):\n+          root_dir = current_dir\n+        current_dir = os.path.dirname(current_dir)\n+\n+      if (os.path.exists(os.path.join(root_dir, \".git\")) or\n+          os.path.exists(os.path.join(root_dir, \".hg\")) or\n+          os.path.exists(os.path.join(root_dir, \".svn\"))):\n+        prefix = os.path.commonprefix([root_dir, project_dir])\n+        return fullname[len(prefix) + 1:]\n+\n+    # Don't know what to do; header guard warnings may be wrong...\n+    return fullname\n \n   def Split(self):\n     \"\"\"Splits the file into the directory, basename, and extension.\n@@ -1313,7 +1352,7 @@ def BaseName(self):\n     return self.Split()[1]\n \n   def Extension(self):\n-    \"\"\"File extension - text following the final period.\"\"\"\n+    \"\"\"File extension - text following the final period, includes that period.\"\"\"\n     return self.Split()[2]\n \n   def NoExtension(self):\n@@ -1383,15 +1422,9 @@ def Error(filename, linenum, category, confidence, message):\n     elif _cpplint_state.output_format == 'eclipse':\n       sys.stderr.write('%s:%s: warning: %s  [%s] [%d]\\n' % (\n           filename, linenum, message, category, confidence))\n-    elif _cpplint_state.output_format == 'tap':\n-      template = ('not ok %(filename)s\\n'\n-          '  ---\\n'\n-          '  message: %(message)s\\n'\n-          '  data:\\n'\n-          '    line: %(linenum)d\\n'\n-          '    ruleId: %(category)s\\n'\n-          '  ...')\n-      logger.info(template % locals())\n+    elif _cpplint_state.output_format == 'junit':\n+        _cpplint_state.AddJUnitFailure(filename, linenum, message, category,\n+            confidence)\n     else:\n       final_message = '%s:%s:  %s  [%s] [%d]\\n' % (\n           filename, linenum, message, category, confidence)\n@@ -1907,7 +1940,7 @@ def CheckForCopyright(filename, lines, error):\n \n   # We'll say it should occur by line 10. Don't forget there's a\n   # dummy line at the front.\n-  for line in xrange(1, min(len(lines), 11)):\n+  for line in range(1, min(len(lines), 11)):\n     if re.search(r'Copyright', lines[line], re.I): break\n   else:                       # means no copyright line was found\n     error(filename, 0, 'legal/copyright', 5,\n@@ -1953,12 +1986,10 @@ def GetHeaderGuardCPPVariable(filename):\n   fileinfo = FileInfo(filename)\n   file_path_from_root = fileinfo.RepositoryName()\n   if _root:\n-    suffix = os.sep\n-    # On Windows using directory separator will leave us with\n-    # \"bogus escape error\" unless we properly escape regex.\n-    if suffix == '\\\\':\n-      suffix += '\\\\'\n-    file_path_from_root = re.sub('^' + _root + suffix, '', file_path_from_root)\n+    # Convert root path to unix format because file_path_from_root is also\n+    # in that format and they wouldn't match otherwise on Windows machines\n+    root = os.path.normpath(_root).replace('\\\\', '/')\n+    file_path_from_root = re.sub('^' + root + '/', '', file_path_from_root)\n   return re.sub(r'[^a-zA-Z0-9]', '_', file_path_from_root).upper() + '_'\n \n \n@@ -2074,22 +2105,22 @@ def CheckHeaderFileIncluded(filename, include_state, error):\n     return\n \n   for ext in GetHeaderExtensions():\n-    basefilename = filename[0:len(filename) - len(fileinfo.Extension())]\n-    headerfile = basefilename + '.' + ext\n-    if not os.path.exists(headerfile):\n-      continue\n-    headername = FileInfo(headerfile).RepositoryName()\n-    first_include = None\n-    for section_list in include_state.include_list:\n-      for f in section_list:\n-        if headername in f[0] or f[0] in headername:\n-          return\n-        if not first_include:\n-          first_include = f[1]\n+      basefilename = filename[0:len(filename) - len(fileinfo.Extension())]\n+      headerfile = basefilename + '.' + ext\n+      if not os.path.exists(headerfile):\n+        continue\n+      headername = FileInfo(headerfile).RepositoryName()\n+      first_include = None\n+      for section_list in include_state.include_list:\n+        for f in section_list:\n+          if headername in f[0] or f[0] in headername:\n+            return\n+          if not first_include:\n+            first_include = f[1]\n \n-    error(filename, first_include, 'build/include', 5,\n-          '%s should include its header file %s' % (fileinfo.RepositoryName(),\n-                                                    headername))\n+      error(filename, first_include, 'build/include', 5,\n+            '%s should include its header file %s' % (fileinfo.RepositoryName(),\n+                                                      headername))\n \n \n def CheckForBadCharacters(filename, lines, error):\n@@ -2117,21 +2148,6 @@ def CheckForBadCharacters(filename, lines, error):\n       error(filename, linenum, 'readability/nul', 5, 'Line contains NUL byte.')\n \n \n-def CheckInlineHeader(filename, include_state, error):\n-  \"\"\"Logs an error if both a header and its inline variant are included.\"\"\"\n-\n-  all_headers = dict(item for sublist in include_state.include_list\n-                     for item in sublist)\n-  bad_headers = set('%s.h' % name[:-6] for name in all_headers.keys()\n-                    if name.endswith('-inl.h'))\n-  bad_headers &= set(all_headers.keys())\n-\n-  for name in bad_headers:\n-    err =  '%s includes both %s and %s-inl.h' % (filename, name, name)\n-    linenum = all_headers[name]\n-    error(filename, linenum, 'build/include', 5, err)\n-\n-\n def CheckForNewlineAtEOF(filename, lines, error):\n   \"\"\"Logs an error if there is no newline char at the end of the file.\n \n@@ -3188,7 +3204,7 @@ def CheckForFunctionLengths(filename, clean_lines, linenum,\n \n   if starting_func:\n     body_found = False\n-    for start_linenum in xrange(linenum, clean_lines.NumLines()):\n+    for start_linenum in range(linenum, clean_lines.NumLines()):\n       start_line = lines[start_linenum]\n       joined_line += ' ' + start_line.lstrip()\n       if Search(r'(;|})', start_line):  # Declarations and trivial functions\n@@ -4409,49 +4425,6 @@ def CheckAltTokens(filename, clean_lines, linenum, error):\n           'Use operator %s instead of %s' % (\n               _ALT_TOKEN_REPLACEMENT[match.group(1)], match.group(1)))\n \n-def CheckNullTokens(filename, clean_lines, linenum, error):\n-  \"\"\"Check NULL usage.\n-\n-  Args:\n-    filename: The name of the current file.\n-    clean_lines: A CleansedLines instance containing the file.\n-    linenum: The number of the line to check.\n-    error: The function to call with any errors found.\n-  \"\"\"\n-  line = clean_lines.elided[linenum]\n-\n-  # Avoid preprocessor lines\n-  if Match(r'^\\s*#', line):\n-    return\n-\n-  if line.find('/*') >= 0 or line.find('*/') >= 0:\n-    return\n-\n-  for match in _NULL_TOKEN_PATTERN.finditer(line):\n-    error(filename, linenum, 'readability/null_usage', 2,\n-          'Use nullptr instead of NULL')\n-\n-def CheckLeftLeaningPointer(filename, clean_lines, linenum, error):\n-  \"\"\"Check for left-leaning pointer placement.\n-\n-  Args:\n-    filename: The name of the current file.\n-    clean_lines: A CleansedLines instance containing the file.\n-    linenum: The number of the line to check.\n-    error: The function to call with any errors found.\n-  \"\"\"\n-  line = clean_lines.elided[linenum]\n-\n-  # Avoid preprocessor lines\n-  if Match(r'^\\s*#', line):\n-    return\n-\n-  if '/*' in line or '*/' in line:\n-    return\n-\n-  for match in _RIGHT_LEANING_POINTER_PATTERN.finditer(line):\n-    error(filename, linenum, 'readability/null_usage', 2,\n-          'Use left leaning pointer instead of right leaning')\n \n def GetLineWidth(line):\n   \"\"\"Determines the width of the line in column positions.\n@@ -4504,10 +4477,6 @@ def CheckStyle(filename, clean_lines, linenum, file_extension, nesting_state,\n     error(filename, linenum, 'whitespace/tab', 1,\n           'Tab found; better to use spaces')\n \n-  if line.find('template<') != -1:\n-    error(filename, linenum, 'whitespace/template', 1,\n-          'Leave a single space after template, as in `template <...>`')\n-\n   # One or three blank spaces at the beginning of the line is weird; it's\n   # hard to reconcile that with 2-space indents.\n   # NOTE: here are the conditions rob pike used for his tests.  Mine aren't\n@@ -4601,8 +4570,6 @@ def CheckStyle(filename, clean_lines, linenum, file_extension, nesting_state,\n   CheckSpacingForFunctionCall(filename, clean_lines, linenum, error)\n   CheckCheck(filename, clean_lines, linenum, error)\n   CheckAltTokens(filename, clean_lines, linenum, error)\n-  CheckNullTokens(filename, clean_lines, linenum, error)\n-  CheckLeftLeaningPointer(filename, clean_lines, linenum, error)\n   classinfo = nesting_state.InnermostClass()\n   if classinfo:\n     CheckSectionSpacing(filename, clean_lines, classinfo, linenum, error)\n@@ -4677,7 +4644,7 @@ def _ClassifyInclude(fileinfo, include, is_system):\n \n   # Headers with C++ extensions shouldn't be considered C system headers\n   if is_system and os.path.splitext(include)[1] in ['.hpp', '.hxx', '.h++']:\n-    is_system = False\n+      is_system = False\n \n   if is_system:\n     if is_cpp_h:\n@@ -4911,8 +4878,6 @@ def CheckLanguage(filename, clean_lines, linenum, file_extension,\n   if match:\n     include_state.ResetSection(match.group(1))\n \n-  # Make Windows paths like Unix.\n-  fullname = os.path.abspath(filename).replace('\\\\', '/')\n \n   # Perform other checks now that we are sure that this is not an include line\n   CheckCasts(filename, clean_lines, linenum, error)\n@@ -5565,12 +5530,15 @@ def ExpectingFunctionArgs(clean_lines, linenum):\n     ('<limits>', ('numeric_limits',)),\n     ('<list>', ('list',)),\n     ('<map>', ('map', 'multimap',)),\n-    ('<memory>', ('allocator',)),\n+    ('<memory>', ('allocator', 'make_shared', 'make_unique', 'shared_ptr',\n+                  'unique_ptr', 'weak_ptr')),\n     ('<queue>', ('queue', 'priority_queue',)),\n     ('<set>', ('set', 'multiset',)),\n     ('<stack>', ('stack',)),\n     ('<string>', ('char_traits', 'basic_string',)),\n     ('<tuple>', ('tuple',)),\n+    ('<unordered_map>', ('unordered_map', 'unordered_multimap')),\n+    ('<unordered_set>', ('unordered_set', 'unordered_multiset')),\n     ('<utility>', ('pair',)),\n     ('<vector>', ('vector',)),\n \n@@ -5585,7 +5553,7 @@ def ExpectingFunctionArgs(clean_lines, linenum):\n     ('<algorithm>', ('copy', 'max', 'min', 'min_element', 'sort',\n                      'transform',\n                     )),\n-    ('<utility>', ('swap',)),\n+    ('<utility>', ('forward', 'make_pair', 'move', 'swap')),\n     )\n \n _RE_PATTERN_STRING = re.compile(r'\\bstring\\b')\n@@ -5716,7 +5684,7 @@ def CheckForIncludeWhatYouUse(filename, clean_lines, include_state, error,\n   required = {}  # A map of header name to linenumber and the template entity.\n                  # Example of required: { '<functional>': (1219, 'less<>') }\n \n-  for linenum in xrange(clean_lines.NumLines()):\n+  for linenum in range(clean_lines.NumLines()):\n     line = clean_lines.elided[linenum]\n     if not line or line[0] == '#':\n       continue\n@@ -5739,8 +5707,13 @@ def CheckForIncludeWhatYouUse(filename, clean_lines, include_state, error,\n       continue\n \n     for pattern, template, header in _re_pattern_templates:\n-      if pattern.search(line):\n-        required[header] = (linenum, template)\n+      matched = pattern.search(line)\n+      if matched:\n+        # Don't warn about IWYU in non-STL namespaces:\n+        # (We check only the first match per line; good enough.)\n+        prefix = line[:matched.start()]\n+        if prefix.endswith('std::') or not prefix.endswith('::'):\n+          required[header] = (linenum, template)\n \n   # The policy is that if you #include something in foo.h you don't need to\n   # include it again in foo.cc. Here, we will look at possible includes.\n@@ -6120,7 +6093,7 @@ def ProcessFileData(filename, file_extension, lines, error,\n   if file_extension in GetHeaderExtensions():\n     CheckForHeaderGuard(filename, clean_lines, error)\n \n-  for line in xrange(clean_lines.NumLines()):\n+  for line in range(clean_lines.NumLines()):\n     ProcessLine(filename, file_extension, clean_lines, line,\n                 include_state, function_state, nesting_state, error,\n                 extra_check_functions)\n@@ -6139,8 +6112,6 @@ def ProcessFileData(filename, file_extension, lines, error,\n \n   CheckForNewlineAtEOF(filename, lines, error)\n \n-  CheckInlineHeader(filename, include_state, error)\n-\n def ProcessConfigOverrides(filename):\n   \"\"\" Loads the configuration files and processes the config overrides.\n \n@@ -6190,7 +6161,7 @@ def ProcessConfigOverrides(filename):\n               if pattern.match(base_name):\n                 _cpplint_state.PrintInfo('Ignoring \"%s\": file excluded by '\n                     '\"%s\". File path component \"%s\" matches pattern \"%s\"\\n' %\n-                                 (filename, cfg_file, base_name, val))\n+                    (filename, cfg_file, base_name, val))\n                 return False\n           elif name == 'linelength':\n             global _line_length\n@@ -6363,7 +6334,6 @@ def ParseArguments(args):\n     (opts, filenames) = getopt.getopt(args, '', ['help', 'output=', 'verbose=',\n                                                  'counting=',\n                                                  'filter=',\n-                                                 'logfile=',\n                                                  'root=',\n                                                  'repository=',\n                                                  'linelength=',\n@@ -6385,9 +6355,9 @@ def ParseArguments(args):\n     if opt == '--help':\n       PrintUsage(None)\n     elif opt == '--output':\n-      if val not in ('emacs', 'vs7', 'eclipse', 'junit', 'tap'):\n-        PrintUsage(\n-            'The only allowed output formats are emacs, vs7, eclipse, junit and tap.')\n+      if val not in ('emacs', 'vs7', 'eclipse', 'junit'):\n+        PrintUsage('The only allowed output formats are emacs, vs7, eclipse '\n+                   'and junit.')\n       output_format = val\n     elif opt == '--verbose':\n       verbosity = int(val)\n@@ -6408,9 +6378,9 @@ def ParseArguments(args):\n     elif opt == '--linelength':\n       global _line_length\n       try:\n-          _line_length = int(val)\n+        _line_length = int(val)\n       except ValueError:\n-          PrintUsage('Line length must be digits.')\n+        PrintUsage('Line length must be digits.')\n     elif opt == '--exclude':\n       global _excludes\n       if not _excludes:\n@@ -6419,7 +6389,7 @@ def ParseArguments(args):\n     elif opt == '--extensions':\n       global _valid_extensions\n       try:\n-          _valid_extensions = set(val.split(','))\n+        _valid_extensions = set(val.split(','))\n       except ValueError:\n           PrintUsage('Extensions must be comma seperated list.')\n     elif opt == '--headers':\n@@ -6430,8 +6400,6 @@ def ParseArguments(args):\n         PrintUsage('Extensions must be comma seperated list.')\n     elif opt == '--recursive':\n       recursive = True\n-    elif opt == '--logfile':\n-      logger.addHandler(logging.FileHandler(val, mode='wb'))\n     elif opt == '--quiet':\n       global _quiet\n       _quiet = True\n@@ -6497,22 +6465,13 @@ def main():\n   try:\n     # Change stderr to write with replacement characters so we don't die\n     # if we try to print something containing non-ASCII characters.\n-    sys.stderr = codecs.StreamReaderWriter(sys.stderr,\n-                                          codecs.getreader('utf8'),\n-                                          codecs.getwriter('utf8'),\n-                                          'replace')\n-\n-    logger.addHandler(logging.StreamHandler(sys.stdout))\n-    logger.setLevel(logging.INFO)\n+    sys.stderr = codecs.StreamReader(sys.stderr, 'replace')\n \n     _cpplint_state.ResetErrorCounts()\n     for filename in filenames:\n-        ProcessFile(filename.decode('utf-8'), _cpplint_state.verbose_level)\n+      ProcessFile(filename, _cpplint_state.verbose_level)\n     _cpplint_state.PrintErrorCounts()\n \n-    if _cpplint_state.output_format == 'tap':\n-      logger.info('TAP version 13')\n-\n     if _cpplint_state.output_format == 'junit':\n       sys.stderr.write(_cpplint_state.FormatJUnitXML())\n "
        }
    ],
    "stats": {
        "total": 275,
        "additions": 117,
        "deletions": 158
    }
}