{
    "author": "aslushnikov",
    "message": "inspector: add inspector_protocol as a direct dependency\n\nCurrently, node.js depends on inspector_protocol indirectly through the\ndependency on v8.\n\nThis is a dependency violation that will make it hard to roll V8 into\nNode if V8 gets a newer inspector protocol version with incompatible\nAPI. In fact, this surfaced on one of our bots when we tried to roll new\ninspector_protocol into V8.\n\nThis patch adds inspector protocol and its required dependencies to node\ndeps:\n- jinja2\n- markupsafe\n\nPR-URL: https://github.com/nodejs/node/pull/21975\nReviewed-By: Eugene Ostroukhov <eostroukhov@google.com>\nReviewed-By: Aleksei Koziatinskii <ak239spb@gmail.com>",
    "sha": "e0395247c899af101f8a1f76a8554be1ff14040a",
    "files": [
        {
            "sha": "7fc997b4f04dc78d9ac0b3fd9ca64eaf77294608",
            "filename": "LICENSE",
            "status": "modified",
            "additions": 103,
            "deletions": 0,
            "changes": 103,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/LICENSE",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/LICENSE",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/LICENSE?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -1035,6 +1035,109 @@ The externally maintained libraries used by Node.js are:\n     OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n   \"\"\"\n \n+- inspector_protocol, located at tools/inspector_protocol, is licensed as follows:\n+  \"\"\"\n+    // Copyright 2016 The Chromium Authors. All rights reserved.\n+    //\n+    // Redistribution and use in source and binary forms, with or without\n+    // modification, are permitted provided that the following conditions are\n+    // met:\n+    //\n+    //    * Redistributions of source code must retain the above copyright\n+    // notice, this list of conditions and the following disclaimer.\n+    //    * Redistributions in binary form must reproduce the above\n+    // copyright notice, this list of conditions and the following disclaimer\n+    // in the documentation and/or other materials provided with the\n+    // distribution.\n+    //    * Neither the name of Google Inc. nor the names of its\n+    // contributors may be used to endorse or promote products derived from\n+    // this software without specific prior written permission.\n+    //\n+    // THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n+    // \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n+    // LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+    // A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n+    // OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+    // SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+    // LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n+    // DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n+    // THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+    // (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n+    // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n+  \"\"\"\n+\n+- jinja2, located at tools/jinja2, is licensed as follows:\n+  \"\"\"\n+    Copyright (c) 2009 by the Jinja Team, see AUTHORS for more details.\n+\n+    Some rights reserved.\n+\n+    Redistribution and use in source and binary forms, with or without\n+    modification, are permitted provided that the following conditions are\n+    met:\n+\n+        * Redistributions of source code must retain the above copyright\n+          notice, this list of conditions and the following disclaimer.\n+\n+        * Redistributions in binary form must reproduce the above\n+          copyright notice, this list of conditions and the following\n+          disclaimer in the documentation and/or other materials provided\n+          with the distribution.\n+\n+        * The names of the contributors may not be used to endorse or\n+          promote products derived from this software without specific\n+          prior written permission.\n+\n+    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n+    \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n+    LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+    A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n+    OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+    SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+    LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n+    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n+    THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+    (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n+    OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n+  \"\"\"\n+\n+- markupsafe, located at tools/markupsafe, is licensed as follows:\n+  \"\"\"\n+    Copyright (c) 2010 by Armin Ronacher and contributors.  See AUTHORS\n+    for more details.\n+\n+    Some rights reserved.\n+\n+    Redistribution and use in source and binary forms of the software as well\n+    as documentation, with or without modification, are permitted provided\n+    that the following conditions are met:\n+\n+    * Redistributions of source code must retain the above copyright\n+      notice, this list of conditions and the following disclaimer.\n+\n+    * Redistributions in binary form must reproduce the above\n+      copyright notice, this list of conditions and the following\n+      disclaimer in the documentation and/or other materials provided\n+      with the distribution.\n+\n+    * The names of the contributors may not be used to endorse or\n+      promote products derived from this software without specific\n+      prior written permission.\n+\n+    THIS SOFTWARE AND DOCUMENTATION IS PROVIDED BY THE COPYRIGHT HOLDERS AND\n+    CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT\n+    NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+    A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER\n+    OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n+    EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n+    PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n+    PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n+    LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n+    NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n+    SOFTWARE AND DOCUMENTATION, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH\n+    DAMAGE.\n+  \"\"\"\n+\n - cpplint.py, located at tools/cpplint.py, is licensed as follows:\n   \"\"\"\n     Copyright (c) 2009 Google Inc. All rights reserved."
        },
        {
            "sha": "8c42474bbed90a7b425bb98825bdc9b297a8032e",
            "filename": "node.gyp",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/node.gyp",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/node.gyp",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/node.gyp?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -1045,7 +1045,7 @@\n     }], # end aix section\n     [ 'v8_enable_inspector==1', {\n       'variables': {\n-        'protocol_path': 'deps/v8/third_party/inspector_protocol',\n+        'protocol_path': 'tools/inspector_protocol',\n         'node_inspector_path': 'src/inspector',\n         'node_inspector_generated_sources': [\n           '<(SHARED_INTERMEDIATE_DIR)/src/node/inspector/protocol/Forward.h',\n@@ -1105,7 +1105,7 @@\n               ],\n               'action': [\n                 'python',\n-                'deps/v8/third_party/inspector_protocol/ConvertProtocolToJSON.py',\n+                'tools/inspector_protocol/ConvertProtocolToJSON.py',\n                 '<@(_inputs)',\n                 '<@(_outputs)',\n               ],\n@@ -1160,7 +1160,7 @@\n               ],\n               'action': [\n                 'python',\n-                'deps/v8/third_party/inspector_protocol/ConvertProtocolToJSON.py',\n+                'tools/inspector_protocol/ConvertProtocolToJSON.py',\n                 '<@(_inputs)',\n                 '<@(_outputs)',\n               ],\n@@ -1176,7 +1176,7 @@\n               ],\n               'action': [\n                 'python',\n-                'deps/v8/third_party/inspector_protocol/ConcatenateProtocols.py',\n+                'tools/inspector_protocol/ConcatenateProtocols.py',\n                 '<@(_inputs)',\n                 '<@(_outputs)',\n               ],"
        },
        {
            "sha": "c70162a2a44ef029e3723bbf4dacd4dbc8389568",
            "filename": "tools/inspector_protocol/CheckProtocolCompatibility.py",
            "status": "added",
            "additions": 479,
            "deletions": 0,
            "changes": 479,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FCheckProtocolCompatibility.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FCheckProtocolCompatibility.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2FCheckProtocolCompatibility.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,479 @@\n+#!/usr/bin/env python\n+# Copyright (c) 2011 Google Inc. All rights reserved.\n+#\n+# Redistribution and use in source and binary forms, with or without\n+# modification, are permitted provided that the following conditions are\n+# met:\n+#\n+#     * Redistributions of source code must retain the above copyright\n+# notice, this list of conditions and the following disclaimer.\n+#     * Redistributions in binary form must reproduce the above\n+# copyright notice, this list of conditions and the following disclaimer\n+# in the documentation and/or other materials provided with the\n+# distribution.\n+#     * Neither the name of Google Inc. nor the names of its\n+# contributors may be used to endorse or promote products derived from\n+# this software without specific prior written permission.\n+#\n+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n+# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n+#\n+# Inspector protocol validator.\n+#\n+# Tests that subsequent protocol changes are not breaking backwards compatibility.\n+# Following violations are reported:\n+#\n+#   - Domain has been removed\n+#   - Command has been removed\n+#   - Required command parameter was added or changed from optional\n+#   - Required response parameter was removed or changed to optional\n+#   - Event has been removed\n+#   - Required event parameter was removed or changed to optional\n+#   - Parameter type has changed.\n+#\n+# For the parameters with composite types the above checks are also applied\n+# recursively to every property of the type.\n+#\n+# Adding --show_changes to the command line prints out a list of valid public API changes.\n+\n+import copy\n+import os.path\n+import optparse\n+import sys\n+\n+try:\n+    import json\n+except ImportError:\n+    import simplejson as json\n+\n+\n+def list_to_map(items, key):\n+    result = {}\n+    for item in items:\n+        if \"experimental\" not in item and \"hidden\" not in item:\n+            result[item[key]] = item\n+    return result\n+\n+\n+def named_list_to_map(container, name, key):\n+    if name in container:\n+        return list_to_map(container[name], key)\n+    return {}\n+\n+\n+def removed(reverse):\n+    if reverse:\n+        return \"added\"\n+    return \"removed\"\n+\n+\n+def required(reverse):\n+    if reverse:\n+        return \"optional\"\n+    return \"required\"\n+\n+\n+def compare_schemas(d_1, d_2, reverse):\n+    errors = []\n+    domains_1 = copy.deepcopy(d_1)\n+    domains_2 = copy.deepcopy(d_2)\n+    types_1 = normalize_types_in_schema(domains_1)\n+    types_2 = normalize_types_in_schema(domains_2)\n+\n+    domains_by_name_1 = list_to_map(domains_1, \"domain\")\n+    domains_by_name_2 = list_to_map(domains_2, \"domain\")\n+\n+    for name in domains_by_name_1:\n+        domain_1 = domains_by_name_1[name]\n+        if name not in domains_by_name_2:\n+            errors.append(\"%s: domain has been %s\" % (name, removed(reverse)))\n+            continue\n+        compare_domains(domain_1, domains_by_name_2[name], types_1, types_2, errors, reverse)\n+    return errors\n+\n+\n+def compare_domains(domain_1, domain_2, types_map_1, types_map_2, errors, reverse):\n+    domain_name = domain_1[\"domain\"]\n+    commands_1 = named_list_to_map(domain_1, \"commands\", \"name\")\n+    commands_2 = named_list_to_map(domain_2, \"commands\", \"name\")\n+    for name in commands_1:\n+        command_1 = commands_1[name]\n+        if name not in commands_2:\n+            errors.append(\"%s.%s: command has been %s\" % (domain_1[\"domain\"], name, removed(reverse)))\n+            continue\n+        compare_commands(domain_name, command_1, commands_2[name], types_map_1, types_map_2, errors, reverse)\n+\n+    events_1 = named_list_to_map(domain_1, \"events\", \"name\")\n+    events_2 = named_list_to_map(domain_2, \"events\", \"name\")\n+    for name in events_1:\n+        event_1 = events_1[name]\n+        if name not in events_2:\n+            errors.append(\"%s.%s: event has been %s\" % (domain_1[\"domain\"], name, removed(reverse)))\n+            continue\n+        compare_events(domain_name, event_1, events_2[name], types_map_1, types_map_2, errors, reverse)\n+\n+\n+def compare_commands(domain_name, command_1, command_2, types_map_1, types_map_2, errors, reverse):\n+    context = domain_name + \".\" + command_1[\"name\"]\n+\n+    params_1 = named_list_to_map(command_1, \"parameters\", \"name\")\n+    params_2 = named_list_to_map(command_2, \"parameters\", \"name\")\n+    # Note the reversed order: we allow removing but forbid adding parameters.\n+    compare_params_list(context, \"parameter\", params_2, params_1, types_map_2, types_map_1, 0, errors, not reverse)\n+\n+    returns_1 = named_list_to_map(command_1, \"returns\", \"name\")\n+    returns_2 = named_list_to_map(command_2, \"returns\", \"name\")\n+    compare_params_list(context, \"response parameter\", returns_1, returns_2, types_map_1, types_map_2, 0, errors, reverse)\n+\n+\n+def compare_events(domain_name, event_1, event_2, types_map_1, types_map_2, errors, reverse):\n+    context = domain_name + \".\" + event_1[\"name\"]\n+    params_1 = named_list_to_map(event_1, \"parameters\", \"name\")\n+    params_2 = named_list_to_map(event_2, \"parameters\", \"name\")\n+    compare_params_list(context, \"parameter\", params_1, params_2, types_map_1, types_map_2, 0, errors, reverse)\n+\n+\n+def compare_params_list(context, kind, params_1, params_2, types_map_1, types_map_2, depth, errors, reverse):\n+    for name in params_1:\n+        param_1 = params_1[name]\n+        if name not in params_2:\n+            if \"optional\" not in param_1:\n+                errors.append(\"%s.%s: required %s has been %s\" % (context, name, kind, removed(reverse)))\n+            continue\n+\n+        param_2 = params_2[name]\n+        if param_2 and \"optional\" in param_2 and \"optional\" not in param_1:\n+            errors.append(\"%s.%s: %s %s is now %s\" % (context, name, required(reverse), kind, required(not reverse)))\n+            continue\n+        type_1 = extract_type(param_1, types_map_1, errors)\n+        type_2 = extract_type(param_2, types_map_2, errors)\n+        compare_types(context + \".\" + name, kind, type_1, type_2, types_map_1, types_map_2, depth, errors, reverse)\n+\n+\n+def compare_types(context, kind, type_1, type_2, types_map_1, types_map_2, depth, errors, reverse):\n+    if depth > 5:\n+        return\n+\n+    base_type_1 = type_1[\"type\"]\n+    base_type_2 = type_2[\"type\"]\n+\n+    if base_type_1 != base_type_2:\n+        errors.append(\"%s: %s base type mismatch, '%s' vs '%s'\" % (context, kind, base_type_1, base_type_2))\n+    elif base_type_1 == \"object\":\n+        params_1 = named_list_to_map(type_1, \"properties\", \"name\")\n+        params_2 = named_list_to_map(type_2, \"properties\", \"name\")\n+        # If both parameters have the same named type use it in the context.\n+        if \"id\" in type_1 and \"id\" in type_2 and type_1[\"id\"] == type_2[\"id\"]:\n+            type_name = type_1[\"id\"]\n+        else:\n+            type_name = \"<object>\"\n+        context += \" %s->%s\" % (kind, type_name)\n+        compare_params_list(context, \"property\", params_1, params_2, types_map_1, types_map_2, depth + 1, errors, reverse)\n+    elif base_type_1 == \"array\":\n+        item_type_1 = extract_type(type_1[\"items\"], types_map_1, errors)\n+        item_type_2 = extract_type(type_2[\"items\"], types_map_2, errors)\n+        compare_types(context, kind, item_type_1, item_type_2, types_map_1, types_map_2, depth + 1, errors, reverse)\n+\n+\n+def extract_type(typed_object, types_map, errors):\n+    if \"type\" in typed_object:\n+        result = {\"id\": \"<transient>\", \"type\": typed_object[\"type\"]}\n+        if typed_object[\"type\"] == \"object\":\n+            result[\"properties\"] = []\n+        elif typed_object[\"type\"] == \"array\":\n+            result[\"items\"] = typed_object[\"items\"]\n+        return result\n+    elif \"$ref\" in typed_object:\n+        ref = typed_object[\"$ref\"]\n+        if ref not in types_map:\n+            errors.append(\"Can not resolve type: %s\" % ref)\n+            types_map[ref] = {\"id\": \"<transient>\", \"type\": \"object\"}\n+        return types_map[ref]\n+\n+\n+def normalize_types_in_schema(domains):\n+    types = {}\n+    for domain in domains:\n+        domain_name = domain[\"domain\"]\n+        normalize_types(domain, domain_name, types)\n+    return types\n+\n+\n+def normalize_types(obj, domain_name, types):\n+    if isinstance(obj, list):\n+        for item in obj:\n+            normalize_types(item, domain_name, types)\n+    elif isinstance(obj, dict):\n+        for key, value in obj.items():\n+            if key == \"$ref\" and value.find(\".\") == -1:\n+                obj[key] = \"%s.%s\" % (domain_name, value)\n+            elif key == \"id\":\n+                obj[key] = \"%s.%s\" % (domain_name, value)\n+                types[obj[key]] = obj\n+            else:\n+                normalize_types(value, domain_name, types)\n+\n+\n+def load_schema(file_name, domains):\n+    # pylint: disable=W0613\n+    if not os.path.isfile(file_name):\n+        return\n+    input_file = open(file_name, \"r\")\n+    json_string = input_file.read()\n+    parsed_json = json.loads(json_string)\n+    domains += parsed_json[\"domains\"]\n+    return parsed_json[\"version\"]\n+\n+\n+def self_test():\n+    def create_test_schema_1():\n+        return [\n+            {\n+                \"domain\": \"Network\",\n+                \"types\": [\n+                    {\n+                        \"id\": \"LoaderId\",\n+                        \"type\": \"string\"\n+                    },\n+                    {\n+                        \"id\": \"Headers\",\n+                        \"type\": \"object\"\n+                    },\n+                    {\n+                        \"id\": \"Request\",\n+                        \"type\": \"object\",\n+                        \"properties\": [\n+                            {\"name\": \"url\", \"type\": \"string\"},\n+                            {\"name\": \"method\", \"type\": \"string\"},\n+                            {\"name\": \"headers\", \"$ref\": \"Headers\"},\n+                            {\"name\": \"becameOptionalField\", \"type\": \"string\"},\n+                            {\"name\": \"removedField\", \"type\": \"string\"},\n+                        ]\n+                    }\n+                ],\n+                \"commands\": [\n+                    {\n+                        \"name\": \"removedCommand\",\n+                    },\n+                    {\n+                        \"name\": \"setExtraHTTPHeaders\",\n+                        \"parameters\": [\n+                            {\"name\": \"headers\", \"$ref\": \"Headers\"},\n+                            {\"name\": \"mismatched\", \"type\": \"string\"},\n+                            {\"name\": \"becameOptional\", \"$ref\": \"Headers\"},\n+                            {\"name\": \"removedRequired\", \"$ref\": \"Headers\"},\n+                            {\"name\": \"becameRequired\", \"$ref\": \"Headers\", \"optional\": True},\n+                            {\"name\": \"removedOptional\", \"$ref\": \"Headers\", \"optional\": True},\n+                        ],\n+                        \"returns\": [\n+                            {\"name\": \"mimeType\", \"type\": \"string\"},\n+                            {\"name\": \"becameOptional\", \"type\": \"string\"},\n+                            {\"name\": \"removedRequired\", \"type\": \"string\"},\n+                            {\"name\": \"becameRequired\", \"type\": \"string\", \"optional\": True},\n+                            {\"name\": \"removedOptional\", \"type\": \"string\", \"optional\": True},\n+                        ]\n+                    }\n+                ],\n+                \"events\": [\n+                    {\n+                        \"name\": \"requestWillBeSent\",\n+                        \"parameters\": [\n+                            {\"name\": \"frameId\", \"type\": \"string\", \"experimental\": True},\n+                            {\"name\": \"request\", \"$ref\": \"Request\"},\n+                            {\"name\": \"becameOptional\", \"type\": \"string\"},\n+                            {\"name\": \"removedRequired\", \"type\": \"string\"},\n+                            {\"name\": \"becameRequired\", \"type\": \"string\", \"optional\": True},\n+                            {\"name\": \"removedOptional\", \"type\": \"string\", \"optional\": True},\n+                        ]\n+                    },\n+                    {\n+                        \"name\": \"removedEvent\",\n+                        \"parameters\": [\n+                            {\"name\": \"errorText\", \"type\": \"string\"},\n+                            {\"name\": \"canceled\", \"type\": \"boolean\", \"optional\": True}\n+                        ]\n+                    }\n+                ]\n+            },\n+            {\n+                \"domain\":  \"removedDomain\"\n+            }\n+        ]\n+\n+    def create_test_schema_2():\n+        return [\n+            {\n+                \"domain\": \"Network\",\n+                \"types\": [\n+                    {\n+                        \"id\": \"LoaderId\",\n+                        \"type\": \"string\"\n+                    },\n+                    {\n+                        \"id\": \"Request\",\n+                        \"type\": \"object\",\n+                        \"properties\": [\n+                            {\"name\": \"url\", \"type\": \"string\"},\n+                            {\"name\": \"method\", \"type\": \"string\"},\n+                            {\"name\": \"headers\", \"type\": \"object\"},\n+                            {\"name\": \"becameOptionalField\", \"type\": \"string\", \"optional\": True},\n+                        ]\n+                    }\n+                ],\n+                \"commands\": [\n+                    {\n+                        \"name\": \"addedCommand\",\n+                    },\n+                    {\n+                        \"name\": \"setExtraHTTPHeaders\",\n+                        \"parameters\": [\n+                            {\"name\": \"headers\", \"type\": \"object\"},\n+                            {\"name\": \"mismatched\", \"type\": \"object\"},\n+                            {\"name\": \"becameOptional\", \"type\": \"object\", \"optional\": True},\n+                            {\"name\": \"addedRequired\", \"type\": \"object\"},\n+                            {\"name\": \"becameRequired\", \"type\": \"object\"},\n+                            {\"name\": \"addedOptional\", \"type\": \"object\", \"optional\": True},\n+                        ],\n+                        \"returns\": [\n+                            {\"name\": \"mimeType\", \"type\": \"string\"},\n+                            {\"name\": \"becameOptional\", \"type\": \"string\", \"optional\": True},\n+                            {\"name\": \"addedRequired\", \"type\": \"string\"},\n+                            {\"name\": \"becameRequired\", \"type\": \"string\"},\n+                            {\"name\": \"addedOptional\", \"type\": \"string\", \"optional\": True},\n+                        ]\n+                    }\n+                ],\n+                \"events\": [\n+                    {\n+                        \"name\": \"requestWillBeSent\",\n+                        \"parameters\": [\n+                            {\"name\": \"request\", \"$ref\": \"Request\"},\n+                            {\"name\": \"becameOptional\", \"type\": \"string\", \"optional\": True},\n+                            {\"name\": \"addedRequired\", \"type\": \"string\"},\n+                            {\"name\": \"becameRequired\", \"type\": \"string\"},\n+                            {\"name\": \"addedOptional\", \"type\": \"string\", \"optional\": True},\n+                        ]\n+                    },\n+                    {\n+                        \"name\": \"addedEvent\"\n+                    }\n+                ]\n+            },\n+            {\n+                \"domain\": \"addedDomain\"\n+            }\n+        ]\n+\n+    expected_errors = [\n+        \"removedDomain: domain has been removed\",\n+        \"Network.removedCommand: command has been removed\",\n+        \"Network.removedEvent: event has been removed\",\n+        \"Network.setExtraHTTPHeaders.mismatched: parameter base type mismatch, 'object' vs 'string'\",\n+        \"Network.setExtraHTTPHeaders.addedRequired: required parameter has been added\",\n+        \"Network.setExtraHTTPHeaders.becameRequired: optional parameter is now required\",\n+        \"Network.setExtraHTTPHeaders.removedRequired: required response parameter has been removed\",\n+        \"Network.setExtraHTTPHeaders.becameOptional: required response parameter is now optional\",\n+        \"Network.requestWillBeSent.removedRequired: required parameter has been removed\",\n+        \"Network.requestWillBeSent.becameOptional: required parameter is now optional\",\n+        \"Network.requestWillBeSent.request parameter->Network.Request.removedField: required property has been removed\",\n+        \"Network.requestWillBeSent.request parameter->Network.Request.becameOptionalField: required property is now optional\",\n+    ]\n+\n+    expected_errors_reverse = [\n+        \"addedDomain: domain has been added\",\n+        \"Network.addedEvent: event has been added\",\n+        \"Network.addedCommand: command has been added\",\n+        \"Network.setExtraHTTPHeaders.mismatched: parameter base type mismatch, 'string' vs 'object'\",\n+        \"Network.setExtraHTTPHeaders.removedRequired: required parameter has been removed\",\n+        \"Network.setExtraHTTPHeaders.becameOptional: required parameter is now optional\",\n+        \"Network.setExtraHTTPHeaders.addedRequired: required response parameter has been added\",\n+        \"Network.setExtraHTTPHeaders.becameRequired: optional response parameter is now required\",\n+        \"Network.requestWillBeSent.becameRequired: optional parameter is now required\",\n+        \"Network.requestWillBeSent.addedRequired: required parameter has been added\",\n+    ]\n+\n+    def is_subset(subset, superset, message):\n+        for i in range(len(subset)):\n+            if subset[i] not in superset:\n+                sys.stderr.write(\"%s error: %s\\n\" % (message, subset[i]))\n+                return False\n+        return True\n+\n+    def errors_match(expected, actual):\n+        return (is_subset(actual, expected, \"Unexpected\") and\n+                is_subset(expected, actual, \"Missing\"))\n+\n+    return (errors_match(expected_errors,\n+                         compare_schemas(create_test_schema_1(), create_test_schema_2(), False)) and\n+            errors_match(expected_errors_reverse,\n+                         compare_schemas(create_test_schema_2(), create_test_schema_1(), True)))\n+\n+\n+def load_domains_and_baselines(file_name, domains, baseline_domains):\n+    version = load_schema(os.path.normpath(file_name), domains)\n+    suffix = \"-%s.%s.json\" % (version[\"major\"], version[\"minor\"])\n+    baseline_file = file_name.replace(\".json\", suffix)\n+    load_schema(os.path.normpath(baseline_file), baseline_domains)\n+    return version\n+\n+\n+def main():\n+    if not self_test():\n+        sys.stderr.write(\"Self-test failed\")\n+        return 1\n+\n+    cmdline_parser = optparse.OptionParser()\n+    cmdline_parser.add_option(\"--show_changes\")\n+    cmdline_parser.add_option(\"--expected_errors\")\n+    cmdline_parser.add_option(\"--stamp\")\n+    arg_options, arg_values = cmdline_parser.parse_args()\n+\n+    if len(arg_values) < 1:\n+        sys.stderr.write(\"Usage: %s [--show_changes] <protocol-1> [, <protocol-2>...]\\n\" % sys.argv[0])\n+        return 1\n+\n+    domains = []\n+    baseline_domains = []\n+    version = load_domains_and_baselines(arg_values[0], domains, baseline_domains)\n+    for dependency in arg_values[1:]:\n+        load_domains_and_baselines(dependency, domains, baseline_domains)\n+\n+    expected_errors = []\n+    if arg_options.expected_errors:\n+        expected_errors_file = open(arg_options.expected_errors, \"r\")\n+        expected_errors = json.loads(expected_errors_file.read())[\"errors\"]\n+        expected_errors_file.close()\n+\n+    errors = compare_schemas(baseline_domains, domains, False)\n+    unexpected_errors = []\n+    for i in range(len(errors)):\n+        if errors[i] not in expected_errors:\n+            unexpected_errors.append(errors[i])\n+    if len(unexpected_errors) > 0:\n+        sys.stderr.write(\"  Compatibility checks FAILED\\n\")\n+        for error in unexpected_errors:\n+            sys.stderr.write(\"    %s\\n\" % error)\n+        return 1\n+\n+    if arg_options.show_changes:\n+        changes = compare_schemas(domains, baseline_domains, True)\n+        if len(changes) > 0:\n+            print \"  Public changes since %s:\" % version\n+            for change in changes:\n+                print \"    %s\" % change\n+\n+    if arg_options.stamp:\n+        with open(arg_options.stamp, 'a') as _:\n+            pass\n+\n+if __name__ == '__main__':\n+    sys.exit(main())"
        },
        {
            "sha": "e630b02985710f0b8a973810df2f9f3b971ea37d",
            "filename": "tools/inspector_protocol/CodeGenerator.py",
            "status": "added",
            "additions": 654,
            "deletions": 0,
            "changes": 654,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FCodeGenerator.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FCodeGenerator.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2FCodeGenerator.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,654 @@\n+# Copyright 2016 The Chromium Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file.\n+\n+import os.path\n+import sys\n+import optparse\n+import collections\n+import functools\n+import re\n+import copy\n+try:\n+    import json\n+except ImportError:\n+    import simplejson as json\n+\n+# Path handling for libraries and templates\n+# Paths have to be normalized because Jinja uses the exact template path to\n+# determine the hash used in the cache filename, and we need a pre-caching step\n+# to be concurrency-safe. Use absolute path because __file__ is absolute if\n+# module is imported, and relative if executed directly.\n+# If paths differ between pre-caching and individual file compilation, the cache\n+# is regenerated, which causes a race condition and breaks concurrent build,\n+# since some compile processes will try to read the partially written cache.\n+module_path, module_filename = os.path.split(os.path.realpath(__file__))\n+\n+def read_config():\n+    # pylint: disable=W0703\n+    def json_to_object(data, output_base, config_base):\n+        def json_object_hook(object_dict):\n+            items = [(k, os.path.join(config_base, v) if k == \"path\" else v) for (k, v) in object_dict.items()]\n+            items = [(k, os.path.join(output_base, v) if k == \"output\" else v) for (k, v) in items]\n+            keys, values = zip(*items)\n+            return collections.namedtuple('X', keys)(*values)\n+        return json.loads(data, object_hook=json_object_hook)\n+\n+    def init_defaults(config_tuple, path, defaults):\n+        keys = list(config_tuple._fields)  # pylint: disable=E1101\n+        values = [getattr(config_tuple, k) for k in keys]\n+        for i in xrange(len(keys)):\n+            if hasattr(values[i], \"_fields\"):\n+                values[i] = init_defaults(values[i], path + \".\" + keys[i], defaults)\n+        for optional in defaults:\n+            if optional.find(path + \".\") != 0:\n+                continue\n+            optional_key = optional[len(path) + 1:]\n+            if optional_key.find(\".\") == -1 and optional_key not in keys:\n+                keys.append(optional_key)\n+                values.append(defaults[optional])\n+        return collections.namedtuple('X', keys)(*values)\n+\n+    try:\n+        cmdline_parser = optparse.OptionParser()\n+        cmdline_parser.add_option(\"--output_base\")\n+        cmdline_parser.add_option(\"--jinja_dir\")\n+        cmdline_parser.add_option(\"--config\")\n+        cmdline_parser.add_option(\"--config_value\", action=\"append\", type=\"string\")\n+        arg_options, _ = cmdline_parser.parse_args()\n+        jinja_dir = arg_options.jinja_dir\n+        if not jinja_dir:\n+            raise Exception(\"jinja directory must be specified\")\n+        jinja_dir = jinja_dir.decode('utf8')\n+        output_base = arg_options.output_base\n+        if not output_base:\n+            raise Exception(\"Base output directory must be specified\")\n+        output_base = output_base.decode('utf8')\n+        config_file = arg_options.config\n+        if not config_file:\n+            raise Exception(\"Config file name must be specified\")\n+        config_file = config_file.decode('utf8')\n+        config_base = os.path.dirname(config_file)\n+        config_values = arg_options.config_value\n+        if not config_values:\n+            config_values = []\n+    except Exception:\n+        # Work with python 2 and 3 http://docs.python.org/py3k/howto/pyporting.html\n+        exc = sys.exc_info()[1]\n+        sys.stderr.write(\"Failed to parse command-line arguments: %s\\n\\n\" % exc)\n+        exit(1)\n+\n+    try:\n+        config_json_file = open(config_file, \"r\")\n+        config_json_string = config_json_file.read()\n+        config_partial = json_to_object(config_json_string, output_base, config_base)\n+        config_json_file.close()\n+        defaults = {\n+            \".use_snake_file_names\": False,\n+            \".use_title_case_methods\": False,\n+            \".imported\": False,\n+            \".imported.export_macro\": \"\",\n+            \".imported.export_header\": False,\n+            \".imported.header\": False,\n+            \".imported.package\": False,\n+            \".imported.options\": False,\n+            \".protocol.export_macro\": \"\",\n+            \".protocol.export_header\": False,\n+            \".protocol.options\": False,\n+            \".exported\": False,\n+            \".exported.export_macro\": \"\",\n+            \".exported.export_header\": False,\n+            \".lib\": False,\n+            \".lib.export_macro\": \"\",\n+            \".lib.export_header\": False,\n+        }\n+        for key_value in config_values:\n+            parts = key_value.split(\"=\")\n+            if len(parts) == 2:\n+                defaults[\".\" + parts[0]] = parts[1]\n+        return (jinja_dir, config_file, init_defaults(config_partial, \"\", defaults))\n+    except Exception:\n+        # Work with python 2 and 3 http://docs.python.org/py3k/howto/pyporting.html\n+        exc = sys.exc_info()[1]\n+        sys.stderr.write(\"Failed to parse config file: %s\\n\\n\" % exc)\n+        exit(1)\n+\n+\n+# ---- Begin of utilities exposed to generator ----\n+\n+\n+def to_title_case(name):\n+    return name[:1].upper() + name[1:]\n+\n+\n+def dash_to_camelcase(word):\n+    prefix = \"\"\n+    if word[0] == \"-\":\n+        prefix = \"Negative\"\n+        word = word[1:]\n+    return prefix + \"\".join(to_title_case(x) or \"-\" for x in word.split(\"-\"))\n+\n+\n+def to_snake_case(name):\n+    return re.sub(r\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", name, sys.maxint).lower()\n+\n+\n+def to_method_case(config, name):\n+    if config.use_title_case_methods:\n+        return to_title_case(name)\n+    return name\n+\n+\n+def join_arrays(dict, keys):\n+    result = []\n+    for key in keys:\n+        if key in dict:\n+            result += dict[key]\n+    return result\n+\n+\n+def format_include(config, header, file_name=None):\n+    if file_name is not None:\n+        header = header + \"/\" + file_name + \".h\"\n+    header = \"\\\"\" + header + \"\\\"\" if header[0] not in \"<\\\"\" else header\n+    if config.use_snake_file_names:\n+        header = to_snake_case(header)\n+    return header\n+\n+\n+def to_file_name(config, file_name):\n+    if config.use_snake_file_names:\n+        return to_snake_case(file_name).replace(\".cpp\", \".cc\")\n+    return file_name\n+\n+\n+# ---- End of utilities exposed to generator ----\n+\n+\n+def initialize_jinja_env(jinja_dir, cache_dir, config):\n+    # pylint: disable=F0401\n+    sys.path.insert(1, os.path.abspath(jinja_dir))\n+    import jinja2\n+\n+    jinja_env = jinja2.Environment(\n+        loader=jinja2.FileSystemLoader(module_path),\n+        # Bytecode cache is not concurrency-safe unless pre-cached:\n+        # if pre-cached this is read-only, but writing creates a race condition.\n+        bytecode_cache=jinja2.FileSystemBytecodeCache(cache_dir),\n+        keep_trailing_newline=True,  # newline-terminate generated files\n+        lstrip_blocks=True,  # so can indent control flow tags\n+        trim_blocks=True)\n+    jinja_env.filters.update({\"to_title_case\": to_title_case, \"dash_to_camelcase\": dash_to_camelcase, \"to_method_case\": functools.partial(to_method_case, config)})\n+    jinja_env.add_extension(\"jinja2.ext.loopcontrols\")\n+    return jinja_env\n+\n+\n+def create_imported_type_definition(domain_name, type, imported_namespace):\n+    # pylint: disable=W0622\n+    return {\n+        \"return_type\": \"std::unique_ptr<%s::%s::API::%s>\" % (imported_namespace, domain_name, type[\"id\"]),\n+        \"pass_type\": \"std::unique_ptr<%s::%s::API::%s>\" % (imported_namespace, domain_name, type[\"id\"]),\n+        \"to_raw_type\": \"%s.get()\",\n+        \"to_pass_type\": \"std::move(%s)\",\n+        \"to_rvalue\": \"std::move(%s)\",\n+        \"type\": \"std::unique_ptr<%s::%s::API::%s>\" % (imported_namespace, domain_name, type[\"id\"]),\n+        \"raw_type\": \"%s::%s::API::%s\" % (imported_namespace, domain_name, type[\"id\"]),\n+        \"raw_pass_type\": \"%s::%s::API::%s*\" % (imported_namespace, domain_name, type[\"id\"]),\n+        \"raw_return_type\": \"%s::%s::API::%s*\" % (imported_namespace, domain_name, type[\"id\"]),\n+    }\n+\n+\n+def create_user_type_definition(domain_name, type):\n+    # pylint: disable=W0622\n+    return {\n+        \"return_type\": \"std::unique_ptr<protocol::%s::%s>\" % (domain_name, type[\"id\"]),\n+        \"pass_type\": \"std::unique_ptr<protocol::%s::%s>\" % (domain_name, type[\"id\"]),\n+        \"to_raw_type\": \"%s.get()\",\n+        \"to_pass_type\": \"std::move(%s)\",\n+        \"to_rvalue\": \"std::move(%s)\",\n+        \"type\": \"std::unique_ptr<protocol::%s::%s>\" % (domain_name, type[\"id\"]),\n+        \"raw_type\": \"protocol::%s::%s\" % (domain_name, type[\"id\"]),\n+        \"raw_pass_type\": \"protocol::%s::%s*\" % (domain_name, type[\"id\"]),\n+        \"raw_return_type\": \"protocol::%s::%s*\" % (domain_name, type[\"id\"]),\n+    }\n+\n+\n+def create_object_type_definition():\n+    # pylint: disable=W0622\n+    return {\n+        \"return_type\": \"std::unique_ptr<protocol::DictionaryValue>\",\n+        \"pass_type\": \"std::unique_ptr<protocol::DictionaryValue>\",\n+        \"to_raw_type\": \"%s.get()\",\n+        \"to_pass_type\": \"std::move(%s)\",\n+        \"to_rvalue\": \"std::move(%s)\",\n+        \"type\": \"std::unique_ptr<protocol::DictionaryValue>\",\n+        \"raw_type\": \"protocol::DictionaryValue\",\n+        \"raw_pass_type\": \"protocol::DictionaryValue*\",\n+        \"raw_return_type\": \"protocol::DictionaryValue*\",\n+    }\n+\n+\n+def create_any_type_definition():\n+    # pylint: disable=W0622\n+    return {\n+        \"return_type\": \"std::unique_ptr<protocol::Value>\",\n+        \"pass_type\": \"std::unique_ptr<protocol::Value>\",\n+        \"to_raw_type\": \"%s.get()\",\n+        \"to_pass_type\": \"std::move(%s)\",\n+        \"to_rvalue\": \"std::move(%s)\",\n+        \"type\": \"std::unique_ptr<protocol::Value>\",\n+        \"raw_type\": \"protocol::Value\",\n+        \"raw_pass_type\": \"protocol::Value*\",\n+        \"raw_return_type\": \"protocol::Value*\",\n+    }\n+\n+\n+def create_string_type_definition():\n+    # pylint: disable=W0622\n+    return {\n+        \"return_type\": \"String\",\n+        \"pass_type\": \"const String&\",\n+        \"to_pass_type\": \"%s\",\n+        \"to_raw_type\": \"%s\",\n+        \"to_rvalue\": \"%s\",\n+        \"type\": \"String\",\n+        \"raw_type\": \"String\",\n+        \"raw_pass_type\": \"const String&\",\n+        \"raw_return_type\": \"String\",\n+    }\n+\n+\n+def create_primitive_type_definition(type):\n+    # pylint: disable=W0622\n+    typedefs = {\n+        \"number\": \"double\",\n+        \"integer\": \"int\",\n+        \"boolean\": \"bool\"\n+    }\n+    defaults = {\n+        \"number\": \"0\",\n+        \"integer\": \"0\",\n+        \"boolean\": \"false\"\n+    }\n+    jsontypes = {\n+        \"number\": \"TypeDouble\",\n+        \"integer\": \"TypeInteger\",\n+        \"boolean\": \"TypeBoolean\",\n+    }\n+    return {\n+        \"return_type\": typedefs[type],\n+        \"pass_type\": typedefs[type],\n+        \"to_pass_type\": \"%s\",\n+        \"to_raw_type\": \"%s\",\n+        \"to_rvalue\": \"%s\",\n+        \"type\": typedefs[type],\n+        \"raw_type\": typedefs[type],\n+        \"raw_pass_type\": typedefs[type],\n+        \"raw_return_type\": typedefs[type],\n+        \"default_value\": defaults[type]\n+    }\n+\n+\n+def wrap_array_definition(type):\n+    # pylint: disable=W0622\n+    return {\n+        \"return_type\": \"std::unique_ptr<protocol::Array<%s>>\" % type[\"raw_type\"],\n+        \"pass_type\": \"std::unique_ptr<protocol::Array<%s>>\" % type[\"raw_type\"],\n+        \"to_raw_type\": \"%s.get()\",\n+        \"to_pass_type\": \"std::move(%s)\",\n+        \"to_rvalue\": \"std::move(%s)\",\n+        \"type\": \"std::unique_ptr<protocol::Array<%s>>\" % type[\"raw_type\"],\n+        \"raw_type\": \"protocol::Array<%s>\" % type[\"raw_type\"],\n+        \"raw_pass_type\": \"protocol::Array<%s>*\" % type[\"raw_type\"],\n+        \"raw_return_type\": \"protocol::Array<%s>*\" % type[\"raw_type\"],\n+        \"out_type\": \"protocol::Array<%s>&\" % type[\"raw_type\"],\n+    }\n+\n+\n+class Protocol(object):\n+    def __init__(self, config):\n+        self.config = config\n+        self.json_api = {\"domains\": []}\n+        self.imported_domains = []\n+        self.exported_domains = []\n+        self.generate_domains = self.read_protocol_file(config.protocol.path)\n+\n+        if config.protocol.options:\n+            self.generate_domains = [rule.domain for rule in config.protocol.options]\n+            self.exported_domains = [rule.domain for rule in config.protocol.options if hasattr(rule, \"exported\")]\n+\n+        if config.imported:\n+            self.imported_domains = self.read_protocol_file(config.imported.path)\n+            if config.imported.options:\n+                self.imported_domains = [rule.domain for rule in config.imported.options]\n+\n+        self.patch_full_qualified_refs()\n+        self.create_notification_types()\n+        self.create_type_definitions()\n+        self.generate_used_types()\n+\n+\n+    def read_protocol_file(self, file_name):\n+        input_file = open(file_name, \"r\")\n+        json_string = input_file.read()\n+        input_file.close()\n+        parsed_json = json.loads(json_string)\n+        version = parsed_json[\"version\"][\"major\"] + \".\" + parsed_json[\"version\"][\"minor\"]\n+        domains = []\n+        for domain in parsed_json[\"domains\"]:\n+            domains.append(domain[\"domain\"])\n+            domain[\"version\"] = version\n+        self.json_api[\"domains\"] += parsed_json[\"domains\"]\n+        return domains\n+\n+\n+    def patch_full_qualified_refs(self):\n+        def patch_full_qualified_refs_in_domain(json, domain_name):\n+            if isinstance(json, list):\n+                for item in json:\n+                    patch_full_qualified_refs_in_domain(item, domain_name)\n+            if not isinstance(json, dict):\n+                return\n+            for key in json:\n+                if key == \"type\" and json[key] == \"string\":\n+                    json[key] = domain_name + \".string\"\n+                if key != \"$ref\":\n+                    patch_full_qualified_refs_in_domain(json[key], domain_name)\n+                    continue\n+                if json[\"$ref\"].find(\".\") == -1:\n+                    json[\"$ref\"] = domain_name + \".\" + json[\"$ref\"]\n+            return\n+\n+        for domain in self.json_api[\"domains\"]:\n+            patch_full_qualified_refs_in_domain(domain, domain[\"domain\"])\n+\n+\n+    def all_references(self, json):\n+        refs = set()\n+        if isinstance(json, list):\n+            for item in json:\n+                refs |= self.all_references(item)\n+        if not isinstance(json, dict):\n+            return refs\n+        for key in json:\n+            if key != \"$ref\":\n+                refs |= self.all_references(json[key])\n+            else:\n+                refs.add(json[\"$ref\"])\n+        return refs\n+\n+    def generate_used_types(self):\n+        all_refs = set()\n+        for domain in self.json_api[\"domains\"]:\n+            domain_name = domain[\"domain\"]\n+            if \"commands\" in domain:\n+                for command in domain[\"commands\"]:\n+                    if self.generate_command(domain_name, command[\"name\"]):\n+                        all_refs |= self.all_references(command)\n+            if \"events\" in domain:\n+                for event in domain[\"events\"]:\n+                    if self.generate_event(domain_name, event[\"name\"]):\n+                        all_refs |= self.all_references(event)\n+                        all_refs.add(domain_name + \".\" + to_title_case(event[\"name\"]) + \"Notification\")\n+\n+        dependencies = self.generate_type_dependencies()\n+        queue = set(all_refs)\n+        while len(queue):\n+            ref = queue.pop()\n+            if ref in dependencies:\n+                queue |= dependencies[ref] - all_refs\n+                all_refs |= dependencies[ref]\n+        self.used_types = all_refs\n+\n+\n+    def generate_type_dependencies(self):\n+        dependencies = dict()\n+        domains_with_types = (x for x in self.json_api[\"domains\"] if \"types\" in x)\n+        for domain in domains_with_types:\n+            domain_name = domain[\"domain\"]\n+            for type in domain[\"types\"]:\n+                related_types = self.all_references(type)\n+                if len(related_types):\n+                    dependencies[domain_name + \".\" + type[\"id\"]] = related_types\n+        return dependencies\n+\n+\n+    def create_notification_types(self):\n+        for domain in self.json_api[\"domains\"]:\n+            if \"events\" in domain:\n+                for event in domain[\"events\"]:\n+                    event_type = dict()\n+                    event_type[\"description\"] = \"Wrapper for notification params\"\n+                    event_type[\"type\"] = \"object\"\n+                    event_type[\"id\"] = to_title_case(event[\"name\"]) + \"Notification\"\n+                    if \"parameters\" in event:\n+                        event_type[\"properties\"] = copy.deepcopy(event[\"parameters\"])\n+                    if \"types\" not in domain:\n+                        domain[\"types\"] = list()\n+                    domain[\"types\"].append(event_type)\n+\n+\n+    def create_type_definitions(self):\n+        imported_namespace = \"::\".join(self.config.imported.namespace) if self.config.imported else \"\"\n+        self.type_definitions = {}\n+        self.type_definitions[\"number\"] = create_primitive_type_definition(\"number\")\n+        self.type_definitions[\"integer\"] = create_primitive_type_definition(\"integer\")\n+        self.type_definitions[\"boolean\"] = create_primitive_type_definition(\"boolean\")\n+        self.type_definitions[\"object\"] = create_object_type_definition()\n+        self.type_definitions[\"any\"] = create_any_type_definition()\n+        for domain in self.json_api[\"domains\"]:\n+            self.type_definitions[domain[\"domain\"] + \".string\"] = create_string_type_definition()\n+            if not (\"types\" in domain):\n+                continue\n+            for type in domain[\"types\"]:\n+                type_name = domain[\"domain\"] + \".\" + type[\"id\"]\n+                if type[\"type\"] == \"object\" and domain[\"domain\"] in self.imported_domains:\n+                    self.type_definitions[type_name] = create_imported_type_definition(domain[\"domain\"], type, imported_namespace)\n+                elif type[\"type\"] == \"object\":\n+                    self.type_definitions[type_name] = create_user_type_definition(domain[\"domain\"], type)\n+                elif type[\"type\"] == \"array\":\n+                    items_type = type[\"items\"][\"type\"]\n+                    self.type_definitions[type_name] = wrap_array_definition(self.type_definitions[items_type])\n+                elif type[\"type\"] == domain[\"domain\"] + \".string\":\n+                    self.type_definitions[type_name] = create_string_type_definition()\n+                else:\n+                    self.type_definitions[type_name] = create_primitive_type_definition(type[\"type\"])\n+\n+\n+    def check_options(self, options, domain, name, include_attr, exclude_attr, default):\n+        for rule in options:\n+            if rule.domain != domain:\n+                continue\n+            if include_attr and hasattr(rule, include_attr):\n+                return name in getattr(rule, include_attr)\n+            if exclude_attr and hasattr(rule, exclude_attr):\n+                return name not in getattr(rule, exclude_attr)\n+            return default\n+        return False\n+\n+\n+    # ---- Begin of methods exposed to generator\n+\n+\n+    def type_definition(self, name):\n+        return self.type_definitions[name]\n+\n+\n+    def resolve_type(self, prop):\n+        if \"$ref\" in prop:\n+            return self.type_definitions[prop[\"$ref\"]]\n+        if prop[\"type\"] == \"array\":\n+            return wrap_array_definition(self.resolve_type(prop[\"items\"]))\n+        return self.type_definitions[prop[\"type\"]]\n+\n+\n+    def generate_command(self, domain, command):\n+        if not self.config.protocol.options:\n+            return domain in self.generate_domains\n+        return self.check_options(self.config.protocol.options, domain, command, \"include\", \"exclude\", True)\n+\n+\n+    def generate_event(self, domain, event):\n+        if not self.config.protocol.options:\n+            return domain in self.generate_domains\n+        return self.check_options(self.config.protocol.options, domain, event, \"include_events\", \"exclude_events\", True)\n+\n+\n+    def generate_type(self, domain, typename):\n+        return domain + \".\" + typename in self.used_types\n+\n+\n+    def is_async_command(self, domain, command):\n+        if not self.config.protocol.options:\n+            return False\n+        return self.check_options(self.config.protocol.options, domain, command, \"async\", None, False)\n+\n+\n+    def is_exported(self, domain, name):\n+        if not self.config.protocol.options:\n+            return False\n+        return self.check_options(self.config.protocol.options, domain, name, \"exported\", None, False)\n+\n+\n+    def is_imported(self, domain, name):\n+        if not self.config.imported:\n+            return False\n+        if not self.config.imported.options:\n+            return domain in self.imported_domains\n+        return self.check_options(self.config.imported.options, domain, name, \"imported\", None, False)\n+\n+\n+    def is_exported_domain(self, domain):\n+        return domain in self.exported_domains\n+\n+\n+    def generate_disable(self, domain):\n+        if \"commands\" not in domain:\n+            return True\n+        for command in domain[\"commands\"]:\n+            if command[\"name\"] == \"disable\" and self.generate_command(domain[\"domain\"], \"disable\"):\n+                return False\n+        return True\n+\n+\n+    def is_imported_dependency(self, domain):\n+        return domain in self.generate_domains or domain in self.imported_domains\n+\n+\n+def main():\n+    jinja_dir, config_file, config = read_config()\n+\n+    protocol = Protocol(config)\n+\n+    if not config.exported and len(protocol.exported_domains):\n+        sys.stderr.write(\"Domains [%s] are exported, but config is missing export entry\\n\\n\" % \", \".join(protocol.exported_domains))\n+        exit(1)\n+\n+    if not os.path.exists(config.protocol.output):\n+        os.mkdir(config.protocol.output)\n+    if len(protocol.exported_domains) and not os.path.exists(config.exported.output):\n+        os.mkdir(config.exported.output)\n+    jinja_env = initialize_jinja_env(jinja_dir, config.protocol.output, config)\n+\n+    inputs = []\n+    inputs.append(__file__)\n+    inputs.append(config_file)\n+    inputs.append(config.protocol.path)\n+    if config.imported:\n+        inputs.append(config.imported.path)\n+    templates_dir = os.path.join(module_path, \"templates\")\n+    inputs.append(os.path.join(templates_dir, \"TypeBuilder_h.template\"))\n+    inputs.append(os.path.join(templates_dir, \"TypeBuilder_cpp.template\"))\n+    inputs.append(os.path.join(templates_dir, \"Exported_h.template\"))\n+    inputs.append(os.path.join(templates_dir, \"Imported_h.template\"))\n+\n+    h_template = jinja_env.get_template(\"templates/TypeBuilder_h.template\")\n+    cpp_template = jinja_env.get_template(\"templates/TypeBuilder_cpp.template\")\n+    exported_template = jinja_env.get_template(\"templates/Exported_h.template\")\n+    imported_template = jinja_env.get_template(\"templates/Imported_h.template\")\n+\n+    outputs = dict()\n+\n+    for domain in protocol.json_api[\"domains\"]:\n+        class_name = domain[\"domain\"]\n+        template_context = {\n+            \"protocol\": protocol,\n+            \"config\": config,\n+            \"domain\": domain,\n+            \"join_arrays\": join_arrays,\n+            \"format_include\": functools.partial(format_include, config),\n+        }\n+\n+        if domain[\"domain\"] in protocol.generate_domains:\n+            outputs[os.path.join(config.protocol.output, to_file_name(config, class_name + \".h\"))] = h_template.render(template_context)\n+            outputs[os.path.join(config.protocol.output, to_file_name(config, class_name + \".cpp\"))] = cpp_template.render(template_context)\n+            if domain[\"domain\"] in protocol.exported_domains:\n+                outputs[os.path.join(config.exported.output, to_file_name(config, class_name + \".h\"))] = exported_template.render(template_context)\n+        if domain[\"domain\"] in protocol.imported_domains:\n+            outputs[os.path.join(config.protocol.output, to_file_name(config, class_name + \".h\"))] = imported_template.render(template_context)\n+\n+    if config.lib:\n+        template_context = {\n+            \"config\": config,\n+            \"format_include\": functools.partial(format_include, config),\n+        }\n+\n+        lib_templates_dir = os.path.join(module_path, \"lib\")\n+        # Note these should be sorted in the right order.\n+        # TODO(dgozman): sort them programmatically based on commented includes.\n+        lib_h_templates = [\n+            \"Collections_h.template\",\n+            \"ErrorSupport_h.template\",\n+            \"Values_h.template\",\n+            \"Object_h.template\",\n+            \"ValueConversions_h.template\",\n+            \"Maybe_h.template\",\n+            \"Array_h.template\",\n+            \"DispatcherBase_h.template\",\n+            \"Parser_h.template\",\n+        ]\n+\n+        lib_cpp_templates = [\n+            \"Protocol_cpp.template\",\n+            \"ErrorSupport_cpp.template\",\n+            \"Values_cpp.template\",\n+            \"Object_cpp.template\",\n+            \"DispatcherBase_cpp.template\",\n+            \"Parser_cpp.template\",\n+        ]\n+\n+        forward_h_templates = [\n+            \"Forward_h.template\",\n+            \"Allocator_h.template\",\n+            \"FrontendChannel_h.template\",\n+        ]\n+\n+        def generate_lib_file(file_name, template_files):\n+            parts = []\n+            for template_file in template_files:\n+                inputs.append(os.path.join(lib_templates_dir, template_file))\n+                template = jinja_env.get_template(\"lib/\" + template_file)\n+                parts.append(template.render(template_context))\n+            outputs[file_name] = \"\\n\\n\".join(parts)\n+\n+        generate_lib_file(os.path.join(config.lib.output, to_file_name(config, \"Forward.h\")), forward_h_templates)\n+        generate_lib_file(os.path.join(config.lib.output, to_file_name(config, \"Protocol.h\")), lib_h_templates)\n+        generate_lib_file(os.path.join(config.lib.output, to_file_name(config, \"Protocol.cpp\")), lib_cpp_templates)\n+\n+    # Make gyp / make generatos happy, otherwise make rebuilds world.\n+    inputs_ts = max(map(os.path.getmtime, inputs))\n+    up_to_date = True\n+    for output_file in outputs.iterkeys():\n+        if not os.path.exists(output_file) or os.path.getmtime(output_file) < inputs_ts:\n+            up_to_date = False\n+            break\n+    if up_to_date:\n+        sys.exit()\n+\n+    for file_name, content in outputs.iteritems():\n+        out_file = open(file_name, \"w\")\n+        out_file.write(content)\n+        out_file.close()\n+\n+\n+main()"
        },
        {
            "sha": "a7cbc992c76e4010d3053f25c63c51f3c28133b0",
            "filename": "tools/inspector_protocol/ConcatenateProtocols.py",
            "status": "added",
            "additions": 39,
            "deletions": 0,
            "changes": 39,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FConcatenateProtocols.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FConcatenateProtocols.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2FConcatenateProtocols.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,39 @@\n+#!/usr/bin/env python\n+# Copyright 2016 The Chromium Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file.\n+\n+import os.path\n+import sys\n+\n+try:\n+    import json\n+except ImportError:\n+    import simplejson as json\n+\n+\n+def main(argv):\n+    if len(argv) < 1:\n+        sys.stderr.write(\"Usage: %s <protocol-1> [<protocol-2> [, <protocol-3>...]] <output-file>\\n\" % sys.argv[0])\n+        return 1\n+\n+    domains = []\n+    version = None\n+    for protocol in argv[:-1]:\n+        file_name = os.path.normpath(protocol)\n+        if not os.path.isfile(file_name):\n+            sys.stderr.write(\"Cannot find %s\\n\" % file_name)\n+            return 1\n+        input_file = open(file_name, \"r\")\n+        json_string = input_file.read()\n+        parsed_json = json.loads(json_string)\n+        domains += parsed_json[\"domains\"]\n+        version = parsed_json[\"version\"]\n+\n+    output_file = open(argv[-1], \"w\")\n+    json.dump({\"version\": version, \"domains\": domains}, output_file, indent=4, sort_keys=False, separators=(',', ': '))\n+    output_file.close()\n+\n+\n+if __name__ == '__main__':\n+    sys.exit(main(sys.argv[1:]))"
        },
        {
            "sha": "56fc09d78cb18f6d5b5646630bdbd572e5662a03",
            "filename": "tools/inspector_protocol/ConvertProtocolToJSON.py",
            "status": "added",
            "additions": 183,
            "deletions": 0,
            "changes": 183,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FConvertProtocolToJSON.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FConvertProtocolToJSON.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2FConvertProtocolToJSON.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,183 @@\n+# Copyright 2017 The Chromium Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file.\n+\n+import collections\n+import json\n+import os.path\n+import re\n+import sys\n+\n+file_name = None\n+description = ''\n+\n+primitiveTypes = ['integer', 'number', 'boolean', 'string', 'object', 'any', 'array']\n+\n+\n+def assignType(item, type, isArray=False):\n+    if isArray:\n+        item['type'] = 'array'\n+        item['items'] = collections.OrderedDict()\n+        assignType(item['items'], type)\n+        return\n+\n+    if type == 'enum':\n+        type = 'string'\n+    if type in primitiveTypes:\n+        item['type'] = type\n+    else:\n+        item['$ref'] = type\n+\n+\n+def createItem(d, experimental, deprecated, name=None):\n+    result = collections.OrderedDict(d)\n+    if name:\n+        result['name'] = name\n+    global description\n+    if description:\n+        result['description'] = description.strip()\n+    if experimental:\n+        result['experimental'] = True\n+    if deprecated:\n+        result['deprecated'] = True\n+    return result\n+\n+\n+def parse(data):\n+    protocol = collections.OrderedDict()\n+    protocol['version'] = collections.OrderedDict()\n+    protocol['domains'] = []\n+    domain = None\n+    item = None\n+    subitems = None\n+    nukeDescription = False\n+    global description\n+    lines = data.split('\\n')\n+    for i in range(0, len(lines)):\n+        if nukeDescription:\n+            description = ''\n+            nukeDescription = False\n+        line = lines[i]\n+        trimLine = line.strip()\n+\n+        if trimLine.startswith('#'):\n+            if len(description):\n+              description += '\\n'\n+            description += trimLine[2:]\n+            continue\n+        else:\n+            nukeDescription = True\n+\n+        if len(trimLine) == 0:\n+            continue\n+\n+        match = re.compile('^(experimental )?(deprecated )?domain (.*)').match(line)\n+        if match:\n+            domain = createItem({'domain' : match.group(3)}, match.group(1), match.group(2))\n+            protocol['domains'].append(domain)\n+            continue\n+\n+        match = re.compile('^  depends on ([^\\s]+)').match(line)\n+        if match:\n+            if 'dependencies' not in domain:\n+                domain['dependencies'] = []\n+            domain['dependencies'].append(match.group(1))\n+            continue\n+\n+        match = re.compile('^  (experimental )?(deprecated )?type (.*) extends (array of )?([^\\s]+)').match(line)\n+        if match:\n+            if 'types' not in domain:\n+                domain['types'] = []\n+            item = createItem({'id': match.group(3)}, match.group(1), match.group(2))\n+            assignType(item, match.group(5), match.group(4))\n+            domain['types'].append(item)\n+            continue\n+\n+        match = re.compile('^  (experimental )?(deprecated )?(command|event) (.*)').match(line)\n+        if match:\n+            list = []\n+            if match.group(3) == 'command':\n+                if 'commands' in domain:\n+                    list = domain['commands']\n+                else:\n+                    list = domain['commands'] = []\n+            else:\n+                if 'events' in domain:\n+                    list = domain['events']\n+                else:\n+                    list = domain['events'] = []\n+\n+            item = createItem({}, match.group(1), match.group(2), match.group(4))\n+            list.append(item)\n+            continue\n+\n+        match = re.compile('^      (experimental )?(deprecated )?(optional )?(array of )?([^\\s]+) ([^\\s]+)').match(line)\n+        if match:\n+            param = createItem({}, match.group(1), match.group(2), match.group(6))\n+            if match.group(3):\n+                param['optional'] = True\n+            assignType(param, match.group(5), match.group(4))\n+            if match.group(5) == 'enum':\n+                enumliterals = param['enum'] = []\n+            subitems.append(param)\n+            continue\n+\n+        match = re.compile('^    (parameters|returns|properties)').match(line)\n+        if match:\n+            subitems = item[match.group(1)] = []\n+            continue\n+\n+        match = re.compile('^    enum').match(line)\n+        if match:\n+            enumliterals = item['enum'] = []\n+            continue\n+\n+        match = re.compile('^version').match(line)\n+        if match:\n+            continue\n+\n+        match = re.compile('^  major (\\d+)').match(line)\n+        if match:\n+            protocol['version']['major'] = match.group(1)\n+            continue\n+\n+        match = re.compile('^  minor (\\d+)').match(line)\n+        if match:\n+            protocol['version']['minor'] = match.group(1)\n+            continue\n+\n+        match = re.compile('^    redirect ([^\\s]+)').match(line)\n+        if match:\n+            item['redirect'] = match.group(1)\n+            continue\n+\n+        match = re.compile('^      (  )?[^\\s]+$').match(line)\n+        if match:\n+            # enum literal\n+            enumliterals.append(trimLine)\n+            continue\n+\n+        print 'Error in %s:%s, illegal token: \\t%s' % (file_name, i, line)\n+        sys.exit(1)\n+    return protocol\n+\n+def main(argv):\n+    if len(argv) < 2:\n+        sys.stderr.write(\"Usage: %s <protocol.pdl> <protocol.json>\\n\" % sys.argv[0])\n+        return 1\n+    global file_name\n+    file_name = os.path.normpath(argv[0])\n+    input_file = open(file_name, \"r\")\n+    pdl_string = input_file.read()\n+    protocol = parse(pdl_string)\n+    output_file = open(argv[0].replace('.pdl', '.json'), 'wb')\n+    json.dump(protocol, output_file, indent=4, separators=(',', ': '))\n+    output_file.close()\n+\n+    output_file = open(os.path.normpath(argv[1]), 'wb')\n+    json.dump(protocol, output_file, indent=4, separators=(',', ': '))\n+    output_file.close()\n+\n+\n+if __name__ == '__main__':\n+    sys.exit(main(sys.argv[1:]))"
        },
        {
            "sha": "800468e5763479bb1f5453934ff0c6ea89d4d9da",
            "filename": "tools/inspector_protocol/LICENSE",
            "status": "added",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FLICENSE",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FLICENSE",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2FLICENSE?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,27 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+//\n+// Redistribution and use in source and binary forms, with or without\n+// modification, are permitted provided that the following conditions are\n+// met:\n+//\n+//    * Redistributions of source code must retain the above copyright\n+// notice, this list of conditions and the following disclaimer.\n+//    * Redistributions in binary form must reproduce the above\n+// copyright notice, this list of conditions and the following disclaimer\n+// in the documentation and/or other materials provided with the\n+// distribution.\n+//    * Neither the name of Google Inc. nor the names of its\n+// contributors may be used to endorse or promote products derived from\n+// this software without specific prior written permission.\n+//\n+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n+// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n+// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n+// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n+// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
        },
        {
            "sha": "8d0b6d90cb233baf66dc4b29c5bc3a56e27e4d9a",
            "filename": "tools/inspector_protocol/OWNERS",
            "status": "added",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FOWNERS",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FOWNERS",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2FOWNERS?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,8 @@\n+set noparent\n+\n+alph@chromium.org\n+caseq@chromium.org\n+dgozman@chromium.org\n+kozyatinskiy@chromium.org\n+pfeldman@chromium.org\n+yangguo@chromium.org"
        },
        {
            "sha": "8a82f2a9c9d691bd26fb268d57e93cd33129b149",
            "filename": "tools/inspector_protocol/README.v8",
            "status": "added",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FREADME.v8",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2FREADME.v8",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2FREADME.v8?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,16 @@\n+Name: inspector protocol\n+Short Name: inspector_protocol\n+URL: https://chromium.googlesource.com/deps/inspector_protocol/\n+Version: 0\n+Revision: 752d4abd13119010cf30e454e8ef9b5fb7ef43a3\n+License: BSD\n+License File: LICENSE\n+Security Critical: no\n+\n+Description:\n+src/inspector uses these scripts to generate handlers from protocol\n+description.\n+\n+Local modifications:\n+- This only includes the lib/ and templates/ directories, scripts, build\n+  and the LICENSE files."
        },
        {
            "sha": "5dcc1f522d863492b28d6d5c35d2232a08d26fe8",
            "filename": "tools/inspector_protocol/inspector_protocol.gni",
            "status": "added",
            "additions": 89,
            "deletions": 0,
            "changes": 89,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Finspector_protocol.gni",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Finspector_protocol.gni",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Finspector_protocol.gni?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,89 @@\n+# Copyright 2016 The Chromium Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file.\n+\n+# This template will generate inspector protocol source code. The code will\n+# not be compiled, use get_target_outputs(<name>) to compile them.\n+#\n+# Inputs\n+#\n+#   config_file  (required)\n+#       Path to json file specifying inspector protocol configuration.\n+#\n+#   out_dir  (required)\n+#       Path to put the generated files in. It must be inside output or\n+#       generated file directory.\n+#\n+#   outputs (required)\n+#       Files generated. Relative to out_dir.\n+#\n+#   inputs  (optional)\n+#       Extra inputs specified by the config file.\n+template(\"inspector_protocol_generate\") {\n+  assert(defined(invoker.config_file))\n+  assert(defined(invoker.out_dir))\n+  assert(defined(invoker.outputs))\n+  assert(defined(invoker.inspector_protocol_dir))\n+  inspector_protocol_dir = invoker.inspector_protocol_dir\n+\n+  action(target_name) {\n+    script = \"$inspector_protocol_dir/CodeGenerator.py\"\n+\n+    inputs = [\n+      invoker.config_file,\n+      \"$inspector_protocol_dir/lib/Allocator_h.template\",\n+      \"$inspector_protocol_dir/lib/Array_h.template\",\n+      \"$inspector_protocol_dir/lib/Collections_h.template\",\n+      \"$inspector_protocol_dir/lib/DispatcherBase_cpp.template\",\n+      \"$inspector_protocol_dir/lib/DispatcherBase_h.template\",\n+      \"$inspector_protocol_dir/lib/ErrorSupport_cpp.template\",\n+      \"$inspector_protocol_dir/lib/ErrorSupport_h.template\",\n+      \"$inspector_protocol_dir/lib/Forward_h.template\",\n+      \"$inspector_protocol_dir/lib/FrontendChannel_h.template\",\n+      \"$inspector_protocol_dir/lib/Maybe_h.template\",\n+      \"$inspector_protocol_dir/lib/Object_cpp.template\",\n+      \"$inspector_protocol_dir/lib/Object_h.template\",\n+      \"$inspector_protocol_dir/lib/Parser_cpp.template\",\n+      \"$inspector_protocol_dir/lib/Parser_h.template\",\n+      \"$inspector_protocol_dir/lib/Protocol_cpp.template\",\n+      \"$inspector_protocol_dir/lib/ValueConversions_h.template\",\n+      \"$inspector_protocol_dir/lib/Values_cpp.template\",\n+      \"$inspector_protocol_dir/lib/Values_h.template\",\n+      \"$inspector_protocol_dir/templates/Exported_h.template\",\n+      \"$inspector_protocol_dir/templates/Imported_h.template\",\n+      \"$inspector_protocol_dir/templates/TypeBuilder_cpp.template\",\n+      \"$inspector_protocol_dir/templates/TypeBuilder_h.template\",\n+    ]\n+    if (defined(invoker.inputs)) {\n+      inputs += invoker.inputs\n+    }\n+\n+    args = [\n+      \"--jinja_dir\",\n+      rebase_path(\"//third_party/\", root_build_dir),  # jinja is in chromium's third_party\n+      \"--output_base\",\n+      rebase_path(invoker.out_dir, root_build_dir),\n+      \"--config\",\n+      rebase_path(invoker.config_file, root_build_dir),\n+    ]\n+\n+    if (defined(invoker.config_values)) {\n+      foreach(value, invoker.config_values) {\n+        args += [\n+          \"--config_value\",\n+          value,\n+        ]\n+      }\n+    }\n+\n+    outputs = get_path_info(rebase_path(invoker.outputs, \".\", invoker.out_dir),\n+                            \"abspath\")\n+\n+    forward_variables_from(invoker,\n+                           [\n+                             \"visibility\",\n+                             \"deps\",\n+                             \"public_deps\",\n+                           ])\n+  }\n+}"
        },
        {
            "sha": "1fb7119b5fa567535b01d040e2fb003a5ed7cdee",
            "filename": "tools/inspector_protocol/inspector_protocol.gypi",
            "status": "added",
            "additions": 33,
            "deletions": 0,
            "changes": 33,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Finspector_protocol.gypi",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Finspector_protocol.gypi",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Finspector_protocol.gypi?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,33 @@\n+# Copyright 2016 The Chromium Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file.\n+\n+{\n+  'variables': {\n+    'inspector_protocol_files': [\n+      'lib/Allocator_h.template',\n+      'lib/Array_h.template',\n+      'lib/Collections_h.template',\n+      'lib/DispatcherBase_cpp.template',\n+      'lib/DispatcherBase_h.template',\n+      'lib/ErrorSupport_cpp.template',\n+      'lib/ErrorSupport_h.template',\n+      'lib/Forward_h.template',\n+      'lib/FrontendChannel_h.template',\n+      'lib/Maybe_h.template',\n+      'lib/Object_cpp.template',\n+      'lib/Object_h.template',\n+      'lib/Parser_cpp.template',\n+      'lib/Parser_h.template',\n+      'lib/Protocol_cpp.template',\n+      'lib/ValueConversions_h.template',\n+      'lib/Values_cpp.template',\n+      'lib/Values_h.template',\n+      'templates/Exported_h.template',\n+      'templates/Imported_h.template',\n+      'templates/TypeBuilder_cpp.template',\n+      'templates/TypeBuilder_h.template',\n+      'CodeGenerator.py',\n+    ]\n+  }\n+}"
        },
        {
            "sha": "8f8109d695c5976647454ce6ccb3d3c99eebe437",
            "filename": "tools/inspector_protocol/lib/Allocator_h.template",
            "status": "added",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FAllocator_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FAllocator_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FAllocator_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,30 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_Allocator_h\n+#define {{\"_\".join(config.protocol.namespace)}}_Allocator_h\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+enum NotNullTagEnum { NotNullLiteral };\n+\n+#define PROTOCOL_DISALLOW_NEW()                                 \\\n+    private:                                                    \\\n+        void* operator new(size_t) = delete;                    \\\n+        void* operator new(size_t, NotNullTagEnum, void*) = delete; \\\n+        void* operator new(size_t, void*) = delete;             \\\n+    public:\n+\n+#define PROTOCOL_DISALLOW_COPY(ClassName) \\\n+    private: \\\n+        ClassName(const ClassName&) = delete; \\\n+        ClassName& operator=(const ClassName&) = delete\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_Allocator_h)"
        },
        {
            "sha": "3854f6e5cd102e9962e847e2650b0b6d3f8ef161",
            "filename": "tools/inspector_protocol/lib/Array_h.template",
            "status": "added",
            "additions": 136,
            "deletions": 0,
            "changes": 136,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FArray_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FArray_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FArray_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,136 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_Array_h\n+#define {{\"_\".join(config.protocol.namespace)}}_Array_h\n+\n+//#include \"ErrorSupport.h\"\n+//#include \"Forward.h\"\n+//#include \"ValueConversions.h\"\n+//#include \"Values.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+template<typename T>\n+class Array {\n+public:\n+    static std::unique_ptr<Array<T>> create()\n+    {\n+        return std::unique_ptr<Array<T>>(new Array<T>());\n+    }\n+\n+    static std::unique_ptr<Array<T>> fromValue(protocol::Value* value, ErrorSupport* errors)\n+    {\n+        protocol::ListValue* array = ListValue::cast(value);\n+        if (!array) {\n+            errors->addError(\"array expected\");\n+            return nullptr;\n+        }\n+        std::unique_ptr<Array<T>> result(new Array<T>());\n+        errors->push();\n+        for (size_t i = 0; i < array->size(); ++i) {\n+            errors->setName(StringUtil::fromInteger(i));\n+            std::unique_ptr<T> item = ValueConversions<T>::fromValue(array->at(i), errors);\n+            result->m_vector.push_back(std::move(item));\n+        }\n+        errors->pop();\n+        if (errors->hasErrors())\n+            return nullptr;\n+        return result;\n+    }\n+\n+    void addItem(std::unique_ptr<T> value)\n+    {\n+        m_vector.push_back(std::move(value));\n+    }\n+\n+    size_t length()\n+    {\n+        return m_vector.size();\n+    }\n+\n+    T* get(size_t index)\n+    {\n+        return m_vector[index].get();\n+    }\n+\n+    std::unique_ptr<protocol::ListValue> toValue()\n+    {\n+        std::unique_ptr<protocol::ListValue> result = ListValue::create();\n+        for (auto& item : m_vector)\n+            result->pushValue(ValueConversions<T>::toValue(item));\n+        return result;\n+    }\n+\n+private:\n+    std::vector<std::unique_ptr<T>> m_vector;\n+};\n+\n+template<typename T>\n+class ArrayBase {\n+public:\n+    static std::unique_ptr<Array<T>> create()\n+    {\n+        return std::unique_ptr<Array<T>>(new Array<T>());\n+    }\n+\n+    static std::unique_ptr<Array<T>> fromValue(protocol::Value* value, ErrorSupport* errors)\n+    {\n+        protocol::ListValue* array = ListValue::cast(value);\n+        if (!array) {\n+            errors->addError(\"array expected\");\n+            return nullptr;\n+        }\n+        errors->push();\n+        std::unique_ptr<Array<T>> result(new Array<T>());\n+        for (size_t i = 0; i < array->size(); ++i) {\n+            errors->setName(StringUtil::fromInteger(i));\n+            T item = ValueConversions<T>::fromValue(array->at(i), errors);\n+            result->m_vector.push_back(item);\n+        }\n+        errors->pop();\n+        if (errors->hasErrors())\n+            return nullptr;\n+        return result;\n+    }\n+\n+    void addItem(const T& value)\n+    {\n+        m_vector.push_back(value);\n+    }\n+\n+    size_t length()\n+    {\n+        return m_vector.size();\n+    }\n+\n+    T get(size_t index)\n+    {\n+        return m_vector[index];\n+    }\n+\n+    std::unique_ptr<protocol::ListValue> toValue()\n+    {\n+        std::unique_ptr<protocol::ListValue> result = ListValue::create();\n+        for (auto& item : m_vector)\n+            result->pushValue(ValueConversions<T>::toValue(item));\n+        return result;\n+    }\n+\n+private:\n+    std::vector<T> m_vector;\n+};\n+\n+template<> class Array<String> : public ArrayBase<String> {};\n+template<> class Array<int> : public ArrayBase<int> {};\n+template<> class Array<double> : public ArrayBase<double> {};\n+template<> class Array<bool> : public ArrayBase<bool> {};\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_Array_h)"
        },
        {
            "sha": "7505a17bfa6e68450d693f915c39ab5d37907ca4",
            "filename": "tools/inspector_protocol/lib/Collections_h.template",
            "status": "added",
            "additions": 43,
            "deletions": 0,
            "changes": 43,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FCollections_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FCollections_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FCollections_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,43 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_Collections_h\n+#define {{\"_\".join(config.protocol.namespace)}}_Collections_h\n+\n+#include {{format_include(config.protocol.package, \"Forward\")}}\n+#include <cstddef>\n+\n+#if defined(__APPLE__) && !defined(_LIBCPP_VERSION)\n+#include <map>\n+#include <set>\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+template <class Key, class T> using HashMap = std::map<Key, T>;\n+template <class Key> using HashSet = std::set<Key>;\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#else\n+#include <unordered_map>\n+#include <unordered_set>\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+template <class Key, class T> using HashMap = std::unordered_map<Key, T>;\n+template <class Key> using HashSet = std::unordered_set<Key>;\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // defined(__APPLE__) && !defined(_LIBCPP_VERSION)\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_Collections_h)"
        },
        {
            "sha": "cecef743bffcc6d1301a5c36180888b23ae709ba",
            "filename": "tools/inspector_protocol/lib/DispatcherBase_cpp.template",
            "status": "added",
            "additions": 354,
            "deletions": 0,
            "changes": 354,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FDispatcherBase_cpp.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FDispatcherBase_cpp.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FDispatcherBase_cpp.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,354 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+//#include \"DispatcherBase.h\"\n+//#include \"Parser.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+// static\n+DispatchResponse DispatchResponse::OK()\n+{\n+    DispatchResponse result;\n+    result.m_status = kSuccess;\n+    result.m_errorCode = kParseError;\n+    return result;\n+}\n+\n+// static\n+DispatchResponse DispatchResponse::Error(const String& error)\n+{\n+    DispatchResponse result;\n+    result.m_status = kError;\n+    result.m_errorCode = kServerError;\n+    result.m_errorMessage = error;\n+    return result;\n+}\n+\n+// static\n+DispatchResponse DispatchResponse::InternalError()\n+{\n+    DispatchResponse result;\n+    result.m_status = kError;\n+    result.m_errorCode = kInternalError;\n+    result.m_errorMessage = \"Internal error\";\n+    return result;\n+}\n+\n+// static\n+DispatchResponse DispatchResponse::InvalidParams(const String& error)\n+{\n+    DispatchResponse result;\n+    result.m_status = kError;\n+    result.m_errorCode = kInvalidParams;\n+    result.m_errorMessage = error;\n+    return result;\n+}\n+\n+// static\n+DispatchResponse DispatchResponse::FallThrough()\n+{\n+    DispatchResponse result;\n+    result.m_status = kFallThrough;\n+    result.m_errorCode = kParseError;\n+    return result;\n+}\n+\n+// static\n+const char DispatcherBase::kInvalidParamsString[] = \"Invalid parameters\";\n+\n+DispatcherBase::WeakPtr::WeakPtr(DispatcherBase* dispatcher) : m_dispatcher(dispatcher) { }\n+\n+DispatcherBase::WeakPtr::~WeakPtr()\n+{\n+    if (m_dispatcher)\n+        m_dispatcher->m_weakPtrs.erase(this);\n+}\n+\n+DispatcherBase::Callback::Callback(std::unique_ptr<DispatcherBase::WeakPtr> backendImpl, int callId, int callbackId)\n+    : m_backendImpl(std::move(backendImpl))\n+    , m_callId(callId)\n+    , m_callbackId(callbackId) { }\n+\n+DispatcherBase::Callback::~Callback() = default;\n+\n+void DispatcherBase::Callback::dispose()\n+{\n+    m_backendImpl = nullptr;\n+}\n+\n+void DispatcherBase::Callback::sendIfActive(std::unique_ptr<protocol::DictionaryValue> partialMessage, const DispatchResponse& response)\n+{\n+    if (!m_backendImpl || !m_backendImpl->get())\n+        return;\n+    m_backendImpl->get()->sendResponse(m_callId, response, std::move(partialMessage));\n+    m_backendImpl = nullptr;\n+}\n+\n+void DispatcherBase::Callback::fallThroughIfActive()\n+{\n+    if (!m_backendImpl || !m_backendImpl->get())\n+        return;\n+    m_backendImpl->get()->markFallThrough(m_callbackId);\n+    m_backendImpl = nullptr;\n+}\n+\n+DispatcherBase::DispatcherBase(FrontendChannel* frontendChannel)\n+    : m_frontendChannel(frontendChannel)\n+    , m_lastCallbackId(0)\n+    , m_lastCallbackFallThrough(false) { }\n+\n+DispatcherBase::~DispatcherBase()\n+{\n+    clearFrontend();\n+}\n+\n+int DispatcherBase::nextCallbackId()\n+{\n+    m_lastCallbackFallThrough = false;\n+    return ++m_lastCallbackId;\n+}\n+\n+void DispatcherBase::markFallThrough(int callbackId)\n+{\n+    DCHECK(callbackId == m_lastCallbackId);\n+    m_lastCallbackFallThrough = true;\n+}\n+\n+void DispatcherBase::sendResponse(int callId, const DispatchResponse& response, std::unique_ptr<protocol::DictionaryValue> result)\n+{\n+    if (!m_frontendChannel)\n+        return;\n+    if (response.status() == DispatchResponse::kError) {\n+        reportProtocolError(callId, response.errorCode(), response.errorMessage(), nullptr);\n+        return;\n+    }\n+    m_frontendChannel->sendProtocolResponse(callId, InternalResponse::createResponse(callId, std::move(result)));\n+}\n+\n+void DispatcherBase::sendResponse(int callId, const DispatchResponse& response)\n+{\n+    sendResponse(callId, response, DictionaryValue::create());\n+}\n+\n+namespace {\n+\n+class ProtocolError : public Serializable {\n+public:\n+    static std::unique_ptr<ProtocolError> createErrorResponse(int callId, DispatchResponse::ErrorCode code, const String& errorMessage, ErrorSupport* errors)\n+    {\n+        std::unique_ptr<ProtocolError> protocolError(new ProtocolError(code, errorMessage));\n+        protocolError->m_callId = callId;\n+        protocolError->m_hasCallId = true;\n+        if (errors && errors->hasErrors())\n+            protocolError->m_data = errors->errors();\n+        return protocolError;\n+    }\n+\n+    static std::unique_ptr<ProtocolError> createErrorNotification(DispatchResponse::ErrorCode code, const String& errorMessage)\n+    {\n+        return std::unique_ptr<ProtocolError>(new ProtocolError(code, errorMessage));\n+    }\n+\n+    String serialize() override\n+    {\n+        std::unique_ptr<protocol::DictionaryValue> error = DictionaryValue::create();\n+        error->setInteger(\"code\", m_code);\n+        error->setString(\"message\", m_errorMessage);\n+        if (m_data.length())\n+            error->setString(\"data\", m_data);\n+        std::unique_ptr<protocol::DictionaryValue> message = DictionaryValue::create();\n+        message->setObject(\"error\", std::move(error));\n+        if (m_hasCallId)\n+            message->setInteger(\"id\", m_callId);\n+        return message->serialize();\n+    }\n+\n+    ~ProtocolError() override {}\n+\n+private:\n+    ProtocolError(DispatchResponse::ErrorCode code, const String& errorMessage)\n+        : m_code(code)\n+        , m_errorMessage(errorMessage)\n+    {\n+    }\n+\n+    DispatchResponse::ErrorCode m_code;\n+    String m_errorMessage;\n+    String m_data;\n+    int m_callId = 0;\n+    bool m_hasCallId = false;\n+};\n+\n+} // namespace\n+\n+static void reportProtocolErrorTo(FrontendChannel* frontendChannel, int callId, DispatchResponse::ErrorCode code, const String& errorMessage, ErrorSupport* errors)\n+{\n+    if (frontendChannel)\n+        frontendChannel->sendProtocolResponse(callId, ProtocolError::createErrorResponse(callId, code, errorMessage, errors));\n+}\n+\n+static void reportProtocolErrorTo(FrontendChannel* frontendChannel, DispatchResponse::ErrorCode code, const String& errorMessage)\n+{\n+    if (frontendChannel)\n+        frontendChannel->sendProtocolNotification(ProtocolError::createErrorNotification(code, errorMessage));\n+}\n+\n+void DispatcherBase::reportProtocolError(int callId, DispatchResponse::ErrorCode code, const String& errorMessage, ErrorSupport* errors)\n+{\n+    reportProtocolErrorTo(m_frontendChannel, callId, code, errorMessage, errors);\n+}\n+\n+void DispatcherBase::clearFrontend()\n+{\n+    m_frontendChannel = nullptr;\n+    for (auto& weak : m_weakPtrs)\n+        weak->dispose();\n+    m_weakPtrs.clear();\n+}\n+\n+std::unique_ptr<DispatcherBase::WeakPtr> DispatcherBase::weakPtr()\n+{\n+    std::unique_ptr<DispatcherBase::WeakPtr> weak(new DispatcherBase::WeakPtr(this));\n+    m_weakPtrs.insert(weak.get());\n+    return weak;\n+}\n+\n+UberDispatcher::UberDispatcher(FrontendChannel* frontendChannel)\n+    : m_frontendChannel(frontendChannel)\n+    , m_fallThroughForNotFound(false) { }\n+\n+void UberDispatcher::setFallThroughForNotFound(bool fallThroughForNotFound)\n+{\n+    m_fallThroughForNotFound = fallThroughForNotFound;\n+}\n+\n+void UberDispatcher::registerBackend(const String& name, std::unique_ptr<protocol::DispatcherBase> dispatcher)\n+{\n+    m_dispatchers[name] = std::move(dispatcher);\n+}\n+\n+void UberDispatcher::setupRedirects(const HashMap<String, String>& redirects)\n+{\n+    for (const auto& pair : redirects)\n+        m_redirects[pair.first] = pair.second;\n+}\n+\n+DispatchResponse::Status UberDispatcher::dispatch(std::unique_ptr<Value> parsedMessage, int* outCallId, String* outMethod)\n+{\n+    if (!parsedMessage) {\n+        reportProtocolErrorTo(m_frontendChannel, DispatchResponse::kParseError, \"Message must be a valid JSON\");\n+        return DispatchResponse::kError;\n+    }\n+    std::unique_ptr<protocol::DictionaryValue> messageObject = DictionaryValue::cast(std::move(parsedMessage));\n+    if (!messageObject) {\n+        reportProtocolErrorTo(m_frontendChannel, DispatchResponse::kInvalidRequest, \"Message must be an object\");\n+        return DispatchResponse::kError;\n+    }\n+\n+    int callId = 0;\n+    protocol::Value* callIdValue = messageObject->get(\"id\");\n+    bool success = callIdValue && callIdValue->asInteger(&callId);\n+    if (outCallId)\n+        *outCallId = callId;\n+    if (!success) {\n+        reportProtocolErrorTo(m_frontendChannel, DispatchResponse::kInvalidRequest, \"Message must have integer 'id' property\");\n+        return DispatchResponse::kError;\n+    }\n+\n+    protocol::Value* methodValue = messageObject->get(\"method\");\n+    String method;\n+    success = methodValue && methodValue->asString(&method);\n+    if (outMethod)\n+        *outMethod = method;\n+    if (!success) {\n+        reportProtocolErrorTo(m_frontendChannel, callId, DispatchResponse::kInvalidRequest, \"Message must have string 'method' property\", nullptr);\n+        return DispatchResponse::kError;\n+    }\n+\n+    HashMap<String, String>::iterator redirectIt = m_redirects.find(method);\n+    if (redirectIt != m_redirects.end())\n+        method = redirectIt->second;\n+\n+    size_t dotIndex = StringUtil::find(method, \".\");\n+    if (dotIndex == StringUtil::kNotFound) {\n+        if (m_fallThroughForNotFound)\n+            return DispatchResponse::kFallThrough;\n+        reportProtocolErrorTo(m_frontendChannel, callId, DispatchResponse::kMethodNotFound, \"'\" + method + \"' wasn't found\", nullptr);\n+        return DispatchResponse::kError;\n+    }\n+    String domain = StringUtil::substring(method, 0, dotIndex);\n+    auto it = m_dispatchers.find(domain);\n+    if (it == m_dispatchers.end()) {\n+        if (m_fallThroughForNotFound)\n+            return DispatchResponse::kFallThrough;\n+        reportProtocolErrorTo(m_frontendChannel, callId, DispatchResponse::kMethodNotFound, \"'\" + method + \"' wasn't found\", nullptr);\n+        return DispatchResponse::kError;\n+    }\n+    return it->second->dispatch(callId, method, std::move(messageObject));\n+}\n+\n+bool UberDispatcher::getCommandName(const String& message, String* method, std::unique_ptr<protocol::DictionaryValue>* parsedMessage)\n+{\n+    std::unique_ptr<protocol::Value> value = StringUtil::parseJSON(message);\n+    if (!value) {\n+        reportProtocolErrorTo(m_frontendChannel, DispatchResponse::kParseError, \"Message must be a valid JSON\");\n+        return false;\n+   }\n+\n+    protocol::DictionaryValue* object = DictionaryValue::cast(value.get());\n+    if (!object) {\n+        reportProtocolErrorTo(m_frontendChannel, DispatchResponse::kInvalidRequest, \"Message must be an object\");\n+        return false;\n+    }\n+\n+    if (!object->getString(\"method\", method)) {\n+        reportProtocolErrorTo(m_frontendChannel, DispatchResponse::kInvalidRequest, \"Message must have string 'method' property\");\n+        return false;\n+    }\n+\n+    parsedMessage->reset(DictionaryValue::cast(value.release()));\n+    return true;\n+}\n+\n+UberDispatcher::~UberDispatcher() = default;\n+\n+// static\n+std::unique_ptr<InternalResponse> InternalResponse::createResponse(int callId, std::unique_ptr<Serializable> params)\n+{\n+    return std::unique_ptr<InternalResponse>(new InternalResponse(callId, String(), std::move(params)));\n+}\n+\n+// static\n+std::unique_ptr<InternalResponse> InternalResponse::createNotification(const String& notification, std::unique_ptr<Serializable> params)\n+{\n+    return std::unique_ptr<InternalResponse>(new InternalResponse(0, notification, std::move(params)));\n+}\n+\n+String InternalResponse::serialize()\n+{\n+    std::unique_ptr<DictionaryValue> result = DictionaryValue::create();\n+    std::unique_ptr<Serializable> params(m_params ? std::move(m_params) : DictionaryValue::create());\n+    if (m_notification.length()) {\n+        result->setString(\"method\", m_notification);\n+        result->setValue(\"params\", SerializedValue::create(params->serialize()));\n+    } else {\n+        result->setInteger(\"id\", m_callId);\n+        result->setValue(\"result\", SerializedValue::create(params->serialize()));\n+    }\n+    return result->serialize();\n+}\n+\n+InternalResponse::InternalResponse(int callId, const String& notification, std::unique_ptr<Serializable> params)\n+    : m_callId(callId)\n+    , m_notification(notification)\n+    , m_params(params ? std::move(params) : nullptr)\n+{\n+}\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}"
        },
        {
            "sha": "d70a4afe71de2c5522e8e1002fd5e6ee19840fdf",
            "filename": "tools/inspector_protocol/lib/DispatcherBase_h.template",
            "status": "added",
            "additions": 173,
            "deletions": 0,
            "changes": 173,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FDispatcherBase_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FDispatcherBase_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FDispatcherBase_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,173 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_DispatcherBase_h\n+#define {{\"_\".join(config.protocol.namespace)}}_DispatcherBase_h\n+\n+//#include \"Collections.h\"\n+//#include \"ErrorSupport.h\"\n+//#include \"Forward.h\"\n+//#include \"Values.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+class WeakPtr;\n+\n+class {{config.lib.export_macro}} DispatchResponse {\n+public:\n+    enum Status {\n+        kSuccess = 0,\n+        kError = 1,\n+        kFallThrough = 2,\n+        kAsync = 3\n+    };\n+\n+    enum ErrorCode {\n+        kParseError = -32700,\n+        kInvalidRequest = -32600,\n+        kMethodNotFound = -32601,\n+        kInvalidParams = -32602,\n+        kInternalError = -32603,\n+        kServerError = -32000,\n+    };\n+\n+    Status status() const { return m_status; }\n+    const String& errorMessage() const { return m_errorMessage; }\n+    ErrorCode errorCode() const { return m_errorCode; }\n+    bool isSuccess() const { return m_status == kSuccess; }\n+\n+    static DispatchResponse OK();\n+    static DispatchResponse Error(const String&);\n+    static DispatchResponse InternalError();\n+    static DispatchResponse InvalidParams(const String&);\n+    static DispatchResponse FallThrough();\n+\n+private:\n+    Status m_status;\n+    String m_errorMessage;\n+    ErrorCode m_errorCode;\n+};\n+\n+class {{config.lib.export_macro}} DispatcherBase {\n+    PROTOCOL_DISALLOW_COPY(DispatcherBase);\n+public:\n+    static const char kInvalidParamsString[];\n+    class {{config.lib.export_macro}} WeakPtr {\n+    public:\n+        explicit WeakPtr(DispatcherBase*);\n+        ~WeakPtr();\n+        DispatcherBase* get() { return m_dispatcher; }\n+        void dispose() { m_dispatcher = nullptr; }\n+\n+    private:\n+        DispatcherBase* m_dispatcher;\n+    };\n+\n+    class {{config.lib.export_macro}} Callback {\n+    public:\n+        Callback(std::unique_ptr<WeakPtr> backendImpl, int callId, int callbackId);\n+        virtual ~Callback();\n+        void dispose();\n+\n+    protected:\n+        void sendIfActive(std::unique_ptr<protocol::DictionaryValue> partialMessage, const DispatchResponse& response);\n+        void fallThroughIfActive();\n+\n+    private:\n+        std::unique_ptr<WeakPtr> m_backendImpl;\n+        int m_callId;\n+        int m_callbackId;\n+    };\n+\n+    explicit DispatcherBase(FrontendChannel*);\n+    virtual ~DispatcherBase();\n+\n+    virtual DispatchResponse::Status dispatch(int callId, const String& method, std::unique_ptr<protocol::DictionaryValue> messageObject) = 0;\n+\n+    void sendResponse(int callId, const DispatchResponse&, std::unique_ptr<protocol::DictionaryValue> result);\n+    void sendResponse(int callId, const DispatchResponse&);\n+\n+    void reportProtocolError(int callId, DispatchResponse::ErrorCode, const String& errorMessage, ErrorSupport* errors);\n+    void clearFrontend();\n+\n+    std::unique_ptr<WeakPtr> weakPtr();\n+\n+    int nextCallbackId();\n+    void markFallThrough(int callbackId);\n+    bool lastCallbackFallThrough() { return m_lastCallbackFallThrough; }\n+\n+private:\n+    FrontendChannel* m_frontendChannel;\n+    protocol::HashSet<WeakPtr*> m_weakPtrs;\n+    int m_lastCallbackId;\n+    bool m_lastCallbackFallThrough;\n+};\n+\n+class {{config.lib.export_macro}} UberDispatcher {\n+    PROTOCOL_DISALLOW_COPY(UberDispatcher);\n+public:\n+    explicit UberDispatcher(FrontendChannel*);\n+    void registerBackend(const String& name, std::unique_ptr<protocol::DispatcherBase>);\n+    void setupRedirects(const HashMap<String, String>&);\n+    DispatchResponse::Status dispatch(std::unique_ptr<Value> message, int* callId = nullptr, String* method = nullptr);\n+    FrontendChannel* channel() { return m_frontendChannel; }\n+    bool fallThroughForNotFound() { return m_fallThroughForNotFound; }\n+    void setFallThroughForNotFound(bool);\n+    bool getCommandName(const String& message, String* method, std::unique_ptr<protocol::DictionaryValue>* parsedMessage);\n+    virtual ~UberDispatcher();\n+\n+private:\n+    FrontendChannel* m_frontendChannel;\n+    bool m_fallThroughForNotFound;\n+    HashMap<String, String> m_redirects;\n+    protocol::HashMap<String, std::unique_ptr<protocol::DispatcherBase>> m_dispatchers;\n+};\n+\n+class InternalResponse : public Serializable {\n+    PROTOCOL_DISALLOW_COPY(InternalResponse);\n+public:\n+    static std::unique_ptr<InternalResponse> createResponse(int callId, std::unique_ptr<Serializable> params);\n+    static std::unique_ptr<InternalResponse> createNotification(const String& notification, std::unique_ptr<Serializable> params = nullptr);\n+\n+    String serialize() override;\n+\n+    ~InternalResponse() override {}\n+\n+private:\n+    InternalResponse(int callId, const String& notification, std::unique_ptr<Serializable> params);\n+\n+    int m_callId;\n+    String m_notification;\n+    std::unique_ptr<Serializable> m_params;\n+};\n+\n+class InternalRawNotification : public Serializable {\n+public:\n+    static std::unique_ptr<InternalRawNotification> create(const String& notification)\n+    {\n+        return std::unique_ptr<InternalRawNotification>(new InternalRawNotification(notification));\n+    }\n+    ~InternalRawNotification() override {}\n+\n+    String serialize() override\n+    {\n+        return m_notification;\n+    }\n+\n+private:\n+  explicit InternalRawNotification(const String& notification)\n+    : m_notification(notification)\n+  {\n+  }\n+\n+  String m_notification;\n+};\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_DispatcherBase_h)"
        },
        {
            "sha": "7b858b8dc48f3746f233896d01a89379eaf9507c",
            "filename": "tools/inspector_protocol/lib/ErrorSupport_cpp.template",
            "status": "added",
            "additions": 71,
            "deletions": 0,
            "changes": 71,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FErrorSupport_cpp.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FErrorSupport_cpp.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FErrorSupport_cpp.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,71 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+//#include \"ErrorSupport.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+ErrorSupport::ErrorSupport() { }\n+ErrorSupport::~ErrorSupport() { }\n+\n+void ErrorSupport::setName(const char* name)\n+{\n+    setName(String(name));\n+}\n+\n+void ErrorSupport::setName(const String& name)\n+{\n+    DCHECK(m_path.size());\n+    m_path[m_path.size() - 1] = name;\n+}\n+\n+void ErrorSupport::push()\n+{\n+    m_path.push_back(String());\n+}\n+\n+void ErrorSupport::pop()\n+{\n+    m_path.pop_back();\n+}\n+\n+void ErrorSupport::addError(const char* error)\n+{\n+    addError(String(error));\n+}\n+\n+void ErrorSupport::addError(const String& error)\n+{\n+    StringBuilder builder;\n+    for (size_t i = 0; i < m_path.size(); ++i) {\n+        if (i)\n+            StringUtil::builderAppend(builder, '.');\n+        StringUtil::builderAppend(builder, m_path[i]);\n+    }\n+    StringUtil::builderAppend(builder, \": \");\n+    StringUtil::builderAppend(builder, error);\n+    m_errors.push_back(StringUtil::builderToString(builder));\n+}\n+\n+bool ErrorSupport::hasErrors()\n+{\n+    return !!m_errors.size();\n+}\n+\n+String ErrorSupport::errors()\n+{\n+    StringBuilder builder;\n+    for (size_t i = 0; i < m_errors.size(); ++i) {\n+        if (i)\n+            StringUtil::builderAppend(builder, \"; \");\n+        StringUtil::builderAppend(builder, m_errors[i]);\n+    }\n+    return StringUtil::builderToString(builder);\n+}\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}"
        },
        {
            "sha": "083f2a5eb0d4d3fddb16ca49b9327221b790ad6d",
            "filename": "tools/inspector_protocol/lib/ErrorSupport_h.template",
            "status": "added",
            "additions": 37,
            "deletions": 0,
            "changes": 37,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FErrorSupport_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FErrorSupport_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FErrorSupport_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,37 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_ErrorSupport_h\n+#define {{\"_\".join(config.protocol.namespace)}}_ErrorSupport_h\n+\n+//#include \"Forward.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+class {{config.lib.export_macro}} ErrorSupport {\n+public:\n+    ErrorSupport();\n+    ~ErrorSupport();\n+\n+    void push();\n+    void setName(const char*);\n+    void setName(const String&);\n+    void pop();\n+    void addError(const char*);\n+    void addError(const String&);\n+    bool hasErrors();\n+    String errors();\n+\n+private:\n+    std::vector<String> m_path;\n+    std::vector<String> m_errors;\n+};\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_ErrorSupport_h)"
        },
        {
            "sha": "34d1c0d3e946cd7553fee0a3ef71b5d1e6d5aa78",
            "filename": "tools/inspector_protocol/lib/Forward_h.template",
            "status": "added",
            "additions": 37,
            "deletions": 0,
            "changes": 37,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FForward_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FForward_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FForward_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,37 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_Forward_h\n+#define {{\"_\".join(config.protocol.namespace)}}_Forward_h\n+\n+{% if config.lib.export_header %}\n+#include {{format_include(config.lib.export_header)}}\n+{% endif %}\n+#include {{format_include(config.lib.string_header)}}\n+\n+#include <vector>\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+template<typename T> class Array;\n+class DictionaryValue;\n+class DispatchResponse;\n+class ErrorSupport;\n+class FundamentalValue;\n+class ListValue;\n+template<typename T> class Maybe;\n+class Object;\n+using Response = DispatchResponse;\n+class SerializedValue;\n+class StringValue;\n+class UberDispatcher;\n+class Value;\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_Forward_h)"
        },
        {
            "sha": "0454978b0c8e88116cf89c66c0a4a9be6460f4f5",
            "filename": "tools/inspector_protocol/lib/FrontendChannel_h.template",
            "status": "added",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FFrontendChannel_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FFrontendChannel_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FFrontendChannel_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,30 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_FrontendChannel_h\n+#define {{\"_\".join(config.protocol.namespace)}}_FrontendChannel_h\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+class {{config.lib.export_macro}} Serializable {\n+public:\n+    virtual String serialize() = 0;\n+    virtual ~Serializable() = default;\n+};\n+\n+class {{config.lib.export_macro}} FrontendChannel {\n+public:\n+    virtual ~FrontendChannel() { }\n+    virtual void sendProtocolResponse(int callId, std::unique_ptr<Serializable> message) = 0;\n+    virtual void sendProtocolNotification(std::unique_ptr<Serializable> message) = 0;\n+    virtual void flushProtocolNotifications() = 0;\n+};\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_FrontendChannel_h)"
        },
        {
            "sha": "71593acd0e553d737e6fd9a623bf1874c35298ee",
            "filename": "tools/inspector_protocol/lib/Maybe_h.template",
            "status": "added",
            "additions": 86,
            "deletions": 0,
            "changes": 86,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FMaybe_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FMaybe_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FMaybe_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,86 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_Maybe_h\n+#define {{\"_\".join(config.protocol.namespace)}}_Maybe_h\n+\n+//#include \"Forward.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+template<typename T>\n+class Maybe {\n+public:\n+    Maybe() : m_value() { }\n+    Maybe(std::unique_ptr<T> value) : m_value(std::move(value)) { }\n+    Maybe(Maybe&& other) : m_value(std::move(other.m_value)) { }\n+    void operator=(std::unique_ptr<T> value) { m_value = std::move(value); }\n+    T* fromJust() const { DCHECK(m_value); return m_value.get(); }\n+    T* fromMaybe(T* defaultValue) const { return m_value ? m_value.get() : defaultValue; }\n+    bool isJust() const { return !!m_value; }\n+    std::unique_ptr<T> takeJust() { DCHECK(m_value); return std::move(m_value); }\n+private:\n+    std::unique_ptr<T> m_value;\n+};\n+\n+template<typename T>\n+class MaybeBase {\n+public:\n+    MaybeBase() : m_isJust(false) { }\n+    MaybeBase(T value) : m_isJust(true), m_value(value) { }\n+    MaybeBase(MaybeBase&& other) : m_isJust(other.m_isJust), m_value(std::move(other.m_value)) { }\n+    void operator=(T value) { m_value = value; m_isJust = true; }\n+    T fromJust() const { DCHECK(m_isJust); return m_value; }\n+    T fromMaybe(const T& defaultValue) const { return m_isJust ? m_value : defaultValue; }\n+    bool isJust() const { return m_isJust; }\n+    T takeJust() { DCHECK(m_isJust); return m_value; }\n+\n+protected:\n+    bool m_isJust;\n+    T m_value;\n+};\n+\n+template<>\n+class Maybe<bool> : public MaybeBase<bool> {\n+public:\n+    Maybe() { }\n+    Maybe(bool value) : MaybeBase(value) { }\n+    Maybe(Maybe&& other) : MaybeBase(std::move(other)) { }\n+    using MaybeBase::operator=;\n+};\n+\n+template<>\n+class Maybe<int> : public MaybeBase<int> {\n+public:\n+    Maybe() { }\n+    Maybe(int value) : MaybeBase(value) { }\n+    Maybe(Maybe&& other) : MaybeBase(std::move(other)) { }\n+    using MaybeBase::operator=;\n+};\n+\n+template<>\n+class Maybe<double> : public MaybeBase<double> {\n+public:\n+    Maybe() { }\n+    Maybe(double value) : MaybeBase(value) { }\n+    Maybe(Maybe&& other) : MaybeBase(std::move(other)) { }\n+    using MaybeBase::operator=;\n+};\n+\n+template<>\n+class Maybe<String> : public MaybeBase<String> {\n+public:\n+    Maybe() { }\n+    Maybe(const String& value) : MaybeBase(value) { }\n+    Maybe(Maybe&& other) : MaybeBase(std::move(other)) { }\n+    using MaybeBase::operator=;\n+};\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_Maybe_h)"
        },
        {
            "sha": "91723a71e29ce4555dc4077f5fdf074b210931e9",
            "filename": "tools/inspector_protocol/lib/Object_cpp.template",
            "status": "added",
            "additions": 38,
            "deletions": 0,
            "changes": 38,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FObject_cpp.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FObject_cpp.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FObject_cpp.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,38 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+//#include \"Object.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+std::unique_ptr<Object> Object::fromValue(protocol::Value* value, ErrorSupport* errors)\n+{\n+    protocol::DictionaryValue* dictionary = DictionaryValue::cast(value);\n+    if (!dictionary) {\n+        errors->addError(\"object expected\");\n+        return nullptr;\n+    }\n+    dictionary = static_cast<protocol::DictionaryValue*>(dictionary->clone().release());\n+    return std::unique_ptr<Object>(new Object(std::unique_ptr<DictionaryValue>(dictionary)));\n+}\n+\n+std::unique_ptr<protocol::DictionaryValue> Object::toValue() const\n+{\n+    return DictionaryValue::cast(m_object->clone());\n+}\n+\n+std::unique_ptr<Object> Object::clone() const\n+{\n+    return std::unique_ptr<Object>(new Object(DictionaryValue::cast(m_object->clone())));\n+}\n+\n+Object::Object(std::unique_ptr<protocol::DictionaryValue> object) : m_object(std::move(object)) { }\n+\n+Object::~Object() { }\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}"
        },
        {
            "sha": "f6ffc57659e148bb7bf19e12bf86ab21c2f9cb97",
            "filename": "tools/inspector_protocol/lib/Object_h.template",
            "status": "added",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FObject_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FObject_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FObject_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,32 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_Object_h\n+#define {{\"_\".join(config.protocol.namespace)}}_Object_h\n+\n+//#include \"ErrorSupport.h\"\n+//#include \"Forward.h\"\n+//#include \"Values.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+class {{config.lib.export_macro}} Object {\n+public:\n+    static std::unique_ptr<Object> fromValue(protocol::Value*, ErrorSupport*);\n+    ~Object();\n+\n+    std::unique_ptr<protocol::DictionaryValue> toValue() const;\n+    std::unique_ptr<Object> clone() const;\n+private:\n+    explicit Object(std::unique_ptr<protocol::DictionaryValue>);\n+    std::unique_ptr<protocol::DictionaryValue> m_object;\n+};\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_Object_h)"
        },
        {
            "sha": "f3dde5ac218e6f7b19a2861e329f5e1b360ba022",
            "filename": "tools/inspector_protocol/lib/Parser_cpp.template",
            "status": "added",
            "additions": 547,
            "deletions": 0,
            "changes": 547,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FParser_cpp.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FParser_cpp.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FParser_cpp.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,547 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+namespace {\n+\n+const int stackLimit = 1000;\n+\n+enum Token {\n+    ObjectBegin,\n+    ObjectEnd,\n+    ArrayBegin,\n+    ArrayEnd,\n+    StringLiteral,\n+    Number,\n+    BoolTrue,\n+    BoolFalse,\n+    NullToken,\n+    ListSeparator,\n+    ObjectPairSeparator,\n+    InvalidToken,\n+};\n+\n+const char* const nullString = \"null\";\n+const char* const trueString = \"true\";\n+const char* const falseString = \"false\";\n+\n+bool isASCII(uint16_t c)\n+{\n+    return !(c & ~0x7F);\n+}\n+\n+bool isSpaceOrNewLine(uint16_t c)\n+{\n+    return isASCII(c) && c <= ' ' && (c == ' ' || (c <= 0xD && c >= 0x9));\n+}\n+\n+double charactersToDouble(const uint16_t* characters, size_t length, bool* ok)\n+{\n+    std::vector<char> buffer;\n+    buffer.reserve(length + 1);\n+    for (size_t i = 0; i < length; ++i) {\n+        if (!isASCII(characters[i])) {\n+            *ok = false;\n+            return 0;\n+        }\n+        buffer.push_back(static_cast<char>(characters[i]));\n+    }\n+    buffer.push_back('\\0');\n+    return StringUtil::toDouble(buffer.data(), length, ok);\n+}\n+\n+double charactersToDouble(const uint8_t* characters, size_t length, bool* ok)\n+{\n+    std::string buffer(reinterpret_cast<const char*>(characters), length);\n+    return StringUtil::toDouble(buffer.data(), length, ok);\n+}\n+\n+template<typename Char>\n+bool parseConstToken(const Char* start, const Char* end, const Char** tokenEnd, const char* token)\n+{\n+    while (start < end && *token != '\\0' && *start++ == *token++) { }\n+    if (*token != '\\0')\n+        return false;\n+    *tokenEnd = start;\n+    return true;\n+}\n+\n+template<typename Char>\n+bool readInt(const Char* start, const Char* end, const Char** tokenEnd, bool canHaveLeadingZeros)\n+{\n+    if (start == end)\n+        return false;\n+    bool haveLeadingZero = '0' == *start;\n+    int length = 0;\n+    while (start < end && '0' <= *start && *start <= '9') {\n+        ++start;\n+        ++length;\n+    }\n+    if (!length)\n+        return false;\n+    if (!canHaveLeadingZeros && length > 1 && haveLeadingZero)\n+        return false;\n+    *tokenEnd = start;\n+    return true;\n+}\n+\n+template<typename Char>\n+bool parseNumberToken(const Char* start, const Char* end, const Char** tokenEnd)\n+{\n+    // We just grab the number here. We validate the size in DecodeNumber.\n+    // According to RFC4627, a valid number is: [minus] int [frac] [exp]\n+    if (start == end)\n+        return false;\n+    Char c = *start;\n+    if ('-' == c)\n+        ++start;\n+\n+    if (!readInt(start, end, &start, false))\n+        return false;\n+    if (start == end) {\n+        *tokenEnd = start;\n+        return true;\n+    }\n+\n+    // Optional fraction part\n+    c = *start;\n+    if ('.' == c) {\n+        ++start;\n+        if (!readInt(start, end, &start, true))\n+            return false;\n+        if (start == end) {\n+            *tokenEnd = start;\n+            return true;\n+        }\n+        c = *start;\n+    }\n+\n+    // Optional exponent part\n+    if ('e' == c || 'E' == c) {\n+        ++start;\n+        if (start == end)\n+            return false;\n+        c = *start;\n+        if ('-' == c || '+' == c) {\n+            ++start;\n+            if (start == end)\n+                return false;\n+        }\n+        if (!readInt(start, end, &start, true))\n+            return false;\n+    }\n+\n+    *tokenEnd = start;\n+    return true;\n+}\n+\n+template<typename Char>\n+bool readHexDigits(const Char* start, const Char* end, const Char** tokenEnd, int digits)\n+{\n+    if (end - start < digits)\n+        return false;\n+    for (int i = 0; i < digits; ++i) {\n+        Char c = *start++;\n+        if (!(('0' <= c && c <= '9') || ('a' <= c && c <= 'f') || ('A' <= c && c <= 'F')))\n+            return false;\n+    }\n+    *tokenEnd = start;\n+    return true;\n+}\n+\n+template<typename Char>\n+bool parseStringToken(const Char* start, const Char* end, const Char** tokenEnd)\n+{\n+    while (start < end) {\n+        Char c = *start++;\n+        if ('\\\\' == c) {\n+\t    if (start == end)\n+\t        return false;\n+            c = *start++;\n+            // Make sure the escaped char is valid.\n+            switch (c) {\n+            case 'x':\n+                if (!readHexDigits(start, end, &start, 2))\n+                    return false;\n+                break;\n+            case 'u':\n+                if (!readHexDigits(start, end, &start, 4))\n+                    return false;\n+                break;\n+            case '\\\\':\n+            case '/':\n+            case 'b':\n+            case 'f':\n+            case 'n':\n+            case 'r':\n+            case 't':\n+            case 'v':\n+            case '\"':\n+                break;\n+            default:\n+                return false;\n+            }\n+        } else if ('\"' == c) {\n+            *tokenEnd = start;\n+            return true;\n+        }\n+    }\n+    return false;\n+}\n+\n+template<typename Char>\n+bool skipComment(const Char* start, const Char* end, const Char** commentEnd)\n+{\n+    if (start == end)\n+        return false;\n+\n+    if (*start != '/' || start + 1 >= end)\n+        return false;\n+    ++start;\n+\n+    if (*start == '/') {\n+        // Single line comment, read to newline.\n+        for (++start; start < end; ++start) {\n+            if (*start == '\\n' || *start == '\\r') {\n+                *commentEnd = start + 1;\n+                return true;\n+            }\n+        }\n+        *commentEnd = end;\n+        // Comment reaches end-of-input, which is fine.\n+        return true;\n+    }\n+\n+    if (*start == '*') {\n+        Char previous = '\\0';\n+        // Block comment, read until end marker.\n+        for (++start; start < end; previous = *start++) {\n+            if (previous == '*' && *start == '/') {\n+                *commentEnd = start + 1;\n+                return true;\n+            }\n+        }\n+        // Block comment must close before end-of-input.\n+        return false;\n+    }\n+\n+    return false;\n+}\n+\n+template<typename Char>\n+void skipWhitespaceAndComments(const Char* start, const Char* end, const Char** whitespaceEnd)\n+{\n+    while (start < end) {\n+        if (isSpaceOrNewLine(*start)) {\n+            ++start;\n+        } else if (*start == '/') {\n+            const Char* commentEnd;\n+            if (!skipComment(start, end, &commentEnd))\n+                break;\n+            start = commentEnd;\n+        } else {\n+            break;\n+        }\n+    }\n+    *whitespaceEnd = start;\n+}\n+\n+template<typename Char>\n+Token parseToken(const Char* start, const Char* end, const Char** tokenStart, const Char** tokenEnd)\n+{\n+    skipWhitespaceAndComments(start, end, tokenStart);\n+    start = *tokenStart;\n+\n+    if (start == end)\n+        return InvalidToken;\n+\n+    switch (*start) {\n+    case 'n':\n+        if (parseConstToken(start, end, tokenEnd, nullString))\n+            return NullToken;\n+        break;\n+    case 't':\n+        if (parseConstToken(start, end, tokenEnd, trueString))\n+            return BoolTrue;\n+        break;\n+    case 'f':\n+        if (parseConstToken(start, end, tokenEnd, falseString))\n+            return BoolFalse;\n+        break;\n+    case '[':\n+        *tokenEnd = start + 1;\n+        return ArrayBegin;\n+    case ']':\n+        *tokenEnd = start + 1;\n+        return ArrayEnd;\n+    case ',':\n+        *tokenEnd = start + 1;\n+        return ListSeparator;\n+    case '{':\n+        *tokenEnd = start + 1;\n+        return ObjectBegin;\n+    case '}':\n+        *tokenEnd = start + 1;\n+        return ObjectEnd;\n+    case ':':\n+        *tokenEnd = start + 1;\n+        return ObjectPairSeparator;\n+    case '0':\n+    case '1':\n+    case '2':\n+    case '3':\n+    case '4':\n+    case '5':\n+    case '6':\n+    case '7':\n+    case '8':\n+    case '9':\n+    case '-':\n+        if (parseNumberToken(start, end, tokenEnd))\n+            return Number;\n+        break;\n+    case '\"':\n+        if (parseStringToken(start + 1, end, tokenEnd))\n+            return StringLiteral;\n+        break;\n+    }\n+    return InvalidToken;\n+}\n+\n+template<typename Char>\n+int hexToInt(Char c)\n+{\n+    if ('0' <= c && c <= '9')\n+        return c - '0';\n+    if ('A' <= c && c <= 'F')\n+        return c - 'A' + 10;\n+    if ('a' <= c && c <= 'f')\n+        return c - 'a' + 10;\n+    DCHECK(false);\n+    return 0;\n+}\n+\n+template<typename Char>\n+bool decodeString(const Char* start, const Char* end, StringBuilder* output)\n+{\n+    while (start < end) {\n+        uint16_t c = *start++;\n+        if ('\\\\' != c) {\n+            StringUtil::builderAppend(*output, c);\n+            continue;\n+        }\n+\tif (start == end)\n+\t    return false;\n+        c = *start++;\n+\n+        if (c == 'x') {\n+            // \\x is not supported.\n+            return false;\n+        }\n+\n+        switch (c) {\n+        case '\"':\n+        case '/':\n+        case '\\\\':\n+            break;\n+        case 'b':\n+            c = '\\b';\n+            break;\n+        case 'f':\n+            c = '\\f';\n+            break;\n+        case 'n':\n+            c = '\\n';\n+            break;\n+        case 'r':\n+            c = '\\r';\n+            break;\n+        case 't':\n+            c = '\\t';\n+            break;\n+        case 'v':\n+            c = '\\v';\n+            break;\n+        case 'u':\n+            c = (hexToInt(*start) << 12) +\n+                (hexToInt(*(start + 1)) << 8) +\n+                (hexToInt(*(start + 2)) << 4) +\n+                hexToInt(*(start + 3));\n+            start += 4;\n+            break;\n+        default:\n+            return false;\n+        }\n+        StringUtil::builderAppend(*output, c);\n+    }\n+    return true;\n+}\n+\n+template<typename Char>\n+bool decodeString(const Char* start, const Char* end, String* output)\n+{\n+    if (start == end) {\n+        *output = \"\";\n+        return true;\n+    }\n+    if (start > end)\n+        return false;\n+    StringBuilder buffer;\n+    StringUtil::builderReserve(buffer, end - start);\n+    if (!decodeString(start, end, &buffer))\n+        return false;\n+    *output = StringUtil::builderToString(buffer);\n+    return true;\n+}\n+\n+template<typename Char>\n+std::unique_ptr<Value> buildValue(const Char* start, const Char* end, const Char** valueTokenEnd, int depth)\n+{\n+    if (depth > stackLimit)\n+        return nullptr;\n+\n+    std::unique_ptr<Value> result;\n+    const Char* tokenStart;\n+    const Char* tokenEnd;\n+    Token token = parseToken(start, end, &tokenStart, &tokenEnd);\n+    switch (token) {\n+    case InvalidToken:\n+        return nullptr;\n+    case NullToken:\n+        result = Value::null();\n+        break;\n+    case BoolTrue:\n+        result = FundamentalValue::create(true);\n+        break;\n+    case BoolFalse:\n+        result = FundamentalValue::create(false);\n+        break;\n+    case Number: {\n+        bool ok;\n+        double value = charactersToDouble(tokenStart, tokenEnd - tokenStart, &ok);\n+        if (!ok)\n+            return nullptr;\n+        int number = static_cast<int>(value);\n+        if (number == value)\n+            result = FundamentalValue::create(number);\n+        else\n+            result = FundamentalValue::create(value);\n+        break;\n+    }\n+    case StringLiteral: {\n+        String value;\n+        bool ok = decodeString(tokenStart + 1, tokenEnd - 1, &value);\n+        if (!ok)\n+            return nullptr;\n+        result = StringValue::create(value);\n+        break;\n+    }\n+    case ArrayBegin: {\n+        std::unique_ptr<ListValue> array = ListValue::create();\n+        start = tokenEnd;\n+        token = parseToken(start, end, &tokenStart, &tokenEnd);\n+        while (token != ArrayEnd) {\n+            std::unique_ptr<Value> arrayNode = buildValue(start, end, &tokenEnd, depth + 1);\n+            if (!arrayNode)\n+                return nullptr;\n+            array->pushValue(std::move(arrayNode));\n+\n+            // After a list value, we expect a comma or the end of the list.\n+            start = tokenEnd;\n+            token = parseToken(start, end, &tokenStart, &tokenEnd);\n+            if (token == ListSeparator) {\n+                start = tokenEnd;\n+                token = parseToken(start, end, &tokenStart, &tokenEnd);\n+                if (token == ArrayEnd)\n+                    return nullptr;\n+            } else if (token != ArrayEnd) {\n+                // Unexpected value after list value. Bail out.\n+                return nullptr;\n+            }\n+        }\n+        if (token != ArrayEnd)\n+            return nullptr;\n+        result = std::move(array);\n+        break;\n+    }\n+    case ObjectBegin: {\n+        std::unique_ptr<DictionaryValue> object = DictionaryValue::create();\n+        start = tokenEnd;\n+        token = parseToken(start, end, &tokenStart, &tokenEnd);\n+        while (token != ObjectEnd) {\n+            if (token != StringLiteral)\n+                return nullptr;\n+            String key;\n+            if (!decodeString(tokenStart + 1, tokenEnd - 1, &key))\n+                return nullptr;\n+            start = tokenEnd;\n+\n+            token = parseToken(start, end, &tokenStart, &tokenEnd);\n+            if (token != ObjectPairSeparator)\n+                return nullptr;\n+            start = tokenEnd;\n+\n+            std::unique_ptr<Value> value = buildValue(start, end, &tokenEnd, depth + 1);\n+            if (!value)\n+                return nullptr;\n+            object->setValue(key, std::move(value));\n+            start = tokenEnd;\n+\n+            // After a key/value pair, we expect a comma or the end of the\n+            // object.\n+            token = parseToken(start, end, &tokenStart, &tokenEnd);\n+            if (token == ListSeparator) {\n+                start = tokenEnd;\n+                token = parseToken(start, end, &tokenStart, &tokenEnd);\n+                if (token == ObjectEnd)\n+                    return nullptr;\n+            } else if (token != ObjectEnd) {\n+                // Unexpected value after last object value. Bail out.\n+                return nullptr;\n+            }\n+        }\n+        if (token != ObjectEnd)\n+            return nullptr;\n+        result = std::move(object);\n+        break;\n+    }\n+\n+    default:\n+        // We got a token that's not a value.\n+        return nullptr;\n+    }\n+\n+    skipWhitespaceAndComments(tokenEnd, end, valueTokenEnd);\n+    return result;\n+}\n+\n+template<typename Char>\n+std::unique_ptr<Value> parseJSONInternal(const Char* start, unsigned length)\n+{\n+    const Char* end = start + length;\n+    const Char *tokenEnd;\n+    std::unique_ptr<Value> value = buildValue(start, end, &tokenEnd, 0);\n+    if (!value || tokenEnd != end)\n+        return nullptr;\n+    return value;\n+}\n+\n+} // anonymous namespace\n+\n+std::unique_ptr<Value> parseJSONCharacters(const uint16_t* characters, unsigned length)\n+{\n+    return parseJSONInternal<uint16_t>(characters, length);\n+}\n+\n+std::unique_ptr<Value> parseJSONCharacters(const uint8_t* characters, unsigned length)\n+{\n+    return parseJSONInternal<uint8_t>(characters, length);\n+}\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}"
        },
        {
            "sha": "8397d3f5d6911c2f83947a8592cebdceda93c46b",
            "filename": "tools/inspector_protocol/lib/Parser_h.template",
            "status": "added",
            "additions": 22,
            "deletions": 0,
            "changes": 22,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FParser_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FParser_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FParser_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,22 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_Parser_h\n+#define {{\"_\".join(config.protocol.namespace)}}_Parser_h\n+\n+//#include \"Forward.h\"\n+//#include \"Values.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+{{config.lib.export_macro}} std::unique_ptr<Value> parseJSONCharacters(const uint8_t*, unsigned);\n+{{config.lib.export_macro}} std::unique_ptr<Value> parseJSONCharacters(const uint16_t*, unsigned);\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_Parser_h)"
        },
        {
            "sha": "901656373a4f5277ea5f34912b261d939803f767",
            "filename": "tools/inspector_protocol/lib/Protocol_cpp.template",
            "status": "added",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FProtocol_cpp.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FProtocol_cpp.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FProtocol_cpp.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,12 @@\n+// This file is generated.\n+\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#include {{format_include(config.protocol.package, \"Protocol\")}}\n+\n+#include <algorithm>\n+#include <cmath>\n+\n+#include <cstring>"
        },
        {
            "sha": "4d64ec9091a6c258444905122f93fb82ec82f839",
            "filename": "tools/inspector_protocol/lib/ValueConversions_h.template",
            "status": "added",
            "additions": 171,
            "deletions": 0,
            "changes": 171,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FValueConversions_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FValueConversions_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FValueConversions_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,171 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_ValueConversions_h\n+#define {{\"_\".join(config.protocol.namespace)}}_ValueConversions_h\n+\n+//#include \"ErrorSupport.h\"\n+//#include \"Forward.h\"\n+//#include \"Values.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+template<typename T>\n+struct ValueConversions {\n+    static std::unique_ptr<T> fromValue(protocol::Value* value, ErrorSupport* errors)\n+    {\n+        return T::fromValue(value, errors);\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(T* value)\n+    {\n+        return value->toValue();\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(const std::unique_ptr<T>& value)\n+    {\n+        return value->toValue();\n+    }\n+};\n+\n+template<>\n+struct ValueConversions<bool> {\n+    static bool fromValue(protocol::Value* value, ErrorSupport* errors)\n+    {\n+        bool result = false;\n+        bool success = value ? value->asBoolean(&result) : false;\n+        if (!success)\n+            errors->addError(\"boolean value expected\");\n+        return result;\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(bool value)\n+    {\n+        return FundamentalValue::create(value);\n+    }\n+};\n+\n+template<>\n+struct ValueConversions<int> {\n+    static int fromValue(protocol::Value* value, ErrorSupport* errors)\n+    {\n+        int result = 0;\n+        bool success = value ? value->asInteger(&result) : false;\n+        if (!success)\n+            errors->addError(\"integer value expected\");\n+        return result;\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(int value)\n+    {\n+        return FundamentalValue::create(value);\n+    }\n+};\n+\n+template<>\n+struct ValueConversions<double> {\n+    static double fromValue(protocol::Value* value, ErrorSupport* errors)\n+    {\n+        double result = 0;\n+        bool success = value ? value->asDouble(&result) : false;\n+        if (!success)\n+            errors->addError(\"double value expected\");\n+        return result;\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(double value)\n+    {\n+        return FundamentalValue::create(value);\n+    }\n+};\n+\n+template<>\n+struct ValueConversions<String> {\n+    static String fromValue(protocol::Value* value, ErrorSupport* errors)\n+    {\n+        String result;\n+        bool success = value ? value->asString(&result) : false;\n+        if (!success)\n+            errors->addError(\"string value expected\");\n+        return result;\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(const String& value)\n+    {\n+        return StringValue::create(value);\n+    }\n+};\n+\n+template<>\n+struct ValueConversions<Value> {\n+    static std::unique_ptr<Value> fromValue(protocol::Value* value, ErrorSupport* errors)\n+    {\n+        bool success = !!value;\n+        if (!success) {\n+            errors->addError(\"value expected\");\n+            return nullptr;\n+        }\n+        return value->clone();\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(Value* value)\n+    {\n+        return value->clone();\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(const std::unique_ptr<Value>& value)\n+    {\n+        return value->clone();\n+    }\n+};\n+\n+template<>\n+struct ValueConversions<DictionaryValue> {\n+    static std::unique_ptr<DictionaryValue> fromValue(protocol::Value* value, ErrorSupport* errors)\n+    {\n+        bool success = value && value->type() == protocol::Value::TypeObject;\n+        if (!success)\n+            errors->addError(\"object expected\");\n+        return DictionaryValue::cast(value->clone());\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(DictionaryValue* value)\n+    {\n+        return value->clone();\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(const std::unique_ptr<DictionaryValue>& value)\n+    {\n+        return value->clone();\n+    }\n+};\n+\n+template<>\n+struct ValueConversions<ListValue> {\n+    static std::unique_ptr<ListValue> fromValue(protocol::Value* value, ErrorSupport* errors)\n+    {\n+        bool success = value && value->type() == protocol::Value::TypeArray;\n+        if (!success)\n+            errors->addError(\"list expected\");\n+        return ListValue::cast(value->clone());\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(ListValue* value)\n+    {\n+        return value->clone();\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(const std::unique_ptr<ListValue>& value)\n+    {\n+        return value->clone();\n+    }\n+};\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_ValueConversions_h)"
        },
        {
            "sha": "b9f061346bf66f9015ff895c13a081516bde45c7",
            "filename": "tools/inspector_protocol/lib/Values_cpp.template",
            "status": "added",
            "additions": 409,
            "deletions": 0,
            "changes": 409,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FValues_cpp.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FValues_cpp.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FValues_cpp.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,409 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+//#include \"Values.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+namespace {\n+\n+const char* const nullValueString = \"null\";\n+const char* const trueValueString = \"true\";\n+const char* const falseValueString = \"false\";\n+\n+inline bool escapeChar(uint16_t c, StringBuilder* dst)\n+{\n+    switch (c) {\n+    case '\\b': StringUtil::builderAppend(*dst, \"\\\\b\"); break;\n+    case '\\f': StringUtil::builderAppend(*dst, \"\\\\f\"); break;\n+    case '\\n': StringUtil::builderAppend(*dst, \"\\\\n\"); break;\n+    case '\\r': StringUtil::builderAppend(*dst, \"\\\\r\"); break;\n+    case '\\t': StringUtil::builderAppend(*dst, \"\\\\t\"); break;\n+    case '\\\\': StringUtil::builderAppend(*dst, \"\\\\\\\\\"); break;\n+    case '\"': StringUtil::builderAppend(*dst, \"\\\\\\\"\"); break;\n+    default:\n+        return false;\n+    }\n+    return true;\n+}\n+\n+const char hexDigits[17] = \"0123456789ABCDEF\";\n+\n+void appendUnsignedAsHex(uint16_t number, StringBuilder* dst)\n+{\n+    StringUtil::builderAppend(*dst, \"\\\\u\");\n+    for (size_t i = 0; i < 4; ++i) {\n+        uint16_t c = hexDigits[(number & 0xF000) >> 12];\n+        StringUtil::builderAppend(*dst, c);\n+        number <<= 4;\n+    }\n+}\n+\n+template <typename Char>\n+void escapeStringForJSONInternal(const Char* str, unsigned len,\n+                                 StringBuilder* dst)\n+{\n+    for (unsigned i = 0; i < len; ++i) {\n+        Char c = str[i];\n+        if (escapeChar(c, dst))\n+            continue;\n+        if (c < 32 || c > 126) {\n+            appendUnsignedAsHex(c, dst);\n+        } else {\n+            StringUtil::builderAppend(*dst, c);\n+        }\n+    }\n+}\n+\n+} // anonymous namespace\n+\n+bool Value::asBoolean(bool*) const\n+{\n+    return false;\n+}\n+\n+bool Value::asDouble(double*) const\n+{\n+    return false;\n+}\n+\n+bool Value::asInteger(int*) const\n+{\n+    return false;\n+}\n+\n+bool Value::asString(String*) const\n+{\n+    return false;\n+}\n+\n+bool Value::asSerialized(String*) const\n+{\n+    return false;\n+}\n+\n+void Value::writeJSON(StringBuilder* output) const\n+{\n+    DCHECK(m_type == TypeNull);\n+    StringUtil::builderAppend(*output, nullValueString, 4);\n+}\n+\n+std::unique_ptr<Value> Value::clone() const\n+{\n+    return Value::null();\n+}\n+\n+String Value::serialize()\n+{\n+    StringBuilder result;\n+    StringUtil::builderReserve(result, 512);\n+    writeJSON(&result);\n+    return StringUtil::builderToString(result);\n+}\n+\n+bool FundamentalValue::asBoolean(bool* output) const\n+{\n+    if (type() != TypeBoolean)\n+        return false;\n+    *output = m_boolValue;\n+    return true;\n+}\n+\n+bool FundamentalValue::asDouble(double* output) const\n+{\n+    if (type() == TypeDouble) {\n+        *output = m_doubleValue;\n+        return true;\n+    }\n+    if (type() == TypeInteger) {\n+        *output = m_integerValue;\n+        return true;\n+    }\n+    return false;\n+}\n+\n+bool FundamentalValue::asInteger(int* output) const\n+{\n+    if (type() != TypeInteger)\n+        return false;\n+    *output = m_integerValue;\n+    return true;\n+}\n+\n+void FundamentalValue::writeJSON(StringBuilder* output) const\n+{\n+    DCHECK(type() == TypeBoolean || type() == TypeInteger || type() == TypeDouble);\n+    if (type() == TypeBoolean) {\n+        if (m_boolValue)\n+            StringUtil::builderAppend(*output, trueValueString, 4);\n+        else\n+            StringUtil::builderAppend(*output, falseValueString, 5);\n+    } else if (type() == TypeDouble) {\n+        if (!std::isfinite(m_doubleValue)) {\n+            StringUtil::builderAppend(*output, nullValueString, 4);\n+            return;\n+        }\n+        StringUtil::builderAppend(*output, StringUtil::fromDouble(m_doubleValue));\n+    } else if (type() == TypeInteger) {\n+        StringUtil::builderAppend(*output, StringUtil::fromInteger(m_integerValue));\n+    }\n+}\n+\n+std::unique_ptr<Value> FundamentalValue::clone() const\n+{\n+    switch (type()) {\n+    case TypeDouble: return FundamentalValue::create(m_doubleValue);\n+    case TypeInteger: return FundamentalValue::create(m_integerValue);\n+    case TypeBoolean: return FundamentalValue::create(m_boolValue);\n+    default:\n+        DCHECK(false);\n+    }\n+    return nullptr;\n+}\n+\n+bool StringValue::asString(String* output) const\n+{\n+    *output = m_stringValue;\n+    return true;\n+}\n+\n+void StringValue::writeJSON(StringBuilder* output) const\n+{\n+    DCHECK(type() == TypeString);\n+    StringUtil::builderAppendQuotedString(*output, m_stringValue);\n+}\n+\n+std::unique_ptr<Value> StringValue::clone() const\n+{\n+    return StringValue::create(m_stringValue);\n+}\n+\n+bool SerializedValue::asSerialized(String* output) const\n+{\n+    *output = m_serializedValue;\n+    return true;\n+}\n+\n+void SerializedValue::writeJSON(StringBuilder* output) const\n+{\n+    DCHECK(type() == TypeSerialized);\n+    StringUtil::builderAppend(*output, m_serializedValue);\n+}\n+\n+std::unique_ptr<Value> SerializedValue::clone() const\n+{\n+    return SerializedValue::create(m_serializedValue);\n+}\n+\n+DictionaryValue::~DictionaryValue()\n+{\n+}\n+\n+void DictionaryValue::setBoolean(const String& name, bool value)\n+{\n+    setValue(name, FundamentalValue::create(value));\n+}\n+\n+void DictionaryValue::setInteger(const String& name, int value)\n+{\n+    setValue(name, FundamentalValue::create(value));\n+}\n+\n+void DictionaryValue::setDouble(const String& name, double value)\n+{\n+    setValue(name, FundamentalValue::create(value));\n+}\n+\n+void DictionaryValue::setString(const String& name, const String& value)\n+{\n+    setValue(name, StringValue::create(value));\n+}\n+\n+void DictionaryValue::setValue(const String& name, std::unique_ptr<Value> value)\n+{\n+    set(name, value);\n+}\n+\n+void DictionaryValue::setObject(const String& name, std::unique_ptr<DictionaryValue> value)\n+{\n+    set(name, value);\n+}\n+\n+void DictionaryValue::setArray(const String& name, std::unique_ptr<ListValue> value)\n+{\n+    set(name, value);\n+}\n+\n+bool DictionaryValue::getBoolean(const String& name, bool* output) const\n+{\n+    protocol::Value* value = get(name);\n+    if (!value)\n+        return false;\n+    return value->asBoolean(output);\n+}\n+\n+bool DictionaryValue::getInteger(const String& name, int* output) const\n+{\n+    Value* value = get(name);\n+    if (!value)\n+        return false;\n+    return value->asInteger(output);\n+}\n+\n+bool DictionaryValue::getDouble(const String& name, double* output) const\n+{\n+    Value* value = get(name);\n+    if (!value)\n+        return false;\n+    return value->asDouble(output);\n+}\n+\n+bool DictionaryValue::getString(const String& name, String* output) const\n+{\n+    protocol::Value* value = get(name);\n+    if (!value)\n+        return false;\n+    return value->asString(output);\n+}\n+\n+DictionaryValue* DictionaryValue::getObject(const String& name) const\n+{\n+    return DictionaryValue::cast(get(name));\n+}\n+\n+protocol::ListValue* DictionaryValue::getArray(const String& name) const\n+{\n+    return ListValue::cast(get(name));\n+}\n+\n+protocol::Value* DictionaryValue::get(const String& name) const\n+{\n+    Dictionary::const_iterator it = m_data.find(name);\n+    if (it == m_data.end())\n+        return nullptr;\n+    return it->second.get();\n+}\n+\n+DictionaryValue::Entry DictionaryValue::at(size_t index) const\n+{\n+    const String key = m_order[index];\n+    return std::make_pair(key, m_data.find(key)->second.get());\n+}\n+\n+bool DictionaryValue::booleanProperty(const String& name, bool defaultValue) const\n+{\n+    bool result = defaultValue;\n+    getBoolean(name, &result);\n+    return result;\n+}\n+\n+int DictionaryValue::integerProperty(const String& name, int defaultValue) const\n+{\n+    int result = defaultValue;\n+    getInteger(name, &result);\n+    return result;\n+}\n+\n+double DictionaryValue::doubleProperty(const String& name, double defaultValue) const\n+{\n+    double result = defaultValue;\n+    getDouble(name, &result);\n+    return result;\n+}\n+\n+void DictionaryValue::remove(const String& name)\n+{\n+    m_data.erase(name);\n+    m_order.erase(std::remove(m_order.begin(), m_order.end(), name), m_order.end());\n+}\n+\n+void DictionaryValue::writeJSON(StringBuilder* output) const\n+{\n+    StringUtil::builderAppend(*output, '{');\n+    for (size_t i = 0; i < m_order.size(); ++i) {\n+        Dictionary::const_iterator it = m_data.find(m_order[i]);\n+        CHECK(it != m_data.end());\n+        if (i)\n+            StringUtil::builderAppend(*output, ',');\n+        StringUtil::builderAppendQuotedString(*output, it->first);\n+        StringUtil::builderAppend(*output, ':');\n+        it->second->writeJSON(output);\n+    }\n+    StringUtil::builderAppend(*output, '}');\n+}\n+\n+std::unique_ptr<Value> DictionaryValue::clone() const\n+{\n+    std::unique_ptr<DictionaryValue> result = DictionaryValue::create();\n+    for (size_t i = 0; i < m_order.size(); ++i) {\n+        String key = m_order[i];\n+        Dictionary::const_iterator value = m_data.find(key);\n+        DCHECK(value != m_data.cend() && value->second);\n+        result->setValue(key, value->second->clone());\n+    }\n+    return std::move(result);\n+}\n+\n+DictionaryValue::DictionaryValue()\n+    : Value(TypeObject)\n+{\n+}\n+\n+ListValue::~ListValue()\n+{\n+}\n+\n+void ListValue::writeJSON(StringBuilder* output) const\n+{\n+    StringUtil::builderAppend(*output, '[');\n+    bool first = true;\n+    for (const std::unique_ptr<protocol::Value>& value : m_data) {\n+        if (!first)\n+            StringUtil::builderAppend(*output, ',');\n+        value->writeJSON(output);\n+        first = false;\n+    }\n+    StringUtil::builderAppend(*output, ']');\n+}\n+\n+std::unique_ptr<Value> ListValue::clone() const\n+{\n+    std::unique_ptr<ListValue> result = ListValue::create();\n+    for (const std::unique_ptr<protocol::Value>& value : m_data)\n+        result->pushValue(value->clone());\n+    return std::move(result);\n+}\n+\n+ListValue::ListValue()\n+    : Value(TypeArray)\n+{\n+}\n+\n+void ListValue::pushValue(std::unique_ptr<protocol::Value> value)\n+{\n+    DCHECK(value);\n+    m_data.push_back(std::move(value));\n+}\n+\n+protocol::Value* ListValue::at(size_t index)\n+{\n+    DCHECK_LT(index, m_data.size());\n+    return m_data[index].get();\n+}\n+\n+void escapeLatinStringForJSON(const uint8_t* str, unsigned len, StringBuilder* dst)\n+{\n+    escapeStringForJSONInternal<uint8_t>(str, len, dst);\n+}\n+\n+void escapeWideStringForJSON(const uint16_t* str, unsigned len, StringBuilder* dst)\n+{\n+    escapeStringForJSONInternal<uint16_t>(str, len, dst);\n+}\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}"
        },
        {
            "sha": "3638b34b4e7718fd2fe0a51377d10c983216cf8c",
            "filename": "tools/inspector_protocol/lib/Values_h.template",
            "status": "added",
            "additions": 249,
            "deletions": 0,
            "changes": 249,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FValues_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Flib%2FValues_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Flib%2FValues_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,249 @@\n+// Copyright 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_Values_h\n+#define {{\"_\".join(config.protocol.namespace)}}_Values_h\n+\n+//#include \"Allocator.h\"\n+//#include \"Collections.h\"\n+//#include \"Forward.h\"\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+\n+class ListValue;\n+class DictionaryValue;\n+class Value;\n+\n+class {{config.lib.export_macro}} Value : public Serializable {\n+    PROTOCOL_DISALLOW_COPY(Value);\n+public:\n+    virtual ~Value() override { }\n+\n+    static std::unique_ptr<Value> null()\n+    {\n+        return std::unique_ptr<Value>(new Value());\n+    }\n+\n+    enum ValueType {\n+        TypeNull = 0,\n+        TypeBoolean,\n+        TypeInteger,\n+        TypeDouble,\n+        TypeString,\n+        TypeObject,\n+        TypeArray,\n+        TypeSerialized\n+    };\n+\n+    ValueType type() const { return m_type; }\n+\n+    bool isNull() const { return m_type == TypeNull; }\n+\n+    virtual bool asBoolean(bool* output) const;\n+    virtual bool asDouble(double* output) const;\n+    virtual bool asInteger(int* output) const;\n+    virtual bool asString(String* output) const;\n+    virtual bool asSerialized(String* output) const;\n+\n+    virtual void writeJSON(StringBuilder* output) const;\n+    virtual std::unique_ptr<Value> clone() const;\n+    String serialize() override;\n+\n+protected:\n+    Value() : m_type(TypeNull) { }\n+    explicit Value(ValueType type) : m_type(type) { }\n+\n+private:\n+    friend class DictionaryValue;\n+    friend class ListValue;\n+\n+    ValueType m_type;\n+};\n+\n+class {{config.lib.export_macro}} FundamentalValue : public Value {\n+public:\n+    static std::unique_ptr<FundamentalValue> create(bool value)\n+    {\n+        return std::unique_ptr<FundamentalValue>(new FundamentalValue(value));\n+    }\n+\n+    static std::unique_ptr<FundamentalValue> create(int value)\n+    {\n+        return std::unique_ptr<FundamentalValue>(new FundamentalValue(value));\n+    }\n+\n+    static std::unique_ptr<FundamentalValue> create(double value)\n+    {\n+        return std::unique_ptr<FundamentalValue>(new FundamentalValue(value));\n+    }\n+\n+    bool asBoolean(bool* output) const override;\n+    bool asDouble(double* output) const override;\n+    bool asInteger(int* output) const override;\n+    void writeJSON(StringBuilder* output) const override;\n+    std::unique_ptr<Value> clone() const override;\n+\n+private:\n+    explicit FundamentalValue(bool value) : Value(TypeBoolean), m_boolValue(value) { }\n+    explicit FundamentalValue(int value) : Value(TypeInteger), m_integerValue(value) { }\n+    explicit FundamentalValue(double value) : Value(TypeDouble), m_doubleValue(value) { }\n+\n+    union {\n+        bool m_boolValue;\n+        double m_doubleValue;\n+        int m_integerValue;\n+    };\n+};\n+\n+class {{config.lib.export_macro}} StringValue : public Value {\n+public:\n+    static std::unique_ptr<StringValue> create(const String& value)\n+    {\n+        return std::unique_ptr<StringValue>(new StringValue(value));\n+    }\n+\n+    static std::unique_ptr<StringValue> create(const char* value)\n+    {\n+        return std::unique_ptr<StringValue>(new StringValue(value));\n+    }\n+\n+    bool asString(String* output) const override;\n+    void writeJSON(StringBuilder* output) const override;\n+    std::unique_ptr<Value> clone() const override;\n+\n+private:\n+    explicit StringValue(const String& value) : Value(TypeString), m_stringValue(value) { }\n+    explicit StringValue(const char* value) : Value(TypeString), m_stringValue(value) { }\n+\n+    String m_stringValue;\n+};\n+\n+class {{config.lib.export_macro}} SerializedValue : public Value {\n+public:\n+    static std::unique_ptr<SerializedValue> create(const String& value)\n+    {\n+        return std::unique_ptr<SerializedValue>(new SerializedValue(value));\n+    }\n+\n+    bool asSerialized(String* output) const override;\n+    void writeJSON(StringBuilder* output) const override;\n+    std::unique_ptr<Value> clone() const override;\n+\n+private:\n+    explicit SerializedValue(const String& value) : Value(TypeSerialized), m_serializedValue(value) { }\n+\n+    String m_serializedValue;\n+};\n+\n+class {{config.lib.export_macro}} DictionaryValue : public Value {\n+public:\n+    using Entry = std::pair<String, Value*>;\n+    static std::unique_ptr<DictionaryValue> create()\n+    {\n+        return std::unique_ptr<DictionaryValue>(new DictionaryValue());\n+    }\n+\n+    static DictionaryValue* cast(Value* value)\n+    {\n+        if (!value || value->type() != TypeObject)\n+            return nullptr;\n+        return static_cast<DictionaryValue*>(value);\n+    }\n+\n+    static std::unique_ptr<DictionaryValue> cast(std::unique_ptr<Value> value)\n+    {\n+        return std::unique_ptr<DictionaryValue>(DictionaryValue::cast(value.release()));\n+    }\n+\n+    void writeJSON(StringBuilder* output) const override;\n+    std::unique_ptr<Value> clone() const override;\n+\n+    size_t size() const { return m_data.size(); }\n+\n+    void setBoolean(const String& name, bool);\n+    void setInteger(const String& name, int);\n+    void setDouble(const String& name, double);\n+    void setString(const String& name, const String&);\n+    void setValue(const String& name, std::unique_ptr<Value>);\n+    void setObject(const String& name, std::unique_ptr<DictionaryValue>);\n+    void setArray(const String& name, std::unique_ptr<ListValue>);\n+\n+    bool getBoolean(const String& name, bool* output) const;\n+    bool getInteger(const String& name, int* output) const;\n+    bool getDouble(const String& name, double* output) const;\n+    bool getString(const String& name, String* output) const;\n+\n+    DictionaryValue* getObject(const String& name) const;\n+    ListValue* getArray(const String& name) const;\n+    Value* get(const String& name) const;\n+    Entry at(size_t index) const;\n+\n+    bool booleanProperty(const String& name, bool defaultValue) const;\n+    int integerProperty(const String& name, int defaultValue) const;\n+    double doubleProperty(const String& name, double defaultValue) const;\n+    void remove(const String& name);\n+\n+    ~DictionaryValue() override;\n+\n+private:\n+    DictionaryValue();\n+    template<typename T>\n+    void set(const String& key, std::unique_ptr<T>& value)\n+    {\n+        DCHECK(value);\n+        bool isNew = m_data.find(key) == m_data.end();\n+        m_data[key] = std::move(value);\n+        if (isNew)\n+            m_order.push_back(key);\n+    }\n+\n+    using Dictionary = protocol::HashMap<String, std::unique_ptr<Value>>;\n+    Dictionary m_data;\n+    std::vector<String> m_order;\n+};\n+\n+class {{config.lib.export_macro}} ListValue : public Value {\n+public:\n+    static std::unique_ptr<ListValue> create()\n+    {\n+        return std::unique_ptr<ListValue>(new ListValue());\n+    }\n+\n+    static ListValue* cast(Value* value)\n+    {\n+        if (!value || value->type() != TypeArray)\n+            return nullptr;\n+        return static_cast<ListValue*>(value);\n+    }\n+\n+    static std::unique_ptr<ListValue> cast(std::unique_ptr<Value> value)\n+    {\n+        return std::unique_ptr<ListValue>(ListValue::cast(value.release()));\n+    }\n+\n+    ~ListValue() override;\n+\n+    void writeJSON(StringBuilder* output) const override;\n+    std::unique_ptr<Value> clone() const override;\n+\n+    void pushValue(std::unique_ptr<Value>);\n+\n+    Value* at(size_t index);\n+    size_t size() const { return m_data.size(); }\n+\n+private:\n+    ListValue();\n+    std::vector<std::unique_ptr<Value>> m_data;\n+};\n+\n+void escapeLatinStringForJSON(const uint8_t* str, unsigned len, StringBuilder* dst);\n+void escapeWideStringForJSON(const uint16_t* str, unsigned len, StringBuilder* dst);\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // {{\"_\".join(config.protocol.namespace)}}_Values_h"
        },
        {
            "sha": "3d36ecffae3ca3db733b807661222a067a0801c7",
            "filename": "tools/inspector_protocol/templates/Exported_h.template",
            "status": "added",
            "additions": 65,
            "deletions": 0,
            "changes": 65,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Ftemplates%2FExported_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Ftemplates%2FExported_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Ftemplates%2FExported_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,65 @@\n+// This file is generated\n+\n+// Copyright (c) 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_{{domain.domain}}_api_h\n+#define {{\"_\".join(config.protocol.namespace)}}_{{domain.domain}}_api_h\n+\n+{% if config.exported.export_header %}\n+#include {{format_include(config.exported.export_header)}}\n+{% endif %}\n+#include {{format_include(config.exported.string_header)}}\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+namespace {{domain.domain}} {\n+namespace API {\n+\n+// ------------- Enums.\n+  {% for type in domain.types %}\n+    {% if (\"enum\" in type) and protocol.is_exported(domain.domain, type.id) %}\n+\n+namespace {{type.id}}Enum {\n+      {% for literal in type.enum %}\n+{{config.exported.export_macro}} extern const char* {{ literal | dash_to_camelcase}};\n+      {% endfor %}\n+} // {{type.id}}Enum\n+    {% endif %}\n+  {% endfor %}\n+  {% for command in join_arrays(domain, [\"commands\", \"events\"]) %}\n+    {% for param in join_arrays(command, [\"parameters\", \"returns\"]) %}\n+      {% if (\"enum\" in param) and protocol.is_exported(domain.domain, command.name + \".\" + param.name) %}\n+\n+namespace {{command.name | to_title_case}} {\n+namespace {{param.name | to_title_case}}Enum {\n+        {% for literal in param.enum %}\n+{{config.exported.export_macro}} extern const char* {{ literal | dash_to_camelcase}};\n+        {% endfor %}\n+} // {{param.name | to_title_case}}Enum\n+} // {{command.name | to_title_case }}\n+      {% endif %}\n+    {% endfor %}\n+  {% endfor %}\n+\n+// ------------- Types.\n+  {% for type in domain.types %}\n+    {% if not (type.type == \"object\") or not (\"properties\" in type) or not protocol.is_exported(domain.domain, type.id) %}{% continue %}{% endif %}\n+\n+class {{config.exported.export_macro}} {{type.id}} {\n+public:\n+    virtual {{config.exported.string_out}} toJSONString() const = 0;\n+    virtual ~{{type.id}}() { }\n+    static std::unique_ptr<protocol::{{domain.domain}}::API::{{type.id}}> fromJSONString(const {{config.exported.string_in}}& json);\n+};\n+  {% endfor %}\n+\n+} // namespace API\n+} // namespace {{domain.domain}}\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_{{domain.domain}}_api_h)"
        },
        {
            "sha": "4c9d24bd5fccf77037a793410a3e9013979528d0",
            "filename": "tools/inspector_protocol/templates/Imported_h.template",
            "status": "added",
            "additions": 55,
            "deletions": 0,
            "changes": 55,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Ftemplates%2FImported_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Ftemplates%2FImported_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Ftemplates%2FImported_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,55 @@\n+// This file is generated\n+\n+// Copyright (c) 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_{{domain.domain}}_imported_h\n+#define {{\"_\".join(config.protocol.namespace)}}_{{domain.domain}}_imported_h\n+\n+#include {{format_include(config.protocol.package, \"Protocol\")}}\n+{% if config.imported.header %}\n+#include {{format_include(config.imported.header)}}\n+{% else %}\n+#include {{format_include(config.imported.package, domain.domain)}}\n+{% endif %}\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+  {% for type in domain.types %}\n+    {% if not (type.type == \"object\") or not (\"properties\" in type) or not protocol.is_imported(domain.domain, type.id) %}{% continue %}{% endif %}\n+\n+template<>\n+struct ValueConversions<{{\"::\".join(config.imported.namespace)}}::{{domain.domain}}::API::{{type.id}}> {\n+    static std::unique_ptr<{{\"::\".join(config.imported.namespace)}}::{{domain.domain}}::API::{{type.id}}> fromValue(protocol::Value* value, ErrorSupport* errors)\n+    {\n+        if (!value) {\n+            errors->addError(\"value expected\");\n+            return nullptr;\n+        }\n+        String json = value->serialize();\n+        auto result = {{\"::\".join(config.imported.namespace)}}::{{domain.domain}}::API::{{type.id}}::fromJSONString({{config.imported.to_imported_string % \"json\"}});\n+        if (!result)\n+            errors->addError(\"cannot parse\");\n+        return result;\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(const {{\"::\".join(config.imported.namespace)}}::{{domain.domain}}::API::{{type.id}}* value)\n+    {\n+        auto json = value->toJSONString();\n+        return SerializedValue::create({{config.imported.from_imported_string % \"std::move(json)\"}});\n+    }\n+\n+    static std::unique_ptr<protocol::Value> toValue(const std::unique_ptr<{{\"::\".join(config.imported.namespace)}}::{{domain.domain}}::API::{{type.id}}>& value)\n+    {\n+        return toValue(value.get());\n+    }\n+};\n+  {% endfor %}\n+\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_{{domain.domain}}_imported_h)"
        },
        {
            "sha": "026c1cdb8da9e1966790d588f625d8547e46d622",
            "filename": "tools/inspector_protocol/templates/TypeBuilder_cpp.template",
            "status": "added",
            "additions": 397,
            "deletions": 0,
            "changes": 397,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Ftemplates%2FTypeBuilder_cpp.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Ftemplates%2FTypeBuilder_cpp.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Ftemplates%2FTypeBuilder_cpp.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,397 @@\n+// This file is generated\n+\n+// Copyright (c) 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#include {{format_include(config.protocol.package, domain.domain)}}\n+\n+#include {{format_include(config.protocol.package, \"Protocol\")}}\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+namespace {{domain.domain}} {\n+\n+// ------------- Enum values from types.\n+\n+const char Metainfo::domainName[] = \"{{domain.domain}}\";\n+const char Metainfo::commandPrefix[] = \"{{domain.domain}}.\";\n+const char Metainfo::version[] = \"{{domain.version}}\";\n+  {% for type in domain.types %}\n+    {% if not protocol.generate_type(domain.domain, type.id) %}{% continue %} {% endif %}\n+    {% if \"enum\" in type %}\n+\n+namespace {{type.id}}Enum {\n+      {% for literal in type.enum %}\n+const char* {{ literal | dash_to_camelcase}} = \"{{literal}}\";\n+      {% endfor %}\n+} // namespace {{type.id}}Enum\n+      {% if protocol.is_exported(domain.domain, type.id) %}\n+\n+namespace API {\n+namespace {{type.id}}Enum {\n+        {% for literal in type.enum %}\n+const char* {{ literal | dash_to_camelcase}} = \"{{literal}}\";\n+        {% endfor %}\n+} // namespace {{type.id}}Enum\n+} // namespace API\n+      {% endif %}\n+    {% endif %}\n+    {% for property in type.properties %}\n+      {% if \"enum\" in property %}\n+\n+        {% for literal in property.enum %}\n+const char* {{type.id}}::{{property.name | to_title_case}}Enum::{{literal | dash_to_camelcase}} = \"{{literal}}\";\n+        {% endfor %}\n+      {% endif %}\n+    {% endfor %}\n+    {% if not (type.type == \"object\") or not (\"properties\" in type) %}{% continue %}{% endif %}\n+\n+std::unique_ptr<{{type.id}}> {{type.id}}::fromValue(protocol::Value* value, ErrorSupport* errors)\n+{\n+    if (!value || value->type() != protocol::Value::TypeObject) {\n+        errors->addError(\"object expected\");\n+        return nullptr;\n+    }\n+\n+    std::unique_ptr<{{type.id}}> result(new {{type.id}}());\n+    protocol::DictionaryValue* object = DictionaryValue::cast(value);\n+    errors->push();\n+    {% for property in type.properties %}\n+    protocol::Value* {{property.name}}Value = object->get(\"{{property.name}}\");\n+      {% if property.optional %}\n+    if ({{property.name}}Value) {\n+        errors->setName(\"{{property.name}}\");\n+        result->m_{{property.name}} = ValueConversions<{{protocol.resolve_type(property).raw_type}}>::fromValue({{property.name}}Value, errors);\n+    }\n+      {% else %}\n+    errors->setName(\"{{property.name}}\");\n+    result->m_{{property.name}} = ValueConversions<{{protocol.resolve_type(property).raw_type}}>::fromValue({{property.name}}Value, errors);\n+      {% endif %}\n+    {% endfor %}\n+    errors->pop();\n+    if (errors->hasErrors())\n+        return nullptr;\n+    return result;\n+}\n+\n+std::unique_ptr<protocol::DictionaryValue> {{type.id}}::toValue() const\n+{\n+    std::unique_ptr<protocol::DictionaryValue> result = DictionaryValue::create();\n+    {% for property in type.properties %}\n+      {% set property_type = protocol.resolve_type(property) %}\n+      {% set property_field = \"m_\" + property.name %}\n+      {% if property.optional %}\n+    if ({{property_field}}.isJust())\n+        result->setValue(\"{{property.name}}\", ValueConversions<{{property_type.raw_type}}>::toValue({{property_field}}.fromJust()));\n+      {% else %}\n+    result->setValue(\"{{property.name}}\", ValueConversions<{{property_type.raw_type}}>::toValue({{property_type.to_raw_type % property_field}}));\n+      {% endif %}\n+    {% endfor %}\n+    return result;\n+}\n+\n+std::unique_ptr<{{type.id}}> {{type.id}}::clone() const\n+{\n+    ErrorSupport errors;\n+    return fromValue(toValue().get(), &errors);\n+}\n+    {% if protocol.is_exported(domain.domain, type.id) %}\n+\n+{{config.exported.string_out}} {{type.id}}::toJSONString() const\n+{\n+    String json = toValue()->serialize();\n+    return {{config.exported.to_string_out % \"json\"}};\n+}\n+\n+// static\n+std::unique_ptr<API::{{type.id}}> API::{{type.id}}::fromJSONString(const {{config.exported.string_in}}& json)\n+{\n+    ErrorSupport errors;\n+    std::unique_ptr<Value> value = StringUtil::parseJSON(json);\n+    if (!value)\n+        return nullptr;\n+    return protocol::{{domain.domain}}::{{type.id}}::fromValue(value.get(), &errors);\n+}\n+    {% endif %}\n+  {% endfor %}\n+\n+// ------------- Enum values from params.\n+\n+  {% for command in join_arrays(domain, [\"commands\", \"events\"]) %}\n+    {% for param in join_arrays(command, [\"parameters\", \"returns\"]) %}\n+      {% if \"enum\" in param %}\n+\n+namespace {{command.name | to_title_case}} {\n+namespace {{param.name | to_title_case}}Enum {\n+        {% for literal in param.enum %}\n+const char* {{ literal | to_title_case}} = \"{{literal}}\";\n+        {% endfor %}\n+} // namespace {{param.name | to_title_case}}Enum\n+} // namespace {{command.name | to_title_case }}\n+        {% if protocol.is_exported(domain.domain, command.name + \".\" + param.name) %}\n+\n+namespace API {\n+namespace {{command.name | to_title_case}} {\n+namespace {{param.name | to_title_case}}Enum {\n+        {% for literal in param.enum %}\n+const char* {{ literal | to_title_case}} = \"{{literal}}\";\n+        {% endfor %}\n+} // namespace {{param.name | to_title_case}}Enum\n+} // namespace {{command.name | to_title_case }}\n+} // namespace API\n+        {% endif %}\n+      {% endif %}\n+    {% endfor %}\n+  {% endfor %}\n+\n+// ------------- Frontend notifications.\n+  {% for event in domain.events %}\n+    {% if not protocol.generate_event(domain.domain, event.name) %}{% continue %}{% endif %}\n+\n+void Frontend::{{event.name | to_method_case}}(\n+    {%- for parameter in event.parameters %}\n+      {% if \"optional\" in parameter -%}\n+        Maybe<{{protocol.resolve_type(parameter).raw_type}}>\n+      {%- else -%}\n+        {{protocol.resolve_type(parameter).pass_type}}\n+      {%- endif %} {{parameter.name}}{%- if not loop.last -%}, {% endif -%}\n+    {% endfor -%})\n+{\n+    if (!m_frontendChannel)\n+        return;\n+      {% if event.parameters %}\n+    std::unique_ptr<{{event.name | to_title_case}}Notification> messageData = {{event.name | to_title_case}}Notification::{{\"create\" | to_method_case}}()\n+        {% for parameter in event.parameters %}\n+          {% if not \"optional\" in parameter %}\n+        .{{\"set\" | to_method_case}}{{parameter.name | to_title_case}}({{protocol.resolve_type(parameter).to_pass_type % parameter.name}})\n+          {% endif %}\n+        {% endfor %}\n+        .{{ \"build\" | to_method_case }}();\n+        {% for parameter in event.parameters %}\n+          {% if \"optional\" in parameter %}\n+    if ({{parameter.name}}.isJust())\n+        messageData->{{\"set\" | to_method_case}}{{parameter.name | to_title_case}}(std::move({{parameter.name}}).takeJust());\n+          {% endif %}\n+        {% endfor %}\n+    m_frontendChannel->sendProtocolNotification(InternalResponse::createNotification(\"{{domain.domain}}.{{event.name}}\", std::move(messageData)));\n+      {% else %}\n+    m_frontendChannel->sendProtocolNotification(InternalResponse::createNotification(\"{{domain.domain}}.{{event.name}}\"));\n+      {% endif %}\n+}\n+  {% endfor %}\n+\n+void Frontend::flush()\n+{\n+    m_frontendChannel->flushProtocolNotifications();\n+}\n+\n+void Frontend::sendRawNotification(const String& notification)\n+{\n+    m_frontendChannel->sendProtocolNotification(InternalRawNotification::create(notification));\n+}\n+\n+// --------------------- Dispatcher.\n+\n+class DispatcherImpl : public protocol::DispatcherBase {\n+public:\n+    DispatcherImpl(FrontendChannel* frontendChannel, Backend* backend, bool fallThroughForNotFound)\n+        : DispatcherBase(frontendChannel)\n+        , m_backend(backend)\n+        , m_fallThroughForNotFound(fallThroughForNotFound) {\n+  {% for command in domain.commands %}\n+    {% if \"redirect\" in command %}\n+      m_redirects[\"{{domain.domain}}.{{command.name}}\"] = \"{{command.redirect}}.{{command.name}}\";\n+      {% continue %}\n+    {% endif %}\n+    {% if not protocol.generate_command(domain.domain, command.name) %}{% continue %}{% endif %}\n+        m_dispatchMap[\"{{domain.domain}}.{{command.name}}\"] = &DispatcherImpl::{{command.name}};\n+  {% endfor %}\n+    }\n+    ~DispatcherImpl() override { }\n+    DispatchResponse::Status dispatch(int callId, const String& method, std::unique_ptr<protocol::DictionaryValue> messageObject) override;\n+    HashMap<String, String>& redirects() { return m_redirects; }\n+\n+protected:\n+    using CallHandler = DispatchResponse::Status (DispatcherImpl::*)(int callId, std::unique_ptr<DictionaryValue> messageObject, ErrorSupport* errors);\n+    using DispatchMap = protocol::HashMap<String, CallHandler>;\n+    DispatchMap m_dispatchMap;\n+    HashMap<String, String> m_redirects;\n+\n+  {% for command in domain.commands %}\n+    {% if \"redirect\" in command %}{% continue %}{% endif %}\n+    {% if not protocol.generate_command(domain.domain, command.name) %}{% continue %}{% endif %}\n+    DispatchResponse::Status {{command.name}}(int callId, std::unique_ptr<DictionaryValue> requestMessageObject, ErrorSupport*);\n+  {% endfor %}\n+\n+    Backend* m_backend;\n+    bool m_fallThroughForNotFound;\n+};\n+\n+DispatchResponse::Status DispatcherImpl::dispatch(int callId, const String& method, std::unique_ptr<protocol::DictionaryValue> messageObject)\n+{\n+    protocol::HashMap<String, CallHandler>::iterator it = m_dispatchMap.find(method);\n+    if (it == m_dispatchMap.end()) {\n+        if (m_fallThroughForNotFound)\n+            return DispatchResponse::kFallThrough;\n+        reportProtocolError(callId, DispatchResponse::kMethodNotFound, \"'\" + method + \"' wasn't found\", nullptr);\n+        return DispatchResponse::kError;\n+    }\n+\n+    protocol::ErrorSupport errors;\n+    return (this->*(it->second))(callId, std::move(messageObject), &errors);\n+}\n+\n+  {% for command in domain.commands %}\n+    {% set command_name_title = command.name | to_title_case %}\n+    {% if \"redirect\" in command %}{% continue %}{% endif %}\n+    {% if not protocol.generate_command(domain.domain, command.name) %}{% continue %}{% endif %}\n+    {% if protocol.is_async_command(domain.domain, command.name) %}\n+\n+class {{command_name_title}}CallbackImpl : public Backend::{{command_name_title}}Callback, public DispatcherBase::Callback {\n+public:\n+    {{command_name_title}}CallbackImpl(std::unique_ptr<DispatcherBase::WeakPtr> backendImpl, int callId, int callbackId)\n+        : DispatcherBase::Callback(std::move(backendImpl), callId, callbackId) { }\n+\n+    void sendSuccess(\n+      {%- for parameter in command.returns -%}\n+        {%- if \"optional\" in parameter -%}\n+        Maybe<{{protocol.resolve_type(parameter).raw_type}}> {{parameter.name}}\n+        {%- else -%}\n+        {{protocol.resolve_type(parameter).pass_type}} {{parameter.name}}\n+        {%- endif -%}\n+        {%- if not loop.last -%}, {% endif -%}\n+      {%- endfor -%}) override\n+    {\n+        std::unique_ptr<protocol::DictionaryValue> resultObject = DictionaryValue::create();\n+          {% for parameter in command.returns %}\n+            {% if \"optional\" in parameter %}\n+        if ({{parameter.name}}.isJust())\n+            resultObject->setValue(\"{{parameter.name}}\", ValueConversions<{{protocol.resolve_type(parameter).raw_type}}>::toValue({{parameter.name}}.fromJust()));\n+           {% else %}\n+        resultObject->setValue(\"{{parameter.name}}\", ValueConversions<{{protocol.resolve_type(parameter).raw_type}}>::toValue({{protocol.resolve_type(parameter).to_raw_type % parameter.name}}));\n+            {% endif %}\n+          {% endfor %}\n+        sendIfActive(std::move(resultObject), DispatchResponse::OK());\n+    }\n+\n+    void fallThrough() override\n+    {\n+        fallThroughIfActive();\n+    }\n+\n+    void sendFailure(const DispatchResponse& response) override\n+    {\n+        DCHECK(response.status() == DispatchResponse::kError);\n+        sendIfActive(nullptr, response);\n+    }\n+};\n+    {% endif %}\n+\n+DispatchResponse::Status DispatcherImpl::{{command.name}}(int callId, std::unique_ptr<DictionaryValue> requestMessageObject, ErrorSupport* errors)\n+{\n+    {% if \"parameters\" in command %}\n+    // Prepare input parameters.\n+    protocol::DictionaryValue* object = DictionaryValue::cast(requestMessageObject->get(\"params\"));\n+    errors->push();\n+      {% for parameter in command.parameters %}\n+        {% set parameter_type = protocol.resolve_type(parameter) %}\n+    protocol::Value* {{parameter.name}}Value = object ? object->get(\"{{parameter.name}}\") : nullptr;\n+        {% if parameter.optional %}\n+    Maybe<{{parameter_type.raw_type}}> in_{{parameter.name}};\n+    if ({{parameter.name}}Value) {\n+        errors->setName(\"{{parameter.name}}\");\n+        in_{{parameter.name}} = ValueConversions<{{parameter_type.raw_type}}>::fromValue({{parameter.name}}Value, errors);\n+    }\n+        {% else %}\n+    errors->setName(\"{{parameter.name}}\");\n+    {{parameter_type.type}} in_{{parameter.name}} = ValueConversions<{{parameter_type.raw_type}}>::fromValue({{parameter.name}}Value, errors);\n+        {% endif %}\n+      {% endfor %}\n+    errors->pop();\n+    if (errors->hasErrors()) {\n+        reportProtocolError(callId, DispatchResponse::kInvalidParams, kInvalidParamsString, errors);\n+        return DispatchResponse::kError;\n+    }\n+    {% endif %}\n+    {% if \"returns\" in command and not protocol.is_async_command(domain.domain, command.name) %}\n+    // Declare output parameters.\n+      {% for parameter in command.returns %}\n+        {% if \"optional\" in parameter %}\n+    Maybe<{{protocol.resolve_type(parameter).raw_type}}> out_{{parameter.name}};\n+        {% else %}\n+    {{protocol.resolve_type(parameter).type}} out_{{parameter.name}};\n+        {% endif %}\n+      {% endfor %}\n+    {% endif %}\n+\n+    {% if not protocol.is_async_command(domain.domain, command.name) %}\n+    std::unique_ptr<DispatcherBase::WeakPtr> weak = weakPtr();\n+    DispatchResponse response = m_backend->{{command.name | to_method_case}}(\n+      {%- for parameter in command.parameters -%}\n+        {%- if not loop.first -%}, {% endif -%}\n+        {%- if \"optional\" in parameter -%}\n+        std::move(in_{{parameter.name}})\n+        {%- else -%}\n+        {{protocol.resolve_type(parameter).to_pass_type % (\"in_\" + parameter.name)}}\n+        {%- endif -%}\n+      {%- endfor %}\n+      {%- if \"returns\" in command %}\n+        {%- for parameter in command.returns -%}\n+          {%- if not loop.first or command.parameters -%}, {% endif -%}\n+          &out_{{parameter.name}}\n+        {%- endfor %}\n+      {% endif %});\n+    if (response.status() == DispatchResponse::kFallThrough)\n+        return response.status();\n+      {% if \"returns\" in command %}\n+    std::unique_ptr<protocol::DictionaryValue> result = DictionaryValue::create();\n+    if (response.status() == DispatchResponse::kSuccess) {\n+        {% for parameter in command.returns %}\n+          {% if \"optional\" in parameter %}\n+        if (out_{{parameter.name}}.isJust())\n+            result->setValue(\"{{parameter.name}}\", ValueConversions<{{protocol.resolve_type(parameter).raw_type}}>::toValue(out_{{parameter.name}}.fromJust()));\n+          {% else %}\n+        result->setValue(\"{{parameter.name}}\", ValueConversions<{{protocol.resolve_type(parameter).raw_type}}>::toValue({{protocol.resolve_type(parameter).to_raw_type % (\"out_\" + parameter.name)}}));\n+          {% endif %}\n+        {% endfor %}\n+    }\n+    if (weak->get())\n+        weak->get()->sendResponse(callId, response, std::move(result));\n+      {% else %}\n+    if (weak->get())\n+        weak->get()->sendResponse(callId, response);\n+      {% endif %}\n+    return response.status();\n+    {% else %}\n+    std::unique_ptr<DispatcherBase::WeakPtr> weak = weakPtr();\n+    std::unique_ptr<{{command_name_title}}CallbackImpl> callback(new {{command.name | to_title_case}}CallbackImpl(weakPtr(), callId, nextCallbackId()));\n+    m_backend->{{command.name | to_method_case}}(\n+      {%- for property in command.parameters -%}\n+        {%- if not loop.first -%}, {% endif -%}\n+        {%- if \"optional\" in property -%}\n+        std::move(in_{{property.name}})\n+        {%- else -%}\n+        {{protocol.resolve_type(property).to_pass_type % (\"in_\" + property.name)}}\n+        {%- endif -%}\n+      {%- endfor -%}\n+        {%- if command.parameters -%}, {% endif -%}\n+        std::move(callback));\n+    return (weak->get() && weak->get()->lastCallbackFallThrough()) ? DispatchResponse::kFallThrough : DispatchResponse::kAsync;\n+    {% endif %}\n+}\n+  {% endfor %}\n+\n+// static\n+void Dispatcher::wire(UberDispatcher* uber, Backend* backend)\n+{\n+    std::unique_ptr<DispatcherImpl> dispatcher(new DispatcherImpl(uber->channel(), backend, uber->fallThroughForNotFound()));\n+    uber->setupRedirects(dispatcher->redirects());\n+    uber->registerBackend(\"{{domain.domain}}\", std::move(dispatcher));\n+}\n+\n+} // {{domain.domain}}\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}"
        },
        {
            "sha": "744d496026a279a853fac7b3eb6b4312588bc824",
            "filename": "tools/inspector_protocol/templates/TypeBuilder_h.template",
            "status": "added",
            "additions": 301,
            "deletions": 0,
            "changes": 301,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Ftemplates%2FTypeBuilder_h.template",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Finspector_protocol%2Ftemplates%2FTypeBuilder_h.template",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Finspector_protocol%2Ftemplates%2FTypeBuilder_h.template?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,301 @@\n+// This file is generated\n+\n+// Copyright (c) 2016 The Chromium Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifndef {{\"_\".join(config.protocol.namespace)}}_{{domain.domain}}_h\n+#define {{\"_\".join(config.protocol.namespace)}}_{{domain.domain}}_h\n+\n+{% if config.protocol.export_header %}\n+#include {{format_include(config.protocol.export_header)}}\n+{% endif %}\n+#include {{format_include(config.protocol.package, \"Protocol\")}}\n+// For each imported domain we generate a ValueConversions struct instead of a full domain definition\n+// and include Domain::API version from there.\n+{% for name in domain.dependencies %}\n+  {% if protocol.is_imported_dependency(name) %}\n+#include {{format_include(config.protocol.package, name)}}\n+  {% endif %}\n+{% endfor %}\n+{% if protocol.is_exported_domain(domain.domain) %}\n+#include {{format_include(config.exported.package, domain.domain)}}\n+{% endif %}\n+\n+{% for namespace in config.protocol.namespace %}\n+namespace {{namespace}} {\n+{% endfor %}\n+namespace {{domain.domain}} {\n+\n+// ------------- Forward and enum declarations.\n+  {% for type in domain.types %}\n+    {% if not protocol.generate_type(domain.domain, type.id) %}{% continue %}{% endif %}\n+    {% if type.type == \"object\" %}\n+      {% if \"properties\" in type %}\n+class {{type.id}};\n+      {% else %}\n+using {{type.id}} = Object;\n+      {% endif %}\n+    {% elif type.type != \"array\" %}\n+using {{type.id}} = {{protocol.resolve_type(type).type}};\n+    {% endif %}\n+  {% endfor %}\n+  {% for type in domain.types %}\n+    {% if not protocol.generate_type(domain.domain, type.id) %}{% continue %}{% endif %}\n+    {% if \"enum\" in type %}\n+\n+namespace {{type.id}}Enum {\n+      {% for literal in type.enum %}\n+{{config.protocol.export_macro}} extern const char* {{ literal | dash_to_camelcase}};\n+      {% endfor %}\n+} // namespace {{type.id}}Enum\n+    {% endif %}\n+  {% endfor %}\n+  {% for command in join_arrays(domain, [\"commands\", \"events\"]) %}\n+    {% for param in join_arrays(command, [\"parameters\", \"returns\"]) %}\n+      {% if \"enum\" in param %}\n+\n+namespace {{command.name | to_title_case}} {\n+namespace {{param.name | to_title_case}}Enum {\n+        {% for literal in param.enum %}\n+{{config.protocol.export_macro}} extern const char* {{literal | dash_to_camelcase}};\n+        {% endfor %}\n+} // {{param.name | to_title_case}}Enum\n+} // {{command.name | to_title_case }}\n+      {% endif %}\n+    {% endfor %}\n+  {% endfor %}\n+\n+// ------------- Type and builder declarations.\n+  {% for type in domain.types %}\n+    {% if not protocol.generate_type(domain.domain, type.id) %}{% continue %}{% endif %}\n+    {% if not (type.type == \"object\") or not (\"properties\" in type) %}{% continue %}{% endif %}\n+\n+class {{config.protocol.export_macro}} {{type.id}} : public Serializable{% if protocol.is_exported(domain.domain, type.id) %}, public API::{{type.id}}{% endif %}{\n+    PROTOCOL_DISALLOW_COPY({{type.id}});\n+public:\n+    static std::unique_ptr<{{type.id}}> fromValue(protocol::Value* value, ErrorSupport* errors);\n+\n+    ~{{type.id}}() override { }\n+    {% for property in type.properties %}\n+      {% set property_type = protocol.resolve_type(property) %}\n+      {% set property_name = property.name | to_title_case %}\n+      {% set property_field = \"m_\" + property.name %}\n+      {% if \"enum\" in property %}\n+\n+    struct {{config.protocol.export_macro}} {{property_name}}Enum {\n+        {% for literal in property.enum %}\n+        static const char* {{literal | dash_to_camelcase}};\n+        {% endfor %}\n+    }; // {{property_name}}Enum\n+      {% endif %}\n+\n+      {% if property.optional %}\n+    bool {{\"has\" | to_method_case}}{{property_name}}() { return {{property_field}}.isJust(); }\n+    {{property_type.raw_return_type}} {{\"get\" | to_method_case}}{{property_name}}({{property_type.raw_pass_type}} defaultValue) { return {{property_field}}.isJust() ? {{property_field}}.fromJust() : defaultValue; }\n+      {% else %}\n+    {{property_type.raw_return_type}} {{\"get\" | to_method_case}}{{property_name}}() { return {{property_type.to_raw_type % property_field}}; }\n+      {% endif %}\n+    void {{\"set\" | to_method_case}}{{property_name}}({{property_type.pass_type}} value) { {{property_field}} = {{property_type.to_rvalue % \"value\"}}; }\n+    {% endfor %}\n+\n+    std::unique_ptr<protocol::DictionaryValue> toValue() const;\n+    String serialize() override { return toValue()->serialize(); }\n+    std::unique_ptr<{{type.id}}> clone() const;\n+    {% if protocol.is_exported(domain.domain, type.id) %}\n+    {{config.exported.string_out}} toJSONString() const override;\n+    {% endif %}\n+\n+    template<int STATE>\n+    class {{type.id}}Builder {\n+    public:\n+        enum {\n+            NoFieldsSet = 0,\n+    {% for property in type.properties|rejectattr(\"optional\") %}\n+            {{property.name | to_title_case}}Set = 1 << {{loop.index}},\n+    {% endfor %}\n+            AllFieldsSet = (\n+    {%- for property in type.properties %}\n+      {% if not(property.optional) %}{{property.name | to_title_case}}Set | {%endif %}\n+    {% endfor %}0)};\n+\n+    {% for property in type.properties %}\n+      {% set property_type = protocol.resolve_type(property) %}\n+      {% set property_name = property.name | to_title_case %}\n+\n+      {% if property.optional %}\n+        {{type.id}}Builder<STATE>& {{\"set\" | to_method_case}}{{property_name}}({{property_type.pass_type}} value)\n+        {\n+            m_result->{{\"set\" | to_method_case}}{{property_name}}({{property_type.to_rvalue % \"value\"}});\n+            return *this;\n+        }\n+      {% else %}\n+        {{type.id}}Builder<STATE | {{property_name}}Set>& {{\"set\" | to_method_case}}{{property_name}}({{property_type.pass_type}} value)\n+        {\n+            static_assert(!(STATE & {{property_name}}Set), \"property {{property.name}} should not be set yet\");\n+            m_result->{{\"set\" | to_method_case}}{{property_name}}({{property_type.to_rvalue % \"value\"}});\n+            return castState<{{property_name}}Set>();\n+        }\n+      {% endif %}\n+    {% endfor %}\n+\n+        std::unique_ptr<{{type.id}}> {{\"build\" | to_method_case}}()\n+        {\n+            static_assert(STATE == AllFieldsSet, \"state should be AllFieldsSet\");\n+            return std::move(m_result);\n+        }\n+\n+    private:\n+        friend class {{type.id}};\n+        {{type.id}}Builder() : m_result(new {{type.id}}()) { }\n+\n+        template<int STEP> {{type.id}}Builder<STATE | STEP>& castState()\n+        {\n+            return *reinterpret_cast<{{type.id}}Builder<STATE | STEP>*>(this);\n+        }\n+\n+        {{protocol.type_definition(domain.domain + \".\" + type.id).type}} m_result;\n+    };\n+\n+    static {{type.id}}Builder<0> {{\"create\" | to_method_case}}()\n+    {\n+        return {{type.id}}Builder<0>();\n+    }\n+\n+private:\n+    {{type.id}}()\n+    {\n+    {% for property in type.properties %}\n+      {% if not(property.optional) and \"default_value\" in protocol.resolve_type(property) %}\n+          m_{{property.name}} = {{protocol.resolve_type(property).default_value}};\n+      {%endif %}\n+    {% endfor %}\n+    }\n+\n+    {% for property in type.properties %}\n+      {% if property.optional %}\n+    Maybe<{{protocol.resolve_type(property).raw_type}}> m_{{property.name}};\n+      {% else %}\n+    {{protocol.resolve_type(property).type}} m_{{property.name}};\n+      {% endif %}\n+    {% endfor %}\n+};\n+\n+  {% endfor %}\n+\n+// ------------- Backend interface.\n+\n+class {{config.protocol.export_macro}} Backend {\n+public:\n+    virtual ~Backend() { }\n+\n+  {% for command in domain.commands %}\n+    {% if \"redirect\" in command %}{% continue %}{% endif %}\n+    {% if not protocol.generate_command(domain.domain, command.name) %}{% continue %}{% endif %}\n+    {% if protocol.is_async_command(domain.domain, command.name) %}\n+    class {{config.protocol.export_macro}} {{command.name | to_title_case}}Callback {\n+    public:\n+        virtual void sendSuccess(\n+      {%- for parameter in command.returns -%}\n+        {%- if \"optional\" in parameter -%}\n+            Maybe<{{protocol.resolve_type(parameter).raw_type}}> {{parameter.name}}\n+        {%- else -%}\n+                {{protocol.resolve_type(parameter).pass_type}} {{parameter.name}}\n+        {%- endif -%}\n+        {%- if not loop.last -%}, {% endif -%}\n+      {%- endfor -%}\n+        ) = 0;\n+        virtual void sendFailure(const DispatchResponse&) = 0;\n+        virtual void fallThrough() = 0;\n+        virtual ~{{command.name | to_title_case}}Callback() { }\n+    };\n+    {% endif %}\n+    {%- if not protocol.is_async_command(domain.domain, command.name) %}\n+    virtual DispatchResponse {{command.name | to_method_case}}(\n+    {%- else %}\n+    virtual void {{command.name | to_method_case}}(\n+    {%- endif %}\n+    {%- for parameter in command.parameters -%}\n+      {%- if not loop.first -%}, {% endif -%}\n+      {%- if \"optional\" in parameter -%}\n+        Maybe<{{protocol.resolve_type(parameter).raw_type}}> in_{{parameter.name}}\n+      {%- else -%}\n+        {{protocol.resolve_type(parameter).pass_type}} in_{{parameter.name}}\n+      {%- endif -%}\n+    {%- endfor -%}\n+    {%- if protocol.is_async_command(domain.domain, command.name) -%}\n+      {%- if command.parameters -%}, {% endif -%}\n+        std::unique_ptr<{{command.name | to_title_case}}Callback> callback\n+    {%- else -%}\n+      {%- for parameter in command.returns -%}\n+        {%- if (not loop.first) or command.parameters -%}, {% endif -%}\n+        {%- if \"optional\" in parameter -%}\n+        Maybe<{{protocol.resolve_type(parameter).raw_type}}>* out_{{parameter.name}}\n+        {%- else -%}\n+        {{protocol.resolve_type(parameter).type}}* out_{{parameter.name}}\n+        {%- endif -%}\n+      {%- endfor -%}\n+    {%- endif -%}\n+    ) = 0;\n+  {% endfor %}\n+\n+  {% if protocol.generate_disable(domain) %}\n+    virtual DispatchResponse {{\"disable\" | to_method_case}}()\n+    {\n+        return DispatchResponse::OK();\n+    }\n+  {% endif %}\n+};\n+\n+// ------------- Frontend interface.\n+\n+class {{config.protocol.export_macro}} Frontend {\n+public:\n+    explicit Frontend(FrontendChannel* frontendChannel) : m_frontendChannel(frontendChannel) { }\n+  {% for event in domain.events %}\n+    {% if not protocol.generate_event(domain.domain, event.name) %}{% continue %}{% endif %}\n+    void {{event.name | to_method_case}}(\n+    {%- for parameter in event.parameters -%}\n+      {%- if \"optional\" in parameter -%}\n+        Maybe<{{protocol.resolve_type(parameter).raw_type}}> {{parameter.name}} = Maybe<{{protocol.resolve_type(parameter).raw_type}}>()\n+      {%- else -%}\n+        {{protocol.resolve_type(parameter).pass_type}} {{parameter.name}}\n+      {%- endif -%}{%- if not loop.last -%}, {% endif -%}\n+    {%- endfor -%}\n+    );\n+  {% endfor %}\n+\n+    void flush();\n+    void sendRawNotification(const String&);\n+private:\n+    FrontendChannel* m_frontendChannel;\n+};\n+\n+// ------------- Dispatcher.\n+\n+class {{config.protocol.export_macro}} Dispatcher {\n+public:\n+    static void wire(UberDispatcher*, Backend*);\n+\n+private:\n+    Dispatcher() { }\n+};\n+\n+// ------------- Metainfo.\n+\n+class {{config.protocol.export_macro}} Metainfo {\n+public:\n+    using BackendClass = Backend;\n+    using FrontendClass = Frontend;\n+    using DispatcherClass = Dispatcher;\n+    static const char domainName[];\n+    static const char commandPrefix[];\n+    static const char version[];\n+};\n+\n+} // namespace {{domain.domain}}\n+{% for namespace in config.protocol.namespace %}\n+} // namespace {{namespace}}\n+{% endfor %}\n+\n+#endif // !defined({{\"_\".join(config.protocol.namespace)}}_{{domain.domain}}_h)"
        },
        {
            "sha": "fd6dbfcbfd8fe246fa04bfc180303071e796efbc",
            "filename": "tools/jinja2/AUTHORS",
            "status": "added",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FAUTHORS",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FAUTHORS",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2FAUTHORS?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,34 @@\n+Jinja is written and maintained by the Jinja Team and various\n+contributors:\n+\n+Lead Developer:\n+\n+- Armin Ronacher <armin.ronacher@active-4.com>\n+\n+Developers:\n+\n+- Christoph Hack\n+- Georg Brandl\n+\n+Contributors:\n+\n+- Bryan McLemore\n+- Mickal Gurin <kael@crocobox.org>\n+- Cameron Knight\n+- Lawrence Journal-World.\n+- David Cramer\n+- Adrian Mnnich (ThiefMaster)\n+\n+Patches and suggestions:\n+\n+- Ronny Pfannschmidt\n+- Axel Bhm\n+- Alexey Melchakov\n+- Bryan McLemore\n+- Clovis Fabricio (nosklo)\n+- Cameron Knight\n+- Peter van Dijk (Habbie)\n+- Stefan Ebner\n+- Rene Leonhardt\n+- Thomas Waldmann\n+- Cory Benfield (Lukasa)"
        },
        {
            "sha": "9137ee129a0a6f31aa62024bf19524f4934c6658",
            "filename": "tools/jinja2/Jinja2-2.10.tar.gz.md5",
            "status": "added",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FJinja2-2.10.tar.gz.md5",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FJinja2-2.10.tar.gz.md5",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2FJinja2-2.10.tar.gz.md5?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1 @@\n+61ef1117f945486472850819b8d1eb3d  Jinja2-2.10.tar.gz"
        },
        {
            "sha": "087d24c18eb80d812e819727d4c361d5ffb93c06",
            "filename": "tools/jinja2/Jinja2-2.10.tar.gz.sha512",
            "status": "added",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FJinja2-2.10.tar.gz.sha512",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FJinja2-2.10.tar.gz.sha512",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2FJinja2-2.10.tar.gz.sha512?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1 @@\n+0ea7371be67ffcf19e46dfd06523a45a0806e678a407d54f5f2f3e573982f0959cf82ec5d07b203670309928a62ef71109701ab16547a9bba2ebcdc178cb67f2  Jinja2-2.10.tar.gz"
        },
        {
            "sha": "31bf900e58e30fefda848353470298a254b9e47b",
            "filename": "tools/jinja2/LICENSE",
            "status": "added",
            "additions": 31,
            "deletions": 0,
            "changes": 31,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FLICENSE",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FLICENSE",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2FLICENSE?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,31 @@\n+Copyright (c) 2009 by the Jinja Team, see AUTHORS for more details.\n+\n+Some rights reserved.\n+\n+Redistribution and use in source and binary forms, with or without\n+modification, are permitted provided that the following conditions are\n+met:\n+\n+    * Redistributions of source code must retain the above copyright\n+      notice, this list of conditions and the following disclaimer.\n+\n+    * Redistributions in binary form must reproduce the above\n+      copyright notice, this list of conditions and the following\n+      disclaimer in the documentation and/or other materials provided\n+      with the distribution.\n+\n+    * The names of the contributors may not be used to endorse or\n+      promote products derived from this software without specific\n+      prior written permission.\n+\n+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n+\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n+OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
        },
        {
            "sha": "ee2bec9ba3a3a236004d1253e8026c737894cd9b",
            "filename": "tools/jinja2/OWNERS",
            "status": "added",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FOWNERS",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FOWNERS",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2FOWNERS?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,6 @@\n+timloh@chromium.org\n+haraken@chromium.org\n+nbarth@chromium.org\n+\n+# TEAM: platform-architecture-dev@chromium.org\n+# COMPONENT: Blink>Internals"
        },
        {
            "sha": "5246c2f84b6021928347c9eeaf6879329ce633d3",
            "filename": "tools/jinja2/README.chromium",
            "status": "added",
            "additions": 26,
            "deletions": 0,
            "changes": 26,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FREADME.chromium",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2FREADME.chromium",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2FREADME.chromium?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,26 @@\n+Name: Jinja2 Python Template Engine\n+Short Name: jinja2\n+URL: http://jinja.pocoo.org/\n+Version: 2.10\n+License: BSD 3-Clause\n+License File: LICENSE\n+Security Critical: no\n+\n+Description:\n+Template engine for code generation in Blink.\n+\n+Source: https://pypi.python.org/packages/56/e6/332789f295cf22308386cf5bbd1f4e00ed11484299c5d7383378cf48ba47/Jinja2-2.10.tar.gz\n+MD5: 61ef1117f945486472850819b8d1eb3d\n+SHA-1: 34b69e5caab12ee37b9df69df9018776c008b7b8\n+\n+Local Modifications:\n+This only includes the jinja2 directory from the tarball and the LICENSE and\n+AUTHORS files. Unit tests (testsuite directory) have been removed.\n+Additional chromium-specific files are:\n+* README.chromium (this file)\n+* OWNERS\n+* get_jinja2.sh (install script)\n+* jinja2.gni (generated by get_jinja2.sh)\n+* files of hashes (MD5 is also posted on website, SHA-512 computed locally).\n+Script checks hash then unpacks archive and installs desired files.\n+Retrieve or update by executing jinja2/get_jinja2.sh from third_party."
        },
        {
            "sha": "42aa763d571e5b01294941e30fc8fe5eabfd88e4",
            "filename": "tools/jinja2/__init__.py",
            "status": "added",
            "additions": 83,
            "deletions": 0,
            "changes": 83,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2F__init__.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2F__init__.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2F__init__.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,83 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2\n+    ~~~~~~\n+\n+    Jinja2 is a template engine written in pure Python.  It provides a\n+    Django inspired non-XML syntax but supports inline expressions and\n+    an optional sandboxed environment.\n+\n+    Nutshell\n+    --------\n+\n+    Here a small example of a Jinja2 template::\n+\n+        {% extends 'base.html' %}\n+        {% block title %}Memberlist{% endblock %}\n+        {% block content %}\n+          <ul>\n+          {% for user in users %}\n+            <li><a href=\"{{ user.url }}\">{{ user.username }}</a></li>\n+          {% endfor %}\n+          </ul>\n+        {% endblock %}\n+\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+__docformat__ = 'restructuredtext en'\n+__version__ = '2.10'\n+\n+# high level interface\n+from jinja2.environment import Environment, Template\n+\n+# loaders\n+from jinja2.loaders import BaseLoader, FileSystemLoader, PackageLoader, \\\n+     DictLoader, FunctionLoader, PrefixLoader, ChoiceLoader, \\\n+     ModuleLoader\n+\n+# bytecode caches\n+from jinja2.bccache import BytecodeCache, FileSystemBytecodeCache, \\\n+     MemcachedBytecodeCache\n+\n+# undefined types\n+from jinja2.runtime import Undefined, DebugUndefined, StrictUndefined, \\\n+     make_logging_undefined\n+\n+# exceptions\n+from jinja2.exceptions import TemplateError, UndefinedError, \\\n+     TemplateNotFound, TemplatesNotFound, TemplateSyntaxError, \\\n+     TemplateAssertionError, TemplateRuntimeError\n+\n+# decorators and public utilities\n+from jinja2.filters import environmentfilter, contextfilter, \\\n+     evalcontextfilter\n+from jinja2.utils import Markup, escape, clear_caches, \\\n+     environmentfunction, evalcontextfunction, contextfunction, \\\n+     is_undefined, select_autoescape\n+\n+__all__ = [\n+    'Environment', 'Template', 'BaseLoader', 'FileSystemLoader',\n+    'PackageLoader', 'DictLoader', 'FunctionLoader', 'PrefixLoader',\n+    'ChoiceLoader', 'BytecodeCache', 'FileSystemBytecodeCache',\n+    'MemcachedBytecodeCache', 'Undefined', 'DebugUndefined',\n+    'StrictUndefined', 'TemplateError', 'UndefinedError', 'TemplateNotFound',\n+    'TemplatesNotFound', 'TemplateSyntaxError', 'TemplateAssertionError',\n+    'TemplateRuntimeError',\n+    'ModuleLoader', 'environmentfilter', 'contextfilter', 'Markup', 'escape',\n+    'environmentfunction', 'contextfunction', 'clear_caches', 'is_undefined',\n+    'evalcontextfilter', 'evalcontextfunction', 'make_logging_undefined',\n+    'select_autoescape',\n+]\n+\n+\n+def _patch_async():\n+    from jinja2.utils import have_async_gen\n+    if have_async_gen:\n+        from jinja2.asyncsupport import patch_all\n+        patch_all()\n+\n+\n+_patch_async()\n+del _patch_async"
        },
        {
            "sha": "61d85301a4a9efa4738624fb7751fbe8e6fbfe67",
            "filename": "tools/jinja2/_compat.py",
            "status": "added",
            "additions": 99,
            "deletions": 0,
            "changes": 99,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2F_compat.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2F_compat.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2F_compat.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,99 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2._compat\n+    ~~~~~~~~~~~~~~\n+\n+    Some py2/py3 compatibility support based on a stripped down\n+    version of six so we don't have to depend on a specific version\n+    of it.\n+\n+    :copyright: Copyright 2013 by the Jinja team, see AUTHORS.\n+    :license: BSD, see LICENSE for details.\n+\"\"\"\n+import sys\n+\n+PY2 = sys.version_info[0] == 2\n+PYPY = hasattr(sys, 'pypy_translation_info')\n+_identity = lambda x: x\n+\n+\n+if not PY2:\n+    unichr = chr\n+    range_type = range\n+    text_type = str\n+    string_types = (str,)\n+    integer_types = (int,)\n+\n+    iterkeys = lambda d: iter(d.keys())\n+    itervalues = lambda d: iter(d.values())\n+    iteritems = lambda d: iter(d.items())\n+\n+    import pickle\n+    from io import BytesIO, StringIO\n+    NativeStringIO = StringIO\n+\n+    def reraise(tp, value, tb=None):\n+        if value.__traceback__ is not tb:\n+            raise value.with_traceback(tb)\n+        raise value\n+\n+    ifilter = filter\n+    imap = map\n+    izip = zip\n+    intern = sys.intern\n+\n+    implements_iterator = _identity\n+    implements_to_string = _identity\n+    encode_filename = _identity\n+\n+else:\n+    unichr = unichr\n+    text_type = unicode\n+    range_type = xrange\n+    string_types = (str, unicode)\n+    integer_types = (int, long)\n+\n+    iterkeys = lambda d: d.iterkeys()\n+    itervalues = lambda d: d.itervalues()\n+    iteritems = lambda d: d.iteritems()\n+\n+    import cPickle as pickle\n+    from cStringIO import StringIO as BytesIO, StringIO\n+    NativeStringIO = BytesIO\n+\n+    exec('def reraise(tp, value, tb=None):\\n raise tp, value, tb')\n+\n+    from itertools import imap, izip, ifilter\n+    intern = intern\n+\n+    def implements_iterator(cls):\n+        cls.next = cls.__next__\n+        del cls.__next__\n+        return cls\n+\n+    def implements_to_string(cls):\n+        cls.__unicode__ = cls.__str__\n+        cls.__str__ = lambda x: x.__unicode__().encode('utf-8')\n+        return cls\n+\n+    def encode_filename(filename):\n+        if isinstance(filename, unicode):\n+            return filename.encode('utf-8')\n+        return filename\n+\n+\n+def with_metaclass(meta, *bases):\n+    \"\"\"Create a base class with a metaclass.\"\"\"\n+    # This requires a bit of explanation: the basic idea is to make a\n+    # dummy metaclass for one level of class instantiation that replaces\n+    # itself with the actual metaclass.\n+    class metaclass(type):\n+        def __new__(cls, name, this_bases, d):\n+            return meta(name, bases, d)\n+    return type.__new__(metaclass, 'temporary_class', (), {})\n+\n+\n+try:\n+    from urllib.parse import quote_from_bytes as url_quote\n+except ImportError:\n+    from urllib import quote as url_quote"
        },
        {
            "sha": "2eac35d5c35531b2b63e3fbdcae4bfd02dd89240",
            "filename": "tools/jinja2/_identifier.py",
            "status": "added",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2F_identifier.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2F_identifier.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2F_identifier.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,2 @@\n+# generated by scripts/generate_identifier_pattern.py\n+pattern = '------------------------------------------------------------------------------------------------------------------------------------------------------------------'"
        },
        {
            "sha": "5c1f46d7fa7d46cff7711321b477f287632ef5e1",
            "filename": "tools/jinja2/asyncfilters.py",
            "status": "added",
            "additions": 146,
            "deletions": 0,
            "changes": 146,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fasyncfilters.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fasyncfilters.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fasyncfilters.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,146 @@\n+from functools import wraps\n+\n+from jinja2.asyncsupport import auto_aiter\n+from jinja2 import filters\n+\n+\n+async def auto_to_seq(value):\n+    seq = []\n+    if hasattr(value, '__aiter__'):\n+        async for item in value:\n+            seq.append(item)\n+    else:\n+        for item in value:\n+            seq.append(item)\n+    return seq\n+\n+\n+async def async_select_or_reject(args, kwargs, modfunc, lookup_attr):\n+    seq, func = filters.prepare_select_or_reject(\n+        args, kwargs, modfunc, lookup_attr)\n+    if seq:\n+        async for item in auto_aiter(seq):\n+            if func(item):\n+                yield item\n+\n+\n+def dualfilter(normal_filter, async_filter):\n+    wrap_evalctx = False\n+    if getattr(normal_filter, 'environmentfilter', False):\n+        is_async = lambda args: args[0].is_async\n+        wrap_evalctx = False\n+    else:\n+        if not getattr(normal_filter, 'evalcontextfilter', False) and \\\n+           not getattr(normal_filter, 'contextfilter', False):\n+            wrap_evalctx = True\n+        is_async = lambda args: args[0].environment.is_async\n+\n+    @wraps(normal_filter)\n+    def wrapper(*args, **kwargs):\n+        b = is_async(args)\n+        if wrap_evalctx:\n+            args = args[1:]\n+        if b:\n+            return async_filter(*args, **kwargs)\n+        return normal_filter(*args, **kwargs)\n+\n+    if wrap_evalctx:\n+        wrapper.evalcontextfilter = True\n+\n+    wrapper.asyncfiltervariant = True\n+\n+    return wrapper\n+\n+\n+def asyncfiltervariant(original):\n+    def decorator(f):\n+        return dualfilter(original, f)\n+    return decorator\n+\n+\n+@asyncfiltervariant(filters.do_first)\n+async def do_first(environment, seq):\n+    try:\n+        return await auto_aiter(seq).__anext__()\n+    except StopAsyncIteration:\n+        return environment.undefined('No first item, sequence was empty.')\n+\n+\n+@asyncfiltervariant(filters.do_groupby)\n+async def do_groupby(environment, value, attribute):\n+    expr = filters.make_attrgetter(environment, attribute)\n+    return [filters._GroupTuple(key, await auto_to_seq(values))\n+            for key, values in filters.groupby(sorted(\n+                await auto_to_seq(value), key=expr), expr)]\n+\n+\n+@asyncfiltervariant(filters.do_join)\n+async def do_join(eval_ctx, value, d=u'', attribute=None):\n+    return filters.do_join(eval_ctx, await auto_to_seq(value), d, attribute)\n+\n+\n+@asyncfiltervariant(filters.do_list)\n+async def do_list(value):\n+    return await auto_to_seq(value)\n+\n+\n+@asyncfiltervariant(filters.do_reject)\n+async def do_reject(*args, **kwargs):\n+    return async_select_or_reject(args, kwargs, lambda x: not x, False)\n+\n+\n+@asyncfiltervariant(filters.do_rejectattr)\n+async def do_rejectattr(*args, **kwargs):\n+    return async_select_or_reject(args, kwargs, lambda x: not x, True)\n+\n+\n+@asyncfiltervariant(filters.do_select)\n+async def do_select(*args, **kwargs):\n+    return async_select_or_reject(args, kwargs, lambda x: x, False)\n+\n+\n+@asyncfiltervariant(filters.do_selectattr)\n+async def do_selectattr(*args, **kwargs):\n+    return async_select_or_reject(args, kwargs, lambda x: x, True)\n+\n+\n+@asyncfiltervariant(filters.do_map)\n+async def do_map(*args, **kwargs):\n+    seq, func = filters.prepare_map(args, kwargs)\n+    if seq:\n+        async for item in auto_aiter(seq):\n+            yield func(item)\n+\n+\n+@asyncfiltervariant(filters.do_sum)\n+async def do_sum(environment, iterable, attribute=None, start=0):\n+    rv = start\n+    if attribute is not None:\n+        func = filters.make_attrgetter(environment, attribute)\n+    else:\n+        func = lambda x: x\n+    async for item in auto_aiter(iterable):\n+        rv += func(item)\n+    return rv\n+\n+\n+@asyncfiltervariant(filters.do_slice)\n+async def do_slice(value, slices, fill_with=None):\n+    return filters.do_slice(await auto_to_seq(value), slices, fill_with)\n+\n+\n+ASYNC_FILTERS = {\n+    'first':        do_first,\n+    'groupby':      do_groupby,\n+    'join':         do_join,\n+    'list':         do_list,\n+    # we intentionally do not support do_last because that would be\n+    # ridiculous\n+    'reject':       do_reject,\n+    'rejectattr':   do_rejectattr,\n+    'map':          do_map,\n+    'select':       do_select,\n+    'selectattr':   do_selectattr,\n+    'sum':          do_sum,\n+    'slice':        do_slice,\n+}"
        },
        {
            "sha": "b1e7b5ce9a27a6e069abfab9d36f80117ce6a74c",
            "filename": "tools/jinja2/asyncsupport.py",
            "status": "added",
            "additions": 256,
            "deletions": 0,
            "changes": 256,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fasyncsupport.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fasyncsupport.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fasyncsupport.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,256 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.asyncsupport\n+    ~~~~~~~~~~~~~~~~~~~\n+\n+    Has all the code for async support which is implemented as a patch\n+    for supported Python versions.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+import sys\n+import asyncio\n+import inspect\n+from functools import update_wrapper\n+\n+from jinja2.utils import concat, internalcode, Markup\n+from jinja2.environment import TemplateModule\n+from jinja2.runtime import LoopContextBase, _last_iteration\n+\n+\n+async def concat_async(async_gen):\n+    rv = []\n+    async def collect():\n+        async for event in async_gen:\n+            rv.append(event)\n+    await collect()\n+    return concat(rv)\n+\n+\n+async def generate_async(self, *args, **kwargs):\n+    vars = dict(*args, **kwargs)\n+    try:\n+        async for event in self.root_render_func(self.new_context(vars)):\n+            yield event\n+    except Exception:\n+        exc_info = sys.exc_info()\n+    else:\n+        return\n+    yield self.environment.handle_exception(exc_info, True)\n+\n+\n+def wrap_generate_func(original_generate):\n+    def _convert_generator(self, loop, args, kwargs):\n+        async_gen = self.generate_async(*args, **kwargs)\n+        try:\n+            while 1:\n+                yield loop.run_until_complete(async_gen.__anext__())\n+        except StopAsyncIteration:\n+            pass\n+    def generate(self, *args, **kwargs):\n+        if not self.environment.is_async:\n+            return original_generate(self, *args, **kwargs)\n+        return _convert_generator(self, asyncio.get_event_loop(), args, kwargs)\n+    return update_wrapper(generate, original_generate)\n+\n+\n+async def render_async(self, *args, **kwargs):\n+    if not self.environment.is_async:\n+        raise RuntimeError('The environment was not created with async mode '\n+                           'enabled.')\n+\n+    vars = dict(*args, **kwargs)\n+    ctx = self.new_context(vars)\n+\n+    try:\n+        return await concat_async(self.root_render_func(ctx))\n+    except Exception:\n+        exc_info = sys.exc_info()\n+    return self.environment.handle_exception(exc_info, True)\n+\n+\n+def wrap_render_func(original_render):\n+    def render(self, *args, **kwargs):\n+        if not self.environment.is_async:\n+            return original_render(self, *args, **kwargs)\n+        loop = asyncio.get_event_loop()\n+        return loop.run_until_complete(self.render_async(*args, **kwargs))\n+    return update_wrapper(render, original_render)\n+\n+\n+def wrap_block_reference_call(original_call):\n+    @internalcode\n+    async def async_call(self):\n+        rv = await concat_async(self._stack[self._depth](self._context))\n+        if self._context.eval_ctx.autoescape:\n+            rv = Markup(rv)\n+        return rv\n+\n+    @internalcode\n+    def __call__(self):\n+        if not self._context.environment.is_async:\n+            return original_call(self)\n+        return async_call(self)\n+\n+    return update_wrapper(__call__, original_call)\n+\n+\n+def wrap_macro_invoke(original_invoke):\n+    @internalcode\n+    async def async_invoke(self, arguments, autoescape):\n+        rv = await self._func(*arguments)\n+        if autoescape:\n+            rv = Markup(rv)\n+        return rv\n+\n+    @internalcode\n+    def _invoke(self, arguments, autoescape):\n+        if not self._environment.is_async:\n+            return original_invoke(self, arguments, autoescape)\n+        return async_invoke(self, arguments, autoescape)\n+    return update_wrapper(_invoke, original_invoke)\n+\n+\n+@internalcode\n+async def get_default_module_async(self):\n+    if self._module is not None:\n+        return self._module\n+    self._module = rv = await self.make_module_async()\n+    return rv\n+\n+\n+def wrap_default_module(original_default_module):\n+    @internalcode\n+    def _get_default_module(self):\n+        if self.environment.is_async:\n+            raise RuntimeError('Template module attribute is unavailable '\n+                               'in async mode')\n+        return original_default_module(self)\n+    return _get_default_module\n+\n+\n+async def make_module_async(self, vars=None, shared=False, locals=None):\n+    context = self.new_context(vars, shared, locals)\n+    body_stream = []\n+    async for item in self.root_render_func(context):\n+        body_stream.append(item)\n+    return TemplateModule(self, context, body_stream)\n+\n+\n+def patch_template():\n+    from jinja2 import Template\n+    Template.generate = wrap_generate_func(Template.generate)\n+    Template.generate_async = update_wrapper(\n+        generate_async, Template.generate_async)\n+    Template.render_async = update_wrapper(\n+        render_async, Template.render_async)\n+    Template.render = wrap_render_func(Template.render)\n+    Template._get_default_module = wrap_default_module(\n+        Template._get_default_module)\n+    Template._get_default_module_async = get_default_module_async\n+    Template.make_module_async = update_wrapper(\n+        make_module_async, Template.make_module_async)\n+\n+\n+def patch_runtime():\n+    from jinja2.runtime import BlockReference, Macro\n+    BlockReference.__call__ = wrap_block_reference_call(\n+        BlockReference.__call__)\n+    Macro._invoke = wrap_macro_invoke(Macro._invoke)\n+\n+\n+def patch_filters():\n+    from jinja2.filters import FILTERS\n+    from jinja2.asyncfilters import ASYNC_FILTERS\n+    FILTERS.update(ASYNC_FILTERS)\n+\n+\n+def patch_all():\n+    patch_template()\n+    patch_runtime()\n+    patch_filters()\n+\n+\n+async def auto_await(value):\n+    if inspect.isawaitable(value):\n+        return await value\n+    return value\n+\n+\n+async def auto_aiter(iterable):\n+    if hasattr(iterable, '__aiter__'):\n+        async for item in iterable:\n+            yield item\n+        return\n+    for item in iterable:\n+        yield item\n+\n+\n+class AsyncLoopContext(LoopContextBase):\n+\n+    def __init__(self, async_iterator, undefined, after, length, recurse=None,\n+                 depth0=0):\n+        LoopContextBase.__init__(self, undefined, recurse, depth0)\n+        self._async_iterator = async_iterator\n+        self._after = after\n+        self._length = length\n+\n+    @property\n+    def length(self):\n+        if self._length is None:\n+            raise TypeError('Loop length for some iterators cannot be '\n+                            'lazily calculated in async mode')\n+        return self._length\n+\n+    def __aiter__(self):\n+        return AsyncLoopContextIterator(self)\n+\n+\n+class AsyncLoopContextIterator(object):\n+    __slots__ = ('context',)\n+\n+    def __init__(self, context):\n+        self.context = context\n+\n+    def __aiter__(self):\n+        return self\n+\n+    async def __anext__(self):\n+        ctx = self.context\n+        ctx.index0 += 1\n+        if ctx._after is _last_iteration:\n+            raise StopAsyncIteration()\n+        ctx._before = ctx._current\n+        ctx._current = ctx._after\n+        try:\n+            ctx._after = await ctx._async_iterator.__anext__()\n+        except StopAsyncIteration:\n+            ctx._after = _last_iteration\n+        return ctx._current, ctx\n+\n+\n+async def make_async_loop_context(iterable, undefined, recurse=None, depth0=0):\n+    # Length is more complicated and less efficient in async mode.  The\n+    # reason for this is that we cannot know if length will be used\n+    # upfront but because length is a property we cannot lazily execute it\n+    # later.  This means that we need to buffer it up and measure :(\n+    #\n+    # We however only do this for actual iterators, not for async\n+    # iterators as blocking here does not seem like the best idea in the\n+    # world.\n+    try:\n+        length = len(iterable)\n+    except (TypeError, AttributeError):\n+        if not hasattr(iterable, '__aiter__'):\n+            iterable = tuple(iterable)\n+            length = len(iterable)\n+        else:\n+            length = None\n+    async_iterator = auto_aiter(iterable)\n+    try:\n+        after = await async_iterator.__anext__()\n+    except StopAsyncIteration:\n+        after = _last_iteration\n+    return AsyncLoopContext(async_iterator, undefined, after, length, recurse,\n+                            depth0)"
        },
        {
            "sha": "080e527cabf33b0422f6b8e5b172c17d7c039d39",
            "filename": "tools/jinja2/bccache.py",
            "status": "added",
            "additions": 362,
            "deletions": 0,
            "changes": 362,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fbccache.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fbccache.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fbccache.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,362 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.bccache\n+    ~~~~~~~~~~~~~~\n+\n+    This module implements the bytecode cache system Jinja is optionally\n+    using.  This is useful if you have very complex template situations and\n+    the compiliation of all those templates slow down your application too\n+    much.\n+\n+    Situations where this is useful are often forking web applications that\n+    are initialized on the first request.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD.\n+\"\"\"\n+from os import path, listdir\n+import os\n+import sys\n+import stat\n+import errno\n+import marshal\n+import tempfile\n+import fnmatch\n+from hashlib import sha1\n+from jinja2.utils import open_if_exists\n+from jinja2._compat import BytesIO, pickle, PY2, text_type\n+\n+\n+# marshal works better on 3.x, one hack less required\n+if not PY2:\n+    marshal_dump = marshal.dump\n+    marshal_load = marshal.load\n+else:\n+\n+    def marshal_dump(code, f):\n+        if isinstance(f, file):\n+            marshal.dump(code, f)\n+        else:\n+            f.write(marshal.dumps(code))\n+\n+    def marshal_load(f):\n+        if isinstance(f, file):\n+            return marshal.load(f)\n+        return marshal.loads(f.read())\n+\n+\n+bc_version = 3\n+\n+# magic version used to only change with new jinja versions.  With 2.6\n+# we change this to also take Python version changes into account.  The\n+# reason for this is that Python tends to segfault if fed earlier bytecode\n+# versions because someone thought it would be a good idea to reuse opcodes\n+# or make Python incompatible with earlier versions.\n+bc_magic = 'j2'.encode('ascii') + \\\n+    pickle.dumps(bc_version, 2) + \\\n+    pickle.dumps((sys.version_info[0] << 24) | sys.version_info[1])\n+\n+\n+class Bucket(object):\n+    \"\"\"Buckets are used to store the bytecode for one template.  It's created\n+    and initialized by the bytecode cache and passed to the loading functions.\n+\n+    The buckets get an internal checksum from the cache assigned and use this\n+    to automatically reject outdated cache material.  Individual bytecode\n+    cache subclasses don't have to care about cache invalidation.\n+    \"\"\"\n+\n+    def __init__(self, environment, key, checksum):\n+        self.environment = environment\n+        self.key = key\n+        self.checksum = checksum\n+        self.reset()\n+\n+    def reset(self):\n+        \"\"\"Resets the bucket (unloads the bytecode).\"\"\"\n+        self.code = None\n+\n+    def load_bytecode(self, f):\n+        \"\"\"Loads bytecode from a file or file like object.\"\"\"\n+        # make sure the magic header is correct\n+        magic = f.read(len(bc_magic))\n+        if magic != bc_magic:\n+            self.reset()\n+            return\n+        # the source code of the file changed, we need to reload\n+        checksum = pickle.load(f)\n+        if self.checksum != checksum:\n+            self.reset()\n+            return\n+        # if marshal_load fails then we need to reload\n+        try:\n+            self.code = marshal_load(f)\n+        except (EOFError, ValueError, TypeError):\n+            self.reset()\n+            return\n+\n+    def write_bytecode(self, f):\n+        \"\"\"Dump the bytecode into the file or file like object passed.\"\"\"\n+        if self.code is None:\n+            raise TypeError('can\\'t write empty bucket')\n+        f.write(bc_magic)\n+        pickle.dump(self.checksum, f, 2)\n+        marshal_dump(self.code, f)\n+\n+    def bytecode_from_string(self, string):\n+        \"\"\"Load bytecode from a string.\"\"\"\n+        self.load_bytecode(BytesIO(string))\n+\n+    def bytecode_to_string(self):\n+        \"\"\"Return the bytecode as string.\"\"\"\n+        out = BytesIO()\n+        self.write_bytecode(out)\n+        return out.getvalue()\n+\n+\n+class BytecodeCache(object):\n+    \"\"\"To implement your own bytecode cache you have to subclass this class\n+    and override :meth:`load_bytecode` and :meth:`dump_bytecode`.  Both of\n+    these methods are passed a :class:`~jinja2.bccache.Bucket`.\n+\n+    A very basic bytecode cache that saves the bytecode on the file system::\n+\n+        from os import path\n+\n+        class MyCache(BytecodeCache):\n+\n+            def __init__(self, directory):\n+                self.directory = directory\n+\n+            def load_bytecode(self, bucket):\n+                filename = path.join(self.directory, bucket.key)\n+                if path.exists(filename):\n+                    with open(filename, 'rb') as f:\n+                        bucket.load_bytecode(f)\n+\n+            def dump_bytecode(self, bucket):\n+                filename = path.join(self.directory, bucket.key)\n+                with open(filename, 'wb') as f:\n+                    bucket.write_bytecode(f)\n+\n+    A more advanced version of a filesystem based bytecode cache is part of\n+    Jinja2.\n+    \"\"\"\n+\n+    def load_bytecode(self, bucket):\n+        \"\"\"Subclasses have to override this method to load bytecode into a\n+        bucket.  If they are not able to find code in the cache for the\n+        bucket, it must not do anything.\n+        \"\"\"\n+        raise NotImplementedError()\n+\n+    def dump_bytecode(self, bucket):\n+        \"\"\"Subclasses have to override this method to write the bytecode\n+        from a bucket back to the cache.  If it unable to do so it must not\n+        fail silently but raise an exception.\n+        \"\"\"\n+        raise NotImplementedError()\n+\n+    def clear(self):\n+        \"\"\"Clears the cache.  This method is not used by Jinja2 but should be\n+        implemented to allow applications to clear the bytecode cache used\n+        by a particular environment.\n+        \"\"\"\n+\n+    def get_cache_key(self, name, filename=None):\n+        \"\"\"Returns the unique hash key for this template name.\"\"\"\n+        hash = sha1(name.encode('utf-8'))\n+        if filename is not None:\n+            filename = '|' + filename\n+            if isinstance(filename, text_type):\n+                filename = filename.encode('utf-8')\n+            hash.update(filename)\n+        return hash.hexdigest()\n+\n+    def get_source_checksum(self, source):\n+        \"\"\"Returns a checksum for the source.\"\"\"\n+        return sha1(source.encode('utf-8')).hexdigest()\n+\n+    def get_bucket(self, environment, name, filename, source):\n+        \"\"\"Return a cache bucket for the given template.  All arguments are\n+        mandatory but filename may be `None`.\n+        \"\"\"\n+        key = self.get_cache_key(name, filename)\n+        checksum = self.get_source_checksum(source)\n+        bucket = Bucket(environment, key, checksum)\n+        self.load_bytecode(bucket)\n+        return bucket\n+\n+    def set_bucket(self, bucket):\n+        \"\"\"Put the bucket into the cache.\"\"\"\n+        self.dump_bytecode(bucket)\n+\n+\n+class FileSystemBytecodeCache(BytecodeCache):\n+    \"\"\"A bytecode cache that stores bytecode on the filesystem.  It accepts\n+    two arguments: The directory where the cache items are stored and a\n+    pattern string that is used to build the filename.\n+\n+    If no directory is specified a default cache directory is selected.  On\n+    Windows the user's temp directory is used, on UNIX systems a directory\n+    is created for the user in the system temp directory.\n+\n+    The pattern can be used to have multiple separate caches operate on the\n+    same directory.  The default pattern is ``'__jinja2_%s.cache'``.  ``%s``\n+    is replaced with the cache key.\n+\n+    >>> bcc = FileSystemBytecodeCache('/tmp/jinja_cache', '%s.cache')\n+\n+    This bytecode cache supports clearing of the cache using the clear method.\n+    \"\"\"\n+\n+    def __init__(self, directory=None, pattern='__jinja2_%s.cache'):\n+        if directory is None:\n+            directory = self._get_default_cache_dir()\n+        self.directory = directory\n+        self.pattern = pattern\n+\n+    def _get_default_cache_dir(self):\n+        def _unsafe_dir():\n+            raise RuntimeError('Cannot determine safe temp directory.  You '\n+                               'need to explicitly provide one.')\n+\n+        tmpdir = tempfile.gettempdir()\n+\n+        # On windows the temporary directory is used specific unless\n+        # explicitly forced otherwise.  We can just use that.\n+        if os.name == 'nt':\n+            return tmpdir\n+        if not hasattr(os, 'getuid'):\n+            _unsafe_dir()\n+\n+        dirname = '_jinja2-cache-%d' % os.getuid()\n+        actual_dir = os.path.join(tmpdir, dirname)\n+\n+        try:\n+            os.mkdir(actual_dir, stat.S_IRWXU)\n+        except OSError as e:\n+            if e.errno != errno.EEXIST:\n+                raise\n+        try:\n+            os.chmod(actual_dir, stat.S_IRWXU)\n+            actual_dir_stat = os.lstat(actual_dir)\n+            if actual_dir_stat.st_uid != os.getuid() \\\n+               or not stat.S_ISDIR(actual_dir_stat.st_mode) \\\n+               or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU:\n+                _unsafe_dir()\n+        except OSError as e:\n+            if e.errno != errno.EEXIST:\n+                raise\n+\n+        actual_dir_stat = os.lstat(actual_dir)\n+        if actual_dir_stat.st_uid != os.getuid() \\\n+           or not stat.S_ISDIR(actual_dir_stat.st_mode) \\\n+           or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU:\n+            _unsafe_dir()\n+\n+        return actual_dir\n+\n+    def _get_cache_filename(self, bucket):\n+        return path.join(self.directory, self.pattern % bucket.key)\n+\n+    def load_bytecode(self, bucket):\n+        f = open_if_exists(self._get_cache_filename(bucket), 'rb')\n+        if f is not None:\n+            try:\n+                bucket.load_bytecode(f)\n+            finally:\n+                f.close()\n+\n+    def dump_bytecode(self, bucket):\n+        f = open(self._get_cache_filename(bucket), 'wb')\n+        try:\n+            bucket.write_bytecode(f)\n+        finally:\n+            f.close()\n+\n+    def clear(self):\n+        # imported lazily here because google app-engine doesn't support\n+        # write access on the file system and the function does not exist\n+        # normally.\n+        from os import remove\n+        files = fnmatch.filter(listdir(self.directory), self.pattern % '*')\n+        for filename in files:\n+            try:\n+                remove(path.join(self.directory, filename))\n+            except OSError:\n+                pass\n+\n+\n+class MemcachedBytecodeCache(BytecodeCache):\n+    \"\"\"This class implements a bytecode cache that uses a memcache cache for\n+    storing the information.  It does not enforce a specific memcache library\n+    (tummy's memcache or cmemcache) but will accept any class that provides\n+    the minimal interface required.\n+\n+    Libraries compatible with this class:\n+\n+    -   `werkzeug <http://werkzeug.pocoo.org/>`_.contrib.cache\n+    -   `python-memcached <https://www.tummy.com/Community/software/python-memcached/>`_\n+    -   `cmemcache <http://gijsbert.org/cmemcache/>`_\n+\n+    (Unfortunately the django cache interface is not compatible because it\n+    does not support storing binary data, only unicode.  You can however pass\n+    the underlying cache client to the bytecode cache which is available\n+    as `django.core.cache.cache._client`.)\n+\n+    The minimal interface for the client passed to the constructor is this:\n+\n+    .. class:: MinimalClientInterface\n+\n+        .. method:: set(key, value[, timeout])\n+\n+            Stores the bytecode in the cache.  `value` is a string and\n+            `timeout` the timeout of the key.  If timeout is not provided\n+            a default timeout or no timeout should be assumed, if it's\n+            provided it's an integer with the number of seconds the cache\n+            item should exist.\n+\n+        .. method:: get(key)\n+\n+            Returns the value for the cache key.  If the item does not\n+            exist in the cache the return value must be `None`.\n+\n+    The other arguments to the constructor are the prefix for all keys that\n+    is added before the actual cache key and the timeout for the bytecode in\n+    the cache system.  We recommend a high (or no) timeout.\n+\n+    This bytecode cache does not support clearing of used items in the cache.\n+    The clear method is a no-operation function.\n+\n+    .. versionadded:: 2.7\n+       Added support for ignoring memcache errors through the\n+       `ignore_memcache_errors` parameter.\n+    \"\"\"\n+\n+    def __init__(self, client, prefix='jinja2/bytecode/', timeout=None,\n+                 ignore_memcache_errors=True):\n+        self.client = client\n+        self.prefix = prefix\n+        self.timeout = timeout\n+        self.ignore_memcache_errors = ignore_memcache_errors\n+\n+    def load_bytecode(self, bucket):\n+        try:\n+            code = self.client.get(self.prefix + bucket.key)\n+        except Exception:\n+            if not self.ignore_memcache_errors:\n+                raise\n+            code = None\n+        if code is not None:\n+            bucket.bytecode_from_string(code)\n+\n+    def dump_bytecode(self, bucket):\n+        args = (self.prefix + bucket.key, bucket.bytecode_to_string())\n+        if self.timeout is not None:\n+            args += (self.timeout,)\n+        try:\n+            self.client.set(*args)\n+        except Exception:\n+            if not self.ignore_memcache_errors:\n+                raise"
        },
        {
            "sha": "d534a827391aeb6f81f94c1ce5688af8d05c5505",
            "filename": "tools/jinja2/compiler.py",
            "status": "added",
            "additions": 1721,
            "deletions": 0,
            "changes": 1721,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fcompiler.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fcompiler.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fcompiler.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,1721 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.compiler\n+    ~~~~~~~~~~~~~~~\n+\n+    Compiles nodes into python code.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+from itertools import chain\n+from copy import deepcopy\n+from keyword import iskeyword as is_python_keyword\n+from functools import update_wrapper\n+from jinja2 import nodes\n+from jinja2.nodes import EvalContext\n+from jinja2.visitor import NodeVisitor\n+from jinja2.optimizer import Optimizer\n+from jinja2.exceptions import TemplateAssertionError\n+from jinja2.utils import Markup, concat, escape\n+from jinja2._compat import range_type, text_type, string_types, \\\n+     iteritems, NativeStringIO, imap, izip\n+from jinja2.idtracking import Symbols, VAR_LOAD_PARAMETER, \\\n+     VAR_LOAD_RESOLVE, VAR_LOAD_ALIAS, VAR_LOAD_UNDEFINED\n+\n+\n+operators = {\n+    'eq':       '==',\n+    'ne':       '!=',\n+    'gt':       '>',\n+    'gteq':     '>=',\n+    'lt':       '<',\n+    'lteq':     '<=',\n+    'in':       'in',\n+    'notin':    'not in'\n+}\n+\n+# what method to iterate over items do we want to use for dict iteration\n+# in generated code?  on 2.x let's go with iteritems, on 3.x with items\n+if hasattr(dict, 'iteritems'):\n+    dict_item_iter = 'iteritems'\n+else:\n+    dict_item_iter = 'items'\n+\n+code_features = ['division']\n+\n+# does this python version support generator stops? (PEP 0479)\n+try:\n+    exec('from __future__ import generator_stop')\n+    code_features.append('generator_stop')\n+except SyntaxError:\n+    pass\n+\n+# does this python version support yield from?\n+try:\n+    exec('def f(): yield from x()')\n+except SyntaxError:\n+    supports_yield_from = False\n+else:\n+    supports_yield_from = True\n+\n+\n+def optimizeconst(f):\n+    def new_func(self, node, frame, **kwargs):\n+        # Only optimize if the frame is not volatile\n+        if self.optimized and not frame.eval_ctx.volatile:\n+            new_node = self.optimizer.visit(node, frame.eval_ctx)\n+            if new_node != node:\n+                return self.visit(new_node, frame)\n+        return f(self, node, frame, **kwargs)\n+    return update_wrapper(new_func, f)\n+\n+\n+def generate(node, environment, name, filename, stream=None,\n+             defer_init=False, optimized=True):\n+    \"\"\"Generate the python source for a node tree.\"\"\"\n+    if not isinstance(node, nodes.Template):\n+        raise TypeError('Can\\'t compile non template nodes')\n+    generator = environment.code_generator_class(environment, name, filename,\n+                                                 stream, defer_init,\n+                                                 optimized)\n+    generator.visit(node)\n+    if stream is None:\n+        return generator.stream.getvalue()\n+\n+\n+def has_safe_repr(value):\n+    \"\"\"Does the node have a safe representation?\"\"\"\n+    if value is None or value is NotImplemented or value is Ellipsis:\n+        return True\n+    if type(value) in (bool, int, float, complex, range_type, Markup) + string_types:\n+        return True\n+    if type(value) in (tuple, list, set, frozenset):\n+        for item in value:\n+            if not has_safe_repr(item):\n+                return False\n+        return True\n+    elif type(value) is dict:\n+        for key, value in iteritems(value):\n+            if not has_safe_repr(key):\n+                return False\n+            if not has_safe_repr(value):\n+                return False\n+        return True\n+    return False\n+\n+\n+def find_undeclared(nodes, names):\n+    \"\"\"Check if the names passed are accessed undeclared.  The return value\n+    is a set of all the undeclared names from the sequence of names found.\n+    \"\"\"\n+    visitor = UndeclaredNameVisitor(names)\n+    try:\n+        for node in nodes:\n+            visitor.visit(node)\n+    except VisitorExit:\n+        pass\n+    return visitor.undeclared\n+\n+\n+class MacroRef(object):\n+\n+    def __init__(self, node):\n+        self.node = node\n+        self.accesses_caller = False\n+        self.accesses_kwargs = False\n+        self.accesses_varargs = False\n+\n+\n+class Frame(object):\n+    \"\"\"Holds compile time information for us.\"\"\"\n+\n+    def __init__(self, eval_ctx, parent=None, level=None):\n+        self.eval_ctx = eval_ctx\n+        self.symbols = Symbols(parent and parent.symbols or None,\n+                               level=level)\n+\n+        # a toplevel frame is the root + soft frames such as if conditions.\n+        self.toplevel = False\n+\n+        # the root frame is basically just the outermost frame, so no if\n+        # conditions.  This information is used to optimize inheritance\n+        # situations.\n+        self.rootlevel = False\n+\n+        # in some dynamic inheritance situations the compiler needs to add\n+        # write tests around output statements.\n+        self.require_output_check = parent and parent.require_output_check\n+\n+        # inside some tags we are using a buffer rather than yield statements.\n+        # this for example affects {% filter %} or {% macro %}.  If a frame\n+        # is buffered this variable points to the name of the list used as\n+        # buffer.\n+        self.buffer = None\n+\n+        # the name of the block we're in, otherwise None.\n+        self.block = parent and parent.block or None\n+\n+        # the parent of this frame\n+        self.parent = parent\n+\n+        if parent is not None:\n+            self.buffer = parent.buffer\n+\n+    def copy(self):\n+        \"\"\"Create a copy of the current one.\"\"\"\n+        rv = object.__new__(self.__class__)\n+        rv.__dict__.update(self.__dict__)\n+        rv.symbols = self.symbols.copy()\n+        return rv\n+\n+    def inner(self, isolated=False):\n+        \"\"\"Return an inner frame.\"\"\"\n+        if isolated:\n+            return Frame(self.eval_ctx, level=self.symbols.level + 1)\n+        return Frame(self.eval_ctx, self)\n+\n+    def soft(self):\n+        \"\"\"Return a soft frame.  A soft frame may not be modified as\n+        standalone thing as it shares the resources with the frame it\n+        was created of, but it's not a rootlevel frame any longer.\n+\n+        This is only used to implement if-statements.\n+        \"\"\"\n+        rv = self.copy()\n+        rv.rootlevel = False\n+        return rv\n+\n+    __copy__ = copy\n+\n+\n+class VisitorExit(RuntimeError):\n+    \"\"\"Exception used by the `UndeclaredNameVisitor` to signal a stop.\"\"\"\n+\n+\n+class DependencyFinderVisitor(NodeVisitor):\n+    \"\"\"A visitor that collects filter and test calls.\"\"\"\n+\n+    def __init__(self):\n+        self.filters = set()\n+        self.tests = set()\n+\n+    def visit_Filter(self, node):\n+        self.generic_visit(node)\n+        self.filters.add(node.name)\n+\n+    def visit_Test(self, node):\n+        self.generic_visit(node)\n+        self.tests.add(node.name)\n+\n+    def visit_Block(self, node):\n+        \"\"\"Stop visiting at blocks.\"\"\"\n+\n+\n+class UndeclaredNameVisitor(NodeVisitor):\n+    \"\"\"A visitor that checks if a name is accessed without being\n+    declared.  This is different from the frame visitor as it will\n+    not stop at closure frames.\n+    \"\"\"\n+\n+    def __init__(self, names):\n+        self.names = set(names)\n+        self.undeclared = set()\n+\n+    def visit_Name(self, node):\n+        if node.ctx == 'load' and node.name in self.names:\n+            self.undeclared.add(node.name)\n+            if self.undeclared == self.names:\n+                raise VisitorExit()\n+        else:\n+            self.names.discard(node.name)\n+\n+    def visit_Block(self, node):\n+        \"\"\"Stop visiting a blocks.\"\"\"\n+\n+\n+class CompilerExit(Exception):\n+    \"\"\"Raised if the compiler encountered a situation where it just\n+    doesn't make sense to further process the code.  Any block that\n+    raises such an exception is not further processed.\n+    \"\"\"\n+\n+\n+class CodeGenerator(NodeVisitor):\n+\n+    def __init__(self, environment, name, filename, stream=None,\n+                 defer_init=False, optimized=True):\n+        if stream is None:\n+            stream = NativeStringIO()\n+        self.environment = environment\n+        self.name = name\n+        self.filename = filename\n+        self.stream = stream\n+        self.created_block_context = False\n+        self.defer_init = defer_init\n+        self.optimized = optimized\n+        if optimized:\n+            self.optimizer = Optimizer(environment)\n+\n+        # aliases for imports\n+        self.import_aliases = {}\n+\n+        # a registry for all blocks.  Because blocks are moved out\n+        # into the global python scope they are registered here\n+        self.blocks = {}\n+\n+        # the number of extends statements so far\n+        self.extends_so_far = 0\n+\n+        # some templates have a rootlevel extends.  In this case we\n+        # can safely assume that we're a child template and do some\n+        # more optimizations.\n+        self.has_known_extends = False\n+\n+        # the current line number\n+        self.code_lineno = 1\n+\n+        # registry of all filters and tests (global, not block local)\n+        self.tests = {}\n+        self.filters = {}\n+\n+        # the debug information\n+        self.debug_info = []\n+        self._write_debug_info = None\n+\n+        # the number of new lines before the next write()\n+        self._new_lines = 0\n+\n+        # the line number of the last written statement\n+        self._last_line = 0\n+\n+        # true if nothing was written so far.\n+        self._first_write = True\n+\n+        # used by the `temporary_identifier` method to get new\n+        # unique, temporary identifier\n+        self._last_identifier = 0\n+\n+        # the current indentation\n+        self._indentation = 0\n+\n+        # Tracks toplevel assignments\n+        self._assign_stack = []\n+\n+        # Tracks parameter definition blocks\n+        self._param_def_block = []\n+\n+        # Tracks the current context.\n+        self._context_reference_stack = ['context']\n+\n+    # -- Various compilation helpers\n+\n+    def fail(self, msg, lineno):\n+        \"\"\"Fail with a :exc:`TemplateAssertionError`.\"\"\"\n+        raise TemplateAssertionError(msg, lineno, self.name, self.filename)\n+\n+    def temporary_identifier(self):\n+        \"\"\"Get a new unique identifier.\"\"\"\n+        self._last_identifier += 1\n+        return 't_%d' % self._last_identifier\n+\n+    def buffer(self, frame):\n+        \"\"\"Enable buffering for the frame from that point onwards.\"\"\"\n+        frame.buffer = self.temporary_identifier()\n+        self.writeline('%s = []' % frame.buffer)\n+\n+    def return_buffer_contents(self, frame, force_unescaped=False):\n+        \"\"\"Return the buffer contents of the frame.\"\"\"\n+        if not force_unescaped:\n+            if frame.eval_ctx.volatile:\n+                self.writeline('if context.eval_ctx.autoescape:')\n+                self.indent()\n+                self.writeline('return Markup(concat(%s))' % frame.buffer)\n+                self.outdent()\n+                self.writeline('else:')\n+                self.indent()\n+                self.writeline('return concat(%s)' % frame.buffer)\n+                self.outdent()\n+                return\n+            elif frame.eval_ctx.autoescape:\n+                self.writeline('return Markup(concat(%s))' % frame.buffer)\n+                return\n+        self.writeline('return concat(%s)' % frame.buffer)\n+\n+    def indent(self):\n+        \"\"\"Indent by one.\"\"\"\n+        self._indentation += 1\n+\n+    def outdent(self, step=1):\n+        \"\"\"Outdent by step.\"\"\"\n+        self._indentation -= step\n+\n+    def start_write(self, frame, node=None):\n+        \"\"\"Yield or write into the frame buffer.\"\"\"\n+        if frame.buffer is None:\n+            self.writeline('yield ', node)\n+        else:\n+            self.writeline('%s.append(' % frame.buffer, node)\n+\n+    def end_write(self, frame):\n+        \"\"\"End the writing process started by `start_write`.\"\"\"\n+        if frame.buffer is not None:\n+            self.write(')')\n+\n+    def simple_write(self, s, frame, node=None):\n+        \"\"\"Simple shortcut for start_write + write + end_write.\"\"\"\n+        self.start_write(frame, node)\n+        self.write(s)\n+        self.end_write(frame)\n+\n+    def blockvisit(self, nodes, frame):\n+        \"\"\"Visit a list of nodes as block in a frame.  If the current frame\n+        is no buffer a dummy ``if 0: yield None`` is written automatically.\n+        \"\"\"\n+        try:\n+            self.writeline('pass')\n+            for node in nodes:\n+                self.visit(node, frame)\n+        except CompilerExit:\n+            pass\n+\n+    def write(self, x):\n+        \"\"\"Write a string into the output stream.\"\"\"\n+        if self._new_lines:\n+            if not self._first_write:\n+                self.stream.write('\\n' * self._new_lines)\n+                self.code_lineno += self._new_lines\n+                if self._write_debug_info is not None:\n+                    self.debug_info.append((self._write_debug_info,\n+                                            self.code_lineno))\n+                    self._write_debug_info = None\n+            self._first_write = False\n+            self.stream.write('    ' * self._indentation)\n+            self._new_lines = 0\n+        self.stream.write(x)\n+\n+    def writeline(self, x, node=None, extra=0):\n+        \"\"\"Combination of newline and write.\"\"\"\n+        self.newline(node, extra)\n+        self.write(x)\n+\n+    def newline(self, node=None, extra=0):\n+        \"\"\"Add one or more newlines before the next write.\"\"\"\n+        self._new_lines = max(self._new_lines, 1 + extra)\n+        if node is not None and node.lineno != self._last_line:\n+            self._write_debug_info = node.lineno\n+            self._last_line = node.lineno\n+\n+    def signature(self, node, frame, extra_kwargs=None):\n+        \"\"\"Writes a function call to the stream for the current node.\n+        A leading comma is added automatically.  The extra keyword\n+        arguments may not include python keywords otherwise a syntax\n+        error could occour.  The extra keyword arguments should be given\n+        as python dict.\n+        \"\"\"\n+        # if any of the given keyword arguments is a python keyword\n+        # we have to make sure that no invalid call is created.\n+        kwarg_workaround = False\n+        for kwarg in chain((x.key for x in node.kwargs), extra_kwargs or ()):\n+            if is_python_keyword(kwarg):\n+                kwarg_workaround = True\n+                break\n+\n+        for arg in node.args:\n+            self.write(', ')\n+            self.visit(arg, frame)\n+\n+        if not kwarg_workaround:\n+            for kwarg in node.kwargs:\n+                self.write(', ')\n+                self.visit(kwarg, frame)\n+            if extra_kwargs is not None:\n+                for key, value in iteritems(extra_kwargs):\n+                    self.write(', %s=%s' % (key, value))\n+        if node.dyn_args:\n+            self.write(', *')\n+            self.visit(node.dyn_args, frame)\n+\n+        if kwarg_workaround:\n+            if node.dyn_kwargs is not None:\n+                self.write(', **dict({')\n+            else:\n+                self.write(', **{')\n+            for kwarg in node.kwargs:\n+                self.write('%r: ' % kwarg.key)\n+                self.visit(kwarg.value, frame)\n+                self.write(', ')\n+            if extra_kwargs is not None:\n+                for key, value in iteritems(extra_kwargs):\n+                    self.write('%r: %s, ' % (key, value))\n+            if node.dyn_kwargs is not None:\n+                self.write('}, **')\n+                self.visit(node.dyn_kwargs, frame)\n+                self.write(')')\n+            else:\n+                self.write('}')\n+\n+        elif node.dyn_kwargs is not None:\n+            self.write(', **')\n+            self.visit(node.dyn_kwargs, frame)\n+\n+    def pull_dependencies(self, nodes):\n+        \"\"\"Pull all the dependencies.\"\"\"\n+        visitor = DependencyFinderVisitor()\n+        for node in nodes:\n+            visitor.visit(node)\n+        for dependency in 'filters', 'tests':\n+            mapping = getattr(self, dependency)\n+            for name in getattr(visitor, dependency):\n+                if name not in mapping:\n+                    mapping[name] = self.temporary_identifier()\n+                self.writeline('%s = environment.%s[%r]' %\n+                               (mapping[name], dependency, name))\n+\n+    def enter_frame(self, frame):\n+        undefs = []\n+        for target, (action, param) in iteritems(frame.symbols.loads):\n+            if action == VAR_LOAD_PARAMETER:\n+                pass\n+            elif action == VAR_LOAD_RESOLVE:\n+                self.writeline('%s = %s(%r)' %\n+                               (target, self.get_resolve_func(), param))\n+            elif action == VAR_LOAD_ALIAS:\n+                self.writeline('%s = %s' % (target, param))\n+            elif action == VAR_LOAD_UNDEFINED:\n+                undefs.append(target)\n+            else:\n+                raise NotImplementedError('unknown load instruction')\n+        if undefs:\n+            self.writeline('%s = missing' % ' = '.join(undefs))\n+\n+    def leave_frame(self, frame, with_python_scope=False):\n+        if not with_python_scope:\n+            undefs = []\n+            for target, _ in iteritems(frame.symbols.loads):\n+                undefs.append(target)\n+            if undefs:\n+                self.writeline('%s = missing' % ' = '.join(undefs))\n+\n+    def func(self, name):\n+        if self.environment.is_async:\n+            return 'async def %s' % name\n+        return 'def %s' % name\n+\n+    def macro_body(self, node, frame):\n+        \"\"\"Dump the function def of a macro or call block.\"\"\"\n+        frame = frame.inner()\n+        frame.symbols.analyze_node(node)\n+        macro_ref = MacroRef(node)\n+\n+        explicit_caller = None\n+        skip_special_params = set()\n+        args = []\n+        for idx, arg in enumerate(node.args):\n+            if arg.name == 'caller':\n+                explicit_caller = idx\n+            if arg.name in ('kwargs', 'varargs'):\n+                skip_special_params.add(arg.name)\n+            args.append(frame.symbols.ref(arg.name))\n+\n+        undeclared = find_undeclared(node.body, ('caller', 'kwargs', 'varargs'))\n+\n+        if 'caller' in undeclared:\n+            # In older Jinja2 versions there was a bug that allowed caller\n+            # to retain the special behavior even if it was mentioned in\n+            # the argument list.  However thankfully this was only really\n+            # working if it was the last argument.  So we are explicitly\n+            # checking this now and error out if it is anywhere else in\n+            # the argument list.\n+            if explicit_caller is not None:\n+                try:\n+                    node.defaults[explicit_caller - len(node.args)]\n+                except IndexError:\n+                    self.fail('When defining macros or call blocks the '\n+                              'special \"caller\" argument must be omitted '\n+                              'or be given a default.', node.lineno)\n+            else:\n+                args.append(frame.symbols.declare_parameter('caller'))\n+            macro_ref.accesses_caller = True\n+        if 'kwargs' in undeclared and not 'kwargs' in skip_special_params:\n+            args.append(frame.symbols.declare_parameter('kwargs'))\n+            macro_ref.accesses_kwargs = True\n+        if 'varargs' in undeclared and not 'varargs' in skip_special_params:\n+            args.append(frame.symbols.declare_parameter('varargs'))\n+            macro_ref.accesses_varargs = True\n+\n+        # macros are delayed, they never require output checks\n+        frame.require_output_check = False\n+        frame.symbols.analyze_node(node)\n+        self.writeline('%s(%s):' % (self.func('macro'), ', '.join(args)), node)\n+        self.indent()\n+\n+        self.buffer(frame)\n+        self.enter_frame(frame)\n+\n+        self.push_parameter_definitions(frame)\n+        for idx, arg in enumerate(node.args):\n+            ref = frame.symbols.ref(arg.name)\n+            self.writeline('if %s is missing:' % ref)\n+            self.indent()\n+            try:\n+                default = node.defaults[idx - len(node.args)]\n+            except IndexError:\n+                self.writeline('%s = undefined(%r, name=%r)' % (\n+                    ref,\n+                    'parameter %r was not provided' % arg.name,\n+                    arg.name))\n+            else:\n+                self.writeline('%s = ' % ref)\n+                self.visit(default, frame)\n+            self.mark_parameter_stored(ref)\n+            self.outdent()\n+        self.pop_parameter_definitions()\n+\n+        self.blockvisit(node.body, frame)\n+        self.return_buffer_contents(frame, force_unescaped=True)\n+        self.leave_frame(frame, with_python_scope=True)\n+        self.outdent()\n+\n+        return frame, macro_ref\n+\n+    def macro_def(self, macro_ref, frame):\n+        \"\"\"Dump the macro definition for the def created by macro_body.\"\"\"\n+        arg_tuple = ', '.join(repr(x.name) for x in macro_ref.node.args)\n+        name = getattr(macro_ref.node, 'name', None)\n+        if len(macro_ref.node.args) == 1:\n+            arg_tuple += ','\n+        self.write('Macro(environment, macro, %r, (%s), %r, %r, %r, '\n+                   'context.eval_ctx.autoescape)' %\n+                   (name, arg_tuple, macro_ref.accesses_kwargs,\n+                    macro_ref.accesses_varargs, macro_ref.accesses_caller))\n+\n+    def position(self, node):\n+        \"\"\"Return a human readable position for the node.\"\"\"\n+        rv = 'line %d' % node.lineno\n+        if self.name is not None:\n+            rv += ' in ' + repr(self.name)\n+        return rv\n+\n+    def dump_local_context(self, frame):\n+        return '{%s}' % ', '.join(\n+            '%r: %s' % (name, target) for name, target\n+            in iteritems(frame.symbols.dump_stores()))\n+\n+    def write_commons(self):\n+        \"\"\"Writes a common preamble that is used by root and block functions.\n+        Primarily this sets up common local helpers and enforces a generator\n+        through a dead branch.\n+        \"\"\"\n+        self.writeline('resolve = context.resolve_or_missing')\n+        self.writeline('undefined = environment.undefined')\n+        self.writeline('if 0: yield None')\n+\n+    def push_parameter_definitions(self, frame):\n+        \"\"\"Pushes all parameter targets from the given frame into a local\n+        stack that permits tracking of yet to be assigned parameters.  In\n+        particular this enables the optimization from `visit_Name` to skip\n+        undefined expressions for parameters in macros as macros can reference\n+        otherwise unbound parameters.\n+        \"\"\"\n+        self._param_def_block.append(frame.symbols.dump_param_targets())\n+\n+    def pop_parameter_definitions(self):\n+        \"\"\"Pops the current parameter definitions set.\"\"\"\n+        self._param_def_block.pop()\n+\n+    def mark_parameter_stored(self, target):\n+        \"\"\"Marks a parameter in the current parameter definitions as stored.\n+        This will skip the enforced undefined checks.\n+        \"\"\"\n+        if self._param_def_block:\n+            self._param_def_block[-1].discard(target)\n+\n+    def push_context_reference(self, target):\n+        self._context_reference_stack.append(target)\n+\n+    def pop_context_reference(self):\n+        self._context_reference_stack.pop()\n+\n+    def get_context_ref(self):\n+        return self._context_reference_stack[-1]\n+\n+    def get_resolve_func(self):\n+        target = self._context_reference_stack[-1]\n+        if target == 'context':\n+            return 'resolve'\n+        return '%s.resolve' % target\n+\n+    def derive_context(self, frame):\n+        return '%s.derived(%s)' % (\n+            self.get_context_ref(),\n+            self.dump_local_context(frame),\n+        )\n+\n+    def parameter_is_undeclared(self, target):\n+        \"\"\"Checks if a given target is an undeclared parameter.\"\"\"\n+        if not self._param_def_block:\n+            return False\n+        return target in self._param_def_block[-1]\n+\n+    def push_assign_tracking(self):\n+        \"\"\"Pushes a new layer for assignment tracking.\"\"\"\n+        self._assign_stack.append(set())\n+\n+    def pop_assign_tracking(self, frame):\n+        \"\"\"Pops the topmost level for assignment tracking and updates the\n+        context variables if necessary.\n+        \"\"\"\n+        vars = self._assign_stack.pop()\n+        if not frame.toplevel or not vars:\n+            return\n+        public_names = [x for x in vars if x[:1] != '_']\n+        if len(vars) == 1:\n+            name = next(iter(vars))\n+            ref = frame.symbols.ref(name)\n+            self.writeline('context.vars[%r] = %s' % (name, ref))\n+        else:\n+            self.writeline('context.vars.update({')\n+            for idx, name in enumerate(vars):\n+                if idx:\n+                    self.write(', ')\n+                ref = frame.symbols.ref(name)\n+                self.write('%r: %s' % (name, ref))\n+            self.write('})')\n+        if public_names:\n+            if len(public_names) == 1:\n+                self.writeline('context.exported_vars.add(%r)' %\n+                               public_names[0])\n+            else:\n+                self.writeline('context.exported_vars.update((%s))' %\n+                               ', '.join(imap(repr, public_names)))\n+\n+    # -- Statement Visitors\n+\n+    def visit_Template(self, node, frame=None):\n+        assert frame is None, 'no root frame allowed'\n+        eval_ctx = EvalContext(self.environment, self.name)\n+\n+        from jinja2.runtime import __all__ as exported\n+        self.writeline('from __future__ import %s' % ', '.join(code_features))\n+        self.writeline('from jinja2.runtime import ' + ', '.join(exported))\n+\n+        if self.environment.is_async:\n+            self.writeline('from jinja2.asyncsupport import auto_await, '\n+                           'auto_aiter, make_async_loop_context')\n+\n+        # if we want a deferred initialization we cannot move the\n+        # environment into a local name\n+        envenv = not self.defer_init and ', environment=environment' or ''\n+\n+        # do we have an extends tag at all?  If not, we can save some\n+        # overhead by just not processing any inheritance code.\n+        have_extends = node.find(nodes.Extends) is not None\n+\n+        # find all blocks\n+        for block in node.find_all(nodes.Block):\n+            if block.name in self.blocks:\n+                self.fail('block %r defined twice' % block.name, block.lineno)\n+            self.blocks[block.name] = block\n+\n+        # find all imports and import them\n+        for import_ in node.find_all(nodes.ImportedName):\n+            if import_.importname not in self.import_aliases:\n+                imp = import_.importname\n+                self.import_aliases[imp] = alias = self.temporary_identifier()\n+                if '.' in imp:\n+                    module, obj = imp.rsplit('.', 1)\n+                    self.writeline('from %s import %s as %s' %\n+                                   (module, obj, alias))\n+                else:\n+                    self.writeline('import %s as %s' % (imp, alias))\n+\n+        # add the load name\n+        self.writeline('name = %r' % self.name)\n+\n+        # generate the root render function.\n+        self.writeline('%s(context, missing=missing%s):' %\n+                       (self.func('root'), envenv), extra=1)\n+        self.indent()\n+        self.write_commons()\n+\n+        # process the root\n+        frame = Frame(eval_ctx)\n+        if 'self' in find_undeclared(node.body, ('self',)):\n+            ref = frame.symbols.declare_parameter('self')\n+            self.writeline('%s = TemplateReference(context)' % ref)\n+        frame.symbols.analyze_node(node)\n+        frame.toplevel = frame.rootlevel = True\n+        frame.require_output_check = have_extends and not self.has_known_extends\n+        if have_extends:\n+            self.writeline('parent_template = None')\n+        self.enter_frame(frame)\n+        self.pull_dependencies(node.body)\n+        self.blockvisit(node.body, frame)\n+        self.leave_frame(frame, with_python_scope=True)\n+        self.outdent()\n+\n+        # make sure that the parent root is called.\n+        if have_extends:\n+            if not self.has_known_extends:\n+                self.indent()\n+                self.writeline('if parent_template is not None:')\n+            self.indent()\n+            if supports_yield_from and not self.environment.is_async:\n+                self.writeline('yield from parent_template.'\n+                               'root_render_func(context)')\n+            else:\n+                self.writeline('%sfor event in parent_template.'\n+                               'root_render_func(context):' %\n+                               (self.environment.is_async and 'async ' or ''))\n+                self.indent()\n+                self.writeline('yield event')\n+                self.outdent()\n+            self.outdent(1 + (not self.has_known_extends))\n+\n+        # at this point we now have the blocks collected and can visit them too.\n+        for name, block in iteritems(self.blocks):\n+            self.writeline('%s(context, missing=missing%s):' %\n+                           (self.func('block_' + name), envenv),\n+                           block, 1)\n+            self.indent()\n+            self.write_commons()\n+            # It's important that we do not make this frame a child of the\n+            # toplevel template.  This would cause a variety of\n+            # interesting issues with identifier tracking.\n+            block_frame = Frame(eval_ctx)\n+            undeclared = find_undeclared(block.body, ('self', 'super'))\n+            if 'self' in undeclared:\n+                ref = block_frame.symbols.declare_parameter('self')\n+                self.writeline('%s = TemplateReference(context)' % ref)\n+            if 'super' in undeclared:\n+                ref = block_frame.symbols.declare_parameter('super')\n+                self.writeline('%s = context.super(%r, '\n+                               'block_%s)' % (ref, name, name))\n+            block_frame.symbols.analyze_node(block)\n+            block_frame.block = name\n+            self.enter_frame(block_frame)\n+            self.pull_dependencies(block.body)\n+            self.blockvisit(block.body, block_frame)\n+            self.leave_frame(block_frame, with_python_scope=True)\n+            self.outdent()\n+\n+        self.writeline('blocks = {%s}' % ', '.join('%r: block_%s' % (x, x)\n+                                                   for x in self.blocks),\n+                       extra=1)\n+\n+        # add a function that returns the debug info\n+        self.writeline('debug_info = %r' % '&'.join('%s=%s' % x for x\n+                                                    in self.debug_info))\n+\n+    def visit_Block(self, node, frame):\n+        \"\"\"Call a block and register it for the template.\"\"\"\n+        level = 0\n+        if frame.toplevel:\n+            # if we know that we are a child template, there is no need to\n+            # check if we are one\n+            if self.has_known_extends:\n+                return\n+            if self.extends_so_far > 0:\n+                self.writeline('if parent_template is None:')\n+                self.indent()\n+                level += 1\n+\n+        if node.scoped:\n+            context = self.derive_context(frame)\n+        else:\n+            context = self.get_context_ref()\n+\n+        if supports_yield_from and not self.environment.is_async and \\\n+           frame.buffer is None:\n+            self.writeline('yield from context.blocks[%r][0](%s)' % (\n+                           node.name, context), node)\n+        else:\n+            loop = self.environment.is_async and 'async for' or 'for'\n+            self.writeline('%s event in context.blocks[%r][0](%s):' % (\n+                           loop, node.name, context), node)\n+            self.indent()\n+            self.simple_write('event', frame)\n+            self.outdent()\n+\n+        self.outdent(level)\n+\n+    def visit_Extends(self, node, frame):\n+        \"\"\"Calls the extender.\"\"\"\n+        if not frame.toplevel:\n+            self.fail('cannot use extend from a non top-level scope',\n+                      node.lineno)\n+\n+        # if the number of extends statements in general is zero so\n+        # far, we don't have to add a check if something extended\n+        # the template before this one.\n+        if self.extends_so_far > 0:\n+\n+            # if we have a known extends we just add a template runtime\n+            # error into the generated code.  We could catch that at compile\n+            # time too, but i welcome it not to confuse users by throwing the\n+            # same error at different times just \"because we can\".\n+            if not self.has_known_extends:\n+                self.writeline('if parent_template is not None:')\n+                self.indent()\n+            self.writeline('raise TemplateRuntimeError(%r)' %\n+                           'extended multiple times')\n+\n+            # if we have a known extends already we don't need that code here\n+            # as we know that the template execution will end here.\n+            if self.has_known_extends:\n+                raise CompilerExit()\n+            else:\n+                self.outdent()\n+\n+        self.writeline('parent_template = environment.get_template(', node)\n+        self.visit(node.template, frame)\n+        self.write(', %r)' % self.name)\n+        self.writeline('for name, parent_block in parent_template.'\n+                       'blocks.%s():' % dict_item_iter)\n+        self.indent()\n+        self.writeline('context.blocks.setdefault(name, []).'\n+                       'append(parent_block)')\n+        self.outdent()\n+\n+        # if this extends statement was in the root level we can take\n+        # advantage of that information and simplify the generated code\n+        # in the top level from this point onwards\n+        if frame.rootlevel:\n+            self.has_known_extends = True\n+\n+        # and now we have one more\n+        self.extends_so_far += 1\n+\n+    def visit_Include(self, node, frame):\n+        \"\"\"Handles includes.\"\"\"\n+        if node.ignore_missing:\n+            self.writeline('try:')\n+            self.indent()\n+\n+        func_name = 'get_or_select_template'\n+        if isinstance(node.template, nodes.Const):\n+            if isinstance(node.template.value, string_types):\n+                func_name = 'get_template'\n+            elif isinstance(node.template.value, (tuple, list)):\n+                func_name = 'select_template'\n+        elif isinstance(node.template, (nodes.Tuple, nodes.List)):\n+            func_name = 'select_template'\n+\n+        self.writeline('template = environment.%s(' % func_name, node)\n+        self.visit(node.template, frame)\n+        self.write(', %r)' % self.name)\n+        if node.ignore_missing:\n+            self.outdent()\n+            self.writeline('except TemplateNotFound:')\n+            self.indent()\n+            self.writeline('pass')\n+            self.outdent()\n+            self.writeline('else:')\n+            self.indent()\n+\n+        skip_event_yield = False\n+        if node.with_context:\n+            loop = self.environment.is_async and 'async for' or 'for'\n+            self.writeline('%s event in template.root_render_func('\n+                           'template.new_context(context.get_all(), True, '\n+                           '%s)):' % (loop, self.dump_local_context(frame)))\n+        elif self.environment.is_async:\n+            self.writeline('for event in (await '\n+                           'template._get_default_module_async())'\n+                           '._body_stream:')\n+        else:\n+            if supports_yield_from:\n+                self.writeline('yield from template._get_default_module()'\n+                               '._body_stream')\n+                skip_event_yield = True\n+            else:\n+                self.writeline('for event in template._get_default_module()'\n+                               '._body_stream:')\n+\n+        if not skip_event_yield:\n+            self.indent()\n+            self.simple_write('event', frame)\n+            self.outdent()\n+\n+        if node.ignore_missing:\n+            self.outdent()\n+\n+    def visit_Import(self, node, frame):\n+        \"\"\"Visit regular imports.\"\"\"\n+        self.writeline('%s = ' % frame.symbols.ref(node.target), node)\n+        if frame.toplevel:\n+            self.write('context.vars[%r] = ' % node.target)\n+        if self.environment.is_async:\n+            self.write('await ')\n+        self.write('environment.get_template(')\n+        self.visit(node.template, frame)\n+        self.write(', %r).' % self.name)\n+        if node.with_context:\n+            self.write('make_module%s(context.get_all(), True, %s)'\n+                       % (self.environment.is_async and '_async' or '',\n+                          self.dump_local_context(frame)))\n+        elif self.environment.is_async:\n+            self.write('_get_default_module_async()')\n+        else:\n+            self.write('_get_default_module()')\n+        if frame.toplevel and not node.target.startswith('_'):\n+            self.writeline('context.exported_vars.discard(%r)' % node.target)\n+\n+    def visit_FromImport(self, node, frame):\n+        \"\"\"Visit named imports.\"\"\"\n+        self.newline(node)\n+        self.write('included_template = %senvironment.get_template('\n+                   % (self.environment.is_async and 'await ' or ''))\n+        self.visit(node.template, frame)\n+        self.write(', %r).' % self.name)\n+        if node.with_context:\n+            self.write('make_module%s(context.get_all(), True, %s)'\n+                       % (self.environment.is_async and '_async' or '',\n+                          self.dump_local_context(frame)))\n+        elif self.environment.is_async:\n+            self.write('_get_default_module_async()')\n+        else:\n+            self.write('_get_default_module()')\n+\n+        var_names = []\n+        discarded_names = []\n+        for name in node.names:\n+            if isinstance(name, tuple):\n+                name, alias = name\n+            else:\n+                alias = name\n+            self.writeline('%s = getattr(included_template, '\n+                           '%r, missing)' % (frame.symbols.ref(alias), name))\n+            self.writeline('if %s is missing:' % frame.symbols.ref(alias))\n+            self.indent()\n+            self.writeline('%s = undefined(%r %% '\n+                           'included_template.__name__, '\n+                           'name=%r)' %\n+                           (frame.symbols.ref(alias),\n+                            'the template %%r (imported on %s) does '\n+                            'not export the requested name %s' % (\n+                                self.position(node),\n+                                repr(name)\n+                           ), name))\n+            self.outdent()\n+            if frame.toplevel:\n+                var_names.append(alias)\n+                if not alias.startswith('_'):\n+                    discarded_names.append(alias)\n+\n+        if var_names:\n+            if len(var_names) == 1:\n+                name = var_names[0]\n+                self.writeline('context.vars[%r] = %s' %\n+                               (name, frame.symbols.ref(name)))\n+            else:\n+                self.writeline('context.vars.update({%s})' % ', '.join(\n+                    '%r: %s' % (name, frame.symbols.ref(name)) for name in var_names\n+                ))\n+        if discarded_names:\n+            if len(discarded_names) == 1:\n+                self.writeline('context.exported_vars.discard(%r)' %\n+                               discarded_names[0])\n+            else:\n+                self.writeline('context.exported_vars.difference_'\n+                               'update((%s))' % ', '.join(imap(repr, discarded_names)))\n+\n+    def visit_For(self, node, frame):\n+        loop_frame = frame.inner()\n+        test_frame = frame.inner()\n+        else_frame = frame.inner()\n+\n+        # try to figure out if we have an extended loop.  An extended loop\n+        # is necessary if the loop is in recursive mode if the special loop\n+        # variable is accessed in the body.\n+        extended_loop = node.recursive or 'loop' in \\\n+                        find_undeclared(node.iter_child_nodes(\n+                            only=('body',)), ('loop',))\n+\n+        loop_ref = None\n+        if extended_loop:\n+            loop_ref = loop_frame.symbols.declare_parameter('loop')\n+\n+        loop_frame.symbols.analyze_node(node, for_branch='body')\n+        if node.else_:\n+            else_frame.symbols.analyze_node(node, for_branch='else')\n+\n+        if node.test:\n+            loop_filter_func = self.temporary_identifier()\n+            test_frame.symbols.analyze_node(node, for_branch='test')\n+            self.writeline('%s(fiter):' % self.func(loop_filter_func), node.test)\n+            self.indent()\n+            self.enter_frame(test_frame)\n+            self.writeline(self.environment.is_async and 'async for ' or 'for ')\n+            self.visit(node.target, loop_frame)\n+            self.write(' in ')\n+            self.write(self.environment.is_async and 'auto_aiter(fiter)' or 'fiter')\n+            self.write(':')\n+            self.indent()\n+            self.writeline('if ', node.test)\n+            self.visit(node.test, test_frame)\n+            self.write(':')\n+            self.indent()\n+            self.writeline('yield ')\n+            self.visit(node.target, loop_frame)\n+            self.outdent(3)\n+            self.leave_frame(test_frame, with_python_scope=True)\n+\n+        # if we don't have an recursive loop we have to find the shadowed\n+        # variables at that point.  Because loops can be nested but the loop\n+        # variable is a special one we have to enforce aliasing for it.\n+        if node.recursive:\n+            self.writeline('%s(reciter, loop_render_func, depth=0):' %\n+                           self.func('loop'), node)\n+            self.indent()\n+            self.buffer(loop_frame)\n+\n+            # Use the same buffer for the else frame\n+            else_frame.buffer = loop_frame.buffer\n+\n+        # make sure the loop variable is a special one and raise a template\n+        # assertion error if a loop tries to write to loop\n+        if extended_loop:\n+            self.writeline('%s = missing' % loop_ref)\n+\n+        for name in node.find_all(nodes.Name):\n+            if name.ctx == 'store' and name.name == 'loop':\n+                self.fail('Can\\'t assign to special loop variable '\n+                          'in for-loop target', name.lineno)\n+\n+        if node.else_:\n+            iteration_indicator = self.temporary_identifier()\n+            self.writeline('%s = 1' % iteration_indicator)\n+\n+        self.writeline(self.environment.is_async and 'async for ' or 'for ', node)\n+        self.visit(node.target, loop_frame)\n+        if extended_loop:\n+            if self.environment.is_async:\n+                self.write(', %s in await make_async_loop_context(' % loop_ref)\n+            else:\n+                self.write(', %s in LoopContext(' % loop_ref)\n+        else:\n+            self.write(' in ')\n+\n+        if node.test:\n+            self.write('%s(' % loop_filter_func)\n+        if node.recursive:\n+            self.write('reciter')\n+        else:\n+            if self.environment.is_async and not extended_loop:\n+                self.write('auto_aiter(')\n+            self.visit(node.iter, frame)\n+            if self.environment.is_async and not extended_loop:\n+                self.write(')')\n+        if node.test:\n+            self.write(')')\n+\n+        if node.recursive:\n+            self.write(', undefined, loop_render_func, depth):')\n+        else:\n+            self.write(extended_loop and ', undefined):' or ':')\n+\n+        self.indent()\n+        self.enter_frame(loop_frame)\n+\n+        self.blockvisit(node.body, loop_frame)\n+        if node.else_:\n+            self.writeline('%s = 0' % iteration_indicator)\n+        self.outdent()\n+        self.leave_frame(loop_frame, with_python_scope=node.recursive\n+                         and not node.else_)\n+\n+        if node.else_:\n+            self.writeline('if %s:' % iteration_indicator)\n+            self.indent()\n+            self.enter_frame(else_frame)\n+            self.blockvisit(node.else_, else_frame)\n+            self.leave_frame(else_frame)\n+            self.outdent()\n+\n+        # if the node was recursive we have to return the buffer contents\n+        # and start the iteration code\n+        if node.recursive:\n+            self.return_buffer_contents(loop_frame)\n+            self.outdent()\n+            self.start_write(frame, node)\n+            if self.environment.is_async:\n+                self.write('await ')\n+            self.write('loop(')\n+            if self.environment.is_async:\n+                self.write('auto_aiter(')\n+            self.visit(node.iter, frame)\n+            if self.environment.is_async:\n+                self.write(')')\n+            self.write(', loop)')\n+            self.end_write(frame)\n+\n+    def visit_If(self, node, frame):\n+        if_frame = frame.soft()\n+        self.writeline('if ', node)\n+        self.visit(node.test, if_frame)\n+        self.write(':')\n+        self.indent()\n+        self.blockvisit(node.body, if_frame)\n+        self.outdent()\n+        for elif_ in node.elif_:\n+            self.writeline('elif ', elif_)\n+            self.visit(elif_.test, if_frame)\n+            self.write(':')\n+            self.indent()\n+            self.blockvisit(elif_.body, if_frame)\n+            self.outdent()\n+        if node.else_:\n+            self.writeline('else:')\n+            self.indent()\n+            self.blockvisit(node.else_, if_frame)\n+            self.outdent()\n+\n+    def visit_Macro(self, node, frame):\n+        macro_frame, macro_ref = self.macro_body(node, frame)\n+        self.newline()\n+        if frame.toplevel:\n+            if not node.name.startswith('_'):\n+                self.write('context.exported_vars.add(%r)' % node.name)\n+            ref = frame.symbols.ref(node.name)\n+            self.writeline('context.vars[%r] = ' % node.name)\n+        self.write('%s = ' % frame.symbols.ref(node.name))\n+        self.macro_def(macro_ref, macro_frame)\n+\n+    def visit_CallBlock(self, node, frame):\n+        call_frame, macro_ref = self.macro_body(node, frame)\n+        self.writeline('caller = ')\n+        self.macro_def(macro_ref, call_frame)\n+        self.start_write(frame, node)\n+        self.visit_Call(node.call, frame, forward_caller=True)\n+        self.end_write(frame)\n+\n+    def visit_FilterBlock(self, node, frame):\n+        filter_frame = frame.inner()\n+        filter_frame.symbols.analyze_node(node)\n+        self.enter_frame(filter_frame)\n+        self.buffer(filter_frame)\n+        self.blockvisit(node.body, filter_frame)\n+        self.start_write(frame, node)\n+        self.visit_Filter(node.filter, filter_frame)\n+        self.end_write(frame)\n+        self.leave_frame(filter_frame)\n+\n+    def visit_With(self, node, frame):\n+        with_frame = frame.inner()\n+        with_frame.symbols.analyze_node(node)\n+        self.enter_frame(with_frame)\n+        for idx, (target, expr) in enumerate(izip(node.targets, node.values)):\n+            self.newline()\n+            self.visit(target, with_frame)\n+            self.write(' = ')\n+            self.visit(expr, frame)\n+        self.blockvisit(node.body, with_frame)\n+        self.leave_frame(with_frame)\n+\n+    def visit_ExprStmt(self, node, frame):\n+        self.newline(node)\n+        self.visit(node.node, frame)\n+\n+    def visit_Output(self, node, frame):\n+        # if we have a known extends statement, we don't output anything\n+        # if we are in a require_output_check section\n+        if self.has_known_extends and frame.require_output_check:\n+            return\n+\n+        allow_constant_finalize = True\n+        if self.environment.finalize:\n+            func = self.environment.finalize\n+            if getattr(func, 'contextfunction', False) or \\\n+               getattr(func, 'evalcontextfunction', False):\n+                allow_constant_finalize = False\n+            elif getattr(func, 'environmentfunction', False):\n+                finalize = lambda x: text_type(\n+                    self.environment.finalize(self.environment, x))\n+            else:\n+                finalize = lambda x: text_type(self.environment.finalize(x))\n+        else:\n+            finalize = text_type\n+\n+        # if we are inside a frame that requires output checking, we do so\n+        outdent_later = False\n+        if frame.require_output_check:\n+            self.writeline('if parent_template is None:')\n+            self.indent()\n+            outdent_later = True\n+\n+        # try to evaluate as many chunks as possible into a static\n+        # string at compile time.\n+        body = []\n+        for child in node.nodes:\n+            try:\n+                if not allow_constant_finalize:\n+                    raise nodes.Impossible()\n+                const = child.as_const(frame.eval_ctx)\n+            except nodes.Impossible:\n+                body.append(child)\n+                continue\n+            # the frame can't be volatile here, becaus otherwise the\n+            # as_const() function would raise an Impossible exception\n+            # at that point.\n+            try:\n+                if frame.eval_ctx.autoescape:\n+                    if hasattr(const, '__html__'):\n+                        const = const.__html__()\n+                    else:\n+                        const = escape(const)\n+                const = finalize(const)\n+            except Exception:\n+                # if something goes wrong here we evaluate the node\n+                # at runtime for easier debugging\n+                body.append(child)\n+                continue\n+            if body and isinstance(body[-1], list):\n+                body[-1].append(const)\n+            else:\n+                body.append([const])\n+\n+        # if we have less than 3 nodes or a buffer we yield or extend/append\n+        if len(body) < 3 or frame.buffer is not None:\n+            if frame.buffer is not None:\n+                # for one item we append, for more we extend\n+                if len(body) == 1:\n+                    self.writeline('%s.append(' % frame.buffer)\n+                else:\n+                    self.writeline('%s.extend((' % frame.buffer)\n+                self.indent()\n+            for item in body:\n+                if isinstance(item, list):\n+                    val = repr(concat(item))\n+                    if frame.buffer is None:\n+                        self.writeline('yield ' + val)\n+                    else:\n+                        self.writeline(val + ',')\n+                else:\n+                    if frame.buffer is None:\n+                        self.writeline('yield ', item)\n+                    else:\n+                        self.newline(item)\n+                    close = 1\n+                    if frame.eval_ctx.volatile:\n+                        self.write('(escape if context.eval_ctx.autoescape'\n+                                   ' else to_string)(')\n+                    elif frame.eval_ctx.autoescape:\n+                        self.write('escape(')\n+                    else:\n+                        self.write('to_string(')\n+                    if self.environment.finalize is not None:\n+                        self.write('environment.finalize(')\n+                        if getattr(self.environment.finalize,\n+                                   \"contextfunction\", False):\n+                            self.write('context, ')\n+                        close += 1\n+                    self.visit(item, frame)\n+                    self.write(')' * close)\n+                    if frame.buffer is not None:\n+                        self.write(',')\n+            if frame.buffer is not None:\n+                # close the open parentheses\n+                self.outdent()\n+                self.writeline(len(body) == 1 and ')' or '))')\n+\n+        # otherwise we create a format string as this is faster in that case\n+        else:\n+            format = []\n+            arguments = []\n+            for item in body:\n+                if isinstance(item, list):\n+                    format.append(concat(item).replace('%', '%%'))\n+                else:\n+                    format.append('%s')\n+                    arguments.append(item)\n+            self.writeline('yield ')\n+            self.write(repr(concat(format)) + ' % (')\n+            self.indent()\n+            for argument in arguments:\n+                self.newline(argument)\n+                close = 0\n+                if frame.eval_ctx.volatile:\n+                    self.write('(escape if context.eval_ctx.autoescape else'\n+                               ' to_string)(')\n+                    close += 1\n+                elif frame.eval_ctx.autoescape:\n+                    self.write('escape(')\n+                    close += 1\n+                if self.environment.finalize is not None:\n+                    self.write('environment.finalize(')\n+                    if getattr(self.environment.finalize,\n+                               'contextfunction', False):\n+                        self.write('context, ')\n+                    elif getattr(self.environment.finalize,\n+                               'evalcontextfunction', False):\n+                        self.write('context.eval_ctx, ')\n+                    elif getattr(self.environment.finalize,\n+                               'environmentfunction', False):\n+                        self.write('environment, ')\n+                    close += 1\n+                self.visit(argument, frame)\n+                self.write(')' * close + ', ')\n+            self.outdent()\n+            self.writeline(')')\n+\n+        if outdent_later:\n+            self.outdent()\n+\n+    def visit_Assign(self, node, frame):\n+        self.push_assign_tracking()\n+        self.newline(node)\n+        self.visit(node.target, frame)\n+        self.write(' = ')\n+        self.visit(node.node, frame)\n+        self.pop_assign_tracking(frame)\n+\n+    def visit_AssignBlock(self, node, frame):\n+        self.push_assign_tracking()\n+        block_frame = frame.inner()\n+        # This is a special case.  Since a set block always captures we\n+        # will disable output checks.  This way one can use set blocks\n+        # toplevel even in extended templates.\n+        block_frame.require_output_check = False\n+        block_frame.symbols.analyze_node(node)\n+        self.enter_frame(block_frame)\n+        self.buffer(block_frame)\n+        self.blockvisit(node.body, block_frame)\n+        self.newline(node)\n+        self.visit(node.target, frame)\n+        self.write(' = (Markup if context.eval_ctx.autoescape '\n+                   'else identity)(')\n+        if node.filter is not None:\n+            self.visit_Filter(node.filter, block_frame)\n+        else:\n+            self.write('concat(%s)' % block_frame.buffer)\n+        self.write(')')\n+        self.pop_assign_tracking(frame)\n+        self.leave_frame(block_frame)\n+\n+    # -- Expression Visitors\n+\n+    def visit_Name(self, node, frame):\n+        if node.ctx == 'store' and frame.toplevel:\n+            if self._assign_stack:\n+                self._assign_stack[-1].add(node.name)\n+        ref = frame.symbols.ref(node.name)\n+\n+        # If we are looking up a variable we might have to deal with the\n+        # case where it's undefined.  We can skip that case if the load\n+        # instruction indicates a parameter which are always defined.\n+        if node.ctx == 'load':\n+            load = frame.symbols.find_load(ref)\n+            if not (load is not None and load[0] == VAR_LOAD_PARAMETER and \\\n+                    not self.parameter_is_undeclared(ref)):\n+                self.write('(undefined(name=%r) if %s is missing else %s)' %\n+                           (node.name, ref, ref))\n+                return\n+\n+        self.write(ref)\n+\n+    def visit_NSRef(self, node, frame):\n+        # NSRefs can only be used to store values; since they use the normal\n+        # `foo.bar` notation they will be parsed as a normal attribute access\n+        # when used anywhere but in a `set` context\n+        ref = frame.symbols.ref(node.name)\n+        self.writeline('if not isinstance(%s, Namespace):' % ref)\n+        self.indent()\n+        self.writeline('raise TemplateRuntimeError(%r)' %\n+                       'cannot assign attribute on non-namespace object')\n+        self.outdent()\n+        self.writeline('%s[%r]' % (ref, node.attr))\n+\n+    def visit_Const(self, node, frame):\n+        val = node.as_const(frame.eval_ctx)\n+        if isinstance(val, float):\n+            self.write(str(val))\n+        else:\n+            self.write(repr(val))\n+\n+    def visit_TemplateData(self, node, frame):\n+        try:\n+            self.write(repr(node.as_const(frame.eval_ctx)))\n+        except nodes.Impossible:\n+            self.write('(Markup if context.eval_ctx.autoescape else identity)(%r)'\n+                       % node.data)\n+\n+    def visit_Tuple(self, node, frame):\n+        self.write('(')\n+        idx = -1\n+        for idx, item in enumerate(node.items):\n+            if idx:\n+                self.write(', ')\n+            self.visit(item, frame)\n+        self.write(idx == 0 and ',)' or ')')\n+\n+    def visit_List(self, node, frame):\n+        self.write('[')\n+        for idx, item in enumerate(node.items):\n+            if idx:\n+                self.write(', ')\n+            self.visit(item, frame)\n+        self.write(']')\n+\n+    def visit_Dict(self, node, frame):\n+        self.write('{')\n+        for idx, item in enumerate(node.items):\n+            if idx:\n+                self.write(', ')\n+            self.visit(item.key, frame)\n+            self.write(': ')\n+            self.visit(item.value, frame)\n+        self.write('}')\n+\n+    def binop(operator, interceptable=True):\n+        @optimizeconst\n+        def visitor(self, node, frame):\n+            if self.environment.sandboxed and \\\n+               operator in self.environment.intercepted_binops:\n+                self.write('environment.call_binop(context, %r, ' % operator)\n+                self.visit(node.left, frame)\n+                self.write(', ')\n+                self.visit(node.right, frame)\n+            else:\n+                self.write('(')\n+                self.visit(node.left, frame)\n+                self.write(' %s ' % operator)\n+                self.visit(node.right, frame)\n+            self.write(')')\n+        return visitor\n+\n+    def uaop(operator, interceptable=True):\n+        @optimizeconst\n+        def visitor(self, node, frame):\n+            if self.environment.sandboxed and \\\n+               operator in self.environment.intercepted_unops:\n+                self.write('environment.call_unop(context, %r, ' % operator)\n+                self.visit(node.node, frame)\n+            else:\n+                self.write('(' + operator)\n+                self.visit(node.node, frame)\n+            self.write(')')\n+        return visitor\n+\n+    visit_Add = binop('+')\n+    visit_Sub = binop('-')\n+    visit_Mul = binop('*')\n+    visit_Div = binop('/')\n+    visit_FloorDiv = binop('//')\n+    visit_Pow = binop('**')\n+    visit_Mod = binop('%')\n+    visit_And = binop('and', interceptable=False)\n+    visit_Or = binop('or', interceptable=False)\n+    visit_Pos = uaop('+')\n+    visit_Neg = uaop('-')\n+    visit_Not = uaop('not ', interceptable=False)\n+    del binop, uaop\n+\n+    @optimizeconst\n+    def visit_Concat(self, node, frame):\n+        if frame.eval_ctx.volatile:\n+            func_name = '(context.eval_ctx.volatile and' \\\n+                        ' markup_join or unicode_join)'\n+        elif frame.eval_ctx.autoescape:\n+            func_name = 'markup_join'\n+        else:\n+            func_name = 'unicode_join'\n+        self.write('%s((' % func_name)\n+        for arg in node.nodes:\n+            self.visit(arg, frame)\n+            self.write(', ')\n+        self.write('))')\n+\n+    @optimizeconst\n+    def visit_Compare(self, node, frame):\n+        self.visit(node.expr, frame)\n+        for op in node.ops:\n+            self.visit(op, frame)\n+\n+    def visit_Operand(self, node, frame):\n+        self.write(' %s ' % operators[node.op])\n+        self.visit(node.expr, frame)\n+\n+    @optimizeconst\n+    def visit_Getattr(self, node, frame):\n+        self.write('environment.getattr(')\n+        self.visit(node.node, frame)\n+        self.write(', %r)' % node.attr)\n+\n+    @optimizeconst\n+    def visit_Getitem(self, node, frame):\n+        # slices bypass the environment getitem method.\n+        if isinstance(node.arg, nodes.Slice):\n+            self.visit(node.node, frame)\n+            self.write('[')\n+            self.visit(node.arg, frame)\n+            self.write(']')\n+        else:\n+            self.write('environment.getitem(')\n+            self.visit(node.node, frame)\n+            self.write(', ')\n+            self.visit(node.arg, frame)\n+            self.write(')')\n+\n+    def visit_Slice(self, node, frame):\n+        if node.start is not None:\n+            self.visit(node.start, frame)\n+        self.write(':')\n+        if node.stop is not None:\n+            self.visit(node.stop, frame)\n+        if node.step is not None:\n+            self.write(':')\n+            self.visit(node.step, frame)\n+\n+    @optimizeconst\n+    def visit_Filter(self, node, frame):\n+        if self.environment.is_async:\n+            self.write('await auto_await(')\n+        self.write(self.filters[node.name] + '(')\n+        func = self.environment.filters.get(node.name)\n+        if func is None:\n+            self.fail('no filter named %r' % node.name, node.lineno)\n+        if getattr(func, 'contextfilter', False):\n+            self.write('context, ')\n+        elif getattr(func, 'evalcontextfilter', False):\n+            self.write('context.eval_ctx, ')\n+        elif getattr(func, 'environmentfilter', False):\n+            self.write('environment, ')\n+\n+        # if the filter node is None we are inside a filter block\n+        # and want to write to the current buffer\n+        if node.node is not None:\n+            self.visit(node.node, frame)\n+        elif frame.eval_ctx.volatile:\n+            self.write('(context.eval_ctx.autoescape and'\n+                       ' Markup(concat(%s)) or concat(%s))' %\n+                       (frame.buffer, frame.buffer))\n+        elif frame.eval_ctx.autoescape:\n+            self.write('Markup(concat(%s))' % frame.buffer)\n+        else:\n+            self.write('concat(%s)' % frame.buffer)\n+        self.signature(node, frame)\n+        self.write(')')\n+        if self.environment.is_async:\n+            self.write(')')\n+\n+    @optimizeconst\n+    def visit_Test(self, node, frame):\n+        self.write(self.tests[node.name] + '(')\n+        if node.name not in self.environment.tests:\n+            self.fail('no test named %r' % node.name, node.lineno)\n+        self.visit(node.node, frame)\n+        self.signature(node, frame)\n+        self.write(')')\n+\n+    @optimizeconst\n+    def visit_CondExpr(self, node, frame):\n+        def write_expr2():\n+            if node.expr2 is not None:\n+                return self.visit(node.expr2, frame)\n+            self.write('undefined(%r)' % ('the inline if-'\n+                       'expression on %s evaluated to false and '\n+                       'no else section was defined.' % self.position(node)))\n+\n+        self.write('(')\n+        self.visit(node.expr1, frame)\n+        self.write(' if ')\n+        self.visit(node.test, frame)\n+        self.write(' else ')\n+        write_expr2()\n+        self.write(')')\n+\n+    @optimizeconst\n+    def visit_Call(self, node, frame, forward_caller=False):\n+        if self.environment.is_async:\n+            self.write('await auto_await(')\n+        if self.environment.sandboxed:\n+            self.write('environment.call(context, ')\n+        else:\n+            self.write('context.call(')\n+        self.visit(node.node, frame)\n+        extra_kwargs = forward_caller and {'caller': 'caller'} or None\n+        self.signature(node, frame, extra_kwargs)\n+        self.write(')')\n+        if self.environment.is_async:\n+            self.write(')')\n+\n+    def visit_Keyword(self, node, frame):\n+        self.write(node.key + '=')\n+        self.visit(node.value, frame)\n+\n+    # -- Unused nodes for extensions\n+\n+    def visit_MarkSafe(self, node, frame):\n+        self.write('Markup(')\n+        self.visit(node.expr, frame)\n+        self.write(')')\n+\n+    def visit_MarkSafeIfAutoescape(self, node, frame):\n+        self.write('(context.eval_ctx.autoescape and Markup or identity)(')\n+        self.visit(node.expr, frame)\n+        self.write(')')\n+\n+    def visit_EnvironmentAttribute(self, node, frame):\n+        self.write('environment.' + node.name)\n+\n+    def visit_ExtensionAttribute(self, node, frame):\n+        self.write('environment.extensions[%r].%s' % (node.identifier, node.name))\n+\n+    def visit_ImportedName(self, node, frame):\n+        self.write(self.import_aliases[node.importname])\n+\n+    def visit_InternalName(self, node, frame):\n+        self.write(node.name)\n+\n+    def visit_ContextReference(self, node, frame):\n+        self.write('context')\n+\n+    def visit_Continue(self, node, frame):\n+        self.writeline('continue', node)\n+\n+    def visit_Break(self, node, frame):\n+        self.writeline('break', node)\n+\n+    def visit_Scope(self, node, frame):\n+        scope_frame = frame.inner()\n+        scope_frame.symbols.analyze_node(node)\n+        self.enter_frame(scope_frame)\n+        self.blockvisit(node.body, scope_frame)\n+        self.leave_frame(scope_frame)\n+\n+    def visit_OverlayScope(self, node, frame):\n+        ctx = self.temporary_identifier()\n+        self.writeline('%s = %s' % (ctx, self.derive_context(frame)))\n+        self.writeline('%s.vars = ' % ctx)\n+        self.visit(node.context, frame)\n+        self.push_context_reference(ctx)\n+\n+        scope_frame = frame.inner(isolated=True)\n+        scope_frame.symbols.analyze_node(node)\n+        self.enter_frame(scope_frame)\n+        self.blockvisit(node.body, scope_frame)\n+        self.leave_frame(scope_frame)\n+        self.pop_context_reference()\n+\n+    def visit_EvalContextModifier(self, node, frame):\n+        for keyword in node.options:\n+            self.writeline('context.eval_ctx.%s = ' % keyword.key)\n+            self.visit(keyword.value, frame)\n+            try:\n+                val = keyword.value.as_const(frame.eval_ctx)\n+            except nodes.Impossible:\n+                frame.eval_ctx.volatile = True\n+            else:\n+                setattr(frame.eval_ctx, keyword.key, val)\n+\n+    def visit_ScopedEvalContextModifier(self, node, frame):\n+        old_ctx_name = self.temporary_identifier()\n+        saved_ctx = frame.eval_ctx.save()\n+        self.writeline('%s = context.eval_ctx.save()' % old_ctx_name)\n+        self.visit_EvalContextModifier(node, frame)\n+        for child in node.body:\n+            self.visit(child, frame)\n+        frame.eval_ctx.revert(saved_ctx)\n+        self.writeline('context.eval_ctx.revert(%s)' % old_ctx_name)"
        },
        {
            "sha": "11efd1ed15832d51acef200d1ce93efc57297664",
            "filename": "tools/jinja2/constants.py",
            "status": "added",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fconstants.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fconstants.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fconstants.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,32 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja.constants\n+    ~~~~~~~~~~~~~~~\n+\n+    Various constants.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+\n+\n+#: list of lorem ipsum words used by the lipsum() helper function\n+LOREM_IPSUM_WORDS = u'''\\\n+a ac accumsan ad adipiscing aenean aliquam aliquet amet ante aptent arcu at\n+auctor augue bibendum blandit class commodo condimentum congue consectetuer\n+consequat conubia convallis cras cubilia cum curabitur curae cursus dapibus\n+diam dictum dictumst dignissim dis dolor donec dui duis egestas eget eleifend\n+elementum elit enim erat eros est et etiam eu euismod facilisi facilisis fames\n+faucibus felis fermentum feugiat fringilla fusce gravida habitant habitasse hac\n+hendrerit hymenaeos iaculis id imperdiet in inceptos integer interdum ipsum\n+justo lacinia lacus laoreet lectus leo libero ligula litora lobortis lorem\n+luctus maecenas magna magnis malesuada massa mattis mauris metus mi molestie\n+mollis montes morbi mus nam nascetur natoque nec neque netus nibh nisi nisl non\n+nonummy nostra nulla nullam nunc odio orci ornare parturient pede pellentesque\n+penatibus per pharetra phasellus placerat platea porta porttitor posuere\n+potenti praesent pretium primis proin pulvinar purus quam quis quisque rhoncus\n+ridiculus risus rutrum sagittis sapien scelerisque sed sem semper senectus sit\n+sociis sociosqu sodales sollicitudin suscipit suspendisse taciti tellus tempor\n+tempus tincidunt torquent tortor tristique turpis ullamcorper ultrices\n+ultricies urna ut varius vehicula vel velit venenatis vestibulum vitae vivamus\n+viverra volutpat vulputate'''"
        },
        {
            "sha": "b61139f0cde17f4914b66bdd541ff149f492fe1d",
            "filename": "tools/jinja2/debug.py",
            "status": "added",
            "additions": 372,
            "deletions": 0,
            "changes": 372,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fdebug.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fdebug.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fdebug.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,372 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.debug\n+    ~~~~~~~~~~~~\n+\n+    Implements the debug interface for Jinja.  This module does some pretty\n+    ugly stuff with the Python traceback system in order to achieve tracebacks\n+    with correct line numbers, locals and contents.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+import sys\n+import traceback\n+from types import TracebackType, CodeType\n+from jinja2.utils import missing, internal_code\n+from jinja2.exceptions import TemplateSyntaxError\n+from jinja2._compat import iteritems, reraise, PY2\n+\n+# on pypy we can take advantage of transparent proxies\n+try:\n+    from __pypy__ import tproxy\n+except ImportError:\n+    tproxy = None\n+\n+\n+# how does the raise helper look like?\n+try:\n+    exec(\"raise TypeError, 'foo'\")\n+except SyntaxError:\n+    raise_helper = 'raise __jinja_exception__[1]'\n+except TypeError:\n+    raise_helper = 'raise __jinja_exception__[0], __jinja_exception__[1]'\n+\n+\n+class TracebackFrameProxy(object):\n+    \"\"\"Proxies a traceback frame.\"\"\"\n+\n+    def __init__(self, tb):\n+        self.tb = tb\n+        self._tb_next = None\n+\n+    @property\n+    def tb_next(self):\n+        return self._tb_next\n+\n+    def set_next(self, next):\n+        if tb_set_next is not None:\n+            try:\n+                tb_set_next(self.tb, next and next.tb or None)\n+            except Exception:\n+                # this function can fail due to all the hackery it does\n+                # on various python implementations.  We just catch errors\n+                # down and ignore them if necessary.\n+                pass\n+        self._tb_next = next\n+\n+    @property\n+    def is_jinja_frame(self):\n+        return '__jinja_template__' in self.tb.tb_frame.f_globals\n+\n+    def __getattr__(self, name):\n+        return getattr(self.tb, name)\n+\n+\n+def make_frame_proxy(frame):\n+    proxy = TracebackFrameProxy(frame)\n+    if tproxy is None:\n+        return proxy\n+    def operation_handler(operation, *args, **kwargs):\n+        if operation in ('__getattribute__', '__getattr__'):\n+            return getattr(proxy, args[0])\n+        elif operation == '__setattr__':\n+            proxy.__setattr__(*args, **kwargs)\n+        else:\n+            return getattr(proxy, operation)(*args, **kwargs)\n+    return tproxy(TracebackType, operation_handler)\n+\n+\n+class ProcessedTraceback(object):\n+    \"\"\"Holds a Jinja preprocessed traceback for printing or reraising.\"\"\"\n+\n+    def __init__(self, exc_type, exc_value, frames):\n+        assert frames, 'no frames for this traceback?'\n+        self.exc_type = exc_type\n+        self.exc_value = exc_value\n+        self.frames = frames\n+\n+        # newly concatenate the frames (which are proxies)\n+        prev_tb = None\n+        for tb in self.frames:\n+            if prev_tb is not None:\n+                prev_tb.set_next(tb)\n+            prev_tb = tb\n+        prev_tb.set_next(None)\n+\n+    def render_as_text(self, limit=None):\n+        \"\"\"Return a string with the traceback.\"\"\"\n+        lines = traceback.format_exception(self.exc_type, self.exc_value,\n+                                           self.frames[0], limit=limit)\n+        return ''.join(lines).rstrip()\n+\n+    def render_as_html(self, full=False):\n+        \"\"\"Return a unicode string with the traceback as rendered HTML.\"\"\"\n+        from jinja2.debugrenderer import render_traceback\n+        return u'%s\\n\\n<!--\\n%s\\n-->' % (\n+            render_traceback(self, full=full),\n+            self.render_as_text().decode('utf-8', 'replace')\n+        )\n+\n+    @property\n+    def is_template_syntax_error(self):\n+        \"\"\"`True` if this is a template syntax error.\"\"\"\n+        return isinstance(self.exc_value, TemplateSyntaxError)\n+\n+    @property\n+    def exc_info(self):\n+        \"\"\"Exception info tuple with a proxy around the frame objects.\"\"\"\n+        return self.exc_type, self.exc_value, self.frames[0]\n+\n+    @property\n+    def standard_exc_info(self):\n+        \"\"\"Standard python exc_info for re-raising\"\"\"\n+        tb = self.frames[0]\n+        # the frame will be an actual traceback (or transparent proxy) if\n+        # we are on pypy or a python implementation with support for tproxy\n+        if type(tb) is not TracebackType:\n+            tb = tb.tb\n+        return self.exc_type, self.exc_value, tb\n+\n+\n+def make_traceback(exc_info, source_hint=None):\n+    \"\"\"Creates a processed traceback object from the exc_info.\"\"\"\n+    exc_type, exc_value, tb = exc_info\n+    if isinstance(exc_value, TemplateSyntaxError):\n+        exc_info = translate_syntax_error(exc_value, source_hint)\n+        initial_skip = 0\n+    else:\n+        initial_skip = 1\n+    return translate_exception(exc_info, initial_skip)\n+\n+\n+def translate_syntax_error(error, source=None):\n+    \"\"\"Rewrites a syntax error to please traceback systems.\"\"\"\n+    error.source = source\n+    error.translated = True\n+    exc_info = (error.__class__, error, None)\n+    filename = error.filename\n+    if filename is None:\n+        filename = '<unknown>'\n+    return fake_exc_info(exc_info, filename, error.lineno)\n+\n+\n+def translate_exception(exc_info, initial_skip=0):\n+    \"\"\"If passed an exc_info it will automatically rewrite the exceptions\n+    all the way down to the correct line numbers and frames.\n+    \"\"\"\n+    tb = exc_info[2]\n+    frames = []\n+\n+    # skip some internal frames if wanted\n+    for x in range(initial_skip):\n+        if tb is not None:\n+            tb = tb.tb_next\n+    initial_tb = tb\n+\n+    while tb is not None:\n+        # skip frames decorated with @internalcode.  These are internal\n+        # calls we can't avoid and that are useless in template debugging\n+        # output.\n+        if tb.tb_frame.f_code in internal_code:\n+            tb = tb.tb_next\n+            continue\n+\n+        # save a reference to the next frame if we override the current\n+        # one with a faked one.\n+        next = tb.tb_next\n+\n+        # fake template exceptions\n+        template = tb.tb_frame.f_globals.get('__jinja_template__')\n+        if template is not None:\n+            lineno = template.get_corresponding_lineno(tb.tb_lineno)\n+            tb = fake_exc_info(exc_info[:2] + (tb,), template.filename,\n+                               lineno)[2]\n+\n+        frames.append(make_frame_proxy(tb))\n+        tb = next\n+\n+    # if we don't have any exceptions in the frames left, we have to\n+    # reraise it unchanged.\n+    # XXX: can we backup here?  when could this happen?\n+    if not frames:\n+        reraise(exc_info[0], exc_info[1], exc_info[2])\n+\n+    return ProcessedTraceback(exc_info[0], exc_info[1], frames)\n+\n+\n+def get_jinja_locals(real_locals):\n+    ctx = real_locals.get('context')\n+    if ctx:\n+        locals = ctx.get_all().copy()\n+    else:\n+        locals = {}\n+\n+    local_overrides = {}\n+\n+    for name, value in iteritems(real_locals):\n+        if not name.startswith('l_') or value is missing:\n+            continue\n+        try:\n+            _, depth, name = name.split('_', 2)\n+            depth = int(depth)\n+        except ValueError:\n+            continue\n+        cur_depth = local_overrides.get(name, (-1,))[0]\n+        if cur_depth < depth:\n+            local_overrides[name] = (depth, value)\n+\n+    for name, (_, value) in iteritems(local_overrides):\n+        if value is missing:\n+            locals.pop(name, None)\n+        else:\n+            locals[name] = value\n+\n+    return locals\n+\n+\n+def fake_exc_info(exc_info, filename, lineno):\n+    \"\"\"Helper for `translate_exception`.\"\"\"\n+    exc_type, exc_value, tb = exc_info\n+\n+    # figure the real context out\n+    if tb is not None:\n+        locals = get_jinja_locals(tb.tb_frame.f_locals)\n+\n+        # if there is a local called __jinja_exception__, we get\n+        # rid of it to not break the debug functionality.\n+        locals.pop('__jinja_exception__', None)\n+    else:\n+        locals = {}\n+\n+    # assamble fake globals we need\n+    globals = {\n+        '__name__':             filename,\n+        '__file__':             filename,\n+        '__jinja_exception__':  exc_info[:2],\n+\n+        # we don't want to keep the reference to the template around\n+        # to not cause circular dependencies, but we mark it as Jinja\n+        # frame for the ProcessedTraceback\n+        '__jinja_template__':   None\n+    }\n+\n+    # and fake the exception\n+    code = compile('\\n' * (lineno - 1) + raise_helper, filename, 'exec')\n+\n+    # if it's possible, change the name of the code.  This won't work\n+    # on some python environments such as google appengine\n+    try:\n+        if tb is None:\n+            location = 'template'\n+        else:\n+            function = tb.tb_frame.f_code.co_name\n+            if function == 'root':\n+                location = 'top-level template code'\n+            elif function.startswith('block_'):\n+                location = 'block \"%s\"' % function[6:]\n+            else:\n+                location = 'template'\n+\n+        if PY2:\n+            code = CodeType(0, code.co_nlocals, code.co_stacksize,\n+                            code.co_flags, code.co_code, code.co_consts,\n+                            code.co_names, code.co_varnames, filename,\n+                            location, code.co_firstlineno,\n+                            code.co_lnotab, (), ())\n+        else:\n+            code = CodeType(0, code.co_kwonlyargcount,\n+                            code.co_nlocals, code.co_stacksize,\n+                            code.co_flags, code.co_code, code.co_consts,\n+                            code.co_names, code.co_varnames, filename,\n+                            location, code.co_firstlineno,\n+                            code.co_lnotab, (), ())\n+    except Exception as e:\n+        pass\n+\n+    # execute the code and catch the new traceback\n+    try:\n+        exec(code, globals, locals)\n+    except:\n+        exc_info = sys.exc_info()\n+        new_tb = exc_info[2].tb_next\n+\n+    # return without this frame\n+    return exc_info[:2] + (new_tb,)\n+\n+\n+def _init_ugly_crap():\n+    \"\"\"This function implements a few ugly things so that we can patch the\n+    traceback objects.  The function returned allows resetting `tb_next` on\n+    any python traceback object.  Do not attempt to use this on non cpython\n+    interpreters\n+    \"\"\"\n+    import ctypes\n+    from types import TracebackType\n+\n+    if PY2:\n+        # figure out size of _Py_ssize_t for Python 2:\n+        if hasattr(ctypes.pythonapi, 'Py_InitModule4_64'):\n+            _Py_ssize_t = ctypes.c_int64\n+        else:\n+            _Py_ssize_t = ctypes.c_int\n+    else:\n+        # platform ssize_t on Python 3\n+        _Py_ssize_t = ctypes.c_ssize_t\n+\n+    # regular python\n+    class _PyObject(ctypes.Structure):\n+        pass\n+    _PyObject._fields_ = [\n+        ('ob_refcnt', _Py_ssize_t),\n+        ('ob_type', ctypes.POINTER(_PyObject))\n+    ]\n+\n+    # python with trace\n+    if hasattr(sys, 'getobjects'):\n+        class _PyObject(ctypes.Structure):\n+            pass\n+        _PyObject._fields_ = [\n+            ('_ob_next', ctypes.POINTER(_PyObject)),\n+            ('_ob_prev', ctypes.POINTER(_PyObject)),\n+            ('ob_refcnt', _Py_ssize_t),\n+            ('ob_type', ctypes.POINTER(_PyObject))\n+        ]\n+\n+    class _Traceback(_PyObject):\n+        pass\n+    _Traceback._fields_ = [\n+        ('tb_next', ctypes.POINTER(_Traceback)),\n+        ('tb_frame', ctypes.POINTER(_PyObject)),\n+        ('tb_lasti', ctypes.c_int),\n+        ('tb_lineno', ctypes.c_int)\n+    ]\n+\n+    def tb_set_next(tb, next):\n+        \"\"\"Set the tb_next attribute of a traceback object.\"\"\"\n+        if not (isinstance(tb, TracebackType) and\n+                (next is None or isinstance(next, TracebackType))):\n+            raise TypeError('tb_set_next arguments must be traceback objects')\n+        obj = _Traceback.from_address(id(tb))\n+        if tb.tb_next is not None:\n+            old = _Traceback.from_address(id(tb.tb_next))\n+            old.ob_refcnt -= 1\n+        if next is None:\n+            obj.tb_next = ctypes.POINTER(_Traceback)()\n+        else:\n+            next = _Traceback.from_address(id(next))\n+            next.ob_refcnt += 1\n+            obj.tb_next = ctypes.pointer(next)\n+\n+    return tb_set_next\n+\n+\n+# try to get a tb_set_next implementation if we don't have transparent\n+# proxies.\n+tb_set_next = None\n+if tproxy is None:\n+    try:\n+        tb_set_next = _init_ugly_crap()\n+    except:\n+        pass\n+    del _init_ugly_crap"
        },
        {
            "sha": "7c93dec0aeb202495ad4c3e7d25e2d11c507e775",
            "filename": "tools/jinja2/defaults.py",
            "status": "added",
            "additions": 56,
            "deletions": 0,
            "changes": 56,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fdefaults.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fdefaults.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fdefaults.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,56 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.defaults\n+    ~~~~~~~~~~~~~~~\n+\n+    Jinja default filters and tags.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+from jinja2._compat import range_type\n+from jinja2.utils import generate_lorem_ipsum, Cycler, Joiner, Namespace\n+\n+\n+# defaults for the parser / lexer\n+BLOCK_START_STRING = '{%'\n+BLOCK_END_STRING = '%}'\n+VARIABLE_START_STRING = '{{'\n+VARIABLE_END_STRING = '}}'\n+COMMENT_START_STRING = '{#'\n+COMMENT_END_STRING = '#}'\n+LINE_STATEMENT_PREFIX = None\n+LINE_COMMENT_PREFIX = None\n+TRIM_BLOCKS = False\n+LSTRIP_BLOCKS = False\n+NEWLINE_SEQUENCE = '\\n'\n+KEEP_TRAILING_NEWLINE = False\n+\n+\n+# default filters, tests and namespace\n+from jinja2.filters import FILTERS as DEFAULT_FILTERS\n+from jinja2.tests import TESTS as DEFAULT_TESTS\n+DEFAULT_NAMESPACE = {\n+    'range':        range_type,\n+    'dict':         dict,\n+    'lipsum':       generate_lorem_ipsum,\n+    'cycler':       Cycler,\n+    'joiner':       Joiner,\n+    'namespace':    Namespace\n+}\n+\n+\n+# default policies\n+DEFAULT_POLICIES = {\n+    'compiler.ascii_str':   True,\n+    'urlize.rel':           'noopener',\n+    'urlize.target':        None,\n+    'truncate.leeway':      5,\n+    'json.dumps_function':  None,\n+    'json.dumps_kwargs':    {'sort_keys': True},\n+    'ext.i18n.trimmed':     False,\n+}\n+\n+\n+# export all constants\n+__all__ = tuple(x for x in locals().keys() if x.isupper())"
        },
        {
            "sha": "549d9afab456b45032945fd47d5c2900e3797a1b",
            "filename": "tools/jinja2/environment.py",
            "status": "added",
            "additions": 1276,
            "deletions": 0,
            "changes": 1276,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fenvironment.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fenvironment.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fenvironment.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,1276 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.environment\n+    ~~~~~~~~~~~~~~~~~~\n+\n+    Provides a class that holds runtime and parsing time options.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+import os\n+import sys\n+import weakref\n+from functools import reduce, partial\n+from jinja2 import nodes\n+from jinja2.defaults import BLOCK_START_STRING, \\\n+     BLOCK_END_STRING, VARIABLE_START_STRING, VARIABLE_END_STRING, \\\n+     COMMENT_START_STRING, COMMENT_END_STRING, LINE_STATEMENT_PREFIX, \\\n+     LINE_COMMENT_PREFIX, TRIM_BLOCKS, NEWLINE_SEQUENCE, \\\n+     DEFAULT_FILTERS, DEFAULT_TESTS, DEFAULT_NAMESPACE, \\\n+     DEFAULT_POLICIES, KEEP_TRAILING_NEWLINE, LSTRIP_BLOCKS\n+from jinja2.lexer import get_lexer, TokenStream\n+from jinja2.parser import Parser\n+from jinja2.nodes import EvalContext\n+from jinja2.compiler import generate, CodeGenerator\n+from jinja2.runtime import Undefined, new_context, Context\n+from jinja2.exceptions import TemplateSyntaxError, TemplateNotFound, \\\n+     TemplatesNotFound, TemplateRuntimeError\n+from jinja2.utils import import_string, LRUCache, Markup, missing, \\\n+     concat, consume, internalcode, have_async_gen\n+from jinja2._compat import imap, ifilter, string_types, iteritems, \\\n+     text_type, reraise, implements_iterator, implements_to_string, \\\n+     encode_filename, PY2, PYPY\n+\n+\n+# for direct template usage we have up to ten living environments\n+_spontaneous_environments = LRUCache(10)\n+\n+# the function to create jinja traceback objects.  This is dynamically\n+# imported on the first exception in the exception handler.\n+_make_traceback = None\n+\n+\n+def get_spontaneous_environment(*args):\n+    \"\"\"Return a new spontaneous environment.  A spontaneous environment is an\n+    unnamed and unaccessible (in theory) environment that is used for\n+    templates generated from a string and not from the file system.\n+    \"\"\"\n+    try:\n+        env = _spontaneous_environments.get(args)\n+    except TypeError:\n+        return Environment(*args)\n+    if env is not None:\n+        return env\n+    _spontaneous_environments[args] = env = Environment(*args)\n+    env.shared = True\n+    return env\n+\n+\n+def create_cache(size):\n+    \"\"\"Return the cache class for the given size.\"\"\"\n+    if size == 0:\n+        return None\n+    if size < 0:\n+        return {}\n+    return LRUCache(size)\n+\n+\n+def copy_cache(cache):\n+    \"\"\"Create an empty copy of the given cache.\"\"\"\n+    if cache is None:\n+        return None\n+    elif type(cache) is dict:\n+        return {}\n+    return LRUCache(cache.capacity)\n+\n+\n+def load_extensions(environment, extensions):\n+    \"\"\"Load the extensions from the list and bind it to the environment.\n+    Returns a dict of instantiated environments.\n+    \"\"\"\n+    result = {}\n+    for extension in extensions:\n+        if isinstance(extension, string_types):\n+            extension = import_string(extension)\n+        result[extension.identifier] = extension(environment)\n+    return result\n+\n+\n+def fail_for_missing_callable(string, name):\n+    msg = string % name\n+    if isinstance(name, Undefined):\n+        try:\n+            name._fail_with_undefined_error()\n+        except Exception as e:\n+            msg = '%s (%s; did you forget to quote the callable name?)' % (msg, e)\n+    raise TemplateRuntimeError(msg)\n+\n+\n+def _environment_sanity_check(environment):\n+    \"\"\"Perform a sanity check on the environment.\"\"\"\n+    assert issubclass(environment.undefined, Undefined), 'undefined must ' \\\n+        'be a subclass of undefined because filters depend on it.'\n+    assert environment.block_start_string != \\\n+        environment.variable_start_string != \\\n+        environment.comment_start_string, 'block, variable and comment ' \\\n+        'start strings must be different'\n+    assert environment.newline_sequence in ('\\r', '\\r\\n', '\\n'), \\\n+        'newline_sequence set to unknown line ending string.'\n+    return environment\n+\n+\n+class Environment(object):\n+    r\"\"\"The core component of Jinja is the `Environment`.  It contains\n+    important shared variables like configuration, filters, tests,\n+    globals and others.  Instances of this class may be modified if\n+    they are not shared and if no template was loaded so far.\n+    Modifications on environments after the first template was loaded\n+    will lead to surprising effects and undefined behavior.\n+\n+    Here are the possible initialization parameters:\n+\n+        `block_start_string`\n+            The string marking the beginning of a block.  Defaults to ``'{%'``.\n+\n+        `block_end_string`\n+            The string marking the end of a block.  Defaults to ``'%}'``.\n+\n+        `variable_start_string`\n+            The string marking the beginning of a print statement.\n+            Defaults to ``'{{'``.\n+\n+        `variable_end_string`\n+            The string marking the end of a print statement.  Defaults to\n+            ``'}}'``.\n+\n+        `comment_start_string`\n+            The string marking the beginning of a comment.  Defaults to ``'{#'``.\n+\n+        `comment_end_string`\n+            The string marking the end of a comment.  Defaults to ``'#}'``.\n+\n+        `line_statement_prefix`\n+            If given and a string, this will be used as prefix for line based\n+            statements.  See also :ref:`line-statements`.\n+\n+        `line_comment_prefix`\n+            If given and a string, this will be used as prefix for line based\n+            comments.  See also :ref:`line-statements`.\n+\n+            .. versionadded:: 2.2\n+\n+        `trim_blocks`\n+            If this is set to ``True`` the first newline after a block is\n+            removed (block, not variable tag!).  Defaults to `False`.\n+\n+        `lstrip_blocks`\n+            If this is set to ``True`` leading spaces and tabs are stripped\n+            from the start of a line to a block.  Defaults to `False`.\n+\n+        `newline_sequence`\n+            The sequence that starts a newline.  Must be one of ``'\\r'``,\n+            ``'\\n'`` or ``'\\r\\n'``.  The default is ``'\\n'`` which is a\n+            useful default for Linux and OS X systems as well as web\n+            applications.\n+\n+        `keep_trailing_newline`\n+            Preserve the trailing newline when rendering templates.\n+            The default is ``False``, which causes a single newline,\n+            if present, to be stripped from the end of the template.\n+\n+            .. versionadded:: 2.7\n+\n+        `extensions`\n+            List of Jinja extensions to use.  This can either be import paths\n+            as strings or extension classes.  For more information have a\n+            look at :ref:`the extensions documentation <jinja-extensions>`.\n+\n+        `optimized`\n+            should the optimizer be enabled?  Default is ``True``.\n+\n+        `undefined`\n+            :class:`Undefined` or a subclass of it that is used to represent\n+            undefined values in the template.\n+\n+        `finalize`\n+            A callable that can be used to process the result of a variable\n+            expression before it is output.  For example one can convert\n+            ``None`` implicitly into an empty string here.\n+\n+        `autoescape`\n+            If set to ``True`` the XML/HTML autoescaping feature is enabled by\n+            default.  For more details about autoescaping see\n+            :class:`~jinja2.utils.Markup`.  As of Jinja 2.4 this can also\n+            be a callable that is passed the template name and has to\n+            return ``True`` or ``False`` depending on autoescape should be\n+            enabled by default.\n+\n+            .. versionchanged:: 2.4\n+               `autoescape` can now be a function\n+\n+        `loader`\n+            The template loader for this environment.\n+\n+        `cache_size`\n+            The size of the cache.  Per default this is ``400`` which means\n+            that if more than 400 templates are loaded the loader will clean\n+            out the least recently used template.  If the cache size is set to\n+            ``0`` templates are recompiled all the time, if the cache size is\n+            ``-1`` the cache will not be cleaned.\n+\n+            .. versionchanged:: 2.8\n+               The cache size was increased to 400 from a low 50.\n+\n+        `auto_reload`\n+            Some loaders load templates from locations where the template\n+            sources may change (ie: file system or database).  If\n+            ``auto_reload`` is set to ``True`` (default) every time a template is\n+            requested the loader checks if the source changed and if yes, it\n+            will reload the template.  For higher performance it's possible to\n+            disable that.\n+\n+        `bytecode_cache`\n+            If set to a bytecode cache object, this object will provide a\n+            cache for the internal Jinja bytecode so that templates don't\n+            have to be parsed if they were not changed.\n+\n+            See :ref:`bytecode-cache` for more information.\n+\n+        `enable_async`\n+            If set to true this enables async template execution which allows\n+            you to take advantage of newer Python features.  This requires\n+            Python 3.6 or later.\n+    \"\"\"\n+\n+    #: if this environment is sandboxed.  Modifying this variable won't make\n+    #: the environment sandboxed though.  For a real sandboxed environment\n+    #: have a look at jinja2.sandbox.  This flag alone controls the code\n+    #: generation by the compiler.\n+    sandboxed = False\n+\n+    #: True if the environment is just an overlay\n+    overlayed = False\n+\n+    #: the environment this environment is linked to if it is an overlay\n+    linked_to = None\n+\n+    #: shared environments have this set to `True`.  A shared environment\n+    #: must not be modified\n+    shared = False\n+\n+    #: these are currently EXPERIMENTAL undocumented features.\n+    exception_handler = None\n+    exception_formatter = None\n+\n+    #: the class that is used for code generation.  See\n+    #: :class:`~jinja2.compiler.CodeGenerator` for more information.\n+    code_generator_class = CodeGenerator\n+\n+    #: the context class thatis used for templates.  See\n+    #: :class:`~jinja2.runtime.Context` for more information.\n+    context_class = Context\n+\n+    def __init__(self,\n+                 block_start_string=BLOCK_START_STRING,\n+                 block_end_string=BLOCK_END_STRING,\n+                 variable_start_string=VARIABLE_START_STRING,\n+                 variable_end_string=VARIABLE_END_STRING,\n+                 comment_start_string=COMMENT_START_STRING,\n+                 comment_end_string=COMMENT_END_STRING,\n+                 line_statement_prefix=LINE_STATEMENT_PREFIX,\n+                 line_comment_prefix=LINE_COMMENT_PREFIX,\n+                 trim_blocks=TRIM_BLOCKS,\n+                 lstrip_blocks=LSTRIP_BLOCKS,\n+                 newline_sequence=NEWLINE_SEQUENCE,\n+                 keep_trailing_newline=KEEP_TRAILING_NEWLINE,\n+                 extensions=(),\n+                 optimized=True,\n+                 undefined=Undefined,\n+                 finalize=None,\n+                 autoescape=False,\n+                 loader=None,\n+                 cache_size=400,\n+                 auto_reload=True,\n+                 bytecode_cache=None,\n+                 enable_async=False):\n+        # !!Important notice!!\n+        #   The constructor accepts quite a few arguments that should be\n+        #   passed by keyword rather than position.  However it's important to\n+        #   not change the order of arguments because it's used at least\n+        #   internally in those cases:\n+        #       -   spontaneous environments (i18n extension and Template)\n+        #       -   unittests\n+        #   If parameter changes are required only add parameters at the end\n+        #   and don't change the arguments (or the defaults!) of the arguments\n+        #   existing already.\n+\n+        # lexer / parser information\n+        self.block_start_string = block_start_string\n+        self.block_end_string = block_end_string\n+        self.variable_start_string = variable_start_string\n+        self.variable_end_string = variable_end_string\n+        self.comment_start_string = comment_start_string\n+        self.comment_end_string = comment_end_string\n+        self.line_statement_prefix = line_statement_prefix\n+        self.line_comment_prefix = line_comment_prefix\n+        self.trim_blocks = trim_blocks\n+        self.lstrip_blocks = lstrip_blocks\n+        self.newline_sequence = newline_sequence\n+        self.keep_trailing_newline = keep_trailing_newline\n+\n+        # runtime information\n+        self.undefined = undefined\n+        self.optimized = optimized\n+        self.finalize = finalize\n+        self.autoescape = autoescape\n+\n+        # defaults\n+        self.filters = DEFAULT_FILTERS.copy()\n+        self.tests = DEFAULT_TESTS.copy()\n+        self.globals = DEFAULT_NAMESPACE.copy()\n+\n+        # set the loader provided\n+        self.loader = loader\n+        self.cache = create_cache(cache_size)\n+        self.bytecode_cache = bytecode_cache\n+        self.auto_reload = auto_reload\n+\n+        # configurable policies\n+        self.policies = DEFAULT_POLICIES.copy()\n+\n+        # load extensions\n+        self.extensions = load_extensions(self, extensions)\n+\n+        self.enable_async = enable_async\n+        self.is_async = self.enable_async and have_async_gen\n+\n+        _environment_sanity_check(self)\n+\n+    def add_extension(self, extension):\n+        \"\"\"Adds an extension after the environment was created.\n+\n+        .. versionadded:: 2.5\n+        \"\"\"\n+        self.extensions.update(load_extensions(self, [extension]))\n+\n+    def extend(self, **attributes):\n+        \"\"\"Add the items to the instance of the environment if they do not exist\n+        yet.  This is used by :ref:`extensions <writing-extensions>` to register\n+        callbacks and configuration values without breaking inheritance.\n+        \"\"\"\n+        for key, value in iteritems(attributes):\n+            if not hasattr(self, key):\n+                setattr(self, key, value)\n+\n+    def overlay(self, block_start_string=missing, block_end_string=missing,\n+                variable_start_string=missing, variable_end_string=missing,\n+                comment_start_string=missing, comment_end_string=missing,\n+                line_statement_prefix=missing, line_comment_prefix=missing,\n+                trim_blocks=missing, lstrip_blocks=missing,\n+                extensions=missing, optimized=missing,\n+                undefined=missing, finalize=missing, autoescape=missing,\n+                loader=missing, cache_size=missing, auto_reload=missing,\n+                bytecode_cache=missing):\n+        \"\"\"Create a new overlay environment that shares all the data with the\n+        current environment except for cache and the overridden attributes.\n+        Extensions cannot be removed for an overlayed environment.  An overlayed\n+        environment automatically gets all the extensions of the environment it\n+        is linked to plus optional extra extensions.\n+\n+        Creating overlays should happen after the initial environment was set\n+        up completely.  Not all attributes are truly linked, some are just\n+        copied over so modifications on the original environment may not shine\n+        through.\n+        \"\"\"\n+        args = dict(locals())\n+        del args['self'], args['cache_size'], args['extensions']\n+\n+        rv = object.__new__(self.__class__)\n+        rv.__dict__.update(self.__dict__)\n+        rv.overlayed = True\n+        rv.linked_to = self\n+\n+        for key, value in iteritems(args):\n+            if value is not missing:\n+                setattr(rv, key, value)\n+\n+        if cache_size is not missing:\n+            rv.cache = create_cache(cache_size)\n+        else:\n+            rv.cache = copy_cache(self.cache)\n+\n+        rv.extensions = {}\n+        for key, value in iteritems(self.extensions):\n+            rv.extensions[key] = value.bind(rv)\n+        if extensions is not missing:\n+            rv.extensions.update(load_extensions(rv, extensions))\n+\n+        return _environment_sanity_check(rv)\n+\n+    lexer = property(get_lexer, doc=\"The lexer for this environment.\")\n+\n+    def iter_extensions(self):\n+        \"\"\"Iterates over the extensions by priority.\"\"\"\n+        return iter(sorted(self.extensions.values(),\n+                           key=lambda x: x.priority))\n+\n+    def getitem(self, obj, argument):\n+        \"\"\"Get an item or attribute of an object but prefer the item.\"\"\"\n+        try:\n+            return obj[argument]\n+        except (AttributeError, TypeError, LookupError):\n+            if isinstance(argument, string_types):\n+                try:\n+                    attr = str(argument)\n+                except Exception:\n+                    pass\n+                else:\n+                    try:\n+                        return getattr(obj, attr)\n+                    except AttributeError:\n+                        pass\n+            return self.undefined(obj=obj, name=argument)\n+\n+    def getattr(self, obj, attribute):\n+        \"\"\"Get an item or attribute of an object but prefer the attribute.\n+        Unlike :meth:`getitem` the attribute *must* be a bytestring.\n+        \"\"\"\n+        try:\n+            return getattr(obj, attribute)\n+        except AttributeError:\n+            pass\n+        try:\n+            return obj[attribute]\n+        except (TypeError, LookupError, AttributeError):\n+            return self.undefined(obj=obj, name=attribute)\n+\n+    def call_filter(self, name, value, args=None, kwargs=None,\n+                    context=None, eval_ctx=None):\n+        \"\"\"Invokes a filter on a value the same way the compiler does it.\n+\n+        Note that on Python 3 this might return a coroutine in case the\n+        filter is running from an environment in async mode and the filter\n+        supports async execution.  It's your responsibility to await this\n+        if needed.\n+\n+        .. versionadded:: 2.7\n+        \"\"\"\n+        func = self.filters.get(name)\n+        if func is None:\n+            fail_for_missing_callable('no filter named %r', name)\n+        args = [value] + list(args or ())\n+        if getattr(func, 'contextfilter', False):\n+            if context is None:\n+                raise TemplateRuntimeError('Attempted to invoke context '\n+                                           'filter without context')\n+            args.insert(0, context)\n+        elif getattr(func, 'evalcontextfilter', False):\n+            if eval_ctx is None:\n+                if context is not None:\n+                    eval_ctx = context.eval_ctx\n+                else:\n+                    eval_ctx = EvalContext(self)\n+            args.insert(0, eval_ctx)\n+        elif getattr(func, 'environmentfilter', False):\n+            args.insert(0, self)\n+        return func(*args, **(kwargs or {}))\n+\n+    def call_test(self, name, value, args=None, kwargs=None):\n+        \"\"\"Invokes a test on a value the same way the compiler does it.\n+\n+        .. versionadded:: 2.7\n+        \"\"\"\n+        func = self.tests.get(name)\n+        if func is None:\n+            fail_for_missing_callable('no test named %r', name)\n+        return func(value, *(args or ()), **(kwargs or {}))\n+\n+    @internalcode\n+    def parse(self, source, name=None, filename=None):\n+        \"\"\"Parse the sourcecode and return the abstract syntax tree.  This\n+        tree of nodes is used by the compiler to convert the template into\n+        executable source- or bytecode.  This is useful for debugging or to\n+        extract information from templates.\n+\n+        If you are :ref:`developing Jinja2 extensions <writing-extensions>`\n+        this gives you a good overview of the node tree generated.\n+        \"\"\"\n+        try:\n+            return self._parse(source, name, filename)\n+        except TemplateSyntaxError:\n+            exc_info = sys.exc_info()\n+        self.handle_exception(exc_info, source_hint=source)\n+\n+    def _parse(self, source, name, filename):\n+        \"\"\"Internal parsing function used by `parse` and `compile`.\"\"\"\n+        return Parser(self, source, name, encode_filename(filename)).parse()\n+\n+    def lex(self, source, name=None, filename=None):\n+        \"\"\"Lex the given sourcecode and return a generator that yields\n+        tokens as tuples in the form ``(lineno, token_type, value)``.\n+        This can be useful for :ref:`extension development <writing-extensions>`\n+        and debugging templates.\n+\n+        This does not perform preprocessing.  If you want the preprocessing\n+        of the extensions to be applied you have to filter source through\n+        the :meth:`preprocess` method.\n+        \"\"\"\n+        source = text_type(source)\n+        try:\n+            return self.lexer.tokeniter(source, name, filename)\n+        except TemplateSyntaxError:\n+            exc_info = sys.exc_info()\n+        self.handle_exception(exc_info, source_hint=source)\n+\n+    def preprocess(self, source, name=None, filename=None):\n+        \"\"\"Preprocesses the source with all extensions.  This is automatically\n+        called for all parsing and compiling methods but *not* for :meth:`lex`\n+        because there you usually only want the actual source tokenized.\n+        \"\"\"\n+        return reduce(lambda s, e: e.preprocess(s, name, filename),\n+                      self.iter_extensions(), text_type(source))\n+\n+    def _tokenize(self, source, name, filename=None, state=None):\n+        \"\"\"Called by the parser to do the preprocessing and filtering\n+        for all the extensions.  Returns a :class:`~jinja2.lexer.TokenStream`.\n+        \"\"\"\n+        source = self.preprocess(source, name, filename)\n+        stream = self.lexer.tokenize(source, name, filename, state)\n+        for ext in self.iter_extensions():\n+            stream = ext.filter_stream(stream)\n+            if not isinstance(stream, TokenStream):\n+                stream = TokenStream(stream, name, filename)\n+        return stream\n+\n+    def _generate(self, source, name, filename, defer_init=False):\n+        \"\"\"Internal hook that can be overridden to hook a different generate\n+        method in.\n+\n+        .. versionadded:: 2.5\n+        \"\"\"\n+        return generate(source, self, name, filename, defer_init=defer_init,\n+                        optimized=self.optimized)\n+\n+    def _compile(self, source, filename):\n+        \"\"\"Internal hook that can be overridden to hook a different compile\n+        method in.\n+\n+        .. versionadded:: 2.5\n+        \"\"\"\n+        return compile(source, filename, 'exec')\n+\n+    @internalcode\n+    def compile(self, source, name=None, filename=None, raw=False,\n+                defer_init=False):\n+        \"\"\"Compile a node or template source code.  The `name` parameter is\n+        the load name of the template after it was joined using\n+        :meth:`join_path` if necessary, not the filename on the file system.\n+        the `filename` parameter is the estimated filename of the template on\n+        the file system.  If the template came from a database or memory this\n+        can be omitted.\n+\n+        The return value of this method is a python code object.  If the `raw`\n+        parameter is `True` the return value will be a string with python\n+        code equivalent to the bytecode returned otherwise.  This method is\n+        mainly used internally.\n+\n+        `defer_init` is use internally to aid the module code generator.  This\n+        causes the generated code to be able to import without the global\n+        environment variable to be set.\n+\n+        .. versionadded:: 2.4\n+           `defer_init` parameter added.\n+        \"\"\"\n+        source_hint = None\n+        try:\n+            if isinstance(source, string_types):\n+                source_hint = source\n+                source = self._parse(source, name, filename)\n+            source = self._generate(source, name, filename,\n+                                    defer_init=defer_init)\n+            if raw:\n+                return source\n+            if filename is None:\n+                filename = '<template>'\n+            else:\n+                filename = encode_filename(filename)\n+            return self._compile(source, filename)\n+        except TemplateSyntaxError:\n+            exc_info = sys.exc_info()\n+        self.handle_exception(exc_info, source_hint=source_hint)\n+\n+    def compile_expression(self, source, undefined_to_none=True):\n+        \"\"\"A handy helper method that returns a callable that accepts keyword\n+        arguments that appear as variables in the expression.  If called it\n+        returns the result of the expression.\n+\n+        This is useful if applications want to use the same rules as Jinja\n+        in template \"configuration files\" or similar situations.\n+\n+        Example usage:\n+\n+        >>> env = Environment()\n+        >>> expr = env.compile_expression('foo == 42')\n+        >>> expr(foo=23)\n+        False\n+        >>> expr(foo=42)\n+        True\n+\n+        Per default the return value is converted to `None` if the\n+        expression returns an undefined value.  This can be changed\n+        by setting `undefined_to_none` to `False`.\n+\n+        >>> env.compile_expression('var')() is None\n+        True\n+        >>> env.compile_expression('var', undefined_to_none=False)()\n+        Undefined\n+\n+        .. versionadded:: 2.1\n+        \"\"\"\n+        parser = Parser(self, source, state='variable')\n+        exc_info = None\n+        try:\n+            expr = parser.parse_expression()\n+            if not parser.stream.eos:\n+                raise TemplateSyntaxError('chunk after expression',\n+                                          parser.stream.current.lineno,\n+                                          None, None)\n+            expr.set_environment(self)\n+        except TemplateSyntaxError:\n+            exc_info = sys.exc_info()\n+        if exc_info is not None:\n+            self.handle_exception(exc_info, source_hint=source)\n+        body = [nodes.Assign(nodes.Name('result', 'store'), expr, lineno=1)]\n+        template = self.from_string(nodes.Template(body, lineno=1))\n+        return TemplateExpression(template, undefined_to_none)\n+\n+    def compile_templates(self, target, extensions=None, filter_func=None,\n+                          zip='deflated', log_function=None,\n+                          ignore_errors=True, py_compile=False):\n+        \"\"\"Finds all the templates the loader can find, compiles them\n+        and stores them in `target`.  If `zip` is `None`, instead of in a\n+        zipfile, the templates will be stored in a directory.\n+        By default a deflate zip algorithm is used. To switch to\n+        the stored algorithm, `zip` can be set to ``'stored'``.\n+\n+        `extensions` and `filter_func` are passed to :meth:`list_templates`.\n+        Each template returned will be compiled to the target folder or\n+        zipfile.\n+\n+        By default template compilation errors are ignored.  In case a\n+        log function is provided, errors are logged.  If you want template\n+        syntax errors to abort the compilation you can set `ignore_errors`\n+        to `False` and you will get an exception on syntax errors.\n+\n+        If `py_compile` is set to `True` .pyc files will be written to the\n+        target instead of standard .py files.  This flag does not do anything\n+        on pypy and Python 3 where pyc files are not picked up by itself and\n+        don't give much benefit.\n+\n+        .. versionadded:: 2.4\n+        \"\"\"\n+        from jinja2.loaders import ModuleLoader\n+\n+        if log_function is None:\n+            log_function = lambda x: None\n+\n+        if py_compile:\n+            if not PY2 or PYPY:\n+                from warnings import warn\n+                warn(Warning('py_compile has no effect on pypy or Python 3'))\n+                py_compile = False\n+            else:\n+                import imp\n+                import marshal\n+                py_header = imp.get_magic() + \\\n+                    u'\\xff\\xff\\xff\\xff'.encode('iso-8859-15')\n+\n+                # Python 3.3 added a source filesize to the header\n+                if sys.version_info >= (3, 3):\n+                    py_header += u'\\x00\\x00\\x00\\x00'.encode('iso-8859-15')\n+\n+        def write_file(filename, data, mode):\n+            if zip:\n+                info = ZipInfo(filename)\n+                info.external_attr = 0o755 << 16\n+                zip_file.writestr(info, data)\n+            else:\n+                f = open(os.path.join(target, filename), mode)\n+                try:\n+                    f.write(data)\n+                finally:\n+                    f.close()\n+\n+        if zip is not None:\n+            from zipfile import ZipFile, ZipInfo, ZIP_DEFLATED, ZIP_STORED\n+            zip_file = ZipFile(target, 'w', dict(deflated=ZIP_DEFLATED,\n+                                                 stored=ZIP_STORED)[zip])\n+            log_function('Compiling into Zip archive \"%s\"' % target)\n+        else:\n+            if not os.path.isdir(target):\n+                os.makedirs(target)\n+            log_function('Compiling into folder \"%s\"' % target)\n+\n+        try:\n+            for name in self.list_templates(extensions, filter_func):\n+                source, filename, _ = self.loader.get_source(self, name)\n+                try:\n+                    code = self.compile(source, name, filename, True, True)\n+                except TemplateSyntaxError as e:\n+                    if not ignore_errors:\n+                        raise\n+                    log_function('Could not compile \"%s\": %s' % (name, e))\n+                    continue\n+\n+                filename = ModuleLoader.get_module_filename(name)\n+\n+                if py_compile:\n+                    c = self._compile(code, encode_filename(filename))\n+                    write_file(filename + 'c', py_header +\n+                               marshal.dumps(c), 'wb')\n+                    log_function('Byte-compiled \"%s\" as %s' %\n+                                 (name, filename + 'c'))\n+                else:\n+                    write_file(filename, code, 'w')\n+                    log_function('Compiled \"%s\" as %s' % (name, filename))\n+        finally:\n+            if zip:\n+                zip_file.close()\n+\n+        log_function('Finished compiling templates')\n+\n+    def list_templates(self, extensions=None, filter_func=None):\n+        \"\"\"Returns a list of templates for this environment.  This requires\n+        that the loader supports the loader's\n+        :meth:`~BaseLoader.list_templates` method.\n+\n+        If there are other files in the template folder besides the\n+        actual templates, the returned list can be filtered.  There are two\n+        ways: either `extensions` is set to a list of file extensions for\n+        templates, or a `filter_func` can be provided which is a callable that\n+        is passed a template name and should return `True` if it should end up\n+        in the result list.\n+\n+        If the loader does not support that, a :exc:`TypeError` is raised.\n+\n+        .. versionadded:: 2.4\n+        \"\"\"\n+        x = self.loader.list_templates()\n+        if extensions is not None:\n+            if filter_func is not None:\n+                raise TypeError('either extensions or filter_func '\n+                                'can be passed, but not both')\n+            filter_func = lambda x: '.' in x and \\\n+                                    x.rsplit('.', 1)[1] in extensions\n+        if filter_func is not None:\n+            x = list(ifilter(filter_func, x))\n+        return x\n+\n+    def handle_exception(self, exc_info=None, rendered=False, source_hint=None):\n+        \"\"\"Exception handling helper.  This is used internally to either raise\n+        rewritten exceptions or return a rendered traceback for the template.\n+        \"\"\"\n+        global _make_traceback\n+        if exc_info is None:\n+            exc_info = sys.exc_info()\n+\n+        # the debugging module is imported when it's used for the first time.\n+        # we're doing a lot of stuff there and for applications that do not\n+        # get any exceptions in template rendering there is no need to load\n+        # all of that.\n+        if _make_traceback is None:\n+            from jinja2.debug import make_traceback as _make_traceback\n+        traceback = _make_traceback(exc_info, source_hint)\n+        if rendered and self.exception_formatter is not None:\n+            return self.exception_formatter(traceback)\n+        if self.exception_handler is not None:\n+            self.exception_handler(traceback)\n+        exc_type, exc_value, tb = traceback.standard_exc_info\n+        reraise(exc_type, exc_value, tb)\n+\n+    def join_path(self, template, parent):\n+        \"\"\"Join a template with the parent.  By default all the lookups are\n+        relative to the loader root so this method returns the `template`\n+        parameter unchanged, but if the paths should be relative to the\n+        parent template, this function can be used to calculate the real\n+        template name.\n+\n+        Subclasses may override this method and implement template path\n+        joining here.\n+        \"\"\"\n+        return template\n+\n+    @internalcode\n+    def _load_template(self, name, globals):\n+        if self.loader is None:\n+            raise TypeError('no loader for this environment specified')\n+        cache_key = (weakref.ref(self.loader), name)\n+        if self.cache is not None:\n+            template = self.cache.get(cache_key)\n+            if template is not None and (not self.auto_reload or\n+                                         template.is_up_to_date):\n+                return template\n+        template = self.loader.load(self, name, globals)\n+        if self.cache is not None:\n+            self.cache[cache_key] = template\n+        return template\n+\n+    @internalcode\n+    def get_template(self, name, parent=None, globals=None):\n+        \"\"\"Load a template from the loader.  If a loader is configured this\n+        method asks the loader for the template and returns a :class:`Template`.\n+        If the `parent` parameter is not `None`, :meth:`join_path` is called\n+        to get the real template name before loading.\n+\n+        The `globals` parameter can be used to provide template wide globals.\n+        These variables are available in the context at render time.\n+\n+        If the template does not exist a :exc:`TemplateNotFound` exception is\n+        raised.\n+\n+        .. versionchanged:: 2.4\n+           If `name` is a :class:`Template` object it is returned from the\n+           function unchanged.\n+        \"\"\"\n+        if isinstance(name, Template):\n+            return name\n+        if parent is not None:\n+            name = self.join_path(name, parent)\n+        return self._load_template(name, self.make_globals(globals))\n+\n+    @internalcode\n+    def select_template(self, names, parent=None, globals=None):\n+        \"\"\"Works like :meth:`get_template` but tries a number of templates\n+        before it fails.  If it cannot find any of the templates, it will\n+        raise a :exc:`TemplatesNotFound` exception.\n+\n+        .. versionadded:: 2.3\n+\n+        .. versionchanged:: 2.4\n+           If `names` contains a :class:`Template` object it is returned\n+           from the function unchanged.\n+        \"\"\"\n+        if not names:\n+            raise TemplatesNotFound(message=u'Tried to select from an empty list '\n+                                            u'of templates.')\n+        globals = self.make_globals(globals)\n+        for name in names:\n+            if isinstance(name, Template):\n+                return name\n+            if parent is not None:\n+                name = self.join_path(name, parent)\n+            try:\n+                return self._load_template(name, globals)\n+            except TemplateNotFound:\n+                pass\n+        raise TemplatesNotFound(names)\n+\n+    @internalcode\n+    def get_or_select_template(self, template_name_or_list,\n+                               parent=None, globals=None):\n+        \"\"\"Does a typecheck and dispatches to :meth:`select_template`\n+        if an iterable of template names is given, otherwise to\n+        :meth:`get_template`.\n+\n+        .. versionadded:: 2.3\n+        \"\"\"\n+        if isinstance(template_name_or_list, string_types):\n+            return self.get_template(template_name_or_list, parent, globals)\n+        elif isinstance(template_name_or_list, Template):\n+            return template_name_or_list\n+        return self.select_template(template_name_or_list, parent, globals)\n+\n+    def from_string(self, source, globals=None, template_class=None):\n+        \"\"\"Load a template from a string.  This parses the source given and\n+        returns a :class:`Template` object.\n+        \"\"\"\n+        globals = self.make_globals(globals)\n+        cls = template_class or self.template_class\n+        return cls.from_code(self, self.compile(source), globals, None)\n+\n+    def make_globals(self, d):\n+        \"\"\"Return a dict for the globals.\"\"\"\n+        if not d:\n+            return self.globals\n+        return dict(self.globals, **d)\n+\n+\n+class Template(object):\n+    \"\"\"The central template object.  This class represents a compiled template\n+    and is used to evaluate it.\n+\n+    Normally the template object is generated from an :class:`Environment` but\n+    it also has a constructor that makes it possible to create a template\n+    instance directly using the constructor.  It takes the same arguments as\n+    the environment constructor but it's not possible to specify a loader.\n+\n+    Every template object has a few methods and members that are guaranteed\n+    to exist.  However it's important that a template object should be\n+    considered immutable.  Modifications on the object are not supported.\n+\n+    Template objects created from the constructor rather than an environment\n+    do have an `environment` attribute that points to a temporary environment\n+    that is probably shared with other templates created with the constructor\n+    and compatible settings.\n+\n+    >>> template = Template('Hello {{ name }}!')\n+    >>> template.render(name='John Doe') == u'Hello John Doe!'\n+    True\n+    >>> stream = template.stream(name='John Doe')\n+    >>> next(stream) == u'Hello John Doe!'\n+    True\n+    >>> next(stream)\n+    Traceback (most recent call last):\n+        ...\n+    StopIteration\n+    \"\"\"\n+\n+    def __new__(cls, source,\n+                block_start_string=BLOCK_START_STRING,\n+                block_end_string=BLOCK_END_STRING,\n+                variable_start_string=VARIABLE_START_STRING,\n+                variable_end_string=VARIABLE_END_STRING,\n+                comment_start_string=COMMENT_START_STRING,\n+                comment_end_string=COMMENT_END_STRING,\n+                line_statement_prefix=LINE_STATEMENT_PREFIX,\n+                line_comment_prefix=LINE_COMMENT_PREFIX,\n+                trim_blocks=TRIM_BLOCKS,\n+                lstrip_blocks=LSTRIP_BLOCKS,\n+                newline_sequence=NEWLINE_SEQUENCE,\n+                keep_trailing_newline=KEEP_TRAILING_NEWLINE,\n+                extensions=(),\n+                optimized=True,\n+                undefined=Undefined,\n+                finalize=None,\n+                autoescape=False,\n+                enable_async=False):\n+        env = get_spontaneous_environment(\n+            block_start_string, block_end_string, variable_start_string,\n+            variable_end_string, comment_start_string, comment_end_string,\n+            line_statement_prefix, line_comment_prefix, trim_blocks,\n+            lstrip_blocks, newline_sequence, keep_trailing_newline,\n+            frozenset(extensions), optimized, undefined, finalize, autoescape,\n+            None, 0, False, None, enable_async)\n+        return env.from_string(source, template_class=cls)\n+\n+    @classmethod\n+    def from_code(cls, environment, code, globals, uptodate=None):\n+        \"\"\"Creates a template object from compiled code and the globals.  This\n+        is used by the loaders and environment to create a template object.\n+        \"\"\"\n+        namespace = {\n+            'environment':  environment,\n+            '__file__':     code.co_filename\n+        }\n+        exec(code, namespace)\n+        rv = cls._from_namespace(environment, namespace, globals)\n+        rv._uptodate = uptodate\n+        return rv\n+\n+    @classmethod\n+    def from_module_dict(cls, environment, module_dict, globals):\n+        \"\"\"Creates a template object from a module.  This is used by the\n+        module loader to create a template object.\n+\n+        .. versionadded:: 2.4\n+        \"\"\"\n+        return cls._from_namespace(environment, module_dict, globals)\n+\n+    @classmethod\n+    def _from_namespace(cls, environment, namespace, globals):\n+        t = object.__new__(cls)\n+        t.environment = environment\n+        t.globals = globals\n+        t.name = namespace['name']\n+        t.filename = namespace['__file__']\n+        t.blocks = namespace['blocks']\n+\n+        # render function and module\n+        t.root_render_func = namespace['root']\n+        t._module = None\n+\n+        # debug and loader helpers\n+        t._debug_info = namespace['debug_info']\n+        t._uptodate = None\n+\n+        # store the reference\n+        namespace['environment'] = environment\n+        namespace['__jinja_template__'] = t\n+\n+        return t\n+\n+    def render(self, *args, **kwargs):\n+        \"\"\"This method accepts the same arguments as the `dict` constructor:\n+        A dict, a dict subclass or some keyword arguments.  If no arguments\n+        are given the context will be empty.  These two calls do the same::\n+\n+            template.render(knights='that say nih')\n+            template.render({'knights': 'that say nih'})\n+\n+        This will return the rendered template as unicode string.\n+        \"\"\"\n+        vars = dict(*args, **kwargs)\n+        try:\n+            return concat(self.root_render_func(self.new_context(vars)))\n+        except Exception:\n+            exc_info = sys.exc_info()\n+        return self.environment.handle_exception(exc_info, True)\n+\n+    def render_async(self, *args, **kwargs):\n+        \"\"\"This works similar to :meth:`render` but returns a coroutine\n+        that when awaited returns the entire rendered template string.  This\n+        requires the async feature to be enabled.\n+\n+        Example usage::\n+\n+            await template.render_async(knights='that say nih; asynchronously')\n+        \"\"\"\n+        # see asyncsupport for the actual implementation\n+        raise NotImplementedError('This feature is not available for this '\n+                                  'version of Python')\n+\n+    def stream(self, *args, **kwargs):\n+        \"\"\"Works exactly like :meth:`generate` but returns a\n+        :class:`TemplateStream`.\n+        \"\"\"\n+        return TemplateStream(self.generate(*args, **kwargs))\n+\n+    def generate(self, *args, **kwargs):\n+        \"\"\"For very large templates it can be useful to not render the whole\n+        template at once but evaluate each statement after another and yield\n+        piece for piece.  This method basically does exactly that and returns\n+        a generator that yields one item after another as unicode strings.\n+\n+        It accepts the same arguments as :meth:`render`.\n+        \"\"\"\n+        vars = dict(*args, **kwargs)\n+        try:\n+            for event in self.root_render_func(self.new_context(vars)):\n+                yield event\n+        except Exception:\n+            exc_info = sys.exc_info()\n+        else:\n+            return\n+        yield self.environment.handle_exception(exc_info, True)\n+\n+    def generate_async(self, *args, **kwargs):\n+        \"\"\"An async version of :meth:`generate`.  Works very similarly but\n+        returns an async iterator instead.\n+        \"\"\"\n+        # see asyncsupport for the actual implementation\n+        raise NotImplementedError('This feature is not available for this '\n+                                  'version of Python')\n+\n+    def new_context(self, vars=None, shared=False, locals=None):\n+        \"\"\"Create a new :class:`Context` for this template.  The vars\n+        provided will be passed to the template.  Per default the globals\n+        are added to the context.  If shared is set to `True` the data\n+        is passed as it to the context without adding the globals.\n+\n+        `locals` can be a dict of local variables for internal usage.\n+        \"\"\"\n+        return new_context(self.environment, self.name, self.blocks,\n+                           vars, shared, self.globals, locals)\n+\n+    def make_module(self, vars=None, shared=False, locals=None):\n+        \"\"\"This method works like the :attr:`module` attribute when called\n+        without arguments but it will evaluate the template on every call\n+        rather than caching it.  It's also possible to provide\n+        a dict which is then used as context.  The arguments are the same\n+        as for the :meth:`new_context` method.\n+        \"\"\"\n+        return TemplateModule(self, self.new_context(vars, shared, locals))\n+\n+    def make_module_async(self, vars=None, shared=False, locals=None):\n+        \"\"\"As template module creation can invoke template code for\n+        asynchronous exections this method must be used instead of the\n+        normal :meth:`make_module` one.  Likewise the module attribute\n+        becomes unavailable in async mode.\n+        \"\"\"\n+        # see asyncsupport for the actual implementation\n+        raise NotImplementedError('This feature is not available for this '\n+                                  'version of Python')\n+\n+    @internalcode\n+    def _get_default_module(self):\n+        if self._module is not None:\n+            return self._module\n+        self._module = rv = self.make_module()\n+        return rv\n+\n+    @property\n+    def module(self):\n+        \"\"\"The template as module.  This is used for imports in the\n+        template runtime but is also useful if one wants to access\n+        exported template variables from the Python layer:\n+\n+        >>> t = Template('{% macro foo() %}42{% endmacro %}23')\n+        >>> str(t.module)\n+        '23'\n+        >>> t.module.foo() == u'42'\n+        True\n+\n+        This attribute is not available if async mode is enabled.\n+        \"\"\"\n+        return self._get_default_module()\n+\n+    def get_corresponding_lineno(self, lineno):\n+        \"\"\"Return the source line number of a line number in the\n+        generated bytecode as they are not in sync.\n+        \"\"\"\n+        for template_line, code_line in reversed(self.debug_info):\n+            if code_line <= lineno:\n+                return template_line\n+        return 1\n+\n+    @property\n+    def is_up_to_date(self):\n+        \"\"\"If this variable is `False` there is a newer version available.\"\"\"\n+        if self._uptodate is None:\n+            return True\n+        return self._uptodate()\n+\n+    @property\n+    def debug_info(self):\n+        \"\"\"The debug info mapping.\"\"\"\n+        return [tuple(imap(int, x.split('='))) for x in\n+                self._debug_info.split('&')]\n+\n+    def __repr__(self):\n+        if self.name is None:\n+            name = 'memory:%x' % id(self)\n+        else:\n+            name = repr(self.name)\n+        return '<%s %s>' % (self.__class__.__name__, name)\n+\n+\n+@implements_to_string\n+class TemplateModule(object):\n+    \"\"\"Represents an imported template.  All the exported names of the\n+    template are available as attributes on this object.  Additionally\n+    converting it into an unicode- or bytestrings renders the contents.\n+    \"\"\"\n+\n+    def __init__(self, template, context, body_stream=None):\n+        if body_stream is None:\n+            if context.environment.is_async:\n+                raise RuntimeError('Async mode requires a body stream '\n+                                   'to be passed to a template module.  Use '\n+                                   'the async methods of the API you are '\n+                                   'using.')\n+            body_stream = list(template.root_render_func(context))\n+        self._body_stream = body_stream\n+        self.__dict__.update(context.get_exported())\n+        self.__name__ = template.name\n+\n+    def __html__(self):\n+        return Markup(concat(self._body_stream))\n+\n+    def __str__(self):\n+        return concat(self._body_stream)\n+\n+    def __repr__(self):\n+        if self.__name__ is None:\n+            name = 'memory:%x' % id(self)\n+        else:\n+            name = repr(self.__name__)\n+        return '<%s %s>' % (self.__class__.__name__, name)\n+\n+\n+class TemplateExpression(object):\n+    \"\"\"The :meth:`jinja2.Environment.compile_expression` method returns an\n+    instance of this object.  It encapsulates the expression-like access\n+    to the template with an expression it wraps.\n+    \"\"\"\n+\n+    def __init__(self, template, undefined_to_none):\n+        self._template = template\n+        self._undefined_to_none = undefined_to_none\n+\n+    def __call__(self, *args, **kwargs):\n+        context = self._template.new_context(dict(*args, **kwargs))\n+        consume(self._template.root_render_func(context))\n+        rv = context.vars['result']\n+        if self._undefined_to_none and isinstance(rv, Undefined):\n+            rv = None\n+        return rv\n+\n+\n+@implements_iterator\n+class TemplateStream(object):\n+    \"\"\"A template stream works pretty much like an ordinary python generator\n+    but it can buffer multiple items to reduce the number of total iterations.\n+    Per default the output is unbuffered which means that for every unbuffered\n+    instruction in the template one unicode string is yielded.\n+\n+    If buffering is enabled with a buffer size of 5, five items are combined\n+    into a new unicode string.  This is mainly useful if you are streaming\n+    big templates to a client via WSGI which flushes after each iteration.\n+    \"\"\"\n+\n+    def __init__(self, gen):\n+        self._gen = gen\n+        self.disable_buffering()\n+\n+    def dump(self, fp, encoding=None, errors='strict'):\n+        \"\"\"Dump the complete stream into a file or file-like object.\n+        Per default unicode strings are written, if you want to encode\n+        before writing specify an `encoding`.\n+\n+        Example usage::\n+\n+            Template('Hello {{ name }}!').stream(name='foo').dump('hello.html')\n+        \"\"\"\n+        close = False\n+        if isinstance(fp, string_types):\n+            if encoding is None:\n+                encoding = 'utf-8'\n+            fp = open(fp, 'wb')\n+            close = True\n+        try:\n+            if encoding is not None:\n+                iterable = (x.encode(encoding, errors) for x in self)\n+            else:\n+                iterable = self\n+            if hasattr(fp, 'writelines'):\n+                fp.writelines(iterable)\n+            else:\n+                for item in iterable:\n+                    fp.write(item)\n+        finally:\n+            if close:\n+                fp.close()\n+\n+    def disable_buffering(self):\n+        \"\"\"Disable the output buffering.\"\"\"\n+        self._next = partial(next, self._gen)\n+        self.buffered = False\n+\n+    def _buffered_generator(self, size):\n+        buf = []\n+        c_size = 0\n+        push = buf.append\n+\n+        while 1:\n+            try:\n+                while c_size < size:\n+                    c = next(self._gen)\n+                    push(c)\n+                    if c:\n+                        c_size += 1\n+            except StopIteration:\n+                if not c_size:\n+                    return\n+            yield concat(buf)\n+            del buf[:]\n+            c_size = 0\n+\n+    def enable_buffering(self, size=5):\n+        \"\"\"Enable buffering.  Buffer `size` items before yielding them.\"\"\"\n+        if size <= 1:\n+            raise ValueError('buffer size too small')\n+\n+        self.buffered = True\n+        self._next = partial(next, self._buffered_generator(size))\n+\n+    def __iter__(self):\n+        return self\n+\n+    def __next__(self):\n+        return self._next()\n+\n+\n+# hook in default template class.  if anyone reads this comment: ignore that\n+# it's possible to use custom templates ;-)\n+Environment.template_class = Template"
        },
        {
            "sha": "c018a33e323cc5682900e5be3bd0daf2c25bdda6",
            "filename": "tools/jinja2/exceptions.py",
            "status": "added",
            "additions": 146,
            "deletions": 0,
            "changes": 146,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fexceptions.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fexceptions.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fexceptions.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,146 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.exceptions\n+    ~~~~~~~~~~~~~~~~~\n+\n+    Jinja exceptions.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+from jinja2._compat import imap, text_type, PY2, implements_to_string\n+\n+\n+class TemplateError(Exception):\n+    \"\"\"Baseclass for all template errors.\"\"\"\n+\n+    if PY2:\n+        def __init__(self, message=None):\n+            if message is not None:\n+                message = text_type(message).encode('utf-8')\n+            Exception.__init__(self, message)\n+\n+        @property\n+        def message(self):\n+            if self.args:\n+                message = self.args[0]\n+                if message is not None:\n+                    return message.decode('utf-8', 'replace')\n+\n+        def __unicode__(self):\n+            return self.message or u''\n+    else:\n+        def __init__(self, message=None):\n+            Exception.__init__(self, message)\n+\n+        @property\n+        def message(self):\n+            if self.args:\n+                message = self.args[0]\n+                if message is not None:\n+                    return message\n+\n+\n+@implements_to_string\n+class TemplateNotFound(IOError, LookupError, TemplateError):\n+    \"\"\"Raised if a template does not exist.\"\"\"\n+\n+    # looks weird, but removes the warning descriptor that just\n+    # bogusly warns us about message being deprecated\n+    message = None\n+\n+    def __init__(self, name, message=None):\n+        IOError.__init__(self)\n+        if message is None:\n+            message = name\n+        self.message = message\n+        self.name = name\n+        self.templates = [name]\n+\n+    def __str__(self):\n+        return self.message\n+\n+\n+class TemplatesNotFound(TemplateNotFound):\n+    \"\"\"Like :class:`TemplateNotFound` but raised if multiple templates\n+    are selected.  This is a subclass of :class:`TemplateNotFound`\n+    exception, so just catching the base exception will catch both.\n+\n+    .. versionadded:: 2.2\n+    \"\"\"\n+\n+    def __init__(self, names=(), message=None):\n+        if message is None:\n+            message = u'none of the templates given were found: ' + \\\n+                      u', '.join(imap(text_type, names))\n+        TemplateNotFound.__init__(self, names and names[-1] or None, message)\n+        self.templates = list(names)\n+\n+\n+@implements_to_string\n+class TemplateSyntaxError(TemplateError):\n+    \"\"\"Raised to tell the user that there is a problem with the template.\"\"\"\n+\n+    def __init__(self, message, lineno, name=None, filename=None):\n+        TemplateError.__init__(self, message)\n+        self.lineno = lineno\n+        self.name = name\n+        self.filename = filename\n+        self.source = None\n+\n+        # this is set to True if the debug.translate_syntax_error\n+        # function translated the syntax error into a new traceback\n+        self.translated = False\n+\n+    def __str__(self):\n+        # for translated errors we only return the message\n+        if self.translated:\n+            return self.message\n+\n+        # otherwise attach some stuff\n+        location = 'line %d' % self.lineno\n+        name = self.filename or self.name\n+        if name:\n+            location = 'File \"%s\", %s' % (name, location)\n+        lines = [self.message, '  ' + location]\n+\n+        # if the source is set, add the line to the output\n+        if self.source is not None:\n+            try:\n+                line = self.source.splitlines()[self.lineno - 1]\n+            except IndexError:\n+                line = None\n+            if line:\n+                lines.append('    ' + line.strip())\n+\n+        return u'\\n'.join(lines)\n+\n+\n+class TemplateAssertionError(TemplateSyntaxError):\n+    \"\"\"Like a template syntax error, but covers cases where something in the\n+    template caused an error at compile time that wasn't necessarily caused\n+    by a syntax error.  However it's a direct subclass of\n+    :exc:`TemplateSyntaxError` and has the same attributes.\n+    \"\"\"\n+\n+\n+class TemplateRuntimeError(TemplateError):\n+    \"\"\"A generic runtime error in the template engine.  Under some situations\n+    Jinja may raise this exception.\n+    \"\"\"\n+\n+\n+class UndefinedError(TemplateRuntimeError):\n+    \"\"\"Raised if a template tries to operate on :class:`Undefined`.\"\"\"\n+\n+\n+class SecurityError(TemplateRuntimeError):\n+    \"\"\"Raised if a template tries to do something insecure if the\n+    sandbox is enabled.\n+    \"\"\"\n+\n+\n+class FilterArgumentError(TemplateRuntimeError):\n+    \"\"\"This error is raised if a filter was called with inappropriate\n+    arguments\n+    \"\"\""
        },
        {
            "sha": "0734a84f73d0ddb735a004c9e0416e018a7d50bd",
            "filename": "tools/jinja2/ext.py",
            "status": "added",
            "additions": 627,
            "deletions": 0,
            "changes": 627,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fext.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fext.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fext.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,627 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.ext\n+    ~~~~~~~~~~\n+\n+    Jinja extensions allow to add custom tags similar to the way django custom\n+    tags work.  By default two example extensions exist: an i18n and a cache\n+    extension.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD.\n+\"\"\"\n+import re\n+\n+from jinja2 import nodes\n+from jinja2.defaults import BLOCK_START_STRING, \\\n+     BLOCK_END_STRING, VARIABLE_START_STRING, VARIABLE_END_STRING, \\\n+     COMMENT_START_STRING, COMMENT_END_STRING, LINE_STATEMENT_PREFIX, \\\n+     LINE_COMMENT_PREFIX, TRIM_BLOCKS, NEWLINE_SEQUENCE, \\\n+     KEEP_TRAILING_NEWLINE, LSTRIP_BLOCKS\n+from jinja2.environment import Environment\n+from jinja2.runtime import concat\n+from jinja2.exceptions import TemplateAssertionError, TemplateSyntaxError\n+from jinja2.utils import contextfunction, import_string, Markup\n+from jinja2._compat import with_metaclass, string_types, iteritems\n+\n+\n+# the only real useful gettext functions for a Jinja template.  Note\n+# that ugettext must be assigned to gettext as Jinja doesn't support\n+# non unicode strings.\n+GETTEXT_FUNCTIONS = ('_', 'gettext', 'ngettext')\n+\n+\n+class ExtensionRegistry(type):\n+    \"\"\"Gives the extension an unique identifier.\"\"\"\n+\n+    def __new__(cls, name, bases, d):\n+        rv = type.__new__(cls, name, bases, d)\n+        rv.identifier = rv.__module__ + '.' + rv.__name__\n+        return rv\n+\n+\n+class Extension(with_metaclass(ExtensionRegistry, object)):\n+    \"\"\"Extensions can be used to add extra functionality to the Jinja template\n+    system at the parser level.  Custom extensions are bound to an environment\n+    but may not store environment specific data on `self`.  The reason for\n+    this is that an extension can be bound to another environment (for\n+    overlays) by creating a copy and reassigning the `environment` attribute.\n+\n+    As extensions are created by the environment they cannot accept any\n+    arguments for configuration.  One may want to work around that by using\n+    a factory function, but that is not possible as extensions are identified\n+    by their import name.  The correct way to configure the extension is\n+    storing the configuration values on the environment.  Because this way the\n+    environment ends up acting as central configuration storage the\n+    attributes may clash which is why extensions have to ensure that the names\n+    they choose for configuration are not too generic.  ``prefix`` for example\n+    is a terrible name, ``fragment_cache_prefix`` on the other hand is a good\n+    name as includes the name of the extension (fragment cache).\n+    \"\"\"\n+\n+    #: if this extension parses this is the list of tags it's listening to.\n+    tags = set()\n+\n+    #: the priority of that extension.  This is especially useful for\n+    #: extensions that preprocess values.  A lower value means higher\n+    #: priority.\n+    #:\n+    #: .. versionadded:: 2.4\n+    priority = 100\n+\n+    def __init__(self, environment):\n+        self.environment = environment\n+\n+    def bind(self, environment):\n+        \"\"\"Create a copy of this extension bound to another environment.\"\"\"\n+        rv = object.__new__(self.__class__)\n+        rv.__dict__.update(self.__dict__)\n+        rv.environment = environment\n+        return rv\n+\n+    def preprocess(self, source, name, filename=None):\n+        \"\"\"This method is called before the actual lexing and can be used to\n+        preprocess the source.  The `filename` is optional.  The return value\n+        must be the preprocessed source.\n+        \"\"\"\n+        return source\n+\n+    def filter_stream(self, stream):\n+        \"\"\"It's passed a :class:`~jinja2.lexer.TokenStream` that can be used\n+        to filter tokens returned.  This method has to return an iterable of\n+        :class:`~jinja2.lexer.Token`\\\\s, but it doesn't have to return a\n+        :class:`~jinja2.lexer.TokenStream`.\n+\n+        In the `ext` folder of the Jinja2 source distribution there is a file\n+        called `inlinegettext.py` which implements a filter that utilizes this\n+        method.\n+        \"\"\"\n+        return stream\n+\n+    def parse(self, parser):\n+        \"\"\"If any of the :attr:`tags` matched this method is called with the\n+        parser as first argument.  The token the parser stream is pointing at\n+        is the name token that matched.  This method has to return one or a\n+        list of multiple nodes.\n+        \"\"\"\n+        raise NotImplementedError()\n+\n+    def attr(self, name, lineno=None):\n+        \"\"\"Return an attribute node for the current extension.  This is useful\n+        to pass constants on extensions to generated template code.\n+\n+        ::\n+\n+            self.attr('_my_attribute', lineno=lineno)\n+        \"\"\"\n+        return nodes.ExtensionAttribute(self.identifier, name, lineno=lineno)\n+\n+    def call_method(self, name, args=None, kwargs=None, dyn_args=None,\n+                    dyn_kwargs=None, lineno=None):\n+        \"\"\"Call a method of the extension.  This is a shortcut for\n+        :meth:`attr` + :class:`jinja2.nodes.Call`.\n+        \"\"\"\n+        if args is None:\n+            args = []\n+        if kwargs is None:\n+            kwargs = []\n+        return nodes.Call(self.attr(name, lineno=lineno), args, kwargs,\n+                          dyn_args, dyn_kwargs, lineno=lineno)\n+\n+\n+@contextfunction\n+def _gettext_alias(__context, *args, **kwargs):\n+    return __context.call(__context.resolve('gettext'), *args, **kwargs)\n+\n+\n+def _make_new_gettext(func):\n+    @contextfunction\n+    def gettext(__context, __string, **variables):\n+        rv = __context.call(func, __string)\n+        if __context.eval_ctx.autoescape:\n+            rv = Markup(rv)\n+        return rv % variables\n+    return gettext\n+\n+\n+def _make_new_ngettext(func):\n+    @contextfunction\n+    def ngettext(__context, __singular, __plural, __num, **variables):\n+        variables.setdefault('num', __num)\n+        rv = __context.call(func, __singular, __plural, __num)\n+        if __context.eval_ctx.autoescape:\n+            rv = Markup(rv)\n+        return rv % variables\n+    return ngettext\n+\n+\n+class InternationalizationExtension(Extension):\n+    \"\"\"This extension adds gettext support to Jinja2.\"\"\"\n+    tags = set(['trans'])\n+\n+    # TODO: the i18n extension is currently reevaluating values in a few\n+    # situations.  Take this example:\n+    #   {% trans count=something() %}{{ count }} foo{% pluralize\n+    #     %}{{ count }} fooss{% endtrans %}\n+    # something is called twice here.  One time for the gettext value and\n+    # the other time for the n-parameter of the ngettext function.\n+\n+    def __init__(self, environment):\n+        Extension.__init__(self, environment)\n+        environment.globals['_'] = _gettext_alias\n+        environment.extend(\n+            install_gettext_translations=self._install,\n+            install_null_translations=self._install_null,\n+            install_gettext_callables=self._install_callables,\n+            uninstall_gettext_translations=self._uninstall,\n+            extract_translations=self._extract,\n+            newstyle_gettext=False\n+        )\n+\n+    def _install(self, translations, newstyle=None):\n+        gettext = getattr(translations, 'ugettext', None)\n+        if gettext is None:\n+            gettext = translations.gettext\n+        ngettext = getattr(translations, 'ungettext', None)\n+        if ngettext is None:\n+            ngettext = translations.ngettext\n+        self._install_callables(gettext, ngettext, newstyle)\n+\n+    def _install_null(self, newstyle=None):\n+        self._install_callables(\n+            lambda x: x,\n+            lambda s, p, n: (n != 1 and (p,) or (s,))[0],\n+            newstyle\n+        )\n+\n+    def _install_callables(self, gettext, ngettext, newstyle=None):\n+        if newstyle is not None:\n+            self.environment.newstyle_gettext = newstyle\n+        if self.environment.newstyle_gettext:\n+            gettext = _make_new_gettext(gettext)\n+            ngettext = _make_new_ngettext(ngettext)\n+        self.environment.globals.update(\n+            gettext=gettext,\n+            ngettext=ngettext\n+        )\n+\n+    def _uninstall(self, translations):\n+        for key in 'gettext', 'ngettext':\n+            self.environment.globals.pop(key, None)\n+\n+    def _extract(self, source, gettext_functions=GETTEXT_FUNCTIONS):\n+        if isinstance(source, string_types):\n+            source = self.environment.parse(source)\n+        return extract_from_ast(source, gettext_functions)\n+\n+    def parse(self, parser):\n+        \"\"\"Parse a translatable tag.\"\"\"\n+        lineno = next(parser.stream).lineno\n+        num_called_num = False\n+\n+        # find all the variables referenced.  Additionally a variable can be\n+        # defined in the body of the trans block too, but this is checked at\n+        # a later state.\n+        plural_expr = None\n+        plural_expr_assignment = None\n+        variables = {}\n+        trimmed = None\n+        while parser.stream.current.type != 'block_end':\n+            if variables:\n+                parser.stream.expect('comma')\n+\n+            # skip colon for python compatibility\n+            if parser.stream.skip_if('colon'):\n+                break\n+\n+            name = parser.stream.expect('name')\n+            if name.value in variables:\n+                parser.fail('translatable variable %r defined twice.' %\n+                            name.value, name.lineno,\n+                            exc=TemplateAssertionError)\n+\n+            # expressions\n+            if parser.stream.current.type == 'assign':\n+                next(parser.stream)\n+                variables[name.value] = var = parser.parse_expression()\n+            elif trimmed is None and name.value in ('trimmed', 'notrimmed'):\n+                trimmed = name.value == 'trimmed'\n+                continue\n+            else:\n+                variables[name.value] = var = nodes.Name(name.value, 'load')\n+\n+            if plural_expr is None:\n+                if isinstance(var, nodes.Call):\n+                    plural_expr = nodes.Name('_trans', 'load')\n+                    variables[name.value] = plural_expr\n+                    plural_expr_assignment = nodes.Assign(\n+                        nodes.Name('_trans', 'store'), var)\n+                else:\n+                    plural_expr = var\n+                num_called_num = name.value == 'num'\n+\n+        parser.stream.expect('block_end')\n+\n+        plural = None\n+        have_plural = False\n+        referenced = set()\n+\n+        # now parse until endtrans or pluralize\n+        singular_names, singular = self._parse_block(parser, True)\n+        if singular_names:\n+            referenced.update(singular_names)\n+            if plural_expr is None:\n+                plural_expr = nodes.Name(singular_names[0], 'load')\n+                num_called_num = singular_names[0] == 'num'\n+\n+        # if we have a pluralize block, we parse that too\n+        if parser.stream.current.test('name:pluralize'):\n+            have_plural = True\n+            next(parser.stream)\n+            if parser.stream.current.type != 'block_end':\n+                name = parser.stream.expect('name')\n+                if name.value not in variables:\n+                    parser.fail('unknown variable %r for pluralization' %\n+                                name.value, name.lineno,\n+                                exc=TemplateAssertionError)\n+                plural_expr = variables[name.value]\n+                num_called_num = name.value == 'num'\n+            parser.stream.expect('block_end')\n+            plural_names, plural = self._parse_block(parser, False)\n+            next(parser.stream)\n+            referenced.update(plural_names)\n+        else:\n+            next(parser.stream)\n+\n+        # register free names as simple name expressions\n+        for var in referenced:\n+            if var not in variables:\n+                variables[var] = nodes.Name(var, 'load')\n+\n+        if not have_plural:\n+            plural_expr = None\n+        elif plural_expr is None:\n+            parser.fail('pluralize without variables', lineno)\n+\n+        if trimmed is None:\n+            trimmed = self.environment.policies['ext.i18n.trimmed']\n+        if trimmed:\n+            singular = self._trim_whitespace(singular)\n+            if plural:\n+                plural = self._trim_whitespace(plural)\n+\n+        node = self._make_node(singular, plural, variables, plural_expr,\n+                               bool(referenced),\n+                               num_called_num and have_plural)\n+        node.set_lineno(lineno)\n+        if plural_expr_assignment is not None:\n+            return [plural_expr_assignment, node]\n+        else:\n+            return node\n+\n+    def _trim_whitespace(self, string, _ws_re=re.compile(r'\\s*\\n\\s*')):\n+        return _ws_re.sub(' ', string.strip())\n+\n+    def _parse_block(self, parser, allow_pluralize):\n+        \"\"\"Parse until the next block tag with a given name.\"\"\"\n+        referenced = []\n+        buf = []\n+        while 1:\n+            if parser.stream.current.type == 'data':\n+                buf.append(parser.stream.current.value.replace('%', '%%'))\n+                next(parser.stream)\n+            elif parser.stream.current.type == 'variable_begin':\n+                next(parser.stream)\n+                name = parser.stream.expect('name').value\n+                referenced.append(name)\n+                buf.append('%%(%s)s' % name)\n+                parser.stream.expect('variable_end')\n+            elif parser.stream.current.type == 'block_begin':\n+                next(parser.stream)\n+                if parser.stream.current.test('name:endtrans'):\n+                    break\n+                elif parser.stream.current.test('name:pluralize'):\n+                    if allow_pluralize:\n+                        break\n+                    parser.fail('a translatable section can have only one '\n+                                'pluralize section')\n+                parser.fail('control structures in translatable sections are '\n+                            'not allowed')\n+            elif parser.stream.eos:\n+                parser.fail('unclosed translation block')\n+            else:\n+                assert False, 'internal parser error'\n+\n+        return referenced, concat(buf)\n+\n+    def _make_node(self, singular, plural, variables, plural_expr,\n+                   vars_referenced, num_called_num):\n+        \"\"\"Generates a useful node from the data provided.\"\"\"\n+        # no variables referenced?  no need to escape for old style\n+        # gettext invocations only if there are vars.\n+        if not vars_referenced and not self.environment.newstyle_gettext:\n+            singular = singular.replace('%%', '%')\n+            if plural:\n+                plural = plural.replace('%%', '%')\n+\n+        # singular only:\n+        if plural_expr is None:\n+            gettext = nodes.Name('gettext', 'load')\n+            node = nodes.Call(gettext, [nodes.Const(singular)],\n+                              [], None, None)\n+\n+        # singular and plural\n+        else:\n+            ngettext = nodes.Name('ngettext', 'load')\n+            node = nodes.Call(ngettext, [\n+                nodes.Const(singular),\n+                nodes.Const(plural),\n+                plural_expr\n+            ], [], None, None)\n+\n+        # in case newstyle gettext is used, the method is powerful\n+        # enough to handle the variable expansion and autoescape\n+        # handling itself\n+        if self.environment.newstyle_gettext:\n+            for key, value in iteritems(variables):\n+                # the function adds that later anyways in case num was\n+                # called num, so just skip it.\n+                if num_called_num and key == 'num':\n+                    continue\n+                node.kwargs.append(nodes.Keyword(key, value))\n+\n+        # otherwise do that here\n+        else:\n+            # mark the return value as safe if we are in an\n+            # environment with autoescaping turned on\n+            node = nodes.MarkSafeIfAutoescape(node)\n+            if variables:\n+                node = nodes.Mod(node, nodes.Dict([\n+                    nodes.Pair(nodes.Const(key), value)\n+                    for key, value in variables.items()\n+                ]))\n+        return nodes.Output([node])\n+\n+\n+class ExprStmtExtension(Extension):\n+    \"\"\"Adds a `do` tag to Jinja2 that works like the print statement just\n+    that it doesn't print the return value.\n+    \"\"\"\n+    tags = set(['do'])\n+\n+    def parse(self, parser):\n+        node = nodes.ExprStmt(lineno=next(parser.stream).lineno)\n+        node.node = parser.parse_tuple()\n+        return node\n+\n+\n+class LoopControlExtension(Extension):\n+    \"\"\"Adds break and continue to the template engine.\"\"\"\n+    tags = set(['break', 'continue'])\n+\n+    def parse(self, parser):\n+        token = next(parser.stream)\n+        if token.value == 'break':\n+            return nodes.Break(lineno=token.lineno)\n+        return nodes.Continue(lineno=token.lineno)\n+\n+\n+class WithExtension(Extension):\n+    pass\n+\n+\n+class AutoEscapeExtension(Extension):\n+    pass\n+\n+\n+def extract_from_ast(node, gettext_functions=GETTEXT_FUNCTIONS,\n+                     babel_style=True):\n+    \"\"\"Extract localizable strings from the given template node.  Per\n+    default this function returns matches in babel style that means non string\n+    parameters as well as keyword arguments are returned as `None`.  This\n+    allows Babel to figure out what you really meant if you are using\n+    gettext functions that allow keyword arguments for placeholder expansion.\n+    If you don't want that behavior set the `babel_style` parameter to `False`\n+    which causes only strings to be returned and parameters are always stored\n+    in tuples.  As a consequence invalid gettext calls (calls without a single\n+    string parameter or string parameters after non-string parameters) are\n+    skipped.\n+\n+    This example explains the behavior:\n+\n+    >>> from jinja2 import Environment\n+    >>> env = Environment()\n+    >>> node = env.parse('{{ (_(\"foo\"), _(), ngettext(\"foo\", \"bar\", 42)) }}')\n+    >>> list(extract_from_ast(node))\n+    [(1, '_', 'foo'), (1, '_', ()), (1, 'ngettext', ('foo', 'bar', None))]\n+    >>> list(extract_from_ast(node, babel_style=False))\n+    [(1, '_', ('foo',)), (1, 'ngettext', ('foo', 'bar'))]\n+\n+    For every string found this function yields a ``(lineno, function,\n+    message)`` tuple, where:\n+\n+    * ``lineno`` is the number of the line on which the string was found,\n+    * ``function`` is the name of the ``gettext`` function used (if the\n+      string was extracted from embedded Python code), and\n+    *  ``message`` is the string itself (a ``unicode`` object, or a tuple\n+       of ``unicode`` objects for functions with multiple string arguments).\n+\n+    This extraction function operates on the AST and is because of that unable\n+    to extract any comments.  For comment support you have to use the babel\n+    extraction interface or extract comments yourself.\n+    \"\"\"\n+    for node in node.find_all(nodes.Call):\n+        if not isinstance(node.node, nodes.Name) or \\\n+           node.node.name not in gettext_functions:\n+            continue\n+\n+        strings = []\n+        for arg in node.args:\n+            if isinstance(arg, nodes.Const) and \\\n+               isinstance(arg.value, string_types):\n+                strings.append(arg.value)\n+            else:\n+                strings.append(None)\n+\n+        for arg in node.kwargs:\n+            strings.append(None)\n+        if node.dyn_args is not None:\n+            strings.append(None)\n+        if node.dyn_kwargs is not None:\n+            strings.append(None)\n+\n+        if not babel_style:\n+            strings = tuple(x for x in strings if x is not None)\n+            if not strings:\n+                continue\n+        else:\n+            if len(strings) == 1:\n+                strings = strings[0]\n+            else:\n+                strings = tuple(strings)\n+        yield node.lineno, node.node.name, strings\n+\n+\n+class _CommentFinder(object):\n+    \"\"\"Helper class to find comments in a token stream.  Can only\n+    find comments for gettext calls forwards.  Once the comment\n+    from line 4 is found, a comment for line 1 will not return a\n+    usable value.\n+    \"\"\"\n+\n+    def __init__(self, tokens, comment_tags):\n+        self.tokens = tokens\n+        self.comment_tags = comment_tags\n+        self.offset = 0\n+        self.last_lineno = 0\n+\n+    def find_backwards(self, offset):\n+        try:\n+            for _, token_type, token_value in \\\n+                    reversed(self.tokens[self.offset:offset]):\n+                if token_type in ('comment', 'linecomment'):\n+                    try:\n+                        prefix, comment = token_value.split(None, 1)\n+                    except ValueError:\n+                        continue\n+                    if prefix in self.comment_tags:\n+                        return [comment.rstrip()]\n+            return []\n+        finally:\n+            self.offset = offset\n+\n+    def find_comments(self, lineno):\n+        if not self.comment_tags or self.last_lineno > lineno:\n+            return []\n+        for idx, (token_lineno, _, _) in enumerate(self.tokens[self.offset:]):\n+            if token_lineno > lineno:\n+                return self.find_backwards(self.offset + idx)\n+        return self.find_backwards(len(self.tokens))\n+\n+\n+def babel_extract(fileobj, keywords, comment_tags, options):\n+    \"\"\"Babel extraction method for Jinja templates.\n+\n+    .. versionchanged:: 2.3\n+       Basic support for translation comments was added.  If `comment_tags`\n+       is now set to a list of keywords for extraction, the extractor will\n+       try to find the best preceeding comment that begins with one of the\n+       keywords.  For best results, make sure to not have more than one\n+       gettext call in one line of code and the matching comment in the\n+       same line or the line before.\n+\n+    .. versionchanged:: 2.5.1\n+       The `newstyle_gettext` flag can be set to `True` to enable newstyle\n+       gettext calls.\n+\n+    .. versionchanged:: 2.7\n+       A `silent` option can now be provided.  If set to `False` template\n+       syntax errors are propagated instead of being ignored.\n+\n+    :param fileobj: the file-like object the messages should be extracted from\n+    :param keywords: a list of keywords (i.e. function names) that should be\n+                     recognized as translation functions\n+    :param comment_tags: a list of translator tags to search for and include\n+                         in the results.\n+    :param options: a dictionary of additional options (optional)\n+    :return: an iterator over ``(lineno, funcname, message, comments)`` tuples.\n+             (comments will be empty currently)\n+    \"\"\"\n+    extensions = set()\n+    for extension in options.get('extensions', '').split(','):\n+        extension = extension.strip()\n+        if not extension:\n+            continue\n+        extensions.add(import_string(extension))\n+    if InternationalizationExtension not in extensions:\n+        extensions.add(InternationalizationExtension)\n+\n+    def getbool(options, key, default=False):\n+        return options.get(key, str(default)).lower() in \\\n+            ('1', 'on', 'yes', 'true')\n+\n+    silent = getbool(options, 'silent', True)\n+    environment = Environment(\n+        options.get('block_start_string', BLOCK_START_STRING),\n+        options.get('block_end_string', BLOCK_END_STRING),\n+        options.get('variable_start_string', VARIABLE_START_STRING),\n+        options.get('variable_end_string', VARIABLE_END_STRING),\n+        options.get('comment_start_string', COMMENT_START_STRING),\n+        options.get('comment_end_string', COMMENT_END_STRING),\n+        options.get('line_statement_prefix') or LINE_STATEMENT_PREFIX,\n+        options.get('line_comment_prefix') or LINE_COMMENT_PREFIX,\n+        getbool(options, 'trim_blocks', TRIM_BLOCKS),\n+        getbool(options, 'lstrip_blocks', LSTRIP_BLOCKS),\n+        NEWLINE_SEQUENCE,\n+        getbool(options, 'keep_trailing_newline', KEEP_TRAILING_NEWLINE),\n+        frozenset(extensions),\n+        cache_size=0,\n+        auto_reload=False\n+    )\n+\n+    if getbool(options, 'trimmed'):\n+        environment.policies['ext.i18n.trimmed'] = True\n+    if getbool(options, 'newstyle_gettext'):\n+        environment.newstyle_gettext = True\n+\n+    source = fileobj.read().decode(options.get('encoding', 'utf-8'))\n+    try:\n+        node = environment.parse(source)\n+        tokens = list(environment.lex(environment.preprocess(source)))\n+    except TemplateSyntaxError as e:\n+        if not silent:\n+            raise\n+        # skip templates with syntax errors\n+        return\n+\n+    finder = _CommentFinder(tokens, comment_tags)\n+    for lineno, func, message in extract_from_ast(node, keywords):\n+        yield lineno, func, message, finder.find_comments(lineno)\n+\n+\n+#: nicer import names\n+i18n = InternationalizationExtension\n+do = ExprStmtExtension\n+loopcontrols = LoopControlExtension\n+with_ = WithExtension\n+autoescape = AutoEscapeExtension"
        },
        {
            "sha": "267ddddaa03478ed77d640c011b8f2c0d6641d04",
            "filename": "tools/jinja2/filters.py",
            "status": "added",
            "additions": 1190,
            "deletions": 0,
            "changes": 1190,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Ffilters.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Ffilters.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Ffilters.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,1190 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.filters\n+    ~~~~~~~~~~~~~~\n+\n+    Bundled jinja filters.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+import re\n+import math\n+import random\n+import warnings\n+\n+from itertools import groupby, chain\n+from collections import namedtuple\n+from jinja2.utils import Markup, escape, pformat, urlize, soft_unicode, \\\n+     unicode_urlencode, htmlsafe_json_dumps\n+from jinja2.runtime import Undefined\n+from jinja2.exceptions import FilterArgumentError\n+from jinja2._compat import imap, string_types, text_type, iteritems, PY2\n+\n+\n+_word_re = re.compile(r'\\w+', re.UNICODE)\n+_word_beginning_split_re = re.compile(r'([-\\s\\(\\{\\[\\<]+)', re.UNICODE)\n+\n+\n+def contextfilter(f):\n+    \"\"\"Decorator for marking context dependent filters. The current\n+    :class:`Context` will be passed as first argument.\n+    \"\"\"\n+    f.contextfilter = True\n+    return f\n+\n+\n+def evalcontextfilter(f):\n+    \"\"\"Decorator for marking eval-context dependent filters.  An eval\n+    context object is passed as first argument.  For more information\n+    about the eval context, see :ref:`eval-context`.\n+\n+    .. versionadded:: 2.4\n+    \"\"\"\n+    f.evalcontextfilter = True\n+    return f\n+\n+\n+def environmentfilter(f):\n+    \"\"\"Decorator for marking environment dependent filters.  The current\n+    :class:`Environment` is passed to the filter as first argument.\n+    \"\"\"\n+    f.environmentfilter = True\n+    return f\n+\n+\n+def ignore_case(value):\n+    \"\"\"For use as a postprocessor for :func:`make_attrgetter`. Converts strings\n+    to lowercase and returns other types as-is.\"\"\"\n+    return value.lower() if isinstance(value, string_types) else value\n+\n+\n+def make_attrgetter(environment, attribute, postprocess=None):\n+    \"\"\"Returns a callable that looks up the given attribute from a\n+    passed object with the rules of the environment.  Dots are allowed\n+    to access attributes of attributes.  Integer parts in paths are\n+    looked up as integers.\n+    \"\"\"\n+    if attribute is None:\n+        attribute = []\n+    elif isinstance(attribute, string_types):\n+        attribute = [int(x) if x.isdigit() else x for x in attribute.split('.')]\n+    else:\n+        attribute = [attribute]\n+\n+    def attrgetter(item):\n+        for part in attribute:\n+            item = environment.getitem(item, part)\n+\n+        if postprocess is not None:\n+            item = postprocess(item)\n+\n+        return item\n+\n+    return attrgetter\n+\n+\n+def do_forceescape(value):\n+    \"\"\"Enforce HTML escaping.  This will probably double escape variables.\"\"\"\n+    if hasattr(value, '__html__'):\n+        value = value.__html__()\n+    return escape(text_type(value))\n+\n+\n+def do_urlencode(value):\n+    \"\"\"Escape strings for use in URLs (uses UTF-8 encoding).  It accepts both\n+    dictionaries and regular strings as well as pairwise iterables.\n+\n+    .. versionadded:: 2.7\n+    \"\"\"\n+    itemiter = None\n+    if isinstance(value, dict):\n+        itemiter = iteritems(value)\n+    elif not isinstance(value, string_types):\n+        try:\n+            itemiter = iter(value)\n+        except TypeError:\n+            pass\n+    if itemiter is None:\n+        return unicode_urlencode(value)\n+    return u'&'.join(unicode_urlencode(k) + '=' +\n+                     unicode_urlencode(v, for_qs=True)\n+                     for k, v in itemiter)\n+\n+\n+@evalcontextfilter\n+def do_replace(eval_ctx, s, old, new, count=None):\n+    \"\"\"Return a copy of the value with all occurrences of a substring\n+    replaced with a new one. The first argument is the substring\n+    that should be replaced, the second is the replacement string.\n+    If the optional third argument ``count`` is given, only the first\n+    ``count`` occurrences are replaced:\n+\n+    .. sourcecode:: jinja\n+\n+        {{ \"Hello World\"|replace(\"Hello\", \"Goodbye\") }}\n+            -> Goodbye World\n+\n+        {{ \"aaaaargh\"|replace(\"a\", \"d'oh, \", 2) }}\n+            -> d'oh, d'oh, aaargh\n+    \"\"\"\n+    if count is None:\n+        count = -1\n+    if not eval_ctx.autoescape:\n+        return text_type(s).replace(text_type(old), text_type(new), count)\n+    if hasattr(old, '__html__') or hasattr(new, '__html__') and \\\n+       not hasattr(s, '__html__'):\n+        s = escape(s)\n+    else:\n+        s = soft_unicode(s)\n+    return s.replace(soft_unicode(old), soft_unicode(new), count)\n+\n+\n+def do_upper(s):\n+    \"\"\"Convert a value to uppercase.\"\"\"\n+    return soft_unicode(s).upper()\n+\n+\n+def do_lower(s):\n+    \"\"\"Convert a value to lowercase.\"\"\"\n+    return soft_unicode(s).lower()\n+\n+\n+@evalcontextfilter\n+def do_xmlattr(_eval_ctx, d, autospace=True):\n+    \"\"\"Create an SGML/XML attribute string based on the items in a dict.\n+    All values that are neither `none` nor `undefined` are automatically\n+    escaped:\n+\n+    .. sourcecode:: html+jinja\n+\n+        <ul{{ {'class': 'my_list', 'missing': none,\n+                'id': 'list-%d'|format(variable)}|xmlattr }}>\n+        ...\n+        </ul>\n+\n+    Results in something like this:\n+\n+    .. sourcecode:: html\n+\n+        <ul class=\"my_list\" id=\"list-42\">\n+        ...\n+        </ul>\n+\n+    As you can see it automatically prepends a space in front of the item\n+    if the filter returned something unless the second parameter is false.\n+    \"\"\"\n+    rv = u' '.join(\n+        u'%s=\"%s\"' % (escape(key), escape(value))\n+        for key, value in iteritems(d)\n+        if value is not None and not isinstance(value, Undefined)\n+    )\n+    if autospace and rv:\n+        rv = u' ' + rv\n+    if _eval_ctx.autoescape:\n+        rv = Markup(rv)\n+    return rv\n+\n+\n+def do_capitalize(s):\n+    \"\"\"Capitalize a value. The first character will be uppercase, all others\n+    lowercase.\n+    \"\"\"\n+    return soft_unicode(s).capitalize()\n+\n+\n+def do_title(s):\n+    \"\"\"Return a titlecased version of the value. I.e. words will start with\n+    uppercase letters, all remaining characters are lowercase.\n+    \"\"\"\n+    return ''.join(\n+        [item[0].upper() + item[1:].lower()\n+         for item in _word_beginning_split_re.split(soft_unicode(s))\n+         if item])\n+\n+\n+def do_dictsort(value, case_sensitive=False, by='key', reverse=False):\n+    \"\"\"Sort a dict and yield (key, value) pairs. Because python dicts are\n+    unsorted you may want to use this function to order them by either\n+    key or value:\n+\n+    .. sourcecode:: jinja\n+\n+        {% for item in mydict|dictsort %}\n+            sort the dict by key, case insensitive\n+\n+        {% for item in mydict|dictsort(reverse=true) %}\n+            sort the dict by key, case insensitive, reverse order\n+\n+        {% for item in mydict|dictsort(true) %}\n+            sort the dict by key, case sensitive\n+\n+        {% for item in mydict|dictsort(false, 'value') %}\n+            sort the dict by value, case insensitive\n+    \"\"\"\n+    if by == 'key':\n+        pos = 0\n+    elif by == 'value':\n+        pos = 1\n+    else:\n+        raise FilterArgumentError(\n+            'You can only sort by either \"key\" or \"value\"'\n+        )\n+\n+    def sort_func(item):\n+        value = item[pos]\n+\n+        if not case_sensitive:\n+            value = ignore_case(value)\n+\n+        return value\n+\n+    return sorted(value.items(), key=sort_func, reverse=reverse)\n+\n+\n+@environmentfilter\n+def do_sort(\n+    environment, value, reverse=False, case_sensitive=False, attribute=None\n+):\n+    \"\"\"Sort an iterable.  Per default it sorts ascending, if you pass it\n+    true as first argument it will reverse the sorting.\n+\n+    If the iterable is made of strings the third parameter can be used to\n+    control the case sensitiveness of the comparison which is disabled by\n+    default.\n+\n+    .. sourcecode:: jinja\n+\n+        {% for item in iterable|sort %}\n+            ...\n+        {% endfor %}\n+\n+    It is also possible to sort by an attribute (for example to sort\n+    by the date of an object) by specifying the `attribute` parameter:\n+\n+    .. sourcecode:: jinja\n+\n+        {% for item in iterable|sort(attribute='date') %}\n+            ...\n+        {% endfor %}\n+\n+    .. versionchanged:: 2.6\n+       The `attribute` parameter was added.\n+    \"\"\"\n+    key_func = make_attrgetter(\n+        environment, attribute,\n+        postprocess=ignore_case if not case_sensitive else None\n+    )\n+    return sorted(value, key=key_func, reverse=reverse)\n+\n+\n+@environmentfilter\n+def do_unique(environment, value, case_sensitive=False, attribute=None):\n+    \"\"\"Returns a list of unique items from the the given iterable.\n+\n+    .. sourcecode:: jinja\n+\n+        {{ ['foo', 'bar', 'foobar', 'FooBar']|unique }}\n+            -> ['foo', 'bar', 'foobar']\n+\n+    The unique items are yielded in the same order as their first occurrence in\n+    the iterable passed to the filter.\n+\n+    :param case_sensitive: Treat upper and lower case strings as distinct.\n+    :param attribute: Filter objects with unique values for this attribute.\n+    \"\"\"\n+    getter = make_attrgetter(\n+        environment, attribute,\n+        postprocess=ignore_case if not case_sensitive else None\n+    )\n+    seen = set()\n+\n+    for item in value:\n+        key = getter(item)\n+\n+        if key not in seen:\n+            seen.add(key)\n+            yield item\n+\n+\n+def _min_or_max(environment, value, func, case_sensitive, attribute):\n+    it = iter(value)\n+\n+    try:\n+        first = next(it)\n+    except StopIteration:\n+        return environment.undefined('No aggregated item, sequence was empty.')\n+\n+    key_func = make_attrgetter(\n+        environment, attribute,\n+        ignore_case if not case_sensitive else None\n+    )\n+    return func(chain([first], it), key=key_func)\n+\n+\n+@environmentfilter\n+def do_min(environment, value, case_sensitive=False, attribute=None):\n+    \"\"\"Return the smallest item from the sequence.\n+\n+    .. sourcecode:: jinja\n+\n+        {{ [1, 2, 3]|min }}\n+            -> 1\n+\n+    :param case_sensitive: Treat upper and lower case strings as distinct.\n+    :param attribute: Get the object with the max value of this attribute.\n+    \"\"\"\n+    return _min_or_max(environment, value, min, case_sensitive, attribute)\n+\n+\n+@environmentfilter\n+def do_max(environment, value, case_sensitive=False, attribute=None):\n+    \"\"\"Return the largest item from the sequence.\n+\n+    .. sourcecode:: jinja\n+\n+        {{ [1, 2, 3]|max }}\n+            -> 3\n+\n+    :param case_sensitive: Treat upper and lower case strings as distinct.\n+    :param attribute: Get the object with the max value of this attribute.\n+    \"\"\"\n+    return _min_or_max(environment, value, max, case_sensitive, attribute)\n+\n+\n+def do_default(value, default_value=u'', boolean=False):\n+    \"\"\"If the value is undefined it will return the passed default value,\n+    otherwise the value of the variable:\n+\n+    .. sourcecode:: jinja\n+\n+        {{ my_variable|default('my_variable is not defined') }}\n+\n+    This will output the value of ``my_variable`` if the variable was\n+    defined, otherwise ``'my_variable is not defined'``. If you want\n+    to use default with variables that evaluate to false you have to\n+    set the second parameter to `true`:\n+\n+    .. sourcecode:: jinja\n+\n+        {{ ''|default('the string was empty', true) }}\n+    \"\"\"\n+    if isinstance(value, Undefined) or (boolean and not value):\n+        return default_value\n+    return value\n+\n+\n+@evalcontextfilter\n+def do_join(eval_ctx, value, d=u'', attribute=None):\n+    \"\"\"Return a string which is the concatenation of the strings in the\n+    sequence. The separator between elements is an empty string per\n+    default, you can define it with the optional parameter:\n+\n+    .. sourcecode:: jinja\n+\n+        {{ [1, 2, 3]|join('|') }}\n+            -> 1|2|3\n+\n+        {{ [1, 2, 3]|join }}\n+            -> 123\n+\n+    It is also possible to join certain attributes of an object:\n+\n+    .. sourcecode:: jinja\n+\n+        {{ users|join(', ', attribute='username') }}\n+\n+    .. versionadded:: 2.6\n+       The `attribute` parameter was added.\n+    \"\"\"\n+    if attribute is not None:\n+        value = imap(make_attrgetter(eval_ctx.environment, attribute), value)\n+\n+    # no automatic escaping?  joining is a lot eaiser then\n+    if not eval_ctx.autoescape:\n+        return text_type(d).join(imap(text_type, value))\n+\n+    # if the delimiter doesn't have an html representation we check\n+    # if any of the items has.  If yes we do a coercion to Markup\n+    if not hasattr(d, '__html__'):\n+        value = list(value)\n+        do_escape = False\n+        for idx, item in enumerate(value):\n+            if hasattr(item, '__html__'):\n+                do_escape = True\n+            else:\n+                value[idx] = text_type(item)\n+        if do_escape:\n+            d = escape(d)\n+        else:\n+            d = text_type(d)\n+        return d.join(value)\n+\n+    # no html involved, to normal joining\n+    return soft_unicode(d).join(imap(soft_unicode, value))\n+\n+\n+def do_center(value, width=80):\n+    \"\"\"Centers the value in a field of a given width.\"\"\"\n+    return text_type(value).center(width)\n+\n+\n+@environmentfilter\n+def do_first(environment, seq):\n+    \"\"\"Return the first item of a sequence.\"\"\"\n+    try:\n+        return next(iter(seq))\n+    except StopIteration:\n+        return environment.undefined('No first item, sequence was empty.')\n+\n+\n+@environmentfilter\n+def do_last(environment, seq):\n+    \"\"\"Return the last item of a sequence.\"\"\"\n+    try:\n+        return next(iter(reversed(seq)))\n+    except StopIteration:\n+        return environment.undefined('No last item, sequence was empty.')\n+\n+\n+@contextfilter\n+def do_random(context, seq):\n+    \"\"\"Return a random item from the sequence.\"\"\"\n+    try:\n+        return random.choice(seq)\n+    except IndexError:\n+        return context.environment.undefined('No random item, sequence was empty.')\n+\n+\n+def do_filesizeformat(value, binary=False):\n+    \"\"\"Format the value like a 'human-readable' file size (i.e. 13 kB,\n+    4.1 MB, 102 Bytes, etc).  Per default decimal prefixes are used (Mega,\n+    Giga, etc.), if the second parameter is set to `True` the binary\n+    prefixes are used (Mebi, Gibi).\n+    \"\"\"\n+    bytes = float(value)\n+    base = binary and 1024 or 1000\n+    prefixes = [\n+        (binary and 'KiB' or 'kB'),\n+        (binary and 'MiB' or 'MB'),\n+        (binary and 'GiB' or 'GB'),\n+        (binary and 'TiB' or 'TB'),\n+        (binary and 'PiB' or 'PB'),\n+        (binary and 'EiB' or 'EB'),\n+        (binary and 'ZiB' or 'ZB'),\n+        (binary and 'YiB' or 'YB')\n+    ]\n+    if bytes == 1:\n+        return '1 Byte'\n+    elif bytes < base:\n+        return '%d Bytes' % bytes\n+    else:\n+        for i, prefix in enumerate(prefixes):\n+            unit = base ** (i + 2)\n+            if bytes < unit:\n+                return '%.1f %s' % ((base * bytes / unit), prefix)\n+        return '%.1f %s' % ((base * bytes / unit), prefix)\n+\n+\n+def do_pprint(value, verbose=False):\n+    \"\"\"Pretty print a variable. Useful for debugging.\n+\n+    With Jinja 1.2 onwards you can pass it a parameter.  If this parameter\n+    is truthy the output will be more verbose (this requires `pretty`)\n+    \"\"\"\n+    return pformat(value, verbose=verbose)\n+\n+\n+@evalcontextfilter\n+def do_urlize(eval_ctx, value, trim_url_limit=None, nofollow=False,\n+              target=None, rel=None):\n+    \"\"\"Converts URLs in plain text into clickable links.\n+\n+    If you pass the filter an additional integer it will shorten the urls\n+    to that number. Also a third argument exists that makes the urls\n+    \"nofollow\":\n+\n+    .. sourcecode:: jinja\n+\n+        {{ mytext|urlize(40, true) }}\n+            links are shortened to 40 chars and defined with rel=\"nofollow\"\n+\n+    If *target* is specified, the ``target`` attribute will be added to the\n+    ``<a>`` tag:\n+\n+    .. sourcecode:: jinja\n+\n+       {{ mytext|urlize(40, target='_blank') }}\n+\n+    .. versionchanged:: 2.8+\n+       The *target* parameter was added.\n+    \"\"\"\n+    policies = eval_ctx.environment.policies\n+    rel = set((rel or '').split() or [])\n+    if nofollow:\n+        rel.add('nofollow')\n+    rel.update((policies['urlize.rel'] or '').split())\n+    if target is None:\n+        target = policies['urlize.target']\n+    rel = ' '.join(sorted(rel)) or None\n+    rv = urlize(value, trim_url_limit, rel=rel, target=target)\n+    if eval_ctx.autoescape:\n+        rv = Markup(rv)\n+    return rv\n+\n+\n+def do_indent(\n+    s, width=4, first=False, blank=False, indentfirst=None\n+):\n+    \"\"\"Return a copy of the string with each line indented by 4 spaces. The\n+    first line and blank lines are not indented by default.\n+\n+    :param width: Number of spaces to indent by.\n+    :param first: Don't skip indenting the first line.\n+    :param blank: Don't skip indenting empty lines.\n+\n+    .. versionchanged:: 2.10\n+        Blank lines are not indented by default.\n+\n+        Rename the ``indentfirst`` argument to ``first``.\n+    \"\"\"\n+    if indentfirst is not None:\n+        warnings.warn(DeprecationWarning(\n+            'The \"indentfirst\" argument is renamed to \"first\".'\n+        ), stacklevel=2)\n+        first = indentfirst\n+\n+    s += u'\\n'  # this quirk is necessary for splitlines method\n+    indention = u' ' * width\n+\n+    if blank:\n+        rv = (u'\\n' + indention).join(s.splitlines())\n+    else:\n+        lines = s.splitlines()\n+        rv = lines.pop(0)\n+\n+        if lines:\n+            rv += u'\\n' + u'\\n'.join(\n+                indention + line if line else line for line in lines\n+            )\n+\n+    if first:\n+        rv = indention + rv\n+\n+    return rv\n+\n+\n+@environmentfilter\n+def do_truncate(env, s, length=255, killwords=False, end='...', leeway=None):\n+    \"\"\"Return a truncated copy of the string. The length is specified\n+    with the first parameter which defaults to ``255``. If the second\n+    parameter is ``true`` the filter will cut the text at length. Otherwise\n+    it will discard the last word. If the text was in fact\n+    truncated it will append an ellipsis sign (``\"...\"``). If you want a\n+    different ellipsis sign than ``\"...\"`` you can specify it using the\n+    third parameter. Strings that only exceed the length by the tolerance\n+    margin given in the fourth parameter will not be truncated.\n+\n+    .. sourcecode:: jinja\n+\n+        {{ \"foo bar baz qux\"|truncate(9) }}\n+            -> \"foo...\"\n+        {{ \"foo bar baz qux\"|truncate(9, True) }}\n+            -> \"foo ba...\"\n+        {{ \"foo bar baz qux\"|truncate(11) }}\n+            -> \"foo bar baz qux\"\n+        {{ \"foo bar baz qux\"|truncate(11, False, '...', 0) }}\n+            -> \"foo bar...\"\n+\n+    The default leeway on newer Jinja2 versions is 5 and was 0 before but\n+    can be reconfigured globally.\n+    \"\"\"\n+    if leeway is None:\n+        leeway = env.policies['truncate.leeway']\n+    assert length >= len(end), 'expected length >= %s, got %s' % (len(end), length)\n+    assert leeway >= 0, 'expected leeway >= 0, got %s' % leeway\n+    if len(s) <= length + leeway:\n+        return s\n+    if killwords:\n+        return s[:length - len(end)] + end\n+    result = s[:length - len(end)].rsplit(' ', 1)[0]\n+    return result + end\n+\n+\n+@environmentfilter\n+def do_wordwrap(environment, s, width=79, break_long_words=True,\n+                wrapstring=None):\n+    \"\"\"\n+    Return a copy of the string passed to the filter wrapped after\n+    ``79`` characters.  You can override this default using the first\n+    parameter.  If you set the second parameter to `false` Jinja will not\n+    split words apart if they are longer than `width`. By default, the newlines\n+    will be the default newlines for the environment, but this can be changed\n+    using the wrapstring keyword argument.\n+\n+    .. versionadded:: 2.7\n+       Added support for the `wrapstring` parameter.\n+    \"\"\"\n+    if not wrapstring:\n+        wrapstring = environment.newline_sequence\n+    import textwrap\n+    return wrapstring.join(textwrap.wrap(s, width=width, expand_tabs=False,\n+                                   replace_whitespace=False,\n+                                   break_long_words=break_long_words))\n+\n+\n+def do_wordcount(s):\n+    \"\"\"Count the words in that string.\"\"\"\n+    return len(_word_re.findall(s))\n+\n+\n+def do_int(value, default=0, base=10):\n+    \"\"\"Convert the value into an integer. If the\n+    conversion doesn't work it will return ``0``. You can\n+    override this default using the first parameter. You\n+    can also override the default base (10) in the second\n+    parameter, which handles input with prefixes such as\n+    0b, 0o and 0x for bases 2, 8 and 16 respectively.\n+    The base is ignored for decimal numbers and non-string values.\n+    \"\"\"\n+    try:\n+        if isinstance(value, string_types):\n+            return int(value, base)\n+        return int(value)\n+    except (TypeError, ValueError):\n+        # this quirk is necessary so that \"42.23\"|int gives 42.\n+        try:\n+            return int(float(value))\n+        except (TypeError, ValueError):\n+            return default\n+\n+\n+def do_float(value, default=0.0):\n+    \"\"\"Convert the value into a floating point number. If the\n+    conversion doesn't work it will return ``0.0``. You can\n+    override this default using the first parameter.\n+    \"\"\"\n+    try:\n+        return float(value)\n+    except (TypeError, ValueError):\n+        return default\n+\n+\n+def do_format(value, *args, **kwargs):\n+    \"\"\"\n+    Apply python string formatting on an object:\n+\n+    .. sourcecode:: jinja\n+\n+        {{ \"%s - %s\"|format(\"Hello?\", \"Foo!\") }}\n+            -> Hello? - Foo!\n+    \"\"\"\n+    if args and kwargs:\n+        raise FilterArgumentError('can\\'t handle positional and keyword '\n+                                  'arguments at the same time')\n+    return soft_unicode(value) % (kwargs or args)\n+\n+\n+def do_trim(value):\n+    \"\"\"Strip leading and trailing whitespace.\"\"\"\n+    return soft_unicode(value).strip()\n+\n+\n+def do_striptags(value):\n+    \"\"\"Strip SGML/XML tags and replace adjacent whitespace by one space.\n+    \"\"\"\n+    if hasattr(value, '__html__'):\n+        value = value.__html__()\n+    return Markup(text_type(value)).striptags()\n+\n+\n+def do_slice(value, slices, fill_with=None):\n+    \"\"\"Slice an iterator and return a list of lists containing\n+    those items. Useful if you want to create a div containing\n+    three ul tags that represent columns:\n+\n+    .. sourcecode:: html+jinja\n+\n+        <div class=\"columwrapper\">\n+          {%- for column in items|slice(3) %}\n+            <ul class=\"column-{{ loop.index }}\">\n+            {%- for item in column %}\n+              <li>{{ item }}</li>\n+            {%- endfor %}\n+            </ul>\n+          {%- endfor %}\n+        </div>\n+\n+    If you pass it a second argument it's used to fill missing\n+    values on the last iteration.\n+    \"\"\"\n+    seq = list(value)\n+    length = len(seq)\n+    items_per_slice = length // slices\n+    slices_with_extra = length % slices\n+    offset = 0\n+    for slice_number in range(slices):\n+        start = offset + slice_number * items_per_slice\n+        if slice_number < slices_with_extra:\n+            offset += 1\n+        end = offset + (slice_number + 1) * items_per_slice\n+        tmp = seq[start:end]\n+        if fill_with is not None and slice_number >= slices_with_extra:\n+            tmp.append(fill_with)\n+        yield tmp\n+\n+\n+def do_batch(value, linecount, fill_with=None):\n+    \"\"\"\n+    A filter that batches items. It works pretty much like `slice`\n+    just the other way round. It returns a list of lists with the\n+    given number of items. If you provide a second parameter this\n+    is used to fill up missing items. See this example:\n+\n+    .. sourcecode:: html+jinja\n+\n+        <table>\n+        {%- for row in items|batch(3, '&nbsp;') %}\n+          <tr>\n+          {%- for column in row %}\n+            <td>{{ column }}</td>\n+          {%- endfor %}\n+          </tr>\n+        {%- endfor %}\n+        </table>\n+    \"\"\"\n+    tmp = []\n+    for item in value:\n+        if len(tmp) == linecount:\n+            yield tmp\n+            tmp = []\n+        tmp.append(item)\n+    if tmp:\n+        if fill_with is not None and len(tmp) < linecount:\n+            tmp += [fill_with] * (linecount - len(tmp))\n+        yield tmp\n+\n+\n+def do_round(value, precision=0, method='common'):\n+    \"\"\"Round the number to a given precision. The first\n+    parameter specifies the precision (default is ``0``), the\n+    second the rounding method:\n+\n+    - ``'common'`` rounds either up or down\n+    - ``'ceil'`` always rounds up\n+    - ``'floor'`` always rounds down\n+\n+    If you don't specify a method ``'common'`` is used.\n+\n+    .. sourcecode:: jinja\n+\n+        {{ 42.55|round }}\n+            -> 43.0\n+        {{ 42.55|round(1, 'floor') }}\n+            -> 42.5\n+\n+    Note that even if rounded to 0 precision, a float is returned.  If\n+    you need a real integer, pipe it through `int`:\n+\n+    .. sourcecode:: jinja\n+\n+        {{ 42.55|round|int }}\n+            -> 43\n+    \"\"\"\n+    if not method in ('common', 'ceil', 'floor'):\n+        raise FilterArgumentError('method must be common, ceil or floor')\n+    if method == 'common':\n+        return round(value, precision)\n+    func = getattr(math, method)\n+    return func(value * (10 ** precision)) / (10 ** precision)\n+\n+\n+# Use a regular tuple repr here.  This is what we did in the past and we\n+# really want to hide this custom type as much as possible.  In particular\n+# we do not want to accidentally expose an auto generated repr in case\n+# people start to print this out in comments or something similar for\n+# debugging.\n+_GroupTuple = namedtuple('_GroupTuple', ['grouper', 'list'])\n+_GroupTuple.__repr__ = tuple.__repr__\n+_GroupTuple.__str__ = tuple.__str__\n+\n+@environmentfilter\n+def do_groupby(environment, value, attribute):\n+    \"\"\"Group a sequence of objects by a common attribute.\n+\n+    If you for example have a list of dicts or objects that represent persons\n+    with `gender`, `first_name` and `last_name` attributes and you want to\n+    group all users by genders you can do something like the following\n+    snippet:\n+\n+    .. sourcecode:: html+jinja\n+\n+        <ul>\n+        {% for group in persons|groupby('gender') %}\n+            <li>{{ group.grouper }}<ul>\n+            {% for person in group.list %}\n+                <li>{{ person.first_name }} {{ person.last_name }}</li>\n+            {% endfor %}</ul></li>\n+        {% endfor %}\n+        </ul>\n+\n+    Additionally it's possible to use tuple unpacking for the grouper and\n+    list:\n+\n+    .. sourcecode:: html+jinja\n+\n+        <ul>\n+        {% for grouper, list in persons|groupby('gender') %}\n+            ...\n+        {% endfor %}\n+        </ul>\n+\n+    As you can see the item we're grouping by is stored in the `grouper`\n+    attribute and the `list` contains all the objects that have this grouper\n+    in common.\n+\n+    .. versionchanged:: 2.6\n+       It's now possible to use dotted notation to group by the child\n+       attribute of another attribute.\n+    \"\"\"\n+    expr = make_attrgetter(environment, attribute)\n+    return [_GroupTuple(key, list(values)) for key, values\n+            in groupby(sorted(value, key=expr), expr)]\n+\n+\n+@environmentfilter\n+def do_sum(environment, iterable, attribute=None, start=0):\n+    \"\"\"Returns the sum of a sequence of numbers plus the value of parameter\n+    'start' (which defaults to 0).  When the sequence is empty it returns\n+    start.\n+\n+    It is also possible to sum up only certain attributes:\n+\n+    .. sourcecode:: jinja\n+\n+        Total: {{ items|sum(attribute='price') }}\n+\n+    .. versionchanged:: 2.6\n+       The `attribute` parameter was added to allow suming up over\n+       attributes.  Also the `start` parameter was moved on to the right.\n+    \"\"\"\n+    if attribute is not None:\n+        iterable = imap(make_attrgetter(environment, attribute), iterable)\n+    return sum(iterable, start)\n+\n+\n+def do_list(value):\n+    \"\"\"Convert the value into a list.  If it was a string the returned list\n+    will be a list of characters.\n+    \"\"\"\n+    return list(value)\n+\n+\n+def do_mark_safe(value):\n+    \"\"\"Mark the value as safe which means that in an environment with automatic\n+    escaping enabled this variable will not be escaped.\n+    \"\"\"\n+    return Markup(value)\n+\n+\n+def do_mark_unsafe(value):\n+    \"\"\"Mark a value as unsafe.  This is the reverse operation for :func:`safe`.\"\"\"\n+    return text_type(value)\n+\n+\n+def do_reverse(value):\n+    \"\"\"Reverse the object or return an iterator that iterates over it the other\n+    way round.\n+    \"\"\"\n+    if isinstance(value, string_types):\n+        return value[::-1]\n+    try:\n+        return reversed(value)\n+    except TypeError:\n+        try:\n+            rv = list(value)\n+            rv.reverse()\n+            return rv\n+        except TypeError:\n+            raise FilterArgumentError('argument must be iterable')\n+\n+\n+@environmentfilter\n+def do_attr(environment, obj, name):\n+    \"\"\"Get an attribute of an object.  ``foo|attr(\"bar\")`` works like\n+    ``foo.bar`` just that always an attribute is returned and items are not\n+    looked up.\n+\n+    See :ref:`Notes on subscriptions <notes-on-subscriptions>` for more details.\n+    \"\"\"\n+    try:\n+        name = str(name)\n+    except UnicodeError:\n+        pass\n+    else:\n+        try:\n+            value = getattr(obj, name)\n+        except AttributeError:\n+            pass\n+        else:\n+            if environment.sandboxed and not \\\n+               environment.is_safe_attribute(obj, name, value):\n+                return environment.unsafe_undefined(obj, name)\n+            return value\n+    return environment.undefined(obj=obj, name=name)\n+\n+\n+@contextfilter\n+def do_map(*args, **kwargs):\n+    \"\"\"Applies a filter on a sequence of objects or looks up an attribute.\n+    This is useful when dealing with lists of objects but you are really\n+    only interested in a certain value of it.\n+\n+    The basic usage is mapping on an attribute.  Imagine you have a list\n+    of users but you are only interested in a list of usernames:\n+\n+    .. sourcecode:: jinja\n+\n+        Users on this page: {{ users|map(attribute='username')|join(', ') }}\n+\n+    Alternatively you can let it invoke a filter by passing the name of the\n+    filter and the arguments afterwards.  A good example would be applying a\n+    text conversion filter on a sequence:\n+\n+    .. sourcecode:: jinja\n+\n+        Users on this page: {{ titles|map('lower')|join(', ') }}\n+\n+    .. versionadded:: 2.7\n+    \"\"\"\n+    seq, func = prepare_map(args, kwargs)\n+    if seq:\n+        for item in seq:\n+            yield func(item)\n+\n+\n+@contextfilter\n+def do_select(*args, **kwargs):\n+    \"\"\"Filters a sequence of objects by applying a test to each object,\n+    and only selecting the objects with the test succeeding.\n+\n+    If no test is specified, each object will be evaluated as a boolean.\n+\n+    Example usage:\n+\n+    .. sourcecode:: jinja\n+\n+        {{ numbers|select(\"odd\") }}\n+        {{ numbers|select(\"odd\") }}\n+        {{ numbers|select(\"divisibleby\", 3) }}\n+        {{ numbers|select(\"lessthan\", 42) }}\n+        {{ strings|select(\"equalto\", \"mystring\") }}\n+\n+    .. versionadded:: 2.7\n+    \"\"\"\n+    return select_or_reject(args, kwargs, lambda x: x, False)\n+\n+\n+@contextfilter\n+def do_reject(*args, **kwargs):\n+    \"\"\"Filters a sequence of objects by applying a test to each object,\n+    and rejecting the objects with the test succeeding.\n+\n+    If no test is specified, each object will be evaluated as a boolean.\n+\n+    Example usage:\n+\n+    .. sourcecode:: jinja\n+\n+        {{ numbers|reject(\"odd\") }}\n+\n+    .. versionadded:: 2.7\n+    \"\"\"\n+    return select_or_reject(args, kwargs, lambda x: not x, False)\n+\n+\n+@contextfilter\n+def do_selectattr(*args, **kwargs):\n+    \"\"\"Filters a sequence of objects by applying a test to the specified\n+    attribute of each object, and only selecting the objects with the\n+    test succeeding.\n+\n+    If no test is specified, the attribute's value will be evaluated as\n+    a boolean.\n+\n+    Example usage:\n+\n+    .. sourcecode:: jinja\n+\n+        {{ users|selectattr(\"is_active\") }}\n+        {{ users|selectattr(\"email\", \"none\") }}\n+\n+    .. versionadded:: 2.7\n+    \"\"\"\n+    return select_or_reject(args, kwargs, lambda x: x, True)\n+\n+\n+@contextfilter\n+def do_rejectattr(*args, **kwargs):\n+    \"\"\"Filters a sequence of objects by applying a test to the specified\n+    attribute of each object, and rejecting the objects with the test\n+    succeeding.\n+\n+    If no test is specified, the attribute's value will be evaluated as\n+    a boolean.\n+\n+    .. sourcecode:: jinja\n+\n+        {{ users|rejectattr(\"is_active\") }}\n+        {{ users|rejectattr(\"email\", \"none\") }}\n+\n+    .. versionadded:: 2.7\n+    \"\"\"\n+    return select_or_reject(args, kwargs, lambda x: not x, True)\n+\n+\n+@evalcontextfilter\n+def do_tojson(eval_ctx, value, indent=None):\n+    \"\"\"Dumps a structure to JSON so that it's safe to use in ``<script>``\n+    tags.  It accepts the same arguments and returns a JSON string.  Note that\n+    this is available in templates through the ``|tojson`` filter which will\n+    also mark the result as safe.  Due to how this function escapes certain\n+    characters this is safe even if used outside of ``<script>`` tags.\n+\n+    The following characters are escaped in strings:\n+\n+    -   ``<``\n+    -   ``>``\n+    -   ``&``\n+    -   ``'``\n+\n+    This makes it safe to embed such strings in any place in HTML with the\n+    notable exception of double quoted attributes.  In that case single\n+    quote your attributes or HTML escape it in addition.\n+\n+    The indent parameter can be used to enable pretty printing.  Set it to\n+    the number of spaces that the structures should be indented with.\n+\n+    Note that this filter is for use in HTML contexts only.\n+\n+    .. versionadded:: 2.9\n+    \"\"\"\n+    policies = eval_ctx.environment.policies\n+    dumper = policies['json.dumps_function']\n+    options = policies['json.dumps_kwargs']\n+    if indent is not None:\n+        options = dict(options)\n+        options['indent'] = indent\n+    return htmlsafe_json_dumps(value, dumper=dumper, **options)\n+\n+\n+def prepare_map(args, kwargs):\n+    context = args[0]\n+    seq = args[1]\n+\n+    if len(args) == 2 and 'attribute' in kwargs:\n+        attribute = kwargs.pop('attribute')\n+        if kwargs:\n+            raise FilterArgumentError('Unexpected keyword argument %r' %\n+                next(iter(kwargs)))\n+        func = make_attrgetter(context.environment, attribute)\n+    else:\n+        try:\n+            name = args[2]\n+            args = args[3:]\n+        except LookupError:\n+            raise FilterArgumentError('map requires a filter argument')\n+        func = lambda item: context.environment.call_filter(\n+            name, item, args, kwargs, context=context)\n+\n+    return seq, func\n+\n+\n+def prepare_select_or_reject(args, kwargs, modfunc, lookup_attr):\n+    context = args[0]\n+    seq = args[1]\n+    if lookup_attr:\n+        try:\n+            attr = args[2]\n+        except LookupError:\n+            raise FilterArgumentError('Missing parameter for attribute name')\n+        transfunc = make_attrgetter(context.environment, attr)\n+        off = 1\n+    else:\n+        off = 0\n+        transfunc = lambda x: x\n+\n+    try:\n+        name = args[2 + off]\n+        args = args[3 + off:]\n+        func = lambda item: context.environment.call_test(\n+            name, item, args, kwargs)\n+    except LookupError:\n+        func = bool\n+\n+    return seq, lambda item: modfunc(func(transfunc(item)))\n+\n+\n+def select_or_reject(args, kwargs, modfunc, lookup_attr):\n+    seq, func = prepare_select_or_reject(args, kwargs, modfunc, lookup_attr)\n+    if seq:\n+        for item in seq:\n+            if func(item):\n+                yield item\n+\n+\n+FILTERS = {\n+    'abs':                  abs,\n+    'attr':                 do_attr,\n+    'batch':                do_batch,\n+    'capitalize':           do_capitalize,\n+    'center':               do_center,\n+    'count':                len,\n+    'd':                    do_default,\n+    'default':              do_default,\n+    'dictsort':             do_dictsort,\n+    'e':                    escape,\n+    'escape':               escape,\n+    'filesizeformat':       do_filesizeformat,\n+    'first':                do_first,\n+    'float':                do_float,\n+    'forceescape':          do_forceescape,\n+    'format':               do_format,\n+    'groupby':              do_groupby,\n+    'indent':               do_indent,\n+    'int':                  do_int,\n+    'join':                 do_join,\n+    'last':                 do_last,\n+    'length':               len,\n+    'list':                 do_list,\n+    'lower':                do_lower,\n+    'map':                  do_map,\n+    'min':                  do_min,\n+    'max':                  do_max,\n+    'pprint':               do_pprint,\n+    'random':               do_random,\n+    'reject':               do_reject,\n+    'rejectattr':           do_rejectattr,\n+    'replace':              do_replace,\n+    'reverse':              do_reverse,\n+    'round':                do_round,\n+    'safe':                 do_mark_safe,\n+    'select':               do_select,\n+    'selectattr':           do_selectattr,\n+    'slice':                do_slice,\n+    'sort':                 do_sort,\n+    'string':               soft_unicode,\n+    'striptags':            do_striptags,\n+    'sum':                  do_sum,\n+    'title':                do_title,\n+    'trim':                 do_trim,\n+    'truncate':             do_truncate,\n+    'unique':               do_unique,\n+    'upper':                do_upper,\n+    'urlencode':            do_urlencode,\n+    'urlize':               do_urlize,\n+    'wordcount':            do_wordcount,\n+    'wordwrap':             do_wordwrap,\n+    'xmlattr':              do_xmlattr,\n+    'tojson':               do_tojson,\n+}"
        },
        {
            "sha": "bc6c4c3068f216a3ce270a3f1ecf512df8883967",
            "filename": "tools/jinja2/get_jinja2.sh",
            "status": "added",
            "additions": 136,
            "deletions": 0,
            "changes": 136,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fget_jinja2.sh",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fget_jinja2.sh",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fget_jinja2.sh?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,136 @@\n+#!/bin/bash\n+# Download and extract Jinja2\n+# Homepage:\n+# http://jinja.pocoo.org/\n+# Installation instructions:\n+# http://jinja.pocoo.org/docs/intro/#from-the-tarball-release\n+# Download page:\n+# https://pypi.python.org/pypi/Jinja2\n+PACKAGE='Jinja2'\n+VERSION='2.10'\n+SRC_URL='https://pypi.python.org/packages/56/e6/332789f295cf22308386cf5bbd1f4e00ed11484299c5d7383378cf48ba47/Jinja2-2.10.tar.gz'\n+PACKAGE_DIR='jinja2'\n+\n+CHROMIUM_FILES=\"README.chromium OWNERS get_jinja2.sh\"\n+EXTRA_FILES='LICENSE AUTHORS'\n+REMOVE_FILES='testsuite'\n+\n+FILENAME=\"$(basename $SRC_URL)\"\n+MD5_FILENAME=\"$FILENAME.md5\"\n+SHA512_FILENAME=\"$FILENAME.sha512\"\n+CHROMIUM_FILES+=\" $MD5_FILENAME $SHA512_FILENAME\"\n+\n+BUILD_DIR=\"$PACKAGE-$VERSION\"\n+THIRD_PARTY=\"$(dirname $(realpath $(dirname \"${BASH_SOURCE[0]}\")))\"\n+INSTALL_DIR=\"$THIRD_PARTY/$PACKAGE_DIR\"\n+OUT_DIR=\"$INSTALL_DIR/$BUILD_DIR/$PACKAGE_DIR\"\n+OLD_DIR=\"$THIRD_PARTY/$PACKAGE_DIR.old\"\n+\n+function check_hashes {\n+  # Hashes generated via:\n+  # FILENAME=Jinja2-2.8.tar.gz\n+  # md5sum \"$FILENAME\" > \"$FILENAME.md5\"\n+  # sha512sum \"$FILENAME\" > \"$FILENAME.sha512\"\n+  # unset FILENAME\n+\n+  # MD5\n+  if ! [ -f \"$MD5_FILENAME\" ]\n+  then\n+    echo \"MD5 hash file $MD5_FILENAME not found, could not verify archive\"\n+    exit 1\n+  fi\n+\n+  # 32-digit hash, followed by filename\n+  MD5_HASHFILE_REGEX=\"^[0-9a-f]{32}  $FILENAME\"\n+  if ! grep --extended-regex --line-regex --silent \\\n+    \"$MD5_HASHFILE_REGEX\" \"$MD5_FILENAME\"\n+  then\n+    echo \"MD5 hash file $MD5_FILENAME does not contain hash for $FILENAME,\" \\\n+         'could not verify archive'\n+    echo 'Hash file contents are:'\n+    cat \"$MD5_FILENAME\"\n+    exit 1\n+  fi\n+\n+  if ! md5sum --check \"$MD5_FILENAME\"\n+  then\n+    echo 'MD5 hash does not match,' \\\n+         \"archive file $FILENAME corrupt or compromised!\"\n+    exit 1\n+  fi\n+\n+  # SHA-512\n+  if ! [ -f \"$SHA512_FILENAME\" ]\n+  then\n+    echo \"SHA-512 hash file $SHA512_FILENAME not found,\" \\\n+         'could not verify archive'\n+    exit 1\n+  fi\n+\n+  # 128-digit hash, followed by filename\n+  SHA512_HASHFILE_REGEX=\"^[0-9a-f]{128}  $FILENAME\"\n+  if ! grep --extended-regex --line-regex --silent \\\n+    \"$SHA512_HASHFILE_REGEX\" \"$SHA512_FILENAME\"\n+  then\n+    echo \"SHA-512 hash file $SHA512_FILENAME does not contain hash for\" \\\n+         \"$FILENAME, could not verify archive\"\n+    echo 'Hash file contents are:'\n+    cat \"$SHA512_FILENAME\"\n+    exit 1\n+  fi\n+\n+  if ! sha512sum --check \"$SHA512_FILENAME\"\n+  then\n+    echo 'SHA-512 hash does not match,' \\\n+         \"archive file $FILENAME corrupt or compromised!\"\n+    exit 1\n+  fi\n+}\n+\n+\n+################################################################################\n+# Body\n+\n+cd \"$INSTALL_DIR\"\n+echo \"Downloading $SRC_URL\"\n+curl --remote-name \"$SRC_URL\"\n+check_hashes\n+tar xvzf \"$FILENAME\"\n+# Copy extra files over\n+for FILE in $CHROMIUM_FILES\n+do\n+  cp \"$FILE\" \"$OUT_DIR\"\n+done\n+\n+cd \"$BUILD_DIR\"\n+for FILE in $EXTRA_FILES\n+do\n+  cp \"$FILE\" \"$OUT_DIR\"\n+done\n+\n+cd \"$OUT_DIR\"\n+for FILE in $REMOVE_FILES\n+do\n+  rm -fr \"$FILE\"\n+done\n+\n+# Replace with new directory\n+cd ..\n+mv \"$INSTALL_DIR\" \"$OLD_DIR\"\n+mv \"$PACKAGE_DIR\" \"$INSTALL_DIR\"\n+cd \"$INSTALL_DIR\"\n+rm -fr \"$OLD_DIR\"\n+\n+# Generating jinja2.gni\n+cat > jinja2.gni <<EOF\n+# DO NOT EDIT\n+# This is generated from get_jinja2.sh.\n+jinja2_sources = [\n+EOF\n+\n+for i in $(LC_COLLATE=C ls *.py)\n+do\n+  echo \"  \\\"//third_party/jinja2/${i}\\\",\" >> jinja2.gni\n+done\n+\n+echo \"]\" >> jinja2.gni"
        },
        {
            "sha": "491bfe083647c9d914b1641432000c3dcd625c22",
            "filename": "tools/jinja2/idtracking.py",
            "status": "added",
            "additions": 286,
            "deletions": 0,
            "changes": 286,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fidtracking.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fidtracking.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fidtracking.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,286 @@\n+from jinja2.visitor import NodeVisitor\n+from jinja2._compat import iteritems\n+\n+\n+VAR_LOAD_PARAMETER = 'param'\n+VAR_LOAD_RESOLVE = 'resolve'\n+VAR_LOAD_ALIAS = 'alias'\n+VAR_LOAD_UNDEFINED = 'undefined'\n+\n+\n+def find_symbols(nodes, parent_symbols=None):\n+    sym = Symbols(parent=parent_symbols)\n+    visitor = FrameSymbolVisitor(sym)\n+    for node in nodes:\n+        visitor.visit(node)\n+    return sym\n+\n+\n+def symbols_for_node(node, parent_symbols=None):\n+    sym = Symbols(parent=parent_symbols)\n+    sym.analyze_node(node)\n+    return sym\n+\n+\n+class Symbols(object):\n+\n+    def __init__(self, parent=None, level=None):\n+        if level is None:\n+            if parent is None:\n+                level = 0\n+            else:\n+                level = parent.level + 1\n+        self.level = level\n+        self.parent = parent\n+        self.refs = {}\n+        self.loads = {}\n+        self.stores = set()\n+\n+    def analyze_node(self, node, **kwargs):\n+        visitor = RootVisitor(self)\n+        visitor.visit(node, **kwargs)\n+\n+    def _define_ref(self, name, load=None):\n+        ident = 'l_%d_%s' % (self.level, name)\n+        self.refs[name] = ident\n+        if load is not None:\n+            self.loads[ident] = load\n+        return ident\n+\n+    def find_load(self, target):\n+        if target in self.loads:\n+            return self.loads[target]\n+        if self.parent is not None:\n+            return self.parent.find_load(target)\n+\n+    def find_ref(self, name):\n+        if name in self.refs:\n+            return self.refs[name]\n+        if self.parent is not None:\n+            return self.parent.find_ref(name)\n+\n+    def ref(self, name):\n+        rv = self.find_ref(name)\n+        if rv is None:\n+            raise AssertionError('Tried to resolve a name to a reference that '\n+                                 'was unknown to the frame (%r)' % name)\n+        return rv\n+\n+    def copy(self):\n+        rv = object.__new__(self.__class__)\n+        rv.__dict__.update(self.__dict__)\n+        rv.refs = self.refs.copy()\n+        rv.loads = self.loads.copy()\n+        rv.stores = self.stores.copy()\n+        return rv\n+\n+    def store(self, name):\n+        self.stores.add(name)\n+\n+        # If we have not see the name referenced yet, we need to figure\n+        # out what to set it to.\n+        if name not in self.refs:\n+            # If there is a parent scope we check if the name has a\n+            # reference there.  If it does it means we might have to alias\n+            # to a variable there.\n+            if self.parent is not None:\n+                outer_ref = self.parent.find_ref(name)\n+                if outer_ref is not None:\n+                    self._define_ref(name, load=(VAR_LOAD_ALIAS, outer_ref))\n+                    return\n+\n+            # Otherwise we can just set it to undefined.\n+            self._define_ref(name, load=(VAR_LOAD_UNDEFINED, None))\n+\n+    def declare_parameter(self, name):\n+        self.stores.add(name)\n+        return self._define_ref(name, load=(VAR_LOAD_PARAMETER, None))\n+\n+    def load(self, name):\n+        target = self.find_ref(name)\n+        if target is None:\n+            self._define_ref(name, load=(VAR_LOAD_RESOLVE, name))\n+\n+    def branch_update(self, branch_symbols):\n+        stores = {}\n+        for branch in branch_symbols:\n+            for target in branch.stores:\n+                if target in self.stores:\n+                    continue\n+                stores[target] = stores.get(target, 0) + 1\n+\n+        for sym in branch_symbols:\n+            self.refs.update(sym.refs)\n+            self.loads.update(sym.loads)\n+            self.stores.update(sym.stores)\n+\n+        for name, branch_count in iteritems(stores):\n+            if branch_count == len(branch_symbols):\n+                continue\n+            target = self.find_ref(name)\n+            assert target is not None, 'should not happen'\n+\n+            if self.parent is not None:\n+                outer_target = self.parent.find_ref(name)\n+                if outer_target is not None:\n+                    self.loads[target] = (VAR_LOAD_ALIAS, outer_target)\n+                    continue\n+            self.loads[target] = (VAR_LOAD_RESOLVE, name)\n+\n+    def dump_stores(self):\n+        rv = {}\n+        node = self\n+        while node is not None:\n+            for name in node.stores:\n+                if name not in rv:\n+                    rv[name] = self.find_ref(name)\n+            node = node.parent\n+        return rv\n+\n+    def dump_param_targets(self):\n+        rv = set()\n+        node = self\n+        while node is not None:\n+            for target, (instr, _) in iteritems(self.loads):\n+                if instr == VAR_LOAD_PARAMETER:\n+                    rv.add(target)\n+            node = node.parent\n+        return rv\n+\n+\n+class RootVisitor(NodeVisitor):\n+\n+    def __init__(self, symbols):\n+        self.sym_visitor = FrameSymbolVisitor(symbols)\n+\n+    def _simple_visit(self, node, **kwargs):\n+        for child in node.iter_child_nodes():\n+            self.sym_visitor.visit(child)\n+\n+    visit_Template = visit_Block = visit_Macro = visit_FilterBlock = \\\n+        visit_Scope = visit_If = visit_ScopedEvalContextModifier = \\\n+        _simple_visit\n+\n+    def visit_AssignBlock(self, node, **kwargs):\n+        for child in node.body:\n+            self.sym_visitor.visit(child)\n+\n+    def visit_CallBlock(self, node, **kwargs):\n+        for child in node.iter_child_nodes(exclude=('call',)):\n+            self.sym_visitor.visit(child)\n+\n+    def visit_OverlayScope(self, node, **kwargs):\n+        for child in node.body:\n+            self.sym_visitor.visit(child)\n+\n+    def visit_For(self, node, for_branch='body', **kwargs):\n+        if for_branch == 'body':\n+            self.sym_visitor.visit(node.target, store_as_param=True)\n+            branch = node.body\n+        elif for_branch == 'else':\n+            branch = node.else_\n+        elif for_branch == 'test':\n+            self.sym_visitor.visit(node.target, store_as_param=True)\n+            if node.test is not None:\n+                self.sym_visitor.visit(node.test)\n+            return\n+        else:\n+            raise RuntimeError('Unknown for branch')\n+        for item in branch or ():\n+            self.sym_visitor.visit(item)\n+\n+    def visit_With(self, node, **kwargs):\n+        for target in node.targets:\n+            self.sym_visitor.visit(target)\n+        for child in node.body:\n+            self.sym_visitor.visit(child)\n+\n+    def generic_visit(self, node, *args, **kwargs):\n+        raise NotImplementedError('Cannot find symbols for %r' %\n+                                  node.__class__.__name__)\n+\n+\n+class FrameSymbolVisitor(NodeVisitor):\n+    \"\"\"A visitor for `Frame.inspect`.\"\"\"\n+\n+    def __init__(self, symbols):\n+        self.symbols = symbols\n+\n+    def visit_Name(self, node, store_as_param=False, **kwargs):\n+        \"\"\"All assignments to names go through this function.\"\"\"\n+        if store_as_param or node.ctx == 'param':\n+            self.symbols.declare_parameter(node.name)\n+        elif node.ctx == 'store':\n+            self.symbols.store(node.name)\n+        elif node.ctx == 'load':\n+            self.symbols.load(node.name)\n+\n+    def visit_NSRef(self, node, **kwargs):\n+        self.symbols.load(node.name)\n+\n+    def visit_If(self, node, **kwargs):\n+        self.visit(node.test, **kwargs)\n+\n+        original_symbols = self.symbols\n+\n+        def inner_visit(nodes):\n+            self.symbols = rv = original_symbols.copy()\n+            for subnode in nodes:\n+                self.visit(subnode, **kwargs)\n+            self.symbols = original_symbols\n+            return rv\n+\n+        body_symbols = inner_visit(node.body)\n+        elif_symbols = inner_visit(node.elif_)\n+        else_symbols = inner_visit(node.else_ or ())\n+\n+        self.symbols.branch_update([body_symbols, elif_symbols, else_symbols])\n+\n+    def visit_Macro(self, node, **kwargs):\n+        self.symbols.store(node.name)\n+\n+    def visit_Import(self, node, **kwargs):\n+        self.generic_visit(node, **kwargs)\n+        self.symbols.store(node.target)\n+\n+    def visit_FromImport(self, node, **kwargs):\n+        self.generic_visit(node, **kwargs)\n+        for name in node.names:\n+            if isinstance(name, tuple):\n+                self.symbols.store(name[1])\n+            else:\n+                self.symbols.store(name)\n+\n+    def visit_Assign(self, node, **kwargs):\n+        \"\"\"Visit assignments in the correct order.\"\"\"\n+        self.visit(node.node, **kwargs)\n+        self.visit(node.target, **kwargs)\n+\n+    def visit_For(self, node, **kwargs):\n+        \"\"\"Visiting stops at for blocks.  However the block sequence\n+        is visited as part of the outer scope.\n+        \"\"\"\n+        self.visit(node.iter, **kwargs)\n+\n+    def visit_CallBlock(self, node, **kwargs):\n+        self.visit(node.call, **kwargs)\n+\n+    def visit_FilterBlock(self, node, **kwargs):\n+        self.visit(node.filter, **kwargs)\n+\n+    def visit_With(self, node, **kwargs):\n+        for target in node.values:\n+            self.visit(target)\n+\n+    def visit_AssignBlock(self, node, **kwargs):\n+        \"\"\"Stop visiting at block assigns.\"\"\"\n+        self.visit(node.target, **kwargs)\n+\n+    def visit_Scope(self, node, **kwargs):\n+        \"\"\"Stop visiting at scopes.\"\"\"\n+\n+    def visit_Block(self, node, **kwargs):\n+        \"\"\"Stop visiting at blocks.\"\"\"\n+\n+    def visit_OverlayScope(self, node, **kwargs):\n+        \"\"\"Do not visit into overlay scopes.\"\"\""
        },
        {
            "sha": "cef0d48a883ef5d7af9220ad6c2b8f7ba36f6441",
            "filename": "tools/jinja2/jinja2.gni",
            "status": "added",
            "additions": 31,
            "deletions": 0,
            "changes": 31,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fjinja2.gni",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fjinja2.gni",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fjinja2.gni?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,31 @@\n+# DO NOT EDIT\n+# This is generated from get_jinja2.sh.\n+jinja2_sources = [\n+  \"//third_party/jinja2/__init__.py\",\n+  \"//third_party/jinja2/_compat.py\",\n+  \"//third_party/jinja2/_identifier.py\",\n+  \"//third_party/jinja2/asyncfilters.py\",\n+  \"//third_party/jinja2/asyncsupport.py\",\n+  \"//third_party/jinja2/bccache.py\",\n+  \"//third_party/jinja2/compiler.py\",\n+  \"//third_party/jinja2/constants.py\",\n+  \"//third_party/jinja2/debug.py\",\n+  \"//third_party/jinja2/defaults.py\",\n+  \"//third_party/jinja2/environment.py\",\n+  \"//third_party/jinja2/exceptions.py\",\n+  \"//third_party/jinja2/ext.py\",\n+  \"//third_party/jinja2/filters.py\",\n+  \"//third_party/jinja2/idtracking.py\",\n+  \"//third_party/jinja2/lexer.py\",\n+  \"//third_party/jinja2/loaders.py\",\n+  \"//third_party/jinja2/meta.py\",\n+  \"//third_party/jinja2/nativetypes.py\",\n+  \"//third_party/jinja2/nodes.py\",\n+  \"//third_party/jinja2/optimizer.py\",\n+  \"//third_party/jinja2/parser.py\",\n+  \"//third_party/jinja2/runtime.py\",\n+  \"//third_party/jinja2/sandbox.py\",\n+  \"//third_party/jinja2/tests.py\",\n+  \"//third_party/jinja2/utils.py\",\n+  \"//third_party/jinja2/visitor.py\",\n+]"
        },
        {
            "sha": "6fd135dd5b0a3a31896794ab2f25cd68582752ce",
            "filename": "tools/jinja2/lexer.py",
            "status": "added",
            "additions": 739,
            "deletions": 0,
            "changes": 739,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Flexer.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Flexer.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Flexer.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,739 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.lexer\n+    ~~~~~~~~~~~~\n+\n+    This module implements a Jinja / Python combination lexer. The\n+    `Lexer` class provided by this module is used to do some preprocessing\n+    for Jinja.\n+\n+    On the one hand it filters out invalid operators like the bitshift\n+    operators we don't allow in templates. On the other hand it separates\n+    template code and python code in expressions.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+import re\n+from collections import deque\n+from operator import itemgetter\n+\n+from jinja2._compat import implements_iterator, intern, iteritems, text_type\n+from jinja2.exceptions import TemplateSyntaxError\n+from jinja2.utils import LRUCache\n+\n+# cache for the lexers. Exists in order to be able to have multiple\n+# environments with the same lexer\n+_lexer_cache = LRUCache(50)\n+\n+# static regular expressions\n+whitespace_re = re.compile(r'\\s+', re.U)\n+string_re = re.compile(r\"('([^'\\\\]*(?:\\\\.[^'\\\\]*)*)'\"\n+                       r'|\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\")', re.S)\n+integer_re = re.compile(r'\\d+')\n+\n+try:\n+    # check if this Python supports Unicode identifiers\n+    compile('f', '<unknown>', 'eval')\n+except SyntaxError:\n+    # no Unicode support, use ASCII identifiers\n+    name_re = re.compile(r'[a-zA-Z_][a-zA-Z0-9_]*')\n+    check_ident = False\n+else:\n+    # Unicode support, build a pattern to match valid characters, and set flag\n+    # to use str.isidentifier to validate during lexing\n+    from jinja2 import _identifier\n+    name_re = re.compile(r'[\\w{0}]+'.format(_identifier.pattern))\n+    check_ident = True\n+    # remove the pattern from memory after building the regex\n+    import sys\n+    del sys.modules['jinja2._identifier']\n+    import jinja2\n+    del jinja2._identifier\n+    del _identifier\n+\n+float_re = re.compile(r'(?<!\\.)\\d+\\.\\d+')\n+newline_re = re.compile(r'(\\r\\n|\\r|\\n)')\n+\n+# internal the tokens and keep references to them\n+TOKEN_ADD = intern('add')\n+TOKEN_ASSIGN = intern('assign')\n+TOKEN_COLON = intern('colon')\n+TOKEN_COMMA = intern('comma')\n+TOKEN_DIV = intern('div')\n+TOKEN_DOT = intern('dot')\n+TOKEN_EQ = intern('eq')\n+TOKEN_FLOORDIV = intern('floordiv')\n+TOKEN_GT = intern('gt')\n+TOKEN_GTEQ = intern('gteq')\n+TOKEN_LBRACE = intern('lbrace')\n+TOKEN_LBRACKET = intern('lbracket')\n+TOKEN_LPAREN = intern('lparen')\n+TOKEN_LT = intern('lt')\n+TOKEN_LTEQ = intern('lteq')\n+TOKEN_MOD = intern('mod')\n+TOKEN_MUL = intern('mul')\n+TOKEN_NE = intern('ne')\n+TOKEN_PIPE = intern('pipe')\n+TOKEN_POW = intern('pow')\n+TOKEN_RBRACE = intern('rbrace')\n+TOKEN_RBRACKET = intern('rbracket')\n+TOKEN_RPAREN = intern('rparen')\n+TOKEN_SEMICOLON = intern('semicolon')\n+TOKEN_SUB = intern('sub')\n+TOKEN_TILDE = intern('tilde')\n+TOKEN_WHITESPACE = intern('whitespace')\n+TOKEN_FLOAT = intern('float')\n+TOKEN_INTEGER = intern('integer')\n+TOKEN_NAME = intern('name')\n+TOKEN_STRING = intern('string')\n+TOKEN_OPERATOR = intern('operator')\n+TOKEN_BLOCK_BEGIN = intern('block_begin')\n+TOKEN_BLOCK_END = intern('block_end')\n+TOKEN_VARIABLE_BEGIN = intern('variable_begin')\n+TOKEN_VARIABLE_END = intern('variable_end')\n+TOKEN_RAW_BEGIN = intern('raw_begin')\n+TOKEN_RAW_END = intern('raw_end')\n+TOKEN_COMMENT_BEGIN = intern('comment_begin')\n+TOKEN_COMMENT_END = intern('comment_end')\n+TOKEN_COMMENT = intern('comment')\n+TOKEN_LINESTATEMENT_BEGIN = intern('linestatement_begin')\n+TOKEN_LINESTATEMENT_END = intern('linestatement_end')\n+TOKEN_LINECOMMENT_BEGIN = intern('linecomment_begin')\n+TOKEN_LINECOMMENT_END = intern('linecomment_end')\n+TOKEN_LINECOMMENT = intern('linecomment')\n+TOKEN_DATA = intern('data')\n+TOKEN_INITIAL = intern('initial')\n+TOKEN_EOF = intern('eof')\n+\n+# bind operators to token types\n+operators = {\n+    '+':            TOKEN_ADD,\n+    '-':            TOKEN_SUB,\n+    '/':            TOKEN_DIV,\n+    '//':           TOKEN_FLOORDIV,\n+    '*':            TOKEN_MUL,\n+    '%':            TOKEN_MOD,\n+    '**':           TOKEN_POW,\n+    '~':            TOKEN_TILDE,\n+    '[':            TOKEN_LBRACKET,\n+    ']':            TOKEN_RBRACKET,\n+    '(':            TOKEN_LPAREN,\n+    ')':            TOKEN_RPAREN,\n+    '{':            TOKEN_LBRACE,\n+    '}':            TOKEN_RBRACE,\n+    '==':           TOKEN_EQ,\n+    '!=':           TOKEN_NE,\n+    '>':            TOKEN_GT,\n+    '>=':           TOKEN_GTEQ,\n+    '<':            TOKEN_LT,\n+    '<=':           TOKEN_LTEQ,\n+    '=':            TOKEN_ASSIGN,\n+    '.':            TOKEN_DOT,\n+    ':':            TOKEN_COLON,\n+    '|':            TOKEN_PIPE,\n+    ',':            TOKEN_COMMA,\n+    ';':            TOKEN_SEMICOLON\n+}\n+\n+reverse_operators = dict([(v, k) for k, v in iteritems(operators)])\n+assert len(operators) == len(reverse_operators), 'operators dropped'\n+operator_re = re.compile('(%s)' % '|'.join(re.escape(x) for x in\n+                         sorted(operators, key=lambda x: -len(x))))\n+\n+ignored_tokens = frozenset([TOKEN_COMMENT_BEGIN, TOKEN_COMMENT,\n+                            TOKEN_COMMENT_END, TOKEN_WHITESPACE,\n+                            TOKEN_LINECOMMENT_BEGIN, TOKEN_LINECOMMENT_END,\n+                            TOKEN_LINECOMMENT])\n+ignore_if_empty = frozenset([TOKEN_WHITESPACE, TOKEN_DATA,\n+                             TOKEN_COMMENT, TOKEN_LINECOMMENT])\n+\n+\n+def _describe_token_type(token_type):\n+    if token_type in reverse_operators:\n+        return reverse_operators[token_type]\n+    return {\n+        TOKEN_COMMENT_BEGIN:        'begin of comment',\n+        TOKEN_COMMENT_END:          'end of comment',\n+        TOKEN_COMMENT:              'comment',\n+        TOKEN_LINECOMMENT:          'comment',\n+        TOKEN_BLOCK_BEGIN:          'begin of statement block',\n+        TOKEN_BLOCK_END:            'end of statement block',\n+        TOKEN_VARIABLE_BEGIN:       'begin of print statement',\n+        TOKEN_VARIABLE_END:         'end of print statement',\n+        TOKEN_LINESTATEMENT_BEGIN:  'begin of line statement',\n+        TOKEN_LINESTATEMENT_END:    'end of line statement',\n+        TOKEN_DATA:                 'template data / text',\n+        TOKEN_EOF:                  'end of template'\n+    }.get(token_type, token_type)\n+\n+\n+def describe_token(token):\n+    \"\"\"Returns a description of the token.\"\"\"\n+    if token.type == 'name':\n+        return token.value\n+    return _describe_token_type(token.type)\n+\n+\n+def describe_token_expr(expr):\n+    \"\"\"Like `describe_token` but for token expressions.\"\"\"\n+    if ':' in expr:\n+        type, value = expr.split(':', 1)\n+        if type == 'name':\n+            return value\n+    else:\n+        type = expr\n+    return _describe_token_type(type)\n+\n+\n+def count_newlines(value):\n+    \"\"\"Count the number of newline characters in the string.  This is\n+    useful for extensions that filter a stream.\n+    \"\"\"\n+    return len(newline_re.findall(value))\n+\n+\n+def compile_rules(environment):\n+    \"\"\"Compiles all the rules from the environment into a list of rules.\"\"\"\n+    e = re.escape\n+    rules = [\n+        (len(environment.comment_start_string), 'comment',\n+         e(environment.comment_start_string)),\n+        (len(environment.block_start_string), 'block',\n+         e(environment.block_start_string)),\n+        (len(environment.variable_start_string), 'variable',\n+         e(environment.variable_start_string))\n+    ]\n+\n+    if environment.line_statement_prefix is not None:\n+        rules.append((len(environment.line_statement_prefix), 'linestatement',\n+                      r'^[ \\t\\v]*' + e(environment.line_statement_prefix)))\n+    if environment.line_comment_prefix is not None:\n+        rules.append((len(environment.line_comment_prefix), 'linecomment',\n+                      r'(?:^|(?<=\\S))[^\\S\\r\\n]*' +\n+                      e(environment.line_comment_prefix)))\n+\n+    return [x[1:] for x in sorted(rules, reverse=True)]\n+\n+\n+class Failure(object):\n+    \"\"\"Class that raises a `TemplateSyntaxError` if called.\n+    Used by the `Lexer` to specify known errors.\n+    \"\"\"\n+\n+    def __init__(self, message, cls=TemplateSyntaxError):\n+        self.message = message\n+        self.error_class = cls\n+\n+    def __call__(self, lineno, filename):\n+        raise self.error_class(self.message, lineno, filename)\n+\n+\n+class Token(tuple):\n+    \"\"\"Token class.\"\"\"\n+    __slots__ = ()\n+    lineno, type, value = (property(itemgetter(x)) for x in range(3))\n+\n+    def __new__(cls, lineno, type, value):\n+        return tuple.__new__(cls, (lineno, intern(str(type)), value))\n+\n+    def __str__(self):\n+        if self.type in reverse_operators:\n+            return reverse_operators[self.type]\n+        elif self.type == 'name':\n+            return self.value\n+        return self.type\n+\n+    def test(self, expr):\n+        \"\"\"Test a token against a token expression.  This can either be a\n+        token type or ``'token_type:token_value'``.  This can only test\n+        against string values and types.\n+        \"\"\"\n+        # here we do a regular string equality check as test_any is usually\n+        # passed an iterable of not interned strings.\n+        if self.type == expr:\n+            return True\n+        elif ':' in expr:\n+            return expr.split(':', 1) == [self.type, self.value]\n+        return False\n+\n+    def test_any(self, *iterable):\n+        \"\"\"Test against multiple token expressions.\"\"\"\n+        for expr in iterable:\n+            if self.test(expr):\n+                return True\n+        return False\n+\n+    def __repr__(self):\n+        return 'Token(%r, %r, %r)' % (\n+            self.lineno,\n+            self.type,\n+            self.value\n+        )\n+\n+\n+@implements_iterator\n+class TokenStreamIterator(object):\n+    \"\"\"The iterator for tokenstreams.  Iterate over the stream\n+    until the eof token is reached.\n+    \"\"\"\n+\n+    def __init__(self, stream):\n+        self.stream = stream\n+\n+    def __iter__(self):\n+        return self\n+\n+    def __next__(self):\n+        token = self.stream.current\n+        if token.type is TOKEN_EOF:\n+            self.stream.close()\n+            raise StopIteration()\n+        next(self.stream)\n+        return token\n+\n+\n+@implements_iterator\n+class TokenStream(object):\n+    \"\"\"A token stream is an iterable that yields :class:`Token`\\\\s.  The\n+    parser however does not iterate over it but calls :meth:`next` to go\n+    one token ahead.  The current active token is stored as :attr:`current`.\n+    \"\"\"\n+\n+    def __init__(self, generator, name, filename):\n+        self._iter = iter(generator)\n+        self._pushed = deque()\n+        self.name = name\n+        self.filename = filename\n+        self.closed = False\n+        self.current = Token(1, TOKEN_INITIAL, '')\n+        next(self)\n+\n+    def __iter__(self):\n+        return TokenStreamIterator(self)\n+\n+    def __bool__(self):\n+        return bool(self._pushed) or self.current.type is not TOKEN_EOF\n+    __nonzero__ = __bool__  # py2\n+\n+    eos = property(lambda x: not x, doc=\"Are we at the end of the stream?\")\n+\n+    def push(self, token):\n+        \"\"\"Push a token back to the stream.\"\"\"\n+        self._pushed.append(token)\n+\n+    def look(self):\n+        \"\"\"Look at the next token.\"\"\"\n+        old_token = next(self)\n+        result = self.current\n+        self.push(result)\n+        self.current = old_token\n+        return result\n+\n+    def skip(self, n=1):\n+        \"\"\"Got n tokens ahead.\"\"\"\n+        for x in range(n):\n+            next(self)\n+\n+    def next_if(self, expr):\n+        \"\"\"Perform the token test and return the token if it matched.\n+        Otherwise the return value is `None`.\n+        \"\"\"\n+        if self.current.test(expr):\n+            return next(self)\n+\n+    def skip_if(self, expr):\n+        \"\"\"Like :meth:`next_if` but only returns `True` or `False`.\"\"\"\n+        return self.next_if(expr) is not None\n+\n+    def __next__(self):\n+        \"\"\"Go one token ahead and return the old one.\n+\n+        Use the built-in :func:`next` instead of calling this directly.\n+        \"\"\"\n+        rv = self.current\n+        if self._pushed:\n+            self.current = self._pushed.popleft()\n+        elif self.current.type is not TOKEN_EOF:\n+            try:\n+                self.current = next(self._iter)\n+            except StopIteration:\n+                self.close()\n+        return rv\n+\n+    def close(self):\n+        \"\"\"Close the stream.\"\"\"\n+        self.current = Token(self.current.lineno, TOKEN_EOF, '')\n+        self._iter = None\n+        self.closed = True\n+\n+    def expect(self, expr):\n+        \"\"\"Expect a given token type and return it.  This accepts the same\n+        argument as :meth:`jinja2.lexer.Token.test`.\n+        \"\"\"\n+        if not self.current.test(expr):\n+            expr = describe_token_expr(expr)\n+            if self.current.type is TOKEN_EOF:\n+                raise TemplateSyntaxError('unexpected end of template, '\n+                                          'expected %r.' % expr,\n+                                          self.current.lineno,\n+                                          self.name, self.filename)\n+            raise TemplateSyntaxError(\"expected token %r, got %r\" %\n+                                      (expr, describe_token(self.current)),\n+                                      self.current.lineno,\n+                                      self.name, self.filename)\n+        try:\n+            return self.current\n+        finally:\n+            next(self)\n+\n+\n+def get_lexer(environment):\n+    \"\"\"Return a lexer which is probably cached.\"\"\"\n+    key = (environment.block_start_string,\n+           environment.block_end_string,\n+           environment.variable_start_string,\n+           environment.variable_end_string,\n+           environment.comment_start_string,\n+           environment.comment_end_string,\n+           environment.line_statement_prefix,\n+           environment.line_comment_prefix,\n+           environment.trim_blocks,\n+           environment.lstrip_blocks,\n+           environment.newline_sequence,\n+           environment.keep_trailing_newline)\n+    lexer = _lexer_cache.get(key)\n+    if lexer is None:\n+        lexer = Lexer(environment)\n+        _lexer_cache[key] = lexer\n+    return lexer\n+\n+\n+class Lexer(object):\n+    \"\"\"Class that implements a lexer for a given environment. Automatically\n+    created by the environment class, usually you don't have to do that.\n+\n+    Note that the lexer is not automatically bound to an environment.\n+    Multiple environments can share the same lexer.\n+    \"\"\"\n+\n+    def __init__(self, environment):\n+        # shortcuts\n+        c = lambda x: re.compile(x, re.M | re.S)\n+        e = re.escape\n+\n+        # lexing rules for tags\n+        tag_rules = [\n+            (whitespace_re, TOKEN_WHITESPACE, None),\n+            (float_re, TOKEN_FLOAT, None),\n+            (integer_re, TOKEN_INTEGER, None),\n+            (name_re, TOKEN_NAME, None),\n+            (string_re, TOKEN_STRING, None),\n+            (operator_re, TOKEN_OPERATOR, None)\n+        ]\n+\n+        # assemble the root lexing rule. because \"|\" is ungreedy\n+        # we have to sort by length so that the lexer continues working\n+        # as expected when we have parsing rules like <% for block and\n+        # <%= for variables. (if someone wants asp like syntax)\n+        # variables are just part of the rules if variable processing\n+        # is required.\n+        root_tag_rules = compile_rules(environment)\n+\n+        # block suffix if trimming is enabled\n+        block_suffix_re = environment.trim_blocks and '\\\\n?' or ''\n+\n+        # strip leading spaces if lstrip_blocks is enabled\n+        prefix_re = {}\n+        if environment.lstrip_blocks:\n+            # use '{%+' to manually disable lstrip_blocks behavior\n+            no_lstrip_re = e('+')\n+            # detect overlap between block and variable or comment strings\n+            block_diff = c(r'^%s(.*)' % e(environment.block_start_string))\n+            # make sure we don't mistake a block for a variable or a comment\n+            m = block_diff.match(environment.comment_start_string)\n+            no_lstrip_re += m and r'|%s' % e(m.group(1)) or ''\n+            m = block_diff.match(environment.variable_start_string)\n+            no_lstrip_re += m and r'|%s' % e(m.group(1)) or ''\n+\n+            # detect overlap between comment and variable strings\n+            comment_diff = c(r'^%s(.*)' % e(environment.comment_start_string))\n+            m = comment_diff.match(environment.variable_start_string)\n+            no_variable_re = m and r'(?!%s)' % e(m.group(1)) or ''\n+\n+            lstrip_re = r'^[ \\t]*'\n+            block_prefix_re = r'%s%s(?!%s)|%s\\+?' % (\n+                    lstrip_re,\n+                    e(environment.block_start_string),\n+                    no_lstrip_re,\n+                    e(environment.block_start_string),\n+                    )\n+            comment_prefix_re = r'%s%s%s|%s\\+?' % (\n+                    lstrip_re,\n+                    e(environment.comment_start_string),\n+                    no_variable_re,\n+                    e(environment.comment_start_string),\n+                    )\n+            prefix_re['block'] = block_prefix_re\n+            prefix_re['comment'] = comment_prefix_re\n+        else:\n+            block_prefix_re = '%s' % e(environment.block_start_string)\n+\n+        self.newline_sequence = environment.newline_sequence\n+        self.keep_trailing_newline = environment.keep_trailing_newline\n+\n+        # global lexing rules\n+        self.rules = {\n+            'root': [\n+                # directives\n+                (c('(.*?)(?:%s)' % '|'.join(\n+                    [r'(?P<raw_begin>(?:\\s*%s\\-|%s)\\s*raw\\s*(?:\\-%s\\s*|%s))' % (\n+                        e(environment.block_start_string),\n+                        block_prefix_re,\n+                        e(environment.block_end_string),\n+                        e(environment.block_end_string)\n+                    )] + [\n+                        r'(?P<%s_begin>\\s*%s\\-|%s)' % (n, r, prefix_re.get(n,r))\n+                        for n, r in root_tag_rules\n+                    ])), (TOKEN_DATA, '#bygroup'), '#bygroup'),\n+                # data\n+                (c('.+'), TOKEN_DATA, None)\n+            ],\n+            # comments\n+            TOKEN_COMMENT_BEGIN: [\n+                (c(r'(.*?)((?:\\-%s\\s*|%s)%s)' % (\n+                    e(environment.comment_end_string),\n+                    e(environment.comment_end_string),\n+                    block_suffix_re\n+                )), (TOKEN_COMMENT, TOKEN_COMMENT_END), '#pop'),\n+                (c('(.)'), (Failure('Missing end of comment tag'),), None)\n+            ],\n+            # blocks\n+            TOKEN_BLOCK_BEGIN: [\n+                (c(r'(?:\\-%s\\s*|%s)%s' % (\n+                    e(environment.block_end_string),\n+                    e(environment.block_end_string),\n+                    block_suffix_re\n+                )), TOKEN_BLOCK_END, '#pop'),\n+            ] + tag_rules,\n+            # variables\n+            TOKEN_VARIABLE_BEGIN: [\n+                (c(r'\\-%s\\s*|%s' % (\n+                    e(environment.variable_end_string),\n+                    e(environment.variable_end_string)\n+                )), TOKEN_VARIABLE_END, '#pop')\n+            ] + tag_rules,\n+            # raw block\n+            TOKEN_RAW_BEGIN: [\n+                (c(r'(.*?)((?:\\s*%s\\-|%s)\\s*endraw\\s*(?:\\-%s\\s*|%s%s))' % (\n+                    e(environment.block_start_string),\n+                    block_prefix_re,\n+                    e(environment.block_end_string),\n+                    e(environment.block_end_string),\n+                    block_suffix_re\n+                )), (TOKEN_DATA, TOKEN_RAW_END), '#pop'),\n+                (c('(.)'), (Failure('Missing end of raw directive'),), None)\n+            ],\n+            # line statements\n+            TOKEN_LINESTATEMENT_BEGIN: [\n+                (c(r'\\s*(\\n|$)'), TOKEN_LINESTATEMENT_END, '#pop')\n+            ] + tag_rules,\n+            # line comments\n+            TOKEN_LINECOMMENT_BEGIN: [\n+                (c(r'(.*?)()(?=\\n|$)'), (TOKEN_LINECOMMENT,\n+                 TOKEN_LINECOMMENT_END), '#pop')\n+            ]\n+        }\n+\n+    def _normalize_newlines(self, value):\n+        \"\"\"Called for strings and template data to normalize it to unicode.\"\"\"\n+        return newline_re.sub(self.newline_sequence, value)\n+\n+    def tokenize(self, source, name=None, filename=None, state=None):\n+        \"\"\"Calls tokeniter + tokenize and wraps it in a token stream.\n+        \"\"\"\n+        stream = self.tokeniter(source, name, filename, state)\n+        return TokenStream(self.wrap(stream, name, filename), name, filename)\n+\n+    def wrap(self, stream, name=None, filename=None):\n+        \"\"\"This is called with the stream as returned by `tokenize` and wraps\n+        every token in a :class:`Token` and converts the value.\n+        \"\"\"\n+        for lineno, token, value in stream:\n+            if token in ignored_tokens:\n+                continue\n+            elif token == 'linestatement_begin':\n+                token = 'block_begin'\n+            elif token == 'linestatement_end':\n+                token = 'block_end'\n+            # we are not interested in those tokens in the parser\n+            elif token in ('raw_begin', 'raw_end'):\n+                continue\n+            elif token == 'data':\n+                value = self._normalize_newlines(value)\n+            elif token == 'keyword':\n+                token = value\n+            elif token == 'name':\n+                value = str(value)\n+                if check_ident and not value.isidentifier():\n+                    raise TemplateSyntaxError(\n+                        'Invalid character in identifier',\n+                        lineno, name, filename)\n+            elif token == 'string':\n+                # try to unescape string\n+                try:\n+                    value = self._normalize_newlines(value[1:-1]) \\\n+                        .encode('ascii', 'backslashreplace') \\\n+                        .decode('unicode-escape')\n+                except Exception as e:\n+                    msg = str(e).split(':')[-1].strip()\n+                    raise TemplateSyntaxError(msg, lineno, name, filename)\n+            elif token == 'integer':\n+                value = int(value)\n+            elif token == 'float':\n+                value = float(value)\n+            elif token == 'operator':\n+                token = operators[value]\n+            yield Token(lineno, token, value)\n+\n+    def tokeniter(self, source, name, filename=None, state=None):\n+        \"\"\"This method tokenizes the text and returns the tokens in a\n+        generator.  Use this method if you just want to tokenize a template.\n+        \"\"\"\n+        source = text_type(source)\n+        lines = source.splitlines()\n+        if self.keep_trailing_newline and source:\n+            for newline in ('\\r\\n', '\\r', '\\n'):\n+                if source.endswith(newline):\n+                    lines.append('')\n+                    break\n+        source = '\\n'.join(lines)\n+        pos = 0\n+        lineno = 1\n+        stack = ['root']\n+        if state is not None and state != 'root':\n+            assert state in ('variable', 'block'), 'invalid state'\n+            stack.append(state + '_begin')\n+        else:\n+            state = 'root'\n+        statetokens = self.rules[stack[-1]]\n+        source_length = len(source)\n+\n+        balancing_stack = []\n+\n+        while 1:\n+            # tokenizer loop\n+            for regex, tokens, new_state in statetokens:\n+                m = regex.match(source, pos)\n+                # if no match we try again with the next rule\n+                if m is None:\n+                    continue\n+\n+                # we only match blocks and variables if braces / parentheses\n+                # are balanced. continue parsing with the lower rule which\n+                # is the operator rule. do this only if the end tags look\n+                # like operators\n+                if balancing_stack and \\\n+                   tokens in ('variable_end', 'block_end',\n+                              'linestatement_end'):\n+                    continue\n+\n+                # tuples support more options\n+                if isinstance(tokens, tuple):\n+                    for idx, token in enumerate(tokens):\n+                        # failure group\n+                        if token.__class__ is Failure:\n+                            raise token(lineno, filename)\n+                        # bygroup is a bit more complex, in that case we\n+                        # yield for the current token the first named\n+                        # group that matched\n+                        elif token == '#bygroup':\n+                            for key, value in iteritems(m.groupdict()):\n+                                if value is not None:\n+                                    yield lineno, key, value\n+                                    lineno += value.count('\\n')\n+                                    break\n+                            else:\n+                                raise RuntimeError('%r wanted to resolve '\n+                                                   'the token dynamically'\n+                                                   ' but no group matched'\n+                                                   % regex)\n+                        # normal group\n+                        else:\n+                            data = m.group(idx + 1)\n+                            if data or token not in ignore_if_empty:\n+                                yield lineno, token, data\n+                            lineno += data.count('\\n')\n+\n+                # strings as token just are yielded as it.\n+                else:\n+                    data = m.group()\n+                    # update brace/parentheses balance\n+                    if tokens == 'operator':\n+                        if data == '{':\n+                            balancing_stack.append('}')\n+                        elif data == '(':\n+                            balancing_stack.append(')')\n+                        elif data == '[':\n+                            balancing_stack.append(']')\n+                        elif data in ('}', ')', ']'):\n+                            if not balancing_stack:\n+                                raise TemplateSyntaxError('unexpected \\'%s\\'' %\n+                                                          data, lineno, name,\n+                                                          filename)\n+                            expected_op = balancing_stack.pop()\n+                            if expected_op != data:\n+                                raise TemplateSyntaxError('unexpected \\'%s\\', '\n+                                                          'expected \\'%s\\'' %\n+                                                          (data, expected_op),\n+                                                          lineno, name,\n+                                                          filename)\n+                    # yield items\n+                    if data or tokens not in ignore_if_empty:\n+                        yield lineno, tokens, data\n+                    lineno += data.count('\\n')\n+\n+                # fetch new position into new variable so that we can check\n+                # if there is a internal parsing error which would result\n+                # in an infinite loop\n+                pos2 = m.end()\n+\n+                # handle state changes\n+                if new_state is not None:\n+                    # remove the uppermost state\n+                    if new_state == '#pop':\n+                        stack.pop()\n+                    # resolve the new state by group checking\n+                    elif new_state == '#bygroup':\n+                        for key, value in iteritems(m.groupdict()):\n+                            if value is not None:\n+                                stack.append(key)\n+                                break\n+                        else:\n+                            raise RuntimeError('%r wanted to resolve the '\n+                                               'new state dynamically but'\n+                                               ' no group matched' %\n+                                               regex)\n+                    # direct state name given\n+                    else:\n+                        stack.append(new_state)\n+                    statetokens = self.rules[stack[-1]]\n+                # we are still at the same position and no stack change.\n+                # this means a loop without break condition, avoid that and\n+                # raise error\n+                elif pos2 == pos:\n+                    raise RuntimeError('%r yielded empty string without '\n+                                       'stack change' % regex)\n+                # publish new function and start again\n+                pos = pos2\n+                break\n+            # if loop terminated without break we haven't found a single match\n+            # either we are at the end of the file or we have a problem\n+            else:\n+                # end of text\n+                if pos >= source_length:\n+                    return\n+                # something went wrong\n+                raise TemplateSyntaxError('unexpected char %r at %d' %\n+                                          (source[pos], pos), lineno,\n+                                          name, filename)"
        },
        {
            "sha": "4c7979376065907d2adca51fbe76ff71079b8000",
            "filename": "tools/jinja2/loaders.py",
            "status": "added",
            "additions": 481,
            "deletions": 0,
            "changes": 481,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Floaders.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Floaders.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Floaders.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,481 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.loaders\n+    ~~~~~~~~~~~~~~\n+\n+    Jinja loader classes.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+import os\n+import sys\n+import weakref\n+from types import ModuleType\n+from os import path\n+from hashlib import sha1\n+from jinja2.exceptions import TemplateNotFound\n+from jinja2.utils import open_if_exists, internalcode\n+from jinja2._compat import string_types, iteritems\n+\n+\n+def split_template_path(template):\n+    \"\"\"Split a path into segments and perform a sanity check.  If it detects\n+    '..' in the path it will raise a `TemplateNotFound` error.\n+    \"\"\"\n+    pieces = []\n+    for piece in template.split('/'):\n+        if path.sep in piece \\\n+           or (path.altsep and path.altsep in piece) or \\\n+           piece == path.pardir:\n+            raise TemplateNotFound(template)\n+        elif piece and piece != '.':\n+            pieces.append(piece)\n+    return pieces\n+\n+\n+class BaseLoader(object):\n+    \"\"\"Baseclass for all loaders.  Subclass this and override `get_source` to\n+    implement a custom loading mechanism.  The environment provides a\n+    `get_template` method that calls the loader's `load` method to get the\n+    :class:`Template` object.\n+\n+    A very basic example for a loader that looks up templates on the file\n+    system could look like this::\n+\n+        from jinja2 import BaseLoader, TemplateNotFound\n+        from os.path import join, exists, getmtime\n+\n+        class MyLoader(BaseLoader):\n+\n+            def __init__(self, path):\n+                self.path = path\n+\n+            def get_source(self, environment, template):\n+                path = join(self.path, template)\n+                if not exists(path):\n+                    raise TemplateNotFound(template)\n+                mtime = getmtime(path)\n+                with file(path) as f:\n+                    source = f.read().decode('utf-8')\n+                return source, path, lambda: mtime == getmtime(path)\n+    \"\"\"\n+\n+    #: if set to `False` it indicates that the loader cannot provide access\n+    #: to the source of templates.\n+    #:\n+    #: .. versionadded:: 2.4\n+    has_source_access = True\n+\n+    def get_source(self, environment, template):\n+        \"\"\"Get the template source, filename and reload helper for a template.\n+        It's passed the environment and template name and has to return a\n+        tuple in the form ``(source, filename, uptodate)`` or raise a\n+        `TemplateNotFound` error if it can't locate the template.\n+\n+        The source part of the returned tuple must be the source of the\n+        template as unicode string or a ASCII bytestring.  The filename should\n+        be the name of the file on the filesystem if it was loaded from there,\n+        otherwise `None`.  The filename is used by python for the tracebacks\n+        if no loader extension is used.\n+\n+        The last item in the tuple is the `uptodate` function.  If auto\n+        reloading is enabled it's always called to check if the template\n+        changed.  No arguments are passed so the function must store the\n+        old state somewhere (for example in a closure).  If it returns `False`\n+        the template will be reloaded.\n+        \"\"\"\n+        if not self.has_source_access:\n+            raise RuntimeError('%s cannot provide access to the source' %\n+                               self.__class__.__name__)\n+        raise TemplateNotFound(template)\n+\n+    def list_templates(self):\n+        \"\"\"Iterates over all templates.  If the loader does not support that\n+        it should raise a :exc:`TypeError` which is the default behavior.\n+        \"\"\"\n+        raise TypeError('this loader cannot iterate over all templates')\n+\n+    @internalcode\n+    def load(self, environment, name, globals=None):\n+        \"\"\"Loads a template.  This method looks up the template in the cache\n+        or loads one by calling :meth:`get_source`.  Subclasses should not\n+        override this method as loaders working on collections of other\n+        loaders (such as :class:`PrefixLoader` or :class:`ChoiceLoader`)\n+        will not call this method but `get_source` directly.\n+        \"\"\"\n+        code = None\n+        if globals is None:\n+            globals = {}\n+\n+        # first we try to get the source for this template together\n+        # with the filename and the uptodate function.\n+        source, filename, uptodate = self.get_source(environment, name)\n+\n+        # try to load the code from the bytecode cache if there is a\n+        # bytecode cache configured.\n+        bcc = environment.bytecode_cache\n+        if bcc is not None:\n+            bucket = bcc.get_bucket(environment, name, filename, source)\n+            code = bucket.code\n+\n+        # if we don't have code so far (not cached, no longer up to\n+        # date) etc. we compile the template\n+        if code is None:\n+            code = environment.compile(source, name, filename)\n+\n+        # if the bytecode cache is available and the bucket doesn't\n+        # have a code so far, we give the bucket the new code and put\n+        # it back to the bytecode cache.\n+        if bcc is not None and bucket.code is None:\n+            bucket.code = code\n+            bcc.set_bucket(bucket)\n+\n+        return environment.template_class.from_code(environment, code,\n+                                                    globals, uptodate)\n+\n+\n+class FileSystemLoader(BaseLoader):\n+    \"\"\"Loads templates from the file system.  This loader can find templates\n+    in folders on the file system and is the preferred way to load them.\n+\n+    The loader takes the path to the templates as string, or if multiple\n+    locations are wanted a list of them which is then looked up in the\n+    given order::\n+\n+    >>> loader = FileSystemLoader('/path/to/templates')\n+    >>> loader = FileSystemLoader(['/path/to/templates', '/other/path'])\n+\n+    Per default the template encoding is ``'utf-8'`` which can be changed\n+    by setting the `encoding` parameter to something else.\n+\n+    To follow symbolic links, set the *followlinks* parameter to ``True``::\n+\n+    >>> loader = FileSystemLoader('/path/to/templates', followlinks=True)\n+\n+    .. versionchanged:: 2.8+\n+       The *followlinks* parameter was added.\n+    \"\"\"\n+\n+    def __init__(self, searchpath, encoding='utf-8', followlinks=False):\n+        if isinstance(searchpath, string_types):\n+            searchpath = [searchpath]\n+        self.searchpath = list(searchpath)\n+        self.encoding = encoding\n+        self.followlinks = followlinks\n+\n+    def get_source(self, environment, template):\n+        pieces = split_template_path(template)\n+        for searchpath in self.searchpath:\n+            filename = path.join(searchpath, *pieces)\n+            f = open_if_exists(filename)\n+            if f is None:\n+                continue\n+            try:\n+                contents = f.read().decode(self.encoding)\n+            finally:\n+                f.close()\n+\n+            mtime = path.getmtime(filename)\n+\n+            def uptodate():\n+                try:\n+                    return path.getmtime(filename) == mtime\n+                except OSError:\n+                    return False\n+            return contents, filename, uptodate\n+        raise TemplateNotFound(template)\n+\n+    def list_templates(self):\n+        found = set()\n+        for searchpath in self.searchpath:\n+            walk_dir = os.walk(searchpath, followlinks=self.followlinks)\n+            for dirpath, dirnames, filenames in walk_dir:\n+                for filename in filenames:\n+                    template = os.path.join(dirpath, filename) \\\n+                        [len(searchpath):].strip(os.path.sep) \\\n+                                          .replace(os.path.sep, '/')\n+                    if template[:2] == './':\n+                        template = template[2:]\n+                    if template not in found:\n+                        found.add(template)\n+        return sorted(found)\n+\n+\n+class PackageLoader(BaseLoader):\n+    \"\"\"Load templates from python eggs or packages.  It is constructed with\n+    the name of the python package and the path to the templates in that\n+    package::\n+\n+        loader = PackageLoader('mypackage', 'views')\n+\n+    If the package path is not given, ``'templates'`` is assumed.\n+\n+    Per default the template encoding is ``'utf-8'`` which can be changed\n+    by setting the `encoding` parameter to something else.  Due to the nature\n+    of eggs it's only possible to reload templates if the package was loaded\n+    from the file system and not a zip file.\n+    \"\"\"\n+\n+    def __init__(self, package_name, package_path='templates',\n+                 encoding='utf-8'):\n+        from pkg_resources import DefaultProvider, ResourceManager, \\\n+                                  get_provider\n+        provider = get_provider(package_name)\n+        self.encoding = encoding\n+        self.manager = ResourceManager()\n+        self.filesystem_bound = isinstance(provider, DefaultProvider)\n+        self.provider = provider\n+        self.package_path = package_path\n+\n+    def get_source(self, environment, template):\n+        pieces = split_template_path(template)\n+        p = '/'.join((self.package_path,) + tuple(pieces))\n+        if not self.provider.has_resource(p):\n+            raise TemplateNotFound(template)\n+\n+        filename = uptodate = None\n+        if self.filesystem_bound:\n+            filename = self.provider.get_resource_filename(self.manager, p)\n+            mtime = path.getmtime(filename)\n+            def uptodate():\n+                try:\n+                    return path.getmtime(filename) == mtime\n+                except OSError:\n+                    return False\n+\n+        source = self.provider.get_resource_string(self.manager, p)\n+        return source.decode(self.encoding), filename, uptodate\n+\n+    def list_templates(self):\n+        path = self.package_path\n+        if path[:2] == './':\n+            path = path[2:]\n+        elif path == '.':\n+            path = ''\n+        offset = len(path)\n+        results = []\n+        def _walk(path):\n+            for filename in self.provider.resource_listdir(path):\n+                fullname = path + '/' + filename\n+                if self.provider.resource_isdir(fullname):\n+                    _walk(fullname)\n+                else:\n+                    results.append(fullname[offset:].lstrip('/'))\n+        _walk(path)\n+        results.sort()\n+        return results\n+\n+\n+class DictLoader(BaseLoader):\n+    \"\"\"Loads a template from a python dict.  It's passed a dict of unicode\n+    strings bound to template names.  This loader is useful for unittesting:\n+\n+    >>> loader = DictLoader({'index.html': 'source here'})\n+\n+    Because auto reloading is rarely useful this is disabled per default.\n+    \"\"\"\n+\n+    def __init__(self, mapping):\n+        self.mapping = mapping\n+\n+    def get_source(self, environment, template):\n+        if template in self.mapping:\n+            source = self.mapping[template]\n+            return source, None, lambda: source == self.mapping.get(template)\n+        raise TemplateNotFound(template)\n+\n+    def list_templates(self):\n+        return sorted(self.mapping)\n+\n+\n+class FunctionLoader(BaseLoader):\n+    \"\"\"A loader that is passed a function which does the loading.  The\n+    function receives the name of the template and has to return either\n+    an unicode string with the template source, a tuple in the form ``(source,\n+    filename, uptodatefunc)`` or `None` if the template does not exist.\n+\n+    >>> def load_template(name):\n+    ...     if name == 'index.html':\n+    ...         return '...'\n+    ...\n+    >>> loader = FunctionLoader(load_template)\n+\n+    The `uptodatefunc` is a function that is called if autoreload is enabled\n+    and has to return `True` if the template is still up to date.  For more\n+    details have a look at :meth:`BaseLoader.get_source` which has the same\n+    return value.\n+    \"\"\"\n+\n+    def __init__(self, load_func):\n+        self.load_func = load_func\n+\n+    def get_source(self, environment, template):\n+        rv = self.load_func(template)\n+        if rv is None:\n+            raise TemplateNotFound(template)\n+        elif isinstance(rv, string_types):\n+            return rv, None, None\n+        return rv\n+\n+\n+class PrefixLoader(BaseLoader):\n+    \"\"\"A loader that is passed a dict of loaders where each loader is bound\n+    to a prefix.  The prefix is delimited from the template by a slash per\n+    default, which can be changed by setting the `delimiter` argument to\n+    something else::\n+\n+        loader = PrefixLoader({\n+            'app1':     PackageLoader('mypackage.app1'),\n+            'app2':     PackageLoader('mypackage.app2')\n+        })\n+\n+    By loading ``'app1/index.html'`` the file from the app1 package is loaded,\n+    by loading ``'app2/index.html'`` the file from the second.\n+    \"\"\"\n+\n+    def __init__(self, mapping, delimiter='/'):\n+        self.mapping = mapping\n+        self.delimiter = delimiter\n+\n+    def get_loader(self, template):\n+        try:\n+            prefix, name = template.split(self.delimiter, 1)\n+            loader = self.mapping[prefix]\n+        except (ValueError, KeyError):\n+            raise TemplateNotFound(template)\n+        return loader, name\n+\n+    def get_source(self, environment, template):\n+        loader, name = self.get_loader(template)\n+        try:\n+            return loader.get_source(environment, name)\n+        except TemplateNotFound:\n+            # re-raise the exception with the correct filename here.\n+            # (the one that includes the prefix)\n+            raise TemplateNotFound(template)\n+\n+    @internalcode\n+    def load(self, environment, name, globals=None):\n+        loader, local_name = self.get_loader(name)\n+        try:\n+            return loader.load(environment, local_name, globals)\n+        except TemplateNotFound:\n+            # re-raise the exception with the correct filename here.\n+            # (the one that includes the prefix)\n+            raise TemplateNotFound(name)\n+\n+    def list_templates(self):\n+        result = []\n+        for prefix, loader in iteritems(self.mapping):\n+            for template in loader.list_templates():\n+                result.append(prefix + self.delimiter + template)\n+        return result\n+\n+\n+class ChoiceLoader(BaseLoader):\n+    \"\"\"This loader works like the `PrefixLoader` just that no prefix is\n+    specified.  If a template could not be found by one loader the next one\n+    is tried.\n+\n+    >>> loader = ChoiceLoader([\n+    ...     FileSystemLoader('/path/to/user/templates'),\n+    ...     FileSystemLoader('/path/to/system/templates')\n+    ... ])\n+\n+    This is useful if you want to allow users to override builtin templates\n+    from a different location.\n+    \"\"\"\n+\n+    def __init__(self, loaders):\n+        self.loaders = loaders\n+\n+    def get_source(self, environment, template):\n+        for loader in self.loaders:\n+            try:\n+                return loader.get_source(environment, template)\n+            except TemplateNotFound:\n+                pass\n+        raise TemplateNotFound(template)\n+\n+    @internalcode\n+    def load(self, environment, name, globals=None):\n+        for loader in self.loaders:\n+            try:\n+                return loader.load(environment, name, globals)\n+            except TemplateNotFound:\n+                pass\n+        raise TemplateNotFound(name)\n+\n+    def list_templates(self):\n+        found = set()\n+        for loader in self.loaders:\n+            found.update(loader.list_templates())\n+        return sorted(found)\n+\n+\n+class _TemplateModule(ModuleType):\n+    \"\"\"Like a normal module but with support for weak references\"\"\"\n+\n+\n+class ModuleLoader(BaseLoader):\n+    \"\"\"This loader loads templates from precompiled templates.\n+\n+    Example usage:\n+\n+    >>> loader = ChoiceLoader([\n+    ...     ModuleLoader('/path/to/compiled/templates'),\n+    ...     FileSystemLoader('/path/to/templates')\n+    ... ])\n+\n+    Templates can be precompiled with :meth:`Environment.compile_templates`.\n+    \"\"\"\n+\n+    has_source_access = False\n+\n+    def __init__(self, path):\n+        package_name = '_jinja2_module_templates_%x' % id(self)\n+\n+        # create a fake module that looks for the templates in the\n+        # path given.\n+        mod = _TemplateModule(package_name)\n+        if isinstance(path, string_types):\n+            path = [path]\n+        else:\n+            path = list(path)\n+        mod.__path__ = path\n+\n+        sys.modules[package_name] = weakref.proxy(mod,\n+            lambda x: sys.modules.pop(package_name, None))\n+\n+        # the only strong reference, the sys.modules entry is weak\n+        # so that the garbage collector can remove it once the\n+        # loader that created it goes out of business.\n+        self.module = mod\n+        self.package_name = package_name\n+\n+    @staticmethod\n+    def get_template_key(name):\n+        return 'tmpl_' + sha1(name.encode('utf-8')).hexdigest()\n+\n+    @staticmethod\n+    def get_module_filename(name):\n+        return ModuleLoader.get_template_key(name) + '.py'\n+\n+    @internalcode\n+    def load(self, environment, name, globals=None):\n+        key = self.get_template_key(name)\n+        module = '%s.%s' % (self.package_name, key)\n+        mod = getattr(self.module, module, None)\n+        if mod is None:\n+            try:\n+                mod = __import__(module, None, None, ['root'])\n+            except ImportError:\n+                raise TemplateNotFound(name)\n+\n+            # remove the entry from sys.modules, we only want the attribute\n+            # on the module object we have stored on the loader.\n+            sys.modules.pop(module, None)\n+\n+        return environment.template_class.from_module_dict(\n+            environment, mod.__dict__, globals)"
        },
        {
            "sha": "7421914f77242d755ede1a43b9518e73b85e894e",
            "filename": "tools/jinja2/meta.py",
            "status": "added",
            "additions": 106,
            "deletions": 0,
            "changes": 106,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fmeta.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fmeta.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fmeta.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,106 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.meta\n+    ~~~~~~~~~~~\n+\n+    This module implements various functions that exposes information about\n+    templates that might be interesting for various kinds of applications.\n+\n+    :copyright: (c) 2017 by the Jinja Team, see AUTHORS for more details.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+from jinja2 import nodes\n+from jinja2.compiler import CodeGenerator\n+from jinja2._compat import string_types, iteritems\n+\n+\n+class TrackingCodeGenerator(CodeGenerator):\n+    \"\"\"We abuse the code generator for introspection.\"\"\"\n+\n+    def __init__(self, environment):\n+        CodeGenerator.__init__(self, environment, '<introspection>',\n+                               '<introspection>')\n+        self.undeclared_identifiers = set()\n+\n+    def write(self, x):\n+        \"\"\"Don't write.\"\"\"\n+\n+    def enter_frame(self, frame):\n+        \"\"\"Remember all undeclared identifiers.\"\"\"\n+        CodeGenerator.enter_frame(self, frame)\n+        for _, (action, param) in iteritems(frame.symbols.loads):\n+            if action == 'resolve':\n+                self.undeclared_identifiers.add(param)\n+\n+\n+def find_undeclared_variables(ast):\n+    \"\"\"Returns a set of all variables in the AST that will be looked up from\n+    the context at runtime.  Because at compile time it's not known which\n+    variables will be used depending on the path the execution takes at\n+    runtime, all variables are returned.\n+\n+    >>> from jinja2 import Environment, meta\n+    >>> env = Environment()\n+    >>> ast = env.parse('{% set foo = 42 %}{{ bar + foo }}')\n+    >>> meta.find_undeclared_variables(ast) == set(['bar'])\n+    True\n+\n+    .. admonition:: Implementation\n+\n+       Internally the code generator is used for finding undeclared variables.\n+       This is good to know because the code generator might raise a\n+       :exc:`TemplateAssertionError` during compilation and as a matter of\n+       fact this function can currently raise that exception as well.\n+    \"\"\"\n+    codegen = TrackingCodeGenerator(ast.environment)\n+    codegen.visit(ast)\n+    return codegen.undeclared_identifiers\n+\n+\n+def find_referenced_templates(ast):\n+    \"\"\"Finds all the referenced templates from the AST.  This will return an\n+    iterator over all the hardcoded template extensions, inclusions and\n+    imports.  If dynamic inheritance or inclusion is used, `None` will be\n+    yielded.\n+\n+    >>> from jinja2 import Environment, meta\n+    >>> env = Environment()\n+    >>> ast = env.parse('{% extends \"layout.html\" %}{% include helper %}')\n+    >>> list(meta.find_referenced_templates(ast))\n+    ['layout.html', None]\n+\n+    This function is useful for dependency tracking.  For example if you want\n+    to rebuild parts of the website after a layout template has changed.\n+    \"\"\"\n+    for node in ast.find_all((nodes.Extends, nodes.FromImport, nodes.Import,\n+                              nodes.Include)):\n+        if not isinstance(node.template, nodes.Const):\n+            # a tuple with some non consts in there\n+            if isinstance(node.template, (nodes.Tuple, nodes.List)):\n+                for template_name in node.template.items:\n+                    # something const, only yield the strings and ignore\n+                    # non-string consts that really just make no sense\n+                    if isinstance(template_name, nodes.Const):\n+                        if isinstance(template_name.value, string_types):\n+                            yield template_name.value\n+                    # something dynamic in there\n+                    else:\n+                        yield None\n+            # something dynamic we don't know about here\n+            else:\n+                yield None\n+            continue\n+        # constant is a basestring, direct template name\n+        if isinstance(node.template.value, string_types):\n+            yield node.template.value\n+        # a tuple or list (latter *should* not happen) made of consts,\n+        # yield the consts that are strings.  We could warn here for\n+        # non string values\n+        elif isinstance(node, nodes.Include) and \\\n+             isinstance(node.template.value, (tuple, list)):\n+            for template_name in node.template.value:\n+                if isinstance(template_name, string_types):\n+                    yield template_name\n+        # something else we don't care about, we could warn here\n+        else:\n+            yield None"
        },
        {
            "sha": "fe17e4138df3f1c1d3cf8d207135c847f5d66615",
            "filename": "tools/jinja2/nativetypes.py",
            "status": "added",
            "additions": 220,
            "deletions": 0,
            "changes": 220,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fnativetypes.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fnativetypes.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fnativetypes.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,220 @@\n+import sys\n+from ast import literal_eval\n+from itertools import islice, chain\n+from jinja2 import nodes\n+from jinja2._compat import text_type\n+from jinja2.compiler import CodeGenerator, has_safe_repr\n+from jinja2.environment import Environment, Template\n+from jinja2.utils import concat, escape\n+\n+\n+def native_concat(nodes):\n+    \"\"\"Return a native Python type from the list of compiled nodes. If the\n+    result is a single node, its value is returned. Otherwise, the nodes are\n+    concatenated as strings. If the result can be parsed with\n+    :func:`ast.literal_eval`, the parsed value is returned. Otherwise, the\n+    string is returned.\n+    \"\"\"\n+    head = list(islice(nodes, 2))\n+\n+    if not head:\n+        return None\n+\n+    if len(head) == 1:\n+        out = head[0]\n+    else:\n+        out = u''.join([text_type(v) for v in chain(head, nodes)])\n+\n+    try:\n+        return literal_eval(out)\n+    except (ValueError, SyntaxError, MemoryError):\n+        return out\n+\n+\n+class NativeCodeGenerator(CodeGenerator):\n+    \"\"\"A code generator which avoids injecting ``to_string()`` calls around the\n+    internal code Jinja uses to render templates.\n+    \"\"\"\n+\n+    def visit_Output(self, node, frame):\n+        \"\"\"Same as :meth:`CodeGenerator.visit_Output`, but do not call\n+        ``to_string`` on output nodes in generated code.\n+        \"\"\"\n+        if self.has_known_extends and frame.require_output_check:\n+            return\n+\n+        finalize = self.environment.finalize\n+        finalize_context = getattr(finalize, 'contextfunction', False)\n+        finalize_eval = getattr(finalize, 'evalcontextfunction', False)\n+        finalize_env = getattr(finalize, 'environmentfunction', False)\n+\n+        if finalize is not None:\n+            if finalize_context or finalize_eval:\n+                const_finalize = None\n+            elif finalize_env:\n+                def const_finalize(x):\n+                    return finalize(self.environment, x)\n+            else:\n+                const_finalize = finalize\n+        else:\n+            def const_finalize(x):\n+                return x\n+\n+        # If we are inside a frame that requires output checking, we do so.\n+        outdent_later = False\n+\n+        if frame.require_output_check:\n+            self.writeline('if parent_template is None:')\n+            self.indent()\n+            outdent_later = True\n+\n+        # Try to evaluate as many chunks as possible into a static string at\n+        # compile time.\n+        body = []\n+\n+        for child in node.nodes:\n+            try:\n+                if const_finalize is None:\n+                    raise nodes.Impossible()\n+\n+                const = child.as_const(frame.eval_ctx)\n+                if not has_safe_repr(const):\n+                    raise nodes.Impossible()\n+            except nodes.Impossible:\n+                body.append(child)\n+                continue\n+\n+            # the frame can't be volatile here, because otherwise the as_const\n+            # function would raise an Impossible exception at that point\n+            try:\n+                if frame.eval_ctx.autoescape:\n+                    if hasattr(const, '__html__'):\n+                        const = const.__html__()\n+                    else:\n+                        const = escape(const)\n+\n+                const = const_finalize(const)\n+            except Exception:\n+                # if something goes wrong here we evaluate the node at runtime\n+                # for easier debugging\n+                body.append(child)\n+                continue\n+\n+            if body and isinstance(body[-1], list):\n+                body[-1].append(const)\n+            else:\n+                body.append([const])\n+\n+        # if we have less than 3 nodes or a buffer we yield or extend/append\n+        if len(body) < 3 or frame.buffer is not None:\n+            if frame.buffer is not None:\n+                # for one item we append, for more we extend\n+                if len(body) == 1:\n+                    self.writeline('%s.append(' % frame.buffer)\n+                else:\n+                    self.writeline('%s.extend((' % frame.buffer)\n+\n+                self.indent()\n+\n+            for item in body:\n+                if isinstance(item, list):\n+                    val = repr(native_concat(item))\n+\n+                    if frame.buffer is None:\n+                        self.writeline('yield ' + val)\n+                    else:\n+                        self.writeline(val + ',')\n+                else:\n+                    if frame.buffer is None:\n+                        self.writeline('yield ', item)\n+                    else:\n+                        self.newline(item)\n+\n+                    close = 0\n+\n+                    if finalize is not None:\n+                        self.write('environment.finalize(')\n+\n+                        if finalize_context:\n+                            self.write('context, ')\n+\n+                        close += 1\n+\n+                    self.visit(item, frame)\n+\n+                    if close > 0:\n+                        self.write(')' * close)\n+\n+                    if frame.buffer is not None:\n+                        self.write(',')\n+\n+            if frame.buffer is not None:\n+                # close the open parentheses\n+                self.outdent()\n+                self.writeline(len(body) == 1 and ')' or '))')\n+\n+        # otherwise we create a format string as this is faster in that case\n+        else:\n+            format = []\n+            arguments = []\n+\n+            for item in body:\n+                if isinstance(item, list):\n+                    format.append(native_concat(item).replace('%', '%%'))\n+                else:\n+                    format.append('%s')\n+                    arguments.append(item)\n+\n+            self.writeline('yield ')\n+            self.write(repr(concat(format)) + ' % (')\n+            self.indent()\n+\n+            for argument in arguments:\n+                self.newline(argument)\n+                close = 0\n+\n+                if finalize is not None:\n+                    self.write('environment.finalize(')\n+\n+                    if finalize_context:\n+                        self.write('context, ')\n+                    elif finalize_eval:\n+                        self.write('context.eval_ctx, ')\n+                    elif finalize_env:\n+                        self.write('environment, ')\n+\n+                    close += 1\n+\n+                self.visit(argument, frame)\n+                self.write(')' * close + ', ')\n+\n+            self.outdent()\n+            self.writeline(')')\n+\n+        if outdent_later:\n+            self.outdent()\n+\n+\n+class NativeTemplate(Template):\n+    def render(self, *args, **kwargs):\n+        \"\"\"Render the template to produce a native Python type. If the result\n+        is a single node, its value is returned. Otherwise, the nodes are\n+        concatenated as strings. If the result can be parsed with\n+        :func:`ast.literal_eval`, the parsed value is returned. Otherwise, the\n+        string is returned.\n+        \"\"\"\n+        vars = dict(*args, **kwargs)\n+\n+        try:\n+            return native_concat(self.root_render_func(self.new_context(vars)))\n+        except Exception:\n+            exc_info = sys.exc_info()\n+\n+        return self.environment.handle_exception(exc_info, True)\n+\n+\n+class NativeEnvironment(Environment):\n+    \"\"\"An environment that renders templates to native Python types.\"\"\"\n+\n+    code_generator_class = NativeCodeGenerator\n+    template_class = NativeTemplate"
        },
        {
            "sha": "4d9a01ad8bb2e7b0b63ed483e7c4c34ed0a22033",
            "filename": "tools/jinja2/nodes.py",
            "status": "added",
            "additions": 999,
            "deletions": 0,
            "changes": 999,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fnodes.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fnodes.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fnodes.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,999 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.nodes\n+    ~~~~~~~~~~~~\n+\n+    This module implements additional nodes derived from the ast base node.\n+\n+    It also provides some node tree helper functions like `in_lineno` and\n+    `get_nodes` used by the parser and translator in order to normalize\n+    python and jinja nodes.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+import types\n+import operator\n+\n+from collections import deque\n+from jinja2.utils import Markup\n+from jinja2._compat import izip, with_metaclass, text_type, PY2\n+\n+\n+#: the types we support for context functions\n+_context_function_types = (types.FunctionType, types.MethodType)\n+\n+\n+_binop_to_func = {\n+    '*':        operator.mul,\n+    '/':        operator.truediv,\n+    '//':       operator.floordiv,\n+    '**':       operator.pow,\n+    '%':        operator.mod,\n+    '+':        operator.add,\n+    '-':        operator.sub\n+}\n+\n+_uaop_to_func = {\n+    'not':      operator.not_,\n+    '+':        operator.pos,\n+    '-':        operator.neg\n+}\n+\n+_cmpop_to_func = {\n+    'eq':       operator.eq,\n+    'ne':       operator.ne,\n+    'gt':       operator.gt,\n+    'gteq':     operator.ge,\n+    'lt':       operator.lt,\n+    'lteq':     operator.le,\n+    'in':       lambda a, b: a in b,\n+    'notin':    lambda a, b: a not in b\n+}\n+\n+\n+class Impossible(Exception):\n+    \"\"\"Raised if the node could not perform a requested action.\"\"\"\n+\n+\n+class NodeType(type):\n+    \"\"\"A metaclass for nodes that handles the field and attribute\n+    inheritance.  fields and attributes from the parent class are\n+    automatically forwarded to the child.\"\"\"\n+\n+    def __new__(cls, name, bases, d):\n+        for attr in 'fields', 'attributes':\n+            storage = []\n+            storage.extend(getattr(bases[0], attr, ()))\n+            storage.extend(d.get(attr, ()))\n+            assert len(bases) == 1, 'multiple inheritance not allowed'\n+            assert len(storage) == len(set(storage)), 'layout conflict'\n+            d[attr] = tuple(storage)\n+        d.setdefault('abstract', False)\n+        return type.__new__(cls, name, bases, d)\n+\n+\n+class EvalContext(object):\n+    \"\"\"Holds evaluation time information.  Custom attributes can be attached\n+    to it in extensions.\n+    \"\"\"\n+\n+    def __init__(self, environment, template_name=None):\n+        self.environment = environment\n+        if callable(environment.autoescape):\n+            self.autoescape = environment.autoescape(template_name)\n+        else:\n+            self.autoescape = environment.autoescape\n+        self.volatile = False\n+\n+    def save(self):\n+        return self.__dict__.copy()\n+\n+    def revert(self, old):\n+        self.__dict__.clear()\n+        self.__dict__.update(old)\n+\n+\n+def get_eval_context(node, ctx):\n+    if ctx is None:\n+        if node.environment is None:\n+            raise RuntimeError('if no eval context is passed, the '\n+                               'node must have an attached '\n+                               'environment.')\n+        return EvalContext(node.environment)\n+    return ctx\n+\n+\n+class Node(with_metaclass(NodeType, object)):\n+    \"\"\"Baseclass for all Jinja2 nodes.  There are a number of nodes available\n+    of different types.  There are four major types:\n+\n+    -   :class:`Stmt`: statements\n+    -   :class:`Expr`: expressions\n+    -   :class:`Helper`: helper nodes\n+    -   :class:`Template`: the outermost wrapper node\n+\n+    All nodes have fields and attributes.  Fields may be other nodes, lists,\n+    or arbitrary values.  Fields are passed to the constructor as regular\n+    positional arguments, attributes as keyword arguments.  Each node has\n+    two attributes: `lineno` (the line number of the node) and `environment`.\n+    The `environment` attribute is set at the end of the parsing process for\n+    all nodes automatically.\n+    \"\"\"\n+    fields = ()\n+    attributes = ('lineno', 'environment')\n+    abstract = True\n+\n+    def __init__(self, *fields, **attributes):\n+        if self.abstract:\n+            raise TypeError('abstract nodes are not instanciable')\n+        if fields:\n+            if len(fields) != len(self.fields):\n+                if not self.fields:\n+                    raise TypeError('%r takes 0 arguments' %\n+                                    self.__class__.__name__)\n+                raise TypeError('%r takes 0 or %d argument%s' % (\n+                    self.__class__.__name__,\n+                    len(self.fields),\n+                    len(self.fields) != 1 and 's' or ''\n+                ))\n+            for name, arg in izip(self.fields, fields):\n+                setattr(self, name, arg)\n+        for attr in self.attributes:\n+            setattr(self, attr, attributes.pop(attr, None))\n+        if attributes:\n+            raise TypeError('unknown attribute %r' %\n+                            next(iter(attributes)))\n+\n+    def iter_fields(self, exclude=None, only=None):\n+        \"\"\"This method iterates over all fields that are defined and yields\n+        ``(key, value)`` tuples.  Per default all fields are returned, but\n+        it's possible to limit that to some fields by providing the `only`\n+        parameter or to exclude some using the `exclude` parameter.  Both\n+        should be sets or tuples of field names.\n+        \"\"\"\n+        for name in self.fields:\n+            if (exclude is only is None) or \\\n+               (exclude is not None and name not in exclude) or \\\n+               (only is not None and name in only):\n+                try:\n+                    yield name, getattr(self, name)\n+                except AttributeError:\n+                    pass\n+\n+    def iter_child_nodes(self, exclude=None, only=None):\n+        \"\"\"Iterates over all direct child nodes of the node.  This iterates\n+        over all fields and yields the values of they are nodes.  If the value\n+        of a field is a list all the nodes in that list are returned.\n+        \"\"\"\n+        for field, item in self.iter_fields(exclude, only):\n+            if isinstance(item, list):\n+                for n in item:\n+                    if isinstance(n, Node):\n+                        yield n\n+            elif isinstance(item, Node):\n+                yield item\n+\n+    def find(self, node_type):\n+        \"\"\"Find the first node of a given type.  If no such node exists the\n+        return value is `None`.\n+        \"\"\"\n+        for result in self.find_all(node_type):\n+            return result\n+\n+    def find_all(self, node_type):\n+        \"\"\"Find all the nodes of a given type.  If the type is a tuple,\n+        the check is performed for any of the tuple items.\n+        \"\"\"\n+        for child in self.iter_child_nodes():\n+            if isinstance(child, node_type):\n+                yield child\n+            for result in child.find_all(node_type):\n+                yield result\n+\n+    def set_ctx(self, ctx):\n+        \"\"\"Reset the context of a node and all child nodes.  Per default the\n+        parser will all generate nodes that have a 'load' context as it's the\n+        most common one.  This method is used in the parser to set assignment\n+        targets and other nodes to a store context.\n+        \"\"\"\n+        todo = deque([self])\n+        while todo:\n+            node = todo.popleft()\n+            if 'ctx' in node.fields:\n+                node.ctx = ctx\n+            todo.extend(node.iter_child_nodes())\n+        return self\n+\n+    def set_lineno(self, lineno, override=False):\n+        \"\"\"Set the line numbers of the node and children.\"\"\"\n+        todo = deque([self])\n+        while todo:\n+            node = todo.popleft()\n+            if 'lineno' in node.attributes:\n+                if node.lineno is None or override:\n+                    node.lineno = lineno\n+            todo.extend(node.iter_child_nodes())\n+        return self\n+\n+    def set_environment(self, environment):\n+        \"\"\"Set the environment for all nodes.\"\"\"\n+        todo = deque([self])\n+        while todo:\n+            node = todo.popleft()\n+            node.environment = environment\n+            todo.extend(node.iter_child_nodes())\n+        return self\n+\n+    def __eq__(self, other):\n+        return type(self) is type(other) and \\\n+               tuple(self.iter_fields()) == tuple(other.iter_fields())\n+\n+    def __ne__(self, other):\n+        return not self.__eq__(other)\n+\n+    # Restore Python 2 hashing behavior on Python 3\n+    __hash__ = object.__hash__\n+\n+    def __repr__(self):\n+        return '%s(%s)' % (\n+            self.__class__.__name__,\n+            ', '.join('%s=%r' % (arg, getattr(self, arg, None)) for\n+                      arg in self.fields)\n+        )\n+\n+    def dump(self):\n+        def _dump(node):\n+            if not isinstance(node, Node):\n+                buf.append(repr(node))\n+                return\n+\n+            buf.append('nodes.%s(' % node.__class__.__name__)\n+            if not node.fields:\n+                buf.append(')')\n+                return\n+            for idx, field in enumerate(node.fields):\n+                if idx:\n+                    buf.append(', ')\n+                value = getattr(node, field)\n+                if isinstance(value, list):\n+                    buf.append('[')\n+                    for idx, item in enumerate(value):\n+                        if idx:\n+                            buf.append(', ')\n+                        _dump(item)\n+                    buf.append(']')\n+                else:\n+                    _dump(value)\n+            buf.append(')')\n+        buf = []\n+        _dump(self)\n+        return ''.join(buf)\n+\n+\n+\n+class Stmt(Node):\n+    \"\"\"Base node for all statements.\"\"\"\n+    abstract = True\n+\n+\n+class Helper(Node):\n+    \"\"\"Nodes that exist in a specific context only.\"\"\"\n+    abstract = True\n+\n+\n+class Template(Node):\n+    \"\"\"Node that represents a template.  This must be the outermost node that\n+    is passed to the compiler.\n+    \"\"\"\n+    fields = ('body',)\n+\n+\n+class Output(Stmt):\n+    \"\"\"A node that holds multiple expressions which are then printed out.\n+    This is used both for the `print` statement and the regular template data.\n+    \"\"\"\n+    fields = ('nodes',)\n+\n+\n+class Extends(Stmt):\n+    \"\"\"Represents an extends statement.\"\"\"\n+    fields = ('template',)\n+\n+\n+class For(Stmt):\n+    \"\"\"The for loop.  `target` is the target for the iteration (usually a\n+    :class:`Name` or :class:`Tuple`), `iter` the iterable.  `body` is a list\n+    of nodes that are used as loop-body, and `else_` a list of nodes for the\n+    `else` block.  If no else node exists it has to be an empty list.\n+\n+    For filtered nodes an expression can be stored as `test`, otherwise `None`.\n+    \"\"\"\n+    fields = ('target', 'iter', 'body', 'else_', 'test', 'recursive')\n+\n+\n+class If(Stmt):\n+    \"\"\"If `test` is true, `body` is rendered, else `else_`.\"\"\"\n+    fields = ('test', 'body', 'elif_', 'else_')\n+\n+\n+class Macro(Stmt):\n+    \"\"\"A macro definition.  `name` is the name of the macro, `args` a list of\n+    arguments and `defaults` a list of defaults if there are any.  `body` is\n+    a list of nodes for the macro body.\n+    \"\"\"\n+    fields = ('name', 'args', 'defaults', 'body')\n+\n+\n+class CallBlock(Stmt):\n+    \"\"\"Like a macro without a name but a call instead.  `call` is called with\n+    the unnamed macro as `caller` argument this node holds.\n+    \"\"\"\n+    fields = ('call', 'args', 'defaults', 'body')\n+\n+\n+class FilterBlock(Stmt):\n+    \"\"\"Node for filter sections.\"\"\"\n+    fields = ('body', 'filter')\n+\n+\n+class With(Stmt):\n+    \"\"\"Specific node for with statements.  In older versions of Jinja the\n+    with statement was implemented on the base of the `Scope` node instead.\n+\n+    .. versionadded:: 2.9.3\n+    \"\"\"\n+    fields = ('targets', 'values', 'body')\n+\n+\n+class Block(Stmt):\n+    \"\"\"A node that represents a block.\"\"\"\n+    fields = ('name', 'body', 'scoped')\n+\n+\n+class Include(Stmt):\n+    \"\"\"A node that represents the include tag.\"\"\"\n+    fields = ('template', 'with_context', 'ignore_missing')\n+\n+\n+class Import(Stmt):\n+    \"\"\"A node that represents the import tag.\"\"\"\n+    fields = ('template', 'target', 'with_context')\n+\n+\n+class FromImport(Stmt):\n+    \"\"\"A node that represents the from import tag.  It's important to not\n+    pass unsafe names to the name attribute.  The compiler translates the\n+    attribute lookups directly into getattr calls and does *not* use the\n+    subscript callback of the interface.  As exported variables may not\n+    start with double underscores (which the parser asserts) this is not a\n+    problem for regular Jinja code, but if this node is used in an extension\n+    extra care must be taken.\n+\n+    The list of names may contain tuples if aliases are wanted.\n+    \"\"\"\n+    fields = ('template', 'names', 'with_context')\n+\n+\n+class ExprStmt(Stmt):\n+    \"\"\"A statement that evaluates an expression and discards the result.\"\"\"\n+    fields = ('node',)\n+\n+\n+class Assign(Stmt):\n+    \"\"\"Assigns an expression to a target.\"\"\"\n+    fields = ('target', 'node')\n+\n+\n+class AssignBlock(Stmt):\n+    \"\"\"Assigns a block to a target.\"\"\"\n+    fields = ('target', 'filter', 'body')\n+\n+\n+class Expr(Node):\n+    \"\"\"Baseclass for all expressions.\"\"\"\n+    abstract = True\n+\n+    def as_const(self, eval_ctx=None):\n+        \"\"\"Return the value of the expression as constant or raise\n+        :exc:`Impossible` if this was not possible.\n+\n+        An :class:`EvalContext` can be provided, if none is given\n+        a default context is created which requires the nodes to have\n+        an attached environment.\n+\n+        .. versionchanged:: 2.4\n+           the `eval_ctx` parameter was added.\n+        \"\"\"\n+        raise Impossible()\n+\n+    def can_assign(self):\n+        \"\"\"Check if it's possible to assign something to this node.\"\"\"\n+        return False\n+\n+\n+class BinExpr(Expr):\n+    \"\"\"Baseclass for all binary expressions.\"\"\"\n+    fields = ('left', 'right')\n+    operator = None\n+    abstract = True\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        # intercepted operators cannot be folded at compile time\n+        if self.environment.sandboxed and \\\n+           self.operator in self.environment.intercepted_binops:\n+            raise Impossible()\n+        f = _binop_to_func[self.operator]\n+        try:\n+            return f(self.left.as_const(eval_ctx), self.right.as_const(eval_ctx))\n+        except Exception:\n+            raise Impossible()\n+\n+\n+class UnaryExpr(Expr):\n+    \"\"\"Baseclass for all unary expressions.\"\"\"\n+    fields = ('node',)\n+    operator = None\n+    abstract = True\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        # intercepted operators cannot be folded at compile time\n+        if self.environment.sandboxed and \\\n+           self.operator in self.environment.intercepted_unops:\n+            raise Impossible()\n+        f = _uaop_to_func[self.operator]\n+        try:\n+            return f(self.node.as_const(eval_ctx))\n+        except Exception:\n+            raise Impossible()\n+\n+\n+class Name(Expr):\n+    \"\"\"Looks up a name or stores a value in a name.\n+    The `ctx` of the node can be one of the following values:\n+\n+    -   `store`: store a value in the name\n+    -   `load`: load that name\n+    -   `param`: like `store` but if the name was defined as function parameter.\n+    \"\"\"\n+    fields = ('name', 'ctx')\n+\n+    def can_assign(self):\n+        return self.name not in ('true', 'false', 'none',\n+                                 'True', 'False', 'None')\n+\n+\n+class NSRef(Expr):\n+    \"\"\"Reference to a namespace value assignment\"\"\"\n+    fields = ('name', 'attr')\n+\n+    def can_assign(self):\n+        # We don't need any special checks here; NSRef assignments have a\n+        # runtime check to ensure the target is a namespace object which will\n+        # have been checked already as it is created using a normal assignment\n+        # which goes through a `Name` node.\n+        return True\n+\n+\n+class Literal(Expr):\n+    \"\"\"Baseclass for literals.\"\"\"\n+    abstract = True\n+\n+\n+class Const(Literal):\n+    \"\"\"All constant values.  The parser will return this node for simple\n+    constants such as ``42`` or ``\"foo\"`` but it can be used to store more\n+    complex values such as lists too.  Only constants with a safe\n+    representation (objects where ``eval(repr(x)) == x`` is true).\n+    \"\"\"\n+    fields = ('value',)\n+\n+    def as_const(self, eval_ctx=None):\n+        rv = self.value\n+        if PY2 and type(rv) is text_type and \\\n+           self.environment.policies['compiler.ascii_str']:\n+            try:\n+                rv = rv.encode('ascii')\n+            except UnicodeError:\n+                pass\n+        return rv\n+\n+    @classmethod\n+    def from_untrusted(cls, value, lineno=None, environment=None):\n+        \"\"\"Return a const object if the value is representable as\n+        constant value in the generated code, otherwise it will raise\n+        an `Impossible` exception.\n+        \"\"\"\n+        from .compiler import has_safe_repr\n+        if not has_safe_repr(value):\n+            raise Impossible()\n+        return cls(value, lineno=lineno, environment=environment)\n+\n+\n+class TemplateData(Literal):\n+    \"\"\"A constant template string.\"\"\"\n+    fields = ('data',)\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        if eval_ctx.volatile:\n+            raise Impossible()\n+        if eval_ctx.autoescape:\n+            return Markup(self.data)\n+        return self.data\n+\n+\n+class Tuple(Literal):\n+    \"\"\"For loop unpacking and some other things like multiple arguments\n+    for subscripts.  Like for :class:`Name` `ctx` specifies if the tuple\n+    is used for loading the names or storing.\n+    \"\"\"\n+    fields = ('items', 'ctx')\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return tuple(x.as_const(eval_ctx) for x in self.items)\n+\n+    def can_assign(self):\n+        for item in self.items:\n+            if not item.can_assign():\n+                return False\n+        return True\n+\n+\n+class List(Literal):\n+    \"\"\"Any list literal such as ``[1, 2, 3]``\"\"\"\n+    fields = ('items',)\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return [x.as_const(eval_ctx) for x in self.items]\n+\n+\n+class Dict(Literal):\n+    \"\"\"Any dict literal such as ``{1: 2, 3: 4}``.  The items must be a list of\n+    :class:`Pair` nodes.\n+    \"\"\"\n+    fields = ('items',)\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return dict(x.as_const(eval_ctx) for x in self.items)\n+\n+\n+class Pair(Helper):\n+    \"\"\"A key, value pair for dicts.\"\"\"\n+    fields = ('key', 'value')\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return self.key.as_const(eval_ctx), self.value.as_const(eval_ctx)\n+\n+\n+class Keyword(Helper):\n+    \"\"\"A key, value pair for keyword arguments where key is a string.\"\"\"\n+    fields = ('key', 'value')\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return self.key, self.value.as_const(eval_ctx)\n+\n+\n+class CondExpr(Expr):\n+    \"\"\"A conditional expression (inline if expression).  (``{{\n+    foo if bar else baz }}``)\n+    \"\"\"\n+    fields = ('test', 'expr1', 'expr2')\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        if self.test.as_const(eval_ctx):\n+            return self.expr1.as_const(eval_ctx)\n+\n+        # if we evaluate to an undefined object, we better do that at runtime\n+        if self.expr2 is None:\n+            raise Impossible()\n+\n+        return self.expr2.as_const(eval_ctx)\n+\n+\n+def args_as_const(node, eval_ctx):\n+    args = [x.as_const(eval_ctx) for x in node.args]\n+    kwargs = dict(x.as_const(eval_ctx) for x in node.kwargs)\n+\n+    if node.dyn_args is not None:\n+        try:\n+            args.extend(node.dyn_args.as_const(eval_ctx))\n+        except Exception:\n+            raise Impossible()\n+\n+    if node.dyn_kwargs is not None:\n+        try:\n+            kwargs.update(node.dyn_kwargs.as_const(eval_ctx))\n+        except Exception:\n+            raise Impossible()\n+\n+    return args, kwargs\n+\n+\n+class Filter(Expr):\n+    \"\"\"This node applies a filter on an expression.  `name` is the name of\n+    the filter, the rest of the fields are the same as for :class:`Call`.\n+\n+    If the `node` of a filter is `None` the contents of the last buffer are\n+    filtered.  Buffers are created by macros and filter blocks.\n+    \"\"\"\n+\n+    fields = ('node', 'name', 'args', 'kwargs', 'dyn_args', 'dyn_kwargs')\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+\n+        if eval_ctx.volatile or self.node is None:\n+            raise Impossible()\n+\n+        # we have to be careful here because we call filter_ below.\n+        # if this variable would be called filter, 2to3 would wrap the\n+        # call in a list beause it is assuming we are talking about the\n+        # builtin filter function here which no longer returns a list in\n+        # python 3.  because of that, do not rename filter_ to filter!\n+        filter_ = self.environment.filters.get(self.name)\n+\n+        if filter_ is None or getattr(filter_, 'contextfilter', False):\n+            raise Impossible()\n+\n+        # We cannot constant handle async filters, so we need to make sure\n+        # to not go down this path.\n+        if (\n+            eval_ctx.environment.is_async\n+            and getattr(filter_, 'asyncfiltervariant', False)\n+        ):\n+            raise Impossible()\n+\n+        args, kwargs = args_as_const(self, eval_ctx)\n+        args.insert(0, self.node.as_const(eval_ctx))\n+\n+        if getattr(filter_, 'evalcontextfilter', False):\n+            args.insert(0, eval_ctx)\n+        elif getattr(filter_, 'environmentfilter', False):\n+            args.insert(0, self.environment)\n+\n+        try:\n+            return filter_(*args, **kwargs)\n+        except Exception:\n+            raise Impossible()\n+\n+\n+class Test(Expr):\n+    \"\"\"Applies a test on an expression.  `name` is the name of the test, the\n+    rest of the fields are the same as for :class:`Call`.\n+    \"\"\"\n+\n+    fields = ('node', 'name', 'args', 'kwargs', 'dyn_args', 'dyn_kwargs')\n+\n+    def as_const(self, eval_ctx=None):\n+        test = self.environment.tests.get(self.name)\n+\n+        if test is None:\n+            raise Impossible()\n+\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        args, kwargs = args_as_const(self, eval_ctx)\n+        args.insert(0, self.node.as_const(eval_ctx))\n+\n+        try:\n+            return test(*args, **kwargs)\n+        except Exception:\n+            raise Impossible()\n+\n+\n+class Call(Expr):\n+    \"\"\"Calls an expression.  `args` is a list of arguments, `kwargs` a list\n+    of keyword arguments (list of :class:`Keyword` nodes), and `dyn_args`\n+    and `dyn_kwargs` has to be either `None` or a node that is used as\n+    node for dynamic positional (``*args``) or keyword (``**kwargs``)\n+    arguments.\n+    \"\"\"\n+    fields = ('node', 'args', 'kwargs', 'dyn_args', 'dyn_kwargs')\n+\n+\n+class Getitem(Expr):\n+    \"\"\"Get an attribute or item from an expression and prefer the item.\"\"\"\n+    fields = ('node', 'arg', 'ctx')\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        if self.ctx != 'load':\n+            raise Impossible()\n+        try:\n+            return self.environment.getitem(self.node.as_const(eval_ctx),\n+                                            self.arg.as_const(eval_ctx))\n+        except Exception:\n+            raise Impossible()\n+\n+    def can_assign(self):\n+        return False\n+\n+\n+class Getattr(Expr):\n+    \"\"\"Get an attribute or item from an expression that is a ascii-only\n+    bytestring and prefer the attribute.\n+    \"\"\"\n+    fields = ('node', 'attr', 'ctx')\n+\n+    def as_const(self, eval_ctx=None):\n+        if self.ctx != 'load':\n+            raise Impossible()\n+        try:\n+            eval_ctx = get_eval_context(self, eval_ctx)\n+            return self.environment.getattr(self.node.as_const(eval_ctx),\n+                                            self.attr)\n+        except Exception:\n+            raise Impossible()\n+\n+    def can_assign(self):\n+        return False\n+\n+\n+class Slice(Expr):\n+    \"\"\"Represents a slice object.  This must only be used as argument for\n+    :class:`Subscript`.\n+    \"\"\"\n+    fields = ('start', 'stop', 'step')\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        def const(obj):\n+            if obj is None:\n+                return None\n+            return obj.as_const(eval_ctx)\n+        return slice(const(self.start), const(self.stop), const(self.step))\n+\n+\n+class Concat(Expr):\n+    \"\"\"Concatenates the list of expressions provided after converting them to\n+    unicode.\n+    \"\"\"\n+    fields = ('nodes',)\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return ''.join(text_type(x.as_const(eval_ctx)) for x in self.nodes)\n+\n+\n+class Compare(Expr):\n+    \"\"\"Compares an expression with some other expressions.  `ops` must be a\n+    list of :class:`Operand`\\\\s.\n+    \"\"\"\n+    fields = ('expr', 'ops')\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        result = value = self.expr.as_const(eval_ctx)\n+        try:\n+            for op in self.ops:\n+                new_value = op.expr.as_const(eval_ctx)\n+                result = _cmpop_to_func[op.op](value, new_value)\n+                value = new_value\n+        except Exception:\n+            raise Impossible()\n+        return result\n+\n+\n+class Operand(Helper):\n+    \"\"\"Holds an operator and an expression.\"\"\"\n+    fields = ('op', 'expr')\n+\n+if __debug__:\n+    Operand.__doc__ += '\\nThe following operators are available: ' + \\\n+        ', '.join(sorted('``%s``' % x for x in set(_binop_to_func) |\n+                  set(_uaop_to_func) | set(_cmpop_to_func)))\n+\n+\n+class Mul(BinExpr):\n+    \"\"\"Multiplies the left with the right node.\"\"\"\n+    operator = '*'\n+\n+\n+class Div(BinExpr):\n+    \"\"\"Divides the left by the right node.\"\"\"\n+    operator = '/'\n+\n+\n+class FloorDiv(BinExpr):\n+    \"\"\"Divides the left by the right node and truncates conver the\n+    result into an integer by truncating.\n+    \"\"\"\n+    operator = '//'\n+\n+\n+class Add(BinExpr):\n+    \"\"\"Add the left to the right node.\"\"\"\n+    operator = '+'\n+\n+\n+class Sub(BinExpr):\n+    \"\"\"Subtract the right from the left node.\"\"\"\n+    operator = '-'\n+\n+\n+class Mod(BinExpr):\n+    \"\"\"Left modulo right.\"\"\"\n+    operator = '%'\n+\n+\n+class Pow(BinExpr):\n+    \"\"\"Left to the power of right.\"\"\"\n+    operator = '**'\n+\n+\n+class And(BinExpr):\n+    \"\"\"Short circuited AND.\"\"\"\n+    operator = 'and'\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return self.left.as_const(eval_ctx) and self.right.as_const(eval_ctx)\n+\n+\n+class Or(BinExpr):\n+    \"\"\"Short circuited OR.\"\"\"\n+    operator = 'or'\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return self.left.as_const(eval_ctx) or self.right.as_const(eval_ctx)\n+\n+\n+class Not(UnaryExpr):\n+    \"\"\"Negate the expression.\"\"\"\n+    operator = 'not'\n+\n+\n+class Neg(UnaryExpr):\n+    \"\"\"Make the expression negative.\"\"\"\n+    operator = '-'\n+\n+\n+class Pos(UnaryExpr):\n+    \"\"\"Make the expression positive (noop for most expressions)\"\"\"\n+    operator = '+'\n+\n+\n+# Helpers for extensions\n+\n+\n+class EnvironmentAttribute(Expr):\n+    \"\"\"Loads an attribute from the environment object.  This is useful for\n+    extensions that want to call a callback stored on the environment.\n+    \"\"\"\n+    fields = ('name',)\n+\n+\n+class ExtensionAttribute(Expr):\n+    \"\"\"Returns the attribute of an extension bound to the environment.\n+    The identifier is the identifier of the :class:`Extension`.\n+\n+    This node is usually constructed by calling the\n+    :meth:`~jinja2.ext.Extension.attr` method on an extension.\n+    \"\"\"\n+    fields = ('identifier', 'name')\n+\n+\n+class ImportedName(Expr):\n+    \"\"\"If created with an import name the import name is returned on node\n+    access.  For example ``ImportedName('cgi.escape')`` returns the `escape`\n+    function from the cgi module on evaluation.  Imports are optimized by the\n+    compiler so there is no need to assign them to local variables.\n+    \"\"\"\n+    fields = ('importname',)\n+\n+\n+class InternalName(Expr):\n+    \"\"\"An internal name in the compiler.  You cannot create these nodes\n+    yourself but the parser provides a\n+    :meth:`~jinja2.parser.Parser.free_identifier` method that creates\n+    a new identifier for you.  This identifier is not available from the\n+    template and is not threated specially by the compiler.\n+    \"\"\"\n+    fields = ('name',)\n+\n+    def __init__(self):\n+        raise TypeError('Can\\'t create internal names.  Use the '\n+                        '`free_identifier` method on a parser.')\n+\n+\n+class MarkSafe(Expr):\n+    \"\"\"Mark the wrapped expression as safe (wrap it as `Markup`).\"\"\"\n+    fields = ('expr',)\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return Markup(self.expr.as_const(eval_ctx))\n+\n+\n+class MarkSafeIfAutoescape(Expr):\n+    \"\"\"Mark the wrapped expression as safe (wrap it as `Markup`) but\n+    only if autoescaping is active.\n+\n+    .. versionadded:: 2.5\n+    \"\"\"\n+    fields = ('expr',)\n+\n+    def as_const(self, eval_ctx=None):\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        if eval_ctx.volatile:\n+            raise Impossible()\n+        expr = self.expr.as_const(eval_ctx)\n+        if eval_ctx.autoescape:\n+            return Markup(expr)\n+        return expr\n+\n+\n+class ContextReference(Expr):\n+    \"\"\"Returns the current template context.  It can be used like a\n+    :class:`Name` node, with a ``'load'`` ctx and will return the\n+    current :class:`~jinja2.runtime.Context` object.\n+\n+    Here an example that assigns the current template name to a\n+    variable named `foo`::\n+\n+        Assign(Name('foo', ctx='store'),\n+               Getattr(ContextReference(), 'name'))\n+    \"\"\"\n+\n+\n+class Continue(Stmt):\n+    \"\"\"Continue a loop.\"\"\"\n+\n+\n+class Break(Stmt):\n+    \"\"\"Break a loop.\"\"\"\n+\n+\n+class Scope(Stmt):\n+    \"\"\"An artificial scope.\"\"\"\n+    fields = ('body',)\n+\n+\n+class OverlayScope(Stmt):\n+    \"\"\"An overlay scope for extensions.  This is a largely unoptimized scope\n+    that however can be used to introduce completely arbitrary variables into\n+    a sub scope from a dictionary or dictionary like object.  The `context`\n+    field has to evaluate to a dictionary object.\n+\n+    Example usage::\n+\n+        OverlayScope(context=self.call_method('get_context'),\n+                     body=[...])\n+\n+    .. versionadded:: 2.10\n+    \"\"\"\n+    fields = ('context', 'body')\n+\n+\n+class EvalContextModifier(Stmt):\n+    \"\"\"Modifies the eval context.  For each option that should be modified,\n+    a :class:`Keyword` has to be added to the :attr:`options` list.\n+\n+    Example to change the `autoescape` setting::\n+\n+        EvalContextModifier(options=[Keyword('autoescape', Const(True))])\n+    \"\"\"\n+    fields = ('options',)\n+\n+\n+class ScopedEvalContextModifier(EvalContextModifier):\n+    \"\"\"Modifies the eval context and reverts it later.  Works exactly like\n+    :class:`EvalContextModifier` but will only modify the\n+    :class:`~jinja2.nodes.EvalContext` for nodes in the :attr:`body`.\n+    \"\"\"\n+    fields = ('body',)\n+\n+\n+# make sure nobody creates custom nodes\n+def _failing_new(*args, **kwargs):\n+    raise TypeError('can\\'t create custom node types')\n+NodeType.__new__ = staticmethod(_failing_new); del _failing_new"
        },
        {
            "sha": "65ab3ceb71f6130e4229a8272c495a91cdea352c",
            "filename": "tools/jinja2/optimizer.py",
            "status": "added",
            "additions": 49,
            "deletions": 0,
            "changes": 49,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Foptimizer.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Foptimizer.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Foptimizer.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,49 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.optimizer\n+    ~~~~~~~~~~~~~~~~\n+\n+    The jinja optimizer is currently trying to constant fold a few expressions\n+    and modify the AST in place so that it should be easier to evaluate it.\n+\n+    Because the AST does not contain all the scoping information and the\n+    compiler has to find that out, we cannot do all the optimizations we\n+    want.  For example loop unrolling doesn't work because unrolled loops would\n+    have a different scoping.\n+\n+    The solution would be a second syntax tree that has the scoping rules stored.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD.\n+\"\"\"\n+from jinja2 import nodes\n+from jinja2.visitor import NodeTransformer\n+\n+\n+def optimize(node, environment):\n+    \"\"\"The context hint can be used to perform an static optimization\n+    based on the context given.\"\"\"\n+    optimizer = Optimizer(environment)\n+    return optimizer.visit(node)\n+\n+\n+class Optimizer(NodeTransformer):\n+\n+    def __init__(self, environment):\n+        self.environment = environment\n+\n+    def fold(self, node, eval_ctx=None):\n+        \"\"\"Do constant folding.\"\"\"\n+        node = self.generic_visit(node)\n+        try:\n+            return nodes.Const.from_untrusted(node.as_const(eval_ctx),\n+                                              lineno=node.lineno,\n+                                              environment=self.environment)\n+        except nodes.Impossible:\n+            return node\n+\n+    visit_Add = visit_Sub = visit_Mul = visit_Div = visit_FloorDiv = \\\n+    visit_Pow = visit_Mod = visit_And = visit_Or = visit_Pos = visit_Neg = \\\n+    visit_Not = visit_Compare = visit_Getitem = visit_Getattr = visit_Call = \\\n+    visit_Filter = visit_Test = visit_CondExpr = fold\n+    del fold"
        },
        {
            "sha": "ed00d9708e962f16c6b9ce061be47068d9b9b1ad",
            "filename": "tools/jinja2/parser.py",
            "status": "added",
            "additions": 903,
            "deletions": 0,
            "changes": 903,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fparser.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fparser.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fparser.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,903 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.parser\n+    ~~~~~~~~~~~~~\n+\n+    Implements the template parser.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+from jinja2 import nodes\n+from jinja2.exceptions import TemplateSyntaxError, TemplateAssertionError\n+from jinja2.lexer import describe_token, describe_token_expr\n+from jinja2._compat import imap\n+\n+\n+_statement_keywords = frozenset(['for', 'if', 'block', 'extends', 'print',\n+                                 'macro', 'include', 'from', 'import',\n+                                 'set', 'with', 'autoescape'])\n+_compare_operators = frozenset(['eq', 'ne', 'lt', 'lteq', 'gt', 'gteq'])\n+\n+_math_nodes = {\n+    'add': nodes.Add,\n+    'sub': nodes.Sub,\n+    'mul': nodes.Mul,\n+    'div': nodes.Div,\n+    'floordiv': nodes.FloorDiv,\n+    'mod': nodes.Mod,\n+}\n+\n+\n+class Parser(object):\n+    \"\"\"This is the central parsing class Jinja2 uses.  It's passed to\n+    extensions and can be used to parse expressions or statements.\n+    \"\"\"\n+\n+    def __init__(self, environment, source, name=None, filename=None,\n+                 state=None):\n+        self.environment = environment\n+        self.stream = environment._tokenize(source, name, filename, state)\n+        self.name = name\n+        self.filename = filename\n+        self.closed = False\n+        self.extensions = {}\n+        for extension in environment.iter_extensions():\n+            for tag in extension.tags:\n+                self.extensions[tag] = extension.parse\n+        self._last_identifier = 0\n+        self._tag_stack = []\n+        self._end_token_stack = []\n+\n+    def fail(self, msg, lineno=None, exc=TemplateSyntaxError):\n+        \"\"\"Convenience method that raises `exc` with the message, passed\n+        line number or last line number as well as the current name and\n+        filename.\n+        \"\"\"\n+        if lineno is None:\n+            lineno = self.stream.current.lineno\n+        raise exc(msg, lineno, self.name, self.filename)\n+\n+    def _fail_ut_eof(self, name, end_token_stack, lineno):\n+        expected = []\n+        for exprs in end_token_stack:\n+            expected.extend(imap(describe_token_expr, exprs))\n+        if end_token_stack:\n+            currently_looking = ' or '.join(\n+                \"'%s'\" % describe_token_expr(expr)\n+                for expr in end_token_stack[-1])\n+        else:\n+            currently_looking = None\n+\n+        if name is None:\n+            message = ['Unexpected end of template.']\n+        else:\n+            message = ['Encountered unknown tag \\'%s\\'.' % name]\n+\n+        if currently_looking:\n+            if name is not None and name in expected:\n+                message.append('You probably made a nesting mistake. Jinja '\n+                               'is expecting this tag, but currently looking '\n+                               'for %s.' % currently_looking)\n+            else:\n+                message.append('Jinja was looking for the following tags: '\n+                               '%s.' % currently_looking)\n+\n+        if self._tag_stack:\n+            message.append('The innermost block that needs to be '\n+                           'closed is \\'%s\\'.' % self._tag_stack[-1])\n+\n+        self.fail(' '.join(message), lineno)\n+\n+    def fail_unknown_tag(self, name, lineno=None):\n+        \"\"\"Called if the parser encounters an unknown tag.  Tries to fail\n+        with a human readable error message that could help to identify\n+        the problem.\n+        \"\"\"\n+        return self._fail_ut_eof(name, self._end_token_stack, lineno)\n+\n+    def fail_eof(self, end_tokens=None, lineno=None):\n+        \"\"\"Like fail_unknown_tag but for end of template situations.\"\"\"\n+        stack = list(self._end_token_stack)\n+        if end_tokens is not None:\n+            stack.append(end_tokens)\n+        return self._fail_ut_eof(None, stack, lineno)\n+\n+    def is_tuple_end(self, extra_end_rules=None):\n+        \"\"\"Are we at the end of a tuple?\"\"\"\n+        if self.stream.current.type in ('variable_end', 'block_end', 'rparen'):\n+            return True\n+        elif extra_end_rules is not None:\n+            return self.stream.current.test_any(extra_end_rules)\n+        return False\n+\n+    def free_identifier(self, lineno=None):\n+        \"\"\"Return a new free identifier as :class:`~jinja2.nodes.InternalName`.\"\"\"\n+        self._last_identifier += 1\n+        rv = object.__new__(nodes.InternalName)\n+        nodes.Node.__init__(rv, 'fi%d' % self._last_identifier, lineno=lineno)\n+        return rv\n+\n+    def parse_statement(self):\n+        \"\"\"Parse a single statement.\"\"\"\n+        token = self.stream.current\n+        if token.type != 'name':\n+            self.fail('tag name expected', token.lineno)\n+        self._tag_stack.append(token.value)\n+        pop_tag = True\n+        try:\n+            if token.value in _statement_keywords:\n+                return getattr(self, 'parse_' + self.stream.current.value)()\n+            if token.value == 'call':\n+                return self.parse_call_block()\n+            if token.value == 'filter':\n+                return self.parse_filter_block()\n+            ext = self.extensions.get(token.value)\n+            if ext is not None:\n+                return ext(self)\n+\n+            # did not work out, remove the token we pushed by accident\n+            # from the stack so that the unknown tag fail function can\n+            # produce a proper error message.\n+            self._tag_stack.pop()\n+            pop_tag = False\n+            self.fail_unknown_tag(token.value, token.lineno)\n+        finally:\n+            if pop_tag:\n+                self._tag_stack.pop()\n+\n+    def parse_statements(self, end_tokens, drop_needle=False):\n+        \"\"\"Parse multiple statements into a list until one of the end tokens\n+        is reached.  This is used to parse the body of statements as it also\n+        parses template data if appropriate.  The parser checks first if the\n+        current token is a colon and skips it if there is one.  Then it checks\n+        for the block end and parses until if one of the `end_tokens` is\n+        reached.  Per default the active token in the stream at the end of\n+        the call is the matched end token.  If this is not wanted `drop_needle`\n+        can be set to `True` and the end token is removed.\n+        \"\"\"\n+        # the first token may be a colon for python compatibility\n+        self.stream.skip_if('colon')\n+\n+        # in the future it would be possible to add whole code sections\n+        # by adding some sort of end of statement token and parsing those here.\n+        self.stream.expect('block_end')\n+        result = self.subparse(end_tokens)\n+\n+        # we reached the end of the template too early, the subparser\n+        # does not check for this, so we do that now\n+        if self.stream.current.type == 'eof':\n+            self.fail_eof(end_tokens)\n+\n+        if drop_needle:\n+            next(self.stream)\n+        return result\n+\n+    def parse_set(self):\n+        \"\"\"Parse an assign statement.\"\"\"\n+        lineno = next(self.stream).lineno\n+        target = self.parse_assign_target(with_namespace=True)\n+        if self.stream.skip_if('assign'):\n+            expr = self.parse_tuple()\n+            return nodes.Assign(target, expr, lineno=lineno)\n+        filter_node = self.parse_filter(None)\n+        body = self.parse_statements(('name:endset',),\n+                                     drop_needle=True)\n+        return nodes.AssignBlock(target, filter_node, body, lineno=lineno)\n+\n+    def parse_for(self):\n+        \"\"\"Parse a for loop.\"\"\"\n+        lineno = self.stream.expect('name:for').lineno\n+        target = self.parse_assign_target(extra_end_rules=('name:in',))\n+        self.stream.expect('name:in')\n+        iter = self.parse_tuple(with_condexpr=False,\n+                                extra_end_rules=('name:recursive',))\n+        test = None\n+        if self.stream.skip_if('name:if'):\n+            test = self.parse_expression()\n+        recursive = self.stream.skip_if('name:recursive')\n+        body = self.parse_statements(('name:endfor', 'name:else'))\n+        if next(self.stream).value == 'endfor':\n+            else_ = []\n+        else:\n+            else_ = self.parse_statements(('name:endfor',), drop_needle=True)\n+        return nodes.For(target, iter, body, else_, test,\n+                         recursive, lineno=lineno)\n+\n+    def parse_if(self):\n+        \"\"\"Parse an if construct.\"\"\"\n+        node = result = nodes.If(lineno=self.stream.expect('name:if').lineno)\n+        while 1:\n+            node.test = self.parse_tuple(with_condexpr=False)\n+            node.body = self.parse_statements(('name:elif', 'name:else',\n+                                               'name:endif'))\n+            node.elif_ = []\n+            node.else_ = []\n+            token = next(self.stream)\n+            if token.test('name:elif'):\n+                node = nodes.If(lineno=self.stream.current.lineno)\n+                result.elif_.append(node)\n+                continue\n+            elif token.test('name:else'):\n+                result.else_ = self.parse_statements(('name:endif',),\n+                                                     drop_needle=True)\n+            break\n+        return result\n+\n+    def parse_with(self):\n+        node = nodes.With(lineno=next(self.stream).lineno)\n+        targets = []\n+        values = []\n+        while self.stream.current.type != 'block_end':\n+            lineno = self.stream.current.lineno\n+            if targets:\n+                self.stream.expect('comma')\n+            target = self.parse_assign_target()\n+            target.set_ctx('param')\n+            targets.append(target)\n+            self.stream.expect('assign')\n+            values.append(self.parse_expression())\n+        node.targets = targets\n+        node.values = values\n+        node.body = self.parse_statements(('name:endwith',),\n+                                          drop_needle=True)\n+        return node\n+\n+    def parse_autoescape(self):\n+        node = nodes.ScopedEvalContextModifier(lineno=next(self.stream).lineno)\n+        node.options = [\n+            nodes.Keyword('autoescape', self.parse_expression())\n+        ]\n+        node.body = self.parse_statements(('name:endautoescape',),\n+                                            drop_needle=True)\n+        return nodes.Scope([node])\n+\n+    def parse_block(self):\n+        node = nodes.Block(lineno=next(self.stream).lineno)\n+        node.name = self.stream.expect('name').value\n+        node.scoped = self.stream.skip_if('name:scoped')\n+\n+        # common problem people encounter when switching from django\n+        # to jinja.  we do not support hyphens in block names, so let's\n+        # raise a nicer error message in that case.\n+        if self.stream.current.type == 'sub':\n+            self.fail('Block names in Jinja have to be valid Python '\n+                      'identifiers and may not contain hyphens, use an '\n+                      'underscore instead.')\n+\n+        node.body = self.parse_statements(('name:endblock',), drop_needle=True)\n+        self.stream.skip_if('name:' + node.name)\n+        return node\n+\n+    def parse_extends(self):\n+        node = nodes.Extends(lineno=next(self.stream).lineno)\n+        node.template = self.parse_expression()\n+        return node\n+\n+    def parse_import_context(self, node, default):\n+        if self.stream.current.test_any('name:with', 'name:without') and \\\n+           self.stream.look().test('name:context'):\n+            node.with_context = next(self.stream).value == 'with'\n+            self.stream.skip()\n+        else:\n+            node.with_context = default\n+        return node\n+\n+    def parse_include(self):\n+        node = nodes.Include(lineno=next(self.stream).lineno)\n+        node.template = self.parse_expression()\n+        if self.stream.current.test('name:ignore') and \\\n+           self.stream.look().test('name:missing'):\n+            node.ignore_missing = True\n+            self.stream.skip(2)\n+        else:\n+            node.ignore_missing = False\n+        return self.parse_import_context(node, True)\n+\n+    def parse_import(self):\n+        node = nodes.Import(lineno=next(self.stream).lineno)\n+        node.template = self.parse_expression()\n+        self.stream.expect('name:as')\n+        node.target = self.parse_assign_target(name_only=True).name\n+        return self.parse_import_context(node, False)\n+\n+    def parse_from(self):\n+        node = nodes.FromImport(lineno=next(self.stream).lineno)\n+        node.template = self.parse_expression()\n+        self.stream.expect('name:import')\n+        node.names = []\n+\n+        def parse_context():\n+            if self.stream.current.value in ('with', 'without') and \\\n+               self.stream.look().test('name:context'):\n+                node.with_context = next(self.stream).value == 'with'\n+                self.stream.skip()\n+                return True\n+            return False\n+\n+        while 1:\n+            if node.names:\n+                self.stream.expect('comma')\n+            if self.stream.current.type == 'name':\n+                if parse_context():\n+                    break\n+                target = self.parse_assign_target(name_only=True)\n+                if target.name.startswith('_'):\n+                    self.fail('names starting with an underline can not '\n+                              'be imported', target.lineno,\n+                              exc=TemplateAssertionError)\n+                if self.stream.skip_if('name:as'):\n+                    alias = self.parse_assign_target(name_only=True)\n+                    node.names.append((target.name, alias.name))\n+                else:\n+                    node.names.append(target.name)\n+                if parse_context() or self.stream.current.type != 'comma':\n+                    break\n+            else:\n+                self.stream.expect('name')\n+        if not hasattr(node, 'with_context'):\n+            node.with_context = False\n+        return node\n+\n+    def parse_signature(self, node):\n+        node.args = args = []\n+        node.defaults = defaults = []\n+        self.stream.expect('lparen')\n+        while self.stream.current.type != 'rparen':\n+            if args:\n+                self.stream.expect('comma')\n+            arg = self.parse_assign_target(name_only=True)\n+            arg.set_ctx('param')\n+            if self.stream.skip_if('assign'):\n+                defaults.append(self.parse_expression())\n+            elif defaults:\n+                self.fail('non-default argument follows default argument')\n+            args.append(arg)\n+        self.stream.expect('rparen')\n+\n+    def parse_call_block(self):\n+        node = nodes.CallBlock(lineno=next(self.stream).lineno)\n+        if self.stream.current.type == 'lparen':\n+            self.parse_signature(node)\n+        else:\n+            node.args = []\n+            node.defaults = []\n+\n+        node.call = self.parse_expression()\n+        if not isinstance(node.call, nodes.Call):\n+            self.fail('expected call', node.lineno)\n+        node.body = self.parse_statements(('name:endcall',), drop_needle=True)\n+        return node\n+\n+    def parse_filter_block(self):\n+        node = nodes.FilterBlock(lineno=next(self.stream).lineno)\n+        node.filter = self.parse_filter(None, start_inline=True)\n+        node.body = self.parse_statements(('name:endfilter',),\n+                                          drop_needle=True)\n+        return node\n+\n+    def parse_macro(self):\n+        node = nodes.Macro(lineno=next(self.stream).lineno)\n+        node.name = self.parse_assign_target(name_only=True).name\n+        self.parse_signature(node)\n+        node.body = self.parse_statements(('name:endmacro',),\n+                                          drop_needle=True)\n+        return node\n+\n+    def parse_print(self):\n+        node = nodes.Output(lineno=next(self.stream).lineno)\n+        node.nodes = []\n+        while self.stream.current.type != 'block_end':\n+            if node.nodes:\n+                self.stream.expect('comma')\n+            node.nodes.append(self.parse_expression())\n+        return node\n+\n+    def parse_assign_target(self, with_tuple=True, name_only=False,\n+                            extra_end_rules=None, with_namespace=False):\n+        \"\"\"Parse an assignment target.  As Jinja2 allows assignments to\n+        tuples, this function can parse all allowed assignment targets.  Per\n+        default assignments to tuples are parsed, that can be disable however\n+        by setting `with_tuple` to `False`.  If only assignments to names are\n+        wanted `name_only` can be set to `True`.  The `extra_end_rules`\n+        parameter is forwarded to the tuple parsing function.  If\n+        `with_namespace` is enabled, a namespace assignment may be parsed.\n+        \"\"\"\n+        if with_namespace and self.stream.look().type == 'dot':\n+            token = self.stream.expect('name')\n+            next(self.stream)  # dot\n+            attr = self.stream.expect('name')\n+            target = nodes.NSRef(token.value, attr.value, lineno=token.lineno)\n+        elif name_only:\n+            token = self.stream.expect('name')\n+            target = nodes.Name(token.value, 'store', lineno=token.lineno)\n+        else:\n+            if with_tuple:\n+                target = self.parse_tuple(simplified=True,\n+                                          extra_end_rules=extra_end_rules)\n+            else:\n+                target = self.parse_primary()\n+            target.set_ctx('store')\n+        if not target.can_assign():\n+            self.fail('can\\'t assign to %r' % target.__class__.\n+                      __name__.lower(), target.lineno)\n+        return target\n+\n+    def parse_expression(self, with_condexpr=True):\n+        \"\"\"Parse an expression.  Per default all expressions are parsed, if\n+        the optional `with_condexpr` parameter is set to `False` conditional\n+        expressions are not parsed.\n+        \"\"\"\n+        if with_condexpr:\n+            return self.parse_condexpr()\n+        return self.parse_or()\n+\n+    def parse_condexpr(self):\n+        lineno = self.stream.current.lineno\n+        expr1 = self.parse_or()\n+        while self.stream.skip_if('name:if'):\n+            expr2 = self.parse_or()\n+            if self.stream.skip_if('name:else'):\n+                expr3 = self.parse_condexpr()\n+            else:\n+                expr3 = None\n+            expr1 = nodes.CondExpr(expr2, expr1, expr3, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return expr1\n+\n+    def parse_or(self):\n+        lineno = self.stream.current.lineno\n+        left = self.parse_and()\n+        while self.stream.skip_if('name:or'):\n+            right = self.parse_and()\n+            left = nodes.Or(left, right, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return left\n+\n+    def parse_and(self):\n+        lineno = self.stream.current.lineno\n+        left = self.parse_not()\n+        while self.stream.skip_if('name:and'):\n+            right = self.parse_not()\n+            left = nodes.And(left, right, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return left\n+\n+    def parse_not(self):\n+        if self.stream.current.test('name:not'):\n+            lineno = next(self.stream).lineno\n+            return nodes.Not(self.parse_not(), lineno=lineno)\n+        return self.parse_compare()\n+\n+    def parse_compare(self):\n+        lineno = self.stream.current.lineno\n+        expr = self.parse_math1()\n+        ops = []\n+        while 1:\n+            token_type = self.stream.current.type\n+            if token_type in _compare_operators:\n+                next(self.stream)\n+                ops.append(nodes.Operand(token_type, self.parse_math1()))\n+            elif self.stream.skip_if('name:in'):\n+                ops.append(nodes.Operand('in', self.parse_math1()))\n+            elif (self.stream.current.test('name:not') and\n+                  self.stream.look().test('name:in')):\n+                self.stream.skip(2)\n+                ops.append(nodes.Operand('notin', self.parse_math1()))\n+            else:\n+                break\n+            lineno = self.stream.current.lineno\n+        if not ops:\n+            return expr\n+        return nodes.Compare(expr, ops, lineno=lineno)\n+\n+    def parse_math1(self):\n+        lineno = self.stream.current.lineno\n+        left = self.parse_concat()\n+        while self.stream.current.type in ('add', 'sub'):\n+            cls = _math_nodes[self.stream.current.type]\n+            next(self.stream)\n+            right = self.parse_concat()\n+            left = cls(left, right, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return left\n+\n+    def parse_concat(self):\n+        lineno = self.stream.current.lineno\n+        args = [self.parse_math2()]\n+        while self.stream.current.type == 'tilde':\n+            next(self.stream)\n+            args.append(self.parse_math2())\n+        if len(args) == 1:\n+            return args[0]\n+        return nodes.Concat(args, lineno=lineno)\n+\n+    def parse_math2(self):\n+        lineno = self.stream.current.lineno\n+        left = self.parse_pow()\n+        while self.stream.current.type in ('mul', 'div', 'floordiv', 'mod'):\n+            cls = _math_nodes[self.stream.current.type]\n+            next(self.stream)\n+            right = self.parse_pow()\n+            left = cls(left, right, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return left\n+\n+    def parse_pow(self):\n+        lineno = self.stream.current.lineno\n+        left = self.parse_unary()\n+        while self.stream.current.type == 'pow':\n+            next(self.stream)\n+            right = self.parse_unary()\n+            left = nodes.Pow(left, right, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return left\n+\n+    def parse_unary(self, with_filter=True):\n+        token_type = self.stream.current.type\n+        lineno = self.stream.current.lineno\n+        if token_type == 'sub':\n+            next(self.stream)\n+            node = nodes.Neg(self.parse_unary(False), lineno=lineno)\n+        elif token_type == 'add':\n+            next(self.stream)\n+            node = nodes.Pos(self.parse_unary(False), lineno=lineno)\n+        else:\n+            node = self.parse_primary()\n+        node = self.parse_postfix(node)\n+        if with_filter:\n+            node = self.parse_filter_expr(node)\n+        return node\n+\n+    def parse_primary(self):\n+        token = self.stream.current\n+        if token.type == 'name':\n+            if token.value in ('true', 'false', 'True', 'False'):\n+                node = nodes.Const(token.value in ('true', 'True'),\n+                                   lineno=token.lineno)\n+            elif token.value in ('none', 'None'):\n+                node = nodes.Const(None, lineno=token.lineno)\n+            else:\n+                node = nodes.Name(token.value, 'load', lineno=token.lineno)\n+            next(self.stream)\n+        elif token.type == 'string':\n+            next(self.stream)\n+            buf = [token.value]\n+            lineno = token.lineno\n+            while self.stream.current.type == 'string':\n+                buf.append(self.stream.current.value)\n+                next(self.stream)\n+            node = nodes.Const(''.join(buf), lineno=lineno)\n+        elif token.type in ('integer', 'float'):\n+            next(self.stream)\n+            node = nodes.Const(token.value, lineno=token.lineno)\n+        elif token.type == 'lparen':\n+            next(self.stream)\n+            node = self.parse_tuple(explicit_parentheses=True)\n+            self.stream.expect('rparen')\n+        elif token.type == 'lbracket':\n+            node = self.parse_list()\n+        elif token.type == 'lbrace':\n+            node = self.parse_dict()\n+        else:\n+            self.fail(\"unexpected '%s'\" % describe_token(token), token.lineno)\n+        return node\n+\n+    def parse_tuple(self, simplified=False, with_condexpr=True,\n+                    extra_end_rules=None, explicit_parentheses=False):\n+        \"\"\"Works like `parse_expression` but if multiple expressions are\n+        delimited by a comma a :class:`~jinja2.nodes.Tuple` node is created.\n+        This method could also return a regular expression instead of a tuple\n+        if no commas where found.\n+\n+        The default parsing mode is a full tuple.  If `simplified` is `True`\n+        only names and literals are parsed.  The `no_condexpr` parameter is\n+        forwarded to :meth:`parse_expression`.\n+\n+        Because tuples do not require delimiters and may end in a bogus comma\n+        an extra hint is needed that marks the end of a tuple.  For example\n+        for loops support tuples between `for` and `in`.  In that case the\n+        `extra_end_rules` is set to ``['name:in']``.\n+\n+        `explicit_parentheses` is true if the parsing was triggered by an\n+        expression in parentheses.  This is used to figure out if an empty\n+        tuple is a valid expression or not.\n+        \"\"\"\n+        lineno = self.stream.current.lineno\n+        if simplified:\n+            parse = self.parse_primary\n+        elif with_condexpr:\n+            parse = self.parse_expression\n+        else:\n+            parse = lambda: self.parse_expression(with_condexpr=False)\n+        args = []\n+        is_tuple = False\n+        while 1:\n+            if args:\n+                self.stream.expect('comma')\n+            if self.is_tuple_end(extra_end_rules):\n+                break\n+            args.append(parse())\n+            if self.stream.current.type == 'comma':\n+                is_tuple = True\n+            else:\n+                break\n+            lineno = self.stream.current.lineno\n+\n+        if not is_tuple:\n+            if args:\n+                return args[0]\n+\n+            # if we don't have explicit parentheses, an empty tuple is\n+            # not a valid expression.  This would mean nothing (literally\n+            # nothing) in the spot of an expression would be an empty\n+            # tuple.\n+            if not explicit_parentheses:\n+                self.fail('Expected an expression, got \\'%s\\'' %\n+                          describe_token(self.stream.current))\n+\n+        return nodes.Tuple(args, 'load', lineno=lineno)\n+\n+    def parse_list(self):\n+        token = self.stream.expect('lbracket')\n+        items = []\n+        while self.stream.current.type != 'rbracket':\n+            if items:\n+                self.stream.expect('comma')\n+            if self.stream.current.type == 'rbracket':\n+                break\n+            items.append(self.parse_expression())\n+        self.stream.expect('rbracket')\n+        return nodes.List(items, lineno=token.lineno)\n+\n+    def parse_dict(self):\n+        token = self.stream.expect('lbrace')\n+        items = []\n+        while self.stream.current.type != 'rbrace':\n+            if items:\n+                self.stream.expect('comma')\n+            if self.stream.current.type == 'rbrace':\n+                break\n+            key = self.parse_expression()\n+            self.stream.expect('colon')\n+            value = self.parse_expression()\n+            items.append(nodes.Pair(key, value, lineno=key.lineno))\n+        self.stream.expect('rbrace')\n+        return nodes.Dict(items, lineno=token.lineno)\n+\n+    def parse_postfix(self, node):\n+        while 1:\n+            token_type = self.stream.current.type\n+            if token_type == 'dot' or token_type == 'lbracket':\n+                node = self.parse_subscript(node)\n+            # calls are valid both after postfix expressions (getattr\n+            # and getitem) as well as filters and tests\n+            elif token_type == 'lparen':\n+                node = self.parse_call(node)\n+            else:\n+                break\n+        return node\n+\n+    def parse_filter_expr(self, node):\n+        while 1:\n+            token_type = self.stream.current.type\n+            if token_type == 'pipe':\n+                node = self.parse_filter(node)\n+            elif token_type == 'name' and self.stream.current.value == 'is':\n+                node = self.parse_test(node)\n+            # calls are valid both after postfix expressions (getattr\n+            # and getitem) as well as filters and tests\n+            elif token_type == 'lparen':\n+                node = self.parse_call(node)\n+            else:\n+                break\n+        return node\n+\n+    def parse_subscript(self, node):\n+        token = next(self.stream)\n+        if token.type == 'dot':\n+            attr_token = self.stream.current\n+            next(self.stream)\n+            if attr_token.type == 'name':\n+                return nodes.Getattr(node, attr_token.value, 'load',\n+                                     lineno=token.lineno)\n+            elif attr_token.type != 'integer':\n+                self.fail('expected name or number', attr_token.lineno)\n+            arg = nodes.Const(attr_token.value, lineno=attr_token.lineno)\n+            return nodes.Getitem(node, arg, 'load', lineno=token.lineno)\n+        if token.type == 'lbracket':\n+            args = []\n+            while self.stream.current.type != 'rbracket':\n+                if args:\n+                    self.stream.expect('comma')\n+                args.append(self.parse_subscribed())\n+            self.stream.expect('rbracket')\n+            if len(args) == 1:\n+                arg = args[0]\n+            else:\n+                arg = nodes.Tuple(args, 'load', lineno=token.lineno)\n+            return nodes.Getitem(node, arg, 'load', lineno=token.lineno)\n+        self.fail('expected subscript expression', self.lineno)\n+\n+    def parse_subscribed(self):\n+        lineno = self.stream.current.lineno\n+\n+        if self.stream.current.type == 'colon':\n+            next(self.stream)\n+            args = [None]\n+        else:\n+            node = self.parse_expression()\n+            if self.stream.current.type != 'colon':\n+                return node\n+            next(self.stream)\n+            args = [node]\n+\n+        if self.stream.current.type == 'colon':\n+            args.append(None)\n+        elif self.stream.current.type not in ('rbracket', 'comma'):\n+            args.append(self.parse_expression())\n+        else:\n+            args.append(None)\n+\n+        if self.stream.current.type == 'colon':\n+            next(self.stream)\n+            if self.stream.current.type not in ('rbracket', 'comma'):\n+                args.append(self.parse_expression())\n+            else:\n+                args.append(None)\n+        else:\n+            args.append(None)\n+\n+        return nodes.Slice(lineno=lineno, *args)\n+\n+    def parse_call(self, node):\n+        token = self.stream.expect('lparen')\n+        args = []\n+        kwargs = []\n+        dyn_args = dyn_kwargs = None\n+        require_comma = False\n+\n+        def ensure(expr):\n+            if not expr:\n+                self.fail('invalid syntax for function call expression',\n+                          token.lineno)\n+\n+        while self.stream.current.type != 'rparen':\n+            if require_comma:\n+                self.stream.expect('comma')\n+                # support for trailing comma\n+                if self.stream.current.type == 'rparen':\n+                    break\n+            if self.stream.current.type == 'mul':\n+                ensure(dyn_args is None and dyn_kwargs is None)\n+                next(self.stream)\n+                dyn_args = self.parse_expression()\n+            elif self.stream.current.type == 'pow':\n+                ensure(dyn_kwargs is None)\n+                next(self.stream)\n+                dyn_kwargs = self.parse_expression()\n+            else:\n+                ensure(dyn_args is None and dyn_kwargs is None)\n+                if self.stream.current.type == 'name' and \\\n+                   self.stream.look().type == 'assign':\n+                    key = self.stream.current.value\n+                    self.stream.skip(2)\n+                    value = self.parse_expression()\n+                    kwargs.append(nodes.Keyword(key, value,\n+                                                lineno=value.lineno))\n+                else:\n+                    ensure(not kwargs)\n+                    args.append(self.parse_expression())\n+\n+            require_comma = True\n+        self.stream.expect('rparen')\n+\n+        if node is None:\n+            return args, kwargs, dyn_args, dyn_kwargs\n+        return nodes.Call(node, args, kwargs, dyn_args, dyn_kwargs,\n+                          lineno=token.lineno)\n+\n+    def parse_filter(self, node, start_inline=False):\n+        while self.stream.current.type == 'pipe' or start_inline:\n+            if not start_inline:\n+                next(self.stream)\n+            token = self.stream.expect('name')\n+            name = token.value\n+            while self.stream.current.type == 'dot':\n+                next(self.stream)\n+                name += '.' + self.stream.expect('name').value\n+            if self.stream.current.type == 'lparen':\n+                args, kwargs, dyn_args, dyn_kwargs = self.parse_call(None)\n+            else:\n+                args = []\n+                kwargs = []\n+                dyn_args = dyn_kwargs = None\n+            node = nodes.Filter(node, name, args, kwargs, dyn_args,\n+                                dyn_kwargs, lineno=token.lineno)\n+            start_inline = False\n+        return node\n+\n+    def parse_test(self, node):\n+        token = next(self.stream)\n+        if self.stream.current.test('name:not'):\n+            next(self.stream)\n+            negated = True\n+        else:\n+            negated = False\n+        name = self.stream.expect('name').value\n+        while self.stream.current.type == 'dot':\n+            next(self.stream)\n+            name += '.' + self.stream.expect('name').value\n+        dyn_args = dyn_kwargs = None\n+        kwargs = []\n+        if self.stream.current.type == 'lparen':\n+            args, kwargs, dyn_args, dyn_kwargs = self.parse_call(None)\n+        elif (self.stream.current.type in ('name', 'string', 'integer',\n+                                           'float', 'lparen', 'lbracket',\n+                                           'lbrace') and not\n+              self.stream.current.test_any('name:else', 'name:or',\n+                                           'name:and')):\n+            if self.stream.current.test('name:is'):\n+                self.fail('You cannot chain multiple tests with is')\n+            args = [self.parse_primary()]\n+        else:\n+            args = []\n+        node = nodes.Test(node, name, args, kwargs, dyn_args,\n+                          dyn_kwargs, lineno=token.lineno)\n+        if negated:\n+            node = nodes.Not(node, lineno=token.lineno)\n+        return node\n+\n+    def subparse(self, end_tokens=None):\n+        body = []\n+        data_buffer = []\n+        add_data = data_buffer.append\n+\n+        if end_tokens is not None:\n+            self._end_token_stack.append(end_tokens)\n+\n+        def flush_data():\n+            if data_buffer:\n+                lineno = data_buffer[0].lineno\n+                body.append(nodes.Output(data_buffer[:], lineno=lineno))\n+                del data_buffer[:]\n+\n+        try:\n+            while self.stream:\n+                token = self.stream.current\n+                if token.type == 'data':\n+                    if token.value:\n+                        add_data(nodes.TemplateData(token.value,\n+                                                    lineno=token.lineno))\n+                    next(self.stream)\n+                elif token.type == 'variable_begin':\n+                    next(self.stream)\n+                    add_data(self.parse_tuple(with_condexpr=True))\n+                    self.stream.expect('variable_end')\n+                elif token.type == 'block_begin':\n+                    flush_data()\n+                    next(self.stream)\n+                    if end_tokens is not None and \\\n+                       self.stream.current.test_any(*end_tokens):\n+                        return body\n+                    rv = self.parse_statement()\n+                    if isinstance(rv, list):\n+                        body.extend(rv)\n+                    else:\n+                        body.append(rv)\n+                    self.stream.expect('block_end')\n+                else:\n+                    raise AssertionError('internal parsing error')\n+\n+            flush_data()\n+        finally:\n+            if end_tokens is not None:\n+                self._end_token_stack.pop()\n+\n+        return body\n+\n+    def parse(self):\n+        \"\"\"Parse the whole template into a `Template` node.\"\"\"\n+        result = nodes.Template(self.subparse(), lineno=1)\n+        result.set_environment(self.environment)\n+        return result"
        },
        {
            "sha": "f9d7a6806caf54996c05f2e108883d380eeec923",
            "filename": "tools/jinja2/runtime.py",
            "status": "added",
            "additions": 813,
            "deletions": 0,
            "changes": 813,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fruntime.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fruntime.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fruntime.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,813 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.runtime\n+    ~~~~~~~~~~~~~~\n+\n+    Runtime helpers.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD.\n+\"\"\"\n+import sys\n+\n+from itertools import chain\n+from types import MethodType\n+\n+from jinja2.nodes import EvalContext, _context_function_types\n+from jinja2.utils import Markup, soft_unicode, escape, missing, concat, \\\n+     internalcode, object_type_repr, evalcontextfunction, Namespace\n+from jinja2.exceptions import UndefinedError, TemplateRuntimeError, \\\n+     TemplateNotFound\n+from jinja2._compat import imap, text_type, iteritems, \\\n+     implements_iterator, implements_to_string, string_types, PY2, \\\n+     with_metaclass\n+\n+\n+# these variables are exported to the template runtime\n+__all__ = ['LoopContext', 'TemplateReference', 'Macro', 'Markup',\n+           'TemplateRuntimeError', 'missing', 'concat', 'escape',\n+           'markup_join', 'unicode_join', 'to_string', 'identity',\n+           'TemplateNotFound', 'Namespace']\n+\n+#: the name of the function that is used to convert something into\n+#: a string.  We can just use the text type here.\n+to_string = text_type\n+\n+#: the identity function.  Useful for certain things in the environment\n+identity = lambda x: x\n+\n+_first_iteration = object()\n+_last_iteration = object()\n+\n+\n+def markup_join(seq):\n+    \"\"\"Concatenation that escapes if necessary and converts to unicode.\"\"\"\n+    buf = []\n+    iterator = imap(soft_unicode, seq)\n+    for arg in iterator:\n+        buf.append(arg)\n+        if hasattr(arg, '__html__'):\n+            return Markup(u'').join(chain(buf, iterator))\n+    return concat(buf)\n+\n+\n+def unicode_join(seq):\n+    \"\"\"Simple args to unicode conversion and concatenation.\"\"\"\n+    return concat(imap(text_type, seq))\n+\n+\n+def new_context(environment, template_name, blocks, vars=None,\n+                shared=None, globals=None, locals=None):\n+    \"\"\"Internal helper to for context creation.\"\"\"\n+    if vars is None:\n+        vars = {}\n+    if shared:\n+        parent = vars\n+    else:\n+        parent = dict(globals or (), **vars)\n+    if locals:\n+        # if the parent is shared a copy should be created because\n+        # we don't want to modify the dict passed\n+        if shared:\n+            parent = dict(parent)\n+        for key, value in iteritems(locals):\n+            if value is not missing:\n+                parent[key] = value\n+    return environment.context_class(environment, parent, template_name,\n+                                     blocks)\n+\n+\n+class TemplateReference(object):\n+    \"\"\"The `self` in templates.\"\"\"\n+\n+    def __init__(self, context):\n+        self.__context = context\n+\n+    def __getitem__(self, name):\n+        blocks = self.__context.blocks[name]\n+        return BlockReference(name, self.__context, blocks, 0)\n+\n+    def __repr__(self):\n+        return '<%s %r>' % (\n+            self.__class__.__name__,\n+            self.__context.name\n+        )\n+\n+\n+def _get_func(x):\n+    return getattr(x, '__func__', x)\n+\n+\n+class ContextMeta(type):\n+\n+    def __new__(cls, name, bases, d):\n+        rv = type.__new__(cls, name, bases, d)\n+        if bases == ():\n+            return rv\n+\n+        resolve = _get_func(rv.resolve)\n+        default_resolve = _get_func(Context.resolve)\n+        resolve_or_missing = _get_func(rv.resolve_or_missing)\n+        default_resolve_or_missing = _get_func(Context.resolve_or_missing)\n+\n+        # If we have a changed resolve but no changed default or missing\n+        # resolve we invert the call logic.\n+        if resolve is not default_resolve and \\\n+           resolve_or_missing is default_resolve_or_missing:\n+            rv._legacy_resolve_mode = True\n+        elif resolve is default_resolve and \\\n+             resolve_or_missing is default_resolve_or_missing:\n+            rv._fast_resolve_mode = True\n+\n+        return rv\n+\n+\n+def resolve_or_missing(context, key, missing=missing):\n+    if key in context.vars:\n+        return context.vars[key]\n+    if key in context.parent:\n+        return context.parent[key]\n+    return missing\n+\n+\n+class Context(with_metaclass(ContextMeta)):\n+    \"\"\"The template context holds the variables of a template.  It stores the\n+    values passed to the template and also the names the template exports.\n+    Creating instances is neither supported nor useful as it's created\n+    automatically at various stages of the template evaluation and should not\n+    be created by hand.\n+\n+    The context is immutable.  Modifications on :attr:`parent` **must not**\n+    happen and modifications on :attr:`vars` are allowed from generated\n+    template code only.  Template filters and global functions marked as\n+    :func:`contextfunction`\\\\s get the active context passed as first argument\n+    and are allowed to access the context read-only.\n+\n+    The template context supports read only dict operations (`get`,\n+    `keys`, `values`, `items`, `iterkeys`, `itervalues`, `iteritems`,\n+    `__getitem__`, `__contains__`).  Additionally there is a :meth:`resolve`\n+    method that doesn't fail with a `KeyError` but returns an\n+    :class:`Undefined` object for missing variables.\n+    \"\"\"\n+    # XXX: we want to eventually make this be a deprecation warning and\n+    # remove it.\n+    _legacy_resolve_mode = False\n+    _fast_resolve_mode = False\n+\n+    def __init__(self, environment, parent, name, blocks):\n+        self.parent = parent\n+        self.vars = {}\n+        self.environment = environment\n+        self.eval_ctx = EvalContext(self.environment, name)\n+        self.exported_vars = set()\n+        self.name = name\n+\n+        # create the initial mapping of blocks.  Whenever template inheritance\n+        # takes place the runtime will update this mapping with the new blocks\n+        # from the template.\n+        self.blocks = dict((k, [v]) for k, v in iteritems(blocks))\n+\n+        # In case we detect the fast resolve mode we can set up an alias\n+        # here that bypasses the legacy code logic.\n+        if self._fast_resolve_mode:\n+            self.resolve_or_missing = MethodType(resolve_or_missing, self)\n+\n+    def super(self, name, current):\n+        \"\"\"Render a parent block.\"\"\"\n+        try:\n+            blocks = self.blocks[name]\n+            index = blocks.index(current) + 1\n+            blocks[index]\n+        except LookupError:\n+            return self.environment.undefined('there is no parent block '\n+                                              'called %r.' % name,\n+                                              name='super')\n+        return BlockReference(name, self, blocks, index)\n+\n+    def get(self, key, default=None):\n+        \"\"\"Returns an item from the template context, if it doesn't exist\n+        `default` is returned.\n+        \"\"\"\n+        try:\n+            return self[key]\n+        except KeyError:\n+            return default\n+\n+    def resolve(self, key):\n+        \"\"\"Looks up a variable like `__getitem__` or `get` but returns an\n+        :class:`Undefined` object with the name of the name looked up.\n+        \"\"\"\n+        if self._legacy_resolve_mode:\n+            rv = resolve_or_missing(self, key)\n+        else:\n+            rv = self.resolve_or_missing(key)\n+        if rv is missing:\n+            return self.environment.undefined(name=key)\n+        return rv\n+\n+    def resolve_or_missing(self, key):\n+        \"\"\"Resolves a variable like :meth:`resolve` but returns the\n+        special `missing` value if it cannot be found.\n+        \"\"\"\n+        if self._legacy_resolve_mode:\n+            rv = self.resolve(key)\n+            if isinstance(rv, Undefined):\n+                rv = missing\n+            return rv\n+        return resolve_or_missing(self, key)\n+\n+    def get_exported(self):\n+        \"\"\"Get a new dict with the exported variables.\"\"\"\n+        return dict((k, self.vars[k]) for k in self.exported_vars)\n+\n+    def get_all(self):\n+        \"\"\"Return the complete context as dict including the exported\n+        variables.  For optimizations reasons this might not return an\n+        actual copy so be careful with using it.\n+        \"\"\"\n+        if not self.vars:\n+            return self.parent\n+        if not self.parent:\n+            return self.vars\n+        return dict(self.parent, **self.vars)\n+\n+    @internalcode\n+    def call(__self, __obj, *args, **kwargs):\n+        \"\"\"Call the callable with the arguments and keyword arguments\n+        provided but inject the active context or environment as first\n+        argument if the callable is a :func:`contextfunction` or\n+        :func:`environmentfunction`.\n+        \"\"\"\n+        if __debug__:\n+            __traceback_hide__ = True  # noqa\n+\n+        # Allow callable classes to take a context\n+        if hasattr(__obj, '__call__'):\n+            fn = __obj.__call__\n+            for fn_type in ('contextfunction',\n+                            'evalcontextfunction',\n+                            'environmentfunction'):\n+                if hasattr(fn, fn_type):\n+                    __obj = fn\n+                    break\n+\n+        if isinstance(__obj, _context_function_types):\n+            if getattr(__obj, 'contextfunction', 0):\n+                args = (__self,) + args\n+            elif getattr(__obj, 'evalcontextfunction', 0):\n+                args = (__self.eval_ctx,) + args\n+            elif getattr(__obj, 'environmentfunction', 0):\n+                args = (__self.environment,) + args\n+        try:\n+            return __obj(*args, **kwargs)\n+        except StopIteration:\n+            return __self.environment.undefined('value was undefined because '\n+                                                'a callable raised a '\n+                                                'StopIteration exception')\n+\n+    def derived(self, locals=None):\n+        \"\"\"Internal helper function to create a derived context.  This is\n+        used in situations where the system needs a new context in the same\n+        template that is independent.\n+        \"\"\"\n+        context = new_context(self.environment, self.name, {},\n+                              self.get_all(), True, None, locals)\n+        context.eval_ctx = self.eval_ctx\n+        context.blocks.update((k, list(v)) for k, v in iteritems(self.blocks))\n+        return context\n+\n+    def _all(meth):\n+        proxy = lambda self: getattr(self.get_all(), meth)()\n+        proxy.__doc__ = getattr(dict, meth).__doc__\n+        proxy.__name__ = meth\n+        return proxy\n+\n+    keys = _all('keys')\n+    values = _all('values')\n+    items = _all('items')\n+\n+    # not available on python 3\n+    if PY2:\n+        iterkeys = _all('iterkeys')\n+        itervalues = _all('itervalues')\n+        iteritems = _all('iteritems')\n+    del _all\n+\n+    def __contains__(self, name):\n+        return name in self.vars or name in self.parent\n+\n+    def __getitem__(self, key):\n+        \"\"\"Lookup a variable or raise `KeyError` if the variable is\n+        undefined.\n+        \"\"\"\n+        item = self.resolve_or_missing(key)\n+        if item is missing:\n+            raise KeyError(key)\n+        return item\n+\n+    def __repr__(self):\n+        return '<%s %s of %r>' % (\n+            self.__class__.__name__,\n+            repr(self.get_all()),\n+            self.name\n+        )\n+\n+\n+# register the context as mapping if possible\n+try:\n+    from collections import Mapping\n+    Mapping.register(Context)\n+except ImportError:\n+    pass\n+\n+\n+class BlockReference(object):\n+    \"\"\"One block on a template reference.\"\"\"\n+\n+    def __init__(self, name, context, stack, depth):\n+        self.name = name\n+        self._context = context\n+        self._stack = stack\n+        self._depth = depth\n+\n+    @property\n+    def super(self):\n+        \"\"\"Super the block.\"\"\"\n+        if self._depth + 1 >= len(self._stack):\n+            return self._context.environment. \\\n+                undefined('there is no parent block called %r.' %\n+                          self.name, name='super')\n+        return BlockReference(self.name, self._context, self._stack,\n+                              self._depth + 1)\n+\n+    @internalcode\n+    def __call__(self):\n+        rv = concat(self._stack[self._depth](self._context))\n+        if self._context.eval_ctx.autoescape:\n+            rv = Markup(rv)\n+        return rv\n+\n+\n+class LoopContextBase(object):\n+    \"\"\"A loop context for dynamic iteration.\"\"\"\n+\n+    _before = _first_iteration\n+    _current = _first_iteration\n+    _after = _last_iteration\n+    _length = None\n+\n+    def __init__(self, undefined, recurse=None, depth0=0):\n+        self._undefined = undefined\n+        self._recurse = recurse\n+        self.index0 = -1\n+        self.depth0 = depth0\n+        self._last_checked_value = missing\n+\n+    def cycle(self, *args):\n+        \"\"\"Cycles among the arguments with the current loop index.\"\"\"\n+        if not args:\n+            raise TypeError('no items for cycling given')\n+        return args[self.index0 % len(args)]\n+\n+    def changed(self, *value):\n+        \"\"\"Checks whether the value has changed since the last call.\"\"\"\n+        if self._last_checked_value != value:\n+            self._last_checked_value = value\n+            return True\n+        return False\n+\n+    first = property(lambda x: x.index0 == 0)\n+    last = property(lambda x: x._after is _last_iteration)\n+    index = property(lambda x: x.index0 + 1)\n+    revindex = property(lambda x: x.length - x.index0)\n+    revindex0 = property(lambda x: x.length - x.index)\n+    depth = property(lambda x: x.depth0 + 1)\n+\n+    @property\n+    def previtem(self):\n+        if self._before is _first_iteration:\n+            return self._undefined('there is no previous item')\n+        return self._before\n+\n+    @property\n+    def nextitem(self):\n+        if self._after is _last_iteration:\n+            return self._undefined('there is no next item')\n+        return self._after\n+\n+    def __len__(self):\n+        return self.length\n+\n+    @internalcode\n+    def loop(self, iterable):\n+        if self._recurse is None:\n+            raise TypeError('Tried to call non recursive loop.  Maybe you '\n+                            \"forgot the 'recursive' modifier.\")\n+        return self._recurse(iterable, self._recurse, self.depth0 + 1)\n+\n+    # a nifty trick to enhance the error message if someone tried to call\n+    # the the loop without or with too many arguments.\n+    __call__ = loop\n+    del loop\n+\n+    def __repr__(self):\n+        return '<%s %r/%r>' % (\n+            self.__class__.__name__,\n+            self.index,\n+            self.length\n+        )\n+\n+\n+class LoopContext(LoopContextBase):\n+\n+    def __init__(self, iterable, undefined, recurse=None, depth0=0):\n+        LoopContextBase.__init__(self, undefined, recurse, depth0)\n+        self._iterator = iter(iterable)\n+\n+        # try to get the length of the iterable early.  This must be done\n+        # here because there are some broken iterators around where there\n+        # __len__ is the number of iterations left (i'm looking at your\n+        # listreverseiterator!).\n+        try:\n+            self._length = len(iterable)\n+        except (TypeError, AttributeError):\n+            self._length = None\n+        self._after = self._safe_next()\n+\n+    @property\n+    def length(self):\n+        if self._length is None:\n+            # if was not possible to get the length of the iterator when\n+            # the loop context was created (ie: iterating over a generator)\n+            # we have to convert the iterable into a sequence and use the\n+            # length of that + the number of iterations so far.\n+            iterable = tuple(self._iterator)\n+            self._iterator = iter(iterable)\n+            iterations_done = self.index0 + 2\n+            self._length = len(iterable) + iterations_done\n+        return self._length\n+\n+    def __iter__(self):\n+        return LoopContextIterator(self)\n+\n+    def _safe_next(self):\n+        try:\n+            return next(self._iterator)\n+        except StopIteration:\n+            return _last_iteration\n+\n+\n+@implements_iterator\n+class LoopContextIterator(object):\n+    \"\"\"The iterator for a loop context.\"\"\"\n+    __slots__ = ('context',)\n+\n+    def __init__(self, context):\n+        self.context = context\n+\n+    def __iter__(self):\n+        return self\n+\n+    def __next__(self):\n+        ctx = self.context\n+        ctx.index0 += 1\n+        if ctx._after is _last_iteration:\n+            raise StopIteration()\n+        ctx._before = ctx._current\n+        ctx._current = ctx._after\n+        ctx._after = ctx._safe_next()\n+        return ctx._current, ctx\n+\n+\n+class Macro(object):\n+    \"\"\"Wraps a macro function.\"\"\"\n+\n+    def __init__(self, environment, func, name, arguments,\n+                 catch_kwargs, catch_varargs, caller,\n+                 default_autoescape=None):\n+        self._environment = environment\n+        self._func = func\n+        self._argument_count = len(arguments)\n+        self.name = name\n+        self.arguments = arguments\n+        self.catch_kwargs = catch_kwargs\n+        self.catch_varargs = catch_varargs\n+        self.caller = caller\n+        self.explicit_caller = 'caller' in arguments\n+        if default_autoescape is None:\n+            default_autoescape = environment.autoescape\n+        self._default_autoescape = default_autoescape\n+\n+    @internalcode\n+    @evalcontextfunction\n+    def __call__(self, *args, **kwargs):\n+        # This requires a bit of explanation,  In the past we used to\n+        # decide largely based on compile-time information if a macro is\n+        # safe or unsafe.  While there was a volatile mode it was largely\n+        # unused for deciding on escaping.  This turns out to be\n+        # problemtic for macros because if a macro is safe or not not so\n+        # much depends on the escape mode when it was defined but when it\n+        # was used.\n+        #\n+        # Because however we export macros from the module system and\n+        # there are historic callers that do not pass an eval context (and\n+        # will continue to not pass one), we need to perform an instance\n+        # check here.\n+        #\n+        # This is considered safe because an eval context is not a valid\n+        # argument to callables otherwise anwyays.  Worst case here is\n+        # that if no eval context is passed we fall back to the compile\n+        # time autoescape flag.\n+        if args and isinstance(args[0], EvalContext):\n+            autoescape = args[0].autoescape\n+            args = args[1:]\n+        else:\n+            autoescape = self._default_autoescape\n+\n+        # try to consume the positional arguments\n+        arguments = list(args[:self._argument_count])\n+        off = len(arguments)\n+\n+        # For information why this is necessary refer to the handling\n+        # of caller in the `macro_body` handler in the compiler.\n+        found_caller = False\n+\n+        # if the number of arguments consumed is not the number of\n+        # arguments expected we start filling in keyword arguments\n+        # and defaults.\n+        if off != self._argument_count:\n+            for idx, name in enumerate(self.arguments[len(arguments):]):\n+                try:\n+                    value = kwargs.pop(name)\n+                except KeyError:\n+                    value = missing\n+                if name == 'caller':\n+                    found_caller = True\n+                arguments.append(value)\n+        else:\n+            found_caller = self.explicit_caller\n+\n+        # it's important that the order of these arguments does not change\n+        # if not also changed in the compiler's `function_scoping` method.\n+        # the order is caller, keyword arguments, positional arguments!\n+        if self.caller and not found_caller:\n+            caller = kwargs.pop('caller', None)\n+            if caller is None:\n+                caller = self._environment.undefined('No caller defined',\n+                                                     name='caller')\n+            arguments.append(caller)\n+\n+        if self.catch_kwargs:\n+            arguments.append(kwargs)\n+        elif kwargs:\n+            if 'caller' in kwargs:\n+                raise TypeError('macro %r was invoked with two values for '\n+                                'the special caller argument.  This is '\n+                                'most likely a bug.' % self.name)\n+            raise TypeError('macro %r takes no keyword argument %r' %\n+                            (self.name, next(iter(kwargs))))\n+        if self.catch_varargs:\n+            arguments.append(args[self._argument_count:])\n+        elif len(args) > self._argument_count:\n+            raise TypeError('macro %r takes not more than %d argument(s)' %\n+                            (self.name, len(self.arguments)))\n+\n+        return self._invoke(arguments, autoescape)\n+\n+    def _invoke(self, arguments, autoescape):\n+        \"\"\"This method is being swapped out by the async implementation.\"\"\"\n+        rv = self._func(*arguments)\n+        if autoescape:\n+            rv = Markup(rv)\n+        return rv\n+\n+    def __repr__(self):\n+        return '<%s %s>' % (\n+            self.__class__.__name__,\n+            self.name is None and 'anonymous' or repr(self.name)\n+        )\n+\n+\n+@implements_to_string\n+class Undefined(object):\n+    \"\"\"The default undefined type.  This undefined type can be printed and\n+    iterated over, but every other access will raise an :exc:`jinja2.exceptions.UndefinedError`:\n+\n+    >>> foo = Undefined(name='foo')\n+    >>> str(foo)\n+    ''\n+    >>> not foo\n+    True\n+    >>> foo + 42\n+    Traceback (most recent call last):\n+      ...\n+    jinja2.exceptions.UndefinedError: 'foo' is undefined\n+    \"\"\"\n+    __slots__ = ('_undefined_hint', '_undefined_obj', '_undefined_name',\n+                 '_undefined_exception')\n+\n+    def __init__(self, hint=None, obj=missing, name=None, exc=UndefinedError):\n+        self._undefined_hint = hint\n+        self._undefined_obj = obj\n+        self._undefined_name = name\n+        self._undefined_exception = exc\n+\n+    @internalcode\n+    def _fail_with_undefined_error(self, *args, **kwargs):\n+        \"\"\"Regular callback function for undefined objects that raises an\n+        `jinja2.exceptions.UndefinedError` on call.\n+        \"\"\"\n+        if self._undefined_hint is None:\n+            if self._undefined_obj is missing:\n+                hint = '%r is undefined' % self._undefined_name\n+            elif not isinstance(self._undefined_name, string_types):\n+                hint = '%s has no element %r' % (\n+                    object_type_repr(self._undefined_obj),\n+                    self._undefined_name\n+                )\n+            else:\n+                hint = '%r has no attribute %r' % (\n+                    object_type_repr(self._undefined_obj),\n+                    self._undefined_name\n+                )\n+        else:\n+            hint = self._undefined_hint\n+        raise self._undefined_exception(hint)\n+\n+    @internalcode\n+    def __getattr__(self, name):\n+        if name[:2] == '__':\n+            raise AttributeError(name)\n+        return self._fail_with_undefined_error()\n+\n+    __add__ = __radd__ = __mul__ = __rmul__ = __div__ = __rdiv__ = \\\n+        __truediv__ = __rtruediv__ = __floordiv__ = __rfloordiv__ = \\\n+        __mod__ = __rmod__ = __pos__ = __neg__ = __call__ = \\\n+        __getitem__ = __lt__ = __le__ = __gt__ = __ge__ = __int__ = \\\n+        __float__ = __complex__ = __pow__ = __rpow__ = __sub__ = \\\n+        __rsub__ = _fail_with_undefined_error\n+\n+    def __eq__(self, other):\n+        return type(self) is type(other)\n+\n+    def __ne__(self, other):\n+        return not self.__eq__(other)\n+\n+    def __hash__(self):\n+        return id(type(self))\n+\n+    def __str__(self):\n+        return u''\n+\n+    def __len__(self):\n+        return 0\n+\n+    def __iter__(self):\n+        if 0:\n+            yield None\n+\n+    def __nonzero__(self):\n+        return False\n+    __bool__ = __nonzero__\n+\n+    def __repr__(self):\n+        return 'Undefined'\n+\n+\n+def make_logging_undefined(logger=None, base=None):\n+    \"\"\"Given a logger object this returns a new undefined class that will\n+    log certain failures.  It will log iterations and printing.  If no\n+    logger is given a default logger is created.\n+\n+    Example::\n+\n+        logger = logging.getLogger(__name__)\n+        LoggingUndefined = make_logging_undefined(\n+            logger=logger,\n+            base=Undefined\n+        )\n+\n+    .. versionadded:: 2.8\n+\n+    :param logger: the logger to use.  If not provided, a default logger\n+                   is created.\n+    :param base: the base class to add logging functionality to.  This\n+                 defaults to :class:`Undefined`.\n+    \"\"\"\n+    if logger is None:\n+        import logging\n+        logger = logging.getLogger(__name__)\n+        logger.addHandler(logging.StreamHandler(sys.stderr))\n+    if base is None:\n+        base = Undefined\n+\n+    def _log_message(undef):\n+        if undef._undefined_hint is None:\n+            if undef._undefined_obj is missing:\n+                hint = '%s is undefined' % undef._undefined_name\n+            elif not isinstance(undef._undefined_name, string_types):\n+                hint = '%s has no element %s' % (\n+                    object_type_repr(undef._undefined_obj),\n+                    undef._undefined_name)\n+            else:\n+                hint = '%s has no attribute %s' % (\n+                    object_type_repr(undef._undefined_obj),\n+                    undef._undefined_name)\n+        else:\n+            hint = undef._undefined_hint\n+        logger.warning('Template variable warning: %s', hint)\n+\n+    class LoggingUndefined(base):\n+\n+        def _fail_with_undefined_error(self, *args, **kwargs):\n+            try:\n+                return base._fail_with_undefined_error(self, *args, **kwargs)\n+            except self._undefined_exception as e:\n+                logger.error('Template variable error: %s', str(e))\n+                raise e\n+\n+        def __str__(self):\n+            rv = base.__str__(self)\n+            _log_message(self)\n+            return rv\n+\n+        def __iter__(self):\n+            rv = base.__iter__(self)\n+            _log_message(self)\n+            return rv\n+\n+        if PY2:\n+            def __nonzero__(self):\n+                rv = base.__nonzero__(self)\n+                _log_message(self)\n+                return rv\n+\n+            def __unicode__(self):\n+                rv = base.__unicode__(self)\n+                _log_message(self)\n+                return rv\n+        else:\n+            def __bool__(self):\n+                rv = base.__bool__(self)\n+                _log_message(self)\n+                return rv\n+\n+    return LoggingUndefined\n+\n+\n+@implements_to_string\n+class DebugUndefined(Undefined):\n+    \"\"\"An undefined that returns the debug info when printed.\n+\n+    >>> foo = DebugUndefined(name='foo')\n+    >>> str(foo)\n+    '{{ foo }}'\n+    >>> not foo\n+    True\n+    >>> foo + 42\n+    Traceback (most recent call last):\n+      ...\n+    jinja2.exceptions.UndefinedError: 'foo' is undefined\n+    \"\"\"\n+    __slots__ = ()\n+\n+    def __str__(self):\n+        if self._undefined_hint is None:\n+            if self._undefined_obj is missing:\n+                return u'{{ %s }}' % self._undefined_name\n+            return '{{ no such element: %s[%r] }}' % (\n+                object_type_repr(self._undefined_obj),\n+                self._undefined_name\n+            )\n+        return u'{{ undefined value printed: %s }}' % self._undefined_hint\n+\n+\n+@implements_to_string\n+class StrictUndefined(Undefined):\n+    \"\"\"An undefined that barks on print and iteration as well as boolean\n+    tests and all kinds of comparisons.  In other words: you can do nothing\n+    with it except checking if it's defined using the `defined` test.\n+\n+    >>> foo = StrictUndefined(name='foo')\n+    >>> str(foo)\n+    Traceback (most recent call last):\n+      ...\n+    jinja2.exceptions.UndefinedError: 'foo' is undefined\n+    >>> not foo\n+    Traceback (most recent call last):\n+      ...\n+    jinja2.exceptions.UndefinedError: 'foo' is undefined\n+    >>> foo + 42\n+    Traceback (most recent call last):\n+      ...\n+    jinja2.exceptions.UndefinedError: 'foo' is undefined\n+    \"\"\"\n+    __slots__ = ()\n+    __iter__ = __str__ = __len__ = __nonzero__ = __eq__ = \\\n+        __ne__ = __bool__ = __hash__ = \\\n+        Undefined._fail_with_undefined_error\n+\n+\n+# remove remaining slots attributes, after the metaclass did the magic they\n+# are unneeded and irritating as they contain wrong data for the subclasses.\n+del Undefined.__slots__, DebugUndefined.__slots__, StrictUndefined.__slots__"
        },
        {
            "sha": "93fb9d45f32d8b511a83c3271a45e0abe01e77fe",
            "filename": "tools/jinja2/sandbox.py",
            "status": "added",
            "additions": 475,
            "deletions": 0,
            "changes": 475,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fsandbox.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fsandbox.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fsandbox.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,475 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.sandbox\n+    ~~~~~~~~~~~~~~\n+\n+    Adds a sandbox layer to Jinja as it was the default behavior in the old\n+    Jinja 1 releases.  This sandbox is slightly different from Jinja 1 as the\n+    default behavior is easier to use.\n+\n+    The behavior can be changed by subclassing the environment.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD.\n+\"\"\"\n+import types\n+import operator\n+from collections import Mapping\n+from jinja2.environment import Environment\n+from jinja2.exceptions import SecurityError\n+from jinja2._compat import string_types, PY2\n+from jinja2.utils import Markup\n+\n+from markupsafe import EscapeFormatter\n+from string import Formatter\n+\n+\n+#: maximum number of items a range may produce\n+MAX_RANGE = 100000\n+\n+#: attributes of function objects that are considered unsafe.\n+if PY2:\n+    UNSAFE_FUNCTION_ATTRIBUTES = set(['func_closure', 'func_code', 'func_dict',\n+                                      'func_defaults', 'func_globals'])\n+else:\n+    # On versions > python 2 the special attributes on functions are gone,\n+    # but they remain on methods and generators for whatever reason.\n+    UNSAFE_FUNCTION_ATTRIBUTES = set()\n+\n+\n+#: unsafe method attributes.  function attributes are unsafe for methods too\n+UNSAFE_METHOD_ATTRIBUTES = set(['im_class', 'im_func', 'im_self'])\n+\n+#: unsafe generator attirbutes.\n+UNSAFE_GENERATOR_ATTRIBUTES = set(['gi_frame', 'gi_code'])\n+\n+#: unsafe attributes on coroutines\n+UNSAFE_COROUTINE_ATTRIBUTES = set(['cr_frame', 'cr_code'])\n+\n+#: unsafe attributes on async generators\n+UNSAFE_ASYNC_GENERATOR_ATTRIBUTES = set(['ag_code', 'ag_frame'])\n+\n+import warnings\n+\n+# make sure we don't warn in python 2.6 about stuff we don't care about\n+warnings.filterwarnings('ignore', 'the sets module', DeprecationWarning,\n+                        module='jinja2.sandbox')\n+\n+from collections import deque\n+\n+_mutable_set_types = (set,)\n+_mutable_mapping_types = (dict,)\n+_mutable_sequence_types = (list,)\n+\n+\n+# on python 2.x we can register the user collection types\n+try:\n+    from UserDict import UserDict, DictMixin\n+    from UserList import UserList\n+    _mutable_mapping_types += (UserDict, DictMixin)\n+    _mutable_set_types += (UserList,)\n+except ImportError:\n+    pass\n+\n+# if sets is still available, register the mutable set from there as well\n+try:\n+    from sets import Set\n+    _mutable_set_types += (Set,)\n+except ImportError:\n+    pass\n+\n+#: register Python 2.6 abstract base classes\n+from collections import MutableSet, MutableMapping, MutableSequence\n+_mutable_set_types += (MutableSet,)\n+_mutable_mapping_types += (MutableMapping,)\n+_mutable_sequence_types += (MutableSequence,)\n+\n+\n+_mutable_spec = (\n+    (_mutable_set_types, frozenset([\n+        'add', 'clear', 'difference_update', 'discard', 'pop', 'remove',\n+        'symmetric_difference_update', 'update'\n+    ])),\n+    (_mutable_mapping_types, frozenset([\n+        'clear', 'pop', 'popitem', 'setdefault', 'update'\n+    ])),\n+    (_mutable_sequence_types, frozenset([\n+        'append', 'reverse', 'insert', 'sort', 'extend', 'remove'\n+    ])),\n+    (deque, frozenset([\n+        'append', 'appendleft', 'clear', 'extend', 'extendleft', 'pop',\n+        'popleft', 'remove', 'rotate'\n+    ]))\n+)\n+\n+\n+class _MagicFormatMapping(Mapping):\n+    \"\"\"This class implements a dummy wrapper to fix a bug in the Python\n+    standard library for string formatting.\n+\n+    See https://bugs.python.org/issue13598 for information about why\n+    this is necessary.\n+    \"\"\"\n+\n+    def __init__(self, args, kwargs):\n+        self._args = args\n+        self._kwargs = kwargs\n+        self._last_index = 0\n+\n+    def __getitem__(self, key):\n+        if key == '':\n+            idx = self._last_index\n+            self._last_index += 1\n+            try:\n+                return self._args[idx]\n+            except LookupError:\n+                pass\n+            key = str(idx)\n+        return self._kwargs[key]\n+\n+    def __iter__(self):\n+        return iter(self._kwargs)\n+\n+    def __len__(self):\n+        return len(self._kwargs)\n+\n+\n+def inspect_format_method(callable):\n+    if not isinstance(callable, (types.MethodType,\n+                                 types.BuiltinMethodType)) or \\\n+       callable.__name__ != 'format':\n+        return None\n+    obj = callable.__self__\n+    if isinstance(obj, string_types):\n+        return obj\n+\n+\n+def safe_range(*args):\n+    \"\"\"A range that can't generate ranges with a length of more than\n+    MAX_RANGE items.\n+    \"\"\"\n+    rng = range(*args)\n+    if len(rng) > MAX_RANGE:\n+        raise OverflowError('range too big, maximum size for range is %d' %\n+                            MAX_RANGE)\n+    return rng\n+\n+\n+def unsafe(f):\n+    \"\"\"Marks a function or method as unsafe.\n+\n+    ::\n+\n+        @unsafe\n+        def delete(self):\n+            pass\n+    \"\"\"\n+    f.unsafe_callable = True\n+    return f\n+\n+\n+def is_internal_attribute(obj, attr):\n+    \"\"\"Test if the attribute given is an internal python attribute.  For\n+    example this function returns `True` for the `func_code` attribute of\n+    python objects.  This is useful if the environment method\n+    :meth:`~SandboxedEnvironment.is_safe_attribute` is overridden.\n+\n+    >>> from jinja2.sandbox import is_internal_attribute\n+    >>> is_internal_attribute(str, \"mro\")\n+    True\n+    >>> is_internal_attribute(str, \"upper\")\n+    False\n+    \"\"\"\n+    if isinstance(obj, types.FunctionType):\n+        if attr in UNSAFE_FUNCTION_ATTRIBUTES:\n+            return True\n+    elif isinstance(obj, types.MethodType):\n+        if attr in UNSAFE_FUNCTION_ATTRIBUTES or \\\n+           attr in UNSAFE_METHOD_ATTRIBUTES:\n+            return True\n+    elif isinstance(obj, type):\n+        if attr == 'mro':\n+            return True\n+    elif isinstance(obj, (types.CodeType, types.TracebackType, types.FrameType)):\n+        return True\n+    elif isinstance(obj, types.GeneratorType):\n+        if attr in UNSAFE_GENERATOR_ATTRIBUTES:\n+            return True\n+    elif hasattr(types, 'CoroutineType') and isinstance(obj, types.CoroutineType):\n+        if attr in UNSAFE_COROUTINE_ATTRIBUTES:\n+            return True\n+    elif hasattr(types, 'AsyncGeneratorType') and isinstance(obj, types.AsyncGeneratorType):\n+        if attr in UNSAFE_ASYNC_GENERATOR_ATTRIBUTES:\n+            return True\n+    return attr.startswith('__')\n+\n+\n+def modifies_known_mutable(obj, attr):\n+    \"\"\"This function checks if an attribute on a builtin mutable object\n+    (list, dict, set or deque) would modify it if called.  It also supports\n+    the \"user\"-versions of the objects (`sets.Set`, `UserDict.*` etc.) and\n+    with Python 2.6 onwards the abstract base classes `MutableSet`,\n+    `MutableMapping`, and `MutableSequence`.\n+\n+    >>> modifies_known_mutable({}, \"clear\")\n+    True\n+    >>> modifies_known_mutable({}, \"keys\")\n+    False\n+    >>> modifies_known_mutable([], \"append\")\n+    True\n+    >>> modifies_known_mutable([], \"index\")\n+    False\n+\n+    If called with an unsupported object (such as unicode) `False` is\n+    returned.\n+\n+    >>> modifies_known_mutable(\"foo\", \"upper\")\n+    False\n+    \"\"\"\n+    for typespec, unsafe in _mutable_spec:\n+        if isinstance(obj, typespec):\n+            return attr in unsafe\n+    return False\n+\n+\n+class SandboxedEnvironment(Environment):\n+    \"\"\"The sandboxed environment.  It works like the regular environment but\n+    tells the compiler to generate sandboxed code.  Additionally subclasses of\n+    this environment may override the methods that tell the runtime what\n+    attributes or functions are safe to access.\n+\n+    If the template tries to access insecure code a :exc:`SecurityError` is\n+    raised.  However also other exceptions may occur during the rendering so\n+    the caller has to ensure that all exceptions are caught.\n+    \"\"\"\n+    sandboxed = True\n+\n+    #: default callback table for the binary operators.  A copy of this is\n+    #: available on each instance of a sandboxed environment as\n+    #: :attr:`binop_table`\n+    default_binop_table = {\n+        '+':        operator.add,\n+        '-':        operator.sub,\n+        '*':        operator.mul,\n+        '/':        operator.truediv,\n+        '//':       operator.floordiv,\n+        '**':       operator.pow,\n+        '%':        operator.mod\n+    }\n+\n+    #: default callback table for the unary operators.  A copy of this is\n+    #: available on each instance of a sandboxed environment as\n+    #: :attr:`unop_table`\n+    default_unop_table = {\n+        '+':        operator.pos,\n+        '-':        operator.neg\n+    }\n+\n+    #: a set of binary operators that should be intercepted.  Each operator\n+    #: that is added to this set (empty by default) is delegated to the\n+    #: :meth:`call_binop` method that will perform the operator.  The default\n+    #: operator callback is specified by :attr:`binop_table`.\n+    #:\n+    #: The following binary operators are interceptable:\n+    #: ``//``, ``%``, ``+``, ``*``, ``-``, ``/``, and ``**``\n+    #:\n+    #: The default operation form the operator table corresponds to the\n+    #: builtin function.  Intercepted calls are always slower than the native\n+    #: operator call, so make sure only to intercept the ones you are\n+    #: interested in.\n+    #:\n+    #: .. versionadded:: 2.6\n+    intercepted_binops = frozenset()\n+\n+    #: a set of unary operators that should be intercepted.  Each operator\n+    #: that is added to this set (empty by default) is delegated to the\n+    #: :meth:`call_unop` method that will perform the operator.  The default\n+    #: operator callback is specified by :attr:`unop_table`.\n+    #:\n+    #: The following unary operators are interceptable: ``+``, ``-``\n+    #:\n+    #: The default operation form the operator table corresponds to the\n+    #: builtin function.  Intercepted calls are always slower than the native\n+    #: operator call, so make sure only to intercept the ones you are\n+    #: interested in.\n+    #:\n+    #: .. versionadded:: 2.6\n+    intercepted_unops = frozenset()\n+\n+    def intercept_unop(self, operator):\n+        \"\"\"Called during template compilation with the name of a unary\n+        operator to check if it should be intercepted at runtime.  If this\n+        method returns `True`, :meth:`call_unop` is excuted for this unary\n+        operator.  The default implementation of :meth:`call_unop` will use\n+        the :attr:`unop_table` dictionary to perform the operator with the\n+        same logic as the builtin one.\n+\n+        The following unary operators are interceptable: ``+`` and ``-``\n+\n+        Intercepted calls are always slower than the native operator call,\n+        so make sure only to intercept the ones you are interested in.\n+\n+        .. versionadded:: 2.6\n+        \"\"\"\n+        return False\n+\n+\n+    def __init__(self, *args, **kwargs):\n+        Environment.__init__(self, *args, **kwargs)\n+        self.globals['range'] = safe_range\n+        self.binop_table = self.default_binop_table.copy()\n+        self.unop_table = self.default_unop_table.copy()\n+\n+    def is_safe_attribute(self, obj, attr, value):\n+        \"\"\"The sandboxed environment will call this method to check if the\n+        attribute of an object is safe to access.  Per default all attributes\n+        starting with an underscore are considered private as well as the\n+        special attributes of internal python objects as returned by the\n+        :func:`is_internal_attribute` function.\n+        \"\"\"\n+        return not (attr.startswith('_') or is_internal_attribute(obj, attr))\n+\n+    def is_safe_callable(self, obj):\n+        \"\"\"Check if an object is safely callable.  Per default a function is\n+        considered safe unless the `unsafe_callable` attribute exists and is\n+        True.  Override this method to alter the behavior, but this won't\n+        affect the `unsafe` decorator from this module.\n+        \"\"\"\n+        return not (getattr(obj, 'unsafe_callable', False) or\n+                    getattr(obj, 'alters_data', False))\n+\n+    def call_binop(self, context, operator, left, right):\n+        \"\"\"For intercepted binary operator calls (:meth:`intercepted_binops`)\n+        this function is executed instead of the builtin operator.  This can\n+        be used to fine tune the behavior of certain operators.\n+\n+        .. versionadded:: 2.6\n+        \"\"\"\n+        return self.binop_table[operator](left, right)\n+\n+    def call_unop(self, context, operator, arg):\n+        \"\"\"For intercepted unary operator calls (:meth:`intercepted_unops`)\n+        this function is executed instead of the builtin operator.  This can\n+        be used to fine tune the behavior of certain operators.\n+\n+        .. versionadded:: 2.6\n+        \"\"\"\n+        return self.unop_table[operator](arg)\n+\n+    def getitem(self, obj, argument):\n+        \"\"\"Subscribe an object from sandboxed code.\"\"\"\n+        try:\n+            return obj[argument]\n+        except (TypeError, LookupError):\n+            if isinstance(argument, string_types):\n+                try:\n+                    attr = str(argument)\n+                except Exception:\n+                    pass\n+                else:\n+                    try:\n+                        value = getattr(obj, attr)\n+                    except AttributeError:\n+                        pass\n+                    else:\n+                        if self.is_safe_attribute(obj, argument, value):\n+                            return value\n+                        return self.unsafe_undefined(obj, argument)\n+        return self.undefined(obj=obj, name=argument)\n+\n+    def getattr(self, obj, attribute):\n+        \"\"\"Subscribe an object from sandboxed code and prefer the\n+        attribute.  The attribute passed *must* be a bytestring.\n+        \"\"\"\n+        try:\n+            value = getattr(obj, attribute)\n+        except AttributeError:\n+            try:\n+                return obj[attribute]\n+            except (TypeError, LookupError):\n+                pass\n+        else:\n+            if self.is_safe_attribute(obj, attribute, value):\n+                return value\n+            return self.unsafe_undefined(obj, attribute)\n+        return self.undefined(obj=obj, name=attribute)\n+\n+    def unsafe_undefined(self, obj, attribute):\n+        \"\"\"Return an undefined object for unsafe attributes.\"\"\"\n+        return self.undefined('access to attribute %r of %r '\n+                              'object is unsafe.' % (\n+            attribute,\n+            obj.__class__.__name__\n+        ), name=attribute, obj=obj, exc=SecurityError)\n+\n+    def format_string(self, s, args, kwargs):\n+        \"\"\"If a format call is detected, then this is routed through this\n+        method so that our safety sandbox can be used for it.\n+        \"\"\"\n+        if isinstance(s, Markup):\n+            formatter = SandboxedEscapeFormatter(self, s.escape)\n+        else:\n+            formatter = SandboxedFormatter(self)\n+        kwargs = _MagicFormatMapping(args, kwargs)\n+        rv = formatter.vformat(s, args, kwargs)\n+        return type(s)(rv)\n+\n+    def call(__self, __context, __obj, *args, **kwargs):\n+        \"\"\"Call an object from sandboxed code.\"\"\"\n+        fmt = inspect_format_method(__obj)\n+        if fmt is not None:\n+            return __self.format_string(fmt, args, kwargs)\n+\n+        # the double prefixes are to avoid double keyword argument\n+        # errors when proxying the call.\n+        if not __self.is_safe_callable(__obj):\n+            raise SecurityError('%r is not safely callable' % (__obj,))\n+        return __context.call(__obj, *args, **kwargs)\n+\n+\n+class ImmutableSandboxedEnvironment(SandboxedEnvironment):\n+    \"\"\"Works exactly like the regular `SandboxedEnvironment` but does not\n+    permit modifications on the builtin mutable objects `list`, `set`, and\n+    `dict` by using the :func:`modifies_known_mutable` function.\n+    \"\"\"\n+\n+    def is_safe_attribute(self, obj, attr, value):\n+        if not SandboxedEnvironment.is_safe_attribute(self, obj, attr, value):\n+            return False\n+        return not modifies_known_mutable(obj, attr)\n+\n+\n+# This really is not a public API apparenlty.\n+try:\n+    from _string import formatter_field_name_split\n+except ImportError:\n+    def formatter_field_name_split(field_name):\n+        return field_name._formatter_field_name_split()\n+\n+\n+class SandboxedFormatterMixin(object):\n+\n+    def __init__(self, env):\n+        self._env = env\n+\n+    def get_field(self, field_name, args, kwargs):\n+        first, rest = formatter_field_name_split(field_name)\n+        obj = self.get_value(first, args, kwargs)\n+        for is_attr, i in rest:\n+            if is_attr:\n+                obj = self._env.getattr(obj, i)\n+            else:\n+                obj = self._env.getitem(obj, i)\n+        return obj, first\n+\n+class SandboxedFormatter(SandboxedFormatterMixin, Formatter):\n+\n+    def __init__(self, env):\n+        SandboxedFormatterMixin.__init__(self, env)\n+        Formatter.__init__(self)\n+\n+class SandboxedEscapeFormatter(SandboxedFormatterMixin, EscapeFormatter):\n+\n+    def __init__(self, env, escape):\n+        SandboxedFormatterMixin.__init__(self, env)\n+        EscapeFormatter.__init__(self, escape)"
        },
        {
            "sha": "0adc3d4dbcbb881910bfd90214534449fafddcb3",
            "filename": "tools/jinja2/tests.py",
            "status": "added",
            "additions": 175,
            "deletions": 0,
            "changes": 175,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Ftests.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Ftests.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Ftests.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,175 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.tests\n+    ~~~~~~~~~~~~\n+\n+    Jinja test functions. Used with the \"is\" operator.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+import operator\n+import re\n+from collections import Mapping\n+from jinja2.runtime import Undefined\n+from jinja2._compat import text_type, string_types, integer_types\n+import decimal\n+\n+number_re = re.compile(r'^-?\\d+(\\.\\d+)?$')\n+regex_type = type(number_re)\n+\n+\n+test_callable = callable\n+\n+\n+def test_odd(value):\n+    \"\"\"Return true if the variable is odd.\"\"\"\n+    return value % 2 == 1\n+\n+\n+def test_even(value):\n+    \"\"\"Return true if the variable is even.\"\"\"\n+    return value % 2 == 0\n+\n+\n+def test_divisibleby(value, num):\n+    \"\"\"Check if a variable is divisible by a number.\"\"\"\n+    return value % num == 0\n+\n+\n+def test_defined(value):\n+    \"\"\"Return true if the variable is defined:\n+\n+    .. sourcecode:: jinja\n+\n+        {% if variable is defined %}\n+            value of variable: {{ variable }}\n+        {% else %}\n+            variable is not defined\n+        {% endif %}\n+\n+    See the :func:`default` filter for a simple way to set undefined\n+    variables.\n+    \"\"\"\n+    return not isinstance(value, Undefined)\n+\n+\n+def test_undefined(value):\n+    \"\"\"Like :func:`defined` but the other way round.\"\"\"\n+    return isinstance(value, Undefined)\n+\n+\n+def test_none(value):\n+    \"\"\"Return true if the variable is none.\"\"\"\n+    return value is None\n+\n+\n+def test_lower(value):\n+    \"\"\"Return true if the variable is lowercased.\"\"\"\n+    return text_type(value).islower()\n+\n+\n+def test_upper(value):\n+    \"\"\"Return true if the variable is uppercased.\"\"\"\n+    return text_type(value).isupper()\n+\n+\n+def test_string(value):\n+    \"\"\"Return true if the object is a string.\"\"\"\n+    return isinstance(value, string_types)\n+\n+\n+def test_mapping(value):\n+    \"\"\"Return true if the object is a mapping (dict etc.).\n+\n+    .. versionadded:: 2.6\n+    \"\"\"\n+    return isinstance(value, Mapping)\n+\n+\n+def test_number(value):\n+    \"\"\"Return true if the variable is a number.\"\"\"\n+    return isinstance(value, integer_types + (float, complex, decimal.Decimal))\n+\n+\n+def test_sequence(value):\n+    \"\"\"Return true if the variable is a sequence. Sequences are variables\n+    that are iterable.\n+    \"\"\"\n+    try:\n+        len(value)\n+        value.__getitem__\n+    except:\n+        return False\n+    return True\n+\n+\n+def test_sameas(value, other):\n+    \"\"\"Check if an object points to the same memory address than another\n+    object:\n+\n+    .. sourcecode:: jinja\n+\n+        {% if foo.attribute is sameas false %}\n+            the foo attribute really is the `False` singleton\n+        {% endif %}\n+    \"\"\"\n+    return value is other\n+\n+\n+def test_iterable(value):\n+    \"\"\"Check if it's possible to iterate over an object.\"\"\"\n+    try:\n+        iter(value)\n+    except TypeError:\n+        return False\n+    return True\n+\n+\n+def test_escaped(value):\n+    \"\"\"Check if the value is escaped.\"\"\"\n+    return hasattr(value, '__html__')\n+\n+\n+def test_in(value, seq):\n+    \"\"\"Check if value is in seq.\n+\n+    .. versionadded:: 2.10\n+    \"\"\"\n+    return value in seq\n+\n+\n+TESTS = {\n+    'odd':              test_odd,\n+    'even':             test_even,\n+    'divisibleby':      test_divisibleby,\n+    'defined':          test_defined,\n+    'undefined':        test_undefined,\n+    'none':             test_none,\n+    'lower':            test_lower,\n+    'upper':            test_upper,\n+    'string':           test_string,\n+    'mapping':          test_mapping,\n+    'number':           test_number,\n+    'sequence':         test_sequence,\n+    'iterable':         test_iterable,\n+    'callable':         test_callable,\n+    'sameas':           test_sameas,\n+    'escaped':          test_escaped,\n+    'in':               test_in,\n+    '==':               operator.eq,\n+    'eq':               operator.eq,\n+    'equalto':          operator.eq,\n+    '!=':               operator.ne,\n+    'ne':               operator.ne,\n+    '>':                operator.gt,\n+    'gt':               operator.gt,\n+    'greaterthan':      operator.gt,\n+    'ge':               operator.ge,\n+    '>=':               operator.ge,\n+    '<':                operator.lt,\n+    'lt':               operator.lt,\n+    'lessthan':         operator.lt,\n+    '<=':               operator.le,\n+    'le':               operator.le,\n+}"
        },
        {
            "sha": "502a311c08e549ac395a02650543e424a6d3e11c",
            "filename": "tools/jinja2/utils.py",
            "status": "added",
            "additions": 647,
            "deletions": 0,
            "changes": 647,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Futils.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Futils.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Futils.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,647 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.utils\n+    ~~~~~~~~~~~~\n+\n+    Utility functions.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+import re\n+import json\n+import errno\n+from collections import deque\n+from threading import Lock\n+from jinja2._compat import text_type, string_types, implements_iterator, \\\n+     url_quote\n+\n+\n+_word_split_re = re.compile(r'(\\s+)')\n+_punctuation_re = re.compile(\n+    '^(?P<lead>(?:%s)*)(?P<middle>.*?)(?P<trail>(?:%s)*)$' % (\n+        '|'.join(map(re.escape, ('(', '<', '&lt;'))),\n+        '|'.join(map(re.escape, ('.', ',', ')', '>', '\\n', '&gt;')))\n+    )\n+)\n+_simple_email_re = re.compile(r'^\\S+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9._-]+$')\n+_striptags_re = re.compile(r'(<!--.*?-->|<[^>]*>)')\n+_entity_re = re.compile(r'&([^;]+);')\n+_letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n+_digits = '0123456789'\n+\n+# special singleton representing missing values for the runtime\n+missing = type('MissingType', (), {'__repr__': lambda x: 'missing'})()\n+\n+# internal code\n+internal_code = set()\n+\n+concat = u''.join\n+\n+_slash_escape = '\\\\/' not in json.dumps('/')\n+\n+\n+def contextfunction(f):\n+    \"\"\"This decorator can be used to mark a function or method context callable.\n+    A context callable is passed the active :class:`Context` as first argument when\n+    called from the template.  This is useful if a function wants to get access\n+    to the context or functions provided on the context object.  For example\n+    a function that returns a sorted list of template variables the current\n+    template exports could look like this::\n+\n+        @contextfunction\n+        def get_exported_names(context):\n+            return sorted(context.exported_vars)\n+    \"\"\"\n+    f.contextfunction = True\n+    return f\n+\n+\n+def evalcontextfunction(f):\n+    \"\"\"This decorator can be used to mark a function or method as an eval\n+    context callable.  This is similar to the :func:`contextfunction`\n+    but instead of passing the context, an evaluation context object is\n+    passed.  For more information about the eval context, see\n+    :ref:`eval-context`.\n+\n+    .. versionadded:: 2.4\n+    \"\"\"\n+    f.evalcontextfunction = True\n+    return f\n+\n+\n+def environmentfunction(f):\n+    \"\"\"This decorator can be used to mark a function or method as environment\n+    callable.  This decorator works exactly like the :func:`contextfunction`\n+    decorator just that the first argument is the active :class:`Environment`\n+    and not context.\n+    \"\"\"\n+    f.environmentfunction = True\n+    return f\n+\n+\n+def internalcode(f):\n+    \"\"\"Marks the function as internally used\"\"\"\n+    internal_code.add(f.__code__)\n+    return f\n+\n+\n+def is_undefined(obj):\n+    \"\"\"Check if the object passed is undefined.  This does nothing more than\n+    performing an instance check against :class:`Undefined` but looks nicer.\n+    This can be used for custom filters or tests that want to react to\n+    undefined variables.  For example a custom default filter can look like\n+    this::\n+\n+        def default(var, default=''):\n+            if is_undefined(var):\n+                return default\n+            return var\n+    \"\"\"\n+    from jinja2.runtime import Undefined\n+    return isinstance(obj, Undefined)\n+\n+\n+def consume(iterable):\n+    \"\"\"Consumes an iterable without doing anything with it.\"\"\"\n+    for event in iterable:\n+        pass\n+\n+\n+def clear_caches():\n+    \"\"\"Jinja2 keeps internal caches for environments and lexers.  These are\n+    used so that Jinja2 doesn't have to recreate environments and lexers all\n+    the time.  Normally you don't have to care about that but if you are\n+    measuring memory consumption you may want to clean the caches.\n+    \"\"\"\n+    from jinja2.environment import _spontaneous_environments\n+    from jinja2.lexer import _lexer_cache\n+    _spontaneous_environments.clear()\n+    _lexer_cache.clear()\n+\n+\n+def import_string(import_name, silent=False):\n+    \"\"\"Imports an object based on a string.  This is useful if you want to\n+    use import paths as endpoints or something similar.  An import path can\n+    be specified either in dotted notation (``xml.sax.saxutils.escape``)\n+    or with a colon as object delimiter (``xml.sax.saxutils:escape``).\n+\n+    If the `silent` is True the return value will be `None` if the import\n+    fails.\n+\n+    :return: imported object\n+    \"\"\"\n+    try:\n+        if ':' in import_name:\n+            module, obj = import_name.split(':', 1)\n+        elif '.' in import_name:\n+            items = import_name.split('.')\n+            module = '.'.join(items[:-1])\n+            obj = items[-1]\n+        else:\n+            return __import__(import_name)\n+        return getattr(__import__(module, None, None, [obj]), obj)\n+    except (ImportError, AttributeError):\n+        if not silent:\n+            raise\n+\n+\n+def open_if_exists(filename, mode='rb'):\n+    \"\"\"Returns a file descriptor for the filename if that file exists,\n+    otherwise `None`.\n+    \"\"\"\n+    try:\n+        return open(filename, mode)\n+    except IOError as e:\n+        if e.errno not in (errno.ENOENT, errno.EISDIR, errno.EINVAL):\n+            raise\n+\n+\n+def object_type_repr(obj):\n+    \"\"\"Returns the name of the object's type.  For some recognized\n+    singletons the name of the object is returned instead. (For\n+    example for `None` and `Ellipsis`).\n+    \"\"\"\n+    if obj is None:\n+        return 'None'\n+    elif obj is Ellipsis:\n+        return 'Ellipsis'\n+    # __builtin__ in 2.x, builtins in 3.x\n+    if obj.__class__.__module__ in ('__builtin__', 'builtins'):\n+        name = obj.__class__.__name__\n+    else:\n+        name = obj.__class__.__module__ + '.' + obj.__class__.__name__\n+    return '%s object' % name\n+\n+\n+def pformat(obj, verbose=False):\n+    \"\"\"Prettyprint an object.  Either use the `pretty` library or the\n+    builtin `pprint`.\n+    \"\"\"\n+    try:\n+        from pretty import pretty\n+        return pretty(obj, verbose=verbose)\n+    except ImportError:\n+        from pprint import pformat\n+        return pformat(obj)\n+\n+\n+def urlize(text, trim_url_limit=None, rel=None, target=None):\n+    \"\"\"Converts any URLs in text into clickable links. Works on http://,\n+    https:// and www. links. Links can have trailing punctuation (periods,\n+    commas, close-parens) and leading punctuation (opening parens) and\n+    it'll still do the right thing.\n+\n+    If trim_url_limit is not None, the URLs in link text will be limited\n+    to trim_url_limit characters.\n+\n+    If nofollow is True, the URLs in link text will get a rel=\"nofollow\"\n+    attribute.\n+\n+    If target is not None, a target attribute will be added to the link.\n+    \"\"\"\n+    trim_url = lambda x, limit=trim_url_limit: limit is not None \\\n+                         and (x[:limit] + (len(x) >=limit and '...'\n+                         or '')) or x\n+    words = _word_split_re.split(text_type(escape(text)))\n+    rel_attr = rel and ' rel=\"%s\"' % text_type(escape(rel)) or ''\n+    target_attr = target and ' target=\"%s\"' % escape(target) or ''\n+\n+    for i, word in enumerate(words):\n+        match = _punctuation_re.match(word)\n+        if match:\n+            lead, middle, trail = match.groups()\n+            if middle.startswith('www.') or (\n+                '@' not in middle and\n+                not middle.startswith('http://') and\n+                not middle.startswith('https://') and\n+                len(middle) > 0 and\n+                middle[0] in _letters + _digits and (\n+                    middle.endswith('.org') or\n+                    middle.endswith('.net') or\n+                    middle.endswith('.com')\n+                )):\n+                middle = '<a href=\"http://%s\"%s%s>%s</a>' % (middle,\n+                    rel_attr, target_attr, trim_url(middle))\n+            if middle.startswith('http://') or \\\n+               middle.startswith('https://'):\n+                middle = '<a href=\"%s\"%s%s>%s</a>' % (middle,\n+                    rel_attr, target_attr, trim_url(middle))\n+            if '@' in middle and not middle.startswith('www.') and \\\n+               not ':' in middle and _simple_email_re.match(middle):\n+                middle = '<a href=\"mailto:%s\">%s</a>' % (middle, middle)\n+            if lead + middle + trail != word:\n+                words[i] = lead + middle + trail\n+    return u''.join(words)\n+\n+\n+def generate_lorem_ipsum(n=5, html=True, min=20, max=100):\n+    \"\"\"Generate some lorem ipsum for the template.\"\"\"\n+    from jinja2.constants import LOREM_IPSUM_WORDS\n+    from random import choice, randrange\n+    words = LOREM_IPSUM_WORDS.split()\n+    result = []\n+\n+    for _ in range(n):\n+        next_capitalized = True\n+        last_comma = last_fullstop = 0\n+        word = None\n+        last = None\n+        p = []\n+\n+        # each paragraph contains out of 20 to 100 words.\n+        for idx, _ in enumerate(range(randrange(min, max))):\n+            while True:\n+                word = choice(words)\n+                if word != last:\n+                    last = word\n+                    break\n+            if next_capitalized:\n+                word = word.capitalize()\n+                next_capitalized = False\n+            # add commas\n+            if idx - randrange(3, 8) > last_comma:\n+                last_comma = idx\n+                last_fullstop += 2\n+                word += ','\n+            # add end of sentences\n+            if idx - randrange(10, 20) > last_fullstop:\n+                last_comma = last_fullstop = idx\n+                word += '.'\n+                next_capitalized = True\n+            p.append(word)\n+\n+        # ensure that the paragraph ends with a dot.\n+        p = u' '.join(p)\n+        if p.endswith(','):\n+            p = p[:-1] + '.'\n+        elif not p.endswith('.'):\n+            p += '.'\n+        result.append(p)\n+\n+    if not html:\n+        return u'\\n\\n'.join(result)\n+    return Markup(u'\\n'.join(u'<p>%s</p>' % escape(x) for x in result))\n+\n+\n+def unicode_urlencode(obj, charset='utf-8', for_qs=False):\n+    \"\"\"URL escapes a single bytestring or unicode string with the\n+    given charset if applicable to URL safe quoting under all rules\n+    that need to be considered under all supported Python versions.\n+\n+    If non strings are provided they are converted to their unicode\n+    representation first.\n+    \"\"\"\n+    if not isinstance(obj, string_types):\n+        obj = text_type(obj)\n+    if isinstance(obj, text_type):\n+        obj = obj.encode(charset)\n+    safe = not for_qs and b'/' or b''\n+    rv = text_type(url_quote(obj, safe))\n+    if for_qs:\n+        rv = rv.replace('%20', '+')\n+    return rv\n+\n+\n+class LRUCache(object):\n+    \"\"\"A simple LRU Cache implementation.\"\"\"\n+\n+    # this is fast for small capacities (something below 1000) but doesn't\n+    # scale.  But as long as it's only used as storage for templates this\n+    # won't do any harm.\n+\n+    def __init__(self, capacity):\n+        self.capacity = capacity\n+        self._mapping = {}\n+        self._queue = deque()\n+        self._postinit()\n+\n+    def _postinit(self):\n+        # alias all queue methods for faster lookup\n+        self._popleft = self._queue.popleft\n+        self._pop = self._queue.pop\n+        self._remove = self._queue.remove\n+        self._wlock = Lock()\n+        self._append = self._queue.append\n+\n+    def __getstate__(self):\n+        return {\n+            'capacity':     self.capacity,\n+            '_mapping':     self._mapping,\n+            '_queue':       self._queue\n+        }\n+\n+    def __setstate__(self, d):\n+        self.__dict__.update(d)\n+        self._postinit()\n+\n+    def __getnewargs__(self):\n+        return (self.capacity,)\n+\n+    def copy(self):\n+        \"\"\"Return a shallow copy of the instance.\"\"\"\n+        rv = self.__class__(self.capacity)\n+        rv._mapping.update(self._mapping)\n+        rv._queue = deque(self._queue)\n+        return rv\n+\n+    def get(self, key, default=None):\n+        \"\"\"Return an item from the cache dict or `default`\"\"\"\n+        try:\n+            return self[key]\n+        except KeyError:\n+            return default\n+\n+    def setdefault(self, key, default=None):\n+        \"\"\"Set `default` if the key is not in the cache otherwise\n+        leave unchanged. Return the value of this key.\n+        \"\"\"\n+        self._wlock.acquire()\n+        try:\n+            try:\n+                return self[key]\n+            except KeyError:\n+                self[key] = default\n+                return default\n+        finally:\n+            self._wlock.release()\n+\n+    def clear(self):\n+        \"\"\"Clear the cache.\"\"\"\n+        self._wlock.acquire()\n+        try:\n+            self._mapping.clear()\n+            self._queue.clear()\n+        finally:\n+            self._wlock.release()\n+\n+    def __contains__(self, key):\n+        \"\"\"Check if a key exists in this cache.\"\"\"\n+        return key in self._mapping\n+\n+    def __len__(self):\n+        \"\"\"Return the current size of the cache.\"\"\"\n+        return len(self._mapping)\n+\n+    def __repr__(self):\n+        return '<%s %r>' % (\n+            self.__class__.__name__,\n+            self._mapping\n+        )\n+\n+    def __getitem__(self, key):\n+        \"\"\"Get an item from the cache. Moves the item up so that it has the\n+        highest priority then.\n+\n+        Raise a `KeyError` if it does not exist.\n+        \"\"\"\n+        self._wlock.acquire()\n+        try:\n+            rv = self._mapping[key]\n+            if self._queue[-1] != key:\n+                try:\n+                    self._remove(key)\n+                except ValueError:\n+                    # if something removed the key from the container\n+                    # when we read, ignore the ValueError that we would\n+                    # get otherwise.\n+                    pass\n+                self._append(key)\n+            return rv\n+        finally:\n+            self._wlock.release()\n+\n+    def __setitem__(self, key, value):\n+        \"\"\"Sets the value for an item. Moves the item up so that it\n+        has the highest priority then.\n+        \"\"\"\n+        self._wlock.acquire()\n+        try:\n+            if key in self._mapping:\n+                self._remove(key)\n+            elif len(self._mapping) == self.capacity:\n+                del self._mapping[self._popleft()]\n+            self._append(key)\n+            self._mapping[key] = value\n+        finally:\n+            self._wlock.release()\n+\n+    def __delitem__(self, key):\n+        \"\"\"Remove an item from the cache dict.\n+        Raise a `KeyError` if it does not exist.\n+        \"\"\"\n+        self._wlock.acquire()\n+        try:\n+            del self._mapping[key]\n+            try:\n+                self._remove(key)\n+            except ValueError:\n+                # __getitem__ is not locked, it might happen\n+                pass\n+        finally:\n+            self._wlock.release()\n+\n+    def items(self):\n+        \"\"\"Return a list of items.\"\"\"\n+        result = [(key, self._mapping[key]) for key in list(self._queue)]\n+        result.reverse()\n+        return result\n+\n+    def iteritems(self):\n+        \"\"\"Iterate over all items.\"\"\"\n+        return iter(self.items())\n+\n+    def values(self):\n+        \"\"\"Return a list of all values.\"\"\"\n+        return [x[1] for x in self.items()]\n+\n+    def itervalue(self):\n+        \"\"\"Iterate over all values.\"\"\"\n+        return iter(self.values())\n+\n+    def keys(self):\n+        \"\"\"Return a list of all keys ordered by most recent usage.\"\"\"\n+        return list(self)\n+\n+    def iterkeys(self):\n+        \"\"\"Iterate over all keys in the cache dict, ordered by\n+        the most recent usage.\n+        \"\"\"\n+        return reversed(tuple(self._queue))\n+\n+    __iter__ = iterkeys\n+\n+    def __reversed__(self):\n+        \"\"\"Iterate over the values in the cache dict, oldest items\n+        coming first.\n+        \"\"\"\n+        return iter(tuple(self._queue))\n+\n+    __copy__ = copy\n+\n+\n+# register the LRU cache as mutable mapping if possible\n+try:\n+    from collections import MutableMapping\n+    MutableMapping.register(LRUCache)\n+except ImportError:\n+    pass\n+\n+\n+def select_autoescape(enabled_extensions=('html', 'htm', 'xml'),\n+                      disabled_extensions=(),\n+                      default_for_string=True,\n+                      default=False):\n+    \"\"\"Intelligently sets the initial value of autoescaping based on the\n+    filename of the template.  This is the recommended way to configure\n+    autoescaping if you do not want to write a custom function yourself.\n+\n+    If you want to enable it for all templates created from strings or\n+    for all templates with `.html` and `.xml` extensions::\n+\n+        from jinja2 import Environment, select_autoescape\n+        env = Environment(autoescape=select_autoescape(\n+            enabled_extensions=('html', 'xml'),\n+            default_for_string=True,\n+        ))\n+\n+    Example configuration to turn it on at all times except if the template\n+    ends with `.txt`::\n+\n+        from jinja2 import Environment, select_autoescape\n+        env = Environment(autoescape=select_autoescape(\n+            disabled_extensions=('txt',),\n+            default_for_string=True,\n+            default=True,\n+        ))\n+\n+    The `enabled_extensions` is an iterable of all the extensions that\n+    autoescaping should be enabled for.  Likewise `disabled_extensions` is\n+    a list of all templates it should be disabled for.  If a template is\n+    loaded from a string then the default from `default_for_string` is used.\n+    If nothing matches then the initial value of autoescaping is set to the\n+    value of `default`.\n+\n+    For security reasons this function operates case insensitive.\n+\n+    .. versionadded:: 2.9\n+    \"\"\"\n+    enabled_patterns = tuple('.' + x.lstrip('.').lower()\n+                             for x in enabled_extensions)\n+    disabled_patterns = tuple('.' + x.lstrip('.').lower()\n+                              for x in disabled_extensions)\n+    def autoescape(template_name):\n+        if template_name is None:\n+            return default_for_string\n+        template_name = template_name.lower()\n+        if template_name.endswith(enabled_patterns):\n+            return True\n+        if template_name.endswith(disabled_patterns):\n+            return False\n+        return default\n+    return autoescape\n+\n+\n+def htmlsafe_json_dumps(obj, dumper=None, **kwargs):\n+    \"\"\"Works exactly like :func:`dumps` but is safe for use in ``<script>``\n+    tags.  It accepts the same arguments and returns a JSON string.  Note that\n+    this is available in templates through the ``|tojson`` filter which will\n+    also mark the result as safe.  Due to how this function escapes certain\n+    characters this is safe even if used outside of ``<script>`` tags.\n+\n+    The following characters are escaped in strings:\n+\n+    -   ``<``\n+    -   ``>``\n+    -   ``&``\n+    -   ``'``\n+\n+    This makes it safe to embed such strings in any place in HTML with the\n+    notable exception of double quoted attributes.  In that case single\n+    quote your attributes or HTML escape it in addition.\n+    \"\"\"\n+    if dumper is None:\n+        dumper = json.dumps\n+    rv = dumper(obj, **kwargs) \\\n+        .replace(u'<', u'\\\\u003c') \\\n+        .replace(u'>', u'\\\\u003e') \\\n+        .replace(u'&', u'\\\\u0026') \\\n+        .replace(u\"'\", u'\\\\u0027')\n+    return Markup(rv)\n+\n+\n+@implements_iterator\n+class Cycler(object):\n+    \"\"\"A cycle helper for templates.\"\"\"\n+\n+    def __init__(self, *items):\n+        if not items:\n+            raise RuntimeError('at least one item has to be provided')\n+        self.items = items\n+        self.reset()\n+\n+    def reset(self):\n+        \"\"\"Resets the cycle.\"\"\"\n+        self.pos = 0\n+\n+    @property\n+    def current(self):\n+        \"\"\"Returns the current item.\"\"\"\n+        return self.items[self.pos]\n+\n+    def next(self):\n+        \"\"\"Goes one item ahead and returns it.\"\"\"\n+        rv = self.current\n+        self.pos = (self.pos + 1) % len(self.items)\n+        return rv\n+\n+    __next__ = next\n+\n+\n+class Joiner(object):\n+    \"\"\"A joining helper for templates.\"\"\"\n+\n+    def __init__(self, sep=u', '):\n+        self.sep = sep\n+        self.used = False\n+\n+    def __call__(self):\n+        if not self.used:\n+            self.used = True\n+            return u''\n+        return self.sep\n+\n+\n+class Namespace(object):\n+    \"\"\"A namespace object that can hold arbitrary attributes.  It may be\n+    initialized from a dictionary or with keyword argments.\"\"\"\n+\n+    def __init__(*args, **kwargs):\n+        self, args = args[0], args[1:]\n+        self.__attrs = dict(*args, **kwargs)\n+\n+    def __getattribute__(self, name):\n+        if name == '_Namespace__attrs':\n+            return object.__getattribute__(self, name)\n+        try:\n+            return self.__attrs[name]\n+        except KeyError:\n+            raise AttributeError(name)\n+\n+    def __setitem__(self, name, value):\n+        self.__attrs[name] = value\n+\n+    def __repr__(self):\n+        return '<Namespace %r>' % self.__attrs\n+\n+\n+# does this python version support async for in and async generators?\n+try:\n+    exec('async def _():\\n async for _ in ():\\n  yield _')\n+    have_async_gen = True\n+except SyntaxError:\n+    have_async_gen = False\n+\n+\n+# Imported here because that's where it was in the past\n+from markupsafe import Markup, escape, soft_unicode"
        },
        {
            "sha": "ba526dfac9283e02593950fe58a843a3d2083bdd",
            "filename": "tools/jinja2/visitor.py",
            "status": "added",
            "additions": 87,
            "deletions": 0,
            "changes": 87,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fvisitor.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fjinja2%2Fvisitor.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fjinja2%2Fvisitor.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,87 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    jinja2.visitor\n+    ~~~~~~~~~~~~~~\n+\n+    This module implements a visitor for the nodes.\n+\n+    :copyright: (c) 2017 by the Jinja Team.\n+    :license: BSD.\n+\"\"\"\n+from jinja2.nodes import Node\n+\n+\n+class NodeVisitor(object):\n+    \"\"\"Walks the abstract syntax tree and call visitor functions for every\n+    node found.  The visitor functions may return values which will be\n+    forwarded by the `visit` method.\n+\n+    Per default the visitor functions for the nodes are ``'visit_'`` +\n+    class name of the node.  So a `TryFinally` node visit function would\n+    be `visit_TryFinally`.  This behavior can be changed by overriding\n+    the `get_visitor` function.  If no visitor function exists for a node\n+    (return value `None`) the `generic_visit` visitor is used instead.\n+    \"\"\"\n+\n+    def get_visitor(self, node):\n+        \"\"\"Return the visitor function for this node or `None` if no visitor\n+        exists for this node.  In that case the generic visit function is\n+        used instead.\n+        \"\"\"\n+        method = 'visit_' + node.__class__.__name__\n+        return getattr(self, method, None)\n+\n+    def visit(self, node, *args, **kwargs):\n+        \"\"\"Visit a node.\"\"\"\n+        f = self.get_visitor(node)\n+        if f is not None:\n+            return f(node, *args, **kwargs)\n+        return self.generic_visit(node, *args, **kwargs)\n+\n+    def generic_visit(self, node, *args, **kwargs):\n+        \"\"\"Called if no explicit visitor function exists for a node.\"\"\"\n+        for node in node.iter_child_nodes():\n+            self.visit(node, *args, **kwargs)\n+\n+\n+class NodeTransformer(NodeVisitor):\n+    \"\"\"Walks the abstract syntax tree and allows modifications of nodes.\n+\n+    The `NodeTransformer` will walk the AST and use the return value of the\n+    visitor functions to replace or remove the old node.  If the return\n+    value of the visitor function is `None` the node will be removed\n+    from the previous location otherwise it's replaced with the return\n+    value.  The return value may be the original node in which case no\n+    replacement takes place.\n+    \"\"\"\n+\n+    def generic_visit(self, node, *args, **kwargs):\n+        for field, old_value in node.iter_fields():\n+            if isinstance(old_value, list):\n+                new_values = []\n+                for value in old_value:\n+                    if isinstance(value, Node):\n+                        value = self.visit(value, *args, **kwargs)\n+                        if value is None:\n+                            continue\n+                        elif not isinstance(value, Node):\n+                            new_values.extend(value)\n+                            continue\n+                    new_values.append(value)\n+                old_value[:] = new_values\n+            elif isinstance(old_value, Node):\n+                new_node = self.visit(old_value, *args, **kwargs)\n+                if new_node is None:\n+                    delattr(node, field)\n+                else:\n+                    setattr(node, field, new_node)\n+        return node\n+\n+    def visit_list(self, node, *args, **kwargs):\n+        \"\"\"As transformers may return lists in some places this method\n+        can be used to enforce a list as return value.\n+        \"\"\"\n+        rv = self.visit(node, *args, **kwargs)\n+        if not isinstance(rv, list):\n+            rv = [rv]\n+        return rv"
        },
        {
            "sha": "1dc9b5ca7d01f6bca2fef101cc473b7cf81b7a35",
            "filename": "tools/license-builder.sh",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Flicense-builder.sh",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Flicense-builder.sh",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Flicense-builder.sh?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -71,6 +71,9 @@ addlicense \"npm\" \"deps/npm\" \"$(cat ${rootdir}/deps/npm/LICENSE)\"\n \n # Build tools\n addlicense \"GYP\" \"tools/gyp\" \"$(cat ${rootdir}/tools/gyp/LICENSE)\"\n+addlicense \"inspector_protocol\" \"tools/inspector_protocol\" \"$(cat ${rootdir}/tools/inspector_protocol/LICENSE)\"\n+addlicense \"jinja2\" \"tools/jinja2\" \"$(cat ${rootdir}/tools/jinja2/LICENSE)\"\n+addlicense \"markupsafe\" \"tools/markupsafe\" \"$(cat ${rootdir}/tools/markupsafe/LICENSE)\"\n \n # Testing tools\n addlicense \"cpplint.py\" \"tools/cpplint.py\" \\"
        },
        {
            "sha": "f7e2942eccd11ed7d5f3d567639e1607d29299d2",
            "filename": "tools/markupsafe/AUTHORS",
            "status": "added",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FAUTHORS",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FAUTHORS",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2FAUTHORS?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,13 @@\n+MarkupSafe is written and maintained by Armin Ronacher and\n+various contributors:\n+\n+Development Lead\n+````````````````\n+\n+- Armin Ronacher <armin.ronacher@active-4.com>\n+\n+Patches and Suggestions\n+```````````````````````\n+\n+- Georg Brandl\n+- Mickal Gurin"
        },
        {
            "sha": "5d2693890dddc34129973f5613afd88767213b24",
            "filename": "tools/markupsafe/LICENSE",
            "status": "added",
            "additions": 33,
            "deletions": 0,
            "changes": 33,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FLICENSE",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FLICENSE",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2FLICENSE?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,33 @@\n+Copyright (c) 2010 by Armin Ronacher and contributors.  See AUTHORS\n+for more details.\n+\n+Some rights reserved.\n+\n+Redistribution and use in source and binary forms of the software as well\n+as documentation, with or without modification, are permitted provided\n+that the following conditions are met:\n+\n+* Redistributions of source code must retain the above copyright\n+  notice, this list of conditions and the following disclaimer.\n+\n+* Redistributions in binary form must reproduce the above\n+  copyright notice, this list of conditions and the following\n+  disclaimer in the documentation and/or other materials provided\n+  with the distribution.\n+\n+* The names of the contributors may not be used to endorse or\n+  promote products derived from this software without specific\n+  prior written permission.\n+\n+THIS SOFTWARE AND DOCUMENTATION IS PROVIDED BY THE COPYRIGHT HOLDERS AND\n+CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT\n+NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER\n+OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n+EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n+PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n+PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n+SOFTWARE AND DOCUMENTATION, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH\n+DAMAGE."
        },
        {
            "sha": "1348d1eea1fb9035ed8b88898eec2b793b9bcb50",
            "filename": "tools/markupsafe/MarkupSafe-0.18.tar.gz.md5",
            "status": "added",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FMarkupSafe-0.18.tar.gz.md5",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FMarkupSafe-0.18.tar.gz.md5",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2FMarkupSafe-0.18.tar.gz.md5?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1 @@\n+f8d252fd05371e51dec2fe9a36890687  MarkupSafe-0.18.tar.gz"
        },
        {
            "sha": "ab752200d5fcb41f01eb3cf10676e3382db8f7ef",
            "filename": "tools/markupsafe/MarkupSafe-0.18.tar.gz.sha512",
            "status": "added",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FMarkupSafe-0.18.tar.gz.sha512",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FMarkupSafe-0.18.tar.gz.sha512",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2FMarkupSafe-0.18.tar.gz.sha512?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1 @@\n+0438ddf0fdab465c40d9afba8c14ad346be0868df654c11130d05e329992d456a9bc278551970cbd09244a29c77213885d0c363c951b0cfd4d9aa95b248ecff5  MarkupSafe-0.18.tar.gz"
        },
        {
            "sha": "6a57e5dc3fed35a7daec6eeb2a9dec4d596bed40",
            "filename": "tools/markupsafe/OWNERS",
            "status": "added",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FOWNERS",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FOWNERS",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2FOWNERS?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,5 @@\n+timloh@chromium.org\n+haraken@chromium.org\n+nbarth@chromium.org\n+\n+# COMPONENT: Internals"
        },
        {
            "sha": "0fcab52fa2b41cb943d62f8e6f9bfd9cc0e5f72c",
            "filename": "tools/markupsafe/README.chromium",
            "status": "added",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FREADME.chromium",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2FREADME.chromium",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2FREADME.chromium?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,24 @@\n+Name: MarkupSafe Python Safe String Class\n+Short Name: markupsafe\n+URL: https://github.com/mitsuhiko/markupsafe\n+Version: 0.18\n+License: BSD 3-clause License\n+License File: NOT_SHIPPED\n+Security Critical: no\n+\n+Description:\n+Safe string class, used by Jinja2 template engine.\n+\n+Source:\n+https://pypi.python.org/packages/source/M/MarkupSafe/MarkupSafe-0.18.tar.gz\n+MD5: f8d252fd05371e51dec2fe9a36890687\n+SHA-512: 0438ddf0fdab465c40d9afba8c14ad346be0868df654c11130d05e329992d456\n+         a9bc278551970cbd09244a29c77213885d0c363c951b0cfd4d9aa95b248ecff5\n+\n+Local Modifications:\n+This only includes the markup directory from the tarball and the LICENSE and\n+AUTHORS files, removing the unneeded unit tests (tests.py).\n+Also includes install script (get_markupsafe.sh) and files of hashes (MD5 is\n+also posted on website, SHA-512 computed locally); script checks hash then\n+unpacks archive and installs desired files.\n+Retrieve or update by executing markupsafe/get_markupsafe.sh from third_party."
        },
        {
            "sha": "e8b4b453c148a899d94d81fdd76ef2ca0bdabf69",
            "filename": "tools/markupsafe/__init__.py",
            "status": "added",
            "additions": 234,
            "deletions": 0,
            "changes": 234,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2F__init__.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2F__init__.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2F__init__.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,234 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    markupsafe\n+    ~~~~~~~~~~\n+\n+    Implements a Markup string.\n+\n+    :copyright: (c) 2010 by Armin Ronacher.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+import re\n+from markupsafe._compat import text_type, string_types, int_types, \\\n+     unichr, PY2\n+\n+\n+__all__ = ['Markup', 'soft_unicode', 'escape', 'escape_silent']\n+\n+\n+_striptags_re = re.compile(r'(<!--.*?-->|<[^>]*>)')\n+_entity_re = re.compile(r'&([^;]+);')\n+\n+\n+class Markup(text_type):\n+    r\"\"\"Marks a string as being safe for inclusion in HTML/XML output without\n+    needing to be escaped.  This implements the `__html__` interface a couple\n+    of frameworks and web applications use.  :class:`Markup` is a direct\n+    subclass of `unicode` and provides all the methods of `unicode` just that\n+    it escapes arguments passed and always returns `Markup`.\n+\n+    The `escape` function returns markup objects so that double escaping can't\n+    happen.\n+\n+    The constructor of the :class:`Markup` class can be used for three\n+    different things:  When passed an unicode object it's assumed to be safe,\n+    when passed an object with an HTML representation (has an `__html__`\n+    method) that representation is used, otherwise the object passed is\n+    converted into a unicode string and then assumed to be safe:\n+\n+    >>> Markup(\"Hello <em>World</em>!\")\n+    Markup(u'Hello <em>World</em>!')\n+    >>> class Foo(object):\n+    ...  def __html__(self):\n+    ...   return '<a href=\"#\">foo</a>'\n+    ...\n+    >>> Markup(Foo())\n+    Markup(u'<a href=\"#\">foo</a>')\n+\n+    If you want object passed being always treated as unsafe you can use the\n+    :meth:`escape` classmethod to create a :class:`Markup` object:\n+\n+    >>> Markup.escape(\"Hello <em>World</em>!\")\n+    Markup(u'Hello &lt;em&gt;World&lt;/em&gt;!')\n+\n+    Operations on a markup string are markup aware which means that all\n+    arguments are passed through the :func:`escape` function:\n+\n+    >>> em = Markup(\"<em>%s</em>\")\n+    >>> em % \"foo & bar\"\n+    Markup(u'<em>foo &amp; bar</em>')\n+    >>> strong = Markup(\"<strong>%(text)s</strong>\")\n+    >>> strong % {'text': '<blink>hacker here</blink>'}\n+    Markup(u'<strong>&lt;blink&gt;hacker here&lt;/blink&gt;</strong>')\n+    >>> Markup(\"<em>Hello</em> \") + \"<foo>\"\n+    Markup(u'<em>Hello</em> &lt;foo&gt;')\n+    \"\"\"\n+    __slots__ = ()\n+\n+    def __new__(cls, base=u'', encoding=None, errors='strict'):\n+        if hasattr(base, '__html__'):\n+            base = base.__html__()\n+        if encoding is None:\n+            return text_type.__new__(cls, base)\n+        return text_type.__new__(cls, base, encoding, errors)\n+\n+    def __html__(self):\n+        return self\n+\n+    def __add__(self, other):\n+        if isinstance(other, string_types) or hasattr(other, '__html__'):\n+            return self.__class__(super(Markup, self).__add__(self.escape(other)))\n+        return NotImplemented\n+\n+    def __radd__(self, other):\n+        if hasattr(other, '__html__') or isinstance(other, string_types):\n+            return self.escape(other).__add__(self)\n+        return NotImplemented\n+\n+    def __mul__(self, num):\n+        if isinstance(num, int_types):\n+            return self.__class__(text_type.__mul__(self, num))\n+        return NotImplemented\n+    __rmul__ = __mul__\n+\n+    def __mod__(self, arg):\n+        if isinstance(arg, tuple):\n+            arg = tuple(_MarkupEscapeHelper(x, self.escape) for x in arg)\n+        else:\n+            arg = _MarkupEscapeHelper(arg, self.escape)\n+        return self.__class__(text_type.__mod__(self, arg))\n+\n+    def __repr__(self):\n+        return '%s(%s)' % (\n+            self.__class__.__name__,\n+            text_type.__repr__(self)\n+        )\n+\n+    def join(self, seq):\n+        return self.__class__(text_type.join(self, map(self.escape, seq)))\n+    join.__doc__ = text_type.join.__doc__\n+\n+    def split(self, *args, **kwargs):\n+        return list(map(self.__class__, text_type.split(self, *args, **kwargs)))\n+    split.__doc__ = text_type.split.__doc__\n+\n+    def rsplit(self, *args, **kwargs):\n+        return list(map(self.__class__, text_type.rsplit(self, *args, **kwargs)))\n+    rsplit.__doc__ = text_type.rsplit.__doc__\n+\n+    def splitlines(self, *args, **kwargs):\n+        return list(map(self.__class__, text_type.splitlines(self, *args, **kwargs)))\n+    splitlines.__doc__ = text_type.splitlines.__doc__\n+\n+    def unescape(self):\n+        r\"\"\"Unescape markup again into an text_type string.  This also resolves\n+        known HTML4 and XHTML entities:\n+\n+        >>> Markup(\"Main &raquo; <em>About</em>\").unescape()\n+        u'Main \\xbb <em>About</em>'\n+        \"\"\"\n+        from markupsafe._constants import HTML_ENTITIES\n+        def handle_match(m):\n+            name = m.group(1)\n+            if name in HTML_ENTITIES:\n+                return unichr(HTML_ENTITIES[name])\n+            try:\n+                if name[:2] in ('#x', '#X'):\n+                    return unichr(int(name[2:], 16))\n+                elif name.startswith('#'):\n+                    return unichr(int(name[1:]))\n+            except ValueError:\n+                pass\n+            return u''\n+        return _entity_re.sub(handle_match, text_type(self))\n+\n+    def striptags(self):\n+        r\"\"\"Unescape markup into an text_type string and strip all tags.  This\n+        also resolves known HTML4 and XHTML entities.  Whitespace is\n+        normalized to one:\n+\n+        >>> Markup(\"Main &raquo;  <em>About</em>\").striptags()\n+        u'Main \\xbb About'\n+        \"\"\"\n+        stripped = u' '.join(_striptags_re.sub('', self).split())\n+        return Markup(stripped).unescape()\n+\n+    @classmethod\n+    def escape(cls, s):\n+        \"\"\"Escape the string.  Works like :func:`escape` with the difference\n+        that for subclasses of :class:`Markup` this function would return the\n+        correct subclass.\n+        \"\"\"\n+        rv = escape(s)\n+        if rv.__class__ is not cls:\n+            return cls(rv)\n+        return rv\n+\n+    def make_wrapper(name):\n+        orig = getattr(text_type, name)\n+        def func(self, *args, **kwargs):\n+            args = _escape_argspec(list(args), enumerate(args), self.escape)\n+            #_escape_argspec(kwargs, kwargs.iteritems(), None)\n+            return self.__class__(orig(self, *args, **kwargs))\n+        func.__name__ = orig.__name__\n+        func.__doc__ = orig.__doc__\n+        return func\n+\n+    for method in '__getitem__', 'capitalize', \\\n+                  'title', 'lower', 'upper', 'replace', 'ljust', \\\n+                  'rjust', 'lstrip', 'rstrip', 'center', 'strip', \\\n+                  'translate', 'expandtabs', 'swapcase', 'zfill':\n+        locals()[method] = make_wrapper(method)\n+\n+    # new in python 2.5\n+    if hasattr(text_type, 'partition'):\n+        def partition(self, sep):\n+            return tuple(map(self.__class__,\n+                             text_type.partition(self, self.escape(sep))))\n+        def rpartition(self, sep):\n+            return tuple(map(self.__class__,\n+                             text_type.rpartition(self, self.escape(sep))))\n+\n+    # new in python 2.6\n+    if hasattr(text_type, 'format'):\n+        format = make_wrapper('format')\n+\n+    # not in python 3\n+    if hasattr(text_type, '__getslice__'):\n+        __getslice__ = make_wrapper('__getslice__')\n+\n+    del method, make_wrapper\n+\n+\n+def _escape_argspec(obj, iterable, escape):\n+    \"\"\"Helper for various string-wrapped functions.\"\"\"\n+    for key, value in iterable:\n+        if hasattr(value, '__html__') or isinstance(value, string_types):\n+            obj[key] = escape(value)\n+    return obj\n+\n+\n+class _MarkupEscapeHelper(object):\n+    \"\"\"Helper for Markup.__mod__\"\"\"\n+\n+    def __init__(self, obj, escape):\n+        self.obj = obj\n+        self.escape = escape\n+\n+    __getitem__ = lambda s, x: _MarkupEscapeHelper(s.obj[x], s.escape)\n+    __unicode__ = __str__ = lambda s: text_type(s.escape(s.obj))\n+    __repr__ = lambda s: str(s.escape(repr(s.obj)))\n+    __int__ = lambda s: int(s.obj)\n+    __float__ = lambda s: float(s.obj)\n+\n+\n+# we have to import it down here as the speedups and native\n+# modules imports the markup type which is define above.\n+try:\n+    from markupsafe._speedups import escape, escape_silent, soft_unicode\n+except ImportError:\n+    from markupsafe._native import escape, escape_silent, soft_unicode\n+\n+if not PY2:\n+    soft_str = soft_unicode\n+    __all__.append('soft_str')"
        },
        {
            "sha": "29e4a3dac13f28e9c1a72792ccae83a03ed193d6",
            "filename": "tools/markupsafe/_compat.py",
            "status": "added",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2F_compat.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2F_compat.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2F_compat.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,24 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    markupsafe._compat\n+    ~~~~~~~~~~~~~~~~~~\n+\n+    Compatibility module for different Python versions.\n+\n+    :copyright: (c) 2013 by Armin Ronacher.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+import sys\n+\n+PY2 = sys.version_info[0] == 2\n+\n+if not PY2:\n+    text_type = str\n+    string_types = (str,)\n+    unichr = chr\n+    int_types = (int,)\n+else:\n+    text_type = unicode\n+    string_types = (str, unicode)\n+    unichr = unichr\n+    int_types = (int, long)"
        },
        {
            "sha": "919bf03c5092e557b164e7e2322b12ed74d349fb",
            "filename": "tools/markupsafe/_constants.py",
            "status": "added",
            "additions": 267,
            "deletions": 0,
            "changes": 267,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2F_constants.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2F_constants.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2F_constants.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,267 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    markupsafe._constants\n+    ~~~~~~~~~~~~~~~~~~~~~\n+\n+    Highlevel implementation of the Markup string.\n+\n+    :copyright: (c) 2010 by Armin Ronacher.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+\n+\n+HTML_ENTITIES = {\n+    'AElig': 198,\n+    'Aacute': 193,\n+    'Acirc': 194,\n+    'Agrave': 192,\n+    'Alpha': 913,\n+    'Aring': 197,\n+    'Atilde': 195,\n+    'Auml': 196,\n+    'Beta': 914,\n+    'Ccedil': 199,\n+    'Chi': 935,\n+    'Dagger': 8225,\n+    'Delta': 916,\n+    'ETH': 208,\n+    'Eacute': 201,\n+    'Ecirc': 202,\n+    'Egrave': 200,\n+    'Epsilon': 917,\n+    'Eta': 919,\n+    'Euml': 203,\n+    'Gamma': 915,\n+    'Iacute': 205,\n+    'Icirc': 206,\n+    'Igrave': 204,\n+    'Iota': 921,\n+    'Iuml': 207,\n+    'Kappa': 922,\n+    'Lambda': 923,\n+    'Mu': 924,\n+    'Ntilde': 209,\n+    'Nu': 925,\n+    'OElig': 338,\n+    'Oacute': 211,\n+    'Ocirc': 212,\n+    'Ograve': 210,\n+    'Omega': 937,\n+    'Omicron': 927,\n+    'Oslash': 216,\n+    'Otilde': 213,\n+    'Ouml': 214,\n+    'Phi': 934,\n+    'Pi': 928,\n+    'Prime': 8243,\n+    'Psi': 936,\n+    'Rho': 929,\n+    'Scaron': 352,\n+    'Sigma': 931,\n+    'THORN': 222,\n+    'Tau': 932,\n+    'Theta': 920,\n+    'Uacute': 218,\n+    'Ucirc': 219,\n+    'Ugrave': 217,\n+    'Upsilon': 933,\n+    'Uuml': 220,\n+    'Xi': 926,\n+    'Yacute': 221,\n+    'Yuml': 376,\n+    'Zeta': 918,\n+    'aacute': 225,\n+    'acirc': 226,\n+    'acute': 180,\n+    'aelig': 230,\n+    'agrave': 224,\n+    'alefsym': 8501,\n+    'alpha': 945,\n+    'amp': 38,\n+    'and': 8743,\n+    'ang': 8736,\n+    'apos': 39,\n+    'aring': 229,\n+    'asymp': 8776,\n+    'atilde': 227,\n+    'auml': 228,\n+    'bdquo': 8222,\n+    'beta': 946,\n+    'brvbar': 166,\n+    'bull': 8226,\n+    'cap': 8745,\n+    'ccedil': 231,\n+    'cedil': 184,\n+    'cent': 162,\n+    'chi': 967,\n+    'circ': 710,\n+    'clubs': 9827,\n+    'cong': 8773,\n+    'copy': 169,\n+    'crarr': 8629,\n+    'cup': 8746,\n+    'curren': 164,\n+    'dArr': 8659,\n+    'dagger': 8224,\n+    'darr': 8595,\n+    'deg': 176,\n+    'delta': 948,\n+    'diams': 9830,\n+    'divide': 247,\n+    'eacute': 233,\n+    'ecirc': 234,\n+    'egrave': 232,\n+    'empty': 8709,\n+    'emsp': 8195,\n+    'ensp': 8194,\n+    'epsilon': 949,\n+    'equiv': 8801,\n+    'eta': 951,\n+    'eth': 240,\n+    'euml': 235,\n+    'euro': 8364,\n+    'exist': 8707,\n+    'fnof': 402,\n+    'forall': 8704,\n+    'frac12': 189,\n+    'frac14': 188,\n+    'frac34': 190,\n+    'frasl': 8260,\n+    'gamma': 947,\n+    'ge': 8805,\n+    'gt': 62,\n+    'hArr': 8660,\n+    'harr': 8596,\n+    'hearts': 9829,\n+    'hellip': 8230,\n+    'iacute': 237,\n+    'icirc': 238,\n+    'iexcl': 161,\n+    'igrave': 236,\n+    'image': 8465,\n+    'infin': 8734,\n+    'int': 8747,\n+    'iota': 953,\n+    'iquest': 191,\n+    'isin': 8712,\n+    'iuml': 239,\n+    'kappa': 954,\n+    'lArr': 8656,\n+    'lambda': 955,\n+    'lang': 9001,\n+    'laquo': 171,\n+    'larr': 8592,\n+    'lceil': 8968,\n+    'ldquo': 8220,\n+    'le': 8804,\n+    'lfloor': 8970,\n+    'lowast': 8727,\n+    'loz': 9674,\n+    'lrm': 8206,\n+    'lsaquo': 8249,\n+    'lsquo': 8216,\n+    'lt': 60,\n+    'macr': 175,\n+    'mdash': 8212,\n+    'micro': 181,\n+    'middot': 183,\n+    'minus': 8722,\n+    'mu': 956,\n+    'nabla': 8711,\n+    'nbsp': 160,\n+    'ndash': 8211,\n+    'ne': 8800,\n+    'ni': 8715,\n+    'not': 172,\n+    'notin': 8713,\n+    'nsub': 8836,\n+    'ntilde': 241,\n+    'nu': 957,\n+    'oacute': 243,\n+    'ocirc': 244,\n+    'oelig': 339,\n+    'ograve': 242,\n+    'oline': 8254,\n+    'omega': 969,\n+    'omicron': 959,\n+    'oplus': 8853,\n+    'or': 8744,\n+    'ordf': 170,\n+    'ordm': 186,\n+    'oslash': 248,\n+    'otilde': 245,\n+    'otimes': 8855,\n+    'ouml': 246,\n+    'para': 182,\n+    'part': 8706,\n+    'permil': 8240,\n+    'perp': 8869,\n+    'phi': 966,\n+    'pi': 960,\n+    'piv': 982,\n+    'plusmn': 177,\n+    'pound': 163,\n+    'prime': 8242,\n+    'prod': 8719,\n+    'prop': 8733,\n+    'psi': 968,\n+    'quot': 34,\n+    'rArr': 8658,\n+    'radic': 8730,\n+    'rang': 9002,\n+    'raquo': 187,\n+    'rarr': 8594,\n+    'rceil': 8969,\n+    'rdquo': 8221,\n+    'real': 8476,\n+    'reg': 174,\n+    'rfloor': 8971,\n+    'rho': 961,\n+    'rlm': 8207,\n+    'rsaquo': 8250,\n+    'rsquo': 8217,\n+    'sbquo': 8218,\n+    'scaron': 353,\n+    'sdot': 8901,\n+    'sect': 167,\n+    'shy': 173,\n+    'sigma': 963,\n+    'sigmaf': 962,\n+    'sim': 8764,\n+    'spades': 9824,\n+    'sub': 8834,\n+    'sube': 8838,\n+    'sum': 8721,\n+    'sup': 8835,\n+    'sup1': 185,\n+    'sup2': 178,\n+    'sup3': 179,\n+    'supe': 8839,\n+    'szlig': 223,\n+    'tau': 964,\n+    'there4': 8756,\n+    'theta': 952,\n+    'thetasym': 977,\n+    'thinsp': 8201,\n+    'thorn': 254,\n+    'tilde': 732,\n+    'times': 215,\n+    'trade': 8482,\n+    'uArr': 8657,\n+    'uacute': 250,\n+    'uarr': 8593,\n+    'ucirc': 251,\n+    'ugrave': 249,\n+    'uml': 168,\n+    'upsih': 978,\n+    'upsilon': 965,\n+    'uuml': 252,\n+    'weierp': 8472,\n+    'xi': 958,\n+    'yacute': 253,\n+    'yen': 165,\n+    'yuml': 255,\n+    'zeta': 950,\n+    'zwj': 8205,\n+    'zwnj': 8204\n+}"
        },
        {
            "sha": "5e83f10a117c4717975327337ef43d0a14a91e96",
            "filename": "tools/markupsafe/_native.py",
            "status": "added",
            "additions": 46,
            "deletions": 0,
            "changes": 46,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2F_native.py",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2F_native.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2F_native.py?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,46 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"\n+    markupsafe._native\n+    ~~~~~~~~~~~~~~~~~~\n+\n+    Native Python implementation the C module is not compiled.\n+\n+    :copyright: (c) 2010 by Armin Ronacher.\n+    :license: BSD, see LICENSE for more details.\n+\"\"\"\n+from markupsafe import Markup\n+from markupsafe._compat import text_type\n+\n+\n+def escape(s):\n+    \"\"\"Convert the characters &, <, >, ' and \" in string s to HTML-safe\n+    sequences.  Use this if you need to display text that might contain\n+    such characters in HTML.  Marks return value as markup string.\n+    \"\"\"\n+    if hasattr(s, '__html__'):\n+        return s.__html__()\n+    return Markup(text_type(s)\n+        .replace('&', '&amp;')\n+        .replace('>', '&gt;')\n+        .replace('<', '&lt;')\n+        .replace(\"'\", '&#39;')\n+        .replace('\"', '&#34;')\n+    )\n+\n+\n+def escape_silent(s):\n+    \"\"\"Like :func:`escape` but converts `None` into an empty\n+    markup string.\n+    \"\"\"\n+    if s is None:\n+        return Markup()\n+    return escape(s)\n+\n+\n+def soft_unicode(s):\n+    \"\"\"Make a string unicode if it isn't already.  That way a markup\n+    string is not converted back to unicode.\n+    \"\"\"\n+    if not isinstance(s, text_type):\n+        s = text_type(s)\n+    return s"
        },
        {
            "sha": "78b708e1b32659912658c24bec5ee039ee3e9cd2",
            "filename": "tools/markupsafe/_speedups.c",
            "status": "added",
            "additions": 239,
            "deletions": 0,
            "changes": 239,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2F_speedups.c",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2F_speedups.c",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2F_speedups.c?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,239 @@\n+/**\n+ * markupsafe._speedups\n+ * ~~~~~~~~~~~~~~~~~~~~\n+ *\n+ * This module implements functions for automatic escaping in C for better\n+ * performance.\n+ *\n+ * :copyright: (c) 2010 by Armin Ronacher.\n+ * :license: BSD.\n+ */\n+\n+#include <Python.h>\n+\n+#define ESCAPED_CHARS_TABLE_SIZE 63\n+#define UNICHR(x) (PyUnicode_AS_UNICODE((PyUnicodeObject*)PyUnicode_DecodeASCII(x, strlen(x), NULL)));\n+\n+#if PY_VERSION_HEX < 0x02050000 && !defined(PY_SSIZE_T_MIN)\n+typedef int Py_ssize_t;\n+#define PY_SSIZE_T_MAX INT_MAX\n+#define PY_SSIZE_T_MIN INT_MIN\n+#endif\n+\n+\n+static PyObject* markup;\n+static Py_ssize_t escaped_chars_delta_len[ESCAPED_CHARS_TABLE_SIZE];\n+static Py_UNICODE *escaped_chars_repl[ESCAPED_CHARS_TABLE_SIZE];\n+\n+static int\n+init_constants(void)\n+{\n+\tPyObject *module;\n+\t/* happing of characters to replace */\n+\tescaped_chars_repl['\"'] = UNICHR(\"&#34;\");\n+\tescaped_chars_repl['\\''] = UNICHR(\"&#39;\");\n+\tescaped_chars_repl['&'] = UNICHR(\"&amp;\");\n+\tescaped_chars_repl['<'] = UNICHR(\"&lt;\");\n+\tescaped_chars_repl['>'] = UNICHR(\"&gt;\");\n+\n+\t/* lengths of those characters when replaced - 1 */\n+\tmemset(escaped_chars_delta_len, 0, sizeof (escaped_chars_delta_len));\n+\tescaped_chars_delta_len['\"'] = escaped_chars_delta_len['\\''] = \\\n+\t\tescaped_chars_delta_len['&'] = 4;\n+\tescaped_chars_delta_len['<'] = escaped_chars_delta_len['>'] = 3;\n+\n+\t/* import markup type so that we can mark the return value */\n+\tmodule = PyImport_ImportModule(\"markupsafe\");\n+\tif (!module)\n+\t\treturn 0;\n+\tmarkup = PyObject_GetAttrString(module, \"Markup\");\n+\tPy_DECREF(module);\n+\n+\treturn 1;\n+}\n+\n+static PyObject*\n+escape_unicode(PyUnicodeObject *in)\n+{\n+\tPyUnicodeObject *out;\n+\tPy_UNICODE *inp = PyUnicode_AS_UNICODE(in);\n+\tconst Py_UNICODE *inp_end = PyUnicode_AS_UNICODE(in) + PyUnicode_GET_SIZE(in);\n+\tPy_UNICODE *next_escp;\n+\tPy_UNICODE *outp;\n+\tPy_ssize_t delta=0, erepl=0, delta_len=0;\n+\n+\t/* First we need to figure out how long the escaped string will be */\n+\twhile (*(inp) || inp < inp_end) {\n+\t\tif (*inp < ESCAPED_CHARS_TABLE_SIZE) {\n+\t\t\tdelta += escaped_chars_delta_len[*inp];\n+\t\t\terepl += !!escaped_chars_delta_len[*inp];\n+\t\t}\n+\t\t++inp;\n+\t}\n+\n+\t/* Do we need to escape anything at all? */\n+\tif (!erepl) {\n+\t\tPy_INCREF(in);\n+\t\treturn (PyObject*)in;\n+\t}\n+\n+\tout = (PyUnicodeObject*)PyUnicode_FromUnicode(NULL, PyUnicode_GET_SIZE(in) + delta);\n+\tif (!out)\n+\t\treturn NULL;\n+\n+\toutp = PyUnicode_AS_UNICODE(out);\n+\tinp = PyUnicode_AS_UNICODE(in);\n+\twhile (erepl-- > 0) {\n+\t\t/* look for the next substitution */\n+\t\tnext_escp = inp;\n+\t\twhile (next_escp < inp_end) {\n+\t\t\tif (*next_escp < ESCAPED_CHARS_TABLE_SIZE &&\n+\t\t\t    (delta_len = escaped_chars_delta_len[*next_escp])) {\n+\t\t\t\t++delta_len;\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t\t++next_escp;\n+\t\t}\n+\n+\t\tif (next_escp > inp) {\n+\t\t\t/* copy unescaped chars between inp and next_escp */\n+\t\t\tPy_UNICODE_COPY(outp, inp, next_escp-inp);\n+\t\t\toutp += next_escp - inp;\n+\t\t}\n+\n+\t\t/* escape 'next_escp' */\n+\t\tPy_UNICODE_COPY(outp, escaped_chars_repl[*next_escp], delta_len);\n+\t\toutp += delta_len;\n+\n+\t\tinp = next_escp + 1;\n+\t}\n+\tif (inp < inp_end)\n+\t\tPy_UNICODE_COPY(outp, inp, PyUnicode_GET_SIZE(in) - (inp - PyUnicode_AS_UNICODE(in)));\n+\n+\treturn (PyObject*)out;\n+}\n+\n+\n+static PyObject*\n+escape(PyObject *self, PyObject *text)\n+{\n+\tPyObject *s = NULL, *rv = NULL, *html;\n+\n+\t/* we don't have to escape integers, bools or floats */\n+\tif (PyLong_CheckExact(text) ||\n+#if PY_MAJOR_VERSION < 3\n+\t    PyInt_CheckExact(text) ||\n+#endif\n+\t    PyFloat_CheckExact(text) || PyBool_Check(text) ||\n+\t    text == Py_None)\n+\t\treturn PyObject_CallFunctionObjArgs(markup, text, NULL);\n+\n+\t/* if the object has an __html__ method that performs the escaping */\n+\thtml = PyObject_GetAttrString(text, \"__html__\");\n+\tif (html) {\n+\t\trv = PyObject_CallObject(html, NULL);\n+\t\tPy_DECREF(html);\n+\t\treturn rv;\n+\t}\n+\n+\t/* otherwise make the object unicode if it isn't, then escape */\n+\tPyErr_Clear();\n+\tif (!PyUnicode_Check(text)) {\n+#if PY_MAJOR_VERSION < 3\n+\t\tPyObject *unicode = PyObject_Unicode(text);\n+#else\n+\t\tPyObject *unicode = PyObject_Str(text);\n+#endif\n+\t\tif (!unicode)\n+\t\t\treturn NULL;\n+\t\ts = escape_unicode((PyUnicodeObject*)unicode);\n+\t\tPy_DECREF(unicode);\n+\t}\n+\telse\n+\t\ts = escape_unicode((PyUnicodeObject*)text);\n+\n+\t/* convert the unicode string into a markup object. */\n+\trv = PyObject_CallFunctionObjArgs(markup, (PyObject*)s, NULL);\n+\tPy_DECREF(s);\n+\treturn rv;\n+}\n+\n+\n+static PyObject*\n+escape_silent(PyObject *self, PyObject *text)\n+{\n+\tif (text != Py_None)\n+\t\treturn escape(self, text);\n+\treturn PyObject_CallFunctionObjArgs(markup, NULL);\n+}\n+\n+\n+static PyObject*\n+soft_unicode(PyObject *self, PyObject *s)\n+{\n+\tif (!PyUnicode_Check(s))\n+#if PY_MAJOR_VERSION < 3\n+\t\treturn PyObject_Unicode(s);\n+#else\n+\t\treturn PyObject_Str(s);\n+#endif\n+\tPy_INCREF(s);\n+\treturn s;\n+}\n+\n+\n+static PyMethodDef module_methods[] = {\n+\t{\"escape\", (PyCFunction)escape, METH_O,\n+\t \"escape(s) -> markup\\n\\n\"\n+\t \"Convert the characters &, <, >, ', and \\\" in string s to HTML-safe\\n\"\n+\t \"sequences.  Use this if you need to display text that might contain\\n\"\n+\t \"such characters in HTML.  Marks return value as markup string.\"},\n+\t{\"escape_silent\", (PyCFunction)escape_silent, METH_O,\n+\t \"escape_silent(s) -> markup\\n\\n\"\n+\t \"Like escape but converts None to an empty string.\"},\n+\t{\"soft_unicode\", (PyCFunction)soft_unicode, METH_O,\n+\t \"soft_unicode(object) -> string\\n\\n\"\n+         \"Make a string unicode if it isn't already.  That way a markup\\n\"\n+         \"string is not converted back to unicode.\"},\n+\t{NULL, NULL, 0, NULL}\t\t/* Sentinel */\n+};\n+\n+\n+#if PY_MAJOR_VERSION < 3\n+\n+#ifndef PyMODINIT_FUNC\t/* declarations for DLL import/export */\n+#define PyMODINIT_FUNC void\n+#endif\n+PyMODINIT_FUNC\n+init_speedups(void)\n+{\n+\tif (!init_constants())\n+\t\treturn;\n+\n+\tPy_InitModule3(\"markupsafe._speedups\", module_methods, \"\");\n+}\n+\n+#else /* Python 3.x module initialization */\n+\n+static struct PyModuleDef module_definition = {\n+        PyModuleDef_HEAD_INIT,\n+\t\"markupsafe._speedups\",\n+\tNULL,\n+\t-1,\n+\tmodule_methods,\n+\tNULL,\n+\tNULL,\n+\tNULL,\n+\tNULL\n+};\n+\n+PyMODINIT_FUNC\n+PyInit__speedups(void)\n+{\n+\tif (!init_constants())\n+\t\treturn NULL;\n+\n+\treturn PyModule_Create(&module_definition);\n+}\n+\n+#endif"
        },
        {
            "sha": "d268832df8ca7fa7c46a67110e0ddf922b8d3560",
            "filename": "tools/markupsafe/get_markupsafe.sh",
            "status": "added",
            "additions": 121,
            "deletions": 0,
            "changes": 121,
            "blob_url": "https://github.com/nodejs/node/blob/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2Fget_markupsafe.sh",
            "raw_url": "https://github.com/nodejs/node/raw/e0395247c899af101f8a1f76a8554be1ff14040a/tools%2Fmarkupsafe%2Fget_markupsafe.sh",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fmarkupsafe%2Fget_markupsafe.sh?ref=e0395247c899af101f8a1f76a8554be1ff14040a",
            "patch": "@@ -0,0 +1,121 @@\n+#!/bin/bash\n+# Download and extract MarkupSafe\n+# Homepage:\n+# https://github.com/mitsuhiko/markupsafe\n+# Download page:\n+# https://pypi.python.org/pypi/MarkupSafe\n+PACKAGE='MarkupSafe'\n+VERSION='0.18'\n+PACKAGE_DIR='markupsafe'\n+\n+CHROMIUM_FILES=\"README.chromium OWNERS get_markupsafe.sh\"\n+EXTRA_FILES='LICENSE AUTHORS'\n+REMOVE_FILES='tests.py'\n+\n+SRC_URL='https://pypi.python.org/packages/source/'\n+SRC_URL+=\"${PACKAGE:0:1}/$PACKAGE/$PACKAGE-$VERSION.tar.gz\"\n+FILENAME=\"$(basename $SRC_URL)\"\n+MD5_FILENAME=\"$FILENAME.md5\"\n+SHA512_FILENAME=\"$FILENAME.sha512\"\n+CHROMIUM_FILES+=\" $MD5_FILENAME $SHA512_FILENAME\"\n+\n+BUILD_DIR=\"$PACKAGE-$VERSION\"\n+THIRD_PARTY=\"$(dirname $(realpath $(dirname \"${BASH_SOURCE[0]}\")))\"\n+INSTALL_DIR=\"$THIRD_PARTY/$PACKAGE_DIR\"\n+OUT_DIR=\"$INSTALL_DIR/$BUILD_DIR/$PACKAGE_DIR\"\n+OLD_DIR=\"$THIRD_PARTY/$PACKAGE_DIR.old\"\n+\n+function check_hashes {\n+  # Hashes generated via:\n+  # FILENAME=MarkupSafe-0.18.tar.gz\n+  # md5sum \"$FILENAME\" > \"$FILENAME.md5\"\n+  # sha512sum \"$FILENAME\" > \"$FILENAME.sha512\"\n+  # unset FILENAME\n+\n+  # MD5\n+  if ! [ -f \"$MD5_FILENAME\" ]\n+  then\n+    echo \"MD5 hash file $MD5_FILENAME not found, could not verify archive\"\n+    exit 1\n+  fi\n+\n+  # 32-digit hash, followed by filename\n+  MD5_HASHFILE_REGEX=\"^[0-9a-f]{32}  $FILENAME\"\n+  if ! grep --extended-regex --line-regex --silent \\\n+    \"$MD5_HASHFILE_REGEX\" \"$MD5_FILENAME\"\n+  then\n+    echo \"MD5 hash file $MD5_FILENAME does not contain hash for $FILENAME,\" \\\n+         'could not verify archive'\n+    echo 'Hash file contents are:'\n+    cat \"$MD5_FILENAME\"\n+    exit 1\n+  fi\n+\n+  if ! md5sum --check \"$MD5_FILENAME\"\n+  then\n+    echo 'MD5 hash does not match,' \\\n+         \"archive file $FILENAME corrupt or compromised!\"\n+    exit 1\n+  fi\n+\n+  # SHA-512\n+  if ! [ -f \"$SHA512_FILENAME\" ]\n+  then\n+    echo \"SHA-512 hash file $SHA512_FILENAME not found,\" \\\n+         'could not verify archive'\n+    exit 1\n+  fi\n+\n+  # 128-digit hash, followed by filename\n+  SHA512_HASHFILE_REGEX=\"^[0-9a-f]{128}  $FILENAME\"\n+  if ! grep --extended-regex --line-regex --silent \\\n+    \"$SHA512_HASHFILE_REGEX\" \"$SHA512_FILENAME\"\n+  then\n+    echo \"SHA-512 hash file $SHA512_FILENAME does not contain hash for\" \\\n+         \"$FILENAME, could not verify archive\"\n+    echo 'Hash file contents are:'\n+    cat \"$SHA512_FILENAME\"\n+    exit 1\n+  fi\n+\n+  if ! sha512sum --check \"$SHA512_FILENAME\"\n+  then\n+    echo 'SHA-512 hash does not match,' \\\n+         \"archive file $FILENAME corrupt or compromised!\"\n+    exit 1\n+  fi\n+}\n+\n+\n+################################################################################\n+# Body\n+\n+cd \"$INSTALL_DIR\"\n+echo \"Downloading $SRC_URL\"\n+curl --remote-name \"$SRC_URL\"\n+check_hashes\n+tar xvzf \"$FILENAME\"\n+# Copy extra files over\n+for FILE in $CHROMIUM_FILES\n+do\n+  cp \"$FILE\" \"$OUT_DIR\"\n+done\n+\n+cd \"$BUILD_DIR\"\n+for FILE in $EXTRA_FILES\n+do\n+  cp \"$FILE\" \"$OUT_DIR\"\n+done\n+\n+cd \"$OUT_DIR\"\n+for FILE in $REMOVE_FILES\n+do\n+  rm -fr \"$FILE\"\n+done\n+\n+# Replace with new directory\n+cd ..\n+mv \"$INSTALL_DIR\" \"$OLD_DIR\"\n+mv \"$PACKAGE_DIR\" \"$INSTALL_DIR\"\n+cd \"$INSTALL_DIR\"\n+rm -fr \"$OLD_DIR\""
        }
    ],
    "stats": {
        "total": 18559,
        "additions": 18555,
        "deletions": 4
    }
}