{
    "author": "boneskull",
    "message": "tools: merge custom cpplint with cpplint v1.3.0\n\nMerged https://github.com/cpplint/cpplint/blob/master/cpplint.py with\nour customized version to enable better IDE/editor integration.\n\nMade file executable.\n\nPR-URL: https://github.com/nodejs/node/pull/22864\nReviewed-By: Anna Henningsen <anna@addaleax.net>\nReviewed-By: Daniel Bevenius <daniel.bevenius@gmail.com>",
    "sha": "fee4d3ab90365aaff0d3469076c7ef8a3a91bc79",
    "files": [
        {
            "sha": "8afcae72a3d83363c90e0d5ff92fbeeef7353924",
            "filename": "tools/cpplint.py",
            "status": "modified",
            "additions": 491,
            "deletions": 134,
            "changes": 625,
            "blob_url": "https://github.com/nodejs/node/blob/fee4d3ab90365aaff0d3469076c7ef8a3a91bc79/tools%2Fcpplint.py",
            "raw_url": "https://github.com/nodejs/node/raw/fee4d3ab90365aaff0d3469076c7ef8a3a91bc79/tools%2Fcpplint.py",
            "contents_url": "https://api.github.com/repos/nodejs/node/contents/tools%2Fcpplint.py?ref=fee4d3ab90365aaff0d3469076c7ef8a3a91bc79",
            "patch": "@@ -44,32 +44,63 @@\n import codecs\n import copy\n import getopt\n+import glob\n import logging\n+import itertools\n import math  # for log\n import os\n import re\n import sre_compile\n import string\n import sys\n import unicodedata\n+import xml.etree.ElementTree\n \n try:\n   xrange\n except NameError:\n   xrange = range\n+# if empty, use defaults\n+_header_extensions = set([])\n \n+# if empty, use defaults\n+_valid_extensions = set([])\n \n+\n+# Files with any of these extensions are considered to be\n+# header files (and will undergo different style checks).\n+# This set can be extended by using the --headers\n+# option (also supported in CPPLINT.cfg)\n+def GetHeaderExtensions():\n+  if not _header_extensions:\n+    return set(['h', 'hpp', 'hxx', 'h++', 'cuh'])\n+  return _header_extensions\n+\n+# The allowed extensions for file names\n+# This is set by --extensions flag\n+def GetAllExtensions():\n+  if not _valid_extensions:\n+    return GetHeaderExtensions().union(set(['c', 'cc', 'cpp', 'cxx', 'c++', 'cu']))\n+  return _valid_extensions\n+\n+def GetNonHeaderExtensions():\n+  return GetAllExtensions().difference(GetHeaderExtensions())\n logger = logging.getLogger('testrunner')\n \n \n _USAGE = \"\"\"\n-Syntax: cpplint.py [--verbose=#] [--output=vs7] [--filter=-x,+y,...]\n-                   [--counting=total|toplevel|detailed] [--root=subdir]\n-                   [--linelength=digits] [--logfile=filename]\n+Syntax: cpplint.py [--verbose=#] [--output=emacs|eclipse|vs7|junit]\n+                   [--filter=-x,+y,...]\n+                   [--counting=total|toplevel|detailed] [--repository=path]\n+                   [--root=subdir] [--linelength=digits] [--recursive]\n+                   [--exclude=path]\n+                   [--headers=ext1,ext2]\n+                   [--logfile=filename]\n+                   [--extensions=hpp,cpp,...]\n         <file> [file] ...\n \n   The style guidelines this tries to follow are those in\n-    https://google-styleguide.googlecode.com/svn/trunk/cppguide.xml\n+    https://google.github.io/styleguide/cppguide.html\n \n   Every problem is given a confidence score from 1-5, with 5 meaning we are\n   certain of the problem, and 1 meaning it could be a legitimate construct.\n@@ -80,17 +111,26 @@\n   suppresses errors of all categories on that line.\n \n   The files passed in will be linted; at least one file must be provided.\n-  Default linted extensions are .cc, .cpp, .cu, .cuh and .h.  Change the\n-  extensions with the --extensions flag.\n+  Default linted extensions are %s.\n+  Other file types will be ignored.\n+  Change the extensions with the --extensions flag.\n \n   Flags:\n \n-    output=vs7\n-      By default, the output is formatted to ease emacs parsing.  Visual Studio\n-      compatible output (vs7) may also be used.  Other formats are unsupported.\n+    output=emacs|eclipse|vs7|junit\n+      By default, the output is formatted to ease emacs parsing.  Output\n+      compatible with eclipse (eclipse), Visual Studio (vs7), and JUnit\n+      XML parsers such as those used in Jenkins and Bamboo may also be\n+      used.  Other formats are unsupported.\n \n     verbose=#\n       Specify a number 0-5 to restrict errors to certain verbosity levels.\n+      Errors with lower verbosity levels have lower confidence and are more\n+      likely to be false positives.\n+\n+    quiet\n+      Supress output other than linting errors, such as information about\n+      which files have been processed and excluded.\n \n     filter=-x,+y,...\n       Specify a comma-separated list of category-filters to apply: only\n@@ -114,17 +154,40 @@\n       also be printed. If 'detailed' is provided, then a count\n       is provided for each category like 'build/class'.\n \n+    repository=path\n+      The top level directory of the repository, used to derive the header\n+      guard CPP variable. By default, this is determined by searching for a\n+      path that contains .git, .hg, or .svn. When this flag is specified, the\n+      given path is used instead. This option allows the header guard CPP\n+      variable to remain consistent even if members of a team have different\n+      repository root directories (such as when checking out a subdirectory\n+      with SVN). In addition, users of non-mainstream version control systems\n+      can use this flag to ensure readable header guard CPP variables.\n+\n+      Examples:\n+        Assuming that Alice checks out ProjectName and Bob checks out\n+        ProjectName/trunk and trunk contains src/chrome/ui/browser.h, then\n+        with no --repository flag, the header guard CPP variable will be:\n+\n+        Alice => TRUNK_SRC_CHROME_BROWSER_UI_BROWSER_H_\n+        Bob   => SRC_CHROME_BROWSER_UI_BROWSER_H_\n+\n+        If Alice uses the --repository=trunk flag and Bob omits the flag or\n+        uses --repository=. then the header guard CPP variable will be:\n+\n+        Alice => SRC_CHROME_BROWSER_UI_BROWSER_H_\n+        Bob   => SRC_CHROME_BROWSER_UI_BROWSER_H_\n+\n     root=subdir\n-      The root directory used for deriving header guard CPP variable.\n-      By default, the header guard CPP variable is calculated as the relative\n-      path to the directory that contains .git, .hg, or .svn.  When this flag\n-      is specified, the relative path is calculated from the specified\n-      directory. If the specified directory does not exist, this flag is\n-      ignored.\n+      The root directory used for deriving header guard CPP variables. This\n+      directory is relative to the top level directory of the repository which\n+      by default is determined by searching for a directory that contains .git,\n+      .hg, or .svn but can also be controlled with the --repository flag. If\n+      the specified directory does not exist, this flag is ignored.\n \n       Examples:\n-        Assuming that src/.git exists, the header guard CPP variables for\n-        src/chrome/browser/ui/browser.h are:\n+        Assuming that src is the top level directory of the repository, the\n+        header guard CPP variables for src/chrome/browser/ui/browser.h are:\n \n         No flag => CHROME_BROWSER_UI_BROWSER_H_\n         --root=chrome => BROWSER_UI_BROWSER_H_\n@@ -137,14 +200,36 @@\n       Examples:\n         --linelength=120\n \n+    recursive\n+      Search for files to lint recursively. Each directory given in the list\n+      of files to be linted is replaced by all files that descend from that\n+      directory. Files with extensions not in the valid extensions list are\n+      excluded.\n+\n+    exclude=path\n+      Exclude the given path from the list of files to be linted. Relative\n+      paths are evaluated relative to the current directory and shell globbing\n+      is performed. This flag can be provided multiple times to exclude\n+      multiple files.\n+\n+      Examples:\n+        --exclude=one.cc\n+        --exclude=src/*.cc\n+        --exclude=src/*.cc --exclude=test/*.cc\n+\n     extensions=extension,extension,...\n       The allowed file extensions that cpplint will check\n \n       Examples:\n-        --extensions=hpp,cpp\n+        --extensions=%s\n+\n+    headers=extension,extension,...\n+      The allowed header extensions that cpplint will consider to be header files\n+      (by default, only files with extensions %s\n+      will be assumed to be headers)\n \n-    logfile=filename\n-      Write TAP output to a logfile.\n+      Examples:\n+        --headers=%s\n \n     cpplint.py supports per-directory configurations specified in CPPLINT.cfg\n     files. CPPLINT.cfg file can contain a number of key=value pairs.\n@@ -154,6 +239,7 @@\n       filter=+filter1,-filter2,...\n       exclude_files=regex\n       linelength=80\n+      root=subdir\n \n     \"set noparent\" option prevents cpplint from traversing directory tree\n     upwards looking for more .cfg files in parent directories. This option\n@@ -165,22 +251,28 @@\n \n     \"exclude_files\" allows to specify a regular expression to be matched against\n     a file name. If the expression matches, the file is skipped and not run\n-    through liner.\n+    through the linter.\n+\n+    \"linelength\" specifies the allowed line length for the project.\n \n-    \"linelength\" allows to specify the allowed line length for the project.\n+    The \"root\" option is similar in function to the --root flag (see example\n+    above).\n \n     CPPLINT.cfg has an effect on files in the same directory and all\n-    sub-directories, unless overridden by a nested configuration file.\n+    subdirectories, unless overridden by a nested configuration file.\n \n       Example file:\n         filter=-build/include_order,+build/include_alpha\n-        exclude_files=.*\\.cc\n+        exclude_files=.*\\\\.cc\n \n     The above example disables build/include_order warning and enables\n     build/include_alpha as well as excludes all .cc from being\n     processed by linter, in the current directory (where the .cfg\n-    file is located) and all sub-directories.\n-\"\"\"\n+    file is located) and all subdirectories.\n+\"\"\" % (list(GetAllExtensions()),\n+       ','.join(list(GetAllExtensions())),\n+       GetHeaderExtensions(),\n+       ','.join(GetHeaderExtensions()))\n \n # We categorize each error message we print.  Here are the categories.\n # We want an explicit list so we can list them all in cpplint --filter=.\n@@ -200,6 +292,7 @@\n     'build/include_alpha',\n     'build/include_order',\n     'build/include_what_you_use',\n+    'build/namespaces_literals',\n     'build/namespaces',\n     'build/printf_format',\n     'build/storage_class',\n@@ -270,6 +363,7 @@\n     '-build/include',\n     '-build/include_alpha',\n     '-build/include_order',\n+    '-build/include_subdir',\n     '-legal/copyright',\n     ]\n \n@@ -447,7 +541,8 @@\n     r'^(?:[^/]*[A-Z][^/]*\\.h|lua\\.h|lauxlib\\.h|lualib\\.h)$')\n \n # Pattern for matching FileInfo.BaseName() against test file name\n-_TEST_FILE_SUFFIX = r'(_test|_unittest|_regtest)$'\n+_test_suffixes = ['_test', '_regtest', '_unittest']\n+_TEST_FILE_SUFFIX = '(' + '|'.join(_test_suffixes) + r')$'\n \n # Pattern that matches only complete whitespace, possibly across multiple lines.\n _EMPTY_CONDITIONAL_BODY_PATTERN = re.compile(r'^\\s*$', re.DOTALL)\n@@ -461,7 +556,7 @@\n     ]\n \n # Replacement macros for CHECK/DCHECK/EXPECT_TRUE/EXPECT_FALSE\n-_CHECK_REPLACEMENT = dict([(m, {}) for m in _CHECK_MACROS])\n+_CHECK_REPLACEMENT = dict([(macro_var, {}) for macro_var in _CHECK_MACROS])\n \n for op, replacement in [('==', 'EQ'), ('!=', 'NE'),\n                         ('>=', 'GE'), ('>', 'GT'),\n@@ -504,6 +599,7 @@\n _ALT_TOKEN_REPLACEMENT_PATTERN = re.compile(\n     r'[ =()](' + ('|'.join(_ALT_TOKEN_REPLACEMENT.keys())) + r')(?=[ (]|$)')\n \n+\n # These constants define types of headers for use with\n # _IncludeState.CheckNextIncludeOrder().\n _C_SYS_HEADER = 1\n@@ -546,13 +642,54 @@\n # This is set by --root flag.\n _root = None\n \n+# The top level repository directory. If set, _root is calculated relative to\n+# this directory instead of the directory containing version control artifacts.\n+# This is set by the --repository flag.\n+_repository = None\n+\n+# Files to exclude from linting. This is set by the --exclude flag.\n+_excludes = None\n+\n+# Whether to supress PrintInfo messages\n+_quiet = False\n+\n # The allowed line length of files.\n # This is set by --linelength flag.\n _line_length = 80\n \n-# The allowed extensions for file names\n-# This is set by --extensions flag.\n-_valid_extensions = set(['cc', 'h', 'cpp', 'cu', 'cuh'])\n+try:\n+  xrange(1, 0)\n+except NameError:\n+  #  -- pylint: disable=redefined-builtin\n+  xrange = range\n+\n+try:\n+  unicode\n+except NameError:\n+  #  -- pylint: disable=redefined-builtin\n+  basestring = unicode = str\n+\n+try:\n+  long(2)\n+except NameError:\n+  #  -- pylint: disable=redefined-builtin\n+  long = int\n+\n+if sys.version_info < (3,):\n+  #  -- pylint: disable=no-member\n+  # BINARY_TYPE = str\n+  itervalues = dict.itervalues\n+  iteritems = dict.iteritems\n+else:\n+  # BINARY_TYPE = bytes\n+  itervalues = dict.values\n+  iteritems = dict.items\n+\n+def unicode_escape_decode(x):\n+  if sys.version_info < (3,):\n+    return codecs.unicode_escape_decode(x)[0]\n+  else:\n+    return x\n \n # {str, bool}: a map from error categories to booleans which indicate if the\n # category should be suppressed for every line.\n@@ -670,7 +807,7 @@ def Search(pattern, s):\n \n def _IsSourceExtension(s):\n   \"\"\"File extension (excluding dot) matches a source file extension.\"\"\"\n-  return s in ('c', 'cc', 'cpp', 'cxx')\n+  return s in GetNonHeaderExtensions()\n \n \n class _IncludeState(object):\n@@ -710,6 +847,8 @@ class _IncludeState(object):\n \n   def __init__(self):\n     self.include_list = [[]]\n+    self._section = None\n+    self._last_header = None\n     self.ResetSection('')\n \n   def FindHeader(self, header):\n@@ -853,9 +992,16 @@ def __init__(self):\n \n     # output format:\n     # \"emacs\" - format that emacs can parse (default)\n+    # \"eclipse\" - format that eclipse can parse\n     # \"vs7\" - format that Microsoft Visual Studio 7 can parse\n+    # \"junit\" - format that Jenkins, Bamboo, etc can parse\n     self.output_format = 'emacs'\n \n+    # For JUnit output, save errors and failures until the end so that they\n+    # can be written into the XML\n+    self._junit_errors = []\n+    self._junit_failures = []\n+\n   def SetOutputFormat(self, output_format):\n     \"\"\"Sets the output format for errors.\"\"\"\n     self.output_format = output_format\n@@ -924,10 +1070,69 @@ def IncrementErrorCount(self, category):\n \n   def PrintErrorCounts(self):\n     \"\"\"Print a summary of errors by category, and the total.\"\"\"\n-    for category, count in self.errors_by_category.iteritems():\n-      sys.stderr.write('Category \\'%s\\' errors found: %d\\n' %\n+    for category, count in sorted(iteritems(self.errors_by_category)):\n+      self.PrintInfo('Category \\'%s\\' errors found: %d\\n' %\n                        (category, count))\n-    sys.stderr.write('Total errors found: %d\\n' % self.error_count)\n+    if self.error_count > 0:\n+      self.PrintInfo('Total errors found: %d\\n' % self.error_count)\n+\n+  def PrintInfo(self, message):\n+    if not _quiet and self.output_format != 'junit':\n+      sys.stderr.write(message)\n+\n+  def PrintError(self, message):\n+    if self.output_format == 'junit':\n+      self._junit_errors.append(message)\n+    else:\n+      sys.stderr.write(message)\n+\n+  def AddJUnitFailure(self, filename, linenum, message, category, confidence):\n+    self._junit_failures.append((filename, linenum, message, category,\n+        confidence))\n+\n+  def FormatJUnitXML(self):\n+    num_errors = len(self._junit_errors)\n+    num_failures = len(self._junit_failures)\n+\n+    testsuite = xml.etree.ElementTree.Element('testsuite')\n+    testsuite.attrib['name'] = 'cpplint'\n+    testsuite.attrib['errors'] = str(num_errors)\n+    testsuite.attrib['failures'] = str(num_failures)\n+\n+    if num_errors == 0 and num_failures == 0:\n+      testsuite.attrib['tests'] = str(1)\n+      xml.etree.ElementTree.SubElement(testsuite, 'testcase', name='passed')\n+\n+    else:\n+      testsuite.attrib['tests'] = str(num_errors + num_failures)\n+      if num_errors > 0:\n+        testcase = xml.etree.ElementTree.SubElement(testsuite, 'testcase')\n+        testcase.attrib['name'] = 'errors'\n+        error = xml.etree.ElementTree.SubElement(testcase, 'error')\n+        error.text = '\\n'.join(self._junit_errors)\n+      if num_failures > 0:\n+        # Group failures by file\n+        failed_file_order = []\n+        failures_by_file = {}\n+        for failure in self._junit_failures:\n+          failed_file = failure[0]\n+          if failed_file not in failed_file_order:\n+            failed_file_order.append(failed_file)\n+            failures_by_file[failed_file] = []\n+          failures_by_file[failed_file].append(failure)\n+        # Create a testcase for each file\n+        for failed_file in failed_file_order:\n+          failures = failures_by_file[failed_file]\n+          testcase = xml.etree.ElementTree.SubElement(testsuite, 'testcase')\n+          testcase.attrib['name'] = failed_file\n+          failure = xml.etree.ElementTree.SubElement(testcase, 'failure')\n+          template = '{0}: {1} [{2}] [{3}]'\n+          texts = [template.format(f[1], f[2], f[3], f[4]) for f in failures]\n+          failure.text = '\\n'.join(texts)\n+\n+    xml_decl = '<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\\n'\n+    return xml_decl + xml.etree.ElementTree.tostring(testsuite, 'utf-8').decode('utf-8')\n+\n \n _cpplint_state = _CppLintState()\n \n@@ -1173,7 +1378,7 @@ def Error(filename, linenum, category, confidence, message):\n   if _ShouldPrintError(category, confidence, linenum):\n     _cpplint_state.IncrementErrorCount(category)\n     if _cpplint_state.output_format == 'vs7':\n-      sys.stderr.write('%s(%s):  %s  [%s] [%d]\\n' % (\n+      _cpplint_state.PrintError('%s(%s): warning: %s  [%s] [%d]\\n' % (\n           filename, linenum, message, category, confidence))\n     elif _cpplint_state.output_format == 'eclipse':\n       sys.stderr.write('%s:%s: warning: %s  [%s] [%d]\\n' % (\n@@ -1188,9 +1393,9 @@ def Error(filename, linenum, category, confidence, message):\n           '  ...')\n       logger.info(template % locals())\n     else:\n-      sys.stderr.write('%s:%s:  %s  [%s] [%d]\\n' % (\n-          filename, linenum, message, category, confidence))\n-\n+      final_message = '%s:%s:  %s  [%s] [%d]\\n' % (\n+          filename, linenum, message, category, confidence)\n+      sys.stderr.write(final_message)\n \n # Matches standard C++ escape sequences per 2.13.2.3 of the C++ standard.\n _RE_PATTERN_CLEANSE_LINE_ESCAPES = re.compile(\n@@ -1748,7 +1953,12 @@ def GetHeaderGuardCPPVariable(filename):\n   fileinfo = FileInfo(filename)\n   file_path_from_root = fileinfo.RepositoryName()\n   if _root:\n-    file_path_from_root = re.sub('^' + _root + os.sep, '', file_path_from_root)\n+    suffix = os.sep\n+    # On Windows using directory separator will leave us with\n+    # \"bogus escape error\" unless we properly escape regex.\n+    if suffix == '\\\\':\n+      suffix += '\\\\'\n+    file_path_from_root = re.sub('^' + _root + suffix, '', file_path_from_root)\n   return re.sub(r'[^a-zA-Z0-9]', '_', file_path_from_root).upper() + '_'\n \n \n@@ -1775,6 +1985,11 @@ def CheckForHeaderGuard(filename, clean_lines, error):\n     if Search(r'//\\s*NOLINT\\(build/header_guard\\)', i):\n       return\n \n+  # Allow pragma once instead of header guards\n+  for i in raw_lines:\n+    if Search(r'^\\s*#pragma\\s+once', i):\n+      return\n+\n   cppvar = GetHeaderGuardCPPVariable(filename)\n \n   ifndef = ''\n@@ -1851,28 +2066,30 @@ def CheckForHeaderGuard(filename, clean_lines, error):\n \n \n def CheckHeaderFileIncluded(filename, include_state, error):\n-  \"\"\"Logs an error if a .cc file does not include its header.\"\"\"\n+  \"\"\"Logs an error if a source file does not include its header.\"\"\"\n \n   # Do not check test files\n   fileinfo = FileInfo(filename)\n   if Search(_TEST_FILE_SUFFIX, fileinfo.BaseName()):\n     return\n \n-  headerfile = filename[0:len(filename) - len(fileinfo.Extension())] + '.h'\n-  if not os.path.exists(headerfile):\n-    return\n-  headername = FileInfo(headerfile).RepositoryName()\n-  first_include = 0\n-  for section_list in include_state.include_list:\n-    for f in section_list:\n-      if headername in f[0] or f[0] in headername:\n-        return\n-      if not first_include:\n-        first_include = f[1]\n+  for ext in GetHeaderExtensions():\n+    basefilename = filename[0:len(filename) - len(fileinfo.Extension())]\n+    headerfile = basefilename + '.' + ext\n+    if not os.path.exists(headerfile):\n+      continue\n+    headername = FileInfo(headerfile).RepositoryName()\n+    first_include = None\n+    for section_list in include_state.include_list:\n+      for f in section_list:\n+        if headername in f[0] or f[0] in headername:\n+          return\n+        if not first_include:\n+          first_include = f[1]\n \n-  error(filename, first_include, 'build/include', 5,\n-        '%s should include its header file %s' % (fileinfo.RepositoryName(),\n-                                                  headername))\n+    error(filename, first_include, 'build/include', 5,\n+          '%s should include its header file %s' % (fileinfo.RepositoryName(),\n+                                                    headername))\n \n \n def CheckForBadCharacters(filename, lines, error):\n@@ -1893,7 +2110,7 @@ def CheckForBadCharacters(filename, lines, error):\n     error: The function to call with any errors found.\n   \"\"\"\n   for linenum, line in enumerate(lines):\n-    if u'\\ufffd' in line:\n+    if unicode_escape_decode('\\ufffd') in line:\n       error(filename, linenum, 'readability/utf8', 5,\n             'Line contains invalid UTF-8 (or Unicode replacement character).')\n     if '\\0' in line:\n@@ -2537,7 +2754,7 @@ def Update(self, filename, clean_lines, linenum, error):\n     #   class LOCKABLE API Object {\n     #   };\n     class_decl_match = Match(\n-        r'^(\\s*(?:template\\s*<[\\w\\s<>,:]*>\\s*)?'\n+        r'^(\\s*(?:template\\s*<[\\w\\s<>,:=]*>\\s*)?'\n         r'(class|struct)\\s+(?:[A-Z_]+\\s+)*(\\w+(?:::\\w+)*))'\n         r'(.*)$', line)\n     if (class_decl_match and\n@@ -2785,6 +3002,7 @@ def CheckForNonStandardConstructs(filename, clean_lines, linenum,\n       constructor_args[i] = constructor_arg\n       i += 1\n \n+    variadic_args = [arg for arg in constructor_args if '&&...' in arg]\n     defaulted_args = [arg for arg in constructor_args if '=' in arg]\n     noarg_constructor = (not constructor_args or  # empty arg list\n                          # 'void' arg specifier\n@@ -2795,7 +3013,10 @@ def CheckForNonStandardConstructs(filename, clean_lines, linenum,\n                           # all but at most one arg defaulted\n                           (len(constructor_args) >= 1 and\n                            not noarg_constructor and\n-                           len(defaulted_args) >= len(constructor_args) - 1))\n+                           len(defaulted_args) >= len(constructor_args) - 1) or\n+                          # variadic arguments with zero or one argument\n+                          (len(constructor_args) <= 2 and\n+                           len(variadic_args) >= 1))\n     initializer_list_constructor = bool(\n         onearg_constructor and\n         Search(r'\\bstd\\s*::\\s*initializer_list\\b', constructor_args[0]))\n@@ -2808,7 +3029,7 @@ def CheckForNonStandardConstructs(filename, clean_lines, linenum,\n         onearg_constructor and\n         not initializer_list_constructor and\n         not copy_constructor):\n-      if defaulted_args:\n+      if defaulted_args or variadic_args:\n         error(filename, linenum, 'runtime/explicit', 5,\n               'Constructors callable with one argument '\n               'should be marked explicit.')\n@@ -3046,7 +3267,7 @@ def CheckComment(line, filename, linenum, next_line_start, error):\n       # If the comment contains an alphanumeric character, there\n       # should be a space somewhere between it and the // unless\n       # it's a /// or //! Doxygen comment.\n-      if (Match(r'(?://[^ ]*\\w)|(?:////\\s*$)', comment) and\n+      if (Match(r'//[^ ]*\\w', comment) and\n           not Match(r'(///|//\\!)(\\s+|$)', comment)):\n         error(filename, linenum, 'whitespace/comments', 4,\n               'Should have a space between // and comment')\n@@ -3568,7 +3789,6 @@ def IsDecltype(clean_lines, linenum, column):\n     return True\n   return False\n \n-\n def CheckSectionSpacing(filename, clean_lines, class_info, linenum, error):\n   \"\"\"Checks for additional blank line issues related to sections.\n \n@@ -3901,6 +4121,14 @@ def CheckTrailingSemicolon(filename, clean_lines, linenum, error):\n       # outputting warnings for the matching closing brace, if there are\n       # nested blocks with trailing semicolons, we will get the error\n       # messages in reversed order.\n+\n+      # We need to check the line forward for NOLINT\n+      raw_lines = clean_lines.raw_lines\n+      ParseNolintSuppressions(filename, raw_lines[endlinenum-1], endlinenum-1,\n+                              error)\n+      ParseNolintSuppressions(filename, raw_lines[endlinenum], endlinenum,\n+                              error)\n+\n       error(filename, endlinenum, 'readability/braces', 4,\n             \"You don't need a ; after a }\")\n \n@@ -3978,12 +4206,12 @@ def CheckEmptyBlockBody(filename, clean_lines, linenum, error):\n         return\n       if closing_linenum > opening_linenum:\n         # Opening line after the {. Ignore comments here since we checked above.\n-        body = list(opening_line[opening_pos+1:])\n+        bodylist = list(opening_line[opening_pos+1:])\n         # All lines until closing line, excluding closing line, with comments.\n-        body.extend(clean_lines.raw_lines[opening_linenum+1:closing_linenum])\n+        bodylist.extend(clean_lines.raw_lines[opening_linenum+1:closing_linenum])\n         # Closing line before the }. Won't (and can't) have comments.\n-        body.append(clean_lines.elided[closing_linenum][:closing_pos-1])\n-        body = '\\n'.join(body)\n+        bodylist.append(clean_lines.elided[closing_linenum][:closing_pos-1])\n+        body = '\\n'.join(bodylist)\n       else:\n         # If statement has brackets and fits on a single line.\n         body = opening_line[opening_pos+1:closing_pos-1]\n@@ -4318,7 +4546,7 @@ def CheckStyle(filename, clean_lines, linenum, file_extension, nesting_state,\n \n   # Check if the line is a header guard.\n   is_header_guard = False\n-  if file_extension == 'h':\n+  if file_extension in GetHeaderExtensions():\n     cppvar = GetHeaderGuardCPPVariable(filename)\n     if (line.startswith('#ifndef %s' % cppvar) or\n         line.startswith('#define %s' % cppvar) or\n@@ -4332,16 +4560,23 @@ def CheckStyle(filename, clean_lines, linenum, file_extension, nesting_state,\n   #\n   # The \"$Id:...$\" comment may also get very long without it being the\n   # developers fault.\n+  #\n+  # Doxygen documentation copying can get pretty long when using an overloaded\n+  # function declaration\n   if (not line.startswith('#include') and not is_header_guard and\n       not Match(r'^\\s*//.*http(s?)://\\S*$', line) and\n       not Match(r'^\\s*//\\s*[^\\s]*$', line) and\n-      not Match(r'^// \\$Id:.*#[0-9]+ \\$$', line)):\n+      not Match(r'^// \\$Id:.*#[0-9]+ \\$$', line) and\n+      not Match(r'^\\s*/// [@\\\\](copydoc|copydetails|copybrief) .*$', line)):\n     line_width = GetLineWidth(line)\n     if line_width > _line_length:\n       error(filename, linenum, 'whitespace/line_length', 2,\n             'Lines should be <= %i characters long' % _line_length)\n \n   if (cleansed_line.count(';') > 1 and\n+      # allow simple single line lambdas\n+      not Match(r'^[^{};]*\\[[^\\[\\]]*\\][^{}]*\\{[^{}\\n\\r]*\\}',\n+                line) and\n       # for loops are allowed two ;'s (and may run over two lines).\n       cleansed_line.find('for') == -1 and\n       (GetPreviousNonBlankLine(clean_lines, linenum)[0].find('for') == -1 or\n@@ -4401,8 +4636,11 @@ def _DropCommonSuffixes(filename):\n   Returns:\n     The filename with the common suffix removed.\n   \"\"\"\n-  for suffix in ('test.cc', 'regtest.cc', 'unittest.cc',\n-                 'inl.h', 'impl.h', 'internal.h'):\n+  for suffix in itertools.chain(\n+      ('%s.%s' % (test_suffix.lstrip('_'), ext)\n+       for test_suffix, ext in itertools.product(_test_suffixes, GetNonHeaderExtensions())),\n+      ('%s.%s' % (suffix, ext)\n+       for suffix, ext in itertools.product(['inl', 'imp', 'internal'], GetHeaderExtensions()))):\n     if (filename.endswith(suffix) and len(filename) > len(suffix) and\n         filename[-len(suffix) - 1] in ('-', '_')):\n       return filename[:-len(suffix) - 1]\n@@ -4437,6 +4675,10 @@ def _ClassifyInclude(fileinfo, include, is_system):\n   # those already checked for above.\n   is_cpp_h = include in _CPP_HEADERS\n \n+  # Headers with C++ extensions shouldn't be considered C system headers\n+  if is_system and os.path.splitext(include)[1] in ['.hpp', '.hxx', '.h++']:\n+    is_system = False\n+\n   if is_system:\n     if is_cpp_h:\n       return _CPP_SYS_HEADER\n@@ -4449,9 +4691,11 @@ def _ClassifyInclude(fileinfo, include, is_system):\n   target_dir, target_base = (\n       os.path.split(_DropCommonSuffixes(fileinfo.RepositoryName())))\n   include_dir, include_base = os.path.split(_DropCommonSuffixes(include))\n+  target_dir_pub = os.path.normpath(target_dir + '/../public')\n+  target_dir_pub = target_dir_pub.replace('\\\\', '/')\n   if target_base == include_base and (\n       include_dir == target_dir or\n-      include_dir == os.path.normpath(target_dir + '/../public')):\n+      include_dir == target_dir_pub):\n     return _LIKELY_MY_HEADER\n \n   # If the target and include share some initial basename\n@@ -4495,7 +4739,7 @@ def CheckIncludeLine(filename, clean_lines, linenum, include_state, error):\n   # naming convention but not the include convention.\n   match = Match(r'#include\\s*\"([^/]+\\.h)\"', line)\n   if match and not _THIRD_PARTY_HEADERS_PATTERN.match(match.group(1)):\n-    error(filename, linenum, 'build/include', 4,\n+    error(filename, linenum, 'build/include_subdir', 4,\n           'Include the directory when naming .h files')\n \n   # we shouldn't include a file more than once. actually, there are a\n@@ -4510,11 +4754,16 @@ def CheckIncludeLine(filename, clean_lines, linenum, include_state, error):\n       error(filename, linenum, 'build/include', 4,\n             '\"%s\" already included at %s:%s' %\n             (include, filename, duplicate_line))\n-    elif (include.endswith('.cc') and\n+      return\n+\n+    for extension in GetNonHeaderExtensions():\n+      if (include.endswith('.' + extension) and\n           os.path.dirname(fileinfo.RepositoryName()) != os.path.dirname(include)):\n-      error(filename, linenum, 'build/include', 4,\n-            'Do not include .cc files from other packages')\n-    elif not _THIRD_PARTY_HEADERS_PATTERN.match(include):\n+        error(filename, linenum, 'build/include', 4,\n+              'Do not include .' + extension + ' files from other packages')\n+        return\n+\n+    if not _THIRD_PARTY_HEADERS_PATTERN.match(include):\n       include_state.include_list[-1].append((include, linenum))\n \n       # We want to ensure that headers appear in the right order:\n@@ -4568,7 +4817,7 @@ def _GetTextInside(text, start_pattern):\n \n   # Give opening punctuations to get the matching close-punctuations.\n   matching_punctuation = {'(': ')', '{': '}', '[': ']'}\n-  closing_punctuation = set(matching_punctuation.itervalues())\n+  closing_punctuation = set(itervalues(matching_punctuation))\n \n   # Find the position to start extracting text.\n   match = re.search(start_pattern, text, re.M)\n@@ -4670,7 +4919,7 @@ def CheckLanguage(filename, clean_lines, linenum, file_extension,\n   CheckGlobalStatic(filename, clean_lines, linenum, error)\n   CheckPrintf(filename, clean_lines, linenum, error)\n \n-  if file_extension == 'h':\n+  if file_extension in GetHeaderExtensions():\n     # TODO(unknown): check that 1-arg constructors are explicit.\n     #                How to tell it's a constructor?\n     #                (handled in CheckForNonStandardConstructs for now)\n@@ -4731,9 +4980,14 @@ def CheckLanguage(filename, clean_lines, linenum, file_extension,\n           % (match.group(1), match.group(2)))\n \n   if Search(r'\\busing namespace\\b', line):\n-    error(filename, linenum, 'build/namespaces', 5,\n-          'Do not use namespace using-directives.  '\n-          'Use using-declarations instead.')\n+    if Search(r'\\bliterals\\b', line):\n+      error(filename, linenum, 'build/namespaces_literals', 5,\n+            'Do not use namespace using-directives.  '\n+            'Use using-declarations instead.')\n+    else:\n+      error(filename, linenum, 'build/namespaces', 5,\n+            'Do not use namespace using-directives.  '\n+            'Use using-declarations instead.')\n \n   # Detect variable-length arrays.\n   match = Match(r'\\s*(.+::)?(\\w+) [a-z]\\w*\\[(.+)];', line)\n@@ -4777,7 +5031,7 @@ def CheckLanguage(filename, clean_lines, linenum, file_extension,\n   # Check for use of unnamed namespaces in header files.  Registration\n   # macros are typically OK, so we allow use of \"namespace {\" on lines\n   # that end with backslashes.\n-  if (file_extension == 'h'\n+  if (file_extension in GetHeaderExtensions()\n       and Search(r'\\bnamespace\\s*{', line)\n       and line[-1] != '\\\\'):\n     error(filename, linenum, 'build/namespaces', 4,\n@@ -5377,28 +5631,31 @@ def FilesBelongToSameModule(filename_cc, filename_h):\n   some false positives. This should be sufficiently rare in practice.\n \n   Args:\n-    filename_cc: is the path for the .cc file\n+    filename_cc: is the path for the source (e.g. .cc) file\n     filename_h: is the path for the header path\n \n   Returns:\n     Tuple with a bool and a string:\n     bool: True if filename_cc and filename_h belong to the same module.\n     string: the additional prefix needed to open the header file.\n   \"\"\"\n+  fileinfo_cc = FileInfo(filename_cc)\n+  if not fileinfo_cc.Extension().lstrip('.') in GetNonHeaderExtensions():\n+    return (False, '')\n \n-  fileinfo = FileInfo(filename_cc)\n-  if not fileinfo.IsSource():\n+  fileinfo_h = FileInfo(filename_h)\n+  if not fileinfo_h.Extension().lstrip('.') in GetHeaderExtensions():\n     return (False, '')\n-  filename_cc = filename_cc[:-len(fileinfo.Extension())]\n-  matched_test_suffix = Search(_TEST_FILE_SUFFIX, fileinfo.BaseName())\n+\n+  filename_cc = filename_cc[:-(len(fileinfo_cc.Extension()))]\n+  matched_test_suffix = Search(_TEST_FILE_SUFFIX, fileinfo_cc.BaseName())\n   if matched_test_suffix:\n     filename_cc = filename_cc[:-len(matched_test_suffix.group(1))]\n+\n   filename_cc = filename_cc.replace('/public/', '/')\n   filename_cc = filename_cc.replace('/internal/', '/')\n \n-  if not filename_h.endswith('.h'):\n-    return (False, '')\n-  filename_h = filename_h[:-len('.h')]\n+  filename_h = filename_h[:-(len(fileinfo_h.Extension()))]\n   if filename_h.endswith('-inl'):\n     filename_h = filename_h[:-len('-inl')]\n   filename_h = filename_h.replace('/public/', '/')\n@@ -5508,7 +5765,7 @@ def CheckForIncludeWhatYouUse(filename, clean_lines, include_state, error,\n \n   # include_dict is modified during iteration, so we iterate over a copy of\n   # the keys.\n-  header_keys = include_dict.keys()\n+  header_keys = list(include_dict.keys())\n   for header in header_keys:\n     (same_module, common_path) = FilesBelongToSameModule(abs_filename, header)\n     fullpath = common_path + header\n@@ -5520,11 +5777,13 @@ def CheckForIncludeWhatYouUse(filename, clean_lines, include_state, error,\n   # didn't include it in the .h file.\n   # TODO(unknown): Do a better job of finding .h files so we are confident that\n   # not having the .h file means there isn't one.\n-  if filename.endswith('.cc') and not header_found:\n-    return\n+  if not header_found:\n+    for extension in GetNonHeaderExtensions():\n+      if filename.endswith('.' + extension):\n+        return\n \n   # All the lines have been processed, report the errors found.\n-  for required_header_unstripped in required:\n+  for required_header_unstripped in sorted(required, key=required.__getitem__):\n     template = required[required_header_unstripped][1]\n     if required_header_unstripped.strip('<>\"') not in include_dict:\n       error(filename, required[required_header_unstripped][0],\n@@ -5663,11 +5922,9 @@ def IsBlockInNameSpace(nesting_state, is_forward_declaration):\n     Whether or not the new block is directly in a namespace.\n   \"\"\"\n   if is_forward_declaration:\n-    if len(nesting_state.stack) >= 1 and (\n-        isinstance(nesting_state.stack[-1], _NamespaceInfo)):\n-      return True\n-    else:\n-      return False\n+    return len(nesting_state.stack) >= 1 and (\n+      isinstance(nesting_state.stack[-1], _NamespaceInfo))\n+\n \n   return (len(nesting_state.stack) > 1 and\n           nesting_state.stack[-1].check_namespace_indentation and\n@@ -5717,7 +5974,7 @@ def CheckItemIndentationInNamespace(filename, raw_lines_no_comments, linenum,\n \n def ProcessLine(filename, file_extension, clean_lines, line,\n                 include_state, function_state, nesting_state, error,\n-                extra_check_functions=[]):\n+                extra_check_functions=None):\n   \"\"\"Processes a single line in the file.\n \n   Args:\n@@ -5756,8 +6013,9 @@ def ProcessLine(filename, file_extension, clean_lines, line,\n   CheckMakePairUsesDeduction(filename, clean_lines, line, error)\n   CheckRedundantVirtual(filename, clean_lines, line, error)\n   CheckRedundantOverrideOrFinal(filename, clean_lines, line, error)\n-  for check_fn in extra_check_functions:\n-    check_fn(filename, clean_lines, line, error)\n+  if extra_check_functions:\n+    for check_fn in extra_check_functions:\n+      check_fn(filename, clean_lines, line, error)\n \n def FlagCxx11Features(filename, clean_lines, linenum, error):\n   \"\"\"Flag those c++11 features that we only allow in certain places.\n@@ -5831,7 +6089,7 @@ def FlagCxx14Features(filename, clean_lines, linenum, error):\n \n \n def ProcessFileData(filename, file_extension, lines, error,\n-                    extra_check_functions=[]):\n+                    extra_check_functions=None):\n   \"\"\"Performs lint checks and reports any errors to the given error function.\n \n   Args:\n@@ -5859,7 +6117,7 @@ def ProcessFileData(filename, file_extension, lines, error,\n   RemoveMultiLineComments(filename, lines, error)\n   clean_lines = CleansedLines(lines)\n \n-  if file_extension == 'h':\n+  if file_extension in GetHeaderExtensions():\n     CheckForHeaderGuard(filename, clean_lines, error)\n \n   for line in xrange(clean_lines.NumLines()):\n@@ -5930,36 +6188,56 @@ def ProcessConfigOverrides(filename):\n             if base_name:\n               pattern = re.compile(val)\n               if pattern.match(base_name):\n-                sys.stderr.write('Ignoring \"%s\": file excluded by \"%s\". '\n-                                 'File path component \"%s\" matches '\n-                                 'pattern \"%s\"\\n' %\n+                _cpplint_state.PrintInfo('Ignoring \"%s\": file excluded by '\n+                    '\"%s\". File path component \"%s\" matches pattern \"%s\"\\n' %\n                                  (filename, cfg_file, base_name, val))\n                 return False\n           elif name == 'linelength':\n             global _line_length\n             try:\n                 _line_length = int(val)\n             except ValueError:\n-                sys.stderr.write('Line length must be numeric.')\n+                _cpplint_state.PrintError('Line length must be numeric.')\n+          elif name == 'extensions':\n+              global _valid_extensions\n+              try:\n+                  extensions = [ext.strip() for ext in val.split(',')]\n+                  _valid_extensions = set(extensions)\n+              except ValueError:\n+                  sys.stderr.write('Extensions should be a comma-separated list of values;'\n+                                   'for example: extensions=hpp,cpp\\n'\n+                                   'This could not be parsed: \"%s\"' % (val,))\n+          elif name == 'headers':\n+              global _header_extensions\n+              try:\n+                  extensions = [ext.strip() for ext in val.split(',')]\n+                  _header_extensions = set(extensions)\n+              except ValueError:\n+                  sys.stderr.write('Extensions should be a comma-separated list of values;'\n+                                   'for example: extensions=hpp,cpp\\n'\n+                                   'This could not be parsed: \"%s\"' % (val,))\n+          elif name == 'root':\n+            global _root\n+            _root = val\n           else:\n-            sys.stderr.write(\n+            _cpplint_state.PrintError(\n                 'Invalid configuration option (%s) in file %s\\n' %\n                 (name, cfg_file))\n \n     except IOError:\n-      sys.stderr.write(\n+      _cpplint_state.PrintError(\n           \"Skipping config file '%s': Can't open for reading\\n\" % cfg_file)\n       keep_looking = False\n \n   # Apply all the accumulated filters in reverse order (top-level directory\n   # config options having the least priority).\n-  for filter in reversed(cfg_filters):\n-     _AddFilters(filter)\n+  for cfg_filter in reversed(cfg_filters):\n+     _AddFilters(cfg_filter)\n \n   return True\n \n \n-def ProcessFile(filename, vlevel, extra_check_functions=[]):\n+def ProcessFile(filename, vlevel, extra_check_functions=None):\n   \"\"\"Does google-lint on a single file.\n \n   Args:\n@@ -6008,7 +6286,7 @@ def ProcessFile(filename, vlevel, extra_check_functions=[]):\n         lf_lines.append(linenum + 1)\n \n   except IOError:\n-    sys.stderr.write(\n+    _cpplint_state.PrintError(\n         \"Skipping input '%s': Can't open for reading\\n\" % filename)\n     _RestoreFilters()\n     return\n@@ -6018,9 +6296,9 @@ def ProcessFile(filename, vlevel, extra_check_functions=[]):\n \n   # When reading from stdin, the extension is unknown, so no cpplint tests\n   # should rely on the extension.\n-  if filename != '-' and file_extension not in _valid_extensions:\n-    sys.stderr.write('Ignoring %s; not a valid file name '\n-                     '(%s)\\n' % (filename, ', '.join(_valid_extensions)))\n+  if filename != '-' and file_extension not in GetAllExtensions():\n+    _cpplint_state.PrintError('Ignoring %s; not a valid file name '\n+                     '(%s)\\n' % (filename, ', '.join(GetAllExtensions())))\n   else:\n     ProcessFileData(filename, file_extension, lines, Error,\n                     extra_check_functions)\n@@ -6043,6 +6321,7 @@ def ProcessFile(filename, vlevel, extra_check_functions=[]):\n         Error(filename, linenum, 'whitespace/newline', 1,\n               'Unexpected \\\\r (^M) found; better to use only \\\\n')\n \n+  _cpplint_state.PrintInfo('Done processing %s\\n' % filename)\n   _RestoreFilters()\n \n \n@@ -6053,10 +6332,11 @@ def PrintUsage(message):\n     message: The optional error message.\n   \"\"\"\n   sys.stderr.write(_USAGE)\n+\n   if message:\n     sys.exit('\\nFATAL ERROR: ' + message)\n   else:\n-    sys.exit(1)\n+    sys.exit(0)\n \n \n def PrintCategories():\n@@ -6085,23 +6365,29 @@ def ParseArguments(args):\n                                                  'filter=',\n                                                  'logfile=',\n                                                  'root=',\n+                                                 'repository=',\n                                                  'linelength=',\n-                                                 'extensions='])\n+                                                 'extensions=',\n+                                                 'exclude=',\n+                                                 'headers=',\n+                                                 'quiet',\n+                                                 'recursive'])\n   except getopt.GetoptError:\n     PrintUsage('Invalid arguments.')\n \n   verbosity = _VerboseLevel()\n   output_format = _OutputFormat()\n   filters = ''\n   counting_style = ''\n+  recursive = False\n \n   for (opt, val) in opts:\n     if opt == '--help':\n       PrintUsage(None)\n     elif opt == '--output':\n-      if val not in ('emacs', 'vs7', 'eclipse', 'tap'):\n+      if val not in ('emacs', 'vs7', 'eclipse', 'junit', 'tap'):\n         PrintUsage(\n-            'The only allowed output formats are emacs, vs7, eclipse and tap.')\n+            'The only allowed output formats are emacs, vs7, eclipse, junit and tap.')\n       output_format = val\n     elif opt == '--verbose':\n       verbosity = int(val)\n@@ -6116,52 +6402,123 @@ def ParseArguments(args):\n     elif opt == '--root':\n       global _root\n       _root = val\n+    elif opt == '--repository':\n+      global _repository\n+      _repository = val\n     elif opt == '--linelength':\n       global _line_length\n       try:\n           _line_length = int(val)\n       except ValueError:\n           PrintUsage('Line length must be digits.')\n+    elif opt == '--exclude':\n+      global _excludes\n+      if not _excludes:\n+        _excludes = set()\n+      _excludes.update(glob.glob(val))\n     elif opt == '--extensions':\n       global _valid_extensions\n       try:\n           _valid_extensions = set(val.split(','))\n       except ValueError:\n+          PrintUsage('Extensions must be comma seperated list.')\n+    elif opt == '--headers':\n+      global _header_extensions\n+      try:\n+          _header_extensions = set(val.split(','))\n+      except ValueError:\n+        PrintUsage('Extensions must be comma seperated list.')\n+    elif opt == '--recursive':\n           PrintUsage('Extensions must be comma separated list.')\n     elif opt == '--logfile':\n+      recursive = True\n+    elif opt == '--quiet':\n       logger.addHandler(logging.FileHandler(val, mode='wb'))\n+      global _quiet\n+      _quiet = True\n \n   if not filenames:\n     PrintUsage('No files were specified.')\n \n+  if recursive:\n+    filenames = _ExpandDirectories(filenames)\n+\n+  if _excludes:\n+    filenames = _FilterExcludedFiles(filenames)\n+\n   _SetOutputFormat(output_format)\n   _SetVerboseLevel(verbosity)\n   _SetFilters(filters)\n   _SetCountingStyle(counting_style)\n \n   return filenames\n \n+def _ExpandDirectories(filenames):\n+  \"\"\"Searches a list of filenames and replaces directories in the list with\n+  all files descending from those directories. Files with extensions not in\n+  the valid extensions list are excluded.\n+\n+  Args:\n+    filenames: A list of files or directories\n+\n+  Returns:\n+    A list of all files that are members of filenames or descended from a\n+    directory in filenames\n+  \"\"\"\n+  expanded = set()\n+  for filename in filenames:\n+      if not os.path.isdir(filename):\n+        expanded.add(filename)\n+        continue\n+\n+      for root, _, files in os.walk(filename):\n+        for loopfile in files:\n+          fullname = os.path.join(root, loopfile)\n+          if fullname.startswith('.' + os.path.sep):\n+            fullname = fullname[len('.' + os.path.sep):]\n+          expanded.add(fullname)\n+\n+  filtered = []\n+  for filename in expanded:\n+      if os.path.splitext(filename)[1][1:] in GetAllExtensions():\n+          filtered.append(filename)\n+\n+  return filtered\n+\n+def _FilterExcludedFiles(filenames):\n+  \"\"\"Filters out files listed in the --exclude command line switch. File paths\n+  in the switch are evaluated relative to the current working directory\n+  \"\"\"\n+  exclude_paths = [os.path.abspath(f) for f in _excludes]\n+  return [f for f in filenames if os.path.abspath(f) not in exclude_paths]\n \n def main():\n   filenames = ParseArguments(sys.argv[1:])\n+  backup_err = sys.stderr\n+  try:\n+    # Change stderr to write with replacement characters so we don't die\n+    # if we try to print something containing non-ASCII characters.\n+    sys.stderr = codecs.StreamReaderWriter(sys.stderr,\n+                                          codecs.getreader('utf8'),\n+                                          codecs.getwriter('utf8'),\n+                                          'replace')\n \n-  # Change stderr to write with replacement characters so we don't die\n-  # if we try to print something containing non-ASCII characters.\n-  sys.stderr = codecs.StreamReaderWriter(sys.stderr,\n-                                         codecs.getreader('utf8'),\n-                                         codecs.getwriter('utf8'),\n-                                         'replace')\n+    logger.addHandler(logging.StreamHandler(sys.stdout))\n+    logger.setLevel(logging.INFO)\n \n-  logger.addHandler(logging.StreamHandler(sys.stdout))\n-  logger.setLevel(logging.INFO)\n+    _cpplint_state.ResetErrorCounts()\n+    for filename in filenames:\n+        ProcessFile(filename.decode('utf-8'), _cpplint_state.verbose_level)\n+    _cpplint_state.PrintErrorCounts()\n \n-  if _cpplint_state.output_format == 'tap':\n-    logger.info('TAP version 13')\n+    if _cpplint_state.output_format == 'tap':\n+      logger.info('TAP version 13')\n \n-  _cpplint_state.ResetErrorCounts()\n-  for filename in filenames:\n-    ProcessFile(filename.decode('utf-8'), _cpplint_state.verbose_level)\n-  _cpplint_state.PrintErrorCounts()\n+    if _cpplint_state.output_format == 'junit':\n+      sys.stderr.write(_cpplint_state.FormatJUnitXML())\n+\n+  finally:\n+    sys.stderr = backup_err\n \n   sys.exit(_cpplint_state.error_count > 0)\n "
        }
    ],
    "stats": {
        "total": 625,
        "additions": 491,
        "deletions": 134
    }
}