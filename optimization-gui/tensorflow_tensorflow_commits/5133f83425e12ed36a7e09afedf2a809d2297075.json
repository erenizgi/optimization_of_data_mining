{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 826363842",
    "sha": "5133f83425e12ed36a7e09afedf2a809d2297075",
    "files": [
        {
            "sha": "583fce11a0ef2839d725584967c1f83a39177918",
            "filename": "tensorflow/core/common_runtime/executor.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor.cc?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -134,9 +134,9 @@ void SetMemory(NodeExecStatsInterface* stats, OpKernelContext* ctx) {\n // Time the execution of kernels (in CPU cycles).  Used to dynamically identify\n // inexpensive kernels which can be dispatched inline.\n struct KernelTimer {\n-  uint64 start_cycles = profile_utils::CpuUtils::GetCurrentClockCycle();\n+  uint64_t start_cycles = profile_utils::CpuUtils::GetCurrentClockCycle();\n \n-  uint64 ElapsedCycles() {\n+  uint64_t ElapsedCycles() {\n     return profile_utils::CpuUtils::GetCurrentClockCycle() - start_cycles;\n   }\n };\n@@ -197,14 +197,14 @@ class ExecutorImpl : public Executor {\n     // given node is expensive. The new cost estimate is a weighted average of\n     // the old cost estimate and the latest cost. We only update cost estimates\n     // for kernels for which IsExpensive() return true.\n-    void UpdateCostEstimate(const NodeItem& node, uint64 elapsed_cycles) {\n+    void UpdateCostEstimate(const NodeItem& node, uint64_t elapsed_cycles) {\n       // N.B. Updates to `cost_estimate` are atomic but unlocked.  Simultaneous\n       // updates may result in one or more updates being ignored.  This does not\n       // affect correctness but may slow down the update frequency.\n       std::atomic_uint_fast64_t& cost_estimate = cost_estimates_[node.node_id];\n       auto prev_estimate = cost_estimate.load(std::memory_order_relaxed);\n \n-      uint64 new_estimate =\n+      uint64_t new_estimate =\n           ((kCostDecay - 1) * prev_estimate + elapsed_cycles) / kCostDecay;\n \n       cost_estimate.store(new_estimate, std::memory_order_relaxed);\n@@ -214,9 +214,9 @@ class ExecutorImpl : public Executor {\n     // Initial time (in CPU cycles) we expect an operation to take.  Used to\n     // determine whether an operation should be place in a threadpool.\n     // Operations start out \"expensive\".\n-    static constexpr uint64 kInitialCostEstimateCycles = 100 * 1000 * 1000;\n-    static constexpr uint64 kOpIsExpensiveThresholdCycles = 8000;\n-    static constexpr uint64 kCostDecay = 10;\n+    static constexpr uint64_t kInitialCostEstimateCycles = 100 * 1000 * 1000;\n+    static constexpr uint64_t kOpIsExpensiveThresholdCycles = 8000;\n+    static constexpr uint64_t kCostDecay = 10;\n \n     std::vector<bool> is_expensive_;\n     // std::unique_ptr<std::atomic<bool>[]> is_expensive_;\n@@ -369,14 +369,14 @@ class ExecutorState {\n   // Maximum number of kernels that can be scheduled inline. If lots of kernels\n   // are ready at the same time, scheduling them in one thread can be very slow.\n   // TODO(fishx): Make it configurable if necessary.\n-  static constexpr uint64 kInlineScheduleReadyThreshold = 500;\n+  static constexpr uint64_t kInlineScheduleReadyThreshold = 500;\n \n   // Not owned.\n   RendezvousInterface* rendezvous_;\n   CollectiveExecutor* collective_executor_ = nullptr;\n   const ConfigProto* const session_config_;\n   SessionState* session_state_;\n-  string session_handle_;\n+  std::string session_handle_;\n   const SessionMetadata* session_metadata_ = nullptr;\n   TensorStore* tensor_store_;\n   // Step-local container.\n@@ -1099,7 +1099,7 @@ absl::Status ExecutorState<PropagatorStateType>::ProcessOutputs(\n     }\n     if (s.code() == error::RESOURCE_EXHAUSTED) {\n       if (stats_collector_) {\n-        string err =\n+        std::string err =\n             stats_collector_->ReportAllocsOnResourceExhausted(s.message());\n         s = errors::CreateWithUpdatedMessage(s, absl::StrCat(s.message(), err));\n       } else {"
        },
        {
            "sha": "cbe63568f69de965606e25f90ef7b203d24046c8",
            "filename": "tensorflow/core/common_runtime/executor.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor.h?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -105,7 +105,7 @@ class Executor {\n     const ConfigProto* session_config = nullptr;\n     SessionState* session_state = nullptr;\n     // Unique session identifier. Can be empty.\n-    string session_handle;\n+    std::string session_handle;\n     TensorStore* tensor_store = nullptr;\n     ScopedStepContainer* step_container = nullptr;\n     CollectiveExecutor* collective_executor = nullptr;"
        },
        {
            "sha": "8346b47748484dcbd9e09e3b1e4572f548532bc2",
            "filename": "tensorflow/core/common_runtime/executor_factory.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor_factory.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor_factory.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor_factory.cc?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -29,15 +29,15 @@ namespace {\n \n static mutex executor_factory_lock(LINKER_INITIALIZED);\n \n-typedef std::unordered_map<string, ExecutorFactory*> ExecutorFactories;\n+typedef std::unordered_map<std::string, ExecutorFactory*> ExecutorFactories;\n ExecutorFactories* executor_factories() {\n   static ExecutorFactories* factories = new ExecutorFactories;\n   return factories;\n }\n \n }  // namespace\n \n-void ExecutorFactory::Register(const string& executor_type,\n+void ExecutorFactory::Register(const std::string& executor_type,\n                                ExecutorFactory* factory) {\n   mutex_lock l(executor_factory_lock);\n   if (!executor_factories()->insert({executor_type, factory}).second) {\n@@ -47,9 +47,9 @@ void ExecutorFactory::Register(const string& executor_type,\n }\n \n namespace {\n-const string RegisteredFactoriesErrorMessageLocked()\n+const std::string RegisteredFactoriesErrorMessageLocked()\n     TF_SHARED_LOCKS_REQUIRED(executor_factory_lock) {\n-  std::vector<string> factory_types;\n+  std::vector<std::string> factory_types;\n   for (const auto& executor_factory : *executor_factories()) {\n     factory_types.push_back(executor_factory.first);\n   }\n@@ -58,7 +58,7 @@ const string RegisteredFactoriesErrorMessageLocked()\n }\n }  // namespace\n \n-absl::Status ExecutorFactory::GetFactory(const string& executor_type,\n+absl::Status ExecutorFactory::GetFactory(const std::string& executor_type,\n                                          ExecutorFactory** out_factory) {\n   tf_shared_lock l(executor_factory_lock);\n \n@@ -73,7 +73,7 @@ absl::Status ExecutorFactory::GetFactory(const string& executor_type,\n   return absl::OkStatus();\n }\n \n-absl::Status NewExecutor(const string& executor_type,\n+absl::Status NewExecutor(const std::string& executor_type,\n                          const LocalExecutorParams& params, const Graph& graph,\n                          std::unique_ptr<Executor>* out_executor) {\n   ExecutorFactory* factory = nullptr;"
        },
        {
            "sha": "3459a4a38b06c9af7b85c5056593b4aa0c62cd20",
            "filename": "tensorflow/core/common_runtime/executor_factory.h",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor_factory.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor_factory.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor_factory.h?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -36,12 +36,13 @@ class ExecutorFactory {\n                                    std::unique_ptr<Executor>* out_executor) = 0;\n   virtual ~ExecutorFactory() {}\n \n-  static void Register(const string& executor_type, ExecutorFactory* factory);\n-  static absl::Status GetFactory(const string& executor_type,\n+  static void Register(const std::string& executor_type,\n+                       ExecutorFactory* factory);\n+  static absl::Status GetFactory(const std::string& executor_type,\n                                  ExecutorFactory** out_factory);\n };\n \n-absl::Status NewExecutor(const string& executor_type,\n+absl::Status NewExecutor(const std::string& executor_type,\n                          const LocalExecutorParams& params, const Graph& graph,\n                          std::unique_ptr<Executor>* out_executor);\n "
        },
        {
            "sha": "81719752519e56e97d99c65e31c23f8474464c85",
            "filename": "tensorflow/core/common_runtime/executor_test.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 17,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fexecutor_test.cc?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -128,7 +128,7 @@ Tensor V(const float val) {\n // A int32 val -> Tensor<int32>\n Tensor VI(const int32_t val) {\n   Tensor tensor(DT_INT32, TensorShape({}));\n-  tensor.scalar<int32>()() = val;\n+  tensor.scalar<int32_t>()() = val;\n   return tensor;\n }\n \n@@ -153,10 +153,11 @@ float V(const Tensor& tensor) {\n   return tensor.scalar<float>()();\n }\n \n-static uint64 kIncarnation = 1;  // Uses in following tests.\n+static uint64_t kIncarnation = 1;  // Uses in following tests.\n \n-Rendezvous::ParsedKey Key(const string& sender, const uint64 incarnation,\n-                          const string& receiver, const string& name) {\n+Rendezvous::ParsedKey Key(const std::string& sender, const uint64_t incarnation,\n+                          const std::string& receiver,\n+                          const std::string& name) {\n   Rendezvous::ParsedKey result;\n   CHECK(\n       Rendezvous::ParseKey(Rendezvous::CreateKey(sender, incarnation, receiver,\n@@ -508,8 +509,8 @@ static void BM_executor(::testing::benchmark::State& state) {\n   Graph* g = new Graph(OpRegistry::Global());\n   random::PhiloxRandom philox(1729, 17);\n   random::SimplePhilox rand(&philox);\n-  uint64 cur = 0;\n-  uint32 r = 1 + rand.Rand32() % width;\n+  uint64_t cur = 0;\n+  uint32_t r = 1 + rand.Rand32() % width;\n   std::vector<Node*> ready_nodes;\n   for (int i = 0; i < r; ++i) {\n     ready_nodes.push_back(test::graph::NoOp(g, {}));\n@@ -589,9 +590,9 @@ static void BM_FeedInputFetchOutput(::testing::benchmark::State& state) {\n   Node* sum = test::graph::Add(g, x, y);\n   Node* z = test::graph::Send(g, sum, \"z\", BOB, 1, ALICE);\n \n-  string x_key = test::GetRendezvousKey(x);\n-  string y_key = test::GetRendezvousKey(y);\n-  string z_key = test::GetRendezvousKey(z);\n+  std::string x_key = test::GetRendezvousKey(x);\n+  std::string y_key = test::GetRendezvousKey(y);\n+  std::string z_key = test::GetRendezvousKey(z);\n \n   Tensor val(DT_FLOAT, TensorShape({}));\n   val.scalar<float>()() = 3.14;\n@@ -603,9 +604,10 @@ static void BM_FeedInputFetchOutput(::testing::benchmark::State& state) {\n BENCHMARK(BM_FeedInputFetchOutput);\n \n absl::Status ReplaceEdgeWithSendRecv(Graph* g, const Edge* edge,\n-                                     const string& tensor, const string& sender,\n-                                     const uint64 sender_incarnation,\n-                                     const string& receiver) {\n+                                     const std::string& tensor,\n+                                     const std::string& sender,\n+                                     const uint64_t sender_incarnation,\n+                                     const std::string& receiver) {\n   Node* send;\n   NodeDef send_def;\n   TF_CHECK_OK(NodeDefBuilder(g->NewName(\"n\"), \"_Send\")\n@@ -662,16 +664,16 @@ static void BM_WhileLoopHelper(::testing::benchmark::State& state,\n   FunctionDefLibrary f_lib_proto;\n \n   // Define the loop body as a function: `x = x + 1`.\n-  const Tensor one_t = test::AsScalar<int32>(1);\n+  const Tensor one_t = test::AsScalar<int32_t>(1);\n \n-  std::vector<string> args;\n+  std::vector<std::string> args;\n   args.reserve(loop_vars);\n   args.push_back(\"x: int32\");\n   for (int i = 1; i < loop_vars; ++i) {\n     args.push_back(absl::StrCat(\"x\", i, \": int32\"));\n   }\n \n-  std::vector<string> body_rets;\n+  std::vector<std::string> body_rets;\n   body_rets.reserve(loop_vars);\n   body_rets.push_back(\"y: int32\");\n   for (int i = 1; i < loop_vars; ++i) {\n@@ -703,7 +705,7 @@ static void BM_WhileLoopHelper(::testing::benchmark::State& state,\n       body_nodes);\n \n   // Define the loop condition as a function: `x < loop_iters`.\n-  const Tensor loop_iters_t = test::AsScalar<int32>(loop_iters);\n+  const Tensor loop_iters_t = test::AsScalar<int32_t>(loop_iters);\n   *f_lib_proto.add_function() = FunctionDefHelper::Define(\n       // Name\n       \"LessThanOrEqualToN\",\n@@ -775,7 +777,7 @@ static void BM_WhileLoopHelper(::testing::benchmark::State& state,\n           if (edge->dst()->type_string() != \"Switch\") {\n             continue;\n           }\n-          string tensor_name = absl::StrCat(\"c\", edge->id());\n+          std::string tensor_name = absl::StrCat(\"c\", edge->id());\n           TF_ASSERT_OK(ReplaceEdgeWithSendRecv(graph.get(), edge, tensor_name,\n                                                BOB, 1, ALICE));\n         }"
        },
        {
            "sha": "900806923233453f85b71a242be86f613ec524f7",
            "filename": "tensorflow/core/common_runtime/function.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 25,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction.cc?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -88,7 +88,7 @@ struct Endpoint {\n   int index;\n \n   // Returns the string name represents this endpoint.\n-  string name() const {\n+  std::string name() const {\n     if (index == 0) {\n       return node->name();\n     } else {\n@@ -100,7 +100,7 @@ struct Endpoint {\n };\n \n struct EndpointHash {\n-  uint64 operator()(const Endpoint& x) const {\n+  uint64_t operator()(const Endpoint& x) const {\n     return Hash64(reinterpret_cast<const char*>(&x.node), sizeof(Node*),\n                   x.index);\n   }\n@@ -166,7 +166,7 @@ class FunctionLibraryRuntimeOverlay : public FunctionLibraryRuntime {\n       : base_flr_(base_flr), lib_def_(std::move(lib_def)) {}\n   ~FunctionLibraryRuntimeOverlay() override;\n \n-  absl::Status Instantiate(const string& function_name, AttrSlice attrs,\n+  absl::Status Instantiate(const std::string& function_name, AttrSlice attrs,\n                            const InstantiateOptions& options,\n                            Handle* handle) override;\n \n@@ -192,7 +192,7 @@ class FunctionLibraryRuntimeOverlay : public FunctionLibraryRuntime {\n   absl::Status CreateKernel(const std::shared_ptr<const NodeProperties>& props,\n                             OpKernel** kernel) override;\n \n-  bool IsStateful(const string& function_name) const override;\n+  bool IsStateful(const std::string& function_name) const override;\n \n   const FunctionLibraryDefinition* GetFunctionLibraryDefinition()\n       const override;\n@@ -204,7 +204,7 @@ class FunctionLibraryRuntimeOverlay : public FunctionLibraryRuntime {\n   std::function<void(std::function<void()>)>* runner() override;\n   const DeviceMgr* device_mgr() const override;\n \n-  string DebugString(Handle handle) override;\n+  std::string DebugString(Handle handle) override;\n   int graph_def_version() const override;\n \n   absl::Status Clone(std::unique_ptr<FunctionLibraryDefinition>* out_lib_def,\n@@ -220,7 +220,7 @@ class FunctionLibraryRuntimeOverlay : public FunctionLibraryRuntime {\n FunctionLibraryRuntimeOverlay::~FunctionLibraryRuntimeOverlay() = default;\n \n absl::Status FunctionLibraryRuntimeOverlay::Instantiate(\n-    const string& function_name, AttrSlice attrs,\n+    const std::string& function_name, AttrSlice attrs,\n     const InstantiateOptions& options, Handle* handle) {\n   // We automatically set the `lib_def` option for all instantiations, if the\n   // caller doesn't set this option explicitly.\n@@ -284,7 +284,7 @@ absl::Status FunctionLibraryRuntimeOverlay::CreateKernel(\n }\n \n bool FunctionLibraryRuntimeOverlay::IsStateful(\n-    const string& function_name) const {\n+    const std::string& function_name) const {\n   // Important: we do not forward lookup to the base FLR.\n   const OpDef* op_def;\n   const absl::Status s = lib_def_.LookUpOpDef(function_name, &op_def);\n@@ -317,7 +317,7 @@ FunctionLibraryRuntimeOverlay::GetFunctionLibraryDefinition() const {\n   return &lib_def_;\n }\n \n-string FunctionLibraryRuntimeOverlay::DebugString(Handle handle) {\n+std::string FunctionLibraryRuntimeOverlay::DebugString(Handle handle) {\n   return base_flr_->DebugString(handle);\n }\n \n@@ -348,7 +348,7 @@ class FunctionLibraryRuntimeImpl : public FunctionLibraryRuntime {\n \n   ~FunctionLibraryRuntimeImpl() override;\n \n-  absl::Status Instantiate(const string& function_name, AttrSlice attrs,\n+  absl::Status Instantiate(const std::string& function_name, AttrSlice attrs,\n                            const InstantiateOptions& options,\n                            Handle* handle) override;\n \n@@ -375,7 +375,7 @@ class FunctionLibraryRuntimeImpl : public FunctionLibraryRuntime {\n   absl::Status RunSync(Options opts, Handle handle,\n                        CallFrameInterface* call_frame) override;\n \n-  bool IsStateful(const string& function) const override;\n+  bool IsStateful(const std::string& function) const override;\n \n   // TODO: b/396484774 - Consider handling the case where the FLR is already\n   // finalized instead of always returning the pointer to the unowned library\n@@ -397,7 +397,7 @@ class FunctionLibraryRuntimeImpl : public FunctionLibraryRuntime {\n   const ConfigProto* const config_proto() override { return config_; }\n   int graph_def_version() const override { return graph_def_version_; }\n \n-  string DebugString(Handle h) override;\n+  std::string DebugString(Handle h) override;\n \n   absl::Status Clone(std::unique_ptr<FunctionLibraryDefinition>* out_lib_def,\n                      std::unique_ptr<ProcessFunctionLibraryRuntime>* out_pflr,\n@@ -416,9 +416,9 @@ class FunctionLibraryRuntimeImpl : public FunctionLibraryRuntime {\n   GraphOptimizer optimizer_;\n   const SessionMetadata* const session_metadata_;\n   Executor::Args::Runner default_runner_;\n-  const string device_name_;\n+  const std::string device_name_;\n \n-  std::function<absl::Status(const string&, const OpDef**)> get_func_sig_;\n+  std::function<absl::Status(const std::string&, const OpDef**)> get_func_sig_;\n   std::function<absl::Status(const std::shared_ptr<const NodeProperties>&,\n                              OpKernel**)>\n       create_kernel_;\n@@ -432,13 +432,13 @@ class FunctionLibraryRuntimeImpl : public FunctionLibraryRuntime {\n   // The instantiated and transformed function is encoded as a Graph\n   // object, and an executor is created for the graph.\n   struct Item {\n-    uint64 instantiation_counter = 0;\n+    uint64_t instantiation_counter = 0;\n     std::unique_ptr<const Graph> graph = nullptr;\n     const FunctionLibraryDefinition* lib_def = nullptr;  // Not owned.\n     FunctionBody* func_graph = nullptr;\n     Executor* exec = nullptr;\n     core::RefCountPtr<FunctionLibraryRuntimeOverlay> overlay_flr = nullptr;\n-    string executor_type;\n+    std::string executor_type;\n     bool allow_small_function_optimizations = false;\n     bool allow_control_flow_sync_execution = false;\n     bool function_runs_at_most_once = false;\n@@ -517,7 +517,7 @@ FunctionLibraryRuntimeImpl::FunctionLibraryRuntimeImpl(\n              absl::flat_hash_map<Handle, std::unique_ptr<Item>>>()),\n       function_handle_cache_(std::make_unique<FunctionHandleCache>(this)),\n       parent_(parent) {\n-  get_func_sig_ = [this](const string& op, const OpDef** sig) {\n+  get_func_sig_ = [this](const std::string& op, const OpDef** sig) {\n     return base_lib_def_->LookUpOpDef(op, sig);\n   };\n   create_kernel_ = [this](const std::shared_ptr<const NodeProperties>& props,\n@@ -714,7 +714,7 @@ absl::Status FunctionLibraryRuntimeImpl::FunctionDefToBody(\n     return FunctionDefToBodyHelper(std::move(record), attrs, lib_def,\n                                    get_func_sig_, fbody);\n   } else {\n-    auto get_func_sig = [lib_def](const string& op, const OpDef** sig) {\n+    auto get_func_sig = [lib_def](const std::string& op, const OpDef** sig) {\n       return lib_def->LookUpOpDef(op, sig);\n     };\n     return FunctionDefToBodyHelper(std::move(record), attrs, lib_def,\n@@ -779,7 +779,7 @@ bool FunctionLibraryRuntimeImpl::IsLocalTarget(\n }\n \n absl::Status FunctionLibraryRuntimeImpl::Instantiate(\n-    const string& function_name, AttrSlice attrs,\n+    const std::string& function_name, AttrSlice attrs,\n     const InstantiateOptions& options, Handle* handle) {\n   if (!IsLocalTarget(options)) {\n     return parent_->Instantiate(function_name, attrs, options, handle);\n@@ -796,7 +796,7 @@ absl::Status FunctionLibraryRuntimeImpl::Instantiate(\n   // in the canonical key.\n   InstantiateOptions options_copy(options);\n   options_copy.target = device_name_;\n-  const string key = Canonicalize(function_name, attrs, options_copy);\n+  const std::string key = Canonicalize(function_name, attrs, options_copy);\n \n   {\n     mutex_lock l(mu_);\n@@ -837,7 +837,7 @@ absl::Status FunctionLibraryRuntimeImpl::Instantiate(\n     if (func.name() == kGradientOp) {\n       return errors::InvalidArgument(\"Can't take gradient of SymbolicGradient\");\n     }\n-    const string grad = lib_def->FindGradient(func.name());\n+    const std::string grad = lib_def->FindGradient(func.name());\n     if (!grad.empty()) {\n       return Instantiate(grad, AttrSlice(&func.attr()), options, handle);\n     }\n@@ -941,7 +941,7 @@ absl::Status FunctionLibraryRuntimeImpl::ReleaseHandle(Handle handle) {\n absl::Status FunctionLibraryRuntimeImpl::CreateItem(Item** item) {\n   const FunctionBody* fbody;\n   FunctionLibraryRuntime* flr;\n-  string executor_type;\n+  std::string executor_type;\n   {\n     tf_shared_lock l(mu_);\n     fbody = (*item)->func_graph;\n@@ -1120,8 +1120,8 @@ void FunctionLibraryRuntimeImpl::RunRemote(const Options& opts, Handle handle,\n                                            absl::Span<const Tensor> args,\n                                            std::vector<Tensor>* rets,\n                                            Item* item, DoneCallback done) {\n-  string target_device = parent_->GetDeviceName(handle);\n-  string source_device = opts.source_device;\n+  std::string target_device = parent_->GetDeviceName(handle);\n+  std::string source_device = opts.source_device;\n   RendezvousInterface* rendezvous = opts.rendezvous;\n   DeviceContext* device_context;\n   absl::Status s = parent_->GetDeviceContext(target_device, &device_context);\n@@ -1436,13 +1436,13 @@ absl::Status FunctionLibraryRuntimeImpl::RunSync(\n   return absl::OkStatus();\n }\n \n-bool FunctionLibraryRuntimeImpl::IsStateful(const string& func) const {\n+bool FunctionLibraryRuntimeImpl::IsStateful(const std::string& func) const {\n   const OpDef* op_def;\n   const absl::Status s = base_lib_def_->LookUpOpDef(func, &op_def);\n   return s.ok() && op_def->is_stateful();\n }\n \n-string FunctionLibraryRuntimeImpl::DebugString(Handle handle) {\n+std::string FunctionLibraryRuntimeImpl::DebugString(Handle handle) {\n   Item* item = nullptr;\n   LocalHandle local_handle = parent_->GetHandleOnDevice(device_name_, handle);\n   absl::Status s = GetOrCreateItem(local_handle, &item);"
        },
        {
            "sha": "570791252dda4e5821b0415f156e2bdbf52a962e",
            "filename": "tensorflow/core/common_runtime/function_def_utils.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_def_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_def_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_def_utils.cc?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -41,7 +41,7 @@ namespace tensorflow {\n absl::Status FunctionDefToBodyHelper(\n     core::RefCountPtr<FunctionRecord>&& record, const AttrSlice& attrs,\n     const FunctionLibraryDefinition* const lib_def,\n-    const std::function<absl::Status(const string&, const OpDef**)>&\n+    const std::function<absl::Status(const std::string&, const OpDef**)>&\n         get_func_sig,\n     std::unique_ptr<FunctionBody>* fbody) {\n   // Instantiates the function template into a graph def.\n@@ -96,7 +96,8 @@ absl::Status FunctionDefToBodyHelper(core::RefCountPtr<FunctionRecord>&& record,\n                                      const AttrSlice& attrs,\n                                      const FunctionLibraryDefinition* lib_def,\n                                      std::unique_ptr<FunctionBody>* fbody) {\n-  const auto get_func_sig = [&lib_def](const string& op, const OpDef** sig) {\n+  const auto get_func_sig = [&lib_def](const std::string& op,\n+                                       const OpDef** sig) {\n     return lib_def->LookUpOpDef(op, sig);\n   };\n   return FunctionDefToBodyHelper(std::move(record), attrs, lib_def,\n@@ -109,7 +110,8 @@ absl::Status FunctionDefToBodyHelper(const FunctionDef& fdef,\n                                      std::unique_ptr<FunctionBody>* fbody) {\n   core::RefCountPtr<FunctionRecord> record(\n       new FunctionRecord(FunctionDef(fdef), {}, true));\n-  const auto get_func_sig = [&lib_def](const string& op, const OpDef** sig) {\n+  const auto get_func_sig = [&lib_def](const std::string& op,\n+                                       const OpDef** sig) {\n     return lib_def->LookUpOpDef(op, sig);\n   };\n   return FunctionDefToBodyHelper(std::move(record), attrs, lib_def,\n@@ -125,8 +127,8 @@ bool PrunableStatefulNode(const Node* n) {\n   // and can produce different results on each invocation (due to variable\n   // updates) but it does not itself modify the variable.\n   // TODO(b/341721055): Consolidate this set with other side effect modeling.\n-  static const absl::flat_hash_set<string>* prunable_stateful_ops =\n-      new absl::flat_hash_set<string>{\n+  static const absl::flat_hash_set<std::string>* prunable_stateful_ops =\n+      new absl::flat_hash_set<std::string>{\n           FunctionLibraryDefinition::kArgOp,\n           \"ResourceGather\",\n           \"ResourceGatherNd\","
        },
        {
            "sha": "589dd9304edea95fe8dbc8a931b18ce6de14d685",
            "filename": "tensorflow/core/common_runtime/function_def_utils.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_def_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_def_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_def_utils.h?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -55,7 +55,7 @@ absl::Status FunctionDefToBodyHelper(const FunctionDef& fdef,\n absl::Status FunctionDefToBodyHelper(\n     core::RefCountPtr<FunctionRecord>&& record, const AttrSlice& attrs,\n     const FunctionLibraryDefinition* lib_def,\n-    const std::function<absl::Status(const string&, const OpDef**)>&\n+    const std::function<absl::Status(const std::string&, const OpDef**)>&\n         get_func_sig,\n     std::unique_ptr<FunctionBody>* fbody);\n "
        },
        {
            "sha": "adf7ea36fdd99d22f7b01ce4cd59376a8820b301",
            "filename": "tensorflow/core/common_runtime/function_test.cc",
            "status": "modified",
            "additions": 40,
            "deletions": 39,
            "changes": 79,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_test.cc?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -74,7 +74,7 @@ using ::tsl::testing::StatusIs;\n using FDH = ::tensorflow::FunctionDefHelper;\n using OutputControlSrc = InlineFunctionBodyOptions::OutputControlSource;\n \n-absl::Status GetOpSig(const string& op, const OpDef** sig) {\n+absl::Status GetOpSig(const std::string& op, const OpDef** sig) {\n   return OpRegistry::Global()->LookUpOpDef(op, sig);\n }\n \n@@ -220,22 +220,22 @@ class FunctionLibraryRuntimeTest : public ::testing::Test {\n     return absl::OkStatus();\n   }\n \n-  absl::Status Instantiate(FunctionLibraryRuntime* flr, const string& name,\n+  absl::Status Instantiate(FunctionLibraryRuntime* flr, const std::string& name,\n                            test::function::Attrs attrs,\n                            FunctionLibraryRuntime::Handle* handle) {\n     return flr->Instantiate(name, attrs, handle);\n   }\n \n   absl::Status Instantiate(\n-      FunctionLibraryRuntime* flr, const string& name,\n+      FunctionLibraryRuntime* flr, const std::string& name,\n       test::function::Attrs attrs,\n       const FunctionLibraryRuntime::InstantiateOptions& options,\n       FunctionLibraryRuntime::Handle* handle) {\n     return flr->Instantiate(name, attrs, options, handle);\n   }\n \n   absl::Status InstantiateAndRun(FunctionLibraryRuntime* flr,\n-                                 const string& name,\n+                                 const std::string& name,\n                                  test::function::Attrs attrs,\n                                  const std::vector<Tensor>& args,\n                                  std::vector<Tensor*> rets) {\n@@ -245,7 +245,7 @@ class FunctionLibraryRuntimeTest : public ::testing::Test {\n   }\n \n   absl::Status InstantiateAndRun(\n-      FunctionLibraryRuntime* flr, const string& name,\n+      FunctionLibraryRuntime* flr, const std::string& name,\n       test::function::Attrs attrs,\n       const FunctionLibraryRuntime::InstantiateOptions& options,\n       const std::vector<Tensor>& args, std::vector<Tensor*> rets) {\n@@ -295,7 +295,7 @@ class FunctionLibraryRuntimeTest : public ::testing::Test {\n   }\n \n   absl::Status InstantiateAndRunViaCallFrameInterface(\n-      FunctionLibraryRuntime* flr, const string& name,\n+      FunctionLibraryRuntime* flr, const std::string& name,\n       test::function::Attrs attrs, const std::vector<Tensor>& args,\n       std::vector<Tensor*> rets) {\n     FunctionLibraryRuntime::Handle handle;\n@@ -331,7 +331,7 @@ class FunctionLibraryRuntimeTest : public ::testing::Test {\n   }\n \n   std::unique_ptr<Graph> GetFuncBody(FunctionLibraryRuntime* flr,\n-                                     const string& name,\n+                                     const std::string& name,\n                                      test::function::Attrs attrs) {\n     FunctionLibraryRuntime::Handle handle;\n     absl::Status status = flr->Instantiate(name, attrs, &handle);\n@@ -347,7 +347,7 @@ class FunctionLibraryRuntimeTest : public ::testing::Test {\n   }\n \n   std::unique_ptr<Graph> GetGradBody(FunctionLibraryRuntime* flr,\n-                                     const string& func,\n+                                     const std::string& func,\n                                      test::function::Attrs attrs) {\n     FunctionLibraryRuntime::Handle handle;\n     absl::Status status = flr->Instantiate(func, attrs, &handle);\n@@ -646,9 +646,9 @@ TEST_F(FunctionLibraryRuntimeTest, StateHandle) {\n       // Attrs\n       {},\n       // Nodes\n-      {FDH::Const<int32>(\"shape\", absl::Span<const int32>({1})),\n-       FDH::Const<int32>(\"minval\", 0),\n-       FDH::Const<int32>(\"maxval\", 10),\n+      {FDH::Const<int32_t>(\"shape\", absl::Span<const int32_t>({1})),\n+       FDH::Const<int32_t>(\"minval\", 0),\n+       FDH::Const<int32_t>(\"maxval\", 10),\n        // A stateful node.\n        {{\"y\"},\n         \"RandomUniformInt\",\n@@ -665,7 +665,7 @@ TEST_F(FunctionLibraryRuntimeTest, StateHandle) {\n     // Simple case: instantiating with no state_handle.\n     for (int32_t expected : {6, 4}) {\n       TF_CHECK_OK(Run(flr0_, handle, opts, {}, {&y}));\n-      test::ExpectTensorEqual<int>(y, test::AsTensor<int32>({expected}));\n+      test::ExpectTensorEqual<int>(y, test::AsTensor<int32_t>({expected}));\n     }\n   }\n \n@@ -678,7 +678,7 @@ TEST_F(FunctionLibraryRuntimeTest, StateHandle) {\n     EXPECT_EQ(handle, handle_non_isolated);\n     for (int32_t expected : {0, 1}) {\n       TF_CHECK_OK(Run(flr0_, handle_non_isolated, opts, {}, {&y}));\n-      test::ExpectTensorEqual<int>(y, test::AsTensor<int32>({expected}));\n+      test::ExpectTensorEqual<int>(y, test::AsTensor<int32_t>({expected}));\n     }\n   }\n \n@@ -693,7 +693,7 @@ TEST_F(FunctionLibraryRuntimeTest, StateHandle) {\n     EXPECT_NE(handle, handle_isolated);\n     for (int32_t expected : {6, 4, 0, 1}) {\n       TF_CHECK_OK(Run(flr0_, handle_isolated, opts, {}, {&y}));\n-      test::ExpectTensorEqual<int>(y, test::AsTensor<int32>({expected}));\n+      test::ExpectTensorEqual<int>(y, test::AsTensor<int32_t>({expected}));\n     }\n   }\n \n@@ -708,7 +708,7 @@ TEST_F(FunctionLibraryRuntimeTest, StateHandle) {\n     EXPECT_NE(handle, handle_isolated);\n     for (int32_t expected : {6, 4, 0, 1}) {\n       TF_CHECK_OK(Run(flr0_, handle_isolated, opts, {}, {&y}));\n-      test::ExpectTensorEqual<int>(y, test::AsTensor<int32>({expected}));\n+      test::ExpectTensorEqual<int>(y, test::AsTensor<int32_t>({expected}));\n     }\n   }\n \n@@ -725,7 +725,7 @@ TEST_F(FunctionLibraryRuntimeTest, StateHandle) {\n       EXPECT_NE(handle, handle_isolated);\n       for (int32_t expected : {6, 4, 0, 1}) {\n         TF_CHECK_OK(Run(flr0_, handle_isolated, opts, {}, {&y}));\n-        test::ExpectTensorEqual<int>(y, test::AsTensor<int32>({expected}));\n+        test::ExpectTensorEqual<int>(y, test::AsTensor<int32_t>({expected}));\n       }\n       TF_CHECK_OK(flr0_->ReleaseHandle(handle_isolated));\n     }\n@@ -1128,9 +1128,9 @@ TEST_F(FunctionLibraryRuntimeTest,\n   std::unique_ptr<Graph> g;\n   ExpandInlineFunctionsOptions opts;\n \n-  const string input_node = \"Func/b/input/_0\";\n-  const string output_node = \"Func/b/output/_1\";\n-  const string output_control_node = \"Func/b/output_control_node/_2\";\n+  const std::string input_node = \"Func/b/input/_0\";\n+  const std::string output_node = \"Func/b/output/_1\";\n+  const std::string output_control_node = \"Func/b/output_control_node/_2\";\n \n   // Use data outputs as output control source.\n   opts.native_options.output_control_src = OutputControlSrc::kDataOutputs;\n@@ -1203,9 +1203,9 @@ TEST_F(FunctionLibraryRuntimeTest, ExpandInlineFunctionsAndKeepCallerNode) {\n     return absl::OkStatus();\n   };\n \n-  const string input_node = \"Func/b/input/_0\";\n-  const string output_node = \"Func/b/output/_1\";\n-  const string output_control_node = \"Func/b/output_control_node/_2\";\n+  const std::string input_node = \"Func/b/input/_0\";\n+  const std::string output_node = \"Func/b/output/_1\";\n+  const std::string output_control_node = \"Func/b/output_control_node/_2\";\n \n   // Construct expected graph after function inlining.\n   auto expected_graph = [&](const NodeDef& caller) -> GraphDef {\n@@ -1266,9 +1266,9 @@ TEST_F(FunctionLibraryRuntimeTest, ExpandInlineFunctionsAndPlaceInlinedNodes) {\n   using test::function::NDef;\n   using KeepCallerNode = InlineFunctionBodyOptions::KeepCallerNode;\n \n-  const string arg_device = \"/job:arg/replica:0/task:0/device:GPU\";\n-  const string call_device = \"/job:call/replica:0/task:1/device:GPU\";\n-  const string body_device = \"/job:body/replica:0/task:1/device:CPU\";\n+  const std::string arg_device = \"/job:arg/replica:0/task:0/device:GPU\";\n+  const std::string call_device = \"/job:call/replica:0/task:1/device:GPU\";\n+  const std::string body_device = \"/job:body/replica:0/task:1/device:CPU\";\n \n   const FunctionDef func = FDH::Create(\n       \"AddFunc\", {\"i: float\"}, {\"o: float\"}, {},\n@@ -1291,12 +1291,13 @@ TEST_F(FunctionLibraryRuntimeTest, ExpandInlineFunctionsAndPlaceInlinedNodes) {\n     return absl::OkStatus();\n   };\n \n-  const string input_node = \"Func/b/input/_0\";\n-  const string output_node = \"Func/b/output/_1\";\n-  const string output_control_node = \"Func/b/output_control_node/_2\";\n+  const std::string input_node = \"Func/b/input/_0\";\n+  const std::string output_node = \"Func/b/output/_1\";\n+  const std::string output_control_node = \"Func/b/output_control_node/_2\";\n \n   // Construct expected graph after function inlining.\n-  auto expected_graph = [&](const std::vector<string>& placed) -> GraphDef {\n+  auto expected_graph =\n+      [&](const std::vector<std::string>& placed) -> GraphDef {\n     return test::function::GDef(\n         {\n             NDef(\"a\", \"_Arg\", {}, {{\"T\", DT_FLOAT}, {\"index\", 0}}, placed[0]),\n@@ -1364,7 +1365,7 @@ TEST_F(FunctionLibraryRuntimeTest, ExpandInlineFunctionsAndPlaceInlinedNodes) {\n     auto g = std::make_unique<Graph>(OpRegistry::Global());\n     TF_ASSERT_OK(construct_graph(&g));\n \n-    const string merged_device = \"/job:body/replica:0/task:1/device:CPU:*\";\n+    const std::string merged_device = \"/job:body/replica:0/task:1/device:CPU:*\";\n \n     ExpandInlineFunctions(flr0_, g.get(), opts);\n     GraphDef expected = expected_graph({/*a*/ arg_device,                //\n@@ -1400,7 +1401,7 @@ TEST_F(FunctionLibraryRuntimeTest, PruneBody) {\n        {{\"x1\"}, \"Add\", {\"o\", \"o\"}, {{\"T\", T}}},\n        {{\"x2\"}, \"Mul\", {\"a\", \"x1\"}, {{\"T\", T}}},\n        {{\"x3\"}, \"Mul\", {\"x1\", \"x2\"}, {{\"T\", T}}},\n-       FDH::Const<int32>(\"shape\", {1, 2}),\n+       FDH::Const<int32_t>(\"shape\", {1, 2}),\n        // A stateful node.\n        {{\"keep_me\"},\n         \"RandomUniform\",\n@@ -1410,7 +1411,7 @@ TEST_F(FunctionLibraryRuntimeTest, PruneBody) {\n        {{\"z\"}, \"Add\", {\"a\", \"o\"}, {{\"T\", T}}}});\n   Init({stateful_func});\n \n-  auto x = test::AsTensor<int32>({1, 2, 3, 4});\n+  auto x = test::AsTensor<int32_t>({1, 2, 3, 4});\n   auto y = test::AsTensor<float>({1.0, 2.0, 3.0, 4.0});\n   Tensor z;\n \n@@ -1427,15 +1428,15 @@ TEST_F(FunctionLibraryRuntimeTest, PruneBody) {\n \n   TF_CHECK_OK(InstantiateAndRun(flr0_, \"SquareAndAddOneWithStatefulNodes\", {},\n                                 {x, y}, {&z}));\n-  test::ExpectTensorEqual<int>(z, test::AsTensor<int32>({2, 5, 10, 17}));\n+  test::ExpectTensorEqual<int>(z, test::AsTensor<int32_t>({2, 5, 10, 17}));\n \n   stats_collector.FinalizeAndSwap(&stats);\n \n   // Note that we do not expect the nodes named \"y\", \"x1\", \"x2\", or \"x3\" to\n   // execute.\n-  std::set<string> expected_node_names(\n+  std::set<std::string> expected_node_names(\n       {\"_SOURCE\", \"shape\", \"x\", \"o\", \"a\", \"keep_me\", \"z\", \"z_RetVal\"});\n-  std::set<string> executed_node_names;\n+  std::set<std::string> executed_node_names;\n   for (const auto& node_stats : stats.dev_stats()[0].node_stats()) {\n     executed_node_names.insert(node_stats.node_name());\n   }\n@@ -1475,9 +1476,9 @@ TEST_F(FunctionLibraryRuntimeTest, DoNotPruneControlOutputsFromBody) {\n \n   stats_collector.FinalizeAndSwap(&stats);\n \n-  std::set<string> expected_node_names(\n+  std::set<std::string> expected_node_names(\n       {\"_SOURCE\", \"i\", \"add\", \"ret\", \"o_RetVal\"});\n-  std::set<string> executed_node_names;\n+  std::set<std::string> executed_node_names;\n   for (const auto& node_stats : stats.dev_stats()[0].node_stats()) {\n     executed_node_names.insert(node_stats.node_name());\n   }\n@@ -1645,7 +1646,7 @@ TEST_F(FunctionLibraryRuntimeTest, Error_InstantiationError) {\n \n TEST_F(FunctionLibraryRuntimeTest, Error_BadControlFlow) {\n   Init({test::function::InvalidControlFlow()});\n-  auto x = test::AsTensor<int32>({0});\n+  auto x = test::AsTensor<int32_t>({0});\n   DCHECK_EQ(x.dtype(), DT_INT32);\n   Tensor y;\n   HasError(InstantiateAndRun(flr0_, \"InvalidControlFlow\", {}, {x}, {&y}),\n@@ -2117,7 +2118,7 @@ TEST_F(FunctionLibraryRuntimeTest, FullTypeForInt32) {\n        {{\"z\"}, \"Add\", {\"x\", \"x\"}, {{\"T\", T}}}});\n   Init({int32_func});\n \n-  auto x = test::AsTensor<int32>({1, 2, 3, 4});\n+  auto x = test::AsTensor<int32_t>({1, 2, 3, 4});\n   auto y = test::AsTensor<float>({1.0, 2.0, 3.0, 4.0});\n   Tensor z;\n "
        },
        {
            "sha": "a37f05da7df38ea8f04df6e9a6a4d3a96e6030d2",
            "filename": "tensorflow/core/common_runtime/function_testlib.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_testlib.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_testlib.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_testlib.cc?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -126,8 +126,8 @@ FunctionDef BlockingOpFn() {\n }\n \n // TODO(phawkins): replace with C++ API for calling functions, when that exists.\n-Output Call(Scope* scope, const string& op_name, const string& fn_name,\n-            absl::Span<const Input> inputs) {\n+Output Call(Scope* scope, const std::string& op_name,\n+            const std::string& fn_name, absl::Span<const Input> inputs) {\n   NodeDef def;\n   NodeDefBuilder builder(op_name, fn_name, scope->graph()->op_registry());\n   for (const Input& input : inputs) {"
        },
        {
            "sha": "b71acef0c834084715c8f3d23f0ed6029a7f7a17",
            "filename": "tensorflow/core/common_runtime/function_testlib.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_testlib.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_testlib.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_testlib.h?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -44,8 +44,8 @@ FunctionDef BlockingOpFn();\n \n // Adds a function call to the given scope and returns the output for the node.\n // TODO(phawkins): replace with C++ API for calling functions, when that exists.\n-Output Call(Scope* scope, const string& op_name, const string& fn_name,\n-            absl::Span<const Input> inputs);\n+Output Call(Scope* scope, const std::string& op_name,\n+            const std::string& fn_name, absl::Span<const Input> inputs);\n \n }  // namespace function\n }  // namespace test"
        },
        {
            "sha": "4c6846593885f5b220363d67a408a459e1eb5a59",
            "filename": "tensorflow/core/common_runtime/function_threadpool_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_threadpool_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_threadpool_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_threadpool_test.cc?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -81,7 +81,7 @@ class FunctionLibraryRuntimeTest : public ::testing::Test {\n                    FunctionLibraryRuntime::Options opts,\n                    const std::vector<Tensor>& args, std::vector<Tensor*> rets,\n                    bool add_runner = true) {\n-    std::atomic<int32> call_count(0);\n+    std::atomic<int32_t> call_count(0);\n     std::function<void(std::function<void()>)> runner =\n         [&call_count](std::function<void()> fn) {\n           ++call_count;\n@@ -115,22 +115,22 @@ class FunctionLibraryRuntimeTest : public ::testing::Test {\n     return absl::OkStatus();\n   }\n \n-  absl::Status Instantiate(FunctionLibraryRuntime* flr, const string& name,\n+  absl::Status Instantiate(FunctionLibraryRuntime* flr, const std::string& name,\n                            test::function::Attrs attrs,\n                            FunctionLibraryRuntime::Handle* handle) {\n     return flr->Instantiate(name, attrs, handle);\n   }\n \n   absl::Status Instantiate(\n-      FunctionLibraryRuntime* flr, const string& name,\n+      FunctionLibraryRuntime* flr, const std::string& name,\n       test::function::Attrs attrs,\n       const FunctionLibraryRuntime::InstantiateOptions& options,\n       FunctionLibraryRuntime::Handle* handle) {\n     return flr->Instantiate(name, attrs, options, handle);\n   }\n \n   absl::Status InstantiateAndRun(FunctionLibraryRuntime* flr,\n-                                 const string& name,\n+                                 const std::string& name,\n                                  test::function::Attrs attrs,\n                                  const std::vector<Tensor>& args,\n                                  std::vector<Tensor*> rets,\n@@ -141,7 +141,7 @@ class FunctionLibraryRuntimeTest : public ::testing::Test {\n   }\n \n   absl::Status InstantiateAndRun(\n-      FunctionLibraryRuntime* flr, const string& name,\n+      FunctionLibraryRuntime* flr, const std::string& name,\n       test::function::Attrs attrs,\n       const FunctionLibraryRuntime::InstantiateOptions& options,\n       const std::vector<Tensor>& args, std::vector<Tensor*> rets,\n@@ -171,7 +171,7 @@ class FunctionLibraryRuntimeTest : public ::testing::Test {\n                    FunctionLibraryRuntime::Handle handle,\n                    FunctionLibraryRuntime::Options opts,\n                    CallFrameInterface* frame, bool add_runner = true) {\n-    std::atomic<int32> call_count(0);\n+    std::atomic<int32_t> call_count(0);\n     std::function<void(std::function<void()>)> runner =\n         [&call_count](std::function<void()> fn) {\n           ++call_count;\n@@ -232,7 +232,7 @@ TEST_F(FunctionLibraryRuntimeTest, DefaultThreadpool) {\n   TF_CHECK_OK(Instantiate(flr0_, \"XTimesTwo\", {{\"T\", DT_FLOAT}}, &h));\n \n   auto x1 = test::AsTensor<float>({1, 2, 3, 4});\n-  std::atomic<int32> num_done(0);\n+  std::atomic<int32_t> num_done(0);\n   FunctionLibraryRuntime::Options opts;\n   for (int i = 0; i < 4; ++i) {\n     tp1->Schedule([&h, &x1, &opts, &num_done, this]() {"
        },
        {
            "sha": "736dcc4db4811b9714e372710f7b07a851cf9691",
            "filename": "tensorflow/core/common_runtime/function_utils.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_utils.cc?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -36,7 +36,7 @@ struct Endpoint {\n   int index;\n \n   // Returns the string name represents this endpoint.\n-  string name() const {\n+  std::string name() const {\n     if (index == 0) {\n       return node->name();\n     } else {\n@@ -285,7 +285,7 @@ bool IsFunctionCall(const FunctionLibraryDefinition& lib_def,\n   return node.IsFunctionCall();\n }\n \n-string NewName(const Node* n, bool pretty) {\n+std::string NewName(const Node* n, bool pretty) {\n   if (pretty) {\n     return absl::StrCat(n->type_string(), n->id());\n   } else {\n@@ -347,7 +347,7 @@ void ToGraphDef(const Graph* g, GraphDef* gdef, bool pretty) {\n         ndef->add_input(\"unknown\");\n         continue;\n       }\n-      const string srcname = NewName(e->src(), pretty);\n+      const std::string srcname = NewName(e->src(), pretty);\n       if (!e->src()->IsOp()) {\n       } else if (e->IsControlEdge()) {\n         ndef->add_input(absl::StrCat(\"^\", srcname));\n@@ -360,7 +360,7 @@ void ToGraphDef(const Graph* g, GraphDef* gdef, bool pretty) {\n   });\n }\n \n-string DebugString(const Graph* g) {\n+std::string DebugString(const Graph* g) {\n   GraphDef gdef;\n   ToGraphDef(g, &gdef);\n   return DebugString(gdef);"
        },
        {
            "sha": "97cd4cc63e8ea4af8ca7937f488f7e0135b3449c",
            "filename": "tensorflow/core/common_runtime/function_utils.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5133f83425e12ed36a7e09afedf2a809d2297075/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Ffunction_utils.h?ref=5133f83425e12ed36a7e09afedf2a809d2297075",
            "patch": "@@ -34,7 +34,7 @@ class OpDef;\n \n // Debugging facility.  Returns a debug string for a graph\n // representing an instantiated function.\n-string DebugString(const Graph* g);\n+std::string DebugString(const Graph* g);\n \n // Dump the contents of the \"graph\" to log files if the logging level is\n // sufficiently high."
        }
    ],
    "stats": {
        "total": 252,
        "additions": 129,
        "deletions": 123
    }
}