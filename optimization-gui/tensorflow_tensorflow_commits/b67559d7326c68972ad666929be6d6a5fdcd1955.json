{
    "author": "beckerhe",
    "message": "Remove `Compiler*` argument from AotCompilationResult::LoadExecutable\n\nLoading an executable should not depend on the Compiler instance. If a particular instance needs access to the Compiler, it can keep a Compiler* in its implementation. So that's what I'm doing for LegacyGpuAotCompilationResult which in fact needs the compiler to produce an executable.\n\nI had to make `Compiler::Export` non-const for this to work, but this will go away again in a subsequent change which moves `Export` to `Executable`.\n\nPiperOrigin-RevId: 843160651",
    "sha": "b67559d7326c68972ad666929be6d6a5fdcd1955",
    "files": [
        {
            "sha": "1042ff1fa7a896d04f382f1bfef2b1865d964f6f",
            "filename": "tensorflow/compiler/aot/codegen.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -1206,9 +1206,9 @@ absl::StatusOr<EmbeddedConstantBuffers> GenerateConstantBuffersData(\n       auto aot_thunk_result_temp,\n       xla::cpu::CpuAotCompilationResult::FromString(serialized, nullptr));\n \n-  TF_ASSIGN_OR_RETURN(\n-      auto executable,\n-      std::move(*aot_thunk_result_temp).LoadExecutable(nullptr, nullptr));\n+  TF_ASSIGN_OR_RETURN(auto executable,\n+                      std::move(*aot_thunk_result_temp)\n+                          .LoadExecutable(/*stream_exec=*/nullptr));\n \n   xla::cpu::CpuExecutable* cpu_executable =\n       tsl::down_cast<xla::cpu::CpuExecutable*>(executable.get());"
        },
        {
            "sha": "68c4d7f90b204c428235ec2f1054c62d52e704e0",
            "filename": "tensorflow/compiler/tf2xla/xla_compiled_cpu_function_thunks.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function_thunks.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function_thunks.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function_thunks.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -50,7 +50,7 @@ XlaCompiledCpuFunctionThunks::XlaCompiledCpuFunctionThunks(\n   TF_CHECK_OK(aot_compilation_result.status());\n   // NO_CDC: aot_compilation_result is checked to be OK above.\n   auto cpu_executable = std::move(*aot_compilation_result.value())\n-                            .LoadExecutable(nullptr, nullptr);\n+                            .LoadExecutable(/*stream_exec=*/nullptr);\n \n   TF_CHECK_OK(cpu_executable.status());\n   auto executable_or_err ="
        },
        {
            "sha": "aa0a0e4c28905506ff2aeec93a6051ee19c7bff6",
            "filename": "third_party/xla/xla/client/local_client.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 8,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fclient%2Flocal_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fclient%2Flocal_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fclient%2Flocal_client.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -482,29 +482,26 @@ absl::StatusOr<std::unique_ptr<LocalExecutable>> LocalClient::Load(\n   TF_ASSIGN_OR_RETURN(\n       std::unique_ptr<xla::AotCompilationResult> aot_result,\n       compiler->LoadAotCompilationResult(serialized_aot_result));\n-  return LoadInternal(std::move(aot_result), compiler.get(), options);\n+  return LoadInternal(std::move(aot_result), options);\n }\n \n absl::StatusOr<std::unique_ptr<LocalExecutable>> LocalClient::Load(\n     std::unique_ptr<xla::AotCompilationResult> aot_result,\n     const ExecutableBuildOptions& options) {\n-  TF_ASSIGN_OR_RETURN(std::unique_ptr<Compiler> compiler,\n-                      Compiler::GetForPlatform(platform()));\n-  return LoadInternal(std::move(aot_result), compiler.get(), options);\n+  return LoadInternal(std::move(aot_result), options);\n }\n \n absl::StatusOr<std::unique_ptr<LocalExecutable>> LocalClient::LoadInternal(\n-    std::unique_ptr<xla::AotCompilationResult> aot_result, Compiler* compiler,\n+    std::unique_ptr<xla::AotCompilationResult> aot_result,\n     const ExecutableBuildOptions& options) {\n   TF_ASSIGN_OR_RETURN(ExecutableBuildOptions updated_options,\n                       UpdateBuildOptions(options, default_device_ordinal()));\n   TF_ASSIGN_OR_RETURN(\n       se::StreamExecutor * executor,\n       backend().stream_executor(updated_options.device_ordinal()));\n \n-  TF_ASSIGN_OR_RETURN(\n-      std::unique_ptr<Executable> executable,\n-      std::move(*aot_result).LoadExecutable(compiler, executor));\n+  TF_ASSIGN_OR_RETURN(std::unique_ptr<Executable> executable,\n+                      std::move(*aot_result).LoadExecutable(executor));\n   return std::make_unique<LocalExecutable>(std::move(executable),\n                                            local_service_->mutable_backend(),\n                                            updated_options);"
        },
        {
            "sha": "4429dc84664f6ba66308c83029a91010ccc90fd9",
            "filename": "third_party/xla/xla/client/local_client.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fclient%2Flocal_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fclient%2Flocal_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fclient%2Flocal_client.h?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -249,7 +249,7 @@ class LocalClient : public Client {\n   LocalService* local_service_;\n \n   absl::StatusOr<std::unique_ptr<LocalExecutable>> LoadInternal(\n-      std::unique_ptr<xla::AotCompilationResult> aot_result, Compiler* compiler,\n+      std::unique_ptr<xla::AotCompilationResult> aot_result,\n       const ExecutableBuildOptions& options);\n };\n "
        },
        {
            "sha": "8a5e603efd34e69808ebee22b85295f1b88ad7df",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -488,7 +488,7 @@ PjRtCpuClient::LoadSerializedExecutable(absl::string_view serialized,\n                       compiler.LoadAotCompilationResult(str));\n   TF_ASSIGN_OR_RETURN(\n       std::unique_ptr<Executable> executable,\n-      std::move(*aot_result).LoadExecutable(&compiler, /*executor=*/nullptr));\n+      std::move(*aot_result).LoadExecutable(/*executor=*/nullptr));\n \n   // Set up other arguments for PjRtCpuExecutable\n   // TODO(b/232263665): Remove duplicated code in DeserializeExecutable and\n@@ -620,7 +620,7 @@ static absl::StatusOr<std::unique_ptr<xla::Executable>> CompileAheadOfTime(\n   TF_ASSIGN_OR_RETURN(std::unique_ptr<AotCompilationResult> aot_result,\n                       compiler.LoadAotCompilationResult(serialized_aot_result));\n \n-  return std::move(*aot_result).LoadExecutable(&compiler, /*executor=*/nullptr);\n+  return std::move(*aot_result).LoadExecutable(/*executor=*/nullptr);\n }\n \n absl::StatusOr<std::unique_ptr<PjRtLoadedExecutable>>"
        },
        {
            "sha": "8aa72f6c944892a13c7c5c597b7297aaac0f74da",
            "filename": "third_party/xla/xla/pjrt/gpu/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -462,7 +462,7 @@ cc_library(\n         \"//xla:status_macros\",\n         \"//xla/hlo/builder:xla_computation\",\n         \"//xla/hlo/ir:hlo\",\n-        \"//xla/hlo/ir:hlo_module_group\",\n+        \"//xla/mlir_hlo:mhlo_passes\",\n         \"//xla/pjrt:mlir_to_hlo\",\n         \"//xla/pjrt:pjrt_client\",\n         \"//xla/pjrt:pjrt_compiler\",\n@@ -480,9 +480,11 @@ cc_library(\n         \"//xla/stream_executor:platform_manager\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/synchronization\",\n         \"@llvm-project//mlir:IR\",\n         \"@local_tsl//tsl/platform:casts\",\n     ],\n@@ -536,7 +538,9 @@ cc_library(\n         \"//xla/pjrt:pjrt_executable\",\n         \"//xla/service:compiler\",\n         \"//xla/stream_executor:platform\",\n+        \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/synchronization\",\n         \"@llvm-project//mlir:IR\",\n     ] + if_cuda([\n         \":se_gpu_pjrt_compiler_cuda_registration\","
        },
        {
            "sha": "bb0668ba72cf28d86fdf3f932b040973038a3bba",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_compiler.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 9,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -25,11 +25,12 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"absl/synchronization/mutex.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n-#include \"xla/hlo/ir/hlo_module_group.h\"\n #include \"xla/layout_util.h\"\n+#include \"xla/mlir_hlo/mhlo/transforms/passes.h\"\n #include \"xla/pjrt/gpu/se_gpu_pjrt_client.h\"\n #include \"xla/pjrt/gpu/se_gpu_topology_description.h\"\n #include \"xla/pjrt/mlir_to_hlo.h\"\n@@ -110,18 +111,27 @@ StreamExecutorGpuCompiler::StreamExecutorGpuCompiler(\n     stream_executor::Platform::Id platform_id)\n     : requested_platform_id_(platform_id) {}\n \n+absl::StatusOr<Compiler*> StreamExecutorGpuCompiler::GetOrCreateCompiler() {\n+  absl::MutexLock lock(compiler_mutex_);\n+  if (compiler_ == nullptr) {\n+    // We get the compiler here because doing so in the constructor might fail\n+    // due to static initialization order shenanigans (An instance of this class\n+    // is initialized statically and this might happen before the compiler is\n+    // registered with Compiler::RegisterCompilerFactory). For the same reason,\n+    // we can't fail construction of this class, therefore we have this\n+    // GetOrCreate function and we can return on error when calling Compile.\n+    TF_ASSIGN_OR_RETURN(compiler_,\n+                        GetCompilerForPlatform(requested_platform_id_));\n+  }\n+  return compiler_.get();\n+}\n+\n absl::StatusOr<std::unique_ptr<PjRtExecutable>>\n StreamExecutorGpuCompiler::Compile(CompileOptions options,\n                                    const XlaComputation& computation,\n                                    const PjRtTopologyDescription& topology,\n                                    PjRtClient* client) {\n-  // We get the compiler here because doing so in the constructor might fail due\n-  // to static initialization order shenanigans. Also we can't fail construction\n-  // of this class because it's also statically constructed.\n-  // TODO(b/382417973): Use factories instead of static initialization of\n-  // singletons.\n-  TF_ASSIGN_OR_RETURN(auto gpu_compiler,\n-                      GetCompilerForPlatform(requested_platform_id_));\n+  TF_ASSIGN_OR_RETURN(Compiler * gpu_compiler, GetOrCreateCompiler());\n \n   CompileOptions input_options = options;\n   if (!options.gpu_target_config) {\n@@ -165,7 +175,7 @@ StreamExecutorGpuCompiler::Compile(CompileOptions options,\n       HloModule::CreateFromProto(hlo_module_proto, *hlo_config));\n   UpdateEntryComputationLayout(\n       hlo_module.get(), std::bind(&Compiler::DefaultDeviceShapeRepresentation,\n-                                  gpu_compiler.get(), std::placeholders::_1));\n+                                  gpu_compiler, std::placeholders::_1));\n   DumpHloModuleIfEnabled(*hlo_module, kBeforeOptimizationsDumpName);\n   Compiler::CompileOptions opts;\n   opts.gpu_target_config = options.gpu_target_config;"
        },
        {
            "sha": "16728c2f6f6dbb29cd97c766ebc413bb4a102141",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_compiler.h",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.h?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -19,11 +19,14 @@ limitations under the License.\n #include <memory>\n #include <optional>\n \n+#include \"absl/base/thread_annotations.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/synchronization/mutex.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_executable.h\"\n+#include \"xla/service/compiler.h\"\n #include \"xla/stream_executor/platform.h\"\n \n namespace xla {\n@@ -49,6 +52,13 @@ class StreamExecutorGpuCompiler : public PjRtCompiler {\n \n  private:\n   std::optional<stream_executor::Platform::Id> requested_platform_id_;\n+  mutable absl::Mutex compiler_mutex_;\n+  std::unique_ptr<Compiler> compiler_ ABSL_GUARDED_BY(compiler_mutex_);\n+\n+  // Returns an instance of the compiler for the given platform (or the default\n+  // GPU platform if none is specified). If one does not exist, creates one. The\n+  // compiler is cached for subsequent calls.\n+  absl::StatusOr<Compiler*> GetOrCreateCompiler();\n };\n }  // namespace xla\n #endif  // XLA_PJRT_GPU_SE_GPU_PJRT_COMPILER_H_"
        },
        {
            "sha": "b47c105d72160c6013c6bb95539a00c83d31dc48",
            "filename": "third_party/xla/xla/service/compiler.h",
            "status": "modified",
            "additions": 9,
            "deletions": 3,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.h?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -28,7 +28,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n-#include \"absl/base/attributes.h\"\n+#include \"absl/base/macros.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n@@ -85,10 +85,16 @@ class AotCompilationResult {\n   }\n \n   virtual absl::StatusOr<std::unique_ptr<Executable>> LoadExecutable(\n-      Compiler* compiler, const se::StreamExecutor* executor) && {\n+      const se::StreamExecutor* executor) && {\n     return Unimplemented(\"LoadExecutable unimplemented.\");\n   }\n \n+  ABSL_DEPRECATE_AND_INLINE()\n+  absl::StatusOr<std::unique_ptr<Executable>> LoadExecutable(\n+      Compiler*, const se::StreamExecutor* executor) && {\n+    return std::move(*this).LoadExecutable(executor);\n+  }\n+\n   virtual absl::StatusOr<std::unique_ptr<BufferAssignment>> buffer_assignment()\n       const {\n     return Unimplemented(\"buffer_assignment unimplemented.\");\n@@ -356,7 +362,7 @@ class Compiler {\n \n   // Returns an AotCompilationResult of the executable for serialization.\n   virtual absl::StatusOr<std::unique_ptr<AotCompilationResult>> Export(\n-      Executable* executable) const {\n+      Executable* executable) {\n     return Unimplemented(\"Export unimplemented\");\n   }\n "
        },
        {
            "sha": "ad60a542567127503ee56b4da90100c226827e51",
            "filename": "third_party/xla/xla/service/cpu/cpu_aot_compilation_result.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 8,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -146,7 +146,6 @@ CpuAotCompilationResult::CpuAotCompilationResult(\n \n absl::StatusOr<std::unique_ptr<Executable>>\n CpuAotCompilationResult::LoadExecutable(\n-    [[maybe_unused]] Compiler* compiler,\n     const se::StreamExecutor* stream_exec) && {\n   TF_ASSIGN_OR_RETURN(\n       std::unique_ptr<HloModule> module,\n@@ -156,13 +155,9 @@ CpuAotCompilationResult::LoadExecutable(\n \n   // Copied from cpu_compiler.cc in order to avoid dependency on cpu_compiler.\n   std::function<int64_t(const BufferValue&)> buffer_size_bytes_function_getter =\n-      compiler ? compiler->BufferSizeBytesFunction() : []() {\n-        HloCostAnalysis::ShapeSizeFunction shape_size =\n-            CpuExecutable::ShapeSizeBytes;\n-        return [shape_size](const BufferValue& buffer) {\n-          return shape_size(buffer.shape());\n-        };\n-      }();\n+      [](const BufferValue& buffer) {\n+        return CpuExecutable::ShapeSizeBytes(buffer.shape());\n+      };\n \n   // Recreate BufferAssignment from proto.\n   AliasInfo alias_info;"
        },
        {
            "sha": "1f845de703b5ec3b8f8e7c40e756bed9df38414b",
            "filename": "third_party/xla/xla/service/cpu/cpu_aot_compilation_result.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -116,10 +116,10 @@ class CpuAotCompilationResult : public AotCompilationResult {\n     return proto_.SerializeAsString();\n   }\n \n-  absl::StatusOr<std::unique_ptr<Executable>> LoadExecutable(\n-      [[maybe_unused]] Compiler* compiler,\n-      const se::StreamExecutor* stream_exec) &&\n-      override;\n+  using AotCompilationResult::LoadExecutable;\n+\n+  absl::StatusOr<std::unique_ptr<Executable>>\n+      LoadExecutable(const se::StreamExecutor* stream_exec) && override;\n \n   const HloModule* optimized_module() const override { return module_.get(); }\n "
        },
        {
            "sha": "114829539d4e8e0382dc528e713893862a915096",
            "filename": "third_party/xla/xla/service/cpu/cpu_aot_compiler_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compiler_test.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -112,8 +112,7 @@ ENTRY e {\n \n     TF_ASSERT_OK_AND_ASSIGN(\n         std::unique_ptr<Executable> executable,\n-        std::move(*aot_result)\n-            .LoadExecutable(compiler, aot_options->executor()));\n+        std::move(*aot_result).LoadExecutable(aot_options->executor()));\n     std::unique_ptr<OpaqueExecutable> wrapped_executable =\n         test_runner_as_hlo_runner().WrapExecutable(std::move(executable));\n "
        },
        {
            "sha": "9175ab43b332165b0f6cda246433b6ff8a3d2f8a",
            "filename": "third_party/xla/xla/service/cpu/cpu_aot_loader.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_loader.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_loader.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_loader.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -148,7 +148,7 @@ absl::StatusOr<std::unique_ptr<Executable>> CpuAotLoader::LoadExecutable(\n \n absl::StatusOr<std::unique_ptr<Executable>> CpuAotLoader::LoadExecutable(\n     xla::AotCompilationResult&& compilation_result) {\n-  return std::move(compilation_result).LoadExecutable(nullptr, nullptr);\n+  return std::move(compilation_result).LoadExecutable(/*executor=*/nullptr);\n }\n \n absl::StatusOr<std::unique_ptr<AotCompilationResult>>"
        },
        {
            "sha": "5cced18ff842468a4709b3a12585d2cc6f1796ff",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -2273,7 +2273,7 @@ HloCostAnalysis::ShapeSizeFunction CpuCompiler::ShapeSizeBytesFunction() const {\n }\n \n absl::StatusOr<std::unique_ptr<AotCompilationResult>> CpuCompiler::Export(\n-    Executable* executable) const {\n+    Executable* executable) {\n   auto* cpu_executable = tensorflow::down_cast<CpuExecutable*>(executable);\n   if (!cpu_executable)\n     return Internal(\"Could not downcast Executable to CpuExecutable\");"
        },
        {
            "sha": "a01fef46396135e02b6e406a8d85bc9d06d9cc29",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.h?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -82,7 +82,7 @@ class CpuCompiler : public LLVMCompiler {\n   HloCostAnalysis::ShapeSizeFunction ShapeSizeBytesFunction() const override;\n \n   absl::StatusOr<std::unique_ptr<AotCompilationResult>> Export(\n-      Executable* executable) const override;\n+      Executable* executable) override;\n \n   // Returns a (deserialized) AotCompilationResult from a serialized\n   // AotCompilationResult."
        },
        {
            "sha": "e69757ba09d09537e2e39d30eee175ca763441ca",
            "filename": "third_party/xla/xla/service/cpu/tests/cpu_aot_export_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fcpu_aot_export_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fcpu_aot_export_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fcpu_aot_export_test.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -67,7 +67,7 @@ class CpuAotCompilationTest : public HloTestBase {\n     // Load Executable from AOT compilation result.\n     TF_ASSERT_OK_AND_ASSIGN(\n         std::unique_ptr<Executable> executable,\n-        std::move(*loaded_aot_result).LoadExecutable(compiler, stream_exec));\n+        std::move(*loaded_aot_result).LoadExecutable(stream_exec));\n   }\n };\n "
        },
        {
            "sha": "1fbf15aaa8865c8a2fe31611e3abafbb9e587cd4",
            "filename": "third_party/xla/xla/service/gpu/gpu_aot_compilation_result.h",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result.h?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -62,9 +62,8 @@ class GpuAotCompilationResult : public AotCompilationResult {\n     return serialized;\n   }\n \n-  absl::StatusOr<std::unique_ptr<Executable>> LoadExecutable(\n-      Compiler* compiler, const se::StreamExecutor* stream_exec) &&\n-      final {\n+  absl::StatusOr<std::unique_ptr<Executable>>\n+      LoadExecutable(const se::StreamExecutor* stream_exec) && final {\n     stream_executor::Platform::Id platform_id =\n         stream_exec->GetPlatform()->id();\n     const auto symbol_resolver = [&](absl::string_view symbol_name) {"
        },
        {
            "sha": "65fa6965ea14f82e2b9033b0bfc3052275584d74",
            "filename": "third_party/xla/xla/service/gpu/gpu_aot_compilation_result_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result_test.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -189,9 +189,8 @@ TEST_F(GpuAotCompilationResultTest, LoadExecutable) {\n \n   EnsureCudaSymbolIsRegistered();\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      std::unique_ptr<Executable> executable,\n-      std::move(*result).LoadExecutable(/*compiler=*/nullptr, &executor_));\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Executable> executable,\n+                          std::move(*result).LoadExecutable(&executor_));\n \n   auto* gpu_executable = dynamic_cast<GpuExecutable*>(executable.get());\n   ASSERT_NE(gpu_executable, nullptr) << \"Executable is not a GpuExecutable.\";"
        },
        {
            "sha": "3acb11b387fabb90699cebc0c0f2f284bc2b05a8",
            "filename": "third_party/xla/xla/service/gpu/gpu_aot_compilation_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 9,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_test.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -102,9 +102,8 @@ TEST_P(GpuAotCompilationTest, ExportAndLoadExecutable) {\n       compiler->LoadAotCompilationResult(serialized_aot_result));\n \n   // Load Executable from AOT compilation result.\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      std::unique_ptr<Executable> executable,\n-      std::move(*aot_result).LoadExecutable(compiler, stream_exec));\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Executable> executable,\n+                          std::move(*aot_result).LoadExecutable(stream_exec));\n }\n \n TEST_P(GpuAotCompilationTest, AotCompilationWithoutGpuDevice) {\n@@ -144,9 +143,8 @@ TEST_P(GpuAotCompilationTest, AotCompilationWithoutGpuDevice) {\n       compiler->LoadAotCompilationResult(serialized_aot_result));\n \n   // Load Executable from AOT compilation result.\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      std::unique_ptr<Executable> executable,\n-      std::move(*aot_result).LoadExecutable(compiler, stream_exec));\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Executable> executable,\n+                          std::move(*aot_result).LoadExecutable(stream_exec));\n }\n \n namespace {\n@@ -257,9 +255,8 @@ TEST_P(GpuAotCompilationTest, ExportAndLoadExecutableWithTriton) {\n       compiler->LoadAotCompilationResult(serialized_aot_result));\n \n   // Load Executable from AOT compilation result.\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      std::unique_ptr<Executable> executable,\n-      std::move(*aot_result).LoadExecutable(compiler, stream_exec));\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Executable> executable,\n+                          std::move(*aot_result).LoadExecutable(stream_exec));\n   std::unique_ptr<OpaqueExecutable> wrapped_executable =\n       test_runner_as_hlo_runner().WrapExecutable(std::move(executable));\n "
        },
        {
            "sha": "d949a15e15783a07b6f6114d2ee8965348f284d7",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -2703,7 +2703,7 @@ GpuCompiler::LegacyCompileAheadOfTime(std::unique_ptr<HloModule> hlo_module,\n           optimized_module.get(),\n           res.compile_module_results.buffer_assignment.get(),\n           res.backend_result.asm_text, res.backend_result.binary,\n-          res.backend_result.dnn_compiled_graphs, pointer_size_));\n+          res.backend_result.dnn_compiled_graphs, pointer_size_, this));\n \n   return std::move(results);\n }\n@@ -2714,7 +2714,7 @@ HloCostAnalysis::ShapeSizeFunction GpuCompiler::ShapeSizeBytesFunction() const {\n }\n \n absl::StatusOr<std::unique_ptr<AotCompilationResult>> GpuCompiler::Export(\n-    Executable* executable) const {\n+    Executable* executable) {\n   auto* gpu_executable = tensorflow::down_cast<GpuExecutable*>(executable);\n   if (!gpu_executable) {\n     return Internal(\"GpuExecutable is null\");\n@@ -2731,7 +2731,7 @@ absl::StatusOr<std::unique_ptr<AotCompilationResult>> GpuCompiler::Export(\n   return LegacyGpuAotCompilationResult::FromModule(\n       &gpu_executable->module(), gpu_executable->buffer_assignment(),\n       gpu_executable->text(), gpu_executable->binary(),\n-      gpu_executable->dnn_compiled_graphs(), pointer_size_);\n+      gpu_executable->dnn_compiled_graphs(), pointer_size_, this);\n }\n \n absl::Status GpuCompiler::RunPreSchedulingPasses(\n@@ -2968,7 +2968,7 @@ GpuCompiler::LoadAotCompilationResult(\n   }\n \n   return LegacyGpuAotCompilationResult::FromProto(gpu_executable_proto,\n-                                                  pointer_size_);\n+                                                  pointer_size_, this);\n }\n \n absl::StatusOr<std::unique_ptr<Executable>>"
        },
        {
            "sha": "ad2e6840dba02e56b3f52c6bd413c1a008a66e16",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -90,7 +90,7 @@ class GpuCompiler : public LLVMCompiler {\n   LoadAotCompilationResult(const std::string& serialized_aot_result) override;\n \n   absl::StatusOr<std::unique_ptr<AotCompilationResult>> Export(\n-      Executable* executable) const override;\n+      Executable* executable) override;\n \n   absl::Status RunPostSchedulingPipelines(\n       HloModule* module, int64_t scheduler_mem_limit,"
        },
        {
            "sha": "944a71ab6a7ee81dc2f40bcd77f0e7d7d2107458",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 8,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -950,9 +950,8 @@ TEST_P(AotCompilationTest, CompileAndLoadAotResult) {\n       std::unique_ptr<AotCompilationResult> aot_result,\n       compiler_->LoadAotCompilationResult(serialized_aot_result));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      std::unique_ptr<Executable> executable,\n-      std::move(*aot_result).LoadExecutable(compiler_, stream_exec_));\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Executable> executable,\n+                          std::move(*aot_result).LoadExecutable(stream_exec_));\n   std::unique_ptr<OpaqueExecutable> wrapped_executable =\n       test_runner_as_hlo_runner().WrapExecutable(std::move(executable));\n \n@@ -988,9 +987,8 @@ TEST_P(AotCompilationTest, ExportAndImportAotResult) {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<AotCompilationResult> aot_result,\n                           compiler_->Export(executable.get()));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      std::unique_ptr<Executable> new_executable,\n-      std::move(*aot_result).LoadExecutable(compiler_, stream_exec_));\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Executable> new_executable,\n+                          std::move(*aot_result).LoadExecutable(stream_exec_));\n   std::unique_ptr<OpaqueExecutable> wrapped_executable =\n       test_runner_as_hlo_runner().WrapExecutable(std::move(new_executable));\n \n@@ -1156,8 +1154,7 @@ ENTRY e {\n \n     TF_ASSERT_OK_AND_ASSIGN(\n         std::unique_ptr<Executable> executable,\n-        std::move(*aot_result)\n-            .LoadExecutable(compiler, aot_options.executor()));\n+        std::move(*aot_result).LoadExecutable(aot_options.executor()));\n     std::unique_ptr<OpaqueExecutable> wrapped_executable =\n         test_runner_as_hlo_runner().WrapExecutable(std::move(executable));\n "
        },
        {
            "sha": "86f920b6d57ed07482aacc17bf188d5b0b046270",
            "filename": "third_party/xla/xla/service/gpu/legacy_gpu_aot_compilation_result.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.cc?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -18,7 +18,6 @@ limitations under the License.\n #include <cstdint>\n #include <memory>\n #include <string>\n-#include <utility>\n \n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n@@ -28,7 +27,6 @@ limitations under the License.\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/buffer_value.h\"\n #include \"xla/service/compiler.h\"\n-#include \"xla/service/executable.h\"\n #include \"xla/service/gpu/gpu_executable.pb.h\"\n #include \"xla/service/gpu/gpu_latency_hiding_scheduler.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n@@ -44,7 +42,8 @@ absl::StatusOr<std::unique_ptr<LegacyGpuAotCompilationResult>>\n LegacyGpuAotCompilationResult::FromModule(\n     const HloModule* hlo_module, const BufferAssignment* buffer_assignment,\n     absl::string_view asm_text, absl::Span<const uint8_t> binary,\n-    const BinaryMap& dnn_compiled_graphs, int pointer_size) {\n+    const BinaryMap& dnn_compiled_graphs, int pointer_size,\n+    Compiler* compiler) {\n   tsl::profiler::TraceMe traceme(\"ResultFromModule\");\n   GpuExecutableProto proto;\n   *proto.mutable_hlo_module_with_config() = hlo_module->ToProtoWithConfig();\n@@ -55,32 +54,33 @@ LegacyGpuAotCompilationResult::FromModule(\n                                               dnn_compiled_graphs.cend());\n   return std::unique_ptr<LegacyGpuAotCompilationResult>(\n       new LegacyGpuAotCompilationResult(hlo_module->Clone(), std::move(proto),\n-                                        pointer_size));\n+                                        pointer_size, compiler));\n }\n \n absl::StatusOr<std::unique_ptr<LegacyGpuAotCompilationResult>>\n LegacyGpuAotCompilationResult::FromString(const std::string& serialized,\n-                                          int pointer_size) {\n+                                          int pointer_size,\n+                                          Compiler* compiler) {\n   tsl::profiler::TraceMe traceme(\"ResultFromString\");\n   GpuExecutableProto proto;\n   if (!proto.ParseFromString(serialized)) {\n     return Internal(\n         \"Failed to parse serialized LegacyGpuAotCompilationResult.\");\n   }\n \n-  return FromProto(proto, pointer_size);\n+  return FromProto(proto, pointer_size, compiler);\n }\n \n absl::StatusOr<std::unique_ptr<LegacyGpuAotCompilationResult>>\n LegacyGpuAotCompilationResult::FromProto(const GpuExecutableProto& proto,\n-                                         int pointer_size) {\n+                                         int pointer_size, Compiler* compiler) {\n   tsl::profiler::TraceMe traceme(\"ResultFromProto\");\n   TF_ASSIGN_OR_RETURN(\n       std::unique_ptr<HloModule> module,\n       HloModule::CreateFromProtoWithConfig(proto.hlo_module_with_config()));\n   return std::unique_ptr<LegacyGpuAotCompilationResult>(\n       new LegacyGpuAotCompilationResult(std::move(module), std::move(proto),\n-                                        pointer_size));\n+                                        pointer_size, compiler));\n }\n \n absl::StatusOr<std::string> LegacyGpuAotCompilationResult::SerializeAsString()\n@@ -90,12 +90,12 @@ absl::StatusOr<std::string> LegacyGpuAotCompilationResult::SerializeAsString()\n \n absl::StatusOr<std::unique_ptr<Executable>>\n LegacyGpuAotCompilationResult::LoadExecutable(\n-    Compiler* compiler, const se::StreamExecutor* stream_exec) && {\n+    const se::StreamExecutor* stream_exec) && {\n   if (stream_exec == nullptr) {\n     return InvalidArgument(\"Stream executor is null.\");\n   }\n \n-  return compiler->LoadExecutableFromAotResult(*this, *stream_exec);\n+  return compiler_->LoadExecutableFromAotResult(*this, *stream_exec);\n }\n \n absl::StatusOr<std::unique_ptr<BufferAssignment>>"
        },
        {
            "sha": "d511992ce5e3710e2e88b85491f62667816799d8",
            "filename": "third_party/xla/xla/service/gpu/legacy_gpu_aot_compilation_result.h",
            "status": "modified",
            "additions": 13,
            "deletions": 8,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b67559d7326c68972ad666929be6d6a5fdcd1955/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.h?ref=b67559d7326c68972ad666929be6d6a5fdcd1955",
            "patch": "@@ -50,19 +50,21 @@ class LegacyGpuAotCompilationResult : public AotCompilationResult {\n   FromModule(const HloModule* hlo_module,\n              const BufferAssignment* buffer_assignment,\n              absl::string_view asm_text, absl::Span<const uint8_t> binary,\n-             const BinaryMap& dnn_compiled_graphs, int pointer_size);\n+             const BinaryMap& dnn_compiled_graphs, int pointer_size,\n+             Compiler* compiler);\n \n   static absl::StatusOr<std::unique_ptr<LegacyGpuAotCompilationResult>>\n-  FromString(const std::string& serialized, int pointer_size);\n+  FromString(const std::string& serialized, int pointer_size,\n+             Compiler* compiler);\n \n   static absl::StatusOr<std::unique_ptr<LegacyGpuAotCompilationResult>>\n-  FromProto(const GpuExecutableProto& proto, int pointer_size);\n+  FromProto(const GpuExecutableProto& proto, int pointer_size,\n+            Compiler* compiler);\n \n   absl::StatusOr<std::string> SerializeAsString() const override;\n \n-  absl::StatusOr<std::unique_ptr<Executable>> LoadExecutable(\n-      Compiler* compiler, const se::StreamExecutor* stream_exec) &&\n-      override;\n+  absl::StatusOr<std::unique_ptr<Executable>>\n+      LoadExecutable(const se::StreamExecutor* stream_exec) && override;\n \n   const HloModule* optimized_module() const override { return module_.get(); }\n   std::unique_ptr<HloModule> consume_optimized_module() override {\n@@ -76,14 +78,17 @@ class LegacyGpuAotCompilationResult : public AotCompilationResult {\n \n  private:\n   LegacyGpuAotCompilationResult(std::unique_ptr<HloModule> module,\n-                                GpuExecutableProto proto, int pointer_size)\n+                                GpuExecutableProto proto, int pointer_size,\n+                                Compiler* compiler)\n       : module_(std::move(module)),\n         proto_(std::move(proto)),\n-        pointer_size_(pointer_size) {}\n+        pointer_size_(pointer_size),\n+        compiler_(compiler) {}\n \n   std::unique_ptr<HloModule> module_;\n   GpuExecutableProto proto_;\n   int pointer_size_;\n+  Compiler* compiler_;\n };\n \n }  // namespace gpu"
        }
    ],
    "stats": {
        "total": 202,
        "additions": 110,
        "deletions": 92
    }
}