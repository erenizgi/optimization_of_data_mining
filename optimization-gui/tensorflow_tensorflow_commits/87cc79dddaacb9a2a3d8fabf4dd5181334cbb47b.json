{
    "author": "akuegel",
    "message": "[XLA:GPU] Prepare to fuse iota into sort.\n\nAs a first step, codegen the iota operands in the first bitonic sort iteration.\nLater we will introduce a sort fusion type that allows to fuse iota operands into\nsort. The new codegen capabilities will not be used yet, as single iotas would\nbe wrapped into a fusion, so we would never find iota operands of sort.\n\nPiperOrigin-RevId: 845676002",
    "sha": "87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b",
    "files": [
        {
            "sha": "30a3ac1a965948a2b63910253b3eb93e344b33f1",
            "filename": "third_party/xla/xla/backends/gpu/codegen/llvm/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2FBUILD?ref=87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b",
            "patch": "@@ -79,6 +79,8 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:elemental_ir_emitter\",\n         \"//xla/service/gpu:ir_emission_utils\",\n         \"//xla/service/gpu:launch_dimensions\",\n         \"//xla/service/gpu:target_util\",\n@@ -87,7 +89,9 @@ cc_library(\n         \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/service/llvm_ir:loop_emitter\",\n         \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:status_macros\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//llvm:Core\","
        },
        {
            "sha": "1fcbeb98e9d9ff25fe6203758ff1c82468b48bba",
            "filename": "third_party/xla/xla/backends/gpu/codegen/llvm/llvm_emitter.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fllvm_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fllvm_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fllvm_emitter.cc?ref=87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b",
            "patch": "@@ -251,6 +251,8 @@ class IrEmitter : public DfsHloVisitorWithDefault,\n \n   llvm::IRBuilderBase* builder() { return &b_; }\n \n+  llvm::Module* module() { return module_; }\n+\n   // Generate the code for the computation passed in the constructor, if it\n   // wasn't already generated previously.\n   // As well as generting the code for the function, emits code for global\n@@ -855,6 +857,7 @@ absl::StatusOr<ThunkSequence> EmitBitonicSortLLVMIR(\n   VLOG(2) << absl::StreamFormat(\"%s launch dims: %d blocks, %d threads/block\",\n                                 op_name, num_blocks, kThreadsPerBlock);\n   ThunkSequence thunks;\n+  bool emit_iota_operands = true;\n   auto emit_kernel = [&](absl::Span<const int64_t> xor_masks) {\n     VLOG(2) << absl::StreamFormat(\n         \"%s uses kernel for xor masks [%s]\", op_name,\n@@ -883,9 +886,9 @@ absl::StatusOr<ThunkSequence> EmitBitonicSortLLVMIR(\n \n     auto* comparator = sort->called_computations().front();\n     auto* builder = ir_emitter.builder();\n-    return llvm_ir::EmitSortInPlace(\n-        dimension_to_sort, output_arrays_span, llvm_ir::IrName(op_name),\n-        xor_masks, ir_emitter.builder(), launch_dimensions,\n+    auto result = llvm_ir::EmitSortInPlace(\n+        sort, output_arrays_span, emit_iota_operands, llvm_ir::IrName(op_name),\n+        xor_masks, ir_emitter.module(), ir_emitter.builder(), launch_dimensions,\n         xor_masks.size() > 1 ? num_iterations_in_sort_dim\n                              : standard_num_iterations_in_sort_dim,\n         tile_size, kUnrollFactor,\n@@ -894,6 +897,8 @@ absl::StatusOr<ThunkSequence> EmitBitonicSortLLVMIR(\n                                        llvm_module, *comparator, operands,\n                                        output);\n         });\n+    emit_iota_operands = false;\n+    return result;\n   };\n   std::vector<int64_t> xor_masks;\n   for (int64_t stage = 0; stage < num_stages; ++stage) {"
        },
        {
            "sha": "40d88f803841db14321a0ab117d1b7e1e251eb81",
            "filename": "third_party/xla/xla/backends/gpu/codegen/llvm/sort_util.cc",
            "status": "modified",
            "additions": 93,
            "deletions": 56,
            "changes": 149,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fsort_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fsort_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fsort_util.cc?ref=87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n \n // IWYU pragma: no_include \"llvm/IR/Intrinsics.gen.inc\"\n #include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n@@ -34,8 +35,12 @@ limitations under the License.\n #include \"llvm/IR/Value.h\"\n #include \"llvm/Support/Casting.h\"\n #include \"xla/backends/gpu/codegen/llvm/parallel_loop_emitter.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/layout_util.h\"\n #include \"xla/primitive_util.h\"\n+#include \"xla/service/elemental_ir_emitter.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n #include \"xla/service/gpu/target_util.h\"\n@@ -48,6 +53,7 @@ limitations under the License.\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n+#include \"xla/tsl/platform/status_macros.h\"\n \n namespace xla {\n namespace llvm_ir {\n@@ -59,7 +65,8 @@ absl::Status EmitCompareLoopBody(\n     int64_t iteration_bound, int64_t num_threads, int64_t unroll_factor,\n     int64_t num_values, llvm::Value* element_pair_index, int64_t xor_mask,\n     llvm::Type* index_type,\n-    std::function<llvm::Value*(int64_t operand, llvm::Value* index)>\n+    std::function<absl::StatusOr<llvm::Value*>(int64_t operand,\n+                                               llvm::Value* index)>\n         element_address,\n     std::function<llvm::Type*(int64_t operand, llvm::Value* index)>\n         element_address_pointee_type,\n@@ -173,16 +180,21 @@ absl::Status EmitCompareLoopBody(\n \n     // if (index_is_inbounds)\n     KernelSupportLibrary ksl(b);\n-    TF_RETURN_IF_ERROR(\n-        ksl.IfWithStatus(\"smaller_comparison_index\", index_is_inbounds, [&]() {\n+    RETURN_IF_ERROR(ksl.IfWithStatus(\n+        \"smaller_comparison_index\", index_is_inbounds, [&]() -> absl::Status {\n           std::vector<llvm::Value*> values_to_compare;\n           std::vector<llvm::Type*> values_to_compare_types;\n+          values_to_compare.reserve(num_values * 2);\n+          values_to_compare_types.reserve(num_values * 2);\n           for (int i = 0; i < num_values; ++i) {\n-            values_to_compare.push_back(element_address(i, compare_keys_index));\n+            ASSIGN_OR_RETURN(llvm::Value * address,\n+                             element_address(i, compare_keys_index));\n+            values_to_compare.push_back(address);\n             values_to_compare_types.push_back(\n                 element_address_pointee_type(i, compare_keys_index));\n \n-            values_to_compare.push_back(element_address(i, current_keys_index));\n+            ASSIGN_OR_RETURN(address, element_address(i, current_keys_index));\n+            values_to_compare.push_back(address);\n             values_to_compare_types.push_back(\n                 element_address_pointee_type(i, current_keys_index));\n           }\n@@ -191,7 +203,7 @@ absl::Status EmitCompareLoopBody(\n           llvm::Value* compare_return_buffer =\n               llvm_ir::EmitAllocaAtFunctionEntry(pred_type,\n                                                  \"compare_return_buffer\", b);\n-          TF_RETURN_IF_ERROR(\n+          RETURN_IF_ERROR(\n               emit_compare_callback(values_to_compare, compare_return_buffer));\n           llvm::Value* result = b->CreateLoad(pred_type, compare_return_buffer);\n \n@@ -217,13 +229,15 @@ absl::Status EmitCompareLoopBody(\n }\n \n absl::Status EmitTiledCompareLoop(\n-    const IrArray::Index& tiled_keys_index, int64_t dimension_to_sort,\n+    const IrArray::Index& tiled_keys_index, const HloSortInstruction* sort,\n     int64_t dimension_to_sort_bound, int64_t num_threads,\n     absl::Span<const int64_t> xor_masks, absl::Span<const IrArray> params,\n+    bool emit_iota_operands,\n     const std::vector<llvm::GlobalVariable*>& param_shmem_buffers,\n     int64_t tile_size, int64_t unroll_factor,\n     const EmitCallToNestedComputationCallback& emit_compare_callback,\n-    llvm::IRBuilderBase* b) {\n+    llvm::Module* module, llvm::IRBuilderBase* b) {\n+  int64_t dimension_to_sort = sort->sort_dimension();\n   KernelSupportLibrary ksl(b);\n   llvm::Value* thread_id = gpu::EmitCallToTargetIntrinsic(\n       gpu::TargetIntrinsicID::kThreadIdx, {}, {}, b);\n@@ -233,50 +247,61 @@ absl::Status EmitTiledCompareLoop(\n   thread_id = b->CreateIntCast(thread_id, tiled_keys_index.GetType(),\n                                /*isSigned=*/true, \"thread.id.x\");\n \n-  auto copy_loop_body =\n-      [&](std::function<void(llvm::Value * cache_index, llvm::Value * index)>\n-              read_or_write) {\n-        auto unroll = tiled_keys_index.GetConstantWithIndexType(unroll_factor);\n-        auto base_keys_index =\n-            b->CreateMul(tiled_keys_index[dimension_to_sort], unroll,\n-                         \"base_keys_index\", /*HasNUW=*/true, /*HasNSW=*/true);\n-        auto base_cache_index =\n-            b->CreateMul(thread_id, unroll, \"base_cache_index\", /*HasNUW=*/true,\n-                         /*HasNSW=*/true);\n-        // We want to copy `unroll_factor` many adjacent elements.\n-        for (int i = 0; i < unroll_factor; ++i) {\n-          auto offset = tiled_keys_index.GetConstantWithIndexType(i);\n-          auto current_keys_index =\n-              b->CreateAdd(base_keys_index, offset, \"current_keys_index\",\n-                           /*HasNUW=*/true, /*HasNSW=*/true);\n-          // We check whether the index position is within bounds.\n-          ksl.If(\"smaller_keys_index\",\n-                 b->CreateICmpSLT(current_keys_index,\n-                                  tiled_keys_index.GetConstantWithIndexType(\n-                                      dimension_to_sort_bound)),\n-                 [&]() {\n-                   auto cache_index =\n-                       b->CreateAdd(base_cache_index, offset, \"cache_index\",\n-                                    /*HasNUW=*/true, /*HasNSW=*/true);\n-                   read_or_write(cache_index, current_keys_index);\n-                 });\n-        }\n-      };\n+  auto copy_loop_body = [&](std::function<absl::Status(\n+                                llvm::Value * cache_index, llvm::Value * index)>\n+                                read_or_write) -> absl::Status {\n+    auto unroll = tiled_keys_index.GetConstantWithIndexType(unroll_factor);\n+    auto base_keys_index =\n+        b->CreateMul(tiled_keys_index[dimension_to_sort], unroll,\n+                     \"base_keys_index\", /*HasNUW=*/true, /*HasNSW=*/true);\n+    auto base_cache_index =\n+        b->CreateMul(thread_id, unroll, \"base_cache_index\", /*HasNUW=*/true,\n+                     /*HasNSW=*/true);\n+    // We want to copy `unroll_factor` many adjacent elements.\n+    for (int i = 0; i < unroll_factor; ++i) {\n+      auto offset = tiled_keys_index.GetConstantWithIndexType(i);\n+      auto current_keys_index =\n+          b->CreateAdd(base_keys_index, offset, \"current_keys_index\",\n+                       /*HasNUW=*/true, /*HasNSW=*/true);\n+      // We check whether the index position is within bounds.\n+      RETURN_IF_ERROR(ksl.IfWithStatus(\n+          \"smaller_keys_index\",\n+          b->CreateICmpSLT(current_keys_index,\n+                           tiled_keys_index.GetConstantWithIndexType(\n+                               dimension_to_sort_bound)),\n+          [&]() {\n+            auto cache_index =\n+                b->CreateAdd(base_cache_index, offset, \"cache_index\",\n+                             /*HasNUW=*/true, /*HasNSW=*/true);\n+            return read_or_write(cache_index, current_keys_index);\n+          }));\n+    }\n+    return absl::OkStatus();\n+  };\n \n   // Copy operand tiles from the operand buffers to shared memory.\n   std::vector<llvm::Value*> keys_multi_index = tiled_keys_index.multidim();\n   for (int64_t i = 0; i < params.size(); ++i) {\n-    copy_loop_body([&](llvm::Value* cache_index, llvm::Value* index) {\n+    RETURN_IF_ERROR(copy_loop_body([&](llvm::Value* cache_index,\n+                                       llvm::Value* index) {\n       keys_multi_index[dimension_to_sort] = index;\n       IrArray::Index keys_index(keys_multi_index, params[i].GetShape(),\n                                 tiled_keys_index.GetType());\n-      auto value = params[i].EmitReadArrayElement(keys_index, b);\n+      llvm::Value* value;\n+      if (emit_iota_operands &&\n+          HloPredicateIsOp<HloOpcode::kIota>(sort->operand(i))) {\n+        ASSIGN_OR_RETURN(value,\n+                         EmitIota(sort->operand(i), keys_index, module, b));\n+      } else {\n+        value = params[i].EmitReadArrayElement(keys_index, b);\n+      }\n       b->CreateStore(\n           value,\n           b->CreateGEP(\n               param_shmem_buffers[i]->getValueType(), param_shmem_buffers[i],\n               {tiled_keys_index.GetConstantWithIndexType(0), cache_index}));\n-    });\n+      return absl::OkStatus();\n+    }));\n   }\n   // Wait until all reads have happened.\n   gpu::EmitCallToTargetIntrinsic(gpu::TargetIntrinsicID::kBarrierId, {}, {}, b);\n@@ -320,7 +345,7 @@ absl::Status EmitTiledCompareLoop(\n     if (dimension_to_sort_bound % tile_size) {\n       // Otherwise we need a bounds check for the last tile. The last tile has\n       // size 'dimension_to_sort_bound' % 'tile_size'.\n-      TF_RETURN_IF_ERROR(ksl.IfWithStatus(\n+      RETURN_IF_ERROR(ksl.IfWithStatus(\n           \"is_last_tile\",\n           b->CreateICmpUGE(\n               b->CreateMul(\n@@ -345,7 +370,7 @@ absl::Status EmitTiledCompareLoop(\n                 /*needs_bounds_checks=*/false);\n           }));\n     } else {\n-      TF_RETURN_IF_ERROR(EmitCompareLoopBody(\n+      RETURN_IF_ERROR(EmitCompareLoopBody(\n           tile_size, num_threads, unroll_factor / 2, params.size(),\n           element_pair_index, xor_mask, tiled_keys_index.GetType(),\n           element_address, element_address_pointee_type, write_element,\n@@ -359,7 +384,8 @@ absl::Status EmitTiledCompareLoop(\n \n   // Copy the operand tiles back from shared memory to the operand buffers.\n   for (int64_t i = 0; i < params.size(); ++i) {\n-    copy_loop_body([&](llvm::Value* cache_index, llvm::Value* index) {\n+    RETURN_IF_ERROR(copy_loop_body([&](llvm::Value* cache_index,\n+                                       llvm::Value* index) {\n       keys_multi_index[dimension_to_sort] = index;\n       IrArray::Index keys_index(keys_multi_index, params[i].GetShape(),\n                                 tiled_keys_index.GetType());\n@@ -371,7 +397,8 @@ absl::Status EmitTiledCompareLoop(\n           {tiled_keys_index.GetConstantWithIndexType(0), cache_index});\n       auto value = b->CreateLoad(gep_type, gep);\n       params[i].EmitWriteArrayElement(keys_index, value, b);\n-    });\n+      return absl::OkStatus();\n+    }));\n   }\n   // We should normally synchronize here to make sure all writes have happened.\n   // However the very next thing each thread does is reading `unroll_factor`\n@@ -387,8 +414,9 @@ absl::Status EmitTiledCompareLoop(\n }  // namespace\n \n absl::Status EmitSortInPlace(\n-    int64_t dimension_to_sort, absl::Span<const IrArray> values_arrays,\n-    absl::string_view name, absl::Span<const int64_t> xor_masks,\n+    const HloSortInstruction* sort, absl::Span<const IrArray> values_arrays,\n+    bool emit_iota_operands, absl::string_view name,\n+    absl::Span<const int64_t> xor_masks, llvm::Module* module,\n     llvm::IRBuilderBase* b, const gpu::LaunchDimensions& launch_dimensions,\n     int64_t num_iterations_in_sort_dim, int64_t tile_size,\n     int64_t unroll_factor,\n@@ -405,6 +433,7 @@ absl::Status EmitSortInPlace(\n   const Shape& keys_shape = values_arrays[0].GetShape();\n   int64_t rank = keys_shape.dimensions().size();\n   int64_t num_threads = std::max(int64_t{1}, tile_size / unroll_factor);\n+  int64_t dimension_to_sort = sort->sort_dimension();\n   int64_t dimension_to_sort_bound = keys_shape.dimensions(dimension_to_sort);\n   std::vector<int64_t> dimensions_in_iteration_order(rank);\n   std::vector<int64_t> iteration_order_to_logical_order(rank);\n@@ -460,23 +489,31 @@ absl::Status EmitSortInPlace(\n     if (xor_masks.size() > 1) {\n       IrArray::Index keys_index(keys_multi_index, values_arrays[0].GetShape(),\n                                 tiles_index.GetType());\n-      TF_RETURN_IF_ERROR(EmitTiledCompareLoop(\n-          keys_index, dimension_to_sort, dimension_to_sort_bound, num_threads,\n-          xor_masks, values_arrays, param_shmem_buffers, tile_size,\n-          unroll_factor, emit_compare_callback, b));\n+      RETURN_IF_ERROR(EmitTiledCompareLoop(\n+          keys_index, sort, dimension_to_sort_bound, num_threads, xor_masks,\n+          values_arrays, emit_iota_operands, param_shmem_buffers, tile_size,\n+          unroll_factor, emit_compare_callback, module, b));\n     } else {\n-      auto element_address = [&](int64_t operand, llvm::Value* index) {\n+      auto element_address =\n+          [&](int64_t operand,\n+              llvm::Value* index) -> absl::StatusOr<llvm::Value*> {\n         keys_multi_index[dimension_to_sort] = index;\n         IrArray::Index keys_index(keys_multi_index,\n                                   values_arrays[operand].GetShape(),\n                                   tiles_index.GetType());\n         PrimitiveType element_type =\n             values_arrays[operand].GetShape().element_type();\n-        if (!primitive_util::IsSubByteNonPredType(element_type)) {\n-          return values_arrays[operand].EmitArrayElementAddress(keys_index, b);\n+        llvm::Value* element;\n+        if (emit_iota_operands &&\n+            HloPredicateIsOp<HloOpcode::kIota>(sort->operand(operand))) {\n+          ASSIGN_OR_RETURN(element, EmitIota(sort, keys_index, module, b));\n+        } else {\n+          if (!primitive_util::IsSubByteNonPredType(element_type)) {\n+            return values_arrays[operand].EmitArrayElementAddress(keys_index,\n+                                                                  b);\n+          }\n+          element = values_arrays[operand].EmitReadArrayElement(keys_index, b);\n         }\n-        auto element =\n-            values_arrays[operand].EmitReadArrayElement(keys_index, b);\n         auto llvm_element_type =\n             llvm_ir::PrimitiveTypeToIrType(element_type, b->getContext());\n         llvm::Value* element_buffer = llvm_ir::EmitAllocaAtFunctionEntry(\n@@ -495,7 +532,7 @@ absl::Status EmitSortInPlace(\n                                   tiles_index.GetType());\n         values_arrays[operand].EmitWriteArrayElement(keys_index, value, b);\n       };\n-      TF_RETURN_IF_ERROR(EmitCompareLoopBody(\n+      RETURN_IF_ERROR(EmitCompareLoopBody(\n           dimension_to_sort_bound, /*num_threads=*/1, unroll_factor / 2,\n           values_arrays.size(), tiles_index[rank - 1], xor_masks[0],\n           tiles_index.GetType(), element_address, element_address_pointee_type,"
        },
        {
            "sha": "13179f189f87f99c7afcd02f8ae9b0e2e0caa388",
            "filename": "third_party/xla/xla/backends/gpu/codegen/llvm/sort_util.h",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fsort_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fsort_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fsort_util.h?ref=87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"llvm/IR/IRBuilder.h\"\n #include \"llvm/IR/Value.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n #include \"xla/service/llvm_ir/ir_array.h\"\n \n@@ -35,9 +36,12 @@ using EmitCallToNestedComputationCallback =\n // dimension of each array in 'values_arrays'. All other dimensions are kept\n // as-is. This implements the inner loop of BitonicSort. It is assumed that\n // 'xor_masks' contains only powers of 2, or values 2^k - 1 (k > 0).\n+// `emit_iota_operands` should be set to true in the first call to\n+// EmitSortInPlace.\n absl::Status EmitSortInPlace(\n-    int64_t dimension_to_sort, absl::Span<const IrArray> values_arrays,\n-    absl::string_view name, absl::Span<const int64_t> xor_masks,\n+    const HloSortInstruction* sort, absl::Span<const IrArray> values_arrays,\n+    bool emit_iota_operands, absl::string_view name,\n+    absl::Span<const int64_t> xor_masks, llvm::Module* module,\n     llvm::IRBuilderBase* b, const gpu::LaunchDimensions& launch_dimensions,\n     int64_t num_iterations_in_sort_dim, int64_t tile_size,\n     int64_t unroll_factor,"
        },
        {
            "sha": "6a6defabe974e8ba2d311745135cfb7be3cd05c3",
            "filename": "third_party/xla/xla/service/elemental_ir_emitter.cc",
            "status": "modified",
            "additions": 128,
            "deletions": 109,
            "changes": 237,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.cc?ref=87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b",
            "patch": "@@ -513,8 +513,79 @@ llvm::Value* EmitIntegralToFloating(llvm::Value* integer_value,\n   }\n }\n \n+llvm::Value* EmitComposeComplex(const HloInstruction* op, llvm::Value* real,\n+                                llvm::Value* imag, llvm::Module* module,\n+                                llvm::IRBuilderBase* b) {\n+  auto cplx_type = llvm_ir::PrimitiveTypeToIrType(op->shape().element_type(),\n+                                                  module->getContext());\n+  auto complex = b->CreateInsertValue(\n+      llvm::ConstantAggregateZero::get(cplx_type), real, {0});\n+  if (imag != nullptr) {\n+    complex = b->CreateInsertValue(complex, imag, {1});\n+  }\n+  return complex;\n+}\n+\n }  // namespace\n \n+absl::StatusOr<llvm::Value*> EmitIota(const HloInstruction* hlo,\n+                                      const IrArray::Index& target_index,\n+                                      llvm::Module* module,\n+                                      llvm::IRBuilderBase* b) {\n+  auto* iota = Cast<HloIotaInstruction>(hlo);\n+  PrimitiveType element_type = iota->shape().element_type();\n+  IrArray::Index elem_index =\n+      iota->shape().dimensions().size() > 1\n+          ? target_index.SourceIndexOfBroadcast(\n+                iota->shape(),\n+                ShapeUtil::MakeShapeWithDescendingLayout(\n+                    element_type,\n+                    {iota->shape().dimensions(iota->iota_dimension())}),\n+                {iota->iota_dimension()}, b)\n+          : target_index;\n+  llvm::Value* elem_index_linear = elem_index.linear();\n+  if (elem_index_linear == nullptr) {\n+    std::vector<int64_t> iota_bound = {\n+        iota->shape().dimensions(iota->iota_dimension())};\n+    elem_index_linear = elem_index.Linearize(iota_bound, b);\n+  }\n+  Shape component_shape = ShapeUtil::ElementIsComplex(iota->shape())\n+                              ? ShapeUtil::ComplexComponentShape(iota->shape())\n+                              : iota->shape();\n+  PrimitiveType component_element_type = component_shape.element_type();\n+  llvm::Value* iota_result;\n+  if (primitive_util::IsIntegralType(component_element_type)) {\n+    iota_result =\n+        b->CreateIntCast(elem_index_linear,\n+                         llvm_ir::PrimitiveTypeToIrType(component_element_type,\n+                                                        module->getContext()),\n+                         /*isSigned=*/false);\n+  } else {\n+    TF_RET_CHECK(primitive_util::IsFloatingPointType(component_element_type))\n+        << component_element_type;\n+    llvm::Type* float_ir_type;\n+    if (component_element_type == F8E4M3FNUZ ||\n+        component_element_type == F8E5M2FNUZ) {\n+      float_ir_type = llvm_ir::PrimitiveTypeToIrType(F16, module->getContext());\n+    } else {\n+      float_ir_type = llvm_ir::PrimitiveTypeToIrType(component_element_type,\n+                                                     module->getContext());\n+    }\n+    llvm::Value* float_val = b->CreateUIToFP(elem_index_linear, float_ir_type);\n+    if (component_element_type == F8E4M3FNUZ ||\n+        component_element_type == F8E5M2FNUZ) {\n+      iota_result =\n+          EmitFxToF8e(module, F16, component_element_type, float_val, b);\n+    } else {\n+      iota_result = float_val;\n+    }\n+  }\n+  if (ShapeUtil::ElementIsComplex(iota->shape())) {\n+    return EmitComposeComplex(iota, iota_result, nullptr, module, b);\n+  }\n+  return iota_result;\n+}\n+\n /*static*/ bool ElementalIrEmitter::OpInvalidatesCache(\n     const HloInstruction* hlo) {\n   switch (hlo->opcode()) {\n@@ -620,13 +691,15 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitIntegerUnaryOp(\n             primitive_util::ComplexComponentType(to_type),\n             module_->getContext());\n         if (primitive_util::IsSignedIntegralType(from_type)) {\n-          return EmitComposeComplex(\n-              op, SIToFP(operand_value, to_ir_component_type), nullptr);\n+          return EmitComposeComplex(op,\n+                                    SIToFP(operand_value, to_ir_component_type),\n+                                    nullptr, module_, b_);\n         }\n         if (primitive_util::IsUnsignedIntegralType(from_type) ||\n             from_type == PRED) {\n-          return EmitComposeComplex(\n-              op, UIToFP(operand_value, to_ir_component_type), nullptr);\n+          return EmitComposeComplex(op,\n+                                    UIToFP(operand_value, to_ir_component_type),\n+                                    nullptr, module_, b_);\n         }\n       }\n       return Unimplemented(\"conversion from primitive type %s to %s\",\n@@ -837,14 +910,14 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatUnaryOp(\n         PrimitiveType to_component_type =\n             primitive_util::ComplexComponentType(to_type);\n         if (from_type == to_component_type) {\n-          return EmitComposeComplex(op, operand_value, nullptr);\n+          return EmitComposeComplex(op, operand_value, nullptr, module_, b_);\n         }\n         return EmitComposeComplex(\n             op,\n             FPCast(operand_value,\n                    llvm_ir::PrimitiveTypeToIrType(to_component_type,\n                                                   module_->getContext())),\n-            nullptr);\n+            nullptr, module_, b_);\n       }\n       if (to_type == BF16) {\n         // F16 to BF16 has to go through an intermediate F32.\n@@ -1181,7 +1254,7 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexUnaryOp(\n                               r);  // handles nan and inf values correctly\n \n       TF_ASSIGN_OR_RETURN(auto imag_part, EmitAtan2(component_type, b, a1, \"\"));\n-      return EmitComposeComplex(op, real_part, imag_part);\n+      return EmitComposeComplex(op, real_part, imag_part, module_, b_);\n     }\n     case HloOpcode::kConvert: {\n       PrimitiveType from_type = op->operand(0)->shape().element_type();\n@@ -1197,7 +1270,8 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexUnaryOp(\n           to_component_type, module_->getContext());\n       return EmitComposeComplex(\n           op, FPCast(EmitExtractReal(operand_value), to_ir_component_type),\n-          FPCast(EmitExtractImag(operand_value), to_ir_component_type));\n+          FPCast(EmitExtractImag(operand_value), to_ir_component_type), module_,\n+          b_);\n     }\n     case HloOpcode::kExp: {\n       // e^(a+bi) = e^a*(cos(b)+sin(b)i)\n@@ -1232,7 +1306,7 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexUnaryOp(\n       auto imag_nonzero = Select(exp_a_is_inf, imag_overflow, imag_normal);\n       auto imag_result = Select(b_is_zero, zero, imag_nonzero);\n \n-      return EmitComposeComplex(op, real_result, imag_result);\n+      return EmitComposeComplex(op, real_result, imag_result, module_, b_);\n     }\n     case HloOpcode::kExpm1: {\n       // e^(a+bi)-1 = (e^a*cos(b)-1)+e^a*sin(b)i\n@@ -1251,7 +1325,7 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexUnaryOp(\n       auto cos_b = FAdd(cos_b_minus_one, one);\n       auto real_result = FAdd(FMul(expm1_a, cos_b), cos_b_minus_one);\n       auto imag_result = Select(b_is_zero, zero, FMul(exp_a, sin_b));\n-      return EmitComposeComplex(op, real_result, imag_result);\n+      return EmitComposeComplex(op, real_result, imag_result, module_, b_);\n     }\n     case HloOpcode::kCos:\n     case HloOpcode::kSin: {\n@@ -1281,7 +1355,7 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexUnaryOp(\n         real_result = FMul(cos_x, cosh_y);\n         imag_result = FNeg(FMul(sin_x, sinh_y));\n       }\n-      return EmitComposeComplex(op, real_result, imag_result);\n+      return EmitComposeComplex(op, real_result, imag_result, module_, b_);\n     }\n     case HloOpcode::kTan:\n       // tan(x+yi) = -i*tanh(-y + xi)\n@@ -1429,8 +1503,9 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexUnaryOp(\n         imag = Select(imag_is_zero, zero, imag);\n       }\n \n-      return op_is_tan ? EmitComposeComplex(op, imag, FMul(neg_one, real))\n-                       : EmitComposeComplex(op, real, imag);\n+      return op_is_tan ? EmitComposeComplex(op, imag, FMul(neg_one, real),\n+                                            module_, b_)\n+                       : EmitComposeComplex(op, real, imag, module_, b_);\n     }\n     case HloOpcode::kAbs: {\n       return EmitComplexAbs(component_type, operand_value);\n@@ -1442,9 +1517,10 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexUnaryOp(\n       auto zero = llvm::ConstantFP::get(type, 0.0);\n       auto oeq = FCmpOEQ(cplx_abs, zero);\n       return Select(\n-          oeq, EmitComposeComplex(op, zero, zero),\n+          oeq, EmitComposeComplex(op, zero, zero, module_, b_),\n           EmitComposeComplex(op, FDiv(EmitExtractReal(operand_value), cplx_abs),\n-                             FDiv(EmitExtractImag(operand_value), cplx_abs)));\n+                             FDiv(EmitExtractImag(operand_value), cplx_abs),\n+                             module_, b_));\n     }\n     case HloOpcode::kSqrt: {\n       return EmitComplexSqrt(op, component_type, operand_value);\n@@ -1454,7 +1530,8 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexUnaryOp(\n     }\n     case HloOpcode::kNegate:\n       return EmitComposeComplex(op, FNeg(EmitExtractReal(operand_value)),\n-                                FNeg(EmitExtractImag(operand_value)));\n+                                FNeg(EmitExtractImag(operand_value)), module_,\n+                                b_);\n     case HloOpcode::kReal:\n       return EmitExtractReal(operand_value);\n     case HloOpcode::kImag:\n@@ -1485,7 +1562,7 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatBinaryOp(\n     const HloInstruction* op, llvm::Value* lhs_value, llvm::Value* rhs_value) {\n   switch (op->opcode()) {\n     case HloOpcode::kComplex:\n-      return EmitComposeComplex(op, lhs_value, rhs_value);\n+      return EmitComposeComplex(op, lhs_value, rhs_value, module_, b_);\n     case HloOpcode::kAdd:\n       return FAdd(lhs_value, rhs_value, op->name());\n     case HloOpcode::kSubtract:\n@@ -1668,14 +1745,16 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexAdd(\n     const HloInstruction* op, llvm::Value* lhs_value, llvm::Value* rhs_value) {\n   return EmitComposeComplex(\n       op, FAdd(EmitExtractReal(lhs_value), EmitExtractReal(rhs_value)),\n-      FAdd(EmitExtractImag(lhs_value), EmitExtractImag(rhs_value)));\n+      FAdd(EmitExtractImag(lhs_value), EmitExtractImag(rhs_value)), module_,\n+      b_);\n }\n \n absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexSubtract(\n     const HloInstruction* op, llvm::Value* lhs_value, llvm::Value* rhs_value) {\n   return EmitComposeComplex(\n       op, FSub(EmitExtractReal(lhs_value), EmitExtractReal(rhs_value)),\n-      FSub(EmitExtractImag(lhs_value), EmitExtractImag(rhs_value)));\n+      FSub(EmitExtractImag(lhs_value), EmitExtractImag(rhs_value)), module_,\n+      b_);\n }\n \n absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexMultiply(\n@@ -1685,7 +1764,8 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexMultiply(\n       FSub(FMul(EmitExtractReal(lhs_value), EmitExtractReal(rhs_value)),\n            FMul(EmitExtractImag(lhs_value), EmitExtractImag(rhs_value))),\n       FAdd(FMul(EmitExtractReal(lhs_value), EmitExtractImag(rhs_value)),\n-           FMul(EmitExtractImag(lhs_value), EmitExtractReal(rhs_value))));\n+           FMul(EmitExtractImag(lhs_value), EmitExtractReal(rhs_value))),\n+      module_, b_);\n }\n \n absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexDivide(\n@@ -1734,7 +1814,7 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexDivide(\n   auto c_i = Select(b_r_lt_b_i,\n                     FDiv(FSub(FMul(b_r_b_i_ratio, a_i), a_r), b_r_b_i_denom),\n                     FDiv(FSub(a_i, FMul(b_i_b_r_ratio, a_r)), b_i_b_r_denom));\n-  auto result = EmitComposeComplex(op, c_r, c_i);\n+  auto result = EmitComposeComplex(op, c_r, c_i, module_, b_);\n \n   // Consider corner cases, if the result is (NaN, NaN).\n   auto zero = llvm::ConstantFP::get(type, 0.0);\n@@ -1747,8 +1827,9 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexDivide(\n           Or(Not(FCmpUNO(a_r, zero)), Not(FCmpUNO(a_i, zero))));\n   auto inf_with_sign_of_b_r = llvm_ir::EmitCallToIntrinsic(\n       llvm::Intrinsic::copysign, {inf, b_r}, {type}, b_);\n-  auto zero_denominator_result = EmitComposeComplex(\n-      op, FMul(inf_with_sign_of_b_r, a_r), FMul(inf_with_sign_of_b_r, a_i));\n+  auto zero_denominator_result =\n+      EmitComposeComplex(op, FMul(inf_with_sign_of_b_r, a_r),\n+                         FMul(inf_with_sign_of_b_r, a_i), module_, b_);\n \n   // Case 2. Infinite numerator, finite denominator.\n   auto b_r_finite = FCmpONE(b_r_abs, inf);\n@@ -1773,7 +1854,8 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexDivide(\n       FMul(inf,\n            FAdd(FMul(a_r_inf_with_sign, b_r), FMul(a_i_inf_with_sign, b_i))),\n       FMul(inf,\n-           FSub(FMul(a_i_inf_with_sign, b_r), FMul(a_r_inf_with_sign, b_i))));\n+           FSub(FMul(a_i_inf_with_sign, b_r), FMul(a_r_inf_with_sign, b_i))),\n+      module_, b_);\n \n   // Case 3. Finite numerator, infinite denominator.\n   auto a_r_finite = FCmpONE(a_r_abs, inf);\n@@ -1794,7 +1876,8 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexDivide(\n       FMul(zero,\n            FAdd(FMul(a_r, b_r_inf_with_sign), FMul(a_i, b_i_inf_with_sign))),\n       FMul(zero,\n-           FSub(FMul(a_i, b_r_inf_with_sign), FMul(a_r, b_i_inf_with_sign))));\n+           FSub(FMul(a_i, b_r_inf_with_sign), FMul(a_r, b_i_inf_with_sign))),\n+      module_, b_);\n \n   auto c_nan = And(FCmpUNO(c_r, zero), FCmpUNO(c_i, zero));\n   return Select(c_nan,\n@@ -1816,7 +1899,7 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexLog(\n   TF_ASSIGN_OR_RETURN(llvm::Value * abs,\n                       EmitComplexAbs(component_type, operand_value));\n   TF_ASSIGN_OR_RETURN(llvm::Value * log_abs, EmitLog(component_type, abs));\n-  return EmitComposeComplex(op, log_abs, angle);\n+  return EmitComposeComplex(op, log_abs, angle, module_, b_);\n }\n \n // Using our EmitComplexPower formula, but setting c=0.5 and d=0, we get:\n@@ -1871,8 +1954,9 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexSqrt(\n     imag_part = Select(FCmpOEQ(sin, zero), sin, FMul(r, sin));\n   }\n \n-  return Select(FCmpOEQ(r, zero), EmitComposeComplex(op, zero, zero),\n-                EmitComposeComplex(op, real_part, imag_part));\n+  return Select(FCmpOEQ(r, zero),\n+                EmitComposeComplex(op, zero, zero, module_, b_),\n+                EmitComposeComplex(op, real_part, imag_part, module_, b_));\n }\n \n // Similar to Sqrt, we can use our EmitComplexPower formula, but set\n@@ -1938,7 +2022,7 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexRsqrt(\n     imag_part = Select(is_zero_zero, nan, FMul(r, sin));\n   }\n \n-  return EmitComposeComplex(op, real_part, imag_part);\n+  return EmitComposeComplex(op, real_part, imag_part, module_, b_);\n }\n \n //   lhs_value^rhs_value\n@@ -1980,34 +2064,38 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexPower(\n   // Nothing's Sign Bit, W. Kahan, Section 10.\n   auto cutoff_0 =\n       Select(And(And(FCmpOEQ(abs, zero), FCmpOEQ(d, zero)), FCmpOLE(zero, c)),\n-             EmitComposeComplex(op, Select(FCmpOEQ(zero, c), one, zero), zero),\n-             EmitComposeComplex(op, FMul(coeff, cos_q), FMul(coeff, sin_q)));\n+             EmitComposeComplex(op, Select(FCmpOEQ(zero, c), one, zero), zero,\n+                                module_, b_),\n+             EmitComposeComplex(op, FMul(coeff, cos_q), FMul(coeff, sin_q),\n+                                module_, b_));\n \n   // Case 1:\n   // x^0 is defined to be 1 for any x, see\n   // Branch Cuts for Complex Elementary Functions or Much Ado About\n   // Nothing's Sign Bit, W. Kahan, Section 10.\n-  auto cutoff_1 = Select(And(FCmpOEQ(zero, c), FCmpOEQ(d, zero)),\n-                         EmitComposeComplex(op, one, zero), cutoff_0);\n+  auto cutoff_1 =\n+      Select(And(FCmpOEQ(zero, c), FCmpOEQ(d, zero)),\n+             EmitComposeComplex(op, one, zero, module_, b_), cutoff_0);\n \n   // Case 2:\n   // 1^(c + d*i) = 1 + 0*i\n-  auto cutoff_2 = Select(And(FCmpOEQ(a, one), FCmpOEQ(b, zero)),\n-                         EmitComposeComplex(op, one, zero), cutoff_1);\n+  auto cutoff_2 =\n+      Select(And(FCmpOEQ(a, one), FCmpOEQ(b, zero)),\n+             EmitComposeComplex(op, one, zero, module_, b_), cutoff_1);\n \n   // Case 3:\n   // inf^(c + 0*i) = inf + 0*i, c > 0\n   auto cutoff_3 = Select(\n       And(FCmpOEQ(a, inf),\n           And(FCmpOEQ(b, zero), And(FCmpOEQ(d, zero), FCmpOGT(c, zero)))),\n-      EmitComposeComplex(op, inf, zero), cutoff_2);\n+      EmitComposeComplex(op, inf, zero, module_, b_), cutoff_2);\n \n   // Case 4:\n   // inf^(c + 0*i) = 0 + 0*i, c < 0\n   auto cutoff_4 = Select(\n       And(FCmpOEQ(a, inf),\n           And(FCmpOEQ(b, zero), And(FCmpOEQ(d, zero), FCmpOLT(c, zero)))),\n-      EmitComposeComplex(op, zero, zero), cutoff_3);\n+      EmitComposeComplex(op, zero, zero, module_, b_), cutoff_3);\n \n   return cutoff_4;\n }\n@@ -2073,15 +2161,15 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitComplexBinaryOp(\n           llvm_ir::PrimitiveTypeToIrType(component_type, module_->getContext());\n       auto zero = llvm::ConstantFP::get(type, 0.0);\n       auto one = llvm::ConstantFP::get(type, 1.0);\n-      auto i = EmitComposeComplex(op, zero, one);\n+      auto i = EmitComposeComplex(op, zero, one, module_, b_);\n       TF_ASSIGN_OR_RETURN(auto i_times_y, EmitComplexMultiply(op, i, y));\n       TF_ASSIGN_OR_RETURN(auto x_plus_iy, EmitComplexAdd(op, x, i_times_y));\n       TF_ASSIGN_OR_RETURN(\n           auto div_result,\n           EmitComplexDivide(op, x_plus_iy, sqrt_x_squared_plus_y_squared));\n       TF_ASSIGN_OR_RETURN(auto log_result, EmitComplexLog(op, div_result));\n       auto negative_one = llvm::ConstantFP::get(type, -1.0);\n-      auto negative_i = EmitComposeComplex(op, zero, negative_one);\n+      auto negative_i = EmitComposeComplex(op, zero, negative_one, module_, b_);\n       return EmitComplexMultiply(op, negative_i, log_result);\n     }\n     default:\n@@ -3345,63 +3433,7 @@ llvm_ir::ElementGenerator ElementalIrEmitter::MakeElementGenerator(\n     case HloOpcode::kIota:\n       return [this, hlo](const IrArray::Index& target_index)\n                  -> absl::StatusOr<llvm::Value*> {\n-        auto* iota = Cast<HloIotaInstruction>(hlo);\n-        PrimitiveType element_type = iota->shape().element_type();\n-        IrArray::Index elem_index =\n-            iota->shape().dimensions().size() > 1\n-                ? target_index.SourceIndexOfBroadcast(\n-                      iota->shape(),\n-                      ShapeUtil::MakeShapeWithDescendingLayout(\n-                          element_type,\n-                          {iota->shape().dimensions(iota->iota_dimension())}),\n-                      {iota->iota_dimension()}, b_)\n-                : target_index;\n-        llvm::Value* elem_index_linear = elem_index.linear();\n-        if (elem_index_linear == nullptr) {\n-          std::vector<int64_t> iota_bound = {\n-              iota->shape().dimensions(iota->iota_dimension())};\n-          elem_index_linear = elem_index.Linearize(iota_bound, b_);\n-        }\n-        Shape component_shape =\n-            ShapeUtil::ElementIsComplex(iota->shape())\n-                ? ShapeUtil::ComplexComponentShape(iota->shape())\n-                : iota->shape();\n-        PrimitiveType component_element_type = component_shape.element_type();\n-        llvm::Value* iota_result;\n-        if (primitive_util::IsIntegralType(component_element_type)) {\n-          iota_result = b_->CreateIntCast(\n-              elem_index_linear,\n-              llvm_ir::PrimitiveTypeToIrType(component_element_type,\n-                                             module_->getContext()),\n-              /*isSigned=*/false);\n-        } else {\n-          TF_RET_CHECK(\n-              primitive_util::IsFloatingPointType(component_element_type))\n-              << component_element_type;\n-          llvm::Type* float_ir_type;\n-          if (component_element_type == F8E4M3FNUZ ||\n-              component_element_type == F8E5M2FNUZ) {\n-            float_ir_type =\n-                llvm_ir::PrimitiveTypeToIrType(F16, module_->getContext());\n-          } else {\n-            float_ir_type = llvm_ir::PrimitiveTypeToIrType(\n-                component_element_type, module_->getContext());\n-          }\n-          llvm::Value* float_val =\n-              b_->CreateUIToFP(elem_index_linear, float_ir_type);\n-          if (component_element_type == F8E4M3FNUZ ||\n-              component_element_type == F8E5M2FNUZ) {\n-            iota_result = EmitFxToF8e(module_, F16, component_element_type,\n-                                      float_val, b_);\n-          } else {\n-            iota_result = float_val;\n-          }\n-        }\n-        if (ShapeUtil::ElementIsComplex(iota->shape())) {\n-          return EmitComposeComplex(iota, iota_result, nullptr);\n-        } else {\n-          return iota_result;\n-        }\n+        return EmitIota(hlo, target_index, module_, b_);\n       };\n     case HloOpcode::kSlice:\n       return [this, hlo, &operand_to_generator](\n@@ -3537,19 +3569,6 @@ llvm::Value* ElementalIrEmitter::EmitExtractImag(llvm::Value* value) {\n   return ExtractValue(value, {1});\n }\n \n-llvm::Value* ElementalIrEmitter::EmitComposeComplex(const HloInstruction* op,\n-                                                    llvm::Value* real,\n-                                                    llvm::Value* imag) {\n-  auto cplx_type = llvm_ir::PrimitiveTypeToIrType(op->shape().element_type(),\n-                                                  module_->getContext());\n-  auto complex =\n-      InsertValue(llvm::ConstantAggregateZero::get(cplx_type), real, {0});\n-  if (imag != nullptr) {\n-    complex = InsertValue(complex, imag, {1});\n-  }\n-  return complex;\n-}\n-\n llvm::Value* ElementalIrEmitter::EmitMulAdd(llvm::Value* lhs, llvm::Value* rhs,\n                                             llvm::Value* accumulator,\n                                             xla::PrimitiveType primitive_type) {"
        },
        {
            "sha": "43deb25a8dfb7fd28061206bc9060f3de98f7766",
            "filename": "third_party/xla/xla/service/elemental_ir_emitter.h",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.h?ref=87cc79dddaacb9a2a3d8fabf4dd5181334cbb47b",
            "patch": "@@ -256,10 +256,6 @@ class ElementalIrEmitter : public IrBuilderMixin<ElementalIrEmitter> {\n       absl::Span<llvm::Value* const> accumulator_addrs,\n       llvm::ArrayRef<llvm::Type*> accumulator_types, bool is_variadic);\n \n-  // Composes a complex struct. imag may be nullptr for simple cast operations.\n-  llvm::Value* EmitComposeComplex(const HloInstruction* op, llvm::Value* real,\n-                                  llvm::Value* imag);\n-\n   // Emit `accumulator + lhs * rhs` for the given primitive type.\n   llvm::Value* EmitMulAdd(llvm::Value* lhs, llvm::Value* rhs,\n                           llvm::Value* accumulator,\n@@ -371,6 +367,11 @@ class ElementalIrEmitterForTests : public ElementalIrEmitter {\n \n   HloToElementGeneratorMap generator_map_;\n };\n+\n+absl::StatusOr<llvm::Value*> EmitIota(\n+    const HloInstruction* hlo, const llvm_ir::IrArray::Index& target_index,\n+    llvm::Module* module, llvm::IRBuilderBase* b);\n+\n }  // namespace xla\n \n #endif  // XLA_SERVICE_ELEMENTAL_IR_EMITTER_H_"
        }
    ],
    "stats": {
        "total": 418,
        "additions": 244,
        "deletions": 174
    }
}