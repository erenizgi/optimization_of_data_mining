{
    "author": "ZixuanJiang",
    "message": "Ignore the divisibility if source OR target tile assignment is 1 in `PatternMatchMergeOrSplitSharding`.\n\nBefore this cl, we still consider the divisibility if source tile assignment is 1, which is too strict.\n\nRefactor the existing test targets on `ComplexReshardUnmerge`. Add new test targets.\n\nPiperOrigin-RevId: 799407760",
    "sha": "2dcb29f28f774b1249aba1859a90d12b3664e20a",
    "files": [
        {
            "sha": "f51cfd1377c8339270746bdab92eee1b439d43e6",
            "filename": "third_party/xla/xla/service/spmd/spmd_partitioner.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2dcb29f28f774b1249aba1859a90d12b3664e20a/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2dcb29f28f774b1249aba1859a90d12b3664e20a/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc?ref=2dcb29f28f774b1249aba1859a90d12b3664e20a",
            "patch": "@@ -2056,11 +2056,11 @@ PatternMatchMergeOrSplitSharding(const Shape& shape, const Shape& base_shape,\n     if (si == ti) {\n       continue;\n     }\n-    if (ti == 1) {\n+    auto [min, max] = std::minmax(si, ti);\n+    if (min == 1) {\n       diff_index.push_back(i);\n       continue;\n     }\n-    auto [min, max] = std::minmax(si, ti);\n     if (max % min != 0) {\n       continue;\n     }"
        },
        {
            "sha": "33ea60f54d79c1bd085d1017ebcab33649d2864f",
            "filename": "third_party/xla/xla/service/spmd/spmd_partitioner_test.cc",
            "status": "modified",
            "additions": 51,
            "deletions": 40,
            "changes": 91,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2dcb29f28f774b1249aba1859a90d12b3664e20a/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2dcb29f28f774b1249aba1859a90d12b3664e20a/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner_test.cc?ref=2dcb29f28f774b1249aba1859a90d12b3664e20a",
            "patch": "@@ -15207,87 +15207,98 @@ ENTRY %main.21 {\n               AllOf(op::Shape(\"s32[2,64]\"), op::Scatter(p0, p0_copy, p0_copy)));\n }\n \n-TEST_P(SpmdPartitioningTest, ComplexReshardUnmerge) {\n+TEST_P(SpmdPartitioningTest, ComplexReshardSplit) {\n   const char* const hlo_string = R\"(\n HloModule Test\n \n-ENTRY main.4 {\n-  Arg_0.1 = f32[8,8,8,8]{3,2,1,0} parameter(0), sharding={devices=[1,1,2,8]0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}\n-  tuple.2 = (f32[8,8,8,8]{3,2,1,0}) tuple(Arg_0.1), sharding={{devices=[1,4,2,2]0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}\n-  ROOT get-tuple-element.3 = f32[8,8,8,8]{3,2,1,0} get-tuple-element(tuple.2), index=0, sharding={devices=[1,4,2,2]0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}\n+ENTRY main {\n+  p0 = f32[8,8,8] parameter(0), sharding={devices=[1,2,8]<=[16]}\n+  ROOT copy = f32[8,8,8] copy(p0), sharding={devices=[4,2,2]<=[16]}\n }\n )\";\n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n                           PartitionComputation(hlo_string, /*num_devices=*/16));\n \n-  XLA_VLOG_LINES(1, module->ToString());\n-  auto* allreduce = FindInstruction(module.get(), HloOpcode::kAllReduce);\n-  EXPECT_EQ(allreduce, nullptr);\n-  auto* alltoall = FindInstruction(module.get(), HloOpcode::kAllToAll);\n-  EXPECT_NE(alltoall, nullptr);\n+  const HloComputation* entry = module->entry_computation();\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kAllReduce), 0);\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kAllToAll), 1);\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kCollectivePermute), 1);\n }\n \n-TEST_P(SpmdPartitioningTest, ComplexReshardUnmergeToRight) {\n+TEST_P(SpmdPartitioningTest, ComplexReshardSplitToRight) {\n   const char* const hlo_string = R\"(\n HloModule Test\n \n-ENTRY main.4 {\n-  Arg_0.1 = f32[8,32]{1,0} parameter(0), sharding={devices=[8,1]<=[4,2]T(1,0)}\n-  tuple.2 = (f32[8,32]{1,0}) tuple(Arg_0.1), sharding={{devices=[2,4]<=[4,2]T(1,0)}}\n-  ROOT get-tuple-element.3 = f32[8,32]{1,0} get-tuple-element(tuple.2), index=0, sharding={devices=[2,4]<=[4,2]T(1,0)}\n+ENTRY main {\n+  p0 = f32[8,32] parameter(0), sharding={devices=[8,1]<=[8]}\n+  ROOT copy = f32[8,32] copy(p0), sharding={devices=[2,4]<=[8]}\n }\n )\";\n \n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n                           PartitionComputation(hlo_string, /*num_devices=*/8));\n \n-  XLA_VLOG_LINES(1, module->ToString());\n-  auto* allreduce = FindInstruction(module.get(), HloOpcode::kAllReduce);\n-  EXPECT_EQ(allreduce, nullptr);\n-  auto* alltoall = FindInstruction(module.get(), HloOpcode::kAllToAll);\n-  EXPECT_NE(alltoall, nullptr);\n+  const HloComputation* entry = module->entry_computation();\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kAllReduce), 0);\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kAllToAll), 1);\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kCollectivePermute), 0);\n }\n \n-TEST_P(SpmdPartitioningTest, ComplexReshardUnmergeToLeft) {\n+TEST_P(SpmdPartitioningTest, ComplexReshardSplitToLeft1) {\n   const char* const hlo_string = R\"(\n HloModule Test\n \n-ENTRY main.4 {\n-  Arg_0.1 = f32[8,32]{1,0} parameter(0), sharding={devices=[1,8]<=[4,2]T(1,0)}\n-  tuple.2 = (f32[8,32]{1,0}) tuple(Arg_0.1), sharding={{devices=[2,4]<=[4,2]T(1,0)}}\n-  ROOT get-tuple-element.3 = f32[8,32]{1,0} get-tuple-element(tuple.2), index=0, sharding={devices=[2,4]<=[4,2]T(1,0)}\n+ENTRY main {\n+  p0 = f32[8,32] parameter(0), sharding={devices=[1,8]<=[8]}\n+  ROOT copy = f32[8,32] copy(p0), sharding={devices=[2,4]<=[4,2]T(1,0)}\n }\n )\";\n \n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n                           PartitionComputation(hlo_string, /*num_devices=*/8));\n \n-  XLA_VLOG_LINES(1, module->ToString());\n-  auto* allreduce = FindInstruction(module.get(), HloOpcode::kAllReduce);\n-  EXPECT_EQ(allreduce, nullptr);\n-  auto* alltoall = FindInstruction(module.get(), HloOpcode::kAllToAll);\n-  EXPECT_NE(alltoall, nullptr);\n+  const HloComputation* entry = module->entry_computation();\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kAllReduce), 0);\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kAllToAll), 1);\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kCollectivePermute), 0);\n }\n \n-TEST_P(SpmdPartitioningTest, NoComplexReshardUnmergeToLeft) {\n+TEST_P(SpmdPartitioningTest, ComplexReshardSplitToLeft2) {\n   const char* const hlo_string = R\"(\n HloModule Test\n \n-ENTRY main.4 {\n-  Arg_0.1 = f32[8,33]{1,0} parameter(0), sharding={devices=[1,8]<=[4,2]T(1,0)}\n-  tuple.2 = (f32[8,33]{1,0}) tuple(Arg_0.1), sharding={{devices=[2,4]<=[4,2]T(1,0)}}\n-  ROOT get-tuple-element.3 = f32[8,33]{1,0} get-tuple-element(tuple.2), index=0, sharding={devices=[2,4]<=[4,2]T(1,0)}\n+ENTRY main {\n+  p0 = f32[5,32] parameter(0), sharding={devices=[1,8]<=[8]}\n+  ROOT copy = f32[5,32] copy(p0), sharding={devices=[4,2]<=[2,4]T(1,0)}\n }\n )\";\n \n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n                           PartitionComputation(hlo_string, /*num_devices=*/8));\n \n-  XLA_VLOG_LINES(1, module->ToString());\n-  auto* allreduce = FindInstruction(module.get(), HloOpcode::kAllReduce);\n-  EXPECT_NE(allreduce, nullptr);\n-  auto* alltoall = FindInstruction(module.get(), HloOpcode::kAllToAll);\n-  EXPECT_EQ(alltoall, nullptr);\n+  const HloComputation* entry = module->entry_computation();\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kAllReduce), 0);\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kAllToAll), 1);\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kCollectivePermute), 0);\n+}\n+\n+TEST_P(SpmdPartitioningTest, NoComplexReshardSplitToLeft) {\n+  const char* const hlo_string = R\"(\n+HloModule Test\n+\n+ENTRY main {\n+  p0 = f32[8,33] parameter(0), sharding={devices=[1,8]<=[8]}\n+  ROOT copy = f32[8,33] copy(p0), sharding={devices=[2,4]<=[4,2]T(1,0)}\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          PartitionComputation(hlo_string, /*num_devices=*/8));\n+\n+  const HloComputation* entry = module->entry_computation();\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kAllReduce), 1);\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kAllToAll), 0);\n+  EXPECT_EQ(NumOfInstructions(entry, HloOpcode::kCollectivePermute), 0);\n }\n \n TEST_P(SpmdPartitioningTest, ReshardCrash) {"
        }
    ],
    "stats": {
        "total": 95,
        "additions": 53,
        "deletions": 42
    }
}