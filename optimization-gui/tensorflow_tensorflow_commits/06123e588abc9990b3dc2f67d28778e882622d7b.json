{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 832711169",
    "sha": "06123e588abc9990b3dc2f67d28778e882622d7b",
    "files": [
        {
            "sha": "29ed664e7ae78f2947b9d24ec16ff5fb4af4f855",
            "filename": "tensorflow/compiler/mlir/lite/python/jax_to_tfl_flatbuffer.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06123e588abc9990b3dc2f67d28778e882622d7b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Fjax_to_tfl_flatbuffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06123e588abc9990b3dc2f67d28778e882622d7b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Fjax_to_tfl_flatbuffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Fjax_to_tfl_flatbuffer.h?ref=06123e588abc9990b3dc2f67d28778e882622d7b",
            "patch": "@@ -31,7 +31,7 @@ namespace tensorflow {\n // error status if it fails to convert the input.\n absl::Status ConvertJaxToTFLiteFlatBuffer(\n     const std::string& input, const tflite::ModelFlags& model_flags,\n-    tflite::ConverterFlags& converter_flags, string* result);\n+    tflite::ConverterFlags& converter_flags, std::string* result);\n \n }  // namespace tensorflow\n "
        },
        {
            "sha": "c334f24442b49176b9482fa57cf038bfd213b049",
            "filename": "tensorflow/compiler/mlir/lite/python/saved_model_to_tfl_flatbuffer.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06123e588abc9990b3dc2f67d28778e882622d7b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Fsaved_model_to_tfl_flatbuffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06123e588abc9990b3dc2f67d28778e882622d7b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Fsaved_model_to_tfl_flatbuffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Fsaved_model_to_tfl_flatbuffer.cc?ref=06123e588abc9990b3dc2f67d28778e882622d7b",
            "patch": "@@ -140,8 +140,8 @@ absl::Status ConvertSavedModelToTFLiteFlatBuffer(\n   mlir::TFL::QuantizationSpecs quant_specs;\n \n   // Parse input arrays.\n-  std::vector<string> node_names;\n-  std::vector<string> node_dtypes;\n+  std::vector<std::string> node_names;\n+  std::vector<std::string> node_dtypes;\n   std::vector<std::optional<std::vector<int>>> node_shapes;\n   std::vector<std::optional<double>> node_mins;\n   std::vector<std::optional<double>> node_maxs;"
        },
        {
            "sha": "446652ccb8da05ec20c2181c987221eb00f16417",
            "filename": "tensorflow/compiler/mlir/lite/python/saved_model_to_tfl_flatbuffer.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06123e588abc9990b3dc2f67d28778e882622d7b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Fsaved_model_to_tfl_flatbuffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06123e588abc9990b3dc2f67d28778e882622d7b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Fsaved_model_to_tfl_flatbuffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Fsaved_model_to_tfl_flatbuffer.h?ref=06123e588abc9990b3dc2f67d28778e882622d7b",
            "patch": "@@ -32,7 +32,7 @@ namespace tensorflow {\n // error status if it fails to convert the input.\n absl::Status ConvertSavedModelToTFLiteFlatBuffer(\n     const tflite::ModelFlags& model_flags,\n-    tflite::ConverterFlags& converter_flags, string* result,\n+    tflite::ConverterFlags& converter_flags, std::string* result,\n     const quantization::PyFunctionLibrary* quantization_py_function_lib);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "de75080ab5da82898af0f994ec24f73dfcacd7bf",
            "filename": "tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.h",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06123e588abc9990b3dc2f67d28778e882622d7b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Ftf_tfl_flatbuffer_helpers.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06123e588abc9990b3dc2f67d28778e882622d7b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Ftf_tfl_flatbuffer_helpers.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fpython%2Ftf_tfl_flatbuffer_helpers.h?ref=06123e588abc9990b3dc2f67d28778e882622d7b",
            "patch": "@@ -46,8 +46,8 @@ absl::Status RegisterAllCustomOps(\n absl::Status PopulateQuantizationSpecs(\n     const tflite::ModelFlags& model_flags,\n     tflite::ConverterFlags& converter_flags,\n-    mlir::TFL::QuantizationSpecs* quant_specs, std::vector<string>* node_names,\n-    std::vector<string>* node_dtypes,\n+    mlir::TFL::QuantizationSpecs* quant_specs,\n+    std::vector<std::string>* node_names, std::vector<std::string>* node_dtypes,\n     std::vector<std::optional<std::vector<int>>>* node_shapes,\n     std::vector<std::optional<double>>* node_mins,\n     std::vector<std::optional<double>>* node_maxs);\n@@ -60,7 +60,8 @@ absl::Status ConvertMLIRToTFLiteFlatBuffer(\n     std::unique_ptr<mlir::MLIRContext>&& context,\n     mlir::OwningOpRef<mlir::ModuleOp> module,\n     const mlir::TFL::PassConfig& pass_config,\n-    const std::unordered_set<std::string>& saved_model_tags, string* result,\n+    const std::unordered_set<std::string>& saved_model_tags,\n+    std::string* result,\n     const quantization::PyFunctionLibrary* quantization_py_function_lib);\n \n // Give a warning for any unused flags that have been specified."
        }
    ],
    "stats": {
        "total": 15,
        "additions": 8,
        "deletions": 7
    }
}