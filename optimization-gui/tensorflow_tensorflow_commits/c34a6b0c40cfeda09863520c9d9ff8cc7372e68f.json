{
    "author": "ImanHosseini",
    "message": "Make LHS less latency-aggressive on retries\n\nPiperOrigin-RevId: 813667543",
    "sha": "c34a6b0c40cfeda09863520c9d9ff8cc7372e68f",
    "files": [
        {
            "sha": "9b1c12d422d97a15a17cf80d8b81b1752a7d1495",
            "filename": "third_party/xla/xla/service/latency_hiding_scheduler.cc",
            "status": "modified",
            "additions": 71,
            "deletions": 8,
            "changes": 79,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c34a6b0c40cfeda09863520c9d9ff8cc7372e68f/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c34a6b0c40cfeda09863520c9d9ff8cc7372e68f/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc?ref=c34a6b0c40cfeda09863520c9d9ff8cc7372e68f",
            "patch": "@@ -1076,6 +1076,28 @@ int64_t GetNumHopsToClosestSelectiveOverlap(\n   return num_hops_to_closest_selective_resource_occupier;\n }\n \n+static constexpr double kAsyncDepthRtolCoefficient = 0.35;\n+static constexpr double kAsyncDepthDeprioritizationThreshold = 0.5;\n+\n+// Returns a relative tolerance for the async depth comparison. When retrying\n+// due to high memory peak we want to deprioritize async depth and let other\n+// properties be considered.\n+double AsyncDepthRtol(const DefaultSchedulerCore::RetryState& retry_state) {\n+  if (retry_state.run_index == 0) {\n+    return 0.0;\n+  }\n+  if (retry_state.memory_peak < retry_state.memory_limit) {\n+    return 0.0;\n+  }\n+  double memory_excess =\n+      static_cast<double>(retry_state.memory_peak - retry_state.memory_limit) /\n+      static_cast<double>(retry_state.memory_limit + 1.0);\n+  if (memory_excess < kAsyncDepthDeprioritizationThreshold) {\n+    return 0.0;\n+  }\n+  return std::min(1.0, kAsyncDepthRtolCoefficient * retry_state.run_index);\n+}\n+\n // Comparator for the ready set. This class represents the priority policies\n // for the nodes in the ready set. The policy can be whatever is appropriate to\n // reduce the execution time of the graph or achieve interesting properties\n@@ -1112,6 +1134,28 @@ class ReadySetLt {\n       RETURN_LOGIC(v, reason_str);                      \\\n     }                                                   \\\n   } while (0)\n+\n+// This is a generalization of CMP_PROPERTY that allows for a relative tolerance\n+// to be specified such that this comparison is only performed if relative\n+// difference between the properties is above the specified relative tolerance.\n+// This is to allow skipping the comparison for minimal differences and let\n+// other properties be considered.\n+#define CMP_PROPERTY_WITH_RTOL(property, rtol, reason_str) \\\n+  do {                                                     \\\n+    auto avalue = an->property;                            \\\n+    auto bvalue = bn->property;                            \\\n+    if (avalue == 0 && bvalue == 0) {                      \\\n+      /* Nothing to do if both are zero. */                \\\n+    } else {                                               \\\n+      double diff = std::abs(avalue - bvalue);             \\\n+      double max_val = std::max(avalue, bvalue);           \\\n+      if (max_val > 0 && (diff / max_val) > rtol) {        \\\n+        if (int v = ThreeWay(avalue, bvalue)) {            \\\n+          RETURN_LOGIC(v, reason_str);                     \\\n+        }                                                  \\\n+      }                                                    \\\n+    }                                                      \\\n+  } while (0)\n #define CMP_EXPLICIT(pa, pb, reason_str) \\\n   do {                                   \\\n     if (int v = ThreeWay((pa), (pb))) {  \\\n@@ -1134,7 +1178,8 @@ class ReadySetLt {\n         config_has_memory_limit_(config_memory_limit_ != UINT64_MAX),\n         has_target_scheduling_rule_(target_scheduling_rule_ != nullptr),\n         has_early_target_scheduling_rule_(early_target_scheduling_rule_ !=\n-                                          nullptr) {}\n+                                          nullptr),\n+        async_depth_rtol_(AsyncDepthRtol(sched_state_.retry_state)) {}\n \n   std::optional<bool> MemoryPressurePolicy(\n       const HloGraphNode* an, std::pair<int64_t, int64_t>& a_increase,\n@@ -1387,7 +1432,7 @@ class ReadySetLt {\n       // Try to favor paths that are dependent of chains of async operations\n       // with long latency as we want to get to them as soon as possible to\n       // overlap them with computation.\n-      CMP_PROPERTY(GetAsyncDepth(), \"kAsyncDepth\");\n+      CMP_PROPERTY_WITH_RTOL(GetAsyncDepth(), async_depth_rtol_, \"kAsyncDepth\");\n \n       // Favor nodes that are the closest in amount of latency they hide\n       // with the highest amount of latency that needs to be hidden to avoid\n@@ -1477,6 +1522,7 @@ class ReadySetLt {\n   bool config_has_memory_limit_;\n   bool has_target_scheduling_rule_;\n   bool has_early_target_scheduling_rule_;\n+  double async_depth_rtol_;\n \n   static bool IsNop(const HloGraphNode& gn) {\n     return IsNopInstruction(gn.GetOpcode(), gn.GetInstr());\n@@ -2939,9 +2985,9 @@ absl::Status DefaultSchedulerCore::SchedulingStep(\n     SchedulingState* sched_state) {\n   // Get the first available node for scheduling that is the node that\n   // satisfies our ready heuristic the best.\n-  TF_ASSIGN_OR_RETURN(HloGraphNode * node,\n-                      FindAndExtractBestNodeAvailable(\n-                          *sched_state, /*should_skip_node=*/nullptr));\n+  TF_ASSIGN_OR_RETURN(HloGraphNode * node, FindAndExtractBestNodeAvailable(\n+                                               *sched_state,\n+                                               /*should_skip_node=*/nullptr));\n   CHECK(node != nullptr);\n   TF_ASSIGN_OR_RETURN(sched_state->current_time,\n                       ScheduleNode(node, sched_state));\n@@ -3086,6 +3132,20 @@ DefaultSchedulerCore::MakeSchedulingState(const HloComputation* computation) {\n   return sched_state;\n }\n \n+absl::StatusOr<std::vector<HloInstruction*>>\n+DefaultSchedulerCore::ScheduleComputation(\n+    const HloComputation* computation, SchedulerCore::RetryState retry_state) {\n+  TF_ASSIGN_OR_RETURN(auto sched_state, MakeSchedulingState(computation));\n+  std::shared_ptr<DefaultSchedulerCore::SchedulingState> sched_state_ =\n+      std::dynamic_pointer_cast<DefaultSchedulerCore::SchedulingState>(\n+          sched_state);\n+  CHECK_NE(sched_state_, nullptr)\n+      << \"ScheduleComputation must be called with a \"\n+      << \"DefaultSchedulerCore::SchedulingState object.\";\n+  sched_state_->retry_state = retry_state;\n+  return ScheduleComputation(computation, sched_state);\n+}\n+\n absl::StatusOr<std::vector<HloInstruction*>>\n DefaultSchedulerCore::ScheduleComputation(const HloComputation* computation) {\n   TF_ASSIGN_OR_RETURN(auto sched_state, MakeSchedulingState(computation));\n@@ -3609,11 +3669,14 @@ absl::StatusOr<bool> LatencyHidingScheduler::Run(\n               << scheduler_core_->GetMemoryLimit()\n               << \". Setting the new limit to \"\n               << scheduler_core_->GetMemoryLimit() * 0.9;\n-    TF_RETURN_IF_ERROR(scheduler_core_->InitializeScheduler(module));\n+    SchedulerCore::RetryState retry_state = {iter + 1,\n+                                             scheduler_core_->GetMemoryLimit(),\n+                                             scheduler_core_->GetMemoryPeak()};\n     scheduler_core_->SetMemoryLimit(scheduler_core_->GetMemoryLimit() * 0.9);\n     for (HloComputation* computation : computations_to_schedule_) {\n-      TF_ASSIGN_OR_RETURN(std::vector<HloInstruction*> new_schedule,\n-                          scheduler_core_->ScheduleComputation(computation));\n+      TF_ASSIGN_OR_RETURN(\n+          std::vector<HloInstruction*> new_schedule,\n+          scheduler_core_->ScheduleComputation(computation, retry_state));\n       scheduling_context_->GetAsyncTracker()->UpdateTargetDefinedStates(\n           computation);\n       module->schedule().set_sequence(computation,"
        },
        {
            "sha": "8ff6a437b174883d26eca01cf107c24378a09f84",
            "filename": "third_party/xla/xla/service/latency_hiding_scheduler.h",
            "status": "modified",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c34a6b0c40cfeda09863520c9d9ff8cc7372e68f/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c34a6b0c40cfeda09863520c9d9ff8cc7372e68f/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h?ref=c34a6b0c40cfeda09863520c9d9ff8cc7372e68f",
            "patch": "@@ -392,6 +392,12 @@ class SchedulerCore {\n     virtual ~SchedulingState() = default;\n   };\n \n+  struct RetryState {\n+    int64_t run_index = 0;\n+    uint64_t memory_limit = UINT64_MAX;\n+    int64_t memory_peak = 0;\n+  };\n+\n   // Hook function to modify scheduling graph before scheduler runs.\n   using GraphProcessingHook = std::function<absl::Status(HloScheduleGraph*)>;\n \n@@ -405,6 +411,11 @@ class SchedulerCore {\n   MakeSchedulingState(const HloComputation* computation) {\n     return absl::UnimplementedError(\"Not implemented.\");\n   }\n+  virtual absl::StatusOr<std::vector<HloInstruction*>> ScheduleComputation(\n+      const HloComputation* computation,\n+      const SchedulerCore::RetryState retry_state) {\n+    return absl::UnimplementedError(\"Not implemented.\");\n+  }\n   virtual absl::StatusOr<std::vector<HloInstruction*>> ScheduleComputation(\n       const HloComputation* computation) {\n     return absl::UnimplementedError(\"Not implemented.\");\n@@ -1572,6 +1583,10 @@ class DefaultSchedulerCore : public SchedulerCore {\n     // reversed before assigning to the HloSchedule.\n     std::vector<HloInstruction*> new_sequence_reversed;\n \n+    // The RetryState is optional, meaning retry-specific logic might\n+    // not be active for all scheduling runs.\n+    SchedulerCore::RetryState retry_state;\n+\n     // Memory pressure during and after an instruction in a schedule.\n     // (memory_after, memory_peak)\n     absl::flat_hash_map<const HloInstruction*, std::pair<int64_t, int64_t>>\n@@ -1675,6 +1690,9 @@ class DefaultSchedulerCore : public SchedulerCore {\n \n   absl::StatusOr<std::shared_ptr<SchedulerCore::SchedulingState>>\n   MakeSchedulingState(const HloComputation* computation) override;\n+  absl::StatusOr<std::vector<HloInstruction*>> ScheduleComputation(\n+      const HloComputation* computation,\n+      SchedulerCore::RetryState retry_state) override;\n   absl::StatusOr<std::vector<HloInstruction*>> ScheduleComputation(\n       const HloComputation* computation) override;\n   absl::StatusOr<std::vector<HloInstruction*>> ScheduleComputation("
        }
    ],
    "stats": {
        "total": 97,
        "additions": 89,
        "deletions": 8
    }
}