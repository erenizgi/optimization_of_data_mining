{
    "author": "bixia1",
    "message": "Rename `WeightInfo` to `DimensionInfo`, `HloWeightPropagation` to `HloDimensionInfoPropagation\".\n\nThis change renames the `WeightInfo` enum and related types/methods to `DimensionInfo` to better reflect that the analysis can be extended beyond just identifying weights.\n\nPiperOrigin-RevId: 830619555",
    "sha": "9720752fe90d5dd68001899948c71a4ca13f58bf",
    "files": [
        {
            "sha": "b38c33cf146b2987bc95fe271d4c02a37b691749",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_dimension_analysis.cc",
            "status": "modified",
            "additions": 72,
            "deletions": 63,
            "changes": 135,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9720752fe90d5dd68001899948c71a4ca13f58bf/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9720752fe90d5dd68001899948c71a4ca13f58bf/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.cc?ref=9720752fe90d5dd68001899948c71a4ca13f58bf",
            "patch": "@@ -48,12 +48,12 @@ bool HloDimensionAnalysis::IsInstructionWeight(\n     return false;\n   }\n   return absl::c_any_of(it->second.leaves(),\n-                        [](const std::pair<ShapeIndex, WeightInfo>& leaf) {\n-                          return leaf.second == WeightInfo::kWeight;\n+                        [](const std::pair<ShapeIndex, DimensionInfo>& leaf) {\n+                          return leaf.second == DimensionInfo::kWeight;\n                         });\n }\n \n-std::optional<ShapeTree<WeightInfo>> HloDimensionAnalysis::GetWeightInfo(\n+std::optional<ShapeTree<DimensionInfo>> HloDimensionAnalysis::GetDimensionInfo(\n     const HloInstruction* instruction) const {\n   auto it = info_map_.find(instruction);\n   if (it == info_map_.end()) {\n@@ -66,31 +66,31 @@ absl::Status HloDimensionAnalysis::SetInstructionAsWeight(\n     HloInstruction* instruction) {\n   auto [it, success] = info_map_.emplace(\n       std::piecewise_construct, std::forward_as_tuple(instruction),\n-      std::forward_as_tuple(instruction->shape(), WeightInfo::kUnknown));\n+      std::forward_as_tuple(instruction->shape(), DimensionInfo::kUnknown));\n \n   if (!success) {\n     return absl::InternalError(absl::StrCat(\n         \"Instruction \", instruction->ToString(), \" already has weight info.\"));\n   }\n \n-  ShapeTree<WeightInfo>& weight_tree = it->second;\n-  weight_tree.ForEachMutableElement(\n-      [&](const ShapeIndex& index, WeightInfo* weight_info) {\n-        if (weight_tree.IsLeaf(index)) {\n-          *weight_info = WeightInfo::kWeight;\n+  ShapeTree<DimensionInfo>& dim_info_tree = it->second;\n+  dim_info_tree.ForEachMutableElement(\n+      [&](const ShapeIndex& index, DimensionInfo* operation_info) {\n+        if (dim_info_tree.IsLeaf(index)) {\n+          *operation_info = DimensionInfo::kWeight;\n           return;\n         }\n-        *weight_info = WeightInfo::kTuple;\n+        *operation_info = DimensionInfo::kTuple;\n       });\n   return absl::OkStatus();\n }\n \n-absl::Status HloDimensionAnalysis::SetWeightInfo(\n-    const HloInstruction* target, ShapeTree<WeightInfo> weight_annotation) {\n-  auto [it, success] = info_map_.emplace(target, std::move(weight_annotation));\n+absl::Status HloDimensionAnalysis::SetDimensionInfo(\n+    const HloInstruction* target, ShapeTree<DimensionInfo> annotation) {\n+  auto [it, success] = info_map_.emplace(target, std::move(annotation));\n   if (!success) {\n     return absl::InternalError(absl::StrCat(\"Instruction \", target->ToString(),\n-                                            \" already has weight info.\"));\n+                                            \" already has dimensioin info.\"));\n   }\n   return absl::OkStatus();\n }\n@@ -109,20 +109,18 @@ absl::Status HloDimensionAnalysis::AnnotateEntryComputationParameters(\n absl::StatusOr<std::unique_ptr<HloDimensionAnalysis>> HloDimensionAnalysis::Run(\n     const HloModule& module,\n     const absl::flat_hash_set<absl::string_view>& execution_threads) {\n-  std::unique_ptr<HloDimensionAnalysis> weight_analysis =\n+  std::unique_ptr<HloDimensionAnalysis> analysis =\n       absl::WrapUnique(new HloDimensionAnalysis(module, execution_threads));\n-  TF_RETURN_IF_ERROR(\n-      weight_analysis->AnnotateEntryComputationParameters(module));\n-  TF_RETURN_IF_ERROR(\n-      weight_analysis->RunOnComputation(*module.entry_computation()));\n-  return weight_analysis;\n+  TF_RETURN_IF_ERROR(analysis->AnnotateEntryComputationParameters(module));\n+  TF_RETURN_IF_ERROR(analysis->RunOnComputation(*module.entry_computation()));\n+  return analysis;\n }\n \n absl::Status HloDimensionAnalysis::RunOnComputation(\n     const HloComputation& computation) {\n   if (HloInstruction::IsThreadIncluded(computation.execution_thread(),\n                                        execution_threads_)) {\n-    HloWeightPropagation propagation(this);\n+    HloDimensionInfoPropagation propagation(this);\n     return propagation.Run(computation);\n   }\n   return absl::OkStatus();\n@@ -133,17 +131,18 @@ absl::Status HloDimensionAnalysis::RunOnComputation(\n     absl::Span<const HloInstruction* const> operands) {\n   CHECK_EQ(computation.num_parameters(), operands.size());\n   for (int i = 0; i < computation.num_parameters(); ++i) {\n-    auto weight_info_iter = info_map_.find(operands[i]);\n-    if (weight_info_iter == info_map_.end()) {\n+    auto operation_info_iter = info_map_.find(operands[i]);\n+    if (operation_info_iter == info_map_.end()) {\n       continue;\n     }\n-    TF_RETURN_IF_ERROR(SetWeightInfo(computation.parameter_instructions()[i],\n-                                     weight_info_iter->second));\n+    TF_RETURN_IF_ERROR(SetDimensionInfo(computation.parameter_instructions()[i],\n+                                        operation_info_iter->second));\n   }\n   return RunOnComputation(computation);\n }\n \n-absl::Status HloWeightPropagation::Run(const HloComputation& computation) {\n+absl::Status HloDimensionInfoPropagation::Run(\n+    const HloComputation& computation) {\n   TF_RETURN_IF_ERROR(computation.root_instruction()->Accept(this));\n   for (HloInstruction* instruction : computation.instructions()) {\n     if (instruction->user_count() == 0) {\n@@ -153,79 +152,84 @@ absl::Status HloWeightPropagation::Run(const HloComputation& computation) {\n   return absl::OkStatus();\n }\n \n-absl::Status HloWeightPropagation::DefaultAction(HloInstruction* instruction) {\n+absl::Status HloDimensionInfoPropagation::DefaultAction(\n+    HloInstruction* instruction) {\n   return absl::OkStatus();\n }\n \n #define RETURN_IF_ALREADY_PROPAGATED(instruction) \\\n-  if (analysis_->HasWeightInfo(instruction)) {    \\\n+  if (analysis_->HasDimensionInfo(instruction)) { \\\n     return absl::OkStatus();                      \\\n   }\n \n-absl::Status HloWeightPropagation::HandleTuple(HloInstruction* tuple) {\n+absl::Status HloDimensionInfoPropagation::HandleTuple(HloInstruction* tuple) {\n   RETURN_IF_ALREADY_PROPAGATED(tuple);\n-  bool has_weight_info = false;\n-  ShapeTree<WeightInfo> weight_tree(tuple->shape(), WeightInfo::kUnknown);\n+  bool has_operation_info = false;\n+  ShapeTree<DimensionInfo> dim_info_tree(tuple->shape(),\n+                                         DimensionInfo::kUnknown);\n   for (int64_t idx = 0; idx < tuple->operand_count(); ++idx) {\n     const HloInstruction* operand = tuple->operand(idx);\n     if (analysis_->IsInstructionWeight(operand)) {\n-      weight_tree.CopySubtreeFrom(*analysis_->GetWeightInfo(operand), {},\n-                                  {idx});\n-      has_weight_info = true;\n+      dim_info_tree.CopySubtreeFrom(*analysis_->GetDimensionInfo(operand), {},\n+                                    {idx});\n+      has_operation_info = true;\n     }\n   }\n \n-  if (has_weight_info) {\n-    TF_RETURN_IF_ERROR(analysis_->SetWeightInfo(tuple, std::move(weight_tree)));\n+  if (has_operation_info) {\n+    TF_RETURN_IF_ERROR(\n+        analysis_->SetDimensionInfo(tuple, std::move(dim_info_tree)));\n   }\n \n   return absl::OkStatus();\n }\n \n-absl::Status HloWeightPropagation::HandleGetTupleElement(\n+absl::Status HloDimensionInfoPropagation::HandleGetTupleElement(\n     HloInstruction* get_tuple_element) {\n   RETURN_IF_ALREADY_PROPAGATED(get_tuple_element);\n   const HloInstruction* operand = get_tuple_element->operand(0);\n   if (analysis_->IsInstructionWeight(operand)) {\n-    ShapeTree<WeightInfo> weight_tree(get_tuple_element->shape(),\n-                                      WeightInfo::kUnknown);\n-    weight_tree.CopySubtreeFrom(*analysis_->GetWeightInfo(operand),\n-                                {get_tuple_element->tuple_index()}, {});\n-    TF_RETURN_IF_ERROR(\n-        analysis_->SetWeightInfo(get_tuple_element, std::move(weight_tree)));\n+    ShapeTree<DimensionInfo> dim_info_tree(get_tuple_element->shape(),\n+                                           DimensionInfo::kUnknown);\n+    dim_info_tree.CopySubtreeFrom(*analysis_->GetDimensionInfo(operand),\n+                                  {get_tuple_element->tuple_index()}, {});\n+    TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(get_tuple_element,\n+                                                   std::move(dim_info_tree)));\n   }\n   return absl::OkStatus();\n }\n \n-absl::Status HloWeightPropagation::HandleCall(HloInstruction* call) {\n+absl::Status HloDimensionInfoPropagation::HandleCall(HloInstruction* call) {\n   RETURN_IF_ALREADY_PROPAGATED(call);\n   HloComputation* computation = call->called_computations()[0];\n   TF_RETURN_IF_ERROR(\n       analysis_->RunOnComputation(*computation, call->operands()));\n   if (analysis_->IsInstructionWeight(computation->root_instruction())) {\n-    TF_RETURN_IF_ERROR(analysis_->SetWeightInfo(\n-        call, *analysis_->GetWeightInfo(computation->root_instruction())));\n+    TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(\n+        call, *analysis_->GetDimensionInfo(computation->root_instruction())));\n   }\n   return absl::OkStatus();\n }\n \n-absl::Status HloWeightPropagation::HandleWhile(HloInstruction* xla_while) {\n+absl::Status HloDimensionInfoPropagation::HandleWhile(\n+    HloInstruction* xla_while) {\n   RETURN_IF_ALREADY_PROPAGATED(xla_while);\n   TF_RETURN_IF_ERROR(analysis_->RunOnComputation(*xla_while->while_condition(),\n                                                  xla_while->operands()));\n   HloComputation* computation = xla_while->while_body();\n   TF_RETURN_IF_ERROR(\n       analysis_->RunOnComputation(*computation, xla_while->operands()));\n   if (analysis_->IsInstructionWeight(computation->root_instruction())) {\n-    TF_RETURN_IF_ERROR(analysis_->SetWeightInfo(\n-        xla_while, *analysis_->GetWeightInfo(computation->root_instruction())));\n+    TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(\n+        xla_while,\n+        *analysis_->GetDimensionInfo(computation->root_instruction())));\n   }\n   return absl::OkStatus();\n }\n \n // Called for operations that operate on a single operand and do not change\n // the weight \"nature\" of their operand.\n-absl::Status HloWeightPropagation::HandleSimpleOp(HloInstruction* op) {\n+absl::Status HloDimensionInfoPropagation::HandleSimpleOp(HloInstruction* op) {\n   RETURN_IF_ALREADY_PROPAGATED(op);\n   const HloInstruction* operand = op->operand(0);\n   if (analysis_->IsInstructionWeight(operand)) {\n@@ -234,12 +238,12 @@ absl::Status HloWeightPropagation::HandleSimpleOp(HloInstruction* op) {\n   return absl::OkStatus();\n }\n \n-absl::Status HloWeightPropagation::HandleDynamicSlice(\n+absl::Status HloDimensionInfoPropagation::HandleDynamicSlice(\n     HloInstruction* dynamic_slice) {\n   return HandleSimpleOp(dynamic_slice);\n }\n \n-absl::Status HloWeightPropagation::HandleDynamicUpdateSlice(\n+absl::Status HloDimensionInfoPropagation::HandleDynamicUpdateSlice(\n     HloInstruction* dynamic_update_slice) {\n   RETURN_IF_ALREADY_PROPAGATED(dynamic_update_slice);\n   // If either the operand or the update is a weight, we consider the output to\n@@ -253,51 +257,56 @@ absl::Status HloWeightPropagation::HandleDynamicUpdateSlice(\n   return absl::OkStatus();\n }\n \n-absl::Status HloWeightPropagation::HandleSlice(HloInstruction* slice) {\n+absl::Status HloDimensionInfoPropagation::HandleSlice(HloInstruction* slice) {\n   return HandleSimpleOp(slice);\n }\n \n-absl::Status HloWeightPropagation::HandleConvert(HloInstruction* convert) {\n+absl::Status HloDimensionInfoPropagation::HandleConvert(\n+    HloInstruction* convert) {\n   return HandleSimpleOp(convert);\n }\n \n-absl::Status HloWeightPropagation::HandleReshape(HloInstruction* reshape) {\n+absl::Status HloDimensionInfoPropagation::HandleReshape(\n+    HloInstruction* reshape) {\n   return HandleSimpleOp(reshape);\n }\n \n-absl::Status HloWeightPropagation::HandleBitcast(HloInstruction* bitcast) {\n+absl::Status HloDimensionInfoPropagation::HandleBitcast(\n+    HloInstruction* bitcast) {\n   return HandleSimpleOp(bitcast);\n }\n \n-absl::Status HloWeightPropagation::HandleTranspose(HloInstruction* transpose) {\n+absl::Status HloDimensionInfoPropagation::HandleTranspose(\n+    HloInstruction* transpose) {\n   return HandleSimpleOp(transpose);\n }\n \n-absl::Status HloWeightPropagation::HandleCopy(HloInstruction* copy) {\n+absl::Status HloDimensionInfoPropagation::HandleCopy(HloInstruction* copy) {\n   return HandleSimpleOp(copy);\n }\n \n-absl::Status HloWeightPropagation::HandleBitcastConvert(\n+absl::Status HloDimensionInfoPropagation::HandleBitcastConvert(\n     HloInstruction* bitcast_convert) {\n   return HandleSimpleOp(bitcast_convert);\n }\n \n-absl::Status HloWeightPropagation::HandleOptimizationBarrier(\n+absl::Status HloDimensionInfoPropagation::HandleOptimizationBarrier(\n     HloInstruction* optimization_barrier) {\n   RETURN_IF_ALREADY_PROPAGATED(optimization_barrier);\n   CHECK_EQ(optimization_barrier->operand_count(), 1)\n       << \"Optimization barrier must have exactly one operand.\";\n   const HloInstruction* optimization_barrier_operand =\n       optimization_barrier->operand(0);\n   if (analysis_->IsInstructionWeight(optimization_barrier_operand)) {\n-    TF_RETURN_IF_ERROR(analysis_->SetWeightInfo(\n+    TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(\n         optimization_barrier,\n-        *analysis_->GetWeightInfo(optimization_barrier_operand)));\n+        *analysis_->GetDimensionInfo(optimization_barrier_operand)));\n   }\n   return absl::OkStatus();\n }\n \n-absl::Status HloWeightPropagation::HandleAllGather(HloInstruction* all_gather) {\n+absl::Status HloDimensionInfoPropagation::HandleAllGather(\n+    HloInstruction* all_gather) {\n   return HandleSimpleOp(all_gather);\n }\n "
        },
        {
            "sha": "9f409ad276b1a12d8f7fcab83b22341eb8ea6cdd",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_dimension_analysis.h",
            "status": "modified",
            "additions": 43,
            "deletions": 38,
            "changes": 81,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9720752fe90d5dd68001899948c71a4ca13f58bf/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9720752fe90d5dd68001899948c71a4ca13f58bf/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.h?ref=9720752fe90d5dd68001899948c71a4ca13f58bf",
            "patch": "@@ -40,52 +40,52 @@ limitations under the License.\n \n namespace xla {\n \n-enum WeightInfo : uint8_t {\n+enum DimensionInfo : uint8_t {\n   kWeight,\n   kTuple,\n   kUnknown,\n };\n \n-inline std::string WeightInfoToString(WeightInfo weight_info) {\n-  switch (weight_info) {\n-    case WeightInfo::kWeight:\n+inline std::string DimensionInfoToString(DimensionInfo dim_info) {\n+  switch (dim_info) {\n+    case DimensionInfo::kWeight:\n       return \"weight\";\n-    case WeightInfo::kTuple:\n+    case DimensionInfo::kTuple:\n       return \"tuple\";\n-    case WeightInfo::kUnknown:\n+    case DimensionInfo::kUnknown:\n       return \"unknown\";\n   }\n }\n \n-using WeightInfoMap =\n-    absl::node_hash_map<const HloInstruction*, ShapeTree<WeightInfo>>;\n+using DimensionInfoMap =\n+    absl::node_hash_map<const HloInstruction*, ShapeTree<DimensionInfo>>;\n \n // This analysis pass determines which HLO instructions produce/are weights.\n // Parameters to the entry computation are considered weights, and this property\n // is propagated through instructions that preserve it (slice, convert,\n // etc).\n class HloDimensionAnalysis {\n  public:\n-  friend class HloWeightPropagation;\n+  friend class HloDimensionInfoPropagation;\n   static absl::StatusOr<std::unique_ptr<HloDimensionAnalysis>> Run(\n       const HloModule& module,\n       const absl::flat_hash_set<absl::string_view>& execution_threads = {});\n \n-  // Whether the instruction has been annotated with weight info.\n-  bool HasWeightInfo(const HloInstruction* instruction) const {\n+  // Whether the instruction has been annotated with dimension info.\n+  bool HasDimensionInfo(const HloInstruction* instruction) const {\n     return info_map_.contains(instruction);\n   }\n \n   // Whether any leaf in the instruction shape is a weight.\n   bool IsInstructionWeight(const HloInstruction* instruction) const;\n \n-  // Returns map of HLO instructions to their weight info.\n+  // Returns map of HLO instructions to their dimension info.\n   // If an instruction is not found in the map, it means that we have not\n-  // determined it is a weight.\n-  const WeightInfoMap& GetWeightInfoMap() const { return info_map_; }\n+  // determined its dimension info.\n+  const DimensionInfoMap& GetDimensionInfoMap() const { return info_map_; }\n \n-  // Returns the weight info for the given instruction.\n-  std::optional<ShapeTree<WeightInfo>> GetWeightInfo(\n+  // Returns the dimension info for the given instruction.\n+  std::optional<ShapeTree<DimensionInfo>> GetDimensionInfo(\n       const HloInstruction* instruction) const;\n \n  protected:\n@@ -99,53 +99,58 @@ class HloDimensionAnalysis {\n   // weights.\n   absl::Status SetInstructionAsWeight(HloInstruction* instruction);\n \n-  // Sets the weight info for the given target instruction.\n-  absl::Status SetWeightInfo(const HloInstruction* target,\n-                             ShapeTree<WeightInfo> weight_annotation);\n+  // Sets the dimension info for the given target instruction.\n+  absl::Status SetDimensionInfo(const HloInstruction* target,\n+                                ShapeTree<DimensionInfo> annotation);\n \n   // Annotates the entry computation parameters as weights.\n   absl::Status AnnotateEntryComputationParameters(const HloModule& module);\n \n-  // Runs the weight analysis on the given computation.\n+  // Runs the analysis on the given computation to determine the DimensionInfo\n+  // for each instruction.\n   absl::Status RunOnComputation(const HloComputation& computation);\n \n-  // Runs the weight analysis on the given computation, with the given operands\n-  // as the computation parameters. Propagates the weight info from the\n+  // Runs the analysis on the given computation, with the given operands as the\n+  // computation parameters. Propagates the dimension info from the callsite\n   // operands to the computation parameters.\n   absl::Status RunOnComputation(\n       const HloComputation& computation,\n       absl::Span<const HloInstruction* const> operands);\n \n-  WeightInfoMap info_map_;\n+  DimensionInfoMap info_map_;\n   const HloModule& module_;\n   const absl::flat_hash_set<absl::string_view>& execution_threads_;\n };\n \n-class HloWeightPropagation : public DfsHloVisitorWithDefault {\n+class HloDimensionInfoPropagation : public DfsHloVisitorWithDefault {\n  public:\n-  explicit HloWeightPropagation(HloDimensionAnalysis* dimension_analysis)\n+  explicit HloDimensionInfoPropagation(HloDimensionAnalysis* dimension_analysis)\n       : analysis_(dimension_analysis) {}\n   absl::Status Run(const HloComputation& computation);\n   absl::Status DefaultAction(HloInstruction* instruction) override;\n-  absl::Status HandleTuple(HloInstruction* tuple) override;\n-  absl::Status HandleGetTupleElement(\n-      HloInstruction* get_tuple_element) override;\n+  // go/keep-sorted start\n+  absl::Status HandleAllGather(HloInstruction* all_gather) override;\n+  absl::Status HandleBitcast(HloInstruction* bitcast) override;\n+  absl::Status HandleBitcastConvert(HloInstruction* bitcast_convert) override;\n   absl::Status HandleCall(HloInstruction* call) override;\n-  absl::Status HandleWhile(HloInstruction* xla_while) override;\n-  absl::Status HandleSimpleOp(HloInstruction* op);\n+  absl::Status HandleConvert(HloInstruction* convert) override;\n+  absl::Status HandleCopy(HloInstruction* copy) override;\n   absl::Status HandleDynamicSlice(HloInstruction* dynamic_slice) override;\n   absl::Status HandleDynamicUpdateSlice(\n       HloInstruction* dynamic_update_slice) override;\n-  absl::Status HandleSlice(HloInstruction* slice) override;\n-  absl::Status HandleConvert(HloInstruction* convert) override;\n-  absl::Status HandleReshape(HloInstruction* reshape) override;\n-  absl::Status HandleBitcast(HloInstruction* bitcast) override;\n-  absl::Status HandleTranspose(HloInstruction* transpose) override;\n-  absl::Status HandleCopy(HloInstruction* copy) override;\n-  absl::Status HandleBitcastConvert(HloInstruction* bitcast_convert) override;\n+  absl::Status HandleGetTupleElement(\n+      HloInstruction* get_tuple_element) override;\n   absl::Status HandleOptimizationBarrier(\n       HloInstruction* optimization_barrier) override;\n-  absl::Status HandleAllGather(HloInstruction* all_gather) override;\n+  absl::Status HandleReshape(HloInstruction* reshape) override;\n+  absl::Status HandleSlice(HloInstruction* slice) override;\n+  absl::Status HandleTranspose(HloInstruction* transpose) override;\n+  absl::Status HandleTuple(HloInstruction* tuple) override;\n+  absl::Status HandleWhile(HloInstruction* xla_while) override;\n+  // go/keep-sorted end\n+\n+ private:\n+  absl::Status HandleSimpleOp(HloInstruction* op);\n \n  protected:\n   HloDimensionAnalysis* analysis_;"
        },
        {
            "sha": "0efffae5bb530b59f945070c4ed66d6234e38aaf",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_dimension_analysis_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9720752fe90d5dd68001899948c71a4ca13f58bf/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9720752fe90d5dd68001899948c71a4ca13f58bf/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis_test.cc?ref=9720752fe90d5dd68001899948c71a4ca13f58bf",
            "patch": "@@ -35,10 +35,10 @@ class HloDimensionAnalysisTest : public HloHardwareIndependentTestBase {\n   bool IsWeight(const HloDimensionAnalysis& hlo_dimension_analysis,\n                 HloModule* module, absl::string_view instruction_name) {\n     HloInstruction* instruction = FindInstruction(module, instruction_name);\n-    std::optional<ShapeTree<WeightInfo>> weight_info =\n-        hlo_dimension_analysis.GetWeightInfo(instruction);\n-    return weight_info.has_value() &&\n-           (*weight_info).element({}) == WeightInfo::kWeight;\n+    std::optional<ShapeTree<DimensionInfo>> dim_info =\n+        hlo_dimension_analysis.GetDimensionInfo(instruction);\n+    return dim_info.has_value() &&\n+           (*dim_info).element({}) == DimensionInfo::kWeight;\n   }\n };\n "
        }
    ],
    "stats": {
        "total": 224,
        "additions": 119,
        "deletions": 105
    }
}