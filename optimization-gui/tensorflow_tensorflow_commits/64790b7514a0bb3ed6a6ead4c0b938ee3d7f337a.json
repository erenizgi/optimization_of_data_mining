{
    "author": "shawnwang18",
    "message": "PR #30472: [XLA:GPU] Move command buffer LHS scheduling to execution graph\n\nImported from GitHub PR https://github.com/openxla/xla/pull/30472\n\nCopybara import of the project:\n\n--\n1cbcf4ad800078bd35de6b4e76c5e91cd7e1c856 by Shawn Wang <shawnw@nvidia.com>:\n\nMove command buffer LHS scheduling to execution graph\n\n--\nb66b9b73cec74385175aa369ed12fa0ec998b88c by Shawn Wang <shawnw@nvidia.com>:\n\nfix format\n\n--\n2b1cb83159aa65918efddc2d8d018bdd115b0e89 by Shawn Wang <shawnw@nvidia.com>:\n\nfix\n\nMerging this change closes #30472\n\nPiperOrigin-RevId: 799577176",
    "sha": "64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a",
    "files": [
        {
            "sha": "74a593b58d58f8d5aae7d7af0ce5e6a27e5603fb",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 149,
            "deletions": 72,
            "changes": 221,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a",
            "patch": "@@ -237,32 +237,155 @@ namespace {\n // execution graph from a command sequence.\n class CommandOperation : public ExecutionGraph::Operation {\n  public:\n-  explicit CommandOperation(const CommandBufferCmd* cmd)\n+  explicit CommandOperation(CommandBufferCmd::BufferUseVector buffers,\n+                            ResourceUseVector resources,\n+                            const CommandBufferCmd* cmd)\n       : name_(absl::StrFormat(\"cmd %s: %s\", cmd->ToString(),\n                               cmd->profile_annotation())),\n-        buffers_(cmd->buffers()),\n-        resources_(cmd->resources()) {}\n+        buffers_(std::move(buffers)),\n+        resources_(std::move(resources)),\n+        cmd_(cmd),\n+        token_(Resource::Create(Resource::Kind::kToken)) {\n+    resources_.push_back(ResourceUse::Write(token_));\n+  }\n \n   absl::string_view name() const final { return name_; }\n   absl::Span<const BufferUse> BufferUses() const final { return buffers_; }\n   absl::Span<const ResourceUse> ResourceUses() const final {\n     return resources_;\n   }\n+  void add_resouce_use(ResourceUse resource_use) {\n+    resources_.push_back(resource_use);\n+  }\n+\n+  std::shared_ptr<Resource> token() const { return token_; }\n+  const CommandBufferCmd* cmd() const { return cmd_; }\n+\n+  std::string ToString() const final {\n+    std::vector<std::string> resource_reprs;\n+    resource_reprs.reserve(resources_.size());\n+    for (const ResourceUse& use : resources_) {\n+      absl::string_view access =\n+          use.access() == ResourceUse::kRead ? \"read\" : \"write\";\n+      absl::string_view kind = Resource::ToString(use.resource()->kind());\n+      resource_reprs.push_back(\n+          absl::StrFormat(\"%s@%p(%s)\", kind, use.resource().get(), access));\n+    }\n+\n+    return absl::StrFormat(\"%s resources=[%s]\", cmd_->ToString(),\n+                           absl::StrJoin(resource_reprs, \", \"));\n+  }\n \n  private:\n   std::string name_;\n   CommandBufferCmd::BufferUseVector buffers_;\n   ResourceUseVector resources_;\n+  const CommandBufferCmd* cmd_;\n+\n+  // The token resource is used to specify dependency other than buffer data\n+  // flow, e.g, LHS topology will use token resouce to specify dependency across\n+  // commands.\n+  std::shared_ptr<Resource> token_;\n };\n }  // namespace\n \n static std::vector<CommandOperation> CreateCommandOperations(\n-    const CommandBufferCmdSequence& commands) {\n+    const CommandBufferCmdSequence& commands,\n+    CommandBufferCmdExecutor::SynchronizationMode synchronization_mode) {\n   std::vector<CommandOperation> operations;\n   operations.reserve(commands.size());\n-  for (const std::unique_ptr<CommandBufferCmd>& cmd : commands) {\n-    operations.emplace_back(cmd.get());\n+  VLOG(3) << \"CreateCommandOperations with synchronization mode: \"\n+          << (synchronization_mode ==\n+                      CommandBufferCmdExecutor::SynchronizationMode::kConcurrent\n+                  ? \"Concurrent\"\n+                  : \"LHS\");\n+  if (synchronization_mode ==\n+      CommandBufferCmdExecutor::SynchronizationMode::kConcurrent) {\n+    // For concurrent synchronization mode, pass in buffer and resouces for\n+    // dependency inference.\n+    for (const std::unique_ptr<CommandBufferCmd>& cmd : commands) {\n+      operations.emplace_back(cmd->buffers(), cmd->resources(), cmd.get());\n+    }\n   }\n+\n+  if (synchronization_mode ==\n+      CommandBufferCmdExecutor::SynchronizationMode::kLHS) {\n+    // For LHS mode, don't pass in buffers.\n+    // Will use token resource to specify dependency across commands.\n+    for (const std::unique_ptr<CommandBufferCmd>& cmd : commands) {\n+      operations.emplace_back(CommandBufferCmd::BufferUseVector{},\n+                              cmd->resources(), cmd.get());\n+    }\n+\n+    auto is_async_start = [](const CommandOperation& op) -> bool {\n+      auto* collective_cmd = dynamic_cast<const CollectiveCmd*>(op.cmd());\n+      return (collective_cmd && collective_cmd->IsAsync());\n+    };\n+\n+    auto is_async_done = [](const CommandOperation& op) -> bool {\n+      auto* async_done_cmd = dynamic_cast<const AsyncDoneCmd*>(op.cmd());\n+      return (async_done_cmd && async_done_cmd->IsAsync());\n+    };\n+\n+    auto find_async_start_cmd_id = [&](int64_t async_done_cmd_id) -> int64_t {\n+      auto* async_done_cmd = dynamic_cast<const AsyncDoneCmd*>(\n+          operations[async_done_cmd_id].cmd());\n+      CHECK(async_done_cmd);\n+      for (int64_t j = async_done_cmd_id - 1; j >= 0; --j) {\n+        if (is_async_start(operations[j])) {\n+          auto* async_start_cmd =\n+              dynamic_cast<const CollectiveCmd*>(operations[j].cmd());\n+          if (async_start_cmd->IsAsync() &&\n+              async_start_cmd->async_events() ==\n+                  async_done_cmd->async_events()) {\n+            return j;\n+          }\n+        }\n+      }\n+      return -1;\n+    };\n+\n+    for (int64_t i = 0; i < operations.size(); ++i) {\n+      if (is_async_start(operations[i])) {\n+        for (int64_t j = i - 1; j >= 0; --j) {\n+          if (is_async_start(operations[j])) {\n+            continue;\n+          }\n+          operations[i].add_resouce_use(\n+              ResourceUse::Read(operations[j].token()));\n+          break;\n+        }\n+      } else if (is_async_done(operations[i])) {\n+        int64_t async_start_cmd_id = find_async_start_cmd_id(i);\n+        CHECK_NE(async_start_cmd_id, -1);\n+        operations[i].add_resouce_use(\n+            ResourceUse::Read(operations[async_start_cmd_id].token()));\n+        CHECK_GT(i, 0);\n+        if ((i - 1) != async_start_cmd_id) {\n+          operations[i].add_resouce_use(\n+              ResourceUse::Read(operations[i - 1].token()));\n+        }\n+      } else {\n+        for (int64_t j = i - 1; j >= 0; --j) {\n+          if (is_async_start(operations[j])) {\n+            // The first command in the async group does not depend on the async\n+            // command\n+            continue;\n+          }\n+          operations[i].add_resouce_use(\n+              ResourceUse::Read(operations[j].token()));\n+          break;\n+        }\n+      }\n+    }\n+  }\n+\n+  if (VLOG_IS_ON(2)) {\n+    for (const CommandOperation& op : operations) {\n+      VLOG(2) << op.ToString();\n+    }\n+  }\n+\n   return operations;\n }\n \n@@ -274,10 +397,11 @@ absl::StatusOr<CommandBufferCmdExecutor> CommandBufferCmdExecutor::Create(\n   // In automatic synchronization mode construct an execution graph for the\n   // sequence of commands and derive the structure of command dependencies\n   // from the buffer use conflicts.\n-  if (synchronization_mode == SynchronizationMode::kConcurrent) {\n-    auto operations = CreateCommandOperations(commands);\n+  if (synchronization_mode != SynchronizationMode::kSerialize) {\n+    auto operations = CreateCommandOperations(commands, synchronization_mode);\n     TF_ASSIGN_OR_RETURN(execution_graph,\n                         ExecutionGraph::Create<CommandOperation>(operations));\n+    VLOG(3) << \"Execution graph: \" << execution_graph->ToString();\n   }\n \n   return CommandBufferCmdExecutor(synchronization_mode, std::move(commands),\n@@ -369,7 +493,8 @@ CommandBufferCmdExecutor::RecordCreate(\n     return std::vector<const se::CommandBuffer::Command*>{};\n   }\n \n-  // Keep a state associated with commands in the sequence in the state manager.\n+  // Keep a state associated with commands in the sequence in the state\n+  // manager.\n   CommandBufferCmd::StateManager& state = record_params.state;\n \n   // Collect sink commands while recording the command sequence.\n@@ -396,9 +521,9 @@ CommandBufferCmdExecutor::RecordCreate(\n     std::vector<const se::CommandBuffer::Command*> command_dependencies =\n         Dependencies(record_params, command_buffer, id);\n \n-    // Source command must depend on external dependencies passed by the caller,\n-    // internal commands dependencies are defined by the command sequence\n-    // structure (buffer and resource dependencies).\n+    // Source command must depend on external dependencies passed by the\n+    // caller, internal commands dependencies are defined by the command\n+    // sequence structure (buffer and resource dependencies).\n     auto record_action =\n         IsSource(id) ? CommandBufferCmd::RecordCreate{dependencies}\n                      : CommandBufferCmd::RecordCreate{command_dependencies};\n@@ -439,7 +564,8 @@ absl::Status CommandBufferCmdExecutor::RecordUpdate(\n     return absl::OkStatus();\n   }\n \n-  // Keep a state associated with commands in the sequence in the state manager.\n+  // Keep a state associated with commands in the sequence in the state\n+  // manager.\n   CommandBufferCmd::StateManager& state = record_params.state;\n \n   // Check if command `id` has to be updated based on the buffer allocations\n@@ -544,7 +670,6 @@ CommandBufferCmdExecutor::Dependencies(const RecordParams& record_params,\n                                        se::CommandBuffer* command_buffer,\n                                        CommandId id) const {\n   // Source commands have no dependencies.\n-  VLOG(2) << \"CommandSequence is :\\n\" << commands_.ToString();\n   if (IsSource(id)) {\n     VLOG(2) << \"Command ID \" << id\n             << \" is a source command, empty dependencies\";\n@@ -558,54 +683,6 @@ CommandBufferCmdExecutor::Dependencies(const RecordParams& record_params,\n          execution_graph_->in_edges(id)) {\n       dependencies_ids.push_back(in_edge.id);\n     }\n-  } else if (synchronization_mode_ == SynchronizationMode::kLHS) {\n-    CHECK(id < commands_.size());\n-    auto is_async_start = [](const CommandBufferCmd* cmd) -> bool {\n-      return cmd->command_type() == CommandBufferCmdType::kAllGatherCmd ||\n-             cmd->command_type() == CommandBufferCmdType::kAllReduceCmd ||\n-             cmd->command_type() == CommandBufferCmdType::kReduceScatterCmd ||\n-             cmd->command_type() == CommandBufferCmdType::kAllToAllCmd;\n-    };\n-\n-    auto find_async_start_cmd_id =\n-        [&](const AsyncDoneCmd* async_done_cmd) -> CommandId {\n-      CHECK(async_done_cmd->async_events() != nullptr);\n-      for (CommandId i = id - 1; i >= 0; --i) {\n-        if (is_async_start(commands_[i].get()) &&\n-            static_cast<const CollectiveCmd*>(commands_[i].get())\n-                    ->async_events() == async_done_cmd->async_events()) {\n-          return i;\n-        }\n-      }\n-      return -1;\n-    };\n-\n-    if (commands_[id]->command_type() == CommandBufferCmdType::kAsyncDone) {\n-      // Add dependency on the async start command.\n-      auto async_start_cmd_id = find_async_start_cmd_id(\n-          static_cast<const AsyncDoneCmd*>(commands_[id].get()));\n-      CHECK_NE(async_start_cmd_id, -1);\n-      dependencies_ids.push_back(async_start_cmd_id);\n-\n-      // Add dependency on the last command in async region.\n-      for (CommandId i = id - 1; i > async_start_cmd_id; --i) {\n-        if (is_async_start(commands_[i].get()) &&\n-            static_cast<const CollectiveCmd*>(commands_[i].get())->IsAsync()) {\n-          continue;\n-        }\n-        dependencies_ids.push_back(i);\n-        break;\n-      }\n-    } else {\n-      for (CommandId i = id - 1; i >= 0; --i) {\n-        if (is_async_start(commands_[i].get()) &&\n-            static_cast<const CollectiveCmd*>(commands_[i].get())->IsAsync()) {\n-          continue;\n-        }\n-        dependencies_ids.push_back(i);\n-        break;\n-      }\n-    }\n   } else {\n     dependencies_ids.push_back(id - 1);\n   }\n@@ -620,10 +697,10 @@ CommandBufferCmdExecutor::Dependencies(const RecordParams& record_params,\n \n     if (record_state->command == nullptr) {\n       // Some commands might end up not recording anything into the command\n-      // buffer, e.g. memcpy commands where source and destination are the same.\n-      // We have to follow dependencies of such commands to find the real\n-      // dependencies, so we don't record a command that is immediately ready to\n-      // execute, as it will create data races.\n+      // buffer, e.g. memcpy commands where source and destination are the\n+      // same. We have to follow dependencies of such commands to find the\n+      // real dependencies, so we don't record a command that is immediately\n+      // ready to execute, as it will create data races.\n       auto deps = Dependencies(record_params, command_buffer, dependency_id);\n       dependencies.insert(dependencies.end(), deps.begin(), deps.end());\n     } else {\n@@ -650,13 +727,13 @@ absl::StatusOr<std::string> CommandBufferCmdExecutor::RenderExecutionGraph() {\n     return Unimplemented(\"No execution graph renderer registered\");\n   }\n \n-  if (synchronization_mode_ != SynchronizationMode::kConcurrent) {\n+  if (synchronization_mode_ == SynchronizationMode::kSerialize) {\n     return Unimplemented(\n         \"Execution graph rendering is only supported for \"\n-        \"concurrent synchronization mode\");\n+        \"concurrent/LHS synchronization mode\");\n   }\n \n-  auto operations = CreateCommandOperations(commands_);\n+  auto operations = CreateCommandOperations(commands_, synchronization_mode_);\n   absl::InlinedVector<const ExecutionGraph::Operation*, 32> operations_ptrs;\n   operations_ptrs.reserve(operations.size());\n   for (const auto& operation : operations) {\n@@ -737,9 +814,9 @@ absl::StatusOr<se::CommandBuffer*> TracedCommandBuffer::GetOrTraceCommandBuffer(\n     }\n   }\n \n-  // Create a new entry by calling a user-provided tracing function, replace the\n-  // last entry with it, move it to front and return a pointer to cached command\n-  // buffer.\n+  // Create a new entry by calling a user-provided tracing function, replace\n+  // the last entry with it, move it to front and return a pointer to cached\n+  // command buffer.\n   TF_ASSIGN_OR_RETURN(\n       entries_[capacity_ - 1].command_buffer,\n       se::TraceCommandBufferFactory::Create(executor, stream, trace));"
        },
        {
            "sha": "4d22a006156654b4c1fd7e9203cccb90453b6b1e",
            "filename": "third_party/xla/xla/runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fruntime%2FBUILD?ref=64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a",
            "patch": "@@ -47,6 +47,7 @@ cc_library(\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/memory\",\n+        \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n     ],\n )"
        },
        {
            "sha": "ef526ee844f775c5bf42af5cae4318eda7999ae1",
            "filename": "third_party/xla/xla/runtime/execution_graph.cc",
            "status": "modified",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fruntime%2Fexecution_graph.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fruntime%2Fexecution_graph.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fruntime%2Fexecution_graph.cc?ref=64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a",
            "patch": "@@ -117,6 +117,7 @@ absl::StatusOr<ExecutionGraph> ExecutionGraph::Create(\n   // most recent updates that touch the whole buffer slice.\n \n   for (NodeId i = 0; i < operations.size(); ++i) {\n+    VLOG(2) << \"Processing operation \" << i << \" \" << operations[i]->ToString();\n     builders[i].id = i;\n \n     const Operation* op = operations[i];\n@@ -136,6 +137,7 @@ absl::StatusOr<ExecutionGraph> ExecutionGraph::Create(\n         auto kind = EdgeKind(resource_rwsets[j].Conflicts(resource_rwsets[i]));\n         builders[j].out_edges.push_back(NodeEdge{kind, i});\n         builders[i].in_edges.push_back(NodeEdge{kind, j});\n+        VLOG(2) << \"Added edge \" << j << \" -> \" << i << \" \" << kind;\n       }\n     }\n   }\n@@ -270,6 +272,32 @@ int64_t ExecutionGraph::EraseEdge(NodeDefBuilder& from, NodeDefBuilder& to,\n   return 1;\n }\n \n+std::string ExecutionGraph::ToString() const {\n+  auto edges_to_string = [](absl::Span<const NodeEdge> edges) {\n+    std::string s;\n+    bool first = true;\n+    for (const NodeEdge& e : edges) {\n+      if (!first) absl::StrAppend(&s, \", \");\n+      first = false;\n+      absl::StrAppendFormat(&s, \"%v\", e);\n+    }\n+    return s;\n+  };\n+\n+  std::string out;\n+  absl::StrAppendFormat(&out, \"ExecutionGraph: %d nodes, is_sequential=%v\\n\",\n+                        nodes_defs_.size(), is_sequential_);\n+\n+  for (NodeId i = 0; i < nodes_defs_.size(); ++i) {\n+    const NodeDef& def = nodes_defs_[i];\n+    absl::StrAppendFormat(&out, \"node %d (priority=%d): in=[%s] out=[%s]\\n\", i,\n+                          def.priority, edges_to_string(def.in_edges),\n+                          edges_to_string(def.out_edges));\n+  }\n+\n+  return out;\n+}\n+\n namespace {\n \n // A state of a DFS traversal for transitive reduction."
        },
        {
            "sha": "9175276a9433fb613f600f8a26d48716b54cb07a",
            "filename": "third_party/xla/xla/runtime/execution_graph.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fruntime%2Fexecution_graph.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fruntime%2Fexecution_graph.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fruntime%2Fexecution_graph.h?ref=64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a",
            "patch": "@@ -82,6 +82,9 @@ class ExecutionGraph {\n     virtual int64_t op_type_id() const { return 0; };\n     virtual absl::Span<const BufferUse> BufferUses() const = 0;\n     virtual absl::Span<const ResourceUse> ResourceUses() const = 0;\n+    virtual std::string ToString() const {\n+      return absl::StrFormat(\"Operation {name: %s}\", name());\n+    }\n \n     const std::vector<\n         std::pair<std::string, std::vector<std::unique_ptr<Operation>>>>&\n@@ -249,6 +252,9 @@ class ExecutionGraph {\n \n   bool is_sequential() const { return is_sequential_; }\n \n+  // Returns a string representation of the execution graph.\n+  std::string ToString() const;\n+\n  private:\n   // We store all `in_edges` and `out_edges` referenced by the `NodeDef` inside\n   // large vectors to optimize for data locality on a hot path."
        },
        {
            "sha": "2202f40c45dfc702737f025002cee094ffd86c57",
            "filename": "third_party/xla/xla/runtime/resource_use.h",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fruntime%2Fresource_use.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fruntime%2Fresource_use.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fruntime%2Fresource_use.h?ref=64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include <vector>\n \n #include \"absl/container/flat_hash_set.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n \n namespace xla {\n@@ -48,6 +49,16 @@ class Resource {\n \n   Kind kind() const { return kind_; }\n \n+  // Returns a short, stable string name for a resource kind.\n+  static absl::string_view ToString(Kind kind) {\n+    switch (kind) {\n+      case Kind::kToken:\n+        return \"token\";\n+      case Kind::kCollectiveCommunicator:\n+        return \"collective_communicator\";\n+    }\n+  }\n+\n  private:\n   explicit Resource(Kind kind);\n   Kind kind_;"
        },
        {
            "sha": "a9d372a150837d389734151793247da180fc6e45",
            "filename": "third_party/xla/xla/service/gpu/tests/command_buffer_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fcommand_buffer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fcommand_buffer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fcommand_buffer_test.cc?ref=64790b7514a0bb3ed6a6ead4c0b938ee3d7f337a",
            "patch": "@@ -28,11 +28,11 @@ namespace xla::gpu {\n namespace {\n \n class CommandBufferTest : public HloPjRtTestBase,\n-                          public ::testing::WithParamInterface<bool> {\n+                          public ::testing::WithParamInterface<\n+                              DebugOptions::CommandBufferSchedulingMode> {\n   DebugOptions GetDebugOptionsForTest() const override {\n     DebugOptions debug_options = HloPjRtTestBase::GetDebugOptionsForTest();\n-    debug_options.set_xla_gpu_command_buffer_scheduling_mode(\n-        DebugOptions::CONCURRENT);\n+    debug_options.set_xla_gpu_command_buffer_scheduling_mode(GetParam());\n     return debug_options;\n   }\n };\n@@ -275,7 +275,8 @@ TEST_P(CommandBufferTest, WhileLoop) {\n }\n \n INSTANTIATE_TEST_SUITE_P(CommandBufferTests, CommandBufferTest,\n-                         ::testing::Values(false, true));\n+                         ::testing::Values(DebugOptions::LHS,\n+                                           DebugOptions::CONCURRENT));\n \n }  // namespace\n }  // namespace xla::gpu"
        }
    ],
    "stats": {
        "total": 276,
        "additions": 200,
        "deletions": 76
    }
}