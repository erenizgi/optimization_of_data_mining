{
    "author": "unknown",
    "message": "[XLA:GPU] Fix incorrect namespace in buffer_debug_log.*\n\nIt was moved to stream_executor/gpu, but code remained in stream_executor::cuda namespace.\n\nPiperOrigin-RevId: 822584666",
    "sha": "94d00be0e6aaafa241337cdc9941eb54b2432460",
    "files": [
        {
            "sha": "c3b5ec08b078a4075c6743293d97b96fcbce7745",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_checksum_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc?ref=94d00be0e6aaafa241337cdc9941eb54b2432460",
            "patch": "@@ -80,8 +80,8 @@ absl::Status BuffersDebugChecksumThunk::ExecuteOnStream(\n \n   se::DeviceMemory<uint8_t> log_ptr(\n       params.buffer_allocations->GetDeviceAddress(log_slice_));\n-  se::cuda::BufferDebugLog buffer_debug_log =\n-      se::cuda::BufferDebugLog::FromDeviceMemoryUnchecked(log_ptr);\n+  se::gpu::BufferDebugLog buffer_debug_log =\n+      se::gpu::BufferDebugLog::FromDeviceMemoryUnchecked(log_ptr);\n \n   for (const auto& [entry_id, buffer] : buffers_) {\n     se::DeviceMemory<uint8_t> device_buffer("
        },
        {
            "sha": "fe0ead2a8c33422e7b928f302fc24880ff9a83a6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_checksum_thunk_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc?ref=94d00be0e6aaafa241337cdc9941eb54b2432460",
            "patch": "@@ -45,7 +45,7 @@ namespace {\n \n namespace se = stream_executor;\n \n-using ::stream_executor::cuda::BufferDebugLog;\n+using ::stream_executor::gpu::BufferDebugLog;\n using ::testing::UnorderedElementsAre;\n \n class BuffersDebugChecksumThunkTest : public ::testing::Test {"
        },
        {
            "sha": "b751a28b0bab5d79e42963018c9d9c2397ae1634",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_checksum_tracing_pass.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc?ref=94d00be0e6aaafa241337cdc9941eb54b2432460",
            "patch": "@@ -130,8 +130,8 @@ absl::StatusOr<std::unique_ptr<Thunk>> WrapThunk(\n XLA_FFI_DEFINE_HANDLER_SYMBOL(\n     kDebugLogInitHandler,\n     [](se::Stream* absl_nonnull stream, xla::ffi::Buffer<U8> log_buffer) {\n-      return se::cuda::BufferDebugLog::CreateOnDevice(\n-                 *stream, log_buffer.device_memory())\n+      return se::gpu::BufferDebugLog::CreateOnDevice(*stream,\n+                                                     log_buffer.device_memory())\n           .status();\n     },\n     xla::ffi::Ffi::Bind().Ctx<xla::ffi::Stream>().Arg<xla::ffi::Buffer<U8>>());\n@@ -147,8 +147,8 @@ XLA_FFI_DEFINE_HANDLER_SYMBOL(\n       CHECK(hlo_module != nullptr);\n       const DebugOptions& debug_options = hlo_module->config().debug_options();\n \n-      se::cuda::BufferDebugLog buffer_debug_log =\n-          se::cuda::BufferDebugLog::FromDeviceMemoryUnchecked(\n+      se::gpu::BufferDebugLog buffer_debug_log =\n+          se::gpu::BufferDebugLog::FromDeviceMemoryUnchecked(\n               log_buffer.device_memory());\n       TF_ASSIGN_OR_RETURN(xla::gpu::BufferDebugLogProto buffer_debug_log_proto,\n                           buffer_debug_log.ReadProto(*stream));"
        },
        {
            "sha": "1f81475c7c8c2639bae08fc022d164a922651089",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_xor_checksum_kernel_cuda_test.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 13,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc?ref=94d00be0e6aaafa241337cdc9941eb54b2432460",
            "patch": "@@ -86,7 +86,7 @@ class ChecksumKernelTest : public ::testing::Test {\n   template <typename T>\n   absl::Status AppendChecksumOnDevice(\n       ThunkBufferId entry_id, const T& input,\n-      se::cuda::BufferDebugLog& buffer_debug_log,\n+      se::gpu::BufferDebugLog& buffer_debug_log,\n       stream_executor::ThreadDim dim = stream_executor::ThreadDim(1, 1, 1)) {\n     // Load kernel\n     gpu::GpuKernelRegistry registry =\n@@ -135,8 +135,8 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumForMultipleOf32Bit) {\n   constexpr uint32_t kExpectedChecksum = 0x12345678;\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::cuda::BufferDebugLog device_log,\n-      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog device_log,\n+      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(ThunkBufferId(), input, device_log));\n \n@@ -150,8 +150,8 @@ TEST_F(ChecksumKernelTest,\n   se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(1024);\n   const std::vector<uint8_t> kInput = std::vector<uint8_t>(1023, 0x55);\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::cuda::BufferDebugLog device_log,\n-      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog device_log,\n+      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(ThunkBufferId(), kInput, device_log));\n \n@@ -169,8 +169,8 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallel) {\n   input[1000] ^= 0x12345678;\n   constexpr uint32_t kExpectedChecksum = 0x12345678;\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::cuda::BufferDebugLog device_log,\n-      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog device_log,\n+      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(ThunkBufferId(), input, device_log,\n                                       se::ThreadDim(2, 4, 8)));\n@@ -188,8 +188,8 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallelWithMaxThreads) {\n   input[1000] ^= 0x12345678;\n   constexpr uint32_t kExpectedChecksum = 0x12345678;\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::cuda::BufferDebugLog device_log,\n-      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog device_log,\n+      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(ThunkBufferId(), input, device_log,\n                                       se::ThreadDim(128, 4, 2)));\n@@ -208,8 +208,8 @@ TEST_F(ChecksumKernelTest, AppendsChecksumsToLog) {\n   constexpr std::array<uint32_t, 1> kInput456 = {0x04560456};\n   constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::cuda::BufferDebugLog device_log,\n-      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog device_log,\n+      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(kId123, kInput123, device_log));\n   TF_EXPECT_OK(AppendChecksumOnDevice(kId456, kInput456, device_log));\n@@ -235,8 +235,8 @@ TEST_F(ChecksumKernelTest, DiscardsOverflowingChecksums) {\n   constexpr std::array<uint32_t, 1> kInput456 = {0x04560456};\n   constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::cuda::BufferDebugLog device_log,\n-      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog device_log,\n+      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(kId123, kInput123, device_log));\n   TF_EXPECT_OK(AppendChecksumOnDevice(kId456, kInput456, device_log));"
        },
        {
            "sha": "ba2a54755e9cb3cbaedc78a2e4b82f7d2bd19354",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc?ref=94d00be0e6aaafa241337cdc9941eb54b2432460",
            "patch": "@@ -31,7 +31,7 @@ limitations under the License.\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n \n-namespace stream_executor::cuda {\n+namespace stream_executor::gpu {\n \n using ::xla::gpu::BufferDebugLogEntry;\n using ::xla::gpu::BufferDebugLogHeader;\n@@ -109,4 +109,4 @@ absl::StatusOr<xla::gpu::BufferDebugLogProto> BufferDebugLog::ReadProto(\n   return buffer_debug_log_proto;\n }\n \n-}  // namespace stream_executor::cuda\n+}  // namespace stream_executor::gpu"
        },
        {
            "sha": "38954f37466efc667e792f271e4fe423b8985894",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h?ref=94d00be0e6aaafa241337cdc9941eb54b2432460",
            "patch": "@@ -26,7 +26,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/stream.h\"\n \n-namespace stream_executor::cuda {\n+namespace stream_executor::gpu {\n \n // A wrapper over a device memory buffer used to store debug info about contents\n // of buffers (e.g. checksums).\n@@ -112,6 +112,6 @@ class BufferDebugLog {\n   DeviceMemory<uint8_t> memory_;\n };\n \n-}  // namespace stream_executor::cuda\n+}  // namespace stream_executor::gpu\n \n #endif  // XLA_STREAM_EXECUTOR_GPU_BUFFER_DEBUG_LOG_H_"
        },
        {
            "sha": "cf1e49563566f43e81f01b06e047109c4ea742a4",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94d00be0e6aaafa241337cdc9941eb54b2432460/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc?ref=94d00be0e6aaafa241337cdc9941eb54b2432460",
            "patch": "@@ -40,7 +40,7 @@ limitations under the License.\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/util/proto/proto_matchers.h\"\n \n-namespace stream_executor::cuda {\n+namespace stream_executor::gpu {\n namespace {\n \n using ::tsl::proto_testing::EqualsProto;\n@@ -150,4 +150,4 @@ TEST_F(BufferDebugLogTest, ReadAsProto) {\n }\n \n }  // namespace\n-}  // namespace stream_executor::cuda\n+}  // namespace stream_executor::gpu"
        }
    ],
    "stats": {
        "total": 52,
        "additions": 26,
        "deletions": 26
    }
}