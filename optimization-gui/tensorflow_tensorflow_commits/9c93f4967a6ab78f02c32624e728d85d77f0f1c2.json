{
    "author": "ermilovmaxim",
    "message": "[XLA] move runtime_intrinsics to xla/backends/gpu/runtime\n\nPiperOrigin-RevId: 810184072",
    "sha": "9c93f4967a6ab78f02c32624e728d85d77f0f1c2",
    "files": [
        {
            "sha": "7de0e9f1e7e3c74b49fc5b31de67d6f03dfed161",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 45,
            "deletions": 0,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=9c93f4967a6ab78f02c32624e728d85d77f0f1c2",
            "patch": "@@ -2564,3 +2564,48 @@ xla_test(\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )\n+\n+cc_library(\n+    name = \"runtime_intrinsics\",\n+    srcs = [\"runtime_intrinsics.cc\"],\n+    hdrs = [\"runtime_intrinsics.h\"],\n+    deps = [\n+        \"//xla:literal\",\n+        \"//xla:shape_util\",\n+        \"//xla:util\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla/ffi\",\n+        \"//xla/ffi:ffi_api\",\n+        \"//xla/service:collective_ops_utils\",\n+        \"//xla/service:custom_call_status\",\n+        \"//xla/service:custom_call_target_registry\",\n+        \"//xla/service:platform_util\",\n+        \"//xla/stream_executor:memory_allocation\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/strings\",\n+    ],\n+    alwayslink = 1,\n+)\n+\n+xla_test(\n+    name = \"runtime_intrinsics_test\",\n+    srcs = [\"runtime_intrinsics_test.cc\"],\n+    backends = [\"gpu\"],\n+    deps = [\n+        \":runtime_intrinsics\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/tests:hlo_test_base\",\n+        \"//xla/tests:xla_internal_test_main\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/platform:test\",\n+        \"@com_google_absl//absl/base:log_severity\",\n+        \"@com_google_absl//absl/log:scoped_mock_log\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_googletest//:gtest\",\n+    ],\n+)"
        },
        {
            "sha": "bd5c38cfc3ca3ffc42f4c5dc85927118da4a8a79",
            "filename": "third_party/xla/xla/backends/gpu/runtime/runtime_intrinsics.cc",
            "status": "added",
            "additions": 164,
            "deletions": 0,
            "changes": 164,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics.cc?ref=9c93f4967a6ab78f02c32624e728d85d77f0f1c2",
            "patch": "@@ -0,0 +1,164 @@\n+/* Copyright 2022 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/runtime_intrinsics.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <string>\n+#include <vector>\n+\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/strings/ascii.h\"\n+#include \"absl/strings/match.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_replace.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/strings/substitute.h\"\n+#include \"xla/ffi/ffi.h\"\n+#include \"xla/ffi/ffi_api.h\"\n+#include \"xla/layout_util.h\"\n+#include \"xla/literal.h\"\n+#include \"xla/service/collective_ops_utils.h\"\n+#include \"xla/service/custom_call_status.h\"\n+#include \"xla/service/custom_call_target_registry.h\"\n+#include \"xla/service/platform_util.h\"\n+#include \"xla/shape.h\"\n+#include \"xla/shape_util.h\"\n+#include \"xla/stream_executor/memory_allocation.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n+#include \"xla/xla_data.pb.h\"\n+\n+namespace xla {\n+\n+namespace {\n+\n+std::string GetGpuPlatformName() {\n+  return absl::AsciiStrToUpper(\n+      PlatformUtil::CanonicalPlatformName(\"gpu\").value());\n+}\n+\n+absl::Status AssertionCustomCall(\n+    se::Stream* stream, ffi::Buffer<PRED> buffer, absl::string_view error_msg,\n+    xla::ffi::Result<xla::ffi::Buffer<xla::TOKEN>> res) {\n+  if (!stream) {\n+    return Internal(\"Stream is nullptr.\");\n+  }\n+\n+  int8_t expected = false;\n+  int64_t byte_size = sizeof(int8_t);\n+  CHECK_EQ(byte_size, ShapeUtil::ByteSizeOfPrimitiveType(PrimitiveType::PRED));\n+  TF_RETURN_IF_ERROR(\n+      stream->Memcpy(&expected, buffer.device_memory(), byte_size));\n+  TF_RETURN_IF_ERROR(stream->BlockHostUntilDone());\n+  if (!static_cast<bool>(expected)) {\n+    return Internal(\"%s\", error_msg);\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n+void NopReturnTokenCustomCall(void* stream_handle, void** buffers,\n+                              const char* opaque, int opaque_len,\n+                              XlaCustomCallStatus* status) {\n+  VLOG(1) << \"NopReturnTokenCustomCall called.\";\n+}\n+\n+absl::Status DebugPrintCustomCall(se::Stream* stream, ffi::RemainingArgs args,\n+                                  absl::string_view format,\n+                                  ffi::Result<ffi::Buffer<xla::TOKEN>> res) {\n+  if (!stream) {\n+    return Internal(\"Stream is nullptr.\");\n+  }\n+\n+  std::vector<ffi::AnyBuffer> args_buffers;\n+  args_buffers.reserve(args.size());\n+  for (int i = 0; i < args.size(); ++i) {\n+    absl::StatusOr<ffi::AnyBuffer> arg = args.get<ffi::AnyBuffer>(i);\n+    if (!arg.ok()) {\n+      return arg.status();\n+    }\n+    args_buffers.push_back(*arg);\n+  }\n+\n+  std::string formatted(format);\n+\n+  // Iterate in reverse order to match the longest string to substitute first.\n+  for (int i = args_buffers.size() - 1; i >= 0; --i) {\n+    std::string to_substitute = absl::StrCat(\"$\", i);\n+    if (!absl::StrContains(formatted, to_substitute)) {\n+      return absl::FailedPreconditionError(absl::Substitute(\n+          \"Missing formatter for argument $0 in debug print custom call\", i));\n+    }\n+    const ffi::AnyBuffer& arg = args_buffers[i];\n+    int64_t size_bytes = arg.size_bytes();\n+    TF_ASSIGN_OR_RETURN(std::unique_ptr<se::MemoryAllocation> host_buffer,\n+                        stream->parent()->HostMemoryAllocate(size_bytes));\n+    TF_RETURN_IF_ERROR(\n+        stream->Memcpy(host_buffer->opaque(), arg.device_memory(), size_bytes));\n+    TF_RETURN_IF_ERROR(stream->BlockHostUntilDone());\n+\n+    Shape shape = ShapeUtil::MakeShape(arg.element_type(), arg.dimensions());\n+    LayoutUtil::SetToDefaultLayout(&shape);\n+    MutableBorrowingLiteral literal(static_cast<char*>(host_buffer->opaque()),\n+                                    shape);\n+    formatted =\n+        absl::StrReplaceAll(formatted, {{to_substitute, literal.ToString()}});\n+  }\n+\n+  LOG(INFO) << formatted;\n+\n+  return absl::OkStatus();\n+}\n+\n+}  // namespace\n+\n+// This custom call copies its arguments to the host and pretty-prints them as\n+// an info log. It takes in a \"format\" attribute to help identify the arguments\n+// in the log. \"Format\" follows the convention of `absl::Substitute`, i.e.,\n+// positional arguments are specified by `$0`, `$1`, etc.\n+XLA_FFI_DEFINE_HANDLER(kXlaGpuDebugPrintCustomCall, DebugPrintCustomCall,\n+                       ffi::Ffi::Bind()\n+                           .Ctx<ffi::Stream>()\n+                           .RemainingArgs()\n+                           .Attr<absl::string_view>(\"format\")\n+                           .Ret<xla::ffi::Buffer<xla::TOKEN>>());\n+\n+XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), kXlaGpuDebugPrintCustomCallTag,\n+                         GetGpuPlatformName(), kXlaGpuDebugPrintCustomCall);\n+\n+XLA_FFI_DEFINE_HANDLER(kXlaGpuAssertCustomCall, AssertionCustomCall,\n+                       ffi::Ffi::Bind()\n+                           .Ctx<ffi::Stream>()\n+                           .Arg<ffi::Buffer<xla::PRED>>()\n+                           .Attr<absl::string_view>(\"error_msg\")\n+                           .Ret<xla::ffi::Buffer<xla::TOKEN>>());\n+\n+XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), kXlaGpuAssertCustomCallTag,\n+                         GetGpuPlatformName(), kXlaGpuAssertCustomCall);\n+\n+// This allows measuring exported HLOs where kOutfeed and kSendDone has been\n+// replaced with NopReturnToken. In that case the runtime of the original\n+// kOutfeed and kSendDone operations is not measured.\n+XLA_REGISTER_CUSTOM_CALL_TARGET_WITH_SYM(\n+    std::string(kNopReturnTokenCustomCallTarget), NopReturnTokenCustomCall,\n+    GetGpuPlatformName());\n+\n+}  // namespace xla"
        },
        {
            "sha": "2397f0a1d21681488cb58d77998a1b920ebdff8d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/runtime_intrinsics.h",
            "status": "added",
            "additions": 31,
            "deletions": 0,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics.h?ref=9c93f4967a6ab78f02c32624e728d85d77f0f1c2",
            "patch": "@@ -0,0 +1,31 @@\n+/* Copyright 2022 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_RUNTIME_INTRINSICS_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_RUNTIME_INTRINSICS_H_\n+\n+#include \"absl/strings/string_view.h\"\n+\n+namespace xla {\n+\n+inline constexpr absl::string_view kXlaGpuAssertCustomCallTag =\n+    \"__xla_gpu_assert\";\n+\n+inline constexpr absl::string_view kXlaGpuDebugPrintCustomCallTag =\n+    \"__xla_gpu_debug_print\";\n+\n+}  // namespace xla\n+\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_RUNTIME_INTRINSICS_H_"
        },
        {
            "sha": "6644623f000281ab42c69c2dacf452c46d26043d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/runtime_intrinsics_test.cc",
            "status": "added",
            "additions": 145,
            "deletions": 0,
            "changes": 145,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics_test.cc?ref=9c93f4967a6ab78f02c32624e728d85d77f0f1c2",
            "patch": "@@ -0,0 +1,145 @@\n+/* Copyright 2023 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <memory>\n+#include <utility>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/base/log_severity.h\"\n+#include \"absl/log/scoped_mock_log.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/tests/hlo_test_base.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/test.h\"\n+\n+namespace xla {\n+namespace gpu {\n+namespace {\n+\n+using RuntimeIntrinsicsTest = HloTestBase;\n+\n+using ::testing::EndsWith;\n+using ::testing::HasSubstr;\n+\n+TEST_F(RuntimeIntrinsicsTest, NopReturnTokenWorks) {\n+  constexpr absl::string_view kHloText = R\"(\n+HloModule m\n+\n+ENTRY e {\n+  constant = u32[2]{0} constant({0, 1})\n+  ROOT nop_return_token = token[] custom-call(constant), custom_call_target=\"NopReturnToken\", custom_call_has_side_effect=true, api_version=API_VERSION_STATUS_RETURNING\n+})\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          GetOptimizedModule(kHloText));\n+\n+  // The parameter of the NopReturnToken is not removed.\n+  EXPECT_EQ(module->entry_computation()->instruction_count(), 2);\n+  // Can run.\n+  EXPECT_TRUE(Run(std::move(module), /*run_hlo_passes=*/false));\n+}\n+\n+TEST_F(RuntimeIntrinsicsTest, AssertionCustomCall) {\n+  constexpr absl::string_view kHloText = R\"(\n+HloModule m\n+\n+ENTRY e {\n+  constant = pred[] constant(true)\n+  ROOT nop_return_token = token[] custom-call(constant), backend_config=\"{error_msg = \\\"1\\\"}\", custom_call_target=\"__xla_gpu_assert\", custom_call_has_side_effect=true, api_version=API_VERSION_TYPED_FFI\n+})\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          GetOptimizedModule(kHloText));\n+\n+  // The parameter of the NopReturnToken is not removed.\n+  EXPECT_EQ(module->entry_computation()->instruction_count(), 2);\n+  // Can run.\n+  EXPECT_TRUE(Run(std::move(module), /*run_hlo_passes=*/false));\n+}\n+\n+TEST_F(RuntimeIntrinsicsTest, AssertionCustomCallFalse) {\n+  constexpr absl::string_view kHloText = R\"(\n+HloModule m\n+\n+ENTRY e {\n+  constant = pred[] constant(false)\n+  ROOT nop_return_token = token[] custom-call(constant), backend_config=\"{error_msg = \\\"1\\\"}\", custom_call_target=\"__xla_gpu_assert\", custom_call_has_side_effect=true, api_version=API_VERSION_TYPED_FFI\n+})\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          GetOptimizedModule(kHloText));\n+\n+  // The parameter of the NopReturnToken is not removed.\n+  EXPECT_EQ(module->entry_computation()->instruction_count(), 2);\n+  // Can run.\n+  EXPECT_FALSE(Run(std::move(module), /*run_hlo_passes=*/false));\n+}\n+\n+TEST_F(RuntimeIntrinsicsTest, DebugPrintCustomCallFailsWhenFormatIsMissing) {\n+  constexpr absl::string_view kHloText = R\"(\n+HloModule m\n+\n+ENTRY e {\n+  constant = f32[2]{0} constant({1, 2})\n+  ROOT print_token = token[] custom-call(constant),\n+    backend_config=\"{format = \\\"test format\\\"}\",\n+    custom_call_target=\"__xla_gpu_debug_print\",\n+    custom_call_has_side_effect=true,\n+    api_version=API_VERSION_TYPED_FFI\n+})\";\n+\n+  ::testing::AssertionResult result = Run(kHloText, /*run_hlo_passes=*/false);\n+  EXPECT_FALSE(result);\n+  EXPECT_THAT(result.message(), HasSubstr(\"Missing formatter for argument 0\"));\n+}\n+\n+TEST_F(RuntimeIntrinsicsTest, DebugPrintCustomCallWithCorrectLogsAsInfo) {\n+  constexpr absl::string_view kHloText = R\"(\n+HloModule m\n+\n+ENTRY e {\n+  constant = f32[2]{0} constant({1, 2})\n+  constant2 = f16[3]{0} constant({3, 4, 5})\n+  ROOT print_token = token[] custom-call(constant, constant2),\n+    backend_config=\"{format = \\\"test format $0 $1\\\"}\",\n+    custom_call_target=\"__xla_gpu_debug_print\",\n+    custom_call_has_side_effect=true,\n+    api_version=API_VERSION_TYPED_FFI\n+})\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          GetOptimizedModule(kHloText));\n+\n+  // The parameters of the custom call are not removed.\n+  EXPECT_EQ(module->entry_computation()->instruction_count(), 3);\n+  absl::ScopedMockLog mock_log(absl::MockLogDefault::kIgnoreUnexpected);\n+  EXPECT_CALL(mock_log,\n+              Log(absl::LogSeverity::kInfo, EndsWith(\"runtime_intrinsics.cc\"),\n+                  HasSubstr(\"test format f32[2] {1, 2} f16[3] {3, 4, 5}\")));\n+  // Run the program once before starting capturing the locks. This works around\n+  // a deadlock caused by ScopedMockLog.\n+  std::unique_ptr<HloModule> module2 = module->Clone();\n+  EXPECT_TRUE(Run(std::move(module2), /*run_hlo_passes=*/false));\n+  mock_log.StartCapturingLogs();\n+  // Runs successfully and logs the expected info.\n+  EXPECT_TRUE(Run(std::move(module), /*run_hlo_passes=*/false));\n+  mock_log.StopCapturingLogs();\n+}\n+\n+}  // namespace\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "903a87a523887e7b2ee91285e2356459e3deb4ff",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 51,
            "changes": 54,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=9c93f4967a6ab78f02c32624e728d85d77f0f1c2",
            "patch": "@@ -14,7 +14,6 @@ load(\n     \"if_google\",\n     \"internal_visibility\",\n     \"tsl_copts\",\n-    \"tsl_gpu_library\",\n )\n load(\"//xla/tsl:tsl.default.bzl\", \"filegroup\", \"get_compatible_with_portable\")\n load(\n@@ -1307,12 +1306,12 @@ cc_library(\n         \":ir_emitter_context\",\n         \":ir_emitter_unnested\",\n         \":metrics\",\n-        \":runtime_intrinsics\",\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n+        \"//xla/backends/gpu/runtime:runtime_intrinsics\",\n         \"//xla/backends/gpu/runtime:sequential_thunk\",\n         \"//xla/hlo/analysis:hlo_ordering\",\n         \"//xla/hlo/ir:hlo\",\n@@ -1445,7 +1444,6 @@ cc_library(\n         \":metrics\",\n         \":pre_scheduling_copy_insertion_pipeline\",\n         \":reduction_utils\",\n-        \":runtime_intrinsics\",\n         \":stream_executor_util\",\n         \"//xla:autotune_results_proto_cc\",\n         \"//xla:debug_options_flags\",\n@@ -1458,6 +1456,7 @@ cc_library(\n         \"//xla/backends/autotuner:codegen_backend\",\n         \"//xla/backends/gpu/autotuner:block_level_emitter\",\n         \"//xla/backends/gpu/codegen/triton:support\",\n+        \"//xla/backends/gpu/runtime:runtime_intrinsics\",\n         \"//xla/backends/gpu/runtime:sequential_thunk\",\n         \"//xla/backends/gpu/runtime:thunk\",\n         \"//xla/core/host_offloading:hlo_host_device_type_call_wrapper\",\n@@ -2315,7 +2314,7 @@ cc_library(\n     srcs = [\"gpu_spmd_pipeline.cc\"],\n     hdrs = [\"gpu_spmd_pipeline.h\"],\n     deps = [\n-        \":runtime_intrinsics\",\n+        \"//xla/backends/gpu/runtime:runtime_intrinsics\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/pass:hlo_pass\",\n         \"//xla/hlo/pass:hlo_pass_pipeline\",\n@@ -2775,53 +2774,6 @@ xla_cc_test(\n     ],\n )\n \n-tsl_gpu_library(\n-    name = \"runtime_intrinsics\",\n-    srcs = [\"runtime_intrinsics.cc\"],\n-    hdrs = [\"runtime_intrinsics.h\"],\n-    deps = [\n-        \"//xla:literal\",\n-        \"//xla:shape_util\",\n-        \"//xla:util\",\n-        \"//xla:xla_data_proto_cc\",\n-        \"//xla/ffi\",\n-        \"//xla/ffi:ffi_api\",\n-        \"//xla/service:collective_ops_utils\",\n-        \"//xla/service:custom_call_status\",\n-        \"//xla/service:custom_call_target_registry\",\n-        \"//xla/service:platform_util\",\n-        \"//xla/stream_executor:memory_allocation\",\n-        \"//xla/stream_executor:stream\",\n-        \"//xla/tsl/platform:errors\",\n-        \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/log\",\n-        \"@com_google_absl//absl/log:check\",\n-        \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/strings\",\n-    ],\n-    alwayslink = 1,\n-)\n-\n-xla_test(\n-    name = \"runtime_intrinsics_test\",\n-    srcs = [\"runtime_intrinsics_test.cc\"],\n-    backends = [\"gpu\"],\n-    deps = [\n-        \":runtime_intrinsics\",\n-        \"//xla/hlo/ir:hlo\",\n-        \"//xla/tests:hlo_test_base\",\n-        \"//xla/tests:xla_internal_test_main\",\n-        \"//xla/tsl/platform:status_matchers\",\n-        \"//xla/tsl/platform:statusor\",\n-        \"//xla/tsl/platform:test\",\n-        \"@com_google_absl//absl/base:log_severity\",\n-        \"@com_google_absl//absl/log:scoped_mock_log\",\n-        \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/strings\",\n-        \"@com_google_googletest//:gtest\",\n-    ],\n-)\n-\n cc_library(\n     name = \"hlo_fusion_stats\",\n     srcs = [\"hlo_fusion_stats.cc\"],"
        },
        {
            "sha": "c0c2c762732502b5141819770c8ef4d0834db6e4",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c93f4967a6ab78f02c32624e728d85d77f0f1c2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=9c93f4967a6ab78f02c32624e728d85d77f0f1c2",
            "patch": "@@ -62,6 +62,7 @@ limitations under the License.\n #include \"mlir/IR/DialectRegistry.h\"\n #include \"mlir/Support/LLVM.h\"\n #include \"xla/backends/gpu/codegen/triton/support.h\"\n+#include \"xla/backends/gpu/runtime/runtime_intrinsics.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/core/host_offloading/hlo_host_device_type_call_wrapper.h\"\n #include \"xla/core/host_offloading/host_compute_asyncifier.h\"\n@@ -188,7 +189,6 @@ limitations under the License.\n #include \"xla/service/gpu/model/sol_gpu_cost_model_stats_collection.h\"\n #include \"xla/service/gpu/pre_scheduling_copy_insertion_pipeline.h\"\n #include \"xla/service/gpu/reduction_utils.h\"\n-#include \"xla/service/gpu/runtime_intrinsics.h\"\n #include \"xla/service/gpu/stream_executor_util.h\"\n #include \"xla/service/gpu/transforms/add_tracking_suffix_to_instruction_names.h\"\n #include \"xla/service/gpu/transforms/algebraic_simplifier.h\""
        }
    ],
    "stats": {
        "total": 441,
        "additions": 389,
        "deletions": 52
    }
}