{
    "author": "unknown",
    "message": "[XLA:GPU] Make Thunk::GetBuffers use BufferUse\n\nIt turned out that we already have a class extremely similar to ThunkBuffer, so\nthere's no point in adding a new one.\n\nPiperOrigin-RevId: 815699778",
    "sha": "ce0e91e50cf254d2f4781872701086d4dae05201",
    "files": [
        {
            "sha": "bf20391398a0d0df43b497ef383d17c95dc8dfb1",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 32,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce0e91e50cf254d2f4781872701086d4dae05201/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce0e91e50cf254d2f4781872701086d4dae05201/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=ce0e91e50cf254d2f4781872701086d4dae05201",
            "patch": "@@ -833,13 +833,13 @@ cc_library(\n     hdrs = [\"kernel_thunk.h\"],\n     deps = [\n         \":thunk\",\n-        \":thunk_buffer\",\n         \":thunk_id\",\n         \":thunk_proto_cc\",\n         \"//xla:shape_util\",\n         \"//xla:types\",\n         \"//xla/codegen/emitters:kernel_arguments\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:launch_dimensions\",\n         \"//xla/service/gpu:stream_executor_util\",\n@@ -877,14 +877,14 @@ xla_test(\n         \":kernel_thunk\",\n         \":sequential_thunk\",\n         \":thunk\",\n-        \":thunk_buffer\",\n         \":thunk_id\",\n         \":thunk_proto_cc\",\n         \"//xla:literal\",\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/codegen/emitters:kernel_arguments\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:executable\",\n         \"//xla/service/gpu:buffer_allocations\",\n@@ -905,7 +905,7 @@ xla_test(\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest_main\",\n-        \"@local_tsl//tsl/platform:protobuf\",\n+        \"@com_google_protobuf//:protobuf\",\n     ],\n )\n \n@@ -1079,7 +1079,6 @@ cc_library(\n         \"//xla/service/gpu:backend_configs_cc\",\n         \"//xla/service/gpu/transforms/collectives:collective_ops_utils\",\n         \"//xla/stream_executor:stream\",\n-        \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:statusor\",\n@@ -1449,12 +1448,10 @@ cc_library(\n         \"//xla/core/collectives:communicator\",\n         \"//xla/core/collectives:rank_id\",\n         \"//xla/hlo/ir:hlo\",\n-        \"//xla/service:collective_ops_utils\",\n         \"//xla/service:computation_placer\",\n         \"//xla/service:global_device_id\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:stream\",\n-        \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\",\n@@ -1511,7 +1508,6 @@ cc_library(\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/stream_executor:event\",\n         \"//xla/stream_executor:stream\",\n-        \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n@@ -1664,33 +1660,11 @@ xla_cc_test(\n     ],\n )\n \n-cc_library(\n-    name = \"thunk_buffer\",\n-    srcs = [\"thunk_buffer.cc\"],\n-    hdrs = [\"thunk_buffer.h\"],\n-    deps = [\n-        \"//xla/service:buffer_assignment\",\n-        \"@com_google_absl//absl/strings:str_format\",\n-    ],\n-)\n-\n-xla_cc_test(\n-    name = \"thunk_buffer_test\",\n-    srcs = [\"thunk_buffer_test.cc\"],\n-    deps = [\n-        \":thunk_buffer\",\n-        \"//xla/service:buffer_assignment\",\n-        \"@com_google_absl//absl/strings\",\n-        \"@com_google_googletest//:gtest_main\",\n-    ],\n-)\n-\n cc_library(\n     name = \"thunk\",\n     srcs = [\"thunk.cc\"],\n     hdrs = [\"thunk.h\"],\n     deps = [\n-        \":thunk_buffer\",\n         \":thunk_id\",\n         \":thunk_proto_cc\",\n         \"//xla:executable_run_options\",\n@@ -1703,6 +1677,7 @@ cc_library(\n         \"//xla/core/collectives:rank_id\",\n         \"//xla/ffi:execution_context\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:executable\",\n         \"//xla/service:global_device_id\",\n@@ -2137,7 +2112,6 @@ cc_library(\n     srcs = [\"ragged_all_to_all.cc\"],\n     hdrs = [\"ragged_all_to_all.h\"],\n     deps = [\n-        \"//xla:future\",\n         \"//xla:shape_util\",\n         \"//xla:types\",\n         \"//xla:util\",\n@@ -2377,7 +2351,6 @@ cc_library(\n         \"//xla/service/gpu/transforms/collectives:collective_ops_utils\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:stream\",\n-        \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n@@ -2471,7 +2444,6 @@ cc_library(\n         \"//xla/service/gpu:backend_configs_cc\",\n         \"//xla/service/gpu/transforms/collectives:collective_ops_utils\",\n         \"//xla/stream_executor:stream\",\n-        \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\","
        },
        {
            "sha": "e180049fa002f9f111356cb1de88b4047c3b714d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/kernel_thunk.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 14,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce0e91e50cf254d2f4781872701086d4dae05201/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce0e91e50cf254d2f4781872701086d4dae05201/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc?ref=ce0e91e50cf254d2f4781872701086d4dae05201",
            "patch": "@@ -34,10 +34,10 @@ limitations under the License.\n #include \"llvm/ADT/STLExtras.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n-#include \"xla/backends/gpu/runtime/thunk_buffer.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/kernels/custom_kernel.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n@@ -54,19 +54,19 @@ limitations under the License.\n namespace xla {\n namespace gpu {\n \n-std::vector<ThunkBuffer> ThunkBuffersFromKernelArguments(\n+Thunk::BufferUses BufferUseFromKernelArguments(\n     absl::Span<const BufferAllocation::Slice> args,\n     const std::vector<bool>& written) {\n-  std::vector<ThunkBuffer> buffers;\n+  Thunk::BufferUses buffers;\n   buffers.reserve(args.size());\n   for (int i = 0; i < args.size(); ++i) {\n-    buffers.push_back(ThunkBuffer{\n-        /*slice=*/args[i],\n-        // We assume that any buffer is either an input or an output of the\n-        // kernel, and inout buffers are represented as 2 separate arguments.\n-        /*is_content_defined_on_input=*/!written[i],\n-        /*is_content_defined_on_output=*/written[i],\n-    });\n+    // We assume that any buffer is either an input or an output of the\n+    // kernel, and inout buffers are represented as 2 separate arguments.\n+    if (written[i]) {\n+      buffers.push_back(BufferUse::Write(args[i]));\n+    } else {\n+      buffers.push_back(BufferUse::Read(args[i]));\n+    }\n   }\n   return buffers;\n }\n@@ -273,8 +273,8 @@ absl::Status KernelThunk::ExecuteOnStream(const ExecuteParams& params) {\n       launch_dimensions_, cluster_dim_, stream);\n }\n \n-std::vector<ThunkBuffer> KernelThunk::GetBuffers() const {\n-  return ThunkBuffersFromKernelArguments(absl::MakeConstSpan(args_), written_);\n+Thunk::BufferUses KernelThunk::buffer_uses() const {\n+  return BufferUseFromKernelArguments(absl::MakeConstSpan(args_), written_);\n }\n \n //===----------------------------------------------------------------------===//\n@@ -345,8 +345,8 @@ absl::Status CustomKernelThunk::ExecuteOnStream(const ExecuteParams& params) {\n                         custom_kernel_.cluster_dims(), params.stream, args);\n }\n \n-std::vector<ThunkBuffer> CustomKernelThunk::GetBuffers() const {\n-  return ThunkBuffersFromKernelArguments(absl::MakeConstSpan(args_), written_);\n+Thunk::BufferUses CustomKernelThunk::buffer_uses() const {\n+  return BufferUseFromKernelArguments(absl::MakeConstSpan(args_), written_);\n }\n \n }  // namespace gpu"
        },
        {
            "sha": "00a604b4f20d309bbc84a6c3e2aefcd77f48f129",
            "filename": "third_party/xla/xla/backends/gpu/runtime/kernel_thunk.h",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce0e91e50cf254d2f4781872701086d4dae05201/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce0e91e50cf254d2f4781872701086d4dae05201/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.h?ref=ce0e91e50cf254d2f4781872701086d4dae05201",
            "patch": "@@ -31,7 +31,6 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n-#include \"xla/backends/gpu/runtime/thunk_buffer.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n@@ -112,7 +111,7 @@ class KernelThunk : public Thunk {\n     return tma_metadata_;\n   }\n \n-  std::vector<ThunkBuffer> GetBuffers() const override;\n+  BufferUses buffer_uses() const override;\n \n  private:\n   // Buffer slices passed to the kernel as arguments.\n@@ -177,7 +176,7 @@ class CustomKernelThunk : public Thunk {\n \n   int64_t shmem_bytes() const { return custom_kernel_.shared_memory_bytes(); }\n \n-  std::vector<ThunkBuffer> GetBuffers() const override;\n+  BufferUses buffer_uses() const override;\n \n  private:\n   // Buffer slices passed to the kernel as arguments."
        },
        {
            "sha": "e319817e654be65f09d374f72d86f9498720479b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/kernel_thunk_test.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 24,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce0e91e50cf254d2f4781872701086d4dae05201/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce0e91e50cf254d2f4781872701086d4dae05201/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk_test.cc?ref=ce0e91e50cf254d2f4781872701086d4dae05201",
            "patch": "@@ -27,17 +27,18 @@ limitations under the License.\n #include <gtest/gtest.h>\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"google/protobuf/text_format.h\"\n #include \"xla/backends/gpu/runtime/command_buffer_cmd.h\"\n #include \"xla/backends/gpu/runtime/command_buffer_cmd_emitter.h\"\n #include \"xla/backends/gpu/runtime/command_buffer_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n-#include \"xla/backends/gpu/runtime/thunk_buffer.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/literal.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/gpu/kernels/custom_kernel.h\"\n@@ -57,7 +58,6 @@ limitations under the License.\n #include \"xla/tsl/platform/test.h\"\n #include \"xla/tsl/util/proto/proto_matchers.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/protobuf.h\"\n \n namespace xla::gpu {\n namespace {\n@@ -269,7 +269,7 @@ TEST(KernelThunkTest, ToAndFromProto) {\n   EXPECT_THAT(reconstructed_thunk->tma_metadata(), tma_metadata);\n }\n \n-TEST(KernelThunkTest, GetBuffersReturnsCorrectBuffers) {\n+TEST(KernelThunkTest, BufferUsesReturnsCorrectBuffers) {\n   BufferAllocation alloc(/*index=*/0, /*size=*/1024, /*color=*/0);\n   BufferAllocation::Slice slice0(&alloc, /*offset=*/0, /*size=*/512);\n   BufferAllocation::Slice slice1(&alloc, /*offset=*/512, /*size=*/512);\n@@ -282,17 +282,13 @@ TEST(KernelThunkTest, GetBuffersReturnsCorrectBuffers) {\n                     LaunchDimensions(), se::ClusterDim(), /*shmem_bytes=*/0,\n                     se::gpu::TmaMetadata());\n \n-  std::vector<ThunkBuffer> buffers = thunk.GetBuffers();\n+  Thunk::BufferUses buffers = thunk.buffer_uses();\n \n-  ASSERT_THAT(buffers,\n-              testing::UnorderedElementsAre(\n-                  ThunkBuffer{slice0, /*is_content_defined_on_input=*/true,\n-                              /*is_content_defined_on_output=*/false},\n-                  ThunkBuffer{slice1, /*is_content_defined_on_input=*/false,\n-                              /*is_content_defined_on_output=*/true}));\n+  ASSERT_THAT(buffers, testing::UnorderedElementsAre(BufferUse::Read(slice0),\n+                                                     BufferUse::Write(slice1)));\n }\n \n-TEST(KernelThunkTest, GetBuffersReturnsBuffersInConsistentOrder) {\n+TEST(KernelThunkTest, BufferUsesReturnsBuffersInConsistentOrder) {\n   BufferAllocation alloc(/*index=*/0, /*size=*/1024, /*color=*/0);\n   BufferAllocation::Slice slice0(&alloc, /*offset=*/0, /*size=*/512);\n   BufferAllocation::Slice slice1(&alloc, /*offset=*/512, /*size=*/512);\n@@ -305,13 +301,13 @@ TEST(KernelThunkTest, GetBuffersReturnsBuffersInConsistentOrder) {\n                     LaunchDimensions(), se::ClusterDim(), /*shmem_bytes=*/0,\n                     se::gpu::TmaMetadata());\n \n-  std::vector<ThunkBuffer> buffers1 = thunk.GetBuffers();\n-  std::vector<ThunkBuffer> buffers2 = thunk.GetBuffers();\n+  Thunk::BufferUses buffers1 = thunk.buffer_uses();\n+  Thunk::BufferUses buffers2 = thunk.buffer_uses();\n \n   ASSERT_THAT(buffers1, testing::ContainerEq(buffers2));\n }\n \n-TEST(CustomKernelThunkTest, GetBuffersReturnsCorrectBuffers) {\n+TEST(CustomKernelThunkTest, BufferUsesReturnsCorrectBuffers) {\n   CustomKernel kernel(\n       /*name=*/\"\",\n       se::KernelLoaderSpec::CreateCudaPtxInMemorySpec(\n@@ -328,17 +324,13 @@ TEST(CustomKernelThunkTest, GetBuffersReturnsCorrectBuffers) {\n   auto hlo = HloInstruction::CreateConstant(Literal());\n   CustomKernelThunk thunk(hlo.get(), kernel, kernel_arguments, ThunkId{0});\n \n-  std::vector<ThunkBuffer> buffers = thunk.GetBuffers();\n+  Thunk::BufferUses buffers = thunk.buffer_uses();\n \n-  ASSERT_THAT(buffers,\n-              testing::UnorderedElementsAre(\n-                  ThunkBuffer{slice0, /*is_content_defined_on_input=*/true,\n-                              /*is_content_defined_on_output=*/false},\n-                  ThunkBuffer{slice1, /*is_content_defined_on_input=*/false,\n-                              /*is_content_defined_on_output=*/true}));\n+  ASSERT_THAT(buffers, testing::UnorderedElementsAre(BufferUse::Read(slice0),\n+                                                     BufferUse::Write(slice1)));\n }\n \n-TEST(CustomKernelThunkTest, GetBuffersReturnsBuffersInConsistentOrder) {\n+TEST(CustomKernelThunkTest, BufferUsesReturnsBuffersInConsistentOrder) {\n   CustomKernel kernel(\n       /*name=*/\"\",\n       se::KernelLoaderSpec::CreateCudaPtxInMemorySpec(\n@@ -355,8 +347,8 @@ TEST(CustomKernelThunkTest, GetBuffersReturnsBuffersInConsistentOrder) {\n   auto hlo = HloInstruction::CreateConstant(Literal());\n   CustomKernelThunk thunk(hlo.get(), kernel, kernel_arguments, ThunkId{0});\n \n-  std::vector<ThunkBuffer> buffers1 = thunk.GetBuffers();\n-  std::vector<ThunkBuffer> buffers2 = thunk.GetBuffers();\n+  Thunk::BufferUses buffers1 = thunk.buffer_uses();\n+  Thunk::BufferUses buffers2 = thunk.buffer_uses();\n \n   ASSERT_THAT(buffers1, testing::ContainerEq(buffers2));\n }"
        },
        {
            "sha": "437533e0617c5e467c3ed577c2165aa01593c42b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.h",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce0e91e50cf254d2f4781872701086d4dae05201/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce0e91e50cf254d2f4781872701086d4dae05201/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h?ref=ce0e91e50cf254d2f4781872701086d4dae05201",
            "patch": "@@ -38,13 +38,13 @@ limitations under the License.\n #include \"xla/backends/gpu/collectives/gpu_cliques.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n-#include \"xla/backends/gpu/runtime/thunk_buffer.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/core/collectives/communicator.h\"\n #include \"xla/core/collectives/rank_id.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/ffi/execution_context.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/global_device_id.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n@@ -500,12 +500,14 @@ class Thunk {\n   // Precondition: Initialize(initialize_params) has been called.\n   virtual absl::Status ExecuteOnStream(const ExecuteParams& params) = 0;\n \n+  using BufferUses = absl::InlinedVector<BufferUse, 4>;\n+\n   // Returns all device buffers used by the thunk.\n   //\n   // Does not propagate buffers from nested thunks.\n   //\n   // The order of the buffers in returned vector is consistent across calls.\n-  virtual std::vector<ThunkBuffer> GetBuffers() const { return {}; }\n+  virtual BufferUses buffer_uses() const { return {}; }\n \n   static absl::string_view KindToString(Thunk::Kind kind);\n "
        },
        {
            "sha": "4a5d91ad453eb17abd4368c6e0f9488ba4d14775",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/eb927a519f145109fb876e1a4f55a55a60381f98/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/eb927a519f145109fb876e1a4f55a55a60381f98/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer.cc?ref=eb927a519f145109fb876e1a4f55a55a60381f98",
            "patch": "@@ -1,31 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/backends/gpu/runtime/thunk_buffer.h\"\n-\n-#include <string>\n-\n-#include \"absl/strings/str_format.h\"\n-\n-namespace xla::gpu {\n-\n-std::string ThunkBuffer::ToString() const {\n-  return absl::StrFormat(\n-      \"{slice:%v, is_content_defined_on_input:%v, \"\n-      \"is_content_defined_on_output:%v}\",\n-      slice, is_content_defined_on_input, is_content_defined_on_output);\n-}\n-\n-}  // namespace xla::gpu"
        },
        {
            "sha": "77ce8a6669b791220b6cc65ec3819d6e3b17288e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer.h",
            "status": "removed",
            "additions": 0,
            "deletions": 57,
            "changes": 57,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/eb927a519f145109fb876e1a4f55a55a60381f98/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/eb927a519f145109fb876e1a4f55a55a60381f98/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer.h?ref=eb927a519f145109fb876e1a4f55a55a60381f98",
            "patch": "@@ -1,57 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_BACKENDS_GPU_RUNTIME_THUNK_BUFFER_H_\n-#define XLA_BACKENDS_GPU_RUNTIME_THUNK_BUFFER_H_\n-\n-#include <string>\n-#include <tuple>\n-\n-#include \"absl/strings/str_format.h\"\n-#include \"xla/service/buffer_assignment.h\"\n-\n-namespace xla::gpu {\n-\n-// A buffer used by a `Thunk`.\n-struct ThunkBuffer {\n-  // The buffer used by the thunk. May be a host or device buffer, check the\n-  // `BufferAllocation::Color` of slice's allocation to determine.\n-  BufferAllocation::Slice slice;\n-  // True if the slice has defined contents when the thunk starts execution.\n-  bool is_content_defined_on_input = true;\n-  // True if the slice has defined contents when the thunk finishes execution.\n-  // This may mean the buffer contains the thunk's output, or that the thunk is\n-  // expected to preserve the original value of the input buffer.\n-  bool is_content_defined_on_output = true;\n-\n-  bool operator==(const ThunkBuffer& other) const {\n-    return std::tie(slice, is_content_defined_on_input,\n-                    is_content_defined_on_output) ==\n-           std::tie(other.slice, other.is_content_defined_on_input,\n-                    other.is_content_defined_on_output);\n-  }\n-  bool operator!=(const ThunkBuffer& other) const { return !(*this == other); }\n-\n-  std::string ToString() const;\n-\n-  template <typename Sink>\n-  friend void AbslStringify(Sink& sink, const ThunkBuffer& buffer) {\n-    absl::Format(&sink, \"%v\", buffer.ToString());\n-  }\n-};\n-\n-}  // namespace xla::gpu\n-\n-#endif  // XLA_BACKENDS_GPU_RUNTIME_THUNK_BUFFER_H_"
        },
        {
            "sha": "939a2356a4fa209fecb2ecd844e3e4c19f35f2d2",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_test.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 42,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/eb927a519f145109fb876e1a4f55a55a60381f98/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/eb927a519f145109fb876e1a4f55a55a60381f98/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_test.cc?ref=eb927a519f145109fb876e1a4f55a55a60381f98",
            "patch": "@@ -1,42 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/backends/gpu/runtime/thunk_buffer.h\"\n-\n-#include <gtest/gtest.h>\n-#include \"absl/strings/str_cat.h\"\n-#include \"xla/service/buffer_assignment.h\"\n-\n-namespace xla::gpu {\n-namespace {\n-\n-TEST(ThunkBufferTest, AbslStringify) {\n-  BufferAllocation alloc(/*index=*/0, /*size=*/1024, /*color=*/0);\n-  BufferAllocation::Slice slice(&alloc, /*offset=*/123, /*size=*/456);\n-\n-  const ThunkBuffer buffer{\n-      /*slice=*/slice,\n-      /*is_content_defined_on_input=*/true,\n-      /*is_content_defined_on_output=*/false,\n-  };\n-\n-  EXPECT_EQ(absl::StrCat(buffer),\n-            \"{slice:{index:0, offset:123, size:456}, \"\n-            \"is_content_defined_on_input:true, \"\n-            \"is_content_defined_on_output:false}\");\n-}\n-\n-}  // namespace\n-}  // namespace xla::gpu"
        }
    ],
    "stats": {
        "total": 245,
        "additions": 40,
        "deletions": 205
    }
}