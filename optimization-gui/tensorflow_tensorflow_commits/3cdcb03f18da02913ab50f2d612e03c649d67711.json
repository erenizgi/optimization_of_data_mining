{
    "author": "olupton",
    "message": "PR #32838: Fix family-conditional logic\n\nImported from GitHub PR https://github.com/openxla/xla/pull/32838\n\nüìù Summary of Changes\nThe fallback logic now correctly identifies the highest known compatible architecture when given an unknown architecture as input.\n\nüéØ Justification\nPreviously the logic would propose an incompatible architecture in this case.\n\nüöÄ Kind of Contribution\nüêõ Bug Fix\n\nüß™ Unit Tests:\nAdded a new test case showing the previously-failing case (it used to propose `sm_110`)\nCopybara import of the project:\n\n--\nf060bb9837d72159343ff2d52f5f2f42b1b7e9a4 by Olli Lupton <olupton@nvidia.com>:\n\nFix family-conditional logic\n\n--\nfc44dcd1e76da67c0b6fe53c33d2a571c3a6ff50 by Olli Lupton <olupton@nvidia.com>:\n\nAccept CR suggestion\n\nMerging this change closes #32838\n\nPiperOrigin-RevId: 822284790",
    "sha": "3cdcb03f18da02913ab50f2d612e03c649d67711",
    "files": [
        {
            "sha": "8ead9f096e1fda91cd30c0528d447668fc1e3ff8",
            "filename": "third_party/xla/xla/service/gpu/llvm_gpu_backend/nvptx_backend.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3cdcb03f18da02913ab50f2d612e03c649d67711/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fnvptx_backend.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3cdcb03f18da02913ab50f2d612e03c649d67711/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fnvptx_backend.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fnvptx_backend.cc?ref=3cdcb03f18da02913ab50f2d612e03c649d67711",
            "patch": "@@ -247,13 +247,16 @@ std::string GetSmName(se::CudaComputeCapability compute_capability) {\n       {12, 1}, {12, 0}, {11, 0}, {10, 3}, {10, 0}, {9, 0}, {8, 9}, {8, 7},\n       {8, 6},  {8, 0},  {7, 5},  {7, 2},  {7, 0},  {6, 2}, {6, 1}, {6, 0},\n       {5, 3},  {5, 2},  {5, 0},  {3, 7},  {3, 5},  {3, 2}, {3, 0}};\n-  auto target_compute_capability = kSupportedVersions[0];\n+  // Initialize to the least supported version, which acts as a safe fallback\n+  auto target_compute_capability =\n+      kSupportedVersions[std::size(kSupportedVersions) - 1];\n \n   for (const auto& v : kSupportedVersions) {\n-    if (!gpu_compute_capability.CanRunOn(v)) {\n+    if (gpu_compute_capability.SupportsAllFeaturesOf(v)) {\n+      // Found the most advanced supported capability\n+      target_compute_capability = v;\n       break;\n     }\n-    target_compute_capability = v;\n   }\n \n   if (target_compute_capability.major == gpu_compute_capability.major &&"
        },
        {
            "sha": "627ec04978ad968e805657a8cb54c378d803cc0e",
            "filename": "third_party/xla/xla/service/gpu/llvm_gpu_backend/nvptx_backend_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3cdcb03f18da02913ab50f2d612e03c649d67711/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fnvptx_backend_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3cdcb03f18da02913ab50f2d612e03c649d67711/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fnvptx_backend_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fnvptx_backend_test.cc?ref=3cdcb03f18da02913ab50f2d612e03c649d67711",
            "patch": "@@ -56,6 +56,10 @@ TEST(UtilsTest, TestGetSmName) {\n             \"sm_121a\");\n   // Do not use the extension for a yet-unknown compute capability.\n   // https://docs.nvidia.com/cuda/parallel-thread-execution/#release-notes-ptx-release-history\n+  ASSERT_EQ(nvptx::GetSmName(se::CudaComputeCapability{10, 9}), \"sm_103f\");\n+  ASSERT_EQ(nvptx::GetSmName(se::CudaComputeCapability{\n+                10, 9, FeatureExtension::kAcceleratedFeatures}),\n+            \"sm_103f\");\n   ASSERT_EQ(nvptx::GetSmName(se::CudaComputeCapability{12, 9}), \"sm_121f\");\n   ASSERT_EQ(nvptx::GetSmName(se::CudaComputeCapability{13, 0}), \"sm_121\");\n }"
        }
    ],
    "stats": {
        "total": 13,
        "additions": 10,
        "deletions": 3
    }
}