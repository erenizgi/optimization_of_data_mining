{
    "author": "ezhulenev",
    "message": "[xla:cpu] Fix data race in ThunkExecutor\n\nAlso add tsl::down_pointer_cast to improve usability.\n\nPiperOrigin-RevId: 822257137",
    "sha": "0fc052399b47a73844bedcce3e484316732ff6d9",
    "files": [
        {
            "sha": "a09487a91e36e33941aa456735cfcd3817aec284",
            "filename": "third_party/xla/xla/backends/cpu/runtime/thunk_executor.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0fc052399b47a73844bedcce3e484316732ff6d9/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0fc052399b47a73844bedcce3e484316732ff6d9/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_executor.cc?ref=0fc052399b47a73844bedcce3e484316732ff6d9",
            "patch": "@@ -233,11 +233,12 @@ tsl::AsyncValueRef<Thunk::ExecuteEvent> ThunkExecutor::TracedExecute(\n \n   // When thunk execution completes, create a consumer traceme to capture the\n   // end event.\n-  execute_event.AndThen([context_id = producer.GetContextId(), &thunk] {\n-    tsl::profiler::TraceMeConsumer(\n-        [&] { return absl::StrFormat(\"end: %s\", thunk.info().op_name); },\n-        tsl::profiler::ContextType::kGeneric, context_id);\n-  });\n+  execute_event.AndThen(\n+      [context_id = producer.GetContextId(), op_name = thunk.info().op_name] {\n+        tsl::profiler::TraceMeConsumer(\n+            [&] { return absl::StrFormat(\"end: %s\", op_name); },\n+            tsl::profiler::ContextType::kGeneric, context_id);\n+      });\n \n   return execute_event;\n }"
        },
        {
            "sha": "86685f8f44a92408cf4118aec53284adbbf83066",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0fc052399b47a73844bedcce3e484316732ff6d9/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0fc052399b47a73844bedcce3e484316732ff6d9/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc?ref=0fc052399b47a73844bedcce3e484316732ff6d9",
            "patch": "@@ -1540,8 +1540,8 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n         });\n   }\n \n-  auto* cpu_executable =\n-      tsl::down_cast<cpu::CpuExecutable*>(cpu_executable_.get());\n+  auto cpu_executable =\n+      tsl::down_pointer_cast<cpu::CpuExecutable>(cpu_executable_);\n   // `buffer_alloc` and `buffer_alloc_and_copy` are used to do real memory\n   // allocation and copy work.\n   BufferAlloc buffer_alloc;\n@@ -1755,7 +1755,6 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n          buffer_alloc_and_copy = std::move(buffer_alloc_and_copy),\n          buffer_table = std::move(buffer_table),\n          run_options = std::move(run_options),\n-         cpu_executable_copy = cpu_executable_,\n          device_assignment = std::move(device_assignment),\n          cpu_run_options = std::move(cpu_run_options),\n          compute_reservation = std::move(compute_reservation),"
        },
        {
            "sha": "3825e2180d5d842917a8204c78ee73a665e5e818",
            "filename": "third_party/xla/xla/tsl/platform/default/casts.h",
            "status": "modified",
            "additions": 11,
            "deletions": 1,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0fc052399b47a73844bedcce3e484316732ff6d9/third_party%2Fxla%2Fxla%2Ftsl%2Fplatform%2Fdefault%2Fcasts.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0fc052399b47a73844bedcce3e484316732ff6d9/third_party%2Fxla%2Fxla%2Ftsl%2Fplatform%2Fdefault%2Fcasts.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fplatform%2Fdefault%2Fcasts.h?ref=0fc052399b47a73844bedcce3e484316732ff6d9",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n \n #include <assert.h>  // for use with down_cast<>\n \n+#include <memory>\n #include <type_traits>\n \n namespace tensorflow {\n@@ -87,10 +88,19 @@ inline To down_cast(From& f) {\n   return static_cast<To>(f);\n }\n \n+// A `down_cast` version for `std::shared_ptr`.\n+template <typename To, typename From>\n+std::shared_ptr<To> down_pointer_cast(const std::shared_ptr<From>& from) {\n+  auto* ptr =\n+      down_cast<typename std::shared_ptr<To>::element_type*>(from.get());\n+  return std::shared_ptr<To>{from, ptr};\n+}\n+\n }  // namespace tensorflow\n \n namespace tsl {\n using ::tensorflow::down_cast;\n-}\n+using ::tensorflow::down_pointer_cast;\n+}  // namespace tsl\n \n #endif  // XLA_TSL_PLATFORM_DEFAULT_CASTS_H_"
        }
    ],
    "stats": {
        "total": 28,
        "additions": 19,
        "deletions": 9
    }
}