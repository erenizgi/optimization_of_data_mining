{
    "author": "WillFroom",
    "message": "[XLA:GPU][XTile] Move xtile lowering to compilation pipeline.\n\nPiperOrigin-RevId: 822066890",
    "sha": "bd257617f73c6b5c17555e0c8995ea5bfd4fc30e",
    "files": [
        {
            "sha": "9a3cfb49ff6567f874017f357c05e2415fa75376",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/compilation_pipeline.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline.cc?ref=bd257617f73c6b5c17555e0c8995ea5bfd4fc30e",
            "patch": "@@ -33,6 +33,7 @@ void CreateTritonXlaPipeline(\n     mlir::OpPassManager* pm,\n     const stream_executor::GpuComputeCapability& gpu_cc, bool rewrite_int4,\n     bool allow_tma) {\n+  pm->addPass(mlir::triton::xla::CreateTritonXLALowerXTilePass());\n   pm->addPass(mlir::triton::xla::CreateTritonXLASqueezeDimsPass());\n   pm->addPass(mlir::triton::xla::CreateTritonXLAFoldTransposePass());\n "
        },
        {
            "sha": "b7b69c55b249bea3624fc099f9bea88c0aae561e",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=bd257617f73c6b5c17555e0c8995ea5bfd4fc30e",
            "patch": "@@ -1936,8 +1936,14 @@ absl::Status CreateInternalError(absl::string_view message,\n \n mlir::MemRefType GetMemRefType(const Shape& shape, mlir::Type element_type) {\n   mlir::MLIRContext* context = element_type.getContext();\n-\n   mlir::Type storage_type = StorageType(element_type);\n+\n+  // Don't add any attribute for default layouts as it adds a lot of noise to\n+  // the printed IR.\n+  if (LayoutUtil::IsMonotonicWithDim0Major(shape.layout())) {\n+    return mlir::MemRefType::get(shape.dimensions(), storage_type);\n+  }\n+\n   auto minor_to_major_attr =\n       mlir::DenseI64ArrayAttr::get(context, shape.layout().minor_to_major());\n   auto layout = mtx::LayoutAttr::get(context, minor_to_major_attr);\n@@ -2328,7 +2334,6 @@ absl::Status LowerXTileToTriton(mlir::ModuleOp xtile_dialect_module,\n     // Disable verifier because the Triton code may be invalid due to the\n     // unsupported types.\n     pm.enableVerifier(/*enabled=*/false);\n-    pm.addPass(mlir::triton::xla::CreateTritonXLALowerXTilePass());\n     pm.addPass(mlir::triton::xla::CreateTensorLowerToTritonPass());\n     pm.addPass(mlir::triton::xla::CreateStableHLOLowerToTritonPass());\n     if (mlir::failed(pm.run(xtile_dialect_module))) {"
        },
        {
            "sha": "a495e09b4ad8f50e981767c0ce4848cd5af97a42",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_port_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc?ref=bd257617f73c6b5c17555e0c8995ea5bfd4fc30e",
            "patch": "@@ -267,7 +267,7 @@ ENTRY e {\n       CreateTritonIrAndFileCheck(*module_and_metadata.computation,\n                                  module_and_metadata.block_level_parameters,\n                                  R\"(\n-CHECK: %[[LOAD:.*]] = triton_xla.extract {{.*}} : tensor<16x16xi8>\n+CHECK: %[[LOAD:.*]] = xtile.extract {{.*}} -> tensor<16x16xi8>\n CHECK: %[[TRUNCI:.*]] = arith.trunci %[[LOAD]] : tensor<16x16xi8> to tensor<16x16xi1>\n CHECK: %{{.*}} = arith.andi %[[TRUNCI]], %{{.*}} : tensor<16x16xi1>\n )\"));"
        },
        {
            "sha": "0a6e6175b4c1b112813c9e287e88237d91bea5e3",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_test.cc",
            "status": "modified",
            "additions": 28,
            "deletions": 10,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc?ref=bd257617f73c6b5c17555e0c8995ea5bfd4fc30e",
            "patch": "@@ -263,7 +263,10 @@ ENTRY e {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheckForDot(this, kHloText, \"triton_gemm_r\", R\"(\n-CHECK:    func.func @triton_fn(%[[LHS:.*]]: !tt.ptr<i8>, %[[RHS:.*]]: !tt.ptr<f32>, %[[OUT:.*]]: !tt.ptr<f32>) {\n+CHECK:    xtile.entry_func @triton_fn(\n+CHECK-SAME:   %[[LHS_MEMREF:.*]]: memref<80x115xi8>\n+CHECK-SAME:   %[[RHS_MEMREF:.*]]: memref<137x115xf32>\n+CHECK-SAME:   %[[OUT_MEMREF:.*]]: memref<80x137xf32>\n CHECK-DAG:  %[[ZERO_KN:.*]] = arith.constant dense<0.000000e+00> : tensor<32x64xf32>\n CHECK-DAG:  %[[ZERO_MK:.*]] = arith.constant dense<0.000000e+00> : tensor<16x32xf32>\n CHECK-DAG:  %[[ZERO_MN:.*]] = arith.constant dense<0.000000e+00> : tensor<16x64xf32>\n@@ -288,9 +291,11 @@ CHECK:      %[[PID_M:.*]] = arith.remsi %[[PID_NC]], %[[GROUP_SIZE]]\n CHECK:      %[[TILE_INDEX_M:.*]] = arith.addi %[[FIRST_PID_M]], %[[PID_M]] : i32\n CHECK:      %[[TMP:.*]] = arith.remsi %[[PID_NC]], %[[WIDTH]] : i32\n CHECK:      %[[TILE_INDEX_N:.*]] = arith.divsi %[[TMP]], %[[GROUP_SIZE]] : i32\n+CHECK:      %[[LHS:.*]] = triton_xla.memref_to_ptr %[[LHS_MEMREF]]\n CHECK:      %[[TILE_OFFSET_M_LHS:.*]] = arith.muli %[[TILE_INDEX_M]], %[[TILE_SIZE_M]]\n CHECK:      %[[LHS_PTR:.*]] = tt.make_tensor_ptr %[[LHS]]\n CHECK:      %[[LHS_TILE_PTR:.*]] = tt.advance %[[LHS_PTR]], [%[[TILE_OFFSET_M_LHS]], %[[C0]]]\n+CHECK:      %[[RHS:.*]] = triton_xla.memref_to_ptr %[[RHS_MEMREF]]\n CHECK:      %[[TILE_OFFSET_N_RHS:.*]] = arith.muli %[[TILE_INDEX_N]], %[[TILE_SIZE_N]]\n CHECK:      %[[RHS_PTR:.*]] = tt.make_tensor_ptr %[[RHS]]\n CHECK:      %[[RHS_TILE_PTR:.*]] = tt.advance %[[RHS_PTR]], [%[[C0]], %[[TILE_OFFSET_N_RHS]]]\n@@ -323,10 +328,11 @@ CHECK:        scf.yield %[[RHS_TILE]] : tensor<32x64xf32>\n CHECK:        %[[ACC_NEXT:.*]] = tt.dot %[[LHS_MASK_IF_STMT]], %[[RHS_MASK_IF_STMT]], %[[ACC]]\n CHECK:        scf.yield %[[LHS_ITER_PTR_NEXT]], %[[RHS_ITER_PTR_NEXT]], %[[ACC_NEXT]] : !tt.ptr<tensor<16x32xi8>>, !tt.ptr<tensor<32x64xf32>>, tensor<16x64xf32>\n CHECK:      }\n+CHECK:      %[[OUT:.*]] = triton_xla.memref_to_ptr %[[OUT_MEMREF]]\n CHECK:      %[[OUT_PTR:.*]] = tt.make_tensor_ptr %[[OUT]], [%[[C80]], %[[SIZE_M]]], [%[[SIZE_M]], %[[C1]]], [%[[C0]], %[[C0]]] {order = array<i32: 1, 0>} : <tensor<16x64xf32>>\n CHECK:      %[[OUT_OFFSET:.*]] = tt.advance %[[OUT_PTR]], [%[[TILE_OFFSET_M_LHS]], %[[TILE_OFFSET_N_RHS]]] : <tensor<16x64xf32>>\n CHECK:      tt.store %[[OUT_OFFSET]], %[[FOR]]#2 {boundaryCheck = array<i32: 1>} : !tt.ptr<tensor<16x64xf32>>\n-CHECK:      return\n+CHECK:      xtile.return\n CHECK:    }\n )\"));\n }\n@@ -355,7 +361,10 @@ ENTRY e {\n \n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheckForDot(this, kHloText, \"triton_dot\", R\"(\n-CHECK:    func.func @triton_fn(%[[LHS:.*]]: !tt.ptr<f32>, %[[RHS:.*]]: !tt.ptr<f32>, %[[OUT:.*]]: !tt.ptr<f32>) {\n+CHECK:    xtile.entry_func @triton_fn(\n+CHECK-SAME:   %[[LHS_MEMREF:.*]]: memref<137x115xf32>\n+CHECK-SAME:   %[[RHS_MEMREF:.*]]: memref<1x115xf32>\n+CHECK-SAME:   %[[OUT_MEMREF:.*]]: memref<137x1xf32>\n CHECK-DAG:  %[[ZERO_KN:.*]] = arith.constant dense<0.000000e+00> : tensor<32x16xf32>\n CHECK-DAG:  %[[ZERO_MK:.*]] = arith.constant dense<0.000000e+00> : tensor<16x32xf32>\n CHECK-DAG:  %[[ZERO_MN:.*]] = arith.constant dense<0.000000e+00> : tensor<16x16xf32>\n@@ -378,9 +387,11 @@ CHECK:    %[[PID_M:.*]] = arith.remsi %[[PID_NC]], %[[GROUP_SIZE]]\n CHECK:    %[[TILE_INDEX_M:.*]] = arith.addi %[[FIRST_PID_M]], %[[PID_M]]\n CHECK:    %[[TMP:.*]] = arith.remsi %[[PID_NC]], %[[C8]]\n CHECK:    %[[TILE_INDEX_N:.*]] = arith.divsi %[[TMP]], %[[GROUP_SIZE]]\n+CHECK:    %[[LHS:.*]] = triton_xla.memref_to_ptr %[[LHS_MEMREF]]\n CHECK:    %[[TILE_OFFSET_M_LHS:.*]] = arith.muli %[[TILE_INDEX_M]], %[[TILE_SIZE_M]]\n CHECK:    %[[LHS_PTR:.*]] = tt.make_tensor_ptr %[[LHS]]\n CHECK:    %[[LHS_TILE_PTR:.*]] = tt.advance %[[LHS_PTR]], [%[[TILE_OFFSET_M_LHS]], %[[C0]]]\n+CHECK:    %[[RHS:.*]] = triton_xla.memref_to_ptr %[[RHS_MEMREF]]\n CHECK:    %[[TILE_OFFSET_N_RHS:.*]] = arith.muli %[[TILE_INDEX_N]], %[[TILE_SIZE_M]]\n CHECK:    %[[RHS_PTR:.*]] = tt.make_tensor_ptr %[[RHS]]\n CHECK:    %[[RHS_TILE_PTR:.*]] = tt.advance %[[RHS_PTR]], [%[[C0]], %[[TILE_OFFSET_N_RHS]]]\n@@ -413,10 +424,11 @@ CHECK:      %[[ACC_NEXT:.*]] = tt.dot %[[LHS_MASK_IF_STMT]], %[[RHS_MASK_IF_STMT\n CHECK:      scf.yield %[[LHS_ITER_PTR_NEXT]], %[[RHS_ITER_PTR_NEXT]], %[[ACC_NEXT]] : !tt.ptr<tensor<16x32xf32>>, !tt.ptr<tensor<32x16xf32>>, tensor<16x16xf32>\n CHECK:    }\n \n+CHECK:    %[[OUT:.*]] = triton_xla.memref_to_ptr %[[OUT_MEMREF]]\n CHECK:    %[[OUT_PTR:.*]] = tt.make_tensor_ptr %[[OUT]], [%[[SIZE_M]], %[[C1]]], [%[[C1]], %[[C1]]], [%[[C0]], %[[C0]]] {order = array<i32: 1, 0>} : <tensor<16x16xf32>>\n CHECK:    %[[OUT_OFFSET:.*]] = tt.advance %[[OUT_PTR]], [%[[TILE_OFFSET_M_LHS]], %[[TILE_OFFSET_N_RHS]]] : <tensor<16x16xf32>>\n CHECK:    tt.store %[[OUT_OFFSET]], %[[FOR]]#2 {boundaryCheck = array<i32: 0, 1>} : !tt.ptr<tensor<16x16xf32>>\n-CHECK:    return\n+CHECK:    xtile.return\n CHECK:  }\n )\"));\n }\n@@ -490,10 +502,12 @@ ENTRY e {\n \n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheckForDot(this, kHloText, \"triton_gemm\", R\"(\n-CHECK:   func.func @triton_fn(%[[P0:[^:]*]]: !tt.ptr<f32>\n-CHECK-SAME:                 %[[P1:[^:]*]]: !tt.ptr<f32>\n-CHECK-SAME:                 %[[P2:[^:]*]]: !tt.ptr<f32>\n-CHECK-DAG: %[[ARG_PTR:.*]] = arith.select %[[CONCAT_COND:.*]], %[[P1]], %[[P2]]\n+CHECK:   xtile.entry_func @triton_fn(%[[P0:[^:]*]]: memref<2x3x10xf32>\n+CHECK-SAME:                          %[[P1:[^:]*]]: memref<2x10x128xf32>\n+CHECK-SAME:                          %[[P2:[^:]*]]: memref<2x10x256xf32>\n+CHECK-DAG: %[[P1_PTR:.*]] = triton_xla.memref_to_ptr %[[P1]]\n+CHECK-DAG: %[[P2_PTR:.*]] = triton_xla.memref_to_ptr %[[P2]]\n+CHECK-DAG: %[[ARG_PTR:.*]] = arith.select %[[CONCAT_COND:.*]], %[[P1_PTR]], %[[P2_PTR]]\n CHECK-DAG: %[[BATCH_STRIDE_P1:.*]] = arith.constant 1280\n CHECK-DAG: %[[BATCH_STRIDE_P2:.*]] = arith.constant 2560\n CHECK-DAG: %[[BATCH_STRIDE:.*]] = arith.select %[[CONCAT_COND_2:.*]], %[[BATCH_STRIDE_P1]], %[[BATCH_STRIDE_P2]]\n@@ -537,13 +551,17 @@ ENTRY e {\n \n   ASSERT_THAT(\n       CreateTritonIrAndFileCheckForDot(this, kHloText, \"triton_gemm\", R\"(\n-CHECK:     func.func @triton_fn({{[^,]*}}, %[[DYNAMIC_SLICE_INPUT:[^:]*]]: !tt.ptr<f32>, %[[START_INDEX0_PTR:[^:]*]]: !tt.ptr<i32>\n+CHECK:     xtile.entry_func @triton_fn(\n+CHECK-SAME: {{[^,]*}}, %[[DYNAMIC_SLICE_INPUT_MEMREF:[^:]*]]: memref<4x5x2xf32>\n+CHECK-SAME: {{[^,]*}}, %[[START_INDEX0_MEMREF:[^:]*]]: memref<i32>\n CHECK-DAG:   %[[C0_i32:.*]] = arith.constant 0 : i32\n CHECK-DAG:   %[[C1_i64:.*]] = arith.constant 1 : i64\n CHECK-DAG:   %[[C2_i64:.*]] = arith.constant 2 : i64\n CHECK-DAG:   %[[C3_i32:.*]] = arith.constant 3 : i32\n CHECK-DAG:   %[[C5_i32:.*]] = arith.constant 5 : i32\n CHECK-DAG:   %[[C5_i64:.*]] = arith.constant 5 : i64\n+CHECK-DAG:   %[[DYNAMIC_SLICE_INPUT:.*]] = triton_xla.memref_to_ptr %[[DYNAMIC_SLICE_INPUT_MEMREF]]\n+CHECK-DAG:   %[[START_INDEX0_PTR:.*]] = triton_xla.memref_to_ptr %[[START_INDEX0_MEMREF]]\n CHECK-DAG:   %[[START_INDEX0:.*]] = tt.load %[[START_INDEX0_PTR]] : !tt.ptr<i32>\n CHECK-DAG:   %[[SEMI_CLAMPED_START_INDEX0:.*]] = arith.maxsi %[[START_INDEX0]], %[[C0_i32]] : i32\n CHECK-DAG:   %[[CLAMPED_START_INDEX0:.*]] = arith.minsi %[[SEMI_CLAMPED_START_INDEX0]], %[[C3_i32]] : i32\n@@ -1229,7 +1247,7 @@ ENTRY e {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheckForDot(this, kHloText, \"triton_gemm_r\", R\"(\n-CHECK:    func.func @triton_fn\n+CHECK:    xtile.entry_func @triton_fn\n CHECK-DAG:      %[[ZERO:.*]] = arith.constant dense<0>\n CHECK-DAG:      %[[FMIN:.*]] = arith.constant dense<-1.280000e+02>\n CHECK-DAG:      %[[IMIN:.*]] = arith.constant dense<-128>"
        },
        {
            "sha": "ffe13a1c51181e389a2bbfb7a6c6e55c1500ae4a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 99,
            "deletions": 96,
            "changes": 195,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=bd257617f73c6b5c17555e0c8995ea5bfd4fc30e",
            "patch": "@@ -397,11 +397,11 @@ ENTRY entry_computation {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n-CHECK-COUNT-1:  triton_xla.extract\n+CHECK-COUNT-1:  xtile.extract\n CHECK:  %[[ABS:.*]] = math.absf\n CHECK: %[[REDUCE:.*]] = \"tt.reduce\"(%[[ABS:.*]]) <{axis = 1 : i32}>\n-CHECK:  triton_xla.insert %[[REDUCE]] {{.*}} : tensor<64xf32>\n-CHECK:  triton_xla.insert %[[ABS]] {{.*}} : tensor<64x512xf32>\n+CHECK:  xtile.insert %[[REDUCE]] {{.*}} : tensor<64xf32>\n+CHECK:  xtile.insert %[[ABS]] {{.*}} : tensor<64x512xf32>\n )\"));\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n@@ -439,11 +439,12 @@ ENTRY entry_computation {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n-CHECK-COUNT-1:  triton_xla.extract\n+CHECK-COUNT-1:  xtile.extract\n CHECK:  %[[ABS:.*]] = math.absf\n CHECK: %[[REDUCE:.*]] = \"tt.reduce\"(%[[ABS:.*]]) <{axis = 0 : i32}>\n-CHECK:  tt.store %arg1, %[[REDUCE]] : !tt.ptr<f32>\n-CHECK:  triton_xla.insert %[[ABS]] {{.*}} : tensor<512xf32>\n+CHECK: %[[SCALAR_TENSOR:.*]] = tensor.from_elements %[[REDUCE]] : tensor<f32>\n+CHECK: xtile.insert %[[SCALAR_TENSOR]] into %arg1\n+CHECK: xtile.insert %[[ABS]] {{.*}} : tensor<512xf32>\n )\"));\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n@@ -806,9 +807,9 @@ ENTRY entry_computation {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n-CHECK-COUNT-1:  triton_xla.extract\n+CHECK-COUNT-1:  xtile.extract\n CHECK: tt.reduce\n-CHECK-COUNT-2:  triton_xla.insert\n+CHECK-COUNT-2:  xtile.insert\n )\"));\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n@@ -954,7 +955,7 @@ CHECK:  })\n   TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n       this, xtile_module_and_hlo_module.first.get(), R\"(\n ; Make sure input reduction tile is padded with a neutral value.\n-CHECK:  %[[LOAD:.*]] = triton_xla.extract\n+CHECK:  %[[LOAD:.*]] = xtile.extract\n CHECK:  %[[RANGE:.*]] = tt.make_range\n CHECK:  %[[EXPAND:.*]] = tt.expand_dims %[[RANGE]]\n CHECK:  %[[BROADCAST:.*]] = tt.broadcast %[[EXPAND]]\n@@ -1005,19 +1006,18 @@ ENTRY main {\n         \"num_stages\":\"1\"}}}})\";\n   TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText,\n                                           \"triton_softmax_computation\", R\"(\n-CHECK:        func.func @triton_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}})\n-CHECK-DAG:        %[[PID:.*]] = tt.get_program_id x : i32\n-CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_cast %[[PID]] : i32 to index\n-CHECK-NEXT:       triton_xla.extract from %[[P0]]\n-CHECK-SAME:       [%[[PID_INDEX]], 0] [1, 128] [1, 1]\n+CHECK:        xtile.entry_func @triton_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}}, %[[PID:.*]]: index)\n+CHECK-DAG:        %[[C_0:.*]] = arith.constant 0 : index\n+CHECK-NEXT:       xtile.extract %[[P0]]\n+CHECK-SAME:       [%[[PID]], %[[C_0]]] [1, 128] [1, 1]\n CHECK:            tt.reduce\n CHECK-NEXT:       ^bb0(%[[ARG2:[^:]*]]: f32, %[[ARG3:[^:]*]]: f32):\n CHECK-NEXT:           %[[ADD:.*]] = arith.addf %[[ARG2]], %[[ARG3]] : f32\n CHECK-NEXT:           tt.reduce.return %[[ADD]] : f32\n CHECK-NEXT:       }) : (tensor<1x128xf32>) -> tensor<1xf32>\n CHECK:            arith.mulf\n CHECK-SAME:       tensor<1x128xf32>\n-CHECK:            triton_xla.insert {{.*}} [%[[PID_INDEX]], 0] [1, 128] [1, 1]\n+CHECK:            xtile.insert {{.*}}[%[[PID]], %[[C_0]]] [1, 128] [1, 1]\n CHECK:            return\n CHECK:        }\n )\"));\n@@ -1060,22 +1060,22 @@ ENTRY main {\n         \"num_stages\":\"1\"}}}})\";\n   TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText,\n                                           \"triton_softmax_computation\", R\"(\n-CHECK:         func.func @triton_fn(\n-CHECK-SAME:                      %[[P0:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n-CHECK-SAME:                      %[[P1:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n-CHECK-SAME:                      %[[P2:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n-CHECK-DAG:        %[[PID:.*]] = tt.get_program_id x : i32\n-CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_cast %[[PID]] : i32 to index\n-CHECK-DAG:        triton_xla.extract from %[[P0]] {{.*}} [%[[PID_INDEX]], 0] [1, 128] [1, 1] : tensor<1x128xf32>\n-CHECK-DAG:        triton_xla.extract from %[[P1]] {{.*}} [0] [128] [1] : tensor<128xf32>\n+CHECK:         xtile.entry_func @triton_fn(\n+CHECK-SAME:                      %[[P0:[A-Za-z0-9_]*]]: memref<125x127xf32>\n+CHECK-SAME:                      %[[P1:[A-Za-z0-9_]*]]: memref<127xf32>\n+CHECK-SAME:                      %[[P2:[A-Za-z0-9_]*]]: memref<125x127xf32>\n+CHECK-SAME:                      %[[TID:[A-Za-z0-9_]*]]: index)\n+CHECK-DAG:        %[[C_0:.*]] = arith.constant 0 : index\n+CHECK-DAG:        xtile.extract %[[P0]][%[[TID]], %[[C_0]]] [1, 128] [1, 1] : {{.*}} -> tensor<1x128xf32>\n+CHECK-DAG:        xtile.extract %[[P1]][%[[C_0]]] [128] [1] : {{.*}} -> tensor<128xf32>\n CHECK:            tt.reduce\n CHECK-NEXT:       ^bb0(%[[ARG3:[^:]*]]: f32, %[[ARG4:[^:]*]]: f32):\n CHECK-NEXT:           %[[ADD:.*]] = arith.addf %[[ARG3]], %[[ARG4]] : f32\n CHECK-NEXT:           tt.reduce.return %[[ADD]] : f32\n CHECK-NEXT:       }) : (tensor<1x128xf32>) -> tensor<1xf32>\n CHECK:            arith.mulf\n-CHECK-DAG:        triton_xla.insert {{.*}} into %[[P2]]\n-CHECK-SAME:       [%[[PID_INDEX]], 0] [1, 128] [1, 1] : tensor<1x128xf32>\n+CHECK-DAG:        xtile.insert {{.*}} into %[[P2]]\n+CHECK-SAME:       [%[[TID]], %[[C_0]]] [1, 128] [1, 1] : tensor<1x128xf32>\n )\"));\n }\n \n@@ -1123,21 +1123,20 @@ ENTRY main {\n                                           \"triton_softmax_computation\", R\"(\n CHECK:        #[[MAP:.*]] = #xla.indexing_map<\"(pid_0) -> (pid_0 floordiv 125), domain: pid_0 in [0, 1249]\">\n CHECK:        #[[MAP1:.*]] = #xla.indexing_map<\"(pid_0) -> (pid_0 mod 125), domain: pid_0 in [0, 1249]\">\n-CHECK:        func.func @triton_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}}, %[[P2:.*]]: {{.*}}, %[[P3:.*]]: {{.*}})\n-CHECK-DAG:        %[[PID:.*]] = tt.get_program_id x : i32\n-CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_cast %[[PID]] : i32 to index\n-CHECK-DAG:        %[[ROW_INDEX:.*]] = xla.apply_indexing #[[MAP]](%[[PID_INDEX]]\n-CHECK-DAG:        %[[COL_INDEX:.*]] = xla.apply_indexing #[[MAP1]](%[[PID_INDEX]]\n-CHECK:            triton_xla.extract from %[[P0]] {{.*}} [%[[ROW_INDEX]], %[[COL_INDEX]], 0] [1, 1, 128] [1, 1, 1] : tensor<1x1x128xf32>\n-CHECK:            triton_xla.extract from %[[P1]] {{.*}} [0] [128] [1] : tensor<128xf32>\n-CHECK:            triton_xla.extract from %[[P2]] {{.*}} [%[[ROW_INDEX]], %[[COL_INDEX]]] [1, 1] [1, 1] : tensor<1x1xf32>\n+CHECK:        xtile.entry_func @triton_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}}, %[[P2:.*]]: {{.*}}, %[[P3:.*]]: {{.*}}, %[[TID:.*]]: index)\n+CHECK-DAG:        %[[C_0:.*]] = arith.constant 0 : index\n+CHECK-DAG:        %[[ROW_INDEX:.*]] = xla.apply_indexing #[[MAP]](%[[TID]]\n+CHECK-DAG:        %[[COL_INDEX:.*]] = xla.apply_indexing #[[MAP1]](%[[TID]]\n+CHECK:            xtile.extract %[[P0]][%[[ROW_INDEX]], %[[COL_INDEX]], %[[C_0]]] [1, 1, 128] [1, 1, 1] : {{.*}} -> tensor<1x1x128xf32>\n+CHECK:            xtile.extract %[[P1]][%[[C_0]]] [128] [1] : {{.*}} -> tensor<128xf32>\n+CHECK:            xtile.extract %[[P2]][%[[ROW_INDEX]], %[[COL_INDEX]]] [1, 1] [1, 1] : {{.*}} -> tensor<1x1xf32>\n CHECK:            tt.reduce\n CHECK-NEXT:       ^bb0(%[[ARG4:[^:]*]]: f32, %[[ARG5:[^:]*]]: f32):\n CHECK-NEXT:           %[[MAX:.*]] = arith.maximumf %[[ARG4]], %[[ARG5]] : f32\n CHECK-NEXT:           tt.reduce.return %[[MAX]] : f32\n CHECK-NEXT:       }) : (tensor<1x1x128xf32>) -> tensor<1x1xf32>\n-CHECK:            triton_xla.insert {{.*}} into %[[P3]]\n-CHECK-SAME:       [%[[ROW_INDEX]], %[[COL_INDEX]], 0] [1, 1, 128] [1, 1, 1] : tensor<1x1x128xf32>\n+CHECK:            xtile.insert {{.*}} into %[[P3]]\n+CHECK-SAME:       [%[[ROW_INDEX]], %[[COL_INDEX]], %[[C_0]]] [1, 1, 128] [1, 1, 1] : tensor<1x1x128xf32>\n )\"));\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n@@ -1322,13 +1321,13 @@ ENTRY main {\n                                           \"triton_softmax_computation\", R\"(\n // CHECK:         #xla.indexing_map<\"(pid_0) -> (pid_0 floordiv 32), domain: pid_0 in [0, 2047]\">\n // CHECK:         #xla.indexing_map<\"(pid_0) -> (pid_0 mod 32), domain: pid_0 in [0, 2047]\">\n-// CHECK-LABEL:   func.func @triton_fn(\n-// CHECK-SAME:                       %[[P0:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n-// CHECK-SAME:                       %[[P1:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n-// CHECK-SAME:                       %[[P2:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n-// CHECK-DAG:       tt.load {{.*}} : !tt.ptr<f32>\n-// CHECK-DAG:       triton_xla.extract {{.*}} : tensor<1x1x16xf32>\n-// CHECK:           triton_xla.insert {{.*}} : tensor<1x1x16xf32>\n+// CHECK-LABEL:   xtile.entry_func @triton_fn(\n+// CHECK-SAME:                       %[[P0:[A-Za-z0-9_]*]]: memref<64x32x16xf32>\n+// CHECK-SAME:                       %[[P1:[A-Za-z0-9_]*]]: memref<f32>\n+// CHECK-SAME:                       %[[P2:[A-Za-z0-9_]*]]: memref<64x32x16xf32>\n+// CHECK-DAG:       xtile.extract {{.*}} -> tensor<f32>\n+// CHECK-DAG:       xtile.extract {{.*}} -> tensor<1x1x16xf32>\n+// CHECK:           xtile.insert {{.*}} : tensor<1x1x16xf32>\n )\"));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n@@ -1523,15 +1522,15 @@ ENTRY main {\n \n   TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText,\n                                           \"triton_reduction_computation\", R\"(\n-CHECK:        func.func @triton_fn(%[[P0:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n-CHECK-SAME:                      %[[P1:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n-CHECK-SAME:                      %[[P2:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n-CHECK-DAG:        triton_xla.extract {{.*}} : tensor<1xf32>\n-CHECK-DAG:        triton_xla.extract {{.*}} : tensor<1x128xf32>\n+CHECK:        xtile.entry_func @triton_fn(%[[P0:[A-Za-z0-9_]*]]: memref<125x127xf32>\n+CHECK-SAME:                               %[[P1:[A-Za-z0-9_]*]]: memref<125xf32>\n+CHECK-SAME:                               %[[P2:[A-Za-z0-9_]*]]: memref<125xf32>\n+CHECK-DAG:        xtile.extract {{.*}} -> tensor<1xf32>\n+CHECK-DAG:        xtile.extract {{.*}} -> tensor<1x128xf32>\n CHECK:            tt.reduce\n CHECK:              (tensor<1x128xf32>) -> tensor<1xf32>\n CHECK:            arith.mulf {{.*}} tensor<1xf32>\n-CHECK:            triton_xla.insert {{.*}} : tensor<1xf32>\n+CHECK:            xtile.insert {{.*}} : tensor<1xf32>\n )\"));\n }\n \n@@ -1849,8 +1848,8 @@ ENTRY main {\n // #xla.indexing_map<\"(pid_0) -> (pid_0 * 32), domain: pid_0 in [0, 1]\n \n // CHECK: xtile.entry_func @{{.*}}(\n-// CHECK-SAME: %[[IN:.*]]: memref<17xf32\n-// CHECK-SAME: %[[OUT:.*]]: memref<49xf32\n+// CHECK-SAME: %[[IN:.*]]: memref<17xf32>\n+// CHECK-SAME: %[[OUT:.*]]: memref<49xf32>\n \n // CHECK: %[[EXTRACT:.*]] = xtile.extract %[[IN]]{{.*}}\n // CHECK: %[[PAD_VALUE:.*]] = arith.constant 1.000000e+00 : f32\n@@ -1874,14 +1873,15 @@ ENTRY main {\n       this, xtile_module_and_hlo_module.first.get(), R\"(\n // #xla.indexing_map<\"(pid_0) -> (pid_0 * 32), domain: pid_0 in [0, 1]\n \n-// CHECK: func @{{.*}}(%[[IN:.*]]: !tt.ptr<f32>, %[[OUT:.*]]: !tt.ptr<f32>)\n+// CHECK: xtile.entry_func @{{.*}}(%[[IN:.*]]: memref<17xf32>\n+// CHECK-SAME:, %[[OUT:.*]]: memref<49xf32>\n \n // CHECK: %[[PAD_VALUE:.*]] = arith.constant dense<1.000000e+00> : tensor<32xf32>\n // CHECK: %[[C17:.*]] = arith.constant 17 : i32\n // CHECK: %[[TILE_OFFSET:.*]] = xla.apply_indexing\n-// CHECK: %[[EXTRACT:.*]] = triton_xla.extract from %[[IN]]\n+// CHECK: %[[EXTRACT:.*]] = xtile.extract %[[IN]]\n // CHECK-SAME: %[[TILE_OFFSET]]] [32] [1]\n-// CHECK-SAME:  : tensor<32xf32>\n+// CHECK-SAME:  -> tensor<32xf32>\n \n // CHECK: %[[IOTA:.*]] = tt.make_range {end = 32 : i32, start = 0 : i32}\n // CHECK: %[[TILE_OFFSET_I32:.*]] = arith.index_cast %[[TILE_OFFSET]]\n@@ -1890,7 +1890,7 @@ ENTRY main {\n // CHECK: %[[MASK:.*]] = arith.cmpi slt, %[[IOTA]], %[[THRESHOLD_SPLAT]]\n // CHECK: %[[SELECT:.*]] = arith.select %[[MASK]], %[[EXTRACT]], %[[PAD_VALUE]]\n \n-// CHECK:   triton_xla.insert %[[SELECT]] into %[[OUT]]\n+// CHECK:   xtile.insert %[[SELECT]] into %[[OUT]]\n // CHECK-SAME: [%[[TILE_OFFSET]]] [32] [1] : tensor<32xf32>\n   )\",\n       GetFusionInstruction(*xtile_module_and_hlo_module.second,\n@@ -1935,7 +1935,7 @@ ENTRY main {\n \n   TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n       this, xtile_module_and_hlo_module.first.get(), R\"(\n-// CHECK: triton_xla.extract {{.*}} : tensor<32x16xf32>\n+// CHECK: xtile.extract {{.*}} -> tensor<32x16xf32>\n // CHECK: tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>\n // CHECK: tt.expand_dims\n // CHECK: tt.broadcast\n@@ -2162,11 +2162,11 @@ CHECK:     xtile.insert\n \n   TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n       this, xtile_module_and_hlo_module.first.get(), R\"(\n-CHECK:     triton_xla.extract\n+CHECK:     xtile.extract\n CHECK-NOT: tt.trans\n CHECK:     tt.reshape\n CHECK-NOT: tt.trans\n-CHECK:     triton_xla.insert\n+CHECK:     xtile.insert\n   )\",\n       GetFusionInstruction(*xtile_module_and_hlo_module.second,\n                            \"triton_computation\")));\n@@ -2197,20 +2197,23 @@ ENTRY entry_computation {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto xtile_module_and_hlo_module,\n       CreateXTileIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n-CHECK:     xtile.extract\n-CHECK:     stablehlo.transpose\n-CHECK:     tt.reshape\n-CHECK-NOT: stablehlo.transpose\n-CHECK:     xtile.insert\n+CHECK:      xtile.entry_func @xtile_dialect_fn(\n+CHECK-SAME: memref<48x16xi32, #triton_xla.layout<[0, 1]>>\n+CHECK-SAME: memref<16x16x3xi32>,\n+CHECK:      xtile.extract\n+CHECK:      stablehlo.transpose\n+CHECK:      tt.reshape\n+CHECK-NOT:  stablehlo.transpose\n+CHECK:      xtile.insert\n           )\"));\n \n   TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n       this, xtile_module_and_hlo_module.first.get(), R\"(\n-CHECK:     triton_xla.extract\n+CHECK:     xtile.extract\n CHECK:     tt.trans\n CHECK:     tt.reshape\n CHECK-NOT: tt.trans\n-CHECK:     triton_xla.insert\n+CHECK:     xtile.insert\n   )\",\n       GetFusionInstruction(*xtile_module_and_hlo_module.second,\n                            \"triton_computation\")));\n@@ -2250,11 +2253,11 @@ CHECK:     xtile.insert\n \n   TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n       this, xtile_module_and_hlo_module.first.get(), R\"(\n-CHECK:     triton_xla.extract\n+CHECK:     xtile.extract\n CHECK-NOT: tt.trans\n CHECK:     tt.reshape\n CHECK:     tt.trans\n-CHECK:     triton_xla.insert\n+CHECK:     xtile.insert\n   )\",\n       GetFusionInstruction(*xtile_module_and_hlo_module.second,\n                            \"triton_computation\")));\n@@ -2295,11 +2298,11 @@ CHECK:     xtile.insert\n \n   TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n       this, xtile_module_and_hlo_module.first.get(), R\"(\n-CHECK:     triton_xla.extract\n+CHECK:     xtile.extract\n CHECK:     tt.trans\n CHECK:     tt.reshape\n CHECK:     tt.trans\n-CHECK:     triton_xla.insert\n+CHECK:     xtile.insert\n   )\",\n       GetFusionInstruction(*xtile_module_and_hlo_module.second,\n                            \"triton_computation\")));\n@@ -2339,11 +2342,11 @@ CHECK:     xtile.insert\n \n   TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n       this, xtile_module_and_hlo_module.first.get(), R\"(\n-CHECK:     triton_xla.extract\n+CHECK:     xtile.extract\n CHECK:     tt.trans\n CHECK-NOT: tt.reshape\n CHECK-NOT: tt.trans\n-CHECK:     triton_xla.insert\n+CHECK:     xtile.insert\n   )\",\n       GetFusionInstruction(*xtile_module_and_hlo_module.second,\n                            \"triton_computation\")));\n@@ -2387,10 +2390,10 @@ ENTRY main {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n-CHECK:     triton_xla.extract\n+CHECK:     xtile.extract\n CHECK:     tt.reduce\n CHECK:     tt.broadcast\n-CHECK:     triton_xla.insert\n+CHECK:     xtile.insert\n )\"));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n@@ -2460,7 +2463,7 @@ ENTRY main {\n       CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n CHECK:      %[[CASTED_OUT:.*]] = arith.extui\n CHECK-SAME:   tensor<4xi1> to tensor<4xi8>\n-CHECK:      triton_xla.insert %[[CASTED_OUT]]\n+CHECK:      xtile.insert %[[CASTED_OUT]]\n )\"));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n@@ -2499,7 +2502,7 @@ ENTRY main {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n-CHECK:      %[[I8_PARAM:.*]] = triton_xla.extract {{.*}} : tensor<4xi8>\n+CHECK:      %[[I8_PARAM:.*]] = xtile.extract {{.*}} -> tensor<4xi8>\n CHECK:      arith.trunci %[[I8_PARAM]] : tensor<4xi8> to tensor<4xi1>\n )\"));\n \n@@ -2537,7 +2540,7 @@ CHECK:      stablehlo.transpose %[[TILE]], dims = [2, 0, 1] : (tensor<8x4x1xf32>\n \n   TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n       this, xtile_module_and_hlo_module.first.get(), R\"(\n-CHECK:      %[[TILE:.*]] = triton_xla.extract {{.*}} : tensor<8x4x1xf32>\n+CHECK:      %[[TILE:.*]] = xtile.extract {{.*}} -> tensor<8x4x1xf32>\n CHECK:      tt.trans %[[TILE]] {order = array<i32: 2, 0, 1>} : tensor<8x4x1xf32> -> tensor<1x8x4xf32>\n   )\",\n       GetFusionInstruction(*xtile_module_and_hlo_module.second,\n@@ -2576,20 +2579,20 @@ ENTRY entry_computation {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto xtile_module_and_hlo_module,\n       CreateXTileIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n-CHECK:         %[[TILE:.*]] = triton_xla.extract {{.*}} : tensor<15x7x3xf32> to tensor<8x4x1xf32>\n-CHECK-NOT:     triton_xla.extract\n+CHECK:         %[[TILE:.*]] = xtile.extract {{.*}} -> tensor<15x7x3xf32> to tensor<8x4x1xf32>\n+CHECK-NOT:     xtile.extract\n CHECK:         %[[ABS:.*]] = math.absf %[[TILE]]\n CHECK:         stablehlo.transpose %[[ABS]], dims = [2, 0, 1] : (tensor<8x4x1xf32>) -> tensor<1x8x4xf32>\n-CHECK-COUNT-2: triton_xla.insert\n+CHECK-COUNT-2: xtile.insert\n           )\"));\n \n   TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n       this, xtile_module_and_hlo_module.first.get(), R\"(\n-CHECK:         %[[TILE:.*]] = triton_xla.extract {{.*}} : tensor<15x7x3xf32> to tensor<8x4x1xf32>\n-CHECK-NOT:     triton_xla.extract\n+CHECK:         %[[TILE:.*]] = xtile.extract {{.*}} -> tensor<15x7x3xf32> to tensor<8x4x1xf32>\n+CHECK-NOT:     xtile.extract\n CHECK:         %[[ABS:.*]] = math.absf %[[TILE]]\n CHECK:         tt.trans %[[ABS]] {order = array<i32: 2, 0, 1>} : tensor<8x4x1xf32> -> tensor<1x8x4xf32>\n-CHECK-COUNT-2: triton_xla.insert\n+CHECK-COUNT-2: xtile.insert\n   )\",\n       GetFusionInstruction(*xtile_module_and_hlo_module.second,\n                            \"fused_computation\")));\n@@ -2742,7 +2745,7 @@ ENTRY entry_computation {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n-CHECK:     triton_xla.extract\n+CHECK:     xtile.extract\n )\"));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n@@ -2780,18 +2783,18 @@ ENTRY entry_computation {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n-CHECK:     tt.load {{.*}} !tt.ptr<f32>\n+CHECK:     xtile.extract {{.*}} -> tensor<f32>\n CHECK:     tt.extern_elementwise {{.*}} (f32) -> f32\n CHECK:     arith.subf {{.*}} f32\n-CHECK:     tt.load {{.*}} !tt.ptr<f32>\n+CHECK:     xtile.extract {{.*}} -> tensor<f32>\n CHECK:     tt.extern_elementwise {{.*}} (f32) -> f32\n CHECK:     arith.subf {{.*}} f32\n CHECK:     arith.addf {{.*}} f32\n CHECK:     arith.mulf {{.*}} f32\n CHECK:     arith.divf {{.*}} f32\n CHECK:     arith.truncf {{.*}} f32 to bf16\n CHECK:     arith.subf {{.*}} bf16\n-CHECK:     tt.store {{.*}} !tt.ptr<bf16>\n+CHECK:     xtile.insert {{.*}} : tensor<bf16>\n )\"));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(\n@@ -2832,11 +2835,11 @@ ENTRY entry_computation {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n-CHECK:     tt.load\n+CHECK:     xtile.extract {{.*}} -> tensor<f32>\n CHECK:     tt.splat\n CHECK:     arith.addf\n CHECK:     tt.reduce\n-CHECK:     tt.store {{.*}} !tt.ptr<f32>\n+CHECK:     xtile.insert {{.*}} : tensor<f32>\n )\"));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(\n@@ -2872,7 +2875,7 @@ CHECK:     tt.reshape\n CHECK:     tt.reduce{{.*}}axis = 0\n CHECK-NOT: tt.reshape\n CHECK:     tt.reduce{{.*}}axis = 0\n-CHECK:     tt.store {{.*}} !tt.ptr<f32>\n+CHECK:     xtile.insert {{.*}} : tensor<f32>\n )\"));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n@@ -2912,11 +2915,11 @@ ENTRY entry_computation {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n-CHECK:     triton_xla.extract\n+CHECK:     xtile.extract\n CHECK:     tt.reshape\n CHECK:     tt.reduce\n CHECK:     tt.reduce\n-CHECK:     triton_xla.insert\n+CHECK:     xtile.insert\n )\"));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n@@ -3239,21 +3242,21 @@ ENTRY entry {\n   const bool is_tma_allowed = GetParam();\n   std::string hlo_text = absl::Substitute(kHloTextTemplate, is_tma_allowed);\n   TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, hlo_text, \"fdot\", R\"(\n-CHECK:      func.func @triton_fn(%[[ARG0:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n-CHECK-SAME:                    %[[ARG1:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n-CHECK-SAME:                    %[[ARG2:[A-Za-z0-9_]*]]: !tt.ptr<f32>)\n+CHECK:      xtile.entry_func @triton_fn(%[[ARG0:[A-Za-z0-9_]*]]: memref<32x123xf32>\n+CHECK-SAME:                             %[[ARG1:[A-Za-z0-9_]*]]: memref<123x512xf32>\n+CHECK-SAME:                             %[[ARG2:[A-Za-z0-9_]*]]: memref<32x512xf32>\n CHECK-DAG:  %[[C0:.*]] = arith.constant 0 : index\n CHECK-DAG:  %[[C4:.*]] = arith.constant 4 : index\n CHECK-DAG:  %[[C1:.*]] = arith.constant 1 : index\n CHECK:      {{.*}} = scf.for %{{.*}} = %[[C0]] to %[[C4]] step %[[C1]]\n CHECK-SAME: iter_args({{.*}}) -> (tensor<16x64xf32>) {\n-CHECK-DAG:  triton_xla.extract from %[[ARG0]]\n-CHECK-DAG:  triton_xla.extract from %[[ARG1]]\n+CHECK-DAG:  xtile.extract %[[ARG0]]\n+CHECK-DAG:  xtile.extract %[[ARG1]]\n CHECK-DAG:  arith.subf {{.*}} : tensor<16x32xf32>\n CHECK-DAG:  math.absf {{.*}} : tensor<32x64xf32>\n CHECK:      tt.dot {{.*}} tensor<16x32xf32> * tensor<32x64xf32> -> tensor<16x64xf32>\n CHECK:      scf.yield {{.*}} : tensor<16x64xf32>\n-CHECK-COUNT-1: triton_xla.insert\n+CHECK-COUNT-1: xtile.insert\n )\"));\n   EXPECT_TRUE(RunAndCompareNoHloPasses(\n       hlo_text, ErrorSpec{/*aabs=*/1e-4, /*arel=*/1e-6}));"
        },
        {
            "sha": "d12c57a65585df56791bc8e3b14bb30f4003f207",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_convert_unsupported_types.mlir",
            "status": "modified",
            "additions": 23,
            "deletions": 12,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_unsupported_types.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_unsupported_types.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_unsupported_types.mlir?ref=bd257617f73c6b5c17555e0c8995ea5bfd4fc30e",
            "patch": "@@ -1,20 +1,31 @@\n // RUN: xla-opt --convert-unsupported-types %s | FileCheck %s\n \n module {\n-  // CHECK:   func.func @triton_fn(%arg0: !tt.ptr<f8E4M3FN>, %arg1: !tt.ptr<i8>, %arg2: !tt.ptr<f8E4M3FN>, %arg3: !tt.ptr<i8>, %arg4: !tt.ptr<f32>) {\n-  func.func @triton_fn(%arg0: !tt.ptr<f8E4M3FN>, %arg1: !tt.ptr<f8E8M0FNU>, %arg2: !tt.ptr<f8E4M3FN>, %arg3: !tt.ptr<f8E8M0FNU>, %arg4: !tt.ptr<f32>) {\n+  // CHECK:   xtile.entry_func @triton_fn(\n+  // CHECK-SAME:   %arg0: memref<64x512xf8E4M3FN, #triton_xla.layout<[1, 0]>>,\n+  // CHECK-SAME:   %arg1: memref<64x16xi8, #triton_xla.layout<[1, 0]>>,\n+  // CHECK-SAME:   %arg2: memref<512x64xf8E4M3FN, #triton_xla.layout<[1, 0]>>,\n+  // CHECK-SAME:   %arg3: memref<16x64xi8, #triton_xla.layout<[1, 0]>>,\n+  xtile.entry_func @triton_fn(\n+      %arg0: memref<64x512xf8E4M3FN, #triton_xla.layout<[1, 0]>>,\n+      %arg1: memref<64x16xf8E8M0FNU, #triton_xla.layout<[1, 0]>>,\n+      %arg2: memref<512x64xf8E4M3FN, #triton_xla.layout<[1, 0]>>,\n+      %arg3: memref<16x64xf8E8M0FNU, #triton_xla.layout<[1, 0]>>,\n+      %tile_id: index) {\n+    // CHECK-DAG: %[[C_0:.*]] = arith.constant 0 : index\n+    %c_0 = arith.constant 0 : index\n     %cst = arith.constant dense<0.000000e+00> : tensor<16x16xf32>\n-    %extracted_tile = triton_xla.extract from %arg0 as memref<64x512xf8E4M3FN, #triton_xla.layout<[1, 0]>> [0, 0] [16, 32] [1, 1] : tensor<16x32xf8E4M3FN>\n-    // CHECK: %[[arg_0:.*]] = triton_xla.extract from %arg0 as memref<64x512xf8E4M3FN, #triton_xla.layout<[1, 0]>> [0, 0] [16, 32] [1, 1] : tensor<16x32xf8E4M3FN>\n-    %extracted_tile_0 = triton_xla.extract from %arg1 as memref<64x16xf8E8M0FNU, #triton_xla.layout<[1, 0]>> [0, 0] [16, 1] [1, 1] : tensor<16x1xf8E8M0FNU>\n-    // CHECK: %[[arg_1:.*]] = triton_xla.extract from %arg1 as memref<64x16xi8, #triton_xla.layout<[1, 0]>> [0, 0] [16, 1] [1, 1] : tensor<16x1xi8>\n-    %extracted_tile_1 = triton_xla.extract from %arg2 as memref<512x64xf8E4M3FN, #triton_xla.layout<[1, 0]>> [0, 0] [32, 16] [1, 1] : tensor<32x16xf8E4M3FN>\n-    // CHECK: %[[arg_2:.*]] = triton_xla.extract from %arg2 as memref<512x64xf8E4M3FN, #triton_xla.layout<[1, 0]>> [0, 0] [32, 16] [1, 1] : tensor<32x16xf8E4M3FN>\n-    %extracted_tile_2 = triton_xla.extract from %arg3 as memref<16x64xf8E8M0FNU, #triton_xla.layout<[1, 0]>> [0, 0] [1, 16] [1, 1] : tensor<1x16xf8E8M0FNU>\n-    // CHECK: %[[arg_3:.*]] = triton_xla.extract from %arg3 as memref<16x64xi8, #triton_xla.layout<[1, 0]>> [0, 0] [1, 16] [1, 1] : tensor<1x16xi8>\n+    %extracted_tile = xtile.extract %arg0[%c_0, %c_0] [16, 32] [1, 1] : memref<64x512xf8E4M3FN, #triton_xla.layout<[1, 0]>> -> tensor<16x32xf8E4M3FN>\n+    // CHECK: %[[arg_0:.*]] = xtile.extract %arg0[%[[C_0]], %[[C_0]]] [16, 32] [1, 1] : memref<64x512xf8E4M3FN, #triton_xla.layout<[1, 0]>> -> tensor<16x32xf8E4M3FN>\n+    %extracted_tile_0 = xtile.extract %arg1[%c_0, %c_0] [16, 1] [1, 1] : memref<64x16xf8E8M0FNU, #triton_xla.layout<[1, 0]>> -> tensor<16x1xf8E8M0FNU>\n+    // CHECK: %[[arg_1:.*]] = xtile.extract %arg1[%[[C_0]], %[[C_0]]] [16, 1] [1, 1] : memref<64x16xi8, #triton_xla.layout<[1, 0]>> -> tensor<16x1xi8>\n+    %extracted_tile_1 = xtile.extract %arg2[%c_0, %c_0] [32, 16] [1, 1] : memref<512x64xf8E4M3FN, #triton_xla.layout<[1, 0]>> -> tensor<32x16xf8E4M3FN>\n+    // CHECK: %[[arg_2:.*]] = xtile.extract %arg2[%[[C_0]], %[[C_0]]] [32, 16] [1, 1] : memref<512x64xf8E4M3FN, #triton_xla.layout<[1, 0]>> -> tensor<32x16xf8E4M3FN>\n+    %extracted_tile_2 = xtile.extract %arg3[%c_0, %c_0] [1, 16] [1, 1] : memref<16x64xf8E8M0FNU, #triton_xla.layout<[1, 0]>> -> tensor<1x16xf8E8M0FNU>\n+    // CHECK: %[[arg_3:.*]] = xtile.extract %arg3[%[[C_0]], %[[C_0]]] [1, 16] [1, 1] : memref<16x64xi8, #triton_xla.layout<[1, 0]>> -> tensor<1x16xi8>\n     %16 = arith.bitcast %extracted_tile_0 : tensor<16x1xf8E8M0FNU> to tensor<16x1xi8>\n     %17 = arith.bitcast %extracted_tile_2 : tensor<1x16xf8E8M0FNU> to tensor<1x16xi8>\n     %18 = tt.dot_scaled %extracted_tile scale %16, %extracted_tile_1 scale %17, %cst lhs = e4m3 rhs = e4m3 {fastMath = true} : tensor<16x32xf8E4M3FN>, tensor<16x1xi8> * tensor<32x16xf8E4M3FN>, tensor<1x16xi8> -> tensor<16x16xf32>\n-    return\n+    xtile.return\n   }\n-}\n\\ No newline at end of file\n+}"
        },
        {
            "sha": "6fcb5f53ea2ebf725ae5492b723e43bbb2b47230",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_convert_unsupported_types.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 8,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_unsupported_types.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd257617f73c6b5c17555e0c8995ea5bfd4fc30e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_unsupported_types.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_unsupported_types.cc?ref=bd257617f73c6b5c17555e0c8995ea5bfd4fc30e",
            "patch": "@@ -27,6 +27,7 @@ limitations under the License.\n #include \"mlir/Support/LogicalResult.h\"\n #include \"mlir/Transforms/DialectConversion.h\"\n #include \"xla/backends/gpu/codegen/triton/ir/triton_xla_ops.h\"\n+#include \"xla/codegen/xtile/ir/xtile_ops.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n #include \"triton/Dialect/Triton/IR/Types.h\"\n \n@@ -87,22 +88,23 @@ class TritonXLAConvertUnsupportedTypesPass\n \n     auto* ctx = &getContext();\n     ConversionTarget target(*ctx);\n-    target.addDynamicallyLegalOp<func::FuncOp>([&](func::FuncOp op) {\n-      return converter.isSignatureLegal(op.getFunctionType()) &&\n-             converter.isLegal(&op.getBody());\n-    });\n+    target.addDynamicallyLegalOp<::xla::xtile::EntryFuncOp>(\n+        [&](::xla::xtile::EntryFuncOp op) {\n+          return converter.isSignatureLegal(op.getFunctionType()) &&\n+                 converter.isLegal(&op.getBody());\n+        });\n     target.markUnknownOpDynamicallyLegal(\n         [&](Operation* op) { return converter.isLegal(op); });\n \n     RewritePatternSet patterns(ctx);\n-    patterns.add<GenericOpConversionPattern<ExtractOp>,\n-                 GenericOpConversionPattern<InsertOp>,\n+    patterns.add<GenericOpConversionPattern<::xla::xtile::ExtractTileOp>,\n+                 GenericOpConversionPattern<::xla::xtile::InsertTileOp>,\n                  GenericOpConversionPattern<ReshapeOp>,\n                  GenericOpConversionPattern<TransOp>,\n                  GenericOpConversionPattern<arith::BitcastOp>>(converter, ctx);\n     scf::populateSCFStructuralTypeConversions(converter, patterns);\n-    populateFunctionOpInterfaceTypeConversionPattern<func::FuncOp>(patterns,\n-                                                                   converter);\n+    populateFunctionOpInterfaceTypeConversionPattern<::xla::xtile::EntryFuncOp>(\n+        patterns, converter);\n     if (failed(applyPartialConversion(getOperation(), target,\n                                       std::move(patterns)))) {\n       return signalPassFailure();"
        }
    ],
    "stats": {
        "total": 298,
        "additions": 169,
        "deletions": 129
    }
}