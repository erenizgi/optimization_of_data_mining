{
    "author": "GleasonK",
    "message": "[PJRT] Add PJRT Reproducers to XLA:GPU\n\nDump PJRT reproducers (StableHLO+CompileOptions+Topology) using `xla_dump_to` option.\n\nPiperOrigin-RevId: 799613399",
    "sha": "32dace53e116970322474128dfaa08b9183dbdc5",
    "files": [
        {
            "sha": "8de507a46188c4ac2b1144d0ec212450023a9dd5",
            "filename": "third_party/xla/xla/pjrt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD?ref=32dace53e116970322474128dfaa08b9183dbdc5",
            "patch": "@@ -634,6 +634,7 @@ cc_library(\n         \"//xla/hlo/builder:xla_computation\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/pjrt/distributed:protocol_proto_cc\",\n+        \"//xla/pjrt/dump\",\n         \"//xla/pjrt/profiling:device_time_measurement\",\n         \"//xla/pjrt/profiling:profiling_context\",\n         \"//xla/service:buffer_assignment\","
        },
        {
            "sha": "2215d0a4d60e3c305f99936bd5b8636caf9e95b0",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 13,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc?ref=32dace53e116970322474128dfaa08b9183dbdc5",
            "patch": "@@ -590,19 +590,7 @@ static absl::StatusOr<std::unique_ptr<xla::Executable>> CompileAheadOfTime(\n \n absl::StatusOr<std::unique_ptr<PjRtLoadedExecutable>>\n PjRtCpuClient::CompileAndLoad(mlir::ModuleOp module, CompileOptions options) {\n-  // Dump compile inputs to the specified path if populated.\n-  if (options.executable_build_options.has_debug_options()) {\n-    std::string dump_path =\n-        options.executable_build_options.debug_options().xla_dump_to();\n-    if (!dump_path.empty()) {\n-      LOG(INFO) << \"Dumping compile inputs to \" << dump_path;\n-      auto dump_status =\n-          pjrt::DumpCompileInputs(dump_path, options, module, topology_);\n-      if (!dump_status.ok()) {\n-        LOG(WARNING) << \"Failed to dump compile inputs: \" << dump_status;\n-      }\n-    }\n-  }\n+  TF_RETURN_IF_ERROR(pjrt::MaybeDumpCompileInputs(options, module, topology_));\n \n   XlaComputation xla_computation;\n   ExecutableBuildOptions& exec_build_options = options.executable_build_options;"
        },
        {
            "sha": "53fa62c1630539f848e7e077ac5c6d9c298338d7",
            "filename": "third_party/xla/xla/pjrt/dump/dump.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.cc?ref=32dace53e116970322474128dfaa08b9183dbdc5",
            "patch": "@@ -102,4 +102,31 @@ absl::Status DumpCompileInputs(absl::string_view dump_to_path,\n   return absl::OkStatus();\n }\n \n+absl::Status MaybeDumpCompileInputs(\n+    xla::CompileOptions compile_options, mlir::ModuleOp module,\n+    const xla::PjRtTopologyDescription& topology) {\n+  LOG(INFO) << \"[MaybeDumpCompileInputs] Dumping PJRT inputs for module: \"\n+            << module.getName().value_or(\"unknown_module\").str();\n+\n+  // Dump compile inputs to the specified path if populated.\n+  const auto& executable_build_options =\n+      compile_options.executable_build_options;\n+  if (!executable_build_options.has_debug_options()) {\n+    LOG(INFO) << \"  Debug options not set, skipping dump.\";\n+    return absl::OkStatus();\n+  }\n+  std::string dump_path(executable_build_options.debug_options().xla_dump_to());\n+  if (dump_path.empty()) {\n+    LOG(INFO) << \"  Dump path not set via xla_dump_to, skipping dump.\";\n+    return absl::OkStatus();\n+  }\n+  LOG(INFO) << \"  Dumping compile inputs to \" << dump_path;\n+  auto dump_status =\n+      pjrt::DumpCompileInputs(dump_path, compile_options, module, topology);\n+  if (!dump_status.ok()) {\n+    LOG(WARNING) << \"  Failed to dump compile inputs: \" << dump_status;\n+  }\n+  return absl::OkStatus();\n+}\n+\n }  // namespace pjrt"
        },
        {
            "sha": "2080c314a8b5357686132645a36d85d47a6f539a",
            "filename": "third_party/xla/xla/pjrt/dump/dump.h",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.h?ref=32dace53e116970322474128dfaa08b9183dbdc5",
            "patch": "@@ -42,6 +42,14 @@ absl::Status DumpCompileInputs(absl::string_view path,\n                                mlir::ModuleOp module,\n                                const xla::PjRtTopologyDescription& topology);\n \n+// Dumps the compile inputs (module, options, topology) to the specified\n+// path if the compile options specify a dump path via `xla_dump_to`.\n+//\n+// Does nothing if the compile options does not set `xla_dump_to`.\n+absl::Status MaybeDumpCompileInputs(\n+    xla::CompileOptions compile_options, mlir::ModuleOp module,\n+    const xla::PjRtTopologyDescription& topology);\n+\n }  // namespace pjrt\n \n #endif  // XLA_PJRT_DUMP_DUMP_H_"
        },
        {
            "sha": "52936b2fee047da240e08448d3f5747cc1c7c5eb",
            "filename": "third_party/xla/xla/pjrt/dump/dump_test.cc",
            "status": "modified",
            "additions": 61,
            "deletions": 0,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump_test.cc?ref=32dace53e116970322474128dfaa08b9183dbdc5",
            "patch": "@@ -158,4 +158,65 @@ TEST(DumpTest, DumpCompileInputs) {\n                                             HasSubstr(\"topology.pb\")));\n }\n \n+TEST(MaybeDumpCompileInputsTest, XlaDumpToNotSet) {\n+  const std::string temp_test_dir = tsl::testing::TmpDir();\n+  const std::string temp_test_subdir =\n+      tsl::io::JoinPath(temp_test_dir, \"compile_maybe_dump_test\",\n+                        absl::StrCat(absl::ToUnixMillis(absl::Now())));\n+  TF_ASSERT_OK(tsl::Env::Default()->RecursivelyCreateDir(temp_test_subdir));\n+  xla::CompileOptions compile_options;\n+  mlir::MLIRContext context;\n+  mlir::OpBuilder builder(&context);\n+  mlir::OwningOpRef<mlir::ModuleOp> module =\n+      builder.create<mlir::ModuleOp>(builder.getUnknownLoc());\n+  auto topology = std::make_unique<TestTopology>();\n+\n+  // xla_dump_to not set\n+  TF_ASSERT_OK(\n+      pjrt::MaybeDumpCompileInputs(compile_options, *module, *topology.get()));\n+\n+  std::vector<std::string> no_files;\n+  TF_ASSERT_OK(tsl::Env::Default()->GetMatchingPaths(\n+      tsl::io::JoinPath(temp_test_subdir, \"*\"), &no_files));\n+\n+  ASSERT_EQ(no_files.size(), 0);\n+}\n+\n+TEST(MaybeDumpCompileInputsTest, XlaDumpToSet) {\n+  const std::string temp_test_dir = tsl::testing::TmpDir();\n+  const std::string temp_test_subdir =\n+      tsl::io::JoinPath(temp_test_dir, \"compile_maybe_dump_test\",\n+                        absl::StrCat(absl::ToUnixMillis(absl::Now())));\n+  TF_ASSERT_OK(tsl::Env::Default()->RecursivelyCreateDir(temp_test_subdir));\n+  xla::CompileOptions compile_options;\n+  mlir::MLIRContext context;\n+  mlir::OpBuilder builder(&context);\n+  mlir::OwningOpRef<mlir::ModuleOp> module =\n+      builder.create<mlir::ModuleOp>(builder.getUnknownLoc());\n+  auto topology = std::make_unique<TestTopology>();\n+\n+  // Set xla_dump_to and dump compile inputs.\n+  compile_options.executable_build_options.mutable_debug_options()\n+      ->set_xla_dump_to(temp_test_subdir);\n+\n+  TF_ASSERT_OK(\n+      pjrt::MaybeDumpCompileInputs(compile_options, *module, *topology.get()));\n+  std::vector<std::string> files;\n+  TF_ASSERT_OK(tsl::Env::Default()->GetMatchingPaths(\n+      tsl::io::JoinPath(temp_test_subdir, \"*\"), &files));\n+\n+  ASSERT_EQ(files.size(), 1);\n+  std::string dump_subdir = files[0];\n+  EXPECT_THAT(tsl::Env::Default()->IsDirectory(dump_subdir), IsOk());\n+\n+  std::vector<std::string> dump_files;\n+  TF_ASSERT_OK(tsl::Env::Default()->GetMatchingPaths(\n+      tsl::io::JoinPath(dump_subdir, \"*\"), &dump_files));\n+  EXPECT_EQ(dump_files.size(), 3);\n+  EXPECT_THAT(dump_files,\n+              testing::UnorderedElementsAre(HasSubstr(\"module.mlir\"),\n+                                            HasSubstr(\"compile_options.pb\"),\n+                                            HasSubstr(\"topology.pb\")));\n+}\n+\n }  // namespace"
        },
        {
            "sha": "891eb5fec501284cbef71a18b1da596728df9c41",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2FBUILD?ref=32dace53e116970322474128dfaa08b9183dbdc5",
            "patch": "@@ -75,6 +75,7 @@ cc_library(\n         \"//xla/pjrt/distributed:key_value_store_interface\",\n         \"//xla/pjrt/distributed:protocol_proto_cc\",\n         \"//xla/pjrt/distributed:topology_util\",\n+        \"//xla/pjrt/dump\",\n         \"//xla/pjrt/gpu:gpu_helpers\",\n         \"//xla/pjrt/gpu:gpu_topology\",\n         \"//xla/pjrt/gpu:gpu_topology_proto_cc\","
        },
        {
            "sha": "06559facb289cda37b06b452527015c37532d01e",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_client.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc?ref=32dace53e116970322474128dfaa08b9183dbdc5",
            "patch": "@@ -58,6 +58,7 @@ limitations under the License.\n #include \"xla/pjrt/distributed/in_memory_key_value_store.h\"\n #include \"xla/pjrt/distributed/key_value_store_interface.h\"\n #include \"xla/pjrt/distributed/protocol.pb.h\"\n+#include \"xla/pjrt/dump/dump.h\"\n #include \"xla/pjrt/gpu/gpu_helpers.h\"\n #include \"xla/pjrt/gpu/gpu_topology.h\"\n #include \"xla/pjrt/gpu/gpu_topology.pb.h\"\n@@ -330,6 +331,7 @@ absl::StatusOr<std::unique_ptr<PjRtExecutable>> TfrtGpuClient::CompileInternal(\n \n absl::StatusOr<std::unique_ptr<PjRtExecutable>> TfrtGpuClient::Compile(\n     mlir::ModuleOp module, CompileOptions options) {\n+  TF_RETURN_IF_ERROR(pjrt::MaybeDumpCompileInputs(options, module, topology_));\n   return Compile(module, options, /*lookup_addressable_devices=*/false);\n }\n "
        },
        {
            "sha": "9c6991b797f0ee1b2f5f4ea4457a578ea5af1fc6",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32dace53e116970322474128dfaa08b9183dbdc5/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=32dace53e116970322474128dfaa08b9183dbdc5",
            "patch": "@@ -109,6 +109,7 @@ limitations under the License.\n #include \"xla/pjrt/abstract_tracked_device_buffer.h\"\n #include \"xla/pjrt/device_event.h\"\n #include \"xla/pjrt/distributed/protocol.pb.h\"\n+#include \"xla/pjrt/dump/dump.h\"\n #include \"xla/pjrt/event_pool.h\"\n #include \"xla/pjrt/host_callback.h\"\n #include \"xla/pjrt/host_memory_spaces.h\"\n@@ -3883,6 +3884,10 @@ PjRtStreamExecutorClient::Compile(mlir::ModuleOp module,\n absl::StatusOr<std::unique_ptr<PjRtExecutable>>\n PjRtStreamExecutorClient::Compile(mlir::ModuleOp module, CompileOptions options,\n                                   bool lookup_addressable_devices) {\n+  TF_ASSIGN_OR_RETURN(const PjRtTopologyDescription* topology,\n+                      GetTopologyDescription());\n+  TF_RETURN_IF_ERROR(pjrt::MaybeDumpCompileInputs(options, module, *topology));\n+\n   XlaComputation xla_computation;\n   ExecutableBuildOptions& exec_build_options = options.executable_build_options;\n   TF_RETURN_IF_ERROR(MlirToXlaComputation("
        }
    ],
    "stats": {
        "total": 119,
        "additions": 106,
        "deletions": 13
    }
}