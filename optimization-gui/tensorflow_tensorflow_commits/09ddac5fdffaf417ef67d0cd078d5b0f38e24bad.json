{
    "author": "dimvar",
    "message": "PR #32187: PTX version 9.0 is supported starting with CUDA 13.0.\n\nImported from GitHub PR https://github.com/openxla/xla/pull/32187\n\nhttps://docs.nvidia.com/cuda/parallel-thread-execution/#release-notes\n\nAlso a slight refactoring of the code.\n\nCopybara import of the project:\n\n--\nf579d2285563d6b93502f1f2a1dfc9731102eef6 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:\n\nPTX version 9.0 is supported starting with CUDA 13.0.\nhttps://docs.nvidia.com/cuda/parallel-thread-execution/#release-notes\n\n--\nf585ea4a5470b72835d6ae6b7def54866c4145e5 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:\n\nFix typo\n\nMerging this change closes #32187\n\nPiperOrigin-RevId: 817233170",
    "sha": "09ddac5fdffaf417ef67d0cd078d5b0f38e24bad",
    "files": [
        {
            "sha": "dafd36d3f33af344cd36c158c5c420dbd322cefe",
            "filename": "third_party/xla/xla/service/gpu/llvm_gpu_backend/ptx_version_util.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 14,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09ddac5fdffaf417ef67d0cd078d5b0f38e24bad/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fptx_version_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09ddac5fdffaf417ef67d0cd078d5b0f38e24bad/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fptx_version_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fptx_version_util.cc?ref=09ddac5fdffaf417ef67d0cd078d5b0f38e24bad",
            "patch": "@@ -19,7 +19,7 @@ namespace xla::gpu::nvptx {\n \n namespace {\n constexpr stream_executor::SemanticVersion kFallbackPtxVersion{6, 5, 0};\n-constexpr stream_executor::SemanticVersion kMaxPtxVersion{8, 8, 0};\n+constexpr stream_executor::SemanticVersion kMaxPtxVersion{9, 0, 0};\n }  // namespace\n \n stream_executor::SemanticVersion\n@@ -33,20 +33,18 @@ DetermineHighestSupportedPtxVersionFromCudaVersion(\n \n   // Mapping determined from\n   // https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#release-notes\n-  // Examples:\n-  // CUDA 11.0 -> PTX 7.0\n-  // CUDA 11.1 -> PTX 7.1\n-  // CUDA 12.0 -> PTX 8.0\n-  // CUDA 12.4 -> PTX 8.4\n-  // This versioning scheme is valid until CUDA 12.6\n-  if (cuda_version < stream_executor::SemanticVersion{12, 6, 0}) {\n-    return {cuda_version.major() - 4, cuda_version.minor(), 0};\n-  }\n-  // CUDA 12.6 -> PTX 8.5\n-  // CUDA 12.8 -> PTX 8.7\n-  // CUDA 12.9 -> PTX 8.8\n-  if (cuda_version < stream_executor::SemanticVersion{12, 10, 0}) {\n+  if (cuda_version >= stream_executor::SemanticVersion{12, 6, 0} &&\n+      cuda_version < stream_executor::SemanticVersion{12, 10, 0}) {\n+    // Examples:\n+    // CUDA 12.6 -> PTX 8.5\n+    // CUDA 12.9 -> PTX 8.8\n     return {cuda_version.major() - 4, cuda_version.minor() - 1, 0};\n+  } else if (cuda_version <= stream_executor::SemanticVersion{13, 0, 0}) {\n+    // Examples:\n+    // CUDA 11.0 -> PTX 7.0\n+    // CUDA 12.4 -> PTX 8.4\n+    // CUDA 13.0 -> PTX 9.0\n+    return {cuda_version.major() - 4, cuda_version.minor(), 0};\n   }\n \n   // Return maximum known PTX version."
        }
    ],
    "stats": {
        "total": 26,
        "additions": 12,
        "deletions": 14
    }
}