{
    "author": "pschuh",
    "message": "Generalize and move CreateOutputs to CommonPjRtClient.\n\nPiperOrigin-RevId: 839954379",
    "sha": "65b9003e858c543d8fa0037dd293d5180550fe61",
    "files": [
        {
            "sha": "e737e773ff85f66df63a134bf3c8d760aba9a497",
            "filename": "third_party/xla/xla/pjrt/common_pjrt_client.cc",
            "status": "modified",
            "additions": 65,
            "deletions": 0,
            "changes": 65,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/65b9003e858c543d8fa0037dd293d5180550fe61/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/65b9003e858c543d8fa0037dd293d5180550fe61/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc?ref=65b9003e858c543d8fa0037dd293d5180550fe61",
            "patch": "@@ -546,6 +546,71 @@ CommonPjRtClient::AllocateOutputBuffersWithInputReuse(\n   return std::move(buffers);\n }\n \n+static std::unique_ptr<PjRtBuffer> CreateOutputLeafBuffer(\n+    const Shape& output_leaf_shape,\n+    tsl::RCReference<PjRtDeviceEvent> definition_event,\n+    bool is_predetermined_error, CommonPjRtClient* client, PjRtDevice* device,\n+    tsl::RCReference<CommonPjRtRawBuffer> leaf_buffer, int kind_id) {\n+  PjRtMemorySpace* memory_space = nullptr;\n+  if (leaf_buffer) {\n+    memory_space = leaf_buffer->memory_space();\n+  } else {\n+    for (PjRtMemorySpace* ms : device->memory_spaces()) {\n+      if (kind_id == ms->kind_id()) {\n+        memory_space = ms;\n+        break;\n+      }\n+    }\n+    CHECK(memory_space) << \"No memory space found for device: \"\n+                        << device->DebugString() << \" kind: \" << kind_id;\n+  }\n+  auto buffer_or = client->DefineBuffer(\n+      output_leaf_shape, memory_space, std::move(leaf_buffer),\n+      {definition_event}, /*raw_buffer_is_mutable=*/true);\n+  CHECK_OK(buffer_or);\n+  return *std::move(buffer_or);\n+}\n+\n+std::vector<std::unique_ptr<PjRtBuffer>> CommonPjRtClient::CreateOutputs(\n+    const Shape& output_device_shape,\n+    tsl::RCReference<PjRtDeviceEvent> definition_event, PjRtDevice* device,\n+    absl::Span<const int> output_memory_space_kind_ids,\n+    absl::InlinedVector<tsl::RCReference<CommonPjRtRawBuffer>, 4>\n+        output_leaf_buffers,\n+    bool is_predetermined_error) {\n+  tsl::profiler::TraceMe t1(\"CommonPjRtClient::CreateOutputs\");\n+  std::vector<std::unique_ptr<PjRtBuffer>> res;\n+  absl::Span<const Shape> output_leaf_shapes =\n+      output_device_shape.IsTuple()\n+          ? absl::MakeSpan(output_device_shape.tuple_shapes())\n+          : absl::MakeSpan(&output_device_shape, 1);\n+  auto get_buffer = [&](int i) {\n+    return i < output_leaf_buffers.size()\n+               ? std::move(output_leaf_buffers[i])\n+               : tsl::RCReference<CommonPjRtRawBuffer>();\n+  };\n+  if (output_device_shape.IsTuple()) {\n+    res.reserve(output_leaf_shapes.size());\n+    for (int i = 0; i < output_leaf_shapes.size(); ++i) {\n+      res.push_back(CreateOutputLeafBuffer(\n+          output_leaf_shapes[i], definition_event, is_predetermined_error, this,\n+          device, get_buffer(i), output_memory_space_kind_ids[i]));\n+    }\n+  } else if (!output_device_shape.IsTuple() &&\n+             output_leaf_buffers.size() == 1) {\n+    res.push_back(CreateOutputLeafBuffer(\n+        output_leaf_shapes[0], definition_event, is_predetermined_error, this,\n+        device, get_buffer(0), output_memory_space_kind_ids[0]));\n+  } else {\n+    CHECK(is_predetermined_error)\n+        << \"Nontuple results must have a single result buffer.\";\n+    res.push_back(CreateOutputLeafBuffer(output_device_shape, definition_event,\n+                                         is_predetermined_error, this, device,\n+                                         {}, output_memory_space_kind_ids[0]));\n+  }\n+  return res;\n+}\n+\n absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n CommonPjRtBufferImpl::CopyToCpuMemorySpace(const xla::Shape& dst_shape,\n                                            PjRtMemorySpace* dst_memory_space) {"
        },
        {
            "sha": "43cc61bc0246963d8ab690d3fa135c40a039f6c6",
            "filename": "third_party/xla/xla/pjrt/common_pjrt_client.h",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/65b9003e858c543d8fa0037dd293d5180550fe61/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/65b9003e858c543d8fa0037dd293d5180550fe61/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h?ref=65b9003e858c543d8fa0037dd293d5180550fe61",
            "patch": "@@ -242,6 +242,14 @@ class CommonPjRtClient : public PjRtClient {\n       absl::Span<const CommonPjRtBuffer::ScopedHold> input_device_buffer_holds,\n       const HloInputOutputAliasConfig& alias_config, PjRtDevice* device,\n       absl::Span<const int> output_memory_space_kind_ids);\n+\n+  std::vector<std::unique_ptr<PjRtBuffer>> CreateOutputs(\n+      const Shape& output_device_shape,\n+      tsl::RCReference<PjRtDeviceEvent> definition_event, PjRtDevice* device,\n+      absl::Span<const int> output_memory_space_kind_ids,\n+      absl::InlinedVector<tsl::RCReference<CommonPjRtRawBuffer>, 4>\n+          output_leaf_buffers,\n+      bool is_predetermined_error);\n };\n \n // TODO(parkers): Merge everything here into CommonPjRtBuffer."
        }
    ],
    "stats": {
        "total": 73,
        "additions": 73,
        "deletions": 0
    }
}