{
    "author": "ezhulenev",
    "message": "[stream_executor] Create NCCL memory allocator for collective memory on CUDA\n\nIt is a layering violation to depend from SE to XLA:GPU collectives. All memory allocations should be done via correct se::MemoryAllocator instances. Prepare for removing memory allocation APIs from GPU collectives.\n\nPiperOrigin-RevId: 843544612",
    "sha": "91b16be2f078084c9657aba0aa8c6ec332ea5387",
    "files": [
        {
            "sha": "dbc9b40220d4f9d68c9dda038ee4bcb954acf7b1",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 26,
            "deletions": 0,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/91b16be2f078084c9657aba0aa8c6ec332ea5387/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/91b16be2f078084c9657aba0aa8c6ec332ea5387/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=91b16be2f078084c9657aba0aa8c6ec332ea5387",
            "patch": "@@ -928,6 +928,32 @@ xla_cc_test(\n     ],\n )\n \n+cc_library(\n+    name = \"nccl_memory_allocator\",\n+    srcs = [\"nccl_memory_allocator.cc\"],\n+    hdrs = [\"nccl_memory_allocator.h\"],\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+    ],\n+    deps = [\n+        \"//xla:util\",\n+        \"//xla/stream_executor:activate_context\",\n+        \"//xla/stream_executor:device_address\",\n+        \"//xla/stream_executor:memory_allocation\",\n+        \"//xla/stream_executor:memory_allocator\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tsl/cuda:nccl\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+        \"@local_tsl//tsl/platform:numbers\",\n+    ],\n+)\n+\n cc_library(\n     name = \"nvjitlink_support\",\n     srcs = [\"nvjitlink_support.cc\"],"
        },
        {
            "sha": "38d8d5508acffba83979862e6a2740d87e9affc8",
            "filename": "third_party/xla/xla/stream_executor/cuda/nccl_memory_allocator.cc",
            "status": "added",
            "additions": 108,
            "deletions": 0,
            "changes": 108,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/91b16be2f078084c9657aba0aa8c6ec332ea5387/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnccl_memory_allocator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/91b16be2f078084c9657aba0aa8c6ec332ea5387/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnccl_memory_allocator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnccl_memory_allocator.cc?ref=91b16be2f078084c9657aba0aa8c6ec332ea5387",
            "patch": "@@ -0,0 +1,108 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/stream_executor/cuda/nccl_memory_allocator.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_format.h\"\n+#include \"third_party/nccl/nccl.h\"\n+#include \"xla/stream_executor/activate_context.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/memory_allocation.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n+#include \"tsl/platform/numbers.h\"\n+\n+namespace stream_executor::gpu {\n+namespace {\n+\n+absl::StatusOr<void*> NcclAllocate(StreamExecutor* executor, uint64_t size) {\n+  std::unique_ptr<ActivateContext> activate = executor->Activate();\n+\n+  void* ptr = nullptr;\n+  ncclResult_t res = ncclMemAlloc(&ptr, size);\n+  if (res != ncclSuccess) {\n+    return absl::InternalError(absl::StrFormat(\n+        \"Failed to allocate %s (%llu bytes) from NCCL: %s. Last \"\n+        \"NCCL warning(error) log entry (may be unrelated): %s\",\n+        tsl::strings::HumanReadableNumBytes(size), size,\n+        ncclGetErrorString(res), ncclGetLastError(nullptr)));\n+  }\n+  XLA_VLOG_DEVICE(2, executor->device_ordinal())\n+      << \"Allocated memory \" << ptr << \" of \" << size << \" bytes from NCCL\";\n+  return ptr;\n+}\n+\n+absl::Status NcclFree(StreamExecutor* executor, void* ptr, uint64_t size) {\n+  std::unique_ptr<ActivateContext> activate = executor->Activate();\n+\n+  ncclResult_t res = ncclMemFree(ptr);\n+  if (res != ncclSuccess) {\n+    return absl::InternalError(absl::StrFormat(\n+        \"Failed to free NCCL memory at %p; result: %s. Last \"\n+        \"NCCL warning(error) log entry (may be unrelated): %s\",\n+        ptr, ncclGetErrorString(res), ncclGetLastError(nullptr)));\n+  }\n+\n+  XLA_VLOG_DEVICE(2, executor->device_ordinal())\n+      << \"Freed NCCL memory \" << ptr << \" of \" << size << \" bytes\";\n+  return absl::OkStatus();\n+}\n+\n+// A memory allocated from NCCL on the given executor.\n+class NcclMemoryAllocation : public MemoryAllocation {\n+ public:\n+  NcclMemoryAllocation(StreamExecutor* executor, void* ptr, uint64_t size);\n+\n+  ~NcclMemoryAllocation() final;\n+  DeviceAddressBase address() const final;\n+\n+ private:\n+  StreamExecutor* executor_;\n+  void* ptr_;\n+  uint64_t size_;\n+};\n+\n+}  // namespace\n+\n+NcclMemoryAllocation::NcclMemoryAllocation(StreamExecutor* executor, void* ptr,\n+                                           uint64_t size)\n+    : executor_(executor), ptr_(ptr), size_(size) {}\n+\n+NcclMemoryAllocation::~NcclMemoryAllocation() {\n+  CHECK_OK(NcclFree(executor_, ptr_, size_));  // Crash OK\n+}\n+\n+DeviceAddressBase NcclMemoryAllocation::address() const {\n+  return DeviceAddressBase(ptr_, size_);\n+}\n+\n+NcclMemoryAllocator::NcclMemoryAllocator(StreamExecutor* executor)\n+    : executor_(executor) {}\n+\n+absl::StatusOr<std::unique_ptr<MemoryAllocation>> NcclMemoryAllocator::Allocate(\n+    uint64_t size) {\n+  TF_ASSIGN_OR_RETURN(void* ptr, NcclAllocate(executor_, size));\n+  return std::make_unique<NcclMemoryAllocation>(executor_, ptr, size);\n+}\n+\n+}  // namespace stream_executor::gpu"
        },
        {
            "sha": "0c678d0c569e57206de347bdae422da366127df5",
            "filename": "third_party/xla/xla/stream_executor/cuda/nccl_memory_allocator.h",
            "status": "added",
            "additions": 43,
            "deletions": 0,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/91b16be2f078084c9657aba0aa8c6ec332ea5387/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnccl_memory_allocator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/91b16be2f078084c9657aba0aa8c6ec332ea5387/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnccl_memory_allocator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnccl_memory_allocator.h?ref=91b16be2f078084c9657aba0aa8c6ec332ea5387",
            "patch": "@@ -0,0 +1,43 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_STREAM_EXECUTOR_CUDA_NCCL_MEMORY_ALLOCATOR_H_\n+#define XLA_STREAM_EXECUTOR_CUDA_NCCL_MEMORY_ALLOCATOR_H_\n+\n+#include <cstdint>\n+#include <memory>\n+\n+#include \"absl/status/statusor.h\"\n+#include \"xla/stream_executor/memory_allocation.h\"\n+#include \"xla/stream_executor/memory_allocator.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+\n+namespace stream_executor::gpu {\n+\n+// A memory allocator that uses NCCL to allocate memory.\n+class NcclMemoryAllocator : public MemoryAllocator {\n+ public:\n+  explicit NcclMemoryAllocator(StreamExecutor* executor);\n+\n+  absl::StatusOr<std::unique_ptr<MemoryAllocation>> Allocate(\n+      uint64_t size) final;\n+\n+ private:\n+  StreamExecutor* executor_;\n+};\n+\n+}  // namespace stream_executor::gpu\n+\n+#endif  // XLA_STREAM_EXECUTOR_CUDA_NCCL_MEMORY_ALLOCATOR_H_"
        }
    ],
    "stats": {
        "total": 177,
        "additions": 177,
        "deletions": 0
    }
}