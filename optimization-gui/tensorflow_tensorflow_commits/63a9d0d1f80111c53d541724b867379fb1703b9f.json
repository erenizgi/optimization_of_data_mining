{
    "author": "SandSnip3r",
    "message": "If device placement annotations are found inside host computations (as a result of nested host computations), hoist them up the call stack. If any unsupported cases or inconsistencies are detected, an error will be returned to the user.\n\nThis allows JAX's migration from their previous `compute_on` API to the new (currently named `compute_on2`) API.\n\nPiperOrigin-RevId: 825177029",
    "sha": "63a9d0d1f80111c53d541724b867379fb1703b9f",
    "files": [
        {
            "sha": "3ff36af21ae04b50a0393b41a929e9cc75f07d9c",
            "filename": "third_party/xla/xla/core/host_offloading/hlo_host_device_type_call_wrapper.cc",
            "status": "modified",
            "additions": 309,
            "deletions": 0,
            "changes": 309,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63a9d0d1f80111c53d541724b867379fb1703b9f/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhlo_host_device_type_call_wrapper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63a9d0d1f80111c53d541724b867379fb1703b9f/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhlo_host_device_type_call_wrapper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhlo_host_device_type_call_wrapper.cc?ref=63a9d0d1f80111c53d541724b867379fb1703b9f",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n \n #include <cstdint>\n #include <memory>\n+#include <string>\n #include <vector>\n \n #include \"absl/algorithm/container.h\"\n@@ -151,6 +152,304 @@ absl::StatusOr<bool> OffloadHostInstructions(\n \n   return modified;\n }\n+\n+std::string GetDevicePlacement(const HloInstruction* instr) {\n+  CHECK(instr->IsCustomCall(memory_annotations::kDevicePlacement))\n+      << \"Input \" << instr->name() << \" must be a device placement annotation\";\n+  CHECK(instr->has_frontend_attributes())\n+      << \"Input \" << instr->name() << \" must have frontend attributes\";\n+  const auto& frontend_attribute_map = instr->frontend_attributes().map();\n+  auto buffer_placement_it =\n+      frontend_attribute_map.find(kXlaBufferPlacementAttr);\n+  CHECK(buffer_placement_it != frontend_attribute_map.end())\n+      << \"Input \" << instr->name()\n+      << \" must have a buffer placement frontend attribute\";\n+  return buffer_placement_it->second;\n+}\n+\n+absl::flat_hash_set<HloInstruction*> CollectAllowedDevicePlacementAnnotations(\n+    const HloComputation* computation) {\n+  // Collect a list of allowed annotations. We only expect annotations in one of\n+  // two locations in host computations currently:\n+  //  1. The ROOT instruction, if the computation returns a single value.\n+  //  2. The items feeding into the ROOT tuple instruction, if the computation\n+  //  returns a tuple.\n+  absl::flat_hash_set<HloInstruction*> allowed_device_placement_annotations;\n+  HloInstruction* root_instr = computation->root_instruction();\n+  if (root_instr->opcode() == HloOpcode::kTuple) {\n+    // Is a tuple\n+    for (int64_t i = 0; i < root_instr->operand_count(); ++i) {\n+      HloInstruction* operand = root_instr->mutable_operand(i);\n+      if (operand->IsCustomCall(memory_annotations::kDevicePlacement)) {\n+        allowed_device_placement_annotations.insert(operand);\n+      }\n+    }\n+  } else {\n+    // Is not a tuple\n+    if (root_instr->IsCustomCall(memory_annotations::kDevicePlacement)) {\n+      allowed_device_placement_annotations.insert(root_instr);\n+    }\n+  }\n+  return allowed_device_placement_annotations;\n+}\n+\n+absl::StatusOr<std::vector<HloInstruction*>>\n+CheckRemainingDevicePlacementAnnotations(\n+    const HloComputation* computation,\n+    const absl::flat_hash_set<HloInstruction*>&\n+        allowed_device_placement_annotations) {\n+  // Look for annotations which are not in the allowed set. If any annotation is\n+  // redundant, return it in a list so that the caller of this function can\n+  // remove it. Any other annotation is an error.\n+  std::vector<HloInstruction*> redundant_annotations;\n+  for (HloInstruction* instr : computation->instructions()) {\n+    if (instr->IsCustomCall(memory_annotations::kDevicePlacement)) {\n+      if (allowed_device_placement_annotations.contains(instr)) {\n+        continue;\n+      }\n+      const std::string device_placement = GetDevicePlacement(instr);\n+      if (device_placement == memory_annotations::kMemoryTargetPinnedHost ||\n+          device_placement == memory_annotations::kMemoryTargetUnpinnedHost) {\n+        // An annotation in host computation annotating the buffer to be on the\n+        // host is redundant.\n+        redundant_annotations.push_back(instr);\n+      } else {\n+        // An annotation in host computation annotating the buffer to be\n+        // somewhere other than the host is not allowed.\n+        return absl::InvalidArgumentError(\n+            absl::StrFormat(\"Host computation %s contains a device placement \"\n+                            \"annotation %s that is not allowed.\",\n+                            computation->name(), instr->ToString()));\n+      }\n+    }\n+  }\n+  return redundant_annotations;\n+}\n+\n+// Returns true if any redundant annotations were removed.\n+absl::StatusOr<bool> CleanUpHostComputationDevicePlacementAnnotations(\n+    const HloComputation* computation) {\n+  const absl::flat_hash_set<HloInstruction*>\n+      allowed_device_placement_annotations =\n+          CollectAllowedDevicePlacementAnnotations(computation);\n+  TF_ASSIGN_OR_RETURN(\n+      const std::vector<HloInstruction*> redundant_device_placement_annotations,\n+      CheckRemainingDevicePlacementAnnotations(\n+          computation, allowed_device_placement_annotations));\n+\n+  // Remove redundant annotations\n+  for (HloInstruction* redundant_annotation :\n+       redundant_device_placement_annotations) {\n+    VLOG(1) << \"Removing redundant annotation: \"\n+            << redundant_annotation->ToString();\n+    CHECK_EQ(redundant_annotation->operand_count(), 1)\n+        << \"A device placement annotation must have exactly one operand.\";\n+    for (HloInstruction* user : redundant_annotation->users()) {\n+      for (int64_t operand_index :\n+           user->operand_indices(redundant_annotation)) {\n+        TF_RETURN_IF_ERROR(user->ReplaceOperandWith(\n+            operand_index, redundant_annotation->mutable_operand(0)));\n+      }\n+    }\n+    TF_RETURN_IF_ERROR(redundant_annotation->parent()->RemoveInstruction(\n+        redundant_annotation));\n+  }\n+\n+  return !redundant_device_placement_annotations.empty();\n+}\n+\n+bool DevicePlacementMemorySpaceIsSame(const HloInstruction* a,\n+                                      const HloInstruction* b) {\n+  CHECK(a->IsCustomCall(memory_annotations::kDevicePlacement))\n+      << \"Input a: \" << a->name() << \" must be a device placement annotation\";\n+  CHECK(b->IsCustomCall(memory_annotations::kDevicePlacement))\n+      << \"Input b: \" << b->name() << \" must be a device placement annotation\";\n+  return GetDevicePlacement(a) == GetDevicePlacement(b);\n+}\n+\n+absl::Status CloneAnnotationToDestination(\n+    HloComputation* destination_computation,\n+    HloInstruction* destination_computation_caller_instruction,\n+    const HloInstruction* original_annotation,\n+    HloInstruction* destination_instruction) {\n+  HloInstruction* moved_annotation = destination_computation->AddInstruction(\n+      original_annotation->CloneWithNewOperands(original_annotation->shape(),\n+                                                {destination_instruction},\n+                                                \"move_to_caller\"));\n+\n+  bool used_new_annotation = false;\n+  for (HloInstruction* destination_user : destination_instruction->users()) {\n+    if (destination_user == moved_annotation) {\n+      // Do not replace the annotation with itself.\n+      continue;\n+    }\n+    if (destination_user->IsCustomCall(memory_annotations::kDevicePlacement)) {\n+      // The destination already has an annotation.\n+      if (!DevicePlacementMemorySpaceIsSame(original_annotation,\n+                                            destination_user)) {\n+        return absl::InvalidArgumentError(\n+            absl::StrFormat(\"Found conflicting host computation output memory \"\n+                            \"space. Call %s wants output memory space %s but \"\n+                            \"call %s wants output memory space %s\",\n+                            original_annotation->operand(0)->name(),\n+                            GetDevicePlacement(original_annotation),\n+                            destination_computation_caller_instruction->name(),\n+                            GetDevicePlacement(destination_user)));\n+      }\n+      // Annotation already exists, nothing to do.\n+      continue;\n+    }\n+    for (int64_t operand_index :\n+         destination_user->operand_indices(destination_instruction)) {\n+      TF_RETURN_IF_ERROR(destination_user->ReplaceOperandWith(\n+          operand_index, moved_annotation));\n+    }\n+    used_new_annotation = true;\n+  }\n+\n+  // All the places where this annotation would be placed already have this\n+  // exact annotation.\n+  if (!used_new_annotation) {\n+    TF_RETURN_IF_ERROR(\n+        destination_computation->RemoveInstruction(moved_annotation));\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n+absl::StatusOr<bool> MoveAnnotationsToCallerTuple(\n+    HloComputation* host_computation) {\n+  bool changed = false;\n+  for (int64_t operand_index = 0;\n+       operand_index < host_computation->root_instruction()->operand_count();\n+       ++operand_index) {\n+    HloInstruction* root_operand =\n+        host_computation->root_instruction()->mutable_operand(operand_index);\n+    if (!root_operand->IsCustomCall(memory_annotations::kDevicePlacement)) {\n+      // Instruction is not a device placement annotation; nothing to do.\n+      continue;\n+    }\n+    // Root is a device placement annotation.\n+    CHECK_EQ(root_operand->operand_count(), 1)\n+        << \"A device placement annotation must have exactly one operand.\";\n+\n+    // Clone the annotation to each of the callers.\n+    for (HloInstruction* caller_instruction :\n+         host_computation->caller_instructions()) {\n+      HloComputation* caller_computation = caller_instruction->parent();\n+      for (HloInstruction* caller_user_gte : caller_instruction->users()) {\n+        if (caller_user_gte->opcode() != HloOpcode::kGetTupleElement) {\n+          return absl::UnimplementedError(\n+              \"When moving device placement annotations out of a host \"\n+              \"computation, the tuple is used by something other than a \"\n+              \"get-tuple-element. This is currently not supported.\");\n+        }\n+        if (caller_user_gte->tuple_index() != operand_index) {\n+          // This get-tuple-element is getting a different index than the one we\n+          // are currently looking at.\n+          continue;\n+        }\n+        TF_RETURN_IF_ERROR(\n+            CloneAnnotationToDestination(caller_computation, caller_instruction,\n+                                         root_operand, caller_user_gte));\n+        changed = true;\n+      }\n+    }\n+\n+    TF_RETURN_IF_ERROR(host_computation->root_instruction()->ReplaceOperandWith(\n+        operand_index, root_operand->mutable_operand(0)));\n+    TF_RETURN_IF_ERROR(host_computation->RemoveInstruction(root_operand));\n+    changed = true;\n+  }\n+  return changed;\n+}\n+\n+absl::StatusOr<bool> MoveAnnotationToCallerNonTuple(\n+    HloComputation* host_computation) {\n+  HloInstruction* root_instr = host_computation->root_instruction();\n+  if (!root_instr->IsCustomCall(memory_annotations::kDevicePlacement)) {\n+    // Root is not a device placement annotation; nothing to do.\n+    return false;\n+  }\n+  // Root is a device placement annotation.\n+  CHECK_EQ(root_instr->operand_count(), 1)\n+      << \"A device placement annotation must have exactly one operand.\";\n+\n+  // Clone the annotation to each of the callers.\n+  for (HloInstruction* caller_instruction :\n+       host_computation->caller_instructions()) {\n+    HloComputation* caller_computation = caller_instruction->parent();\n+    TF_RETURN_IF_ERROR(\n+        CloneAnnotationToDestination(caller_computation, caller_instruction,\n+                                     root_instr, caller_instruction));\n+  }\n+\n+  // Remove the annotation from inside this computation.\n+  host_computation->set_root_instruction(root_instr->mutable_operand(0));\n+  TF_RETURN_IF_ERROR(host_computation->RemoveInstruction(root_instr));\n+  return true;\n+}\n+\n+// Move host device placement annotations out of this computation to the calling\n+// computation.\n+absl::StatusOr<bool> MoveAnnotationsToCaller(HloComputation* computation) {\n+  bool changed = false;\n+  TF_ASSIGN_OR_RETURN(\n+      bool cleaned_up,\n+      CleanUpHostComputationDevicePlacementAnnotations(computation));\n+  changed = changed || cleaned_up;\n+  // All annotations at this point are valid.\n+  if (computation->root_instruction()->opcode() == HloOpcode::kTuple) {\n+    // When the computation returns a tuple, the annotation is on the operands\n+    // of the root tuple.\n+    TF_ASSIGN_OR_RETURN(bool moved, MoveAnnotationsToCallerTuple(computation));\n+    changed = changed || moved;\n+  } else {\n+    // When the computation returns a single value, the annotation is the root\n+    // instruction.\n+    TF_ASSIGN_OR_RETURN(bool moved,\n+                        MoveAnnotationToCallerNonTuple(computation));\n+    changed = changed || moved;\n+  }\n+  return changed;\n+}\n+\n+absl::StatusOr<bool> RemoveDevicePlacementAnnotationsFromHostComputations(\n+    HloModule* module) {\n+  // The only time we currently find device placement annotations in host\n+  // computations are when the host computation calls another host computation\n+  // and that called host computation has an output memory space annotated. That\n+  // output memory space annotation is usually on the users of the host call (or\n+  // users of the get-tuple-elements if the call returns a tuple).\n+  //\n+  // Visit host computations in post-order. We will push annotations out of host\n+  // computations into their callers.\n+  std::vector<HloComputation*> host_computations;\n+  for (HloComputation* computation : module->MakeComputationPostOrder()) {\n+    // Check if this computation is a host computation.\n+    for (const HloInstruction* caller_instruction :\n+         computation->caller_instructions()) {\n+      if (caller_instruction->has_frontend_attributes()) {\n+        FrontendAttributes frontend_attributes =\n+            caller_instruction->frontend_attributes();\n+        if (frontend_attributes.map().contains(kXlaComputeTypeAttr) &&\n+            frontend_attributes.map().at(kXlaComputeTypeAttr) ==\n+                kXlaComputeTypeHost) {\n+          // The computation is a host computation.\n+          host_computations.push_back(computation);\n+          break;\n+        }\n+      }\n+    }\n+  }\n+\n+  bool changed = false;\n+  for (HloComputation* computation : host_computations) {\n+    TF_ASSIGN_OR_RETURN(bool moved, MoveAnnotationsToCaller(computation));\n+    changed = changed || moved;\n+  }\n+  return changed;\n+}\n }  // namespace\n \n /*static*/ absl::StatusOr<HloCallInstruction*>\n@@ -321,6 +620,16 @@ absl::StatusOr<bool> HloHostDeviceTypeCallWrapper::Run(\n     return false;\n   }\n \n+  // Before any other passes run, move device placement annotations out of host\n+  // computations.\n+  TF_ASSIGN_OR_RETURN(\n+      bool modified,\n+      RemoveDevicePlacementAnnotationsFromHostComputations(module));\n+  // At this point, this pass will always modify the module. The return value of\n+  // this function, which indicates whether the module was modified, is not\n+  // useful.\n+  (void)modified;\n+\n   TF_RETURN_IF_ERROR(\n       AnnotateHostComputeOffload().Run(module, execution_threads).status());\n   TF_RETURN_IF_ERROR(CallInliner().Run(module, execution_threads).status());"
        }
    ],
    "stats": {
        "total": 309,
        "additions": 309,
        "deletions": 0
    }
}