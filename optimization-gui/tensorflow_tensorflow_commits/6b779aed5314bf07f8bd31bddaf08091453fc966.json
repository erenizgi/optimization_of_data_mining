{
    "author": "mwhittaker",
    "message": "Pipe incarnations through C plugin.\n\nRecall that when a task in a multi-controller JAX (mcjax) job starts, it is\ngiven a randomly generated incarnation id. If the task fails and restarts, it\ngets a new id. These incarnation ids help us distinguish two different\ninstances of the same task.\n\nWhen a group of tasks wants to perform a collective (e.g., AllReduce), every\nparticipate needs to agree on the set of participants. If task 0 thinks the\ncollective is with tasks {0, 1, 2} while task 1 thinks the collective is with\ntasks {0, 1, 3}, the program will not execute smoothly.\n\nThe participants also need to agree on everyone's incarnations. For example, if\ntask 0 thinks task 2 has incarnation 42 while task 1 thinks task 2 has\nincarnation 100, they will disagree on whether task 2 has failed or not.\n\nTasks get the set of participants and their incarnations from calls to\n`live_devices`. `live_devices` runs a barrier across tasks and returns the set\nof currently alive processes along with their incarnations. This CL pipes this\ninformation through the C API, so that open source clients can use the\ninformation. Concretely, the incarnations of every task are passed to an\nexecutable when it is run.\n\nPiperOrigin-RevId: 810549686",
    "sha": "6b779aed5314bf07f8bd31bddaf08091453fc966",
    "files": [
        {
            "sha": "36dc5af9310413f340688a57ee26022c4b646d87",
            "filename": "tensorflow/core/common_runtime/eager/context_distributed_manager.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext_distributed_manager.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext_distributed_manager.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext_distributed_manager.cc?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -321,7 +321,6 @@ absl::Status CreateClientOnce(\n             /*host_memory_allocator=*/std::move(info->host_memory_allocator),\n             /*should_stage_host_to_device_transfers=*/true,\n             /*gpu_run_options=*/std::move(gpu_run_options), kv_store,\n-            /*distributed_client=*/nullptr,\n             /*abort_collectives_on_failure=*/false,\n             /*gpu_topology=*/\n             xla::GpuTopology::FromProto(device_topology_pair->second),"
        },
        {
            "sha": "22eecde5ba7d8a7d0f3d2434d1842abfe79df464",
            "filename": "tensorflow/core/common_runtime/gpu/gpu_device.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -1947,7 +1947,7 @@ Status BaseGPUDeviceFactory::CreateDevices(\n               /*host_memory_allocator=*/std::move(pjrt_gpu_host_allocator),\n               /*should_stage_host_to_device_transfers=*/true,\n               /*gpu_run_options=*/std::move(gpu_run_options),\n-              /*kv_store=*/nullptr, /*distributed_client=*/nullptr,\n+              /*kv_store=*/nullptr,\n               /*abort_collectives_on_failure=*/false, /*gpu_topology=*/nullptr,\n               /*num_nodes=*/std::nullopt);\n "
        },
        {
            "sha": "574979394d75304c4f669bd256c2a1bd2ef63f5d",
            "filename": "third_party/xla/xla/pjrt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -362,6 +362,7 @@ cc_library(\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:compiler\",\n         \"//xla/service:computation_layout\",\n+        \"//xla/service:global_device_id\",\n         \"//xla/service:hlo_cost_analysis\",\n         \"//xla/service:hlo_proto_cc\",\n         \"//xla/service:hlo_value\","
        },
        {
            "sha": "92dce5588027743d51b6fe34f8d8c9bb107e9262",
            "filename": "third_party/xla/xla/pjrt/c/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2FBUILD?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -279,6 +279,7 @@ cc_library(\n         \"//xla/pjrt/proto:compile_options_proto_cc\",\n         \"//xla/pjrt/proto:topology_description_proto_cc\",\n         \"//xla/service:computation_placer_hdr\",\n+        \"//xla/service:global_device_id\",\n         \"//xla/service:hlo_proto_cc\",\n         \"//xla/tsl/framework:allocator\",\n         \"//xla/tsl/platform:errors\","
        },
        {
            "sha": "3499654563e358ccf7cdd3d7bb6b63853d7469c0",
            "filename": "third_party/xla/xla/pjrt/c/CHANGELOG.md",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2FCHANGELOG.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2FCHANGELOG.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2FCHANGELOG.md?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -1,5 +1,9 @@\n # PJRT C API changelog\n \n+## 0.78\n+\n+* Add incarnations to `PJRT_ExecuteOptions`.\n+\n ## 0.77\n \n * Added buffer aliasing support to the PJRT C API"
        },
        {
            "sha": "8f61f0b10cb315c2b11ca6e2b50304ebb5db6e15",
            "filename": "third_party/xla/xla/pjrt/c/pjrt_c_api.h",
            "status": "modified",
            "additions": 8,
            "deletions": 2,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api.h?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -102,7 +102,7 @@ PJRT_DEFINE_STRUCT_TRAITS(PJRT_Extension_Base, next);\n // Changes include:\n // * Adding a new field to the PJRT_Api or argument structs\n // * Renaming a method or argument (doesn't affect ABI)\n-#define PJRT_API_MINOR 77\n+#define PJRT_API_MINOR 78\n \n // The plugin should set the major_version and minor_version of\n // PJRT_Api.pjrt_api_version to be the `PJRT_API_MAJOR` and `PJRT_API_MINOR` in\n@@ -1704,8 +1704,14 @@ struct PJRT_ExecuteOptions {\n   // null-terminated string. It is only valid for the duration of the C API\n   // call. The plugin must copy the string if it needs to be stored.\n   const char* call_location;\n+\n+  // The incarnation id for every task. For every 0 <= i < num_tasks,\n+  // task task_ids[i] has incarnation incarnation_ids[i].\n+  size_t num_tasks;\n+  int* task_ids;\n+  int64_t* incarnation_ids;\n };\n-PJRT_DEFINE_STRUCT_TRAITS(PJRT_ExecuteOptions, call_location);\n+PJRT_DEFINE_STRUCT_TRAITS(PJRT_ExecuteOptions, incarnation_ids);\n \n struct PJRT_LoadedExecutable_Execute_Args {\n   size_t struct_size;"
        },
        {
            "sha": "fbafaef173a5a6042c2fedece9304142f6273c80",
            "filename": "third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_wrapper_impl.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_wrapper_impl.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_wrapper_impl.cc?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -64,6 +64,7 @@ limitations under the License.\n #include \"xla/pjrt/proto/topology_description.pb.h\"\n #include \"xla/pjrt/raw_buffer.h\"\n #include \"xla/service/computation_placer.h\"\n+#include \"xla/service/global_device_id.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n@@ -1812,6 +1813,12 @@ PJRT_Error* PJRT_LoadedExecutable_Execute(\n     }\n   }\n \n+  for (size_t i = 0; i < args->options->num_tasks; ++i) {\n+    int task_id = args->options->task_ids[i];\n+    int64_t incarnation_id = args->options->incarnation_ids[i];\n+    options.incarnations.insert({task_id, xla::IncarnationId(incarnation_id)});\n+  }\n+\n   std::vector<std::vector<xla::PjRtBuffer*>> cpp_argument_lists =\n       Convert2DCBuffersToCppBuffers(args->argument_lists, args->num_devices,\n                                     args->num_args);"
        },
        {
            "sha": "b23c5bdf1c1d1e84c68c6138afc194048c8e37ed",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 20,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -624,7 +624,6 @@ StreamExecutorGpuClient::StreamExecutorGpuClient(\n     bool should_stage_host_to_device_transfers,\n     std::unique_ptr<gpu::GpuExecutableRunOptions> gpu_run_options,\n     std::shared_ptr<KeyValueStoreInterface> kv_store,\n-    std::shared_ptr<DistributedRuntimeClient> distributed_client,\n     bool abort_collectives_on_failure,\n     std::shared_ptr<const GpuTopology> gpu_topology,\n     std::optional<int> num_nodes)\n@@ -635,8 +634,7 @@ StreamExecutorGpuClient::StreamExecutorGpuClient(\n           should_stage_host_to_device_transfers, std::move(gpu_run_options)),\n       num_nodes_(num_nodes),\n       abort_collectives_on_failure_(abort_collectives_on_failure),\n-      kv_store_(std::move(kv_store)),\n-      distributed_client_(std::move(distributed_client)) {\n+      kv_store_(std::move(kv_store)) {\n   if (gpu_topology != nullptr) {\n     topology_.emplace(tsl::Fingerprint64(platform_name), platform_name,\n                       std::move(gpu_topology),\n@@ -723,35 +721,33 @@ StreamExecutorGpuClient::CreateBuffersForAsyncHostToDevice(\n }\n \n absl::StatusOr<absl::flat_hash_map<GlobalDeviceId, IncarnationId>>\n-StreamExecutorGpuClient::GetLatestIncarnations() {\n-  // Get the coordination service agent.\n-  if (!distributed_client_) {\n-    return FailedPrecondition(\"No distributed client\");\n-  }\n-  TF_ASSIGN_OR_RETURN(tsl::CoordinationServiceAgent * agent,\n-                      distributed_client_->GetCoordinationServiceAgent());\n-\n+StreamExecutorGpuClient::GetLatestIncarnations(const ExecuteOptions& options) {\n   // Get the latest incarnation for every task.\n   if (!num_nodes_.has_value()) {\n     return FailedPrecondition(\"Unknown number of nodes\");\n   }\n   std::vector<int> tasks(*num_nodes_);\n   std::iota(tasks.begin(), tasks.end(), 0);\n-  TF_ASSIGN_OR_RETURN(std::vector<IncarnationId> task_incarnations,\n-                      agent->Incarnations(tasks));\n \n   // Map every device to its incarnation.\n   absl::flat_hash_map<GlobalDeviceId, IncarnationId> device_incarnations;\n   for (const PjRtDevice* device : devices()) {\n-    device_incarnations[GlobalDeviceId(device->global_device_id().value())] =\n-        task_incarnations[device->process_index()];\n+    int task_id = device->process_index();\n+    GlobalDeviceId device_id(device->global_device_id().value());\n+\n+    auto it = options.incarnations.find(task_id);\n+    if (it == options.incarnations.end()) {\n+      return FailedPrecondition(\"Incarnation for task %d not found\", task_id);\n+    }\n+    device_incarnations[device_id] = it->second;\n   }\n   return device_incarnations;\n }\n \n-gpu::GpuExecutableRunOptions* StreamExecutorGpuClient::gpu_run_options() {\n+gpu::GpuExecutableRunOptions* StreamExecutorGpuClient::gpu_run_options(\n+    const ExecuteOptions& options) {\n   absl::StatusOr<absl::flat_hash_map<GlobalDeviceId, IncarnationId>>\n-      incarnations = GetLatestIncarnations();\n+      incarnations = GetLatestIncarnations(options);\n   if (!incarnations.ok()) {\n     VLOG(1) << \"Unable to set incarnations in GpuExecutableRunOptions: \"\n             << incarnations.status();\n@@ -1720,9 +1716,8 @@ absl::StatusOr<std::unique_ptr<PjRtClient>> GetStreamExecutorGpuClient(\n       pjrt_platform_name, xla_client, std::move(device_topology_pair.first),\n       options.node_id, std::move(allocator), std::move(host_memory_allocator),\n       options.should_stage_host_to_device_transfers, std::move(gpu_run_options),\n-      std::move(kv_store), std::move(options.distributed_runtime_client),\n-      options.abort_collectives_on_failure, std::move(gpu_topology),\n-      options.num_nodes);\n+      std::move(kv_store), options.abort_collectives_on_failure,\n+      std::move(gpu_topology), options.num_nodes);\n }\n \n std::vector<std::unique_ptr<PjRtStreamExecutorDevice>> BuildLocalDevices("
        },
        {
            "sha": "39aadf60fa8cc39208c91d327ffdaec8d34e2e2a",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -111,7 +111,6 @@ class StreamExecutorGpuClient : public xla::PjRtStreamExecutorClient {\n       bool should_stage_host_to_device_transfers,\n       std::unique_ptr<gpu::GpuExecutableRunOptions> gpu_run_options,\n       std::shared_ptr<KeyValueStoreInterface> kv_store,\n-      std::shared_ptr<DistributedRuntimeClient> distributed_client,\n       bool abort_collectives_on_failure,\n       std::shared_ptr<const GpuTopology> gpu_topology,\n       std::optional<int> num_nodes);\n@@ -121,7 +120,8 @@ class StreamExecutorGpuClient : public xla::PjRtStreamExecutorClient {\n     return kv_store_;\n   }\n \n-  gpu::GpuExecutableRunOptions* gpu_run_options() override;\n+  gpu::GpuExecutableRunOptions* gpu_run_options(\n+      const ExecuteOptions& options) override;\n \n   absl::StatusOr<xla::DeviceAssignment> GetDefaultDeviceAssignment(\n       int num_replicas, int num_partitions) const override;\n@@ -180,13 +180,12 @@ class StreamExecutorGpuClient : public xla::PjRtStreamExecutorClient {\n \n  private:\n   absl::StatusOr<absl::flat_hash_map<GlobalDeviceId, IncarnationId>>\n-  GetLatestIncarnations();\n+  GetLatestIncarnations(const ExecuteOptions& options);\n \n   std::optional<int> num_nodes_;\n   const bool abort_collectives_on_failure_ = false;\n   std::optional<xla::StreamExecutorGpuTopologyDescription> topology_;\n   std::shared_ptr<KeyValueStoreInterface> kv_store_;\n-  std::shared_ptr<DistributedRuntimeClient> distributed_client_;\n \n   absl::Mutex task_state_infos_mu_;\n   std::vector<tensorflow::CoordinatedTaskStateInfo> task_state_infos_"
        },
        {
            "sha": "121a123456dbd1144ab57ef8f2ba47eaefdb786b",
            "filename": "third_party/xla/xla/pjrt/pjrt_c_api_client.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 3,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_c_api_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_c_api_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_c_api_client.cc?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -2058,7 +2058,9 @@ PjRtCApiLoadedExecutable::GetCommonExecuteArgs(\n     std::vector<PJRT_Buffer**>& c_output_lists,\n     std::optional<std::vector<PJRT_Event*>>& device_complete_events,\n     SendRecvCallbackData& callback_data,\n-    std::vector<int64_t>& non_donatable_input_indices_storage) const {\n+    std::vector<int64_t>& non_donatable_input_indices_storage,\n+    std::vector<int>& task_ids_storage,\n+    std::vector<int64_t>& incarnation_ids_storage) const {\n   bool using_host_callbacks =\n       !options.send_callbacks.empty() || !options.recv_callbacks.empty();\n   if (using_host_callbacks &&\n@@ -2086,6 +2088,14 @@ PjRtCApiLoadedExecutable::GetCommonExecuteArgs(\n     args.options->call_location = options.call_location.c_str();\n   }\n \n+  for (const auto& [task_id, incarnation_id] : options.incarnations) {\n+    task_ids_storage.push_back(task_id);\n+    incarnation_ids_storage.push_back(incarnation_id.value());\n+  }\n+  args.options->num_tasks = options.incarnations.size();\n+  args.options->task_ids = task_ids_storage.data();\n+  args.options->incarnation_ids = incarnation_ids_storage.data();\n+\n   // If the executable has no addressable devices, `num_args` cannot be\n   // determined but it is unused. 0 serves as a placeholder.\n   args.num_args = (args.num_devices > 0) ? argument_handles[0].size() : 0;\n@@ -2196,6 +2206,8 @@ PjRtCApiLoadedExecutable::Execute(\n   std::vector<std::vector<PJRT_Buffer*>> c_output_lists_storage;\n   std::vector<PJRT_Buffer**> c_output_lists;\n   std::vector<int64_t> non_donatable_input_indices_storage;\n+  std::vector<int> task_ids_storage;\n+  std::vector<int64_t> incarnation_ids_storage;\n   std::vector<PJRT_Buffer**> c_arguments;\n   std::optional<std::vector<PJRT_Event*>> device_complete_events;\n   if (returned_futures.has_value()) {\n@@ -2225,7 +2237,8 @@ PjRtCApiLoadedExecutable::Execute(\n                            c_argument_lists_storage, c_arguments,\n                            c_output_lists_storage, c_output_lists,\n                            device_complete_events, *callback_data,\n-                           non_donatable_input_indices_storage));\n+                           non_donatable_input_indices_storage,\n+                           task_ids_storage, incarnation_ids_storage));\n \n   args.execute_device = nullptr;\n   PJRT_Profiler_Extension profiler_extension =\n@@ -2281,6 +2294,8 @@ PjRtCApiLoadedExecutable::ExecuteWithSingleDevice(\n   std::vector<std::vector<PJRT_Buffer*>> c_output_lists_storage;\n   std::vector<PJRT_Buffer**> c_output_lists;\n   std::vector<int64_t> non_donatable_input_indices_storage;\n+  std::vector<int> task_ids_storage;\n+  std::vector<int64_t> incarnation_ids_storage;\n   std::vector<PJRT_Buffer**> c_arguments;\n   std::optional<std::vector<PJRT_Event*>> device_complete_events;\n   if (fill_future) {\n@@ -2296,7 +2311,8 @@ PjRtCApiLoadedExecutable::ExecuteWithSingleDevice(\n                            c_argument_lists_storage, c_arguments,\n                            c_output_lists_storage, c_output_lists,\n                            device_complete_events, *callback_data,\n-                           non_donatable_input_indices_storage));\n+                           non_donatable_input_indices_storage,\n+                           task_ids_storage, incarnation_ids_storage));\n \n   args.execute_device =\n       tensorflow::down_cast<PjRtCApiDevice*>(device)->c_device();"
        },
        {
            "sha": "348aa61de9b75ac3f427875ea668e727113dccdf",
            "filename": "third_party/xla/xla/pjrt/pjrt_c_api_client.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_c_api_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_c_api_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_c_api_client.h?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -726,7 +726,9 @@ class PjRtCApiLoadedExecutable : public PjRtLoadedExecutable {\n       std::vector<PJRT_Buffer**>& c_output_lists,\n       std::optional<std::vector<PJRT_Event*>>& device_complete_events,\n       SendRecvCallbackData& send_recv_callback_data,\n-      std::vector<int64_t>& non_donatable_input_indices_storage) const;\n+      std::vector<int64_t>& non_donatable_input_indices_storage,\n+      std::vector<int>& task_ids_storage,\n+      std::vector<int64_t>& incarnation_ids_storage) const;\n \n   absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n   ExecuteWithSingleDevice(absl::Span<PjRtBuffer* const> argument_handles,"
        },
        {
            "sha": "17cc6126c58e3df17617015ff0fbc3ac17c47400",
            "filename": "third_party/xla/xla/pjrt/pjrt_executable.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.h?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -44,6 +44,7 @@ limitations under the License.\n #include \"xla/pjrt/proto/execute_options.pb.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/compiler.h\"\n+#include \"xla/service/global_device_id.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/service/hlo_cost_analysis.h\"\n #include \"xla/shape.h\"\n@@ -292,6 +293,9 @@ struct ExecuteOptions {\n   // call. The plugin must copy the string if it needs to be stored.\n   std::string call_location = \"\";\n \n+  // The latest known incarnation ids for all alive tasks, keyed by task id.\n+  absl::flat_hash_map<int, IncarnationId> incarnations;\n+\n   absl::StatusOr<ExecuteOptionsProto> ToProto() const;\n   static absl::StatusOr<ExecuteOptions> FromProto(\n       const ExecuteOptionsProto& proto);"
        },
        {
            "sha": "268ce6b7ec9fac46d501d63b8b1706023b6de47c",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -2821,7 +2821,7 @@ PjRtStreamExecutorLoadedExecutable::EnqueueExecution(\n     run_options.set_run_id(run_id);\n   }\n   run_options.set_rng_seed(device_state->GetNewPrngSeed());\n-  run_options.set_gpu_executable_run_options(client_->gpu_run_options());\n+  run_options.set_gpu_executable_run_options(client_->gpu_run_options(options));\n   run_options.set_launch_id(options.launch_id);\n   run_options.set_send_device_memory_function(&send_device_memory);\n   run_options.set_recv_device_memory_function(&recv_device_memory);"
        },
        {
            "sha": "8dd81306270955030a0d525c34c5cfad8f112ed9",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -364,7 +364,8 @@ class PjRtStreamExecutorClient : public CommonPjRtClient {\n     return should_stage_host_to_device_transfers_;\n   }\n \n-  virtual gpu::GpuExecutableRunOptions* gpu_run_options() {\n+  virtual gpu::GpuExecutableRunOptions* gpu_run_options(\n+      const ExecuteOptions& options) {\n     return gpu_run_options_.get();\n   }\n "
        },
        {
            "sha": "286bb5ee840833532c2121011431cf8b71b4ae9d",
            "filename": "third_party/xla/xla/python/pjrt_ifrt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2FBUILD?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -343,6 +343,7 @@ cc_library(\n         \"//xla/python/ifrt:user_context\",\n         \"//xla/python/ifrt/hlo:hlo_program\",\n         \"//xla/service:computation_placer_hdr\",\n+        \"//xla/service:global_device_id\",\n         \"//xla/service:hlo_proto_cc\",\n         \"//xla/tsl/concurrency:ref_count\",\n         \"//xla/tsl/distributed_runtime:call_options\","
        },
        {
            "sha": "b118cfa770ce9fff19d3aa2a7553935f1265e07d",
            "filename": "third_party/xla/xla/python/pjrt_ifrt/pjrt_client.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_client.cc?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -84,6 +84,7 @@ limitations under the License.\n #include \"xla/python/pjrt_ifrt/pjrt_topology.h\"\n #include \"xla/python/pjrt_ifrt/pjrt_tuple.h\"\n #include \"xla/python/pjrt_ifrt/xla_sharding.h\"\n+#include \"xla/service/global_device_id.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n@@ -1659,5 +1660,15 @@ absl::Status PjRtClient::TransferFromOutfeed(PjRtDevice* device,\n   return device->pjrt_device()->TransferFromOutfeed(literal);\n }\n \n+absl::StatusOr<absl::flat_hash_map<int, IncarnationId>>\n+PjRtClient::Incarnations() const {\n+  if (!distributed_client_) {\n+    return absl::FailedPreconditionError(\"missing distributed client\");\n+  }\n+  TF_ASSIGN_OR_RETURN(tsl::CoordinationServiceAgent * agent,\n+                      distributed_client_->GetCoordinationServiceAgent());\n+  return agent->Incarnations();\n+}\n+\n }  // namespace ifrt\n }  // namespace xla"
        },
        {
            "sha": "b45aaa3b2f9d7ac0fc1b6af63921db56a575faf8",
            "filename": "third_party/xla/xla/python/pjrt_ifrt/pjrt_client.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_client.h?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -325,6 +325,9 @@ class PjRtClient final\n     return tsl::RCReference<UserContext>();\n   }\n \n+  // Returns the latest set of incarnation ids for every task.\n+  absl::StatusOr<absl::flat_hash_map<int, IncarnationId>> Incarnations() const;\n+\n   static char ID;  // NOLINT\n \n  private:"
        },
        {
            "sha": "9c049bcfa2f5215af85a58bf4bb727eed3867fbc",
            "filename": "third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 4,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_executable.cc?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -64,6 +64,7 @@ limitations under the License.\n #include \"xla/python/pjrt_ifrt/pjrt_host_callback.h\"\n #include \"xla/python/pjrt_ifrt/pjrt_memory.h\"\n #include \"xla/python/pjrt_ifrt/xla_compiler.h\"\n+#include \"xla/service/global_device_id.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n@@ -208,7 +209,7 @@ absl::StatusOr<std::string> PjRtExecutable::Serialize() const {\n }\n \n absl::StatusOr<LoadedExecutableRef> PjRtLoadedExecutable::Create(\n-    PjRtCompatibleClient* client,\n+    PjRtClient* client,\n     std::shared_ptr<xla::PjRtLoadedExecutable> pjrt_loaded_executable,\n     std::vector<tsl::RCReference<LoadedHostCallback>> loaded_host_callbacks,\n     DeviceListRef executable_devices) {\n@@ -249,7 +250,7 @@ static absl::StatusOr<std::vector<xla::Shape>> ResultShapesOfModule(\n }\n \n absl::StatusOr<LoadedExecutableRef> PjRtLoadedExecutable::Create(\n-    PjRtCompatibleClient* client, mlir::ModuleOp module,\n+    PjRtClient* client, mlir::ModuleOp module,\n     xla::CompileOptions compile_options,\n     std::vector<tsl::RCReference<LoadedHostCallback>> loaded_host_callbacks,\n     DeviceListRef executable_devices) {\n@@ -321,7 +322,7 @@ absl::StatusOr<LoadedExecutableRef> PjRtLoadedExecutable::Create(\n }\n \n absl::StatusOr<LoadedExecutableRef> PjRtLoadedExecutable::CreateInternal(\n-    PjRtCompatibleClient* client,\n+    PjRtClient* client,\n     std::shared_ptr<xla::PjRtLoadedExecutable> pjrt_loaded_executable,\n     absl::Span<const xla::PrimitiveType> result_element_types,\n     absl::Span<const xla::DimensionVector> result_dimensions,\n@@ -491,7 +492,7 @@ absl::StatusOr<LoadedExecutableRef> PjRtLoadedExecutable::CreateInternal(\n }\n \n PjRtLoadedExecutable::PjRtLoadedExecutable(\n-    PjRtCompatibleClient* client,\n+    PjRtClient* client,\n     std::shared_ptr<xla::PjRtLoadedExecutable> pjrt_loaded_executable,\n     DeviceListRef devices, std::vector<Device*> addressable_devices,\n     std::vector<tsl::RCReference<LoadedHostCallback>> all_loaded_host_callbacks,\n@@ -571,6 +572,13 @@ PjRtLoadedExecutable::Execute(absl::Span<ArrayRef> args,\n   opts.use_major_to_minor_data_layout_for_callbacks = true;\n   opts.non_donatable_input_indices = options.non_donatable_input_indices;\n   opts.execution_stream_id = options.execution_stream_id;\n+  absl::StatusOr<absl::flat_hash_map<int, IncarnationId>> incarnations =\n+      client()->Incarnations();\n+  if (incarnations.ok()) {\n+    opts.incarnations = *std::move(incarnations);\n+  } else {\n+    LOG(WARNING) << \"Unable to get incarnations: \" << incarnations.status();\n+  }\n \n   if (options.custom_options.has_value()) {\n     const auto& attributes = options.custom_options->map();"
        },
        {
            "sha": "55609fe64c039bd6aab28d32562870ec3112ba82",
            "filename": "third_party/xla/xla/python/pjrt_ifrt/pjrt_executable.h",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_executable.h?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -185,7 +185,7 @@ class PjRtLoadedExecutable final\n   // xla::PjRtLoadedExecutable has fixed output dtypes/shapes/shardings.\n   // PjRtLoadedExecutable::GetHloModules() must be implemented.\n   static absl::StatusOr<LoadedExecutableRef> Create(\n-      PjRtCompatibleClient* client,\n+      PjRtClient* client,\n       std::shared_ptr<xla::PjRtLoadedExecutable> pjrt_loaded_executable,\n       std::vector<tsl::RCReference<LoadedHostCallback>> loaded_host_callbacks,\n       DeviceListRef executable_devices);\n@@ -196,7 +196,7 @@ class PjRtLoadedExecutable final\n   // allow_spmd_sharding_propagation_to_output enabled,\n   // PjRtLoadedExecutable::GetHloModules() must be implemented.\n   static absl::StatusOr<LoadedExecutableRef> Create(\n-      PjRtCompatibleClient* client, mlir::ModuleOp module,\n+      PjRtClient* client, mlir::ModuleOp module,\n       xla::CompileOptions compile_options,\n       std::vector<tsl::RCReference<LoadedHostCallback>> loaded_host_callbacks,\n       DeviceListRef executable_devices);\n@@ -294,7 +294,7 @@ class PjRtLoadedExecutable final\n     return pjrt_loaded_executable_->GetOutputMemoryKinds();\n   }\n \n-  PjRtCompatibleClient* client() const override {\n+  PjRtClient* client() const override {\n     DCHECK(this);\n     return client_;\n   }\n@@ -319,7 +319,7 @@ class PjRtLoadedExecutable final\n \n  private:\n   static absl::StatusOr<LoadedExecutableRef> CreateInternal(\n-      PjRtCompatibleClient* client,\n+      PjRtClient* client,\n       std::shared_ptr<xla::PjRtLoadedExecutable> pjrt_loaded_executable,\n       absl::Span<const xla::PrimitiveType> result_element_types,\n       absl::Span<const xla::DimensionVector> result_dimensions,\n@@ -329,7 +329,7 @@ class PjRtLoadedExecutable final\n       DeviceListRef executable_devices);\n \n   PjRtLoadedExecutable(\n-      PjRtCompatibleClient* client,\n+      PjRtClient* client,\n       std::shared_ptr<xla::PjRtLoadedExecutable> pjrt_loaded_executable,\n       DeviceListRef devices, std::vector<Device*> addressable_devices,\n       std::vector<tsl::RCReference<LoadedHostCallback>>\n@@ -339,7 +339,7 @@ class PjRtLoadedExecutable final\n       std::vector<DType> output_dtypes, std::vector<Shape> output_shapes,\n       std::vector<ShardingRef> output_shardings);\n \n-  PjRtCompatibleClient* client_;\n+  PjRtClient* client_;\n   std::shared_ptr<xla::PjRtLoadedExecutable> pjrt_loaded_executable_;\n   // Devices that `pjrt_loaded_executable_` runs on. Empty if the executable is\n   // portable."
        },
        {
            "sha": "22cdbacf14520015a6660dc783a39444720e62b6",
            "filename": "third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Fcoordination%2Fcoordination_service_agent.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Fcoordination%2Fcoordination_service_agent.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Fcoordination%2Fcoordination_service_agent.cc?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -1052,21 +1052,6 @@ CoordinationServiceAgent::GetAliveTasks(\n       response->alive_tasks().begin(), response->alive_tasks().end());\n }\n \n-absl::StatusOr<std::vector<IncarnationId>>\n-CoordinationServiceAgent::Incarnations(absl::Span<const int> tasks) const {\n-  absl::MutexLock lock(incarnations_mu_);\n-  std::vector<IncarnationId> incarnations;\n-  for (const auto& task_id : tasks) {\n-    auto it = incarnations_.find(task_id);\n-    if (it == incarnations_.end()) {\n-      return absl::FailedPreconditionError(\n-          absl::StrFormat(\"Task %d not found\", task_id));\n-    }\n-    incarnations.push_back(it->second);\n-  }\n-  return incarnations;\n-}\n-\n // Returns an error if agent is not running.\n absl::Status CoordinationServiceAgent::ValidateRunningAgent(\n     bool allow_disconnected) {"
        },
        {
            "sha": "7e3bc0fa798d143eb92d834dd3e2a64266605789",
            "filename": "third_party/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.h",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Fcoordination%2Fcoordination_service_agent.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6b779aed5314bf07f8bd31bddaf08091453fc966/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Fcoordination%2Fcoordination_service_agent.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Fcoordination%2Fcoordination_service_agent.h?ref=6b779aed5314bf07f8bd31bddaf08091453fc966",
            "patch": "@@ -323,15 +323,17 @@ class CoordinationServiceAgent {\n   absl::StatusOr<std::vector<tensorflow::CoordinatedTask>> GetAliveTasks(\n       const std::vector<tensorflow::CoordinatedTask>& tasks);\n \n-  // Returns the latest known set of incarnation ids for the provided\n-  // tasks. Incarnation ids can be refreshed by calling GetAliveTasks.\n+  // Returns the latest known set of incarnation ids for every task. Incarnation\n+  // ids can be refreshed by calling GetAliveTasks.\n   //\n   // When a task starts executing, it generates a random 64 bit incarnation id.\n   // If a task fails and restarts, for example, it will have a different\n   // incarnation id before and after it fails. This allows us to distinguish\n   // different executions of the same task.\n-  absl::StatusOr<std::vector<IncarnationId>> Incarnations(\n-      absl::Span<const int> tasks) const;\n+  absl::flat_hash_map<int, IncarnationId> Incarnations() const {\n+    absl::MutexLock lock(incarnations_mu_);\n+    return incarnations_;\n+  }\n \n   // Get unowned Env* that the agent was initialized with.\n   absl::StatusOr<Env*> GetEnv();"
        }
    ],
    "stats": {
        "total": 171,
        "additions": 108,
        "deletions": 63
    }
}