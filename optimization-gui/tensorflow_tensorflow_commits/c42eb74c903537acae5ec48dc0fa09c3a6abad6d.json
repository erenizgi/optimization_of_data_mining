{
    "author": "derdrdirk",
    "message": "[Autotuner] Fix behavior when cublas is disabled and autotune level is set to 0.\n\nPiperOrigin-RevId: 843153465",
    "sha": "c42eb74c903537acae5ec48dc0fa09c3a6abad6d",
    "files": [
        {
            "sha": "2578a24a614d8fc54a6975e3410876c22845e1a7",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 9,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c42eb74c903537acae5ec48dc0fa09c3a6abad6d/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c42eb74c903537acae5ec48dc0fa09c3a6abad6d/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc?ref=c42eb74c903537acae5ec48dc0fa09c3a6abad6d",
            "patch": "@@ -332,6 +332,17 @@ absl::StatusOr<Autotuner::Config> Autotuner::TuneBestConfig(\n     }\n   }\n \n+  if (autotune_config_.exclude_cublas_config) {\n+    executable_candidates.erase(\n+        std::remove_if(executable_candidates.begin(),\n+                       executable_candidates.end(),\n+                       [](const ExecutableCandidate& candidate) {\n+                         return candidate.config.codegen_backend->name() ==\n+                                \"Cublas_fission\";\n+                       }),\n+        executable_candidates.end());\n+  }\n+\n   if (executable_candidates.empty()) {\n     return absl::InternalError(\n         absl::StrCat(\"Autotuner could not compile any configs for HLO: \",\n@@ -502,15 +513,6 @@ absl::StatusOr<std::vector<Autotuner::ConfigResult>> Autotuner::ProfileAll(\n \n absl::StatusOr<Autotuner::ConfigResult> Autotuner::PickBestConfig(\n     std::vector<ConfigResult>& results) {\n-  if (autotune_config_.exclude_cublas_config) {\n-    results.erase(\n-        std::remove_if(results.begin(), results.end(),\n-                       [](const ConfigResult& result) {\n-                         return result.config.codegen_backend->name() ==\n-                                \"Cublas_fission\";\n-                       }),\n-        results.end());\n-  }\n \n   absl::Duration min_duration = absl::InfiniteDuration();\n   ConfigResult* best_result = nullptr;"
        },
        {
            "sha": "bd4cc84715935b2a7a0adfe1f161b4e4527d473e",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c42eb74c903537acae5ec48dc0fa09c3a6abad6d/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c42eb74c903537acae5ec48dc0fa09c3a6abad6d/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc?ref=c42eb74c903537acae5ec48dc0fa09c3a6abad6d",
            "patch": "@@ -709,12 +709,6 @@ TEST_F(AutotunerTest, ExcludeCublasConfig) {\n   backends.push_back(std::move(backend));\n \n   auto profiler = std::make_unique<MockProfiler>();\n-  EXPECT_CALL(*profiler, CreateInputBuffers(_))\n-      .WillOnce(Return(std::make_unique<InputBuffers>()));\n-  EXPECT_CALL(*profiler, Profile(_, _))\n-      .WillOnce(Return(ProfileResult({absl::Seconds(1)})))\n-      .WillOnce(Return(ProfileResult({absl::Seconds(2)})));\n-\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto autotuner, Autotuner::Create(std::move(backends),\n                                         std::move(profiler), config_, nullptr));"
        },
        {
            "sha": "714f6ef7fe1c6888d7b64e827b5ee3418b5e1bb6",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_pass.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c42eb74c903537acae5ec48dc0fa09c3a6abad6d/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c42eb74c903537acae5ec48dc0fa09c3a6abad6d/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc?ref=c42eb74c903537acae5ec48dc0fa09c3a6abad6d",
            "patch": "@@ -63,7 +63,8 @@ AutotuneConfig GetAutotuneConfig(const DebugOptions& debug_options,\n       !debug_options.xla_gpu_cublas_fallback();\n   autotune_config.select_first_config =\n       debug_options.xla_gpu_deterministic_ops() ||\n-      debug_options.xla_gpu_exclude_nondeterministic_ops();\n+      debug_options.xla_gpu_exclude_nondeterministic_ops() ||\n+      debug_options.xla_gpu_autotune_level() == 0;\n \n   if (is_deviceless) {\n     // If we are running on a deviceless target, we want to use default configs."
        }
    ],
    "stats": {
        "total": 29,
        "additions": 13,
        "deletions": 16
    }
}