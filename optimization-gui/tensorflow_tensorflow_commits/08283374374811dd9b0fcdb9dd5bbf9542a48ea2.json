{
    "author": "basioli-k",
    "message": "[XLA][cuda] Check if memory is managed in `CudaExecutor::GetPointerMemorySpace`\n\nPiperOrigin-RevId: 817289384",
    "sha": "08283374374811dd9b0fcdb9dd5bbf9542a48ea2",
    "files": [
        {
            "sha": "4188965245db883244c8a9ace7f288ec91ea866b",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/08283374374811dd9b0fcdb9dd5bbf9542a48ea2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/08283374374811dd9b0fcdb9dd5bbf9542a48ea2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=08283374374811dd9b0fcdb9dd5bbf9542a48ea2",
            "patch": "@@ -1218,6 +1218,7 @@ xla_test(\n         \":cuda_platform\",\n         \":cuda_platform_id\",\n         \"//xla/stream_executor:device_description\",\n+        \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:kernel\",\n         \"//xla/stream_executor:kernel_spec\",\n         \"//xla/stream_executor:memory_allocation\","
        },
        {
            "sha": "3509821b82314bec24245575a1f67d60ecd761c5",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/08283374374811dd9b0fcdb9dd5bbf9542a48ea2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/08283374374811dd9b0fcdb9dd5bbf9542a48ea2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc?ref=08283374374811dd9b0fcdb9dd5bbf9542a48ea2",
            "patch": "@@ -1498,6 +1498,14 @@ CudaExecutor::CreateDeviceDescription(int device_ordinal) {\n absl::StatusOr<MemoryType> CudaExecutor::GetPointerMemorySpace(\n     const void* ptr) {\n   CUdeviceptr pointer = reinterpret_cast<CUdeviceptr>(const_cast<void*>(ptr));\n+  unsigned int is_managed;\n+  TF_RETURN_IF_ERROR(cuda::ToStatus(cuPointerGetAttribute(\n+      &is_managed, CU_POINTER_ATTRIBUTE_IS_MANAGED, pointer)));\n+\n+  if (is_managed) {\n+    return MemoryType::kUnified;\n+  }\n+\n   unsigned int value;\n   TF_RETURN_IF_ERROR(cuda::ToStatus(cuPointerGetAttribute(\n       &value, CU_POINTER_ATTRIBUTE_MEMORY_TYPE, pointer)));"
        },
        {
            "sha": "4d1c4ca56da342db9e6db9e648e6c3555d5b834a",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor_test.cc",
            "status": "modified",
            "additions": 42,
            "deletions": 0,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/08283374374811dd9b0fcdb9dd5bbf9542a48ea2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/08283374374811dd9b0fcdb9dd5bbf9542a48ea2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor_test.cc?ref=08283374374811dd9b0fcdb9dd5bbf9542a48ea2",
            "patch": "@@ -25,6 +25,7 @@ limitations under the License.\n #include \"xla/stream_executor/cuda/cuda_platform.h\"\n #include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n #include \"xla/stream_executor/device_description.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/gpu/gpu_test_kernels.h\"\n #include \"xla/stream_executor/kernel.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n@@ -169,5 +170,46 @@ TEST(CudaExecutorTest, CreateUnsupportedMemoryAllocatorsFail) {\n   EXPECT_THAT(executor->CreateMemoryAllocator(MemoryType::kDevice),\n               Not(absl_testing::IsOk()));\n }\n+\n+TEST(CudaExecutorTest, GetPointerMemorySpaceWorksWithUnifiedMemory) {\n+  TF_ASSERT_OK_AND_ASSIGN(Platform * platform,\n+                          PlatformManager::PlatformWithName(\"CUDA\"));\n+  TF_ASSERT_OK_AND_ASSIGN(StreamExecutor * executor,\n+                          platform->ExecutorForDevice(0));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto unified_memory_allocator,\n+      executor->CreateMemoryAllocator(MemoryType::kUnified));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<MemoryAllocation> allocation,\n+                          unified_memory_allocator->Allocate(256));\n+  EXPECT_THAT(executor->GetPointerMemorySpace(allocation->opaque()),\n+              IsOkAndHolds(MemoryType::kUnified));\n+}\n+\n+TEST(CudaExecutorTest, GetPointerMemorySpaceWorksWithHostMemory) {\n+  TF_ASSERT_OK_AND_ASSIGN(Platform * platform,\n+                          PlatformManager::PlatformWithName(\"CUDA\"));\n+  TF_ASSERT_OK_AND_ASSIGN(StreamExecutor * executor,\n+                          platform->ExecutorForDevice(0));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<MemoryAllocation> allocation,\n+                          executor->HostMemoryAllocate(256));\n+  EXPECT_THAT(executor->GetPointerMemorySpace(allocation->opaque()),\n+              IsOkAndHolds(MemoryType::kHost));\n+}\n+\n+TEST(CudaExecutorTest, GetPointerMemorySpaceWorksWithDeviceMemory) {\n+  TF_ASSERT_OK_AND_ASSIGN(Platform * platform,\n+                          PlatformManager::PlatformWithName(\"CUDA\"));\n+  TF_ASSERT_OK_AND_ASSIGN(StreamExecutor * executor,\n+                          platform->ExecutorForDevice(0));\n+\n+  DeviceMemoryBase allocation = executor->Allocate(256);\n+  EXPECT_NE(allocation.opaque(), nullptr);\n+  EXPECT_THAT(executor->GetPointerMemorySpace(allocation.opaque()),\n+              IsOkAndHolds(MemoryType::kDevice));\n+}\n+\n }  // namespace\n }  // namespace stream_executor::gpu"
        }
    ],
    "stats": {
        "total": 51,
        "additions": 51,
        "deletions": 0
    }
}