{
    "author": "basioli-k",
    "message": "[XLA][codegen] Migrate triton operations that have shared dialect lowerings are implemented for.\n\nThese were missed in previous commits.\nAddresses transpose and bitcast.\n\nPiperOrigin-RevId: 826158776",
    "sha": "f4ebf9d47dec4b8552ae62f677a23a92b16e9886",
    "files": [
        {
            "sha": "af24f06275d0e7ab360c325c741c43135835f5d8",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f4ebf9d47dec4b8552ae62f677a23a92b16e9886/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f4ebf9d47dec4b8552ae62f677a23a92b16e9886/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD?ref=f4ebf9d47dec4b8552ae62f677a23a92b16e9886",
            "patch": "@@ -137,8 +137,8 @@ cc_library(\n         \"@llvm-project//mlir:IR\",\n         \"@llvm-project//mlir:LLVMDialect\",\n         \"@llvm-project//mlir:MathDialect\",\n-        \"@llvm-project//mlir:NVVMDialect\",\n         \"@llvm-project//mlir:Support\",\n+        \"@llvm-project//mlir:TensorDialect\",\n         \"@triton//:TritonDialects\",\n     ],\n )\n@@ -428,6 +428,7 @@ cc_library(\n         \"@llvm-project//mlir:MathDialect\",\n         \"@llvm-project//mlir:Support\",\n         \"@local_tsl//tsl/platform:tensor_float_32_hdr_lib\",\n+        \"@stablehlo//:stablehlo_ops\",\n         \"@triton//:TritonDialects\",\n     ],\n )"
        },
        {
            "sha": "de8e540b3640f3a0c269add118e9174e97ffe2d6",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/dot_algorithms.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f4ebf9d47dec4b8552ae62f677a23a92b16e9886/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f4ebf9d47dec4b8552ae62f677a23a92b16e9886/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms.cc?ref=f4ebf9d47dec4b8552ae62f677a23a92b16e9886",
            "patch": "@@ -36,6 +36,7 @@ limitations under the License.\n #include \"mlir/IR/TypeUtilities.h\"\n #include \"mlir/IR/Value.h\"\n #include \"mlir/Support/LLVM.h\"\n+#include \"stablehlo/dialect/StablehloOps.h\"\n #include \"xla/backends/gpu/codegen/triton/emitter_helpers.h\"\n #include \"xla/codegen/emitter_loc_op_builder.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n@@ -160,8 +161,8 @@ absl::StatusOr<Value> ScaledDot(EmitterLocOpBuilder b,\n   Value rhs_scale;\n   if (rhs_dot_elem_type != ttir::ScaleDotElemType::BF16) {\n     rhs_scale = Bitcast(b, operands.rhs_scale, b.getI8Type());\n-    rhs_scale =\n-        b.create<ttir::TransOp>(rhs_scale, mlir::ArrayRef<int32_t>{1, 0});\n+    rhs_scale = b.create<mlir::stablehlo::TransposeOp>(\n+        rhs_scale, b.getDenseI64ArrayAttr({1, 0}));\n   }\n \n   // make type with the same shape as the scale but with i8 type"
        },
        {
            "sha": "5bb29f009085a7268b0e54c248c8b5397f673d4d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/emitter_helpers.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f4ebf9d47dec4b8552ae62f677a23a92b16e9886/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f4ebf9d47dec4b8552ae62f677a23a92b16e9886/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc?ref=f4ebf9d47dec4b8552ae62f677a23a92b16e9886",
            "patch": "@@ -35,6 +35,7 @@ limitations under the License.\n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"mlir/Dialect/Math/IR/Math.h\"\n+#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/Builders.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n@@ -501,7 +502,7 @@ absl::StatusOr<Value> EmitElementwise(EmitterLocOpBuilder& b,\n                   mh::ComparisonDirection::NE),\n           inputs[1], inputs[2]);\n     case HloOpcode::kReducePrecision:\n-      return mh::reducePrecision<mt::BitcastOp>(\n+      return mh::reducePrecision<mlir::tensor::BitcastOp>(\n           b.getLoc(), inputs[0], hlo.exponent_bits(), hlo.mantissa_bits(), &b);\n     default:\n       return absl::InvalidArgumentError("
        }
    ],
    "stats": {
        "total": 11,
        "additions": 7,
        "deletions": 4
    }
}