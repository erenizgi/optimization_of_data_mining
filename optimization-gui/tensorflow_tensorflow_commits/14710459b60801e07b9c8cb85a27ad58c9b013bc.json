{
    "author": "subhankarshah",
    "message": "[XLA:MSA] Allow MSA to schedule custom-call prefetches.\n\nPiperOrigin-RevId: 821900214",
    "sha": "14710459b60801e07b9c8cb85a27ad58c9b013bc",
    "files": [
        {
            "sha": "97f189396d62109dfa54cedb99de9efd2097c6b2",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.cc",
            "status": "modified",
            "additions": 345,
            "deletions": 69,
            "changes": 414,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc?ref=14710459b60801e07b9c8cb85a27ad58c9b013bc",
            "patch": "@@ -2007,7 +2007,7 @@ absl::Status MsaAlgorithm::ProcessColoredBuffers() {\n   return absl::OkStatus();\n }\n \n-int64_t MsaAlgorithm::MaxReservedScopedMemory() {\n+int64_t MsaAlgorithm::MaxScopedMemoryOffset() {\n   const std::vector<HloInstruction*>& instruction_sequence =\n       hlo_live_range_.flattened_instruction_sequence().instructions();\n   int64_t max_reserved_scoped_memory = 0;\n@@ -2089,6 +2089,35 @@ std::optional<int64_t> MsaAlgorithm::EarliestBlockPrefetchStartTime(\n \n namespace {\n \n+struct UseInterval {\n+  int64_t first_use_time;\n+  int64_t last_use_time;\n+};\n+\n+absl::flat_hash_map<const HloValue*, UseInterval> GetUseIntervals(\n+    const std::vector<const HloValue*>& values,\n+    const absl::flat_hash_map<const HloInstruction*, int64_t>&\n+        instruction_schedule) {\n+  absl::flat_hash_map<const HloValue*, UseInterval> value_to_use_intervals;\n+  for (const HloValue* value : values) {\n+    UseInterval& use_interval = value_to_use_intervals[value];\n+    use_interval.first_use_time = std::numeric_limits<int64_t>::max();\n+    use_interval.last_use_time = -1;\n+    for (const HloUse& use : value->GetUses()) {\n+      auto it = instruction_schedule.find(use.instruction);\n+      if (it == instruction_schedule.end()) {\n+        continue;\n+      }\n+      use_interval.first_use_time =\n+          std::min(use_interval.first_use_time, it->second);\n+      use_interval.last_use_time =\n+          std::max(use_interval.last_use_time, it->second);\n+    }\n+    CHECK_NE(use_interval.last_use_time, -1);\n+  }\n+  return value_to_use_intervals;\n+}\n+\n absl::flat_hash_set<HloPosition> GetParameterInstructionsAliasedToOutput(\n     const HloInputOutputAliasConfig& alias_config,\n     const HloInstruction* root_instruction) {\n@@ -2104,17 +2133,245 @@ absl::flat_hash_set<HloPosition> GetParameterInstructionsAliasedToOutput(\n   return aliased_parameter_positions;\n }\n \n+void PopulateExistingBlockPrefetchedValues(\n+    const Options& options, const HloAliasAnalysis& alias_analysis,\n+    std::vector<const HloValue*>& block_prefetched_values,\n+    absl::flat_hash_map<const HloValue*, const HloValue*>&\n+        prefetch_done_value_to_original_value,\n+    absl::flat_hash_map<const HloValue*, HloInstruction*>&\n+        prefetch_done_value_to_prefetch_start_instruction) {\n+  // Block prefetched values are prefetch done HloValues. Original values are\n+  // the HLO values that are being prefetched. We maintain a map of prefetch\n+  // done value to original value. We also maintain a map of prefetch done\n+  // HloValue to the prefetch start instruction.\n+  for (const auto& [position, custom_call_prefetch_details] :\n+       options.hlo_position_to_custom_call_prefetch_details) {\n+    const HloValue* original_value =\n+        &alias_analysis.dataflow_analysis().GetUniqueValueAt(\n+            position.instruction, position.index);\n+    for (const auto& custom_call_prefetch_detail :\n+         custom_call_prefetch_details) {\n+      HloInstruction* prefetch_start =\n+          custom_call_prefetch_detail.prefetch_start;\n+      HloInstruction* prefetch_done = custom_call_prefetch_detail.prefetch_done;\n+      const HloValue* prefetch_done_value =\n+          &alias_analysis.dataflow_analysis().GetUniqueValueAt(prefetch_done,\n+                                                               {});\n+      prefetch_done_value_to_original_value[prefetch_done_value] =\n+          original_value;\n+      prefetch_done_value_to_prefetch_start_instruction[prefetch_done_value] =\n+          prefetch_start;\n+      block_prefetched_values.push_back(prefetch_done_value);\n+    }\n+  }\n+}\n+\n }  // namespace\n \n-absl::Status MsaAlgorithm::ProcessBlockPrefetches() {\n-  if (!options_.hlo_position_to_custom_call_prefetch_details.empty()) {\n-    return absl::UnimplementedError(\n-        \"Block prefetching for custom call prefetches is not yet implemented \"\n-        \"in MSA.\");\n+absl::Status MsaAlgorithm::AllocateAndScheduleExistingBlockPrefetches() {\n+  if (options_.hlo_position_to_custom_call_prefetch_details.empty()) {\n+    return absl::OkStatus();\n   }\n   if (options_.reserved_bytes_for_block_prefetches <= 0) {\n+    return absl::FailedPreconditionError(\n+        \"Reserved bytes for block prefetches is zero, we need memory to \"\n+        \"schedule custom call block prefetches.\");\n+  }\n+  // List of all block prefetched HloValues.\n+  std::vector<const HloValue*> block_prefetched_values;\n+  absl::flat_hash_map<const HloValue*, const HloValue*>\n+      prefetch_done_value_to_original_value;\n+  absl::flat_hash_map<const HloValue*, HloInstruction*>\n+      prefetch_done_value_to_prefetch_start_instruction;\n+\n+  PopulateExistingBlockPrefetchedValues(\n+      options_, alias_analysis_, block_prefetched_values,\n+      prefetch_done_value_to_original_value,\n+      prefetch_done_value_to_prefetch_start_instruction);\n+\n+  const auto& instruction_schedule = hlo_live_range_.instruction_schedule();\n+\n+  // Compute the live ranges for each block prefetched value.\n+  absl::flat_hash_map<const HloValue*, UseInterval> value_to_use_intervals =\n+      GetUseIntervals(block_prefetched_values, instruction_schedule);\n+\n+  // Erase all the values from block_prefetched_values that have been finalized.\n+  block_prefetched_values.erase(\n+      std::remove_if(block_prefetched_values.begin(),\n+                     block_prefetched_values.end(),\n+                     [&](const HloValue* value) {\n+                       return finalized_values_.contains(value);\n+                     }),\n+      block_prefetched_values.end());\n+\n+  // Sort block prefetched values in ascending order of first use time.\n+  absl::c_sort(block_prefetched_values,\n+               [&](const HloValue* a, const HloValue* b) {\n+                 return value_to_use_intervals.at(a).first_use_time <\n+                        value_to_use_intervals.at(b).first_use_time;\n+               });\n+\n+  // We need to reserve a continuous block of memory for the block prefetches,\n+  // since scoped allocations are initially placed at offset 0 we place the\n+  // block prefetches at the end of the reserved scoped allocations.\n+  int64_t block_prefetching_starting_offset = MaxScopedMemoryOffset();\n+  // All block prefetches should be placed within this limit.\n+  int64_t block_prefetching_limit_bytes =\n+      block_prefetching_starting_offset +\n+      options_.reserved_bytes_for_block_prefetches;\n+  CHECK_LE(block_prefetching_limit_bytes, options_.max_size_in_bytes);\n+  VLOG(1) << \"block prefetched values bytes limit: \"\n+          << block_prefetching_limit_bytes;\n+  int64_t previous_start_time = -1;\n+  int64_t max_in_flight_prefetches_allowed =\n+      options_.max_outstanding_block_prefetches;\n+  std::vector<int64_t> prefetch_end_times;\n+  std::vector<int64_t> prefetch_done_schedule_before_times;\n+\n+  absl::flat_hash_map<const HloValue*, Allocation*> value_to_pinned_allocation;\n+\n+  // For each block prefetched value, we try to find a chunk within the block\n+  // prefetching limit, ensuring FIFO ordering. After a suitable chunk is found\n+  // for a block prefetched value, we:\n+  // 1. Commit the chunk to the alternate memory.\n+  // 2. Update the operands in alternate memory map.\n+  // 3. Add the copy done and copy start values to the finalized values set.\n+  // 4. Add a repack allocation block to the repack allocation blocks list.\n+  // 5. Serve the uses of the original value from the pinned allocation in the\n+  //    default memory.\n+  // 6. Clear the pending chunks after the loop.\n+  for (const HloValue* prefetch_done_value : block_prefetched_values) {\n+    UseInterval use_interval = value_to_use_intervals.at(prefetch_done_value);\n+    int64_t first_use_time = use_interval.first_use_time;\n+    int64_t last_use_time = use_interval.last_use_time;\n+    auto it = prefetch_done_value_to_original_value.find(prefetch_done_value);\n+    CHECK(it != prefetch_done_value_to_original_value.end());\n+    const HloValue* original_value = it->second;\n+    int64_t definition_time =\n+        instruction_schedule.at(original_value->defining_instruction());\n+    int64_t end_time = last_use_time;\n+    int64_t buffer_size = buffer_intervals_.at(prefetch_done_value).size;\n+    int64_t earliest_start_time_candidate =\n+        std::max(definition_time, previous_start_time);\n+    CHECK_LE(earliest_start_time_candidate, first_use_time);\n+\n+    // Find the earliest start time for which a chunk can be allocated for the\n+    // block prefetched value.\n+    std::optional<int64_t> optional_start_time = EarliestBlockPrefetchStartTime(\n+        previous_start_time, definition_time, first_use_time, end_time,\n+        buffer_size, block_prefetching_limit_bytes,\n+        max_in_flight_prefetches_allowed, prefetch_done_schedule_before_times,\n+        prefetch_end_times);\n+\n+    if (!optional_start_time.has_value()) {\n+      // Custom call block prefetches must be allocated in the alternate memory.\n+      return absl::FailedPreconditionError(absl::StrCat(\n+          \"Could not find a chunk for block prefetched value: \",\n+          prefetch_done_value->defining_position().ToString(), \" buffer size: \",\n+          buffer_size, \" within limit: \", block_prefetching_limit_bytes));\n+    }\n+\n+    int64_t start_time = optional_start_time.value();\n+    MsaBufferInterval interval = MsaBufferInterval{/*buffer=*/original_value,\n+                                                   /*size=*/buffer_size,\n+                                                   /*start=*/start_time,\n+                                                   /*end=*/end_time,\n+                                                   /*colocations=*/{},\n+                                                   /*need_allocation=*/true};\n+    Chunk chunk_candidate = FindChunkCandidate(interval);\n+\n+    // The chunk candidate should always be within the block prefetched values\n+    // limit, otherwise we would have returned earlier.\n+    CHECK_LE(chunk_candidate.chunk_end(), block_prefetching_limit_bytes);\n+\n+    // Add a pinned allocation in the default memory to serve as the prev\n+    // allocation for the copy allocation or extend the existing pinned\n+    // allocation.\n+    Allocation* pinned_allocation;\n+    auto pinned_allocation_it = value_to_pinned_allocation.find(original_value);\n+    if (pinned_allocation_it == value_to_pinned_allocation.end()) {\n+      allocations_->push_back(std::make_unique<PinnedAllocation>(\n+          original_value->defining_position(), MemorySpace::kDefault,\n+          kDummyChunk, definition_time, end_time));\n+      pinned_allocation = allocations_->back().get();\n+      value_to_pinned_allocation[original_value] = pinned_allocation;\n+    } else {\n+      pinned_allocation = pinned_allocation_it->second;\n+      pinned_allocation->Extend(end_time);\n+    }\n+\n+    HloInstruction* async_mem_op_start =\n+        prefetch_done_value_to_prefetch_start_instruction[prefetch_done_value];\n+    HloInstruction* asyn_mem_op_done = prefetch_done_value->instruction();\n+\n+    // Add an async slice copy for the block prefetched value value.\n+    AddAsyncCopyOrOtherMemOp(\n+        /*prev_allocation=*/*pinned_allocation,\n+        /*memory_space=*/MemorySpace::kAlternate,\n+        /*chunk=*/chunk_candidate,\n+        /*exclusive_start_time=*/InclusiveToExclusiveStartTime(start_time),\n+        /*end_time=*/end_time,\n+        /*copy_done_schedule_before_time=*/first_use_time,\n+        /*allocations=*/allocations_,\n+        /*aliased_offset=*/nullptr,\n+        /*resource=*/0.0,\n+        /*cross_program_prefetch_index=*/std::nullopt,\n+        /*sync_mem_op=*/nullptr,\n+        /*async_mem_op_start*/ async_mem_op_start,\n+        /*async_mem_op_done=*/asyn_mem_op_done);\n+\n+    previous_start_time = start_time;\n+    auto const sorted_position = std::lower_bound(\n+        prefetch_end_times.begin(), prefetch_end_times.end(), end_time);\n+    prefetch_end_times.insert(sorted_position, end_time);\n+    prefetch_done_schedule_before_times.push_back(first_use_time);\n+\n+    // 1. Commit the chunk to the alternate memory.\n+    AddToPendingChunks(interval, chunk_candidate);\n+\n+    for (const HloUse& use : prefetch_done_value->GetUses()) {\n+      allocations_->back()->AddUse(use);\n+      // 2. Update the operands in alternate memory map.\n+      operands_in_alternate_memory_map_[use.instruction].insert(\n+          std::make_pair(use.operand_number, use.operand_index));\n+    }\n+\n+    // 3. Add the copy done and copy start values to the finalized values set.\n+    finalized_values_.insert(prefetch_done_value);\n+    const HloValue* copy_start_value =\n+        &alias_analysis_.dataflow_analysis().GetUniqueValueAt(\n+            async_mem_op_start, {0});\n+    finalized_values_.insert(copy_start_value);\n+\n+    // 4. Add a repack allocation block to the repack allocation blocks list.\n+    repack_allocation_blocks_.push_back(MakeRepackAllocationBlock(\n+        start_time, end_time, chunk_candidate.size, chunk_candidate.offset,\n+        allocations_->back().get()));\n+    repack_allocation_blocks_.back().next_colocated =\n+        &(repack_allocation_blocks_.back());\n+  }\n+\n+  // 5. Serve the uses of the original value from the pinned allocation in the\n+  //    default memory.\n+  for (auto [_, original_value] : prefetch_done_value_to_original_value) {\n+    Allocation* allocation = value_to_pinned_allocation[original_value];\n+    for (const HloUse& use : original_value->GetUses()) {\n+      allocation->AddUse(use);\n+    }\n+    finalized_values_.insert(original_value);\n+  }\n+\n+  // 6. Clear the pending chunks.\n+  ClearPendingChunks();\n+  return absl::OkStatus();\n+}\n+\n+absl::Status MsaAlgorithm::CreateNewBlockPrefetches() {\n+  if (!options_.hlo_position_to_custom_call_prefetch_details.empty() ||\n+      options_.reserved_bytes_for_block_prefetches <= 0) {\n     return absl::OkStatus();\n   }\n+\n   absl::flat_hash_set<HloPosition> aliased_parameter_positions =\n       GetParameterInstructionsAliasedToOutput(\n           module_->input_output_alias_config(),\n@@ -2127,38 +2384,52 @@ absl::Status MsaAlgorithm::ProcessBlockPrefetches() {\n   absl::flat_hash_map<const HloValue*, const HloValue*>\n       sliced_value_to_original_value;\n   for (const HloPosition& position : options_.block_prefetched_positions) {\n-    if (aliased_parameter_positions.contains(position)) {\n-      // TODO(b/441344194): Add support for block allocations for parameters\n-      // that are aliased to outputs.\n-      continue;\n-    }\n     const HloValue* value =\n         &alias_analysis_.dataflow_analysis().GetUniqueValueAt(\n             position.instruction, position.index);\n-    block_prefetched_values.push_back(value);\n+    const HloBuffer& buffer = alias_analysis_.GetBufferContainingValue(*value);\n+    if (!aliased_parameter_positions.contains(value->defining_position()) &&\n+        buffer.values().size() == 1) {\n+      block_prefetched_values.push_back(value);\n+    } else if (aliased_parameter_positions.contains(position)) {\n+      // TODO(b/441344194): Add support for block allocations for parameters\n+      // that are aliased to outputs.\n+      LOG(WARNING) << \"Skipping block prefetch for value: \"\n+                   << position.ToString()\n+                   << \" because it is aliased to a program output.\";\n+    } else {\n+      LOG(WARNING) << \"Skipping block prefetch for value: \"\n+                   << position.ToString()\n+                   << \" because it is aliased to multiple values.\";\n+    }\n+\n     // As mentioned above, we also track slices of block prefetched values.\n     for (const HloUse& use : value->GetUses()) {\n       if (use.instruction->opcode() == HloOpcode::kSlice) {\n         const HloValue* slice_value =\n             &alias_analysis_.dataflow_analysis().GetUniqueValueAt(\n                 use.instruction, {});\n+        const HloBuffer& buffer =\n+            alias_analysis_.GetBufferContainingValue(*slice_value);\n+        if (buffer.values().size() > 1) {\n+          VLOG(1) << \"Skipping block prefetch for value: \"\n+                  << value->defining_position().ToString()\n+                  << \" because it is aliased to multiple values.\";\n+          continue;\n+        }\n         block_prefetched_values.push_back(slice_value);\n         sliced_value_to_original_value[slice_value] = value;\n       }\n     }\n   }\n \n   const auto& instruction_schedule = hlo_live_range_.instruction_schedule();\n-  struct LiveRange {\n-    int64_t first_use_time;\n-    int64_t last_use_time;\n-  };\n   // Compute the live ranges for each block prefetched value.\n-  absl::flat_hash_map<const HloValue*, LiveRange> value_to_live_ranges;\n+  absl::flat_hash_map<const HloValue*, UseInterval> value_to_use_intervals;\n   for (const HloValue* value : block_prefetched_values) {\n-    LiveRange& live_range = value_to_live_ranges[value];\n-    live_range.first_use_time = std::numeric_limits<int64_t>::max();\n-    live_range.last_use_time = -1;\n+    UseInterval& use_interval = value_to_use_intervals[value];\n+    use_interval.first_use_time = std::numeric_limits<int64_t>::max();\n+    use_interval.last_use_time = -1;\n     bool is_original_value = !sliced_value_to_original_value.contains(value);\n     for (const HloUse& use : value->GetUses()) {\n       // We skip slices here because they have been explicitly added to\n@@ -2170,62 +2441,70 @@ absl::Status MsaAlgorithm::ProcessBlockPrefetches() {\n       if (it == instruction_schedule.end()) {\n         continue;\n       }\n-      live_range.first_use_time =\n-          std::min(live_range.first_use_time, it->second);\n-      live_range.last_use_time = std::max(live_range.last_use_time, it->second);\n-    }\n-    if (live_range.last_use_time == -1) {\n-      // If the value does not have any direct uses other than slices, we can\n-      // finalize it. Note, slices are handled separately as part of\n-      // block_prefetched_values.\n+      use_interval.first_use_time =\n+          std::min(use_interval.first_use_time, it->second);\n+      use_interval.last_use_time =\n+          std::max(use_interval.last_use_time, it->second);\n+    }\n+  }\n+\n+  // Finalize all the values that have no uses.\n+  for (const auto& [value, use_interval] : value_to_use_intervals) {\n+    if (use_interval.last_use_time == -1) {\n       finalized_values_.insert(value);\n     }\n   }\n \n-  // Erase all the values from block_prefetched_values that are not used\n-  // directly and have been finalized.\n+  // Erase all the values from block_prefetched_values that have been finalized.\n   block_prefetched_values.erase(\n-      std::remove_if(\n-          block_prefetched_values.begin(), block_prefetched_values.end(),\n-          [&](const HloValue* value) {\n-            return value_to_live_ranges.at(value).last_use_time == -1;\n-          }),\n+      std::remove_if(block_prefetched_values.begin(),\n+                     block_prefetched_values.end(),\n+                     [&](const HloValue* value) {\n+                       return finalized_values_.contains(value);\n+                     }),\n       block_prefetched_values.end());\n \n   // Sort block prefetched value values in ascending order of first use time.\n   absl::c_sort(block_prefetched_values,\n                [&](const HloValue* a, const HloValue* b) {\n-                 return value_to_live_ranges.at(a).first_use_time <\n-                        value_to_live_ranges.at(b).first_use_time;\n+                 return value_to_use_intervals.at(a).first_use_time <\n+                        value_to_use_intervals.at(b).first_use_time;\n                });\n \n   // Block allocations can also happen in the fragmented scoped memory, so we\n   // need to account for the max reserved scoped memory in the block prefetched\n   // memory limit.\n-  int64_t max_reserved_scoped_memory = MaxReservedScopedMemory();\n+  int64_t block_prefetching_starting_offset = MaxScopedMemoryOffset();\n   int64_t block_prefetching_limit_bytes =\n-      max_reserved_scoped_memory + options_.reserved_bytes_for_block_prefetches;\n+      block_prefetching_starting_offset +\n+      options_.reserved_bytes_for_block_prefetches;\n   CHECK_LE(block_prefetching_limit_bytes, options_.max_size_in_bytes);\n   VLOG(1) << \"block prefetched values bytes limit: \"\n           << block_prefetching_limit_bytes;\n-\n-  // To ensure fifo ordering, we need to ensure that the prefetch start time of\n-  // each block prefetched value is greater than or equal to the previous block\n-  // prefetched value's prefetch start time. We are traversing these is\n-  // ascending order of use time, so the previous prefetchs start time will\n-  // always be less than or equal to the current prefetchs use time.\n   int64_t previous_start_time = -1;\n   int64_t max_in_flight_prefetches_allowed =\n       options_.max_outstanding_block_prefetches;\n   std::vector<int64_t> prefetch_end_times;\n-  std::vector<int64_t> copy_done_schedule_before_times;\n+  std::vector<int64_t> prefetch_done_schedule_before_times;\n \n   absl::flat_hash_map<const HloValue*, Allocation*> value_to_pinned_allocation;\n \n+  // For each block prefetched value, we try to find a chunk within the block\n+  // prefetching limit, ensuring FIFO ordering. After a suitable chunk is found\n+  // for a block prefetched value, we:\n+  // 1. Commit the chunk to the alternate memory.\n+  // 2. Update the operands in alternate memory map.\n+  // 3. Add the value to the finalized values set.\n+  // 4. Add a repack allocation block to the repack allocation blocks list.\n+  // Outside the loop:\n+  // 5. Finalize the original sources of the sliced values that have not yet\n+  //    been finalized, so we don't try to process those sources again, outside\n+  //    of block prefetching.\n+  // 6. Clear the pending chunks after the loop.\n   for (const HloValue* maybe_sliced_value : block_prefetched_values) {\n-    LiveRange live_range = value_to_live_ranges.at(maybe_sliced_value);\n-    int64_t first_use_time = live_range.first_use_time;\n-    int64_t last_use_time = live_range.last_use_time;\n+    UseInterval use_interval = value_to_use_intervals.at(maybe_sliced_value);\n+    int64_t first_use_time = use_interval.first_use_time;\n+    int64_t last_use_time = use_interval.last_use_time;\n     auto it = sliced_value_to_original_value.find(maybe_sliced_value);\n     const HloValue* original_value;\n     if (it != sliced_value_to_original_value.end()) {\n@@ -2242,7 +2521,7 @@ absl::Status MsaAlgorithm::ProcessBlockPrefetches() {\n     std::optional<int64_t> optional_start_time = EarliestBlockPrefetchStartTime(\n         previous_start_time, definition_time, first_use_time, end_time,\n         buffer_size, block_prefetching_limit_bytes,\n-        max_in_flight_prefetches_allowed, copy_done_schedule_before_times,\n+        max_in_flight_prefetches_allowed, prefetch_done_schedule_before_times,\n         prefetch_end_times);\n \n     if (!optional_start_time.has_value()) {\n@@ -2252,8 +2531,8 @@ absl::Status MsaAlgorithm::ProcessBlockPrefetches() {\n                    << \" within limit: \" << block_prefetching_limit_bytes;\n       continue;\n     }\n-    int64_t start_time = optional_start_time.value();\n \n+    int64_t start_time = optional_start_time.value();\n     MsaBufferInterval interval = MsaBufferInterval{/*buffer=*/original_value,\n                                                    /*size=*/buffer_size,\n                                                    /*start=*/start_time,\n@@ -2304,16 +2583,9 @@ absl::Status MsaAlgorithm::ProcessBlockPrefetches() {\n     auto const sorted_position = std::lower_bound(\n         prefetch_end_times.begin(), prefetch_end_times.end(), end_time);\n     prefetch_end_times.insert(sorted_position, end_time);\n-    copy_done_schedule_before_times.push_back(first_use_time);\n-\n-    // Bookkeeping Checklist:\n-    // Commit the chunk to the alternate memory.\n-    // Add entries to operands in alternate memory map.\n-    // Add the value to the finalized values set.\n-    // Add a repack allocation block to the repack allocation blocks list.\n-    // Clear the pending chunks.\n+    prefetch_done_schedule_before_times.push_back(first_use_time);\n \n-    // Commit the chunk to the alternate memory.\n+    // 1. Commit the chunk to the alternate memory.\n     AddToPendingChunks(interval, chunk_candidate);\n \n     for (const HloUse& use : maybe_sliced_value->GetUses()) {\n@@ -2324,23 +2596,24 @@ absl::Status MsaAlgorithm::ProcessBlockPrefetches() {\n         continue;\n       }\n       allocations_->back()->AddUse(use);\n-      // Add entries to operands in alternate memory map.\n+      // 2. Update the operands in alternate memory map.\n       operands_in_alternate_memory_map_[use.instruction].insert(\n           std::make_pair(use.operand_number, use.operand_index));\n     }\n \n-    // Add the value to the finalized values set.\n+    // 3. Add the value to the finalized values set.\n     finalized_values_.insert(maybe_sliced_value);\n-    // Add a repack allocation block to the repack allocation blocks list.\n+    // 4. Add a repack allocation block to the repack allocation blocks list.\n     repack_allocation_blocks_.push_back(MakeRepackAllocationBlock(\n         start_time, end_time, chunk_candidate.size, chunk_candidate.offset,\n         allocations_->back().get()));\n     repack_allocation_blocks_.back().next_colocated =\n         &(repack_allocation_blocks_.back());\n   }\n \n-  // Finalize the original values of the sliced values that are not finalized\n-  // yet to avoid being allocated twice.\n+  // 5. Finalize the original sources of the sliced values that have not yet\n+  //    been finalized, so we don't try to process those sources again, outside\n+  //    of block prefetching.\n   for (auto [_, original_value] : sliced_value_to_original_value) {\n     if (finalized_values_.contains(original_value)) {\n       continue;\n@@ -2352,7 +2625,7 @@ absl::Status MsaAlgorithm::ProcessBlockPrefetches() {\n     finalized_values_.insert(original_value);\n   }\n \n-  // Clear the pending chunks.\n+  // 6. Clear the pending chunks.\n   ClearPendingChunks();\n   return absl::OkStatus();\n }\n@@ -2370,7 +2643,9 @@ absl::StatusOr<HeapSimulator::Result<HloValue>> MsaAlgorithm::Finish() {\n                                                                  : \"disabled\");\n \n   AllocateReservedScopedAllocations();\n-  TF_RETURN_IF_ERROR(ProcessBlockPrefetches());\n+\n+  TF_RETURN_IF_ERROR(AllocateAndScheduleExistingBlockPrefetches());\n+  TF_RETURN_IF_ERROR(CreateNewBlockPrefetches());\n \n   std::vector<MsaBufferInterval> sorted_buffer_intervals =\n       GetSortedBufferIntervals();\n@@ -5969,7 +6244,8 @@ void MsaAlgorithm::AddAsyncCopyOrOtherMemOp(\n     int64_t copy_done_schedule_before_time, AllocationSequence* allocations,\n     AliasedOffset* aliased_offset, float resource,\n     std::optional<int> cross_program_prefetch_index,\n-    HloInstruction* sync_mem_op) {\n+    HloInstruction* sync_mem_op, HloInstruction* async_mem_op_start,\n+    HloInstruction* async_mem_op_done) {\n   VLOG(3) << \"Copy to \"\n           << (memory_space == MemorySpace::kDefault ? \"default\" : \"alternate\")\n           << \" memory in (\" << exclusive_start_time << \", \"\n@@ -5980,7 +6256,7 @@ void MsaAlgorithm::AddAsyncCopyOrOtherMemOp(\n   allocations->push_back(std::make_unique<CopyAllocation>(\n       prev_allocation, memory_space, chunk, exclusive_start_time,\n       copy_done_schedule_before_time, end_time, cross_program_prefetch_index,\n-      sync_mem_op));\n+      sync_mem_op, async_mem_op_start, async_mem_op_done));\n \n   RegisterAsyncCopy(memory_space, exclusive_start_time,\n                     copy_done_schedule_before_time, allocations, aliased_offset,"
        },
        {
            "sha": "048a8cc389e349a20226e0af9337ac4f90f719e2",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.h",
            "status": "modified",
            "additions": 26,
            "deletions": 5,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h?ref=14710459b60801e07b9c8cb85a27ad58c9b013bc",
            "patch": "@@ -334,12 +334,27 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n \n   absl::StatusOr<HeapSimulator::Result<HloValue>> Finish() override;\n \n-  // Processes all block prefetches.\n-  absl::Status ProcessBlockPrefetches();\n+  // Block prefetching is an MSA feature that allows processing all prefetches\n+  // in one pass within a block of memory space in the alternate memory. This\n+  // guarantees FIFO ordering of all prefetches and allows for more aggressive\n+  // prefetching i.e. allowing for bandwidth saturation.\n+\n+  // Processes existing, explicit block prefetched copy start/done instructions.\n+  // Such instructions are inserted before MSA. MSA just needs to schedule them.\n+  //\n+  // REQUIRED: Scoped vmem must be allocated at offset 0 at the time this method\n+  //           is called.\n+  absl::Status AllocateAndScheduleExistingBlockPrefetches();\n+\n+  // Create, allocate and schedule new block prefetches.\n+  //\n+  // REQUIRED: Scoped vmem must be allocated at offset 0 at the time this method\n+  //           is called.\n+  absl::Status CreateNewBlockPrefetches();\n \n   // Returns the maximum amount of scoped memory that is reserved at any time in\n   // the program.\n-  int64_t MaxReservedScopedMemory();\n+  int64_t MaxScopedMemoryOffset();\n \n   // Finds and returns the earliest block prefetch start time subject to the\n   // following constraints:\n@@ -974,15 +989,21 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n   // allocations. We pass sync_mem_op to the CopyAllocation constructor. When\n   // sync_mem_op is set, instead of an async copy, CopyAllocation::Process()\n   // will replace sync_mem_op with the async version of sync_mem_op's opcode\n-  // (e.g., slice) and shape.\n+  // (e.g., slice) and shape. Generally, MSA inserts and schedules new async\n+  // copy instructions. If async copy instructions are already present in the\n+  // original schedule, MSA will just schedule them in correct positions. If not\n+  // null, `async_mem_op_start` and `async_mem_op_done` are async copy start and\n+  // done instructions that are already present in the original schedule.\n   void AddAsyncCopyOrOtherMemOp(\n       Allocation& prev_allocation, MemorySpace memory_space,\n       std::optional<Chunk> chunk, int64_t exclusive_start_time,\n       int64_t end_time, int64_t copy_done_schedule_before_time,\n       AllocationSequence* allocations, AliasedOffset* aliased_offset,\n       float resource,\n       std::optional<int> cross_program_prefetch_index = std::nullopt,\n-      HloInstruction* sync_mem_op = nullptr);\n+      HloInstruction* sync_mem_op = nullptr,\n+      HloInstruction* async_mem_op_start = nullptr,\n+      HloInstruction* async_mem_op_done = nullptr);\n \n   // For prefetching, adds a SlicedCopyAllocation to allocations. Also updates\n   // asynchronous copy data structures, prefetch_interval_tree_, and aliasing"
        },
        {
            "sha": "ee494918bc7fa30733334bfbaa3a22277ba31895",
            "filename": "third_party/xla/xla/service/memory_space_assignment/allocation.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 8,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.cc?ref=14710459b60801e07b9c8cb85a27ad58c9b013bc",
            "patch": "@@ -376,7 +376,8 @@ CopyAllocation::CopyAllocation(\n     int64_t copy_start_schedule_after_time,\n     int64_t copy_done_schedule_before_time, int64_t end_time,\n     std::optional<int64_t> cross_program_prefetch_index,\n-    HloInstruction* sync_mem_op)\n+    HloInstruction* sync_mem_op, HloInstruction* async_mem_op_start,\n+    HloInstruction* async_mem_op_done)\n     : Allocation(\n           /*defining_position=*/{nullptr, {}}, memory_space, chunk,\n           // Allocation uses an inclusive start time\n@@ -385,13 +386,26 @@ CopyAllocation::CopyAllocation(\n       prev_allocation_(prev_allocation),\n       copy_start_schedule_after_(copy_start_schedule_after_time),\n       copy_done_schedule_before_(copy_done_schedule_before_time),\n+      copy_start_(async_mem_op_start),\n+      copy_done_(async_mem_op_done),\n       sync_mem_op_(sync_mem_op) {}\n \n int64_t CopyAllocation::earliest_available_time() const {\n   return copy_done_schedule_before_;\n }\n \n absl::Status CopyAllocation::Process(const BitcastSplitFn& bitcast_split_fn) {\n+  // If the copy start and copy done instructions are already present in the\n+  // original schedule we just need to schedule them in correct positions. There\n+  // is no need to create new instructions.\n+  if (copy_start_ != nullptr && copy_done_ != nullptr) {\n+    // Update the allocation position with the copy complete instruction, so\n+    // that if there are further copies from it, they can find the correct\n+    // position.\n+    set_original_defining_position(HloPosition{copy_start_, {0}});\n+    return absl::OkStatus();\n+  }\n+\n   // Copy allocations need to insert asynchronous copy nodes.\n   Shape shape = defining_position().shape();\n   HloInstruction* producing_instruction = AddGetTupleElements();\n@@ -457,13 +471,16 @@ std::string CopyAllocation::ToString() const {\n     absl::StrAppend(&memory_space_str, \" (off: \", chunk->offset,\n                     \", size: \", chunk->size, \")\");\n   }\n-  return absl::StrCat(\"Copy Allocation in \", memory_space_str,\n-                      \", start_time:\", start_time(), \", end_time:\", end_time(),\n-                      \", copy_start_after_time: \", copy_start_schedule_after(),\n-                      \", copy_done_before_time: \", copy_done_schedule_before(),\n-                      \", uses: \", UsesToString(uses()), \", sync_mem_op: \",\n-                      sync_mem_op_ ? sync_mem_op_->name() : \"none\", \", from \",\n-                      prev_allocation_.ToString());\n+  return absl::StrCat(\n+      \"Copy Allocation in \", memory_space_str, \", start_time:\", start_time(),\n+      \", end_time:\", end_time(),\n+      \", copy_start_after_time: \", copy_start_schedule_after(),\n+      \", copy_done_before_time: \", copy_done_schedule_before(),\n+      \", uses: \", UsesToString(uses()),\n+      \", existing sync_mem_op: \", sync_mem_op_ ? sync_mem_op_->name() : \"none\",\n+      \", existing copy_start: \", copy_start_ ? copy_start_->name() : \"none\",\n+      \", existing copy_done: \", copy_done_ ? copy_done_->name() : \"none\",\n+      \", from \", prev_allocation_.ToString());\n }\n \n HloPosition CopyAllocation::defining_position() const {"
        },
        {
            "sha": "20f4a7e23950385ec005e6fd041f06c1fe0a674e",
            "filename": "third_party/xla/xla/service/memory_space_assignment/allocation.h",
            "status": "modified",
            "additions": 20,
            "deletions": 7,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.h?ref=14710459b60801e07b9c8cb85a27ad58c9b013bc",
            "patch": "@@ -287,10 +287,21 @@ class ReservedAllocation final : public Allocation {\n   bool reserved_;\n };\n \n-// This class represents an allocation as a result of an asynchronous copy.\n-// Note: CopyStart instructions are inserted after\n-// `copy_start_schedule_after`, while CopyDone instructions are inserted\n-// before `copy_done_schedule_before_time`.\n+// This class represents an allocation as a result of a single asynchronous\n+// data movement operation. The data movement operation is a copy, except when\n+// certain arguments are set, as described below.\n+// * CopyStart instructions are inserted after `copy_start_schedule_after`,\n+//   while CopyDone instructions are inserted before\n+//   `copy_done_schedule_before_time`.\n+// * When `sync_mem_op` is set, it points to a sync data movement instruction\n+//   that we intend to turn into an asynchronous data movement operation.\n+// * When `async_mem_op_start` and `async_mem_op_done` are set, it indicates\n+//   that an asynchronous data movement operation already exists, but MSA\n+//   needs to appropriately schedule the operation.\n+// * If `sync_mem_op` is non-null, `async_mem_op_start` and `async_mem_op_done`\n+//   must be null.\n+// * If are `async_mem_op_start` and `async_mem_op_done` are non-null,\n+//   `sync_mem_op` must be null.\n class CopyAllocation final : public Allocation {\n  public:\n   CopyAllocation(\n@@ -299,7 +310,9 @@ class CopyAllocation final : public Allocation {\n       int64_t copy_start_schedule_after_time,\n       int64_t copy_done_schedule_before_time, int64_t end_time,\n       std::optional<int64_t> cross_program_prefetch_index = std::nullopt,\n-      HloInstruction* sync_mem_op = nullptr);\n+      HloInstruction* sync_mem_op = nullptr,\n+      HloInstruction* async_mem_op_start = nullptr,\n+      HloInstruction* async_mem_op_done = nullptr);\n \n   // Overridden methods\n   //\n@@ -352,8 +365,8 @@ class CopyAllocation final : public Allocation {\n   HloInstruction* sync_mem_op_ = nullptr;\n };\n \n-// This class represents an allocation resulting from asynchronous sliced\n-// copies.\n+// This class represents an allocation resulting from a collection of\n+// asynchronous sliced copies that work together to copy a single tensor.\n //\n // Let the sliced allocation be represented as follows, and imagine that t3\n // is the time when the entire buffer [p0, p3) is available for use"
        },
        {
            "sha": "3ac208f21c02924debc5b457111b989d9cebde95",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.cc",
            "status": "modified",
            "additions": 26,
            "deletions": 1,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.cc?ref=14710459b60801e07b9c8cb85a27ad58c9b013bc",
            "patch": "@@ -1068,6 +1068,30 @@ absl::Status MemorySpaceAssignment::FixSchedule() {\n     computation_to_stats[computation] = {};\n   }\n \n+  // This set contains instructions that should be ignored when iterating\n+  // through `flattened_instructions_` to build the new schedule.  MSA adds new\n+  // asynchronous copy instructions (e.g., `copy-start`, `copy-done`) and\n+  // decides to schedule them before or after a certain instruction as an\n+  // anchor. For each instruction in the schedule, it first schedules the\n+  // instructions that are supposed to be scheduled before the current\n+  // instruction, then the current instruction and finally the instructions that\n+  // are supposed to be scheduled after the current instruction. If the \"anchor\"\n+  // instruction itself is scheduled relative to another instruction, we skip\n+  // it when iterating over the original schedule.\n+  absl::flat_hash_set<HloInstruction*> pass_over_instructions;\n+  for (const auto& [_, custom_call_prefetch_details] :\n+       options_.hlo_position_to_custom_call_prefetch_details) {\n+    for (const auto& custom_call_prefetch_detail :\n+         custom_call_prefetch_details) {\n+      pass_over_instructions.insert(custom_call_prefetch_detail.prefetch_start);\n+      pass_over_instructions.insert(custom_call_prefetch_detail.prefetch_done);\n+      for (const auto& intermediate_instruction :\n+           custom_call_prefetch_detail.intermediate_instructions) {\n+        pass_over_instructions.insert(intermediate_instruction);\n+      }\n+    }\n+  }\n+\n   // Create the schedule for all computations at the same time, by first\n   // scheduling the before instructions, then the current instruction and\n   // finally the after instructions (each in its respective computation).\n@@ -1101,7 +1125,8 @@ absl::Status MemorySpaceAssignment::FixSchedule() {\n       // dependencies.\n       if (instruction != nullptr &&\n           instruction->opcode() != HloOpcode::kBitcast &&\n-          instruction->opcode() != HloOpcode::kTuple) {\n+          instruction->opcode() != HloOpcode::kTuple &&\n+          !pass_over_instructions.contains(instruction)) {\n         HloComputation* computation = instruction->parent();\n         if (computation_to_stats.contains(computation)) {\n           ComputationStats& stats = computation_to_stats[computation];"
        },
        {
            "sha": "c582ecb70371ddb03dd60b1520a58dc572413593",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc",
            "status": "modified",
            "additions": 195,
            "deletions": 0,
            "changes": 195,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc?ref=14710459b60801e07b9c8cb85a27ad58c9b013bc",
            "patch": "@@ -15426,6 +15426,201 @@ ENTRY entry {\n   EXPECT_EQ(num_prefetches, 6);\n }\n \n+TEST_F(MemorySpaceAssignmentTest, TestScheduleCustomCallPrefetchesBasic) {\n+  absl::string_view hlo_string = R\"(\n+HloModule module, is_scheduled=true\n+\n+ENTRY entry {\n+  param0 = f32[2,1,3]{2,1,0} parameter(0), sharding={replicated}\n+\n+  prefetch_start_param0 = (f32[2,1,3]{2,1,0:S(1)}, s32[]{:T(128)S(2)}) custom-call(param0), custom_call_target=\"tpu_custom_call\"\n+  gte_param0_0 = f32[2,1,3]{2,1,0:S(1)} get-tuple-element(prefetch_start_param0), index=0\n+  gte_param0_1 = s32[]{:T(128)S(2)} get-tuple-element(prefetch_start_param0), index=1\n+  prefetch_done_param0 = f32[2,1,3]{2,1,0:S(1)} custom-call(param0, gte_param0_0, gte_param0_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  first_slice_prefetch_start_param0 = (f32[1,1,3]{2,1,0:S(1)}, s32[]{:T(128)S(2)}) custom-call(param0), custom_call_target=\"tpu_custom_call\"\n+  first_slice_gte_param0_0 = f32[1,1,3]{2,1,0:S(1)} get-tuple-element(first_slice_prefetch_start_param0), index=0\n+  first_slice_gte_param0_1 = s32[]{:T(128)S(2)} get-tuple-element(first_slice_prefetch_start_param0), index=1\n+  first_slice_prefetch_done_param0 = f32[1,1,3]{2,1,0:S(1)} custom-call(param0, first_slice_gte_param0_0, first_slice_gte_param0_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  second_slice_prefetch_start_param0 = (f32[1,1,3]{2,1,0:S(1)}, s32[]{:T(128)S(2)}) custom-call(param0), custom_call_target=\"tpu_custom_call\"\n+  second_slice_gte_param0_0 = f32[1,1,3]{2,1,0:S(1)} get-tuple-element(second_slice_prefetch_start_param0), index=0\n+  second_slice_gte_param0_1 = s32[]{:T(128)S(2)} get-tuple-element(second_slice_prefetch_start_param0), index=1\n+  second_slice_prefetch_done_param0 = f32[1,1,3]{2,1,0:S(1)} custom-call(param0, second_slice_gte_param0_0, second_slice_gte_param0_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  negate_param0 = f32[2,1,3]{2,1,0} negate(prefetch_done_param0)\n+  add_param0 = f32[2,1,3]{2,1,0} add(prefetch_done_param0, negate_param0)\n+  negate_param0_first_slice = f32[1,1,3]{2,1,0} negate(first_slice_prefetch_done_param0)\n+  add_param0_first_slice = f32[1,1,3]{2,1,0} add(first_slice_prefetch_done_param0, negate_param0_first_slice)\n+  negate_param0_second_slice = f32[1,1,3]{2,1,0} negate(second_slice_prefetch_done_param0)\n+  add_param0_second_slice = f32[1,1,3]{2,1,0} add(second_slice_prefetch_done_param0, negate_param0_second_slice)\n+  ROOT tuple = (f32[2,1,3]{2,1,0}, f32[1,1,3]{2,1,0}, f32[1,1,3]{2,1,0}) tuple(add_param0, add_param0_first_slice, add_param0_second_slice)\n+})\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+\n+  Options memory_space_options = DefaultMemorySpaceOptions();\n+  memory_space_options.max_size_in_bytes = 200;\n+  memory_space_options.reserved_bytes_for_block_prefetches = 200;\n+  memory_space_options.max_outstanding_block_prefetches = 10;\n+  memory_space_options.max_outstanding_prefetches = 0;\n+\n+  std::vector<CustomCallPrefetchInfo> custom_call_prefetch_instructions = {\n+      {\"param0\", \"prefetch_start_param0\", \"prefetch_done_param0\"},\n+      {\"param0\", \"first_slice_prefetch_start_param0\",\n+       \"first_slice_prefetch_done_param0\"},\n+      {\"param0\", \"second_slice_prefetch_start_param0\",\n+       \"second_slice_prefetch_done_param0\"}};\n+\n+  memory_space_options.hlo_position_to_custom_call_prefetch_details =\n+      GetCustomCallPrefetchDetailsMap(/*module=*/module.get(),\n+                                      /*custom_call_prefetch_instructions=*/\n+                                      custom_call_prefetch_instructions);\n+\n+  XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n+  XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n+\n+  std::vector<std::string> prefetch_uses = {\n+      \"add_param0\",\n+      \"add_param0_first_slice\",\n+      \"add_param0_second_slice\",\n+      \"negate_param0\",\n+      \"negate_param0_first_slice\",\n+      \"negate_param0_second_slice\",\n+  };\n+\n+  // Check that all uses of custom call prefetches are in alternate memory\n+  // space.\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/prefetch_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kCustomCall,\n+      /*operand_memory_space=*/kAlternateMemorySpace);\n+}\n+\n+TEST_F(MemorySpaceAssignmentTest,\n+       TestScheduleCustomCallPrefetchesWithMultipleUses) {\n+  // params p0, p1, p2 have sliced and non-sliced custom call prefetches.\n+  // slice_done_1 and prefetch_done_0 have multiple uses.\n+  // p0, p1 and p2 have uses apart from the custom call prefetches.\n+  absl::string_view hlo_string = R\"(\n+HloModule module, is_scheduled=true\n+\n+ENTRY entry {\n+  p0 = f32[4,3]{1,0} parameter(0)\n+  p1 = f32[4,3]{1,0} parameter(1)\n+  p2 = f32[4,3]{1,0} parameter(2)\n+\n+  prefetch_start0 = (f32[4,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p0), custom_call_target=\"tpu_custom_call\"\n+  prefetch_start0_gte_0 = f32[4,3]{1,0} get-tuple-element(prefetch_start0), index=0\n+  prefetch_start0_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(prefetch_start0), index=1\n+  prefetch_done_0 = f32[4,3]{1,0} custom-call(p0, prefetch_start0_gte_0, prefetch_start0_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+\n+  slice_start_0 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p0), custom_call_target=\"tpu_custom_call\"\n+  slice_start_0_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_0), index=0\n+  slice_start_0_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_0), index=1\n+  slice_done_0 = f32[2,3]{1,0} custom-call(p0, slice_start_0_gte_0, slice_start_0_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  slice_start_1 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p1), custom_call_target=\"tpu_custom_call\"\n+  slice_start_1_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_1), index=0\n+  slice_start_1_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_1), index=1\n+  slice_done_1 = f32[2,3]{1,0} custom-call(p1, slice_start_1_gte_0, slice_start_1_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  slice_start_2 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p2), custom_call_target=\"tpu_custom_call\"\n+  slice_start_2_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_2), index=0\n+  slice_start_2_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_2), index=1\n+  slice_done_2 = f32[2,3]{1,0} custom-call(p2, slice_start_2_gte_0, slice_start_2_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  slice_start_3 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p0), custom_call_target=\"tpu_custom_call\"\n+  slice_start_3_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_3), index=0\n+  slice_start_3_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_3), index=1\n+  slice_done_3 = f32[2,3]{1,0} custom-call(p0, slice_start_3_gte_0, slice_start_3_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  slice_start_4 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p1), custom_call_target=\"tpu_custom_call\"\n+  slice_start_4_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_4), index=0\n+  slice_start_4_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_4), index=1\n+  slice_done_4 = f32[2,3]{1,0} custom-call(p1, slice_start_4_gte_0, slice_start_4_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  slice_start_5 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p2), custom_call_target=\"tpu_custom_call\"\n+  slice_start_5_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_5), index=0\n+  slice_start_5_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_5), index=1\n+  slice_done_5 = f32[2,3]{1,0} custom-call(p2, slice_start_5_gte_0, slice_start_5_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  negate0 = f32[2,3]{1,0} negate(slice_done_0)\n+  negate1 = f32[2,3]{1,0} negate(negate0)\n+  negate2 = f32[2,3]{1,0} negate(negate1)\n+  add3 = f32[2,3]{1,0} add(slice_done_1, negate2)\n+  negate4 = f32[2,3]{1,0} negate(add3)\n+  negate5 = f32[2,3]{1,0} negate(negate4)\n+  add6 = f32[2,3]{1,0} add(slice_done_2, negate5)\n+  negate7 = f32[2,3]{1,0} negate(add6)\n+  negate8 = f32[2,3]{1,0} negate(negate7)\n+  add9 = f32[2,3]{1,0} add(slice_done_3, negate8)\n+  negate10 = f32[2,3]{1,0} negate(add9)\n+  add11 = f32[2,3]{1,0} add(slice_done_1, negate10)\n+  add12 = f32[2,3]{1,0} add(slice_done_4, add11)\n+  negate13 = f32[2,3]{1,0} negate(add12)\n+  negate14 = f32[2,3]{1,0} negate(negate13)\n+  add15 = f32[2,3]{1,0} add(slice_done_5, negate14)\n+  negate16 = f32[4,3]{1,0} negate(prefetch_done_0)\n+  add17 = f32[4,3]{1,0} add(prefetch_done_0, negate16)\n+  add18 = f32[4,3]{1,0} add(p0, add17)\n+  add19 = f32[4,3]{1,0} add(p1, add18)\n+  add20 = f32[4,3]{1,0} add(p2, add19)\n+  ROOT tuple = (f32[4,3]{1,0}, f32[2,3]{1,0}) tuple(add20, add15)\n+})\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+\n+  Options memory_space_options = DefaultMemorySpaceOptions();\n+  memory_space_options.max_size_in_bytes = 96;\n+  memory_space_options.reserved_bytes_for_block_prefetches = 96;\n+  memory_space_options.max_outstanding_block_prefetches = 10;\n+  memory_space_options.max_outstanding_prefetches = 0;\n+  memory_space_options.verify = true;\n+\n+  std::vector<CustomCallPrefetchInfo> custom_call_prefetch_instructions = {\n+      {\"p0\", \"prefetch_start0\", \"prefetch_done_0\"},\n+      {\"p0\", \"slice_start_0\", \"slice_done_0\"},\n+      {\"p0\", \"slice_start_3\", \"slice_done_3\"},\n+      {\"p1\", \"slice_start_1\", \"slice_done_1\"},\n+      {\"p1\", \"slice_start_4\", \"slice_done_4\"},\n+      {\"p2\", \"slice_start_2\", \"slice_done_2\"},\n+      {\"p2\", \"slice_start_5\", \"slice_done_5\"}};\n+\n+  memory_space_options.hlo_position_to_custom_call_prefetch_details =\n+      GetCustomCallPrefetchDetailsMap(/*module=*/module.get(),\n+                                      /*custom_call_prefetch_instructions=*/\n+                                      custom_call_prefetch_instructions);\n+\n+  XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n+  XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n+\n+  // Check that all uses of custom call prefetches are in alternate memory\n+  // space.\n+  std::vector<std::string> prefetched_uses = {\"negate0\", \"add3\",     \"add6\",\n+                                              \"add9\",    \"add11\",    \"add12\",\n+                                              \"add15\",   \"negate16\", \"add17\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/prefetched_uses,\n+      /*operand_index=*/0,\n+      /*operand_opcode=*/HloOpcode::kCustomCall,\n+      /*operand_memory_space=*/kAlternateMemorySpace);\n+\n+  // Check that all direct uses of parameters are in default memory space.\n+  std::vector<std::string> direct_uses = {\"add18\", \"add19\", \"add20\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/direct_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kParameter,\n+      /*operand_memory_space=*/kDefaultMemorySpace);\n+}\n+\n TEST_F(SlicedPrefetchTest, TestMultiplePinnedAllocationsBug) {\n   // When block prefetching, finalize the original value if a sliced value is\n   // prefetched successfully and the original value is not, if not finalized it"
        },
        {
            "sha": "5facb9e56b756ec2f3d9176e06800cb061d27398",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test_base.h",
            "status": "modified",
            "additions": 38,
            "deletions": 0,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test_base.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/14710459b60801e07b9c8cb85a27ad58c9b013bc/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test_base.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test_base.h?ref=14710459b60801e07b9c8cb85a27ad58c9b013bc",
            "patch": "@@ -391,6 +391,44 @@ class MemorySpaceAssignmentTestBase : public HloTestBase {\n     return block_prefetched_positions;\n   }\n \n+  struct CustomCallPrefetchInfo {\n+    std::string prefetched_instruction_name;\n+    std::string prefetch_start_instruction_name;\n+    std::string prefetch_done_instruction_name;\n+  };\n+\n+  // Returns a map of HloPositions to CustomCallPrefetchDetails for the given\n+  // custom call prefetch instructions.\n+  absl::flat_hash_map<HloPosition, std::vector<CustomCallPrefetchDetails>>\n+  GetCustomCallPrefetchDetailsMap(\n+      const HloModule* module,\n+      std::vector<CustomCallPrefetchInfo> custom_call_prefetch_instructions) {\n+    absl::flat_hash_map<HloPosition, std::vector<CustomCallPrefetchDetails>>\n+        hlo_position_to_custom_call_prefetch_details;\n+    for (const auto& info : custom_call_prefetch_instructions) {\n+      HloInstruction* param =\n+          FindInstruction(module, info.prefetched_instruction_name);\n+      EXPECT_NE(param, nullptr);\n+      HloPosition param_position{param, {}};\n+      HloInstruction* prefetch_start =\n+          FindInstruction(module, info.prefetch_start_instruction_name);\n+      EXPECT_NE(prefetch_start, nullptr);\n+      HloInstruction* prefetch_done =\n+          FindInstruction(module, info.prefetch_done_instruction_name);\n+      EXPECT_NE(prefetch_done, nullptr);\n+\n+      CustomCallPrefetchDetails details{/*prefetch_start=*/prefetch_start,\n+                                        /*prefetch_done=*/prefetch_done,\n+                                        /*intermediate_instructions=*/\n+                                        {prefetch_done->mutable_operand(1),\n+                                         prefetch_done->mutable_operand(2)}};\n+\n+      hlo_position_to_custom_call_prefetch_details[param_position].push_back(\n+          details);\n+    }\n+    return hlo_position_to_custom_call_prefetch_details;\n+  }\n+\n   // Checks for every instruction in instruction_names that the operand at\n   // operand_index has the given opcode and memory space.\n   void CheckOperandOpcodeAndMemorySpaceForInstructionNames("
        }
    ],
    "stats": {
        "total": 765,
        "additions": 675,
        "deletions": 90
    }
}