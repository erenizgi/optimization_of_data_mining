{
    "author": "ermilovmaxim",
    "message": "Introduce debug buffer saver inserter to thunk rewriter\n\nPiperOrigin-RevId: 834060787",
    "sha": "f7ba7e3431e9d77c8cd98a8894f31d08a487407d",
    "files": [
        {
            "sha": "981682d9fba4b3bb5040cb98a0a08beb4c440c45",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=f7ba7e3431e9d77c8cd98a8894f31d08a487407d",
            "patch": "@@ -3001,19 +3001,22 @@ cc_library(\n         \"thunk_buffer_debug_filter.cc\",\n         \"thunk_buffer_debug_float_check.cc\",\n         \"thunk_buffer_debug_pass.cc\",\n+        \"thunk_buffer_debug_saver_inserter.cc\",\n     ],\n     hdrs = [\n         \"thunk_buffer_debug_checksum.h\",\n         \"thunk_buffer_debug_filter.h\",\n         \"thunk_buffer_debug_float_check.h\",\n         \"thunk_buffer_debug_pass.h\",\n+        \"thunk_buffer_debug_saver_inserter.h\",\n     ],\n     deps = [\n         \":buffer_debug_log_entry_metadata_store\",\n         \":buffer_debug_log_structs\",\n         \":buffers_checksum_thunk\",\n         \":buffers_float_check_thunk\",\n         \":custom_call_thunk\",\n+        \":runtime_intrinsics\",\n         \":sequential_thunk\",\n         \":shaped_slice\",\n         \":thunk\",\n@@ -3043,6 +3046,7 @@ cc_library(\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_googlesource_code_re2//:re2\",\n     ],\n@@ -3056,6 +3060,7 @@ xla_cc_test(\n         \":buffers_float_check_thunk\",\n         \":conditional_thunk\",\n         \":custom_call_thunk\",\n+        \":runtime_intrinsics\",\n         \":sequential_thunk\",\n         \":thunk\",\n         \":thunk_buffer_debug_pass\",\n@@ -3068,7 +3073,9 @@ xla_cc_test(\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/stream_executor:device_description\",\n+        \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_googletest//:gtest_main\","
        },
        {
            "sha": "40dfb17375bfdfb0cdea4749d348765ec6aecd04",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_pass.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass.cc?ref=f7ba7e3431e9d77c8cd98a8894f31d08a487407d",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk_buffer_debug_checksum.h\"\n #include \"xla/backends/gpu/runtime/thunk_buffer_debug_float_check.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_debug_saver_inserter.h\"\n #include \"xla/backends/gpu/runtime/thunk_pass_pipeline.h\"\n #include \"xla/ffi/ffi.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n@@ -52,6 +53,10 @@ absl::StatusOr<bool> ThunkBufferDebugPass::Run(\n       TF_RETURN_IF_ERROR(RunFloatCheckPassInternal(root_thunk, debug_options,\n                                                    hlo_module, allocator));\n       break;\n+    case Mode::kBufferSaver:\n+      TF_RETURN_IF_ERROR(\n+          RunDebugSaverInserter(*root_thunk, debug_options, *hlo_module));\n+      break;\n   }\n \n   return true;"
        },
        {
            "sha": "f99c63158ef65ed879b8e57f9ec675a0c98a2d73",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_pass.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass.h?ref=f7ba7e3431e9d77c8cd98a8894f31d08a487407d",
            "patch": "@@ -33,6 +33,7 @@ class ThunkBufferDebugPass : public ThunkPassInterface {\n   enum class Mode {\n     kChecksum,\n     kFloatChecker,\n+    kBufferSaver,\n   };\n \n   explicit ThunkBufferDebugPass(Mode mode) : mode_(mode) {}"
        },
        {
            "sha": "1f0b15d1dfcef67da4ebd2bc52c6262ca6cbd57f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_pass_test.cc",
            "status": "modified",
            "additions": 55,
            "deletions": 0,
            "changes": 55,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc?ref=f7ba7e3431e9d77c8cd98a8894f31d08a487407d",
            "patch": "@@ -30,8 +30,10 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/buffers_float_check_thunk.h\"\n #include \"xla/backends/gpu/runtime/conditional_thunk.h\"\n #include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n+#include \"xla/backends/gpu/runtime/runtime_intrinsics.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_debug_saver_inserter.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/backends/gpu/runtime/thunk_pass_pipeline.h\"\n #include \"xla/backends/gpu/runtime/while_thunk.h\"\n@@ -43,7 +45,9 @@ limitations under the License.\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/stream_executor/device_description.h\"\n+#include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n \n namespace xla {\n namespace gpu {\n@@ -519,6 +523,57 @@ TEST_F(ThunkBufferDebugPassTest, InsertsBuffersDebugFloatCheckThunks) {\n               UnorderedElementsAre(Pair(1, slice_o), Pair(2, slice_io)));\n }\n \n+TEST_F(ThunkBufferDebugPassTest, BufferSaverInserter) {\n+  static constexpr ThunkId kTestThunkId = ThunkId(123);\n+  // The callbacks created by ThunkBufferDebugPass require a HloModule with\n+  // a non-null entry computation.\n+  auto builder = HloComputation::Builder(\"entry\");\n+  HloInstruction* root = builder.AddInstruction(\n+      HloInstruction::CreateConstant(LiteralUtil::CreateR0(1.0f)));\n+  std::unique_ptr<HloComputation> entry_computation = builder.Build(root);\n+  HloModule hlo_module(\"test_module\", HloModuleConfig());\n+  hlo_module.AddEntryComputation(std::move(entry_computation));\n+\n+  // Create a fake thunk with a few different buffer uses.\n+  BufferAllocation alloc(0, 1024, 0);\n+  BufferAllocation::Slice slice_o(&alloc, 1, 1, PrimitiveType::F32);\n+  BufferAllocation::Slice slice_io(&alloc, 2, 1, PrimitiveType::F32);\n+  Thunk::ThunkInfo fake_thunk_info;\n+  fake_thunk_info.thunk_id = kTestThunkId;\n+\n+  std::vector<std::unique_ptr<Thunk>> thunks;\n+  thunks.push_back(std::make_unique<FakeThunk>(\n+      fake_thunk_info,\n+      Thunk::BufferUses{\n+          // Write is undefined on input, but defined on output.\n+          BufferUse::Write(slice_o),\n+          // Unlike Consume, Read is supposed to preserve the contents of the\n+          // buffer, so we check it on input *and* output.\n+          BufferUse::Read(slice_io),\n+      }));\n+  auto root_thunk =\n+      std::make_unique<SequentialThunk>(Thunk::ThunkInfo(), std::move(thunks));\n+\n+  DebugOptions debug_options =\n+      tsl::proto_testing::ParseTextProtoOrDie<DebugOptions>(R\"pb(\n+        xla_dump_to: \"/tmp/123\"\n+        xla_gpu_experimental_enable_buffer_saver_on_thunks: true\n+      )pb\");\n+\n+  TF_EXPECT_OK(RunDebugSaverInserter(*root_thunk, debug_options, hlo_module));\n+\n+  // Expected thunk structure after the pass:\n+  // 1. SequentialThunk\n+  //    1. FakeThunk\n+  //    2. CustomCall (buffer saver)\n+  const std::vector<std::unique_ptr<Thunk>>& new_thunks = root_thunk->thunks();\n+  EXPECT_THAT(\n+      new_thunks,\n+      ElementsAre(IsSequentialThunkWith(ElementsAre(\n+          ThunkKindIs(Thunk::Kind::kGemm),\n+          IsCustomCallThunkWithTargetName(kXlaGpuAppendToFileCustomCallTag)))));\n+}\n+\n TEST_F(ThunkBufferDebugPassTest, FiltersThunksByIdRanges) {\n   DebugOptions debug_options;\n   debug_options.set_xla_gpu_experimental_enable_checksum_tracing_on_thunks("
        },
        {
            "sha": "e9dd5cd28492e00364dcc51094fb4b765b71b0a5",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_saver_inserter.cc",
            "status": "added",
            "additions": 136,
            "deletions": 0,
            "changes": 136,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_saver_inserter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_saver_inserter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_saver_inserter.cc?ref=f7ba7e3431e9d77c8cd98a8894f31d08a487407d",
            "patch": "@@ -0,0 +1,136 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdint>\n+#include <memory>\n+#include <optional>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n+#include \"xla/backends/gpu/runtime/runtime_intrinsics.h\"\n+#include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/backends/gpu/runtime/shaped_slice.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_debug_filter.h\"\n+#include \"xla/ffi/attribute_map.h\"\n+#include \"xla/ffi/ffi.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/runtime/buffer_use.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/shape.h\"\n+#include \"xla/shape_util.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/xla_data.pb.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+Shape FindShapeFor(const BufferAllocation::Slice& slice, const Thunk& thunk) {\n+  for (const auto& [hlo, offset_size] :\n+       slice.allocation()->assigned_buffers()) {\n+    if (offset_size.offset != slice.offset() ||\n+        offset_size.size != slice.size()) {\n+      continue;\n+    }\n+    if (hlo->instruction()->name() != thunk.thunk_info().profile_annotation) {\n+      continue;\n+    }\n+    if (hlo->shape().element_type() != slice.element_type()) {\n+      continue;\n+    }\n+    return hlo->shape();\n+  }\n+\n+  LOG(WARNING) << \"Buffer assigment not found. Assuming flat shape.\";\n+  return ShapeUtil::MakeShape(\n+      slice.element_type(),\n+      std::vector<int64_t>{slice.size() / ShapeUtil::ByteSizeOfPrimitiveType(\n+                                              slice.element_type())});\n+}\n+\n+absl::StatusOr<std::unique_ptr<Thunk>> InsertBufferSaverCustomCall(\n+    const HloModule& hlo_module, std::unique_ptr<Thunk> thunk,\n+    const std::string& path) {\n+  std::vector<std::unique_ptr<Thunk>> sequence;\n+  sequence.emplace_back(std::move(thunk));\n+\n+  absl::flat_hash_set<BufferAllocation::Slice> processed;\n+\n+  Thunk::BufferUses uses = sequence[0]->buffer_uses();\n+  // Results are last in the list. Process in reverse order in case of InOut\n+  // argument, which appears in the list twice.\n+  for (int i = uses.size() - 1; i >= 0; i--) {\n+    const BufferUse& buffer = uses[i];\n+    if (buffer.access() != BufferUse::MemoryAccess::kWrite) {\n+      continue;\n+    }\n+\n+    const BufferAllocation::Slice& slice = buffer.slice();\n+    if (!processed.insert(slice).second) {\n+      continue;\n+    }\n+\n+    ShapedSlice output{slice, FindShapeFor(slice, *sequence[0])};\n+    ffi::AttributesMap attributes{\n+        {\"dir\", ffi::Attribute{path}},\n+        {\"metadata\", {sequence[0]->thunk_info().profile_annotation}}};\n+\n+    Thunk::ThunkInfo info;\n+    info.profile_annotation =\n+        absl::StrCat(\"Buffer saver \", sequence[0]->profile_annotation());\n+    info.execution_stream_id = sequence[0]->execution_stream_id();\n+\n+    TF_ASSIGN_OR_RETURN(\n+        auto log_thunk,\n+        CustomCallThunk::Create(\n+            info, std::string{kXlaGpuAppendToFileCustomCallTag}, {output},\n+            {std::nullopt}, attributes, hlo_module.entry_computation(), \"GPU\"));\n+    log_thunk->add_control_predecessor(sequence[0].get());\n+    sequence.emplace_back(std::move(log_thunk));\n+  }\n+\n+  auto wrapped_thunk = std::make_unique<SequentialThunk>(Thunk::ThunkInfo(),\n+                                                         std::move(sequence));\n+  return std::unique_ptr<Thunk>(std::move(wrapped_thunk));\n+}\n+\n+}  // namespace\n+\n+absl::Status RunDebugSaverInserter(SequentialThunk& root_thunk,\n+                                   const DebugOptions& debug_options,\n+                                   const HloModule& hlo_module) {\n+  if (debug_options.xla_dump_to().empty()) {\n+    LOG(WARNING)\n+        << \"Buffer saver enabled but target directory is not provided.\";\n+    return absl::OkStatus();\n+  }\n+  ThunkFilter thunk_filter = CreateThunkFilter(debug_options);\n+  return root_thunk.TransformAllNestedThunks(\n+      [&](std::unique_ptr<Thunk> thunk)\n+          -> absl::StatusOr<std::unique_ptr<Thunk>> {\n+        if (thunk_filter(*thunk) == InstrumentAction::kSkip) {\n+          return thunk;\n+        }\n+        return InsertBufferSaverCustomCall(hlo_module, std::move(thunk),\n+                                           debug_options.xla_dump_to());\n+      });\n+}\n+\n+}  // namespace xla::gpu"
        },
        {
            "sha": "66a9c30235ed4566cb1844209ba5709585896761",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_saver_inserter.h",
            "status": "added",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_saver_inserter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_saver_inserter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_saver_inserter.h?ref=f7ba7e3431e9d77c8cd98a8894f31d08a487407d",
            "patch": "@@ -0,0 +1,32 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_THUNK_BUFFER_DEBUG_SAVER_INSERTER_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_THUNK_BUFFER_DEBUG_SAVER_INSERTER_H_\n+\n+#include \"absl/status/status.h\"\n+#include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+\n+namespace xla::gpu {\n+\n+// Records outputs of thunks selected by ThunkFilter.\n+absl::Status RunDebugSaverInserter(SequentialThunk& root_thunk,\n+                                   const DebugOptions& debug_options,\n+                                   const HloModule& hlo_module);\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_THUNK_BUFFER_DEBUG_SAVER_INSERTER_H_"
        },
        {
            "sha": "b7b70892f157cc875dc66aa4e62f5bc5eab4af35",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=f7ba7e3431e9d77c8cd98a8894f31d08a487407d",
            "patch": "@@ -478,6 +478,7 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n \n   opts.set_xla_keep_shardings_after_spmd(false);\n   opts.set_xla_gpu_experimental_enable_checksum_tracing_on_thunks(false);\n+  opts.set_xla_gpu_experimental_enable_buffer_saver_on_thunks(false);\n   opts.set_xla_gpu_detect_nan(DebugOptions::DETECTION_MODE_NONE);\n   opts.set_xla_gpu_detect_inf(DebugOptions::DETECTION_MODE_NONE);\n   return opts;\n@@ -2696,6 +2697,14 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n       debug_options->xla_gpu_experimental_enable_checksum_tracing_on_thunks(),\n       \"Enables an experimental feature to record checksums of selected thunk \"\n       \"inputs/outputs.\"));\n+  flag_list->push_back(tsl::Flag(\n+      \"xla_gpu_experimental_enable_buffer_saver_on_thunks\",\n+      bool_setter_for(\n+          &DebugOptions::\n+              set_xla_gpu_experimental_enable_buffer_saver_on_thunks),\n+      debug_options->xla_gpu_experimental_enable_buffer_saver_on_thunks(),\n+      \"When provided, enables an experimental feature to save results of \"\n+      \"selected thunks.\"));\n   flag_list->push_back(tsl::Flag(\n       \"xla_gpu_experimental_thunk_buffer_debug_filter_by_thunk_id_ranges\",\n       setter_for_thunk_buffer_debug_filter_by_thunk_id, \"(none)\","
        },
        {
            "sha": "61995756588bd9031afa9ae0af04e732fd0b0b12",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc?ref=f7ba7e3431e9d77c8cd98a8894f31d08a487407d",
            "patch": "@@ -182,6 +182,10 @@ static absl::Status RunThunkPasses(const DebugOptions& debug_options,\n     pipeline.AddPass(std::make_unique<ThunkBufferDebugPass>(\n         ThunkBufferDebugPass::Mode::kChecksum));\n   }\n+  if (debug_options.xla_gpu_experimental_enable_buffer_saver_on_thunks()) {\n+    pipeline.AddPass(std::make_unique<ThunkBufferDebugPass>(\n+        ThunkBufferDebugPass::Mode::kBufferSaver));\n+  }\n   if ((debug_options.xla_gpu_detect_nan() !=\n        DebugOptions::DETECTION_MODE_NONE) ||\n       (debug_options.xla_gpu_detect_inf() !="
        },
        {
            "sha": "580d67ab978a4fef5ec347fde27efd8cb3085cb9",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h?ref=f7ba7e3431e9d77c8cd98a8894f31d08a487407d",
            "patch": "@@ -193,7 +193,7 @@ class GpuExecutable : public Executable {\n \n   const GpuAliasInfo* alias_info() const { return alias_info_.get(); }\n \n-  const SequentialThunk& GetThunk() { return *thunks_; }\n+  const SequentialThunk& GetThunk() const { return *thunks_; }\n \n   absl::Status ExecuteThunks(const BufferAllocations& buffer_allocations,\n                              const ServiceExecutableRunOptions* run_options);"
        },
        {
            "sha": "8c3ad1becffff891bab4adea4587fe58f95b0a19",
            "filename": "third_party/xla/xla/xla.proto",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fxla.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f7ba7e3431e9d77c8cd98a8894f31d08a487407d/third_party%2Fxla%2Fxla%2Fxla.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fxla.proto?ref=f7ba7e3431e9d77c8cd98a8894f31d08a487407d",
            "patch": "@@ -663,6 +663,10 @@ message DebugOptions {\n   // xla_gpu_multi_streamed_windowed_einsum is set to true.\n   optional bool xla_gpu_experimental_enable_alltoall_windowed_einsum = 360;\n \n+  // Enables an experimental feature to record outputs of selected thunks.\n+  // Writes to --xla_dump_to.\n+  optional bool xla_gpu_experimental_enable_buffer_saver_on_thunks = 431;\n+\n   // Enables an experimental feature to record checksums of selected thunk\n   // inputs/outputs.\n   optional bool xla_gpu_experimental_enable_checksum_tracing_on_thunks = 414;\n@@ -1426,7 +1430,7 @@ message DebugOptions {\n   // Note: when adding a new flag, please add it to one of the hardware-specific\n   // or hardware-agnostic sections at the top of this proto message.\n \n-  // Next id: 431\n+  // Next id: 432\n \n   // Extra options to pass to the compilation backend (e.g. LLVM); specific\n   // interpretation of these values is left to the backend."
        }
    ],
    "stats": {
        "total": 257,
        "additions": 255,
        "deletions": 2
    }
}