{
    "author": "sirakiin",
    "message": "Add constant folder for tanh\n\nPiperOrigin-RevId: 831509064",
    "sha": "aea00a23d76e2195bcc4b07990e7499a08937675",
    "files": [
        {
            "sha": "d7027e91f480efd059e5876e5a67ba1208c4ee06",
            "filename": "tensorflow/compiler/mlir/lite/ir/tfl_ops.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aea00a23d76e2195bcc4b07990e7499a08937675/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aea00a23d76e2195bcc4b07990e7499a08937675/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc?ref=aea00a23d76e2195bcc4b07990e7499a08937675",
            "patch": "@@ -5233,6 +5233,22 @@ int64_t SoftmaxOp::GetArithmeticCount(Operation* op) {\n // TanhOp\n //===----------------------------------------------------------------------===//\n \n+OpFoldResult TanhOp::fold(FoldAdaptor adaptor) {\n+  if (!ShouldFoldOperation(this->getOperation())) return {};\n+\n+  auto operands = adaptor.getOperands();\n+  Type result_type = getType();\n+  // Only constant fold for tensor of f32 is implemented.\n+  if (!IsF32ShapedType(result_type)) return nullptr;\n+\n+  auto compute = [](APFloat value) -> APFloat {\n+    float f = value.convertToFloat();\n+    float result = std::tanh(f);\n+    return APFloat(result);\n+  };\n+  return ConstFoldUnaryOp(result_type, operands[0], compute);\n+}\n+\n int64_t TanhOp::GetArithmeticCount(Operation* op) {\n   int64_t count;\n   // As a very rough ballpark, the cost of evaluating a math function"
        },
        {
            "sha": "c90859cd6accfed92eabe9f72d76752c7ae855e0",
            "filename": "tensorflow/compiler/mlir/lite/ir/tfl_ops.td",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aea00a23d76e2195bcc4b07990e7499a08937675/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aea00a23d76e2195bcc4b07990e7499a08937675/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td?ref=aea00a23d76e2195bcc4b07990e7499a08937675",
            "patch": "@@ -3575,6 +3575,8 @@ def TFL_TanhOp: TFL_Op<\"tanh\", [\n         /*scale=*/1.0 / (1<<(bit_width-1)), /*zero_point=*/0);\n   }\n   }];\n+\n+  let hasFolder = 1;\n }\n \n def TFL_TileOp: TFL_Op<\"tile\", ["
        },
        {
            "sha": "2fcdfb80b6a0ad024dc3dede53fbebc56fcde6f0",
            "filename": "tensorflow/compiler/mlir/lite/tests/const-fold.mlir",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aea00a23d76e2195bcc4b07990e7499a08937675/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fconst-fold.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aea00a23d76e2195bcc4b07990e7499a08937675/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fconst-fold.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fconst-fold.mlir?ref=aea00a23d76e2195bcc4b07990e7499a08937675",
            "patch": "@@ -261,14 +261,15 @@ func.func @mul_one_quant(%arg0: tensor<32x!quant.uniform<u8:f32, 1.0>>) -> tenso\n \n \n // CHECK-LABEL: @elementwise_unary_ops\n-func.func @elementwise_unary_ops() -> (tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>) {\n+func.func @elementwise_unary_ops() -> (tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>) {\n   %0 = arith.constant dense<-1.0> : tensor<f32>\n   %1 = arith.constant dense<1.0> : tensor<f32>\n   %2 = arith.constant dense<1.0> : tensor<f32>\n   %3 = arith.constant dense<1.0> : tensor<f32>\n   %4 = arith.constant dense<4.0> : tensor<f32>\n   %5 = arith.constant dense<4.0> : tensor<f32>\n   %6 = arith.constant dense<2.0> : tensor<f32>\n+  %one = arith.constant dense<1.0> : tensor<f32>\n \n   // CHECK-DAG: [[cst0:%.*]] = arith.constant dense<1.000000e+00> : tensor<f32>\n   // CHECK-DAG: [[cst1:%.*]] = arith.constant dense<0.841470957> : tensor<f32>\n@@ -277,7 +278,8 @@ func.func @elementwise_unary_ops() -> (tensor<f32>, tensor<f32>, tensor<f32>, te\n   // CHECK-DAG: [[cst4:%.*]] = arith.constant dense<2.000000e+00> : tensor<f32>\n   // CHECK-DAG: [[cst5:%.*]] = arith.constant dense<5.000000e-01> : tensor<f32>\n   // CHECK-DAG: [[cst6:%.*]] = arith.constant dense<4.000000e+00> : tensor<f32>\n-  // CHECK: return [[cst0]], [[cst1]], [[cst2]], [[cst3]], [[cst4]], [[cst5]], [[cst6]]\n+  // CHECK-DAG: [[cst7:%.*]] = arith.constant dense<0.761594176> : tensor<f32>\n+  // CHECK: return [[cst0]], [[cst1]], [[cst2]], [[cst3]], [[cst4]], [[cst5]], [[cst6]], [[cst7]]\n \n   %7 = \"tfl.abs\"(%0) : (tensor<f32>) -> tensor<f32>\n   %8 = \"tfl.sin\"(%1) : (tensor<f32>) -> tensor<f32>\n@@ -286,8 +288,9 @@ func.func @elementwise_unary_ops() -> (tensor<f32>, tensor<f32>, tensor<f32>, te\n   %11 = \"tfl.sqrt\"(%4) : (tensor<f32>) -> tensor<f32>\n   %12 = \"tfl.rsqrt\"(%5) : (tensor<f32>) -> tensor<f32>\n   %13 = \"tfl.square\"(%6) : (tensor<f32>) -> tensor<f32>\n+  %14 = \"tfl.tanh\"(%one) : (tensor<f32>) -> tensor<f32>\n \n-  func.return %7, %8, %9, %10, %11, %12, %13 : tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>\n+  func.return %7, %8, %9, %10, %11, %12, %13, %14 : tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>\n }\n \n // CHECK-LABEL: @max_with_neg_f32_max_val"
        }
    ],
    "stats": {
        "total": 27,
        "additions": 24,
        "deletions": 3
    }
}