{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Set limit on stack allocation in tiled lowering.\n\nWe probably want to try hard to avoid this with scratch memory / better reuse of allocations but for now place a limit to avoid stack overflow.\n\nPiperOrigin-RevId: 840310411",
    "sha": "f305abaa31d4eb4a8a31b495771e93bd358807c2",
    "files": [
        {
            "sha": "4753a80c341de5799d253b64d8837b97f0c3feda",
            "filename": "third_party/xla/xla/backends/cpu/codegen/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f305abaa31d4eb4a8a31b495771e93bd358807c2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f305abaa31d4eb4a8a31b495771e93bd358807c2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD?ref=f305abaa31d4eb4a8a31b495771e93bd358807c2",
            "patch": "@@ -34,8 +34,6 @@ cc_library(\n         \":builtin_pow\",\n         \"@com_google_absl//absl/base:no_destructor\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n-        \"@com_google_absl//absl/functional:any_invocable\",\n-        \"@com_google_absl//absl/strings:string_view\",\n         \"@llvm-project//llvm:Core\",\n         \"@llvm-project//llvm:OrcJIT\",\n         \"@llvm-project//llvm:OrcShared\","
        },
        {
            "sha": "7da8fc5412167e28c62c4947c29f3a48a2cf3674",
            "filename": "third_party/xla/xla/backends/cpu/codegen/builtin_definition_generator.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f305abaa31d4eb4a8a31b495771e93bd358807c2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fbuiltin_definition_generator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f305abaa31d4eb4a8a31b495771e93bd358807c2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fbuiltin_definition_generator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fbuiltin_definition_generator.cc?ref=f305abaa31d4eb4a8a31b495771e93bd358807c2",
            "patch": "@@ -15,6 +15,8 @@ limitations under the License.\n \n #include \"xla/backends/cpu/codegen/builtin_definition_generator.h\"\n \n+#include <cstdlib>\n+\n #ifdef _MSC_VER\n #include <math.h>\n #endif  // _MSC_VER\n@@ -148,6 +150,8 @@ static Registry CreateRegistry() {\n       SymbolDef(static_cast<void* (*)(void*, const void*, size_t)>(memmove));\n   registry[\"memset\"] =\n       SymbolDef(static_cast<void* (*)(void*, int, size_t)>(memset));\n+  registry[\"malloc\"] = SymbolDef(static_cast<void* (*)(size_t)>(malloc));\n+  registry[\"free\"] = SymbolDef(static_cast<void (*)(void*)>(free));\n \n   registry[\"__gnu_f2h_ieee\"] = SymbolDef(__gnu_f2h_ieee);\n   registry[\"__gnu_h2f_ieee\"] = SymbolDef(__gnu_h2f_ieee);"
        },
        {
            "sha": "65996cf9b41d306b390ac751e10e614eee6b51b2",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f305abaa31d4eb4a8a31b495771e93bd358807c2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f305abaa31d4eb4a8a31b495771e93bd358807c2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=f305abaa31d4eb4a8a31b495771e93bd358807c2",
            "patch": "@@ -293,16 +293,15 @@ static void AddBufferizationPasses(mlir::OpPassManager& pm) {\n   pm.addNestedPass<mlir::func::FuncOp>(\n       mlir::bufferization::createBufferHoistingPass());\n   pm.addPass(mlir::memref::createFoldMemRefAliasOpsPass());\n+\n   mlir::bufferization::PromoteBuffersToStackPassOptions\n       buffer_promotion_options;\n-  // We don't want any heap allocation for now.\n-  buffer_promotion_options.maxAllocSizeInBytes =\n-      std::numeric_limits<unsigned>::max();\n+  // TODO(willfroom): Look at a more principled way to set this option.\n+  buffer_promotion_options.maxAllocSizeInBytes = 4096;\n   pm.addNestedPass<mlir::func::FuncOp>(\n       mlir::bufferization::createPromoteBuffersToStackPass(\n           buffer_promotion_options));\n-  // This shouldn't be necessary as we promote everything to the stack, but we\n-  // leave it in for now while we are experimenting.\n+\n   mlir::bufferization::buildBufferDeallocationPipeline(\n       pm, mlir::bufferization::BufferDeallocationPipelineOptions());\n }"
        }
    ],
    "stats": {
        "total": 15,
        "additions": 8,
        "deletions": 7
    }
}