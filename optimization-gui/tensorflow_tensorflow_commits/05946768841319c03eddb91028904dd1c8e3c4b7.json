{
    "author": "ZixuanJiang",
    "message": "Pass attributes to `OptimizationBarrierOp` in HLO to MHLO import.\n\nThe attributes from the HLO instruction are now passed when creating the `mlir::stablehlo::OptimizationBarrierOp`, ensuring they are preserved during the conversion.\n\nPiperOrigin-RevId: 797951790",
    "sha": "05946768841319c03eddb91028904dd1c8e3c4b7",
    "files": [
        {
            "sha": "f1e427176203c867f0a5a63d64e11e9caac85c59",
            "filename": "third_party/xla/xla/hlo/translate/hlo_to_mhlo/hlo_function_importer.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05946768841319c03eddb91028904dd1c8e3c4b7/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Fhlo_function_importer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05946768841319c03eddb91028904dd1c8e3c4b7/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Fhlo_function_importer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Fhlo_function_importer.cc?ref=05946768841319c03eddb91028904dd1c8e3c4b7",
            "patch": "@@ -2060,7 +2060,7 @@ absl::StatusOr<mlir::Operation*> HloFunctionImporter::ImportInstructionImpl(\n       FlattenTupleValue(func_builder, loc, operands[0], flattened_operands);\n \n       auto op = func_builder->create<mlir::stablehlo::OptimizationBarrierOp>(\n-          loc, flattened_operand_types, flattened_operands);\n+          loc, flattened_operand_types, flattened_operands, attributes);\n \n       return CreateTupleFromOpResults(func_builder, loc, op.getOperation(),\n                                       operands[0].getType());"
        },
        {
            "sha": "6f5cde9414f5fe14889ead94d96dd626663b8c1b",
            "filename": "third_party/xla/xla/hlo/translate/hlo_to_mhlo/tests/import_emit_stablehlo.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05946768841319c03eddb91028904dd1c8e3c4b7/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Ftests%2Fimport_emit_stablehlo.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05946768841319c03eddb91028904dd1c8e3c4b7/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Ftests%2Fimport_emit_stablehlo.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Ftests%2Fimport_emit_stablehlo.hlo?ref=05946768841319c03eddb91028904dd1c8e3c4b7",
            "patch": "@@ -2242,7 +2242,7 @@ ENTRY %main.3 (Arg_0.1: f32[3,4]) -> f32[3,4,1] {\n \n // CHECK-LABEL: module @main attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {\n // CHECK:         func.func @main(%[[VAL_0:.*]]: tensor<4x4xf32>, %[[VAL_1:.*]]: tensor<3x4xf32>) -> tuple<tensor<4x4xf32>, tensor<3x4xf32>> {\n-// CHECK:           %[[VAL_2:.*]]:2 = stablehlo.optimization_barrier %[[VAL_0]], %[[VAL_1]] : tensor<4x4xf32>, tensor<3x4xf32>\n+// CHECK:           %[[VAL_2:.*]]:2 = stablehlo.optimization_barrier {mhlo.sharding = \"{{\\{\\{}}replicated}, {devices=[1,2]<=[2]}}\"} %[[VAL_0]], %[[VAL_1]] : tensor<4x4xf32>, tensor<3x4xf32>\n // CHECK:           %[[VAL_3:.*]] = stablehlo.tuple %[[VAL_2]]#0, %[[VAL_2]]#1 {xla_shape = \"(f32[4,4]{1,0}, f32[3,4]{1,0})\"} : tuple<tensor<4x4xf32>, tensor<3x4xf32>>\n // CHECK:           return %[[VAL_3]] : tuple<tensor<4x4xf32>, tensor<3x4xf32>>\n // CHECK:         }"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}