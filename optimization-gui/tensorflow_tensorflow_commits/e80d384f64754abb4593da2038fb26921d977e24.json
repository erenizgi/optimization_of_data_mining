{
    "author": "pschuh",
    "message": "Add a test that verifies that CreateBuffersForAsyncHostToDevice is properly\nsynchronized with the compute stream.\n\nPiperOrigin-RevId: 816301428",
    "sha": "e80d384f64754abb4593da2038fb26921d977e24",
    "files": [
        {
            "sha": "faaf0c988616011607a2b8fbaad283bb77aaf1f3",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc",
            "status": "modified",
            "additions": 109,
            "deletions": 1,
            "changes": 110,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e80d384f64754abb4593da2038fb26921d977e24/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e80d384f64754abb4593da2038fb26921d977e24/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc?ref=e80d384f64754abb4593da2038fb26921d977e24",
            "patch": "@@ -2463,7 +2463,7 @@ TEST(StreamExecutorGpuClientTest, MultipleDeviceShareDmaMapping) {\n   TF_EXPECT_OK(client->DmaUnmap(host_dma_ptr.get()));\n }\n \n-TEST(TpuLocalClientTest, RawBuffer) {\n+TEST(StreamExecutorGpuClientTest, RawBuffer) {\n   TF_ASSERT_OK_AND_ASSIGN(auto client,\n                           GetStreamExecutorGpuClient(DefaultOptions()));\n \n@@ -2501,6 +2501,114 @@ TEST(TpuLocalClientTest, RawBuffer) {\n   tsl::port::AlignedFree(dst2);\n }\n \n+TEST(StreamExecutorGpuClientTest, ComputeSynchronizedAllocatorRace) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto client,\n+                          GetStreamExecutorGpuClient(DefaultOptions()));\n+  PjRtDevice* const device = client->addressable_devices()[0];\n+\n+  std::unique_ptr<xla::PjRtBuffer> w;\n+  {\n+    static constexpr char const* kInitMatrixProgram =\n+        R\"(\n+HloModule jit_init_matrix, input_output_alias={}, entry_computation_layout={()->f32[4096,4096]{1,0}}\n+\n+ENTRY main.5 {\n+  %a = f32[] constant(0)\n+  ROOT %b = f32[4096,4096]{1,0} broadcast(%a), dimensions={}\n+}\n+)\";\n+    TF_ASSERT_OK_AND_ASSIGN(auto executable,\n+                            CompileExecutable(kInitMatrixProgram, *client));\n+    std::vector<std::vector<PjRtBuffer*>> input_ptrs = {{}};\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto results,\n+        executable->Execute(absl::MakeSpan(input_ptrs), ExecuteOptions()));\n+    w = std::move(results[0][0]);\n+  }\n+\n+  static constexpr char const* kSlowCheckProgram =\n+      R\"(\n+HloModule jit_slow_verify, input_output_alias={}, entry_computation_layout={(f32[4096,4096]{1,0}, s32[4194304]{0})->(f32[4096,4096]{1,0}, s32[])}\n+\n+ENTRY main.5 {\n+  %w.0 = f32[4096,4096]{1,0} parameter(0), sharding={replicated}\n+  %w.1 = f32[4096,4096]{1,0} dot(%w.0, %w.0), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+  %w.2 = f32[4096,4096]{1,0} dot(%w.1, %w.1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+  %checks.1 = s32[4194304]{0} parameter(1), sharding={replicated}\n+  %optimization_barrier.4 = (f32[4096,4096]{1,0}, s32[4194304]{0}) tuple(%w.2, %checks.1)\n+  %optimization_barrier.5 = (f32[4096,4096]{1,0}, s32[4194304]{0}) opt-barrier(%optimization_barrier.4)\n+  %optimization_barrier.6 = f32[4096,4096]{1,0} get-tuple-element(%optimization_barrier.5), index=0\n+  %optimization_barrier.7 = s32[4194304]{0} get-tuple-element(%optimization_barrier.5), index=1\n+  %slice.1 = s32[1]{0} slice(%optimization_barrier.7), slice={[0:1]}\n+  %squeeze.1 = s32[] reshape(%slice.1)\n+  ROOT %tuple.1 = (f32[4096,4096]{1,0}, s32[]) tuple(%optimization_barrier.6, %squeeze.1)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto executable,\n+                          CompileExecutable(kSlowCheckProgram, *client));\n+\n+  size_t dma_size = 4 * 1024;\n+  size_t alignment = 1024;\n+  auto host_dma_ptr = xla::AlignedAlloc(alignment, dma_size);\n+  TF_EXPECT_OK(client->DmaMap(host_dma_ptr.get(), dma_size));\n+  memset(host_dma_ptr.get(), 0, dma_size);\n+  Shape shape =\n+      ShapeUtil::MakeShape(S32, {static_cast<int64_t>(dma_size * 1024)});\n+\n+  void* last_opaque_ptr = nullptr;\n+  bool clobbered = false;\n+  std::vector<std::unique_ptr<xla::PjRtBuffer>> res_lst;\n+  for (int32_t i = 0; i < 10; ++i) {\n+    TF_ASSERT_OK_AND_ASSIGN(auto transfer_manager,\n+                            client->CreateBuffersForAsyncHostToDevice(\n+                                {shape}, device->memory_spaces()[0]));\n+    auto buffer = transfer_manager->RetrieveBuffer(0);\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto raw_buffer,\n+        xla::PjRtRawBuffer::CreateRawAliasOfBuffer(buffer.get()));\n+\n+    auto* opaque_ptr =\n+        tensorflow::down_cast<xla::CommonPjRtRawBuffer*>(raw_buffer.get())\n+            ->OpaqueDeviceMemoryDataPointer();\n+    if (opaque_ptr == last_opaque_ptr) {\n+      clobbered = true;\n+    }\n+    last_opaque_ptr = opaque_ptr;\n+\n+    memcpy(host_dma_ptr.get(), &i, sizeof(int32_t));\n+    absl::Notification done;\n+    TF_EXPECT_OK(transfer_manager->TransferRawDataToSubBuffer(\n+        0, host_dma_ptr.get(), 0, dma_size, true,\n+        [&done]() { done.Notify(); }));\n+    done.WaitForNotification();\n+\n+    std::vector<std::vector<xla::PjRtBuffer*>> input_ptrs = {\n+        {w.get(), buffer.get()}};\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto results,\n+        executable->Execute(absl::MakeSpan(input_ptrs), ExecuteOptions()));\n+    w = std::move(results[0][0]);\n+    res_lst.push_back(std::move(results[0][1]));\n+    if (i - 1 > 0) {\n+      TF_EXPECT_OK(res_lst[i - 1]->GetReadyFuture().Await());\n+    }\n+  }\n+\n+  std::vector<int32_t> expected;\n+  std::vector<int32_t> actual;\n+  for (int32_t i = 0; i < static_cast<int32_t>(res_lst.size()); ++i) {\n+    TF_ASSERT_OK_AND_ASSIGN(auto lit, res_lst[i]->ToLiteralSync());\n+    expected.push_back(i);\n+    actual.push_back(lit->data<int32_t>()[0]);\n+  }\n+\n+  EXPECT_EQ(expected, actual);\n+\n+  EXPECT_TRUE(clobbered);\n+\n+  TF_EXPECT_OK(client->DmaUnmap(host_dma_ptr.get()));\n+}\n+\n struct ShardedAutotuningTestInfo {\n   bool use_xla_computation;\n   int num_active_nodes;"
        }
    ],
    "stats": {
        "total": 110,
        "additions": 109,
        "deletions": 1
    }
}