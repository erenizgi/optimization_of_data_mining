{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Fix collective_ops_e2e_test timeout and enable it in OSS presubmits.\n\nPiperOrigin-RevId: 837038901",
    "sha": "3ecc9762ae21bc1697a66ef98251f10b14c712a4",
    "files": [
        {
            "sha": "648d0f7edaa4ce84c868a7f2c477d568e600b597",
            "filename": "third_party/xla/xla/tests/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3ecc9762ae21bc1697a66ef98251f10b14c712a4/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3ecc9762ae21bc1697a66ef98251f10b14c712a4/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2FBUILD?ref=3ecc9762ae21bc1697a66ef98251f10b14c712a4",
            "patch": "@@ -2906,6 +2906,9 @@ xla_test(\n     backend_tags = {\n         \"gpu\": [\n             \"multi_gpu\",\n+        ],\n+        \"nvgpu_any\": [\n+            \"broken\",\n             \"no_oss\",\n         ],\n     },"
        },
        {
            "sha": "1951e7242bbe2072ce4d41dcab5d5f1b368408cb",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3ecc9762ae21bc1697a66ef98251f10b14c712a4/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3ecc9762ae21bc1697a66ef98251f10b14c712a4/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc?ref=3ecc9762ae21bc1697a66ef98251f10b14c712a4",
            "patch": "@@ -1541,6 +1541,7 @@ TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n                                        /*enable_enzyme_comms_opt=*/false);\n }\n \n+// TODO(463571743): Reduce the shapes to make test-case faster.\n TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n        KeepPartitionedNonSlicedDimensionWithConstantIndices) {\n   const std::string hlo_text = R\"(\n@@ -3269,13 +3270,13 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_8GPUs_2ReplicasPerGroups) {\n   HloModule module, num_partitions=1\n \n   ENTRY entry {\n-    input = f32[4096,1024] parameter(0)\n-    output = f32[8192,1024] parameter(1)\n-    input_offsets = s64[32] parameter(2)\n-    send_sizes = s64[32] parameter(3)\n-    output_offsets = s64[32] parameter(4)\n-    recv_sizes = s64[32] parameter(5)\n-    ROOT ra2a = f32[8192,1024] ragged-all-to-all(input, output,\n+    input = f32[512, 5, 32] parameter(0)\n+    output = f32[512, 5, 32] parameter(1)\n+    input_offsets = s32[32] parameter(2)\n+    send_sizes = s32[32] parameter(3)\n+    output_offsets = s32[32] parameter(4)\n+    recv_sizes = s32[32] parameter(5)\n+    ROOT ra2a = f32[512, 5, 32] ragged-all-to-all(input, output,\n       input_offsets, send_sizes, output_offsets, recv_sizes),\n       replica_groups={{0,4},{1,5},{2,6},{3,7}}\n   })\";"
        }
    ],
    "stats": {
        "total": 18,
        "additions": 11,
        "deletions": 7
    }
}