{
    "author": "shawnwang18",
    "message": "PR #30799: [XLA:GPU] Add command buffer NestedChildCmd unittest.\n\nImported from GitHub PR https://github.com/openxla/xla/pull/30799\n\nüìù Summary of Changes\nThis PR add a unit test to test the command buffer ChildCmd inside another ChildCmd pattern, verify command buffer create and update operation works.\n\nüéØ Justification\nMore testing coverage.\n\nüöÄ Kind of Contribution\nüß™ Tests\n\nCopybara import of the project:\n\n--\ndea886c0d9867b9045b71a370a0bd6592dc303d9 by Shawn Wang <shawnw@nvidia.com>:\n\nfix\n\n--\na8d00d54158ab7637837947dcb39f3db6e86b0bc by Shawn Wang <shawnw@nvidia.com>:\n\nAdd ChildCmd inside another ChildCmd unittest\n\n--\n06a25bbb1e01d2ee17e1d976eaaf9fd4b597efb2 by Shawn Wang <shawnw@nvidia.com>:\n\nrestore other changes\n\n--\n300bac4604056460ad26811cf17c94c67cbf60ba by Shawn Wang <shawnw@nvidia.com>:\n\nfix\n\n--\n05dd01cdd6536c2159dd964d1468080e8b209e9a by Shawn Wang <shawnw@nvidia.com>:\n\nfix\n\nMerging this change closes #30799\n\nPiperOrigin-RevId: 802456380",
    "sha": "d355b1581c9a749f497b5c8824efea292af04599",
    "files": [
        {
            "sha": "167278e306d7dd67c50c3f792463e4809d4a2434",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd_test.cc",
            "status": "modified",
            "additions": 153,
            "deletions": 0,
            "changes": 153,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d355b1581c9a749f497b5c8824efea292af04599/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d355b1581c9a749f497b5c8824efea292af04599/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc?ref=d355b1581c9a749f497b5c8824efea292af04599",
            "patch": "@@ -60,6 +60,24 @@ static se::StreamExecutor* GpuExecutor() {\n   return platform->ExecutorForDevice(0).value();\n }\n \n+// Some of the tests rely on CUDA 12.9+ features.\n+bool IsAtLeastCuda12900(const se::StreamExecutor* stream_executor) {\n+  const auto& device_description = stream_executor->GetDeviceDescription();\n+  const auto* cuda_cc = std::get_if<se::CudaComputeCapability>(\n+      &device_description.gpu_compute_capability());\n+  if (cuda_cc != nullptr) {\n+    // We need a recent driver to support the feature at runtime and we need a\n+    // recent version of the toolkit at compile time, so that we have access to\n+    // the driver's headers.\n+    if (std::min(device_description.driver_version(),\n+                 device_description.compile_time_toolkit_version()) >=\n+        stream_executor::SemanticVersion(12, 9, 0)) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n // Give a short alias to synchronization mode.\n static constexpr auto serialize =\n     CommandBufferCmdExecutor::SynchronizationMode::kSerialize;\n@@ -685,6 +703,141 @@ TEST(CommandBufferCmdTest, RecordExecutorsWithDependencies) {\n   ASSERT_EQ(dst, std::vector<int32_t>(length, 2));\n }\n \n+TEST(CommandBufferCmdTest, NestedChildCmdCreateAndUpdate) {\n+  se::StreamExecutor* stream_executor = GpuExecutor();\n+  if (!IsAtLeastCuda12900(stream_executor)) {\n+    GTEST_SKIP() << \"Child command is not supported for CUDA < 12.9\";\n+  }\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_executor->CreateStream());\n+\n+  // Prepare device memory for three buffers.\n+  int64_t length = 4;\n+  int64_t byte_length = sizeof(int32_t) * length;\n+  se::DeviceMemory<int32_t> a = stream_executor->AllocateArray<int32_t>(length);\n+  se::DeviceMemory<int32_t> b = stream_executor->AllocateArray<int32_t>(length);\n+  se::DeviceMemory<int32_t> c = stream_executor->AllocateArray<int32_t>(length);\n+\n+  // Initialize a = 1s, b = 0s, c = 0s.\n+  TF_ASSERT_OK(stream->Memset32(&a, /*pattern=*/1, byte_length));\n+  TF_ASSERT_OK(stream->MemZero(&b, byte_length));\n+  TF_ASSERT_OK(stream->MemZero(&c, byte_length));\n+\n+  // Buffer allocations.\n+  BufferAllocation alloc_a(/*index=*/0, byte_length, /*color=*/0);\n+  BufferAllocation alloc_b(/*index=*/1, byte_length, /*color=*/0);\n+  BufferAllocation alloc_c(/*index=*/2, byte_length, /*color=*/0);\n+\n+  BufferAllocation::Slice slice_a(&alloc_a, 0, byte_length);\n+  BufferAllocation::Slice slice_b(&alloc_b, 0, byte_length);\n+  BufferAllocation::Slice slice_c(&alloc_c, 0, byte_length);\n+\n+  // Inner child: c = a (device-to-device memcpy)\n+  CommandBufferCmdSequence inner_seq;\n+  inner_seq.Emplace<MemcpyDeviceToDeviceCmd>(slice_c, slice_a, byte_length);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      CommandBufferCmdExecutor inner_executor,\n+      CommandBufferCmdExecutor::Create(std::move(inner_seq), serialize));\n+\n+  // Middle child wraps inner.\n+  CommandBufferCmdSequence middle_seq;\n+  middle_seq.Emplace<ChildCmd>(std::move(inner_executor));\n+  // Add a couple of extra commands that don't affect `c`.\n+  middle_seq.Emplace<Memset32Cmd>(slice_b, /*bit_pattern=*/3);\n+  middle_seq.Emplace<MemcpyDeviceToDeviceCmd>(slice_b, slice_b, byte_length);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      CommandBufferCmdExecutor middle_executor,\n+      CommandBufferCmdExecutor::Create(std::move(middle_seq), serialize));\n+\n+  // Outer child wraps middle.\n+  CommandBufferCmdSequence outer_seq;\n+  outer_seq.Emplace<ChildCmd>(std::move(middle_executor));\n+  // Add a couple more commands at the outer level that still don't affect `c`.\n+  outer_seq.Emplace<MemzeroCmd>(slice_b);\n+  outer_seq.Emplace<EmptyCmd>();\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      CommandBufferCmdExecutor outer_executor,\n+      CommandBufferCmdExecutor::Create(std::move(outer_seq), serialize));\n+\n+  // Prepare state and params; ChildCmd requires initialization to create a\n+  // nested buffer.\n+  CommandBufferCmd::StateManager state;\n+  Thunk::ExecutableSource source = {/*text=*/\"\", /*binary=*/{}};\n+  se::StreamExecutorMemoryAllocator allocator(stream_executor);\n+  BufferAllocations allocations({a, b, c}, 0, &allocator);\n+  TF_ASSERT_OK(outer_executor.Initialize(\n+      {stream_executor, source, &allocations, stream.get(), stream.get()},\n+      state));\n+\n+  // allocations already created above\n+  ServiceExecutableRunOptions run_options;\n+  Thunk::ExecuteParams exec_params = Thunk::ExecuteParams::Create(\n+      run_options, allocations, stream.get(), stream.get(), nullptr, nullptr);\n+  CommandBufferCmd::RecordParams record_params = {state};\n+\n+  // Create a command buffer and record the nested ChildCmd (Create).\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto command_buffer,\n+      stream_executor->CreateCommandBuffer(se::CommandBuffer::Mode::kPrimary));\n+  TF_ASSERT_OK(outer_executor.Record(exec_params, record_params,\n+                                     CommandBufferCmd::RecordCreate{},\n+                                     command_buffer.get(), /*finalize=*/true));\n+  TF_ASSERT_OK(command_buffer->Submit(stream.get()));\n+\n+  // Verify c == a (all ones).\n+  std::vector<int32_t> dst(length, 0);\n+  TF_ASSERT_OK(stream->Memcpy(dst.data(), c, byte_length));\n+  ASSERT_EQ(dst, std::vector<int32_t>(length, 1));\n+\n+  // Also verify a == 1s and b == 0s.\n+  {\n+    std::vector<int32_t> a_host(length, 0);\n+    std::vector<int32_t> b_host(length, 0);\n+    TF_ASSERT_OK(stream->Memcpy(a_host.data(), a, byte_length));\n+    TF_ASSERT_OK(stream->Memcpy(b_host.data(), b, byte_length));\n+    ASSERT_EQ(a_host, std::vector<int32_t>(length, 1));\n+    ASSERT_EQ(b_host, std::vector<int32_t>(length, 0));\n+  }\n+\n+  // Now update: change a and c buffers and record an update on the same command\n+  // buffer.\n+  se::DeviceMemory<int32_t> a2 =\n+      stream_executor->AllocateArray<int32_t>(length);\n+  se::DeviceMemory<int32_t> c2 =\n+      stream_executor->AllocateArray<int32_t>(length);\n+  TF_ASSERT_OK(stream->Memset32(&a2, /*pattern=*/7, byte_length));\n+  TF_ASSERT_OK(stream->MemZero(&c2, byte_length));\n+\n+  BufferAllocations allocations2({a2, b, c2}, 0, &allocator);\n+  Thunk::ExecuteParams exec_params2 = Thunk::ExecuteParams::Create(\n+      run_options, allocations2, stream.get(), stream.get(), nullptr, nullptr);\n+\n+  // Indicate which allocations changed to ensure update is not skipped.\n+  std::vector<BufferAllocation::Index> updated_allocs = {0, 2};\n+  CommandBufferCmd::RecordParams record_params2 = {state,\n+                                                   std::move(updated_allocs)};\n+\n+  TF_ASSERT_OK(outer_executor.Record(exec_params2, record_params2,\n+                                     CommandBufferCmd::RecordCreate{},\n+                                     command_buffer.get(), /*finalize=*/true));\n+  TF_ASSERT_OK(command_buffer->Submit(stream.get()));\n+\n+  // Verify c2 == a2 (all sevens).\n+  std::vector<int32_t> dst2(length, 0);\n+  TF_ASSERT_OK(stream->Memcpy(dst2.data(), c2, byte_length));\n+  ASSERT_EQ(dst2, std::vector<int32_t>(length, 7));\n+\n+  // Also verify a2 == 7s and b == 0s.\n+  {\n+    std::vector<int32_t> a2_host(length, 0);\n+    std::vector<int32_t> b_host(length, 0);\n+    TF_ASSERT_OK(stream->Memcpy(a2_host.data(), a2, byte_length));\n+    TF_ASSERT_OK(stream->Memcpy(b_host.data(), b, byte_length));\n+    ASSERT_EQ(a2_host, std::vector<int32_t>(length, 7));\n+    ASSERT_EQ(b_host, std::vector<int32_t>(length, 0));\n+  }\n+}\n+\n //===----------------------------------------------------------------------===//\n // Performance benchmarks below\n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "3eed07d8efb4b2a98a3089192473fcc30fb7ae1d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_thunk_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d355b1581c9a749f497b5c8824efea292af04599/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d355b1581c9a749f497b5c8824efea292af04599/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc?ref=d355b1581c9a749f497b5c8824efea292af04599",
            "patch": "@@ -871,15 +871,12 @@ TEST(CommandBufferThunkTest, ChildGemmCmd) {\n       run_options, allocations, stream.get(), stream.get(), nullptr, nullptr);\n \n   Thunk::ExecutableSource source = {/*text=*/\"\", /*binary=*/{}};\n-  VLOG(0) << \"Initialize thunk\";\n   TF_ASSERT_OK(thunk.Initialize(\n       {stream_executor, source, &allocations, stream.get(), stream.get()}));\n \n-  VLOG(0) << \"Initialize done\";\n   // Execute command buffer thunk and verify that it executed a GEMM.\n   TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n \n-  VLOG(0) << \"Execute thunk done\";\n   TF_ASSERT_OK(stream->BlockHostUntilDone());\n \n   // Copy `out` data back to host."
        }
    ],
    "stats": {
        "total": 156,
        "additions": 153,
        "deletions": 3
    }
}