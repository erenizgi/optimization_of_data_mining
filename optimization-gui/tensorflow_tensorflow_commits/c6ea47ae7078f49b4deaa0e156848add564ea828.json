{
    "author": "loislo",
    "message": "[XLA:GPU] Add CompositeRewriter to GPU compiler.\n\nThis change introduces a new HLO pass, `CompositeRewriter`. This pass identifies `kCall` instructions marked as a composite named \"xla.scaled_dot\" and rewrites them into a dedicated `ScaledDot` HLO instruction.\n\nPiperOrigin-RevId: 815612986",
    "sha": "c6ea47ae7078f49b4deaa0e156848add564ea828",
    "files": [
        {
            "sha": "6358fac97fdf6545f707f54697763138040b3327",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=c6ea47ae7078f49b4deaa0e156848add564ea828",
            "patch": "@@ -1723,6 +1723,7 @@ cc_library(\n         \"//xla/service/gpu/transforms:algorithm_checker\",\n         \"//xla/service/gpu/transforms:async_wrapper\",\n         \"//xla/service/gpu/transforms:command_buffer_scheduling\",\n+        \"//xla/service/gpu/transforms:composite_rewriter\",\n         \"//xla/service/gpu/transforms:conv_rewriter\",\n         \"//xla/service/gpu/transforms:cudnn_custom_call_converter\",\n         \"//xla/service/gpu/transforms:custom_kernel_fusion_rewriter\","
        },
        {
            "sha": "640effec6d24ace08de1f53d8d7f764aa801c125",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=c6ea47ae7078f49b4deaa0e156848add564ea828",
            "patch": "@@ -217,6 +217,7 @@ limitations under the License.\n #include \"xla/service/gpu/transforms/collectives/gpu_collective_combiner_utils.h\"\n #include \"xla/service/gpu/transforms/collectives/reduce_scatter_combiner.h\"\n #include \"xla/service/gpu/transforms/command_buffer_scheduling.h\"\n+#include \"xla/service/gpu/transforms/composite_rewriter.h\"\n #include \"xla/service/gpu/transforms/conv_rewriter.h\"\n #include \"xla/service/gpu/transforms/cudnn_custom_call_converter.h\"\n #include \"xla/service/gpu/transforms/custom_kernel_fusion_rewriter.h\"\n@@ -615,6 +616,7 @@ absl::Status RunPreSPMDPartitionerPasses(HloModule* hlo_module) {\n   // Run some IR cleanup passes before running the SPMD partitioning\n   // passes.\n   pre_spmd_pipeline.AddPass<CuDnnCustomCallConverter>();\n+  pre_spmd_pipeline.AddPass<CompositeRewriter>();\n   pre_spmd_pipeline.AddPass<ConvertMemoryPlacementToInternalAnnotations>();\n   pre_spmd_pipeline.AddPass<FlattenCallGraph>();\n   pre_spmd_pipeline.AddPass<CallInliner>("
        },
        {
            "sha": "ff032d523a292b6ff0ef804b5bad6b55eaa2368a",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 31,
            "deletions": 0,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=c6ea47ae7078f49b4deaa0e156848add564ea828",
            "patch": "@@ -2415,6 +2415,37 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"composite_rewriter\",\n+    srcs = [\"composite_rewriter.cc\"],\n+    hdrs = [\"composite_rewriter.h\"],\n+    deps = [\n+        \"//xla:util\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/pass:hlo_pass\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"composite_rewriter_test\",\n+    srcs = [\"composite_rewriter_test.cc\"],\n+    deps = [\n+        \":composite_rewriter\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/parser:hlo_parser\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n xla_cc_test(\n     name = \"scalar_constant_sinker_test\",\n     srcs = [\"scalar_constant_sinker_test.cc\"],"
        },
        {
            "sha": "a18de06d956cf69691f8ac32781633ce7cc740a1",
            "filename": "third_party/xla/xla/service/gpu/transforms/composite_rewriter.cc",
            "status": "added",
            "additions": 86,
            "deletions": 0,
            "changes": 86,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcomposite_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcomposite_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcomposite_rewriter.cc?ref=c6ea47ae7078f49b4deaa0e156848add564ea828",
            "patch": "@@ -0,0 +1,86 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/transforms/composite_rewriter.h\"\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_casting_utils.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n+#include \"xla/xla_data.pb.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+absl::StatusOr<bool> CompositeRewriter::RewriteComputation(\n+    HloComputation* computation) {\n+  bool changed = false;\n+  for (HloInstruction* instruction : computation->MakeInstructionPostOrder()) {\n+    if (instruction->opcode() != HloOpcode::kCall) {\n+      continue;\n+    }\n+    auto call = Cast<HloCallInstruction>(instruction);\n+    if (!call->is_composite()) {\n+      continue;\n+    }\n+    if (!call->has_frontend_attributes()) {\n+      VLOG(3) << \"No frontend attributes\";\n+      continue;\n+    }\n+    auto attrs = call->frontend_attributes().map();\n+    auto key = \"composite.name\";\n+    if (!attrs.contains(key) || attrs.at(key) != \"xla.scaled_dot\") {\n+      VLOG(3) << key << \" is not xla.scaled_dot: \" << attrs.at(key);\n+      continue;\n+    }\n+    DotDimensionNumbers dot_dimension_numbers;\n+    dot_dimension_numbers.add_lhs_contracting_dimensions(2);\n+    dot_dimension_numbers.add_rhs_contracting_dimensions(2);\n+    dot_dimension_numbers.add_lhs_batch_dimensions(0);\n+    dot_dimension_numbers.add_rhs_batch_dimensions(0);\n+\n+    auto* scaled_dot =\n+        computation->AddInstruction(HloInstruction::CreateScaledDot(\n+            call->shape(), call->mutable_operand(0), call->mutable_operand(2),\n+            call->mutable_operand(1), call->mutable_operand(3),\n+            dot_dimension_numbers, PrecisionConfig{}));\n+    TF_RETURN_IF_ERROR(call->ReplaceAllUsesWith(scaled_dot));\n+    TF_RETURN_IF_ERROR(computation->RemoveInstruction(call));\n+    changed = true;\n+  }\n+  return changed;\n+}\n+\n+absl::StatusOr<bool> CompositeRewriter::Run(\n+    HloModule* module, const absl::flat_hash_set<absl::string_view>&) {\n+  bool changed = false;\n+  for (HloComputation* computation : module->computations()) {\n+    TF_ASSIGN_OR_RETURN(bool result, RewriteComputation(computation));\n+    changed |= result;\n+  }\n+  return changed;\n+}\n+\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "bcad646641470d41be269a1ad346eec22f5345aa",
            "filename": "third_party/xla/xla/service/gpu/transforms/composite_rewriter.h",
            "status": "added",
            "additions": 45,
            "deletions": 0,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcomposite_rewriter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcomposite_rewriter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcomposite_rewriter.h?ref=c6ea47ae7078f49b4deaa0e156848add564ea828",
            "patch": "@@ -0,0 +1,45 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_SERVICE_GPU_TRANSFORMS_COMPOSITE_REWRITER_H_\n+#define XLA_SERVICE_GPU_TRANSFORMS_COMPOSITE_REWRITER_H_\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/pass/hlo_pass_interface.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+// This pass rewrites the composite a specific instruction.\n+class CompositeRewriter : public HloModulePass {\n+ public:\n+  absl::string_view name() const override { return \"composite-rewriter\"; }\n+\n+  using HloPassInterface::Run;\n+  absl::StatusOr<bool> Run(\n+      HloModule* module,\n+      const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n+\n+  absl::StatusOr<bool> RewriteComputation(HloComputation* computation);\n+};\n+\n+}  // namespace gpu\n+}  // namespace xla\n+\n+#endif  // XLA_SERVICE_GPU_TRANSFORMS_COMPOSITE_REWRITER_H_"
        },
        {
            "sha": "7968e3bba68561d71ed02fb18e620abde9ee8365",
            "filename": "third_party/xla/xla/service/gpu/transforms/composite_rewriter_test.cc",
            "status": "added",
            "additions": 80,
            "deletions": 0,
            "changes": 80,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcomposite_rewriter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6ea47ae7078f49b4deaa0e156848add564ea828/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcomposite_rewriter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcomposite_rewriter_test.cc?ref=c6ea47ae7078f49b4deaa0e156848add564ea828",
            "patch": "@@ -0,0 +1,80 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/transforms/composite_rewriter.h\"\n+\n+#include <string>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/status/status_matchers.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/parser/hlo_parser.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+TEST(CompositeRewriterTest, ScaledDotCompositeRewrite) {\n+  const std::string hlo_string = R\"(\n+    HloModule jit_my_dot\n+\n+    %xla.scaled_dot.1 {\n+      %lhs = f8e4m3fn[3,128,256]{2,1,0} parameter(0)\n+      %lhs_bf16 = bf16[3,128,256]{2,1,0} convert(%lhs)\n+      %lhs_scales = f8e8m0fnu[3,128,8]{2,1,0} parameter(2)\n+      %lhs_scales_bf16 = bf16[3,128,8]{2,1,0} convert(%lhs_scales)\n+      %lhs_scales_bf16_broadcasted = bf16[3,128,8,32]{3,2,1,0} broadcast(%lhs_scales_bf16), dimensions={0,1,2}\n+      %lhs_scales_broadcasted = bf16[3,128,256]{2,1,0} reshape(%lhs_scales_bf16_broadcasted)\n+      %lhs_scaled = bf16[3,128,256]{2,1,0} multiply(%lhs_bf16, %lhs_scales_broadcasted)\n+      %rhs = f8e4m3fn[3,128,256]{2,1,0} parameter(1)\n+      %rhs_bf16 = bf16[3,128,256]{2,1,0} convert(%rhs)\n+      %rhs_scales = f8e8m0fnu[3,128,8]{2,1,0} parameter(3)\n+      %rhs_scales_bf16 = bf16[3,128,8]{2,1,0} convert(%rhs_scales)\n+      %rhs_scales_bf16_broadcasted = bf16[3,128,8,32]{3,2,1,0} broadcast(%rhs_scales_bf16), dimensions={0,1,2}\n+      %rhs_scales_broadcasted = bf16[3,128,256]{2,1,0} reshape(%rhs_scales_bf16_broadcasted)\n+      %rhs_scaled = bf16[3,128,256]{2,1,0} multiply(%rhs_bf16, %rhs_scales_broadcasted)\n+      %rhs_scaled_transposed = bf16[3,256,128]{1,2,0} transpose(%rhs_scaled), dimensions={0,2,1}\n+      ROOT %dot_general.1 = bf16[3,128,128]{2,1,0} dot(%lhs_scaled, %rhs_scaled_transposed),\n+          lhs_batch_dims={0},\n+          lhs_contracting_dims={2},\n+          rhs_batch_dims={0},\n+          rhs_contracting_dims={1}\n+    }\n+\n+    ENTRY %main {\n+      %lhs = f8e4m3fn[3,128,256]{2,1,0} parameter(0)\n+      %rhs = f8e4m3fn[3,128,256]{2,1,0} parameter(1)\n+      %lhs_scales = f8e8m0fnu[3,128,8]{2,1,0} parameter(2)\n+      %rhs_scales = f8e8m0fnu[3,128,8]{2,1,0} parameter(3)\n+      ROOT %call.1 = bf16[3,128,128]{2,1,0} call(%lhs, %rhs, %lhs_scales, %rhs_scales),\n+          to_apply=%xla.scaled_dot.1,\n+          is_composite=true,\n+          frontend_attributes={\n+            composite.attributes={preferred_element_type = bf16},\n+            composite.name=\"xla.scaled_dot\",\n+            composite.version=\"1\"\n+          }\n+    })\";\n+  CompositeRewriter rewriter;\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnUnverifiedModule(hlo_string));\n+  EXPECT_THAT(rewriter.Run(module.get()), absl_testing::IsOkAndHolds(true));\n+  EXPECT_THAT(module->entry_computation()->root_instruction()->opcode(),\n+              HloOpcode::kScaledDot);\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        }
    ],
    "stats": {
        "total": 245,
        "additions": 245,
        "deletions": 0
    }
}