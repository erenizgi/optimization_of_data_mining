{
    "author": "beckerhe",
    "message": "Reverts bce2e5f26d70c61f90df210206ab2f7d1a121be5\n\nPiperOrigin-RevId: 800575277",
    "sha": "328551db6e55b042b1bcf6df1392c94907708166",
    "files": [
        {
            "sha": "cef8c96859c7de8c3f07350a2c5c21d2330b014c",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 47,
            "changes": 47,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/328551db6e55b042b1bcf6df1392c94907708166/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/328551db6e55b042b1bcf6df1392c94907708166/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=328551db6e55b042b1bcf6df1392c94907708166",
            "patch": "@@ -437,7 +437,6 @@ cc_library(\n         \":cuda_compute_capability\",\n         \":cuda_diagnostics\",\n         \":cuda_platform_id\",\n-        \":cudnn_api_wrappers\",\n         \":cudnn_frontend_helpers\",\n         \":cudnn_sdpa_score_mod\",\n         \"//xla/stream_executor:activate_context\",\n@@ -448,7 +447,6 @@ cc_library(\n         \"//xla/stream_executor:numeric_options\",\n         \"//xla/stream_executor:plugin_registry\",\n         \"//xla/stream_executor:scratch_allocator\",\n-        \"//xla/stream_executor:semantic_version\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/platform:initialize\",\n@@ -483,50 +481,6 @@ cc_library(\n     alwayslink = True,\n )\n \n-cc_library(\n-    name = \"cudnn_api_wrappers\",\n-    srcs = [\"cudnn_api_wrappers.cc\"],\n-    hdrs = [\"cudnn_api_wrappers.h\"],\n-    tags = [\n-        \"cuda-only\",\n-        \"gpu\",\n-    ],\n-    deps = [\n-        \"//xla/stream_executor:semantic_version\",\n-        \"//xla/tsl/platform:errors\",\n-        \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/status:statusor\",\n-        \"@com_google_absl//absl/strings\",\n-        \"@com_google_absl//absl/strings:string_view\",\n-        \"@local_config_cuda//cuda:cuda_headers\",\n-        \"@local_config_cuda//cuda:cudnn_header\",\n-    ],\n-)\n-\n-xla_cc_test(\n-    name = \"cudnn_api_wrappers_test\",\n-    srcs = [\"cudnn_api_wrappers_test.cc\"],\n-    tags = [\n-        \"cuda-only\",\n-        \"gpu\",\n-    ] + if_google([\n-        \"not_run:arm\",  # TODO(hebecker): Remove this once we have a cuDNN build for AArch64.\n-    ]),\n-    deps = [\n-        \":cuda_platform_id\",\n-        \":cudnn_api_wrappers\",\n-        \"//xla/stream_executor:platform_manager\",\n-        \"//xla/stream_executor:semantic_version\",\n-        \"//xla/tsl/cuda:cudnn\",  # build_cleaner: keep\n-        \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/status:status_matchers\",\n-        \"@com_google_googletest//:gtest_main\",\n-        \"@local_config_cuda//cuda:cuda_headers\",\n-    ],\n-)\n-\n cc_library(\n     name = \"cudnn_sdpa_score_mod\",\n     srcs = [\"cudnn_sdpa_score_mod.cc\"],\n@@ -1052,7 +1006,6 @@ cc_library(\n         \":cuda_stream\",\n         \":cuda_timer\",\n         \":cuda_version_parser\",\n-        \":cudnn_api_wrappers\",\n         \":tma_util\",\n         \"//xla/backends/gpu/collectives:gpu_collectives\",\n         \"//xla/core/collectives:collectives_registry\","
        },
        {
            "sha": "49568260a3bad9760b48759e7c1d4fe7f71262fd",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc",
            "status": "modified",
            "additions": 23,
            "deletions": 16,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/328551db6e55b042b1bcf6df1392c94907708166/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_dnn.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/328551db6e55b042b1bcf6df1392c94907708166/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_dnn.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_dnn.cc?ref=328551db6e55b042b1bcf6df1392c94907708166",
            "patch": "@@ -57,7 +57,6 @@ limitations under the License.\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/cuda/cuda_diagnostics.h\"\n #include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n-#include \"xla/stream_executor/cuda/cudnn_api_wrappers.h\"\n #include \"xla/stream_executor/cuda/cudnn_frontend_helpers.h\"\n #include \"xla/stream_executor/cuda/cudnn_sdpa_score_mod.h\"\n #include \"xla/stream_executor/data_type.h\"\n@@ -68,7 +67,6 @@ limitations under the License.\n #include \"xla/stream_executor/platform/initialize.h\"\n #include \"xla/stream_executor/plugin_registry.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n-#include \"xla/stream_executor/semantic_version.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -236,10 +234,10 @@ class CudnnHandle {\n //\n // Patch releases are always forward and backward compatible and therefore\n // need not match.\n-bool IsSourceCompatibleWithCudnnLibrary(const SemanticVersion& source_version,\n-                                        const SemanticVersion& loaded_version) {\n-  return loaded_version.major() == source_version.major() &&\n-         loaded_version.minor() >= source_version.minor();\n+bool IsSourceCompatibleWithCudnnLibrary(dnn::VersionInfo source_version,\n+                                        dnn::VersionInfo loaded_version) {\n+  return loaded_version.major_version() == source_version.major_version() &&\n+         loaded_version.minor_version() >= source_version.minor_version();\n }\n \n }  // namespace\n@@ -339,6 +337,12 @@ namespace {\n // RNNs in cudnn.\n cudnnDataType_t GetRnnComputeType(dnn::DataType data_type);\n \n+absl::StatusOr<int> GetCudnnProperty(libraryPropertyType type) {\n+  int value;\n+  RETURN_IF_CUDNN_ERROR(cudnnGetProperty(type, &value));\n+  return value;\n+}\n+\n cudnnRNNAlgo_t ToCudnnRNNAlgo(std::optional<dnn::AlgorithmDesc> algorithm) {\n   if (!algorithm.has_value()) {\n     return CUDNN_RNN_ALGO_STANDARD;\n@@ -354,6 +358,13 @@ cudnnRNNAlgo_t ToCudnnRNNAlgo(std::optional<dnn::AlgorithmDesc> algorithm) {\n   }\n }\n \n+absl::StatusOr<dnn::VersionInfo> GetLoadedCudnnVersion() {\n+  TF_ASSIGN_OR_RETURN(int major, GetCudnnProperty(MAJOR_VERSION));\n+  TF_ASSIGN_OR_RETURN(int minor, GetCudnnProperty(MINOR_VERSION));\n+  TF_ASSIGN_OR_RETURN(int patch_level, GetCudnnProperty(PATCH_LEVEL));\n+  return dnn::VersionInfo(major, minor, patch_level);\n+}\n+\n enum class PreloadCudnnType { ConvFwd, ConvBwdFilter, ConvBwdData, Rnn };\n \n // Preload sub libs for cudnn 8.0.4+ to make sure that the loading time isn't\n@@ -439,15 +450,14 @@ absl::Status CudnnSupport::Init() {\n   cudnnHandle_t cudnn_handle = nullptr;\n   const auto status = cudnnCreate(&cudnn_handle);\n   if (status == CUDNN_STATUS_SUCCESS) {\n-    constexpr SemanticVersion kSourceVersion(CUDNN_MAJOR, CUDNN_MINOR,\n-                                             CUDNN_PATCHLEVEL);\n+    dnn::VersionInfo source_version(CUDNN_MAJOR, CUDNN_MINOR, CUDNN_PATCHLEVEL);\n \n-    TF_ASSIGN_OR_RETURN(SemanticVersion loaded_version,\n-                        cuda::GetLoadedCudnnVersion());\n-    if (!IsSourceCompatibleWithCudnnLibrary(kSourceVersion, loaded_version)) {\n+    TF_ASSIGN_OR_RETURN(dnn::VersionInfo loaded_version,\n+                        GetLoadedCudnnVersion());\n+    if (!IsSourceCompatibleWithCudnnLibrary(source_version, loaded_version)) {\n       const std::string error = absl::StrCat(\n           \"Loaded runtime CuDNN library: \", loaded_version.ToString(),\n-          \" but source was compiled with: \", kSourceVersion.ToString(),\n+          \" but source was compiled with: \", source_version.ToString(),\n           \".  CuDNN library needs to have matching major version and equal or \"\n           \"higher minor version. If using a binary install, upgrade your CuDNN \"\n           \"library.  If building from sources, make sure the library loaded at \"\n@@ -494,10 +504,7 @@ void CudnnSupport::NotifyStreamDestroyed(Stream* stream) /* override */ {\n }\n \n absl::StatusOr<stream_executor::dnn::VersionInfo> CudnnSupport::GetVersion() {\n-  TF_ASSIGN_OR_RETURN(SemanticVersion version,\n-                      stream_executor::cuda::GetLoadedCudnnVersion());\n-  return stream_executor::dnn::VersionInfo(version.major(), version.minor(),\n-                                           version.patch());\n+  return GetLoadedCudnnVersion();\n }\n \n namespace {"
        },
        {
            "sha": "be937f4b31b854897561d4c089f583e54fd8057f",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 11,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/328551db6e55b042b1bcf6df1392c94907708166/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/328551db6e55b042b1bcf6df1392c94907708166/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc?ref=328551db6e55b042b1bcf6df1392c94907708166",
            "patch": "@@ -62,7 +62,6 @@ limitations under the License.\n #include \"xla/stream_executor/cuda/cuda_stream.h\"\n #include \"xla/stream_executor/cuda/cuda_timer.h\"\n #include \"xla/stream_executor/cuda/cuda_version_parser.h\"\n-#include \"xla/stream_executor/cuda/cudnn_api_wrappers.h\"\n #include \"xla/stream_executor/cuda/tma_util.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_memory.h\"\n@@ -1309,16 +1308,6 @@ CudaExecutor::CreateDeviceDescription(int device_ordinal) {\n   desc.set_compile_time_toolkit_version(\n       ParseCudaVersion(CUDA_VERSION).value_or(SemanticVersion{0, 0, 0}));\n \n-  absl::StatusOr<SemanticVersion> cudnn_version = cuda::GetLoadedCudnnVersion();\n-  if (cudnn_version.ok()) {\n-    desc.set_dnn_version(*cudnn_version);\n-  } else {\n-    LOG(WARNING)\n-        << \"Failed to determine cuDNN version (Note that this is expected if \"\n-           \"the application doesn't link the cuDNN plugin): \"\n-        << cudnn_version.status();\n-  }\n-\n   {\n     std::string pci_bus_id = GetPCIBusID(device);\n     desc.set_pci_bus_id(pci_bus_id);"
        },
        {
            "sha": "d2af599714b7338046b3a6004307dec89c8f6dd1",
            "filename": "third_party/xla/xla/stream_executor/cuda/cudnn_api_wrappers.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 118,
            "changes": 118,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/af421afff05cbc7f331b6f1a7948645ea15186f8/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcudnn_api_wrappers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/af421afff05cbc7f331b6f1a7948645ea15186f8/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcudnn_api_wrappers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcudnn_api_wrappers.cc?ref=af421afff05cbc7f331b6f1a7948645ea15186f8",
            "patch": "@@ -1,118 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/stream_executor/cuda/cudnn_api_wrappers.h\"\n-\n-#include <string>\n-\n-#include \"absl/status/status.h\"\n-#include \"absl/status/statusor.h\"\n-#include \"absl/strings/str_cat.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"third_party/gpus/cuda/include/library_types.h\"\n-#include \"third_party/gpus/cudnn/cudnn_graph.h\"\n-#include \"xla/stream_executor/semantic_version.h\"\n-#include \"xla/tsl/platform/errors.h\"\n-#include \"xla/tsl/platform/statusor.h\"\n-\n-namespace stream_executor {\n-namespace cuda {\n-\n-static std::string CudnnStatusToString(cudnnStatus_t status) {\n-  switch (status) {\n-    case CUDNN_STATUS_SUCCESS:\n-      return \"CUDNN_STATUS_SUCCESS\";\n-    case CUDNN_STATUS_NOT_INITIALIZED:\n-      return \"CUDNN_STATUS_NOT_INITIALIZED\";\n-    case CUDNN_STATUS_ALLOC_FAILED:\n-      return \"CUDNN_STATUS_ALLOC_FAILED\";\n-    case CUDNN_STATUS_BAD_PARAM:\n-      return \"CUDNN_STATUS_BAD_PARAM\";\n-    case CUDNN_STATUS_INTERNAL_ERROR:\n-      return \"CUDNN_STATUS_INTERNAL_ERROR\";\n-    case CUDNN_STATUS_INVALID_VALUE:\n-      return \"CUDNN_STATUS_INVALID_VALUE\";\n-    case CUDNN_STATUS_ARCH_MISMATCH:\n-      return \"CUDNN_STATUS_ARCH_MISMATCH\";\n-    case CUDNN_STATUS_MAPPING_ERROR:\n-      return \"CUDNN_STATUS_MAPPING_ERROR\";\n-    case CUDNN_STATUS_EXECUTION_FAILED:\n-      return \"CUDNN_STATUS_EXECUTION_FAILED\";\n-    case CUDNN_STATUS_NOT_SUPPORTED:\n-      return \"CUDNN_STATUS_NOT_SUPPORTED\";\n-    case CUDNN_STATUS_LICENSE_ERROR:\n-      return \"CUDNN_STATUS_LICENSE_ERROR\";\n-    case CUDNN_STATUS_RUNTIME_PREREQUISITE_MISSING:\n-      return \"CUDNN_STATUS_RUNTIME_PREREQUISITE_MISSING\";\n-    case CUDNN_STATUS_RUNTIME_IN_PROGRESS:\n-      return \"CUDNN_STATUS_RUNTIME_IN_PROGRESS\";\n-    case CUDNN_STATUS_RUNTIME_FP_OVERFLOW:\n-      return \"CUDNN_STATUS_RUNTIME_FP_OVERFLOW\";\n-    default:\n-      return absl::StrCat(\"<unknown cudnn status: \", static_cast<int>(status),\n-                          \">\");\n-  }\n-}\n-\n-absl::Status ToStatus(cudnnStatus_t status, absl::string_view detail) {\n-  if (status == CUDNN_STATUS_SUCCESS) {\n-    return absl::OkStatus();\n-  }\n-  return absl::InternalError(\n-      absl::StrCat(\"cuDNN error: \", CudnnStatusToString(status),\n-                   detail.empty() ? \"\" : absl::StrCat(\":\", detail)));\n-}\n-\n-// cudnnGetProperty is forward declared as a weak symbol such that XLA-internal\n-// targets can depend on this wrapper library without linking the\n-// cudnn_plugin. This is mainly relevant for unit tests that use the CUDA\n-// executor which depends on this wrapper but should not introduce a dependency\n-// on cudnn.\n-extern \"C\" [[gnu::weak]] cudnnStatus_t cudnnGetProperty(\n-    libraryPropertyType type, int* value);\n-\n-static libraryPropertyType ToLibraryPropertyType(CudnnProperty type) {\n-  switch (type) {\n-    case CudnnProperty::kMajorVersion:\n-      return MAJOR_VERSION;\n-    case CudnnProperty::kMinorVersion:\n-      return MINOR_VERSION;\n-    case CudnnProperty::kPatchLevelVersion:\n-      return PATCH_LEVEL;\n-  }\n-}\n-\n-absl::StatusOr<int> GetCudnnProperty(CudnnProperty type) {\n-  if (!cudnnGetProperty) {\n-    return absl::NotFoundError(\"cuDNN is not linked into the application.\");\n-  }\n-  int value;\n-  TF_RETURN_IF_ERROR(\n-      ToStatus(cudnnGetProperty(ToLibraryPropertyType(type), &value)));\n-  return value;\n-}\n-\n-absl::StatusOr<SemanticVersion> GetLoadedCudnnVersion() {\n-  TF_ASSIGN_OR_RETURN(int major,\n-                      GetCudnnProperty(CudnnProperty::kMajorVersion));\n-  TF_ASSIGN_OR_RETURN(int minor,\n-                      GetCudnnProperty(CudnnProperty::kMinorVersion));\n-  TF_ASSIGN_OR_RETURN(int patch,\n-                      GetCudnnProperty(CudnnProperty::kPatchLevelVersion));\n-  return SemanticVersion(major, minor, patch);\n-}\n-\n-}  // namespace cuda\n-}  // namespace stream_executor"
        },
        {
            "sha": "b6fc23b6f0090a5afa12c4fa3fd4734a0ccc9b1a",
            "filename": "third_party/xla/xla/stream_executor/cuda/cudnn_api_wrappers.h",
            "status": "removed",
            "additions": 0,
            "deletions": 51,
            "changes": 51,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/af421afff05cbc7f331b6f1a7948645ea15186f8/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcudnn_api_wrappers.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/af421afff05cbc7f331b6f1a7948645ea15186f8/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcudnn_api_wrappers.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcudnn_api_wrappers.h?ref=af421afff05cbc7f331b6f1a7948645ea15186f8",
            "patch": "@@ -1,51 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_STREAM_EXECUTOR_CUDA_CUDNN_API_WRAPPERS_H_\n-#define XLA_STREAM_EXECUTOR_CUDA_CUDNN_API_WRAPPERS_H_\n-\n-#include \"absl/status/status.h\"\n-#include \"absl/status/statusor.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"third_party/gpus/cudnn/cudnn_graph.h\"\n-#include \"xla/stream_executor/semantic_version.h\"\n-\n-namespace stream_executor {\n-namespace cuda {\n-\n-// This enum holds all the properties that can be queried from cuDNN.\n-enum class CudnnProperty {\n-  kMajorVersion,\n-  kMinorVersion,\n-  kPatchLevelVersion,\n-};\n-\n-// Returns the value of the given cuDNN property - or an error if cuDNN is not\n-// loaded.\n-absl::StatusOr<int> GetCudnnProperty(CudnnProperty type);\n-\n-// Returns the version of the loaded cuDNN library - or an error if cuDNN is not\n-// loaded.\n-absl::StatusOr<SemanticVersion> GetLoadedCudnnVersion();\n-\n-// Converts a cuDNN status code to an absl::Status of type\n-// absl::StatusCode::kInternal. If `detail` is non-empty, it is appended to the\n-// error message.\n-absl::Status ToStatus(cudnnStatus_t status, absl::string_view detail = \"\");\n-\n-}  // namespace cuda\n-}  // namespace stream_executor\n-\n-#endif  // XLA_STREAM_EXECUTOR_CUDA_CUDNN_API_WRAPPERS_H_"
        },
        {
            "sha": "8c16b7e1f56b143552969f76ddf338bfce06ec36",
            "filename": "third_party/xla/xla/stream_executor/cuda/cudnn_api_wrappers_test.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 72,
            "changes": 72,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/af421afff05cbc7f331b6f1a7948645ea15186f8/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcudnn_api_wrappers_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/af421afff05cbc7f331b6f1a7948645ea15186f8/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcudnn_api_wrappers_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcudnn_api_wrappers_test.cc?ref=af421afff05cbc7f331b6f1a7948645ea15186f8",
            "patch": "@@ -1,72 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/stream_executor/cuda/cudnn_api_wrappers.h\"\n-\n-#include <gmock/gmock.h>\n-#include <gtest/gtest.h>\n-#include \"absl/status/status.h\"\n-#include \"absl/status/status_matchers.h\"\n-#include \"third_party/gpus/cudnn/cudnn_graph.h\"\n-#include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n-#include \"xla/stream_executor/platform_manager.h\"\n-#include \"xla/stream_executor/semantic_version.h\"\n-#include \"xla/tsl/platform/statusor.h\"\n-\n-namespace stream_executor {\n-namespace cuda {\n-namespace {\n-using absl_testing::IsOk;\n-using absl_testing::IsOkAndHolds;\n-using absl_testing::StatusIs;\n-using testing::Ge;\n-using testing::HasSubstr;\n-\n-TEST(CudnnApiWrappersTest, GetCudnnProperty) {\n-  EXPECT_THAT(GetCudnnProperty(CudnnProperty::kMajorVersion),\n-              IsOkAndHolds(Ge(8)));\n-}\n-\n-TEST(CudnnApiWrappersTest, GetLoadedCudnnVersion) {\n-  // This test makes sure we can determine the version of cuDNN without an\n-  // accelerator present and without initializing cuDNN.\n-  TF_ASSERT_OK_AND_ASSIGN(SemanticVersion version,\n-                          stream_executor::cuda::GetLoadedCudnnVersion());\n-\n-  // As the time of writing this test, the oldest supported version of cuDNN\n-  // is 8.9.4. So we expect the version to be at least this.\n-  EXPECT_GE(version, SemanticVersion(8, 9, 4));\n-\n-  // We don't link in the CUDA platform intentionally, to make sure the above\n-  // version query works without any additional dependencies. This assertion\n-  // ensures that the dependency on the CUDA platform will not be accidentally\n-  // introduced in the future.\n-  EXPECT_THAT(stream_executor::PlatformManager::PlatformWithId(kCudaPlatformId),\n-              StatusIs(absl::StatusCode::kNotFound));\n-}\n-\n-TEST(CudnnApiWrappersTest, ToStatus) {\n-  EXPECT_THAT(ToStatus(CUDNN_STATUS_SUCCESS), IsOk());\n-  EXPECT_THAT(ToStatus(CUDNN_STATUS_NOT_INITIALIZED),\n-              StatusIs(absl::StatusCode::kInternal,\n-                       HasSubstr(\"CUDNN_STATUS_NOT_INITIALIZED\")));\n-  EXPECT_THAT(ToStatus(CUDNN_STATUS_NOT_SUPPORTED, \"some additional detail\"),\n-              absl_testing::StatusIs(absl::StatusCode::kInternal,\n-                                     HasSubstr(\"some additional detail\")));\n-}\n-\n-}  // namespace\n-}  // namespace cuda\n-}  // namespace stream_executor"
        },
        {
            "sha": "cb8163d494c0a30991eec534c30866bc281e2728",
            "filename": "third_party/xla/xla/stream_executor/device_description.h",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/328551db6e55b042b1bcf6df1392c94907708166/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/328551db6e55b042b1bcf6df1392c94907708166/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h?ref=328551db6e55b042b1bcf6df1392c94907708166",
            "patch": "@@ -192,9 +192,6 @@ class DeviceDescription {\n     return compile_time_toolkit_version_;\n   }\n \n-  // Returns the DNN version (cuDNN or hipDNN) - or 0.0.0 if not available.\n-  SemanticVersion dnn_version() const { return dnn_version_; }\n-\n   // Returns the name that the device reports. Vendor dependent.\n   const std::string& name() const { return name_; }\n \n@@ -411,7 +408,6 @@ class DeviceDescription {\n   void set_runtime_version(const SemanticVersion& value) {\n     runtime_version_ = value;\n   }\n-  void set_dnn_version(const SemanticVersion& value) { dnn_version_ = value; }\n   void set_compile_time_toolkit_version(const SemanticVersion& value) {\n     compile_time_toolkit_version_ = value;\n   }\n@@ -518,7 +514,6 @@ class DeviceDescription {\n   SemanticVersion driver_version_{0, 0, 0};\n   SemanticVersion runtime_version_{0, 0, 0};\n   SemanticVersion compile_time_toolkit_version_{0, 0, 0};\n-  SemanticVersion dnn_version_{0, 0, 0};\n };\n \n // Returns whether the given thread_dim is acceptable given the limits described"
        }
    ],
    "stats": {
        "total": 343,
        "additions": 23,
        "deletions": 320
    }
}