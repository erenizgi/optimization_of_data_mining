{
    "author": "unknown",
    "message": "[XLA:GPU] Add experimental buffer checksum tracing\n\nA debugging tool meant to pinpoint nondeterministic computations by finding\ndifferences in buffer values across multiple runs. It makes XLA calculate\nchecksums of input/output buffers, and dump them to the output directory.\n\nEnabling the new `--xla_gpu_experimental_enable_checksum_tracing_on_thunks`\nflag enables a new ThunkChecksumTracingPass, which adds checksum thunks to the\nthunk graph:\n\n- Inserts SDC log initialization to beginning.\n- Replaces each thunk with a SequentialThunk [checksum inputs, run original\n  thunk, checksum outputs].\n- Inserts a thunk that dumps SDC log to a file at the end of execution.\n\nPiperOrigin-RevId: 820148916",
    "sha": "72dc64133ab6f52845afd7265664d909a74ce498",
    "files": [
        {
            "sha": "2e14d5b0e95062047fbcd83493d569f7f87929ff",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=72dc64133ab6f52845afd7265664d909a74ce498",
            "patch": "@@ -2895,13 +2895,29 @@ cc_library(\n     srcs = [\"thunk_checksum_tracing_pass.cc\"],\n     hdrs = [\"thunk_checksum_tracing_pass.h\"],\n     deps = [\n+        \":custom_call_thunk\",\n+        \":sdc_buffer_id\",\n+        \":sdc_thunk\",\n         \":sequential_thunk\",\n+        \":thunk\",\n         \":thunk_pass_pipeline\",\n+        \"//xla:shape_util\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla/ffi\",\n+        \"//xla/ffi/api:c_api\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n+        \"//xla/service:dump\",\n         \"//xla/stream_executor:device_description\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/stream_executor/cuda:sdc_log\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/base:nullability\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n     ],\n@@ -2911,11 +2927,19 @@ xla_cc_test(\n     name = \"thunk_checksum_tracing_pass_test\",\n     srcs = [\"thunk_checksum_tracing_pass_test.cc\"],\n     deps = [\n+        \":custom_call_thunk\",\n+        \":sdc_buffer_id\",\n+        \":sdc_thunk\",\n         \":sequential_thunk\",\n         \":thunk\",\n         \":thunk_checksum_tracing_pass\",\n+        \":thunk_id\",\n         \":thunk_pass_pipeline\",\n+        \"//xla:literal_util\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n+        \"//xla/service:hlo_module_config\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/status\","
        },
        {
            "sha": "857b9500733a069f54ef8faf3b83958fb368aa95",
            "filename": "third_party/xla/xla/backends/gpu/runtime/sdc_thunk.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk.h?ref=72dc64133ab6f52845afd7265664d909a74ce498",
            "patch": "@@ -49,6 +49,11 @@ class SdcThunk : public Thunk {\n     return {};\n   }\n \n+  const absl::flat_hash_map<SdcBufferId, BufferAllocation::Slice>&\n+  buffer_slices() const {\n+    return buffers_;\n+  }\n+\n  private:\n   // Loaded in Initialize.\n   std::optional<stream_executor::gpu::SdcXorChecksumKernel::KernelType> kernel_;"
        },
        {
            "sha": "4f662b10de8912da0a759638065bd41feef2442e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_checksum_tracing_pass.cc",
            "status": "modified",
            "additions": 184,
            "deletions": 7,
            "changes": 191,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc?ref=72dc64133ab6f52845afd7265664d909a74ce498",
            "patch": "@@ -15,29 +15,206 @@ limitations under the License.\n \n #include \"xla/backends/gpu/runtime/thunk_checksum_tracing_pass.h\"\n \n+#include <cstddef>\n+#include <cstring>\n+#include <memory>\n+#include <utility>\n+#include <vector>\n+\n #include \"absl/base/nullability.h\"\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n+#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n+#include \"xla/backends/gpu/runtime/sdc_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk_pass_pipeline.h\"\n+#include \"xla/ffi/api/c_api.h\"\n+#include \"xla/ffi/ffi.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/dump.h\"\n+#include \"xla/shape.h\"\n+#include \"xla/stream_executor/cuda/sdc_log.h\"\n #include \"xla/stream_executor/device_description.h\"\n+#include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/xla_data.pb.h\"\n+\n+namespace xla::gpu {\n+\n+namespace se = stream_executor;\n+\n+// With SdcLogEntry size of 8 bytes, this is enough to hold ~8K entries.\n+constexpr size_t kLogSizeBytes = 64 * 1024;\n+\n+namespace {\n+\n+// If the thunk has any interesting buffers to check, turns it into a sequence\n+// of:\n+// - SdcThunk checking the buffers before execution\n+// - The original thunk\n+// - SdcThunk checking the buffers after execution\n+//\n+// If the thunk got wrapped, the data dependencies between the thunks will be\n+// configured to ensure `predecessor_thunk` executes before the wrapped thunk\n+// and `successor_thunk` executes after.\n+absl::StatusOr<std::unique_ptr<Thunk>> WrapThunk(\n+    std::unique_ptr<Thunk> thunk, BufferAllocation::Slice log_slice,\n+    const Thunk& predecessor_thunk, Thunk& successor_thunk) {\n+  const auto& thunk_buffers = thunk->buffer_uses();\n+  if (thunk_buffers.empty()) {\n+    return thunk;\n+  }\n+\n+  absl::flat_hash_map<SdcBufferId, BufferAllocation::Slice>\n+      buffers_to_check_before;\n+  absl::flat_hash_map<SdcBufferId, BufferAllocation::Slice>\n+      buffers_to_check_after;\n+\n+  for (size_t buffer_idx = 0; buffer_idx < thunk_buffers.size(); ++buffer_idx) {\n+    absl::StatusOr<SdcBufferId> buffer_id =\n+        SdcBufferId::Create(thunk->thunk_info().thunk_id, buffer_idx);\n+    if (!buffer_id.ok()) {\n+      LOG(WARNING) << \"Skipping buffer \" << buffer_idx << \" in thunk \"\n+                   << thunk->thunk_info().thunk_id << \": \"\n+                   << buffer_id.status();\n+      continue;\n+    }\n+\n+    const BufferUse& use = thunk_buffers[buffer_idx];\n+    if (use.HasDefinedContentsOnInput()) {\n+      buffers_to_check_before.emplace(buffer_id.value(), use.slice());\n+    }\n+    if (use.HasDefinedContentsOnOutput()) {\n+      buffers_to_check_after.emplace(buffer_id.value(), use.slice());\n+    }\n+  }\n+\n+  if (buffers_to_check_before.empty() && buffers_to_check_after.empty()) {\n+    return thunk;\n+  }\n+\n+  std::vector<std::unique_ptr<Thunk>> thunk_and_checks;\n+  if (!buffers_to_check_before.empty()) {\n+    auto sdc_before_thunk = std::make_unique<SdcThunk>(\n+        Thunk::ThunkInfo(), log_slice, std::move(buffers_to_check_before));\n+    thunk->add_control_predecessor(sdc_before_thunk.get());\n+    thunk_and_checks.push_back(std::move(sdc_before_thunk));\n+  }\n+\n+  Thunk* thunk_ptr = thunk.get();\n+  thunk_and_checks.push_back(std::move(thunk));\n \n-namespace xla {\n-namespace gpu {\n+  if (!buffers_to_check_after.empty()) {\n+    auto sdc_after_thunk = std::make_unique<SdcThunk>(\n+        Thunk::ThunkInfo(), log_slice, std::move(buffers_to_check_after));\n+    sdc_after_thunk->add_control_predecessor(thunk_ptr);\n+    thunk_and_checks.push_back(std::move(sdc_after_thunk));\n+  }\n+\n+  auto wrapped_thunk = std::make_unique<SequentialThunk>(\n+      Thunk::ThunkInfo(), std::move(thunk_and_checks));\n+  wrapped_thunk->add_control_predecessor(&predecessor_thunk);\n+  successor_thunk.add_control_predecessor(wrapped_thunk.get());\n+  return wrapped_thunk;\n+}\n+\n+XLA_FFI_DEFINE_HANDLER_SYMBOL(\n+    kDebugLogInitHandler,\n+    [](se::Stream* absl_nonnull stream, xla::ffi::Buffer<U8> log_buffer) {\n+      return se::cuda::SdcLog::CreateOnDevice(*stream,\n+                                              log_buffer.device_memory())\n+          .status();\n+    },\n+    xla::ffi::Ffi::Bind().Ctx<xla::ffi::Stream>().Arg<xla::ffi::Buffer<U8>>());\n+\n+XLA_FFI_DEFINE_HANDLER_SYMBOL(\n+    kDebugLogDumpHandler,\n+    [](se::Stream* stream, const HloComputation* absl_nonnull hlo_computation,\n+       xla::ffi::Buffer<U8> log_buffer) {\n+      VLOG(1) << \"[SDC LOG] HLO computation ptr: \" << hlo_computation;\n+      const HloModule* hlo_module = hlo_computation->parent();\n+      VLOG(1) << \"[SDC LOG] HLO module ptr: \" << hlo_module;\n+      VLOG(1) << \"[SDC LOG] HLO module name: \" << hlo_module->name();\n+      CHECK(hlo_module != nullptr);\n+      const DebugOptions& debug_options = hlo_module->config().debug_options();\n+\n+      se::cuda::SdcLog sdc_log = se::cuda::SdcLog::FromDeviceMemoryUnchecked(\n+          log_buffer.device_memory());\n+      TF_ASSIGN_OR_RETURN(xla::gpu::SdcLogProto sdc_log_proto,\n+                          sdc_log.ReadProto(*stream));\n+      VLOG(1) << \"[SDC LOG] read \" << sdc_log_proto.entries_size()\n+              << \" entries\";\n+      DumpPerExecutionProtobufToFile(*hlo_module, sdc_log_proto, debug_options,\n+                                     \"sdc_log\", nullptr);\n+      return absl::OkStatus();\n+    },\n+    xla::ffi::Ffi::Bind()\n+        .Ctx<xla::ffi::Stream>()\n+        .Ctx<xla::ffi::CalledComputation>()\n+        .Arg<xla::ffi::Buffer<U8>>());\n+\n+}  // namespace\n \n absl::StatusOr<bool> ThunkChecksumTracingPass::Run(\n     SequentialThunk* root_thunk, const DebugOptions& debug_options,\n     const HloModule* absl_nullable hlo_module,\n     const se::DeviceDescription& device_info,\n     ThunkPassBufferAllocator& allocator) {\n+  VLOG(1) << \"[SDC LOG] ThunkChecksumTracingPass running\";\n+  if (hlo_module == nullptr) {\n+    // We need the HLO module to dump the SDC log proto to a file. If it's not\n+    // available, there's no point in doing extra work.\n+    VLOG(1) << \"[SDC LOG] HLO module is null, skipping\";\n+    return false;\n+  }\n+\n   TF_ASSIGN_OR_RETURN(BufferAllocation * log_alloc,\n-                      allocator.NewEmptyAllocation(1234));\n-  (void)log_alloc;\n+                      allocator.NewEmptyAllocation(kLogSizeBytes));\n+  BufferAllocation::Slice log_slice(log_alloc, 0, log_alloc->size());\n+  ShapedSlice shaped_log_slice{\n+      /*slice=*/log_slice,\n+      /*shape=*/Shape(PrimitiveType::U8, /*dimensions=*/{log_alloc->size()}),\n+  };\n+\n+  XLA_FFI_Handler_Bundle sdc_init_bundle{};\n+  sdc_init_bundle.execute = kDebugLogInitHandler;\n+  TF_ASSIGN_OR_RETURN(\n+      auto sdc_init_thunk,\n+      CustomCallThunk::Create(Thunk::ThunkInfo(), \"xla_gpu_sdc_log_init\",\n+                              sdc_init_bundle, /*operands=*/{shaped_log_slice},\n+                              /*results=*/{}, /*attributes=*/{},\n+                              hlo_module->entry_computation()));\n+\n+  XLA_FFI_Handler_Bundle sdc_dump_bundle{};\n+  sdc_dump_bundle.execute = kDebugLogDumpHandler;\n+  TF_ASSIGN_OR_RETURN(\n+      auto sdc_dump_thunk,\n+      CustomCallThunk::Create(\n+          Thunk::ThunkInfo(), \"xla_gpu_sdc_log_dump\", sdc_dump_bundle,\n+          /*operands=*/{shaped_log_slice},\n+          /*results=*/{}, /*attributes=*/{}, hlo_module->entry_computation()));\n+\n+  ThunkSequence& thunks = root_thunk->thunks();\n+  for (auto& thunk : thunks) {\n+    TF_ASSIGN_OR_RETURN(thunk,\n+                        WrapThunk(std::move(thunk), log_slice,\n+                                  /*predecessor_thunk=*/*sdc_init_thunk.get(),\n+                                  /*successor_thunk=*/*sdc_dump_thunk.get()));\n+  }\n+\n+  thunks.reserve(thunks.size() + 2);\n+  thunks.insert(thunks.begin(), std::move(sdc_init_thunk));\n+  thunks.push_back(std::move(sdc_dump_thunk));\n \n-  return false;\n+  return true;\n }\n \n-}  // namespace gpu\n-}  // namespace xla\n+}  // namespace xla::gpu"
        },
        {
            "sha": "3c3b4ef0bf6efdb53671a98cddf35373843c5ad9",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_checksum_tracing_pass_test.cc",
            "status": "modified",
            "additions": 144,
            "deletions": 5,
            "changes": 149,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass_test.cc?ref=72dc64133ab6f52845afd7265664d909a74ce498",
            "patch": "@@ -17,22 +17,42 @@ limitations under the License.\n \n #include <cstdint>\n #include <memory>\n+#include <utility>\n #include <vector>\n \n+#include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n+#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n+#include \"xla/backends/gpu/runtime/sdc_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/backends/gpu/runtime/thunk_pass_pipeline.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/literal_util.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/hlo_module_config.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/tsl/platform/statusor.h\"\n \n namespace xla {\n namespace gpu {\n namespace {\n \n+using testing::ElementsAre;\n+using testing::Pair;\n+using testing::Pointer;\n+using testing::SizeIs;\n+using testing::UnorderedElementsAre;\n+\n+MATCHER_P(IsUniquePointerTo, ptr, \"\") { return arg.get() == ptr; }\n+\n class FakeThunkPassBufferAllocator : public ThunkPassBufferAllocator {\n  public:\n   absl::StatusOr<BufferAllocation*> NewEmptyAllocation(int64_t size) override {\n@@ -49,19 +69,138 @@ class FakeThunkPassBufferAllocator : public ThunkPassBufferAllocator {\n   std::unique_ptr<BufferAllocation> alloc_;\n };\n \n-TEST(ThunkChecksumTracingPassTest, CreatesLogAlloc) {\n-  ThunkChecksumTracingPass pass;\n-  auto root_thunk = std::make_unique<SequentialThunk>(\n-      Thunk::ThunkInfo(), std::vector<std::unique_ptr<Thunk>>());\n+class FakeThunk : public Thunk {\n+ public:\n+  explicit FakeThunk(ThunkInfo info, BufferUses buffer_uses)\n+      : Thunk(Thunk::Kind::kGemm, std::move(info)),\n+        buffer_uses_(std::move(buffer_uses)) {}\n+\n+  absl::Status ExecuteOnStream(const ExecuteParams& params) override {\n+    return absl::OkStatus();\n+  }\n+\n+  BufferUses buffer_uses() const override { return buffer_uses_; }\n+\n+ private:\n+  BufferUses buffer_uses_;\n+};\n+\n+TEST(ThunkChecksumTracingPassTest, IsNoOpWhenHloModuleIsNull) {\n   DebugOptions debug_options;\n+  debug_options.set_xla_gpu_experimental_enable_checksum_tracing_on_thunks(\n+      true);\n   se::DeviceDescription device_info;\n   FakeThunkPassBufferAllocator allocator;\n+  BufferAllocation alloc(0, 1024, 0);\n+  BufferAllocation::Slice slice(&alloc, 0, 1);\n+  auto fake_thunk = std::make_unique<FakeThunk>(\n+      Thunk::ThunkInfo(), Thunk::BufferUses{BufferUse::Read(slice)});\n+  Thunk* fake_thunk_ptr = fake_thunk.get();\n+  std::vector<std::unique_ptr<Thunk>> thunks;\n+  thunks.push_back(std::move(fake_thunk));\n+  auto root_thunk =\n+      std::make_unique<SequentialThunk>(Thunk::ThunkInfo(), std::move(thunks));\n \n+  ThunkChecksumTracingPass pass;\n   TF_ASSERT_OK_AND_ASSIGN(\n       bool changed, pass.Run(root_thunk.get(), debug_options,\n                              /*hlo_module=*/nullptr, device_info, allocator));\n   EXPECT_FALSE(changed);\n-  EXPECT_TRUE(allocator.CreatedAlloc());\n+  EXPECT_THAT(root_thunk->thunks(), ElementsAre(Pointer(fake_thunk_ptr)));\n+}\n+\n+TEST(ThunkChecksumTracingPassTest, InsertsSdcThunks) {\n+  static constexpr ThunkId kTestThunkId = ThunkId(123);\n+  DebugOptions debug_options;\n+  debug_options.set_xla_gpu_experimental_enable_checksum_tracing_on_thunks(\n+      true);\n+  se::DeviceDescription device_info;\n+  FakeThunkPassBufferAllocator allocator;\n+  // The callbacks created by ThunkChecksumTracingPass require a HloModule with\n+  // a non-null entry computation.\n+  auto builder = HloComputation::Builder(\"entry\");\n+  HloInstruction* root = builder.AddInstruction(\n+      HloInstruction::CreateConstant(LiteralUtil::CreateR0(1)));\n+  std::unique_ptr<HloComputation> entry_computation = builder.Build(root);\n+  HloModule hlo_module(\"test_module\", HloModuleConfig());\n+  hlo_module.AddEntryComputation(std::move(entry_computation));\n+  // Create a fake thunk with a few different buffer uses.\n+  BufferAllocation alloc(0, 1024, 0);\n+  BufferAllocation::Slice slice_i(&alloc, 0, 1);\n+  BufferAllocation::Slice slice_o(&alloc, 1, 1);\n+  BufferAllocation::Slice slice_io(&alloc, 2, 1);\n+  BufferAllocation::Slice slice_scratch(&alloc, 3, 1);\n+  Thunk::ThunkInfo fake_thunk_info;\n+  fake_thunk_info.thunk_id = ThunkId(kTestThunkId);\n+  auto fake_thunk = std::make_unique<FakeThunk>(\n+      fake_thunk_info,\n+      Thunk::BufferUses{\n+          // Consume means the thunk can reuse the buffer for scratch space, so\n+          // only check it on input.\n+          BufferUse::Consume(slice_i),\n+          // Write is undefined on input, but defined on output.\n+          BufferUse::Write(slice_o),\n+          // Unlike Consume, Read is supposed to preserve the contents of the\n+          // buffer, so we check it on input *and* output.\n+          BufferUse::Read(slice_io),\n+          // Scratch buffers are not checked at all.\n+          BufferUse::Scratch(slice_scratch),\n+      });\n+  Thunk* fake_thunk_ptr = fake_thunk.get();\n+  std::vector<std::unique_ptr<Thunk>> thunks;\n+  thunks.push_back(std::move(fake_thunk));\n+  auto root_thunk =\n+      std::make_unique<SequentialThunk>(Thunk::ThunkInfo(), std::move(thunks));\n+\n+  ThunkChecksumTracingPass pass;\n+  TF_ASSERT_OK_AND_ASSIGN(bool changed,\n+                          pass.Run(root_thunk.get(), debug_options, &hlo_module,\n+                                   device_info, allocator));\n+  EXPECT_TRUE(changed);\n+\n+  // Expected thunk structure after the pass:\n+  // 1. CustomCallThunk (SDC init)\n+  // 2. SequentialThunk\n+  //    1. SdcThunk (SDC checks on input buffers)\n+  //    2. FakeThunk\n+  //    3. SdcThunk (SDC checks on output buffers)\n+  // 3. CustomCallThunk (SDC dump)\n+  const std::vector<std::unique_ptr<Thunk>>& new_thunks = root_thunk->thunks();\n+  EXPECT_THAT(new_thunks, SizeIs(3));\n+  EXPECT_EQ(new_thunks[0]->kind(), Thunk::Kind::kCustomCall);\n+  EXPECT_EQ(new_thunks[1]->kind(), Thunk::Kind::kSequential);\n+  EXPECT_EQ(new_thunks[2]->kind(), Thunk::Kind::kCustomCall);\n+\n+  const CustomCallThunk& sdc_init_thunk =\n+      static_cast<const CustomCallThunk&>(*new_thunks[0]);\n+  EXPECT_EQ(sdc_init_thunk.target_name(), \"xla_gpu_sdc_log_init\");\n+\n+  const CustomCallThunk& sdc_dump_thunk =\n+      static_cast<const CustomCallThunk&>(*new_thunks[2]);\n+  EXPECT_EQ(sdc_dump_thunk.target_name(), \"xla_gpu_sdc_log_dump\");\n+\n+  const std::vector<std::unique_ptr<Thunk>>& sub_thunks =\n+      static_cast<const SequentialThunk&>(*new_thunks[1]).thunks();\n+  EXPECT_THAT(sub_thunks, SizeIs(3));\n+  EXPECT_EQ(sub_thunks[0]->kind(), Thunk::Kind::kSdc);\n+  EXPECT_THAT(sub_thunks[1], Pointer(fake_thunk_ptr));\n+  EXPECT_EQ(sub_thunks[2]->kind(), Thunk::Kind::kSdc);\n+\n+  const SdcThunk& sdc_before_fake_thunk =\n+      static_cast<const SdcThunk&>(*sub_thunks[0]);\n+  EXPECT_THAT(\n+      sdc_before_fake_thunk.buffer_slices(),\n+      UnorderedElementsAre(\n+          Pair(SdcBufferId::Create(kTestThunkId, 0).value(), slice_i),\n+          Pair(SdcBufferId::Create(kTestThunkId, 2).value(), slice_io)));\n+\n+  const SdcThunk& sdc_after_fake_thunk =\n+      static_cast<const SdcThunk&>(*sub_thunks[2]);\n+  EXPECT_THAT(\n+      sdc_after_fake_thunk.buffer_slices(),\n+      UnorderedElementsAre(\n+          Pair(SdcBufferId::Create(kTestThunkId, 1).value(), slice_o),\n+          Pair(SdcBufferId::Create(kTestThunkId, 2).value(), slice_io)));\n }\n \n }  // namespace"
        },
        {
            "sha": "d1aebe6ac976778ebe3784ebc90f8b15c72fe1e5",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=72dc64133ab6f52845afd7265664d909a74ce498",
            "patch": "@@ -2587,6 +2587,14 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n       bool_setter_for(&DebugOptions::set_xla_keep_shardings_after_spmd),\n       debug_options->xla_keep_shardings_after_spmd(),\n       \"If true, keep shardings after SPMD.\"));\n+  flag_list->push_back(tsl::Flag(\n+      \"xla_gpu_experimental_enable_checksum_tracing_on_thunks\",\n+      bool_setter_for(\n+          &DebugOptions::\n+              set_xla_gpu_experimental_enable_checksum_tracing_on_thunks),\n+      debug_options->xla_gpu_experimental_enable_checksum_tracing_on_thunks(),\n+      \"Enables an experimental feature to record checksums of selected thunk \"\n+      \"inputs/outputs.\"));\n }  // NOLINT(readability/fn_size)\n \n // Allocates flag_values and flag_objects; this function must not be called more"
        },
        {
            "sha": "fdf6eb6ed9978b9b929c165a856a52831795f6c6",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=72dc64133ab6f52845afd7265664d909a74ce498",
            "patch": "@@ -810,6 +810,7 @@ xla_cc_test(\n         \":gpu_executable\",\n         \":launch_dimensions\",\n         \"//xla:debug_options_flags\",\n+        \"//xla:literal_util\",\n         \"//xla:shape_layout\",\n         \"//xla:shape_util\",\n         \"//xla/backends/gpu/runtime:copy_thunk\","
        },
        {
            "sha": "2a3186e010a3a80d6805f701839e016e5a571058",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable_test.cc",
            "status": "modified",
            "additions": 40,
            "deletions": 4,
            "changes": 44,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72dc64133ab6f52845afd7265664d909a74ce498/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc?ref=72dc64133ab6f52845afd7265664d909a74ce498",
            "patch": "@@ -36,8 +36,10 @@ limitations under the License.\n #include \"xla/hlo/analysis/alias_info.h\"\n #include \"xla/hlo/analysis/hlo_ordering.h\"\n #include \"xla/hlo/ir/hlo_input_output_alias_config.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/parser/hlo_parser.h\"\n+#include \"xla/literal_util.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/buffer_value.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n@@ -301,9 +303,42 @@ TEST(GpuExecutableTest, MlirAllocationsArePreferred) {\n }\n \n TEST(GpuExecutableTest, ThunkChecksumPassAddsAllocation) {\n+  BufferAllocation alloc(0, 1024, 0);\n+  BufferAllocation::Slice slice(&alloc, 0, 1024);\n+\n+  // Set up a thunk graph with a kernel that has some buffers that should be\n+  // checked, otherwise the pass is a no-op and doesn't need to allocate.\n+  auto make_test_thunk_sequence = [&]() {\n+    Thunk::ThunkInfo thunk_info;\n+    ThunkSequence thunk_sequence;\n+    thunk_sequence.push_back(std::make_unique<KernelThunk>(\n+        thunk_info,\n+        /*kernel_name=*/\"test_kernel\",\n+        /*kernel_arguments=*/\n+        emitters::KernelArguments({\n+            emitters::KernelArgument(\n+                ShapeUtil::MakeShape(F32, /*dimensions=*/{16}), slice),\n+        }),\n+        /*launch_dimensions=*/LaunchDimensions(),\n+        /*cluster_dim=*/std::nullopt,\n+        /*shmem_bytes=*/0,\n+        /*tma_metadata=*/se::gpu::TmaMetadata()));\n+    return thunk_sequence;\n+  };\n+  auto make_test_hlo_module = []() {\n+    HloComputation::Builder builder(\"test_computation\");\n+    HloInstruction* root = builder.AddInstruction(\n+        HloInstruction::CreateConstant(LiteralUtil::CreateR0(1)));\n+    auto hlo_module =\n+        std::make_unique<HloModule>(\"test_module\", HloModuleConfig());\n+    hlo_module->AddEntryComputation(builder.Build(/*root_instruction=*/root));\n+    return hlo_module;\n+  };\n+\n   GpuExecutable::Params params_without_pass;\n-  params_without_pass.executable =\n-      std::make_unique<SequentialThunk>(Thunk::ThunkInfo{}, ThunkSequence{});\n+  params_without_pass.debug_module = make_test_hlo_module();\n+  params_without_pass.executable = std::make_unique<SequentialThunk>(\n+      Thunk::ThunkInfo{}, make_test_thunk_sequence());\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::unique_ptr<GpuExecutable> executable_without_pass,\n@@ -312,8 +347,9 @@ TEST(GpuExecutableTest, ThunkChecksumPassAddsAllocation) {\n       executable_without_pass->GetAllocations().size();\n \n   GpuExecutable::Params params_with_pass;\n-  params_with_pass.executable =\n-      std::make_unique<SequentialThunk>(Thunk::ThunkInfo{}, ThunkSequence{});\n+  params_with_pass.debug_module = make_test_hlo_module();\n+  params_with_pass.executable = std::make_unique<SequentialThunk>(\n+      Thunk::ThunkInfo{}, make_test_thunk_sequence());\n   params_with_pass.debug_options\n       .set_xla_gpu_experimental_enable_checksum_tracing_on_thunks(true);\n "
        }
    ],
    "stats": {
        "total": 422,
        "additions": 406,
        "deletions": 16
    }
}