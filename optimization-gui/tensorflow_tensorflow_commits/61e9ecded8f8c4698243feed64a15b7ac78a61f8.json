{
    "author": "tensorflower-gardener",
    "message": "Add option to track resource usage of sync ops.\n\nPiperOrigin-RevId: 809091316",
    "sha": "61e9ecded8f8c4698243feed64a15b7ac78a61f8",
    "files": [
        {
            "sha": "7ed062c5c88ab1c0e0a010759e5f77eada5febd0",
            "filename": "third_party/xla/xla/service/latency_hiding_scheduler.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 2,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61e9ecded8f8c4698243feed64a15b7ac78a61f8/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61e9ecded8f8c4698243feed64a15b7ac78a61f8/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc?ref=61e9ecded8f8c4698243feed64a15b7ac78a61f8",
            "patch": "@@ -462,8 +462,22 @@ ResourcesVector AsyncTracker::GetResourcesFromInstructionImpl(\n       }\n       return result;\n     }\n-    default:\n-      return ResourcesVector{};\n+    default: {\n+      // At this point we are dealing with sync instructions that did not fall\n+      // into any of the cases above. We model their resources as a\n+      // kResourceOccupy and a kResourceRelease that follows immediately after.\n+      ResourcesVector res;\n+      if (config_.track_sync_op_resource_usage) {\n+        ResourceType type = get_resource_for_op(hlo.opcode());\n+        if (type != ResourceType::kNoResource) {\n+          res.push_back(std::make_pair(ResourceTypeToIndex(type),\n+                                       ResourceUsageType::kResourceOccupy));\n+          res.push_back(std::make_pair(ResourceTypeToIndex(type),\n+                                       ResourceUsageType::kResourceRelease));\n+        }\n+      }\n+      return res;\n+    }\n   }\n }\n "
        },
        {
            "sha": "cb545e4d7d83f77b3bc273ea01dd715d18a79e3b",
            "filename": "third_party/xla/xla/service/latency_hiding_scheduler.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61e9ecded8f8c4698243feed64a15b7ac78a61f8/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61e9ecded8f8c4698243feed64a15b7ac78a61f8/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h?ref=61e9ecded8f8c4698243feed64a15b7ac78a61f8",
            "patch": "@@ -167,6 +167,8 @@ struct SchedulerConfig {\n   // If true, estimate the fragmentation size of the module by running the heap\n   // simulator.\n   bool estimate_fragmentation_size = false;\n+  // If true, track the resource usage of sync ops in latency hiding scheduler.\n+  bool track_sync_op_resource_usage = false;\n };\n \n // Class used estimate latency between instructions and cost of HLOs."
        },
        {
            "sha": "5d973e6be776776f56708e28f30b1d4ad75a9a6c",
            "filename": "third_party/xla/xla/service/latency_hiding_scheduler_test.cc",
            "status": "modified",
            "additions": 190,
            "deletions": 3,
            "changes": 193,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61e9ecded8f8c4698243feed64a15b7ac78a61f8/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61e9ecded8f8c4698243feed64a15b7ac78a61f8/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler_test.cc?ref=61e9ecded8f8c4698243feed64a15b7ac78a61f8",
            "patch": "@@ -155,14 +155,18 @@ absl::StatusOr<bool> RunScheduler(\n         std::make_unique<ApproximateLatencyEstimator>(),\n     std::unique_ptr<AsyncTracker> async_tracker = nullptr,\n     std::unique_ptr<LegalizeSchedulingAnnotations::Config> legalizer_config =\n-        nullptr) {\n+        nullptr,\n+    bool skip_async_collective_creator = false) {\n   AsyncCollectiveCreator::CollectiveCreatorConfig config{\n       /*convert_all_reduce=*/HloPredicateTrue,\n       /*convert_all_gather=*/HloPredicateTrue,\n       /*convert_collective_broadcast=*/HloPredicateTrue,\n       /*convert_collective_permute=*/HloPredicateTrue};\n-  TF_ASSIGN_OR_RETURN(bool value,\n-                      AsyncCollectiveCreator(std::move(config)).Run(module));\n+  bool value = false;\n+  if (!skip_async_collective_creator) {\n+    TF_ASSIGN_OR_RETURN(value,\n+                        AsyncCollectiveCreator(std::move(config)).Run(module));\n+  }\n   if (!legalizer_config) {\n     legalizer_config =\n         std::make_unique<LegalizeSchedulingAnnotations::Config>();\n@@ -4735,6 +4739,189 @@ ROOT tuple.2 = (f32[16,2048,2048]{2,1,0}, f32[8,128,128]{2,1,0}, f32[16,2048,204\n             GetIndex(new_instruction_sequence, \"cp1d\"));\n }\n \n+TEST_F(LatencyHidingSchedulerTest, SyncAllGatherResource) {\n+  absl::string_view hlo_string = R\"(\n+HloModule module, is_scheduled=true\n+\n+ENTRY entry {\n+  p0 = bf16[4]{0} parameter(0)\n+  all-gather.2 = bf16[8]{0} all-gather(p0), replica_groups={{0,1},{2,3}}, dimensions={0}, channel_id=2\n+  all-gather-start.1 = (bf16[4]{0}, bf16[8]{0}) all-gather-start(p0), replica_groups={{0,1},{2,3}}, dimensions={0}\n+  all-gather-done.1 = bf16[8]{0} all-gather-done(all-gather-start.1)\n+  ROOT tuple.2 = (bf16[8]{0}, bf16[8]{0}) tuple(all-gather-done.1, all-gather.2)\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto hlo_module, ParseHloText(hlo_string));\n+  HloSchedule& module_schedule = hlo_module->schedule();\n+  EXPECT_TRUE(hlo_module->has_entry_computation());\n+  auto sched_config = GetDefaultSchedConfig();\n+  sched_config.track_sync_op_resource_usage = true;\n+  TF_EXPECT_OK(RunScheduler(hlo_module.get(), sched_config,\n+                            std::make_unique<ApproximateLatencyEstimator>(),\n+                            /*async_tracker=*/nullptr,\n+                            /*legalizer_config=*/nullptr,\n+                            /*skip_async_collective_creator=*/true));\n+  EXPECT_TRUE(hlo_module->has_entry_computation());\n+  VLOG(1) << \"module after: \";\n+  XLA_VLOG_LINES(1, hlo_module->ToString());\n+\n+  std::vector<HloInstruction*> new_instruction_sequence =\n+      module_schedule.sequence(hlo_module->entry_computation()).instructions();\n+  if (VLOG_IS_ON(1)) {\n+    for (auto* new_i : new_instruction_sequence) {\n+      VLOG(1) << new_i->ToString();\n+    }\n+  }\n+  // Check that the sync AG does not overlap with the async AG due to resource\n+  // constraint of 1 for kAllGather\n+  auto sync_ag_index = GetIndex(new_instruction_sequence, \"all-gather.2\");\n+  auto async_ag_start_index =\n+      GetIndex(new_instruction_sequence, \"all-gather-start.1\");\n+  auto async_ag_done_index =\n+      GetIndex(new_instruction_sequence, \"all-gather-done.1\");\n+  EXPECT_TRUE(sync_ag_index < async_ag_start_index ||\n+              sync_ag_index > async_ag_done_index);\n+}\n+\n+TEST_F(LatencyHidingSchedulerTest, SyncAllGatherResourceLimitOfTwo) {\n+  absl::string_view hlo_string = R\"(\n+HloModule module, is_scheduled=true\n+\n+ENTRY entry {\n+  p0 = bf16[4]{0} parameter(0)\n+  all-gather.2 = bf16[8]{0} all-gather(p0), replica_groups={{0,1},{2,3}}, dimensions={0}, channel_id=2\n+  all-gather-start.1 = (bf16[4]{0}, bf16[8]{0}) all-gather-start(p0), replica_groups={{0,1},{2,3}}, dimensions={0}\n+  all-gather-done.1 = bf16[8]{0} all-gather-done(all-gather-start.1)\n+  ROOT tuple.2 = (bf16[8]{0}, bf16[8]{0}) tuple(all-gather-done.1, all-gather.2)\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto hlo_module, ParseHloText(hlo_string));\n+  HloSchedule& module_schedule = hlo_module->schedule();\n+  EXPECT_TRUE(hlo_module->has_entry_computation());\n+  auto sched_config = GetDefaultSchedConfig();\n+  sched_config.track_sync_op_resource_usage = true;\n+  sched_config.all_gather_overlap_limit = 2;\n+  TF_EXPECT_OK(RunScheduler(hlo_module.get(), sched_config,\n+                            std::make_unique<ApproximateLatencyEstimator>(),\n+                            /*async_tracker=*/nullptr,\n+                            /*legalizer_config=*/nullptr,\n+                            /*skip_async_collective_creator=*/true));\n+  EXPECT_TRUE(hlo_module->has_entry_computation());\n+  VLOG(1) << \"module after: \";\n+  XLA_VLOG_LINES(1, hlo_module->ToString());\n+\n+  std::vector<HloInstruction*> new_instruction_sequence =\n+      module_schedule.sequence(hlo_module->entry_computation()).instructions();\n+  if (VLOG_IS_ON(1)) {\n+    for (auto* new_i : new_instruction_sequence) {\n+      VLOG(1) << new_i->ToString();\n+    }\n+  }\n+  // Check that the sync AG does not overlap with the async AG due to resource\n+  // constraint of 1 for kAllGather\n+  auto sync_ag_index = GetIndex(new_instruction_sequence, \"all-gather.2\");\n+  auto async_ag_start_index =\n+      GetIndex(new_instruction_sequence, \"all-gather-start.1\");\n+  auto async_ag_done_index =\n+      GetIndex(new_instruction_sequence, \"all-gather-done.1\");\n+  EXPECT_TRUE(sync_ag_index > async_ag_start_index &&\n+              sync_ag_index < async_ag_done_index);\n+}\n+\n+TEST_F(LatencyHidingSchedulerTest, SyncAllGatherResourceAnnotationGroup) {\n+  absl::string_view hlo_string = R\"(\n+HloModule module, is_scheduled=true\n+\n+ENTRY entry {\n+  p0 = bf16[4]{0} parameter(0)\n+  all-gather.2 = bf16[8]{0} all-gather(p0), replica_groups={{0,1},{2,3}}, dimensions={0}, channel_id=2, frontend_attributes={_scheduling_group_id=\"0\"}\n+  all-gather-start.1 = (bf16[4]{0}, bf16[8]{0}) all-gather-start(p0), replica_groups={{0,1},{2,3}}, dimensions={0}, frontend_attributes={_scheduling_group_id=\"0\"}\n+  all-gather-done.1 = bf16[8]{0} all-gather-done(all-gather-start.1), frontend_attributes={_scheduling_group_id=\"0\"}\n+  ROOT tuple.2 = (bf16[8]{0}, bf16[8]{0}) tuple(all-gather-done.1, all-gather.2)\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto hlo_module, ParseHloText(hlo_string));\n+  HloSchedule& module_schedule = hlo_module->schedule();\n+  EXPECT_TRUE(hlo_module->has_entry_computation());\n+  auto sched_config = GetDefaultSchedConfig();\n+  sched_config.track_sync_op_resource_usage = true;\n+  TF_EXPECT_OK(RunScheduler(hlo_module.get(), sched_config,\n+                            std::make_unique<ApproximateLatencyEstimator>(),\n+                            /*async_tracker=*/nullptr,\n+                            /*legalizer_config=*/nullptr,\n+                            /*skip_async_collective_creator=*/true));\n+  EXPECT_TRUE(hlo_module->has_entry_computation());\n+  VLOG(1) << \"module after: \";\n+  XLA_VLOG_LINES(1, hlo_module->ToString());\n+\n+  std::vector<HloInstruction*> new_instruction_sequence =\n+      module_schedule.sequence(hlo_module->entry_computation()).instructions();\n+  if (VLOG_IS_ON(1)) {\n+    for (auto* new_i : new_instruction_sequence) {\n+      VLOG(1) << new_i->ToString();\n+    }\n+  }\n+  // Check that the sync AG does not overlap with the async AG due to resource\n+  // constraint of 1 for kAllGather\n+  auto sync_ag_index = GetIndex(new_instruction_sequence, \"all-gather.2\");\n+  auto async_ag_start_index =\n+      GetIndex(new_instruction_sequence, \"all-gather-start.1\");\n+  auto async_ag_done_index =\n+      GetIndex(new_instruction_sequence, \"all-gather-done.1\");\n+  EXPECT_TRUE(sync_ag_index < async_ag_start_index ||\n+              sync_ag_index > async_ag_done_index);\n+}\n+\n+TEST_F(LatencyHidingSchedulerTest,\n+       SyncAllGatherResourceLimitOfTwoAnnotationGroup) {\n+  absl::string_view hlo_string = R\"(\n+HloModule module, is_scheduled=true\n+\n+ENTRY entry {\n+  p0 = bf16[4]{0} parameter(0)\n+  all-gather.2 = bf16[8]{0} all-gather(p0), replica_groups={{0,1},{2,3}}, dimensions={0}, channel_id=2, frontend_attributes={_scheduling_group_id=\"0\"}\n+  all-gather-start.1 = (bf16[4]{0}, bf16[8]{0}) all-gather-start(p0), replica_groups={{0,1},{2,3}}, dimensions={0}, frontend_attributes={_scheduling_group_id=\"0\"}\n+  all-gather-done.1 = bf16[8]{0} all-gather-done(all-gather-start.1), frontend_attributes={_scheduling_group_id=\"0\"}\n+  ROOT tuple.2 = (bf16[8]{0}, bf16[8]{0}) tuple(all-gather-done.1, all-gather.2)\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto hlo_module, ParseHloText(hlo_string));\n+  HloSchedule& module_schedule = hlo_module->schedule();\n+  EXPECT_TRUE(hlo_module->has_entry_computation());\n+  auto sched_config = GetDefaultSchedConfig();\n+  sched_config.track_sync_op_resource_usage = true;\n+  sched_config.all_gather_overlap_limit = 2;\n+  TF_EXPECT_OK(RunScheduler(hlo_module.get(), sched_config,\n+                            std::make_unique<ApproximateLatencyEstimator>(),\n+                            /*async_tracker=*/nullptr,\n+                            /*legalizer_config=*/nullptr,\n+                            /*skip_async_collective_creator=*/true));\n+  EXPECT_TRUE(hlo_module->has_entry_computation());\n+  VLOG(1) << \"module after: \";\n+  XLA_VLOG_LINES(1, hlo_module->ToString());\n+\n+  std::vector<HloInstruction*> new_instruction_sequence =\n+      module_schedule.sequence(hlo_module->entry_computation()).instructions();\n+  if (VLOG_IS_ON(1)) {\n+    for (auto* new_i : new_instruction_sequence) {\n+      VLOG(1) << new_i->ToString();\n+    }\n+  }\n+  // Check that the sync AG does not overlap with the async AG due to resource\n+  // constraint of 1 for kAllGather\n+  auto sync_ag_index = GetIndex(new_instruction_sequence, \"all-gather.2\");\n+  auto async_ag_start_index =\n+      GetIndex(new_instruction_sequence, \"all-gather-start.1\");\n+  auto async_ag_done_index =\n+      GetIndex(new_instruction_sequence, \"all-gather-done.1\");\n+  EXPECT_TRUE(sync_ag_index > async_ag_start_index &&\n+              sync_ag_index < async_ag_done_index);\n+}\n+\n class LatencyHidingSchedulerBenchmark : public LatencyHidingSchedulerTest {\n  public:\n   void TestBody() override {}"
        }
    ],
    "stats": {
        "total": 213,
        "additions": 208,
        "deletions": 5
    }
}