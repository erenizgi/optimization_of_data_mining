{
    "author": "tensorflower-gardener",
    "message": "[Autotuner]Add support for sharded autotuning in the pass.\n\nPiperOrigin-RevId: 826417614",
    "sha": "e32304ddc52b41093da1505830007c1d15de69f2",
    "files": [
        {
            "sha": "bdd919aa69b758b41db70db363127bb8f1191dcd",
            "filename": "third_party/xla/xla/service/gpu/autotuning/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e32304ddc52b41093da1505830007c1d15de69f2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e32304ddc52b41093da1505830007c1d15de69f2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD?ref=e32304ddc52b41093da1505830007c1d15de69f2",
            "patch": "@@ -724,6 +724,7 @@ cc_library(\n         \"//xla/backends/gpu/autotuner:legacy_cache\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/pass:hlo_pass\",\n+        \"//xla/pjrt/distributed:key_value_store_interface\",\n         \"//xla/service:compiler\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:device_memory_allocator\","
        },
        {
            "sha": "d62cfbee1b6e5bb9f9ddb47dd89d919dac167465",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_pass.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 4,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e32304ddc52b41093da1505830007c1d15de69f2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e32304ddc52b41093da1505830007c1d15de69f2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc?ref=e32304ddc52b41093da1505830007c1d15de69f2",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"xla/backends/gpu/autotuner/legacy_cache.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/pjrt/distributed/key_value_store_interface.h\"\n #include \"xla/service/compiler.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n@@ -91,7 +92,8 @@ absl::StatusOr<std::unique_ptr<AutotunerPass>> AutotunerPass::Create(\n     stream_executor::StreamExecutor* stream_executor,\n     tsl::thread::ThreadPool* thread_pool, InstructionFilterFn should_autotune,\n     const Compiler::TargetConfig* target_config,\n-    se::DeviceMemoryAllocator* allocator, bool optimize_scratch_bytes) {\n+    se::DeviceMemoryAllocator* allocator, bool optimize_scratch_bytes,\n+    MultiProcessKeyValueStore key_value_store) {\n   std::unique_ptr<Profiler> profiler = nullptr;\n   bool is_deviceless = stream_executor == nullptr;\n   AutotuneConfig autotune_config =\n@@ -112,16 +114,24 @@ absl::StatusOr<std::unique_ptr<AutotunerPass>> AutotunerPass::Create(\n       std::unique_ptr<Autotuner> autotuner,\n       Autotuner::Create(std::move(backends), std::move(profiler),\n                         autotune_config, std::move(cache), thread_pool));\n-  return absl::WrapUnique(\n-      new AutotunerPass(std::move(autotuner), should_autotune));\n+  return absl::WrapUnique(new AutotunerPass(\n+      std::move(autotuner), should_autotune, std::move(key_value_store),\n+      debug_options.xla_gpu_shard_autotuning()));\n }\n \n absl::StatusOr<bool> AutotunerPass::Run(\n     HloModule* module,\n     const absl::flat_hash_set<absl::string_view>& execution_threads) {\n   VLOG(1) << \"Running Autotuner Pass\";\n \n-  TF_RETURN_IF_ERROR(autotuner_->Autotune(module, should_autotune_));\n+  bool shard_autotuning =\n+      enable_sharding_ && key_value_store_.process_count > 1;\n+  if (shard_autotuning) {\n+    TF_RETURN_IF_ERROR(\n+        autotuner_->Autotune(module, should_autotune_, key_value_store_));\n+  } else {\n+    TF_RETURN_IF_ERROR(autotuner_->Autotune(module, should_autotune_));\n+  }\n   return true;\n }\n "
        },
        {
            "sha": "5d55ae570d61bfa3af415f7cfd9e2d305c2922fb",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_pass.h",
            "status": "modified",
            "additions": 13,
            "deletions": 3,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e32304ddc52b41093da1505830007c1d15de69f2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e32304ddc52b41093da1505830007c1d15de69f2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.h?ref=e32304ddc52b41093da1505830007c1d15de69f2",
            "patch": "@@ -27,6 +27,7 @@ limitations under the License.\n #include \"xla/backends/autotuner/codegen_backend.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/pass/hlo_pass_interface.h\"\n+#include \"xla/pjrt/distributed/key_value_store_interface.h\"\n #include \"xla/service/compiler.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -36,6 +37,7 @@ limitations under the License.\n namespace xla {\n namespace gpu {\n \n+// HloModulePass that runs the autotuner.\n class AutotunerPass : public HloModulePass {\n  public:\n   // Note: the target_config must outlive the pass.\n@@ -45,7 +47,8 @@ class AutotunerPass : public HloModulePass {\n       tsl::thread::ThreadPool* thread_pool, InstructionFilterFn should_autotune,\n       const Compiler::TargetConfig* target_config,\n       se::DeviceMemoryAllocator* allocator = nullptr,\n-      bool optimize_scratch_bytes = true);\n+      bool optimize_scratch_bytes = true,\n+      MultiProcessKeyValueStore key_value_store = MultiProcessKeyValueStore());\n \n   absl::string_view name() const override { return \"autotuner\"; }\n \n@@ -56,11 +59,18 @@ class AutotunerPass : public HloModulePass {\n \n  private:\n   explicit AutotunerPass(std::unique_ptr<Autotuner> autotuner,\n-                         InstructionFilterFn should_autotune)\n-      : autotuner_(std::move(autotuner)), should_autotune_(should_autotune) {}\n+                         InstructionFilterFn should_autotune,\n+                         MultiProcessKeyValueStore key_value_store,\n+                         bool enable_sharding)\n+      : autotuner_(std::move(autotuner)),\n+        should_autotune_(should_autotune),\n+        key_value_store_(std::move(key_value_store)),\n+        enable_sharding_(enable_sharding) {}\n \n   std::unique_ptr<Autotuner> autotuner_;\n   InstructionFilterFn should_autotune_;\n+  MultiProcessKeyValueStore key_value_store_;\n+  bool enable_sharding_ = false;\n };\n \n }  // namespace gpu"
        }
    ],
    "stats": {
        "total": 35,
        "additions": 28,
        "deletions": 7
    }
}