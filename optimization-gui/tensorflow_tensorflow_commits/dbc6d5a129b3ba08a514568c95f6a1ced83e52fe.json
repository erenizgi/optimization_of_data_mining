{
    "author": "ezhulenev",
    "message": "[xla:cpu] Use dot_lib in tfcompiled executables\n\nPiperOrigin-RevId: 834355928",
    "sha": "dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
    "files": [
        {
            "sha": "87cb051b75df6316d419b66a38ce5cf7e5323c1e",
            "filename": "tensorflow/compiler/aot/codegen.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 8,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -670,22 +670,16 @@ absl::Status ExtendRewrites(\n         \" is outside the range of temp sizes: [0,\", buffer_infos_size, \")\"));\n   }\n \n-  const bool xla_cpu_multi_thread_eigen =\n-      xla::GetDebugOptionsFromFlags().xla_cpu_multi_thread_eigen();\n-\n   std::vector<std::string> runtime_specific_includes = {R\"(\n #include \"absl/log/check.h\"\n+#include \"absl/synchronization/blocking_counter.h\"\n #include \"xla/backends/cpu/runtime/kernel_c_api.h\"\n #include \"xla/types.h\")\"};\n \n   if (HasThunkKind(aot_thunks->proto().thunk_sequence(),\n                    xla::cpu::ThunkProto::kDotThunk)) {\n-    if (xla_cpu_multi_thread_eigen) {\n-      runtime_specific_includes.push_back(\n-          R\"(#include \"xla/service/cpu/runtime_matmul.h\")\");\n-    }\n     runtime_specific_includes.push_back(\n-        R\"(#include \"xla/service/cpu/runtime_single_threaded_matmul.h\")\");\n+        R\"(#include \"xla/backends/cpu/runtime/dot_lib.h\")\");\n   }\n \n   if (HasThunkKind(aot_thunks->proto().thunk_sequence(),"
        },
        {
            "sha": "67fea2e6a022c1fc2a336693c5c8428283141b6d",
            "filename": "tensorflow/compiler/aot/tfcompile.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/tensorflow%2Fcompiler%2Faot%2Ftfcompile.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/tensorflow%2Fcompiler%2Faot%2Ftfcompile.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2Ftfcompile.bzl?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -323,10 +323,10 @@ def _tf_library(\n             # generated code will fail to compile.\n             \"//third_party/absl/log:check\",\n             \"//third_party/absl/synchronization\",\n+            \"//tensorflow/core:framework_lite\",\n             \"//tensorflow/compiler/tf2xla:xla_compiled_cpu_function\",\n             \"@local_xla//xla:types\",\n             \"@local_xla//xla/backends/cpu/runtime:kernel_c_api\",\n-            \"//tensorflow/core:framework_lite\",\n             \"@local_xla//xla/backends/cpu/runtime:rng_state_lib\",\n         ] + (need_xla_data_proto and [\n             # If we're generating the program shape, we must depend on the\n@@ -337,6 +337,7 @@ def _tf_library(\n         ] or []) + (include_standard_runtime_deps and [\n             # TODO(cwhipkey): only depend on kernel code that the model actually\n             # needed.\n+            \"@local_xla//xla/backends/cpu/runtime:dot_lib\",\n             \"@local_xla//xla/backends/cpu/runtime:sort_lib\",\n             \"@local_xla//xla/backends/cpu/runtime:topk_lib\",\n             \"@local_xla//xla/backends/cpu/runtime:convolution_lib\","
        },
        {
            "sha": "485bfd36dfa0a53cfb163584dde07d32bfb2e5b6",
            "filename": "tensorflow/compiler/aot/thunk_proto_execution_deserializer.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 63,
            "changes": 87,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/tensorflow%2Fcompiler%2Faot%2Fthunk_proto_execution_deserializer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/tensorflow%2Fcompiler%2Faot%2Fthunk_proto_execution_deserializer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2Fthunk_proto_execution_deserializer.cc?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -127,32 +127,23 @@ ThunkProtoExecutionDeserializer::ThunkSpecificRunImplFromThunkSequence(\n }\n \n absl::StatusOr<std::string> ThunkProtoExecutionDeserializer::GetMatmulFunction(\n-    xla::PrimitiveType xla_type, bool is_single_threaded) {\n+    xla::PrimitiveType xla_type) {\n   switch (xla_type) {\n     case xla::F16:\n-      return is_single_threaded\n-                 ? \"__xla_cpu_runtime_EigenSingleThreadedMatMulF16\"\n-                 : \"__xla_cpu_runtime_EigenMatMulF16\";\n+      return \"::xla::cpu::internal::TypedMatMul<Eigen::half, Eigen::half, \"\n+             \"Eigen::half>\";\n     case xla::F32:\n-      return is_single_threaded\n-                 ? \"__xla_cpu_runtime_EigenSingleThreadedMatMulF32\"\n-                 : \"__xla_cpu_runtime_EigenMatMulF32\";\n+      return \"::xla::cpu::internal::TypedMatMul<float, float, float>\";\n     case xla::F64:\n-      return is_single_threaded\n-                 ? \"__xla_cpu_runtime_EigenSingleThreadedMatMulF64\"\n-                 : \"__xla_cpu_runtime_EigenMatMulF64\";\n+      return \"::xla::cpu::internal::TypedMatMul<double, double, double>\";\n     case xla::C64:\n-      return is_single_threaded\n-                 ? \"__xla_cpu_runtime_EigenSingleThreadedMatMulC64\"\n-                 : \"__xla_cpu_runtime_EigenMatMulC64\";\n+      return \"::xla::cpu::internal::TypedMatMul<std::complex<float>, \"\n+             \"std::complex<float>, std::complex<float>\";\n     case xla::C128:\n-      return is_single_threaded\n-                 ? \"__xla_cpu_runtime_EigenSingleThreadedMatMulC128\"\n-                 : \"__xla_cpu_runtime_EigenMatMulC128\";\n+      return \"::xla::cpu::internal::TypedMatMul<std::complex<double>, \"\n+             \"std::complex<double>, std::complex<double>\";\n     case xla::S32:\n-      return is_single_threaded\n-                 ? \"__xla_cpu_runtime_EigenSingleThreadedMatMulS32\"\n-                 : \"__xla_cpu_runtime_EigenMatMulS32\";\n+      return \"::xla::cpu::internal::TypedMatMul<int32_t, int32_t, int32_t>\";\n     default:\n       return xla::Internal(\"Unsupported xla type: %d\", xla_type);\n   }\n@@ -166,43 +157,23 @@ absl::StatusOr<std::string> ThunkProtoExecutionDeserializer::GetDotThunkRunImpl(\n   }\n   const xla::cpu::DotThunkProto& dot_thunk = thunk.dot_thunk();\n \n-  absl::string_view dot_thunk_invocation_format = xla_cpu_multi_thread_eigen_\n-                                                      ? R\"(\n+  absl::string_view dot_thunk_invocation_format = R\"(\n      // Dot Thunk\n      {\n+        absl::BlockingCounter done({{BATCH_SIZE}});\n         for (int64_t i = 0; i < {{BATCH_SIZE}}; ++i) {\n-          if (run_options->intra_op_thread_pool() != nullptr) {\n-            {{MATMUL_FUNCTION}}(\n-              run_options,\n-              {{OUTPUT_PTR}} + {{OUTPUT_STRIDE}} * i,\n-              {{LHS_PTR}} + {{LHS_STRIDE}} * i,\n-              {{RHS_PTR}} + {{RHS_STRIDE}} * i,\n-              {{M}}, {{N}}, {{K}}, {{TRANSPOSE_LHS}}, {{TRANSPOSE_RHS}});\n-          } else {\n-            {{SINGLE_THREADED_MATMUL_FUNCTION}}(\n-                nullptr,\n-                {{OUTPUT_PTR}} + {{OUTPUT_STRIDE}} * i,\n-                {{LHS_PTR}} + {{LHS_STRIDE}} * i,\n-                {{RHS_PTR}} + {{RHS_STRIDE}} * i,\n-                {{M}}, {{N}}, {{K}}, {{TRANSPOSE_LHS}}, {{TRANSPOSE_RHS}});\n-          }\n+          {{MATMUL_FUNCTION}}(\n+            run_options->intra_op_thread_pool(),\n+            {{OUTPUT_PTR}} + {{OUTPUT_STRIDE}} * i,\n+            {{LHS_PTR}} + {{LHS_STRIDE}} * i,\n+            {{RHS_PTR}} + {{RHS_STRIDE}} * i,\n+            {{M}}, {{N}}, {{K}}, {{TRANSPOSE_LHS}}, {{TRANSPOSE_RHS}},\n+            [&done] { done.DecrementCount(); }\n+          );\n         }\n+        done.Wait();\n      }\n-     )\"\n-                                                      :\n-                                                      R\"(\n-      // Dot Thunk\n-      {\n-         for (int64_t i = 0; i < {{BATCH_SIZE}}; ++i) {\n-          {{SINGLE_THREADED_MATMUL_FUNCTION}}(\n-                nullptr,\n-                {{OUTPUT_PTR}} + {{OUTPUT_STRIDE}} * i,\n-                {{LHS_PTR}} + {{LHS_STRIDE}} * i,\n-                {{RHS_PTR}} + {{RHS_STRIDE}} * i,\n-                {{M}}, {{N}}, {{K}}, {{TRANSPOSE_LHS}}, {{TRANSPOSE_RHS}});\n-         }\n-      }\n-      )\";\n+     )\";\n \n   if (!(dot_thunk.lhs_buffer_shape().shape().element_type() ==\n             dot_thunk.rhs_buffer_shape().shape().element_type() &&\n@@ -214,13 +185,7 @@ absl::StatusOr<std::string> ThunkProtoExecutionDeserializer::GetDotThunkRunImpl(\n \n   TF_ASSIGN_OR_RETURN(\n       std::string matmul_function,\n-      GetMatmulFunction(dot_thunk.lhs_buffer_shape().shape().element_type(),\n-                        /*is_single_threaded=*/false));\n-\n-  TF_ASSIGN_OR_RETURN(\n-      std::string single_threaded_matmul_function,\n-      GetMatmulFunction(dot_thunk.lhs_buffer_shape().shape().element_type(),\n-                        /*is_single_threaded=*/true));\n+      GetMatmulFunction(dot_thunk.lhs_buffer_shape().shape().element_type()));\n \n   TF_ASSIGN_OR_RETURN(std::string data_type,\n                       CppDataTypeFromXlaType(\n@@ -280,7 +245,7 @@ absl::StatusOr<std::string> ThunkProtoExecutionDeserializer::GetDotThunkRunImpl(\n   int64_t out_stride = m * n;\n \n   std::vector<std::pair<std::string, std::string>> rewrites = {\n-      {\"{{SINGLE_THREADED_MATMUL_FUNCTION}}\", single_threaded_matmul_function},\n+      {\"{{MATMUL_FUNCTION}}\", matmul_function},\n       {\"{{OUTPUT_PTR}}\", output_ptr},\n       {\"{{OUTPUT_STRIDE}}\", absl::StrCat(out_stride)},\n       {\"{{LHS_PTR}}\", lhs_ptr},\n@@ -294,10 +259,6 @@ absl::StatusOr<std::string> ThunkProtoExecutionDeserializer::GetDotThunkRunImpl(\n       {\"{{TRANSPOSE_RHS}}\", transpose_rhs ? \"true\" : \"false\"},\n       {\"{{BATCH_SIZE}}\", absl::StrCat(dot_shape.batch_size)}};\n \n-  if (xla_cpu_multi_thread_eigen_) {\n-    rewrites.push_back({\"{{MATMUL_FUNCTION}}\", matmul_function});\n-  }\n-\n   return absl::StrReplaceAll(dot_thunk_invocation_format, rewrites);\n };\n "
        },
        {
            "sha": "a5f7ddcd5fa13b8008a1785f7089ea66836dc2ef",
            "filename": "tensorflow/compiler/aot/thunk_proto_execution_deserializer.h",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/tensorflow%2Fcompiler%2Faot%2Fthunk_proto_execution_deserializer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/tensorflow%2Fcompiler%2Faot%2Fthunk_proto_execution_deserializer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2Fthunk_proto_execution_deserializer.h?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -44,8 +44,7 @@ class ThunkProtoExecutionDeserializer {\n       const xla::cpu::ThunkSequenceProto& thunk_sequence_proto);\n \n  protected:\n-  absl::StatusOr<std::string> GetMatmulFunction(xla::PrimitiveType xla_type,\n-                                                bool is_single_threaded);\n+  absl::StatusOr<std::string> GetMatmulFunction(xla::PrimitiveType xla_type);\n \n   absl::StatusOr<std::string> GetDotThunkRunImpl(\n       const xla::cpu::ThunkProto& thunk);"
        },
        {
            "sha": "a71bf4c999163d203bbebd9b8965ebcfe7357960",
            "filename": "third_party/xla/xla/backends/cpu/runtime/BUILD",
            "status": "modified",
            "additions": 31,
            "deletions": 1,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -24,6 +24,13 @@ filegroup(\n     srcs = [\n         \"convolution_lib_f16.cc\",\n         \"convolution_lib_f32.cc\",\n+        \"dot_lib_c128.cc\",\n+        \"dot_lib_c64.cc\",\n+        \"dot_lib_f16.cc\",\n+        \"dot_lib_f32.cc\",\n+        \"dot_lib_f64.cc\",\n+        \"dot_lib_s32.cc\",\n+        \"dot_lib_s8.cc\",\n         \"rng_state_lib.cc\",\n         \"sort_lib.cc\",\n     ],\n@@ -34,6 +41,7 @@ filegroup(\n     name = \"runtime_hdrs\",\n     srcs = [\n         \"convolution_lib.h\",\n+        \"dot_lib.h\",\n         \"kernel_c_api.h\",\n         \"rng_state_lib.h\",\n         \"sort_lib.h\",\n@@ -743,6 +751,28 @@ cc_library(\n         \"dot_lib_s8.cc\",\n     ],\n     hdrs = [\"dot_lib.h\"],\n+    deps = [\n+        \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/functional:any_invocable\",\n+        \"@eigen_archive//:eigen3\",\n+    ],\n+)\n+\n+# By including `eigen_contraction_kernel` into the list of dependencies, we enable the use of\n+# oneDNN Eigen contraction kernel for jit-compiling microkernels. This brings oneDNN to the list\n+# of transitive dependencies, and some clients (e.g. tfcompile) don't want this extra dependency.\n+cc_library(\n+    name = \"dot_lib_onednn\",\n+    srcs = [\n+        \"dot_lib_c128.cc\",\n+        \"dot_lib_c64.cc\",\n+        \"dot_lib_f16.cc\",\n+        \"dot_lib_f32.cc\",\n+        \"dot_lib_f64.cc\",\n+        \"dot_lib_s32.cc\",\n+        \"dot_lib_s8.cc\",\n+    ],\n+    hdrs = [\"dot_lib.h\"],\n     deps = [\n         \"//xla/tsl/framework/contraction:eigen_contraction_kernel\",\n         \"@com_google_absl//absl/base:core_headers\",\n@@ -757,7 +787,7 @@ cc_library(\n     hdrs = [\"dot_thunk.h\"],\n     deps = [\n         \":dot_dims\",\n-        \":dot_lib\",\n+        \":dot_lib_onednn\",\n         \":thunk\",\n         \"//xla:shape_util\",\n         \"//xla:types\","
        }
    ],
    "stats": {
        "total": 135,
        "additions": 60,
        "deletions": 75
    }
}