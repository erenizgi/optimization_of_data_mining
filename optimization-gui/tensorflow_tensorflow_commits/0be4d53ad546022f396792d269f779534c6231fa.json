{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 845648351",
    "sha": "0be4d53ad546022f396792d269f779534c6231fa",
    "files": [
        {
            "sha": "54d6276c05cc327692fbee8edd874823acd0f231",
            "filename": "tensorflow/compiler/jit/kernels/xla_ops.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 8,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0be4d53ad546022f396792d269f779534c6231fa/tensorflow%2Fcompiler%2Fjit%2Fkernels%2Fxla_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0be4d53ad546022f396792d269f779534c6231fa/tensorflow%2Fcompiler%2Fjit%2Fkernels%2Fxla_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fkernels%2Fxla_ops.cc?ref=0be4d53ad546022f396792d269f779534c6231fa",
            "patch": "@@ -166,7 +166,7 @@ class ExecutableClosureStore {\n  public:\n   ExecutableClosureStore() : key_counter_(0) {}\n \n-  using KeyT = string;\n+  using KeyT = std::string;\n \n   KeyT Produce(ExecutableClosure<ExecutableType, ClientType> result) {\n     mutex_lock l(mutex_);\n@@ -217,7 +217,8 @@ se::Stream* GetStream(OpKernelContext* ctx) {\n \n XlaComputationLaunchContext GetLaunchContext(\n     const XlaPlatformInfo& platform_info, OpKernelContext* ctx,\n-    xla::LocalClient* client, se::DeviceMemoryAllocator* allocator) {\n+    xla::LocalClient* client,\n+    stream_executor::DeviceAddressAllocator* allocator) {\n   se::Stream* stream = GetStream(ctx);\n   int device_ordinal = stream ? stream->parent()->device_ordinal()\n                               : client->default_device_ordinal();\n@@ -230,7 +231,7 @@ XlaComputationLaunchContext GetLaunchContext(\n \n absl::Status GetTaskName(const absl::string_view device_name,\n                          std::string* task_name) {\n-  string ignored;\n+  std::string ignored;\n   if (!DeviceNameUtils::SplitDeviceName(device_name, task_name, &ignored)) {\n     return errors::InvalidArgument(\"Unable to parse device name: \",\n                                    device_name);\n@@ -246,7 +247,7 @@ xla::SendDeviceMemoryFunction GetSendDeviceMemoryFunction(\n   return\n       [ctx, program_key](\n           int64_t channel_id, se::Stream* stream, const xla::Shape& shape,\n-          const se::DeviceMemoryBase& device_memory_base,\n+          const stream_executor::DeviceAddressBase& device_memory_base,\n           const absl::flat_hash_map<std::string, std::string>& frontend_attrs)\n           -> absl::StatusOr<tsl::AsyncValueRef<std::unique_ptr<se::Event>>> {\n         auto iter = frontend_attrs.find(\"_xla_host_transfer_rendezvous\");\n@@ -293,7 +294,7 @@ xla::RecvDeviceMemoryFunction GetRecvDeviceMemoryFunction(\n   return\n       [ctx, program_key](\n           int64_t channel_id, se::Stream* stream, const xla::Shape& shape,\n-          se::DeviceMemoryBase* device_memory_base,\n+          stream_executor::DeviceAddressBase* device_memory_base,\n           const absl::flat_hash_map<std::string, std::string>& frontend_attrs)\n           -> absl::StatusOr<tsl::AsyncValueRef<std::unique_ptr<se::Event>>> {\n         auto iter = frontend_attrs.find(\"_xla_host_transfer_rendezvous\");\n@@ -339,7 +340,7 @@ absl::StatusOr<xla::ExecutionOutput> RunExecutable(\n     const XlaComputationLaunchContext& launch_context,\n     std::vector<xla::ExecutionInput> execution_inputs,\n     xla::ExecutableRunOptions run_options, xla::LocalExecutable* executable,\n-    OpKernelContext* ctx, se::DeviceMemoryAllocator* allocator) {\n+    OpKernelContext* ctx, stream_executor::DeviceAddressAllocator* allocator) {\n   VLOG(2) << \"Executing Xla Computation.\";\n   Env* env = Env::Default();\n   auto start_time = env->NowMicros();\n@@ -620,7 +621,7 @@ void XlaLocalLaunchBase::ComputeAsync(OpKernelContext* ctx, DoneCallback done) {\n         resource_var_ptrs[resources[i]] = variable_infos[i].var()->tensor();\n       }\n \n-      std::shared_ptr<se::DeviceMemoryAllocator> allocator =\n+      std::shared_ptr<stream_executor::DeviceAddressAllocator> allocator =\n           GetAllocator(ctx->device(), GetStream(ctx), platform_info);\n       XlaComputationLaunchContext launch_context =\n           GetLaunchContext(platform_info, ctx, client, allocator.get());\n@@ -928,7 +929,7 @@ void XlaRunOp::Compute(OpKernelContext* ctx) {\n \n   XlaExecutableClosure closure =\n       XlaExecutableClosureStore::Global()->Consume(key);\n-  std::shared_ptr<se::DeviceMemoryAllocator> allocator =\n+  std::shared_ptr<stream_executor::DeviceAddressAllocator> allocator =\n       GetAllocator(ctx->device(), GetStream(ctx), platform_info_);\n   XlaComputationLaunchContext launch_context =\n       GetLaunchContext(platform_info_, ctx, closure.client(), allocator.get());"
        }
    ],
    "stats": {
        "total": 17,
        "additions": 9,
        "deletions": 8
    }
}