{
    "author": "othakkar",
    "message": "PR #31747: [XLA:CPU][oneDNN] Use Async Threadpool for Pre-Computing Blocked Weights\n\nImported from GitHub PR https://github.com/openxla/xla/pull/31747\n\nThis PR replaces the use of the synchronous (legacy) oneDNN threadpool interface with the asynchronous oneDNN threadpool interface to reorder weights for pre-computing blocked weights.\nCopybara import of the project:\n\n--\nb1fe4386a02e1504c3924891033f638acdbad863 by Om Thakkar <om.thakkar@intel.com>:\n\nuse async threadpool for weight-prepacking\n\n--\na1ffd8dd669c537f95e194e258f115607fb05b8f by Om Thakkar <om.thakkar@intel.com>:\n\nadd a unit test for the failing case\n\n--\ndb9ee236690e47f5174f2d6cdbce1d820dfbd7a3 by Om Thakkar <om.thakkar@intel.com>:\n\nadd missing dep\n\n--\n46bc2e644eb57fa7c482d058c76449c3de03d187 by Om Thakkar <om.thakkar@intel.com>:\n\nset --xla_cpu_experimental_onednn_custom_call=true for oneDNN MatMul and Conv unit tests\n\nMerging this change closes #31747\n\nPiperOrigin-RevId: 816191098",
    "sha": "4604295bfed3349a29d4c109ac805e05a722e93b",
    "files": [
        {
            "sha": "99180b9a4259b121cc8586539949115a78ac3a7e",
            "filename": "third_party/xla/xla/backends/cpu/runtime/onednn/onednn_threadpool.h",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4604295bfed3349a29d4c109ac805e05a722e93b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_threadpool.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4604295bfed3349a29d4c109ac805e05a722e93b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_threadpool.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_threadpool.h?ref=4604295bfed3349a29d4c109ac805e05a722e93b",
            "patch": "@@ -49,7 +49,7 @@ class OneDnnThreadPool final\n       : thread_pool_(thread_pool), is_async_(is_async) {\n     if (is_async_) {\n       done_event_ = OkDoneEventSingleton();\n-      dnnl_threadpool_interop_set_max_concurrency(thread_pool_->NumThreads());\n+      set_onednn_max_threads(thread_pool_->NumThreads());\n     }\n   }\n \n@@ -109,6 +109,10 @@ class OneDnnThreadPool final\n \n   tsl::AsyncValueRef<tsl::Chain> done_event() const { return done_event_; }\n \n+  static void set_onednn_max_threads(int num_threads) {\n+    dnnl_threadpool_interop_set_max_concurrency(num_threads);\n+  }\n+\n  private:\n   Eigen::ThreadPoolInterface* thread_pool_;\n "
        },
        {
            "sha": "fb56888b41d8a8fa59311e8547dadcfdb8932928",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4604295bfed3349a29d4c109ac805e05a722e93b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4604295bfed3349a29d4c109ac805e05a722e93b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=4604295bfed3349a29d4c109ac805e05a722e93b",
            "patch": "@@ -1860,7 +1860,6 @@ onednn_cc_library(\n         \"onednn_contraction_rewriter.h\",\n         \"onednn_convolution.h\",\n         \"onednn_matmul.h\",\n-        \"//xla/tsl/util:onednn_util_hdrs\",\n     ],\n     copts = tsl_copts(),\n     deps = [\n@@ -1877,6 +1876,7 @@ onednn_cc_library(\n         \"//xla:status_macros\",\n         \"//xla:types\",\n         \"//xla:util\",\n+        \"//xla/backends/cpu/runtime/onednn:onednn_threadpool\",\n         \"//xla/hlo/evaluator:hlo_evaluator\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/pass:hlo_pass\","
        },
        {
            "sha": "bc3df0361d082aa7c1c84d6a0757cc6cad869d58",
            "filename": "third_party/xla/xla/service/cpu/onednn_contraction_rewriter.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4604295bfed3349a29d4c109ac805e05a722e93b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4604295bfed3349a29d4c109ac805e05a722e93b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc?ref=4604295bfed3349a29d4c109ac805e05a722e93b",
            "patch": "@@ -34,6 +34,8 @@ limitations under the License.\n #include \"Eigen/Core\"\n #include \"oneapi/dnnl/dnnl.hpp\"\n #include \"oneapi/dnnl/dnnl_common.hpp\"\n+#include \"oneapi/dnnl/dnnl_threadpool.hpp\"\n+#include \"xla/backends/cpu/runtime/onednn/onednn_threadpool.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/hlo/evaluator/hlo_evaluator.h\"\n #include \"xla/hlo/ir/dfs_hlo_visitor_with_default.h\"\n@@ -58,7 +60,6 @@ limitations under the License.\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n-#include \"xla/tsl/util/onednn_threadpool.h\"\n #include \"xla/types.h\"\n #include \"xla/util.h\"\n #include \"tsl/platform/cpu_info.h\"\n@@ -1302,7 +1303,7 @@ class OneDnnPostRewriteVisitor : public DfsHloRewriteVisitor {\n \n #ifndef ENABLE_ONEDNN_OPENMP\n     // Set oneDNN concurrency settings (which is thread-local)\n-    tsl::OneDnnThreadPool::set_onednn_max_threads(intra_op_parallelism_);\n+    OneDnnThreadPool::set_onednn_max_threads(intra_op_parallelism_);\n #endif\n   }\n \n@@ -1462,13 +1463,16 @@ class OneDnnPostRewriteVisitor : public DfsHloRewriteVisitor {\n \n   void ReorderWeight(const dnnl::memory::desc& src_md, void* src_buf,\n                      const dnnl::memory::desc& dst_md, void* dst_buf) {\n-    auto onednn_threadpool = CreateOneDnnThreadPool(threadpool_device_.get());\n+    auto onednn_threadpool = std::make_unique<OneDnnThreadPool>(\n+        threadpool_device_->getPool(), /*is_async=*/true);\n     dnnl::engine cpu_engine(dnnl::engine::kind::cpu, 0);\n-    auto onednn_stream = MakeOneDnnStream(cpu_engine, onednn_threadpool.get());\n+    auto onednn_stream = dnnl::threadpool_interop::make_stream(\n+        cpu_engine, onednn_threadpool.get());\n     auto src_mem = dnnl::memory(src_md, cpu_engine, src_buf);\n     auto dst_mem = dnnl::memory(dst_md, cpu_engine, dst_buf);\n     dnnl::reorder reorder_prim{src_mem, dst_mem};\n     reorder_prim.execute(onednn_stream, src_mem, dst_mem);\n+    // Wait for the reorder to finish before destroying the threadpool.\n     onednn_stream.wait();\n   }\n "
        },
        {
            "sha": "f1dcc5caed67438c9e939a752c4d5c2b37b698e3",
            "filename": "third_party/xla/xla/service/cpu/tests/onednn_convolution_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4604295bfed3349a29d4c109ac805e05a722e93b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_convolution_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4604295bfed3349a29d4c109ac805e05a722e93b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_convolution_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_convolution_test.cc?ref=4604295bfed3349a29d4c109ac805e05a722e93b",
            "patch": "@@ -35,6 +35,7 @@ class ConvolutionTest : public HloTestBase,\n  protected:\n   DebugOptions GetDebugOptionsForTest() const override {\n     DebugOptions debug_options = HloTestBase::GetDebugOptionsForTest();\n+    debug_options.set_xla_cpu_experimental_onednn_custom_calls(true);\n     return debug_options;\n   }\n "
        },
        {
            "sha": "8348d38f505c40b2efb71d29f0441d0118cd41b2",
            "filename": "third_party/xla/xla/service/cpu/tests/onednn_matmul_test.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4604295bfed3349a29d4c109ac805e05a722e93b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_matmul_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4604295bfed3349a29d4c109ac805e05a722e93b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_matmul_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_matmul_test.cc?ref=4604295bfed3349a29d4c109ac805e05a722e93b",
            "patch": "@@ -28,6 +28,7 @@ class MatmulTest : public HloTestBase {\n  protected:\n   DebugOptions GetDebugOptionsForTest() const override {\n     DebugOptions debug_options = HloTestBase::GetDebugOptionsForTest();\n+    debug_options.set_xla_cpu_experimental_onednn_custom_call(true);\n     return debug_options;\n   }\n \n@@ -1647,6 +1648,32 @@ TEST_F(MatmulTest, WeightsPrepackAndScratch) {\n   )\");\n }\n \n+TEST_F(MatmulTest, PrepackLarge2DWeights) {\n+  const char* matmul_module_str = R\"(\n+  HloModule matmul.weights_prepack_large.f32\n+\n+  ENTRY matmul.weights_prepack_large.f32 {\n+    lhs = f32[2,4096] parameter(0), parameter_replication={false}\n+    c = f32[] constant(1)\n+    rhs = f32[4096,4096] broadcast(c), dimensions={}\n+    ROOT dot = f32[2,4096] dot(lhs, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+  })\";\n+\n+  MatchOptimizedHlo(matmul_module_str,\n+                    R\"(\n+  ; CHECK: %matmul.weights_prepack_large.f32\n+  ; CHECK:     custom_call_target=\"__onednn$matmul\",\n+  ; CHECK:       backend_config={\n+  ; CHECK-DAG:     \"onednn_matmul_config\":{\n+  ; CHECK-DAG:       \"optimization_config\":{\n+  ; CHECK-DAG:         \"weights_prepacked\":true,\n+  ; CHECK-DAG:         \"user_scratchpad\":true\n+  ; CHECK-DAG:       }\n+  ; CHECK-DAG:     }\n+  ; CHECK:       }\n+  )\");\n+}\n+\n TEST_F(MatmulTest, ColMajorBF16DotBeforeLayoutAssignment) {\n   if (!IsSupportedType(PrimitiveType::BF16)) {\n     GTEST_SKIP() << \"CPU does not support BF16.\";"
        }
    ],
    "stats": {
        "total": 48,
        "additions": 42,
        "deletions": 6
    }
}