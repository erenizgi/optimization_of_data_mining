{
    "author": "basioli-k",
    "message": "[XLA:CPU][nanort] Enable loading nanort executable from CompilationResultProto.\n\nPiperOrigin-RevId: 810830079",
    "sha": "c39405f018045a740f354ae5c38f417084010412",
    "files": [
        {
            "sha": "c57638cf287bcb835c86832b4c196747fe052ce1",
            "filename": "third_party/xla/xla/backends/cpu/nanort/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2FBUILD?ref=c39405f018045a740f354ae5c38f417084010412",
            "patch": "@@ -64,6 +64,7 @@ xla_cc_test(\n         \"//xla/pjrt/plugin/xla_cpu:xla_cpu_pjrt_client\",\n         \"//xla/runtime:device_id\",\n         \"//xla/service:computation_placer_hdr\",\n+        \"//xla/service/cpu:cpu_aot_compilation_result\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:logging\",\n@@ -77,6 +78,7 @@ xla_cc_test(\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n         \"@eigen_archive//:eigen3\",\n+        \"@local_tsl//tsl/platform:casts\",\n     ],\n )\n \n@@ -104,7 +106,9 @@ cc_library(\n         \"//xla/service:computation_placer_hdr\",\n         \"//xla/service:executable\",\n         \"//xla/service:hlo_value\",\n+        \"//xla/service/cpu:cpu_aot_loader\",\n         \"//xla/service/cpu:cpu_executable\",\n+        \"//xla/service/cpu:executable_proto_cc\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:errors\","
        },
        {
            "sha": "3dd8db1f22ebaad2b937b06dcfde1051348a7915",
            "filename": "third_party/xla/xla/backends/cpu/nanort/nanort_client.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_client.cc?ref=c39405f018045a740f354ae5c38f417084010412",
            "patch": "@@ -83,4 +83,10 @@ absl::StatusOr<std::unique_ptr<NanoRtExecutable>> NanoRtClient::Compile(\n                                   optimized_hlo_program_shape);\n }\n \n+absl::StatusOr<std::unique_ptr<AotCompilationResult>> NanoRtClient::Export(\n+    NanoRtExecutable* executable) {\n+  cpu::CpuCompiler compiler;\n+  return compiler.Export(executable->executable());\n+}\n+\n }  // namespace xla::cpu"
        },
        {
            "sha": "3dc3ddf29620199ba614acc377779c6d693f5db9",
            "filename": "third_party/xla/xla/backends/cpu/nanort/nanort_client.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_client.h?ref=c39405f018045a740f354ae5c38f417084010412",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"xla/backends/cpu/nanort/nanort_executable.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n+#include \"xla/service/compiler.h\"\n \n namespace xla::cpu {\n \n@@ -33,6 +34,10 @@ class NanoRtClient {\n   // backend.\n   absl::StatusOr<std::unique_ptr<NanoRtExecutable>> Compile(\n       const XlaComputation& computation);\n+\n+  // Exports the given NanoRtExecutable to an AotCompilationResult.\n+  absl::StatusOr<std::unique_ptr<AotCompilationResult>> Export(\n+      NanoRtExecutable* executable);\n };\n \n }  // namespace xla::cpu"
        },
        {
            "sha": "d8df49dcb12c9a37ac86da5b1c8a182be52d9bd5",
            "filename": "third_party/xla/xla/backends/cpu/nanort/nanort_client_test.cc",
            "status": "modified",
            "additions": 46,
            "deletions": 28,
            "changes": 74,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_client_test.cc?ref=c39405f018045a740f354ae5c38f417084010412",
            "patch": "@@ -47,6 +47,7 @@ limitations under the License.\n #include \"xla/pjrt/plugin/xla_cpu/xla_cpu_pjrt_client.h\"\n #include \"xla/runtime/device_id.h\"\n #include \"xla/service/computation_placer.h\"\n+#include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n@@ -55,6 +56,7 @@ limitations under the License.\n #include \"xla/tsl/platform/test.h\"\n #include \"xla/tsl/platform/test_benchmark.h\"\n #include \"xla/xla_data.pb.h\"\n+#include \"tsl/platform/casts.h\"\n \n #define EIGEN_USE_THREADS\n \n@@ -67,7 +69,26 @@ namespace {\n using Arguments = absl::InlinedVector<NanoRtExecutable::Argument, 8>;\n using Results = absl::InlinedVector<NanoRtExecutable::Result, 8>;\n \n-TEST(NanoRtClientTest, ManagedTempAlignment) {\n+absl::StatusOr<std::unique_ptr<NanoRtExecutable>> GetExecutable(\n+    const XlaComputation& computation, bool export_executable) {\n+  NanoRtClient client;\n+  TF_ASSIGN_OR_RETURN(std::unique_ptr<NanoRtExecutable> executable,\n+                      client.Compile(computation));\n+\n+  if (export_executable) {\n+    TF_ASSIGN_OR_RETURN(auto exported, client.Export(executable.get()));\n+    CpuAotCompilationResult* aot_compilation_result =\n+        tsl::down_cast<CpuAotCompilationResult*>(exported.get());\n+    return NanoRtExecutable::Create(aot_compilation_result->proto(),\n+                                    executable->program_shape());\n+  }\n+\n+  return executable;\n+}\n+\n+class NanoRtClientTest : public ::testing::TestWithParam<bool> {};\n+\n+TEST(NanoRtClientStandaloneTest, ManagedTempAlignment) {\n   NanoRtExecutable::ManagedTemp<3> temp0(1);\n   NanoRtExecutable::ManagedTemp<3> temp1(2);\n   NanoRtExecutable::ManagedTemp<3> temp2(3);\n@@ -79,7 +100,7 @@ TEST(NanoRtClientTest, ManagedTempAlignment) {\n   EXPECT_EQ(reinterpret_cast<uintptr_t>(&temp3.data()[0]) % Align(), 0);\n }\n \n-TEST(NanoRtClientTest, CompileAndRunScalarComputation) {\n+TEST_P(NanoRtClientTest, CompileAndRunScalarComputation) {\n   constexpr absl::string_view hlo = R\"(\n     HloModule add\n \n@@ -93,9 +114,8 @@ TEST(NanoRtClientTest, CompileAndRunScalarComputation) {\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnUnverifiedModule(hlo));\n   XlaComputation computation(module->ToProto());\n \n-  NanoRtClient client;\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<NanoRtExecutable> executable,\n-                          client.Compile(computation));\n+                          GetExecutable(computation, GetParam()));\n \n   // Storage for executable parameters and results.\n   alignas(32) float p0_value = 1.0f;\n@@ -113,7 +133,7 @@ TEST(NanoRtClientTest, CompileAndRunScalarComputation) {\n   EXPECT_EQ(r0_value, 3.0f);\n }\n \n-TEST(NanoRtClientTest, CompileAndRunTupledComputation) {\n+TEST_P(NanoRtClientTest, CompileAndRunTupledComputation) {\n   constexpr absl::string_view hlo = R\"(\n     HloModule add_and_mul\n \n@@ -130,9 +150,8 @@ TEST(NanoRtClientTest, CompileAndRunTupledComputation) {\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnUnverifiedModule(hlo));\n   XlaComputation computation(module->ToProto());\n \n-  NanoRtClient client;\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<NanoRtExecutable> executable,\n-                          client.Compile(computation));\n+                          GetExecutable(computation, GetParam()));\n \n   // Storage for executable parameters and results.\n   alignas(32) float p0_value = 2.0f;\n@@ -152,7 +171,7 @@ TEST(NanoRtClientTest, CompileAndRunTupledComputation) {\n   EXPECT_EQ(r1_value, 6.0f);\n }\n \n-TEST(NanoRtClientTest, CompileAndRunConstantComputation) {\n+TEST_P(NanoRtClientTest, CompileAndRunConstantComputation) {\n   absl::string_view hlo = R\"(\n     HloModule cst\n \n@@ -164,9 +183,8 @@ TEST(NanoRtClientTest, CompileAndRunConstantComputation) {\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnUnverifiedModule(hlo));\n   XlaComputation computation(module->ToProto());\n \n-  NanoRtClient client;\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<NanoRtExecutable> executable,\n-                          client.Compile(computation));\n+                          GetExecutable(computation, GetParam()));\n \n   // Storage for executable results.\n   alignas(32) float r0_value = 0.0f;\n@@ -182,7 +200,7 @@ TEST(NanoRtClientTest, CompileAndRunConstantComputation) {\n   EXPECT_EQ(r0_value, 42.0f);\n }\n \n-TEST(NanoRtClientTest, CompileAndRunConditionalComputation) {\n+TEST_P(NanoRtClientTest, CompileAndRunConditionalComputation) {\n   absl::string_view hlo = R\"(\n     HloModule conditional\n \n@@ -207,9 +225,8 @@ TEST(NanoRtClientTest, CompileAndRunConditionalComputation) {\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnUnverifiedModule(hlo));\n   XlaComputation computation(module->ToProto());\n \n-  NanoRtClient client;\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<NanoRtExecutable> executable,\n-                          client.Compile(computation));\n+                          GetExecutable(computation, GetParam()));\n \n   // Storage for executable parameters and results.\n   alignas(32) int32_t p0_value = 0;\n@@ -228,7 +245,7 @@ TEST(NanoRtClientTest, CompileAndRunConditionalComputation) {\n   EXPECT_EQ(r0_value, 8.0f);\n }\n \n-TEST(NanoRtClientTest, CompileAndRunModelWithThreadPool) {\n+TEST_P(NanoRtClientTest, CompileAndRunModelWithThreadPool) {\n   // Implements matmul(A, C) + matmul(B, C)\n   absl::string_view hlo = R\"(\n     HloModule test_module\n@@ -245,9 +262,8 @@ ENTRY test_module {\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnUnverifiedModule(hlo));\n   XlaComputation computation(module->ToProto());\n \n-  NanoRtClient client;\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<NanoRtExecutable> executable,\n-                          client.Compile(computation));\n+                          GetExecutable(computation, GetParam()));\n \n   xla::Literal first_literal =\n       LiteralUtil::CreateR2FromArray2D<float>(Array2D<float>(1024, 4096, 1.0f));\n@@ -286,7 +302,7 @@ ENTRY test_module {\n   EXPECT_EQ(result_span[0], expected_result);\n }\n \n-TEST(NanoRtClientTest, CompileAndRunPartitionAndReplicaIdInstructions) {\n+TEST_P(NanoRtClientTest, CompileAndRunPartitionAndReplicaIdInstructions) {\n   constexpr absl::string_view hlo = R\"(\n     HloModule replica-and-partition-id\n \n@@ -300,9 +316,8 @@ ENTRY ReplicaAndPartitionId {\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnUnverifiedModule(hlo));\n   XlaComputation computation(module->ToProto());\n \n-  NanoRtClient client;\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<NanoRtExecutable> executable,\n-                          client.Compile(computation));\n+                          GetExecutable(computation, GetParam()));\n \n   ComputationPlacer computation_placer;\n   constexpr int kReplicaCount = 2;\n@@ -361,7 +376,7 @@ XLA_FFI_DEFINE_HANDLER(kAdd, Add,\n XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"__xla_nanort_test$$add\", \"Host\",\n                          kAdd);\n \n-TEST(NanoRtClientTest, CustomCallTest) {\n+TEST_P(NanoRtClientTest, CustomCallTest) {\n   const char* kModuleStr = R\"(\n     HloModule module\n \n@@ -377,9 +392,8 @@ TEST(NanoRtClientTest, CustomCallTest) {\n                           ParseAndReturnUnverifiedModule(kModuleStr));\n   XlaComputation computation(module->ToProto());\n \n-  NanoRtClient client;\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<NanoRtExecutable> executable,\n-                          client.Compile(computation));\n+                          GetExecutable(computation, GetParam()));\n \n   int32_t a = 1.0f;\n   int32_t b = 2.0f;\n@@ -404,7 +418,7 @@ TEST(NanoRtClientTest, CustomCallTest) {\n   EXPECT_EQ(result, 3.0f);\n }\n \n-TEST(NanoRtClientTest, ProgramShapeTestInt4) {\n+TEST_P(NanoRtClientTest, ProgramShapeTestInt4) {\n   constexpr absl::string_view kModuleStr = R\"(\n     HloModule int4_function\n \n@@ -419,9 +433,8 @@ TEST(NanoRtClientTest, ProgramShapeTestInt4) {\n                           ParseAndReturnUnverifiedModule(kModuleStr));\n   XlaComputation computation(module->ToProto());\n \n-  NanoRtClient client;\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<NanoRtExecutable> executable,\n-                          client.Compile(computation));\n+                          GetExecutable(computation, GetParam()));\n   ASSERT_TRUE(executable->program_shape().has_value());\n \n   auto program_shape = executable->program_shape();\n@@ -435,7 +448,7 @@ TEST(NanoRtClientTest, ProgramShapeTestInt4) {\n       executable->program_shape()->result().layout().element_size_in_bits(), 4);\n }\n \n-TEST(NanoRtClientTest, ProgramShapeKeepsLayout) {\n+TEST_P(NanoRtClientTest, ProgramShapeKeepsLayout) {\n   constexpr absl::string_view kModuleStr = R\"(\n     HloModule layout_test\n \n@@ -450,9 +463,8 @@ TEST(NanoRtClientTest, ProgramShapeKeepsLayout) {\n                           ParseAndReturnUnverifiedModule(kModuleStr));\n   XlaComputation computation(hlo_module->ToProto());\n \n-  NanoRtClient client;\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<NanoRtExecutable> executable,\n-                          client.Compile(computation));\n+                          GetExecutable(computation, GetParam()));\n   ASSERT_TRUE(executable->program_shape().has_value());\n \n   auto program_shape = executable->program_shape();\n@@ -465,6 +477,12 @@ TEST(NanoRtClientTest, ProgramShapeKeepsLayout) {\n             absl::Span<const int64_t>({0, 1}));\n }\n \n+INSTANTIATE_TEST_SUITE_P(NanoRtClientTestSuite, NanoRtClientTest,\n+                         ::testing::Bool(),\n+                         [](const ::testing::TestParamInfo<bool>& info) {\n+                           return info.param ? \"EXPORT\" : \"NO_EXPORT\";\n+                         });\n+\n //===----------------------------------------------------------------------===//\n // Performance benchmarks below\n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "208da4bd4c0ad351c868d21cb7a17b4b3916b40a",
            "filename": "third_party/xla/xla/backends/cpu/nanort/nanort_executable.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_executable.cc?ref=c39405f018045a740f354ae5c38f417084010412",
            "patch": "@@ -39,7 +39,9 @@ limitations under the License.\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/computation_layout.h\"\n #include \"xla/service/computation_placer.h\"\n+#include \"xla/service/cpu/cpu_aot_loader.h\"\n #include \"xla/service/cpu/cpu_executable.h\"\n+#include \"xla/service/cpu/executable.pb.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/hlo_value.h\"\n #include \"xla/shape.h\"\n@@ -281,6 +283,15 @@ absl::StatusOr<std::unique_ptr<NanoRtExecutable>> NanoRtExecutable::Create(\n                            temp_allocation_index, program_shape));\n }\n \n+absl::StatusOr<std::unique_ptr<NanoRtExecutable>> NanoRtExecutable::Create(\n+    CompilationResultProto aot_compilation_result,\n+    std::optional<ProgramShape> program_shape) {\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<Executable> executable,\n+      CpuAotLoader::LoadExecutable(std::move(aot_compilation_result)));\n+  return Create(std::move(executable), program_shape);\n+}\n+\n NanoRtExecutable::NanoRtExecutable(\n     std::unique_ptr<Executable> executable,\n     std::vector<size_t> allocation_sizes,"
        },
        {
            "sha": "f12920e5a64a9d1e803a31c24d8189f34262e7e2",
            "filename": "third_party/xla/xla/backends/cpu/nanort/nanort_executable.h",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_executable.h?ref=c39405f018045a740f354ae5c38f417084010412",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"xla/ffi/execution_context.h\"\n #include \"xla/runtime/device_id.h\"\n #include \"xla/service/computation_placer.h\"\n+#include \"xla/service/cpu/executable.pb.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/shape.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n@@ -53,6 +54,12 @@ class NanoRtExecutable {\n       std::unique_ptr<Executable> executable,\n       std::optional<ProgramShape> program_shape = std::nullopt);\n \n+  // Creates a new instance of the NanoRtExecutable from an AOT compilation\n+  // result.\n+  static absl::StatusOr<std::unique_ptr<NanoRtExecutable>> Create(\n+      CompilationResultProto aot_compilation_result,\n+      std::optional<ProgramShape> program_shape = std::nullopt);\n+\n   // NanoRtExecutable can be asynchronous and return unavailable async value\n   // that becomes available after the execution is complete. It is the caller's\n   // responsibility to make sure that arguments, results and temp buffers are\n@@ -189,6 +196,8 @@ class NanoRtExecutable {\n \n   std::optional<ProgramShape> program_shape() const { return program_shape_; }\n \n+  Executable* executable() const { return executable_.get(); }\n+\n  private:\n   NanoRtExecutable(std::unique_ptr<Executable> executable,\n                    std::vector<size_t> allocation_sizes,"
        },
        {
            "sha": "ccfcf5611f38841ee2212abe3e591d91ae4651c2",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c39405f018045a740f354ae5c38f417084010412/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=c39405f018045a740f354ae5c38f417084010412",
            "patch": "@@ -2202,5 +2202,13 @@ cc_library(\n         \"@llvm-project//llvm:Support\",\n         \"@llvm-project//llvm:Target\",\n         \"@llvm-project//llvm:ir_headers\",\n-    ],\n+    ] + if_llvm_aarch64_available([\n+        \"@llvm-project//llvm:AArch64CodeGen\",  # fixdeps: keep\n+    ]) + if_llvm_powerpc_available([\n+        \"@llvm-project//llvm:PowerPCCodeGen\",  # fixdeps: keep\n+    ]) + if_llvm_system_z_available([\n+        \"@llvm-project//llvm:SystemZCodeGen\",  # fixdeps: keep\n+    ]) + if_llvm_x86_available([\n+        \"@llvm-project//llvm:X86CodeGen\",  # fixdeps: keep\n+    ]),\n )"
        }
    ],
    "stats": {
        "total": 119,
        "additions": 90,
        "deletions": 29
    }
}