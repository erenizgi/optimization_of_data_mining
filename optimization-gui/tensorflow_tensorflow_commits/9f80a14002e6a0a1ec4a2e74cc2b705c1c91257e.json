{
    "author": "matthiaskramm",
    "message": "Reverts 79307d0f596dda1e90d13a9e62f94288c98fea8c\n\nPiperOrigin-RevId: 800283046",
    "sha": "9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e",
    "files": [
        {
            "sha": "9ec71c36687c65b31849970c75d12e688a17fcef",
            "filename": "tensorflow/compiler/mlir/tensorflow/tests/cannonicalize_ops_outside_compilation.mlir",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fcannonicalize_ops_outside_compilation.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fcannonicalize_ops_outside_compilation.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fcannonicalize_ops_outside_compilation.mlir?ref=9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e",
            "patch": "@@ -6,10 +6,7 @@\n \n // Reshape should not be executed on TPU as all are marked by outside\n // compilation. And there should be no host-device communication.\n-// CHECK: tf._TPUCompile\n-// CHECK-NOT: tf.Reshape\n-// CHECK: launch{{.*}}CPU\n-// CHECK: tf.TPUCompileSucceeded\n+// CHECK: tf._TPUCompileMlir\n // CHECK-NOT: tf.Reshape\n // CHECK-NOT: tf._XlaHostComputeMlir\n "
        },
        {
            "sha": "8c1920efd9432d2edd4a3605bd28214464fbc82b",
            "filename": "tensorflow/compiler/mlir/tensorflow/tests/ici_weight_distribution_spmd_mlir_end_to_end.mlir",
            "status": "modified",
            "additions": 19,
            "deletions": 20,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fici_weight_distribution_spmd_mlir_end_to_end.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fici_weight_distribution_spmd_mlir_end_to_end.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fici_weight_distribution_spmd_mlir_end_to_end.mlir?ref=9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e",
            "patch": "@@ -1,32 +1,31 @@\n // RUN: tf-opt %s -tf-replicated-clustering-bridge-v2 -tfrt-lower-cluster-to-runtime-ops-tpu -tf-dialect-to-executor-v2 | FileCheck %s\n \n // CHECK-LABEL: func.func @main\n-// CHECK: %outputs:5, %control = tf_executor.island wraps \"tf._TPUCompileMlir\"()\n-// CHECK: %outputs_0, %control_1 = tf_executor.island wraps \"tf.ReadVariableOp\"(%arg3) : (tensor<*x!tf_type.resource<tensor<128x1024xf32>>>) -> tensor<128x1024xf32>\n-// CHECK: %outputs_2, %control_3 = tf_executor.island wraps \"tf.ReadVariableOp\"(%arg4) : (tensor<*x!tf_type.resource<tensor<1024xf32>>>) -> tensor<1024xf32>\n-// CHECK: %outputs_4, %control_5 = tf_executor.island wraps \"tf.TPUDummyInput\"() <{shape = #tf_type.shape<128x1024>}> {_ici_weight_distribution_mlir_bridge_marker = true} : () -> tensor<128x1024xf32>\n-// CHECK: %outputs_6, %control_7 = tf_executor.island wraps \"tf.TPUDummyInput\"() <{shape = #tf_type.shape<1024>}> {_ici_weight_distribution_mlir_bridge_marker = true} : () -> tensor<1024xf32>\n-// CHECK: %outputs_8, %control_9 = tf_executor.island wraps \"tf.Identity\"(%outputs#0) {device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<!tf_type.string>) -> tensor<!tf_type.string>\n+// CHECK: %outputs, %control = tf_executor.island wraps \"tf.ReadVariableOp\"(%arg3) : (tensor<*x!tf_type.resource<tensor<128x1024xf32>>>) -> tensor<128x1024xf32>\n+// CHECK: %outputs_0, %control_1 = tf_executor.island wraps \"tf.ReadVariableOp\"(%arg4) : (tensor<*x!tf_type.resource<tensor<1024xf32>>>) -> tensor<1024xf32>\n+// CHECK: %outputs_2, %control_3 = tf_executor.island wraps \"tf.TPUDummyInput\"() <{shape = #tf_type.shape<128x1024>}> {_ici_weight_distribution_mlir_bridge_marker = true} : () -> tensor<128x1024xf32>\n+// CHECK: %outputs_4, %control_5 = tf_executor.island wraps \"tf.TPUDummyInput\"() <{shape = #tf_type.shape<1024>}> {_ici_weight_distribution_mlir_bridge_marker = true} : () -> tensor<1024xf32>\n+// CHECK: %outputs_6:5, %control_7 = tf_executor.island wraps \"tf._TPUCompileMlir\"()\n+// CHECK: %outputs_8, %control_9 = tf_executor.island wraps \"tf.Identity\"(%outputs_6#0) {device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<!tf_type.string>) -> tensor<!tf_type.string>\n // CHECK: %control_10 = tf_executor.island wraps \"tf.TPUCompileSucceededAssert\"(%outputs_8) {device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<!tf_type.string>) -> ()\n // CHECK: %outputs_11, %control_12 = tf_executor.island wraps \"tf.Const\"() <{value = dense<0> : tensor<i32>}> {_ici_weight_distribution_mlir_bridge_marker = true} : () -> tensor<i32>\n-// CHECK: %outputs_13, %control_14 = tf_executor.island wraps \"tf.Identity\"(%outputs_0) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<128x1024xf32>) -> tensor<128x1024xf32>\n-// CHECK: %outputs_15, %control_16 = tf_executor.island wraps \"tf.Identity\"(%outputs_2) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<1024xf32>) -> tensor<1024xf32>\n+// CHECK: %outputs_13, %control_14 = tf_executor.island wraps \"tf.Identity\"(%outputs) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<128x1024xf32>) -> tensor<128x1024xf32>\n+// CHECK: %outputs_15, %control_16 = tf_executor.island wraps \"tf.Identity\"(%outputs_0) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<1024xf32>) -> tensor<1024xf32>\n // CHECK: %outputs_17:4, %control_18 = tf_executor.island wraps \"tf.Split\"(%outputs_11, %outputs_13) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:0\", num_split = 4 : i32} : (tensor<i32>, tensor<128x1024xf32>) -> (tensor<32x1024xf32>, tensor<32x1024xf32>, tensor<32x1024xf32>, tensor<32x1024xf32>)\n-// CHECK: %outputs_19, %control_20 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#0, %outputs_15, %outputs#1) {_parallel_execution_ids = \"r0:0,p0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_21, %control_22 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#1, %outputs_15, %outputs#2) {_parallel_execution_ids = \"r0:0,p0:1\", device = \"/job:tpu_host_worker/replica:0/task:0/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_23, %control_24 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#2, %outputs_15, %outputs#3) {_parallel_execution_ids = \"r0:0,p0:2\", device = \"/job:tpu_host_worker/replica:0/task:1/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_25, %control_26 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#3, %outputs_15, %outputs#4) {_parallel_execution_ids = \"r0:0,p0:3\", device = \"/job:tpu_host_worker/replica:0/task:1/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_27, %control_28 = tf_executor.island wraps \"tf.Identity\"(%outputs_4) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"} : (tensor<128x1024xf32>) -> tensor<128x1024xf32>\n-// CHECK: %outputs_29, %control_30 = tf_executor.island wraps \"tf.Identity\"(%outputs_6) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"} : (tensor<1024xf32>) -> tensor<1024xf32>\n+// CHECK: %outputs_19, %control_20 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#0, %outputs_15, %outputs_6#1) {_parallel_execution_ids = \"r0:0,p0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_21, %control_22 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#1, %outputs_15, %outputs_6#2) {_parallel_execution_ids = \"r0:0,p0:1\", device = \"/job:tpu_host_worker/replica:0/task:0/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_23, %control_24 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#2, %outputs_15, %outputs_6#3) {_parallel_execution_ids = \"r0:0,p0:2\", device = \"/job:tpu_host_worker/replica:0/task:1/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_25, %control_26 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#3, %outputs_15, %outputs_6#4) {_parallel_execution_ids = \"r0:0,p0:3\", device = \"/job:tpu_host_worker/replica:0/task:1/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_27, %control_28 = tf_executor.island wraps \"tf.Identity\"(%outputs_2) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"} : (tensor<128x1024xf32>) -> tensor<128x1024xf32>\n+// CHECK: %outputs_29, %control_30 = tf_executor.island wraps \"tf.Identity\"(%outputs_4) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"} : (tensor<1024xf32>) -> tensor<1024xf32>\n // CHECK: %outputs_31:4, %control_32 = tf_executor.island wraps \"tf.Split\"(%outputs_11, %outputs_27) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:1\", num_split = 4 : i32} : (tensor<i32>, tensor<128x1024xf32>) -> (tensor<32x1024xf32>, tensor<32x1024xf32>, tensor<32x1024xf32>, tensor<32x1024xf32>)\n-// CHECK: %outputs_33, %control_34 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#0, %outputs_29, %outputs#1) {_parallel_execution_ids = \"r0:1,p0:0\", device = \"/job:tpu_host_worker/replica:0/task:2/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_35, %control_36 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#1, %outputs_29, %outputs#2) {_parallel_execution_ids = \"r0:1,p0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_37, %control_38 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#2, %outputs_29, %outputs#3) {_parallel_execution_ids = \"r0:1,p0:2\", device = \"/job:tpu_host_worker/replica:0/task:3/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_39, %control_40 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#3, %outputs_29, %outputs#4) {_parallel_execution_ids = \"r0:1,p0:3\", device = \"/job:tpu_host_worker/replica:0/task:3/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_33, %control_34 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#0, %outputs_29, %outputs_6#1) {_parallel_execution_ids = \"r0:1,p0:0\", device = \"/job:tpu_host_worker/replica:0/task:2/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_35, %control_36 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#1, %outputs_29, %outputs_6#2) {_parallel_execution_ids = \"r0:1,p0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_37, %control_38 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#2, %outputs_29, %outputs_6#3) {_parallel_execution_ids = \"r0:1,p0:2\", device = \"/job:tpu_host_worker/replica:0/task:3/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_39, %control_40 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#3, %outputs_29, %outputs_6#4) {_parallel_execution_ids = \"r0:1,p0:3\", device = \"/job:tpu_host_worker/replica:0/task:3/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n // CHECK: %outputs_41, %control_42 = tf_executor.island wraps \"tf.ReadVariableOp\"(%arg2) {device = \"\"} : (tensor<*x!tf_type.resource<tensor<i64>>>) -> tensor<i64>\n // CHECK: %outputs_43, %control_44 = tf_executor.island wraps \"tf.Identity\"(%outputs_41) {device = \"\"} : (tensor<i64>) -> tensor<i64>\n-// CHECK: tf_executor.fetch %outputs_43, %control_1, %control_3, %control_20, %control_22, %control_24, %control_26, %control_34, %control_36, %control_38, %control_40, %control_42 : tensor<i64>, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control\n-\n+// CHECK: tf_executor.fetch %outputs_43, %control, %control_1, %control_20, %control_22, %control_24, %control_26, %control_34, %control_36, %control_38, %control_40, %control_42 : tensor<i64>, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control\n \n module attributes {tf.devices = {\"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\", \"/job:tpu_host_worker/replica:0/task:0/device:TPU:0\", \"/job:tpu_host_worker/replica:0/task:0/device:TPU:1\", \"/job:tpu_host_worker/replica:0/task:0/device:TPU_SYSTEM:0\", \"/job:tpu_host_worker/replica:0/task:1/device:CPU:0\", \"/job:tpu_host_worker/replica:0/task:1/device:TPU:0\", \"/job:tpu_host_worker/replica:0/task:1/device:TPU:1\", \"/job:tpu_host_worker/replica:0/task:1/device:TPU_SYSTEM:0\", \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\", \"/job:tpu_host_worker/replica:0/task:2/device:TPU:0\", \"/job:tpu_host_worker/replica:0/task:2/device:TPU:1\", \"/job:tpu_host_worker/replica:0/task:2/device:TPU_SYSTEM:0\", \"/job:tpu_host_worker/replica:0/task:3/device:CPU:0\", \"/job:tpu_host_worker/replica:0/task:3/device:TPU:0\", \"/job:tpu_host_worker/replica:0/task:3/device:TPU:1\", \"/job:tpu_host_worker/replica:0/task:3/device:TPU_SYSTEM:0\"}, tf.versions = {bad_consumers = [], min_consumer = 0 : i32, producer = 1857 : i32}} {\n   func.func @main(%arg0: tensor<i32> {tf._user_specified_name = \"steps\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg1: tensor<*x!tf_type.resource<tensor<i64>>> {tf._user_specified_name = \"899\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg2: tensor<*x!tf_type.resource<tensor<i64>>> {tf._user_specified_name = \"901\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg3: tensor<*x!tf_type.resource<tensor<128x1024xf32>>> {tf._user_specified_name = \"903\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg4: tensor<*x!tf_type.resource<tensor<1024xf32>>> {tf._user_specified_name = \"905\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg5: tensor<*x!tf_type.resource<tensor<1024x1xf32>>> {tf._user_specified_name = \"907\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg6: tensor<*x!tf_type.resource<tensor<i64>>> {tf._user_specified_name = \"909\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg7: tensor<*x!tf_type.resource<tensor<25001x64xf32>>> {tf._user_specified_name = \"911\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg8: tensor<*x!tf_type.resource<tensor<25001x64xf32>>> {tf._user_specified_name = \"913\", tf.device = \"/job:tpu_host_worker/replica:0/task:1/device:CPU:0\"}, %arg9: tensor<*x!tf_type.resource<tensor<25001x64xf32>>> {tf._user_specified_name = \"915\", tf.device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"}, %arg10: tensor<*x!tf_type.resource<tensor<25001x64xf32>>> {tf._user_specified_name = \"917\", tf.device = \"/job:tpu_host_worker/replica:0/task:3/device:CPU:0\"}, %arg11: tensor<*x!tf_type.resource<tensor<25001x32xf32>>> {tf._user_specified_name = \"919\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg12: tensor<*x!tf_type.resource<tensor<25001x32xf32>>> {tf._user_specified_name = \"921\", tf.device = \"/job:tpu_host_worker/replica:0/task:1/device:CPU:0\"}, %arg13: tensor<*x!tf_type.resource<tensor<25001x32xf32>>> {tf._user_specified_name = \"923\", tf.device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"}, %arg14: tensor<*x!tf_type.resource<tensor<25001x32xf32>>> {tf._user_specified_name = \"925\", tf.device = \"/job:tpu_host_worker/replica:0/task:3/device:CPU:0\"}, %arg15: tensor<*x!tf_type.resource<tensor<6x32xf32>>> {tf._user_specified_name = \"927\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg16: tensor<*x!tf_type.resource<tensor<6x32xf32>>> {tf._user_specified_name = \"929\", tf.device = \"/job:tpu_host_worker/replica:0/task:1/device:CPU:0\"}, %arg17: tensor<*x!tf_type.resource<tensor<6x32xf32>>> {tf._user_specified_name = \"931\", tf.device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"}, %arg18: tensor<*x!tf_type.resource<tensor<6x32xf32>>> {tf._user_specified_name = \"933\", tf.device = \"/job:tpu_host_worker/replica:0/task:3/device:CPU:0\"}, %arg19: tensor<*x!tf_type.resource<tensor<128x1024xf32>>> {tf._user_specified_name = \"935\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg20: tensor<*x!tf_type.resource<tensor<1024xf32>>> {tf._user_specified_name = \"937\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg21: tensor<*x!tf_type.resource<tensor<1024x1xf32>>> {tf._user_specified_name = \"939\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}) -> tensor<*xi64> attributes {allow_soft_placement = false, tf.entry_function = {control_outputs = \"\", inputs = \"steps,unknown,unknown_0,unknown_1,unknown_2,unknown_3,unknown_4,unknown_5,unknown_6,unknown_7,unknown_8,unknown_9,unknown_10,unknown_11,unknown_12,unknown_13,unknown_14,unknown_15,unknown_16,unknown_17,unknown_18,unknown_19\", outputs = \"statefulpartitionedcall_RetVal\"}} {"
        },
        {
            "sha": "266e95e74e8e80ba947ac3669888296d1e1fa65e",
            "filename": "tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/lower_cluster_to_runtime_ops.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops.cc?ref=9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e",
            "patch": "@@ -79,7 +79,6 @@ void AddTPULowerClusterToRuntimeOpsPassPipeline(OpPassManager& pm,\n   pm.addPass(mlir::createSymbolDCEPass());\n   pm.addNestedPass<FuncOp>(\n       mlir::TFDevice::CreateReplicateInvariantOpHoistingPass());\n-  pm.addPass(mlir::TF::CreateOrderForProgramKeyPass());\n   pm.addNestedPass<FuncOp>(mlir::TFDevice::CreateEmbeddingProgramKeyPass());\n   pm.addPass(mlir::TFTPU::CreateTPUMergeVariablesWithExecutePass());\n   pm.addNestedPass<FuncOp>("
        },
        {
            "sha": "0130e7a63c70bc3368e317e07e656bf75f9d43d8",
            "filename": "tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/lower_cluster_to_runtime_ops_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops_test.cc?ref=9f80a14002e6a0a1ec4a2e74cc2b705c1c91257e",
            "patch": "@@ -191,7 +191,7 @@ TEST_F(LowerClusterToRuntimeOpsTest, DumpsPipelinePasses) {\n       *mlir_module_, DeviceType(DEVICE_TPU_XLA_JIT)));\n \n   TF_ASSERT_OK(env_->GetChildren(test_dir_, &files));\n-  EXPECT_THAT(files, ::testing::SizeIs(16));\n+  EXPECT_THAT(files, ::testing::SizeIs(15));\n }\n \n }  // namespace"
        }
    ],
    "stats": {
        "total": 47,
        "additions": 21,
        "deletions": 26
    }
}