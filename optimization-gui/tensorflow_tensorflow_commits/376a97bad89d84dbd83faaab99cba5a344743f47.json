{
    "author": "mkuperst",
    "message": "[XLA] Add an option to control whether the collective pipeliner uniquifies channel IDs.\n\nPiperOrigin-RevId: 839921754",
    "sha": "376a97bad89d84dbd83faaab99cba5a344743f47",
    "files": [
        {
            "sha": "553beccf215b3c64ab61c0eb6a090b96a47683ec",
            "filename": "third_party/xla/xla/service/collective_pipeliner.cc",
            "status": "modified",
            "additions": 38,
            "deletions": 30,
            "changes": 68,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/376a97bad89d84dbd83faaab99cba5a344743f47/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/376a97bad89d84dbd83faaab99cba5a344743f47/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.cc?ref=376a97bad89d84dbd83faaab99cba5a344743f47",
            "patch": "@@ -715,9 +715,11 @@ std::string ToString(const WhileMoveInfo& move_info) {\n       move_info.sliced_idx);\n }\n \n-// Set channel_id of instruction to next available to avoid collisions.\n+// Set channel_id of instruction to next available to avoid collisions, if\n+// necessary.\n void UpdateInstructionChannelId(HloInstruction* cloned_instr,\n-                                int64_t& next_channel_id) {\n+                                int64_t& next_channel_id,\n+                                bool update_collective) {\n   // Avoid updating Send and Recv instructions because pipelined Send and Recv\n   // instructions should keep the same channel-id to indicate that the group of\n   // instructions need to cooperate.\n@@ -737,7 +739,7 @@ void UpdateInstructionChannelId(HloInstruction* cloned_instr,\n           Cast<HloChannelInstruction>(operand)->channel_id());\n       return;\n     }\n-    if (channel_instr->channel_id()) {\n+    if (update_collective && channel_instr->channel_id()) {\n       channel_instr->set_channel_id(next_channel_id++);\n     }\n   }\n@@ -770,7 +772,7 @@ template <typename Comp>\n absl::StatusOr<HloInstruction*> CloneBackwardChain(\n     Comp& target_computation, const WhileMoveInfo& move_info,\n     InstructionMap& clone_map, int64_t loop_iter_idx, int64_t& next_channel_id,\n-    int64_t& next_scheduling_id,\n+    bool update_collective_channel_id, int64_t& next_scheduling_id,\n     absl::flat_hash_map<int64_t, int64_t>& annotation_map,\n     LoopVariantParameterInfo* loop_variant_parameter_info = nullptr,\n     CollectivePipeliner::HloPostprocessor postprocess_pipelined_ops = {}) {\n@@ -788,7 +790,8 @@ absl::StatusOr<HloInstruction*> CloneBackwardChain(\n     HloInstruction* cloned = target_computation.AddInstruction(\n         chain_op->CloneWithNewOperands(chain_op->shape(), new_operands));\n     TF_RETURN_IF_ERROR(UpdateControlDependencies(chain_op, cloned, clone_map));\n-    UpdateInstructionChannelId(cloned, next_channel_id);\n+    UpdateInstructionChannelId(cloned, next_channel_id,\n+                               update_collective_channel_id);\n     if (next_scheduling_id != -1) {\n       RemoveSchedulingAnnotation(cloned);\n     }\n@@ -1792,7 +1795,7 @@ absl::Status TransformLoopForward(\n     int64_t level_to_operate_on, bool pipeline_use_tree,\n     bool process_different_sized_ops, HloPredicate should_process,\n     HloPredicate acceptable_formatting, HloPredicate reuse_output_buffer,\n-    int64_t& next_channel_id,\n+    int64_t& next_channel_id, bool update_collective_channel_id,\n     CollectivePipeliner::HloPostprocessor post_processing_fn) {\n   // Defining some maps/sets to keep track of instructions duplicated.\n   InstructionMap while_body_to_peeled;\n@@ -1909,7 +1912,8 @@ absl::Status TransformLoopForward(\n     }\n     TF_RETURN_IF_ERROR(\n         UpdateControlDependencies(instr, cloned_instr, while_body_to_peeled));\n-    UpdateInstructionChannelId(cloned_instr, next_channel_id);\n+    UpdateInstructionChannelId(cloned_instr, next_channel_id,\n+                               update_collective_channel_id);\n     if (HasSchedulingAnnotation(cloned_instr) &&\n         GetSchedulingAnnotation(cloned_instr)\n             ->value()\n@@ -2050,16 +2054,17 @@ absl::Status TransformLoopForward(\n         base->shape(), base, to_insert, indices));\n   };\n   auto process_slice =\n-      [&next_channel_id, &post_processing_fn, insert_non_alias_custom_call,\n-       level_to_operate_on](\n+      [&next_channel_id, &update_collective_channel_id, &post_processing_fn,\n+       insert_non_alias_custom_call, level_to_operate_on](\n           HloInstruction* stacked_data,\n           const InstructionMap& pipelined_values_map,\n           const WhileMoveInfo& move_info, InstructionMap* formatting_cloned_map,\n           bool update_annotations) -> absl::StatusOr<HloInstruction*> {\n     HloInstruction* processed = stacked_data->parent()->AddInstruction(\n         move_info.collectives_to_move.front()->CloneWithNewOperands(\n             move_info.collectives_to_move.front()->shape(), {stacked_data}));\n-    UpdateInstructionChannelId(processed, next_channel_id);\n+    UpdateInstructionChannelId(processed, next_channel_id,\n+                               update_collective_channel_id);\n     if (update_annotations) {\n       RemoveSchedulingAnnotation(processed);\n     }\n@@ -2294,7 +2299,7 @@ absl::Status TransformFormattingOp(\n     HloInstruction* formatting_op, const WhileMoveInfo& to_move,\n     HloComputation* loop_computation, InstructionMap& pipelined_map,\n     const absl::flat_hash_set<HloInstruction*>& to_add_batch_set,\n-    int64_t& next_channel_id) {\n+    int64_t& next_channel_id, bool update_collective_channel_id) {\n   auto collect_operands = [&pipelined_map, &to_add_batch_set, loop_computation,\n                            &to_move](HloInstruction* instr) {\n     std::vector<HloInstruction*> operands;\n@@ -2342,7 +2347,8 @@ absl::Status TransformFormattingOp(\n     HloInstruction* cloned_not_to_batch =\n         loop_computation->AddInstruction(formatting_op->CloneWithNewOperands(\n             formatting_op->shape(), collect_operands(formatting_op)));\n-    UpdateInstructionChannelId(cloned_not_to_batch, next_channel_id);\n+    UpdateInstructionChannelId(cloned_not_to_batch, next_channel_id,\n+                               update_collective_channel_id);\n     pipelined_map[formatting_op] = cloned_not_to_batch;\n     return absl::OkStatus();\n   }\n@@ -2519,13 +2525,11 @@ absl::Status TransformFormattingOp(\n // }\n // xg_all = all-reduce(x_all)\n // yg_all = all-reduce(y_all)\n-absl::Status TransformLoopForwardSink(const WhileLoopAnalysis& loop_analysis,\n-                                      bool insert_non_alias_custom_call,\n-                                      int64_t level_to_operate_on,\n-                                      bool pipeline_use_tree,\n-                                      bool process_different_sized_ops,\n-                                      HloPredicate should_process,\n-                                      int64_t& next_channel_id) {\n+absl::Status TransformLoopForwardSink(\n+    const WhileLoopAnalysis& loop_analysis, bool insert_non_alias_custom_call,\n+    int64_t level_to_operate_on, bool pipeline_use_tree,\n+    bool process_different_sized_ops, HloPredicate should_process,\n+    int64_t& next_channel_id, bool update_collective_channel_id) {\n   // Defining some maps/sets to keep track of instructions duplicated.\n   absl::flat_hash_map<HloInstruction*, int64_t> is_output_instruction;\n   absl::flat_hash_map<const HloInstruction*, bool> invariant_cache;\n@@ -2826,7 +2830,8 @@ absl::Status TransformLoopForwardSink(const WhileLoopAnalysis& loop_analysis,\n           loop_computation->AddInstruction(collective->CloneWithNewOperands(\n               ComputeFullOutputShape(to_move, collective->shape()),\n               {pipelined_map[collective->mutable_operand(0)]}));\n-      UpdateInstructionChannelId(pipelined_instr_cloned, next_channel_id);\n+      UpdateInstructionChannelId(pipelined_instr_cloned, next_channel_id,\n+                                 update_collective_channel_id);\n       pipelined_map[collective] = pipelined_instr_cloned;\n     }\n     absl::flat_hash_set<HloInstruction*> to_add_batch_set;\n@@ -2843,7 +2848,7 @@ absl::Status TransformLoopForwardSink(const WhileLoopAnalysis& loop_analysis,\n     for (HloInstruction* formatting_op : to_move.formatting_ops) {\n       TF_RETURN_IF_ERROR(TransformFormattingOp(\n           formatting_op, to_move, loop_computation, pipelined_map,\n-          to_add_batch_set, next_channel_id));\n+          to_add_batch_set, next_channel_id, update_collective_channel_id));\n     }\n     for (int64_t i = 0; i < to_move.output_indices.size(); ++i) {\n       HloDynamicUpdateSliceInstruction* d_update =\n@@ -2908,7 +2913,7 @@ static absl::Status TransformLoopBackward(\n     CollectivePipeliner::HloPostprocessor postprocess_peeled,\n     CollectivePipeliner::HloPostprocessor postprocess_rotated,\n     CollectivePipeliner::HloPostprocessor postprocess_peeled_trailing_op,\n-    int64_t& next_channel_id,\n+    int64_t& next_channel_id, bool update_collective_channel_id,\n     CollectivePipeliner::HloPostprocessor post_processing_fn) {\n   // Defining some maps/sets to keep track of instructions duplicated.\n   absl::flat_hash_map<HloInstruction*, HloInstruction*> while_body_to_peeled;\n@@ -3010,7 +3015,8 @@ static absl::Status TransformLoopBackward(\n         CloneBackwardChain(\n             *while_loop->parent(), loop_analysis.GetMoveInfos()[i],\n             chain_clone_map, *loop_analysis.GetLoopIterationIdx(),\n-            next_channel_id, next_scheduling_id, annotation_map,\n+            next_channel_id, update_collective_channel_id, next_scheduling_id,\n+            annotation_map,\n             /*loop_variant_parameter_info=*/nullptr, post_processing_fn));\n \n     if (post_processing_fn) {\n@@ -3071,8 +3077,8 @@ static absl::Status TransformLoopBackward(\n               body_builder, loop_analysis.GetMoveInfos()[it->second],\n               collective_to_move_clone_map,\n               *loop_analysis.GetLoopIterationIdx(), next_channel_id,\n-              next_scheduling_id, annotation_map, &loop_variant_parameter_info,\n-              post_processing_fn));\n+              update_collective_channel_id, next_scheduling_id, annotation_map,\n+              &loop_variant_parameter_info, post_processing_fn));\n \n       if (post_processing_fn) {\n         TF_RETURN_IF_ERROR(\n@@ -3097,7 +3103,8 @@ static absl::Status TransformLoopBackward(\n       }\n       TF_RETURN_IF_ERROR(UpdateControlDependencies(instr, cloned_instr,\n                                                    while_body_replacement_map));\n-      UpdateInstructionChannelId(cloned_instr, next_channel_id);\n+      UpdateInstructionChannelId(cloned_instr, next_channel_id,\n+                                 update_collective_channel_id);\n     }\n     if (it != collective_to_move_map.end()) {\n       const int64_t tuple_idx =\n@@ -3233,7 +3240,8 @@ static absl::Status TransformLoopBackward(\n \n     TF_RETURN_IF_ERROR(UpdateControlDependencies(instr, cloned_instr,\n                                                  while_body_replacement_map));\n-    UpdateInstructionChannelId(cloned_instr, next_channel_id);\n+    UpdateInstructionChannelId(cloned_instr, next_channel_id,\n+                               update_collective_channel_id);\n     TF_RETURN_IF_ERROR(UpdateInstructionSchedulingAnnotation(\n         cloned_instr, next_scheduling_id, annotation_map));\n     // TODO(b/398891001): Remove this once we have eliminated the need for\n@@ -3334,13 +3342,13 @@ absl::StatusOr<bool> CollectivePipeliner::RunPipeliner(\n           config_.pipeline_use_tree, config_.process_different_sized_ops,\n           config_.should_process, config_.acceptable_formatting,\n           config_.reuse_pipelined_op_buffer, next_channel_id,\n-          config_.postprocess_pipelined_ops));\n+          config_.unique_channel_id, config_.postprocess_pipelined_ops));\n     } else if (config_.pipelining_direction ==\n                collective_pipeliner_utils::PipeliningDirection::kForwardSink) {\n       TF_RETURN_IF_ERROR(TransformLoopForwardSink(\n           *loop_analysis, !config_.last_run, config_.level_to_operate_on,\n           config_.pipeline_use_tree, config_.process_different_sized_ops,\n-          config_.should_process, next_channel_id));\n+          config_.should_process, next_channel_id, config_.unique_channel_id));\n     } else {\n       CHECK_EQ(config_.pipelining_direction,\n                collective_pipeliner_utils::PipeliningDirection::kBackward);\n@@ -3350,7 +3358,7 @@ absl::StatusOr<bool> CollectivePipeliner::RunPipeliner(\n           config_.postprocess_backward_peeled_op,\n           config_.postprocess_backward_rotated_op,\n           config_.postprocess_backward_peeled_trailing_op, next_channel_id,\n-          config_.postprocess_pipelined_ops));\n+          config_.unique_channel_id, config_.postprocess_pipelined_ops));\n     }\n     ++transformed_loops;\n     changed = true;"
        },
        {
            "sha": "7988daa085caaf1c247eb8dd64d674a531a75f09",
            "filename": "third_party/xla/xla/service/collective_pipeliner.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/376a97bad89d84dbd83faaab99cba5a344743f47/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/376a97bad89d84dbd83faaab99cba5a344743f47/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.h?ref=376a97bad89d84dbd83faaab99cba5a344743f47",
            "patch": "@@ -110,6 +110,8 @@ class CollectivePipeliner : public HloModulePass {\n     HloPostprocessor postprocess_pipelined_ops;\n     int64_t collective_size_threshold_to_delay_sinking = INT64_MAX;\n     bool delay_sinking_large_collectives = true;\n+    // When cloning collectives, use a unique channel id for each clone.\n+    bool unique_channel_id = true;\n   };\n   static const char* const kInsertedByPreviousStep;\n   static const char* const kSunkByPreviousStep;"
        },
        {
            "sha": "24e6ba9be4aa1bb6714dfceb4e11562206db3e2a",
            "filename": "third_party/xla/xla/service/collective_pipeliner_test.cc",
            "status": "modified",
            "additions": 168,
            "deletions": 2,
            "changes": 170,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/376a97bad89d84dbd83faaab99cba5a344743f47/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/376a97bad89d84dbd83faaab99cba5a344743f47/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner_test.cc?ref=376a97bad89d84dbd83faaab99cba5a344743f47",
            "patch": "@@ -106,7 +106,8 @@ absl::StatusOr<bool> RunOptimizer(\n     CollectivePipeliner::HloPostprocessor postprocess_backward_peeled_trailing =\n         {},\n     bool should_add_loop_invariant_op_in_chain = false,\n-    int64_t collective_size_threshold_to_delay_sinking = INT64_MAX) {\n+    int64_t collective_size_threshold_to_delay_sinking = INT64_MAX,\n+    bool unique_channel_id = true) {\n   CollectivePipeliner::Config config = {\n       /*level_to_operate_on=*/level_to_operate_on,\n       /*max_pipelining_per_loop=*/INT64_MAX,\n@@ -123,7 +124,8 @@ absl::StatusOr<bool> RunOptimizer(\n       postprocess_backward_rotated, postprocess_backward_peeled_trailing,\n       should_add_loop_invariant_op_in_chain,\n       /*postprocess_pipelined_ops=*/{},\n-      collective_size_threshold_to_delay_sinking};\n+      collective_size_threshold_to_delay_sinking,\n+      /*delay_sinking_large_collectives=*/true, unique_channel_id};\n   HloPassPipeline pass(\"optimizer\");\n   pass.AddPass<HloVerifier>(/*layout_sensitive=*/false,\n                             /*allow_mixed_precision=*/false);\n@@ -544,6 +546,90 @@ ENTRY entry {\n   EXPECT_EQ(channel_id(unrolled_send), channel_id(unrolled_send_done));\n }\n \n+TEST_F(CollectivePipelinerTest,\n+       MatchingSendRecvChannelIdForHostTransfersNoUpdate) {\n+  constexpr absl::string_view hlo_string = R\"(\n+HloModule module\n+\n+add {\n+  lhs = bf16[] parameter(0)\n+  rhs = bf16[] parameter(1)\n+  ROOT add = bf16[] add(lhs, rhs)\n+}\n+\n+while_cond {\n+  param = (s32[], bf16[3,8,128], bf16[3,8,128]) parameter(0)\n+  gte = s32[] get-tuple-element(param), index=0\n+  constant.1 = s32[] constant(3)\n+  ROOT cmp = pred[] compare(gte, constant.1), direction=LT\n+}\n+\n+while_body {\n+  param = (s32[], bf16[3,8,128], bf16[3,8,128]) parameter(0)\n+  get-tuple-element.394 = s32[] get-tuple-element(param), index=0\n+  get-tuple-element.395 = bf16[3,8,128] get-tuple-element(param), index=1\n+  get-tuple-element.5 = bf16[3,8,128] get-tuple-element(param), index=2\n+  constant.2557 = s32[] constant(1)\n+  add.230 = s32[] add(get-tuple-element.394, constant.2557)\n+  constant.2559 = s32[] constant(3)\n+  subtract.139 = s32[] subtract(constant.2559, get-tuple-element.394)\n+  constant.2560 = s32[] constant(-1)\n+  add.231 = s32[] add(subtract.139, constant.2560)\n+  constant.2561 = s32[] constant(0)\n+  compare.747 = pred[] compare(add.231, constant.2561), direction=LT\n+  constant.2562 = s32[] constant(2)\n+  add.232 = s32[] add(subtract.139, constant.2562)\n+  after-all = after-all()\n+  send.88 = (s32[], u32[], token[]) send(\n+      add.232, after-all), channel_id=2, is_host_transfer=true\n+  send-done.88 = token[] send-done(send.88), channel_id=2, is_host_transfer=true\n+  select.1348 = s32[] select(compare.747, add.232, add.231)\n+  dynamic-slice.99 = bf16[1,8,128] dynamic-slice(get-tuple-element.5, select.1348, constant.2561, constant.2561), dynamic_slice_sizes={1,8,128}\n+  mul = bf16[1,8,128] multiply(dynamic-slice.99, dynamic-slice.99)\n+  ar.1 = bf16[1,8,128] all-reduce(mul), replica_groups={}, to_apply=add, channel_id=1\n+  dynamic-update-slice.35 = bf16[3,8,128] dynamic-update-slice(get-tuple-element.395, ar.1, select.1348, constant.2561, constant.2561)\n+  ROOT tuple = (s32[], bf16[3,8,128], bf16[3,8,128]) tuple(add.230, dynamic-update-slice.35, get-tuple-element.5)\n+}\n+\n+ENTRY entry {\n+  c0 = s32[] constant(0)\n+  p0 = bf16[3,8,128] parameter(0)\n+  tuple = (s32[], bf16[3,8,128], bf16[3,8,128]) tuple(c0, p0, p0)\n+  while = (s32[], bf16[3,8,128], bf16[3,8,128]) while(tuple), condition=while_cond, body=while_body\n+  ROOT gte1 = bf16[3,8,128] get-tuple-element(while), index=1\n+}\n+)\";\n+  auto module = ParseAndReturnUnverifiedModule(hlo_string, config_).value();\n+  EXPECT_TRUE(\n+      RunOptimizer(\n+          module.get(), /*last_run=*/true,\n+          /*level_to_operate_on=*/0,\n+          /*pipeline_use_tree=*/false,\n+          /*process_different_sized_ops=*/true,\n+          /*direction=*/\n+          collective_pipeliner_utils::PipeliningDirection::kForward,\n+          /*should_process=*/HloPredicateIsOp<HloOpcode::kAllReduce>,\n+          /*acceptable_formatting=*/HloPredicateTrue,\n+          /*reuse_pipelined_op_buffer=*/HloPredicateTrue,\n+          /*should_allow_loop_variant_parameter_in_chain=*/HloPredicateFalse,\n+          /*postprocess_backward_peeled=*/{},\n+          /*postprocess_backward_rotated=*/{},\n+          /*postprocess_backward_peeled_trailing=*/{},\n+          /*should_add_loop_invariant_op_in_chain=*/false,\n+          /*collective_size_threshold_to_delay_sinking=*/INT64_MAX,\n+          /*unique_channel_id=*/false)\n+          .value());\n+  XLA_VLOG_LINES(1, module->ToString());\n+  auto* entry_comp = module->entry_computation();\n+  auto* unrolled_send_done = entry_comp->GetInstructionWithName(\"send-done.0\");\n+  ASSERT_THAT(unrolled_send_done, ::testing::NotNull());\n+  auto* unrolled_send = unrolled_send_done->operand(0);\n+  auto channel_id = [](const HloInstruction* instr) {\n+    return DynCast<HloChannelInstruction>(instr)->channel_id();\n+  };\n+  EXPECT_EQ(channel_id(unrolled_send), channel_id(unrolled_send_done));\n+}\n+\n TEST_F(CollectivePipelinerTest, TransformIncrementIndexByOneNoReuse) {\n   constexpr absl::string_view hlo_string = R\"(\n HloModule module\n@@ -608,6 +694,86 @@ ENTRY entry {\n   EXPECT_EQ(while_instr->shape().tuple_shapes().size(), 5);\n }\n \n+TEST_F(CollectivePipelinerTest,\n+       TransformIncrementIndexByOneNoReuseNoChannelIdUpdate) {\n+  constexpr absl::string_view hlo_string = R\"(\n+HloModule module\n+\n+add {\n+  lhs = bf16[] parameter(0)\n+  rhs = bf16[] parameter(1)\n+  ROOT add = bf16[] add(lhs, rhs)\n+}\n+\n+while_cond {\n+  param = (s32[], bf16[3,8,128], bf16[3,8,128]) parameter(0)\n+  gte = s32[] get-tuple-element(param), index=0\n+  constant.1 = s32[] constant(3)\n+  ROOT cmp = pred[] compare(gte, constant.1), direction=LT\n+}\n+\n+while_body {\n+  param = (s32[], bf16[3,8,128], bf16[3,8,128]) parameter(0)\n+  get-tuple-element.394 = s32[] get-tuple-element(param), index=0\n+  get-tuple-element.395 = bf16[3,8,128] get-tuple-element(param), index=1\n+  get-tuple-element.5 = bf16[3,8,128] get-tuple-element(param), index=2\n+  constant.2557 = s32[] constant(1)\n+  add.230 = s32[] add(get-tuple-element.394, constant.2557)\n+  constant.2559 = s32[] constant(3)\n+  subtract.139 = s32[] subtract(constant.2559, get-tuple-element.394)\n+  constant.2560 = s32[] constant(-1)\n+  add.231 = s32[] add(subtract.139, constant.2560)\n+  constant.2561 = s32[] constant(0)\n+  compare.747 = pred[] compare(add.231, constant.2561), direction=LT\n+  constant.2562 = s32[] constant(2)\n+  add.232 = s32[] add(subtract.139, constant.2562)\n+  select.1348 = s32[] select(compare.747, add.232, add.231)\n+  dynamic-slice.99 = bf16[1,8,128] dynamic-slice(get-tuple-element.5, select.1348, constant.2561, constant.2561), dynamic_slice_sizes={1,8,128}\n+  mul = bf16[1,8,128] multiply(dynamic-slice.99, dynamic-slice.99)\n+  ar.1 = bf16[1,8,128] all-reduce(mul), replica_groups={}, to_apply=add, channel_id=1\n+  dynamic-update-slice.35 = bf16[3,8,128] dynamic-update-slice(get-tuple-element.395, ar.1, select.1348, constant.2561, constant.2561)\n+  ROOT tuple = (s32[], bf16[3,8,128], bf16[3,8,128]) tuple(add.230, dynamic-update-slice.35, get-tuple-element.5)\n+}\n+\n+ENTRY entry {\n+  c0 = s32[] constant(0)\n+  p0 = bf16[3,8,128] parameter(0)\n+  tuple = (s32[], bf16[3,8,128], bf16[3,8,128]) tuple(c0, p0, p0)\n+  while = (s32[], bf16[3,8,128], bf16[3,8,128]) while(tuple), condition=while_cond, body=while_body\n+  ROOT gte1 = bf16[3,8,128] get-tuple-element(while), index=1\n+}\n+)\";\n+  auto module = ParseAndReturnUnverifiedModule(hlo_string, config_).value();\n+  EXPECT_TRUE(\n+      RunOptimizer(\n+          module.get(), /*last_run=*/true, 0, false, true,\n+          collective_pipeliner_utils::PipeliningDirection::kForward,\n+          HloPredicateIsOp<HloOpcode::kAllReduce>,\n+          /*acceptable_formatting=*/\n+          [](const HloInstruction* i) { return true; },\n+          /*reuse_pipelined_op_buffer=*/\n+          [](const HloInstruction* i) { return false; },\n+          /*should_allow_loop_variant_parameter_in_chain=*/HloPredicateFalse,\n+          /*postprocess_backward_peeled=*/{},\n+          /*postprocess_backward_rotated=*/{},\n+          /*postprocess_backward_peeled_trailing=*/{},\n+          /*should_add_loop_invariant_op_in_chain=*/false,\n+          /*collective_size_threshold_to_delay_sinking=*/INT64_MAX,\n+          /*unique_channel_id=*/false)\n+          .value());\n+  XLA_VLOG_LINES(1, module->ToString());\n+  HloInstruction* while_instr =\n+      FindInstruction(module.get(), HloOpcode::kWhile);\n+  EXPECT_EQ(while_instr->shape().tuple_shapes().size(), 5);\n+  auto all_reduce_instrs =\n+      FindInstructions(module.get(), HloOpcode::kAllReduce);\n+  EXPECT_EQ(all_reduce_instrs.size(), 3);\n+  for (auto* all_reduce : all_reduce_instrs) {\n+    auto channel_id = DynCast<HloChannelInstruction>(all_reduce)->channel_id();\n+    EXPECT_EQ(channel_id, 1);\n+  }\n+}\n+\n TEST_F(CollectivePipelinerTest, TransformIncrementIndexByOneNotFirstIdx) {\n   constexpr absl::string_view hlo_string = R\"(\n HloModule module"
        }
    ],
    "stats": {
        "total": 240,
        "additions": 208,
        "deletions": 32
    }
}