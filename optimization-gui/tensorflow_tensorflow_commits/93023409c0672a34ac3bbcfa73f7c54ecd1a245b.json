{
    "author": "ezhulenev",
    "message": "[xla:ffi] Group internal CPU and GPU APIs for readability\n\nMove APIs around to put related APIs next to each other in preparation for extending GPU-specific internal APIs.\n\nPiperOrigin-RevId: 836510874",
    "sha": "93023409c0672a34ac3bbcfa73f7c54ecd1a245b",
    "files": [
        {
            "sha": "d2ce0cdd5888a214c2987b7c4598b48da8ba962f",
            "filename": "third_party/xla/xla/ffi/api/c_api_internal.h",
            "status": "modified",
            "additions": 35,
            "deletions": 18,
            "changes": 53,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/93023409c0672a34ac3bbcfa73f7c54ecd1a245b/third_party%2Fxla%2Fxla%2Fffi%2Fapi%2Fc_api_internal.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/93023409c0672a34ac3bbcfa73f7c54ecd1a245b/third_party%2Fxla%2Fxla%2Fffi%2Fapi%2Fc_api_internal.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fffi%2Fapi%2Fc_api_internal.h?ref=93023409c0672a34ac3bbcfa73f7c54ecd1a245b",
            "patch": "@@ -32,11 +32,15 @@ limitations under the License.\n extern \"C\" {\n #endif\n \n-// Because this is an internal XLA FFI API we use a slightly relaxed C API\n-// style and do not track the struct size, as we expect this API to be used\n-// only in statically linked binaries, and we do not need any backward or\n+// IMPORTANT: Because this is an internal XLA FFI API we use a slightly relaxed\n+// C API style and do not track the struct size, as we expect this API to be\n+// used only in statically linked binaries, and we do not need any backward or\n // forward compatibility.\n \n+//===----------------------------------------------------------------------===//\n+// Generic XLA internal APIs available on all XLA backends.\n+//===----------------------------------------------------------------------===//\n+\n // Forwards `absl::Status` object pointed to by `status` to XLA FFI error\n // (status left in moved-from state). Pointer ownership stays with the\n // caller.\n@@ -46,12 +50,6 @@ typedef XLA_FFI_Error* XLA_FFI_INTERNAL_Error_Forward(void* status);\n // future. Async value ownership transferred to the XLA FFI future.\n typedef XLA_FFI_Future* XLA_FFI_INTERNAL_Future_Forward(void* async_value);\n \n-// Returns a pointer to main compute stream (`se::Stream` pointer). In\n-// contrast to public C API which returns a pointer to underlying platform\n-// stream (i.e. cudaStream_t for CUDA backend), this API returns a pointer to\n-// StreamExecutor stream which is unsafe to use across dynamic library boundary.\n-typedef void* XLA_FFI_INTERNAL_Stream_Get(XLA_FFI_ExecutionContext* ctx);\n-\n // Returns the device ordinal of the device associated with the execution\n // context.\n typedef int32_t XLA_FFI_INTERNAL_DeviceOrdinal_Get(\n@@ -60,12 +58,6 @@ typedef int32_t XLA_FFI_INTERNAL_DeviceOrdinal_Get(\n // Returns the run id associated with the execution context.\n typedef int64_t XLA_FFI_INTERNAL_RunId_Get(XLA_FFI_ExecutionContext* ctx);\n \n-// Returns a pointer to device memory allocator (`se::DeviceMemoryAllocator`\n-// pointer) which allows to allocate memory inside a custom call from the same\n-// allocator as XLA (i.e. it allows to construct scratch memory allocator).\n-typedef void* XLA_FFI_INTERNAL_DeviceMemoryAllocator_Get(\n-    XLA_FFI_ExecutionContext* ctx);\n-\n // Returns a pointer to `xla::HloComputation` if FFI handler has a called\n // computation attached to it.\n typedef void* XLA_FFI_INTERNAL_CalledComputation_Get(\n@@ -81,29 +73,54 @@ typedef void* XLA_FFI_INTERNAL_ExecutionContext_Get(\n typedef void* XLA_FFI_INTERNAL_ExecutionState_Get(\n     XLA_FFI_ExecutionContext* ctx);\n \n+//===----------------------------------------------------------------------===//\n+// XLA:CPU specific internal APIs.\n+//===----------------------------------------------------------------------===//\n+\n // Returns a pointer to the `Eigen::ThreadPoolDevice` passed via run options,\n // which allows FFI handlers to execute tasks in the same thread pool as XLA.\n typedef void* XLA_FFI_INTERNAL_IntraOpThreadPool_Get(\n     XLA_FFI_ExecutionContext* ctx);\n \n+//===----------------------------------------------------------------------===//\n+// XLA:GPU specific internal APIs.\n+//===----------------------------------------------------------------------===//\n+\n+// Returns a pointer to main compute stream (`se::Stream` pointer). In\n+// contrast to public C API which returns a pointer to underlying platform\n+// stream (i.e. cudaStream_t for CUDA backend), this API returns a pointer to\n+// StreamExecutor stream which is unsafe to use across dynamic library boundary.\n+typedef void* XLA_FFI_INTERNAL_Stream_Get(XLA_FFI_ExecutionContext* ctx);\n+\n+// Returns a pointer to device memory allocator (`se::DeviceMemoryAllocator`\n+// pointer) which allows to allocate memory inside a custom call from the same\n+// allocator as XLA (i.e. it allows to construct scratch memory allocator).\n+typedef void* XLA_FFI_INTERNAL_DeviceMemoryAllocator_Get(\n+    XLA_FFI_ExecutionContext* ctx);\n+\n //===----------------------------------------------------------------------===//\n // API access\n //===----------------------------------------------------------------------===//\n \n #define _XLA_FFI_INTERNAL_API_STRUCT_FIELD(fn_type) fn_type* fn_type\n \n struct XLA_FFI_InternalApi {\n+  // Generic XLA APIs available on all XLA backends.\n   _XLA_FFI_INTERNAL_API_STRUCT_FIELD(XLA_FFI_INTERNAL_Error_Forward);\n   _XLA_FFI_INTERNAL_API_STRUCT_FIELD(XLA_FFI_INTERNAL_Future_Forward);\n-  _XLA_FFI_INTERNAL_API_STRUCT_FIELD(XLA_FFI_INTERNAL_Stream_Get);\n   _XLA_FFI_INTERNAL_API_STRUCT_FIELD(XLA_FFI_INTERNAL_DeviceOrdinal_Get);\n   _XLA_FFI_INTERNAL_API_STRUCT_FIELD(XLA_FFI_INTERNAL_RunId_Get);\n-  _XLA_FFI_INTERNAL_API_STRUCT_FIELD(\n-      XLA_FFI_INTERNAL_DeviceMemoryAllocator_Get);\n   _XLA_FFI_INTERNAL_API_STRUCT_FIELD(XLA_FFI_INTERNAL_CalledComputation_Get);\n   _XLA_FFI_INTERNAL_API_STRUCT_FIELD(XLA_FFI_INTERNAL_ExecutionContext_Get);\n   _XLA_FFI_INTERNAL_API_STRUCT_FIELD(XLA_FFI_INTERNAL_ExecutionState_Get);\n+\n+  // XLA:CPU specific APIs.\n   _XLA_FFI_INTERNAL_API_STRUCT_FIELD(XLA_FFI_INTERNAL_IntraOpThreadPool_Get);\n+\n+  // XLA:GPU specific APIs.\n+  _XLA_FFI_INTERNAL_API_STRUCT_FIELD(XLA_FFI_INTERNAL_Stream_Get);\n+  _XLA_FFI_INTERNAL_API_STRUCT_FIELD(\n+      XLA_FFI_INTERNAL_DeviceMemoryAllocator_Get);\n };\n \n #undef _XLA_FFI_INTERNAL_API_STRUCT_FIELD"
        },
        {
            "sha": "f1e08097fec7668c7aa6f0c0b159860706954a23",
            "filename": "third_party/xla/xla/ffi/ffi_api.cc",
            "status": "modified",
            "additions": 44,
            "deletions": 29,
            "changes": 73,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/93023409c0672a34ac3bbcfa73f7c54ecd1a245b/third_party%2Fxla%2Fxla%2Fffi%2Fffi_api.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/93023409c0672a34ac3bbcfa73f7c54ecd1a245b/third_party%2Fxla%2Fxla%2Fffi%2Fffi_api.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fffi%2Fffi_api.cc?ref=93023409c0672a34ac3bbcfa73f7c54ecd1a245b",
            "patch": "@@ -889,7 +889,7 @@ static XLA_FFI_Error* XLA_FFI_ThreadPool_NumThreads(\n }\n \n //===----------------------------------------------------------------------===//\n-// XLA FFI Internal Api Implementation\n+// Generic XLA internal APIs available on all XLA backends.\n //===----------------------------------------------------------------------===//\n \n static XLA_FFI_Error* XLA_FFI_INTERNAL_Error_Forward(void* status) {\n@@ -908,16 +908,6 @@ static XLA_FFI_Future* XLA_FFI_INTERNAL_Future_Forward(void* async_value) {\n       tsl::AsyncValueRef<tsl::Chain>(tsl::TakeRef(tsl_async_value))};\n }\n \n-static void* XLA_FFI_INTERNAL_Stream_Get(XLA_FFI_ExecutionContext* ctx) {\n-  if (auto* gpu = std::get_if<XLA_FFI_ExecutionContext::GpuContext>(\n-          &ctx->backend_context)) {\n-    return gpu->stream;\n-  }\n-\n-  return new XLA_FFI_Error{\n-      InvalidArgument(\"XLA FFI GPU context is not available\")};\n-}\n-\n static int32_t XLA_FFI_INTERNAL_DeviceOrdinal_Get(\n     XLA_FFI_ExecutionContext* ctx) {\n   return ctx->device_ordinal;\n@@ -927,59 +917,84 @@ static int64_t XLA_FFI_INTERNAL_RunId_Get(XLA_FFI_ExecutionContext* ctx) {\n   return ctx->run_id.ToInt();\n }\n \n-static void* XLA_FFI_INTERNAL_DeviceMemoryAllocator_Get(\n-    XLA_FFI_ExecutionContext* ctx) {\n-  if (auto* gpu = std::get_if<XLA_FFI_ExecutionContext::GpuContext>(\n-          &ctx->backend_context)) {\n-    return gpu->allocator;\n-  }\n-\n-  return new XLA_FFI_Error{\n-      InvalidArgument(\"XLA FFI GPU context is not available\")};\n-}\n-\n static void* XLA_FFI_INTERNAL_CalledComputation_Get(\n     XLA_FFI_ExecutionContext* ctx) {\n-  return const_cast<HloComputation*>(ctx->called_computation);\n+  return const_cast<HloComputation*>(ctx->called_computation);  // NOLINT\n }\n \n static void* XLA_FFI_INTERNAL_ExecutionContext_Get(\n     XLA_FFI_ExecutionContext* ctx) {\n-  return const_cast<ffi::ExecutionContext*>(ctx->execution_context);\n+  return const_cast<ffi::ExecutionContext*>(ctx->execution_context);  // NOLINT\n }\n \n static void* XLA_FFI_INTERNAL_ExecutionState_Get(\n     XLA_FFI_ExecutionContext* ctx) {\n-  return const_cast<ffi::ExecutionState*>(ctx->execution_state);\n+  return const_cast<ffi::ExecutionState*>(ctx->execution_state);  // NOLINT\n }\n \n-void* XLA_FFI_INTERNAL_IntraOpThreadPool_Get(XLA_FFI_ExecutionContext* ctx) {\n+//===----------------------------------------------------------------------===//\n+// XLA:CPU specific internal APIs.\n+//===----------------------------------------------------------------------===//\n+\n+static void* XLA_FFI_INTERNAL_IntraOpThreadPool_Get(\n+    XLA_FFI_ExecutionContext* ctx) {\n   if (auto* cpu = std::get_if<XLA_FFI_ExecutionContext::CpuContext>(\n           &ctx->backend_context)) {\n-    return const_cast<Eigen::ThreadPoolDevice*>(cpu->intra_op_thread_pool);\n+    return const_cast<Eigen::ThreadPoolDevice*>(  // NOLINT\n+        cpu->intra_op_thread_pool);\n   }\n \n   return new XLA_FFI_Error{\n       InvalidArgument(\"XLA FFI CPU context is not available\")};\n }\n \n+//===----------------------------------------------------------------------===//\n+// XLA:GPU specific internal APIs.\n+//===----------------------------------------------------------------------===//\n+\n+static void* XLA_FFI_INTERNAL_Stream_Get(XLA_FFI_ExecutionContext* ctx) {\n+  if (auto* gpu = std::get_if<XLA_FFI_ExecutionContext::GpuContext>(\n+          &ctx->backend_context)) {\n+    return gpu->stream;\n+  }\n+\n+  return new XLA_FFI_Error{\n+      InvalidArgument(\"XLA FFI GPU context is not available\")};\n+}\n+\n+static void* XLA_FFI_INTERNAL_DeviceMemoryAllocator_Get(\n+    XLA_FFI_ExecutionContext* ctx) {\n+  if (auto* gpu = std::get_if<XLA_FFI_ExecutionContext::GpuContext>(\n+          &ctx->backend_context)) {\n+    return gpu->allocator;\n+  }\n+\n+  return new XLA_FFI_Error{\n+      InvalidArgument(\"XLA FFI GPU context is not available\")};\n+}\n+\n //===----------------------------------------------------------------------===//\n // XLA FFI Api access\n //===----------------------------------------------------------------------===//\n \n extern \"C\" const XLA_FFI_Api* XLA_FFI_GetApi() { return GetXlaFfiApi(); }\n \n static XLA_FFI_InternalApi internal_api = {\n+    // Generic XLA APIs available on all XLA backends.\n     XLA_FFI_INTERNAL_Error_Forward,\n     XLA_FFI_INTERNAL_Future_Forward,\n-    XLA_FFI_INTERNAL_Stream_Get,\n     XLA_FFI_INTERNAL_DeviceOrdinal_Get,\n     XLA_FFI_INTERNAL_RunId_Get,\n-    XLA_FFI_INTERNAL_DeviceMemoryAllocator_Get,\n     XLA_FFI_INTERNAL_CalledComputation_Get,\n     XLA_FFI_INTERNAL_ExecutionContext_Get,\n     XLA_FFI_INTERNAL_ExecutionState_Get,\n+\n+    // XLA:CPU specific APIs.\n     XLA_FFI_INTERNAL_IntraOpThreadPool_Get,\n+\n+    // XLA:GPU specific APIs.\n+    XLA_FFI_INTERNAL_Stream_Get,\n+    XLA_FFI_INTERNAL_DeviceMemoryAllocator_Get,\n };\n \n static XLA_FFI_Api api = {"
        }
    ],
    "stats": {
        "total": 126,
        "additions": 79,
        "deletions": 47
    }
}