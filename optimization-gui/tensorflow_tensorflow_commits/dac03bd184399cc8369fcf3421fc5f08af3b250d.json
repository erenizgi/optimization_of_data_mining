{
    "author": "khasanovaa",
    "message": "Add serialization of ExecutionState for CustomCallThunk.\n\nThis change adds the `xla.ffi.ExecutionStateProto` to the `CustomCallThunkProto` and updates the `CustomCallThunk` de/serialization to include the `ffi::ExecutionState`. The `CustomCallThunk::Create` methods now accept an optional `std::unique_ptr<ffi::ExecutionState>`, allowing a pre-existing state to be provided during deserialization.\n\nThis allows users to move the compilation of custom calls from FFI_Execute handler to FFI_Instantiate and pass the compiled kernel via ExecutionState, while keeping the CustomCallThunk serializable\n\nPiperOrigin-RevId: 843648575",
    "sha": "dac03bd184399cc8369fcf3421fc5f08af3b250d",
    "files": [
        {
            "sha": "91708edcc9ef5be21a7c4663469e0d7ed7b8fbdf",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=dac03bd184399cc8369fcf3421fc5f08af3b250d",
            "patch": "@@ -762,7 +762,9 @@ xla_test(\n         \"//xla:shape_util\",\n         \"//xla/ffi\",\n         \"//xla/ffi:attribute_map\",\n+        \"//xla/ffi:execution_state\",\n         \"//xla/ffi:ffi_api\",\n+        \"//xla/ffi:type_registry\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:custom_call_status_public_headers\",\n@@ -2765,6 +2767,7 @@ tf_proto_library(\n         \"//xla:xla_data_proto\",\n         \"//xla/core/host_offloading:host_offloading_executable_proto\",\n         \"//xla/ffi:attribute_map_proto\",\n+        \"//xla/ffi:execution_state_proto\",\n         \"//xla/service:buffer_assignment_proto\",\n         \"//xla/service:hlo_proto\",\n         \"//xla/service/gpu:backend_configs\","
        },
        {
            "sha": "10425250431f3488390d7a496993427703a6d976",
            "filename": "third_party/xla/xla/backends/gpu/runtime/custom_call_thunk.cc",
            "status": "modified",
            "additions": 45,
            "deletions": 21,
            "changes": 66,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.cc?ref=dac03bd184399cc8369fcf3421fc5f08af3b250d",
            "patch": "@@ -215,38 +215,42 @@ absl::StatusOr<std::unique_ptr<CustomCallThunk>> CustomCallThunk::Create(\n     ThunkInfo thunk_info, std::string target_name,\n     std::vector<NullableShapedSlice> operands,\n     std::vector<NullableShapedSlice> results, ffi::AttributesMap attributes,\n-    const HloComputation* called_computation, absl::string_view platform_name) {\n+    const HloComputation* called_computation, absl::string_view platform_name,\n+    std::unique_ptr<ffi::ExecutionState> execution_state) {\n   TF_ASSIGN_OR_RETURN(ffi::HandlerRegistration registration,\n                       ffi::FindHandler(target_name, platform_name));\n \n   return Create(thunk_info, std::move(target_name),\n                 std::move(registration.bundle), std::move(operands),\n-                std::move(results), std::move(attributes), called_computation);\n+                std::move(results), std::move(attributes), called_computation,\n+                std::move(execution_state));\n }\n \n absl::StatusOr<std::unique_ptr<CustomCallThunk>> CustomCallThunk::Create(\n     ThunkInfo thunk_info, std::string target_name,\n     XLA_FFI_Handler_Bundle bundle, std::vector<NullableShapedSlice> operands,\n     std::vector<NullableShapedSlice> results, ffi::AttributesMap attributes,\n-    const HloComputation* called_computation) {\n-  auto execution_state = std::make_unique<ffi::ExecutionState>();\n-\n+    const HloComputation* called_computation,\n+    std::unique_ptr<ffi::ExecutionState> execution_state) {\n   // Initialize FFI handler state if it has an instantiate callback.\n-  if (bundle.instantiate) {\n-    // At FFI handler instantiation time, we don't have any arguments or\n-    // results or access to the underlying device (stream, etc.)\n-    CallFrameBuilder builder(/*num_args=*/0, /*num_rets=*/0);\n-\n-    CallFrameBuilder::AttributesBuilder attrs;\n-    attrs.Append(attributes);\n-\n-    builder.AddAttributes(attrs.Build());\n-    CallFrame call_frame = builder.Build();\n-\n-    CallOptions options;\n-    options.execution_state = execution_state.get();\n-    TF_RETURN_IF_ERROR(Call(bundle.instantiate, call_frame, options,\n-                            XLA_FFI_ExecutionStage_INSTANTIATE));\n+  if (execution_state == nullptr) {\n+    execution_state = std::make_unique<ffi::ExecutionState>();\n+    if (bundle.instantiate) {\n+      // At FFI handler instantiation time, we don't have any arguments or\n+      // results or access to the underlying device (stream, etc.)\n+      CallFrameBuilder builder(/*num_args=*/0, /*num_rets=*/0);\n+\n+      CallFrameBuilder::AttributesBuilder attrs;\n+      attrs.Append(attributes);\n+\n+      builder.AddAttributes(attrs.Build());\n+      CallFrame call_frame = builder.Build();\n+\n+      CallOptions options;\n+      options.execution_state = execution_state.get();\n+      TF_RETURN_IF_ERROR(Call(bundle.instantiate, call_frame, options,\n+                              XLA_FFI_ExecutionStage_INSTANTIATE));\n+    }\n   }\n \n   TF_ASSIGN_OR_RETURN(CallFrame call_frame,\n@@ -602,6 +606,12 @@ absl::StatusOr<ThunkProto> CustomCallThunk::ToProto() const {\n     *proto.mutable_custom_call_thunk()->mutable_attributes() =\n         attributes_->ToProto();\n   }\n+\n+  if (execution_state_ && execution_state_->IsSerializable()) {\n+    TF_ASSIGN_OR_RETURN(\n+        *proto.mutable_custom_call_thunk()->mutable_execution_state(),\n+        execution_state_->ToProto());\n+  }\n   return proto;\n }\n \n@@ -629,6 +639,14 @@ absl::StatusOr<std::unique_ptr<CustomCallThunk>> CustomCallThunk::FromProto(\n         NullableShapedSlice::FromProto(result_proto, buffer_allocations));\n     results.push_back(std::move(result));\n   }\n+\n+  if (proto.api_version() != CustomCallApiVersion::API_VERSION_TYPED_FFI) {\n+    // Create a thunk that uses the legacy custom call registry.\n+    return CustomCallThunk::Create(\n+        std::move(thunk_info), proto.target_name(), std::move(operands),\n+        std::move(results), proto.opaque(), proto.api_version(), platform_name);\n+  }\n+\n   TF_ASSIGN_OR_RETURN(ffi::AttributesMap attributes,\n                       ffi::AttributesMap::FromProto(proto.attributes()));\n \n@@ -643,11 +661,17 @@ absl::StatusOr<std::unique_ptr<CustomCallThunk>> CustomCallThunk::FromProto(\n           \"' not found in the HloModule with name '\", hlo_module->name(), \"'\"));\n     }\n   }\n+  std::unique_ptr<ffi::ExecutionState> execution_state;\n+  if (proto.has_execution_state()) {\n+    TF_ASSIGN_OR_RETURN(\n+        auto state, ffi::ExecutionState::FromProto(proto.execution_state()));\n+    execution_state = std::make_unique<ffi::ExecutionState>(std::move(state));\n+  }\n \n   return CustomCallThunk::Create(std::move(thunk_info), proto.target_name(),\n                                  std::move(operands), std::move(results),\n                                  std::move(attributes), called_computation,\n-                                 platform_name);\n+                                 platform_name, std::move(execution_state));\n }\n \n }  // namespace gpu"
        },
        {
            "sha": "f032c954acc1b5ad61e9c4491014f0b888b0905a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/custom_call_thunk.h",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.h?ref=dac03bd184399cc8369fcf3421fc5f08af3b250d",
            "patch": "@@ -103,8 +103,8 @@ class CustomCallThunk : public Thunk {\n       std::vector<NullableShapedSlice> operands,\n       std::vector<NullableShapedSlice> results,\n       xla::ffi::AttributesMap attributes,\n-      const HloComputation* called_computation,\n-      absl::string_view platform_name);\n+      const HloComputation* called_computation, absl::string_view platform_name,\n+      std::unique_ptr<xla::ffi::ExecutionState> execution_state = nullptr);\n \n   // Creates a serializable custom call thunk from the given XLA FFI handler\n   // bundle. Note that `target_name` needs to refer to a registered XLA FFI\n@@ -114,7 +114,8 @@ class CustomCallThunk : public Thunk {\n       XLA_FFI_Handler_Bundle bundle, std::vector<NullableShapedSlice> operands,\n       std::vector<NullableShapedSlice> results,\n       xla::ffi::AttributesMap attributes,\n-      const HloComputation* called_computation);\n+      const HloComputation* called_computation,\n+      std::unique_ptr<xla::ffi::ExecutionState> execution_state = nullptr);\n \n   // Creates a custom call thunk from a bundle of handlers created with\n   // xla::ffi::Bind(). Any pointer or reference lambda captures must be valid"
        },
        {
            "sha": "897a3bda32f4292e227e4820f7466749e372f52b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/custom_call_thunk_test.cc",
            "status": "modified",
            "additions": 168,
            "deletions": 3,
            "changes": 171,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk_test.cc?ref=dac03bd184399cc8369fcf3421fc5f08af3b250d",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include <cstdint>\n #include <memory>\n #include <string>\n+#include <type_traits>\n #include <utility>\n \n #include <gmock/gmock.h>\n@@ -35,8 +36,10 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/ffi/attribute_map.h\"\n+#include \"xla/ffi/execution_state.h\"\n #include \"xla/ffi/ffi.h\"\n #include \"xla/ffi/ffi_api.h\"\n+#include \"xla/ffi/type_registry.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n@@ -56,6 +59,49 @@ limitations under the License.\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/util/proto/parse_text_proto.h\"\n \n+namespace xla::gpu {\n+struct TestState {\n+  std::string value;\n+};\n+\n+struct NonSerializableTestState {\n+  int value;\n+};\n+\n+struct FailingSerializableTestState {\n+  int value;\n+};\n+}  // namespace xla::gpu\n+\n+namespace xla::ffi {\n+template <>\n+struct TypeRegistry::SerDes<xla::gpu::TestState> : public std::true_type {\n+  static absl::StatusOr<std::string> Serialize(\n+      const xla::gpu::TestState& value) {\n+    return value.value;\n+  }\n+  static absl::StatusOr<std::unique_ptr<xla::gpu::TestState>> Deserialize(\n+      absl::string_view data) {\n+    return std::make_unique<xla::gpu::TestState>(\n+        xla::gpu::TestState{std::string(data)});\n+  }\n+};\n+\n+template <>\n+struct TypeRegistry::SerDes<xla::gpu::FailingSerializableTestState>\n+    : public std::true_type {\n+  static absl::StatusOr<std::string> Serialize(\n+      const xla::gpu::FailingSerializableTestState& value) {\n+    return absl::InternalError(\"Serialization failed\");\n+  }\n+  static absl::StatusOr<std::unique_ptr<xla::gpu::FailingSerializableTestState>>\n+  Deserialize(absl::string_view data) {\n+    return std::make_unique<xla::gpu::FailingSerializableTestState>(\n+        xla::gpu::FailingSerializableTestState{0});\n+  }\n+};\n+}  // namespace xla::ffi\n+\n namespace xla::gpu {\n namespace {\n using absl_testing::IsOk;\n@@ -335,7 +381,8 @@ TEST(CustomCallThunkTest, CustomCallWithOwnedHandlersWithoutExecute) {\n absl::Status VerifyCallbackArguments(int my_attribute,\n                                      ffi::AnyBuffer my_operand,\n                                      ffi::Result<ffi::AnyBuffer> my_result,\n-                                     const HloComputation* called_computation) {\n+                                     const HloComputation* called_computation,\n+                                     xla::gpu::TestState* state) {\n   EXPECT_EQ(my_attribute, 42);\n   EXPECT_EQ(my_operand.element_type(), xla::PrimitiveType::U8);\n   EXPECT_EQ(my_operand.device_memory().opaque(),\n@@ -344,6 +391,7 @@ absl::Status VerifyCallbackArguments(int my_attribute,\n   EXPECT_EQ(my_result->device_memory().opaque(),\n             absl::bit_cast<void*>(static_cast<intptr_t>(0xABCDEF)));\n   EXPECT_EQ(called_computation->name(), \"test_computation\");\n+  EXPECT_EQ(state->value, \"some state\");\n   return absl::OkStatus();\n }\n \n@@ -352,7 +400,8 @@ XLA_FFI_DEFINE_HANDLER(kVerifyCallbackArguments, VerifyCallbackArguments,\n                            .Attr<int>(\"my_attribute\")\n                            .Arg<ffi::AnyBuffer>()\n                            .Ret<ffi::AnyBuffer>()\n-                           .Ctx<ffi::CalledComputation>(),\n+                           .Ctx<ffi::CalledComputation>()\n+                           .Ctx<ffi::State<xla::gpu::TestState>>(),\n                        {ffi::Traits::kCmdBufferCompatible});\n \n constexpr absl::string_view kVerifyCallbackArgumentsCustomCallName =\n@@ -383,6 +432,11 @@ TEST(CustomCallThunkTest, ProtoConversion) {\n   ShapedSlice result_slice{BufferAllocation::Slice{&alloc1, 0, 1024},\n                            ShapeUtil::MakeShape(U16, {512})};\n \n+  auto execution_state = std::make_unique<ffi::ExecutionState>();\n+  ASSERT_THAT(execution_state->Set(\n+                  std::make_unique<TestState>(TestState{\"some state\"})),\n+              IsOk());\n+\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::unique_ptr<CustomCallThunk> original_thunk,\n       CustomCallThunk::Create(\n@@ -391,9 +445,10 @@ TEST(CustomCallThunkTest, ProtoConversion) {\n           /*operands=*/{operand_slice},\n           /*results=*/{result_slice}, /*attributes=*/{{\"my_attribute\", 42}},\n           hlo_module.entry_computation(),\n-          /*platform_name=*/kTestPlatformName));\n+          /*platform_name=*/kTestPlatformName, std::move(execution_state)));\n   TF_ASSERT_OK_AND_ASSIGN(ThunkProto proto, original_thunk->ToProto());\n   ASSERT_TRUE(proto.has_custom_call_thunk());\n+  ASSERT_TRUE(proto.custom_call_thunk().has_execution_state());\n   original_thunk.reset();\n \n   std::array allocations = {alloc0, alloc1};\n@@ -442,5 +497,115 @@ TEST(CustomCallThunkTest, DeserializationFailsWithMissingHloModule) {\n               StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n+TEST(CustomCallThunkTest, RoundtripWithNonSerializableExecutionState) {\n+  TF_ASSERT_OK_AND_ASSIGN(se::StreamExecutor * executor, GpuExecutor());\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<se::Stream> stream,\n+                          executor->CreateStream());\n+\n+  HloModuleConfig config;\n+  HloModule hlo_module(\"test_module\", config);\n+  HloComputation::Builder builder(\"test_computation\");\n+  builder.AddInstruction(HloInstruction::CreateParameter(\n+      0, ShapeUtil::MakeShape(U32, {42}), \"parameter\"));\n+  hlo_module.AddEntryComputation(builder.Build());\n+\n+  auto execution_state = std::make_unique<ffi::ExecutionState>();\n+  ASSERT_THAT(execution_state->Set(std::make_unique<NonSerializableTestState>(\n+                  NonSerializableTestState{42})),\n+              IsOk());\n+  EXPECT_FALSE(execution_state->IsSerializable());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<CustomCallThunk> original_thunk,\n+      CustomCallThunk::Create(\n+          Thunk::ThunkInfo(),\n+          /*target_name=*/std::string(kVerifyCallbackArgumentsCustomCallName),\n+          /*operands=*/{},\n+          /*results=*/{}, /*attributes=*/{}, hlo_module.entry_computation(),\n+          /*platform_name=*/kTestPlatformName, std::move(execution_state)));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(ThunkProto proto, original_thunk->ToProto());\n+  ASSERT_TRUE(proto.has_custom_call_thunk());\n+  EXPECT_FALSE(proto.custom_call_thunk().has_execution_state());\n+\n+  original_thunk.reset();\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<CustomCallThunk> new_thunk,\n+      CustomCallThunk::FromProto(Thunk::ThunkInfo(), proto.custom_call_thunk(),\n+                                 /*buffer_allocations=*/{}, &hlo_module,\n+                                 kTestPlatformName));\n+\n+  EXPECT_NE(new_thunk->execution_state(), nullptr);\n+  EXPECT_FALSE(new_thunk->execution_state()->IsSet());\n+}\n+\n+TEST(CustomCallThunkTest, SerializationFails) {\n+  HloModuleConfig config;\n+  HloModule hlo_module(\"test_module\", config);\n+  HloComputation::Builder builder(\"test_computation\");\n+  builder.AddInstruction(HloInstruction::CreateParameter(\n+      0, ShapeUtil::MakeShape(U32, {42}), \"parameter\"));\n+  hlo_module.AddEntryComputation(builder.Build());\n+\n+  auto execution_state = std::make_unique<ffi::ExecutionState>();\n+  ASSERT_OK(execution_state->Set(std::make_unique<FailingSerializableTestState>(\n+      FailingSerializableTestState{42})));\n+  EXPECT_TRUE(execution_state->IsSerializable());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<CustomCallThunk> thunk,\n+      CustomCallThunk::Create(\n+          Thunk::ThunkInfo(),\n+          /*target_name=*/std::string(kVerifyCallbackArgumentsCustomCallName),\n+          /*operands=*/{},\n+          /*results=*/{}, /*attributes=*/{}, hlo_module.entry_computation(),\n+          /*platform_name=*/kTestPlatformName, std::move(execution_state)));\n+\n+  EXPECT_THAT(thunk->ToProto(), StatusIs(absl::StatusCode::kInternal,\n+                                         HasSubstr(\"Serialization failed\")));\n+}\n+\n+TEST(CustomCallThunkTest, LegacyCustomCallRoundTrip) {\n+  TF_ASSERT_OK_AND_ASSIGN(se::StreamExecutor * executor, GpuExecutor());\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<se::Stream> stream,\n+                          executor->CreateStream());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<CustomCallThunk> original_thunk,\n+      CustomCallThunk::Create(\n+          Thunk::ThunkInfo(),\n+          /*target_name=*/\"Callback_WithStatusFailed\",\n+          /*operands=*/{},\n+          /*results=*/{}, /*opaque=*/\"opaque\",\n+          CustomCallApiVersion::API_VERSION_STATUS_RETURNING,\n+          /*platform_name=*/executor->GetPlatform()->Name()));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(ThunkProto proto, original_thunk->ToProto());\n+  original_thunk.reset();\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<CustomCallThunk> new_thunk,\n+      CustomCallThunk::FromProto(Thunk::ThunkInfo(), proto.custom_call_thunk(),\n+                                 /*buffer_allocations=*/{},\n+                                 /*hlo_module=*/nullptr,\n+                                 executor->GetPlatform()->Name()));\n+\n+  se::StreamExecutorMemoryAllocator allocator(executor);\n+  BufferAllocations empty_unused_allocations({}, 0, &allocator);\n+  Thunk::ExecuteParams params = Thunk::ExecuteParams::Create(\n+      ServiceExecutableRunOptions(), empty_unused_allocations,\n+      /*stream=*/stream.get(),\n+      /*command_buffer_trace_stream=*/stream.get(),\n+      /*collective_params=*/nullptr,\n+      /*collective_cliques=*/nullptr);\n+\n+  // We check that the new thunk behaves like the original one (returning\n+  // internal error with specific message).\n+  EXPECT_THAT(new_thunk->ExecuteOnStream(params),\n+              StatusIs(absl::StatusCode::kInternal,\n+                       HasSubstr(\"Legacy Custom call was executed!\")));\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "f2a93d80e31eb82a6255707b4267c3181f6f4b44",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=dac03bd184399cc8369fcf3421fc5f08af3b250d",
            "patch": "@@ -22,6 +22,7 @@ import \"xla/backends/gpu/runtime/dynamic_slice_thunk.proto\";\n import \"xla/backends/gpu/runtime/shaped_slice.proto\";\n import \"xla/core/host_offloading/host_offloading_executable.proto\";\n import \"xla/ffi/attribute_map.proto\";\n+import \"xla/ffi/execution_state.proto\";\n import \"xla/service/buffer_assignment.proto\";\n import \"xla/service/gpu/gpu_conv_runner.proto\";\n import \"xla/service/gpu/gpu_norm_runner.proto\";\n@@ -290,6 +291,7 @@ message CustomCallThunkProto {\n   // The name of the called computation. It needs to match the HloCompuation in\n   // the HloModule that is used to deserialize the thunk.\n   optional string called_computation = 7;\n+  optional xla.ffi.ExecutionStateProto execution_state = 8;\n }\n \n message CustomKernelThunkProto {"
        },
        {
            "sha": "8613d387871abf673e79b102d1eb6fa4358f4fa3",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc?ref=dac03bd184399cc8369fcf3421fc5f08af3b250d",
            "patch": "@@ -764,6 +764,7 @@ TEST(ThunkProtoDeserializationTest, CustomCallThunk) {\n             }\n           }\n           called_computation: \"called_computation\"\n+          execution_state {}\n         }\n       )pb\");\n   std::vector<BufferAllocation> buffer_allocations = {"
        },
        {
            "sha": "a3b5439a1ba1e7f5f4bf7fb05e35e1b67a25c6e6",
            "filename": "third_party/xla/xla/ffi/execution_state.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fffi%2Fexecution_state.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fffi%2Fexecution_state.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fffi%2Fexecution_state.cc?ref=dac03bd184399cc8369fcf3421fc5f08af3b250d",
            "patch": "@@ -125,4 +125,11 @@ bool ExecutionState::IsSet() const {\n   return type_id_ != TypeRegistry::kUnknownTypeId;\n }\n \n+bool ExecutionState::IsSerializable() const {\n+  if (!IsSet()) {\n+    return true;\n+  }\n+  return type_info_.serializer != nullptr;\n+}\n+\n }  // namespace xla::ffi"
        },
        {
            "sha": "d4aa091932e066a42586f011b68b7a4f94506c39",
            "filename": "third_party/xla/xla/ffi/execution_state.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fffi%2Fexecution_state.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fffi%2Fexecution_state.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fffi%2Fexecution_state.h?ref=dac03bd184399cc8369fcf3421fc5f08af3b250d",
            "patch": "@@ -91,6 +91,7 @@ class ExecutionState {\n   absl::StatusOr<T*> Get() const;\n \n   bool IsSet() const;\n+  bool IsSerializable() const;\n \n  private:\n   absl::Status Set(TypeId type_id, TypeInfo type_info, void* state);"
        },
        {
            "sha": "e79a54f339edc47ecbea2cd2a821c91ac5c51b6d",
            "filename": "third_party/xla/xla/ffi/execution_state_test.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fffi%2Fexecution_state_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dac03bd184399cc8369fcf3421fc5f08af3b250d/third_party%2Fxla%2Fxla%2Fffi%2Fexecution_state_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fffi%2Fexecution_state_test.cc?ref=dac03bd184399cc8369fcf3421fc5f08af3b250d",
            "patch": "@@ -123,4 +123,23 @@ TEST(ExecutionStateTest, Serialization) {\n   EXPECT_EQ(static_cast<MyState*>(round_trip_data)->value, \"some_state_data\");\n }\n \n+TEST(ExecutionStateTest, IsSerializable) {\n+  ExecutionState state;\n+  // Empty state is serializable (as empty proto).\n+  EXPECT_TRUE(state.IsSerializable());\n+\n+  // State without serializer.\n+  struct NoSerializer {\n+    int x;\n+  };\n+  TF_ASSERT_OK(state.Set(std::make_unique<NoSerializer>(NoSerializer{42})));\n+  EXPECT_FALSE(state.IsSerializable());\n+\n+  // State with serializer.\n+  ExecutionState serializable_state;\n+  TF_ASSERT_OK(\n+      serializable_state.Set(std::make_unique<MyState>(MyState{\"foo\"})));\n+  EXPECT_TRUE(serializable_state.IsSerializable());\n+}\n+\n }  // namespace xla::ffi"
        }
    ],
    "stats": {
        "total": 277,
        "additions": 250,
        "deletions": 27
    }
}