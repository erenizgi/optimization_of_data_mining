{
    "author": "paulinesho",
    "message": "Add plumbing for blockwise for TFLite interpreter\n\nPiperOrigin-RevId: 812940180",
    "sha": "6d3931869f719fd8972184d523881f92e78973ab",
    "files": [
        {
            "sha": "292a1a959d224312bfb2626de3b10cf1f9a8f4fa",
            "filename": "tensorflow/lite/core/interpreter_builder.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d3931869f719fd8972184d523881f92e78973ab/tensorflow%2Flite%2Fcore%2Finterpreter_builder.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d3931869f719fd8972184d523881f92e78973ab/tensorflow%2Flite%2Fcore%2Finterpreter_builder.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fcore%2Finterpreter_builder.cc?ref=6d3931869f719fd8972184d523881f92e78973ab",
            "patch": "@@ -416,7 +416,9 @@ TfLiteStatus InterpreterBuilder::ParseQuantization(\n         reinterpret_cast<TfLiteBlockwiseQuantization*>(\n             malloc(sizeof(TfLiteBlockwiseQuantization)));\n     blockwise_quantization->scale = src_quant->scales();\n-    blockwise_quantization->quantized_dimension = 0;\n+    blockwise_quantization->zero_point = src_quant->zero_points();\n+    blockwise_quantization->quantized_dimension =\n+        src_quantization->quantized_dimension();\n     blockwise_quantization->blocksize = src_quant->block_size();\n     quantization->params = reinterpret_cast<void*>(blockwise_quantization);\n     return kTfLiteOk;"
        },
        {
            "sha": "0560133b6c3a49f4012d2aa1ded65bf7f7393425",
            "filename": "tensorflow/lite/kernels/test_util.h",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d3931869f719fd8972184d523881f92e78973ab/tensorflow%2Flite%2Fkernels%2Ftest_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d3931869f719fd8972184d523881f92e78973ab/tensorflow%2Flite%2Fkernels%2Ftest_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fkernels%2Ftest_util.h?ref=6d3931869f719fd8972184d523881f92e78973ab",
            "patch": "@@ -1105,10 +1105,8 @@ class SingleOpModel {\n     flatbuffers::Offset<QuantizationParameters> q_params = 0;\n     q_params = CreateQuantizationParameters(\n         builder_, /*min=*/0, /*max=*/0,\n-        /*scale=*/\n-        0,\n-        /*zero point=*/\n-        0, QuantizationDetails_BlockwiseQuantization,\n+        /*scale=*/0,\n+        /*zero point=*/0, QuantizationDetails_BlockwiseQuantization,\n         *reinterpret_cast<flatbuffers::Offset<void>*>(&blockwise_quant_params),\n         t.shape.size() - 1);\n     int buffer_id = 0;"
        },
        {
            "sha": "40852fafaad5646b010bc74a68a4c94486206393",
            "filename": "tensorflow/lite/python/interpreter.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d3931869f719fd8972184d523881f92e78973ab/tensorflow%2Flite%2Fpython%2Finterpreter.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d3931869f719fd8972184d523881f92e78973ab/tensorflow%2Flite%2Fpython%2Finterpreter.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fpython%2Finterpreter.py?ref=6d3931869f719fd8972184d523881f92e78973ab",
            "patch": "@@ -664,6 +664,7 @@ def _get_tensor_details(self, tensor_index, subgraph_index):\n             'scales': tensor_quantization_params[0],\n             'zero_points': tensor_quantization_params[1],\n             'quantized_dimension': tensor_quantization_params[2],\n+            'block_size': tensor_quantization_params[3],\n         },\n         'sparsity_parameters': tensor_sparsity_params,\n     }"
        },
        {
            "sha": "922f655dfc855db44788c5b316be3b800dd0ef96",
            "filename": "tensorflow/lite/python/interpreter_wrapper/interpreter_wrapper.cc",
            "status": "modified",
            "additions": 41,
            "deletions": 2,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d3931869f719fd8972184d523881f92e78973ab/tensorflow%2Flite%2Fpython%2Finterpreter_wrapper%2Finterpreter_wrapper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d3931869f719fd8972184d523881f92e78973ab/tensorflow%2Flite%2Fpython%2Finterpreter_wrapper%2Finterpreter_wrapper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fpython%2Finterpreter_wrapper%2Finterpreter_wrapper.cc?ref=6d3931869f719fd8972184d523881f92e78973ab",
            "patch": "@@ -129,6 +129,16 @@ PyObject* PyArrayFromFloatVector(const float* data, npy_intp size) {\n   return obj;\n }\n \n+PyObject* PyArrayFromFloat16Vector(const uint16_t* data, npy_intp size) {\n+  void* pydata = malloc(size * sizeof(uint16_t));\n+  if (data != nullptr) {\n+    memcpy(pydata, data, size * sizeof(uint16_t));\n+  }\n+  PyObject* obj = PyArray_SimpleNewFromData(1, &size, NPY_FLOAT16, pydata);\n+  PyArray_ENABLEFLAGS(reinterpret_cast<PyArrayObject*>(obj), NPY_ARRAY_OWNDATA);\n+  return obj;\n+}\n+\n PyObject* PyArrayFromIntVector(const int* data, npy_intp size) {\n   void* pydata = malloc(size * sizeof(int));\n   if (data != nullptr) {\n@@ -534,6 +544,9 @@ PyObject* InterpreterWrapper::TensorQuantizationParameters(\n   int32_t scales_size = 0;\n   int32_t zero_points_size = 0;\n   int32_t quantized_dimension = 0;\n+  int32_t block_size = 0;\n+  PyObject* scales_array = nullptr;\n+\n   if (quantization.type == kTfLiteAffineQuantization) {\n     const TfLiteAffineQuantization* q_params =\n         reinterpret_cast<const TfLiteAffineQuantization*>(quantization.params);\n@@ -546,15 +559,41 @@ PyObject* InterpreterWrapper::TensorQuantizationParameters(\n       zero_points_size = q_params->zero_point->size;\n     }\n     quantized_dimension = q_params->quantized_dimension;\n+    scales_array = PyArrayFromFloatVector(scales_data, scales_size);\n+  } else if (quantization.type == kTfLiteBlockwiseQuantization) {\n+    const TfLiteBlockwiseQuantization* bq_params =\n+        reinterpret_cast<const TfLiteBlockwiseQuantization*>(\n+            quantization.params);\n+    TFLITE_PY_SUBGRAPH_TENSOR_BOUNDS_CHECK(bq_params->scale, subgraph_index);\n+    const TfLiteTensor* scale_tensor = subgraph->tensor(bq_params->scale);\n+    auto* scales_data =\n+        reinterpret_cast<const uint16_t*>(scale_tensor->data.f16);\n+    scales_size = scale_tensor->bytes / sizeof(uint16_t);\n+    scales_array = PyArrayFromFloat16Vector(scales_data, scales_size);\n+    if (bq_params->zero_point != -1) {\n+      TFLITE_PY_SUBGRAPH_TENSOR_BOUNDS_CHECK(bq_params->zero_point,\n+                                             subgraph_index);\n+      const TfLiteTensor* zero_point_tensor =\n+          subgraph->tensor(bq_params->zero_point);\n+      zero_points_data = zero_point_tensor->data.i32;\n+      zero_points_size = zero_point_tensor->bytes / sizeof(int32_t);\n+    } else {\n+      zero_points_data = nullptr;\n+      zero_points_size = 0;\n+    }\n+    quantized_dimension = bq_params->quantized_dimension;\n+    block_size = bq_params->blocksize;\n+  } else {\n+    scales_array = PyArrayFromFloatVector(scales_data, scales_size);\n   }\n-  PyObject* scales_array = PyArrayFromFloatVector(scales_data, scales_size);\n   PyObject* zero_points_array =\n       PyArrayFromIntVector(zero_points_data, zero_points_size);\n \n-  PyObject* result = PyTuple_New(3);\n+  PyObject* result = PyTuple_New(4);\n   PyTuple_SET_ITEM(result, 0, scales_array);\n   PyTuple_SET_ITEM(result, 1, zero_points_array);\n   PyTuple_SET_ITEM(result, 2, PyLong_FromLong(quantized_dimension));\n+  PyTuple_SET_ITEM(result, 3, PyLong_FromLong(block_size));\n   return result;\n }\n "
        },
        {
            "sha": "819b0ef89c8c3d881ea0a26db72b5694114ac65f",
            "filename": "tensorflow/lite/tools/optimize/quantization_utils.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d3931869f719fd8972184d523881f92e78973ab/tensorflow%2Flite%2Ftools%2Foptimize%2Fquantization_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d3931869f719fd8972184d523881f92e78973ab/tensorflow%2Flite%2Ftools%2Foptimize%2Fquantization_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Ftools%2Foptimize%2Fquantization_utils.cc?ref=6d3931869f719fd8972184d523881f92e78973ab",
            "patch": "@@ -414,7 +414,7 @@ void SymmetricPerBlockQuantizeValues(\n         for (indices[3] = 0; indices[3] < tensor_dims.Dims(3); indices[3]++) {\n           int index = Offset(tensor_dims, indices);\n           int scale_indices[4] = {indices[0], indices[1], indices[2],\n-                                  indices[3] % blocksize};\n+                                  indices[3] / blocksize};\n           int scale_index = Offset(scale_dims, scale_indices);\n           const float val = input[index];\n           const int32_t quantized_value ="
        }
    ],
    "stats": {
        "total": 56,
        "additions": 48,
        "deletions": 8
    }
}