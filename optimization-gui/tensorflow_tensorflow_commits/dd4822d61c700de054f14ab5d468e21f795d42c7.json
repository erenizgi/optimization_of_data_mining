{
    "author": "WillFroom",
    "message": "[XLA:CPU] Fix flaky test.\n\nPiperOrigin-RevId: 821835738",
    "sha": "dd4822d61c700de054f14ab5d468e21f795d42c7",
    "files": [
        {
            "sha": "eee98e14e881cc09e25775f57254b2f7dceb0462",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/tiled_kernel_test.py",
            "status": "modified",
            "additions": 18,
            "deletions": 13,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd4822d61c700de054f14ab5d468e21f795d42c7/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd4822d61c700de054f14ab5d468e21f795d42c7/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py?ref=dd4822d61c700de054f14ab5d468e21f795d42c7",
            "patch": "@@ -14,6 +14,7 @@\n # ==============================================================================\n \n from collections.abc import Callable, Iterable\n+from typing import Optional\n \n from absl.testing import absltest\n import numpy as np\n@@ -33,7 +34,7 @@ def compare_kernel(\n     output_shape: tuple[int, ...],\n     dtype,\n     expected_output: Callable[[np.ndarray, ...], np.ndarray],\n-    exact: bool = True,\n+    maxulp: Optional[int] = None,\n ) -> None:\n   mlir_emitter = cpu_testlib.MlirTestKernelEmitter(\n       ir, kernel_name, (num_workgroups, 1, 1)\n@@ -47,16 +48,20 @@ def compare_kernel(\n   inputs = [np.random.rand(*shape).astype(dtype) for shape in input_shapes]\n \n   input_tensors = [create_literal(input) for input in inputs]\n-  output_tensor = create_literal(np.zeros(output_shape, dtype=dtype))\n+  output_tensor = create_literal(\n+      np.zeros(shape=output_shape, dtype=dtype)\n+      if output_shape\n+      else np.array(0, dtype=dtype)\n+  )\n   runner.call(input_tensors + [output_tensor])\n \n-  if exact:\n-    np.testing.assert_array_equal(\n-        np.asarray(output_tensor), expected_output(*inputs)\n-    )\n+  output_np = np.asarray(output_tensor)\n+  expected_output_np = expected_output(*inputs)\n+  if maxulp is None:\n+    np.testing.assert_array_equal(output_np, expected_output_np)\n   else:\n-    np.testing.assert_array_almost_equal_nulp(\n-        np.asarray(output_tensor), expected_output(*inputs), nulp=3\n+    np.testing.assert_array_max_ulp(\n+        output_np, expected_output_np, maxulp=maxulp\n     )\n \n \n@@ -171,7 +176,7 @@ def test_dot_single_tile(self):\n         (8, 8),\n         np.float32,\n         lambda lhs, rhs: lhs @ rhs,\n-        False,\n+        maxulp=5,\n     )\n \n   def test_dot_scalar_output(self):\n@@ -197,10 +202,10 @@ def test_dot_scalar_output(self):\n         \"test_dot_scalar_output\",\n         1,\n         [(8, 16), (16, 8)],\n-        (1,),\n+        (),\n         np.float32,\n-        lambda lhs, rhs: np.tensordot(lhs, rhs, axes=([1, 0], [0, 1])),\n-        False,\n+        lambda lhs, rhs: np.tensordot(lhs, rhs, axes=[[1, 0], [0, 1]]),\n+        maxulp=8,\n     )\n \n   def test_dot_fusion_single_tile(self):\n@@ -233,7 +238,7 @@ def test_dot_fusion_single_tile(self):\n         (8, 1),\n         np.float32,\n         lambda lhs_0, lhs_1, rhs: np.tanh((lhs_0 + lhs_1) @ rhs),\n-        False,\n+        maxulp=5,\n     )\n \n "
        }
    ],
    "stats": {
        "total": 31,
        "additions": 18,
        "deletions": 13
    }
}