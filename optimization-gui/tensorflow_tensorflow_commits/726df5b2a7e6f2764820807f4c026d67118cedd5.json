{
    "author": "beckerhe",
    "message": "Make the autotuning cache key depend on the cudnn version\n\nThis is adding the current cuDNN version to the autotuner cache key.\n\nIt makes sure that the cache gets invalidated if we change the cuDNN\nversion.\n\nPiperOrigin-RevId: 801811810",
    "sha": "726df5b2a7e6f2764820807f4c026d67118cedd5",
    "files": [
        {
            "sha": "f6683b85248bf2059f2d1981ac10c638ab5284d0",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=726df5b2a7e6f2764820807f4c026d67118cedd5",
            "patch": "@@ -1748,6 +1748,7 @@ xla_test(\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:platform_manager\",\n+        \"//xla/stream_executor:semantic_version\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/tests:hlo_test_base\",\n         \"//xla/tests:literal_test_util\",\n@@ -1759,10 +1760,11 @@ xla_test(\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:logging\",\n-        \"//xla/tsl/platform:status_matchers\",\n+        \"//xla/tsl/platform:status\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n         \"@com_google_absl//absl/base:log_severity\",\n+        \"@com_google_absl//absl/cleanup\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/log:scoped_mock_log\","
        },
        {
            "sha": "a16829eb55ee53abbabc29010021044e25ffac0c",
            "filename": "third_party/xla/xla/service/gpu/autotuning/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD?ref=726df5b2a7e6f2764820807f4c026d67118cedd5",
            "patch": "@@ -799,6 +799,7 @@ xla_cc_test(\n         \"//xla/stream_executor:device_description_proto_cc\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:platform_manager\",\n+        \"//xla/stream_executor:semantic_version\",\n         \"//xla/stream_executor/host:host_platform\",\n         \"//xla/tests:hlo_test_base\",\n         \"//xla/tests:xla_internal_test_main\","
        },
        {
            "sha": "c61bdac92138a39cdd507f1cdcff231d75ac305f",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotune_cache_key.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.cc?ref=726df5b2a7e6f2764820807f4c026d67118cedd5",
            "patch": "@@ -86,11 +86,12 @@ std::string AutotuneCacheKey::DeviceDescriptionToCacheKey(\n   constexpr double kBytesPerMegabyte = 1 << 20;\n   double l2_cache_size = device_description.l2_cache_size() / kBytesPerMegabyte;\n \n-  return absl::StrCat(compute_capability,\n-                      \", Cores: \", device_description.core_count(),\n-                      \", GPU clock: \", device_description.clock_rate_ghz(),\n-                      \" GHz, Memory bandwidth: \", memory_bandwidth,\n-                      \" GB/s, L2 cache: \", l2_cache_size, \" MB\");\n+  return absl::StrCat(\n+      compute_capability, \", Cores: \", device_description.core_count(),\n+      \", GPU clock: \", device_description.clock_rate_ghz(),\n+      \" GHz, Memory bandwidth: \", memory_bandwidth,\n+      \" GB/s, L2 cache: \", l2_cache_size,\n+      \" MB, DNN version: \", device_description.dnn_version().ToString());\n }\n \n AutotuneCacheKey::AutotuneCacheKey("
        },
        {
            "sha": "db615006fb37397cd03ff1e4e61be58532cc102c",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotune_cache_key_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key_test.cc?ref=726df5b2a7e6f2764820807f4c026d67118cedd5",
            "patch": "@@ -78,17 +78,17 @@ TEST(AutotuneCacheKeyTest, DeviceDescriptionToCacheKey) {\n   EXPECT_EQ(AutotuneCacheKey::DeviceDescriptionToCacheKey(\n                 device_description(\"a100_sxm_40.txtpb\")),\n             \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: \"\n-            \"1555 GB/s, L2 cache: 40 MB\");\n+            \"1555 GB/s, L2 cache: 40 MB, DNN version: 0.0.0\");\n \n   EXPECT_EQ(AutotuneCacheKey::DeviceDescriptionToCacheKey(\n                 device_description(\"a100_sxm_80.txtpb\")),\n             \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: \"\n-            \"2039 GB/s, L2 cache: 40 MB\");\n+            \"2039 GB/s, L2 cache: 40 MB, DNN version: 0.0.0\");\n \n   EXPECT_EQ(AutotuneCacheKey::DeviceDescriptionToCacheKey(\n                 device_description(\"mi200.txtpb\")),\n             \"ROCM: gfx90a, Cores: 110, GPU clock: 1.7 GHz, Memory bandwidth: \"\n-            \"1638 GB/s, L2 cache: 8 MB\");\n+            \"1638 GB/s, L2 cache: 8 MB, DNN version: 0.0.0\");\n }\n \n TEST(AutotuneCacheKeyTest, VersionIsIncludedInCacheKey) {"
        },
        {
            "sha": "dfbb6a54509bd8e29646484b82f5b6134f9084ac",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_util_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util_test.cc?ref=726df5b2a7e6f2764820807f4c026d67118cedd5",
            "patch": "@@ -109,7 +109,7 @@ ENTRY e {\n   static constexpr absl::string_view kResultText = R\"pb(\n     version: 3\n     results {\n-      device: \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 1555 GB/s, L2 cache: 40 MB\"\n+      device: \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 1555 GB/s, L2 cache: 40 MB, DNN version: 1.2.3\"\n       hlo: \"{\\n  tmp_0 = f16[1,16,17,3]{3,2,1,0} parameter(0)\\n  tmp_1 = f16[16,51]{1,0} bitcast(f16[1,16,17,3]{3,2,1,0} tmp_0)\\n  tmp_2 = s8[16,17,3]{2,1,0} parameter(1)\\n  tmp_3 = s8[51,16]{0,1} bitcast(s8[16,17,3]{2,1,0} tmp_2)\\n  tmp_4 = f16[51,16]{0,1} convert(s8[51,16]{0,1} tmp_3)\\n  tmp_5 = f16[16,16]{1,0} dot(f16[16,51]{1,0} tmp_1, f16[51,16]{0,1} tmp_4), lhs_contracting_dims={1}, rhs_contracting_dims={0}\\n  ROOT tmp_6 = f16[1,16,16]{2,1,0} bitcast(f16[16,16]{1,0} tmp_5)\\n}\"\n       result {\n         run_time { nanos: 31744 }\n@@ -217,6 +217,7 @@ TEST_F(AutotunerUtilTest, LoadAutotuneResultsFromFile_TextProto1) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       stream_executor::DeviceDescription device_description,\n       stream_executor::DeviceDescription::FromProto(device_description_proto));\n+  device_description.set_dnn_version({1, 2, 3});\n   AutotuneCacheKey key(device_description,\n                        *module->entry_computation()->root_instruction());\n "
        },
        {
            "sha": "a388c5cb13288efc972b7f4c9b2f39fdab59b617",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler_test.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 4,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc?ref=726df5b2a7e6f2764820807f4c026d67118cedd5",
            "patch": "@@ -16,7 +16,6 @@ limitations under the License.\n #include \"xla/service/gpu/gpu_compiler.h\"\n \n #include <algorithm>\n-#include <cstddef>\n #include <cstdint>\n #include <iostream>\n #include <limits>\n@@ -32,12 +31,14 @@ limitations under the License.\n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/base/log_severity.h\"\n+#include \"absl/cleanup/cleanup.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/log/scoped_mock_log.h\"\n #include \"absl/status/status_matchers.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_replace.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/strings/substitute.h\"\n #include \"xla/autotune_results.pb.h\"\n@@ -72,6 +73,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n+#include \"xla/stream_executor/semantic_version.h\"\n #include \"xla/tests/hlo_test_base.h\"\n #include \"xla/tests/literal_test_util.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n@@ -81,7 +83,7 @@ limitations under the License.\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/logging.h\"\n-#include \"xla/tsl/platform/status_matchers.h\"\n+#include \"xla/tsl/platform/status.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n@@ -610,11 +612,36 @@ ENTRY main {\n \n class GpuCompilerTestWithAutotuneDb : public GpuCompilerTest {\n  public:\n-  static void SetUpTestSuite() {\n+  void SetUp() override {\n     std::string path =\n         tsl::io::JoinPath(tsl::testing::XlaSrcRoot(), \"service\", \"gpu\",\n                           \"gpu_compiler_test_autotune_db.textproto\");\n-    TF_EXPECT_OK(AutotunerUtil::LoadAutotuneResultsFromFile(path));\n+\n+    tsl::Env* env = tsl::Env::Default();\n+    std::string tmp_filepath = ::testing::TempDir();\n+    ASSERT_TRUE(env->CreateUniqueFileName(&tmp_filepath, \".textproto\"));\n+\n+    absl::Cleanup cleanup = [&] { TF_CHECK_OK(env->DeleteFile(tmp_filepath)); };\n+\n+    std::string contents;\n+    TF_CHECK_OK(tsl::ReadFileToString(env, path, &contents));\n+\n+    // The autotuning cache entries depend on the DNN library version, but this\n+    // is not relevant for these tests. Therefore we replace the DNN version\n+    // with the actual version of the DNN library so that the cache entries\n+    // match.\n+    stream_executor::SemanticVersion dnn_version =\n+        backend()\n+            .default_stream_executor()\n+            ->GetDeviceDescription()\n+            .dnn_version();\n+    constexpr absl::string_view kCudnnVersionPlaceholder = \"1.2.3\";\n+    contents = absl::StrReplaceAll(\n+        contents, {{kCudnnVersionPlaceholder, dnn_version.ToString()}});\n+\n+    TF_EXPECT_OK(tsl::WriteStringToFile(env, tmp_filepath, contents));\n+    AutotunerUtil::ClearAutotuneResults();\n+    TF_EXPECT_OK(AutotunerUtil::LoadAutotuneResultsFromFile(tmp_filepath));\n   }\n \n   static void TearDownTestSuite() { AutotunerUtil::ClearAutotuneResults(); }"
        },
        {
            "sha": "5c66f5f2d3bf5076fda160adec494cd032fbd229",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler_test_autotune_db.textproto",
            "status": "modified",
            "additions": 13,
            "deletions": 13,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test_autotune_db.textproto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/726df5b2a7e6f2764820807f4c026d67118cedd5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test_autotune_db.textproto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test_autotune_db.textproto?ref=726df5b2a7e6f2764820807f4c026d67118cedd5",
            "patch": "@@ -14,7 +14,7 @@\n \n version: 3\n results {\n-  device: \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 1555 GB/s, L2 cache: 40 MB\"\n+  device: \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 1555 GB/s, L2 cache: 40 MB, DNN version: 1.2.3\"\n   hlo: \"{\\n  tmp_0 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(0)\\n  tmp_1 = f32[1,4,32,1024,1024]{4,3,2,1,0} convert(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_0)\\n  tmp_2 = bf16[] constant({...})\\n  tmp_3 = bf16[1,4,32,1024,1024]{4,3,2,1,0} broadcast(bf16[] tmp_2), dimensions={}\\n  tmp_4 = f32[1,4,32,1024,1024]{4,3,2,1,0} convert(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_3)\\n  tmp_5 = f32[1,4,32,1024,1024]{4,3,2,1,0} multiply(f32[1,4,32,1024,1024]{4,3,2,1,0} tmp_1, f32[1,4,32,1024,1024]{4,3,2,1,0} tmp_4)\\n  tmp_6 = bf16[1,4,32,1024,1024]{4,3,2,1,0} convert(f32[1,4,32,1024,1024]{4,3,2,1,0} tmp_5)\\n  tmp_7 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_6)\\n  tmp_8 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[4,32,1024,1024]{3,2,1,0} tmp_7)\\n  tmp_9 = bf16[128,1024,1024]{2,1,0} transpose(bf16[128,1024,1024]{2,1,0} tmp_8), dimensions={0,2,1}\\n  tmp_10 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[128,1024,1024]{2,1,0} tmp_9)\\n  tmp_11 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[4,32,1024,1024]{3,2,1,0} tmp_10)\\n  tmp_12 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(1)\\n  tmp_13 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_12)\\n  tmp_14 = bf16[128,1024,1024]{2,1,0} dot(bf16[128,1024,1024]{2,1,0} tmp_11, bf16[128,1024,1024]{2,1,0} tmp_13), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}\\n  ROOT tmp_15 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[128,1024,1024]{2,1,0} tmp_14)\\n}\"\n   result {\n     gemm {\n@@ -26,7 +26,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 1555 GB/s, L2 cache: 40 MB\"\n+  device: \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 1555 GB/s, L2 cache: 40 MB, DNN version: 1.2.3\"\n   hlo: \"(bf16[128,1024,1024]{2,1,0}, s8[4194304]{0}) custom-call(bf16[128,1024,1024]{2,1,0}, bf16[128,1024,1024]{2,1,0}), custom_call_target=\\\"__cublas$gemm\\\", backend_config={\\\"force_earliest_schedule\\\":false,\\\"gemm_backend_config\\\":{\\\"alpha_imag\\\":0,\\\"alpha_real\\\":1,\\\"beta\\\":0,\\\"damax_output\\\":false,\\\"dot_dimension_numbers\\\":{\\\"lhs_batch_dimensions\\\":[\\\"0\\\"],\\\"lhs_contracting_dimensions\\\":[\\\"2\\\"],\\\"rhs_batch_dimensions\\\":[\\\"0\\\"],\\\"rhs_contracting_dimensions\\\":[\\\"1\\\"]},\\\"epilogue\\\":\\\"DEFAULT\\\",\\\"grad_x\\\":false,\\\"grad_y\\\":false,\\\"lhs_stride\\\":\\\"1048576\\\",\\\"precision_config\\\":{\\\"algorithm\\\":\\\"ALG_UNSET\\\",\\\"operand_precision\\\":[\\\"DEFAULT\\\",\\\"DEFAULT\\\"]},\\\"rhs_stride\\\":\\\"1048576\\\"},\\\"operation_queue_id\\\":\\\"0\\\",\\\"wait_on_operation_queues\\\":[]}\"\n   result {\n     run_time {\n@@ -38,7 +38,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB\"\n+  device: \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB, DNN version: 1.2.3\"\n   hlo: \"{\\n  tmp_0 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(0)\\n  tmp_1 = f32[1,4,32,1024,1024]{4,3,2,1,0} convert(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_0)\\n  tmp_2 = bf16[] constant({...})\\n  tmp_3 = bf16[1,4,32,1024,1024]{4,3,2,1,0} broadcast(bf16[] tmp_2), dimensions={}\\n  tmp_4 = f32[1,4,32,1024,1024]{4,3,2,1,0} convert(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_3)\\n  tmp_5 = f32[1,4,32,1024,1024]{4,3,2,1,0} multiply(f32[1,4,32,1024,1024]{4,3,2,1,0} tmp_1, f32[1,4,32,1024,1024]{4,3,2,1,0} tmp_4)\\n  tmp_6 = bf16[1,4,32,1024,1024]{4,3,2,1,0} convert(f32[1,4,32,1024,1024]{4,3,2,1,0} tmp_5)\\n  tmp_7 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_6)\\n  tmp_8 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[4,32,1024,1024]{3,2,1,0} tmp_7)\\n  tmp_9 = bf16[128,1024,1024]{2,1,0} transpose(bf16[128,1024,1024]{2,1,0} tmp_8), dimensions={0,2,1}\\n  tmp_10 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[128,1024,1024]{2,1,0} tmp_9)\\n  tmp_11 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[4,32,1024,1024]{3,2,1,0} tmp_10)\\n  tmp_12 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(1)\\n  tmp_13 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_12)\\n  tmp_14 = bf16[128,1024,1024]{2,1,0} dot(bf16[128,1024,1024]{2,1,0} tmp_11, bf16[128,1024,1024]{2,1,0} tmp_13), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}\\n  ROOT tmp_15 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[128,1024,1024]{2,1,0} tmp_14)\\n}\"\n   result {\n     gemm {\n@@ -50,7 +50,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB\"\n+  device: \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: 2039 GB/s, L2 cache: 40 MB, DNN version: 1.2.3\"\n   hlo: \"(bf16[128,1024,1024]{2,1,0}, s8[4194304]{0}) custom-call(bf16[128,1024,1024]{2,1,0}, bf16[128,1024,1024]{2,1,0}), custom_call_target=\\\"__cublas$gemm\\\", backend_config={\\\"force_earliest_schedule\\\":false,\\\"gemm_backend_config\\\":{\\\"alpha_imag\\\":0,\\\"alpha_real\\\":1,\\\"beta\\\":0,\\\"damax_output\\\":false,\\\"dot_dimension_numbers\\\":{\\\"lhs_batch_dimensions\\\":[\\\"0\\\"],\\\"lhs_contracting_dimensions\\\":[\\\"2\\\"],\\\"rhs_batch_dimensions\\\":[\\\"0\\\"],\\\"rhs_contracting_dimensions\\\":[\\\"1\\\"]},\\\"epilogue\\\":\\\"DEFAULT\\\",\\\"grad_x\\\":false,\\\"grad_y\\\":false,\\\"lhs_stride\\\":\\\"1048576\\\",\\\"precision_config\\\":{\\\"algorithm\\\":\\\"ALG_UNSET\\\",\\\"operand_precision\\\":[\\\"DEFAULT\\\",\\\"DEFAULT\\\"]},\\\"rhs_stride\\\":\\\"1048576\\\"},\\\"operation_queue_id\\\":\\\"0\\\",\\\"wait_on_operation_queues\\\":[]}\"\n   result {\n     run_time {\n@@ -62,7 +62,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB\"\n+  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB, DNN version: 1.2.3\"\n   hlo: \"{\\n  tmp_0 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(0)\\n  tmp_1 = bf16[] constant({...})\\n  tmp_2 = bf16[1,4,32,1024,1024]{4,3,2,1,0} broadcast(bf16[] tmp_1), dimensions={}\\n  tmp_3 = bf16[1,4,32,1024,1024]{4,3,2,1,0} multiply(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_0, bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_2)\\n  tmp_4 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_3)\\n  tmp_5 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[4,32,1024,1024]{3,2,1,0} tmp_4)\\n  tmp_6 = bf16[128,1024,1024]{2,1,0} transpose(bf16[128,1024,1024]{2,1,0} tmp_5), dimensions={0,2,1}\\n  tmp_7 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[128,1024,1024]{2,1,0} tmp_6)\\n  tmp_8 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[4,32,1024,1024]{3,2,1,0} tmp_7)\\n  tmp_9 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(1)\\n  tmp_10 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_9)\\n  tmp_11 = bf16[128,1024,1024]{2,1,0} dot(bf16[128,1024,1024]{2,1,0} tmp_8, bf16[128,1024,1024]{2,1,0} tmp_10), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}\\n  ROOT tmp_12 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[128,1024,1024]{2,1,0} tmp_11)\\n}\"\n   result {\n     gemm {\n@@ -74,7 +74,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB\"\n+  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB, DNN version: 1.2.3\"\n   hlo: \"(bf16[128,1024,1024]{2,1,0}, s8[33554432]{0}) custom-call(bf16[128,1024,1024]{2,1,0}, bf16[128,1024,1024]{2,1,0}), custom_call_target=\\\"__cublas$gemm\\\", backend_config={\\\"force_earliest_schedule\\\":false,\\\"gemm_backend_config\\\":{\\\"alpha_imag\\\":0,\\\"alpha_real\\\":1,\\\"beta\\\":0,\\\"damax_output\\\":false,\\\"dot_dimension_numbers\\\":{\\\"lhs_batch_dimensions\\\":[\\\"0\\\"],\\\"lhs_contracting_dimensions\\\":[\\\"2\\\"],\\\"rhs_batch_dimensions\\\":[\\\"0\\\"],\\\"rhs_contracting_dimensions\\\":[\\\"1\\\"]},\\\"epilogue\\\":\\\"DEFAULT\\\",\\\"grad_x\\\":false,\\\"grad_y\\\":false,\\\"lhs_stride\\\":\\\"1048576\\\",\\\"precision_config\\\":{\\\"algorithm\\\":\\\"ALG_UNSET\\\",\\\"operand_precision\\\":[\\\"DEFAULT\\\",\\\"DEFAULT\\\"]},\\\"rhs_stride\\\":\\\"1048576\\\"},\\\"operation_queue_id\\\":\\\"0\\\",\\\"wait_on_operation_queues\\\":[]}\"\n   result {\n     gemm {\n@@ -86,7 +86,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB\"\n+  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB, DNN version: 1.2.3\"\n   hlo: \"(bf16[12288,16384]{1,0}, s8[33554432]{0}) custom-call(f8e4m3fn[4096,12288]{0,1}, f8e4m3fn[4096,16384]{0,1}, f32[], f32[], f32[], f32[]), custom_call_target=\\\"__cublas$lt$matmul$f8\\\", backend_config={\\\"force_earliest_schedule\\\":false,\\\"gemm_backend_config\\\":{\\\"alpha_imag\\\":0,\\\"alpha_real\\\":0.95703125,\\\"beta\\\":0,\\\"damax_output\\\":false,\\\"dot_dimension_numbers\\\":{\\\"lhs_batch_dimensions\\\":[],\\\"lhs_contracting_dimensions\\\":[\\\"0\\\"],\\\"rhs_batch_dimensions\\\":[],\\\"rhs_contracting_dimensions\\\":[\\\"0\\\"]},\\\"epilogue\\\":\\\"DEFAULT\\\",\\\"grad_x\\\":false,\\\"grad_y\\\":false,\\\"lhs_stride\\\":\\\"50331648\\\",\\\"precision_config\\\":{\\\"algorithm\\\":\\\"ALG_UNSET\\\",\\\"operand_precision\\\":[\\\"DEFAULT\\\",\\\"DEFAULT\\\"]},\\\"rhs_stride\\\":\\\"67108864\\\"},\\\"operation_queue_id\\\":\\\"0\\\",\\\"wait_on_operation_queues\\\":[]}\"\n   result {\n     gemm {\n@@ -97,7 +97,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB\"\n+  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB, DNN version: 1.2.3\"\n   hlo: \"{\\n  tmp_0 = f8e4m3fn[12288,4096]{0,1} parameter(0)\\n  tmp_1 = f8e4m3fn[4096,16384]{0,1} parameter(1)\\n  tmp_2 = bf16[12288,16384]{1,0} dot(f8e4m3fn[12288,4096]{0,1} tmp_0, f8e4m3fn[4096,16384]{0,1} tmp_1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\\n  tmp_3 = bf16[] constant({...})\\n  tmp_4 = bf16[12288,16384]{1,0} broadcast(bf16[] tmp_3), dimensions={}\\n  ROOT tmp_5 = bf16[12288,16384]{1,0} multiply(bf16[12288,16384]{1,0} tmp_2, bf16[12288,16384]{1,0} tmp_4)\\n}\"\n   result {\n     gemm {\n@@ -109,7 +109,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB\"\n+  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB, DNN version: 1.2.3\"\n   hlo: \"{\\n  tmp_0 = f8e4m3fn[12288,4096]{0,1} parameter(0)\\n  tmp_1 = f8e4m3fn[4096,12288]{1,0} bitcast(f8e4m3fn[12288,4096]{0,1} tmp_0)\\n  tmp_2 = f8e4m3fn[4096,16384]{0,1} parameter(1)\\n  tmp_3 = bf16[12288,16384]{1,0} dot(f8e4m3fn[4096,12288]{1,0} tmp_1, f8e4m3fn[4096,16384]{0,1} tmp_2), lhs_contracting_dims={0}, rhs_contracting_dims={0}\\n  tmp_4 = bf16[] constant({...})\\n  tmp_5 = bf16[12288,16384]{1,0} broadcast(bf16[] tmp_4), dimensions={}\\n  ROOT tmp_6 = bf16[12288,16384]{1,0} multiply(bf16[12288,16384]{1,0} tmp_3, bf16[12288,16384]{1,0} tmp_5)\\n}\"\n   result {\n     gemm {\n@@ -121,7 +121,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 10.0, Cores: 148, GPU clock: 1.65 GHz, Memory bandwidth: 8192 GB/s, L2 cache: 126.5 MB\"\n+  device: \"CUDA: 10.0, Cores: 148, GPU clock: 1.65 GHz, Memory bandwidth: 8192 GB/s, L2 cache: 126.5 MB, DNN version: 1.2.3\"\n   hlo: \"{\\n  tmp_0 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(0)\\n  tmp_1 = bf16[] constant({...})\\n  tmp_2 = bf16[1,4,32,1024,1024]{4,3,2,1,0} broadcast(bf16[] tmp_1), dimensions={}\\n  tmp_3 = bf16[1,4,32,1024,1024]{4,3,2,1,0} multiply(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_0, bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_2)\\n  tmp_4 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_3)\\n  tmp_5 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[4,32,1024,1024]{3,2,1,0} tmp_4)\\n  tmp_6 = bf16[128,1024,1024]{2,1,0} transpose(bf16[128,1024,1024]{2,1,0} tmp_5), dimensions={0,2,1}\\n  tmp_7 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[128,1024,1024]{2,1,0} tmp_6)\\n  tmp_8 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[4,32,1024,1024]{3,2,1,0} tmp_7)\\n  tmp_9 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(1)\\n  tmp_10 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_9)\\n  tmp_11 = bf16[128,1024,1024]{2,1,0} dot(bf16[128,1024,1024]{2,1,0} tmp_8, bf16[128,1024,1024]{2,1,0} tmp_10), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}\\n  ROOT tmp_12 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[128,1024,1024]{2,1,0} tmp_11)\\n}\"\n   result {\n     gemm {\n@@ -133,7 +133,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 10.0, Cores: 148, GPU clock: 1.65 GHz, Memory bandwidth: 8192 GB/s, L2 cache: 126.5 MB\"\n+  device: \"CUDA: 10.0, Cores: 148, GPU clock: 1.65 GHz, Memory bandwidth: 8192 GB/s, L2 cache: 126.5 MB, DNN version: 1.2.3\"\n   hlo: \"{\\n  tmp_0 = f8e4m3fn[12288,4096]{0,1} parameter(0)\\n  tmp_1 = f8e4m3fn[4096,16384]{0,1} parameter(1)\\n  tmp_2 = bf16[12288,16384]{1,0} dot(f8e4m3fn[12288,4096]{0,1} tmp_0, f8e4m3fn[4096,16384]{0,1} tmp_1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\\n  tmp_3 = bf16[] constant({...})\\n  tmp_4 = bf16[12288,16384]{1,0} broadcast(bf16[] tmp_3), dimensions={}\\n  ROOT tmp_5 = bf16[12288,16384]{1,0} multiply(bf16[12288,16384]{1,0} tmp_2, bf16[12288,16384]{1,0} tmp_4)\\n}\"\n   result {\n     gemm {\n@@ -145,7 +145,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 10.0, Cores: 148, GPU clock: 1.965 GHz, Memory bandwidth: 7672 GB/s, L2 cache: 126.5 MB\"\n+  device: \"CUDA: 10.0, Cores: 148, GPU clock: 1.965 GHz, Memory bandwidth: 7672 GB/s, L2 cache: 126.5 MB, DNN version: 1.2.3\"\n   hlo: \"{\\n  tmp_0 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(0)\\n  tmp_1 = bf16[] constant({...})\\n  tmp_2 = bf16[1,4,32,1024,1024]{4,3,2,1,0} broadcast(bf16[] tmp_1), dimensions={}\\n  tmp_3 = bf16[1,4,32,1024,1024]{4,3,2,1,0} multiply(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_0, bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_2)\\n  tmp_4 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_3)\\n  tmp_5 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[4,32,1024,1024]{3,2,1,0} tmp_4)\\n  tmp_6 = bf16[128,1024,1024]{2,1,0} transpose(bf16[128,1024,1024]{2,1,0} tmp_5), dimensions={0,2,1}\\n  tmp_7 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[128,1024,1024]{2,1,0} tmp_6)\\n  tmp_8 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[4,32,1024,1024]{3,2,1,0} tmp_7)\\n  tmp_9 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(1)\\n  tmp_10 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_9)\\n  tmp_11 = bf16[128,1024,1024]{2,1,0} dot(bf16[128,1024,1024]{2,1,0} tmp_8, bf16[128,1024,1024]{2,1,0} tmp_10), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}\\n  ROOT tmp_12 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[128,1024,1024]{2,1,0} tmp_11)\\n}\"\n   result {\n     gemm {\n@@ -157,7 +157,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 10.0, Cores: 148, GPU clock: 1.965 GHz, Memory bandwidth: 7672 GB/s, L2 cache: 126.5 MB\"\n+  device: \"CUDA: 10.0, Cores: 148, GPU clock: 1.965 GHz, Memory bandwidth: 7672 GB/s, L2 cache: 126.5 MB, DNN version: 1.2.3\"\n   hlo: \"{\\n  tmp_0 = f8e4m3fn[12288,4096]{0,1} parameter(0)\\n  tmp_1 = f8e4m3fn[4096,16384]{0,1} parameter(1)\\n  tmp_2 = bf16[12288,16384]{1,0} dot(f8e4m3fn[12288,4096]{0,1} tmp_0, f8e4m3fn[4096,16384]{0,1} tmp_1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\\n  tmp_3 = bf16[] constant({...})\\n  tmp_4 = bf16[12288,16384]{1,0} broadcast(bf16[] tmp_3), dimensions={}\\n  ROOT tmp_5 = bf16[12288,16384]{1,0} multiply(bf16[12288,16384]{1,0} tmp_2, bf16[12288,16384]{1,0} tmp_4)\\n}\"\n   result {\n     gemm {"
        }
    ],
    "stats": {
        "total": 86,
        "additions": 59,
        "deletions": 27
    }
}