{
    "author": "akuegel",
    "message": "[XLA:GPU][XLA:CPU] Turn no-op bitcast-convert into bitcast.\n\nCurrently we lower such bitcasts into a slow copy, but there is no reason for\nthat.\n\nPiperOrigin-RevId: 798133404",
    "sha": "2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
    "files": [
        {
            "sha": "967ddb13fef41a38c7ff96e83436139dae3b042c",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/dot_algorithms_legacy_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 8,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_legacy_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_legacy_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_legacy_test.cc?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -442,14 +442,13 @@ TEST_F(BlasAlgorithmTest, Algorithm_TF32_TF32_F32_X3) {\n     case CudaComputeCapabilities::kBlackwell:\n     case CudaComputeCapabilities::kAmpere:\n     case CudaComputeCapabilities::kHopper:\n-      EXPECT_THAT(\n-          kernel_names,\n-          ::testing::UnorderedElementsAre(\n-              ::testing::HasSubstr(\"bitcast_convert_subtract\"),\n-              ::testing::HasSubstr(\"bitcast_convert_subtract\"),\n-              ::testing::HasSubstr(\"loop_select_fusion\"),\n-              ::testing::HasSubstr(\"gemm_\"), ::testing::HasSubstr(\"gemm_\"),\n-              ::testing::HasSubstr(\"gemm_\")));\n+      EXPECT_THAT(kernel_names, ::testing::UnorderedElementsAre(\n+                                    ::testing::HasSubstr(\"loop_and_subtract\"),\n+                                    ::testing::HasSubstr(\"loop_and_subtract\"),\n+                                    ::testing::HasSubstr(\"loop_select_fusion\"),\n+                                    ::testing::HasSubstr(\"gemm_\"),\n+                                    ::testing::HasSubstr(\"gemm_\"),\n+                                    ::testing::HasSubstr(\"gemm_\")));\n       break;\n     default:\n       GTEST_SKIP() << \"Unsupported compute capability: \" << cc.major"
        },
        {
            "sha": "32e60300a40364038c4cb0ce833ce748485b167e",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/dot_algorithms_test.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 24,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_test.cc?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -449,34 +449,31 @@ TEST_F(BlasAlgorithmTest, Algorithm_TF32_TF32_F32_X3) {\n       stream_executor::CudaComputeCapability::CudaComputeCapabilities;\n   switch (cc.major) {\n     case CudaComputeCapabilities::kBlackwell:\n-      EXPECT_THAT(kernel_names,\n-                  ::testing::UnorderedElementsAre(\n-                      ::testing::HasSubstr(\"bitcast_convert_subtract\"),\n-                      ::testing::HasSubstr(\"bitcast_convert_subtract\"),\n-                      ::testing::HasSubstr(\"loop_select_fusion\"),\n-                      ::testing::HasSubstr(\"tf32gemm\"),\n-                      ::testing::HasSubstr(\"tf32gemm\"),\n-                      ::testing::HasSubstr(\"tf32gemm\")));\n+      EXPECT_THAT(kernel_names, ::testing::UnorderedElementsAre(\n+                                    ::testing::HasSubstr(\"loop_and_subtract\"),\n+                                    ::testing::HasSubstr(\"loop_and_subtract\"),\n+                                    ::testing::HasSubstr(\"loop_select_fusion\"),\n+                                    ::testing::HasSubstr(\"tf32gemm\"),\n+                                    ::testing::HasSubstr(\"tf32gemm\"),\n+                                    ::testing::HasSubstr(\"tf32gemm\")));\n       break;\n     case CudaComputeCapabilities::kAmpere:\n-      EXPECT_THAT(kernel_names,\n-                  ::testing::UnorderedElementsAre(\n-                      ::testing::HasSubstr(\"bitcast_convert_subtract\"),\n-                      ::testing::HasSubstr(\"bitcast_convert_subtract\"),\n-                      ::testing::HasSubstr(\"loop_select_fusion\"),\n-                      ::testing::HasSubstr(\"cutlass_80\"),\n-                      ::testing::HasSubstr(\"cutlass_80\"),\n-                      ::testing::HasSubstr(\"cutlass_80\")));\n+      EXPECT_THAT(kernel_names, ::testing::UnorderedElementsAre(\n+                                    ::testing::HasSubstr(\"loop_and_subtract\"),\n+                                    ::testing::HasSubstr(\"loop_and_subtract\"),\n+                                    ::testing::HasSubstr(\"loop_select_fusion\"),\n+                                    ::testing::HasSubstr(\"cutlass_80\"),\n+                                    ::testing::HasSubstr(\"cutlass_80\"),\n+                                    ::testing::HasSubstr(\"cutlass_80\")));\n       break;\n     case CudaComputeCapabilities::kHopper:\n-      EXPECT_THAT(\n-          kernel_names,\n-          ::testing::UnorderedElementsAre(\n-              ::testing::HasSubstr(\"bitcast_convert_subtract\"),\n-              ::testing::HasSubstr(\"bitcast_convert_subtract\"),\n-              ::testing::HasSubstr(\"loop_select_fusion\"),\n-              ::testing::HasSubstr(\"tf32f32\"), ::testing::HasSubstr(\"tf32f32\"),\n-              ::testing::HasSubstr(\"tf32f32\")));\n+      EXPECT_THAT(kernel_names, ::testing::UnorderedElementsAre(\n+                                    ::testing::HasSubstr(\"loop_and_subtract\"),\n+                                    ::testing::HasSubstr(\"loop_and_subtract\"),\n+                                    ::testing::HasSubstr(\"loop_select_fusion\"),\n+                                    ::testing::HasSubstr(\"tf32f32\"),\n+                                    ::testing::HasSubstr(\"tf32f32\"),\n+                                    ::testing::HasSubstr(\"tf32f32\")));\n       break;\n     default:\n       GTEST_SKIP() << \"Unsupported compute capability: \" << cc.major"
        },
        {
            "sha": "1448c2d038cadb4e6f27607477bdacffe6c76f7b",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/support.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport.cc?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -642,6 +642,12 @@ CodegenDecision IsTritonSupportedInstructionImpl(\n       return CodegenDecision::Forbid(\n           \"dynamic slice is supported but not enabled yet\");\n     case HloOpcode::kBitcast:\n+      if (instr.shape().element_type() !=\n+          instr.operand(0)->shape().element_type()) {\n+        return CodegenDecision::Forbid(\"Bitcast-convert is not supported\");\n+      }\n+      return CodegenDecision(instr.shape().element_type() != S4,\n+                             \"S4 is not supported.\");\n     case HloOpcode::kBroadcast:\n     case HloOpcode::kReshape:\n     case HloOpcode::kSlice:"
        },
        {
            "sha": "b0d6c79274e71b76e40635d9e7c658b530930e74",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/support_legacy.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_legacy.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_legacy.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_legacy.cc?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -405,6 +405,11 @@ CodegenDecision IsTritonSupportedInstruction(\n           *Cast<HloDynamicSliceInstruction>(&instr));\n     }\n     case HloOpcode::kBitcast:\n+      if (instr.shape().element_type() !=\n+          instr.operand(0)->shape().element_type()) {\n+        return CodegenDecision::Forbid(\"Bitcast-convert is not supported\");\n+      }\n+      return CodegenDecision::Allow();\n     case HloOpcode::kTranspose:\n     case HloOpcode::kSlice:\n     case HloOpcode::kReshape:"
        },
        {
            "sha": "2d343747d6a3f81e5a1acbf0deef520a1c4d6f0a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/support_test.cc",
            "status": "modified",
            "additions": 36,
            "deletions": 0,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_test.cc?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -2508,6 +2508,42 @@ ENTRY triton_computation {\n   RunSupportTest(std::move(ti), output_tile_sizes, cc);\n }\n \n+TEST_P(BitcastConvertTest, BitcastConvertDisguisedAsBitcast) {\n+  auto [data_type_in, data_type_out, cc] = GetParam();\n+\n+  if (primitive_util::IsComplexType(data_type_in) !=\n+      primitive_util::IsComplexType(data_type_out)) {\n+    GTEST_SKIP()\n+        << \"BitcastConvert does not support complex <-> real conversion.\";\n+  }\n+\n+  const int bit_width_in = primitive_util::BitWidth(data_type_in);\n+  const int bit_width_out = primitive_util::BitWidth(data_type_out);\n+  if (bit_width_in != bit_width_out) {\n+    GTEST_SKIP() << \"We don't replace bitcast-convert with bitcast if the \"\n+                    \"bitwidth is different\";\n+  }\n+  const std::string data_type_in_str =\n+      primitive_util::LowercasePrimitiveTypeName(data_type_in);\n+  const std::string data_type_out_str =\n+      primitive_util::LowercasePrimitiveTypeName(data_type_out);\n+\n+  std::string hlo_text = absl::Substitute(\n+      R\"(\n+ENTRY triton_computation {\n+  parameter = $0[33,68] parameter(0)\n+  ROOT bc_convert = $1[33,68] bitcast(parameter)\n+})\",\n+      data_type_in_str, data_type_out_str);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(TestedInstruction ti,\n+                          ParseTemplateAndGetInstruction(hlo_text, data_type_in,\n+                                                         HloOpcode::kBitcast));\n+\n+  std::vector<int64_t> output_tile_sizes = {1, 32};\n+  RunSupportTest(std::move(ti), output_tile_sizes, cc);\n+}\n+\n INSTANTIATE_TEST_SUITE_P(\n     BitcastConvertSuite, BitcastConvertTest,\n     ::testing::Combine(::testing::ValuesIn(AllXlaDataTypes()),"
        },
        {
            "sha": "3ddd52f9c833aca6dba968999023be5ffcc235cb",
            "filename": "third_party/xla/xla/codegen/emitters/elemental_hlo_to_mlir.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Felemental_hlo_to_mlir.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Felemental_hlo_to_mlir.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Felemental_hlo_to_mlir.cc?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -1172,6 +1172,13 @@ absl::StatusOr<SmallVector<Value, 1>> HloToMlir(\n     case HloOpcode::kConvert:\n       return EmitConvert(instr, arg_types, operands, builder);\n     case HloOpcode::kBitcast:\n+      // Handle bitcasts that are actually a bitcast-convert.\n+      if (element_type != instr->operand(0)->shape().element_type()) {\n+        return MapHloOp<mhlo::BitcastConvertOp>(\n+            PrimitiveTypeToMlirType(element_type, builder), arg_types, operands,\n+            /*attributes=*/{}, builder);\n+      }\n+      return operands;\n     case HloOpcode::kCopy:\n     case HloOpcode::kSlice:\n     case HloOpcode::kBroadcast:"
        },
        {
            "sha": "f82cb624ffde2d8a23d5424ba13af06fde8e253c",
            "filename": "third_party/xla/xla/codegen/emitters/tests/loop/bitcast_add.hlo",
            "status": "added",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Floop%2Fbitcast_add.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Floop%2Fbitcast_add.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Floop%2Fbitcast_add.hlo?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -0,0 +1,12 @@\n+// RUN: gpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize | FileCheck %s\n+// RUN: cpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize | FileCheck %s\n+// RUN: gpu_test_correctness %s\n+// RUN: cpu_test_correctness %s\n+\n+fusion {\n+  input = f16[20] parameter(0)\n+  bitcast = s16[4,5] bitcast(input)\n+  ROOT add = s16[4,5] add(bitcast, bitcast)\n+}\n+// CHECK: arith.bitcast\n+// CHECK: arith.addi"
        },
        {
            "sha": "46e3bda0eefafc632cf69506b831e05e52559a3b",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/algebraic_simplifier.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier.cc?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -1626,6 +1626,16 @@ absl::Status AlgebraicSimplifierVisitor::HandleBitcastConvert(\n   if (replaced) {\n     return absl::OkStatus();\n   }\n+  if (options_.is_layout_sensitive() &&\n+      options_.rewrite_no_op_bitcast_convert_to_bitcast() &&\n+      // Equal shape ignoring element type implies same bitwidth, as for\n+      // different bitwidth shape inference would yield a different shape for\n+      // the output. A bitcast-convert with same shape but different bitwidth\n+      // would fail the HloVerifier.\n+      ShapeUtil::EqualIgnoringElementType(bitcast->shape(), operand->shape())) {\n+    ReplaceWithBitcast(bitcast);\n+    return absl::OkStatus();\n+  }\n   // Eliminate bitcast converts between same shape.\n   ReplaceInstructionIfCompatible(bitcast, bitcast->mutable_operand(0));\n   return absl::OkStatus();"
        },
        {
            "sha": "d55d927cd14a96b565d42ffa495b3753c82e8113",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/algebraic_simplifier.h",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier.h?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -355,6 +355,14 @@ class AlgebraicSimplifierOptions {\n \n   void set_run_to_fixed_point(bool value) { run_to_fixed_point_ = value; }\n \n+  bool rewrite_no_op_bitcast_convert_to_bitcast() const {\n+    return rewrite_no_op_bitcast_convert_to_bitcast_;\n+  }\n+\n+  void set_rewrite_no_op_bitcast_convert_to_bitcast(bool value) {\n+    rewrite_no_op_bitcast_convert_to_bitcast_ = value;\n+  }\n+\n  private:\n   // Metadata struct can be used to store any metadata information encapsulated\n   // with the AlgebraicSimplifierOptions that can be later used in an\n@@ -401,6 +409,7 @@ class AlgebraicSimplifierOptions {\n   bool enable_onednn_support_{false};\n   bool rewrite_reshape_transpose_as_slice_concatenate_{true};\n   bool run_to_fixed_point_{true};\n+  bool rewrite_no_op_bitcast_convert_to_bitcast_{false};\n   Metadata metadata_;\n };\n "
        },
        {
            "sha": "3ceda23bba523f7a4508dbb085ae5f8f0f8c468f",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/algebraic_simplifier_test.cc",
            "status": "modified",
            "additions": 38,
            "deletions": 0,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier_test.cc?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -11394,6 +11394,44 @@ TEST_F(AlgebraicSimplifierTest, SimplifyTautologicalBitcastConvert) {\n               GmockMatch(m::Parameter(0)));\n }\n \n+TEST_F(AlgebraicSimplifierTest,\n+       SimplifyBitcastConvertWithSameShapeIgnoringElementType) {\n+  constexpr absl::string_view kModuleStr = R\"(\n+    HloModule m\n+\n+    ENTRY test {\n+      p0 = s32[10] parameter(0)\n+      ROOT out = u32[10] bitcast-convert(p0)\n+    }\n+  )\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto m, ParseAndReturnVerifiedModule(kModuleStr));\n+  AlgebraicSimplifierOptions options;\n+  ASSERT_FALSE(AlgebraicSimplifier(options).Run(m.get()).value());\n+  options.set_is_layout_sensitive(true);\n+  ASSERT_FALSE(AlgebraicSimplifier(options).Run(m.get()).value());\n+  options.set_rewrite_no_op_bitcast_convert_to_bitcast(true);\n+  ASSERT_TRUE(AlgebraicSimplifier(options).Run(m.get()).value());\n+  EXPECT_THAT(m->entry_computation()->root_instruction(),\n+              GmockMatch(m::Bitcast()));\n+}\n+\n+TEST_F(AlgebraicSimplifierTest,\n+       DoNotSimplifyBitcastConvertIfDifferentBitwidth) {\n+  constexpr absl::string_view kModuleStr = R\"(\n+    HloModule m\n+\n+    ENTRY test {\n+      p0 = s32[10] parameter(0)\n+      ROOT out = s16[10,2] bitcast-convert(p0)\n+    }\n+  )\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto m, ParseAndReturnVerifiedModule(kModuleStr));\n+  AlgebraicSimplifierOptions options;\n+  options.set_is_layout_sensitive(true);\n+  options.set_rewrite_no_op_bitcast_convert_to_bitcast(true);\n+  EXPECT_FALSE(AlgebraicSimplifier(options).Run(m.get()).value());\n+}\n+\n TEST_F(AlgebraicSimplifierTest, SimplifyBitcastConvertChain) {\n   constexpr absl::string_view kModuleStr = R\"(\n     HloModule m"
        },
        {
            "sha": "b04c15ba906783b9a6af195a62674b50e921bca1",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -473,6 +473,7 @@ std::unique_ptr<HloPassFix<HloPassPipeline>> CreateSimplificationPipeline(\n   options.set_supports_non_canonical_dots(false);\n   options.set_executing_on_cpu(true);\n   options.set_enable_onednn_support(is_onednn_compatible);\n+  options.set_rewrite_no_op_bitcast_convert_to_bitcast(true);\n   pipeline->AddPass<AlgebraicSimplifier>(options);\n   pipeline->AddPass<SortSimplifier>();\n   pipeline->AddPass<HloDCE>();\n@@ -947,6 +948,7 @@ absl::Status CpuCompiler::RunHloPassesAfterLayoutAssn(\n     options.set_executing_on_cpu(true);\n     // oneDNN support is currently enabled only when thunk runtime is turned off\n     options.set_enable_onednn_support(is_onednn_compatible);\n+    options.set_rewrite_no_op_bitcast_convert_to_bitcast(true);\n     pipeline.AddPass<AlgebraicSimplifier>(options);\n     pipeline.AddPass<HloDCE>();\n     pipeline.AddPass<HloCSE>(/*is_layout_sensitive=*/true);"
        },
        {
            "sha": "b722e0916a1d917c252ecf65e0f76f1bc4f5fe23",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=2ad3f80d3dace6d61283b8e9d3939cc223bd2e3b",
            "patch": "@@ -1386,6 +1386,7 @@ AlgebraicSimplifierOptions GpuCompiler::GetAlgebraicSimplifierOptions(\n   // GPU only supports canonical convolutions.\n   opts.set_supports_non_canonical_dots(false);\n   opts.set_enable_unconditional_reduce_of_concat_replacement(false);\n+  opts.set_rewrite_no_op_bitcast_convert_to_bitcast(true);\n \n   switch (mode) {\n     case AlgebraicSimplifierMode::kPostFusionSimplification:"
        }
    ],
    "stats": {
        "total": 186,
        "additions": 154,
        "deletions": 32
    }
}