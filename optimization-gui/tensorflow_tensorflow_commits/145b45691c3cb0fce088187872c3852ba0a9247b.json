{
    "author": "olupton",
    "message": "PR #35330: Respect print_metadata option when dumping HLO\n\nImported from GitHub PR https://github.com/openxla/xla/pull/35330\n\nüìù Summary of Changes\nhttps://github.com/openxla/xla/pull/34060 caused more stack trace metadata to be included in the text representation that is used when calculating HLO module fingerprints. This trickles through into the `fingerprint_before_lhs` attribute, which is used by profiler tooling to group executions of the same program across different processes.\n\nüéØ Justification\nWithout this change, getting fingerprints to match across processes is unnecessarily difficult, requiring that (for JAX programs) all absolute Python paths and stack frames strictly match - including the parts outside the JIT.\n\nüöÄ Kind of Contribution\nüêõ Bug Fix, üß™ Tests\n\nüìä Benchmark (for Performance Improvements)\nn/a\n\nüß™ Unit Tests:\nNew unit test in `xla/service/gpu/gpu_hlo_schedule_test.cc` verifying that the fingerprint is independent of the metadata.\n\nüß™ Execution Tests:\nn/a\nCopybara import of the project:\n\n--\n9fd2ef7084f1152ebdb15757c37c0bd9e0e9e3ad by Olli Lupton <olupton@nvidia.com>:\n\nTest fingerprint_before_lhs is independent of metadata\n\nOtherwise an identical computation will get a different fingerprint if\nany part of the metadata differs. For JAX programs, this includes the\nfull Python stack trace, with full path names, above the @jax.jit-ed\nfunction. This fingerprint is used by profiler tooling to group\nexecutions of the same program across different processes.\n\nMerging this change closes #35330\n\nPiperOrigin-RevId: 845675780",
    "sha": "145b45691c3cb0fce088187872c3852ba0a9247b",
    "files": [
        {
            "sha": "4b78ae2e0fe441bd1444b5d83a2c5b14a4a0018a",
            "filename": "third_party/xla/xla/service/gpu/gpu_hlo_schedule_test.cc",
            "status": "modified",
            "additions": 47,
            "deletions": 2,
            "changes": 49,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/145b45691c3cb0fce088187872c3852ba0a9247b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_hlo_schedule_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/145b45691c3cb0fce088187872c3852ba0a9247b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_hlo_schedule_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_hlo_schedule_test.cc?ref=145b45691c3cb0fce088187872c3852ba0a9247b",
            "patch": "@@ -124,12 +124,19 @@ class GpuHloScheduleTest : public HloTestBase {\n                                        GetModuleConfig(test_config));\n   }\n \n-  static bool HasValidFingerprint(HloModule* module) {\n+  static std::optional<std::string> ValidFingerprint(HloModule* module) {\n     // Verify that the fingerprint of HLO prior to LHS is present.\n     const FrontendAttributes& attrs = module->frontend_attributes();\n     auto it = attrs.map().find(kFingerprintBeforeLHS);\n     // The fingerprint is 128 bits stored as a hex string (128/4 hex digits).\n-    return it != attrs.map().end() && it->second.size() == 128 / 4;\n+    if (it != attrs.map().end() && it->second.size() == 128 / 4) {\n+      return it->second;\n+    }\n+    return std::nullopt;\n+  }\n+\n+  static bool HasValidFingerprint(HloModule* module) {\n+    return ValidFingerprint(module).has_value();\n   }\n };\n \n@@ -1792,6 +1799,44 @@ TEST_F(GpuHloScheduleTest, AsyncOps) {\n                           HloOpcode::kAsyncDone, HloOpcode::kAdd));\n }\n \n+TEST_F(GpuHloScheduleTest, MetadataIgnoredInFingerprint) {\n+  absl::string_view hlo = R\"(\n+HloModule test\n+\n+FileNames\n+1 \"$0\"\n+\n+FunctionNames\n+1 \"<module>\"\n+\n+FileLocations\n+1 {file_name_id=1 function_name_id=1 line=1 end_line=2 column=0 end_column=1}\n+\n+StackFrames\n+1 {file_location_id=1 parent_frame_id=1}\n+\n+fused_computation {\n+  param_0 = f32[1024,1024]{1,0} parameter(0)\n+  ROOT exponential.1 = f32[1024,1024]{1,0} exponential(param_0), metadata={stack_frame_id=1}\n+}\n+\n+ENTRY e {\n+  p = f32[1024,1024]{1,0} parameter(0)\n+  ROOT wrapped_exp = f32[1024,1024]{1,0} fusion(p), kind=kLoop, calls=fused_computation\n+})\";\n+  ASSERT_OK_AND_ASSIGN(auto mod1, ParseAndReturnVerifiedModule(\n+                                      absl::Substitute(hlo, \"filename1.py\")));\n+  ASSERT_OK_AND_ASSIGN(auto mod2, ParseAndReturnVerifiedModule(\n+                                      absl::Substitute(hlo, \"filename2.py\")));\n+  CHECK_OK(ScheduleGpuModule(mod1.get()).status());\n+  CHECK_OK(ScheduleGpuModule(mod2.get()).status());\n+  const std::optional<std::string> fp1 = ValidFingerprint(mod1.get());\n+  const std::optional<std::string> fp2 = ValidFingerprint(mod2.get());\n+  EXPECT_TRUE(fp1.has_value());\n+  EXPECT_TRUE(fp2.has_value());\n+  EXPECT_EQ(*fp1, *fp2);\n+}\n+\n // This test verifies that the latency hiding scheduler overlaps host memory\n // offloading (copy-start/copy-done) with computation.\n TEST_P(GpuHloScheduleParameterizedTest, CopyStartDoneScheduled) {"
        }
    ],
    "stats": {
        "total": 49,
        "additions": 47,
        "deletions": 2
    }
}