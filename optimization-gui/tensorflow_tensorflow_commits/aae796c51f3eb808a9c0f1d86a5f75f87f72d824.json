{
    "author": "EusebioDM",
    "message": "Add proto (de)serialisation for `GpuConvDescriptor`\n\nWe need `GpuConvDescriptor` to be serializable to be able to add (de)serialisation for the `ConvolutionThunk`\n\nPiperOrigin-RevId: 818581222",
    "sha": "aae796c51f3eb808a9c0f1d86a5f75f87f72d824",
    "files": [
        {
            "sha": "174049fb2fa0446e4d12138627b941a08850393b",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aae796c51f3eb808a9c0f1d86a5f75f87f72d824/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aae796c51f3eb808a9c0f1d86a5f75f87f72d824/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=aae796c51f3eb808a9c0f1d86a5f75f87f72d824",
            "patch": "@@ -1184,6 +1184,7 @@ cc_library(\n     deps = [\n         \":backend_configs_cc\",\n         \":cublas_cudnn\",\n+        \":gpu_conv_runner_proto_cc\",\n         \":stream_executor_util\",\n         \"//xla:shape_util\",\n         \"//xla:util\",\n@@ -1205,6 +1206,30 @@ cc_library(\n     ],\n )\n \n+tf_proto_library(\n+    name = \"gpu_conv_runner_proto\",\n+    srcs = [\"gpu_conv_runner.proto\"],\n+    deps = [\n+        \":backend_configs\",\n+        \"//xla:xla_data_proto\",\n+        \"//xla/tsl/protobuf:dnn_proto\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"gpu_conv_runner_test\",\n+    srcs = [\"gpu_conv_runner_test.cc\"],\n+    deps = [\n+        \":backend_configs_cc\",\n+        \":gpu_conv_runner\",\n+        \":gpu_conv_runner_proto_cc\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n cc_library(\n     name = \"gpu_norm_runner\",\n     srcs = [\"gpu_norm_runner.cc\"],"
        },
        {
            "sha": "cab867ee3e58a1a9cf12ff3f9a49277875624fa8",
            "filename": "third_party/xla/xla/service/gpu/gpu_conv_runner.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 0,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aae796c51f3eb808a9c0f1d86a5f75f87f72d824/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aae796c51f3eb808a9c0f1d86a5f75f87f72d824/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner.cc?ref=aae796c51f3eb808a9c0f1d86a5f75f87f72d824",
            "patch": "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/cublas_cudnn.h\"\n+#include \"xla/service/gpu/gpu_conv_runner.pb.h\"\n #include \"xla/service/gpu/stream_executor_util.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n@@ -652,5 +653,37 @@ absl::Status RunGpuConv(const gpu::GpuConvConfig& config,\n   }\n }\n \n+absl::StatusOr<GpuConvDescriptor> GpuConvDescriptor::FromProto(\n+    const GpuConvDescriptorProto& proto) {\n+  GpuConvDescriptor descriptor;\n+  TF_ASSIGN_OR_RETURN(descriptor.kind, CudnnConvKindFromProto(proto.kind()));\n+  descriptor.backend_config = proto.backend_config();\n+  TF_ASSIGN_OR_RETURN(descriptor.operand0_shape,\n+                      Shape::FromProto(proto.operand0_shape()));\n+  TF_ASSIGN_OR_RETURN(descriptor.operand1_shape,\n+                      Shape::FromProto(proto.operand1_shape()));\n+  TF_ASSIGN_OR_RETURN(descriptor.result_shape,\n+                      Shape::FromProto(proto.result_shape()));\n+  descriptor.scratch_size = proto.scratch_size();\n+  descriptor.window = proto.window();\n+  descriptor.dnums = proto.dnums();\n+  descriptor.feature_group_count = proto.feature_group_count();\n+  return descriptor;\n+}\n+\n+GpuConvDescriptorProto GpuConvDescriptor::ToProto() const {\n+  GpuConvDescriptorProto proto;\n+  proto.set_kind(CudnnConvKindToProto(kind));\n+  *proto.mutable_backend_config() = backend_config;\n+  *proto.mutable_operand0_shape() = operand0_shape.ToProto();\n+  *proto.mutable_operand1_shape() = operand1_shape.ToProto();\n+  *proto.mutable_result_shape() = result_shape.ToProto();\n+  proto.set_scratch_size(scratch_size);\n+  *proto.mutable_window() = window;\n+  *proto.mutable_dnums() = dnums;\n+  proto.set_feature_group_count(feature_group_count);\n+  return proto;\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "db6d2400f81336bb97fc70affac6e002c2f1b410",
            "filename": "third_party/xla/xla/service/gpu/gpu_conv_runner.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aae796c51f3eb808a9c0f1d86a5f75f87f72d824/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aae796c51f3eb808a9c0f1d86a5f75f87f72d824/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner.h?ref=aae796c51f3eb808a9c0f1d86a5f75f87f72d824",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/cublas_cudnn.h\"\n+#include \"xla/service/gpu/gpu_conv_runner.pb.h\"\n #include \"xla/shape.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/dnn.h\"\n@@ -239,6 +240,11 @@ struct GpuConvDescriptor {\n   Window window;\n   ConvolutionDimensionNumbers dnums;\n   int64_t feature_group_count;\n+\n+  static absl::StatusOr<GpuConvDescriptor> FromProto(\n+      const GpuConvDescriptorProto& proto);\n+\n+  GpuConvDescriptorProto ToProto() const;\n };\n \n // Returns the convolution configuration given a XLA HLO instruction."
        },
        {
            "sha": "0e5d81731e4ce5f872e8b80592e4ec491f50a896",
            "filename": "third_party/xla/xla/service/gpu/gpu_conv_runner.proto",
            "status": "added",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aae796c51f3eb808a9c0f1d86a5f75f87f72d824/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aae796c51f3eb808a9c0f1d86a5f75f87f72d824/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner.proto?ref=aae796c51f3eb808a9c0f1d86a5f75f87f72d824",
            "patch": "@@ -0,0 +1,20 @@\n+syntax = \"proto3\";\n+\n+package xla.gpu;\n+\n+import \"xla/service/gpu/backend_configs.proto\";\n+import \"xla/tsl/protobuf/dnn.proto\";\n+import \"xla/xla_data.proto\";\n+\n+// Serialization of xla::gpu::GpuConvDescriptor struct.\n+message GpuConvDescriptorProto {\n+  stream_executor.dnn.ConvolutionKind kind = 1;\n+  CudnnConvBackendConfig backend_config = 2;\n+  xla.ShapeProto operand0_shape = 3;\n+  xla.ShapeProto operand1_shape = 4;\n+  xla.ShapeProto result_shape = 5;\n+  int64 scratch_size = 6;\n+  xla.Window window = 7;\n+  xla.ConvolutionDimensionNumbers dnums = 8;\n+  int64 feature_group_count = 9;\n+}"
        },
        {
            "sha": "1a7333f88e7215967d8d8b7ce0b82d21b9fc98a4",
            "filename": "third_party/xla/xla/service/gpu/gpu_conv_runner_test.cc",
            "status": "added",
            "additions": 101,
            "deletions": 0,
            "changes": 101,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aae796c51f3eb808a9c0f1d86a5f75f87f72d824/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aae796c51f3eb808a9c0f1d86a5f75f87f72d824/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_conv_runner_test.cc?ref=aae796c51f3eb808a9c0f1d86a5f75f87f72d824",
            "patch": "@@ -0,0 +1,101 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/gpu_conv_runner.h\"\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"xla/service/gpu/backend_configs.pb.h\"\n+#include \"xla/service/gpu/gpu_conv_runner.pb.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n+\n+namespace xla {\n+namespace gpu {\n+namespace {\n+\n+using ::tsl::proto_testing::EqualsProto;\n+using ::tsl::proto_testing::ParseTextProtoOrDie;\n+\n+TEST(GpuConvDescriptorTest, ProtoRoundTrip) {\n+  auto proto = ParseTextProtoOrDie<GpuConvDescriptorProto>(R\"pb(\n+    kind: FORWARD\n+    backend_config {\n+      algorithm { algo_id: 1 }\n+      conv_result_scale: 1.0\n+    }\n+    operand0_shape {\n+      element_type: F32\n+      dimensions: [ 1, 1, 1, 1 ]\n+      layout {\n+        minor_to_major: [ 3, 2, 1, 0 ]\n+        tail_padding_alignment_in_elements: 1\n+      }\n+      is_dynamic_dimension: [ false, false, false, false ]\n+    }\n+    operand1_shape {\n+      element_type: F32\n+      dimensions: [ 1, 1, 1, 1 ]\n+      layout {\n+        minor_to_major: [ 3, 2, 1, 0 ]\n+        tail_padding_alignment_in_elements: 1\n+      }\n+      is_dynamic_dimension: [ false, false, false, false ]\n+    }\n+    result_shape {\n+      element_type: F32\n+      dimensions: [ 1, 1, 1, 1 ]\n+      layout {\n+        minor_to_major: [ 3, 2, 1, 0 ]\n+        tail_padding_alignment_in_elements: 1\n+      }\n+      is_dynamic_dimension: [ false, false, false, false ]\n+    }\n+    scratch_size: 1024\n+    window {\n+      dimensions {\n+        size: 1\n+        stride: 1\n+        padding_low: 0\n+        padding_high: 0\n+        window_dilation: 1\n+        base_dilation: 1\n+        window_reversal: false\n+      }\n+    }\n+    dnums {\n+      input_batch_dimension: 0\n+      input_feature_dimension: 1\n+      input_spatial_dimensions: 2\n+      kernel_input_feature_dimension: 1\n+      kernel_output_feature_dimension: 0\n+      kernel_spatial_dimensions: [ 2 ]\n+      output_batch_dimension: 0\n+      output_feature_dimension: 1\n+      output_spatial_dimensions: 2\n+    }\n+    feature_group_count: 1\n+  )pb\");\n+\n+  TF_ASSERT_OK_AND_ASSIGN(GpuConvDescriptor desc,\n+                          GpuConvDescriptor::FromProto(proto));\n+\n+  EXPECT_THAT(desc.ToProto(), EqualsProto(proto));\n+}\n+\n+}  // namespace\n+}  // namespace gpu\n+}  // namespace xla"
        }
    ],
    "stats": {
        "total": 185,
        "additions": 185,
        "deletions": 0
    }
}