{
    "author": "olegshyshkov",
    "message": "[XLA:GPU] Unify `Kernel::Launch` to always accept optional cluster dimensions.\n\nCurrently we pack and unpack the cluster dim optional without any need.\n\nPiperOrigin-RevId: 806222588",
    "sha": "a9c1fbfcac2c5288a8f8563266a22d19397f32bc",
    "files": [
        {
            "sha": "dcc35fcb497449574b5bc12ed7dbbe167fe27d91",
            "filename": "third_party/xla/xla/backends/gpu/runtime/kernel_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 6,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a9c1fbfcac2c5288a8f8563266a22d19397f32bc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a9c1fbfcac2c5288a8f8563266a22d19397f32bc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc?ref=a9c1fbfcac2c5288a8f8563266a22d19397f32bc",
            "patch": "@@ -319,13 +319,9 @@ absl::Status CustomKernelThunk::ExecuteOnStream(const ExecuteParams& params) {\n   se::KernelArgsDeviceMemoryArray args(buffer_args,\n                                        custom_kernel_.shared_memory_bytes());\n \n-  if (auto cluster = custom_kernel_.cluster_dims(); cluster.has_value()) {\n-    return kernel->Launch(custom_kernel_.thread_dims(),\n-                          custom_kernel_.block_dims(), *cluster, params.stream,\n-                          args);\n-  }\n   return kernel->Launch(custom_kernel_.thread_dims(),\n-                        custom_kernel_.block_dims(), params.stream, args);\n+                        custom_kernel_.block_dims(),\n+                        custom_kernel_.cluster_dims(), params.stream, args);\n }\n \n }  // namespace gpu"
        },
        {
            "sha": "13b42b8f61c6cf9819fc3065a1331608e19e2fe7",
            "filename": "third_party/xla/xla/service/gpu/stream_executor_util.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a9c1fbfcac2c5288a8f8563266a22d19397f32bc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fstream_executor_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a9c1fbfcac2c5288a8f8563266a22d19397f32bc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fstream_executor_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fstream_executor_util.cc?ref=a9c1fbfcac2c5288a8f8563266a22d19397f32bc",
            "patch": "@@ -409,12 +409,8 @@ absl::Status ExecuteKernelOnStream(\n       std::unique_ptr<se::KernelArgsPackedArrayBase> kernel_args,\n       se::PackKernelArgs(args, kernel.metadata()));\n \n-  if (cluster_dim.has_value()) {\n-    return kernel.Launch(dims.thread_counts_per_block(), dims.block_counts(),\n-                         cluster_dim.value(), stream, *kernel_args);\n-  }\n   return kernel.Launch(dims.thread_counts_per_block(), dims.block_counts(),\n-                       stream, *kernel_args);\n+                       cluster_dim, stream, *kernel_args);\n }\n \n // Unimplemented for integers yet."
        },
        {
            "sha": "1ab6d767d3ac64f84c60e98967c5b5ccacec7f74",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_kernel.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 9,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a9c1fbfcac2c5288a8f8563266a22d19397f32bc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_kernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a9c1fbfcac2c5288a8f8563266a22d19397f32bc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_kernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_kernel.cc?ref=a9c1fbfcac2c5288a8f8563266a22d19397f32bc",
            "patch": "@@ -100,15 +100,9 @@ absl::Status CudaKernel::Launch(const ThreadDim& thread_dims,\n \n     void** params = const_cast<void**>(packed.argument_addresses().data());\n \n-    if (cluster_dims.has_value()) {\n-      return stream->LaunchKernel(thread_dims, block_dims, cluster_dims,\n-                                  function, name(), params,\n-                                  packed.number_of_shared_bytes());\n-    } else {\n-      return stream->LaunchKernel(thread_dims, block_dims, std::nullopt,\n-                                  function, name(), params,\n-                                  packed.number_of_shared_bytes());\n-    }\n+    return stream->LaunchKernel(thread_dims, block_dims, cluster_dims, function,\n+                                name(), params,\n+                                packed.number_of_shared_bytes());\n   };\n \n   // If arguments are already packed we can just launch the kernel."
        },
        {
            "sha": "d49a88e82ed73272086ee68cb2f21695f2376c3a",
            "filename": "third_party/xla/xla/stream_executor/kernel.h",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a9c1fbfcac2c5288a8f8563266a22d19397f32bc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a9c1fbfcac2c5288a8f8563266a22d19397f32bc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h?ref=a9c1fbfcac2c5288a8f8563266a22d19397f32bc",
            "patch": "@@ -236,20 +236,13 @@ class Kernel {\n   absl::Status Launch(const ThreadDim &thread_dims, const BlockDim &block_dims,\n                       Stream *stream, const KernelArgs &args);\n \n-  // Launches a data parallel kernel with the given thread/block\n-  // dimensionality and already-packed args/sizes to pass to the underlying\n-  // platform driver.\n-  absl::Status Launch(const ThreadDim &thread_dims, const BlockDim &block_dims,\n-                      const ClusterDim &cluster_dims, Stream *stream,\n-                      const KernelArgs &args);\n-\n- private:\n   // Helper method to launch a kernel with optional cluster dimensions.\n   virtual absl::Status Launch(const ThreadDim &thread_dims,\n                               const BlockDim &block_dims,\n                               const std::optional<ClusterDim> &cluster_dims,\n                               Stream *stream, const KernelArgs &args) = 0;\n \n+ private:\n   std::string name_;\n \n   KernelMetadata metadata_;\n@@ -261,13 +254,6 @@ inline absl::Status Kernel::Launch(const ThreadDim &thread_dims,\n                                    const KernelArgs &args) {\n   return Launch(thread_dims, block_dims, std::nullopt, stream, args);\n }\n-inline absl::Status Kernel::Launch(const ThreadDim &thread_dims,\n-                                   const BlockDim &block_dims,\n-                                   const ClusterDim &cluster_dims,\n-                                   Stream *stream, const KernelArgs &args) {\n-  return Launch(thread_dims, block_dims, std::make_optional(cluster_dims),\n-                stream, args);\n-}\n \n //===----------------------------------------------------------------------===//\n // Typed kernel"
        },
        {
            "sha": "cc10638d09c78cc8904bed75b0457742b255fb45",
            "filename": "third_party/xla/xla/stream_executor/rocm/rocm_kernel.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 9,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a9c1fbfcac2c5288a8f8563266a22d19397f32bc/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_kernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a9c1fbfcac2c5288a8f8563266a22d19397f32bc/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_kernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_kernel.cc?ref=a9c1fbfcac2c5288a8f8563266a22d19397f32bc",
            "patch": "@@ -98,15 +98,9 @@ absl::Status RocmKernel::Launch(const ThreadDim& thread_dims,\n \n     void** params = const_cast<void**>(packed.argument_addresses().data());\n \n-    if (cluster_dims.has_value()) {\n-      return stream->LaunchKernel(thread_dims, block_dims, cluster_dims,\n-                                  function, name(), params,\n-                                  packed.number_of_shared_bytes());\n-    } else {\n-      return stream->LaunchKernel(thread_dims, block_dims, std::nullopt,\n-                                  function, name(), params,\n-                                  packed.number_of_shared_bytes());\n-    }\n+    return stream->LaunchKernel(thread_dims, block_dims, cluster_dims, function,\n+                                name(), params,\n+                                packed.number_of_shared_bytes());\n   };\n \n   // If arguments are already packed we can just launch the kernel."
        }
    ],
    "stats": {
        "total": 54,
        "additions": 10,
        "deletions": 44
    }
}