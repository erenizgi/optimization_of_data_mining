{
    "author": "ezhulenev",
    "message": "[xla:cpu] Do not serialize buffer assignment to proto when registering module for debugging\n\nPiperOrigin-RevId: 797144421",
    "sha": "ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b",
    "files": [
        {
            "sha": "a8962fc45a789b7784be3932f86b065fad5af78a",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b",
            "patch": "@@ -5363,21 +5363,17 @@ cc_library(\n \n cc_library(\n     name = \"xla_debug_info_manager\",\n-    srcs = [\n-        \"xla_debug_info_manager.cc\",\n-    ],\n-    hdrs = [\n-        \"xla_debug_info_manager.h\",\n-    ],\n+    srcs = [\"xla_debug_info_manager.cc\"],\n+    hdrs = [\"xla_debug_info_manager.h\"],\n     deps = [\n         \":hlo_proto_cc\",\n         \":hlo_proto_util\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:buffer_assignment\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/synchronization\",\n-        \"@local_tsl//tsl/platform:status\",\n     ],\n )\n \n@@ -5390,6 +5386,7 @@ xla_cc_test(\n         \":xla_debug_info_manager\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/service:buffer_assignment\",\n         \"//xla/tests:xla_internal_test_main\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/synchronization\","
        },
        {
            "sha": "863c691d64a4a8789c1f7d41a994334fae927814",
            "filename": "third_party/xla/xla/service/cpu/cpu_executable.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_executable.cc?ref=ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b",
            "patch": "@@ -157,8 +157,7 @@ CpuExecutable::CpuExecutable(\n                  std::move(hlo_profile_index_map)),\n       assignment_(std::move(assignment)) {\n   if (assignment_ && has_module()) {\n-    XlaDebugInfoManager::Get()->RegisterModule(shared_module(),\n-                                               assignment_->ToProto());\n+    XlaDebugInfoManager::Get()->RegisterModule(shared_module(), assignment_);\n   }\n \n   // Once we compiled HLO module to CPU executable, we don't need to keep the"
        },
        {
            "sha": "9cd0fe232b2adb5cf2b8a1cdabb99bd8d38967c2",
            "filename": "third_party/xla/xla/service/cpu/cpu_executable.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_executable.h?ref=ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b",
            "patch": "@@ -220,7 +220,7 @@ class CpuExecutable : public Executable {\n       symbol_type_id_to_function_type_id_;\n \n   // Buffer assignment for the buffers we need to allocate.\n-  const std::unique_ptr<const BufferAssignment> assignment_;\n+  std::shared_ptr<const BufferAssignment> assignment_;\n \n   // The LLVM IR, in string format, of the unoptimized module generated for this\n   // CpuExecutable. We save a string instead of an llvm::Module* because leaving"
        },
        {
            "sha": "8ca8294d9e659dd92e2f719e969458769aaab7d9",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc?ref=ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b",
            "patch": "@@ -171,7 +171,7 @@ GpuExecutable::GpuExecutable(GpuExecutable::Params params)\n   }\n   if (has_module() && enable_debug_info_manager_) {\n     XlaDebugInfoManager::Get()->RegisterModule(shared_module(),\n-                                               buffer_assignment_->ToProto());\n+                                               buffer_assignment_);\n   }\n }\n "
        },
        {
            "sha": "eb6f2996c2e56627ca385bbb45f7eecd61e8f522",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h?ref=ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b",
            "patch": "@@ -277,7 +277,7 @@ class GpuExecutable : public Executable {\n   // See the comment on GetAllocations().\n   //\n   // This object is also used for dumping debug info.\n-  std::unique_ptr<const xla::BufferAssignment> buffer_assignment_;\n+  std::shared_ptr<const xla::BufferAssignment> buffer_assignment_;\n \n   // Backend specific aliasing information whether operands can/should share the\n   // buffer with the user."
        },
        {
            "sha": "b5aefce3af5f42e447f9f2ac5c03c26f2eab56c2",
            "filename": "third_party/xla/xla/service/xla_debug_info_manager.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fxla_debug_info_manager.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fxla_debug_info_manager.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fxla_debug_info_manager.cc?ref=ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b",
            "patch": "@@ -22,14 +22,15 @@ limitations under the License.\n #include \"absl/log/check.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/service/hlo_proto_util.h\"\n \n namespace xla {\n \n void XlaDebugInfoManager::RegisterModule(\n     std::shared_ptr<const HloModule> hlo_module,\n-    BufferAssignmentProto buffer_assignment) {\n+    std::shared_ptr<const BufferAssignment> buffer_assignment) {\n   CHECK(hlo_module != nullptr);\n   absl::MutexLock lock(&mutex_);\n   auto result = modules_.try_emplace(hlo_module->unique_id());\n@@ -87,7 +88,10 @@ void XlaDebugInfoManager::StopTracing(\n     module_debug_info->clear();\n     for (const auto& m : modules_to_serialize) {\n       auto hlo_proto = std::make_unique<HloProto>(MakeHloProto(*m.hlo_module));\n-      *hlo_proto->mutable_buffer_assignment() = m.buffer_assignment;\n+      if (m.buffer_assignment != nullptr) {\n+        *hlo_proto->mutable_buffer_assignment() =\n+            m.buffer_assignment->ToProto();\n+      }\n       module_debug_info->emplace_back(std::move(hlo_proto));\n     }\n   }"
        },
        {
            "sha": "11e0e3a0dfbfcc2a1f2ae1769b256aee5cc86877",
            "filename": "third_party/xla/xla/service/xla_debug_info_manager.h",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fxla_debug_info_manager.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fxla_debug_info_manager.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fxla_debug_info_manager.h?ref=ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b",
            "patch": "@@ -17,16 +17,14 @@ limitations under the License.\n #define XLA_SERVICE_XLA_DEBUG_INFO_MANAGER_H_\n \n #include <memory>\n-#include <string>\n-#include <utility>\n #include <vector>\n \n #include \"absl/base/thread_annotations.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/hlo.pb.h\"\n-#include \"tsl/platform/status.h\"\n \n namespace xla {\n \n@@ -45,8 +43,9 @@ class XlaDebugInfoManager {\n \n   // Registers an active module to XlaDebugInfoManager.\n   // The module_id of the module is expected to be unique per process.\n-  void RegisterModule(std::shared_ptr<const HloModule> hlo_module,\n-                      BufferAssignmentProto buffer_assignment);\n+  void RegisterModule(\n+      std::shared_ptr<const HloModule> hlo_module,\n+      std::shared_ptr<const BufferAssignment> buffer_assignment);\n \n   // Unregisters an active module.\n   void UnregisterModule(ModuleIdentifier module_id);\n@@ -71,7 +70,7 @@ class XlaDebugInfoManager {\n \n   struct XlaModuleEntry {\n     std::shared_ptr<const HloModule> hlo_module;\n-    BufferAssignmentProto buffer_assignment;\n+    std::shared_ptr<const BufferAssignment> buffer_assignment;\n     bool active = false;\n   };\n "
        },
        {
            "sha": "8b8dd149ec9c6d6cf5b31a15ef72c7d7ecd13221",
            "filename": "third_party/xla/xla/service/xla_debug_info_manager_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fxla_debug_info_manager_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b/third_party%2Fxla%2Fxla%2Fservice%2Fxla_debug_info_manager_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fxla_debug_info_manager_test.cc?ref=ba0a1ab1a8ed850d9e4dae5a0cbef37b97fbed8b",
            "patch": "@@ -25,15 +25,17 @@ limitations under the License.\n #include \"absl/synchronization/mutex.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/service/hlo_module_config.h\"\n \n namespace xla {\n \n class XlaDebugInfoManagerTestPeer {\n  public:\n-  void RegisterModule(std::shared_ptr<const HloModule> hlo_module,\n-                      BufferAssignmentProto buffer_assignment) {\n+  void RegisterModule(\n+      std::shared_ptr<const HloModule> hlo_module,\n+      std::shared_ptr<const BufferAssignment> buffer_assignment) {\n     return xla_debug_info_manager_.RegisterModule(hlo_module,\n                                                   std::move(buffer_assignment));\n   }\n@@ -88,8 +90,7 @@ class XlaDebugInfoManagerTest : public HloHardwareIndependentTestBase {\n     debug_info.module = std::make_shared<HloModule>(module_name, config);\n     ModuleIdentifier unique_id = debug_info.module->unique_id();\n     debug_info.unique_id = unique_id;\n-    xla_debug_info_manager_.RegisterModule(debug_info.module,\n-                                           BufferAssignmentProto());\n+    xla_debug_info_manager_.RegisterModule(debug_info.module, nullptr);\n     external_references_.push_back(std::move(debug_info));\n     return unique_id;\n   }"
        }
    ],
    "stats": {
        "total": 48,
        "additions": 24,
        "deletions": 24
    }
}