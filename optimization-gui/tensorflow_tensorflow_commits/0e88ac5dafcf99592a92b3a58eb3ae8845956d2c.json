{
    "author": "akhilgoe",
    "message": "PR #32800: [XLA:CPU][oneDNN] Undo proto workarounds after switching to thunks based execution\n\nImported from GitHub PR https://github.com/openxla/xla/pull/32800\n\nThis PR removes the proto workarounds that were added to make the code work with the legacy runtime. Specifically, it undoes:\n1. Using 1-based indexing for proto repeated fields.\n2. Type punning for floats.\n\nCopybara import of the project:\n\n--\n21c6726ba769ffa28fcf16242927b7aeda21eed7 by Akhil Goel <akhil.goel@intel.com>:\n\nUndo proto workarounds\n\nMerging this change closes #32800\n\nPiperOrigin-RevId: 827995246",
    "sha": "0e88ac5dafcf99592a92b3a58eb3ae8845956d2c",
    "files": [
        {
            "sha": "3900fdc388408d288fe7e8c5ce7ceedd35597c6c",
            "filename": "third_party/xla/xla/backends/cpu/runtime/onednn/onednn_op_thunk_test.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 25,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk_test.cc?ref=0e88ac5dafcf99592a92b3a58eb3ae8845956d2c",
            "patch": "@@ -114,12 +114,6 @@ TEST(OneDnnOpThunkTest, SimpleOneDnnMatMulThunk) {\n // Input: 1x3x3x1, Kernel: 2x2x1x1 with values [[1,0],[0,1]] (HWIO).\n // Output (valid conv): each element = top-left + bottom-right of 2x2 patch:\n // [[1+5, 2+6], [4+8, 5+9]] = [[6, 8], [12, 14]].\n-// Layout metadata uses one-based spatial dim indices.\n-// Window parameter encoding (matches runtime expectations defined in\n-// onednn_contraction_rewriter.cc):\n-//   strides stored as (actual + 1)\n-//   pads stored as (actual + 1)\n-//   dilations stored as (actual + 1).\n TEST(OneDnnOpThunkTest, SimpleOneDnnConvolutionThunk) {\n   tsl::thread::ThreadPool threads(tsl::Env::Default(), \"test\", 4);\n   Eigen::ThreadPoolDevice device(threads.AsEigenThreadPool(),\n@@ -176,44 +170,39 @@ TEST(OneDnnOpThunkTest, SimpleOneDnnConvolutionThunk) {\n   OneDnnDataLayoutProto* inp_data = inp->mutable_data();\n   inp_data->set_batch_dim(0);\n   inp_data->set_feature_dim(3);\n-  // Spatial dims stored as one-based (so 1->2, 2->3).\n+  inp_data->add_spatial_dims(1);\n   inp_data->add_spatial_dims(2);\n-  inp_data->add_spatial_dims(3);\n \n   // Kernel layout assumed HWIO (H,W,In,Out):\n   OneDnnTensorLayoutProto* ker = conv_config.mutable_kernel();\n   ker->set_dims(4);\n   OneDnnFilterLayoutProto* filter = ker->mutable_filter();\n-  filter->set_input_feature_dim(2);   // zero-based index of IC\n-  filter->set_output_feature_dim(3);  // zero-based index of OC\n-  // Spatial dims (H,W) one-based: (0->1,1->2) => 1,2\n+  filter->set_input_feature_dim(2);\n+  filter->set_output_feature_dim(3);\n+  filter->add_spatial_dims(0);\n   filter->add_spatial_dims(1);\n-  filter->add_spatial_dims(2);\n \n   // Output layout NHWC\n   OneDnnTensorLayoutProto* out = conv_config.mutable_output();\n   out->set_dims(4);\n   OneDnnDataLayoutProto* out_data = out->mutable_data();\n   out_data->set_batch_dim(0);\n   out_data->set_feature_dim(3);\n+  out_data->add_spatial_dims(1);\n   out_data->add_spatial_dims(2);\n-  out_data->add_spatial_dims(3);\n \n   conv_config.set_feature_groups(1);\n \n-  // Window parameters: stride=1, pad=0, dilation=1 encoded with offsets.\n+  // Window parameters: stride=1, pad=0, dilation=1.\n   OneDnnWindowProto* win = conv_config.mutable_window();\n-  // Store (actual + 1) for strides so 2 -> (2 - 1 = 1 real stride).\n-  win->add_strides(2);\n-  win->add_strides(2);\n-  // Pads store (actual +1) so 1 -> 0 actual pad.\n-  win->add_pad_left(1);\n-  win->add_pad_left(1);\n-  win->add_pad_right(1);\n-  win->add_pad_right(1);\n-  // Dilations store (actual +1) so 2 -> 1 actual dilation.\n-  win->add_window_dilations(2);\n-  win->add_window_dilations(2);\n+  win->add_strides(1);\n+  win->add_strides(1);\n+  win->add_pad_left(0);\n+  win->add_pad_left(0);\n+  win->add_pad_right(0);\n+  win->add_pad_right(0);\n+  win->add_window_dilations(1);\n+  win->add_window_dilations(1);\n \n   // Set up op buffers\n   OneDnnOpThunk::OpBuffers op_buffers;"
        },
        {
            "sha": "85b46db3793e707dd1e371d3bf95b23e46be74c2",
            "filename": "third_party/xla/xla/service/cpu/onednn_config.proto",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_config.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_config.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_config.proto?ref=0e88ac5dafcf99592a92b3a58eb3ae8845956d2c",
            "patch": "@@ -54,9 +54,8 @@ message OneDnnFusionConfig {\n     SWISH = 12;\n   }\n   repeated FusionKind ops = 1;\n-  // To avoid protobuf failures for specific decimal values,\n-  // the original float value alpha is type-casted to int32.\n-  repeated int32 alpha_typecast = 2;\n+  reserved 2;  // was alpha_typecast\n+  repeated float alpha = 3;\n }\n \n message OneDnnTensorLayoutProto {"
        },
        {
            "sha": "a530fc45da296972a696cd90d3016e2f13b33c9c",
            "filename": "third_party/xla/xla/service/cpu/onednn_contraction_rewriter.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 13,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc?ref=0e88ac5dafcf99592a92b3a58eb3ae8845956d2c",
            "patch": "@@ -679,22 +679,20 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n           (*it).window_reversal()) {\n         return absl::OkStatus();\n       }\n-      // Changing the input subspace of uint repeated fields from whole numbers\n-      // to natural nummbers to avoid misinterpretation of buffer values.\n-      conv_config->mutable_window()->add_pad_left((*it).padding_low() + 1);\n-      conv_config->mutable_window()->add_pad_right((*it).padding_high() + 1);\n-      conv_config->mutable_window()->add_strides((*it).stride() + 1);\n+      conv_config->mutable_window()->add_pad_left((*it).padding_low());\n+      conv_config->mutable_window()->add_pad_right((*it).padding_high());\n+      conv_config->mutable_window()->add_strides((*it).stride());\n       conv_config->mutable_window()->add_window_dilations(\n-          (*it).window_dilation() + 1);\n+          (*it).window_dilation());\n     }\n \n     for (int i = 0; i < dims; i++) {\n       conv_config->mutable_input()->mutable_data()->add_spatial_dims(\n-          conv_dims.input_spatial_dimensions()[i] + 1);\n+          conv_dims.input_spatial_dimensions()[i]);\n       conv_config->mutable_kernel()->mutable_filter()->add_spatial_dims(\n-          conv_dims.kernel_spatial_dimensions()[i] + 1);\n+          conv_dims.kernel_spatial_dimensions()[i]);\n       conv_config->mutable_output()->mutable_data()->add_spatial_dims(\n-          conv_dims.output_spatial_dimensions()[i] + 1);\n+          conv_dims.output_spatial_dimensions()[i]);\n     }\n \n     HloInstruction* custom_call =\n@@ -1065,10 +1063,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n       auto backend_config = custom_call->backend_config<BackendConfig>();\n       auto fusions_config = GetFusionsConfig(&backend_config);\n       fusions_config->add_ops(OneDnnFusionConfig::LINEAR);\n-      // Casting to int32 because of issues in proto config for decimal types\n-      // handling.\n-      fusions_config->add_alpha_typecast(\n-          *(reinterpret_cast<int32_t*>(&constant_value.value())));\n+      fusions_config->add_alpha(constant_value.value());\n       TF_RETURN_IF_ERROR(custom_call->set_backend_config(*backend_config));\n       HloInstruction* new_instr;\n       if (optional_convert != nullptr &&"
        },
        {
            "sha": "3065c22ad21dba1ff9cfaafe1944e498835e25b7",
            "filename": "third_party/xla/xla/service/cpu/onednn_convolution.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 12,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_convolution.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_convolution.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_convolution.cc?ref=0e88ac5dafcf99592a92b3a58eb3ae8845956d2c",
            "patch": "@@ -56,7 +56,7 @@ using dnnl::prop_kind;\n using dnnl::stream;\n \n memory::dims GetPrimitiveParameter(\n-    const tsl::protobuf::RepeatedField<uint64_t>& field, int offset) {\n+    const tsl::protobuf::RepeatedField<uint64_t>& field, int offset = 0) {\n   memory::dims param_field(field.begin(), field.end());\n   // Subtract the offset so that values are interpreted accurately\n   for (int64_t& n : param_field) {\n@@ -73,7 +73,7 @@ std::vector<int> ComputePermutations(\n   perm_axes[dim1] = 1;\n   int index = 2;\n   for (uint64_t n : spatial_dims) {\n-    perm_axes[n - 1] = index++;\n+    perm_axes[n] = index++;\n   }\n   return perm_axes;\n }\n@@ -134,14 +134,13 @@ CreateOneDnnPrimDesc<dnnl::convolution_forward::primitive_desc>(\n   memory::desc weights_md = ShapeToMemDesc(weight_shape);\n   memory::desc output_md = ShapeToMemDesc(output_shape);\n \n-  memory::dims strides =\n-      GetPrimitiveParameter(conv_config.window().strides(), 1);\n+  memory::dims strides = GetPrimitiveParameter(conv_config.window().strides());\n   memory::dims pad_left =\n-      GetPrimitiveParameter(conv_config.window().pad_left(), 1);\n+      GetPrimitiveParameter(conv_config.window().pad_left());\n   memory::dims pad_right =\n-      GetPrimitiveParameter(conv_config.window().pad_right(), 1);\n+      GetPrimitiveParameter(conv_config.window().pad_right());\n   memory::dims rhs_dilations =\n-      GetPrimitiveParameter(conv_config.window().window_dilations(), 2);\n+      GetPrimitiveParameter(conv_config.window().window_dilations(), 1);\n \n   uint64_t groups = conv_config.feature_groups();\n \n@@ -241,14 +240,13 @@ void ExecuteOneDnnConvolution(absl::Span<MemrefInfoHandler> arguments,\n       conv_config.output().data().feature_dim(),\n       conv_config.output().data().spatial_dims()));\n \n-  memory::dims strides =\n-      GetPrimitiveParameter(conv_config.window().strides(), 1);\n+  memory::dims strides = GetPrimitiveParameter(conv_config.window().strides());\n   memory::dims pad_left =\n-      GetPrimitiveParameter(conv_config.window().pad_left(), 1);\n+      GetPrimitiveParameter(conv_config.window().pad_left());\n   memory::dims pad_right =\n-      GetPrimitiveParameter(conv_config.window().pad_right(), 1);\n+      GetPrimitiveParameter(conv_config.window().pad_right());\n   memory::dims rhs_dilations =\n-      GetPrimitiveParameter(conv_config.window().window_dilations(), 2);\n+      GetPrimitiveParameter(conv_config.window().window_dilations(), 1);\n \n   uint64_t groups = conv_config.feature_groups();\n "
        },
        {
            "sha": "46519fadafc8b68b58ac807e07f635cf07b01084",
            "filename": "third_party/xla/xla/service/cpu/onednn_util.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_util.cc?ref=0e88ac5dafcf99592a92b3a58eb3ae8845956d2c",
            "patch": "@@ -114,9 +114,7 @@ dnnl::post_ops PopulateOneDnnPostOps(\n         fused_operand_idx++;\n       } break;\n       case OneDnnFusionConfig::LINEAR: {\n-        float const_float;\n-        *(reinterpret_cast<int32_t*>(&const_float)) =\n-            fusion_config->alpha_typecast()[linear_scale_idx];\n+        float const_float = fusion_config->alpha()[linear_scale_idx];\n         post_ops.append_eltwise(dnnl::algorithm::eltwise_linear, const_float,\n                                 0.f);\n         linear_scale_idx++;"
        },
        {
            "sha": "d60c1c2ae3593948f9e40bbe4a68960ea74decb2",
            "filename": "third_party/xla/xla/service/cpu/tests/onednn_convolution_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_convolution_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e88ac5dafcf99592a92b3a58eb3ae8845956d2c/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_convolution_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_convolution_test.cc?ref=0e88ac5dafcf99592a92b3a58eb3ae8845956d2c",
            "patch": "@@ -300,20 +300,20 @@ TEST_P(ConvolutionTest, ConvInsufficientScratchTest) {\n             \"dims\":\"3\",\n             \"input\":{\n               \"dims\":\"3\",\n-              \"data\":{\"batch_dim\":\"0\",\"feature_dim\":\"2\",\"spatial_dims\":[\"2\"]}\n+              \"data\":{\"batch_dim\":\"0\",\"feature_dim\":\"2\",\"spatial_dims\":[\"1\"]}\n             },\n             \"kernel\":{\n               \"dims\":\"3\",\n               \"filter\":{\"input_feature_dim\":\"1\",\"output_feature_dim\":\"2\",\n-                \"spatial_dims\":[\"1\"],\"shape\":[]}\n+                \"spatial_dims\":[\"0\"],\"shape\":[]}\n             },\n             \"output\":{\n               \"dims\":\"3\",\n-              \"data\":{\"batch_dim\":\"0\",\"feature_dim\":\"2\",\"spatial_dims\":[\"2\"]}\n+              \"data\":{\"batch_dim\":\"0\",\"feature_dim\":\"2\",\"spatial_dims\":[\"1\"]}\n             },\n             \"window\":{\n-              \"size\":[],\"pad_left\":[\"1\"],\"pad_right\":[\"1\"],\n-              \"strides\":[\"2\"],\"window_dilations\":[\"2\"]\n+              \"size\":[],\"pad_left\":[\"0\"],\"pad_right\":[\"0\"],\n+              \"strides\":[\"1\"],\"window_dilations\":[\"1\"]\n             },\n             \"feature_groups\":\"1\",\n             \"optimization_config\":{\"user_scratchpad\":true}"
        }
    ],
    "stats": {
        "total": 101,
        "additions": 40,
        "deletions": 61
    }
}