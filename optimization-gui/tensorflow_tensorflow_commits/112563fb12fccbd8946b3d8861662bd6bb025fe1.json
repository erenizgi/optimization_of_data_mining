{
    "author": "unknown",
    "message": "Improve CallInliner policy callback to enable ignoring frontend attributes.\n\nPiperOrigin-RevId: 827428862",
    "sha": "112563fb12fccbd8946b3d8861662bd6bb025fe1",
    "files": [
        {
            "sha": "12f9e70912773df4d685c817f345fb27e1ce931d",
            "filename": "third_party/xla/xla/service/call_inliner.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 9,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/112563fb12fccbd8946b3d8861662bd6bb025fe1/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/112563fb12fccbd8946b3d8861662bd6bb025fe1/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc?ref=112563fb12fccbd8946b3d8861662bd6bb025fe1",
            "patch": "@@ -262,7 +262,7 @@ bool InlineComposites(\n \n // Introduces a specific attribute so that the frontend has the direct\n // control over inlining specific calls.\n-bool InlineInstruction(HloInstruction* instruction) {\n+bool FrontendAttributesAllowInlining(HloInstruction* instruction) {\n   auto it = instruction->frontend_attributes().map().find(\"inlineable\");\n   if (it != instruction->frontend_attributes().map().end()) {\n     return it->second == \"true\";\n@@ -325,11 +325,6 @@ bool CallInliner::IsInlineableCallOp(HloInstruction* instruction) const {\n   if (!prerequisite) {\n     return false;\n   }\n-  if (!InlineInstruction(instruction)) {\n-    // Always prioritize user's explicit requests after fulfilling the\n-    // prerequisites.\n-    return false;\n-  }\n   if (instruction->GetModule()->config().use_shardy_partitioner() &&\n       (absl::StrContains(instruction->to_apply()->name(), \"shmap_body\") ||\n        absl::StrContains(instruction->to_apply()->name(),\n@@ -352,16 +347,30 @@ bool CallInliner::IsInlineableCallOp(HloInstruction* instruction) const {\n \n bool CallInliner::ShouldInline(const CallGraph& call_graph,\n                                HloInstruction* instruction) const {\n+  // Check this is an inlineable call op (but not frontend attributes)\n   if (!IsInlineableCallOp(instruction)) {\n     return false;\n   }\n \n-  if (should_inline_.has_value()) {\n-    if (!(*should_inline_)(call_graph, instruction)) {\n+  // Check the override policy, if any.\n+  InlineOverridePolicy policy = InlineOverridePolicy::kAllowInline;\n+  if (override_policy_.has_value()) {\n+    policy = (*override_policy_)(call_graph, instruction);\n+  }\n+\n+  // If the policy is to never inline, we're done.\n+  if (policy == InlineOverridePolicy::kProhibitInline) {\n+    return false;\n+  }\n+\n+  // If the policy is to ignore frontend attributes, do so.\n+  if (policy != InlineOverridePolicy::kAllowIgnoreFrontendAttributes) {\n+    if (!FrontendAttributesAllowInlining(instruction)) {\n       return false;\n     }\n   }\n \n+  // If we're only inlining calls with a single call site, check that.\n   if (single_call_site_) {\n     return call_graph.GetNode(instruction->to_apply())\n                .caller_callsites()\n@@ -507,7 +516,7 @@ bool IsInlineableComputation(HloComputation* computation) {\n     bool prerequisite = instruction->opcode() == HloOpcode::kCall &&\n                         !instruction->has_backend_config() &&\n                         !instruction->parent()->IsAsyncComputation();\n-    if (!prerequisite || !InlineInstruction(instruction)) {\n+    if (!prerequisite || (!FrontendAttributesAllowInlining(instruction))) {\n       return false;\n     }\n     return true;"
        },
        {
            "sha": "fb4418176d06a9280288433d3f37ad53cd607313",
            "filename": "third_party/xla/xla/service/call_inliner.h",
            "status": "modified",
            "additions": 16,
            "deletions": 8,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/112563fb12fccbd8946b3d8861662bd6bb025fe1/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/112563fb12fccbd8946b3d8861662bd6bb025fe1/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.h?ref=112563fb12fccbd8946b3d8861662bd6bb025fe1",
            "patch": "@@ -39,6 +39,13 @@ namespace xla {\n // called function, and proceed recursively.\n class CallInliner : public HloModulePass {\n  public:\n+  enum class InlineOverridePolicy {\n+    kAllowInline,                    // Allow inlining as normal.\n+    kProhibitInline,                 // Prohibit inlining of this callsite.\n+    kAllowIgnoreFrontendAttributes,  // Allow even with the 'inlineable'\n+                                     // frontend attribute is set != 'true'.\n+  };\n+\n   using InlinedInstructionMap =\n       absl::flat_hash_map<HloInstruction*, HloInstruction*>;\n \n@@ -52,19 +59,20 @@ class CallInliner : public HloModulePass {\n   // are being inlined if necessary.\n   // If `uniquify_channel_ids` is true, the channel ids of the resulting\n   // computation will be uniquified.\n-  // If the callback `should_inline` is provided, only functions callsite for\n-  // which it returns true will be inlined.\n+  // If the callback `override_policy` is provided, callsites will be inlined\n+  // according to the policy returned.\n   explicit CallInliner(\n       bool single_call_site = false, bool update_domain = false,\n       absl::flat_hash_set<std::string> composites_to_preserve = {},\n       bool uniquify_channel_ids = false,\n-      std::optional<std::function<bool(const CallGraph&, HloInstruction*)>>\n-          should_inline = std::nullopt)\n+      std::optional<std::function<InlineOverridePolicy(const CallGraph&,\n+                                                       const HloInstruction*)>>\n+          override_policy = std::nullopt)\n       : single_call_site_(single_call_site),\n         update_domain_(update_domain),\n         uniquify_channel_ids_(uniquify_channel_ids),\n         composites_to_preserve_(std::move(composites_to_preserve)),\n-        should_inline_(std::move(should_inline)) {}\n+        override_policy_(std::move(override_policy)) {}\n   ~CallInliner() override = default;\n   absl::string_view name() const override { return \"call-inliner\"; }\n \n@@ -97,9 +105,9 @@ class CallInliner : public HloModulePass {\n   bool update_domain_;\n   bool uniquify_channel_ids_;\n   absl::flat_hash_set<std::string> composites_to_preserve_;\n-  std::optional<\n-      std::function<bool(const CallGraph& call_graph, HloInstruction*)>>\n-      should_inline_;\n+  std::optional<std::function<InlineOverridePolicy(const CallGraph& call_graph,\n+                                                   const HloInstruction*)>>\n+      override_policy_;\n   int64_t next_unique_channel_id_ = 1;\n };\n "
        },
        {
            "sha": "532906d92ad2721a59221a5fec11a80ce5f59b20",
            "filename": "third_party/xla/xla/service/call_inliner_test.cc",
            "status": "modified",
            "additions": 42,
            "deletions": 3,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/112563fb12fccbd8946b3d8861662bd6bb025fe1/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/112563fb12fccbd8946b3d8861662bd6bb025fe1/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner_test.cc?ref=112563fb12fccbd8946b3d8861662bd6bb025fe1",
            "patch": "@@ -443,6 +443,40 @@ TEST_F(CallInlinerTest, DontInlineCallWithAttributeInlineableFalse) {\n   EXPECT_EQ(call->to_apply()->name(), \"test\");\n }\n \n+TEST_F(CallInlinerTest, InlineCallWithOverriddenAttributeInlineableFalse) {\n+  const char* const hloString = R\"(\n+    HloModule jit_f, entry_computation_layout={(f32[8,8]{1,0})->f32[8,8]{1,0}}\n+    %test (Arg_0.5: f32[1,8]) -> f32[1,8] {\n+      %Arg_0.5 = f32[1,8]{1,0} parameter(0)\n+      ROOT %add.6 = f32[1,8]{1,0} add(f32[1,8]{1,0} %Arg_0.5, f32[1,8]{1,0} %Arg_0.5), metadata={source_file=\"-\" source_line=11}\n+    }\n+    ENTRY %main.10 (Arg_0.1: f32[8,8]) -> f32[8,8] {\n+      %Arg_0.1 = f32[8,8]{1,0} parameter(0)\n+      %custom-call.3 = f32[1,8]{1,0} custom-call(f32[8,8]{1,0} %Arg_0.1), custom_call_target=\"SPMDFullToShardShape\", sharding={manual}, metadata={source_file=\"-\" source_line=4}\n+      %call.7 = f32[1,8]{1,0} call(f32[1,8]{1,0} %custom-call.3), to_apply=%test, frontend_attributes={inlineable=\"false\"}\n+      ROOT %custom-call.9 = f32[8,8]{1,0} custom-call(f32[1,8]{1,0} %call.7), custom_call_target=\"SPMDShardToFullShape\", sharding={devices=[8,1]<=[8]}, metadata={source_file=\"-\" source_line=7}\n+    })\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(hloString));\n+  module->mutable_config().set_use_shardy_partitioner(true);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      bool changed,\n+      CallInliner(\n+          /*single_call_site=*/false, /*update_domain=*/false,\n+          /*composites_to_preserve=*/absl::flat_hash_set<std::string>{},\n+          /*uniquify_channel_ids=*/false,\n+          /*override_policy=*/\n+          [](const CallGraph&, const HloInstruction*) {\n+            return CallInliner::InlineOverridePolicy::\n+                kAllowIgnoreFrontendAttributes;\n+          })\n+          .Run(module.get()));\n+  // The single call will be inlined despite the inlineable attribute being\n+  // false because we set override_frontend_attributes to true.\n+  EXPECT_TRUE(changed);\n+  HloInstruction* call = FindInstruction(module.get(), xla::HloOpcode::kCall);\n+  EXPECT_EQ(call, nullptr);\n+}\n+\n TEST_F(CallInlinerTest, UseShardyMhloToHloShmapBodyNotInlined) {\n   const char* const hloString = R\"(\n     HloModule jit_f, entry_computation_layout={(f32[8,8]{1,0})->f32[8,8]{1,0}}\n@@ -942,15 +976,20 @@ ENTRY main {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> m,\n                           ParseAndReturnVerifiedModule(hlo));\n \n+  using InlineOverridePolicy = CallInliner::InlineOverridePolicy;\n   auto inline_trivial_only = [](const CallGraph& call_graph,\n-                                HloInstruction* instruction) {\n+                                const HloInstruction* instruction) {\n     HloComputation* callee = instruction->to_apply();\n-    return (callee->root_instruction()->opcode() == HloOpcode::kParameter);\n+    InlineOverridePolicy policy = InlineOverridePolicy::kProhibitInline;\n+    if (callee->root_instruction()->opcode() == HloOpcode::kParameter) {\n+      policy = InlineOverridePolicy::kAllowInline;\n+    }\n+    return policy;\n   };\n   CallInliner call_inliner(/*single_call_site=*/false, /*update_domain=*/false,\n                            /*composites_to_preserve=*/{},\n                            /*uniquify_channel_ids=*/false,\n-                           /*should_inline=*/inline_trivial_only);\n+                           /*override_policy=*/inline_trivial_only);\n \n   ASSERT_THAT(call_inliner.Run(m.get()), absl_testing::IsOkAndHolds(true));\n   EXPECT_THAT(m->entry_computation()->root_instruction(),"
        },
        {
            "sha": "aa61b5aac98d479fe08174d9d770a1827d1271ae",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/112563fb12fccbd8946b3d8861662bd6bb025fe1/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/112563fb12fccbd8946b3d8861662bd6bb025fe1/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=112563fb12fccbd8946b3d8861662bd6bb025fe1",
            "patch": "@@ -615,10 +615,14 @@ absl::Status CpuCompiler::RunHloPassesThroughLayoutAssn(\n         /*update_domain=*/false,\n         /*composites_to_preserve=*/absl::flat_hash_set<std::string>{},\n         /*uniquify_channel_ids=*/false,\n-        /*should_inline=*/\n-        [](const xla::CallGraph& call_graph, xla::HloInstruction* instruction) {\n-          return absl::StrContains(instruction->to_apply()->name(),\n-                                   sdy::kInlineableManualComputationFuncName);\n+        /*override_policy=*/\n+        [](const xla::CallGraph& call_graph,\n+           const xla::HloInstruction* instruction) {\n+          if (absl::StrContains(instruction->to_apply()->name(),\n+                                sdy::kInlineableManualComputationFuncName)) {\n+            return CallInliner::InlineOverridePolicy::kAllowInline;\n+          }\n+          return CallInliner::InlineOverridePolicy::kProhibitInline;\n         });\n     TF_RETURN_IF_ERROR(spmd_pipeline.Run(module).status());\n   } else {"
        },
        {
            "sha": "46146af1c57ae785d600a1cbeb4f25f5b191c575",
            "filename": "third_party/xla/xla/service/gpu/gpu_spmd_pipeline.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/112563fb12fccbd8946b3d8861662bd6bb025fe1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_spmd_pipeline.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/112563fb12fccbd8946b3d8861662bd6bb025fe1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_spmd_pipeline.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_spmd_pipeline.cc?ref=112563fb12fccbd8946b3d8861662bd6bb025fe1",
            "patch": "@@ -143,10 +143,14 @@ void AddSPMDPasses(\n       /*update_domain=*/false,\n       /*composites_to_preserve=*/absl::flat_hash_set<std::string>{},\n       /*uniquify_channel_ids=*/false,\n-      /*should_inline=*/\n-      [](const xla::CallGraph& call_graph, xla::HloInstruction* instruction) {\n-        return absl::StrContains(instruction->to_apply()->name(),\n-                                 sdy::kInlineableManualComputationFuncName);\n+      /*override_policy=*/\n+      [](const xla::CallGraph& call_graph,\n+         const xla::HloInstruction* instruction) {\n+        if (absl::StrContains(instruction->to_apply()->name(),\n+                              sdy::kInlineableManualComputationFuncName)) {\n+          return xla::CallInliner::InlineOverridePolicy::kAllowInline;\n+        }\n+        return xla::CallInliner::InlineOverridePolicy::kProhibitInline;\n       });\n   spmd_pipeline.AddPass<CollectivePermuteMotion>();\n }"
        }
    ],
    "stats": {
        "total": 120,
        "additions": 92,
        "deletions": 28
    }
}