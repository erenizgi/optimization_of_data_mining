{
    "author": "tensorflower-gardener",
    "message": "Reverts 6383e3632c91bdc8eccd458f699b317f03968b84\n\nPiperOrigin-RevId: 847161450",
    "sha": "44a702d0be1fcba7641fbdfa4bac4d2ea6103653",
    "files": [
        {
            "sha": "a0bdf45320c23efe399d400411d7e2558cb37cbd",
            "filename": "third_party/xla/xla/pjrt/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44a702d0be1fcba7641fbdfa4bac4d2ea6103653/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44a702d0be1fcba7641fbdfa4bac4d2ea6103653/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD?ref=44a702d0be1fcba7641fbdfa4bac4d2ea6103653",
            "patch": "@@ -972,7 +972,6 @@ cc_library(\n xla_cc_test(\n     name = \"transpose_test\",\n     srcs = [\"transpose_test.cc\"],\n-    shard_count = 10,\n     deps = [\n         \":transpose\",\n         \"//xla:array\","
        },
        {
            "sha": "c7eb090396085c496f18eb8711c4f7e87e08fb7e",
            "filename": "third_party/xla/xla/pjrt/transpose.cc",
            "status": "modified",
            "additions": 166,
            "deletions": 193,
            "changes": 359,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44a702d0be1fcba7641fbdfa4bac4d2ea6103653/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44a702d0be1fcba7641fbdfa4bac4d2ea6103653/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.cc?ref=44a702d0be1fcba7641fbdfa4bac4d2ea6103653",
            "patch": "@@ -120,8 +120,9 @@ static constexpr int kMaxInnerBlockSizeBytes = 16;\n // A plan is a data structure that describes a loop nest.\n // TODO(phawkins): consider shrinking Node so it fits in a cache line.\n struct TransposePlan::Node {\n-  // The loop should iterate over the index space range(0, end, inc).\n+  // The loop should iterate over the index space range(start, end, inc).\n   // These fields are ignored by the macrokernel.\n+  int64_t start;\n   int64_t end;  // For the inner loop of a memcpy loop nest, this is the size of\n                 // the transfer.\n   int64_t inc;  // The transpose sentinel node has inc < 0.\n@@ -202,6 +203,7 @@ void Transpose(const char* __restrict a, int outer_bs_a, char* __restrict b,\n   DVLOG(10) << \"Transpose \" << outer_bs_a << \" \" << outer_bs_b;\n   DCHECK_GT(outer_bs_a, 0);\n   DCHECK_GT(outer_bs_b, 0);\n+  const int64_t start = node->start;\n   const int64_t end = node->end;\n   const int64_t stop = node->end - (node->inc - 1);\n   const int64_t lda = node->lda;\n@@ -215,7 +217,7 @@ void Transpose(const char* __restrict a, int outer_bs_a, char* __restrict b,\n     const int64_t lda_block = next_node->lda;\n     const int64_t ldb_block = next_node->ldb;\n     int64_t i;\n-    for (i = 0; i < stop; i += inc) {\n+    for (i = start; i < stop; i += inc) {\n       MacroKernel<T, inner_bs, transformation>(a + i * lda, lda_block,\n                                                outer_bs_a, b + i * ldb,\n                                                ldb_block, outer_bs_b, scratch);\n@@ -279,7 +281,7 @@ void Transpose(const char* __restrict a, int outer_bs_a, char* __restrict b,\n     // inner loops. Structurally this code is identical to the previous case,\n     // but we call Transpose() recursively instead of MacroKernel().\n     int64_t i;\n-    for (i = 0; i < stop; i += inc) {\n+    for (i = start; i < stop; i += inc) {\n       Transpose<T, inner_bs, transformation>(\n           a + i * lda, outer_bs_a, b + i * ldb, outer_bs_b, next_node, scratch);\n     }\n@@ -333,44 +335,59 @@ void Transpose(const char* __restrict a, int outer_bs_a, char* __restrict b,\n \n void TransposeConstStride1(const char* __restrict a, char* __restrict b,\n                            TransposePlan::Node const* __restrict node) {\n+  a += node[0].start * node[0].lda;\n+  b += node[0].start * node[0].ldb;\n   if (node[0].is_inner_dim_in_a) {\n     int64_t num_bytes = node->end;\n     std::memcpy(b, a, num_bytes);\n   } else if (node[1].is_inner_dim_in_a) {\n+    int64_t offset_a = node[1].start * node[1].lda;\n+    int64_t offset_b = node[1].start * node[1].ldb;\n     int64_t num_bytes = node[1].end;\n-    for (int64_t i = 0; i < node[0].end; ++i) {\n+    a += offset_a;\n+    b += offset_b;\n+    for (int64_t i = node[0].start; i < node[0].end; ++i) {\n       std::memcpy(b, a, num_bytes);\n       a += node[0].lda;\n       b += node[0].ldb;\n     }\n     if (node[0].trailing_tile_next_node_inc) {\n-      TransposeConstStride1(a, b, node + node[0].trailing_tile_next_node_inc);\n+      TransposeConstStride1(a - offset_a, b - offset_b,\n+                            node + node[0].trailing_tile_next_node_inc);\n     }\n   } else if (node[2].is_inner_dim_in_a) {\n     int64_t num_bytes = node[2].end;\n-    for (int64_t i = 0; i < node[0].end; ++i) {\n+    int64_t offset_a1 = node[1].start * node[1].lda;\n+    int64_t offset_b1 = node[1].start * node[1].ldb;\n+    int64_t offset_a2 = node[2].start * node[2].lda;\n+    int64_t offset_b2 = node[2].start * node[2].ldb;\n+    a += offset_a1 + offset_a2;\n+    b += offset_b1 + offset_b2;\n+    for (int64_t i = node[0].start; i < node[0].end; ++i) {\n       const char* a1 = a;\n       char* b1 = b;\n-      for (int64_t j = 0; j < node[1].end; ++j) {\n+      for (int64_t j = node[1].start; j < node[1].end; ++j) {\n         std::memcpy(b1, a1, num_bytes);\n         a1 += node[1].lda;\n         b1 += node[1].ldb;\n       }\n       if (node[1].trailing_tile_next_node_inc) {\n-        TransposeConstStride1(a1, b1,\n+        TransposeConstStride1(a1 - offset_a2, b1 - offset_b2,\n                               &node[1] + node[1].trailing_tile_next_node_inc);\n       }\n       a += node[0].lda;\n       b += node[0].ldb;\n     }\n     if (node[0].trailing_tile_next_node_inc) {\n-      TransposeConstStride1(a, b, node + node[0].trailing_tile_next_node_inc);\n+      TransposeConstStride1(a - offset_a1 - offset_a2,\n+                            b - offset_b1 - offset_b2,\n+                            node + node[0].trailing_tile_next_node_inc);\n     }\n   } else {\n-    for (int64_t i = 0; i < node[0].end; ++i) {\n-      const char* a1 = a;\n-      char* b1 = b;\n-      for (int64_t j = 0; j < node[1].end; ++j) {\n+    for (int64_t i = node[0].start; i < node[0].end; ++i) {\n+      const char* a1 = a + node[1].start * node[1].lda;\n+      char* b1 = b + node[1].start * node[1].ldb;\n+      for (int64_t j = node[1].start; j < node[1].end; ++j) {\n         TransposeConstStride1(a1, b1, node + 2);\n         a1 += node[1].lda;\n         b1 += node[1].ldb;\n@@ -442,49 +459,6 @@ struct uint128 {\n };\n static_assert(sizeof(uint128) == 16, \"uint128 should be 16 bytes in size\");\n \n-void TransposePlan::ExecuteChunk(int chunk_id, const void* a, void* b) const {\n-  if (num_elems_ == 0) {\n-    return;\n-  }\n-  tsl::profiler::TraceMe traceme(\"Transpose::ExecuteChunk\", /*level=*/2);\n-\n-  absl::Span<Node const> nodes = nodes_[chunk_id];\n-  const char* ac = static_cast<const char*>(a) + input_offset_bytes_[chunk_id];\n-  char* bc = static_cast<char*>(b) + output_offset_bytes_[chunk_id];\n-\n-  if (inner_kernel_is_memcpy_) {\n-    DCHECK(transformation_ == Transformation::kNone);\n-    // Memcpy-based plans all assume element size 1 (i.e., bytes).\n-    TransposeConstStride1(ac, bc, nodes.data());\n-    return;\n-  }\n-\n-  switch (elem_size_in_bytes_) {\n-    case 1:\n-      ExecuteTyped<uint8_t, Transformation::kNone>(ac, bc, nodes);\n-      break;\n-    case 2:\n-      ExecuteTyped<uint16_t, Transformation::kNone>(ac, bc, nodes);\n-      break;\n-    case 4:\n-      if (transformation_ == Transformation::kNone) {\n-        ExecuteTyped<uint32_t, Transformation::kNone>(ac, bc, nodes);\n-      } else {\n-        DCHECK(transformation_ == Transformation::kF64ToEf57);\n-        ExecuteTyped<uint32_t, Transformation::kF64ToEf57>(ac, bc, nodes);\n-      }\n-      break;\n-    case 8:\n-      ExecuteTyped<uint64_t, Transformation::kNone>(ac, bc, nodes);\n-      break;\n-    case 16:\n-      ExecuteTyped<uint128, Transformation::kNone>(ac, bc, nodes);\n-      break;\n-    default:\n-      LOG(FATAL) << \"Unimplemented element size \" << elem_size_in_bytes_;\n-  }\n-}\n-\n void TransposePlan::Execute(\n     const void* a, void* b,\n     std::optional<absl::FunctionRef<void(std::function<void(void)>)>>\n@@ -494,19 +468,58 @@ void TransposePlan::Execute(\n   }\n   tsl::profiler::TraceMe traceme(\"Transpose::Execute\", /*level=*/2);\n \n-  if (!schedule_work || Parallelism() <= 1) {\n-    for (int i = 0; i < Parallelism(); ++i) {\n-      ExecuteChunk(i, a, b);\n+  const char* ac = static_cast<const char*>(a);\n+  char* bc = static_cast<char*>(b);\n+\n+  auto execute_by_type = [&](absl::Span<Node const> nodes) {\n+    if (inner_kernel_is_memcpy_) {\n+      DCHECK(transformation_ == Transformation::kNone);\n+      // Memcpy-based plans all assume element size 1 (i.e., bytes).\n+      TransposeConstStride1(ac, bc, nodes.data());\n+      return;\n+    }\n+\n+    switch (elem_size_in_bytes_) {\n+      case 1:\n+        ExecuteTyped<uint8_t, Transformation::kNone>(ac, bc, nodes);\n+        break;\n+      case 2:\n+        ExecuteTyped<uint16_t, Transformation::kNone>(ac, bc, nodes);\n+        break;\n+      case 4:\n+        if (transformation_ == Transformation::kNone) {\n+          ExecuteTyped<uint32_t, Transformation::kNone>(ac, bc, nodes);\n+        } else {\n+          DCHECK(transformation_ == Transformation::kF64ToEf57);\n+          ExecuteTyped<uint32_t, Transformation::kF64ToEf57>(ac, bc, nodes);\n+        }\n+        break;\n+      case 8:\n+        ExecuteTyped<uint64_t, Transformation::kNone>(ac, bc, nodes);\n+        break;\n+      case 16:\n+        ExecuteTyped<uint128, Transformation::kNone>(ac, bc, nodes);\n+        break;\n+      default:\n+        LOG(FATAL) << \"Unimplemented element size \" << elem_size_in_bytes_;\n+    }\n+  };\n+\n+  if (!schedule_work || nodes_.size() <= 1) {\n+    for (const auto& nodes : nodes_) {\n+      execute_by_type(nodes);\n     }\n   } else {\n-    absl::BlockingCounter counter(Parallelism() - 1);\n+    absl::BlockingCounter counter(nodes_.size() - 1);\n     for (size_t i = 1; i < nodes_.size(); ++i) {\n-      (*schedule_work)([&, i]() {\n-        ExecuteChunk(i, a, b);\n+      absl::Span<Node const> nodes = nodes_[i];\n+      (*schedule_work)([&, nodes]() {\n+        execute_by_type(nodes);\n         counter.DecrementCount();\n       });\n     }\n-    ExecuteChunk(0, a, b);\n+    // Run the first chunk inline in this thread.\n+    execute_by_type(nodes_[0]);\n     counter.Wait();\n   }\n }\n@@ -587,41 +600,51 @@ bool TransposePlan::Loop::operator==(const Loop& other) const {\n          lda == other.lda && ldb == other.ldb &&\n          is_inner_dim_in_a == other.is_inner_dim_in_a &&\n          is_inner_dim_in_b == other.is_inner_dim_in_b &&\n-         parallelism == other.parallelism && start == other.start &&\n-         end == other.end;\n+         parallelism == other.parallelism;\n }\n \n // Helper function that builds a plan.\n-void TransposePlan::BuildPlanNodes(int chunk_id,\n+void TransposePlan::BuildPlanNodes(int thread_id,\n                                    std::vector<TransposePlan::Node>& nodes) {\n   VLOG(8) << \"Before plan build: \" << ToString();\n   const int ndim = a_dims_.size();\n   DCHECK_GT(ndim, 0);\n \n-  // Use the pre-computed chunk loops which have start/end bounds already set.\n-  absl::Span<const Loop> chunk_loops = chunk_loops_[chunk_id];\n-\n   // We build plans in a depth-first order, visiting loops from outermost to\n   // innermost. We use a stack (depth-first) order to handle trailing partial\n   // tiles, which we \"come back to\" after handling the non-trailing case.\n   struct Agendum {\n-    // The ID of the loop to visit in chunk_loops.\n+    // The ID of the loop to visit in loop_order_.\n     int loop_id;\n     // The parent node ID whose trailing tile should be made to point to this\n     // node.\n     int parent_node_id;\n \n+    // The number of parallel tasks available to run this loop and its\n+    // successors.\n+    int num_tasks_at_loop;\n+\n+    // The ID number of the current thread in the tasks at this loop.\n+    int task_id_at_loop;\n+\n     // For which dimensions of `a` are we to visit the partial trailing tile\n     // a loop that visits that tile's interior?\n     absl::InlinedVector<bool, 4> partial_tiles;\n   };\n   std::stack<Agendum> agenda;\n \n+  int total_tasks = 1;\n+  for (const Loop& loop : loop_order_) {\n+    total_tasks *= loop.parallelism;\n+  }\n+\n   agenda.push(Agendum{/*loop_id=*/0, /*parent_node_id=*/-1,\n+                      /*num_tasks_at_loop=*/total_tasks,\n+                      /*task_id_at_loop=*/thread_id,\n                       absl::InlinedVector<bool, 4>(ndim, false)});\n \n   auto loop_has_trivial_iteration_space = [](const Node& node) {\n-    return node.inc == node.end;\n+    return node.start == 0 && node.start + node.inc == node.end;\n   };\n \n   while (!agenda.empty()) {\n@@ -636,13 +659,14 @@ void TransposePlan::BuildPlanNodes(int chunk_id,\n           node_id - agendum.parent_node_id;\n     }\n \n-    if (agendum.loop_id == chunk_loops.size()) {\n+    if (agendum.loop_id == loop_order_.size()) {\n       // We've reached the end of the loop nest.\n+      DCHECK_EQ(agendum.num_tasks_at_loop, 1);\n       // Transpose loops have a sentinel node, indicated by a negative `inc`\n       // value, that describes the striding of the inner transpose kernel.\n       if (!inner_kernel_is_memcpy_) {\n         Node node;\n-        node.end = node.inc = -1;\n+        node.start = node.end = node.inc = -1;\n         node.lda = sentinel_lda_;\n         node.ldb = sentinel_ldb_;\n         nodes.push_back(node);\n@@ -651,9 +675,14 @@ void TransposePlan::BuildPlanNodes(int chunk_id,\n       continue;\n     }\n \n-    const Loop& loop = chunk_loops[agendum.loop_id];\n+    const Loop& loop = loop_order_[agendum.loop_id];\n     int a_dim = loop.dim_in_a;\n \n+    // Compute the number of tasks for the next loop iteration.\n+    int task_id_at_loop = agendum.task_id_at_loop;\n+    int num_tasks_at_loop = agendum.num_tasks_at_loop / loop.parallelism;\n+    int task_id_at_next_loop = task_id_at_loop % num_tasks_at_loop;\n+\n     Node node;\n     node.lda = loop.lda;\n     node.ldb = loop.ldb;\n@@ -666,20 +695,22 @@ void TransposePlan::BuildPlanNodes(int chunk_id,\n       node.inc = inner_block_elems_ * outer_block_elems_b_;\n     }\n \n+    int task_id = task_id_at_loop / num_tasks_at_loop;\n+\n     if (loop.tile_interior) {\n       // We are visiting the tile interior of a tiled dimension.\n       bool partial = agendum.partial_tiles[a_dim];\n \n       int64_t size = partial ? loop.dim_size % loop.tile_size : loop.tile_size;\n-      // loop.start and loop.end are in element units.\n-      // Verify alignment to block boundaries.\n-      CHECK(loop.start % node.inc == 0)\n-          << \"loop.start=\" << loop.start\n-          << \" must be aligned to node.inc=\" << node.inc;\n-      node.end = std::min<int64_t>(size, loop.end) - loop.start;\n+      int64_t num_iterations = CeilOfRatio(size, node.inc);\n+      int64_t num_iterations_per_task =\n+          CeilOfRatio<int64_t>(num_iterations, loop.parallelism);\n+      node.start = std::min(size, task_id * num_iterations_per_task * node.inc);\n+      node.end =\n+          std::min(size, (task_id + 1) * num_iterations_per_task * node.inc);\n \n       if (node.is_inner_dim_in_a && inner_kernel_is_memcpy_) {\n-        node.end *= elem_size_in_bytes_;\n+        node.end = (node.end - node.start) * elem_size_in_bytes_;\n       }\n \n       if (!loop_has_trivial_iteration_space(node) ||\n@@ -689,6 +720,8 @@ void TransposePlan::BuildPlanNodes(int chunk_id,\n       Agendum new_agendum;\n       new_agendum.loop_id = agendum.loop_id + 1;\n       new_agendum.parent_node_id = -1;\n+      new_agendum.task_id_at_loop = task_id_at_next_loop;\n+      new_agendum.num_tasks_at_loop = num_tasks_at_loop;\n       new_agendum.partial_tiles = agendum.partial_tiles;\n       agenda.push(std::move(new_agendum));\n     } else {\n@@ -699,16 +732,14 @@ void TransposePlan::BuildPlanNodes(int chunk_id,\n \n       // If there is a trailing partial tile as well as complete tiles, handle\n       // it as a trailer on the loop over complete tiles.\n-      // A chunk is responsible for the trailing tile if its loop.end covers\n-      // the full dimension.\n-      int64_t full_size = CeilOfRatio(loop.dim_size, loop.tile_size);\n-      bool handles_trailing =\n-          loop.end >= full_size && loop.start <= num_complete_tiles;\n       bool has_trailing_plan_node = false;\n-      if (num_complete_tiles > 0 && has_partial_tile && handles_trailing) {\n+      if (num_complete_tiles > 0 && has_partial_tile &&\n+          task_id == loop.parallelism - 1) {\n         Agendum new_agendum;\n         new_agendum.loop_id = agendum.loop_id + 1;\n         new_agendum.parent_node_id = node_id;\n+        new_agendum.task_id_at_loop = task_id_at_next_loop;\n+        new_agendum.num_tasks_at_loop = num_tasks_at_loop;\n         new_agendum.partial_tiles = agendum.partial_tiles;\n         new_agendum.partial_tiles[a_dim] = true;\n         agenda.push(std::move(new_agendum));\n@@ -720,12 +751,18 @@ void TransposePlan::BuildPlanNodes(int chunk_id,\n       // path to handle the trailing tile.\n       bool partial = num_complete_tiles == 0 && has_partial_tile;\n \n-      // loop.start and loop.end are in tile units.\n+      // Evenly divide the loop iterations amongst the threads.\n       int64_t num_tiles = partial ? 1 : num_complete_tiles;\n-      node.end = std::min<int64_t>(num_tiles, loop.end) - loop.start;\n+      int64_t num_iterations = CeilOfRatio(num_tiles, node.inc);\n+      int64_t num_iterations_per_task =\n+          CeilOfRatio<int64_t>(num_iterations, loop.parallelism);\n+      node.start =\n+          std::min(num_tiles, task_id * num_iterations_per_task * node.inc);\n+      node.end = std::min(num_tiles,\n+                          (task_id + 1) * num_iterations_per_task * node.inc);\n \n       if (node.is_inner_dim_in_a && inner_kernel_is_memcpy_) {\n-        node.end *= elem_size_in_bytes_;\n+        node.end = (node.end - node.start) * elem_size_in_bytes_;\n       }\n \n       // If this loop has a trivial iteration space, drop it.\n@@ -737,6 +774,8 @@ void TransposePlan::BuildPlanNodes(int chunk_id,\n       Agendum new_agendum;\n       new_agendum.loop_id = agendum.loop_id + 1;\n       new_agendum.parent_node_id = -1;\n+      new_agendum.task_id_at_loop = task_id_at_next_loop;\n+      new_agendum.num_tasks_at_loop = num_tasks_at_loop;\n       new_agendum.partial_tiles = agendum.partial_tiles;\n       new_agendum.partial_tiles[a_dim] = partial;\n       agenda.push(std::move(new_agendum));\n@@ -960,10 +999,7 @@ void TransposePlan::Initialize() {\n                         : ldb_[pos_stride1a_in_b];\n   }\n \n-  // Order to traverse dimensions, from slowest-varying to fastest-varying.\n-  std::vector<Loop> loop_order;\n-\n-  loop_order.reserve(ndim);\n+  loop_order_.reserve(ndim);\n   for (int i = 0; i < ndim; ++i) {\n     Loop loop;\n     loop.dim_in_a = i;\n@@ -981,7 +1017,7 @@ void TransposePlan::Initialize() {\n     }\n     loop.is_inner_dim_in_a = (loop.tile_size == 1) && (i == pos_stride1a);\n     loop.is_inner_dim_in_b = (loop.tile_size == 1) && (i == pos_stride1b_in_a);\n-    loop_order.push_back(loop);\n+    loop_order_.push_back(loop);\n \n     if (loop.tile_size > 1) {\n       loop.tile_interior = true;\n@@ -990,12 +1026,12 @@ void TransposePlan::Initialize() {\n                              : ldb_[inverse_permutation[i]];\n       loop.is_inner_dim_in_a = (i == pos_stride1a);\n       loop.is_inner_dim_in_b = (i == pos_stride1b_in_a);\n-      loop_order.push_back(loop);\n+      loop_order_.push_back(loop);\n     }\n   }\n \n-  RemoveTrivialLoops(loop_order);\n-  CoalesceLoops(loop_order);\n+  RemoveTrivialLoops(loop_order_);\n+  CoalesceLoops(loop_order_);\n \n   // Bound the block sizes so they are smaller than the stride-1 dimension\n   // size.\n@@ -1082,7 +1118,7 @@ void TransposePlan::Initialize() {\n                            inner_kernel_is_memcpy_ && l.tile_interior,\n                            -std::min<double>(a_stride * penalty, b_stride));\n   };\n-  absl::c_stable_sort(loop_order, [&](const Loop& a, const Loop& b) {\n+  absl::c_stable_sort(loop_order_, [&](const Loop& a, const Loop& b) {\n     return cost(a) < cost(b);\n   });\n   // It is a required invariant of the loop order that tile interiors always\n@@ -1091,15 +1127,13 @@ void TransposePlan::Initialize() {\n   // both input and output.\n \n   // The stride-1 loop must be innermost for a memcpy loop.\n-  DCHECK(!inner_kernel_is_memcpy_ || loop_order.back().is_inner_dim_in_a)\n+  DCHECK(!inner_kernel_is_memcpy_ || loop_order_.back().is_inner_dim_in_a)\n       << ToString();\n \n-  int num_chunks = ChooseParallelizationStrategy(loop_order);\n-  PartitionLoops(num_chunks, loop_order, chunk_loops_, input_offset_bytes_,\n-                 output_offset_bytes_);\n-  nodes_.resize(num_chunks);\n-  for (int chunk_id = 0; chunk_id < num_chunks; ++chunk_id) {\n-    BuildPlanNodes(chunk_id, nodes_[chunk_id]);\n+  int num_threads = ChooseParallelizationStrategy();\n+  nodes_.resize(num_threads);\n+  for (int thread_id = 0; thread_id < num_threads; ++thread_id) {\n+    BuildPlanNodes(thread_id, nodes_[thread_id]);\n   }\n \n   switch (transformation_) {\n@@ -1114,8 +1148,7 @@ void TransposePlan::Initialize() {\n   }\n }\n \n-int TransposePlan::ChooseParallelizationStrategy(\n-    std::vector<Loop>& loop_order) {\n+int TransposePlan::ChooseParallelizationStrategy() {\n   int available_parallelism = num_threads_requested_;\n \n   // Compute the number of iterations in `loop`.\n@@ -1137,14 +1170,14 @@ int TransposePlan::ChooseParallelizationStrategy(\n   };\n \n   // Estimate the number of bytes each iteration of each loop processes.\n-  absl::InlinedVector<int64_t, 4> work_in_bytes(loop_order.size());\n+  absl::InlinedVector<int64_t, 4> work_in_bytes(loop_order_.size());\n   int64_t acc = elem_size_in_bytes_;\n   if (!inner_kernel_is_memcpy_) {\n     acc *= inner_block_elems_ * inner_block_elems_ * outer_block_elems_a_ *\n            outer_block_elems_b_;\n   }\n   auto work_it = work_in_bytes.rbegin();\n-  for (auto it = loop_order.rbegin(); it != loop_order.rend(); ++it) {\n+  for (auto it = loop_order_.rbegin(); it != loop_order_.rend(); ++it) {\n     *work_it++ = acc;\n     acc *= loop_iterations(*it);\n   }\n@@ -1153,79 +1186,28 @@ int TransposePlan::ChooseParallelizationStrategy(\n \n   // Heuristic that attempts to parallelize the outermost loops, down to a\n   // minimum per-thread number of bytes processed.\n-  int num_chunks = 1;\n-  for (size_t i = 0; i < loop_order.size(); ++i) {\n-    Loop& loop = loop_order[i];\n+  int num_threads = 1;\n+  for (size_t i = 0; i < loop_order_.size(); ++i) {\n+    Loop& loop = loop_order_[i];\n     CHECK_GE(available_parallelism, 1);\n     int64_t iterations = loop_iterations(loop);\n-\n-    // Initialize loop iteration bounds to full range in element units.\n-    loop.start = 0;\n-    loop.end = loop.tile_interior ? loop.tile_size\n-                                  : CeilOfRatio(loop.dim_size, loop.tile_size);\n-\n     int kMinBytesPerThread = inner_kernel_is_memcpy_ ? (1 << 20) : (1 << 26);\n     int64_t min_iterations_per_thread =\n         CeilOfRatio<int64_t>(kMinBytesPerThread, work_in_bytes[i]);\n     int64_t parallel_work = CeilOfRatio(iterations, min_iterations_per_thread);\n \n     VLOG(8) << \"iterations=\" << iterations << \" parallel_work=\" << parallel_work\n             << \" available_parallelism=\" << available_parallelism;\n-    int parallelism = std::min<int64_t>(available_parallelism, parallel_work);\n-    if (parallelism > 1) {\n-      // If we use CeilOfRatio(iterations, parallelism) as the chunk size, we\n-      // might end up with fewer chunks than parallelism if the chunk size is\n-      // large. For example, if iterations=17 and parallelism=16,\n-      // chunk_size=2. Then useful_tasks=9. We should reduce parallelism to 9.\n-      int64_t chunk_size =\n-          CeilOfRatio(iterations, static_cast<int64_t>(parallelism));\n-      int64_t useful_tasks = CeilOfRatio(iterations, chunk_size);\n-      parallelism = useful_tasks;\n-    }\n-    loop.parallelism = parallelism;\n-    available_parallelism /= parallelism;\n-    num_chunks *= loop.parallelism;\n-  }\n-  return num_chunks;\n-}\n-\n-/*static*/ void TransposePlan::PartitionLoops(\n-    int num_chunks, const std::vector<Loop>& loop_order,\n-    std::vector<std::vector<TransposePlan::Loop>>& result,\n-    std::vector<int64_t>& input_offset_bytes,\n-    std::vector<int64_t>& output_offset_bytes) {\n-  // Copy the base loop order for each chunk.\n-  result.resize(num_chunks, loop_order);\n-  input_offset_bytes.resize(num_chunks);\n-  output_offset_bytes.resize(num_chunks);\n-  for (int chunk_id = 0; chunk_id < num_chunks; ++chunk_id) {\n-    // For each loop, narrow the start/end bounds to this chunk's portion.\n-    int task_id_remaining = chunk_id;\n-    int num_tasks_remaining = num_chunks;\n-\n-    for (size_t i = 0; i < loop_order.size(); ++i) {\n-      Loop& chunk_loop = result[chunk_id][i];\n-      const Loop& base_loop = loop_order[i];\n-\n-      num_tasks_remaining /= base_loop.parallelism;\n-      int task_id = task_id_remaining / num_tasks_remaining;\n-      task_id_remaining = task_id_remaining % num_tasks_remaining;\n-\n-      // Divide this loop's iterations (in element units) among parallelism\n-      // tasks.\n-      int64_t iterations = base_loop.end - base_loop.start;\n-      int64_t iterations_per_task =\n-          CeilOfRatio<int64_t>(iterations, base_loop.parallelism);\n-\n-      chunk_loop.start =\n-          base_loop.start + std::min(iterations, task_id * iterations_per_task);\n-      chunk_loop.end =\n-          base_loop.start +\n-          std::min(iterations, (task_id + 1) * iterations_per_task);\n-      input_offset_bytes[chunk_id] += chunk_loop.start * chunk_loop.lda;\n-      output_offset_bytes[chunk_id] += chunk_loop.start * chunk_loop.ldb;\n+    if (parallel_work >= available_parallelism) {\n+      loop.parallelism = available_parallelism;\n+      available_parallelism = 1;\n+    } else {\n+      loop.parallelism = parallel_work;\n+      available_parallelism /= parallel_work;\n     }\n+    num_threads *= loop.parallelism;\n   }\n+  return num_threads;\n }\n \n std::string TransposePlan::ToString() const {\n@@ -1238,28 +1220,19 @@ std::string TransposePlan::ToString() const {\n                   absl::StrAppendFormat(\n                       out,\n                       \"    \"\n-                      \"Node(end=%d,inc=%d,lda=%\"\n+                      \"Node(start=%d,end=%d,inc=%d,lda=%\"\n                       \"d,ldb=%d,next_trailing=%d,inner_a=%s,inner_b=%s)\",\n-                      node.end, node.inc, node.lda, node.ldb,\n+                      node.start, node.end, node.inc, node.lda, node.ldb,\n                       node.trailing_tile_next_node_inc,\n                       node.is_inner_dim_in_a ? \"y\" : \"n\",\n                       node.is_inner_dim_in_b ? \"y\" : \"n\");\n                 }));\n       });\n-  auto format_loop = [](std::string* out, const Loop& loop) {\n-    absl::StrAppendFormat(out, \"%d%s[%d,%d](%d)\", loop.dim_in_a,\n-                          loop.tile_interior ? \"[tile]\" : \"\", loop.start,\n-                          loop.end, loop.parallelism);\n+  auto format_loop_order = [](std::string* out, const Loop& loop) {\n+    return absl::StrAppend(out, loop.dim_in_a,\n+                           loop.tile_interior ? \"[tile]\" : \"\", \"(\",\n+                           loop.parallelism, \")\");\n   };\n-  std::vector<std::string> chunk_strings;\n-  chunk_strings.reserve(chunk_loops_.size());\n-  for (int i = 0; i < chunk_loops_.size(); ++i) {\n-    chunk_strings.push_back(absl::StrFormat(\n-        \"    chunk %d: input_offset=%d output_offset=%d loops=%s\", i,\n-        input_offset_bytes_[i], output_offset_bytes_[i],\n-        absl::StrJoin(chunk_loops_[i], \", \", format_loop)));\n-  }\n-  std::string chunk_loops_str = absl::StrJoin(chunk_strings, \"\\n\");\n   std::string transformation_str;\n   switch (transformation_) {\n     case Transformation::kNone:\n@@ -1271,19 +1244,19 @@ std::string TransposePlan::ToString() const {\n   }\n   return absl::StrFormat(\n       \"elem_size=%d a_dims=%s b_dims=%s permutation=%s a_tiling=%s b_tiling=%s \"\n-      \"lda=%s lda_tile=%s ldb=%s ldb_tile=%s \"\n+      \"lda=%s lda_tile=%s ldb=%s ldb_tile=%s loop_order=%s \"\n       \"outer_bs=[%d,%d] inner_bs=%d \"\n       \"transformation=%s scratch_size=%d\\n\"\n-      \"chunk_loops:\\n%s\\n\"\n       \"nodes:\\n%s\",\n       elem_size_in_bytes_, absl::StrJoin(a_dims_, \",\"),\n       absl::StrJoin(Permute(a_dims_, permutation_), \",\"),\n       absl::StrJoin(permutation_, \",\"), absl::StrJoin(a_tiling_, \",\"),\n       absl::StrJoin(b_tiling_, \",\"), absl::StrJoin(lda_, \",\"),\n       absl::StrJoin(lda_tile_, \",\"), absl::StrJoin(ldb_, \",\"),\n-      absl::StrJoin(ldb_tile_, \",\"), outer_block_elems_a_, outer_block_elems_b_,\n-      inner_block_elems_, transformation_str, scratch_size_, chunk_loops_str,\n-      nodes_str);\n+      absl::StrJoin(ldb_tile_, \",\"),\n+      absl::StrJoin(loop_order_, \",\", format_loop_order), outer_block_elems_a_,\n+      outer_block_elems_b_, inner_block_elems_, transformation_str,\n+      scratch_size_, nodes_str);\n }\n \n bool TransposePlanCacheKey::operator==(\n@@ -1367,7 +1340,7 @@ absl::StatusOr<std::shared_ptr<TransposePlan>> TransposePlanCache::GetOrCreate(\n   }\n \n   // Coalesce from slow-varying to fast-varying (outer to inner).\n-  // loops[0] is slowest.\n+  // loop_order_[0] is slowest.\n   int write_pos = 0;\n   for (int read_pos = 1; read_pos < loops.size(); ++read_pos) {\n     Loop& outer = loops[write_pos];"
        },
        {
            "sha": "aef51be791a04bbb1a05b51d5f3a954b4139fd52",
            "filename": "third_party/xla/xla/pjrt/transpose.h",
            "status": "modified",
            "additions": 6,
            "deletions": 30,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44a702d0be1fcba7641fbdfa4bac4d2ea6103653/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44a702d0be1fcba7641fbdfa4bac4d2ea6103653/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.h?ref=44a702d0be1fcba7641fbdfa4bac4d2ea6103653",
            "patch": "@@ -124,12 +124,6 @@ class TransposePlan {\n                std::optional<absl::FunctionRef<void(std::function<void(void)>)>>\n                    schedule_work = std::nullopt) const;\n \n-  // Executes a single chunk of the transposition. To perform a complete\n-  // transposition, call ExecuteChunk for each chunk ID from 0 to Parallelism()\n-  // - 1. It is legal to call ExecuteChunk for independent chunks in parallel.\n-  // This is useful for callers that want to manage their own threading.\n-  void ExecuteChunk(int chunk_id, const void* a, void* b) const;\n-\n   // Returns a human-readable description of the plan.\n   std::string ToString() const;\n \n@@ -181,11 +175,6 @@ class TransposePlan {\n     // Number of parallel threads to use for this loop.\n     int64_t parallelism;\n \n-    // Iteration bounds for this chunk. Initially [0, full_iterations).\n-    // After chunk splitting, each chunk's loops have narrowed bounds.\n-    int64_t start = 0;  // Inclusive start of iteration range\n-    int64_t end = 0;    // Exclusive end of iteration range\n-\n     bool operator==(const Loop& other) const;\n   };\n \n@@ -197,20 +186,11 @@ class TransposePlan {\n   // Performs plan initialization that cannot fail.\n   void Initialize();\n \n-  void BuildPlanNodes(int chunk_id, std::vector<Node>& nodes);\n-\n-  // Chooses a parallelism for each loop. Returns the number of separate chunks\n-  // in the plan, and populates the `parallelism` field of each loop.\n-  int ChooseParallelizationStrategy(std::vector<Loop>& loop_order);\n+  void BuildPlanNodes(int thread_id, std::vector<Node>& output_nodes);\n \n-  // Creates per-chunk loop vectors by splitting loop_order_ into per-chunk\n-  // loops. Returns a vector of loop vectors, one per chunk. Each chunk's\n-  // loops have their start/end bounds narrowed to represent that chunk's work.\n-  static void PartitionLoops(\n-      int num_chunks, const std::vector<Loop>& loop_order,\n-      std::vector<std::vector<TransposePlan::Loop>>& result,\n-      std::vector<int64_t>& input_offset_bytes,\n-      std::vector<int64_t>& output_offset_bytes);\n+  // Chooses a parallelism for each loop. Returns the total number of parallel\n+  // work units.\n+  int ChooseParallelizationStrategy();\n \n   // The signature of ExecuteTyped uses char* pointers because we perform\n   // address calculations with strides in bytes; the strides need not be\n@@ -257,13 +237,9 @@ class TransposePlan {\n   bool a_is_tiled_;\n   bool b_is_tiled_;\n \n-  // Per-chunk loop nests. Each loop nest has its own start/end bounds\n-  // representing one chunk of the work.\n-  std::vector<std::vector<Loop>> chunk_loops_;\n+  // Order to traverse dimensions, from slowest-varying to fastest-varying.\n \n-  // Per-chunk byte offsets into the input and output arrays.\n-  std::vector<int64_t> input_offset_bytes_;\n-  std::vector<int64_t> output_offset_bytes_;\n+  std::vector<Loop> loop_order_;\n \n   // Root nodes of the plan, i.e., pointing to the outermost loops in the loop\n   // nest. The outer vector is indexed on the thread ID."
        },
        {
            "sha": "c136540eee1175f14dbf4cce5ce9a5fea4cd09ce",
            "filename": "third_party/xla/xla/pjrt/transpose_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44a702d0be1fcba7641fbdfa4bac4d2ea6103653/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44a702d0be1fcba7641fbdfa4bac4d2ea6103653/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose_test.cc?ref=44a702d0be1fcba7641fbdfa4bac4d2ea6103653",
            "patch": "@@ -462,10 +462,7 @@ std::vector<TransposeTestCase> GetTransposeTestCases() {\n                         /*permutation=*/{3, 1, 2, 0},\n                         /*input_tiling=*/{},\n                         /*output_tiling=*/{8, 128}),\n-      TransposeTestCase{/*dims=*/{129, 1234567},\n-                        /*permutation=*/{0, 1},\n-                        /*input_tiling=*/{},\n-                        /*output_tiling=*/{8, 128}}};\n+  };\n   return cases;\n }\n "
        }
    ],
    "stats": {
        "total": 401,
        "additions": 173,
        "deletions": 228
    }
}