{
    "author": "beckerhe",
    "message": "Enable deserialization of CustomKernelThunks with in-process symbols.\n\nThis change allows `GpuExecutable::FromProto` to deserialize `CustomKernelThunk`s that use in-process symbols. A symbol resolver is introduced in `GpuExecutable::FromProto` and `GpuAotCompilationResult::LoadExecutable`, which uses the global `KernelSymbolRegistry` to look up symbols. The `KernelLoaderSpec` deserialization is also updated to correctly handle kernel argument packing specs for in-process symbols.\n\nPiperOrigin-RevId: 840218503",
    "sha": "2b3b6718d065ff0b02747286c879a822d0277435",
    "files": [
        {
            "sha": "21f8119aa503886964a52a81e5c53ff03e5547eb",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=2b3b6718d065ff0b02747286c879a822d0277435",
            "patch": "@@ -3577,6 +3577,7 @@ cc_library(\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:kernel\",\n         \"//xla/stream_executor:kernel_args\",\n+        \"//xla/stream_executor:kernel_argument_packing_spec\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/tsl/platform:statusor\","
        },
        {
            "sha": "2169723a2276e1d3ba4be0a1717e073911fbab5c",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 15,
            "deletions": 1,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=2b3b6718d065ff0b02747286c879a822d0277435",
            "patch": "@@ -785,6 +785,7 @@ xla_cc_test(\n         \"//xla:shape_layout\",\n         \"//xla:shape_util\",\n         \"//xla/backends/gpu/runtime:copy_thunk\",\n+        \"//xla/backends/gpu/runtime:custom_kernel_thunk\",\n         \"//xla/backends/gpu/runtime:kernel_thunk\",\n         \"//xla/backends/gpu/runtime:sequential_thunk\",\n         \"//xla/backends/gpu/runtime:thunk\",\n@@ -800,12 +801,14 @@ xla_cc_test(\n         \"//xla/service:logical_buffer\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:semantic_version\",\n+        \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/stream_executor/gpu:tma_metadata\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/testing:temporary_directory\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n         \"//xla/tsl/util/proto:proto_matchers\",\n         \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/status:statusor\",\n@@ -1995,15 +1998,17 @@ cc_library(\n     deps = [\n         \":gpu_executable\",\n         \":gpu_executable_proto_cc\",\n-        \"//xla:util\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:compiler\",\n         \"//xla/service:executable\",\n+        \"//xla/stream_executor:kernel_symbol_registry\",\n+        \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/memory\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n     ],\n )\n \n@@ -2015,6 +2020,7 @@ xla_cc_test(\n         \":gpu_executable\",\n         \":launch_dimensions\",\n         \"//xla:literal_util\",\n+        \"//xla/backends/gpu/runtime:custom_kernel_thunk\",\n         \"//xla/backends/gpu/runtime:kernel_thunk\",\n         \"//xla/backends/gpu/runtime:sequential_thunk\",\n         \"//xla/backends/gpu/runtime:thunk\",\n@@ -2023,14 +2029,22 @@ xla_cc_test(\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:executable\",\n         \"//xla/service:hlo_module_config\",\n+        \"//xla/service/gpu/kernels:custom_kernel\",\n         \"//xla/stream_executor:device_description\",\n+        \"//xla/stream_executor:kernel_symbol_registry\",\n+        \"//xla/stream_executor:launch_dim\",\n         \"//xla/stream_executor:mock_platform\",\n         \"//xla/stream_executor:mock_stream_executor\",\n+        \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:semantic_version\",\n+        \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/stream_executor/gpu:tma_metadata\",\n+        \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest_main\","
        },
        {
            "sha": "11141620ef3d6621d9fa849b1d119b90e96ea7b1",
            "filename": "third_party/xla/xla/service/gpu/gpu_aot_compilation_result.h",
            "status": "modified",
            "additions": 13,
            "deletions": 3,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result.h?ref=2b3b6718d065ff0b02747286c879a822d0277435",
            "patch": "@@ -23,11 +23,14 @@ limitations under the License.\n #include \"absl/memory/memory.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/service/compiler.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/gpu/gpu_executable.h\"\n #include \"xla/service/gpu/gpu_executable.pb.h\"\n+#include \"xla/stream_executor/kernel_symbol_registry.h\"\n+#include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/statusor.h\"\n \n@@ -62,9 +65,16 @@ class GpuAotCompilationResult : public AotCompilationResult {\n   absl::StatusOr<std::unique_ptr<Executable>> LoadExecutable(\n       Compiler* compiler, const se::StreamExecutor* stream_exec) &&\n       final {\n-    return GpuExecutable::FromProto(executable_,\n-                                    stream_exec->GetDeviceDescription(),\n-                                    stream_exec->GetPlatform()->Name());\n+    stream_executor::Platform::Id platform_id =\n+        stream_exec->GetPlatform()->id();\n+    const auto symbol_resolver = [&](absl::string_view symbol_name) {\n+      stream_executor::KernelSymbolRegistry& registry =\n+          stream_executor::KernelSymbolRegistry::GetGlobalInstance();\n+      return registry.FindSymbol(symbol_name, platform_id);\n+    };\n+    return GpuExecutable::FromProto(\n+        executable_, stream_exec->GetDeviceDescription(),\n+        stream_exec->GetPlatform()->Name(), symbol_resolver);\n   }\n \n   const HloModule* optimized_module() const final { return hlo_module_.get(); };"
        },
        {
            "sha": "091e616bac25f7343a313a3c7ffd37171f5cb261",
            "filename": "third_party/xla/xla/service/gpu/gpu_aot_compilation_result_test.cc",
            "status": "modified",
            "additions": 45,
            "deletions": 0,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result_test.cc?ref=2b3b6718d065ff0b02747286c879a822d0277435",
            "patch": "@@ -23,8 +23,11 @@ limitations under the License.\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n+#include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/backends/gpu/runtime/custom_kernel_thunk.h\"\n #include \"xla/backends/gpu/runtime/kernel_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n@@ -36,24 +39,33 @@ limitations under the License.\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/gpu/gpu_executable.h\"\n+#include \"xla/service/gpu/kernels/custom_kernel.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/gpu/tma_metadata.h\"\n+#include \"xla/stream_executor/kernel_symbol_registry.h\"\n+#include \"xla/stream_executor/launch_dim.h\"\n #include \"xla/stream_executor/mock_platform.h\"\n #include \"xla/stream_executor/mock_stream_executor.h\"\n+#include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/semantic_version.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/util/proto/proto_matchers.h\"\n \n namespace xla::gpu {\n namespace {\n \n+using ::absl_testing::IsOkAndHolds;\n+using ::absl_testing::StatusIs;\n using ::stream_executor::DeviceDescription;\n using ::stream_executor::GpuComputeCapability;\n using ::stream_executor::MockPlatform;\n using ::stream_executor::MockStreamExecutor;\n+using ::testing::AnyOf;\n using ::testing::Return;\n using ::testing::ReturnRef;\n using ::tsl::proto_testing::EqualsProto;\n@@ -74,8 +86,11 @@ class GpuAotCompilationResultTest : public ::testing::Test {\n         .WillRepeatedly(ReturnRef(device_description_));\n     EXPECT_CALL(executor_, GetPlatform()).WillRepeatedly(Return(&platform_));\n     EXPECT_CALL(platform_, Name()).WillRepeatedly(ReturnRef(platform_name_));\n+    EXPECT_CALL(platform_, id()).WillRepeatedly(Return(platform_id_));\n   }\n \n+  void* const kCudaSymbol = reinterpret_cast<void*>(0x1234567890);\n+\n   // Creates a dummy GpuExecutableProto, the actual values don't matter much.\n   absl::StatusOr<GpuExecutableProto> CreateGpuExecutableProto() {\n     Thunk::ThunkInfo thunk_info;\n@@ -88,6 +103,16 @@ class GpuAotCompilationResultTest : public ::testing::Test {\n         LaunchDimensions(),\n         /*cluster_dim=*/std::nullopt,\n         /*shmem_bytes=*/0, ::stream_executor::gpu::TmaMetadata()));\n+    CustomKernel custom_kernel{\n+        \"custom_kernel_name\",\n+        stream_executor::KernelLoaderSpec::\n+            CreateSerializableInProcessSymbolSpec(\n+                \"persistent_kernel_name\", kCudaSymbol, \"test_custom_kernel\",\n+                /*arity=*/42),\n+        stream_executor::BlockDim(), stream_executor::ThreadDim(),\n+        /*shared_memory_bytes=*/23};\n+    thunk_sequence.push_back(std::make_unique<CustomKernelThunk>(\n+        thunk_info, custom_kernel, emitters::KernelArguments({})));\n \n     auto hlo_module = std::make_unique<HloModule>(\"test_module_with_shape\",\n                                                   HloModuleConfig());\n@@ -115,10 +140,28 @@ class GpuAotCompilationResultTest : public ::testing::Test {\n     return executable->ToProto();\n   }\n \n+  void EnsureCudaSymbolIsRegistered() {\n+    // This test has to rely on the global registry, because\n+    // `GpuAotCompilationResult` uses the global registry to look up symbols.\n+    // That means different test cases can affect each other. Therefore we check\n+    // if the symbol is registered, and only register it if it's not.\n+    stream_executor::KernelSymbolRegistry& registry =\n+        stream_executor::KernelSymbolRegistry::GetGlobalInstance();\n+    ASSERT_THAT(registry.FindSymbol(\"persistent_kernel_name\", platform_id_),\n+                AnyOf(IsOkAndHolds(kCudaSymbol),\n+                      StatusIs(absl::StatusCode::kNotFound)));\n+    if (!registry.FindSymbol(\"persistent_kernel_name\", platform_id_).ok()) {\n+      TF_ASSERT_OK(registry.RegisterSymbol(\"persistent_kernel_name\",\n+                                           platform_id_, kCudaSymbol));\n+    }\n+  }\n+\n   DeviceDescription device_description_;\n   MockStreamExecutor executor_;\n   MockPlatform platform_;\n   const std::string platform_name_ = \"gpu\";\n+  stream_executor::Platform::Id platform_id_ =\n+      reinterpret_cast<stream_executor::Platform::Id>(123);\n };\n \n TEST_F(GpuAotCompilationResultTest, CreateAndSerialize) {\n@@ -144,6 +187,8 @@ TEST_F(GpuAotCompilationResultTest, LoadExecutable) {\n       std::unique_ptr<GpuAotCompilationResult> result,\n       GpuAotCompilationResult::FromProto(reference_executable));\n \n+  EnsureCudaSymbolIsRegistered();\n+\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::unique_ptr<Executable> executable,\n       std::move(*result).LoadExecutable(/*compiler=*/nullptr, &executor_));"
        },
        {
            "sha": "cf6d4905db2f7c8d2980e5462e70994ff73a177a",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc?ref=2b3b6718d065ff0b02747286c879a822d0277435",
            "patch": "@@ -1259,7 +1259,9 @@ absl::StatusOr<GpuExecutableProto> GpuExecutable::ToProto() const {\n absl::StatusOr<std::unique_ptr<GpuExecutable>> GpuExecutable::FromProto(\n     const GpuExecutableProto& proto,\n     const se::DeviceDescription& device_description,\n-    absl::string_view platform_name) {\n+    absl::string_view platform_name,\n+    const std::optional<stream_executor::KernelLoaderSpec::SymbolResolver>&\n+        symbol_resolver) {\n   Params params;\n   params.enable_debug_info_manager = false;\n   params.asm_text = proto.asm_text();\n@@ -1302,7 +1304,8 @@ absl::StatusOr<std::unique_ptr<GpuExecutable>> GpuExecutable::FromProto(\n   TF_ASSIGN_OR_RETURN(\n       std::unique_ptr<Thunk> thunk,\n       DeserializeThunkProto(proto.thunk(), params.mlir_allocations.value(),\n-                            params.debug_module.get(), platform_name));\n+                            params.debug_module.get(), platform_name,\n+                            symbol_resolver));\n \n   if (dynamic_cast<const SequentialThunk*>(thunk.get()) == nullptr) {\n     return absl::InvalidArgumentError("
        },
        {
            "sha": "df83444fb4e0701673f094f9a1f0531545a2716e",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.h",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h?ref=2b3b6718d065ff0b02747286c879a822d0277435",
            "patch": "@@ -55,6 +55,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/kernel_stats.h\"\n+#include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/scoped_module_handle.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n \n@@ -222,7 +223,9 @@ class GpuExecutable : public Executable {\n   static absl::StatusOr<std::unique_ptr<GpuExecutable>> FromProto(\n       const GpuExecutableProto&,\n       const se::DeviceDescription& device_description,\n-      absl::string_view platform);\n+      absl::string_view platform,\n+      const std::optional<stream_executor::KernelLoaderSpec::SymbolResolver>&\n+          symbol_resolver = std::nullopt);\n \n   absl::StatusOr<GpuExecutableProto> ToProto() const;\n "
        },
        {
            "sha": "99376fa9446f180f0ec4d90b59fccca29acb20f5",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable_test.cc",
            "status": "modified",
            "additions": 79,
            "deletions": 0,
            "changes": 79,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc?ref=2b3b6718d065ff0b02747286c879a822d0277435",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"xla/service/gpu/gpu_executable.h\"\n \n #include <cstddef>\n+#include <cstdint>\n #include <memory>\n #include <optional>\n #include <string>\n@@ -27,7 +28,9 @@ limitations under the License.\n #include \"absl/status/status_matchers.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"xla/backends/gpu/runtime/copy_thunk.h\"\n+#include \"xla/backends/gpu/runtime/custom_kernel_thunk.h\"\n #include \"xla/backends/gpu/runtime/kernel_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n@@ -52,24 +55,29 @@ limitations under the License.\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/gpu/tma_metadata.h\"\n #include \"xla/stream_executor/semantic_version.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n #include \"xla/tsl/testing/temporary_directory.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n #include \"xla/tsl/util/proto/proto_matchers.h\"\n #include \"tsl/platform/path.h\"\n \n namespace xla::gpu {\n namespace {\n using ::testing::ElementsAre;\n using ::testing::ElementsAreArray;\n+using ::testing::Field;\n+using ::testing::Optional;\n using ::testing::Pair;\n using ::testing::Pointee;\n using ::testing::Property;\n using ::testing::SizeIs;\n using ::testing::UnorderedElementsAre;\n using ::tsl::proto_testing::EqualsProto;\n+using ::tsl::proto_testing::ParseTextProtoOrDie;\n using ::tsl::proto_testing::Partially;\n using ::tsl::testing::TemporaryDirectory;\n \n@@ -571,5 +579,76 @@ TEST(GpuExecutableTest, GpuExecutableDump) {\n               )pb\")));\n }\n \n+void* InventPointerToCudaKernel(uint64_t address) {\n+  return reinterpret_cast<void*>(address);\n+}\n+\n+TEST(GpuExecutableTest, FromProtoWithSymbolResolver) {\n+  const auto proto = ParseTextProtoOrDie<GpuExecutableProto>(R\"pb(\n+    module_name: \"test_module\"\n+    gpu_compute_capability: {\n+      cuda_compute_capability: { major: 9 minor: 0 feature_extension: NONE }\n+    }\n+    thunk {\n+      thunk_info { thunk_id: 1 }\n+      sequential_thunk {\n+        thunks {\n+          thunk_info { thunk_id: 2 }\n+          custom_kernel_thunk {\n+            custom_kernel {\n+              kernel_spec {\n+                in_process_symbol { persistent_name: \"persistent_kernel_name\" }\n+                kernel_name: \"kernel_name\"\n+                arity: 42\n+                kernel_args_packing_spec {\n+                  kernel_arguments {\n+                    relocations {\n+                      type: TYPE_BITS64_ABSOLUTE\n+                      argument_index: 0\n+                      offset: 0\n+                    }\n+                    data: \"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n+                  }\n+                  kernel_arguments { data: \"\\x34\\x12\\x00\\x00\" }\n+                }\n+              }\n+              block_dims { coordinates { x: 1 y: 1 z: 1 } }\n+              thread_dims { coordinates { x: 1 y: 1 z: 1 } }\n+              cluster_dim { coordinates { x: 1 y: 1 z: 1 } }\n+            }\n+          }\n+        }\n+      }\n+    }\n+  )pb\");\n+\n+  void* const kCudaSymbol = InventPointerToCudaKernel(0x1234567890);\n+\n+  stream_executor::DeviceDescription device_description;\n+  device_description.set_gpu_compute_capability(\n+      se::GpuComputeCapability{se::CudaComputeCapability::Hopper()});\n+\n+  int symbol_resolver_invocations = 0;\n+  const auto symbol_resolver = [&](absl::string_view name) {\n+    EXPECT_EQ(name, \"persistent_kernel_name\");\n+    ++symbol_resolver_invocations;\n+    return kCudaSymbol;\n+  };\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<GpuExecutable> executable,\n+      GpuExecutable::FromProto(proto, device_description, \"TEST_PLATFORM\",\n+                               symbol_resolver));\n+\n+  const CustomKernelThunk* custom_kernel_thunk =\n+      dynamic_cast<const CustomKernelThunk*>(\n+          executable->GetThunk().thunks().front().get());\n+  ASSERT_NE(custom_kernel_thunk, nullptr);\n+  EXPECT_THAT(\n+      custom_kernel_thunk->custom_kernel().kernel_spec().in_process_symbol(),\n+      Optional(Field(&stream_executor::InProcessSymbol::symbol, kCudaSymbol)));\n+  EXPECT_EQ(symbol_resolver_invocations, 1);\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "69f3ed1565f32a885ea2b4421c9af65b110e477b",
            "filename": "third_party/xla/xla/stream_executor/kernel_spec.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.cc?ref=2b3b6718d065ff0b02747286c879a822d0277435",
            "patch": "@@ -162,7 +162,7 @@ absl::StatusOr<KernelLoaderSpec> KernelLoaderSpec::FromProto(\n           (*symbol_resolver)(proto.in_process_symbol().persistent_name()));\n       return KernelLoaderSpec::CreateSerializableInProcessSymbolSpec(\n           proto.in_process_symbol().persistent_name(), symbol,\n-          proto.kernel_name(), proto.arity());\n+          proto.kernel_name(), proto.arity(), kernel_args_packing);\n     }\n \n     default:"
        },
        {
            "sha": "812fb30e3623aed202f0161c17153cd26bf09646",
            "filename": "third_party/xla/xla/stream_executor/kernel_spec_test.cc",
            "status": "modified",
            "additions": 23,
            "deletions": 0,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2b3b6718d065ff0b02747286c879a822d0277435/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec_test.cc?ref=2b3b6718d065ff0b02747286c879a822d0277435",
            "patch": "@@ -40,6 +40,8 @@ using ::absl_testing::IsOkAndHolds;\n using ::absl_testing::StatusIs;\n using ::testing::Field;\n using ::testing::Optional;\n+using ::testing::Property;\n+using ::testing::VariantWith;\n using ::tsl::proto_testing::EqualsProto;\n using ::tsl::proto_testing::ParseTextProtoOrDie;\n \n@@ -175,6 +177,13 @@ TEST(KernelLoaderSpec, InProcessSymbolFromProto) {\n     in_process_symbol { persistent_name: \"persistent_kernel_name\" }\n     kernel_name: \"kernel_name\"\n     arity: 42\n+    kernel_args_packing_spec {\n+      kernel_arguments {\n+        relocations { type: TYPE_BITS64_ABSOLUTE argument_index: 0 offset: 0 }\n+        data: \"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n+      }\n+      kernel_arguments { data: \"\\x34\\x12\\x00\\x00\" }\n+    }\n   )pb\");\n \n   const auto symbol_resolver = [](absl::string_view name) {\n@@ -192,6 +201,20 @@ TEST(KernelLoaderSpec, InProcessSymbolFromProto) {\n               Optional(Field(&InProcessSymbol::persistent_name,\n                              \"persistent_kernel_name\")));\n \n+  const auto kReferenceKernelArgsPackingSpecProto =\n+      R\"pb(\n+    kernel_arguments {\n+      relocations { type: TYPE_BITS64_ABSOLUTE argument_index: 0 offset: 0 }\n+      data: \"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n+    }\n+    kernel_arguments { data: \"\\x34\\x12\\x00\\x00\" }\n+      )pb\";\n+  EXPECT_THAT(\n+      spec.kernel_args_packing(),\n+      VariantWith<KernelArgumentsPackingSpec>(Property(\n+          &KernelArgumentsPackingSpec::ToProto,\n+          IsOkAndHolds(EqualsProto(kReferenceKernelArgsPackingSpecProto)))));\n+\n   // If the symbol resolver is not provided, the spec cannot be deserialized.\n   EXPECT_THAT(KernelLoaderSpec::FromProto(proto),\n               StatusIs(absl::StatusCode::kInvalidArgument));"
        }
    ],
    "stats": {
        "total": 194,
        "additions": 186,
        "deletions": 8
    }
}