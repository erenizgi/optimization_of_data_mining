{
    "author": "nvgrw",
    "message": "BufferValue::SizeFunction should be moved rather than copied.\n\nSizeFunction is often passed around with std::move, but rarely if ever can it\nactally be 'moved'. A future patch will change the definition of SizeFunction to\nbe move-only.\n\nPiperOrigin-RevId: 814677247",
    "sha": "c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
    "files": [
        {
            "sha": "1125f15ebc05b9283fc6373a2c001ccf55f4e259",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -306,10 +306,12 @@ cc_library(\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/base:nullability\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/log:die_if_null\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n@@ -339,6 +341,7 @@ xla_cc_test(\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/base:nullability\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/strings:string_view\","
        },
        {
            "sha": "f10e5a8c7e832bdb757005ba49d6fe1472da6cf1",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/hlo_memory_scheduler.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 11,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_memory_scheduler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_memory_scheduler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_memory_scheduler.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -26,9 +26,11 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/base/nullability.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/log/check.h\"\n+#include \"absl/log/die_if_null.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n@@ -95,7 +97,7 @@ class ListScheduler {\n   static absl::StatusOr<HloInstructionSequence> Run(\n       HloComputation* computation,\n       const TuplePointsToAnalysis& points_to_analysis,\n-      const BufferValue::SizeFunction& size_function) {\n+      const BufferValue::SizeFunction* absl_nonnull size_function) {\n     ListScheduler scheduler(computation, points_to_analysis, size_function);\n     return scheduler.CreateSchedule();\n   }\n@@ -117,10 +119,10 @@ class ListScheduler {\n \n   ListScheduler(HloComputation* computation,\n                 const TuplePointsToAnalysis& points_to_analysis,\n-                const BufferValue::SizeFunction& size_function)\n+                const BufferValue::SizeFunction* absl_nonnull size_function)\n       : computation_(computation),\n         points_to_analysis_(points_to_analysis),\n-        size_function_(size_function) {\n+        size_function_(ABSL_DIE_IF_NULL(size_function)) {\n     // Create a map containing the LogicalBuffer uses for each HLO\n     // instruction. An HLO instruction \"uses\" a LogicalBuffer if the\n     // LogicalBuffer is in an operand of the instruction as indicated by\n@@ -194,7 +196,7 @@ class ListScheduler {\n     for (auto* buffer :\n          points_to_analysis_.GetBuffersDefinedByInstruction(instruction)) {\n       if (!IgnoreBuffer(*buffer)) {\n-        entry.bytes_defined += size_function_(*buffer);\n+        entry.bytes_defined += (*size_function_)(*buffer);\n       }\n     }\n \n@@ -238,7 +240,7 @@ class ListScheduler {\n       auto buffer = kv->first;\n       auto use_count = kv->second;\n       if (use_count == 1) {\n-        freed_bytes += size_function_(*buffer);\n+        freed_bytes += (*size_function_)(*buffer);\n       }\n     }\n     return freed_bytes - entry.bytes_defined;\n@@ -368,7 +370,7 @@ class ListScheduler {\n \n   HloComputation* computation_;\n   const TuplePointsToAnalysis& points_to_analysis_;\n-  const BufferValue::SizeFunction& size_function_;\n+  const BufferValue::SizeFunction* absl_nonnull size_function_;\n \n   // A map containing the LogicalBuffers that each instruction uses.\n   absl::flat_hash_map<const HloInstruction*, std::vector<const LogicalBuffer*>>\n@@ -450,7 +452,7 @@ absl::StatusOr<HloInstructionSequence> DFSMemoryScheduler::Run(\n     HloValueSet value_set =\n         alias_analysis.dataflow_analysis().GetFlattenedValueSet(hlo);\n     int64_t logical_buffer_size =\n-        SumBufferSizes(hlo, value_set, size_function_);\n+        SumBufferSizes(hlo, value_set, *size_function_);\n     stats.total_sizes = logical_buffer_size;\n     cumulative_total_size += logical_buffer_size;\n     absl::flat_hash_set<const HloInstruction*> unique_operands(\n@@ -647,12 +649,12 @@ absl::StatusOr<HloSchedule> ScheduleModule(\n \n absl::StatusOr<HloSchedule> ScheduleModule(\n     const HloModule* module, const AliasInfo* alias_info,\n-    const BufferValue::SizeFunction& size_function,\n+    BufferValue::SizeFunction size_function,\n     const absl::flat_hash_set<absl::string_view>& execution_threads,\n     int64_t* peak_memory) {\n-  return ScheduleModule(module,\n-                        DefaultMemoryScheduler(alias_info, size_function),\n-                        execution_threads, peak_memory);\n+  return ScheduleModule(\n+      module, DefaultMemoryScheduler(alias_info, std::move(size_function)),\n+      execution_threads, peak_memory);\n }\n \n absl::StatusOr<bool> HloMemoryScheduler::Run("
        },
        {
            "sha": "f06330b53ff0ff2d8ba4e4c77171e8d7cea19051",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/hlo_memory_scheduler.h",
            "status": "modified",
            "additions": 65,
            "deletions": 9,
            "changes": 74,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_memory_scheduler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_memory_scheduler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_memory_scheduler.h?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -19,9 +19,12 @@ limitations under the License.\n #include <cstdint>\n #include <functional>\n #include <memory>\n+#include <optional>\n #include <utility>\n \n+#include \"absl/base/nullability.h\"\n #include \"absl/container/flat_hash_set.h\"\n+#include \"absl/log/die_if_null.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/hlo/analysis/alias_info.h\"\n@@ -81,14 +84,24 @@ class ComputationSchedulerAlgorithm : public ModuleSchedulerAlgorithm {\n       int64_t* peak_memory) const override;\n \n  protected:\n+  ComputationSchedulerAlgorithm(\n+      const AliasInfo* alias_info,\n+      const BufferValue::SizeFunction* absl_nonnull size_function,\n+      SchedulerPostprocessor postprocessor)\n+      : ModuleSchedulerAlgorithm(alias_info),\n+        size_function_(ABSL_DIE_IF_NULL(size_function)),\n+        postprocessor_(std::move(postprocessor)) {}\n+  // Variant of the above constructor that takes ownership of the size function.\n   ComputationSchedulerAlgorithm(const AliasInfo* alias_info,\n                                 BufferValue::SizeFunction size_function,\n                                 SchedulerPostprocessor postprocessor)\n       : ModuleSchedulerAlgorithm(alias_info),\n-        size_function_(std::move(size_function)),\n+        owned_size_function_(std::move(size_function)),\n+        size_function_(&*owned_size_function_),\n         postprocessor_(std::move(postprocessor)) {}\n \n-  BufferValue::SizeFunction size_function_;\n+  std::optional<BufferValue::SizeFunction> owned_size_function_;\n+  const BufferValue::SizeFunction* absl_nonnull size_function_;\n   SchedulerPostprocessor postprocessor_;\n };\n \n@@ -97,6 +110,12 @@ class ComputationSchedulerAlgorithm : public ModuleSchedulerAlgorithm {\n // frees bigger buffer and defines smaller outputs.\n class ListMemoryScheduler : public ComputationSchedulerAlgorithm {\n  public:\n+  ListMemoryScheduler(\n+      const AliasInfo* alias_info,\n+      const BufferValue::SizeFunction* absl_nonnull size_function,\n+      SchedulerPostprocessor postprocessor = {})\n+      : ComputationSchedulerAlgorithm(alias_info, size_function,\n+                                      std::move(postprocessor)) {}\n   ListMemoryScheduler(const AliasInfo* alias_info,\n                       BufferValue::SizeFunction size_function,\n                       SchedulerPostprocessor postprocessor = {})\n@@ -112,6 +131,12 @@ class ListMemoryScheduler : public ComputationSchedulerAlgorithm {\n // DFS-order scheduler with a heuristic to decide which operand to visit first.\n class DFSMemoryScheduler : public ComputationSchedulerAlgorithm {\n  public:\n+  DFSMemoryScheduler(\n+      const AliasInfo* alias_info,\n+      const BufferValue::SizeFunction* absl_nonnull size_function,\n+      SchedulerPostprocessor postprocessor = {})\n+      : ComputationSchedulerAlgorithm(alias_info, size_function,\n+                                      std::move(postprocessor)) {}\n   DFSMemoryScheduler(const AliasInfo* alias_info,\n                      BufferValue::SizeFunction size_function,\n                      SchedulerPostprocessor postprocessor = {})\n@@ -136,6 +161,11 @@ class DFSMemoryScheduler : public ComputationSchedulerAlgorithm {\n // a lot of available compute cores, and cheap concurrency primitives.\n class BFScheduler : public ComputationSchedulerAlgorithm {\n  public:\n+  BFScheduler(const AliasInfo* alias_info,\n+              const BufferValue::SizeFunction* absl_nonnull size_function,\n+              SchedulerPostprocessor postprocessor = {})\n+      : ComputationSchedulerAlgorithm(alias_info, size_function,\n+                                      std::move(postprocessor)) {}\n   BFScheduler(const AliasInfo* alias_info,\n               BufferValue::SizeFunction size_function,\n               SchedulerPostprocessor postprocessor = {})\n@@ -150,6 +180,12 @@ class BFScheduler : public ComputationSchedulerAlgorithm {\n // Naive Post Order scheduler\n class PostOrderScheduler : public ComputationSchedulerAlgorithm {\n  public:\n+  explicit PostOrderScheduler(\n+      const AliasInfo* alias_info,\n+      const BufferValue::SizeFunction* absl_nonnull size_function,\n+      SchedulerPostprocessor postprocessor = {})\n+      : ComputationSchedulerAlgorithm(alias_info, size_function,\n+                                      std::move(postprocessor)) {}\n   explicit PostOrderScheduler(const AliasInfo* alias_info,\n                               BufferValue::SizeFunction size_function,\n                               SchedulerPostprocessor postprocessor = {})\n@@ -168,20 +204,34 @@ class PostOrderScheduler : public ComputationSchedulerAlgorithm {\n // to the peak memory of the resulting schedule according to the HeapSimulator.\n class DefaultMemoryScheduler : public ModuleSchedulerAlgorithm {\n  public:\n+  DefaultMemoryScheduler(\n+      const AliasInfo* alias_info,\n+      const BufferValue::SizeFunction* absl_nonnull size_function,\n+      const SchedulerPostprocessor& postprocessor = {})\n+      : ModuleSchedulerAlgorithm(alias_info),\n+        size_function_(size_function),\n+        list_scheduler_(alias_info, size_function_, postprocessor),\n+        dfs_scheduler_(alias_info, size_function_, postprocessor),\n+        post_order_scheduler_(alias_info, size_function_, postprocessor) {}\n+  // Variant of the above constructor that takes ownership of the size function.\n   DefaultMemoryScheduler(const AliasInfo* alias_info,\n-                         const BufferValue::SizeFunction& size_function,\n+                         BufferValue::SizeFunction size_function,\n                          const SchedulerPostprocessor& postprocessor = {})\n       : ModuleSchedulerAlgorithm(alias_info),\n-        list_scheduler_(alias_info, size_function, postprocessor),\n-        dfs_scheduler_(alias_info, size_function, postprocessor),\n-        post_order_scheduler_(alias_info, size_function, postprocessor) {}\n+        owned_size_function_(std::move(size_function)),\n+        size_function_(&*owned_size_function_),\n+        list_scheduler_(alias_info, size_function_, postprocessor),\n+        dfs_scheduler_(alias_info, size_function_, postprocessor),\n+        post_order_scheduler_(alias_info, size_function_, postprocessor) {}\n   absl::StatusOr<HloSchedule> Run(\n       const HloModule* module, const TuplePointsToAnalysis& points_to_analysis,\n       const HloAliasAnalysis& alias_analysis,\n       const absl::flat_hash_set<absl::string_view>& execution_threads,\n       int64_t* peak_memory) const override;\n \n  private:\n+  std::optional<BufferValue::SizeFunction> owned_size_function_;\n+  const BufferValue::SizeFunction* absl_nonnull size_function_;\n   ListMemoryScheduler list_scheduler_;\n   DFSMemoryScheduler dfs_scheduler_;\n   PostOrderScheduler post_order_scheduler_;\n@@ -198,7 +248,7 @@ absl::StatusOr<HloSchedule> ScheduleModule(\n // Schedule the module using the DefaultMemoryScheduler algorithm.\n absl::StatusOr<HloSchedule> ScheduleModule(\n     const HloModule* module, const AliasInfo* alias_info,\n-    const BufferValue::SizeFunction& size_function,\n+    BufferValue::SizeFunction size_function,\n     const absl::flat_hash_set<absl::string_view>& execution_threads = {},\n     int64_t* peak_memory = nullptr);\n \n@@ -212,10 +262,16 @@ class HloMemoryScheduler : public HloModulePass {\n   explicit HloMemoryScheduler(\n       std::unique_ptr<ModuleSchedulerAlgorithm> algorithm)\n       : algorithm_(std::move(algorithm)) {}\n-  HloMemoryScheduler(const AliasInfo* alias_info,\n-                     const BufferValue::SizeFunction& size_function)\n+  HloMemoryScheduler(\n+      const AliasInfo* alias_info,\n+      const BufferValue::SizeFunction* absl_nonnull size_function)\n       : algorithm_(std::make_unique<DefaultMemoryScheduler>(alias_info,\n                                                             size_function)) {}\n+  // Variant of the above constructor that takes ownership of the size function.\n+  HloMemoryScheduler(const AliasInfo* alias_info,\n+                     BufferValue::SizeFunction size_function)\n+      : algorithm_(std::make_unique<DefaultMemoryScheduler>(\n+            alias_info, std::move(size_function))) {}\n \n   absl::string_view name() const override { return \"hlo-memory-scheduler\"; }\n "
        },
        {
            "sha": "059b0970c4eb8b72ba15d448965b723d9c351611",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/hlo_memory_scheduler_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_memory_scheduler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_memory_scheduler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_memory_scheduler_test.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n \n #include <gtest/gtest.h>\n #include \"absl/algorithm/container.h\"\n+#include \"absl/base/nullability.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/log/check.h\"\n #include \"absl/strings/string_view.h\"\n@@ -57,7 +58,8 @@ class HloSchedulingTest : public HloHardwareIndependentTestBase {\n };\n \n int64_t PeakMemoryUseOfEntryComputation(\n-    HloModule* module, LogicalBuffer::SizeFunction size_function) {\n+    HloModule* module,\n+    const LogicalBuffer::SizeFunction* absl_nonnull size_function) {\n   CHECK(module->has_entry_computation());\n   CHECK(module->has_schedule());\n \n@@ -158,13 +160,13 @@ ENTRY root {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(module_str));\n \n-  auto size_fn = [](const BufferValue& buffer) {\n+  BufferValue::SizeFunction size_fn = [](const BufferValue& buffer) {\n     return ShapeUtil::ByteSizeOf(buffer.shape(), /*pointer_size=*/8);\n   };\n   int64_t peak_memory;\n   TF_ASSERT_OK_AND_ASSIGN(\n       HloSchedule schedule,\n-      ScheduleModule(module.get(), ListMemoryScheduler(&alias_info_, size_fn),\n+      ScheduleModule(module.get(), ListMemoryScheduler(&alias_info_, &size_fn),\n                      /*execution_threads=*/{}, &peak_memory));\n   TF_ASSERT_OK(module->set_schedule(schedule));\n   // Verify that all instructions are in the sequence.\n@@ -187,7 +189,7 @@ ENTRY root {\n   SequentialHloOrdering ordering(schedule);\n   EXPECT_TRUE(ordering.ExecutesBefore(instructions_by_name.at(\"d\"),\n                                       instructions_by_name.at(\"e\")));\n-  EXPECT_EQ(PeakMemoryUseOfEntryComputation(module.get(), size_fn),\n+  EXPECT_EQ(PeakMemoryUseOfEntryComputation(module.get(), &size_fn),\n             peak_memory);\n }\n "
        },
        {
            "sha": "94e1f217233211f9687bef8949c44e8a33a85ee0",
            "filename": "third_party/xla/xla/service/buffer_assignment.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -853,7 +853,7 @@ absl::StatusOr<int64_t> BufferAssignment::ComputeTotalFragmentationBytes(\n     TF_ASSIGN_OR_RETURN(\n         const int64_t min_size,\n         HeapSimulator::MinimumMemoryForModule(schedule, alias_analysis(),\n-                                              alias_info, buffer_size_));\n+                                              alias_info, &buffer_size_));\n     return stats_.total_allocation_bytes - min_size;\n   }\n   return -1;\n@@ -1974,7 +1974,7 @@ absl::Status BufferAssigner::AssignBuffersWithSequentialOrdering(\n               HeapSimulator::Run(\n                   get_heap_algorithm(alignment), *private_stack_computation,\n                   *instruction_sequence, assignment->alias_analysis(),\n-                  alias_info_, assignment->buffer_size_, &schedule, options));\n+                  alias_info_, &assignment->buffer_size_, &schedule, options));\n           TF_RETURN_IF_ERROR(AssignBuffersFromHeapSimulator(\n               result, assignment, color, isolation_options));\n         }\n@@ -1985,7 +1985,7 @@ absl::Status BufferAssigner::AssignBuffersWithSequentialOrdering(\n             HeapSimulator::Run(get_heap_algorithm(alignment),\n                                assignment->module(), schedule,\n                                assignment->alias_analysis(), alias_info_,\n-                               assignment->buffer_size_, options));\n+                               &assignment->buffer_size_, options));\n         TF_RETURN_IF_ERROR(AssignBuffersFromHeapSimulator(\n             result, assignment, color, isolation_options));\n       }\n@@ -2019,7 +2019,7 @@ absl::Status BufferAssigner::AssignBuffersWithSequentialOrdering(\n             HeapSimulator::Run(get_heap_algorithm(alignment), *computation,\n                                *instruction_sequence,\n                                assignment->alias_analysis(), alias_info_,\n-                               assignment->buffer_size_, options));\n+                               &assignment->buffer_size_, options));\n         TF_RETURN_IF_ERROR(AssignBuffersFromHeapSimulator(\n             result, assignment, color, isolation_options));\n       }"
        },
        {
            "sha": "5f15b88cc114b09f8e872d2711d7a60955628ff9",
            "filename": "third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -247,7 +247,7 @@ absl::Status LoadCache(IrEmitterContext& ir_emitter_context,\n \n absl::StatusOr<std::unique_ptr<BufferAssignment>> RunBufferAssignment(\n     const HloModule* module, const GpuAliasInfo* alias_info,\n-    const BufferValue::SizeFunction& buffer_size_bytes_function) {\n+    BufferValue::SizeFunction buffer_size_bytes_function) {\n   ScopedAnnotation annotation(Phase(\"XlaBufferAssignment\", module));\n \n   const DebugOptions& options = module->config().debug_options();\n@@ -262,7 +262,7 @@ absl::StatusOr<std::unique_ptr<BufferAssignment>> RunBufferAssignment(\n       std::unique_ptr<BufferAssignment> buffer_assignment,\n       BufferAssigner::Run(\n           module, std::make_unique<SequentialHloOrdering>(module->schedule()),\n-          buffer_size_bytes_function, alias_info,\n+          std::move(buffer_size_bytes_function), alias_info,\n           /*color_alignment=*/\n           [](LogicalBuffer::Color) { return kXlaAllocatedBufferAlignBytes; },\n           /*allocate_buffers_for_constants=*/true,\n@@ -282,7 +282,7 @@ absl::StatusOr<CompileModuleResults> CompileModuleToLlvmIr(\n     const std::string& target_triple, const std::string& data_layout,\n     const se::Platform* platform, const se::DeviceDescription& device_desc,\n     const GpuAliasInfo* alias_info,\n-    const BufferValue::SizeFunction& buffer_size_bytes_function,\n+    BufferValue::SizeFunction buffer_size_bytes_function,\n     bool split_constants_module) {\n   tsl::profiler::TraceMe traceme(\"CompileModuleToLlvmIr\");\n   const bool use_cache =\n@@ -294,7 +294,8 @@ absl::StatusOr<CompileModuleResults> CompileModuleToLlvmIr(\n \n   TF_ASSIGN_OR_RETURN(\n       results.buffer_assignment,\n-      RunBufferAssignment(hlo_module, alias_info, buffer_size_bytes_function));\n+      RunBufferAssignment(hlo_module, alias_info,\n+                          std::move(buffer_size_bytes_function)));\n   TF_ASSIGN_OR_RETURN(results.output_info,\n                       GetOutputInfo(*hlo_module, *results.buffer_assignment));\n "
        },
        {
            "sha": "e40088194fdfaf88be5c84b2d102a3cf70325ac6",
            "filename": "third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.h?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -72,7 +72,7 @@ absl::StatusOr<CompileModuleResults> CompileModuleToLlvmIr(\n     const std::string& target_triple, const std::string& data_layout,\n     const se::Platform* platform, const se::DeviceDescription& device_desc,\n     const GpuAliasInfo* alias_info,\n-    const BufferValue::SizeFunction& buffer_size_bytes_function,\n+    BufferValue::SizeFunction buffer_size_bytes_function,\n     bool split_constants_module = false);\n \n }  // namespace gpu"
        },
        {
            "sha": "9708127464a459249ecafda9d1ce2d045ebc84a6",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 6,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -2551,13 +2551,15 @@ GpuCompiler::CompileToBackendResult(\n   {\n     xla::llvm_ir::LLVMCommandLineOptionsLock llvm_options_lock(\n         GetLLVMCommandLineOptions(module->config().debug_options()));\n+    BufferValue::SizeFunction buffer_size_bytes_function =\n+        BufferSizeBytesFunction();\n     // Compile the module to thnks and llvm IR.\n-    TF_ASSIGN_OR_RETURN(\n-        compile_module_results,\n-        CompileModuleToLlvmIr(module, llvm_context, target_triple_,\n-                              data_layout_, *platform, gpu_device_info,\n-                              alias_info.get(), BufferSizeBytesFunction(),\n-                              /*split_constants_module=*/use_cache));\n+    TF_ASSIGN_OR_RETURN(compile_module_results,\n+                        CompileModuleToLlvmIr(\n+                            module, llvm_context, target_triple_, data_layout_,\n+                            *platform, gpu_device_info, alias_info.get(),\n+                            std::move(buffer_size_bytes_function),\n+                            /*split_constants_module=*/use_cache));\n   }\n \n   if (user_pre_optimization_hook_) {"
        },
        {
            "sha": "da6c9bb3f67ab16ad2c39f088faf8a16512cefc6",
            "filename": "third_party/xla/xla/service/gpu/gpu_hlo_schedule.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_hlo_schedule.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_hlo_schedule.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_hlo_schedule.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -646,13 +646,13 @@ absl::StatusOr<HloSchedule> ScheduleGpuModuleWithMemoryScheduler(\n     }\n     return ShapeUtil::ByteSizeOf(shape, pointer_size);\n   };\n-  return ScheduleModule(\n-      module,\n-      DefaultMemoryScheduler(alias_info, size_func, PostProcessSchedule),\n-      /*execution_threads=*/\n-      {HloInstruction::kMainExecutionThread,\n-       StreamAttributeAsyncWrapper::kParallelExecutionThread},\n-      peak_memory_bytes);\n+  return ScheduleModule(module,\n+                        DefaultMemoryScheduler(alias_info, std::move(size_func),\n+                                               PostProcessSchedule),\n+                        /*execution_threads=*/\n+                        {HloInstruction::kMainExecutionThread,\n+                         StreamAttributeAsyncWrapper::kParallelExecutionThread},\n+                        peak_memory_bytes);\n }\n \n }  // end namespace"
        },
        {
            "sha": "9b652789bd50acd5c9aa2b70230a1fa3b5bb5e56",
            "filename": "third_party/xla/xla/service/heap_simulator/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2FBUILD?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -53,6 +53,7 @@ cc_library(\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/base:nullability\",\n         \"@com_google_absl//absl/container:btree\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:flat_hash_set\","
        },
        {
            "sha": "3e4cac0e9a8b3878fb8b44a5085d9c24d791e0b5",
            "filename": "third_party/xla/xla/service/heap_simulator/heap_simulator.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 12,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2Fheap_simulator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2Fheap_simulator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2Fheap_simulator.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include <vector>\n \n #include \"absl/algorithm/container.h\"\n+#include \"absl/base/nullability.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/container/inlined_vector.h\"\n@@ -209,7 +210,7 @@ std::ostream& operator<<(std::ostream& stream,\n absl::StatusOr<int64_t> HeapSimulator::MinimumMemoryForModule(\n     const HloSchedule& schedule, const HloAliasAnalysis& alias_analysis,\n     const AliasInfo* alias_info,\n-    const LogicalBuffer::SizeFunction& size_function) {\n+    const LogicalBuffer::SizeFunction* absl_nonnull size_function) {\n   if (schedule.empty()) {\n     return 0;\n   }\n@@ -232,7 +233,7 @@ absl::StatusOr<int64_t> HeapSimulator::MinimumMemoryForModule(\n absl::StatusOr<int64_t> HeapSimulator::MinimumMemoryForComputation(\n     const HloComputation& computation, const HloInstructionSequence& sequence,\n     const HloAliasAnalysis& alias_analysis, const AliasInfo* alias_info,\n-    const LogicalBuffer::SizeFunction& size_function) {\n+    const LogicalBuffer::SizeFunction* absl_nonnull size_function) {\n   TF_ASSIGN_OR_RETURN(\n       HeapSimulator::Result<HloValue> result,\n       HeapSimulator::Run(std::make_unique<NoFragmentationStatsHeap<HloValue>>(),\n@@ -245,7 +246,8 @@ absl::StatusOr<int64_t> HeapSimulator::MinimumMemoryForComputation(\n absl::StatusOr<HeapSimulator::Result<HloValue>> HeapSimulator::Run(\n     std::unique_ptr<HeapAlgorithm<HloValue>> algorithm, const HloModule& module,\n     const HloSchedule& schedule, const HloAliasAnalysis& alias_analysis,\n-    const AliasInfo* alias_info, const BufferValue::SizeFunction& size_fn,\n+    const AliasInfo* alias_info,\n+    const BufferValue::SizeFunction* absl_nonnull size_fn,\n     const Options& options) {\n   HeapSimulator heap(std::move(algorithm), size_fn, options, &schedule);\n   const HloComputation* entry_computation = module.entry_computation();\n@@ -266,7 +268,8 @@ absl::StatusOr<HeapSimulator::Result<HloValue>> HeapSimulator::Run(\n     const HloComputation& computation,\n     const HloInstructionSequence& instruction_sequence,\n     const HloAliasAnalysis& alias_analysis, const AliasInfo* alias_info,\n-    const BufferValue::SizeFunction& size_fn, const Options& options) {\n+    const BufferValue::SizeFunction* absl_nonnull size_fn,\n+    const Options& options) {\n   HeapSimulator heap(std::move(algorithm), size_fn, options,\n                      /*schedule=*/nullptr);\n   HloSchedule schedule(computation.parent());\n@@ -286,8 +289,8 @@ absl::StatusOr<HeapSimulator::Result<HloValue>> HeapSimulator::Run(\n     const HloComputation& computation,\n     const HloInstructionSequence& instruction_sequence,\n     const HloAliasAnalysis& alias_analysis, const AliasInfo* alias_info,\n-    const BufferValue::SizeFunction& size_fn, const HloSchedule* schedule,\n-    const Options& options) {\n+    const BufferValue::SizeFunction* absl_nonnull size_fn,\n+    const HloSchedule* schedule, const Options& options) {\n   HeapSimulator heap(std::move(algorithm), size_fn, options,\n                      /*schedule=*/schedule);\n   TF_ASSIGN_OR_RETURN(\n@@ -376,7 +379,7 @@ absl::Status HeapSimulator::RunComputation(\n   for (const HloBuffer& buffer : alias_analysis.buffers()) {\n     int64_t size = 0;\n     for (const HloValue* value : buffer.values()) {\n-      size = std::max(size, size_fn_(*value));\n+      size = std::max(size, (*size_fn_)(*value));\n     }\n     for (const HloValue* value : buffer.values()) {\n       buffer_sizes_[value] = size;\n@@ -464,7 +467,7 @@ absl::Status HeapSimulator::RunComputation(\n               operand_live_range.end = user_live_range.end;\n               VLOG(1) << \"Sharing \" << value->ToShortString() << \" with \"\n                       << operand_value->ToShortString()\n-                      << \", size:\" << size_fn_(*value);\n+                      << \", size:\" << (*size_fn_)(*value);\n               shared = true;\n               break;\n             }\n@@ -492,10 +495,10 @@ absl::Status HeapSimulator::RunComputation(\n   return absl::OkStatus();\n }\n \n-HeapSimulator::HeapSimulator(std::unique_ptr<HeapAlgorithm<HloValue>> algorithm,\n-                             const BufferValue::SizeFunction& size_fn,\n-                             const Options& options,\n-                             const HloSchedule* schedule)\n+HeapSimulator::HeapSimulator(\n+    std::unique_ptr<HeapAlgorithm<HloValue>> algorithm,\n+    const BufferValue::SizeFunction* absl_nonnull size_fn,\n+    const Options& options, const HloSchedule* schedule)\n     : no_fragmentation_stats_(\n           std::make_unique<NoFragmentationStatsHeap<HloValue>>()),\n       algorithm_(std::move(algorithm)),"
        },
        {
            "sha": "a9e30a6e9a9cc960abc564352df5741855c4ae64",
            "filename": "third_party/xla/xla/service/heap_simulator/heap_simulator.h",
            "status": "modified",
            "additions": 10,
            "deletions": 8,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2Fheap_simulator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2Fheap_simulator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2Fheap_simulator.h?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -28,6 +28,8 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/base/nullability.h\"\n+\n // TODO(b/210891274): Use btree_map after build issue in Windows is resolved.\n #if defined(__GNUC__) || defined(__clang__)\n #include \"absl/container/btree_map.h\"\n@@ -146,14 +148,14 @@ class HeapSimulator {\n   static absl::StatusOr<int64_t> MinimumMemoryForModule(\n       const HloSchedule& schedule, const HloAliasAnalysis& alias_analysis,\n       const AliasInfo* alias_info,\n-      const LogicalBuffer::SizeFunction& size_function);\n+      const LogicalBuffer::SizeFunction* absl_nonnull size_function);\n \n   // Returns the minimum memory required to compute the given computation,\n   // assuming no fragmentation.\n   static absl::StatusOr<int64_t> MinimumMemoryForComputation(\n       const HloComputation& computation, const HloInstructionSequence& sequence,\n       const HloAliasAnalysis& alias_analysis, const AliasInfo* alias_info,\n-      const LogicalBuffer::SizeFunction& size_function);\n+      const LogicalBuffer::SizeFunction* absl_nonnull size_function);\n \n   // Run the heap simulation with the given algorithm, assuming the given\n   // schedule, which must contain a topologically-consistent total\n@@ -168,7 +170,7 @@ class HeapSimulator {\n       std::unique_ptr<HeapAlgorithm<HloValue>> algorithm,\n       const HloModule& module, const HloSchedule& schedule,\n       const HloAliasAnalysis& alias_analysis, const AliasInfo* alias_info,\n-      const BufferValue::SizeFunction& size_fn,\n+      const BufferValue::SizeFunction* absl_nonnull size_fn,\n       const Options& options = Options());\n \n   // Same as above, but runs on a single computation. The 'instruction_sequence'\n@@ -180,7 +182,7 @@ class HeapSimulator {\n       const HloComputation& computation,\n       const HloInstructionSequence& instruction_sequence,\n       const HloAliasAnalysis& alias_analysis, const AliasInfo* alias_info,\n-      const BufferValue::SizeFunction& size_fn,\n+      const BufferValue::SizeFunction* absl_nonnull size_fn,\n       const Options& options = Options());\n \n   // Same as above, but runs on with a schedule that covers all nested\n@@ -190,15 +192,15 @@ class HeapSimulator {\n       const HloComputation& computation,\n       const HloInstructionSequence& instruction_sequence,\n       const HloAliasAnalysis& alias_analysis, const AliasInfo* alias_info,\n-      const BufferValue::SizeFunction& size_fn, const HloSchedule* schedule,\n-      const Options& options = Options());\n+      const BufferValue::SizeFunction* absl_nonnull size_fn,\n+      const HloSchedule* schedule, const Options& options = Options());\n \n  private:\n   // If 'schedule' is non-null, it is used to find kCall and kWhile\n   // sub-computations, and the heap simulation for those sub-computations will\n   // be run recursively. I.e. the simulation is run over the whole module.\n   HeapSimulator(std::unique_ptr<HeapAlgorithm<HloValue>> algorithm,\n-                const BufferValue::SizeFunction& size_fn,\n+                const BufferValue::SizeFunction* absl_nonnull size_fn,\n                 const Options& options, const HloSchedule* schedule = nullptr);\n   ~HeapSimulator();\n \n@@ -236,7 +238,7 @@ class HeapSimulator {\n   const std::unique_ptr<NoFragmentationStatsHeap<HloValue>>\n       no_fragmentation_stats_;\n   const std::unique_ptr<HeapAlgorithm<HloValue>> algorithm_;\n-  const BufferValue::SizeFunction size_fn_;\n+  const BufferValue::SizeFunction* absl_nonnull size_fn_;\n   const Options options_;\n   // schedule_ is set by buffer assignment. Then, in RunComputation, we check\n   // both in order to handle subcomputations. It would be good to unify the"
        },
        {
            "sha": "c9cdfd584a9aec8f69d6defb4410740e5c432a04",
            "filename": "third_party/xla/xla/service/heap_simulator/heap_simulator_test.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 12,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2Fheap_simulator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2Fheap_simulator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fheap_simulator%2Fheap_simulator_test.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -110,7 +110,7 @@ TEST_F(MinimumMemoryForSequenceTest, MultiComputation) {\n   HloComputation* entry_computation =\n       module->AddEntryComputation(builder.Build());\n \n-  auto size_fn = [](const BufferValue& buffer) {\n+  BufferValue::SizeFunction size_fn = [](const BufferValue& buffer) {\n     return ShapeUtil::ByteSizeOf(buffer.shape(), /*pointer_size=*/8);\n   };\n \n@@ -124,7 +124,7 @@ TEST_F(MinimumMemoryForSequenceTest, MultiComputation) {\n   std::unique_ptr<HloAliasAnalysis> alias_analysis =\n       HloAliasAnalysis::Run(module.get(), &alias_info_).value();\n   EXPECT_EQ(25, HeapSimulator::MinimumMemoryForModule(schedule, *alias_analysis,\n-                                                      &alias_info_, size_fn)\n+                                                      &alias_info_, &size_fn)\n                     .value());\n }\n \n@@ -230,7 +230,7 @@ TEST_F(MinimumMemoryForSequenceTest, SubcomputationAccounting) {\n   schedule.set_sequence(body_computation, while_body_vec);\n   schedule.set_sequence(entry_computation, entry_comp_vec);\n \n-  auto size_fn = [](const BufferValue& buffer) {\n+  BufferValue::SizeFunction size_fn = [](const BufferValue& buffer) {\n     return ShapeUtil::ByteSizeOf(buffer.shape());\n   };\n \n@@ -241,7 +241,7 @@ TEST_F(MinimumMemoryForSequenceTest, SubcomputationAccounting) {\n   // so we don't double count.\n   EXPECT_EQ(64, HeapSimulator::MinimumMemoryForComputation(\n                     *entry_computation, schedule.sequence(entry_computation),\n-                    *alias_analysis, &alias_info_, size_fn)\n+                    *alias_analysis, &alias_info_, &size_fn)\n                     .value());\n }\n \n@@ -352,12 +352,13 @@ class HeapSimulatorTracker {\n     // the sequence. This lets us ensure the Alloc calls are in the sequence\n     // order. The Free calls are sorted by BufferValue.id, which is at least\n     // deterministic.\n-    auto size_fn = [&reverse_position](const BufferValue& buffer) {\n-      return reverse_position[buffer.instruction()];\n-    };\n+    BufferValue::SizeFunction size_fn =\n+        [&reverse_position](const BufferValue& buffer) {\n+          return reverse_position[buffer.instruction()];\n+        };\n     auto algorithm = std::make_unique<HeapCallRecorder>(&actual_calls_);\n     result_ = HeapSimulator::Run(std::move(algorithm), *module_, schedule,\n-                                 *alias_analysis_, &alias_info_, size_fn)\n+                                 *alias_analysis_, &alias_info_, &size_fn)\n                   .value();\n   }\n \n@@ -416,7 +417,9 @@ class HeapSimulatorTracker {\n     // size of the buffers doesn't matter, so we always return 0.  We rely on\n     // the secondary sorting criteria of DecreasingSizeRunsHeap to sort calls\n     // by buffer id, for determinism in the tests.\n-    auto zero_size = [](const BufferValue& buffer) { return 0; };\n+    BufferValue::SizeFunction zero_size = [](const BufferValue& buffer) {\n+      return 0;\n+    };\n     auto algorithm = std::make_unique<HeapCallRecorder>(&actual_calls_);\n \n     alias_analysis_ = HloAliasAnalysis::Run(module_.get(), alias_info).value();\n@@ -426,7 +429,7 @@ class HeapSimulatorTracker {\n     result_ =\n         HeapSimulator::Run(std::move(algorithm), *module_->entry_computation(),\n                            HloInstructionSequence(instruction_sequence),\n-                           *alias_analysis_, &alias_info_, zero_size, options)\n+                           *alias_analysis_, &alias_info_, &zero_size, options)\n             .value();\n   }\n \n@@ -998,7 +1001,7 @@ TEST_F(HeapSimulatorTest, AsyncCallImplicitSharding) {\n                           ParseAndReturnUnverifiedModule(hlo_string));\n   TF_ASSERT_OK_AND_ASSIGN(auto alias_analysis,\n                           HloAliasAnalysis::Run(module.get(), &alias_info_));\n-  auto size_fn = [](const BufferValue& buffer) -> int64_t {\n+  BufferValue::SizeFunction size_fn = [](const BufferValue& buffer) -> int64_t {\n     const Shape& shape = buffer.shape();\n     if (!shape.IsArray()) {\n       return 0;\n@@ -1010,7 +1013,7 @@ TEST_F(HeapSimulatorTest, AsyncCallImplicitSharding) {\n \n   HeapSimulator::Result<HloValue> result =\n       HeapSimulator::Run(std::move(algorithm), *module, module->schedule(),\n-                         *alias_analysis, &alias_info_, size_fn)\n+                         *alias_analysis, &alias_info_, &size_fn)\n           .value();\n   for (const auto& [value, chunk] : result.heap_results[0].chunk_map) {\n     if (value->instruction()->name() == \"dynamic-update-slice\") {"
        },
        {
            "sha": "ecfa69a01d80b870bba35ae63a4a2bc4f1745290",
            "filename": "third_party/xla/xla/service/latency_hiding_scheduler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -203,7 +203,7 @@ int64_t EstimateFragmentationSize(HloModule* module,\n   // Run heap simulator on the whole module to estimate the fragmentation size.\n   auto algorithm = std::make_unique<GlobalDecreasingSizeBestFitHeap<HloValue>>(\n       /*alignment=*/1);\n-  auto size_fn = [](const BufferValue& buffer) -> int64_t {\n+  BufferValue::SizeFunction size_fn = [](const BufferValue& buffer) -> int64_t {\n     const Shape& shape = buffer.shape();\n     if (!shape.IsArray()) {\n       return 0;\n@@ -212,7 +212,7 @@ int64_t EstimateFragmentationSize(HloModule* module,\n   };\n   auto result =\n       HeapSimulator::Run(std::move(algorithm), *module, module->schedule(),\n-                         alias_analysis, alias_info, size_fn);\n+                         alias_analysis, alias_info, &size_fn);\n   CHECK_OK(result.status());\n   int64_t fragmentation_size = result.value().fragmentation_size;\n   VLOG(3) << module->name() << \": Heap simulator estimated fragmentation size: \""
        },
        {
            "sha": "80131ac112211c7a59421812ee75107a589af38a",
            "filename": "third_party/xla/xla/service/memory_space_assignment/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2FBUILD?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -51,7 +51,6 @@ cc_library(\n         \"//xla/hlo/analysis:hlo_dataflow_analysis\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/utils:hlo_live_range\",\n-        \"//xla/service:buffer_value\",\n         \"//xla/service:hlo_buffer\",\n         \"//xla/service:hlo_proto_cc\",\n         \"//xla/service:hlo_value\",\n@@ -508,10 +507,12 @@ cc_library(\n         \"//xla/service/heap_simulator:allocation_block\",\n         \"//xla/tsl/platform:errors\",\n         \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/base:nullability\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/log:die_if_null\",\n         \"@com_google_absl//absl/memory\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\","
        },
        {
            "sha": "35f13657a4d0a24e0f53a8a8c9510d0da5166f64",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_bound_loop_optimizer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_bound_loop_optimizer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_bound_loop_optimizer.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -17,7 +17,6 @@ limitations under the License.\n \n #include <algorithm>\n #include <cstdint>\n-#include <functional>\n #include <iterator>\n #include <memory>\n #include <optional>\n@@ -28,9 +27,11 @@ limitations under the License.\n #include <vector>\n \n #include \"absl/algorithm/container.h\"\n+#include \"absl/base/nullability.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/log/check.h\"\n+#include \"absl/log/die_if_null.h\"\n #include \"absl/log/log.h\"\n #include \"absl/memory/memory.h\"\n #include \"absl/status/status.h\"\n@@ -350,7 +351,7 @@ MemoryBoundLoopOptimizer::Create(int loop_start, int loop_end,\n       absl::WrapUnique(new MemoryBoundLoopOptimizer(\n           loop_start, loop_end, options.max_size_in_bytes,\n           options.memory_bound_loop_optimizer_options, hlo_live_range,\n-          alias_analysis, *options.cost_analysis, options.size_fn,\n+          alias_analysis, *options.cost_analysis, &options.size_fn,\n           options.reserved_scoped_memory_fn, options.alignment_in_bytes));\n   TF_RETURN_IF_ERROR(optimizer->Initialize());\n   return std::move(optimizer);\n@@ -361,7 +362,7 @@ MemoryBoundLoopOptimizer::MemoryBoundLoopOptimizer(\n     const MemoryBoundLoopOptimizerOptions& options,\n     const HloLiveRange& hlo_live_range, const HloAliasAnalysis& alias_analysis,\n     const CostAnalysis& cost_analysis,\n-    const BufferValue::SizeFunction& size_function,\n+    const BufferValue::SizeFunction* absl_nonnull size_function,\n     const ReservedScopedMemoryFunction& reserved_scoped_memory_fn,\n     int64_t alignment_in_bytes)\n     : loop_start_(loop_start),\n@@ -372,7 +373,7 @@ MemoryBoundLoopOptimizer::MemoryBoundLoopOptimizer(\n       hlo_live_range_(hlo_live_range),\n       alias_analysis_(alias_analysis),\n       cost_analysis_(cost_analysis),\n-      size_function_(size_function),\n+      size_function_(ABSL_DIE_IF_NULL(size_function)),\n       reserved_scoped_memory_fn_(reserved_scoped_memory_fn),\n       heap_(LoopOptimizerBestFitHeap(alternate_memory_size,\n                                      /*loop_size=*/loop_end - loop_start,\n@@ -541,7 +542,7 @@ void MemoryBoundLoopOptimizer::MaybeCreateLoopValue(\n   // later, so we will add that one instead.\n   if ((!loop_value.loop_positions.empty() || !loop_value.loop_uses.empty()) &&\n       loop_value.prev_iteration_positions.empty()) {\n-    loop_value.size = size_function_(**buffer.values().begin());\n+    loop_value.size = (*size_function_)(**buffer.values().begin());\n     VLOG(3) << \"Size: \" << loop_value.size;\n     // Classify the type of allocation. See the comment in LoopValue definition.\n     loop_value.allocation_type = LoopValue::AllocationType::kUnsupported;"
        },
        {
            "sha": "a5d20c5a70b6de02660aedff24ef7e036d878532",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_bound_loop_optimizer.h",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_bound_loop_optimizer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_bound_loop_optimizer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_bound_loop_optimizer.h?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/base/nullability.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/log/check.h\"\n #include \"absl/status/status.h\"\n@@ -382,7 +383,7 @@ class MemoryBoundLoopOptimizer {\n       const HloLiveRange& hlo_live_range,\n       const HloAliasAnalysis& alias_analysis_,\n       const CostAnalysis& cost_analysis,\n-      const BufferValue::SizeFunction& size_function,\n+      const BufferValue::SizeFunction* absl_nonnull size_function,\n       const ReservedScopedMemoryFunction& reserved_scoped_memory_fn,\n       int64_t alignment_in_bytes);\n \n@@ -451,7 +452,7 @@ class MemoryBoundLoopOptimizer {\n   const HloLiveRange& hlo_live_range_;\n   const HloAliasAnalysis& alias_analysis_;\n   const CostAnalysis& cost_analysis_;\n-  BufferValue::SizeFunction size_function_;\n+  const BufferValue::SizeFunction* absl_nonnull size_function_;\n \n   absl::flat_hash_map<const HloInstruction*, int64_t> instructions_in_loop_;\n   absl::flat_hash_map<const HloInstruction*, int64_t>"
        },
        {
            "sha": "b51f13a57d32812e618a2807f7a4db51aa525f97",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -47,7 +47,6 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_schedule.h\"\n #include \"xla/hlo/utils/hlo_live_range.h\"\n #include \"xla/layout.h\"\n-#include \"xla/service/buffer_value.h\"\n #include \"xla/service/heap_simulator/heap_simulator.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/service/hlo_buffer.h\"\n@@ -456,12 +455,10 @@ absl::Status MemorySpaceAssignment::FindAllocationSequence(\n   HeapSimulator::Options heap_simulator_options;\n   heap_simulator_options.may_reuse_operand_buffers = false;\n   heap_simulator_options.alloc_constants = true;\n-  TF_RETURN_IF_ERROR(HeapSimulator::Run(std::move(algorithm), *module_,\n-                                        module_->schedule(), alias_analysis,\n-                                        alias_info_, options_.size_fn,\n-                                        heap_simulator_options)\n-                         .status());\n-  return absl::OkStatus();\n+  return HeapSimulator::Run(std::move(algorithm), *module_, module_->schedule(),\n+                            alias_analysis, alias_info_, &options_.size_fn,\n+                            heap_simulator_options)\n+      .status();\n }\n \n MemorySpaceAssignment::ScopedMemorySource"
        },
        {
            "sha": "ebe573127607b02f8e4016af9bbfb721b48cfbf2",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc",
            "status": "modified",
            "additions": 261,
            "deletions": 201,
            "changes": 462,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -215,7 +215,7 @@ TEST_F(MemorySpaceAssignmentTest, Simple) {\n \n   Options options = DefaultMemorySpaceOptions();\n   options.post_module_scoped_alternate_memory_size_in_bytes = 10;\n-  auto preset_assignments = AssignMemorySpace(module.get(), options);\n+  auto preset_assignments = AssignMemorySpace(module.get(), std::move(options));\n \n   // Check that the post-module scoped alternate memory chunk is set correctly.\n   ASSERT_TRUE(preset_assignments->post_module_scoped_alternate_memory_chunk()\n@@ -298,7 +298,7 @@ TEST_F(MemorySpaceAssignmentTest, BasicSplit) {\n     return std::nullopt;\n   };\n \n-  auto preset_assignments = AssignMemorySpace(module.get(), options);\n+  auto preset_assignments = AssignMemorySpace(module.get(), std::move(options));\n \n   // Inputs and outputs are currently placed in the default memory. Everything\n   // else should be in the alternate memory.\n@@ -462,7 +462,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(hlo_string));\n   Options options = DefaultMemorySpaceOptions();\n   options.enable_sync_copy_replacement = true;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* add0 = FindInstruction(module.get(), \"add0\");\n   ASSERT_NE(add0, nullptr);\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n@@ -496,7 +496,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(hlo_string));\n   Options options = DefaultMemorySpaceOptions();\n   options.enable_sync_copy_replacement = true;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* add0 = FindInstruction(module.get(), \"add0\");\n   ASSERT_NE(add0, nullptr);\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n@@ -560,7 +560,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(hlo_string));\n   Options options = DefaultMemorySpaceOptions();\n   options.enable_sync_copy_replacement = true;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n \n   HloInstruction* dynamic_update_slice_0 =\n@@ -606,7 +606,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(hlo_string));\n   Options options = DefaultMemorySpaceOptions();\n   options.enable_sync_copy_replacement = true;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n   HloInstruction* add0 = FindInstruction(module.get(), \"add0\");\n   HloInstruction* p0_negate0 = FindInstruction(module.get(), \"p0_negate0\");\n@@ -650,7 +650,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncSliceReplacementAfterPrefetch) {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* concat = FindInstruction(module.get(), \"concat\");\n   ASSERT_NE(concat, nullptr);\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n@@ -692,11 +692,14 @@ TEST_F(MemorySpaceAssignmentTest,\n                           ParseAndReturnVerifiedModule(hlo_string));\n   auto module_copy = module->Clone();\n \n-  Options options = DefaultMemorySpaceOptions();\n-  options.max_size_in_bytes = 512;  // Ensure p0_data can be prefetched\n-  options.enable_sync_slice_replacement = true;\n-  options.is_async_slice_implemented_fn =\n-      [](const HloInstruction* instruction) { return true; };\n+  const auto kMakeOptions = [this]() {\n+    Options options = DefaultMemorySpaceOptions();\n+    options.max_size_in_bytes = 512;  // Ensure p0_data can be prefetched\n+    options.enable_sync_slice_replacement = true;\n+    options.is_async_slice_implemented_fn =\n+        [](const HloInstruction* instruction) { return true; };\n+    return options;\n+  };\n \n   // The index operand is not available until the dynamic-slice instruction\n   // itself which pushes earliest_prefetch_time to right before the\n@@ -705,15 +708,17 @@ TEST_F(MemorySpaceAssignmentTest,\n   //   The dynamic slice is NOT replaced by an async. This is because we\n   //   require at least 2 instructions to be overlapped (including the\n   //   dynamic-slice).\n-  AssignMemorySpace(module.get(), options, /*max_prefetch_interval=*/10,\n+  AssignMemorySpace(module.get(), kMakeOptions(),\n+                    /*max_prefetch_interval=*/10,\n                     /*min_prefetch_interval=*/2);\n   HloInstruction* root = module->entry_computation()->root_instruction();\n   ASSERT_NE(root, nullptr);\n   ASSERT_EQ(root->operand(0)->opcode(), HloOpcode::kDynamicSlice);\n \n   // Case 2 - min_prefetch_interval = 1:\n   //   The dynamic slice is replaced by an async.\n-  AssignMemorySpace(module_copy.get(), options, /*max_prefetch_interval=*/10,\n+  AssignMemorySpace(module_copy.get(), kMakeOptions(),\n+                    /*max_prefetch_interval=*/10,\n                     /*min_prefetch_interval=*/1);\n   root = module_copy->entry_computation()->root_instruction();\n   ASSERT_NE(root, nullptr);\n@@ -750,7 +755,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncDynamicSliceReplacementAfterPrefetch) {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* concat = FindInstruction(module.get(), \"concat\");\n   ASSERT_NE(concat, nullptr);\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n@@ -791,7 +796,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncSliceReplacementIgnoredTrivials) {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* concat = FindInstruction(module.get(), \"concat\");\n   ASSERT_NE(concat, nullptr);\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n@@ -832,7 +837,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncDynamicSliceReplacementIgnoredTrivials) {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* concat = FindInstruction(module.get(), \"concat\");\n   ASSERT_NE(concat, nullptr);\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n@@ -878,7 +883,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncSliceReplacementAfterEviction) {\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n \n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   HloInstruction* negate_p0 = FindInstruction(module.get(), \"negate_p0\");\n   ASSERT_NE(negate_p0, nullptr);\n@@ -925,7 +930,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncDynamicSliceReplacementAfterEviction) {\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n \n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* negate_p0 = FindInstruction(module.get(), \"negate_p0\");\n   ASSERT_NE(negate_p0, nullptr);\n   HloInstruction* concat = FindInstruction(module.get(), \"concat\");\n@@ -968,7 +973,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncSliceReplacementTwoSlices) {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* add = FindInstruction(module.get(), \"add\");\n   ASSERT_NE(add, nullptr);\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n@@ -1009,7 +1014,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncDynamicSliceReplacementTwoSlices) {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* add = FindInstruction(module.get(), \"add\");\n   ASSERT_NE(add, nullptr);\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n@@ -1057,7 +1062,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncSliceReplacementNestedSlices) {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n   ASSERT_NE(p0, nullptr);\n   HloInstruction* concat = FindInstruction(module.get(), \"concat\");\n@@ -1101,7 +1106,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncDynamicSliceReplacementNestedSlices) {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n   HloInstruction* index = FindInstruction(module.get(), \"index\");\n   HloInstruction* zero = FindInstruction(module.get(), \"zero\");\n@@ -1143,7 +1148,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncSliceReplacementOneFails) {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n   ASSERT_NE(p0, nullptr);\n   HloInstruction* add0 = FindInstruction(module.get(), \"add.0\");\n@@ -1187,7 +1192,7 @@ TEST_F(MemorySpaceAssignmentTest, SyncDynamicSliceReplacementOneFails) {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n   HloInstruction* index = FindInstruction(module.get(), \"index\");\n   HloInstruction* zero = FindInstruction(module.get(), \"zero\");\n@@ -1226,15 +1231,19 @@ ENTRY entry {\n   }\n   )\";\n \n-  Options options = DefaultMemorySpaceOptions();\n-  options.is_async_slice_implemented_fn =\n-      [](const HloInstruction* instruction) { return true; };\n-  options.max_size_in_bytes = 64;\n+  const auto kMakeOptions = [this](bool enable_sync_slice_replacement) {\n+    Options options = DefaultMemorySpaceOptions();\n+    options.is_async_slice_implemented_fn =\n+        [](const HloInstruction* instruction) { return true; };\n+    options.max_size_in_bytes = 64;\n+    options.enable_sync_slice_replacement = enable_sync_slice_replacement;\n+    return options;\n+  };\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module1,\n                           ParseAndReturnVerifiedModule(hlo_string));\n-  options.enable_sync_slice_replacement = false;\n-  AssignMemorySpace(module1.get(), options);\n+  AssignMemorySpace(module1.get(),\n+                    kMakeOptions(/*enable_sync_slice_replacement=*/false));\n   HloInstruction* p0 = FindInstruction(module1.get(), \"p0\");\n   ASSERT_NE(p0, nullptr);\n   HloInstruction* concat = FindInstruction(module1.get(), \"concat\");\n@@ -1243,8 +1252,8 @@ ENTRY entry {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module2,\n                           ParseAndReturnVerifiedModule(hlo_string));\n-  options.enable_sync_slice_replacement = true;\n-  AssignMemorySpace(module2.get(), options);\n+  AssignMemorySpace(module2.get(),\n+                    kMakeOptions(/*enable_sync_slice_replacement=*/true));\n   p0 = FindInstruction(module2.get(), \"p0\");\n   ASSERT_NE(p0, nullptr);\n   concat = FindInstruction(module2.get(), \"concat\");\n@@ -1281,7 +1290,7 @@ ENTRY entry {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n   ASSERT_NE(p0, nullptr);\n   HloInstruction* concat = FindInstruction(module.get(), \"concat\");\n@@ -1348,7 +1357,7 @@ ENTRY %entry (p0.2: f32[10,2,3], p1: f32[10,2,3], p2: pred[]) -> f32[10,2,3] {\n   options.enable_sync_slice_replacement = true;\n   options.is_async_slice_implemented_fn =\n       [](const HloInstruction* instruction) { return true; };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   HloInstruction* while_instruction = FindInstruction(module.get(), \"while.1\");\n   ASSERT_NE(while_instruction, nullptr);\n   const HloInstruction* tuple = while_instruction->operand(0);\n@@ -1391,7 +1400,7 @@ TEST_F(MemorySpaceAssignmentTest, ConditionalCopyReplacement) {\n                           ParseAndReturnVerifiedModule(hlo_string));\n   Options options = DefaultMemorySpaceOptions();\n   options.enable_sync_copy_replacement = true;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   auto conditional =\n       module->GetComputationWithName(\"entry\")->GetInstructionWithName(\n           \"conditional\");\n@@ -1426,8 +1435,7 @@ ENTRY entry {\n   // The baseline behavior is to prefetch p0 at add0.\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> baseline_module,\n                           ParseAndReturnVerifiedModule(hlo_string));\n-  Options options = DefaultMemorySpaceOptions();\n-  AssignMemorySpace(baseline_module.get(), options);\n+  AssignMemorySpace(baseline_module.get(), DefaultMemorySpaceOptions());\n   HloInstruction* add0 = FindInstruction(baseline_module.get(), \"add0\");\n   ASSERT_NE(add0, nullptr);\n   HloInstruction* p0 = FindInstruction(baseline_module.get(), \"p0\");\n@@ -1440,17 +1448,19 @@ ENTRY entry {\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::unique_ptr<VerifiedHloModule> result_modifier_module,\n       ParseAndReturnVerifiedModule(hlo_string));\n-  options.max_retries = 1;\n-  options.allocation_request_modifier_testing_fn = nullptr;\n-  options.allocation_result_modifier_testing_fn =\n+  Options options_result_modifier = DefaultMemorySpaceOptions();\n+  options_result_modifier.max_retries = 1;\n+  options_result_modifier.allocation_request_modifier_testing_fn = nullptr;\n+  options_result_modifier.allocation_result_modifier_testing_fn =\n       [](const AllocationRequest& request, AllocationResult& result) {\n         if (request.allocation_value_to_update->defining_instruction()\n                     ->name() == \"p0\" &&\n             request.use->hlo_use.instruction->name() == \"add0\") {\n           result = AllocationResult::kFailRequiresUncommit;\n         }\n       };\n-  AssignMemorySpace(result_modifier_module.get(), options);\n+  AssignMemorySpace(result_modifier_module.get(),\n+                    std::move(options_result_modifier));\n   add0 = FindInstruction(result_modifier_module.get(), \"add0\");\n   ASSERT_NE(add0, nullptr);\n   p0 = FindInstruction(result_modifier_module.get(), \"p0\");\n@@ -1462,8 +1472,9 @@ ENTRY entry {\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::unique_ptr<VerifiedHloModule> request_modifier_module,\n       ParseAndReturnVerifiedModule(hlo_string));\n-  options.max_retries = 1;\n-  options\n+  Options options_request_modifier = DefaultMemorySpaceOptions();\n+  options_request_modifier.max_retries = 1;\n+  options_request_modifier\n       .allocation_request_modifier_testing_fn = [](AllocationRequest& request) {\n     if (request.allocation_value_to_update->defining_instruction()->name() ==\n             \"p0\" &&\n@@ -1472,8 +1483,9 @@ ENTRY entry {\n       request.latest_prefetch_time = 6;\n     }\n   };\n-  options.allocation_result_modifier_testing_fn = nullptr;\n-  AssignMemorySpace(request_modifier_module.get(), options);\n+  options_request_modifier.allocation_result_modifier_testing_fn = nullptr;\n+  AssignMemorySpace(request_modifier_module.get(),\n+                    std::move(options_request_modifier));\n   add0 = FindInstruction(request_modifier_module.get(), \"add0\");\n   CHECK_NE(add0, nullptr);\n   p0 = FindInstruction(request_modifier_module.get(), \"p0\");\n@@ -1547,7 +1559,7 @@ ENTRY entry {\n   // options.inefficient_use_to_copy_ratio must be greater than 0 and the cost\n   // model must be set to trigger the inefficient allocation site logic.\n   options.inefficient_use_to_copy_ratio = 1.0;\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(), std::move(options));\n \n   HloInstruction* p0_copy = FindInstruction(module.get(), \"p0_copy\");\n   ASSERT_NE(p0_copy, nullptr);\n@@ -1614,7 +1626,7 @@ ENTRY entry {\n   TF_ASSERT_OK_AND_ASSIGN(auto msa_sort_order_overrides,\n                           ParseTextProto<MsaSortOrderOverrides>(text_proto));\n   auto preset_assignments = AssignMemorySpaceUsingCostAnalysis(\n-      module.get(), options,\n+      module.get(), std::move(options),\n       /*cost_analysis_options_override=*/std::nullopt,\n       /*hlo_cost_options_override=*/std::nullopt,\n       /*optional_msa_sort_order_overrides=*/msa_sort_order_overrides);\n@@ -1658,7 +1670,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(hlo_string));\n   Options options = DefaultMemorySpaceOptions();\n   options.always_spill_to_default_memory = true;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   const HloInstructionSequence& sequence =\n       module->schedule().sequence(module->entry_computation());\n   for (int i = 0; i < sequence.instructions().size(); ++i) {\n@@ -1714,7 +1726,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(hlo_string));\n   Options options = DefaultMemorySpaceOptions();\n   options.always_spill_to_default_memory = true;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   const HloInstructionSequence& sequence =\n       module->schedule().sequence(module->entry_computation());\n   for (int i = 0; i < sequence.instructions().size(); ++i) {\n@@ -1795,7 +1807,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(hlo_string));\n   Options options = DefaultMemorySpaceOptions();\n   options.always_spill_to_default_memory = true;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   const HloInstructionSequence& sequence =\n       module->schedule().sequence(module->entry_computation());\n   for (int i = 0; i < sequence.instructions().size(); ++i) {\n@@ -1879,7 +1891,7 @@ TEST_F(MemorySpaceAssignmentTest, FilterUpdatePreferredPrefetchTest) {\n       options.preferred_prefetch_overrides,\n       ParseTextProto<PreferredPrefetchOverrides>(text_proto));\n \n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   EXPECT_THAT(add, op::Add(op::Negate(), op::AsyncCopy(kAlternateMemorySpace,\n                                                        kDefaultMemorySpace,\n@@ -1957,7 +1969,7 @@ TEST_F(MemorySpaceAssignmentTest, FilterUpdateConfigExactMatchBeforeTest) {\n       options.preferred_prefetch_overrides,\n       ParseTextProto<PreferredPrefetchOverrides>(text_proto));\n \n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   EXPECT_THAT(add, op::Add(op::Negate(), op::AsyncCopy(kAlternateMemorySpace,\n                                                        kDefaultMemorySpace,\n@@ -2035,7 +2047,7 @@ TEST_F(MemorySpaceAssignmentTest, FilterUpdateConfigExactMatchAfterTest) {\n       options.preferred_prefetch_overrides,\n       ParseTextProto<PreferredPrefetchOverrides>(text_proto));\n \n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   EXPECT_THAT(add, op::Add(op::Negate(), op::AsyncCopy(kAlternateMemorySpace,\n                                                        kDefaultMemorySpace,\n@@ -2113,7 +2125,7 @@ TEST_F(MemorySpaceAssignmentTest, FilterUpdateConfigExactMatchTooLateTest) {\n       options.preferred_prefetch_overrides,\n       ParseTextProto<PreferredPrefetchOverrides>(text_proto));\n \n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   // Ensure the Async copy is not scheduled.\n   EXPECT_THAT(add, op::Add(op::Negate(), op::Parameter(1)));\n@@ -2187,7 +2199,7 @@ TEST_F(MemorySpaceAssignmentTest, FilterUpdateConfigPrecedenceTest) {\n       options.preferred_prefetch_overrides,\n       ParseTextProto<PreferredPrefetchOverrides>(text_proto));\n \n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   EXPECT_THAT(add, op::Add(op::Negate(), op::AsyncCopy(kAlternateMemorySpace,\n                                                        kDefaultMemorySpace,\n@@ -2270,7 +2282,7 @@ TEST_F(MemorySpaceAssignmentTest, FilterUpdateConfigExactMatchPrecedenceTest) {\n       options.preferred_prefetch_overrides,\n       ParseTextProto<PreferredPrefetchOverrides>(text_proto));\n \n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   EXPECT_THAT(add, op::Add(op::Negate(), op::AsyncCopy(kAlternateMemorySpace,\n                                                        kDefaultMemorySpace,\n@@ -2347,7 +2359,7 @@ TEST_F(MemorySpaceAssignmentTest, FilterUpdatePreferredPrefetchNoMatchTest) {\n       options.preferred_prefetch_overrides,\n       ParseTextProto<PreferredPrefetchOverrides>(text_proto));\n \n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   EXPECT_THAT(add, op::Add(op::Negate(), op::AsyncCopy(kAlternateMemorySpace,\n                                                        kDefaultMemorySpace,\n@@ -5541,9 +5553,9 @@ ENTRY entry {\n                           ParseTextProto<MsaSortOrderOverrides>(text_proto));\n \n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options,\n-                                     std::nullopt, std::nullopt,\n-                                     msa_sort_order_overrides);\n+  AssignMemorySpaceUsingCostAnalysis(\n+      module.get(), std::move(memory_space_options), std::nullopt, std::nullopt,\n+      msa_sort_order_overrides);\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n   EXPECT_EQ(\n       FindInstruction(module.get(), \"tanh0\")->shape().layout().memory_space(),\n@@ -5590,9 +5602,9 @@ ENTRY entry {\n                           ParseTextProto<MsaSortOrderOverrides>(text_proto));\n \n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options,\n-                                     std::nullopt, std::nullopt,\n-                                     msa_sort_order_overrides);\n+  AssignMemorySpaceUsingCostAnalysis(\n+      module.get(), std::move(memory_space_options), std::nullopt, std::nullopt,\n+      msa_sort_order_overrides);\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n   EXPECT_EQ(FindInstruction(module.get(), \"negate4\")\n                 ->operand(1)\n@@ -5646,9 +5658,9 @@ ENTRY entry {\n                           ParseTextProto<MsaSortOrderOverrides>(text_proto));\n \n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options,\n-                                     std::nullopt, std::nullopt,\n-                                     msa_sort_order_overrides);\n+  AssignMemorySpaceUsingCostAnalysis(\n+      module.get(), std::move(memory_space_options), std::nullopt, std::nullopt,\n+      msa_sort_order_overrides);\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n   EXPECT_EQ(\n       FindInstruction(module.get(), \"tanh0\")->shape().layout().memory_space(),\n@@ -5705,9 +5717,9 @@ ROOT tuple = (f32[3,4]{1,0}, f32[3,4]{1,0}) tuple(tanh4, negate4)\n                           ParseTextProto<MsaSortOrderOverrides>(text_proto));\n \n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options,\n-                                     std::nullopt, std::nullopt,\n-                                     msa_sort_order_overrides);\n+  AssignMemorySpaceUsingCostAnalysis(\n+      module.get(), std::move(memory_space_options), std::nullopt, std::nullopt,\n+      msa_sort_order_overrides);\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n   EXPECT_EQ(\n       FindInstruction(module.get(), \"tanh0\")->shape().layout().memory_space(),\n@@ -5770,9 +5782,9 @@ ROOT tuple = (f32[3,4]{1,0}, f32[3,4]{1,0}) tuple(tanh4, negate4)\n                           ParseTextProto<MsaSortOrderOverrides>(text_proto));\n \n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options,\n-                                     std::nullopt, std::nullopt,\n-                                     msa_sort_order_overrides);\n+  AssignMemorySpaceUsingCostAnalysis(\n+      module.get(), std::move(memory_space_options), std::nullopt, std::nullopt,\n+      msa_sort_order_overrides);\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n   EXPECT_EQ(\n       FindInstruction(module.get(), \"negate0\")->shape().layout().memory_space(),\n@@ -5848,7 +5860,7 @@ ENTRY main {\n   options.buffer_colorings = {{negate1_position, kAlternateMemorySpace}};\n \n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(), std::move(options));\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n \n   EXPECT_EQ(\n@@ -5949,7 +5961,7 @@ ENTRY main {\n   options.buffer_colorings = {{negate1_position, kAlternateMemorySpace}};\n \n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(), std::move(options));\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n \n   EXPECT_EQ(\n@@ -6162,7 +6174,7 @@ TEST_F(MemorySpaceAssignmentTest,\n   // to alternate memory.\n   memory_space_options.max_size_in_bytes = 120;\n   AssignMemorySpaceUsingCostAnalysis(\n-      module.get(), memory_space_options,\n+      module.get(), std::move(memory_space_options),\n       /*cost_analysis_options_override=*/std::nullopt,\n       /*hlo_cost_options_override=*/std::nullopt,\n       /*optional_msa_sort_order_overrides=*/msa_sort_order_overrides);\n@@ -6238,7 +6250,7 @@ TEST_F(MemorySpaceAssignmentTest,\n   // tanh3.\n   memory_space_options.max_size_in_bytes = 160;\n   AssignMemorySpaceUsingCostAnalysis(\n-      module.get(), memory_space_options,\n+      module.get(), std::move(memory_space_options),\n       /*cost_analysis_options_override=*/std::nullopt,\n       /*hlo_cost_options_override=*/std::nullopt,\n       /*optional_msa_sort_order_overrides=*/msa_sort_order_overrides);\n@@ -6604,7 +6616,7 @@ TEST_F(MemorySpaceAssignmentTest,\n   };\n   XLA_VLOG_LINES(3, module->ToString());\n   std::unique_ptr<PresetAssignments> preset_assignments =\n-      AssignMemorySpace(module.get(), options);\n+      AssignMemorySpace(module.get(), std::move(options));\n   // Check that the post-module scoped alternate memory chunk is set correctly.\n   ASSERT_TRUE(preset_assignments->post_module_scoped_alternate_memory_chunk()\n                   .has_value());\n@@ -6822,7 +6834,7 @@ TEST_F(MemorySpaceAssignmentTest, DisallowedUseBug) {\n   options.is_use_allowed_in_alternate_mem_fn = [](const HloUse& use) {\n     return use.instruction->opcode() != HloOpcode::kTanh;\n   };\n-  AssignMemorySpace(module.get(), options, buffer_interval_compare,\n+  AssignMemorySpace(module.get(), std::move(options), buffer_interval_compare,\n                     &prefetch_interval_picker);\n }\n \n@@ -6885,7 +6897,7 @@ TEST_F(MemorySpaceAssignmentTest, DisallowedUseBugInWhile) {\n   options.is_use_allowed_in_alternate_mem_fn = [](const HloUse& use) {\n     return use.instruction->opcode() != HloOpcode::kTanh;\n   };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n }\n \n TEST_F(MemorySpaceAssignmentTest, TwoLiveAllocationValuesBase) {\n@@ -6928,8 +6940,8 @@ TEST_F(MemorySpaceAssignmentTest, TwoLiveAllocationValuesBase) {\n       CreateBufferIntervalCompareFnFromInstructionNames({\"negate.0\"});\n   InstructionCountPrefetchIntervalPicker prefetch_interval_picker(1, 10);\n   std::unique_ptr<PresetAssignments> preset_assignments =\n-      AssignMemorySpace(module.get(), options, buffer_interval_compare,\n-                        &prefetch_interval_picker);\n+      AssignMemorySpace(module.get(), std::move(options),\n+                        buffer_interval_compare, &prefetch_interval_picker);\n   VLOG(1) << \"Module after MSA:\\n\" << module->ToString();\n \n   HloInstruction* copy0 = FindInstruction(module.get(), \"negate.0\");\n@@ -6978,8 +6990,8 @@ TEST_F(MemorySpaceAssignmentTest,\n       CreateBufferIntervalCompareFnFromInstructionNames({\"negate.0\"});\n   InstructionCountPrefetchIntervalPicker prefetch_interval_picker(1, 10);\n   std::unique_ptr<PresetAssignments> preset_assignments =\n-      AssignMemorySpace(module.get(), options, buffer_interval_compare,\n-                        &prefetch_interval_picker);\n+      AssignMemorySpace(module.get(), std::move(options),\n+                        buffer_interval_compare, &prefetch_interval_picker);\n   VLOG(1) << \"Module after MSA:\\n\" << module->ToString();\n \n   HloInstruction* copy0 = FindInstruction(module.get(), \"negate.0\");\n@@ -7031,8 +7043,8 @@ TEST_F(MemorySpaceAssignmentTest,\n       CreateBufferIntervalCompareFnFromInstructionNames({\"negate.0\"});\n   InstructionCountPrefetchIntervalPicker prefetch_interval_picker(1, 10);\n   std::unique_ptr<PresetAssignments> preset_assignments =\n-      AssignMemorySpace(module.get(), options, buffer_interval_compare,\n-                        &prefetch_interval_picker);\n+      AssignMemorySpace(module.get(), std::move(options),\n+                        buffer_interval_compare, &prefetch_interval_picker);\n   VLOG(1) << \"Module after MSA:\\n\" << module->ToString();\n \n   HloInstruction* copy0 = FindInstruction(module.get(), \"negate.0\");\n@@ -7085,8 +7097,8 @@ TEST_F(MemorySpaceAssignmentTest,\n       CreateBufferIntervalCompareFnFromInstructionNames({\"v.2\", \"negate.0\"});\n   InstructionCountPrefetchIntervalPicker prefetch_interval_picker(1, 10);\n   std::unique_ptr<PresetAssignments> preset_assignments =\n-      AssignMemorySpace(module.get(), options, buffer_interval_compare,\n-                        &prefetch_interval_picker);\n+      AssignMemorySpace(module.get(), std::move(options),\n+                        buffer_interval_compare, &prefetch_interval_picker);\n   VLOG(1) << \"Module after MSA:\\n\" << module->ToString();\n \n   HloInstruction* v2 = FindInstruction(module.get(), \"v.2\");\n@@ -7761,7 +7773,7 @@ TEST_F(MemorySpaceAssignmentTest,\n     }\n     return {};\n   };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n }\n \n TEST_F(MemorySpaceAssignmentTest, DisablePrefetch) {\n@@ -7789,7 +7801,7 @@ TEST_F(MemorySpaceAssignmentTest, DisablePrefetch) {\n \n   Options options = DefaultMemorySpaceOptions();\n   options.max_outstanding_prefetches = 0;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   EXPECT_THAT(module->entry_computation()->root_instruction()->operand(1),\n               op::Parameter());\n@@ -7893,8 +7905,8 @@ TEST_F(MemorySpaceAssignmentTest, PrecoloredBuffer) {\n   InstructionCountPrefetchIntervalPicker prefetch_interval_picker(2, 10);\n   Options options = DefaultMemorySpaceOptions();\n   std::unique_ptr<PresetAssignments> preset_assignments =\n-      AssignMemorySpace(module.get(), options, buffer_interval_compare,\n-                        &prefetch_interval_picker);\n+      AssignMemorySpace(module.get(), std::move(options),\n+                        buffer_interval_compare, &prefetch_interval_picker);\n \n   const HloInstruction* r = FindInstruction(module.get(), \"r\");\n   const HloInstruction* d = FindInstruction(module.get(), \"d\");\n@@ -7968,9 +7980,9 @@ TEST_F(MemorySpaceAssignmentTest, PrecoloredBufferOOM) {\n \n   InstructionCountPrefetchIntervalPicker prefetch_interval_picker(2, 10);\n   Options options = DefaultMemorySpaceOptions();\n-  auto status_or = AssignMemorySpaceAndReturnStatus(module.get(), options,\n-                                                    buffer_interval_compare,\n-                                                    &prefetch_interval_picker);\n+  auto status_or = AssignMemorySpaceAndReturnStatus(\n+      module.get(), std::move(options), buffer_interval_compare,\n+      &prefetch_interval_picker);\n   EXPECT_THAT(\n       status_or.status(),\n       absl_testing::StatusIs(\n@@ -8432,7 +8444,7 @@ ENTRY entry {\n         }\n         return 0;\n       };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   auto get_memory_space = [&](absl::string_view instruction_name) {\n     return module->entry_computation()\n         ->GetInstructionWithName(instruction_name)\n@@ -8618,7 +8630,7 @@ TEST_F(MemorySpaceAssignmentTest, Repack) {\n   Options options = DefaultMemorySpaceOptions();\n   options.max_repacks = 1;\n   options.repacker = &repacker;\n-  AssignMemorySpace(module.get(), options, buffer_interval_compare,\n+  AssignMemorySpace(module.get(), std::move(options), buffer_interval_compare,\n                     &prefetch_interval_picker);\n \n   // If repacking succeeds, we should find the buffer for d in alternate memory.\n@@ -8731,7 +8743,7 @@ TEST_F(MemorySpaceAssignmentTest, RepackExportsAliasedOffsets) {\n   Options options = DefaultMemorySpaceOptions();\n   options.max_repacks = 1;\n   options.repacker = &repacker;\n-  AssignMemorySpace(module.get(), options, buffer_interval_compare,\n+  AssignMemorySpace(module.get(), std::move(options), buffer_interval_compare,\n                     &prefetch_interval_picker);\n }\n \n@@ -8779,7 +8791,7 @@ ENTRY entry {\n   FakeMemorySpaceAssignmentRepacker repacker =\n       FakeMemorySpaceAssignmentRepacker(repack_map, check_fun);\n   options.repacker = &repacker;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   EXPECT_TRUE(repacker_ran);\n }\n \n@@ -8859,7 +8871,7 @@ TEST_F(MemorySpaceAssignmentTest,\n       FakeMemorySpaceAssignmentRepacker(repack_map, nullptr);\n   options.repacker = &repacker;\n   std::unique_ptr<PresetAssignments> assignments =\n-      AssignMemorySpace(module.get(), options);\n+      AssignMemorySpace(module.get(), std::move(options));\n   // This lambda checks if an instruction's operand has been assigned in\n   // alternate memory.\n   auto instruction_consumes_assignment_fn =\n@@ -8980,7 +8992,7 @@ TEST_F(MemorySpaceAssignmentTest, ScopedAllocationWithDifferentOffset) {\n   options.max_repacks = 1;\n   options.repacker = &repacker;\n   options.allocate_reserved_scoped_memory_at_same_offset = false;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n }\n \n TEST_F(MemorySpaceAssignmentTest,\n@@ -9042,7 +9054,7 @@ TEST_F(MemorySpaceAssignmentTest,\n   FakeMemorySpaceAssignmentRepacker repacker =\n       FakeMemorySpaceAssignmentRepacker(repack_map, nullptr);\n   options.repacker = &repacker;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n }\n \n TEST_F(MemorySpaceAssignmentTest,\n@@ -9090,7 +9102,7 @@ TEST_F(MemorySpaceAssignmentTest,\n   options.repacker = &repacker;\n   options.repack_after_every_allocation = true;\n   InstructionCountPrefetchIntervalPicker prefetch_interval_picker(2, 10);\n-  AssignMemorySpace(module.get(), options,\n+  AssignMemorySpace(module.get(), std::move(options),\n                     /*buffer_interval_compare=*/{}, &prefetch_interval_picker);\n }\n \n@@ -9237,7 +9249,7 @@ ENTRY entry {\n            pos.instruction->opcode() != HloOpcode::kAsyncDone &&\n            pos.instruction->parent()->IsMainThread();\n   };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   auto has_alternate_memory_allocation =\n       [&](const HloInstruction* instruction) {\n         bool result = false;\n@@ -9327,13 +9339,14 @@ ENTRY entry {\n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n                           ParseAndReturnVerifiedModule(hlo_string));\n \n-  Options options = DefaultMemorySpaceOptions();\n-  options.enable_cross_program_prefetch = false;\n+  Options options0 = DefaultMemorySpaceOptions();\n+  options0.enable_cross_program_prefetch = false;\n   // Disable inefficiency check. Expect that the fusion output and operand are\n   // in the alternate memory.\n-  options.inefficient_use_to_copy_ratio = 0.0;\n-  AssignMemorySpaceUsingCostAnalysis(module.get(),\n-                                     /*memory_space_options_override=*/options);\n+  options0.inefficient_use_to_copy_ratio = 0.0;\n+  AssignMemorySpaceUsingCostAnalysis(\n+      module.get(),\n+      /*memory_space_options_override=*/std::move(options0));\n   EXPECT_THAT(\n       module->entry_computation()->root_instruction(),\n       op::Tuple(op::AsyncCopy(kDefaultMemorySpace, kAlternateMemorySpace,\n@@ -9346,9 +9359,12 @@ ENTRY entry {\n   // 8B of data (f32[2,1]) but copies 48B of data (prefetch and eviction of\n   // f32[2,3]), so this should be considered inefficient (8/48 < 0.5).\n   TF_ASSERT_OK_AND_ASSIGN(module, ParseAndReturnVerifiedModule(hlo_string));\n-  options.inefficient_use_to_copy_ratio = 0.5;\n-  AssignMemorySpaceUsingCostAnalysis(module.get(),\n-                                     /*memory_space_options_override=*/options);\n+  Options options1 = DefaultMemorySpaceOptions();\n+  options1.enable_cross_program_prefetch = false;\n+  options1.inefficient_use_to_copy_ratio = 0.5;\n+  AssignMemorySpaceUsingCostAnalysis(\n+      module.get(),\n+      /*memory_space_options_override=*/std::move(options1));\n   EXPECT_THAT(module->entry_computation()->root_instruction(),\n               op::Tuple(op::Fusion(op::Parameter()), op::Negate()));\n }\n@@ -9422,7 +9438,7 @@ ENTRY entry {\n   hlo_cost_options.set_transcendentals_per_second(0.4);\n \n   AssignMemorySpaceUsingCostAnalysis(\n-      module.get(), /*memory_space_options_override=*/options,\n+      module.get(), /*memory_space_options_override=*/std::move(options),\n       /*cost_analysis_options_override=*/std::nullopt,\n       /*hlo_cost_options_override=*/hlo_cost_options);\n }\n@@ -9481,7 +9497,7 @@ TEST_F(MemorySpaceAssignmentTest,\n   hlo_cost_options.set_transcendentals_per_second(0.4);\n \n   AssignMemorySpaceUsingCostAnalysis(\n-      module.get(), /*memory_space_options_override=*/options,\n+      module.get(), /*memory_space_options_override=*/std::move(options),\n       /*cost_analysis_options_override=*/std::nullopt,\n       /*hlo_cost_options_override=*/hlo_cost_options);\n }\n@@ -9567,7 +9583,7 @@ ENTRY entry {\n \n   InstructionCountPrefetchIntervalPicker prefetch_interval_picker(2, 10);\n   Options options = DefaultMemorySpaceOptions();\n-  AssignMemorySpace(module.get(), options, buffer_interval_compare,\n+  AssignMemorySpace(module.get(), std::move(options), buffer_interval_compare,\n                     &prefetch_interval_picker);\n }\n \n@@ -9637,7 +9653,7 @@ ENTRY main {\n         }\n         return false;\n       };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   HloInstruction* fusion1 =\n       module->entry_computation()->GetInstructionWithName(\"fusion1\");\n@@ -9743,7 +9759,7 @@ ENTRY main {\n         }\n         return false;\n       };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   HloInstruction* fusion1 =\n       module->entry_computation()->GetInstructionWithName(\"fusion1\");\n@@ -9866,7 +9882,7 @@ ENTRY main {\n         }\n         return false;\n       };\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n }\n \n // This test seeks to test that MSA will schedule async copy operations with\n@@ -9903,7 +9919,7 @@ TEST_F(MemorySpaceAssignmentTest, HoistCopyStart) {\n   options.post_module_scoped_alternate_memory_size_in_bytes = 64;\n   options.enable_cross_program_prefetch = true;\n   std::unique_ptr<PresetAssignments> preset_assignments =\n-      AssignMemorySpace(module.get(), options);\n+      AssignMemorySpace(module.get(), std::move(options));\n \n   // Ensure that get-tuple-element.1 is chosen for cross-program prefetch.\n   auto cross_program_prefetches = module->CrossProgramPrefetches();\n@@ -9964,7 +9980,7 @@ TEST_F(MemorySpaceAssignmentTest,\n                           ParseAndReturnVerifiedModule(hlo_string));\n   Options options = DefaultMemorySpaceOptions();\n   options.enable_cross_program_prefetch = true;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   // Ensure that get-tuple-element.1 is chosen for cross-program prefetch.\n   auto cross_program_prefetches = module->CrossProgramPrefetches();\n@@ -9999,7 +10015,8 @@ entry {\n   options.op_span_size_fn =\n       [&](HloInstruction* original_hlo, HloInstruction* cloned_hlo,\n           int64_t operand_index) -> int64_t { return 32; };\n-  AssignMemorySpace(module.get(), options, /*max_prefetch_interval=*/10,\n+  AssignMemorySpace(module.get(), std::move(options),\n+                    /*max_prefetch_interval=*/10,\n                     /*min_prefetch_interval=*/0);\n   const HloInstruction* fusion = FindInstruction(module.get(), \"fusion\");\n   // The fusion instruction should have 9 operands: the 3 original operands\n@@ -10070,7 +10087,8 @@ entry {\n   options.enable_window_prefetch = true;\n   options.op_span_size_fn = op_span_size_fn;\n   options.reserved_scoped_memory_fn = reserved_scoped_memory_fn;\n-  AssignMemorySpace(module.get(), options, /*max_prefetch_interval=*/10,\n+  AssignMemorySpace(module.get(), std::move(options),\n+                    /*max_prefetch_interval=*/10,\n                     /*min_prefetch_interval=*/0);\n   const HloInstruction* fusion = FindInstruction(module.get(), \"t3\");\n   // Verify that the fusion instruction is window prefetched. If the fusion\n@@ -10703,7 +10721,7 @@ TEST_F(MemorySpaceAssignmentTest, MultiCrossProgramPrefetchTest) {\n   options.max_size_in_bytes = 256;\n   options.alignment_in_bytes = 8;\n   options.verify = true;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n \n   auto cross_program_prefetches = module->CrossProgramPrefetches();\n   EXPECT_EQ(cross_program_prefetches.size(), 2);\n@@ -11120,7 +11138,7 @@ TEST_F(MemorySpaceAssignmentTest, CrossProgramPrefetchPinnedTest) {\n     return true;\n   };\n   std::unique_ptr<PresetAssignments> preset_assignments =\n-      AssignMemorySpace(module.get(), options);\n+      AssignMemorySpace(module.get(), std::move(options));\n \n   auto cross_program_prefetches = module->CrossProgramPrefetches();\n   EXPECT_GT(cross_program_prefetches.size(), 0);\n@@ -11167,7 +11185,7 @@ TEST_F(MemorySpaceAssignmentTest, CrossProgramPrefetchPinnedTupleTest) {\n     return true;\n   };\n   std::unique_ptr<PresetAssignments> preset_assignments =\n-      AssignMemorySpace(module.get(), options);\n+      AssignMemorySpace(module.get(), std::move(options));\n \n   auto cross_program_prefetches = module->CrossProgramPrefetches();\n   EXPECT_GT(cross_program_prefetches.size(), 0);\n@@ -11369,7 +11387,7 @@ TEST_F(MemorySpaceAssignmentTest, CrossProgramPrefetchNoReuse) {\n   auto options = DefaultMemorySpaceOptions();\n   // Enough space to fit the cross-program prefetch for both p0 and p1.\n   options.max_size_in_bytes = 512;\n-  auto preset_assignments = AssignMemorySpace(module.get(), options,\n+  auto preset_assignments = AssignMemorySpace(module.get(), std::move(options),\n                                               /*max_prefetch_interval=*/5,\n                                               /*min_prefetch_interval=*/2);\n \n@@ -11461,7 +11479,7 @@ TEST_F(MemorySpaceAssignmentTest, CrossProgramPrefetchWithOverrideNoReuse) {\n   TF_ASSERT_OK_AND_ASSIGN(options.msa_sort_order_overrides,\n                           ParseTextProto<MsaSortOrderOverrides>(text_proto));\n   options.max_size_in_bytes = 256;\n-  auto preset_assignments = AssignMemorySpace(module.get(), options,\n+  auto preset_assignments = AssignMemorySpace(module.get(), std::move(options),\n                                               /*max_prefetch_interval=*/5,\n                                               /*min_prefetch_interval=*/2);\n \n@@ -11542,7 +11560,7 @@ TEST_F(MemorySpaceAssignmentTest, UserAnnotatedCrossProgramPrefetchNoReuse) {\n                           ParseAndReturnVerifiedModule(hlo_string));\n   auto options = DefaultMemorySpaceOptions();\n   options.max_size_in_bytes = 256;\n-  auto preset_assignments = AssignMemorySpace(module.get(), options,\n+  auto preset_assignments = AssignMemorySpace(module.get(), std::move(options),\n                                               /*max_prefetch_interval=*/5,\n                                               /*min_prefetch_interval=*/2);\n \n@@ -11641,7 +11659,7 @@ TEST_F(MemorySpaceAssignmentTest,\n                           ParseAndReturnVerifiedModule(hlo_string));\n   auto options = DefaultMemorySpaceOptions();\n   options.max_size_in_bytes = 256;\n-  auto preset_assignments = AssignMemorySpace(module.get(), options,\n+  auto preset_assignments = AssignMemorySpace(module.get(), std::move(options),\n                                               /*max_prefetch_interval=*/5,\n                                               /*min_prefetch_interval=*/2);\n \n@@ -12047,7 +12065,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(hlo_string));\n   Options options = DefaultMemorySpaceOptions();\n   options.cross_program_prefetch_permissive_mode = true;\n-  AssignMemorySpace(module.get(), options);\n+  AssignMemorySpace(module.get(), std::move(options));\n   auto cross_program_prefetches = module->CrossProgramPrefetches();\n   EXPECT_EQ(cross_program_prefetches.size(), 1);\n }\n@@ -12135,7 +12153,8 @@ ENTRY main {\n   };\n \n   // Run test.\n-  AssignMemorySpace(module.get(), options, compare, &prefetch_interval_picker);\n+  AssignMemorySpace(module.get(), std::move(options), compare,\n+                    &prefetch_interval_picker);\n \n   // - Make sure the setup occurred, i.e., that p0 is prefetched to alternate\n   //   memory for use by c.\n@@ -12242,8 +12261,8 @@ TEST_F(MemorySpaceAssignmentTest, ExpandScopedAlternateMemory) {\n       ExpandedScopedAlternateMemoryMode::ENABLED;\n   options.alignment_in_bytes = 10;\n   std::unique_ptr<PresetAssignments> preset_assignments =\n-      AssignMemorySpace(module.get(), options, buffer_interval_compare,\n-                        &prefetch_interval_picker);\n+      AssignMemorySpace(module.get(), std::move(options),\n+                        buffer_interval_compare, &prefetch_interval_picker);\n \n   VLOG(1) << \"Post-MSA module:\\n\" << module->ToString();\n \n@@ -13223,25 +13242,15 @@ class SlicedPrefetchTest : public MemorySpaceAssignmentTestBase {\n   SlicedPrefetchTest() {\n     // Force tests to fail if ProposeSlices is unexpectedly called.\n     EXPECT_CALL(slice_proposer_, ProposeSlices(_, _)).Times(0);\n-\n-    options_.max_size_in_bytes = 1024;\n-    options_.sliced_prefetch_options.set_max_slices(2);\n-    options_.sliced_prefetch_options.set_min_bytes(8);\n-    options_.propose_slice_fn = [&](const Shape& shape,\n-                                    const SlicedPrefetchOptions& options) {\n-      return slice_proposer_.ProposeSlices(shape, options);\n-    };\n-    options_.get_equivalent_s8_shape_fn = [](const Shape& original_shape) {\n-      return ShapeUtil::MakeShape(S8, {ShapeSize(original_shape)});\n-    };\n+    options_ = MakeDefaultOptions();\n   }\n \n   // Optional method to setup common ProposeSlices expectations for several\n   // tests.\n   void SetupProposeSlicesToExpect2SlicesOfF32x8x8() {\n     EXPECT_CALL(slice_proposer_,\n                 ProposeSlices(f32_8_8_, EqualsSlicedPrefetchOptions(\n-                                            options_.sliced_prefetch_options)))\n+                                            options().sliced_prefetch_options)))\n         .WillRepeatedly(Return(SliceProposalCollection({\n             SliceProposal({f32_4_8_, std::vector<SliceParam>({{0, 4}, {0, 8}}),\n                            ShapeSize(f32_4_8_)}),\n@@ -13250,10 +13259,29 @@ class SlicedPrefetchTest : public MemorySpaceAssignmentTestBase {\n         })));\n   }\n \n+  Options MakeDefaultOptions() {\n+    Options options = DefaultMemorySpaceOptions();\n+    options.max_size_in_bytes = 1024;\n+    options.sliced_prefetch_options.set_max_slices(2);\n+    options.sliced_prefetch_options.set_min_bytes(8);\n+    options.propose_slice_fn = [&](const Shape& shape,\n+                                   const SlicedPrefetchOptions& options) {\n+      return slice_proposer_.ProposeSlices(shape, options);\n+    };\n+    options.get_equivalent_s8_shape_fn = [](const Shape& original_shape) {\n+      return ShapeUtil::MakeShape(S8, {ShapeSize(original_shape)});\n+    };\n+    return options;\n+  }\n+\n+  const Options& options() const { return options_; }\n+\n   const Shape f32_8_8_ = ShapeUtil::MakeShape(F32, {8, 8});\n   const Shape f32_4_8_ = ShapeUtil::MakeShape(F32, {4, 8});\n   MockSliceProposer slice_proposer_;\n-  Options options_ = DefaultMemorySpaceOptions();\n+\n+ private:\n+  Options options_;\n };\n \n TEST_F(SlicedPrefetchTest, TwoSlices) {\n@@ -13278,7 +13306,7 @@ ENTRY main {\n           << module->ToString(HloPrintOptions::ShortParsable());\n \n   std::unique_ptr<PresetAssignments> assignments = AssignMemorySpace(\n-      module.get(), options_,\n+      module.get(), MakeDefaultOptions(),\n       /*max_prefetch_interval=*/10, /*min_prefetch_interval=*/1);\n \n   VLOG(1) << \"Post-MSA module:\\n\"\n@@ -13323,7 +13351,7 @@ ENTRY main {\n \n   ROOT r = f32[8,8] add(r1, r2)\n })zz\";\n-  Options options = options_;\n+  Options options = MakeDefaultOptions();\n   options.enable_sync_copy_replacement = true;\n   SetupProposeSlicesToExpect2SlicesOfF32x8x8();\n \n@@ -13332,7 +13360,7 @@ ENTRY main {\n           << module->ToString(HloPrintOptions::ShortParsable());\n \n   std::unique_ptr<PresetAssignments> assignments = AssignMemorySpace(\n-      module.get(), options,\n+      module.get(), std::move(options),\n       /*max_prefetch_interval=*/10, /*min_prefetch_interval=*/1);\n \n   VLOG(1) << \"Post-MSA module:\\n\"\n@@ -13356,11 +13384,12 @@ ENTRY main {\n   const Shape f32_3_8 = ShapeUtil::MakeShape(F32, {3, 8});\n   const Shape f32_2_8 = ShapeUtil::MakeShape(F32, {2, 8});\n \n-  options_.sliced_prefetch_options.set_max_slices(3);\n+  Options options = MakeDefaultOptions();\n+  options.sliced_prefetch_options.set_max_slices(3);\n \n   EXPECT_CALL(slice_proposer_,\n               ProposeSlices(f32_8_8_, EqualsSlicedPrefetchOptions(\n-                                          options_.sliced_prefetch_options)))\n+                                          options.sliced_prefetch_options)))\n       .WillRepeatedly(Return(SliceProposalCollection({\n           SliceProposal({f32_3_8, std::vector<SliceParam>({{0, 3}, {0, 8}}),\n                          ShapeSize(f32_3_8)}),\n@@ -13375,7 +13404,7 @@ ENTRY main {\n           << module->ToString(HloPrintOptions::ShortParsable());\n \n   std::unique_ptr<PresetAssignments> assignments = AssignMemorySpace(\n-      module.get(), options_,\n+      module.get(), std::move(options),\n       /*max_prefetch_interval=*/10, /*min_prefetch_interval=*/1);\n \n   VLOG(1) << \"Post-MSA module:\\n\"\n@@ -13417,14 +13446,15 @@ ENTRY main {\n   ROOT r = f32[8,8] add(c, p1)\n })zz\";\n \n-  options_.sliced_prefetch_options.set_max_slices(0);\n+  Options options = MakeDefaultOptions();\n+  options.sliced_prefetch_options.set_max_slices(0);\n \n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(hlo_text));\n   VLOG(1) << \"Original module:\\n\"\n           << module->ToString(HloPrintOptions::ShortParsable());\n \n   std::unique_ptr<PresetAssignments> assignments = AssignMemorySpace(\n-      module.get(), options_,\n+      module.get(), std::move(options),\n       /*max_prefetch_interval=*/10, /*min_prefetch_interval=*/1);\n \n   VLOG(1) << \"Post-MSA module:\\n\"\n@@ -13455,14 +13485,15 @@ ENTRY main {\n   ROOT r = f32[8,8] add(c, p1)\n })zz\";\n \n-  options_.sliced_prefetch_options.set_min_bytes(1000000000);\n+  Options options = MakeDefaultOptions();\n+  options.sliced_prefetch_options.set_min_bytes(1000000000);\n \n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(hlo_text));\n   VLOG(1) << \"Original module:\\n\"\n           << module->ToString(HloPrintOptions::ShortParsable());\n \n   std::unique_ptr<PresetAssignments> assignments = AssignMemorySpace(\n-      module.get(), options_,\n+      module.get(), std::move(options),\n       /*max_prefetch_interval=*/10, /*min_prefetch_interval=*/1);\n \n   VLOG(1) << \"Post-MSA module:\\n\"\n@@ -13494,9 +13525,10 @@ ENTRY main {\n   ROOT r = f32[8,8] add(c, p1)\n })zz\";\n \n+  Options options = MakeDefaultOptions();\n   EXPECT_CALL(slice_proposer_,\n               ProposeSlices(f32_8_8_, EqualsSlicedPrefetchOptions(\n-                                          options_.sliced_prefetch_options)))\n+                                          options.sliced_prefetch_options)))\n       .WillRepeatedly(Return(absl::StatusOr<SliceProposalCollection>(\n           FailedPrecondition(\"%s\", \"Cannot slice.\"))));\n \n@@ -13505,7 +13537,7 @@ ENTRY main {\n           << module->ToString(HloPrintOptions::ShortParsable());\n \n   std::unique_ptr<PresetAssignments> assignments = AssignMemorySpace(\n-      module.get(), options_,\n+      module.get(), std::move(options),\n       /*max_prefetch_interval=*/10, /*min_prefetch_interval=*/1);\n \n   VLOG(1) << \"Post-MSA module:\\n\"\n@@ -13545,7 +13577,7 @@ ENTRY main {\n \n   std::unique_ptr<PresetAssignments> assignments =\n       AssignMemorySpaceUsingCostAnalysis(\n-          module.get(), /*memory_space_options_override=*/options_);\n+          module.get(), /*memory_space_options_override=*/MakeDefaultOptions());\n \n   VLOG(1) << \"Post-MSA module:\\n\"\n           << module->ToString(HloPrintOptions::ShortParsable());\n@@ -13622,7 +13654,7 @@ ENTRY main {\n \n   std::unique_ptr<PresetAssignments> assignments =\n       AssignMemorySpaceUsingCostAnalysis(\n-          module.get(), /*memory_space_options_override=*/options_);\n+          module.get(), /*memory_space_options_override=*/MakeDefaultOptions());\n \n   VLOG(1) << \"Post-MSA module:\\n\"\n           << module->ToString(HloPrintOptions::ShortParsable());\n@@ -13756,11 +13788,11 @@ ENTRY main {\n   Shape f32_32_16 = ShapeUtil::MakeShape(F32, {32, 16});\n   EXPECT_CALL(slice_proposer_,\n               ProposeSlices(f32_16_16, EqualsSlicedPrefetchOptions(\n-                                           options_.sliced_prefetch_options)))\n+                                           options().sliced_prefetch_options)))\n       .WillRepeatedly(Return(SliceProposalCollection({})));\n   EXPECT_CALL(slice_proposer_,\n               ProposeSlices(f32_32_16, EqualsSlicedPrefetchOptions(\n-                                           options_.sliced_prefetch_options)))\n+                                           options().sliced_prefetch_options)))\n       .WillRepeatedly(Return(SliceProposalCollection({\n           SliceProposal({f32_16_16, std::vector<SliceParam>({{0, 16}, {0, 16}}),\n                          ShapeSize(f32_16_16)}),\n@@ -13794,13 +13826,14 @@ ENTRY main {\n \n   // Configure MSA.\n   InstructionCountPrefetchIntervalPicker prefetch_interval_picker(2, 50);\n-  options_.max_size_in_bytes = 4 * 1024;\n-  options_.max_repacks = 0;\n+  Options options_no_repacking = MakeDefaultOptions();\n+  options_no_repacking.max_size_in_bytes = 4 * 1024;\n+  options_no_repacking.max_repacks = 0;\n \n   // Run MSA without repacking\n-  std::unique_ptr<PresetAssignments> assignments =\n-      AssignMemorySpace(module_no_repacking.get(), options_,\n-                        buffer_interval_compare, &prefetch_interval_picker);\n+  std::unique_ptr<PresetAssignments> assignments = AssignMemorySpace(\n+      module_no_repacking.get(), std::move(options_no_repacking),\n+      buffer_interval_compare, &prefetch_interval_picker);\n   VLOG(1) << \"Post-MSA module (no repacking):\\n\"\n           << module_no_repacking->ToString(HloPrintOptions::ShortParsable());\n \n@@ -13859,11 +13892,14 @@ ENTRY main {\n \n         return true;\n       });\n-  options_.max_repacks = 1;\n-  options_.repacker = &repacker;\n-  assignments =\n-      AssignMemorySpace(module_with_repacking.get(), options_,\n-                        buffer_interval_compare, &prefetch_interval_picker);\n+  Options options_with_repacking = MakeDefaultOptions();\n+  options_with_repacking.max_size_in_bytes = 4 * 1024;\n+  options_with_repacking.max_repacks = 0;\n+  options_with_repacking.max_repacks = 1;\n+  options_with_repacking.repacker = &repacker;\n+  assignments = AssignMemorySpace(\n+      module_with_repacking.get(), std::move(options_with_repacking),\n+      buffer_interval_compare, &prefetch_interval_picker);\n   VLOG(1) << \"Post-MSA module (with repacking):\\n\"\n           << module_with_repacking->ToString(HloPrintOptions::ShortParsable());\n \n@@ -14031,21 +14067,23 @@ ENTRY main {\n   // We set the minimum prefetch interval to a large enough value (32) to force\n   // us to prefetch around both while loops, and not just 1.\n   InstructionCountPrefetchIntervalPicker prefetch_interval_picker(32, 100);\n-  options_.max_size_in_bytes = 4 * 64;\n+  Options options0 = MakeDefaultOptions();\n+  options0.max_size_in_bytes = 4 * 64;\n \n   // Define a lambda for running MSA on the specified HLO, with the\n   // configuration above.\n   auto run_msa =\n-      [&](absl::string_view hlo_text) -> absl::StatusOr<ModuleAndAssignments> {\n+      [&](Options options,\n+          absl::string_view hlo_text) -> absl::StatusOr<ModuleAndAssignments> {\n     ModuleAndAssignments module_and_assignments;\n     TF_ASSIGN_OR_RETURN(module_and_assignments.module,\n                         ParseAndReturnVerifiedModule(hlo_text));\n     VLOG(1) << \"Original module:\\n\"\n             << module_and_assignments.module->ToString(\n                    HloPrintOptions::ShortParsable());\n-    module_and_assignments.assignments =\n-        AssignMemorySpace(module_and_assignments.module.get(), options_,\n-                          buffer_interval_compare, &prefetch_interval_picker);\n+    module_and_assignments.assignments = AssignMemorySpace(\n+        module_and_assignments.module.get(), std::move(options),\n+        buffer_interval_compare, &prefetch_interval_picker);\n     VLOG(1) << \"Post-MSA module:\\n\"\n             << module_and_assignments.module->ToString(\n                    HloPrintOptions::ShortParsable());\n@@ -14057,7 +14095,8 @@ ENTRY main {\n   // rather than during the second while loop.\n   TF_ASSERT_OK_AND_ASSIGN(\n       ModuleAndAssignments module_and_assignments1,\n-      run_msa(gen_hlo(while_computation_cheap, while_computation_expensive)));\n+      run_msa(std::move(options0),\n+              gen_hlo(while_computation_cheap, while_computation_expensive)));\n   auto root1 =\n       module_and_assignments1.module->entry_computation()->root_instruction();\n   EXPECT_THAT(root1, op::Add(_, op::Tanh(IsAsyncSlicedCopy(\n@@ -14093,13 +14132,17 @@ ENTRY main {\n       absl::c_is_sorted<std::vector<int>>(\n           {start_indices[1], first_while, start_indices[0], second_while}));\n \n+  Options options1 = MakeDefaultOptions();\n+  options1.max_size_in_bytes = 4 * 64;\n+\n   // In this case, more time elapses during the first while loop than the\n   // second. This should push us to use a normal prefetch, rather than slicing,\n   // since the ideal time to start the second slice will get pushed before\n   // both while loops.\n   TF_ASSERT_OK_AND_ASSIGN(\n       ModuleAndAssignments module_and_assignments2,\n-      run_msa(gen_hlo(while_computation_expensive, while_computation_cheap)));\n+      run_msa(std::move(options1),\n+              gen_hlo(while_computation_expensive, while_computation_cheap)));\n   auto root2 =\n       module_and_assignments2.module->entry_computation()->root_instruction();\n   EXPECT_THAT(root2, op::Add(_, op::Tanh(op::AsyncCopy(kAlternateMemorySpace,\n@@ -14193,12 +14236,13 @@ ENTRY main {\n   const Shape f32_8_16 = ShapeUtil::MakeShape(F32, {8, 16});\n   const Shape s8_128 = ShapeUtil::MakeShape(S8, {128});\n \n-  options_.sliced_prefetch_options.set_max_slices(100000);\n-  options_.sliced_prefetch_options.set_preferred_slice_size(4 * 8 * 4);\n+  Options options = MakeDefaultOptions();\n+  options.sliced_prefetch_options.set_max_slices(100000);\n+  options.sliced_prefetch_options.set_preferred_slice_size(4 * 8 * 4);\n \n   EXPECT_CALL(slice_proposer_,\n               ProposeSlices(f32_8_8_, EqualsSlicedPrefetchOptions(\n-                                          options_.sliced_prefetch_options)))\n+                                          options.sliced_prefetch_options)))\n       .WillRepeatedly(Return(SliceProposalCollection({\n           SliceProposal(\n               {s8_128, std::vector<SliceParam>({{0, 128}}), ShapeSize(s8_128)}),\n@@ -14208,7 +14252,7 @@ ENTRY main {\n \n   EXPECT_CALL(slice_proposer_,\n               ProposeSlices(f32_8_16, EqualsSlicedPrefetchOptions(\n-                                          options_.sliced_prefetch_options)))\n+                                          options.sliced_prefetch_options)))\n       .WillRepeatedly(Return(SliceProposalCollection({\n           SliceProposal(\n               {s8_128, std::vector<SliceParam>({{0, 128}}), ShapeSize(s8_128)}),\n@@ -14225,7 +14269,7 @@ ENTRY main {\n           << module->ToString(HloPrintOptions::ShortParsable());\n \n   std::unique_ptr<PresetAssignments> assignments = AssignMemorySpace(\n-      module.get(), options_,\n+      module.get(), std::move(options),\n       /*max_prefetch_interval=*/100, /*min_prefetch_interval=*/1);\n \n   VLOG(1) << \"Post-MSA module:\\n\"\n@@ -14362,7 +14406,8 @@ ENTRY %main.13 (Arg_0.1: f32[8,128]) -> (f32[8,128], f32[8,128]) {\n       };\n \n   XLA_VLOG_LINES(3, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(3, \"After MSA: \\n\" + module->ToString());\n \n   EXPECT_EQ(FindInstruction(module.get(), \"copy_done.2\")\n@@ -14504,7 +14549,8 @@ ENTRY %main.28_spmd (param.1: bf16[1024,512], param.2: bf16[2,512,4096], param:\n   memory_space_options.repacker = &best_fit_repacker;\n \n   XLA_VLOG_LINES(3, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(3, \"After MSA: \\n\" + module->ToString());\n   auto latency_optimized_reduce_scatter_kernel = FindInstruction(\n       module.get(),\n@@ -14548,7 +14594,8 @@ TEST_F(MemorySpaceAssignmentTest, TestColoringMultipleOperands) {\n   memory_space_options.max_size_in_bytes = 48;\n \n   XLA_VLOG_LINES(3, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(3, \"After MSA: \\n\" + module->ToString());\n \n   HloInstruction* add_after_msa = FindInstruction(module.get(), \"add\");\n@@ -14591,7 +14638,7 @@ TEST_F(MemorySpaceAssignmentTest,\n         return 10;\n       };\n   std::unique_ptr<PresetAssignments> preset_assignments =\n-      AssignMemorySpace(module.get(), options);\n+      AssignMemorySpace(module.get(), std::move(options));\n   EXPECT_THAT(preset_assignments->scoped_allocation_chunks(),\n               ::testing::Each(::testing::ResultOf(\n                   \"instruction->name()\",\n@@ -14653,7 +14700,8 @@ ENTRY entry {\n                                                      p4_position, p5_position};\n \n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n \n   HloInstruction* negate0 = FindInstruction(module.get(), \"negate0\");\n@@ -14732,7 +14780,8 @@ ENTRY entry {\n   memory_space_options.max_outstanding_block_prefetches = 2;\n   memory_space_options.max_outstanding_prefetches = 0;\n   XLA_LOG_LINES(INFO, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_LOG_LINES(INFO, \"After MSA: \\n\" + module->ToString());\n \n   HloInstruction* negate0 = FindInstruction(module.get(), \"negate0\");\n@@ -14812,7 +14861,8 @@ ENTRY entry {\n                                                      p1_position, p0_position};\n   memory_space_options.max_outstanding_block_prefetches = 10;\n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n \n   HloInstruction* negate0 = FindInstruction(module.get(), \"negate0\");\n@@ -14889,7 +14939,8 @@ ENTRY entry {\n                                                      p1_position, p0_position};\n   memory_space_options.max_outstanding_block_prefetches = 10;\n   XLA_LOG_LINES(INFO, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_LOG_LINES(INFO, \"After MSA: \\n\" + module->ToString());\n \n   HloInstruction* negate0 = FindInstruction(module.get(), \"negate0\");\n@@ -14962,7 +15013,8 @@ ENTRY entry {\n                                                      p1_position, p0_position};\n   memory_space_options.max_outstanding_block_prefetches = 10;\n   XLA_VLOG_LINES(3, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(3, \"After MSA: \\n\" + module->ToString());\n   HloInstruction* negate0 = FindInstruction(module.get(), \"negate0\");\n   EXPECT_EQ(negate0->operand(0)->shape().layout().memory_space(),\n@@ -15039,7 +15091,8 @@ ENTRY entry {\n                                                      p1_position, p0_position};\n   memory_space_options.max_outstanding_block_prefetches = 10;\n   XLA_VLOG_LINES(3, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(3, \"After MSA: \\n\" + module->ToString());\n   HloInstruction* negate0 = FindInstruction(module.get(), \"negate0\");\n   const HloInstruction* negate0_operand0 = negate0->operand(0);\n@@ -15136,7 +15189,8 @@ ENTRY entry {\n   memory_space_options.buffer_colorings = {\n       {add15_negate14_use, kAlternateMemorySpace}};\n   XLA_VLOG_LINES(3, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(3, \"After MSA: \\n\" + module->ToString());\n   HloInstruction* negate0 = FindInstruction(module.get(), \"negate0\");\n   EXPECT_EQ(negate0->operand(0)->shape().layout().memory_space(),\n@@ -15229,7 +15283,8 @@ ENTRY entry {\n   memory_space_options.buffer_colorings = {\n       {add15_negate14_use, kAlternateMemorySpace}};\n   XLA_VLOG_LINES(3, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(3, \"After MSA: \\n\" + module->ToString());\n   HloInstruction* negate0 = FindInstruction(module.get(), \"negate0\");\n   EXPECT_EQ(negate0->operand(0)->shape().layout().memory_space(),\n@@ -15304,7 +15359,8 @@ ENTRY entry {\n                                                      p2_position};\n \n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n \n   HloInstruction* negate0 = FindInstruction(module.get(), \"negate0\");\n@@ -15405,7 +15461,8 @@ ENTRY entry {\n                                                      p2_position};\n \n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n \n   HloInstruction* negate0 = FindInstruction(module.get(), \"negate0\");\n@@ -15526,7 +15583,8 @@ ENTRY entry {\n                                                      p2_position};\n \n   XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n \n   HloInstruction* negate0 = FindInstruction(module.get(), \"negate0\");\n@@ -15607,7 +15665,8 @@ ENTRY %NegateChain (p0: f32[2,3], p1: f32[2,3]) -> f32[2,3] {\n   memory_space_options.async_instruction_bw_adjustment_factor_fn =\n       async_instruction_bw_adjustment_factor_fn;\n   XLA_VLOG_LINES(3, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(3, \"After MSA: \\n\" + module->ToString());\n   HloInstruction* add = FindInstruction(module.get(), \"add\");\n   EXPECT_EQ(add->operand(1)->shape().layout().memory_space(),\n@@ -15647,7 +15706,8 @@ ENTRY %NegateChain (p0: f32[2,3], p1: f32[2,3]) -> f32[2,3] {\n   memory_space_options.async_instruction_bw_adjustment_factor_fn =\n       async_instruction_bw_adjustment_factor_fn;\n   XLA_VLOG_LINES(3, \"Before MSA: \\n\" + module->ToString());\n-  AssignMemorySpaceUsingCostAnalysis(module.get(), memory_space_options);\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n   XLA_VLOG_LINES(3, \"After MSA: \\n\" + module->ToString());\n   HloInstruction* add = FindInstruction(module.get(), \"add\");\n   EXPECT_EQ(add->operand(1)->shape().layout().memory_space(),"
        },
        {
            "sha": "b94dfc01e0e0ee30d603d68f82f24e747121953c",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test_base.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test_base.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test_base.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test_base.h?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -195,7 +195,7 @@ class MemorySpaceAssignmentTestBase : public HloTestBase {\n \n     Options memory_space_options = DefaultMemorySpaceOptions();\n     if (memory_space_options_override) {\n-      memory_space_options = *memory_space_options_override;\n+      memory_space_options = *std::move(memory_space_options_override);\n     }\n     CostAnalysisOptions cost_analysis_options = DefaultCostAnalysisOptions();\n     if (cost_analysis_options_override) {\n@@ -230,7 +230,7 @@ class MemorySpaceAssignmentTestBase : public HloTestBase {\n     MemoryBoundednessBufferIntervalComparator comparator(\n         *cost_analysis, &cache_, msa_sort_order_overrides);\n     return AssignMemorySpace(\n-        module, memory_space_options,\n+        module, std::move(memory_space_options),\n         [&comparator](const MsaBufferInterval& lhs,\n                       const MsaBufferInterval& rhs) {\n           return comparator.LessThan(lhs, rhs);\n@@ -298,7 +298,7 @@ class MemorySpaceAssignmentTestBase : public HloTestBase {\n \n     Options options = DefaultMemorySpaceOptions();\n     if (options_override) {\n-      options = *options_override;\n+      options = *std::move(options_override);\n     }\n     std::unique_ptr<TestBufferIntervalComparator> test_comparator;\n     if (buffer_interval_compare.has_value()) {"
        },
        {
            "sha": "36e8182cc8de16e7d5f75b6945272967ad63c423",
            "filename": "third_party/xla/xla/tools/hlo_opt/cpu_opt.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 9,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Fcpu_opt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Fcpu_opt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Fcpu_opt.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -112,14 +112,15 @@ class CpuOptProvider : public CompiledOptProvider {\n     DebugOptions debug_opts = GetDebugOptionsFromFlags();\n     auto executor = GetExecutor();\n     HloModuleConfig module_config = module.config();\n-    BufferValue::SizeFunction size_func = [](const BufferValue& buffer) {\n-      const Shape& shape = buffer.shape();\n-      // On the cpu, opaques are pointers.\n-      if (shape.IsOpaque()) {\n-        return static_cast<int64_t>(sizeof(void*));\n-      }\n-      return ShapeUtil::ByteSizeOf(shape, sizeof(void*));\n-    };\n+    static BufferValue::SizeFunction* const kSizeFunction =\n+        new BufferValue::SizeFunction([](const BufferValue& buffer) {\n+          const Shape& shape = buffer.shape();\n+          // On the cpu, opaques are pointers.\n+          if (shape.IsOpaque()) {\n+            return static_cast<int64_t>(sizeof(void*));\n+          }\n+          return ShapeUtil::ByteSizeOf(shape, sizeof(void*));\n+        });\n     absl::StatusOr<std::unique_ptr<llvm::TargetMachine>> jit_target_machine =\n         cpu::IrCompiler::InferTargetMachine(\n             CompilerTargetOptions(module_config),\n@@ -167,7 +168,7 @@ class CpuOptProvider : public CompiledOptProvider {\n         },\n         TransposeFolding::NeverFoldTranspose);\n     RegisterPass<cpu::ConvCanonicalization>(&target_machine_features);\n-    RegisterPass<HloMemoryScheduler>(alias_info_.get(), size_func);\n+    RegisterPass<HloMemoryScheduler>(alias_info_.get(), kSizeFunction);\n     RegisterPass<HostOffloader>(alias_info_.get());\n \n     // Fails to register if module does not have entry computation layout"
        },
        {
            "sha": "e0e04c4ecac33c226082638c828a42bd2247fc31",
            "filename": "third_party/xla/xla/tools/hlo_opt/gpu_opt.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 10,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Fgpu_opt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c6636562edd19ddb127cfc1bd52b227b15ddd2dd/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Fgpu_opt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Fgpu_opt.cc?ref=c6636562edd19ddb127cfc1bd52b227b15ddd2dd",
            "patch": "@@ -149,17 +149,18 @@ class GpuOptProvider : public CompiledOptProvider {\n              \"--xla_gpu_target_config_filename= to specify a target config.\";\n       gpu_compute_capability = stream_executor::CudaComputeCapability::Hopper();\n     }\n-    BufferValue::SizeFunction size_func = [](const BufferValue& buffer) {\n-      const Shape& shape = buffer.shape();\n-      if (shape.has_layout() &&\n-          shape.layout().memory_space() == Layout::kHostMemorySpace) {\n-        return static_cast<int64_t>(0);\n-      }\n-      return ShapeUtil::ByteSizeOf(shape, sizeof(void*));\n-    };\n+    static BufferValue::SizeFunction* const kSizeFunction =\n+        new BufferValue::SizeFunction([](const BufferValue& buffer) {\n+          const Shape& shape = buffer.shape();\n+          if (shape.has_layout() &&\n+              shape.layout().memory_space() == Layout::kHostMemorySpace) {\n+            return static_cast<int64_t>(0);\n+          }\n+          return ShapeUtil::ByteSizeOf(shape, sizeof(void*));\n+        });\n     // go/keep-sorted start\n     RegisterPass<CopyInsertion>(alias_info_.get());\n-    RegisterPass<HloMemoryScheduler>(alias_info_.get(), size_func);\n+    RegisterPass<HloMemoryScheduler>(alias_info_.get(), kSizeFunction);\n     RegisterPass<HostOffloader>(alias_info_.get());\n     RegisterPass<gpu::AllGatherOptimizer>();\n     RegisterPass<gpu::CuDnnCustomCallConverter>();\n@@ -223,12 +224,14 @@ class GpuOptProvider : public CompiledOptProvider {\n     }\n \n     llvm::LLVMContext llvm_context;\n+    BufferValue::SizeFunction buffer_size_bytes_function =\n+        gpu_compiler->BufferSizeBytesFunction();\n     TF_ASSIGN_OR_RETURN(\n         xla::gpu::CompileModuleResults results,\n         xla::gpu::CompileModuleToLlvmIr(\n             optimized_module, &llvm_context, gpu_compiler->GetTargetTriple(),\n             gpu_compiler->GetDataLayout(), platform, device_description,\n-            alias_info.get(), gpu_compiler->BufferSizeBytesFunction()));\n+            alias_info.get(), std::move(buffer_size_bytes_function)));\n     return llvm_ir::DumpToString(results.llvm_module.get());\n   }\n };"
        }
    ],
    "stats": {
        "total": 775,
        "additions": 457,
        "deletions": 318
    }
}