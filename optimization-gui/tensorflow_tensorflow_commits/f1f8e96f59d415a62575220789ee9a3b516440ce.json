{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 829714998",
    "sha": "f1f8e96f59d415a62575220789ee9a3b516440ce",
    "files": [
        {
            "sha": "1af57f169efd975e4bfc0f9123b7cec04b411657",
            "filename": "tensorflow/core/data/snapshot_utils.h",
            "status": "modified",
            "additions": 24,
            "deletions": 22,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fsnapshot_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fsnapshot_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fsnapshot_utils.h?ref=f1f8e96f59d415a62575220789ee9a3b516440ce",
            "patch": "@@ -65,10 +65,10 @@ constexpr char kShardDirectorySuffix[] = \".shard\";\n enum Mode { READER = 0, WRITER = 1, PASSTHROUGH = 2 };\n \n // Returns the name of the \"hash\" directory for the given base path and hash ID.\n-std::string HashDirectory(const std::string& path, uint64 hash);\n+std::string HashDirectory(const std::string& path, uint64_t hash);\n \n // Returns the name of the \"run\" directory for the given base path and run ID.\n-std::string RunDirectory(const std::string& hash_directory, uint64 run_id);\n+std::string RunDirectory(const std::string& hash_directory, uint64_t run_id);\n std::string RunDirectory(const std::string& hash_directory,\n                          const std::string& run_id);\n \n@@ -78,7 +78,7 @@ std::string ShardDirectory(const std::string& run_directory, int64_t shard_id);\n \n // Returns the checkpoint file name for the given directory and checkpoint ID.\n std::string GetCheckpointFileName(const std::string& shard_directory,\n-                                  uint64 checkpoint_id);\n+                                  uint64_t checkpoint_id);\n \n // This is a interface class that exposes snapshot writing functionality.\n class Writer {\n@@ -132,7 +132,7 @@ class TFRecordWriter : public Writer {\n // Writes snapshot with a custom (legacy) file format.\n class CustomWriter : public Writer {\n  public:\n-  static constexpr const size_t kHeaderSize = sizeof(uint64);\n+  static constexpr const size_t kHeaderSize = sizeof(uint64_t);\n \n   static constexpr const char* const kClassName = \"SnapshotWriter\";\n   static constexpr const char* const kWriteStringPiece = \"WriteStringPiece\";\n@@ -210,7 +210,7 @@ class Reader {\n   // the `version`, `compression_type`, and `dtypes` arguments passed into\n   // `Writer` and `Reader` must be the same for the reading to succeed.\n   static absl::Status Create(Env* env, const std::string& filename,\n-                             const string& compression_type, int version,\n+                             const std::string& compression_type, int version,\n                              const DataTypeVector& dtypes,\n                              std::unique_ptr<Reader>* out_reader);\n \n@@ -221,7 +221,8 @@ class Reader {\n   // contains all the elements written out to each individual snapshot file.\n   static absl::Status MakeNestedDataset(\n       Env* env, const std::vector<std::string>& shard_dirs,\n-      const string& compression_type, int version, const DataTypeVector& dtypes,\n+      const std::string& compression_type, int version,\n+      const DataTypeVector& dtypes,\n       const std::vector<PartialTensorShape>& shapes, int64_t start_index,\n       DatasetBase** output);\n \n@@ -253,7 +254,8 @@ class TFRecordReaderImpl {\n   // tensorflow/compiler/xla/tsl/lib/io/compression.h.\n   // `output_buffer_size` specifies the buffer size required by Snappy/Zlib\n   // compression algorithms. Ignored if compression is not enabled.\n-  TFRecordReaderImpl(const std::string& filename, const string& compression,\n+  TFRecordReaderImpl(const std::string& filename,\n+                     const std::string& compression,\n                      std::optional<int64_t> output_buffer_size = std::nullopt);\n \n   // Initializes the reader. Callers must initialize the reader before calling\n@@ -279,14 +281,14 @@ class TFRecordReaderImpl {\n   uint64_t offset_ = 0;\n   uint64_t bytes_read_ = 0;\n \n-  const string compression_;\n+  const std::string compression_;\n   const std::optional<int64_t> output_buffer_size_;\n };\n \n // Reads snapshots previously written with `TFRecordWriter`.\n class TFRecordReader : public Reader {\n  public:\n-  TFRecordReader(const std::string& filename, const string& compression,\n+  TFRecordReader(const std::string& filename, const std::string& compression,\n                  const DataTypeVector& dtypes,\n                  std::optional<int64_t> output_buffer_size = std::nullopt)\n       : reader_impl_(filename, compression, output_buffer_size),\n@@ -321,14 +323,14 @@ class CustomReader : public Reader {\n   // TODO(b/148804377): Set this in a smarter fashion.\n   static constexpr const int64_t kSnappyReaderOutputBufferSizeBytes =\n       32 << 20;  // 32 MiB\n-  static constexpr const size_t kHeaderSize = sizeof(uint64);\n+  static constexpr const size_t kHeaderSize = sizeof(uint64_t);\n \n   static constexpr const char* const kClassName = \"SnapshotReader\";\n   static constexpr const char* const kReadString = \"ReadString\";\n   static constexpr const char* const kReadCord = \"ReadCord\";\n   static constexpr const char* const kSeparator = \"::\";\n \n-  CustomReader(const std::string& filename, const string& compression_type,\n+  CustomReader(const std::string& filename, const std::string& compression_type,\n                int version, const DataTypeVector& dtypes);\n \n   absl::Status ReadTensors(std::vector<Tensor>* read_tensors) override;\n@@ -356,7 +358,7 @@ class CustomReader : public Reader {\n   std::string filename_;\n   std::unique_ptr<RandomAccessFile> file_;\n   std::unique_ptr<io::InputStreamInterface> input_stream_;\n-  const string compression_type_;\n+  const std::string compression_type_;\n   const int version_;\n   const DataTypeVector dtypes_;\n   int num_simple_ = 0;\n@@ -366,18 +368,18 @@ class CustomReader : public Reader {\n \n // Writes snapshot metadata to the given directory.\n absl::Status WriteMetadataFile(\n-    Env* env, const string& dir,\n+    Env* env, const std::string& dir,\n     const experimental::SnapshotMetadataRecord* metadata);\n \n // Writes distributed snapshot metadata to the given directory. An error is\n // returned if `dir` is unable to be created or if `metadata` is unable to be\n // written.\n absl::Status WriteMetadataFile(\n-    Env* env, const string& dir,\n+    Env* env, const std::string& dir,\n     const experimental::DistributedSnapshotMetadata* metadata);\n \n // Reads snapshot metadata from the given directory.\n-absl::Status ReadMetadataFile(Env* env, const string& dir,\n+absl::Status ReadMetadataFile(Env* env, const std::string& dir,\n                               experimental::SnapshotMetadataRecord* metadata,\n                               bool* file_exists);\n \n@@ -386,17 +388,17 @@ absl::Status ReadMetadataFile(Env* env, const string& dir,\n // returned. If the file exists in `dir` but is unable to be opened, an error\n // is returned.\n absl::Status ReadMetadataFile(\n-    Env* env, const string& dir,\n+    Env* env, const std::string& dir,\n     experimental::DistributedSnapshotMetadata* metadata, bool* file_exists);\n \n // Writes a dataset graph to the given directory.\n-absl::Status DumpDatasetGraph(Env* env, const std::string& path, uint64 hash,\n+absl::Status DumpDatasetGraph(Env* env, const std::string& path, uint64_t hash,\n                               const GraphDef* graph);\n \n absl::Status DetermineOpState(\n     const std::string& mode_string, bool file_exists,\n     const experimental::SnapshotMetadataRecord* metadata,\n-    uint64 pending_snapshot_expiry_seconds, Mode* mode);\n+    uint64_t pending_snapshot_expiry_seconds, Mode* mode);\n \n // Represents a dataset element or EOF.\n struct ElementOrEOF {\n@@ -420,9 +422,9 @@ struct ElementOrEOF {\n class AsyncWriter {\n  public:\n   explicit AsyncWriter(Env* env, int64_t file_index,\n-                       const std::string& shard_directory, uint64 checkpoint_id,\n-                       const std::string& compression, int64_t version,\n-                       const DataTypeVector& output_types,\n+                       const std::string& shard_directory,\n+                       uint64_t checkpoint_id, const std::string& compression,\n+                       int64_t version, const DataTypeVector& output_types,\n                        std::function<void(absl::Status)> done);\n \n   // Writes the given tensors. The method is non-blocking and returns without\n@@ -437,7 +439,7 @@ class AsyncWriter {\n   void Consume(ElementOrEOF* be) TF_LOCKS_EXCLUDED(mu_);\n   bool ElementAvailable() TF_EXCLUSIVE_LOCKS_REQUIRED(mu_);\n   absl::Status WriterThread(Env* env, const std::string& shard_directory,\n-                            uint64 checkpoint_id,\n+                            uint64_t checkpoint_id,\n                             const std::string& compression, int64_t version,\n                             DataTypeVector output_types);\n "
        },
        {
            "sha": "b8088a3aa9826fcccfe79b19998b5159f8bd1c85",
            "filename": "tensorflow/core/data/split_utils.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fsplit_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fsplit_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fsplit_utils.cc?ref=f1f8e96f59d415a62575220789ee9a3b516440ce",
            "patch": "@@ -82,7 +82,7 @@ absl::Status IndexSplitProvider::Restore(\n int64_t IndexSplitProvider::Cardinality() const {\n   // RandomDataset uses kint64max to simulate infinite splits.\n   // See RandomDatasetOp::Dataset::MakeSplitProviders.\n-  if (n_ == tsl::kint64max) {\n+  if (n_ == std::numeric_limits<int64_t>::max()) {\n     return kInfiniteCardinality;\n   }\n   return n_;"
        },
        {
            "sha": "74c87c5103e21b23f4054a4d308f73a0bedd471f",
            "filename": "tensorflow/core/data/standalone.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fstandalone.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fstandalone.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fstandalone.cc?ref=f1f8e96f59d415a62575220789ee9a3b516440ce",
            "patch": "@@ -162,7 +162,7 @@ absl::Status Dataset::FromGraph(Params params, const GraphDef& graph_def,\n         return absl::OkStatus();\n       }});\n \n-  string fetch_node = \"\";\n+  std::string fetch_node = \"\";\n   for (const auto& node : graph_def.node()) {\n     if (node.op() == \"_Retval\") {\n       fetch_node = node.input(0);"
        },
        {
            "sha": "aa8e7259b5d90be129d7a87e0f6d10b13fff89cd",
            "filename": "tensorflow/core/data/standalone_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fstandalone_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fstandalone_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fstandalone_test.cc?ref=f1f8e96f59d415a62575220789ee9a3b516440ce",
            "patch": "@@ -514,7 +514,7 @@ constexpr const char* const kMapGraphNoAutotuneProto = R\"pb(\n \n TEST(Scalar, Standalone) {\n   struct TestCase {\n-    string graph_string;\n+    std::string graph_string;\n     std::vector<int64_t> expected_outputs;\n   };\n   auto test_cases = {"
        },
        {
            "sha": "12c12b8907994e99ba8dd6c6ff6dc950f1be98c4",
            "filename": "tensorflow/core/data/stats_utils.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fstats_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fstats_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fstats_utils.cc?ref=f1f8e96f59d415a62575220789ee9a3b516440ce",
            "patch": "@@ -33,39 +33,39 @@ ABSL_CONST_INIT const char kFeaturesCount[] = \"features_count\";\n ABSL_CONST_INIT const char kFeatureValuesCount[] = \"feature_values_count\";\n ABSL_CONST_INIT const char kExamplesCount[] = \"examples_count\";\n \n-string ExecutionTimeHistogramName(const string& prefix) {\n+std::string ExecutionTimeHistogramName(const std::string& prefix) {\n   return absl::StrCat(prefix, kDelimiter, kExecutionTime);\n }\n \n-string ThreadUtilizationScalarName(const string& prefix) {\n+std::string ThreadUtilizationScalarName(const std::string& prefix) {\n   return absl::StrCat(prefix, kDelimiter, kThreadUtilization);\n }\n \n-string BufferSizeScalarName(const string& prefix) {\n+std::string BufferSizeScalarName(const std::string& prefix) {\n   return absl::StrCat(prefix, kDelimiter, kBufferSize);\n }\n \n-string BufferCapacityScalarName(const string& prefix) {\n+std::string BufferCapacityScalarName(const std::string& prefix) {\n   return absl::StrCat(prefix, kDelimiter, kBufferCapacity);\n }\n \n-string BufferUtilizationHistogramName(const string& prefix) {\n+std::string BufferUtilizationHistogramName(const std::string& prefix) {\n   return absl::StrCat(prefix, kDelimiter, kBufferUtilization);\n }\n \n-string FilterdElementsScalarName(const string& prefix) {\n+std::string FilterdElementsScalarName(const std::string& prefix) {\n   return absl::StrCat(prefix, kDelimiter, kFilteredElements);\n }\n \n-string DroppedElementsScalarName(const string& prefix) {\n+std::string DroppedElementsScalarName(const std::string& prefix) {\n   return absl::StrCat(prefix, kDelimiter, kDroppedElements);\n }\n \n-string FeatureHistogramName(const string& prefix) {\n+std::string FeatureHistogramName(const std::string& prefix) {\n   return absl::StrCat(prefix, kDelimiter, kFeaturesCount);\n }\n \n-string FeatureValueHistogramName(const string& prefix) {\n+std::string FeatureValueHistogramName(const std::string& prefix) {\n   return absl::StrCat(prefix, kDelimiter, kFeatureValuesCount);\n }\n "
        },
        {
            "sha": "22a40b9be963a78bb6f118365b9184128ab386c2",
            "filename": "tensorflow/core/data/stats_utils.h",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fstats_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Fstats_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fstats_utils.h?ref=f1f8e96f59d415a62575220789ee9a3b516440ce",
            "patch": "@@ -33,33 +33,33 @@ extern const char kFeatureValuesCount[];\n extern const char kExamplesCount[];\n \n // Name for tf.data function execution time (in ns) histogram metrics.\n-string ExecutionTimeHistogramName(const string& prefix);\n+std::string ExecutionTimeHistogramName(const std::string& prefix);\n \n // Name for thread utilization (ratio of threads being used and maximum number\n // of threads allocated) scalar metrics.\n-string ThreadUtilizationScalarName(const string& prefix);\n+std::string ThreadUtilizationScalarName(const std::string& prefix);\n \n // Name for buffer size scalar metrics.\n-string BufferSizeScalarName(const string& prefix);\n+std::string BufferSizeScalarName(const std::string& prefix);\n \n // Name for buffer capacity (maximum allocated buffer size) scalar metrics.\n-string BufferCapacityScalarName(const string& prefix);\n+std::string BufferCapacityScalarName(const std::string& prefix);\n \n // Name for buffer utilization (ratio of buffer size and maximum allocated\n // buffer size.) histogram metrics.\n-string BufferUtilizationHistogramName(const string& prefix);\n+std::string BufferUtilizationHistogramName(const std::string& prefix);\n \n // Name for filtered elements scalar metrics.\n-string FilterdElementsScalarName(const string& prefix);\n+std::string FilterdElementsScalarName(const std::string& prefix);\n \n // Name for dropped elements scalar mereics.\n-string DroppedElementsScalarName(const string& prefix);\n+std::string DroppedElementsScalarName(const std::string& prefix);\n \n // Name for features count histogram metrics.\n-string FeatureHistogramName(const string& prefix);\n+std::string FeatureHistogramName(const std::string& prefix);\n \n // Name for feature-values count histogram metrics.\n-string FeatureValueHistogramName(const string& prefix);\n+std::string FeatureValueHistogramName(const std::string& prefix);\n \n }  // namespace stats_utils\n }  // namespace data"
        },
        {
            "sha": "6d1963222986120cdfb79cf83a1a17cb4324e195",
            "filename": "tensorflow/core/data/unbounded_thread_pool.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Funbounded_thread_pool.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Funbounded_thread_pool.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Funbounded_thread_pool.cc?ref=f1f8e96f59d415a62575220789ee9a3b516440ce",
            "patch": "@@ -59,7 +59,7 @@ class UnboundedThreadPool::LogicalThreadFactory : public ThreadFactory {\n  public:\n   explicit LogicalThreadFactory(UnboundedThreadPool* pool) : pool_(pool) {}\n \n-  std::unique_ptr<Thread> StartThread(const string& name,\n+  std::unique_ptr<Thread> StartThread(const std::string& name,\n                                       std::function<void()> fn) override {\n     auto done = std::make_shared<absl::Notification>();\n     pool_->ScheduleOnWorkQueue(std::move(fn), done);"
        },
        {
            "sha": "1046c8ad5e7bb7aee3ede2674e1b75c2fce20042",
            "filename": "tensorflow/core/data/unbounded_thread_pool.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Funbounded_thread_pool.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1f8e96f59d415a62575220789ee9a3b516440ce/tensorflow%2Fcore%2Fdata%2Funbounded_thread_pool.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Funbounded_thread_pool.h?ref=f1f8e96f59d415a62575220789ee9a3b516440ce",
            "patch": "@@ -35,9 +35,9 @@ namespace data {\n // `UnboundedWorkQueue`.\n class UnboundedThreadPool : public thread::ThreadPoolInterface {\n  public:\n-  UnboundedThreadPool(Env* env, const string& thread_name)\n+  UnboundedThreadPool(Env* env, const std::string& thread_name)\n       : unbounded_work_queue_(env, thread_name) {}\n-  UnboundedThreadPool(Env* env, const string& thread_name,\n+  UnboundedThreadPool(Env* env, const std::string& thread_name,\n                       const ThreadOptions& thread_options)\n       : unbounded_work_queue_(env, thread_name, thread_options) {}\n   ~UnboundedThreadPool() override = default;"
        }
    ],
    "stats": {
        "total": 94,
        "additions": 48,
        "deletions": 46
    }
}