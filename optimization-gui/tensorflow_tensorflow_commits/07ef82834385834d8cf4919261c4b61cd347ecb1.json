{
    "author": "SandSnip3r",
    "message": "Introduce a flag which changes the default behavior of automatic host compute offloading.\n`--xla_disable_automatic_host_compute_offload`\n\nDuring compilation, when device compute is encountered during host memory offloading, normally, that compute is automatically converted to host compute. If `--xla_disable_automatic_host_compute_offload` is specified, XLA will instead return an `InvalidArgumentError`.\n\nPiperOrigin-RevId: 800300553",
    "sha": "07ef82834385834d8cf4919261c4b61cd347ecb1",
    "files": [
        {
            "sha": "6f5ee2662cf1cb0171d676c9f6e5ad6f088c2c2e",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 5,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07ef82834385834d8cf4919261c4b61cd347ecb1/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07ef82834385834d8cf4919261c4b61cd347ecb1/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=07ef82834385834d8cf4919261c4b61cd347ecb1",
            "patch": "@@ -444,6 +444,7 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n   opts.set_xla_hlo_pass_fix_detect_cycles(false);\n   opts.set_xla_gpu_experimental_enable_heuristic_collective_combining(true);\n   opts.set_xla_unsupported_crash_on_hlo_pass_silent_hlo_change(false);\n+  opts.set_xla_disable_automatic_host_compute_offload(false);\n   opts.set_xla_unsupported_crash_on_hlo_pass_noop_change(false);\n   opts.set_xla_gpu_experimental_enable_split_k_rewrite(false);\n   opts.set_xla_gpu_experimental_enable_triton_tma(false);\n@@ -2491,6 +2492,13 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n       \"If non empty will interpret this variable as a path for performance \"\n       \"tables for collectives. Expects `xla.gpu.DeviceHloInstructionProfiles` \"\n       \"proto.\"));\n+  flag_list->push_back(tsl::Flag(\n+      \"xla_unsupported_crash_on_hlo_pass_noop_change\",\n+      bool_setter_for(\n+          &DebugOptions::set_xla_unsupported_crash_on_hlo_pass_noop_change),\n+      debug_options->xla_unsupported_crash_on_hlo_pass_noop_change(),\n+      \"Crash if a pass reports that it did change the HLO but in fact it \"\n+      \"did not.\"));\n   flag_list->push_back(tsl::Flag(\n       \"xla_unsupported_crash_on_hlo_pass_silent_hlo_change\",\n       bool_setter_for(\n@@ -2500,12 +2508,12 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n       \"Crash if a pass reports that it did not change the HLO but in fact it \"\n       \"did.\"));\n   flag_list->push_back(tsl::Flag(\n-      \"xla_unsupported_crash_on_hlo_pass_noop_change\",\n+      \"xla_disable_automatic_host_compute_offload\",\n       bool_setter_for(\n-          &DebugOptions::set_xla_unsupported_crash_on_hlo_pass_noop_change),\n-      debug_options->xla_unsupported_crash_on_hlo_pass_noop_change(),\n-      \"Crash if a pass reports that it did change the HLO but in fact it \"\n-      \"did not.\"));\n+          &DebugOptions::set_xla_disable_automatic_host_compute_offload),\n+      debug_options->xla_disable_automatic_host_compute_offload(),\n+      \"Return an error if HostOffloader would have automatically offloaded some\"\n+      \" compute to the host.\"));\n   flag_list->push_back(tsl::Flag(\n       \"xla_gpu_experimental_matmul_perf_table_path\",\n       string_setter_for("
        },
        {
            "sha": "a524561bb2d27da7b379738f3099950490bb92b4",
            "filename": "third_party/xla/xla/hlo/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07ef82834385834d8cf4919261c4b61cd347ecb1/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07ef82834385834d8cf4919261c4b61cd347ecb1/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD?ref=07ef82834385834d8cf4919261c4b61cd347ecb1",
            "patch": "@@ -340,6 +340,7 @@ xla_cc_test(\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest\","
        },
        {
            "sha": "bae9c065b7f3bde54da711a6642ec998c9d90cca",
            "filename": "third_party/xla/xla/hlo/transforms/host_offloader.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07ef82834385834d8cf4919261c4b61cd347ecb1/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07ef82834385834d8cf4919261c4b61cd347ecb1/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader.cc?ref=07ef82834385834d8cf4919261c4b61cd347ecb1",
            "patch": "@@ -280,6 +280,13 @@ absl::StatusOr<bool> HostOffloader::WalkDownHostMemoryOffloadPaths(\n           \"to move the inputs to the device so that computation happens on the \"\n           \"device.\",\n           instruction->name());\n+      if (instruction->GetModule()\n+              ->config()\n+              .debug_options()\n+              .xla_disable_automatic_host_compute_offload()) {\n+        return absl::InvalidArgumentError(\n+            \"Automatic host compute offloading is disabled.\");\n+      }\n       host_offload_utils::SetHostComputeFrontendAttribute(*instruction);\n     }\n     if (!already_saved_buffer) {"
        },
        {
            "sha": "e69c664222b65d32286ae24fa5bde0308f8fda33",
            "filename": "third_party/xla/xla/hlo/transforms/host_offloader_test.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 3,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07ef82834385834d8cf4919261c4b61cd347ecb1/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07ef82834385834d8cf4919261c4b61cd347ecb1/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader_test.cc?ref=07ef82834385834d8cf4919261c4b61cd347ecb1",
            "patch": "@@ -25,6 +25,7 @@ limitations under the License.\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/hlo/analysis/alias_info.h\"\n@@ -53,7 +54,7 @@ namespace {\n \n class HostOffloaderTest : public HloHardwareIndependentTestBase {\n  protected:\n-  absl::StatusOr<bool> RunHostOffloader(HloModule* module) {\n+  absl::StatusOr<bool> RunHostOffloader(HloModule* module) const {\n     TF_EXPECT_OK(verifier().Run(module).status());\n     if (module->has_schedule()) {\n       return absl::InternalError(\"Expected a non-scheduled module\");\n@@ -68,12 +69,13 @@ class HostOffloaderTest : public HloHardwareIndependentTestBase {\n     return changed;\n   }\n \n-  void TestShapeHasMemorySpace(const Shape& shape, int64_t memory_space) {\n+  static void TestShapeHasMemorySpace(const Shape& shape,\n+                                      int64_t memory_space) {\n     ASSERT_TRUE(shape.has_layout());\n     EXPECT_EQ(shape.layout().memory_space(), memory_space);\n   }\n \n-  bool HaveRemainingOffloadAnnotations(const HloModule* module) {\n+  static bool HaveRemainingOffloadAnnotations(const HloModule* module) {\n     for (const HloComputation* computation : module->computations()) {\n       for (const HloInstruction* instruction : computation->instructions()) {\n         if (instruction->IsCustomCall(\n@@ -86,6 +88,12 @@ class HostOffloaderTest : public HloHardwareIndependentTestBase {\n     return false;\n   }\n \n+  static void DisableAutomaticHostComputeOffload(HloModule* module) {\n+    module->mutable_config()\n+        .mutable_debug_options()\n+        .set_xla_disable_automatic_host_compute_offload(true);\n+  }\n+\n   AliasInfo alias_info_;\n };\n \n@@ -4528,6 +4536,27 @@ ENTRY main.39_spmd (param.2: f32[16,16,16]) -> (f32[16,16,16], f32[16,16,16]) {\n   EXPECT_EQ(default_memory_space_count, 1);\n }\n \n+TEST_F(HostOffloaderTest, AutomaticHostComputeOffloadDisabled) {\n+  const absl::string_view hlo_string = R\"(\n+    HloModule module, entry_computation_layout={(f32[1024]{0})->f32[1024]{0}}\n+\n+    ENTRY main {\n+      param = f32[1024]{0} parameter(0)\n+      to_host = f32[1024]{0} custom-call(param), custom_call_target=\"MoveToHost\"\n+      tanh = f32[1024]{0} tanh(to_host)\n+      ROOT to_device = f32[1024]{0} custom-call(tanh), custom_call_target=\"MoveToDevice\"\n+    })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  DisableAutomaticHostComputeOffload(module.get());\n+  // Normally, the tanh will be offloaded to host compute, but because we have\n+  // disabled automatic host compute offloading, we expect an error.\n+  absl::StatusOr<bool> changed = RunHostOffloader(module.get());\n+  EXPECT_THAT(changed,\n+              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+}\n+\n }  // namespace\n \n }  // namespace xla"
        },
        {
            "sha": "af20205e7360fcf38085c858893ad2a6038e4280",
            "filename": "third_party/xla/xla/xla.proto",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07ef82834385834d8cf4919261c4b61cd347ecb1/third_party%2Fxla%2Fxla%2Fxla.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07ef82834385834d8cf4919261c4b61cd347ecb1/third_party%2Fxla%2Fxla%2Fxla.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fxla.proto?ref=07ef82834385834d8cf4919261c4b61cd347ecb1",
            "patch": "@@ -127,6 +127,9 @@ message DebugOptions {\n   //--------------------------------------------------------------------------//\n   // go/keep-sorted start\n \n+  // Return an error if HostOffloader would have automatically offloaded some\n+  // compute to the host.\n+  optional bool xla_disable_automatic_host_compute_offload = 408;\n   // Perform hash-based cycle detection in fixed-point loops.\n   optional bool xla_hlo_pass_fix_detect_cycles = 370;\n   // Crash if HloPassFix can not converge after a fixed number of iterations.\n@@ -1328,7 +1331,7 @@ message DebugOptions {\n   // Note: when adding a new flag, please add it to one of the hardware-specific\n   // or hardware-agnostic sections at the top of this proto message.\n \n-  // Next id: 408\n+  // Next id: 409\n \n   // Extra options to pass to the compilation backend (e.g. LLVM); specific\n   // interpretation of these values is left to the backend."
        }
    ],
    "stats": {
        "total": 66,
        "additions": 57,
        "deletions": 9
    }
}