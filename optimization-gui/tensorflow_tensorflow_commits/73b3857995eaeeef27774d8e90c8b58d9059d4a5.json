{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Cleanup collective ops e2e test\n\nPiperOrigin-RevId: 815729480",
    "sha": "73b3857995eaeeef27774d8e90c8b58d9059d4a5",
    "files": [
        {
            "sha": "0b056e2a79e228d2f29e04c8bf80f6ef2647c02a",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/73b3857995eaeeef27774d8e90c8b58d9059d4a5/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/73b3857995eaeeef27774d8e90c8b58d9059d4a5/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=73b3857995eaeeef27774d8e90c8b58d9059d4a5",
            "patch": "@@ -4428,6 +4428,7 @@ cc_library(\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/stream_executor/integrations:tf_allocator_adapter\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/base:nullability\",\n         \"@com_google_absl//absl/log\",\n@@ -4470,7 +4471,6 @@ cc_library(\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:stream_executor_h\",\n-        \"//xla/stream_executor:stream_executor_memory_allocator\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\","
        },
        {
            "sha": "0cbb261e049ccd341a3928b01c54783ccdd06f76",
            "filename": "third_party/xla/xla/service/hlo_runner.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/73b3857995eaeeef27774d8e90c8b58d9059d4a5/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/73b3857995eaeeef27774d8e90c8b58d9059d4a5/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner.cc?ref=73b3857995eaeeef27774d8e90c8b58d9059d4a5",
            "patch": "@@ -57,7 +57,6 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n-#include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/logging.h\"\n@@ -94,7 +93,8 @@ class HloRunnerExecutable : public OpaqueExecutable {\n };\n }  // namespace\n \n-HloRunner::HloRunner(se::Platform* platform, int intra_op_parallelism_threads) {\n+HloRunner::HloRunner(se::Platform* platform, int intra_op_parallelism_threads,\n+                     std::unique_ptr<se::DeviceMemoryAllocator> allocator) {\n   BackendOptions backend_options;\n   backend_options.set_platform(platform);\n   backend_options.set_intra_op_parallelism_threads(\n@@ -103,16 +103,15 @@ HloRunner::HloRunner(se::Platform* platform, int intra_op_parallelism_threads) {\n   device_shape_representation_fn_ = [this](const Shape& shape) {\n     return backend_->compiler()->DefaultDeviceShapeRepresentation(shape);\n   };\n+  allocator_ = std::move(allocator);\n   VLOG(1) << \"Created HloRunner for platform: \" << platform->Name();\n }\n \n HloRunner::~HloRunner() {}\n \n se::DeviceMemoryAllocator* HloRunner::GetAllocator() {\n-  absl::MutexLock lock(mu_);\n   if (allocator_ == nullptr) {\n-    allocator_ = std::make_unique<se::StreamExecutorMemoryAllocator>(\n-        backend().default_stream_executor());\n+    return backend_->memory_allocator();\n   }\n   return allocator_.get();\n }\n@@ -793,7 +792,7 @@ ServiceExecutableRunOptions HloRunner::GetServiceRunOptionsForDevice(\n   run_options.set_local_device_count(local_device_count);\n \n   run_options.set_stream(stream);\n-  run_options.set_allocator(backend().memory_allocator());\n+  run_options.set_allocator(GetAllocator());\n   run_options.set_intra_op_thread_pool(\n       backend().eigen_intra_op_thread_pool_device());\n   if (device_assignment != nullptr) {"
        },
        {
            "sha": "e6c40007c0c9cbfe389e833625a3fd8deb73797f",
            "filename": "third_party/xla/xla/service/hlo_runner.h",
            "status": "modified",
            "additions": 32,
            "deletions": 29,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/73b3857995eaeeef27774d8e90c8b58d9059d4a5/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/73b3857995eaeeef27774d8e90c8b58d9059d4a5/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner.h?ref=73b3857995eaeeef27774d8e90c8b58d9059d4a5",
            "patch": "@@ -50,19 +50,22 @@ namespace xla {\n \n class BufferAssignmentProto;\n \n-// A base class for running an HloModule. This executes the given HloModule on a\n-// certain backend directly without using the client interface. HloModule can be\n-// explicitly built, or loaded from a serialization file (e.g., hlo proto\n+// A base class for running an `HloModule`. This executes the given `HloModule`\n+// on a certain backend directly without using the client interface. `HloModule`\n+// can be explicitly built, or loaded from a serialization file (e.g., hlo proto\n // file), or parsed from a hlo textual IR string.\n class HloRunner : public HloRunnerInterface {\n  public:\n-  // intra_op_parallelism_threads: For the CPU backend only. It is the thread\n+  // `intra_op_parallelism_threads`: For the CPU backend only. It is the thread\n   // pool size for parallel execution of an individual operator. The default\n   // value of -1 will result in initializing the thread pool with the number of\n   // threads equal to the number of\n   // cores in the system.\n-  explicit HloRunner(se::Platform* platform,\n-                     int intra_op_parallelism_threads = -1);\n+  // allocator: If non-null, a custom device memory allocator to use instead of\n+  // the backend allocator.\n+  explicit HloRunner(\n+      se::Platform* platform, int intra_op_parallelism_threads = -1,\n+      std::unique_ptr<se::DeviceMemoryAllocator> allocator = nullptr);\n \n   ~HloRunner() override;\n \n@@ -74,7 +77,7 @@ class HloRunner : public HloRunnerInterface {\n   // Executes the given module with given literals as input and returns the\n   // result as a Literal.\n   //\n-  // If run_hlo_passes is false, the module will be executed without Hlo\n+  // If `run_hlo_passes` is false, the module will be executed without Hlo\n   // optimization.\n \n   using HloRunnerInterface::Execute;\n@@ -100,7 +103,7 @@ class HloRunner : public HloRunnerInterface {\n       OpaqueExecutable* executable, absl::Span<const Literal* const> arguments,\n       ExecutionProfile* profile);\n \n-  // As Execute(), but accepts and returns device buffers instead of host\n+  // As `Execute()`, but accepts and returns device buffers instead of host\n   // buffers.\n   //\n   // ExecuteWithMovedDeviceBuffers is more memory-safe, but it consumes the\n@@ -118,11 +121,11 @@ class HloRunner : public HloRunnerInterface {\n       absl::Span<ScopedShapedBuffer const> arguments,\n       ExecutionProfile* profile);\n \n-  // As Execute(), but accepts and returns device buffers instead of host\n+  // As `Execute()`, but accepts and returns device buffers instead of host\n   // buffers.\n   //\n-  // This is a memory-safer version of ExecuteWithDeviceBuffers, but it consumes\n-  // the arguments.\n+  // This is a memory-safer version of `ExecuteWithDeviceBuffers`, but it\n+  // consumes the arguments.\n   absl::StatusOr<ExecutionOutput> ExecuteWithMovedDeviceBuffers(\n       std::unique_ptr<HloModule> module,\n       std::vector<ScopedShapedBuffer> arguments, bool run_hlo_passes,\n@@ -139,7 +142,7 @@ class HloRunner : public HloRunnerInterface {\n       Executable* executable, std::vector<ScopedShapedBuffer> arguments,\n       ExecutionProfile* profile);\n \n-  // Creates an executable object given an HLO module. If run_hlo_passes is\n+  // Creates an executable object given an HLO module. If `run_hlo_passes` is\n   // true, the HLO passes will be run as part of compilation.\n   absl::StatusOr<std::unique_ptr<OpaqueExecutable>> CreateExecutable(\n       std::unique_ptr<HloModule> module, bool run_hlo_passes) override;\n@@ -173,7 +176,7 @@ class HloRunner : public HloRunnerInterface {\n   // Same as above, but with a reusable Executable.  This may update the profile\n   // information in *executable.\n   //\n-  // Note that this call ignores ReplicatedExecutionOptions::run_hlo_passes,\n+  // Note that this call ignores `ReplicatedExecutionOptions::run_hlo_passes`,\n   // since we've already compiled the Executable.\n   absl::StatusOr<std::vector<Literal>> ExecuteReplicated(\n       OpaqueExecutable* executable, const ReplicatedExecuteOptions& options,\n@@ -182,8 +185,8 @@ class HloRunner : public HloRunnerInterface {\n   // Same as above, but with different reusable Executables. This may update the\n   // profile information in *executables.\n   //\n-  // Note that this call ignores ReplicatedExecutionOptions::run_hlo_passes,\n-  // since we've already compiled the Executable.\n+  // Note that this call ignores `ReplicatedExecutionOptions::run_hlo_passes`,\n+  // since we've already compiled the `Executable`.\n   absl::StatusOr<std::vector<Literal>> ExecuteReplicated(\n       std::function<OpaqueExecutable*(int64_t)> executable_provider,\n       std::function<int64_t(int64_t)> argument_count_provider,\n@@ -195,7 +198,7 @@ class HloRunner : public HloRunnerInterface {\n   // default backend. If creation fails, crashes the program.\n   //\n   // This creates the backend lazily so it's possible to instantiate an\n-  // HloRunner in a program without any backends linked in.\n+  // `HloRunner` in a program without any backends linked in.\n   Backend& backend();\n   const Backend& backend() const;\n \n@@ -214,11 +217,11 @@ class HloRunner : public HloRunnerInterface {\n       std::unique_ptr<Executable> executable) const;\n   absl::StatusOr<const HloModule* absl_nonnull> HloModuleFromWrapped(\n       const OpaqueExecutable* wrapped) const override;\n-  // Returns the HloProto of the Executable wrapped by the given\n+  // Returns the `HloProto` of the `Executable` wrapped by the given\n   // OpaqueExecutable. This is a temporary API to help move to OpaqueExecutable.\n   // We need to come up with a better way to obtain this information and\n   // evaluate whether we need to do this at all. A drop-in migration to\n-  // HloRunnerPjRt (via HloRunnerInterface) won't be possible because this\n+  // `HloRunnerPjRt` (via `HloRunnerInterface`) won't be possible because this\n   // information is not available from a PjRt(Loaded)Executable.\n   //\n   // TODO: b/393183864 - Remove this API.\n@@ -251,10 +254,10 @@ class HloRunner : public HloRunnerInterface {\n       Executable* executable, std::vector<ExecutionInput> arguments,\n       ExecutionProfile* profile);\n \n-  // Creates a ServiceExecutableRunOptions object to configure a run on device,\n-  // using the provided stream object. If device_assignment is not nullptr, it\n-  // will be used to configure the replication parameters. Replicated executions\n-  // should pass the device_assignment parameter.\n+  // Creates a `ServiceExecutableRunOptions` object to configure a run on\n+  // device, using the provided stream object. If device_assignment is not\n+  // nullptr, it will be used to configure the replication parameters.\n+  // Replicated executions should pass the device_assignment parameter.\n   ServiceExecutableRunOptions GetServiceRunOptionsForDevice(\n       int64_t device, se::Stream* stream, DeviceAssignment* device_assignment,\n       RunId run_id, int local_device_count);\n@@ -270,12 +273,12 @@ class HloRunner : public HloRunnerInterface {\n       const ReplicatedExecuteOptions& options,\n       DeviceAssignment* device_assignment);\n \n-  // Gets or creates the DeviceMemoryAllocator.\n-  se::DeviceMemoryAllocator* GetAllocator() ABSL_LOCKS_EXCLUDED(mu_);\n+  // Gets or creates the `DeviceMemoryAllocator`.\n+  se::DeviceMemoryAllocator* GetAllocator();\n \n-  // Calls UpdateEntryComputationLayout if HloRunner has not called it on the\n+  // Calls `UpdateEntryComputationLayout` if HloRunner has not called it on the\n   // module before. This method is called before the module is executed. The\n-  // reason UpdateEntryComputationLayout is only called once instead of every\n+  // reason `UpdateEntryComputationLayout` is only called once instead of every\n   // time is to avoid one thread updating the layout while another thread is\n   // reading it during execution.\n   void MaybeUpdateEntryComputationLayout(HloModule* module)\n@@ -284,11 +287,11 @@ class HloRunner : public HloRunnerInterface {\n   std::unique_ptr<Backend> backend_;\n   TransferManager::DeviceShapeRepresentationFn device_shape_representation_fn_;\n \n-  absl::Mutex mu_;\n-  std::unique_ptr<se::DeviceMemoryAllocator> allocator_ ABSL_GUARDED_BY(mu_);\n+  std::unique_ptr<se::DeviceMemoryAllocator> allocator_;\n \n+  absl::Mutex mu_;\n   // Set of module unique_ids that we already called\n-  // UpdateEntryComputationLayout() on\n+  // `UpdateEntryComputationLayout() on\n   absl::flat_hash_set<int> module_ids_with_updated_layouts_\n       ABSL_GUARDED_BY(mu_);\n };"
        },
        {
            "sha": "6a994d8ef9a4d925cc01259fa07ba4703e94d3b0",
            "filename": "third_party/xla/xla/tests/BUILD",
            "status": "modified",
            "additions": 11,
            "deletions": 2,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/73b3857995eaeeef27774d8e90c8b58d9059d4a5/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/73b3857995eaeeef27774d8e90c8b58d9059d4a5/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2FBUILD?ref=73b3857995eaeeef27774d8e90c8b58d9059d4a5",
            "patch": "@@ -2779,8 +2779,6 @@ xla_test(\n         \"gpu\",\n     ],\n     deps = [\n-        \":hlo_runner_agnostic_test_base\",\n-        \":hlo_test_base\",\n         \":literal_test_util\",\n         \":test_utils\",\n         \":xla_internal_test_main\",\n@@ -2791,14 +2789,25 @@ xla_test(\n         \"//xla:types\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n         \"//xla/hlo/testlib:verified_hlo_module\",\n         \"//xla/hlo/utils:hlo_matchers\",\n+        \"//xla/service:backend\",\n         \"//xla/service:computation_placer_hdr\",\n         \"//xla/service:hlo_module_config\",\n+        \"//xla/service:hlo_runner\",\n         \"//xla/service:hlo_runner_interface\",\n+        \"//xla/service:platform_util\",\n         \"//xla/service/gpu:backend_configs_cc\",\n+        \"//xla/service/gpu:gpu_memory_space_assignment\",\n         \"//xla/stream_executor:device_description\",\n+        \"//xla/stream_executor:platform\",\n+        \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n+        \"//xla/stream_executor/integrations:device_mem_allocator\",\n+        \"//xla/stream_executor/integrations:tf_allocator_adapter\",\n+        \"//xla/tsl/framework:bfc_allocator\",\n+        \"//xla/tsl/framework:device_id\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\","
        },
        {
            "sha": "d078c3a811e4182dc29b416e7ba888f59847d5e4",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test.cc",
            "status": "modified",
            "additions": 417,
            "deletions": 300,
            "changes": 717,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/73b3857995eaeeef27774d8e90c8b58d9059d4a5/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/73b3857995eaeeef27774d8e90c8b58d9059d4a5/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc?ref=73b3857995eaeeef27774d8e90c8b58d9059d4a5",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include <algorithm>\n #include <cmath>\n+#include <cstddef>\n #include <cstdint>\n #include <functional>\n #include <memory>\n@@ -44,20 +45,29 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/ir/hlo_sharding.h\"\n+#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n #include \"xla/hlo/testlib/verified_hlo_module.h\"\n #include \"xla/hlo/utils/hlo_matchers.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n+#include \"xla/service/backend.h\"\n #include \"xla/service/computation_placer.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n+#include \"xla/service/gpu/gpu_memory_space_assignment.h\"\n #include \"xla/service/hlo_module_config.h\"\n+#include \"xla/service/hlo_runner.h\"\n #include \"xla/service/hlo_runner_interface.h\"\n+#include \"xla/service/platform_util.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.h\"\n-#include \"xla/tests/hlo_runner_agnostic_test_base.h\"\n-#include \"xla/tests/hlo_test_base.h\"\n+#include \"xla/stream_executor/integrations/device_mem_allocator.h\"\n+#include \"xla/stream_executor/integrations/tf_allocator_adapter.h\"\n+#include \"xla/stream_executor/platform.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tests/literal_test_util.h\"\n #include \"xla/tests/test_utils.h\"\n+#include \"xla/tsl/framework/bfc_allocator.h\"\n+#include \"xla/tsl/framework/device_id.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -82,9 +92,57 @@ DeviceAssignment MakeDeviceAssn(int64_t num_replicas) {\n   return assn;\n }\n \n-class CollectiveOpsTestE2E : public HloTestBase {\n+std::unique_ptr<tsl::BFCAllocator> CreateAllocator(se::StreamExecutor* executor,\n+                                                   int64_t device_ordinal,\n+                                                   std::string name_suffix,\n+                                                   size_t memory_size) {\n+  tsl::BFCAllocator::Options opts;\n+  opts.allow_growth = false;\n+  return std::make_unique<tsl::BFCAllocator>(\n+      std::make_unique<se::DeviceMemAllocator>(\n+          executor, tsl::PlatformDeviceId(device_ordinal)),\n+      memory_size, absl::StrCat(\"GPU_\", device_ordinal, name_suffix), opts);\n+}\n+\n+template <typename Type>\n+Type CheckStatus(absl::StatusOr<Type> result) {\n+  CHECK_OK(result);\n+  return *result;\n+}\n+\n+class CollectiveOpsTestE2E : public HloHardwareIndependentTestBase {\n  public:\n   CollectiveOpsTestE2E() {\n+    se::Platform* platform = CheckStatus(PlatformUtil::GetPlatform(\"GPU\"));\n+    se::Platform* reference_platform =\n+        CheckStatus(PlatformUtil::GetPlatform(\"GPU\"));\n+\n+    std::vector<se::MultiDeviceAdapter::AllocatorInfo> allocators;\n+    constexpr int64_t kGB = 1024LL * 1024LL * 1024LL;\n+    size_t common_buffers_size = 8 * kGB;   // 8GB\n+    size_t collectives_buffers_size = kGB;  // 1GB\n+    for (int64_t i = 0; i < platform->VisibleDeviceCount(); ++i) {\n+      se::StreamExecutor* executor =\n+          CheckStatus(platform->ExecutorForDevice(i));\n+      // Common memory allocator for device i.\n+      allocators.emplace_back(\n+          CreateAllocator(executor, i, \"_bfc\", common_buffers_size), nullptr, 0,\n+          i, platform);\n+\n+      // Collectives and symmetric memory allocator for device i.\n+      allocators.emplace_back(CreateAllocator(executor, i, \"_collectives_bfc\",\n+                                              collectives_buffers_size),\n+                              nullptr, (int)gpu::MemorySpaceColor::kCollective,\n+                              i, platform);\n+    }\n+\n+    hlo_runner_ = std::make_unique<HloRunner>(\n+        platform, /*intra_op_parallelism_threads=*/0,\n+        std::make_unique<se::MultiDeviceAdapter>(platform,\n+                                                 std::move(allocators)));\n+    reference_hlo_runner_ = std::make_unique<HloRunner>(\n+        reference_platform, /*intra_op_parallelism_threads=*/0);\n+\n     replacements_[kF8E4M3DatatypePlaceholder] =\n         IsCuda() ? \"f8e4m3fn\" : \"f8e4m3fnuz\";\n     replacements_[kF8E5M2DatatypePlaceholder] =\n@@ -96,7 +154,7 @@ class CollectiveOpsTestE2E : public HloTestBase {\n   }\n \n   const se::GpuComputeCapability& Capability() {\n-    return backend()\n+    return hlo_runner_->backend()\n         .default_stream_executor()\n         ->GetDeviceDescription()\n         .gpu_compute_capability();\n@@ -126,23 +184,82 @@ class CollectiveOpsTestE2E : public HloTestBase {\n     TF_ASSERT_OK_AND_ASSIGN(auto module,\n                             ParseAndReturnVerifiedModule(hlo_text, config));\n \n-    TF_ASSERT_OK_AND_ASSIGN(auto executable,\n-                            CreateExecutable(std::move(module),\n-                                             /*run_hlo_passes=*/true));\n+    TF_ASSERT_OK_AND_ASSIGN(auto executable, hlo_runner_->CreateExecutable(\n+                                                 std::move(module),\n+                                                 /*run_hlo_passes=*/true));\n     TF_ASSERT_OK_AND_ASSIGN(\n         const HloModule* const hlo_module,\n-        test_runner().HloModuleFromWrapped(executable.get()));\n+        hlo_runner_->HloModuleFromWrapped(executable.get()));\n     std::vector<HloInstruction*> gemm_ops =\n         FindInstructions(hlo_module, HloOpcode::kCustomCall);\n     for (HloInstruction* gemm_op : gemm_ops) {\n       EXPECT_EQ(gemm_op->custom_call_target(), \"__cublas$lt$matmul$f8\");\n     }\n   }\n \n+  // TODO(b/449655621) Use absl::AnyInvocable instead of std::function.\n+  absl::StatusOr<std::vector<Literal>> ExecuteReplicated(\n+      const std::function<OpaqueExecutable*(int64_t)> executable_provider,\n+      const std::function<int64_t(int64_t)> argument_count_provider,\n+      const std::function<const Literal*(int64_t, int64_t)> argument_provider,\n+      const int64_t num_replicas, const bool run_hlo_passes,\n+      DeviceAssignment* const device_assignment) {\n+    // TODO(b/441865120): Use designated initializers this once XLA moves to\n+    // C++20.\n+    HloRunnerInterface::ReplicatedExecuteOptions options;\n+    options.num_replicas = num_replicas;\n+    options.run_hlo_passes = run_hlo_passes;\n+    options.use_threads = true;\n+\n+    return hlo_runner_->ExecuteReplicated(\n+        std::move(executable_provider), std::move(argument_count_provider),\n+        std::move(argument_provider), std::move(options), device_assignment);\n+  }\n+\n+  absl::StatusOr<std::vector<Literal>> ExecuteReplicated(\n+      std::unique_ptr<HloModule> module,\n+      const absl::Span<const Literal* const> arguments,\n+      const int64_t num_replicas, DeviceAssignment* const device_assignment,\n+      const bool run_hlo_passes, const bool use_threads) {\n+    // TODO(b/441865120): Use designated initializers this once XLA moves to\n+    // C++20.\n+    HloRunnerInterface::ReplicatedExecuteOptions options;\n+    options.num_replicas = num_replicas;\n+    options.arguments = {arguments.begin(), arguments.end()};\n+    options.run_hlo_passes = run_hlo_passes;\n+    options.use_threads = use_threads;\n+\n+    return hlo_runner_->ExecuteReplicated(std::move(module), std::move(options),\n+                                          device_assignment);\n+  }\n+\n+  absl::StatusOr<std::vector<Literal>> ExecuteReplicated(\n+      std::unique_ptr<HloModule> module,\n+      const std::vector<std::vector<Literal*>> arguments,\n+      DeviceAssignment* const device_assignment, const int64_t num_replicas,\n+      const bool run_hlo_passes) {\n+    CHECK(num_replicas > 0 && \"expect at least one replica\");\n+    CHECK(num_replicas == arguments.size() &&\n+          \"expect arguments for each replica\");\n+    int64_t argument_count = arguments.front().size();\n+    TF_ASSIGN_OR_RETURN(\n+        const std::unique_ptr<OpaqueExecutable> executable,\n+        hlo_runner_->CreateExecutable(std::move(module), run_hlo_passes));\n+    return ExecuteReplicated(\n+        /*executable_provider=*/[&](int64_t) { return executable.get(); },\n+        /*argument_count_provider=*/[&](int64_t) { return argument_count; },\n+        /*argument_provider=*/\n+        [&](int64_t replica_idx, int64_t argument_idx) -> const Literal* {\n+          return arguments[replica_idx][argument_idx];\n+        },\n+        num_replicas, /*run_hlo_passes=*/run_hlo_passes,\n+        /*device_assignment=*/device_assignment);\n+  }\n+\n   absl::StatusOr<std::vector<Literal>> ExecuteReplicated(\n       OpaqueExecutable* executable, int64_t num_replicas) {\n     DeviceAssignment device_assignment = MakeDeviceAssn(num_replicas);\n-    return HloTestBase::ExecuteReplicated(\n+    return ExecuteReplicated(\n         /*executable_provider*/ [&](int64_t) { return executable; },\n         /*argument_count_provider*/ [](int64_t) { return 0; },\n         /*argument_provider*/ [](int64_t, int64_t) { return nullptr; },\n@@ -158,6 +275,8 @@ class CollectiveOpsTestE2E : public HloTestBase {\n \n  protected:\n   absl::flat_hash_map<absl::string_view, absl::string_view> replacements_;\n+  std::unique_ptr<HloRunner> hlo_runner_;\n+  std::unique_ptr<HloRunner> reference_hlo_runner_;\n \n  private:\n   static constexpr const char* kF8E4M3DatatypePlaceholder{\"<<F8E4M3>>\"};\n@@ -174,15 +293,15 @@ class CollectiveOpsTestE2E : public HloTestBase {\n class CollectiveOpsWithFlagsBase : public CollectiveOpsTestE2E {\n  public:\n   CollectiveOpsWithFlagsBase(bool enable_async, bool enable_p2p_memcpy)\n-      : enable_async_(enable_async),\n-        enable_p2p_memcpy_(enable_p2p_memcpy),\n-        num_devices_(backend().device_count()) {\n+      : enable_async_(enable_async), enable_p2p_memcpy_(enable_p2p_memcpy) {\n     VLOG(1) << \"Running with \" << num_devices_ << \" devices\";\n+    num_devices_ = hlo_runner_->backend().device_count();\n   }\n \n  protected:\n   DebugOptions GetDebugOptionsForTest() const override {\n-    DebugOptions debug_options = HloTestBase::GetDebugOptionsForTest();\n+    DebugOptions debug_options =\n+        HloHardwareIndependentTestBase::GetDebugOptionsForTest();\n \n     // Disable autotuning which is unnecessary.\n     debug_options.set_xla_gpu_autotune_level(0);\n@@ -212,13 +331,13 @@ class CollectiveOpsWithFlagsBase : public CollectiveOpsTestE2E {\n \n     TF_ASSIGN_OR_RETURN(auto module,\n                         ParseAndReturnVerifiedModule(hlo_string, config));\n-    return CreateExecutable(std::move(module),\n-                            /*run_hlo_passes=*/true);\n+    return hlo_runner_->CreateExecutable(std::move(module),\n+                                         /*run_hlo_passes=*/true);\n   }\n-  using CollectiveOpsTestE2E::CreateExecutable;\n+\n   const bool enable_async_;\n   const bool enable_p2p_memcpy_;\n-  const int64_t num_devices_;\n+  int64_t num_devices_;\n };\n \n class AsyncCollectiveOps : public CollectiveOpsWithFlagsBase,\n@@ -285,15 +404,15 @@ TEST_P(AsyncCollectiveOps, AsyncAllReduce) {\n     )\";\n \n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n   const bool enable_async_all_reduce = GetParam();\n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   HloInstruction* all_reduce_start =\n       FindInstruction(hlo_module, HloOpcode::kAllReduceStart);\n@@ -326,16 +445,16 @@ TEST_P(AsyncCollectiveOps, AsyncAllGather) {\n   }\n   )\";\n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n   const bool enable_async_all_gather = GetParam();\n \n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   HloInstruction* all_gather_start =\n       FindInstruction(hlo_module, HloOpcode::kAllGatherStart);\n@@ -372,16 +491,16 @@ TEST_P(AsyncCollectiveOps, AsyncAllGatherMixedTypes) {\n   }\n   )\";\n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n   const bool enable_async_all_gather = GetParam();\n \n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   HloInstruction* all_gather_start =\n       FindInstruction(hlo_module, HloOpcode::kAllGatherStart);\n@@ -415,15 +534,15 @@ TEST_P(AsyncCollectiveOps, AsyncCollectiveBroadcast) {\n   }\n   )\";\n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n   const bool enable_async_collective_broadcast = GetParam();\n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   HloInstruction* cb_start =\n       FindInstruction(hlo_module, HloOpcode::kAsyncStart);\n@@ -452,15 +571,15 @@ TEST_P(AsyncCollectiveOps, AsyncCollectivePermute) {\n   }\n   )\";\n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n   const bool enable_async_collective_permute = GetParam();\n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   HloInstruction* cp_start =\n       FindInstruction(hlo_module, HloOpcode::kCollectivePermuteStart);\n@@ -497,7 +616,7 @@ TEST_P(AsyncCollectiveOps, CombinedCollectivePermute) {\n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   HloInstruction* cp_start =\n       FindInstruction(hlo_module, HloOpcode::kCollectivePermuteStart);\n@@ -532,14 +651,14 @@ TEST_P(AsyncCollectiveOps, CollectivePermuteCombiner) {\n   )\";\n   const int64_t kNumReplicas = 4;\n   const bool enable_async_collective_permute = GetParam();\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   HloInstruction* cp_start =\n       FindInstruction(hlo_module, HloOpcode::kCollectivePermuteStart);\n@@ -597,15 +716,15 @@ TEST_P(AsyncCollectiveOps, AsyncReduceScatter) {\n   )\";\n \n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n   const bool enable_async_reduce_scatter = GetParam();\n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   HloInstruction* rs_start =\n       FindInstruction(hlo_module, HloOpcode::kAsyncStart);\n@@ -635,15 +754,15 @@ TEST_P(AsyncCollectiveOps, AsyncAllToAllWithSplitDim) {\n   }\n   )\";\n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n   const bool enable_async_all_to_all = GetParam();\n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   HloInstruction* a2a_start =\n       FindInstruction(hlo_module, HloOpcode::kAsyncStart);\n@@ -684,10 +803,10 @@ TEST_F(CollectiveOpsTestE2E, AsyncAllToAllMemCpyWithSplitDim) {\n                           ParseAndReturnVerifiedModule(kModuleStr, config));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto executable,\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/true));\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const executable_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   // Verify that the all-to-all is not decomposed into a tuple all-to-all.\n   const HloInstruction* all_to_all =\n@@ -723,15 +842,15 @@ TEST_P(AsyncCollectiveOps, AsyncAllToAllWithoutSplitDim) {\n   }\n   )\";\n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n   const bool enable_async_all_to_all = GetParam();\n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   HloInstruction* a2a_start =\n       FindInstruction(hlo_module, HloOpcode::kAsyncStart);\n@@ -780,8 +899,8 @@ TEST_P(AsyncCollectiveOps, AsyncAllToAllMemCpyWithoutSplitDim) {\n                           ParseAndReturnVerifiedModule(kModuleStr, config));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto executable,\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/true));\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n \n   TF_ASSERT_OK_AND_ASSIGN(std::vector<Literal> results,\n                           ExecuteReplicated(executable.get(), kNumReplicas));\n@@ -803,15 +922,15 @@ TEST_P(AsyncCollectiveOps, AsyncAllToAllNumberOfElementsLargerThanInt32Max) {\n   }\n   )\";\n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n   const bool enable_async_all_to_all = GetParam();\n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   HloInstruction* a2a_start =\n       FindInstruction(hlo_module, HloOpcode::kAsyncStart);\n@@ -856,15 +975,15 @@ ENTRY entry {\n )\";\n \n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CreateExecutable(kModuleStr, kNumReplicas));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   const bool enable_async_ragged_all_to_all = GetParam();\n   HloInstruction* ra2a_start =\n@@ -907,9 +1026,9 @@ TEST_P(AsyncMemcpyCollectiveOps, AsyncAllToAllMultipleReplicaGroups) {\n   }\n   )\";\n   const int64_t kNumReplicas = 4;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -918,8 +1037,8 @@ TEST_P(AsyncMemcpyCollectiveOps, AsyncAllToAllMultipleReplicaGroups) {\n                           ParseAndReturnVerifiedModule(kModuleStr, config));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto executable,\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/true));\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n \n   TF_ASSERT_OK_AND_ASSIGN(std::vector<Literal> results,\n                           ExecuteReplicated(executable.get(), kNumReplicas));\n@@ -943,9 +1062,9 @@ TEST_P(AsyncMemcpyCollectiveOps, AsyncAllToAllDegenerateWithSplitDim) {\n   }\n   )\";\n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -954,8 +1073,8 @@ TEST_P(AsyncMemcpyCollectiveOps, AsyncAllToAllDegenerateWithSplitDim) {\n                           ParseAndReturnVerifiedModule(kModuleStr, config));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto executable,\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/true));\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n \n   TF_ASSERT_OK_AND_ASSIGN(std::vector<Literal> results,\n                           ExecuteReplicated(executable.get(), kNumReplicas));\n@@ -978,9 +1097,9 @@ TEST_P(AsyncMemcpyCollectiveOps, AsyncAllToAllDegenerateWithoutSplitDim) {\n   }\n   )\";\n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -989,8 +1108,8 @@ TEST_P(AsyncMemcpyCollectiveOps, AsyncAllToAllDegenerateWithoutSplitDim) {\n                           ParseAndReturnVerifiedModule(kModuleStr, config));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto executable,\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/true));\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n \n   TF_ASSERT_OK_AND_ASSIGN(std::vector<Literal> results,\n                           ExecuteReplicated(executable.get(), kNumReplicas));\n@@ -1015,9 +1134,9 @@ TEST_P(MemcpyCollectiveOps, AllToAll8Gpus) {\n   )\";\n   const int64_t kNumReplicas = 8;\n   const int64_t kNumPartitions = 1;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -1027,8 +1146,8 @@ TEST_P(MemcpyCollectiveOps, AllToAll8Gpus) {\n                           ParseAndReturnVerifiedModule(kModuleStr, config));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto executable,\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/true));\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n \n   TF_ASSERT_OK_AND_ASSIGN(std::vector<Literal> results,\n                           ExecuteReplicated(executable.get(), kNumReplicas));\n@@ -1077,9 +1196,9 @@ TEST_P(AsyncCollectiveOps, MatmulReplicated) {\n    }\n   )\";\n   const int64_t kNumReplicas = 4;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -1102,25 +1221,27 @@ TEST_P(AsyncCollectiveOps, MatmulReplicated) {\n   for (int i = 0; i < fake_arguments.size(); i++) {\n     fake_ptrs[i] = &fake_arguments[i];\n   }\n-  TF_ASSERT_OK_AND_ASSIGN(std::vector<Literal> results,\n-                          HloTestBase::ExecuteReplicated(\n-                              std::move(module), fake_ptrs, kNumReplicas, &assn,\n-                              true /*run_hlo_passes*/, true /*use-threads*/));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::vector<Literal> results,\n+      ExecuteReplicated(std::move(module), fake_ptrs, kNumReplicas, &assn,\n+                        /*run_hlo_passes=*/true, /*use_threads=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       auto ref_module, ParseAndReturnVerifiedModule(kModuleSingleStr, config));\n-  TF_ASSERT_OK_AND_ASSIGN(auto ref_exec, reference_runner().CreateExecutable(\n-                                             std::move(ref_module), true));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto ref_exec,\n+      reference_hlo_runner_->CreateExecutable(std::move(ref_module), true));\n \n   ErrorSpec error_spec{5e-3, 5e-3};\n   fake_ptrs.push_back(nullptr);\n   for (int i = 0; i < kNumReplicas; i++) {\n     auto replica_id =\n         LiteralUtil::CreateFullWithDescendingLayout<uint32_t>({}, i);\n     fake_ptrs.back() = &replica_id;\n-    TF_ASSERT_OK_AND_ASSIGN(auto res, reference_runner().ExecuteWithExecutable(\n-                                          ref_exec.get(), fake_ptrs));\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto res, reference_hlo_runner_->ExecuteWithExecutable(ref_exec.get(),\n+                                                               fake_ptrs));\n     EXPECT_TRUE(LiteralTestUtil::Near(res, results[i], error_spec));\n   }\n }\n@@ -1208,9 +1329,9 @@ TEST_F(CollectiveOpsTestE2E, WhileLoopReduceScatterCodeMotion) {\n   )\";\n \n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   DebugOptions debug_options = GetDebugOptionsForTest();\n@@ -1223,10 +1344,10 @@ TEST_F(CollectiveOpsTestE2E, WhileLoopReduceScatterCodeMotion) {\n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n                           ParseAndReturnVerifiedModule(kModuleStr, config));\n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto executable,\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/true));\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const executable_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   // Verify that the reduce-scatter get hoisted out of the while loop.\n   const HloInstruction* while_loop =\n@@ -1266,9 +1387,9 @@ TEST_F(CollectiveOpsTestE2E, NoAllToAllDecomposition) {\n   }\n   )\";\n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -1277,10 +1398,10 @@ TEST_F(CollectiveOpsTestE2E, NoAllToAllDecomposition) {\n                           ParseAndReturnVerifiedModule(kModuleStr, config));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto executable,\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/true));\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const executable_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   // Verify that the all-to-all is not decomposed into a tuple all-to-all.\n   const HloInstruction* all_to_all =\n@@ -1314,9 +1435,9 @@ TEST_F(CollectiveOpsTestE2E, NoAsyncCollectives) {\n   }\n   )\";\n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -1329,10 +1450,10 @@ TEST_F(CollectiveOpsTestE2E, NoAsyncCollectives) {\n                           ParseAndReturnVerifiedModule(kModuleStr, config));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto executable,\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/true));\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const executable_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   // Verify that the all-to-all is a sync collective.\n   const HloInstruction* all_to_all =\n@@ -1372,8 +1493,8 @@ TEST_F(CollectiveOpsTestE2E, HostMemoryOffloadingWithDonation) {\n       /*param_index=*/{},\n       /*kind=*/HloInputOutputAliasConfig::AliasKind::kMustAlias));\n \n-  auto executable_or =\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/false);\n+  auto executable_or = hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/false);\n \n   EXPECT_FALSE(executable_or.ok())\n       << \"Expected buffer assignment error but compilation succeeded\";\n@@ -1391,9 +1512,9 @@ class CollectiveOpsTestE2EShardedUnsharded : public CollectiveOpsTestE2E {\n   void CollectiveOpsCompareShardedUnsharded(const std::string& hlo_text,\n                                             const int64_t num_partitions = 2) {\n     const int64_t num_replicas = 1;\n-    if (test_runner().device_count() < num_replicas * num_partitions) {\n+    if (hlo_runner_->device_count() < num_replicas * num_partitions) {\n       GTEST_SKIP() << \"Test requires at least \" << num_replicas * num_partitions\n-                   << \" devices (\" << test_runner().device_count()\n+                   << \" devices (\" << hlo_runner_->device_count()\n                    << \" available)\";\n     }\n \n@@ -1440,10 +1561,10 @@ class CollectiveOpsTestE2EShardedUnsharded : public CollectiveOpsTestE2E {\n     DeviceAssignment ref_assn(/*replica_count=*/1,\n                               /*computation_count=*/1);\n     ref_assn(0, 0) = 0;\n-    return HloTestBase::ExecuteReplicated(std::move(ref_module), ref_fake_ptrs,\n-                                          /*num_replicas=*/1, &ref_assn,\n-                                          /*run_hlo_passes=*/true,\n-                                          /*use-threads=*/true);\n+    return ExecuteReplicated(std::move(ref_module), ref_fake_ptrs,\n+                             /*num_replicas=*/1, &ref_assn,\n+                             /*run_hlo_passes=*/true,\n+                             /*use_threads=*/true);\n   }\n \n   // Execute the sharded case.\n@@ -1518,9 +1639,9 @@ class CollectiveOpsTestE2EShardedUnsharded : public CollectiveOpsTestE2E {\n     for (int64_t i = 0; i < num_partitions; ++i) {\n       assn(0, i) = i;\n     }\n-    return HloTestBase::ExecuteReplicated(std::move(module), fake_ptrs,\n-                                          num_partitions,\n-                                          /*run_hlo_passes=*/true, &assn);\n+    return ExecuteReplicated(std::move(module), fake_ptrs, &assn,\n+                             num_partitions,\n+                             /*run_hlo_passes=*/true);\n   }\n \n   // Slice the unsharded reference results and compare to the sharded case.\n@@ -1784,9 +1905,9 @@ class CollectiveOpsTestE2EWindowedNonWindowed : public CollectiveOpsTestE2E {\n       bool enable_a2a_rewrite = false) {\n     const int64_t kNumReplicas = 1;\n     const int64_t kNumPartitions = 4;\n-    if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+    if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n       GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                   << \" devices (\" << test_runner().device_count()\n+                   << \" devices (\" << hlo_runner_->device_count()\n                    << \" available)\";\n     }\n \n@@ -1816,9 +1937,9 @@ class CollectiveOpsTestE2EWindowedNonWindowed : public CollectiveOpsTestE2E {\n \n     TF_ASSERT_OK_AND_ASSIGN(\n         std::vector<Literal> ref_results,\n-        HloTestBase::ExecuteReplicated(\n-            std::move(ref_module), ref_fake_ptrs, kNumPartitions, &assn,\n-            true /*run_hlo_passes*/, true /*use-threads*/));\n+        ExecuteReplicated(std::move(ref_module), ref_fake_ptrs, kNumPartitions,\n+                          &assn, /*run_hlo_passes=*/true,\n+                          /*use_threads=*/true));\n \n     HloModuleConfig config =\n         GetModuleConfigForTest(/*replica_count=*/kNumReplicas);\n@@ -1847,9 +1968,8 @@ class CollectiveOpsTestE2EWindowedNonWindowed : public CollectiveOpsTestE2E {\n \n     TF_ASSERT_OK_AND_ASSIGN(\n         std::vector<Literal> results,\n-        HloTestBase::ExecuteReplicated(\n-            std::move(module), fake_ptrs, kNumPartitions, &assn,\n-            true /*run_hlo_passes*/, true /*use-threads*/));\n+        ExecuteReplicated(std::move(module), fake_ptrs, kNumPartitions, &assn,\n+                          /*run_hlo_passes=*/true, /*use_threads=*/true));\n     ASSERT_EQ(results.size(), kNumPartitions);\n \n     ASSERT_EQ(ref_results.size(), kNumPartitions);\n@@ -2191,9 +2311,9 @@ ENTRY entry {\n )\";\n \n   const int64_t kNumReplicas = 1;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -2210,9 +2330,9 @@ class CollectiveOpsTestE2EPipelinedNonPipelined : public CollectiveOpsTestE2E {\n   void CollectiveOpsComparePipelinedNonPipelined(absl::string_view hlo_string) {\n     const int64_t kNumReplicas = 1;\n     const int64_t kNumPartitions = 2;\n-    if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+    if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n       GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                   << \" devices (\" << test_runner().device_count()\n+                   << \" devices (\" << hlo_runner_->device_count()\n                    << \" available)\";\n     }\n \n@@ -2236,9 +2356,8 @@ class CollectiveOpsTestE2EPipelinedNonPipelined : public CollectiveOpsTestE2E {\n \n     TF_ASSERT_OK_AND_ASSIGN(\n         std::vector<Literal> results,\n-        HloTestBase::ExecuteReplicated(\n-            std::move(module), fake_ptrs, kNumPartitions, &assn,\n-            /*run_hlo_passes=*/true, /*use-threads=*/true));\n+        ExecuteReplicated(std::move(module), fake_ptrs, kNumPartitions, &assn,\n+                          /*run_hlo_passes=*/true, /*use_threads=*/true));\n     ASSERT_EQ(results.size(), kNumPartitions);\n \n     HloModuleConfig ref_config =\n@@ -2258,9 +2377,9 @@ class CollectiveOpsTestE2EPipelinedNonPipelined : public CollectiveOpsTestE2E {\n \n     TF_ASSERT_OK_AND_ASSIGN(\n         std::vector<Literal> ref_results,\n-        HloTestBase::ExecuteReplicated(\n-            std::move(ref_module), ref_fake_ptrs, kNumPartitions, &assn,\n-            /*run_hlo_passes=*/true, /*use-threads=*/true));\n+        ExecuteReplicated(std::move(ref_module), ref_fake_ptrs, kNumPartitions,\n+                          &assn,\n+                          /*run_hlo_passes=*/true, /*use_threads=*/true));\n     ASSERT_EQ(ref_results.size(), kNumPartitions);\n     ErrorSpec error_spec{1e-5, 1e-5};\n     // Expect same results with and without pipelining of collectives.\n@@ -2457,9 +2576,9 @@ ENTRY entry {\n \n   const int64_t kNumReplicas = 1;\n   const int64_t kNumPartitions = 2;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -2469,11 +2588,11 @@ ENTRY entry {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto module, ParseAndReturnVerifiedModule(kModuleReplicatedStr, config));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto executable,\n-                          CreateExecutable(std::move(module),\n-                                           /*run_hlo_passes=*/true));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n   HloInstruction* all_to_all =\n       FindInstruction(hlo_module, HloOpcode::kAllToAll);\n   EXPECT_THAT(all_to_all, NotNull());\n@@ -2489,9 +2608,9 @@ ENTRY entry {\n   }\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), {}, kNumPartitions,\n-                                     &assignment, /*run_hlo_passes=*/true,\n-                                     /*use_threads=*/true));\n+      ExecuteReplicated(std::move(module), {}, kNumPartitions, &assignment,\n+                        /*run_hlo_passes=*/true,\n+                        /*use_threads=*/true));\n   ASSERT_EQ(results.size(), kNumPartitions);\n   const bfloat16 four = static_cast<bfloat16>(4.);\n   const bfloat16 eight = static_cast<bfloat16>(8.);\n@@ -2514,9 +2633,9 @@ ENTRY entry {\n \n   const int64_t kNumReplicas = 1;\n   const int64_t kNumPartitions = 2;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -2528,11 +2647,11 @@ ENTRY entry {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto module, ParseAndReturnVerifiedModule(kModuleReplicatedStr, config));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto executable,\n-                          CreateExecutable(std::move(module),\n-                                           /*run_hlo_passes=*/true));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n   HloInstruction* all_to_all =\n       FindInstruction(hlo_module, HloOpcode::kAllToAll);\n   EXPECT_THAT(all_to_all, NotNull());\n@@ -2548,9 +2667,9 @@ ENTRY entry {\n   }\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), {}, kNumPartitions,\n-                                     &assignment, /*run_hlo_passes=*/true,\n-                                     /*use_threads=*/true));\n+      ExecuteReplicated(std::move(module), {}, kNumPartitions, &assignment,\n+                        /*run_hlo_passes=*/true,\n+                        /*use_threads=*/true));\n   ASSERT_EQ(results.size(), kNumPartitions);\n   LiteralTestUtil::ExpectR1Equal<float>({4., 4.}, results[0]);\n   LiteralTestUtil::ExpectR1Equal<float>({8., 8.}, results[1]);\n@@ -2591,11 +2710,11 @@ ENTRY entry {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto module, ParseAndReturnVerifiedModule(kModuleReplicatedStr, config));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto executable,\n-                          CreateExecutable(std::move(module),\n-                                           /*run_hlo_passes=*/true));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n   HloInstruction* all_gather =\n       FindInstruction(hlo_module, HloOpcode::kAllGatherStart);\n \n@@ -2616,9 +2735,9 @@ ENTRY entry {\n )\";\n \n   const int64_t kNumReplicas = 1;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n   const int64_t kNumPartitions = 4;\n \n@@ -2633,12 +2752,12 @@ ENTRY entry {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto module, ParseAndReturnVerifiedModule(kModuleReplicatedStr, config));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto executable,\n-                          CreateExecutable(std::move(module),\n-                                           /*run_hlo_passes=*/true));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/true));\n \n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const hlo_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n   EXPECT_NE(hlo_module, nullptr);\n }\n \n@@ -2929,9 +3048,9 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs) {\n \n   const int64_t kNumReplicas = 2;\n   const int64_t kNumPartitions = 1;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -2947,10 +3066,10 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -2973,9 +3092,9 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_InputBufferLargerThanOutput) {\n \n   const int64_t kNumReplicas = 2;\n   const int64_t kNumPartitions = 1;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -2991,10 +3110,10 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_InputBufferLargerThanOutput) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -3017,9 +3136,9 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_OutputBufferLargerThanInput) {\n \n   const int64_t kNumReplicas = 2;\n   const int64_t kNumPartitions = 1;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3035,10 +3154,10 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_OutputBufferLargerThanInput) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -3061,9 +3180,9 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_MultipleUpdates) {\n \n   const int64_t kNumReplicas = 2;\n   const int64_t kNumPartitions = 1;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3079,10 +3198,10 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_MultipleUpdates) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -3106,9 +3225,9 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_MultiDimData) {\n \n   const int64_t kNumReplicas = 2;\n   const int64_t kNumPartitions = 1;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3124,10 +3243,10 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_MultiDimData) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n@@ -3151,9 +3270,9 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_Degenerate) {\n \n   const int64_t kNumReplicas = 2;\n   const int64_t kNumPartitions = 1;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3169,10 +3288,10 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_Degenerate) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -3196,9 +3315,9 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_NonDefaultLayout) {\n \n   const int64_t kNumReplicas = 2;\n   const int64_t kNumPartitions = 1;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3218,10 +3337,10 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_NonDefaultLayout) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n@@ -3246,9 +3365,9 @@ TEST_P(RaggedAllToAllTest,\n \n   const int64_t kNumReplicas = 2;\n   const int64_t kNumPartitions = 1;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3264,10 +3383,10 @@ TEST_P(RaggedAllToAllTest,\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -3292,9 +3411,9 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_8GPUs) {\n   const int64_t kNumReplicas = 8;\n   const int64_t kNumPartitions = 1;\n   const int64_t kNumUpdatesPerReplica = 4;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3312,10 +3431,10 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_8GPUs) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   for (int i = 0; i < kNumReplicas; ++i) {\n@@ -3343,9 +3462,9 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_8GPUs_2ReplicasPerGroups) {\n   const int64_t kNumReplicasPerGroup = 2;\n   const int64_t kNumPartitions = 1;\n   const int64_t kNumUpdatesPerReplica = 16;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3363,10 +3482,10 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_8GPUs_2ReplicasPerGroups) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   for (int i = 0; i < kNumReplicas; ++i) {\n@@ -3394,9 +3513,9 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_8GPUs_4ReplicasPerGroups) {\n   const int64_t kNumReplicasPerGroup = 4;\n   const int64_t kNumPartitions = 1;\n   const int64_t kNumUpdatesPerReplica = 8;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3414,10 +3533,10 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_8GPUs_4ReplicasPerGroups) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   for (int i = 0; i < kNumReplicas; ++i) {\n@@ -3491,9 +3610,9 @@ TEST_F(RaggedAllToAllMultiHostDecomposerTest, RaggedAllToAll_2GPUs_SliceSize1) {\n   const int64_t kNumReplicas = 2;\n   const int64_t kNumPartitions = 1;\n   const int64_t kNumUpdatesPerReplica = 16;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3514,10 +3633,10 @@ TEST_F(RaggedAllToAllMultiHostDecomposerTest, RaggedAllToAll_2GPUs_SliceSize1) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   for (int i = 0; i < kNumReplicas; ++i) {\n@@ -3544,9 +3663,9 @@ TEST_F(RaggedAllToAllMultiHostDecomposerTest, RaggedAllToAll_8GPUs_SliceSize4) {\n   const int64_t kNumReplicas = 8;\n   const int64_t kNumPartitions = 1;\n   const int64_t kNumUpdatesPerReplica = 4;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3567,10 +3686,10 @@ TEST_F(RaggedAllToAllMultiHostDecomposerTest, RaggedAllToAll_8GPUs_SliceSize4) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   for (int i = 0; i < kNumReplicas; ++i) {\n@@ -3644,9 +3763,9 @@ ENTRY main.49 {\n \n   const int64_t kNumReplicas = 1;\n   const int64_t kNumPartitions = 4;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3670,9 +3789,8 @@ ENTRY main.49 {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(\n-          std::move(module), fake_ptrs, kNumPartitions, &assn,\n-          /*run_hlo_passes=*/true, /*use-threads=*/true));\n+      ExecuteReplicated(std::move(module), fake_ptrs, kNumPartitions, &assn,\n+                        /*run_hlo_passes=*/true, /*use_threads=*/true));\n   ASSERT_EQ(results.size(), kNumPartitions);\n \n   HloModuleConfig ref_config =\n@@ -3690,9 +3808,9 @@ ENTRY main.49 {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> ref_results,\n-      HloTestBase::ExecuteReplicated(\n-          std::move(ref_module), ref_fake_ptrs, kNumPartitions, &assn,\n-          /*run_hlo_passes=*/true, /*use-threads=*/true));\n+      ExecuteReplicated(std::move(ref_module), ref_fake_ptrs, kNumPartitions,\n+                        &assn,\n+                        /*run_hlo_passes=*/true, /*use_threads=*/true));\n   ASSERT_EQ(ref_results.size(), kNumPartitions);\n   ErrorSpec error_spec{1e-5, 1e-5};\n   // Expect same results with and without pipelining of collectives.\n@@ -3729,9 +3847,9 @@ ENTRY main {\n \n   const int64_t kNumReplicas = 1;\n   const int64_t kNumPartitions = 4;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3770,16 +3888,15 @@ ENTRY main {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(\n-          std::move(module), fake_ptrs, kNumPartitions, &assn,\n-          /*run_hlo_passes=*/true, /*use-threads=*/true));\n+      ExecuteReplicated(std::move(module), fake_ptrs, kNumPartitions, &assn,\n+                        /*run_hlo_passes=*/true, /*use_threads=*/true));\n   ASSERT_EQ(results.size(), kNumPartitions);\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> ref_results,\n-      HloTestBase::ExecuteReplicated(\n-          std::move(ref_module), ref_fake_ptrs, kNumPartitions, &assn,\n-          /*run_hlo_passes=*/true, /*use-threads=*/true));\n+      ExecuteReplicated(std::move(ref_module), ref_fake_ptrs, kNumPartitions,\n+                        &assn,\n+                        /*run_hlo_passes=*/true, /*use_threads=*/true));\n   ASSERT_EQ(ref_results.size(), kNumPartitions);\n   ErrorSpec error_spec{1e-5, 1e-5};\n   // Expect same results with and without pipelining of collectives.\n@@ -3806,9 +3923,9 @@ ENTRY main {\n \n   const int64_t kNumReplicas = 1;\n   const int64_t kNumPartitions = 4;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3822,10 +3939,10 @@ ENTRY main {\n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n                           ParseAndReturnVerifiedModule(hlo_string, config));\n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto executable,\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/false));\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/false));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const executable_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n   HloInstruction* ag_start =\n       FindInstructions(executable_module, HloOpcode::kAllGatherStart)[0];\n   // Both ag and its producer should have collective memory space 1\n@@ -3855,9 +3972,9 @@ ROOT tuple = (bf16[1024,1024]{1,0}, bf16[]) tuple(all-reduce-done, all-reduce-do\n \n   const int64_t kNumReplicas = 1;\n   const int64_t kNumPartitions = 4;\n-  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n-                 << \" devices (\" << test_runner().device_count()\n+                 << \" devices (\" << hlo_runner_->device_count()\n                  << \" available)\";\n   }\n \n@@ -3871,10 +3988,10 @@ ROOT tuple = (bf16[1024,1024]{1,0}, bf16[]) tuple(all-reduce-done, all-reduce-do\n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n                           ParseAndReturnVerifiedModule(hlo_string, config));\n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto executable,\n-      CreateExecutable(std::move(module), /*run_hlo_passes=*/false));\n+      auto executable, hlo_runner_->CreateExecutable(std::move(module),\n+                                                     /*run_hlo_passes=*/false));\n   TF_ASSERT_OK_AND_ASSIGN(const HloModule* const executable_module,\n-                          test_runner().HloModuleFromWrapped(executable.get()));\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n   std::vector<HloInstruction*> all_ar =\n       FindInstructions(executable_module, HloOpcode::kAllReduceStart);\n   // Both allreduces should have their operands copied to collective memory\n@@ -3985,9 +4102,9 @@ TEST_P(AllReduceTest, AsyncAllReduce_F32_2GPUs) {\n   )\";\n \n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -4014,11 +4131,11 @@ TEST_P(AllReduceTest, AsyncAllReduce_F32_2GPUs) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module),\n-                                     {{&input_literal1}, {&input_literal2}},\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module),\n+                        {{&input_literal1}, {&input_literal2}},\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_output_literal, results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_output_literal, results[1]));\n@@ -4066,9 +4183,9 @@ TEST_P(AllReduceTest, AsyncAllReduceInsideWhile_F32_2GPUs) {\n       kNumIterations, kNumElements, kReplicaGroups);\n \n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -4096,11 +4213,11 @@ TEST_P(AllReduceTest, AsyncAllReduceInsideWhile_F32_2GPUs) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module),\n-                                     {{&input_literal1}, {&input_literal2}},\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module),\n+                        {{&input_literal1}, {&input_literal2}},\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_output_literal, results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_output_literal, results[1]));\n@@ -4123,9 +4240,9 @@ TEST_P(AllReduceTest, AsyncAllReduce_BF16_2GPUs) {\n   )\";\n \n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -4152,11 +4269,11 @@ TEST_P(AllReduceTest, AsyncAllReduce_BF16_2GPUs) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module),\n-                                     {{&input_literal1}, {&input_literal2}},\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module),\n+                        {{&input_literal1}, {&input_literal2}},\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_output_literal, results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_output_literal, results[1]));\n@@ -4179,9 +4296,9 @@ TEST_P(AllReduceTest, AsyncAllReduce_PRED_2GPUs) {\n   )\";\n \n   const int64_t kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -4208,11 +4325,11 @@ TEST_P(AllReduceTest, AsyncAllReduce_PRED_2GPUs) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module),\n-                                     {{&input_literal1}, {&input_literal2}},\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module),\n+                        {{&input_literal1}, {&input_literal2}},\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_output_literal, results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_output_literal, results[1]));\n@@ -4236,9 +4353,9 @@ TEST_P(AllReduceTest, AsyncAllReduce_8GPUs_AllReplicasOneGroup) {\n   )\";\n \n   const int64_t kNumReplicas = 8;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -4252,11 +4369,11 @@ TEST_P(AllReduceTest, AsyncAllReduce_8GPUs_AllReplicasOneGroup) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module),\n-                                     /*arguments=*/test_io.InputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module),\n+                        /*arguments=*/test_io.InputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   for (int i = 0; i < kNumReplicas; ++i) {\n     // NB: nccl accumulation order can be different from expected calculations\n@@ -4308,9 +4425,9 @@ TEST_P(AllReduceTest, AsyncAllReduce_8GPUs_2ReplicasPerGroup) {\n       kNumIterations, kNumElements);\n \n   const int64_t kNumReplicas = 8;\n-  if (test_runner().device_count() < kNumReplicas) {\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n     GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n-                 << test_runner().device_count() << \" available)\";\n+                 << hlo_runner_->device_count() << \" available)\";\n   }\n \n   HloModuleConfig config =\n@@ -4325,11 +4442,11 @@ TEST_P(AllReduceTest, AsyncAllReduce_8GPUs_2ReplicasPerGroup) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> results,\n-      HloTestBase::ExecuteReplicated(std::move(module),\n-                                     /*arguments=*/test_io.InputLiteralPtrs(),\n-                                     /*num_replicas=*/kNumReplicas,\n-                                     /*run_hlo_passes=*/true,\n-                                     /*device_assignment=*/nullptr));\n+      ExecuteReplicated(std::move(module),\n+                        /*arguments=*/test_io.InputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n   ASSERT_EQ(results.size(), kNumReplicas);\n   for (int i = 0; i < kNumReplicas; ++i) {\n     ASSERT_TRUE(LiteralTestUtil::Equal(test_io.expected_outputs[i], results[i]))"
        }
    ],
    "stats": {
        "total": 804,
        "additions": 466,
        "deletions": 338
    }
}