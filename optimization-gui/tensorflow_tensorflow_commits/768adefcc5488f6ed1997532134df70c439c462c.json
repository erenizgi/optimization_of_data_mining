{
    "author": "tensorflower-gardener",
    "message": "[Autotuner] Make buffer checking best effort, rather than forcing it.\n\n- There are cases in gemm_fusion_autotuner where we don't have a reference output from cuBLAS and we skip the requested correctness check. Hence updating the code in new infra to match current state.\n\nPiperOrigin-RevId: 833337857",
    "sha": "768adefcc5488f6ed1997532134df70c439c462c",
    "files": [
        {
            "sha": "2c2dcb14750ef75203252ea13520b636ccb08b9b",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/768adefcc5488f6ed1997532134df70c439c462c/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/768adefcc5488f6ed1997532134df70c439c462c/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc?ref=768adefcc5488f6ed1997532134df70c439c462c",
            "patch": "@@ -458,8 +458,11 @@ absl::StatusOr<std::vector<Autotuner::ConfigResult>> Autotuner::ProfileAll(\n \n   std::optional<ScopedShapedBuffer> reference_output;\n   if (autotune_config_.check_buffers) {\n-    TF_ASSIGN_OR_RETURN(reference_output,\n-                        GetReferenceOutput(candidates, *input_buffers));\n+    reference_output = GetReferenceOutput(candidates, *input_buffers);\n+    if (!reference_output.has_value()) {\n+      LOG(WARNING) << \"No reference output found even though buffer checking \"\n+                      \"was requested while autotuning\";\n+    }\n   }\n \n   for (int i = 0; i < candidates.size(); ++i) {\n@@ -475,8 +478,7 @@ absl::StatusOr<std::vector<Autotuner::ConfigResult>> Autotuner::ProfileAll(\n     } else {\n       duration = profile_result->duration;\n       scratch_bytes = profile_result->scratch_bytes;\n-      if (autotune_config_.check_buffers) {\n-        CHECK(reference_output.has_value());\n+      if (autotune_config_.check_buffers && reference_output.has_value()) {\n         CHECK(profile_result->output_buffer.has_value());\n         failure =\n             CheckBuffers(*input_buffers, profile_result->output_buffer.value(),\n@@ -558,7 +560,7 @@ absl::Status Autotuner::DumpHlo(HloInstruction* instr, const Config& config) {\n   return absl::OkStatus();\n }\n \n-absl::StatusOr<ScopedShapedBuffer> Autotuner::GetReferenceOutput(\n+std::optional<ScopedShapedBuffer> Autotuner::GetReferenceOutput(\n     std::vector<ExecutableCandidate>& candidates, InputBuffers& input_buffers) {\n   for (auto& candidate : candidates) {\n     if (candidate.config.codegen_backend->CanProduceWrongResults()) {\n@@ -574,8 +576,7 @@ absl::StatusOr<ScopedShapedBuffer> Autotuner::GetReferenceOutput(\n       return std::move(profile_result.value().output_buffer.value());\n     }\n   }\n-  return absl::NotFoundError(\n-      \"No reference output found but correctness checking is enabled!\");\n+  return std::nullopt;\n }\n \n std::optional<Autotuner::Failure> Autotuner::CheckBuffers("
        },
        {
            "sha": "eb15e516070b22344ad8f89b9f91e143acd921db",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/768adefcc5488f6ed1997532134df70c439c462c/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/768adefcc5488f6ed1997532134df70c439c462c/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h?ref=768adefcc5488f6ed1997532134df70c439c462c",
            "patch": "@@ -46,6 +46,8 @@ namespace xla {\n struct AutotuneConfig {\n   // Whether to check the correctness of the output buffers and OOM reads on\n   // Input Buffers.\n+  // Correctness check is only performed when a trustable reference output is\n+  // available.\n   bool check_buffers = true;\n   // Relative tolerance for correctness check.\n   float relative_tolerance = 1e-6;\n@@ -197,7 +199,7 @@ class Autotuner {\n   absl::StatusOr<ConfigResult> PickBestConfig(\n       std::vector<ConfigResult>& results);\n \n-  absl::StatusOr<ScopedShapedBuffer> GetReferenceOutput(\n+  std::optional<ScopedShapedBuffer> GetReferenceOutput(\n       std::vector<ExecutableCandidate>& candidates,\n       InputBuffers& input_buffers);\n "
        },
        {
            "sha": "1fc74269cead16684a267c2bc1951ec7fcd7b7ff",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner_test.cc",
            "status": "modified",
            "additions": 38,
            "deletions": 1,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/768adefcc5488f6ed1997532134df70c439c462c/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/768adefcc5488f6ed1997532134df70c439c462c/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc?ref=768adefcc5488f6ed1997532134df70c439c462c",
            "patch": "@@ -467,7 +467,7 @@ TEST_F(AutotunerTest, CacheHit) {\n   EXPECT_THAT(autotuner->Autotune(dummy_instr.get()), IsOk());\n }\n \n-TEST_F(AutotunerTest, AutotuneWithBufferCheck) {\n+TEST_F(AutotunerTest, AutotuneWithBufferCheckFiltersWrongResults) {\n   config_.check_buffers = true;\n \n   std::vector<std::unique_ptr<BackendConfig>> configs_1;\n@@ -514,6 +514,43 @@ TEST_F(AutotunerTest, AutotuneWithBufferCheck) {\n   EXPECT_THAT(autotuner->Autotune(dummy_instr.get()), IsOk());\n }\n \n+TEST_F(AutotunerTest, AutotuneSkipsBufferCheckWhenNoReferenceOutput) {\n+  config_.check_buffers = true;\n+\n+  std::vector<std::unique_ptr<BackendConfig>> configs;\n+  configs.push_back(GetTestConfig(\"test_config_1\"));\n+  configs.push_back(GetTestConfig(\"test_config_2\"));\n+  auto backend = std::make_unique<MockCodegenBackendWithWrongResults>();\n+  EXPECT_CALL(*backend, GetSupportedConfigs)\n+      .WillOnce(Return(std::move(configs)));\n+  EXPECT_CALL(*backend, Compile(_, _))\n+      .WillOnce(Return(std::unique_ptr<Executable>()))\n+      .WillOnce(Return(std::unique_ptr<Executable>()));\n+\n+  EXPECT_CALL(*backend, ApplyConfig(_, ConfigMatcher(\"test_config_1\")))\n+      .Times(1)\n+      .WillRepeatedly(Return(absl::OkStatus()));\n+\n+  auto profiler = std::make_unique<MockProfiler>();\n+  ScopedShapedBuffer output_1(Shape(), nullptr, 0),\n+      output_2(Shape(), nullptr, 0), output_3(Shape(), nullptr, 0);\n+  EXPECT_CALL(*profiler, CreateInputBuffers(_))\n+      .WillOnce(Return(std::make_unique<InputBuffers>()));\n+  EXPECT_CALL(*profiler, Profile(_, _))\n+      .WillOnce(Return(ProfileResult({absl::Seconds(1), std::move(output_1)})))\n+      .WillOnce(Return(ProfileResult({absl::Seconds(2), std::nullopt})));\n+  EXPECT_CALL(*profiler, CheckOutputBuffer(_, _, _)).Times(0);\n+\n+  std::vector<std::unique_ptr<CodegenBackend>> backends;\n+  backends.push_back(std::move(backend));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto autotuner,\n+      Autotuner::Create(std::move(backends), std::move(profiler), config_,\n+                        std::make_unique<MockAutotunerCache>()));\n+  auto dummy_instr = HloInstruction::CreateConstant(LiteralUtil::CreateR0(1));\n+  EXPECT_THAT(autotuner->Autotune(dummy_instr.get()), IsOk());\n+}\n+\n TEST_F(AutotunerTest, AutotuneWithScratchBytesOptimization) {\n   std::vector<std::unique_ptr<BackendConfig>> configs;\n   configs.push_back(GetTestConfig(\"config_most_time_less_scratch\"));"
        }
    ],
    "stats": {
        "total": 58,
        "additions": 49,
        "deletions": 9
    }
}