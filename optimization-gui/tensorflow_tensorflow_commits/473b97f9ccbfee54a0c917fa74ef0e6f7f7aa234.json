{
    "author": "pschuh",
    "message": "Implement AllocateDestinationBuffer in terms of raw buffer APIs.\n\nPiperOrigin-RevId: 796999391",
    "sha": "473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234",
    "files": [
        {
            "sha": "b7eb8f77d724e9b7b6cc3c4fb93dffd61f73c5c1",
            "filename": "third_party/xla/xla/pjrt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD?ref=473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234",
            "patch": "@@ -602,6 +602,7 @@ cc_library(\n     deps = [\n         \":abstract_tracked_device_buffer\",\n         \":common_pjrt_client\",\n+        \":device_event\",\n         \":event_pool\",\n         \":host_callback\",\n         \":host_memory_spaces\","
        },
        {
            "sha": "4f98a91cc9bfbae7938f1b5fc5584faacd46f2ed",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 54,
            "changes": 54,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234",
            "patch": "@@ -936,60 +936,6 @@ PjRtFuture<> StreamExecutorGpuClient::CopyRawSubBufferToHost(\n       });\n }\n \n-tsl::RCReference<PjRtDeviceEvent> StreamExecutorGpuClient::CopyRawHostToDevice(\n-    LocalDeviceState* local_device,\n-    tsl::RCReference<RawSEDeviceMemory> device_buffer, const void* src,\n-    int64_t offset, int64_t transfer_size) {\n-  auto promise = PjRtFuture<>::CreatePromise();\n-  se::Stream* stream = local_device->host_to_device_stream();\n-  auto device_event = BufferSequencingEvent::Create(thread_pool());\n-  thread_pool()->Schedule([this, device_event, local_device, stream,\n-                           buffer = std::move(device_buffer), src, offset,\n-                           transfer_size, promise]() mutable {\n-    se::DeviceMemoryBase sub_buffer = buffer->mem();\n-    if (transfer_size < sub_buffer.size()) {\n-      sub_buffer = sub_buffer.GetByteSlice(offset, transfer_size);\n-    }\n-    auto status = stream->Memcpy(&sub_buffer, src, transfer_size);\n-    if (status.ok()) {\n-      status = AllocateAndRecordEvent(device_event, local_device, stream);\n-    }\n-    if (!status.ok()) {\n-      SetEventAsError(device_event, status);\n-    }\n-  });\n-  return tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(std::move(device_event),\n-                                                     \"StreamExecutorGpuClient\",\n-                                                     \"CopyRawHostToDevice\");\n-}\n-\n-tsl::RCReference<PjRtDeviceEvent> StreamExecutorGpuClient::CopyRawDeviceToHost(\n-    LocalDeviceState* local_device,\n-    tsl::RCReference<RawSEDeviceMemory> device_buffer, void* dst,\n-    int64_t offset, int64_t transfer_size) {\n-  auto promise = PjRtFuture<>::CreatePromise();\n-  se::Stream* stream = local_device->GetDeviceToHostStream();\n-  auto device_event = BufferSequencingEvent::Create(thread_pool());\n-  thread_pool()->Schedule([this, device_event, local_device, stream,\n-                           buffer = std::move(device_buffer), dst, offset,\n-                           transfer_size, promise]() mutable {\n-    se::DeviceMemoryBase sub_buffer = buffer->mem();\n-    if (transfer_size < sub_buffer.size()) {\n-      sub_buffer = sub_buffer.GetByteSlice(offset, transfer_size);\n-    }\n-    auto status = stream->Memcpy(dst, sub_buffer, transfer_size);\n-    if (status.ok()) {\n-      status = AllocateAndRecordEvent(device_event, local_device, stream);\n-    }\n-    if (!status.ok()) {\n-      SetEventAsError(device_event, status);\n-    }\n-  });\n-  return tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(std::move(device_event),\n-                                                     \"StreamExecutorGpuClient\",\n-                                                     \"CopyRawDeviceToHost\");\n-}\n-\n absl::Status StreamExecutorGpuClient::UpdateCompileOptionsInternal(\n     CompileOptions* options, ExecutableExtras* returned_extras,\n     bool lookup_addressable_devices) {"
        },
        {
            "sha": "c840b5a687966b8cefb0b79d30bff4dfa68488e1",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h",
            "status": "modified",
            "additions": 0,
            "deletions": 10,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h?ref=473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234",
            "patch": "@@ -144,16 +144,6 @@ class StreamExecutorGpuClient : public xla::PjRtStreamExecutorClient {\n                                       int64_t offset,\n                                       int64_t transfer_size) override;\n \n-  tsl::RCReference<PjRtDeviceEvent> CopyRawHostToDevice(\n-      LocalDeviceState* local_device,\n-      tsl::RCReference<RawSEDeviceMemory> device_buffer, const void* src,\n-      int64_t offset, int64_t transfer_size) override;\n-\n-  tsl::RCReference<PjRtDeviceEvent> CopyRawDeviceToHost(\n-      LocalDeviceState* local_device,\n-      tsl::RCReference<RawSEDeviceMemory> device_buffer, void* dst,\n-      int64_t offset, int64_t transfer_size) override;\n-\n   void CopyToRemoteDevice(PjRtBuffer* buffer,\n                           absl::string_view serialized_descriptor,\n                           PjRtBuffer::RemoteSendCallback on_done) override;"
        },
        {
            "sha": "6472bc483b2d5cbd487790f093c61a467f68efb5",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 144,
            "deletions": 71,
            "changes": 215,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234",
            "patch": "@@ -107,6 +107,7 @@ limitations under the License.\n #include \"xla/layout_util.h\"\n #include \"xla/literal.h\"\n #include \"xla/pjrt/abstract_tracked_device_buffer.h\"\n+#include \"xla/pjrt/device_event.h\"\n #include \"xla/pjrt/distributed/protocol.pb.h\"\n #include \"xla/pjrt/event_pool.h\"\n #include \"xla/pjrt/host_callback.h\"\n@@ -122,6 +123,7 @@ limitations under the License.\n #include \"xla/pjrt/pjrt_future.h\"\n #include \"xla/pjrt/profiling/device_time_measurement.h\"\n #include \"xla/pjrt/profiling/profiling_context.h\"\n+#include \"xla/pjrt/raw_buffer.h\"\n #include \"xla/pjrt/se_raw_buffer.h\"\n #include \"xla/pjrt/semaphore.h\"\n #include \"xla/pjrt/stream_executor_executable.h\"\n@@ -483,6 +485,116 @@ absl::StatusOr<int64_t> PjRtStreamExecutorClient::GetOnDeviceBytesCount(\n   return client()->backend().transfer_manager()->GetByteSizeRequirement(shape);\n }\n \n+absl::StatusOr<xla::Shape>\n+PjRtStreamExecutorClient::MakeDefaultShapeForMemorySpace(\n+    PjRtMemorySpace* memory_space, xla::Shape shape,\n+    const xla::Layout* layout) const {\n+  TransferManager* transfer_manager = client()->backend().transfer_manager();\n+  if (layout != nullptr) {\n+    *(shape.mutable_layout()) = *layout;\n+  } else {\n+    TF_ASSIGN_OR_RETURN(shape,\n+                        transfer_manager->ChooseCompactLayoutForShape(shape));\n+  }\n+  auto* device = tensorflow::down_cast<PjRtStreamExecutorDevice*>(\n+      memory_space->devices()[0]);\n+  PjRtMemorySpace* default_memory_space =\n+      device->default_memory_space().value_or(nullptr);\n+  Shape on_device_shape = transfer_manager->HostShapeToDeviceShape(shape);\n+  // Only allow pinned host memory or device memory.\n+  if (memory_space->kind() == PinnedHostMemorySpace::kKind) {\n+    on_device_shape.mutable_layout()->set_memory_space(\n+        Layout::kHostMemorySpace);\n+  } else if (memory_space == default_memory_space) {\n+    if (on_device_shape.has_layout()) {\n+      on_device_shape.mutable_layout()->set_memory_space(\n+          Layout::kDefaultMemorySpace);\n+    }\n+  } else {\n+    return absl::InvalidArgumentError(\n+        absl::StrCat(\"Buffer allocation: invalid memory space: \",\n+                     memory_space->DebugString()));\n+  }\n+  return on_device_shape;\n+}\n+\n+absl::StatusOr<tsl::RCReference<CommonPjRtRawBuffer>>\n+PjRtStreamExecutorClient::AllocateRawBuffer(\n+    PjRtMemorySpace* memory_space, size_t on_device_bytes_count,\n+    bool retry_on_oom, tsl::AsyncValueRef<bool> allocate_after) {\n+  CHECK(allocate_after == nullptr)\n+      << \"allocate_after is not supported for PjRtStreamExecutorClient.\";\n+  auto* device = tensorflow::down_cast<PjRtStreamExecutorDevice*>(\n+      memory_space->devices()[0]);\n+  TF_ASSIGN_OR_RETURN(LocalDeviceState * local_device,\n+                      device->GetLocalDeviceState());\n+  PjRtMemorySpace* default_memory_space =\n+      device->default_memory_space().value_or(nullptr);\n+  auto layout_memory_space = Layout::kDefaultMemorySpace;\n+  if (memory_space->kind() == PinnedHostMemorySpace::kKind) {\n+    layout_memory_space = Layout::kHostMemorySpace;\n+  } else if (memory_space != default_memory_space) {\n+    return absl::InvalidArgumentError(\n+        absl::StrCat(\"Buffer allocation: invalid memory space: \",\n+                     memory_space->DebugString()));\n+  }\n+  TF_ASSIGN_OR_RETURN(\n+      auto buffer,\n+      allocator()->Allocate(local_device->local_device_id().value(),\n+                            on_device_bytes_count, true, layout_memory_space));\n+  auto mem = RawSEDeviceMemory::Create(buffer.Release(),\n+                                       device->local_device_id(), allocator());\n+  if (local_device->allocation_model() !=\n+      LocalDeviceState::kComputeSynchronized) {\n+    DCHECK(client()->backend().transfer_manager()->CanBufferBeAccessedNow(\n+        local_device->compute_stream()->parent(), mem->mem()));\n+  }\n+  return tsl::MakeRef<PjRtStreamExecutorRawBuffer>(\n+      this, memory_space, local_device, std::move(mem));\n+}\n+\n+absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n+PjRtStreamExecutorClient::DefineBuffer(\n+    const Shape& on_device_shape,\n+    tsl::RCReference<CommonPjRtRawBuffer> raw_buffer,\n+    absl::InlinedVector<tsl::RCReference<PjRtDeviceEvent>, 4>\n+        definition_device_events,\n+    bool raw_buffer_is_mutable) {\n+  absl::InlinedVector<BufferSequencingEventRef, 2> definition_events;\n+  definition_events.reserve(definition_device_events.size());\n+  for (auto& ev : definition_device_events) {\n+    definition_events.push_back(\n+        tensorflow::down_cast<PjRtStreamExecutorDeviceEvent*>(ev.get())\n+            ->event());\n+  }\n+  auto* memory_space = raw_buffer->memory_space();\n+  auto* device = tensorflow::down_cast<PjRtStreamExecutorDevice*>(\n+      memory_space->devices()[0]);\n+\n+  auto dst_device_buffer = std::make_unique<TrackedDeviceBuffer>(\n+      device,\n+      tensorflow::down_cast<PjRtStreamExecutorRawBuffer*>(raw_buffer.get())\n+          ->device_buffer(),\n+      definition_events);\n+\n+  auto py_buffer = std::make_unique<PjRtStreamExecutorBuffer>(\n+      on_device_shape, std::move(dst_device_buffer), this, device,\n+      memory_space);\n+  return py_buffer;\n+}\n+\n+void PjRtStreamExecutorClient::WaitForAllocation(\n+    se::Stream* stream, const CommonPjRtRawBuffer& raw_buffer) {\n+  auto* local_device =\n+      tensorflow::down_cast<const PjRtStreamExecutorRawBuffer*>(&raw_buffer)\n+          ->local_device();\n+  if (local_device->allocation_model() ==\n+      LocalDeviceState::kComputeSynchronized) {\n+    CHECK(stream);\n+    CHECK_OK(stream->WaitFor(local_device->compute_stream()));\n+  }\n+}\n+\n absl::StatusOr<std::unique_ptr<PjRtStreamExecutorBuffer>>\n AllocateDestinationBuffer(const Shape& on_host_shape, PjRtDevice* device,\n                           LocalDeviceState* local_device,\n@@ -495,95 +607,56 @@ AllocateDestinationBuffer(const Shape& on_host_shape, PjRtDevice* device,\n         \"Cannot allocate a PjRtStreamExecutorBuffer for a tuple.\");\n   }\n \n-  PjRtMemorySpace* default_memory_space =\n-      device->default_memory_space().value_or(nullptr);\n   if (!memory_space) {\n-    memory_space = default_memory_space;\n-  }\n-  bool is_pinned_host_memory =\n-      memory_space && (memory_space->kind() == PinnedHostMemorySpace::kKind);\n-  // Only allow pinned host memory or device memory.\n-  if (memory_space != default_memory_space && !is_pinned_host_memory) {\n-    return InvalidArgument(\"Buffer allocation: invalid memory space\");\n+    memory_space = device->default_memory_space().value_or(nullptr);\n   }\n \n-  auto* se_client = tensorflow::down_cast<PjRtStreamExecutorClient*>(client);\n-  TransferManager* transfer_manager =\n-      se_client->client()->backend().transfer_manager();\n-\n-  // Communicate the desired memory space to the allocator via the shape\n-  // callback.\n-  auto memory_space_shape_fn = [is_pinned_host_memory,\n-                                transfer_manager](const Shape& shape) {\n-    Shape result = transfer_manager->HostShapeToDeviceShape(shape);\n-    if (is_pinned_host_memory) {\n-      result.mutable_layout()->set_memory_space(Layout::kHostMemorySpace);\n-    }\n-    return result;\n-  };\n-\n   TF_ASSIGN_OR_RETURN(\n-      ScopedShapedBuffer dst_buffer,\n-      transfer_manager->AllocateScopedShapedBuffer(\n-          on_host_shape, se_client->allocator(),\n-          local_device->local_device_id().value(),\n-          local_device->local_hardware_id().value(), memory_space_shape_fn));\n-  if (local_device->allocation_model() ==\n-      LocalDeviceState::kComputeSynchronized) {\n-    if (copy_stream == nullptr) {\n-      CHECK(is_uninitialized_create);\n-    } else {\n-      CHECK(copy_stream->WaitFor(local_device->compute_stream()).ok());\n-    }\n-  } else {\n-    DCHECK(transfer_manager->CanShapedBufferBeAccessedNow(\n-        local_device->compute_stream()->parent(), dst_buffer));\n-  }\n-  Shape on_device_shape = dst_buffer.on_device_shape();\n+      Shape on_device_shape,\n+      client->MakeDefaultShapeForMemorySpace(\n+          memory_space, on_host_shape,\n+          on_host_shape.has_layout() ? &on_host_shape.layout() : nullptr));\n+  TF_ASSIGN_OR_RETURN(\n+      size_t on_device_bytes_count,\n+      client->GetOnDeviceBytesCount(memory_space, on_device_shape));\n+  TF_ASSIGN_OR_RETURN(\n+      tsl::RCReference<CommonPjRtRawBuffer> raw_buffer,\n+      client->AllocateRawBuffer(memory_space, on_device_bytes_count,\n+                                /*retry_on_oom=*/true,\n+                                /*allocate_after=*/{}));\n \n-  absl::InlinedVector<BufferSequencingEventRef, 2> definition_events;\n+  absl::InlinedVector<tsl::RCReference<PjRtDeviceEvent>, 4> definition_events;\n+  // Record the caller's definition event.\n+  if (definition_event) {\n+    definition_events.push_back(tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(\n+        std::move(definition_event)));\n+  }\n   if (is_uninitialized_create) {\n     // There is not going to be any copy into the buffer so in general we don't\n     // need a definition event.\n     // But if the caller provided a definition event then we record that. Also\n     // put it as the first definition event so that we can guarantee only the\n     // first one might not have event recorded.\n-    if (definition_event) {\n-      definition_events.push_back(definition_event);\n-    }\n     if (local_device->allocation_model() ==\n         LocalDeviceState::kComputeSynchronized) {\n-      // The allocation is not valid until the compute stream passes this point,\n-      // so add a definition event in the compute stream.\n-      definition_events.emplace_back(\n-          BufferSequencingEvent::Create(client->thread_pool()));\n-      TF_RETURN_IF_ERROR(\n-          client->AllocateAndRecordEvent(definition_events.back(), local_device,\n-                                         local_device->compute_stream()));\n+      TF_ASSIGN_OR_RETURN(auto allocation_ready_event,\n+                          raw_buffer->MakeAllocationReadyEvent());\n+      definition_events.push_back(std::move(allocation_ready_event));\n     }\n   } else {\n-    // We have at least one definition event, for the copy completing to\n-    // the device buffers.\n-    if (definition_event) {\n-      definition_events.push_back(definition_event);\n-    } else {\n+    client->WaitForAllocation(copy_stream, *raw_buffer);\n+    // Callers expect at least one event.\n+    if (definition_events.empty()) {\n       definition_events.emplace_back(\n-          BufferSequencingEvent::Create(client->thread_pool()));\n+          tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(\n+              BufferSequencingEvent::Create(client->thread_pool())));\n     }\n   }\n-\n-  auto mem = RawSEDeviceMemory::Create(dst_buffer.buffer({}),\n-                                       device->local_device_id(),\n-                                       dst_buffer.memory_allocator());\n-  dst_buffer.clear();\n-\n-  auto dst_device_buffer = std::make_unique<TrackedDeviceBuffer>(\n-      device, std::move(mem), definition_events);\n-\n-  auto py_buffer = std::make_unique<PjRtStreamExecutorBuffer>(\n-      on_device_shape, std::move(dst_device_buffer), client, device,\n-      memory_space);\n-  return py_buffer;\n+  TF_ASSIGN_OR_RETURN(\n+      auto buffer, client->DefineBuffer(on_device_shape, std::move(raw_buffer),\n+                                        std::move(definition_events), true));\n+  return std::unique_ptr<PjRtStreamExecutorBuffer>(\n+      tensorflow::down_cast<PjRtStreamExecutorBuffer*>(buffer.release()));\n }\n \n void PjRtStreamExecutorBuffer::ScopedHold::ConvertUsageHold("
        },
        {
            "sha": "513a7a563daa372c7d11bc89aefc8949c10e3698",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.h",
            "status": "modified",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h?ref=473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234",
            "patch": "@@ -405,6 +405,24 @@ class PjRtStreamExecutorClient : public CommonPjRtClient {\n   absl::StatusOr<int64_t> GetOnDeviceBytesCount(\n       PjRtMemorySpace* memory_space, const xla::Shape& shape) const override;\n \n+  absl::StatusOr<xla::Shape> MakeDefaultShapeForMemorySpace(\n+      PjRtMemorySpace* memory_space, xla::Shape shape,\n+      const xla::Layout* layout) const override;\n+\n+  absl::StatusOr<tsl::RCReference<CommonPjRtRawBuffer>> AllocateRawBuffer(\n+      PjRtMemorySpace* memory_space, size_t on_device_bytes_count,\n+      bool retry_on_oom, tsl::AsyncValueRef<bool> allocate_after) override;\n+\n+  absl::StatusOr<std::unique_ptr<PjRtBuffer>> DefineBuffer(\n+      const Shape& on_device_shape,\n+      tsl::RCReference<CommonPjRtRawBuffer> raw_buffer,\n+      absl::InlinedVector<tsl::RCReference<PjRtDeviceEvent>, 4>\n+          definition_device_events,\n+      bool raw_buffer_is_mutable) override;\n+\n+  void WaitForAllocation(se::Stream* stream,\n+                         const CommonPjRtRawBuffer& raw_buffer);\n+\n  protected:\n   friend class PjRtStreamExecutorBuffer;\n   friend class PjRtStreamExecutorRawBuffer;"
        },
        {
            "sha": "161c04443bab5c9b2e95ad5109418a118ea5e642",
            "filename": "third_party/xla/xla/pjrt/se_raw_buffer.cc",
            "status": "modified",
            "additions": 57,
            "deletions": 4,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc?ref=473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n \n #include <cstdint>\n #include <optional>\n+#include <utility>\n \n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n@@ -25,7 +26,12 @@ limitations under the License.\n #include \"xla/pjrt/pjrt_future.h\"\n #include \"xla/pjrt/pjrt_stream_executor_client.h\"\n #include \"xla/pjrt/raw_buffer.h\"\n+#include \"xla/pjrt/tracked_device_buffer.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"tsl/platform/casts.h\"\n #include \"tsl/profiler/lib/connected_traceme.h\"\n \n namespace xla {\n@@ -61,15 +67,53 @@ PjRtFuture<> PjRtStreamExecutorDeviceEvent::GetReadyFuture() {\n absl::StatusOr<tsl::RCReference<PjRtDeviceEvent>>\n PjRtStreamExecutorRawBuffer::CopyRawHostToDeviceAndReturnEvent(\n     const void* src, int64_t offset, int64_t transfer_size) {\n-  return client_->CopyRawHostToDevice(local_device_, device_buffer_, src,\n-                                      offset, transfer_size);\n+  se::Stream* stream = local_device_->host_to_device_stream();\n+  auto device_event = BufferSequencingEvent::Create(client_->thread_pool());\n+  client_->thread_pool()->Schedule(\n+      [client = client_, device_event, local_device = local_device_, stream,\n+       buffer = device_buffer_, src, offset, transfer_size]() mutable {\n+        se::DeviceMemoryBase sub_buffer = buffer->mem();\n+        if (transfer_size < sub_buffer.size()) {\n+          sub_buffer = sub_buffer.GetByteSlice(offset, transfer_size);\n+        }\n+        auto status = stream->Memcpy(&sub_buffer, src, transfer_size);\n+        if (status.ok()) {\n+          status = client->AllocateAndRecordEvent(device_event, local_device,\n+                                                  stream);\n+        }\n+        if (!status.ok()) {\n+          client->SetEventAsError(device_event, status);\n+        }\n+      });\n+  return tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(\n+      std::move(device_event), \"PjRtStreamExecutorRawBuffer\",\n+      \"CopyRawHostToDevice\");\n }\n \n absl::StatusOr<tsl::RCReference<PjRtDeviceEvent>>\n PjRtStreamExecutorRawBuffer::CopyRawDeviceToHostAndReturnEvent(\n     void* dst, int64_t offset, int64_t transfer_size) {\n-  return client_->CopyRawDeviceToHost(local_device_, device_buffer_, dst,\n-                                      offset, transfer_size);\n+  se::Stream* stream = local_device_->GetDeviceToHostStream();\n+  auto device_event = BufferSequencingEvent::Create(client_->thread_pool());\n+  client_->thread_pool()->Schedule(\n+      [client = client_, device_event, local_device = local_device_, stream,\n+       buffer = device_buffer_, dst, offset, transfer_size]() mutable {\n+        se::DeviceMemoryBase sub_buffer = buffer->mem();\n+        if (transfer_size < sub_buffer.size()) {\n+          sub_buffer = sub_buffer.GetByteSlice(offset, transfer_size);\n+        }\n+        auto status = stream->Memcpy(dst, sub_buffer, transfer_size);\n+        if (status.ok()) {\n+          status = client->AllocateAndRecordEvent(device_event, local_device,\n+                                                  stream);\n+        }\n+        if (!status.ok()) {\n+          client->SetEventAsError(device_event, status);\n+        }\n+      });\n+  return tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(\n+      std::move(device_event), \"PjRtStreamExecutorRawBuffer\",\n+      \"CopyRawDeviceToHost\");\n }\n \n ShapedBuffer PjRtStreamExecutorRawBuffer::AsShapedBuffer(\n@@ -114,6 +158,15 @@ void PjRtStreamExecutorRawBuffer::CopyToLiteralAsync(\n \n absl::StatusOr<tsl::RCReference<PjRtDeviceEvent>>\n PjRtStreamExecutorRawBuffer::MakeAllocationReadyEvent() {\n+  if (local_device_->allocation_model() ==\n+      LocalDeviceState::kComputeSynchronized) {\n+    auto* client = tensorflow::down_cast<PjRtStreamExecutorClient*>(\n+        memory_space_->client());\n+    auto result = BufferSequencingEvent::Create(client->thread_pool());\n+    TF_RETURN_IF_ERROR(client->AllocateAndRecordEvent(\n+        result, local_device_, local_device_->compute_stream()));\n+    return tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(std::move(result));\n+  }\n   return absl::UnimplementedError(\"Cannot make ready event\");\n }\n "
        },
        {
            "sha": "93dd89a1a27e0391626bdbfe8da4231caf399b8b",
            "filename": "third_party/xla/xla/pjrt/se_raw_buffer.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.h?ref=473b97f9ccbfee54a0c917fa74ef0e6f7f7aa234",
            "patch": "@@ -65,8 +65,15 @@ class PjRtStreamExecutorRawBuffer : public CommonPjRtRawBuffer {\n         memory_space_(memory_space),\n         local_device_(local_device),\n         device_buffer_(device_buffer) {}\n+\n   PjRtMemorySpace* memory_space() const override { return memory_space_; }\n \n+  LocalDeviceState* local_device() const { return local_device_; }\n+\n+  const tsl::RCReference<RawSEDeviceMemory>& device_buffer() const {\n+    return device_buffer_;\n+  }\n+\n   void* GetHostPointer() const override {\n     return client_->IsOnCpu(memory_space()) ? device_buffer_->opaque()\n                                             : nullptr;"
        }
    ],
    "stats": {
        "total": 366,
        "additions": 227,
        "deletions": 139
    }
}