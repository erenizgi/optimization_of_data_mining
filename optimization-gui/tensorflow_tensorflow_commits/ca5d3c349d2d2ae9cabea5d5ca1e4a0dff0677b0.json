{
    "author": "jcai19",
    "message": "[XLA][Numerics][Hlo Value Tracking] Add a test case for recovering tuple-type sharded data\n\nPiperOrigin-RevId: 831467384",
    "sha": "ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0",
    "files": [
        {
            "sha": "de70e70aef46c4edcf37b44735d47194ca03bf37",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 14,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc?ref=ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0",
            "patch": "@@ -1694,33 +1694,32 @@ void HloModule::OriginalValueRecoveryTable::AddRecoveryComputation(\n   for (const auto& [shape_index, old_original_array] :\n        old_original_value->original_arrays()) {\n     if (!old_original_array || table_.contains(*old_original_array)) {\n-      // If the replaced array is already tracked by the recovery table, we can\n+      // If the original array is already tracked by the recovery table, we can\n       // ignore it since it is already handled by another path.\n       continue;\n     }\n-    // If build_recovery_computation is not provided, we can just propagate the\n-    // replaced original array.\n     std::optional<std::unique_ptr<HloModule>> recovery_computation(nullptr);\n     if (build_recovery_computation) {\n       recovery_computation = build_recovery_computation(\n           shape_index, *old_original_array,\n           ShapeUtil::GetSubshape(old_inst->shape(), shape_index),\n           ShapeUtil::GetSubshape(new_inst->shape(), shape_index));\n-    }\n-    if (!recovery_computation) {\n-      continue;\n+      if (!recovery_computation) {\n+        // Skips if build_recovery_computation returns a nullopt, which\n+        // indicates\n+        // the original array is not recoverable.\n+        continue;\n+      }\n     }\n     std::optional<OriginalArray>* new_original_array =\n         new_inst->original_value()->mutable_original_array(shape_index);\n-    if (recovery_computation->get() == nullptr &&\n-        !new_original_array->has_value()) {\n-      // If the recovery computation is the identity computation and the\n-      // replacing original array is not set, we can just propagate the replaced\n-      // original array without setting any recovery computation.\n-      new_original_array->emplace(*old_original_array);\n-      continue;\n-    }\n     if (!*new_original_array) {\n+      if (recovery_computation->get() == nullptr) {\n+        // If the recovery computation is a nullptr, it means this is an\n+        // identity computation and we can just pass through the original array.\n+        new_original_array->emplace(*old_original_array);\n+        continue;\n+      }\n       new_original_array->emplace(\n           OriginalArray{GetOriginalValuePlaceholderInstructionName(\n                             old_original_array->instruction_name),"
        },
        {
            "sha": "3d83f8f6a8b3b61dd4cf5ba1cf055fb335763d58",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module.h",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h?ref=ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0",
            "patch": "@@ -1010,8 +1010,8 @@ class HloModule {\n     // `std::optional<std::unique_ptr<HloModule>>(\n     //     const ShapeIndex& index,\n     //     const OriginalArray& old_original_array,\n-    //     const xla::Shape& old_array_shape,\n-    //     const xla::Shape& new_array_shape)`\n+    //     const xla::Shape& old_shape,\n+    //     const xla::Shape& new_shape)`\n     //\n     // It is called for each `OriginalArray` in `old_inst` and should\n     // return one of the following:\n@@ -1042,9 +1042,8 @@ class HloModule {\n         const HloInstruction* old_inst, HloInstruction* new_inst,\n         std::function<std::optional<std::unique_ptr<HloModule>>(\n             const ShapeIndex& index, const OriginalArray& old_original_array,\n-            const xla::Shape& old_array_shape,\n-            const xla::Shape& new_array_shape)>&& build_recovery_computation =\n-            nullptr);\n+            const xla::Shape& old_shape, const xla::Shape& new_shape)>&&\n+            build_recovery_computation = nullptr);\n \n     // Similar to `AddRecoveryComputation`, but the callback is provided an\n     // HLO module builder so that caller can directly build the recovery\n@@ -1054,8 +1053,8 @@ class HloModule {\n         std::function<std::optional<HloInstruction*>(\n             xla::HloComputation::Builder& builder, const ShapeIndex& index,\n             const OriginalArray& old_original_array,\n-            const xla::Shape& old_array_shape,\n-            const xla::Shape& new_array_shape)>&& build_recovery_computation);\n+            const xla::Shape& old_shape, const xla::Shape& new_shape)>&&\n+            build_recovery_computation);\n \n     bool empty() const { return table_.empty(); }\n \n@@ -1070,6 +1069,8 @@ class HloModule {\n     const_iterator begin() const { return table_.begin(); }\n     const_iterator end() const { return table_.end(); }\n \n+    size_t size() const { return table_.size(); }\n+\n    private:\n     friend class HloModule;\n     Table table_;"
        },
        {
            "sha": "8fbc2db207677ffc7ec254e6257656f87aee5c07",
            "filename": "third_party/xla/xla/service/spmd/spmd_partitioner.cc",
            "status": "modified",
            "additions": 43,
            "deletions": 43,
            "changes": 86,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc?ref=ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0",
            "patch": "@@ -6240,50 +6240,50 @@ void SpmdPartitioningVisitor::SetPartitionedHlo(\n   } else if (!sharding.IsReplicated()) {\n     // Adds recovery computation to the original value recovery table.\n     auto* module = const_cast<HloModule*>(hlo->parent()->parent());\n-    module->mutable_original_value_recovery_table().AddRecoveryComputation(\n-        hlo, partitioned_hlo.hlo(),\n+    auto build_recovery_computation =\n         [&](const ShapeIndex& index, const OriginalArray& old_original_array,\n-            const xla::Shape& old_array_shape,\n-            const xla::Shape& new_array_shape)\n-            -> std::optional<std::unique_ptr<HloModule>> {\n-          if (ShapeUtil::Compatible(old_array_shape, new_array_shape)) {\n-            // If the shapes are the same, nothing is sharded so we return\n-            // nullptr to indicate identity recovery module. This may happen\n-            // for scalars in tuples.\n-            return nullptr;\n-          }\n-          SpmdBuilder builder(\"recovery_computation\", nullptr);\n-          auto* param =\n-              builder.AddInstruction(xla::HloInstruction::CreateParameter(\n-                  0, new_array_shape, \"param\"));\n-          if (sharding.IsTuple()) {\n-            param->set_sharding(sharding.GetSubSharding(hlo->shape(), index));\n-          } else {\n-            param->set_sharding(sharding);\n-          }\n-          xla::HloModuleConfig config;\n-          auto recovery_module =\n-              std::make_unique<HloModule>(\"recovery_module\", config);\n-          PartitionedHlo::ReshardCache reshard_cache;\n-          int64_t next_channel_id = hlo_query::NextChannelId(*recovery_module);\n-\n-          xla::spmd::PartitionedHlo::PartitioningState partitioning_state =\n-              partitioned_hlo.state();\n-          partitioning_state.b = &builder;\n-          partitioning_state.module = recovery_module.get();\n-          partitioning_state.partition_id =\n-              partitioning_state.collective_ops_creator.create_partition_id(\n-                  &builder);\n-          partitioning_state.next_channel_id = &next_channel_id;\n-          partitioning_state.reshard_cache = &reshard_cache;\n-\n-          PartitionedHlo param_partitioned_hlo(param, old_array_shape,\n-                                               partitioning_state);\n-          // Creates computation to recover the partitioned value.\n-          param_partitioned_hlo.Replicate();\n-          recovery_module->AddEntryComputation(builder.Build());\n-          return recovery_module;\n-        });\n+            const xla::Shape& old_shape, const xla::Shape& new_shape)\n+        -> std::optional<std::unique_ptr<HloModule>> {\n+      SpmdBuilder builder(\"recovery_computation\", nullptr);\n+      auto* param = builder.AddInstruction(\n+          xla::HloInstruction::CreateParameter(0, new_shape, \"param\"));\n+      if (sharding.IsTuple()) {\n+        const HloSharding sub_sharding =\n+            sharding.GetSubSharding(hlo->shape(), index);\n+        if (sub_sharding.IsReplicated()) {\n+          return nullptr;\n+        }\n+        param->set_sharding(sub_sharding);\n+      } else {\n+        param->set_sharding(sharding);\n+      }\n+\n+      xla::HloModuleConfig config;\n+      auto recovery_module =\n+          std::make_unique<HloModule>(\"recovery_module\", config);\n+      PartitionedHlo::ReshardCache reshard_cache;\n+      int64_t next_channel_id = hlo_query::NextChannelId(*recovery_module);\n+\n+      xla::spmd::PartitionedHlo::PartitioningState partitioning_state =\n+          partitioned_hlo.state();\n+      partitioning_state.b = &builder;\n+      partitioning_state.module = recovery_module.get();\n+      partitioning_state.partition_id =\n+          partitioning_state.collective_ops_creator.create_partition_id(\n+              &builder);\n+      partitioning_state.next_channel_id = &next_channel_id;\n+      partitioning_state.reshard_cache = &reshard_cache;\n+\n+      PartitionedHlo param_partitioned_hlo(param, old_shape,\n+                                           partitioning_state);\n+      // Creates computation to recover the partitioned value.\n+      param_partitioned_hlo.Replicate();\n+      recovery_module->AddEntryComputation(builder.Build());\n+      return recovery_module;\n+    };\n+\n+    module->mutable_original_value_recovery_table().AddRecoveryComputation(\n+        hlo, partitioned_hlo.hlo(), build_recovery_computation);\n   }\n \n   partitioned_instructions_.emplace(hlo, partitioned_hlo);"
        },
        {
            "sha": "e35825c33f2ad6d30cb530b76cb6c05ab14fc051",
            "filename": "third_party/xla/xla/service/spmd/spmd_partitioner_test.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner_test.cc?ref=ca5d3c349d2d2ae9cabea5d5ca1e4a0dff0677b0",
            "patch": "@@ -16599,6 +16599,27 @@ ENTRY entry {\n               ::testing::ElementsAre(8, 10, 12, 14, 9, 11, 13, 15))));\n }\n \n+TEST_P(SpmdPartitioningTest, OriginalValueWithTupleTypeShardingAnnotation) {\n+  absl::string_view hlo_string = R\"(\n+HloModule module\n+\n+ENTRY entry {\n+  token0 = token[] after-all(), sharding={maximal device=0}\n+  infeed = ((f32[9,2]{1,0}, f32[2]{0}), token[]) infeed(token0),\n+    sharding={{devices=[2,1]0,1}, {replicated}, {maximal device=0}}\n+  ROOT infeed.data = (f32[9,2]{1,0}, f32[2]{0}) get-tuple-element(infeed),\n+    index=0, sharding={{devices=[2,1]0,1}, {replicated}}, origin={({\"a\"}, {\"b\"})}\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          PartitionComputation(hlo_string, /*num_devices=*/2));\n+  EXPECT_EQ(module->original_value_recovery_table().size(), 1);\n+  EXPECT_EQ(module->original_value_recovery_table().begin()->first.ToString(),\n+            R\"(\"a\")\");\n+  EXPECT_EQ(\n+      module->original_value_recovery_table().begin()->second.first.ToString(),\n+      R\"(\"a)\" + std::string(kOriginalValuePlaceholderDelimiter) + R\"(0\")\");\n+}\n+\n TEST_P(SpmdPartitioningTest, ShardingPreprocessOrderWhile) {\n   absl::string_view hlo_string = R\"(\n HloModule module"
        }
    ],
    "stats": {
        "total": 149,
        "additions": 85,
        "deletions": 64
    }
}