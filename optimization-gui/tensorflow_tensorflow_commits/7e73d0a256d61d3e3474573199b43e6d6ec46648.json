{
    "author": "mtsokol",
    "message": "PR #32107: Expand tiling docs\n\nImported from GitHub PR https://github.com/openxla/xla/pull/32107\n\nüìù Summary of Changes\n\nThis PR expands tiling docs with Motivation section and Tiling formats.\n\nüéØ Justification\n\nExpand Tiling docs\n\nüöÄ Kind of Contribution\n\nüìö Documentation\n\nCopybara import of the project:\n\n--\na57a6362fb7d40786f5e50844953379fb44d68c0 by Mateusz Sok√≥≈Ç <mat646@gmail.com>:\n\nExtend tiling docs\n\n--\n7292499bb0ac7750dcc8394028ac3e254dcb7af9 by Mateusz Sok√≥≈Ç <mat646@gmail.com>:\n\nApply review comments\n\n--\n8e98d87c4d929610e4a3e95f24e79c1172df312a by Mateusz Sok√≥≈Ç <mat646@gmail.com>:\n\nRemove unused images\n\n--\n19ccaf61fc5ce1de71786e78e6d64f80fd2feaf9 by Mateusz Sok√≥≈Ç <mat646@gmail.com>:\n\nTweak layout description\n\nMerging this change closes #32107\n\nPiperOrigin-RevId: 838766890",
    "sha": "7e73d0a256d61d3e3474573199b43e6d6ec46648",
    "files": [
        {
            "sha": "b1e81c6073061f37625b50a6113fa0330fb142c8",
            "filename": "third_party/xla/docs/tiled_layout.md",
            "status": "modified",
            "additions": 42,
            "deletions": 2,
            "changes": 44,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e73d0a256d61d3e3474573199b43e6d6ec46648/third_party%2Fxla%2Fdocs%2Ftiled_layout.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e73d0a256d61d3e3474573199b43e6d6ec46648/third_party%2Fxla%2Fdocs%2Ftiled_layout.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Ftiled_layout.md?ref=7e73d0a256d61d3e3474573199b43e6d6ec46648",
            "patch": "@@ -1,7 +1,13 @@\n # Tiled layout\n \n-> **Caution:** Tiled layout is *pre-release* and this describes how it's\n-> intended to work. Errors may be silently ignored.\n+XLA TPU uses a variety of tile-based formats due to the two-dimensional nature\n+of its vector registers.\n+\n+## Tiled formats\n+\n+A tiled format breaks down a shape into tiles (usually 1D or 2D). Tiles are laid\n+out in memory in major to minor order (row major layout). Within a tile,\n+elements are also laid out in major to minor order.\n \n ![](images/xla_array_layout_figure1.png)\n <br>Figure 1\n@@ -80,6 +86,10 @@ logical shape is then\n = (1 ‚àô 3 + 1) ‚àô 2 ‚àô 2 + (0 ‚àô 2 + 1) <br>\n = 17.\n \n+$$ LinearIndexWithTile((2,3), (3,5), (2,2)) \\\\ = LinearIndex((1,1,0,1),\n+(2,3,2,2)) \\\\ = LinearIndex((1,1), (2,3)) \\cdot 2 \\cdot 2 + LinearIndex((0,1),\n+(2,2)) \\\\ = (1 \\cdot 3 + 1) \\cdot 2 \\cdot 2 + (0 \\cdot 2 + 1) \\\\ = 17 $$\n+\n ## Tiling as pad-reshape-transpose\n \n Tiling-based layout operates as follows: <br>\n@@ -153,3 +163,33 @@ removed from both the shape being tiled and the tile vector, and what was\n dimension i-1 of the shape has its array bound increased from d<sub>i-1</sub> to\n d<sub>i</sub>d<sub>i-1</sub>. This step is repeated for each asterisk in the\n tile vector.\n+\n+## Examples of tiling formats\n+\n+This section shows examples of popular XLA formats.\n+\n+1.  **Untiled format** - Most arrays not on the TPU use an untiled linear\n+    format, same as in e.g. C++.\n+2.  **TPU tile format** - The most common format in XLA/TPU is tiling by\n+    `8x128`, which matches the 32-bit `8x128` vector registers on a TPU.\n+3.  **TPU small tile format** (a.k.a. \"Compact 2nd Minor Layout\") - When the\n+    second most minor dimension size is 1 or 2, XLA/TPU instead tiles by `2x128`\n+    to save memory since a `2x128` tile is smaller than an `8x128` tile. When\n+    the second most minor dimension size is 3 or 4, XLA/TPU tiles by `4x128`.\n+4.  **TPU 16 bit tile format** - When array element type is BF16, the tiles we\n+    use are typically (8,128)(2,1). The second level of tiling does the\n+    so-called BF16 packing. See Figure 2 above, one element from an even row and\n+    one element from an odd row are laid out together and put in one 32-bit\n+    element. This format is used because TPUs work with 32 bit values natively\n+    and it is much more efficient to move data across the second most minor\n+    dimension than across the most minor dimension, so collecting two 16 bit\n+    values to get 32 bits from the same column is much more efficient than doing\n+    it in the more obvious fashion of taking two 16 bit values from the same\n+    row.\n+5.  **TPU 8 bit tile format** - The format here is very similar to the 16 bit\n+    format, the difference is just that we need to collect together 4 elements\n+    to get 32 bits instead of just the two, so the tiling becomes\n+    `(8,128)(4,1)`.\n+6.  **TPU 1 bit tile format** - TPUs currently use 1 byte for one boolean value,\n+    i.e. the size in bytes of the PRED element type is 1. It would be less\n+    wasteful to use a tiling by `(32,128)(32,1)` and use only 1 bit per element."
        }
    ],
    "stats": {
        "total": 44,
        "additions": 42,
        "deletions": 2
    }
}