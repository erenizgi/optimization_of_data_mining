{
    "author": "apivovarov",
    "message": "Add support for CollectivePermuteThunk in Command Buffer.\n\nThis change contains the following:\n- Adds CollectivePermuteCmd class\n- Integrates `CollectivePermuteStartThunk` and `CollectivePermuteDoneThunk` into the command buffer execution framework, allowing them to be converted into command buffer commands.\n\nPiperOrigin-RevId: 834463319",
    "sha": "f82ea8bde51a5d13af7f2d422f40f620801c89e0",
    "files": [
        {
            "sha": "8f8c8616ee440e72bba08bbb916c19f45ed6609f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 39,
            "deletions": 0,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=f82ea8bde51a5d13af7f2d422f40f620801c89e0",
            "patch": "@@ -67,11 +67,13 @@ cc_library(\n         \":all_to_all_thunk\",\n         \":annotation\",\n         \":collective_broadcast_thunk\",\n+        \":collective_permute_thunk\",\n         \":collective_thunk\",\n         \":copy_thunk\",\n         \":custom_call_thunk\",\n         \":dynamic_slice_thunk\",\n         \":gpublas_lt_matmul_thunk\",\n+        \":p2p_thunk_common\",\n         \":shaped_slice\",\n         \":thunk\",\n         \":while_thunk\",\n@@ -110,6 +112,7 @@ cc_library(\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:dnn\",\n         \"//xla/stream_executor:kernel\",\n+        \"//xla/stream_executor:kernel_args\",\n         \"//xla/stream_executor:memory_allocation\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:stream\",\n@@ -187,6 +190,7 @@ cc_library(\n         \":all_reduce_thunk\",\n         \":all_to_all_thunk\",\n         \":collective_broadcast_thunk\",\n+        \":collective_permute_thunk\",\n         \":collective_thunk\",\n         \":command_buffer_cmd\",\n         \":conditional_thunk\",\n@@ -1521,6 +1525,41 @@ cc_library(\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/synchronization\",\n         \"@com_google_absl//absl/time\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@local_tsl//tsl/platform:casts\",\n+    ],\n+)\n+\n+xla_test(\n+    name = \"collective_permute_thunk_test\",\n+    srcs = [\"collective_permute_thunk_test.cc\"],\n+    backends = [\"gpu\"],\n+    deps = [\n+        \":collective_permute_thunk\",\n+        \":collective_thunk\",\n+        \":command_buffer_cmd\",\n+        \":command_buffer_cmd_emitter\",\n+        \":command_buffer_thunk\",\n+        \":sequential_thunk\",\n+        \":thunk\",\n+        \":thunk_proto_cc\",\n+        \"//xla:util\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:verified_hlo_module\",\n+        \"//xla/service:backend\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/service:executable\",\n+        \"//xla/service:hlo_module_config\",\n+        \"//xla/service/gpu:gpu_constants\",\n+        \"//xla/service/gpu:gpu_executable\",\n+        \"//xla/stream_executor:platform\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tests:hlo_test_base\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/platform:test\",\n+        \"@com_google_googletest//:gtest_main\",\n         \"@local_tsl//tsl/platform:casts\",\n     ],\n )"
        },
        {
            "sha": "7f9be0360e67e961d076d27d26265f0add1f6792",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc?ref=f82ea8bde51a5d13af7f2d422f40f620801c89e0",
            "patch": "@@ -45,13 +45,11 @@ limitations under the License.\n #include \"xla/hlo/ir/collective_op_group_mode.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n-#include \"xla/service/computation_placer.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/transforms/collectives/collective_ops_utils.h\"\n #include \"xla/service/rendezvous.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/stream.h\"\n-#include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -293,7 +291,7 @@ absl::StatusOr<bool> CollectivePermuteStartThunk::RunCollective(\n \n   TF_RETURN_IF_ERROR(::xla::gpu::RunCollectivePermute(\n       source_target, device_buffers, stream, comm_handle.comm, device_string,\n-      current_id, use_memcpy, recv_ptr_map_,\n+      current_id, use_memcpy, &recv_ptr_map_,\n       config_.config.use_symmetric_buffer));\n \n   if (use_memcpy) {\n@@ -338,9 +336,10 @@ absl::StatusOr<bool> CollectivePermuteStartThunk::RunCollective(\n \n absl::Status RunCollectivePermute(\n     P2PConfig::SourceTargetMapEntry source_target,\n-    std::vector<DeviceBufferPair>& buffers, se::Stream& stream,\n+    const std::vector<DeviceBufferPair>& buffers, se::Stream& stream,\n     Communicator* comm, absl::string_view device_string, int64_t current_id,\n-    bool use_memcpy, CollectivePermuteStartThunk::RecvPtrMap& recv_ptr_map,\n+    bool use_memcpy,\n+    const CollectivePermuteStartThunk::RecvPtrMap* recv_ptr_map,\n     bool use_symmetric_buffer) {\n   // Determine the source and target IDs for this instance. The source ID is the\n   // ID which will copy its data to this instance. The destination ID is the ID\n@@ -438,7 +437,9 @@ absl::Status RunCollectivePermute(\n   }\n \n   if (use_memcpy && target_id) {\n-    TF_ASSIGN_OR_RETURN(auto recv_ptrs, recv_ptr_map.GetRecvPtr(*target_id));\n+    CHECK(recv_ptr_map != nullptr);\n+    TF_ASSIGN_OR_RETURN(AsyncValueRef<std::vector<void*>> recv_ptrs,\n+                        recv_ptr_map->GetRecvPtr(*target_id));\n \n     VLOG(3) << \"Using memcpy, received target pointers, current_id: \"\n             << current_id << \" target_id: \" << *target_id;"
        },
        {
            "sha": "39476490ccfc80a8da0f8a35e8ad18c2f351e69f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.h",
            "status": "modified",
            "additions": 17,
            "deletions": 9,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.h?ref=f82ea8bde51a5d13af7f2d422f40f620801c89e0",
            "patch": "@@ -29,8 +29,10 @@ limitations under the License.\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/p2p_thunk_common.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/core/collectives/communicator.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/stream_executor/event.h\"\n@@ -47,7 +49,7 @@ class CollectivePermuteStartThunk : public CollectiveThunk {\n  public:\n   class RecvPtrMap {\n    public:\n-    bool IsInitialized(int64_t current_id) {\n+    bool IsInitialized(int64_t current_id) const {\n       absl::MutexLock lock(mutex_);\n       return recv_ptrs_.find(current_id) != recv_ptrs_.end();\n     }\n@@ -74,17 +76,17 @@ class CollectivePermuteStartThunk : public CollectiveThunk {\n     }\n \n     absl::StatusOr<AsyncValueRef<std::vector<void*>>> GetRecvPtr(\n-        int64_t target_id) {\n+        int64_t target_id) const {\n       if (!IsInitialized(target_id)) {\n         return absl::InternalError(absl::StrCat(\"Target ID \", target_id,\n                                                 \" has not been initialized!\"));\n       }\n       absl::MutexLock lock(mutex_);\n-      return recv_ptrs_[target_id];\n+      return recv_ptrs_.at(target_id);\n     }\n \n    private:\n-    absl::Mutex mutex_;\n+    mutable absl::Mutex mutex_;\n     absl::node_hash_map<int64_t, AsyncValueRef<std::vector<void*>>> recv_ptrs_\n         ABSL_GUARDED_BY(mutex_);\n   };\n@@ -104,12 +106,18 @@ class CollectivePermuteStartThunk : public CollectiveThunk {\n                               const std::vector<Buffer>& buffers,\n                               bool p2p_memcpy_enabled,\n                               AsyncStreamKind stream_kind);\n+\n   absl::Status Initialize(const InitializeParams& params) override;\n \n   static const char* GetHloOpName() { return \"collective-permute-start\"; }\n \n- protected:\n   const CollectiveConfig& config() const override { return config_.config; }\n+\n+  absl::Span<const Buffer> buffers() const { return buffers_; }\n+\n+  const P2PConfig& p2p_config() const { return config_; }\n+\n+ protected:\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n                                      se::Stream& stream,\n                                      CommunicatorHandle comm_handle) override;\n@@ -123,16 +131,16 @@ class CollectivePermuteStartThunk : public CollectiveThunk {\n       receiver_barrier_events_;\n   absl::flat_hash_map<int64_t, std::unique_ptr<se::Event>>\n       sender_barrier_events_;\n-\n   bool p2p_memcpy_enabled_ = false;\n-  int64_t device_count_;\n+  int64_t device_count_ = 0;\n };\n \n absl::Status RunCollectivePermute(\n     P2PConfig::SourceTargetMapEntry source_target,\n-    std::vector<DeviceBufferPair>& buffers, se::Stream& stream,\n+    const std::vector<DeviceBufferPair>& buffers, se::Stream& stream,\n     Communicator* comm, absl::string_view device_string, int64_t current_id,\n-    bool use_memcpy, CollectivePermuteStartThunk::RecvPtrMap& recv_ptr_map,\n+    bool use_memcpy = false,\n+    const CollectivePermuteStartThunk::RecvPtrMap* recv_ptr_map = nullptr,\n     bool use_symmetric_buffer = false);\n \n }  // namespace gpu"
        },
        {
            "sha": "5036ebd04d8b13e2f8cf0cd847f7d4146ebef49c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk_test.cc",
            "status": "added",
            "additions": 219,
            "deletions": 0,
            "changes": 219,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk_test.cc?ref=f82ea8bde51a5d13af7f2d422f40f620801c89e0",
            "patch": "@@ -0,0 +1,219 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/collective_permute_thunk.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"xla/backends/gpu/runtime/collective_thunk.h\"\n+#include \"xla/backends/gpu/runtime/command_buffer_cmd.h\"\n+#include \"xla/backends/gpu/runtime/command_buffer_cmd_emitter.h\"\n+#include \"xla/backends/gpu/runtime/command_buffer_thunk.h\"\n+#include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/testlib/verified_hlo_module.h\"\n+#include \"xla/service/backend.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/executable.h\"\n+#include \"xla/service/gpu/gpu_constants.h\"\n+#include \"xla/service/gpu/gpu_executable.h\"\n+#include \"xla/service/hlo_module_config.h\"\n+#include \"xla/stream_executor/platform.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tests/hlo_test_base.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/test.h\"\n+#include \"xla/util.h\"\n+#include \"xla/xla_data.pb.h\"\n+#include \"tsl/platform/casts.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+using ::testing::ElementsAre;\n+using Kind = Thunk::Kind;\n+\n+class GpuCollectivePermuteTest : public HloTestBase {};\n+\n+// Test case to verify that a CollectivePermute HLO instruction is correctly\n+// converted into a sequence of command buffer commands (Start and Done).\n+TEST_F(GpuCollectivePermuteTest, TestConvertToCommands) {\n+  // Generate HLO text\n+  std::string hlo_text = R\"(\n+HloModule test, replica_count=2\n+ENTRY test_computation {\n+  p = u32[4] parameter(0)\n+  ROOT permute = u32[4] collective-permute(p), source_target_pairs={{0,1}, {1,0}}\n+}\n+)\";\n+\n+  // Configure module with debug options for command buffer.\n+  HloModuleConfig config;\n+  DebugOptions debug_options = GetDebugOptionsForTest();\n+  debug_options.set_xla_gpu_graph_min_graph_size(1);\n+  debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::COLLECTIVES);\n+  config.set_debug_options(debug_options);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_text, config));\n+\n+  // Get CollectivePermute Instruction\n+  const HloInstruction* root_instr =\n+      module->entry_computation()->root_instruction();\n+  ASSERT_EQ(root_instr->opcode(), HloOpcode::kCollectivePermute);\n+  const HloCollectivePermuteInstruction* cp_instr =\n+      tensorflow::down_cast<const HloCollectivePermuteInstruction*>(root_instr);\n+  ASSERT_NE(cp_instr, nullptr);\n+\n+  // Buffer and Allocation Setup\n+  using DataT = int32_t;\n+  constexpr int64_t kNumElements = 4;\n+  constexpr int64_t kAlignmentBytes = kXlaAllocatedBufferAlignBytes;\n+\n+  const int64_t kElementSize = sizeof(DataT);\n+  const int64_t kTotalDataBytes = kNumElements * kElementSize;\n+\n+  // Use RoundUpTo to calculate the actual size needed for one buffer.\n+  const int64_t kAlignedSliceBytes =\n+      xla::RoundUpTo<uint64_t>(kTotalDataBytes, kAlignmentBytes);\n+\n+  // The total buffer size must accommodate input and output slices.\n+  const int64_t kTotalBufferBytes = 2 * kAlignedSliceBytes;\n+\n+  BufferAllocation buffer_allocation(/*index=*/0, kTotalBufferBytes,\n+                                     /*color=*/0);\n+  BufferAllocation::Slice input_slice(&buffer_allocation, /*offset=*/0,\n+                                      kAlignedSliceBytes);\n+  BufferAllocation::Slice output_slice(&buffer_allocation, kAlignedSliceBytes,\n+                                       kAlignedSliceBytes);\n+\n+  // Use designated initializers if possible, or format for clarity.\n+  std::vector<CollectiveThunk::Buffer> buffers = {\n+      {/*element_count=*/kNumElements,\n+       /*source_buffer=*/input_slice,\n+       /*destination_buffer=*/output_slice,\n+       /*source_memory_space=*/0,\n+       /*destination_memory_space=*/0},\n+  };\n+\n+  // ThunkSequence Creation\n+  std::shared_ptr<CollectiveThunk::AsyncEvents> async_events =\n+      std::make_shared<CollectiveThunk::AsyncEvents>();\n+\n+  auto cp_start_thunk = std::make_unique<CollectivePermuteStartThunk>(\n+      Thunk::ThunkInfo{}, cp_instr, /*replica_count=*/2,\n+      /*partition_count=*/1, std::move(buffers),\n+      /*p2p_memcpy_enabled=*/false,\n+      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE);\n+\n+  cp_start_thunk->set_async_events(async_events);\n+\n+  auto cp_done_thunk = std::make_unique<CollectiveDoneThunk>(\n+      Kind::kCollectivePermuteDone, Thunk::ThunkInfo{}, async_events,\n+      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE);\n+\n+  ThunkSequence thunk_sequence;\n+  thunk_sequence.push_back(std::move(cp_start_thunk));\n+  thunk_sequence.push_back(std::move(cp_done_thunk));\n+\n+  // Convert to Commands and Verification\n+  ConvertToCommandsOptions conv_options;\n+  // Use LHS synchronization mode to append Done command\n+  conv_options.synchronization_mode =\n+      CommandBufferCmdExecutor::SynchronizationMode::kLHS;\n+  TF_ASSERT_OK_AND_ASSIGN(CommandBufferCmdExecutor cb_cmd_executor,\n+                          ConvertToCommands(thunk_sequence, conv_options));\n+\n+  // Check that we have two commands: start and done.\n+  EXPECT_EQ(cb_cmd_executor.size(), 2);\n+}\n+\n+TEST_F(GpuCollectivePermuteTest,\n+       TestCommandBufferThunkContainsCollectivePermute) {\n+  // Generate HLO text\n+  std::string hlo_text = R\"(\n+HloModule test, replica_count=2\n+ENTRY test_computation {\n+  replica = u32[] replica-id()\n+  p = u32[4] broadcast(replica), dimensions={}\n+  ROOT permute = u32[4] collective-permute(p), source_target_pairs={{0,1}, {1,0}}\n+}\n+)\";\n+\n+  // Configure module with debug options for command buffer.\n+  HloModuleConfig config;\n+  DebugOptions debug_options = GetDebugOptionsForTest();\n+  debug_options.set_xla_gpu_graph_min_graph_size(1);\n+  debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::COLLECTIVES);\n+  config.set_debug_options(debug_options);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_text, config));\n+\n+  se::StreamExecutor* executor = backend().default_stream_executor();\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<HloModule> compiled_module,\n+      backend().compiler()->RunHloPasses(module->Clone(), executor,\n+                                         /*device_allocator=*/nullptr));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<Executable> executable,\n+      backend().compiler()->RunBackend(std::move(compiled_module), executor,\n+                                       {/*device_allocator=*/nullptr,\n+                                        /*thread_pool=*/nullptr,\n+                                        /*layout_canonicalization_callback=*/{},\n+                                        /*is_autotuning_compilation=*/false}));\n+  // Downcast to GPU executable\n+  xla::gpu::GpuExecutable* gpu_executable =\n+      tensorflow::down_cast<xla::gpu::GpuExecutable*>(executable.get());\n+  ASSERT_NE(gpu_executable, nullptr);\n+\n+  // Get the thunk sequence and check its size and type\n+  const SequentialThunk& seq_thunk = gpu_executable->GetThunk();\n+  ASSERT_EQ(seq_thunk.thunks().size(), 1);\n+\n+  const std::unique_ptr<Thunk>& thunk = seq_thunk.thunks().front();\n+  ASSERT_EQ(thunk->kind(), Thunk::kCommandBuffer);\n+\n+  // Downcast to the specific CommandBufferThunk type for inspection.\n+  CommandBufferThunk* cmd_buffer_thunk =\n+      tensorflow::down_cast<CommandBufferThunk*>(thunk.get());\n+  ASSERT_NE(cmd_buffer_thunk, nullptr);\n+\n+  // Inspect the Thunk kinds\n+  std::vector<Kind> kinds;\n+  const auto& inner_thunks = cmd_buffer_thunk->thunks()->thunks();\n+  kinds.reserve(inner_thunks.size());\n+  for (const auto& thunk : inner_thunks) {\n+    kinds.push_back(thunk->kind());\n+  }\n+  // Verify that the inner Thunks match the expected sequence from the HLO\n+  EXPECT_THAT(kinds, ElementsAre(Kind::kReplicaId, Kind::kKernel,\n+                                 Kind::kCollectivePermuteStart));\n+}\n+}  // namespace\n+}  // namespace xla::gpu"
        },
        {
            "sha": "ff326a7d5d01800e07961d1565057a7893d6156e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 84,
            "deletions": 0,
            "changes": 84,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=f82ea8bde51a5d13af7f2d422f40f620801c89e0",
            "patch": "@@ -52,10 +52,12 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/all_to_all_thunk.h\"\n #include \"xla/backends/gpu/runtime/annotation.h\"\n #include \"xla/backends/gpu/runtime/collective_broadcast_thunk.h\"\n+#include \"xla/backends/gpu/runtime/collective_permute_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/copy_thunk.h\"\n #include \"xla/backends/gpu/runtime/dynamic_slice_thunk.h\"\n #include \"xla/backends/gpu/runtime/gpublas_lt_matmul_thunk.h\"\n+#include \"xla/backends/gpu/runtime/p2p_thunk_common.h\"\n #include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/while_thunk.h\"\n@@ -87,6 +89,7 @@ limitations under the License.\n #include \"xla/stream_executor/dnn.h\"\n #include \"xla/stream_executor/gpu/tma_metadata.h\"\n #include \"xla/stream_executor/kernel.h\"\n+#include \"xla/stream_executor/kernel_args.h\"\n #include \"xla/stream_executor/memory_allocation.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream.h\"\n@@ -2227,6 +2230,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllToAllCmd::Record(\n               config().group_mode,\n               AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n \n+  // MemCpy case is not currently supported in CommandBuffer.\n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n       [&](se::Stream* stream) {\n@@ -2371,6 +2375,86 @@ CommandBufferCmd::BufferUseVector CollectiveBroadcastCmd::buffers() const {\n   return buffer_usage;\n }\n \n+//===----------------------------------------------------------------------===//\n+// CollectivePermuteCmd\n+//===----------------------------------------------------------------------===//\n+\n+CollectivePermuteCmd::CollectivePermuteCmd(\n+    CollectiveConfig config, P2PConfig p2p_config,\n+    absl::Span<const CollectiveThunk::Buffer> buffers,\n+    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events)\n+    : CollectiveCmd(CommandBufferCmdType::kCollectivePermuteCmd,\n+                    std::move(config), std::move(async_events)),\n+      p2p_config_(std::move(p2p_config)),\n+      buffers_(buffers.begin(), buffers.end()) {}\n+\n+absl::StatusOr<const se::CommandBuffer::Command*> CollectivePermuteCmd::Record(\n+    const Thunk::ExecuteParams& execute_params,\n+    const RecordParams& record_params, RecordAction record_action,\n+    se::CommandBuffer* command_buffer) {\n+  TF_ASSIGN_OR_RETURN(\n+      std::vector<DeviceBufferPair> device_buffers,\n+      ConvertToDeviceBuffers(execute_params.buffer_allocations, buffers_,\n+                             config().operand_element_type));\n+\n+  int device_ordinal = execute_params.stream->parent()->device_ordinal();\n+  VLOG(5) << \"[\" << device_ordinal << \"] CollectivePermuteCmd:\";\n+\n+  for (size_t i = 0; i < device_buffers.size(); ++i) {\n+    VLOG(5) << \"[\" << device_ordinal << \"]  Src: \" << buffers_[i].source_buffer\n+            << \" (\" << device_buffers[i].source_buffer.opaque() << \")\";\n+    VLOG(5) << \"[\" << device_ordinal\n+            << \"]  Dst: \" << buffers_[i].destination_buffer << \" (\"\n+            << device_buffers[i].destination_buffer.opaque() << \")\";\n+  }\n+\n+  if (!execute_params.collective_params || !execute_params.collective_cliques) {\n+    return absl::InvalidArgumentError(\n+        \"CollectivePermuteCmd requires collective parameters and cliques\");\n+  }\n+\n+  TF_ASSIGN_OR_RETURN(GpuCollectives * collectives,\n+                      Thunk::GetGpuCollectives(execute_params));\n+\n+  TF_ASSIGN_OR_RETURN(\n+      CommunicatorHandle comm_handle,\n+      GetComm(collectives, *execute_params.collective_params,\n+              *execute_params.collective_cliques, config().replica_groups,\n+              config().group_mode,\n+              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n+\n+  std::string device_string =\n+      CollectiveThunk::GetDeviceString(*execute_params.collective_params);\n+  bool use_symmetric_buffer = config().use_symmetric_buffer;\n+\n+  TF_ASSIGN_OR_RETURN(\n+      const int64_t current_id,\n+      GetCollectiveCurrentId(execute_params.collective_params, p2p_config_));\n+\n+  const P2PConfig::SourceTargetMapEntry source_target =\n+      P2PConfig::GetSourceTarget(p2p_config_.id_to_source_target, current_id);\n+\n+  // MemCpy case is not currently supported in CommandBuffer.\n+  return RecordTracedCommand(\n+      execute_params, record_params, std::move(record_action), command_buffer,\n+      [&](se::Stream* stream) {\n+        return RunCollectivePermute(source_target, device_buffers, *stream,\n+                                    comm_handle.comm, device_string, current_id,\n+                                    /*use_memcpy=*/false,\n+                                    /*recv_ptr_map=*/nullptr,\n+                                    use_symmetric_buffer);\n+      });\n+}\n+\n+CommandBufferCmd::BufferUseVector CollectivePermuteCmd::buffers() const {\n+  BufferUseVector buffer_usage;\n+  for (const CollectiveThunk::Buffer& buffer : buffers_) {\n+    buffer_usage.emplace_back(BufferUse::Read(buffer.source_buffer));\n+    buffer_usage.emplace_back(BufferUse::Write(buffer.destination_buffer));\n+  }\n+  return buffer_usage;\n+}\n+\n //===----------------------------------------------------------------------===//\n // DynamicSliceFusionCmd\n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "6bd03ebda93ccd076e686515e9095c84321a1f48",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.h",
            "status": "modified",
            "additions": 26,
            "deletions": 0,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h?ref=f82ea8bde51a5d13af7f2d422f40f620801c89e0",
            "patch": "@@ -37,11 +37,13 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/backends/gpu/runtime/collective_permute_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/copy_thunk.h\"\n #include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n #include \"xla/backends/gpu/runtime/dynamic_slice_thunk.h\"\n #include \"xla/backends/gpu/runtime/gpublas_lt_matmul_thunk.h\"\n+#include \"xla/backends/gpu/runtime/p2p_thunk_common.h\"\n #include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/ffi/api/c_api.h\"\n@@ -96,6 +98,7 @@ namespace xla::gpu {\n   V(kAllToAllCmd, \"AllToAllCmd\")                                 \\\n   V(kAllGatherCmd, \"AllGatherCmd\")                               \\\n   V(kCollectiveBroadcastCmd, \"CollectiveBroadcastCmd\")           \\\n+  V(kCollectivePermuteCmd, \"CollectivePermuteCmd\")               \\\n   V(kAsyncDone, \"AsyncDone\")                                     \\\n   V(kDynamicSliceFusionCmd, \"DynamicSliceFusionCmd\")             \\\n   V(kDynamicSliceCopyFusionCmd, \"DynamicSliceCopyFusionCmd\")     \\\n@@ -1209,6 +1212,29 @@ class CollectiveBroadcastCmd : public CollectiveCmd {\n   std::vector<CollectiveThunk::Buffer> buffers_;\n };\n \n+//===----------------------------------------------------------------------===//\n+// CollectivePermuteCmd\n+//===----------------------------------------------------------------------===//\n+\n+class CollectivePermuteCmd : public CollectiveCmd {\n+ public:\n+  CollectivePermuteCmd(\n+      CollectiveConfig config, P2PConfig p2p_config,\n+      absl::Span<const CollectiveThunk::Buffer> buffers,\n+      std::shared_ptr<CollectiveThunk::AsyncEvents> async_events);\n+\n+  absl::StatusOr<const se::CommandBuffer::Command*> Record(\n+      const Thunk::ExecuteParams& execute_params,\n+      const RecordParams& record_params, RecordAction record_action,\n+      se::CommandBuffer* command_buffer) override;\n+\n+  BufferUseVector buffers() const override;\n+\n+ private:\n+  P2PConfig p2p_config_;\n+  std::vector<CollectiveThunk::Buffer> buffers_;\n+};\n+\n //===----------------------------------------------------------------------===//\n // DynamicSliceFusionCmd\n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "a4532883b8215dde8aa36b0d6f5eac15acfe4229",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd_emitter.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc?ref=f82ea8bde51a5d13af7f2d422f40f620801c89e0",
            "patch": "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/all_reduce_thunk.h\"\n #include \"xla/backends/gpu/runtime/all_to_all_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_broadcast_thunk.h\"\n+#include \"xla/backends/gpu/runtime/collective_permute_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/command_buffer_cmd.h\"\n #include \"xla/backends/gpu/runtime/conditional_thunk.h\"\n@@ -191,6 +192,13 @@ static absl::StatusOr<Command> Convert(\n       thunk.config(), thunk.buffers(), thunk.async_events());\n }\n \n+static absl::StatusOr<Command> Convert(\n+    const CollectivePermuteStartThunk& thunk) {\n+  return std::make_unique<CollectivePermuteCmd>(\n+      thunk.config(), thunk.p2p_config(), thunk.buffers(),\n+      thunk.async_events());\n+}\n+\n static absl::StatusOr<Command> Convert(\n     const DynamicSliceThunk& thunk, const ConvertToCommandsOptions& options) {\n   TF_ASSIGN_OR_RETURN(\n@@ -297,6 +305,8 @@ static absl::Status AppendCommands(CommandBufferCmdSequence& cmd_sequence,\n       return append(Convert<AllToAllStartThunk>(thunk));\n     case Thunk::Kind::kCollectiveBroadcastStart:\n       return append(Convert<CollectiveBroadcastStartThunk>(thunk));\n+    case Thunk::Kind::kCollectivePermuteStart:\n+      return append(Convert<CollectivePermuteStartThunk>(thunk));\n     case Thunk::Kind::kPartitionId:\n       return append(Convert<PartitionIdThunk>(thunk));\n     case Thunk::Kind::kReplicaId:\n@@ -319,6 +329,7 @@ static absl::Status AppendCommands(CommandBufferCmdSequence& cmd_sequence,\n     case Thunk::Kind::kAllReduceDone:\n     case Thunk::Kind::kAllToAllDone:\n     case Thunk::Kind::kCollectiveBroadcastDone:\n+    case Thunk::Kind::kCollectivePermuteDone:\n     case Thunk::Kind::kReduceScatterDone:\n       if (options.synchronization_mode ==\n           CommandBufferCmdExecutor::SynchronizationMode::kLHS) {"
        },
        {
            "sha": "debf9850b5c7e3344d72e2b5bc884684d6237245",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f82ea8bde51a5d13af7f2d422f40f620801c89e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc?ref=f82ea8bde51a5d13af7f2d422f40f620801c89e0",
            "patch": "@@ -3068,6 +3068,8 @@ absl::Status IrEmitterUnnested::EmitHloInstruction(\n         case HloOpcode::kCollectiveBroadcast:\n           return EmitCollectiveAsyncDone(Thunk::kCollectiveBroadcastDone,\n                                          instr);\n+        case HloOpcode::kCollectivePermute:\n+          return EmitCollectiveAsyncDone(Thunk::kCollectivePermuteDone, instr);\n         case HloOpcode::kFusion: {\n           auto collective_hero = GetCollectiveHeroForDynamicSliceFusion(\n               Cast<HloFusionInstruction>(wrapped));"
        }
    ],
    "stats": {
        "total": 420,
        "additions": 405,
        "deletions": 15
    }
}