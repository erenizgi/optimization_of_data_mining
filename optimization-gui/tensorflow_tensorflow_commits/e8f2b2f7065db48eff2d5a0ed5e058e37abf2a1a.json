{
    "author": "majnemer",
    "message": "Replace deprecated integral type limits with `std::numeric_limits`.\n\nThis change replaces usages of `kintXXmax`, `kintXXmin`, and `kuintXXmax` with their standard C++ equivalents from `<limits>`, such as `std::numeric_limits<int32_t>::max()`. This aligns with modern C++ practices and removes dependencies on deprecated TensorFlow-specific integral type constants.\n\nPiperOrigin-RevId: 830718685",
    "sha": "e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
    "files": [
        {
            "sha": "1d23f9d87e2d7ddfe6ed3bb6d0ad2a0ccbf917e9",
            "filename": "tensorflow/cc/training/queue_runner.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcc%2Ftraining%2Fqueue_runner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcc%2Ftraining%2Fqueue_runner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcc%2Ftraining%2Fqueue_runner.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -17,7 +17,9 @@ limitations under the License.\n \n #include <chrono>\n #include <cstddef>\n+#include <cstdint>\n #include <functional>\n+#include <limits>\n #include <memory>\n \n #include \"absl/log/log.h\"\n@@ -70,7 +72,7 @@ absl::Status QueueRunner::Init(const QueueRunnerDef& queue_runner_def) {\n                            queue_runner_def.enqueue_op_name().begin(),\n                            queue_runner_def.enqueue_op_name().end());\n   size_t op_names_size = enqueue_op_names_.size();\n-  if (op_names_size > kint32max) {\n+  if (op_names_size > std::numeric_limits<int32_t>::max()) {\n     return absl::Status(absl::StatusCode::kInvalidArgument,\n                         \"Enqueue ops to run cannot exceed kint32max\");\n   }"
        },
        {
            "sha": "d1bf00a53d1cc30763ddd54fe4f78acac657e1d0",
            "filename": "tensorflow/compiler/tf2tensorrt/utils/trt_lru_cache.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcompiler%2Ftf2tensorrt%2Futils%2Ftrt_lru_cache.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcompiler%2Ftf2tensorrt%2Futils%2Ftrt_lru_cache.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2tensorrt%2Futils%2Ftrt_lru_cache.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -99,7 +99,7 @@ string TRTEngineCacheResource::DebugString() const {\n EngineContext* TRTEngineCacheResource::GetEngineContext(\n     const std::vector<TensorShape>& input_shapes) {\n   EngineContext* engine_context = nullptr;\n-  int64 min_matched_batch_size = kint64max;\n+  int64 min_matched_batch_size = std::numeric_limits<int64_t>::max();\n   for (const auto& pair : cache_) {\n     const std::vector<TensorShape>& cached_input_shapes = pair.first;\n     // This should not happen, but just for safety."
        },
        {
            "sha": "207173eb18f1ffb6fbf186ead6f818b3c58d5c63",
            "filename": "tensorflow/core/common_runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fcommon_runtime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fcommon_runtime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2FBUILD?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -1111,6 +1111,7 @@ cc_library(\n         \"//tensorflow/core:framework\",\n         \"//tensorflow/core:graph\",\n         \"//tensorflow/core:lib\",\n+        \"@com_google_absl//absl/log:check\",\n     ],\n )\n "
        },
        {
            "sha": "f84dbfac0d3f6da8529ea63b93244cdd5d009784",
            "filename": "tensorflow/core/common_runtime/graph_view.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 5,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fcommon_runtime%2Fgraph_view.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fcommon_runtime%2Fgraph_view.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fgraph_view.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include <unordered_map>\n #include <vector>\n \n+#include \"absl/log/check.h\"\n #include \"tensorflow/core/common_runtime/device.h\"\n #include \"tensorflow/core/framework/node_def_util.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n@@ -69,7 +70,7 @@ namespace {\n typedef std::tuple<int32, int32> OutputAndControlEdges;\n \n OutputAndControlEdges CountOutputEdges(const Node* n) {\n-  DCHECK_LE(n->out_edges().size(), kint32max);\n+  DCHECK_LE(n->out_edges().size(), std::numeric_limits<int32_t>::max());\n   int32_t num_output_edges = 0;\n   int32_t num_output_control_edges = 0;\n   for (auto e : n->out_edges()) {\n@@ -125,7 +126,8 @@ size_t GraphView::NodeItemBytes(const Node* n) {\n \n char* GraphView::InitializeNode(char* ptr, const Node* n) {\n   const int id = n->id();\n-  CHECK(node_offsets_[id] == kuint32max);  // Initial value in constructor\n+  CHECK(node_offsets_[id] ==\n+        std::numeric_limits<uint32_t>::max());  // Initial value in constructor\n \n   const size_t bytes = NodeItemBytes(n);\n   constexpr size_t kItemAlignment = sizeof(NodeItem*);\n@@ -137,7 +139,8 @@ char* GraphView::InitializeNode(char* ptr, const Node* n) {\n   // (versus 64 bits on most machines if we just stored an array of NodeItem*\n   // pointers). Casting to int64 is needed on 32bit CPU to avoid comparing\n   // values as \"int\" vs \"size_t\" in CHECK_LE.\n-  CHECK_LE(static_cast<int64_t>(ptr - space_), kuint32max);\n+  CHECK_LE(static_cast<int64_t>(ptr - space_),\n+           std::numeric_limits<uint32_t>::max());\n   const uint32 offset = static_cast<uint32>(ptr - space_);\n   node_offsets_[id] = offset;\n   ptr += bytes;\n@@ -252,7 +255,7 @@ absl::Status GraphView::Initialize(const Graph* g) {\n   num_nodes_ = num_nodes;\n   size_t total_bytes = 0;\n   for (const Node* n : g->nodes()) {\n-    if (n->out_edges().size() > kint32max) {\n+    if (n->out_edges().size() > std::numeric_limits<int32_t>::max()) {\n       return errors::InvalidArgument(\n           \"The executor cannot handle nodes with more than \",\n           std::numeric_limits<int32_t>::max(), \" output edges. Node \",\n@@ -263,7 +266,7 @@ absl::Status GraphView::Initialize(const Graph* g) {\n \n   node_offsets_ = new uint32[num_nodes];\n   for (int i = 0; i < num_nodes; i++) {\n-    node_offsets_[i] = kuint32max;\n+    node_offsets_[i] = std::numeric_limits<uint32_t>::max();\n   }\n \n   space_ = new char[total_bytes];  // NodeItem objects are allocated here"
        },
        {
            "sha": "3864df8a6ce165185e2715f6561ec9f115de2675",
            "filename": "tensorflow/core/common_runtime/graph_view.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fcommon_runtime%2Fgraph_view.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fcommon_runtime%2Fgraph_view.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fgraph_view.h?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -221,7 +221,7 @@ class GraphView {\n     DCHECK_GE(id, 0);\n     DCHECK_LT(id, num_nodes_);\n     uint32 offset = node_offsets_[id];\n-    return ((offset == kuint32max)\n+    return ((offset == std::numeric_limits<uint32_t>::max())\n                 ? nullptr\n                 : reinterpret_cast<NodeItem*>(space_ + node_offsets_[id]));\n   }\n@@ -233,7 +233,7 @@ class GraphView {\n     DCHECK_GE(id, 0);\n     DCHECK_LT(id, num_nodes_);\n     uint32 offset = node_offsets_[id];\n-    DCHECK_NE(offset, kuint32max);\n+    DCHECK_NE(offset, std::numeric_limits<uint32_t>::max());\n     return *reinterpret_cast<NodeItem*>(space_ + node_offsets_[id]);\n   }\n "
        },
        {
            "sha": "f733c905fe7d6e35f1bd5e43550785eb45d6596c",
            "filename": "tensorflow/core/data/compression_utils.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fcompression_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fcompression_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fcompression_utils.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -15,6 +15,8 @@ limitations under the License.\n #include \"tensorflow/core/data/compression_utils.h\"\n \n #include <cstddef>\n+#include <cstdint>\n+#include <limits>\n #include <string>\n #include <vector>\n \n@@ -123,7 +125,7 @@ absl::Status CompressElement(const std::vector<Tensor>& element,\n     }\n   }\n \n-  if (iov.NumBytes() > kuint32max) {\n+  if (iov.NumBytes() > std::numeric_limits<uint32_t>::max()) {\n     return errors::OutOfRange(\"Encountered dataset element of size \",\n                               iov.NumBytes(),\n                               \", exceeding the 4GB Snappy limit.\");"
        },
        {
            "sha": "1a79089fbccc0f9c9dacab1045db6ecc3cb653ce",
            "filename": "tensorflow/core/data/service/client/data_service_client.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fservice%2Fclient%2Fdata_service_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fservice%2Fclient%2Fdata_service_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fservice%2Fclient%2Fdata_service_client.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -119,7 +119,7 @@ absl::Status DataServiceClient::Initialize(\n           << \" in tf.data service client.\";\n   dispatcher_ = std::make_unique<DataServiceDispatcherClient>(params_.address,\n                                                               params_.protocol);\n-  int64_t deadline_micros = kint64max;\n+  int64_t deadline_micros = std::numeric_limits<int64_t>::max();\n   std::optional<std::string> job_name;\n   if (!params_.job_name.empty()) {\n     job_name = params_.job_name;\n@@ -668,7 +668,7 @@ void DataServiceClient::RunWorkerThread(std::function<void()> done)\n       }\n       VLOG(3) << \"Processing task \" << task_to_process->info.task_id();\n     }\n-    int64_t deadline_micros = kint64max;\n+    int64_t deadline_micros = std::numeric_limits<int64_t>::max();\n     absl::Status s = GetElementTraced(task_to_process.get(), deadline_micros,\n                                       /*enqueue_result=*/!IsCoordinatedRead(),\n                                       allow_skip, result);"
        },
        {
            "sha": "c06acb3e332ddfcb20a327fe85af939a23aa1dc2",
            "filename": "tensorflow/core/data/service/dispatcher_client.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fservice%2Fdispatcher_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fservice%2Fdispatcher_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fservice%2Fdispatcher_client.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -379,9 +379,9 @@ absl::Status DataServiceDispatcherClient::DisableCompressionAtRuntime(\n }\n \n absl::Status DataServiceDispatcherClient::EnsureInitialized() {\n-  return grpc_util::Retry([this] { return Initialize(); },\n-                          \"Initialize dispatcher client\",\n-                          /*deadline_micros=*/kint64max);\n+  return grpc_util::Retry(\n+      [this] { return Initialize(); }, \"Initialize dispatcher client\",\n+      /*deadline_micros=*/std::numeric_limits<int64_t>::max());\n }\n \n }  // namespace data"
        },
        {
            "sha": "6dfd18f7a293b837b4b8af60bc4574f8de9398ce",
            "filename": "tensorflow/core/data/service/task_runner.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fservice%2Ftask_runner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fservice%2Ftask_runner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fservice%2Ftask_runner.h?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -291,7 +291,7 @@ class RoundRobinTaskRunner : public TaskRunner {\n       requests_ TF_GUARDED_BY(mu_);\n   // Index of the first round we plan to serve. At startup, this is the minimum\n   // of all requested element indices.\n-  int64_t first_round_ TF_GUARDED_BY(mu_) = kint64max;\n+  int64_t first_round_ TF_GUARDED_BY(mu_) = std::numeric_limits<int64_t>::max();\n   int64_t current_round_ TF_GUARDED_BY(mu_) = -1;\n   bool round_skipped_ TF_GUARDED_BY(mu_) = false;\n   // Buffered results for the current round."
        },
        {
            "sha": "f5978a573b24e479ec476f6d0bbb9d9f797a7bfb",
            "filename": "tensorflow/core/data/service/worker_impl.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fservice%2Fworker_impl.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fservice%2Fworker_impl.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fservice%2Fworker_impl.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n #include \"tensorflow/core/data/service/worker_impl.h\"\n \n #include <cstdint>\n+#include <limits>\n #include <memory>\n #include <optional>\n #include <string>\n@@ -183,9 +184,9 @@ absl::Status DataServiceWorkerImpl::Start(\n     mutex_lock l(mu_);\n     return !cancelled_;\n   };\n-  TF_RETURN_IF_ERROR(grpc_util::Retry([this]() { return Heartbeat(); },\n-                                      should_retry, \"Worker heartbeat.\",\n-                                      /*deadline_micros=*/kint64max));\n+  TF_RETURN_IF_ERROR(grpc_util::Retry(\n+      [this]() { return Heartbeat(); }, should_retry, \"Worker heartbeat.\",\n+      /*deadline_micros=*/std::numeric_limits<int64_t>::max()));\n   LOG(INFO) << \"Worker registered with dispatcher running at \"\n             << config_.dispatcher_address()\n             << \". Worker config: \" << config_.DebugString();\n@@ -248,10 +249,10 @@ DataServiceWorkerImpl::CreateDispatcherClient() const TF_LOCKS_EXCLUDED(mu_) {\n     mutex_lock l(mu_);\n     return !cancelled_;\n   };\n-  TF_RETURN_IF_ERROR(\n-      grpc_util::Retry([&dispatcher]() { return dispatcher->Initialize(); },\n-                       should_retry, \"Initialize dispatcher client.\",\n-                       /*deadline_micros=*/kint64max));\n+  TF_RETURN_IF_ERROR(grpc_util::Retry(\n+      [&dispatcher]() { return dispatcher->Initialize(); }, should_retry,\n+      \"Initialize dispatcher client.\",\n+      /*deadline_micros=*/std::numeric_limits<int64_t>::max()));\n   return dispatcher;\n }\n "
        },
        {
            "sha": "44eda7649af7cc5834afab919c1a99f6991b1ea8",
            "filename": "tensorflow/core/data/split_utils.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fsplit_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdata%2Fsplit_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fsplit_utils.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n #include <cstddef>\n #include <cstdint>\n #include <functional>\n+#include <limits>\n #include <memory>\n #include <string>\n #include <utility>"
        },
        {
            "sha": "5935465711a02e33a6c6c1cdd6d407bdc005aca2",
            "filename": "tensorflow/core/distributed_runtime/scheduler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdistributed_runtime%2Fscheduler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fdistributed_runtime%2Fscheduler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fscheduler.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include \"tensorflow/core/distributed_runtime/scheduler.h\"\n \n+#include <limits>\n #include <queue>\n \n #include \"tensorflow/core/common_runtime/device.h\"\n@@ -280,7 +281,7 @@ Microseconds GreedyScheduler::ComputeSchedule(\n const Node* GreedyScheduler::GetNodeWithHighestPriority(\n     const std::vector<const Node*>& nodes) {\n   const Node* curr_node = nullptr;\n-  int64_t curr_priority = kint64max;\n+  int64_t curr_priority = std::numeric_limits<int64_t>::max();\n   for (const Node* n : nodes) {\n     if ((*priority_)[n->id()] < curr_priority) {\n       curr_node = n;"
        },
        {
            "sha": "9b81a620120cab95fd6a44b6a9b7aa526bb58248",
            "filename": "tensorflow/core/framework/shape_inference.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fframework%2Fshape_inference.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fframework%2Fshape_inference.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fframework%2Fshape_inference.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n #include \"tensorflow/core/framework/shape_inference.h\"\n \n #include <cstdint>\n+#include <limits>\n #include <memory>\n \n #include \"tensorflow/core/framework/bounds_check.h\""
        },
        {
            "sha": "2db5464941f6b92abeb196b9c516fdd8b248f97d",
            "filename": "tensorflow/core/framework/tensor_shape.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fframework%2Ftensor_shape.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fframework%2Ftensor_shape.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fframework%2Ftensor_shape.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -229,8 +229,8 @@ absl::Status TensorShapeBase<Shape>::InitDims(\n     absl::Span<const int64_t> dim_sizes) {\n   DCHECK_EQ(tag(), REP16);\n \n-  // Allow sizes that are under kint64max^0.25 so that 4-way multiplication\n-  // below cannot overflow.\n+  // Allow sizes that are under std::numeric_limits<int64_t>::max()^0.25 so that\n+  // 4-way multiplication below cannot overflow.\n   static const int64_t kMaxSmall = 0xd744;\n   static_assert(kMaxSmall * kMaxSmall * kMaxSmall * kMaxSmall <=\n                     std::numeric_limits<int64_t>::max(),"
        },
        {
            "sha": "f11c7391930d191396f52ccee63b42e4df2fe00c",
            "filename": "tensorflow/core/grappler/costs/utils.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fgrappler%2Fcosts%2Futils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fgrappler%2Fcosts%2Futils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Fcosts%2Futils.h?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -16,6 +16,8 @@ limitations under the License.\n #ifndef TENSORFLOW_CORE_GRAPPLER_COSTS_UTILS_H_\n #define TENSORFLOW_CORE_GRAPPLER_COSTS_UTILS_H_\n \n+#include <cstdint>\n+#include <limits>\n #include <string>\n #include <unordered_map>\n #include <vector>\n@@ -104,7 +106,7 @@ class TensorSizeHistogram {\n   uint64 sum_elem_ = 0;\n   // min_ and max_ are initialized to a very large value and zero, respectively,\n   // so that any value added can replace the initial min_ and max_.\n-  uint64 min_ = kuint64max;\n+  uint64_t min_ = std::numeric_limits<uint64_t>::max();\n   uint64 max_ = 0;\n   // Buckets are logarithmic:\n   // 0B, 1B, 2-3B, 4-7B, 8-15B, ..., 2^N - 2^(N+1)-1B, ..."
        },
        {
            "sha": "0e1cbc6b9aeed47cc3a6bca28098fae93e4634e8",
            "filename": "tensorflow/core/grappler/optimizers/constant_folding.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 22,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fconstant_folding.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fconstant_folding.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fconstant_folding.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -17,7 +17,9 @@ limitations under the License.\n \n #include \"tensorflow/core/grappler/optimizers/constant_folding.h\"\n \n+#include <algorithm>\n #include <cmath>\n+#include <limits>\n #include <utility>\n \n #include \"absl/status/status.h\"\n@@ -1267,28 +1269,28 @@ absl::Status ConstantFolding::CreateNodeDef(const string& name,\n   // Use the packed representation whenever possible to avoid generating large\n   // graphdefs. Moreover, avoid repeating the last values if they're equal.\n   if (tensor->NumElements() > 4) {\n-#define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)         \\\n-  {                                                               \\\n-    const auto* val_ptr = tensor->flat<TYPE>().data();            \\\n-    auto last = *val_ptr;                                         \\\n-    int64_t last_index = 0;                                       \\\n-    for (int64_t i = 0; i < tensor->NumElements(); ++i) {         \\\n-      TYPE cur = *val_ptr++;                                      \\\n-      if (PackedValuesNotEqual(cur, last)) {                      \\\n-        last = cur;                                               \\\n-        last_index = i;                                           \\\n-      }                                                           \\\n-    }                                                             \\\n-    encoded_size = (last_index + 1) * sizeof(FIELDTYPE);          \\\n-    if (encoded_size < kint32max) {                               \\\n-      optimized = true;                                           \\\n-      t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);    \\\n-      const auto* src_ptr = tensor->flat<TYPE>().data();          \\\n-      auto* dst_ptr = t->mutable_##FIELDTYPE##_val()              \\\n-                          -> AddNAlreadyReserved(last_index + 1); \\\n-      std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);      \\\n-    }                                                             \\\n-  }                                                               \\\n+#define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)                      \\\n+  {                                                                            \\\n+    const auto* val_ptr = tensor->flat<TYPE>().data();                         \\\n+    auto last = *val_ptr;                                                      \\\n+    int64_t last_index = 0;                                                    \\\n+    for (int64_t i = 0; i < tensor->NumElements(); ++i) {                      \\\n+      TYPE cur = *val_ptr++;                                                   \\\n+      if (PackedValuesNotEqual(cur, last)) {                                   \\\n+        last = cur;                                                            \\\n+        last_index = i;                                                        \\\n+      }                                                                        \\\n+    }                                                                          \\\n+    encoded_size = (last_index + 1) * sizeof(FIELDTYPE);                       \\\n+    if (encoded_size < std::numeric_limits<int32_t>::max()) {                  \\\n+      optimized = true;                                                        \\\n+      t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);                 \\\n+      const auto* src_ptr = tensor->flat<TYPE>().data();                       \\\n+      auto* dst_ptr =                                                          \\\n+          t->mutable_##FIELDTYPE##_val()->AddNAlreadyReserved(last_index + 1); \\\n+      std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);                   \\\n+    }                                                                          \\\n+  }                                                                            \\\n   break\n \n     switch (tensor->dtype()) {"
        },
        {
            "sha": "1ddb54cd5c3f08a0ecfa2d939c1527afd621997e",
            "filename": "tensorflow/core/kernels/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2FBUILD?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -2458,6 +2458,7 @@ cc_library(\n         \"//tensorflow/core:lib\",\n         \"//tensorflow/core:lib_internal\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/log:check\",\n     ],\n )\n "
        },
        {
            "sha": "607d434ec4fa1fbaf0765202a8273044165feeb1",
            "filename": "tensorflow/core/kernels/data/experimental/random_dataset_op.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Frandom_dataset_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Frandom_dataset_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Frandom_dataset_op.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -14,6 +14,9 @@ limitations under the License.\n ==============================================================================*/\n #include \"tensorflow/core/kernels/data/experimental/random_dataset_op.h\"\n \n+#include <cstdint>\n+#include <limits>\n+#include <memory>\n #include <string>\n #include <utility>\n \n@@ -84,7 +87,8 @@ class RandomDatasetOp::Dataset : public DatasetBase {\n     // These splits aren't actually used during iteration.\n     // TODO(aaudibert): Avoid sending dummy splits over RPC when using tf.data\n     // service with RandomDataset.\n-    split_providers->push_back(std::make_unique<IndexSplitProvider>(kint64max));\n+    split_providers->push_back(std::make_unique<IndexSplitProvider>(\n+        std::numeric_limits<int64_t>::max()));\n     return absl::OkStatus();\n   }\n "
        },
        {
            "sha": "2641c447a1624996a278191346e36bb309adf786",
            "filename": "tensorflow/core/kernels/data/range_dataset_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fdata%2Frange_dataset_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fdata%2Frange_dataset_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Frange_dataset_op.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -14,8 +14,10 @@ limitations under the License.\n ==============================================================================*/\n #include \"tensorflow/core/kernels/data/range_dataset_op.h\"\n \n+#include <cstdint>\n #include <cstdlib>\n #include <functional>\n+#include <limits>\n #include <optional>\n #include <string>\n #include <utility>\n@@ -73,7 +75,7 @@ int64_t sgn(int64_t val) { return (0 < val) - (val < 0); }\n \n int64_t RangeCardinality(int64_t start, int64_t stop, int64_t step) {\n   // `enumerate` uses int max to simulate an infinite range dataset.\n-  if (stop >= tsl::kint64max) {\n+  if (stop >= std::numeric_limits<int64_t>::max()) {\n     return kInfiniteCardinality;\n   }\n "
        },
        {
            "sha": "4cac7f8f1be68a80c2e7f6105cdca6e482a01bd6",
            "filename": "tensorflow/core/kernels/gather_op.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fgather_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fgather_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fgather_op.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -82,9 +82,12 @@ class GatherOp : public OpKernel {\n                     absl::InvalidArgumentError(\"axis must be int32 or int64.\"));\n       }\n     }\n-    // special case to avoid checkfail when axis = kint64max.\n-    OP_REQUIRES(c, axis < std::numeric_limits<int64_t>::max(),\n-                absl::InvalidArgumentError(\"axis must be less than kint64max\"));\n+    // special case to avoid checkfail when axis =\n+    // std::numeric_limits<int64_t>::max().\n+    OP_REQUIRES(\n+        c, axis < std::numeric_limits<int64_t>::max(),\n+        absl::InvalidArgumentError(\n+            \"axis must be less than std::numeric_limits<int64_t>::max()\"));\n \n     int64_t min_params_dim = axis < 0 ? -axis : axis + 1;\n     OP_REQUIRES(c, params.dims() >= min_params_dim,"
        },
        {
            "sha": "820f921c167400f5be060f1a3578d1718ac9c032",
            "filename": "tensorflow/core/kernels/linalg/linalg_ops_common.h",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Flinalg_ops_common.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Flinalg_ops_common.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Flinalg_ops_common.h?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -102,8 +102,9 @@ class LinearAlgebraOp : public OpKernel {\n     double m = static_cast<double>(input_matrix_shapes[0].dim_size(0));\n     double n = static_cast<double>(input_matrix_shapes[0].dim_size(1));\n     double cost = std::max(m, n) * std::min(m, n) * std::min(m, n);\n-    return cost >= static_cast<double>(kint64max) ? kint64max\n-                                                  : static_cast<int64_t>(cost);\n+    return cost >= static_cast<double>(std::numeric_limits<int64_t>::max())\n+               ? std::numeric_limits<int64_t>::max()\n+               : static_cast<int64_t>(cost);\n   }\n \n   // Returns true if it is safe to forward (alias) input to output buffer"
        },
        {
            "sha": "a59f5de7c223821b35e6aa2643909eb85b08dbbc",
            "filename": "tensorflow/core/kernels/linalg/lu_op.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Flu_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Flu_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Flu_op.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include <cstdint>\n+#include <limits>\n \n #include \"absl/container/inlined_vector.h\"\n #include \"Eigen/Core\"  // from @eigen_archive\n@@ -61,8 +62,9 @@ class LuOp : public OpKernel {\n   int64_t GetCostPerUnit(const TensorShape& input_matrix_shape) const {\n     double num_rows = static_cast<double>(input_matrix_shape.dim_size(0));\n     double cost = (2 / 3.0) * MathUtil::IPow(num_rows, 3);\n-    return cost >= static_cast<double>(kint64max) ? kint64max\n-                                                  : static_cast<int64_t>(cost);\n+    return cost >= static_cast<double>(std::numeric_limits<int64_t>::max())\n+               ? std::numeric_limits<int64_t>::max()\n+               : static_cast<int64_t>(cost);\n   }\n \n   void Compute(OpKernelContext* context) override {"
        },
        {
            "sha": "97088a08d65019463cf382939f0ada25bc1ea855",
            "filename": "tensorflow/core/kernels/linalg/matrix_solve_ls_op_impl.h",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_ls_op_impl.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_ls_op_impl.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_ls_op_impl.h?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -18,6 +18,8 @@ limitations under the License.\n \n // See docs in ../ops/linalg_ops.cc.\n \n+#include <limits>\n+\n #include \"Eigen/Cholesky\"  // from @eigen_archive\n #include \"Eigen/Core\"  // from @eigen_archive\n #include \"Eigen/QR\"  // from @eigen_archive\n@@ -67,8 +69,9 @@ class MatrixSolveLsOp : public LinearAlgebraOp<Scalar> {\n     double n = static_cast<double>(input_matrix_shapes[0].dim_size(1));\n     double num_rhss = static_cast<double>(input_matrix_shapes[1].dim_size(1));\n     double cost = std::max(m, n) * std::min(m, n) * (std::min(m, n) + num_rhss);\n-    return cost >= static_cast<double>(kint64max) ? kint64max\n-                                                  : static_cast<int64_t>(cost);\n+    return cost >= static_cast<double>(std::numeric_limits<int64_t>::max())\n+               ? std::numeric_limits<int64_t>::max()\n+               : static_cast<int64_t>(cost);\n   }\n \n   bool EnableInputForwarding() const final { return false; }"
        },
        {
            "sha": "8ccd74cb9d2eac778fb809a1db9e00c7f72e9b7b",
            "filename": "tensorflow/core/kernels/linalg/matrix_solve_op.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_op.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n #define EIGEN_USE_GPU\n #endif\n \n+#include <limits>\n #include <numeric>\n \n #include \"Eigen/Core\"  // from @eigen_archive\n@@ -66,8 +67,9 @@ class MatrixSolveOp : public LinearAlgebraOp<Scalar> {\n     double rows = static_cast<double>(input_matrix_shapes[0].dim_size(0));\n     double num_rhss = static_cast<double>(input_matrix_shapes[1].dim_size(1));\n     double cost = rows * rows * (rows + num_rhss);\n-    return cost >= static_cast<double>(kint64max) ? kint64max\n-                                                  : static_cast<int64_t>(cost);\n+    return cost >= static_cast<double>(std::numeric_limits<int64_t>::max())\n+               ? std::numeric_limits<int64_t>::max()\n+               : static_cast<int64_t>(cost);\n   }\n \n   bool EnableInputForwarding() const final { return false; }"
        },
        {
            "sha": "7dfa1122e4d99bd5981a2a23cdb4cf14a5f7bdb5",
            "filename": "tensorflow/core/kernels/linalg/qr_op_impl.h",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fqr_op_impl.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fqr_op_impl.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fqr_op_impl.h?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n // individual kernels. A separate file is used for each instantiated kernel to\n // improve compilation times.\n #include <algorithm>\n+#include <limits>\n #include <numeric>\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n@@ -89,8 +90,9 @@ class QrOp : public LinearAlgebraOp<Scalar> {\n                   2 * min_size * min_size * min_size / 3.;\n     // TODO(jpoulson): Increase the cost if full_matrices is true in a manner\n     // that reflects the algorithm used for the expansion.\n-    return cost >= static_cast<double>(kint64max) ? kint64max\n-                                                  : static_cast<int64_t>(cost);\n+    return cost >= static_cast<double>(std::numeric_limits<int64_t>::max())\n+               ? std::numeric_limits<int64_t>::max()\n+               : static_cast<int64_t>(cost);\n   }\n \n   using Matrix = typename Base::Matrix;"
        },
        {
            "sha": "b63b99a7e6de965ccbd1e8e78519ab4f94496eab",
            "filename": "tensorflow/core/kernels/linalg/svd_op_impl.h",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fsvd_op_impl.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fsvd_op_impl.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fsvd_op_impl.h?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n // individual kernels. A separate file is used for each instantiated kernel to\n // improve compilation times.\n #include <algorithm>\n+#include <limits>\n \n #include \"Eigen/SVD\"  // from @eigen_archive\n #include \"tensorflow/core/framework/kernel_def_builder.h\"\n@@ -72,8 +73,9 @@ class SvdOp : public LinearAlgebraOp<Scalar> {\n     double m = static_cast<double>(input_matrix_shapes[0].dim_size(0));\n     double n = static_cast<double>(input_matrix_shapes[0].dim_size(1));\n     double cost = 12 * std::max(m, n) * std::min(m, n) * std::min(m, n);\n-    return cost >= static_cast<double>(kint64max) ? kint64max\n-                                                  : static_cast<int64_t>(cost);\n+    return cost >= static_cast<double>(std::numeric_limits<int64_t>::max())\n+               ? std::numeric_limits<int64_t>::max()\n+               : static_cast<int64_t>(cost);\n   }\n \n   using Matrix = typename Base::Matrix;"
        },
        {
            "sha": "5e83c65b538491d233151ded01cb32316ac5c10a",
            "filename": "tensorflow/core/kernels/linalg/tridiagonal_matmul_op.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Ftridiagonal_matmul_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Ftridiagonal_matmul_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Ftridiagonal_matmul_op.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n // See docs in ../ops/linalg_ops.cc.\n \n #include <cstdint>\n+#include <limits>\n \n #include \"tensorflow/core/framework/kernel_def_builder.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n@@ -75,8 +76,9 @@ class TridiagonalMatMulOp : public LinearAlgebraOp<Scalar> {\n \n     const double cost = num_rhss * ((3 * num_eqs - 2) * mult_cost +\n                                     (2 * num_eqs - 2) * add_cost);\n-    return cost >= static_cast<double>(kint64max) ? kint64max\n-                                                  : static_cast<int64_t>(cost);\n+    return cost >= static_cast<double>(std::numeric_limits<int64_t>::max())\n+               ? std::numeric_limits<int64_t>::max()\n+               : static_cast<int64_t>(cost);\n   }\n \n   // Needed to prevent writing result to the same location where input is."
        },
        {
            "sha": "a10391c693df5fab98fd1dba60d29265224a8a56",
            "filename": "tensorflow/core/kernels/linalg/tridiagonal_solve_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Ftridiagonal_solve_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Flinalg%2Ftridiagonal_solve_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Ftridiagonal_solve_op.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -104,8 +104,9 @@ class TridiagonalSolveOp : public LinearAlgebraOp<Scalar> {\n       cost = num_eqs * (div_cost * (num_rhss + 1) +\n                         (add_cost + mult_cost) * (2 * num_rhss + 1));\n     }\n-    return cost >= static_cast<double>(kint64max) ? kint64max\n-                                                  : static_cast<int64_t>(cost);\n+    return cost >= static_cast<double>(std::numeric_limits<int64_t>::max())\n+               ? std::numeric_limits<int64_t>::max()\n+               : static_cast<int64_t>(cost);\n   }\n \n   bool EnableInputForwarding() const final { return false; }"
        },
        {
            "sha": "9d0fc7530ae8893512d3e6b7b57ee69bca018d18",
            "filename": "tensorflow/core/kernels/population_count_op.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fpopulation_count_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fpopulation_count_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpopulation_count_op.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -18,10 +18,11 @@ limitations under the License.\n \n #define EIGEN_USE_THREADS\n \n-#include <bitset>\n-\n #include \"tensorflow/core/kernels/population_count_op.h\"\n \n+#include <bitset>\n+#include <limits>\n+\n #include \"unsupported/Eigen/CXX11/Tensor\"  // from @eigen_archive\n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/register_types.h\"\n@@ -114,9 +115,10 @@ struct PopulationCount<CPUDevice, T> {\n     // (bitset.count() -> output).  The .count() itself is relatively cheap.\n     const double total_cost = (Eigen::TensorOpCost::CastCost<T, uint8>() +\n                                Eigen::TensorOpCost::CastCost<int64_t, uint8>());\n-    const int64_t shard_cost = (total_cost >= static_cast<double>(kint64max))\n-                                   ? kint64max\n-                                   : static_cast<int64_t>(total_cost);\n+    const int64_t shard_cost =\n+        (total_cost >= static_cast<double>(std::numeric_limits<int64_t>::max()))\n+            ? std::numeric_limits<int64_t>::max()\n+            : static_cast<int64_t>(total_cost);\n \n     auto worker_threads = *(c->device()->tensorflow_cpu_worker_threads());\n     Shard(worker_threads.num_threads, worker_threads.workers, total_shards,"
        },
        {
            "sha": "db4f97c3e925de15f9e89f0cbb3ed0fadd8fb18e",
            "filename": "tensorflow/core/kernels/range_sampler.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 5,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Frange_sampler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Frange_sampler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Frange_sampler.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -15,10 +15,14 @@ limitations under the License.\n \n #include \"tensorflow/core/kernels/range_sampler.h\"\n \n+#include <algorithm>\n #include <cmath>\n+#include <cstdint>\n+#include <limits>\n #include <vector>\n \n #include \"absl/container/flat_hash_set.h\"\n+#include \"absl/log/check.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/lib/gtl/map_util.h\"\n #include \"tensorflow/core/lib/io/inputbuffer.h\"\n@@ -90,7 +94,7 @@ void RangeSampler::SampleBatchGetExpectedCountAvoid(\n     num_tries = 0;\n     while (num_picked < batch_size) {\n       num_tries++;\n-      CHECK_LT(num_tries, kint32max);\n+      CHECK_LT(num_tries, std::numeric_limits<int32_t>::max());\n       int64_t value = Sample(rnd);\n       if (gtl::InsertIfNotPresent(&used, value)) {\n         batch[num_picked++] = value;\n@@ -178,7 +182,7 @@ float LogUniformSampler::Probability(int64_t value) const {\n \n ThreadUnsafeUnigramSampler::ThreadUnsafeUnigramSampler(int64_t range)\n     : RangeSampler(range), picker_(range) {\n-  CHECK_LT(range, kint32max);\n+  CHECK_LT(range, std::numeric_limits<int32_t>::max());\n }\n \n int64_t ThreadUnsafeUnigramSampler::Sample(random::SimplePhilox* rnd) const {\n@@ -190,8 +194,9 @@ float ThreadUnsafeUnigramSampler::Probability(int64_t value) const {\n }\n \n void ThreadUnsafeUnigramSampler::Update(absl::Span<const int64_t> values) {\n-  int num_updates = std::min(static_cast<int>(values.size()),\n-                             kint32max - picker_.total_weight());\n+  int num_updates =\n+      std::min(static_cast<int>(values.size()),\n+               std::numeric_limits<int32_t>::max() - picker_.total_weight());\n   for (int i = 0; i < num_updates; i++) {\n     const int64_t value = values[i];\n     picker_.set_weight(value, picker_.get_weight(value) + 1);\n@@ -201,7 +206,7 @@ void ThreadUnsafeUnigramSampler::Update(absl::Span<const int64_t> values) {\n // Thread-safe unigram sampler\n UnigramSampler::UnigramSampler(int64_t range)\n     : RangeSampler(range), unsafe_sampler_(range) {\n-  CHECK_LT(range, kint32max);\n+  CHECK_LT(range, std::numeric_limits<int32_t>::max());\n }\n \n int64_t UnigramSampler::Sample(random::SimplePhilox* rnd) const {"
        },
        {
            "sha": "2461dbca7efb93c7b1172210377c3c4a68045810",
            "filename": "tensorflow/core/kernels/segment_reduction_ops_impl.h",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fsegment_reduction_ops_impl.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fsegment_reduction_ops_impl.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsegment_reduction_ops_impl.h?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n #include <cmath>\n #include <cstddef>\n #include <cstdint>\n+#include <limits>\n #include <type_traits>\n #include <vector>\n \n@@ -576,7 +577,9 @@ class SparseSegmentReductionOpBase : public OpKernel {\n     // sorted.\n     const SegmentId last_segment_id =\n         num_indices > 0 ? segment_vec(num_indices - 1) : 0;\n-    int64_t limit = dtidx_ == DataType::DT_INT32 ? kint32max : kint64max;\n+    int64_t limit = dtidx_ == DataType::DT_INT32\n+                        ? std::numeric_limits<int32_t>::max()\n+                        : std::numeric_limits<int64_t>::max();\n \n     OP_REQUIRES(\n         context, last_segment_id < limit,"
        },
        {
            "sha": "bc2334590b4eef8246aeef1b6bbde77c40c72ac1",
            "filename": "tensorflow/core/kernels/shuffle_common.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fshuffle_common.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fshuffle_common.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fshuffle_common.h?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -19,7 +19,9 @@ limitations under the License.\n #define TENSORFLOW_CORE_KERNELS_SHUFFLE_COMMON_H_\n \n #include <algorithm>\n+#include <cstdint>\n #include <functional>\n+#include <limits>\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor_util.h\"\n@@ -87,7 +89,7 @@ absl::Status RandomShuffle(\n           context->allocate_output(output_idx, input.shape(), &output));\n       const auto input_mat = input.flat_outer_dims<T>();\n       auto output_mat = output->flat_outer_dims<T>();\n-      if (size < kint32max) {\n+      if (size < std::numeric_limits<int32_t>::max()) {\n         IndexedShuffle<int32>(size, input_mat, output_mat, uniform);\n       } else {\n         IndexedShuffle<int64_t>(size, input_mat, output_mat, uniform);"
        },
        {
            "sha": "2da0fcc1ad3f7d6100c9b709b6d212cc277f911c",
            "filename": "tensorflow/core/kernels/string_ngrams_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fstring_ngrams_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Fstring_ngrams_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fstring_ngrams_op.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -14,6 +14,8 @@ limitations under the License.\n ==============================================================================*/\n \n #include <algorithm>\n+#include <cstdint>\n+#include <limits>\n #include <locale>\n #include <string>\n \n@@ -52,7 +54,7 @@ class StringNGramsOp : public tensorflow::OpKernel {\n \n   absl::StatusOr<int> get_num_ngrams(const int length,\n                                      const int ngram_width) const {\n-    int64 limit = kint32max;\n+    int64_t limit = std::numeric_limits<int32_t>::max();\n     int pad_width = get_pad_width(ngram_width);\n     if (pad_width > limit / 2 - length) {\n       return errors::InvalidArgument("
        },
        {
            "sha": "ab8ddccd15bfeb3752a8250aaafe8adf8a32c57f",
            "filename": "tensorflow/core/kernels/tile_functor_gpu.h",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Ftile_functor_gpu.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Ftile_functor_gpu.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftile_functor_gpu.h?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -51,9 +51,11 @@ template <typename T>\n void TileSimple(const Eigen::GpuDevice& d, Tensor* out, const Tensor& in) {\n   // Ensures we can use 32-bit index.\n   const int64 in_nelem = in.NumElements();\n-  CHECK_LT(in_nelem, kint32max) << \"Tensor too large to transpose on GPU\";\n+  CHECK_LT(in_nelem, std::numeric_limits<int32_t>::max())\n+      << \"Tensor too large to transpose on GPU\";\n   const int64 out_nelem = out->NumElements();\n-  CHECK_LT(out_nelem, kint32max) << \"Tensor too large to transpose on GPU\";\n+  CHECK_LT(out_nelem, std::numeric_limits<int32_t>::max())\n+      << \"Tensor too large to transpose on GPU\";\n   // Pack strides and input dimension sizes into one buffer.\n   const int32 ndims = in.dims();\n   gtl::InlinedVector<int32, 24> host_buf(ndims * 3);"
        },
        {
            "sha": "64f4d2d33c50d445e34ebb1356eaa471f6dc6752",
            "filename": "tensorflow/core/kernels/transpose_functor_gpu.cu.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Ftranspose_functor_gpu.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Ftranspose_functor_gpu.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftranspose_functor_gpu.cu.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -67,7 +67,8 @@ void TransposeSimple(const GPUDevice& d, const Tensor& in,\n                      const gtl::ArraySlice<int32> perm, Tensor* out) {\n   // Ensures we can use 32-bit index.\n   const int64 nelem = in.NumElements();\n-  CHECK_LT(nelem, kint32max) << \"Tensor too large to transpose on GPU\";\n+  CHECK_LT(nelem, std::numeric_limits<int32_t>::max())\n+      << \"Tensor too large to transpose on GPU\";\n   // Pack strides and permutation into one buffer.\n   const int32 ndims = in.dims();\n   GpuLaunchConfig cfg = GetGpuLaunchConfig(nelem, d);"
        },
        {
            "sha": "dd9447444deac37c1f948c08c0d4547664d2e83f",
            "filename": "tensorflow/core/kernels/unravel_index_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Funravel_index_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fkernels%2Funravel_index_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Funravel_index_op.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include <cstdint>\n+#include <limits>\n \n #include \"tensorflow/core/framework/types.pb.h\"\n #include \"tensorflow/core/platform/types.h\"\n@@ -64,9 +65,9 @@ class UnravelIndexOp : public OpKernel {\n     double prod = 1;\n     uint64_t limit;\n     if (dtidx_ == DataType::DT_INT64) {\n-      limit = kint64max;\n+      limit = std::numeric_limits<int64_t>::max();\n     } else {\n-      limit = kint32max;\n+      limit = std::numeric_limits<int32_t>::max();\n     }\n \n     for (int i = 0; i < dims.size(); i++) {"
        },
        {
            "sha": "41db93ae910a186fc0715297761cf0722f9ce5d1",
            "filename": "tensorflow/core/lib/wav/wav_io.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 6,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Flib%2Fwav%2Fwav_io.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Flib%2Fwav%2Fwav_io.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Flib%2Fwav%2Fwav_io.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include <string.h>\n \n #include <algorithm>\n+#include <cstdint>\n \n #include \"absl/base/casts.h\"\n #include \"tensorflow/core/lib/core/coding.h\"\n@@ -74,8 +75,9 @@ constexpr char kDataChunkId[] = \"data\";\n \n inline int16 FloatToInt16Sample(float data) {\n   constexpr float kMultiplier = 1.0f * (1 << 15);\n-  return std::min<float>(std::max<float>(roundf(data * kMultiplier), kint16min),\n-                         kint16max);\n+  return std::min<float>(std::max<float>(roundf(data * kMultiplier),\n+                                         std::numeric_limits<int16_t>::min()),\n+                         std::numeric_limits<int16_t>::max());\n }\n \n inline float Int16SampleToFloat(int16_t data) {\n@@ -156,11 +158,12 @@ absl::Status EncodeAudioAsS16LEWav(const float* audio, size_t sample_rate,\n   if (wav_string == nullptr) {\n     return errors::InvalidArgument(\"wav_string is null\");\n   }\n-  if (sample_rate == 0 || sample_rate > kuint32max) {\n+  if (sample_rate == 0 || sample_rate > std::numeric_limits<uint32_t>::max()) {\n     return errors::InvalidArgument(\"sample_rate must be in (0, 2^32), got: \",\n                                    sample_rate);\n   }\n-  if (num_channels == 0 || num_channels > kuint16max) {\n+  if (num_channels == 0 ||\n+      num_channels > std::numeric_limits<uint16_t>::max()) {\n     return errors::InvalidArgument(\"num_channels must be in (0, 2^16), got: \",\n                                    num_channels);\n   }\n@@ -172,8 +175,8 @@ absl::Status EncodeAudioAsS16LEWav(const float* audio, size_t sample_rate,\n   const size_t bytes_per_frame = kBytesPerSample * num_channels;\n \n   // WAV represents the length of the file as a uint32 so file_size cannot\n-  // exceed kuint32max.\n-  if (file_size > kuint32max) {\n+  // exceed std::numeric_limits<uint32_t>::max().\n+  if (file_size > std::numeric_limits<uint32_t>::max()) {\n     return errors::InvalidArgument(\n         \"Provided channels and frames cannot be encoded as a WAV.\");\n   }"
        },
        {
            "sha": "dfc75257cc85f57c9e4276b5242c3bb8bd31fb36",
            "filename": "tensorflow/core/lib/wav/wav_io_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Flib%2Fwav%2Fwav_io_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Flib%2Fwav%2Fwav_io_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Flib%2Fwav%2Fwav_io_test.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -15,6 +15,9 @@ limitations under the License.\n \n #include \"tensorflow/core/lib/wav/wav_io.h\"\n \n+#include <cstddef>\n+#include <cstdint>\n+#include <limits>\n #include <string>\n \n #include \"tensorflow/core/lib/core/status_test_util.h\"\n@@ -45,8 +48,10 @@ TEST(WavIO, BadArguments) {\n       error::INVALID_ARGUMENT,\n       EncodeAudioAsS16LEWav(audio, 44100, 2, 3, (tstring*)nullptr).code());\n \n-  const size_t kuint32max_plus_one = static_cast<size_t>(kuint32max) + 1;\n-  const size_t kuint16max_plus_one = static_cast<size_t>(kuint16max) + 1;\n+  const size_t kuint32max_plus_one =\n+      static_cast<size_t>(std::numeric_limits<uint32_t>::max()) + 1;\n+  const size_t kuint16max_plus_one =\n+      static_cast<size_t>(std::numeric_limits<uint16_t>::max()) + 1;\n \n   // Zero values are invalid.\n   EXPECT_EQ(error::INVALID_ARGUMENT,"
        },
        {
            "sha": "0213914a564647aba3dd87605b9068230586f94e",
            "filename": "tensorflow/core/ops/array_ops.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fops%2Farray_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fcore%2Fops%2Farray_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fops%2Farray_ops.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include <algorithm>\n+#include <limits>\n #include <ostream>\n #include <vector>\n "
        },
        {
            "sha": "f276b676285f08af13f8e030924c787c1adf907f",
            "filename": "tensorflow/python/data/experimental/service/server_lib_wrapper.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fservice%2Fserver_lib_wrapper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fservice%2Fserver_lib_wrapper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fservice%2Fserver_lib_wrapper.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -130,7 +130,7 @@ PYBIND11_MODULE(_pywrap_server_lib, m) {\n          const std::string& protocol) -> tensorflow::data::DataServiceMetadata {\n         tensorflow::data::DataServiceMetadata metadata;\n         tensorflow::data::DataServiceDispatcherClient client(address, protocol);\n-        int64_t deadline_micros = tensorflow::kint64max;\n+        int64_t deadline_micros = std::numeric_limits<int64_t>::max();\n         absl::Status status;\n         Py_BEGIN_ALLOW_THREADS;\n         status = tensorflow::data::grpc_util::Retry("
        },
        {
            "sha": "b7142c5e2f56750ed33978fca01f8d2fb8437669",
            "filename": "third_party/xla/third_party/tsl/tsl/platform/integral_types_test.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 9,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fintegral_types_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fintegral_types_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fintegral_types_test.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -13,6 +13,9 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include <cstdint>\n+#include <limits>\n+\n #include \"xla/tsl/platform/test.h\"\n #include \"xla/tsl/platform/types.h\"\n \n@@ -32,15 +35,19 @@ TEST(IntegralTypes, Basic) {\n }\n \n TEST(IntegralTypes, MinAndMaxConstants) {\n-  EXPECT_EQ(static_cast<uint8>(kint8min), static_cast<uint8>(kint8max) + 1);\n-  EXPECT_EQ(static_cast<uint16>(kint16min), static_cast<uint16>(kint16max) + 1);\n-  EXPECT_EQ(static_cast<uint32>(kint32min), static_cast<uint32>(kint32max) + 1);\n-  EXPECT_EQ(static_cast<uint64>(kint64min), static_cast<uint64>(kint64max) + 1);\n-\n-  EXPECT_EQ(0, static_cast<uint8>(kuint8max + 1));\n-  EXPECT_EQ(0, static_cast<uint16>(kuint16max + 1));\n-  EXPECT_EQ(0, static_cast<uint32>(kuint32max + 1));\n-  EXPECT_EQ(0, static_cast<uint64>(kuint64max + 1));\n+  EXPECT_EQ(static_cast<uint8_t>(std::numeric_limits<int8_t>::min()),\n+            static_cast<uint8_t>(std::numeric_limits<int8_t>::max()) + 1);\n+  EXPECT_EQ(static_cast<uint16_t>(std::numeric_limits<int16_t>::min()),\n+            static_cast<uint16_t>(std::numeric_limits<int16_t>::max()) + 1);\n+  EXPECT_EQ(static_cast<uint32_t>(std::numeric_limits<int32_t>::min()),\n+            static_cast<uint32_t>(std::numeric_limits<int32_t>::max()) + 1);\n+  EXPECT_EQ(static_cast<uint64_t>(std::numeric_limits<int64_t>::min()),\n+            static_cast<uint64_t>(std::numeric_limits<int64_t>::max()) + 1);\n+\n+  EXPECT_EQ(0, static_cast<uint8_t>(std::numeric_limits<uint8_t>::max() + 1));\n+  EXPECT_EQ(0, static_cast<uint16_t>(std::numeric_limits<uint16_t>::max() + 1));\n+  EXPECT_EQ(0, static_cast<uint32_t>(std::numeric_limits<uint32_t>::max() + 1));\n+  EXPECT_EQ(0, static_cast<uint64_t>(std::numeric_limits<uint64_t>::max() + 1));\n }\n \n }  // namespace"
        },
        {
            "sha": "db94c24766767ce8fbe7986abdf16385e8e41fdc",
            "filename": "third_party/xla/third_party/tsl/tsl/platform/numbers_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fnumbers_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fnumbers_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fnumbers_test.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -206,9 +206,9 @@ TEST(safe_strto64, Int64s) {\n   EXPECT_EQ(true, absl::SimpleAtoi(\"9223372036854775807\", &result));\n   EXPECT_EQ(9223372036854775807, result);\n   EXPECT_EQ(true, absl::SimpleAtoi(\"-9223372036854775808\", &result));\n-  // kint64min == -9223372036854775808\n+  // std::numeric_limits<int64_t>::min() == -9223372036854775808\n   // Use -9223372036854775808 directly results in out of range error\n-  EXPECT_EQ(kint64min, result);\n+  EXPECT_EQ(std::numeric_limits<int64_t>::min(), result);\n \n   // Invalid argument\n   EXPECT_EQ(false, absl::SimpleAtoi(\" 132as \", &result));"
        },
        {
            "sha": "04e03a9c0d73406bb3027501be21d1c8352be54c",
            "filename": "third_party/xla/xla/tsl/lib/math/math_util_test.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 9,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Fmath%2Fmath_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Fmath%2Fmath_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Fmath%2Fmath_util_test.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"xla/tsl/lib/math/math_util.h\"\n \n #include <cmath>\n+#include <cstdint>\n #include <limits>\n #include <vector>\n \n@@ -185,18 +186,23 @@ void TestThatCeilOfRatioDenomMinusOneIsIncorrect() {\n   // It does not work with negative values\n   TestThatCeilOfRatioDenomMinusOneIsIncorrect(-1LL, -2LL, -1LL);\n \n-  // This would also fail if given kint64max because of signed integer overflow.\n+  // This would also fail if given std::numeric_limits<int64_t>::max() because\n+  // of signed integer overflow.\n }\n \n TEST(MathUtil, CeilOfRatio) {\n-  TestCeilOfRatioUnsigned<uint8>(kuint8max);\n-  TestCeilOfRatioUnsigned<uint16>(kuint16max);\n-  TestCeilOfRatioUnsigned<uint32>(kuint32max);\n-  TestCeilOfRatioUnsigned<uint64>(kuint64max);\n-  TestCeilOfRatioSigned<int8>(kint8min, kint8max);\n-  TestCeilOfRatioSigned<int16>(kint16min, kint16max);\n-  TestCeilOfRatioSigned<int32>(kint32min, kint32max);\n-  TestCeilOfRatioSigned<int64_t>(kint64min, kint64max);\n+  TestCeilOfRatioUnsigned<uint8_t>(std::numeric_limits<uint8_t>::max());\n+  TestCeilOfRatioUnsigned<uint16_t>(std::numeric_limits<uint16_t>::max());\n+  TestCeilOfRatioUnsigned<uint32_t>(std::numeric_limits<uint32_t>::max());\n+  TestCeilOfRatioUnsigned<uint64_t>(std::numeric_limits<uint64_t>::max());\n+  TestCeilOfRatioSigned<int8_t>(std::numeric_limits<int8_t>::min(),\n+                                std::numeric_limits<int8_t>::max());\n+  TestCeilOfRatioSigned<int16_t>(std::numeric_limits<int16_t>::min(),\n+                                 std::numeric_limits<int16_t>::max());\n+  TestCeilOfRatioSigned<int32_t>(std::numeric_limits<int32_t>::min(),\n+                                 std::numeric_limits<int32_t>::max());\n+  TestCeilOfRatioSigned<int64_t>(std::numeric_limits<int64_t>::min(),\n+                                 std::numeric_limits<int64_t>::max());\n #if 0\n   TestThatCeilOfRatioDenomMinusOneIsIncorrect();\n #endif"
        },
        {
            "sha": "36a6c1c1fd8c858d547e2f2cbeff97672e5b7138",
            "filename": "third_party/xla/xla/tsl/lib/random/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Frandom%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Frandom%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Frandom%2FBUILD?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -164,6 +164,7 @@ tsl_cc_test(\n         \"//xla/tsl/platform:test_benchmark\",\n         \"//xla/tsl/platform:test_main\",\n         \"//xla/tsl/platform:types\",\n+        \"@com_google_absl//absl/log:check\",\n     ],\n )\n "
        },
        {
            "sha": "4cbff0d5fcfec747a2fe698fa270c49db26d1905",
            "filename": "third_party/xla/xla/tsl/lib/random/distribution_sampler_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Frandom%2Fdistribution_sampler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Frandom%2Fdistribution_sampler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Frandom%2Fdistribution_sampler_test.cc?ref=e8f2b2f7065db48eff2d5a0ed5e058e37abf2a1a",
            "patch": "@@ -17,9 +17,12 @@ limitations under the License.\n \n #include <string.h>\n \n+#include <cstdint>\n+#include <limits>\n #include <memory>\n #include <vector>\n \n+#include \"absl/log/check.h\"\n #include \"xla/tsl/lib/random/simple_philox.h\"\n #include \"xla/tsl/platform/macros.h\"\n #include \"xla/tsl/platform/test.h\"\n@@ -96,7 +99,7 @@ static void BM_DistributionSampler(::testing::benchmark::State& state) {\n   for (auto s : state) {\n     r |= picker.Sample(&rand);\n   }\n-  CHECK_NE(r, kint32max);\n+  CHECK_NE(r, std::numeric_limits<int32_t>::max());\n }\n \n BENCHMARK(BM_DistributionSampler)->Arg(10)->Arg(100)->Arg(1000);"
        }
    ],
    "stats": {
        "total": 321,
        "additions": 203,
        "deletions": 118
    }
}