{
    "author": "penpornk",
    "message": "[xla:cpu:onednn] Remove INTEL_MKL ifdef guards from oneDNN primitive calls.\n\n* onednn_matmul\n* onednn_convolution\n* onednn_layer_norm\n* onednn_softmax\n\n+ Fix ClangTidy/Linter errors/warnings.\n\nPiperOrigin-RevId: 812127555",
    "sha": "4e6b6311fcd4bb412a7a25bfbac71d591cff10f0",
    "files": [
        {
            "sha": "2c594be187b50db5fd2edca83d01f31c7422f998",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 10,
            "deletions": 21,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=4e6b6311fcd4bb412a7a25bfbac71d591cff10f0",
            "patch": "@@ -1748,7 +1748,7 @@ onednn_cc_library(\n     ],\n )\n \n-cc_library(\n+onednn_cc_library(\n     name = \"onednn_matmul\",\n     srcs = [\"onednn_matmul.cc\"],\n     hdrs = [\"onednn_matmul.h\"],\n@@ -1761,20 +1761,21 @@ cc_library(\n         \":onednn_util\",\n         \":runtime_lightweight_check\",\n         \"//xla:executable_run_options\",\n+        \"//xla:literal\",\n         \"//xla:shape_util\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/tsl/mkl:onednn\",\n+        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:core_headers\",\n-        \"@com_google_absl//absl/base:dynamic_annotations\",\n-        \"@com_google_absl//absl/synchronization\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/types:span\",\n         \"@eigen_archive//:eigen3\",\n-        \"@local_tsl//tsl/platform:env\",\n-        \"@local_tsl//tsl/platform:logging\",\n         \"@local_tsl//tsl/platform:platform_port\",\n     ],\n )\n \n-cc_library(\n+onednn_cc_library(\n     name = \"onednn_convolution\",\n     srcs = [\"onednn_convolution.cc\"],\n     hdrs = [\"onednn_convolution.h\"],\n@@ -1791,16 +1792,12 @@ cc_library(\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/tsl/mkl:onednn\",\n         \"@com_google_absl//absl/base:core_headers\",\n-        \"@com_google_absl//absl/base:dynamic_annotations\",\n-        \"@com_google_absl//absl/synchronization\",\n+        \"@com_google_absl//absl/status:statusor\",\n         \"@eigen_archive//:eigen3\",\n-        \"@local_tsl//tsl/platform:env\",\n-        \"@local_tsl//tsl/platform:logging\",\n-        \"@local_tsl//tsl/platform:platform_port\",\n     ],\n )\n \n-cc_library(\n+onednn_cc_library(\n     name = \"onednn_layer_norm\",\n     srcs = [\"onednn_layer_norm.cc\"],\n     hdrs = [\n@@ -1818,15 +1815,13 @@ cc_library(\n         \"//xla/tsl/mkl:onednn\",\n         \"//xla/tsl/platform:env\",\n         \"@com_google_absl//absl/base:core_headers\",\n-        \"@com_google_absl//absl/base:dynamic_annotations\",\n         \"@com_google_absl//absl/synchronization\",\n         \"@eigen_archive//:eigen3\",\n-        \"@local_tsl//tsl/platform:env\",\n         \"@local_tsl//tsl/platform:platform_port\",\n     ],\n )\n \n-cc_library(\n+onednn_cc_library(\n     name = \"onednn_softmax\",\n     srcs = [\"onednn_softmax.cc\"],\n     hdrs = [\n@@ -1844,10 +1839,8 @@ cc_library(\n         \"//xla/tsl/mkl:onednn\",\n         \"//xla/tsl/platform:env\",\n         \"@com_google_absl//absl/base:core_headers\",\n-        \"@com_google_absl//absl/base:dynamic_annotations\",\n         \"@com_google_absl//absl/synchronization\",\n         \"@eigen_archive//:eigen3\",\n-        \"@local_tsl//tsl/platform:env\",\n         \"@local_tsl//tsl/platform:platform_port\",\n     ],\n )\n@@ -1860,7 +1853,6 @@ onednn_cc_library(\n         \":onednn_util\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:pattern_matcher\",\n-        \"//xla/tsl/mkl:onednn\",\n     ],\n )\n \n@@ -1885,17 +1877,14 @@ cc_library(\n         \"//xla:executable_run_options\",\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n-        \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/evaluator:hlo_evaluator\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/pass:hlo_pass\",\n         \"//xla/service:hlo_cost_analysis\",\n-        \"//xla/service:hlo_creation_utils\",\n         \"//xla/service:pattern_matcher\",\n         \"//xla/tsl/mkl:onednn\",\n         \"//xla/tsl/platform:env\",\n         \"@com_google_absl//absl/algorithm:container\",\n-        \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/synchronization\",\n         \"@eigen_archive//:eigen3\",\n         \"@local_tsl//tsl/platform:env\","
        },
        {
            "sha": "44e07bb0ba8db4678eadb742df22271257f33c9c",
            "filename": "third_party/xla/xla/service/cpu/onednn_convolution.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 15,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_convolution.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_convolution.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_convolution.cc?ref=4e6b6311fcd4bb412a7a25bfbac71d591cff10f0",
            "patch": "@@ -13,41 +13,41 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#if defined(INTEL_MKL)\n-\n #include \"xla/service/cpu/onednn_convolution.h\"\n \n-#include <algorithm>\n-#include <cmath>\n-#include <cstring>\n+#include <cstdint>\n #include <initializer_list>\n-#include <iterator>\n+#include <memory>\n+#include <unordered_map>\n #include <utility>\n #include <vector>\n \n-#include \"absl/base/dynamic_annotations.h\"\n+#include \"absl/base/attributes.h\"\n+#include \"absl/status/statusor.h\"\n #include \"unsupported/Eigen/CXX11/Tensor\"\n-#include \"dnnl.hpp\"\n+#include \"oneapi/dnnl/dnnl.hpp\"\n+#include \"oneapi/dnnl/dnnl_common.hpp\"\n #include \"oneapi/dnnl/dnnl_threadpool.hpp\"\n+#include \"oneapi/dnnl/dnnl_types.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/service/cpu/backend_config.pb.h\"\n #include \"xla/service/cpu/onednn_config.pb.h\"\n #include \"xla/service/cpu/onednn_memory_util.h\"\n #include \"xla/service/cpu/onednn_util.h\"\n #include \"xla/service/cpu/runtime_lightweight_check.h\"\n #include \"xla/shape.h\"\n-#include \"xla/shape_util.h\"\n #include \"xla/tsl/util/onednn_threadpool.h\"\n-#include \"tsl/platform/cpu_info.h\"\n-#include \"tsl/platform/logging.h\"\n \n #define EIGEN_USE_THREADS\n \n namespace xla {\n namespace cpu {\n namespace {\n+\n using dnnl::algorithm;\n using dnnl::convolution_forward;\n using dnnl::memory;\n@@ -58,7 +58,9 @@ memory::dims GetPrimitiveParameter(\n     const tsl::protobuf::RepeatedField<uint64_t>& field, int offset) {\n   memory::dims param_field(field.begin(), field.end());\n   // Subtract the offset so that values are interpreted accurately\n-  for (int64_t& n : param_field) n -= offset;\n+  for (int64_t& n : param_field) {\n+    n -= offset;\n+  }\n   return param_field;\n }\n \n@@ -69,7 +71,9 @@ std::vector<int> ComputePermutations(\n   perm_axes[dim0] = 0;\n   perm_axes[dim1] = 1;\n   int index = 2;\n-  for (uint64_t n : spatial_dims) perm_axes[n - 1] = index++;\n+  for (uint64_t n : spatial_dims) {\n+    perm_axes[n - 1] = index++;\n+  }\n   return perm_axes;\n }\n \n@@ -373,5 +377,3 @@ ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_OneDnnConvolution(\n \n }  // namespace cpu\n }  // namespace xla\n-\n-#endif  // INTEL_MKL"
        },
        {
            "sha": "df07a1d182c36839b4762e46fe0c8843d2e21936",
            "filename": "third_party/xla/xla/service/cpu/onednn_convolution.h",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_convolution.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_convolution.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_convolution.h?ref=4e6b6311fcd4bb412a7a25bfbac71d591cff10f0",
            "patch": "@@ -15,7 +15,6 @@ limitations under the License.\n \n #ifndef XLA_SERVICE_CPU_ONEDNN_CONVOLUTION_H_\n #define XLA_SERVICE_CPU_ONEDNN_CONVOLUTION_H_\n-#if defined(INTEL_MKL)\n \n #include \"xla/service/cpu/onednn_util.h\"\n \n@@ -38,5 +37,4 @@ struct PrimitiveTrait<kOnednnConvConfig> {\n }  // namespace cpu\n }  // namespace xla\n \n-#endif  // INTEL_MKL\n #endif  // XLA_SERVICE_CPU_ONEDNN_CONVOLUTION_H_"
        },
        {
            "sha": "d8d2061cb4a2eacdd4bb77183953e7ca5be1a637",
            "filename": "third_party/xla/xla/service/cpu/onednn_layer_norm.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 11,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_layer_norm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_layer_norm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_layer_norm.cc?ref=4e6b6311fcd4bb412a7a25bfbac71d591cff10f0",
            "patch": "@@ -13,38 +13,38 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#if defined(INTEL_MKL)\n-\n #include \"xla/service/cpu/onednn_layer_norm.h\"\n \n-#include <algorithm>\n-#include <cmath>\n-#include <initializer_list>\n-#include <vector>\n+#include <cstdint>\n+#include <string>\n+#include <unordered_map>\n \n #define EIGEN_USE_THREADS\n \n-#include \"absl/base/dynamic_annotations.h\"\n-#include \"dnnl.hpp\"\n+#include \"absl/base/attributes.h\"\n #include \"oneapi/dnnl/dnnl_threadpool.hpp\"\n+#include \"oneapi/dnnl/dnnl_types.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/service/cpu/backend_config.pb.h\"\n #include \"xla/service/cpu/onednn_config.pb.h\"\n #include \"xla/service/cpu/onednn_memory_util.h\"\n #include \"xla/service/cpu/runtime_lightweight_check.h\"\n #include \"xla/tsl/util/onednn_threadpool.h\"\n-// Below must come after `onednn_threadpool.h`\n+\n+// Eigen Tensor must come after `onednn_threadpool.h`\n #include \"unsupported/Eigen/CXX11/Tensor\"  // NOLINT\n \n namespace xla {\n namespace cpu {\n namespace {\n+\n using dnnl::engine;\n using dnnl::layer_normalization_forward;\n using dnnl::memory;\n using dnnl::normalization_flags;\n using dnnl::prop_kind;\n using dnnl::stream;\n+\n }  // namespace\n \n ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_OneDnnLayerNorm(\n@@ -105,5 +105,3 @@ ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_OneDnnLayerNorm(\n \n }  // namespace cpu\n }  // namespace xla\n-\n-#endif  // INTEL_MKL"
        },
        {
            "sha": "167e20a51a00294b714cf0194975dcb1a95f50b2",
            "filename": "third_party/xla/xla/service/cpu/onednn_layer_norm.h",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_layer_norm.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_layer_norm.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_layer_norm.h?ref=4e6b6311fcd4bb412a7a25bfbac71d591cff10f0",
            "patch": "@@ -15,7 +15,6 @@ limitations under the License.\n \n #ifndef XLA_SERVICE_CPU_ONEDNN_LAYER_NORM_H_\n #define XLA_SERVICE_CPU_ONEDNN_LAYER_NORM_H_\n-#if defined(INTEL_MKL)\n \n namespace xla {\n namespace cpu {\n@@ -27,5 +26,4 @@ extern void __xla_cpu_runtime_OneDnnLayerNorm(void* result, void** args);\n }  // namespace cpu\n }  // namespace xla\n \n-#endif  // INTEL_MKL\n #endif  // XLA_SERVICE_CPU_ONEDNN_LAYER_NORM_H_"
        },
        {
            "sha": "76d64a37203b77dbcb2343df6839ebfa70d1b86f",
            "filename": "third_party/xla/xla/service/cpu/onednn_matmul.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 10,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_matmul.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_matmul.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_matmul.cc?ref=4e6b6311fcd4bb412a7a25bfbac71d591cff10f0",
            "patch": "@@ -12,38 +12,50 @@ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n-#if defined(INTEL_MKL)\n+\n #include \"xla/service/cpu/onednn_matmul.h\"\n \n #include <algorithm>\n-#include <cmath>\n+#include <cstdint>\n #include <cstring>\n #include <initializer_list>\n #include <iterator>\n+#include <memory>\n+#include <numeric>\n+#include <string>\n+#include <unordered_map>\n #include <utility>\n #include <vector>\n \n-#include \"absl/base/dynamic_annotations.h\"\n+#include \"absl/algorithm/container.h\"\n+#include \"absl/base/attributes.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/types/span.h\"\n #include \"unsupported/Eigen/CXX11/Tensor\"\n-#include \"dnnl.hpp\"\n+#include \"oneapi/dnnl/dnnl.hpp\"\n+#include \"oneapi/dnnl/dnnl_common.hpp\"\n+#include \"oneapi/dnnl/dnnl_types.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/literal.h\"\n #include \"xla/service/cpu/backend_config.pb.h\"\n #include \"xla/service/cpu/onednn_config.pb.h\"\n+#include \"xla/service/cpu/onednn_memory_util.h\"\n #include \"xla/service/cpu/onednn_util.h\"\n #include \"xla/service/cpu/runtime_lightweight_check.h\"\n #include \"xla/shape.h\"\n-#include \"xla/shape_util.h\"\n-#include \"xla/tsl/util/onednn_threadpool.h\"\n #include \"tsl/platform/cpu_info.h\"\n-#include \"tsl/platform/logging.h\"\n \n #define EIGEN_USE_THREADS\n \n namespace xla {\n namespace cpu {\n namespace {\n+\n using dnnl::engine;\n using dnnl::matmul;\n using dnnl::memory;\n@@ -53,7 +65,9 @@ using dnnl::stream;\n void TransposeIfNecessary(\n     const tsl::protobuf::RepeatedField<uint64_t> dimensions,\n     bool transpose_last_2_dims, dnnl::memory::desc& mem_desc) {\n-  if (mem_desc.get_ndims() < 2) return;\n+  if (mem_desc.get_ndims() < 2) {\n+    return;\n+  }\n   std::vector<int> permutation(mem_desc.get_ndims());\n   std::iota(permutation.begin(), permutation.end(), 0);\n   int counter = 0;\n@@ -503,5 +517,3 @@ ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_OneDnnMatMulReorder(\n \n }  // namespace cpu\n }  // namespace xla\n-\n-#endif  // INTEL_MKL"
        },
        {
            "sha": "abf6bc6cea4c491d3e6e7a9d3bb76ede0a0671f5",
            "filename": "third_party/xla/xla/service/cpu/onednn_matmul.h",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_matmul.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_matmul.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_matmul.h?ref=4e6b6311fcd4bb412a7a25bfbac71d591cff10f0",
            "patch": "@@ -15,9 +15,7 @@ limitations under the License.\n \n #ifndef XLA_SERVICE_CPU_ONEDNN_MATMUL_H_\n #define XLA_SERVICE_CPU_ONEDNN_MATMUL_H_\n-#if defined(INTEL_MKL)\n \n-#include \"dnnl.hpp\"\n #include \"xla/service/cpu/backend_config.pb.h\"\n #include \"xla/service/cpu/onednn_memory_util.h\"\n #include \"xla/service/cpu/onednn_util.h\"\n@@ -57,5 +55,4 @@ struct PrimitiveTrait<kOnednnMatmulConfig> {\n }  // namespace cpu\n }  // namespace xla\n \n-#endif  // INTEL_MKL\n #endif  // XLA_SERVICE_CPU_ONEDNN_MATMUL_H_"
        },
        {
            "sha": "703dfeb5ab43747441f66f8874d24b17a0d3b5b0",
            "filename": "third_party/xla/xla/service/cpu/onednn_softmax.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 9,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_softmax.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_softmax.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_softmax.cc?ref=4e6b6311fcd4bb412a7a25bfbac71d591cff10f0",
            "patch": "@@ -12,17 +12,17 @@ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n-#if defined(INTEL_MKL)\n+\n #include \"xla/service/cpu/onednn_softmax.h\"\n \n-#include <algorithm>\n-#include <cmath>\n-#include <initializer_list>\n-#include <vector>\n+#include <string>\n+#include <unordered_map>\n \n-#include \"absl/base/dynamic_annotations.h\"\n-#include \"dnnl.hpp\"\n+#include \"absl/base/attributes.h\"\n+#include \"oneapi/dnnl/dnnl.hpp\"\n+#include \"oneapi/dnnl/dnnl_common.hpp\"\n #include \"oneapi/dnnl/dnnl_threadpool.hpp\"\n+#include \"oneapi/dnnl/dnnl_types.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/service/cpu/backend_config.pb.h\"\n #include \"xla/service/cpu/onednn_config.pb.h\"\n@@ -82,5 +82,3 @@ ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_OneDnnSoftmax(\n \n }  // namespace cpu\n }  // namespace xla\n-\n-#endif  // INTEL_MKL"
        },
        {
            "sha": "90f423da6d0094b76ef6c6695b958807670f1b2e",
            "filename": "third_party/xla/xla/service/cpu/onednn_softmax.h",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_softmax.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e6b6311fcd4bb412a7a25bfbac71d591cff10f0/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_softmax.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_softmax.h?ref=4e6b6311fcd4bb412a7a25bfbac71d591cff10f0",
            "patch": "@@ -15,7 +15,6 @@ limitations under the License.\n \n #ifndef XLA_SERVICE_CPU_ONEDNN_SOFTMAX_H_\n #define XLA_SERVICE_CPU_ONEDNN_SOFTMAX_H_\n-#if defined(INTEL_MKL)\n \n namespace xla {\n namespace cpu {\n@@ -29,5 +28,4 @@ extern void __xla_cpu_runtime_OneDnnSoftmax(const void* run_options_ptr,\n }  // namespace cpu\n }  // namespace xla\n \n-#endif  // INTEL_MKL\n #endif  // XLA_SERVICE_CPU_ONEDNN_SOFTMAX_H_"
        }
    ],
    "stats": {
        "total": 140,
        "additions": 65,
        "deletions": 75
    }
}