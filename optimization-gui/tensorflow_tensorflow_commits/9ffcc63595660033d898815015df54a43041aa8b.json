{
    "author": "dsharletg",
    "message": "Add support for dot ops in YNN fusions\n\nCurrently we only have support for dots *or* fusions, this fixes that (but leaves the refactoring cleanup to a subsequent CL).\n\nPiperOrigin-RevId: 844804682",
    "sha": "9ffcc63595660033d898815015df54a43041aa8b",
    "files": [
        {
            "sha": "5229eadb70dbc9c25e12c4b6bbf7858f9bb9cada",
            "filename": "third_party/xla/xla/backends/cpu/ynn_emitter.cc",
            "status": "modified",
            "additions": 64,
            "deletions": 0,
            "changes": 64,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9ffcc63595660033d898815015df54a43041aa8b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9ffcc63595660033d898815015df54a43041aa8b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_emitter.cc?ref=9ffcc63595660033d898815015df54a43041aa8b",
            "patch": "@@ -246,6 +246,58 @@ static absl::StatusOr<uint32_t> DefineReduceOp(ynn_subgraph_t subgraph,\n   return out;\n }\n \n+static absl::StatusOr<uint32_t> DefineDotOp(ynn_subgraph_t subgraph,\n+                                            TensorIdMap& tensor_ids,\n+                                            const HloInstruction* instr) {\n+  VLOG(3) << absl::StreamFormat(\"Define tensor value for dot op: %s\",\n+                                instr->ToString());\n+  CHECK_EQ(instr->opcode(), HloOpcode::kDot);\n+  const HloInstruction* lhs = instr->operand(0);\n+  const HloInstruction* rhs = instr->operand(1);\n+  CHECK_EQ(lhs->shape().element_type(), instr->shape().element_type());\n+  CHECK_EQ(rhs->shape().element_type(), instr->shape().element_type());\n+\n+  TF_ASSIGN_OR_RETURN(auto lhs_id, FindTensorValue(tensor_ids, lhs));\n+  TF_ASSIGN_OR_RETURN(auto rhs_id, FindTensorValue(tensor_ids, rhs));\n+  TF_ASSIGN_OR_RETURN(auto output_id, DefineTensorValue(subgraph, instr));\n+\n+  const Shape& lhs_shape = lhs->shape();\n+  const Shape& rhs_shape = rhs->shape();\n+  const Shape& out_shape = instr->shape();\n+\n+  DotDimensionNumbers dot_dimensions = instr->dot_dimension_numbers();\n+  TF_ASSIGN_OR_RETURN(DotShape dot_shape, GetDotShape(dot_dimensions, lhs_shape,\n+                                                      rhs_shape, out_shape));\n+\n+  TF_ASSIGN_OR_RETURN(DotCanonicalDims dot_canonical_dims,\n+                      GetDotCanonicalDims(dot_dimensions, dot_shape));\n+\n+  const size_t b_rank = rhs_shape.dimensions().size();\n+  const bool transpose_b = !dot_canonical_dims.rhs_canonical;\n+\n+  if (transpose_b) {\n+    uint32_t rhs_id_transposed = YNN_INVALID_VALUE_ID;\n+    std::array<int32_t, YNN_MAX_TENSOR_RANK> perm;\n+    absl::c_iota(perm, 0);\n+    CHECK_LT(b_rank, YNN_MAX_TENSOR_RANK);\n+    CHECK_GE(b_rank, 2);\n+    std::swap(perm[b_rank - 1], perm[b_rank - 2]);\n+    ynn_status status = ynn_define_static_transpose(\n+        subgraph,\n+        /*num_dims=*/b_rank, perm.data(), rhs_id, &rhs_id_transposed,\n+        /*flags=*/0);\n+    if (status != ynn_status_success) {\n+      return status;\n+    }\n+    rhs_id = rhs_id_transposed;\n+  }\n+\n+  YNN_RETURN_IF_ERROR(ynn_define_dot(subgraph, /*num_k_dims=*/1, lhs_id, rhs_id,\n+                                     YNN_INVALID_VALUE_ID, &output_id,\n+                                     /*flags=*/0));\n+  return output_id;\n+}\n+\n //===----------------------------------------------------------------------===//\n // Emit YNNPACK subgraph for the given HLO computation.\n //===----------------------------------------------------------------------===//\n@@ -320,6 +372,16 @@ static absl::StatusOr<YnnSubgraph> EmitYnnSubgraph(\n                             DefineBitcastOp(subgraph.get(), tensor_ids, instr));\n       } break;\n \n+      case HloOpcode::kDot: {\n+        if (!IsDotSupportedByYnn(instr).value_or(false)) {\n+          return InvalidArgument(\n+              \"Unsupported dot instruction in YNN fusion: %s\",\n+              instr->ToString());\n+        }\n+        TF_ASSIGN_OR_RETURN(tensor_ids[instr],\n+                            DefineDotOp(subgraph.get(), tensor_ids, instr));\n+      } break;\n+\n       case HloOpcode::kReduce: {\n         TF_ASSIGN_OR_RETURN(tensor_ids[instr],\n                             DefineReduceOp(subgraph.get(), tensor_ids, instr));\n@@ -432,6 +494,8 @@ static absl::StatusOr<YnnSubgraph> EmitYnnDotSubgraph(\n     std::vector<std::unique_ptr<Literal>>& literals,\n     absl::Span<const se::DeviceAddressBase> arguments_buffers,\n     bool capture_rhs) {\n+  // TODO(b/468895209): Use the fusion emitter above instead of replicating the\n+  // logic here.\n   TF_ASSIGN_OR_RETURN(\n       YnnSubgraph subgraph, CreateYnnSubgraph([&](ynn_subgraph_t* subgraph) {\n         return ynn_create_subgraph("
        },
        {
            "sha": "949748ad1430712a7d33c613b17f8b6015d79628",
            "filename": "third_party/xla/xla/backends/cpu/ynn_support.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9ffcc63595660033d898815015df54a43041aa8b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9ffcc63595660033d898815015df54a43041aa8b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.cc?ref=9ffcc63595660033d898815015df54a43041aa8b",
            "patch": "@@ -218,6 +218,13 @@ absl::StatusOr<bool> IsDotSupportedByYnn(\n   return true;\n }\n \n+absl::StatusOr<bool> IsDotSupportedByYnn(const HloInstruction* hlo) {\n+  CHECK_EQ(hlo->opcode(), HloOpcode::kDot);\n+  return IsDotSupportedByYnn(hlo->dot_dimension_numbers(),\n+                             hlo->operand(0)->shape(), hlo->operand(1)->shape(),\n+                             hlo->shape());\n+}\n+\n bool IsReduceOpSupportedByYnn(const HloInstruction* hlo) {\n   CHECK_EQ(hlo->opcode(), HloOpcode::kReduce);\n   if (!YnnType(hlo->shape().element_type()).ok()) {"
        },
        {
            "sha": "4586126a6171870395b4966e9c9beb2d96d158f2",
            "filename": "third_party/xla/xla/backends/cpu/ynn_support.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9ffcc63595660033d898815015df54a43041aa8b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9ffcc63595660033d898815015df54a43041aa8b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.h?ref=9ffcc63595660033d898815015df54a43041aa8b",
            "patch": "@@ -64,6 +64,7 @@ bool IsElementwiseOpSupportedByYnn(const HloInstruction* hlo);\n absl::StatusOr<bool> IsDotSupportedByYnn(\n     const DotDimensionNumbers& dot_dimensions, const Shape& lhs_shape,\n     const Shape& rhs_shape, const Shape& out_shape);\n+absl::StatusOr<bool> IsDotSupportedByYnn(const HloInstruction* hlo);\n \n // Returns true if the reduce op is supported by YNNPACK.\n bool IsReduceOpSupportedByYnn(const HloInstruction* hlo);"
        },
        {
            "sha": "540a2a6f1550fa23dd2f24a37bdaa18ed3d99efc",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9ffcc63595660033d898815015df54a43041aa8b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9ffcc63595660033d898815015df54a43041aa8b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=9ffcc63595660033d898815015df54a43041aa8b",
            "patch": "@@ -539,9 +539,9 @@ auto LibrarySupportsConvolution(\n \n auto LibrarySupportsDot(HloModule* module,\n                         TargetMachineFeatures* target_machine_features) {\n-  // TODO(b/406806134): Stop calling XNNPACK from regular Dot thunks. All XNN\n-  // Dots should be wrapped in an `__xnn_fusion` fusion region and processed in\n-  // `XnnFusionThunk`.\n+  // TODO(b/468895209): Stop calling YNNPACK from regular Dot thunks. All YNN\n+  // Dots should be wrapped in an `__ynn_fusion` fusion region and processed in\n+  // `YnnFusionThunk`.\n   const bool ynnpack_dot_enabled = absl::c_linear_search(\n       module->config().debug_options().xla_cpu_experimental_ynn_fusion_type(),\n       DebugOptions::LIBRARY_FUSION_TYPE_INDIVIDUAL_DOT);"
        },
        {
            "sha": "ff6a8a4c99b947ffcf9e83fa1fde3edeb0ab36ee",
            "filename": "third_party/xla/xla/service/cpu/parallel_task_assignment_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9ffcc63595660033d898815015df54a43041aa8b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9ffcc63595660033d898815015df54a43041aa8b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment_test.cc?ref=9ffcc63595660033d898815015df54a43041aa8b",
            "patch": "@@ -247,7 +247,7 @@ TEST_F(ParallelTaskAssignmentTest, ConstantNotParallelized) {\n \n TEST_F(ParallelTaskAssignmentTest, CustomFusionUnchanged) {\n   constexpr absl::string_view hlo_string = R\"(\n-HloModule jit_xnn_bin_ops\n+HloModule jit_ynn_bin_ops\n \n fused_computation (matrix_a: f32[1000,1000], matrix_b: f32[1000,1000]) -> f32[1000,1000] {\n   matrix_a = f32[1000,1000] parameter(0)\n@@ -260,7 +260,7 @@ fused_computation (matrix_a: f32[1000,1000], matrix_b: f32[1000,1000]) -> f32[10\n ENTRY main (input_x: f32[1000,1000], input_y: f32[1000,1000]) -> f32[1000,1000] {\n   input_x = f32[1000,1000] parameter(0)\n   input_y = f32[1000,1000] parameter(1)\n-  ROOT fused_result = f32[1000,1000] fusion(input_x, input_y), kind=kCustom, calls=fused_computation, backend_config={\"outer_dimension_partitions\":[],\"fusion_config\":{\"kind\":\"__xnn_fusion\"}}\n+  ROOT fused_result = f32[1000,1000] fusion(input_x, input_y), kind=kCustom, calls=fused_computation, backend_config={\"outer_dimension_partitions\":[],\"fusion_config\":{\"kind\":\"__ynn_fusion\"}}\n }\n )\";\n "
        }
    ],
    "stats": {
        "total": 82,
        "additions": 77,
        "deletions": 5
    }
}