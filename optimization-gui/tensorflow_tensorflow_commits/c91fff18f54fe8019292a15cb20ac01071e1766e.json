{
    "author": "ezhulenev",
    "message": "[xla:cpu:nanort] Add support for unowned zero copy buffers\n\n```\nname                    cpu/op        cpu/op      vs base\nBM_IfRtAddScalars       372.1n ± 0%   351.4n ± 0%  -5.57% (n=80)\nBM_IfRtAddManyScalars   1.145µ ± 0%   1.093µ ± 1%  -4.55% (n=80)\ngeomean                 652.8n        619.8n       -5.06%\n\nname                    time/op       time/op     vs base\nBM_IfRtAddScalars       373.0n ± 0%   352.2n ± 0%  -5.59% (n=80)\nBM_IfRtAddManyScalars   1.148µ ± 0%   1.096µ ± 1%  -4.54% (n=80)\ngeomean                 654.5n        621.3n       -5.07%\n```\n\nPiperOrigin-RevId: 798314866",
    "sha": "c91fff18f54fe8019292a15cb20ac01071e1766e",
    "files": [
        {
            "sha": "c266bda4283f8bc82786c29ee6736f3305b988a0",
            "filename": "third_party/xla/xla/backends/cpu/nanort/ifrt_client.cc",
            "status": "modified",
            "additions": 90,
            "deletions": 52,
            "changes": 142,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c91fff18f54fe8019292a15cb20ac01071e1766e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c91fff18f54fe8019292a15cb20ac01071e1766e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.cc?ref=c91fff18f54fe8019292a15cb20ac01071e1766e",
            "patch": "@@ -158,29 +158,38 @@ class NanoValue : public llvm::RTTIExtends<Self, Base> {\n // multiple existing shards.\n class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n  public:\n-  // A pointer to the underlying buffer. We use a shared_ptr because for some\n-  // operations (like disassembly) we can just alias the memory, but we still\n-  // need to support deletion of the NanoArray that created the buffer.\n-  using DataPtr = std::shared_ptr<void>;\n+  // An owning pointer to the underlying buffer (can be allocated for NanoArray,\n+  // or \"owned\" via the `on_done_with_host_buffer` callback passed by the user).\n+  //\n+  // We use a shared_ptr because for some operations (like disassembly) we can\n+  // just alias the memory, but we still need to support deletion of the\n+  // NanoArray that created the buffer.\n+  //\n+  // For non-owned buffers, we simply use a `void*` pointer, that we got from\n+  // the user, and we expect that the user will keep it alive as long as needed.\n+  using OwnedDataPtr = std::shared_ptr<void>;\n \n+  // Creates a NanoArray that owns underlying data.\n   NanoArray(NanoIfrtClient* client, ifrt::DType dtype, const ifrt::Shape& shape,\n-            DataPtr data, ifrt::ShardingRef sharding)\n-      : NanoValue<NanoArray, ifrt::Array>(client),\n-        dtype_(dtype),\n-        shape_(shape),\n-        data_(std::move(data)),\n-        sharding_(std::move(sharding)) {}\n+            OwnedDataPtr owned_data, ifrt::ShardingRef sharding)\n+      : NanoArray(client, dtype, shape, owned_data.get(), std::move(owned_data),\n+                  std::move(sharding)) {}\n+\n+  // Creates a NanoArray that does not own underlying data.\n+  NanoArray(NanoIfrtClient* client, ifrt::DType dtype, const ifrt::Shape& shape,\n+            void* data, ifrt::ShardingRef sharding)\n+      : NanoArray(client, dtype, shape, data, nullptr, std::move(sharding)) {}\n \n   // Allocates a new array of the given type and shape.\n   static absl::StatusOr<tsl::RCReference<NanoArray>> Allocate(\n       NanoIfrtClient* client, ifrt::DType dtype, const ifrt::Shape& shape,\n       ifrt::ShardingRef sharding) {\n     TF_RET_CHECK(dtype.byte_size().has_value());\n     TF_ASSIGN_OR_RETURN(\n-        DataPtr data_ptr,\n+        OwnedDataPtr owned_data,\n         AllocateData(dtype.byte_size().value() * shape.num_elements()));\n-    return tsl::TakeRef(new NanoArray(client, dtype, shape, std::move(data_ptr),\n-                                      std::move(sharding)));\n+    return tsl::TakeRef(new NanoArray(\n+        client, dtype, shape, std::move(owned_data), std::move(sharding)));\n   }\n \n   // Creates an array from a host buffer. The buffer will be used directly\n@@ -191,8 +200,6 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n       const ifrt::Shape& shape, ifrt::ShardingRef sharding,\n       std::optional<absl::Span<const int64_t>> byte_strides, bool make_copy,\n       std::function<void()> on_done_with_host_buffer) {\n-    DataPtr data_ptr;\n-\n     bool layout_compatible = LayoutCompatible(dtype, shape, byte_strides);\n     bool aligned = reinterpret_cast<uintptr_t>(data) % MinAlign() == 0;\n \n@@ -202,16 +209,16 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n       int64_t size = dtype.byte_size().value_or(0) * shape.num_elements();\n       TF_RET_CHECK(size > 0);\n \n-      TF_ASSIGN_OR_RETURN(data_ptr, AllocateData(size));\n+      TF_ASSIGN_OR_RETURN(OwnedDataPtr owned_data, AllocateData(size));\n       if (layout_compatible) {\n         // Input has a compatible layout, so we can just do a memcpy.\n-        memcpy(data_ptr.get(), data, size);\n+        memcpy(owned_data.get(), data, size);\n       } else {\n         // Input has an incompatible layout, so we need to copy it with an\n         // appropriate stride.\n         TF_ASSIGN_OR_RETURN(auto dense_strides, DenseByteStrides(dtype, shape));\n         TF_RETURN_IF_ERROR(CopyWithByteStrides(\n-            reinterpret_cast<std::byte*>(data_ptr.get()), dense_strides,\n+            reinterpret_cast<std::byte*>(owned_data.get()), dense_strides,\n             reinterpret_cast<std::byte*>(data),\n             byte_strides.value_or(dense_strides), shape.dims(),\n             dtype.byte_size().value()));\n@@ -221,23 +228,29 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n       if (on_done_with_host_buffer) {\n         on_done_with_host_buffer();\n       }\n-    } else {\n-      // We're allowed to keep the input buffer, and it's dense and row major,\n-      // so we can just use it directly.\n-      data_ptr = DataPtr(\n-          data, [done = std::move(on_done_with_host_buffer)](void* ptr) {\n-            if (done) {\n-              done();\n-            }\n-          });\n+\n+      return tsl::TakeRef(new NanoArray(\n+          client, dtype, shape, std::move(owned_data), std::move(sharding)));\n+    }\n+\n+    // We can create a view into the user's buffer, but we must take ownership\n+    // of it via the provided callback.\n+    if (ABSL_PREDICT_FALSE(on_done_with_host_buffer)) {\n+      return tsl::TakeRef(new NanoArray(\n+          client, dtype, shape,\n+          OwnedDataPtr(data, [done = std::move(on_done_with_host_buffer)](\n+                                 void* ptr) { done(); }),\n+          std::move(sharding)));\n     }\n \n-    DCHECK(data_ptr) << \"data_ptr should be allocated\";\n-    return tsl::TakeRef(new NanoArray(client, dtype, shape, std::move(data_ptr),\n-                                      std::move(sharding)));\n+    // User didn't pass a callback, so we can assume that it will keep the data\n+    // alive for as long as it needs to be.\n+    return tsl::TakeRef(\n+        new NanoArray(client, dtype, shape, data, std::move(sharding)));\n   }\n \n-  const DataPtr& data() const { return data_; }\n+  void* data() const { return data_; }\n+  const OwnedDataPtr& owned_data() const { return owned_data_; }\n \n   // Copies a sub-array of the given size from src to dst. The dst array must\n   // already be allocated and of the correct type and shape. Values outside of\n@@ -295,7 +308,7 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n         stride *= array.shape().dims()[i];\n       }\n       offset *= element_size;\n-      return static_cast<std::byte*>(array.data().get()) + offset;\n+      return static_cast<std::byte*>(array.data()) + offset;\n     };\n \n     // Get the pointers to the start of the rows we're copying.\n@@ -327,9 +340,9 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n       for (auto* device : sharding().devices()->devices()) {\n         auto one_device_sharding = ifrt::SingleDeviceSharding::Create(\n             device, sharding().memory_kind());\n-        shards.push_back(\n-            tsl::TakeRef(new NanoArray(nano_client(), dtype_, shape_, data_,\n-                                       std::move(one_device_sharding))));\n+        shards.push_back(tsl::TakeRef(\n+            new NanoArray(nano_client(), dtype_, shape_, data_, owned_data_,\n+                          std::move(one_device_sharding))));\n       }\n       return shards;\n     }\n@@ -362,28 +375,31 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n \n   NanoRtExecutable::Argument AsArgument() {\n     return NanoRtExecutable::Argument(\n-        reinterpret_cast<std::byte*>(data_.get()),\n+        reinterpret_cast<std::byte*>(data_),\n         dtype_.byte_size().value() * shape_.num_elements());\n   }\n \n   NanoRtExecutable::Result AsResult() {\n     return NanoRtExecutable::Result(\n-        reinterpret_cast<std::byte*>(data_.get()),\n+        reinterpret_cast<std::byte*>(data_),\n         dtype_.byte_size().value() * shape_.num_elements());\n   }\n \n   std::string DebugString() const override {\n     return absl::StrCat(\"NanoArray(\", dtype_.DebugString(), \", \",\n                         shape_.DebugString(), \", @\",\n-                        reinterpret_cast<uintptr_t>(data_.get()), \")\");\n+                        reinterpret_cast<uintptr_t>(data_), \")\");\n   }\n \n   ifrt::Future<> Delete() override {\n     data_ = nullptr;\n+    owned_data_ = nullptr;\n     return Ready();\n   }\n \n-  bool IsDeleted() const override { return data_ == nullptr; }\n+  bool IsDeleted() const override {\n+    return data_ == nullptr && owned_data_ == nullptr;\n+  }\n \n   ifrt::DType dtype() const override { return dtype_; }\n \n@@ -425,15 +441,15 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n       if (ABSL_PREDICT_TRUE(!byte_strides.has_value() ||\n                             HasMajorToMinorLayout(xla_dtype, shape().dims(),\n                                                   *byte_strides))) {\n-        memcpy(data, data_.get(),\n+        memcpy(data, data_,\n                dtype().byte_size().value() * shape().num_elements());\n       } else {\n         TF_ASSIGN_OR_RETURN(auto in_strides,\n                             DenseByteStrides(dtype(), shape()));\n         TF_RETURN_IF_ERROR(CopyWithByteStrides(\n             reinterpret_cast<std::byte*>(data), *byte_strides,\n-            reinterpret_cast<std::byte*>(data_.get()), in_strides,\n-            shape().dims(), dtype().byte_size().value()));\n+            reinterpret_cast<std::byte*>(data_), in_strides, shape().dims(),\n+            dtype().byte_size().value()));\n       }\n       return absl::OkStatus();\n     }());\n@@ -442,6 +458,22 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n   static char ID;  // NOLINT\n \n  private:\n+  friend class ::xla::cpu::NanoIfrtClient;\n+\n+  NanoArray(NanoIfrtClient* client, ifrt::DType dtype, const ifrt::Shape& shape,\n+            void* data, OwnedDataPtr owned_data, ifrt::ShardingRef sharding)\n+      : NanoValue<NanoArray, ifrt::Array>(client),\n+        dtype_(dtype),\n+        shape_(shape),\n+        data_(data),\n+        owned_data_(std::move(owned_data)),\n+        sharding_(std::move(sharding)) {\n+    if (owned_data_) {\n+      DCHECK_EQ(data_, owned_data_.get())\n+          << \"`data_` must point to the buffer owned by `owned_data_`\";\n+    }\n+  }\n+\n   // Returns true if the given data type, shape, and strides are compatible\n   // with NanoArray (we can either use this memory directly or memcpy it into\n   // our own memory).\n@@ -475,18 +507,18 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n   }\n \n   // Allocates an aligned buffer of the given size.\n-  static absl::StatusOr<DataPtr> AllocateData(size_t size) {\n-    DataPtr data_ptr(\n+  static absl::StatusOr<OwnedDataPtr> AllocateData(size_t size) {\n+    OwnedDataPtr owned_data(\n         tsl::port::AlignedMalloc(std::max<size_t>(size, Align()), Align()),\n         [](void* ptr) { tsl::port::AlignedFree(ptr); });\n-    if (ABSL_PREDICT_FALSE(data_ptr == nullptr)) {\n+    if (ABSL_PREDICT_FALSE(owned_data.get() == nullptr)) {\n       return Internal(\"Failed to allocate memory for NanoArray. Errno: %s\",\n                       strerror(errno));\n     }\n     // Suppress msan warnings for memory that will be initialized by the\n     // jit-compiled code.\n-    ABSL_ANNOTATE_MEMORY_IS_INITIALIZED(data_ptr.get(), size);\n-    return data_ptr;\n+    ABSL_ANNOTATE_MEMORY_IS_INITIALIZED(owned_data.get(), size);\n+    return owned_data;\n   }\n \n   // Copies data between two buffers that represent the same shape but have\n@@ -517,7 +549,13 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n \n   ifrt::DType dtype_;\n   ifrt::Shape shape_;\n-  DataPtr data_;\n+\n+  // A pointer to the data buffer. This is either owned by `owned_data_` or\n+  // directly owned by the user. Owned data is null if NanoArray is a zero\n+  // copy view of an external array with a lifetime managed by the user.\n+  void* data_;\n+  OwnedDataPtr owned_data_;\n+\n   ifrt::ShardingRef sharding_;\n };\n \n@@ -1312,17 +1350,17 @@ absl::StatusOr<std::vector<ifrt::ArrayRef>> NanoIfrtClient::CopyArrays(\n     TF_ASSIGN_OR_RETURN(auto sharding, array->sharding().WithDeviceAssignment(\n                                            devices, memory_kind));\n     if (auto nano_array = llvm::dyn_cast_or_null<NanoArray>(array.get())) {\n-      copy = tsl::TakeRef(new NanoArray(this, nano_array->dtype(),\n-                                        nano_array->shape(), nano_array->data(),\n-                                        std::move(sharding)));\n+      copy = tsl::TakeRef(new NanoArray(\n+          this, nano_array->dtype(), nano_array->shape(), nano_array->data(),\n+          nano_array->owned_data(), std::move(sharding)));\n     } else if (auto sharded_nano_array =\n                    llvm::dyn_cast_or_null<ShardedNanoArray>(array.get())) {\n       std::vector<tsl::RCReference<NanoArray>> shards_copy;\n       shards_copy.reserve(sharded_nano_array->shards().size());\n       for (const auto& shard : sharded_nano_array->shards()) {\n         shards_copy.push_back(tsl::TakeRef(\n             new NanoArray(this, shard->dtype(), shard->shape(), shard->data(),\n-                          shard->shared_ptr_sharding())));\n+                          shard->owned_data(), shard->shared_ptr_sharding())));\n       }\n       TF_ASSIGN_OR_RETURN(\n           copy, ShardedNanoArray::FromShards(this, sharded_nano_array->shape(),"
        },
        {
            "sha": "865bb9c43306fe7cc231447011a0e0d6042be234",
            "filename": "third_party/xla/xla/backends/cpu/nanort/ifrt_client_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c91fff18f54fe8019292a15cb20ac01071e1766e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c91fff18f54fe8019292a15cb20ac01071e1766e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client_test.cc?ref=c91fff18f54fe8019292a15cb20ac01071e1766e",
            "patch": "@@ -147,7 +147,7 @@ static absl::StatusOr<ifrt::ArrayRef> MakeArrayFromLiteral(\n       ifrt::Shape(literal.shape().dimensions()),\n       /*byte_strides=*/std::nullopt, std::move(sharding),\n       ifrt::Client::HostBufferSemantics::kImmutableZeroCopy,\n-      /*on_done_with_host_buffer=*/{});\n+      /*on_done_with_host_buffer=*/nullptr);\n }\n \n static void BM_IfRtAddScalars(benchmark::State& state) {"
        }
    ],
    "stats": {
        "total": 144,
        "additions": 91,
        "deletions": 53
    }
}