{
    "author": "tensorflower-gardener",
    "message": "[Autotuner] Add sharding support using KeyValueStore Interface.\n\n- The logic is ported from gemm_fusion_autotuner. I have changed the key of the Key Value store to be just module-fingerprint, earlier it was module-fingerprint + autotunable-fusion-set-from-the-module-fingerprint. The module fingerprint should already represent the fusion-sets contained in it.\n- We can improve or just remove this functionality when we design storage for offline autotuning.\n\nPiperOrigin-RevId: 826103885",
    "sha": "dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb",
    "files": [
        {
            "sha": "80ce2534deac66724107095283386fbbaebc66c4",
            "filename": "third_party/xla/xla/backends/autotuner/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD?ref=dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb",
            "patch": "@@ -39,6 +39,7 @@ cc_library(\n         \"//xla:autotune_results_proto_cc\",\n         \"//xla:autotuning_proto_cc\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/pjrt/distributed:key_value_store_interface\",\n         \"//xla/service:executable\",\n         \"//xla/service:shaped_buffer\",\n         \"//xla/tsl/platform:env\",\n@@ -60,7 +61,6 @@ cc_library(\n         \"@local_tsl//tsl/platform:blocking_counter\",\n         \"@local_tsl//tsl/platform:fingerprint\",\n         \"@local_tsl//tsl/platform:path\",\n-        \"@local_tsl//tsl/platform:protobuf\",\n     ],\n )\n \n@@ -78,6 +78,7 @@ xla_cc_test(\n         \"//xla:shape_util\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/pjrt/distributed:key_value_store_interface\",\n         \"//xla/service:executable\",\n         \"//xla/service:shaped_buffer\",\n         \"//xla/service/gpu:backend_configs_cc\",\n@@ -92,13 +93,12 @@ xla_cc_test(\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/time\",\n-        \"@com_google_absl//absl/types:optional\",\n+        \"@com_google_absl//absl/types:span\",\n         \"@com_google_googletest//:gtest_main\",\n         \"@com_google_protobuf//:any_cc_proto\",\n         \"@com_google_protobuf//:protobuf\",\n         \"@local_tsl//tsl/platform:path\",\n         \"@local_tsl//tsl/platform:protobuf\",\n-        \"@local_tsl//tsl/platform:test\",\n     ],\n )\n "
        },
        {
            "sha": "3c9e14367d6352222c82b96449cd70836aaf3524",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.cc",
            "status": "modified",
            "additions": 139,
            "deletions": 8,
            "changes": 147,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc?ref=dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb",
            "patch": "@@ -16,7 +16,10 @@ limitations under the License.\n #include \"xla/backends/autotuner/autotuner.h\"\n \n #include <algorithm>\n+#include <cmath>\n+#include <cstddef>\n #include <cstdint>\n+#include <iterator>\n #include <limits>\n #include <memory>\n #include <optional>\n@@ -25,6 +28,7 @@ limitations under the License.\n #include <vector>\n \n #include \"google/protobuf/any.pb.h\"\n+#include \"absl/container/flat_hash_map.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/memory/memory.h\"\n@@ -41,6 +45,7 @@ limitations under the License.\n #include \"xla/backends/autotuner/profiler.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_print_options.h\"\n+#include \"xla/pjrt/distributed/key_value_store_interface.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/shaped_buffer.h\"\n #include \"xla/tsl/platform/env.h\"\n@@ -50,7 +55,6 @@ limitations under the License.\n #include \"xla/tsl/util/proto/proto_utils.h\"\n #include \"tsl/platform/blocking_counter.h\"\n #include \"tsl/platform/fingerprint.h\"\n-#include \"tsl/platform/protobuf.h\"\n \n namespace xla {\n \n@@ -74,6 +78,38 @@ std::string UnpackedAnyShortDebugString(const google::protobuf::Any& any) {\n   return s;\n }\n \n+// It is important to fingerprint the entire module not just the autotuning\n+// candidates, to avoid collisions in the key-value store when several\n+// distinct modules have the same fusions, and are compiled at different\n+// times by the same PjRt client.\n+//\n+// TODO(b/394763704): Eliminate the sharding feature when we have offline\n+// autotuning. See below for an explanation of some issues.\n+//\n+// Theoretically, we also want to include the hash of the module config\n+// to ensure that a module compiled twice with different configs is\n+// autotuned twice.\n+//\n+// This is important since the config could e.g. affect codegen, or the\n+// space of possible parameters for autotuning. As a result, the autotuning\n+// results could look very different for the same module.\n+//\n+// Why is it not done here? Well, proto serialization is non-deterministic\n+// and may change across different builds. Which means that users who run\n+// on several hosts with different CPUs may end up generating different\n+// fingerprints for the same module config. They would then fail to\n+// exchange results through the key value store, which would lead to\n+// deadlocks. Therefore, we don't hash the module config here.\n+//\n+// The flip side is this: if we compile the same module twice in the same\n+// client, but with a different module config each time, we may hit the\n+// cache the second time and recover potentially inferior, or incomplete\n+// autotuning results.\n+std::string GetKvStoreKey(const HloModule* module, int shard_index) {\n+  return absl::StrCat(\"autotune_results_\", module->GetFingerprint128(), \"_\",\n+                      shard_index);\n+}\n+\n }  // namespace\n \n absl::StatusOr<Autotuner::Config> Autotuner::GetDefaultConfig(\n@@ -110,15 +146,15 @@ absl::StatusOr<std::unique_ptr<Autotuner>> Autotuner::Create(\n \n absl::Status Autotuner::Autotune(HloModule* module,\n                                  const InstructionFilterFn& should_autotune) {\n-  InstructionsByFingerprint instrunctions_by_fingerprint =\n+  InstructionsByFingerprint instructions_by_fingerprint =\n       GetAutotuningCandidates(module, should_autotune);\n-  if (instrunctions_by_fingerprint.empty()) {\n+  if (instructions_by_fingerprint.empty()) {\n     VLOG(1) << \"No instructions to autotune.\";\n     return absl::OkStatus();\n   }\n-  VLOG(1) << \"Finding configs for \" << instrunctions_by_fingerprint.size()\n+  VLOG(1) << \"Finding configs for \" << instructions_by_fingerprint.size()\n           << \" unique instructions.\";\n-  for (auto& [_, instructions] : instrunctions_by_fingerprint) {\n+  for (auto& [_, instructions] : instructions_by_fingerprint) {\n     CHECK(!instructions.empty());\n     TF_ASSIGN_OR_RETURN(Config config, GetConfig(instructions[0]));\n     CodegenBackend* codegen_backend = config.codegen_backend;\n@@ -130,6 +166,101 @@ absl::Status Autotuner::Autotune(HloModule* module,\n   return DumpLogsToFile();\n }\n \n+absl::Status Autotuner::Autotune(HloModule* module,\n+                                 const InstructionFilterFn& should_autotune,\n+                                 MultiProcessKeyValueStore& sharding_kv_store) {\n+  CHECK(cache_ != nullptr) << \"Sharding autotuning requires a cache.\";\n+  int total_shards = sharding_kv_store.process_count;\n+  int my_shard_index = sharding_kv_store.process_index;\n+\n+  // 1. Get all the instructions that could be autotuned.\n+  InstructionsByFingerprint all_instructions_by_fingerprint =\n+      GetAutotuningCandidates(module, should_autotune);\n+  if (all_instructions_by_fingerprint.empty()) {\n+    VLOG(1) << \"No instructions to autotune.\";\n+    return absl::OkStatus();\n+  }\n+\n+  // 2. Shard and get instructions to autotune for current shard.\n+  const size_t bucket_size =\n+      std::ceil(static_cast<double>(all_instructions_by_fingerprint.size()) /\n+                static_cast<double>(total_shards));\n+  const size_t start = bucket_size * my_shard_index;\n+  const size_t end =\n+      std::min(start + bucket_size, all_instructions_by_fingerprint.size());\n+  InstructionsByFingerprint instructions_by_fingerprint(\n+      std::next(all_instructions_by_fingerprint.begin(), start),\n+      std::next(all_instructions_by_fingerprint.begin(), end));\n+\n+  // 3. Autotune instructions for this shard. Use cached configs if available,\n+  // otherwise autotune and cache the best config.\n+  VLOG(1) << \"Shard \" << my_shard_index << \"/\" << total_shards\n+          << \": finding configs for \" << instructions_by_fingerprint.size()\n+          << \"/\" << all_instructions_by_fingerprint.size()\n+          << \" unique instructions \";\n+  std::vector<const HloInstruction*> autotuned_instructions;\n+  for (auto& [_, instructions] : instructions_by_fingerprint) {\n+    CHECK(!instructions.empty());\n+    TF_ASSIGN_OR_RETURN(Config config, GetConfig(instructions[0]));\n+    autotuned_instructions.push_back(instructions[0]);\n+  }\n+  TF_RETURN_IF_ERROR(DumpLogsToFile());\n+\n+  // 4. Store the results for this shard as a serialized string to the KV store.\n+  KeyValueStoreInterface& kv_store = *sharding_kv_store.key_value_store;\n+  const std::string local_key = GetKvStoreKey(module, my_shard_index);\n+  std::string local_results;\n+  if (!autotuned_instructions.empty()) {\n+    TF_ASSIGN_OR_RETURN(local_results,\n+                        cache_->Serialize(autotuned_instructions));\n+  }\n+  absl::StatusOr<std::string> stored_result = kv_store.TryGet(local_key);\n+  if (stored_result.status().code() == absl::StatusCode::kNotFound) {\n+    VLOG(2) << \"Storing results for \" << local_key;\n+    TF_RETURN_IF_ERROR(kv_store.Set(local_key, local_results));\n+    VLOG(2) << \"Shard \" << my_shard_index << \" stored results at \" << local_key;\n+  } else if (!stored_result.ok()) {\n+    return stored_result.status();\n+  } else {\n+    VLOG(2) << \"Results already exist for \" << local_key << \", skipping store.\";\n+  }\n+\n+  // 5. Load the autotune results of other shards from the KV store and update\n+  // the current shard's cache by deserializing the results.\n+  for (int i = 0; i < total_shards; ++i) {\n+    if (i == my_shard_index) {\n+      continue;\n+    }\n+    const std::string remote_key = GetKvStoreKey(module, i);\n+    VLOG(2) << \"Shard \" << my_shard_index << \": waiting for results from shard \"\n+            << i << \" / \" << total_shards << \" at \" << remote_key;\n+    // TODO(b/361009609): reset to infinite duration once issue with MPI is\n+    // fixed. https://github.com/google/jax/issues/22995.\n+    TF_ASSIGN_OR_RETURN(std::string remote_results,\n+                        kv_store.Get(remote_key, absl::Hours(24)));\n+    if (!remote_results.empty()) {\n+      TF_RETURN_IF_ERROR(cache_->Deserialize(remote_results));\n+    }\n+  }\n+\n+  // 6. Apply the results to all candidate instructions, must be already in\n+  // cache_ due to step 3 and 5 above.\n+  for (auto& [_, instructions] : all_instructions_by_fingerprint) {\n+    CHECK(!instructions.empty());\n+    std::optional<Config> cached_config = LookUp(instructions[0]);\n+    CHECK(cached_config.has_value())\n+        << \"Sharding autotuning failed: no config found for HLO: \" +\n+               instructions[0]->ToString();\n+    CodegenBackend* codegen_backend = cached_config->codegen_backend;\n+    for (auto* instr : instructions) {\n+      TF_RETURN_IF_ERROR(\n+          codegen_backend->ApplyConfig(*instr, *cached_config->backend_config));\n+    }\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n absl::Status Autotuner::Autotune(HloInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(Config config, GetConfig(instr));\n   CodegenBackend* codegen_backend = config.codegen_backend;\n@@ -221,15 +352,15 @@ absl::StatusOr<Autotuner::Config> Autotuner::TuneBestConfig(\n \n Autotuner::InstructionsByFingerprint Autotuner::GetAutotuningCandidates(\n     const HloModule* module, const InstructionFilterFn& should_autotune) {\n-  InstructionsByFingerprint instrunctions_by_fingerprint;\n+  InstructionsByFingerprint instructions_by_fingerprint;\n   for (HloComputation* computation : module->MakeNonfusionComputations()) {\n     for (HloInstruction* instr : computation->MakeInstructionPostOrder()) {\n       if (should_autotune(*instr)) {\n-        instrunctions_by_fingerprint[GetFingerprint(instr)].push_back(instr);\n+        instructions_by_fingerprint[GetFingerprint(instr)].push_back(instr);\n       }\n     }\n   }\n-  return instrunctions_by_fingerprint;\n+  return instructions_by_fingerprint;\n }\n \n std::optional<Autotuner::Config> Autotuner::LookUp("
        },
        {
            "sha": "c8b3b29beed37b23fbd577b9559494e9ce5a7dde",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.h",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h?ref=dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"xla/backends/autotuner/codegen_backend.h\"\n #include \"xla/backends/autotuner/profiler.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/pjrt/distributed/key_value_store_interface.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/shaped_buffer.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n@@ -103,6 +104,13 @@ class Autotuner {\n   absl::Status Autotune(HloModule* module,\n                         const InstructionFilterFn& should_autotune);\n \n+  // Same as above, but also takes a sharding KV store which helps to shard\n+  // the autotuning work across multiple processes.\n+  // This is used for distributed autotuning.\n+  absl::Status Autotune(HloModule* module,\n+                        const InstructionFilterFn& should_autotune,\n+                        MultiProcessKeyValueStore& sharding_kv_store);\n+\n  private:\n   using InstructionsByFingerprint =\n       absl::flat_hash_map<tsl::Fprint128, std::vector<HloInstruction*>,"
        },
        {
            "sha": "e7cf4a2cfc51534f7bfcbc3b4bee6ac1e060cc0f",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner_test.cc",
            "status": "modified",
            "additions": 89,
            "deletions": 17,
            "changes": 106,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc?ref=dd3a14ace49bb8a82a9ca27129cfe4ec96d0c4eb",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/time/time.h\"\n+#include \"absl/types/span.h\"\n #include \"google/protobuf/text_format.h\"\n #include \"xla/autotune_results.pb.h\"\n #include \"xla/autotuning.pb.h\"\n@@ -39,6 +40,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n #include \"xla/literal_util.h\"\n+#include \"xla/pjrt/distributed/key_value_store_interface.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/shaped_buffer.h\"\n@@ -66,6 +68,7 @@ MATCHER_P(ConfigMatcher, name, \"\") {\n }\n \n MATCHER_P(InstructionMatcher, opcode, \"\") { return arg.opcode() == opcode; }\n+MATCHER_P(InstrPtrMatcher, opcode, \"\") { return arg->opcode() == opcode; }\n \n std::unique_ptr<google::protobuf::Any> GetTestConfig(std::string name) {\n   TestConfig config;\n@@ -125,6 +128,11 @@ class MockAutotunerCache : public AutotunerCacheInterface {\n               (const HloInstruction* instr,\n                const AutotunerCacheInterface::Config& best_config),\n               (override));\n+  MOCK_METHOD(absl::StatusOr<std::string>, Serialize,\n+              (absl::Span<const HloInstruction* const> instructions),\n+              (override));\n+  MOCK_METHOD(absl::Status, Deserialize, (absl::string_view serialized_cache),\n+              (override));\n };\n \n using absl_testing::IsOk;\n@@ -143,29 +151,27 @@ se::DeviceDescription CreateDummyDeviceDescription() {\n \n absl::StatusOr<std::unique_ptr<Autotuner>> SetupAutotunerWithExpectations(\n     HloOpcode instr_to_autotune,\n-    std::pair<HloOpcode, int> instr_to_apply_config_and_count) {\n-  auto cache_manager = std::make_unique<MockAutotunerCache>();\n-  EXPECT_CALL(*cache_manager, Lookup(_)).WillRepeatedly(Return(std::nullopt));\n-  EXPECT_CALL(*cache_manager, Insert(_, _))\n-      .WillRepeatedly(Return(absl::OkStatus()));\n-\n+    std::vector<std::pair<HloOpcode, int>> instrs_to_apply_config_and_count,\n+    std::unique_ptr<MockAutotunerCache> cache = nullptr) {\n   std::vector<std::unique_ptr<BackendConfig>> configs;\n-  configs.push_back(GetTestConfig(\"test_config_1\"));\n-  configs.push_back(GetTestConfig(\"test_config_2\"));\n+  configs.push_back(GetTestConfig(\"another_config\"));\n+  configs.push_back(GetTestConfig(\"best_config\"));\n \n   auto backend = std::make_unique<MockCodegenBackend>();\n+  EXPECT_CALL(*backend, name()).WillRepeatedly(Return(\"mock_backend\"));\n   EXPECT_CALL(*backend,\n               GetSupportedConfigs(InstructionMatcher(instr_to_autotune)))\n       .WillOnce(Return(std::move(configs)));\n   EXPECT_CALL(*backend, Compile(_, _))\n       .WillOnce(Return(std::unique_ptr<Executable>()))\n       .WillOnce(Return(std::unique_ptr<Executable>()));\n-  HloOpcode instr_to_apply_config = instr_to_apply_config_and_count.first;\n-  int count = instr_to_apply_config_and_count.second;\n-  EXPECT_CALL(*backend,\n-              ApplyConfig(InstructionMatcher(instr_to_apply_config), _))\n-      .Times(count)\n-      .WillRepeatedly(Return(absl::OkStatus()));\n+  for (const auto& [instr_to_apply_config, count] :\n+       instrs_to_apply_config_and_count) {\n+    EXPECT_CALL(*backend,\n+                ApplyConfig(InstructionMatcher(instr_to_apply_config), _))\n+        .Times(count)\n+        .WillRepeatedly(Return(absl::OkStatus()));\n+  }\n \n   auto profiler = std::make_unique<MockProfiler>();\n   auto device_description = CreateDummyDeviceDescription();\n@@ -178,7 +184,7 @@ absl::StatusOr<std::unique_ptr<Autotuner>> SetupAutotunerWithExpectations(\n   std::vector<std::unique_ptr<CodegenBackend>> backends;\n   backends.push_back(std::move(backend));\n   return Autotuner::Create(std::move(backends), std::move(profiler),\n-                           GetTestAutotuneConfig(), std::move(cache_manager));\n+                           GetTestAutotuneConfig(), std::move(cache));\n }\n \n constexpr absl::string_view kHlo = R\"(\n@@ -371,7 +377,7 @@ TEST_F(AutotunerTest, AutotuneModuleFollowsFilter) {\n       std::unique_ptr<Autotuner> autotuner,\n       SetupAutotunerWithExpectations(\n           /*instr_to_autotune=*/HloOpcode::kCopy,\n-          /*instr_to_apply_config_and_count=*/{HloOpcode::kCopy, 1}));\n+          /*instrs_to_apply_config_and_count=*/{{HloOpcode::kCopy, 1}}));\n \n   EXPECT_THAT(autotuner->Autotune(module.get(), should_autotune),\n               absl_testing::IsOk());\n@@ -388,7 +394,7 @@ TEST_F(AutotunerTest, AutotuneModuleWithDuplicateInstructions) {\n       std::unique_ptr<Autotuner> autotuner,\n       SetupAutotunerWithExpectations(\n           /*instr_to_autotune=*/HloOpcode::kAdd,\n-          /*instr_to_apply_config_and_count=*/{HloOpcode::kAdd, 2}));\n+          /*instrs_to_apply_config_and_count=*/{{HloOpcode::kAdd, 2}}));\n \n   EXPECT_THAT(autotuner->Autotune(module.get(), should_autotune), IsOk());\n }\n@@ -745,5 +751,71 @@ TEST_F(AutotunerTest, UseDefaultConfigUnimplemented) {\n                \"GetDefaultConfig is not implemented for mock_backend\");\n }\n \n+class MockKeyValueStore : public KeyValueStoreInterface {\n+ public:\n+  MOCK_METHOD(absl::Status, Set,\n+              (absl::string_view key, absl::string_view value), (override));\n+  MOCK_METHOD(absl::StatusOr<std::string>, Get,\n+              (absl::string_view key, absl::Duration timeout), (override));\n+  MOCK_METHOD(absl::StatusOr<std::string>, TryGet, (absl::string_view key),\n+              (override));\n+};\n+\n+AutotunerCacheInterface::Config GetCacheConfig(absl::string_view name) {\n+  AutotunerCacheInterface::Config config;\n+  config.codegen_backend_name = \"mock_backend\";\n+  config.backend_config = *GetTestConfig(std::string(name));\n+  return config;\n+};\n+\n+TEST_F(AutotunerTest, ShardedAutotuning) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(kHlo));\n+  constexpr int kShardCount = 2;\n+  auto should_autotune = [](const HloInstruction& instruction) {\n+    return instruction.opcode() == HloOpcode::kAdd ||\n+           instruction.opcode() == HloOpcode::kCopy;\n+  };\n+  auto kv_store = std::make_shared<MockKeyValueStore>();\n+  auto cache = std::make_unique<MockAutotunerCache>();\n+\n+  // Shard 0 autotunes kCopy instructions, updates the cache and serializes the\n+  // result to a string \"kCopy_autotune_result\".\n+  EXPECT_CALL(*cache, Lookup(InstrPtrMatcher(HloOpcode::kCopy)))\n+      .WillOnce(Return(std::nullopt))                    // During autotuning.\n+      .WillOnce(Return(GetCacheConfig(\"best_config\")));  // Config application.\n+  EXPECT_CALL(*cache, Insert(InstrPtrMatcher(HloOpcode::kCopy), _))\n+      .WillOnce(Return(absl::OkStatus()));\n+  EXPECT_CALL(*cache, Serialize(_)).WillOnce(Return(\"kCopy_autotune_result\"));\n+  // Stores the serialized results to the KV store if it does not exist.\n+  EXPECT_CALL(*kv_store, TryGet(testing::HasSubstr(\"_0\")))\n+      .WillOnce(Return(absl::NotFoundError(\"not found\")));\n+  EXPECT_CALL(*kv_store, Set(testing::HasSubstr(\"_0\"), \"kCopy_autotune_result\"))\n+      .WillOnce(Return(absl::OkStatus()));\n+\n+  // Shard 0 reads the KV store entry for shard 1 and updates the current cache.\n+  EXPECT_CALL(*kv_store, Get(testing::HasSubstr(\"_1\"), _))\n+      .WillOnce(Return(\"kAdd_autotune_result\"));\n+  EXPECT_CALL(*cache, Deserialize(\"kAdd_autotune_result\"))\n+      .WillOnce(Return(absl::OkStatus()));\n+  EXPECT_CALL(*cache, Lookup(InstrPtrMatcher(HloOpcode::kAdd)))\n+      .WillOnce(Return(GetCacheConfig(\"best_config\")));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<Autotuner> autotuner,\n+      SetupAutotunerWithExpectations(\n+          /*instr_to_autotune=*/HloOpcode::kCopy,\n+          /*instrs_to_apply_config_and_count=*/\n+          {{HloOpcode::kCopy, 1}, {HloOpcode::kAdd, 2}}, std::move(cache)));\n+\n+  MultiProcessKeyValueStore sharding_kv_store;\n+  sharding_kv_store.key_value_store = kv_store;\n+  sharding_kv_store.process_count = kShardCount;\n+  sharding_kv_store.process_index = 0;\n+  EXPECT_THAT(\n+      autotuner->Autotune(module.get(), should_autotune, sharding_kv_store),\n+      IsOk());\n+}\n+\n }  // namespace\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 267,
        "additions": 239,
        "deletions": 28
    }
}