{
    "author": "beckerhe",
    "message": "Remove HLO and Autotuner dependency from CublasLtMatmulThunk\n\nThunks should not depend on compiler components, therefore I\nremove the HLOInstruction pointer from the constructor and\nperform the necessary data accesses in IrEmitterUnnested.\n\nThat's also how other thunks work.\n\nPiperOrigin-RevId: 800876577",
    "sha": "7f6ec190fdd9fa48b638c01853a5af45c237cec7",
    "files": [
        {
            "sha": "42e86cfec7eeeee39e9f70ad1425d9f93bb6b1b6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=7f6ec190fdd9fa48b638c01853a5af45c237cec7",
            "patch": "@@ -728,7 +728,6 @@ cc_library(\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/service/gpu:matmul_utils\",\n-        \"//xla/service/gpu/autotuning:autotuner_util\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor/gpu:gpu_blas_lt\","
        },
        {
            "sha": "af6381a6bdf32ed5780ad6aeba6cf75245fa8589",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_thunk_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc?ref=7f6ec190fdd9fa48b638c01853a5af45c237cec7",
            "patch": "@@ -1133,11 +1133,12 @@ TEST(CommandBufferThunkTest, CublasLtCmd) {\n   // Prepare commands sequence for constructing command buffer.\n   CommandBufferCmdSequence commands;\n   commands.Emplace<CublasLtCmd>(CublasLtMatmulThunk(\n-      nullptr, config.value(), se::gpu::BlasLt::Epilogue::kDefault, 0, slice_a,\n-      slice_b, slice_c, slice_d, BufferAllocation::Slice(),\n+      Thunk::ThunkInfo(), /*canonical_hlo=*/\"\", config.value(),\n+      se::gpu::BlasLt::Epilogue::kDefault, 0, slice_a, slice_b, slice_c,\n+      slice_d, BufferAllocation::Slice(), BufferAllocation::Slice(),\n       BufferAllocation::Slice(), BufferAllocation::Slice(),\n       BufferAllocation::Slice(), BufferAllocation::Slice(),\n-      BufferAllocation::Slice(), BufferAllocation::Slice(), slice_workspace));\n+      BufferAllocation::Slice(), slice_workspace));\n   TF_ASSERT_OK_AND_ASSIGN(\n       CommandBufferCmdExecutor executor,\n       CommandBufferCmdExecutor::Create(std::move(commands), serialize));"
        },
        {
            "sha": "997f9b523b722a37b34243046eb2a236fe0c1863",
            "filename": "third_party/xla/xla/backends/gpu/runtime/gpublas_lt_matmul_thunk.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 16,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.cc?ref=7f6ec190fdd9fa48b638c01853a5af45c237cec7",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n \n #include <cstdint>\n #include <optional>\n+#include <string>\n #include <utility>\n \n #include \"absl/log/log.h\"\n@@ -25,7 +26,6 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/service/buffer_assignment.h\"\n-#include \"xla/service/gpu/autotuning/autotuner_util.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/gpu/matmul_utils.h\"\n #include \"xla/stream_executor/device_memory.h\"\n@@ -57,21 +57,20 @@ CublasLtMatmulThunk::CublasLtMatmulThunk(const CublasLtMatmulThunk& rhs)\n       workspace_(rhs.workspace_) {}\n \n CublasLtMatmulThunk::CublasLtMatmulThunk(\n-    const HloInstruction* instr, GemmConfig gemm_config,\n-    se::gpu::BlasLt::Epilogue epilogue, int64_t algorithm_idx,\n-    BufferAllocation::Slice a, BufferAllocation::Slice b,\n+    Thunk::ThunkInfo thunk_info, std::string canonical_hlo,\n+    GemmConfig gemm_config, se::gpu::BlasLt::Epilogue epilogue,\n+    int64_t algorithm_idx, BufferAllocation::Slice a, BufferAllocation::Slice b,\n     BufferAllocation::Slice c, BufferAllocation::Slice d,\n     BufferAllocation::Slice bias, BufferAllocation::Slice aux,\n     BufferAllocation::Slice a_scale, BufferAllocation::Slice b_scale,\n     BufferAllocation::Slice c_scale, BufferAllocation::Slice d_scale,\n     BufferAllocation::Slice d_amax,\n     std::optional<const BufferAllocation::Slice> workspace)\n-    : Thunk(Kind::kCublasLtMatmul,\n-            instr ? Thunk::ThunkInfo::WithProfileAnnotation(instr)\n-                  : Thunk::ThunkInfo{}),\n+    : Thunk(Kind::kCublasLtMatmul, std::move(thunk_info)),\n       gemm_config_(std::move(gemm_config)),\n       epilogue_(epilogue),\n       algorithm_idx_(algorithm_idx),\n+      canonical_hlo_(std::move(canonical_hlo)),\n       a_(a),\n       b_(b),\n       c_(c),\n@@ -83,14 +82,7 @@ CublasLtMatmulThunk::CublasLtMatmulThunk(\n       c_scale_(c_scale),\n       d_scale_(d_scale),\n       d_amax_(d_amax),\n-      workspace_(workspace) {\n-  // The tests creating CublasLtMatmulThunk directly might not provide the\n-  // pointer to the actual instruction, in this case Matmul plans are not\n-  // cached.\n-  if (instr != nullptr) {\n-    canonical_hlo_ = AutotuneCacheKey::HloInstructionToCanonicalString(*instr);\n-  }\n-}\n+      workspace_(workspace) {}\n \n absl::Status CublasLtMatmulThunk::ExecuteOnStreamInternal(\n     se::Stream* stream, const ExecuteParams& params) {\n@@ -141,7 +133,7 @@ CublasLtMatmulThunk::GetCachedMatmulPlan(const ExecuteParams& params) {\n \n     TF_ASSIGN_OR_RETURN(auto plan,\n                         blas_lt->GetMatmulPlan(gemm_config_, epilogue_));\n-    // if workspace buffer is not provided, consider onlt the algorithms which\n+    // if workspace buffer is not provided, consider only the algorithms which\n     // do not require a scratch space\n     int64_t max_workspace =\n         workspace_.has_value() ? workspace_.value().size() : 0;"
        },
        {
            "sha": "ae0ab9c52417dbb59721dad5df8ab89ce8d0465e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/gpublas_lt_matmul_thunk.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.h?ref=7f6ec190fdd9fa48b638c01853a5af45c237cec7",
            "patch": "@@ -18,8 +18,8 @@ limitations under the License.\n \n #include <cstdint>\n #include <optional>\n+#include <string>\n \n-#include \"absl/base/thread_annotations.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n@@ -33,7 +33,8 @@ namespace gpu {\n \n class CublasLtMatmulThunk : public Thunk {\n  public:\n-  CublasLtMatmulThunk(const HloInstruction* instr, GemmConfig gemm_config,\n+  CublasLtMatmulThunk(Thunk::ThunkInfo thunk_info, std::string canonical_hlo,\n+                      GemmConfig gemm_config,\n                       se::gpu::BlasLt::Epilogue epilogue, int64_t algorithm_idx,\n                       BufferAllocation::Slice a, BufferAllocation::Slice b,\n                       BufferAllocation::Slice c, BufferAllocation::Slice d,\n@@ -62,7 +63,6 @@ class CublasLtMatmulThunk : public Thunk {\n   absl::StatusOr<se::gpu::BlasLt::MatmulPlan*> GetCachedMatmulPlan(\n       const ExecuteParams& params);\n \n- protected:\n   GemmConfig gemm_config_;\n   se::gpu::BlasLt::Epilogue epilogue_;\n   int64_t algorithm_idx_;"
        },
        {
            "sha": "cab243bc83fcd209a6840469f1a313cd71762503",
            "filename": "third_party/xla/xla/backends/gpu/runtime/gpublas_lt_matmul_thunk_test.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 2,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk_test.cc?ref=7f6ec190fdd9fa48b638c01853a5af45c237cec7",
            "patch": "@@ -36,6 +36,7 @@ limitations under the License.\n #include \"xla/error_spec.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_print_options.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n@@ -96,7 +97,8 @@ class GpuBlasLtMatmulThunkTest : public HloTestBase {\n                                   absl::string_view hlo_string);\n };\n \n-struct GpuBlasLtThunkBuilder {\n+class GpuBlasLtThunkBuilder {\n+ public:\n   GpuBlasLtThunkBuilder(se::StreamExecutor* exec,\n                         const se::GpuComputeCapability& gpu_comp)\n       : exec_(exec), allocator_(exec), gpu_comp_(gpu_comp) {}\n@@ -143,8 +145,13 @@ struct GpuBlasLtThunkBuilder {\n       bias = slices[has_matrix_bias ? 3 : 2];\n     }\n \n+    Thunk::ThunkInfo thunk_info = Thunk::ThunkInfo::WithProfileAnnotation(gemm);\n+    std::string canonical_hlo = gemm->ToString(\n+        HloPrintOptions::Fingerprint().set_print_backend_config(true));\n+\n     return std::make_unique<CublasLtMatmulThunk>(\n-        gemm, std::move(gemm_config), epilogue,\n+        std::move(thunk_info), std::move(canonical_hlo), std::move(gemm_config),\n+        epilogue,\n         /*algorithm_idx*/ 0, slices[0], slices[1],\n         has_matrix_bias ? slices[2] : slices.back(), slices.back(), bias,\n         BufferAllocation::Slice{} /* aux */,"
        },
        {
            "sha": "c0cdc1ea45fce5ff58dad904d36143b4c8fb80f3",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 4,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7f6ec190fdd9fa48b638c01853a5af45c237cec7/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc?ref=7f6ec190fdd9fa48b638c01853a5af45c237cec7",
            "patch": "@@ -126,6 +126,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_print_options.h\"\n #include \"xla/hlo/ir/hlo_schedule.h\"\n #include \"xla/hlo/utils/hlo_traversal.h\"\n #include \"xla/layout.h\"\n@@ -765,9 +766,13 @@ absl::Status IrEmitterUnnested::EmitCublasLtMatmulThunk(\n   BufferAllocation::Slice a_scale, b_scale, c_scale, d_scale, d_amax;\n   TF_ASSIGN_OR_RETURN(se::gpu::BlasLt::Epilogue blas_lt_epilogue,\n                       gpublas_lt::AsBlasLtEpilogue(epilogue));\n+  Thunk::ThunkInfo thunk_info = Thunk::ThunkInfo::WithProfileAnnotation(instr);\n+  std::string canonical_hlo = instr->ToString(\n+      HloPrintOptions::Fingerprint().set_print_backend_config(true));\n   auto thunk = std::make_unique<CublasLtMatmulThunk>(\n-      instr, std::move(gemm_config), blas_lt_epilogue, algorithm, a, b, c, d,\n-      bias, aux, a_scale, b_scale, c_scale, d_scale, d_amax, workspace_buffer);\n+      std::move(thunk_info), std::move(canonical_hlo), std::move(gemm_config),\n+      blas_lt_epilogue, algorithm, a, b, c, d, bias, aux, a_scale, b_scale,\n+      c_scale, d_scale, d_amax, workspace_buffer);\n   AddThunkToThunkSequence(std::move(thunk));\n   return absl::OkStatus();\n }\n@@ -857,9 +862,13 @@ absl::Status IrEmitterUnnested::EmitCublasLtMatmulThunkF8(\n \n   TF_ASSIGN_OR_RETURN(se::gpu::BlasLt::Epilogue blas_lt_epilogue,\n                       gpublas_lt::AsBlasLtEpilogue(epilogue));\n+  Thunk::ThunkInfo thunk_info = Thunk::ThunkInfo::WithProfileAnnotation(instr);\n+  std::string canonical_hlo = instr->ToString(\n+      HloPrintOptions::Fingerprint().set_print_backend_config(true));\n   auto thunk = std::make_unique<CublasLtMatmulThunk>(\n-      instr, std::move(gemm_config), blas_lt_epilogue, algorithm, a, b, c, d,\n-      bias, aux, a_scale, b_scale, c_scale, d_scale, d_amax, workspace_buffer);\n+      std::move(thunk_info), std::move(canonical_hlo), std::move(gemm_config),\n+      blas_lt_epilogue, algorithm, a, b, c, d, bias, aux, a_scale, b_scale,\n+      c_scale, d_scale, d_amax, workspace_buffer);\n   AddThunkToThunkSequence(std::move(thunk));\n   return absl::OkStatus();\n }"
        }
    ],
    "stats": {
        "total": 66,
        "additions": 37,
        "deletions": 29
    }
}