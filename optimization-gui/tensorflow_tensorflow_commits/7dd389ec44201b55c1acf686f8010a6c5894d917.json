{
    "author": "unknown",
    "message": "[XLA:GPU] Remove gpu_p2p_pipeliner\n\nIt's not referenced by any build files.\n\nPiperOrigin-RevId: 839233703",
    "sha": "7dd389ec44201b55c1acf686f8010a6c5894d917",
    "files": [
        {
            "sha": "0d12b814b16328574bd02cd1b93cbe719c081f48",
            "filename": "third_party/xla/xla/service/gpu/gpu_p2p_pipeliner.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 629,
            "changes": 629,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9f02b8aa9ff936c90c41f3a31c74eae5b758ff71/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_p2p_pipeliner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9f02b8aa9ff936c90c41f3a31c74eae5b758ff71/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_p2p_pipeliner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_p2p_pipeliner.cc?ref=9f02b8aa9ff936c90c41f3a31c74eae5b758ff71",
            "patch": "@@ -1,629 +0,0 @@\n-/* Copyright 2024 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/gpu/gpu_p2p_pipeliner.h\"\n-\n-#include <cstdint>\n-#include <functional>\n-#include <optional>\n-#include <string>\n-#include <utility>\n-#include <vector>\n-\n-#include \"absl/algorithm/container.h\"\n-#include \"absl/base/nullability.h\"\n-#include \"absl/container/flat_hash_map.h\"\n-#include \"absl/container/flat_hash_set.h\"\n-#include \"absl/log/check.h\"\n-#include \"absl/log/log.h\"\n-#include \"absl/status/status.h\"\n-#include \"absl/strings/str_cat.h\"\n-#include \"absl/strings/str_join.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"xla/hlo/ir/hlo_casting_utils.h\"\n-#include \"xla/hlo/ir/hlo_computation.h\"\n-#include \"xla/hlo/ir/hlo_instruction.h\"\n-#include \"xla/hlo/ir/hlo_instructions.h\"\n-#include \"xla/hlo/ir/hlo_opcode.h\"\n-#include \"xla/hlo/parser/hlo_parser.h\"\n-#include \"xla/service/collective_conflict_analysis.h\"\n-#include \"xla/service/collective_ops_utils.h\"\n-#include \"xla/service/collective_pipeliner.h\"\n-#include \"xla/service/collective_pipeliner_utils.h\"\n-#include \"xla/service/pattern_matcher.h\"\n-#include \"xla/tsl/platform/errors.h\"\n-#include \"xla/tsl/platform/statusor.h\"\n-#include \"xla/util.h\"\n-\n-namespace xla {\n-namespace gpu {\n-namespace {\n-\n-using ::xla::match::GetTupleElement;\n-using ::xla::match::Op;\n-using ::xla::match::Parameter;\n-using ::xla::match::Recv;\n-using ::xla::match::Send;\n-\n-// Rather than pipelining the send/recv and *-done instructions, we only\n-// pipeline send/recv instructions. This allows spanning async send/recv across\n-// the loop boundary.\n-bool PipelineOnlySendRecvStart(\n-    const HloInstruction* instruction,\n-    absl::flat_hash_map<const HloInstruction*, bool>& cache) {\n-  auto it = cache.find(instruction);\n-  if (it != cache.end()) {\n-    return it->second;\n-  }\n-\n-  // Only pipeline send/recv instructions that operate on a loop parameter.\n-  if (!Match(instruction, Recv()) &&\n-      !Match(instruction, Send(GetTupleElement(Parameter()), Op()))) {\n-    cache[instruction] = false;\n-    return false;\n-  }\n-\n-  // Only pipeline them if all control predecessors are also pipelined.\n-  for (HloInstruction* other_instruction :\n-       instruction->control_predecessors()) {\n-    if (!PipelineOnlySendRecvStart(other_instruction, cache)) {\n-      cache[instruction] = false;\n-      return false;\n-    }\n-  }\n-\n-  cache.insert({instruction, true});\n-  return true;\n-}\n-\n-// Fully pipeline recv and recv-done instructions w/o any control dependencies.\n-// Determines if a given instruction matches `recv-done(recv())` to configure\n-// the pipeliner to pipeline these two instructions together.\n-bool FullyPipelineRecv(const HloInstruction* recv_done_candidate) {\n-  if (recv_done_candidate->opcode() != HloOpcode::kRecvDone ||\n-      !recv_done_candidate->control_predecessors().empty()) {\n-    return false;\n-  }\n-  const HloInstruction* recv_candidate = recv_done_candidate->operand(0);\n-  return recv_candidate->opcode() == HloOpcode::kRecv &&\n-         recv_candidate->control_predecessors().empty();\n-}\n-\n-bool ShouldPipeline(const HloInstruction* instruction) {\n-  if (!HloPredicateIsOp<HloOpcode::kRecvDone, HloOpcode::kSendDone>(\n-          instruction)) {\n-    return false;\n-  }\n-  // Not annotated for pipelining.\n-  auto it =\n-      instruction->frontend_attributes().map().find(kSendRecvPipelineAttr);\n-  if (it == instruction->frontend_attributes().map().end()) {\n-    return false;\n-  }\n-\n-  // Allow RecvDone to have a Send as a control predecessor. This control\n-  // predecessor will be dropped by the pipeliner, which is what we needed\n-  // when we rotate the RecvDone to the beginning of the while-body.\n-  auto allowed_predecessor = [&]() {\n-    return instruction->opcode() == HloOpcode::kRecvDone &&\n-           instruction->control_predecessors().size() == 1 &&\n-           instruction->control_predecessors()[0]->opcode() == HloOpcode::kSend;\n-  };\n-  if (!instruction->control_successors().empty() ||\n-      (!instruction->control_predecessors().empty() &&\n-       !allowed_predecessor())) {\n-    return false;\n-  }\n-\n-  // Checks that the SendDone or RecvDone is used for non-trivial computation.\n-  // This avoids repeatedly pipelining a loop.\n-  bool is_pipelined =\n-      (instruction->user_count() == 1 && instruction->parent() != nullptr &&\n-       instruction->users()[0] == instruction->parent()->root_instruction());\n-  return !is_pipelined;\n-}\n-\n-bool ShouldAllowLoopVariantParameterInChain(const HloInstruction* instr) {\n-  // Allow any loop parameter needed for pipelining the Send/Recv instructions\n-  // that have been decided to pipeline.\n-  CHECK(instr->opcode() == HloOpcode::kGetTupleElement &&\n-        instr->operand(0)->opcode() == HloOpcode::kParameter);\n-  return true;\n-}\n-\n-absl::Status PostprocessP2PImpl(\n-    HloInstruction* instr,\n-    std::function<std::string(std::vector<ReplicaGroup>&)> transformer) {\n-  // The input instruction is a Done instruction.\n-  if (!HloPredicateIsOp<HloOpcode::kRecvDone, HloOpcode::kSendDone>(instr)) {\n-    return Internal(\"Expected SendDone/RecvDone as the pipelined collective\");\n-  }\n-  instr = instr->mutable_operand(0);\n-  if (!HloPredicateIsOp<HloOpcode::kRecv, HloOpcode::kSend>(instr)) {\n-    return Internal(\"Expected Send/Recv as the SendDone/RecvDone operand\");\n-  }\n-  auto validation_it =\n-      instr->frontend_attributes().map().find(kSendRecvValidationAttr);\n-  if (validation_it == instr->frontend_attributes().map().end() ||\n-      validation_it->second == \"invalid\") {\n-    return absl::OkStatus();\n-  }\n-  auto statusor_bounds = ParseReplicaGroupsOnly(validation_it->second);\n-  if (!statusor_bounds.ok()) {\n-    return statusor_bounds.status();\n-  }\n-  std::string validation_attr = transformer(statusor_bounds.value());\n-  xla::FrontendAttributes attributes = instr->frontend_attributes();\n-  (*attributes.mutable_map())[kSendRecvValidationAttr] = validation_attr;\n-  instr->set_frontend_attributes(attributes);\n-  return absl::OkStatus();\n-}\n-\n-// Modifies the loop iteration frontend attribute for the peeled off Send and\n-// Recv for the first iteration of a loop.\n-absl::Status PostprocessPeeledP2P(HloInstruction* instr,\n-                                  HloInstruction* new_while_instr) {\n-  // We only use this to post-process the peeled send/recv before the new loop\n-  // was created.\n-  CHECK(new_while_instr == nullptr);\n-\n-  auto transform_bounds = [&](std::vector<ReplicaGroup>& replica_groups) {\n-    std::vector<std::pair<int64_t, int64_t>> bounds;\n-    bounds.reserve(replica_groups.size());\n-    bool all_invalid = true;\n-    for (const auto& replica_group : replica_groups) {\n-      // The peeled off instruction is for executing the first iteration of\n-      // the loop.\n-      int64_t lower_bound = replica_group.replica_ids(0);\n-      int64_t upper_bound = replica_group.replica_ids(1);\n-      if (lower_bound <= 0 && upper_bound >= 0) {\n-        all_invalid = false;\n-        bounds.push_back({0, 0});\n-      } else {\n-        bounds.push_back({1, 0});\n-      }\n-    }\n-    std::string validation_attr;\n-    if (all_invalid) {\n-      // An optimized way to represent that all source-target pairs are\n-      // communicating invalid data, to avoid the overhead related to the use\n-      // of execution counters.\n-      validation_attr = \"invalid\";\n-    } else {\n-      validation_attr = \"{\" +\n-                        absl::StrJoin(bounds, \",\",\n-                                      absl::PairFormatter(\n-                                          [](std::string* out, int64_t value) {\n-                                            absl::StrAppend(out, \"{\", value);\n-                                          },\n-                                          \",\",\n-                                          [](std::string* out, int64_t value) {\n-                                            absl::StrAppend(out, value, \"}\");\n-                                          })) +\n-                        \"}\";\n-    }\n-    return validation_attr;\n-  };\n-  return PostprocessP2PImpl(instr, transform_bounds);\n-};\n-\n-// Modifies the loop iteration frontend attribute for the rotated Send and Recv\n-// for the remaining iterations in a loop.\n-absl::Status PostprocessRotatedP2P(HloInstruction* instr,\n-                                   HloInstruction* new_while_instr) {\n-  // We only use this to post-process the peeled send/recv before the new loop\n-  // was created.\n-  CHECK(new_while_instr == nullptr);\n-\n-  auto transform_bounds = [&](std::vector<ReplicaGroup>& replica_groups) {\n-    std::vector<std::pair<int64_t, int64_t>> bounds;\n-    bounds.reserve(replica_groups.size());\n-    bool all_invalid = true;\n-    for (const auto& replica_group : replica_groups) {\n-      int64_t lower_bound = replica_group.replica_ids(0);\n-      int64_t upper_bound = replica_group.replica_ids(1);\n-      if (lower_bound <= upper_bound) {\n-        if (lower_bound >= 1) {\n-          --lower_bound;\n-        }\n-        if (upper_bound >= 1) {\n-          --upper_bound;\n-        }\n-        if (lower_bound <= upper_bound) {\n-          all_invalid = false;\n-          bounds.push_back({lower_bound, upper_bound});\n-        } else {\n-          bounds.push_back({1, 0});\n-        }\n-      } else {\n-        bounds.push_back({lower_bound, upper_bound});\n-      }\n-    }\n-\n-    std::string validation_attr;\n-    if (all_invalid) {\n-      // An optimized way to represent that all source-target pairs are\n-      // communicating invalid data, to avoid the overhead related to the use\n-      // of execution counters.\n-      validation_attr = \"invalid\";\n-    } else {\n-      validation_attr = \"{\" +\n-                        absl::StrJoin(bounds, \",\",\n-                                      absl::PairFormatter(\n-                                          [](std::string* out, int64_t value) {\n-                                            absl::StrAppend(out, \"{\", value);\n-                                          },\n-                                          \",\",\n-                                          [](std::string* out, int64_t value) {\n-                                            absl::StrAppend(out, value, \"}\");\n-                                          })) +\n-                        \"}\";\n-    }\n-    return validation_attr;\n-  };\n-\n-  return PostprocessP2PImpl(instr, transform_bounds);\n-}\n-\n-struct PeeledHloInstructionInfo {\n-  HloInstruction* instr;\n-  // The new while out of which this instruction was peeled. Can be nullptr if\n-  // the new loop was not yet created.\n-  HloInstruction* while_instr;\n-};\n-\n-}  // anonymous namespace\n-\n-// Finds the start instruction for send/recv where send/recv-done are chosen to\n-// be pipelined.\n-static HloInstruction* absl_nullable GetSendRecvStartInstruction(\n-    HloInstruction* absl_nonnull instr) {\n-  if (instr->opcode() == HloOpcode::kRecv ||\n-      instr->opcode() == HloOpcode::kSend) {\n-    return instr;\n-  }\n-  if (instr->opcode() == HloOpcode::kRecvDone ||\n-      instr->opcode() == HloOpcode::kSendDone) {\n-    return instr->mutable_operand(0);\n-  }\n-  return nullptr;\n-}\n-\n-static std::vector<HloInstruction* absl_nonnull> GetSendRecvStartInstructions(\n-    const std::vector<HloInstruction* absl_nonnull>& instructions) {\n-  std::vector<HloInstruction* absl_nonnull> start_instructions;\n-  for (HloInstruction* absl_nonnull instr : instructions) {\n-    HloInstruction* absl_nullable start_instr =\n-        GetSendRecvStartInstruction(instr);\n-    if (start_instr != nullptr) start_instructions.push_back(start_instr);\n-  }\n-  return start_instructions;\n-}\n-\n-static HloInstruction* absl_nonnull GetSendRecvStartInstructionOrSelf(\n-    HloInstruction* absl_nonnull instr) {\n-  HloInstruction* send_recv_start = GetSendRecvStartInstruction(instr);\n-  return send_recv_start != nullptr ? send_recv_start : instr;\n-}\n-\n-static HloInstruction* absl_nonnull GetSendRecvDoneInstructionOrSelf(\n-    HloInstruction* absl_nonnull rotated_instr) {\n-  auto it = absl::c_find_if(rotated_instr->users(), [](HloInstruction* user) {\n-    return user->opcode() == HloOpcode::kRecvDone ||\n-           user->opcode() == HloOpcode::kSendDone;\n-  });\n-  return it != rotated_instr->users().end() ? *it : rotated_instr;\n-}\n-\n-// Post-process rotated send/recv ops to add control dependencies with\n-// conflicting collectives.\n-static absl::Status PostProcessRotatedSendRecvOps(\n-    const std::vector<HloInstruction*>& rotated) {\n-  // Find the start instructions for send/recv.\n-  std::vector<HloInstruction* absl_nonnull> rotated_send_recvs =\n-      GetSendRecvStartInstructions(rotated);\n-\n-  VLOG(5) << \"Post-processing rotated send/recv ops:\";\n-  if (VLOG_IS_ON(5)) {\n-    for (HloInstruction* instr : rotated_send_recvs) {\n-      VLOG(5) << \" - \" << instr->ToShortString();\n-    }\n-  }\n-\n-  // Convert to set for faster lookup.\n-  absl::flat_hash_set<HloInstruction* absl_nonnull> rotated_send_recvs_set(\n-      rotated_send_recvs.begin(), rotated_send_recvs.end());\n-\n-  // Add control dependencies from conflicting collectives to rotated send/recv\n-  // ops.\n-  for (HloInstruction* rotated_instr : rotated_send_recvs) {\n-    VLOG(5) << \"Working on \" << rotated_instr->ToShortString();\n-    CHECK(rotated_instr->opcode() == HloOpcode::kRecv ||\n-          rotated_instr->opcode() == HloOpcode::kSend);\n-    HloComputation* parent = rotated_instr->parent();\n-    int64_t num_conflicting_collectives = 0;\n-    for (HloInstruction* conflicting_collective :\n-         FindAllConflictingCollectives(parent, {rotated_instr})) {\n-      if (rotated_send_recvs_set.contains(conflicting_collective)) continue;\n-      num_conflicting_collectives++;\n-      conflicting_collective =\n-          GetSendRecvDoneInstructionOrSelf(conflicting_collective);\n-      rotated_instr = GetSendRecvStartInstructionOrSelf(rotated_instr);\n-      TF_RETURN_IF_ERROR(\n-          conflicting_collective->AddControlDependencyTo(rotated_instr));\n-      VLOG(5) << \"Adding control dependency from \"\n-              << conflicting_collective->ToShortString() << \" to \"\n-              << rotated_instr->ToShortString() << \"\\n\";\n-    }\n-    VLOG(5) << \"Conflicting collectives: \" << num_conflicting_collectives;\n-  }\n-\n-  return absl::OkStatus();\n-}\n-\n-// For a peeled send/recv instruction, find the corresponding send/recv-done\n-// instruction after the while loop.\n-// TODO(frgossen): Simplify this to support only directly consuming\n-// send/recv-done ops when we no longer support partial pipelining.\n-static HloInstruction* FindSendRecvDoneInstruction(HloInstruction* instr) {\n-  CHECK(instr->opcode() == HloOpcode::kRecv ||\n-        instr->opcode() == HloOpcode::kSend);\n-  CHECK_EQ(instr->user_count(), 1);\n-\n-  HloInstruction* candidate = instr->users().front();\n-  if (candidate->opcode() == HloOpcode::kTuple) {\n-    HloInstruction* tuple_op = candidate;\n-    int64_t i = tuple_op->operand_index(instr);\n-    CHECK_EQ(tuple_op->user_count(), 1);\n-    HloInstruction* while_op = tuple_op->users().front();\n-    CHECK_EQ(while_op->opcode(), HloOpcode::kWhile);\n-    for (HloInstruction* user : while_op->users()) {\n-      HloGetTupleElementInstruction* gte_op =\n-          DynCast<HloGetTupleElementInstruction>(user);\n-      if (gte_op == nullptr || gte_op->tuple_index() != i) continue;\n-      CHECK_EQ(gte_op->user_count(), 1);\n-      candidate = gte_op->users().front();\n-      break;\n-    }\n-  }\n-  CHECK(candidate->opcode() == HloOpcode::kRecvDone ||\n-        candidate->opcode() == HloOpcode::kSendDone);\n-  return candidate;\n-}\n-\n-static absl::Status AddControlDependencies(\n-    std::vector<HloInstruction*>& from_instructions, HloInstruction* to_instr) {\n-  for (HloInstruction* from_instr : from_instructions) {\n-    VLOG(5) << \"Adding control dependency from \" << from_instr->ToShortString()\n-            << \" to \" << to_instr->ToShortString();\n-    TF_RETURN_IF_ERROR(from_instr->AddControlDependencyTo(to_instr));\n-  }\n-  return absl::OkStatus();\n-}\n-\n-static absl::Status AddControlDependencies(\n-    HloInstruction* from_instr,\n-    absl::flat_hash_set<HloInstruction*>& to_instructions) {\n-  for (HloInstruction* to_instr : to_instructions) {\n-    VLOG(5) << \"Adding control dependency from \" << from_instr->ToShortString()\n-            << \" to \" << to_instr->ToShortString();\n-    TF_RETURN_IF_ERROR(from_instr->AddControlDependencyTo(to_instr));\n-  }\n-  return absl::OkStatus();\n-}\n-\n-static std::vector<PeeledHloInstructionInfo> GetSendRecvStartInstructions(\n-    const std::vector<PeeledHloInstructionInfo>& peeled) {\n-  std::vector<PeeledHloInstructionInfo> peeled_send_recvs;\n-  for (const auto [instr, while_instr] : peeled) {\n-    HloInstruction* send_recv_start = GetSendRecvStartInstruction(instr);\n-    if (send_recv_start == nullptr) continue;\n-    peeled_send_recvs.push_back({send_recv_start, while_instr});\n-  }\n-  return peeled_send_recvs;\n-}\n-\n-static absl::Status PostProcessPeeledSendRecvOps(\n-    const std::vector<PeeledHloInstructionInfo>& peeled) {\n-  // Find the start instructions for send/recv.\n-  std::vector<PeeledHloInstructionInfo> peeled_send_recvs =\n-      GetSendRecvStartInstructions(peeled);\n-\n-  VLOG(5) << \"Post-processing peeled send/recv ops:\";\n-  if (VLOG_IS_ON(5)) {\n-    for (const auto [instr, while_instr] : peeled_send_recvs) {\n-      VLOG(5) << \" - \" << instr->ToShortString();\n-    }\n-  }\n-\n-  // Convert to set for faster lookup.\n-  absl::flat_hash_set<HloInstruction*> peeled_send_recvs_set;\n-  for (const PeeledHloInstructionInfo& info : peeled_send_recvs) {\n-    peeled_send_recvs_set.insert(info.instr);\n-  }\n-\n-  // Add control dependencies between conflicting collectives and peeled\n-  // send/recv ops.\n-  for (PeeledHloInstructionInfo peeled : peeled_send_recvs) {\n-    VLOG(5) << \"Working on \" << peeled.instr->ToShortString();\n-    CHECK(peeled.instr->opcode() == HloOpcode::kRecv ||\n-          peeled.instr->opcode() == HloOpcode::kSend);\n-\n-    // Find all conflicting collectives that were not peeled out of the loop.\n-    absl::flat_hash_set<HloInstruction*> unpeeled_conflicting_collectives;\n-    for (HloInstruction* instr : FindAllConflictingCollectives(peeled.instr)) {\n-      if (peeled_send_recvs_set.contains(instr)) continue;\n-      unpeeled_conflicting_collectives.insert(instr);\n-    }\n-    VLOG(5) << \"Conflicting collectives: \"\n-            << unpeeled_conflicting_collectives.size();\n-\n-    // We separate unpeeled conflicting collectives into two categories: those\n-    // dominating the while loop (while loop has a data dependency on them), and\n-    // those that don't.\n-    std::vector<HloInstruction*> dominating_unpeeled_conflicting_collectives;\n-    for (HloInstruction* instr :\n-         peeled.while_instr->parent()->MakeInstructionPostOrderFrom(\n-             *peeled.while_instr)) {\n-      if (unpeeled_conflicting_collectives.contains(instr)) {\n-        dominating_unpeeled_conflicting_collectives.push_back(instr);\n-        unpeeled_conflicting_collectives.erase(instr);\n-      }\n-    }\n-\n-    // Add control dependencies from dominating conflicting collectives to the\n-    // peeled send/recv instruction. This guarantees that the conflicting\n-    // collectives cannot slip in between the peeled send/recv instructions\n-    // where it could cause a deadlock.\n-    VLOG(5) << \"Adding control dependencies FROM dominating conflicting\";\n-    TF_RETURN_IF_ERROR(AddControlDependencies(\n-        dominating_unpeeled_conflicting_collectives, peeled.instr));\n-\n-    // Add control dependencies from the final peeleled send/recv-done\n-    // instruction to the conflicting collectives that are dominated by the\n-    // while loop. This guarantees that the conflicting collectives cannot slip\n-    // in between the peeled send/recv instructions where it could cause a\n-    // deadlock.\n-    VLOG(5) << \"Adding control dependencies TO dominating conflicting\";\n-    HloInstruction* done_op = FindSendRecvDoneInstruction(peeled.instr);\n-    CHECK_NE(done_op, nullptr);\n-    TF_RETURN_IF_ERROR(\n-        AddControlDependencies(done_op, unpeeled_conflicting_collectives));\n-  }\n-\n-  return absl::OkStatus();\n-}\n-\n-static absl::Status PostProcessPeeledSendRecvOps(\n-    const std::vector<HloInstruction*>& peeled) {\n-  std::vector<PeeledHloInstructionInfo> peeled_info;\n-\n-  // For each peeled non-trailing send/recv instruction, find the corresponding\n-  // while loop. The while loop is the immediate user of the recv -> recv-done\n-  // chain.\n-  for (HloInstruction* instr : peeled) {\n-    HloInstruction* instr_start = GetSendRecvStartInstruction(instr);\n-    CHECK_NE(instr_start, nullptr);\n-\n-    // Find the while loop.\n-    HloInstruction* peeled_instr = instr_start;\n-    CHECK_EQ(peeled_instr->user_count(), 1);\n-    HloInstruction* closest_to_while_op = peeled_instr->users().front();\n-    if (closest_to_while_op->opcode() == HloOpcode::kRecvDone ||\n-        closest_to_while_op->opcode() == HloOpcode::kSendDone) {\n-      CHECK_EQ(closest_to_while_op->user_count(), 1);\n-      closest_to_while_op = closest_to_while_op->users().front();\n-    }\n-    HloInstruction* tuple_op = closest_to_while_op;\n-    CHECK_EQ(tuple_op->opcode(), HloOpcode::kTuple);\n-    CHECK_EQ(tuple_op->user_count(), 1);\n-    HloInstruction* while_op = tuple_op->users().front();\n-    CHECK_EQ(while_op->opcode(), HloOpcode::kWhile);\n-\n-    peeled_info.push_back({instr_start, while_op});\n-  }\n-\n-  // Post-process peeled send/recv ops with the now known corresponding while\n-  // loop.\n-  return PostProcessPeeledSendRecvOps(peeled_info);\n-}\n-\n-absl::StatusOr<bool> GpuP2PPipeliner::Run(\n-    HloModule* module,\n-    const absl::flat_hash_set<absl::string_view>& execution_threads) {\n-  HloPredicate should_process = ShouldPipeline;\n-  CollectivePipeliner::HloPostprocessor postprocess_backward_peeled_op =\n-      PostprocessPeeledP2P;\n-  CollectivePipeliner::HloPostprocessor postprocess_backward_rotated_op =\n-      PostprocessRotatedP2P;\n-  CollectivePipeliner::HloPostprocessor postprocess_backward_peeled_trailing_op;\n-\n-  // If partial send/recv pipelining is enabled, collect send/recv instructions\n-  // for post-processing.\n-  std::vector<HloInstruction*> peeled_send_recvs;\n-  std::vector<HloInstruction*> rotated_send_recvs;\n-  std::vector<PeeledHloInstructionInfo> peeled_trailing_send_recvs;\n-\n-  if (enable_partial_send_recv_pipelining_) {\n-    should_process = FullyPipelineRecv;\n-    postprocess_backward_peeled_op = [&](HloInstruction* it,\n-                                         HloInstruction* new_while_instr) {\n-      // When post-processing non-trailing peeled send/recv, the new while loop\n-      // was not yet created.\n-      CHECK_EQ(new_while_instr, nullptr);\n-      peeled_send_recvs.push_back(it);\n-      return absl::OkStatus();\n-    };\n-    postprocess_backward_rotated_op = [&](HloInstruction* it,\n-                                          HloInstruction* new_while_instr) {\n-      // When post-processing non-trailing peeled send/recv, the new while loop\n-      // was not yet created.\n-      CHECK_EQ(new_while_instr, nullptr);\n-      rotated_send_recvs.push_back(it);\n-      return absl::OkStatus();\n-    };\n-    postprocess_backward_peeled_trailing_op =\n-        [&](HloInstruction* it, HloInstruction* new_while_instr) {\n-          // When post-processing trailing peeled send/recv, we need the new\n-          // while loop.\n-          CHECK_NE(new_while_instr, nullptr);\n-          peeled_trailing_send_recvs.push_back({it, new_while_instr});\n-          return absl::OkStatus();\n-        };\n-  }\n-\n-  // Run pipeliner.\n-  CollectivePipeliner::Config config{\n-      /*level_to_operate_on=*/0,\n-      // Pipeline everything annotated for pipelining.\n-      /*max_pipelining_per_loop=*/INT64_MAX,\n-      /*last_run=*/true,\n-      /*pipeline_use_tree=*/false,\n-      /*process_different_sized_ops=*/true,\n-      /*pipelining_direction=*/\n-      collective_pipeliner_utils::PipeliningDirection::kBackward,\n-      /*should_process=*/should_process,\n-      /*acceptable_formatting=*/HloPredicateTrue,\n-      /*reuse_pipelined_op_buffer=*/HloPredicateTrue,\n-      /*should_allow_loop_variant_parameter_in_chain=*/\n-      ShouldAllowLoopVariantParameterInChain,\n-      /*should_allow_control_dependencies=*/true,\n-      /*postprocess_backward_peeled_op=*/postprocess_backward_peeled_op,\n-      /*postprocess_backward_rotated_op=*/postprocess_backward_rotated_op,\n-      /*postprocess_backward_peeled_trailing_op=*/\n-      postprocess_backward_peeled_trailing_op};\n-  TF_ASSIGN_OR_RETURN(\n-      bool changed, CollectivePipeliner(config).Run(module, execution_threads));\n-\n-  VLOG(5) << \"After pipelining, before post-processing:\";\n-  XLA_VLOG_LINES(5, module->ToString());\n-\n-  // Post-process rotated and peeled send/recv ops to add control dependencies\n-  // with conflicting collectives.\n-  if (enable_partial_send_recv_pipelining_) {\n-    TF_RETURN_IF_ERROR(PostProcessRotatedSendRecvOps(rotated_send_recvs));\n-    TF_RETURN_IF_ERROR(\n-        PostProcessPeeledSendRecvOps(peeled_trailing_send_recvs));\n-    TF_RETURN_IF_ERROR(PostProcessPeeledSendRecvOps(peeled_send_recvs));\n-  }\n-\n-  VLOG(5) << \"After post-processing:\";\n-  XLA_VLOG_LINES(5, module->ToString());\n-\n-  return changed;\n-}\n-\n-}  // namespace gpu\n-}  // namespace xla"
        },
        {
            "sha": "06e791ad67ef42f31a9e07dcd589f6b80c8fe26d",
            "filename": "third_party/xla/xla/service/gpu/gpu_p2p_pipeliner.h",
            "status": "removed",
            "additions": 0,
            "deletions": 43,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9f02b8aa9ff936c90c41f3a31c74eae5b758ff71/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_p2p_pipeliner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9f02b8aa9ff936c90c41f3a31c74eae5b758ff71/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_p2p_pipeliner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_p2p_pipeliner.h?ref=9f02b8aa9ff936c90c41f3a31c74eae5b758ff71",
            "patch": "@@ -1,43 +0,0 @@\n-/* Copyright 2024 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_SERVICE_GPU_GPU_P2P_PIPELINER_H_\n-#define XLA_SERVICE_GPU_GPU_P2P_PIPELINER_H_\n-\n-#include \"xla/hlo/pass/hlo_pass_pipeline.h\"\n-\n-namespace xla {\n-namespace gpu {\n-\n-class GpuP2PPipeliner : public HloModulePass {\n- public:\n-  explicit GpuP2PPipeliner(bool enable_partial_send_recv_pipelining)\n-      : enable_partial_send_recv_pipelining_(\n-            enable_partial_send_recv_pipelining) {}\n-\n-  absl::string_view name() const override { return \"gpu-p2p-pipeliner\"; }\n-\n-  absl::StatusOr<bool> Run(\n-      HloModule* module,\n-      const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n-\n- private:\n-  bool enable_partial_send_recv_pipelining_;\n-};\n-\n-}  // namespace gpu\n-}  // namespace xla\n-\n-#endif  // XLA_SERVICE_GPU_GPU_P2P_PIPELINER_H_"
        },
        {
            "sha": "fad6b1141b28abcaca53450caba6bcac312a1ac0",
            "filename": "third_party/xla/xla/service/gpu/gpu_p2p_pipeliner_test.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 857,
            "changes": 857,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9f02b8aa9ff936c90c41f3a31c74eae5b758ff71/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_p2p_pipeliner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9f02b8aa9ff936c90c41f3a31c74eae5b758ff71/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_p2p_pipeliner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_p2p_pipeliner_test.cc?ref=9f02b8aa9ff936c90c41f3a31c74eae5b758ff71",
            "patch": "@@ -1,857 +0,0 @@\n-/* Copyright 2024 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/gpu/gpu_p2p_pipeliner.h\"\n-\n-#include <cstdint>\n-#include <memory>\n-#include <string>\n-\n-#include <gmock/gmock.h>\n-#include <gtest/gtest.h>\n-#include \"absl/log/check.h\"\n-#include \"absl/status/statusor.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"xla/hlo/ir/hlo_casting_utils.h\"\n-#include \"xla/hlo/ir/hlo_computation.h\"\n-#include \"xla/hlo/ir/hlo_instruction.h\"\n-#include \"xla/hlo/ir/hlo_instructions.h\"\n-#include \"xla/hlo/ir/hlo_module.h\"\n-#include \"xla/hlo/ir/hlo_opcode.h\"\n-#include \"xla/hlo/parser/hlo_parser.h\"\n-#include \"xla/hlo/pass/hlo_pass_pipeline.h\"\n-#include \"xla/hlo/testlib/filecheck.h\"\n-#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n-#include \"xla/hlo/testlib/pattern_matcher_gmock.h\"\n-#include \"xla/service/hlo_module_config.h\"\n-#include \"xla/service/hlo_verifier.h\"\n-#include \"xla/service/pattern_matcher.h\"\n-#include \"xla/util.h\"\n-\n-namespace xla {\n-namespace gpu {\n-namespace {\n-\n-namespace m = xla::match;\n-using ::testing::IsEmpty;\n-using ::testing::UnorderedElementsAre;\n-\n-class GpuP2PPipelinerTest : public HloHardwareIndependentTestBase {\n- public:\n-  GpuP2PPipelinerTest() {\n-    const int64_t kNumReplicas = 1;\n-    const int64_t kNumPartitions = 4;\n-    config_ = GetModuleConfigForTest(/*replica_count=*/kNumReplicas,\n-                                     /*num_partitions=*/kNumPartitions);\n-  }\n-\n-  absl::StatusOr<bool> RunOptimizer(\n-      HloModule* module, bool enable_partial_send_recv_pipelining = false) {\n-    HloPassPipeline pipeline(\"optimizer\");\n-    pipeline.AddPass<HloVerifier>(/*layout_sensitive=*/false,\n-                                  /*allow_mixed_precision=*/false);\n-    pipeline.AddPass<GpuP2PPipeliner>(enable_partial_send_recv_pipelining);\n-    pipeline.AddPass<HloVerifier>(/*layout_sensitive=*/false,\n-                                  /*allow_mixed_precision=*/false);\n-    return pipeline.Run(module);\n-  }\n-\n- protected:\n-  HloModuleConfig config_;\n-};\n-\n-TEST_F(GpuP2PPipelinerTest,\n-       TransformRecvSendBackwardsWithMetaDataPostProcessing) {\n-  const char* kHloStr = R\"(\n-  HloModule module\n-  cond {\n-    param = (u32[], u32[2]) parameter(0)\n-    count = get-tuple-element(param), index=0\n-    ub = u32[] constant(10)\n-    ROOT result = pred[] compare(count, ub), direction=LT\n-  }\n-\n-  body {\n-    param = (u32[], u32[2]) parameter(0)\n-    count = get-tuple-element(param), index=0\n-    send-data = get-tuple-element(param), index=1\n-\n-    after-all.0 = token[] after-all()\n-    recv.0 = (u32[2], u32[], token[]) recv(after-all.0), channel_id=1,\n-      frontend_attributes={\n-        _xla_send_recv_source_target_pairs=\"{{1,0}}\",\n-        _xla_send_recv_pipeline=\"0\",\n-        _xla_send_recv_validation=\"{{1,7}}\"\n-      }\n-    after-all.0.s = token[] after-all()\n-    send.0 = (u32[2], u32[], token[]) send(send-data, after-all.0.s),\n-      channel_id=1, frontend_attributes={\n-        _xla_send_recv_source_target_pairs=\"{{1,0}}\",\n-        _xla_send_recv_pipeline=\"0\",\n-        _xla_send_recv_validation=\"{{1,7}}\"\n-      }\n-    recv-done.0 = (u32[2], token[]) recv-done(recv.0), channel_id=1,\n-      frontend_attributes={\n-        _xla_send_recv_pipeline=\"0\"\n-      }, control-predecessors={send.0}\n-    recv_data = u32[2] get-tuple-element(recv-done.0), index=0\n-\n-    c1 = u32[] constant(1)\n-    new_count = u32[] add(count, c1)\n-\n-    r = u32[2] broadcast(c1), dimensions={}\n-    s = u32[2] add(r, recv_data)\n-\n-    send-done.0 = token[] send-done(send.0), channel_id=1,\n-      frontend_attributes={\n-        _xla_send_recv_pipeline=\"0\"\n-      }\n-    ROOT result = (u32[], u32[2]) tuple(new_count, s)\n-  }\n-\n-  ENTRY test_computation {\n-    c0 = u32[] constant(0)\n-    c1 = u32[] constant(1)\n-    r = u32[] replica-id()\n-    a = u32[] add(c1, r)\n-    init = u32[2] broadcast(a), dimensions={}\n-    while_init = (u32[], u32[2]) tuple(c0, init)\n-    while_result = (u32[], u32[2]) while(while_init), body=body, condition=cond\n-    ROOT result = u32[2] get-tuple-element(while_result), index=1\n-  })\";\n-\n-  auto module = ParseAndReturnUnverifiedModule(kHloStr, config_).value();\n-  EXPECT_TRUE(RunOptimizer(module.get()).value());\n-  XLA_VLOG_LINES(10, module->ToString());\n-  auto while_op = FindInstruction(module.get(), \"while\");\n-  EXPECT_EQ(while_op->opcode(), HloOpcode::kWhile);\n-  EXPECT_EQ(while_op->shape().tuple_shapes().size(), 5);\n-  auto recv1 =\n-      DynCast<HloRecvInstruction>(FindInstruction(module.get(), \"recv.1\"));\n-  EXPECT_NE(recv1, nullptr);\n-  auto recv2 =\n-      DynCast<HloRecvInstruction>(FindInstruction(module.get(), \"recv.2\"));\n-  EXPECT_NE(recv2, nullptr);\n-  EXPECT_EQ(recv1->channel_id(), recv2->channel_id());\n-\n-  auto send1 =\n-      DynCast<HloSendInstruction>(FindInstruction(module.get(), \"send.1\"));\n-  EXPECT_NE(send1, nullptr);\n-  auto send2 =\n-      DynCast<HloSendInstruction>(FindInstruction(module.get(), \"send.2\"));\n-  EXPECT_NE(send2, nullptr);\n-  EXPECT_EQ(send1->channel_id(), send2->channel_id());\n-\n-  const char* kPeeledAttr = \"_xla_send_recv_validation=\\\"invalid\\\"\";\n-  const char* kRotatedAttr = \"_xla_send_recv_validation={{0,6}}\";\n-  EXPECT_THAT(send1->ToString(), ::testing::HasSubstr(kPeeledAttr));\n-  EXPECT_THAT(recv1->ToString(), ::testing::HasSubstr(kPeeledAttr));\n-  EXPECT_THAT(send2->ToString(), ::testing::HasSubstr(kRotatedAttr));\n-  EXPECT_THAT(recv2->ToString(), ::testing::HasSubstr(kRotatedAttr));\n-}\n-\n-TEST_F(GpuP2PPipelinerTest, SendRecvForwardCycle) {\n-  const char* kHloStr = R\"(\n-  HloModule test\n-\n-  while_body {\n-    inputs = (u32[], f32[2,2], f32[2,2]) parameter(0)\n-    iter = u32[] get-tuple-element(inputs), index=0\n-    iter_increment = u32[] constant(1)\n-    next_iter = u32[] add(iter, iter_increment)\n-    weights = f32[2,2] get-tuple-element(inputs), index=2\n-    partition-id = u32[] partition-id()\n-    zero = u32[] constant(0)\n-    compare = pred[] compare(partition-id, zero), direction=EQ\n-    broadcast = pred[2,2] broadcast(compare), dimensions={}\n-    data = f32[2,2] get-tuple-element(inputs), index=1\n-    after-all = token[] after-all()\n-\n-    send = (f32[2,2], u32[], token[]) send(data, after-all), channel_id=1,\n-      frontend_attributes={\n-        _xla_send_recv_pipeline=\"0\",\n-        _xla_send_recv_source_target_pairs=\"{{3,0}}\",\n-        _xla_send_recv_validation=\"{{3,10}}\"\n-      }\n-    recv = (f32[2,2], u32[], token[]) recv(after-all), channel_id=1,\n-      frontend_attributes={\n-        _xla_send_recv_pipeline=\"0\",\n-        _xla_send_recv_source_target_pairs=\"{{3,0}}\",\n-        _xla_send_recv_validation=\"{{3,10}}\"\n-      }\n-    recv-done = (f32[2,2], token[]) recv-done(recv), channel_id=1,\n-      frontend_attributes={_xla_send_recv_pipeline=\"0\"}, control-predecessors={send}\n-    recv-done-data = f32[2,2] get-tuple-element(recv-done), index=0\n-    after-all.1 = token[] after-all()\n-    send.1 = (f32[2,2], u32[], token[]) send(data, after-all.1), channel_id=2,\n-      frontend_attributes={\n-        _xla_send_recv_pipeline=\"1\",\n-        _xla_send_recv_source_target_pairs=\"{{0,1},{1,2},{2,3}}\",\n-        _xla_send_recv_validation=\"{{0,7},{1,8},{2,9}}\"\n-      }\n-    recv.1 = (f32[2,2], u32[], token[]) recv(after-all.1), channel_id=2,\n-      frontend_attributes={\n-        _xla_send_recv_pipeline=\"1\",\n-        _xla_send_recv_source_target_pairs=\"{{0,1},{1,2},{2,3}}\",\n-        _xla_send_recv_validation=\"{{0,7},{1,8},{2,9}}\"\n-      }\n-    recv-done.1 = (f32[2,2], token[]) recv-done(recv.1), channel_id=2,\n-      frontend_attributes={_xla_send_recv_pipeline=\"1\"}, control-predecessors={send.1}\n-    recv-done-1-data = f32[2,2] get-tuple-element(recv-done.1), index=0\n-    select = f32[2,2] select(broadcast, recv-done-data, recv-done-1-data)\n-    matmul = f32[2,2] dot(weights, select),\n-      lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-\n-    ROOT result = (u32[], f32[2,2], f32[2,2]) tuple(next_iter, matmul, weights)\n-\n-    send-done = token[] send-done(send), channel_id=1,\n-      frontend_attributes={_xla_send_recv_pipeline=\"0\"}\n-    send-done.1 = token[] send-done(send.1), channel_id=2,\n-      frontend_attributes={_xla_send_recv_pipeline=\"1\"}\n-  }\n-\n-  while_cond {\n-    inputs = (u32[], f32[2,2], f32[2,2]) parameter(0)\n-    iter = u32[] get-tuple-element(inputs), index=0\n-    max_iter = u32[] constant(3)\n-    ROOT compare = pred[] compare(iter, max_iter), direction=LT\n-  }\n-\n-  ENTRY test_computation {\n-    start_iter = u32[] constant(0)\n-    input_data = f32[2,2] parameter(0)\n-    input_weights = f32[2,2] parameter(1)\n-    input = (u32[], f32[2,2], f32[2,2]) tuple(start_iter, input_data, input_weights)\n-    while_result = (u32[], f32[2,2], f32[2,2]) while(input), condition=while_cond, body=while_body\n-    ROOT data_out = f32[2,2] get-tuple-element(while_result), index=1\n-  }\n-  )\";\n-  auto module = ParseAndReturnUnverifiedModule(kHloStr, config_).value();\n-  EXPECT_TRUE(RunOptimizer(module.get()).value());\n-  EXPECT_TRUE(RunFileCheck(module->ToString(), R\"(\n-    // Check there are two sets of send/recv in main while loop, one set for the\n-    // back edge and one set for the forward edge. Also check that the send/recv\n-    // target pairs and validation attributes are correct.\n-    CHECK: %[[RECV_BWD_START:.*]] = {{.*}} after-all()\n-    CHECK: %[[RECV_BWD:.*]] = {{.*}} recv(%[[RECV_BWD_START:.*]]), channel_id=1, frontend_attributes={_xla_send_recv_pipeline=\"0\",_xla_send_recv_source_target_pairs={{[{][{]}}3,0{{[}][}]}},_xla_send_recv_validation={{[{][{]}}2,9{{[}][}]}}}\n-    CHECK: %[[RECV_DONE_BWD:.*]] = {{.*}} recv-done(%[[RECV_BWD:.*]]), channel_id=1, frontend_attributes={_xla_send_recv_pipeline=\"0\"}\n-    CHECK: %[[RECV_FWD_START:.*]] = {{.*}} after-all()\n-    CHECK: %[[RECV_FWD:.*]] = {{.*}} recv(%[[RECV_FWD_START:.*]]), channel_id=2, frontend_attributes={_xla_send_recv_pipeline=\"1\",_xla_send_recv_source_target_pairs={{[{][{]}}0,1},{1,2},{2,3{{[}][}]}},_xla_send_recv_validation={{[{][{]}}0,6},{0,7},{1,8{{[}][}]}}}\n-    CHECK: %[[RECV_DONE_FWD:.*]] = {{.*}} recv-done(%[[RECV_FWD:.*]]), channel_id=2, frontend_attributes={_xla_send_recv_pipeline=\"1\"}\n-    CHECK: %[[SEND_BWD:.*]] = {{.*}} send(%[[RECV_BWD_START:.*]]), channel_id=1, frontend_attributes={_xla_send_recv_pipeline=\"0\",_xla_send_recv_source_target_pairs={{[{][{]}}3,0{{[}][}]}},_xla_send_recv_validation={{[{][{]}}2,9{{[}][}]}}}\n-    CHECK: %[[SEND_DONE_BWD:.*]] = {{.*}} send-done(%[[SEND_BWD:.*]]), channel_id=1, frontend_attributes={_xla_send_recv_pipeline=\"0\"}\n-    CHECK: %[[SEND_FWD:.*]] = {{.*}} send(%[[RECV_FWD_START:.*]]), channel_id=2, frontend_attributes={_xla_send_recv_pipeline=\"1\",_xla_send_recv_source_target_pairs={{[{][{]}}0,1},{1,2},{2,3{{[}][}]}},_xla_send_recv_validation={{[{][{]}}0,6},{0,7},{1,8{{[}][}]}}}\n-    CHECK: %[[SEND_DONE_FWD:.*]] = {{.*}} send-done(%[[SEND_FWD:.*]]), channel_id=2, frontend_attributes={_xla_send_recv_pipeline=\"1\"}\n-    // Check that the total iterations of the while loop in the output is 1\n-    // fewer than the max iteration of the input HLO.\n-    CHECK: %[[WHILE_COND:.*]] (cond_param: {{.*}}\n-    CHECK-NEXT: %[[COND_PARAM:.*]] = {{.*}} parameter(0)\n-    CHECK: %[[CURRENT_ITER:.*]] = {{.*}} get-tuple-element(%[[COND_PARAM:.*]]), index=0\n-    CHECK: %[[TWO:.*]] = {{.*}} constant(2)\n-    CHECK: ROOT %[[COMPARE:.*]] = pred[] compare(%[[CURRENT_ITER:.*]], %[[TWO:.*]]), direction=LT\n-\n-    // Check that after transformation, main function in ENTRY contains the\n-    // first iteration of the while loop.\n-    CHECK: ENTRY %[[TEST_COMPUTATION:.*]] (input_data: {{.*}}\n-\n-    // Set up dummy send and recv.\n-    CHECK: %[[RECV_BWD_DUMMY_START:.*]] = {{.*}} after-all()\n-    CHECK: %[[RECV_BWD_DUMMY:.*]] = {{.*}} recv(%[[RECV_BWD_DUMMY_START:.*]]), channel_id=1, frontend_attributes={_xla_send_recv_pipeline=\"0\",_xla_send_recv_source_target_pairs={{[{][{]}}3,0{{[}][}]}},_xla_send_recv_validation=\"invalid\"}\n-    CHECK: %[[RECV_DONE_BWD_DUMMY:.*]] = {{.*}} recv-done(%[[RECV_BWD_DUMMY:.*]]), channel_id=1, frontend_attributes={_xla_send_recv_pipeline=\"0\"}\n-\n-    // Execute what was previously iter 0 of the while loop.\n-    CHECK: %[[RECV_FWD_FIRST_ITER_START:.*]] = {{.*}} after-all()\n-    CHECK: %[[RECV_FWD_FIRST_ITER:.*]] = {{.*}} recv(%[[RECV_FWD_FIRST_ITER_START:.*]]), channel_id=2, frontend_attributes={_xla_send_recv_pipeline=\"1\",_xla_send_recv_source_target_pairs={{[{][{]}}0,1},{1,2},{2,3{{[}][}]}},_xla_send_recv_validation={{[{][{]}}0,0},{1,0},{1,0{{[}][}]}}}\n-    CHECK: %[[RECV_DONE_FWD_FIRST_ITER:.*]] = {{.*}} recv-done(%[[RECV_FWD_FIRST_ITER:.*]]), channel_id=2, frontend_attributes={_xla_send_recv_pipeline=\"1\"}\n-    CHECK: %[[SEND_BWD_DUMMY:.*]] = {{.*}} send(%[[RECV_DUMMY_START:.*]]), channel_id=1, frontend_attributes={_xla_send_recv_pipeline=\"0\",_xla_send_recv_source_target_pairs={{[{][{]}}3,0{{[}][}]}},_xla_send_recv_validation=\"invalid\"}\n-    CHECK: %[[SEND_DONE_BWD_DUMMY:.*]] = {{.*}} send-done(%[[SEND_BWD_DUMMY:.*]]), channel_id=1, frontend_attributes={_xla_send_recv_pipeline=\"0\"}\n-    CHECK: %[[SEND_FWD_FIRST_ITER:.*]] = {{.*}} send(%[[RECV_FWD_FIRST_ITER_START:.*]]), channel_id=2, frontend_attributes={_xla_send_recv_pipeline=\"1\",_xla_send_recv_source_target_pairs={{[{][{]}}0,1},{1,2},{2,3{{[}][}]}},_xla_send_recv_validation={{[{][{]}}0,0},{1,0},{1,0{{[}][}]}}}\n-    CHECK: %[[SEND_DONE_FWD_FIRST_ITER:.*]] = {{.*}} send-done(%[[SEND_FWD_FIRST_ITER:.*]]), channel_id=2, frontend_attributes={_xla_send_recv_pipeline=\"1\"}\n-\n-    // Set up main loop, starting from iter 1.\n-    CHECK: %[[START_LOOP_FROM_ITER_ONE:.*]] = u32[] constant(1)\n-    CHECK: %[[LOOP_INPUT:.*]] = {{.*}} tuple(%[[START_LOOP_FROM_ITER_ONE:.*]])\n-    CHECK: %[[WHILE:.*]] = {{.*}} while(%[[LOOP_INPUT:.*]]), {{.*}}\n-  )\")\n-                  .value());\n-}\n-\n-// Expect leading recv and recv-done to be pipelined but none of the other\n-// send/recv ops.\n-TEST_F(GpuP2PPipelinerTest, PipelineParallelismExperimentalOpt) {\n-  const char* kHloStr = R\"(\n-    HloModule test\n-\n-    while_cond {\n-      inputs = (u32[], f32[2,2], f32[2,2]) parameter(0)\n-      iter = u32[] get-tuple-element(inputs), index=0\n-      max_iter = u32[] constant(3)\n-      ROOT compare = pred[] compare(iter, max_iter), direction=LT\n-    }\n-\n-    while_body {\n-      inputs = (u32[], f32[2,2], f32[2,2]) parameter(0)\n-      iter = u32[] get-tuple-element(inputs), index=0\n-      iter_increment = u32[] constant(1)\n-      next_iter = u32[] add(iter, iter_increment)\n-      weights = f32[2,2] get-tuple-element(inputs), index=2\n-      partition-id = u32[] partition-id()\n-      zero = u32[] constant(0)\n-      compare = pred[] compare(partition-id, zero), direction=EQ\n-      broadcast = pred[2,2] broadcast(compare), dimensions={}\n-      data = f32[2,2] get-tuple-element(inputs), index=1\n-      after-all = token[] after-all()\n-      recv = (f32[2,2], u32[], token[]) recv(after-all), channel_id=1,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}}\n-      recv-done = (f32[2,2], token[]) recv-done(recv), channel_id=1\n-      send = (f32[2,2], u32[], token[]) send(data, after-all), channel_id=1,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}},\n-          control-predecessors={recv}\n-      send-done = token[] send-done(send), channel_id=1,\n-          control-predecessors={recv-done}\n-      after-all.1 = token[] after-all()\n-      recv.1 = (f32[2,2], u32[], token[]) recv(after-all.1), channel_id=2,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{3,0}}},\n-          control-predecessors={send}\n-      recv-done.1 = (f32[2,2], token[]) recv-done(recv.1), channel_id=2,\n-          control-predecessors={send-done}\n-      send.1 = (f32[2,2], u32[], token[]) send(data, after-all.1), channel_id=2,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{3,0}}},\n-          control-predecessors={recv.1}\n-      send-done.1 = token[] send-done(send.1), channel_id=2,\n-          control-predecessors={recv-done.1}\n-      recv-done-data = f32[2,2] get-tuple-element(recv-done), index=0\n-      recv-done-1-data = f32[2,2] get-tuple-element(recv-done.1), index=0\n-      select = f32[2,2] select(broadcast, recv-done-data, recv-done-1-data)\n-      matmul = f32[2,2] dot(weights, select),\n-          lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-      ROOT result = (u32[], f32[2,2], f32[2,2]) tuple(next_iter, matmul,\n-          weights)\n-    }\n-\n-    ENTRY test_computation {\n-      start_iter = u32[] constant(0)\n-      input_data = f32[2,2] parameter(0)\n-      input_weights = f32[2,2] parameter(1)\n-      input = (u32[], f32[2,2], f32[2,2]) tuple(start_iter, input_data,\n-      input_weights) while_result = (u32[], f32[2,2], f32[2,2]) while(input),\n-      condition=while_cond, body=while_body ROOT data_out = f32[2,2]\n-      get-tuple-element(while_result), index=1\n-    }\n-  )\";\n-\n-  TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnUnverifiedModule(kHloStr, config_));\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      bool changed, RunOptimizer(module.get(),\n-                                 /*enable_partial_send_recv_pipelining=*/true));\n-  EXPECT_TRUE(changed);\n-\n-  EXPECT_TRUE(RunFileCheck(module->ToString(), R\"(\n-    // Check that recv and recv-done ops are rotated in loop body.\n-    // CHECK:      %[[WHILE_BODY:while_body[\\w\\.]+]]\n-    // CHECK:        send(\n-    // CHECK:        send-done(\n-    // CHECK:        recv(\n-    // CHECK:        recv-done(\n-    // CHECK:        send(\n-    // CHECK:        send-done(\n-    // CHECK:        recv(\n-    // CHECK:        recv-done(\n-\n-    // Check that recv and recv-done ops are peeled out of the while loop.\n-    // CHECK:      ENTRY %test_computation\n-    // CHECK:        recv(\n-    // CHECK:        recv-done(\n-    // CHECK:        while(\n-    // CHECK-SAME:   body=%[[WHILE_BODY]]\n-    // CHECK:        send(\n-    // CHECK:        send-done(\n-    // CHECK:        recv(\n-    // CHECK:        recv-done(\n-    // CHECK:        send(\n-    // CHECK:        send-done(\n-    )\")\n-                  .value());\n-}\n-\n-TEST_F(GpuP2PPipelinerTest, OneSendRecvWithOneConflictingAllReduce) {\n-  const char* kHloStr = R\"(\n-    HloModule test\n-\n-    add {\n-      lhs = f32[] parameter(0)\n-      rhs = f32[] parameter(1)\n-      ROOT add = f32[] add(lhs, rhs)\n-    }\n-\n-    cond {\n-      param = (u32[], f32[64], f32[64]) parameter(0)\n-      i = u32[] get-tuple-element(param), index=0\n-      n = u32[] constant(2)\n-      ROOT result = pred[] compare(i, n), direction=LT\n-    }\n-\n-    body {\n-      param = (u32[], f32[64], f32[64]) parameter(0)\n-      i = u32[] get-tuple-element(param), index=0\n-      data_a = f32[64] get-tuple-element(param), index=1\n-      data_b = f32[64] get-tuple-element(param), index=2\n-\n-      // Decomposed cp_fwd.\n-      after-all = token[] after-all()\n-      recv = (f32[64], u32[], token[]) recv(after-all), channel_id=1,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}}\n-      send = (f32[64], u32[], token[]) send(data_a, after-all), channel_id=1,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}},\n-          control-predecessors={recv}\n-      recv_done = (f32[64], token[]) recv-done(recv), channel_id=1\n-      send_done = token[] send-done(send), channel_id=1\n-      recv_data = f32[64] get-tuple-element(recv_done), index=0\n-\n-      // Conflicting all-reduce.\n-      ar = f32[64] all-reduce(data_b), channel_id=2, replica_groups={{0,1,2,3}},\n-          to_apply=add, control-predecessors={send_done}\n-\n-      c1 = u32[] constant(1)\n-      i_ = u32[] add(u32[] i, u32[] c1)\n-\n-      ROOT result = (u32[], f32[64], f32[64]) tuple(i_, recv_data, ar)\n-    }\n-\n-    ENTRY entry {\n-      c0 = u32[] constant(0)\n-      a = f32[] constant(42)\n-      data = f32[64] broadcast(a), dimensions={}\n-      while_init = (u32[], f32[64], f32[64]) tuple(c0, data, data)\n-      ROOT result = (u32[], f32[64], f32[64]) while(while_init), condition=cond,\n-         body=body\n-    }\n-  )\";\n-  TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnUnverifiedModule(kHloStr, config_));\n-\n-  // Run pass.\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      bool changed,\n-      RunOptimizer(module.get(), /*enable_partial_send_recv_pipelining=*/true));\n-  EXPECT_TRUE(changed);\n-\n-  // Find while loop.\n-  HloInstruction* while_op = FindInstruction(module.get(), \"while\");\n-  HloComputation* body = while_op->while_body();\n-\n-  // Find ops in while loop body.\n-  HloInstruction* send_op = FindInstruction(module.get(), \"send.1\");\n-  HloInstruction* send_done_op = FindInstruction(module.get(), \"send_done.1\");\n-  HloInstruction* ar_op = FindInstruction(module.get(), \"ar.1\");\n-  HloInstruction* recv_op = FindInstruction(module.get(), \"recv.2\");\n-  HloInstruction* recv_done_op = FindInstruction(module.get(), \"recv_done.2\");\n-  EXPECT_EQ(send_op->parent(), body);\n-  EXPECT_EQ(send_done_op->parent(), body);\n-  EXPECT_EQ(ar_op->parent(), body);\n-  EXPECT_EQ(recv_op->parent(), body);\n-  EXPECT_EQ(recv_done_op->parent(), body);\n-\n-  // Expect control dependencies from rotated recv and recv-done to conflicting\n-  // all-reduce.\n-  EXPECT_THAT(send_op->control_predecessors(), IsEmpty());\n-  EXPECT_THAT(send_done_op->control_predecessors(), IsEmpty());\n-  EXPECT_THAT(ar_op->control_predecessors(),\n-              UnorderedElementsAre(send_done_op));\n-  EXPECT_THAT(recv_op->control_predecessors(),\n-              UnorderedElementsAre(send_done_op, ar_op));\n-  EXPECT_THAT(recv_done_op->control_predecessors(), IsEmpty());\n-}\n-\n-TEST_F(GpuP2PPipelinerTest, OneSendRecvWithConflictingAllReduceAfterLoop) {\n-  const char* kHloStr = R\"(\n-    HloModule test\n-\n-    add {\n-      lhs = f32[] parameter(0)\n-      rhs = f32[] parameter(1)\n-      ROOT add = f32[] add(lhs, rhs)\n-    }\n-\n-    cond {\n-      param = (u32[], f32[64]) parameter(0)\n-      i = u32[] get-tuple-element(param), index=0\n-      n = u32[] constant(2)\n-      ROOT result = pred[] compare(i, n), direction=LT\n-    }\n-\n-    body {\n-      param = (u32[], f32[64]) parameter(0)\n-      i = u32[] get-tuple-element(param), index=0\n-      data = f32[64] get-tuple-element(param), index=1\n-\n-      // Decomposed cp_fwd.\n-      after-all = token[] after-all()\n-      recv = (f32[64], u32[], token[]) recv(after-all), channel_id=1,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}}\n-      recv_done = (f32[64], token[]) recv-done(recv), channel_id=1\n-      send = (f32[64], u32[], token[]) send(data, after-all), channel_id=1,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}},\n-          control-predecessors={recv}\n-      send_done = token[] send-done(send), channel_id=1,\n-          control-predecessors={recv_done}\n-      recv_data = f32[64] get-tuple-element(recv_done), index=0\n-\n-      c1 = u32[] constant(1)\n-      i_ = u32[] add(u32[] i, u32[] c1)\n-\n-      ROOT result = (u32[], f32[64]) tuple(i_, recv_data)\n-    }\n-\n-    ENTRY entry {\n-      c0 = u32[] constant(0)\n-      a = f32[] constant(42)\n-      data = f32[64] broadcast(a), dimensions={}\n-      while_init = (u32[], f32[64]) tuple(c0, data)\n-      while = (u32[], f32[64]) while(while_init), condition=cond,\n-         body=body\n-\n-      // Conflicting all-reduce after loop.\n-      while_dep_data = f32[64] get-tuple-element(while), index=1\n-      ROOT ar = f32[64] all-reduce(while_dep_data), channel_id=3,\n-          replica_groups={{0,1,2,3}}, to_apply=add\n-    }\n-  )\";\n-  TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnUnverifiedModule(kHloStr, config_));\n-\n-  // Run pass.\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      bool changed, RunOptimizer(module.get(),\n-                                 /*enable_partial_send_recv_pipelining=*/true));\n-  EXPECT_TRUE(changed);\n-\n-  // Find while loop.\n-  HloInstruction* while_op = FindInstruction(module.get(), \"while.1\");\n-  HloComputation* body = while_op->while_body();\n-\n-  // Find ops in while loop body.\n-  HloInstruction* send_op = FindInstruction(module.get(), \"send.1\");\n-  HloInstruction* send_done_op = FindInstruction(module.get(), \"send_done.1\");\n-  HloInstruction* recv_op = FindInstruction(module.get(), \"recv.2\");\n-  HloInstruction* recv_done_op = FindInstruction(module.get(), \"recv_done.2\");\n-  EXPECT_EQ(send_op->parent(), body);\n-  EXPECT_EQ(send_done_op->parent(), body);\n-  EXPECT_THAT(send_done_op, GmockMatch(m::SendDone(m::Op().Is(send_op))));\n-  EXPECT_EQ(recv_op->parent(), body);\n-  EXPECT_EQ(recv_done_op->parent(), body);\n-  EXPECT_THAT(recv_done_op, GmockMatch(m::RecvDone(m::Op().Is(recv_op))));\n-\n-  // Find peeled ops before while loop.\n-  HloInstruction* peeled_recv_op = FindInstruction(module.get(), \"recv.1\");\n-  HloInstruction* peeled_recv_done_op =\n-      FindInstruction(module.get(), \"recv_done.1\");\n-  EXPECT_THAT(peeled_recv_done_op,\n-              GmockMatch(m::RecvDone(m::Op().Is(peeled_recv_op))));\n-\n-  // Find peeled ops after while loop.\n-  HloInstruction* peeled_send_op = FindInstruction(module.get(), \"send.2\");\n-  HloInstruction* peeled_send_done_op =\n-      FindInstruction(module.get(), \"send_done.2\");\n-  EXPECT_THAT(peeled_send_done_op,\n-              GmockMatch(m::SendDone(m::Op().Is(peeled_send_op))));\n-\n-  // Find conflicting all-reduce after loop.\n-  HloInstruction* ar_op = FindInstruction(module.get(), \"ar\");\n-\n-  // Expect all peeled ops to have control dependencies to teh conflicting\n-  // all-reduce after the loop.\n-  EXPECT_THAT(ar_op->control_predecessors(),\n-              UnorderedElementsAre(peeled_send_done_op, peeled_recv_done_op));\n-}\n-\n-TEST_F(GpuP2PPipelinerTest,\n-       OneSendRecvWithConflictingAllReduceBeforeAndAfterLoop) {\n-  const char* kHloStr = R\"(\n-    HloModule test\n-\n-    add {\n-      lhs = f32[] parameter(0)\n-      rhs = f32[] parameter(1)\n-      ROOT add = f32[] add(lhs, rhs)\n-    }\n-\n-    cond {\n-      param = (u32[], f32[64]) parameter(0)\n-      i = u32[] get-tuple-element(param), index=0\n-      n = u32[] constant(2)\n-      ROOT result = pred[] compare(i, n), direction=LT\n-    }\n-\n-    body {\n-      param = (u32[], f32[64]) parameter(0)\n-      i = u32[] get-tuple-element(param), index=0\n-      data = f32[64] get-tuple-element(param), index=1\n-\n-      // Decomposed cp_fwd.\n-      after-all = token[] after-all()\n-      recv = (f32[64], u32[], token[]) recv(after-all), channel_id=1,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}}\n-      recv_done = (f32[64], token[]) recv-done(recv), channel_id=1\n-      send = (f32[64], u32[], token[]) send(data, after-all), channel_id=1,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}},\n-          control-predecessors={recv}\n-      send_done = token[] send-done(send), channel_id=1,\n-          control-predecessors={recv_done}\n-      recv_data = f32[64] get-tuple-element(recv_done), index=0\n-\n-      c1 = u32[] constant(1)\n-      i_ = u32[] add(u32[] i, u32[] c1)\n-\n-      ROOT result = (u32[], f32[64]) tuple(i_, recv_data)\n-    }\n-\n-    ENTRY entry {\n-      c0 = u32[] constant(0)\n-      a = f32[] constant(42)\n-      data = f32[64] broadcast(a), dimensions={}\n-\n-      // Conflicting all-reduce before loop.\n-      ar = f32[64] all-reduce(data), channel_id=2, replica_groups={{0,1,2,3}},\n-          to_apply=add\n-\n-      while_init = (u32[], f32[64]) tuple(c0, ar)\n-      while = (u32[], f32[64]) while(while_init), condition=cond,\n-         body=body\n-\n-      // Conflicting all-reduce after loop.\n-      while_dep_data = f32[64] get-tuple-element(while), index=1\n-      ROOT final_ar = f32[64] all-reduce(while_dep_data), channel_id=3,\n-          replica_groups={{0,1,2,3}}, to_apply=add\n-    }\n-  )\";\n-  TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnUnverifiedModule(kHloStr, config_));\n-\n-  // Run pass.\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      bool changed, RunOptimizer(module.get(),\n-                                 /*enable_partial_send_recv_pipelining=*/true));\n-  EXPECT_TRUE(changed);\n-\n-  // Find ops around the new while loop.\n-  HloInstruction* ar_op = FindInstruction(module.get(), \"ar\");\n-  HloInstruction* recv_op = FindInstruction(module.get(), \"recv.1\");\n-  HloInstruction* recv_done_op = FindInstruction(module.get(), \"recv_done.1\");\n-  EXPECT_THAT(recv_done_op, GmockMatch(m::RecvDone(m::Op().Is(recv_op))));\n-  HloInstruction* while_op = FindInstruction(module.get(), \"while.1\");\n-  EXPECT_THAT(while_op, GmockMatch(m::While(m::Tuple(m::Op(), m::Op().Is(ar_op),\n-                                                     m::Op().Is(recv_done_op),\n-                                                     m::Op()))));\n-  HloInstruction* send_op = FindInstruction(module.get(), \"send.2\");\n-  HloInstruction* send_done_op = FindInstruction(module.get(), \"send_done.2\");\n-  EXPECT_THAT(send_done_op, GmockMatch(m::SendDone(m::Op().Is(send_op))));\n-  HloInstruction* final_ar_op = FindInstruction(module.get(), \"final_ar\");\n-\n-  // Expect control dependency from conflicting all-reduce before the while loop\n-  // to peeled recv (before the new loop) and peeled send (after the new loop).\n-  // Also, expect control dependency from peeled recv-done and peeled send-done\n-  // (before and after the new loop) to conflicting all-reduce after the loop.\n-  EXPECT_THAT(recv_op->control_predecessors(), UnorderedElementsAre(ar_op));\n-  EXPECT_THAT(send_op->control_predecessors(),\n-              UnorderedElementsAre(ar_op, recv_op, recv_done_op));\n-  EXPECT_THAT(final_ar_op->control_predecessors(),\n-              UnorderedElementsAre(recv_done_op, send_done_op));\n-}\n-\n-TEST_F(GpuP2PPipelinerTest, TwoLoopsWithConflictingAllReduces) {\n-  const char* kHloStr = R\"(\n-    HloModule test\n-\n-    add {\n-      lhs = f32[] parameter(0)\n-      rhs = f32[] parameter(1)\n-      ROOT add = f32[] add(lhs, rhs)\n-    }\n-\n-    cond {\n-      param = (u32[], f32[64]) parameter(0)\n-      i = u32[] get-tuple-element(param), index=0\n-      n = u32[] constant(2)\n-      ROOT result = pred[] compare(i, n), direction=LT\n-    }\n-\n-    body {\n-      param = (u32[], f32[64]) parameter(0)\n-      i = u32[] get-tuple-element(param), index=0\n-      data = f32[64] get-tuple-element(param), index=1\n-\n-      // Decomposed cp_fwd.\n-      after-all = token[] after-all()\n-      recv = (f32[64], u32[], token[]) recv(after-all), channel_id=1,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}}\n-      recv_done = (f32[64], token[]) recv-done(recv), channel_id=1\n-      send = (f32[64], u32[], token[]) send(data, after-all), channel_id=2,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}},\n-          control-predecessors={recv}\n-      send_done = token[] send-done(send), channel_id=2,\n-          control-predecessors={recv_done}\n-      recv_data = f32[64] get-tuple-element(recv_done), index=0\n-\n-      c1 = u32[] constant(1)\n-      i_ = u32[] add(u32[] i, u32[] c1)\n-\n-      ROOT result = (u32[], f32[64]) tuple(i_, recv_data)\n-    }\n-\n-    ENTRY entry {\n-      c0 = u32[] constant(0)\n-      a = f32[] constant(42)\n-      data = f32[64] broadcast(a), dimensions={}\n-\n-      // Conflicting all-reduce before loop.\n-      ar = f32[64] all-reduce(data), channel_id=3, replica_groups={{0,1,2,3}},\n-          to_apply=add\n-\n-      while_a_init = (u32[], f32[64]) tuple(c0, ar)\n-      while_a = (u32[], f32[64]) while(while_a_init), condition=cond, body=body\n-\n-      // Conflicting all-reduce after loop.\n-      while_a_dep_data = f32[64] get-tuple-element(while_a), index=1\n-      sandwitched_ar = f32[64] all-reduce(while_a_dep_data), channel_id=4,\n-          replica_groups={{0,1,2,3}}, to_apply=add\n-\n-      while_b_init = (u32[], f32[64]) tuple(c0, sandwitched_ar)\n-      while_b = (u32[], f32[64]) while(while_b_init), condition=cond, body=body\n-\n-      // Conflicting all-reduce after loop.\n-      while_b_dep_data = f32[64] get-tuple-element(while_b), index=1\n-      ROOT final_ar = f32[64] all-reduce(while_b_dep_data), channel_id=5,\n-          replica_groups={{0,1,2,3}}, to_apply=add\n-    }\n-  )\";\n-  TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnUnverifiedModule(kHloStr, config_));\n-\n-  // Run pass.\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      bool changed,\n-      RunOptimizer(module.get(), /*enable_partial_send_recv_pipelining=*/true));\n-  EXPECT_TRUE(changed);\n-\n-  // Find ops around the while loop.\n-  HloInstruction* ar_op = FindInstruction(module.get(), \"ar\");\n-  HloInstruction* recv_a_op = FindInstruction(module.get(), \"recv.1\");\n-  HloInstruction* recv_done_a_op = FindInstruction(module.get(), \"recv_done.1\");\n-  HloInstruction* send_a_op = FindInstruction(module.get(), \"send.2\");\n-  HloInstruction* send_done_a_op = FindInstruction(module.get(), \"send_done.2\");\n-  HloInstruction* sandwitched_ar_op =\n-      FindInstruction(module.get(), \"sandwitched_ar\");\n-  HloInstruction* recv_b_op = FindInstruction(module.get(), \"recv.3\");\n-  HloInstruction* recv_done_b_op = FindInstruction(module.get(), \"recv_done.3\");\n-  HloInstruction* send_b_op = FindInstruction(module.get(), \"send.4\");\n-  HloInstruction* send_done_b_op = FindInstruction(module.get(), \"send_done.4\");\n-  HloInstruction* final_ar_op = FindInstruction(module.get(), \"final_ar\");\n-\n-  // Find the two while loops.\n-  HloInstruction* while_a_op = FindInstruction(module.get(), \"while\");\n-  HloInstruction* while_b_op = FindInstruction(module.get(), \"while.1\");\n-\n-  // Assert relation between send/recv ops and while loops.\n-  EXPECT_THAT(recv_done_a_op, GmockMatch(m::RecvDone(m::Op().Is(recv_a_op))));\n-  EXPECT_THAT(\n-      while_a_op,\n-      GmockMatch(m::While(m::Tuple(m::Op(), m::Op().Is(ar_op),\n-                                   m::Op().Is(recv_done_a_op), m::Op()))));\n-  EXPECT_THAT(send_done_a_op, GmockMatch(m::SendDone(m::Op().Is(send_a_op))));\n-  EXPECT_THAT(recv_done_b_op, GmockMatch(m::RecvDone(m::Op().Is(recv_b_op))));\n-  EXPECT_THAT(\n-      while_b_op,\n-      GmockMatch(m::While(m::Tuple(m::Op(), m::Op().Is(sandwitched_ar_op),\n-                                   m::Op().Is(recv_done_b_op), m::Op()))));\n-  EXPECT_THAT(send_done_b_op, GmockMatch(m::SendDone(m::Op().Is(send_b_op))));\n-\n-  // Expect control dependencies between peeled ops and the conflicting\n-  // collectives.\n-  EXPECT_THAT(recv_a_op->control_predecessors(), UnorderedElementsAre(ar_op));\n-  EXPECT_THAT(send_a_op->control_predecessors(),\n-              UnorderedElementsAre(ar_op, recv_a_op, recv_done_a_op));\n-  EXPECT_THAT(sandwitched_ar_op->control_predecessors(),\n-              UnorderedElementsAre(recv_done_a_op, send_done_a_op));\n-  EXPECT_THAT(recv_b_op->control_predecessors(),\n-              UnorderedElementsAre(ar_op, sandwitched_ar_op, send_done_a_op,\n-                                   send_a_op));\n-  EXPECT_THAT(send_b_op->control_predecessors(),\n-              UnorderedElementsAre(ar_op, sandwitched_ar_op, recv_a_op,\n-                                   recv_done_a_op, recv_b_op, recv_done_b_op));\n-  EXPECT_THAT(final_ar_op->control_predecessors(),\n-              UnorderedElementsAre(send_done_b_op, send_done_a_op,\n-                                   recv_done_b_op, recv_done_a_op));\n-}\n-\n-TEST_F(GpuP2PPipelinerTest, ConflictingControlDependencies) {\n-  absl::string_view kHloStr = R\"(\n-    HloModule test\n-\n-    cond {\n-      param = (u32[], f32[64]) parameter(0)\n-      i = u32[] get-tuple-element(param), index=0\n-      n = u32[] constant(2)\n-      ROOT result = pred[] compare(i, n), direction=LT\n-    }\n-\n-    body {\n-      param = (u32[], f32[64]) parameter(0)\n-      i = u32[] get-tuple-element(param), index=0\n-      data = f32[64] get-tuple-element(param), index=1\n-\n-      // Avoids pipelining send.\n-      after-all = token[] after-all()\n-      data_ = f32[64] add(data, data)\n-      send = (f32[64], u32[], token[]) send(data_, after-all), channel_id=2,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}}\n-\n-      // Could be pipelined if it didn't have a control dependency on send.\n-      recv = (f32[64], u32[], token[]) recv(after-all), channel_id=1,\n-          frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2},{2,3}}},\n-          control-predecessors={send}\n-      recv_done = (f32[64], token[]) recv-done(recv), channel_id=1\n-      send_done = token[] send-done(send), channel_id=2\n-      recv_data = f32[64] get-tuple-element(recv_done), index=0\n-\n-      c1 = u32[] constant(1)\n-      i_ = u32[] add(u32[] i, u32[] c1)\n-\n-      ROOT result = (u32[], f32[64]) tuple(i_, recv_data)\n-    }\n-\n-    ENTRY entry {\n-      c0 = u32[] constant(0)\n-      a = f32[] constant(42)\n-      data = f32[64] broadcast(a), dimensions={}\n-      while_init = (u32[], f32[64]) tuple(c0, data)\n-      ROOT while = (u32[], f32[64]) while(while_init), condition=cond, body=body\n-    }\n-  )\";\n-  TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnUnverifiedModule(kHloStr, config_));\n-\n-  // Run pass and expect no change. We cannot pipeline recv/recv-done because\n-  // of the control dependency on send.\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      bool changed, RunOptimizer(module.get(),\n-                                 /*enable_partial_send_recv_pipelining=*/true));\n-  EXPECT_FALSE(changed);\n-}\n-\n-}  // namespace\n-}  // namespace gpu\n-}  // namespace xla"
        }
    ],
    "stats": {
        "total": 1529,
        "additions": 0,
        "deletions": 1529
    }
}