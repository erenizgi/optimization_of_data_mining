{
    "author": "gaurides",
    "message": "PR #32357: Update gemma2 keras benchmark script - fix ttft, and use tokenizer\n\nImported from GitHub PR https://github.com/openxla/xla/pull/32357\n\nüìù Summary of Changes\n\n1. Update calculation for TTFT to be the time to first generated token. This will also impact TPOT calculations.\n2. Use tokenizer to count the number of tokens generated instead of counting words using space\n\nüéØ Justification\nCurrently the script computes TTFT as time to first token which is from the prompt and still in prefill stage.\n\nüöÄ Kind of Contribution\nüêõ Bug Fix\nCopybara import of the project:\n\n--\n25178775f936a6f40a205e6969582222f150f0dd by Gauri Deshpande <gauri1.deshpande@intel.com>:\n\nUpdate gemma2 keras benchmark script - fix ttft, and use tokenizer\n\n--\n9b20ead588ad38152e648067c7d34314ba8a5645 by Gauri Deshpande <gauri1.deshpande@intel.com>:\n\naddress review comments\n\nMerging this change closes #32357\n\nPiperOrigin-RevId: 818656164",
    "sha": "d39d15f929a02bb87a3f8726004a3ee42fab68be",
    "files": [
        {
            "sha": "4bd8a254255a930c330d3da5c44f20752776a2bd",
            "filename": "third_party/xla/xla/backends/cpu/benchmarks/e2e/gemma2/keras/benchmark.py",
            "status": "modified",
            "additions": 26,
            "deletions": 9,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d39d15f929a02bb87a3f8726004a3ee42fab68be/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fe2e%2Fgemma2%2Fkeras%2Fbenchmark.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d39d15f929a02bb87a3f8726004a3ee42fab68be/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fe2e%2Fgemma2%2Fkeras%2Fbenchmark.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fe2e%2Fgemma2%2Fkeras%2Fbenchmark.py?ref=d39d15f929a02bb87a3f8726004a3ee42fab68be",
            "patch": "@@ -51,21 +51,32 @@ def compute_stats(array):\n   return (mean, diff)\n \n \n-def run(gemma_lm, max_len):\n+def run(gemma_lm, tokenizer, max_len):\n   \"\"\"Benchmarks inferences with at most `max_len` output tokens.\n \n   Args:\n     gemma_lm: The Gemma2 Keras model.\n+    tokenizer: The tokenizer for the Gemma2 model.\n     max_len: The maximum number of output tokens per one inference.\n \n   Returns:\n     mean ¬± %diff and the actual number of output tokens generated per inference.\n   \"\"\"\n+  in_tokens = tokenizer(_QUERY)\n+  in_tokens_len = len(in_tokens)\n+  total_output_len = in_tokens_len + max_len\n+  if max_len < 1:\n+    print(f\"Error: max_len {max_len} should be >= 1\")\n+    exit()\n+\n   # Warm up.\n   start = time.time()\n-  output = gemma_lm.generate(_QUERY, max_length=max_len + 1)\n-  num_actual_output_tokens = len(output.split(\" \"))\n+  output = gemma_lm.generate(_QUERY, max_length=total_output_len + 1)\n   warmup_time = (time.time() - start) * 1000\n+  num_actual_output_tokens = len(tokenizer(output))\n+  gen_tokens = max(num_actual_output_tokens - in_tokens_len, 0)\n+\n+  print(\"Warmup: Number of generated output tokens: \", gen_tokens)\n \n   if _VERBOSE:\n     print(\"=== Max len: %d ===\" % max_len)\n@@ -75,27 +86,33 @@ def run(gemma_lm, max_len):\n   times = []\n   for i in range(1, 6):\n     start = time.time()\n-    output = gemma_lm.generate(_QUERY, max_length=max_len + 1)\n-    assert num_actual_output_tokens == len(output.split(\" \"))\n+    output = gemma_lm.generate(_QUERY, max_length=total_output_len + 1)\n     elapsed_time = (time.time() - start) * 1000\n+    assert num_actual_output_tokens == len(tokenizer(output))\n     times.append(elapsed_time)\n+\n     if _VERBOSE:\n       print(\"%d: %lf ms\" % (i, elapsed_time))\n+      print(\"Benchmark: Number of generated output tokens: \", gen_tokens)\n \n   mean, diff = compute_stats(times)\n   if _VERBOSE:\n     print(\"Mean: %lf ¬± %d%% ms\\n\" % (mean, diff))\n \n-  return (mean, diff, num_actual_output_tokens)\n+  return (mean, diff, gen_tokens)\n \n \n def main():\n   if _VERBOSE:\n     print(\"Query: %s\" % _QUERY)\n \n-  gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma2_2b_en\")\n-  mean_1, diff_1, _ = run(gemma_lm, 1)\n-  mean_n, diff_n, num_output_tokens = run(gemma_lm, _NUM_OUTPUT_TOKENS)\n+  model_name = \"gemma2_2b_en\"\n+  gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(model_name)\n+  tokenizer = keras_nlp.models.GemmaTokenizer.from_preset(model_name)\n+  mean_1, diff_1, _ = run(gemma_lm, tokenizer, 1)\n+  mean_n, diff_n, num_output_tokens = run(\n+      gemma_lm, tokenizer, _NUM_OUTPUT_TOKENS\n+  )\n \n   print(\"Generated %d tokens\", num_output_tokens)\n   tpot = (mean_n - mean_1) / (num_output_tokens - 1)"
        }
    ],
    "stats": {
        "total": 35,
        "additions": 26,
        "deletions": 9
    }
}