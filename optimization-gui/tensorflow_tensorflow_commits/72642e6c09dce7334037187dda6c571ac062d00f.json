{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 850622205",
    "sha": "72642e6c09dce7334037187dda6c571ac062d00f",
    "files": [
        {
            "sha": "3cdea8c35a094328c9400ae0249c71db576a4877",
            "filename": "tensorflow/core/kernels/image/adjust_hsv_gpu.cu.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_hsv_gpu.cu.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_hsv_gpu.cu.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_hsv_gpu.cu.h?ref=72642e6c09dce7334037187dda6c571ac062d00f",
            "patch": "@@ -93,13 +93,13 @@ inline __device__ RgbTuple hsv2rgb_cuda(const float h, const float s,\n \n template <bool AdjustHue, bool AdjustSaturation, bool AdjustV, typename T>\n __global__ void adjust_hsv_nhwc(\n-    const int64 number_elements, const T* const __restrict__ input,\n+    const int64_t number_elements, const T* const __restrict__ input,\n     T* const __restrict__ output, const float* const __restrict__ hue_delta,\n     const float* const __restrict__ saturation_scale,\n     const float* const __restrict__ value_scale) {\n   // multiply by 3 since we're dealing with contiguous RGB bytes for each pixel\n   // (NHWC)\n-  for (int64 idx = (blockDim.x * blockIdx.x + threadIdx.x) * 3;\n+  for (int64_t idx = (blockDim.x * blockIdx.x + threadIdx.x) * 3;\n        idx < number_elements; idx += blockDim.x * gridDim.x * 3) {\n     if (!AdjustHue && !AdjustSaturation && !AdjustV) {\n       output[idx] = input[idx];"
        },
        {
            "sha": "7ca07e0b72c87f9f10c79c7258b98d2ff84d3a37",
            "filename": "tensorflow/core/kernels/image/adjust_hue_op_gpu.cu.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_hue_op_gpu.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_hue_op_gpu.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_hue_op_gpu.cu.cc?ref=72642e6c09dce7334037187dda6c571ac062d00f",
            "patch": "@@ -26,7 +26,7 @@ namespace functor {\n \n template <typename T>\n void AdjustHueGPU<T>::operator()(GPUDevice* device,\n-                                 const int64 number_of_elements,\n+                                 const int64_t number_of_elements,\n                                  const T* const input, const float* const delta,\n                                  T* const output) {\n   const auto stream = device->stream();"
        },
        {
            "sha": "265696177689528ae9465121e9c5986706926d90",
            "filename": "tensorflow/core/kernels/image/adjust_saturation_op_gpu.cu.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_saturation_op_gpu.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_saturation_op_gpu.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_saturation_op_gpu.cu.cc?ref=72642e6c09dce7334037187dda6c571ac062d00f",
            "patch": "@@ -26,7 +26,7 @@ namespace functor {\n \n template <typename T>\n void AdjustSaturationGPU<T>::operator()(GPUDevice* device,\n-                                        const int64 number_of_elements,\n+                                        const int64_t number_of_elements,\n                                         const T* const input,\n                                         const float* const scale,\n                                         T* const output) {"
        },
        {
            "sha": "3d2e695e78c7c51dec740195ef7b4610f71e5cfa",
            "filename": "tensorflow/core/kernels/image/crop_and_resize_op_gpu.cu.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 19,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op_gpu.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op_gpu.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op_gpu.cu.cc?ref=72642e6c09dce7334037187dda6c571ac062d00f",
            "patch": "@@ -37,12 +37,15 @@ enum InterpolationMethod {\n };\n \n template <typename T>\n-__global__ void CropAndResizeKernel(\n-    const int32 nthreads, const T* __restrict__ image_ptr,\n-    const float* __restrict__ boxes_ptr, const int32* __restrict__ box_ind_ptr,\n-    int num_boxes, int batch, int image_height, int image_width,\n-    int crop_height, int crop_width, int depth, int method_id,\n-    float extrapolation_value, float* __restrict__ crops_ptr) {\n+__global__ void CropAndResizeKernel(const int32_t nthreads,\n+                                    const T* __restrict__ image_ptr,\n+                                    const float* __restrict__ boxes_ptr,\n+                                    const int32_t* __restrict__ box_ind_ptr,\n+                                    int num_boxes, int batch, int image_height,\n+                                    int image_width, int crop_height,\n+                                    int crop_width, int depth, int method_id,\n+                                    float extrapolation_value,\n+                                    float* __restrict__ crops_ptr) {\n   // Precompute some constants outside the loop.\n   //\n   // The compiler doesn't hoist them outside the loop because of the\n@@ -73,7 +76,7 @@ __global__ void CropAndResizeKernel(\n     const float y2 = boxes_ptr[b * 4 + 2];\n     const float x2 = boxes_ptr[b * 4 + 3];\n \n-    const int32 b_in = box_ind_ptr[b];\n+    const int32_t b_in = box_ind_ptr[b];\n     if (b_in < 0 || b_in >= batch) {\n       continue;\n     }\n@@ -142,11 +145,11 @@ __global__ void CropAndResizeKernel(\n \n template <typename T>\n __global__ void CropAndResizeBackpropImageKernel(\n-    const int32 nthreads, const float* __restrict__ grads_ptr,\n-    const float* __restrict__ boxes_ptr, const int32* __restrict__ box_ind_ptr,\n-    int num_boxes, int batch, int image_height, int image_width,\n-    int crop_height, int crop_width, int depth, T* __restrict__ grads_image_ptr,\n-    int method_id) {\n+    const int32_t nthreads, const float* __restrict__ grads_ptr,\n+    const float* __restrict__ boxes_ptr,\n+    const int32_t* __restrict__ box_ind_ptr, int num_boxes, int batch,\n+    int image_height, int image_width, int crop_height, int crop_width,\n+    int depth, T* __restrict__ grads_image_ptr, int method_id) {\n   GPU_1D_KERNEL_LOOP(out_idx, nthreads) {\n     // out_idx = d + depth * (w + crop_width * (h + crop_height * b))\n     int idx = out_idx;\n@@ -162,7 +165,7 @@ __global__ void CropAndResizeBackpropImageKernel(\n     const float y2 = boxes_ptr[b * 4 + 2];\n     const float x2 = boxes_ptr[b * 4 + 3];\n \n-    const int32 b_in = box_ind_ptr[b];\n+    const int32_t b_in = box_ind_ptr[b];\n     if (b_in < 0 || b_in >= batch) {\n       continue;\n     }\n@@ -238,9 +241,9 @@ __global__ void CropAndResizeBackpropImageKernel(\n \n template <typename T>\n __global__ void CropAndResizeBackpropBoxesKernel(\n-    const int32 nthreads, const float* __restrict__ grads_ptr,\n+    const int32_t nthreads, const float* __restrict__ grads_ptr,\n     const T* __restrict__ image_ptr, const float* __restrict__ boxes_ptr,\n-    const int32* __restrict__ box_ind_ptr, int num_boxes, int batch,\n+    const int32_t* __restrict__ box_ind_ptr, int num_boxes, int batch,\n     int image_height, int image_width, int crop_height, int crop_width,\n     int depth, float* __restrict__ grads_boxes_ptr) {\n   GPU_1D_KERNEL_LOOP(out_idx, nthreads) {\n@@ -258,7 +261,7 @@ __global__ void CropAndResizeBackpropBoxesKernel(\n     const float y2 = boxes_ptr[b * 4 + 2];\n     const float x2 = boxes_ptr[b * 4 + 3];\n \n-    const int32 b_in = box_ind_ptr[b];\n+    const int32_t b_in = box_ind_ptr[b];\n     if (b_in < 0 || b_in >= batch) {\n       continue;\n     }\n@@ -362,7 +365,7 @@ struct CropAndResize<GPUDevice, T> {\n   bool operator()(const OpKernelContext* context,\n                   typename TTypes<T, 4>::ConstTensor image,\n                   typename TTypes<float, 2>::ConstTensor boxes,\n-                  typename TTypes<int32, 1>::ConstTensor box_ind,\n+                  typename TTypes<int32_t, 1>::ConstTensor box_ind,\n                   const std::string& method_name, float extrapolation_value,\n                   typename TTypes<float, 4>::Tensor crops) {\n     const int batch = image.dimension(0);\n@@ -400,7 +403,7 @@ struct CropAndResizeBackpropImage<GPUDevice, T> {\n   bool operator()(const OpKernelContext* context,\n                   typename TTypes<float, 4>::ConstTensor grads,\n                   typename TTypes<float, 2>::ConstTensor boxes,\n-                  typename TTypes<int32, 1>::ConstTensor box_ind,\n+                  typename TTypes<int32_t, 1>::ConstTensor box_ind,\n                   typename TTypes<T, 4>::Tensor grads_image,\n                   const std::string& method_name) {\n     const int batch = grads_image.dimension(0);\n@@ -452,7 +455,7 @@ struct CropAndResizeBackpropBoxes<GPUDevice, T> {\n                   typename TTypes<float, 4>::ConstTensor grads,\n                   typename TTypes<T, 4>::ConstTensor image,\n                   typename TTypes<float, 2>::ConstTensor boxes,\n-                  typename TTypes<int32, 1>::ConstTensor box_ind,\n+                  typename TTypes<int32_t, 1>::ConstTensor box_ind,\n                   typename TTypes<float, 2>::Tensor grads_boxes) {\n     const int batch = image.dimension(0);\n     const int image_height = image.dimension(1);"
        },
        {
            "sha": "996a8860d54f30f3eedabb62273f6584eb909958",
            "filename": "tensorflow/core/kernels/image/non_max_suppression_op.cu.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 31,
            "changes": 63,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fnon_max_suppression_op.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fnon_max_suppression_op.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fnon_max_suppression_op.cu.cc?ref=72642e6c09dce7334037187dda6c571ac062d00f",
            "patch": "@@ -108,8 +108,8 @@ __device__ EIGEN_STRONG_INLINE void Flipped<true>(Box& box) {\n   if (box.y1 > box.y2) Swap(box.y1, box.y2);\n }\n template <typename T>\n-__device__ EIGEN_STRONG_INLINE bool CheckBit(T* bit_mask, uint32 bit) {\n-  constexpr uint32 kNumBits = 8 * sizeof(T);\n+__device__ EIGEN_STRONG_INLINE bool CheckBit(T* bit_mask, uint32_t bit) {\n+  constexpr uint32_t kNumBits = 8 * sizeof(T);\n   return (bit_mask[bit / kNumBits] >> (bit % kNumBits)) & 1;\n }\n \n@@ -271,8 +271,8 @@ struct GreaterThanCubOp {\n // (It might be better to use DeviceReduce::Sum with a custom iterator to do the\n // count.  But in practice SelectIf is quite fast.)\n template <typename Op>\n-StatusOr<int> CountIf(OpKernelContext* context, const float* dev_array,\n-                      const Op& op, int num_elements) {\n+absl::StatusOr<int> CountIf(OpKernelContext* context, const float* dev_array,\n+                            const Op& op, int num_elements) {\n   size_t workspace_size = 0;\n   auto cuda_stream = tensorflow::GetGpuStream(context);\n   auto device = context->eigen_gpu_device();\n@@ -287,7 +287,7 @@ StatusOr<int> CountIf(OpKernelContext* context, const float* dev_array,\n \n   Tensor workspace;\n   TF_RETURN_IF_ERROR(context->allocate_temp(\n-      DataType::DT_INT8, TensorShape({(int64)workspace_size}), &workspace));\n+      DataType::DT_INT8, TensorShape({(int64_t)workspace_size}), &workspace));\n \n   // num_selected is a host pinned tensor.  The GPU kernel can write to it\n   // directly, instead of writing to GPU memory and then copying down to\n@@ -304,18 +304,18 @@ StatusOr<int> CountIf(OpKernelContext* context, const float* dev_array,\n   TF_RETURN_IF_CUDA_ERROR(\n       gpuEventCreateWithFlags(&copy_done, gpuEventDisableTiming));\n   TF_RETURN_IF_CUDA_ERROR(gpuprim::DeviceSelect::If(\n-      workspace.flat<int8>().data(), workspace_size, dev_array,\n-      scratch_output.flat<float>().data(), num_selected.flat<int32>().data(),\n+      workspace.flat<int8_t>().data(), workspace_size, dev_array,\n+      scratch_output.flat<float>().data(), num_selected.flat<int32_t>().data(),\n       num_elements, op, cuda_stream));\n   TF_RETURN_IF_CUDA_ERROR(gpuEventRecord(copy_done, device.stream()));\n   TF_RETURN_IF_CUDA_ERROR(gpuEventSynchronize(copy_done));\n-  return *num_selected.flat<int32>().data();\n+  return *num_selected.flat<int32_t>().data();\n }\n \n-Status DoNMS(OpKernelContext* context, const Tensor& boxes,\n-             const Tensor& scores, const int64_t max_output_size,\n-             const float iou_threshold_val, const float score_threshold,\n-             bool pad_to_max_output, int* num_saved_outputs) {\n+absl::Status DoNMS(OpKernelContext* context, const Tensor& boxes,\n+                   const Tensor& scores, const int64_t max_output_size,\n+                   const float iou_threshold_val, const float score_threshold,\n+                   bool pad_to_max_output, int* num_saved_outputs) {\n   int num_boxes = boxes.dim_size(0);\n   size_t cub_sort_temp_storage_bytes = 0;\n   auto cuda_stream = GetGpuStream(context);\n@@ -328,7 +328,7 @@ Status DoNMS(OpKernelContext* context, const Tensor& boxes,\n     Tensor* output_indices = nullptr;\n     TF_RETURN_IF_ERROR(\n         context->allocate_output(0, TensorShape({0}), &output_indices));\n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n \n   cudaError_t cuda_ret = gpuprim::DeviceRadixSort::SortPairsDescending(\n@@ -345,7 +345,7 @@ Status DoNMS(OpKernelContext* context, const Tensor& boxes,\n \n   Tensor d_cub_sort_buffer;\n   TF_RETURN_IF_ERROR(context->allocate_temp(\n-      DataType::DT_INT8, TensorShape({(int64)cub_sort_temp_storage_bytes}),\n+      DataType::DT_INT8, TensorShape({(int64_t)cub_sort_temp_storage_bytes}),\n       &d_cub_sort_buffer));\n   Tensor d_indices;\n   TF_RETURN_IF_ERROR(context->allocate_temp(\n@@ -372,7 +372,7 @@ Status DoNMS(OpKernelContext* context, const Tensor& boxes,\n                               d_indices.flat<int>().data()));\n   TF_RETURN_IF_CUDA_ERROR(cudaGetLastError());\n   cuda_ret = gpuprim::DeviceRadixSort::SortPairsDescending(\n-      d_cub_sort_buffer.flat<int8>().data(), cub_sort_temp_storage_bytes,\n+      d_cub_sort_buffer.flat<int8_t>().data(), cub_sort_temp_storage_bytes,\n       scores.flat<float>().data(), d_sorted_scores.flat<float>().data(),\n       d_indices.flat<int>().data(), d_sorted_indices.flat<int>().data(),\n       num_boxes, 0,\n@@ -406,7 +406,7 @@ Status DoNMS(OpKernelContext* context, const Tensor& boxes,\n       *num_saved_outputs = 0;\n       TF_RETURN_IF_ERROR(context->allocate_output(0, TensorShape({len_output}),\n                                                   &output_indices));\n-      return OkStatus();\n+      return absl::OkStatus();\n     } else {\n       VLOG(2) << \"Number of boxes above threshold=\" << score_threshold << \" is \"\n               << limited_num_boxes;\n@@ -441,7 +441,7 @@ Status DoNMS(OpKernelContext* context, const Tensor& boxes,\n   }\n   if (num_outputs == 0) {\n     *num_saved_outputs = num_outputs;\n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n   config = GetGpuLaunchConfig(num_outputs, device);\n   TF_CHECK_OK(GpuLaunchKernel(\n@@ -451,7 +451,7 @@ Status DoNMS(OpKernelContext* context, const Tensor& boxes,\n       (*output_indices).flat<int>().data()));\n   TF_RETURN_IF_CUDA_ERROR(cudaGetLastError());\n   *num_saved_outputs = num_outputs;\n-  return OkStatus();\n+  return absl::OkStatus();\n }\n \n // Extracts a scalar of type T from a tensor, with correct type checking.\n@@ -475,9 +475,9 @@ T GetScalar(const Tensor& tensor) {\n   return static_cast<T>(0);\n }\n \n-Status CheckValidInputs(const Tensor& boxes, const Tensor& scores,\n-                        const Tensor& max_output_size,\n-                        const Tensor& iou_threshold) {\n+absl::Status CheckValidInputs(const Tensor& boxes, const Tensor& scores,\n+                              const Tensor& max_output_size,\n+                              const Tensor& iou_threshold) {\n   if (!TensorShapeUtils::IsScalar(max_output_size.shape())) {\n     return errors::InvalidArgument(\"max_output_size must be 0-D, got shape \",\n                                    max_output_size.shape().DebugString(),\n@@ -519,7 +519,7 @@ Status CheckValidInputs(const Tensor& boxes, const Tensor& scores,\n         \"(Dimensions must be equal, but are \",  // otherwise tests fail!\n         num_boxes, \" and \", scores.dim_size(0), \")\");\n   }\n-  return OkStatus();\n+  return absl::OkStatus();\n }\n class NonMaxSuppressionV2GPUOp : public OpKernel {\n  public:\n@@ -664,9 +664,10 @@ class NonMaxSuppressionV4GPUOp : public OpKernel {\n \n }  // namespace\n \n-Status NmsGpu(const float* d_sorted_boxes_float_ptr, const int num_boxes,\n-              const float iou_threshold, int* d_selected_indices, int* h_nkeep,\n-              OpKernelContext* context, const int max_boxes, bool flip_boxes) {\n+absl::Status NmsGpu(const float* d_sorted_boxes_float_ptr, const int num_boxes,\n+                    const float iou_threshold, int* d_selected_indices,\n+                    int* h_nkeep, OpKernelContext* context, const int max_boxes,\n+                    bool flip_boxes) {\n   // Making sure we respect the __align(16)__\n   // we promised to the compiler.\n   auto iptr = reinterpret_cast<std::uintptr_t>(d_sorted_boxes_float_ptr);\n@@ -678,7 +679,7 @@ Status NmsGpu(const float* d_sorted_boxes_float_ptr, const int num_boxes,\n   const int bit_mask_len =\n       (num_boxes + kNmsBoxesPerThread - 1) / kNmsBoxesPerThread;\n \n-  int64 max_nms_mask_size = num_boxes * bit_mask_len;\n+  int64_t max_nms_mask_size = num_boxes * bit_mask_len;\n   TF_RETURN_IF_ERROR(context->allocate_temp(\n       DataType::DT_INT32, TensorShape({max_nms_mask_size}), &d_nms_mask));\n   // reset data sensitive tensors\n@@ -687,7 +688,7 @@ Status NmsGpu(const float* d_sorted_boxes_float_ptr, const int num_boxes,\n   TF_CHECK_OK(GpuLaunchKernel(SetZero<int>, config.block_count,\n                               config.thread_per_block, 0, device.stream(),\n                               config.virtual_thread_count,\n-                              d_nms_mask.flat<int32>().data()));\n+                              d_nms_mask.flat<int32_t>().data()));\n \n   // h_num_selected is a host pinned tensor.  The GPU kernel can write to it\n   // directly, instead of writing to GPU memory and then copying down to\n@@ -738,7 +739,7 @@ Status NmsGpu(const float* d_sorted_boxes_float_ptr, const int num_boxes,\n                               config.virtual_thread_count, 0,\n                               d_indices.flat<int>().data()));\n \n-  char* selected = (char*)(selected_boxes.flat<int8>().data());\n+  char* selected = (char*)(selected_boxes.flat<int8_t>().data());\n   TF_CHECK_OK(GpuLaunchKernel(NMSReduce, 1, 1024, bit_mask_len * sizeof(int),\n                               device.stream(), d_delete_mask, bit_mask_len,\n                               num_boxes, max_boxes, selected));\n@@ -755,14 +756,14 @@ Status NmsGpu(const float* d_sorted_boxes_float_ptr, const int num_boxes,\n       num_boxes, device.stream()));\n   Tensor cub_scratch;\n   TF_RETURN_IF_ERROR(context->allocate_temp(\n-      DataType::DT_INT8, TensorShape({(int64)flagged_buffer_size}),\n+      DataType::DT_INT8, TensorShape({(int64_t)flagged_buffer_size}),\n       &cub_scratch));\n   Tensor d_num_selected;\n   TF_RETURN_IF_ERROR(context->allocate_temp(DataType::DT_INT32,\n                                             TensorShape({1}), &d_num_selected));\n \n   TF_RETURN_IF_CUDA_ERROR(gpuprim::DeviceSelect::Flagged(\n-      (void*)cub_scratch.flat<int8>().data(),  // temp_storage\n+      (void*)cub_scratch.flat<int8_t>().data(),  // temp_storage\n       flagged_buffer_size,\n       d_indices.flat<int>().data(),  // input\n       selected,                      // selection flag\n@@ -776,7 +777,7 @@ Status NmsGpu(const float* d_sorted_boxes_float_ptr, const int num_boxes,\n   TF_RETURN_IF_CUDA_ERROR(gpuEventDestroy(copy_done));\n \n   *h_nkeep = *h_selected_count;\n-  return OkStatus();\n+  return absl::OkStatus();\n }\n \n REGISTER_KERNEL_BUILDER(Name(\"NonMaxSuppressionV2\")"
        },
        {
            "sha": "ce43c959470a5a7c02e648a097ae8bad989e0935",
            "filename": "tensorflow/core/kernels/image/non_max_suppression_op.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fnon_max_suppression_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fnon_max_suppression_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fnon_max_suppression_op.h?ref=72642e6c09dce7334037187dda6c571ac062d00f",
            "patch": "@@ -39,10 +39,10 @@ extern const int kNmsBoxesPerTread;\n //   to keep.\n // - flip_boxes: flag reorders the boxes use lower left and upper right\n //   corners if they are given in mixed format.\n-Status NmsGpu(const float* d_sorted_boxes_float_ptr, const int num_boxes,\n-              const float iou_threshold, int* d_selected_indices,\n-              int* h_num_boxes_to_keep, OpKernelContext* context,\n-              const int max_boxes, bool flip_boxes = false);\n+absl::Status NmsGpu(const float* d_sorted_boxes_float_ptr, const int num_boxes,\n+                    const float iou_threshold, int* d_selected_indices,\n+                    int* h_num_boxes_to_keep, OpKernelContext* context,\n+                    const int max_boxes, bool flip_boxes = false);\n #endif\n \n }  // namespace tensorflow"
        },
        {
            "sha": "de649d623ecc394809bb69bfcda4306295092343",
            "filename": "tensorflow/core/kernels/image/resize_bilinear_op_gpu.cu.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_bilinear_op_gpu.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72642e6c09dce7334037187dda6c571ac062d00f/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_bilinear_op_gpu.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_bilinear_op_gpu.cu.cc?ref=72642e6c09dce7334037187dda6c571ac062d00f",
            "patch": "@@ -114,7 +114,7 @@ __global__ void ResizeBilinearKernel_faster(\n \n template <typename T>\n __global__ void ResizeBilinearKernel(\n-    const int32 nthreads, const T* __restrict__ images, float height_scale,\n+    const int32_t nthreads, const T* __restrict__ images, float height_scale,\n     float width_scale, int batch, int in_height, int in_width, int channels,\n     int out_height, int out_width, float* __restrict__ output) {\n   GPU_1D_KERNEL_LOOP(out_idx, nthreads) {\n@@ -163,7 +163,7 @@ __global__ void ResizeBilinearKernel(\n }\n \n template <typename T>\n-__global__ void ResizeBilinearGradKernel(const int32 nthreads,\n+__global__ void ResizeBilinearGradKernel(const int32_t nthreads,\n                                          const float* __restrict__ input_grad,\n                                          float height_scale, float width_scale,\n                                          int batch, int original_height,\n@@ -229,7 +229,7 @@ __global__ void ResizeBilinearGradKernel(const int32 nthreads,\n \n template <typename T>\n __global__ void ResizeBilinearDeterministicGradKernel(\n-    const int32 nthreads, const float* __restrict__ input_grad,\n+    const int32_t nthreads, const float* __restrict__ input_grad,\n     float height_scale, float inverse_height_scale, float width_scale,\n     float inverse_width_scale, int batch, int original_height,\n     int original_width, int channels, int resized_height, int resized_width,\n@@ -282,7 +282,7 @@ __global__ void ResizeBilinearDeterministicGradKernel(\n \n template <typename T>\n __global__ void LegacyResizeBilinearKernel(\n-    const int32 nthreads, const T* __restrict__ images, float height_scale,\n+    const int32_t nthreads, const T* __restrict__ images, float height_scale,\n     float width_scale, int batch, int in_height, int in_width, int channels,\n     int out_height, int out_width, float* __restrict__ output) {\n   GPU_1D_KERNEL_LOOP(out_idx, nthreads) {\n@@ -332,7 +332,7 @@ __global__ void LegacyResizeBilinearKernel(\n \n template <typename T>\n __global__ void LegacyResizeBilinearGradKernel(\n-    const int32 nthreads, const float* __restrict__ input_grad,\n+    const int32_t nthreads, const float* __restrict__ input_grad,\n     float height_scale, float width_scale, int batch, int original_height,\n     int original_width, int channels, int resized_height, int resized_width,\n     T* __restrict__ output_grad) {"
        }
    ],
    "stats": {
        "total": 130,
        "additions": 67,
        "deletions": 63
    }
}