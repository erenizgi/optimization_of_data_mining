{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Add first experimental integration of tiled emitter.\n\nCan be enabled with `XLA_FLAGS=\"--xla_backend_extra_options=xla_cpu_enable_tiled_emitter\"` (!warning! may not work as expected for now)\n\nPiperOrigin-RevId: 836351940",
    "sha": "335be54cf16896a093589c755dd9ee7d012216b6",
    "files": [
        {
            "sha": "e56a85dbec9ac6cb32b0fee6188c141f23a6cb74",
            "filename": "third_party/xla/xla/backends/cpu/codegen/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -706,6 +706,7 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:util\",\n         \"//xla/backends/cpu:alignment\",\n+        \"//xla/backends/cpu/codegen/tiled:tiled_fusion_emitter\",\n         \"//xla/codegen:hlo_fusion_spec\",\n         \"//xla/codegen:ir_emission_utils\",\n         \"//xla/codegen:kernel_definition\","
        },
        {
            "sha": "fcdca13ab6cd924e11f3ef10e4b0df3ed3b57b65",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -331,6 +331,9 @@ static void AddTiledOptimizationPasses(mlir::OpPassManager& pm) {\n   AddBufferizationPasses(pm);\n \n   pm.addPass(CreateLinalgElementwiseToVectorPass());\n+\n+  pm.addPass(mlir::createCanonicalizerPass());\n+  pm.addPass(mlir::createCSEPass());\n }\n \n // Lowering passes for the tiled emitter."
        },
        {
            "sha": "5e0bdaddccbb5f6bd26790096978e3c17bbef925",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_emitter.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 2,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.cc?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n #include <cstdint>\n #include <functional>\n #include <memory>\n+#include <optional>\n #include <string>\n #include <utility>\n \n@@ -36,6 +37,7 @@ limitations under the License.\n #include \"xla/backends/cpu/alignment.h\"\n #include \"xla/backends/cpu/codegen/kernel_api_ir_builder.h\"\n #include \"xla/backends/cpu/codegen/symbol_name_util.h\"\n+#include \"xla/backends/cpu/codegen/tiled/tiled_fusion_emitter.h\"\n #include \"xla/codegen/emitters/concatenate_kernel_emitter.h\"\n #include \"xla/codegen/emitters/dynamic_update_slice_kernel_emitter.h\"\n #include \"xla/codegen/emitters/ir/xla_ops.h\"\n@@ -283,9 +285,20 @@ EmitDynamicUpdateSliceFusionKernel(MLIRContext& context,\n \n absl::StatusOr<KernelDefinition<MlirKernelSource>> EmitFusionKernel(\n     MLIRContext& mlir_context, const HloFusionInstruction& fusion,\n-    const BufferAssignment* buffer_assignment, bool use_unique_c_name) {\n+    const BufferAssignment* buffer_assignment, bool use_unique_c_name,\n+    bool enable_tiled_emitter) {\n+  TF_ASSIGN_OR_RETURN(std::string name, GetName(fusion, use_unique_c_name));\n+\n+  if (enable_tiled_emitter) {\n+    if (auto tiling_or = GetTilingIfSupported(mlir_context, fusion);\n+        tiling_or.ok()) {\n+      return EmitTiledFusionKernel(mlir_context, fusion, buffer_assignment,\n+                                   name, GetWorkGroupCount(fusion),\n+                                   std::move(*tiling_or));\n+    }\n+  }\n+\n   if (fusion.fusion_kind() == HloFusionInstruction::FusionKind::kLoop) {\n-    TF_ASSIGN_OR_RETURN(std::string name, GetName(fusion, use_unique_c_name));\n     const HloInstruction& hero =\n         FindNonTrivialHero(*fusion.fused_expression_root());\n     if (hero.opcode() == HloOpcode::kConcatenate) {"
        },
        {
            "sha": "74302f25fd368e41a50613adf3e2e5d066f9ef12",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_emitter.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.h?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -31,7 +31,8 @@ emitters::KernelArguments::BufferAlignment GetDefaultBufferAlignment();\n \n absl::StatusOr<KernelDefinition<MlirKernelSource>> EmitFusionKernel(\n     mlir::MLIRContext& mlir_context, const HloFusionInstruction& fusion,\n-    const BufferAssignment* buffer_assignment, bool use_unique_c_name);\n+    const BufferAssignment* buffer_assignment, bool use_unique_c_name,\n+    bool enable_tiled_emitter);\n \n }  // namespace xla::cpu\n "
        },
        {
            "sha": "47f14330325cd29b2bd929e45b5b09b2b1eef6ce",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_emitter_test.py",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter_test.py?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -57,6 +57,7 @@ def test_basic_add_sub(self):\n         mlir_context,\n         hlo_module.get_root_instruction(),\n         buffer_assignment,\n+        False,\n     )\n \n     kernel_runner = testlib_cpu.KernelRunner.create(\n@@ -117,6 +118,7 @@ def test_convert_f32_bf16_f32(self):\n         mlir_context,\n         hlo_module.get_root_instruction(),\n         buffer_assignment,\n+        False,\n     )\n \n     kernel_runner = testlib_cpu.KernelRunner.create(\n@@ -172,6 +174,7 @@ def test_convert_f32_bf16_f32_nan(self):\n         mlir_context,\n         hlo_module.get_root_instruction(),\n         buffer_assignment,\n+        False,\n     )\n \n     kernel_runner = testlib_cpu.KernelRunner.create(\n@@ -224,6 +227,7 @@ def test_constant_with_layout(self):\n         mlir_context,\n         hlo_module.get_root_instruction(),\n         buffer_assignment,\n+        False,\n     )\n \n     kernel_runner = testlib_cpu.KernelRunner.create(\n@@ -273,6 +277,7 @@ def test_exp_nan_dce(self):\n         mlir_context,\n         hlo_module.get_root_instruction(),\n         buffer_assignment,\n+        False,\n     )\n \n     kernel_runner = testlib_cpu.KernelRunner.create("
        },
        {
            "sha": "4d01ccd097a39d4ada632574f4c27394bf8fe0f9",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/BUILD",
            "status": "modified",
            "additions": 47,
            "deletions": 0,
            "changes": 47,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2FBUILD?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -1,4 +1,9 @@\n load(\"//xla:py_strict.bzl\", \"py_strict_test\")\n+load(\n+    \"//xla/stream_executor:build_defs.bzl\",\n+    \"if_cuda_or_rocm_is_configured\",\n+)\n+load(\"//xla/tsl/platform:rules_cc.bzl\", \"cc_library\")\n \n package(\n     # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n@@ -19,3 +24,45 @@ py_strict_test(\n         \"@absl_py//absl/testing:absltest\",\n     ],\n )\n+\n+cc_library(\n+    name = \"tiled_fusion_emitter\",\n+    # As the tiled emitter currently depends on GPU code we need to add a stub in the case that CUDA\n+    # or ROCm is not enabled (in effect this is non-Linux builds).\n+    srcs = if_cuda_or_rocm_is_configured(\n+        [\"tiled_fusion_emitter.cc\"],\n+        [\"tiled_fusion_emitter_stub.cc\"],\n+    ),\n+    hdrs = [\"tiled_fusion_emitter.h\"],\n+    visibility = [\"//xla/backends/cpu/codegen:__pkg__\"],\n+    deps = [\n+        \"//xla:shape_util\",\n+        \"//xla:util\",\n+        \"//xla/backends/cpu/codegen:kernel_api_ir_builder\",\n+        \"//xla/codegen:kernel_definition\",\n+        \"//xla/codegen:kernel_spec\",\n+        \"//xla/codegen:mlir_kernel_source\",\n+        \"//xla/codegen/emitters:kernel_api_builder\",\n+        \"//xla/codegen/emitters/ir:xla\",\n+        \"//xla/codegen/tiling:symbolic_tile_analysis\",\n+        \"//xla/codegen/tiling:tiling_specification\",\n+        \"//xla/codegen/xtile/ir:xtile\",\n+        \"//xla/hlo/analysis:symbolic_expr\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:work_dimensions\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/service:instruction_fusion\",\n+        \"//xla/service/gpu/model:block_level_parameters\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@llvm-project//llvm:Support\",\n+        \"@llvm-project//mlir:IR\",\n+    ] + if_cuda_or_rocm_is_configured([\n+        \"//xla/backends/gpu/codegen/triton:fusion_emitter\",\n+    ]),\n+)"
        },
        {
            "sha": "ef29eb2231841adaf279738fc727702728530699",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/tiled_fusion_emitter.cc",
            "status": "added",
            "additions": 242,
            "deletions": 0,
            "changes": 242,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.cc?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -0,0 +1,242 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/cpu/codegen/tiled/tiled_fusion_emitter.h\"\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <cstdlib>\n+#include <limits>\n+#include <utility>\n+#include <variant>\n+#include <vector>\n+\n+#include \"absl/log/check.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n+#include \"llvm/ADT/ArrayRef.h\"\n+#include \"llvm/ADT/STLExtras.h\"\n+#include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"xla/backends/cpu/codegen/kernel_api_ir_builder.h\"\n+#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n+#include \"xla/codegen/emitters/ir/xla_ops.h\"\n+#include \"xla/codegen/emitters/kernel_api_builder.h\"\n+#include \"xla/codegen/kernel_definition.h\"\n+#include \"xla/codegen/kernel_spec.h\"\n+#include \"xla/codegen/mlir_kernel_source.h\"\n+#include \"xla/codegen/tiling/symbolic_tile_analysis.h\"\n+#include \"xla/codegen/tiling/tiling_specification.h\"\n+#include \"xla/codegen/xtile/ir/xtile_attrs.h\"\n+#include \"xla/codegen/xtile/ir/xtile_ops.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/layout.h\"\n+#include \"xla/primitive_util.h\"\n+#include \"xla/runtime/work_dimensions.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/gpu/model/block_level_parameters.h\"\n+#include \"xla/service/instruction_fusion.h\"\n+#include \"xla/shape.h\"\n+#include \"xla/shape_util.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n+\n+namespace xla::cpu {\n+\n+absl::StatusOr<std::vector<FlatTiling>> GetTiling(\n+    mlir::MLIRContext& context, const HloFusionInstruction& fusion) {\n+  auto symbolic_tile_analysis_or = SymbolicTileAnalysis::AnalyzeComputation(\n+      *fusion.fused_instructions_computation(), &context);\n+  if (std::holds_alternative<FusionDecision>(symbolic_tile_analysis_or)) {\n+    return Internal(\n+        \"Unsupported fusion in EmitGeneric: %s\",\n+        std::get<FusionDecision>(symbolic_tile_analysis_or).Explain());\n+  }\n+\n+  const auto& symbolic_tile_analysis =\n+      std::get<SymbolicTileAnalysis>(symbolic_tile_analysis_or);\n+\n+  TF_ASSIGN_OR_RETURN(auto valid_tilings,\n+                      symbolic_tile_analysis.GetValidTilings());\n+  if (valid_tilings.empty()) {\n+    return Internal(\"No valid tilings found for fusion: %s\", fusion.name());\n+  }\n+\n+  // TODO(willfroom): Improve this heuristic.\n+  constexpr int64_t kTargetDimSize = 8;\n+\n+  auto l1_distance = [&](llvm::ArrayRef<int64_t> tile_sizes) {\n+    int64_t distance = 0;\n+    for (auto [dim, tile_size] :\n+         llvm::zip(fusion.shape().dimensions(), tile_sizes)) {\n+      auto target_dim = std::min<int64_t>(dim, kTargetDimSize);\n+      distance += std::abs(target_dim - tile_size);\n+    }\n+    return distance;\n+  };\n+\n+  auto root_hlo = fusion.fused_instructions_computation()->root_instruction();\n+  std::vector<int64_t> filtered_tilings;\n+  int64_t best_distance = std::numeric_limits<int64_t>::max();\n+  FlatTiling best_tile_sizes;\n+  for (const auto& tiling : valid_tilings) {\n+    auto tile_sizes = tiling.tile_sizes().at(root_hlo);\n+    auto distance_to_target = l1_distance(tile_sizes);\n+\n+    if (distance_to_target < best_distance) {\n+      best_distance = distance_to_target;\n+      best_tile_sizes.assign(tile_sizes.begin(), tile_sizes.end());\n+    }\n+  }\n+\n+  std::vector<FlatTiling> result{best_tile_sizes};\n+  return result;\n+}\n+\n+// We don't currently support sub-byte types in the tiled CPU emitter.\n+static bool IsSupportedType(PrimitiveType type) {\n+  if (type == PRED) {\n+    return true;\n+  }\n+\n+  if (primitive_util::BitWidth(type) < 8) {\n+    return false;\n+  }\n+\n+  if (primitive_util::IsUnsignedIntegralType(type)) {\n+    return false;\n+  }\n+\n+  if (primitive_util::IsComplexType(type)) {\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n+static bool IsSupportedShape(const Shape& shape) {\n+  bool is_supported = true;\n+  ShapeUtil::ForEachSubshape(\n+      shape, [&](const Shape& subshape, const ShapeIndex& index) {\n+        if (subshape.IsArray()) {\n+          if (!IsSupportedType(subshape.element_type())) {\n+            is_supported = false;\n+          }\n+        }\n+      });\n+\n+  return is_supported;\n+}\n+\n+static bool IsSupportedInstruction(const HloInstruction& inst) {\n+  HloOpcode opcode = inst.opcode();\n+  switch (opcode) {\n+    case xla::HloOpcode::kBitcast:\n+    case xla::HloOpcode::kIota:\n+    case xla::HloOpcode::kReshape:\n+    case xla::HloOpcode::kTranspose:\n+    case xla::HloOpcode::kParameter:\n+    case xla::HloOpcode::kConstant:\n+      return true;\n+    case xla::HloOpcode::kBitcastConvert:\n+      return false;\n+      break;\n+    default:\n+      return inst.IsElementwise();\n+  }\n+}\n+\n+absl::StatusOr<std::vector<FlatTiling>> GetTilingIfSupported(\n+    mlir::MLIRContext& context, const HloFusionInstruction& fusion) {\n+  // TODO(willfroom): Support multi-output fusions.\n+  if (!fusion.shape().IsArray()) {\n+    return Internal(\n+        \"Multi-output fusions are not supported by the tiled CPU emitter.\");\n+  }\n+\n+  for (const HloInstruction* operand : fusion.operands()) {\n+    if (!operand->shape().IsArray()) {\n+      return Internal(\n+          \"Non-array operands are not supported by the tiled CPU emitter.\");\n+    }\n+  }\n+\n+  for (const HloInstruction* inst : fusion.fused_instructions()) {\n+    if (!IsSupportedShape(inst->shape())) {\n+      return Internal(\n+          \"Instruction %s has a type, which is not supported by the \"\n+          \"tiled CPU emitter.\",\n+          inst->ToString());\n+    }\n+\n+    if (!IsSupportedInstruction(*inst)) {\n+      return Internal(\n+          \"Instruction %s is not supported by the tiled CPU emitter.\",\n+          inst->ToString());\n+    }\n+  }\n+\n+  return GetTiling(context, fusion);\n+}\n+\n+absl::StatusOr<KernelDefinition<MlirKernelSource>> EmitTiledFusionKernel(\n+    mlir::MLIRContext& context, const HloFusionInstruction& fusion,\n+    const BufferAssignment* buffer_assignment, absl::string_view name,\n+    int64_t num_work_groups, absl::Span<const FlatTiling> tiling) {\n+  gpu::BlockLevelParameters block_level_parameters;\n+  for (const auto& tile_sizes : tiling) {\n+    block_level_parameters.output_tile_sizes.emplace_back(tile_sizes.begin(),\n+                                                          tile_sizes.end());\n+  }\n+\n+  TF_ASSIGN_OR_RETURN(\n+      auto module,\n+      gpu::ir_emitter_triton_internal::EmitXTileModule(\n+          name, nullptr, &fusion, block_level_parameters, context));\n+  module->setName(absl::StrCat(\"__compute_module\", \"_\", name));\n+\n+  int64_t num_tiles = 1;\n+  for (auto [dim, tile_size] :\n+       llvm::zip(fusion.shape().dimensions(),\n+                 block_level_parameters.output_tile_sizes.front())) {\n+    num_tiles *= CeilOfRatio(dim, tile_size);\n+  }\n+  int64_t tiles_per_workgroup =\n+      CeilOfRatio<int64_t>(num_tiles, num_work_groups);\n+  module->walk([&](xtile::EntryFuncOp op) {\n+    auto info = xtile::TilingInfoAttr::get(op->getContext(), num_tiles,\n+                                           tiles_per_workgroup);\n+    op->setAttr(\"xtile.tiling_info\", info);\n+  });\n+\n+  module->getOperation()->setAttr(\n+      xla::CpuMemoryRegionNameAttr::name,\n+      mlir::StringAttr::get(\n+          &context, BuildModuleMemoryRegionName(\"tiled_emitter\", &fusion)));\n+\n+  WorkDimensions work_dimensions;\n+  work_dimensions.num_work_groups.x = num_work_groups;\n+  TF_ASSIGN_OR_RETURN(KernelSpec kernel_spec,\n+                      emitters::GetKernelSpec(name, fusion, buffer_assignment,\n+                                              work_dimensions));\n+  return KernelDefinition<MlirKernelSource>(\n+      std::move(kernel_spec), MlirKernelSource(std::move(module)));\n+}\n+\n+}  // namespace xla::cpu"
        },
        {
            "sha": "d2f88d17d85b744a71b5d0a0bee0fdfd17564b52",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/tiled_fusion_emitter.h",
            "status": "added",
            "additions": 45,
            "deletions": 0,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.h?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -0,0 +1,45 @@\n+#include <cstdint>\n+\n+#include \"absl/types/span.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"xla/codegen/kernel_definition.h\"\n+#include \"xla/codegen/tiling/tiling_specification.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_CPU_CODEGEN_TILED_TILED_FUSION_EMITTER_H_\n+#define XLA_BACKENDS_CPU_CODEGEN_TILED_TILED_FUSION_EMITTER_H_\n+\n+#include <vector>\n+\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/codegen/mlir_kernel_source.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+\n+namespace xla::cpu {\n+\n+absl::StatusOr<std::vector<FlatTiling>> GetTilingIfSupported(\n+    mlir::MLIRContext& context, const HloFusionInstruction& fusion);\n+\n+absl::StatusOr<KernelDefinition<MlirKernelSource>> EmitTiledFusionKernel(\n+    mlir::MLIRContext& context, const HloFusionInstruction& fusion,\n+    const BufferAssignment* buffer_assignment, absl::string_view name,\n+    int64_t num_work_groups, absl::Span<const FlatTiling> tiling);\n+\n+}  // namespace xla::cpu\n+\n+#endif  // XLA_BACKENDS_CPU_CODEGEN_TILED_TILED_FUSION_EMITTER_H_"
        },
        {
            "sha": "37f2abadb37ce4c47304277a67b7e51d10165da3",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/tiled_fusion_emitter_stub.cc",
            "status": "added",
            "additions": 45,
            "deletions": 0,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter_stub.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter_stub.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter_stub.cc?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -0,0 +1,45 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"xla/backends/cpu/codegen/tiled/tiled_fusion_emitter.h\"\n+#include \"xla/codegen/kernel_definition.h\"\n+#include \"xla/codegen/mlir_kernel_source.h\"\n+#include \"xla/codegen/tiling/tiling_specification.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+\n+namespace xla::cpu {\n+\n+absl::StatusOr<std::vector<FlatTiling>> GetTilingIfSupported(\n+    mlir::MLIRContext& context, const HloFusionInstruction& fusion) {\n+  return absl::UnimplementedError(\"not supported for this build configuration\");\n+}\n+\n+absl::StatusOr<KernelDefinition<MlirKernelSource>> EmitTiledFusionKernel(\n+    mlir::MLIRContext& context, const HloFusionInstruction& fusion,\n+    const BufferAssignment* buffer_assignment, absl::string_view name,\n+    int64_t num_work_groups, absl::Span<const FlatTiling> tiling) {\n+  return absl::UnimplementedError(\"not supported for this build configuration\");\n+}\n+\n+}  // namespace xla::cpu"
        },
        {
            "sha": "e58cdb044d38063fcd540ecce5506bcabdda74a3",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tools/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2FBUILD?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -85,8 +85,8 @@ xla_cc_binary(\n     deps = [\n         \"//xla/backends/cpu/codegen:fusion_compiler\",\n         \"//xla/backends/cpu/codegen:fusion_emitter\",\n+        \"//xla/codegen:kernel_definition\",\n         \"//xla/codegen/tools:test_lib\",\n-        \"//xla/hlo/analysis:symbolic_expr\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log:check\","
        },
        {
            "sha": "9b08b75b3789505f8fb95201408f9e107a4d0807",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tools/fusion_to_mlir.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2Ffusion_to_mlir.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2Ffusion_to_mlir.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2Ffusion_to_mlir.cc?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -21,8 +21,8 @@ limitations under the License.\n #include \"llvm/Support/raw_ostream.h\"\n #include \"xla/backends/cpu/codegen/fusion_compiler.h\"\n #include \"xla/backends/cpu/codegen/fusion_emitter.h\"\n+#include \"xla/codegen/kernel_definition.h\"\n #include \"xla/codegen/tools/test_lib.h\"\n-#include \"xla/hlo/analysis/symbolic_expr.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -36,8 +36,9 @@ absl::Status Run(const std::string& filename) {\n   auto fusion = DynCast<HloFusionInstruction>(\n       module->entry_computation()->root_instruction());\n   fusion->SetAndSanitizeName(\"main\");\n-  TF_ASSIGN_OR_RETURN(KernelDefinition kernel_definition,\n-                      EmitFusionKernel(*mlir_context, *fusion, nullptr, false));\n+  TF_ASSIGN_OR_RETURN(\n+      KernelDefinition kernel_definition,\n+      EmitFusionKernel(*mlir_context, *fusion, nullptr, false, false));\n   llvm::outs() << kernel_definition.source().ToString();\n   return absl::OkStatus();\n }"
        },
        {
            "sha": "20385e34237e0d4b1dec2d1951186e6e9e2bb03c",
            "filename": "third_party/xla/xla/backends/cpu/testlib/kernel_runner_extension.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fkernel_runner_extension.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fkernel_runner_extension.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fkernel_runner_extension.cc?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -200,9 +200,10 @@ NB_MODULE(_extension, kernel_runner_module) {\n   kernel_runner_module.def(\n       \"emit_fusion_kernel\",\n       [](mlir::MLIRContext& mlir_context, const HloFusionInstruction& fusion,\n-         const BufferAssignment* buffer_assignment) {\n+         const BufferAssignment* buffer_assignment, bool enable_tiled_emitter) {\n         auto kernel_definition =\n-            EmitFusionKernel(mlir_context, fusion, buffer_assignment, false);\n+            EmitFusionKernel(mlir_context, fusion, buffer_assignment, false,\n+                             enable_tiled_emitter);\n         if (!kernel_definition.ok()) {\n           throw std::runtime_error(kernel_definition.status().ToString());\n         }"
        },
        {
            "sha": "3bed8d7cc44269ebae36d25ae31973bda4f4e10a",
            "filename": "third_party/xla/xla/service/cpu/cpu_options.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.cc?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -161,4 +161,10 @@ bool UseMultiOutputFusion(const HloModuleConfig& config) {\n   return extra_options_map.count(kUseMultiOutputFusion) > 0;\n }\n \n+bool EnableTiledEmitter(const HloModuleConfig& config) {\n+  const auto& extra_options_map =\n+      config.debug_options().xla_backend_extra_options();\n+  return extra_options_map.count(kEnableTiledEmitter) > 0;\n+}\n+\n }  // namespace xla::cpu::options"
        },
        {
            "sha": "800b66104412b96b9cd1030f0fcee54d74227cc2",
            "filename": "third_party/xla/xla/service/cpu/cpu_options.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.h?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -52,6 +52,8 @@ inline constexpr absl::string_view kUseMultiOutputFusion =\n     \"xla_cpu_use_multi_output_fusion\";\n inline constexpr absl::string_view kDisablePlatformDependentMath =\n     \"xla_cpu_disable_platform_dependent_math\";\n+inline constexpr absl::string_view kEnableTiledEmitter =\n+    \"xla_cpu_enable_tiled_emitter\";\n \n bool OptimizeForSizeRequested(const HloModuleConfig& config);\n bool VectorizedReduceDisabled(const HloModuleConfig& config);\n@@ -68,6 +70,7 @@ absl::StatusOr<int64_t> SmallWhileLoopByteThreshold(\n bool UseExperimentalLoopFusion(const HloModuleConfig& config);\n bool FlattenAfterFusion(const HloModuleConfig& config);\n bool UseMultiOutputFusion(const HloModuleConfig& config);\n+bool EnableTiledEmitter(const HloModuleConfig& config);\n \n }  // namespace xla::cpu::options\n "
        },
        {
            "sha": "5de636cc5a76f42cd184d9791a9c1ab7ace4142c",
            "filename": "third_party/xla/xla/service/cpu/parallel_fusion_emitter.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.cc?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -143,12 +143,14 @@ ParallelFusionEmitter::FusionCompilerPool::GetNestedHooks() const {\n ParallelFusionEmitter::ParallelFusionEmitter(\n     tsl::thread::ThreadPool& thread_pool, FusionCompiler::Options options,\n     FusionCompiler::CompilationHooks hooks,\n-    const BufferAssignment* buffer_assignment, bool use_unique_c_name)\n+    const BufferAssignment* buffer_assignment, bool use_unique_c_name,\n+    bool enable_tiled_emitter)\n     : thread_pool_(thread_pool),\n       fusion_compiler_pool_(\n           std::make_unique<FusionCompilerPool>(options, std::move(hooks))),\n       buffer_assignment_(buffer_assignment),\n-      use_unique_c_name_(use_unique_c_name) {}\n+      use_unique_c_name_(use_unique_c_name),\n+      enable_tiled_emitter_(enable_tiled_emitter) {}\n \n ParallelFusionEmitter::~ParallelFusionEmitter() {\n   absl::MutexLock lock(kernels_mutex_);\n@@ -167,7 +169,8 @@ absl::StatusOr<KernelSpec> ParallelFusionEmitter::AddFusion(\n   TF_ASSIGN_OR_RETURN(\n       KernelDefinition mlir_kernel_definition,\n       EmitFusionKernel(*compiler_instance->mlir_context, *fusion,\n-                       buffer_assignment_, use_unique_c_name_));\n+                       buffer_assignment_, use_unique_c_name_,\n+                       enable_tiled_emitter_));\n \n   {\n     absl::MutexLock lock(kernels_mutex_);"
        },
        {
            "sha": "555ff29eb42abb25944e8f4f7470d2d3d5e9a254",
            "filename": "third_party/xla/xla/service/cpu/parallel_fusion_emitter.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.h?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -44,7 +44,7 @@ class ParallelFusionEmitter {\n                         FusionCompiler::Options options,\n                         FusionCompiler::CompilationHooks hooks,\n                         const BufferAssignment* buffer_assignment,\n-                        bool use_unique_c_name);\n+                        bool use_unique_c_name, bool enable_tiled_emitter);\n \n   ~ParallelFusionEmitter();\n \n@@ -69,6 +69,7 @@ class ParallelFusionEmitter {\n   std::unique_ptr<FusionCompilerPool> fusion_compiler_pool_;\n   const BufferAssignment* buffer_assignment_;\n   bool use_unique_c_name_;\n+  bool enable_tiled_emitter_;\n \n   absl::Mutex kernels_mutex_;\n   int64_t outstanding_kernels_ ABSL_GUARDED_BY(kernels_mutex_) = 0;"
        },
        {
            "sha": "74acf74402e85d36aee21ad7aebb58b3f1236a17",
            "filename": "third_party/xla/xla/service/cpu/parallel_fusion_emitter_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter_test.cc?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -116,7 +116,8 @@ TEST_F(ParallelFusionEmitterTest, HappyPathSingleFusion) {\n   tsl::thread::ThreadPool thread_pool(tsl::Env::Default(), \"test_pool\", 4);\n \n   xla::cpu::ParallelFusionEmitter fussion_emitter(\n-      thread_pool, CreateDefaultOptions(), CreateMockHooks(1), nullptr, false);\n+      thread_pool, CreateDefaultOptions(), CreateMockHooks(1), nullptr, false,\n+      false);\n \n   TF_ASSERT_OK_AND_ASSIGN(auto kernel_spec, fussion_emitter.AddFusion(fusion));\n   EXPECT_EQ(kernel_spec.name(), expected_name);\n@@ -170,7 +171,8 @@ TEST_F(ParallelFusionEmitterTest, FusionsAreSorted) {\n \n   xla::cpu::ParallelFusionEmitter fussion_emitter(\n       thread_pool, CreateDefaultOptions(), CreateMockHooks(2),\n-      /*buffer_assignment=*/nullptr, /*use_unique_c_name=*/false);\n+      /*buffer_assignment=*/nullptr, /*use_unique_c_name=*/false,\n+      /*enable_tiled_emitter=*/false);\n \n   // Add the fusions in reverse order.\n   TF_ASSERT_OK_AND_ASSIGN(auto kernel_spec_1,\n@@ -214,7 +216,8 @@ TEST_F(ParallelFusionEmitterTest, Error) {\n \n   tsl::thread::ThreadPool thread_pool(tsl::Env::Default(), \"test_pool\", 4);\n   xla::cpu::ParallelFusionEmitter fussion_emitter(\n-      thread_pool, CreateDefaultOptions(), CreateMockHooks(0), nullptr, false);\n+      thread_pool, CreateDefaultOptions(), CreateMockHooks(0), nullptr, false,\n+      false);\n \n   EXPECT_THAT(fussion_emitter.AddFusion(fusion), Not(IsOk()));\n }"
        },
        {
            "sha": "1a6599959d479df0d0c9ac94050fbd36dfe2f76d",
            "filename": "third_party/xla/xla/service/cpu/thunk_emitter.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/335be54cf16896a093589c755dd9ee7d012216b6/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc?ref=335be54cf16896a093589c755dd9ee7d012216b6",
            "patch": "@@ -214,7 +214,8 @@ ThunkEmitter::ThunkEmitter(IrEmitter2& ir_emitter,\n           thread_pool, FusionCompilerOptions(hlo_module_config_),\n           FusionCompilerHooks(hlo_module), &buffer_assignment,\n           hlo_module_config_.debug_options()\n-              .xla_cpu_generate_unique_c_style_kernel_entry_points()) {}\n+              .xla_cpu_generate_unique_c_style_kernel_entry_points(),\n+          options::EnableTiledEmitter(hlo_module_config_)) {}\n \n static Thunk::Info ThunkInfo(const HloInstruction* instruction) {\n   const HloModule* module = instruction->GetModule();"
        }
    ],
    "stats": {
        "total": 455,
        "additions": 438,
        "deletions": 17
    }
}