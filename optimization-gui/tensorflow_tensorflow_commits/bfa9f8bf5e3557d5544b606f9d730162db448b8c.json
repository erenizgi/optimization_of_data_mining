{
    "author": "shawnwang18",
    "message": "PR #34802: [XLA:GPU] Add buffer type information for GpuExecutable memory allocation profile\n\nImported from GitHub PR https://github.com/openxla/xla/pull/34802\n\nüìù Summary of Changes\nAdd buffer type information for GpuExecutable memory allocation profile\n\nüéØ Justification\nGive us some insights on which allocation is frequently changed, and useful for command buffer optimization.\n\nüöÄ Kind of Contribution\n üìö Documentation\n\nCopybara import of the project:\n\n--\n8930cae81077e508dc69c3bf367f03d0439c6205 by Shawn Wang <shawnw@nvidia.com>:\n\nUpdate stable address profile to include allocation type\n\nMerging this change closes #34802\n\nPiperOrigin-RevId: 841634857",
    "sha": "bfa9f8bf5e3557d5544b606f9d730162db448b8c",
    "files": [
        {
            "sha": "d72fdeddab4fe3556137c257cd2ed8fcf480fa66",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 1,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bfa9f8bf5e3557d5544b606f9d730162db448b8c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bfa9f8bf5e3557d5544b606f9d730162db448b8c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc?ref=bfa9f8bf5e3557d5544b606f9d730162db448b8c",
            "patch": "@@ -1062,7 +1062,14 @@ absl::Status GpuExecutable::ExecuteThunks(\n         }\n         module_allocations_[executor][i] =\n             buffer_allocations.GetDeviceAddress(i);\n-        VLOG(5) << \"Gpu address changed for module \" << module_name_;\n+        const BufferAllocation& allocation =\n+            buffer_assignment_->GetAllocation(i);\n+        const char* allocation_type =\n+            allocation.is_entry_computation_parameter() ? \"parameter\"\n+            : allocation.maybe_live_out()               ? \"live-out\"\n+                                                        : \"temp\";\n+        VLOG(5) << \"Gpu address changed for module \" << module_name_\n+                << \", allocation \" << i << \" (\" << allocation_type << \")\";\n       }\n     }\n   }"
        }
    ],
    "stats": {
        "total": 9,
        "additions": 8,
        "deletions": 1
    }
}