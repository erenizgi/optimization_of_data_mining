{
    "author": "sohaibiftikhar",
    "message": "[XLA:GPU]: Fix formatting errors in kernel.h\n\nThis change simply runs the formatter on the file.\nThis avoids unnecessary changes in the followup change.\n\nPiperOrigin-RevId: 810767940",
    "sha": "0124a7735126444453a4ea76037fc00a5625378d",
    "files": [
        {
            "sha": "dccb6d118892205dfbcba93a84040f88b9dfe509",
            "filename": "third_party/xla/xla/stream_executor/kernel.h",
            "status": "modified",
            "additions": 69,
            "deletions": 69,
            "changes": 138,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0124a7735126444453a4ea76037fc00a5625378d/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0124a7735126444453a4ea76037fc00a5625378d/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h?ref=0124a7735126444453a4ea76037fc00a5625378d",
            "patch": "@@ -176,9 +176,9 @@ class KernelArgs {\n class KernelArgsPackedArrayBase : public KernelArgs {\n  public:\n   // Gets the list of argument addresses.\n-  virtual absl::Span<const void *const> argument_addresses() const = 0;\n+  virtual absl::Span<const void* const> argument_addresses() const = 0;\n \n-  static bool classof(const KernelArgs *args) {\n+  static bool classof(const KernelArgs* args) {\n     return args->kind() == Kind::kPackedArray;\n   }\n \n@@ -202,13 +202,13 @@ class Kernel {\n   // StreamExecutor as a generic `Kernel`.\n   using KernelArgsPacking =\n       std::function<absl::StatusOr<std::unique_ptr<KernelArgsPackedArrayBase>>(\n-          const Kernel &kernel, const KernelArgs &args)>;\n+          const Kernel& kernel, const KernelArgs& args)>;\n \n   Kernel() = default;\n   virtual ~Kernel() = default;\n \n-  Kernel(const Kernel &) = delete;\n-  void operator=(const Kernel &) = delete;\n+  Kernel(const Kernel&) = delete;\n+  void operator=(const Kernel&) = delete;\n \n   // Returns the number of parameters that this kernel accepts. (Arity refers to\n   // nullary, unary, ...).\n@@ -219,10 +219,10 @@ class Kernel {\n   virtual absl::StatusOr<int32_t> GetMaxOccupiedBlocksPerCore(\n       ThreadDim threads, size_t dynamic_shared_memory_bytes) const = 0;\n \n-  const KernelMetadata &metadata() const { return metadata_; }\n+  const KernelMetadata& metadata() const { return metadata_; }\n   void set_metadata(KernelMetadata metadata) { metadata_ = metadata; }\n \n-  const KernelArgsPacking &args_packing() const { return args_packing_; }\n+  const KernelArgsPacking& args_packing() const { return args_packing_; }\n   void set_args_packing(KernelArgsPacking args_packing) {\n     args_packing_ = std::move(args_packing);\n   }\n@@ -233,14 +233,14 @@ class Kernel {\n   // Launches a data parallel kernel with the given thread/block\n   // dimensionality and already-packed args/sizes to pass to the underlying\n   // platform driver.\n-  absl::Status Launch(const ThreadDim &thread_dims, const BlockDim &block_dims,\n-                      Stream *stream, const KernelArgs &args);\n+  absl::Status Launch(const ThreadDim& thread_dims, const BlockDim& block_dims,\n+                      Stream* stream, const KernelArgs& args);\n \n   // Helper method to launch a kernel with optional cluster dimensions.\n-  virtual absl::Status Launch(const ThreadDim &thread_dims,\n-                              const BlockDim &block_dims,\n-                              const std::optional<ClusterDim> &cluster_dims,\n-                              Stream *stream, const KernelArgs &args) = 0;\n+  virtual absl::Status Launch(const ThreadDim& thread_dims,\n+                              const BlockDim& block_dims,\n+                              const std::optional<ClusterDim>& cluster_dims,\n+                              Stream* stream, const KernelArgs& args) = 0;\n \n  private:\n   std::string name_;\n@@ -249,9 +249,9 @@ class Kernel {\n   KernelArgsPacking args_packing_;\n };\n \n-inline absl::Status Kernel::Launch(const ThreadDim &thread_dims,\n-                                   const BlockDim &block_dims, Stream *stream,\n-                                   const KernelArgs &args) {\n+inline absl::Status Kernel::Launch(const ThreadDim& thread_dims,\n+                                   const BlockDim& block_dims, Stream* stream,\n+                                   const KernelArgs& args) {\n   return Launch(thread_dims, block_dims, std::nullopt, stream, args);\n }\n \n@@ -269,11 +269,11 @@ class TypedKernel {\n \n   TypedKernel() = default;\n \n-  Kernel &operator*() { return *kernel_; }\n-  const Kernel &operator*() const { return *kernel_; }\n+  Kernel& operator*() { return *kernel_; }\n+  const Kernel& operator*() const { return *kernel_; }\n \n-  Kernel *operator->() { return kernel_.get(); }\n-  const Kernel *operator->() const { return kernel_.get(); }\n+  Kernel* operator->() { return kernel_.get(); }\n+  const Kernel* operator->() const { return kernel_.get(); }\n \n   operator bool() const { return static_cast<bool>(kernel_); }  // NOLINT\n \n@@ -300,14 +300,14 @@ class TypedKernel {\n   // argument number and types that were mismatched.\n   template <typename... Args>\n   inline absl::Status Launch(ThreadDim thread_dims, BlockDim block_dims,\n-                             Stream *stream, Args... args) {\n+                             Stream* stream, Args... args) {\n     auto kernel_args = PackKernelArgs(*this, args...);\n     return kernel_->Launch(thread_dims, block_dims, stream, *kernel_args);\n   }\n \n   template <typename... Args>\n   inline absl::Status Launch(ThreadDim thread_dims, BlockDim block_dims,\n-                             int32_t shmem_bytes, Stream *stream,\n+                             int32_t shmem_bytes, Stream* stream,\n                              Args... args) {\n     auto kernel_args = PackKernelArgs(shmem_bytes, args...);\n     return kernel_->Launch(thread_dims, block_dims, stream, *kernel_args);\n@@ -325,31 +325,31 @@ class TypedKernel {\n // Kernel arguments LLVM-style RTTI library\n //===----------------------------------------------------------------------===//\n \n-template <class T, KernelArgs::IsKernelArgs<T> * = nullptr>\n-T *Cast(KernelArgs *args) {\n+template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n+T* Cast(KernelArgs* args) {\n   CHECK(T::classof(args)) << \"Invalid arguments casting to a destination type: \"\n                           << typeid(T).name();\n   CHECK(args != nullptr) << \"Casted arguments must be not null\";\n-  return static_cast<const T *>(args);\n+  return static_cast<const T*>(args);\n }\n \n-template <class T, KernelArgs::IsKernelArgs<T> * = nullptr>\n-const T *Cast(const KernelArgs *args) {\n+template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n+const T* Cast(const KernelArgs* args) {\n   CHECK(T::classof(args)) << \"Invalid arguments casting to a destination type: \"\n                           << typeid(T).name();\n   CHECK(args != nullptr) << \"Casted arguments must be not null\";\n-  return static_cast<const T *>(args);\n+  return static_cast<const T*>(args);\n }\n \n-template <class T, KernelArgs::IsKernelArgs<T> * = nullptr>\n-const T *DynCast(const KernelArgs *args) {\n+template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n+const T* DynCast(const KernelArgs* args) {\n   CHECK(args != nullptr) << \"Casted arguments must be not null\";\n-  return T::classof(args) ? static_cast<const T *>(args) : nullptr;\n+  return T::classof(args) ? static_cast<const T*>(args) : nullptr;\n }\n \n-template <class T, KernelArgs::IsKernelArgs<T> * = nullptr>\n-const T *DynCastOrNull(const KernelArgs *args) {\n-  return args && T::classof(args) ? static_cast<const T *>(args) : nullptr;\n+template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n+const T* DynCastOrNull(const KernelArgs* args) {\n+  return args && T::classof(args) ? static_cast<const T*>(args) : nullptr;\n }\n \n //===----------------------------------------------------------------------===//\n@@ -363,7 +363,7 @@ class KernelArgsDeviceMemoryArray : public KernelArgs {\n       : device_memory_args_(args.begin(), args.end()),\n         shared_memory_bytes_(shared_memory_bytes) {}\n \n-  static bool classof(const KernelArgs *args) {\n+  static bool classof(const KernelArgs* args) {\n     return args->kind() == Kind::kDeviceMemoryArray;\n   }\n \n@@ -379,7 +379,7 @@ class KernelArgsDeviceMemoryArray : public KernelArgs {\n     return device_memory_args_;\n   }\n \n-  const void *device_memory_ptr(size_t index) const {\n+  const void* device_memory_ptr(size_t index) const {\n     return device_memory_args_[index].opaque();\n   }\n \n@@ -413,13 +413,13 @@ template <size_t capacity, size_t size = 8,\n class PodArgs {\n  protected:\n   template <typename T>\n-  const std::byte *add_pod_argument(const T &arg) {\n+  const std::byte* add_pod_argument(const T& arg) {\n     static_assert(std::is_trivially_copyable_v<T> &&\n                       sizeof(T) <= size & alignof(T) <= alignment,\n                   \"Type is not compatible with POD arguments storage\");\n \n     assert(num_args_ < capacity && \"pod args overflow\");\n-    std::byte *arg_storage = args_storage_[num_args_++].storage;\n+    std::byte* arg_storage = args_storage_[num_args_++].storage;\n     std::memcpy(arg_storage, &arg, sizeof(T));\n \n     return arg_storage;\n@@ -453,12 +453,12 @@ class KernelArgsPackedArray : public KernelArgsPackedArrayBase, ArgsStorage {\n \n   // KernelArgsPackedArray is not copyable or movable because argument addresses\n   // point to inline storage that can't be moved.\n-  KernelArgsPackedArray(const KernelArgsPackedArray &) = delete;\n-  KernelArgsPackedArray &operator=(const KernelArgsPackedArray &) = delete;\n+  KernelArgsPackedArray(const KernelArgsPackedArray&) = delete;\n+  KernelArgsPackedArray& operator=(const KernelArgsPackedArray&) = delete;\n \n   // Adds an argument to the list.\n   template <typename T>\n-  void add_argument(const T &arg) {\n+  void add_argument(const T& arg) {\n     if constexpr (internal::is_pod_args_v<ArgsStorage>) {\n       argument_addresses_[number_of_argument_addresses_++] =\n           ArgsStorage::add_pod_argument(arg);\n@@ -469,8 +469,8 @@ class KernelArgsPackedArray : public KernelArgsPackedArrayBase, ArgsStorage {\n   }\n \n   // Adds a device memory argument to the list.\n-  void add_device_memory_argument(const DeviceMemoryBase &arg) {\n-    const void **copy_ptr =\n+  void add_device_memory_argument(const DeviceMemoryBase& arg) {\n+    const void** copy_ptr =\n         &device_memory_opaque_pointers_[number_of_argument_addresses_];\n     *copy_ptr = arg.opaque();\n     argument_addresses_[number_of_argument_addresses_] = copy_ptr;\n@@ -495,17 +495,17 @@ class KernelArgsPackedArray : public KernelArgsPackedArrayBase, ArgsStorage {\n   uint64_t number_of_shared_bytes() const final { return shared_memory_bytes_; }\n \n   // Gets the list of argument addresses.\n-  absl::Span<const void *const> argument_addresses() const final {\n-    return absl::Span<const void *const>(argument_addresses_.data(),\n+  absl::Span<const void* const> argument_addresses() const final {\n+    return absl::Span<const void* const>(argument_addresses_.data(),\n                                          number_of_argument_addresses_);\n   }\n \n  private:\n   // A place to store copies of opaque pointers from device memory arguments.\n-  std::array<const void *, num_args> device_memory_opaque_pointers_;\n+  std::array<const void*, num_args> device_memory_opaque_pointers_;\n \n   // Addresses for non-shared-memory arguments.\n-  std::array<const void *, num_args> argument_addresses_;\n+  std::array<const void*, num_args> argument_addresses_;\n \n   // Shared memory required by a kernel.\n   size_t shared_memory_bytes_ = 0;\n@@ -521,7 +521,7 @@ template <int n>\n std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(\n     absl::Span<const DeviceMemoryBase> args, uint32_t shared_mem_bytes) {\n   auto packed = std::make_unique<KernelArgsPackedArray<n, EmptyArgs>>();\n-  for (const DeviceMemoryBase &buf : args) {\n+  for (const DeviceMemoryBase& buf : args) {\n     packed->add_device_memory_argument(buf);\n   }\n   if (shared_mem_bytes > 0) {\n@@ -534,15 +534,15 @@ template <int n>\n std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(\n     absl::Span<const KernelArgument> args, uint32_t shared_mem_bytes) {\n   auto contains_tensor_map = [](absl::Span<const KernelArgument> args) -> bool {\n-    return absl::c_any_of(args, [](const auto &arg) {\n+    return absl::c_any_of(args, [](const auto& arg) {\n       return std::holds_alternative<TensorMap>(arg);\n     });\n   };\n \n   if (contains_tensor_map(args)) {\n     auto packed =\n         std::make_unique<KernelArgsPackedArray<n, PodArgs<n, 128, 64>>>();\n-    for (auto &buf : args) {\n+    for (auto& buf : args) {\n       if (std::holds_alternative<DeviceMemoryBase>(buf)) {\n         // Buffer argument.\n         packed->add_device_memory_argument(std::get<DeviceMemoryBase>(buf));\n@@ -559,7 +559,7 @@ std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(\n \n   // No TensorMap arguments -> Can use EmptyArgs.\n   auto packed = std::make_unique<KernelArgsPackedArray<n, EmptyArgs>>();\n-  for (auto &buf : args) {\n+  for (auto& buf : args) {\n     packed->add_device_memory_argument(std::get<DeviceMemoryBase>(buf));\n   }\n   if (shared_mem_bytes > 0) {\n@@ -604,7 +604,7 @@ PackKernelArgs(absl::Span<const ArgType> args, uint32_t shared_mem_bytes) {\n \n template <typename ArgType>\n inline absl::StatusOr<std::unique_ptr<KernelArgsPackedArrayBase>>\n-PackKernelArgs(absl::Span<const ArgType> args, const KernelMetadata &metadata) {\n+PackKernelArgs(absl::Span<const ArgType> args, const KernelMetadata& metadata) {\n   return PackKernelArgs(args, metadata.shared_memory_bytes().value_or(0));\n }\n \n@@ -635,7 +635,7 @@ struct PackedArgType {\n \n template <>\n struct PackedArgType<DeviceMemoryBase> {\n-  using Type = const void *;\n+  using Type = const void*;\n };\n \n template <typename T>\n@@ -644,44 +644,44 @@ struct PackedArgType<DeviceMemory<T>> {\n };\n \n template <>\n-struct PackedArgType<DeviceMemoryBase *> {\n+struct PackedArgType<DeviceMemoryBase*> {\n   using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n };\n \n template <>\n-struct PackedArgType<const DeviceMemoryBase *> {\n+struct PackedArgType<const DeviceMemoryBase*> {\n   using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n };\n \n template <typename T>\n-struct PackedArgType<DeviceMemory<T> *> {\n+struct PackedArgType<DeviceMemory<T>*> {\n   using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n };\n \n template <typename T>\n-struct PackedArgType<const DeviceMemory<T> *> {\n+struct PackedArgType<const DeviceMemory<T>*> {\n   using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n };\n \n // Overload set for packing kernel arguments. This overload set matches\n // supported kernel arguments types defined by `PackedArgType`.\n-template <typename T, std::enable_if_t<!std::is_pointer_v<T>> * = nullptr>\n-T PackArg(const T &arg) {\n+template <typename T, std::enable_if_t<!std::is_pointer_v<T>>* = nullptr>\n+T PackArg(const T& arg) {\n   return arg;\n }\n \n-inline const void *PackArg(const DeviceMemoryBase &arg) { return arg.opaque(); }\n-inline const void *PackArg(const DeviceMemoryBase *arg) {\n+inline const void* PackArg(const DeviceMemoryBase& arg) { return arg.opaque(); }\n+inline const void* PackArg(const DeviceMemoryBase* arg) {\n   return PackArg(*arg);\n }\n \n template <typename T>\n-const void *PackArg(const DeviceMemory<T> &arg) {\n+const void* PackArg(const DeviceMemory<T>& arg) {\n   return arg.opaque();\n }\n \n template <typename T>\n-const void *PackArg(const DeviceMemory<T> *arg) {\n+const void* PackArg(const DeviceMemory<T>* arg) {\n   return PackArg(*arg);\n }\n \n@@ -703,17 +703,17 @@ class KernelArgsPackedTuple : public KernelArgsPackedArrayBase {\n \n   // KernelArgsPackedTuple is not copyable or movable because argument addresses\n   // point to inline storage that can't be moved.\n-  KernelArgsPackedTuple(const KernelArgsPackedTuple &) = delete;\n-  KernelArgsPackedTuple &operator=(const KernelArgsPackedTuple &) = delete;\n+  KernelArgsPackedTuple(const KernelArgsPackedTuple&) = delete;\n+  KernelArgsPackedTuple& operator=(const KernelArgsPackedTuple&) = delete;\n \n   size_t number_of_arguments() const final {\n     return kSize + (shared_memory_bytes_ > 0);\n   }\n \n   uint64_t number_of_shared_bytes() const final { return shared_memory_bytes_; }\n \n-  absl::Span<const void *const> argument_addresses() const final {\n-    return absl::Span<const void *const>(argument_addresses_.data(), kSize);\n+  absl::Span<const void* const> argument_addresses() const final {\n+    return absl::Span<const void* const>(argument_addresses_.data(), kSize);\n   }\n \n   // Compile time check that KernelArgsPackedTuple is compatible with\n@@ -742,7 +742,7 @@ class KernelArgsPackedTuple : public KernelArgsPackedArrayBase {\n   size_t shared_memory_bytes_ = 0;\n \n   // Pointers into `storage_`.\n-  std::array<const void *, kSize> argument_addresses_;\n+  std::array<const void*, kSize> argument_addresses_;\n };\n \n // Packs the given arguments into a KernelArgsPackedTuple.\n@@ -757,7 +757,7 @@ std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(int64_t shmem_bytes,\n // checks that arguments are compatible with TypedKernel signature.\n template <typename... Params, typename... Args>\n std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(\n-    const TypedKernel<Params...> &kernel, Args... args) {\n+    const TypedKernel<Params...>& kernel, Args... args) {\n   using PackedParams = KernelArgsPackedTuple<Params...>;\n   using PackedArgs = KernelArgsPackedTuple<Args...>;\n "
        }
    ],
    "stats": {
        "total": 138,
        "additions": 69,
        "deletions": 69
    }
}