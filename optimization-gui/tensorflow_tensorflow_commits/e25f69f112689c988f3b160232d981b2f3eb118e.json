{
    "author": "beckerhe",
    "message": "Use KernelArgumentsPackingSpec in KernelSpec\n\nThis integrate `KernelArgumentsPackingSpec` into `KernelSpec`. `KernelSpec` can now either carry a `KernelArgsPackingFunc` (which is the previously existing callback) or the new `KernelArgumentsPackingSpec`. The latter will turned into a `KernelArgsPackingFunc` during kernel loading (while creating a `Kernel` object).\n\n`KernelSpec` instances with a custom `KernelArgumentsPackingSpec` can now be serialized using `KernelSpec::ToProto`.\n\nThe feature gets a unit test for `KernelSpec` and an integration in `gpu_kernel_test.cc`. The latter verifies that the whole flow (loading and executing a kernel with a custom `KernelArgumentsPackingSpec`) works.\n\nPiperOrigin-RevId: 831304990",
    "sha": "e25f69f112689c988f3b160232d981b2f3eb118e",
    "files": [
        {
            "sha": "d111c588153329028cfc4964968b310852841792",
            "filename": "third_party/xla/xla/stream_executor/BUILD",
            "status": "modified",
            "additions": 9,
            "deletions": 2,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -549,7 +549,10 @@ cc_library(\n     hdrs = [\"kernel_spec.h\"],\n     deps = [\n         \":kernel\",\n+        \":kernel_args\",\n+        \":kernel_argument_packing_spec\",\n         \":kernel_spec_proto_cc\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n@@ -561,22 +564,25 @@ cc_library(\n tf_proto_library(\n     name = \"kernel_spec_proto\",\n     srcs = [\"kernel_spec.proto\"],\n+    protodeps = [\":kernel_argument_packing_spec_proto\"],\n )\n \n xla_cc_test(\n     name = \"kernel_spec_test\",\n     srcs = [\"kernel_spec_test.cc\"],\n     deps = [\n+        \":kernel_argument_packing_spec\",\n         \":kernel_spec\",\n         \":kernel_spec_proto_cc\",\n-        \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n         \"//xla/tsl/util/proto:proto_matchers\",\n         \"@com_google_absl//absl/base\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest_main\",\n-        \"@local_tsl//tsl/platform:protobuf\",\n+        \"@com_google_protobuf//:protobuf\",\n     ],\n )\n \n@@ -642,6 +648,7 @@ cc_library(\n     deps = [\n         \":device_memory\",\n         \":kernel_args\",\n+        \":kernel_argument_packing_spec\",\n         \":kernel_metadata\",\n         \":launch_dim\",\n         \":stream\","
        },
        {
            "sha": "38f21935225b5c8b541dd88e4bc4c7154fcfc119",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -1148,6 +1148,8 @@ cc_library(\n         \"//xla/stream_executor:generic_memory_allocation\",\n         \"//xla/stream_executor:generic_memory_allocator\",\n         \"//xla/stream_executor:kernel\",\n+        \"//xla/stream_executor:kernel_args\",\n+        \"//xla/stream_executor:kernel_argument_packing_spec\",\n         \"//xla/stream_executor:kernel_metadata\",\n         \"//xla/stream_executor:kernel_spec\",\n         \"//xla/stream_executor:launch_dim\",\n@@ -2487,6 +2489,7 @@ cuda_library(\n     deps = [\n         \":cuda_platform_id\",\n         \"//xla/stream_executor:kernel\",\n+        \"//xla/stream_executor:kernel_argument_packing_spec\",\n         \"//xla/stream_executor:kernel_spec\",\n         \"//xla/stream_executor/gpu:gpu_kernel_registry\",\n         \"//xla/stream_executor/gpu:gpu_test_kernel_traits\","
        },
        {
            "sha": "348602366858e2b281e15402577064ce6fba5def",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 1,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -30,6 +30,7 @@ limitations under the License.\n #include <variant>\n \n #include \"absl/algorithm/container.h\"\n+#include \"absl/base/call_once.h\"\n #include \"absl/base/casts.h\"\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/log/check.h\"\n@@ -80,6 +81,8 @@ limitations under the License.\n #include \"xla/stream_executor/gpu/scoped_activate_context.h\"\n #include \"xla/stream_executor/gpu/tma_metadata.h\"\n #include \"xla/stream_executor/kernel.h\"\n+#include \"xla/stream_executor/kernel_args.h\"\n+#include \"xla/stream_executor/kernel_argument_packing_spec.h\"\n #include \"xla/stream_executor/kernel_metadata.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n@@ -1191,7 +1194,23 @@ absl::StatusOr<std::unique_ptr<Kernel>> CudaExecutor::LoadKernel(\n   TF_ASSIGN_OR_RETURN(KernelMetadata kernel_metadata,\n                       cuda_kernel->GetKernelMetadata());\n   cuda_kernel->set_metadata(kernel_metadata);\n-  cuda_kernel->set_args_packing(spec.kernel_args_packing());\n+  if (std::holds_alternative<KernelLoaderSpec::KernelArgsPackingFunc>(\n+          spec.kernel_args_packing())) {\n+    cuda_kernel->set_args_packing(\n+        std::get<KernelLoaderSpec::KernelArgsPackingFunc>(\n+            spec.kernel_args_packing()));\n+  } else {\n+    const auto& packing_spec =\n+        std::get<KernelArgumentsPackingSpec>(spec.kernel_args_packing());\n+    cuda_kernel->set_args_packing([packing_spec](const Kernel& kernel,\n+                                                 const KernelArgs& args) {\n+      const auto& mem_args =\n+          stream_executor::Cast<stream_executor::KernelArgsDeviceMemoryArray>(\n+              &args);\n+      return packing_spec.BuildArguments(mem_args->device_memory_args(),\n+                                         args.number_of_shared_bytes());\n+    });\n+  }\n   return std::move(cuda_kernel);\n }\n "
        },
        {
            "sha": "849cdbe9f90e1386229711f9a7fcc00a680e95eb",
            "filename": "third_party/xla/xla/stream_executor/cuda/gpu_test_kernels_cuda.cu.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 1,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fgpu_test_kernels_cuda.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fgpu_test_kernels_cuda.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fgpu_test_kernels_cuda.cu.cc?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -21,7 +21,7 @@ limitations under the License.\n #include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n #include \"xla/stream_executor/gpu/gpu_test_kernel_traits.h\"\n #include \"xla/stream_executor/gpu/gpu_test_kernels_lib.cu.h\"\n-#include \"xla/stream_executor/kernel.h\"\n+#include \"xla/stream_executor/kernel_argument_packing_spec.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n \n GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(\n@@ -33,6 +33,25 @@ GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(\n           \"AddI32\", arity);\n     }));\n \n+GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(\n+    IncrementBy5I32KernelWithCustomArgsPackingCuda,\n+    stream_executor::gpu::internal::IncrementBy5I32KernelWithCustomArgsPacking,\n+    stream_executor::cuda::kCudaPlatformId, ([](size_t arity) {\n+      stream_executor::KernelArgumentsPackingSpec spec;\n+      // This kernels is implemented in terms of the generic `IncI32` kernel\n+      // which accepts a constant scalar argument and an addressable pointer\n+      // argument. We use a custom args packing spec to pass a constant scalar\n+      // value of 5 to the kernel.\n+      spec.AddConstantArgument<int32_t>(5);\n+      spec.AddAddressArgument(/*argument_index=*/0);\n+      spec.AddAddressArgument(/*argument_index=*/1);\n+\n+      return stream_executor::KernelLoaderSpec::CreateInProcessSymbolSpec(\n+          absl::bit_cast<void*>(&stream_executor::gpu::IncI32),\n+\n+          \"IncI32\", /*arity=*/3, spec);\n+    }));\n+\n GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(\n     MulI32KernelCuda, stream_executor::gpu::internal::MulI32Kernel,\n     stream_executor::cuda::kCudaPlatformId, ([](size_t arity) {"
        },
        {
            "sha": "0ee856e9abde0636eb2e0635ca6087058f9b07be",
            "filename": "third_party/xla/xla/stream_executor/gpu/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -586,6 +586,7 @@ xla_test(\n         \"//xla/stream_executor:command_buffer\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:kernel\",\n+        \"//xla/stream_executor:kernel_args\",\n         \"//xla/stream_executor:kernel_spec\",\n         \"//xla/stream_executor:launch_dim\",\n         \"//xla/stream_executor:platform\",\n@@ -597,13 +598,13 @@ xla_test(\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n         \"@com_google_googletest//:gtest\",\n         \"@com_google_googletest//:gtest_main\",\n-        \"@local_tsl//tsl/platform:protobuf\",\n     ],\n )\n "
        },
        {
            "sha": "f3dddfd3bb80d1c437dd5083fcb4327127eef02c",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_kernel_test.cc",
            "status": "modified",
            "additions": 37,
            "deletions": 4,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_kernel_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_kernel_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_kernel_test.cc?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n #include <cstddef>\n #include <cstdint>\n #include <memory>\n+#include <optional>\n #include <vector>\n \n #include <gmock/gmock.h>\n@@ -34,6 +35,7 @@ limitations under the License.\n #include \"xla/stream_executor/gpu/tma_metadata.h\"\n #include \"xla/stream_executor/gpu/tma_metadata.pb.h\"\n #include \"xla/stream_executor/kernel.h\"\n+#include \"xla/stream_executor/kernel_args.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n #include \"xla/stream_executor/platform.h\"\n@@ -45,10 +47,12 @@ limitations under the License.\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/logging.h\"\n #include \"xla/tsl/platform/statusor.h\"\n-#include \"tsl/platform/protobuf.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n \n namespace stream_executor::gpu {\n namespace {\n+using ::testing::Each;\n+using tsl::proto_testing::ParseTextProtoOrDie;\n \n using AddI32Kernel =\n     TypedKernelFactory<DeviceMemory<int32_t>, DeviceMemory<int32_t>,\n@@ -119,6 +123,36 @@ TEST_F(GpuKernelTest, LoadAndRunKernelFromSymbol) {\n   RunAddI32Kernel(spec);\n }\n \n+TEST_F(GpuKernelTest, LoadAndRunKernelFromSymbolWithCustomArgsPacking) {\n+  constexpr int64_t kArraySize = 4;\n+  constexpr int64_t kArraySizeBytes = sizeof(int32_t) * kArraySize;\n+\n+  // Prepare arguments: in=10, out=0\n+  DeviceMemory<int32_t> in =\n+      executor_->AllocateArray<int32_t>(kArraySize, /*memory_space=*/0);\n+  DeviceMemory<int32_t> out =\n+      executor_->AllocateArray<int32_t>(kArraySize, /*memory_space=*/0);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Stream> stream,\n+                          executor_->CreateStream());\n+  TF_ASSERT_OK(stream->Memset32(&in, 10, kArraySizeBytes));\n+  TF_ASSERT_OK(stream->MemZero(&out, kArraySizeBytes));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(KernelLoaderSpec spec,\n+                          GetIncrementBy5I32TestKernelSpecWithCustomArgsPacking(\n+                              executor_->GetPlatform()->id()));\n+  TF_ASSERT_OK_AND_ASSIGN(auto kernel, executor_->LoadKernel(spec));\n+  TF_ASSERT_OK(kernel->Launch(\n+      ThreadDim(), BlockDim(4),\n+      /*cluster_dims=*/std::nullopt, stream.get(),\n+      KernelArgsDeviceMemoryArray({in, out}, /*shared_memory_bytes=*/0)));\n+\n+  // Copy data back to host and verify that the output is 5 + 10 = 15.\n+  std::vector<int32_t> dst(4, 0);\n+  TF_ASSERT_OK(stream->Memcpy(dst.data(), out, kArraySizeBytes));\n+  EXPECT_THAT(dst, Each(15));\n+}\n+\n TEST_F(GpuKernelTest, ArrayArgByValue) {\n   TF_ASSERT_OK_AND_ASSIGN(auto stream, executor_->CreateStream());\n   TF_ASSERT_OK_AND_ASSIGN(auto kernel, LoadCopyTestKernel(executor_));\n@@ -157,9 +191,8 @@ TEST_F(GpuKernelTest, TmaLoadAndRunKernelFromPtx) {\n \n   auto get_tma_descriptor_from_proto =\n       [](absl::string_view proto) -> absl::StatusOr<TmaDescriptor> {\n-    TmaDescriptorProto tma_descriptor_proto;\n-    tsl::protobuf::TextFormat::ParseFromString(proto, &tma_descriptor_proto);\n-    return TmaDescriptor::FromProto(tma_descriptor_proto);\n+    return TmaDescriptor::FromProto(\n+        ParseTextProtoOrDie<TmaDescriptorProto>(proto));\n   };\n \n   TF_ASSERT_OK_AND_ASSIGN(TmaDescriptor arg0_desc,"
        },
        {
            "sha": "2827935044415169ddbc7422c74675e06d813637",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_test_kernel_traits.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernel_traits.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernel_traits.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernel_traits.h?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -38,6 +38,10 @@ struct AddI32Kernel {\n                                  DeviceMemory<int32_t>>;\n };\n \n+struct IncrementBy5I32KernelWithCustomArgsPacking {\n+  using KernelType = TypedKernel<DeviceMemory<int32_t>>;\n+};\n+\n struct MulI32Kernel {\n   using KernelType = TypedKernel<DeviceMemory<int32_t>, DeviceMemory<int32_t>,\n                                  DeviceMemory<int32_t>>;"
        },
        {
            "sha": "668aa3d284539498d9bcd105afed849aff318bdc",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_test_kernels.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernels.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernels.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernels.cc?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -59,6 +59,14 @@ absl::StatusOr<KernelLoaderSpec> GetAddI32TestKernelSpec(\n       .FindKernel<internal::AddI32Kernel>(platform_id);\n }\n \n+absl::StatusOr<KernelLoaderSpec>\n+GetIncrementBy5I32TestKernelSpecWithCustomArgsPacking(\n+    Platform::Id platform_id) {\n+  return GpuKernelRegistry::GetGlobalRegistry()\n+      .FindKernel<internal::IncrementBy5I32KernelWithCustomArgsPacking>(\n+          platform_id);\n+}\n+\n KernelLoaderSpec GetAddI32PtxKernelSpec() {\n   // PTX kernel compiled from:\n   //"
        },
        {
            "sha": "902de0e5f1fc1b8c660e7b06bf210a526b93aebd",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_test_kernels.h",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernels.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernels.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernels.h?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -49,6 +49,17 @@ absl::StatusOr<internal::CopyKernel::KernelType> LoadCopyTestKernel(\n absl::StatusOr<KernelLoaderSpec> GetAddI32TestKernelSpec(\n     Platform::Id platform_id);\n \n+// This is using a kernel with the function signature `void IncI32(int32_t a,\n+// int32_t* b, int32_t* c)` under the hood and implements `c[i] = a + b[i]`.\n+// It uses a custom argument packing that supplies a constant scalar value of 5\n+// to the kernel for `a`, therefore it appears as if the the kernel had the\n+// function signature `void IncI32(DeviceMemory<int32_t> in,\n+// DeviceMemory<int32_t> out)`.\n+//\n+// The main purpose is the testing of the custom argument packing feature.\n+absl::StatusOr<KernelLoaderSpec>\n+GetIncrementBy5I32TestKernelSpecWithCustomArgsPacking(Platform::Id platform_id);\n+\n // Returns a PTX kernel loader spec for the `AddI32` PTX kernel above.\n KernelLoaderSpec GetAddI32PtxKernelSpec();\n "
        },
        {
            "sha": "d92bc5c536b00dbcc0f43db13af1a6ca0e5e94b5",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_test_kernels_lib.cu.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernels_lib.cu.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernels_lib.cu.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_test_kernels_lib.cu.h?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -32,6 +32,11 @@ __global__ void AddI32(int32_t* a, int32_t* b, int32_t* c) {\n   c[index] = a[index] + b[index];\n }\n \n+__global__ void IncI32(int32_t a, int32_t* b, int32_t* c) {\n+  int index = threadIdx.x + blockIdx.x * blockDim.x;\n+  c[index] = a + b[index];\n+}\n+\n __global__ void MulI32(int32_t* a, int32_t* b, int32_t* c) {\n   int index = threadIdx.x + blockIdx.x * blockDim.x;\n   c[index] = a[index] * b[index];"
        },
        {
            "sha": "2210746bad14e8164f8c0198e34e3372704acc7f",
            "filename": "third_party/xla/xla/stream_executor/kernel_spec.cc",
            "status": "modified",
            "additions": 23,
            "deletions": 4,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.cc?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -19,14 +19,17 @@ limitations under the License.\n #include <cstdint>\n #include <string>\n #include <utility>\n+#include <variant>\n #include <vector>\n \n #include \"absl/log/check.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/stream_executor/kernel_argument_packing_spec.h\"\n #include \"xla/stream_executor/kernel_spec.pb.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n \n namespace stream_executor {\n \n@@ -66,9 +69,10 @@ KernelLoaderSpec KernelLoaderSpec::CreateOwningCudaPtxInMemorySpec(\n }\n \n absl::StatusOr<KernelLoaderSpecProto> KernelLoaderSpec::ToProto() const {\n-  if (kernel_args_packing_ != nullptr) {\n+  if (std::holds_alternative<KernelArgsPackingFunc>(kernel_args_packing_) &&\n+      std::get<KernelArgsPackingFunc>(kernel_args_packing_) != nullptr) {\n     return absl::UnimplementedError(\n-        \"KernelLoaderSpecs with KernelArgsPacking are not currently\"\n+        \"KernelLoaderSpecs with a function for argument packing is not \"\n         \"serializable.\");\n   }\n \n@@ -93,21 +97,36 @@ absl::StatusOr<KernelLoaderSpecProto> KernelLoaderSpec::ToProto() const {\n \n   CHECK(proto.has_cubin() || proto.has_ptx());\n \n+  if (std::holds_alternative<KernelArgumentsPackingSpec>(\n+          kernel_args_packing_)) {\n+    TF_ASSIGN_OR_RETURN(\n+        *proto.mutable_kernel_args_packing_spec(),\n+        std::get<KernelArgumentsPackingSpec>(kernel_args_packing_).ToProto());\n+  }\n+\n   return proto;\n }\n \n absl::StatusOr<KernelLoaderSpec> KernelLoaderSpec::FromProto(\n     const KernelLoaderSpecProto& proto) {\n+  KernelArgsPacking kernel_args_packing;\n+  if (proto.has_kernel_args_packing_spec()) {\n+    TF_ASSIGN_OR_RETURN(kernel_args_packing,\n+                        KernelArgumentsPackingSpec::FromProto(\n+                            proto.kernel_args_packing_spec()));\n+  }\n+\n   if (proto.has_cubin()) {\n     const std::string& data = proto.cubin().data();\n     return KernelLoaderSpec::CreateOwningCudaCubinInMemorySpec(\n         std::vector<uint8_t>{data.begin(), data.end()}, proto.kernel_name(),\n-        proto.arity());\n+        proto.arity(), std::move(kernel_args_packing));\n   }\n \n   if (proto.has_ptx()) {\n     return KernelLoaderSpec::CreateOwningCudaPtxInMemorySpec(\n-        proto.ptx().data(), proto.kernel_name(), proto.arity());\n+        proto.ptx().data(), proto.kernel_name(), proto.arity(),\n+        std::move(kernel_args_packing));\n   }\n \n   return absl::InvalidArgumentError("
        },
        {
            "sha": "9f2b5a7acf6172cd653be55a379f4ff0203bebfc",
            "filename": "third_party/xla/xla/stream_executor/kernel_spec.h",
            "status": "modified",
            "additions": 24,
            "deletions": 15,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.h?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -1,3 +1,4 @@\n+#include \"xla/stream_executor/kernel.h\"\n /* Copyright 2015 The OpenXLA Authors.\n \n Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -51,15 +52,16 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n-#include \"xla/stream_executor/kernel.h\"\n+#include \"xla/stream_executor/kernel_args.h\"\n+#include \"xla/stream_executor/kernel_argument_packing_spec.h\"\n #include \"xla/stream_executor/kernel_spec.pb.h\"\n \n namespace stream_executor {\n \n // Loads kernel from in process symbol pointer (e.g. pointer to C++ device\n // function).\n struct InProcessSymbol {\n-  void *symbol;\n+  void* symbol;\n };\n \n // Kernel loader specification for PTX text that resides in memory.\n@@ -89,9 +91,15 @@ class KernelLoaderSpec {\n   // that can be directly passed to a device kernel. This indirection allows\n   // registering custom CUDA C++ kernels with non-trivial C++ API with a\n   // StreamExecutor as a generic `Kernel`.\n-  using KernelArgsPacking =\n+  using KernelArgsPackingFunc =\n       std::function<absl::StatusOr<std::unique_ptr<KernelArgsPackedArrayBase>>(\n-          const Kernel &kernel, const KernelArgs &args)>;\n+          const Kernel& kernel, const KernelArgs& args)>;\n+\n+  // Kernel arguments packing can be either a function or a specification.\n+  // The specification has the advantage that it can be serialized and is\n+  // therefore a requirement for AOT compilation.\n+  using KernelArgsPacking =\n+      std::variant<KernelArgsPackingFunc, KernelArgumentsPackingSpec>;\n \n   // Returns the number of arguments that this kernel accepts.\n   size_t arity() const { return arity_; }\n@@ -145,44 +153,45 @@ class KernelLoaderSpec {\n   // the PTX being loaded. Also be aware that in CUDA C++ the kernel name may be\n   // mangled by the compiler if it is not declared in an extern \"C\" scope.\n   static KernelLoaderSpec CreateInProcessSymbolSpec(\n-      void *symbol, std::string kernel_name, size_t arity,\n+      void* symbol, std::string kernel_name, size_t arity,\n       KernelArgsPacking kernel_args_packing = nullptr);\n   static KernelLoaderSpec CreateCudaCubinInMemorySpec(\n       absl::Span<const uint8_t> cubin_bytes, std::string kernel_name,\n-      size_t arity, KernelArgsPacking kernel_args_packing = nullptr);\n+      size_t arity,\n+      KernelArgsPacking kernel_args_packing = KernelArgsPackingFunc{});\n   static KernelLoaderSpec CreateOwningCudaCubinInMemorySpec(\n       std::vector<uint8_t> cubin_bytes, std::string kernel_name, size_t arity,\n-      KernelArgsPacking kernel_args_packing = nullptr);\n+      KernelArgsPacking kernel_args_packing = KernelArgsPackingFunc{});\n   static KernelLoaderSpec CreateCudaPtxInMemorySpec(\n       absl::string_view ptx, std::string kernel_name, size_t arity,\n-      KernelArgsPacking kernel_args_packing = nullptr);\n+      KernelArgsPacking kernel_args_packing = KernelArgsPackingFunc{});\n   static KernelLoaderSpec CreateOwningCudaPtxInMemorySpec(\n       std::string ptx, std::string kernel_name, size_t arity,\n-      KernelArgsPacking kernel_args_packing = nullptr);\n+      KernelArgsPacking kernel_args_packing = KernelArgsPackingFunc{});\n \n   void set_kernel_args_packing(KernelArgsPacking kernel_args_packing) {\n     kernel_args_packing_ = std::move(kernel_args_packing);\n   }\n \n-  const KernelArgsPacking &kernel_args_packing() const {\n+  const KernelArgsPacking& kernel_args_packing() const {\n     return kernel_args_packing_;\n   }\n \n-  const std::string &kernel_name() const { return kernel_name_; }\n+  const std::string& kernel_name() const { return kernel_name_; }\n \n   absl::StatusOr<KernelLoaderSpecProto> ToProto() const;\n \n   static absl::StatusOr<KernelLoaderSpec> FromProto(\n-      const KernelLoaderSpecProto &proto);\n+      const KernelLoaderSpecProto& proto);\n \n  private:\n   using Payload =\n       std::variant<InProcessSymbol, CudaCubinInMemory, CudaPtxInMemory,\n                    OwningCudaCubinInMemory, OwningCudaPtxInMemory>;\n \n-  explicit KernelLoaderSpec(Payload payload, std::string kernel_name,\n-                            size_t arity,\n-                            KernelArgsPacking kernel_args_packing = nullptr)\n+  explicit KernelLoaderSpec(\n+      Payload payload, std::string kernel_name, size_t arity,\n+      KernelArgsPacking kernel_args_packing = KernelArgsPackingFunc{})\n       : payload_(std::move(payload)),\n         kernel_name_(std::move(kernel_name)),\n         arity_(arity),"
        },
        {
            "sha": "7c813b855c6ecf2e37c9a5d03f3ad36eff353633",
            "filename": "third_party/xla/xla/stream_executor/kernel_spec.proto",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec.proto?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -2,6 +2,8 @@ syntax = \"proto3\";\n \n package stream_executor;\n \n+import \"xla/stream_executor/kernel_argument_packing_spec.proto\";\n+\n message CudaPtxProto {\n   string data = 1;\n }\n@@ -18,4 +20,6 @@ message KernelLoaderSpecProto {\n \n   int32 arity = 3;\n   string kernel_name = 4;\n+\n+  optional KernelArgumentsPackingSpecProto kernel_args_packing_spec = 5;\n }"
        },
        {
            "sha": "033188aeba04725a92d0343f096c0da778f93350",
            "filename": "third_party/xla/xla/stream_executor/kernel_spec_test.cc",
            "status": "modified",
            "additions": 48,
            "deletions": 4,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_spec_test.cc?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -18,27 +18,30 @@ limitations under the License.\n #include <array>\n #include <cstdint>\n #include <string>\n+#include <utility>\n #include <vector>\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/base/casts.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"google/protobuf/text_format.h\"\n+#include \"xla/stream_executor/kernel_argument_packing_spec.h\"\n #include \"xla/stream_executor/kernel_spec.pb.h\"\n-#include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n #include \"xla/tsl/util/proto/proto_matchers.h\"\n-#include \"tsl/platform/protobuf.h\"\n \n namespace stream_executor {\n namespace {\n \n+using ::absl_testing::IsOkAndHolds;\n using ::testing::Field;\n using ::testing::Optional;\n using ::tsl::proto_testing::EqualsProto;\n-using ::tsl::testing::IsOkAndHolds;\n-using ::tsl::testing::StatusIs;\n+using ::tsl::proto_testing::ParseTextProtoOrDie;\n \n TEST(KernelLoaderSpec, InProcessSymbol) {\n   void* symbol = absl::bit_cast<void*>(0xDEADBEEFul);\n@@ -176,5 +179,46 @@ TEST(KernelLoaderSpec, InProcessSymbolToProto) {\n               absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n+TEST(kernelLoaderSpec, StoresKernelArgsPackingSpec) {\n+  auto kernel_args_packing_spec_proto =\n+      ParseTextProtoOrDie<KernelArgumentsPackingSpecProto>(\n+          R\"pb(\n+            kernel_arguments {\n+              relocations {\n+                type: TYPE_BITS64_ABSOLUTE\n+                argument_index: 0\n+                offset: 0\n+              }\n+              data: \"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n+            }\n+            kernel_arguments { data: \"\\x34\\x12\\x00\\x00\" }\n+          )pb\");\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelArgumentsPackingSpec kernel_args_packing_spec,\n+      KernelArgumentsPackingSpec::FromProto(kernel_args_packing_spec_proto));\n+\n+  auto spec = KernelLoaderSpec::CreateOwningCudaCubinInMemorySpec(\n+      std::vector<uint8_t>{'C', 'U', 'B', 'I', 'N'}, \"kernel_name\",\n+      /*arity=*/42, std::move(kernel_args_packing_spec));\n+\n+  EXPECT_THAT(spec.ToProto(), IsOkAndHolds(EqualsProto(R\"pb(\n+                cubin { data: \"CUBIN\" }\n+                kernel_name: \"kernel_name\"\n+                arity: 42\n+                kernel_args_packing_spec {\n+                  kernel_arguments {\n+                    relocations {\n+                      type: TYPE_BITS64_ABSOLUTE\n+                      argument_index: 0\n+                      offset: 0\n+                    }\n+                    data: \"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n+                  }\n+                  kernel_arguments { data: \"\\x34\\x12\\x00\\x00\" }\n+                }\n+              )pb\")));\n+}\n+\n }  // namespace\n }  // namespace stream_executor"
        },
        {
            "sha": "21235c60daf845ce8f0f17e7ed2c324502214f21",
            "filename": "third_party/xla/xla/stream_executor/rocm/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2FBUILD?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -167,6 +167,8 @@ cc_library(\n         \"//xla/stream_executor:generic_memory_allocation\",\n         \"//xla/stream_executor:generic_memory_allocator\",\n         \"//xla/stream_executor:kernel\",\n+        \"//xla/stream_executor:kernel_args\",\n+        \"//xla/stream_executor:kernel_argument_packing_spec\",\n         \"//xla/stream_executor:kernel_metadata\",\n         \"//xla/stream_executor:kernel_spec\",\n         \"//xla/stream_executor:launch_dim\",\n@@ -202,9 +204,9 @@ cc_library(\n         \"@com_google_absl//absl/synchronization\",\n         \"@com_google_absl//absl/types:span\",\n         \"@local_config_rocm//rocm:rocm_headers\",\n-        \"@local_tsl//tsl/platform:casts\",\n         \"@local_tsl//tsl/platform:fingerprint\",\n         \"@local_tsl//tsl/platform:numbers\",\n+        \"@local_tsl//tsl/platform:platform_port\",\n     ],\n     alwayslink = True,\n )\n@@ -1249,7 +1251,7 @@ rocm_library(\n     ],\n     deps = [\n         \":rocm_platform_id\",\n-        \"//xla/stream_executor:kernel\",\n+        \"//xla/stream_executor:kernel_argument_packing_spec\",\n         \"//xla/stream_executor:kernel_spec\",\n         \"//xla/stream_executor/gpu:gpu_kernel_registry\",\n         \"//xla/stream_executor/gpu:gpu_test_kernel_traits\","
        },
        {
            "sha": "1dc83bc2ba276bde52a3ced581d509c01a51f081",
            "filename": "third_party/xla/xla/stream_executor/rocm/gpu_test_kernels_rocm.cu.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 1,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fgpu_test_kernels_rocm.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fgpu_test_kernels_rocm.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fgpu_test_kernels_rocm.cu.cc?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -19,7 +19,7 @@ limitations under the License.\n #include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n #include \"xla/stream_executor/gpu/gpu_test_kernel_traits.h\"\n #include \"xla/stream_executor/gpu/gpu_test_kernels_lib.cu.h\"\n-#include \"xla/stream_executor/kernel.h\"\n+#include \"xla/stream_executor/kernel_argument_packing_spec.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n #include \"xla/stream_executor/rocm/rocm_platform_id.h\"\n \n@@ -32,6 +32,24 @@ GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(\n           \"AddI32\", arity);\n     }));\n \n+GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(\n+    IncrementBy5I32KernelWithCustomArgsPackingRocm,\n+    stream_executor::gpu::internal::IncrementBy5I32KernelWithCustomArgsPacking,\n+    stream_executor::rocm::kROCmPlatformId, ([](size_t arity) {\n+      // This kernels is implemented in terms of the generic `IncI32` kernel\n+      // which accepts a constant scalar argument and an addressable pointer\n+      // argument. We use a custom args packing spec to pass a constant scalar\n+      // value of 5 to the kernel.\n+      stream_executor::KernelArgumentsPackingSpec spec;\n+      spec.AddConstantArgument<int32_t>(5);\n+      spec.AddAddressArgument(/*argument_index=*/0);\n+      spec.AddAddressArgument(/*argument_index=*/1);\n+\n+      return stream_executor::KernelLoaderSpec::CreateInProcessSymbolSpec(\n+          absl::bit_cast<void*>(&stream_executor::gpu::IncI32), \"IncI32\",\n+          /*arity=*/3, spec);\n+    }));\n+\n GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(\n     MulI32KernelRocm, stream_executor::gpu::internal::MulI32Kernel,\n     stream_executor::rocm::kROCmPlatformId, ([](size_t arity) {"
        },
        {
            "sha": "4e8364593f4ddfc614e6e2b6e423a0ade496ce4b",
            "filename": "third_party/xla/xla/stream_executor/rocm/rocm_executor.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 2,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e25f69f112689c988f3b160232d981b2f3eb118e/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_executor.cc?ref=e25f69f112689c988f3b160232d981b2f3eb118e",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n \n #include <unistd.h>\n \n+#include <algorithm>\n #include <cstddef>\n #include <cstdint>\n #include <memory>\n@@ -61,6 +62,8 @@ limitations under the License.\n #include \"xla/stream_executor/gpu/read_numa_node.h\"\n #include \"xla/stream_executor/gpu/scoped_activate_context.h\"\n #include \"xla/stream_executor/kernel.h\"\n+#include \"xla/stream_executor/kernel_args.h\"\n+#include \"xla/stream_executor/kernel_argument_packing_spec.h\"\n #include \"xla/stream_executor/kernel_metadata.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n@@ -88,8 +91,8 @@ limitations under the License.\n #include \"xla/tsl/platform/logging.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n-#include \"tsl/platform/casts.h\"\n #include \"tsl/platform/fingerprint.h\"\n+#include \"tsl/platform/numa.h\"\n #include \"tsl/platform/numbers.h\"\n \n namespace stream_executor {\n@@ -719,7 +722,23 @@ absl::StatusOr<std::unique_ptr<Kernel>> RocmExecutor::LoadKernel(\n     rocm_kernel->set_metadata(kernel_metadata);\n   }\n   rocm_kernel->set_name(kernel_name);\n-  rocm_kernel->set_args_packing(spec.kernel_args_packing());\n+  if (std::holds_alternative<KernelLoaderSpec::KernelArgsPackingFunc>(\n+          spec.kernel_args_packing())) {\n+    rocm_kernel->set_args_packing(\n+        std::get<KernelLoaderSpec::KernelArgsPackingFunc>(\n+            spec.kernel_args_packing()));\n+  } else {\n+    const auto& packing_spec =\n+        std::get<KernelArgumentsPackingSpec>(spec.kernel_args_packing());\n+    rocm_kernel->set_args_packing([packing_spec](const Kernel& kernel,\n+                                                 const KernelArgs& args) {\n+      const auto& mem_args =\n+          stream_executor::Cast<stream_executor::KernelArgsDeviceMemoryArray>(\n+              &args);\n+      return packing_spec.BuildArguments(mem_args->device_memory_args(),\n+                                         args.number_of_shared_bytes());\n+    });\n+  }\n   return std::move(rocm_kernel);\n }\n "
        }
    ],
    "stats": {
        "total": 299,
        "additions": 262,
        "deletions": 37
    }
}