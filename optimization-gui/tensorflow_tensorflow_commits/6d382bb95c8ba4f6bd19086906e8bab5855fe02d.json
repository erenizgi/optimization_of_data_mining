{
    "author": "WillFroom",
    "message": "[XLA:CPU/GPU] Migrate in-place dynamic update slice to common emitter.\n\nPiperOrigin-RevId: 800824307",
    "sha": "6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
    "files": [
        {
            "sha": "fec9bbc2755b6261cdd92bed0905c0a7cbb7cd57",
            "filename": "third_party/xla/xla/backends/cpu/codegen/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -624,8 +624,10 @@ cc_library(\n         \"//xla:util\",\n         \"//xla/backends/cpu:alignment\",\n         \"//xla/codegen:hlo_fusion_spec\",\n+        \"//xla/codegen:ir_emission_utils\",\n         \"//xla/codegen:mlir_kernel_definition\",\n         \"//xla/codegen/emitters:concatenate_kernel_emitter\",\n+        \"//xla/codegen/emitters:dynamic_update_slice_kernel_emitter\",\n         \"//xla/codegen/emitters:kernel_arguments\",\n         \"//xla/codegen/emitters:loop_kernel_emitter\",\n         \"//xla/codegen/emitters/ir:xla\","
        },
        {
            "sha": "00d5867b8dfdf60c9a8eddac0ca0234fdebc543b",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_emitter.cc",
            "status": "modified",
            "additions": 48,
            "deletions": 0,
            "changes": 48,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.cc?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -37,10 +37,12 @@ limitations under the License.\n #include \"xla/backends/cpu/codegen/kernel_api_ir_builder.h\"\n #include \"xla/backends/cpu/codegen/symbol_name_util.h\"\n #include \"xla/codegen/emitters/concatenate_kernel_emitter.h\"\n+#include \"xla/codegen/emitters/dynamic_update_slice_kernel_emitter.h\"\n #include \"xla/codegen/emitters/ir/xla_ops.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n #include \"xla/codegen/emitters/loop_kernel_emitter.h\"\n #include \"xla/codegen/hlo_fusion_spec.h\"\n+#include \"xla/codegen/ir_emission_utils.h\"\n #include \"xla/codegen/mlir_kernel_definition.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n@@ -179,6 +181,14 @@ static WorkDimensions GetConcatenateEmitterWorkDims(\n   return GetWorkDimensions(indexing_shape, fusion);\n }\n \n+static WorkDimensions GetDynamicUpdateSliceEmitterWorkDims(\n+    const HloFusionInstruction& fusion, const HloFusionSpec& fusion_spec) {\n+  Shape indexing_shape =\n+      emitters::DynamicUpdateSliceKernelEmitter::GetIndexingShape(fusion_spec);\n+\n+  return GetWorkDimensions(indexing_shape, fusion);\n+}\n+\n static HloFusionSpec GetLoopFusionSpec(const HloFusionInstruction& fusion) {\n   // Crash OK, this is checked in the caller.\n   CHECK(fusion.fusion_kind() == HloFusionInstruction::FusionKind::kLoop);\n@@ -249,6 +259,33 @@ static absl::StatusOr<MlirKernelDefinition> EmitConcatenateFusionKernel(\n   return MlirKernelDefinition(std::move(kernel_spec), std::move(kernel_source));\n }\n \n+static absl::StatusOr<MlirKernelDefinition> EmitDynamicUpdateSliceFusionKernel(\n+    mlir::MLIRContext& context, const HloFusionInstruction& fusion,\n+    const BufferAssignment* buffer_assignment, absl::string_view name) {\n+  VLOG(2) << \"Emitting dynamic update slice fusion kernel: \" << name;\n+  HloFusionSpec fusion_spec = GetLoopFusionSpec(fusion);\n+  auto work_dimensions =\n+      GetDynamicUpdateSliceEmitterWorkDims(fusion, fusion_spec);\n+\n+  emitters::DynamicUpdateSliceKernelEmitter emitter(\n+      context, fusion, std::move(fusion_spec), buffer_assignment,\n+      GetDefaultBufferAlignment(), work_dimensions, name, BackendKind::kCpu);\n+  TF_ASSIGN_OR_RETURN(auto mlir_kernel_definition,\n+                      emitter.EmitKernelDefinition());\n+\n+  // We have to release otherwise the source wouldn't be mutable, and we\n+  // wouldn't be able to set the CpuMemoryRegionNameAttr.\n+  auto [kernel_spec, kernel_source] =\n+      std::move(mlir_kernel_definition).ReleaseStorage();\n+\n+  mlir::OpBuilder builder(&context);\n+  kernel_source.module().getOperation()->setAttr(\n+      xla::CpuMemoryRegionNameAttr::name,\n+      builder.getStringAttr(\n+          BuildModuleMemoryRegionName(emitter.name(), &fusion)));\n+  return MlirKernelDefinition(std::move(kernel_spec), std::move(kernel_source));\n+}\n+\n absl::StatusOr<MlirKernelDefinition> EmitFusionKernel(\n     mlir::MLIRContext& context, const HloFusionInstruction& fusion,\n     const BufferAssignment* buffer_assignment, bool use_unique_c_name) {\n@@ -260,6 +297,17 @@ absl::StatusOr<MlirKernelDefinition> EmitFusionKernel(\n       return EmitConcatenateFusionKernel(context, fusion, buffer_assignment,\n                                          name);\n     }\n+    auto fusion_spec = GetLoopFusionSpec(fusion);\n+    if (IsDynamicUpdateSliceFusion(fusion_spec)) {\n+      TF_ASSIGN_OR_RETURN(\n+          bool dus_inplace,\n+          CanEmitFusedDynamicUpdateSliceInPlace(fusion_spec.fusion(),\n+                                                buffer_assignment, &fusion));\n+      if (dus_inplace) {\n+        return EmitDynamicUpdateSliceFusionKernel(context, fusion,\n+                                                  buffer_assignment, name);\n+      }\n+    }\n     return EmitLoopFusionKernel(context, fusion, buffer_assignment, name);\n   }\n "
        },
        {
            "sha": "5952f63df9058faeb5dabac56f13fa509aa867fc",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2FBUILD?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -167,17 +167,22 @@ cc_library(\n     hdrs = [\"in_place_dynamic_update_slice.h\"],\n     deps = [\n         \":emitter_base\",\n-        \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/codegen/emitters:computation_partitioner\",\n+        \"//xla/codegen/emitters:dynamic_update_slice_kernel_emitter\",\n         \"//xla/codegen/emitters:elemental_hlo_to_mlir\",\n+        \"//xla/codegen/emitters/ir:xla\",\n         \"//xla/hlo/analysis:indexing_analysis\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/utils:hlo_traversal\",\n+        \"//xla/runtime:work_dimensions\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/service/gpu:gpu_constants\",\n         \"//xla/service/gpu:gpu_fusible\",\n         \"//xla/service/gpu:hlo_fusion_analysis\",\n         \"//xla/service/gpu:ir_emission_utils\",\n         \"//xla/service/gpu:launch_dimensions\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n         \"@llvm-project//llvm:Support\","
        },
        {
            "sha": "88b849419fc7f7bd1979185e5090498f54091b14",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/in_place_dynamic_update_slice.cc",
            "status": "modified",
            "additions": 41,
            "deletions": 100,
            "changes": 141,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Fin_place_dynamic_update_slice.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Fin_place_dynamic_update_slice.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Fin_place_dynamic_update_slice.cc?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -16,51 +16,36 @@ limitations under the License.\n \n #include <cstdint>\n #include <optional>\n+#include <string>\n+#include <utility>\n #include <vector>\n \n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"llvm/ADT/STLExtras.h\"\n-#include \"llvm/ADT/SmallVector.h\"\n-#include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n-#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/AffineExpr.h\"\n #include \"mlir/IR/AffineMap.h\"\n-#include \"mlir/IR/ImplicitLocOpBuilder.h\"\n+#include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/MLIRContext.h\"\n-#include \"mlir/IR/Value.h\"\n-#include \"mlir/IR/ValueRange.h\"\n+#include \"mlir/IR/OwningOpRef.h\"\n #include \"xla/codegen/emitters/computation_partitioner.h\"\n-#include \"xla/codegen/emitters/elemental_hlo_to_mlir.h\"\n-#include \"xla/hlo/analysis/indexing_analysis.h\"\n+#include \"xla/codegen/emitters/dynamic_update_slice_kernel_emitter.h\"\n+#include \"xla/codegen/emitters/ir/xla_ops.h\"\n #include \"xla/hlo/analysis/indexing_map.h\"\n-#include \"xla/hlo/ir/hlo_casting_utils.h\"\n-#include \"xla/hlo/ir/hlo_computation.h\"\n-#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n-#include \"xla/primitive_util.h\"\n+#include \"xla/runtime/work_dimensions.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/gpu/gpu_constants.h\"\n #include \"xla/service/gpu/hlo_fusion_analysis.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/xla_data.pb.h\"\n \n namespace xla {\n namespace gpu {\n namespace {\n \n-using emitters::ApplyIndexing;\n-using emitters::CallTargetProvider;\n-using emitters::ClampIndex;\n-using emitters::PartitionedComputations;\n-using emitters::ProvideParameter;\n-using llvm::SmallVector;\n-using mlir::ImplicitLocOpBuilder;\n-using mlir::Value;\n-using mlir::ValueRange;\n-using mlir::arith::AddIOp;\n-using mlir::func::ReturnOp;\n-using mlir::tensor::InsertOp;\n-\n constexpr int kDUSUpdateIndex = 1;\n \n }  // namespace\n@@ -80,12 +65,12 @@ InPlaceDynamicUpdateSliceFusion::ComputeThreadIdToInputIndexing(\n   if (hero_operand_index != kDUSUpdateIndex) {\n     return std::nullopt;\n   }\n-  auto launch_dims = launch_dimensions();\n-  // It is guaranteed that all DUS ops have the same output shape at this point.\n-  const auto& update_shape =\n-      dus_ops_.front().GetOperand(kDUSUpdateIndex).shape();\n-  return GetDefaultThreadIdIndexingMap(launch_dims, config_.unroll_factor,\n-                                       update_shape, indexing_context);\n+\n+  using KernelEmitter = emitters::DynamicUpdateSliceKernelEmitter;\n+  return KernelEmitter::ComputeWorkItemIdToOutputIndexing(\n+      GetWorkDimensions(),\n+      KernelEmitter::GetIndexingShape(analysis_.fusion_spec()),\n+      indexing_context);\n }\n \n std::vector<emitters::EpilogueSpecification>\n@@ -102,77 +87,33 @@ InPlaceDynamicUpdateSliceFusion::GetEpilogues(\n   return epilogues;\n }\n \n+WorkDimensions InPlaceDynamicUpdateSliceFusion::GetWorkDimensions() const {\n+  WorkDimensions work_dimensions = launch_dimensions().AsWorkDimensions();\n+  work_dimensions.work_tile_size.dimensions.push_back(config_.unroll_factor);\n+  return work_dimensions;\n+}\n+\n+absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>>\n+InPlaceDynamicUpdateSliceFusion::CreateMLIRModule(\n+    mlir::MLIRContext& context, const HloFusionInstruction& fusion,\n+    const std::string& entry_function_name,\n+    const BufferAssignment* buffer_assignment) const {\n+  emitters::DynamicUpdateSliceKernelEmitter emitter(\n+      context, fusion, analysis_.fusion_spec(), buffer_assignment,\n+      GetDefaultBufferAlignment(), GetWorkDimensions(), entry_function_name,\n+      BackendKind::kGpu);\n+\n+  TF_ASSIGN_OR_RETURN(auto kernel_definition, emitter.EmitKernelDefinition());\n+  auto [spec, source] = std::move(kernel_definition).ReleaseStorage();\n+  return std::move(source).ReleaseStorage().module;\n+}\n+\n absl::Status InPlaceDynamicUpdateSliceFusion::EmitEntryFunction(\n-    const PartitionedComputations& computations,\n-    const CallTargetProvider& call_targets, mlir::func::FuncOp entry_function,\n+    const emitters::PartitionedComputations& computations,\n+    const emitters::CallTargetProvider& call_targets,\n+    mlir::func::FuncOp entry_function,\n     const HloFusionInstruction& fusion) const {\n-  ImplicitLocOpBuilder b(entry_function.getLoc(), entry_function);\n-  b.setInsertionPointToStart(entry_function.addEntryBlock());\n-  auto thread_and_block_ids = EmitThreadAndBlockIds(b);\n-\n-  mlir::MLIRContext* mlir_context = entry_function.getContext();\n-\n-  auto indexing = *ComputeThreadIdToInputIndexing(\n-      /*root_index=*/0,\n-      /*hero_operand_index=*/kDUSUpdateIndex, mlir_context);\n-  indexing.Simplify();\n-  indexing.RemoveUnusedSymbols();\n-\n-  int num_inputs = fusion.fused_instructions_computation()->num_parameters();\n-  auto output_tensor_args =\n-      entry_function.getArguments().drop_front(num_inputs);\n-\n-  const auto& root_computation = computations.FindPartitionedComputation(\n-      fusion.fused_instructions_computation());\n-  auto result_tensors = emitters::EmitXlaLoopOp(\n-      b, thread_and_block_ids, output_tensor_args, indexing,\n-      [&](ImplicitLocOpBuilder& nested_b, ValueRange symbol_values,\n-          ValueRange input_indices,\n-          ValueRange output_tensors) -> llvm::SmallVector<Value> {\n-        llvm::SmallVector<Value> results;\n-        for (auto [instr, root, output] :\n-             llvm::zip(dus_ops_, analysis_.fusion_roots(), output_tensors)) {\n-          const auto* dus_instr =\n-              Cast<HloDynamicUpdateSliceInstruction>(&instr.instruction());\n-          const auto& update_shape = dus_instr->update()->shape();\n-          SmallVector<Value> update_indices;\n-          auto start_indices =\n-              ProvideParameterRange(root_computation, dus_instr,\n-                                    dus_instr->first_index_operand_number(),\n-                                    update_shape.dimensions().size(), {},\n-                                    call_targets, entry_function, nested_b);\n-          for (int i = 0; i < update_shape.dimensions().size(); ++i) {\n-            int64_t update_size = update_shape.dimensions(i);\n-            auto start_index = ClampIndex(\n-                start_indices[i],\n-                primitive_util::IsUnsignedIntegralType(\n-                    dus_instr\n-                        ->operand(i + dus_instr->first_index_operand_number())\n-                        ->shape()\n-                        .element_type()),\n-                dus_instr->shape().dimensions(i) - update_size, nested_b);\n-\n-            update_indices.push_back(\n-                nested_b.create<AddIOp>(input_indices[i], start_index));\n-          }\n-\n-          auto updated_value = ProvideParameter(\n-              root_computation, dus_instr, kDUSUpdateIndex, input_indices,\n-              call_targets, entry_function, nested_b);\n-          // Handle bitcasts under the DUS.\n-          if (dus_instr->shape() != root.shape()) {\n-            update_indices = ApplyIndexing(\n-                GetBitcastMap(dus_instr->shape(), root.shape(), b.getContext()),\n-                update_indices, {}, nested_b);\n-          }\n-          results.push_back(nested_b.create<InsertOp>(updated_value[0], output,\n-                                                      update_indices));\n-        }\n-        return results;\n-      });\n-\n-  b.create<ReturnOp>(result_tensors);\n-  return absl::OkStatus();\n+  return absl::UnimplementedError(\"Not implemented\");\n }\n \n }  // namespace gpu"
        },
        {
            "sha": "40099c5904deeb95aa909936877c8965900c8912",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/in_place_dynamic_update_slice.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Fin_place_dynamic_update_slice.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Fin_place_dynamic_update_slice.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Fin_place_dynamic_update_slice.h?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -66,6 +66,11 @@ class InPlaceDynamicUpdateSliceFusion : public EmitterBase {\n       mlir::MLIRContext* indexing_context) const override;\n \n  protected:\n+  absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> CreateMLIRModule(\n+      mlir::MLIRContext& context, const HloFusionInstruction& fusion,\n+      const std::string& entry_function_name,\n+      const BufferAssignment* buffer_assignment) const override;\n+\n   absl::Status EmitEntryFunction(\n       const emitters::PartitionedComputations& computations,\n       const emitters::CallTargetProvider& call_targets,\n@@ -76,6 +81,8 @@ class InPlaceDynamicUpdateSliceFusion : public EmitterBase {\n       const HloFusionInstruction& fusion,\n       mlir::MLIRContext* mlir_context) const override;\n \n+  WorkDimensions GetWorkDimensions() const;\n+\n  private:\n   const HloFusionAnalysis& analysis_;\n   std::vector<HloInstructionAdaptor> dus_ops_;"
        },
        {
            "sha": "01d921e5719c6f56f3e85c878d79be999ed81d88",
            "filename": "third_party/xla/xla/codegen/emitters/BUILD",
            "status": "modified",
            "additions": 45,
            "deletions": 0,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2FBUILD?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -399,6 +399,51 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"dynamic_update_slice_kernel_emitter\",\n+    srcs = [\"dynamic_update_slice_kernel_emitter.cc\"],\n+    hdrs = [\"dynamic_update_slice_kernel_emitter.h\"],\n+    deps = [\n+        \":computation_partitioner\",\n+        \":elemental_hlo_to_mlir\",\n+        \":kernel_api_builder\",\n+        \":kernel_arguments\",\n+        \"//xla:shape_util\",\n+        \"//xla:util\",\n+        \"//xla/codegen:hlo_fusion_spec\",\n+        \"//xla/codegen:ir_emission_utils\",\n+        \"//xla/codegen:kernel_definition\",\n+        \"//xla/codegen:kernel_spec\",\n+        \"//xla/codegen:mlir_kernel_definition\",\n+        \"//xla/codegen:mlir_kernel_emitter\",\n+        \"//xla/codegen:mlir_kernel_source\",\n+        \"//xla/codegen/emitters/ir:xla\",\n+        \"//xla/hlo/analysis:indexing_analysis\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/utils:hlo_traversal\",\n+        \"//xla/runtime:work_dimensions\",\n+        \"//xla/runtime:work_item\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/service/llvm_ir:llvm_util\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@llvm-project//llvm:Support\",\n+        \"@llvm-project//mlir:ArithDialect\",\n+        \"@llvm-project//mlir:DialectUtils\",\n+        \"@llvm-project//mlir:FuncDialect\",\n+        \"@llvm-project//mlir:IR\",\n+        \"@llvm-project//mlir:SCFDialect\",\n+        \"@llvm-project//mlir:Support\",\n+        \"@llvm-project//mlir:TensorDialect\",\n+    ],\n+)\n+\n xla_cc_test(\n     name = \"type_util_test\",\n     srcs = [\"type_util_test.cc\"],"
        },
        {
            "sha": "a3c9b174e01530c17ed720e74ef97dc66b15ea60",
            "filename": "third_party/xla/xla/codegen/emitters/dynamic_update_slice_kernel_emitter.cc",
            "status": "added",
            "additions": 312,
            "deletions": 0,
            "changes": 312,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fdynamic_update_slice_kernel_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fdynamic_update_slice_kernel_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fdynamic_update_slice_kernel_emitter.cc?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -0,0 +1,312 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/codegen/emitters/dynamic_update_slice_kernel_emitter.h\"\n+\n+#include <array>\n+#include <cstdint>\n+#include <optional>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/algorithm/container.h\"\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"llvm/ADT/STLExtras.h\"\n+#include \"llvm/ADT/SmallVector.h\"\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/Dialect/SCF/IR/SCF.h\"\n+#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n+#include \"mlir/Dialect/Utils/StaticValueUtils.h\"\n+#include \"mlir/IR/AffineExpr.h\"\n+#include \"mlir/IR/AffineMap.h\"\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/BuiltinOps.h\"\n+#include \"mlir/IR/Location.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/IR/OwningOpRef.h\"\n+#include \"mlir/IR/Value.h\"\n+#include \"mlir/IR/ValueRange.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"xla/codegen/emitters/computation_partitioner.h\"\n+#include \"xla/codegen/emitters/elemental_hlo_to_mlir.h\"\n+#include \"xla/codegen/emitters/ir/xla_ops.h\"\n+#include \"xla/codegen/emitters/kernel_api_builder.h\"\n+#include \"xla/codegen/emitters/kernel_arguments.h\"\n+#include \"xla/codegen/hlo_fusion_spec.h\"\n+#include \"xla/codegen/ir_emission_utils.h\"\n+#include \"xla/codegen/kernel_spec.h\"\n+#include \"xla/codegen/mlir_kernel_definition.h\"\n+#include \"xla/codegen/mlir_kernel_source.h\"\n+#include \"xla/hlo/analysis/indexing_analysis.h\"\n+#include \"xla/hlo/analysis/indexing_map.h\"\n+#include \"xla/hlo/ir/hlo_casting_utils.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/utils/hlo_traversal.h\"\n+#include \"xla/primitive_util.h\"\n+#include \"xla/runtime/work_dimensions.h\"\n+#include \"xla/runtime/work_item.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/llvm_ir/llvm_util.h\"\n+#include \"xla/shape.h\"\n+#include \"xla/shape_util.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n+\n+namespace xla::emitters {\n+\n+constexpr int kDUSUpdateIndex = 1;\n+\n+DynamicUpdateSliceKernelEmitter::DynamicUpdateSliceKernelEmitter(\n+    mlir::MLIRContext& mlir_context, const HloFusionInstruction& fusion,\n+    const HloFusionSpec& fusion_spec, const BufferAssignment* buffer_assignment,\n+    KernelArguments::BufferAlignment buffer_alignment,\n+    WorkDimensions work_dimensions, absl::string_view entry_function_name,\n+    BackendKind backend_kind)\n+    : mlir_context_(mlir_context),\n+      fusion_(fusion),\n+      fusion_spec_(fusion_spec),\n+      dus_ops_(\n+          GetOutputDefiningDynamicUpdateSlices(fusion_spec.fusion_roots())),\n+      buffer_assignment_(buffer_assignment),\n+      buffer_alignment_(std::move(buffer_alignment)),\n+      work_dimensions_(std::move(work_dimensions)),\n+      entry_function_name_(entry_function_name),\n+      backend_kind_(backend_kind) {}\n+\n+absl::StatusOr<MlirKernelDefinition>\n+DynamicUpdateSliceKernelEmitter::EmitKernelDefinition() {\n+  mlir::OpBuilder builder(&mlir_context_);\n+  auto loc = mlir::NameLoc::get(builder.getStringAttr(fusion_.name()));\n+  mlir::OwningOpRef<mlir::ModuleOp> module = llvm_ir::CreateMlirModuleOp(\n+      loc, absl::StrCat(fusion_.name(), \"_kernel_module\"));\n+\n+  bool force_64_bit = backend_kind_ == BackendKind::kCpu;\n+  emitters::SetIndexDataLayout(*module, fusion_, force_64_bit);\n+\n+  TF_ASSIGN_OR_RETURN(\n+      mlir::func::FuncOp entry_func,\n+      emitters::EmitKernelApi(*module, fusion_, buffer_assignment_,\n+                              buffer_alignment_, entry_function_name_));\n+  SetBackendKind(&mlir_context_, entry_func, backend_kind_);\n+\n+  emitters::PartitionedComputations computations(\n+      fusion_.fused_instructions_computation(), &mlir_context_, GetEpilogues());\n+  TF_ASSIGN_OR_RETURN(auto call_targets, emitters::EmitPartitionedComputations(\n+                                             *module, computations));\n+\n+  TF_RETURN_IF_ERROR(\n+      EmitEntryFunction(computations, call_targets, entry_func, fusion_));\n+\n+  TF_ASSIGN_OR_RETURN(auto kernel_spec, GetKernelSpec());\n+\n+  return MlirKernelDefinition(std::move(kernel_spec),\n+                              MlirKernelSource(std::move(module)));\n+}\n+\n+IndexingMap DynamicUpdateSliceKernelEmitter::ComputeWorkItemIdToInputIndexing(\n+    mlir::MLIRContext* ctx) const {\n+  // It is guaranteed that all DUS ops have the same output shape at this point.\n+  const auto& update_shape =\n+      dus_ops_.front().GetOperand(kDUSUpdateIndex).shape();\n+  return ComputeWorkItemIdToOutputIndexing(work_dimensions_, update_shape, ctx);\n+}\n+\n+Shape DynamicUpdateSliceKernelEmitter::GetIndexingShape(\n+    const HloFusionSpec& fusion_spec) {\n+  auto dus_ops =\n+      GetOutputDefiningDynamicUpdateSlices(fusion_spec.fusion_roots());\n+  return dus_ops.front().GetOperand(kDUSUpdateIndex).shape();\n+}\n+\n+IndexingMap DynamicUpdateSliceKernelEmitter::ComputeWorkItemIdToOutputIndexing(\n+    const WorkDimensions& work_dimensions, const Shape& update_shape,\n+    mlir::MLIRContext* ctx) {\n+  return GetDefaultWorkItemIndexingMap(work_dimensions, update_shape, ctx);\n+}\n+\n+absl::StatusOr<KernelSpec> DynamicUpdateSliceKernelEmitter::GetKernelSpec()\n+    const {\n+  if (buffer_assignment_ == nullptr) {\n+    return KernelSpec(entry_function_name_, work_dimensions_,\n+                      KernelSpec::Buffers(), KernelSpec::Buffers(),\n+                      absl::flat_hash_set<int64_t>());\n+  }\n+\n+  KernelSpec::Buffers result_buffers;\n+  for (auto& indexed : ShapeUtil::GetLeafShapes(fusion_.shape())) {\n+    TF_ASSIGN_OR_RETURN(\n+        BufferAllocation::Slice slice,\n+        buffer_assignment_->GetUniqueSlice(&fusion_, indexed.index));\n+    result_buffers.push_back(std::move(slice));\n+  }\n+\n+  KernelSpec::Buffers argument_buffers;\n+  absl::flat_hash_set<int64_t> invariant_arguments;\n+  int64_t operand_index = 0;\n+  for (HloInstruction* operand : fusion_.operands()) {\n+    for (auto& indexed : ShapeUtil::GetLeafShapes(operand->shape())) {\n+      TF_ASSIGN_OR_RETURN(\n+          BufferAllocation::Slice slice,\n+          buffer_assignment_->GetUniqueSlice(operand, indexed.index));\n+\n+      bool invariant = absl::c_none_of(\n+          result_buffers,\n+          [&slice](const BufferAllocation::Slice& result_slice) {\n+            return result_slice.OverlapsWith(slice);\n+          });\n+      if (invariant) {\n+        invariant_arguments.insert(operand_index);\n+      }\n+\n+      argument_buffers.push_back(std::move(slice));\n+      ++operand_index;\n+    }\n+  }\n+\n+  return KernelSpec(entry_function_name_, work_dimensions_,\n+                    std::move(argument_buffers), std::move(result_buffers),\n+                    std::move(invariant_arguments));\n+}\n+\n+absl::Status DynamicUpdateSliceKernelEmitter::EmitEntryFunction(\n+    const emitters::PartitionedComputations& computations,\n+    const emitters::CallTargetProvider& call_targets,\n+    mlir::func::FuncOp entry_function,\n+    const HloFusionInstruction& fusion) const {\n+  mlir::MLIRContext* context = entry_function.getContext();\n+\n+  mlir::ImplicitLocOpBuilder builder(entry_function.getLoc(), entry_function);\n+  builder.setInsertionPointToStart(entry_function.addEntryBlock());\n+\n+  auto indexing = ComputeWorkItemIdToInputIndexing(context);\n+  indexing.Simplify();\n+  indexing.RemoveUnusedSymbols();\n+\n+  int num_inputs = fusion.fused_instructions_computation()->num_parameters();\n+  auto output_tensor_args =\n+      entry_function.getArguments().drop_front(num_inputs);\n+\n+  const auto& root_computation = computations.FindPartitionedComputation(\n+      fusion.fused_instructions_computation());\n+\n+  auto body_builder =\n+      [&](mlir::ImplicitLocOpBuilder& nested_b, mlir::ValueRange symbol_values,\n+          mlir::ValueRange input_indices,\n+          mlir::ValueRange output_tensors) -> llvm::SmallVector<mlir::Value> {\n+    llvm::SmallVector<mlir::Value> results;\n+    for (auto [instr, root, output] :\n+         llvm::zip(dus_ops_, fusion_spec_.fusion_roots(), output_tensors)) {\n+      const auto* dus_instr =\n+          Cast<HloDynamicUpdateSliceInstruction>(&instr.instruction());\n+      const auto& update_shape = dus_instr->update()->shape();\n+      llvm::SmallVector<mlir::Value> update_indices;\n+      auto start_indices = ProvideParameterRange(\n+          root_computation, dus_instr, dus_instr->first_index_operand_number(),\n+          update_shape.dimensions().size(), {}, call_targets, entry_function,\n+          nested_b);\n+      for (int i = 0; i < update_shape.dimensions().size(); ++i) {\n+        int64_t update_size = update_shape.dimensions(i);\n+        auto start_index = ClampIndex(\n+            start_indices[i],\n+            primitive_util::IsUnsignedIntegralType(\n+                dus_instr->operand(i + dus_instr->first_index_operand_number())\n+                    ->shape()\n+                    .element_type()),\n+            dus_instr->shape().dimensions(i) - update_size, nested_b);\n+\n+        update_indices.push_back(nested_b.create<mlir::arith::AddIOp>(\n+            input_indices[i], start_index));\n+      }\n+\n+      auto updated_value = ProvideParameter(\n+          root_computation, dus_instr, kDUSUpdateIndex, input_indices,\n+          call_targets, entry_function, nested_b);\n+      // Handle bitcasts under the DUS.\n+      if (dus_instr->shape() != root.shape()) {\n+        update_indices = ApplyIndexing(\n+            GetBitcastMap(dus_instr->shape(), root.shape(), context),\n+            update_indices, {}, nested_b);\n+      }\n+      results.push_back(nested_b.create<mlir::tensor::InsertOp>(\n+          updated_value[0], output, update_indices));\n+    }\n+    return results;\n+  };\n+\n+  auto workgroup_ids =\n+      EmitWorkGroupIds(builder, work_dimensions_.num_work_groups);\n+\n+  const auto forall_builder = [&](mlir::OpBuilder& builder, mlir::Location loc,\n+                                  mlir::ValueRange workitem_ids_and_outputs) {\n+    mlir::ImplicitLocOpBuilder nested_b(loc, builder);\n+\n+    mlir::ValueRange workitem_ids = workitem_ids_and_outputs.take_front(3);\n+    mlir::ValueRange outputs = workitem_ids_and_outputs.drop_front(3);\n+\n+    llvm::SmallVector<mlir::Value, 6> work_dims;\n+    work_dims.insert(work_dims.end(), workitem_ids.begin(), workitem_ids.end());\n+    work_dims.insert(work_dims.end(), workgroup_ids.begin(),\n+                     workgroup_ids.end());\n+\n+    auto loop_results = emitters::EmitXlaLoopOp(\n+        nested_b, mlir::ValueRange(work_dims), outputs, indexing, body_builder);\n+    auto terminator = nested_b.create<mlir::scf::InParallelOp>();\n+    nested_b.setInsertionPointToStart(terminator.getBody());\n+    for (auto [result, output] : llvm::zip(loop_results, outputs)) {\n+      auto output_tensor = mlir::cast<mlir::RankedTensorType>(output.getType());\n+      llvm::SmallVector<mlir::OpFoldResult> offsets(output_tensor.getRank(),\n+                                                    nested_b.getIndexAttr(0));\n+      llvm::SmallVector<mlir::OpFoldResult> sizes =\n+          mlir::getAsIndexOpFoldResult(context, output_tensor.getShape());\n+      llvm::SmallVector<mlir::OpFoldResult> strides(output_tensor.getRank(),\n+                                                    nested_b.getIndexAttr(1));\n+      nested_b.create<mlir::tensor::ParallelInsertSliceOp>(\n+          result, output, offsets, sizes, strides);\n+    }\n+  };\n+\n+  const NumWorkItems& num_work_items = work_dimensions_.num_work_items;\n+  llvm::SmallVector<mlir::OpFoldResult> upper_bounds =\n+      mlir::getAsIndexOpFoldResult(context,\n+                                   {static_cast<int64_t>(num_work_items.x),\n+                                    static_cast<int64_t>(num_work_items.y),\n+                                    static_cast<int64_t>(num_work_items.z)});\n+  builder.create<mlir::func::ReturnOp>(\n+      builder\n+          .create<mlir::scf::ForallOp>(upper_bounds, output_tensor_args,\n+                                       std::nullopt, forall_builder)\n+          .getResults());\n+  return absl::OkStatus();\n+}\n+\n+std::vector<emitters::EpilogueSpecification>\n+DynamicUpdateSliceKernelEmitter::GetEpilogues() const {\n+  std::vector<emitters::EpilogueSpecification> epilogues;\n+  for (const auto& [dus_op, root] :\n+       llvm::zip(dus_ops_, fusion_spec_.fusion_roots())) {\n+    epilogues.push_back(emitters::EpilogueSpecification::FromIdentityIndexing(\n+        &dus_op.instruction(), &root.instruction(), &mlir_context_));\n+  }\n+  return epilogues;\n+}\n+\n+}  // namespace xla::emitters"
        },
        {
            "sha": "e0a2353d030b9c8712693a1229c6c7f6c46bcc35",
            "filename": "third_party/xla/xla/codegen/emitters/dynamic_update_slice_kernel_emitter.h",
            "status": "added",
            "additions": 100,
            "deletions": 0,
            "changes": 100,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fdynamic_update_slice_kernel_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fdynamic_update_slice_kernel_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fdynamic_update_slice_kernel_emitter.h?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -0,0 +1,100 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_CODEGEN_EMITTERS_DYNAMIC_UPDATE_SLICE_KERNEL_EMITTER_H_\n+#define XLA_CODEGEN_EMITTERS_DYNAMIC_UPDATE_SLICE_KERNEL_EMITTER_H_\n+\n+#include <string>\n+#include <vector>\n+\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"xla/codegen/emitters/computation_partitioner.h\"\n+#include \"xla/codegen/emitters/ir/xla_ops.h\"\n+#include \"xla/codegen/emitters/kernel_arguments.h\"\n+#include \"xla/codegen/hlo_fusion_spec.h\"\n+#include \"xla/codegen/kernel_definition.h\"\n+#include \"xla/codegen/kernel_spec.h\"\n+#include \"xla/codegen/mlir_kernel_definition.h\"\n+#include \"xla/codegen/mlir_kernel_emitter.h\"\n+#include \"xla/hlo/analysis/indexing_map.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/utils/hlo_traversal.h\"\n+#include \"xla/runtime/work_dimensions.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/shape.h\"\n+\n+namespace xla::emitters {\n+\n+// Fusion node where the root is either:\n+// 1. a dynamic-update-slice op\n+// 2. a bitcast of a dynamic-update-slice op\n+// 3. a tuple op returning the result of several dynamic-update-slice ops\n+// 4. a tuple op returning the result of several bitcast\n+//    dynamic-update-slice ops\n+class DynamicUpdateSliceKernelEmitter final : public MlirKernelEmitter {\n+ public:\n+  DynamicUpdateSliceKernelEmitter(\n+      mlir::MLIRContext& mlir_context, const HloFusionInstruction& fusion,\n+      const HloFusionSpec& fusion_spec,\n+      const BufferAssignment* buffer_assignment,\n+      KernelArguments::BufferAlignment buffer_alignment,\n+      WorkDimensions work_dimensions, absl::string_view entry_function_name,\n+      BackendKind backend_kind);\n+\n+  absl::StatusOr<MlirKernelDefinition> EmitKernelDefinition() override;\n+\n+  // Get the shape that will be used for loop indexing for the given fusion\n+  // specification.\n+  static Shape GetIndexingShape(const HloFusionSpec& fusion_spec);\n+  // Get the mapping from work item id to output.\n+  static IndexingMap ComputeWorkItemIdToOutputIndexing(\n+      const WorkDimensions& work_dimensions, const Shape& update_shape,\n+      mlir::MLIRContext* ctx);\n+\n+  std::string name() const final {\n+    return \"dynamic_update_slice_kernel_emitter\";\n+  }\n+\n+ private:\n+  IndexingMap ComputeWorkItemIdToInputIndexing(mlir::MLIRContext* ctx) const;\n+  absl::StatusOr<KernelSpec> GetKernelSpec() const;\n+\n+  absl::Status EmitEntryFunction(\n+      const emitters::PartitionedComputations& computations,\n+      const emitters::CallTargetProvider& call_targets,\n+      mlir::func::FuncOp entry_function,\n+      const HloFusionInstruction& fusion) const;\n+\n+  std::vector<emitters::EpilogueSpecification> GetEpilogues() const;\n+\n+ private:\n+  mlir::MLIRContext& mlir_context_;\n+  const HloFusionInstruction& fusion_;\n+  const HloFusionSpec& fusion_spec_;\n+  std::vector<HloInstructionAdaptor> dus_ops_;\n+  const BufferAssignment* buffer_assignment_;\n+  KernelArguments::BufferAlignment buffer_alignment_;\n+  WorkDimensions work_dimensions_;\n+  std::string entry_function_name_;\n+  BackendKind backend_kind_;\n+};\n+\n+}  // namespace xla::emitters\n+\n+#endif  // XLA_CODEGEN_EMITTERS_DYNAMIC_UPDATE_SLICE_KERNEL_EMITTER_H_"
        },
        {
            "sha": "dc490a95a504c6e5f4a5cd583b19a7df7e131d7e",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/mof.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fmof.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fmof.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fmof.hlo?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -1,5 +1,5 @@\n // RUN: gpu_test_correctness %s\n-// b/435101580: Add CPU test once DUS is migrated.\n+// RUN: cpu_test_correctness %s\n \n fusion {\n   p0 = f32[10,11,12] parameter(0)"
        },
        {
            "sha": "25a1b058c192801f21112d4c5c28dd0a8b284610",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/operand_subgraph_two_roots.hlo",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Foperand_subgraph_two_roots.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Foperand_subgraph_two_roots.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Foperand_subgraph_two_roots.hlo?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -1,4 +1,6 @@\n // RUN: gpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n+// RUN:   FileCheck %s --check-prefixes=CHECK,CHECK-GPU\n+// RUN: cpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n // RUN:   FileCheck %s\n // RUN: gpu_test_correctness %s\n // RUN: cpu_test_correctness %s\n@@ -36,8 +38,8 @@ ENTRY main {\n // CHECK-SAME:  , %[[ARG4:[^:]+]]: tensor<512x512xf32>\n // CHECK-DAG:   %[[C_384:.*]] = arith.constant 384\n // CHECK-DAG:   %[[C_0:.*]] = arith.constant 0\n-// CHECK:       %[[THREAD_ID:.*]] = gpu.thread_id  x\n-// CHECK:       %[[BLOCK_ID:.*]] = gpu.block_id  x\n+// CHECK-GPU:   %[[WORKGROUP_ID:.*]] = xla.workgroup_id x\n+// CHECK-GPU:   scf.forall (%[[WORKITEM_ID:.*]]) in (128)\n // CHECK:     xla.loop\n // CHECK-SAME:  -> (%[[RA:.*]], %[[RB:.*]]) in\n // CHECK:       %[[I0:.*]] = xla.pure_call @fusion_param_2_plus_one"
        },
        {
            "sha": "b7059f18815299f61660656f349ec62fe35f225b",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/out_of_bounds.hlo",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fout_of_bounds.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fout_of_bounds.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fout_of_bounds.hlo?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -1,4 +1,6 @@\n // RUN: gpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n+// RUN:   FileCheck %s --check-prefixes=CHECK,CHECK-GPU\n+// RUN: cpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n // RUN:   FileCheck %s\n // RUN: gpu_test_correctness %s\n // RUN: cpu_test_correctness %s\n@@ -30,7 +32,7 @@ ENTRY main {\n // CHECK-SAME:  %arg4: tensor<7x8xf32>\n // CHECK-DAG:   %[[C_5:.*]] = arith.constant 5\n // CHECK-DAG:   %[[C_0:.*]] = arith.constant 0\n-// CHECK:       %[[THREAD_ID:.*]] = gpu.thread_id  x\n+// CHECK-GPU:   scf.forall (%[[WORKITEM_ID:.*]]) in (6)\n // CHECK:     xla.loop\n // CHECK-SAME:  -> (%[[RA:.*]], %[[RB:.*]]) in\n // CHECK:       %[[I0:.*]] = xla.pure_call @fusion_i0"
        },
        {
            "sha": "9095353b8f1a575d67b796ad80b66bf959c99885",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/simple.hlo",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fsimple.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fsimple.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fsimple.hlo?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -1,4 +1,6 @@\n // RUN: gpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n+// RUN:   FileCheck %s --check-prefixes=CHECK,CHECK-GPU\n+// RUN: cpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n // RUN:   FileCheck %s\n // RUN: gpu_test_correctness %s --bijection_inputs=updated:1\n // RUN: cpu_test_correctness %s\n@@ -31,7 +33,7 @@ ENTRY main {\n // CHECK-DAG:   %[[C_24:.*]] = arith.constant 24\n // CHECK-DAG:   %[[C_15:.*]] = arith.constant 15\n // CHECK-DAG:   %[[C_0:.*]] = arith.constant 0\n-// CHECK:       %[[THREAD_ID:.*]] = gpu.thread_id  x\n+// CHECK-GPU:   scf.forall (%[[WORKITEM_ID:.*]]) in (30)\n \n // CHECK:     xla.loop\n // CHECK-SAME:  -> (%[[RA:.*]], %[[RB:.*]]) in"
        },
        {
            "sha": "59b20ad6a4593d773982c76eb493b092c87cb5b2",
            "filename": "third_party/xla/xla/service/cpu/cpu_instruction_fusion.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_instruction_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d382bb95c8ba4f6bd19086906e8bab5855fe02d/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_instruction_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_instruction_fusion.cc?ref=6d382bb95c8ba4f6bd19086906e8bab5855fe02d",
            "patch": "@@ -40,8 +40,7 @@ namespace {\n bool CanBeLoopFused(const HloInstruction& hlo) {\n   // These are the only ones we fuse since we rely on effective elemental IR\n   // generation.\n-  return hlo.IsElementwise() ||  //\n-         hlo.opcode() == HloOpcode::kBitcast ||\n+  return hlo.IsElementwise() || hlo.opcode() == HloOpcode::kBitcast ||\n          hlo.opcode() == HloOpcode::kBroadcast ||\n          hlo.opcode() == HloOpcode::kConcatenate ||\n          hlo.opcode() == HloOpcode::kDynamicSlice ||"
        }
    ],
    "stats": {
        "total": 681,
        "additions": 573,
        "deletions": 108
    }
}