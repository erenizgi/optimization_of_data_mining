{
    "author": "pifon2a",
    "message": "[XLA:GPU] Create xla::gpu::GpuModel enum.\n\nPiperOrigin-RevId: 849266522",
    "sha": "81faadcec5adf1b06774748c20c7012bbe6aaa72",
    "files": [
        {
            "sha": "9fe363f667eba8d6005913049e847078761ba933",
            "filename": "third_party/xla/xla/backends/gpu/target_config/target_config.cc",
            "status": "modified",
            "additions": 28,
            "deletions": 36,
            "changes": 64,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/81faadcec5adf1b06774748c20c7012bbe6aaa72/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/81faadcec5adf1b06774748c20c7012bbe6aaa72/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.cc?ref=81faadcec5adf1b06774748c20c7012bbe6aaa72",
            "patch": "@@ -30,48 +30,40 @@ namespace xla::gpu {\n namespace {\n \n absl::StatusOr<absl::string_view> GetEmbeddedGpuTargetConfigData(\n-    const std::string& gpu_model) {\n-  if (gpu_model == \"a100_pcie_80\") {\n-    return get_a100_pcie_80();\n+    GpuModel gpu_model) {\n+  switch (gpu_model) {\n+    case GpuModel::A100_PCIE_80:\n+      return get_a100_pcie_80();\n+    case GpuModel::A100_SXM_40:\n+      return get_a100_sxm_40();\n+    case GpuModel::A100_SXM_80:\n+      return get_a100_sxm_80();\n+    case GpuModel::A6000:\n+      return get_a6000();\n+    case GpuModel::B200:\n+      return get_b200();\n+    case GpuModel::B300:\n+      return get_b300();\n+    case GpuModel::H100_PCIE:\n+      return get_h100_pcie();\n+    case GpuModel::H100_SXM:\n+      return get_h100_sxm();\n+    case GpuModel::MI200:\n+      return get_mi200();\n+    case GpuModel::P100:\n+      return get_p100();\n+    case GpuModel::V100:\n+      return get_v100();\n+    default:\n+      return absl::NotFoundError(\n+          absl::StrCat(\"Embedded file not found: \", gpu_model, \".txtpb\"));\n   }\n-  if (gpu_model == \"a100_sxm_40\") {\n-    return get_a100_sxm_40();\n-  }\n-  if (gpu_model == \"a100_sxm_80\") {\n-    return get_a100_sxm_80();\n-  }\n-  if (gpu_model == \"a6000\") {\n-    return get_a6000();\n-  }\n-  if (gpu_model == \"b200\") {\n-    return get_b200();\n-  }\n-  if (gpu_model == \"b300\") {\n-    return get_b300();\n-  }\n-  if (gpu_model == \"h100_pcie\") {\n-    return get_h100_pcie();\n-  }\n-  if (gpu_model == \"h100_sxm\") {\n-    return get_h100_sxm();\n-  }\n-  if (gpu_model == \"mi200\") {\n-    return get_mi200();\n-  }\n-  if (gpu_model == \"p100\") {\n-    return get_p100();\n-  }\n-  if (gpu_model == \"v100\") {\n-    return get_v100();\n-  }\n-  return absl::NotFoundError(\n-      absl::StrCat(\"Embedded file not found: \", gpu_model, \".txtpb\"));\n }\n \n }  // namespace\n \n absl::StatusOr<stream_executor::GpuTargetConfigProto> GetGpuTargetConfig(\n-    const std::string& gpu_model) {\n+    GpuModel gpu_model) {\n   TF_ASSIGN_OR_RETURN(absl::string_view gpu_spec,\n                       GetEmbeddedGpuTargetConfigData(gpu_model));\n "
        },
        {
            "sha": "2ca38f97fbc3d56bea937b6b7909a8c52af70bd6",
            "filename": "third_party/xla/xla/backends/gpu/target_config/target_config.h",
            "status": "modified",
            "additions": 15,
            "deletions": 1,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/81faadcec5adf1b06774748c20c7012bbe6aaa72/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/81faadcec5adf1b06774748c20c7012bbe6aaa72/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.h?ref=81faadcec5adf1b06774748c20c7012bbe6aaa72",
            "patch": "@@ -23,9 +23,23 @@ limitations under the License.\n \n namespace xla::gpu {\n \n+enum class GpuModel {\n+  A100_PCIE_80,\n+  A100_SXM_40,\n+  A100_SXM_80,\n+  A6000,\n+  B200,\n+  B300,\n+  H100_PCIE,\n+  H100_SXM,\n+  MI200,\n+  P100,\n+  V100,\n+};\n+\n // Returns the GpuTargetConfigProto for the given GPU model.\n absl::StatusOr<stream_executor::GpuTargetConfigProto> GetGpuTargetConfig(\n-    const std::string& gpu_model);\n+    GpuModel gpu_model);\n \n }  // namespace xla::gpu\n "
        },
        {
            "sha": "d40db71c6f90d26c15a4d1226add9cebd2c10a54",
            "filename": "third_party/xla/xla/backends/gpu/target_config/target_config_test.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 13,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/81faadcec5adf1b06774748c20c7012bbe6aaa72/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/81faadcec5adf1b06774748c20c7012bbe6aaa72/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config_test.cc?ref=81faadcec5adf1b06774748c20c7012bbe6aaa72",
            "patch": "@@ -32,7 +32,7 @@ using ::tsl::testing::StatusIs;\n \n struct GpuTargetConfigTestCase {\n   std::string test_name;\n-  std::string gpu_model;\n+  GpuModel gpu_model;\n   bool expect_ok;\n };\n \n@@ -57,18 +57,17 @@ TEST_P(GetGpuTargetConfigTest, TestProtoRetrieval) {\n INSTANTIATE_TEST_SUITE_P(\n     GetGpuTargetConfigTests, GetGpuTargetConfigTest,\n     ::testing::ValuesIn<GpuTargetConfigTestCase>({\n-        {\"A100_PCIE_80\", \"a100_pcie_80\", true},\n-        {\"A100_SXM_40\", \"a100_sxm_40\", true},\n-        {\"A100_SXM_80\", \"a100_sxm_80\", true},\n-        {\"A6000\", \"a6000\", true},\n-        {\"B200\", \"b200\", true},\n-        {\"B300\", \"b300\", true},\n-        {\"H100_PCIE\", \"h100_pcie\", true},\n-        {\"H100_SXM\", \"h100_sxm\", true},\n-        {\"MI200\", \"mi200\", true},\n-        {\"P100\", \"p100\", true},\n-        {\"V100\", \"v100\", true},\n-        {\"UnknownModel\", \"unknown_gpu\", false},\n+        {\"A100_PCIE_80\", GpuModel::A100_PCIE_80, true},\n+        {\"A100_SXM_40\", GpuModel::A100_SXM_40, true},\n+        {\"A100_SXM_80\", GpuModel::A100_SXM_80, true},\n+        {\"A6000\", GpuModel::A6000, true},\n+        {\"B200\", GpuModel::B200, true},\n+        {\"B300\", GpuModel::B300, true},\n+        {\"H100_PCIE\", GpuModel::H100_PCIE, true},\n+        {\"H100_SXM\", GpuModel::H100_SXM, true},\n+        {\"MI200\", GpuModel::MI200, true},\n+        {\"P100\", GpuModel::P100, true},\n+        {\"V100\", GpuModel::V100, true},\n     }),\n     [](const ::testing::TestParamInfo<GetGpuTargetConfigTest::ParamType>&\n            info) { return info.param.test_name; });"
        }
    ],
    "stats": {
        "total": 105,
        "additions": 55,
        "deletions": 50
    }
}