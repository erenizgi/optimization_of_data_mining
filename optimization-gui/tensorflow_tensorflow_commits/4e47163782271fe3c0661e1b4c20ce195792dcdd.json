{
    "author": "pifon2a",
    "message": "[XLA:GPU] Merge ir_emitter and ir_emitter_nested.\n\nPiperOrigin-RevId: 838458519",
    "sha": "4e47163782271fe3c0661e1b4c20ce195792dcdd",
    "files": [
        {
            "sha": "43cd45f395a9cc7b55b9416d9d9fff0ef43d2959",
            "filename": "third_party/xla/xla/backends/gpu/codegen/llvm/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e47163782271fe3c0661e1b4c20ce195792dcdd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e47163782271fe3c0661e1b4c20ce195792dcdd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2FBUILD?ref=4e47163782271fe3c0661e1b4c20ce195792dcdd",
            "patch": "@@ -65,9 +65,7 @@ cc_library(\n         \"@llvm-project//llvm:Core\",\n         \"@llvm-project//llvm:Support\",\n         \"@llvm-project//llvm:TargetParser\",\n-        \"@local_tsl//tsl/platform:errors\",\n         \"@local_tsl//tsl/platform:fingerprint\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n "
        },
        {
            "sha": "37599808bdeb479108e0d4857829a4f28a249fe7",
            "filename": "third_party/xla/xla/backends/gpu/codegen/llvm/llvm_emitter.cc",
            "status": "modified",
            "additions": 100,
            "deletions": 144,
            "changes": 244,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e47163782271fe3c0661e1b4c20ce195792dcdd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fllvm_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e47163782271fe3c0661e1b4c20ce195792dcdd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fllvm_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fllvm_emitter.cc?ref=4e47163782271fe3c0661e1b4c20ce195792dcdd",
            "patch": "@@ -16,7 +16,9 @@ limitations under the License.\n #include \"xla/backends/gpu/codegen/llvm/llvm_emitter.h\"\n \n #include <algorithm>\n+#include <cstddef>\n #include <cstdint>\n+#include <iterator>\n #include <memory>\n #include <optional>\n #include <string>\n@@ -47,6 +49,7 @@ limitations under the License.\n #include \"llvm/IR/Instructions.h\"\n #include \"llvm/IR/LLVMContext.h\"\n #include \"llvm/IR/Module.h\"\n+#include \"llvm/Support/Alignment.h\"\n #include \"llvm/Support/Casting.h\"\n #include \"llvm/TargetParser/Triple.h\"\n #include \"xla/backends/gpu/codegen/fusion_emitter.h\"\n@@ -57,6 +60,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/codegen/emitters/computation_fingerprint.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n+#include \"xla/hlo/ir/dfs_hlo_visitor_with_default.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n@@ -67,12 +71,14 @@ limitations under the License.\n #include \"xla/service/elemental_ir_emitter.h\"\n #include \"xla/service/gpu/gpu_constants.h\"\n #include \"xla/service/gpu/gpu_executable.h\"\n+#include \"xla/service/gpu/hlo_to_ir_bindings.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n #include \"xla/service/gpu/ir_emitter_context.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n #include \"xla/service/llvm_ir/buffer_assignment_util.h\"\n #include \"xla/service/llvm_ir/fused_ir_emitter.h\"\n #include \"xla/service/llvm_ir/ir_array.h\"\n+#include \"xla/service/llvm_ir/ir_builder_mixin.h\"\n #include \"xla/service/llvm_ir/kernel_support_library.h\"\n #include \"xla/service/llvm_ir/llvm_util.h\"\n #include \"xla/service/llvm_ir/loop_emitter.h\"\n@@ -85,23 +91,14 @@ limitations under the License.\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n-#include \"tsl/platform/errors.h\"\n #include \"tsl/platform/fingerprint.h\"\n-#include \"tsl/platform/statusor.h\"\n \n namespace xla::gpu {\n namespace {\n \n // Emits LLVM IR for a \"nested computation\" into a non-kernel device function.\n //\n-// This is used to emit code for HloComputations that don't require a separate\n-// kernel call.  For example, IrEmitterNested is used to emit code for a kReduce\n-// HLO's elementwise reduction computation.  Notably, IrEmitterNested is *not*\n-// used to emit code for fusion nodes -- fusion nodes use FusedIrEmitter, which\n-// is a different beast altogether.\n-//\n-// IrEmitterNested generates a non-kernel function with the following\n-// parameters:\n+// IrEmitter generates a non-kernel function with the following parameters:\n //\n //   - N pointers to the buffers of each of the N parameters to the computation,\n //   - a pointer to the output buffer of the computation, and\n@@ -113,23 +110,11 @@ absl::Status CallNestedComputation(llvm::IRBuilderBase* builder,\n                                    absl::Span<llvm::Value* const> operands,\n                                    llvm::Value* output);\n \n-// Abstract base class for translating HLO graphs to LLVM IR for a GPU.\n-//\n-// There are two concrete subclasses of IrEmitter: IrEmitterNested and\n-// IrEmitterUnnested.  In the unnested variety, each HLO gets its own kernel\n-// function, whereas in the nested version the whole computation is emitted as\n-// one *non-kernel* function.\n+// Class for translating HLO graphs to LLVM IR for a GPU.\n //\n-// In XLA, kernel functions never call other kernel functions.  This means that\n-// if we have a kernel -- e.g. implementing a kReduce HLO -- that wants to use\n-// an HLO computation as a \"subroutine\" -- e.g. the HLO computation that\n-// specifies how to reduce two elements -- then the subroutine computation must\n-// be emitted using IrEmitterNested.\n-//\n-// Fusion nodes are a special case.  A fusion node is emitted using\n-// IrEmitterUnnested, but the code is generated using FusedIrEmitter, which is\n-// not a subclass of gpu::IrEmitter, and in fact is better understood as an IR\n-// generator generator.  See comments on that class.\n+// In the unnested variety, each HLO gets its own kernel function, whereas in\n+// the nested version the whole computation is emitted as one *non-kernel*\n+// function.\n class IrEmitter : public DfsHloVisitorWithDefault,\n                   public IrBuilderMixin<IrEmitter> {\n  public:\n@@ -163,6 +148,7 @@ class IrEmitter : public DfsHloVisitorWithDefault,\n             &b_));\n     return absl::OkStatus();\n   }\n+\n   absl::Status HandleConvolution(HloInstruction* convolution) override {\n     if (ShapeUtil::IsZeroElementArray(convolution->shape())) {\n       // Emit no code for an empty output.\n@@ -235,9 +221,26 @@ class IrEmitter : public DfsHloVisitorWithDefault,\n     return Unimplemented(\"custom-call\");\n   }\n \n-  absl::Status HandleBatchNormInference(HloInstruction* batch_norm) override;\n-  absl::Status HandleBatchNormTraining(HloInstruction* batch_norm) override;\n-  absl::Status HandleBatchNormGrad(HloInstruction* batch_norm) override;\n+  absl::Status HandleBatchNormInference(HloInstruction*) override {\n+    return Unimplemented(\n+        \"The GPU backend does not implement BatchNormInference directly.  It \"\n+        \"should be lowered before IR emission to HLO-soup using \"\n+        \"BatchNormRewriter.\");\n+  }\n+\n+  absl::Status HandleBatchNormTraining(HloInstruction*) override {\n+    return Unimplemented(\n+        \"The GPU backend does not implement BatchNormTraining directly.  It \"\n+        \"should be lowered before IR emission to HLO-soup using \"\n+        \"BatchNormRewriter.\");\n+  }\n+\n+  absl::Status HandleBatchNormGrad(HloInstruction*) override {\n+    return Unimplemented(\n+        \"The GPU backend does not implement BatchNormGrad directly.  It should \"\n+        \"be lowered before IR emission to HLO-soup using BatchNormRewriter.\");\n+  }\n+\n   absl::Status HandleAddDependency(HloInstruction* add_dependency) override;\n \n   absl::Status FinishVisit(HloInstruction* root) override {\n@@ -246,6 +249,20 @@ class IrEmitter : public DfsHloVisitorWithDefault,\n \n   llvm::IRBuilderBase* builder() { return &b_; }\n \n+  // Generate the code for the computation passed in the constructor, if it\n+  // wasn't already generated previously.\n+  // As well as generting the code for the function, emits code for global\n+  // constants, and also populates related information to 'ir_emitter_context'\n+  // for large-constant initializations. Large constants don't get initializers\n+  // in the generated code and so must be initialized by XLA. The value of these\n+  // constants will be stored in 'content'. Constants with initializers in the\n+  // generated code will have empty 'content'.\n+  //\n+  // The allocation index for these constants will always be -1 (i.e. doesn't\n+  // correspond to any allocation)\n+  absl::StatusOr<llvm::Function*> CodegenNestedComputation(\n+      const HloComputation& nested_computation);\n+\n  protected:\n   // Helper for calling HloToIrBindings::GetIrArray.\n   //\n@@ -273,8 +290,9 @@ class IrEmitter : public DfsHloVisitorWithDefault,\n   // in the result of the given HLO instruction. This produces a series of\n   // nested loops (e.g. one for each dimension of the `hlo`'s shape). The body\n   // of the inner-most loop is provided by the body_emitter function.\n-  virtual absl::Status EmitTargetElementLoop(\n-      const HloInstruction& hlo, const llvm_ir::ElementGenerator& body_emitter);\n+  absl::Status EmitTargetElementLoop(\n+      const HloInstruction& hlo,\n+      const llvm_ir::ElementGenerator& element_generator);\n \n   IrEmitterContext* ir_emitter_context_;\n   llvm::Module* module_;\n@@ -291,51 +309,6 @@ class IrEmitter : public DfsHloVisitorWithDefault,\n                            FusedIrEmitter* fused_emitter);\n };\n \n-class IrEmitterNested : public IrEmitter {\n- public:\n-  // Constructs an LLVM IR emitter for a nested HLO computation. `function` is\n-  // the containing IR function this emitter produces IR to. See\n-  // IrEmitter::IrEmitter for the meanings of other arguments.\n-  IrEmitterNested(const HloComputation& nested_computation,\n-                  IrEmitterContext* ir_emitter_context)\n-      : IrEmitter(ir_emitter_context,\n-                  /*is_nested=*/true),\n-        nested_computation_(nested_computation) {}\n-\n-  IrEmitterNested(const IrEmitterNested&) = delete;\n-  IrEmitterNested& operator=(const IrEmitterNested&) = delete;\n-\n-  // Overrides the default empty implementation. Binds the given instruction\n-  // \"parameter\" with the parameter of the IR function.\n-  absl::Status HandleParameter(HloInstruction* parameter) override {\n-    return absl::OkStatus();\n-  }\n-\n-  // Generate the code for the computation passed in the constructor, if it\n-  // wasn't already generated previously.\n-  // As well as generting the code for the function, emits code for global\n-  // constants, and also populates related information to 'ir_emitter_context_'\n-  // for large-constant initializations. Large constants don't get initializers\n-  // in the generated code and so must be initialized by XLA. The value of these\n-  // constants will be stored in 'content'. Constants with initializers in the\n-  // generated code will have empty 'content'.\n-  //\n-  // The allocation index for these constants will always be -1 (i.e. doesn't\n-  // correspond to any allocation)\n-  absl::StatusOr<llvm::Function*> CodegenNestedComputation();\n-\n- protected:\n-  absl::Status EmitTargetElementLoop(\n-      const HloInstruction& hlo,\n-      const llvm_ir::ElementGenerator& element_generator) override;\n-\n- private:\n-  // Emits constants to generated LLVM IR, and also populates related\n-  // information to 'ir_emitter_context_' for large-constant initializations.\n-  absl::Status EmitConstants(const HloComputation& computation);\n-\n-  const HloComputation& nested_computation_;\n-};\n \n absl::Status IrEmitter::DefaultAction(HloInstruction* hlo) {\n   ElementalIrEmitter::HloToElementGeneratorMap operand_to_generator;\n@@ -387,8 +360,8 @@ absl::Status CallNestedComputation(llvm::IRBuilderBase* builder,\n   TF_RET_CHECK(computation.num_parameters() > 0);\n \n   TF_ASSIGN_OR_RETURN(llvm::Function * emitted_function,\n-                      IrEmitterNested(computation, &ir_emitter_context)\n-                          .CodegenNestedComputation());\n+                      IrEmitter(&ir_emitter_context, /*is_nested=*/true)\n+                          .CodegenNestedComputation(computation));\n \n   // Operands are in default address space for non-AMDGPU target.\n   // However for AMDGPU target, addrspacecast alloca variables from\n@@ -406,26 +379,6 @@ absl::Status CallNestedComputation(llvm::IRBuilderBase* builder,\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitter::HandleBatchNormInference(HloInstruction*) {\n-  return Unimplemented(\n-      \"The GPU backend does not implement BatchNormInference directly.  It \"\n-      \"should be lowered before IR emission to HLO-soup using \"\n-      \"BatchNormRewriter.\");\n-}\n-\n-absl::Status IrEmitter::HandleBatchNormTraining(HloInstruction*) {\n-  return Unimplemented(\n-      \"The GPU backend does not implement BatchNormTraining directly.  It \"\n-      \"should be lowered before IR emission to HLO-soup using \"\n-      \"BatchNormRewriter.\");\n-}\n-\n-absl::Status IrEmitter::HandleBatchNormGrad(HloInstruction*) {\n-  return Unimplemented(\n-      \"The GPU backend does not implement BatchNormGrad directly.  It should \"\n-      \"be lowered before IR emission to HLO-soup using BatchNormRewriter.\");\n-}\n-\n std::vector<llvm_ir::IrArray> IrEmitter::ConstructIrArrayForOutputs(\n     const HloInstruction& hlo) {\n   std::vector<llvm_ir::IrArray> output_arrays;\n@@ -441,11 +394,6 @@ std::vector<llvm_ir::IrArray> IrEmitter::ConstructIrArrayForOutputs(\n   return output_arrays;\n }\n \n-absl::Status IrEmitter::EmitTargetElementLoop(\n-    const HloInstruction& hlo, const llvm_ir::ElementGenerator& body_emitter) {\n-  return Internal(\"This should be unreachable\");\n-}\n-\n void IrEmitter::BindFusionArguments(const HloInstruction* fusion,\n                                     FusedIrEmitter* fused_emitter) {\n   for (int i = 0; i < fusion->operand_count(); i++) {\n@@ -459,24 +407,61 @@ void IrEmitter::BindFusionArguments(const HloInstruction* fusion,\n   }\n }\n \n+// Emits constants to generated LLVM IR, and also populates related information\n+// to 'ir_emitter_context' for large-constant initializations.\n+absl::Status EmitConstants(llvm::Module* module,\n+                           IrEmitterContext* ir_emitter_context,\n+                           const HloComputation& computation) {\n+  for (HloInstruction* instr : computation.instructions()) {\n+    if (instr->opcode() != HloOpcode::kConstant) {\n+      continue;\n+    }\n+    const Literal& literal = instr->literal();\n+\n+    // These globals will be looked up by name by GpuExecutable so we need to\n+    // give them an external linkage.  Not all of their uses are visible in\n+    // the LLVM IR (e.g. TupleThunk) so we can't give then a linkage that\n+    // merely preserves their names (like available_externally), we also need\n+    // to ensure that they stick around even if they're \"unused\".\n+    //\n+    // We may have to be more clever here in the future if we notice that we're\n+    // keeping around too many globals because of their linkage.\n+    std::string global_name = llvm_ir::ConstantHloToGlobalName(*instr);\n+\n+    auto base = static_cast<const uint8_t*>(literal.untyped_data());\n+    GpuExecutable::ConstantInfo info = AppendGlobalConstant(\n+        module, literal.element_count(),\n+        ShapeUtil::ByteSizeOfPrimitiveType(literal.shape().element_type()),\n+        global_name, /*allocation_idx=*/-1,\n+        DenseDataIntermediate::Alias(\n+            absl::MakeSpan(base, base + literal.size_bytes())));\n+    ir_emitter_context->constants().push_back(std::move(info));\n+  }\n+  return absl::OkStatus();\n+}\n+\n // Nested function serves the same purpose on GPU as a thread-local function on\n // a CPU.\n-absl::StatusOr<llvm::Function*> IrEmitterNested::CodegenNestedComputation() {\n+absl::StatusOr<llvm::Function*> IrEmitter::CodegenNestedComputation(\n+    const HloComputation& nested_computation) {\n   // Include a fingerprint of the HLO in the function name to make the name\n   // unique.\n   tsl::Fprint128 fingerprint = tsl::Fingerprint128(\n-      emitters::GetComputationFingerprint(&nested_computation_, {}));\n+      emitters::GetComputationFingerprint(&nested_computation, {}));\n   std::string function_name = llvm_ir::SanitizeFunctionName(absl::StrCat(\n-      nested_computation_.name(), \"_\", fingerprint.low64, fingerprint.high64));\n+      nested_computation.name(), \"_\", fingerprint.low64, fingerprint.high64));\n \n   auto* function = module_->getFunction(function_name);\n-  if (function) return function;\n+  if (function) {\n+    return function;\n+  }\n \n-  TF_RETURN_IF_ERROR(EmitConstants(nested_computation_));\n+  TF_RETURN_IF_ERROR(EmitConstants(ir_emitter_context_->llvm_module(),\n+                                   ir_emitter_context_, nested_computation));\n   std::vector<const HloInstruction*> io_hlos;\n   std::vector<llvm::Type*> argument_types;\n   std::vector<int64_t> argument_dereferenceable_bytes;\n-  const auto& params = nested_computation_.parameter_instructions();\n+  const auto& params = nested_computation.parameter_instructions();\n   const auto n = params.size() + 1;\n   io_hlos.reserve(n - 1);\n   argument_types.reserve(n);\n@@ -490,7 +475,7 @@ absl::StatusOr<llvm::Function*> IrEmitterNested::CodegenNestedComputation() {\n     argument_dereferenceable_bytes.push_back(param_size);\n   }\n \n-  const HloInstruction* root = nested_computation_.root_instruction();\n+  const HloInstruction* root = nested_computation.root_instruction();\n   {\n     const Shape& root_shape = root->shape();\n     argument_types.push_back(b_.getPtrTy());\n@@ -524,21 +509,21 @@ absl::StatusOr<llvm::Function*> IrEmitterNested::CodegenNestedComputation() {\n \n   std::vector<const HloInstruction*> non_io_hlos;\n   non_io_hlos.push_back(root);\n-  for (const auto* hlo : nested_computation_.instructions()) {\n+  for (const auto* hlo : nested_computation.instructions()) {\n     if (hlo->opcode() != HloOpcode::kParameter &&\n-        hlo != nested_computation_.root_instruction()) {\n+        hlo != nested_computation.root_instruction()) {\n       non_io_hlos.push_back(hlo);\n     }\n   }\n   bindings_.EmitBasePointersForHlos(io_hlos, non_io_hlos);\n \n-  TF_RETURN_IF_ERROR(nested_computation_.root_instruction()->Accept(this));\n+  TF_RETURN_IF_ERROR(nested_computation.root_instruction()->Accept(this));\n   b_.SetInsertPoint(ret_instr);\n \n   // Function epilogue: copy the output value back.\n   {\n     const HloInstruction* root_instruction =\n-        nested_computation_.root_instruction();\n+        nested_computation.root_instruction();\n     llvm::Value* root_value = bindings_.GetBasePointer(*root_instruction);\n     const Shape& return_shape = root_instruction->shape();\n \n@@ -578,7 +563,7 @@ absl::StatusOr<llvm::Function*> IrEmitterNested::CodegenNestedComputation() {\n   return function;\n }\n \n-absl::Status IrEmitterNested::EmitTargetElementLoop(\n+absl::Status IrEmitter::EmitTargetElementLoop(\n     const HloInstruction& hlo,\n     const llvm_ir::ElementGenerator& element_generator) {\n   // For MOF we give the loop emitter an array for every output it should\n@@ -595,35 +580,6 @@ absl::Status IrEmitterNested::EmitTargetElementLoop(\n       .EmitLoop();\n }\n \n-absl::Status IrEmitterNested::EmitConstants(const HloComputation& computation) {\n-  for (HloInstruction* instr : computation.instructions()) {\n-    if (instr->opcode() != HloOpcode::kConstant) {\n-      continue;\n-    }\n-    const Literal& literal = instr->literal();\n-\n-    // These globals will be looked up by name by GpuExecutable so we need to\n-    // give them an external linkage.  Not all of their uses are visible in\n-    // the LLVM IR (e.g. TupleThunk) so we can't give then a linkage that\n-    // merely preserves their names (like available_externally), we also need\n-    // to ensure that they stick around even if they're \"unused\".\n-    //\n-    // We may have to be more clever here in the future if we notice that we're\n-    // keeping around too many globals because of their linkage.\n-    std::string global_name = llvm_ir::ConstantHloToGlobalName(*instr);\n-\n-    auto base = static_cast<const uint8_t*>(literal.untyped_data());\n-    GpuExecutable::ConstantInfo info = AppendGlobalConstant(\n-        module_, literal.element_count(),\n-        ShapeUtil::ByteSizeOfPrimitiveType(literal.shape().element_type()),\n-        global_name, /*allocation_idx=*/-1,\n-        DenseDataIntermediate::Alias(\n-            absl::MakeSpan(base, base + literal.size_bytes())));\n-    ir_emitter_context_->constants().push_back(std::move(info));\n-  }\n-  return absl::OkStatus();\n-}\n-\n struct KernelThunkInfo {\n   std::vector<llvm_ir::IrArray> ir_arrays;\n   std::unique_ptr<Thunk> thunk;"
        },
        {
            "sha": "e001a9f2d18b8a09aa049a380150411813781c06",
            "filename": "third_party/xla/xla/backends/gpu/codegen/llvm/llvm_emitter.h",
            "status": "modified",
            "additions": 4,
            "deletions": 11,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4e47163782271fe3c0661e1b4c20ce195792dcdd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fllvm_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4e47163782271fe3c0661e1b4c20ce195792dcdd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fllvm_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fllvm%2Fllvm_emitter.h?ref=4e47163782271fe3c0661e1b4c20ce195792dcdd",
            "patch": "@@ -16,24 +16,17 @@ limitations under the License.\n #ifndef XLA_BACKENDS_GPU_CODEGEN_LLVM_LLVM_EMITTER_H_\n #define XLA_BACKENDS_GPU_CODEGEN_LLVM_LLVM_EMITTER_H_\n \n-#include <vector>\n+#include <cstdint>\n \n-#include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"llvm/IR/Function.h\"\n-#include \"llvm/IR/IRBuilder.h\"\n #include \"llvm/IR/Value.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n-#include \"xla/hlo/ir/dfs_hlo_visitor_with_default.h\"\n-#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n-#include \"xla/service/gpu/hlo_to_ir_bindings.h\"\n+#include \"xla/service/gpu/gpu_executable.h\"\n+#include \"xla/service/gpu/ir_emission_utils.h\"\n #include \"xla/service/gpu/ir_emitter_context.h\"\n-#include \"xla/service/llvm_ir/fused_ir_emitter.h\"\n-#include \"xla/service/llvm_ir/ir_array.h\"\n-#include \"xla/service/llvm_ir/ir_builder_mixin.h\"\n-#include \"xla/service/llvm_ir/loop_emitter.h\"\n-#include \"xla/shape_util.h\"\n \n namespace xla::gpu {\n "
        }
    ],
    "stats": {
        "total": 261,
        "additions": 104,
        "deletions": 157
    }
}