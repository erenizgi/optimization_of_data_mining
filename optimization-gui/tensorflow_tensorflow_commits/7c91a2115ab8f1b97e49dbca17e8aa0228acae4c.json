{
    "author": "pifon2a",
    "message": "[XLA:GPU] Rename IrEmitterUnnested to ThunkEmitter like in XLA:CPU.\n\nPiperOrigin-RevId: 836957266",
    "sha": "7c91a2115ab8f1b97e49dbca17e8aa0228acae4c",
    "files": [
        {
            "sha": "df0029ffce608a71f4353f52e8ab67c7c3df89d3",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7c91a2115ab8f1b97e49dbca17e8aa0228acae4c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7c91a2115ab8f1b97e49dbca17e8aa0228acae4c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=7c91a2115ab8f1b97e49dbca17e8aa0228acae4c",
            "patch": "@@ -446,9 +446,9 @@ cc_library(\n )\n \n cc_library(\n-    name = \"ir_emitter_unnested\",\n-    srcs = [\"ir_emitter_unnested.cc\"],\n-    hdrs = [\"ir_emitter_unnested.h\"],\n+    name = \"thunk_emitter\",\n+    srcs = [\"thunk_emitter.cc\"],\n+    hdrs = [\"thunk_emitter.h\"],\n     tags = [\"gpu\"],\n     deps = [\n         \":backend_configs_cc\",\n@@ -1523,9 +1523,9 @@ cc_library(\n         \":gpu_executable\",\n         \":gpu_memory_space_assignment\",\n         \":ir_emitter_context\",\n-        \":ir_emitter_unnested\",\n         \":kernel_reuse_cache_proto_cc\",\n         \":metrics\",\n+        \":thunk_emitter\",\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla:util\",\n@@ -1663,14 +1663,14 @@ cc_library(\n         \":ir_emission_utils\",\n         \":ir_emitter\",\n         \":ir_emitter_context\",\n-        \":ir_emitter_unnested\",\n         \":kernel_reuse_cache\",\n         \":legacy_gpu_aot_compilation_result\",\n         \":matmul_utils\",\n         \":metrics\",\n         \":pre_scheduling_copy_insertion_pipeline\",\n         \":reduction_utils\",\n         \":stream_executor_util\",\n+        \":thunk_emitter\",\n         \"//xla:autotune_results_proto_cc\",\n         \"//xla:debug_options_flags\",\n         \"//xla:shape_util\","
        },
        {
            "sha": "0e19ca1bb3bbb2d72efcb48c08bd0d4c59faa3cd",
            "filename": "third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7c91a2115ab8f1b97e49dbca17e8aa0228acae4c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7c91a2115ab8f1b97e49dbca17e8aa0228acae4c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.cc?ref=7c91a2115ab8f1b97e49dbca17e8aa0228acae4c",
            "patch": "@@ -59,8 +59,8 @@ limitations under the License.\n #include \"xla/service/gpu/gpu_executable.h\"\n #include \"xla/service/gpu/gpu_memory_space_assignment.h\"\n #include \"xla/service/gpu/ir_emitter_context.h\"\n-#include \"xla/service/gpu/ir_emitter_unnested.h\"\n #include \"xla/service/gpu/metrics.h\"\n+#include \"xla/service/gpu/thunk_emitter.h\"\n #include \"xla/service/logical_buffer.h\"\n #include \"xla/shape.h\"\n #include \"xla/status_macros.h\"\n@@ -190,13 +190,13 @@ absl::StatusOr<std::unique_ptr<SequentialThunk>> LowerHlo(\n     TF_RETURN_IF_ERROR(\n         LoadCache(ir_emitter_context, options.xla_gpu_kernel_cache_file()));\n   }\n-  std::unique_ptr<IrEmitterUnnested> ir_emitter =\n-      IrEmitterUnnested::Create(&ir_emitter_context);\n+  std::unique_ptr<ThunkEmitter> thunk_emitter =\n+      ThunkEmitter::Create(&ir_emitter_context);\n   {\n     XLA_SCOPED_LOGGING_TIMER(absl::StrCat(\n         \"GpuCompiler::RunBackend - IR emission for \", hlo_module->name()));\n \n-    TF_RETURN_IF_ERROR(ir_emitter->EmitHloEntryComputation(hlo_module));\n+    TF_RETURN_IF_ERROR(thunk_emitter->EmitHloEntryComputation(hlo_module));\n \n     RemoveUnusedAndUninitializedGlobals(\n         platform_id, options, ir_emitter_context.llvm_module_constants(),\n@@ -207,7 +207,7 @@ absl::StatusOr<std::unique_ptr<SequentialThunk>> LowerHlo(\n     uint64_t end_usecs = tsl::Env::Default()->NowMicros();\n     RecordHloToLlvmDuration(end_usecs - start_usecs);\n   }\n-  return ir_emitter->ConsumeThunkSequence();\n+  return thunk_emitter->ConsumeThunkSequence();\n }\n \n }  // namespace"
        },
        {
            "sha": "a8888161ca4b1ec5e39463161feca7c6e3cc085b",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7c91a2115ab8f1b97e49dbca17e8aa0228acae4c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7c91a2115ab8f1b97e49dbca17e8aa0228acae4c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=7c91a2115ab8f1b97e49dbca17e8aa0228acae4c",
            "patch": "@@ -188,7 +188,6 @@ limitations under the License.\n #include \"xla/service/gpu/hlo_fusion_stats.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n #include \"xla/service/gpu/ir_emitter_context.h\"\n-#include \"xla/service/gpu/ir_emitter_unnested.h\"\n #include \"xla/service/gpu/kernel_reuse_cache.h\"\n #include \"xla/service/gpu/legacy_gpu_aot_compilation_result.h\"\n #include \"xla/service/gpu/matmul_utils.h\"\n@@ -201,6 +200,7 @@ limitations under the License.\n #include \"xla/service/gpu/pre_scheduling_copy_insertion_pipeline.h\"\n #include \"xla/service/gpu/reduction_utils.h\"\n #include \"xla/service/gpu/stream_executor_util.h\"\n+#include \"xla/service/gpu/thunk_emitter.h\"\n #include \"xla/service/gpu/transforms/add_tracking_suffix_to_instruction_names.h\"\n #include \"xla/service/gpu/transforms/algebraic_simplifier.h\"\n #include \"xla/service/gpu/transforms/algorithm_checker.h\"\n@@ -3041,7 +3041,7 @@ GpuCompiler::LoadExecutableFromAotResult(\n     TF_RETURN_IF_ERROR(LoadCache(ir_emitter_context, cache_file_path));\n   }\n \n-  auto ir_emitter = IrEmitterUnnested::Create(&ir_emitter_context);\n+  auto ir_emitter = ThunkEmitter::Create(&ir_emitter_context);\n   TF_RETURN_IF_ERROR(ir_emitter->EmitHloEntryComputation(hlo_module.get()));\n \n   // Get all other fields required by GpuExecutable."
        },
        {
            "sha": "393f705a4e3b38aaf8111dea709c24e7ea6e5296",
            "filename": "third_party/xla/xla/service/gpu/thunk_emitter.cc",
            "status": "renamed",
            "additions": 72,
            "deletions": 81,
            "changes": 153,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7c91a2115ab8f1b97e49dbca17e8aa0228acae4c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7c91a2115ab8f1b97e49dbca17e8aa0228acae4c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc?ref=7c91a2115ab8f1b97e49dbca17e8aa0228acae4c",
            "patch": "@@ -13,7 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include \"xla/service/gpu/ir_emitter_unnested.h\"\n+#include \"xla/service/gpu/thunk_emitter.h\"\n \n #include <algorithm>\n #include <cassert>\n@@ -211,7 +211,7 @@ static constexpr bool kRequiresCollectiveKernelThunk =\n \n // The signature of this function would change to absl::Status once we lift the\n // CollectiveKernelThunk out as a top level thunk. It would then become a member\n-// function of IrEmitterUnnested.\n+// function of ThunkEmitter.\n // As it stands now the collective kernel thunk is wrapped inside other\n // collective thunks such as AllReduceStart. So this function is only\n // responsible for emitting the collective kernel thunk and its dependencies.\n@@ -246,21 +246,19 @@ std::unique_ptr<llvm::Module> CreateLocalLLVMModule(\n \n }  // namespace\n \n-IrEmitterUnnested::IrEmitterUnnested(IrEmitterContext* ir_emitter_context)\n+ThunkEmitter::ThunkEmitter(IrEmitterContext* ir_emitter_context)\n     : IrEmitter(ir_emitter_context, /*is_nested=*/false),\n       send_recv_events_(std::make_shared<HostSendRecvAsyncEvents>()),\n       copy_events_(std::make_shared<CopyThunk::AsyncEvents>()),\n       nvshmem_buffer_addresses_(std::make_shared<NvshmemBufferAddresses>()),\n       call_graph_(CallGraph::Build(&ir_emitter_context->hlo_module())) {}\n \n-std::unique_ptr<IrEmitterUnnested> IrEmitterUnnested::Create(\n+std::unique_ptr<ThunkEmitter> ThunkEmitter::Create(\n     IrEmitterContext* ir_emitter_context) {\n-  return std::unique_ptr<IrEmitterUnnested>(\n-      new IrEmitterUnnested(ir_emitter_context));\n+  return std::unique_ptr<ThunkEmitter>(new ThunkEmitter(ir_emitter_context));\n }\n \n-absl::Status IrEmitterUnnested::EmitConstant(\n-    const HloConstantInstruction* instr) {\n+absl::Status ThunkEmitter::EmitConstant(const HloConstantInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(DenseDataIntermediate content,\n                       LiteralToXlaFormat(instr->literal()));\n \n@@ -281,12 +279,12 @@ absl::Status IrEmitterUnnested::EmitConstant(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitConditional(const HloInstruction* instr) {\n+absl::Status ThunkEmitter::EmitConditional(const HloInstruction* instr) {\n   std::vector<std::unique_ptr<SequentialThunk>> branch_thunks;\n   branch_thunks.reserve(instr->branch_count());\n \n   for (auto comp : instr->branch_computations()) {\n-    auto ir_emitter = IrEmitterUnnested::Create(ir_emitter_context_);\n+    auto ir_emitter = ThunkEmitter::Create(ir_emitter_context_);\n     TF_RETURN_IF_ERROR(ir_emitter->EmitHloComputation(comp));\n     Thunk::ThunkInfo branch_thunk_info =\n         Thunk::ThunkInfo::WithProfileAnnotation(\n@@ -307,9 +305,9 @@ absl::Status IrEmitterUnnested::EmitConditional(const HloInstruction* instr) {\n   return absl::OkStatus();\n }\n \n-llvm::Value* IrEmitterUnnested::CreateLoad(llvm::Value* address,\n-                                           llvm::Type* data_type,\n-                                           int alignment_bytes) {\n+llvm::Value* ThunkEmitter::CreateLoad(llvm::Value* address,\n+                                      llvm::Type* data_type,\n+                                      int alignment_bytes) {\n   int data_bytes = data_type->getPrimitiveSizeInBits() /\n                    primitive_util::BitWidth(PrimitiveType::U8);\n   if (alignment_bytes == 0) {\n@@ -336,8 +334,8 @@ llvm::Value* IrEmitterUnnested::CreateLoad(llvm::Value* address,\n   return output;\n }\n \n-void IrEmitterUnnested::CreateStore(llvm::Value* data, llvm::Value* address,\n-                                    int alignment_bytes) {\n+void ThunkEmitter::CreateStore(llvm::Value* data, llvm::Value* address,\n+                               int alignment_bytes) {\n   int data_bytes = data->getType()->getPrimitiveSizeInBits() /\n                    primitive_util::BitWidth(PrimitiveType::U8);\n   CHECK_GE(data_bytes, alignment_bytes);\n@@ -363,7 +361,7 @@ void IrEmitterUnnested::CreateStore(llvm::Value* data, llvm::Value* address,\n \n // Input = {dynamic array(with dynamic dimension meta data at the\n // end)} Output = {static array, dynamic_dim0, dynamic_dim1}\n-absl::Status IrEmitterUnnested::EmitPadToStatic(\n+absl::Status ThunkEmitter::EmitPadToStatic(\n     const HloCustomCallInstruction* instr) {\n   std::string ir_name = std::string(instr->name());\n   auto local_llvm_module =\n@@ -498,7 +496,7 @@ absl::Status IrEmitterUnnested::EmitPadToStatic(\n \n // Input = {dynamic array(with dynamic dimension meta data at the\n // end)} Output = {static array, dynamic_dim0, dynamic_dim1}\n-absl::Status IrEmitterUnnested::EmitSliceToDynamic(\n+absl::Status ThunkEmitter::EmitSliceToDynamic(\n     const HloCustomCallInstruction* instr) {\n   std::string ir_name = std::string(instr->name());\n   auto local_llvm_module =\n@@ -623,16 +621,15 @@ absl::Status IrEmitterUnnested::EmitSliceToDynamic(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitCommandBufferThunk(\n-    const HloInstruction* instr) {\n-  // Spawn a new IrEmitterUnnested to emit thunks for the command\n+absl::Status ThunkEmitter::EmitCommandBufferThunk(const HloInstruction* instr) {\n+  // Spawn a new ThunkEmitter to emit thunks for the command\n   // buffer computation. Then convert emitted thunks to a sequence\n   // of CommandBufferCmd. The resulting thunk added to the thunk\n   // sequence is a CommandBufferThunk. Thunks emitted from the\n   // command buffer computation are discarded.\n   DCHECK_EQ(instr->called_computations().size(), 1);\n   const HloComputation* command_buffer = instr->called_computations().front();\n-  auto ir_emitter = IrEmitterUnnested::Create(ir_emitter_context_);\n+  auto ir_emitter = ThunkEmitter::Create(ir_emitter_context_);\n   TF_RETURN_IF_ERROR(ir_emitter->EmitHloComputation(command_buffer));\n   std::unique_ptr<SequentialThunk> thunk_sequence =\n       ir_emitter->ConsumeThunkSequence();\n@@ -680,7 +677,7 @@ absl::Status IrEmitterUnnested::EmitCommandBufferThunk(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitConvolutionThunk(\n+absl::Status ThunkEmitter::EmitConvolutionThunk(\n     const HloCustomCallInstruction* instr) {\n   std::vector<BufferAllocation::Slice> operand_slices;\n   operand_slices.reserve(instr->operand_count());\n@@ -728,7 +725,7 @@ absl::Status IrEmitterUnnested::EmitConvolutionThunk(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitGemmThunk(\n+absl::Status ThunkEmitter::EmitGemmThunk(\n     const HloCustomCallInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(BufferAllocation::Slice a,\n                       GetAllocationSliceForHlo(instr->operand(0), {}));\n@@ -762,7 +759,7 @@ absl::Status IrEmitterUnnested::EmitGemmThunk(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitCublasLtMatmulThunk(\n+absl::Status ThunkEmitter::EmitCublasLtMatmulThunk(\n     const HloCustomCallInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(const auto gpu_config,\n                       instr->backend_config<xla::gpu::GpuBackendConfig>());\n@@ -844,7 +841,7 @@ absl::Status IrEmitterUnnested::EmitCublasLtMatmulThunk(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitCublasLtMatmulThunkF8(\n+absl::Status ThunkEmitter::EmitCublasLtMatmulThunkF8(\n     const HloCustomCallInstruction* instr) {\n   TF_RET_CHECK(instr->operand_count() > 3 && instr->operand_count() < 8);\n   TF_ASSIGN_OR_RETURN(const auto gpu_config,\n@@ -940,7 +937,7 @@ absl::Status IrEmitterUnnested::EmitCublasLtMatmulThunkF8(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitConvolutionReorderThunk(\n+absl::Status ThunkEmitter::EmitConvolutionReorderThunk(\n     const HloCustomCallInstruction* instr) {\n   bool has_bias = instr->operand_count() > 1;\n   Shape shape = has_bias ? instr->shape().tuple_shapes(0) : instr->shape();\n@@ -979,7 +976,7 @@ absl::Status IrEmitterUnnested::EmitConvolutionReorderThunk(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitNormThunk(\n+absl::Status ThunkEmitter::EmitNormThunk(\n     const HloCustomCallInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(auto const gpu_backend_config,\n                       instr->backend_config<xla::gpu::GpuBackendConfig>());\n@@ -1060,7 +1057,7 @@ absl::Status IrEmitterUnnested::EmitNormThunk(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitCuDnnThunk(\n+absl::Status ThunkEmitter::EmitCuDnnThunk(\n     const HloCustomCallInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(auto kernel_arguments,\n                       emitters::KernelArguments::Create(\n@@ -1084,22 +1081,21 @@ absl::Status IrEmitterUnnested::EmitCuDnnThunk(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitPtxCustomCall(\n+absl::Status ThunkEmitter::EmitPtxCustomCall(\n     const HloCustomCallInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(auto thunk,\n                       EmitPtxCustomKernelThunk(instr, ir_emitter_context_));\n   AddThunkToThunkSequence(std::move(thunk));\n   return absl::OkStatus();\n }\n \n-absl::StatusOr<BufferAllocation::Slice>\n-IrEmitterUnnested::GetAllocationSliceForHlo(const HloInstruction* instr,\n-                                            const ShapeIndex& index) const {\n+absl::StatusOr<BufferAllocation::Slice> ThunkEmitter::GetAllocationSliceForHlo(\n+    const HloInstruction* instr, const ShapeIndex& index) const {\n   return xla::gpu::GetAllocationSlice(ir_emitter_context_->buffer_assignment(),\n                                       instr, index);\n }\n \n-absl::Status IrEmitterUnnested::EmitCubDeviceRadixSort(\n+absl::Status ThunkEmitter::EmitCubDeviceRadixSort(\n     const HloCustomCallInstruction* instr) {\n   if (instr->operand_count() != 1 && instr->operand_count() != 2) {\n     return Internal(\"Invalid number of operands for radix sort\");\n@@ -1147,7 +1143,7 @@ absl::Status IrEmitterUnnested::EmitCubDeviceRadixSort(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitCustomCallThunk(\n+absl::Status ThunkEmitter::EmitCustomCallThunk(\n     const HloCustomCallInstruction* instr) {\n   const std::string& call_target_name = instr->custom_call_target();\n \n@@ -1262,7 +1258,7 @@ absl::Status IrEmitterUnnested::EmitCustomCallThunk(\n   return custom_call_thunk.status();\n }\n \n-absl::Status IrEmitterUnnested::EmitFftThunk(const HloFftInstruction* instr) {\n+absl::Status ThunkEmitter::EmitFftThunk(const HloFftInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(BufferAllocation::Slice arg_slice,\n                       GetAllocationSliceForHlo(instr->operand(0)));\n   TF_ASSIGN_OR_RETURN(BufferAllocation::Slice dest_slice,\n@@ -1278,7 +1274,7 @@ absl::Status IrEmitterUnnested::EmitFftThunk(const HloFftInstruction* instr) {\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitTriangularSolveCustomCall(\n+absl::Status ThunkEmitter::EmitTriangularSolveCustomCall(\n     const HloInstruction* instr) {\n   TF_RET_CHECK(instr->operand_count() == 2);\n   auto operands = instr->operands();\n@@ -1360,7 +1356,7 @@ absl::Status IrEmitterUnnested::EmitTriangularSolveCustomCall(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitTopKCustomCall(\n+absl::Status ThunkEmitter::EmitTopKCustomCall(\n     const HloCustomCallInstruction* instr) {\n   auto operands = instr->operands();\n   const auto& shape = instr->shape();\n@@ -1442,7 +1438,7 @@ absl::Status IrEmitterUnnested::EmitTopKCustomCall(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitTritonCustomCall(\n+absl::Status ThunkEmitter::EmitTritonCustomCall(\n     const HloCustomCallInstruction* instr) {\n   auto generate = [this, &instr]() -> absl::StatusOr<KernelReuseCache::Entry> {\n     mlir::MLIRContext& mlir_context = *ir_emitter_context_->mlir_context();\n@@ -1532,16 +1528,15 @@ absl::Status IrEmitterUnnested::EmitTritonCustomCall(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitAsyncComputation(\n-    const HloInstruction* instr) {\n+absl::Status ThunkEmitter::EmitAsyncComputation(const HloInstruction* instr) {\n   const HloInstruction* wrapped = instr->async_wrapped_instruction();\n   const ExecutionStreamAssignment& stream_assignment =\n       ir_emitter_context_->execution_stream_assignment();\n   TF_ASSIGN_OR_RETURN(auto stream,\n                       stream_assignment.GetSyncExecutionStreamId(wrapped));\n   TF_RET_CHECK(wrapped->called_computations().size() == 1);\n   auto computation = wrapped->called_computations().front();\n-  auto ir_emitter = IrEmitterUnnested::Create(ir_emitter_context_);\n+  auto ir_emitter = ThunkEmitter::Create(ir_emitter_context_);\n   TF_RETURN_IF_ERROR(ir_emitter->EmitHloComputation(computation));\n   std::unique_ptr<SequentialThunk> thunk_sequence =\n       ir_emitter->ConsumeThunkSequence();\n@@ -1565,12 +1560,12 @@ absl::Status IrEmitterUnnested::EmitAsyncComputation(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitFusion(const HloFusionInstruction* instr) {\n+absl::Status ThunkEmitter::EmitFusion(const HloFusionInstruction* instr) {\n   const se::DeviceDescription& device_info =\n       ir_emitter_context_->gpu_device_info();\n   const HloFusionAnalysis fusion_analysis =\n       HloFusionAnalysis::Create(*instr, device_info);\n-  VLOG(3) << \"IrEmitterUnnested::EmitFusion:start\";\n+  VLOG(3) << \"ThunkEmitter::EmitFusion:start\";\n   std::unique_ptr<FusionInterface> emitter = GetFusionEmitter(\n       /*fusion_info=*/HloFusionInfo(\n           /*analysis=*/fusion_analysis, instr,\n@@ -1595,11 +1590,11 @@ absl::Status IrEmitterUnnested::EmitFusion(const HloFusionInstruction* instr) {\n     thunk->set_execution_stream_id(execution_stream_id);\n     AddThunkToThunkSequence(std::move(thunk));\n   }\n-  VLOG(3) << \"IrEmitterUnnested::EmitFusion:complete\";\n+  VLOG(3) << \"ThunkEmitter::EmitFusion:complete\";\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitCopy(const HloInstruction* instr) {\n+absl::Status ThunkEmitter::EmitCopy(const HloInstruction* instr) {\n   TF_RET_CHECK(LayoutUtil::LayoutsInShapesEqual(\n       instr->operand(0)->shape(), instr->shape(),\n       Layout::Equal().MinorToMajorOnly()));\n@@ -1616,7 +1611,7 @@ absl::Status IrEmitterUnnested::EmitCopy(const HloInstruction* instr) {\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitAsyncCustomCallStart(\n+absl::Status ThunkEmitter::EmitAsyncCustomCallStart(\n     const HloInstruction* instr) {\n   const HloInstruction* wrapped = instr->async_wrapped_instruction();\n   auto* async_start = Cast<HloAsyncInstruction>(instr);\n@@ -1658,7 +1653,7 @@ absl::Status IrEmitterUnnested::EmitAsyncCustomCallStart(\n                   HloOpcodeString(wrapped->opcode()));\n }\n \n-absl::Status IrEmitterUnnested::AssertNonDeterminismIsOkay(\n+absl::Status ThunkEmitter::AssertNonDeterminismIsOkay(\n     const std::string& op_name) {\n   if (RequireDeterminism(ir_emitter_context_->hlo_module().config())) {\n     return Unimplemented(\n@@ -1670,7 +1665,7 @@ absl::Status IrEmitterUnnested::AssertNonDeterminismIsOkay(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitWhile(const HloInstruction* instr) {\n+absl::Status ThunkEmitter::EmitWhile(const HloInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(auto config,\n                       instr->backend_config<xla::WhileLoopBackendConfig>());\n \n@@ -1690,7 +1685,7 @@ absl::Status IrEmitterUnnested::EmitWhile(const HloInstruction* instr) {\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitRngGetAndUpdateState(\n+absl::Status ThunkEmitter::EmitRngGetAndUpdateState(\n     const HloRngGetAndUpdateStateInstruction* instr) {\n   // Emit a kernel to increment the global state for Philox RNG\n   // algorithm.\n@@ -1707,7 +1702,7 @@ absl::Status IrEmitterUnnested::EmitRngGetAndUpdateState(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitSort(const HloSortInstruction* sort) {\n+absl::Status ThunkEmitter::EmitSort(const HloSortInstruction* sort) {\n   std::string op_name(sort->name());\n   const Shape& keys_shape = sort->operand(0)->shape();\n   int64_t dimension_to_sort = sort->sort_dimension();\n@@ -1905,7 +1900,7 @@ absl::Status IrEmitterUnnested::EmitSort(const HloSortInstruction* sort) {\n }\n \n template <typename ThunkType>\n-absl::Status IrEmitterUnnested::EmitReplicaOrPartitionId(\n+absl::Status ThunkEmitter::EmitReplicaOrPartitionId(\n     const HloInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(BufferAllocation::Slice result_slice,\n                       GetAllocationSliceForHlo(instr, {}));\n@@ -1927,8 +1922,7 @@ bool IsNvshmemCollective(const HloInstruction* instr) {\n   return false;\n }\n \n-absl::Status IrEmitterUnnested::EmitCollectiveMetadata(\n-    const HloInstruction* instr) {\n+absl::Status ThunkEmitter::EmitCollectiveMetadata(const HloInstruction* instr) {\n   std::vector<CollectiveMetadataThunk::Buffer> buffers;\n   buffers.reserve(instr->operands().size());\n   for (const HloInstruction* operand : instr->operands()) {\n@@ -1952,7 +1946,7 @@ absl::Status IrEmitterUnnested::EmitCollectiveMetadata(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitCollectivePermute(\n+absl::Status ThunkEmitter::EmitCollectivePermute(\n     const HloCollectivePermuteInstruction* instr) {\n   // First output is aliased.\n   TF_RET_CHECK(\n@@ -2035,7 +2029,7 @@ absl::Status IrEmitterUnnested::EmitCollectivePermute(\n }\n \n template <typename CollectiveThunkType, typename HloInstType>\n-absl::Status IrEmitterUnnested::EmitCollectiveThunk(\n+absl::Status ThunkEmitter::EmitCollectiveThunk(\n     Thunk::Kind kind, const HloInstruction* async_start,\n     const HloInstType* inst, std::optional<bool> use_global_device_ids) {\n   const auto& hlo_config = ir_emitter_context_->hlo_module().config();\n@@ -2343,7 +2337,7 @@ std::vector<const HloInstruction*> GetRealDependencyInstructions(\n   }\n }\n \n-absl::Status IrEmitterUnnested::EmitCollectiveGroupStartThunk(\n+absl::Status ThunkEmitter::EmitCollectiveGroupStartThunk(\n     const HloInstruction* instr) {\n   emit_group_thunks_ = true;\n   std::optional<AsyncStreamKind> stream_kind;\n@@ -2370,8 +2364,8 @@ absl::Status IrEmitterUnnested::EmitCollectiveGroupStartThunk(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitCollectiveAsyncDone(\n-    Thunk::Kind kind, const HloInstruction* inst) {\n+absl::Status ThunkEmitter::EmitCollectiveAsyncDone(Thunk::Kind kind,\n+                                                   const HloInstruction* inst) {\n   // Partial pipelining is only implemented for send/recv.\n   bool is_send_recv =\n       kind == Thunk::Kind::kRecvDone || kind == Thunk::Kind::kSendDone;\n@@ -2404,8 +2398,8 @@ absl::Status IrEmitterUnnested::EmitCollectiveAsyncDone(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitNvshmemAsyncDone(\n-    Thunk::Kind kind, const HloInstruction* inst) {\n+absl::Status ThunkEmitter::EmitNvshmemAsyncDone(Thunk::Kind kind,\n+                                                const HloInstruction* inst) {\n   bool is_send_recv = kind == Thunk::Kind::kNvshmemRecvDone ||\n                       kind == Thunk::Kind::kNvshmemSendDone;\n   const HloInstruction* start =\n@@ -2445,7 +2439,7 @@ absl::Status IrEmitterUnnested::EmitNvshmemAsyncDone(\n }\n \n template <typename NvshmemAllReduceThunkType, typename HloAllReduceInstruction>\n-absl::Status IrEmitterUnnested::EmitNvshmemThunk(\n+absl::Status ThunkEmitter::EmitNvshmemThunk(\n     Thunk::Kind kind, const HloInstruction* async_start,\n     const HloAllReduceInstruction* inst,\n     std::optional<bool> use_global_device_ids) {\n@@ -2522,7 +2516,7 @@ absl::Status IrEmitterUnnested::EmitNvshmemThunk(\n }\n \n template <typename HloInstType>\n-absl::Status IrEmitterUnnested::EmitDegeneratedCollectiveThunk(\n+absl::Status ThunkEmitter::EmitDegeneratedCollectiveThunk(\n     std::vector<CollectiveThunk::Buffer>& buffers,\n     const HloInstruction* async_start, const HloInstType* inst) {\n   // Signal that start thunk not created with nullptr.\n@@ -2551,7 +2545,7 @@ absl::Status IrEmitterUnnested::EmitDegeneratedCollectiveThunk(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitInfeed(const HloInfeedInstruction* instr) {\n+absl::Status ThunkEmitter::EmitInfeed(const HloInfeedInstruction* instr) {\n   // Infeed instruction returns a tuple containing the result data\n   // and a token. We only need the result data to construct the\n   // infeed thunk.\n@@ -2579,8 +2573,7 @@ absl::Status IrEmitterUnnested::EmitInfeed(const HloInfeedInstruction* instr) {\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitOutfeed(\n-    const HloOutfeedInstruction* instr) {\n+absl::Status ThunkEmitter::EmitOutfeed(const HloOutfeedInstruction* instr) {\n   // HLO outfeed instruction has 2 operands, the source and a token,\n   // and a single token output.\n   const HloInstruction* source = instr->operand(0);\n@@ -2609,7 +2602,7 @@ absl::Status IrEmitterUnnested::EmitOutfeed(\n }\n \n absl::StatusOr<std::vector<llvm_ir::IrArray>>\n-IrEmitterUnnested::BuildKernelThunkForNonFusionOp(\n+ThunkEmitter::BuildKernelThunkForNonFusionOp(\n     llvm::Module* llvm_module, const HloInstruction* instr,\n     const LaunchDimensions& launch_dimensions) {\n   std::string suggested_kernel_name(instr->name());\n@@ -2655,18 +2648,18 @@ IrEmitterUnnested::BuildKernelThunkForNonFusionOp(\n   return ir_arrays;\n }\n \n-absl::StatusOr<std::unique_ptr<Thunk>> IrEmitterUnnested::BuildWhileThunk(\n+absl::StatusOr<std::unique_ptr<Thunk>> ThunkEmitter::BuildWhileThunk(\n     const HloInstruction* instr, const Thunk::ThunkInfo& thunk_info,\n     std::optional<int64_t> trip_count) {\n   HloComputation* condition = instr->while_condition();\n   HloComputation* body = instr->while_body();\n \n   // Generate thunk sequence for while 'condition'.\n-  auto ir_emitter_condition = IrEmitterUnnested::Create(ir_emitter_context_);\n+  auto ir_emitter_condition = ThunkEmitter::Create(ir_emitter_context_);\n   TF_RETURN_IF_ERROR(ir_emitter_condition->EmitHloComputation(condition));\n \n   // Generate thunk sequence for while 'body'.\n-  auto ir_emitter_body = IrEmitterUnnested::Create(ir_emitter_context_);\n+  auto ir_emitter_body = ThunkEmitter::Create(ir_emitter_context_);\n   TF_RETURN_IF_ERROR(ir_emitter_body->EmitHloComputation(body));\n \n   // Buffer slice holding while loop predicate.\n@@ -2686,7 +2679,7 @@ absl::StatusOr<std::unique_ptr<Thunk>> IrEmitterUnnested::BuildWhileThunk(\n       ir_emitter_body->ConsumeThunkSequence(body_thunk_info), trip_count));\n }\n \n-absl::Status IrEmitterUnnested::EmitTargetElementLoop(\n+absl::Status ThunkEmitter::EmitTargetElementLoop(\n     const HloInstruction& hlo, const llvm_ir::ElementGenerator& body_emitter) {\n   return Internal(\"This should be unreachable\");\n }\n@@ -2714,7 +2707,7 @@ absl::StatusOr<bool> ShapeHasHostMemorySpace(Shape shape, int index,\n          shape.tuple_shapes(index).layout().memory_space() == host_memory_space;\n }\n \n-absl::Status IrEmitterUnnested::EmitCopyStartThunk(\n+absl::Status ThunkEmitter::EmitCopyStartThunk(\n     const HloCopyStartInstruction* copy_start_instr) {\n   // copy-start has a tuple shape: {host, device, context},\n   // or {device, host, context}.\n@@ -2782,7 +2775,7 @@ absl::Status IrEmitterUnnested::EmitCopyStartThunk(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitCopyDoneThunk(const HloInstruction* instr) {\n+absl::Status ThunkEmitter::EmitCopyDoneThunk(const HloInstruction* instr) {\n   const HloInstruction* copy_start_instr = instr->operand(0);\n   CHECK(copy_start_instr->opcode() == HloOpcode::kCopyStart);\n \n@@ -2796,7 +2789,7 @@ absl::Status IrEmitterUnnested::EmitCopyDoneThunk(const HloInstruction* instr) {\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitSendThunk(const HloSendInstruction* instr) {\n+absl::Status ThunkEmitter::EmitSendThunk(const HloSendInstruction* instr) {\n   const HloInstruction* src = instr->operand(0);\n   TF_ASSIGN_OR_RETURN(BufferAllocation::Slice slice,\n                       GetAllocationSliceForHlo(src, {}));\n@@ -2876,7 +2869,7 @@ absl::Status IrEmitterUnnested::EmitSendThunk(const HloSendInstruction* instr) {\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitSendDoneThunk(\n+absl::Status ThunkEmitter::EmitSendDoneThunk(\n     const HloSendDoneInstruction* instr) {\n   if (!instr->is_host_transfer()) {\n     if (IsNvshmemCollective(instr)) {\n@@ -2898,7 +2891,7 @@ absl::Status IrEmitterUnnested::EmitSendDoneThunk(\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitRecvThunk(const HloRecvInstruction* instr) {\n+absl::Status ThunkEmitter::EmitRecvThunk(const HloRecvInstruction* instr) {\n   TF_RET_CHECK(instr->shape().IsTuple());\n   TF_ASSIGN_OR_RETURN(BufferAllocation::Slice slice,\n                       GetAllocationSliceForHlo(instr, {0}));\n@@ -2980,7 +2973,7 @@ absl::Status IrEmitterUnnested::EmitRecvThunk(const HloRecvInstruction* instr) {\n   return absl::OkStatus();\n }\n \n-absl::Status IrEmitterUnnested::EmitRecvDoneThunk(\n+absl::Status ThunkEmitter::EmitRecvDoneThunk(\n     const HloRecvDoneInstruction* instr) {\n   if (!instr->is_host_transfer()) {\n     if (IsNvshmemCollective(instr)) {\n@@ -3014,8 +3007,7 @@ std::optional<const HloInstruction*> GetCollectiveHeroForDynamicSliceFusion(\n       [](const HloInstruction* instr) { return IsCollective(instr); });\n }\n \n-absl::Status IrEmitterUnnested::EmitHloInstruction(\n-    const HloInstruction* instr) {\n+absl::Status ThunkEmitter::EmitHloInstruction(const HloInstruction* instr) {\n   switch (instr->opcode()) {\n     case HloOpcode::kAllGatherDone:\n       return EmitCollectiveAsyncDone(Thunk::kAllGatherDone, instr);\n@@ -3382,12 +3374,11 @@ absl::Status IrEmitterUnnested::EmitHloInstruction(\n   return Internal(\"Unhandled HLO instruction\");\n }\n \n-absl::Status IrEmitterUnnested::EmitHloEntryComputation(\n-    const HloModule* module) {\n+absl::Status ThunkEmitter::EmitHloEntryComputation(const HloModule* module) {\n   return EmitHloComputation(module->entry_computation());\n }\n \n-absl::Status IrEmitterUnnested::EmitHloComputation(\n+absl::Status ThunkEmitter::EmitHloComputation(\n     const HloComputation* computation) {\n   const HloSchedule& schedule = computation->parent()->schedule();\n   if (!schedule.is_computation_scheduled(computation)) {",
            "previous_filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.cc"
        },
        {
            "sha": "ed1efd93d19b9b6339ff711c388af49b0b88b160",
            "filename": "third_party/xla/xla/service/gpu/thunk_emitter.h",
            "status": "renamed",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7c91a2115ab8f1b97e49dbca17e8aa0228acae4c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7c91a2115ab8f1b97e49dbca17e8aa0228acae4c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.h?ref=7c91a2115ab8f1b97e49dbca17e8aa0228acae4c",
            "patch": "@@ -13,8 +13,8 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#ifndef XLA_SERVICE_GPU_IR_EMITTER_UNNESTED_H_\n-#define XLA_SERVICE_GPU_IR_EMITTER_UNNESTED_H_\n+#ifndef XLA_SERVICE_GPU_THUNK_EMITTER_H_\n+#define XLA_SERVICE_GPU_THUNK_EMITTER_H_\n \n #include <array>\n #include <cstdint>\n@@ -63,16 +63,16 @@ namespace gpu {\n //  - The true/false computation of an HLO conditional.\n //\n // Note the opportunity for confusion -- the while loop's computation is nested\n-// within the root computation, but it's emitted using IrEmitterUnnested!  Don't\n+// within the root computation, but it's emitted using ThunkEmitter!  Don't\n // think about it too hard.\n //\n // Examples of things that are not unnested computations:\n //\n-//  - The body of a fusion node.  IrEmitterUnnested emits the relevant code\n+//  - The body of a fusion node.  ThunkEmitter emits the relevant code\n //    within a kernel function using FusedIrEmitter.  (FusedIrEmitter is not\n //    really an IrEmitter, but is more an \"IR generator generator\".)\n //\n-class IrEmitterUnnested : public IrEmitter {\n+class ThunkEmitter : public IrEmitter {\n  public:\n   absl::string_view platform_name() const {\n     return ir_emitter_context_->platform_name();\n@@ -83,10 +83,10 @@ class IrEmitterUnnested : public IrEmitter {\n \n   using ConstantGenerator = std::function<llvm::Value*(int64_t)>;\n \n-  IrEmitterUnnested(const IrEmitterUnnested&) = delete;\n-  IrEmitterUnnested& operator=(const IrEmitterUnnested&) = delete;\n+  ThunkEmitter(const ThunkEmitter&) = delete;\n+  ThunkEmitter& operator=(const ThunkEmitter&) = delete;\n \n-  static std::unique_ptr<IrEmitterUnnested> Create(\n+  static std::unique_ptr<ThunkEmitter> Create(\n       IrEmitterContext* ir_emitter_context);\n \n   // Transfers the ownership of thunk_sequence_ out.\n@@ -99,7 +99,7 @@ class IrEmitterUnnested : public IrEmitter {\n   absl::Status EmitHloEntryComputation(const HloModule* module);\n \n  private:\n-  explicit IrEmitterUnnested(IrEmitterContext* ir_emitter_context);\n+  explicit ThunkEmitter(IrEmitterContext* ir_emitter_context);\n \n   // Emits code for the given HLO computation.\n   //\n@@ -112,7 +112,7 @@ class IrEmitterUnnested : public IrEmitter {\n \n   absl::Status EmitCommandBufferThunk(const HloInstruction* instr);\n \n-  // IrEmitterUnnested handles the following instructions differently from\n+  // ThunkEmitter handles the following instructions differently from\n   // IrEmitter. It also mixes in some special handling for custom kernels\n   // via the ThunkEmitter.\n   absl::Status EmitConstant(const HloConstantInstruction* instr);\n@@ -365,4 +365,4 @@ class IrEmitterUnnested : public IrEmitter {\n }  // namespace gpu\n }  // namespace xla\n \n-#endif  // XLA_SERVICE_GPU_IR_EMITTER_UNNESTED_H_\n+#endif  // XLA_SERVICE_GPU_THUNK_EMITTER_H_",
            "previous_filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.h"
        }
    ],
    "stats": {
        "total": 199,
        "additions": 95,
        "deletions": 104
    }
}