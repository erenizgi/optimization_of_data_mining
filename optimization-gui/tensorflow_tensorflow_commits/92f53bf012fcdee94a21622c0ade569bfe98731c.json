{
    "author": "loislo",
    "message": "[XLA:GPU] Refactor BufferDebugLog to be a template class.\n\nThis change makes `BufferDebugLog` a template class `BufferDebugLog<Entry>`, inheriting from a new `BufferDebugLogBase`. This allows methods like `RequiredSizeForEntries`, `CreateOnDevice`, and `ReadFromDevice` to be type-safe and simplifies their usage by removing the need to explicitly pass the `Entry` type in many calls.\n\nPiperOrigin-RevId: 830956449",
    "sha": "92f53bf012fcdee94a21622c0ade569bfe98731c",
    "files": [
        {
            "sha": "46bd1554469d5ad342d005e3b500196381931f40",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_checksum_thunk.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc?ref=92f53bf012fcdee94a21622c0ade569bfe98731c",
            "patch": "@@ -107,8 +107,9 @@ absl::Status BuffersDebugChecksumThunk::ExecuteOnStream(\n \n   se::DeviceMemory<uint8_t> log_ptr(\n       params.buffer_allocations->GetDeviceAddress(log_slice_));\n-  se::gpu::BufferDebugLog buffer_debug_log =\n-      se::gpu::BufferDebugLog::FromDeviceMemoryUnchecked(log_ptr);\n+  auto buffer_debug_log =\n+      se::gpu::BufferDebugLog<BufferDebugLogEntry>::FromDeviceMemoryUnchecked(\n+          log_ptr);\n \n   for (const auto& [buffer_idx, buffer] : checked_thunk_buffers_) {\n     BufferDebugLogEntryMetadataStore::Metadata metadata{\n@@ -127,7 +128,7 @@ absl::Status BuffersDebugChecksumThunk::ExecuteOnStream(\n     TF_RETURN_IF_ERROR(kernel->Launch(\n         thread_dim, se::BlockDim(1, 1, 1), params.stream, log_entry_id,\n         device_buffer, device_buffer.size(), buffer_debug_log.GetDeviceHeader(),\n-        buffer_debug_log.GetDeviceEntries<BufferDebugLogEntry>()));\n+        buffer_debug_log.GetDeviceEntries()));\n   }\n \n   return absl::OkStatus();"
        },
        {
            "sha": "4aa9116473b4c598fabe4bb7614a408d415382b8",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_checksum_thunk_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc?ref=92f53bf012fcdee94a21622c0ade569bfe98731c",
            "patch": "@@ -117,7 +117,7 @@ class BuffersDebugChecksumThunkTest : public ::testing::Test {\n \n TEST_F(BuffersDebugChecksumThunkTest, CalculatesChecksums) {\n   static constexpr size_t kLogSize =\n-      BufferDebugLog::RequiredSizeForEntries(10, sizeof(BufferDebugLogEntry));\n+      BufferDebugLog<BufferDebugLogEntry>::RequiredSizeForEntries(10);\n   static constexpr size_t kInputSize = 1024;\n   static constexpr size_t kInputCount = 2;\n   static constexpr size_t kTotalDeviceMemoryBytes =\n@@ -139,8 +139,8 @@ TEST_F(BuffersDebugChecksumThunkTest, CalculatesChecksums) {\n   se::DeviceMemoryBase inputs0_mem = allocations.GetDeviceAddress(inputs[0]);\n   se::DeviceMemoryBase inputs1_mem = allocations.GetDeviceAddress(inputs[1]);\n   // Initialize the log in device memory\n-  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n-                          BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+  TF_ASSERT_OK_AND_ASSIGN(auto device_log,\n+                          BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(\n                               *stream_, se::DeviceMemory<uint8_t>(log_mem)));\n   // Fill inputs with some data\n   std::vector<uint32_t> zeros(1024, 0);\n@@ -167,9 +167,8 @@ TEST_F(BuffersDebugChecksumThunkTest, CalculatesChecksums) {\n   TF_ASSERT_OK(thunk.Initialize(init_params));\n   TF_ASSERT_OK(thunk.Prepare(Thunk::PrepareParams{}, resource_requests));\n   TF_ASSERT_OK(thunk.ExecuteOnStream(execute_params));\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<BufferDebugLogEntry> entries,\n-      device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(std::vector<BufferDebugLogEntry> entries,\n+                          device_log.ReadFromDevice(*stream_));\n \n   // BuffersDebugChecksumThunk launches a kernel for each input buffer, they may\n   // complete in any order."
        },
        {
            "sha": "325424632f7c7ae83a3ddb689b7051c18f5edb62",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_float_check_thunk.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk.cc?ref=92f53bf012fcdee94a21622c0ade569bfe98731c",
            "patch": "@@ -107,8 +107,9 @@ absl::Status BuffersDebugFloatCheckThunk::ExecuteOnStream(\n \n   se::DeviceMemory<uint8_t> log_ptr(\n       params.buffer_allocations->GetDeviceAddress(log_slice_));\n-  se::gpu::BufferDebugLog buffer_debug_log =\n-      se::gpu::BufferDebugLog::FromDeviceMemoryUnchecked(log_ptr);\n+  se::gpu::BufferDebugLog<BufferDebugFloatCheckEntry> buffer_debug_log =\n+      se::gpu::BufferDebugLog<\n+          BufferDebugFloatCheckEntry>::FromDeviceMemoryUnchecked(log_ptr);\n   const uint32_t execution_id = execution_count_.fetch_add(1);\n \n   for (const auto& [buffer_idx, buffer] : checked_thunk_buffers_) {\n@@ -131,15 +132,15 @@ absl::Status BuffersDebugFloatCheckThunk::ExecuteOnStream(\n       TF_RETURN_IF_ERROR(kernels->f32.Launch(\n           thread_dim, se::BlockDim(1, 1, 1), params.stream, entry_id,\n           f32_buffer, f32_buffer.size(), buffer_debug_log.GetDeviceHeader(),\n-          buffer_debug_log.GetDeviceEntries<BufferDebugFloatCheckEntry>()));\n+          buffer_debug_log.GetDeviceEntries()));\n     } else if (buffer_type == PrimitiveType::BF16) {\n       VLOG(1) << \"BF16 buffer detected with id: \" << entry_id\n               << \" and size: \" << device_buffer.size();\n       se::DeviceMemory<Eigen::bfloat16> bf16_buffer(device_buffer);\n       TF_RETURN_IF_ERROR(kernels->bf16.Launch(\n           thread_dim, se::BlockDim(1, 1, 1), params.stream, entry_id,\n           bf16_buffer, bf16_buffer.size(), buffer_debug_log.GetDeviceHeader(),\n-          buffer_debug_log.GetDeviceEntries<BufferDebugFloatCheckEntry>()));\n+          buffer_debug_log.GetDeviceEntries()));\n     } else {\n       VLOG(1) << \"Unsupported primitive type for float checking: \"\n               << PrimitiveType_Name(buffer_type);"
        },
        {
            "sha": "a1d551181fad6cd5e77c9d95c8eee5b9845f00d0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_float_check_thunk_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 7,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc?ref=92f53bf012fcdee94a21622c0ade569bfe98731c",
            "patch": "@@ -100,8 +100,8 @@ class BuffersDebugFloatCheckThunkTest : public ::testing::Test {\n };\n \n TEST_F(BuffersDebugFloatCheckThunkTest, CalculatesNanCounts) {\n-  static constexpr size_t kLogSize = BufferDebugLog::RequiredSizeForEntries(\n-      10, sizeof(BufferDebugFloatCheckEntry));\n+  static constexpr size_t kLogSize =\n+      BufferDebugLog<BufferDebugFloatCheckEntry>::RequiredSizeForEntries(10);\n   static constexpr size_t kInputElems = 1024;\n   static constexpr size_t kInputSizeInBytes = kInputElems * sizeof(float);\n   static constexpr size_t kTotalDeviceMemoryBytes =\n@@ -131,8 +131,8 @@ TEST_F(BuffersDebugFloatCheckThunkTest, CalculatesNanCounts) {\n   se::DeviceMemoryBase inputs1_mem = allocations.GetDeviceAddress(inputs[1]);\n   // Initialize the log in device memory\n   TF_ASSERT_OK_AND_ASSIGN(\n-      BufferDebugLog device_log,\n-      BufferDebugLog::CreateOnDevice<BufferDebugFloatCheckEntry>(\n+      auto device_log,\n+      BufferDebugLog<BufferDebugFloatCheckEntry>::CreateOnDevice(\n           *stream_, se::DeviceMemory<uint8_t>(log_mem)));\n   // Fill inputs with some data\n   {\n@@ -166,9 +166,8 @@ TEST_F(BuffersDebugFloatCheckThunkTest, CalculatesNanCounts) {\n   TF_ASSERT_OK(thunk.Initialize(init_params));\n   TF_ASSERT_OK(thunk.Prepare(Thunk::PrepareParams{}, resource_requests));\n   TF_ASSERT_OK(thunk.ExecuteOnStream(execute_params));\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<BufferDebugFloatCheckEntry> entries,\n-      device_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(std::vector<BufferDebugFloatCheckEntry> entries,\n+                          device_log.ReadFromDevice(*stream_));\n \n   // BuffersDebugFloatCheckThunk launches a kernel for each input buffer, they\n   // may complete in any order."
        },
        {
            "sha": "f58f8b7c3b4d6ff4f83b3bbbf52a3144b3febde3",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_checksum.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_checksum.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_checksum.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_checksum.cc?ref=92f53bf012fcdee94a21622c0ade569bfe98731c",
            "patch": "@@ -146,12 +146,11 @@ absl::Status DumpBufferDebugChecksumLog(\n   CHECK(hlo_module != nullptr);\n   const DebugOptions& debug_options = hlo_module->config().debug_options();\n \n-  se::gpu::BufferDebugLog buffer_debug_log =\n-      se::gpu::BufferDebugLog::FromDeviceMemoryUnchecked(\n+  auto buffer_debug_log =\n+      se::gpu::BufferDebugLog<BufferDebugLogEntry>::FromDeviceMemoryUnchecked(\n           log_buffer.device_memory());\n-  TF_ASSIGN_OR_RETURN(\n-      std::vector<BufferDebugLogEntry> log_entries,\n-      buffer_debug_log.ReadFromDevice<BufferDebugLogEntry>(*stream));\n+  TF_ASSIGN_OR_RETURN(std::vector<BufferDebugLogEntry> log_entries,\n+                      buffer_debug_log.ReadFromDevice(*stream));\n   BufferDebugLogProto buffer_debug_log_proto =\n       metadata_store->EntriesToProto(log_entries);\n \n@@ -183,7 +182,7 @@ absl::Status DumpBufferDebugChecksumLog(\n XLA_FFI_DEFINE_HANDLER_SYMBOL(\n     kBufferDebugChecksumLogInitHandler,\n     [](se::Stream* absl_nonnull stream, xla::ffi::Buffer<U8> log_buffer) {\n-      return se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+      return se::gpu::BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(\n                  *stream, log_buffer.device_memory())\n           .status();\n     },"
        },
        {
            "sha": "eeb3f48f0936ccb531b814c333aa6db33e742a78",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_float_check.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 10,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_float_check.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_float_check.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_float_check.cc?ref=92f53bf012fcdee94a21622c0ade569bfe98731c",
            "patch": "@@ -146,12 +146,10 @@ absl::Status BufferDebugFloatCheck(\n   VLOG(1) << \"HLO module name: \" << hlo_module->name();\n   CHECK(hlo_module != nullptr);\n \n-  se::gpu::BufferDebugLog buffer_debug_log =\n-      se::gpu::BufferDebugLog::FromDeviceMemoryUnchecked(\n-          log_buffer.device_memory());\n-  TF_ASSIGN_OR_RETURN(\n-      std::vector<BufferDebugFloatCheckEntry> entries,\n-      buffer_debug_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream));\n+  auto buffer_debug_log = se::gpu::BufferDebugLog<BufferDebugFloatCheckEntry>::\n+      FromDeviceMemoryUnchecked(log_buffer.device_memory());\n+  TF_ASSIGN_OR_RETURN(std::vector<BufferDebugFloatCheckEntry> entries,\n+                      buffer_debug_log.ReadFromDevice(*stream));\n \n   std::vector<BufferDebugLogEntryId> entry_ids;\n   entry_ids.reserve(entries.size());\n@@ -195,10 +193,9 @@ absl::Status BufferDebugFloatCheck(\n XLA_FFI_DEFINE_HANDLER_SYMBOL(\n     kBufferDebugFloatCheckLogInitHandler,\n     [](se::Stream* absl_nonnull stream, xla::ffi::Buffer<U8> log_buffer) {\n-      return se::gpu::BufferDebugLog::CreateOnDevice<\n-                 xla::gpu::BufferDebugFloatCheckEntry>(\n-                 *stream, log_buffer.device_memory())\n-          .status();\n+      return se::gpu::BufferDebugLog<xla::gpu::BufferDebugFloatCheckEntry>::\n+          CreateOnDevice(*stream, log_buffer.device_memory())\n+              .status();\n     },\n     xla::ffi::Ffi::Bind().Ctx<xla::ffi::Stream>().Arg<xla::ffi::Buffer<U8>>());\n "
        },
        {
            "sha": "e556af42a9aec1e8a876166e84bb2e329ffe62b7",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_float_check_kernel_cuda_test.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 42,
            "changes": 74,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc?ref=92f53bf012fcdee94a21622c0ade569bfe98731c",
            "patch": "@@ -82,10 +82,10 @@ class FloatCheckKernelTest : public ::testing::Test {\n     return device_memory;\n   }\n \n-  template <typename Kernel, typename T>\n+  template <typename Kernel, typename InputType, typename BufferType>\n   absl::Status AppendFloatCheckOnDevice(\n-      BufferDebugLogEntryId entry_id, const std::vector<T>& input,\n-      se::gpu::BufferDebugLog& buffer_debug_log,\n+      BufferDebugLogEntryId entry_id, const std::vector<InputType>& input,\n+      se::gpu::BufferDebugLog<BufferType>& buffer_debug_log,\n       stream_executor::ThreadDim dim = stream_executor::ThreadDim(1, 1, 1)) {\n     // Load kernel\n     gpu::GpuKernelRegistry registry =\n@@ -94,8 +94,9 @@ class FloatCheckKernelTest : public ::testing::Test {\n \n     // Setup device buffers\n     TF_ASSIGN_OR_RETURN(\n-        se::DeviceMemory<T> device_input,\n-        CheckNotNull(executor_->AllocateArray<T>(input.size()), \"input\"));\n+        se::DeviceMemory<InputType> device_input,\n+        CheckNotNull(executor_->AllocateArray<InputType>(input.size()),\n+                     \"input\"));\n     auto cleanup_input =\n         absl::MakeCleanup([&]() { executor_->Deallocate(&device_input); });\n \n@@ -104,9 +105,9 @@ class FloatCheckKernelTest : public ::testing::Test {\n                                        input.size() * sizeof(input[0])));\n     TF_RETURN_IF_ERROR(kernel.Launch(\n         dim, stream_executor::BlockDim(1, 1, 1), stream_.get(), entry_id,\n-        device_input, device_input.ElementCount() * sizeof(T),\n+        device_input, device_input.ElementCount() * sizeof(InputType),\n         buffer_debug_log.GetDeviceHeader(),\n-        buffer_debug_log.GetDeviceEntries<BufferDebugFloatCheckEntry>()));\n+        buffer_debug_log.GetDeviceEntries()));\n     TF_RETURN_IF_ERROR(stream_->BlockHostUntilDone());\n \n     // The result gets stored in `buffer_debug_log`.\n@@ -121,56 +122,47 @@ class FloatCheckKernelTest : public ::testing::Test {\n \n TEST_F(FloatCheckKernelTest, ChecksFloatsForF32) {\n   se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(1024);\n-  std::vector<float> input = {\n-      1.0f,\n-      std::numeric_limits<float>::quiet_NaN(),\n-      2.0f,\n-      std::numeric_limits<float>::quiet_NaN(),\n-      0.0f,\n-      std::numeric_limits<float>::infinity(),\n-      std::numeric_limits<float>::infinity(),\n-      std::numeric_limits<float>::infinity(),\n-  };\n+  std::vector<float> input(1024, 1.0f);\n+  input[100] = std::numeric_limits<float>::quiet_NaN();\n+  input[200] = std::numeric_limits<float>::quiet_NaN();\n+  input[300] = 0.0f;\n+  input[400] = std::numeric_limits<float>::infinity();\n+  input[500] = std::numeric_limits<float>::infinity();\n+  input[600] = std::numeric_limits<float>::infinity();\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugFloatCheckEntry>(\n+      auto device_log,\n+      se::gpu::BufferDebugLog<BufferDebugFloatCheckEntry>::CreateOnDevice(\n           *stream_, mem));\n \n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckF32Kernel>(\n       BufferDebugLogEntryId{123}, input, device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log,\n-      device_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].nan_count, 2);\n   EXPECT_EQ(host_log[0].inf_count, 3);\n   EXPECT_EQ(host_log[0].zero_count, 1);\n }\n \n TEST_F(FloatCheckKernelTest, ChecksFloatsForBf16) {\n+  std::vector<xla::bfloat16> input(1024, xla::bfloat16(1.0f));\n+  input[10] = xla::bfloat16(std::numeric_limits<float>::quiet_NaN());\n+  input[20] = xla::bfloat16(std::numeric_limits<float>::quiet_NaN());\n+  input[30] = xla::bfloat16(0.0f),\n+  input[40] = xla::bfloat16(std::numeric_limits<float>::infinity());\n+  input[50] = xla::bfloat16(std::numeric_limits<float>::infinity());\n+  input[60] = xla::bfloat16(std::numeric_limits<float>::infinity());\n+\n   se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(1024);\n-  std::vector<xla::bfloat16> input = {\n-      xla::bfloat16(1.0f),\n-      xla::bfloat16(std::numeric_limits<float>::quiet_NaN()),\n-      xla::bfloat16(2.0f),\n-      xla::bfloat16(std::numeric_limits<float>::quiet_NaN()),\n-      xla::bfloat16(0.0f),\n-      xla::bfloat16(std::numeric_limits<float>::infinity()),\n-      xla::bfloat16(std::numeric_limits<float>::infinity()),\n-      xla::bfloat16(std::numeric_limits<float>::infinity()),\n-  };\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugFloatCheckEntry>(\n+      auto device_log,\n+      se::gpu::BufferDebugLog<BufferDebugFloatCheckEntry>::CreateOnDevice(\n           *stream_, mem));\n \n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckBf16Kernel>(\n       BufferDebugLogEntryId{0}, input, device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log,\n-      device_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].nan_count, 2);\n   EXPECT_EQ(host_log[0].inf_count, 3);\n@@ -188,18 +180,16 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsInParallel) {\n   input[700] = std::numeric_limits<float>::infinity();\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugFloatCheckEntry>(\n+      auto device_log,\n+      se::gpu::BufferDebugLog<BufferDebugFloatCheckEntry>::CreateOnDevice(\n           *stream_, mem));\n \n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckF32Kernel>(\n       BufferDebugLogEntryId{0}, input, device_log, se::ThreadDim(2, 4, 8)));\n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckF32Kernel>(\n       BufferDebugLogEntryId{0}, input, device_log, se::ThreadDim(2, 4, 8)));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log,\n-      device_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 2);\n   EXPECT_EQ(host_log[0].nan_count, 3);\n   EXPECT_EQ(host_log[0].inf_count, 2);"
        },
        {
            "sha": "e9dfe49d313102f1143a851b4f25dd81205e2c4c",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_xor_checksum_kernel_cuda_test.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 30,
            "changes": 54,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc?ref=92f53bf012fcdee94a21622c0ade569bfe98731c",
            "patch": "@@ -83,7 +83,7 @@ class ChecksumKernelTest : public ::testing::Test {\n   template <typename T>\n   absl::Status AppendChecksumOnDevice(\n       BufferDebugLogEntryId entry_id, const T& input,\n-      se::gpu::BufferDebugLog& buffer_debug_log,\n+      se::gpu::BufferDebugLog<BufferDebugLogEntry>& buffer_debug_log,\n       stream_executor::ThreadDim dim = stream_executor::ThreadDim(1, 1, 1)) {\n     // Load kernel\n     gpu::GpuKernelRegistry registry =\n@@ -103,11 +103,11 @@ class ChecksumKernelTest : public ::testing::Test {\n     // Call kernel\n     TF_RETURN_IF_ERROR(stream_->Memcpy(&device_input, input.data(),\n                                        input.size() * sizeof(input[0])));\n-    TF_RETURN_IF_ERROR(kernel.Launch(\n-        dim, stream_executor::BlockDim(1, 1, 1), stream_.get(), entry_id,\n-        device_input, device_input.ElementCount(),\n-        buffer_debug_log.GetDeviceHeader(),\n-        buffer_debug_log.GetDeviceEntries<BufferDebugLogEntry>()));\n+    TF_RETURN_IF_ERROR(kernel.Launch(dim, stream_executor::BlockDim(1, 1, 1),\n+                                     stream_.get(), entry_id, device_input,\n+                                     device_input.ElementCount(),\n+                                     buffer_debug_log.GetDeviceHeader(),\n+                                     buffer_debug_log.GetDeviceEntries()));\n     TF_RETURN_IF_ERROR(stream_->BlockHostUntilDone());\n \n     // The result gets stored in `buffer_debug_log`.\n@@ -132,15 +132,14 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumForMultipleOf32Bit) {\n   constexpr uint32_t kExpectedChecksum = 0x12345678;\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+      auto device_log,\n+      se::gpu::BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(*stream_,\n                                                                    mem));\n \n   TF_EXPECT_OK(\n       AppendChecksumOnDevice(BufferDebugLogEntryId{0}, input, device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].value, kExpectedChecksum);\n }\n@@ -150,15 +149,14 @@ TEST_F(ChecksumKernelTest,\n   se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(1024);\n   const std::vector<uint8_t> kInput = std::vector<uint8_t>(1023, 0x55);\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+      auto device_log,\n+      se::gpu::BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(*stream_,\n                                                                    mem));\n \n   TF_EXPECT_OK(\n       AppendChecksumOnDevice(BufferDebugLogEntryId{0}, kInput, device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   // Assumes the device uses little-endian byte order.\n   EXPECT_EQ(host_log[0].value, 0x55000000);\n@@ -172,15 +170,14 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallel) {\n   input[1000] ^= 0x12345678;\n   constexpr uint32_t kExpectedChecksum = 0x12345678;\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+      auto device_log,\n+      se::gpu::BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(*stream_,\n                                                                    mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{0}, input,\n                                       device_log, se::ThreadDim(2, 4, 8)));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].value, kExpectedChecksum);\n }\n@@ -193,15 +190,14 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallelWithMaxThreads) {\n   input[1000] ^= 0x12345678;\n   constexpr uint32_t kExpectedChecksum = 0x12345678;\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+      auto device_log,\n+      se::gpu::BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(*stream_,\n                                                                    mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{0}, input,\n                                       device_log, se::ThreadDim(128, 4, 2)));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].value, kExpectedChecksum);\n }\n@@ -212,8 +208,8 @@ TEST_F(ChecksumKernelTest, AppendsChecksumsToLog) {\n   constexpr std::array<uint32_t, 1> kInput456 = {0x04560456};\n   constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+      auto device_log,\n+      se::gpu::BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(*stream_,\n                                                                    mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{123}, kInput123,\n@@ -223,8 +219,7 @@ TEST_F(ChecksumKernelTest, AppendsChecksumsToLog) {\n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{789}, kInput789,\n                                       device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 3);\n   EXPECT_EQ(host_log[0].entry_id, 123);\n   EXPECT_EQ(host_log[0].value, 0x01230123);\n@@ -241,8 +236,8 @@ TEST_F(ChecksumKernelTest, DiscardsOverflowingChecksums) {\n   constexpr std::array<uint32_t, 1> kInput456 = {0x04560456};\n   constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n   TF_ASSERT_OK_AND_ASSIGN(\n-      se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+      auto device_log,\n+      se::gpu::BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(*stream_,\n                                                                    mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{123}, kInput123,\n@@ -253,8 +248,7 @@ TEST_F(ChecksumKernelTest, DiscardsOverflowingChecksums) {\n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{789}, kInput789,\n                                       device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 2);\n   EXPECT_EQ(host_log[0].entry_id, 123);\n   EXPECT_EQ(host_log[0].value, 0x01230123);"
        },
        {
            "sha": "fee98c27c6db590196c64f643a18417ebac20789",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 16,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc?ref=92f53bf012fcdee94a21622c0ade569bfe98731c",
            "patch": "@@ -34,50 +34,51 @@ namespace stream_executor::gpu {\n \n using ::xla::gpu::BufferDebugLogHeader;\n \n-absl::StatusOr<BufferDebugLog> BufferDebugLog::CreateOnDevice(\n-    Stream& stream, DeviceMemory<uint8_t> log_buffer, size_t entry_size) {\n-  if (log_buffer.is_null()) {\n+absl::StatusOr<DeviceMemory<uint8_t>> BufferDebugLogBase::CreateOnDevice(\n+    Stream& stream, DeviceMemory<uint8_t> memory, size_t entry_size) {\n+  if (memory.is_null()) {\n     return absl::InvalidArgumentError(\"Log buffer must be non-null\");\n   }\n \n   size_t kMinBufferSize = sizeof(BufferDebugLogHeader) + entry_size;\n-  if (log_buffer.size() < kMinBufferSize) {\n+  if (memory.size() < kMinBufferSize) {\n     return absl::InvalidArgumentError(\n         absl::StrFormat(\"Log buffer size %u is too small to hold any log \"\n                         \"entries (required: %u bytes)\",\n-                        log_buffer.size(), kMinBufferSize));\n+                        memory.size(), kMinBufferSize));\n   }\n \n   const uint32_t max_entries =\n-      (log_buffer.size() - sizeof(BufferDebugLogHeader)) / entry_size;\n+      (memory.size() - sizeof(BufferDebugLogHeader)) / entry_size;\n   const BufferDebugLogHeader empty_header{\n       /*write_idx=*/0,\n       /*capacity=*/max_entries,\n   };\n   TF_RETURN_IF_ERROR(\n-      stream.Memcpy(&log_buffer, &empty_header, sizeof(empty_header)));\n-  return BufferDebugLog(log_buffer);\n+      stream.Memcpy(&memory, &empty_header, sizeof(empty_header)));\n+  return memory;\n }\n \n-absl::StatusOr<BufferDebugLogHeader> BufferDebugLog::ReadHeaderFromDevice(\n-    Stream& stream) const {\n+absl::StatusOr<BufferDebugLogHeader> BufferDebugLogBase::ReadHeaderFromDevice(\n+    Stream& stream, DeviceMemory<uint8_t> memory) const {\n   BufferDebugLogHeader header;\n-  TF_RETURN_IF_ERROR(stream.Memcpy(&header, memory_, sizeof(header)));\n+  TF_RETURN_IF_ERROR(stream.Memcpy(&header, memory, sizeof(header)));\n   TF_RETURN_IF_ERROR(stream.BlockHostUntilDone());\n   return header;\n }\n \n-absl::StatusOr<size_t> BufferDebugLog::ReadFromDevice(\n-    Stream& stream, size_t entry_size, void* entries_data) const {\n-  std::vector<uint8_t> buffer(memory_.size());\n-  TF_RETURN_IF_ERROR(stream.Memcpy(buffer.data(), memory_, memory_.size()));\n+absl::StatusOr<size_t> BufferDebugLogBase::ReadFromDevice(\n+    Stream& stream, DeviceMemory<uint8_t> memory, size_t entry_size,\n+    void* entries_data) const {\n+  std::vector<uint8_t> buffer(memory.size());\n+  TF_RETURN_IF_ERROR(stream.Memcpy(buffer.data(), memory, memory.size()));\n   TF_RETURN_IF_ERROR(stream.BlockHostUntilDone());\n \n   BufferDebugLogHeader header;\n   memcpy(&header, buffer.data(), sizeof(header));\n \n   const uint32_t max_entries =\n-      (memory_.size() - sizeof(BufferDebugLogHeader)) / entry_size;\n+      (memory.size() - sizeof(BufferDebugLogHeader)) / entry_size;\n   const size_t initialized_entries =\n       std::min(max_entries, std::min(header.capacity, header.write_idx));\n   memcpy(entries_data, buffer.data() + sizeof(header),"
        },
        {
            "sha": "28d805eb77a3f40f13acd5637026ef1d00ffe21f",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log.h",
            "status": "modified",
            "additions": 32,
            "deletions": 17,
            "changes": 49,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h?ref=92f53bf012fcdee94a21622c0ade569bfe98731c",
            "patch": "@@ -29,17 +29,34 @@ limitations under the License.\n \n namespace stream_executor::gpu {\n \n+// Base class for BufferDebugLog.\n+//\n+// This class is not intended to be used directly. Use BufferDebugLog instead.\n+class BufferDebugLogBase {\n+ protected:\n+  absl::StatusOr<xla::gpu::BufferDebugLogHeader> ReadHeaderFromDevice(\n+      Stream& stream, DeviceMemory<uint8_t> memory) const;\n+\n+  absl::StatusOr<size_t> ReadFromDevice(Stream& stream,\n+                                        DeviceMemory<uint8_t> memory,\n+                                        size_t entry_size,\n+                                        void* entries_data) const;\n+\n+  static absl::StatusOr<DeviceMemory<uint8_t>> CreateOnDevice(\n+      Stream& stream, DeviceMemory<uint8_t> memory, size_t entry_size);\n+};\n+\n // A wrapper over a device memory buffer used to store debug info about contents\n // of buffers (e.g. checksums).\n //\n // It holds a BufferDebugLogHeader and a variable number of Entry structs.\n-class BufferDebugLog {\n+template <typename Entry>\n+class BufferDebugLog : public BufferDebugLogBase {\n  public:\n   // Returns the number of bytes required to store a log with `entries`\n   // entries.\n-  static constexpr size_t RequiredSizeForEntries(size_t entries,\n-                                                 size_t entry_size) {\n-    return sizeof(xla::gpu::BufferDebugLogHeader) + entry_size * entries;\n+  static constexpr size_t RequiredSizeForEntries(size_t entries) {\n+    return sizeof(xla::gpu::BufferDebugLogHeader) + sizeof(Entry) * entries;\n   }\n \n   // Initializes an empty `BufferDebugLog` using a `log_buffer` allocated in\n@@ -52,27 +69,30 @@ class BufferDebugLog {\n   //\n   // Fails with `absl::StatusCode::kInvalidArgument` if `log_buffer` is too\n   // small to hold any entries.\n-  template <typename Entry>\n-  static absl::StatusOr<BufferDebugLog> CreateOnDevice(\n+  static absl::StatusOr<BufferDebugLog<Entry>> CreateOnDevice(\n       Stream& stream, DeviceMemory<uint8_t> log_buffer) {\n-    return CreateOnDevice(stream, log_buffer, sizeof(Entry));\n+    TF_ASSIGN_OR_RETURN(auto memory, BufferDebugLogBase::CreateOnDevice(\n+                                         stream, log_buffer, sizeof(Entry)));\n+    return BufferDebugLog<Entry>(memory);\n   }\n \n   // Creates a `BufferDebugLog` from an already initialized device memory\n   // buffer.\n   //\n   // `log_buffer` must contain an initialized `BufferDebugLogHeader`.\n   static BufferDebugLog FromDeviceMemoryUnchecked(\n-      DeviceMemory<uint8_t> log_buffer) {\n-    return BufferDebugLog(log_buffer);\n+      DeviceMemory<uint8_t> memory) {\n+    return BufferDebugLog<Entry>(memory);\n   }\n \n   // Reads the header from the device log.\n   //\n   // `stream` must be associated with the same device as the one used to create\n   // the log.\n   absl::StatusOr<xla::gpu::BufferDebugLogHeader> ReadHeaderFromDevice(\n-      Stream& stream) const;\n+      Stream& stream) const {\n+    return BufferDebugLogBase::ReadHeaderFromDevice(stream, memory_);\n+  }\n \n   // Reads all entries from the device log into host memory.\n   //\n@@ -81,11 +101,11 @@ class BufferDebugLog {\n   //\n   // `stream` must be associated with the same device as the one used to create\n   // the log.\n-  template <typename Entry>\n   absl::StatusOr<std::vector<Entry>> ReadFromDevice(Stream& stream) const {\n     std::vector<Entry> entries(memory_.size() / sizeof(Entry), Entry{});\n     TF_ASSIGN_OR_RETURN(size_t initialized_entries,\n-                        ReadFromDevice(stream, sizeof(Entry), entries.data()));\n+                        BufferDebugLogBase::ReadFromDevice(\n+                            stream, memory_, sizeof(Entry), entries.data()));\n     entries.resize(initialized_entries);\n     return entries;\n   }\n@@ -103,7 +123,6 @@ class BufferDebugLog {\n   //\n   // The returned `DeviceMemory` gets invalidated when the `BufferDebugLog` is\n   // destroyed.\n-  template <typename Entry>\n   DeviceMemory<Entry> GetDeviceEntries() const {\n     return DeviceMemory<Entry>(memory_.GetByteSlice(\n         sizeof(xla::gpu::BufferDebugLogHeader),\n@@ -112,10 +131,6 @@ class BufferDebugLog {\n \n  private:\n   explicit BufferDebugLog(DeviceMemory<uint8_t> memory) : memory_(memory) {}\n-  absl::StatusOr<size_t> ReadFromDevice(Stream& stream, size_t entry_size,\n-                                        void* entries_data) const;\n-  static absl::StatusOr<BufferDebugLog> CreateOnDevice(\n-      Stream& stream, DeviceMemory<uint8_t> log_buffer, size_t entry_size);\n \n   DeviceMemory<uint8_t> memory_;\n };"
        },
        {
            "sha": "27b7bb3c9d254edbd425396ace87532d6387affc",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log_test.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 17,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92f53bf012fcdee94a21622c0ade569bfe98731c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc?ref=92f53bf012fcdee94a21622c0ade569bfe98731c",
            "patch": "@@ -64,11 +64,10 @@ class BufferDebugLogTest : public ::testing::Test {\n TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_InitializesEmptyLog) {\n   DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(1024);\n \n-  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n-                          BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+  TF_ASSERT_OK_AND_ASSIGN(auto device_log,\n+                          BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(\n                               *stream_, log_buffer));\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n \n   EXPECT_EQ(host_log.size(), 0);\n }\n@@ -82,23 +81,21 @@ TEST_F(BufferDebugLogTest,\n   DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n       kExpectedHeaderSize + kExpectedEntriesSize);\n \n-  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n-                          BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+  TF_ASSERT_OK_AND_ASSIGN(auto device_log,\n+                          BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(\n                               *stream_, log_buffer));\n \n   EXPECT_EQ(device_log.GetDeviceHeader().size(), kExpectedHeaderSize);\n-  EXPECT_EQ(device_log.GetDeviceEntries<BufferDebugLogEntry>().size(),\n-            kExpectedEntriesSize);\n+  EXPECT_EQ(device_log.GetDeviceEntries().size(), kExpectedEntriesSize);\n }\n \n TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_InitializesHeader) {\n   constexpr size_t kMaxEntries = 123;\n-  DeviceMemory<uint8_t> log_buffer =\n-      executor_->AllocateArray<uint8_t>(BufferDebugLog::RequiredSizeForEntries(\n-          kMaxEntries, sizeof(BufferDebugLogEntry)));\n+  DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n+      BufferDebugLog<BufferDebugLogEntry>::RequiredSizeForEntries(kMaxEntries));\n \n-  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n-                          BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+  TF_ASSERT_OK_AND_ASSIGN(auto device_log,\n+                          BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(\n                               *stream_, log_buffer));\n   TF_ASSERT_OK_AND_ASSIGN(BufferDebugLogHeader header,\n                           device_log.ReadHeaderFromDevice(*stream_));\n@@ -108,19 +105,18 @@ TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_InitializesHeader) {\n }\n \n TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_FailsForNullBuffer) {\n-  EXPECT_THAT(BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+  EXPECT_THAT(BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(\n                   *stream_, DeviceMemory<uint8_t>()),\n               absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n TEST_F(BufferDebugLogTest,\n        CreateBufferDebugLogOnDevice_FailsForTooSmallBuffer) {\n   DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n-      BufferDebugLog::RequiredSizeForEntries(1, sizeof(BufferDebugLogEntry)) -\n-      1);\n+      BufferDebugLog<BufferDebugLogEntry>::RequiredSizeForEntries(1) - 1);\n \n   EXPECT_THAT(\n-      BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_, log_buffer),\n+      BufferDebugLog<BufferDebugLogEntry>::CreateOnDevice(*stream_, log_buffer),\n       absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n }\n "
        }
    ],
    "stats": {
        "total": 308,
        "additions": 150,
        "deletions": 158
    }
}