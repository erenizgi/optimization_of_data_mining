{
    "author": "ermilovmaxim",
    "message": "Add proto serialization for RaggedAllToAllStartThunk\n\nPiperOrigin-RevId: 847830182",
    "sha": "1fa15367ad8e996e777e1d688d01dcd0f1a33db6",
    "files": [
        {
            "sha": "717afa12e2e74faf4878172d4f765ecd3b746050",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 17,
            "deletions": 1,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=1fa15367ad8e996e777e1d688d01dcd0f1a33db6",
            "patch": "@@ -1498,7 +1498,6 @@ cc_library(\n     name = \"ragged_all_to_all_thunk\",\n     srcs = [\"ragged_all_to_all_thunk.cc\"],\n     hdrs = [\"ragged_all_to_all_thunk.h\"],\n-    tags = [\"gpu\"],\n     deps = [\n         \":collective_thunk\",\n         \":ragged_all_to_all\",\n@@ -1513,6 +1512,7 @@ cc_library(\n         \"//xla/core/collectives:communicator\",\n         \"//xla/core/collectives:rank_id\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:buffer_assignment\",\n         \"//xla/service:rendezvous\",\n         \"//xla/service/gpu/transforms/collectives:collective_ops_utils\",\n         \"//xla/stream_executor:device_address\",\n@@ -1540,6 +1540,21 @@ cc_library(\n     ],\n )\n \n+xla_cc_test(\n+    name = \"ragged_all_to_all_thunk_test\",\n+    srcs = [\"ragged_all_to_all_thunk_test.cc\"],\n+    deps = [\n+        \":collective_thunk\",\n+        \":ragged_all_to_all_thunk\",\n+        \":thunk\",\n+        \":thunk_proto_cc\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n cc_library(\n     name = \"collective_broadcast_thunk\",\n     srcs = [\"collective_broadcast_thunk.cc\"],\n@@ -2927,6 +2942,7 @@ cc_library(\n         \":memset_thunk\",\n         \":norm_thunk\",\n         \":outfeed_thunk\",\n+        \":ragged_all_to_all_thunk\",\n         \":replica_id_thunk\",\n         \":sequential_thunk\",\n         \":thunk\","
        },
        {
            "sha": "377d64404c8f34f6ab45150008fe9c288fee9c4d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all_thunk.cc",
            "status": "modified",
            "additions": 89,
            "deletions": 16,
            "changes": 105,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc?ref=1fa15367ad8e996e777e1d688d01dcd0f1a33db6",
            "patch": "@@ -45,6 +45,7 @@ limitations under the License.\n #include \"xla/future.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/transforms/collectives/collective_ops_utils.h\"\n #include \"xla/service/rendezvous.h\"\n #include \"xla/shape.h\"\n@@ -218,6 +219,32 @@ absl::Status RunRaggedAllToAll(\n \n }  // namespace\n \n+RaggedAllToAllStartThunk::RaggedAllToAllStartThunk(\n+    ThunkInfo thunk_info, const HloRaggedAllToAllInstruction* instr,\n+    std::vector<CollectiveThunk::Buffer> buffers, bool p2p_memcpy_enabled)\n+    : RaggedAllToAllStartThunk(\n+          std::move(thunk_info), GetRaggedAllToAllConfig(instr),\n+          IsGPUSyncCollective(*instr)\n+              ? nullptr\n+              : std::make_shared<CollectiveThunk::AsyncEvents>(),\n+          std::move(buffers),\n+          instr->GetModule()\n+              ->config()\n+              .debug_options()\n+              .xla_gpu_unsupported_use_ragged_all_to_all_one_shot_kernel()) {}\n+\n+RaggedAllToAllStartThunk::RaggedAllToAllStartThunk(\n+    ThunkInfo thunk_info, const RaggedAllToAllConfig& config,\n+    std::shared_ptr<AsyncEvents> async_events,\n+    std::vector<CollectiveThunk::Buffer> buffers, bool one_shot_kernel_enabled)\n+    : CollectiveThunk(Thunk::kRaggedAllToAllStart, thunk_info, async_events,\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n+      config_(config),\n+      buffers_(std::move(buffers)),\n+      one_shot_kernel_enabled_(one_shot_kernel_enabled) {\n+  CHECK_EQ(config_.config.operand_element_type.size(), buffers_.size());\n+}\n+\n // Executes the rendezvous before the kernel start.\n // Inserts CUDA events into the stream to ensure that all devices have reached\n // the start event before the kernel starts.\n@@ -333,22 +360,6 @@ absl::Status RaggedAllToAllStartThunk::RunOneShotRaggedAllToAll(\n                                      *rendezvous_values);\n }\n \n-RaggedAllToAllStartThunk::RaggedAllToAllStartThunk(\n-    ThunkInfo thunk_info, const HloRaggedAllToAllInstruction* instr,\n-    std::vector<CollectiveThunk::Buffer> buffers, bool p2p_memcpy_enabled)\n-    : CollectiveThunk(Thunk::kRaggedAllToAllStart, thunk_info,\n-                      IsGPUSyncCollective(*instr),\n-                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n-      config_(GetRaggedAllToAllConfig(instr)),\n-      buffers_(std::move(buffers)),\n-      one_shot_kernel_enabled_(\n-          instr->GetModule()\n-              ->config()\n-              .debug_options()\n-              .xla_gpu_unsupported_use_ragged_all_to_all_one_shot_kernel()) {\n-  CHECK_EQ(config_.config.operand_element_type.size(), buffers_.size());\n-}\n-\n /*static*/ absl::Status RaggedAllToAllStartThunk::CheckImplementable(\n     const HloRaggedAllToAllInstruction* instr, int64_t replica_count,\n     int64_t partition_count) {\n@@ -452,6 +463,68 @@ bool RaggedAllToAllStartThunk::is_local() const {\n   return true;\n }\n \n+absl::StatusOr<std::unique_ptr<RaggedAllToAllStartThunk>>\n+RaggedAllToAllStartThunk::FromProto(\n+    ThunkInfo thunk_info, const RaggedAllToAllStartThunkProto& thunk_proto,\n+    absl::Span<const BufferAllocation> buffer_allocations,\n+    CollectiveThunk::AsyncEventsMap& async_events_map) {\n+  std::vector<CollectiveThunk::Buffer> buffers;\n+  buffers.reserve(thunk_proto.buffers_size());\n+  for (const CollectiveBufferProto& proto : thunk_proto.buffers()) {\n+    ASSIGN_OR_RETURN(\n+        CollectiveThunk::Buffer buffer,\n+        CollectiveThunk::Buffer::FromProto(proto, buffer_allocations));\n+    buffers.push_back(buffer);\n+  }\n+\n+  std::shared_ptr<CollectiveThunk::AsyncEvents> async_events;\n+  if (thunk_proto.has_async_events_unique_id()) {\n+    std::shared_ptr<CollectiveThunk::AsyncEvents>& events =\n+        async_events_map[AsyncEventsUniqueId{\n+            thunk_proto.async_events_unique_id()}];\n+    if (!events) {\n+      events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+    }\n+    async_events = events;\n+  }\n+\n+  CollectiveConfig config =\n+      CollectiveConfig::FromProto(thunk_proto.collective_config());\n+\n+  return std::make_unique<RaggedAllToAllStartThunk>(\n+      std::move(thunk_info),\n+      RaggedAllToAllConfig{config, thunk_proto.num_total_updates(),\n+                           thunk_proto.num_input_rows(),\n+                           thunk_proto.num_row_elements()},\n+      async_events, std::move(buffers), thunk_proto.one_shot_kernel_enabled());\n+}\n+\n+absl::StatusOr<ThunkProto> RaggedAllToAllStartThunk::ToProto() const {\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+\n+  RaggedAllToAllStartThunkProto* thunk_proto =\n+      proto.mutable_ragged_all_to_all_start_thunk();\n+\n+  std::optional<AsyncEventsUniqueId> async_events_id = GetAsyncEventsUniqueId();\n+  if (async_events_id.has_value()) {\n+    thunk_proto->set_async_events_unique_id(async_events_id->value());\n+  }\n+\n+  for (const Buffer& buffer : buffers_) {\n+    ASSIGN_OR_RETURN(*thunk_proto->add_buffers(), buffer.ToProto());\n+  }\n+\n+  *thunk_proto->mutable_collective_config() = config_.config.ToProto();\n+\n+  thunk_proto->set_num_total_updates(config_.num_total_updates);\n+  thunk_proto->set_num_input_rows(config_.num_input_rows);\n+  thunk_proto->set_num_row_elements(config_.num_row_elements);\n+  thunk_proto->set_one_shot_kernel_enabled(one_shot_kernel_enabled_);\n+\n+  return proto;\n+}\n+\n absl::StatusOr<bool> RaggedAllToAllStartThunk::RunCollective(\n     const ExecuteParams& params, const GpuCliqueKey& clique_key,\n     se::Stream& stream, Communicator& comm) {"
        },
        {
            "sha": "fc56dfdae00c5a6029f1c127a62842b483ac4437",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all_thunk.h",
            "status": "modified",
            "additions": 15,
            "deletions": 1,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.h?ref=1fa15367ad8e996e777e1d688d01dcd0f1a33db6",
            "patch": "@@ -25,13 +25,15 @@ limitations under the License.\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/core/collectives/communicator.h\"\n #include \"xla/core/collectives/rank_id.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/device_address_handle.h\"\n #include \"xla/stream_executor/event.h\"\n@@ -57,6 +59,11 @@ class RaggedAllToAllStartThunk : public CollectiveThunk {\n                            const HloRaggedAllToAllInstruction* instr,\n                            std::vector<Buffer> buffers,\n                            bool p2p_memcpy_enabled);\n+  RaggedAllToAllStartThunk(ThunkInfo thunk_info,\n+                           const RaggedAllToAllConfig& config,\n+                           std::shared_ptr<AsyncEvents> async_events,\n+                           std::vector<CollectiveThunk::Buffer> buffers,\n+                           bool one_shot_kernel_enabled);\n \n   // Returns whether the given instruction can be lowered to a nccl\n   // ragged-all-to-all call.\n@@ -66,14 +73,21 @@ class RaggedAllToAllStartThunk : public CollectiveThunk {\n \n   absl::Status Initialize(const InitializeParams& params) override;\n \n-  static const char* GetHloOpName() { return \"ragged-all-to-all-start\"; }\n+  static absl::string_view GetHloOpName() { return \"ragged-all-to-all-start\"; }\n \n   static CollectiveOpGroupMode GetGroupMode(\n       const HloRaggedAllToAllInstruction* instr);\n \n   const CollectiveConfig& config() const override { return config_.config; }\n   absl::Span<const Buffer> buffers() const { return buffers_; }\n \n+  static absl::StatusOr<std::unique_ptr<RaggedAllToAllStartThunk>> FromProto(\n+      ThunkInfo thunk_info, const RaggedAllToAllStartThunkProto& thunk_proto,\n+      absl::Span<const BufferAllocation> buffer_allocations,\n+      CollectiveThunk::AsyncEventsMap& async_events_map);\n+\n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n  protected:\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n                                      const GpuCliqueKey& clique_key,"
        },
        {
            "sha": "3b476b5777834f649dd1e52a331c79254ce6cd78",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all_thunk_test.cc",
            "status": "added",
            "additions": 78,
            "deletions": 0,
            "changes": 78,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk_test.cc?ref=1fa15367ad8e996e777e1d688d01dcd0f1a33db6",
            "patch": "@@ -0,0 +1,78 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/ragged_all_to_all_thunk.h\"\n+\n+#include <memory>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"xla/backends/gpu/runtime/collective_thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+using ::tsl::proto_testing::EqualsProto;\n+\n+TEST(CollectiveThunkTest, ProtoRoundTrip) {\n+  ThunkProto proto = tsl::proto_testing::ParseTextProtoOrDie<ThunkProto>(\n+      R\"pb(\n+        thunk_info {\n+          profile_annotation: \"partition_id_profile_annotation\"\n+          execution_stream_id: 2\n+        }\n+        ragged_all_to_all_start_thunk {\n+          async_events_unique_id: 3\n+          collective_config {}\n+          num_total_updates: 10\n+          num_input_rows: 2\n+          num_row_elements: 5\n+          one_shot_kernel_enabled: true\n+        }\n+      )pb\");\n+\n+  Thunk::ThunkInfo thunk_info;\n+  thunk_info.profile_annotation = proto.thunk_info().profile_annotation();\n+  thunk_info.execution_stream_id = xla::gpu::ExecutionStreamId{\n+      static_cast<xla::gpu::ExecutionStreamId::ValueType>(\n+          proto.thunk_info().execution_stream_id())};\n+\n+  CollectiveThunk::AsyncEventsMap async_events_map;\n+  std::vector<BufferAllocation> buffer_allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/4, /*color=*/0)};\n+\n+  ASSERT_OK_AND_ASSIGN(std::unique_ptr<RaggedAllToAllStartThunk> thunk,\n+                       RaggedAllToAllStartThunk::FromProto(\n+                           thunk_info, proto.ragged_all_to_all_start_thunk(),\n+                           buffer_allocations, async_events_map));\n+  ASSERT_NE(thunk->async_events(), nullptr);\n+\n+  ASSERT_OK_AND_ASSIGN(ThunkProto round_trip_proto, thunk->ToProto());\n+\n+  // Ids are unique and expected to differ.\n+  proto.mutable_ragged_all_to_all_start_thunk()->set_async_events_unique_id(\n+      round_trip_proto.ragged_all_to_all_start_thunk()\n+          .async_events_unique_id());\n+  EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        },
        {
            "sha": "661dd23c95dfd6d2edbe3202f8dc83a0d3fd23d8",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=1fa15367ad8e996e777e1d688d01dcd0f1a33db6",
            "patch": "@@ -435,6 +435,17 @@ message AllToAllStartThunkProto {\n   bool p2p_memcpy_enabled = 5;\n }\n \n+message RaggedAllToAllStartThunkProto {\n+  optional uint64 async_events_unique_id = 1;\n+  CollectiveConfigProto collective_config = 2;\n+  repeated CollectiveBufferProto buffers = 3;\n+\n+  int64 num_total_updates = 4;\n+  int64 num_input_rows = 5;\n+  int64 num_row_elements = 6;\n+  bool one_shot_kernel_enabled = 7;\n+}\n+\n message CollectiveDoneThunkProto {\n   ThunkKindProto thunk_kind = 1;\n   AsyncStreamKind async_stream_kind = 2;\n@@ -483,6 +494,7 @@ message ThunkProto {\n     AllGatherStartThunkProto all_gather_start_thunk = 38;\n     AllReduceStartThunkProto all_reduce_start_thunk = 39;\n     AllToAllStartThunkProto all_to_all_start_thunk = 40;\n+    RaggedAllToAllStartThunkProto ragged_all_to_all_start_thunk = 41;\n   }\n }\n "
        },
        {
            "sha": "f2303b3ac4df9a89132cccc823e31a92163234be",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1fa15367ad8e996e777e1d688d01dcd0f1a33db6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc?ref=1fa15367ad8e996e777e1d688d01dcd0f1a33db6",
            "patch": "@@ -51,6 +51,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/memset_thunk.h\"\n #include \"xla/backends/gpu/runtime/norm_thunk.h\"\n #include \"xla/backends/gpu/runtime/outfeed_thunk.h\"\n+#include \"xla/backends/gpu/runtime/ragged_all_to_all_thunk.h\"\n #include \"xla/backends/gpu/runtime/replica_id_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n@@ -257,6 +258,10 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n       return AllToAllStartThunk::FromProto(\n           std::move(thunk_info), thunk_proto.all_to_all_start_thunk(),\n           buffer_allocations, collective_async_events_map);\n+    case ThunkProto::kRaggedAllToAllStartThunk:\n+      return RaggedAllToAllStartThunk::FromProto(\n+          std::move(thunk_info), thunk_proto.ragged_all_to_all_start_thunk(),\n+          buffer_allocations, collective_async_events_map);\n     default:\n       std::optional<absl::string_view> unsupported_thunk_type =\n           GetStoredThunkTypeName(thunk_proto);"
        }
    ],
    "stats": {
        "total": 234,
        "additions": 216,
        "deletions": 18
    }
}