{
    "author": "ezhulenev",
    "message": "[xla:cpu] Add serialization support for YnnFusionThunk\n\nPiperOrigin-RevId: 827576161",
    "sha": "92cb28a9a5e9e2736994503551b879ebff07cd8f",
    "files": [
        {
            "sha": "600388d1427a183903df001b48f438b6715c3966",
            "filename": "third_party/xla/xla/backends/cpu/runtime/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD?ref=92cb28a9a5e9e2736994503551b879ebff07cd8f",
            "patch": "@@ -1208,19 +1208,24 @@ cc_library(\n         \"//xla/runtime:work_group\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:collective_ops_utils\",\n+        \"//xla/stream_executor:device_memory\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/functional:any_invocable\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/types:span\",\n         \"@local_tsl//tsl/platform:casts\",\n     ] + if_ynnpack([\n         \"//xla/backends/cpu/runtime/ynnpack:ynn_fusion_thunk\",\n+        \"//xla/backends/cpu:ynn_emitter\",\n+        \"//xla/backends/cpu/runtime/ynnpack:ynn_interop\",\n     ]),\n )\n "
        },
        {
            "sha": "0af36ecb40e915ed62c7574e0b55286c1d3115ba",
            "filename": "third_party/xla/xla/backends/cpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.proto?ref=92cb28a9a5e9e2736994503551b879ebff07cd8f",
            "patch": "@@ -181,6 +181,10 @@ message XnnFusionThunkProto {\n \n message YnnFusionThunkProto {\n   YnnFusionOptions options = 1;\n+\n+  int64 instruction_id = 2;\n+  repeated ShapeBufferAllocationSliceProto arguments_shapes = 3;\n+  repeated ShapeBufferAllocationSliceProto results_shapes = 4;\n }\n \n message DotThunkProto {\n@@ -306,6 +310,7 @@ message ThunkProto {\n     CollectiveThunkProto collective_thunk = 18;\n     PartitionIdThunkProto partition_id_thunk = 19;\n     ReplicaIdThunkProto replica_id_thunk = 20;\n+    YnnFusionThunkProto ynn_fusion_thunk = 21;\n   }\n }\n "
        },
        {
            "sha": "7fa479ba96f8debeddddafb693c412d5bea3e3b0",
            "filename": "third_party/xla/xla/backends/cpu/runtime/thunk_proto_serdes.cc",
            "status": "modified",
            "additions": 127,
            "deletions": 0,
            "changes": 127,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_proto_serdes.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_proto_serdes.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_proto_serdes.cc?ref=92cb28a9a5e9e2736994503551b879ebff07cd8f",
            "patch": "@@ -27,12 +27,14 @@ limitations under the License.\n \n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/flat_hash_set.h\"\n+#include \"absl/functional/any_invocable.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/cpu/runtime/all_gather_thunk.h\"\n #include \"xla/backends/cpu/runtime/all_reduce_thunk.h\"\n #include \"xla/backends/cpu/runtime/all_to_all_thunk.h\"\n@@ -63,16 +65,27 @@ limitations under the License.\n #include \"xla/backends/cpu/runtime/xnnpack/xnn_fusion_thunk.h\"\n #include \"xla/backends/cpu/xnn_fusion_options.pb.h\"\n #include \"xla/backends/cpu/ynn_fusion_options.pb.h\"\n+#include \"xla/hlo/ir/hlo_casting_utils.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/runtime/resource_use.h\"\n #include \"xla/runtime/work_group.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/collective_ops_utils.h\"\n #include \"xla/shape.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n #include \"tsl/platform/casts.h\"\n \n+#ifdef XLA_YNNPACK\n+#include \"xla/backends/cpu/runtime/ynnpack/ynn_fusion_thunk.h\"\n+#include \"xla/backends/cpu/runtime/ynnpack/ynn_interop.h\"\n+#include \"xla/backends/cpu/ynn_emitter.h\"\n+#endif  // XLA_YNNPACK\n+\n namespace xla::cpu {\n \n void ForEachThunkProto(const ThunkSequenceProto& proto,\n@@ -164,6 +177,8 @@ static absl::StatusOr<Thunk::Kind> ProtoThunkToThunkKind(\n       return Thunk::Kind::kPartitionId;\n     case ThunkProto::ImplCase::kReplicaIdThunk:\n       return Thunk::Kind::kReplicaId;\n+    case ThunkProto::ImplCase::kYnnFusionThunk:\n+      return Thunk::Kind::kYnnFusion;\n     case ThunkProto::ImplCase::IMPL_NOT_SET:\n       return Internal(\"Thunk kind not set.\");\n   }\n@@ -724,6 +739,28 @@ static absl::Status ToProto(const WhileThunk& thunk, ThunkProto& proto) {\n   return absl::OkStatus();\n }\n \n+#ifdef XLA_YNNPACK\n+static absl::Status ToProto(const YnnFusionThunk& thunk, ThunkProto& proto) {\n+  YnnFusionThunkProto* ynn_fusion_proto = proto.mutable_ynn_fusion_thunk();\n+  ynn_fusion_proto->mutable_options()->set_use_threadpool(\n+      thunk.options().use_threadpool);\n+  ynn_fusion_proto->set_instruction_id(thunk.hlo()->unique_id());\n+\n+  for (const YnnFusionThunk::Argument& argument : thunk.arguments()) {\n+    TF_RETURN_IF_ERROR(\n+        SerializeSliceShapeIntoProto(argument.slice, argument.shape,\n+                                     ynn_fusion_proto->add_arguments_shapes()));\n+  }\n+\n+  for (const YnnFusionThunk::Result& result : thunk.results()) {\n+    TF_RETURN_IF_ERROR(SerializeSliceShapeIntoProto(\n+        result.slice, result.shape, ynn_fusion_proto->add_results_shapes()));\n+  }\n+\n+  return absl::OkStatus();\n+}\n+#endif  // XLA_YNNPACK\n+\n static absl::Status ToProto(const XnnFusionThunk& thunk, ThunkProto& proto) {\n   // TODO(basioli) XnnFusionThunk is not serializable because it contains\n   // a builder function that is not serializable.\n@@ -984,6 +1021,12 @@ absl::StatusOr<ThunkProto> ThunkSerDesProtobuf::ToProto(\n                   internal::LogicalIdKind::kReplicaId>&>(thunk)),\n           proto));\n       break;\n+#ifdef XLA_YNNPACK\n+    case Thunk::Kind::kYnnFusion:\n+      TF_RETURN_IF_ERROR(::xla::cpu::ToProto(\n+          tsl::down_cast<const YnnFusionThunk&>(thunk), proto));\n+      break;\n+#endif  // XLA_YNNPACK\n     default:\n       return absl::UnimplementedError(\n           absl::StrFormat(\"ToProto is not implemented for thunk kind: %s\",\n@@ -1514,6 +1557,86 @@ static absl::StatusOr<std::unique_ptr<WhileThunk>> WhileThunkFromProto(\n                             std::move(*body_sequence), trip_count);\n }\n \n+#ifdef XLA_YNNPACK\n+static absl::StatusOr<std::unique_ptr<YnnFusionThunk>> YnnFusionThunkFromProto(\n+    const ThunkProto& proto, const HloModule* hlo_module,\n+    const std::vector<BufferAllocation>& buffer_allocations) {\n+  const YnnFusionThunkProto& ynn_fusion_proto = proto.ynn_fusion_thunk();\n+\n+  YnnFusionThunk::Options options = {\n+      ynn_fusion_proto.options().use_threadpool(),\n+  };\n+\n+  TF_ASSIGN_OR_RETURN(Thunk::Info info, ThunkInfoFromProto(proto.info()));\n+\n+  const HloInstruction* hlo = std::invoke([&]() -> const HloInstruction* {\n+    for (const HloComputation* computation : hlo_module->computations()) {\n+      for (const HloInstruction* instruction : computation->instructions()) {\n+        if (instruction->unique_id() == ynn_fusion_proto.instruction_id()) {\n+          return instruction;\n+        }\n+      }\n+    }\n+    return nullptr;\n+  });\n+\n+  if (hlo == nullptr) {\n+    return Internal(\n+        \"HLO instruction with unique id %d not found in the HLO module\",\n+        ynn_fusion_proto.instruction_id());\n+  }\n+\n+  std::vector<YnnFusionThunk::Argument> arguments;\n+  for (auto& argument_shape_proto : ynn_fusion_proto.arguments_shapes()) {\n+    TF_ASSIGN_OR_RETURN(auto argument_shape,\n+                        DeserializeSliceShapeFromProto(argument_shape_proto,\n+                                                       buffer_allocations));\n+    arguments.push_back(\n+        YnnFusionThunk::Argument{argument_shape.first, argument_shape.second});\n+  }\n+\n+  std::vector<YnnFusionThunk::Result> results;\n+  for (auto& result_shape_proto : ynn_fusion_proto.results_shapes()) {\n+    TF_ASSIGN_OR_RETURN(\n+        auto result_shape,\n+        DeserializeSliceShapeFromProto(result_shape_proto, buffer_allocations));\n+    results.push_back(\n+        YnnFusionThunk::Result{result_shape.first, result_shape.second});\n+  }\n+\n+  absl::AnyInvocable<absl::StatusOr<YnnSubgraph>(\n+      absl::Span<const se::DeviceMemoryBase> arguments_buffers)>\n+      builder;\n+  absl::Span<const int64_t> captured_arguments_ids;\n+  if (hlo->opcode() == HloOpcode::kDot) {\n+    const HloDotInstruction* dot = Cast<HloDotInstruction>(hlo);\n+    // TODO(b/455903737): If we know the RHS is a constant, we should capture it\n+    // here.\n+    bool capture_rhs = false;\n+    // Construct YNNPACK subgraph builder from the dot instruction.\n+    TF_ASSIGN_OR_RETURN(builder, EmitYnnDotBuilder(dot, capture_rhs));\n+    static constexpr int64_t kCapturedIds[1] = {1};\n+    if (capture_rhs) {\n+      captured_arguments_ids = kCapturedIds;\n+    }\n+  } else {\n+    auto* fusion = Cast<HloFusionInstruction>(hlo);\n+    const HloComputation* computation =\n+        fusion->fused_instructions_computation();\n+    // Construct YNNPACK subgraph builder from the fusion computation.\n+    TF_ASSIGN_OR_RETURN(builder, EmitYnnFusionBuilder(computation));\n+  }\n+\n+  return YnnFusionThunk::Create(\n+      std::move(options), std::move(info), hlo, std::move(arguments),\n+      std::move(results),\n+      [b = std::move(builder)](auto, auto, auto arg_buffers) mutable {\n+        return b(arg_buffers);\n+      },\n+      captured_arguments_ids);\n+}\n+#endif  // XLA_YNNPACK\n+\n static absl::StatusOr<std::unique_ptr<XnnFusionThunk>> XnnFusionThunkFromProto(\n     const ThunkProto& proto,\n     const std::vector<BufferAllocation>& buffer_allocations) {\n@@ -1712,6 +1835,10 @@ absl::StatusOr<std::unique_ptr<Thunk>> ThunkSerDesProtobuf::FromProto(\n       return PartitionIdThunkFromProto(proto, *buffer_allocations_);\n     case Thunk::Kind::kReplicaId:\n       return ReplicaIdThunkFromProto(proto, *buffer_allocations_);\n+#ifdef XLA_YNNPACK\n+    case Thunk::Kind::kYnnFusion:\n+      return YnnFusionThunkFromProto(proto, hlo_module_, *buffer_allocations_);\n+#endif  // XLA_YNNPACK\n     default:\n       return absl::Status(absl::StatusCode::kInvalidArgument,\n                           absl::StrFormat(\"Unsupported thunk kind: %s\","
        },
        {
            "sha": "c8a41602e67a399c3368dca92f7fa3b4958fd9e8",
            "filename": "third_party/xla/xla/backends/cpu/runtime/ynnpack/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2FBUILD?ref=92cb28a9a5e9e2736994503551b879ebff07cd8f",
            "patch": "@@ -91,6 +91,7 @@ cc_library(\n         \":ynn_interop\",\n         \"//xla:shape_util\",\n         \"//xla/backends/cpu/runtime:thunk\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/runtime:buffer_use\",\n         \"//xla/runtime:object_pool\",\n         \"//xla/service:buffer_assignment\",\n@@ -129,6 +130,7 @@ ynn_cc_test(\n         \"//xla/backends/cpu/runtime:buffer_allocations\",\n         \"//xla/backends/cpu/runtime:thunk\",\n         \"//xla/backends/cpu/runtime:thunk_testlib\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:statusor\","
        },
        {
            "sha": "ee6a1bcdfc037b7f95dbecc7a3478e190c830e39",
            "filename": "third_party/xla/xla/backends/cpu/runtime/ynnpack/ynn_fusion_thunk.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 6,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2Fynn_fusion_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2Fynn_fusion_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2Fynn_fusion_thunk.cc?ref=92cb28a9a5e9e2736994503551b879ebff07cd8f",
            "patch": "@@ -37,6 +37,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/cpu/runtime/thunk.h\"\n #include \"xla/backends/cpu/runtime/ynnpack/ynn_interop.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/runtime/buffer_use.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n@@ -230,43 +231,49 @@ std::vector<se::DeviceMemoryBase> YnnFusionThunk::CaptureArguments(\n }\n \n absl::StatusOr<std::unique_ptr<YnnFusionThunk>> YnnFusionThunk::Create(\n-    Options options, Info info, std::vector<Argument> arguments,\n-    std::vector<Result> results, Builder builder) {\n+    Options options, Info info, const HloInstruction* hlo,\n+    std::vector<Argument> arguments, std::vector<Result> results,\n+    Builder builder) {\n   return absl::WrapUnique(new YnnFusionThunk(\n-      YnnFusionKind::kFusion, std::move(options), std::move(info),\n+      YnnFusionKind::kFusion, std::move(options), std::move(info), hlo,\n       std::move(arguments), std::move(results), std::move(builder)));\n }\n \n absl::StatusOr<std::unique_ptr<YnnFusionThunk>> YnnFusionThunk::Create(\n-    Options options, Info info, std::vector<Argument> arguments,\n-    std::vector<Result> results, CapturingBuilder capturing_builder,\n+    Options options, Info info, const HloInstruction* hlo,\n+    std::vector<Argument> arguments, std::vector<Result> results,\n+    CapturingBuilder capturing_builder,\n     absl::Span<const int64_t> captured_arguments_ids) {\n   return absl::WrapUnique(new YnnFusionThunk(\n-      YnnFusionKind::kFusion, std::move(options), std::move(info),\n+      YnnFusionKind::kFusion, std::move(options), std::move(info), hlo,\n       std::move(arguments), std::move(results), std::move(capturing_builder),\n       captured_arguments_ids));\n }\n \n YnnFusionThunk::YnnFusionThunk(YnnFusionKind kind, Options options, Info info,\n+                               const HloInstruction* hlo,\n                                std::vector<Argument> arguments,\n                                std::vector<Result> results, Builder builder)\n     : Thunk(Kind::kYnnFusion, std::move(info)),\n       ynn_fusion_kind_(kind),\n       options_(std::move(options)),\n+      hlo_(hlo),\n       arguments_(std::move(arguments)),\n       results_(std::move(results)),\n       builder_(std::move(builder)),\n       ynn_executable_pool_(\n           absl::bind_front(&YnnFusionThunk::CreateYnnExecutable, this)) {}\n \n YnnFusionThunk::YnnFusionThunk(YnnFusionKind kind, Options options, Info info,\n+                               const HloInstruction* hlo,\n                                std::vector<Argument> arguments,\n                                std::vector<Result> results,\n                                CapturingBuilder capturing_builder,\n                                absl::Span<const int64_t> captured_arguments_ids)\n     : Thunk(Kind::kYnnFusion, std::move(info)),\n       ynn_fusion_kind_(kind),\n       options_(std::move(options)),\n+      hlo_(hlo),\n       arguments_(std::move(arguments)),\n       results_(std::move(results)),\n       capturing_builder_(std::move(capturing_builder)),"
        },
        {
            "sha": "19518575a3f1e7528ece4e20a30c4f146c1d784d",
            "filename": "third_party/xla/xla/backends/cpu/runtime/ynnpack/ynn_fusion_thunk.h",
            "status": "modified",
            "additions": 20,
            "deletions": 7,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2Fynn_fusion_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2Fynn_fusion_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2Fynn_fusion_thunk.h?ref=92cb28a9a5e9e2736994503551b879ebff07cd8f",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/cpu/runtime/thunk.h\"\n #include \"xla/backends/cpu/runtime/ynnpack/ynn_interop.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/runtime/object_pool.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/shape.h\"\n@@ -86,12 +87,14 @@ class YnnFusionThunk : public Thunk {\n       absl::Span<const se::DeviceMemoryBase> arguments_buffers)>;\n \n   static absl::StatusOr<std::unique_ptr<YnnFusionThunk>> Create(\n-      Options options, Info info, std::vector<Argument> arguments,\n-      std::vector<Result> results, Builder builder);\n+      Options options, Info info, const HloInstruction* hlo,\n+      std::vector<Argument> arguments, std::vector<Result> results,\n+      Builder builder);\n \n   static absl::StatusOr<std::unique_ptr<YnnFusionThunk>> Create(\n-      Options options, Info info, std::vector<Argument> arguments,\n-      std::vector<Result> results, CapturingBuilder capturing_builder,\n+      Options options, Info info, const HloInstruction* hlo,\n+      std::vector<Argument> arguments, std::vector<Result> results,\n+      CapturingBuilder capturing_builder,\n       absl::Span<const int64_t> captured_arguments_ids);\n \n   tsl::AsyncValueRef<ExecuteEvent> Execute(const ExecuteParams& params) final;\n@@ -104,13 +107,19 @@ class YnnFusionThunk : public Thunk {\n \n   YnnFusionKind ynn_fusion_kind() const { return ynn_fusion_kind_; }\n \n+  const HloInstruction* hlo() const { return hlo_; }\n+\n+  absl::Span<const Argument> arguments() const { return arguments_; }\n+  absl::Span<const Result> results() const { return results_; }\n+\n  protected:\n   YnnFusionThunk(YnnFusionKind kind, Options options, Info info,\n-                 std::vector<Argument> arguments, std::vector<Result> results,\n-                 Builder builder);\n+                 const HloInstruction* hlo, std::vector<Argument> arguments,\n+                 std::vector<Result> results, Builder builder);\n \n   YnnFusionThunk(YnnFusionKind kind, Options options, Info info,\n-                 std::vector<Argument> arguments, std::vector<Result> results,\n+                 const HloInstruction* hlo, std::vector<Argument> arguments,\n+                 std::vector<Result> results,\n                  CapturingBuilder capturing_builder,\n                  absl::Span<const int64_t> captured_arguments_ids);\n \n@@ -151,6 +160,10 @@ class YnnFusionThunk : public Thunk {\n   YnnFusionKind ynn_fusion_kind_;\n   Options options_;\n \n+  // A pointer to the HLO instruction that this thunk is associated with. Owned\n+  // by the `HloModule` associated with the XLA executable.\n+  const HloInstruction* hlo_;  // not owned\n+\n   std::vector<Argument> arguments_;\n   std::vector<Result> results_;\n "
        },
        {
            "sha": "8a1c79540ac5302bfe44b2b41635ac39a8cfda29",
            "filename": "third_party/xla/xla/backends/cpu/runtime/ynnpack/ynn_fusion_thunk_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2Fynn_fusion_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2Fynn_fusion_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fynnpack%2Fynn_fusion_thunk_test.cc?ref=92cb28a9a5e9e2736994503551b879ebff07cd8f",
            "patch": "@@ -30,6 +30,7 @@ limitations under the License.\n #include \"xla/backends/cpu/runtime/thunk_testlib.h\"\n #include \"xla/backends/cpu/runtime/ynnpack/ynn_interop.h\"\n #include \"xla/backends/cpu/runtime/ynnpack/ynn_threadpool.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/literal_util.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n@@ -130,6 +131,7 @@ TEST_P(YnnFusionThunkTest, ElementwiseAdd) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto thunk, YnnFusionThunk::Create(\n                       YnnFusionThunk::Options{use_threadpool()}, {\"fusion\"},\n+                      reinterpret_cast<HloInstruction*>(0xDEADBEEF),\n                       {lhs_arg, rhs_arg}, {out_res}, &BuildBinaryAddSubgraph));\n \n   YnnThreadpool threadpool;"
        },
        {
            "sha": "fb6842e92c2cb7d44c0345214c4e80cfba240621",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client_test.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 2,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc?ref=92cb28a9a5e9e2736994503551b879ebff07cd8f",
            "patch": "@@ -1063,14 +1063,27 @@ TEST(PjRtCpuClientTest, SerializeYnnFusions) {\n                                         literal, client->memory_spaces()[0]));\n \n   ExecuteOptions opts;\n-  auto result =\n-      executable->Execute(/*argument_handles=*/{{buf.get(), buf.get()}}, opts);\n+  auto result = executable->Execute({{buf.get(), buf.get()}}, opts);\n \n   TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<xla::Literal> result_literal,\n                           result->at(0).at(0)->ToLiteralSync());\n   EXPECT_TRUE(LiteralTestUtil::Equal(\n       LiteralUtil::CreateR1<float>({4.0f, 16.0f, 36.0f, 64.0f}),\n       *result_literal));\n+\n+  // Check that serialized/deserialized executable works and produces the same\n+  // result.\n+  TF_ASSERT_OK_AND_ASSIGN(std::string serialized,\n+                          executable->SerializeExecutable());\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto reloaded_executable,\n+      client->LoadSerializedExecutable(serialized, std::nullopt, {}));\n+\n+  result = executable->Execute({{buf.get(), buf.get()}}, opts);\n+  TF_ASSERT_OK_AND_ASSIGN(result_literal, result->at(0).at(0)->ToLiteralSync());\n+  EXPECT_TRUE(LiteralTestUtil::Equal(\n+      LiteralUtil::CreateR1<float>({4.0f, 16.0f, 36.0f, 64.0f}),\n+      *result_literal));\n }\n \n }  // namespace"
        },
        {
            "sha": "85fd32ca8f14491dc47ab837fa5caa9231e05b49",
            "filename": "third_party/xla/xla/service/cpu/thunk_emitter.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/92cb28a9a5e9e2736994503551b879ebff07cd8f/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc?ref=92cb28a9a5e9e2736994503551b879ebff07cd8f",
            "patch": "@@ -1571,8 +1571,8 @@ absl::StatusOr<ThunkSequence> ThunkEmitter::EmitYnnFusionThunk(\n   }\n \n   return ThunkSequence::Of<YnnFusionThunk>(\n-      YnnFusionThunk::Options{}, ThunkInfo(instruction), std::move(arguments),\n-      std::move(results),\n+      YnnFusionThunk::Options{}, ThunkInfo(instruction), instruction,\n+      std::move(arguments), std::move(results),\n       [b = std::move(builder)](auto, auto, auto arg_buffers) mutable {\n         return b(arg_buffers);\n       },"
        }
    ],
    "stats": {
        "total": 208,
        "additions": 191,
        "deletions": 17
    }
}