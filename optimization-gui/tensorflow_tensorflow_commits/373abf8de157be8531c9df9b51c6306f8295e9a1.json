{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Add support for strided extract/insert tile.\n\nPiperOrigin-RevId: 822035319",
    "sha": "373abf8de157be8531c9df9b51c6306f8295e9a1",
    "files": [
        {
            "sha": "fd79949e60e36121440a8d66e070c3721aaa5aa2",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373abf8de157be8531c9df9b51c6306f8295e9a1/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373abf8de157be8531c9df9b51c6306f8295e9a1/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=373abf8de157be8531c9df9b51c6306f8295e9a1",
            "patch": "@@ -255,6 +255,7 @@ static void AddTiledLoweringPasses(mlir::OpPassManager& pm) {\n   pm.addPass(mlir::createConvertVectorToLLVMPass());\n \n   pm.addPass(mlir::createConvertComplexToStandardPass());\n+  pm.addPass(mlir::memref::createExpandStridedMetadataPass());\n \n   AddGenericLoweringPasses(pm);\n }"
        },
        {
            "sha": "4fbb7a0eee3f938521b8e045f291eda15c96c2a3",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/tiled_kernel_test.py",
            "status": "modified",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373abf8de157be8531c9df9b51c6306f8295e9a1/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373abf8de157be8531c9df9b51c6306f8295e9a1/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py?ref=373abf8de157be8531c9df9b51c6306f8295e9a1",
            "patch": "@@ -98,6 +98,30 @@ def test_slice(self):\n         lambda arg: arg.transpose(),\n     )\n \n+  def test_strided(self):\n+    ir = \"\"\"\n+      module @tiled_slice {\n+        xtile.entry_func @tiled_slice(\n+            %input: memref<64x64xf32>,\n+            %output: memref<4x32xf32>,\n+            %tile_id: index) attributes {xtile.tiling_info = #xtile.tiling_info<tile_count:1, tiles_per_workgroup:1>} {\n+          %input_tile = xtile.extract %input[%tile_id, %tile_id][4, 32][21, 2] : memref<64x64xf32> -> tensor<4x32xf32>\n+          xtile.insert %input_tile into %output[%tile_id, %tile_id][4, 32][1, 1] : tensor<4x32xf32> -> memref<4x32xf32>\n+          xtile.return\n+        }\n+      }\n+    \"\"\"\n+\n+    compare_kernel(\n+        ir,\n+        \"tiled_slice\",\n+        1,\n+        [(64, 64)],\n+        (4, 32),\n+        np.float32,\n+        lambda arg: arg[::21, ::2],\n+    )\n+\n   def test_transpose(self):\n     ir = \"\"\"\n       module @tiled_transpose {"
        },
        {
            "sha": "aa1f510ba7a5e58df62025516b3c6a807068e51c",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373abf8de157be8531c9df9b51c6306f8295e9a1/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373abf8de157be8531c9df9b51c6306f8295e9a1/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD?ref=373abf8de157be8531c9df9b51c6306f8295e9a1",
            "patch": "@@ -72,11 +72,13 @@ cc_library(\n         \"@llvm-project//mlir:LLVMDialect\",\n         \"@llvm-project//mlir:MathDialect\",\n         \"@llvm-project//mlir:MathOpsIncGen\",\n+        \"@llvm-project//mlir:MemRefDialect\",\n         \"@llvm-project//mlir:Pass\",\n         \"@llvm-project//mlir:SCFDialect\",\n         \"@llvm-project//mlir:Support\",\n         \"@llvm-project//mlir:TensorDialect\",\n         \"@llvm-project//mlir:TransformUtils\",\n+        \"@llvm-project//mlir:UBDialect\",\n         \"@llvm-project//mlir:VectorDialect\",\n         \"@stablehlo//:stablehlo_ops\",\n     ],"
        },
        {
            "sha": "d4ba7a6a99183a550f456b908f8b957a3802aab9",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tests/xtile_to_vector.mlir",
            "status": "modified",
            "additions": 37,
            "deletions": 9,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373abf8de157be8531c9df9b51c6306f8295e9a1/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fxtile_to_vector.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373abf8de157be8531c9df9b51c6306f8295e9a1/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fxtile_to_vector.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fxtile_to_vector.mlir?ref=373abf8de157be8531c9df9b51c6306f8295e9a1",
            "patch": "@@ -1,30 +1,58 @@\n-// RUN: emitters_opt %s --xtile-cpu-xtile-to-vector -split-input-file | FileCheck %s\n+// RUN: emitters_opt %s --xtile-cpu-xtile-to-vector -cse -split-input-file | FileCheck %s\n \n // CHECK-LABEL: @simple_insert_extract\n // CHECK-SAME: (%[[INPUT:.*]]: memref<1024xf32>, %[[OUTPUT:.*]]: memref<1024xf32>, %[[TILE_ID:.*]]: index)\n xtile.entry_func @simple_insert_extract(%input: memref<1024xf32>, %output: memref<1024xf32>, %tile_id: index) {\n   // CHECK-DAG: %[[POISON:.*]] = ub.poison : f32\n-  // CHECK: %[[EXTRACT:.*]] = vector.transfer_read %[[INPUT]][%[[TILE_ID]]], %[[POISON]] : memref<1024xf32>, vector<1xf32>\n+  // CHECK-DAG: %[[C_0:.*]] = arith.constant 0 : index\n+  // CHECK: %[[IN_SUBVIEW:.*]] = memref.subview %[[INPUT]][%[[TILE_ID]]] [1] [1]\n+  // CHECK-SAME: memref<1024xf32> to memref<1xf32, strided<[1], offset: ?>>\n+  // CHECK: %[[MASK:.*]] = vector.create_mask\n+  // CHECK: %[[EXTRACT:.*]] = vector.transfer_read %[[IN_SUBVIEW]][%[[C_0]]], %[[POISON]], %[[MASK]]\n   %tile = xtile.extract %input[%tile_id][1][1] : memref<1024xf32> -> tensor<1xf32>\n-  // CHECK: vector.transfer_write %[[EXTRACT]], %[[OUTPUT]][%[[TILE_ID]]] : vector<1xf32>, memref<1024xf32>\n+  // CHECK: %[[OUT_SUBVIEW:.*]] = memref.subview %[[OUTPUT]][%[[TILE_ID]]] [1] [1]\n+  // CHECK-SAME: memref<1024xf32> to memref<1xf32, strided<[1], offset: ?>>\n+  // CHECK: vector.transfer_write %[[EXTRACT]], %[[OUT_SUBVIEW]][%[[C_0]]], %[[MASK]]\n   xtile.insert %tile into %output[%tile_id][1][1] : tensor<1xf32> -> memref<1024xf32>\n   xtile.return\n }\n \n-\n // -----\n \n-// CHECK: #[[MAP:.*]] = affine_map<(d0, d1) -> (d0)>\n // CHECK: @reduce_dimension(%[[INPUT:.*]]: memref<16x1024xf32>, %[[OUTPUT:.*]]: memref<16x1024xf32>, %[[TILE_ID:.*]]: index)\n xtile.entry_func @reduce_dimension(%input: memref<16x1024xf32>, %output: memref<16x1024xf32>, %tile_id: index) {\n-  // CHECK: %[[OFFSET:.*]] = arith.constant 0 : index\n+  // CHECK: %[[C_0:.*]] = arith.constant 0 : index\n   %offset = arith.constant 0 : index\n-  // CHECK: %[[POISON:.*]] = ub.poison : f32\n-  // CHECK: %[[EXTRACT:.*]] = vector.transfer_read %[[INPUT]][%[[OFFSET]], %[[TILE_ID]]], %[[POISON]] {in_bounds = [true], permutation_map = #[[MAP]]} : memref<16x1024xf32>, vector<10xf32>\n-  // CHECK: vector.transfer_write %[[EXTRACT]], %[[OUTPUT]][%[[OFFSET]], %[[TILE_ID]]] {in_bounds = [true], permutation_map = #[[MAP]]} : vector<10xf32>, memref<16x1024xf32>\n+  // CHECK: memref.subview %[[INPUT]][%[[C_0]], %[[TILE_ID]]] [10, 1] [1, 1]\n+  // CHECK-SAME: memref<16x1024xf32> to memref<10xf32, strided<[1024], offset: ?>>\n   %tile = xtile.extract %input[%offset, %tile_id][10, 1][1, 1] : memref<16x1024xf32> -> tensor<10xf32>\n+  // CHECK: memref.subview %[[OUTPUT]][%[[C_0]], %[[TILE_ID]]] [10, 1] [1, 1]\n+  // CHECK-SAME: memref<16x1024xf32> to memref<10xf32, strided<[1024], offset: ?>>\n   xtile.insert %tile into %output[%offset, %tile_id][10, 1][1, 1] : tensor<10xf32> -> memref<16x1024xf32>\n   xtile.return\n }\n \n // -----\n+\n+// CHECK: @extract_strided(%[[SOURCE:.*]]: memref<16xf32>, %[[TILE_ID:.*]]: index)\n+func.func @extract_strided(%source: memref<16xf32>, %tile_id: index) -> tensor<8xf32> {\n+  // CHECK: memref.subview %[[SOURCE]][%[[TILE_ID]]] [8] [2] :\n+  // CHECK-SAME: memref<16xf32> to memref<8xf32, strided<[2], offset: ?>>\n+  %tile = xtile.extract %source[%tile_id][8][2] : memref<16xf32> -> tensor<8xf32>\n+  return %tile : tensor<8xf32>\n+}\n+\n+// -----\n+\n+// CHECK: @insert_strided(\n+// CHECK-SAME: %[[SOURCE:.*]]: tensor<8xf32>,\n+// CHECK-SAME: %[[DESTINATION:.*]]: memref<16xf32>,\n+// CHECK-SAME: %[[TILE_ID:.*]]: index)\n+func.func @insert_strided(%source: tensor<8xf32>, %destination: memref<16xf32>, %tile_id: index) {\n+  // CHECK: memref.subview %[[DESTINATION]][%[[TILE_ID]]] [8] [2] :\n+  // CHECK-SAME: memref<16xf32> to memref<8xf32, strided<[2], offset: ?>>\n+  xtile.insert %source into %destination[%tile_id][8][2] : tensor<8xf32> -> memref<16xf32>\n+  return\n+}\n+\n+"
        },
        {
            "sha": "f7c6f2fc8f36041e1bf1a3518f84693099b3a817",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/xtile_to_vector.cc",
            "status": "modified",
            "additions": 130,
            "deletions": 33,
            "changes": 163,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373abf8de157be8531c9df9b51c6306f8295e9a1/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fxtile_to_vector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373abf8de157be8531c9df9b51c6306f8295e9a1/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fxtile_to_vector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fxtile_to_vector.cc?ref=373abf8de157be8531c9df9b51c6306f8295e9a1",
            "patch": "@@ -14,25 +14,38 @@ limitations under the License.\n ==============================================================================*/\n \n #include <cassert>\n+#include <cstdint>\n #include <memory>\n #include <optional>\n #include <utility>\n \n+#include \"absl/algorithm/container.h\"\n+#include \"llvm/ADT/ArrayRef.h\"\n #include \"llvm/ADT/DenseSet.h\"\n+#include \"llvm/ADT/STLExtras.h\"\n+#include \"llvm/ADT/SmallVector.h\"\n+#include \"llvm/ADT/SmallVectorExtras.h\"\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"  // IWYU pragma: keep\n+#include \"mlir/Dialect/MemRef/IR/MemRef.h\"\n+#include \"mlir/Dialect/UB/IR/UBOps.h\"\n #include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n #include \"mlir/IR/AffineExpr.h\"\n+#include \"mlir/IR/Attributes.h\"\n+#include \"mlir/IR/Builders.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n-#include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/IR/OpDefinition.h\"\n #include \"mlir/IR/PatternMatch.h\"\n #include \"mlir/IR/Value.h\"\n+#include \"mlir/IR/ValueRange.h\"\n #include \"mlir/IR/Visitors.h\"\n #include \"mlir/Pass/Pass.h\"\n #include \"mlir/Support/LLVM.h\"\n #include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"xla/backends/cpu/codegen/tiled/transforms/lowering_utils.h\"\n #include \"xla/backends/cpu/codegen/tiled/transforms/passes.h\"\n #include \"xla/codegen/xtile/ir/xtile_ops.h\"\n \n@@ -44,34 +57,115 @@ namespace xla::cpu {\n \n namespace {\n \n-mlir::AffineMap GetFilteredDims(mlir::MLIRContext* context, unsigned rank,\n-                                llvm::SmallDenseSet<unsigned> reduced_dims) {\n-  return mlir::AffineMap::getFilteredIdentityMap(\n-      context, rank, [&reduced_dims](mlir::AffineDimExpr dim) {\n-        return !reduced_dims.contains(dim.getPosition());\n-      });\n+// Dims are dropped in the subview so we use the identity map.\n+mlir::AffineMapAttr GetIdentityMap(xtile::TiledBufferInterface op) {\n+  int64_t rank = op.getTile().getType().getRank();\n+  return mlir::AffineMapAttr::get(\n+      mlir::AffineMap::getMultiDimIdentityMap(rank, op.getContext()));\n+}\n+\n+mlir::TypedValue<mlir::MemRefType> GetSubView(\n+    mlir::ImplicitLocOpBuilder& builder, xtile::TiledBufferInterface op) {\n+  auto get_static_fold_result = [&](llvm::ArrayRef<int64_t> input) {\n+    return llvm::map_to_vector(input, [&builder](int64_t value) {\n+      return mlir::OpFoldResult(builder.getIndexAttr(value));\n+    });\n+  };\n+\n+  auto offsets = llvm::SmallVector<mlir::OpFoldResult>(op.getOffsets());\n+  auto full_tile_shape = get_static_fold_result(op.getFullTileShape());\n+  auto strides = get_static_fold_result(op.getStrides());\n+\n+  mlir::MemRefType subview_type =\n+      mlir::memref::SubViewOp::inferRankReducedResultType(\n+          op.getTile().getType().getShape(), op.getBuffer().getType(), offsets,\n+          full_tile_shape, get_static_fold_result(op.getStrides()));\n+\n+  return builder.create<mlir::memref::SubViewOp>(\n+      subview_type, op.getBuffer(), offsets, full_tile_shape, strides);\n+}\n+\n+llvm::SmallVector<mlir::Value> GetZeroIndexVector(\n+    mlir::ImplicitLocOpBuilder& builder, int64_t rank) {\n+  return llvm::SmallVector<mlir::Value>(\n+      rank, builder.create<mlir::arith::ConstantIndexOp>(0));\n+}\n+\n+mlir::ArrayAttr GetInBoundsAttr(mlir::ImplicitLocOpBuilder& builder,\n+                                int64_t rank) {\n+  // TODO(willfroom): Add proper support for inBounds attr.\n+  llvm::SmallVector<mlir::Attribute> in_bounds(rank,\n+                                               builder.getBoolAttr(false));\n+  return builder.getArrayAttr(in_bounds);\n+}\n+\n+// Get the mask for the given transfer_<read/write> op on a subview of the\n+// original memeref.\n+// The inequality we need to satisfy in 1D is:\n+//  1. offset + subview_idx * stride <= size - 1\n+//  2. subview_idx * stride <= size - 1 - offset\n+//  3. subview_idx <= (size - 1 - offset) / stride\n+//  4. subview_idx < ((size - 1 - offset) / stride) + 1\n+//  5. subview_idx < (size + stride - 1 - offset) / stride\n+mlir::Value GetMask(mlir::ImplicitLocOpBuilder& builder,\n+                    xtile::TiledBufferInterface op) {\n+  mlir::RankedTensorType tile_tensor_type = op.getTile().getType();\n+\n+  auto get_const_index_op = [&](int64_t value) {\n+    return builder.create<mlir::arith::ConstantIndexOp>(value);\n+  };\n+\n+  if (tile_tensor_type.getRank() == 0) {\n+    // Vector transfer read/write currently don't support 0D masks.\n+    auto mask_0D_type = mlir::VectorType::get({1}, builder.getI1Type());\n+    return builder.create<mlir::vector::CreateMaskOp>(\n+        mask_0D_type, mlir::OpFoldResult(builder.getIndexAttr(1)));\n+  }\n+\n+  llvm::SmallDenseSet<unsigned> reduced_dims = op.getReducedDimensions();\n+  llvm::SmallVector<mlir::Value> upper_bounds;\n+  int64_t idx = 0;\n+  for (auto [offset, size, stride] :\n+       llvm::zip(op.getOffsets(), op.getBuffer().getType().getShape(),\n+                 op.getStrides())) {\n+    if (reduced_dims.contains(idx++)) {\n+      continue;\n+    }\n+    upper_bounds.push_back(builder.create<mlir::arith::DivSIOp>(\n+        builder.create<mlir::arith::SubIOp>(\n+            get_const_index_op(size + stride - 1), offset),\n+        get_const_index_op(stride)));\n+  }\n+\n+  auto mask_type = mlir::VectorType::get(op.getTile().getType().getShape(),\n+                                         builder.getI1Type());\n+  return builder.create<mlir::vector::CreateMaskOp>(mask_type, upper_bounds);\n }\n \n struct LowerExtractTile : mlir::OpRewritePattern<xtile::ExtractTileOp> {\n   using OpRewritePattern::OpRewritePattern;\n \n   mlir::LogicalResult matchAndRewrite(\n       xtile::ExtractTileOp op, mlir::PatternRewriter& rewriter) const override {\n-    mlir::RankedTensorType dest_tensor_type = op.getResult().getType();\n-    auto vector_type = mlir::VectorType::get(dest_tensor_type.getShape(),\n-                                             dest_tensor_type.getElementType());\n+    mlir::ImplicitLocOpBuilder builder(op->getLoc(), rewriter);\n+    auto vector_type = GetVectorType(op.getResult().getType());\n+\n+    mlir::TypedValue<mlir::MemRefType> buffer_subview = GetSubView(builder, op);\n+\n+    int64_t reduced_rank = vector_type.getRank();\n+\n+    // The subview is already offset so the read has zero offsets.\n+    auto zero_index = GetZeroIndexVector(builder, reduced_rank);\n+    mlir::Value padding =\n+        builder.create<mlir::ub::PoisonOp>(vector_type.getElementType());\n+    mlir::Value mask = GetMask(builder, op);\n+    auto in_bounds = GetInBoundsAttr(builder, reduced_rank);\n \n-    // TODO(willfroom): Add support for inBounds attr.\n     mlir::Value vector_value = rewriter.create<mlir::vector::TransferReadOp>(\n-        op->getLoc(), vector_type, op.getSource(), op.getOffsets(),\n-        /*padding=*/std::nullopt,\n-        GetFilteredDims(rewriter.getContext(),\n-                        op.getSource().getType().getRank(),\n-                        op.getReducedDimensions()));\n-    mlir::UnrealizedConversionCastOp cast =\n-        rewriter.create<mlir::UnrealizedConversionCastOp>(\n-            op->getLoc(), op.getResult().getType(), vector_value);\n-    rewriter.replaceOp(op, cast);\n+        op->getLoc(), vector_type, buffer_subview, zero_index,\n+        GetIdentityMap(op), padding, mask, in_bounds);\n+\n+    rewriter.replaceOp(op, CastToTensor(builder, vector_value));\n     return mlir::success();\n   }\n };\n@@ -81,20 +175,23 @@ struct LowerInsertTile : mlir::OpRewritePattern<xtile::InsertTileOp> {\n \n   mlir::LogicalResult matchAndRewrite(\n       xtile::InsertTileOp op, mlir::PatternRewriter& rewriter) const override {\n-    mlir::RankedTensorType source_tensor_type = op.getSource().getType();\n-    auto vector_type = mlir::VectorType::get(\n-        source_tensor_type.getShape(), source_tensor_type.getElementType());\n-    mlir::Value cast = rewriter\n-                           .create<mlir::UnrealizedConversionCastOp>(\n-                               op->getLoc(), vector_type, op.getSource())\n-                           .getResult(0);\n-    // TODO(willfroom): Add support for inBounds attr.\n+    mlir::ImplicitLocOpBuilder builder(op->getLoc(), rewriter);\n+    mlir::TypedValue<mlir::VectorType> vector_tile =\n+        CastToVector(builder, op.getSource());\n+\n+    mlir::TypedValue<mlir::MemRefType> buffer_subview = GetSubView(builder, op);\n+\n+    int64_t reduced_rank = vector_tile.getType().getRank();\n+\n+    // The subview is already offset so the write has zero offsets.\n+    auto zero_index = GetZeroIndexVector(builder, reduced_rank);\n+    mlir::Value mask = GetMask(builder, op);\n+    auto in_bounds = GetInBoundsAttr(builder, reduced_rank);\n+\n     mlir::vector::TransferWriteOp transfer_write =\n-        rewriter.create<mlir::vector::TransferWriteOp>(\n-            op->getLoc(), cast, op.getDestination(), op.getOffsets(),\n-            GetFilteredDims(rewriter.getContext(),\n-                            op.getDestination().getType().getRank(),\n-                            op.getReducedDimensions()));\n+        builder.create<mlir::vector::TransferWriteOp>(\n+            vector_tile, buffer_subview, zero_index, GetIdentityMap(op), mask,\n+            in_bounds);\n \n     rewriter.replaceOp(op, transfer_write);\n     return mlir::success();"
        }
    ],
    "stats": {
        "total": 236,
        "additions": 194,
        "deletions": 42
    }
}