{
    "author": "loislo",
    "message": "[XLA:GPU] add nan count cuda kernel\n\nThe kernel is similar to the one for the checksum calculation\n\nPiperOrigin-RevId: 824428856",
    "sha": "78a0ca0b60bd15e1b1aac724799764777228dea5",
    "files": [
        {
            "sha": "f654c2b467027c5c54f8fc127cbf055c2b547c86",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 57,
            "deletions": 0,
            "changes": 57,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/78a0ca0b60bd15e1b1aac724799764777228dea5/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/78a0ca0b60bd15e1b1aac724799764777228dea5/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=78a0ca0b60bd15e1b1aac724799764777228dea5",
            "patch": "@@ -478,6 +478,63 @@ xla_test(\n     ],\n )\n \n+cuda_library(\n+    name = \"buffer_debug_nan_count_kernel_cuda\",\n+    srcs = [\"buffer_debug_nan_count_kernel_cuda.cu.cc\"],\n+    # copybara:uncomment compatible_with = [\"//buildenv/target:non_prod\"],\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+    ],\n+    deps = [\n+        \":cuda_platform\",\n+        \"//xla/backends/gpu/runtime:buffer_debug_log_structs\",\n+        \"//xla/backends/gpu/runtime:thunk_buffer_id\",\n+        \"//xla/stream_executor:kernel_spec\",\n+        \"//xla/stream_executor/gpu:buffer_debug_nan_count_kernel\",\n+        \"//xla/stream_executor/gpu:gpu_kernel_registry\",\n+        \"//xla/tsl/platform:logging\",\n+        \"@com_google_absl//absl/base\",\n+        \"@local_config_cuda//cuda:cuda_headers\",\n+    ],\n+    alwayslink = True,\n+)\n+\n+xla_test(\n+    name = \"buffer_debug_nan_count_kernel_cuda_test\",\n+    srcs = [\"buffer_debug_nan_count_kernel_cuda_test.cc\"],\n+    backends = [\"gpu\"],\n+    tags = [\"cuda-only\"],\n+    deps = [\n+        \":buffer_debug_nan_count_kernel_cuda\",\n+        \"//xla:types\",\n+        \"//xla/backends/gpu/runtime:buffer_debug_log_structs\",\n+        \"//xla/backends/gpu/runtime:thunk_buffer_id\",\n+        \"//xla/backends/gpu/runtime:thunk_id\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:launch_dim\",\n+        \"//xla/stream_executor:platform\",\n+        \"//xla/stream_executor:platform_manager\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor:stream_executor_memory_allocator\",\n+        \"//xla/stream_executor:typed_kernel_factory\",\n+        \"//xla/stream_executor/gpu:buffer_debug_log\",\n+        \"//xla/stream_executor/gpu:buffer_debug_nan_count_kernel\",\n+        \"//xla/stream_executor/gpu:gpu_kernel_registry\",\n+        \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/cleanup\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n cc_library(\n     name = \"cudnn_plugin\",\n     srcs = [\"cuda_dnn.cc\"],"
        },
        {
            "sha": "96fface75cf50924f8e318aa998a1f06155ca098",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_nan_count_kernel_cuda.cu.cc",
            "status": "added",
            "additions": 223,
            "deletions": 0,
            "changes": 223,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/78a0ca0b60bd15e1b1aac724799764777228dea5/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_nan_count_kernel_cuda.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/78a0ca0b60bd15e1b1aac724799764777228dea5/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_nan_count_kernel_cuda.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_nan_count_kernel_cuda.cu.cc?ref=78a0ca0b60bd15e1b1aac724799764777228dea5",
            "patch": "@@ -0,0 +1,223 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdint>\n+#include <cstdlib>\n+#include <cstring>\n+\n+#include \"absl/base/casts.h\"\n+#include \"third_party/gpus/cuda/include/cuda/atomic\"\n+#include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n+#include \"xla/stream_executor/cuda/cuda_platform.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_nan_count_kernel.h\"\n+#include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n+#include \"xla/stream_executor/kernel_spec.h\"\n+#include \"xla/tsl/platform/logging.h\"\n+\n+namespace se = stream_executor;\n+\n+namespace {\n+\n+__device__ unsigned int ThreadIdx() {\n+  return threadIdx.z * blockDim.y * blockDim.x + threadIdx.y * blockDim.x +\n+         threadIdx.x;\n+}\n+\n+__device__ unsigned int BlockIdx() {\n+  return blockIdx.z * gridDim.y * gridDim.x + blockIdx.y * gridDim.x +\n+         blockIdx.x;\n+}\n+\n+// Based on\n+// https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf\n+template <unsigned int BLOCK_SIZE>\n+__device__ void WarpReduceSum(unsigned int tid, volatile uint32_t* data) {\n+  if (BLOCK_SIZE >= 64) data[tid] += data[tid + 32];\n+  if (BLOCK_SIZE >= 32) data[tid] += data[tid + 16];\n+  if (BLOCK_SIZE >= 16) data[tid] += data[tid + 8];\n+  if (BLOCK_SIZE >= 8) data[tid] += data[tid + 4];\n+  if (BLOCK_SIZE >= 4) data[tid] += data[tid + 2];\n+  if (BLOCK_SIZE >= 2) data[tid] += data[tid + 1];\n+}\n+\n+__device__ inline bool IsNan(float v) { return isnan(v); }\n+__device__ inline bool IsNan(__nv_bfloat16 v) { return __isnan(v); }\n+\n+// Calculates count of NaNs of all elements of `input` and puts result in\n+// `output`.\n+//\n+// Optimized implementation based on\n+// https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf\n+// that takes advantage of `BLOCK_SIZE` threads.\n+//\n+// `BLOCK_SIZE` must be a power of 2 no larger than 1024.\n+template <typename T, unsigned int BLOCK_SIZE>\n+__device__ void ReduceSum(const T* input, uint64_t input_size,\n+                          uint32_t* output) {\n+  __shared__ uint32_t scratch[BLOCK_SIZE];\n+\n+  assert(BlockIdx() == 0);\n+  const unsigned int tid = ThreadIdx();\n+\n+  scratch[tid] = 0;\n+  for (unsigned int i = tid; i < input_size; i += BLOCK_SIZE) {\n+    if (IsNan(input[i])) {\n+      scratch[tid]++;\n+    }\n+  }\n+\n+  __syncthreads();\n+\n+  if (BLOCK_SIZE >= 1024) {\n+    if (tid < 512) {\n+      scratch[tid] += scratch[tid + 512];\n+    }\n+    __syncthreads();\n+  }\n+  if (BLOCK_SIZE >= 512) {\n+    if (tid < 256) {\n+      scratch[tid] += scratch[tid + 256];\n+    }\n+    __syncthreads();\n+  }\n+  if (BLOCK_SIZE >= 256) {\n+    if (tid < 128) {\n+      scratch[tid] += scratch[tid + 128];\n+    }\n+    __syncthreads();\n+  }\n+  if (BLOCK_SIZE >= 128) {\n+    if (tid < 64) {\n+      scratch[tid] += scratch[tid + 64];\n+    }\n+    __syncthreads();\n+  }\n+  if (tid < 32) WarpReduceSum<BLOCK_SIZE>(tid, scratch);\n+  if (tid == 0) *output = scratch[0];\n+}\n+\n+// Attempts to append the NaN count of the `input` buffer to the `log_entries`,\n+// using `log_header` to track available capacity and used space.\n+//\n+// The log entry is tagged with `entry_id`. The NaN count is parallelized as\n+// much as block dimensions allow it.\n+//\n+// If the log does not have enough space for the new entry, the entry is\n+// discarded.\n+//\n+// `input_size_in_bytes` is the size of the input buffer in bytes.\n+//\n+// LIMITATIONS:\n+// - Only a single thread block is supported.\n+// - Block dimensions must be a power of 2.\n+template <typename T>\n+__global__ void AppendNanCount(xla::gpu::ThunkBufferId entry_id, const T* input,\n+                               uint64_t input_size_in_bytes,\n+                               xla::gpu::BufferDebugLogHeader* log_header,\n+                               xla::gpu::BufferDebugLogEntry* log_entries) {\n+  const uint32_t block_size = blockDim.x * blockDim.y * blockDim.z;\n+  const uint64_t input_size = input_size_in_bytes / sizeof(T);\n+  uint32_t nan_count = 0;\n+\n+  assert(gridDim.x == 1 && gridDim.y == 1 && gridDim.z == 1);\n+  if (BlockIdx() != 0) {\n+    return;\n+  }\n+\n+  // https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/:\n+  // > CUDA architecture limits the numbers of threads per block (1024 threads\n+  // > per block limit).\n+  switch (block_size) {\n+    case 1024:\n+      ReduceSum<T, 1024>(input, input_size, &nan_count);\n+      break;\n+    case 512:\n+      ReduceSum<T, 512>(input, input_size, &nan_count);\n+      break;\n+    case 256:\n+      ReduceSum<T, 256>(input, input_size, &nan_count);\n+      break;\n+    case 128:\n+      ReduceSum<T, 128>(input, input_size, &nan_count);\n+      break;\n+    case 64:\n+      ReduceSum<T, 64>(input, input_size, &nan_count);\n+      break;\n+    case 32:\n+      ReduceSum<T, 32>(input, input_size, &nan_count);\n+      break;\n+    case 16:\n+      ReduceSum<T, 16>(input, input_size, &nan_count);\n+      break;\n+    case 8:\n+      ReduceSum<T, 8>(input, input_size, &nan_count);\n+      break;\n+    case 4:\n+      ReduceSum<T, 4>(input, input_size, &nan_count);\n+      break;\n+    case 2:\n+      ReduceSum<T, 2>(input, input_size, &nan_count);\n+      break;\n+    case 1:\n+      ReduceSum<T, 1>(input, input_size, &nan_count);\n+      break;\n+    default:\n+      // Unsupported block size.\n+      assert(false);\n+      return;\n+  }\n+\n+  if (ThreadIdx() == 0) {\n+    cuda::atomic_ref<uint32_t, cuda::thread_scope_system>\n+        nan_count_log_write_idx(log_header->write_idx);\n+#if __CUDA_ARCH__ >= 600\n+    const uint32_t write_idx = nan_count_log_write_idx.fetch_add(1);\n+    if (nan_count_log_write_idx.load() < log_header->capacity) {\n+      log_entries[write_idx] = {entry_id, nan_count};\n+    }\n+#else\n+    // Our toolchains generate a fetch_add PTX instructions with system scope,\n+    // which is not supported on pre-Pascal architectures.\n+    assert(false);\n+#endif\n+  }\n+}\n+\n+absl::StatusOr<se::KernelLoaderSpec> GetNanCountF32KernelSpec() {\n+  return se::KernelLoaderSpec::CreateInProcessSymbolSpec(\n+      absl::bit_cast<void*>(&AppendNanCount<float>),\n+      \"BufferDebugNanCountF32Kernel\",\n+      /*arity=*/5);\n+}\n+\n+absl::StatusOr<se::KernelLoaderSpec> GetNanCountBf16KernelSpec() {\n+  return se::KernelLoaderSpec::CreateInProcessSymbolSpec(\n+      absl::bit_cast<void*>(&AppendNanCount<__nv_bfloat16>),\n+      \"BufferDebugNanCountBf16Kernel\",\n+      /*arity=*/5);\n+}\n+\n+}  // namespace\n+\n+GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(\n+    BufferDebugNanCountF32Kernel, se::gpu::BufferDebugNanCountF32Kernel,\n+    se::cuda::kCudaPlatformId,\n+    ([](size_t _arity) { return GetNanCountF32KernelSpec().value(); }));\n+\n+GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(\n+    BufferDebugNanCountBf16Kernel, se::gpu::BufferDebugNanCountBf16Kernel,\n+    se::cuda::kCudaPlatformId,\n+    ([](size_t _arity) { return GetNanCountBf16KernelSpec().value(); }));"
        },
        {
            "sha": "40f0b06f6dedadcb8ee1114699170ce2386c924f",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_nan_count_kernel_cuda_test.cc",
            "status": "added",
            "additions": 179,
            "deletions": 0,
            "changes": 179,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/78a0ca0b60bd15e1b1aac724799764777228dea5/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_nan_count_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/78a0ca0b60bd15e1b1aac724799764777228dea5/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_nan_count_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_nan_count_kernel_cuda_test.cc?ref=78a0ca0b60bd15e1b1aac724799764777228dea5",
            "patch": "@@ -0,0 +1,179 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdint>\n+#include <limits>\n+#include <memory>\n+#include <optional>\n+#include <vector>\n+\n+#include <gtest/gtest.h>\n+#include \"absl/cleanup/cleanup.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_format.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n+#include \"xla/backends/gpu/runtime/thunk_id.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_log.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_nan_count_kernel.h\"\n+#include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n+#include \"xla/stream_executor/launch_dim.h\"\n+#include \"xla/stream_executor/platform.h\"\n+#include \"xla/stream_executor/platform_manager.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n+#include \"xla/stream_executor/typed_kernel_factory.h\"  // IWYU pragma: keep, required for KernelType::FactoryType::Create\n+#include \"xla/tsl/lib/core/status_test_util.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/types.h\"\n+\n+namespace se = stream_executor;\n+\n+namespace stream_executor::cuda {\n+namespace {\n+\n+using xla::gpu::ThunkBufferId;\n+using xla::gpu::ThunkId;\n+\n+class NanCountKernelTest : public ::testing::Test {\n+ protected:\n+  void SetUp() override {\n+    TF_ASSERT_OK_AND_ASSIGN(platform_,\n+                            se::PlatformManager::PlatformWithName(\"CUDA\"));\n+    TF_ASSERT_OK_AND_ASSIGN(executor_, platform_->ExecutorForDevice(0));\n+    TF_ASSERT_OK_AND_ASSIGN(stream_, executor_->CreateStream(std::nullopt));\n+    allocator_ =\n+        std::make_unique<se::StreamExecutorMemoryAllocator>(stream_->parent());\n+\n+    if (!executor_->GetDeviceDescription()\n+             .cuda_compute_capability()\n+             .IsAtLeastPascal()) {\n+      GTEST_SKIP()\n+          << \"Buffer checking is not supported on CUDA architectures older \"\n+             \"than Pascal due to missing atomic fetch_add with system scope\";\n+    }\n+  }\n+\n+  template <typename T>\n+  absl::StatusOr<se::DeviceMemory<T>> CheckNotNull(\n+      se::DeviceMemory<T> device_memory, absl::string_view name) {\n+    if (device_memory.is_null()) {\n+      return absl::InternalError(\n+          absl::StrFormat(\"Device memory for %s is null\", name));\n+    }\n+    return device_memory;\n+  }\n+\n+  template <typename Kernel, typename T>\n+  absl::Status AppendNanCountOnDevice(\n+      ThunkBufferId entry_id, const std::vector<T>& input,\n+      se::gpu::BufferDebugLog& buffer_debug_log,\n+      stream_executor::ThreadDim dim = stream_executor::ThreadDim(1, 1, 1)) {\n+    // Load kernel\n+    gpu::GpuKernelRegistry registry =\n+        gpu::GpuKernelRegistry::GetGlobalRegistry();\n+    TF_ASSIGN_OR_RETURN(auto kernel, registry.LoadKernel<Kernel>(executor_));\n+\n+    // Setup device buffers\n+    TF_ASSIGN_OR_RETURN(\n+        se::DeviceMemory<T> device_input,\n+        CheckNotNull(executor_->AllocateArray<T>(input.size()), \"input\"));\n+    auto cleanup_input =\n+        absl::MakeCleanup([&]() { executor_->Deallocate(&device_input); });\n+\n+    // Call kernel\n+    TF_RETURN_IF_ERROR(stream_->Memcpy(&device_input, input.data(),\n+                                       input.size() * sizeof(input[0])));\n+    TF_RETURN_IF_ERROR(kernel.Launch(dim, stream_executor::BlockDim(1, 1, 1),\n+                                     stream_.get(), entry_id, device_input,\n+                                     device_input.ElementCount() * sizeof(T),\n+                                     buffer_debug_log.GetDeviceHeader(),\n+                                     buffer_debug_log.GetDeviceEntries()));\n+    TF_RETURN_IF_ERROR(stream_->BlockHostUntilDone());\n+\n+    // The result gets stored in `buffer_debug_log`.\n+    return absl::OkStatus();\n+  }\n+\n+  se::Platform* platform_;\n+  se::StreamExecutor* executor_;\n+  std::unique_ptr<se::Stream> stream_;\n+  std::unique_ptr<se::StreamExecutorMemoryAllocator> allocator_;\n+};\n+\n+TEST_F(NanCountKernelTest, CountsNansForF32) {\n+  se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(1024);\n+  std::vector<float> input = {1.0f, std::numeric_limits<float>::quiet_NaN(),\n+                              2.0f, std::numeric_limits<float>::quiet_NaN()};\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      se::gpu::BufferDebugLog device_log,\n+      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+\n+  TF_EXPECT_OK(AppendNanCountOnDevice<gpu::BufferDebugNanCountF32Kernel>(\n+      ThunkBufferId(), input, device_log));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  ASSERT_GE(host_log.size(), 1);\n+  EXPECT_EQ(host_log[0].checksum, 2);\n+}\n+\n+TEST_F(NanCountKernelTest, CountsNansForBf16) {\n+  se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(1024);\n+  std::vector<xla::bfloat16> input = {\n+      xla::bfloat16(1.0f),\n+      xla::bfloat16(std::numeric_limits<float>::quiet_NaN()),\n+      xla::bfloat16(2.0f),\n+      xla::bfloat16(std::numeric_limits<float>::quiet_NaN())};\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      se::gpu::BufferDebugLog device_log,\n+      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+\n+  TF_EXPECT_OK(AppendNanCountOnDevice<gpu::BufferDebugNanCountBf16Kernel>(\n+      ThunkBufferId(), input, device_log));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  ASSERT_GE(host_log.size(), 1);\n+  EXPECT_EQ(host_log[0].checksum, 2);\n+}\n+\n+TEST_F(NanCountKernelTest, CountsNansInParallel) {\n+  se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(1024);\n+  std::vector<float> input(1024, 1.0f);\n+  input[100] = std::numeric_limits<float>::quiet_NaN();\n+  input[200] = std::numeric_limits<float>::quiet_NaN();\n+  input[300] = std::numeric_limits<float>::quiet_NaN();\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      se::gpu::BufferDebugLog device_log,\n+      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+\n+  TF_EXPECT_OK(AppendNanCountOnDevice<gpu::BufferDebugNanCountF32Kernel>(\n+      ThunkBufferId(), input, device_log, se::ThreadDim(2, 4, 8)));\n+  TF_EXPECT_OK(AppendNanCountOnDevice<gpu::BufferDebugNanCountF32Kernel>(\n+      ThunkBufferId(), input, device_log, se::ThreadDim(2, 4, 8)));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  ASSERT_GE(host_log.size(), 2);\n+  EXPECT_EQ(host_log[0].checksum, 3);\n+  EXPECT_EQ(host_log[1].checksum, 3);\n+}\n+\n+}  // namespace\n+}  // namespace stream_executor::cuda"
        },
        {
            "sha": "77efe09109b2fda61d9de22e33a840d47a430690",
            "filename": "third_party/xla/xla/stream_executor/gpu/BUILD",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/78a0ca0b60bd15e1b1aac724799764777228dea5/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/78a0ca0b60bd15e1b1aac724799764777228dea5/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD?ref=78a0ca0b60bd15e1b1aac724799764777228dea5",
            "patch": "@@ -995,3 +995,15 @@ cc_library(\n         \"//xla/stream_executor:kernel\",\n     ],\n )\n+\n+cc_library(\n+    name = \"buffer_debug_nan_count_kernel\",\n+    hdrs = [\"buffer_debug_nan_count_kernel.h\"],\n+    deps = [\n+        \"//xla:types\",\n+        \"//xla/backends/gpu/runtime:buffer_debug_log_structs\",\n+        \"//xla/backends/gpu/runtime:thunk_buffer_id\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:kernel\",\n+    ],\n+)"
        },
        {
            "sha": "4b90d23ad8029a1bc38a71a8b13d5fe01f499835",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_nan_count_kernel.h",
            "status": "added",
            "additions": 49,
            "deletions": 0,
            "changes": 49,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/78a0ca0b60bd15e1b1aac724799764777228dea5/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_nan_count_kernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/78a0ca0b60bd15e1b1aac724799764777228dea5/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_nan_count_kernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_nan_count_kernel.h?ref=78a0ca0b60bd15e1b1aac724799764777228dea5",
            "patch": "@@ -0,0 +1,49 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_STREAM_EXECUTOR_GPU_BUFFER_DEBUG_NAN_COUNT_KERNEL_H_\n+#define XLA_STREAM_EXECUTOR_GPU_BUFFER_DEBUG_NAN_COUNT_KERNEL_H_\n+\n+#include <cstdint>\n+\n+#include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/kernel.h\"\n+#include \"xla/types.h\"\n+\n+namespace stream_executor::gpu {\n+\n+// Trait for a kernel that computes the NaN count of given input buffer and\n+// appends it to the buffer debug log.\n+//\n+// This kernel MUST execute on a single thread block.\n+struct BufferDebugNanCountF32Kernel {\n+  using KernelType =\n+      TypedKernel<xla::gpu::ThunkBufferId, DeviceMemory<float>, uint64_t,\n+                  DeviceMemory<xla::gpu::BufferDebugLogHeader>,\n+                  DeviceMemory<xla::gpu::BufferDebugLogEntry>>;\n+};\n+\n+struct BufferDebugNanCountBf16Kernel {\n+  using KernelType =\n+      TypedKernel<xla::gpu::ThunkBufferId, DeviceMemory<Eigen::bfloat16>,\n+                  uint64_t, DeviceMemory<xla::gpu::BufferDebugLogHeader>,\n+                  DeviceMemory<xla::gpu::BufferDebugLogEntry>>;\n+};\n+\n+}  // namespace stream_executor::gpu\n+\n+#endif  // XLA_STREAM_EXECUTOR_GPU_BUFFER_DEBUG_NAN_COUNT_KERNEL_H_"
        }
    ],
    "stats": {
        "total": 520,
        "additions": 520,
        "deletions": 0
    }
}