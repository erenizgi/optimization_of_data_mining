{
    "author": "khasanovaa",
    "message": "Add proto [de]serialization for DynamicSliceThunk.\n\nPiperOrigin-RevId: 816072761",
    "sha": "7ada6b71378af8dc6008c29d640225e2820e7545",
    "files": [
        {
            "sha": "76c15b0bc0c8439da35ed84df1fc4f7602c416ee",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 14,
            "deletions": 1,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7ada6b71378af8dc6008c29d640225e2820e7545/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7ada6b71378af8dc6008c29d640225e2820e7545/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=7ada6b71378af8dc6008c29d640225e2820e7545",
            "patch": "@@ -214,20 +214,27 @@ cc_library(\n     srcs = [\"dynamic_slice_thunk.cc\"],\n     hdrs = [\"dynamic_slice_thunk.h\"],\n     deps = [\n+        \":dynamic_slice_thunk_proto_cc\",\n         \":sequential_thunk\",\n         \":thunk\",\n+        \":thunk_proto_cc\",\n+        \":thunk_proto_deserialization\",\n         \"//xla:literal\",\n         \"//xla:literal_util\",\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla/hlo/evaluator:hlo_evaluator\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/service:buffer_assignment\",\n+        \"//xla/service:hlo_proto_cc\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/service/gpu:ir_emission_utils\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:memory_allocation\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n@@ -237,6 +244,7 @@ cc_library(\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/synchronization\",\n+        \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//llvm:Support\",\n         \"@local_tsl//tsl/platform:errors\",\n         \"@local_tsl//tsl/platform:logging\",\n@@ -253,13 +261,15 @@ xla_test(\n     deps = [\n         \":custom_call_thunk\",\n         \":dynamic_slice_thunk\",\n+        \":dynamic_slice_thunk_proto_cc\",\n         \":gemm_thunk\",\n         \":thunk\",\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/ffi\",\n         \"//xla/ffi:ffi_api\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/parser:hlo_parser\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:executable\",\n@@ -277,10 +287,13 @@ xla_test(\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor:stream_executor_memory_allocator\",\n         \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:status\",\n         \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/types:span\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )\n@@ -2252,8 +2265,8 @@ tf_proto_library(\n     protodeps = [\n         # keep sorted\n         \"//xla:xla_data_proto\",\n+        \"//xla:xla_proto\",\n         \"//xla/service:buffer_assignment_proto\",\n-        \"//xla/service:hlo_proto\",\n     ],\n )\n "
        },
        {
            "sha": "17961ee2d8884836aadeca088f2e5f0356e47b89",
            "filename": "third_party/xla/xla/backends/gpu/runtime/dynamic_slice_thunk.cc",
            "status": "modified",
            "additions": 289,
            "deletions": 0,
            "changes": 289,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7ada6b71378af8dc6008c29d640225e2820e7545/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7ada6b71378af8dc6008c29d640225e2820e7545/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.cc?ref=7ada6b71378af8dc6008c29d640225e2820e7545",
            "patch": "@@ -23,17 +23,23 @@ limitations under the License.\n #include <variant>\n #include <vector>\n \n+#include \"absl/algorithm/container.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/functional/function_ref.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/synchronization/mutex.h\"\n+#include \"absl/types/span.h\"\n #include \"llvm/ADT/STLExtras.h\"\n+#include \"xla/backends/gpu/runtime/dynamic_slice_thunk.pb.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/backends/gpu/runtime/thunk_proto_deserialization.h\"\n #include \"xla/hlo/evaluator/hlo_evaluator.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/literal_util.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n@@ -44,6 +50,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/memory_allocation.h\"\n #include \"xla/stream_executor/stream.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"tsl/platform/errors.h\"\n #include \"tsl/platform/logging.h\"\n #include \"tsl/platform/statusor.h\"\n@@ -68,8 +75,42 @@ Literal& Indvar(DynamicSliceThunk* thunk) {\n   return indvar_map[thunk];\n }\n \n+using DynamicSliceOffsetProto =\n+    OptionalDynamicSliceOffsetsProto::DynamicSliceOffsetProto;\n+\n }  // namespace\n \n+absl::StatusOr<OffsetAsFunctionOfIndvarModulesMetadataProto>\n+DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata::ToProto() const {\n+  OffsetAsFunctionOfIndvarModulesMetadataProto proto;\n+  *proto.mutable_indvar_init() = indvar_init->ToProtoWithConfig();\n+  *proto.mutable_indvar_update() = indvar_update->ToProtoWithConfig();\n+  for (const auto& module : extracted_offset_modules) {\n+    *proto.add_extracted_offset_modules() = module->ToProtoWithConfig();\n+  }\n+  return proto;\n+}\n+\n+absl::StatusOr<DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata>\n+DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata::FromProto(\n+    const OffsetAsFunctionOfIndvarModulesMetadataProto& proto) {\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<HloModule> indvar_init,\n+      HloModule::CreateFromProtoWithConfig(proto.indvar_init()));\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<HloModule> indvar_update,\n+      HloModule::CreateFromProtoWithConfig(proto.indvar_update()));\n+  std::vector<std::unique_ptr<HloModule>> extracted_offset_modules;\n+  for (const auto& module_proto : proto.extracted_offset_modules()) {\n+    TF_ASSIGN_OR_RETURN(std::unique_ptr<HloModule> module,\n+                        HloModule::CreateFromProtoWithConfig(module_proto));\n+    extracted_offset_modules.push_back(std::move(module));\n+  }\n+  return OffsetAsFunctionOfIndvarModulesMetadata(\n+      std::move(indvar_init), std::move(indvar_update),\n+      std::move(extracted_offset_modules));\n+}\n+\n DynamicSliceThunk::DynamicSliceThunk(\n     ThunkInfo thunk_info, std::unique_ptr<ThunkSequence> embedded_thunk,\n     std::vector<std::optional<BufferAllocation::Slice>> arguments,\n@@ -329,5 +370,253 @@ void DynamicSliceThunk::ForAllThunksMutable(\n   fn(this);\n   embedded_thunk_->ForAllThunksMutable(fn);\n }\n+\n+absl::StatusOr<OptionalDynamicSliceOffsetsProto>\n+SerializeOptionalDynamicSliceOffsetsToProto(\n+    const std::optional<std::vector<DynamicSliceThunk::Offset>>& offsets_item,\n+    const std::optional<\n+        DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata>&\n+        offset_as_function_of_indvar_metadata) {\n+  OptionalDynamicSliceOffsetsProto offsets_proto;\n+  if (offsets_item.has_value()) {\n+    auto& offsets_inner = *offsets_proto.mutable_offsets();\n+    for (const auto& offset : *offsets_item) {\n+      auto& offset_proto = *offsets_inner.add_offsets();\n+      if (const int64_t* const_offset = std::get_if<int64_t>(&offset)) {\n+        offset_proto.set_const_offset(*const_offset);\n+      } else if (const BufferAllocation::Slice* slice_offset =\n+                     std::get_if<BufferAllocation::Slice>(&offset)) {\n+        TF_ASSIGN_OR_RETURN(*offset_proto.mutable_slice_offset(),\n+                            slice_offset->ToProto());\n+      } else if (const HloModule* const* module_offset =\n+                     std::get_if<HloModule*>(&offset)) {\n+        TF_RET_CHECK(offset_as_function_of_indvar_metadata.has_value());\n+        const std::vector<std::unique_ptr<HloModule>>& modules =\n+            offset_as_function_of_indvar_metadata->extracted_offset_modules;\n+        auto it = absl::c_find_if(modules, [&](const auto& module) {\n+          return module.get() == *module_offset;\n+        });\n+        TF_RET_CHECK(it != modules.end());\n+        offset_proto.set_hlo_module_offset_idx(it - modules.begin());\n+      } else {\n+        return absl::InternalError(\n+            \"Unhandled offset type in DynamicSliceThunk::ToProto\");\n+      }\n+    }\n+  }\n+  return offsets_proto;\n+}\n+\n+absl::Status SerializeOffsetsToProto(\n+    const std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>>&\n+        offsets,\n+    const std::optional<\n+        DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata>&\n+        offset_as_function_of_indvar_metadata,\n+    DynamicSliceThunkProto* proto) {\n+  for (const auto& offsets_item : offsets) {\n+    TF_ASSIGN_OR_RETURN(\n+        *proto->add_offsets(),\n+        SerializeOptionalDynamicSliceOffsetsToProto(\n+            offsets_item, offset_as_function_of_indvar_metadata));\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::StatusOr<std::optional<std::vector<DynamicSliceThunk::Offset>>>\n+DeserializeOptionalDynamicSliceOffsetsFromProto(\n+    const OptionalDynamicSliceOffsetsProto& proto,\n+    absl::Span<const BufferAllocation> buffer_allocations,\n+    const std::optional<\n+        DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata>&\n+        offset_as_function_of_indvar_metadata) {\n+  if (!proto.has_offsets()) {\n+    return std::nullopt;\n+  }\n+  std::vector<DynamicSliceThunk::Offset> offsets;\n+\n+  for (const auto& offset_proto : proto.offsets().offsets()) {\n+    switch (offset_proto.offset_case()) {\n+      case DynamicSliceOffsetProto::kConstOffset:\n+        offsets.push_back(offset_proto.const_offset());\n+        break;\n+      case DynamicSliceOffsetProto::kSliceOffset: {\n+        TF_ASSIGN_OR_RETURN(\n+            auto slice, BufferAllocation::Slice::FromProto(\n+                            offset_proto.slice_offset(), buffer_allocations));\n+        offsets.push_back(slice);\n+        break;\n+      }\n+      case DynamicSliceOffsetProto::kHloModuleOffsetIdx: {\n+        TF_RET_CHECK(offset_as_function_of_indvar_metadata.has_value());\n+        const std::vector<std::unique_ptr<HloModule>>& modules =\n+            offset_as_function_of_indvar_metadata->extracted_offset_modules;\n+        TF_RET_CHECK(modules.size() > offset_proto.hlo_module_offset_idx());\n+        offsets.push_back(modules[offset_proto.hlo_module_offset_idx()].get());\n+        break;\n+      }\n+      default:\n+        return absl::InternalError(\n+            \"Offset not set in OptionalDynamicSliceOffsetsProto\");\n+    }\n+  }\n+  return offsets;\n+}\n+\n+absl::StatusOr<\n+    std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>>>\n+DeserializeOffsetsFromProto(\n+    const DynamicSliceThunkProto& proto,\n+    absl::Span<const BufferAllocation> buffer_allocations,\n+    const std::optional<\n+        DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata>&\n+        offset_as_function_of_indvar_metadata) {\n+  std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>> offsets;\n+  for (const auto& offsets_proto : proto.offsets()) {\n+    TF_ASSIGN_OR_RETURN(offsets.emplace_back(),\n+                        DeserializeOptionalDynamicSliceOffsetsFromProto(\n+                            offsets_proto, buffer_allocations,\n+                            offset_as_function_of_indvar_metadata));\n+  }\n+  return offsets;\n+}\n+\n+absl::StatusOr<ThunkProto> DynamicSliceThunk::ToProto() const {\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+\n+  DynamicSliceThunkProto* dynamic_slice_proto =\n+      proto.mutable_dynamic_slice_thunk();\n+\n+  TF_ASSIGN_OR_RETURN(ThunkProto embedded_thunk_proto,\n+                      embedded_thunk_->ToProto());\n+  TF_RET_CHECK(embedded_thunk_proto.has_sequential_thunk());\n+  *dynamic_slice_proto->mutable_embedded_thunk() =\n+      std::move(embedded_thunk_proto.sequential_thunk());\n+\n+  // arguments\n+  for (const auto& arg : arguments_) {\n+    auto& proto_arg = *dynamic_slice_proto->add_arguments();\n+    if (arg.has_value()) {\n+      TF_ASSIGN_OR_RETURN(*proto_arg.mutable_slice(), arg->ToProto());\n+    }\n+  }\n+\n+  TF_RETURN_IF_ERROR(SerializeOffsetsToProto(\n+      offsets_, offset_as_function_of_indvar_metadata_, dynamic_slice_proto));\n+\n+  // orig_shapes\n+  for (const auto& shape : orig_shapes_) {\n+    auto& proto_shape = *dynamic_slice_proto->add_orig_shapes();\n+    if (shape.has_value()) {\n+      *proto_shape.mutable_shape() = shape->ToProto();\n+    }\n+  }\n+\n+  // sliced_shapes\n+  for (const auto& shape : sliced_shapes_) {\n+    auto& proto_shape = *dynamic_slice_proto->add_sliced_shapes();\n+    if (shape.has_value()) {\n+      *proto_shape.mutable_shape() = shape->ToProto();\n+    }\n+  }\n+\n+  // offset_byte_sizes\n+  for (const auto& size : offset_byte_sizes_) {\n+    auto& proto_size = *dynamic_slice_proto->add_offset_byte_sizes();\n+    if (size.has_value()) {\n+      proto_size.set_value(size.value());\n+    }\n+  }\n+\n+  // offset_as_function_of_indvar_metadata\n+  if (offset_as_function_of_indvar_metadata_.has_value()) {\n+    TF_ASSIGN_OR_RETURN(\n+        *dynamic_slice_proto\n+             ->mutable_offset_as_function_of_indvar_modules_metadata(),\n+        offset_as_function_of_indvar_metadata_->ToProto());\n+  }\n+  return proto;\n+}\n+\n+absl::StatusOr<std::unique_ptr<DynamicSliceThunk>> DynamicSliceThunk::FromProto(\n+    ThunkInfo thunk_info, const DynamicSliceThunkProto& proto,\n+    absl::Span<const BufferAllocation> buffer_allocations,\n+    absl::Span<const BufferAllocation> fake_allocations) {\n+  // offset_as_function_of_indvar_metadata\n+  std::optional<OffsetAsFunctionOfIndvarModulesMetadata>\n+      offset_as_function_of_indvar_metadata;\n+  if (proto.has_offset_as_function_of_indvar_modules_metadata()) {\n+    TF_ASSIGN_OR_RETURN(\n+        offset_as_function_of_indvar_metadata,\n+        OffsetAsFunctionOfIndvarModulesMetadata::FromProto(\n+            proto.offset_as_function_of_indvar_modules_metadata()));\n+  }\n+\n+  // arguments\n+  std::vector<std::optional<BufferAllocation::Slice>> arguments;\n+  for (auto& arg_proto : proto.arguments()) {\n+    arguments.push_back(std::nullopt);\n+    if (arg_proto.has_slice()) {\n+      TF_ASSIGN_OR_RETURN(arguments.back(),\n+                          BufferAllocation::Slice::FromProto(\n+                              arg_proto.slice(), buffer_allocations));\n+    }\n+  }\n+\n+  // offsets\n+  TF_ASSIGN_OR_RETURN(\n+      std::vector<std::optional<std::vector<Offset>>> offsets,\n+      DeserializeOffsetsFromProto(proto, buffer_allocations,\n+                                  offset_as_function_of_indvar_metadata));\n+\n+  // orig_shapes\n+  std::vector<std::optional<Shape>> orig_shapes;\n+  for (auto& shape_proto : proto.orig_shapes()) {\n+    orig_shapes.push_back(std::nullopt);\n+    if (shape_proto.has_shape()) {\n+      TF_ASSIGN_OR_RETURN(orig_shapes.back(),\n+                          Shape::FromProto(shape_proto.shape()));\n+    }\n+  }\n+\n+  // sliced_shapes\n+  std::vector<std::optional<Shape>> sliced_shapes;\n+  for (auto& shape_proto : proto.sliced_shapes()) {\n+    sliced_shapes.push_back(std::nullopt);\n+    if (shape_proto.has_shape()) {\n+      TF_ASSIGN_OR_RETURN(sliced_shapes.back(),\n+                          Shape::FromProto(shape_proto.shape()));\n+    }\n+  }\n+\n+  // offset_byte_sizes\n+  std::vector<std::optional<uint64_t>> offset_byte_sizes;\n+  for (auto& size_proto : proto.offset_byte_sizes()) {\n+    offset_byte_sizes.push_back(std::nullopt);\n+    if (size_proto.has_value()) {\n+      offset_byte_sizes.back() = size_proto.value();\n+    }\n+  }\n+\n+  // embedded_thunk\n+  std::vector<std::unique_ptr<Thunk>> embedded_thunks;\n+  for (const auto& thunk_proto : proto.embedded_thunk().thunks()) {\n+    TF_ASSIGN_OR_RETURN(auto thunk,\n+                        DeserializeThunkProto(thunk_proto, fake_allocations));\n+    embedded_thunks.push_back(std::move(thunk));\n+  }\n+\n+  // leave fake_allocations empty, because we manage their lifetime outside\n+  // of this function.\n+  return std::make_unique<DynamicSliceThunk>(\n+      thunk_info, std::make_unique<ThunkSequence>(std::move(embedded_thunks)),\n+      std::move(arguments),\n+      /*fake_allocations=*/std::vector<std::unique_ptr<BufferAllocation>>(),\n+      std::move(offsets), std::move(orig_shapes), std::move(sliced_shapes),\n+      std::move(offset_byte_sizes),\n+      std::move(offset_as_function_of_indvar_metadata));\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "0835c5a1521d88f3d22159efd99cc9609ffc442c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/dynamic_slice_thunk.h",
            "status": "modified",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7ada6b71378af8dc6008c29d640225e2820e7545/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7ada6b71378af8dc6008c29d640225e2820e7545/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.h?ref=7ada6b71378af8dc6008c29d640225e2820e7545",
            "patch": "@@ -101,6 +101,11 @@ class DynamicSliceThunk : public Thunk {\n           << \"Induction variable update module expected with signature \"\n              \"`(integer[]) -> integer[]`.\";\n     }\n+\n+    absl::StatusOr<OffsetAsFunctionOfIndvarModulesMetadataProto> ToProto()\n+        const;\n+    static absl::StatusOr<OffsetAsFunctionOfIndvarModulesMetadata> FromProto(\n+        const OffsetAsFunctionOfIndvarModulesMetadataProto& proto);\n   };\n \n   DynamicSliceThunk(\n@@ -165,6 +170,21 @@ class DynamicSliceThunk : public Thunk {\n   void ForAllThunks(absl::FunctionRef<void(const Thunk*)> fn) const override;\n   void ForAllThunksMutable(absl::FunctionRef<void(Thunk*)> fn) override;\n \n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n+  // `buffer_allocations`: the actual buffer allocations; required to parse the\n+  // `arguments` (BufferAllocation::Slice) -- the tensors that we are later\n+  // slicing from.\n+  // `fake_allocations`: The fake allocations that are used as\n+  // placeholders during creation of the embedded thunk. These are being\n+  // replaced during execution in `ExecuteOnStream` with the actual (dynamic)\n+  // slices. We have to create these outside of this method to manage their\n+  // lifetime correctly.\n+  static absl::StatusOr<std::unique_ptr<DynamicSliceThunk>> FromProto(\n+      ThunkInfo thunk_info, const DynamicSliceThunkProto& proto,\n+      absl::Span<const BufferAllocation> buffer_allocations,\n+      absl::Span<const BufferAllocation> fake_allocations);\n+\n  private:\n   std::unique_ptr<SequentialThunk> embedded_thunk_;\n   std::vector<std::optional<BufferAllocation::Slice>> arguments_;\n@@ -195,6 +215,20 @@ class DynamicSliceThunk : public Thunk {\n       offset_as_function_of_indvar_metadata_;\n };\n \n+absl::StatusOr<OptionalDynamicSliceOffsetsProto>\n+SerializeOptionalDynamicSliceOffsetsToProto(\n+    const std::optional<std::vector<DynamicSliceThunk::Offset>>& offsets_item,\n+    const std::optional<\n+        DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata>&\n+        offset_as_function_of_indvar_metadata);\n+\n+absl::StatusOr<std::optional<std::vector<DynamicSliceThunk::Offset>>>\n+DeserializeOptionalDynamicSliceOffsetsFromProto(\n+    const OptionalDynamicSliceOffsetsProto& proto,\n+    absl::Span<const BufferAllocation> buffer_allocations,\n+    const std::optional<\n+        DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata>&\n+        offset_as_function_of_indvar_metadata);\n }  // namespace gpu\n }  // namespace xla\n "
        },
        {
            "sha": "6fc504f10ca83eb2970e8b3168629b9b74d510c1",
            "filename": "third_party/xla/xla/backends/gpu/runtime/dynamic_slice_thunk.proto",
            "status": "modified",
            "additions": 8,
            "deletions": 5,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7ada6b71378af8dc6008c29d640225e2820e7545/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7ada6b71378af8dc6008c29d640225e2820e7545/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.proto?ref=7ada6b71378af8dc6008c29d640225e2820e7545",
            "patch": "@@ -22,7 +22,7 @@ syntax = \"proto3\";\n package xla.gpu;\n \n import \"xla/service/buffer_assignment.proto\";\n-import \"xla/service/hlo.proto\";\n+import \"xla/xla.proto\";\n import \"xla/xla_data.proto\";\n \n message OptionalBufferAllocationSliceProto {\n@@ -37,12 +37,15 @@ message OptionalInt64Proto {\n   optional int64 value = 1;\n }\n \n+// Reflects std::optional<std::vector<Offset>>\n message OptionalDynamicSliceOffsetsProto {\n   message DynamicSliceOffsetProto {\n     oneof offset {\n       int64 const_offset = 1;\n       xla.buffer_assignment.BufferAllocationSliceProto slice_offset = 2;\n-      int64 hlo_module_offset_id = 3;\n+      // Index of the HLO module in the list of extracted_offset_modules in\n+      // the OffsetAsFunctionOfIndvarModulesMetadataProto.\n+      int64 hlo_module_offset_idx = 3;\n     }\n   }\n \n@@ -53,7 +56,7 @@ message OptionalDynamicSliceOffsetsProto {\n }\n \n message OffsetAsFunctionOfIndvarModulesMetadataProto {\n-  optional xla.HloModuleProto indvar_init = 1;\n-  optional xla.HloModuleProto indvar_update = 2;\n-  repeated xla.HloModuleProto extracted_offset_modules = 3;\n+  xla.HloModuleProtoWithConfig indvar_init = 1;\n+  xla.HloModuleProtoWithConfig indvar_update = 2;\n+  repeated xla.HloModuleProtoWithConfig extracted_offset_modules = 3;\n }"
        },
        {
            "sha": "04106df2e9bc5cd8044c7b46552f7d4f88c79443",
            "filename": "third_party/xla/xla/backends/gpu/runtime/dynamic_slice_thunk_test.cc",
            "status": "modified",
            "additions": 708,
            "deletions": 356,
            "changes": 1064,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7ada6b71378af8dc6008c29d640225e2820e7545/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7ada6b71378af8dc6008c29d640225e2820e7545/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk_test.cc?ref=7ada6b71378af8dc6008c29d640225e2820e7545",
            "patch": "@@ -21,25 +21,31 @@ limitations under the License.\n #include <optional>\n #include <string>\n #include <utility>\n+#include <variant>\n #include <vector>\n \n+#include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/ascii.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n+#include \"xla/backends/gpu/runtime/dynamic_slice_thunk.pb.h\"\n #include \"xla/backends/gpu/runtime/gemm_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/ffi/ffi.h\"\n #include \"xla/ffi/ffi_api.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/parser/hlo_parser.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/gpu/matmul_utils.h\"\n #include \"xla/service/gpu/resource_requests.h\"\n #include \"xla/service/platform_util.h\"\n #include \"xla/service/service_executable_run_options.h\"\n+#include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/stream_executor/blas.h\"\n #include \"xla/stream_executor/command_buffer.h\"\n@@ -52,12 +58,14 @@ limitations under the License.\n #include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n #include \"xla/xla_data.pb.h\"\n \n namespace xla::gpu {\n namespace {\n \n using DynamicSliceThunkTest = HloHardwareIndependentTestBase;\n+using ::tsl::proto_testing::EqualsProto;\n \n std::string GetPlatformName() {\n   return absl::AsciiStrToUpper(\n@@ -69,31 +77,84 @@ se::StreamExecutor* GpuExecutor() {\n       se::PlatformManager::PlatformWithName(GetPlatformName()).value();\n   return platform->ExecutorForDevice(0).value();\n }\n+void CheckProtoRoundTrip(const DynamicSliceThunk& thunk,\n+                         const DynamicSliceThunkProto& proto) {\n+  std::vector<BufferAllocation> buffer_allocations;\n+  for (int i = 0; i < 10; ++i) {\n+    buffer_allocations.push_back(BufferAllocation(\n+        /*index=*/i, /*size=*/1024, /*color=*/0));\n+  }\n \n-TEST_F(DynamicSliceThunkTest, SlicedGemm) {\n-  se::StreamExecutor* executor = GpuExecutor();\n+  std::vector<BufferAllocation> fake_allocations_span;\n+  const auto& arguments = thunk.get_arguments();\n+  for (int i = 0; i < arguments.size(); ++i) {\n+    if (arguments[i].has_value()) {\n+      fake_allocations_span.push_back(\n+          BufferAllocation(i, arguments[i].value().allocation()->size(), 0));\n+    }\n+  }\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto thunk_from_proto,\n+      DynamicSliceThunk::FromProto(Thunk::ThunkInfo(), proto,\n+                                   /*buffer_allocations=*/buffer_allocations,\n+                                   /*fake_allocations=*/fake_allocations_span));\n+  TF_ASSERT_OK_AND_ASSIGN(auto proto_roundtrip, thunk_from_proto->ToProto());\n+  auto dynamic_slice_thunk_proto_roundtrip =\n+      proto_roundtrip.dynamic_slice_thunk();\n+  auto proto_no_ids = proto;\n+  // Hlo ids are expected to be different after roundtrip, thus we drop them\n+  // from comparison.\n+  proto_no_ids.mutable_offset_as_function_of_indvar_modules_metadata()\n+      ->mutable_indvar_init()\n+      ->mutable_hlo_module()\n+      ->clear_id();\n+  proto_no_ids.mutable_offset_as_function_of_indvar_modules_metadata()\n+      ->mutable_indvar_update()\n+      ->mutable_hlo_module()\n+      ->clear_id();\n+  for (auto& module_with_config :\n+       *proto_no_ids.mutable_offset_as_function_of_indvar_modules_metadata()\n+            ->mutable_extracted_offset_modules()) {\n+    module_with_config.mutable_hlo_module()->clear_id();\n+  }\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n+  dynamic_slice_thunk_proto_roundtrip\n+      .mutable_offset_as_function_of_indvar_modules_metadata()\n+      ->mutable_indvar_init()\n+      ->mutable_hlo_module()\n+      ->clear_id();\n+  dynamic_slice_thunk_proto_roundtrip\n+      .mutable_offset_as_function_of_indvar_modules_metadata()\n+      ->mutable_indvar_update()\n+      ->mutable_hlo_module()\n+      ->clear_id();\n+  for (auto& module_with_config :\n+       *dynamic_slice_thunk_proto_roundtrip\n+            .mutable_offset_as_function_of_indvar_modules_metadata()\n+            ->mutable_extracted_offset_modules()) {\n+    module_with_config.mutable_hlo_module()->clear_id();\n+  }\n+\n+  EXPECT_THAT(dynamic_slice_thunk_proto_roundtrip, EqualsProto(proto_no_ids));\n+}\n \n+absl::StatusOr<std::unique_ptr<DynamicSliceThunk>> CreateSlicedGemmThunk(\n+    std::vector<std::unique_ptr<BufferAllocation>>& backing_allocations) {\n+  se::StreamExecutor* executor = GpuExecutor();\n   int64_t lhs_length = sizeof(float) * 2 * 4;\n   int64_t rhs_length = sizeof(float) * 3 * 1;\n   int64_t out_length = sizeof(float) * 1 * 1;\n   int64_t offset_length = sizeof(int64_t);\n-\n-  // Step 1:\n-  // Prepare embedded and address computation thunks.\n-\n   // Preparing buffer allocation slices for thunk creations.\n-  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations(4);\n-\n+  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations;\n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/0, rhs_length, /*color=*/0));\n   BufferAllocation::Slice slice_lhs_fake(fake_allocations.back().get(), 0,\n                                          rhs_length);\n \n-  BufferAllocation alloc_lhs(/*index=*/0, lhs_length, /*color=*/0);\n-  BufferAllocation::Slice slice_lhs(&alloc_lhs, 0, lhs_length);\n-\n+  auto alloc_lhs =\n+      std::make_unique<BufferAllocation>(/*index=*/0, lhs_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs(alloc_lhs.get(), 0, lhs_length);\n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/1, rhs_length, /*color=*/0));\n   BufferAllocation::Slice slice_rhs(fake_allocations.back().get(), 0,\n@@ -109,47 +170,75 @@ TEST_F(DynamicSliceThunkTest, SlicedGemm) {\n   BufferAllocation::Slice slice_workspace(fake_allocations.back().get(), 0,\n                                           1024 * 1024);\n \n-  BufferAllocation alloc_lhs_offset_0(/*index=*/4, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_0(&alloc_lhs_offset_0, 0,\n+  auto alloc_lhs_offset_0 = std::make_unique<BufferAllocation>(\n+      /*index=*/4, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_0(alloc_lhs_offset_0.get(), 0,\n                                              offset_length);\n \n-  BufferAllocation alloc_lhs_offset_1(/*index=*/5, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_1(&alloc_lhs_offset_1, 0,\n+  auto alloc_lhs_offset_1 = std::make_unique<BufferAllocation>(\n+      /*index=*/5, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_1(alloc_lhs_offset_1.get(), 0,\n                                              offset_length);\n \n+  backing_allocations.push_back(std::move(alloc_lhs));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_0));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_1));\n   // Preparing config for GEMM thunk.\n-  auto config = GemmConfig::For(\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n-      PrecisionConfig::ALG_UNSET, std::nullopt,\n-      se::blas::kDefaultComputePrecision, false, false,\n-      executor->GetDeviceDescription().gpu_compute_capability());\n-  ASSERT_TRUE(config.ok());\n-\n+  TF_ASSIGN_OR_RETURN(\n+      GemmConfig config,\n+      GemmConfig::For(\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n+          PrecisionConfig::ALG_UNSET, std::nullopt,\n+          se::blas::kDefaultComputePrecision, false, false,\n+          executor->GetDeviceDescription().gpu_compute_capability()));\n   // Creating embedded GEMM thunk.\n   ThunkSequence seq;\n   seq.emplace_back(std::make_unique<GemmThunk>(\n-      Thunk::ThunkInfo(), config.value(), slice_lhs_fake, slice_rhs, slice_out,\n+      Thunk::ThunkInfo(), config, slice_lhs_fake, slice_rhs, slice_out,\n       slice_workspace, /*deterministic=*/true));\n \n   // Wrapping address computation thunk around the GEMM thunk.\n   std::vector<DynamicSliceThunk::Offset> lhs_offsets{slice_lhs_offset_0,\n                                                      slice_lhs_offset_1};\n-  DynamicSliceThunk thunk(\n+  return std::make_unique<DynamicSliceThunk>(\n       Thunk::ThunkInfo(), std::make_unique<ThunkSequence>(std::move(seq)),\n-      {slice_lhs, slice_rhs, slice_out, slice_workspace},\n+      std::vector<std::optional<BufferAllocation::Slice>>{\n+          slice_lhs, slice_rhs, slice_out, slice_workspace},\n       std::move(fake_allocations),\n-      {lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n-       std::nullopt, std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), std::nullopt,\n-       std::nullopt, std::nullopt},\n-      {sizeof(int64_t), std::nullopt, std::nullopt, std::nullopt});\n+      std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>>{\n+          lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n+          std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), std::nullopt,\n+          std::nullopt, std::nullopt},\n+      std::vector<std::optional<uint64_t>>{sizeof(int64_t), std::nullopt,\n+                                           std::nullopt, std::nullopt});\n+}\n+\n+TEST_F(DynamicSliceThunkTest, SlicedGemmProtoRoundTrip) {\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(auto thunk,\n+                          CreateSlicedGemmThunk(backing_allocations));\n+  TF_ASSERT_OK_AND_ASSIGN(auto proto, thunk->ToProto());\n+  CheckProtoRoundTrip(*thunk, proto.dynamic_slice_thunk());\n+}\n+\n+TEST_F(DynamicSliceThunkTest, SlicedGemm) {\n+  se::StreamExecutor* executor = GpuExecutor();\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(auto thunk,\n+                          CreateSlicedGemmThunk(backing_allocations));\n+\n+  int64_t lhs_length = sizeof(float) * 2 * 4;\n+  int64_t rhs_length = sizeof(float) * 3 * 1;\n+  int64_t out_length = sizeof(float) * 1 * 1;\n+  int64_t offset_length = sizeof(int64_t);\n \n-  // Step 2:\n   // Execute address computation thunk.\n   //\n   // Given a `lhs` tensor of shape f32[2,4]{1,0}\n@@ -196,11 +285,11 @@ TEST_F(DynamicSliceThunkTest, SlicedGemm) {\n       run_options, allocations, stream.get(), stream.get(), nullptr, nullptr);\n \n   Thunk::ExecutableSource source = {/*text=*/\"\", /*binary=*/{}};\n-  TF_ASSERT_OK(thunk.Initialize(\n+  TF_ASSERT_OK(thunk->Initialize(\n       {executor, source, &allocations, stream.get(), stream.get()}));\n \n   // Executing address computation thunk.\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n   TF_ASSERT_OK(stream->BlockHostUntilDone());\n \n   // Copying `out` data back to host for verification.\n@@ -210,110 +299,127 @@ TEST_F(DynamicSliceThunkTest, SlicedGemm) {\n   ASSERT_EQ(dst, std::vector<float>({9}));\n }\n \n-TEST_F(DynamicSliceThunkTest, MulipleSlicedOperandsGemm) {\n+absl::StatusOr<std::unique_ptr<DynamicSliceThunk>>\n+CreateMultipleSlicedOperandsGemmThunk(\n+    std::vector<std::unique_ptr<BufferAllocation>>& backing_allocations) {\n   se::StreamExecutor* executor = GpuExecutor();\n-\n-  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n-\n   int64_t length = sizeof(float) * 2 * 4;\n   int64_t out_length = sizeof(float) * 1;\n   int64_t offset_length = sizeof(int64_t);\n   int64_t slice_length = sizeof(float) * 3;\n-\n-  // Step 1:\n-  // Prepare embedded and address computation thunks.\n-\n   // Preparing buffer allocation slices for thunk creations.\n-  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations(4);\n-\n+  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations;\n   fake_allocations.push_back(std::make_unique<BufferAllocation>(\n       /*index=*/0, slice_length, /*color=*/0));\n   BufferAllocation::Slice slice_lhs_fake(fake_allocations.back().get(), 0,\n                                          slice_length);\n-\n   fake_allocations.push_back(std::make_unique<BufferAllocation>(\n       /*index=*/1, slice_length, /*color=*/0));\n   BufferAllocation::Slice slice_rhs_fake(fake_allocations.back().get(), 0,\n                                          slice_length);\n-\n-  BufferAllocation alloc_lhs(/*index=*/0, length, /*color=*/0);\n-  BufferAllocation::Slice slice_lhs(&alloc_lhs, 0, length);\n-\n-  BufferAllocation alloc_rhs(/*index=*/1, length, /*color=*/0);\n-  BufferAllocation::Slice slice_rhs(&alloc_rhs, 0, length);\n-\n+  auto alloc_lhs =\n+      std::make_unique<BufferAllocation>(/*index=*/0, length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs(alloc_lhs.get(), 0, length);\n+  auto alloc_rhs =\n+      std::make_unique<BufferAllocation>(/*index=*/1, length, /*color=*/0);\n+  BufferAllocation::Slice slice_rhs(alloc_rhs.get(), 0, length);\n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/2, out_length, /*color=*/0));\n   BufferAllocation::Slice slice_out(fake_allocations.back().get(), 0,\n                                     out_length);\n-\n   fake_allocations.push_back(std::make_unique<BufferAllocation>(\n       /*index=*/3, 1024 * 1024, /*color=*/0));\n   BufferAllocation::Slice slice_workspace(fake_allocations.back().get(), 0,\n                                           1024 * 1024);\n-\n-  BufferAllocation alloc_lhs_offset_0(/*index=*/4, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_0(&alloc_lhs_offset_0, 0,\n+  auto alloc_lhs_offset_0 = std::make_unique<BufferAllocation>(\n+      /*index=*/4, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_0(alloc_lhs_offset_0.get(), 0,\n                                              offset_length);\n-\n-  BufferAllocation alloc_lhs_offset_1(/*index=*/5, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_1(&alloc_lhs_offset_1, 0,\n+  auto alloc_lhs_offset_1 = std::make_unique<BufferAllocation>(\n+      /*index=*/5, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_1(alloc_lhs_offset_1.get(), 0,\n                                              offset_length);\n-\n-  BufferAllocation alloc_rhs_offset_0(/*index=*/6, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_rhs_offset_0(&alloc_rhs_offset_0, 0,\n+  auto alloc_rhs_offset_0 = std::make_unique<BufferAllocation>(\n+      /*index=*/6, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_rhs_offset_0(alloc_rhs_offset_0.get(), 0,\n                                              offset_length);\n-\n-  BufferAllocation alloc_rhs_offset_1(/*index=*/7, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_rhs_offset_1(&alloc_rhs_offset_1, 0,\n+  auto alloc_rhs_offset_1 = std::make_unique<BufferAllocation>(\n+      /*index=*/7, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_rhs_offset_1(alloc_rhs_offset_1.get(), 0,\n                                              offset_length);\n \n+  backing_allocations.push_back(std::move(alloc_lhs));\n+  backing_allocations.push_back(std::move(alloc_rhs));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_0));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_1));\n+  backing_allocations.push_back(std::move(alloc_rhs_offset_0));\n+  backing_allocations.push_back(std::move(alloc_rhs_offset_1));\n+\n   // Preparing config for GEMM thunk.\n-  auto config = GemmConfig::For(\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n-      PrecisionConfig::ALG_UNSET, std::nullopt,\n-      se::blas::kDefaultComputePrecision, false, false,\n-      executor->GetDeviceDescription().gpu_compute_capability());\n-  ASSERT_TRUE(config.ok());\n+  TF_ASSIGN_OR_RETURN(\n+      GemmConfig config,\n+      GemmConfig::For(\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n+          PrecisionConfig::ALG_UNSET, std::nullopt,\n+          se::blas::kDefaultComputePrecision, false, false,\n+          executor->GetDeviceDescription().gpu_compute_capability()));\n \n   // Creating embedded GEMM thunk.\n   ThunkSequence seq;\n   seq.emplace_back(std::make_unique<GemmThunk>(\n-      Thunk::ThunkInfo(), config.value(), slice_lhs_fake, slice_rhs_fake,\n-      slice_out, slice_workspace, /*deterministic=*/true));\n+      Thunk::ThunkInfo(), config, slice_lhs_fake, slice_rhs_fake, slice_out,\n+      slice_workspace, /*deterministic=*/true));\n \n   // Wrapping address computation thunk around the GEMM thunk.\n   std::vector<DynamicSliceThunk::Offset> lhs_offsets{slice_lhs_offset_0,\n                                                      slice_lhs_offset_1};\n   std::vector<DynamicSliceThunk::Offset> rhs_offsets{slice_rhs_offset_0,\n                                                      slice_rhs_offset_1};\n-  DynamicSliceThunk thunk(\n+  return std::make_unique<DynamicSliceThunk>(\n       Thunk::ThunkInfo(), std::make_unique<ThunkSequence>(std::move(seq)),\n-      {slice_lhs, slice_rhs, slice_out, slice_workspace},\n+      std::vector<std::optional<BufferAllocation::Slice>>{\n+          slice_lhs, slice_rhs, slice_out, slice_workspace},\n       std::move(fake_allocations),\n-      {lhs_offsets, rhs_offsets, std::nullopt, std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}),\n-       ShapeUtil::MakeShape(PrimitiveType::F32, {8, 1}), std::nullopt,\n-       std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}),\n-       ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), std::nullopt,\n-       std::nullopt},\n-      {sizeof(int64_t), sizeof(int64_t), std::nullopt, std::nullopt});\n+      std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>>{\n+          lhs_offsets, rhs_offsets, std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}),\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {8, 1}), std::nullopt,\n+          std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}),\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), std::nullopt,\n+          std::nullopt},\n+      std::vector<std::optional<uint64_t>>{sizeof(int64_t), sizeof(int64_t),\n+                                           std::nullopt, std::nullopt});\n+}\n \n-  // Step 2:\n-  // Execute address computation thunk.\n-  //\n+TEST_F(DynamicSliceThunkTest, MultipleSlicedOperandsGemmProtoRoundTrip) {\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto thunk, CreateMultipleSlicedOperandsGemmThunk(backing_allocations));\n+  TF_ASSERT_OK_AND_ASSIGN(auto proto, thunk->ToProto());\n+  CheckProtoRoundTrip(*thunk, proto.dynamic_slice_thunk());\n+}\n+\n+TEST_F(DynamicSliceThunkTest, MultipleSlicedOperandsGemm) {\n   // Given a `lhs` tensor of shape f32[2,4]{1,0}\n   // The `lhs` slice that we want to use will be equivalent to this static\n   // slice op:\n   // f32[1,3]{1,0} slice(lhs), slice={[0:1], [1:4]}\n \n+  se::StreamExecutor* executor = GpuExecutor();\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto thunk, CreateMultipleSlicedOperandsGemmThunk(backing_allocations));\n+\n+  int64_t length = sizeof(float) * 2 * 4;\n+  int64_t out_length = sizeof(float) * 1;\n+  int64_t offset_length = sizeof(int64_t);\n+\n   // Preparing memory for thunk arguments.\n   // lhs = [1.0, 2.0, 3.0, 4.0,\n   //        5.0, 6.0, 7.0, 8.0]\n@@ -334,7 +440,6 @@ TEST_F(DynamicSliceThunkTest, MulipleSlicedOperandsGemm) {\n   //        7.0,\n   //        8.0]\n   se::DeviceMemory<float> rhs = executor->AllocateArray<float>(8);\n-  std::vector<float> rhs_arr(8, 1);\n   TF_ASSERT_OK(stream->Memcpy(&rhs, arr.data(), length));\n \n   se::DeviceMemory<float> out = executor->AllocateArray<float>(1);\n@@ -371,12 +476,12 @@ TEST_F(DynamicSliceThunkTest, MulipleSlicedOperandsGemm) {\n       run_options, allocations, stream.get(), stream.get(), nullptr, nullptr);\n \n   Thunk::ExecutableSource source = {/*text=*/\"\", /*binary=*/{}};\n-  TF_ASSERT_OK(thunk.Initialize(\n+  TF_ASSERT_OK(thunk->Initialize(\n       {executor, source, &allocations, stream.get(), stream.get()}));\n \n   // Execute address computation thunk and verify that it executed a GEMM on the\n   // right slices.\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n   TF_ASSERT_OK(stream->BlockHostUntilDone());\n \n   // Copy `out` data back to host for verification.\n@@ -450,9 +555,9 @@ TEST_F(DynamicSliceThunkTest, SlicedMemcpy) {\n \n   // Preparing custom call thunk: setting up call target and operands + results\n   // buffers.\n-  auto registration =\n-      xla::ffi::FindHandler(\"__xla_test$$memcpy\", GetPlatformName());\n-  ASSERT_TRUE(registration.ok());\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto registration,\n+      xla::ffi::FindHandler(\"__xla_test$$memcpy\", GetPlatformName()));\n \n   std::vector<std::optional<CustomCallThunk::Slice>> operands{\n       CustomCallThunk::Slice{slice_src_fake,\n@@ -466,7 +571,7 @@ TEST_F(DynamicSliceThunkTest, SlicedMemcpy) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       seq.emplace_back(),\n       CustomCallThunk::Create(Thunk::ThunkInfo(), \"__xla_test$$memcpy\",\n-                              registration->bundle, operands, results,\n+                              registration.bundle, operands, results,\n                               /*attributes=*/CustomCallThunk::AttributesMap(),\n                               /*called_computation=*/nullptr));\n \n@@ -613,9 +718,9 @@ TEST_F(DynamicSliceThunkTest, SlicedOutputMemcpy) {\n \n   // Preparing custom call thunk: setting up call target and operands + results\n   // buffers.\n-  auto registration =\n-      xla::ffi::FindHandler(\"__xla_test$$memcpy\", GetPlatformName());\n-  ASSERT_TRUE(registration.ok());\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto registration,\n+      xla::ffi::FindHandler(\"__xla_test$$memcpy\", GetPlatformName()));\n \n   std::vector<std::optional<CustomCallThunk::Slice>> operands{\n       CustomCallThunk::Slice{slice_src_fake,\n@@ -629,7 +734,7 @@ TEST_F(DynamicSliceThunkTest, SlicedOutputMemcpy) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       seq.emplace_back(),\n       CustomCallThunk::Create(Thunk::ThunkInfo(), \"__xla_test$$memcpy\",\n-                              registration->bundle, operands, results,\n+                              registration.bundle, operands, results,\n                               /*attributes=*/CustomCallThunk::AttributesMap(),\n                               /*called_computation=*/nullptr));\n \n@@ -742,95 +847,121 @@ TEST_F(DynamicSliceThunkTest, SlicedOutputMemcpy) {\n   ASSERT_EQ(out, ref);\n }\n \n-TEST_F(DynamicSliceThunkTest, SlicedGemmArbitraryArgumentOrder) {\n+absl::StatusOr<std::unique_ptr<DynamicSliceThunk>>\n+CreateSlicedGemmArbitraryArgumentOrderThunk(\n+    std::vector<std::unique_ptr<BufferAllocation>>& backing_allocations) {\n   se::StreamExecutor* executor = GpuExecutor();\n-\n-  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n-\n   int64_t lhs_length = sizeof(float) * 2 * 4;\n   int64_t rhs_length = sizeof(float) * 3 * 1;\n   int64_t out_length = sizeof(float) * 1 * 1;\n   int64_t offset_length = sizeof(int64_t);\n \n-  // Step 1:\n-  // Prepare embedded and address computation thunks.\n-\n   // Preparing buffer allocation slices for thunk creations.\n-  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations(4);\n-\n+  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations;\n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/0, rhs_length, /*color=*/0));\n   BufferAllocation::Slice slice_lhs_fake(fake_allocations.back().get(), 0,\n                                          rhs_length);\n-\n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/1, rhs_length, /*color=*/0));\n   BufferAllocation::Slice slice_rhs_fake(fake_allocations.back().get(), 0,\n                                          rhs_length);\n-\n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/2, out_length, /*color=*/0));\n   BufferAllocation::Slice slice_out_fake(fake_allocations.back().get(), 0,\n                                          out_length);\n-\n   fake_allocations.push_back(std::make_unique<BufferAllocation>(\n       /*index=*/3, 1024 * 1024, /*color=*/0));\n   BufferAllocation::Slice slice_workspace_fake(fake_allocations.back().get(), 0,\n                                                1024 * 1024);\n \n-  BufferAllocation alloc_lhs(/*index=*/1, lhs_length, /*color=*/0);\n-  BufferAllocation::Slice slice_lhs(&alloc_lhs, 0, lhs_length);\n-\n-  BufferAllocation alloc_rhs(/*index=*/3, rhs_length, /*color=*/0);\n-  BufferAllocation::Slice slice_rhs(&alloc_rhs, 0, rhs_length);\n-\n-  BufferAllocation alloc_out(/*index=*/2, out_length, /*color=*/0);\n-  BufferAllocation::Slice slice_out(&alloc_out, 0, out_length);\n-\n-  BufferAllocation alloc_workspace(/*index=*/0, 1024 * 1024, /*color=*/0);\n-  BufferAllocation::Slice slice_workspace(&alloc_workspace, 0, 1024 * 1024);\n-\n-  BufferAllocation alloc_lhs_offset_0(/*index=*/4, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_0(&alloc_lhs_offset_0, 0,\n+  auto alloc_lhs =\n+      std::make_unique<BufferAllocation>(/*index=*/1, lhs_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs(alloc_lhs.get(), 0, lhs_length);\n+  auto alloc_rhs =\n+      std::make_unique<BufferAllocation>(/*index=*/3, rhs_length, /*color=*/0);\n+  BufferAllocation::Slice slice_rhs(alloc_rhs.get(), 0, rhs_length);\n+  auto alloc_out =\n+      std::make_unique<BufferAllocation>(/*index=*/2, out_length, /*color=*/0);\n+  BufferAllocation::Slice slice_out(alloc_out.get(), 0, out_length);\n+  auto alloc_workspace = std::make_unique<BufferAllocation>(\n+      /*index=*/0, 1024 * 1024, /*color=*/0);\n+  BufferAllocation::Slice slice_workspace(alloc_workspace.get(), 0,\n+                                          1024 * 1024);\n+  auto alloc_lhs_offset_0 = std::make_unique<BufferAllocation>(\n+      /*index=*/4, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_0(alloc_lhs_offset_0.get(), 0,\n                                              offset_length);\n-\n-  BufferAllocation alloc_lhs_offset_1(/*index=*/5, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_1(&alloc_lhs_offset_1, 0,\n+  auto alloc_lhs_offset_1 = std::make_unique<BufferAllocation>(\n+      /*index=*/5, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_1(alloc_lhs_offset_1.get(), 0,\n                                              offset_length);\n+  backing_allocations.push_back(std::move(alloc_lhs));\n+  backing_allocations.push_back(std::move(alloc_rhs));\n+  backing_allocations.push_back(std::move(alloc_out));\n+  backing_allocations.push_back(std::move(alloc_workspace));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_0));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_1));\n \n   // Preparing config for GEMM thunk.\n-  auto config = GemmConfig::For(\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n-      PrecisionConfig::ALG_UNSET, std::nullopt,\n-      se::blas::kDefaultComputePrecision, false, false,\n-      executor->GetDeviceDescription().gpu_compute_capability());\n-  ASSERT_TRUE(config.ok());\n+  TF_ASSIGN_OR_RETURN(\n+      GemmConfig config,\n+      GemmConfig::For(\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n+          PrecisionConfig::ALG_UNSET, std::nullopt,\n+          se::blas::kDefaultComputePrecision, false, false,\n+          executor->GetDeviceDescription().gpu_compute_capability()));\n \n   // Creating embedded GEMM thunk.\n   ThunkSequence seq;\n   seq.emplace_back(std::make_unique<GemmThunk>(\n-      Thunk::ThunkInfo(), config.value(), slice_lhs_fake, slice_rhs_fake,\n+      Thunk::ThunkInfo(), config, slice_lhs_fake, slice_rhs_fake,\n       slice_out_fake, slice_workspace_fake, /*deterministic=*/true));\n \n   // Wrapping address computation thunk around the GEMM thunk.\n   std::vector<DynamicSliceThunk::Offset> lhs_offsets{slice_lhs_offset_0,\n                                                      slice_lhs_offset_1};\n-  DynamicSliceThunk thunk(\n+  return std::make_unique<DynamicSliceThunk>(\n       Thunk::ThunkInfo(), std::make_unique<ThunkSequence>(std::move(seq)),\n-      {slice_lhs, slice_rhs, slice_out, slice_workspace},\n+      std::vector<std::optional<BufferAllocation::Slice>>{\n+          slice_lhs, slice_rhs, slice_out, slice_workspace},\n       std::move(fake_allocations),\n-      {lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n-       std::nullopt, std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), std::nullopt,\n-       std::nullopt, std::nullopt},\n-      {sizeof(int64_t), std::nullopt, std::nullopt, std::nullopt});\n+      std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>>{\n+          lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n+          std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), std::nullopt,\n+          std::nullopt, std::nullopt},\n+      std::vector<std::optional<uint64_t>>{sizeof(int64_t), std::nullopt,\n+                                           std::nullopt, std::nullopt});\n+}\n+\n+TEST_F(DynamicSliceThunkTest, SlicedGemmArbitraryArgumentOrderProtoRoundTrip) {\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto thunk,\n+      CreateSlicedGemmArbitraryArgumentOrderThunk(backing_allocations));\n+  TF_ASSERT_OK_AND_ASSIGN(auto proto, thunk->ToProto());\n+  CheckProtoRoundTrip(*thunk, proto.dynamic_slice_thunk());\n+}\n+\n+TEST_F(DynamicSliceThunkTest, SlicedGemmArbitraryArgumentOrder) {\n+  se::StreamExecutor* executor = GpuExecutor();\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<DynamicSliceThunk> thunk,\n+      CreateSlicedGemmArbitraryArgumentOrderThunk(backing_allocations));\n+\n+  int64_t lhs_length = sizeof(float) * 2 * 4;\n+  int64_t rhs_length = sizeof(float) * 3 * 1;\n+  int64_t out_length = sizeof(float) * 1 * 1;\n+  int64_t offset_length = sizeof(int64_t);\n \n-  // Step 2:\n   // Execute address computation thunk.\n   //\n   // Given a `lhs` tensor of shape f32[2,4]{1,0}\n@@ -877,11 +1008,11 @@ TEST_F(DynamicSliceThunkTest, SlicedGemmArbitraryArgumentOrder) {\n       run_options, allocations, stream.get(), stream.get(), nullptr, nullptr);\n \n   Thunk::ExecutableSource source = {/*text=*/\"\", /*binary=*/{}};\n-  TF_ASSERT_OK(thunk.Initialize(\n+  TF_ASSERT_OK(thunk->Initialize(\n       {executor, source, &allocations, stream.get(), stream.get()}));\n \n   // Executing address computation thunk.\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n   TF_ASSERT_OK(stream->BlockHostUntilDone());\n \n   // Copying `out` data back to host for verification.\n@@ -891,102 +1022,128 @@ TEST_F(DynamicSliceThunkTest, SlicedGemmArbitraryArgumentOrder) {\n   ASSERT_EQ(dst, std::vector<float>({9}));\n }\n \n-TEST_F(DynamicSliceThunkTest, SlicedGemmArbitraryNumberOfArguments) {\n+absl::StatusOr<std::unique_ptr<DynamicSliceThunk>>\n+CreateSlicedGemmArbitraryNumberOfArgumentsThunk(\n+    std::vector<std::unique_ptr<BufferAllocation>>& backing_allocations) {\n   se::StreamExecutor* executor = GpuExecutor();\n-\n-  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n-\n   int64_t lhs_length = sizeof(float) * 2 * 4;\n   int64_t rhs_length = sizeof(float) * 3 * 1;\n   int64_t out_length = sizeof(float) * 1 * 1;\n   int64_t offset_length = sizeof(int64_t);\n \n-  // Step 1:\n-  // Prepare embedded and address computation thunks.\n-\n   // Preparing buffer allocation slices for thunk creations.\n-  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations(4);\n-\n+  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations;\n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/0, rhs_length, /*color=*/0));\n   BufferAllocation::Slice slice_lhs_fake(fake_allocations.back().get(), 0,\n                                          rhs_length);\n-\n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/1, rhs_length, /*color=*/0));\n   BufferAllocation::Slice slice_rhs_fake(fake_allocations.back().get(), 0,\n                                          rhs_length);\n-\n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/2, out_length, /*color=*/0));\n   BufferAllocation::Slice slice_out_fake(fake_allocations.back().get(), 0,\n                                          out_length);\n-\n   fake_allocations.push_back(std::make_unique<BufferAllocation>(\n       /*index=*/3, 1024 * 1024, /*color=*/0));\n   BufferAllocation::Slice slice_workspace_fake(fake_allocations.back().get(), 0,\n                                                1024 * 1024);\n \n-  BufferAllocation alloc_lhs(/*index=*/7, lhs_length, /*color=*/0);\n-  BufferAllocation::Slice slice_lhs(&alloc_lhs, 0, lhs_length);\n-\n-  BufferAllocation alloc_rhs(/*index=*/3, rhs_length, /*color=*/0);\n-  BufferAllocation::Slice slice_rhs(&alloc_rhs, 0, rhs_length);\n-\n-  BufferAllocation alloc_out(/*index=*/2, out_length, /*color=*/0);\n-  BufferAllocation::Slice slice_out(&alloc_out, 0, out_length);\n-\n-  BufferAllocation alloc_workspace(/*index=*/0, 1024 * 1024, /*color=*/0);\n-  BufferAllocation::Slice slice_workspace(&alloc_workspace, 0, 1024 * 1024);\n-\n-  BufferAllocation alloc_lhs_offset_0(/*index=*/4, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_0(&alloc_lhs_offset_0, 0,\n+  auto alloc_lhs =\n+      std::make_unique<BufferAllocation>(/*index=*/7, lhs_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs(alloc_lhs.get(), 0, lhs_length);\n+  auto alloc_rhs =\n+      std::make_unique<BufferAllocation>(/*index=*/3, rhs_length, /*color=*/0);\n+  BufferAllocation::Slice slice_rhs(alloc_rhs.get(), 0, rhs_length);\n+  auto alloc_out =\n+      std::make_unique<BufferAllocation>(/*index=*/2, out_length, /*color=*/0);\n+  BufferAllocation::Slice slice_out(alloc_out.get(), 0, out_length);\n+  auto alloc_workspace = std::make_unique<BufferAllocation>(\n+      /*index=*/0, 1024 * 1024, /*color=*/0);\n+  BufferAllocation::Slice slice_workspace(alloc_workspace.get(), 0,\n+                                          1024 * 1024);\n+  auto alloc_lhs_offset_0 = std::make_unique<BufferAllocation>(\n+      /*index=*/4, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_0(alloc_lhs_offset_0.get(), 0,\n                                              offset_length);\n-\n-  BufferAllocation alloc_lhs_offset_1(/*index=*/5, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_1(&alloc_lhs_offset_1, 0,\n+  auto alloc_lhs_offset_1 = std::make_unique<BufferAllocation>(\n+      /*index=*/5, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_1(alloc_lhs_offset_1.get(), 0,\n                                              offset_length);\n \n+  backing_allocations.push_back(std::move(alloc_lhs));\n+  backing_allocations.push_back(std::move(alloc_rhs));\n+  backing_allocations.push_back(std::move(alloc_out));\n+  backing_allocations.push_back(std::move(alloc_workspace));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_0));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_1));\n+\n   // Preparing config for GEMM thunk.\n-  auto config = GemmConfig::For(\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n-      PrecisionConfig::ALG_UNSET, std::nullopt,\n-      se::blas::kDefaultComputePrecision, false, false,\n-      executor->GetDeviceDescription().gpu_compute_capability());\n-  ASSERT_TRUE(config.ok());\n+  TF_ASSIGN_OR_RETURN(\n+      GemmConfig config,\n+      GemmConfig::For(\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n+          PrecisionConfig::ALG_UNSET, std::nullopt,\n+          se::blas::kDefaultComputePrecision, false, false,\n+          executor->GetDeviceDescription().gpu_compute_capability()));\n \n   // Creating embedded GEMM thunk.\n   ThunkSequence seq;\n   seq.emplace_back(std::make_unique<GemmThunk>(\n-      Thunk::ThunkInfo(), config.value(), slice_lhs_fake, slice_rhs_fake,\n+      Thunk::ThunkInfo(), config, slice_lhs_fake, slice_rhs_fake,\n       slice_out_fake, slice_workspace_fake, /*deterministic=*/true));\n \n   // Wrapping address computation thunk around the GEMM thunk.\n   std::vector<DynamicSliceThunk::Offset> lhs_offsets{slice_lhs_offset_0,\n                                                      slice_lhs_offset_1};\n-  DynamicSliceThunk thunk(\n+  return std::make_unique<DynamicSliceThunk>(\n       Thunk::ThunkInfo(), std::make_unique<ThunkSequence>(std::move(seq)),\n-      {slice_lhs, slice_rhs, slice_out, slice_workspace},\n+      std::vector<std::optional<BufferAllocation::Slice>>{\n+          slice_lhs, slice_rhs, slice_out, slice_workspace},\n       std::move(fake_allocations),\n-      {lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n-       std::nullopt, std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), std::nullopt,\n-       std::nullopt, std::nullopt},\n-      {sizeof(int64_t), std::nullopt, std::nullopt, std::nullopt});\n+      std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>>{\n+          lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n+          std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), std::nullopt,\n+          std::nullopt, std::nullopt},\n+      std::vector<std::optional<uint64_t>>{sizeof(int64_t), std::nullopt,\n+                                           std::nullopt, std::nullopt});\n+}\n \n-  // Step 2:\n-  // Execute address computation thunk.\n-  //\n+TEST_F(DynamicSliceThunkTest,\n+       SlicedGemmArbitraryNumberOfArgumentsProtoRoundTrip) {\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<DynamicSliceThunk> thunk,\n+      CreateSlicedGemmArbitraryNumberOfArgumentsThunk(backing_allocations));\n+  TF_ASSERT_OK_AND_ASSIGN(auto proto, thunk->ToProto());\n+  CheckProtoRoundTrip(*thunk, proto.dynamic_slice_thunk());\n+}\n+\n+TEST_F(DynamicSliceThunkTest, SlicedGemmArbitraryNumberOfArguments) {\n   // Given a `lhs` tensor of shape f32[2,4]{1,0}\n   // The `lhs` slice that we want to use will be equivalent to this static\n   // slice op:\n   // f32[1,3]{1,0} slice(lhs), slice={[0:1], [1:4]}\n \n+  se::StreamExecutor* executor = GpuExecutor();\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<DynamicSliceThunk> thunk,\n+      CreateSlicedGemmArbitraryNumberOfArgumentsThunk(backing_allocations));\n+\n+  int64_t lhs_length = sizeof(float) * 2 * 4;\n+  int64_t rhs_length = sizeof(float) * 3 * 1;\n+  int64_t out_length = sizeof(float) * 1 * 1;\n+  int64_t offset_length = sizeof(int64_t);\n+\n   // Preparing memory for thunk arguments.\n   // lhs = [1.0, 2.0, 3.0, 4.0,\n   //        5.0, 6.0, 7.0, 8.0]\n@@ -1028,11 +1185,11 @@ TEST_F(DynamicSliceThunkTest, SlicedGemmArbitraryNumberOfArguments) {\n       run_options, allocations, stream.get(), stream.get(), nullptr, nullptr);\n \n   Thunk::ExecutableSource source = {/*text=*/\"\", /*binary=*/{}};\n-  TF_ASSERT_OK(thunk.Initialize(\n+  TF_ASSERT_OK(thunk->Initialize(\n       {executor, source, &allocations, stream.get(), stream.get()}));\n \n   // Executing address computation thunk.\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n   TF_ASSERT_OK(stream->BlockHostUntilDone());\n \n   // Copying `out` data back to host for verification.\n@@ -1042,29 +1199,25 @@ TEST_F(DynamicSliceThunkTest, SlicedGemmArbitraryNumberOfArguments) {\n   ASSERT_EQ(dst, std::vector<float>({9}));\n }\n \n-TEST_F(DynamicSliceThunkTest, SlicedTupledOperandGemm) {\n+absl::StatusOr<std::unique_ptr<DynamicSliceThunk>>\n+CreateSlicedTupledOperandGemmThunk(\n+    std::vector<std::unique_ptr<BufferAllocation>>& backing_allocations) {\n   se::StreamExecutor* executor = GpuExecutor();\n-\n-  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n-\n   int64_t lhs_length = sizeof(float) * 2 * 4;\n   int64_t rhs_length = sizeof(float) * 3 * 1;\n   int64_t out_length = sizeof(float) * 1 * 1;\n   int64_t offset_length = sizeof(int64_t);\n \n-  // Step 1:\n-  // Prepare embedded and address computation thunks.\n-\n   // Preparing buffer allocation slices for thunk creations.\n-  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations(4);\n-\n+  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations;\n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/0, rhs_length, /*color=*/0));\n   BufferAllocation::Slice slice_lhs_fake(fake_allocations.back().get(), 0,\n                                          rhs_length);\n \n-  BufferAllocation alloc_lhs(/*index=*/0, 3 * lhs_length, /*color=*/0);\n-  BufferAllocation::Slice slice_lhs(&alloc_lhs, lhs_length, lhs_length);\n+  auto alloc_lhs = std::make_unique<BufferAllocation>(\n+      /*index=*/0, 3 * lhs_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs(alloc_lhs.get(), lhs_length, lhs_length);\n \n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/1, rhs_length, /*color=*/0));\n@@ -1081,49 +1234,76 @@ TEST_F(DynamicSliceThunkTest, SlicedTupledOperandGemm) {\n   BufferAllocation::Slice slice_workspace(fake_allocations.back().get(), 0,\n                                           1024 * 1024);\n \n-  BufferAllocation alloc_lhs_offset_0(/*index=*/4, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_0(&alloc_lhs_offset_0, 0,\n+  auto alloc_lhs_offset_0 = std::make_unique<BufferAllocation>(\n+      /*index=*/4, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_0(alloc_lhs_offset_0.get(), 0,\n                                              offset_length);\n \n-  BufferAllocation alloc_lhs_offset_1(/*index=*/5, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_1(&alloc_lhs_offset_1, 0,\n+  auto alloc_lhs_offset_1 = std::make_unique<BufferAllocation>(\n+      /*index=*/5, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_1(alloc_lhs_offset_1.get(), 0,\n                                              offset_length);\n \n+  backing_allocations.push_back(std::move(alloc_lhs));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_0));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_1));\n+\n   // Preparing config for GEMM thunk.\n-  auto config = GemmConfig::For(\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n-      PrecisionConfig::ALG_UNSET, std::nullopt,\n-      se::blas::kDefaultComputePrecision, false, false,\n-      executor->GetDeviceDescription().gpu_compute_capability());\n-  ASSERT_TRUE(config.ok());\n+  TF_ASSIGN_OR_RETURN(\n+      GemmConfig config,\n+      GemmConfig::For(\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n+          PrecisionConfig::ALG_UNSET, std::nullopt,\n+          se::blas::kDefaultComputePrecision, false, false,\n+          executor->GetDeviceDescription().gpu_compute_capability()));\n \n   // Creating embedded GEMM thunk.\n   ThunkSequence seq;\n   seq.emplace_back(std::make_unique<GemmThunk>(\n-      Thunk::ThunkInfo(), config.value(), slice_lhs_fake, slice_rhs, slice_out,\n+      Thunk::ThunkInfo(), config, slice_lhs_fake, slice_rhs, slice_out,\n       slice_workspace, /*deterministic=*/true));\n \n   // Wrapping address computation thunk around the GEMM thunk.\n   std::vector<DynamicSliceThunk::Offset> lhs_offsets{slice_lhs_offset_0,\n                                                      slice_lhs_offset_1};\n-  DynamicSliceThunk thunk(\n+  return std::make_unique<DynamicSliceThunk>(\n       Thunk::ThunkInfo(), std::make_unique<ThunkSequence>(std::move(seq)),\n-      {slice_lhs, slice_rhs, slice_out, slice_workspace},\n+      std::vector<std::optional<BufferAllocation::Slice>>{\n+          slice_lhs, slice_rhs, slice_out, slice_workspace},\n       std::move(fake_allocations),\n-      {lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n-       std::nullopt, std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), std::nullopt,\n-       std::nullopt, std::nullopt},\n-      {sizeof(int64_t), std::nullopt, std::nullopt, std::nullopt});\n+      std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>>{\n+          lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n+          std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), std::nullopt,\n+          std::nullopt, std::nullopt},\n+      std::vector<std::optional<uint64_t>>{sizeof(int64_t), std::nullopt,\n+                                           std::nullopt, std::nullopt});\n+}\n \n-  // Step 2:\n-  // Execute address computation thunk.\n-  //\n+TEST_F(DynamicSliceThunkTest, SlicedTupledOperandGemmProtoRoundTrip) {\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto thunk, CreateSlicedTupledOperandGemmThunk(backing_allocations));\n+  TF_ASSERT_OK_AND_ASSIGN(auto proto, thunk->ToProto());\n+  CheckProtoRoundTrip(*thunk, proto.dynamic_slice_thunk());\n+}\n+\n+TEST_F(DynamicSliceThunkTest, SlicedTupledOperandGemm) {\n+  se::StreamExecutor* executor = GpuExecutor();\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto thunk, CreateSlicedTupledOperandGemmThunk(backing_allocations));\n+\n+  int64_t lhs_length = sizeof(float) * 2 * 4;\n+  int64_t rhs_length = sizeof(float) * 3 * 1;\n+  int64_t out_length = sizeof(float) * 1 * 1;\n+  int64_t offset_length = sizeof(int64_t);\n \n   // Preparing memory for thunk arguments.\n   // lhs = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 4.0,\n@@ -1176,11 +1356,11 @@ TEST_F(DynamicSliceThunkTest, SlicedTupledOperandGemm) {\n       run_options, allocations, stream.get(), stream.get(), nullptr, nullptr);\n \n   Thunk::ExecutableSource source = {/*text=*/\"\", /*binary=*/{}};\n-  TF_ASSERT_OK(thunk.Initialize(\n+  TF_ASSERT_OK(thunk->Initialize(\n       {executor, source, &allocations, stream.get(), stream.get()}));\n \n   // Executing address computation thunk.\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n   TF_ASSERT_OK(stream->BlockHostUntilDone());\n \n   // Copying `out` data back to host for verification.\n@@ -1260,9 +1440,9 @@ TEST_F(DynamicSliceThunkTest, SlicedMemcpyOOB) {\n \n   // Preparing custom call thunk: setting up call target and operands + results\n   // buffers.\n-  auto registration =\n-      xla::ffi::FindHandler(\"__xla_test$$memcpy\", GetPlatformName());\n-  ASSERT_TRUE(registration.ok());\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto registration,\n+      xla::ffi::FindHandler(\"__xla_test$$memcpy\", GetPlatformName()));\n \n   std::vector<std::optional<CustomCallThunk::Slice>> operands{\n       CustomCallThunk::Slice{slice_src_fake,\n@@ -1276,7 +1456,7 @@ TEST_F(DynamicSliceThunkTest, SlicedMemcpyOOB) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       seq.emplace_back(),\n       CustomCallThunk::Create(Thunk::ThunkInfo(), \"__xla_test$$memcpy\",\n-                              registration->bundle, operands, results,\n+                              registration.bundle, operands, results,\n                               /*attributes=*/CustomCallThunk::AttributesMap(),\n                               /*called_computation=*/nullptr));\n \n@@ -1392,22 +1572,17 @@ TEST_F(DynamicSliceThunkTest, SlicedMemcpyOOB) {\n   ASSERT_EQ(out, ref);\n }\n \n-TEST_F(DynamicSliceThunkTest, SlicedOperandsSameBufferGemm) {\n+absl::StatusOr<std::unique_ptr<DynamicSliceThunk>>\n+CreateSlicedOperandsSameBufferGemmThunk(\n+    std::vector<std::unique_ptr<BufferAllocation>>& backing_allocations) {\n   se::StreamExecutor* executor = GpuExecutor();\n-\n-  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n-\n   int64_t lhs_length = sizeof(float) * 2 * 4;\n   int64_t rhs_length = sizeof(float) * 3 * 1;\n   int64_t out_length = sizeof(float) * 1 * 1;\n   int64_t offset_length = sizeof(int64_t);\n \n-  // Step 1:\n-  // Prepare embedded and address computation thunks.\n-\n   // Preparing buffer allocation slices for thunk creations.\n-  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations(4);\n-\n+  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations;\n   fake_allocations.push_back(\n       std::make_unique<BufferAllocation>(/*index=*/0, rhs_length, /*color=*/0));\n   BufferAllocation::Slice slice_lhs_fake(fake_allocations.back().get(), 0,\n@@ -1428,59 +1603,89 @@ TEST_F(DynamicSliceThunkTest, SlicedOperandsSameBufferGemm) {\n   BufferAllocation::Slice slice_workspace_fake(fake_allocations.back().get(), 0,\n                                                1024 * 1024);\n \n-  BufferAllocation alloc(/*index=*/0, lhs_length + rhs_length + out_length,\n-                         /*color=*/0);\n-  BufferAllocation::Slice slice_lhs(&alloc, 0, lhs_length);\n-  BufferAllocation::Slice slice_rhs(&alloc, lhs_length, rhs_length);\n-  BufferAllocation::Slice slice_out(&alloc, lhs_length + rhs_length,\n+  auto alloc = std::make_unique<BufferAllocation>(\n+      /*index=*/0, lhs_length + rhs_length + out_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs(alloc.get(), 0, lhs_length);\n+  BufferAllocation::Slice slice_rhs(alloc.get(), lhs_length, rhs_length);\n+  BufferAllocation::Slice slice_out(alloc.get(), lhs_length + rhs_length,\n                                     out_length);\n \n-  BufferAllocation alloc_workspace(/*index=*/1, 1024 * 1024, /*color=*/0);\n-  BufferAllocation::Slice slice_workspace(&alloc_workspace, 0, 1024 * 1024);\n+  auto alloc_workspace = std::make_unique<BufferAllocation>(\n+      /*index=*/1, 1024 * 1024, /*color=*/0);\n+  BufferAllocation::Slice slice_workspace(alloc_workspace.get(), 0,\n+                                          1024 * 1024);\n \n-  BufferAllocation alloc_lhs_offset_0(/*index=*/2, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_0(&alloc_lhs_offset_0, 0,\n+  auto alloc_lhs_offset_0 = std::make_unique<BufferAllocation>(\n+      /*index=*/2, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_0(alloc_lhs_offset_0.get(), 0,\n                                              offset_length);\n \n-  BufferAllocation alloc_lhs_offset_1(/*index=*/3, offset_length,\n-                                      /*color=*/0);\n-  BufferAllocation::Slice slice_lhs_offset_1(&alloc_lhs_offset_1, 0,\n+  auto alloc_lhs_offset_1 = std::make_unique<BufferAllocation>(\n+      /*index=*/3, offset_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs_offset_1(alloc_lhs_offset_1.get(), 0,\n                                              offset_length);\n \n+  backing_allocations.push_back(std::move(alloc));\n+  backing_allocations.push_back(std::move(alloc_workspace));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_0));\n+  backing_allocations.push_back(std::move(alloc_lhs_offset_1));\n+\n   // Preparing config for GEMM thunk.\n-  auto config = GemmConfig::For(\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n-      ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n-      PrecisionConfig::ALG_UNSET, std::nullopt,\n-      se::blas::kDefaultComputePrecision, false, false,\n-      executor->GetDeviceDescription().gpu_compute_capability());\n-  ASSERT_TRUE(config.ok());\n+  TF_ASSIGN_OR_RETURN(\n+      GemmConfig config,\n+      GemmConfig::For(\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), {}, {1},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {3, 1}), {}, {0},\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 1}), 1.0, 0.0, 0.0,\n+          PrecisionConfig::ALG_UNSET, std::nullopt,\n+          se::blas::kDefaultComputePrecision, false, false,\n+          executor->GetDeviceDescription().gpu_compute_capability()));\n \n   // Creating embedded GEMM thunk.\n   ThunkSequence seq;\n   seq.emplace_back(std::make_unique<GemmThunk>(\n-      Thunk::ThunkInfo(), config.value(), slice_lhs_fake, slice_rhs_fake,\n+      Thunk::ThunkInfo(), config, slice_lhs_fake, slice_rhs_fake,\n       slice_out_fake, slice_workspace_fake, /*deterministic=*/true));\n \n   // Wrapping address computation thunk around the GEMM thunk.\n   std::vector<DynamicSliceThunk::Offset> lhs_offsets{slice_lhs_offset_0,\n                                                      slice_lhs_offset_1};\n-  DynamicSliceThunk thunk(\n+  return std::make_unique<DynamicSliceThunk>(\n       Thunk::ThunkInfo(), std::make_unique<ThunkSequence>(std::move(seq)),\n-      {slice_lhs, slice_rhs, slice_out, slice_workspace},\n+      std::vector<std::optional<BufferAllocation::Slice>>{\n+          slice_lhs, slice_rhs, slice_out, slice_workspace},\n       std::move(fake_allocations),\n-      {lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n-       std::nullopt, std::nullopt},\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), std::nullopt,\n-       std::nullopt, std::nullopt},\n-      {sizeof(int64_t), std::nullopt, std::nullopt, std::nullopt});\n+      std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>>{\n+          lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n+          std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 3}), std::nullopt,\n+          std::nullopt, std::nullopt},\n+      std::vector<std::optional<uint64_t>>{sizeof(int64_t), std::nullopt,\n+                                           std::nullopt, std::nullopt});\n+}\n \n-  // Step 2:\n-  // Execute address computation thunk.\n-  //\n+TEST_F(DynamicSliceThunkTest, SlicedOperandsSameBufferGemmProtoRoundTrip) {\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto thunk, CreateSlicedOperandsSameBufferGemmThunk(backing_allocations));\n+  TF_ASSERT_OK_AND_ASSIGN(auto proto, thunk->ToProto());\n+  CheckProtoRoundTrip(*thunk, proto.dynamic_slice_thunk());\n+}\n+\n+TEST_F(DynamicSliceThunkTest, SlicedOperandsSameBufferGemm) {\n+  se::StreamExecutor* executor = GpuExecutor();\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto thunk, CreateSlicedOperandsSameBufferGemmThunk(backing_allocations));\n+\n+  int64_t lhs_length = sizeof(float) * 2 * 4;\n+  int64_t rhs_length = sizeof(float) * 3 * 1;\n+  int64_t out_length = sizeof(float) * 1 * 1;\n+  int64_t offset_length = sizeof(int64_t);\n \n   // Preparing memory for thunk arguments.\n   // lhs = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 4.0,\n@@ -1532,11 +1737,11 @@ TEST_F(DynamicSliceThunkTest, SlicedOperandsSameBufferGemm) {\n       run_options, allocations, stream.get(), stream.get(), nullptr, nullptr);\n \n   Thunk::ExecutableSource source = {/*text=*/\"\", /*binary=*/{}};\n-  TF_ASSERT_OK(thunk.Initialize(\n+  TF_ASSERT_OK(thunk->Initialize(\n       {executor, source, &allocations, stream.get(), stream.get()}));\n \n   // Executing address computation thunk.\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n   TF_ASSERT_OK(stream->BlockHostUntilDone());\n \n   // Copying `out` data back to host for verification.\n@@ -1546,8 +1751,9 @@ TEST_F(DynamicSliceThunkTest, SlicedOperandsSameBufferGemm) {\n   ASSERT_EQ(dst, std::vector<float>({9}));\n }\n \n-TEST_F(DynamicSliceThunkTest,\n-       HostInductionVariableAndOffsetEvaluationExecutesCorrectly) {\n+absl::StatusOr<std::unique_ptr<DynamicSliceThunk>>\n+CreateHostInductionVariableAndOffsetEvaluationThunk(\n+    std::vector<std::unique_ptr<BufferAllocation>>& backing_allocations) {\n   std::vector<std::unique_ptr<HloModule>> offset_modules;\n   const char* offset = R\"(\n     HloModule offset\n@@ -1560,17 +1766,18 @@ TEST_F(DynamicSliceThunkTest,\n       ROOT select = s32[] select(compare, add, p0)\n     }\n   )\";\n-  TF_ASSERT_OK_AND_ASSIGN(offset_modules.emplace_back(),\n-                          ParseAndReturnVerifiedModule(offset));\n-  HloModule* offset_module = offset_modules.back().get();\n+  TF_ASSIGN_OR_RETURN(auto offset_module,\n+                      ParseAndReturnUnverifiedModule(offset));\n+  offset_modules.emplace_back(std::move(offset_module));\n+  HloModule* offset_module_ptr = offset_modules.back().get();\n   const char* indvar_init = R\"(\n     HloModule indvar_init\n     ENTRY main {\n       ROOT c0 = s32[] constant(0)\n     }\n   )\";\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> indvar_init_module,\n-                          ParseAndReturnVerifiedModule(indvar_init));\n+  TF_ASSIGN_OR_RETURN(auto indvar_init_module,\n+                      ParseAndReturnUnverifiedModule(indvar_init));\n   const char* indvar_update = R\"(\n     HloModule indvar_update\n     ENTRY main {\n@@ -1579,32 +1786,25 @@ TEST_F(DynamicSliceThunkTest,\n       ROOT add = s32[] add(p0, c1)\n     }\n   )\";\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> indvar_update_module,\n-                          ParseAndReturnVerifiedModule(indvar_update));\n-\n+  TF_ASSIGN_OR_RETURN(auto indvar_update_module,\n+                      ParseAndReturnUnverifiedModule(indvar_update));\n   se::StreamExecutor* executor = GpuExecutor();\n \n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<stream_executor::Stream> stream,\n-                          executor->CreateStream());\n-\n   int64_t lhs_length = sizeof(float) * 2 * 4;\n   int64_t rhs_length = sizeof(float) * 4 * 1;\n   int64_t out_length = sizeof(float) * 1 * 1;\n \n-  // Step 1:\n-  // Prepare embedded and address computation thunks.\n-\n   // Preparing buffer allocation slices for thunk creations.\n-  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations(4);\n-\n+  std::vector<std::unique_ptr<BufferAllocation>> fake_allocations;\n   fake_allocations.push_back(std::make_unique<BufferAllocation>(\n       /*index=*/0, /*size=*/rhs_length, /*color=*/0));\n   BufferAllocation::Slice slice_lhs_fake(\n       /*allocation=*/fake_allocations.back().get(), /*offset=*/0,\n       /*size=*/rhs_length);\n \n-  BufferAllocation alloc_lhs(/*index=*/0, /*size=*/lhs_length, /*color=*/0);\n-  BufferAllocation::Slice slice_lhs(&alloc_lhs, /*offset=*/0,\n+  auto alloc_lhs = std::make_unique<BufferAllocation>(\n+      /*index=*/0, /*size=*/lhs_length, /*color=*/0);\n+  BufferAllocation::Slice slice_lhs(alloc_lhs.get(), /*offset=*/0,\n                                     /*size=*/lhs_length);\n \n   fake_allocations.push_back(std::make_unique<BufferAllocation>(\n@@ -1625,66 +1825,100 @@ TEST_F(DynamicSliceThunkTest,\n       /*allocation=*/fake_allocations.back().get(), /*offset=*/0,\n       /*size=*/1024 * 1024);\n \n+  backing_allocations.push_back(std::move(alloc_lhs));\n+\n   // Preparing config for GEMM thunk.\n-  absl::StatusOr<GemmConfig> config = GemmConfig::For(\n-      /*lhs_shape=*/ShapeUtil::MakeShape(/*element_type=*/PrimitiveType::F32,\n-                                         /*dimensions=*/{1, 4}),\n-      /*lhs_batch_dims=*/{}, /*lhs_contracting_dims=*/{1},\n-      /*rhs_shape=*/\n-      ShapeUtil::MakeShape(/*element_type=*/PrimitiveType::F32,\n-                           /*dimensions=*/{4, 1}),\n-      /*rhs_batch_dims=*/{}, /*rhs_contracting_dims=*/{0},\n-      /*output_shape=*/\n-      ShapeUtil::MakeShape(/*element_type=*/PrimitiveType::F32,\n-                           /*dimensions=*/{1, 1}),\n-      /*alpha_real=*/1.0, /*alpha_imag=*/0.0, /*beta=*/0.0,\n-      /*precision_algorithm=*/PrecisionConfig::ALG_UNSET,\n-      /*algorithm=*/std::nullopt,\n-      /*compute_precision=*/se::blas::kDefaultComputePrecision,\n-      /*grad_x=*/false, /*grad_y=*/false,\n-      /*gpu_version=*/\n-      executor->GetDeviceDescription().gpu_compute_capability());\n-  ASSERT_TRUE(config.ok());\n+\n+  TF_ASSIGN_OR_RETURN(\n+      GemmConfig config,\n+      GemmConfig::For(\n+          /*lhs_shape=*/ShapeUtil::MakeShape(\n+              /*element_type=*/PrimitiveType::F32,\n+              /*dimensions=*/{1, 4}),\n+          /*lhs_batch_dims=*/{}, /*lhs_contracting_dims=*/{1},\n+          /*rhs_shape=*/\n+          ShapeUtil::MakeShape(/*element_type=*/PrimitiveType::F32,\n+                               /*dimensions=*/{4, 1}),\n+          /*rhs_batch_dims=*/{}, /*rhs_contracting_dims=*/{0},\n+          /*output_shape=*/\n+          ShapeUtil::MakeShape(/*element_type=*/PrimitiveType::F32,\n+                               /*dimensions=*/{1, 1}),\n+          /*alpha_real=*/1.0, /*alpha_imag=*/0.0, /*beta=*/0.0,\n+          /*precision_algorithm=*/PrecisionConfig::ALG_UNSET,\n+          /*algorithm=*/std::nullopt,\n+          /*compute_precision=*/se::blas::kDefaultComputePrecision,\n+          /*grad_x=*/false, /*grad_y=*/false,\n+          /*gpu_version=*/\n+          executor->GetDeviceDescription().gpu_compute_capability()));\n \n   // Creating embedded GEMM thunk.\n   ThunkSequence seq;\n   seq.emplace_back(std::make_unique<GemmThunk>(\n-      /*thunk_info*/ Thunk::ThunkInfo(), /*config=*/config.value(),\n+      /*thunk_info*/ Thunk::ThunkInfo(), /*config=*/config,\n       /*lhs_buffer=*/slice_lhs_fake, /*rhs_buffer=*/slice_rhs,\n       /*output_buffer=*/slice_out,\n       /*workspace=*/slice_workspace, /*deterministic=*/true));\n \n-  // Wrapping address computation thunk around the GEMM thunk.\n-  std::vector<DynamicSliceThunk::Offset> lhs_offsets{offset_module, 0l};\n+  // Wrapping dynamic slice thunk around the GEMM thunk.\n+  std::vector<DynamicSliceThunk::Offset> lhs_offsets{offset_module_ptr, 0l};\n   DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata\n       offset_as_function_of_indvar_modules_metadata(\n           std::move(indvar_init_module), std::move(indvar_update_module),\n           std::move(offset_modules));\n-  DynamicSliceThunk thunk(\n+  return std::make_unique<DynamicSliceThunk>(\n       /*thunk_info=*/Thunk::ThunkInfo(),\n       /*embedded_thunk=*/std::make_unique<ThunkSequence>(std::move(seq)),\n-      /*arguments=*/{slice_lhs, slice_rhs, slice_out, slice_workspace},\n+      /*arguments=*/\n+      std::vector<std::optional<BufferAllocation::Slice>>{\n+          slice_lhs, slice_rhs, slice_out, slice_workspace},\n       /*fake_allocations=*/std::move(fake_allocations),\n-      /*offsets=*/{lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n+      /*offsets=*/\n+      std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>>{\n+          lhs_offsets, std::nullopt, std::nullopt, std::nullopt},\n       /*orig_shapes=*/\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n-       std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {2, 4}), std::nullopt,\n+          std::nullopt, std::nullopt},\n       /*sliced_shapes=*/\n-      {ShapeUtil::MakeShape(PrimitiveType::F32, {1, 4}), std::nullopt,\n-       std::nullopt, std::nullopt},\n+      std::vector<std::optional<Shape>>{\n+          ShapeUtil::MakeShape(PrimitiveType::F32, {1, 4}), std::nullopt,\n+          std::nullopt, std::nullopt},\n       /*offset_byte_sizes=*/\n-      {sizeof(int64_t), std::nullopt, std::nullopt, std::nullopt},\n+      std::vector<std::optional<uint64_t>>{sizeof(int64_t), std::nullopt,\n+                                           std::nullopt, std::nullopt},\n       /*offset_as_function_of_indvar_metadata=*/\n       std::move(offset_as_function_of_indvar_modules_metadata));\n+}\n \n-  // Step 2:\n-  // Execute address computation thunk.\n-  //\n+TEST_F(\n+    DynamicSliceThunkTest,\n+    HostInductionVariableAndOffsetEvaluationExecutesCorrectlyProtoRoundTrip) {\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto thunk,\n+      CreateHostInductionVariableAndOffsetEvaluationThunk(backing_allocations));\n+  TF_ASSERT_OK_AND_ASSIGN(auto proto, thunk->ToProto());\n+  CheckProtoRoundTrip(*thunk, proto.dynamic_slice_thunk());\n+}\n+\n+TEST_F(DynamicSliceThunkTest,\n+       HostInductionVariableAndOffsetEvaluationExecutesCorrectly) {\n   // Given a `lhs` tensor of shape f32[2,4]{1,0}\n   // The `lhs` slice that we want to use will be equivalent to this static\n   // slice op:\n   // f32[1,3]{1,0} slice(lhs), slice={[0:1], [0:4]}\n \n+  se::StreamExecutor* executor = GpuExecutor();\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n+  std::vector<std::unique_ptr<BufferAllocation>> backing_allocations;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto thunk,\n+      CreateHostInductionVariableAndOffsetEvaluationThunk(backing_allocations));\n+\n+  int64_t lhs_length = sizeof(float) * 2 * 4;\n+  int64_t rhs_length = sizeof(float) * 4 * 1;\n+  int64_t out_length = sizeof(float) * 1 * 1;\n+\n   // Preparing memory for thunk arguments.\n   // lhs = [1.0, 2.0, 3.0, 4.0,\n   //        5.0, 6.0, 7.0, 8.0]\n@@ -1727,13 +1961,13 @@ TEST_F(DynamicSliceThunkTest,\n       /*collective_params=*/nullptr, /*collective_cliques=*/nullptr);\n \n   Thunk::ExecutableSource source = {/*text=*/\"\", /*binary=*/{}};\n-  TF_ASSERT_OK(thunk.Initialize(\n+  TF_ASSERT_OK(thunk->Initialize(\n       {executor, source, &allocations, stream.get(), stream.get()}));\n \n   // Executing address computation thunk.\n   ResourceRequests resource_requests;\n-  TF_ASSERT_OK(thunk.Prepare(prepare_params, resource_requests));\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+  TF_ASSERT_OK(thunk->Prepare(prepare_params, resource_requests));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n   TF_ASSERT_OK(stream->BlockHostUntilDone());\n \n   // Copying `out` data back to host for verification.\n@@ -1743,7 +1977,7 @@ TEST_F(DynamicSliceThunkTest,\n \n   ASSERT_EQ(dst, std::vector<float>({1 * 4 + 2 * 3 + 3 * 2 + 4 * 1}));\n \n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n   TF_ASSERT_OK(stream->BlockHostUntilDone());\n \n   // Copying `out` data back to host for verification.\n@@ -1753,5 +1987,123 @@ TEST_F(DynamicSliceThunkTest,\n   EXPECT_EQ(dst, std::vector<float>({5 * 4 + 6 * 3 + 7 * 2 + 8 * 1}));\n }\n \n+TEST_F(DynamicSliceThunkTest,\n+       SerializeAndDeserializeOptionalOffsetsWithNullopt) {\n+  std::optional<std::vector<DynamicSliceThunk::Offset>> offsets_item =\n+      std::nullopt;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto proto,\n+      SerializeOptionalDynamicSliceOffsetsToProto(offsets_item, std::nullopt));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto deserialized_offsets,\n+      DeserializeOptionalDynamicSliceOffsetsFromProto(proto, {}, std::nullopt));\n+  EXPECT_FALSE(deserialized_offsets.has_value());\n+}\n+\n+TEST_F(DynamicSliceThunkTest,\n+       SerializeAndDeserializeOptionalOffsetsWithConstOffset) {\n+  std::optional<std::vector<DynamicSliceThunk::Offset>> offsets_item =\n+      std::vector<DynamicSliceThunk::Offset>{123l};\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto proto,\n+      SerializeOptionalDynamicSliceOffsetsToProto(offsets_item, std::nullopt));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto deserialized_offsets,\n+      DeserializeOptionalDynamicSliceOffsetsFromProto(proto, {}, std::nullopt));\n+  ASSERT_TRUE(deserialized_offsets.has_value());\n+  ASSERT_EQ(deserialized_offsets->size(), 1);\n+  EXPECT_EQ(std::get<int64_t>((*deserialized_offsets)[0]), 123l);\n+}\n+\n+TEST_F(DynamicSliceThunkTest,\n+       SerializeAndDeserializeOptionalOffsetsWithSliceOffset) {\n+  std::vector<BufferAllocation> allocations;\n+  allocations.emplace_back(0, 1024, 0);\n+  BufferAllocation::Slice slice(&allocations.back(), 128, 256);\n+  std::optional<std::vector<DynamicSliceThunk::Offset>> offsets_item =\n+      std::vector<DynamicSliceThunk::Offset>{slice};\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto proto,\n+      SerializeOptionalDynamicSliceOffsetsToProto(offsets_item, std::nullopt));\n+  TF_ASSERT_OK_AND_ASSIGN(auto deserialized_offsets,\n+                          DeserializeOptionalDynamicSliceOffsetsFromProto(\n+                              proto, allocations, std::nullopt));\n+  ASSERT_TRUE(deserialized_offsets.has_value());\n+  ASSERT_EQ(deserialized_offsets->size(), 1);\n+  auto deserialized_slice =\n+      std::get<BufferAllocation::Slice>((*deserialized_offsets)[0]);\n+  EXPECT_EQ(deserialized_slice.allocation(), &allocations.back());\n+  EXPECT_EQ(deserialized_slice.offset(), 128);\n+  EXPECT_EQ(deserialized_slice.size(), 256);\n+}\n+\n+TEST_F(DynamicSliceThunkTest,\n+       SerializeAndDeserializeOptionalOffsetsWithHloModuleOffset) {\n+  const char* hlo_text = R\"(\n+      HloModule test_module\n+      ENTRY main {\n+        ROOT c = f32[] constant(0.0)\n+      }\n+    )\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto hlo_module,\n+                          ParseAndReturnUnverifiedModule(hlo_text));\n+  HloModule* hlo_module_ptr = hlo_module.get();\n+\n+  std::vector<std::unique_ptr<HloModule>> modules;\n+  modules.push_back(std::move(hlo_module));\n+\n+  const char* indvar_init_hlo = R\"(\n+      HloModule indvar_init\n+      ENTRY main {\n+        ROOT c0 = s32[] constant(0)\n+      }\n+    )\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto indvar_init_module,\n+                          ParseAndReturnUnverifiedModule(indvar_init_hlo));\n+\n+  const char* indvar_update_hlo = R\"(\n+      HloModule indvar_update\n+      ENTRY main {\n+        p0 = s32[] parameter(0)\n+        c1 = s32[] constant(1)\n+        ROOT add = s32[] add(p0, c1)\n+      }\n+    )\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto indvar_update_module,\n+                          ParseAndReturnUnverifiedModule(indvar_update_hlo));\n+\n+  DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata metadata(\n+      std::move(indvar_init_module), std::move(indvar_update_module),\n+      std::move(modules));\n+\n+  std::optional<std::vector<DynamicSliceThunk::Offset>> offsets_item =\n+      std::vector<DynamicSliceThunk::Offset>{hlo_module_ptr};\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto proto,\n+                          SerializeOptionalDynamicSliceOffsetsToProto(\n+                              offsets_item, std::move(metadata)));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto hlo_module2,\n+                          ParseAndReturnUnverifiedModule(hlo_text));\n+  std::vector<std::unique_ptr<HloModule>> modules2;\n+  modules2.push_back(std::move(hlo_module2));\n+  TF_ASSERT_OK_AND_ASSIGN(auto indvar_init_module2,\n+                          ParseAndReturnUnverifiedModule(indvar_init_hlo));\n+  TF_ASSERT_OK_AND_ASSIGN(auto indvar_update_module2,\n+                          ParseAndReturnUnverifiedModule(indvar_update_hlo));\n+  DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata metadata2(\n+      std::move(indvar_init_module2), std::move(indvar_update_module2),\n+      std::move(modules2));\n+  TF_ASSERT_OK_AND_ASSIGN(auto deserialized_offsets,\n+                          DeserializeOptionalDynamicSliceOffsetsFromProto(\n+                              proto, {}, std::move(metadata2)));\n+  ASSERT_TRUE(deserialized_offsets.has_value());\n+  ASSERT_EQ(deserialized_offsets->size(), 1);\n+  EXPECT_TRUE(std::holds_alternative<HloModule*>((*deserialized_offsets)[0]));\n+  EXPECT_NE(std::get<HloModule*>((*deserialized_offsets)[0]), nullptr);\n+  EXPECT_EQ(proto.offsets().offsets(0).hlo_module_offset_idx(), 0);\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        }
    ],
    "stats": {
        "total": 1415,
        "additions": 1053,
        "deletions": 362
    }
}