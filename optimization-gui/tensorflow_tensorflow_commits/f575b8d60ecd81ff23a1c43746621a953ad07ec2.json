{
    "author": "akuegel",
    "message": "[XLA:GPU] Register BF16 kernels for Cub sort and Cub prefix sum\n\nThis was probably an oversight. Our tests did not detect this, as SortRewriter\nwill not rewrite if there is no kernel registered for the data type.\nAdjust the SortSupportsType test so that it would catch this issue.\n\nPiperOrigin-RevId: 833305248",
    "sha": "f575b8d60ecd81ff23a1c43746621a953ad07ec2",
    "files": [
        {
            "sha": "086142041b3088b130749726093c61c7cad4d3eb",
            "filename": "third_party/xla/xla/service/gpu/build_defs.bzl",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbuild_defs.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbuild_defs.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbuild_defs.bzl?ref=f575b8d60ecd81ff23a1c43746621a953ad07ec2",
            "patch": "@@ -11,6 +11,7 @@ def get_cub_sort_kernel_types(name = \"\"):\n     \"\"\" List of supported types for CUB sort kernels.\n     \"\"\"\n     return [\n+        \"bf16\",\n         \"f16\",\n         \"f32\",\n         \"f64\","
        },
        {
            "sha": "2050c766e39fd17d47f6ef011322585844164ed6",
            "filename": "third_party/xla/xla/service/gpu/tests/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD?ref=f575b8d60ecd81ff23a1c43746621a953ad07ec2",
            "patch": "@@ -600,6 +600,7 @@ xla_test(\n     local_defines = if_cuda_is_configured([\"GOOGLE_CUDA=1\"]) + if_rocm_is_configured([\n         \"TENSORFLOW_USE_ROCM=1\",\n     ]),\n+    shard_count = 15,\n     deps = [\n         \":gpu_codegen_test\",\n         \"//xla:error_spec\","
        },
        {
            "sha": "cf4762121764c9904dae08847583c0bf7703f31e",
            "filename": "third_party/xla/xla/service/gpu/tests/sorting_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsorting_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsorting_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsorting_test.cc?ref=f575b8d60ecd81ff23a1c43746621a953ad07ec2",
            "patch": "@@ -59,12 +59,17 @@ ROOT lt = pred[] compare(p.0.lhs, p.0.rhs), direction=LT\n }\n \n ENTRY test {\n-p0 = $0[32]{0} parameter(0)\n-ROOT sort = $0[32]{0} sort(p0), dimensions={0}, is_stable=true,\n+p0 = $0[132000]{0} parameter(0)\n+ROOT sort = $0[132000]{0} sort(p0), dimensions={0}, is_stable=false,\n to_apply=compare\n })\";\n   std::string hlo = absl::Substitute(\n       kHloTemplate, primitive_util::LowercasePrimitiveTypeName(GetParam()));\n+  // We expect that all types except PRED and F8 types are rewritten to a custom\n+  // call.\n+  if (GetParam() != PRED && !primitive_util::IsF8Type(GetParam())) {\n+    MatchOptimizedHlo(hlo, \"CHECK: custom-call\");\n+  }\n   EXPECT_TRUE(RunAndCompare(hlo, ErrorSpec{0, 0}));\n }\n "
        },
        {
            "sha": "b2b709f9865419a828dc35cde5277e70db68d772",
            "filename": "third_party/xla/xla/stream_executor/cuda/cub_prefix_sum_kernel_cuda.cu.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcub_prefix_sum_kernel_cuda.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcub_prefix_sum_kernel_cuda.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcub_prefix_sum_kernel_cuda.cu.cc?ref=f575b8d60ecd81ff23a1c43746621a953ad07ec2",
            "patch": "@@ -121,6 +121,9 @@ __global__ void PrefixSum(const void* data_in, void* data_out,\n   }\n \n // Floating point types.\n+#ifdef CUB_TYPE_BF16\n+XLA_CUB_PREFIX_SUM_KERNEL_SPEC(BF16, __nv_bfloat16)\n+#endif\n #ifdef CUB_TYPE_F16\n XLA_CUB_PREFIX_SUM_KERNEL_SPEC(F16, __half)\n #endif\n@@ -167,6 +170,9 @@ XLA_CUB_PREFIX_SUM_KERNEL_SPEC(U64, uint64_t)\n       se::gpu::PrefixSum##primitive_type##Kernel, kCudaPlatformId, \\\n       GetPrefixSum##primitive_type##KernelSpec)\n \n+#ifdef CUB_TYPE_BF16\n+REGISTER_PREFIX_SUM_KERNEL(BF16)\n+#endif\n #ifdef CUB_TYPE_F16\n REGISTER_PREFIX_SUM_KERNEL(F16)\n #endif"
        },
        {
            "sha": "2a18b7ad29b31b562b678aba9381e25485fe596e",
            "filename": "third_party/xla/xla/stream_executor/cuda/cub_prefix_sum_kernel_cuda_test.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 5,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcub_prefix_sum_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcub_prefix_sum_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcub_prefix_sum_kernel_cuda_test.cc?ref=f575b8d60ecd81ff23a1c43746621a953ad07ec2",
            "patch": "@@ -132,7 +132,7 @@ class CubPrefixSumKernelCudaTest\n       for (int j = 0; j < num_items; ++j) {\n         // We use only small values, otherwise we will get precision problems\n         // with small data types.\n-        input[i * num_items + j] = static_cast<T>((i + j) % 8);\n+        input[i * num_items + j] = static_cast<T>((i + j) % 5);\n         expected.push_back(input[i * num_items + j]);\n         if (j > 0) {\n           expected.back() += expected[expected.size() - 2];\n@@ -155,6 +155,14 @@ TEST_P(CubPrefixSumKernelCudaTest, TestPrefixSum) {\n   absl::Status status;\n   const auto& [primitive_type, num_rows, num_items, in_place] = GetParam();\n   switch (primitive_type) {\n+    case xla::BF16:\n+      if (num_items > 128) {\n+        GTEST_SKIP() << \"Rounding errors\";\n+      }\n+      status = CheckComputePrefixSumOnDevice<gpu::PrefixSumBF16Kernel,\n+                                             xla::bfloat16>(num_rows, num_items,\n+                                                            in_place);\n+      break;\n     case xla::F16:\n       status =\n           CheckComputePrefixSumOnDevice<gpu::PrefixSumF16Kernel, xla::half>(\n@@ -218,10 +226,10 @@ std::string ParametersToString(\n \n INSTANTIATE_TEST_SUITE_P(\n     CubPrefixSumKernelCudaTestInstance, CubPrefixSumKernelCudaTest,\n-    ::testing::Combine(::testing::ValuesIn({xla::F16, xla::F32, xla::F64,\n-                                            xla::S8, xla::S16, xla::S32,\n-                                            xla::S64, xla::U8, xla::U16,\n-                                            xla::U32, xla::U64}),\n+    ::testing::Combine(::testing::ValuesIn({xla::BF16, xla::F16, xla::F32,\n+                                            xla::F64, xla::S8, xla::S16,\n+                                            xla::S32, xla::S64, xla::U8,\n+                                            xla::U16, xla::U32, xla::U64}),\n                        ::testing::ValuesIn({1, 2, 3, 128, 511, 512}),\n                        ::testing::ValuesIn({1, 2, 3, 128, 511, 513}),\n                        ::testing::ValuesIn({false, true})),"
        },
        {
            "sha": "c669f6b3927bad6ae0779f4fd698f5441e607a2b",
            "filename": "third_party/xla/xla/stream_executor/gpu/prefix_sum_kernel.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fprefix_sum_kernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fprefix_sum_kernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fprefix_sum_kernel.h?ref=f575b8d60ecd81ff23a1c43746621a953ad07ec2",
            "patch": "@@ -24,6 +24,10 @@ limitations under the License.\n #include \"xla/types.h\"\n \n namespace stream_executor::gpu {\n+struct PrefixSumBF16Kernel {\n+  using KernelType = TypedKernel<const DeviceMemory<xla::bfloat16>,\n+                                 DeviceMemory<xla::bfloat16>, size_t>;\n+};\n struct PrefixSumF16Kernel {\n   using KernelType = TypedKernel<const DeviceMemory<xla::half>,\n                                  DeviceMemory<xla::half>, size_t>;"
        },
        {
            "sha": "0784512c2ba7add6d7e98cb89f00eb7b4294e109",
            "filename": "third_party/xla/xla/stream_executor/rocm/cub_sort_kernel_rocm.cu.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fcub_sort_kernel_rocm.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f575b8d60ecd81ff23a1c43746621a953ad07ec2/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fcub_sort_kernel_rocm.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fcub_sort_kernel_rocm.cu.cc?ref=f575b8d60ecd81ff23a1c43746621a953ad07ec2",
            "patch": "@@ -284,7 +284,7 @@ static absl::Status CubSortPairsGetScratchSize(size_t* temp_bytes,\n \n // Floating point types.\n #ifdef CUB_TYPE_BF16\n-XLA_CUB_DEFINE_SORT_KEYS(bf16, __nv_bfloat16)\n+XLA_CUB_DEFINE_SORT_KEYS(bf16, hip_bfloat16)\n #endif\n #ifdef CUB_TYPE_F16\n XLA_CUB_DEFINE_SORT_KEYS(f16, __half)"
        }
    ],
    "stats": {
        "total": 41,
        "additions": 33,
        "deletions": 8
    }
}