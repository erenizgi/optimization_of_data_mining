{
    "author": "ezhulenev",
    "message": "[xla:gpu] Remove redundant operand_count from CollectiveConfig\n\n- also update outdated documentation and cleanup unused variables\n\nPiperOrigin-RevId: 836553618",
    "sha": "6d07098dfc6d680f6c0f78b81e2238011708c4a1",
    "files": [
        {
            "sha": "672772eccd1c8286c28bdd498e413d9a76bcc05e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_gather_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -76,7 +76,7 @@ AllGatherStartThunk::AllGatherStartThunk(ThunkInfo thunk_info,\n                       AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n       config_(impl::GetAllGatherConfig(inst)),\n       buffers_(std::move(buffers)) {\n-  CHECK_EQ(config_.config.operand_count, buffers_.size());\n+  CHECK_EQ(config_.config.operand_element_type.size(), buffers_.size());\n }\n \n /*static*/ absl::Status AllGatherStartThunk::CheckImplementable("
        },
        {
            "sha": "e5ee61a451456c3772ccc0f94bc69c9bd92b2f9a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_reduce_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -116,7 +116,7 @@ AllReduceReduceScatterThunkBase::AllReduceReduceScatterThunkBase(\n                       AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n       config_(std::move(config)),\n       buffers_(std::move(buffers)) {\n-  CHECK_EQ(config_.config.operand_count, buffers_.size());\n+  CHECK_EQ(config_.config.operand_element_type.size(), buffers_.size());\n }\n \n AllReduceStartThunk::AllReduceStartThunk("
        },
        {
            "sha": "9c187408622be12918c904f13d9ce3ea892bfbc6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_to_all_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -84,7 +84,7 @@ AllToAllStartThunk::AllToAllStartThunk(\n       config_(GetAllToAllConfig(instr)),\n       buffers_(std::move(buffers)),\n       p2p_memcpy_enabled_(p2p_memcpy_enabled) {\n-  CHECK_EQ(config_.config.operand_count, buffers_.size());\n+  CHECK_EQ(config_.config.operand_element_type.size(), buffers_.size());\n }\n \n /*static*/ absl::Status AllToAllStartThunk::CheckImplementable("
        },
        {
            "sha": "83f98a4dc6de2023c639b980069f8bbbec9c2fa0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -160,7 +160,6 @@ CollectiveKernelThunkMetadata CreateCollectiveKernelThunk(\n   }\n \n   CollectiveConfig collective_config{\n-      /*operand_count=*/1,\n       /*operand_element_type=*/{PrimitiveType::F32},\n       /*replica_groups=*/{replica_group},\n       /*group_mode=*/"
        },
        {
            "sha": "79948fe7e2800b1d25a5657c02d14b68dde3de68",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_metadata_thunk.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -52,11 +52,9 @@ namespace gpu {\n CollectiveConfig CollectiveMetadataThunk::GetCollectiveConfig(\n     const HloInstruction& hlo) {\n   CollectiveConfig config;\n-  config.operand_count = hlo.operands().size();\n-  config.operand_element_type.reserve(config.operand_count);\n-  for (int i = 0; i < config.operand_count; i++) {\n-    config.operand_element_type.push_back(\n-        hlo.operand(i)->shape().element_type());\n+  config.operand_element_type.reserve(hlo.operands().size());\n+  for (const HloInstruction* operand : hlo.operands()) {\n+    config.operand_element_type.push_back(operand->shape().element_type());\n   }\n \n   if (hlo.has_backend_config()) {"
        },
        {
            "sha": "efe521872692c2238e3c1dd127ddcc5e9a5e040d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -100,10 +100,8 @@ CollectivePermuteStartThunk::CollectivePermuteStartThunk(\n           ->config()\n           .debug_options()\n           .xla_gpu_experimental_enable_nccl_symmetric_buffers();\n-  config.operand_count = instr->operand_count();\n-  for (int i = 0; i < config.operand_count; ++i) {\n-    config.operand_element_type.push_back(\n-        instr->operand(i)->shape().element_type());\n+  for (const HloInstruction* operand : instr->operands()) {\n+    config.operand_element_type.push_back(operand->shape().element_type());\n   }\n   config.group_mode = GetGroupMode(instr);\n "
        },
        {
            "sha": "a2d8713277e8d1b5fcb0f5248defbe94f83ea12e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 24,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -37,13 +37,13 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n+#include \"xla/backends/gpu/runtime/collective_cliques.h\"\n #include \"xla/backends/gpu/runtime/collective_params.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/core/collectives/communicator.h\"\n #include \"xla/core/collectives/rank_id.h\"\n #include \"xla/debug_options_flags.h\"\n #include \"xla/hlo/ir/collective_op_group_mode.h\"\n-#include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/primitive_util.h\"\n #include \"xla/service/collective_ops_utils.h\"\n #include \"xla/service/computation_placer.h\"\n@@ -66,7 +66,6 @@ namespace xla::gpu {\n namespace {\n \n static constexpr int64_t kCollectiveMemorySpaceColor = 1;\n-static constexpr CollectiveStreamId kNoStreamId = CollectiveStreamId(0);\n \n bool IsTypeSupportedBy(PrimitiveType element_type, Thunk::Kind reduction_op) {\n   switch (element_type) {\n@@ -120,19 +119,6 @@ int64_t GetNumLocalParticipants(\n \n }  // namespace\n \n-// This file runs collective ops (i.e. ops that communicate between multiple\n-// GPUs) using NCCL.\n-//\n-// Here's a high-level overview of how running an op works.\n-//\n-//  - Multiple threads call ExecuteOnStream.\n-//  - All threads that \"go together\" (i.e. are participating in the \"same\"\n-//    collective op) choose the same Rendezvous object from a global map.\n-//  - Once all threads have arrived at the Rendezvous, we know exactly which\n-//    GPUs are participating in the op, so we get or create a NcclClique\n-//    containing those GPUs.\n-//  - We perform the NCCL operation using the clique.\n-\n // Returns if the collective communication operation is degenerate because all\n // the groups formed by the operation are singleton. A given op can be\n // degenerate under several conditions, corresponding to the modes supported\n@@ -185,11 +171,9 @@ bool CollectiveConfig::IsDegenerate(int64_t replica_count,\n CollectiveConfig GetCollectiveConfig(\n     const HloInstruction* hlo, std::optional<bool> use_global_device_ids) {\n   CollectiveConfig config;\n-  config.operand_count = hlo->operands().size();\n-  config.operand_element_type.reserve(config.operand_count);\n-  for (int i = 0; i < config.operand_count; i++) {\n-    config.operand_element_type.push_back(\n-        hlo->operand(i)->shape().element_type());\n+  config.operand_element_type.reserve(hlo->operands().size());\n+  for (const HloInstruction* operand : hlo->operands()) {\n+    config.operand_element_type.push_back(operand->shape().element_type());\n   }\n   config.replica_groups = hlo->replica_groups();\n \n@@ -324,8 +308,9 @@ absl::StatusOr<std::vector<DeviceBufferPair>> ConvertToDeviceBuffers(\n     const BufferAllocations* buffer_allocations,\n     const std::vector<CollectiveThunk::Buffer>& buffers,\n     const std::vector<PrimitiveType>& element_types) {\n-  if (buffers.size() != element_types.size())\n+  if (buffers.size() != element_types.size()) {\n     return FailedPrecondition(\"Mismatch in operand buffer counts.\");\n+  }\n \n   std::vector<DeviceBufferPair> device_buffers;\n   device_buffers.reserve(buffers.size());\n@@ -344,8 +329,8 @@ absl::Status MaybeRegisterBuffer(se::StreamExecutor* executor,\n                                  Communicator* comm,\n                                  bool use_symmetric_buffer) {\n   TF_ASSIGN_OR_RETURN(auto range, executor->GetMemoryRange(buffer));\n-  VLOG(1) << \"[\" << executor->device_ordinal()\n-          << \"] Registering range: \" << range.opaque()\n+  VLOG(1) << \"[\" << executor->device_ordinal() << \"] \"\n+          << \"Registering range: \" << range.opaque()\n           << \" with size: \" << range.size()\n           << \" for buffer: \" << buffer.opaque()\n           << \" with size: \" << buffer.size()\n@@ -376,7 +361,9 @@ absl::Status MaybeRegisterBuffers(se::StreamExecutor* executor,\n absl::Status CollectiveThunk::AsyncEvents::Initialize(\n     se::StreamExecutor* executor) {\n   absl::MutexLock lock(mu_);\n-  if (events_.contains(executor)) return absl::OkStatus();\n+  if (events_.contains(executor)) {\n+    return absl::OkStatus();\n+  }\n \n   TF_ASSIGN_OR_RETURN(auto event, executor->CreateEvent());\n "
        },
        {
            "sha": "b185047c65fb95c5f8dad6294585184dcb033990",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -1,3 +1,5 @@\n+#include <cstddef>\n+\n #include \"xla/backends/gpu/runtime/collective_cliques.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n /* Copyright 2019 The OpenXLA Authors.\n@@ -55,7 +57,6 @@ struct CollectiveConfig {\n   // the groups formed by the operation are singleton.\n   bool IsDegenerate(int64_t replica_count, int64_t partition_count) const;\n \n-  int64_t operand_count;\n   std::vector<PrimitiveType> operand_element_type;\n   std::vector<ReplicaGroup> replica_groups;\n   CollectiveOpGroupMode group_mode;"
        },
        {
            "sha": "c7ea3d6a9efd1dc778f988a40f480edda2d0ddb9",
            "filename": "third_party/xla/xla/backends/gpu/runtime/nvshmem_all_reduce_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_all_reduce_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_all_reduce_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_all_reduce_thunk.cc?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -91,7 +91,7 @@ NvshmemAllReduceReduceScatterThunkBase::NvshmemAllReduceReduceScatterThunkBase(\n     : NvshmemCollectiveThunk(kind, thunk_info, is_sync),\n       config_(std::move(config)),\n       buffers_(std::move(buffers)) {\n-  CHECK_EQ(config_.config.operand_count, buffers_.size());\n+  CHECK_EQ(config_.config.operand_element_type.size(), buffers_.size());\n }\n \n NvshmemAllReduceStartThunk::NvshmemAllReduceStartThunk("
        },
        {
            "sha": "2f03bec297a318c0bd6daaf3f30b12b4b2d260fe",
            "filename": "third_party/xla/xla/backends/gpu/runtime/nvshmem_collective_permute_thunk.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_permute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_permute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_permute_thunk.cc?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -71,7 +71,6 @@ NvshmemCollectivePermuteStartThunk::NvshmemCollectivePermuteStartThunk(\n   P2PConfig collective_permute_config;\n   auto& config = collective_permute_config.config;\n \n-  config.operand_count = instr->operand_count();\n   for (const HloInstruction* operand : instr->operands()) {\n     config.operand_element_type.push_back(operand->shape().element_type());\n   }"
        },
        {
            "sha": "a4ea9df511a28474273efe37335d48c0e1605655",
            "filename": "third_party/xla/xla/backends/gpu/runtime/p2p_thunk_common.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fp2p_thunk_common.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fp2p_thunk_common.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fp2p_thunk_common.cc?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -93,7 +93,6 @@ P2PConfig GetP2PConfigForSendRecv(const HloSendRecvInstruction* instr,\n   P2PConfig p2p_config;\n   auto& config = p2p_config.config;\n \n-  config.operand_count = 1;\n   config.operand_element_type.push_back(shape.element_type());\n   config.group_mode = GetCollectiveOpGroupMode(\n                           instr->channel_id().value_or(0) > 0, std::nullopt)"
        },
        {
            "sha": "0cc5e7dc6fda60ac25ba82affac2984bfedf4cfa",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d07098dfc6d680f6c0f78b81e2238011708c4a1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc?ref=6d07098dfc6d680f6c0f78b81e2238011708c4a1",
            "patch": "@@ -416,7 +416,7 @@ RaggedAllToAllStartThunk::RaggedAllToAllStartThunk(\n               ->config()\n               .debug_options()\n               .xla_gpu_unsupported_use_ragged_all_to_all_one_shot_kernel()) {\n-  CHECK_EQ(config_.config.operand_count, buffers_.size());\n+  CHECK_EQ(config_.config.operand_element_type.size(), buffers_.size());\n }\n \n /*static*/ absl::Status RaggedAllToAllStartThunk::CheckImplementable("
        }
    ],
    "stats": {
        "total": 65,
        "additions": 23,
        "deletions": 42
    }
}