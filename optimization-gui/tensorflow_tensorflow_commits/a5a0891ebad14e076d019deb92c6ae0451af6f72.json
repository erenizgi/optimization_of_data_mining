{
    "author": "ezhulenev",
    "message": "[xla:gpu] Add command buffer + profiling TraceMe warning\n\nPiperOrigin-RevId: 829094009",
    "sha": "a5a0891ebad14e076d019deb92c6ae0451af6f72",
    "files": [
        {
            "sha": "98ef994a72f44a6c453195d8e2be05873eaec254",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a5a0891ebad14e076d019deb92c6ae0451af6f72/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a5a0891ebad14e076d019deb92c6ae0451af6f72/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk.cc?ref=a5a0891ebad14e076d019deb92c6ae0451af6f72",
            "patch": "@@ -236,6 +236,7 @@ absl::Status CommandBufferThunk::ExecuteOnStream(const ExecuteParams& params) {\n       !enable_command_buffers_during_profiling_) {\n     VLOG(1) << \"Execute command buffer thunk as a regular thunk sequence \"\n                \"because we detected active profiling session\";\n+    TraceMe trace(\"WARNING: CommandBuffer disabled when profiling\");\n     return thunks_->ExecuteOnStream(params);\n   }\n \n@@ -346,7 +347,7 @@ void CommandBufferThunk::TrackCommandBuffers(\n }\n \n void CommandBufferThunk::EvictCommandBuffers() {\n-  TraceMe trace([&] { return \"EvictCommandBuffers\"; });\n+  TraceMe trace(\"EvictCommandBuffers\");\n \n   auto* global_state = GetGlobalState();\n   absl::MutexLock global_state_lock(global_state->mutex);"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}