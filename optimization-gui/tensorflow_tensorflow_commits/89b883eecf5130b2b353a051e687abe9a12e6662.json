{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 845638609",
    "sha": "89b883eecf5130b2b353a051e687abe9a12e6662",
    "files": [
        {
            "sha": "3919cb763171c712b2bc7ff7f0d22d0ee38ccf4d",
            "filename": "tensorflow/core/kernels/list_kernels.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flist_kernels.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flist_kernels.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flist_kernels.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -48,7 +48,7 @@ typedef Eigen::ThreadPoolDevice CPUDevice;\n \n absl::Status TensorShapeFromTensor(const Tensor& t, PartialTensorShape* out) {\n   if (t.shape() == TensorShape({})) {\n-    if ((t.dtype() == DT_INT32 && t.scalar<int32>()() == -1) ||\n+    if ((t.dtype() == DT_INT32 && t.scalar<int32_t>()() == -1) ||\n         (t.dtype() == DT_INT64 && t.scalar<int64_t>()() == -1)) {\n       *out = PartialTensorShape();\n       return absl::OkStatus();\n@@ -61,7 +61,7 @@ absl::Status TensorShapeFromTensor(const Tensor& t, PartialTensorShape* out) {\n                                    t.shape().dims());\n   }\n   if (t.dtype() == DT_INT32) {\n-    return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),\n+    return PartialTensorShape::MakePartialShape(t.vec<int32_t>().data(),\n                                                 t.NumElements(), out);\n   } else if (t.dtype() == DT_INT64) {\n     return PartialTensorShape::MakePartialShape(t.vec<int64_t>().data(),\n@@ -157,7 +157,7 @@ class EmptyTensorList : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape{}, &result, attr));\n     TensorList empty;\n     empty.element_dtype = element_dtype_;\n-    empty.max_num_elements = max_num_elements_t.scalar<int32>()();\n+    empty.max_num_elements = max_num_elements_t.scalar<int32_t>()();\n     PartialTensorShape element_shape;\n     OP_REQUIRES_OK(ctx, TensorShapeFromTensor(ctx->input(0), &element_shape));\n     empty.element_shape = element_shape;\n@@ -257,7 +257,7 @@ class TensorListLength : public OpKernel {\n     OP_REQUIRES_OK(c, GetInputList(c, 0, &l));\n     Tensor* result;\n     OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape{}, &result));\n-    result->scalar<int32>()() = l->tensors().size();\n+    result->scalar<int32_t>()() = l->tensors().size();\n   }\n };\n \n@@ -287,7 +287,7 @@ class TensorListElementShape : public OpKernel {\n     if (l->element_shape.unknown_rank()) {\n       OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape({}), &result));\n       if (result->dtype() == DT_INT32) {\n-        result->scalar<int32>()() = -1;\n+        result->scalar<int32_t>()() = -1;\n       } else {\n         result->scalar<int64_t>()() = -1;\n       }\n@@ -296,7 +296,7 @@ class TensorListElementShape : public OpKernel {\n                             0, TensorShape{l->element_shape.dims()}, &result));\n       for (int i = 0; i < l->element_shape.dims(); ++i) {\n         if (result->dtype() == DT_INT32) {\n-          result->flat<int32>()(i) = l->element_shape.dim_size(i);\n+          result->flat<int32_t>()(i) = l->element_shape.dim_size(i);\n         } else {\n           result->flat<int64_t>()(i) = l->element_shape.dim_size(i);\n         }\n@@ -336,7 +336,7 @@ class TensorListReserve : public OpKernel {\n         errors::InvalidArgument(\n             \"The num_elements to reserve must be a tensor size 1, but got \",\n             c->input(1).shape()));\n-    int32_t num_elements = c->input(1).scalar<int32>()();\n+    int32_t num_elements = c->input(1).scalar<int32_t>()();\n     OP_REQUIRES(c, num_elements >= 0,\n                 errors::InvalidArgument(\"The num_elements to reserve must be a \"\n                                         \"non negative number, but got \",\n@@ -384,7 +384,7 @@ class TensorListResize : public OpKernel {\n     OP_REQUIRES_OK(c, GetInputList(c, 0, &input_list));\n     OP_REQUIRES(c, TensorShapeUtils::IsScalar(c->input(1).shape()),\n                 errors::InvalidArgument(\"size must be a scalar\"));\n-    int32_t size = c->input(1).scalar<int32>()();\n+    int32_t size = c->input(1).scalar<int32_t>()();\n     OP_REQUIRES(\n         c, size >= 0,\n         errors::InvalidArgument(\n@@ -473,7 +473,7 @@ class TensorListSetItem : public OpKernel {\n                     \" list shape: \", l->element_shape.DebugString()));\n     TensorList* output_list = nullptr;\n     OP_REQUIRES_OK(c, ForwardInputOrCreateNewList(c, 0, 0, *l, &output_list));\n-    int32_t index = c->input(1).scalar<int32>()();\n+    int32_t index = c->input(1).scalar<int32_t>()();\n     if (!resize_if_index_out_of_bounds_) {\n       OP_REQUIRES(c, index < l->tensors().size(),\n                   errors::InvalidArgument(\"Trying to modify element \", index,"
        },
        {
            "sha": "5af26a518f0b18fb5433ab21a38463dc4a3bd847",
            "filename": "tensorflow/core/kernels/list_kernels.h",
            "status": "modified",
            "additions": 19,
            "deletions": 16,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flist_kernels.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flist_kernels.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flist_kernels.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -80,8 +80,8 @@ template <typename Device, typename T>\n inline void SetZero(OpKernelContext* ctx, Tensor& tensor) {\n #ifdef PLUGGABLE_DEVICE_SUPPORTED\n   if (IsPluggableDevice(ctx)) {\n-    auto ptr =\n-        se::DeviceMemoryBase(tensor.flat<T>().data(), tensor.TotalBytes());\n+    auto ptr = stream_executor::DeviceAddressBase(tensor.flat<T>().data(),\n+                                                  tensor.TotalBytes());\n     auto stream = ctx->op_device_context()->stream();\n     auto result = stream->MemZero(&ptr, tensor.TotalBytes()).ok();\n     DCHECK_EQ(true, result);\n@@ -101,8 +101,10 @@ inline void CopyTensorPluggableDevice(OpKernelContext* ctx, Tensor& src,\n   auto src_t = src.unaligned_flat<T>();\n   auto dst_t = dst.flat<T>();\n   DCHECK(DataTypeCanUseMemcpy(DataTypeToEnum<T>::v()));\n-  auto src_ptr = se::DeviceMemoryBase(src_t.data(), src.TotalBytes());\n-  auto dst_ptr = se::DeviceMemoryBase(dst_t.data(), dst.TotalBytes());\n+  auto src_ptr =\n+      stream_executor::DeviceAddressBase(src_t.data(), src.TotalBytes());\n+  auto dst_ptr =\n+      stream_executor::DeviceAddressBase(dst_t.data(), dst.TotalBytes());\n   auto stream = ctx->op_device_context()->stream();\n   auto result = stream->Memcpy(&dst_ptr, src_ptr, src.TotalBytes()).ok();\n   DCHECK_EQ(true, result);\n@@ -133,7 +135,7 @@ void ConcatPluggableDevice(\n   size_t num_inputs = inputs.size();\n   std::vector<ptrdiff_t> sizes;\n   sizes.reserve(num_inputs);\n-  int64 row_size = 0;\n+  int64_t row_size = 0;\n   for (const auto& input : inputs) {\n     sizes.push_back(input->dimension(1));\n     row_size += sizes.back();\n@@ -145,12 +147,13 @@ void ConcatPluggableDevice(\n   for (const auto& input : inputs) {\n     inp.push_back(&(*input)(0, 0));\n   }\n-  const int64 dim0 = output->dimension(0);\n-  for (int64 i = 0; i < dim0; ++i) {\n-    for (int64 j = 0; j < num_inputs; ++j) {\n+  const int64_t dim0 = output->dimension(0);\n+  for (int64_t i = 0; i < dim0; ++i) {\n+    for (int64_t j = 0; j < num_inputs; ++j) {\n       auto size = sizes[j];\n-      se::DeviceMemoryBase out_base{out, size * sizeof(T)};\n-      se::DeviceMemoryBase inp_base{const_cast<T*>(inp[j]), size * sizeof(T)};\n+      stream_executor::DeviceAddressBase out_base{out, size * sizeof(T)};\n+      stream_executor::DeviceAddressBase inp_base{const_cast<T*>(inp[j]),\n+                                                  size * sizeof(T)};\n       OP_REQUIRES_OK(context,\n                      stream->Memcpy(&out_base, inp_base, size * sizeof(T)));\n       out += size;\n@@ -284,7 +287,7 @@ class TensorListGetItem : public OpKernel {\n                                         DataTypeString(element_dtype_),\n                                         \" but list elements \",\n                                         DataTypeString(l->element_dtype)));\n-    int32_t index = c->input(1).scalar<int32>()();\n+    int32_t index = c->input(1).scalar<int32_t>()();\n     OP_REQUIRES(c, index < l->tensors().size(),\n                 errors::InvalidArgument(\"Trying to access element \", index,\n                                         \" in a list with \", l->tensors().size(),\n@@ -693,7 +696,7 @@ class TensorListGather : public OpKernel {\n     // element tensors.\n     if (!tensor_list->element_shape.IsFullyDefined()) {\n       for (int index = 0; index < indices.NumElements(); ++index) {\n-        const int i = indices.flat<int32>()(index);\n+        const int i = indices.flat<int32_t>()(index);\n \n         OP_REQUIRES(c, 0 <= i && i < tensor_list->tensors().size(),\n                     absl::InvalidArgumentError(absl::StrCat(\n@@ -728,7 +731,7 @@ class TensorListGather : public OpKernel {\n     inputs_flat.reserve(indices.NumElements());\n     Tensor zeros;\n     for (int index = 0; index < indices.NumElements(); ++index) {\n-      const int i = indices.flat<int32>()(index);\n+      const int i = indices.flat<int32_t>()(index);\n       OP_REQUIRES(\n           c, i < tensor_list->tensors().size(),\n           errors::InvalidArgument(\"Index \", i, \" out o range; list only has \",\n@@ -832,7 +835,7 @@ absl::Status Scatter(OpKernelContext* c, const Tensor& value,\n   const auto copy_tensor = IsPluggableDevice(c) ? &CopyTensorPluggableDevice<T>\n                                                 : &CopyTensor<Device, T>;\n   for (int index = 0; index < indices.NumElements(); ++index) {\n-    const int i = indices.flat<int32>()(index);\n+    const int i = indices.flat<int32_t>()(index);\n     Tensor tmp = value.Slice(index, index + 1);\n     TensorShape tmp_shape = tmp.shape();\n     tmp_shape.RemoveDim(0);\n@@ -885,7 +888,7 @@ class TensorListScatterIntoExistingList : public OpKernel {\n     // Resize the list if needed to accommodate all indices.\n     TensorList* output_list = nullptr;\n     OP_REQUIRES_OK(c, ForwardInputOrCreateNewList(c, 0, 0, *l, &output_list));\n-    const auto indices_vec = indices.vec<int32>();\n+    const auto indices_vec = indices.vec<int32_t>();\n     int32_t max_index =\n         (indices.NumElements() == 0)\n             ? -1\n@@ -956,7 +959,7 @@ class TensorListScatter : public OpKernel {\n     {\n       int highest_index = -1;\n       for (int index = 0; index < indices.NumElements(); ++index) {\n-        const int i = indices.flat<int32>()(index);\n+        const int i = indices.flat<int32_t>()(index);\n         OP_REQUIRES(\n             c, i >= 0,\n             errors::InvalidArgument("
        },
        {
            "sha": "eb0a6eec9345aaee992173a9507035c0d0882adb",
            "filename": "tensorflow/core/kernels/listdiff_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flistdiff_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flistdiff_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flistdiff_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -48,7 +48,7 @@ class ListDiffOp : public OpKernel {\n     const auto Ty = y.vec<T>();\n     const size_t y_size = Ty.size();\n \n-    OP_REQUIRES(context, x_size < std::numeric_limits<int32>::max(),\n+    OP_REQUIRES(context, x_size < std::numeric_limits<int32_t>::max(),\n                 errors::InvalidArgument(\"x too large for int32 indexing\"));\n \n     std::unordered_set<T> y_set;"
        },
        {
            "sha": "a952da3595ccda079ac2dc0ceee9fd938ebf2cfd",
            "filename": "tensorflow/core/kernels/load_and_remap_matrix_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fload_and_remap_matrix_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fload_and_remap_matrix_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fload_and_remap_matrix_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -133,11 +133,11 @@ class LoadAndRemapMatrixOp : public OpKernel {\n         errors::InvalidArgument(\"The `ckpt_path` tensor must have exactly one \"\n                                 \"element, got tensor of shape \",\n                                 ckpt_path_t->shape().DebugString()));\n-    const string& ckpt_path = ckpt_path_t->scalar<tstring>()();\n+    const std::string& ckpt_path = ckpt_path_t->scalar<tstring>()();\n     const Tensor* old_tensor_name_t;\n     OP_REQUIRES_OK(context,\n                    context->input(\"old_tensor_name\", &old_tensor_name_t));\n-    const string& old_tensor_name = old_tensor_name_t->scalar<tstring>()();\n+    const std::string& old_tensor_name = old_tensor_name_t->scalar<tstring>()();\n \n     LOG(INFO) << \"Processing checkpoint : \" << ckpt_path;\n     BundleReader reader(context->env(), ckpt_path);"
        },
        {
            "sha": "b589d918626f1dd238c0908b9982167b14fe59e7",
            "filename": "tensorflow/core/kernels/logging_ops.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 13,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flogging_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flogging_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flogging_ops.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -64,7 +64,7 @@ void AssertOp::Compute(OpKernelContext* ctx) {\n   if (cond.scalar<bool>()()) {\n     return;\n   }\n-  string msg = \"assertion failed: \";\n+  std::string msg = \"assertion failed: \";\n   for (int i = 1; i < ctx->num_inputs(); ++i) {\n     absl::StrAppend(&msg, \"[\", ctx->input(i).SummarizeValue(summarize_), \"]\");\n     if (i < ctx->num_inputs() - 1) absl::StrAppend(&msg, \" \");\n@@ -98,7 +98,7 @@ class PrintOp : public OpKernel {\n       if (call_counter_ >= first_n_) return;\n       call_counter_++;\n     }\n-    string msg;\n+    std::string msg;\n     absl::StrAppend(&msg, message_);\n     for (int i = 1; i < ctx->num_inputs(); ++i) {\n       absl::StrAppend(&msg, \"[\", ctx->input(i).SummarizeValue(summarize_), \"]\");\n@@ -110,8 +110,8 @@ class PrintOp : public OpKernel {\n   mutex mu_;\n   int64_t call_counter_ TF_GUARDED_BY(mu_) = 0;\n   int64_t first_n_ = 0;\n-  int32 summarize_ = 0;\n-  string message_;\n+  int32_t summarize_ = 0;\n+  std::string message_;\n };\n \n REGISTER_KERNEL_BUILDER(Name(\"Print\").Device(DEVICE_CPU), PrintOp);\n@@ -130,8 +130,8 @@ class PrintV2Op : public OpKernel {\n                   std::end(valid_output_streams_), output_stream_);\n \n     if (output_stream_index == std::end(valid_output_streams_)) {\n-      string error_msg = absl::StrCat(\"Unknown output stream: \", output_stream_,\n-                                      \", Valid streams are:\");\n+      std::string error_msg = absl::StrCat(\n+          \"Unknown output stream: \", output_stream_, \", Valid streams are:\");\n       for (auto valid_stream : valid_output_streams_) {\n         absl::StrAppend(&error_msg, \" \", valid_stream);\n       }\n@@ -146,9 +146,9 @@ class PrintV2Op : public OpKernel {\n         ctx, TensorShapeUtils::IsScalar(input_->shape()),\n         errors::InvalidArgument(\"Input is expected to be scalar, but got \",\n                                 input_->shape()));\n-    const string& msg = input_->scalar<tstring>()();\n+    const std::string& msg = input_->scalar<tstring>()();\n \n-    string ended_msg = absl::StrCat(msg, end_);\n+    std::string ended_msg = absl::StrCat(msg, end_);\n \n     if (!file_path_.empty()) {\n       // Outputs to a file at the specified path.\n@@ -172,8 +172,8 @@ class PrintV2Op : public OpKernel {\n     } else if (output_stream_ == \"log(error)\") {\n       LOG(ERROR) << ended_msg << std::flush;\n     } else {\n-      string error_msg = absl::StrCat(\"Unknown output stream: \", output_stream_,\n-                                      \", Valid streams are:\");\n+      std::string error_msg = absl::StrCat(\n+          \"Unknown output stream: \", output_stream_, \", Valid streams are:\");\n       for (auto valid_stream : valid_output_streams_) {\n         absl::StrAppend(&error_msg, \" \", valid_stream);\n       }\n@@ -186,10 +186,10 @@ class PrintV2Op : public OpKernel {\n                                           \"log(warning)\", \"log(error)\"};\n \n  private:\n-  string end_;\n+  std::string end_;\n   // Either output_stream_ or file_path_ (but not both) will be non-empty.\n-  string output_stream_;\n-  string file_path_;\n+  std::string output_stream_;\n+  std::string file_path_;\n \n   // If output_stream_ is a file path, extracts it to file_path_ and clears\n   // output_stream_; otherwise sets file_paths_ to \"\"."
        },
        {
            "sha": "f5a58643d8e1a3506145ebf614942c616ce4baf8",
            "filename": "tensorflow/core/kernels/logging_ops.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flogging_ops.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flogging_ops.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flogging_ops.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -25,7 +25,7 @@ class AssertOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override;\n \n  private:\n-  int32 summarize_ = 0;\n+  int32_t summarize_ = 0;\n };\n \n }  // namespace tensorflow"
        },
        {
            "sha": "fbce44642938dbf9e848148ddf0e5793501ca438",
            "filename": "tensorflow/core/kernels/logging_ops_test.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 22,
            "changes": 44,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flogging_ops_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flogging_ops_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flogging_ops_test.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -34,7 +34,7 @@ namespace {\n \n class PrintingV2GraphTest : public OpsTestBase {\n  protected:\n-  absl::Status Init(const string& output_stream = \"log(warning)\") {\n+  absl::Status Init(const std::string& output_stream = \"log(warning)\") {\n     TF_CHECK_OK(NodeDefBuilder(\"op\", \"PrintV2\")\n                     .Input(FakeInput(DT_STRING))\n                     .Attr(\"output_stream\", output_stream)\n@@ -61,8 +61,8 @@ TEST_F(PrintingV2GraphTest, InvalidInputRank) {\n \n class PrintingGraphTest : public OpsTestBase {\n  protected:\n-  absl::Status Init(DataType input_type1, DataType input_type2, string msg = \"\",\n-                    int first_n = -1, int summarize = 3) {\n+  absl::Status Init(DataType input_type1, DataType input_type2,\n+                    std::string msg = \"\", int first_n = -1, int summarize = 3) {\n     TF_CHECK_OK(NodeDefBuilder(\"op\", \"Print\")\n                     .Input(FakeInput(input_type1))\n                     .Input(FakeInput(2, input_type2))\n@@ -76,58 +76,58 @@ class PrintingGraphTest : public OpsTestBase {\n \n TEST_F(PrintingGraphTest, Int32Success_6) {\n   TF_ASSERT_OK(Init(DT_INT32, DT_INT32));\n-  AddInputFromArray<int32>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n-  AddInputFromArray<int32>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n-  AddInputFromArray<int32>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n+  AddInputFromArray<int32_t>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n+  AddInputFromArray<int32_t>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n+  AddInputFromArray<int32_t>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_INT32, TensorShape({6}));\n-  test::FillValues<int32>(&expected, {1, 2, 3, 4, 5, 6});\n-  test::ExpectTensorEqual<int32>(expected, *GetOutput(0));\n+  test::FillValues<int32_t>(&expected, {1, 2, 3, 4, 5, 6});\n+  test::ExpectTensorEqual<int32_t>(expected, *GetOutput(0));\n }\n \n TEST_F(PrintingGraphTest, Int32Success_Summarize6) {\n   TF_ASSERT_OK(Init(DT_INT32, DT_INT32, \"\", -1, 6));\n-  AddInputFromArray<int32>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n-  AddInputFromArray<int32>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n-  AddInputFromArray<int32>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n+  AddInputFromArray<int32_t>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n+  AddInputFromArray<int32_t>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n+  AddInputFromArray<int32_t>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_INT32, TensorShape({6}));\n-  test::FillValues<int32>(&expected, {1, 2, 3, 4, 5, 6});\n-  test::ExpectTensorEqual<int32>(expected, *GetOutput(0));\n+  test::FillValues<int32_t>(&expected, {1, 2, 3, 4, 5, 6});\n+  test::ExpectTensorEqual<int32_t>(expected, *GetOutput(0));\n }\n \n TEST_F(PrintingGraphTest, StringSuccess) {\n   TF_ASSERT_OK(Init(DT_INT32, DT_STRING));\n-  AddInputFromArray<int32>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n+  AddInputFromArray<int32_t>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n   AddInputFromArray<tstring>(TensorShape({}), {\"foo\"});\n   AddInputFromArray<tstring>(TensorShape({}), {\"bar\"});\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_INT32, TensorShape({6}));\n-  test::FillValues<int32>(&expected, {1, 2, 3, 4, 5, 6});\n-  test::ExpectTensorEqual<int32>(expected, *GetOutput(0));\n+  test::FillValues<int32_t>(&expected, {1, 2, 3, 4, 5, 6});\n+  test::ExpectTensorEqual<int32_t>(expected, *GetOutput(0));\n }\n \n TEST_F(PrintingGraphTest, MsgSuccess) {\n   TF_ASSERT_OK(Init(DT_INT32, DT_STRING, \"Message: \"));\n-  AddInputFromArray<int32>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n+  AddInputFromArray<int32_t>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n   AddInputFromArray<tstring>(TensorShape({}), {\"foo\"});\n   AddInputFromArray<tstring>(TensorShape({}), {\"bar\"});\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_INT32, TensorShape({6}));\n-  test::FillValues<int32>(&expected, {1, 2, 3, 4, 5, 6});\n-  test::ExpectTensorEqual<int32>(expected, *GetOutput(0));\n+  test::FillValues<int32_t>(&expected, {1, 2, 3, 4, 5, 6});\n+  test::ExpectTensorEqual<int32_t>(expected, *GetOutput(0));\n }\n \n TEST_F(PrintingGraphTest, FirstNSuccess) {\n   TF_ASSERT_OK(Init(DT_INT32, DT_STRING, \"\", 3));\n-  AddInputFromArray<int32>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n+  AddInputFromArray<int32_t>(TensorShape({6}), {1, 2, 3, 4, 5, 6});\n   AddInputFromArray<tstring>(TensorShape({}), {\"foo\"});\n   AddInputFromArray<tstring>(TensorShape({}), {\"bar\"});\n   // run 4 times but we only print 3 as intended\n   for (int i = 0; i < 4; i++) TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_INT32, TensorShape({6}));\n-  test::FillValues<int32>(&expected, {1, 2, 3, 4, 5, 6});\n-  test::ExpectTensorEqual<int32>(expected, *GetOutput(0));\n+  test::FillValues<int32_t>(&expected, {1, 2, 3, 4, 5, 6});\n+  test::ExpectTensorEqual<int32_t>(expected, *GetOutput(0));\n }\n \n class TimestampTest : public OpsTestBase {"
        },
        {
            "sha": "fb13ccc162eb9004ca20d2f227c7930afc066726",
            "filename": "tensorflow/core/kernels/lookup_ops_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_ops_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_ops_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flookup_ops_test.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -51,8 +51,8 @@ class MockHashTable : public lookup::HashTable<K, V> {\n   ~MockHashTable() override { alive = false; }\n };\n \n-typedef int32 key_dtype;\n-typedef int32 value_dtype;\n+typedef int32_t key_dtype;\n+typedef int32_t value_dtype;\n \n REGISTER_KERNEL_BUILDER(\n     Name(\"MockAnonymousHashTable\")"
        },
        {
            "sha": "c936cad9addd6d1bb8e12114a3d5e0a6a40ec8e5",
            "filename": "tensorflow/core/kernels/lookup_table_init_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_table_init_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_table_init_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flookup_table_init_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -111,7 +111,7 @@ class InitializeTableFromTextFileOp : public OpKernel {\n     if (ctx->HasAttr(\"offset\")) {\n       OP_REQUIRES_OK(ctx, ctx->GetAttr(\"offset\", &offset_));\n     }\n-    string delimiter;\n+    std::string delimiter;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"delimiter\", &delimiter));\n     OP_REQUIRES(ctx, delimiter.size() == 1,\n                 errors::InvalidArgument(\"delimiter should be only 1 char\"));\n@@ -137,7 +137,8 @@ class InitializeTableFromTextFileOp : public OpKernel {\n         errors::InvalidArgument(\"filename should be a single string, but got \",\n                                 vocab_filename_tensor.shape().DebugString()));\n \n-    const string& vocab_filename = vocab_filename_tensor.scalar<tstring>()();\n+    const std::string& vocab_filename =\n+        vocab_filename_tensor.scalar<tstring>()();\n     OP_REQUIRES(ctx, !vocab_filename.empty(),\n                 errors::InvalidArgument(\"filename cannot be empty.\"));\n "
        },
        {
            "sha": "f6e246486a45325b57b64a680eb012f51c233e7e",
            "filename": "tensorflow/core/kernels/lookup_table_init_op.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_table_init_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_table_init_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flookup_table_init_op.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -22,7 +22,7 @@ namespace tensorflow {\n namespace lookup {\n \n // Helper function to initialize an InitializableLookupTable from a text file.\n-absl::Status InitializeTableFromTextFile(const string& filename,\n+absl::Status InitializeTableFromTextFile(const std::string& filename,\n                                          int64_t vocab_size, char delimiter,\n                                          int32_t key_index, int32_t value_index,\n                                          Env* env,"
        },
        {
            "sha": "54d2c8cca1669e29adef147add040c4057d0f341",
            "filename": "tensorflow/core/kernels/lookup_table_op.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 31,
            "changes": 62,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_table_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_table_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flookup_table_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -411,11 +411,11 @@ class MutableHashTableOfTensors final : public LookupInterface {\n namespace {\n \n template <typename T>\n-inline uint64 HashScalar(const T& key) {\n-  return static_cast<uint64>(key);\n+inline uint64_t HashScalar(const T& key) {\n+  return static_cast<uint64_t>(key);\n }\n \n-inline uint64 HashScalar(const tstring& key) { return Hash64(key); }\n+inline uint64_t HashScalar(const tstring& key) { return Hash64(key); }\n \n // If the given shape is a scalar return {1} instead. Otherwise leave it alone.\n TensorShape MaybeVectorizeShape(const TensorShape& shape) {\n@@ -523,7 +523,7 @@ class MutableDenseHashTable final : public LookupInterface {\n     const int64_t bit_mask = num_buckets_ - 1;\n     // TODO(andreasst): parallelize using work_sharder\n     for (int64_t i = 0; i < num_elements; ++i) {\n-      const uint64 key_hash = HashKey(key_matrix, i);\n+      const uint64_t key_hash = HashKey(key_matrix, i);\n       if (empty_key_hash_ == key_hash &&\n           IsEqualKey(empty_key_matrix, 0, key_matrix, i)) {\n         return errors::InvalidArgument(\n@@ -693,7 +693,7 @@ class MutableDenseHashTable final : public LookupInterface {\n         deleted_key_.template shaped<K, 2>({1, key_size});\n     const int64_t bit_mask = num_buckets_ - 1;\n     for (int64_t i = 0; i < num_elements; ++i) {\n-      const uint64 key_hash = HashKey(key_matrix, i);\n+      const uint64_t key_hash = HashKey(key_matrix, i);\n       if (empty_key_hash_ == key_hash &&\n           IsEqualKey(empty_key_tensor, 0, key_matrix, i)) {\n         if (ignore_empty_and_deleted_key) {\n@@ -760,7 +760,7 @@ class MutableDenseHashTable final : public LookupInterface {\n     const auto deleted_key_flat = deleted_key_.template flat<K>();\n     const int64_t bit_mask = num_buckets_ - 1;\n     for (int64_t i = 0; i < num_elements; ++i) {\n-      const uint64 key_hash = HashKey(key_matrix, i);\n+      const uint64_t key_hash = HashKey(key_matrix, i);\n       if (empty_key_hash_ == key_hash &&\n           IsEqualKey(empty_key_tensor, 0, key_matrix, i)) {\n         return errors::InvalidArgument(\n@@ -843,11 +843,11 @@ class MutableDenseHashTable final : public LookupInterface {\n     return DoInsert(ctx, old_key_buckets, old_value_buckets, true);\n   }\n \n-  uint64 HashKey(typename TTypes<K>::ConstMatrix key, int64_t index) const {\n+  uint64_t HashKey(typename TTypes<K>::ConstMatrix key, int64_t index) const {\n     if (key_shape_.num_elements() == 1) {\n       return HashScalar(key(index, 0));\n     }\n-    uint64 result = 0;\n+    uint64_t result = 0;\n     for (int64_t i = 0; i < key_shape_.num_elements(); ++i) {\n       result = Hash64Combine(result, HashScalar(key(index, i)));\n     }\n@@ -876,9 +876,9 @@ class MutableDenseHashTable final : public LookupInterface {\n   Tensor key_buckets_ TF_GUARDED_BY(mu_);\n   Tensor value_buckets_ TF_GUARDED_BY(mu_);\n   Tensor empty_key_;\n-  uint64 empty_key_hash_;\n+  uint64_t empty_key_hash_;\n   Tensor deleted_key_;\n-  uint64 deleted_key_hash_;\n+  uint64_t deleted_key_hash_;\n };\n \n }  // namespace lookup\n@@ -1103,19 +1103,19 @@ REGISTER_KERNEL_BUILDER(Name(\"LookupTableImportV2\").Device(DEVICE_CPU),\n       AnonymousLookupTableOp<lookup::HashTable<key_dtype, value_dtype>,   \\\n                              key_dtype, value_dtype>)\n \n-REGISTER_KERNEL(int32, double);\n-REGISTER_KERNEL(int32, float);\n-REGISTER_KERNEL(int32, int32);\n-REGISTER_KERNEL(int32, tstring);\n+REGISTER_KERNEL(int32_t, double);\n+REGISTER_KERNEL(int32_t, float);\n+REGISTER_KERNEL(int32_t, int32_t);\n+REGISTER_KERNEL(int32_t, tstring);\n REGISTER_KERNEL(int64_t, double);\n REGISTER_KERNEL(int64_t, float);\n-REGISTER_KERNEL(int64_t, int32);\n+REGISTER_KERNEL(int64_t, int32_t);\n REGISTER_KERNEL(int64_t, int64_t);\n REGISTER_KERNEL(int64_t, tstring);\n REGISTER_KERNEL(tstring, bool);\n REGISTER_KERNEL(tstring, double);\n REGISTER_KERNEL(tstring, float);\n-REGISTER_KERNEL(tstring, int32);\n+REGISTER_KERNEL(tstring, int32_t);\n REGISTER_KERNEL(tstring, int64_t);\n REGISTER_KERNEL(tstring, tstring);\n \n@@ -1146,19 +1146,19 @@ REGISTER_KERNEL(tstring, tstring);\n           lookup::MutableHashTableOfScalars<key_dtype, value_dtype>,           \\\n           key_dtype, value_dtype>)\n \n-REGISTER_KERNEL(int32, double);\n-REGISTER_KERNEL(int32, float);\n-REGISTER_KERNEL(int32, int32);\n+REGISTER_KERNEL(int32_t, double);\n+REGISTER_KERNEL(int32_t, float);\n+REGISTER_KERNEL(int32_t, int32_t);\n REGISTER_KERNEL(int64_t, double);\n REGISTER_KERNEL(int64_t, float);\n-REGISTER_KERNEL(int64_t, int32);\n+REGISTER_KERNEL(int64_t, int32_t);\n REGISTER_KERNEL(int64_t, int64_t);\n REGISTER_KERNEL(int64_t, tstring);\n REGISTER_KERNEL(int64_t, Variant);\n REGISTER_KERNEL(tstring, bool);\n REGISTER_KERNEL(tstring, double);\n REGISTER_KERNEL(tstring, float);\n-REGISTER_KERNEL(tstring, int32);\n+REGISTER_KERNEL(tstring, int32_t);\n REGISTER_KERNEL(tstring, int64_t);\n \n #undef REGISTER_KERNEL\n@@ -1188,18 +1188,18 @@ REGISTER_KERNEL(tstring, int64_t);\n           lookup::MutableHashTableOfTensors<key_dtype, value_dtype>,           \\\n           key_dtype, value_dtype>)\n \n-REGISTER_KERNEL(int32, double);\n-REGISTER_KERNEL(int32, float);\n-REGISTER_KERNEL(int32, int32);\n+REGISTER_KERNEL(int32_t, double);\n+REGISTER_KERNEL(int32_t, float);\n+REGISTER_KERNEL(int32_t, int32_t);\n REGISTER_KERNEL(int64_t, double);\n REGISTER_KERNEL(int64_t, float);\n-REGISTER_KERNEL(int64_t, int32);\n+REGISTER_KERNEL(int64_t, int32_t);\n REGISTER_KERNEL(int64_t, int64_t);\n REGISTER_KERNEL(int64_t, tstring);\n REGISTER_KERNEL(tstring, bool);\n REGISTER_KERNEL(tstring, double);\n REGISTER_KERNEL(tstring, float);\n-REGISTER_KERNEL(tstring, int32);\n+REGISTER_KERNEL(tstring, int32_t);\n REGISTER_KERNEL(tstring, int64_t);\n \n #undef REGISTER_KERNEL\n@@ -1229,19 +1229,19 @@ REGISTER_KERNEL(tstring, int64_t);\n           lookup::MutableDenseHashTable<key_dtype, value_dtype>, key_dtype, \\\n           value_dtype>)\n \n-REGISTER_KERNEL(int32, double);\n-REGISTER_KERNEL(int32, float);\n-REGISTER_KERNEL(int32, int32);\n+REGISTER_KERNEL(int32_t, double);\n+REGISTER_KERNEL(int32_t, float);\n+REGISTER_KERNEL(int32_t, int32_t);\n REGISTER_KERNEL(int64_t, bool);\n REGISTER_KERNEL(int64_t, double);\n REGISTER_KERNEL(int64_t, float);\n-REGISTER_KERNEL(int64_t, int32);\n+REGISTER_KERNEL(int64_t, int32_t);\n REGISTER_KERNEL(int64_t, int64_t);\n REGISTER_KERNEL(int64_t, Variant);\n REGISTER_KERNEL(tstring, bool);\n REGISTER_KERNEL(tstring, double);\n REGISTER_KERNEL(tstring, float);\n-REGISTER_KERNEL(tstring, int32);\n+REGISTER_KERNEL(tstring, int32_t);\n REGISTER_KERNEL(tstring, int64_t);\n REGISTER_KERNEL(tstring, ResourceHandle);\n "
        },
        {
            "sha": "840720d2e3e61d8f1420caef9ddd86aeeac20f63",
            "filename": "tensorflow/core/kernels/lookup_table_op.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_table_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_table_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flookup_table_op.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -300,7 +300,7 @@ class HashTable : public InitializableLookupTable {\n     return absl::OkStatus();\n   };\n \n-  absl::Status DoLazyPrepare(std::function<int64(void)> size_fn) override {\n+  absl::Status DoLazyPrepare(std::function<int64_t(void)> size_fn) override {\n     return DoPrepare(size_fn());\n   }\n "
        },
        {
            "sha": "744b2e9c21b5acbdd1a43c4a9d127f0b4e95b7e9",
            "filename": "tensorflow/core/kernels/lookup_util.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 20,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flookup_util.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -37,13 +37,13 @@ static const int kInputBufferSize = 1 * 1024 * 1024; /* bytes */\n static const int kLineNumber = -1;\n static const int kWholeLine = -2;\n \n-absl::Status GetNumLinesInTextFile(Env* env, const string& vocab_file,\n+absl::Status GetNumLinesInTextFile(Env* env, const std::string& vocab_file,\n                                    int64_t* num_lines) {\n   std::unique_ptr<RandomAccessFile> file;\n   TF_RETURN_IF_ERROR(env->NewRandomAccessFile(vocab_file, &file));\n \n   io::InputBuffer input_buffer(file.get(), kInputBufferSize);\n-  string line;\n+  std::string line;\n   absl::Status s = input_buffer.ReadLine(&line);\n   int64_t next_id = 0;\n   while (s.ok()) {\n@@ -81,9 +81,10 @@ class TextFileLineIterator\n   // - Index -1 means the line number stored in int64.\n   // - Index >= 0 represent index (starting at zero) of the split line based on\n   //   delimiter.\n-  absl::Status Init(const string& filename, int64_t vocab_size, char delimiter,\n-                    DataType key_dtype, int64_t key_index, DataType value_dtype,\n-                    int64_t value_index, int64_t offset, Env* env) {\n+  absl::Status Init(const std::string& filename, int64_t vocab_size,\n+                    char delimiter, DataType key_dtype, int64_t key_index,\n+                    DataType value_dtype, int64_t value_index, int64_t offset,\n+                    Env* env) {\n     filename_ = filename;\n     vocab_size_ = vocab_size;\n     delimiter_ = delimiter;\n@@ -108,7 +109,7 @@ class TextFileLineIterator\n   void Next() override {\n     if (!valid_) return;\n \n-    string line;\n+    std::string line;\n     status_ = input_buffer_->ReadLine(&line);\n     if (!status_.ok()) {\n       if (absl::IsOutOfRange(status_) && vocab_size_ != -1 &&\n@@ -137,7 +138,7 @@ class TextFileLineIterator\n       return;\n     }\n \n-    std::vector<string> tokens;\n+    std::vector<std::string> tokens;\n     if (!ignore_split_) {\n       tokens = str_util::Split(line, delimiter_);\n       const auto expected_size =\n@@ -197,7 +198,7 @@ class TextFileLineIterator\n   int64_t next_id_;\n   int64_t offset_;\n   int64_t vocab_size_;\n-  string filename_;\n+  std::string filename_;\n   char delimiter_;\n   absl::Status status_;\n   bool ignore_split_;\n@@ -206,13 +207,14 @@ class TextFileLineIterator\n \n   // Set the corresponding value from line or tokens based on 'index' into the\n   // tensor 't'. The value is transformed to the given data type 'dtype'.\n-  absl::Status SetValue(const string& line, const std::vector<string>& tokens,\n-                        int64_t index, Tensor* tensor) {\n+  absl::Status SetValue(const std::string& line,\n+                        const std::vector<std::string>& tokens, int64_t index,\n+                        Tensor* tensor) {\n     if (index == kLineNumber) {\n       tensor->flat<int64_t>()(0) = next_id_ + offset_;\n       return absl::OkStatus();\n     }\n-    const string& token = (index == kWholeLine) ? line : tokens[index];\n+    const std::string& token = (index == kWholeLine) ? line : tokens[index];\n     const DataType& dtype = tensor->dtype();\n     switch (dtype) {\n       case DT_INT32: {\n@@ -222,7 +224,7 @@ class TextFileLineIterator\n           return errors::InvalidArgument(\"Field \", token, \" in line \", next_id_,\n                                          \" is not a valid int32.\");\n         }\n-        tensor->flat<int32>()(0) = value + offset_;\n+        tensor->flat<int32_t>()(0) = value + offset_;\n       } break;\n       case DT_INT64: {\n         int64_t value;\n@@ -267,7 +269,7 @@ class TextFileLineIterator\n };\n \n absl::Status GetTableHandle(absl::string_view input_name, OpKernelContext* ctx,\n-                            string* container, string* table_handle) {\n+                            std::string* container, std::string* table_handle) {\n   {\n     mutex* mu;\n     TF_RETURN_IF_ERROR(ctx->input_ref_mutex(input_name, &mu));\n@@ -300,8 +302,8 @@ absl::Status GetResourceLookupTable(absl::string_view input_name,\n absl::Status GetReferenceLookupTable(absl::string_view input_name,\n                                      OpKernelContext* ctx,\n                                      LookupInterface** table) {\n-  string container;\n-  string table_handle;\n+  std::string container;\n+  std::string table_handle;\n   TF_RETURN_IF_ERROR(\n       GetTableHandle(input_name, ctx, &container, &table_handle));\n   return ctx->resource_manager()->Lookup(container, table_handle, table);\n@@ -335,8 +337,8 @@ absl::Status GetInitializableLookupTable(absl::string_view input_name,\n                                      handle.name(), \" is not initializable\");\n     }\n   } else {\n-    string container;\n-    string table_handle;\n+    std::string container;\n+    std::string table_handle;\n     TF_RETURN_IF_ERROR(\n         GetTableHandle(input_name, ctx, &container, &table_handle));\n     TF_RETURN_IF_ERROR(ctx->resource_manager()->Lookup(container, table_handle,\n@@ -353,7 +355,7 @@ absl::Status GetInitializableLookupTable(absl::string_view input_name,\n \n absl::Status CheckTableDataTypes(const LookupInterface& table,\n                                  DataType key_dtype, DataType value_dtype,\n-                                 const string& table_name) {\n+                                 const std::string& table_name) {\n   if (table.key_dtype() != key_dtype || table.value_dtype() != value_dtype) {\n     return errors::InvalidArgument(\n         \"Conflicting key/value dtypes \", DataTypeString(key_dtype), \"->\",\n@@ -365,7 +367,7 @@ absl::Status CheckTableDataTypes(const LookupInterface& table,\n }\n \n // Helper function to initialize an InitializableLookupTable from a text file.\n-absl::Status InitializeTableFromTextFile(const string& filename,\n+absl::Status InitializeTableFromTextFile(const std::string& filename,\n                                          int64_t vocab_size, char delimiter,\n                                          int32_t key_index, int32_t value_index,\n                                          int64_t offset, Env* env,\n@@ -376,7 +378,7 @@ absl::Status InitializeTableFromTextFile(const string& filename,\n }\n \n absl::Status InitializeTableFromTextFile(\n-    const string& filename, int64_t vocab_size, char delimiter,\n+    const std::string& filename, int64_t vocab_size, char delimiter,\n     int32_t key_index, int32_t value_index, int64_t offset, Env* env,\n     std::unique_ptr<InitializableLookupTable::InitializerSerializer> serializer,\n     InitializableLookupTable* table) {"
        },
        {
            "sha": "e48718ad805bdbe5e0620600ee9724ddbd19cd24",
            "filename": "tensorflow/core/kernels/lookup_util.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flookup_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flookup_util.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -53,10 +53,10 @@ absl::Status GetInitializableLookupTable(absl::string_view input_name,\n // table's data types.\n absl::Status CheckTableDataTypes(const LookupInterface& table,\n                                  DataType key_dtype, DataType value_dtype,\n-                                 const string& table_name);\n+                                 const std::string& table_name);\n \n // Initializes `table` from `filename`.\n-absl::Status InitializeTableFromTextFile(const string& filename,\n+absl::Status InitializeTableFromTextFile(const std::string& filename,\n                                          int64_t vocab_size, char delimiter,\n                                          int32_t key_index, int32_t value_index,\n                                          int64_t offset, Env* env,\n@@ -65,7 +65,7 @@ absl::Status InitializeTableFromTextFile(const string& filename,\n // Initializes `table` from `filename`. `func` may specify how to represent the\n // initializer as a graphdef, so that the table can be serialized as metadata.\n absl::Status InitializeTableFromTextFile(\n-    const string& filename, int64_t vocab_size, char delimiter,\n+    const std::string& filename, int64_t vocab_size, char delimiter,\n     int32_t key_index, int32_t value_index, int64_t offset, Env* env,\n     std::unique_ptr<InitializableLookupTable::InitializerSerializer> serializer,\n     InitializableLookupTable* table);"
        },
        {
            "sha": "3c8515d522501b1e1209882b21a66a07b6198bda",
            "filename": "tensorflow/core/kernels/lrn_op_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flrn_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Flrn_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flrn_op_test.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -40,13 +40,13 @@ class LRNFloatTest : public OpsTestBase {\n  protected:\n   LRNFloatTest() : philox_(123, 17), rand_(&philox_) {}\n \n-  int GetIntAttr(const string& name) {\n+  int GetIntAttr(const std::string& name) {\n     int value;\n     TF_CHECK_OK(GetNodeAttr(*node_def(), name, &value));\n     return value;\n   }\n \n-  float GetFloatAttr(const string& name) {\n+  float GetFloatAttr(const std::string& name) {\n     float value;\n     TF_CHECK_OK(GetNodeAttr(*node_def(), name, &value));\n     return value;"
        },
        {
            "sha": "ab57ba02dccbc4da6914c866348ef05750b05c4c",
            "filename": "tensorflow/core/kernels/map_kernels.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmap_kernels.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmap_kernels.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fmap_kernels.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -102,7 +102,7 @@ class TensorMapSize : public OpKernel {\n     OP_REQUIRES_OK(ctx, GetInputMap(ctx, 0, &map));\n     Tensor* result;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape{}, &result));\n-    result->scalar<int32>()() = map->tensors().size();\n+    result->scalar<int32_t>()() = map->tensors().size();\n   }\n };\n "
        },
        {
            "sha": "12e018dfdd311d1641145f2a409990a47a13365b",
            "filename": "tensorflow/core/kernels/map_stage_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmap_stage_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmap_stage_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fmap_stage_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -489,7 +489,7 @@ class StagingMap : public ResourceBase {\n     return map_.size();\n   }\n \n-  string DebugString() const override { return \"StagingMap\"; }\n+  std::string DebugString() const override { return \"StagingMap\"; }\n };\n \n template <bool Ordered>\n@@ -736,7 +736,7 @@ class MapSizeOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &size));\n \n     // Set it to the actual size\n-    size->scalar<int32>().setConstant(map->size());\n+    size->scalar<int32_t>().setConstant(map->size());\n   }\n };\n \n@@ -766,7 +766,7 @@ class MapIncompleteSizeOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &size));\n \n     // Set it to the actual size\n-    size->scalar<int32>().setConstant(map->incomplete_size());\n+    size->scalar<int32_t>().setConstant(map->incomplete_size());\n   }\n };\n "
        },
        {
            "sha": "c48e6aeeab3bad17d81ffba6f81c93d64f6c900c",
            "filename": "tensorflow/core/kernels/matching_files_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmatching_files_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmatching_files_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fmatching_files_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -43,7 +43,7 @@ class MatchingFilesOp : public OpKernel {\n     const auto patterns = patterns_t->flat<tstring>();\n     int num_patterns = patterns.size();\n     int num_files = 0;\n-    std::vector<std::vector<string>> all_fnames(num_patterns);\n+    std::vector<std::vector<std::string>> all_fnames(num_patterns);\n     for (int i = 0; i < num_patterns; i++) {\n       OP_REQUIRES_OK(context, context->env()->GetMatchingPaths(patterns(i),\n                                                                &all_fnames[i]));"
        },
        {
            "sha": "54049fb852c0086dd3bddbe042d358f3664e185e",
            "filename": "tensorflow/core/kernels/matmul_op_real.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmatmul_op_real.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmatmul_op_real.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fmatmul_op_real.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -29,18 +29,18 @@ TF_CALL_int64(REGISTER_BATCH_MATMUL_CPU);\n REGISTER_BATCH_MATMUL_TOUT_CPU(bfloat16, bfloat16, bfloat16);\n REGISTER_BATCH_MATMUL_TOUT_CPU(float, float, float);\n REGISTER_BATCH_MATMUL_TOUT_CPU(double, double, double);\n-REGISTER_BATCH_MATMUL_TOUT_CPU(int16, int16, int16);\n-REGISTER_BATCH_MATMUL_TOUT_CPU(int32, int32, int32);\n+REGISTER_BATCH_MATMUL_TOUT_CPU(int16_t, int16_t, int16_t);\n+REGISTER_BATCH_MATMUL_TOUT_CPU(int32_t, int32_t, int32_t);\n REGISTER_BATCH_MATMUL_TOUT_CPU(int64_t, int64_t, int64_t);\n-REGISTER_BATCH_MATMUL_TOUT_CPU(int8, int8, int32);\n-REGISTER_BATCH_MATMUL_TOUT_CPU(uint8, int8, int32);\n-REGISTER_BATCH_MATMUL_TOUT_CPU(int8, uint8, int32);\n-REGISTER_BATCH_MATMUL_TOUT_CPU(uint8, uint8, int32);\n-\n-REGISTER_BATCH_MATMUL_TOUT_CPU(bfloat16, int8, bfloat16);\n-REGISTER_BATCH_MATMUL_TOUT_CPU(bfloat16, uint8, bfloat16);\n-REGISTER_BATCH_MATMUL_TOUT_CPU(int8, bfloat16, bfloat16);\n-REGISTER_BATCH_MATMUL_TOUT_CPU(uint8, bfloat16, bfloat16);\n+REGISTER_BATCH_MATMUL_TOUT_CPU(int8_t, int8_t, int32_t);\n+REGISTER_BATCH_MATMUL_TOUT_CPU(uint8_t, int8_t, int32_t);\n+REGISTER_BATCH_MATMUL_TOUT_CPU(int8_t, uint8_t, int32_t);\n+REGISTER_BATCH_MATMUL_TOUT_CPU(uint8_t, uint8_t, int32_t);\n+\n+REGISTER_BATCH_MATMUL_TOUT_CPU(bfloat16, int8_t, bfloat16);\n+REGISTER_BATCH_MATMUL_TOUT_CPU(bfloat16, uint8_t, bfloat16);\n+REGISTER_BATCH_MATMUL_TOUT_CPU(int8_t, bfloat16, bfloat16);\n+REGISTER_BATCH_MATMUL_TOUT_CPU(uint8_t, bfloat16, bfloat16);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n TF_CALL_GPU_NUMBER_TYPES(REGISTER_BATCH_MATMUL_GPU);"
        },
        {
            "sha": "e755ceb2beed1abc195642d3f546f6e501a661da",
            "filename": "tensorflow/core/kernels/matmul_op_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 10,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmatmul_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmatmul_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fmatmul_op_test.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -52,7 +52,7 @@ class FusedMatMulOpTest : public OpsTestBase {\n   // of 'fetch' node into the output Tensor. Optional `fetch_node` parameter\n   // allows to define a fetch node directly using a NodeDef for the ops that are\n   // not supported by the C++ Api.\n-  void RunAndFetch(const tensorflow::Scope& root, const string& fetch,\n+  void RunAndFetch(const tensorflow::Scope& root, const std::string& fetch,\n                    Tensor* output, bool allow_gpu_device,\n                    const NodeDef* fetch_node = nullptr,\n                    absl::Status* last_status = nullptr) {\n@@ -97,7 +97,8 @@ class FusedMatMulOpTest : public OpsTestBase {\n     // to compare GPU vs CPU numbers, so place all nodes on CPU in this case.\n     const bool place_all_on_gpu = allow_gpu_device && has_gpu_device;\n \n-    const string device = place_all_on_gpu ? \"/device:GPU:0\" : \"/device:CPU:0\";\n+    const std::string device =\n+        place_all_on_gpu ? \"/device:GPU:0\" : \"/device:CPU:0\";\n     for (NodeDef& mutable_node : *graph.mutable_node()) {\n       mutable_node.set_device(device);\n     }\n@@ -137,7 +138,7 @@ class FusedMatMulOpTest : public OpsTestBase {\n \n   void RunMatMulWithBiasAndActivation(\n       const Tensor& lhs_data, const Tensor& rhs_data, const Tensor& bias_data,\n-      bool transpose_a, bool transpose_b, const string& activation_type,\n+      bool transpose_a, bool transpose_b, const std::string& activation_type,\n       Tensor* output, bool allow_gpu_device = false) {\n     Scope root = tensorflow::Scope::NewRootScope();\n \n@@ -175,8 +176,8 @@ class FusedMatMulOpTest : public OpsTestBase {\n \n   void RunFusedMatMulOp(const Tensor& lhs_data, const Tensor& rhs_data,\n                         const std::vector<Tensor>& args_data,\n-                        const std::vector<string>& fused_ops, bool transpose_a,\n-                        bool transpose_b, Tensor* output,\n+                        const std::vector<std::string>& fused_ops,\n+                        bool transpose_a, bool transpose_b, Tensor* output,\n                         bool allow_gpu_device = false,\n                         bool* test_skipped = nullptr) {\n     Scope root = tensorflow::Scope::NewRootScope();\n@@ -295,7 +296,7 @@ class FusedMatMulOpTest : public OpsTestBase {\n   // to FusedMatMul.\n   void VerifyConv2DWithBiasAndActivation(int m, int k, int n, bool transpose_a,\n                                          bool transpose_b,\n-                                         const string& activation) {\n+                                         const std::string& activation) {\n     bool use_gpu_device =\n         activation == \"Relu\" || (this->kTValueType == DT_HALF);\n     const BiasAddGraphRunner run_default =\n@@ -372,7 +373,7 @@ static auto GetActivations(DataType dtype) {\n }\n \n TYPED_TEST_P(FusedMatMulWithBiasOpTest, MatMul256x128x64WithActivation) {\n-  for (const string& activation : GetActivations(this->kTValueType)) {\n+  for (const std::string& activation : GetActivations(this->kTValueType)) {\n     this->VerifyConv2DWithBiasAndActivation(256, 128, 64, false, false,\n                                             activation);\n     this->VerifyConv2DWithBiasAndActivation(256, 128, 64, true, false,\n@@ -385,21 +386,21 @@ TYPED_TEST_P(FusedMatMulWithBiasOpTest, MatMul256x128x64WithActivation) {\n }\n \n TYPED_TEST_P(FusedMatMulWithBiasOpTest, MatMul1x256x256WithActivation) {\n-  for (const string& activation : GetActivations(this->kTValueType)) {\n+  for (const std::string& activation : GetActivations(this->kTValueType)) {\n     this->VerifyConv2DWithBiasAndActivation(1, 256, 256, false, false,\n                                             activation);\n   }\n }\n \n TYPED_TEST_P(FusedMatMulWithBiasOpTest, MatMul256x256x1WithActivation) {\n-  for (const string& activation : GetActivations(this->kTValueType)) {\n+  for (const std::string& activation : GetActivations(this->kTValueType)) {\n     this->VerifyConv2DWithBiasAndActivation(256, 256, 1, false, false,\n                                             activation);\n   }\n }\n \n TYPED_TEST_P(FusedMatMulWithBiasOpTest, MatMul1x256x1WithActivation) {\n-  for (const string& activation : GetActivations(this->kTValueType)) {\n+  for (const std::string& activation : GetActivations(this->kTValueType)) {\n     this->VerifyConv2DWithBiasAndActivation(1, 256, 1, false, false,\n                                             activation);\n   }"
        },
        {
            "sha": "c20e9a957be25d5632192de308b2c6c1ca99e8e5",
            "filename": "tensorflow/core/kernels/maxpooling_op.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 31,
            "changes": 62,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -227,7 +227,7 @@ template <class Device, class T>\n class MaxPoolingGradOp : public OpKernel {\n  public:\n   explicit MaxPoolingGradOp(OpKernelConstruction* context) : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -289,16 +289,16 @@ class MaxPoolingGradOp : public OpKernel {\n     OP_REQUIRES_OK(context, context->allocate_temp(DataTypeToEnum<int64_t>::v(),\n                                                    tensor_out.shape(),\n                                                    &tensor_out_arg_max));\n-    std::vector<int32> ksize = ksize_;\n-    std::vector<int32> stride = stride_;\n+    std::vector<int32_t> ksize = ksize_;\n+    std::vector<int32_t> stride = stride_;\n     if (context->num_inputs() == 5) {\n       const Tensor& tensor_ksize = context->input(3);\n-      auto value_ksize = tensor_ksize.flat<int32>();\n+      auto value_ksize = tensor_ksize.flat<int32_t>();\n       ksize.resize(tensor_ksize.shape().num_elements());\n       std::copy_n(&value_ksize(0), ksize.size(), ksize.begin());\n \n       const Tensor& tensor_stride = context->input(4);\n-      auto value_stride = tensor_stride.flat<int32>();\n+      auto value_stride = tensor_stride.flat<int32_t>();\n       stride.resize(tensor_stride.shape().num_elements());\n       std::copy_n(&value_stride(0), stride.size(), stride.begin());\n     }\n@@ -351,8 +351,8 @@ class MaxPoolingGradOp : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   std::vector<int64_t> explicit_paddings_;\n   TensorFormat data_format_;\n@@ -473,7 +473,7 @@ class MaxPoolingGradGradOp : public OpKernel {\n  public:\n   explicit MaxPoolingGradGradOp(OpKernelConstruction* context)\n       : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -518,16 +518,16 @@ class MaxPoolingGradGradOp : public OpKernel {\n         context, out_grad_backprop.dims() == 4,\n         errors::InvalidArgument(\"out_grad_backprop must be 4-dimensional\"));\n \n-    std::vector<int32> ksize = ksize_;\n-    std::vector<int32> stride = stride_;\n+    std::vector<int32_t> ksize = ksize_;\n+    std::vector<int32_t> stride = stride_;\n     if (context->num_inputs() == 5) {\n       const Tensor& tensor_ksize = context->input(3);\n-      auto value_ksize = tensor_ksize.flat<int32>();\n+      auto value_ksize = tensor_ksize.flat<int32_t>();\n       ksize.resize(tensor_ksize.shape().num_elements());\n       std::copy_n(&value_ksize(0), ksize.size(), ksize.begin());\n \n       const Tensor& tensor_stride = context->input(4);\n-      auto value_stride = tensor_stride.flat<int32>();\n+      auto value_stride = tensor_stride.flat<int32_t>();\n       stride.resize(tensor_stride.shape().num_elements());\n       std::copy_n(&value_stride(0), stride.size(), stride.begin());\n     }\n@@ -683,8 +683,8 @@ class MaxPoolingGradGradOp : public OpKernel {\n           params.tensor_in_batch, shard_cost, shard);\n   }\n \n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_;\n };\n@@ -815,7 +815,7 @@ class MaxPoolingNoMaskOp : public OpKernel {\n  public:\n   explicit MaxPoolingNoMaskOp(OpKernelConstruction* context)\n       : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -866,8 +866,8 @@ class MaxPoolingNoMaskOp : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_;\n };\n@@ -877,7 +877,7 @@ class MaxPoolingNoMaskV2Op : public OpKernel {\n  public:\n   explicit MaxPoolingNoMaskV2Op(OpKernelConstruction* context)\n       : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -912,17 +912,17 @@ class MaxPoolingNoMaskV2Op : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& tensor_in = context->input(0);\n \n-    std::vector<int32> ksize = ksize_;\n-    std::vector<int32> stride = stride_;\n+    std::vector<int32_t> ksize = ksize_;\n+    std::vector<int32_t> stride = stride_;\n \n     if (context->num_inputs() != 1) {\n       const Tensor& tensor_ksize = context->input(1);\n-      auto value_ksize = tensor_ksize.flat<int32>();\n+      auto value_ksize = tensor_ksize.flat<int32_t>();\n       ksize.resize(tensor_ksize.shape().num_elements());\n       std::copy_n(&value_ksize(0), ksize.size(), ksize.begin());\n \n       const Tensor& tensor_stride = context->input(2);\n-      auto value_stride = tensor_stride.flat<int32>();\n+      auto value_stride = tensor_stride.flat<int32_t>();\n       stride.resize(tensor_stride.shape().num_elements());\n       std::copy_n(&value_stride(0), stride.size(), stride.begin());\n     }\n@@ -956,8 +956,8 @@ class MaxPoolingNoMaskV2Op : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_;\n };\n@@ -1036,8 +1036,8 @@ class MaxPoolingWithArgmaxOp : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   bool propagate_nans_;\n   bool include_batch_in_index_;\n@@ -1109,7 +1109,7 @@ class MaxPoolingGradWithArgmaxOp : public OpKernel {\n  public:\n   explicit MaxPoolingGradWithArgmaxOp(OpKernelConstruction* context)\n       : OpKernel(context) {\n-    string data_format_str;\n+    std::string data_format_str;\n     if (std::is_same<Device, GPUDevice>::value) {\n       OP_REQUIRES(context, !tensorflow::OpDeterminismRequired(),\n                   errors::Unimplemented(\"Determinism is not yet supported \"\n@@ -1187,8 +1187,8 @@ class MaxPoolingGradWithArgmaxOp : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_;\n   bool include_batch_in_index_;\n@@ -1257,8 +1257,8 @@ class MaxPoolingGradGradWithArgmaxOp : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   bool include_batch_in_index_;\n };"
        },
        {
            "sha": "d1185f0d5d7998139f3829e26f7a8ee7dfb93ccf",
            "filename": "tensorflow/core/kernels/merge_v2_checkpoints_op_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 6,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmerge_v2_checkpoints_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmerge_v2_checkpoints_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fmerge_v2_checkpoints_op_test.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -34,7 +34,8 @@ limitations under the License.\n namespace tensorflow {\n namespace {\n \n-void WriteCheckpoint(const string& prefix, absl::Span<const string> names,\n+void WriteCheckpoint(const std::string& prefix,\n+                     absl::Span<const std::string> names,\n                      absl::Span<const Tensor> tensors) {\n   BundleWriter writer(Env::Default(), prefix);\n   ASSERT_TRUE(names.size() == tensors.size());\n@@ -65,12 +66,12 @@ class MergeV2CheckpointsOpTest : public OpsTestBase {\n \n   void RunMergeTest(bool delete_old_dirs, bool allow_missing_files) {\n     // Writes two checkpoints.\n-    const std::vector<string> prefixes = {\n+    const std::vector<std::string> prefixes = {\n         io::JoinPath(testing::TmpDir(), \"worker0/ckpt0\"),\n         io::JoinPath(testing::TmpDir(), \"worker1/ckpt1\"),\n         io::JoinPath(testing::TmpDir(), \"merged/ckpt\") /* merged prefix */};\n     // In a different directory, to exercise \"delete_old_dirs\".\n-    const string& kMergedPrefix = prefixes[2];\n+    const std::string& kMergedPrefix = prefixes[2];\n \n     // Only write this particular checkpoint if we do not allow missing files.\n     if (!allow_missing_files) {\n@@ -123,9 +124,10 @@ class MergeV2CheckpointsOpTest : public OpsTestBase {\n     for (int i = 0; i < 2; ++i) {\n       // If we allow missing files, the first checkpoint file did not exist.\n       if (allow_missing_files && i == 0) continue;\n-      int directory_found = Env::Default()\n-                                ->IsDirectory(string(io::Dirname(prefixes[i])))\n-                                .raw_code();\n+      int directory_found =\n+          Env::Default()\n+              ->IsDirectory(std::string(io::Dirname(prefixes[i])))\n+              .raw_code();\n       if (delete_old_dirs) {\n         EXPECT_EQ(error::NOT_FOUND, directory_found);\n       } else {"
        },
        {
            "sha": "760781605239fbe96fcc7d3d00170ff6084913f0",
            "filename": "tensorflow/core/kernels/mfcc_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmfcc_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmfcc_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fmfcc_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -49,7 +49,7 @@ class MfccOp : public OpKernel {\n                 errors::InvalidArgument(\n                     \"Input sample_rate should be a scalar tensor, got \",\n                     sample_rate_tensor.shape().DebugString(), \" instead.\"));\n-    const int32_t sample_rate = sample_rate_tensor.scalar<int32>()();\n+    const int32_t sample_rate = sample_rate_tensor.scalar<int32_t>()();\n \n     const int spectrogram_channels = spectrogram.dim_size(2);\n     const int spectrogram_samples = spectrogram.dim_size(1);\n@@ -105,8 +105,8 @@ class MfccOp : public OpKernel {\n  private:\n   float upper_frequency_limit_;\n   float lower_frequency_limit_;\n-  int32 filterbank_channel_count_;\n-  int32 dct_coefficient_count_;\n+  int32_t filterbank_channel_count_;\n+  int32_t dct_coefficient_count_;\n };\n REGISTER_KERNEL_BUILDER(Name(\"Mfcc\").Device(DEVICE_CPU), MfccOp);\n "
        },
        {
            "sha": "e7ce0bddbd61199a47841df706fe32b7eba0b6ff",
            "filename": "tensorflow/core/kernels/multinomial_op_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmultinomial_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmultinomial_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fmultinomial_op_test.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -29,7 +29,7 @@ static Graph* Multinomial(int batch_size, int num_classes, int num_samples) {\n   Tensor logits_t(DT_FLOAT, TensorShape({batch_size, num_classes}));\n   Tensor num_samples_t(DT_INT32, TensorShape());\n   logits_t.flat<float>().setRandom();\n-  num_samples_t.scalar<int32>().setConstant(num_samples);\n+  num_samples_t.scalar<int32_t>().setConstant(num_samples);\n \n   Node* ret;\n   TF_CHECK_OK(NodeBuilder(g->NewName(\"multinomial\"), \"Multinomial\")"
        },
        {
            "sha": "61a745df498cdd20848e5bd7225add05b7f41a96",
            "filename": "tensorflow/core/kernels/mutex_ops.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmutex_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fmutex_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fmutex_ops.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -36,7 +36,7 @@ namespace {\n \n class Mutex : public ResourceBase {\n  public:\n-  explicit Mutex(OpKernelContext* c, const string& name)\n+  explicit Mutex(OpKernelContext* c, const std::string& name)\n       : locked_(false),\n         thread_pool_(new thread::ThreadPool(\n             c->env(), ThreadOptions(),\n@@ -46,7 +46,9 @@ class Mutex : public ResourceBase {\n     VLOG(2) << \"Creating mutex with name \" << name << \": \" << this;\n   }\n \n-  string DebugString() const override { return absl::StrCat(\"Mutex \", name_); }\n+  std::string DebugString() const override {\n+    return absl::StrCat(\"Mutex \", name_);\n+  }\n \n   class LockReleaser {\n    public:\n@@ -127,7 +129,7 @@ class Mutex : public ResourceBase {\n   condition_variable cv_ TF_GUARDED_BY(mu_);\n   bool locked_ TF_GUARDED_BY(mu_);\n   std::unique_ptr<thread::ThreadPool> thread_pool_;\n-  string name_;\n+  std::string name_;\n };\n \n }  // namespace"
        },
        {
            "sha": "dfaad0122c6e5707d483d6dba0166110b7d76b0d",
            "filename": "tensorflow/core/kernels/nn_ops_test.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 30,
            "changes": 63,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fnn_ops_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fnn_ops_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fnn_ops_test.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -57,8 +57,9 @@ limitations under the License.\n \n namespace tensorflow {\n \n-static void SetConstOp(const string& name, std::initializer_list<int64_t> dims,\n-                       DataType data_type, NodeDef* node) {\n+static void SetConstOp(const std::string& name,\n+                       std::initializer_list<int64_t> dims, DataType data_type,\n+                       NodeDef* node) {\n   Tensor tensor(data_type, TensorShape(dims));\n   for (int64_t i = 0; i < tensor.NumElements(); ++i) {\n     switch (data_type) {\n@@ -81,13 +82,13 @@ static void SetConstOp(const string& name, std::initializer_list<int64_t> dims,\n                   .Finalize(node));\n }\n \n-static void SetConstSizesOp(const string& name, const std::vector<int32>& sizes,\n-                            NodeDef* node) {\n+static void SetConstSizesOp(const std::string& name,\n+                            const std::vector<int32_t>& sizes, NodeDef* node) {\n   TensorShape shape;\n   shape.AddDim(sizes.size());\n   Tensor tensor(DT_INT32, shape);\n   for (int64_t i = 0; i < tensor.NumElements(); ++i) {\n-    tensor.flat<int32>()(i) = sizes[i];\n+    tensor.flat<int32_t>()(i) = sizes[i];\n   }\n   TF_CHECK_OK(NodeDefBuilder(name, \"Const\")\n                   .Attr(\"dtype\", DT_INT32)\n@@ -112,7 +113,7 @@ static void BM_ConvFloat(::testing::benchmark::State& state, int batch,\n                          int filter_rows, int filter_cols, CONV_OP op,\n                          int num_threads, int stride, Padding padding,\n                          bool use_gpu, DataType data_type,\n-                         const string& label) {\n+                         const std::string& label) {\n   if (!IsGoogleCudaEnabled() && use_gpu) {\n     state.SkipWithError(\n         absl::StrCat(\"Skipping GPU test (no --config=cuda): \", label));\n@@ -159,19 +160,19 @@ static void BM_ConvFloat(::testing::benchmark::State& state, int batch,\n   SetConstOp(\"output_backprop\", {batch, out_rows, out_cols, out_depth},\n              data_type, graph.add_node());\n   SetConstSizesOp(\"input_sizes\",\n-                  std::vector<int32>({batch, rows, cols, in_depth}),\n+                  std::vector<int32_t>({batch, rows, cols, in_depth}),\n                   graph.add_node());\n   SetConstSizesOp(\n       \"filter_sizes\",\n-      std::vector<int32>({filter_rows, filter_cols, in_depth, out_depth}),\n+      std::vector<int32_t>({filter_rows, filter_cols, in_depth, out_depth}),\n       graph.add_node());\n-  SetConstSizesOp(\"resize_size\", std::vector<int32>({rows, cols}),\n+  SetConstSizesOp(\"resize_size\", std::vector<int32_t>({rows, cols}),\n                   graph.add_node());\n \n   TensorShape paddings_shape({4, 2});\n   Tensor paddings_tensor(DT_INT32, paddings_shape);\n   for (int64_t i = 0; i < paddings_tensor.NumElements(); ++i) {\n-    paddings_tensor.flat<int32>()(i) = 0;\n+    paddings_tensor.flat<int32_t>()(i) = 0;\n   }\n   TF_CHECK_OK(NodeDefBuilder(\"paddings\", \"Const\")\n                   .Attr(\"dtype\", DT_INT32)\n@@ -234,7 +235,7 @@ static void BM_ConvFloat(::testing::benchmark::State& state, int batch,\n   GraphConstructorOptions opts;\n   TF_CHECK_OK(ConvertGraphDefToGraph(opts, graph, g));\n \n-  string device = use_gpu ? \"gpu\" : \"cpu\";\n+  std::string device = use_gpu ? \"gpu\" : \"cpu\";\n   test::Benchmark(device, g, &options, nullptr, nullptr, \"\",\n                   /*old_benchmark_api*/ false)\n       .Run(state);\n@@ -540,7 +541,7 @@ static void BM_ConvFloatDepthwise(::testing::benchmark::State& state, int batch,\n                                   int filter_rows, int filter_cols,\n                                   DEPTHWISE_CONV_OP op, int num_threads,\n                                   int stride, Padding padding, bool use_gpu,\n-                                  const string& label) {\n+                                  const std::string& label) {\n   if (!IsGoogleCudaEnabled() && use_gpu) {\n     state.SkipWithError(\n         absl::StrCat(\"Skipping GPU test (no --config=cuda): \", label));\n@@ -594,10 +595,10 @@ static void BM_ConvFloatDepthwise(::testing::benchmark::State& state, int batch,\n   SetConstOp(\"output_backprop\", {batch, out_rows, out_cols, out_depth}, dtype,\n              graph.add_node());\n   SetConstSizesOp(\"input_sizes\",\n-                  std::vector<int32>({batch, rows, cols, in_depth}),\n+                  std::vector<int32_t>({batch, rows, cols, in_depth}),\n                   graph.add_node());\n   SetConstSizesOp(\"filter_sizes\",\n-                  std::vector<int32>(\n+                  std::vector<int32_t>(\n                       {filter_rows, filter_cols, in_depth, depth_multiplier}),\n                   graph.add_node());\n \n@@ -637,7 +638,7 @@ static void BM_ConvFloatDepthwise(::testing::benchmark::State& state, int batch,\n   GraphConstructorOptions opts;\n   TF_CHECK_OK(ConvertGraphDefToGraph(opts, graph, g));\n \n-  string device = use_gpu ? \"gpu\" : \"cpu\";\n+  std::string device = use_gpu ? \"gpu\" : \"cpu\";\n   test::Benchmark(device, g, &options, nullptr, nullptr, \"\",\n                   /*old_benchmark_api=*/false)\n       .Run(state);\n@@ -788,7 +789,7 @@ BM_ConvFloatDepthwiseBk_All(bfloat16);\n \n static void BM_LRNFloat(::testing::benchmark::State& state, int depth, int cols,\n                         int rows, int batch_size, int range, int num_threads,\n-                        const string& label) {\n+                        const std::string& label) {\n   std::unique_ptr<Device> device(\n       DeviceFactory::NewDevice(\"CPU\", {}, \"/job:a/replica:0/task:0\"));\n \n@@ -869,7 +870,7 @@ AvgPooling Op\n static void BM_AvgPool(::testing::benchmark::State& state, int batch_size,\n                        int rows, int cols, int depth, int kernel_rows,\n                        int kernel_cols, int stride, Padding padding,\n-                       int num_threads, const string& label) {\n+                       int num_threads, const std::string& label) {\n   std::unique_ptr<Device> device(\n       DeviceFactory::NewDevice(\"CPU\", {}, \"/job:a/replica:0/task:0\"));\n \n@@ -960,7 +961,7 @@ BM_AvgPoolFwdCPU(32, 14, 14, 576, 3, 3, 2, SAME, 4, \"avgpool10_SAME\");\n static void BM_AvgPoolBk(::testing::benchmark::State& state, int batch_size,\n                          int rows, int cols, int depth, int kernel_rows,\n                          int kernel_cols, int stride, Padding padding,\n-                         int num_threads, const string& label) {\n+                         int num_threads, const std::string& label) {\n   std::unique_ptr<Device> device(\n       DeviceFactory::NewDevice(\"CPU\", {}, \"/job:a/replica:0/task:0\"));\n \n@@ -979,9 +980,9 @@ static void BM_AvgPoolBk(::testing::benchmark::State& state, int batch_size,\n   TensorShape output_shape({batch_size, out_height, out_width, depth});\n   TensorShape shape2({4});\n   Tensor input_shape_tensor(DT_INT32, shape2);\n-  int32 input_dims[] = {batch_size, rows, cols, depth};\n+  int32_t input_dims[] = {batch_size, rows, cols, depth};\n   for (int i = 0; i < 4; i++) {\n-    input_shape_tensor.flat<int32>()(i) = input_dims[i];\n+    input_shape_tensor.flat<int32_t>()(i) = input_dims[i];\n   }\n   inputs.push_back({nullptr, &input_shape_tensor});\n \n@@ -1063,7 +1064,7 @@ MaxPooling Op\n static void BM_MaxPool(::testing::benchmark::State& state, int batch_size,\n                        int rows, int cols, int depth, int kernel_rows,\n                        int kernel_cols, int stride, Padding padding,\n-                       int num_threads, const string& label) {\n+                       int num_threads, const std::string& label) {\n   SessionOptions options;\n   options.config.set_intra_op_parallelism_threads(num_threads);\n \n@@ -1158,7 +1159,8 @@ BM_MaxPoolFwdCPU(32, 14, 14, 576, 3, 3, 2, SAME, 4, \"maxpool10_SAME\");\n static void BM_MaxPoolBk(::testing::benchmark::State& state, int batch_size,\n                          int rows, int cols, int depth, int kernel_rows,\n                          int kernel_cols, int stride, Padding padding,\n-                         int num_threads, bool use_gpu, const string& label) {\n+                         int num_threads, bool use_gpu,\n+                         const std::string& label) {\n   if (!IsGoogleCudaEnabled() && use_gpu) {\n     state.SkipWithError(\n         absl::StrCat(\"Skipping GPU test (no --config=cuda): \", label));\n@@ -1192,7 +1194,7 @@ static void BM_MaxPoolBk(::testing::benchmark::State& state, int batch_size,\n   TF_CHECK_OK(root.status());\n   Graph* g = new Graph(OpRegistry::Global());\n   TF_CHECK_OK(root.ToGraph(g));\n-  string device = use_gpu ? \"gpu\" : \"cpu\";\n+  std::string device = use_gpu ? \"gpu\" : \"cpu\";\n   test::Benchmark(device, g, /*old_benchmark_api*/ false).Run(state);\n \n   state.SetItemsProcessed(batch_size * rows * cols * depth *\n@@ -1252,7 +1254,7 @@ Run benchmark with:\n */\n static void BM_ReluFloat(::testing::benchmark::State& state, int batch_size,\n                          int rows, int cols, int depth, int num_threads,\n-                         const string& label) {\n+                         const std::string& label) {\n   std::unique_ptr<Device> device(\n       DeviceFactory::NewDevice(\"CPU\", {}, \"/job:a/replica:0/task:0\"));\n \n@@ -1323,7 +1325,7 @@ Run benchmark with:\n */\n static void BM_SoftplusFloat(::testing::benchmark::State& state, int batch_size,\n                              int rows, int cols, int depth, int num_threads,\n-                             const string& label) {\n+                             const std::string& label) {\n   std::unique_ptr<Device> device(\n       DeviceFactory::NewDevice(\"CPU\", {}, \"/job:a/replica:0/task:0\"));\n \n@@ -1392,7 +1394,7 @@ BM_Softplus(32, 14, 14, 576, 4, \"softplus10\");\n static void BM_ImageNetSoftmaxFwd(::testing::benchmark::State& state,\n                                   int batch_size, int node_depth,\n                                   int num_threads, bool use_gpu,\n-                                  const string& label) {\n+                                  const std::string& label) {\n   if (!IsGoogleCudaEnabled() && use_gpu) {\n     state.SkipWithError(\n         absl::StrCat(\"Skipping GPU test (no --config=cuda): \", label));\n@@ -1409,7 +1411,7 @@ static void BM_ImageNetSoftmaxFwd(::testing::benchmark::State& state,\n   TF_CHECK_OK(root.status());\n   Graph* g = new Graph(OpRegistry::Global());\n   TF_CHECK_OK(root.ToGraph(g));\n-  string device = use_gpu ? \"gpu\" : \"cpu\";\n+  std::string device = use_gpu ? \"gpu\" : \"cpu\";\n   SessionOptions opts;\n   opts.config.set_inter_op_parallelism_threads(1);\n   opts.config.set_intra_op_parallelism_threads(num_threads);\n@@ -1444,7 +1446,8 @@ BM_ImageNetSoftmaxFwd(8192, 1024, 1, true, \"softmax32\");\n BM_ImageNetSoftmaxFwd(8192, 32768, 1, true, \"softmax128\");\n \n static void BM_TopK(::testing::benchmark::State& state, int rows, int cols,\n-                    int k, int num_threads, bool use_gpu, const string& label) {\n+                    int k, int num_threads, bool use_gpu,\n+                    const std::string& label) {\n   if (!IsGoogleCudaEnabled() && use_gpu) {\n     state.SkipWithError(\n         absl::StrCat(\"Skipping GPU test (no --config=cuda): \", label));\n@@ -1458,14 +1461,14 @@ static void BM_TopK(::testing::benchmark::State& state, int rows, int cols,\n   input.flat<float>().setRandom();\n \n   Tensor input_k(DT_INT32, TensorShape({}));\n-  input_k.scalar<int32>()() = k;\n+  input_k.scalar<int32_t>()() = k;\n \n   auto top_k = ops::TopK(root, input, input_k, ops::TopK::Sorted(true));\n \n   TF_CHECK_OK(root.status());\n   Graph* g = new Graph(OpRegistry::Global());\n   TF_CHECK_OK(root.ToGraph(g));\n-  string device = use_gpu ? \"gpu\" : \"cpu\";\n+  std::string device = use_gpu ? \"gpu\" : \"cpu\";\n   SessionOptions opts;\n   opts.config.set_inter_op_parallelism_threads(1);\n   opts.config.set_intra_op_parallelism_threads(num_threads);"
        },
        {
            "sha": "12db3b63d8cdad266d1675ea09ddf73a0bb3a5c8",
            "filename": "tensorflow/core/kernels/nth_element_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fnth_element_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fnth_element_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fnth_element_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -43,7 +43,7 @@ class NthElementOp : public OpKernel {\n     OP_REQUIRES(\n         context, TensorShapeUtils::IsScalar(n_in.shape()),\n         errors::InvalidArgument(\"N must be scalar but has rank \", n_in.dims()));\n-    int n = n_in.scalar<int32>()();\n+    int n = n_in.scalar<int32_t>()();\n     OP_REQUIRES(context, n >= 0,\n                 errors::InvalidArgument(\"n must be non-negative but is \", n));\n "
        },
        {
            "sha": "4a205ac3503f2e001e7afcd3422ae9aca4245940",
            "filename": "tensorflow/core/kernels/one_hot_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fone_hot_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fone_hot_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fone_hot_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -77,7 +77,7 @@ class OneHotOp : public OpKernel {\n     const int axis = (axis_ == -1) ? indices_dims : axis_;\n \n     // The one-hot dimension.\n-    const int32_t depth_v = depth.scalar<int32>()();\n+    const int32_t depth_v = depth.scalar<int32_t>()();\n     OP_REQUIRES(\n         ctx, depth_v >= 0,\n         errors::InvalidArgument(\"depth must be non-negative, got: \", depth_v));\n@@ -122,7 +122,7 @@ class OneHotOp : public OpKernel {\n   }\n \n  private:\n-  int32 axis_;\n+  int32_t axis_;\n \n   OneHotOp(const OneHotOp&) = delete;\n   void operator=(const OneHotOp&) = delete;"
        },
        {
            "sha": "ec0c6a1adcadf5960e406cf26c904237ccdc3856",
            "filename": "tensorflow/core/kernels/ops_testutil.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fops_testutil.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fops_testutil.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fops_testutil.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -176,7 +176,7 @@ void OpsTestBase::CreateContext() {\n   params_->frame_iter = FrameAndIter(0, 0);\n   params_->inputs = inputs_;\n   params_->op_kernel = kernel_.get();\n-  step_container_.reset(new ScopedStepContainer(0, [](const string&) {}));\n+  step_container_.reset(new ScopedStepContainer(0, [](const std::string&) {}));\n   params_->step_container = step_container_.get();\n   test::SetOutputAttrs(params_.get(), &out_alloc_attrs_);\n   params_->slice_reader_cache = &slice_reader_cache_wrapper_;"
        },
        {
            "sha": "da2ccad9cbba72b9e3ad9e8b3b36cfa988ceda3c",
            "filename": "tensorflow/core/kernels/ops_testutil.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fops_testutil.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fops_testutil.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fops_testutil.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -119,7 +119,7 @@ class OpsTestBase : public ::testing::Test {\n   // Adds a Resource type as input. If <container> is empty, uses the default\n   // container name.\n   template <typename T>\n-  void AddResourceInput(const string& container, const string& name,\n+  void AddResourceInput(const std::string& container, const std::string& name,\n                         T* resource) {\n     CHECK_GT(input_types_.size(), inputs_.size())\n         << \"Adding more inputs than types; perhaps you need to call MakeOp\";"
        },
        {
            "sha": "bd9a07006a88706809950953eb4dd74e5f2ddf2a",
            "filename": "tensorflow/core/kernels/padding_fifo_queue.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpadding_fifo_queue.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpadding_fifo_queue.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpadding_fifo_queue.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -36,7 +36,8 @@ namespace tensorflow {\n \n PaddingFIFOQueue::PaddingFIFOQueue(\n     int capacity, const DataTypeVector& component_dtypes,\n-    const std::vector<PartialTensorShape>& component_shapes, const string& name)\n+    const std::vector<PartialTensorShape>& component_shapes,\n+    const std::string& name)\n     : FIFOQueue(capacity, component_dtypes,\n                 ConvertShapesPartialDimensionsToZero(component_shapes), name),\n       partial_shapes_(component_shapes) {}"
        },
        {
            "sha": "f05862ff9b3bddce2f75d845a2d394be927cf16d",
            "filename": "tensorflow/core/kernels/padding_fifo_queue.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpadding_fifo_queue.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpadding_fifo_queue.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpadding_fifo_queue.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -36,7 +36,7 @@ class PaddingFIFOQueue : public FIFOQueue {\n  public:\n   PaddingFIFOQueue(int32_t capacity, const DataTypeVector& component_dtypes,\n                    const std::vector<PartialTensorShape>& component_shapes,\n-                   const string& name);\n+                   const std::string& name);\n \n   absl::Status Initialize() override;\n "
        },
        {
            "sha": "66ec30bc4a213699bfc44c511ee4d6ed714a0dd5",
            "filename": "tensorflow/core/kernels/parameterized_truncated_normal_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fparameterized_truncated_normal_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fparameterized_truncated_normal_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fparameterized_truncated_normal_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -777,8 +777,8 @@ class StatelessParameterizedTruncatedNormal : public OpKernel {\n                                 shape_tensor.shape().DebugString()));\n     TensorShape output_shape;\n     if (shape_tensor.dtype() == DataType::DT_INT32) {\n-      OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(shape_tensor.vec<int32>(),\n-                                                      &output_shape));\n+      OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(\n+                              shape_tensor.vec<int32_t>(), &output_shape));\n     } else {\n       OP_REQUIRES_OK(ctx, TensorShapeUtils::MakeShape(\n                               shape_tensor.vec<int64_t>(), &output_shape));"
        },
        {
            "sha": "1257b8da742ce2b875ec89c74cf09b8f89963100",
            "filename": "tensorflow/core/kernels/parameterized_truncated_normal_op_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fparameterized_truncated_normal_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fparameterized_truncated_normal_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fparameterized_truncated_normal_op_test.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -27,7 +27,7 @@ namespace tensorflow {\n static Graph* PTruncatedNormal(int num_batches, int samples_per_batch) {\n   Graph* g = new Graph(OpRegistry::Global());\n   Tensor shape_t(DT_INT32, TensorShape({2}));\n-  shape_t.flat<int32>().setValues({num_batches, samples_per_batch});\n+  shape_t.flat<int32_t>().setValues({num_batches, samples_per_batch});\n \n   // Use mean 0 and stdev 1\n   Tensor means_t(DT_FLOAT, TensorShape({num_batches}));\n@@ -56,7 +56,7 @@ static Graph* PTruncatedNormal(int num_batches, int samples_per_batch) {\n static Graph* PTruncatedNormal2SD(int num_batches, int samples_per_batch) {\n   Graph* g = new Graph(OpRegistry::Global());\n   Tensor shape_t(DT_INT32, TensorShape({2}));\n-  shape_t.flat<int32>().setValues({num_batches, samples_per_batch});\n+  shape_t.flat<int32_t>().setValues({num_batches, samples_per_batch});\n \n   Tensor means_t(DT_FLOAT, TensorShape({num_batches}));\n   means_t.flat<float>().setConstant(0.0);\n@@ -83,7 +83,7 @@ static Graph* PTruncatedNormal2SD(int num_batches, int samples_per_batch) {\n static Graph* PTruncatedNormalOneTail(int num_batches, int samples_per_batch) {\n   Graph* g = new Graph(OpRegistry::Global());\n   Tensor shape_t(DT_INT32, TensorShape({2}));\n-  shape_t.flat<int32>().setValues({num_batches, samples_per_batch});\n+  shape_t.flat<int32_t>().setValues({num_batches, samples_per_batch});\n \n   Tensor means_t(DT_FLOAT, TensorShape({num_batches}));\n   means_t.flat<float>().setConstant(0.0);"
        },
        {
            "sha": "d5a40489b64fd32671b82c185fd0da8294973200",
            "filename": "tensorflow/core/kernels/parse_tensor_test.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 22,
            "changes": 47,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fparse_tensor_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fparse_tensor_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fparse_tensor_test.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -106,57 +106,60 @@ TEST_F(SerializeTensorOpTest, SerializeTensorOpTest_double) {\n }\n \n TEST_F(SerializeTensorOpTest, SerializeTensorOpTest_int64) {\n-  MakeOp<int64_t>(TensorShape({2, 3, 4}),\n-                  [](int x) -> int64 { return static_cast<int64_t>(x - 10); });\n+  MakeOp<int64_t>(TensorShape({2, 3, 4}), [](int x) -> int64_t {\n+    return static_cast<int64_t>(x - 10);\n+  });\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor parse_output;\n   ParseSerializedOutput<int64_t>(GetOutput(0), &parse_output);\n   test::ExpectTensorEqual<int64_t>(parse_output, GetInput(0));\n }\n \n TEST_F(SerializeTensorOpTest, SerializeTensorOpTest_int32) {\n-  MakeOp<int32>(TensorShape({4, 2}),\n-                [](int x) -> int32 { return static_cast<int32>(x + 7); });\n+  MakeOp<int32_t>(TensorShape({4, 2}),\n+                  [](int x) -> int32_t { return static_cast<int32_t>(x + 7); });\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor parse_output;\n-  ParseSerializedOutput<int32>(GetOutput(0), &parse_output);\n-  test::ExpectTensorEqual<int32>(parse_output, GetInput(0));\n+  ParseSerializedOutput<int32_t>(GetOutput(0), &parse_output);\n+  test::ExpectTensorEqual<int32_t>(parse_output, GetInput(0));\n }\n \n TEST_F(SerializeTensorOpTest, SerializeTensorOpTest_int16) {\n-  MakeOp<int16>(TensorShape({8}),\n-                [](int x) -> int16 { return static_cast<int16>(x + 18); });\n+  MakeOp<int16_t>(TensorShape({8}), [](int x) -> int16_t {\n+    return static_cast<int16_t>(x + 18);\n+  });\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor parse_output;\n-  ParseSerializedOutput<int16>(GetOutput(0), &parse_output);\n-  test::ExpectTensorEqual<int16>(parse_output, GetInput(0));\n+  ParseSerializedOutput<int16_t>(GetOutput(0), &parse_output);\n+  test::ExpectTensorEqual<int16_t>(parse_output, GetInput(0));\n }\n \n TEST_F(SerializeTensorOpTest, SerializeTensorOpTest_int8) {\n-  MakeOp<int8>(TensorShape({2}),\n-               [](int x) -> int8 { return static_cast<int8>(x + 8); });\n+  MakeOp<int8_t>(TensorShape({2}),\n+                 [](int x) -> int8_t { return static_cast<int8_t>(x + 8); });\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor parse_output;\n-  ParseSerializedOutput<int8>(GetOutput(0), &parse_output);\n-  test::ExpectTensorEqual<int8>(parse_output, GetInput(0));\n+  ParseSerializedOutput<int8_t>(GetOutput(0), &parse_output);\n+  test::ExpectTensorEqual<int8_t>(parse_output, GetInput(0));\n }\n \n TEST_F(SerializeTensorOpTest, SerializeTensorOpTest_uint16) {\n-  MakeOp<uint16>(TensorShape({1, 3}),\n-                 [](int x) -> uint16 { return static_cast<uint16>(x + 2); });\n+  MakeOp<uint16_t>(TensorShape({1, 3}), [](int x) -> uint16_t {\n+    return static_cast<uint16_t>(x + 2);\n+  });\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor parse_output;\n-  ParseSerializedOutput<uint16>(GetOutput(0), &parse_output);\n-  test::ExpectTensorEqual<uint16>(parse_output, GetInput(0));\n+  ParseSerializedOutput<uint16_t>(GetOutput(0), &parse_output);\n+  test::ExpectTensorEqual<uint16_t>(parse_output, GetInput(0));\n }\n \n TEST_F(SerializeTensorOpTest, SerializeTensorOpTest_uint8) {\n-  MakeOp<uint8>(TensorShape({2, 1, 1}),\n-                [](int x) -> uint8 { return static_cast<uint8>(x + 1); });\n+  MakeOp<uint8_t>(TensorShape({2, 1, 1}),\n+                  [](int x) -> uint8_t { return static_cast<uint8_t>(x + 1); });\n   TF_ASSERT_OK(RunOpKernel());\n   Tensor parse_output;\n-  ParseSerializedOutput<uint8>(GetOutput(0), &parse_output);\n-  test::ExpectTensorEqual<uint8>(parse_output, GetInput(0));\n+  ParseSerializedOutput<uint8_t>(GetOutput(0), &parse_output);\n+  test::ExpectTensorEqual<uint8_t>(parse_output, GetInput(0));\n }\n \n TEST_F(SerializeTensorOpTest, SerializeTensorOpTest_complex64) {"
        },
        {
            "sha": "bbff2dc35654ad11303627032241dad2f3e763a1",
            "filename": "tensorflow/core/kernels/partitioned_function_ops.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpartitioned_function_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpartitioned_function_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpartitioned_function_ops.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -43,9 +43,9 @@ PartitionedCallOp::PartitionedCallOp(OpKernelConstruction* ctx)\n       shared_rendezvous_(false) {\n   OP_REQUIRES_OK(\n       ctx, ctx->GetAttr(FunctionLibraryDefinition::kFuncAttr, func_.get()));\n-  string deprecated_config_serialized;\n+  std::string deprecated_config_serialized;\n   OP_REQUIRES_OK(ctx, ctx->GetAttr(\"config\", &deprecated_config_serialized));\n-  string config_proto_serialized;\n+  std::string config_proto_serialized;\n   OP_REQUIRES_OK(ctx, ctx->GetAttr(\"config_proto\", &config_proto_serialized));\n   OP_REQUIRES(\n       ctx,\n@@ -232,7 +232,7 @@ void PartitionedCallOp::RunFunction(FunctionLibraryRuntime::Handle handle,\n   FunctionLibraryRuntime::Options run_opts;\n   ResourceMgr* resource_mgr = lib->device()->resource_manager();\n   ScopedStepContainer* step_container = new ScopedStepContainer(\n-      run_opts.step_id, [resource_mgr](const string& name) {\n+      run_opts.step_id, [resource_mgr](const std::string& name) {\n         resource_mgr->Cleanup(name).IgnoreError();\n       });\n   run_opts.step_container = step_container;\n@@ -251,13 +251,13 @@ void PartitionedCallOp::RunFunction(FunctionLibraryRuntime::Handle handle,\n   }\n \n   std::vector<Tensor>* rets = new std::vector<Tensor>;\n-  const string& func_name = func_->name();\n+  const std::string& func_name = func_->name();\n   tsl::profiler::TraceMe trace_me(\"PartitionedCallOp\");\n   lib->Run(run_opts, handle, inputs, rets,\n            [rets, done = std::move(done), ctx, func_name,\n             step_container](const absl::Status& status) {\n              if (!status.ok()) {\n-               const string function_and_msg =\n+               const std::string function_and_msg =\n                    absl::StrCat(errors::FormatFunctionForError(func_name), \" \",\n                                 status.message());\n                ctx->SetStatus("
        },
        {
            "sha": "f38ad56e8a9f737e8772f2bbf8b667f670ff2a32",
            "filename": "tensorflow/core/kernels/partitioned_function_ops.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpartitioned_function_ops.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpartitioned_function_ops.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpartitioned_function_ops.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -57,7 +57,7 @@ class PartitionedCallOp : public AsyncOpKernel {\n   // Using unique pointers to avoid including proto headers in kernel headers\n   std::unique_ptr<NameAttrList> func_;\n   std::unique_ptr<ConfigProto> config_proto_;\n-  string executor_type_;\n+  std::string executor_type_;\n   bool shared_rendezvous_;\n   mutex mu_;\n   // Cache the handle per FLR because this kernel may be instantiated for"
        },
        {
            "sha": "42e00c52a8c814eda7833d7d408c2c361ccccd3a",
            "filename": "tensorflow/core/kernels/pooling_ops_3d.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 29,
            "changes": 58,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -46,8 +46,8 @@ typedef Eigen::ThreadPoolDevice CPUDevice;\n typedef Eigen::GpuDevice GPUDevice;\n \n Pool3dParameters::Pool3dParameters(OpKernelContext* context,\n-                                   const std::vector<int32>& ksize,\n-                                   const std::vector<int32>& stride,\n+                                   const std::vector<int32_t>& ksize,\n+                                   const std::vector<int32_t>& stride,\n                                    Padding padding, TensorFormat data_format,\n                                    const TensorShape& tensor_in_shape) {\n   // For maxpooling, tensor_in should have 4 dimensions.\n@@ -97,9 +97,9 @@ absl::Status Pool3dParameters::forward_output_shape(TensorShape* shape) {\n template <typename T>\n struct LaunchPoolingOp<CPUDevice, T, AVG> {\n   static void launch(OpKernelContext* context, const Tensor& tensor_in,\n-                     const std::array<int64, 3>& window,\n-                     const std::array<int64, 3>& stride,\n-                     const std::array<int64, 3>& padding,\n+                     const std::array<int64_t, 3>& window,\n+                     const std::array<int64_t, 3>& stride,\n+                     const std::array<int64_t, 3>& padding,\n                      TensorFormat data_format, Padding padding_type,\n                      Tensor* output) {\n     output->tensor<T, 5>().device(context->eigen_device<CPUDevice>()) =\n@@ -112,9 +112,9 @@ struct LaunchPoolingOp<CPUDevice, T, AVG> {\n template <typename T>\n struct LaunchPoolingOp<CPUDevice, T, MAX> {\n   static void launch(OpKernelContext* context, const Tensor& tensor_in,\n-                     const std::array<int64, 3>& window,\n-                     const std::array<int64, 3>& stride,\n-                     const std::array<int64, 3>& padding,\n+                     const std::array<int64_t, 3>& window,\n+                     const std::array<int64_t, 3>& stride,\n+                     const std::array<int64_t, 3>& padding,\n                      TensorFormat data_format, Padding padding_type,\n                      Tensor* output) {\n     output->tensor<T, 5>().device(context->eigen_device<CPUDevice>()) =\n@@ -128,7 +128,7 @@ template <typename Device, typename T, PoolingType Type>\n class Pooling3DOp : public UnaryOp<T> {\n  public:\n   explicit Pooling3DOp(OpKernelConstruction* context) : UnaryOp<T>(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -204,8 +204,8 @@ class Pooling3DOp : public UnaryOp<T> {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_;\n };\n@@ -214,10 +214,10 @@ template <typename T>\n struct LaunchMaxPooling3dGradOp<CPUDevice, T> {\n   static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                      const Tensor& tensor_out, const Tensor& out_backprop,\n-                     const std::array<int64, 3>& window,\n-                     const std::array<int64, 3>& stride,\n-                     const std::array<int64, 3>& out,\n-                     const std::array<int64, 3>& padding,\n+                     const std::array<int64_t, 3>& window,\n+                     const std::array<int64_t, 3>& stride,\n+                     const std::array<int64_t, 3>& out,\n+                     const std::array<int64_t, 3>& padding,\n                      TensorFormat data_format, Tensor* output) {\n     output->flat<T>().setZero();\n     for (int64_t p = 0; p < out_backprop.dim_size(3); ++p) {\n@@ -307,7 +307,7 @@ class MaxPooling3dGradOp : public OpKernel {\n  public:\n   explicit MaxPooling3dGradOp(OpKernelConstruction* context)\n       : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -391,8 +391,8 @@ class MaxPooling3dGradOp : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_;\n };\n@@ -402,10 +402,10 @@ struct LaunchAvgPooling3dGradOp<CPUDevice, T> {\n   static void launch(OpKernelContext* context,\n                      const TensorShape& tensor_in_shape,\n                      const Tensor& out_backprop,\n-                     const std::array<int64, 3>& window,\n-                     const std::array<int64, 3>& stride,\n-                     const std::array<int64, 3>& output_shape,\n-                     const std::array<int64, 3>& padding,\n+                     const std::array<int64_t, 3>& window,\n+                     const std::array<int64_t, 3>& stride,\n+                     const std::array<int64_t, 3>& output_shape,\n+                     const std::array<int64_t, 3>& padding,\n                      TensorFormat data_format, Tensor* output) {\n     OP_REQUIRES(\n         context, tensor_in_shape.dim_size(0) == out_backprop.dim_size(0),\n@@ -487,7 +487,7 @@ class AvgPooling3dGradOp : public OpKernel {\n  public:\n   explicit AvgPooling3dGradOp(OpKernelConstruction* context)\n       : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -536,7 +536,7 @@ class AvgPooling3dGradOp : public OpKernel {\n                 errors::InvalidArgument(\"out_backprop must be 5-dimensional\"));\n \n     TensorShape output_shape;\n-    auto shape_vec = tensor_in_shape.vec<int32>();\n+    auto shape_vec = tensor_in_shape.vec<int32_t>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n       OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n@@ -568,8 +568,8 @@ class AvgPooling3dGradOp : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_;\n };\n@@ -693,7 +693,7 @@ class MaxPooling3dGradGradOp : public OpKernel {\n  public:\n   explicit MaxPooling3dGradGradOp(OpKernelConstruction* context)\n       : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -779,8 +779,8 @@ class MaxPooling3dGradGradOp : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_;\n };"
        },
        {
            "sha": "edc59f89f760bbb6ce9b9182b64c8722322eb0fd",
            "filename": "tensorflow/core/kernels/pooling_ops_3d.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -39,8 +39,8 @@ struct LaunchMaxPooling3dGradGradOp;\n // A helper class to manage sizes and shapes for 3d pooling operations.\n struct Pool3dParameters {\n   // Updates context->status if there is an invalid input.\n-  Pool3dParameters(OpKernelContext* context, const std::vector<int32>& ksize,\n-                   const std::vector<int32>& stride, Padding padding,\n+  Pool3dParameters(OpKernelContext* context, const std::vector<int32_t>& ksize,\n+                   const std::vector<int32_t>& stride, Padding padding,\n                    TensorFormat data_format,\n                    const TensorShape& tensor_in_shape);\n "
        },
        {
            "sha": "ac0cd5df525b90378bf6a0e440e2cc89450c9d73",
            "filename": "tensorflow/core/kernels/pooling_ops_common.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -49,7 +49,7 @@ struct RawType {\n \n template <>\n struct RawType<qint8> {\n-  using type = int8;\n+  using type = int8_t;\n };\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n@@ -117,8 +117,8 @@ absl::Status CheckPaddingSize(int64_t window_rows, int64_t window_cols,\n }\n \n PoolParameters::PoolParameters(OpKernelContext* context,\n-                               const std::vector<int32>& ksize,\n-                               const std::vector<int32>& stride,\n+                               const std::vector<int32_t>& ksize,\n+                               const std::vector<int32_t>& stride,\n                                Padding padding,\n                                std::vector<int64_t> explicit_paddings,\n                                TensorFormat data_format,"
        },
        {
            "sha": "71cddc32bbb3c5b419a6eb69fb463749e4b86cfd",
            "filename": "tensorflow/core/kernels/pooling_ops_common.h",
            "status": "modified",
            "additions": 12,
            "deletions": 12,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -47,8 +47,8 @@ struct PoolParameters {\n   // Updates context->status if there is an invalid input.\n   // explicit_paddings has eight elements if padding==EXPLIICT, and zero\n   // elements otherwise.\n-  PoolParameters(OpKernelContext* context, const std::vector<int32>& ksize,\n-                 const std::vector<int32>& stride, Padding padding,\n+  PoolParameters(OpKernelContext* context, const std::vector<int32_t>& ksize,\n+                 const std::vector<int32_t>& stride, Padding padding,\n                  std::vector<int64_t> explicit_paddings,\n                  TensorFormat data_format, const TensorShape& tensor_in_shape);\n \n@@ -90,7 +90,7 @@ template <typename Device, typename T>\n class MaxPoolingOp : public OpKernel {\n  public:\n   explicit MaxPoolingOp(OpKernelConstruction* context) : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     auto status = context->GetAttr(\"data_format\", &data_format);\n     if (status.ok()) {\n       OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n@@ -297,8 +297,8 @@ class MaxPoolingOp : public OpKernel {\n     }\n   }\n \n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   std::vector<int64_t> explicit_paddings_;\n   TensorFormat data_format_;\n@@ -338,7 +338,7 @@ template <typename Device, typename T>\n class MaxPoolingV2Op : public OpKernel {\n  public:\n   explicit MaxPoolingV2Op(OpKernelConstruction* context) : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     auto status = context->GetAttr(\"data_format\", &data_format);\n     if (status.ok()) {\n       OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n@@ -375,17 +375,17 @@ class MaxPoolingV2Op : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& tensor_in = context->input(0);\n \n-    std::vector<int32> ksize = ksize_;\n-    std::vector<int32> stride = stride_;\n+    std::vector<int32_t> ksize = ksize_;\n+    std::vector<int32_t> stride = stride_;\n \n     if (context->num_inputs() != 1) {\n       const Tensor& tensor_ksize = context->input(1);\n-      auto value_ksize = tensor_ksize.flat<int32>();\n+      auto value_ksize = tensor_ksize.flat<int32_t>();\n       ksize.resize(tensor_ksize.shape().num_elements());\n       std::copy_n(&value_ksize(0), ksize.size(), ksize.begin());\n \n       const Tensor& tensor_stride = context->input(2);\n-      auto value_stride = tensor_stride.flat<int32>();\n+      auto value_stride = tensor_stride.flat<int32_t>();\n       stride.resize(tensor_stride.shape().num_elements());\n       std::copy_n(&value_stride(0), stride.size(), stride.begin());\n     }\n@@ -572,8 +572,8 @@ class MaxPoolingV2Op : public OpKernel {\n     }\n   }\n \n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_;\n };"
        },
        {
            "sha": "c43415982f257ae9a9c27731e3a4ed7379b4bf71",
            "filename": "tensorflow/core/kernels/population_count_op.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 10,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpopulation_count_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpopulation_count_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpopulation_count_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -49,7 +49,7 @@ class PopulationCountOp : public OpKernel {\n     OP_REQUIRES_OK(c, c->allocate_output(0, input_t.shape(), &output_t));\n \n     auto input = input_t.flat<T>();\n-    auto output = output_t->flat<uint8>();\n+    auto output = output_t->flat<uint8_t>();\n \n     functor::PopulationCount<Device, T> popcnt;\n     popcnt(c, input, output);\n@@ -77,7 +77,7 @@ namespace functor {\n namespace {\n \n template <typename T>\n-inline uint8 PopCnt(const T v);\n+inline uint8_t PopCnt(const T v);\n \n #define POPCNT(T, N)                  \\\n   template <>                         \\\n@@ -86,13 +86,13 @@ inline uint8 PopCnt(const T v);\n   }\n \n POPCNT(int8_t, 8);\n-POPCNT(uint8, 8);\n+POPCNT(uint8_t, 8);\n POPCNT(int16_t, 16);\n-POPCNT(uint16, 16);\n+POPCNT(uint16_t, 16);\n POPCNT(int32_t, 32);\n-POPCNT(uint32, 32);\n+POPCNT(uint32_t, 32);\n POPCNT(int64_t, 64);\n-POPCNT(uint64, 64);\n+POPCNT(uint64_t, 64);\n \n #undef POPCNT\n \n@@ -101,9 +101,9 @@ POPCNT(uint64, 64);\n template <typename T>\n struct PopulationCount<CPUDevice, T> {\n   void operator()(OpKernelContext* c, typename TTypes<T>::ConstFlat input,\n-                  TTypes<uint8>::Flat output) {\n+                  TTypes<uint8_t>::Flat output) {\n     const T* input_ptr = input.data();\n-    uint8* output_ptr = output.data();\n+    uint8_t* output_ptr = output.data();\n     auto shard = [input_ptr, output_ptr](int64_t start, int64_t limit) {\n       for (int64_t i = start; i < limit; ++i) {\n         output_ptr[i] = PopCnt<T>(input_ptr[i]);\n@@ -113,8 +113,9 @@ struct PopulationCount<CPUDevice, T> {\n     // Approximating cost of popcnt: convert T to int64\n     // (std::bitset constructor) and convert int64 to uint8\n     // (bitset.count() -> output).  The .count() itself is relatively cheap.\n-    const double total_cost = (Eigen::TensorOpCost::CastCost<T, uint8>() +\n-                               Eigen::TensorOpCost::CastCost<int64_t, uint8>());\n+    const double total_cost =\n+        (Eigen::TensorOpCost::CastCost<T, uint8_t>() +\n+         Eigen::TensorOpCost::CastCost<int64_t, uint8_t>());\n     const int64_t shard_cost =\n         (total_cost >= static_cast<double>(std::numeric_limits<int64_t>::max()))\n             ? std::numeric_limits<int64_t>::max()"
        },
        {
            "sha": "b9811e59c3ea38e9306fed19a1217110ac47b77f",
            "filename": "tensorflow/core/kernels/population_count_op.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpopulation_count_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpopulation_count_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpopulation_count_op.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -28,7 +28,7 @@ namespace functor {\n template <typename Device, typename T>\n struct PopulationCount {\n   void operator()(OpKernelContext* c, typename TTypes<T>::ConstFlat input,\n-                  TTypes<uint8>::Flat output);\n+                  TTypes<uint8_t>::Flat output);\n };\n \n }  // namespace functor"
        },
        {
            "sha": "490cc338ddb99c98f02487f94416ede86dda7005",
            "filename": "tensorflow/core/kernels/priority_queue.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpriority_queue.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpriority_queue.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpriority_queue.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -37,7 +37,7 @@ namespace tensorflow {\n PriorityQueue::PriorityQueue(int32_t capacity,\n                              const DataTypeVector& component_dtypes,\n                              const std::vector<TensorShape>& component_shapes,\n-                             const string& name)\n+                             const std::string& name)\n     : TypedQueue(capacity, component_dtypes, component_shapes, name) {}\n \n absl::Status PriorityQueue::Initialize() {"
        },
        {
            "sha": "464083007786732952407d1fe82e0ea185d1c335",
            "filename": "tensorflow/core/kernels/priority_queue.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpriority_queue.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fpriority_queue.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpriority_queue.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -50,7 +50,7 @@ class PriorityQueue\n  public:\n   PriorityQueue(int32_t capacity, const DataTypeVector& component_dtypes,\n                 const std::vector<TensorShape>& component_shapes,\n-                const string& name);\n+                const std::string& name);\n \n   absl::Status Initialize()\n       override;  // Must be called before any other method.\n@@ -69,7 +69,7 @@ class PriorityQueue\n   absl::Status MatchesPriorityNodeDefTypes(const NodeDef& node_def) const;\n   absl::Status MatchesPriorityNodeDefShapes(const NodeDef& node_def) const;\n \n-  int32 size() const override {\n+  int32_t size() const override {\n     mutex_lock lock(mu_);\n     return queues_[0].size();\n   }"
        },
        {
            "sha": "f10b5e823d4143c1beebe3f4d2531c310f9fd07b",
            "filename": "tensorflow/core/kernels/quantization_utils.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fquantization_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fquantization_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fquantization_utils.h?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -84,7 +84,7 @@ T FloatToQuantized(float input, float range_min, float range_max) {\n       static_cast<int64_t>(Eigen::NumTraits<T>::highest());\n   quantized = std::max(quantized, lowest_quantized);\n   quantized = std::min(quantized, highest_quantized);\n-  return static_cast<T>(static_cast<int32>(quantized));\n+  return static_cast<T>(static_cast<int32_t>(quantized));\n }\n \n template <class T>\n@@ -284,7 +284,7 @@ inline void RequantizeManyInNewRangeReference(const qint32* input,\n     int64_t quantized_int64 = round_intermediate >> fp_shift;\n     quantized_int64 = std::max(quantized_int64, int64_t{0});\n     quantized_int64 = std::min(quantized_int64, int64_t{255});\n-    output[index] = static_cast<quint8>(static_cast<int32>(quantized_int64));\n+    output[index] = static_cast<quint8>(static_cast<int32_t>(quantized_int64));\n   }\n }\n \n@@ -310,7 +310,7 @@ inline void RequantizeManyInNewRange8To32BitReference(\n     int64_t output_value = code_0_int64 + (input_value * mult_int32);\n     output_value = std::max(output_value, lowest_quantized);\n     output_value = std::min(output_value, highest_quantized);\n-    output[i] = static_cast<int32>(output_value);\n+    output[i] = static_cast<int32_t>(output_value);\n   }\n }\n \n@@ -725,7 +725,7 @@ inline void RequantizeManyInNewRangeUsingEigen<qint32, quint8>(\n   auto intermediate = fp_value.unaryExpr(int64_right_shift_op<fp_shift>());\n   auto input_requantized = intermediate.cwiseMax(int64_t{0})\n                                .cwiseMin(int64_t{255})\n-                               .template cast<int32>()\n+                               .template cast<int32_t>()\n                                .template cast<quint8>();\n   output->flat<quint8>().device(device) = input_requantized;\n }"
        },
        {
            "sha": "6c0251b72494845ce85715fa1525f7d165ffb126",
            "filename": "tensorflow/core/kernels/quantization_utils_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fquantization_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fquantization_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fquantization_utils_test.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -60,7 +60,7 @@ void TestRequantizeMany(Eigen::ThreadPoolDevice* eigen_device, float input_min,\n         &o_tensor);\n   }\n \n-  const string tolerance_str = absl::StrCat(\"+-\", tolerance);\n+  const std::string tolerance_str = absl::StrCat(\"+-\", tolerance);\n   for (size_t value_index = 0; value_index < values_count; ++value_index) {\n     int e = expected_values[value_index];\n     int v = output_values(value_index);\n@@ -96,7 +96,7 @@ void TestRequantizeMany8To32Bit(float input_min, float input_max,\n                            input_max, output_min, output_max,\n                            output_values.data());\n \n-  const string tolerance_str = absl::StrCat(\"+-\", tolerance);\n+  const std::string tolerance_str = absl::StrCat(\"+-\", tolerance);\n   for (int value_index = 0; value_index < values_count; ++value_index) {\n     const qint32 e = expected_values[value_index];\n     const qint32 v = output_values(value_index);\n@@ -143,7 +143,7 @@ void TestRequantizeManyInNewRange32To8Bit(\n     qint32 high = Eigen::NumTraits<qint32>::highest();\n     std::vector<qint32> vals{low, high};\n     int num_steps = 14419;\n-    qint32 step = static_cast<int32>((1LL << 32) / num_steps);\n+    qint32 step = static_cast<int32_t>((1LL << 32) / num_steps);\n     qint32 v = low + static_cast<qint32>(1);\n     for (int i = 0; i < num_steps; ++i) {\n       vals.push_back(v);\n@@ -405,7 +405,7 @@ void TestQuantizedToFloatInPlaceUsingEigen(\n         input_array(i) = Eigen::NumTraits<T>::lowest() + i;\n       } else {\n         int64_t offset = static_cast<int64_t>(q_range / values_count * i);\n-        input_array(i) = static_cast<int32>(\n+        input_array(i) = static_cast<int32_t>(\n             std::min<int64_t>(Eigen::NumTraits<T>::lowest() + offset,\n                               Eigen::NumTraits<T>::highest()));\n       }\n@@ -662,8 +662,8 @@ void TestOverflowWithEigen() {\n   // because the implementation does a bounds check using float, not int32.\n   test::FillValues<qint32>(\n       &expected,\n-      {static_cast<int32>(-2147483648), static_cast<int32>(-2147483648),\n-       static_cast<int32>(2147483520), static_cast<int32>(2147483520)});\n+      {static_cast<int32_t>(-2147483648), static_cast<int32_t>(-2147483648),\n+       static_cast<int32_t>(2147483520), static_cast<int32_t>(2147483520)});\n \n   FloatToQuantizedStruct<qint32> f2q(input_min, input_max);\n   Tensor output(DT_QINT32, shape);"
        },
        {
            "sha": "64e7ec09c46eed2c8d61f2baa3ba46fbad1e9502",
            "filename": "tensorflow/core/kernels/quantize_and_dequantize_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -57,7 +57,7 @@ class QuantizeAndDequantizeV2Op : public OpKernel {\n                                 \" with signed_input_ \", signed_input_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n \n-    string round_mode_string;\n+    std::string round_mode_string;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"round_mode\", &round_mode_string));\n     OP_REQUIRES(\n         ctx,\n@@ -284,7 +284,7 @@ class QuantizeAndDequantizeV3Op : public OpKernel {\n                                 \"be a scalar. Got dimensions: \",\n                                 num_bits_tensor.dims()));\n \n-    const int num_bits_val = num_bits_tensor.scalar<int32>()();\n+    const int num_bits_val = num_bits_tensor.scalar<int32_t>()();\n     OP_REQUIRES(ctx,\n                 num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),\n                 InvalidArgument(\"num_bits is out of range: \", num_bits_val,"
        },
        {
            "sha": "b93292f83d677ac51fcbe884bfff9f8ea49ef244",
            "filename": "tensorflow/core/kernels/quantize_and_dequantize_op_test.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fquantize_and_dequantize_op_test.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -86,7 +86,7 @@ TEST_F(QuantizeAndDequantizeTest, Convert_scalar_tensor_V3) {\n   AddInputFromArray<float>(TensorShape({1}), {-3.5});\n   AddInputFromArray<float>(TensorShape({}), {0.0});  // Min\n   AddInputFromArray<float>(TensorShape({}), {0.0});  // Max\n-  AddInputFromArray<int32>(TensorShape({}), {8});    // num_bits\n+  AddInputFromArray<int32_t>(TensorShape({}), {8});  // num_bits\n \n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1}));\n@@ -103,7 +103,7 @@ TEST_F(QuantizeAndDequantizeTest, Convert_scalar_tensor_V3) {\n template <typename T>\n std::vector<T> ScalePerSliceAlongAxis(std::vector<int64_t> dims, int axis,\n                                       const std::vector<T>& data) {\n-  uint32 seed = 123;\n+  uint32_t seed = 123;\n   int64_t out_size = 1;\n   for (int dim : dims) {\n     out_size *= dim;\n@@ -292,7 +292,7 @@ TEST_F(QuantizeAndDequantizeTest, Convert_1D_tensor_with_int8_V3) {\n   AddInputFromArray<float>(TensorShape({6}), {-1, -0.5, 0, 0.3, 0.8, 0.555});\n   AddInputFromArray<float>(TensorShape({}), {0.0});  // Min\n   AddInputFromArray<float>(TensorShape({}), {0.0});  // Max\n-  AddInputFromArray<int32>(TensorShape({}), {8});    // num_bits\n+  AddInputFromArray<int32_t>(TensorShape({}), {8});  // num_bits\n \n   // With int8, the tensor is quantized to {-128, -64, 0, 38, 102, 71}.\n   // Scale is: 1/128\n@@ -337,7 +337,7 @@ TEST_P(ParameterizedQuantizeAndDequantizeTest,\n   std::vector<float> init_value(num_slices, 0.0f);\n   AddInputFromArray<float>(range_shape, init_value);  // Min\n   AddInputFromArray<float>(range_shape, init_value);  // Max\n-  AddInputFromArray<int32>(TensorShape({}), {8});     // num_bits\n+  AddInputFromArray<int32_t>(TensorShape({}), {8});   // num_bits\n \n   // With int8, the values in the tensor are quantized to\n   // {-127, -63, 0, 38, 102, 70, 64}.\n@@ -490,7 +490,7 @@ TEST_F(QuantizeAndDequantizeTest, Convert_1D_tensor_with_int4_V3) {\n   AddInputFromArray<float>(TensorShape({6}), {-1, -0.5, 0, 0.3, 0.8, 0.555});\n   AddInputFromArray<float>(TensorShape({}), {0.0});  // Min\n   AddInputFromArray<float>(TensorShape({}), {0.0});  // Max\n-  AddInputFromArray<int32>(TensorShape({}), {4});    // num_bits\n+  AddInputFromArray<int32_t>(TensorShape({}), {4});  // num_bits\n \n   // With int4, the tensor is quantized to {-8, -4, 0, 2, 6, 4}.\n   // Scale is: 1/8\n@@ -583,7 +583,7 @@ TEST_F(QuantizeAndDequantizeTest, Convert_2D_tensor_with_int8_range_given_V3) {\n                            {-0.8, -0.5, 0, 0.3, 0.8, 0.555, -2, 33});\n   AddInputFromArray<float>(TensorShape({}), {-1.0});  // Min\n   AddInputFromArray<float>(TensorShape({}), {1.0});   // Max\n-  AddInputFromArray<int32>(TensorShape({}), {8});     // num_bits\n+  AddInputFromArray<int32_t>(TensorShape({}), {8});   // num_bits\n \n   // Note that the range is given as [-1, 1].\n   // With int8, the tensor is quantized to {-102, -64, 0, 38, 102, 70, -128,\n@@ -664,7 +664,7 @@ TEST_F(QuantizeAndDequantizeTest, Convert_4D_tensor_with_uint8_range_given_V3) {\n   AddInputFromArray<float>(TensorShape({2, 2, 1, 1}), {-0.5, 0, 0.3, 0.8});\n   AddInputFromArray<float>(TensorShape({}), {0.0});  // Min\n   AddInputFromArray<float>(TensorShape({}), {1.0});  // Max\n-  AddInputFromArray<int32>(TensorShape({}), {8});    // num_bits\n+  AddInputFromArray<int32_t>(TensorShape({}), {8});  // num_bits\n \n   // Note that the range is given as [0, 1].\n   // With int8, the tensor is quantized to {0, 0, 76, 204}\n@@ -712,7 +712,7 @@ TEST_F(QuantizeAndDequantizeTest, Convert_tensor_with_all_0_V3) {\n   AddInputFromArray<float>(TensorShape({2, 2, 1, 1}), {0, 0, 0, 0});\n   AddInputFromArray<float>(TensorShape({}), {0.0});  // Min\n   AddInputFromArray<float>(TensorShape({}), {0.0});  // Max\n-  AddInputFromArray<int32>(TensorShape({}), {8});    // num_bits\n+  AddInputFromArray<int32_t>(TensorShape({}), {8});  // num_bits\n \n   TF_ASSERT_OK(RunOpKernel());\n   Tensor expected(allocator(), DT_FLOAT, TensorShape({2, 2, 1, 1}));\n@@ -755,7 +755,7 @@ TEST_F(QuantizeAndDequantizeTest, Invalid_range_given_V3) {\n   AddInputFromArray<float>(TensorShape({2, 2, 1, 1}), {-0.5, 0, 0.3, 0.8});\n   AddInputFromArray<float>(TensorShape({}), {1.0});  // Min\n   AddInputFromArray<float>(TensorShape({}), {0.0});  // Max\n-  AddInputFromArray<int32>(TensorShape({}), {8});    // num_bits\n+  AddInputFromArray<int32_t>(TensorShape({}), {8});  // num_bits\n \n   absl::Status s = RunOpKernel();\n   EXPECT_TRUE(absl::StrContains(s.ToString(),\n@@ -778,7 +778,7 @@ TEST_F(QuantizeAndDequantizeTest, Invalid_axis_given_V3) {\n   AddInputFromArray<float>(TensorShape({2, 2, 1, 1}), {-0.5, 0, 0.3, 0.8});\n   AddInputFromArray<float>(TensorShape({}), {1.0});  // Min\n   AddInputFromArray<float>(TensorShape({}), {0.0});  // Max\n-  AddInputFromArray<int32>(TensorShape({}), {8});    // num_bits\n+  AddInputFromArray<int32_t>(TensorShape({}), {8});  // num_bits\n \n   EXPECT_THAT(\n       RunOpKernel(),"
        },
        {
            "sha": "9a49f96d4c60245e3ed0165b87409f2b65f63211",
            "filename": "tensorflow/core/kernels/quantize_down_and_shrink_range.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fquantize_down_and_shrink_range.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/89b883eecf5130b2b353a051e687abe9a12e6662/tensorflow%2Fcore%2Fkernels%2Fquantize_down_and_shrink_range.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fquantize_down_and_shrink_range.cc?ref=89b883eecf5130b2b353a051e687abe9a12e6662",
            "patch": "@@ -64,9 +64,9 @@ class QuantizeDownAndShrinkRangeOp : public OpKernel {\n     // See QuantizationRangeOp as well, which has a copy of this logic.\n     auto input_array = input.flat<T1>();\n     const int32_t input_lowest_quantized =\n-        static_cast<int32>(Eigen::NumTraits<T1>::lowest());\n+        static_cast<int32_t>(Eigen::NumTraits<T1>::lowest());\n     const int32_t input_highest_quantized =\n-        static_cast<int32>(Eigen::NumTraits<T1>::highest());\n+        static_cast<int32_t>(Eigen::NumTraits<T1>::highest());\n     T1 actual_min_quantized = input_highest_quantized;\n     T1 actual_max_quantized = input_lowest_quantized;\n     for (int i = 0; i < input_array.size(); ++i) {"
        }
    ],
    "stats": {
        "total": 719,
        "additions": 369,
        "deletions": 350
    }
}