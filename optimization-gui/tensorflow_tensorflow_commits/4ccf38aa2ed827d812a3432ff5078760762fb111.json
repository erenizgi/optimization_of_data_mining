{
    "author": "ezhulenev",
    "message": "[xla:gpu] Switch to type safe LocalDeviceId in local to global device id mapping\n\nPiperOrigin-RevId: 837366466",
    "sha": "4ccf38aa2ed827d812a3432ff5078760762fb111",
    "files": [
        {
            "sha": "45814517342abcad3ec2a5eff62e5190c1fced6c",
            "filename": "tensorflow/compiler/tf2xla/xla_helpers.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_helpers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_helpers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_helpers.cc?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -233,7 +233,7 @@ absl::Status ResolveDeviceAssignment(\n     // For GPU collectives, `xla_global_id`s are arbitrary integers, and XLA\n     // requires a mapping from local device IDs to global device IDs.\n     const DeviceMgr* device_mgr = ctx->function_library()->device_mgr();\n-    std::map<int, xla::GlobalDeviceId> global_device_ids;\n+    absl::btree_map<xla::LocalDeviceId, xla::GlobalDeviceId> global_device_ids;\n \n     for (int device_idx = 0; device_idx < params->group.group_size;\n          device_idx++) {\n@@ -246,8 +246,8 @@ absl::Status ResolveDeviceAssignment(\n         // This is a local device, so include it in the mapping.\n         const DeviceBase::AcceleratorDeviceInfo* accelerator_device_info =\n             resolved_device->tensorflow_accelerator_device_info();\n-        global_device_ids[accelerator_device_info->stream->parent()\n-                              ->device_ordinal()] =\n+        global_device_ids[xla::LocalDeviceId(\n+            accelerator_device_info->stream->parent()->device_ordinal())] =\n             device_attributes.xla_global_id();\n       }\n     }"
        },
        {
            "sha": "34ee607d5731f083b1d0eee9f73bcf07cbd1522b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -1281,6 +1281,7 @@ xla_test(\n         \"//xla:array\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/backends/gpu/runtime:collective_params\",\n         \"//xla/pjrt:worker_thread\",\n         \"//xla/runtime:device_id\",\n         \"//xla/service:buffer_assignment\",\n@@ -1597,6 +1598,7 @@ cc_library(\n     deps = [\n         \":collective_clique_requests\",\n         \"//xla:executable_run_options\",\n+        \"//xla:util\",\n         \"//xla/backends/gpu/collectives:gpu_clique_key\",\n         \"//xla/backends/gpu/collectives:gpu_collectives\",\n         \"//xla/runtime:device_id\","
        },
        {
            "sha": "31965812082fe80851ac7792f69963ba2cb1d181",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -16,7 +16,6 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/collective_kernel_thunk.h\"\n \n #include <cstdint>\n-#include <map>\n #include <memory>\n #include <string>\n #include <utility>\n@@ -26,6 +25,7 @@ limitations under the License.\n #include \"absl/log/log.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/backends/gpu/runtime/collective_params.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/runtime/device_id.h\"\n@@ -203,9 +203,9 @@ absl::StatusOr<se::DeviceMemoryBase> RunCollectiveKernelThunk(\n   BufferAllocation buffer_allocation(\n       /*index=*/0, /*size=*/metadata.total_buffer_size, /*color=*/0);\n   GpuExecutableRunOptions gpu_options;\n-  gpu_options.set_gpu_global_device_ids(\n-      std::map{std::make_pair(0, GlobalDeviceId(0)),\n-               std::make_pair(1, GlobalDeviceId(1))});\n+  gpu_options.set_gpu_global_device_ids(GpuExecutableRunOptions::DeviceIdMap{\n+      std::make_pair(LocalDeviceId(0), GlobalDeviceId(0)),\n+      std::make_pair(LocalDeviceId(1), GlobalDeviceId(1))});\n \n   TF_ASSIGN_OR_RETURN(auto stream, executor->CreateStream());\n   ServiceExecutableRunOptions run_options;\n@@ -221,10 +221,10 @@ absl::StatusOr<se::DeviceMemoryBase> RunCollectiveKernelThunk(\n   run_options.mutable_run_options()->set_gpu_executable_run_options(\n       &gpu_options);\n \n-  TF_ASSIGN_OR_RETURN(auto collective_params,\n-                      CollectiveParams::Create(\n-                          run_options, /*async_streams=*/{},\n-                          /*local_device_ordinal=*/executor->device_ordinal()));\n+  TF_ASSIGN_OR_RETURN(\n+      auto collective_params,\n+      CollectiveParams::Create(run_options, /*async_streams=*/{},\n+                               LocalDeviceId(executor->device_ordinal())));\n   std::vector<se::DeviceMemoryBase> allocated_buffers = {\n       executor->AllocateArray<uint64_t>(metadata.total_buffer_size)};\n "
        },
        {
            "sha": "269adedd08b013af015a96f2aa43d17113ce43b7",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_params.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 13,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_params.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_params.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_params.cc?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -18,9 +18,7 @@ limitations under the License.\n #include <cstdint>\n \n #include \"absl/container/flat_hash_map.h\"\n-#include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n-#include \"absl/strings/str_cat.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/executable_run_options.h\"\n@@ -31,6 +29,7 @@ limitations under the License.\n #include \"xla/service/service_executable_run_options.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n \n namespace xla::gpu {\n \n@@ -39,26 +38,25 @@ using GlobalDeviceIdMap = CollectiveParams::GlobalDeviceIdMap;\n // Returns global device id for a local device ordinal or an error if global\n // device id map is misconfigured and missing an entry for a local device.\n static absl::StatusOr<GlobalDeviceId> GetGlobalDeviceId(\n-    const GlobalDeviceIdMap* device_id_map, int64_t local_device_ordinal) {\n+    const GlobalDeviceIdMap* device_id_map, LocalDeviceId local_device_id) {\n   // No local -> global mapping was provided; assume the identity mapping.\n   if (!device_id_map) {\n-    return GlobalDeviceId(local_device_ordinal);\n+    return GlobalDeviceId(local_device_id.value());\n   }\n \n   // Find a global device id in a global device id map.\n-  auto it = device_id_map->find(local_device_ordinal);\n+  auto it = device_id_map->find(local_device_id);\n   if (it == device_id_map->end()) {\n-    return absl::NotFoundError(\n-        absl::StrCat(\"No global device id found for local device ordinal: \",\n-                     local_device_ordinal));\n+    return NotFound(\"No global device id found for local device ordinal: %d\",\n+                    local_device_id.value());\n   }\n \n   return it->second;\n }\n \n absl::StatusOr<CollectiveParams> CollectiveParams::Create(\n     const ServiceExecutableRunOptions& run_options,\n-    absl::Span<se::Stream* const> async_streams, int64_t local_device_ordinal,\n+    absl::Span<se::Stream* const> async_streams, LocalDeviceId local_device_id,\n     int64_t collective_max_nchannels, int64_t p2p_max_nchannels) {\n   const GpuExecutableRunOptions* gpu_options =\n       run_options.run_options().gpu_executable_run_options();\n@@ -80,19 +78,19 @@ absl::StatusOr<CollectiveParams> CollectiveParams::Create(\n                            : nullptr;\n \n   TF_ASSIGN_OR_RETURN(GlobalDeviceId global_device_id,\n-                      GetGlobalDeviceId(device_id_map, local_device_ordinal));\n+                      GetGlobalDeviceId(device_id_map, local_device_id));\n \n   return CollectiveParams(collectives, run_options.stream()->parent(),\n                           run_options.run_options().run_id(), async_streams,\n-                          local_device_ordinal, global_device_id,\n+                          local_device_id, global_device_id,\n                           run_options.run_options().device_assignment(),\n                           device_id_map, clique_id_callback, incarnations,\n                           collective_max_nchannels, p2p_max_nchannels);\n }\n \n CollectiveParams::CollectiveParams(\n     GpuCollectives* collectives, se::StreamExecutor* executor, RunId run_id,\n-    absl::Span<se::Stream* const> async_streams, int64_t local_device_ordinal,\n+    absl::Span<se::Stream* const> async_streams, LocalDeviceId local_device_id,\n     GlobalDeviceId global_device_id, const DeviceAssignment* device_assn,\n     const GlobalDeviceIdMap* global_device_id_map,\n     const CliqueIdCallback* nccl_clique_id_callback,\n@@ -102,7 +100,7 @@ CollectiveParams::CollectiveParams(\n       executor(executor),\n       run_id(run_id),\n       async_streams(async_streams.begin(), async_streams.end()),\n-      local_device_ordinal(local_device_ordinal),\n+      local_device_id(local_device_id),\n       global_device_id(global_device_id),\n       device_assn(device_assn),\n       global_device_id_map(global_device_id_map),"
        },
        {
            "sha": "d4a6fdbeb735555f2504a452e555b4a77f2ba156",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_params.h",
            "status": "modified",
            "additions": 8,
            "deletions": 9,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_params.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_params.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_params.h?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -17,7 +17,6 @@ limitations under the License.\n #define XLA_BACKENDS_GPU_RUNTIME_COLLECTIVE_PARAMS_H_\n \n #include <cstdint>\n-#include <map>\n \n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/inlined_vector.h\"\n@@ -38,17 +37,16 @@ namespace xla::gpu {\n // XLA executables (multiple partitions and replicas).\n struct CollectiveParams {\n   // A mapping from local device ordinals to global device IDs.\n-  //\n-  // TODO(ezhulenev): Use type safe RankId instead of int32_t.\n-  using GlobalDeviceIdMap = std::map<int32_t, GlobalDeviceId>;\n+  using GlobalDeviceIdMap = GpuExecutableRunOptions::DeviceIdMap;\n \n   // Creates NCCL execution parameters from the run options for the given\n   // local device. Returns an error if run options are misconfigured (i.e.\n   // missing a global device mapping for a local device ordinal).\n   static absl::StatusOr<CollectiveParams> Create(\n       const ServiceExecutableRunOptions& run_options,\n-      absl::Span<se::Stream* const> async_streams, int64_t local_device_ordinal,\n-      int64_t collective_max_nchannels = 0, int64_t p2p_max_nchannels = 0);\n+      absl::Span<se::Stream* const> async_streams,\n+      LocalDeviceId local_device_id, int64_t collective_max_nchannels = 0,\n+      int64_t p2p_max_nchannels = 0);\n \n   GpuCollectives* collectives;\n   se::StreamExecutor* executor;\n@@ -60,7 +58,7 @@ struct CollectiveParams {\n   // Streams for asynchronous collective communications.\n   absl::InlinedVector<se::Stream*, 4> async_streams;\n \n-  int64_t local_device_ordinal;\n+  LocalDeviceId local_device_id;\n   GlobalDeviceId global_device_id;\n \n   const DeviceAssignment* device_assn;\n@@ -76,8 +74,9 @@ struct CollectiveParams {\n  private:\n   CollectiveParams(\n       GpuCollectives* collectives, se::StreamExecutor* executor, RunId run_id,\n-      absl::Span<se::Stream* const> async_streams, int64_t local_device_ordinal,\n-      GlobalDeviceId global_device_id, const DeviceAssignment* device_assn,\n+      absl::Span<se::Stream* const> async_streams,\n+      LocalDeviceId local_device_id, GlobalDeviceId global_device_id,\n+      const DeviceAssignment* device_assn,\n       const GlobalDeviceIdMap* global_device_id_map,\n       const CliqueIdCallback* nccl_clique_id_callback,\n       const absl::flat_hash_map<GlobalDeviceId, IncarnationId>* incarnations,"
        },
        {
            "sha": "23e21a65eb7f8f153421ffdc80a10fdc21d6cc6e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -503,7 +503,7 @@ std::string CollectiveThunk::GetDeviceString(\n   return absl::StrFormat(\"(r%d, p%d) : GlobalID %d, ord %d\",\n                          logical_id.replica_id, logical_id.computation_id,\n                          global_device_id.value(),\n-                         collective_params.local_device_ordinal);\n+                         collective_params.local_device_id.value());\n }\n \n std::optional<AsyncEventsUniqueId> CollectiveThunk::GetAsyncEventsUniqueId()"
        },
        {
            "sha": "1c2e9cb21c37968ddf42a68ac27a131f680fe69d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -1854,7 +1854,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> CuDnnCmd::Record(\n       [&](se::Stream* stream) {\n         return graph_->get()->Execute(\n             *stream, absl::Span<se::DeviceMemoryBase>(operands),\n-            execute_params.collective_params->local_device_ordinal);\n+            execute_params.collective_params->local_device_id.value());\n       });\n }\n "
        },
        {
            "sha": "d8ee7e0d193952d8080438b2e943c6972e0a93ad",
            "filename": "third_party/xla/xla/backends/gpu/runtime/cudnn_thunk.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcudnn_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcudnn_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcudnn_thunk.cc?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -89,9 +89,9 @@ absl::Status CuDnnThunk::ExecuteOnStream(const ExecuteParams& params) {\n     }\n     buffer_args.push_back(addr);\n   }\n-  return graph_->get()->Execute(*params.stream,\n-                                absl::Span<se::DeviceMemoryBase>(buffer_args),\n-                                params.collective_params->local_device_ordinal);\n+  return graph_->get()->Execute(\n+      *params.stream, absl::Span<se::DeviceMemoryBase>(buffer_args),\n+      params.collective_params->local_device_id.value());\n }\n \n absl::StatusOr<ThunkProto> CuDnnThunk::ToProto() const {"
        },
        {
            "sha": "b5bd5df0bd6b7237a0950b5d7f7ab79da458ce93",
            "filename": "third_party/xla/xla/pjrt/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -141,6 +141,7 @@ cc_library(\n         \"//xla/tsl/util:env_var\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/container:btree\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/functional:any_invocable\","
        },
        {
            "sha": "4fa963b9040ba172086f8e37dc39799525413621",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -30,6 +30,7 @@ limitations under the License.\n \n #include \"absl/algorithm/container.h\"\n #include \"absl/base/thread_annotations.h\"\n+#include \"absl/container/btree_map.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/functional/any_invocable.h\"\n@@ -88,6 +89,7 @@ limitations under the License.\n #include \"xla/pjrt/se_raw_buffer.h\"\n #include \"xla/pjrt/tracked_device_buffer.h\"\n #include \"xla/pjrt/worker_thread.h\"\n+#include \"xla/runtime/device_id.h\"\n #include \"xla/service/compiler.h\"\n #include \"xla/service/computation_placer.h\"\n #include \"xla/service/global_device_id.h\"\n@@ -1226,7 +1228,7 @@ absl::StatusOr<DeviceTopologyPair> BuildDistributedDevices(\n         &global_topology, /*assign_global_device_ids=*/true));\n   }\n \n-  std::map<int, GlobalDeviceId> gpu_device_ids;\n+  absl::btree_map<LocalDeviceId, GlobalDeviceId> gpu_device_ids;\n   absl::flat_hash_map<GlobalDeviceId, int> device_to_node;\n   int curr_partition_index = -1;\n   int curr_process_index = -1;\n@@ -1255,7 +1257,8 @@ absl::StatusOr<DeviceTopologyPair> BuildDistributedDevices(\n             << device_proto.local_device_ordinal();\n         TF_RET_CHECK(it->second != nullptr);\n         local_device = std::move(it->second);\n-        gpu_device_ids[device_proto.local_device_ordinal()] = global_device_id;\n+        gpu_device_ids[LocalDeviceId(device_proto.local_device_ordinal())] =\n+            global_device_id;\n         // Assign some descriptive names for profiling tools.\n         NameDeviceAndLauncherThread(node, device_proto,\n                                     local_device->execute_thread());"
        },
        {
            "sha": "2aaf31b53fc27a07cae0cf37691044e4a76bfb9a",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/utils.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 4,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.cc?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -30,6 +30,7 @@ limitations under the License.\n #include <vector>\n \n #include \"absl/algorithm/container.h\"\n+#include \"absl/container/btree_map.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/functional/any_invocable.h\"\n #include \"absl/log/check.h\"\n@@ -73,6 +74,7 @@ limitations under the License.\n #include \"xla/pjrt/pjrt_executable.h\"\n #include \"xla/pjrt/plugin/xla_gpu/xla_gpu_allocator_config.h\"\n #include \"xla/pjrt/proto/compile_options.pb.h\"\n+#include \"xla/runtime/device_id.h\"\n #include \"xla/service/compiler.h\"\n #include \"xla/service/computation_placer.h\"\n #include \"xla/service/global_device_id.h\"\n@@ -812,7 +814,7 @@ absl::StatusOr<DeviceTopologyPair> BuildDistributedDevices(\n         &global_topology, /*assign_global_device_ids=*/true));\n   }\n \n-  std::map<int, GlobalDeviceId> gpu_device_ids;\n+  absl::btree_map<LocalDeviceId, GlobalDeviceId> gpu_device_ids;\n   absl::flat_hash_map<GlobalDeviceId, int> device_to_node;\n   int curr_partition_index = -1;\n   int curr_process_index = -1;\n@@ -836,7 +838,8 @@ absl::StatusOr<DeviceTopologyPair> BuildDistributedDevices(\n       device_to_node[global_device_id] = node.node_id();\n       TfrtGpuDevice::Options options;\n       if (node.node_id() == node_id) {\n-        gpu_device_ids[device_proto.local_device_ordinal()] = global_device_id;\n+        gpu_device_ids[LocalDeviceId(device_proto.local_device_ordinal())] =\n+            global_device_id;\n         // Assign some descriptive names for profiling tools.\n         // TODO: hhb\n         // NameDeviceAndLauncherThread(node, device_proto,\n@@ -869,8 +872,8 @@ absl::StatusOr<DeviceTopologyPair> BuildDistributedDevices(\n   }\n   for (se::StreamExecutor* executor :\n        xla_client->backend().stream_executors()) {\n-    TF_RET_CHECK(gpu_device_ids.find(executor->device_ordinal()) !=\n-                 gpu_device_ids.end());\n+    TF_RET_CHECK(gpu_device_ids.find(LocalDeviceId(\n+                     executor->device_ordinal())) != gpu_device_ids.end());\n   }\n   gpu_executable_run_options->set_gpu_global_device_ids(\n       std::move(gpu_device_ids));"
        },
        {
            "sha": "a12f6af3c87c31c501fe032c3b219f77b58914c7",
            "filename": "third_party/xla/xla/runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fruntime%2FBUILD?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -163,6 +163,7 @@ cc_library(\n     name = \"device_id\",\n     hdrs = [\"device_id.h\"],\n     deps = [\n+        \"//xla/tsl/distributed_runtime/coordination:coordination_service\",\n         \"//xla/tsl/lib/gtl:int_type\",\n     ],\n )"
        },
        {
            "sha": "86b0e1926d18b84d3ccc470cca1ebcf0a5b920b3",
            "filename": "third_party/xla/xla/runtime/device_id.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fruntime%2Fdevice_id.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fruntime%2Fdevice_id.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fruntime%2Fdevice_id.h?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n \n #include <cstdint>\n \n+#include \"xla/tsl/distributed_runtime/coordination/coordination_service.h\"\n #include \"xla/tsl/lib/gtl/int_type.h\"\n \n namespace xla {\n@@ -29,6 +30,8 @@ namespace xla {\n TSL_LIB_GTL_DEFINE_INT_TYPE(GlobalDeviceId, int64_t);\n TSL_LIB_GTL_DEFINE_INT_TYPE(LocalDeviceId, int64_t);\n \n+using ::tsl::IncarnationId;  // NOLINT(misc-unused-using-decls)\n+\n }  // namespace xla\n \n #endif  // XLA_RUNTIME_DEVICE_ID_H_"
        },
        {
            "sha": "aff76b21cf7f9fc2e4ba06771cbaceed7442cb60",
            "filename": "third_party/xla/xla/service/global_device_id.h",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fservice%2Fglobal_device_id.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fservice%2Fglobal_device_id.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fglobal_device_id.h?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -20,18 +20,12 @@ limitations under the License.\n \n #include \"absl/types/span.h\"\n #include \"xla/runtime/device_id.h\"\n-#include \"xla/tsl/distributed_runtime/coordination/coordination_service.h\"\n \n namespace xla {\n \n-// DEPRECATED: Use GlobalDeviceId from device_id.h instead.\n-using GlobalDeviceId = GlobalDeviceId;\n-\n // Returns a comma-separated string of global device IDs.\n std::string GlobalDeviceIdsToString(absl::Span<GlobalDeviceId const> ids);\n \n-using ::tsl::IncarnationId;  // NOLINT(misc-unused-using-decls)\n-\n }  // namespace xla\n \n #endif  // XLA_SERVICE_GLOBAL_DEVICE_ID_H_"
        },
        {
            "sha": "8f8796b2a38c58acb9442aacc3e893f15a110b84",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -90,7 +90,8 @@ cc_library(\n         \"//xla/backends/gpu/collectives:gpu_collectives\",\n         \"//xla/core/collectives:clique_id\",\n         \"//xla/core/collectives:clique_key\",\n-        \"//xla/service:global_device_id\",\n+        \"//xla/runtime:device_id\",\n+        \"@com_google_absl//absl/container:btree\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/functional:any_invocable\",\n         \"@com_google_absl//absl/status:statusor\",\n@@ -787,6 +788,7 @@ cc_library(\n         \"//xla/core/collectives:clique_key\",\n         \"//xla/core/collectives:communicator\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:device_id\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:computation_layout\",\n         \"//xla/service:dump\","
        },
        {
            "sha": "a9289d1f82466b46ff7005bfd4c44fb3114d0de6",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -60,6 +60,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/map_util.h\"\n+#include \"xla/runtime/device_id.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/dump.h\"\n #include \"xla/service/executable.h\"\n@@ -425,9 +426,10 @@ absl::Status ExecuteThunksImpl(\n   // Parameters for executing collective operations.\n   TF_ASSIGN_OR_RETURN(\n       CollectiveParams collective_params,\n-      CollectiveParams::Create(*run_options, async_comms_streams,\n-                               main_stream->parent()->device_ordinal(),\n-                               collective_max_nchannels, p2p_max_nchannels));\n+      CollectiveParams::Create(\n+          *run_options, async_comms_streams,\n+          LocalDeviceId(main_stream->parent()->device_ordinal()),\n+          collective_max_nchannels, p2p_max_nchannels));\n \n   CollectiveCliqueRequests clique_requests;\n "
        },
        {
            "sha": "919efca994ddca6e6f9c07ca740e92038918dd3d",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable_run_options.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_run_options.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_run_options.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_run_options.cc?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -15,25 +15,23 @@ limitations under the License.\n \n #include \"xla/service/gpu/gpu_executable_run_options.h\"\n \n-#include <cstdint>\n-#include <map>\n #include <optional>\n #include <utility>\n \n #include \"absl/container/flat_hash_map.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/executable_run_options.h\"\n-#include \"xla/service/global_device_id.h\"\n+#include \"xla/runtime/device_id.h\"\n \n namespace xla::gpu {\n \n GpuExecutableRunOptions& GpuExecutableRunOptions::set_gpu_global_device_ids(\n-    std::optional<std::map<int, GlobalDeviceId>> gpu_global_device_ids) {\n+    std::optional<DeviceIdMap> gpu_global_device_ids) {\n   gpu_global_device_ids_ = std::move(gpu_global_device_ids);\n   return *this;\n }\n \n-const std::optional<std::map<int, GlobalDeviceId>>&\n+const std::optional<GpuExecutableRunOptions::DeviceIdMap>&\n GpuExecutableRunOptions::gpu_global_device_ids() const {\n   return gpu_global_device_ids_;\n }"
        },
        {
            "sha": "b97dfdef2334e68810249701718294f51deef09d",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable_run_options.h",
            "status": "modified",
            "additions": 8,
            "deletions": 10,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_run_options.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ccf38aa2ed827d812a3432ff5078760762fb111/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_run_options.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_run_options.h?ref=4ccf38aa2ed827d812a3432ff5078760762fb111",
            "patch": "@@ -16,21 +16,17 @@ limitations under the License.\n #ifndef XLA_SERVICE_GPU_GPU_EXECUTABLE_RUN_OPTIONS_H_\n #define XLA_SERVICE_GPU_GPU_EXECUTABLE_RUN_OPTIONS_H_\n \n-#include <cstdint>\n #include <functional>\n-#include <map>\n #include <optional>\n-#include <vector>\n \n+#include \"absl/container/btree_map.h\"\n #include \"absl/container/flat_hash_map.h\"\n-#include \"absl/functional/any_invocable.h\"\n #include \"absl/status/statusor.h\"\n-#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/core/collectives/clique_id.h\"\n #include \"xla/core/collectives/clique_key.h\"\n #include \"xla/executable_run_options.h\"\n-#include \"xla/service/global_device_id.h\"\n+#include \"xla/runtime/device_id.h\"\n \n namespace xla::gpu {\n \n@@ -46,14 +42,16 @@ using CliqueIdCallback =  // NOLINT\n // dependencies to ExecutableRunOptions.\n class GpuExecutableRunOptions {\n  public:\n+  // A mapping from local device ordinal to global device ID.\n+  using DeviceIdMap = absl::btree_map<LocalDeviceId, GlobalDeviceId>;\n+\n   // Sets a mapping from local device ordinals to global device IDs.\n   // Used only on NVidia GPUs for cross-host NCCL collectives. If set, the\n   // elements of `device_assignment` are interpreted as global device IDs, not\n   // local device ordinals.\n   GpuExecutableRunOptions& set_gpu_global_device_ids(\n-      std::optional<std::map<int, GlobalDeviceId>> gpu_global_device_ids);\n-  const std::optional<std::map<int, GlobalDeviceId>>& gpu_global_device_ids()\n-      const;\n+      std::optional<DeviceIdMap> device_ids);\n+  const std::optional<DeviceIdMap>& gpu_global_device_ids() const;\n \n   // Callback that returns a unique clieque id for a given clique key.\n   GpuExecutableRunOptions& set_clique_id_callback(\n@@ -92,7 +90,7 @@ class GpuExecutableRunOptions {\n  private:\n   bool requires_exclusive_lock_on_gpu_ = false;\n   bool enable_mock_collectives_ = false;\n-  std::optional<std::map<int, GlobalDeviceId>> gpu_global_device_ids_;\n+  std::optional<DeviceIdMap> gpu_global_device_ids_;\n   CliqueIdCallback clique_id_callback_;\n   GpuCollectives* collectives_;\n   std::optional<absl::flat_hash_map<GlobalDeviceId, IncarnationId>>"
        }
    ],
    "stats": {
        "total": 142,
        "additions": 73,
        "deletions": 69
    }
}