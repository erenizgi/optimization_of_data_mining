{
    "author": "Varcho",
    "message": "[Upkeep] Resolve 4 instances of the following issue: Todo (resolved)\n\nPiperOrigin-RevId: 821824006",
    "sha": "a40f3bdebd5971d4e680e05237cb987716d82356",
    "files": [
        {
            "sha": "495abf85385fa016a05a960c730b0d1ef3055942",
            "filename": "third_party/xla/xla/hlo/transforms/collectives/collectives_schedule_linearizer.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a40f3bdebd5971d4e680e05237cb987716d82356/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcollectives%2Fcollectives_schedule_linearizer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a40f3bdebd5971d4e680e05237cb987716d82356/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcollectives%2Fcollectives_schedule_linearizer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcollectives%2Fcollectives_schedule_linearizer.cc?ref=a40f3bdebd5971d4e680e05237cb987716d82356",
            "patch": "@@ -31,7 +31,6 @@ limitations under the License.\n \n namespace xla {\n \n-// TODO(b/181653482): Fix for interprocedural collectives as well.\n absl::StatusOr<bool> CollectivesScheduleLinearizer::Run(\n     HloModule* module,\n     const absl::flat_hash_set<absl::string_view>& execution_threads) {"
        },
        {
            "sha": "afdc58a81b7008dfad7596b2628c1373970f585b",
            "filename": "third_party/xla/xla/tests/collective_pipeline_parallelism_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a40f3bdebd5971d4e680e05237cb987716d82356/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_pipeline_parallelism_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a40f3bdebd5971d4e680e05237cb987716d82356/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_pipeline_parallelism_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_pipeline_parallelism_test.cc?ref=a40f3bdebd5971d4e680e05237cb987716d82356",
            "patch": "@@ -1274,7 +1274,6 @@ TEST_P(CollectivePipelineParallelismTest,\n \n // This is the partially pipelined version of\n // NaiveBFSMicrobatch5CircularRepeat2Replica4 and should yield the same results.\n-// TODO(b/383868854): replace this with GPU pipeliner implementation.\n TEST_P(CollectivePipelineParallelismTest,\n        NaiveBFSMb5Cr2Replica4SendRecvPartiallyPipelined) {\n   constexpr char kMoreComputationsStr[] = R\"(\n@@ -1508,7 +1507,6 @@ TEST_P(CollectivePipelineParallelismTest,\n \n // This is the async-grouped version of\n // NaiveBFSMicrobatch5CircularRepeat2Replica4 and should yield the same results.\n-// TODO(b/383868854): replace this with GPU pipeliner implementation.\n TEST_P(CollectivePipelineParallelismTest,\n        NaiveBFSMb5Cr2Replica4SendRecvAsyncGroup) {\n   constexpr char kMoreComputationsStr[] = R\"("
        },
        {
            "sha": "cf581896f882d66dfb5d3eb94d8d6876c8e24a84",
            "filename": "third_party/xla/xla/tools/collective_perf_table_gen_main.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a40f3bdebd5971d4e680e05237cb987716d82356/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen_main.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a40f3bdebd5971d4e680e05237cb987716d82356/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen_main.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen_main.cc?ref=a40f3bdebd5971d4e680e05237cb987716d82356",
            "patch": "@@ -158,8 +158,6 @@ std::string DefaultCollectiveDevicesIfEmpty(\n \n }  // namespace\n \n-// TODO(b/390097558): Add an option to generate perf table for collective which\n-// gets overlap to model resource contention.\n int main(int argc, char* argv[]) {\n   // Default args.\n   int32_t num_nodes = 1;"
        }
    ],
    "stats": {
        "total": 5,
        "additions": 0,
        "deletions": 5
    }
}