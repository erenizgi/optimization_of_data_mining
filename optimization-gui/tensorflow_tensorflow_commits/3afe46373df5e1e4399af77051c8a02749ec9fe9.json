{
    "author": "pschuh",
    "message": "Change PjRtStreamExecutorBuffer to inherit from CommonPjRtBufferImpl instead of\nCommonPjRtBuffer directly.\n\nPiperOrigin-RevId: 814840732",
    "sha": "3afe46373df5e1e4399af77051c8a02749ec9fe9",
    "files": [
        {
            "sha": "fbe2fb39d8aba53e05a52be779d08bc7348e341c",
            "filename": "third_party/xla/xla/pjrt/abstract_tracked_device_buffer.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fabstract_tracked_device_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fabstract_tracked_device_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fabstract_tracked_device_buffer.h?ref=3afe46373df5e1e4399af77051c8a02749ec9fe9",
            "patch": "@@ -89,6 +89,11 @@ class AbstractTrackedDeviceBuffer {\n     return Unimplemented(\"GetDefinitionEvent is not supported for %s\",\n                          memory_space->ToString());\n   }\n+\n+  virtual absl::Status WaitUntilBufferReadyOnStream(std::intptr_t stream) {\n+    return absl::UnimplementedError(\n+        \"WaitUntilBufferReadyOnStream is only implemented for GPU.\");\n+  }\n };\n \n class CommonPjRtBuffer : public PjRtBuffer {"
        },
        {
            "sha": "5c4118777ba3cd78b33b20ba5b0d6c7ab5246272",
            "filename": "third_party/xla/xla/pjrt/common_pjrt_client.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc?ref=3afe46373df5e1e4399af77051c8a02749ec9fe9",
            "patch": "@@ -953,6 +953,10 @@ CommonPjRtBufferImpl::AcquireExternalReference() {\n       }\n     }\n \n+    absl::Status WaitUntilBufferReadyOnStream(std::intptr_t stream) override {\n+      return external_reference_.buffer()->WaitUntilBufferReadyOnStream(stream);\n+    }\n+\n     ~ScopedHoldAsExternalReference() override = default;\n \n    private:"
        },
        {
            "sha": "1c9ef71a0ea629ddd2ecab1087c3abd6564e5a17",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=3afe46373df5e1e4399af77051c8a02749ec9fe9",
            "patch": "@@ -719,7 +719,8 @@ Future<> StreamExecutorGpuClient::CopyRawSubBufferToHost(\n     int64_t transfer_size) {\n   auto* buffer = tensorflow::down_cast<PjRtStreamExecutorBuffer*>(pjrt_buffer);\n   DCHECK(buffer);\n-  PjRtStreamExecutorDevice* device = buffer->device();\n+  auto* device =\n+      tensorflow::down_cast<PjRtStreamExecutorDevice*>(buffer->device());\n   LocalDeviceState* local_device = device->local_device_state();\n   se::Stream* stream = local_device->GetDeviceToHostStream();\n "
        },
        {
            "sha": "9fa765d614e453745b4658d287863030f9ed62fb",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 42,
            "deletions": 132,
            "changes": 174,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=3afe46373df5e1e4399af77051c8a02749ec9fe9",
            "patch": "@@ -108,6 +108,7 @@ limitations under the License.\n #include \"xla/layout_util.h\"\n #include \"xla/literal.h\"\n #include \"xla/pjrt/abstract_tracked_device_buffer.h\"\n+#include \"xla/pjrt/common_pjrt_client.h\"\n #include \"xla/pjrt/device_event.h\"\n #include \"xla/pjrt/distributed/protocol.pb.h\"\n #include \"xla/pjrt/dump/dump.h\"\n@@ -739,107 +740,6 @@ bool PjRtStreamExecutorClient::IsOnCpu(PjRtMemorySpace* memory_space) {\n   return memory_space->kind() == PinnedHostMemorySpace::kKind;\n }\n \n-absl::StatusOr<Shape> PjRtStreamExecutorBuffer::logical_on_device_shape() {\n-  if (on_device_shape_.is_static()) {\n-    return on_device_shape_;\n-  }\n-  auto* local_device = device_->local_device_state();\n-  auto* stream = local_device->GetDeviceToHostStream();\n-  auto device_buffer = GetBufferWithUsageHold();\n-  if (!device_buffer.ok()) {\n-    return InvalidArgument(\n-        \"logical_on_device_shape() called on deleted or donated buffer: %s\",\n-        device_buffer.status().ToString());\n-  }\n-\n-  WaitForBufferDefinitionEventsOnStream(device_buffer->definition_events(),\n-                                        stream);\n-  ShapedBuffer shaped_buffer = device_buffer->AsShapedBuffer(on_device_shape_);\n-  absl::StatusOr<EventPool::Handle> event_or =\n-      local_device->event_pool().AllocateEvent(stream->parent());\n-  if (!event_or.ok()) {\n-    return event_or.status();\n-  }\n-  Shape ret_shape = on_device_shape_;\n-  TransferManager* transfer_manager =\n-      client_->client()->backend().transfer_manager();\n-  TF_RETURN_IF_ERROR(\n-      transfer_manager->ReadDynamicShapes(stream, &shaped_buffer, &ret_shape));\n-  return ret_shape;\n-}\n-\n-namespace {\n-\n-// Implements PjRtBuffer::ExternalReference as a wrapped\n-// ScopedHold::kExternalReference.\n-class ScopedHoldAsExternalReference : public PjRtBuffer::ExternalReference {\n- public:\n-  explicit ScopedHoldAsExternalReference(\n-      PjRtStreamExecutorBuffer::ScopedHold hold)\n-      : external_reference_(std::move(hold)) {\n-    CHECK(external_reference_.type() ==\n-          PjRtStreamExecutorBuffer::ScopedHold::kExternalReference);\n-    data_ptr_ = external_reference_->device_memory()->opaque();\n-  }\n-\n-  ~ScopedHoldAsExternalReference() override = default;\n-\n-  absl::Status WaitUntilBufferReadyOnStream(std::intptr_t stream) override {\n-    for (const BufferSequencingEventRef& event :\n-         external_reference_->definition_events()) {\n-      TF_RETURN_IF_ERROR(event->WaitForEventOnExternalStream(stream));\n-    }\n-    return absl::OkStatus();\n-  }\n-\n- private:\n-  PjRtStreamExecutorBuffer::ScopedHold external_reference_;\n-};\n-\n-}  // namespace\n-\n-absl::StatusOr<std::unique_ptr<PjRtBuffer::ExternalReference>>\n-PjRtStreamExecutorBuffer::AcquireExternalReference() {\n-  ScopedHold hold = GetBufferWithExternalReference();\n-  absl::Status hold_status = hold.status();\n-  if (!hold_status.ok()) return hold_status;\n-  return std::unique_ptr<ExternalReference>(\n-      std::make_unique<ScopedHoldAsExternalReference>(std::move(hold)));\n-}\n-\n-class TrackedDeviceBufferExternalReference\n-    : public PjRtBuffer::ExternalReference {\n- public:\n-  explicit TrackedDeviceBufferExternalReference(\n-      tsl::RCReference<RawSEDeviceMemory> memory)\n-      : memory_(std::move(memory)) {\n-    data_ptr_ = memory_->opaque();\n-  }\n-\n-  ~TrackedDeviceBufferExternalReference() override = default;\n-\n- private:\n-  tsl::RCReference<RawSEDeviceMemory> memory_;\n-};\n-\n-absl::StatusOr<std::unique_ptr<PjRtBuffer::ExternalReference>>\n-PjRtStreamExecutorBuffer::ReleaseDeviceMemoryOwnership(\n-    bool wait_for_operations_to_complete) {\n-  if (on_device_shape_.IsTuple()) {\n-    return InvalidArgument(\n-        \"ReleaseDeviceMemoryOwnership allowed only for non-tuple\");\n-  }\n-  TF_ASSIGN_OR_RETURN(tsl::RCReference<RawSEDeviceMemory> tracked_device_buffer,\n-                      Release(wait_for_operations_to_complete));\n-\n-  std::unique_ptr<PjRtBuffer::ExternalReference> ref;\n-  if (tracked_device_buffer) {\n-    ref = std::make_unique<TrackedDeviceBufferExternalReference>(\n-        std::move(tracked_device_buffer));\n-  }\n-  return ref;\n-}\n-\n absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n PjRtStreamExecutorBuffer::DonateWithControlDependency(Future<> dependency) {\n   VLOG(1) << \"PjRtStreamExecutorBuffer::DonateWithControlDependency\";\n@@ -857,9 +757,10 @@ PjRtStreamExecutorBuffer::DonateWithControlDependency(Future<> dependency) {\n   // Copy all the data in the existing tracked_buffer.\n   const auto& original_definition_events = tracked_buffer->definition_events();\n   absl::InlinedVector<BufferSequencingEventRef, 4> definition_events;\n+  auto* se_client = tensorflow::down_cast<PjRtStreamExecutorClient*>(client());\n \n   auto definition_event_for_status =\n-      BufferSequencingEvent::Create(client()->thread_pool());\n+      BufferSequencingEvent::Create(se_client->thread_pool());\n   // definition_event_for_status must be the first one so that it blocks other\n   // actions like D2H transfer from execution before the buffer is ready.\n   definition_events.push_back(definition_event_for_status);\n@@ -874,14 +775,15 @@ PjRtStreamExecutorBuffer::DonateWithControlDependency(Future<> dependency) {\n   // definition event.\n   new_buffer =\n       std::unique_ptr<PjRtBuffer>(std::make_unique<PjRtStreamExecutorBuffer>(\n-          on_device_shape(), std::move(new_device_buffer), client(), device(),\n+          on_device_shape(), std::move(new_device_buffer), se_client, device(),\n           device()->default_memory_space().value_or(nullptr)));\n \n-  PjRtStreamExecutorDevice* device = this->device();\n+  auto* device =\n+      tensorflow::down_cast<PjRtStreamExecutorDevice*>(this->device());\n   LocalDeviceState* local_device = device->local_device_state();\n   dependency.OnReady(\n       [definition_event_for_status = std::move(definition_event_for_status),\n-       local_device, client = client_](absl::Status status) mutable {\n+       local_device, client = se_client](absl::Status status) mutable {\n         // Forward the absl::Status from the supplied dependency to the\n         // definition event.\n         auto stream = local_device->BorrowStreamFromPool();\n@@ -1359,10 +1261,8 @@ absl::Span<PjRtMemorySpace* const> PjRtStreamExecutorClient::memory_spaces()\n PjRtStreamExecutorBuffer::PjRtStreamExecutorBuffer(\n     Shape on_device_shape, std::unique_ptr<TrackedDeviceBuffer> device_buffer,\n     PjRtClient* client, PjRtDevice* device, PjRtMemorySpace* memory_space)\n-    : CommonPjRtBuffer(std::move(device_buffer), memory_space),\n-      client_(tensorflow::down_cast<PjRtStreamExecutorClient*>(client)),\n-      on_device_shape_(std::move(on_device_shape)),\n-      device_(tensorflow::down_cast<PjRtStreamExecutorDevice*>(device)) {}\n+    : CommonPjRtBufferImpl(std::move(on_device_shape), std::move(device_buffer),\n+                           memory_space) {}\n \n PjRtStreamExecutorBuffer::~PjRtStreamExecutorBuffer() { Delete(); }\n \n@@ -1377,7 +1277,8 @@ PjRtStreamExecutorBuffer::Release(bool wait_for_operations_to_complete) {\n   TrackedDeviceBuffer::StreamAndEventContainer events =\n       device_buffer->LockUseAndTransferUsageEvents();\n   auto device_memory = device_buffer->device_memory();\n-  LocalDeviceState* local_device_state = device_->local_device_state();\n+  auto* se_device = tensorflow::down_cast<PjRtStreamExecutorDevice*>(device());\n+  LocalDeviceState* local_device_state = se_device->local_device_state();\n   if (wait_for_operations_to_complete) {\n     // Block the host until all usage events have completed. Usage events\n     // dominate definition events, so this also waits for the buffer to be\n@@ -1513,10 +1414,9 @@ Future<> PjRtStreamExecutorBuffer::ToLiteral(MutableLiteralBase* literal) {\n Future<> PjRtStreamExecutorBuffer::ToLiteralHelper(\n     Future<MutableLiteralBase*> literal) {\n   VLOG(3) << \"PjRtStreamExecutorBuffer::ToLiteral\";\n-  if (IsEmptyTuple()) {\n-    return Future<>(InvalidArgument(\"ToLiteral called on empty tuple\"));\n-  }\n-  LocalDeviceState* local_device = device_->local_device_state();\n+  auto* se_device = tensorflow::down_cast<PjRtStreamExecutorDevice*>(device());\n+  auto* se_client = tensorflow::down_cast<PjRtStreamExecutorClient*>(client());\n+  LocalDeviceState* local_device = se_device->local_device_state();\n   se::Stream* stream = local_device->GetDeviceToHostStream();\n   auto device_buffer = GetBufferWithUsageHold();\n   if (!device_buffer.ok()) {\n@@ -1526,10 +1426,10 @@ Future<> PjRtStreamExecutorBuffer::ToLiteralHelper(\n   }\n \n   auto [promise, future] = Future<>::MakePromise();\n-  auto usage_event = BufferSequencingEvent::Create(client_->thread_pool());\n+  auto usage_event = BufferSequencingEvent::Create(se_client->thread_pool());\n \n   TransferManager* transfer_manager =\n-      client_->client()->backend().transfer_manager();\n+      se_client->client()->backend().transfer_manager();\n \n   auto device_memory = device_buffer->device_memory();\n   auto definition_events = device_buffer->definition_events();\n@@ -1553,7 +1453,7 @@ Future<> PjRtStreamExecutorBuffer::ToLiteralHelper(\n                        std::shared_ptr<TransposePlan>>>::MakePromise();\n \n   literal.OnReady(\n-      [client = client_, on_device_shape{on_device_shape_},\n+      [client = se_client, on_device_shape{on_device_shape()},\n        promise = std::move(literal_and_transpose_promise)](\n           const absl::StatusOr<MutableLiteralBase*>& value) mutable {\n         if (!value.ok()) {\n@@ -1607,12 +1507,12 @@ Future<> PjRtStreamExecutorBuffer::ToLiteralHelper(\n         promise.Set(std::make_pair(literal, std::move(transpose)));\n       });\n \n-  auto async_to_literal = [client = client_, usage_event,\n+  auto async_to_literal = [client = se_client, usage_event,\n                            device_memory = std::move(device_memory),\n                            definition_events = std::move(definition_events),\n-                           stream, device = device_,\n+                           stream, device = se_device,\n                            transfer_manager = std::move(transfer_manager),\n-                           on_device_shape{on_device_shape_},\n+                           on_device_shape{on_device_shape()},\n                            literal_and_transpose =\n                                std::move(literal_and_transpose_future),\n                            promise = std::move(promise).ToShared(),\n@@ -1737,14 +1637,16 @@ absl::StatusOr<size_t> PjRtStreamExecutorBuffer::GetOnDeviceSizeInBytes()\n \n Future<> PjRtStreamExecutorBuffer::CopyRawToHost(void* dst, int64_t offset,\n                                                  int64_t transfer_size) {\n-  return client_->CopyRawSubBufferToHost(this, Future<void*>(dst), offset,\n-                                         transfer_size);\n+  auto* se_client = tensorflow::down_cast<PjRtStreamExecutorClient*>(client());\n+  return se_client->CopyRawSubBufferToHost(this, Future<void*>(dst), offset,\n+                                           transfer_size);\n }\n \n Future<> PjRtStreamExecutorBuffer::CopyRawToHostFuture(Future<void*> dst,\n                                                        int64_t offset,\n                                                        int64_t transfer_size) {\n-  return client_->CopyRawSubBufferToHost(this, dst, offset, transfer_size);\n+  auto* se_client = tensorflow::down_cast<PjRtStreamExecutorClient*>(client());\n+  return se_client->CopyRawSubBufferToHost(this, dst, offset, transfer_size);\n }\n \n PjRtStreamExecutorBuffer::ScopedHold\n@@ -1763,11 +1665,12 @@ PjRtStreamExecutorBuffer::CopyToDeviceHelper(\n     PjRtMemorySpace* dst_memory_space, LocalDeviceState* transfer_local_device,\n     LocalDeviceState* src_local_device, se::Stream* transfer_stream,\n     const TrackedDeviceBuffer& src_device_buffer) {\n+  auto* se_client = tensorflow::down_cast<PjRtStreamExecutorClient*>(client());\n   TF_ASSIGN_OR_RETURN(std::unique_ptr<PjRtStreamExecutorBuffer> py_buffer,\n                       AllocateDestinationBuffer(\n-                          ShapeUtil::DeviceShapeToHostShape(on_device_shape_),\n+                          ShapeUtil::DeviceShapeToHostShape(on_device_shape()),\n                           dst_device, dst_local_device, transfer_stream,\n-                          /*is_uninitialized_create=*/false, client_,\n+                          /*is_uninitialized_create=*/false, se_client,\n                           /*definition_event=*/nullptr, dst_memory_space));\n \n   ScopedHold dst_device_buffer(py_buffer->GetBufferWithUsageHold());\n@@ -1788,7 +1691,7 @@ PjRtStreamExecutorBuffer::CopyToDeviceHelper(\n                                transfer_local_device =\n                                    std::move(transfer_local_device),\n                                dst_local_device = std::move(dst_local_device),\n-                               client = client_]() mutable {\n+                               client = se_client]() mutable {\n     tsl::profiler::TraceMe traceme(\n         \"PjRtStreamExecutorBuffer::CopyToDeviceHelper::async_copy_to_\"\n         \"device\");\n@@ -1859,8 +1762,10 @@ PjRtStreamExecutorBuffer::CopyToDeviceHelper(\n absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n PjRtStreamExecutorBuffer::CopyToDeviceMemorySpace(\n     PjRtDevice* dst_device, PjRtMemorySpace* dst_memory_space) {\n+  auto* se_client = tensorflow::down_cast<PjRtStreamExecutorClient*>(client());\n+  auto* se_device = tensorflow::down_cast<PjRtStreamExecutorDevice*>(device());\n   // Copying across PjRtClients involves a copy through the host.\n-  if (dst_device->client() != client_) {\n+  if (dst_device->client() != se_client) {\n     TF_ASSIGN_OR_RETURN(std::shared_ptr<Literal> literal, ToLiteralSync());\n     // Avoid use-after-free on `literal` due to unsequenced move and use.\n     Literal* literal_pointer = literal.get();\n@@ -1882,8 +1787,9 @@ PjRtStreamExecutorBuffer::CopyToDeviceMemorySpace(\n       tensorflow::down_cast<PjRtStreamExecutorDevice*>(dst_device)\n           ->GetLocalDeviceState());\n   LocalDeviceState* transfer_local_device =\n-      client_->EnqueueD2DTransfersOnSrcStream() ? device_->local_device_state()\n-                                                : dst_local_device;\n+      se_client->EnqueueD2DTransfersOnSrcStream()\n+          ? se_device->local_device_state()\n+          : dst_local_device;\n   CHECK_EQ(dst_local_device->allocation_model(),\n            transfer_local_device->allocation_model());\n \n@@ -1901,7 +1807,7 @@ PjRtStreamExecutorBuffer::CopyToDeviceMemorySpace(\n       std::pair<std::unique_ptr<PjRtBuffer>, BufferSequencingEventRef>>\n       buffer_and_event_or = CopyToDeviceHelper(\n           dst_device, dst_local_device, dst_memory_space, transfer_local_device,\n-          device_->local_device_state(), transfer_stream, *src_device_buffer);\n+          se_device->local_device_state(), transfer_stream, *src_device_buffer);\n   if (!buffer_and_event_or.ok()) {\n     return buffer_and_event_or.status();\n   }\n@@ -1930,7 +1836,9 @@ void PjRtStreamExecutorBuffer::CopyToRemoteDevice(\n   VLOG(3) << \"PjRtStreamExecutorBuffer::CopyToRemoteDevice\";\n   auto desc = serialized_descriptor.Await();\n   if (desc.ok()) {\n-    client_->CopyToRemoteDevice(this, *desc, std::move(on_done));\n+    auto* se_client =\n+        tensorflow::down_cast<PjRtStreamExecutorClient*>(client());\n+    se_client->CopyToRemoteDevice(this, *desc, std::move(on_done));\n   } else {\n     on_done(desc.status(), /*sends_enqueued=*/false);\n   }\n@@ -1955,7 +1863,9 @@ Future<> PjRtStreamExecutorBuffer::GetReadyFuture() {\n   }\n \n   if (!definition_events.empty()) {\n-    LocalDeviceState* local_device_state = device_->local_device_state();\n+    auto* se_device =\n+        tensorflow::down_cast<PjRtStreamExecutorDevice*>(device());\n+    LocalDeviceState* local_device_state = se_device->local_device_state();\n     auto first_definition_event = definition_events[0];\n     auto async_wait_for_events =\n         [definition_events = std::move(definition_events),"
        },
        {
            "sha": "e393be1c92117372a294b54fbd338678df24bd1b",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.h",
            "status": "modified",
            "additions": 1,
            "deletions": 24,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h?ref=3afe46373df5e1e4399af77051c8a02749ec9fe9",
            "patch": "@@ -550,7 +550,7 @@ class PjRtStreamExecutorClient : public CommonPjRtClient {\n absl::StatusOr<DeviceAssignment> DevicesToDeviceAssignment(\n     absl::Span<const std::vector<PjRtDevice*>> devices);\n \n-class PjRtStreamExecutorBuffer : public CommonPjRtBuffer {\n+class PjRtStreamExecutorBuffer : public CommonPjRtBufferImpl {\n  public:\n   class ScopedHold : public CommonPjRtBuffer::ScopedHold {\n    public:\n@@ -595,25 +595,6 @@ class PjRtStreamExecutorBuffer : public CommonPjRtBuffer {\n   PjRtStreamExecutorBuffer& operator=(const PjRtStreamExecutorBuffer&) = delete;\n   PjRtStreamExecutorBuffer& operator=(PjRtStreamExecutorBuffer&&) = delete;\n \n-  const Shape& on_device_shape() const override { return on_device_shape_; }\n-\n-  absl::StatusOr<Shape> logical_on_device_shape() override;\n-  PjRtMemorySpace* memory_space() const override { return memory_space_; }\n-  PjRtStreamExecutorDevice* device() const override { return device_; }\n-  PjRtPlatformId platform_id() const { return client_->platform_id(); }\n-  absl::string_view platform_name() const { return client_->platform_name(); }\n-  PjRtStreamExecutorClient* client() const override { return client_; }\n-  bool IsEmptyTuple() const {\n-    return on_device_shape_.IsTuple() &&\n-           on_device_shape_.tuple_shapes().size() == 0;\n-  }\n-\n-  absl::StatusOr<std::unique_ptr<ExternalReference>> AcquireExternalReference()\n-      override;\n-\n-  absl::StatusOr<std::unique_ptr<ExternalReference>>\n-  ReleaseDeviceMemoryOwnership(bool wait_for_operations_to_complete) override;\n-\n   using PjRtBuffer::ToLiteralSync;\n   Future<> ToLiteral(MutableLiteralBase* literal) override;\n   Future<> LazyToLiteral(\n@@ -705,10 +686,6 @@ class PjRtStreamExecutorBuffer : public CommonPjRtBuffer {\n       PjRtDevice* dst_device, PjRtMemorySpace* dst_memory_space = nullptr);\n \n   Future<> ToLiteralHelper(Future<MutableLiteralBase*> literal);\n-\n-  PjRtStreamExecutorClient* const client_;\n-  const Shape on_device_shape_;\n-  PjRtStreamExecutorDevice* const device_;\n };\n \n // Allocates the device buffers for a buffer that will be used as the"
        },
        {
            "sha": "fb878b4e96b5497ee7ec313f98751ca2c5d0fee9",
            "filename": "third_party/xla/xla/pjrt/se_raw_buffer.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 25,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc?ref=3afe46373df5e1e4399af77051c8a02749ec9fe9",
            "patch": "@@ -187,29 +187,4 @@ void PjRtStreamExecutorRawBuffer::CopyTo(\n   definition_event_promise->SetError(status);\n }\n \n-std::optional<absl::StatusOr<tsl::RCReference<PjRtRawBuffer>>>\n-CreateGPURawBuffer(PjRtBuffer* buffer) {\n-  if (auto* se_buffer = dynamic_cast<PjRtStreamExecutorBuffer*>(buffer)) {\n-    auto* se_client = dynamic_cast<PjRtStreamExecutorClient*>(buffer->client());\n-    if (se_client == nullptr) {\n-      return absl::InvalidArgumentError(\"invalid se-client\");\n-    }\n-    PjRtStreamExecutorBuffer::ScopedHold hold(\n-        se_buffer->GetBufferWithUsageHold());\n-    if (!hold.ok()) {\n-      return hold.status();\n-    }\n-    if (!hold->device_memory()) {\n-      return absl::InvalidArgumentError(\n-          \"Create raw buffer called on an invalid buffer\");\n-    }\n-    return tsl::MakeRef<PjRtStreamExecutorRawBuffer>(\n-        se_client, se_buffer->memory_space(),\n-        se_buffer->device()->local_device_state(), hold->device_memory());\n-  }\n-  return std::nullopt;\n-}\n-\n-REGISTER_PJRT_RAW_BUFFER_FACTORY(CreateGPURawBuffer);\n-\n }  // namespace xla"
        },
        {
            "sha": "481055eb045a13b601011be0ccdf75777a9e4a95",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3afe46373df5e1e4399af77051c8a02749ec9fe9/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h?ref=3afe46373df5e1e4399af77051c8a02749ec9fe9",
            "patch": "@@ -308,6 +308,13 @@ class TrackedDeviceBuffer : public AbstractTrackedDeviceBuffer {\n     LOG(FATAL) << \"Implement\";\n   }\n \n+  absl::Status WaitUntilBufferReadyOnStream(std::intptr_t stream) override {\n+    for (const BufferSequencingEventRef& event : definition_events()) {\n+      TF_RETURN_IF_ERROR(event->WaitForEventOnExternalStream(stream));\n+    }\n+    return absl::OkStatus();\n+  }\n+\n  private:\n   PjRtDevice* device_;\n "
        }
    ],
    "stats": {
        "total": 243,
        "additions": 61,
        "deletions": 182
    }
}