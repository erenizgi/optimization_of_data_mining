{
    "author": "Arech8",
    "message": "PR #29766: [ROCm] Add bf16 starting from gfx11, bugfix & optimize RocmComputeCapability\n\nImported from GitHub PR https://github.com/openxla/xla/pull/29766\n\n* Bugfix and improve device_description.h::RocmComputeCompatibility\n\n* Enable ALG_DOT_BF16* on rocm with HW support\n\nCopybara import of the project:\n\n--\n6eb7214b7da651ece7571355773e7b4fd52f0bf3 by Aleksei <208770786+Arech8@users.noreply.github.com>:\n\nAdd bf16 starting from gfx11, bugfix & optimize RocmComputeCapability (#303)\n\n* Bugfix and improve device_description.h::RocmComputeCompatibility\n\n* Enable ALG_DOT_BF16* on rocm with HW support\n\n(cherry picked from commit 510ea0628be3d3259def59f5a7b9a01811957474)\n\n--\nc87f68d3f6021d1cd6a1b37bc2479f1d0fe7d9d0 by Aleksei Rechinskii <Aleksei.Rechinskii@amd.com>:\n\nadd operator!= to RocmComputeCapability\n\nI don't think it's useful, as there was never a demand for it, but a reviewer wants it.\n\n--\n485c071f37d6ea0d70a3fe5927d9d919a0514872 by Aleksei Rechinskii <Aleksei.Rechinskii@amd.com>:\n\nAdd tests for main RocmComputeCapability accessors\n\n--\n653adf0bbff9243cbd1407a76bbf2f35385d3eb3 by Aleksei Rechinskii <Aleksei.Rechinskii@amd.com>:\n\nfix formatting of the test file\n\n--\n9f63f70e055f44d039c43097c3f4971ffa1bbcc4 by Aleksei Rechinskii <Aleksei.Rechinskii@amd.com>:\n\nSimplify gfx_version() default value test\n\n--\n3e93169390761c7511fcb027adc79dac9bccda94 by Aleksei Rechinskii <Aleksei.Rechinskii@amd.com>:\n\nRestore gfx11_rx7900() and gfx12_rx8900() for AMD/TF\n\nMerging this change closes #29766\n\nPiperOrigin-RevId: 805430493",
    "sha": "478bd3a4fc256c40333fc52d0f673cc704936025",
    "files": [
        {
            "sha": "8966b283cc7d5bae869534a5e9c61ad59badfc89",
            "filename": "third_party/xla/xla/service/algorithm_util.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 4,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/478bd3a4fc256c40333fc52d0f673cc704936025/third_party%2Fxla%2Fxla%2Fservice%2Falgorithm_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/478bd3a4fc256c40333fc52d0f673cc704936025/third_party%2Fxla%2Fxla%2Fservice%2Falgorithm_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Falgorithm_util.cc?ref=478bd3a4fc256c40333fc52d0f673cc704936025",
            "patch": "@@ -215,7 +215,7 @@ bool IsSupportedByElementalIrEmitter(PrecisionConfig::Algorithm algorithm) {\n // input/output storage types.\n bool IsSupportedDotAlgorithmOnGpu(\n     PrecisionConfig::Algorithm algorithm,\n-    stream_executor::GpuComputeCapability gpu_compute_capability,\n+    const stream_executor::GpuComputeCapability& gpu_compute_capability,\n     PrimitiveType input_storage_type, PrimitiveType output_storage_type) {\n   // Note: We may want to add some complex types here if people request that.\n   const bool is_cuda_ge_ampere =\n@@ -236,6 +236,12 @@ bool IsSupportedDotAlgorithmOnGpu(\n       std::get<se::RocmComputeCapability>(gpu_compute_capability)\n           .gfx9_mi100_or_later();\n \n+  const bool is_rocm_bf16 =\n+      std::holds_alternative<se::RocmComputeCapability>(\n+          gpu_compute_capability) &&\n+      std::get<se::RocmComputeCapability>(gpu_compute_capability)\n+          .has_bf16_dtype_support();\n+\n   switch (algorithm) {\n     case PrecisionConfig::ALG_DOT_ANY_F8_ANY_F8_F32:\n     case PrecisionConfig::ALG_DOT_ANY_F8_ANY_F8_F32_FAST_ACCUM:\n@@ -249,7 +255,7 @@ bool IsSupportedDotAlgorithmOnGpu(\n       return input_storage_type == F16 &&\n              (output_storage_type == F16 || output_storage_type == F32);\n     case PrecisionConfig::ALG_DOT_BF16_BF16_F32:\n-      if (!is_cuda_ge_ampere && !is_rocm_mi100_and_above) return false;\n+      if (!is_cuda_ge_ampere && !is_rocm_bf16) return false;\n       switch (input_storage_type) {\n         case BF16:\n           return output_storage_type == BF16 || output_storage_type == F32;\n@@ -261,8 +267,8 @@ bool IsSupportedDotAlgorithmOnGpu(\n     case PrecisionConfig::ALG_DOT_BF16_BF16_F32_X3:\n     case PrecisionConfig::ALG_DOT_BF16_BF16_F32_X6:\n     case PrecisionConfig::ALG_DOT_BF16_BF16_F32_X9:\n-      return (is_cuda_ge_ampere || is_rocm_mi100_and_above) &&\n-             input_storage_type == F32 && output_storage_type == F32;\n+      return (is_cuda_ge_ampere || is_rocm_bf16) && input_storage_type == F32 &&\n+             output_storage_type == F32;\n     case PrecisionConfig::ALG_DOT_TF32_TF32_F32_X3:\n     case PrecisionConfig::ALG_DOT_TF32_TF32_F32:\n       return (is_cuda_ge_ampere || is_rocm_mi100_and_above) &&"
        },
        {
            "sha": "835bf10f63556ccc2f92855a7bb5ebb4a1c277cb",
            "filename": "third_party/xla/xla/service/algorithm_util.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/478bd3a4fc256c40333fc52d0f673cc704936025/third_party%2Fxla%2Fxla%2Fservice%2Falgorithm_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/478bd3a4fc256c40333fc52d0f673cc704936025/third_party%2Fxla%2Fxla%2Fservice%2Falgorithm_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Falgorithm_util.h?ref=478bd3a4fc256c40333fc52d0f673cc704936025",
            "patch": "@@ -87,7 +87,7 @@ bool IsSupportedByElementalIrEmitter(PrecisionConfig::Algorithm algorithm);\n // input/output storage types.\n bool IsSupportedDotAlgorithmOnGpu(\n     PrecisionConfig::Algorithm algorithm,\n-    stream_executor::GpuComputeCapability gpu_compute_capability,\n+    const stream_executor::GpuComputeCapability& gpu_compute_capability,\n     PrimitiveType input_storage_type, PrimitiveType output_storage_type);\n \n }  // namespace algorithm_util"
        },
        {
            "sha": "751ae3a737aa60ca5fa44cdec4ab5895197e6e7e",
            "filename": "third_party/xla/xla/stream_executor/device_description.h",
            "status": "modified",
            "additions": 102,
            "deletions": 45,
            "changes": 147,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/478bd3a4fc256c40333fc52d0f673cc704936025/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/478bd3a4fc256c40333fc52d0f673cc704936025/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h?ref=478bd3a4fc256c40333fc52d0f673cc704936025",
            "patch": "@@ -20,8 +20,10 @@ limitations under the License.\n #ifndef XLA_STREAM_EXECUTOR_DEVICE_DESCRIPTION_H_\n #define XLA_STREAM_EXECUTOR_DEVICE_DESCRIPTION_H_\n \n+#include <algorithm>\n #include <cassert>\n #include <cstdint>\n+#include <cstring>\n #include <string>\n #include <type_traits>\n #include <utility>\n@@ -30,6 +32,7 @@ limitations under the License.\n \n #include \"absl/algorithm/container.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/match.h\"\n #include \"absl/strings/str_join.h\"\n #include \"absl/strings/str_split.h\"\n #include \"absl/strings/string_view.h\"\n@@ -55,13 +58,49 @@ class RocmComputeCapability {\n \n   std::string gcn_arch_name() const { return gcn_arch_name_; }\n \n+  std::string ToString() const { return gcn_arch_name(); }\n+\n+  RocmComputeCapabilityProto ToProto() const {\n+    RocmComputeCapabilityProto proto;\n+    proto.set_gcn_arch_name(gcn_arch_name_);\n+    return proto;\n+  }\n+\n+  bool operator==(const RocmComputeCapability& other) const {\n+    return gcn_arch_name_ == other.gcn_arch_name_;\n+  }\n+\n+  bool operator!=(const RocmComputeCapability& other) const {\n+    return !this->operator==(other);\n+  }\n+\n   std::string gfx_version() const {\n-    std::vector<std::string> tokens = absl::StrSplit(gcn_arch_name_, ':');\n-    return tokens[0];\n+    //  std::strchr() is faster for the case than std::string::find()\n+    const char* const p_colon = std::strchr(gcn_arch_name_.c_str(), ':');\n+    if (nullptr == p_colon) {\n+      return gcn_arch_name_;  // likely it's the default invalid value\n+    }\n+    return std::string(gcn_arch_name_.c_str(), p_colon);\n   }\n \n+  // note, while there's no particular reason to make the lists public, it won't\n+  // hurt since they are immutable, but keeping them close to methods simplifies\n+  // maintanance.\n+  static constexpr absl::string_view kSupportedGfxVersions[]{\n+      \"gfx900\",   // MI25\n+      \"gfx906\",   // MI50 / MI60\n+      \"gfx908\",   // MI100\n+      \"gfx90a\",   // MI200\n+      \"gfx942\",   // MI300\n+      \"gfx950\",   // MI350\n+      \"gfx1030\",  // RX68xx / RX69xx\n+      \"gfx1100\",  // RX7900\n+      \"gfx1101\",  // RX7700 / RX7800\n+      \"gfx1103\", \"gfx1150\", \"gfx1151\", \"gfx1200\", \"gfx1201\",\n+  };\n+\n   bool is_supported_gfx_version() const {\n-    return absl::c_count(kSupportedGfxVersions, gfx_version()) != 0;\n+    return IsThisGfxInAnyList(kSupportedGfxVersions);\n   }\n \n   std::string supported_gfx_versions_str() const {\n@@ -70,98 +109,116 @@ class RocmComputeCapability {\n \n   bool gfx9_mi100() const { return gfx_version() == \"gfx908\"; }\n \n+  static constexpr absl::string_view kMI100Series[] = {\"gfx908\"};\n+\n   bool gfx9_mi200() const { return gfx_version() == \"gfx90a\"; }\n \n+  static constexpr absl::string_view kMI200Series[] = {\"gfx90a\"};\n+\n   bool gfx9_mi300() const { return gfx_version() == \"gfx942\"; }\n \n   bool gfx9_mi350() const { return gfx_version() == \"gfx950\"; }\n \n-  bool gfx9_mi300_series() const { return gfx9_mi300() || gfx9_mi350(); }\n+  static constexpr absl::string_view kMI300Series[] = {\"gfx942\", \"gfx950\"};\n+  bool gfx9_mi300_series() const { return IsThisGfxInAnyList(kMI300Series); }\n \n   bool gfx9_mi100_or_later() const {\n-    static constexpr absl::string_view kList[] = {\"gfx908\", \"gfx90a\", \"gfx942\",\n-                                                  \"gfx950\"};\n-    return absl::c_count(kList, gfx_version()) != 0;\n+    return IsThisGfxInAnyList(kMI300Series, kMI200Series, kMI100Series);\n   }\n \n   bool gfx9_mi200_or_later() const {\n-    static constexpr absl::string_view kList[] = {\"gfx90a\", \"gfx942\", \"gfx950\"};\n-    return absl::c_count(kList, gfx_version()) != 0;\n+    return IsThisGfxInAnyList(kMI300Series, kMI200Series);\n   }\n \n   bool gfx10_rx68xx() const { return gfx_version() == \"gfx1030\"; }\n \n   bool gfx10_rx69xx() const { return gfx_version() == \"gfx1030\"; }\n \n-  bool gfx11() const { return gfx_version().find(\"gfx11\"); }\n+  bool gfx11() const { return absl::StartsWith(gfx_version(), \"gfx11\"); }\n+\n+  static constexpr absl::string_view kGfx11Discrete[] = {\"gfx1100\", \"gfx1101\"};\n+  bool gfx11_discrete() const { return IsThisGfxInAnyList(kGfx11Discrete); }\n \n-  bool gfx1200() const { return gfx_version() == \"gfx1200\"; }\n+  static constexpr absl::string_view kGfx11Apu[] = {\"gfx1103\", \"gfx1150\",\n+                                                    \"gfx1151\"};\n+  bool gfx11_apu() const { return IsThisGfxInAnyList(kGfx11Apu); }\n \n-  bool gfx1201() const { return gfx_version() == \"gfx1201\"; }\n+  static constexpr absl::string_view kGfx11Rx7900[] = {\"gfx1100\", \"gfx1101\",\n+                                                       \"gfx1102\"};\n+  bool gfx11_rx7900() const {\n+    // TODO(AMD/TF): instead of this, other gfx11*() methods might be better\n+    return IsThisGfxInAnyList(kGfx11Rx7900);\n+  }\n+\n+  bool gfx12() const { return absl::StartsWith(gfx_version(), \"gfx12\"); }\n+\n+  static constexpr absl::string_view kGfx12Discrete[] = {\"gfx1200\", \"gfx1201\"};\n+  bool gfx12_discrete() const { return IsThisGfxInAnyList(kGfx12Discrete); }\n+\n+  bool gfx12_rx8900() const { return gfx12_discrete(); }\n \n   bool has_nhwc_layout_support() const { return gfx9_mi100_or_later(); }\n \n-  bool has_bf16_dtype_support() const { return gfx9_mi100_or_later(); }\n+  bool has_bf16_dtype_support() const {\n+    return gfx9_mi100_or_later() || gfx12() || gfx11();\n+  }\n \n   bool has_fast_fp16_support() const {\n-    return gfx9_mi100_or_later() || gfx10_rx68xx() || gfx10_rx69xx() || gfx11();\n+    return gfx9_mi100_or_later() || gfx11() || gfx10_rx68xx() || gfx10_rx69xx();\n   }\n \n   bool has_mfma_instr_support() const { return gfx9_mi100_or_later(); }\n \n   bool has_amd_matrix_core() const {\n-    return (gfx9_mi100_or_later() || gfx_version().find(\"gfx11\") ||\n-            gfx_version().find(\"gfx12\"));\n+    return gfx9_mi100_or_later() || gfx12() || gfx11();\n   }\n \n   bool has_packed_fp16_atomics_support() const { return gfx9_mi100_or_later(); }\n \n   bool has_packed_bf16_atomics_support() const { return gfx9_mi300_series(); }\n \n   bool fence_before_barrier() const {\n-    return gfx_version() != \"gfx900\" && gfx_version() != \"gfx906\";\n+    static constexpr absl::string_view kList[] = {\"gfx900\", \"gfx906\"};\n+    return !IsThisGfxInAnyList(kList);\n   }\n \n   bool has_hipblaslt() const {\n-    return gfx9_mi200_or_later() || gfx1200() || gfx1201();\n+    return IsThisGfxInAnyList(kMI300Series, kMI200Series, kGfx12Discrete,\n+                              kGfx11Discrete, kGfx11Apu);\n   }\n \n   bool has_fp8_support() const {\n     return has_ocp_fp8_support() || has_nanoo_fp8_support();\n   }\n \n-  bool has_ocp_fp8_support() const {\n-    return gfx1200() || gfx1201() || gfx9_mi350();\n-  }\n+  bool has_ocp_fp8_support() const { return gfx9_mi350() || gfx12_discrete(); }\n \n   bool has_nanoo_fp8_support() const { return gfx9_mi300(); }\n \n-  std::string ToString() const { return gcn_arch_name(); }\n-\n-  RocmComputeCapabilityProto ToProto() const {\n-    RocmComputeCapabilityProto proto;\n-    proto.set_gcn_arch_name(gcn_arch_name_);\n-    return proto;\n-  }\n-\n-  bool operator==(const RocmComputeCapability& other) const {\n-    return gcn_arch_name_ == other.gcn_arch_name_;\n-  }\n+  /// \\brief Invalid gfx id for default gcn_arch_name_ value and testing\n+  static constexpr absl::string_view kInvalidGfx = \"gfx000\";\n \n  private:\n-  std::string gcn_arch_name_ = \"gfx000\";  // default to invalid arch.\n-\n-  static constexpr absl::string_view kSupportedGfxVersions[]{\n-      \"gfx900\",   // MI25\n-      \"gfx906\",   // MI50 / MI60\n-      \"gfx908\",   // MI100\n-      \"gfx90a\",   // MI200\n-      \"gfx942\",   // MI300\n-      \"gfx950\",   // MI355\n-      \"gfx1030\",  // RX68xx / RX69xx\n-      \"gfx1100\",  // RX7900\n-      \"gfx1101\", \"gfx1200\", \"gfx1201\",\n-  };\n+  /// \\brief Takes one or more arrays of string-like objects and tests if the\n+  /// result of `gfx_version()` matches to any string in any of the arrays.\n+  template <typename... ArrayOfStrings>\n+  bool IsThisGfxInAnyList(ArrayOfStrings&&... arr) const {\n+    static_assert(sizeof...(arr) >= 1);\n+    const auto gfx = gfx_version();\n+    return (implIsThisGfxInAnyList(std::begin(arr), std::end(arr), gfx) || ...);\n+  }\n+\n+  /// \\brief Template-less implementation of IsThisGfxInAnyList().\n+  /// \\warning Don't use directly!\n+  bool implIsThisGfxInAnyList(const absl::string_view* beg,\n+                              const absl::string_view* end,\n+                              const std::string& gfx) const {\n+    return std::any_of(beg, end, [&gfx = gfx](const absl::string_view& s) {\n+      return gfx == s;\n+    });\n+  }\n+\n+  std::string gcn_arch_name_{kInvalidGfx};  // default to invalid arch.\n };\n \n using GpuComputeCapability ="
        },
        {
            "sha": "51443ddf666f865065472d6f8c2f23a85886df85",
            "filename": "third_party/xla/xla/stream_executor/device_description_test.cc",
            "status": "modified",
            "additions": 83,
            "deletions": 0,
            "changes": 83,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/478bd3a4fc256c40333fc52d0f673cc704936025/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/478bd3a4fc256c40333fc52d0f673cc704936025/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description_test.cc?ref=478bd3a4fc256c40333fc52d0f673cc704936025",
            "patch": "@@ -14,6 +14,8 @@ limitations under the License.\n ==============================================================================*/\n #include \"xla/stream_executor/device_description.h\"\n \n+#include <string>\n+\n #include <gtest/gtest.h>\n #include \"xla/stream_executor/semantic_version.h\"\n \n@@ -33,5 +35,86 @@ TEST(DeviceDescription, DefaultConstruction) {\n   EXPECT_EQ(desc.pci_bus_id(), \"<undefined>\");\n }\n \n+///////////////////////////////////////////////////////////////////////////////\n+// class RocmComputeCapability tests. To be moved to a separate file once the\n+// class is refactored out of device_description.h\n+\n+TEST(RocmComputeCapability, GfxVersion) {\n+  RocmComputeCapability rcc0;  // default constructed\n+  auto default_gcn_arch_name = RocmComputeCapability::kInvalidGfx;\n+  // failure is serious enough to not expect the rest could pass\n+  ASSERT_EQ(default_gcn_arch_name, rcc0.gfx_version());\n+\n+  const std::string gfx{\"some_string\"};\n+  std::string gcn_arch{gfx};\n+  ASSERT_EQ(gfx, RocmComputeCapability{gcn_arch}.gfx_version());\n+\n+  gcn_arch.append(\":tail\");\n+  ASSERT_EQ(gfx, RocmComputeCapability{gcn_arch}.gfx_version());\n+\n+  gcn_arch.append(\":even_longer\");\n+  ASSERT_EQ(gfx, RocmComputeCapability{gcn_arch}.gfx_version());\n+}\n+\n+TEST(RocmComputeCapability, IsSupportedGfxVersion) {\n+  ASSERT_TRUE(RocmComputeCapability{\"gfx900\"}.is_supported_gfx_version());\n+  ASSERT_TRUE(RocmComputeCapability{\"gfx1201\"}.is_supported_gfx_version());\n+  ASSERT_TRUE(RocmComputeCapability{\"gfx942\"}.is_supported_gfx_version());\n+  ASSERT_FALSE(RocmComputeCapability{\"some_string\"}.is_supported_gfx_version());\n+}\n+\n+TEST(RocmComputeCapability, Accessors) {\n+  // there's not much point in testing individual trivial implementations as\n+  // this require to put here the whole knowledge of RocmComputeCapability.\n+  // This will make maintanance of the class unnecessary more painful.\n+  // Testing only the most complicated methods, basically IsThisGfxInAnyList().\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx942\"}.gfx9_mi300_series());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx942x\"}.gfx9_mi300_series());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx950\"}.gfx9_mi300_series());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx951\"}.gfx9_mi300_series());\n+\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx942\"}.gfx9_mi200_or_later());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx942x\"}.gfx9_mi200_or_later());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx950\"}.gfx9_mi200_or_later());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx951\"}.gfx9_mi200_or_later());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx90a\"}.gfx9_mi200_or_later());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx90x\"}.gfx9_mi200_or_later());\n+\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx942\"}.gfx9_mi100_or_later());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx942x\"}.gfx9_mi100_or_later());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx950\"}.gfx9_mi100_or_later());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx951\"}.gfx9_mi100_or_later());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx90a\"}.gfx9_mi100_or_later());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx90x\"}.gfx9_mi100_or_later());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx908\"}.gfx9_mi100_or_later());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx907\"}.gfx9_mi100_or_later());\n+\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx11\"}.gfx11());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx10\"}.gfx11());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx12\"}.gfx11());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx1100\"}.gfx11());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx11xx\"}.gfx11());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx11xxblabla\"}.gfx11());\n+\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx12\"}.gfx12());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx11\"}.gfx12());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx13\"}.gfx12());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx1200\"}.gfx12());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx12xx\"}.gfx12());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx12xxblabla\"}.gfx12());\n+\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx12\"}.fence_before_barrier());\n+  EXPECT_TRUE(RocmComputeCapability{\"anything\"}.fence_before_barrier());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx900\"}.fence_before_barrier());\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx906\"}.fence_before_barrier());\n+\n+  EXPECT_FALSE(RocmComputeCapability{\"gfx900\"}.has_hipblaslt());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx942\"}.has_hipblaslt());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx90a\"}.has_hipblaslt());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx1200\"}.has_hipblaslt());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx1100\"}.has_hipblaslt());\n+  EXPECT_TRUE(RocmComputeCapability{\"gfx1103\"}.has_hipblaslt());\n+}\n+\n }  // namespace\n }  // namespace stream_executor"
        }
    ],
    "stats": {
        "total": 246,
        "additions": 196,
        "deletions": 50
    }
}