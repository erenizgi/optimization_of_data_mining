{
    "author": "basioli-k",
    "message": "[XLA:GPU][codegen] Emit tensor dialect for bitcast and implement lowering of bitcast from tensor dialect to triton.\n\nPiperOrigin-RevId: 819833904",
    "sha": "948d0df40909851200a4803ef304ba2c5842284c",
    "files": [
        {
            "sha": "bc310470ee2420f293655add0c029188adcf1fe5",
            "filename": "third_party/xla/xla/backends/gpu/codegen/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD?ref=948d0df40909851200a4803ef304ba2c5842284c",
            "patch": "@@ -270,6 +270,7 @@ cc_library(\n         \"@llvm-project//llvm:ir_headers\",\n         \"@llvm-project//mlir:IR\",\n         \"@llvm-project//mlir:LLVMDialect\",\n+        \"@llvm-project//mlir:TensorDialect\",\n     ],\n )\n "
        },
        {
            "sha": "9ccc4c6c5b673893de2a3c00913813a153d34998",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=948d0df40909851200a4803ef304ba2c5842284c",
            "patch": "@@ -691,7 +691,7 @@ absl::StatusOr<ScalarOrTensor> EmitTiledBitcast(\n                   GetPaddedTileSizes(tiled_bitcast.operand(0)->tile_sizes()),\n                   output_element_type)\n             : output_element_type;\n-    input = b.create<ttir::BitcastOp>(output_type, input);\n+    input = b.create<mlir::tensor::BitcastOp>(output_type, input);\n     input_shape.set_element_type(output_shape.element_type());\n   }\n \n@@ -2305,6 +2305,7 @@ absl::Status LowerXTileToTriton(mlir::ModuleOp xtile_dialect_module,\n     // Disable verifier because the Triton code may be invalid due to the\n     // unsupported types.\n     pm.enableVerifier(/*enabled=*/false);\n+    pm.addPass(mlir::triton::xla::CreateTensorLowerToTritonPass());\n     pm.addPass(mlir::triton::xla::CreateStableHLOLowerToTritonPass());\n     if (mlir::failed(pm.run(xtile_dialect_module))) {\n       return CreateInternalError("
        },
        {
            "sha": "712bbd1af831f02b24109c8e4d52a8164f260f76",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_shared_dialect_test.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc?ref=948d0df40909851200a4803ef304ba2c5842284c",
            "patch": "@@ -68,6 +68,35 @@ CHECK: %[[RES:.*]] = stablehlo.transpose %[[ARG:.*]], dims = [1, 0] : (tensor<32\n )\"));\n }\n \n+TEST_F(XTileDialectTest, TestEmittingTensorBitcast) {\n+  constexpr absl::string_view kHloText = R\"(\n+HloModule t, is_scheduled=true\n+\n+bitcast_fusion {\n+  p0 = f32[150,160] parameter(0)\n+  ROOT bitcast_convert = s32[150,160] bitcast(p0)\n+}\n+\n+ENTRY e {\n+  p0 = f32[150,160] parameter(0)\n+  ROOT custom-call = s32[150,160] fusion(p0), kind=kCustom,\n+    calls=bitcast_fusion,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton\"}}\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(kHloText));\n+\n+  BlockLevelParameters block_level_parameters;\n+  block_level_parameters.output_tile_sizes = {{16, 32}};\n+\n+  TF_EXPECT_OK(CreateXTileIrAndFileCheck(\n+      this, *module->GetComputationWithName(\"bitcast_fusion\"),\n+      block_level_parameters,\n+      R\"(\n+CHECK: %[[RES:.*]] = tensor.bitcast %[[ARG:.*]] : tensor<16x32xf32> to tensor<16x32xi32>\n+)\"));\n+}\n+\n }  // namespace\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "c9999c7d6e80b4175f794c286702f770603fa364",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD?ref=948d0df40909851200a4803ef304ba2c5842284c",
            "patch": "@@ -36,6 +36,7 @@ cc_library(\n         \"int4_passes.cc\",\n         \"round_f32_to_tf32_for_tf32_dot_pass.cc\",\n         \"stablehlo_lower_to_triton.cc\",\n+        \"tensor_lower_to_triton.cc\",\n         \"triton_xla_convert_unsupported_types.cc\",\n         \"triton_xla_extract_insert_to_triton_pass.cc\",\n         \"triton_xla_fold_transpose_pass.cc\",\n@@ -78,6 +79,7 @@ cc_library(\n         \"@llvm-project//mlir:SCFDialect\",\n         \"@llvm-project//mlir:SCFTransforms\",\n         \"@llvm-project//mlir:Support\",\n+        \"@llvm-project//mlir:TensorDialect\",\n         \"@llvm-project//mlir:TransformUtils\",\n         \"@stablehlo//:stablehlo_ops\",\n         \"@triton//:TritonDialects\","
        },
        {
            "sha": "0a5df5e64bf15b6afca5cf46e103c7b8c21d544c",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/passes.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h?ref=948d0df40909851200a4803ef304ba2c5842284c",
            "patch": "@@ -46,6 +46,7 @@ std::unique_ptr<mlir::Pass> CreateTritonXLALowerBlockBarrierPass();\n std::unique_ptr<mlir::Pass> CreateTritonXLAConvertUnsupportedTypesPass();\n std::unique_ptr<mlir::Pass> CreateTritonXLALowerRemoteAccessPass();\n std::unique_ptr<mlir::Pass> CreateStableHLOLowerToTritonPass();\n+std::unique_ptr<mlir::Pass> CreateTensorLowerToTritonPass();\n \n // Returns true if the `op` contains an operation in it's regions that satisfies\n // the `fn`."
        },
        {
            "sha": "82af6d296bd09989c8e07742fa637919762c783b",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/passes.td",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td?ref=948d0df40909851200a4803ef304ba2c5842284c",
            "patch": "@@ -200,4 +200,14 @@ def StableHLOLowerToTritonPass\n   let constructor = \"CreateStableHLOLowerToTritonPass()\";\n }\n \n+def TensorLowerToTritonPass\n+    : Pass<\"tensor-lower-to-triton\", \"mlir::ModuleOp\"> {\n+  let summary = \"Lowers tensor operations to their Triton equivalent.\";\n+  let dependentDialects = [\n+    \"tensor::TensorDialect\",\n+    \"triton::TritonDialect\"\n+  ];\n+  let constructor = \"CreateTensorLowerToTritonPass()\";\n+}\n+\n #endif  // XLA_BACKENDS_GPU_CODEGEN_TRITON_PASSES_TD_"
        },
        {
            "sha": "a23da3276b7b84245c85f44c58dc5a542a03ac5a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/stablehlo_lower_to_triton.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc?ref=948d0df40909851200a4803ef304ba2c5842284c",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"llvm/ADT/SmallVector.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n+#include \"mlir/IR/Diagnostics.h\"\n #include \"mlir/IR/PatternMatch.h\"\n #include \"mlir/IR/Value.h\"\n #include \"mlir/Pass/Pass.h\""
        },
        {
            "sha": "b729dd71366c11599f192d2dab80f66f25901590",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tensor_lower_to_triton.cc",
            "status": "added",
            "additions": 76,
            "deletions": 0,
            "changes": 76,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftensor_lower_to_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftensor_lower_to_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftensor_lower_to_triton.cc?ref=948d0df40909851200a4803ef304ba2c5842284c",
            "patch": "@@ -0,0 +1,76 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdint>\n+#include <memory>\n+#include <utility>\n+\n+#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n+#include \"mlir/IR/BuiltinTypeInterfaces.h\"\n+#include \"mlir/IR/Diagnostics.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Support/LogicalResult.h\"\n+#include \"mlir/Transforms/DialectConversion.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"triton/Dialect/Triton/IR/Dialect.h\"\n+\n+namespace mlir::triton::xla {\n+\n+namespace ttir = ::mlir::triton;\n+\n+#define GEN_PASS_DEF_TENSORLOWERTOTRITONPASS\n+#include \"xla/backends/gpu/codegen/triton/transforms/passes.h.inc\"\n+\n+namespace {\n+\n+class LowerBitcast : public mlir::OpRewritePattern<tensor::BitcastOp> {\n+ public:\n+  using OpRewritePattern::OpRewritePattern;\n+\n+ private:\n+  mlir::LogicalResult matchAndRewrite(\n+      tensor::BitcastOp op, mlir::PatternRewriter& rewriter) const override {\n+    rewriter.replaceOpWithNewOp<ttir::BitcastOp>(op, op.getResult().getType(),\n+                                                 op.getOperand());\n+    return mlir::success();\n+  }\n+};\n+\n+// TODO(basioli): Consider fusing this with the stablehlo lowering pass into a\n+// single xtile to triton lowering pass.\n+class TensorLowerToTritonPass\n+    : public impl::TensorLowerToTritonPassBase<TensorLowerToTritonPass> {\n+ public:\n+  void runOnOperation() override {\n+    mlir::MLIRContext* mlir_context = &getContext();\n+    mlir::RewritePatternSet patterns(mlir_context);\n+    patterns.add<LowerBitcast>(mlir_context);\n+\n+    if (mlir::failed(\n+            mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {\n+      return signalPassFailure();\n+    }\n+  }\n+};\n+\n+}  // namespace\n+\n+std::unique_ptr<Pass> CreateTensorLowerToTritonPass() {\n+  return std::make_unique<TensorLowerToTritonPass>();\n+}\n+\n+}  // namespace mlir::triton::xla"
        },
        {
            "sha": "822ecb88da2de3b01441b765d78bcbf41020aee4",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/stable_hlo_to_triton_lowering.mlir",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir?ref=948d0df40909851200a4803ef304ba2c5842284c",
            "patch": "@@ -8,4 +8,4 @@ func.func @lower_transpose(%arg0: tensor<2x4x8xf32>) -> tensor<8x2x4xf32> {\n   %0 = stablehlo.transpose %arg0, dims = [2, 0, 1] : (tensor<2x4x8xf32>) -> tensor<8x2x4xf32>\n   // CHECK: return %[[RES]] : tensor<8x2x4xf32>\n   return %0 : tensor<8x2x4xf32>\n-}\n+}\n\\ No newline at end of file"
        },
        {
            "sha": "6ce9f505c8f41d75f0be39f66bb5c49cdb0c8cee",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/tensor_to_triton_lowering.mlir",
            "status": "added",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftensor_to_triton_lowering.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/948d0df40909851200a4803ef304ba2c5842284c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftensor_to_triton_lowering.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftensor_to_triton_lowering.mlir?ref=948d0df40909851200a4803ef304ba2c5842284c",
            "patch": "@@ -0,0 +1,13 @@\n+// RUN: xla-opt %s -split-input-file \\\n+// RUN: -tensor-lower-to-triton \\\n+// RUN: | FileCheck %s\n+\n+//TODO(basioli): Consider fusing this and stablehlo_to_triton_lowering.mlir into xtile_to_triton_lowering.mlir\n+\n+// CHECK: func @lower_bitcast(%[[ARG:.*]]: tensor<2x4x8xf32>) -> tensor<2x4x8xi32>\n+func.func @lower_bitcast(%arg0: tensor<2x4x8xf32>) -> tensor<2x4x8xi32> {\n+  // CHECK: %[[RES:.*]] = tt.bitcast %[[ARG]] : tensor<2x4x8xf32> -> tensor<2x4x8xi32>\n+  %0 = tensor.bitcast %arg0 : tensor<2x4x8xf32> to tensor<2x4x8xi32>\n+  // CHECK: return %[[RES]] : tensor<2x4x8xi32>\n+  return %0 : tensor<2x4x8xi32>\n+}"
        }
    ],
    "stats": {
        "total": 138,
        "additions": 136,
        "deletions": 2
    }
}