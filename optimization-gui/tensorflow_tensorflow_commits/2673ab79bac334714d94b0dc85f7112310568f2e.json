{
    "author": "golechwierowicz",
    "message": "Remove newline from documentation so that markdown renders it correctly\n\nPiperOrigin-RevId: 809031639",
    "sha": "2673ab79bac334714d94b0dc85f7112310568f2e",
    "files": [
        {
            "sha": "4c854242a7b1530699c983488b6235a424e43858",
            "filename": "third_party/xla/docs/flags_guidance.md",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2673ab79bac334714d94b0dc85f7112310568f2e/third_party%2Fxla%2Fdocs%2Fflags_guidance.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2673ab79bac334714d94b0dc85f7112310568f2e/third_party%2Fxla%2Fdocs%2Fflags_guidance.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Fflags_guidance.md?ref=2673ab79bac334714d94b0dc85f7112310568f2e",
            "patch": "@@ -81,8 +81,7 @@ Flag                                            | Type                 | Notes\n | :---- | :---- | :----- |\n | `xla_gpu_enable_latency_hiding_scheduler` | Boolean (true/false) |This flag enables latency hiding schedulers to overlap asynchronous communication with computation efficiently. The default value is False. |\n | `xla_gpu_enable_triton_gemm` | Boolean (true/false) | Use Triton-based matrix multiplication. |\n-| `xla_gpu_enable_command_buffer` | List of CommandBufferCmdType | Which kind of\n-commands should be captured in command buffers. |\n+| `xla_gpu_enable_command_buffer` | List of CommandBufferCmdType | Which kind of commands should be captured in command buffers. |\n | `xla_gpu_all_reduce_combine_threshold_bytes` | Integer (bytes) | These flags tune when to combine multiple small AllGather / ReduceScatter / AllReduce into one big AllGather / ReduceScatter / AllReduce to reduce time spent on cross-device communication. For example, for the AllGather / ReduceScatter thresholds on a Transformer-based workload, consider tuning them high enough so as to combine at least a Transformer Layerâ€™s weight AllGather / ReduceScatter. By default, the combine_threshold_bytes is set to 256. |\n | `xla_gpu_all_gather_combine_threshold_bytes` | Integer (bytes) | See xla_gpu_all_reduce_combine_threshold_bytes above. |\n | `xla_gpu_reduce_scatter_combine_threshold_bytes` | Integer (bytes) | See xla_gpu_all_reduce_combine_threshold_bytes above. |"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 1,
        "deletions": 2
    }
}