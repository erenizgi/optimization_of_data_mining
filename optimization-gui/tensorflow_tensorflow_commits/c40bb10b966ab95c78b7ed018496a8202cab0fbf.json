{
    "author": "tensorflower-gardener",
    "message": "Add the option to dump before/after autotuned instructions in AutotunerConfig.\n\n- This change is required to still support the functionality of xla_gpu_dump_autotuned_gemm_fusions in the new infra.\n\nPiperOrigin-RevId: 826161466",
    "sha": "c40bb10b966ab95c78b7ed018496a8202cab0fbf",
    "files": [
        {
            "sha": "87fa53104ca953e352922f10623cd4f48445dc5c",
            "filename": "third_party/xla/xla/backends/autotuner/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c40bb10b966ab95c78b7ed018496a8202cab0fbf/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c40bb10b966ab95c78b7ed018496a8202cab0fbf/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD?ref=c40bb10b966ab95c78b7ed018496a8202cab0fbf",
            "patch": "@@ -40,8 +40,10 @@ cc_library(\n         \"//xla:autotuning_proto_cc\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/pjrt/distributed:key_value_store_interface\",\n+        \"//xla/service:dump\",\n         \"//xla/service:executable\",\n         \"//xla/service:shaped_buffer\",\n+        \"//xla/tools:hlo_decomposer_lib\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n@@ -86,6 +88,7 @@ xla_cc_test(\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n+        \"//xla/tsl/testing:temporary_directory\",\n         \"//xla/tsl/util/proto:proto_matchers\",\n         \"//xla/tsl/util/proto:proto_utils\",\n         \"@com_google_absl//absl/status\","
        },
        {
            "sha": "850bf0eabe140750b1692c36a7acd47bcdba67a2",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c40bb10b966ab95c78b7ed018496a8202cab0fbf/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c40bb10b966ab95c78b7ed018496a8202cab0fbf/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc?ref=c40bb10b966ab95c78b7ed018496a8202cab0fbf",
            "patch": "@@ -46,8 +46,10 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_print_options.h\"\n #include \"xla/pjrt/distributed/key_value_store_interface.h\"\n+#include \"xla/service/dump.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/shaped_buffer.h\"\n+#include \"xla/tools/hlo_decomposer.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -158,6 +160,9 @@ absl::Status Autotuner::Autotune(HloModule* module,\n     CHECK(!instructions.empty());\n     TF_ASSIGN_OR_RETURN(Config config, GetConfig(instructions[0]));\n     CodegenBackend* codegen_backend = config.codegen_backend;\n+    if (autotune_config_.dump_hlos) {\n+      TF_RETURN_IF_ERROR(DumpHlo(instructions[0], config));\n+    }\n     for (auto* instr : instructions) {\n       TF_RETURN_IF_ERROR(\n           codegen_backend->ApplyConfig(*instr, *config.backend_config));\n@@ -251,6 +256,9 @@ absl::Status Autotuner::Autotune(HloModule* module,\n     CHECK(cached_config.has_value())\n         << \"Sharding autotuning failed: no config found for HLO: \" +\n                instructions[0]->ToString();\n+    if (autotune_config_.dump_hlos) {\n+      TF_RETURN_IF_ERROR(DumpHlo(instructions[0], *cached_config));\n+    }\n     CodegenBackend* codegen_backend = cached_config->codegen_backend;\n     for (auto* instr : instructions) {\n       TF_RETURN_IF_ERROR(\n@@ -264,6 +272,9 @@ absl::Status Autotuner::Autotune(HloModule* module,\n absl::Status Autotuner::Autotune(HloInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(Config config, GetConfig(instr));\n   CodegenBackend* codegen_backend = config.codegen_backend;\n+  if (autotune_config_.dump_hlos) {\n+    TF_RETURN_IF_ERROR(DumpHlo(instr, config));\n+  }\n   TF_RETURN_IF_ERROR(\n       codegen_backend->ApplyConfig(*instr, *config.backend_config));\n   return DumpLogsToFile();\n@@ -531,6 +542,22 @@ absl::StatusOr<Autotuner::ConfigResult> Autotuner::PickBestConfig(\n   return std::move(*best_result);\n }\n \n+absl::Status Autotuner::DumpHlo(HloInstruction* instr, const Config& config) {\n+  const HloModule* parent_module = instr->GetModule();\n+  std::unique_ptr<HloModule> module = ExtractInstructionIntoNewModule(*instr);\n+  module->set_name(std::string(instr->name()));\n+  std::string id =\n+      absl::StrCat(\"autotuner_\", dump_counter_++, \".\", instr->name());\n+  DumpToFileInDirOrStdout(*parent_module, \"\", absl::StrCat(id, \".before.txt\"),\n+                          module->ToString());\n+  HloInstruction* root = module->entry_computation()->root_instruction();\n+  TF_RETURN_IF_ERROR(\n+      config.codegen_backend->ApplyConfig(*root, *config.backend_config));\n+  DumpToFileInDirOrStdout(*parent_module, \"\", absl::StrCat(id, \".after.txt\"),\n+                          module->ToString());\n+  return absl::OkStatus();\n+}\n+\n absl::StatusOr<ScopedShapedBuffer> Autotuner::GetReferenceOutput(\n     std::vector<ExecutableCandidate>& candidates, InputBuffers& input_buffers) {\n   for (auto& candidate : candidates) {"
        },
        {
            "sha": "ee7c63c360b4a74f54908f0104e35ce9a5e97d6b",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c40bb10b966ab95c78b7ed018496a8202cab0fbf/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c40bb10b966ab95c78b7ed018496a8202cab0fbf/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h?ref=c40bb10b966ab95c78b7ed018496a8202cab0fbf",
            "patch": "@@ -82,6 +82,9 @@ struct AutotuneConfig {\n   // Note: If cache is provided, the cached config will be used instead of the\n   // default config.\n   bool use_default_config = false;\n+  // If true, dump the autotuned instructions to the modules's xla_dump_to or\n+  // to stdout if not set.\n+  bool dump_hlos = false;\n };\n \n class Autotuner {\n@@ -205,13 +208,16 @@ class Autotuner {\n   void LogConfigResults(const HloInstruction& instr,\n                         const std::vector<ConfigResult>& results);\n   absl::Status DumpLogsToFile();\n+  // Dumps HLO before and after applying the config.\n+  absl::Status DumpHlo(HloInstruction* instr, const Config& config);\n \n   std::vector<std::unique_ptr<CodegenBackend>> codegen_backends_;\n   std::unique_ptr<Profiler> profiler_;\n   AutotuneConfig autotune_config_;\n   std::unique_ptr<AutotunerCacheInterface> cache_;\n   tsl::thread::ThreadPool* thread_pool_;\n   AutotuningLogs logs_;\n+  int dump_counter_ = 0;\n };\n }  // namespace xla\n "
        },
        {
            "sha": "2357b5dd5c270b84d6e0f04fd709206e4710556f",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner_test.cc",
            "status": "modified",
            "additions": 73,
            "deletions": 26,
            "changes": 99,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c40bb10b966ab95c78b7ed018496a8202cab0fbf/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c40bb10b966ab95c78b7ed018496a8202cab0fbf/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc?ref=c40bb10b966ab95c78b7ed018496a8202cab0fbf",
            "patch": "@@ -50,6 +50,7 @@ limitations under the License.\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n+#include \"xla/tsl/testing/temporary_directory.h\"\n #include \"xla/tsl/util/proto/proto_matchers.h\"\n #include \"xla/tsl/util/proto/proto_utils.h\"\n #include \"tsl/platform/path.h\"\n@@ -140,7 +141,9 @@ using absl_testing::StatusIs;\n using ::testing::_;\n using ::testing::AtMost;\n using ::testing::ByMove;\n+using ::testing::MatchesRegex;\n using ::testing::Return;\n+using ::testing::UnorderedElementsAre;\n using tsl::proto_utils::ToDurationProto;\n \n se::DeviceDescription CreateDummyDeviceDescription() {\n@@ -150,41 +153,45 @@ se::DeviceDescription CreateDummyDeviceDescription() {\n }\n \n absl::StatusOr<std::unique_ptr<Autotuner>> SetupAutotunerWithExpectations(\n-    HloOpcode instr_to_autotune,\n+    std::vector<HloOpcode> instrs_to_autotune,\n     std::vector<std::pair<HloOpcode, int>> instrs_to_apply_config_and_count,\n-    std::unique_ptr<MockAutotunerCache> cache = nullptr) {\n-  std::vector<std::unique_ptr<BackendConfig>> configs;\n-  configs.push_back(GetTestConfig(\"another_config\"));\n-  configs.push_back(GetTestConfig(\"best_config\"));\n-\n+    std::unique_ptr<MockAutotunerCache> cache = nullptr,\n+    bool dump_hlos = false) {\n   auto backend = std::make_unique<MockCodegenBackend>();\n+  auto profiler = std::make_unique<MockProfiler>();\n   EXPECT_CALL(*backend, name()).WillRepeatedly(Return(\"mock_backend\"));\n-  EXPECT_CALL(*backend,\n-              GetSupportedConfigs(InstructionMatcher(instr_to_autotune)))\n-      .WillOnce(Return(std::move(configs)));\n+  for (const auto& instr_to_autotune : instrs_to_autotune) {\n+    std::vector<std::unique_ptr<BackendConfig>> configs;\n+    // Best config is just by notion here since profiler time is same for all.\n+    configs.push_back(GetTestConfig(\"best_config\"));\n+    configs.push_back(GetTestConfig(\"another_config\"));\n+    EXPECT_CALL(*backend,\n+                GetSupportedConfigs(InstructionMatcher(instr_to_autotune)))\n+        .WillOnce(Return(std::move(configs)));\n+  }\n+  EXPECT_CALL(*profiler, CreateInputBuffers(_))\n+      .Times(instrs_to_autotune.size())\n+      .WillRepeatedly([] { return std::make_unique<InputBuffers>(); });\n   EXPECT_CALL(*backend, Compile(_, _))\n-      .WillOnce(Return(std::unique_ptr<Executable>()))\n-      .WillOnce(Return(std::unique_ptr<Executable>()));\n+      .Times(2 * instrs_to_autotune.size())\n+      .WillRepeatedly([] { return std::unique_ptr<Executable>(); });\n+  EXPECT_CALL(*profiler, Profile(_, _))\n+      .Times(2 * instrs_to_autotune.size())\n+      .WillRepeatedly([] { return ProfileResult({absl::Seconds(1)}); });\n+\n   for (const auto& [instr_to_apply_config, count] :\n        instrs_to_apply_config_and_count) {\n     EXPECT_CALL(*backend,\n                 ApplyConfig(InstructionMatcher(instr_to_apply_config), _))\n         .Times(count)\n         .WillRepeatedly(Return(absl::OkStatus()));\n   }\n-\n-  auto profiler = std::make_unique<MockProfiler>();\n-  auto device_description = CreateDummyDeviceDescription();\n-  EXPECT_CALL(*profiler, CreateInputBuffers(_))\n-      .WillOnce(Return(std::make_unique<InputBuffers>()));\n-  EXPECT_CALL(*profiler, Profile(_, _))\n-      .WillOnce(Return(ProfileResult({absl::Seconds(2)})))\n-      .WillOnce(Return(ProfileResult({absl::Seconds(1)})));\n-\n   std::vector<std::unique_ptr<CodegenBackend>> backends;\n   backends.push_back(std::move(backend));\n-  return Autotuner::Create(std::move(backends), std::move(profiler),\n-                           GetTestAutotuneConfig(), std::move(cache));\n+  AutotuneConfig config = GetTestAutotuneConfig();\n+  config.dump_hlos = dump_hlos;\n+  return Autotuner::Create(std::move(backends), std::move(profiler), config,\n+                           std::move(cache));\n }\n \n constexpr absl::string_view kHlo = R\"(\n@@ -376,7 +383,7 @@ TEST_F(AutotunerTest, AutotuneModuleFollowsFilter) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::unique_ptr<Autotuner> autotuner,\n       SetupAutotunerWithExpectations(\n-          /*instr_to_autotune=*/HloOpcode::kCopy,\n+          /*instrs_to_autotune=*/{HloOpcode::kCopy},\n           /*instrs_to_apply_config_and_count=*/{{HloOpcode::kCopy, 1}}));\n \n   EXPECT_THAT(autotuner->Autotune(module.get(), should_autotune),\n@@ -393,7 +400,7 @@ TEST_F(AutotunerTest, AutotuneModuleWithDuplicateInstructions) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::unique_ptr<Autotuner> autotuner,\n       SetupAutotunerWithExpectations(\n-          /*instr_to_autotune=*/HloOpcode::kAdd,\n+          /*instrs_to_autotune=*/{HloOpcode::kAdd},\n           /*instrs_to_apply_config_and_count=*/{{HloOpcode::kAdd, 2}}));\n \n   EXPECT_THAT(autotuner->Autotune(module.get(), should_autotune), IsOk());\n@@ -585,7 +592,10 @@ TEST_F(AutotunerTest, ExpectAllInstructionsInCache) {\n }\n \n TEST_F(AutotunerTest, DumpLogsToFile) {\n-  config_.dump_logs_to = tsl::io::JoinPath(tsl::testing::TmpDir(), \"dump.log\");\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      tsl::testing::TemporaryDirectory temp_dir,\n+      tsl::testing::TemporaryDirectory::CreateForCurrentTestcase());\n+  config_.dump_logs_to = tsl::io::JoinPath(temp_dir.path(), \"dump.log\");\n \n   std::vector<std::unique_ptr<BackendConfig>> configs;\n   configs.push_back(GetTestConfig(\"test_config_1\"));\n@@ -804,7 +814,7 @@ TEST_F(AutotunerTest, ShardedAutotuning) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::unique_ptr<Autotuner> autotuner,\n       SetupAutotunerWithExpectations(\n-          /*instr_to_autotune=*/HloOpcode::kCopy,\n+          /*instrs_to_autotune=*/{HloOpcode::kCopy},\n           /*instrs_to_apply_config_and_count=*/\n           {{HloOpcode::kCopy, 1}, {HloOpcode::kAdd, 2}}, std::move(cache)));\n \n@@ -817,5 +827,42 @@ TEST_F(AutotunerTest, ShardedAutotuning) {\n       IsOk());\n }\n \n+TEST_F(AutotunerTest, DumpHlos) {\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      tsl::testing::TemporaryDirectory dump_dir,\n+      tsl::testing::TemporaryDirectory::CreateForCurrentTestcase());\n+  auto module = ParseAndReturnVerifiedModule(kHlo).value();\n+  module->mutable_config().mutable_debug_options().set_xla_dump_to(\n+      dump_dir.path());\n+  auto should_autotune = [](const HloInstruction& instruction) {\n+    return instruction.opcode() == HloOpcode::kCopy ||\n+           instruction.opcode() == HloOpcode::kAdd;\n+  };\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<Autotuner> autotuner,\n+      SetupAutotunerWithExpectations(\n+          /*instrs_to_autotune=*/{HloOpcode::kCopy, HloOpcode::kAdd},\n+          // One apply config call per instruction is expected for dumping HLOs.\n+          /*instrs_to_apply_config_and_count=*/\n+          {{HloOpcode::kCopy, 2}, {HloOpcode::kAdd, 3}},\n+          /*cache=*/nullptr,\n+          /*dump_hlos=*/true));\n+\n+  EXPECT_THAT(autotuner->Autotune(module.get(), should_autotune), IsOk());\n+\n+  std::vector<std::string> files;\n+  EXPECT_THAT(tsl::Env::Default()->GetChildren(dump_dir.path(), &files),\n+              IsOk());\n+  EXPECT_THAT(files.size(), 4);\n+  EXPECT_THAT(\n+      files,\n+      UnorderedElementsAre(\n+          MatchesRegex(\".*\\\\.test_module\\\\.autotuner_0\\\\.copy\\\\.before\\\\.txt\"),\n+          MatchesRegex(\".*\\\\.test_module\\\\.autotuner_0\\\\.copy\\\\.after\\\\.txt\"),\n+          MatchesRegex(\".*\\\\.test_module\\\\.autotuner_1\\\\.add\\\\.after\\\\.txt\"),\n+          MatchesRegex(\".*\\\\.test_module\\\\.autotuner_1\\\\.add\\\\.before\\\\.txt\")));\n+}\n+\n }  // namespace\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 135,
        "additions": 109,
        "deletions": 26
    }
}