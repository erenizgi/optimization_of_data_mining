{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 845723345",
    "sha": "8f2afda3704da057a5e1ab1cd31991015099ae1b",
    "files": [
        {
            "sha": "a7e53647b72bf9db728219afa6508a22ef4f0ea1",
            "filename": "tensorflow/core/kernels/conv_grad_shape_utils.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 12,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_grad_shape_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_grad_shape_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_grad_shape_utils.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -53,10 +53,10 @@ namespace {\n absl::Status ConvBackpropExtractAndVerifyDimension(\n     absl::string_view label, const TensorShape& input_shape,\n     const TensorShape& filter_shape, const TensorShape& output_shape,\n-    const absl::Span<const int32> dilations, const std::vector<int32>& strides,\n-    Padding padding, int64_t padding_before, int64_t padding_after,\n-    int spatial_dim, int filter_spatial_dim,\n-    ConvBackpropSpatialDimension* dim) {\n+    const absl::Span<const int32_t> dilations,\n+    const std::vector<int32_t>& strides, Padding padding,\n+    int64_t padding_before, int64_t padding_after, int spatial_dim,\n+    int filter_spatial_dim, ConvBackpropSpatialDimension* dim) {\n   dim->input_size = input_shape.dim_size(spatial_dim);\n   dim->filter_size = filter_shape.dim_size(filter_spatial_dim);\n   dim->output_size = output_shape.dim_size(spatial_dim);\n@@ -96,9 +96,10 @@ absl::Status ConvBackpropComputeDimensionsV2(\n     absl::string_view label, int num_spatial_dims,\n     const TensorShape& input_shape, const TensorShape& filter_shape,\n     const TensorShape& out_backprop_shape,\n-    const absl::Span<const int32> dilations, const std::vector<int32>& strides,\n-    Padding padding, absl::Span<const int64_t> explicit_paddings,\n-    TensorFormat data_format, ConvBackpropDimensions* dims) {\n+    const absl::Span<const int32_t> dilations,\n+    const std::vector<int32_t>& strides, Padding padding,\n+    absl::Span<const int64_t> explicit_paddings, TensorFormat data_format,\n+    ConvBackpropDimensions* dims) {\n   // The + 2 in the following line is for the batch and feature dimensions.\n   const int num_dims = num_spatial_dims + 2;\n   if (input_shape.dims() != num_dims) {\n@@ -161,9 +162,9 @@ absl::Status ConvBackpropComputeDimensionsV2(\n absl::Status ConvBackpropComputeDimensions(\n     absl::string_view label, int num_spatial_dims,\n     const TensorShape& input_shape, const TensorShape& filter_shape,\n-    const TensorShape& out_backprop_shape, const std::vector<int32>& strides,\n+    const TensorShape& out_backprop_shape, const std::vector<int32_t>& strides,\n     Padding padding, TensorFormat data_format, ConvBackpropDimensions* dims) {\n-  static constexpr std::array<int32, 5> one_dilations = {{1, 1, 1, 1, 1}};\n+  static constexpr std::array<int32_t, 5> one_dilations = {{1, 1, 1, 1, 1}};\n   return ConvBackpropComputeDimensionsV2(\n       label, num_spatial_dims, input_shape, filter_shape, out_backprop_shape,\n       one_dilations, strides, padding, /*explicit_paddings=*/{}, data_format,\n@@ -181,13 +182,13 @@ absl::Status Conv2DBackpropComputeInputShape(\n   }\n \n   if (input_sizes.dim_size(0) == 4) {\n-    return TensorShapeUtils::MakeShape(input_sizes.vec<int32>(), input_shape);\n+    return TensorShapeUtils::MakeShape(input_sizes.vec<int32_t>(), input_shape);\n   }\n \n   if (input_sizes.dim_size(0) == 2) {\n     const int batch_size = GetTensorDim(out_backprop_shape, data_format, 'N');\n-    const int output_height = input_sizes.vec<int32>()(0);\n-    const int output_width = input_sizes.vec<int32>()(1);\n+    const int output_height = input_sizes.vec<int32_t>()(0);\n+    const int output_width = input_sizes.vec<int32_t>()(1);\n     const int output_depth = filter_shape.dim_size(2);\n     if (output_height < 0 || output_width < 0) {\n       return errors::InvalidArgument("
        },
        {
            "sha": "cc0708c4fe4f743a6789123ac230025ac966a88b",
            "filename": "tensorflow/core/kernels/conv_grad_shape_utils.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_grad_shape_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_grad_shape_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_grad_shape_utils.h?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -69,7 +69,7 @@ struct ConvBackpropDimensions {\n absl::Status ConvBackpropComputeDimensions(\n     absl::string_view label, int num_spatial_dims,\n     const TensorShape& input_shape, const TensorShape& filter_shape,\n-    const TensorShape& out_backprop_shape, const std::vector<int32>& strides,\n+    const TensorShape& out_backprop_shape, const std::vector<int32_t>& strides,\n     Padding padding, TensorFormat data_format, ConvBackpropDimensions* dims);\n \n // The V2 version computes the same outputs with arbitrary dilation rate and\n@@ -78,8 +78,8 @@ absl::Status ConvBackpropComputeDimensions(\n absl::Status ConvBackpropComputeDimensionsV2(\n     absl::string_view label, int num_spatial_dims,\n     const TensorShape& input_shape, const TensorShape& filter_shape,\n-    const TensorShape& out_backprop_shape, absl::Span<const int32> dilations,\n-    const std::vector<int32>& strides, Padding padding,\n+    const TensorShape& out_backprop_shape, absl::Span<const int32_t> dilations,\n+    const std::vector<int32_t>& strides, Padding padding,\n     absl::Span<const int64_t> explicit_paddings, TensorFormat data_format,\n     ConvBackpropDimensions* dims);\n "
        },
        {
            "sha": "51003ace32475c4b105cb4f8d6421d7a5f6ca71a",
            "filename": "tensorflow/core/kernels/conv_ops.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_ops.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -48,7 +48,7 @@ absl::Status InitConv2DParameters(const OpKernelConstruction* context,\n     TF_RETURN_IF_ERROR(\n         context->GetAttr(\"explicit_paddings\", &params->explicit_paddings));\n   }\n-  string data_format_string;\n+  std::string data_format_string;\n   TF_RETURN_IF_ERROR(context->GetAttr(\"data_format\", &data_format_string));\n   TF_REQUIRES(FormatFromString(data_format_string, &params->data_format),\n               errors::InvalidArgument(\"Invalid data format\"));"
        },
        {
            "sha": "199cd94c99cbaa1bb5c019f33646756b0b0bede7",
            "filename": "tensorflow/core/kernels/conv_ops.h",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_ops.h?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -45,8 +45,8 @@ template <typename Device, typename T>\n struct LaunchConvOp {\n   void operator()(OpKernelContext* context, bool cudnn_use_autotune,\n                   const Tensor& input, const Tensor& filter,\n-                  const std::vector<int64>& dilations,\n-                  const std::vector<int64>& strides, Padding padding,\n+                  const std::vector<int64_t>& dilations,\n+                  const std::vector<int64_t>& strides, Padding padding,\n                   const std::vector<int64_t>& explicit_paddings,\n                   TensorFormat data_format, Tensor* output);\n };\n@@ -85,13 +85,13 @@ struct Im2ColBufferResource : public ResourceBase {\n   // the buffer memory held by this resource.\n   mutex mu;\n   T* data;\n-  string DebugString() const { return \"Im2ColBufferResource\"; }\n+  std::string DebugString() const { return \"Im2ColBufferResource\"; }\n };\n \n // Convolution parameters specified by Op attributes.\n struct Conv2DParameters {\n-  std::vector<int32> dilations;\n-  std::vector<int32> strides;\n+  std::vector<int32_t> dilations;\n+  std::vector<int32_t> strides;\n   Padding padding;\n   TensorFormat data_format;\n   std::vector<int64_t> explicit_paddings;"
        },
        {
            "sha": "00c02ccd51c7118c73333155a4160eeb3958a2df",
            "filename": "tensorflow/core/kernels/conv_ops_3d.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_3d.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_3d.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_ops_3d.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -65,7 +65,7 @@ template <typename Device, typename T>\n class Conv3DOp : public BinaryOp<T> {\n  public:\n   explicit Conv3DOp(OpKernelConstruction* context) : BinaryOp<T>(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -175,8 +175,8 @@ class Conv3DOp : public BinaryOp<T> {\n   }\n \n  private:\n-  std::vector<int32> dilation_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> dilation_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_;\n   bool cudnn_use_autotune_;"
        },
        {
            "sha": "779fbb7a50bcd6329b437317eafe2211a0aea7c5",
            "filename": "tensorflow/core/kernels/conv_ops_benchmark_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 8,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_benchmark_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_benchmark_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_ops_benchmark_test.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -189,7 +189,7 @@ static int64_t Conv2DWithPostOpsFlops(int batch, int height, int width,\n template <typename T>\n static Conv2DWithBiasAndActivationGraph Conv2DWithBiasAndActivation(\n     int batch, int height, int width, int in_depth, int filter_w, int filter_h,\n-    int out_depth, const string& activation_type,\n+    int out_depth, const std::string& activation_type,\n     TensorFormat data_format = FORMAT_NHWC) {\n   Conv2DWithBiasGraph conv_graph =\n       Conv2DWithBias<T>(batch, height, width, in_depth, filter_w, filter_h,\n@@ -249,7 +249,7 @@ static Conv2DWithBatchNormGraph Conv2DWithBatchNorm(\n template <typename T>\n static Conv2DWithBatchNormAndActivationGraph Conv2DWithBatchNormAndActivation(\n     int batch, int height, int width, int in_depth, int filter_w, int filter_h,\n-    int out_depth, const string& activation_type,\n+    int out_depth, const std::string& activation_type,\n     TensorFormat data_format = FORMAT_NHWC) {\n   Conv2DWithBatchNormGraph conv_graph =\n       Conv2DWithBatchNorm<T>(batch, height, width, in_depth, filter_w, filter_h,\n@@ -271,11 +271,10 @@ static Conv2DWithBatchNormAndActivationGraph Conv2DWithBatchNormAndActivation(\n // Creates a tensorflow graph with a single FusedConv2D (with BiasAdd) node and\n // fuses into it additional computations (e.g. Relu).\n template <typename T>\n-static Graph* FusedConv2DWithBias(int batch, int height, int width,\n-                                  int in_depth, int filter_w, int filter_h,\n-                                  int out_depth,\n-                                  const std::vector<string>& fused_ops = {},\n-                                  TensorFormat data_format = FORMAT_NHWC) {\n+static Graph* FusedConv2DWithBias(\n+    int batch, int height, int width, int in_depth, int filter_w, int filter_h,\n+    int out_depth, const std::vector<std::string>& fused_ops = {},\n+    TensorFormat data_format = FORMAT_NHWC) {\n   Graph* graph = new Graph(OpRegistry::Global());\n \n   Tensor images_t = data_format == FORMAT_NHWC\n@@ -341,7 +340,7 @@ static Graph* FusedConv2DWithBias(int batch, int height, int width,\n template <typename T>\n static Graph* FusedConv2DWithBatchNorm(\n     int batch, int height, int width, int in_depth, int filter_w, int filter_h,\n-    int out_depth, const std::vector<string>& fused_ops = {},\n+    int out_depth, const std::vector<std::string>& fused_ops = {},\n     TensorFormat data_format = FORMAT_NHWC) {\n   Graph* graph = new Graph(OpRegistry::Global());\n "
        },
        {
            "sha": "ef031685c4093e3534a249abda58ebc2a88c51b3",
            "filename": "tensorflow/core/kernels/conv_ops_fused_image_transform.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_fused_image_transform.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_fused_image_transform.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_ops_fused_image_transform.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -711,7 +711,7 @@ class FusedResizeConv2DUsingGemmOp : public OpKernel {\n \n     // Compute the shape of the output tensor, and allocate it.\n     TensorShape padded_shape;\n-    TTypes<int32>::ConstMatrix paddings_matrix = paddings.matrix<int32>();\n+    TTypes<int32_t>::ConstMatrix paddings_matrix = paddings.matrix<int32_t>();\n     for (int d = 0; d < dims; ++d) {\n       const int32_t before =\n           paddings_matrix(d, 0);  // Pad before existing elements.\n@@ -867,7 +867,7 @@ class FusedResizeConv2DUsingGemmOp : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> strides_;\n+  std::vector<int32_t> strides_;\n   Padding padding_;\n   bool align_corners_;\n   int offset_;"
        },
        {
            "sha": "154f43a226cfdbff200996246aa4828e780599f3",
            "filename": "tensorflow/core/kernels/conv_ops_fused_impl.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_fused_impl.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_fused_impl.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_ops_fused_impl.h?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -307,7 +307,7 @@ struct LaunchFusedConv2DOp<CPUDevice, T> {\n };\n \n template <>\n-struct LaunchFusedConv2DOp<CPUDevice, int8>;\n+struct LaunchFusedConv2DOp<CPUDevice, int8_t>;\n \n template <>\n struct LaunchFusedConv2DOp<CPUDevice, qint8>;\n@@ -732,7 +732,7 @@ class FusedConv2DOp : public OpKernel {\n     // convolution with BiasAdd, but in practice it doesn't work, cuDNN ignores\n     // this parameter and always does Relu activation.\n     if (std::is_same<Device, GPUDevice>::value) {\n-      if (std::is_same<T, int8>::value || std::is_same<T, qint8>::value) {\n+      if (std::is_same<T, int8_t>::value || std::is_same<T, qint8>::value) {\n         patterns = {{FCT::kBiasAdd, {\"BiasAdd\"}},\n                     {FCT::kBiasAddWithRelu, {\"BiasAdd\", \"Relu\"}}};\n       } else {"
        },
        {
            "sha": "e23864960c1568ea08105f76a4aa0c86fe3d177f",
            "filename": "tensorflow/core/kernels/conv_ops_fused_int8.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_fused_int8.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_fused_int8.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_ops_fused_int8.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -300,9 +300,8 @@ struct LaunchFusedConv2DOpCpuInt8Helper {\n };\n \n template <>\n-struct LaunchFusedConv2DOp<CPUDevice, int8>\n-    : LaunchFusedConv2DOpCpuInt8Helper<int8> {\n-};\n+struct LaunchFusedConv2DOp<CPUDevice, int8_t>\n+    : LaunchFusedConv2DOpCpuInt8Helper<int8_t> {};\n \n template <>\n struct LaunchFusedConv2DOp<CPUDevice, qint8>"
        },
        {
            "sha": "3d5a0ac76e5b5bddd217882816e363797dafb4bf",
            "filename": "tensorflow/core/kernels/conv_ops_impl.h",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_impl.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_impl.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_ops_impl.h?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -178,13 +178,13 @@ struct LaunchGrouped {\n     std::array<int64_t, 5> shuffle({3, 0, 1, 2, 4});\n \n     // Compute pre shuffle dimemnsions.\n-    auto pre_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n+    auto pre_shuffle = [&](const Tensor& tensor) -> std::array<int64_t, 5> {\n       return {tensor.dim_size(0), tensor.dim_size(1), tensor.dim_size(2),\n               num_groups, tensor.dim_size(3) / num_groups};\n     };\n \n     // Compute post shuffle dimemnsions.\n-    auto post_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n+    auto post_shuffle = [&](const Tensor& tensor) -> std::array<int64_t, 5> {\n       return {num_groups, tensor.dim_size(0), tensor.dim_size(1),\n               tensor.dim_size(2), tensor.dim_size(3) / num_groups};\n     };\n@@ -262,8 +262,8 @@ template <typename T>\n struct LaunchConvOp<CPUDevice, T> {\n   void operator()(OpKernelContext* context, bool cudnn_use_autotune,\n                   const Tensor& input, const Tensor& filter,\n-                  const std::vector<int64>& dilations,\n-                  const std::vector<int64>& strides, const Padding padding,\n+                  const std::vector<int64_t>& dilations,\n+                  const std::vector<int64_t>& strides, const Padding padding,\n                   const std::vector<int64_t>& explicit_paddings,\n                   TensorFormat data_format, Tensor* output) {\n     // For now just calling existing launchers based on spatial dimensions.\n@@ -292,7 +292,7 @@ class ConvOp : public BinaryOp<T> {\n     OP_REQUIRES(context, groups_ == 1,\n                 absl::UnimplementedError(\n                     \"Grouped/Depthwise Convolutions are not supported yet.\"));\n-    string data_format_str;\n+    std::string data_format_str;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format_str));\n     OP_REQUIRES(context,\n                 data_format_str == \"CHANNELS_LAST\" ||"
        },
        {
            "sha": "a582aeb4b7277c319f4ccae029b16fad78a66104",
            "filename": "tensorflow/core/kernels/conv_ops_int32.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_int32.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_int32.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_ops_int32.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -30,12 +30,12 @@ template struct Conv2DOp<CPUDevice, int32>;\n // CPU implementation, don't register this EigenTensor-based version.\n #if !defined(USE_GEMM_FOR_CONV)\n REGISTER_KERNEL_BUILDER(\n-    Name(\"Conv2D\").Device(DEVICE_CPU).TypeConstraint<int32>(\"T\"),\n-    Conv2DOp<CPUDevice, int32>);\n+    Name(\"Conv2D\").Device(DEVICE_CPU).TypeConstraint<int32_t>(\"T\"),\n+    Conv2DOp<CPUDevice, int32_t>);\n #endif  // USE_GEMM_FOR_CONV\n REGISTER_KERNEL_BUILDER(\n-    Name(\"Conv\").Device(DEVICE_CPU).TypeConstraint<int32>(\"T\"),\n-    ConvOp<CPUDevice, int32>);\n+    Name(\"Conv\").Device(DEVICE_CPU).TypeConstraint<int32_t>(\"T\"),\n+    ConvOp<CPUDevice, int32_t>);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n template <>"
        },
        {
            "sha": "caff583b5700921332e517c44467afe9b5501582",
            "filename": "tensorflow/core/kernels/conv_ops_test.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 13,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_ops_test.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -86,8 +86,9 @@ class FusedResizePadConvOpTest : public OpsTestBase {\n     const int right_padding = 0;\n \n     AddInputFromArray<T>(image.shape(), image.flat<T>());\n-    AddInputFromArray<int32>(TensorShape({2}), {resized_height, resized_width});\n-    AddInputFromArray<int32>(\n+    AddInputFromArray<int32_t>(TensorShape({2}),\n+                               {resized_height, resized_width});\n+    AddInputFromArray<int32_t>(\n         TensorShape({4, 2}),\n         {0, 0, top_padding, bottom_padding, left_padding, right_padding, 0, 0});\n     AddInputFromArray<T>(filter.shape(), filter.flat<T>());\n@@ -128,8 +129,8 @@ class FusedResizePadConvOpTest : public OpsTestBase {\n                                int resize_height, int y_padding, int x_padding,\n                                int filter_size, int filter_count,\n                                bool resize_align_corners,\n-                               const string& pad_mode, int stride,\n-                               const string& padding, DataType dtype) {\n+                               const std::string& pad_mode, int stride,\n+                               const std::string& padding, DataType dtype) {\n     Scope root = tensorflow::Scope::NewRootScope();\n     using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)\n \n@@ -188,8 +189,9 @@ class FusedResizePadConvOpTest : public OpsTestBase {\n   void CompareFusedPadOnlyAndSeparate(int input_width, int input_height,\n                                       int input_depth, int y_padding,\n                                       int x_padding, int filter_size,\n-                                      int filter_count, const string& pad_mode,\n-                                      int stride, const string& padding,\n+                                      int filter_count,\n+                                      const std::string& pad_mode, int stride,\n+                                      const std::string& padding,\n                                       DataType dtype) {\n     Scope root = tensorflow::Scope::NewRootScope();\n     using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)\n@@ -488,7 +490,7 @@ class FusedConv2DOpTest : public OpsTestBase {\n   static constexpr int kImageBatchCount = 8;\n \n   static constexpr bool kIsInt8 =\n-      std::is_same<T, int8>::value || std::is_same<T, qint8>::value;\n+      std::is_same<T, int8_t>::value || std::is_same<T, qint8>::value;\n \n   using BiasAddGraphRunner =\n       std::function<void(const Tensor& input_data, const Tensor& filter_data,\n@@ -680,7 +682,7 @@ class FusedConv2DOpTest : public OpsTestBase {\n       const Tensor& input_data, const Tensor& filter_data,\n       const Tensor& scale_data, const Tensor& offset_data,\n       const Tensor& mean_data, const Tensor& variance_data,\n-      const string& activation_type, const std::string& padding,\n+      const std::string& activation_type, const std::string& padding,\n       const std::vector<int>& explicit_paddings, Tensor* output,\n       bool allow_gpu_device = false, int stride = 1) {\n     Scope root = tensorflow::Scope::NewRootScope();\n@@ -780,7 +782,7 @@ class FusedConv2DOpTest : public OpsTestBase {\n         TensorShape shape = arg_data.shape();\n         Tensor arg_data_float = Tensor(dtype_args, shape);\n         for (int index = 0; index < arg_data.NumElements(); index++) {\n-          int8 v = *(reinterpret_cast<int8*>(arg_data.data()) + index);\n+          int8_t v = *(reinterpret_cast<int8_t*>(arg_data.data()) + index);\n           *(reinterpret_cast<float*>(arg_data_float.data()) + index) =\n               static_cast<float>(v);\n         }\n@@ -886,7 +888,7 @@ class FusedConv2DOpTest : public OpsTestBase {\n \n   void ExpectMatch(const Tensor& x, const Tensor& y, double atol) {\n     constexpr bool exact_match =\n-        std::is_same<T, int8>::value || std::is_same<T, qint8>::value;\n+        std::is_same<T, int8_t>::value || std::is_same<T, qint8>::value;\n     if (exact_match) {\n       test::ExpectEqual(x, y);\n     } else {\n@@ -903,7 +905,7 @@ class FusedConv2DOpTest : public OpsTestBase {\n \n     constexpr int int8_scale = 80;\n \n-    using ConvT = typename std::conditional<kIsInt8, int8, T>::type;\n+    using ConvT = typename std::conditional<kIsInt8, int8_t, T>::type;\n     DataType dtype_conv = DataTypeToEnum<ConvT>::v();\n \n     TensorShape image_shape{image_batch_count, image_height, image_width,\n@@ -1120,7 +1122,7 @@ class FusedConv2DOpTest : public OpsTestBase {\n   // Verifies that computing Conv2D+FusedBatchNorm+{Activation} in a graph is\n   // identical to FusedConv2D.\n   void VerifyConv2DWithBatchNormAndActivation(\n-      const string& activation, int filter_size, int filter_count,\n+      const std::string& activation, int filter_size, int filter_count,\n       const std::vector<int>& explicit_paddings = {}, int depth = kDepth,\n       int image_width = kImageWidth, int image_height = kImageHeight,\n       int image_batch_count = kImageBatchCount) {\n@@ -1353,7 +1355,7 @@ REGISTER_TYPED_TEST_SUITE_P(FusedConv2DWithBatchNormOpTest,     //\n                             SpatialConvolutionAndActivation);\n #endif\n \n-using FusedBiasAddDataTypes = ::testing::Types<float, double, int8, qint8>;\n+using FusedBiasAddDataTypes = ::testing::Types<float, double, int8_t, qint8>;\n INSTANTIATE_TYPED_TEST_SUITE_P(Test, FusedConv2DWithBiasOpTest,\n                                FusedBiasAddDataTypes);\n "
        },
        {
            "sha": "531b6377b2ff641b3047f4ef4ed0b1a7c660f3df",
            "filename": "tensorflow/core/kernels/conv_ops_using_gemm.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_using_gemm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fconv_ops_using_gemm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconv_ops_using_gemm.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -433,7 +433,7 @@ class Conv2DUsingGemmOp : public BinaryOp<T> {\n   explicit Conv2DUsingGemmOp(OpKernelConstruction* context)\n       : BinaryOp<T>(context) {\n     OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &strides_));\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -557,7 +557,7 @@ class Conv2DUsingGemmOp : public BinaryOp<T> {\n   }\n \n  private:\n-  std::vector<int32> strides_;\n+  std::vector<int32_t> strides_;\n   Padding padding_;\n   TensorFormat data_format_;\n "
        },
        {
            "sha": "fe0709186c68098a227314e1665ab9ebefba61e1",
            "filename": "tensorflow/core/kernels/count_up_to_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcount_up_to_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcount_up_to_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcount_up_to_op.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -102,7 +102,7 @@ class ResourceCountUpToOp : public OpKernel {\n       Name(\"ResourceCountUpTo\").TypeConstraint<TYPE>(\"T\").Device(DEVICE_CPU), \\\n       ResourceCountUpToOp<TYPE>)\n \n-REGISTER(int32);\n+REGISTER(int32_t);\n REGISTER(int64_t);\n \n #undef REGISTER"
        },
        {
            "sha": "7c6d9132dd2142ddf442c0a56b72260595638153",
            "filename": "tensorflow/core/kernels/ctc_decoder_ops.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fctc_decoder_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fctc_decoder_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fctc_decoder_ops.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -91,7 +91,7 @@ class CTCDecodeHelper {\n           \" batch_size: \", batch_size);\n     }\n \n-    auto seq_len_t = (*seq_len)->vec<int32>();\n+    auto seq_len_t = (*seq_len)->vec<int32_t>();\n \n     for (int b = 0; b < batch_size; ++b) {\n       if (!(seq_len_t(b) <= max_time)) {\n@@ -220,7 +220,7 @@ class CTCGreedyDecoderOp : public OpKernel {\n       input_list_t.emplace_back(inputs_t.data() + t * batch_size * num_classes,\n                                 batch_size, num_classes);\n     }\n-    auto seq_len_t = seq_len->vec<int32>();\n+    auto seq_len_t = seq_len->vec<int32_t>();\n     auto log_prob_t = log_prob->matrix<T>();\n \n     log_prob_t.setZero();\n@@ -309,7 +309,7 @@ class CTCBeamSearchDecoderOp : public OpKernel {\n                             &decoded_values, &decoded_shape));\n \n     auto inputs_t = inputs->tensor<T, 3>();\n-    auto seq_len_t = seq_len->vec<int32>();\n+    auto seq_len_t = seq_len->vec<int32_t>();\n     auto log_prob_t = log_prob->matrix<T>();\n \n     const TensorShape& inputs_shape = inputs->shape();"
        },
        {
            "sha": "a1b851feb206dbdfcb4f888ce892b0def544b2f0",
            "filename": "tensorflow/core/kernels/ctc_loss_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fctc_loss_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fctc_loss_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fctc_loss_op.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -127,7 +127,7 @@ class CTCLossOp : public OpKernel {\n         errors::InvalidArgument(\"len(sequence_length) != batch_size.  \",\n                                 \"len(sequence_length):  \", seq_len->dim_size(0),\n                                 \" batch_size: \", batch_size));\n-    auto seq_len_t = seq_len->vec<int32>();\n+    auto seq_len_t = seq_len->vec<int32_t>();\n \n     OP_REQUIRES(ctx, labels_indices->dim_size(0) == labels_values->dim_size(0),\n                 errors::InvalidArgument(\n@@ -166,7 +166,7 @@ class CTCLossOp : public OpKernel {\n                                           0, \" and \", batch_size,\n                                           \" but saw: \", batch_indices));\n \n-      auto values = g.values<int32>();\n+      auto values = g.values<int32_t>();\n       std::vector<int>* b_values = &labels_t[batch_indices];\n       b_values->resize(values.size());\n       for (int i = 0; i < values.size(); ++i) (*b_values)[i] = values(i);"
        },
        {
            "sha": "4f3e04d7cd4c7fa28dcdde09ba32003bc1ad53cb",
            "filename": "tensorflow/core/kernels/cwise_op_abs.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_abs.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_abs.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_abs.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -18,7 +18,7 @@ limitations under the License.\n namespace tensorflow {\n \n REGISTER8(UnaryOp, CPU, \"Abs\", functor::abs, Eigen::half, bfloat16, float,\n-          double, int8, int16, int32, int64_t);\n+          double, int8_t, int16_t, int32_t, int64_t);\n \n REGISTER2(UnaryOp, CPU, \"ComplexAbs\", functor::abs, complex64, complex128);\n \n@@ -44,7 +44,7 @@ REGISTER_KERNEL_BUILDER(Name(\"Abs\")\n                             .Device(DEVICE_DEFAULT)\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        UnaryOp<CPUDevice, functor::abs<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        UnaryOp<CPUDevice, functor::abs<int32_t>>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "50fce03c1e0f95befc0b2bd9eca34105604957e3",
            "filename": "tensorflow/core/kernels/cwise_op_acos.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_acos.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_acos.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_acos.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,9 +17,9 @@ limitations under the License.\n \n namespace tensorflow {\n REGISTER5(UnaryOp, CPU, \"Acos\", functor::acos, Eigen::half, bfloat16, float,\n-          double, int8);\n-REGISTER5(UnaryOp, CPU, \"Acos\", functor::acos, int16, int32, int64_t, complex64,\n-          complex128);\n+          double, int8_t);\n+REGISTER5(UnaryOp, CPU, \"Acos\", functor::acos, int16_t, int32_t, int64_t,\n+          complex64, complex128);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "35483f244836fa860af07eb020f125204b02edb3",
            "filename": "tensorflow/core/kernels/cwise_op_add_1.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_add_1.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_add_1.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_add_1.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -16,11 +16,11 @@ limitations under the License.\n #include \"tensorflow/core/kernels/cwise_ops_common.h\"\n \n namespace tensorflow {\n-REGISTER6(BinaryOp, CPU, \"Add\", functor::add, float, Eigen::half, double, int32,\n-          int64_t, bfloat16);\n+REGISTER6(BinaryOp, CPU, \"Add\", functor::add, float, Eigen::half, double,\n+          int32_t, int64_t, bfloat16);\n \n REGISTER6(BinaryOp, CPU, \"AddV2\", functor::add, float, Eigen::half, double,\n-          int32, int64_t, bfloat16);\n+          int32_t, int64_t, bfloat16);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n \n@@ -55,14 +55,14 @@ REGISTER_KERNEL_BUILDER(Name(\"Add\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::add<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::add<int32_t>>);\n REGISTER_KERNEL_BUILDER(Name(\"AddV2\")\n                             .Device(DEVICE_DEFAULT)\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::add<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::add<int32_t>>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "bb897eedca48b0203f9919021acfa0faf066bb42",
            "filename": "tensorflow/core/kernels/cwise_op_add_2.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_add_2.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_add_2.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_add_2.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -22,13 +22,13 @@ namespace tensorflow {\n // sharded files, only make its register calls when not __ANDROID_TYPES_SLIM__.\n #if !defined(__ANDROID_TYPES_SLIM__)\n \n-REGISTER6(BinaryOp, CPU, \"Add\", functor::add, int8, int16, complex64, uint8,\n-          complex128, tstring);\n+REGISTER6(BinaryOp, CPU, \"Add\", functor::add, int8_t, int16_t, complex64,\n+          uint8_t, complex128, tstring);\n \n // Notice: String is excluded to allow marking AddV2 is_commutative and\n // is_aggregate.\n-REGISTER8(BinaryOp, CPU, \"AddV2\", functor::add, int8, int16, complex64, uint8,\n-          uint16, uint32, uint64, complex128);\n+REGISTER8(BinaryOp, CPU, \"AddV2\", functor::add, int8_t, int16_t, complex64,\n+          uint8_t, uint16_t, uint32_t, uint64_t, complex128);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "927c017cbabb82c69c9bde1d822b0eb6039b5915",
            "filename": "tensorflow/core/kernels/cwise_op_bitwise_and.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_bitwise_and.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_bitwise_and.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_bitwise_and.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,8 +17,8 @@ limitations under the License.\n \n namespace tensorflow {\n \n-REGISTER8(BinaryOp, CPU, \"BitwiseAnd\", functor::bitwise_and, int8, int16, int32,\n-          int64_t, uint8, uint16, uint32, uint64);\n+REGISTER8(BinaryOp, CPU, \"BitwiseAnd\", functor::bitwise_and, int8_t, int16_t,\n+          int32_t, int64_t, uint8_t, uint16_t, uint32_t, uint64_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "aab01711419c2c76a75a2102911d9293d4a5ba26",
            "filename": "tensorflow/core/kernels/cwise_op_bitwise_or.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_bitwise_or.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_bitwise_or.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_bitwise_or.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -19,8 +19,8 @@ namespace tensorflow {\n \n #if !defined(MLIR_GENERATED_CPU_KERNELS_ENABLED) || \\\n     !defined(MLIR_GENERATED_EXPERIMENTAL_KERNELS_ENABLED)\n-REGISTER8(BinaryOp, CPU, \"BitwiseOr\", functor::bitwise_or, int8, int16, int32,\n-          int64_t, uint8, uint16, uint32, uint64);\n+REGISTER8(BinaryOp, CPU, \"BitwiseOr\", functor::bitwise_or, int8_t, int16_t,\n+          int32_t, int64_t, uint8_t, uint16_t, uint32_t, uint64_t);\n #endif\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM"
        },
        {
            "sha": "a7a7c91fde59f0403d12801a4556fabad1c0aa69",
            "filename": "tensorflow/core/kernels/cwise_op_bitwise_xor.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_bitwise_xor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_bitwise_xor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_bitwise_xor.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,8 +17,8 @@ limitations under the License.\n \n namespace tensorflow {\n \n-REGISTER8(BinaryOp, CPU, \"BitwiseXor\", functor::bitwise_xor, int8, int16, int32,\n-          int64_t, uint8, uint16, uint32, uint64);\n+REGISTER8(BinaryOp, CPU, \"BitwiseXor\", functor::bitwise_xor, int8_t, int16_t,\n+          int32_t, int64_t, uint8_t, uint16_t, uint32_t, uint64_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "f8cbd536b24731bb375e1901e491f06a671d9e41",
            "filename": "tensorflow/core/kernels/cwise_op_clip.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_clip.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_clip.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_clip.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -269,12 +269,12 @@ REGISTER_CPU_KERNEL(Eigen::half);\n REGISTER_CPU_KERNEL(float);\n REGISTER_CPU_KERNEL(double);\n REGISTER_CPU_KERNEL(bfloat16);\n-REGISTER_CPU_KERNEL(int8);\n-REGISTER_CPU_KERNEL(int16);\n-REGISTER_CPU_KERNEL(int32);\n+REGISTER_CPU_KERNEL(int8_t);\n+REGISTER_CPU_KERNEL(int16_t);\n+REGISTER_CPU_KERNEL(int32_t);\n REGISTER_CPU_KERNEL(int64_t);\n-REGISTER_CPU_KERNEL(uint8);\n-REGISTER_CPU_KERNEL(uint16);\n+REGISTER_CPU_KERNEL(uint8_t);\n+REGISTER_CPU_KERNEL(uint16_t);\n REGISTER_CPU_KERNEL(std::complex<float>);\n REGISTER_CPU_KERNEL(std::complex<double>);\n #undef REGISTER_CPU_KERNEL"
        },
        {
            "sha": "d537a7f39e0753bdba53fd69f8d88bbfb509d2e6",
            "filename": "tensorflow/core/kernels/cwise_op_div.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_div.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_div.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_div.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -19,10 +19,10 @@ namespace tensorflow {\n \n REGISTER6(BinaryOp, CPU, \"Div\", functor::div, float, Eigen::half, double,\n           bfloat16, complex64, complex128);\n-REGISTER8(BinaryOp, CPU, \"Div\", functor::safe_div, uint8, uint16, uint32,\n-          uint64, int8, int16, int32, int64_t);\n-REGISTER8(BinaryOp, CPU, \"TruncateDiv\", functor::safe_div, uint8, uint16,\n-          uint32, uint64, int8, int16, int32, int64_t);\n+REGISTER8(BinaryOp, CPU, \"Div\", functor::safe_div, uint8_t, uint16_t, uint32_t,\n+          uint64_t, int8_t, int16_t, int32_t, int64_t);\n+REGISTER8(BinaryOp, CPU, \"TruncateDiv\", functor::safe_div, uint8_t, uint16_t,\n+          uint32_t, uint64_t, int8_t, int16_t, int32_t, int64_t);\n REGISTER4(BinaryOp, CPU, \"TruncateDiv\", functor::truncate_div_real, Eigen::half,\n           bfloat16, float, double);\n REGISTER6(BinaryOp, CPU, \"RealDiv\", functor::div, float, Eigen::half, double,\n@@ -35,8 +35,8 @@ REGISTER_KERNEL_BUILDER(Name(\"Div\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::safe_div<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::safe_div<int32_t>>);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "7aecd4f62b2bf79f02cdea32aa078803aa3c23a1",
            "filename": "tensorflow/core/kernels/cwise_op_equal_to_1.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_equal_to_1.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_equal_to_1.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_equal_to_1.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,9 +17,9 @@ limitations under the License.\n \n namespace tensorflow {\n REGISTER7(BinaryOp, CPU, \"Equal\", functor::equal_to, float, Eigen::half, double,\n-          uint8, int8, int16, bfloat16);\n-REGISTER8(BinaryOp, CPU, \"Equal\", functor::equal_to, uint16, uint32, uint64,\n-          qint8, qint16, quint8, quint16, qint32);\n+          uint8_t, int8_t, int16_t, bfloat16);\n+REGISTER8(BinaryOp, CPU, \"Equal\", functor::equal_to, uint16_t, uint32_t,\n+          uint64_t, qint8, qint16, quint8, quint16, qint32);\n REGISTER_KERNEL_BUILDER(\n     Name(\"ApproximateEqual\").Device(DEVICE_CPU).TypeConstraint<float>(\"T\"),\n     ApproximateEqualOp<CPUDevice, float>);\n@@ -32,8 +32,8 @@ REGISTER_KERNEL_BUILDER(Name(\"Equal\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::equal_to<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::equal_to<int32_t>>);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "e17cda8f2fbab6c820c0499484615cdc32f6a23b",
            "filename": "tensorflow/core/kernels/cwise_op_equal_to_2.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_equal_to_2.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_equal_to_2.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_equal_to_2.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -22,8 +22,8 @@ namespace tensorflow {\n // sharded files, only make its register calls when not __ANDROID_TYPES_SLIM__.\n #if !defined(__ANDROID_TYPES_SLIM__)\n \n-REGISTER6(BinaryOp, CPU, \"Equal\", functor::equal_to, int32, int64_t, complex64,\n-          complex128, tstring, bool);\n+REGISTER6(BinaryOp, CPU, \"Equal\", functor::equal_to, int32_t, int64_t,\n+          complex64, complex128, tstring, bool);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n REGISTER6(BinaryOp, GPU, \"Equal\", functor::equal_to, int8, int16, int64,"
        },
        {
            "sha": "95c5652548004afbd19bc457ff8c8bab5f8ccc59",
            "filename": "tensorflow/core/kernels/cwise_op_floor_div.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_floor_div.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_floor_div.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_floor_div.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,8 +17,8 @@ limitations under the License.\n \n namespace tensorflow {\n \n-REGISTER8(BinaryOp, CPU, \"FloorDiv\", functor::safe_floor_div, uint8, uint16,\n-          uint32, uint64, int8, int16, int32, int64_t);\n+REGISTER8(BinaryOp, CPU, \"FloorDiv\", functor::safe_floor_div, uint8_t, uint16_t,\n+          uint32_t, uint64_t, int8_t, int16_t, int32_t, int64_t);\n REGISTER4(BinaryOp, CPU, \"FloorDiv\", functor::floor_div_real, float,\n           Eigen::half, bfloat16, double);\n \n@@ -49,7 +49,7 @@ REGISTER_KERNEL_BUILDER(Name(\"FloorDiv\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::safe_floor_div<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::safe_floor_div<int32_t>>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "9cc40508e1adced8b3b3c33fabc87b4758806124",
            "filename": "tensorflow/core/kernels/cwise_op_floor_mod.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_floor_mod.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_floor_mod.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_floor_mod.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -16,8 +16,8 @@ limitations under the License.\n #include \"tensorflow/core/kernels/cwise_ops_common.h\"\n \n namespace tensorflow {\n-REGISTER8(BinaryOp, CPU, \"FloorMod\", functor::safe_floor_mod, int8, int16,\n-          int32, int64_t, uint8, uint16, uint32, uint64);\n+REGISTER8(BinaryOp, CPU, \"FloorMod\", functor::safe_floor_mod, int8_t, int16_t,\n+          int32_t, int64_t, uint8_t, uint16_t, uint32_t, uint64_t);\n REGISTER4(BinaryOp, CPU, \"FloorMod\", functor::floor_fmod, Eigen::half, bfloat16,\n           float, double);\n \n@@ -39,7 +39,7 @@ REGISTER_KERNEL_BUILDER(Name(\"FloorMod\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::safe_floor_mod<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::safe_floor_mod<int32_t>>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "1cd27097ce66fe4e6c7180bc4ac8806a5eb2405e",
            "filename": "tensorflow/core/kernels/cwise_op_greater.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_greater.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_greater.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_greater.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,8 +17,9 @@ limitations under the License.\n \n namespace tensorflow {\n REGISTER9(BinaryOp, CPU, \"Greater\", functor::greater, float, Eigen::half,\n-          double, int32, int64_t, uint8, uint16, uint32, uint64);\n-REGISTER3(BinaryOp, CPU, \"Greater\", functor::greater, int8, int16, bfloat16);\n+          double, int32_t, int64_t, uint8_t, uint16_t, uint32_t, uint64_t);\n+REGISTER3(BinaryOp, CPU, \"Greater\", functor::greater, int8_t, int16_t,\n+          bfloat16);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n REGISTER6(BinaryOp, GPU, \"Greater\", functor::greater, float, Eigen::half,\n@@ -44,6 +45,6 @@ REGISTER_KERNEL_BUILDER(Name(\"Greater\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::greater<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::greater<int32_t>>);\n }  // namespace tensorflow"
        },
        {
            "sha": "1c9e7df836deb7a407cea411af68e201241b44b3",
            "filename": "tensorflow/core/kernels/cwise_op_greater_equal.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_greater_equal.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_greater_equal.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_greater_equal.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,9 +17,10 @@ limitations under the License.\n \n namespace tensorflow {\n REGISTER9(BinaryOp, CPU, \"GreaterEqual\", functor::greater_equal, float,\n-          Eigen::half, double, int32, int64_t, uint8, uint16, uint32, uint64);\n-REGISTER3(BinaryOp, CPU, \"GreaterEqual\", functor::greater_equal, int8, int16,\n-          bfloat16);\n+          Eigen::half, double, int32_t, int64_t, uint8_t, uint16_t, uint32_t,\n+          uint64_t);\n+REGISTER3(BinaryOp, CPU, \"GreaterEqual\", functor::greater_equal, int8_t,\n+          int16_t, bfloat16);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n REGISTER9(BinaryOp, GPU, \"GreaterEqual\", functor::greater_equal, float,\n@@ -45,7 +46,7 @@ REGISTER_KERNEL_BUILDER(Name(\"GreaterEqual\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::greater_equal<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::greater_equal<int32_t>>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "2f54bd8292b3b6b2d189c685688dbecd7d2cfd6f",
            "filename": "tensorflow/core/kernels/cwise_op_invert.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_invert.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_invert.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_invert.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,8 +17,8 @@ limitations under the License.\n \n namespace tensorflow {\n \n-REGISTER8(UnaryOp, CPU, \"Invert\", functor::invert, int8, int16, int32, int64_t,\n-          uint8, uint16, uint32, uint64);\n+REGISTER8(UnaryOp, CPU, \"Invert\", functor::invert, int8_t, int16_t, int32_t,\n+          int64_t, uint8_t, uint16_t, uint32_t, uint64_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "76632030feec8f8fcd36d271eb5d8fd23d3d789e",
            "filename": "tensorflow/core/kernels/cwise_op_left_shift.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_left_shift.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_left_shift.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_left_shift.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,8 +17,8 @@ limitations under the License.\n \n namespace tensorflow {\n \n-REGISTER8(BinaryOp, CPU, \"LeftShift\", functor::left_shift, int8, int16, int32,\n-          int64_t, uint8, uint16, uint32, uint64);\n+REGISTER8(BinaryOp, CPU, \"LeftShift\", functor::left_shift, int8_t, int16_t,\n+          int32_t, int64_t, uint8_t, uint16_t, uint32_t, uint64_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "62dd9a18a5d86efda50c02937d14445dddfa06a2",
            "filename": "tensorflow/core/kernels/cwise_op_less.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_less.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_less.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_less.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,9 +17,9 @@ limitations under the License.\n \n namespace tensorflow {\n REGISTER5(BinaryOp, CPU, \"Less\", functor::less, float, Eigen::half, double,\n-          bfloat16, int32);\n-REGISTER7(BinaryOp, CPU, \"Less\", functor::less, uint8, uint16, uint32, uint64,\n-          int8, int16, int64_t);\n+          bfloat16, int32_t);\n+REGISTER7(BinaryOp, CPU, \"Less\", functor::less, uint8_t, uint16_t, uint32_t,\n+          uint64_t, int8_t, int16_t, int64_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n@@ -45,6 +45,6 @@ REGISTER_KERNEL_BUILDER(Name(\"Less\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::less<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::less<int32_t>>);\n }  // namespace tensorflow"
        },
        {
            "sha": "e17272986381fb4201118167a960365266cb73a9",
            "filename": "tensorflow/core/kernels/cwise_op_less_equal.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_less_equal.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_less_equal.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_less_equal.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,9 +17,9 @@ limitations under the License.\n \n namespace tensorflow {\n REGISTER5(BinaryOp, CPU, \"LessEqual\", functor::less_equal, float, Eigen::half,\n-          bfloat16, double, int32);\n-REGISTER7(BinaryOp, CPU, \"LessEqual\", functor::less_equal, int64_t, uint8,\n-          uint16, uint32, uint64, int8, int16);\n+          bfloat16, double, int32_t);\n+REGISTER7(BinaryOp, CPU, \"LessEqual\", functor::less_equal, int64_t, uint8_t,\n+          uint16_t, uint32_t, uint64_t, int8_t, int16_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n@@ -45,7 +45,7 @@ REGISTER_KERNEL_BUILDER(Name(\"LessEqual\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::less_equal<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::less_equal<int32_t>>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "74db589e7783d296bf674a7d30bf1dbe6a24f07b",
            "filename": "tensorflow/core/kernels/cwise_op_maximum.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_maximum.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_maximum.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_maximum.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -18,8 +18,8 @@ limitations under the License.\n namespace tensorflow {\n REGISTER4(BinaryOp, CPU, \"Maximum\", functor::maximum, float, Eigen::half,\n           bfloat16, double);\n-REGISTER8(BinaryOp, CPU, \"Maximum\", functor::maximum, int8, uint8, int16,\n-          uint16, int32, uint32, int64_t, uint64);\n+REGISTER8(BinaryOp, CPU, \"Maximum\", functor::maximum, int8_t, uint8_t, int16_t,\n+          uint16_t, int32_t, uint32_t, int64_t, uint64_t);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n REGISTER6(BinaryOp, GPU, \"Maximum\", functor::maximum, float, Eigen::half,\n@@ -44,7 +44,7 @@ REGISTER_KERNEL_BUILDER(Name(\"Maximum\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::maximum<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::maximum<int32_t>>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "5a101acf5e47ce2c77dd74d12a7357bf8897d1f6",
            "filename": "tensorflow/core/kernels/cwise_op_minimum.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_minimum.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_minimum.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_minimum.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -18,8 +18,8 @@ limitations under the License.\n namespace tensorflow {\n REGISTER4(BinaryOp, CPU, \"Minimum\", functor::minimum, float, Eigen::half,\n           bfloat16, double);\n-REGISTER8(BinaryOp, CPU, \"Minimum\", functor::minimum, int8, uint8, int16,\n-          uint16, int32, uint32, int64_t, uint64);\n+REGISTER8(BinaryOp, CPU, \"Minimum\", functor::minimum, int8_t, uint8_t, int16_t,\n+          uint16_t, int32_t, uint32_t, int64_t, uint64_t);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n REGISTER6(BinaryOp, GPU, \"Minimum\", functor::minimum, float, Eigen::half,\n@@ -45,7 +45,7 @@ REGISTER_KERNEL_BUILDER(Name(\"Minimum\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::minimum<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::minimum<int32_t>>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "51b91ceb85c2fd5b5c40dc73a5f4f7dd20f286d8",
            "filename": "tensorflow/core/kernels/cwise_op_mod.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_mod.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_mod.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_mod.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -16,9 +16,9 @@ limitations under the License.\n #include \"tensorflow/core/kernels/cwise_ops_common.h\"\n \n namespace tensorflow {\n-REGISTER2(BinaryOp, CPU, \"Mod\", functor::safe_mod, int32, int64_t);\n+REGISTER2(BinaryOp, CPU, \"Mod\", functor::safe_mod, int32_t, int64_t);\n REGISTER2(BinaryOp, CPU, \"Mod\", functor::fmod, float, double);\n-REGISTER2(BinaryOp, CPU, \"TruncateMod\", functor::safe_mod, int32, int64_t);\n+REGISTER2(BinaryOp, CPU, \"TruncateMod\", functor::safe_mod, int32_t, int64_t);\n REGISTER2(BinaryOp, CPU, \"TruncateMod\", functor::fmod, float, double);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n@@ -45,13 +45,13 @@ REGISTER_KERNEL_BUILDER(Name(\"Mod\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::safe_mod<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::safe_mod<int32_t>>);\n REGISTER_KERNEL_BUILDER(Name(\"TruncateMod\")\n                             .Device(DEVICE_DEFAULT)\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::safe_mod<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::safe_mod<int32_t>>);\n }  // namespace tensorflow"
        },
        {
            "sha": "cc6fd91248766ca2cbcab2a3253e339c97bdefb1",
            "filename": "tensorflow/core/kernels/cwise_op_mul_1.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_mul_1.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_mul_1.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_mul_1.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,8 +17,8 @@ limitations under the License.\n \n namespace tensorflow {\n \n-REGISTER6(BinaryOp, CPU, \"Mul\", functor::mul, float, Eigen::half, double, uint8,\n-          int32, bfloat16);\n+REGISTER6(BinaryOp, CPU, \"Mul\", functor::mul, float, Eigen::half, double,\n+          uint8_t, int32_t, bfloat16);\n REGISTER6(BinaryOp, CPU, \"MulNoNan\", functor::mul_no_nan, Eigen::half, float,\n           double, complex64, complex128, bfloat16);\n \n@@ -53,8 +53,8 @@ REGISTER_KERNEL_BUILDER(Name(\"Mul\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::mul<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::mul<int32_t>>);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "31080a3e01bc0aad912c016a71a425ffa255b4e1",
            "filename": "tensorflow/core/kernels/cwise_op_mul_2.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_mul_2.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_mul_2.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_mul_2.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -22,8 +22,8 @@ namespace tensorflow {\n // sharded files, only make its register calls when not __ANDROID_TYPES_SLIM__.\n #if !defined(__ANDROID_TYPES_SLIM__)\n \n-REGISTER8(BinaryOp, CPU, \"Mul\", functor::mul, int8, uint16, uint32, uint64,\n-          int16, int64_t, complex64, complex128);\n+REGISTER8(BinaryOp, CPU, \"Mul\", functor::mul, int8_t, uint16_t, uint32_t,\n+          uint64_t, int16_t, int64_t, complex64, complex128);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n REGISTER8(BinaryOp, GPU, \"Mul\", functor::mul, int8, uint16, uint32, uint64,"
        },
        {
            "sha": "7f589ece2e313fbc5033f9935024c032d71bf842",
            "filename": "tensorflow/core/kernels/cwise_op_neg_1.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_neg_1.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_neg_1.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_neg_1.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -16,7 +16,7 @@ limitations under the License.\n #include \"tensorflow/core/kernels/cwise_ops_common.h\"\n \n namespace tensorflow {\n-REGISTER4(UnaryOp, CPU, \"Neg\", functor::neg, int8, int16, int32, int64_t);\n+REGISTER4(UnaryOp, CPU, \"Neg\", functor::neg, int8_t, int16_t, int32_t, int64_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n@@ -37,6 +37,6 @@ REGISTER_KERNEL_BUILDER(Name(\"Neg\")\n                             .Device(DEVICE_DEFAULT)\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        UnaryOp<CPUDevice, functor::neg<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        UnaryOp<CPUDevice, functor::neg<int32_t>>);\n }  // namespace tensorflow"
        },
        {
            "sha": "6e787b88bb169448cc7a20b66437b192382cc705",
            "filename": "tensorflow/core/kernels/cwise_op_not_equal_to_1.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_not_equal_to_1.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_not_equal_to_1.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_not_equal_to_1.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,17 +17,17 @@ limitations under the License.\n \n namespace tensorflow {\n REGISTER7(BinaryOp, CPU, \"NotEqual\", functor::not_equal_to, float, Eigen::half,\n-          double, uint8, int8, int16, bfloat16);\n-REGISTER8(BinaryOp, CPU, \"NotEqual\", functor::not_equal_to, uint16, uint32,\n-          uint64, qint8, qint16, quint8, quint16, qint32);\n+          double, uint8_t, int8_t, int16_t, bfloat16);\n+REGISTER8(BinaryOp, CPU, \"NotEqual\", functor::not_equal_to, uint16_t, uint32_t,\n+          uint64_t, qint8, qint16, quint8, quint16, qint32);\n \n REGISTER_KERNEL_BUILDER(Name(\"NotEqual\")\n                             .Device(DEVICE_DEFAULT)\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::not_equal_to<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::not_equal_to<int32_t>>);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "537a8c4c0b8bf979887ef53e2a8b7c40e22d23cd",
            "filename": "tensorflow/core/kernels/cwise_op_not_equal_to_2.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_not_equal_to_2.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_not_equal_to_2.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_not_equal_to_2.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -22,7 +22,7 @@ namespace tensorflow {\n // sharded files, only make its register calls when not __ANDROID_TYPES_SLIM__.\n #if !defined(__ANDROID_TYPES_SLIM__)\n \n-REGISTER6(BinaryOp, CPU, \"NotEqual\", functor::not_equal_to, int32, int64_t,\n+REGISTER6(BinaryOp, CPU, \"NotEqual\", functor::not_equal_to, int32_t, int64_t,\n           complex64, complex128, tstring, bool);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "ae21c4613f1bc44c89012ce5aefc3121c2f9f344",
            "filename": "tensorflow/core/kernels/cwise_op_pow.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_pow.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_pow.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_pow.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -18,7 +18,8 @@ limitations under the License.\n namespace tensorflow {\n REGISTER6(BinaryOp, CPU, \"Pow\", functor::pow, float, Eigen::half, bfloat16,\n           double, complex64, complex128);\n-REGISTER4(BinaryOp, CPU, \"Pow\", functor::safe_pow, int8, int16, int32, int64_t);\n+REGISTER4(BinaryOp, CPU, \"Pow\", functor::safe_pow, int8_t, int16_t, int32_t,\n+          int64_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "cc960b023390a1e16e8a641fdc429aa51f49316a",
            "filename": "tensorflow/core/kernels/cwise_op_right_shift.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_right_shift.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_right_shift.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_right_shift.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,8 +17,8 @@ limitations under the License.\n \n namespace tensorflow {\n \n-REGISTER8(BinaryOp, CPU, \"RightShift\", functor::right_shift, int8, int16, int32,\n-          int64_t, uint8, uint16, uint32, uint64);\n+REGISTER8(BinaryOp, CPU, \"RightShift\", functor::right_shift, int8_t, int16_t,\n+          int32_t, int64_t, uint8_t, uint16_t, uint32_t, uint64_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "bab42c5b58f5cc8bdb4369508bce4c525f562640",
            "filename": "tensorflow/core/kernels/cwise_op_round.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_round.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_round.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_round.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -18,7 +18,7 @@ limitations under the License.\n namespace tensorflow {\n \n REGISTER6(UnaryOp, CPU, \"Round\", functor::round, Eigen::half, float, double,\n-          bfloat16, int32, int64_t);\n+          bfloat16, int32_t, int64_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)"
        },
        {
            "sha": "632e4a8cce12d5d6424a42aaf436ec6b215660dc",
            "filename": "tensorflow/core/kernels/cwise_op_sign.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_sign.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_sign.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_sign.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -18,7 +18,8 @@ limitations under the License.\n namespace tensorflow {\n REGISTER6(UnaryOp, CPU, \"Sign\", functor::sign, float, double, Eigen::half,\n           bfloat16, complex64, complex128);\n-REGISTER4(UnaryOp, CPU, \"Sign\", functor::sign, int8, int16, int32, int64_t);\n+REGISTER4(UnaryOp, CPU, \"Sign\", functor::sign, int8_t, int16_t, int32_t,\n+          int64_t);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n REGISTER6(UnaryOp, GPU, \"Sign\", functor::sign, float, Eigen::half, double,\n@@ -41,7 +42,7 @@ REGISTER_KERNEL_BUILDER(Name(\"Sign\")\n                             .Device(DEVICE_DEFAULT)\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        UnaryOp<CPUDevice, functor::sign<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        UnaryOp<CPUDevice, functor::sign<int32_t>>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "ddca86ae25b7c95db1c2d57c78c90934a638d6fc",
            "filename": "tensorflow/core/kernels/cwise_op_square.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_square.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_square.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_square.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -18,9 +18,9 @@ limitations under the License.\n namespace tensorflow {\n \n REGISTER7(UnaryOp, CPU, \"Square\", functor::square, float, Eigen::half, double,\n-          int32, int64_t, complex64, complex128);\n-REGISTER7(UnaryOp, CPU, \"Square\", functor::square, bfloat16, int8, int16, uint8,\n-          uint16, uint32, uint64);\n+          int32_t, int64_t, complex64, complex128);\n+REGISTER7(UnaryOp, CPU, \"Square\", functor::square, bfloat16, int8_t, int16_t,\n+          uint8_t, uint16_t, uint32_t, uint64_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n@@ -45,7 +45,7 @@ REGISTER_KERNEL_BUILDER(Name(\"Square\")\n                             .Device(DEVICE_DEFAULT)\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        UnaryOp<CPUDevice, functor::square<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        UnaryOp<CPUDevice, functor::square<int32_t>>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "c6f3fe2567afea42ae8aca3d46bf909f8176dea0",
            "filename": "tensorflow/core/kernels/cwise_op_squared_difference.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_squared_difference.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_squared_difference.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_squared_difference.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -17,7 +17,7 @@ limitations under the License.\n \n namespace tensorflow {\n REGISTER8(BinaryOp, CPU, \"SquaredDifference\", functor::squared_difference,\n-          float, Eigen::half, double, bfloat16, int32, int64_t, complex64,\n+          float, Eigen::half, double, bfloat16, int32_t, int64_t, complex64,\n           complex128);\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #if !defined(MLIR_GENERATED_GPU_KERNELS_ENABLED)\n@@ -37,16 +37,16 @@ REGISTER_KERNEL_BUILDER(\n         .HostMemory(\"x\")\n         .HostMemory(\"y\")\n         .HostMemory(\"z\")\n-        .TypeConstraint<int32>(\"T\"),\n-    BinaryOp<CPUDevice, functor::squared_difference<int32>>);\n+        .TypeConstraint<int32_t>(\"T\"),\n+    BinaryOp<CPUDevice, functor::squared_difference<int32_t>>);\n \n REGISTER_KERNEL_BUILDER(\n     Name(\"SquaredDifference\")\n         .Device(DEVICE_DEFAULT)\n         .HostMemory(\"x\")\n         .HostMemory(\"y\")\n         .HostMemory(\"z\")\n-        .TypeConstraint<int32>(\"T\"),\n-    BinaryOp<CPUDevice, functor::squared_difference<int32>>);\n+        .TypeConstraint<int32_t>(\"T\"),\n+    BinaryOp<CPUDevice, functor::squared_difference<int32_t>>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "b4eb0447115d223c42a28ee52506bbeabc34776c",
            "filename": "tensorflow/core/kernels/cwise_op_sub.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_sub.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f2afda3704da057a5e1ab1cd31991015099ae1b/tensorflow%2Fcore%2Fkernels%2Fcwise_op_sub.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fcwise_op_sub.cc?ref=8f2afda3704da057a5e1ab1cd31991015099ae1b",
            "patch": "@@ -16,12 +16,12 @@ limitations under the License.\n #include \"tensorflow/core/kernels/cwise_ops_common.h\"\n \n namespace tensorflow {\n-REGISTER8(BinaryOp, CPU, \"Sub\", functor::sub, float, Eigen::half, double, int32,\n-          int64_t, bfloat16, complex64, complex128);\n+REGISTER8(BinaryOp, CPU, \"Sub\", functor::sub, float, Eigen::half, double,\n+          int32_t, int64_t, bfloat16, complex64, complex128);\n #if !defined(__ANDROID_TYPES_SLIM__)\n // Sub op for int8, uint8, int16, uint16\n-REGISTER6(BinaryOp, CPU, \"Sub\", functor::sub, int8, uint8, int16, uint16,\n-          uint32, uint64);\n+REGISTER6(BinaryOp, CPU, \"Sub\", functor::sub, int8_t, uint8_t, int16_t,\n+          uint16_t, uint32_t, uint64_t);\n #else\n // We only register the first type when we have multi-argument calls in the\n // case where we're trying to reduce executable size, but it turns out that the\n@@ -53,7 +53,7 @@ REGISTER_KERNEL_BUILDER(Name(\"Sub\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\")\n                             .HostMemory(\"z\")\n-                            .TypeConstraint<int32>(\"T\"),\n-                        BinaryOp<CPUDevice, functor::sub<int32>>);\n+                            .TypeConstraint<int32_t>(\"T\"),\n+                        BinaryOp<CPUDevice, functor::sub<int32_t>>);\n \n }  // namespace tensorflow"
        }
    ],
    "stats": {
        "total": 391,
        "additions": 198,
        "deletions": 193
    }
}