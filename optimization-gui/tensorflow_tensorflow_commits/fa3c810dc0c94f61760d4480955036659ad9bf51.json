{
    "author": "thomasjoerg",
    "message": "Reverts e34b86def524974cf527541fc98970288637ed70\n\nPiperOrigin-RevId: 830411263",
    "sha": "fa3c810dc0c94f61760d4480955036659ad9bf51",
    "files": [
        {
            "sha": "5cafb77aade175aa1027f28c49ef5630c7fdd634",
            "filename": "third_party/xla/xla/hlo/transforms/expanders/dot_decomposer.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa3c810dc0c94f61760d4480955036659ad9bf51/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa3c810dc0c94f61760d4480955036659ad9bf51/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer.cc?ref=fa3c810dc0c94f61760d4480955036659ad9bf51",
            "patch": "@@ -33,7 +33,6 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n-#include \"xla/layout_util.h\"\n #include \"xla/service/shape_inference.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n@@ -105,8 +104,8 @@ absl::Status CanonicalizeDot(HloDotInstruction* original_dot) {\n   HloInstruction* lhs_operand = original_dot->mutable_operand(0);\n   HloInstruction* transposed_lhs = computation->AddInstruction(\n       HloInstruction::CreateTranspose(\n-          ShapeUtil::PermuteDimensionsIgnoringLayout(lhs_transpose, lhs_shape),\n-          lhs_operand, lhs_transpose),\n+          ShapeUtil::PermuteDimensions(lhs_transpose, lhs_shape), lhs_operand,\n+          lhs_transpose),\n       &lhs_operand->metadata());\n \n   std::vector<int64_t> lhs_reshape_dims = batch_dim_sizes;\n@@ -164,8 +163,8 @@ absl::Status CanonicalizeDot(HloDotInstruction* original_dot) {\n   HloInstruction* rhs_operand = original_dot->mutable_operand(1);\n   HloInstruction* transposed_rhs = computation->AddInstruction(\n       HloInstruction::CreateTranspose(\n-          ShapeUtil::PermuteDimensionsIgnoringLayout(rhs_transpose, rhs_shape),\n-          rhs_operand, rhs_transpose),\n+          ShapeUtil::PermuteDimensions(rhs_transpose, rhs_shape), rhs_operand,\n+          rhs_transpose),\n       &rhs_operand->metadata());\n \n   std::vector<int64_t> rhs_reshape_dims = batch_dim_sizes;"
        },
        {
            "sha": "e7e285bbdfaf4d87b301f0c426cc4ade42feab2a",
            "filename": "third_party/xla/xla/hlo/transforms/expanders/dot_decomposer_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 16,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa3c810dc0c94f61760d4480955036659ad9bf51/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa3c810dc0c94f61760d4480955036659ad9bf51/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer_test.cc?ref=fa3c810dc0c94f61760d4480955036659ad9bf51",
            "patch": "@@ -24,7 +24,6 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n-#include \"xla/hlo/testlib/pattern_matcher_gmock.h\"\n #include \"xla/hlo/utils/hlo_matchers.h\"\n #include \"xla/service/pattern_matcher.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -100,21 +99,13 @@ TEST_F(DotDecomposerTest, TransposeContractingDimsUponCanonicalization) {\n   TF_ASSERT_OK_AND_ASSIGN(bool canonicalized,\n                           DotDecomposer().Run(module.get()));\n   EXPECT_TRUE(canonicalized) << module->ToString();\n-  const HloInstruction* dot = nullptr;\n-  const HloInstruction* lhs_transpose = nullptr;\n-  const HloInstruction* rhs_transpose = nullptr;\n-  EXPECT_THAT(\n-      module->entry_computation()->root_instruction(),\n-      GmockMatch(m::Reshape(\n-          m::Op(&dot)\n-              .WithOperand(0, m::Reshape(m::Transpose(&lhs_transpose)))\n-              .WithOperand(1, m::Reshape(m::Transpose(&rhs_transpose))))));\n-  EXPECT_THAT(dot, AllOf(op::Dot(op::Reshape(), op::Reshape(),\n-                                 /*lhs_contracting_dim=*/1,\n-                                 /*rhs_contracting_dim=*/0),\n-                         op::Shape(\"f32[1024,1024]\")));\n-  EXPECT_THAT(lhs_transpose, op::ShapeWithLayout(\"f32[32,32,512]\"));\n-  EXPECT_THAT(rhs_transpose, op::ShapeWithLayout(\"f32[512,1024]\"));\n+  EXPECT_THAT(module->entry_computation()->root_instruction(),\n+              op::Reshape(AllOf(op::Dot(op::Reshape(op::Transpose()),\n+                                        op::Reshape(op::Transpose()),\n+                                        /*lhs_contracting_dim=*/1,\n+                                        /*rhs_contracting_dim=*/0),\n+                                op::Shape(\"f32[1024,1024]\"))))\n+      << module->ToString();\n }\n \n TEST_F(DotDecomposerTest, DontCanonicalizeIfNoNoncontractingDims) {"
        },
        {
            "sha": "0d736f73cb036e46747d51c14866af8da24e38e4",
            "filename": "third_party/xla/xla/shape_util.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 6,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa3c810dc0c94f61760d4480955036659ad9bf51/third_party%2Fxla%2Fxla%2Fshape_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa3c810dc0c94f61760d4480955036659ad9bf51/third_party%2Fxla%2Fxla%2Fshape_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fshape_util.cc?ref=fa3c810dc0c94f61760d4480955036659ad9bf51",
            "patch": "@@ -1264,7 +1264,7 @@ ShapeUtil::PackedFactorFor1DInterleavedArray(const Shape& shape) {\n       [&](int64_t dim) -> bool { return shape.dimensions()[dim] != 1; }, shape);\n }\n \n-/* static */ Shape ShapeUtil::PermuteDimensionsIgnoringLayout(\n+/* static */ Shape ShapeUtil::PermuteDimensions(\n     absl::Span<const int64_t> permutation, const Shape& shape) {\n   Shape new_shape = shape;\n   new_shape.clear_dimensions();\n@@ -1274,12 +1274,7 @@ ShapeUtil::PackedFactorFor1DInterleavedArray(const Shape& shape) {\n   for (int i = 0; i < permuted_dims.size(); ++i) {\n     new_shape.add_dimensions(permuted_dims[i], permuted_dynamic_dims[i]);\n   }\n-  return new_shape;\n-}\n \n-/* static */ Shape ShapeUtil::PermuteDimensions(\n-    absl::Span<const int64_t> permutation, const Shape& shape) {\n-  Shape new_shape = PermuteDimensionsIgnoringLayout(permutation, shape);\n   // If `shape` has a layout, by contract we choose a new layout such that the\n   // transpose defined by this permutation is a bitcast.\n   //"
        },
        {
            "sha": "3968ed9ad6c04334b897776dfe0c9e9557a1b766",
            "filename": "third_party/xla/xla/shape_util.h",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa3c810dc0c94f61760d4480955036659ad9bf51/third_party%2Fxla%2Fxla%2Fshape_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa3c810dc0c94f61760d4480955036659ad9bf51/third_party%2Fxla%2Fxla%2Fshape_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fshape_util.h?ref=fa3c810dc0c94f61760d4480955036659ad9bf51",
            "patch": "@@ -827,10 +827,6 @@ class ShapeUtil {\n   // Drops any degenerate dimensions (i.e. dimensions of size 1)\n   static Shape DropDegenerateDimensions(const Shape& shape);\n \n-  // Permutes the dimensions of `shape` without changing the layout, if present.\n-  static Shape PermuteDimensionsIgnoringLayout(\n-      absl::Span<const int64_t> permutation, const Shape& shape);\n-\n   // Permutes the dimensions by the given permutation, so\n   // return_value.dimensions[i] = argument.dimensions[permutation[i]].\n   //"
        },
        {
            "sha": "b714bf9661d660cb3c78448ecd983baacb66d553",
            "filename": "third_party/xla/xla/shape_util_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 18,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa3c810dc0c94f61760d4480955036659ad9bf51/third_party%2Fxla%2Fxla%2Fshape_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa3c810dc0c94f61760d4480955036659ad9bf51/third_party%2Fxla%2Fxla%2Fshape_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fshape_util_test.cc?ref=fa3c810dc0c94f61760d4480955036659ad9bf51",
            "patch": "@@ -1022,24 +1022,6 @@ TEST(ShapeUtilTest, HasDegenerateDimensions) {\n       ShapeUtil::HasDegenerateDimensions(ShapeUtil::MakeShape(F32, {3, 0, 5})));\n }\n \n-TEST(ShapeUtilTest, PermuteDimensionsIgnoringLayout) {\n-  {\n-    Shape s =\n-        ShapeUtil::MakeShapeWithDenseLayout(F32, {10, 100, 1000}, {2, 1, 0});\n-    Shape permuted = ShapeUtil::PermuteDimensionsIgnoringLayout({1, 2, 0}, s);\n-    EXPECT_EQ(permuted, ShapeUtil::MakeShapeWithDenseLayout(\n-                            F32, {100, 1000, 10}, {2, 1, 0}));\n-  }\n-  {\n-    Shape s = ShapeUtil::MakeShape(F32, {10, 100, 1000});\n-    LayoutUtil::ClearLayout(&s);\n-    Shape permuted = ShapeUtil::PermuteDimensionsIgnoringLayout({1, 2, 0}, s);\n-    Shape expected = ShapeUtil::MakeShape(F32, {100, 1000, 10});\n-    LayoutUtil::ClearLayout(&expected);\n-    EXPECT_EQ(permuted, expected);\n-  }\n-}\n-\n TEST(ShapeUtilTest, PermuteDimensionsLayout) {\n   std::vector<int64_t> layout(3);\n   std::iota(layout.begin(), layout.end(), 0);"
        }
    ],
    "stats": {
        "total": 61,
        "additions": 12,
        "deletions": 49
    }
}