{
    "author": "tensorflower-gardener",
    "message": "Make max_inflight_computations configurable in async PjRT. This controls the number of parallel computations we can schedule at the same time.\n\nPiperOrigin-RevId: 830730930",
    "sha": "6757a4216da336e9f65b6976608563d436dd925f",
    "files": [
        {
            "sha": "659eca271177f8ab9ead4e4c5ba7435dea482276",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_client.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6757a4216da336e9f65b6976608563d436dd925f/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6757a4216da336e9f65b6976608563d436dd925f/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc?ref=6757a4216da336e9f65b6976608563d436dd925f",
            "patch": "@@ -1209,7 +1209,8 @@ absl::StatusOr<std::unique_ptr<PjRtClient>> GetTfrtGpuClient(\n   TF_ASSIGN_OR_RETURN(\n       DeviceTopologyPair device_topology_pair,\n       BuildDistributedDevices(\n-          pjrt_platform_name, xla_client, options.node_id, options.num_nodes,\n+          pjrt_platform_name, xla_client, options.node_id,\n+          options.max_inflight_computations, options.num_nodes,\n           gpu_run_options.get(), kv_store, options.enable_mock_nccl,\n           options.mock_gpu_topology, options.partition_index, absl::Minutes(2),\n           absl::Minutes(5)));"
        },
        {
            "sha": "06b165166ac6af4d7b509bb9b3fd6b6779176ffb",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/utils.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6757a4216da336e9f65b6976608563d436dd925f/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6757a4216da336e9f65b6976608563d436dd925f/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.cc?ref=6757a4216da336e9f65b6976608563d436dd925f",
            "patch": "@@ -704,7 +704,8 @@ using DeviceTopologyPair =\n \n absl::StatusOr<DeviceTopologyPair> BuildDistributedDevices(\n     absl::string_view platform_name, LocalClient* xla_client, int node_id,\n-    int num_nodes, gpu::GpuExecutableRunOptions* gpu_executable_run_options,\n+    int max_inflight_computations, int num_nodes,\n+    gpu::GpuExecutableRunOptions* gpu_executable_run_options,\n     std::shared_ptr<KeyValueStoreInterface> kv_store, bool enable_mock_nccl,\n     std::optional<absl::string_view> mock_gpu_topology,\n     std::optional<int> partition_index,\n@@ -854,7 +855,7 @@ absl::StatusOr<DeviceTopologyPair> BuildDistributedDevices(\n       options.process_index = node.node_id();\n       options.process_index_in_partition = curr_process_index_in_partition;\n       options.partition_index = device_proto.partition_index();\n-      options.max_inflight_computations = 8;\n+      options.max_inflight_computations = max_inflight_computations;\n       options.platform_version = device_proto.name();\n       options.device_vendor = device_proto.vendor();\n       options.compute_capability = device_proto.compute_capability();"
        },
        {
            "sha": "59f93d17298a67f208e5e053874af1b57a86f69f",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/utils.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6757a4216da336e9f65b6976608563d436dd925f/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6757a4216da336e9f65b6976608563d436dd925f/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.h?ref=6757a4216da336e9f65b6976608563d436dd925f",
            "patch": "@@ -163,7 +163,8 @@ using DeviceTopologyPair =\n \n absl::StatusOr<DeviceTopologyPair> BuildDistributedDevices(\n     absl::string_view platform_name, LocalClient* xla_client, int node_id,\n-    int num_nodes, gpu::GpuExecutableRunOptions* gpu_executable_run_options,\n+    int num_nodes, int max_inflight_computations,\n+    gpu::GpuExecutableRunOptions* gpu_executable_run_options,\n     std::shared_ptr<KeyValueStoreInterface> kv_store, bool enable_mock_nccl,\n     std::optional<absl::string_view> mock_gpu_topology,\n     std::optional<int> partition_index,"
        },
        {
            "sha": "dd832637eb07b14e65884fca76bac38d13cf46f6",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_gpu/xla_gpu_client_options.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6757a4216da336e9f65b6976608563d436dd925f/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_gpu%2Fxla_gpu_client_options.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6757a4216da336e9f65b6976608563d436dd925f/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_gpu%2Fxla_gpu_client_options.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_gpu%2Fxla_gpu_client_options.h?ref=6757a4216da336e9f65b6976608563d436dd925f",
            "patch": "@@ -56,6 +56,8 @@ struct GpuClientOptions {\n   std::optional<int> partition_index;\n \n   bool use_tfrt_gpu_client = false;\n+\n+  int max_inflight_computations = 8;\n };\n \n }  //  namespace xla"
        }
    ],
    "stats": {
        "total": 13,
        "additions": 9,
        "deletions": 4
    }
}