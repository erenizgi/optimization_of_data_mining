{
    "author": "EusebioDM",
    "message": "Add (de)serialization methods to  `CubSortThunk`\n\nAlso adding a platform_name parameter to the `DeserializeThunkProto` function since we need to to deserialize this thunk (and it doesn't make sense to store in the proto).\n\nPiperOrigin-RevId: 828417473",
    "sha": "10669e6976f97f5f5361fd66b0fc93150de23e23",
    "files": [
        {
            "sha": "bf0e842c3e3a99ad00307c17d69cdf83dcfdcba9",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=10669e6976f97f5f5361fd66b0fc93150de23e23",
            "patch": "@@ -1,4 +1,8 @@\n load(\"@local_config_cuda//cuda:build_defs.bzl\", \"cuda_library\")\n+load(\n+    \"@local_config_rocm//rocm:build_defs.bzl\",\n+    \"if_rocm_is_configured\",\n+)\n load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n load(\"//xla:xla.default.bzl\", \"xla_cc_test\", \"xla_internal\", \"xla_py_proto_library\")\n load(\"//xla/tests:build_defs.bzl\", \"xla_test\")\n@@ -666,6 +670,7 @@ cc_library(\n     hdrs = [\"cub_sort_thunk.h\"],\n     deps = [\n         \":thunk\",\n+        \":thunk_proto_cc\",\n         \"//xla:executable_run_options\",\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n@@ -688,9 +693,37 @@ cc_library(\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/types:span\",\n     ],\n )\n \n+xla_cc_test(\n+    name = \"cub_sort_thunk_test\",\n+    srcs = [\"cub_sort_thunk_test.cc\"],\n+    tags = [\"gpu\"],\n+    deps = [\n+        \":cub_sort_thunk\",\n+        \":thunk\",\n+        \":thunk_proto_cc\",\n+        \"//xla/ffi\",\n+        \"//xla/ffi:ffi_api\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/service:platform_util\",\n+        \"//xla/stream_executor:platform\",\n+        \"//xla/stream_executor:platform_manager\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ] + if_cuda_is_configured([\n+        \"//xla/stream_executor/cuda:all_runtime\",\n+    ]) + if_rocm_is_configured([\n+        \"//xla/stream_executor/rocm:all_runtime\",\n+    ]),\n+)\n+\n cc_library(\n     name = \"custom_call_thunk\",\n     srcs = [\"custom_call_thunk.cc\"],\n@@ -2544,6 +2577,7 @@ cc_library(\n         \":convolution_reorder_thunk\",\n         \":convolution_thunk\",\n         \":copy_thunk\",\n+        \":cub_sort_thunk\",\n         \":cudnn_thunk\",\n         \":custom_call_thunk\",\n         \":dynamic_slice_thunk\","
        },
        {
            "sha": "7d532fcf4cb4334dec58d20c469163b19d7fb402",
            "filename": "third_party/xla/xla/backends/gpu/runtime/cub_sort_thunk.cc",
            "status": "modified",
            "additions": 65,
            "deletions": 4,
            "changes": 69,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.cc?ref=10669e6976f97f5f5361fd66b0fc93150de23e23",
            "patch": "@@ -30,6 +30,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/ffi/api/c_api.h\"\n@@ -47,6 +48,8 @@ limitations under the License.\n \n namespace xla {\n namespace gpu {\n+using buffer_assignment::BufferAllocationSliceProto;\n+\n namespace {\n \n // N pairs of [start_offset, end_offset) require (N+1) storage.\n@@ -63,7 +66,9 @@ absl::Status CopyOffsets(se::Stream* stream, se::DeviceMemoryBase scratch,\n       static_cast<char*>(scratch.opaque()) + scratch.size() - offsets_size;\n   se::DeviceMemoryBase d_offsets(offsets_buffer, offsets_size);\n   std::vector<int> h_offsets(batch_size + 1);\n-  for (int i = 0; i <= batch_size; ++i) h_offsets[i] = i * segment_size;\n+  for (int i = 0; i <= batch_size; ++i) {\n+    h_offsets[i] = i * segment_size;\n+  }\n   return stream->Memcpy(&d_offsets, h_offsets.data(), offsets_size);\n }\n \n@@ -295,13 +300,14 @@ absl::StatusOr<std::unique_ptr<CubSortThunk>> CubSortThunk::Create(\n       std::unique_ptr<CubSortRunnerInterface> runner,\n       CubSortRunnerInterface::Create(type, value_type, platform_name));\n \n-  return absl::WrapUnique<CubSortThunk>(\n-      new CubSortThunk(thunk_info, std::move(runner), std::move(operands),\n-                       std::move(results), scratch, descending, batch_size));\n+  return absl::WrapUnique<CubSortThunk>(new CubSortThunk(\n+      thunk_info, std::move(runner), type, value_type, std::move(operands),\n+      std::move(results), scratch, descending, batch_size));\n }\n \n CubSortThunk::CubSortThunk(\n     ThunkInfo thunk_info, std::unique_ptr<CubSortRunnerInterface> runner,\n+    PrimitiveType type, std::optional<PrimitiveType> value_type,\n     absl::InlinedVector<BufferAllocation::Slice, 2> operands,\n     absl::InlinedVector<BufferAllocation::Slice, 2> results,\n     BufferAllocation::Slice scratch, bool descending, int64_t batch_size)\n@@ -310,8 +316,63 @@ CubSortThunk::CubSortThunk(\n       operands_(std::move(operands)),\n       results_(std::move(results)),\n       scratch_(scratch),\n+      type_(type),\n+      value_type_(value_type),\n       descending_(descending),\n       batch_size_(batch_size) {}\n \n+absl::StatusOr<std::unique_ptr<CubSortThunk>> CubSortThunk::FromProto(\n+    ThunkInfo thunk_info, const CubSortThunkProto& proto,\n+    absl::Span<const BufferAllocation> buffer_allocations,\n+    absl::string_view platform_name) {\n+  absl::InlinedVector<BufferAllocation::Slice, 2> operands;\n+  for (const BufferAllocationSliceProto& slice_proto : proto.operands()) {\n+    TF_ASSIGN_OR_RETURN(\n+        operands.emplace_back(),\n+        BufferAllocation::Slice::FromProto(slice_proto, buffer_allocations));\n+  }\n+\n+  absl::InlinedVector<BufferAllocation::Slice, 2> results;\n+  for (const BufferAllocationSliceProto& slice_proto : proto.results()) {\n+    TF_ASSIGN_OR_RETURN(\n+        results.emplace_back(),\n+        BufferAllocation::Slice::FromProto(slice_proto, buffer_allocations));\n+  }\n+\n+  TF_ASSIGN_OR_RETURN(\n+      BufferAllocation::Slice scratch,\n+      BufferAllocation::Slice::FromProto(proto.scratch(), buffer_allocations));\n+\n+  std::optional<PrimitiveType> value_type;\n+  if (proto.has_value_type()) {\n+    value_type = proto.value_type();\n+  }\n+\n+  return Create(thunk_info, proto.type(), value_type, operands, results,\n+                scratch, proto.descending(), proto.batch_size(), platform_name);\n+}\n+\n+absl::StatusOr<ThunkProto> CubSortThunk::ToProto() const {\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+  CubSortThunkProto* cub_sort_proto = proto.mutable_cub_sort_thunk();\n+\n+  cub_sort_proto->set_type(type_);\n+  if (value_type_.has_value()) {\n+    cub_sort_proto->set_value_type(*value_type_);\n+  }\n+  for (const BufferAllocation::Slice& slice : operands_) {\n+    TF_ASSIGN_OR_RETURN(*cub_sort_proto->add_operands(), slice.ToProto());\n+  }\n+  for (const BufferAllocation::Slice& slice : results_) {\n+    TF_ASSIGN_OR_RETURN(*cub_sort_proto->add_results(), slice.ToProto());\n+  }\n+  TF_ASSIGN_OR_RETURN(*cub_sort_proto->mutable_scratch(), scratch_.ToProto());\n+  cub_sort_proto->set_descending(descending_);\n+  cub_sort_proto->set_batch_size(batch_size_);\n+\n+  return proto;\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "f04b84ca022a299cfbecefbb36f9a652246a8e35",
            "filename": "third_party/xla/xla/backends/gpu/runtime/cub_sort_thunk.h",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.h?ref=10669e6976f97f5f5361fd66b0fc93150de23e23",
            "patch": "@@ -24,7 +24,9 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/stream.h\"\n@@ -66,6 +68,13 @@ class CubSortThunk : public Thunk {\n     return runner_->Run(params, this);\n   }\n \n+  static absl::StatusOr<std::unique_ptr<CubSortThunk>> FromProto(\n+      ThunkInfo thunk_info, const CubSortThunkProto& proto,\n+      absl::Span<const BufferAllocation> buffer_allocations,\n+      absl::string_view platform_name);\n+\n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n   BufferAllocation::Slice operand(int i) const { return operands_[i]; }\n   BufferAllocation::Slice result(int i) const { return results_[i]; }\n   BufferAllocation::Slice scratch() const { return scratch_; }\n@@ -75,6 +84,7 @@ class CubSortThunk : public Thunk {\n  private:\n   CubSortThunk(ThunkInfo thunk_info,\n                std::unique_ptr<CubSortRunnerInterface> runner,\n+               PrimitiveType type, std::optional<PrimitiveType> value_type,\n                absl::InlinedVector<BufferAllocation::Slice, 2> operands,\n                absl::InlinedVector<BufferAllocation::Slice, 2> results,\n                BufferAllocation::Slice scratch, bool descending,\n@@ -83,6 +93,8 @@ class CubSortThunk : public Thunk {\n   absl::InlinedVector<BufferAllocation::Slice, 2> operands_;\n   absl::InlinedVector<BufferAllocation::Slice, 2> results_;\n   BufferAllocation::Slice scratch_;\n+  PrimitiveType type_;\n+  std::optional<PrimitiveType> value_type_;\n   bool descending_;\n   int64_t batch_size_;\n };"
        },
        {
            "sha": "dfd04751d72bcd6098fd9bb855212c297def5c4e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/cub_sort_thunk_test.cc",
            "status": "added",
            "additions": 74,
            "deletions": 0,
            "changes": 74,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk_test.cc?ref=10669e6976f97f5f5361fd66b0fc93150de23e23",
            "patch": "@@ -0,0 +1,74 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/cub_sort_thunk.h\"\n+\n+#include <memory>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/ffi/ffi.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/platform_util.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+using ::tsl::proto_testing::EqualsProto;\n+using ::tsl::proto_testing::ParseTextProtoOrDie;\n+\n+TEST(CubSortThunkTest, ProtoRoundTrip) {\n+  TF_ASSERT_OK_AND_ASSIGN(absl::string_view name,\n+                          PlatformUtil::CanonicalPlatformName(\"gpu\"));\n+  auto proto = ParseTextProtoOrDie<ThunkProto>(R\"pb(\n+    thunk_info {\n+      profile_annotation: \"cub_sort_thunk_profile\"\n+      execution_stream_id: 1\n+    }\n+    cub_sort_thunk {\n+      type: F32\n+      value_type: F32\n+      operands { offset: 0 size: 4 buffer_allocation_index: 0 }\n+      results { offset: 0 size: 4 buffer_allocation_index: 1 }\n+      scratch { offset: 0 size: 1024 buffer_allocation_index: 2 }\n+      descending: true\n+      batch_size: 1\n+    }\n+  )pb\");\n+\n+  std::vector<BufferAllocation> buffer_allocations;\n+  buffer_allocations.emplace_back(/*index=*/0, /*size=*/4, /*color=*/0);\n+  buffer_allocations.emplace_back(/*index=*/1, /*size=*/4, /*color=*/0);\n+  buffer_allocations.emplace_back(/*index=*/2, /*size=*/1024, /*color=*/0);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Thunk::ThunkInfo thunk_info,\n+                          Thunk::ThunkInfo::FromProto(proto.thunk_info()));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<CubSortThunk> thunk,\n+      CubSortThunk::FromProto(thunk_info, proto.cub_sort_thunk(),\n+                              buffer_allocations, name));\n+  TF_ASSERT_OK_AND_ASSIGN(ThunkProto round_trip_proto, thunk->ToProto());\n+  EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        },
        {
            "sha": "898a72ae0edaca6423cfd2db8d47f62655b87774",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=10669e6976f97f5f5361fd66b0fc93150de23e23",
            "patch": "@@ -212,6 +212,16 @@ message CublasLtMatmulThunkProto {\n   optional xla.buffer_assignment.BufferAllocationSliceProto workspace = 16;\n }\n \n+message CubSortThunkProto {\n+  xla.PrimitiveType type = 1;\n+  optional xla.PrimitiveType value_type = 3;\n+  repeated xla.buffer_assignment.BufferAllocationSliceProto operands = 4;\n+  repeated xla.buffer_assignment.BufferAllocationSliceProto results = 5;\n+  xla.buffer_assignment.BufferAllocationSliceProto scratch = 6;\n+  bool descending = 7;\n+  int64 batch_size = 8;\n+}\n+\n message NormThunkProto {\n   GpuNormDescriptorProto norm_descriptor = 1;\n   xla.buffer_assignment.BufferAllocationSliceProto x = 2;\n@@ -294,6 +304,7 @@ message ThunkProto {\n     CholeskyThunkProto cholesky_thunk = 28;\n     Memset32BitValueThunkProto memset32bit_value_thunk = 29;\n     CustomCallThunkProto custom_call_thunk = 30;\n+    CubSortThunkProto cub_sort_thunk = 31;\n   }\n }\n "
        },
        {
            "sha": "aede9cbd06dfb30bc8007c22d1a0bbaf1f714124",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/10669e6976f97f5f5361fd66b0fc93150de23e23/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc?ref=10669e6976f97f5f5361fd66b0fc93150de23e23",
            "patch": "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/convolution_reorder_thunk.h\"\n #include \"xla/backends/gpu/runtime/convolution_thunk.h\"\n #include \"xla/backends/gpu/runtime/copy_thunk.h\"\n+#include \"xla/backends/gpu/runtime/cub_sort_thunk.h\"\n #include \"xla/backends/gpu/runtime/cudnn_thunk.h\"\n #include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n #include \"xla/backends/gpu/runtime/dynamic_slice_thunk.h\"\n@@ -186,6 +187,10 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProto(\n       return CustomCallThunk::FromProto(\n           std::move(thunk_info), thunk_proto.custom_call_thunk(),\n           buffer_allocations, hlo_module, platform_name);\n+    case ThunkProto::kCubSortThunk:\n+      return CubSortThunk::FromProto(std::move(thunk_info),\n+                                     thunk_proto.cub_sort_thunk(),\n+                                     buffer_allocations, platform_name);\n     default:\n       std::optional<absl::string_view> unsupported_thunk_type =\n           GetStoredThunkTypeName(thunk_proto);"
        }
    ],
    "stats": {
        "total": 205,
        "additions": 201,
        "deletions": 4
    }
}