{
    "author": "WillFroom",
    "message": "[XLA:GPU][XTile] Use to_scalar/to_tensor rather than tensor extract/from_elements.\n\nPiperOrigin-RevId: 827542044",
    "sha": "52a8c6aa15734299538fabb99afcbd16b3e13f4d",
    "files": [
        {
            "sha": "75eb2231f3801d3cf4458ff5bb99596356709288",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 23,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=52a8c6aa15734299538fabb99afcbd16b3e13f4d",
            "patch": "@@ -317,12 +317,8 @@ ScalarOrTensor BroadcastInDims(EmitterLocOpBuilder b, ScalarOrTensor value,\n \n   if (value.IsScalar()) {\n     CHECK(dims.empty()) << \"scalar broadcast must have empty dims\";\n-    auto scalar_tensor_type =\n-        mlir::RankedTensorType::get(/*shape=*/{}, value.getType());\n-\n-    broadcast_in_dim_input = b.create<mlir::tensor::FromElementsOp>(\n-                                  scalar_tensor_type, value.UnwrapScalar())\n-                                 .getResult();\n+    broadcast_in_dim_input =\n+        b.create<xtile::ToTensorOp>(value.UnwrapScalar()).getResult();\n   } else {\n     broadcast_in_dim_input = value.UnwrapTensor();\n   }\n@@ -357,7 +353,7 @@ ScalarOrTensor EmitParameterExtract(EmitterLocOpBuilder b,\n   if (tensor_type.getRank() == 0) {\n     // Triton does not support 0-D tensors so we must extract the scalar value.\n     // TODO(csigg): This should be handled in the extract/insert rewrite.\n-    return ScalarOrTensor(b.create<mlir::tensor::ExtractOp>(extracted_tensor));\n+    return ScalarOrTensor(b.create<xtile::ToScalarOp>(extracted_tensor));\n   }\n \n   return ScalarOrTensor(extracted_tensor);\n@@ -413,9 +409,7 @@ absl::StatusOr<ScalarOrTensor> EmitReduce(\n                                                      neutral.UnwrapUnsafe()));\n   }\n \n-  Value init_value = b.create<mlir::tensor::FromElementsOp>(\n-      mlir::RankedTensorType::get(\n-          /*shape=*/{}, values[tiled_hlo_reduce.operand(1)].getType()),\n+  Value init_value = b.create<xtile::ToTensorOp>(\n       values[tiled_hlo_reduce.operand(1)].UnwrapScalar());\n \n   stablehlo::ReduceOp reduction = b.create<stablehlo::ReduceOp>(\n@@ -446,12 +440,10 @@ absl::StatusOr<ScalarOrTensor> EmitReduce(\n           return Internal(\"Expected reducer argument to be a tensor.\");\n         }\n \n-        // Emit extract op so that the reducer can be lowered to triton, as the\n-        // triton reducer can only work with scalars.\n+        // Emit from tensor op so that the reducer can be lowered to triton, as\n+        // the triton reducer can only work with scalars.\n         auto extracted_argument =\n-            ScalarOrTensor(b.create<mlir::tensor::ExtractOp>(\n-                                argument.getType().getElementType(), argument)\n-                               .getResult());\n+            ScalarOrTensor(b.create<xtile::ToScalarOp>(argument));\n         TF_RET_CHECK(region_values.insert({instr, extracted_argument}).second);\n       } else {\n         to_emit.push_back(instr);\n@@ -465,16 +457,14 @@ absl::StatusOr<ScalarOrTensor> EmitReduce(\n                                   region_values));\n     // Emit from_elements op so that the reducer can be lowered to triton, as\n     // the triton reducer can only work with scalars.\n-    auto result_as_scalar = b.create<mlir::tensor::FromElementsOp>(\n-        result_ty, result.UnwrapUnsafe());\n+    auto result_as_scalar = b.create<xtile::ToTensorOp>(result.UnwrapUnsafe());\n     b.create<stablehlo::ReturnOp>(SmallVector<Value>({result_as_scalar}));\n     b.setInsertionPointAfter(reduction);\n   }\n \n   auto result = reduction.getResult(0);\n   if (mlir::cast<ShapedType>(result.getType()).getRank() == 0) {\n-    result = b.create<mlir::tensor::ExtractOp>(\n-        mlir::cast<ShapedType>(result.getType()).getElementType(), result);\n+    result = b.create<xtile::ToScalarOp>(result);\n   }\n \n   return ScalarOrTensor(result);\n@@ -1856,10 +1846,7 @@ absl::Status EmitGeneric(mlir::OpBuilder builder,\n     if (result.IsScalar()) {\n       // TODO(csigg): Handle this in extract/insert rewrite.\n       mlir::Value scalar_value = result.UnwrapScalar();\n-      auto tensor_type =\n-          mlir::RankedTensorType::get({}, scalar_value.getType());\n-      input_tensor =\n-          b.create<mlir::tensor::FromElementsOp>(tensor_type, scalar_value);\n+      input_tensor = b.create<xtile::ToTensorOp>(scalar_value);\n     } else {\n       input_tensor = result.UnwrapTensor();\n     }"
        },
        {
            "sha": "e201f3723e6165bbaf7d8d12881fa7f3252e60a4",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 32,
            "changes": 64,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=52a8c6aa15734299538fabb99afcbd16b3e13f4d",
            "patch": "@@ -392,12 +392,12 @@ ENTRY entry_computation {\n       CreateXTileIrAndFileCheck(this, kHloText, \"fused_reduce\", R\"(\n CHECK: stablehlo.reduce\n CHECK: reducer(%[[ARG0:.*]]: tensor<f32>, %[[ARG1:.*]]: tensor<f32>)\n-CHECK:   %[[EXTRACTED_0:.*]] = tensor.extract %[[ARG0]][] : tensor<f32>\n-CHECK:   %[[EXTRACTED_1:.*]] = tensor.extract %[[ARG1]][] : tensor<f32>\n-CHECK:   %[[ADD:.*]] = arith.addf %[[EXTRACTED_0]], %[[EXTRACTED_1]] : f32\n+CHECK:   %[[SCALAR_0:.*]] = xtile.to_scalar %[[ARG0]] : tensor<f32>\n+CHECK:   %[[SCALAR_1:.*]] = xtile.to_scalar %[[ARG1]] : tensor<f32>\n+CHECK:   %[[ADD:.*]] = arith.addf %[[SCALAR_0]], %[[SCALAR_1]] : f32\n CHECK:   %[[MIN:.*]] = arith.minimumf %[[ADD]]\n-CHECK:   %[[FROM_ELEMENTS:.*]] = tensor.from_elements %[[MIN]] : tensor<f32>\n-CHECK:   stablehlo.return %[[FROM_ELEMENTS]] : tensor<f32>\n+CHECK:   %[[TO_TENSOR:.*]] = xtile.to_tensor %[[MIN]] : f32\n+CHECK:   stablehlo.return %[[TO_TENSOR]] : tensor<f32>\n )\"));\n \n   TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n@@ -513,7 +513,7 @@ CHECK:  xtile.insert %[[ABS]]\n CHECK-COUNT-1:  xtile.extract\n CHECK:  %[[ABS:.*]] = math.absf\n CHECK:  %[[REDUCE:.*]] = \"tt.reduce\"(%[[ABS:.*]]) <{axis = 0 : i32}>\n-CHECK: %[[SCALAR_TENSOR:.*]] = tensor.from_elements %[[REDUCE]] : tensor<f32>\n+CHECK: %[[SCALAR_TENSOR:.*]] = xtile.to_tensor %[[REDUCE]] : f32\n CHECK: xtile.insert %[[SCALAR_TENSOR]] into %arg1\n CHECK:  xtile.insert %[[ABS]] {{.*}} : tensor<512xf32>\n )\",\n@@ -1033,11 +1033,11 @@ CHECK:  %[[CMPI:.*]] = arith.cmpi slt, %[[BROADCAST]]\n CHECK:  %[[SELECT:.*]] = arith.select %[[CMPI]], %[[LOAD]], %{{.*}}\n CHECK: %[[REDUCE:.*]] = stablehlo.reduce(%[[SELECT]] init: %{{.*}}) across dimensions = [0] : (tensor<8x4xf32>, tensor<f32>) -> tensor<4xf32>\n CHECK:   reducer(%[[ARG0:.*]]: tensor<f32>, %[[ARG1:.*]]: tensor<f32>)  {\n-CHECK:   %[[EXTRACTED_0:.*]] = tensor.extract %[[ARG0]][] : tensor<f32>\n-CHECK:   %[[EXTRACTED_1:.*]] = tensor.extract %[[ARG1]][] : tensor<f32>\n-CHECK:   %[[MAX:.*]] = arith.maximumf %[[EXTRACTED_0]], %[[EXTRACTED_1]] : f32\n-CHECK:   %[[FROM_ELEMENTS:.*]] = tensor.from_elements %[[MAX]] : tensor<f32>\n-CHECK:   stablehlo.return %[[FROM_ELEMENTS]] : tensor<f32>\n+CHECK:   %[[SCALAR_0:.*]] = xtile.to_scalar %[[ARG0]] : tensor<f32>\n+CHECK:   %[[SCALAR_1:.*]] = xtile.to_scalar %[[ARG1]] : tensor<f32>\n+CHECK:   %[[MAX:.*]] = arith.maximumf %[[SCALAR_0]], %[[SCALAR_1]] : f32\n+CHECK:   %[[TO_TENSOR:.*]] = xtile.to_tensor %[[MAX]] : f32\n+CHECK:   stablehlo.return %[[TO_TENSOR]] : tensor<f32>\n CHECK: }\n           )\"));\n \n@@ -1102,11 +1102,11 @@ CHECK-NEXT:       xtile.extract %[[P0]]\n CHECK-SAME:       [%[[PID]], %[[EXTRACT_IDX_0]]] [1, 128] [1, 1]\n CHECK:            stablehlo.reduce\n CHECK-NEXT:       reducer(%[[ARG2:[^:]*]]: tensor<f32>, %[[ARG3:[^:]*]]: tensor<f32>)  {\n-CHECK-NEXT:           %[[ARG2_EXTRACTED:.*]] = tensor.extract %[[ARG2]][] : tensor<f32>\n-CHECK-NEXT:           %[[ARG3_EXTRACTED:.*]] = tensor.extract %[[ARG3]][] : tensor<f32>\n-CHECK-NEXT:           %[[ADD:.*]] = arith.addf %[[ARG2_EXTRACTED]], %[[ARG3_EXTRACTED]] : f32\n-CHECK-NEXT:           %[[FROM_ELEMENTS:.*]] = tensor.from_elements %[[ADD]] : tensor<f32>\n-CHECK-NEXT:           stablehlo.return %[[FROM_ELEMENTS]] : tensor<f32>\n+CHECK-NEXT:           %[[ARG2_SCALAR:.*]] = xtile.to_scalar %[[ARG2]] : tensor<f32>\n+CHECK-NEXT:           %[[ARG3_SCALAR:.*]] = xtile.to_scalar %[[ARG3]] : tensor<f32>\n+CHECK-NEXT:           %[[ADD:.*]] = arith.addf %[[ARG2_SCALAR]], %[[ARG3_SCALAR]] : f32\n+CHECK-NEXT:           %[[TO_TENSOR:.*]] = xtile.to_tensor %[[ADD]] : f32\n+CHECK-NEXT:           stablehlo.return %[[TO_TENSOR]] : tensor<f32>\n CHECK-NEXT:       }\n CHECK:            arith.mulf\n CHECK-SAME:       tensor<1x128xf32>\n@@ -1186,11 +1186,11 @@ CHECK-DAG:        %[[EXTRACT_IDX_1:.*]] = xla.apply_indexing #indexing_map(%[[TI\n CHECK-DAG:        xtile.extract %[[P1]][%[[EXTRACT_IDX_1]]] [128] [1] : {{.*}} -> tensor<128xf32>\n CHECK:            stablehlo.reduce\n CHECK-NEXT:       reducer(%[[ARG3:[^:]*]]: tensor<f32>, %[[ARG4:[^:]*]]: tensor<f32>)  {\n-CHECK-NEXT:           %[[ARG3_EXTRACTED:.*]] = tensor.extract %[[ARG3]][] : tensor<f32>\n-CHECK-NEXT:           %[[ARG4_EXTRACTED:.*]] = tensor.extract %[[ARG4]][] : tensor<f32>\n-CHECK-NEXT:           %[[ADD:.*]] = arith.addf %[[ARG3_EXTRACTED]], %[[ARG4_EXTRACTED]] : f32\n-CHECK-NEXT:           %[[FROM_ELEMENTS:.*]] = tensor.from_elements %[[ADD]] : tensor<f32>\n-CHECK-NEXT:           stablehlo.return %[[FROM_ELEMENTS]] : tensor<f32>\n+CHECK-NEXT:           %[[ARG3_SCALAR:.*]] = xtile.to_scalar %[[ARG3]] : tensor<f32>\n+CHECK-NEXT:           %[[ARG4_SCALAR:.*]] = xtile.to_scalar %[[ARG4]] : tensor<f32>\n+CHECK-NEXT:           %[[ADD:.*]] = arith.addf %[[ARG3_SCALAR]], %[[ARG4_SCALAR]] : f32\n+CHECK-NEXT:           %[[TO_TENSOR:.*]] = xtile.to_tensor %[[ADD]] : f32\n+CHECK-NEXT:           stablehlo.return %[[TO_TENSOR]] : tensor<f32>\n CHECK-NEXT:       }\n CHECK:            arith.mulf\n CHECK-DAG:        xtile.insert {{.*}} into %[[P2]]\n@@ -1278,11 +1278,11 @@ CHECK-DAG:        %[[COL_INDEX_COPY:.*]] = xla.apply_indexing #[[MAP1]](%[[TID]]\n CHECK:            xtile.extract %[[P2]][%[[ROW_INDEX_COPY]], %[[COL_INDEX_COPY]]] [1, 1] [1, 1] : {{.*}} -> tensor<1x1xf32>\n CHECK:            stablehlo.reduce\n CHECK-NEXT:       reducer(%[[ARG4:[^:]*]]: tensor<f32>, %[[ARG5:[^:]*]]: tensor<f32>)  {\n-CHECK-NEXT:           %[[ARG4_EXTRACTED:.*]] = tensor.extract %[[ARG4]][] : tensor<f32>\n-CHECK-NEXT:           %[[ARG5_EXTRACTED:.*]] = tensor.extract %[[ARG5]][] : tensor<f32>\n-CHECK-NEXT:           %[[MAX:.*]] = arith.maximumf %[[ARG4_EXTRACTED]], %[[ARG5_EXTRACTED]] : f32\n-CHECK-NEXT:           %[[FROM_ELEMENTS_MAX:.*]] = tensor.from_elements %[[MAX]] : tensor<f32>\n-CHECK-NEXT:           stablehlo.return %[[FROM_ELEMENTS_MAX]] : tensor<f32>\n+CHECK-NEXT:           %[[ARG4_SCALAR:.*]] = xtile.to_scalar %[[ARG4]] : tensor<f32>\n+CHECK-NEXT:           %[[ARG5_SCALAR:.*]] = xtile.to_scalar %[[ARG5]] : tensor<f32>\n+CHECK-NEXT:           %[[MAX:.*]] = arith.maximumf %[[ARG4_SCALAR]], %[[ARG5_SCALAR]] : f32\n+CHECK-NEXT:           %[[TO_TENSOR_MAX:.*]] = xtile.to_tensor %[[MAX]] : f32\n+CHECK-NEXT:           stablehlo.return %[[TO_TENSOR_MAX]] : tensor<f32>\n CHECK-NEXT:       }\n CHECK:            xtile.insert {{.*}} into %[[P3]]{{.*}}\n )\"));\n@@ -2054,11 +2054,11 @@ ENTRY main {\n // CHECK: %[[TILE_OFFSET_I32:.*]] = arith.index_cast %[[TILE_OFFSET]]\n // CHECK: %[[C17:.*]] = arith.constant 17 : i32\n // CHECK: %[[THRESHOLD:.*]] = arith.subi %[[C17]], %[[TILE_OFFSET_I32]]\n-// CHECK: %[[FROM_ELEMENTS_THRESHOLD:.*]] = tensor.from_elements %[[THRESHOLD]]\n-// CHECK: %[[THRESHOLD_SPLAT:.*]] = stablehlo.broadcast_in_dim %[[FROM_ELEMENTS_THRESHOLD]], dims = []\n+// CHECK: %[[TO_TENSOR_THRESHOLD:.*]] = xtile.to_tensor %[[THRESHOLD]]\n+// CHECK: %[[THRESHOLD_SPLAT:.*]] = stablehlo.broadcast_in_dim %[[TO_TENSOR_THRESHOLD]], dims = []\n // CHECK: %[[MASK:.*]] = arith.cmpi slt, %[[IOTA]], %[[THRESHOLD_SPLAT]]\n-// CHECK: %[[FROM_ELEMENTS_PAD_VALUE:.*]] = tensor.from_elements %[[PAD_VALUE]]\n-// CHECK: %[[PAD_SPLAT:.*]] = stablehlo.broadcast_in_dim %[[FROM_ELEMENTS_PAD_VALUE]], dims = []\n+// CHECK: %[[TO_TENSOR_PAD_VALUE:.*]] = xtile.to_tensor %[[PAD_VALUE]]\n+// CHECK: %[[PAD_SPLAT:.*]] = stablehlo.broadcast_in_dim %[[TO_TENSOR_PAD_VALUE]], dims = []\n // CHECK: %[[SELECT:.*]] = arith.select %[[MASK]], %[[EXTRACT]], %[[PAD_SPLAT]]\n \n // CHECK:   xtile.insert %[[SELECT]] into %[[OUT]]\n@@ -2636,8 +2636,8 @@ ENTRY main {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto xtile_module_and_hlo_module,\n       CreateXTileIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n-CHECK:       %[[RES_FROM_ELEMENTS:.*]] = tensor.from_elements %[[ARG:.*]] : tensor<f32>\n-CHECK:       stablehlo.broadcast_in_dim %[[RES_FROM_ELEMENTS]], dims = []\n+CHECK:       %[[RES_TO_TENSOR:.*]] = xtile.to_tensor %[[ARG:.*]] : f32\n+CHECK:       stablehlo.broadcast_in_dim %[[RES_TO_TENSOR]], dims = []\n           )\"));\n \n   TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck("
        },
        {
            "sha": "cabd592cc1ead56a097db1fc9d21cb3a58e6a5ed",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_shared_dialect_test.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc?ref=52a8c6aa15734299538fabb99afcbd16b3e13f4d",
            "patch": "@@ -179,8 +179,8 @@ ENTRY e {\n       this, *module->GetComputationWithName(\"broadcast_in_dim_fusion\"),\n       block_level_parameters,\n       R\"(\n-CHECK: %[[RES_FROM_ELEMENTS:.*]] = tensor.from_elements %[[ARG:.*]] : tensor<f32>\n-CHECK: %[[RES:.*]] = stablehlo.broadcast_in_dim %[[RES_FROM_ELEMENTS]], dims = [] : (tensor<f32>) -> tensor<16x32x8xf32>\n+CHECK: %[[TO_TENSOR:.*]] = xtile.to_tensor %[[ARG:.*]] : f32\n+CHECK: %[[RES:.*]] = stablehlo.broadcast_in_dim %[[TO_TENSOR]], dims = [] : (tensor<f32>) -> tensor<16x32x8xf32>\n )\"));\n }\n \n@@ -217,14 +217,14 @@ ENTRY e {\n       block_level_parameters,\n       R\"(\n CHECK: %[[REDUCE_INPUT:.*]] = arith.select {{.*}}\n-CHECK: %[[INIT_VALUE_FROM_ELEMENTS:.*]] = tensor.from_elements %{{.*}} : tensor<f32>\n-CHECK: %[[RES:.*]] = stablehlo.reduce(%[[REDUCE_INPUT]] init: %[[INIT_VALUE_FROM_ELEMENTS]]) across dimensions = [0] : (tensor<256x16xf32>, tensor<f32>) -> tensor<16xf32>\n+CHECK: %[[INIT_VALUE_TO_TENSOR:.*]] = xtile.to_tensor %{{.*}} : f32\n+CHECK: %[[RES:.*]] = stablehlo.reduce(%[[REDUCE_INPUT]] init: %[[INIT_VALUE_TO_TENSOR]]) across dimensions = [0] : (tensor<256x16xf32>, tensor<f32>) -> tensor<16xf32>\n CHECK: reducer(%[[ARG_0:.*]]: tensor<f32>, %[[ARG_1:.*]]: tensor<f32>)  {\n-CHECK:   %[[EXTRACTED_0:.*]] = tensor.extract %[[ARG_0]][] : tensor<f32>\n-CHECK:   %[[EXTRACTED_1:.*]] = tensor.extract %[[ARG_1]][] : tensor<f32>\n-CHECK:   %[[SUM:.*]] = arith.addf %[[EXTRACTED_0]], %[[EXTRACTED_1]] : f32\n-CHECK:   %[[FROM_ELEMENTS:.*]] = tensor.from_elements %[[SUM]] : tensor<f32>\n-CHECK:   stablehlo.return %[[FROM_ELEMENTS]] : tensor<f32>\n+CHECK:   %[[SCALAR_0:.*]] = xtile.to_scalar %[[ARG_0]] : tensor<f32>\n+CHECK:   %[[SCALAR_1:.*]] = xtile.to_scalar %[[ARG_1]] : tensor<f32>\n+CHECK:   %[[SUM:.*]] = arith.addf %[[SCALAR_0]], %[[SCALAR_1]] : f32\n+CHECK:   %[[TO_TENSOR:.*]] = xtile.to_tensor %[[SUM]] : f32\n+CHECK:   stablehlo.return %[[TO_TENSOR]] : tensor<f32>\n CHECK: }\n )\"));\n }"
        },
        {
            "sha": "32e41cf1f2803d1868b01b300656aaab76b7c5cc",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/passes.td",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td?ref=52a8c6aa15734299538fabb99afcbd16b3e13f4d",
            "patch": "@@ -211,8 +211,9 @@ def StableHLOLowerToTritonPass\n     : Pass<\"stablehlo-lower-to-triton\", \"mlir::ModuleOp\"> {\n   let summary = \"Lowers StableHLO operations to their Triton equivalent.\";\n   let dependentDialects = [\n-    \"stablehlo::StablehloDialect\",\n-    \"triton::TritonDialect\"\n+    \"::mlir::stablehlo::StablehloDialect\",\n+    \"::mlir::triton::TritonDialect\",\n+    \"::xla::xtile::XTileDialect\",\n   ];\n   let constructor = \"CreateStableHLOLowerToTritonPass()\";\n }"
        },
        {
            "sha": "23343e2e983c0aaad2f772b55c380e2fc51c3946",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/stablehlo_lower_to_triton.cc",
            "status": "modified",
            "additions": 44,
            "deletions": 111,
            "changes": 155,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc?ref=52a8c6aa15734299538fabb99afcbd16b3e13f4d",
            "patch": "@@ -18,12 +18,17 @@ limitations under the License.\n #include <utility>\n \n #include \"absl/log/check.h\"\n+#include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/SmallVector.h\"\n+#include \"llvm/Support/Casting.h\"\n+#include \"llvm/Support/raw_ostream.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/Diagnostics.h\"\n+#include \"mlir/IR/IRMapping.h\"\n+#include \"mlir/IR/Location.h\"\n #include \"mlir/IR/PatternMatch.h\"\n #include \"mlir/IR/Value.h\"\n #include \"mlir/Pass/Pass.h\"\n@@ -33,6 +38,7 @@ limitations under the License.\n #include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n #include \"stablehlo/dialect/StablehloOps.h\"\n #include \"xla/codegen/emitter_loc_op_builder.h\"\n+#include \"xla/codegen/xtile/ir/xtile_ops.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n \n namespace mlir::triton::xla {\n@@ -111,12 +117,9 @@ class LowerBroadcastInDim\n \n     if (input_shape.empty()) {\n       auto broadcast_dim_input = op.getOperand();\n-      auto broadcast_dim_input_element_type =\n-          broadcast_dim_input.getType().getElementType();\n \n-      auto extracted = mlir::tensor::ExtractOp::create(\n-          rewriter, op.getLoc(), broadcast_dim_input_element_type,\n-          broadcast_dim_input);\n+      auto extracted = ::xla::xtile::ToScalarOp::create(rewriter, op.getLoc(),\n+                                                        broadcast_dim_input);\n \n       rewriter.replaceOpWithNewOp<ttir::SplatOp>(op, op.getResult().getType(),\n                                                  extracted);\n@@ -171,49 +174,56 @@ class LowerReduce : public mlir::OpRewritePattern<stablehlo::ReduceOp> {\n \n     auto triton_reduce_op = ttir::ReduceOp::create(\n         rewriter, op.getLoc(), adjusted_result_types, op.getInputs(), axis);\n-\n     Region& triton_reduce_region = triton_reduce_op.getCombineOp();\n-    rewriter.cloneRegionBefore(op.getBody(), triton_reduce_region,\n-                               triton_reduce_region.end());\n+\n+    mlir::Block& old_block = op.getBody().front();\n+    llvm::SmallVector<Type> arg_types;\n+    llvm::SmallVector<mlir::Location> arg_locs;\n+    for (auto old_arg_type : old_block.getArgumentTypes()) {\n+      arg_types.push_back(\n+          llvm::cast<ShapedType>(old_arg_type).getElementType());\n+      arg_locs.push_back(op.getLoc());\n+    }\n+    rewriter.createBlock(&triton_reduce_region, triton_reduce_region.begin(),\n+                         arg_types, arg_locs);\n+\n+    mlir::IRMapping mapping;\n     Block& triton_reduce_region_block = triton_reduce_region.front();\n-    for (mlir::BlockArgument& argument :\n-         triton_reduce_region_block.getArguments()) {\n-      auto extract_op = cast<mlir::tensor::ExtractOp>(*argument.user_begin());\n-\n-      auto scalar_type =\n-          cast<mlir::RankedTensorType>(argument.getType()).getElementType();\n-      argument.setType(scalar_type);\n-      rewriter.replaceOp(extract_op, argument);\n+    rewriter.setInsertionPointToStart(&triton_reduce_region_block);\n+    for (auto [old_arg, new_arg] :\n+         llvm::zip(old_block.getArguments(),\n+                   triton_reduce_region_block.getArguments())) {\n+      auto to_tensor_op =\n+          ::xla::xtile::ToTensorOp::create(rewriter, op.getLoc(), new_arg);\n+      mapping.map(old_arg, to_tensor_op);\n     }\n \n-    Operation* terminator = triton_reduce_region_block.getTerminator();\n-    rewriter.setInsertionPointToEnd(&triton_reduce_region_block);\n-    SmallVector<Value> return_operands;\n-    for (Value operand : terminator->getOperands()) {\n-      auto defining_op = operand.getDefiningOp();\n-      return_operands.push_back(mlir::tensor::ExtractOp::create(\n-          rewriter, defining_op->getLoc(),\n-          cast<mlir::RankedTensorType>(operand.getType()).getElementType(),\n-          defining_op->getResult(0)));\n+    for (mlir::Operation& op : old_block.without_terminator()) {\n+      rewriter.clone(op, mapping);\n     }\n-    rewriter.replaceOpWithNewOp<ttir::ReduceReturnOp>(terminator,\n-                                                      return_operands);\n \n-    rewriter.replaceOp(op, triton_reduce_op);\n+    SmallVector<Value> return_operands;\n+    for (Value operand : old_block.getTerminator()->getOperands()) {\n+      return_operands.push_back(::xla::xtile::ToScalarOp::create(\n+          rewriter, op->getLoc(), mapping.lookup(operand)));\n+    }\n+    ttir::ReduceReturnOp::create(rewriter, op.getLoc(), return_operands);\n \n     // Replace usages of the original op results. If the original result was a\n     // 0-rank tensor, we need to wrap the scalar result of tt.reduce in a\n-    // tensor.from_elements op.\n+    // tensor.to_tensor op.\n     rewriter.setInsertionPointAfter(triton_reduce_op);\n+    llvm::SmallVector<Value> new_results;\n     for (const auto& triton_result : triton_reduce_op.getResults()) {\n       if (mlir::isa<mlir::ShapedType>(triton_result.getType())) {\n-        continue;\n+        new_results.push_back(triton_result);\n+      } else {\n+        new_results.push_back(::xla::xtile::ToTensorOp::create(\n+            rewriter, op.getLoc(), triton_result));\n       }\n-      auto extract_op =\n-          cast<mlir::tensor::ExtractOp>(*triton_result.user_begin());\n-\n-      rewriter.replaceOp(extract_op, triton_result);\n     }\n+\n+    rewriter.replaceOp(op, new_results);\n     return mlir::success();\n   }\n \n@@ -225,18 +235,6 @@ class LowerReduce : public mlir::OpRewritePattern<stablehlo::ReduceOp> {\n   // the result is a zero rank tensor.\n   mlir::LogicalResult VerifyOpIsCompatibleWithTritonReduce(\n       stablehlo::ReduceOp op, mlir::PatternRewriter& rewriter) const {\n-    if (mlir::failed(VerifyReducerArgs(op, rewriter))) {\n-      return mlir::failure();\n-    }\n-\n-    if (mlir::failed(VerifyReducerResults(op, rewriter))) {\n-      return mlir::failure();\n-    }\n-\n-    if (mlir::failed(VerifyResults(op, rewriter))) {\n-      return mlir::failure();\n-    }\n-\n     // Check that the reduction is along a single dimension.\n     auto dimensions = op.getDimensions();\n     if (dimensions.size() != 1) {\n@@ -246,71 +244,6 @@ class LowerReduce : public mlir::OpRewritePattern<stablehlo::ReduceOp> {\n \n     return mlir::success();\n   }\n-\n-  mlir::LogicalResult VerifyReducerArgs(stablehlo::ReduceOp op,\n-                                        mlir::PatternRewriter& rewriter) const {\n-    // Check that all arguments get extracted into a scalar.\n-    for (mlir::BlockArgument& argument : op.getBody().front().getArguments()) {\n-      if (!argument.hasOneUse()) {\n-        return rewriter.notifyMatchFailure(\n-            op, \"Expected a single user for an argument to a reduce combiner.\");\n-      }\n-      if (!dyn_cast<mlir::tensor::ExtractOp>(*argument.user_begin())) {\n-        return rewriter.notifyMatchFailure(op,\n-                                           \"Expected a tensor extract op as \"\n-                                           \"user of reduce combiner argument.\");\n-      }\n-    }\n-\n-    return mlir::success();\n-  }\n-\n-  mlir::LogicalResult VerifyReducerResults(\n-      stablehlo::ReduceOp op, mlir::PatternRewriter& rewriter) const {\n-    // Check that all outputs get created by a from_elements op.\n-    for (Value operand : op.getBody().front().getTerminator()->getOperands()) {\n-      if (!operand.hasOneUse()) {\n-        return rewriter.notifyMatchFailure(\n-            op->getLoc(),\n-            \"Expected a single user for an output of a reduce combiner.\");\n-      }\n-      auto from_elements =\n-          operand.getDefiningOp<mlir::tensor::FromElementsOp>();\n-      if (!from_elements) {\n-        return rewriter.notifyMatchFailure(op->getLoc(),\n-                                           \"Expected a from_elements op as \"\n-                                           \"user of reduce combiner output.\");\n-      }\n-    }\n-    return mlir::success();\n-  }\n-\n-  mlir::LogicalResult VerifyResults(stablehlo::ReduceOp op,\n-                                    mlir::PatternRewriter& rewriter) const {\n-    // Check that all results get created by a from_elements op.\n-    for (Value result : op.getResults()) {\n-      auto shaped_type = cast<mlir::ShapedType>(result.getType());\n-      // If the result is a shaped type, then we don't need to do anything.\n-      if (shaped_type.getRank() != 0) {\n-        continue;\n-      }\n-\n-      if (!result.hasOneUse()) {\n-        return rewriter.notifyMatchFailure(\n-            op->getLoc(), \"Expected a single user for reduce result.\");\n-      }\n-\n-      auto extract_op = dyn_cast<mlir::tensor::ExtractOp>(*result.user_begin());\n-\n-      if (!extract_op) {\n-        return rewriter.notifyMatchFailure(\n-            op->getLoc(),\n-            \"Expected a tensor extract op as \"\n-            \"the only user of 0 rank reduce result.\");\n-      }\n-    }\n-    return mlir::success();\n-  }\n };\n \n class LowerReshape : public mlir::OpRewritePattern<stablehlo::ReshapeOp> {"
        },
        {
            "sha": "6beb328033aa320696d45ec2585846447c191d36",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/stable_hlo_to_triton_lowering.mlir",
            "status": "modified",
            "additions": 23,
            "deletions": 69,
            "changes": 92,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir?ref=52a8c6aa15734299538fabb99afcbd16b3e13f4d",
            "patch": "@@ -44,12 +44,12 @@ func.func @lower_broadcast_in_dim(%arg0: tensor<2x4xf32>) -> tensor<8x2x4x16xf32\n   return %0 : tensor<8x2x4x16xf32>\n }\n \n-// CHECK: func @lower_broadcast_in_dim_on_0d_tensor_produced_by_from_elements_to_splat(%[[ARG0:.*]]: f32) -> tensor<4x2xf32>\n-func.func @lower_broadcast_in_dim_on_0d_tensor_produced_by_from_elements_to_splat(%arg0: f32) -> tensor<4x2xf32> {\n-  // CHECK-NOT: tensor.from_elements\n+// CHECK: func @lower_broadcast_in_dim_on_0d_tensor_produced_by_to_tensor_to_splat(%[[ARG0:.*]]: f32) -> tensor<4x2xf32>\n+func.func @lower_broadcast_in_dim_on_0d_tensor_produced_by_to_tensor_to_splat(%arg0: f32) -> tensor<4x2xf32> {\n+  // CHECK-NOT: xtile.to_tensor\n   // CHECK: %[[RES:.*]] = tt.splat %[[ARG0]] : f32 -> tensor<4x2xf32>\n-  %from_elements = tensor.from_elements %arg0 : tensor<f32>\n-  %0 = stablehlo.broadcast_in_dim %from_elements, dims = [] : (tensor<f32>) -> tensor<4x2xf32>\n+  %to_tensor = xtile.to_tensor %arg0 : f32\n+  %0 = stablehlo.broadcast_in_dim %to_tensor, dims = [] : (tensor<f32>) -> tensor<4x2xf32>\n   // CHECK: return %[[RES]] : tensor<4x2xf32>\n   return %0 : tensor<4x2xf32>\n }\n@@ -63,10 +63,10 @@ func.func @reduce(%arg0: tensor<16x8xf32>) -> tensor<8xf32> {\n   ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n     // CHECK: %[[RES:.*]] = arith.addf %[[ARG1]], %[[ARG2]] : f32\n     // CHECK: tt.reduce.return %[[RES]] : f32\n-    %extracted_arg1 = tensor.extract %arg1[] : tensor<f32>\n-    %extracted_arg2 = tensor.extract %arg2[] : tensor<f32>\n+    %extracted_arg1 = xtile.to_scalar %arg1 : tensor<f32>\n+    %extracted_arg2 = xtile.to_scalar %arg2 : tensor<f32>\n     %2 = arith.addf %extracted_arg1, %extracted_arg2 : f32\n-    %3 = tensor.from_elements %2 : tensor<f32>\n+    %3 = xtile.to_tensor %2 : f32\n     stablehlo.return %3 : tensor<f32>\n   }) {dimensions = array<i64: 0>} : (tensor<16x8xf32>, tensor<f32>) -> tensor<8xf32>\n   return %1 : tensor<8xf32>\n@@ -81,95 +81,49 @@ func.func @reduce_to_scalar_followed_by_extract(%arg0: tensor<16xf32>) -> f32 {\n   ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n     // CHECK: %[[RES:.*]] = arith.addf %[[ARG1]], %[[ARG2]] : f32\n     // CHECK: tt.reduce.return %[[RES]] : f32\n-    %extracted_arg1 = tensor.extract %arg1[] : tensor<f32>\n-    %extracted_arg2 = tensor.extract %arg2[] : tensor<f32>\n+    %extracted_arg1 = xtile.to_scalar %arg1 : tensor<f32>\n+    %extracted_arg2 = xtile.to_scalar %arg2 : tensor<f32>\n     %2 = arith.addf %extracted_arg1, %extracted_arg2 : f32\n-    %3 = tensor.from_elements %2 : tensor<f32>\n+    %3 = xtile.to_tensor %2 : f32\n     stablehlo.return %3 : tensor<f32>\n   }) {dimensions = array<i64: 0>} : (tensor<16xf32>, tensor<f32>) -> tensor<f32>\n-  // CHECK-NOT: tensor.from_elements\n-  // CHECK-NOT: tensor.extract\n-  %extract = tensor.extract %1[] : tensor<f32>\n+  // CHECK-NOT: xtile.to_tensor\n+  // CHECK-NOT: xtile.to_scalar\n+  %extract = xtile.to_scalar %1 : tensor<f32>\n   // CHECK: return %[[REDUCE_RESULT:.*]] : f32\n   return %extract : f32\n }\n \n-// CHECK: func @reduce_to_zero_rank_tensor_without_extract_falls_back_to_stablehlo(%[[ARG0:.*]]: tensor<16xf32>) -> tensor<f32>\n-func.func @reduce_to_zero_rank_tensor_without_extract_falls_back_to_stablehlo(%arg0: tensor<16xf32>) -> tensor<f32> {\n-  // CHECK: %[[CST:.*]] = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n-  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n-  // CHECK: %[[REDUCE_RESULT:.*]] = stablehlo.reduce(%[[ARG0]] init: %[[CST]]) across dimensions = [0] : (tensor<16xf32>, tensor<f32>) -> tensor<f32>\n-  %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n-  ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n-    %extracted_arg1 = tensor.extract %arg1[] : tensor<f32>\n-    %extracted_arg2 = tensor.extract %arg2[] : tensor<f32>\n-    %2 = arith.addf %extracted_arg1, %extracted_arg2 : f32\n-    %3 = tensor.from_elements %2 : tensor<f32>\n-    stablehlo.return %3 : tensor<f32>\n-  }) {dimensions = array<i64: 0>} : (tensor<16xf32>, tensor<f32>) -> tensor<f32>\n-  return %1 : tensor<f32>\n-}\n-\n // CHECK: func @reduce_over_multiple_dimensions_falls_back_to_stablehlo(%[[ARG0:.*]]: tensor<16x8x4xf32>) -> tensor<4xf32>\n func.func @reduce_over_multiple_dimensions_falls_back_to_stablehlo(%arg0: tensor<16x8x4xf32>) -> tensor<4xf32> {\n   %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n   // CHECK: %[[RES:.*]] = stablehlo.reduce(%[[ARG0]] init: %{{.*}}) across dimensions = [0, 1] : (tensor<16x8x4xf32>, tensor<f32>) -> tensor<4xf32>\n   %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n   ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n-    %extracted_arg1 = tensor.extract %arg1[] : tensor<f32>\n-    %extracted_arg2 = tensor.extract %arg2[] : tensor<f32>\n+    %extracted_arg1 = xtile.to_scalar %arg1 : tensor<f32>\n+    %extracted_arg2 = xtile.to_scalar %arg2 : tensor<f32>\n     %2 = arith.addf %extracted_arg1, %extracted_arg2 : f32\n-    %3 = tensor.from_elements %2 : tensor<f32>\n+    %3 = xtile.to_tensor %2 : f32\n     stablehlo.return %3 : tensor<f32>\n   }) {dimensions = array<i64: 0, 1>} : (tensor<16x8x4xf32>, tensor<f32>) -> tensor<4xf32>\n   // CHECK: return %[[RES]] : tensor<4xf32>\n   return %1 : tensor<4xf32>\n }\n \n-// CHECK: func @reduce_without_extract_on_input_falls_back_to_stablehlo(%[[ARG0:.*]]: tensor<16x8xf32>) -> tensor<8xf32>\n-func.func @reduce_without_extract_on_input_falls_back_to_stablehlo(%arg0: tensor<16x8xf32>) -> tensor<8xf32> {\n-  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n-  // CHECK: %[[RES:.*]] = stablehlo.reduce(%[[ARG0]] init: %{{.*}}) applies stablehlo.add across dimensions = [0] : (tensor<16x8xf32>, tensor<f32>) -> tensor<8xf32>\n-  %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n-  ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n-    %2 = stablehlo.add %arg1, %arg2 : tensor<f32>\n-    stablehlo.return %2 : tensor<f32>\n-  }) {dimensions = array<i64: 0>} : (tensor<16x8xf32>, tensor<f32>) -> tensor<8xf32>\n-  // CHECK: return %[[RES]] : tensor<8xf32>\n-  return %1 : tensor<8xf32>\n-}\n-\n-// CHECK: func @reduce_without_from_elements_on_output_falls_back_to_stablehlo(%[[ARG0:.*]]: tensor<16x8xf32>) -> tensor<8xf32>\n-func.func @reduce_without_from_elements_on_output_falls_back_to_stablehlo(%arg0: tensor<16x8xf32>) -> tensor<8xf32> {\n-  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n-  // CHECK: %[[RES:.*]] = stablehlo.reduce(%[[ARG0]] init: %{{.*}}) across dimensions = [0] : (tensor<16x8xf32>, tensor<f32>) -> tensor<8xf32>\n-  %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n-  ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n-    %extracted_arg1 = tensor.extract %arg1[] : tensor<f32>\n-    %extracted_arg2 = tensor.extract %arg2[] : tensor<f32>\n-    %from_elements_arg1 = tensor.from_elements %extracted_arg1 : tensor<f32>\n-    %from_elements_arg2 = tensor.from_elements %extracted_arg2 : tensor<f32>\n-    %2 = stablehlo.add %from_elements_arg1, %from_elements_arg2 : tensor<f32>\n-    stablehlo.return %2 : tensor<f32>\n-  }) {dimensions = array<i64: 0>} : (tensor<16x8xf32>, tensor<f32>) -> tensor<8xf32>\n-  // CHECK: return %[[RES]] : tensor<8xf32>\n-  return %1 : tensor<8xf32>\n-}\n-\n // CHECK: func @reduce_with_multiple_inputs(%[[ARG0:.*]]: tensor<16x8xf32>, %[[ARG1:.*]]: tensor<16x8xf32>) -> tensor<8xf32>\n func.func @reduce_with_multiple_inputs(%arg0: tensor<16x8xf32>, %arg1: tensor<16x8xf32>) -> tensor<8xf32> {\n   %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n   // CHECK: %[[REDUCE_RESULT:.*]] = \"tt.reduce\"(%[[ARG0]], %[[ARG1]]) <{axis = 0 : i32}> ({\n   %1, %2 = \"stablehlo.reduce\"(%arg0, %arg1, %0, %0) ({\n   ^bb0(%arg0_reducer: tensor<f32>, %arg1_reducer: tensor<f32>, %arg2_reducer: tensor<f32>, %arg3_reducer: tensor<f32>):\n-    %extracted_arg0 = tensor.extract %arg0_reducer[] : tensor<f32>\n-    %extracted_arg1 = tensor.extract %arg1_reducer[] : tensor<f32>\n+    %extracted_arg0 = xtile.to_scalar %arg0_reducer : tensor<f32>\n+    %extracted_arg1 = xtile.to_scalar %arg1_reducer : tensor<f32>\n     %2 = arith.addf %extracted_arg0, %extracted_arg1 : f32\n-    %3 = tensor.from_elements %2 : tensor<f32>\n-    %extracted_arg2 = tensor.extract %arg2_reducer[] : tensor<f32>\n-    %extracted_arg3 = tensor.extract %arg3_reducer[] : tensor<f32>\n+    %3 = xtile.to_tensor %2 : f32\n+    %extracted_arg2 = xtile.to_scalar %arg2_reducer : tensor<f32>\n+    %extracted_arg3 = xtile.to_scalar %arg3_reducer : tensor<f32>\n     %4 = arith.addf %extracted_arg2, %extracted_arg3 : f32\n-    %5 = tensor.from_elements %4 : tensor<f32>\n+    %5 = xtile.to_tensor %4 : f32\n     stablehlo.return %3, %5 : tensor<f32>, tensor<f32>\n   }) {dimensions = array<i64: 0>} : (tensor<16x8xf32>, tensor<16x8xf32>, tensor<f32>, tensor<f32>) -> (tensor<8xf32>, tensor<8xf32>)\n   return %1 : tensor<8xf32>"
        },
        {
            "sha": "9742649af3d5248c3cb81bd3d567ce51c60c9191",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_lower_xtile_pass.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_xtile_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/52a8c6aa15734299538fabb99afcbd16b3e13f4d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_xtile_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_xtile_pass.cc?ref=52a8c6aa15734299538fabb99afcbd16b3e13f4d",
            "patch": "@@ -212,8 +212,8 @@ class XTileExtractToTriton\n           extract_op->getLoc(), memref_to_ptr, ttir::CacheModifier::NONE,\n           ttir::EvictionPolicy::NORMAL, /*isVolatile=*/false);\n \n-      rewriter.replaceOpWithNewOp<mlir::tensor::FromElementsOp>(\n-          extract_op, extract_op.getType(), scalar_value);\n+      rewriter.replaceOpWithNewOp<::xla::xtile::ToTensorOp>(extract_op,\n+                                                            scalar_value);\n       return mlir::success();\n     }\n \n@@ -250,8 +250,8 @@ class XTileInsertToTriton\n         CreateMemrefToPtr(rewriter, insert_op.getDestination());\n \n     if (insert_op.getSource().getType().getRank() == 0) {\n-      mlir::Value scalar_value = rewriter.create<mlir::tensor::ExtractOp>(\n-          insert_op.getLoc(), insert_op.getSource());\n+      mlir::Value scalar_value = ::xla::xtile::ToScalarOp::create(\n+          rewriter, insert_op.getLoc(), insert_op.getSource());\n \n       rewriter.replaceOpWithNewOp<ttir::StoreOp>(\n           insert_op, memref_to_ptr, scalar_value, /*mask=*/nullptr);"
        }
    ],
    "stats": {
        "total": 375,
        "additions": 125,
        "deletions": 250
    }
}