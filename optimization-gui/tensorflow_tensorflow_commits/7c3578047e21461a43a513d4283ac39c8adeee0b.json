{
    "author": "ermilovmaxim",
    "message": "remove left over files\n\nPiperOrigin-RevId: 816745413",
    "sha": "7c3578047e21461a43a513d4283ac39c8adeee0b",
    "files": [
        {
            "sha": "d919e88d93ec10a9888607355e9af93d390e80e4",
            "filename": "third_party/xla/xla/service/gpu/runtime_intrinsics.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 164,
            "changes": 164,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/33bb8f381285149caa98acfadbbaecf5f726cd6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fruntime_intrinsics.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/33bb8f381285149caa98acfadbbaecf5f726cd6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fruntime_intrinsics.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fruntime_intrinsics.cc?ref=33bb8f381285149caa98acfadbbaecf5f726cd6f",
            "patch": "@@ -1,164 +0,0 @@\n-/* Copyright 2022 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/gpu/runtime_intrinsics.h\"\n-\n-#include <cstdint>\n-#include <memory>\n-#include <string>\n-#include <vector>\n-\n-#include \"absl/log/check.h\"\n-#include \"absl/log/log.h\"\n-#include \"absl/status/status.h\"\n-#include \"absl/strings/ascii.h\"\n-#include \"absl/strings/match.h\"\n-#include \"absl/strings/str_cat.h\"\n-#include \"absl/strings/str_replace.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"absl/strings/substitute.h\"\n-#include \"xla/ffi/ffi.h\"\n-#include \"xla/ffi/ffi_api.h\"\n-#include \"xla/layout_util.h\"\n-#include \"xla/literal.h\"\n-#include \"xla/service/collective_ops_utils.h\"\n-#include \"xla/service/custom_call_status.h\"\n-#include \"xla/service/custom_call_target_registry.h\"\n-#include \"xla/service/platform_util.h\"\n-#include \"xla/shape.h\"\n-#include \"xla/shape_util.h\"\n-#include \"xla/stream_executor/memory_allocation.h\"\n-#include \"xla/stream_executor/stream.h\"\n-#include \"xla/tsl/platform/errors.h\"\n-#include \"xla/tsl/platform/statusor.h\"\n-#include \"xla/util.h\"\n-#include \"xla/xla_data.pb.h\"\n-\n-namespace xla {\n-\n-namespace {\n-\n-std::string GetGpuPlatformName() {\n-  return absl::AsciiStrToUpper(\n-      PlatformUtil::CanonicalPlatformName(\"gpu\").value());\n-}\n-\n-absl::Status AssertionCustomCall(\n-    se::Stream* stream, ffi::Buffer<PRED> buffer, absl::string_view error_msg,\n-    xla::ffi::Result<xla::ffi::Buffer<xla::TOKEN>> res) {\n-  if (!stream) {\n-    return Internal(\"Stream is nullptr.\");\n-  }\n-\n-  int8_t expected = false;\n-  int64_t byte_size = sizeof(int8_t);\n-  CHECK_EQ(byte_size, ShapeUtil::ByteSizeOfPrimitiveType(PrimitiveType::PRED));\n-  TF_RETURN_IF_ERROR(\n-      stream->Memcpy(&expected, buffer.device_memory(), byte_size));\n-  TF_RETURN_IF_ERROR(stream->BlockHostUntilDone());\n-  if (!static_cast<bool>(expected)) {\n-    return Internal(\"%s\", error_msg);\n-  }\n-\n-  return absl::OkStatus();\n-}\n-\n-void NopReturnTokenCustomCall(void* stream_handle, void** buffers,\n-                              const char* opaque, int opaque_len,\n-                              XlaCustomCallStatus* status) {\n-  VLOG(1) << \"NopReturnTokenCustomCall called.\";\n-}\n-\n-absl::Status DebugPrintCustomCall(se::Stream* stream, ffi::RemainingArgs args,\n-                                  absl::string_view format,\n-                                  ffi::Result<ffi::Buffer<xla::TOKEN>> res) {\n-  if (!stream) {\n-    return Internal(\"Stream is nullptr.\");\n-  }\n-\n-  std::vector<ffi::AnyBuffer> args_buffers;\n-  args_buffers.reserve(args.size());\n-  for (int i = 0; i < args.size(); ++i) {\n-    absl::StatusOr<ffi::AnyBuffer> arg = args.get<ffi::AnyBuffer>(i);\n-    if (!arg.ok()) {\n-      return arg.status();\n-    }\n-    args_buffers.push_back(*arg);\n-  }\n-\n-  std::string formatted(format);\n-\n-  // Iterate in reverse order to match the longest string to substitute first.\n-  for (int i = args_buffers.size() - 1; i >= 0; --i) {\n-    std::string to_substitute = absl::StrCat(\"$\", i);\n-    if (!absl::StrContains(formatted, to_substitute)) {\n-      return absl::FailedPreconditionError(absl::Substitute(\n-          \"Missing formatter for argument $0 in debug print custom call\", i));\n-    }\n-    const ffi::AnyBuffer& arg = args_buffers[i];\n-    int64_t size_bytes = arg.size_bytes();\n-    TF_ASSIGN_OR_RETURN(std::unique_ptr<se::MemoryAllocation> host_buffer,\n-                        stream->parent()->HostMemoryAllocate(size_bytes));\n-    TF_RETURN_IF_ERROR(\n-        stream->Memcpy(host_buffer->opaque(), arg.device_memory(), size_bytes));\n-    TF_RETURN_IF_ERROR(stream->BlockHostUntilDone());\n-\n-    Shape shape = ShapeUtil::MakeShape(arg.element_type(), arg.dimensions());\n-    LayoutUtil::SetToDefaultLayout(&shape);\n-    MutableBorrowingLiteral literal(static_cast<char*>(host_buffer->opaque()),\n-                                    shape);\n-    formatted =\n-        absl::StrReplaceAll(formatted, {{to_substitute, literal.ToString()}});\n-  }\n-\n-  LOG(INFO) << formatted;\n-\n-  return absl::OkStatus();\n-}\n-\n-}  // namespace\n-\n-// This custom call copies its arguments to the host and pretty-prints them as\n-// an info log. It takes in a \"format\" attribute to help identify the arguments\n-// in the log. \"Format\" follows the convention of `absl::Substitute`, i.e.,\n-// positional arguments are specified by `$0`, `$1`, etc.\n-XLA_FFI_DEFINE_HANDLER(kXlaGpuDebugPrintCustomCall, DebugPrintCustomCall,\n-                       ffi::Ffi::Bind()\n-                           .Ctx<ffi::Stream>()\n-                           .RemainingArgs()\n-                           .Attr<absl::string_view>(\"format\")\n-                           .Ret<xla::ffi::Buffer<xla::TOKEN>>());\n-\n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), kXlaGpuDebugPrintCustomCallTag,\n-                         GetGpuPlatformName(), kXlaGpuDebugPrintCustomCall);\n-\n-XLA_FFI_DEFINE_HANDLER(kXlaGpuAssertCustomCall, AssertionCustomCall,\n-                       ffi::Ffi::Bind()\n-                           .Ctx<ffi::Stream>()\n-                           .Arg<ffi::Buffer<xla::PRED>>()\n-                           .Attr<absl::string_view>(\"error_msg\")\n-                           .Ret<xla::ffi::Buffer<xla::TOKEN>>());\n-\n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), kXlaGpuAssertCustomCallTag,\n-                         GetGpuPlatformName(), kXlaGpuAssertCustomCall);\n-\n-// This allows measuring exported HLOs where kOutfeed and kSendDone has been\n-// replaced with NopReturnToken. In that case the runtime of the original\n-// kOutfeed and kSendDone operations is not measured.\n-XLA_REGISTER_CUSTOM_CALL_TARGET_WITH_SYM(\n-    std::string(kNopReturnTokenCustomCallTarget), NopReturnTokenCustomCall,\n-    GetGpuPlatformName());\n-\n-}  // namespace xla"
        },
        {
            "sha": "2b522a899f86dc708ed882d5dc17d5871f82d880",
            "filename": "third_party/xla/xla/service/gpu/runtime_intrinsics.h",
            "status": "removed",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/33bb8f381285149caa98acfadbbaecf5f726cd6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fruntime_intrinsics.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/33bb8f381285149caa98acfadbbaecf5f726cd6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fruntime_intrinsics.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fruntime_intrinsics.h?ref=33bb8f381285149caa98acfadbbaecf5f726cd6f",
            "patch": "@@ -1,31 +0,0 @@\n-/* Copyright 2022 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_SERVICE_GPU_RUNTIME_INTRINSICS_H_\n-#define XLA_SERVICE_GPU_RUNTIME_INTRINSICS_H_\n-\n-#include \"absl/strings/string_view.h\"\n-\n-namespace xla {\n-\n-inline constexpr absl::string_view kXlaGpuAssertCustomCallTag =\n-    \"__xla_gpu_assert\";\n-\n-inline constexpr absl::string_view kXlaGpuDebugPrintCustomCallTag =\n-    \"__xla_gpu_debug_print\";\n-\n-}  // namespace xla\n-\n-#endif  // XLA_SERVICE_GPU_RUNTIME_INTRINSICS_H_"
        },
        {
            "sha": "6644623f000281ab42c69c2dacf452c46d26043d",
            "filename": "third_party/xla/xla/service/gpu/runtime_intrinsics_test.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 145,
            "changes": 145,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/33bb8f381285149caa98acfadbbaecf5f726cd6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fruntime_intrinsics_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/33bb8f381285149caa98acfadbbaecf5f726cd6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fruntime_intrinsics_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fruntime_intrinsics_test.cc?ref=33bb8f381285149caa98acfadbbaecf5f726cd6f",
            "patch": "@@ -1,145 +0,0 @@\n-/* Copyright 2023 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include <memory>\n-#include <utility>\n-\n-#include <gmock/gmock.h>\n-#include <gtest/gtest.h>\n-#include \"absl/base/log_severity.h\"\n-#include \"absl/log/scoped_mock_log.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"xla/hlo/ir/hlo_module.h\"\n-#include \"xla/tests/hlo_test_base.h\"\n-#include \"xla/tsl/platform/statusor.h\"\n-#include \"xla/tsl/platform/test.h\"\n-\n-namespace xla {\n-namespace gpu {\n-namespace {\n-\n-using RuntimeIntrinsicsTest = HloTestBase;\n-\n-using ::testing::EndsWith;\n-using ::testing::HasSubstr;\n-\n-TEST_F(RuntimeIntrinsicsTest, NopReturnTokenWorks) {\n-  constexpr absl::string_view kHloText = R\"(\n-HloModule m\n-\n-ENTRY e {\n-  constant = u32[2]{0} constant({0, 1})\n-  ROOT nop_return_token = token[] custom-call(constant), custom_call_target=\"NopReturnToken\", custom_call_has_side_effect=true, api_version=API_VERSION_STATUS_RETURNING\n-})\";\n-\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          GetOptimizedModule(kHloText));\n-\n-  // The parameter of the NopReturnToken is not removed.\n-  EXPECT_EQ(module->entry_computation()->instruction_count(), 2);\n-  // Can run.\n-  EXPECT_TRUE(Run(std::move(module), /*run_hlo_passes=*/false));\n-}\n-\n-TEST_F(RuntimeIntrinsicsTest, AssertionCustomCall) {\n-  constexpr absl::string_view kHloText = R\"(\n-HloModule m\n-\n-ENTRY e {\n-  constant = pred[] constant(true)\n-  ROOT nop_return_token = token[] custom-call(constant), backend_config=\"{error_msg = \\\"1\\\"}\", custom_call_target=\"__xla_gpu_assert\", custom_call_has_side_effect=true, api_version=API_VERSION_TYPED_FFI\n-})\";\n-\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          GetOptimizedModule(kHloText));\n-\n-  // The parameter of the NopReturnToken is not removed.\n-  EXPECT_EQ(module->entry_computation()->instruction_count(), 2);\n-  // Can run.\n-  EXPECT_TRUE(Run(std::move(module), /*run_hlo_passes=*/false));\n-}\n-\n-TEST_F(RuntimeIntrinsicsTest, AssertionCustomCallFalse) {\n-  constexpr absl::string_view kHloText = R\"(\n-HloModule m\n-\n-ENTRY e {\n-  constant = pred[] constant(false)\n-  ROOT nop_return_token = token[] custom-call(constant), backend_config=\"{error_msg = \\\"1\\\"}\", custom_call_target=\"__xla_gpu_assert\", custom_call_has_side_effect=true, api_version=API_VERSION_TYPED_FFI\n-})\";\n-\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          GetOptimizedModule(kHloText));\n-\n-  // The parameter of the NopReturnToken is not removed.\n-  EXPECT_EQ(module->entry_computation()->instruction_count(), 2);\n-  // Can run.\n-  EXPECT_FALSE(Run(std::move(module), /*run_hlo_passes=*/false));\n-}\n-\n-TEST_F(RuntimeIntrinsicsTest, DebugPrintCustomCallFailsWhenFormatIsMissing) {\n-  constexpr absl::string_view kHloText = R\"(\n-HloModule m\n-\n-ENTRY e {\n-  constant = f32[2]{0} constant({1, 2})\n-  ROOT print_token = token[] custom-call(constant),\n-    backend_config=\"{format = \\\"test format\\\"}\",\n-    custom_call_target=\"__xla_gpu_debug_print\",\n-    custom_call_has_side_effect=true,\n-    api_version=API_VERSION_TYPED_FFI\n-})\";\n-\n-  ::testing::AssertionResult result = Run(kHloText, /*run_hlo_passes=*/false);\n-  EXPECT_FALSE(result);\n-  EXPECT_THAT(result.message(), HasSubstr(\"Missing formatter for argument 0\"));\n-}\n-\n-TEST_F(RuntimeIntrinsicsTest, DebugPrintCustomCallWithCorrectLogsAsInfo) {\n-  constexpr absl::string_view kHloText = R\"(\n-HloModule m\n-\n-ENTRY e {\n-  constant = f32[2]{0} constant({1, 2})\n-  constant2 = f16[3]{0} constant({3, 4, 5})\n-  ROOT print_token = token[] custom-call(constant, constant2),\n-    backend_config=\"{format = \\\"test format $0 $1\\\"}\",\n-    custom_call_target=\"__xla_gpu_debug_print\",\n-    custom_call_has_side_effect=true,\n-    api_version=API_VERSION_TYPED_FFI\n-})\";\n-\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          GetOptimizedModule(kHloText));\n-\n-  // The parameters of the custom call are not removed.\n-  EXPECT_EQ(module->entry_computation()->instruction_count(), 3);\n-  absl::ScopedMockLog mock_log(absl::MockLogDefault::kIgnoreUnexpected);\n-  EXPECT_CALL(mock_log,\n-              Log(absl::LogSeverity::kInfo, EndsWith(\"runtime_intrinsics.cc\"),\n-                  HasSubstr(\"test format f32[2] {1, 2} f16[3] {3, 4, 5}\")));\n-  // Run the program once before starting capturing the locks. This works around\n-  // a deadlock caused by ScopedMockLog.\n-  std::unique_ptr<HloModule> module2 = module->Clone();\n-  EXPECT_TRUE(Run(std::move(module2), /*run_hlo_passes=*/false));\n-  mock_log.StartCapturingLogs();\n-  // Runs successfully and logs the expected info.\n-  EXPECT_TRUE(Run(std::move(module), /*run_hlo_passes=*/false));\n-  mock_log.StopCapturingLogs();\n-}\n-\n-}  // namespace\n-}  // namespace gpu\n-}  // namespace xla"
        }
    ],
    "stats": {
        "total": 340,
        "additions": 0,
        "deletions": 340
    }
}