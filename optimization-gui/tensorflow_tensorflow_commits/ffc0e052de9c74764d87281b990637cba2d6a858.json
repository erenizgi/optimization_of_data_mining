{
    "author": "tensorflower-gardener",
    "message": "Adds an option for Hlo Module's CreateFromProto to not preserve instruction unique ids and reassigned them in a compacted way. Options is turned off for now but should be the new default moving forward. Deprecates RemapInstructionIds.\n\nPiperOrigin-RevId: 822146834",
    "sha": "ffc0e052de9c74764d87281b990637cba2d6a858",
    "files": [
        {
            "sha": "fde53b5064d02a15a2712b9ba34944d2a3351b35",
            "filename": "third_party/xla/xla/hlo/ir/BUILD",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD?ref=ffc0e052de9c74764d87281b990637cba2d6a858",
            "patch": "@@ -246,15 +246,23 @@ xla_cc_test(\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n+        \"//xla/hlo/analysis:alias_info\",\n+        \"//xla/hlo/analysis:hlo_ordering\",\n         \"//xla/hlo/parser:hlo_parser\",\n         \"//xla/hlo/testlib:filecheck\",\n         \"//xla/hlo/utils:hlo_query\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/service:buffer_value\",\n         \"//xla/service:hlo_module_config\",\n+        \"//xla/service:hlo_proto_util\",\n+        \"//xla/service:logical_buffer\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:status\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n         \"@com_google_absl//absl/container:btree\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/hash\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:string_view\","
        },
        {
            "sha": "325d8783a41943f8e0d0e72f202c93641b5162a7",
            "filename": "third_party/xla/xla/hlo/ir/hlo_computation.cc",
            "status": "modified",
            "additions": 82,
            "deletions": 47,
            "changes": 129,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_computation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_computation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_computation.cc?ref=ffc0e052de9c74764d87281b990637cba2d6a858",
            "patch": "@@ -152,15 +152,15 @@ std::unique_ptr<HloComputation> HloComputation::Builder::Build(\n HloComputation::HloComputation(\n     const std::string& name, int parameter_count,\n     std::vector<std::unique_ptr<HloInstruction>>* instructions,\n-    HloInstruction* root_instruction, bool from_proto)\n+    HloInstruction* root_instruction, bool preserve_instruction_ids)\n     : unique_id_(-1),\n       root_instruction_(root_instruction),\n       instruction_count_(0),\n       name_(NameUniquer::GetSanitizedName(name)) {\n   param_instructions_.resize(parameter_count, nullptr);\n   bool root_found = false;\n \n-  if (from_proto) {\n+  if (preserve_instruction_ids) {\n     // Pre-allocate all instructions in the vector since it state should be\n     // identical.\n     int32_t max_instruction_local_id = 0;\n@@ -191,7 +191,7 @@ HloComputation::HloComputation(\n       param_instructions_[param_no] = instruction.get();\n     }\n     root_found |= instruction.get() == root_instruction_;\n-    AddInstructionInternal(std::move(instruction), from_proto);\n+    AddInstructionInternal(std::move(instruction), preserve_instruction_ids);\n   }\n   CHECK(root_found)\n       << \"\\nERROR: root instruction is not present in computation.\";\n@@ -398,7 +398,7 @@ absl::flat_hash_map<HloInstruction*, int>* const HloComputation::GetCallersMap()\n }\n \n HloInstruction* HloComputation::AddInstructionInternal(\n-    std::unique_ptr<HloInstruction> instruction, bool from_proto) {\n+    std::unique_ptr<HloInstruction> instruction, bool preserve_unique_id) {\n   if (parent() != nullptr) {\n     instruction->UniquifyName(parent());\n   }\n@@ -408,18 +408,18 @@ HloInstruction* HloComputation::AddInstructionInternal(\n   info.opcode_ = pinst->opcode();\n   info.inst_ = pinst;\n \n-  if (from_proto && pinst->local_id_ >= 0) {\n-    // Already set unique id from proto sources therefore it is preserved.\n-    // Calls for AddInstructionInternal from proto sources assume that all space\n-    // in instructions_ vector has been pre-allocated.\n+  if (preserve_unique_id && pinst->local_id_ >= 0) {\n+    // Already set unique id previously therefore it is preserved.\n+    // Calls for AddInstructionInternal from preserving sources assume that all\n+    // space in instructions_ vector has been pre-allocated.\n     CHECK(pinst->local_id() < instructions_.size())\n         << \"Instruction local_id \" << pinst->local_id()\n         << \" is out of range [0, \" << instructions_.size()\n         << \") when adding instruction from proto\";\n     next_instruction_unique_id_ = instructions_.size();\n     instructions_[pinst->local_id()] = info;\n   } else {\n-    // Unset instructions from proto sources and regular instructions get\n+    // Unset instructions from preserving sources and regular instructions get\n     // assigned a new unique id.\n     pinst->ClearUniqueIdInternal();\n     // Must match the size of the instructions_ vector.\n@@ -1286,22 +1286,31 @@ HloComputationProto HloComputation::ToProto() const {\n HloComputation::CreateFromProto(\n     const HloComputationProto& proto,\n     const absl::flat_hash_map<int64_t, HloComputation*>& computation_map,\n-    bool prohibit_empty_literal) {\n+    bool prohibit_empty_literal, bool preserve_instruction_ids,\n+    absl::flat_hash_map<int64_t, int64_t>* id_remap_map) {\n+  // Instruction_map uses the ids of the instructions as defined in the proto.\n+  // The final instruction ids will change if preserve_instruction_ids is false.\n   absl::flat_hash_map<int64_t, HloInstruction*> instruction_map;\n   absl::flat_hash_map<HloInstruction*, int64_t> to_proto_id;\n   std::vector<std::unique_ptr<HloInstruction>> instructions;\n-  tsl::protobuf::internal::RepeatedPtrIterator<const xla::HloInstructionProto>\n-      instruction_with_max_id = absl::c_max_element(\n-          proto.instructions(),\n-          [](const HloInstructionProto& a, const HloInstructionProto& b) {\n-            return HloInstruction::CalculateLocalId(a.id()) <\n-                   HloInstruction::CalculateLocalId(b.id());\n-          });\n-  int32_t max_proto_instruction_local_id =\n-      instruction_with_max_id == proto.instructions().end()\n-          ? 0\n-          : HloInstruction::CalculateLocalId(instruction_with_max_id->id());\n-  instructions.resize(max_proto_instruction_local_id + 1);\n+\n+  if (preserve_instruction_ids) {\n+    // If preserve_instruction_ids is true, we need to reserve space for all\n+    // instructions in the proto, even if they are gaps to keep the condition\n+    // that instructions[instruction->local_id_] == instruction.\n+    tsl::protobuf::internal::RepeatedPtrIterator<const xla::HloInstructionProto>\n+        instruction_with_max_id = absl::c_max_element(\n+            proto.instructions(),\n+            [](const HloInstructionProto& a, const HloInstructionProto& b) {\n+              return HloInstruction::CalculateLocalId(a.id()) <\n+                     HloInstruction::CalculateLocalId(b.id());\n+            });\n+    int32_t max_proto_instruction_local_id =\n+        instruction_with_max_id == proto.instructions().end()\n+            ? 0\n+            : HloInstruction::CalculateLocalId(instruction_with_max_id->id());\n+    instructions.resize(max_proto_instruction_local_id + 1);\n+  }\n \n   int64_t parameter_count = 0;\n \n@@ -1313,51 +1322,72 @@ HloComputation::CreateFromProto(\n     if (instruction->opcode() == HloOpcode::kParameter) {\n       parameter_count++;\n     }\n+\n     int32_t local_proto_id =\n         HloInstruction::CalculateLocalId(instruction_proto.id());\n+\n     TF_RET_CHECK(!ContainsKey(instruction_map, local_proto_id));\n     instruction_map[local_proto_id] = instruction.get();\n     to_proto_id[instruction.get()] = local_proto_id;\n-    // The instruction's id is the same as the index in the instructions\n-    // vector. This will be reproduced when placing the instruction in the\n-    // instructions vector.\n-    TF_RET_CHECK(instruction->local_id_ >= 0 &&\n-                 instruction->local_id_ < instructions.size())\n-        << \"Instruction local id is out of bounds\" << \" Value is \"\n-        << instruction->local_id_ << \" and size is \" << instructions.size();\n-    TF_RET_CHECK(instructions[instruction->local_id_] == nullptr)\n-        << \"Instruction \" << instruction->name() << \" has duplicate local id \"\n-        << instruction->local_id_;\n-    instructions[instruction->local_id_] = std::move(instruction);\n+    if (preserve_instruction_ids) {\n+      // The instruction's id is the same as the index in the instructions\n+      // vector. This will be reproduced when placing the instruction in the\n+      // instructions vector.\n+      TF_RET_CHECK(instruction->local_id_ >= 0 &&\n+                   instruction->local_id_ < instructions.size())\n+          << \"Instruction local id is out of bounds\" << \" Value is \"\n+          << instruction->local_id_ << \" and size is \" << instructions.size();\n+      TF_RET_CHECK(instructions[instruction->local_id_] == nullptr)\n+          << \"Instruction \" << instruction->name() << \" has duplicate local id \"\n+          << instruction->local_id_;\n+      instructions[instruction->local_id_] = std::move(instruction);\n+    } else {\n+      // Instructions will be placed sequentially in the instructions vector.\n+      // The local id will be assigned sequentially starting from 0.\n+      instruction->local_id_ = instructions.size();\n+      if (id_remap_map != nullptr) {\n+        // When creating a new HloComputation from proto, the computation ids\n+        // are preserved.\n+        (*id_remap_map)[instruction_proto.id()] =\n+            HloInstruction::CalculateUniqueId(proto.id(),\n+                                              instruction->local_id_);\n+      }\n+      instructions.push_back(std::move(instruction));\n+    }\n   }\n-\n   TF_RET_CHECK(proto.root_id() != -1);\n   int32_t root_local_id = HloInstruction::CalculateLocalId(proto.root_id());\n-  TF_RET_CHECK(ContainsKey(instruction_map, root_local_id));\n+  TF_RET_CHECK(ContainsKey(instruction_map, root_local_id))\n+      << \"Root instruction not found in instruction map\";\n   HloInstruction* root = instruction_map.at(root_local_id);\n \n   // Check if each computation's instructions are unique in their local id\n   // (lowers 32bits)\n   absl::flat_hash_set<int32_t> instruction_local_ids;\n   for (const auto& instruction : instructions) {\n-    // Since the instructions vector replicates the instructions from the proto,\n-    // if there are any gaps in the sequence of instruction ids in the proto, it\n-    // will be represented as a null instruction in the vector.\n-    if (instruction == nullptr) {\n+    // Since the instructions vector replicates the instructions from the proto\n+    // when preserve_instruction_ids is true, if there are any gaps in the\n+    // sequence of instruction ids in the proto, it will be represented as a\n+    // null instruction in the vector.\n+    if (instruction == nullptr && preserve_instruction_ids) {\n       continue;\n     }\n     TF_RET_CHECK(to_proto_id.contains(instruction.get()))\n         << \"Instruction not found in to_proto_id map: \" << instruction->name()\n         << \" local_id: \" << instruction->local_id_;\n     int32_t local_id_from_proto =\n         HloInstruction::CalculateLocalId(to_proto_id[instruction.get()]);\n-    TF_RET_CHECK(local_id_from_proto == instruction->local_id_)\n-        << \"Instruction has different local id from proto: proto: \"\n-        << local_id_from_proto << \" vs local: \" << instruction->local_id_;\n-    TF_RET_CHECK(!instruction_local_ids.contains(local_id_from_proto))\n+\n+    if (preserve_instruction_ids) {\n+      TF_RET_CHECK(local_id_from_proto == instruction->local_id_)\n+          << \"Instruction has different local id from proto: proto: \"\n+          << local_id_from_proto << \" vs local: \" << instruction->local_id_;\n+    }\n+\n+    TF_RET_CHECK(!instruction_local_ids.contains(instruction->local_id_))\n         << \"Instruction \" << instruction->name()\n-        << \" has duplicate internal unique id \" << local_id_from_proto;\n-    instruction_local_ids.insert(local_id_from_proto);\n+        << \" has duplicate internal unique id \" << instruction->local_id_;\n+    instruction_local_ids.insert(instruction->local_id_);\n   }\n   TF_RETURN_IF_ERROR([&]() -> absl::Status {\n     std::vector<bool> parameters_seen(parameter_count);\n@@ -1384,8 +1414,13 @@ HloComputation::CreateFromProto(\n     return absl::OkStatus();\n   }());\n \n-  auto computation = absl::WrapUnique(new HloComputation(\n-      proto.name(), parameter_count, &instructions, root, /*from_proto=*/true));\n+  // Because we have formed the instructions vector manually, we can have the\n+  // creator of the HLO computation assume the instructions vector is well\n+  // formed and that the instruction ids are consistent. Will also assume that\n+  // instructions[instruction->local_id_] == instruction.\n+  auto computation = absl::WrapUnique(\n+      new HloComputation(proto.name(), parameter_count, &instructions, root,\n+                         /*preserve_instruction_ids=*/true));\n   computation->SetUniqueIdHelper(proto.id());\n   if (!proto.execution_thread().empty()) {\n     computation->SetExecutionThread(proto.execution_thread());"
        },
        {
            "sha": "5f3f26ad766bb17003cbdea5fbc57164ccb81c28",
            "filename": "third_party/xla/xla/hlo/ir/hlo_computation.h",
            "status": "modified",
            "additions": 12,
            "deletions": 3,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_computation.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_computation.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_computation.h?ref=ffc0e052de9c74764d87281b990637cba2d6a858",
            "patch": "@@ -400,10 +400,18 @@ class HloComputation {\n   //   computation_map: a map from computation id to HloComputation*. This map\n   //     must contain all computations which the newly constructed computation\n   //     calls.\n+  //   preserve_instruction_ids: if true, the instruction ids in the proto will\n+  //     be preserved. Otherwise, the instruction ids will be remapped to start\n+  //     from 0.\n+  //   id_remap_map: if not null, it will be populated with a map from the\n+  //     original instruction ids in the proto as is, to the remapped\n+  //     instructions full unique ids using the proto's computation id. This is\n+  //     only meaningful if preserve_instruction_ids is false.\n   static absl::StatusOr<std::unique_ptr<HloComputation>> CreateFromProto(\n       const HloComputationProto& proto,\n       const absl::flat_hash_map<int64_t, HloComputation*>& computation_map,\n-      bool prohibit_empty_literal = true);\n+      bool prohibit_empty_literal = true, bool preserve_instruction_ids = true,\n+      absl::flat_hash_map<int64_t, int64_t>* id_remap_map = nullptr);\n \n   // Generates a hash value of an HLO computation. Hash considers\n   // information on opcode, shape, operands, and typically a root instruction.\n@@ -948,12 +956,13 @@ class HloComputation {\n   explicit HloComputation(\n       const std::string& name, int parameter_count,\n       std::vector<std::unique_ptr<HloInstruction>>* instructions,\n-      HloInstruction* root_instruction, bool from_proto = false);\n+      HloInstruction* root_instruction, bool preserve_instruction_ids = false);\n \n   // Internal helper for adding instructions. Only assigns a unique id if it is\n   // not already set.\n   HloInstruction* AddInstructionInternal(\n-      std::unique_ptr<HloInstruction> instruction, bool from_proto = false);\n+      std::unique_ptr<HloInstruction> instruction,\n+      bool preserve_unique_id = false);\n \n   // Internal helper for comparison with different options.\n   bool EqualInternal("
        },
        {
            "sha": "521eb5b2d479f9a836e71d57f773ca2fef60098d",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction.h",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h?ref=ffc0e052de9c74764d87281b990637cba2d6a858",
            "patch": "@@ -314,8 +314,9 @@ class HloInstruction {\n   // Creates an instruction from the given proto. Arguments:\n   //\n   //   proto: the proto to convert from.\n-  //   instruction_map: a map from local instruction id to HloInstruction*. This\n-  //     map must contain all operands of the newly constructed instruction.\n+  //   instruction_map: a map from local instruction id (as defined in the\n+  //     proto) to HloInstruction*. This map must contain all operands of the\n+  //     newly constructed instruction.\n   //   computation_map: a map from computation id to HloComputation*. This map\n   //     must contain all computations which the newly constructed instruction\n   //     calls.\n@@ -1886,6 +1887,13 @@ class HloInstruction {\n     return static_cast<int32_t>(unique_id & 0xFFFFFFFF);\n   }\n \n+  // Returns the parent ID of the instruction by extracting it from the more\n+  // general unique ID. The method does not differentiate between a parentless\n+  // unique id and a unique id with a parent id of 0.\n+  static int32_t CalculateParentId(int64_t unique_id) {\n+    return static_cast<int32_t>(unique_id >> 32);\n+  }\n+\n   bool has_backend_config() const { return !backend_config_.empty(); }\n \n   void clear_backend_config() { backend_config_ = BackendConfigWrapper(); }"
        },
        {
            "sha": "df30601f578c7914493951f09b8d352aeae992b4",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module.cc",
            "status": "modified",
            "additions": 94,
            "deletions": 9,
            "changes": 103,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc?ref=ffc0e052de9c74764d87281b990637cba2d6a858",
            "patch": "@@ -659,7 +659,6 @@ absl::Status HloModule::CheckUniqueNamesAndIdsForComputationsAndInstructions()\n   }\n   return absl::OkStatus();\n }\n-\n /* static */\n absl::Status HloModule::UpdateIdsInSchedule(\n     HloModuleProto& proto, int64_t computation_proto_id,\n@@ -723,13 +722,29 @@ absl::StatusOr<HloModuleProto> HloModule::RemapInstructionIds(\n   return proto_copy;\n }\n \n+/* static */\n+absl::StatusOr<std::unique_ptr<HloModule>> HloModule::CreateFromProto(\n+    const HloModuleProto& proto, const HloModuleConfig& module_config,\n+    BufferAssignmentProto* buffer_assignment_proto,\n+    bool preserve_instruction_ids) {\n+  return CreateFromProto(proto, module_config, /*prohibit_empty_literal=*/true,\n+                         /*comp_envs=*/nullptr, preserve_instruction_ids,\n+                         buffer_assignment_proto);\n+}\n+\n /* static */\n absl::StatusOr<std::unique_ptr<HloModule>> HloModule::CreateFromProto(\n     const HloModuleProto& proto, const HloModuleConfig& module_config,\n     bool prohibit_empty_literal,\n-    std::unique_ptr<CompilationEnvironments> comp_envs) {\n+    std::unique_ptr<CompilationEnvironments> comp_envs,\n+    bool preserve_instruction_ids,\n+    BufferAssignmentProto* buffer_assignment_proto) {\n   VLOG(2) << \"CreateFromProto()\";\n   XLA_VLOG_LINES(3, proto.DebugString());\n+  bool buffer_assignment_needs_remap =\n+      !preserve_instruction_ids && buffer_assignment_proto != nullptr;\n+  bool requires_remap_memorization =\n+      proto.has_schedule() || buffer_assignment_needs_remap;\n \n   // The ProgramShape in the passed in module config must match the shapes of\n   // the entry parameters and root.\n@@ -763,11 +778,20 @@ absl::StatusOr<std::unique_ptr<HloModule>> HloModule::CreateFromProto(\n   absl::flat_hash_map<HloComputation*, int64_t> to_proto_id;\n   std::vector<std::unique_ptr<HloComputation>> computations;\n   HloComputation* entry = nullptr;\n+  // Only used for fixing the schedule or buffer assignment later\n+  absl::flat_hash_map<int64_t, absl::flat_hash_map<int64_t, int64_t>>\n+      computation_id_to_id_remap_map;\n   for (const HloComputationProto& computation_proto : proto.computations()) {\n+    // Old instruction ids to new instruction ids after they are loaded into the\n+    // computation and potentially changed. Only used for fixing the schedule\n+    // or buffer assignment later.\n+    absl::flat_hash_map<int64_t, int64_t> id_remap_map;\n     TF_ASSIGN_OR_RETURN(\n         std::unique_ptr<HloComputation> computation,\n-        HloComputation::CreateFromProto(computation_proto, computation_map,\n-                                        prohibit_empty_literal));\n+        HloComputation::CreateFromProto(\n+            computation_proto, computation_map, prohibit_empty_literal,\n+            preserve_instruction_ids,\n+            requires_remap_memorization ? &id_remap_map : nullptr));\n     CHECK_NE(computation.get(), nullptr);\n     int64_t computation_id = computation_proto.id();\n     TF_RET_CHECK(computation_id != -1);\n@@ -778,6 +802,9 @@ absl::StatusOr<std::unique_ptr<HloModule>> HloModule::CreateFromProto(\n       entry = computation.get();\n     }\n     computations.push_back(std::move(computation));\n+    if (requires_remap_memorization) {\n+      computation_id_to_id_remap_map[computation_id] = std::move(id_remap_map);\n+    }\n   }\n   TF_RET_CHECK(entry != nullptr);\n \n@@ -816,10 +843,20 @@ absl::StatusOr<std::unique_ptr<HloModule>> HloModule::CreateFromProto(\n   if (proto.has_schedule()) {\n     TF_ASSIGN_OR_RETURN(\n         HloSchedule schedule,\n-        HloSchedule::CreateFromProto(module.get(), proto.schedule()));\n+        HloSchedule::CreateFromProto(module.get(), proto.schedule(),\n+                                     preserve_instruction_ids\n+                                         ? nullptr\n+                                         : &computation_id_to_id_remap_map));\n     TF_RETURN_IF_ERROR(module->set_schedule(std::move(schedule)));\n   }\n \n+  // If a pointer to a buffer assignment proto is provided, that means we need\n+  // to keep the HloModule and the Buffer Assignment proto consistent.\n+  if (buffer_assignment_needs_remap) {\n+    TF_RETURN_IF_ERROR(UpdateBufferAssignmentProto(\n+        buffer_assignment_proto, computation_id_to_id_remap_map));\n+  }\n+\n   for (const auto& prefetch : proto.cross_program_prefetches()) {\n     module->AddCrossProgramPrefetch(\n         prefetch.parameter(),\n@@ -879,6 +916,42 @@ absl::StatusOr<std::unique_ptr<HloModule>> HloModule::CreateFromProto(\n   return module;\n }\n \n+/* static */\n+absl::Status HloModule::UpdateBufferAssignmentProto(\n+    BufferAssignmentProto* buffer_assignment_proto,\n+    const absl::flat_hash_map<int64_t, absl::flat_hash_map<int64_t, int64_t>>&\n+        computation_id_to_id_remap_map) {\n+  for (xla::LogicalBufferProto& logical_buffer :\n+       *buffer_assignment_proto->mutable_logical_buffers()) {\n+    int64_t computation_id = HloInstruction::CalculateParentId(\n+        logical_buffer.defined_at().instruction_id());\n+    TF_RET_CHECK(computation_id_to_id_remap_map.contains(computation_id))\n+        << \"Computation id \" << computation_id << \" not found in id remap map.\";\n+    TF_RET_CHECK(computation_id_to_id_remap_map.at(computation_id)\n+                     .contains(logical_buffer.defined_at().instruction_id()))\n+        << \"Instruction id \" << logical_buffer.defined_at().instruction_id()\n+        << \" not found in id remap map for computation id \" << computation_id;\n+    logical_buffer.mutable_defined_at()->set_instruction_id(\n+        computation_id_to_id_remap_map.at(computation_id)\n+            .at(logical_buffer.defined_at().instruction_id()));\n+  }\n+  for (xla::BufferAssignmentProto::BufferAlias& buffer_alias :\n+       *buffer_assignment_proto->mutable_buffer_aliases()) {\n+    int64_t computation_id = HloInstruction::CalculateParentId(\n+        buffer_alias.location().instruction_id());\n+    TF_RET_CHECK(computation_id_to_id_remap_map.contains(computation_id))\n+        << \"Computation id \" << computation_id << \" not found in id remap map.\";\n+    TF_RET_CHECK(computation_id_to_id_remap_map.at(computation_id)\n+                     .contains(buffer_alias.location().instruction_id()))\n+        << \"Instruction id \" << buffer_alias.location().instruction_id()\n+        << \" not found in id remap map for computation id \" << computation_id;\n+    buffer_alias.mutable_location()->set_instruction_id(\n+        computation_id_to_id_remap_map.at(computation_id)\n+            .at(buffer_alias.location().instruction_id()));\n+  }\n+  return absl::OkStatus();\n+}\n+\n /* static */\n absl::StatusOr<HloModuleConfig> HloModule::CreateModuleConfigFromShape(\n     const ProgramShape& program_shape, const DebugOptions& debug_options,\n@@ -986,15 +1059,27 @@ absl::StatusOr<HloModuleConfig> HloModule::CreateModuleConfigFromProto(\n   return config;\n }\n \n+/* static */\n+absl::StatusOr<std::unique_ptr<HloModule>> HloModule::CreateFromProtoWithConfig(\n+    const HloModuleProtoWithConfig& proto,\n+    BufferAssignmentProto* buffer_assignment_proto,\n+    bool preserve_instruction_ids) {\n+  return CreateFromProtoWithConfig(\n+      proto, /*prohibit_empty_literal=*/true,\n+      /*comp_envs=*/nullptr, preserve_instruction_ids, buffer_assignment_proto);\n+}\n+\n absl::StatusOr<std::unique_ptr<HloModule>> HloModule::CreateFromProtoWithConfig(\n     const HloModuleProtoWithConfig& proto, bool prohibit_empty_literal,\n-    std::unique_ptr<CompilationEnvironments> comp_envs) {\n+    std::unique_ptr<CompilationEnvironments> comp_envs,\n+    bool preserve_instruction_ids,\n+    BufferAssignmentProto* buffer_assignment_proto) {\n   const auto& hlo_module_proto = proto.hlo_module();\n   TF_ASSIGN_OR_RETURN(std::unique_ptr<HloModuleConfig> config_ptr,\n                       HloModuleConfig::CreateFromProto(proto.config()));\n-  return HloModule::CreateFromProto(hlo_module_proto, *config_ptr,\n-                                    prohibit_empty_literal,\n-                                    std::move(comp_envs));\n+  return HloModule::CreateFromProto(\n+      hlo_module_proto, *config_ptr, prohibit_empty_literal,\n+      std::move(comp_envs), preserve_instruction_ids, buffer_assignment_proto);\n }\n \n namespace {"
        },
        {
            "sha": "22258b747a0e8c911201696478f95d0406eadfa6",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module.h",
            "status": "modified",
            "additions": 38,
            "deletions": 7,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h?ref=ffc0e052de9c74764d87281b990637cba2d6a858",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include <variant>\n #include <vector>\n \n+#include \"absl/base/attributes.h\"\n #include \"absl/base/thread_annotations.h\"\n #include \"absl/container/btree_map.h\"\n #include \"absl/container/flat_hash_map.h\"\n@@ -492,33 +493,63 @@ class HloModule {\n   // for loading a proto that had its ids manually created, created incorrectly\n   // or in an older version of the compiler. Instructions will only have the\n   // local id in the id field.\n+  ABSL_DEPRECATED(\n+      \"Use CreateFromProto with preserve_instruction_ids=false \"\n+      \"instead.\")\n   static absl::StatusOr<HloModuleProto> RemapInstructionIds(\n       const HloModuleProto& proto);\n \n   // Updates the instruction ids in the computation's schedule to match the new\n   // instruction ids as defined by the old_instr_id_to_new_id map. The map only\n   // needs to be consistent and unique within the computation level.\n+  ABSL_DEPRECATED(\n+      \"Use CreateFromProto with preserve_instruction_ids=false \"\n+      \"instead when loading the HLO module.\")\n   static absl::Status UpdateIdsInSchedule(\n       HloModuleProto& proto, int64_t computation_proto_id,\n       absl::flat_hash_map<int64_t, int64_t>& old_instr_id_to_new_id);\n \n-  // Convert an HloModule to or from a proto.\n+  // Updates all instruction ids in the buffer assignment proto with modified\n+  // instruction ids as defined in the map.\n+  static absl::Status UpdateBufferAssignmentProto(\n+      BufferAssignmentProto* buffer_assignment_proto,\n+      const absl::flat_hash_map<int64_t, absl::flat_hash_map<int64_t, int64_t>>&\n+          computation_id_to_id_remap_map);\n+\n+  // Convert an HloModule to a proto.\n   HloModuleProto ToProto() const;\n \n-  // Converts an HloModuleProto to an HloModule. If the module had its ids\n-  // manually changed or was created in an older version of the compiler, it\n-  // might be necessary to call RemapInstructionIds to make the ids consistent\n-  // and compact.\n+  // Converts an HloModuleProto to an HloModule. If preserve_instruction_ids is\n+  // true, the instruction ids in the proto will be preserved. Otherwise, the\n+  // instruction ids will be remapped to be consecutive starting from 0. If the\n+  // conversion is using too much memory, preserve_instruction_ids should be\n+  // set to false. If a pointer to a buffer assignment proto is provided, that\n+  // means the proto will be updated to keep the HloModule and the Buffer\n+  // Assignment proto consistent.\n   static absl::StatusOr<std::unique_ptr<HloModule>> CreateFromProto(\n       const HloModuleProto& proto, const HloModuleConfig& module_config,\n       bool prohibit_empty_literal = true,\n-      std::unique_ptr<CompilationEnvironments> comp_envs = nullptr);\n+      std::unique_ptr<CompilationEnvironments> comp_envs = nullptr,\n+      bool preserve_instruction_ids = true,\n+      BufferAssignmentProto* buffer_assignment_proto = nullptr);\n+\n+  static absl::StatusOr<std::unique_ptr<HloModule>> CreateFromProto(\n+      const HloModuleProto& proto, const HloModuleConfig& module_config,\n+      BufferAssignmentProto* buffer_assignment_proto,\n+      bool preserve_instruction_ids = true);\n \n   // Convert an HloModule to or from a proto that includes module configuration\n   HloModuleProtoWithConfig ToProtoWithConfig() const;\n   static absl::StatusOr<std::unique_ptr<HloModule>> CreateFromProtoWithConfig(\n       const HloModuleProtoWithConfig& proto, bool prohibit_empty_literal = true,\n-      std::unique_ptr<CompilationEnvironments> comp_envs = nullptr);\n+      std::unique_ptr<CompilationEnvironments> comp_envs = nullptr,\n+      bool preserve_instruction_ids = true,\n+      BufferAssignmentProto* buffer_assignment_proto = nullptr);\n+\n+  static absl::StatusOr<std::unique_ptr<HloModule>> CreateFromProtoWithConfig(\n+      const HloModuleProtoWithConfig& proto,\n+      BufferAssignmentProto* buffer_assignment_proto,\n+      bool preserve_instruction_ids = true);\n \n   // Creates and returns an HloModuleConfig with an appropriate program shape\n   // for the HLO module in the given proto."
        },
        {
            "sha": "73c1825853872d89000360194d33e93b63ca0d3d",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module_test.cc",
            "status": "modified",
            "additions": 342,
            "deletions": 0,
            "changes": 342,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module_test.cc?ref=ffc0e052de9c74764d87281b990637cba2d6a858",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n \n #include <cstddef>\n #include <cstdint>\n+#include <iterator>\n #include <memory>\n #include <optional>\n #include <string>\n@@ -26,23 +27,32 @@ limitations under the License.\n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/container/btree_map.h\"\n+#include \"absl/container/flat_hash_map.h\"\n #include \"absl/hash/hash.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_replace.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/analysis/alias_info.h\"\n+#include \"xla/hlo/analysis/hlo_ordering.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_print_options.h\"\n #include \"xla/hlo/ir/hlo_schedule.h\"\n #include \"xla/hlo/parser/hlo_parser.h\"\n #include \"xla/hlo/testlib/filecheck.h\"\n #include \"xla/hlo/utils/hlo_query.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/buffer_value.h\"\n #include \"xla/service/hlo_module_config.h\"\n+#include \"xla/service/hlo_proto_util.h\"\n+#include \"xla/service/logical_buffer.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/status.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n #include \"xla/util.h\"\n #include \"xla/xla.pb.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -54,8 +64,17 @@ namespace {\n using ::testing::ElementsAre;\n using ::testing::Eq;\n using ::testing::IsEmpty;\n+using ::testing::Pointwise;\n+using ::testing::Property;\n using ::testing::UnorderedElementsAre;\n \n+// Adapts the internal equals proto to work with PointWise\n+MATCHER(EqualsProto, \"\") {\n+  const auto& a = ::testing::get<0>(arg);\n+  const auto& b = ::testing::get<1>(arg);\n+  return ::testing::Matches(tsl::proto_testing::EqualsProto(b))(a);\n+}\n+\n TEST(HloModuleTest, AbslHashValue) {\n   HloModule module1(\"temp_module\", HloModuleConfig());\n   HloModule module2(\"temp_module3\", HloModuleConfig());\n@@ -881,5 +900,328 @@ computations {\n               Eq(remapped_hlo_module_proto.computations(1).root_id()));\n }\n \n+TEST(HloModuleTest, LoadAndFixNonConsecutiveInstructionIds) {\n+  xla::HloModuleProto hlo_module_proto;\n+  ASSERT_TRUE(tsl::protobuf::TextFormat::ParseFromString(\n+      R\"pb(\n+        name: \"some_module\"\n+        entry_computation_name: \"entry_computation\"\n+        computations {\n+          name: \"comp2\"\n+          instructions {\n+            name: \"arg0.comp2\"\n+            opcode: \"parameter\"\n+            shape {\n+              element_type: S32\n+              layout { tail_padding_alignment_in_elements: 1 }\n+            }\n+            id: 21474836499\n+          }\n+          instructions {\n+            name: \"arg1.comp2\"\n+            opcode: \"parameter\"\n+            shape {\n+              element_type: S32\n+              layout { tail_padding_alignment_in_elements: 1 }\n+            }\n+            parameter_number: 1\n+            id: 21474836480\n+          }\n+          instructions {\n+            name: \"add.comp2\"\n+            opcode: \"tuple\"\n+            shape {\n+              element_type: TUPLE\n+              tuple_shapes {\n+                element_type: S32\n+                layout { tail_padding_alignment_in_elements: 1 }\n+              }\n+            }\n+            id: 21474836488\n+            operand_ids: 0\n+            operand_ids: 19\n+          }\n+          instructions {\n+            name: \"XLA_Retvals.comp2\"\n+            opcode: \"tuple\"\n+            shape {\n+              element_type: TUPLE\n+              tuple_shapes {\n+                element_type: S32\n+                layout { tail_padding_alignment_in_elements: 1 }\n+              }\n+            }\n+            id: 21474836487\n+            operand_ids: 0\n+          }\n+          id: 21\n+          root_id: 21474836487\n+        }\n+        computations {\n+          name: \"entry_computation\"\n+          instructions {\n+            name: \"arg0.1\"\n+            opcode: \"parameter\"\n+            shape {\n+              element_type: S32\n+              layout { tail_padding_alignment_in_elements: 1 }\n+            }\n+            id: 4294967297\n+          }\n+          instructions {\n+            name: \"arg1.1\"\n+            opcode: \"parameter\"\n+            shape {\n+              element_type: S32\n+              layout { tail_padding_alignment_in_elements: 1 }\n+            }\n+            parameter_number: 1\n+            id: 4294967298\n+          }\n+          instructions {\n+            name: \"XLA_Retvals.1\"\n+            opcode: \"tuple\"\n+            shape {\n+              element_type: TUPLE\n+              tuple_shapes {\n+                element_type: S32\n+                layout { tail_padding_alignment_in_elements: 1 }\n+              }\n+            }\n+            id: 4294967303\n+            operand_ids: 1\n+          }\n+          id: 1\n+          root_id: 4294967303\n+        }\n+        host_program_shape {\n+          parameters {\n+            element_type: S32\n+            layout { tail_padding_alignment_in_elements: 1 }\n+          }\n+          parameters {\n+            element_type: S32\n+            layout { tail_padding_alignment_in_elements: 1 }\n+          }\n+          result {\n+            element_type: TUPLE\n+            tuple_shapes {\n+              element_type: S32\n+              layout { tail_padding_alignment_in_elements: 1 }\n+            }\n+          }\n+          parameter_names: \"arg0\"\n+          parameter_names: \"arg1\"\n+        }\n+        id: 1\n+        entry_computation_id: 1\n+        schedule {\n+          sequences {\n+            key: 1\n+            value {\n+              instruction_ids: 4294967297\n+              instruction_ids: 4294967298\n+              instruction_ids: 4294967303\n+            }\n+          }\n+          sequences {\n+            key: 21\n+            value {\n+              instruction_ids: 21474836499\n+              instruction_ids: 21474836480\n+              instruction_ids: 21474836488\n+              instruction_ids: 21474836487\n+            }\n+          }\n+        }\n+      )pb\",\n+      &hlo_module_proto));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(HloModuleConfig config,\n+                          xla::HloModule::CreateModuleConfigFromProto(\n+                              hlo_module_proto, xla::DebugOptions()));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<HloModule> module,\n+      xla::HloModule::CreateFromProto(hlo_module_proto, config,\n+                                      /* prohibit_empty_literal= */ true,\n+                                      /* comp_envs= */ nullptr,\n+                                      /* preserve_instruction_ids= */ false));\n+\n+  EXPECT_EQ(module->computation_count(), 2);\n+  HloComputation* entry_computation = module->entry_computation();\n+  HloComputation* computation_2 = *std::next(module->computations().begin());\n+  EXPECT_EQ(entry_computation->instruction_count(), 3);\n+\n+  EXPECT_EQ(computation_2->instruction_count(), 4);\n+  // Check that ids are consecutive\n+  EXPECT_THAT(entry_computation->instructions(),\n+              ElementsAre(Property(&xla::HloInstruction::local_id, 0),\n+                          Property(&xla::HloInstruction::local_id, 1),\n+                          Property(&xla::HloInstruction::local_id, 2)));\n+  // Check correct operand translation for entry computation\n+  EXPECT_EQ(entry_computation->parameter_instruction(0)->name(), \"arg0.1\");\n+  EXPECT_EQ(entry_computation->parameter_instruction(0)->local_id(), 0);\n+  EXPECT_THAT(entry_computation->root_instruction()->operands(),\n+              ElementsAre(entry_computation->parameter_instruction(0)));\n+  // Check correct operand translation for computation 2\n+  EXPECT_THAT(computation_2->parameter_instructions(),\n+              ElementsAre(Property(&xla::HloInstruction::local_id, 0),\n+                          Property(&xla::HloInstruction::local_id, 1)));\n+  EXPECT_THAT(computation_2->parameter_instructions(),\n+              ElementsAre(Property(&xla::HloInstruction::name, \"arg0.comp2\"),\n+                          Property(&xla::HloInstruction::name, \"arg1.comp2\")));\n+  // Retvals has operand with local id 0, which in the proto was arg1.comp2\n+  EXPECT_THAT(computation_2->root_instruction()->operands(),\n+              ElementsAre(computation_2->parameter_instruction(1)));\n+  // Check operands for add.comp2\n+  EXPECT_THAT(computation_2->GetInstructionWithName(\"add.comp2\")->operands(),\n+              ElementsAre(computation_2->parameter_instruction(1),\n+                          computation_2->parameter_instruction(0)));\n+  // Check Hlo Schedule\n+  EXPECT_THAT(\n+      module->schedule().GetOrCreateSequence(entry_computation).instructions(),\n+      ElementsAre(Property(&xla::HloInstruction::local_id, 0),\n+                  Property(&xla::HloInstruction::local_id, 1),\n+                  Property(&xla::HloInstruction::local_id, 2)));\n+  EXPECT_THAT(\n+      module->schedule().GetOrCreateSequence(computation_2).instructions(),\n+      ElementsAre(Property(&xla::HloInstruction::local_id, 0),\n+                  Property(&xla::HloInstruction::local_id, 1),\n+                  Property(&xla::HloInstruction::local_id, 2),\n+                  Property(&xla::HloInstruction::local_id, 3)));\n+}\n+\n+TEST(HloModuleTest, TestHloModuleToFromProtoInvarianceInComputation) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnUnverifiedModule(R\"(\n+  HloModule test_module, is_scheduled=true, entry_computation_layout={(f32[]{:T(256)}, f32[100]{0:T(256)}, f32[100]{0:T(256)})->f32[100]{0:T(256)}}\n+\n+  %fused_computation (param_0.1: f32[100], param_1.3: f32[100], param_2.1: f32[]) -> f32[100] {\n+    %param_2.1 = f32[]{:T(256)S(6)} parameter(2)\n+    %broadcast.1 = f32[100]{0:T(256)} broadcast(%param_2.1), dimensions={}\n+    %param_0.1 = f32[100]{0:T(256)} parameter(0)\n+    %param_1.3 = f32[100]{0:T(256)} parameter(1)\n+    %multiply.1 = f32[100]{0:T(256)} multiply(%broadcast.1, %param_1.3)\n+    %add.1 = f32[100]{0:T(256)} add(%multiply.1, %param_0.1)\n+    ROOT %subtract.1 = f32[100]{0:T(256)} subtract(%add.1, %param_0.1)\n+  }\n+\n+  ENTRY %EntryComputation (p: f32[], p1: f32[100], p2: f32[100]) -> f32[100] {\n+    %p = f32[]{:T(256)} parameter(0)\n+    %copy = f32[]{:T(256)S(6)} copy(%p)\n+    %p2 = f32[100]{0:T(256)} parameter(2)\n+    %p1 = f32[100]{0:T(256)} parameter(1)\n+    ROOT %add_subtract_fusion = f32[100]{0:T(256)} fusion(%p2, %p1, %copy), kind=kLoop, calls=%fused_computation\n+                            })\"));\n+  HloModuleProto module_proto = module->ToProto();\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<HloModule> module_from_proto,\n+      HloModule::CreateFromProto(module_proto, module->config(),\n+                                 /*buffer_assignment_proto=*/nullptr,\n+                                 /*preserve_instruction_ids=*/true));\n+\n+  EXPECT_THAT(\n+      module_proto.computations(),\n+      Pointwise(EqualsProto(), module_from_proto->ToProto().computations()));\n+}\n+\n+TEST(HloModuleTest, TestCreateFromProtoUpdatesBufferAssignment) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnUnverifiedModule(R\"(\n+  HloModule test_module, is_scheduled=true, entry_computation_layout={(f32[]{:T(256)}, f32[100]{0:T(256)}, f32[100]{0:T(256)})->f32[100]{0:T(256)}}\n+\n+  %fused_computation (param_0.1: f32[100], param_1.3: f32[100], param_2.1: f32[]) -> f32[100] {\n+    %param_2.1 = f32[]{:T(256)S(6)} parameter(2)\n+    %broadcast.1 = f32[100]{0:T(256)} broadcast(%param_2.1), dimensions={}\n+    %param_0.1 = f32[100]{0:T(256)} parameter(0)\n+    %param_1.3 = f32[100]{0:T(256)} parameter(1)\n+    %multiply.1 = f32[100]{0:T(256)} multiply(%broadcast.1, %param_1.3)\n+    %add.1 = f32[100]{0:T(256)} add(%multiply.1, %param_0.1)\n+    ROOT %subtract.1 = f32[100]{0:T(256)} subtract(%add.1, %param_0.1)\n+  }\n+\n+  ENTRY %EntryComputation (p: f32[], p1: f32[100], p2: f32[100]) -> f32[100] {\n+    %p = f32[]{:T(256)} parameter(0)\n+    %copy = f32[]{:T(256)S(6)} copy(%p)\n+    %p2 = f32[100]{0:T(256)} parameter(2)\n+    %p1 = f32[100]{0:T(256)} parameter(1)\n+    ROOT %add_subtract_fusion = f32[100]{0:T(256)} fusion(%p2, %p1, %copy), kind=kLoop, calls=%fused_computation\n+                            })\"));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      HloModuleConfig config,\n+      HloModule::CreateModuleConfigFromShape(\n+          module->entry_computation()->ComputeProgramShape(), DebugOptions()));\n+\n+  module->set_config(std::move(config));\n+\n+  // Create and save the HLO proto and the buffer assignment proto for the HLO\n+  // module.\n+  HloProto opt_hlo_module_proto = MakeHloProto(*module);\n+\n+  AliasInfo alias_info;\n+  BufferValue::SizeFunction buffer_size_func =\n+      [](const BufferValue& buffer) -> int64_t {\n+    return ShapeUtil::ByteSizeOf(buffer.shape(), sizeof(void*));\n+  };\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto buffer_assignment,\n+      BufferAssigner::Run(\n+          /*module=*/module.get(),\n+          /*hlo_ordering=*/\n+          std::make_unique<DependencyHloOrdering>(module.get()),\n+          /*buffer_size=*/std::move(buffer_size_func),\n+          /*alias_info=*/&alias_info,\n+          /*color_alignment=*/[](LogicalBuffer::Color) -> int64_t { return 1; },\n+          /*allocate_buffers_for_constants=*/true));\n+\n+  BufferAssignmentProto buffer_assignment_proto = buffer_assignment->ToProto();\n+  *opt_hlo_module_proto.mutable_buffer_assignment() = buffer_assignment_proto;\n+\n+  // Replace instruction ids with non-consecutive ones\n+  absl::flat_hash_map<std::string, std::string> instruction_id_remap_map = {\n+      {\"4294967298\", \"4294967323\"},\n+      {\"4294967299\", \"4294967324\"},\n+      {\"4294967296\", \"4294967363\"},\n+      {\"4294967297\", \"4294967423\"},\n+      {\"4294967300\", \"4294967523\"}};\n+\n+  std::string opt_hlo_module_proto_str;\n+  ASSERT_TRUE(tsl::protobuf::TextFormat::PrintToString(\n+      opt_hlo_module_proto, &opt_hlo_module_proto_str));\n+\n+  ASSERT_GT(\n+      absl::StrReplaceAll(instruction_id_remap_map, &opt_hlo_module_proto_str),\n+      5);\n+\n+  // Load modified HloProto from string and reassign ids instead of preserving\n+  // them.\n+  HloProto opt_hlo_module_proto_modified;\n+  ASSERT_TRUE(tsl::protobuf::TextFormat::ParseFromString(\n+      opt_hlo_module_proto_str, &opt_hlo_module_proto_modified));\n+\n+  // Recreate the hlo module from the altered protos.\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      HloModuleConfig module_config_recreated,\n+      HloModule::CreateModuleConfigFromProto(\n+          opt_hlo_module_proto_modified.hlo_module(), DebugOptions()));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<HloModule> hlo_module_recreated,\n+      HloModule::CreateFromProto(\n+          opt_hlo_module_proto_modified.hlo_module(), module_config_recreated,\n+          opt_hlo_module_proto_modified.mutable_buffer_assignment(),\n+          /*preserve_instruction_ids=*/false));\n+\n+  buffer_size_func = [](const BufferValue& buffer) -> int64_t {\n+    return ShapeUtil::ByteSizeOf(buffer.shape(), sizeof(void*));\n+  };\n+  // Will fail if buffer assignment is not updated in the HLO proto.\n+  TF_EXPECT_OK(BufferAssignment::FromProto(\n+      opt_hlo_module_proto_modified.buffer_assignment(),\n+      hlo_module_recreated.get(), std::move(buffer_size_func), &alias_info));\n+}\n+\n }  // namespace\n }  // namespace xla"
        },
        {
            "sha": "0b29cd724cac02e1867cfa11f59aef4a1743db05",
            "filename": "third_party/xla/xla/hlo/ir/hlo_schedule.cc",
            "status": "modified",
            "additions": 23,
            "deletions": 4,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.cc?ref=ffc0e052de9c74764d87281b990637cba2d6a858",
            "patch": "@@ -47,7 +47,9 @@ limitations under the License.\n namespace xla {\n \n /* static */ absl::StatusOr<HloSchedule> HloSchedule::CreateFromProto(\n-    const HloModule* module, const HloScheduleProto& proto) {\n+    const HloModule* module, const HloScheduleProto& proto,\n+    const absl::flat_hash_map<int64_t, absl::flat_hash_map<int64_t, int64_t>>*\n+        computation_id_to_instruction_id_remap) {\n   absl::flat_hash_map<int64_t, const HloComputation*> id_to_computation;\n   for (const HloComputation* computation : module->computations()) {\n     id_to_computation[computation->unique_id()] = computation;\n@@ -72,14 +74,31 @@ namespace xla {\n \n     HloInstructionSequence& sequence =\n         schedule.GetOrCreateSequence(computation);\n+    if (computation_id_to_instruction_id_remap != nullptr) {\n+      TF_RET_CHECK(\n+          computation_id_to_instruction_id_remap->contains(computation_id))\n+          << \"Computation id \" << computation_id\n+          << \" not found in computation_id_to_instruction_id_remap\";\n+    }\n+\n     for (const int64_t instruction_id : id_sequence.second.instruction_ids()) {\n+      int64_t corrected_instruction_id = instruction_id;\n+      if (computation_id_to_instruction_id_remap != nullptr) {\n+        TF_RET_CHECK(computation_id_to_instruction_id_remap->at(computation_id)\n+                         .contains(instruction_id))\n+            << \"Instruction id \" << instruction_id\n+            << \" not found in its computation's proto_id_to_instruction_id_map\";\n+        corrected_instruction_id =\n+            computation_id_to_instruction_id_remap->at(computation_id)\n+                .at(instruction_id);\n+      }\n       int64_t complete_unique_id = HloInstruction::CalculateUniqueId(\n-          computation->unique_id(), instruction_id);\n+          computation->unique_id(), corrected_instruction_id);\n       auto instr_it = id_to_instruction.find(complete_unique_id);\n       TF_RET_CHECK(instr_it != id_to_instruction.end())\n           << \"No instruction exists in HLO computation \" << computation->name()\n-          << \" with unique id \" << instruction_id << \" (complete unique id \"\n-          << complete_unique_id << \")\";\n+          << \" with unique id \" << corrected_instruction_id\n+          << \" (complete unique id \" << complete_unique_id << \")\";\n       sequence.push_back(instr_it->second);\n     }\n   }"
        },
        {
            "sha": "9e29106d00dd0770d07242749ff4454eadfb0a8b",
            "filename": "third_party/xla/xla/hlo/ir/hlo_schedule.h",
            "status": "modified",
            "additions": 9,
            "deletions": 2,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ffc0e052de9c74764d87281b990637cba2d6a858/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.h?ref=ffc0e052de9c74764d87281b990637cba2d6a858",
            "patch": "@@ -157,9 +157,16 @@ class HloSchedule {\n  public:\n   explicit HloSchedule(const HloModule* module) : module_(module) {}\n \n-  // (De)Serialize an HloSchedule to/from a HloScheduleProto.\n+  // (De)Serialize an HloSchedule to/from a HloScheduleProto. If\n+  // proto_id_to_instruction_id_map is provided, it will be used to map the\n+  // instruction ids in the proto to the instruction ids in the HloModule. This\n+  // is necessary if the HloModuleProto was created with\n+  // preserve_instruction_ids=false. The map must use full instruction unique\n+  // ids as keys.\n   static absl::StatusOr<HloSchedule> CreateFromProto(\n-      const HloModule* module, const HloScheduleProto& proto);\n+      const HloModule* module, const HloScheduleProto& proto,\n+      const absl::flat_hash_map<int64_t, absl::flat_hash_map<int64_t, int64_t>>*\n+          computation_id_to_instruction_id_remap = nullptr);\n   absl::StatusOr<HloScheduleProto> ToProto() const;\n \n   // Returns a reference to the sequence for the given computation."
        }
    ],
    "stats": {
        "total": 692,
        "additions": 618,
        "deletions": 74
    }
}