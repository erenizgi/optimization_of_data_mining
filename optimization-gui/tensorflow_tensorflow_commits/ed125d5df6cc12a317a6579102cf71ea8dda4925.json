{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 809689708",
    "sha": "ed125d5df6cc12a317a6579102cf71ea8dda4925",
    "files": [
        {
            "sha": "73d4469b3b767d1f5927aa1e7515a08f90a47061",
            "filename": "third_party/xla/xla/tsl/distributed_runtime/rpc/coordination/grpc_coordination_client.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ed125d5df6cc12a317a6579102cf71ea8dda4925/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Frpc%2Fcoordination%2Fgrpc_coordination_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ed125d5df6cc12a317a6579102cf71ea8dda4925/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Frpc%2Fcoordination%2Fgrpc_coordination_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Frpc%2Fcoordination%2Fgrpc_coordination_client.cc?ref=ed125d5df6cc12a317a6579102cf71ea8dda4925",
            "patch": "@@ -337,7 +337,7 @@ class GrpcCoordinationClientCache : public CoordinationClientCache {\n   ~GrpcCoordinationClientCache() override = default;\n \n   CoordinationClient* GetClient(const std::string& target) override {\n-    absl::MutexLock l(&clients_mu_);\n+    absl::MutexLock l(clients_mu_);\n     auto it = clients_.find(target);\n     if (it == clients_.end()) {\n       SharedGrpcChannelPtr channel = channel_cache_->FindWorkerChannel(target);\n@@ -370,7 +370,7 @@ class GrpcCoordinationClientCache : public CoordinationClientCache {\n   size_t AssignClientToThread(const std::string& target) {\n     // Round-robin target assignment, but keeps the same target on the same\n     // polling thread always, as this is important for gRPC performance\n-    absl::MutexLock l(&assignment_mu_);\n+    absl::MutexLock l(assignment_mu_);\n     auto it = target_assignments_.find(target);\n     if (it == target_assignments_.end()) {\n       it = target_assignments_"
        },
        {
            "sha": "66594c194f283f55b2643f543096a80d6173e58b",
            "filename": "third_party/xla/xla/tsl/distributed_runtime/rpc/coordination/grpc_coordination_service_impl.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ed125d5df6cc12a317a6579102cf71ea8dda4925/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Frpc%2Fcoordination%2Fgrpc_coordination_service_impl.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ed125d5df6cc12a317a6579102cf71ea8dda4925/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Frpc%2Fcoordination%2Fgrpc_coordination_service_impl.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fdistributed_runtime%2Frpc%2Fcoordination%2Fgrpc_coordination_service_impl.cc?ref=ed125d5df6cc12a317a6579102cf71ea8dda4925",
            "patch": "@@ -84,7 +84,7 @@ void GrpcCoordinationServiceImpl::HandleRPCsLoop() {\n }\n \n void GrpcCoordinationServiceImpl::Shutdown() {\n-  absl::MutexLock l(&shutdown_mu_);\n+  absl::MutexLock l(shutdown_mu_);\n   shutdown_ = true;\n   // This enqueues a special event (with a null tag) that causes the completion\n   // queue to be shut down on the polling thread."
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}