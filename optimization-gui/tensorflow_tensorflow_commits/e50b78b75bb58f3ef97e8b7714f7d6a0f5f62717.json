{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 819038195",
    "sha": "e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717",
    "files": [
        {
            "sha": "a821ce8d7c08e621fd25711b848795d7df58a720",
            "filename": "third_party/xla/xla/tsl/framework/allocator_registry.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_registry.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_registry.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_registry.cc?ref=e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717",
            "patch": "@@ -43,7 +43,7 @@ void AllocatorFactoryRegistry::Register(const char* source_file,\n                                         int source_line, const string& name,\n                                         int priority,\n                                         AllocatorFactory* factory) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   CHECK(!first_alloc_made_) << \"Attempt to register an AllocatorFactory \"\n                             << \"after call to GetAllocator()\";\n   CHECK(!name.empty()) << \"Need a valid name for Allocator\";\n@@ -69,7 +69,7 @@ void AllocatorFactoryRegistry::Register(const char* source_file,\n }\n \n Allocator* AllocatorFactoryRegistry::GetAllocator() {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   first_alloc_made_ = true;\n   FactoryEntry* best_entry = nullptr;\n   for (auto& entry : factories_) {\n@@ -91,7 +91,7 @@ Allocator* AllocatorFactoryRegistry::GetAllocator() {\n }\n \n SubAllocator* AllocatorFactoryRegistry::GetSubAllocator(int numa_node) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   first_alloc_made_ = true;\n   FactoryEntry* best_entry = nullptr;\n   for (auto& entry : factories_) {"
        },
        {
            "sha": "b6267e6c2d32e57e19308087d12d9cffb14ed0ca",
            "filename": "third_party/xla/xla/tsl/framework/allocator_registry.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_registry.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_registry.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_registry.h?ref=e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717",
            "patch": "@@ -90,15 +90,15 @@ class AllocatorFactoryRegistry {\n   static AllocatorFactoryRegistry* singleton();\n \n   ProcessStateInterface* process_state() const {\n-    absl::MutexLock ml(&mu_);\n+    absl::MutexLock ml(mu_);\n     return process_state_;\n   }\n \n  protected:\n   friend class tensorflow::ProcessState;\n \n   void SetProcessState(ProcessStateInterface* interface) {\n-    absl::MutexLock ml(&mu_);\n+    absl::MutexLock ml(mu_);\n     process_state_ = interface;\n   }\n "
        },
        {
            "sha": "d500bdbce6e581e6248c940a38d29852473d2a11",
            "filename": "third_party/xla/xla/tsl/framework/allocator_retry.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_retry.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_retry.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_retry.cc?ref=e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717",
            "patch": "@@ -54,7 +54,7 @@ AllocatorRetry::AllocatorRetry() : env_(Env::Default()) {}\n AllocatorRetry::~AllocatorRetry() {\n   // Lock the mutex to make sure that all memory effects are safely published\n   // and available to a thread running the destructor.\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n }\n \n void* AllocatorRetry::AllocateRaw(\n@@ -80,7 +80,7 @@ void* AllocatorRetry::AllocateRaw(\n     }\n     if (now < deadline) {\n       tracker.Enable();\n-      absl::MutexLock l(&mu_);\n+      absl::MutexLock l(mu_);\n       memory_returned_.WaitWithDeadline(&mu_, deadline);\n     } else {\n       return alloc_func(alignment, num_bytes, true);"
        },
        {
            "sha": "254cd2b86732273710bd9cdd49112517d6fd9522",
            "filename": "third_party/xla/xla/tsl/framework/allocator_retry.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_retry.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_retry.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fallocator_retry.h?ref=e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717",
            "patch": "@@ -55,7 +55,7 @@ class AllocatorRetry {\n \n // Implementation details below\n inline void AllocatorRetry::NotifyDealloc() {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   memory_returned_.SignalAll();\n }\n "
        },
        {
            "sha": "7e3e60e2a82da9796782614f2dbd1bd4bf2de380",
            "filename": "third_party/xla/xla/tsl/framework/bfc_allocator.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fbfc_allocator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fbfc_allocator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fbfc_allocator.cc?ref=e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717",
            "patch": "@@ -104,7 +104,7 @@ BFCAllocator::~BFCAllocator() {\n   // Lock the mutex to make sure that all memory effects are safely published\n   // and available to a thread running the destructor (i.e., deallocations\n   // happened on a different thread right before the destructor).\n-  absl::MutexLock l(&mutex_);\n+  absl::MutexLock l(mutex_);\n \n   // Return memory back.\n   VLOG(2) << \"Number of regions allocated: \"\n@@ -446,7 +446,7 @@ void* BFCAllocator::AllocateRawInternal(size_t unused_alignment,\n   // The BFC allocator tries to find the best fit first.\n   BinNum bin_num = BinNumForSize(rounded_bytes);\n \n-  absl::MutexLock l(&mutex_);\n+  absl::MutexLock l(mutex_);\n   if (!timestamped_chunks_.empty()) {\n     // Merge timestamped chunks whose counts have become safe for general use.\n     MergeTimestampedChunks(0);\n@@ -703,7 +703,7 @@ void BFCAllocator::DeallocateRawInternal(void* ptr) {\n     VLOG(2) << \"tried to deallocate nullptr\";\n     return;\n   }\n-  absl::MutexLock l(&mutex_);\n+  absl::MutexLock l(mutex_);\n \n   // Find the chunk from the ptr.\n   BFCAllocator::ChunkHandle h = region_manager_.get_handle(ptr);\n@@ -947,7 +947,7 @@ bool BFCAllocator::TracksAllocationSizes() const { return true; }\n \n size_t BFCAllocator::RequestedSize(const void* ptr) const {\n   CHECK(ptr);\n-  absl::MutexLock l(&mutex_);\n+  absl::MutexLock l(mutex_);\n   BFCAllocator::ChunkHandle h = region_manager_.get_handle(ptr);\n   CHECK(h != kInvalidChunkHandle)\n       << \"Asked for requested size of pointer we never allocated: \" << ptr;\n@@ -956,7 +956,7 @@ size_t BFCAllocator::RequestedSize(const void* ptr) const {\n }\n \n size_t BFCAllocator::AllocatedSize(const void* ptr) const {\n-  absl::MutexLock l(&mutex_);\n+  absl::MutexLock l(mutex_);\n   BFCAllocator::ChunkHandle h = region_manager_.get_handle(ptr);\n   CHECK(h != kInvalidChunkHandle)\n       << \"Asked for allocated size of pointer we never allocated: \" << ptr;\n@@ -965,7 +965,7 @@ size_t BFCAllocator::AllocatedSize(const void* ptr) const {\n }\n \n int64_t BFCAllocator::AllocationId(const void* ptr) const {\n-  absl::MutexLock l(&mutex_);\n+  absl::MutexLock l(mutex_);\n   BFCAllocator::ChunkHandle h = region_manager_.get_handle(ptr);\n   CHECK(h != kInvalidChunkHandle)\n       << \"Asked for allocation id of pointer we never allocated: \" << ptr;\n@@ -1146,7 +1146,7 @@ void BFCAllocator::MaybeWriteMemoryMap() {\n }\n \n MemoryDump BFCAllocator::RecordMemoryMap() {\n-  absl::MutexLock l(&mutex_);\n+  absl::MutexLock l(mutex_);\n   return RecordMemoryMapInternal();\n }\n \n@@ -1217,12 +1217,12 @@ MemoryDump BFCAllocator::RecordMemoryMapInternal() {\n }\n \n std::optional<AllocatorStats> BFCAllocator::GetStats() {\n-  absl::MutexLock l(&mutex_);\n+  absl::MutexLock l(mutex_);\n   return stats_;\n }\n \n bool BFCAllocator::ClearStats() {\n-  absl::MutexLock l(&mutex_);\n+  absl::MutexLock l(mutex_);\n   stats_.num_allocs = 0;\n   stats_.peak_bytes_in_use = stats_.bytes_in_use;\n   stats_.largest_alloc_size = 0;"
        },
        {
            "sha": "fc7f2b8760bc1a6f667d1963e055675cc5c109d2",
            "filename": "third_party/xla/xla/tsl/framework/cancellation.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fcancellation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fcancellation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fcancellation.cc?ref=e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717",
            "patch": "@@ -48,7 +48,7 @@ void CancellationManager::StartCancelWithStatus(const absl::Status& status) {\n   std::forward_list<CancellationManager*> children_to_cancel;\n   absl::Notification* cancelled_notification = nullptr;\n   {\n-    absl::MutexLock l(&mu_);\n+    absl::MutexLock l(mu_);\n     if (is_cancelled_.load(std::memory_order_relaxed) || is_cancelling_) {\n       return;\n     }\n@@ -87,7 +87,7 @@ void CancellationManager::StartCancelWithStatus(const absl::Status& status) {\n     child->StartCancelWithStatus(status);\n   }\n   {\n-    absl::MutexLock l(&mu_);\n+    absl::MutexLock l(mu_);\n     is_cancelling_ = false;\n     is_cancelled_.store(true, std::memory_order_release);\n   }\n@@ -112,7 +112,7 @@ bool CancellationManager::RegisterCallbackWithErrorLogging(\n bool CancellationManager::RegisterCallbackConfig(CancellationToken token,\n                                                  CallbackConfiguration config) {\n   DCHECK_LT(token, next_cancellation_token_) << \"Invalid cancellation token\";\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   bool should_register = !is_cancelled_ && !is_cancelling_;\n   if (should_register) {\n     if (!state_) {\n@@ -124,14 +124,14 @@ bool CancellationManager::RegisterCallbackConfig(CancellationToken token,\n }\n \n bool CancellationManager::DeregisterCallback(CancellationToken token) {\n-  mu_.Lock();\n+  mu_.lock();\n   if (is_cancelled_) {\n-    mu_.Unlock();\n+    mu_.unlock();\n     return false;\n   } else if (is_cancelling_) {\n     absl::Notification* cancelled_notification =\n         state_ ? &state_->cancelled_notification : nullptr;\n-    mu_.Unlock();\n+    mu_.unlock();\n     // Wait for all of the cancellation callbacks to be called. This\n     // wait ensures that the caller of DeregisterCallback does not\n     // return immediately and free objects that may be used in the\n@@ -144,13 +144,13 @@ bool CancellationManager::DeregisterCallback(CancellationToken token) {\n     if (state_) {\n       state_->callbacks.erase(token);\n     }\n-    mu_.Unlock();\n+    mu_.unlock();\n     return true;\n   }\n }\n \n bool CancellationManager::RegisterChild(CancellationManager* child) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   if (is_cancelled_.load(std::memory_order_relaxed) || is_cancelling_) {\n     child->is_removed_from_parent_ = true;\n     return true;\n@@ -176,7 +176,7 @@ void CancellationManager::DeregisterChild(CancellationManager* child) {\n   DCHECK_EQ(child->parent_, this);\n   absl::Notification* cancelled_notification = nullptr;\n   {\n-    absl::MutexLock l(&mu_);\n+    absl::MutexLock l(mu_);\n     if (!child->is_removed_from_parent_) {\n       // Remove the child from this manager's list of children.\n       DCHECK(state_);\n@@ -209,7 +209,7 @@ void CancellationManager::DeregisterChild(CancellationManager* child) {\n }\n \n bool CancellationManager::TryDeregisterCallback(CancellationToken token) {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   if (is_cancelled_ || is_cancelling_) {\n     return false;\n   } else {\n@@ -230,7 +230,7 @@ CancellationManager::~CancellationManager() {\n }\n \n bool CancellationManager::IsCancelling() {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   return is_cancelling_;\n }\n "
        },
        {
            "sha": "fefd86a79a0cad65bb10781bf955667c547e641c",
            "filename": "third_party/xla/xla/tsl/framework/cpu_allocator_impl.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fcpu_allocator_impl.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fcpu_allocator_impl.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fcpu_allocator_impl.cc?ref=e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717",
            "patch": "@@ -89,7 +89,7 @@ class CPUAllocator : public Allocator {\n     void* p = port::AlignedMalloc(num_bytes, alignment);\n     if (cpu_allocator_collect_stats) {\n       const std::size_t alloc_size = port::MallocExtension_GetAllocatedSize(p);\n-      absl::MutexLock l(&mu_);\n+      absl::MutexLock l(mu_);\n       ++stats_.num_allocs;\n       stats_.bytes_in_use += alloc_size;\n       stats_.peak_bytes_in_use =\n@@ -115,7 +115,7 @@ class CPUAllocator : public Allocator {\n     if (cpu_allocator_collect_stats) {\n       const std::size_t alloc_size =\n           port::MallocExtension_GetAllocatedSize(ptr);\n-      absl::MutexLock l(&mu_);\n+      absl::MutexLock l(mu_);\n       stats_.bytes_in_use -= alloc_size;\n       AddTraceMe(\"MemoryDeallocation\", ptr, 0, alloc_size);\n     }\n@@ -126,7 +126,7 @@ class CPUAllocator : public Allocator {\n     if (cpu_allocator_collect_stats) {\n       const std::size_t alloc_size =\n           port::MallocExtension_GetAllocatedSize(ptr);\n-      absl::MutexLock l(&mu_);\n+      absl::MutexLock l(mu_);\n       stats_.bytes_in_use -= alloc_size;\n       AddTraceMe(\"MemoryDeallocation\", ptr, 0, alloc_size);\n     }\n@@ -161,13 +161,13 @@ class CPUAllocator : public Allocator {\n     if (!cpu_allocator_collect_stats) {\n       return std::nullopt;\n     }\n-    absl::MutexLock l(&mu_);\n+    absl::MutexLock l(mu_);\n     return stats_;\n   }\n \n   bool ClearStats() override {\n     if (!cpu_allocator_collect_stats) return false;\n-    absl::MutexLock l(&mu_);\n+    absl::MutexLock l(mu_);\n     stats_.num_allocs = 0;\n     stats_.peak_bytes_in_use = stats_.bytes_in_use;\n     stats_.largest_alloc_size = 0;"
        },
        {
            "sha": "bb6b451225065e91940da47bd29022c7d1056ffa",
            "filename": "third_party/xla/xla/tsl/framework/device_id_manager.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fdevice_id_manager.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fdevice_id_manager.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Fdevice_id_manager.cc?ref=e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717",
            "patch": "@@ -44,7 +44,7 @@ class TfToPlatformDeviceIdMap {\n       TF_LOCKS_EXCLUDED(mu_) {\n     std::pair<IdMapType::iterator, bool> result;\n     {\n-      absl::MutexLock lock(&mu_);\n+      absl::MutexLock lock(mu_);\n       TypeIdMapType::iterator device_id_map_iter =\n           id_map_.insert({type.type_string(), IdMapType()}).first;\n       result = device_id_map_iter->second.insert(\n@@ -69,7 +69,7 @@ class TfToPlatformDeviceIdMap {\n             PlatformDeviceId* platform_device_id) const TF_LOCKS_EXCLUDED(mu_) {\n     // TODO(mrry): Consider replacing this with an atomic `is_initialized` bit,\n     // to avoid writing to a shared cache line in the tf_shared_lock.\n-    absl::ReaderMutexLock lock(&mu_);\n+    absl::ReaderMutexLock lock(mu_);\n     auto type_id_map_iter = id_map_.find(type.type_string());\n     if (type_id_map_iter == id_map_.end()) return false;\n     auto id_map_iter = type_id_map_iter->second.find(tf_device_id.value());\n@@ -81,7 +81,7 @@ class TfToPlatformDeviceIdMap {\n   absl::StatusOr<std::vector<TfDeviceId>> GetTfDevicesOnPlatform(\n       const DeviceType& type, PlatformDeviceId platform_device_id) const\n       TF_LOCKS_EXCLUDED(mu_) {\n-    absl::ReaderMutexLock lock(&mu_);\n+    absl::ReaderMutexLock lock(mu_);\n     auto type_id_map_iter = id_map_.find(type.type_string());\n     if (type_id_map_iter == id_map_.end()) {\n       return absl::NotFoundError(\n@@ -101,7 +101,7 @@ class TfToPlatformDeviceIdMap {\n   TfToPlatformDeviceIdMap() = default;\n \n   void TestOnlyReset() TF_LOCKS_EXCLUDED(mu_) {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     id_map_.clear();\n   }\n "
        },
        {
            "sha": "63e8dc53ef1ec9ff74acd69757dc911054598753",
            "filename": "third_party/xla/xla/tsl/framework/tracking_allocator.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Ftracking_allocator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Ftracking_allocator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fframework%2Ftracking_allocator.cc?ref=e50b78b75bb58f3ef97e8b7714f7d6a0f5f62717",
            "patch": "@@ -44,7 +44,7 @@ void* TrackingAllocator::AllocateRaw(\n   if (allocator_->TracksAllocationSizes()) {\n     size_t allocated_bytes = allocator_->AllocatedSize(ptr);\n     {\n-      absl::MutexLock lock(&mu_);\n+      absl::MutexLock lock(mu_);\n       allocated_ += allocated_bytes;\n       high_watermark_ = std::max(high_watermark_, allocated_);\n       total_bytes_ += allocated_bytes;\n@@ -57,7 +57,7 @@ void* TrackingAllocator::AllocateRaw(\n     // use the requested size as an approximation.\n     size_t allocated_bytes = allocator_->AllocatedSizeSlow(ptr);\n     allocated_bytes = std::max(num_bytes, allocated_bytes);\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     next_allocation_id_ += 1;\n     Chunk chunk = {num_bytes, allocated_bytes, next_allocation_id_};\n     in_use_.emplace(std::make_pair(ptr, chunk));\n@@ -67,7 +67,7 @@ void* TrackingAllocator::AllocateRaw(\n     allocations_.emplace_back(allocated_bytes, Env::Default()->NowMicros());\n     ++ref_;\n   } else {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     total_bytes_ += num_bytes;\n     allocations_.emplace_back(num_bytes, Env::Default()->NowMicros());\n     ++ref_;\n@@ -88,7 +88,7 @@ void TrackingAllocator::DeallocateRaw(void* ptr) {\n   if (tracks_allocation_sizes) {\n     allocated_bytes = allocator_->AllocatedSize(ptr);\n   } else if (track_sizes_locally_) {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     auto itr = in_use_.find(ptr);\n     if (itr != in_use_.end()) {\n       tracks_allocation_sizes = true;\n@@ -98,7 +98,7 @@ void TrackingAllocator::DeallocateRaw(void* ptr) {\n   }\n   Allocator* allocator = allocator_;\n   {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     if (tracks_allocation_sizes) {\n       CHECK_GE(allocated_, allocated_bytes);\n       allocated_ -= allocated_bytes;\n@@ -118,7 +118,7 @@ bool TrackingAllocator::TracksAllocationSizes() const {\n \n size_t TrackingAllocator::RequestedSize(const void* ptr) const {\n   if (track_sizes_locally_) {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     auto it = in_use_.find(ptr);\n     if (it != in_use_.end()) {\n       return (*it).second.requested_size;\n@@ -131,7 +131,7 @@ size_t TrackingAllocator::RequestedSize(const void* ptr) const {\n \n size_t TrackingAllocator::AllocatedSize(const void* ptr) const {\n   if (track_sizes_locally_) {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     auto it = in_use_.find(ptr);\n     if (it != in_use_.end()) {\n       return (*it).second.allocated_size;\n@@ -144,7 +144,7 @@ size_t TrackingAllocator::AllocatedSize(const void* ptr) const {\n \n int64_t TrackingAllocator::AllocationId(const void* ptr) const {\n   if (track_sizes_locally_) {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     auto it = in_use_.find(ptr);\n     if (it != in_use_.end()) {\n       return (*it).second.allocation_id;\n@@ -166,7 +166,7 @@ std::tuple<size_t, size_t, size_t> TrackingAllocator::GetSizes() {\n   size_t total_bytes;\n   size_t still_live_bytes;\n   {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     high_watermark = high_watermark_;\n     total_bytes = total_bytes_;\n     still_live_bytes = allocated_;\n@@ -178,7 +178,7 @@ absl::InlinedVector<AllocRecord, 4UL> TrackingAllocator::GetRecordsAndUnRef() {\n   bool should_delete;\n   absl::InlinedVector<AllocRecord, 4UL> allocations;\n   {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     allocations.swap(allocations_);\n     should_delete = UnRef();\n   }\n@@ -191,7 +191,7 @@ absl::InlinedVector<AllocRecord, 4UL> TrackingAllocator::GetRecordsAndUnRef() {\n absl::InlinedVector<AllocRecord, 4UL> TrackingAllocator::GetCurrentRecords() {\n   absl::InlinedVector<AllocRecord, 4UL> allocations;\n   {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     for (const AllocRecord& alloc : allocations_) {\n       allocations.push_back(alloc);\n     }"
        }
    ],
    "stats": {
        "total": 96,
        "additions": 48,
        "deletions": 48
    }
}