{
    "author": "tensorflower-gardener",
    "message": "Remove no-op xla_gpu_enable_custom_fusions_re.\n\nPiperOrigin-RevId: 810859589",
    "sha": "d0fd82b538e68a92c049b54d5161a11604ad7f1b",
    "files": [
        {
            "sha": "05447dade603c7fe338449047a94cfa5ac70506e",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 7,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d0fd82b538e68a92c049b54d5161a11604ad7f1b/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d0fd82b538e68a92c049b54d5161a11604ad7f1b/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=d0fd82b538e68a92c049b54d5161a11604ad7f1b",
            "patch": "@@ -1672,13 +1672,6 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n                 bool_setter_for(&DebugOptions::set_xla_dump_full_hlo_config),\n                 debug_options->xla_dump_full_hlo_config(),\n                 \"Enable dumping the full HloModuleConfig proto.\"));\n-  flag_list->push_back(tsl::Flag(\n-      \"xla_gpu_enable_custom_fusions_re\",\n-      string_setter_for(&DebugOptions::set_xla_gpu_enable_custom_fusions_re),\n-      debug_options->xla_gpu_enable_custom_fusions_re(),\n-      \"Limits custom fusion only to fusions which match this regular \"\n-      \"expression. Default is all custom fusions registerered in a current \"\n-      \"process.\"));\n   flag_list->push_back(tsl::Flag(\n       \"xla_gpu_enable_dynamic_slice_fusion\",\n       bool_setter_for(&DebugOptions::set_xla_gpu_enable_dynamic_slice_fusion),"
        },
        {
            "sha": "5abfd4f7385a0f99c6fec3d467675fb5a46ae983",
            "filename": "third_party/xla/xla/xla.proto",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d0fd82b538e68a92c049b54d5161a11604ad7f1b/third_party%2Fxla%2Fxla%2Fxla.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d0fd82b538e68a92c049b54d5161a11604ad7f1b/third_party%2Fxla%2Fxla%2Fxla.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fxla.proto?ref=d0fd82b538e68a92c049b54d5161a11604ad7f1b",
            "patch": "@@ -479,10 +479,6 @@ message DebugOptions {\n   // Rewrite layer norm patterns into cuDNN library calls.\n   optional bool xla_gpu_enable_cudnn_layer_norm = 262;\n \n-  // A regular expression enabling only a subset of custom fusions. Enabled only\n-  // if `xla_gpu_enable_custom_fusion` set to true.\n-  optional string xla_gpu_enable_custom_fusions_re = 264;\n-\n   // Enables address computation fusion to optimize dynamic-slice and\n   // dynamic-update-slice operations around library calls.\n   optional bool xla_gpu_enable_dynamic_slice_fusion = 105;\n@@ -1196,6 +1192,7 @@ message DebugOptions {\n   reserved 168;  // Was xla_gpu_simplify_all_fp_conversions.\n   reserved 172;  // Was xla_gpu_normalize_layouts.\n   reserved 263;  // Was xla_gpu_enable_custom_fusions\n+  reserved 264;  // Was xla_gpu_enable_custom_fusions_re\n \n   // Generate calls to Arm Compute Library in the CPU backend.\n   optional bool xla_cpu_use_acl = 174;"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 1,
        "deletions": 11
    }
}