{
    "author": "ermilovmaxim",
    "message": "Add proto serialization for Collective(Done)Thunk\n\nPiperOrigin-RevId: 843846667",
    "sha": "ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5",
    "files": [
        {
            "sha": "2b410193a09098e0185e53cd09218fc3522af166",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5",
            "patch": "@@ -1795,6 +1795,21 @@ cc_library(\n     ],\n )\n \n+xla_cc_test(\n+    name = \"collective_thunk_test\",\n+    srcs = [\"collective_thunk_test.cc\"],\n+    deps = [\n+        \":collective_thunk\",\n+        \":thunk\",\n+        \":thunk_proto_cc\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n cc_library(\n     name = \"p2p_thunk_common\",\n     srcs = [\"p2p_thunk_common.cc\"],\n@@ -2171,6 +2186,7 @@ cc_library(\n         \"@com_google_absl//absl/functional:function_ref\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n@@ -2799,6 +2815,7 @@ cc_library(\n     srcs = [\"thunk_proto_deserialization.cc\"],\n     hdrs = [\"thunk_proto_deserialization.h\"],\n     deps = [\n+        \":collective_thunk\",\n         \":conditional_thunk\",\n         \":convolution_reorder_thunk\",\n         \":convolution_thunk\","
        },
        {
            "sha": "1d94ec8c5c8ce05efa338e2a12d3320bb02075bd",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 51,
            "deletions": 0,
            "changes": 51,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5",
            "patch": "@@ -410,6 +410,22 @@ std::optional<AsyncEventsUniqueId> CollectiveThunk::GetAsyncEventsUniqueId()\n   return absl::bit_cast<AsyncEventsUniqueId>(async_events_.get());\n }\n \n+absl::StatusOr<CollectiveThunkProto> CollectiveThunk::ToCollectiveThunkProto()\n+    const {\n+  CollectiveThunkProto proto;\n+\n+  proto.set_async_stream_kind(stream_kind_);\n+\n+  std::optional<AsyncEventsUniqueId> async_events_id = GetAsyncEventsUniqueId();\n+  if (!async_events_id.has_value()) {\n+    return absl::FailedPreconditionError(\"AsyncEvents is not set.\");\n+  }\n+  proto.set_async_events_unique_id(async_events_id->value());\n+  proto.set_thunk_kind(Thunk::KindToProto(kind()));\n+\n+  return proto;\n+}\n+\n CollectiveDoneThunk::CollectiveDoneThunk(\n     Thunk::Kind kind, ThunkInfo thunk_info,\n     std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n@@ -446,4 +462,39 @@ std::optional<AsyncEventsUniqueId> CollectiveDoneThunk::GetAsyncEventsUniqueId()\n   // We rely on the fact that the pointer to async_events_ is unique.\n   return absl::bit_cast<AsyncEventsUniqueId>(async_events_.get());\n }\n+\n+absl::StatusOr<ThunkProto> CollectiveDoneThunk::ToProto() const {\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+\n+  CollectiveDoneThunkProto* thunk_proto = proto.mutable_collective_done_thunk();\n+  thunk_proto->set_async_stream_kind(stream_kind_);\n+\n+  std::optional<AsyncEventsUniqueId> async_events_id = GetAsyncEventsUniqueId();\n+  if (!async_events_id.has_value()) {\n+    return absl::FailedPreconditionError(\"AsyncEvents is not set.\");\n+  }\n+  thunk_proto->set_async_events_unique_id(async_events_id->value());\n+  thunk_proto->set_thunk_kind(Thunk::KindToProto(kind()));\n+  return proto;\n+}\n+\n+absl::StatusOr<std::unique_ptr<CollectiveDoneThunk>>\n+CollectiveDoneThunk::FromProto(\n+    ThunkInfo thunk_info, const CollectiveDoneThunkProto& thunk_proto,\n+    CollectiveThunk::AsyncEventsMap& async_events_map) {\n+  std::shared_ptr<CollectiveThunk::AsyncEvents>& async_events =\n+      async_events_map[AsyncEventsUniqueId{\n+          thunk_proto.async_events_unique_id()}];\n+  if (!async_events) {\n+    async_events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+  }\n+\n+  TF_ASSIGN_OR_RETURN(Thunk::Kind kind,\n+                      Thunk::KindFromProto(thunk_proto.thunk_kind()));\n+  return std::make_unique<CollectiveDoneThunk>(kind, std::move(thunk_info),\n+                                               async_events,\n+                                               thunk_proto.async_stream_kind());\n+}\n+\n }  // namespace xla::gpu"
        },
        {
            "sha": "be08146f9a95c5aa857e342a124c1ed30153b80c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.h",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h?ref=ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5",
            "patch": "@@ -117,6 +117,8 @@ class CollectiveThunk : public Thunk {\n     absl::flat_hash_map<se::StreamExecutor*, std::unique_ptr<se::Event>> events_\n         ABSL_GUARDED_BY(mu_);\n   };\n+  using AsyncEventsMap =\n+      absl::flat_hash_map<AsyncEventsUniqueId, std::shared_ptr<AsyncEvents>>;\n \n   // Logging support.\n   static std::string GetDeviceString(const CollectiveParams& params);\n@@ -149,6 +151,8 @@ class CollectiveThunk : public Thunk {\n                              nccl_stream_id().value());\n   }\n \n+  absl::StatusOr<CollectiveThunkProto> ToCollectiveThunkProto() const;\n+\n  protected:\n   // Run collective operation on a given stream and return if the first call\n   // rendezvous with other participants is needed.\n@@ -220,6 +224,11 @@ class CollectiveDoneThunk : public Thunk {\n     return async_events_;\n   }\n \n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+  static absl::StatusOr<std::unique_ptr<CollectiveDoneThunk>> FromProto(\n+      ThunkInfo thunk_info, const CollectiveDoneThunkProto& thunk_proto,\n+      CollectiveThunk::AsyncEventsMap& async_events_map);\n+\n  private:\n   std::shared_ptr<CollectiveThunk::AsyncEvents> async_events_;\n   AsyncStreamKind stream_kind_ = AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE;"
        },
        {
            "sha": "43aa470e09577881c181507efa601c2865c84866",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk_test.cc",
            "status": "added",
            "additions": 69,
            "deletions": 0,
            "changes": 69,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk_test.cc?ref=ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5",
            "patch": "@@ -0,0 +1,69 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/collective_thunk.h\"\n+\n+#include <memory>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/log/check.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+using ::tsl::proto_testing::EqualsProto;\n+\n+TEST(CollectiveThunkTest, ProtoRoundTrip) {\n+  ThunkProto proto = tsl::proto_testing::ParseTextProtoOrDie<ThunkProto>(\n+      R\"pb(\n+        thunk_info {\n+          profile_annotation: \"partition_id_profile_annotation\"\n+          execution_stream_id: 2\n+        }\n+        collective_done_thunk {\n+          thunk_kind: 1\n+          async_stream_kind: 2\n+          async_events_unique_id: 3\n+        }\n+      )pb\");\n+\n+  Thunk::ThunkInfo thunk_info;\n+  thunk_info.profile_annotation = proto.thunk_info().profile_annotation();\n+  thunk_info.execution_stream_id = xla::gpu::ExecutionStreamId{\n+      static_cast<xla::gpu::ExecutionStreamId::ValueType>(\n+          proto.thunk_info().execution_stream_id())};\n+  CollectiveThunk::AsyncEventsMap async_events_map;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<CollectiveDoneThunk> thunk,\n+      CollectiveDoneThunk::FromProto(thunk_info, proto.collective_done_thunk(),\n+                                     async_events_map));\n+  CHECK_NE(thunk->async_events(), nullptr);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(ThunkProto round_trip_proto, thunk->ToProto());\n+\n+  // Ids are unique and expected to differ.\n+  proto.mutable_collective_done_thunk()->set_async_events_unique_id(\n+      round_trip_proto.collective_done_thunk().async_events_unique_id());\n+  EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        },
        {
            "sha": "5e174cf83177b05c3878cf620acc86fd830cb8d0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.cc",
            "status": "modified",
            "additions": 305,
            "deletions": 0,
            "changes": 305,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc?ref=ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"absl/functional/function_ref.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n@@ -109,6 +110,310 @@ Thunk::ExecuteParams::ExecuteParams(\n \n //===----------------------------------------------------------------------===//\n \n+ThunkKindProto Thunk::KindToProto(Kind kind) {\n+  switch (kind) {\n+    case kAllGather:\n+      return THUNK_KIND_ALL_GATHER;\n+    case kAllGatherDone:\n+      return THUNK_KIND_ALL_GATHER_DONE;\n+    case kAllGatherStart:\n+      return THUNK_KIND_ALL_GATHER_START;\n+    case kAllReduce:\n+      return THUNK_KIND_ALL_REDUCE;\n+    case kAllReduceDone:\n+      return THUNK_KIND_ALL_REDUCE_DONE;\n+    case kAllReduceStart:\n+      return THUNK_KIND_ALL_REDUCE_START;\n+    case kAllToAll:\n+      return THUNK_KIND_ALL_TO_ALL;\n+    case kAllToAllDone:\n+      return THUNK_KIND_ALL_TO_ALL_DONE;\n+    case kAllToAllStart:\n+      return THUNK_KIND_ALL_TO_ALL_START;\n+    case kBuffersDebugChecksum:\n+      return THUNK_KIND_BUFFERS_DEBUG_CHECKSUM;\n+    case kBuffersDebugFloatCheck:\n+      return THUNK_KIND_BUFFERS_DEBUG_FLOAT_CHECK;\n+    case kCollectiveBroadcast:\n+      return THUNK_KIND_COLLECTIVE_BROADCAST;\n+    case kCollectiveBroadcastDone:\n+      return THUNK_KIND_COLLECTIVE_BROADCAST_DONE;\n+    case kCollectiveBroadcastStart:\n+      return THUNK_KIND_COLLECTIVE_BROADCAST_START;\n+    case kCollectiveKernel:\n+      return THUNK_KIND_COLLECTIVE_KERNEL;\n+    case kCollectiveMetadata:\n+      return THUNK_KIND_COLLECTIVE_METADATA;\n+    case kCollectivePermute:\n+      return THUNK_KIND_COLLECTIVE_PERMUTE;\n+    case kCollectivePermuteDone:\n+      return THUNK_KIND_COLLECTIVE_PERMUTE_DONE;\n+    case kCollectivePermuteStart:\n+      return THUNK_KIND_COLLECTIVE_PERMUTE_START;\n+    case kCommandBuffer:\n+      return THUNK_KIND_COMMAND_BUFFER;\n+    case kConditional:\n+      return THUNK_KIND_CONDITIONAL;\n+    case kConvolution:\n+      return THUNK_KIND_CONVOLUTION;\n+    case kConvolutionReorder:\n+      return THUNK_KIND_CONVOLUTION_REORDER;\n+    case kCopy:\n+      return THUNK_KIND_COPY;\n+    case kCopyDone:\n+      return THUNK_KIND_COPY_DONE;\n+    case kCuDnn:\n+      return THUNK_KIND_CU_DNN;\n+    case kCubSort:\n+      return THUNK_KIND_CUB_SORT;\n+    case kCublasLtMatmul:\n+      return THUNK_KIND_CUBLAS_LT_MATMUL;\n+    case kCustomCall:\n+      return THUNK_KIND_CUSTOM_CALL;\n+    case kCustomKernel:\n+      return THUNK_KIND_CUSTOM_KERNEL;\n+    case kDynamicSlice:\n+      return THUNK_KIND_DYNAMIC_SLICE;\n+    case kFft:\n+      return THUNK_KIND_FFT;\n+    case kGemm:\n+      return THUNK_KIND_GEMM;\n+    case kGroupDone:\n+      return THUNK_KIND_GROUP_DONE;\n+    case kGroupStart:\n+      return THUNK_KIND_GROUP_START;\n+    case kHostExecuteDone:\n+      return THUNK_KIND_HOST_EXECUTE_DONE;\n+    case kHostExecuteStart:\n+      return THUNK_KIND_HOST_EXECUTE_START;\n+    case kHostRecv:\n+      return THUNK_KIND_HOST_RECV;\n+    case kHostRecvDone:\n+      return THUNK_KIND_HOST_RECV_DONE;\n+    case kHostSend:\n+      return THUNK_KIND_HOST_SEND;\n+    case kHostSendDone:\n+      return THUNK_KIND_HOST_SEND_DONE;\n+    case kInfeed:\n+      return THUNK_KIND_INFEED;\n+    case kKernel:\n+      return THUNK_KIND_KERNEL;\n+    case kMemset32BitValue:\n+      return THUNK_KIND_MEMSET32_BIT_VALUE;\n+    case kMemzero:\n+      return THUNK_KIND_MEMZERO;\n+    case kNorm:\n+      return THUNK_KIND_NORM;\n+    case kNvshmemAllReduceDone:\n+      return THUNK_KIND_NVSHMEM_ALL_REDUCE_DONE;\n+    case kNvshmemAllReduceStart:\n+      return THUNK_KIND_NVSHMEM_ALL_REDUCE_START;\n+    case kNvshmemCollectivePermute:\n+      return THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE;\n+    case kNvshmemCollectivePermuteDone:\n+      return THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE_DONE;\n+    case kNvshmemCollectivePermuteStart:\n+      return THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE_START;\n+    case kNvshmemRecv:\n+      return THUNK_KIND_NVSHMEM_RECV;\n+    case kNvshmemRecvDone:\n+      return THUNK_KIND_NVSHMEM_RECV_DONE;\n+    case kNvshmemSend:\n+      return THUNK_KIND_NVSHMEM_SEND;\n+    case kNvshmemSendDone:\n+      return THUNK_KIND_NVSHMEM_SEND_DONE;\n+    case kOutfeed:\n+      return THUNK_KIND_OUTFEED;\n+    case kPartitionId:\n+      return THUNK_KIND_PARTITION_ID;\n+    case kRaggedAllToAll:\n+      return THUNK_KIND_RAGGED_ALL_TO_ALL;\n+    case kRaggedAllToAllDone:\n+      return THUNK_KIND_RAGGED_ALL_TO_ALL_DONE;\n+    case kRaggedAllToAllStart:\n+      return THUNK_KIND_RAGGED_ALL_TO_ALL_START;\n+    case kRecv:\n+      return THUNK_KIND_RECV;\n+    case kRecvDone:\n+      return THUNK_KIND_RECV_DONE;\n+    case kReduceScatter:\n+      return THUNK_KIND_REDUCE_SCATTER;\n+    case kReduceScatterDone:\n+      return THUNK_KIND_REDUCE_SCATTER_DONE;\n+    case kReduceScatterStart:\n+      return THUNK_KIND_REDUCE_SCATTER_START;\n+    case kReplicaId:\n+      return THUNK_KIND_REPLICA_ID;\n+    case kSelectK:\n+      return THUNK_KIND_SELECT_K;\n+    case kSend:\n+      return THUNK_KIND_SEND;\n+    case kSendDone:\n+      return THUNK_KIND_SEND_DONE;\n+    case kSequential:\n+      return THUNK_KIND_SEQUENTIAL;\n+    case kTriangularSolve:\n+      return THUNK_KIND_TRIANGULAR_SOLVE;\n+    case kWaitForStreams:\n+      return THUNK_KIND_WAIT_FOR_STREAMS;\n+    case kWhile:\n+      return THUNK_KIND_WHILE;\n+  };\n+}\n+\n+absl::StatusOr<Thunk::Kind> Thunk::KindFromProto(ThunkKindProto kind) {\n+  switch (kind) {\n+    case THUNK_KIND_ALL_GATHER:\n+      return kAllGather;\n+    case THUNK_KIND_ALL_GATHER_DONE:\n+      return kAllGatherDone;\n+    case THUNK_KIND_ALL_GATHER_START:\n+      return kAllGatherStart;\n+    case THUNK_KIND_ALL_REDUCE:\n+      return kAllReduce;\n+    case THUNK_KIND_ALL_REDUCE_DONE:\n+      return kAllReduceDone;\n+    case THUNK_KIND_ALL_REDUCE_START:\n+      return kAllReduceStart;\n+    case THUNK_KIND_ALL_TO_ALL:\n+      return kAllToAll;\n+    case THUNK_KIND_ALL_TO_ALL_DONE:\n+      return kAllToAllDone;\n+    case THUNK_KIND_ALL_TO_ALL_START:\n+      return kAllToAllStart;\n+    case THUNK_KIND_BUFFERS_DEBUG_CHECKSUM:\n+      return kBuffersDebugChecksum;\n+    case THUNK_KIND_BUFFERS_DEBUG_FLOAT_CHECK:\n+      return kBuffersDebugFloatCheck;\n+    case THUNK_KIND_COLLECTIVE_BROADCAST:\n+      return kCollectiveBroadcast;\n+    case THUNK_KIND_COLLECTIVE_BROADCAST_DONE:\n+      return kCollectiveBroadcastDone;\n+    case THUNK_KIND_COLLECTIVE_BROADCAST_START:\n+      return kCollectiveBroadcastStart;\n+    case THUNK_KIND_COLLECTIVE_KERNEL:\n+      return kCollectiveKernel;\n+    case THUNK_KIND_COLLECTIVE_METADATA:\n+      return kCollectiveMetadata;\n+    case THUNK_KIND_COLLECTIVE_PERMUTE:\n+      return kCollectivePermute;\n+    case THUNK_KIND_COLLECTIVE_PERMUTE_DONE:\n+      return kCollectivePermuteDone;\n+    case THUNK_KIND_COLLECTIVE_PERMUTE_START:\n+      return kCollectivePermuteStart;\n+    case THUNK_KIND_COMMAND_BUFFER:\n+      return kCommandBuffer;\n+    case THUNK_KIND_CONDITIONAL:\n+      return kConditional;\n+    case THUNK_KIND_CONVOLUTION:\n+      return kConvolution;\n+    case THUNK_KIND_CONVOLUTION_REORDER:\n+      return kConvolutionReorder;\n+    case THUNK_KIND_COPY:\n+      return kCopy;\n+    case THUNK_KIND_COPY_DONE:\n+      return kCopyDone;\n+    case THUNK_KIND_CU_DNN:\n+      return kCuDnn;\n+    case THUNK_KIND_CUB_SORT:\n+      return kCubSort;\n+    case THUNK_KIND_CUBLAS_LT_MATMUL:\n+      return kCublasLtMatmul;\n+    case THUNK_KIND_CUSTOM_CALL:\n+      return kCustomCall;\n+    case THUNK_KIND_CUSTOM_KERNEL:\n+      return kCustomKernel;\n+    case THUNK_KIND_DYNAMIC_SLICE:\n+      return kDynamicSlice;\n+    case THUNK_KIND_FFT:\n+      return kFft;\n+    case THUNK_KIND_GEMM:\n+      return kGemm;\n+    case THUNK_KIND_GROUP_DONE:\n+      return kGroupDone;\n+    case THUNK_KIND_GROUP_START:\n+      return kGroupStart;\n+    case THUNK_KIND_HOST_EXECUTE_DONE:\n+      return kHostExecuteDone;\n+    case THUNK_KIND_HOST_EXECUTE_START:\n+      return kHostExecuteStart;\n+    case THUNK_KIND_HOST_RECV:\n+      return kHostRecv;\n+    case THUNK_KIND_HOST_RECV_DONE:\n+      return kHostRecvDone;\n+    case THUNK_KIND_HOST_SEND:\n+      return kHostSend;\n+    case THUNK_KIND_HOST_SEND_DONE:\n+      return kHostSendDone;\n+    case THUNK_KIND_INFEED:\n+      return kInfeed;\n+    case THUNK_KIND_KERNEL:\n+      return kKernel;\n+    case THUNK_KIND_MEMSET32_BIT_VALUE:\n+      return kMemset32BitValue;\n+    case THUNK_KIND_MEMZERO:\n+      return kMemzero;\n+    case THUNK_KIND_NORM:\n+      return kNorm;\n+    case THUNK_KIND_NVSHMEM_ALL_REDUCE_DONE:\n+      return kNvshmemAllReduceDone;\n+    case THUNK_KIND_NVSHMEM_ALL_REDUCE_START:\n+      return kNvshmemAllReduceStart;\n+    case THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE:\n+      return kNvshmemCollectivePermute;\n+    case THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE_DONE:\n+      return kNvshmemCollectivePermuteDone;\n+    case THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE_START:\n+      return kNvshmemCollectivePermuteStart;\n+    case THUNK_KIND_NVSHMEM_RECV:\n+      return kNvshmemRecv;\n+    case THUNK_KIND_NVSHMEM_RECV_DONE:\n+      return kNvshmemRecvDone;\n+    case THUNK_KIND_NVSHMEM_SEND:\n+      return kNvshmemSend;\n+    case THUNK_KIND_NVSHMEM_SEND_DONE:\n+      return kNvshmemSendDone;\n+    case THUNK_KIND_OUTFEED:\n+      return kOutfeed;\n+    case THUNK_KIND_PARTITION_ID:\n+      return kPartitionId;\n+    case THUNK_KIND_RAGGED_ALL_TO_ALL:\n+      return kRaggedAllToAll;\n+    case THUNK_KIND_RAGGED_ALL_TO_ALL_DONE:\n+      return kRaggedAllToAllDone;\n+    case THUNK_KIND_RAGGED_ALL_TO_ALL_START:\n+      return kRaggedAllToAllStart;\n+    case THUNK_KIND_RECV:\n+      return kRecv;\n+    case THUNK_KIND_RECV_DONE:\n+      return kRecvDone;\n+    case THUNK_KIND_REDUCE_SCATTER:\n+      return kReduceScatter;\n+    case THUNK_KIND_REDUCE_SCATTER_DONE:\n+      return kReduceScatterDone;\n+    case THUNK_KIND_REDUCE_SCATTER_START:\n+      return kReduceScatterStart;\n+    case THUNK_KIND_REPLICA_ID:\n+      return kReplicaId;\n+    case THUNK_KIND_SELECT_K:\n+      return kSelectK;\n+    case THUNK_KIND_SEND:\n+      return kSend;\n+    case THUNK_KIND_SEND_DONE:\n+      return kSendDone;\n+    case THUNK_KIND_SEQUENTIAL:\n+      return kSequential;\n+    case THUNK_KIND_TRIANGULAR_SOLVE:\n+      return kTriangularSolve;\n+    case THUNK_KIND_WAIT_FOR_STREAMS:\n+      return kWaitForStreams;\n+    case THUNK_KIND_WHILE:\n+      return kWhile;\n+    default:\n+      return absl::InternalError(absl::StrCat(\"Unknown ThunkKindProto:\", kind));\n+  };\n+}\n+\n /*static*/ absl::string_view Thunk::KindToString(Thunk::Kind kind) {\n #define CASE(x)  \\\n   case Thunk::x: \\"
        },
        {
            "sha": "bd88654eaf963a09432cccce352d7588e7eece26",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h?ref=ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5",
            "patch": "@@ -202,6 +202,9 @@ class Thunk {\n     // go/keep-sorted end\n   };\n \n+  static ThunkKindProto KindToProto(Kind kind);\n+  static absl::StatusOr<Thunk::Kind> KindFromProto(ThunkKindProto kind);\n+\n   // TODO(ezhulenev): This should become a part of StreamExecutor library, but\n   // for now we keep it here as a Thunk implementation detail. It's not yet\n   // clear what else should become a part of \"executable source\", we likely"
        },
        {
            "sha": "0cd18e571009c5d2db3077129e103765ce2e5de0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 90,
            "deletions": 0,
            "changes": 90,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5",
            "patch": "@@ -53,6 +53,83 @@ message ThunkMetadataListProto {\n   repeated ThunkMetadataProto thunk_metadata = 1;\n }\n \n+enum ThunkKindProto {\n+  THUNK_KIND_UNSPECIFIED = 0;\n+  THUNK_KIND_ALL_GATHER = 1;\n+  THUNK_KIND_ALL_GATHER_DONE = 2;\n+  THUNK_KIND_ALL_GATHER_START = 3;\n+  THUNK_KIND_ALL_REDUCE = 4;\n+  THUNK_KIND_ALL_REDUCE_DONE = 5;\n+  THUNK_KIND_ALL_REDUCE_START = 6;\n+  THUNK_KIND_ALL_TO_ALL = 7;\n+  THUNK_KIND_ALL_TO_ALL_DONE = 8;\n+  THUNK_KIND_ALL_TO_ALL_START = 9;\n+  THUNK_KIND_BUFFERS_DEBUG_CHECKSUM = 10;\n+  THUNK_KIND_BUFFERS_DEBUG_FLOAT_CHECK = 11;\n+  THUNK_KIND_COLLECTIVE_BROADCAST = 12;\n+  THUNK_KIND_COLLECTIVE_BROADCAST_DONE = 13;\n+  THUNK_KIND_COLLECTIVE_BROADCAST_START = 14;\n+  THUNK_KIND_COLLECTIVE_KERNEL = 15;\n+  THUNK_KIND_COLLECTIVE_METADATA = 16;\n+  THUNK_KIND_COLLECTIVE_PERMUTE = 17;\n+  THUNK_KIND_COLLECTIVE_PERMUTE_DONE = 18;\n+  THUNK_KIND_COLLECTIVE_PERMUTE_START = 19;\n+  THUNK_KIND_COMMAND_BUFFER = 20;\n+  THUNK_KIND_CONDITIONAL = 21;\n+  THUNK_KIND_CONVOLUTION = 22;\n+  THUNK_KIND_CONVOLUTION_REORDER = 23;\n+  THUNK_KIND_COPY = 24;\n+  THUNK_KIND_COPY_DONE = 25;\n+  THUNK_KIND_CU_DNN = 26;\n+  THUNK_KIND_CUB_SORT = 27;\n+  THUNK_KIND_CUBLAS_LT_MATMUL = 28;\n+  THUNK_KIND_CUSTOM_CALL = 29;\n+  THUNK_KIND_CUSTOM_KERNEL = 30;\n+  THUNK_KIND_DYNAMIC_SLICE = 31;\n+  THUNK_KIND_FFT = 32;\n+  THUNK_KIND_GEMM = 33;\n+  THUNK_KIND_GROUP_DONE = 34;\n+  THUNK_KIND_GROUP_START = 35;\n+  THUNK_KIND_HOST_EXECUTE_DONE = 36;\n+  THUNK_KIND_HOST_EXECUTE_START = 37;\n+  THUNK_KIND_HOST_RECV = 38;\n+  THUNK_KIND_HOST_RECV_DONE = 39;\n+  THUNK_KIND_HOST_SEND = 40;\n+  THUNK_KIND_HOST_SEND_DONE = 41;\n+  THUNK_KIND_INFEED = 42;\n+  THUNK_KIND_KERNEL = 43;\n+  THUNK_KIND_MEMSET32_BIT_VALUE = 44;\n+  THUNK_KIND_MEMZERO = 45;\n+  THUNK_KIND_NORM = 46;\n+  THUNK_KIND_NVSHMEM_ALL_REDUCE_DONE = 47;\n+  THUNK_KIND_NVSHMEM_ALL_REDUCE_START = 48;\n+  THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE = 49;\n+  THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE_DONE = 50;\n+  THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE_START = 51;\n+  THUNK_KIND_NVSHMEM_RECV = 52;\n+  THUNK_KIND_NVSHMEM_RECV_DONE = 53;\n+  THUNK_KIND_NVSHMEM_SEND = 54;\n+  THUNK_KIND_NVSHMEM_SEND_DONE = 55;\n+  THUNK_KIND_OUTFEED = 56;\n+  THUNK_KIND_PARTITION_ID = 57;\n+  THUNK_KIND_RAGGED_ALL_TO_ALL = 58;\n+  THUNK_KIND_RAGGED_ALL_TO_ALL_DONE = 59;\n+  THUNK_KIND_RAGGED_ALL_TO_ALL_START = 60;\n+  THUNK_KIND_RECV = 61;\n+  THUNK_KIND_RECV_DONE = 62;\n+  THUNK_KIND_REDUCE_SCATTER = 63;\n+  THUNK_KIND_REDUCE_SCATTER_DONE = 64;\n+  THUNK_KIND_REDUCE_SCATTER_START = 65;\n+  THUNK_KIND_REPLICA_ID = 66;\n+  THUNK_KIND_SELECT_K = 67;\n+  THUNK_KIND_SEND = 68;\n+  THUNK_KIND_SEND_DONE = 69;\n+  THUNK_KIND_SEQUENTIAL = 70;\n+  THUNK_KIND_TRIANGULAR_SOLVE = 71;\n+  THUNK_KIND_WAIT_FOR_STREAMS = 72;\n+  THUNK_KIND_WHILE = 73;\n+}\n+\n message CopyThunkProto {\n   ShapedSliceProto source_buffer = 1;\n   ShapedSliceProto destination_buffer = 2;\n@@ -300,6 +377,18 @@ message CustomKernelThunkProto {\n   CustomKernelProto custom_kernel = 3;\n }\n \n+message CollectiveThunkProto {\n+  ThunkKindProto thunk_kind = 1;\n+  AsyncStreamKind async_stream_kind = 2;\n+  uint64 async_events_unique_id = 3;\n+}\n+\n+message CollectiveDoneThunkProto {\n+  ThunkKindProto thunk_kind = 1;\n+  AsyncStreamKind async_stream_kind = 2;\n+  uint64 async_events_unique_id = 3;\n+}\n+\n message ThunkProto {\n   ThunkInfoProto thunk_info = 1;\n \n@@ -338,6 +427,7 @@ message ThunkProto {\n     HostRecvThunkProto host_recv_thunk = 34;\n     HostRecvDoneThunkProto host_recv_done_thunk = 35;\n     CustomKernelThunkProto custom_kernel_thunk = 36;\n+    CollectiveDoneThunkProto collective_done_thunk = 37;\n   }\n }\n "
        },
        {
            "sha": "a34814163fe4be2a1c5cabbf087809c6d84a63de",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 4,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc?ref=ab3cb0704610923c13ac5b99f4aa9fd7c22f74a5",
            "patch": "@@ -28,6 +28,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"google/protobuf/descriptor.h\"\n #include \"google/protobuf/message.h\"\n+#include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/conditional_thunk.h\"\n #include \"xla/backends/gpu/runtime/convolution_reorder_thunk.h\"\n #include \"xla/backends/gpu/runtime/convolution_thunk.h\"\n@@ -87,6 +88,7 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n     const HloModule* absl_nullable hlo_module, absl::string_view platform_name,\n     HostExecuteAsyncEventsMap& host_executable_async_events_map,\n     HostSendRecvAsyncEventsMap& host_send_recv_async_events_map,\n+    CollectiveThunk::AsyncEventsMap& collective_async_events_map,\n     const std::optional<stream_executor::KernelLoaderSpec::SymbolResolver>&\n         symbol_resolver) {\n   TF_ASSIGN_OR_RETURN(Thunk::ThunkInfo thunk_info,\n@@ -95,7 +97,7 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n     return DeserializeThunkProtoImpl(\n         thunk_proto, buffer_allocations, hlo_module, platform_name,\n         host_executable_async_events_map, host_send_recv_async_events_map,\n-        symbol_resolver);\n+        collective_async_events_map, symbol_resolver);\n   };\n \n   switch (thunk_proto.impl_case()) {\n@@ -189,7 +191,8 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n             return DeserializeThunkProtoImpl(\n                 thunk_proto, custom_allocations, hlo_module, platform_name,\n                 host_executable_async_events_map,\n-                host_send_recv_async_events_map, symbol_resolver);\n+                host_send_recv_async_events_map, collective_async_events_map,\n+                symbol_resolver);\n           };\n       return DynamicSliceThunk::FromProto(std::move(thunk_info),\n                                           thunk_proto.dynamic_slice_thunk(),\n@@ -235,7 +238,10 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n       return CustomKernelThunk::FromProto(std::move(thunk_info),\n                                           thunk_proto.custom_kernel_thunk(),\n                                           buffer_allocations, symbol_resolver);\n-\n+    case ThunkProto::kCollectiveDoneThunk:\n+      return CollectiveDoneThunk::FromProto(std::move(thunk_info),\n+                                            thunk_proto.collective_done_thunk(),\n+                                            collective_async_events_map);\n     default:\n       std::optional<absl::string_view> unsupported_thunk_type =\n           GetStoredThunkTypeName(thunk_proto);\n@@ -263,10 +269,11 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProto(\n         symbol_resolver) {\n   HostExecuteAsyncEventsMap host_executable_async_events_map;\n   HostSendRecvAsyncEventsMap host_send_recv_async_events_map;\n+  CollectiveThunk::AsyncEventsMap collective_async_events_map;\n   return DeserializeThunkProtoImpl(\n       thunk_proto, buffer_allocations, hlo_module, platform_name,\n       host_executable_async_events_map, host_send_recv_async_events_map,\n-      symbol_resolver);\n+      collective_async_events_map, symbol_resolver);\n }\n \n }  // namespace xla::gpu"
        }
    ],
    "stats": {
        "total": 559,
        "additions": 555,
        "deletions": 4
    }
}