{
    "author": "vsytch",
    "message": "[XLA] HloInstruction::set_backend_config does not return errors\n\nLiterally.\n\nPiperOrigin-RevId: 803962800",
    "sha": "f1050d735b1045fca794059bbc0bc9db823b8339",
    "files": [
        {
            "sha": "4d2bf5406b47fac6b3d239e2c808d1efeb4e6842",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/llvm_kernel_backend.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_backend.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_backend.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_backend.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -100,7 +100,7 @@ absl::Status LlvmKernelBackend::ApplyConfig(HloInstruction& instr,\n \n   *backend_config.mutable_llvm_kernel_options() = llvm_kernel_config;\n \n-  TF_RETURN_IF_ERROR(instr.set_backend_config(backend_config));\n+  instr.set_backend_config(backend_config);\n \n   return absl::OkStatus();\n }"
        },
        {
            "sha": "67ec52f2587c36a131ab2914d050236ddd4c58ee",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/xnnpack_backend.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -116,7 +116,7 @@ absl::Status XnnpackBackend::ApplyConfig(HloInstruction& instr,\n   *backend_config.mutable_fusion_config()->mutable_xnn_fusion_config() =\n       xnn_config;\n \n-  TF_RETURN_IF_ERROR(instr.set_backend_config(backend_config));\n+  instr.set_backend_config(backend_config);\n \n   return absl::OkStatus();\n }"
        },
        {
            "sha": "956d6b9d92b3bfbd5b441e8b2f9d290c249442e8",
            "filename": "third_party/xla/xla/backends/cpu/transforms/dot_library_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -76,7 +76,7 @@ absl::StatusOr<HloFusionInstruction*> CreateLibraryFusion(\n   BackendConfig backend_config;\n   FusionBackendConfig* fusion_config = backend_config.mutable_fusion_config();\n   fusion_config->set_kind(fusion_kind);\n-  TF_RETURN_IF_ERROR(fusion->set_backend_config(backend_config));\n+  fusion->set_backend_config(backend_config);\n \n   // Replace the instruction.\n   TF_RETURN_IF_ERROR("
        },
        {
            "sha": "8359527ce5aad188d95fb60b3371f222355caf87",
            "filename": "third_party/xla/xla/backends/cpu/transforms/xnn_graph_fusion.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_graph_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_graph_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_graph_fusion.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -91,7 +91,7 @@ HloInstruction* XnnGraphFusion::Fuse(HloInstruction* producer,\n   FusionBackendConfig* fusion_config = backend_config.mutable_fusion_config();\n   fusion_config->set_kind(std::string{kXnnFusionKind});\n   CHECK(backend_config.has_fusion_config());\n-  TF_CHECK_OK(fusion->set_backend_config(backend_config));\n+  fusion->set_backend_config(backend_config);\n   return fusion;\n }\n "
        },
        {
            "sha": "f812ea11cfabef25eb777247e9d600f2abda020d",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/block_level_emitter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -386,7 +386,7 @@ absl::Status BlockLevelEmitterBackend::ApplyConfig(\n   *backend_config.mutable_block_level_fusion_config() =\n       block_level_fusion_config;\n   // Re-attach the modified GPU config back to the instruction.\n-  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_backend_config)));\n+  instr.set_backend_config(std::move(gpu_backend_config));\n   instr.set_fusion_kind(HloInstruction::FusionKind::kCustom);\n   return absl::OkStatus();\n }"
        },
        {
            "sha": "3b708fac6b1408a45f3813944326335af89fa825",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cublas.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -193,7 +193,7 @@ absl::Status CublasBackend::ApplyConfig(HloInstruction& instr,\n                       instr.backend_config<GpuBackendConfig>());\n   GemmBackendConfig& backend_config = *gpu_config.mutable_gemm_backend_config();\n   backend_config.set_selected_algorithm(gemm_key.algorithm());\n-  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_config)));\n+  instr.set_backend_config(std::move(gpu_config));\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "10493b5d67a50e86a61437da496b498693dbed78",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cublaslt.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublaslt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublaslt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublaslt.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -157,7 +157,7 @@ absl::Status CublasLtBackend::ApplyConfig(HloInstruction& instr,\n                       instr.backend_config<GpuBackendConfig>());\n   GemmBackendConfig& backend_config = *gpu_config.mutable_gemm_backend_config();\n   backend_config.set_selected_algorithm(gemm_key.algorithm());\n-  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_config)));\n+  instr.set_backend_config(std::move(gpu_config));\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "d9eda2427d4a8aebe6dd16adba99e4d8ca5390b1",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cudnn.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -91,7 +91,7 @@ absl::Status ApplyConfigAndUpdateWorkspaceInOutputTuple(\n   CudnnConvBackendConfig* cudnn_conv_config =\n       gpu_backend_config.mutable_cudnn_conv_backend_config();\n   *cudnn_conv_config->mutable_algorithm() = config;\n-  TF_RETURN_IF_ERROR(new_call->set_backend_config(gpu_backend_config));\n+  new_call->set_backend_config(gpu_backend_config);\n \n   std::vector<HloInstruction*> new_tuple_elements;\n   new_tuple_elements.reserve(new_call->shape().tuple_shapes().size() - 1);\n@@ -290,7 +290,7 @@ absl::Status ApplyConfigToCudnnFusion(HloInstruction& instr,\n   FusionBackendConfig* backend_config =\n       gpu_config.mutable_fusion_backend_config();\n   backend_config->mutable_cudnn_fusion_config()->set_plan_id(config.algo_id());\n-  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_config)));\n+  instr.set_backend_config(std::move(gpu_config));\n   return absl::OkStatus();\n }\n \n@@ -304,7 +304,7 @@ absl::Status ApplyConfigToCudnnCustomCall(HloInstruction& instr,\n   CudnnConvBackendConfig* cudnn_conv_config =\n       gpu_config.mutable_cudnn_conv_backend_config();\n   *cudnn_conv_config->mutable_algorithm() = config;\n-  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_config)));\n+  instr.set_backend_config(std::move(gpu_config));\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "e09c3b60ff296a8ebf96378d13516f24d2b35170",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/custom_kernel.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcustom_kernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcustom_kernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcustom_kernel.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -146,7 +146,7 @@ absl::Status CustomKernelBackend::ApplyConfig(HloInstruction& instr,\n       gpu_config.mutable_fusion_backend_config();\n   backend_config->mutable_custom_fusion_config()->set_kernel_index(\n       custom_kernel_config.kernel_index());\n-  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_config)));\n+  instr.set_backend_config(std::move(gpu_config));\n \n   return absl::OkStatus();\n }"
        },
        {
            "sha": "c3487c15b82e6edba9637fd9e8644c8d93d93d6a",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/native_emitter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -85,7 +85,7 @@ absl::Status NativeEmitterBackend::ApplyConfig(HloInstruction& instr,\n                       instr.backend_config<GpuBackendConfig>());\n   *gpu_backend_config.mutable_native_emitter_backend_config() =\n       native_emitter_fusion_config;\n-  TF_RETURN_IF_ERROR(fusion_instr->set_backend_config(gpu_backend_config));\n+  fusion_instr->set_backend_config(gpu_backend_config);\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "7895659d806028f921090d98f438fcc940c94e01",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/triton.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -176,7 +176,7 @@ absl::Status TritonBackend::ApplyConfig(HloInstruction& instr,\n       *gpu_config.mutable_fusion_backend_config();\n \n   *backend_config.mutable_triton_gemm_config() = triton_config_proto;\n-  TF_RETURN_IF_ERROR(instr.set_backend_config(gpu_config));\n+  instr.set_backend_config(gpu_config);\n \n   TF_ASSIGN_OR_RETURN(TritonGemmConfig triton_config,\n                       TritonGemmConfig::FromProto(triton_config_proto));"
        },
        {
            "sha": "b14c9a3250379bc787f5d13c539b5b35dd4e15d8",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -715,7 +715,7 @@ ENTRY entry {\n   config.set_num_warps(8);\n   config.set_num_stages(4);\n \n-  TF_ASSERT_OK(triton_dot_fusion->set_backend_config(backend_config));\n+  triton_dot_fusion->set_backend_config(backend_config);\n \n   BlockLevelParameters block_level_parameters;\n   block_level_parameters.num_ctas = 1;\n@@ -733,7 +733,7 @@ ENTRY entry {\n   config.set_block_n(128);\n   config.set_block_k(128);\n   block_level_parameters.num_stages = 1;\n-  TF_ASSERT_OK(triton_dot_fusion->set_backend_config(backend_config));\n+  triton_dot_fusion->set_backend_config(backend_config);\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       const auto result,\n@@ -1310,7 +1310,7 @@ ENTRY entry {\n   config.set_num_ctas(1);\n   config.set_num_stages(1);\n   config.set_num_warps(2);\n-  TF_ASSERT_OK(triton_dot_fusion->set_backend_config(backend_config));\n+  triton_dot_fusion->set_backend_config(backend_config);\n \n   BlockLevelParameters block_level_parameters;\n   block_level_parameters.num_ctas = 1;\n@@ -1327,7 +1327,7 @@ ENTRY entry {\n   config.set_block_m(32);\n   config.set_block_n(32);\n   config.set_block_k(32);\n-  TF_ASSERT_OK(triton_dot_fusion->set_backend_config(backend_config));\n+  triton_dot_fusion->set_backend_config(backend_config);\n \n   TF_ASSERT_OK(TritonWrapper(\"test_fn\", triton_dot_fusion, CudaAmpereOrRocm(),\n                              dev_info, block_level_parameters, &llvm_module,"
        },
        {
            "sha": "3e69266ad5b7b6ca563ca2157691a6002c9aed17",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_int4_device_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -144,7 +144,8 @@ class TritonTest : public GpuCodegenTest {\n     triton_gemm_key->set_num_stages(1);\n     triton_gemm_key->set_num_warps(2);\n     triton_gemm_key->set_num_ctas(1);\n-    return fusion->set_backend_config(gpu_config);\n+    fusion->set_backend_config(gpu_config);\n+    return absl::OkStatus();\n   }\n \n  protected:"
        },
        {
            "sha": "538f2f2c2d01bee1a9524e06fd12c07b9124fe8c",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/test_utils.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftest_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftest_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftest_utils.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -262,7 +262,7 @@ absl::Status ConvertEntryToTritonFusion(HloModule* module,\n     gpu_config.mutable_fusion_backend_config()->set_kind(\n         std::string(kTritonFusionKind));\n   }\n-  TF_RETURN_IF_ERROR(fusion->set_backend_config(gpu_config));\n+  fusion->set_backend_config(gpu_config);\n \n   auto new_entry =\n       module->AddComputationAndUnifyNamesAndIds(builder.Build(),"
        },
        {
            "sha": "43f233cc569798a11e34e46efe9d90c0e9b16f17",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction.h",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -2035,9 +2035,8 @@ class HloInstruction {\n     return proto;\n   }\n \n-  absl::Status set_backend_config(const tsl::protobuf::Message& proto) {\n+  void set_backend_config(const tsl::protobuf::Message& proto) {\n     backend_config_ = BackendConfigWrapper(proto);\n-    return absl::OkStatus();\n   }\n \n   // Getter/setter for raw JSON-encoded backend config.  Prefer the"
        },
        {
            "sha": "3ece0f60bb9f41606b73cd07a93cb021eedc3c9a",
            "filename": "third_party/xla/xla/hlo/transforms/while_loop_trip_count_annotator.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fwhile_loop_trip_count_annotator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fwhile_loop_trip_count_annotator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fwhile_loop_trip_count_annotator.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -67,7 +67,7 @@ absl::StatusOr<bool> WhileLoopTripCountAnnotator::Run(\n           config.mutable_known_trip_count()->set_n(*trip_count);\n         }\n \n-        TF_RETURN_IF_ERROR(instr->set_backend_config(config));\n+        instr->set_backend_config(config);\n         changed = true;\n       }\n     }"
        },
        {
            "sha": "40e81b3d9ee192a899d278b103a662cb61c4d32f",
            "filename": "third_party/xla/xla/service/cpu/onednn_contraction_rewriter.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 8,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -579,7 +579,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n     bool transpose_b = (rhs_dim_k != rhs_shape.dimensions_size() - 2);\n     matmul_config->set_transpose_a(transpose_a);\n     matmul_config->set_transpose_b(transpose_b);\n-    TF_RETURN_IF_ERROR(matmul_call->set_backend_config(backend_config));\n+    matmul_call->set_backend_config(backend_config);\n     TF_RETURN_IF_ERROR(ReplaceInstruction(dot_instr, matmul_call));\n     return absl::OkStatus();\n   }\n@@ -645,7 +645,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n             output_shape, {conv->mutable_operand(0), conv->mutable_operand(1)},\n             \"__onednn$convolution\"));\n \n-    TF_RETURN_IF_ERROR(custom_call->set_backend_config(backend_config));\n+    custom_call->set_backend_config(backend_config);\n     TF_RETURN_IF_ERROR(ReplaceInstruction(conv, custom_call));\n     return absl::OkStatus();\n   }\n@@ -815,7 +815,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n       if (optional_addend_broadcast) {\n         optimization_config->set_bias_broadcast(true);\n       }\n-      TF_RETURN_IF_ERROR(custom_call->set_backend_config(*backend_config));\n+      custom_call->set_backend_config(*backend_config);\n \n       HloInstruction* new_instr;\n       // If matched pattern has custom-call -> bitcast -> add, then we need to\n@@ -1010,7 +1010,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n       // handling.\n       fusions_config->add_alpha_typecast(\n           *(reinterpret_cast<int32_t*>(&constant_value.value())));\n-      TF_RETURN_IF_ERROR(custom_call->set_backend_config(*backend_config));\n+      custom_call->set_backend_config(*backend_config);\n       HloInstruction* new_instr;\n       if (optional_convert != nullptr &&\n           optional_convert->opcode() == HloOpcode::kConvert) {\n@@ -1070,7 +1070,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n       auto matmul_call = Cast<HloCustomCallInstruction>(\n           custom_call->AddInstruction(custom_call->CloneWithNewOperands(\n               copy->shape(), custom_call->mutable_operands())));\n-      TF_RETURN_IF_ERROR(matmul_call->set_backend_config(*backend_config));\n+      matmul_call->set_backend_config(*backend_config);\n       TF_RETURN_IF_ERROR(ReplaceInstruction(copy, matmul_call));\n     }\n     return absl::OkStatus();\n@@ -1084,7 +1084,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n     auto backend_config = contraction->backend_config<BackendConfig>();\n     auto fusions_config = GetFusionsConfig(&backend_config);\n     fusions_config->add_ops(kind);\n-    TF_RETURN_IF_ERROR(contraction->set_backend_config(*backend_config));\n+    contraction->set_backend_config(*backend_config);\n     std::unique_ptr<HloInstruction> output = contraction->Clone();\n     if (optional_bitcast != nullptr &&\n         optional_bitcast->opcode() == HloOpcode::kBitcast) {\n@@ -1274,7 +1274,7 @@ class OneDnnPostRewriteVisitor : public DfsHloRewriteVisitor {\n       auto matmul_call = Cast<HloCustomCallInstruction>(\n           contraction->AddInstruction(contraction->CloneWithNewOperands(\n               contraction->shape(), new_ops)));\n-      TF_RETURN_IF_ERROR(matmul_call->set_backend_config(*backend_config));\n+      matmul_call->set_backend_config(*backend_config);\n       TF_RETURN_IF_ERROR(ReplaceInstruction(contraction, matmul_call));\n       return HandleCustomCallInternal<dnnl::matmul::primitive_desc>(\n           matmul_call);\n@@ -1449,7 +1449,8 @@ EMIT_GET_BACKEND_CONFIG_SPECIALIZATION(\n                         custom_call->backend_config<BackendConfig>());         \\\n     CONFIG_TYPE* config = backend_config.mutable_##CONFIG();                   \\\n     config->mutable_##SUB_CONFIG()->set_##FIELD(value);                        \\\n-    return custom_call->set_backend_config(backend_config);                    \\\n+    custom_call->set_backend_config(backend_config);                           \\\n+    return absl::OkStatus();                                                   \\\n   }\n \n EMIT_SET_BACKEND_CONFIG_SPECIALIZATION(SetWeightsPrepack,"
        },
        {
            "sha": "18a76b47805ab5a5bbc6d53bef9c4113dbd72b40",
            "filename": "third_party/xla/xla/service/cpu/onednn_ops_rewriter.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_ops_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_ops_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_ops_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -506,7 +506,7 @@ class OneDnnOpsRewriterVisitor : public DfsHloRewriteVisitor {\n         backend_config.mutable_onednn_layer_norm_config();\n     ln_config->set_rescale(OneDnnNormConfig::SCALE_AND_SHIFT);\n     ln_config->set_epsilon_typecast(*(reinterpret_cast<int32_t*>(&eps)));\n-    TF_RETURN_IF_ERROR(ln_call->set_backend_config(backend_config));\n+    ln_call->set_backend_config(backend_config);\n \n     if (convert_instr != nullptr && is_bf16orfp16_convert &&\n         is_producer_bf16orfp16) {\n@@ -568,7 +568,7 @@ class OneDnnOpsRewriterVisitor : public DfsHloRewriteVisitor {\n     OneDnnSoftmaxConfig* softmax_config =\n         backend_config.mutable_onednn_softmax_config();\n     softmax_config->set_softmax_axis(axis);\n-    TF_RETURN_IF_ERROR(softmax_call->set_backend_config(backend_config));\n+    softmax_call->set_backend_config(backend_config);\n     TF_RETURN_IF_ERROR(ReplaceInstruction(divide_instr, softmax_call));\n \n     return absl::OkStatus();"
        },
        {
            "sha": "4abfcb408e7975bb9414dbe927a87f71dd0bb688",
            "filename": "third_party/xla/xla/service/cpu/parallel_task_assignment.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -286,7 +286,7 @@ bool ParallelTaskAssigner::AssignParallelTasksHelper(\n     absl::c_copy(dim_partition_counts,\n                  tsl::protobuf::RepeatedFieldBackInserter(\n                      backend_config.mutable_outer_dimension_partitions()));\n-    TF_CHECK_OK(instruction->set_backend_config(backend_config));\n+    instruction->set_backend_config(backend_config);\n \n     VLOG(2) << \"Assigned parallel task count: \" << total_partition_count\n             << \" to instruction: \" << instruction->name();"
        },
        {
            "sha": "6a42daa770a56b2f75a57753ee55ea355114631e",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_pass_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass_test.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -224,8 +224,7 @@ TEST_F(AutotunerPassTest, CublasGemmIsAutotunedAndCached) {\n   gemm_config.clear_selected_algorithm();\n   *gpu_backend_config_before_second_run.mutable_gemm_backend_config() =\n       gemm_config;\n-  TF_ASSERT_OK(\n-      custom_call->set_backend_config(gpu_backend_config_before_second_run));\n+  custom_call->set_backend_config(gpu_backend_config_before_second_run);\n \n   // Run the pass for the second time, this should hit the cache.\n   {"
        },
        {
            "sha": "39a0977ec8d25658d618357681bf8f5850c45453",
            "filename": "third_party/xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -1119,7 +1119,7 @@ absl::StatusOr<bool> GpuConvAlgorithmPicker::RunOnInstruction(\n   VLOG(3) << \"Replacing convolution \" << instr->ToString() << \" with \"\n           << new_call->ToString();\n \n-  TF_RETURN_IF_ERROR(new_call->set_backend_config(gpu_backend_config));\n+  new_call->set_backend_config(gpu_backend_config);\n \n   std::vector<HloInstruction*> new_tuple_elements;\n   new_tuple_elements.reserve(new_call->shape().tuple_shapes().size() - 1);"
        },
        {
            "sha": "f825ab5d5b4b8462a95c5ca63c34bddf51df0f96",
            "filename": "third_party/xla/xla/service/gpu/autotuning/custom_kernel_fusion_autotuner.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fcustom_kernel_fusion_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fcustom_kernel_fusion_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fcustom_kernel_fusion_autotuner.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -64,7 +64,7 @@ absl::StatusOr<std::unique_ptr<HloModule>> ExtractFusionModule(\n   gpu_config.mutable_fusion_backend_config()\n       ->mutable_custom_fusion_config()\n       ->set_kernel_index(kernel_index);\n-  TF_RETURN_IF_ERROR(instruction->set_backend_config(gpu_config));\n+  instruction->set_backend_config(gpu_config);\n \n   return hlo_module;\n }\n@@ -129,7 +129,7 @@ absl::Status UpdateFusionInstructionKernelIndex(\n   gpu_config.mutable_fusion_backend_config()\n       ->mutable_custom_fusion_config()\n       ->set_kernel_index(kernel_index);\n-  TF_RETURN_IF_ERROR(fusion_instruction->set_backend_config(gpu_config));\n+  fusion_instruction->set_backend_config(gpu_config);\n \n   return absl::OkStatus();\n }"
        },
        {
            "sha": "a578d5184bb32edc20ac970ef3c8146707aaba90",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 7,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -291,7 +291,7 @@ absl::StatusOr<std::unique_ptr<HloModule>> TritonGemmAutotuneExtractor(\n       *gpu_config.mutable_fusion_backend_config();\n \n   *backend_config.mutable_triton_gemm_config() = config.ToProto();\n-  TF_RETURN_IF_ERROR(cloned_dot_fusion->set_backend_config(gpu_config));\n+  cloned_dot_fusion->set_backend_config(gpu_config);\n \n   if (config.split_k > 1) {\n     TF_RETURN_IF_ERROR(MakeDotSplitKBatch(cloned_dot_fusion, config));\n@@ -361,7 +361,7 @@ absl::Status UpdateFusionInstructionKernelIndex(\n   gpu_config.mutable_fusion_backend_config()\n       ->mutable_custom_fusion_config()\n       ->set_kernel_index(kernel_index);\n-  TF_RETURN_IF_ERROR(fusion_instruction->set_backend_config(gpu_config));\n+  fusion_instruction->set_backend_config(gpu_config);\n \n   return absl::OkStatus();\n }\n@@ -415,9 +415,8 @@ absl::StatusOr<std::unique_ptr<HloModule>> CuDnnFusionExtractor(\n   backend_config.set_kind(std::string(kCuDnnFusionKind));\n   // Provided a plan ID the autotuner just compiles one plan.\n   backend_config.mutable_cudnn_fusion_config()->set_plan_id(plan_id);\n-  TF_RETURN_IF_ERROR(\n-      module->entry_computation()->root_instruction()->set_backend_config(\n-          gpu_config));\n+  module->entry_computation()->root_instruction()->set_backend_config(\n+      gpu_config);\n   return module;\n }\n \n@@ -695,7 +694,7 @@ absl::Status GemmFusionAutotunerRewriterVisitor::HandleFusion(\n   if (autotune_result.has_triton()) {\n     *fusion_backend_config.mutable_triton_gemm_config() =\n         autotune_result.triton();\n-    TF_RETURN_IF_ERROR(fusion_instr->set_backend_config(gpu_config));\n+    fusion_instr->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(HandleTritonGemm(fusion_instr, fusion_backend_config));\n     MarkAsChanged();\n     return absl::OkStatus();\n@@ -720,7 +719,7 @@ absl::Status GemmFusionAutotunerRewriterVisitor::HandleFusion(\n   fusion_backend_config.set_kind(std::string(kCuDnnFusionKind));\n   fusion_backend_config.mutable_cudnn_fusion_config()->set_plan_id(\n       autotune_result.algorithm().algo_id());\n-  TF_RETURN_IF_ERROR(fusion_instr->set_backend_config(gpu_config));\n+  fusion_instr->set_backend_config(gpu_config);\n   MarkAsChanged();\n   return absl::OkStatus();\n }"
        },
        {
            "sha": "3eb67d9d53839004fa531fa31fbaa5760a4487b9",
            "filename": "third_party/xla/xla/service/gpu/backend_configs_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbackend_configs_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbackend_configs_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbackend_configs_test.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -131,8 +131,7 @@ TEST_F(BackendConfigsTest, DefaultGpuBackendConfigSetOpQueue) {\n   EXPECT_FALSE(add->has_backend_config());\n   GpuBackendConfig gpu_backend_config;\n   gpu_backend_config.set_operation_queue_id(2);\n-  EXPECT_THAT(add->set_backend_config(gpu_backend_config),\n-              absl_testing::IsOk());\n+  add->set_backend_config(gpu_backend_config);\n   EXPECT_THAT(\n       add->raw_backend_config_string(),\n       HasSubstr(\"{\\\"operation_queue_id\\\":\\\"2\\\",\\\"wait_on_operation_queues\\\":[],\"\n@@ -160,8 +159,7 @@ TEST_F(BackendConfigsTest, DefaultGpuBackendConfigSetWaitOnQueue) {\n   // Wait on queues {0, 1}\n   gpu_backend_config.mutable_wait_on_operation_queues()->Add(0);\n   gpu_backend_config.mutable_wait_on_operation_queues()->Add(1);\n-  EXPECT_THAT(add->set_backend_config(gpu_backend_config),\n-              absl_testing::IsOk());\n+  add->set_backend_config(gpu_backend_config);\n   EXPECT_THAT(\n       add->raw_backend_config_string(),\n       HasSubstr("
        },
        {
            "sha": "779135bd85f41c137445beea346bd2efbe461cb8",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -695,15 +695,16 @@ absl::Status SetHostDeviceType(HloInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(auto backend_config,\n                       instr->backend_config<GpuBackendConfig>());\n   backend_config.set_device_type(DEVICE_TYPE_HOST);\n-  TF_RETURN_IF_ERROR(instr->set_backend_config(backend_config));\n+  instr->set_backend_config(backend_config);\n   return absl::OkStatus();\n }\n \n absl::Status ClearBackendConfigDeviceType(HloInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(auto backend_config,\n                       instr->backend_config<GpuBackendConfig>());\n   backend_config.clear_device_type();\n-  return instr->set_backend_config(backend_config);\n+  instr->set_backend_config(backend_config);\n+  return absl::OkStatus();\n }\n \n bool BackendConfigDeviceTypeIsHost(HloInstruction* instr) {"
        },
        {
            "sha": "de15697cc3a78a89aba1ed4e47c849ae3cba006a",
            "filename": "third_party/xla/xla/service/gpu/gpu_float_support_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_float_support_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_float_support_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_float_support_test.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -137,7 +137,7 @@ class FloatSupportTest : public HloHardwareIndependentTestBase {\n     GpuBackendConfig config;\n     config.mutable_fusion_backend_config()->set_kind(\n         std::string(kTritonGemmFusionKind));\n-    CHECK_OK(fusion->set_backend_config(config));\n+    fusion->set_backend_config(config);\n \n     module->AddEntryComputation(builder.Build());\n "
        },
        {
            "sha": "18384ae86c7c35e120e72fc4b81d8a8779b7a702",
            "filename": "third_party/xla/xla/service/gpu/model/collective_ptable_stats_collection.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_ptable_stats_collection.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_ptable_stats_collection.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_ptable_stats_collection.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -99,7 +99,7 @@ absl::StatusOr<bool> CollectivePerfTableStatsCollection::Run(\n         reification_cost->set_exec_time_us(\n             absl::ToDoubleMicroseconds(exec_time));\n         *reification_cost->mutable_name() = name();\n-        TF_CHECK_OK(instr->set_backend_config(*gpu_config));\n+        instr->set_backend_config(*gpu_config);\n       });\n \n   return false;"
        },
        {
            "sha": "5713f661a00ae5ac51ab57098f65a16ca6a6a79e",
            "filename": "third_party/xla/xla/service/gpu/model/gpu_performance_model.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fgpu_performance_model.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fgpu_performance_model.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fgpu_performance_model.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -303,7 +303,7 @@ void GpuPerformanceModel::RecordEstimatedRunTime(\n       absl::ToDoubleMicroseconds(data.read_time + data.write_time));\n   reification_cost->set_exec_time_us(\n       absl::ToDoubleMicroseconds(data.exec_time));\n-  TF_CHECK_OK(instruction->set_backend_config(*gpu_config));\n+  instruction->set_backend_config(*gpu_config);\n \n   VLOG(8) << \"RecordEstimatedRunTime: \" << instruction->ToString();\n }"
        },
        {
            "sha": "44c7c71d1d06e0d971121b84776baec57538cedb",
            "filename": "third_party/xla/xla/service/gpu/model/matmul_ptable_stats_collection.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -103,7 +103,8 @@ absl::Status SetReificationCost(HloInstruction& instr, absl::Duration exec_time,\n   ReificationCost& reification_cost = *gpu_config.add_reification_cost();\n   reification_cost.set_exec_time_us(absl::ToDoubleMicroseconds(exec_time));\n   *reification_cost.mutable_name() = reification_name;\n-  return instr.set_backend_config(gpu_config);\n+  instr.set_backend_config(gpu_config);\n+  return absl::OkStatus();\n }\n \n // Computes the runtime estimation via analytical GEMM cost model and adds a"
        },
        {
            "sha": "b9fd4ce1c331464d789a9cacb5885778a51ea683",
            "filename": "third_party/xla/xla/service/gpu/model/sol_gpu_cost_model_stats_collection.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model_stats_collection.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model_stats_collection.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model_stats_collection.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -62,7 +62,8 @@ bool SetReificationCost(HloInstruction* instr, double cost_us) {\n   auto reification_cost = gpu_config->add_reification_cost();\n   reification_cost->set_exec_time_us(cost_us);\n   reification_cost->set_name(\"sol\");\n-  return instr->set_backend_config(*gpu_config).ok();\n+  instr->set_backend_config(*gpu_config);\n+  return true;\n }\n \n // Returns true if reification cost has been successfully recorded."
        },
        {
            "sha": "4389bee97f7bc1bf6d9593532fba0b823b58619c",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/async_collective_annotator.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fasync_collective_annotator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fasync_collective_annotator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fasync_collective_annotator.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -43,7 +43,7 @@ absl::StatusOr<bool> AsyncCollectiveAnnotator::Run(\n                           instruction->backend_config<GpuBackendConfig>());\n       gpu_config.mutable_collective_backend_config()->set_is_sync(\n           !is_collective_async_(instruction));\n-      TF_RETURN_IF_ERROR(instruction->set_backend_config(gpu_config));\n+      instruction->set_backend_config(gpu_config);\n       changed = true;\n     }\n   }"
        },
        {
            "sha": "5b108016a35122f5acb4b5bfac24e5e9592077e2",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_backend_assigner.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -112,7 +112,7 @@ absl::StatusOr<bool> CollectiveBackendAssigner::Run(\n       VLOG(1) << \"CollectiveBackendAssigner: setting backend to NVSHMEM for \"\n               << instr->name();\n \n-      TF_RETURN_IF_ERROR(instr->set_backend_config(gpu_config));\n+      instr->set_backend_config(gpu_config);\n       changed = true;\n     }\n   }"
        },
        {
            "sha": "3c28ed04a728d0ebaebd391fc216fb50fa66a629",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/convert_async_collectives_to_sync.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fconvert_async_collectives_to_sync.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fconvert_async_collectives_to_sync.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fconvert_async_collectives_to_sync.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -52,7 +52,7 @@ absl::Status GpuConvertAsyncCollectivesToSync::ConvertAsyncInstructionsToSync(\n     TF_ASSIGN_OR_RETURN(GpuBackendConfig gpu_config,\n                         async_start->backend_config<GpuBackendConfig>());\n     gpu_config.mutable_collective_backend_config()->set_is_sync(true);\n-    TF_RETURN_IF_ERROR(async_start->set_backend_config(gpu_config));\n+    async_start->set_backend_config(gpu_config);\n     replaced_ops[async_start] = nullptr;\n     replaced_ops[async_done] = async_start;\n   }"
        },
        {
            "sha": "d13a2ab564b9092290bb61e2a3aed7d291a72d0e",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/gpu_collective_combiner_utils.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fgpu_collective_combiner_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fgpu_collective_combiner_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fgpu_collective_combiner_utils.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -34,7 +34,8 @@ absl::Status AppendPipelinedInstruction(HloInstruction* instr,\n   TF_ASSIGN_OR_RETURN(auto config,\n                       instr->backend_config<gpu::GpuBackendConfig>());\n   config.mutable_collective_backend_config()->set_is_pipelined(true);\n-  return instr->set_backend_config(config);\n+  instr->set_backend_config(config);\n+  return absl::OkStatus();\n }\n \n bool IsPipelinedCollective(const HloInstruction& instr) {"
        },
        {
            "sha": "d403fdea391857b843e91d4791c339d4d1222808",
            "filename": "third_party/xla/xla/service/gpu/transforms/conv_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fconv_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fconv_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fconv_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -826,7 +826,7 @@ absl::StatusOr<bool> RunOnInstruction(HloInstruction* conv,\n   GpuBackendConfig gpu_backend_config;\n   *gpu_backend_config.mutable_cudnn_conv_backend_config() =\n       GetDefaultBackendConfig();\n-  TF_RETURN_IF_ERROR(custom_call->set_backend_config(gpu_backend_config));\n+  custom_call->set_backend_config(gpu_backend_config);\n \n   VLOG(1) << \"Replacing convolution \" << conv->ToString() << \" with \"\n           << custom_call->ToString();"
        },
        {
            "sha": "85a11f75b8af81984ef0656c80ad63a1b076bdbd",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_custom_call_compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_compiler.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -307,7 +307,7 @@ absl::StatusOr<se::gpu::CudnnGraph> BuildGraphForCustomCallToBackwardFMHA(\n   const bool force_deterministic =\n       RequireDeterminism(custom_call->GetModule()->config());\n   config.set_force_deterministic(force_deterministic);\n-  TF_RETURN_IF_ERROR(custom_call->set_backend_config(gpu_config));\n+  custom_call->set_backend_config(gpu_config);\n \n   TF_ASSIGN_OR_RETURN(\n       MatmulTensorDescriptor q,\n@@ -432,7 +432,7 @@ absl::StatusOr<se::gpu::CudnnGraph> BuildGraphForCustomCallToBackwardFMHAF8(\n   // 3 gradients, 4 amaxs and one workspace\n   TF_RET_CHECK(8 == custom_call->shape().tuple_shapes().size());\n \n-  TF_RETURN_IF_ERROR(custom_call->set_backend_config(gpu_config));\n+  custom_call->set_backend_config(gpu_config);\n \n   TF_ASSIGN_OR_RETURN(CudnnfMHAMaskKind cudnn_mask_type,\n                       AsCudnnFmhaMaskKind(config.mask_type()));"
        },
        {
            "sha": "9d4d4c682f200e25bcf6f6d57d74cd411e77e840",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_custom_call_converter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_converter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_converter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_converter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -47,7 +47,7 @@ class CustomCallVisitor : public DfsHloRewriteVisitor {\n     FusionBackendConfig &backend_config =\n         *gpu_config.mutable_fusion_backend_config();\n     backend_config.set_kind(hlo->custom_call_target());\n-    TF_RETURN_IF_ERROR(fusion->set_backend_config(gpu_config));\n+    fusion->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(ReplaceInstruction(hlo, fusion));\n     return absl::OkStatus();\n   }"
        },
        {
            "sha": "996a1486885e93586ed1260c6214effb28418ab8",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_fused_conv_rewriter.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fused_conv_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fused_conv_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fused_conv_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -355,7 +355,7 @@ absl::StatusOr<bool> FuseConvAlpha(HloComputation* comp) {\n \n     TF_ASSIGN_OR_RETURN(Literal alpha_f64, alpha->literal().Convert(F64));\n     config.set_conv_result_scale(alpha_f64.GetFirstElement<double>());\n-    TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n+    conv->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(conv->parent()->ReplaceInstruction(instr, gte));\n \n     changed = true;\n@@ -943,7 +943,7 @@ absl::StatusOr<bool> F8GraphConv(HloComputation* comp,\n               ShapeUtil::MakeTupleShape(output_shapes), operands));\n \n       new_convolution->set_custom_call_target(kCudnnConvForwardGraphCallTarget);\n-      TF_RETURN_IF_ERROR(new_convolution->set_backend_config(gpu_config));\n+      new_convolution->set_backend_config(gpu_config);\n       TF_ASSIGN_OR_RETURN(HloInstruction * new_gte,\n                           MakeGetTupleElementHlo(new_convolution, 0));\n       TF_RETURN_IF_ERROR(comp->ReplaceInstruction(final_instr, new_gte));\n@@ -1055,7 +1055,7 @@ absl::StatusOr<bool> FuseBiasOrSideInput(HloComputation* comp) {\n     HloInstruction* new_conv = comp->AddInstruction(\n         conv->CloneWithNewOperands(conv->shape(), new_operands));\n     comp->parent()->SetAndUniquifyInstrName(new_conv, conv->name());\n-    TF_RETURN_IF_ERROR(new_conv->set_backend_config(gpu_config));\n+    new_conv->set_backend_config(gpu_config);\n     TF_ASSIGN_OR_RETURN(HloInstruction * new_instr,\n                         MakeGetTupleElementHlo(new_conv, 0));\n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, new_instr));\n@@ -1173,7 +1173,7 @@ absl::StatusOr<bool> FuseSideInputAlpha(HloComputation* comp) {\n \n     TF_ASSIGN_OR_RETURN(Literal alpha_f64, alpha->literal().Convert(F64));\n     config.set_side_input_scale(alpha_f64.GetFirstElement<double>());\n-    TF_RETURN_IF_ERROR(new_conv->set_backend_config(gpu_config));\n+    new_conv->set_backend_config(gpu_config);\n \n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(conv, new_conv));\n     changed = true;\n@@ -1238,7 +1238,7 @@ absl::StatusOr<bool> FuseElu(HloComputation* comp,\n     }\n     TF_ASSIGN_OR_RETURN(conv, EnsureIsConvBiasActivation(conv));\n     config.set_activation_mode(se::dnn::kElu);\n-    TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n+    conv->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, gte1));\n     changed = true;\n   }\n@@ -1275,7 +1275,7 @@ absl::StatusOr<bool> FuseRelu(HloComputation* comp) {\n     }\n     TF_ASSIGN_OR_RETURN(conv, EnsureIsConvBiasActivation(conv));\n     config.set_activation_mode(se::dnn::kRelu);\n-    TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n+    conv->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, gte));\n     changed = true;\n   }\n@@ -1324,7 +1324,7 @@ absl::StatusOr<bool> FuseRelu6(HloComputation* comp,\n     }\n     TF_ASSIGN_OR_RETURN(conv, EnsureIsConvBiasActivation(conv));\n     config.set_activation_mode(se::dnn::kRelu6);\n-    TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n+    conv->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, gte));\n     changed = true;\n   }\n@@ -1385,7 +1385,7 @@ absl::StatusOr<bool> FuseLeakyRelu(HloComputation* comp,\n     config.set_activation_mode(se::dnn::kLeakyRelu);\n     TF_ASSIGN_OR_RETURN(Literal alpha_f64, alpha->literal().Convert(F64));\n     config.set_leakyrelu_alpha(alpha_f64.GetFirstElement<double>());\n-    TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n+    conv->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, gte1));\n     changed = true;\n   }"
        },
        {
            "sha": "decd1959923e997dc569b4d5ba3e730595335724",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_fusion_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -709,7 +709,7 @@ class CuDnnFusionVisitor : public DfsHloRewriteVisitor {\n             gpu_config.mutable_fusion_backend_config()\n                 ->mutable_cudnn_fusion_config();\n         cudnn_config->set_plan_id(plan_id);\n-        TF_RETURN_IF_ERROR(hlo->set_backend_config(gpu_config));\n+        hlo->set_backend_config(gpu_config);\n       }\n       return graph;\n     };"
        },
        {
            "sha": "2379b81fce2d817ceaa0cea2e7871b20937b8704",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_norm_rewriter.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_norm_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_norm_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_norm_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -1058,7 +1058,7 @@ class CudnnNormRewriterVisitor : public DfsHloRewriteVisitor {\n           instr->AddInstruction(HloInstruction::CreateCustomCall(\n               custom_call_shape, {x_reshape, scale_reshape, bias_reshape},\n               kCudnnNormCallTarget));\n-      TF_RETURN_IF_ERROR(custom_call->set_backend_config(gpu_backend_config));\n+      custom_call->set_backend_config(gpu_backend_config);\n \n       TF_ASSIGN_OR_RETURN(HloInstruction * gte,\n                           MakeGetTupleElementHlo(custom_call, 0));\n@@ -1174,8 +1174,7 @@ class CudnnNormRewriterVisitor : public DfsHloRewriteVisitor {\n       const int64_t workspace_size = (2 * c_constant * (4 + 256)) + 32;\n       backend_config.mutable_algorithm()->mutable_workspace_size()->set_value(\n           workspace_size);\n-      TF_RETURN_IF_ERROR(\n-          new_custom_call->set_backend_config(gpu_backend_config));\n+      new_custom_call->set_backend_config(gpu_backend_config);\n \n       auto replace_with_new_cc = [new_custom_call, this](\n                                      HloInstruction* old_instr,\n@@ -1456,7 +1455,7 @@ class CudnnNormRewriterVisitor : public DfsHloRewriteVisitor {\n               {x.instr(), scale.instr(), reshaped_dy, fused_expectation.instr(),\n                fused_norm_factor.instr()},\n               kCudnnNormCallTarget));\n-      TF_RETURN_IF_ERROR(custom_call->set_backend_config(gpu_backend_config));\n+      custom_call->set_backend_config(gpu_backend_config);\n \n       auto replace_with_cc = [custom_call, norm_metadata, transposed_dy, this](\n                                  HloInstruction* old_instr,"
        },
        {
            "sha": "82cc3b0f42e2a1c5d7b9dfcc7ed2f24f4c01d952",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_vectorize_convolutions.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -283,7 +283,7 @@ absl::Status ReorderInt8NchwVect(HloCustomCallInstruction* conv,\n   CudnnConvBackendConfig& config =\n       *gpu_config.mutable_cudnn_conv_backend_config();\n   config.set_reordered_int8_nchw_vect(true);\n-  TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n+  conv->set_backend_config(gpu_config);\n \n   // Reorder the filter.\n   TF_ASSIGN_OR_RETURN(Shape filter_shape, builder->GetShape(operands[1]));"
        },
        {
            "sha": "5f245ee9ce778ae9f1fae9dde6fc27611573bf7a",
            "filename": "third_party/xla/xla/service/gpu/transforms/custom_kernel_fusion_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcustom_kernel_fusion_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcustom_kernel_fusion_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcustom_kernel_fusion_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -176,7 +176,7 @@ absl::StatusOr<HloInstruction*> CreateFusionInstruction(\n   backend_config.set_kind(\"__custom_fusion\");\n   *backend_config.mutable_custom_fusion_config() = match.config();\n   backend_config.mutable_custom_fusion_config()->set_kernel_index(kernel_index);\n-  TF_RETURN_IF_ERROR(fusion->set_backend_config(std::move(gpu_config)));\n+  fusion->set_backend_config(std::move(gpu_config));\n \n   // If we don't have workspace we can return constructed fusion instruction.\n   if (match.workspace_size_bytes() == 0) return fusion;"
        },
        {
            "sha": "26e160383fb7f9b037cd7ac1d2220143030666e9",
            "filename": "third_party/xla/xla/service/gpu/transforms/double_buffer_loop_unrolling.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdouble_buffer_loop_unrolling.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdouble_buffer_loop_unrolling.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdouble_buffer_loop_unrolling.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -376,7 +376,7 @@ absl::StatusOr<bool> FullyUnroll(HloInstruction* while_instr,\n \n   WhileLoopBackendConfig new_config;\n   new_config.mutable_known_trip_count()->set_n(1);\n-  TF_RETURN_IF_ERROR(while_instr->set_backend_config(new_config));\n+  while_instr->set_backend_config(new_config);\n \n   return changed;\n }\n@@ -532,7 +532,7 @@ absl::StatusOr<bool> DoubleBufferingUnroll(HloInstruction* while_instr,\n         config.known_init_step().init() + (peel_one_iteration ? step : 0));\n   }\n \n-  TF_RETURN_IF_ERROR(while_instr->set_backend_config(new_config));\n+  while_instr->set_backend_config(new_config);\n   return true;  // changed\n }\n "
        },
        {
            "sha": "9d6068c982992a1287568ed16463ab7a4b4d6e14",
            "filename": "third_party/xla/xla/service/gpu/transforms/dynamic_slice_fusion_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdynamic_slice_fusion_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdynamic_slice_fusion_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdynamic_slice_fusion_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -235,7 +235,7 @@ absl::StatusOr<HloInstruction*> CreateFusionInstruction(\n       dynamic ? kDynamicSliceFusionWithDynamicAddressComputationConfigName\n               : kDynamicSliceFusionWithStaticAddressComputationConfigName));\n   *backend_config.mutable_custom_fusion_config() = config;\n-  TF_RETURN_IF_ERROR(fusion->set_backend_config(std::move(gpu_config)));\n+  fusion->set_backend_config(std::move(gpu_config));\n \n   return fusion;\n }"
        },
        {
            "sha": "c53fda7cf2c63cbd25e06ef0ed7a0dec9e19da9b",
            "filename": "third_party/xla/xla/service/gpu/transforms/explicit_stream_annotation_async_wrapper.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fexplicit_stream_annotation_async_wrapper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fexplicit_stream_annotation_async_wrapper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fexplicit_stream_annotation_async_wrapper.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -69,7 +69,7 @@ static absl::StatusOr<bool> AsynchronizeInstruction(HloInstruction* instr) {\n   // Set earliest schedule of done op to be false so it can be scheduled\n   // far apart from start.\n   gpu_config.set_force_earliest_schedule(false);\n-  TF_RETURN_IF_ERROR(done->set_backend_config(gpu_config));\n+  done->set_backend_config(gpu_config);\n   VLOG(5) << \"Created async instruction: \" << done->ToString();\n   return true;\n }"
        },
        {
            "sha": "226b071162d6094cffb56ef16d20a6ac93a5abd3",
            "filename": "third_party/xla/xla/service/gpu/transforms/fusion_block_level_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -229,7 +229,7 @@ absl::StatusOr<bool> ProcessFusionInstruction(\n        ->mutable_block_level_fusion_config() =\n       tiled_runtime_data.block_level_parameters.ToBlockLevelFusionConfig();\n   backend_config.mutable_fusion_backend_config()->set_kind(kTritonFusionKind);\n-  TF_RETURN_IF_ERROR(fusion_instruction->set_backend_config(backend_config));\n+  fusion_instruction->set_backend_config(backend_config);\n   fusion_instruction->set_fusion_kind(HloInstruction::FusionKind::kCustom);\n   return true;\n }"
        },
        {
            "sha": "d58ade5a14b42bbe0d6c278f578befc3eec98d0c",
            "filename": "third_party/xla/xla/service/gpu/transforms/fusion_dynamic_memcpy_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_dynamic_memcpy_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_dynamic_memcpy_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_dynamic_memcpy_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -293,7 +293,7 @@ absl::StatusOr<bool> FusionDynamicMemcpyRewriter::Run(\n       }\n     }\n \n-    TF_RETURN_IF_ERROR(fusion->set_backend_config(backend_config));\n+    fusion->set_backend_config(backend_config);\n     has_changed = true;\n   }\n "
        },
        {
            "sha": "9c836da4cd2f7cfb2e3929f322b25d9f4b72d538",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_broadcast_folding_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_broadcast_folding_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_broadcast_folding_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_broadcast_folding_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -95,7 +95,7 @@ class GemmBroadcastFoldingVisitor : public DfsHloRewriteVisitor {\n       }\n       TF_RETURN_IF_ERROR(existing_gemm->ReplaceOperandWithDifferentShape(\n           bcast_operand_index, bcast->mutable_operand(0)));\n-      TF_RETURN_IF_ERROR(existing_gemm->set_backend_config(gpu_config));\n+      existing_gemm->set_backend_config(gpu_config);\n       MarkAsChanged();\n     }\n     return absl::OkStatus();"
        },
        {
            "sha": "28c36365f21eb4fbf3911701af00dc249fd937f5",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_fusion.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -806,7 +806,7 @@ class GemmFusionVisitor : public DfsHloRewriteVisitor {\n     FusionBackendConfig& backend_config =\n         *gpu_config.mutable_fusion_backend_config();\n     backend_config.set_kind(std::string(kTritonGemmFusionKind));\n-    TF_RETURN_IF_ERROR(dot_fusion->set_backend_config(gpu_config));\n+    dot_fusion->set_backend_config(gpu_config);\n \n     if (fusion_output->IsRoot()) {\n       fusion_output->parent()->set_root_instruction(dot_fusion);\n@@ -849,7 +849,7 @@ class GemmFusionVisitor : public DfsHloRewriteVisitor {\n     FusionBackendConfig& backend_config =\n         *gpu_config.mutable_fusion_backend_config();\n     backend_config.set_kind(\"__triton_ragged_dot\");\n-    TF_RETURN_IF_ERROR(dot_fusion->set_backend_config(gpu_config));\n+    dot_fusion->set_backend_config(gpu_config);\n \n     TF_RETURN_IF_ERROR(ReplaceInstruction(ragged_dot, dot_fusion));\n     MarkAsChanged();\n@@ -890,7 +890,7 @@ class GemmFusionVisitor : public DfsHloRewriteVisitor {\n     FusionBackendConfig& backend_config =\n         *gpu_config.mutable_fusion_backend_config();\n     backend_config.set_kind(kTritonScaledDotFusionKind);\n-    TF_RETURN_IF_ERROR(fusion->set_backend_config(gpu_config));\n+    fusion->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(ReplaceInstruction(scaled_dot, fusion));\n     MarkAsChanged();\n     return absl::OkStatus();"
        },
        {
            "sha": "5a2164566050b108c5e7b6ec1856c239c8f2f6c1",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_rewriter.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -688,7 +688,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n                   output_shape,\n                   {instr->mutable_operand(0), instr->mutable_operand(1)},\n                   gemm_custom_call_target));\n-          TF_RETURN_IF_ERROR(gemm_call->set_backend_config(gpu_backend_config));\n+          gemm_call->set_backend_config(gpu_backend_config);\n           TF_RETURN_IF_ERROR(ReplaceInstruction(instr, gemm_call));\n         }\n       } break;\n@@ -715,7 +715,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n     HloInstruction *gemm_call =\n         instr->AddInstruction(HloInstruction::CreateCustomCall(\n             output_shape, {lhs_convert, rhs_convert}, gemm_custom_call_target));\n-    TF_RETURN_IF_ERROR(gemm_call->set_backend_config(gpu_backend_config));\n+    gemm_call->set_backend_config(gpu_backend_config);\n     TF_RETURN_IF_ERROR(ReplaceInstruction(instr, gemm_call));\n     return absl::OkStatus();\n   }\n@@ -741,7 +741,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n             *alpha->literal().GetAsComplex128({}) * prev_alpha;\n         config.set_alpha_real(new_alpha.real());\n         config.set_alpha_imag(new_alpha.imag());\n-        TF_RETURN_IF_ERROR(existing_gemm->set_backend_config(gpu_config));\n+        existing_gemm->set_backend_config(gpu_config);\n         return ReplaceInstruction(instr, existing_gemm);\n       }\n     }\n@@ -1408,7 +1408,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n                 instr->shape().element_type(), new_output_shape.dimensions(),\n                 instr->shape().layout().minor_to_major()),\n             operands_list, kCublasLtMatmulF8CallTarget));\n-    TF_RETURN_IF_ERROR(new_custom_call->set_backend_config(gpu_backend_config));\n+    new_custom_call->set_backend_config(gpu_backend_config);\n     TF_RETURN_IF_ERROR(SetName(instr->GetModule(), new_custom_call));\n \n     // Slice the result of the GEMM if the operands were padded.\n@@ -1611,7 +1611,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n                         gemm_and_damax->backend_config<GpuBackendConfig>());\n     GemmBackendConfig &config = *gpu_config.mutable_gemm_backend_config();\n     config.set_damax_output(true);\n-    TF_RETURN_IF_ERROR(gemm_and_damax->set_backend_config(gpu_config));\n+    gemm_and_damax->set_backend_config(gpu_config);\n \n     // Obtain D and DAmax separately from the output tuple.\n     HloInstruction *d =\n@@ -1724,7 +1724,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n         gemm->CloneWithNewOperands(gemm->shape(), operands);\n     // set output shape to bias shape if mix type\n     fused_op->mutable_shape()->set_element_type(bias->shape().element_type());\n-    TF_RETURN_IF_ERROR(fused_op->set_backend_config(gpu_config));\n+    fused_op->set_backend_config(gpu_config);\n \n     // Choose whether the bias must alias the output. Legacy cublas GEMMs must\n     // operate in place and alias the bias with the output, whereas with\n@@ -1878,7 +1878,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n     HloInstruction *result = computation->AddInstruction(\n         gemm->CloneWithNewOperands(gemm->shape(), operands));\n \n-    TF_RETURN_IF_ERROR(result->set_backend_config(gpu_config));\n+    result->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(SetName(gemm->GetModule(), result));\n     if (slice) {\n       result = computation->AddInstruction(\n@@ -1922,7 +1922,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n \n     HloComputation *computation = gemm->parent();\n     HloInstruction *result = computation->AddInstruction(gemm->Clone());\n-    TF_RETURN_IF_ERROR(result->set_backend_config(gpu_config));\n+    result->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(SetName(gemm->GetModule(), result));\n \n     if (slice_or_bitcast) {\n@@ -1970,7 +1970,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n     std::unique_ptr<HloInstruction> output = gemm->CloneWithNewShape(\n         has_aux ? ShapeUtil::MakeTupleShape({gemm->shape(), gemm->shape()})\n                 : gemm->shape());\n-    TF_RETURN_IF_ERROR(output->set_backend_config(gpu_config));\n+    output->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(SetName(multiply->GetModule(), output.get()));\n \n     if (slice_or_bitcast) {\n@@ -2024,7 +2024,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n     std::unique_ptr<HloInstruction> output = gemm->CloneWithNewShape(\n         has_aux ? ShapeUtil::MakeTupleShape({gemm->shape(), gemm->shape()})\n                 : gemm->shape());\n-    TF_RETURN_IF_ERROR(output->set_backend_config(gpu_config));\n+    output->set_backend_config(gpu_config);\n     TF_RETURN_IF_ERROR(SetName(multiply->GetModule(), output.get()));\n \n     if (slice_or_bitcast) {"
        },
        {
            "sha": "a495e719e9c9ec46204e1f7e283ca49d7ac9138c",
            "filename": "third_party/xla/xla/service/gpu/transforms/gpusolver_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgpusolver_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgpusolver_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgpusolver_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -105,7 +105,7 @@ absl::StatusOr<HloInstruction*> CreateCholesky(\n       computation->AddInstruction(HloInstruction::CreateCustomCall(\n           call_shape, {operand}, kCusolverCholeskyCallTarget, {a_shape}));\n   custom_call->set_metadata(metadata);\n-  TF_RETURN_IF_ERROR(custom_call->set_backend_config(options));\n+  custom_call->set_backend_config(options);\n   HloInstruction* out = computation->AddInstruction(\n       HloInstruction::CreateGetTupleElement(a_shape, custom_call, 0));\n   HloInstruction* info = computation->AddInstruction("
        },
        {
            "sha": "48e2c433d90ca96dbb62cb6aa87ba93b611e210f",
            "filename": "third_party/xla/xla/service/gpu/transforms/nest_gemm_fusion.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -144,7 +144,7 @@ absl::Status FuseInstructionsForConsumer(HloInstruction& root,\n                       fusion->backend_config<GpuBackendConfig>());\n   gpu_config.mutable_fusion_backend_config()->set_kind(\n       std::string(kTritonNestedGemmFusionKind));\n-  TF_RETURN_IF_ERROR(fusion->set_backend_config(gpu_config));\n+  fusion->set_backend_config(gpu_config);\n \n   for (int64_t operand_index : consumer.OperandIndices(&root)) {\n     TF_RETURN_IF_ERROR(consumer.ReplaceOperandWith(operand_index, fusion));\n@@ -197,7 +197,7 @@ absl::Status AnnotateDotOperandNestedFusionImpl(\n   *gpu_config.mutable_fusion_backend_config()\n        ->mutable_block_level_fusion_config() =\n       block_level_parameters.ToBlockLevelFusionConfig();\n-  TF_RETURN_IF_ERROR(nested_fusion.set_backend_config(gpu_config));\n+  nested_fusion.set_backend_config(gpu_config);\n \n   return absl::OkStatus();\n }\n@@ -298,7 +298,7 @@ absl::Status MakeNestedFusionFromGemmFusion(HloFusionInstruction* fusion,\n \n   *backend_config.mutable_block_level_fusion_config() =\n       block_level_parameters.ToBlockLevelFusionConfig();\n-  TF_RETURN_IF_ERROR(fusion->set_backend_config(gpu_config));\n+  fusion->set_backend_config(gpu_config);\n \n   return absl::OkStatus();\n }"
        },
        {
            "sha": "19d7c6f0f6d28a2ae174e1c71c07b7c98213e69f",
            "filename": "third_party/xla/xla/service/gpu/transforms/priority_fusion.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -1197,8 +1197,8 @@ absl::StatusOr<bool> PriorityFusion::Run(\n             Fuse(producer, consumer, use_multi_output_fusion);\n         auto backend_config_it = block_level_parameters_map.find(consumer);\n         if (backend_config_it != block_level_parameters_map.end()) {\n-          TF_RETURN_IF_ERROR(fusion_instruction->set_backend_config(\n-              GetTritonGpuBackendConfig(backend_config_it->second)));\n+          fusion_instruction->set_backend_config(\n+              GetTritonGpuBackendConfig(backend_config_it->second));\n           fusion_instruction->set_fusion_kind(\n               HloInstruction::FusionKind::kCustom);\n         }"
        },
        {
            "sha": "f201300eb7ff435ad1eae076e9c4a28c49f6d4f8",
            "filename": "third_party/xla/xla/service/gpu/transforms/softmax_rewriter_triton.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsoftmax_rewriter_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsoftmax_rewriter_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsoftmax_rewriter_triton.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -254,7 +254,7 @@ absl::StatusOr<HloFusionInstruction*> MakeFusionForDiamond(\n   FusionBackendConfig& backend_config =\n       *gpu_config.mutable_fusion_backend_config();\n   backend_config.set_kind(std::string(kTritonFusionKind));\n-  TF_RETURN_IF_ERROR(normalization_fusion->set_backend_config(gpu_config));\n+  normalization_fusion->set_backend_config(gpu_config);\n   return xla::Cast<HloFusionInstruction>(normalization_fusion);\n }\n \n@@ -386,7 +386,7 @@ DecideIfShouldFuseAndMaybeSetBlockLevelParameters(\n   *backend_config.mutable_fusion_backend_config()\n        ->mutable_block_level_fusion_config() =\n       tiled_runtime_data.block_level_parameters.ToBlockLevelFusionConfig();\n-  TF_RETURN_IF_ERROR(normalization_fusion->set_backend_config(backend_config));\n+  normalization_fusion->set_backend_config(backend_config);\n   VLOG(2) << \"Fusing with backend config: \" << backend_config.DebugString();\n \n   return FusionDecision::Allow();"
        },
        {
            "sha": "634cffdbbd342778b1d864f30df46096a82d0fe1",
            "filename": "third_party/xla/xla/service/gpu/transforms/sort_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsort_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsort_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsort_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -530,7 +530,7 @@ absl::StatusOr<bool> SortRewriter::RunOnInstruction(\n \n   xla::SortOptions backend_config;\n   backend_config.set_descending(sort_analysis.descending);\n-  TF_RETURN_IF_ERROR(custom_call->set_backend_config(backend_config));\n+  custom_call->set_backend_config(backend_config);\n \n   // Build the replacement instruction.\n   HloInstruction* replacement;"
        },
        {
            "sha": "0a80ad1f494f3b29e842d36ca3b65acee1ddda2e",
            "filename": "third_party/xla/xla/service/gpu/transforms/stream_attribute_annotator.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_annotator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_annotator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_annotator.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -87,7 +87,7 @@ absl::StatusOr<bool> AnnotateStreamAttributesForInstruction(\n       comp_root_gpu_config->operation_queue_id());\n   *instr_gpu_config.mutable_wait_on_operation_queues() =\n       comp_root_gpu_config->wait_on_operation_queues();\n-  TF_RETURN_IF_ERROR(instr->set_backend_config(instr_gpu_config));\n+  instr->set_backend_config(instr_gpu_config);\n   return true;\n }\n \n@@ -100,7 +100,7 @@ absl::StatusOr<bool> AnnotateStreamAttributesForCopyStart(\n     return false;\n   }\n   instr_gpu_config.set_operation_queue_id(channel_id);\n-  TF_RETURN_IF_ERROR(instr->set_backend_config(instr_gpu_config));\n+  instr->set_backend_config(instr_gpu_config);\n   VLOG(3) << \"Add copy-start's backend config: \" << channel_id;\n   return true;\n }\n@@ -139,7 +139,7 @@ absl::StatusOr<bool> WrapIntoFusionAndAnnotateStreamAttributes(\n   TF_RETURN_IF_ERROR(computation->RemoveInstruction(instruction));\n \n   instr_gpu_config.set_operation_queue_id(channel_id);\n-  TF_RETURN_IF_ERROR(fusion_instruction->set_backend_config(instr_gpu_config));\n+  fusion_instruction->set_backend_config(instr_gpu_config);\n   VLOG(3) << \"Add async stream \" << channel_id << \" and wrapped instruction \"\n           << instruction->ToString();\n   VLOG(3) << \"  Fusion wrapper: \" << fusion_instruction->ToString();\n@@ -168,7 +168,7 @@ absl::StatusOr<bool> AnnotateStreamAttributesForUsers(\n     if (it == gpu_config.wait_on_operation_queues().end() &&\n         gpu_config.operation_queue_id() != stream_id) {\n       gpu_config.mutable_wait_on_operation_queues()->Add(stream_id);\n-      TF_RETURN_IF_ERROR(user->set_backend_config(gpu_config));\n+      user->set_backend_config(gpu_config);\n       changed = true;\n     }\n   }"
        },
        {
            "sha": "f2be71a75739c92feb88f38eb2060b5967854c7c",
            "filename": "third_party/xla/xla/service/gpu/transforms/stream_attribute_async_wrapper.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_async_wrapper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_async_wrapper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_async_wrapper.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -48,7 +48,7 @@ static absl::StatusOr<bool> AsynchronizeInstruction(HloInstruction* instr) {\n   // Set the false delay of done op to be false so it can be scheduled\n   // far apart from start.\n   gpu_config.set_force_earliest_schedule(false);\n-  TF_RETURN_IF_ERROR(done->set_backend_config(gpu_config));\n+  done->set_backend_config(gpu_config);\n   VLOG(5) << \"Created async instruction: \" << done->ToString();\n   return true;\n }"
        },
        {
            "sha": "da1a5f280647f5755b9b2406872eebca67daced5",
            "filename": "third_party/xla/xla/service/gpu/transforms/triangular_solve_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriangular_solve_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriangular_solve_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriangular_solve_rewriter.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -68,8 +68,7 @@ absl::StatusOr<bool> TriangularSolveRewriter::Run(\n           comp->AddInstruction(HloInstruction::CreateCustomCall(\n               new_shape, instr->operands(), kTriangularSolveCallTarget));\n       module->SetAndUniquifyInstrName(custom_call, \"triangular-solve\");\n-      TF_RETURN_IF_ERROR(\n-          custom_call->set_backend_config(instr->triangular_solve_options()));\n+      custom_call->set_backend_config(instr->triangular_solve_options());\n \n       // Preserve metadata from `instr`.\n       custom_call->set_metadata(instr->metadata());"
        },
        {
            "sha": "d3248af14c768254e5ae950a317efedb3b95b8ec",
            "filename": "third_party/xla/xla/service/gpu/transforms/windowed_einsum_handler.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fwindowed_einsum_handler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fwindowed_einsum_handler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fwindowed_einsum_handler.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -331,8 +331,8 @@ absl::Status UpdateDotAndConsumerConfig(HloInstruction* dot,\n     updater_gpu_config->mutable_wait_on_operation_queues()->Add(stream_id);\n   }\n \n-  TF_RETURN_IF_ERROR(dot->set_backend_config(dot_gpu_config.value()));\n-  TF_RETURN_IF_ERROR(updater->set_backend_config(updater_gpu_config.value()));\n+  dot->set_backend_config(dot_gpu_config.value());\n+  updater->set_backend_config(updater_gpu_config.value());\n   return absl::OkStatus();\n }\n \n@@ -342,7 +342,7 @@ absl::Status SetForceDelayForInstruction(HloInstruction* instr,\n \n   gpu_config->set_force_earliest_schedule(force_delay);\n \n-  TF_RETURN_IF_ERROR(instr->set_backend_config(gpu_config.value()));\n+  instr->set_backend_config(gpu_config.value());\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "1800bd4f22fd0ee8d4a851319bd8c13f31247709",
            "filename": "third_party/xla/xla/service/hlo_instruction_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_instruction_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_instruction_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_instruction_test.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -2555,7 +2555,7 @@ TEST_F(HloInstructionTest, BackendConfigCanContainNonFiniteFloats) {\n       *gpu_config.mutable_gemm_backend_config();\n   orig_config.set_alpha_real(std::numeric_limits<double>::infinity());\n   orig_config.set_alpha_imag(std::numeric_limits<double>::quiet_NaN());\n-  TF_ASSERT_OK(dot->set_backend_config(gpu_config));\n+  dot->set_backend_config(gpu_config);\n \n   TF_ASSERT_OK_AND_ASSIGN(auto new_gpu_config,\n                           dot->backend_config<gpu::GpuBackendConfig>());\n@@ -2868,7 +2868,7 @@ TEST_F(HloInstructionTest, BackendConfigCopiedToDerived) {\n \n   gpu::GpuBackendConfig gpu_config;\n   gpu_config.set_operation_queue_id(2);\n-  TF_ASSERT_OK(add->set_backend_config(gpu_config));\n+  add->set_backend_config(gpu_config);\n   auto add2 = b.AddInstruction(\n       HloInstruction::CreateBinary(shape, HloOpcode::kAdd, p0, p0));\n   add->SetupDerivedInstruction(add2);\n@@ -2887,7 +2887,7 @@ TEST_F(HloInstructionTest, BackendConfigNotCopiedToDerivedWithDiffOpcode) {\n \n   gpu::GpuBackendConfig gpu_config;\n   gpu_config.set_operation_queue_id(2);\n-  TF_ASSERT_OK(or1->set_backend_config(gpu_config));\n+  or1->set_backend_config(gpu_config);\n   auto add2 = b.AddInstruction(\n       HloInstruction::CreateBinary(shape, HloOpcode::kAdd, p0, p1));\n   or1->SetupDerivedInstruction(add2);\n@@ -2907,10 +2907,10 @@ TEST_F(HloInstructionTest, BackendConfigNotCopiedToDerivedWithConfig) {\n   gpu_config0.set_operation_queue_id(2);\n   gpu_config1.set_operation_queue_id(3);\n \n-  TF_ASSERT_OK(add->set_backend_config(gpu_config0));\n+  add->set_backend_config(gpu_config0);\n   auto add2 = b.AddInstruction(\n       HloInstruction::CreateBinary(shape, HloOpcode::kAdd, p0, p0));\n-  TF_ASSERT_OK(add2->set_backend_config(gpu_config1));\n+  add2->set_backend_config(gpu_config1);\n \n   add->SetupDerivedInstruction(add2);\n   auto backend_config = add2->backend_config<gpu::GpuBackendConfig>();"
        },
        {
            "sha": "ccc89b557eb304ee66153f5b0b2904e4d2de9945",
            "filename": "third_party/xla/xla/tests/hlo_runner_agnostic_test_base.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 10,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Ftests%2Fhlo_runner_agnostic_test_base.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1050d735b1045fca794059bbc0bc9db823b8339/third_party%2Fxla%2Fxla%2Ftests%2Fhlo_runner_agnostic_test_base.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fhlo_runner_agnostic_test_base.cc?ref=f1050d735b1045fca794059bbc0bc9db823b8339",
            "patch": "@@ -459,9 +459,8 @@ ::testing::AssertionResult HloRunnerAgnosticTestBase::Run(\n     // Set backend configuration if it is given.\n     HloInstruction* instruction =\n         (*module)->entry_computation()->root_instruction();\n-    absl::Status s = instruction->set_backend_config(*backend_config);\n-    return s.ok() ? ::testing::AssertionSuccess()\n-                  : ::testing::AssertionFailure() << s.message();\n+    instruction->set_backend_config(*backend_config);\n+    return ::testing::AssertionSuccess();\n   }\n \n   if (const absl::Status status = PreprocessModuleForTestRunner(module->get());\n@@ -500,10 +499,7 @@ ::testing::AssertionResult HloRunnerAgnosticTestBase::RunReplicated(\n     // Set backend configuration if it is given.\n     HloInstruction* instruction =\n         (*module)->entry_computation()->root_instruction();\n-    if (const absl::Status s = instruction->set_backend_config(*backend_config);\n-        !s.ok()) {\n-      return ::testing::AssertionFailure() << s.message();\n-    }\n+    instruction->set_backend_config(*backend_config);\n     return ::testing::AssertionSuccess();\n   }\n \n@@ -548,9 +544,8 @@ ::testing::AssertionResult HloRunnerAgnosticTestBase::RunMultipleTimes(\n       // Set backend configuration if it is given.\n       HloInstruction* instruction =\n           (*module)->entry_computation()->root_instruction();\n-      absl::Status s = instruction->set_backend_config(*backend_config);\n-      return s.ok() ? ::testing::AssertionSuccess()\n-                    : ::testing::AssertionFailure() << s.message();\n+      instruction->set_backend_config(*backend_config);\n+      return ::testing::AssertionSuccess();\n     }\n \n     if (const absl::Status status ="
        }
    ],
    "stats": {
        "total": 260,
        "additions": 127,
        "deletions": 133
    }
}