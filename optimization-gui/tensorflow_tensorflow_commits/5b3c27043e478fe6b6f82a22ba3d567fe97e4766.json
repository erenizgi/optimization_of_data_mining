{
    "author": "pschuh",
    "message": "Remove all usages of arguments_are_tupled since the default is false and it is\nnever set otherwise. Also it is an error to set it to be true.\n\nPiperOrigin-RevId: 827647060",
    "sha": "5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
    "files": [
        {
            "sha": "8ccb236897ce39945ef53994b748a07d4763f259",
            "filename": "tensorflow/compiler/jit/xla_launch_util.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/tensorflow%2Fcompiler%2Fjit%2Fxla_launch_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/tensorflow%2Fcompiler%2Fjit%2Fxla_launch_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fxla_launch_util.cc?ref=5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
            "patch": "@@ -809,7 +809,6 @@ xla::ExecuteOptions GetPjRtExecuteOptions(\n     const DeviceType& device_type,\n     absl::flat_hash_set<int> non_donatable_input_indices) {\n   xla::ExecuteOptions options;\n-  options.arguments_are_tupled = false;\n   // Hardcode run id to always be one: TF distributed strategy\n   // differentiates between subsequent runs using dependency edges. This\n   // is safe, as only TF dist-strat can produce distributed ops, and we"
        },
        {
            "sha": "d8ed5feac79f127ee0e96927430541503eb403f8",
            "filename": "tensorflow/compiler/jit/xla_launch_util_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/tensorflow%2Fcompiler%2Fjit%2Fxla_launch_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/tensorflow%2Fcompiler%2Fjit%2Fxla_launch_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fxla_launch_util_test.cc?ref=5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
            "patch": "@@ -207,7 +207,6 @@ class PjRtExecutionUtilTest : public OpsTestBase {\n         &executable_args, /*owned_args=*/{}, &non_donatable_input_indices));\n \n     xla::ExecuteOptions exe_options;\n-    exe_options.arguments_are_tupled = false;\n \n     // TODO(b/257548614): currently PJRT is compiled as portable (num_replica =\n     // 1 and num_partition = 1). Support multiple partitions case.\n@@ -519,7 +518,6 @@ TEST_F(PjRtExecutionUtilTest, PopulateCtxOutputsResourceUpdates) {\n TEST(XlaLaunchUtilTest, GetPjRtExecuteOptions) {\n   xla::ExecuteOptions options =\n       GetPjRtExecuteOptions(DeviceType(DEVICE_GPU), {});\n-  EXPECT_FALSE(options.arguments_are_tupled);\n   EXPECT_FALSE(options.strict_shape_checking);\n   EXPECT_TRUE(options.use_major_to_minor_data_layout_for_callbacks);\n }"
        },
        {
            "sha": "92fd83a628bf4491396b1d3d6e6fced02a8ce57a",
            "filename": "third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_wrapper_impl.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_wrapper_impl.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_wrapper_impl.cc?ref=5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
            "patch": "@@ -1817,7 +1817,6 @@ PJRT_Error* PJRT_LoadedExecutable_Execute(\n     options.call_location = std::string(args->options->call_location);\n   }\n   options.strict_shape_checking = true;\n-  options.arguments_are_tupled = false;\n   options.context = args->options->context\n                         ? args->options->context->execute_context.get()\n                         : nullptr;"
        },
        {
            "sha": "196d08f54d822712cb3f217c94f4f376c1310055",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc?ref=5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
            "patch": "@@ -1369,20 +1369,6 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n   CHECK_EQ(device->process_index(), client_->process_index());\n \n   // Handle inputs.\n-  if (options.arguments_are_tupled) {\n-    if (!parameter_is_tupled_arguments_) {\n-      return InvalidArgument(\n-          \"Arguments may only be supplied as a tuple when the executable was \"\n-          \"compiled with a single tupled parameter\");\n-    }\n-    if (argument_handles.size() != 1) {\n-      return InvalidArgument(\n-          \"Option arguments_are_tupled was true but %d buffers were passed to \"\n-          \"execution\",\n-          argument_handles.size());\n-    }\n-  }\n-\n   // `execute_event` indicates whether cpu computation is complete and whether\n   // there was an error.\n   auto execute_event = tsl::MakeConstructedAsyncValueRef<CpuEvent>();\n@@ -1482,7 +1468,7 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n   // Tuplize the inputs if compiler expects a single tuple argument but runtime\n   // gets many inputs that are not yet tupled.\n   tsl::AsyncValueRef<CpuDeviceMemory> tuple_index_table;\n-  if (parameter_is_tupled_arguments_ && !options.arguments_are_tupled) {\n+  if (parameter_is_tupled_arguments_) {\n     absl::InlinedVector<tsl::AsyncValueRef<CpuDeviceMemory>, 4> leaf_buffers;\n     leaf_buffers.reserve(tracked_buffers.size());\n     for (const auto& tracked_buffer : tracked_buffers) {"
        },
        {
            "sha": "ff2507763aa59a73660e18a9c797ed52ef606290",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_executable.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 16,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_executable.cc?ref=5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
            "patch": "@@ -380,20 +380,6 @@ absl::StatusOr<PjRtLoadedExecutable::Result> TfrtGpuExecutable::ExecuteHelper(\n   }\n \n   // Handle inputs.\n-  if (options.arguments_are_tupled) {\n-    if (!parameter_is_tupled_arguments_) {\n-      return InvalidArgument(\n-          \"Arguments may only be supplied as a tuple when the executable was\"\n-          \"compiled with a single tupled parameter\");\n-    }\n-    if (argument_handles.size() != 1) {\n-      return InvalidArgument(\n-          \"Option arguments_are_tupled was true but %d buffers were passed to\"\n-          \"execution\",\n-          argument_handles.size());\n-    }\n-  }\n-\n   // SPMD sharding produces a single executable for multiple partitions.\n   int executable_idx = executables_.size() > 1 ? partition : 0;\n \n@@ -851,7 +837,6 @@ absl::StatusOr<PjRtLoadedExecutable::Result> TfrtGpuExecutable::ExecuteHelper(\n        execute_fn(std::move(execute_fn)), input_deps(std::move(input_deps)),\n        parameter_shapes(on_device_executable_parameter_shapes_[executable_idx]),\n        parameter_is_tupled_arguments(parameter_is_tupled_arguments_),\n-       arguments_are_tupled(options.arguments_are_tupled),\n        input_buffer_sizes_in_bytes(\n            input_buffer_sizes_in_bytes_[executable_idx])]() mutable {\n         tsl::profiler::TraceMeConsumer activity(\n@@ -892,7 +877,7 @@ absl::StatusOr<PjRtLoadedExecutable::Result> TfrtGpuExecutable::ExecuteHelper(\n         }\n \n         std::vector<ExecutionInput> inputs;\n-        if (parameter_is_tupled_arguments && !arguments_are_tupled) {\n+        if (parameter_is_tupled_arguments) {\n           inputs.emplace_back(\n               ShapeTree<MaybeOwningDeviceMemory>(&parameter_shapes->front()));\n           ExecutionInput& input = inputs.back();"
        },
        {
            "sha": "e68c8db311787c9ea67394481672ea1076b3aacc",
            "filename": "third_party/xla/xla/pjrt/interpreter/interpreter_client.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Finterpreter%2Finterpreter_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Finterpreter%2Finterpreter_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Finterpreter%2Finterpreter_client.cc?ref=5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
            "patch": "@@ -122,7 +122,7 @@ absl::StatusOr<std::tuple<std::vector<Literal*>, std::unique_ptr<Literal>>>\n ExtractInterpreterInputLiteralsFromBuffers(\n     const absl::Span<PjRtBuffer* const> buffers,\n     const HloComputation& entry_computation,\n-    const bool parameter_is_tupled_arguments, const bool arguments_are_tupled) {\n+    const bool parameter_is_tupled_arguments) {\n   std::vector<Literal*> literals;\n   for (PjRtBuffer* const buffer : buffers) {\n     InterpreterLiteralWrapperBuffer* interpreter_buffer =\n@@ -135,7 +135,7 @@ ExtractInterpreterInputLiteralsFromBuffers(\n   }\n \n   // Return early if arguments don't need to be re-tupled.\n-  if (!parameter_is_tupled_arguments || arguments_are_tupled) {\n+  if (!parameter_is_tupled_arguments) {\n     return std::make_tuple(std::move(literals), nullptr);\n   }\n \n@@ -248,8 +248,7 @@ InterpreterLoadedExecutable::ExecuteSharded(\n   TF_ASSIGN_OR_RETURN(const auto literals_and_storage,\n                       ExtractInterpreterInputLiteralsFromBuffers(\n                           argument_handles, computation,\n-                          compile_options_.parameter_is_tupled_arguments,\n-                          options.arguments_are_tupled));\n+                          compile_options_.parameter_is_tupled_arguments));\n   const absl::Span<const Literal* const> literals =\n       std::get<0>(literals_and_storage);\n   if (computation.num_parameters() != literals.size()) {"
        },
        {
            "sha": "a315ecea6c0cc762a075688274746863720eecec",
            "filename": "third_party/xla/xla/pjrt/pjrt_executable.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.cc?ref=5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
            "patch": "@@ -148,7 +148,7 @@ MultiSliceConfig::~MultiSliceConfig() = default;\n absl::StatusOr<ExecuteOptionsProto> ExecuteOptions::ToProto() const {\n   ExecuteOptionsProto proto;\n \n-  proto.set_arguments_are_tupled(arguments_are_tupled);\n+  proto.set_arguments_are_tupled(false);\n   proto.set_untuple_result(untuple_result);\n   proto.set_launch_id(launch_id);\n   if (context != nullptr) {\n@@ -197,7 +197,6 @@ absl::StatusOr<ExecuteOptions> ExecuteOptions::FromProto(\n     const ExecuteOptionsProto& proto) {\n   ExecuteOptions options;\n \n-  options.arguments_are_tupled = proto.arguments_are_tupled();\n   options.untuple_result = proto.untuple_result();\n   options.launch_id = proto.launch_id();\n   options.strict_shape_checking = proto.strict_shape_checking();"
        },
        {
            "sha": "f5c761714b521f4326660fe1b46beef270981be4",
            "filename": "third_party/xla/xla/pjrt/pjrt_executable.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.h?ref=5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
            "patch": "@@ -218,7 +218,8 @@ struct ExecuteOptions {\n   // If true, the client must pass a single PjRtBuffer which contains all of\n   // the arguments as a single XLA tuple, otherwise each argument must be\n   // passed in its own PjRtBuffer. May only be true if the executable was\n-  // compiled with parameter_is_tupled_arguments==true.\n+  // compiled with parameter_is_tupled_arguments==true. This field is\n+  // deprecated.\n   bool arguments_are_tupled = false;\n   // TODO(b/430587318): Remove this deprecated field.\n   bool untuple_result = true;"
        },
        {
            "sha": "05a352e3c1852875013f1bf9a59639b086b44079",
            "filename": "third_party/xla/xla/pjrt/pjrt_executable_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable_test.cc?ref=5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
            "patch": "@@ -75,7 +75,6 @@ TEST(CompileOptionsTest, Defaults) {\n \n TEST(ExecuteOptionsTest, Serialization) {\n   ExecuteOptions src;\n-  src.arguments_are_tupled = true;\n   src.launch_id = 1234;\n   src.strict_shape_checking = true;\n   src.execution_mode = ExecuteOptions::ExecutionMode::kAsynchronous;"
        },
        {
            "sha": "f5729586901f203ef90dc3ebe4ae8249804dfdd6",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 15,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
            "patch": "@@ -1370,7 +1370,7 @@ PjRtStreamExecutorLoadedExecutable::MakeExecutionInputsAndWaitForEvents(\n   // Lift tuple_write_event outside the conditional so that the event it\n   // returns is not destroyed until after the loop below that waits on events.\n   BufferSequencingEventRef tuple_write_event;\n-  if (parameter_is_tupled_arguments_ && !options.arguments_are_tupled) {\n+  if (parameter_is_tupled_arguments_) {\n     TF_ASSIGN_OR_RETURN(\n         auto tuple_handle,\n         MakeTupleHelper(client_, device_state, options.strict_shape_checking,\n@@ -1784,20 +1784,6 @@ PjRtStreamExecutorLoadedExecutable::EnqueueExecution(\n                           &events);\n   }\n \n-  if (options.arguments_are_tupled) {\n-    if (!parameter_is_tupled_arguments_) {\n-      return InvalidArgument(\n-          \"Arguments may only be supplied as a tuple when the executable was \"\n-          \"compiled with a single tupled parameter\");\n-    }\n-    if (argument_handles.size() != 1) {\n-      return InvalidArgument(\n-          \"Option arguments_are_tupled was true but %d buffers were passed to \"\n-          \"execution\",\n-          argument_handles.size());\n-    }\n-  }\n-\n   TF_ASSIGN_OR_RETURN(\n       std::vector<ShapeTree<PjRtStreamExecutorExecutionInput>> execution_inputs,\n       MakeExecutionInputsAndWaitForEvents("
        },
        {
            "sha": "10fc35eb824671f2a24e6a14fb56b89a53c42889",
            "filename": "third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 10,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Ffunctional_hlo_runner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5b3c27043e478fe6b6f82a22ba3d567fe97e4766/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Ffunctional_hlo_runner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Ffunctional_hlo_runner.cc?ref=5b3c27043e478fe6b6f82a22ba3d567fe97e4766",
            "patch": "@@ -111,20 +111,11 @@ absl::Span<PjRtDevice* const> GetLocalDevices(const PjRtClient& client) {\n //\n // Case 1: the HLO module is compiled with\n // CompileOptions::parameter_is_tupled_arguments = true\n-// and the HLO module is executed with\n-// ExecuteOptions::arguments_are_tupled = false.\n // This enables PjRtClient::Execute to assemble the tupled arguments from\n // a flat list of buffers.\n //\n // Case 2: the HLO module is compiled with\n // CompileOptions::parameter_is_tupled_arguments = false\n-// and the HLO module is executed with\n-// ExecuteOptions::arguments_are_tupled = false.\n-//\n-// Case 3: the HLO module is compiled with\n-// CompileOptions::parameter_is_tupled_arguments = false\n-// and the HLO module is executed with\n-// ExecuteOptions::arguments_are_tupled = false.\n // We will create new on-device buffers for each repeated execution.\n \n enum class ParameterType {\n@@ -571,7 +562,6 @@ absl::StatusOr<PerDeviceLiteralVecType> RunInternal(\n   };\n \n   std::vector<std::vector<std::unique_ptr<PjRtBuffer>>> output_buffers;\n-  execute_options.arguments_are_tupled = false;\n   std::optional<std::vector<Future<>>> futures;\n   futures.emplace();\n   std::vector<std::vector<std::unique_ptr<PjRtBuffer>>> device_buffers;"
        }
    ],
    "stats": {
        "total": 77,
        "additions": 9,
        "deletions": 68
    }
}