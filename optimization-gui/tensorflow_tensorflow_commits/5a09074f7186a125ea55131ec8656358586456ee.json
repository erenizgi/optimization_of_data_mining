{
    "author": "sohaibiftikhar",
    "message": "[XLA:GPU]: Fix OptimizedSubByteAllGatherOutputIsCorrect test in e2e tests\n\nFor some reason the CI did not break on submission of this test.\nIts possible due to some race with the refactoring which was submitted a day\nearlier but its unclear to me why.\n\nPiperOrigin-RevId: 816167717",
    "sha": "5a09074f7186a125ea55131ec8656358586456ee",
    "files": [
        {
            "sha": "90181b4cbe4be15a4a48c254291c6c080c52db6a",
            "filename": "third_party/xla/xla/tests/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5a09074f7186a125ea55131ec8656358586456ee/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5a09074f7186a125ea55131ec8656358586456ee/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2FBUILD?ref=5a09074f7186a125ea55131ec8656358586456ee",
            "patch": "@@ -2798,6 +2798,7 @@ xla_test(\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service:hlo_runner\",\n         \"//xla/service:hlo_runner_interface\",\n+        \"//xla/service:pattern_matcher\",\n         \"//xla/service:platform_util\",\n         \"//xla/service/gpu:backend_configs_cc\",\n         \"//xla/service/gpu:gpu_memory_space_assignment\","
        },
        {
            "sha": "7063a5ac2f8f4867c8dfa6e83744ac8285a85c87",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 16,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5a09074f7186a125ea55131ec8656358586456ee/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5a09074f7186a125ea55131ec8656358586456ee/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc?ref=5a09074f7186a125ea55131ec8656358586456ee",
            "patch": "@@ -57,6 +57,7 @@ limitations under the License.\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/service/hlo_runner.h\"\n #include \"xla/service/hlo_runner_interface.h\"\n+#include \"xla/service/pattern_matcher.h\"\n #include \"xla/service/platform_util.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.h\"\n@@ -4422,28 +4423,31 @@ TEST_P(AllReduceTest, AsyncAllReduce_8GPUs_2ReplicasPerGroup) {\n \n TEST_F(CollectiveOpsTestE2E, OptimizedSubByteAllGatherOutputIsCorrect) {\n   constexpr int kNumReplicas = 2;\n-  if (test_runner().device_count() < kNumReplicas) {\n-    GTEST_SKIP() << \"The test requires at least \" << kNumReplicas\n-                 << \" devices.\";\n-  }\n+  ASSERT_GE(hlo_runner_->device_count(), kNumReplicas)\n+      << \"Test requires at least \" << kNumReplicas << \" devices (\"\n+      << hlo_runner_->device_count() << \" available)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto unoptimized_module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+    HloModule m, replica_count=2\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto module, GetOptimizedModule(\n-                                           R\"(\n-HloModule m, replica_count=2\n+    e {\n+      a = s4[2,4]{1,0:E(4)} constant({{0,1,2,3},{4,5,5,4}})\n+      b = s4[4,4]{1,0:E(4)} all-gather(a), dimensions={0}\n+    })\"));\n \n-e {\n-  a = s4[2,4]{1,0:E(4)} constant({{0,1,2,3},{4,5,5,4}})\n-  b = s4[4,4]{1,0:E(4)} all-gather(a), dimensions={0}\n-})\"));\n+  TF_ASSERT_OK_AND_ASSIGN(auto executable, hlo_runner_->CreateExecutable(\n+                                               std::move(unoptimized_module),\n+                                               /*run_hlo_passes=*/true));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(const HloModule* const module,\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n \n   EXPECT_THAT(module->entry_computation()->root_instruction(),\n               GmockMatch(m::Bitcast(m::AllGatherDone().WithShape(S8, {4, 2}))));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> result,\n-      HloTestBase::ExecuteReplicated(std::move(module),\n-                                     absl::Span<const Literal* const>{},\n-                                     kNumReplicas, /*use_threads=*/true));\n+  TF_ASSERT_OK_AND_ASSIGN(std::vector<Literal> result,\n+                          ExecuteReplicated(executable.get(), kNumReplicas));\n \n   const Literal expected_result =\n       LiteralUtil::CreateR2<s4>({{s4(0), s4(1), s4(2), s4(3)},"
        }
    ],
    "stats": {
        "total": 37,
        "additions": 21,
        "deletions": 16
    }
}