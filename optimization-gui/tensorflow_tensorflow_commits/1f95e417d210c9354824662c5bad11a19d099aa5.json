{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Use bufferization rather than unrealized_conversion_cast.\n\nThis will enable us to rewrite the lowering patterns at a higher level if needed and also allow us to reuse buffers. It will also make vectorizing using target length vectors possible e.g vector<8xf32> rather than the current scheme of emitting super-vectors and relying on LLVM to split.\n\nPiperOrigin-RevId: 828448837",
    "sha": "1f95e417d210c9354824662c5bad11a19d099aa5",
    "files": [
        {
            "sha": "2d6324079ca6637a650f8e031ddc7fdf6c3ba42a",
            "filename": "third_party/xla/xla/backends/cpu/codegen/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD?ref=1f95e417d210c9354824662c5bad11a19d099aa5",
            "patch": "@@ -211,6 +211,8 @@ cc_library(\n         \"@llvm-project//mlir:AffineToStandard\",\n         \"@llvm-project//mlir:AffineTransforms\",\n         \"@llvm-project//mlir:ArithDialect\",\n+        \"@llvm-project//mlir:ArithTransforms\",\n+        \"@llvm-project//mlir:BufferizationTransforms\",\n         \"@llvm-project//mlir:BuiltinToLLVMIRTranslation\",\n         \"@llvm-project//mlir:ComplexToStandard\",\n         \"@llvm-project//mlir:ControlFlowDialect\",\n@@ -229,8 +231,10 @@ cc_library(\n         \"@llvm-project//mlir:ReconcileUnrealizedCasts\",\n         \"@llvm-project//mlir:SCFDialect\",\n         \"@llvm-project//mlir:SCFToControlFlow\",\n+        \"@llvm-project//mlir:SCFTransforms\",\n         \"@llvm-project//mlir:Support\",\n         \"@llvm-project//mlir:TensorDialect\",\n+        \"@llvm-project//mlir:TensorTransforms\",\n         \"@llvm-project//mlir:ToLLVMIRTranslation\",\n         \"@llvm-project//mlir:Transforms\",\n         \"@llvm-project//mlir:UBToLLVM\","
        },
        {
            "sha": "d231d5014e929da06188997153d29a998c41e2bc",
            "filename": "third_party/xla/xla/backends/cpu/codegen/emitters/ir/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fir%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fir%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fir%2FBUILD?ref=1f95e417d210c9354824662c5bad11a19d099aa5",
            "patch": "@@ -23,6 +23,7 @@ td_library(\n     deps = [\n         \"@llvm-project//mlir:BuiltinDialectTdFiles\",\n         \"@llvm-project//mlir:OpBaseTdFiles\",\n+        \"@llvm-project//mlir:SideEffectInterfacesTdFiles\",\n     ],\n )\n \n@@ -94,5 +95,6 @@ cc_library(\n         \"@llvm-project//llvm:Support\",\n         \"@llvm-project//mlir:BytecodeOpInterface\",\n         \"@llvm-project//mlir:IR\",\n+        \"@llvm-project//mlir:SideEffectInterfaces\",\n     ],\n )"
        },
        {
            "sha": "972ffff654e9be0b206e163c5a4cf821893913ea",
            "filename": "third_party/xla/xla/backends/cpu/codegen/emitters/ir/xla_cpu_ops.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fir%2Fxla_cpu_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fir%2Fxla_cpu_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fir%2Fxla_cpu_ops.cc?ref=1f95e417d210c9354824662c5bad11a19d099aa5",
            "patch": "@@ -15,7 +15,26 @@ limitations under the License.\n \n #include \"xla/backends/cpu/codegen/emitters/ir/xla_cpu_ops.h\"\n \n+#include \"llvm/ADT/SmallVector.h\"\n #include \"mlir/IR/Builders.h\"  // IWYU pragma: keep\n+#include \"mlir/Interfaces/SideEffectInterfaces.h\"\n+\n+namespace xla::cpu {\n+\n+using EffectsVector = llvm::SmallVectorImpl<\n+    mlir::SideEffects::EffectInstance<mlir::MemoryEffects::Effect>>;\n+\n+void LoadOp::getEffects(EffectsVector& effects) {\n+  effects.emplace_back(mlir::MemoryEffects::Read::get(), &getCallFrameMutable(),\n+                       mlir::SideEffects::DefaultResource::get());\n+}\n+\n+void ExtractWorkgroupIdOp::getEffects(EffectsVector& effects) {\n+  effects.emplace_back(mlir::MemoryEffects::Read::get(), &getCallFrameMutable(),\n+                       mlir::SideEffects::DefaultResource::get());\n+}\n+\n+}  // namespace xla::cpu\n \n #define GET_OP_CLASSES\n #include \"xla/backends/cpu/codegen/emitters/ir/xla_cpu_ops.cc.inc\""
        },
        {
            "sha": "b4581ba1f50560e3a234b3f779338889c0df02f8",
            "filename": "third_party/xla/xla/backends/cpu/codegen/emitters/ir/xla_cpu_ops.td",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fir%2Fxla_cpu_ops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fir%2Fxla_cpu_ops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fir%2Fxla_cpu_ops.td?ref=1f95e417d210c9354824662c5bad11a19d099aa5",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n #define XLA_BACKENDS_CPU_CODEGEN_EMITTERS_IR_XLA_CPU_OPS\n \n include \"mlir/IR/OpBase.td\"\n+include \"mlir/Interfaces/SideEffectInterfaces.td\"\n include \"xla/backends/cpu/codegen/emitters/ir/xla_cpu_dialect.td\"\n include \"xla/backends/cpu/codegen/emitters/ir/xla_cpu_types.td\"\n include \"xla/codegen/emitters/ir/xla_attrs.td\"\n@@ -31,7 +32,8 @@ def TensorOrMemRef : AnyTypeOf<[AnyMemRef, AnyRankedTensor]>;\n // !xla_cpu.load\n //===----------------------------------------------------------------------===//\n \n-def XLACPU_LoadOp : XLACPU_Op<\"load\"> {\n+def XLACPU_LoadOp : XLACPU_Op<\"load\",\n+    [DeclareOpInterfaceMethods<MemoryEffectsOpInterface>]> {\n   let summary = \"Loads a tensor from an XLA:CPU call frame\";\n \n   let description = [{\n@@ -56,7 +58,8 @@ def XLACPU_LoadOp : XLACPU_Op<\"load\"> {\n // !xla_cpu.extract_workgroup_id\n //===----------------------------------------------------------------------===//\n \n-def XLACPU_ExtractWorkgroupIdOp : XLACPU_Op<\"extract_workgroup_id\"> {\n+def XLACPU_ExtractWorkgroupIdOp : XLACPU_Op<\"extract_workgroup_id\",\n+    [DeclareOpInterfaceMethods<MemoryEffectsOpInterface>]> {\n   let summary = \"Extracts the workgroup id from the call frame\";\n \n   let description = [{\n@@ -83,7 +86,7 @@ def XLACPU_ExtractWorkgroupIdOp : XLACPU_Op<\"extract_workgroup_id\"> {\n // !xla_cpu.success\n //===----------------------------------------------------------------------===//\n \n-def XLACPU_SuccessOp : XLACPU_Op<\"success\"> {\n+def XLACPU_SuccessOp : XLACPU_Op<\"success\", [Pure]> {\n   let summary = \"Creates an !xla_cpu.error in the 'success' state.\";\n   let arguments = (ins);\n   let results = (outs XLACPU_Error:$result);"
        },
        {
            "sha": "f1547830784949949e26b1153ce4b12dca810139",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=1f95e417d210c9354824662c5bad11a19d099aa5",
            "patch": "@@ -49,6 +49,9 @@ limitations under the License.\n #include \"mlir/Dialect/Affine/IR/AffineOps.h\"\n #include \"mlir/Dialect/Affine/Passes.h\"\n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/Arith/Transforms/BufferizableOpInterfaceImpl.h\"\n+#include \"mlir/Dialect/Bufferization/Transforms/FuncBufferizableOpInterfaceImpl.h\"\n+#include \"mlir/Dialect/Bufferization/Transforms/Passes.h\"\n #include \"mlir/Dialect/ControlFlow/IR/ControlFlow.h\"\n #include \"mlir/Dialect/DLTI/DLTI.h\"\n #include \"mlir/Dialect/Func/Extensions/InlinerExtension.h\"\n@@ -59,9 +62,13 @@ limitations under the License.\n #include \"mlir/Dialect/Math/IR/Math.h\"\n #include \"mlir/Dialect/MemRef/Transforms/Passes.h\"\n #include \"mlir/Dialect/SCF/IR/SCF.h\"\n+#include \"mlir/Dialect/SCF/Transforms/BufferizableOpInterfaceImpl.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n+#include \"mlir/Dialect/Tensor/Transforms/BufferizableOpInterfaceImpl.h\"\n #include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n+#include \"mlir/Dialect/Vector/Transforms/BufferizableOpInterfaceImpl.h\"\n #include \"mlir/Dialect/Vector/Transforms/Passes.h\"\n+#include \"mlir/Dialect/Vector/Transforms/SubsetOpInterfaceImpl.h\"\n #include \"mlir/Dialect/Vector/Transforms/VectorRewritePatterns.h\"\n #include \"mlir/IR/Attributes.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n@@ -257,6 +264,8 @@ static void AddTiledLoweringPasses(mlir::OpPassManager& pm) {\n       mlir::vector::createLowerVectorMultiReductionPass(\n           mlir::vector::VectorMultiReductionLowering::InnerParallel));\n   pm.addPass(CreateTensorOpsToVectorPass());\n+  pm.addPass(mlir::bufferization::createOneShotBufferizePass());\n+  pm.addPass(mlir::bufferization::createOwnershipBasedBufferDeallocationPass());\n   pm.addPass(cpu::createLowerToLLVMPass());\n   pm.addPass(mlir::createConvertVectorToSCFPass(\n       mlir::VectorTransferToSCFOptions().enableFullUnroll(false)));\n@@ -435,14 +444,26 @@ std::unique_ptr<mlir::MLIRContext> FusionCompiler::CreateContext() {\n                        xla::XlaDialect, xla::xtile::XTileDialect>();\n \n   mlir::DialectRegistry registry;\n+\n   mlir::LLVM::registerInlinerInterface(registry);\n   mlir::func::registerInlinerExtension(registry);\n+\n+  mlir::arith::registerBufferizableOpInterfaceExternalModels(registry);\n+  mlir::bufferization::func_ext::registerBufferizableOpInterfaceExternalModels(\n+      registry);\n+  mlir::scf::registerBufferizableOpInterfaceExternalModels(registry);\n+  mlir::tensor::registerBufferizableOpInterfaceExternalModels(registry);\n+  mlir::vector::registerBufferizableOpInterfaceExternalModels(registry);\n+\n+  mlir::vector::registerSubsetOpInterfaceExternalModels(registry);\n+\n   mlir::registerLLVMDialectTranslation(registry);\n   mlir::registerBuiltinDialectTranslation(registry);\n   mlir::registerConvertMathToLLVMInterface(registry);\n   mlir::registerConvertMemRefToLLVMInterface(registry);\n   mlir::ub::registerConvertUBToLLVMInterface(registry);\n   mlir::vector::registerConvertVectorToLLVMInterface(registry);\n+\n   context->appendDialectRegistry(registry);\n \n   return context;"
        },
        {
            "sha": "f208e43a1dfa469dd1219ecfc2b3992ef26e1f61",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/elemental_tensor_to_vector.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 4,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Felemental_tensor_to_vector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Felemental_tensor_to_vector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Felemental_tensor_to_vector.cc?ref=1f95e417d210c9354824662c5bad11a19d099aa5",
            "patch": "@@ -14,25 +14,29 @@ limitations under the License.\n ==============================================================================*/\n \n #include <cassert>\n+#include <cstdint>\n #include <memory>\n #include <utility>\n \n #include \"llvm/Support/LogicalResult.h\"\n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/Func/Transforms/FuncConversions.h\"\n #include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n+#include \"mlir/IR/Builders.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/PatternMatch.h\"\n #include \"mlir/IR/Types.h\"\n #include \"mlir/IR/Value.h\"\n+#include \"mlir/IR/ValueRange.h\"\n #include \"mlir/IR/Visitors.h\"\n #include \"mlir/Interfaces/DataLayoutInterfaces.h\"\n #include \"mlir/Pass/Pass.h\"\n #include \"mlir/Support/LLVM.h\"\n #include \"mlir/Transforms/DialectConversion.h\"\n+#include \"xla/backends/cpu/codegen/tiled/transforms/lowering_utils.h\"\n #include \"xla/backends/cpu/codegen/tiled/transforms/passes.h\"\n \n namespace xla::cpu {\n@@ -59,6 +63,33 @@ class TensorToVectorTypeConverter : public mlir::TypeConverter {\n       }\n       return mlir::VectorType::get(type.getShape(), type.getElementType());\n     });\n+\n+    addSourceMaterialization([](mlir::OpBuilder& builder,\n+                                mlir::Type result_type, mlir::ValueRange inputs,\n+                                mlir::Location loc) -> mlir::Value {\n+      if (inputs.size() != 1) {\n+        return nullptr;\n+      }\n+\n+      return WriteVectorToTensor(builder, inputs.front());\n+    });\n+\n+    addTargetMaterialization([](mlir::OpBuilder& builder,\n+                                mlir::Type result_type, mlir::ValueRange inputs,\n+                                mlir::Location loc) -> mlir::Value {\n+      if (inputs.size() != 1) {\n+        return nullptr;\n+      }\n+\n+      return ReadTensorToVector(builder, inputs.front());\n+    });\n+  }\n+\n+ private:\n+  static llvm::SmallVector<mlir::Value> MakeZeroIndices(\n+      mlir::OpBuilder& builder, mlir::Location loc, int64_t rank) {\n+    return llvm::SmallVector<mlir::Value>(\n+        rank, mlir::arith::ConstantIndexOp::create(builder, loc, 0));\n   }\n };\n \n@@ -153,10 +184,7 @@ struct ElementalTensorToVectorPass\n     AddArithOpConversions(target, patterns, typeConverter);\n     AddMathOpConversions(target, patterns, typeConverter);\n \n-    mlir::ConversionConfig config;\n-    config.buildMaterializations = false;\n-    if (failed(applyPartialConversion(module, target, std::move(patterns),\n-                                      config))) {\n+    if (failed(applyPartialConversion(module, target, std::move(patterns)))) {\n       signalPassFailure();\n     }\n   }"
        },
        {
            "sha": "c88fd34f242e40774b6f5a6b5f94d29fcb6a3926",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/lowering_utils.cc",
            "status": "modified",
            "additions": 28,
            "deletions": 12,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.cc?ref=1f95e417d210c9354824662c5bad11a19d099aa5",
            "patch": "@@ -15,24 +15,34 @@ limitations under the License.\n \n #include \"xla/backends/cpu/codegen/tiled/transforms/lowering_utils.h\"\n \n+#include <cstdint>\n+#include <optional>\n+\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/MemRef/IR/MemRef.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n #include \"mlir/IR/Builders.h\"\n-#include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/Value.h\"\n #include \"mlir/Support/LLVM.h\"\n \n namespace xla::cpu {\n \n+static llvm::SmallVector<mlir::Value> MakeZeroIndices(mlir::OpBuilder& builder,\n+                                                      mlir::Location loc,\n+                                                      int64_t rank) {\n+  return llvm::SmallVector<mlir::Value>(\n+      rank, mlir::arith::ConstantIndexOp::create(builder, loc, 0));\n+}\n+\n mlir::VectorType GetVectorType(mlir::ShapedType type) {\n   return mlir::VectorType::get(type.getShape(), type.getElementType());\n }\n \n-mlir::TypedValue<mlir::VectorType> CastToVector(mlir::OpBuilder& builder,\n-                                                mlir::Value input) {\n+mlir::TypedValue<mlir::VectorType> ReadTensorToVector(mlir::OpBuilder& builder,\n+                                                      mlir::Value input) {\n   if (input.getType().isIntOrFloat()) {\n     return builder.create<mlir::vector::FromElementsOp>(\n         input.getLoc(), mlir::VectorType::get({}, input.getType()), input);\n@@ -41,29 +51,35 @@ mlir::TypedValue<mlir::VectorType> CastToVector(mlir::OpBuilder& builder,\n   auto input_tensor =\n       mlir::cast<mlir::TypedValue<mlir::RankedTensorType>>(input);\n   auto vector_type = GetVectorType(input_tensor.getType());\n-  auto cast_op = builder.create<mlir::UnrealizedConversionCastOp>(\n-      input.getLoc(), vector_type, input_tensor);\n-  return mlir::cast<mlir::TypedValue<mlir::VectorType>>(cast_op.getResult(0));\n+\n+  return mlir::vector::TransferReadOp::create(\n+      builder, input.getLoc(), vector_type, input_tensor,\n+      MakeZeroIndices(builder, input.getLoc(), vector_type.getRank()),\n+      std::nullopt);\n }\n \n mlir::RankedTensorType GetTensorType(mlir::ShapedType type) {\n   return mlir::RankedTensorType::get(type.getShape(), type.getElementType());\n }\n \n-mlir::TypedValue<mlir::RankedTensorType> CastToTensor(mlir::OpBuilder& builder,\n-                                                      mlir::Value input) {\n+mlir::TypedValue<mlir::RankedTensorType> WriteVectorToTensor(\n+    mlir::OpBuilder& builder, mlir::Value input) {\n   if (input.getType().isIntOrFloat()) {\n     return builder.create<mlir::tensor::FromElementsOp>(\n         input.getLoc(), mlir::RankedTensorType::get({}, input.getType()),\n         input);\n   }\n \n   auto input_vector = mlir::cast<mlir::TypedValue<mlir::VectorType>>(input);\n-  auto tensor_type = GetTensorType(input_vector.getType());\n-  auto cast_op = builder.create<mlir::UnrealizedConversionCastOp>(\n-      input.getLoc(), tensor_type, input_vector);\n+  mlir::VectorType vector_type = input_vector.getType();\n+  auto empty_tensor = mlir::tensor::EmptyOp::create(\n+      builder, input.getLoc(), vector_type.getShape(),\n+      vector_type.getElementType());\n   return mlir::cast<mlir::TypedValue<mlir::RankedTensorType>>(\n-      cast_op.getResult(0));\n+      mlir::vector::TransferWriteOp::create(\n+          builder, input.getLoc(), input, empty_tensor,\n+          MakeZeroIndices(builder, input.getLoc(), vector_type.getRank()))\n+          .getResult());\n }\n \n mlir::TypedValue<mlir::MemRefType> CreateBufferOfShape(mlir::OpBuilder& builder,"
        },
        {
            "sha": "dee0a0a607725d1a95702e2a91a185a6970fcb6d",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/lowering_utils.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.h?ref=1f95e417d210c9354824662c5bad11a19d099aa5",
            "patch": "@@ -32,8 +32,8 @@ mlir::VectorType GetVectorType(mlir::ShapedType tensor_type);\n // vector.from_elements to create a 0D vector.\n // If it is a vector it will be cast to a vector using an unrealized cast op.\n // Any other type will crash.\n-mlir::TypedValue<mlir::VectorType> CastToVector(mlir::OpBuilder& builder,\n-                                                mlir::Value input);\n+mlir::TypedValue<mlir::VectorType> ReadTensorToVector(mlir::OpBuilder& builder,\n+                                                      mlir::Value input);\n \n // Get the tensor type that has the same shape and element type as the vector\n // type.\n@@ -44,8 +44,8 @@ mlir::RankedTensorType GetTensorType(mlir::ShapedType vector_type);\n // tensor.from_elements to create a 0D tensor.\n // If it is a vector it will be cast to a tensor using an unrealized cast op.\n // Any other type will crash.\n-mlir::TypedValue<mlir::RankedTensorType> CastToTensor(mlir::OpBuilder& builder,\n-                                                      mlir::Value input);\n+mlir::TypedValue<mlir::RankedTensorType> WriteVectorToTensor(\n+    mlir::OpBuilder& builder, mlir::Value input);\n \n mlir::TypedValue<mlir::MemRefType> CreateBufferOfShape(mlir::OpBuilder& builder,\n                                                        mlir::Location loc,"
        },
        {
            "sha": "67104b94997bd847a4e9c47fe6ed16a5515b7648",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/shlo_to_vector.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 12,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fshlo_to_vector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fshlo_to_vector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fshlo_to_vector.cc?ref=1f95e417d210c9354824662c5bad11a19d099aa5",
            "patch": "@@ -136,10 +136,10 @@ struct LowerDotGeneral : mlir::OpRewritePattern<mlir::stablehlo::DotGeneralOp> {\n   mlir::LogicalResult matchAndRewrite(\n       mlir::stablehlo::DotGeneralOp op,\n       mlir::PatternRewriter& rewriter) const override {\n-    auto lhs_vector = CastToVector(rewriter, op.getLhs());\n+    auto lhs_vector = ReadTensorToVector(rewriter, op.getLhs());\n     auto lhs_rank = lhs_vector.getType().getRank();\n \n-    auto rhs_vector = CastToVector(rewriter, op.getRhs());\n+    auto rhs_vector = ReadTensorToVector(rewriter, op.getRhs());\n     auto rhs_rank = rhs_vector.getType().getRank();\n \n     // TODO(willfroom): Ensure this is being folded into the accumulator in the\n@@ -184,7 +184,7 @@ struct LowerDotGeneral : mlir::OpRewritePattern<mlir::stablehlo::DotGeneralOp> {\n         op->getLoc(), lhs_vector, rhs_vector, accumulator, indexing_maps,\n         iterator_types);\n \n-    rewriter.replaceOp(op, CastToTensor(rewriter, result));\n+    rewriter.replaceOp(op, WriteVectorToTensor(rewriter, result));\n \n     return mlir::success();\n   }\n@@ -212,13 +212,13 @@ struct LowerTranspose : mlir::OpRewritePattern<mlir::stablehlo::TransposeOp> {\n   mlir::LogicalResult matchAndRewrite(\n       mlir::stablehlo::TransposeOp op,\n       mlir::PatternRewriter& rewriter) const override {\n-    mlir::Value source_vector = CastToVector(rewriter, op.getOperand());\n+    mlir::Value source_vector = ReadTensorToVector(rewriter, op.getOperand());\n \n     mlir::TypedValue<mlir::VectorType> dest_vector =\n         rewriter.create<mlir::vector::TransposeOp>(op->getLoc(), source_vector,\n                                                    op.getPermutation());\n \n-    mlir::Value dest_tensor = CastToTensor(rewriter, dest_vector);\n+    mlir::Value dest_tensor = WriteVectorToTensor(rewriter, dest_vector);\n \n     rewriter.replaceAllUsesWith(op, dest_tensor);\n     return mlir::success();\n@@ -237,7 +237,7 @@ struct LowerReduce : mlir::OpRewritePattern<mlir::stablehlo::ReduceOp> {\n     }\n \n     mlir::TypedValue<mlir::VectorType> source_vector =\n-        CastToVector(rewriter, op.getInputs().front());\n+        ReadTensorToVector(rewriter, op.getInputs().front());\n     mlir::VectorType source_vector_type = source_vector.getType();\n \n     mlir::Value init_value = rewriter.create<mlir::tensor::ExtractOp>(\n@@ -258,7 +258,7 @@ struct LowerReduce : mlir::OpRewritePattern<mlir::stablehlo::ReduceOp> {\n         rewriter, op->getLoc(), result_vector_type, source_vector, init_value,\n         reduction_dims, op.getBody().front());\n \n-    rewriter.replaceOp(op, CastToTensor(rewriter, reduced_vector));\n+    rewriter.replaceOp(op, WriteVectorToTensor(rewriter, reduced_vector));\n \n     return mlir::success();\n   }\n@@ -271,7 +271,7 @@ struct LowerBroadcastInDim\n   mlir::LogicalResult matchAndRewrite(\n       mlir::stablehlo::BroadcastInDimOp op,\n       mlir::PatternRewriter& rewriter) const override {\n-    auto source_vector = CastToVector(rewriter, op.getOperand());\n+    auto source_vector = ReadTensorToVector(rewriter, op.getOperand());\n     auto result_vector_type = GetVectorType(op.getType());\n \n     llvm::ArrayRef<int64_t> source_shape = source_vector.getType().getShape();\n@@ -295,7 +295,7 @@ struct LowerBroadcastInDim\n     mlir::Value broadcast_op = mlir::vector::BroadcastOp::create(\n         rewriter, op->getLoc(), result_vector_type, intermediate_vector);\n \n-    rewriter.replaceOp(op, CastToTensor(rewriter, broadcast_op));\n+    rewriter.replaceOp(op, WriteVectorToTensor(rewriter, broadcast_op));\n     return mlir::success();\n   }\n };\n@@ -306,13 +306,13 @@ struct LowerReshape : mlir::OpRewritePattern<mlir::stablehlo::ReshapeOp> {\n   mlir::LogicalResult matchAndRewrite(\n       mlir::stablehlo::ReshapeOp op,\n       mlir::PatternRewriter& rewriter) const override {\n-    auto source_vector = CastToVector(rewriter, op.getOperand());\n+    auto source_vector = ReadTensorToVector(rewriter, op.getOperand());\n     auto result_vector_type = GetVectorType(op.getType());\n \n     mlir::Value reshaped_vector = mlir::vector::ShapeCastOp::create(\n         rewriter, op->getLoc(), result_vector_type, source_vector);\n \n-    rewriter.replaceOp(op, CastToTensor(rewriter, reshaped_vector));\n+    rewriter.replaceOp(op, WriteVectorToTensor(rewriter, reshaped_vector));\n     return mlir::success();\n   }\n };\n@@ -341,7 +341,7 @@ struct LowerIota : mlir::OpRewritePattern<mlir::stablehlo::IotaOp> {\n         rewriter, op->getLoc(),\n         mlir::DenseElementsAttr::get(result_vector_type, iota_values));\n \n-    rewriter.replaceOp(op, CastToTensor(rewriter, iota_const));\n+    rewriter.replaceOp(op, WriteVectorToTensor(rewriter, iota_const));\n     return mlir::success();\n   }\n };"
        },
        {
            "sha": "daffa5978ffc3c0b7b840abd57a7d739e9a63d45",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tensor_ops_to_vector.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftensor_ops_to_vector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftensor_ops_to_vector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftensor_ops_to_vector.cc?ref=1f95e417d210c9354824662c5bad11a19d099aa5",
            "patch": "@@ -57,8 +57,7 @@ struct LowerFromElements\n     mlir::Value vector_from_elements =\n         rewriter.create<mlir::vector::FromElementsOp>(op.getLoc(), vector_type,\n                                                       op->getOperands());\n-    rewriter.replaceOpWithNewOp<mlir::UnrealizedConversionCastOp>(\n-        op, op.getType(), vector_from_elements);\n+    rewriter.replaceOp(op, WriteVectorToTensor(rewriter, vector_from_elements));\n     return mlir::success();\n   }\n };\n@@ -69,7 +68,7 @@ struct LowerExtract : mlir::OpRewritePattern<mlir::tensor::ExtractOp> {\n   mlir::LogicalResult matchAndRewrite(\n       mlir::tensor::ExtractOp op,\n       mlir::PatternRewriter& rewriter) const override {\n-    mlir::Value vector_input = CastToVector(rewriter, op.getTensor());\n+    mlir::Value vector_input = ReadTensorToVector(rewriter, op.getTensor());\n     llvm::SmallVector<mlir::OpFoldResult> indices(op.getIndices());\n     rewriter.replaceOpWithNewOp<mlir::vector::ExtractOp>(op, vector_input,\n                                                          indices);"
        },
        {
            "sha": "4c3c89e0471292a62c9f73409155a7b020ba0ea2",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/xtile_to_vector.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fxtile_to_vector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f95e417d210c9354824662c5bad11a19d099aa5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fxtile_to_vector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fxtile_to_vector.cc?ref=1f95e417d210c9354824662c5bad11a19d099aa5",
            "patch": "@@ -165,7 +165,7 @@ struct LowerExtractTile : mlir::OpRewritePattern<xtile::ExtractTileOp> {\n         op->getLoc(), vector_type, buffer_subview, zero_index,\n         GetIdentityMap(op), padding, mask, in_bounds);\n \n-    rewriter.replaceOp(op, CastToTensor(builder, vector_value));\n+    rewriter.replaceOp(op, WriteVectorToTensor(builder, vector_value));\n     return mlir::success();\n   }\n };\n@@ -177,7 +177,7 @@ struct LowerInsertTile : mlir::OpRewritePattern<xtile::InsertTileOp> {\n       xtile::InsertTileOp op, mlir::PatternRewriter& rewriter) const override {\n     mlir::ImplicitLocOpBuilder builder(op->getLoc(), rewriter);\n     mlir::TypedValue<mlir::VectorType> vector_tile =\n-        CastToVector(builder, op.getSource());\n+        ReadTensorToVector(builder, op.getSource());\n \n     mlir::TypedValue<mlir::MemRefType> buffer_subview = GetSubView(builder, op);\n "
        }
    ],
    "stats": {
        "total": 172,
        "additions": 132,
        "deletions": 40
    }
}