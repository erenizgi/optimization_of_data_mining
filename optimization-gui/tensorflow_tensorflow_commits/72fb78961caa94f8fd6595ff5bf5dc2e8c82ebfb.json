{
    "author": "jcai19",
    "message": "[XLA][Numerics][HLO Value Tracking] Export HLO original value for more stableHLO ops\n\nPiperOrigin-RevId: 816400565",
    "sha": "72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb",
    "files": [
        {
            "sha": "60a62ac88d6f66f4949b8aacce64dbb1f0b9efea",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/gen_hlo_op_writer.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.cc?ref=72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb",
            "patch": "@@ -215,11 +215,6 @@ static bool OperatorWritersMain(raw_ostream& os, const RecordKeeper& records) {\n         \"mlir::mhlo::CreateOpMetadataFromLocation(\"\n         \"op, lowering_context.frame_index_builder));\\n\\n\";\n \n-  // Create a scoped object to assign original values to generated XLA ops.\n-  os << \"  xla::XlaScopedOriginalValueAssignment \"\n-        \"original_value(lowering_context.builder, \"\n-        \"CreateOriginalValueFromOp(op));\\n\\n\";\n-\n   // Retrieve all the definitions derived from MHLO_Op and sort by record name.\n   for (auto dialect_def : dialect_defs) {\n     for (const auto* def : records.getAllDerivedDefinitions(dialect_def)) {"
        },
        {
            "sha": "20a7a0140269137a6b761081a2b5a147c5b00052",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc?ref=72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb",
            "patch": "@@ -5807,6 +5807,9 @@ LogicalResult ConvertToHloModule::Lower(\n     return failure();\n   }\n \n+  xla::XlaScopedOriginalValueAssignment original_value(\n+      builder, CreateOriginalValueFromOp(inst));\n+\n   *return_value = xla::XlaOp();\n \n   if (succeeded(ExportXlaOperator(inst, {value_lowering, this, builder,"
        },
        {
            "sha": "a0a34a51e452fe40625791dd0c057d2cd223bcde",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/tests/export.mlir",
            "status": "modified",
            "additions": 32,
            "deletions": 7,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fexport.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fexport.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fexport.mlir?ref=72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb",
            "patch": "@@ -3170,12 +3170,37 @@ func.func @main(%input0: tensor<16x16xf32>, %input1: tensor<16x16xi32>) {\n }\n \n // -----\n+\n+// CHECK: HloModule\n+// CHECK: ENTRY\n+// CHECK-LITERAL:: f32[192] parameter(0), origin={{\"a\"}}\n+\n+module {\n+  func.func @main(%arg0: tensor<192xf32> {mhlo.original_value = \"{{\\22a\\22}}\"}) -> tensor<192xf32> {\n+    return %arg0 : tensor<192xf32>\n+  }\n+}\n+\n+// -----\n+\n // CHECK: HloModule\n // CHECK: ENTRY\n-// CHECK: %[[ARG0:.*]] = f32[192] parameter(0), origin={{[{][{]}}\"a\"{{[}][}]}}\n-// CHECK: ROOT %[[RESULT:.*]] = f32[1,17,17,192] broadcast(%[[ARG0]]), dimensions={3}, origin={{[{][{]}}\"broadcast.2342\"{{[}][}]}}\n+// CHECK-LITERAL: ROOT %constant.1 = s32[] constant(0), origin={{\"constant.5\"}}\n \n-func.func @main(%arg0: tensor<192xf32> {mhlo.original_value = \"{{\\22a\\22}}\"}) -> tensor<1x17x17x192xf32> {\n+module {\n+  func.func @main() -> tensor<i32> {\n+    %0 = mhlo.constant {mhlo.original_value = \"{{\\22constant.5\\22}}\"} dense<0> : tensor<i32>\n+    return %0 : tensor<i32>\n+  }\n+}\n+\n+// -----\n+// CHECK: HloModule\n+// CHECK: ENTRY\n+// CHECK: %[[ARG0:.*]] = f32[192] parameter(0)\n+// CHECK-LITERAL: ROOT %[[RESULT:.*]] = f32[1,17,17,192] broadcast(%[[ARG0]]), dimensions={3}, origin={{\"broadcast.2342\"}}\n+\n+func.func @main(%arg0: tensor<192xf32>) -> tensor<1x17x17x192xf32> {\n   %0 = \"mhlo.broadcast_in_dim\"(%arg0) <{broadcast_dimensions = dense<3> : tensor<1xi64>}> {mhlo.original_value = \"{{\\22broadcast.2342\\22}}\"} : (tensor<192xf32>) -> tensor<1x17x17x192xf32>\n   return %0 : tensor<1x17x17x192xf32>\n }\n@@ -3184,10 +3209,10 @@ func.func @main(%arg0: tensor<192xf32> {mhlo.original_value = \"{{\\22a\\22}}\"}) ->\n \n // CHECK: HloModule\n // CHECK: ENTRY\n-// CHECK:  %Arg_0.1 = f32[10] parameter(0)\n-// CHECK:  %[[TOPK:.*]] = (f32[8], s32[8]) topk(%Arg_0.1), k=8, largest=true, origin={({\"t\" {0}{{[}]}}, {\"t\" {1}{{[}]}})}\n-// CHECK:  ROOT %[[GTE0:.*]] = f32[8] get-tuple-element(%[[TOPK]]), index=0, origin={{[{][{]}}\"t\" {0}{{[}][}]}}\n-// CHECK:  %[[GTE1:.*]] = s32[8] get-tuple-element(%[[TOPK]]), index=1, origin={{[{][{]}}\"t\" {1}{{[}][}]}}\n+// CHECK:  %[[ARG0:.*]] = f32[10] parameter(0)\n+// CHECK-LITERAL:  %[[TOPK:.*]] = (f32[8], s32[8]) topk(%[[ARG0]]), k=8, largest=true, origin={({\"t\" {0}}, {\"t\" {1}})}\n+// CHECK-LITERAL:  ROOT %[[GTE0:.*]] = f32[8] get-tuple-element(%[[TOPK]]), index=0, origin={{\"t\" {0}}}\n+// CHECK-LITERAL:  %[[GTE1:.*]] = s32[8] get-tuple-element(%[[TOPK]]), index=1, origin={{\"t\" {1}}}\n func.func @main(%arg0: tensor<10xf32>) -> tensor<8xf32> {\n   %0:2 = mhlo.topk(%arg0, k=8, largest=true) {mhlo.original_value=\"{({\\22t\\22 {0}}, {\\22t\\22 {1}})}\"} : tensor<10xf32> -> (tensor<8xf32>, tensor<8xi32>)\n   return %0#0 : tensor<8xf32>"
        },
        {
            "sha": "bb4a1ab6deb7dd1070c82b48520276b2f85b406a",
            "filename": "third_party/xla/xla/hlo/translate/tests/stablehlo.mlir",
            "status": "modified",
            "additions": 31,
            "deletions": 7,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Ftests%2Fstablehlo.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Ftests%2Fstablehlo.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Ftests%2Fstablehlo.mlir?ref=72fb78961caa94f8fd6595ff5bf5dc2e8c82ebfb",
            "patch": "@@ -1951,13 +1951,37 @@ module {\n // -----\n \n // CHECK-LABEL: HloModule main\n+// CHECK: ENTRY\n+// CHECK-LITERAL:: f32[192] parameter(0), origin={{\"a\"}}\n+\n+module {\n+  func.func @main(%arg0: tensor<192xf32> {mhlo.original_value = \"{{\\22a\\22}}\"}) -> tensor<192xf32> {\n+    return %arg0 : tensor<192xf32>\n+  }\n+}\n \n+// -----\n+\n+// CHECK-LABEL: HloModule main\n+// CHECK: ENTRY\n+// CHECK-LITERAL: ROOT %constant.1 = s32[] constant(0), origin={{\"constant.5\"}}\n+\n+module {\n+  func.func @main() -> tensor<i32> {\n+    %0 = stablehlo.constant {mhlo.original_value = \"{{\\22constant.5\\22}}\"} dense<0> : tensor<i32>\n+    return %0 : tensor<i32>\n+  }\n+}\n+\n+// -----\n+\n+// CHECK-LABEL: HloModule main\n // CHECK: ENTRY\n-// CHECK: %[[ARG0:.*]] = f32[192] parameter(0), origin={{[{][{]}}\"a\"{{[}][}]}}\n-// CHECK: ROOT %[[RESULT:.*]] = f32[1,17,17,192] broadcast(%[[ARG0]]), dimensions={3}, origin={{[{][{]}}\"broadcast.2342\"{{[}][}]}}\n+// CHECK: %[[ARG0:.*]] = f32[192] parameter(0)\n+// CHECK-LITERAL: ROOT %[[RESULT:.*]] = f32[1,17,17,192] broadcast(%[[ARG0]]), dimensions={3}, origin={{\"broadcast.2342\"}}\n \n module {\n-  func.func @main(%arg0: tensor<192xf32> {mhlo.original_value = \"{{\\22a\\22}}\"}) -> tensor<1x17x17x192xf32> {\n+  func.func @main(%arg0: tensor<192xf32>) -> tensor<1x17x17x192xf32> {\n     %0 = stablehlo.broadcast_in_dim %arg0, dims = [3] {mhlo.original_value = \"{{\\22broadcast.2342\\22}}\"} : (tensor<192xf32>) -> tensor<1x17x17x192xf32>\n     return %0 : tensor<1x17x17x192xf32>\n   }\n@@ -1967,10 +1991,10 @@ module {\n \n // CHECK-LABEL: HloModule main\n // CHECK: ENTRY\n-// CHECK:  %Arg_0.1 = f32[10] parameter(0)\n-// CHECK:  %[[TOPK:.*]] = (f32[8], s32[8]) topk(%Arg_0.1), k=8, largest=true, origin={({\"t\" {0}{{[}]}}, {\"t\" {1}{{[}]}})}\n-// CHECK:  ROOT %[[GTE0:.*]] = f32[8] get-tuple-element(%[[TOPK]]), index=0, origin={{[{][{]}}\"t\" {0}{{[}][}]}}\n-// CHECK:  %[[GTE1:.*]] = s32[8] get-tuple-element(%[[TOPK]]), index=1, origin={{[{][{]}}\"t\" {1}{{[}][}]}}\n+// CHECK:  %[[ARG0:.*]] = f32[10] parameter(0)\n+// CHECK-LITERAL:  %[[TOPK:.*]] = (f32[8], s32[8]) topk(%[[ARG0]]), k=8, largest=true, origin={({\"t\" {0}}, {\"t\" {1}})}\n+// CHECK-LITERAL:  ROOT %[[GTE0:.*]] = f32[8] get-tuple-element(%[[TOPK]]), index=0, origin={{\"t\" {0}}}\n+// CHECK-LITERAL:  %[[GTE1:.*]] = s32[8] get-tuple-element(%[[TOPK]]), index=1, origin={{\"t\" {1}}}\n func.func @main(%arg0: tensor<10xf32>) -> tensor<8xf32> {\n   %0:2 = mhlo.topk(%arg0, k=8, largest=true) {mhlo.original_value=\"{({\\22t\\22 {0}}, {\\22t\\22 {1}})}\"} : tensor<10xf32> -> (tensor<8xf32>, tensor<8xi32>)\n   return %0#0 : tensor<8xf32>"
        }
    ],
    "stats": {
        "total": 85,
        "additions": 66,
        "deletions": 19
    }
}