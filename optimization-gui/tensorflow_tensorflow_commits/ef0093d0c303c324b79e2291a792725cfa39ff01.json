{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 809705748",
    "sha": "ef0093d0c303c324b79e2291a792725cfa39ff01",
    "files": [
        {
            "sha": "6fb2d2044b2d3760730fe2b8023cb94982d2d12a",
            "filename": "tensorflow/c/experimental/filesystem/plugins/gcs/expiring_lru_cache.h",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef0093d0c303c324b79e2291a792725cfa39ff01/tensorflow%2Fc%2Fexperimental%2Ffilesystem%2Fplugins%2Fgcs%2Fexpiring_lru_cache.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef0093d0c303c324b79e2291a792725cfa39ff01/tensorflow%2Fc%2Fexperimental%2Ffilesystem%2Fplugins%2Fgcs%2Fexpiring_lru_cache.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fc%2Fexperimental%2Ffilesystem%2Fplugins%2Fgcs%2Fexpiring_lru_cache.h?ref=ef0093d0c303c324b79e2291a792725cfa39ff01",
            "patch": "@@ -51,15 +51,15 @@ class ExpiringLRUCache {\n     if (max_age_ == 0) {\n       return;\n     }\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     InsertLocked(key, value);\n   }\n \n   // Delete the entry with key `key`. Return true if the entry was found for\n   // `key`, false if the entry was not found. In both cases, there is no entry\n   // with key `key` existed after the call.\n   bool Delete(const std::string& key) {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     return DeleteLocked(key);\n   }\n \n@@ -70,7 +70,7 @@ class ExpiringLRUCache {\n     if (max_age_ == 0) {\n       return false;\n     }\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     return LookupLocked(key, value);\n   }\n \n@@ -90,7 +90,7 @@ class ExpiringLRUCache {\n     // is okay, as stat requests are typically fast, and concurrent requests are\n     // often for the same file. Future work can split this up into one lock per\n     // key if this proves to be a significant performance bottleneck.\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     if (LookupLocked(key, value)) {\n       return TF_SetStatus(status, TF_OK, \"\");\n     }\n@@ -102,7 +102,7 @@ class ExpiringLRUCache {\n \n   /// Clear the cache.\n   void Clear() {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     cache_.clear();\n     lru_list_.clear();\n   }"
        },
        {
            "sha": "c92a6dfbd3890f884a40b5de6e638d49b93e4fa9",
            "filename": "tensorflow/c/experimental/filesystem/plugins/gcs/ram_file_block_cache.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 12,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef0093d0c303c324b79e2291a792725cfa39ff01/tensorflow%2Fc%2Fexperimental%2Ffilesystem%2Fplugins%2Fgcs%2Fram_file_block_cache.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef0093d0c303c324b79e2291a792725cfa39ff01/tensorflow%2Fc%2Fexperimental%2Ffilesystem%2Fplugins%2Fgcs%2Fram_file_block_cache.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fc%2Fexperimental%2Ffilesystem%2Fplugins%2Fgcs%2Fram_file_block_cache.cc?ref=ef0093d0c303c324b79e2291a792725cfa39ff01",
            "patch": "@@ -32,7 +32,7 @@ limitations under the License.\n namespace tf_gcs_filesystem {\n \n bool RamFileBlockCache::BlockNotStale(const std::shared_ptr<Block>& block) {\n-  absl::MutexLock l(&block->mu);\n+  absl::MutexLock l(block->mu);\n   if (block->state != FetchState::FINISHED) {\n     return true;  // No need to check for staleness.\n   }\n@@ -42,7 +42,7 @@ bool RamFileBlockCache::BlockNotStale(const std::shared_ptr<Block>& block) {\n \n std::shared_ptr<RamFileBlockCache::Block> RamFileBlockCache::Lookup(\n     const Key& key) {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   auto entry = block_map_.find(key);\n   if (entry != block_map_.end()) {\n     if (BlockNotStale(entry->second)) {\n@@ -76,7 +76,7 @@ void RamFileBlockCache::Trim() {\n void RamFileBlockCache::UpdateLRU(const Key& key,\n                                   const std::shared_ptr<Block>& block,\n                                   TF_Status* status) {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   if (block->timestamp == 0) {\n     // The block was evicted from another thread. Allow it to remain evicted.\n     return TF_SetStatus(status, TF_OK, \"\");\n@@ -113,7 +113,7 @@ void RamFileBlockCache::MaybeFetch(const Key& key,\n     // Perform this action in a cleanup callback to avoid locking mu_ after\n     // locking block->mu.\n     if (downloaded_block) {\n-      absl::MutexLock l(&mu_);\n+      absl::MutexLock l(mu_);\n       // Do not update state if the block is already to be evicted.\n       if (block->timestamp != 0) {\n         // Use capacity() instead of size() to account for all  memory\n@@ -129,21 +129,21 @@ void RamFileBlockCache::MaybeFetch(const Key& key,\n   });\n   // Loop until either block content is successfully fetched, or our request\n   // encounters an error.\n-  absl::MutexLock l(&block->mu);\n+  absl::MutexLock l(block->mu);\n   TF_SetStatus(status, TF_OK, \"\");\n   while (true) {\n     switch (block->state) {\n       case FetchState::ERROR:\n         // TF_FALLTHROUGH_INTENDED\n       case FetchState::CREATED:\n         block->state = FetchState::FETCHING;\n-        block->mu.Unlock();  // Release the lock while making the API call.\n+        block->mu.unlock();  // Release the lock while making the API call.\n         block->data.clear();\n         block->data.resize(block_size_, 0);\n         int64_t bytes_transferred;\n         bytes_transferred = block_fetcher_(key.first, key.second, block_size_,\n                                            block->data.data(), status);\n-        block->mu.Lock();  // Reacquire the lock immediately afterwards\n+        block->mu.lock();  // Reacquire the lock immediately afterwards\n         if (TF_GetCode(status) == TF_OK) {\n           block->data.resize(bytes_transferred, 0);\n           // Shrink the data capacity to the actual size used.\n@@ -242,7 +242,7 @@ int64_t RamFileBlockCache::Read(const std::string& filename, size_t offset,\n \n bool RamFileBlockCache::ValidateAndUpdateFileSignature(\n     const std::string& filename, int64_t file_signature) {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   auto it = file_signature_map_.find(filename);\n   if (it != file_signature_map_.end()) {\n     if (it->second == file_signature) {\n@@ -258,14 +258,14 @@ bool RamFileBlockCache::ValidateAndUpdateFileSignature(\n }\n \n size_t RamFileBlockCache::CacheSize() const {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   return cache_size_;\n }\n \n void RamFileBlockCache::Prune() {\n   while (!stop_pruning_thread_.WaitForNotificationWithTimeout(\n       absl::Microseconds(1000000))) {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     uint64_t now = timer_seconds_();\n     while (!lra_list_.empty()) {\n       auto it = block_map_.find(lra_list_.back());\n@@ -281,15 +281,15 @@ void RamFileBlockCache::Prune() {\n }\n \n void RamFileBlockCache::Flush() {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   block_map_.clear();\n   lru_list_.clear();\n   lra_list_.clear();\n   cache_size_ = 0;\n }\n \n void RamFileBlockCache::RemoveFile(const std::string& filename) {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   RemoveFile_Locked(filename);\n }\n "
        }
    ],
    "stats": {
        "total": 34,
        "additions": 17,
        "deletions": 17
    }
}