{
    "author": "alexander-shaposhnikov",
    "message": "Add initial bits for matching xnnpack reductions.\n\nPiperOrigin-RevId: 801068888",
    "sha": "081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2",
    "files": [
        {
            "sha": "bee65709ed3140cea1e5b47679ddbf157a402b36",
            "filename": "third_party/xla/xla/backends/cpu/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD?ref=081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2",
            "patch": "@@ -102,6 +102,7 @@ cc_library(\n         \"//xla/backends/cpu:xnn_support\",\n         \"//xla/backends/cpu/codegen:target_machine_features\",\n         \"//xla/hlo/ir:hlo\",\n+        \"@com_google_absl//absl/base:no_destructor\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\","
        },
        {
            "sha": "f433053d478022ad239e35b31a57a699d27570ba",
            "filename": "third_party/xla/xla/backends/cpu/transforms/dot_library_rewriter.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc?ref=081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2",
            "patch": "@@ -288,14 +288,17 @@ absl::Status DotLibraryRewriter::FuseNeighbors(HloFusionInstruction* fusion,\n absl::StatusOr<bool> DotLibraryRewriter::ProcessComputation(\n     HloComputation* computation) {\n   // Construct a list of instructions that can start a library fusion, starting\n-  // from the root up to the top. Prioritize dot ops over element-wise ops.\n+  // from the root up to the top. Prioritize dot and reduce ops over\n+  // element-wise ops.\n   // TODO(penporn): Use priority queue when we have a cost model.\n   std::vector<HloInstruction*> fusion_starters;\n   std::vector<HloInstruction*> eltwise_ops;\n   auto instructions = computation->MakeInstructionPostOrder();\n   for (auto it = instructions.rbegin(); it != instructions.rend(); ++it) {\n     if (fuse_dot_ && (*it)->opcode() == HloOpcode::kDot) {\n       fusion_starters.push_back(*it);\n+    } else if (fuse_reduce_ && (*it)->opcode() == HloOpcode::kReduce) {\n+      fusion_starters.push_back(*it);\n     } else if (fuse_eltwise_ && (*it)->IsElementwise()) {\n       eltwise_ops.push_back(*it);\n     }"
        },
        {
            "sha": "833d3008f88b87cec2968fd777cf06ebf5bf29fd",
            "filename": "third_party/xla/xla/backends/cpu/transforms/dot_library_rewriter.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.h?ref=081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2",
            "patch": "@@ -77,6 +77,8 @@ class DotLibraryRewriter : public HloModulePass {\n     // Check if any library supports each of the fusion types.\n     fuse_dot_ =\n         absl::c_any_of(libs_, [](const auto& lib) { return lib->fuse_dot(); });\n+    fuse_reduce_ = absl::c_any_of(\n+        libs_, [](const auto& lib) { return lib->fuse_reduce(); });\n     fuse_eltwise_ = absl::c_any_of(\n         libs_, [](const auto& lib) { return lib->fuse_eltwise(); });\n   }\n@@ -125,6 +127,7 @@ class DotLibraryRewriter : public HloModulePass {\n   absl::flat_hash_set<HloOpcode> supported_ops_;\n   absl::flat_hash_set<HloInstruction*> fused_;\n   bool fuse_dot_ = false;\n+  bool fuse_reduce_ = false;\n   bool fuse_eltwise_ = false;\n };\n "
        },
        {
            "sha": "c9266707634fb2535a908d60151eb1d3be4ae6c6",
            "filename": "third_party/xla/xla/backends/cpu/transforms/dot_library_rewriter_test.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 4,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter_test.cc?ref=081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2",
            "patch": "@@ -95,6 +95,9 @@ class CpuLibraryTest : public TargetMachineTestBase {\n     if (spec.fusion_mode == \"greedy\") {\n       fusion_types.Add(DebugOptions::LIBRARY_FUSION_TYPE_ELTWISE);\n     }\n+    if (spec.fusion_mode == \"reduce\") {\n+      fusion_types.Add(DebugOptions::LIBRARY_FUSION_TYPE_REDUCE);\n+    }\n     tsl::protobuf::RepeatedField<int> empty_fusion_types;\n     bool use_onednn = spec.lib == \"onednn\";\n     bool use_xnnpack = spec.lib == \"xnn\";\n@@ -512,15 +515,40 @@ TEST_P(CpuLibraryFusionTypeTest, JoiningFusions) {\n       ROOT %mul = $in_dtype[64,64] multiply(%exp, %add2)\n     })\";\n \n-  RunTest(hlo_template, GetParam() == \"greedy\"\n-                            ? FusionProperties{HloOpcode::kMultiply, 3, 8, true}\n-                            : FusionProperties{HloOpcode::kDot, 3, 5, true});\n+  if (GetParam() == \"greedy\") {\n+    RunTest(hlo_template, FusionProperties{HloOpcode::kMultiply, 3, 8, true});\n+  }\n+  if (GetParam() == \"dot\") {\n+    RunTest(hlo_template, FusionProperties{HloOpcode::kDot, 3, 5, true});\n+  }\n+}\n+\n+TEST_P(CpuLibraryFusionTypeTest, Reduce) {\n+  const absl::string_view hlo_template = R\"(\n+    HloModule reduce\n+\n+    reducer_add {\n+      lhs = $in_dtype[] parameter(0)\n+      rhs = $in_dtype[] parameter(1)\n+      ROOT sum = $in_dtype[] add(lhs, rhs)\n+    }\n+\n+    ENTRY main {\n+      input = $in_dtype[64,64]{1,0} parameter(0)\n+      c = $in_dtype[] constant(0)\n+      ROOT output = $in_dtype[64]{0} reduce(input, c), dimensions={1}, to_apply=reducer_add\n+    }\n+    )\";\n+  if (GetParam() == \"reduce\") {\n+    RunTest(hlo_template, {HloOpcode::kReduce, 1, 3, true});\n+  }\n }\n \n INSTANTIATE_TEST_SUITE_P(CpuLibraryFusionTypeTestSuite,\n                          CpuLibraryFusionTypeTest,\n                          ::testing::ValuesIn({std::string(\"dot\"),\n-                                              std::string(\"greedy\")}),\n+                                              std::string(\"greedy\"),\n+                                              std::string(\"reduce\")}),\n                          CpuLibraryFusionTypeTest::Name);\n \n TEST_F(CpuLibraryTest, UpdateFusion) {"
        },
        {
            "sha": "bc1c2bf9ba9f88698f4b3d17028743e4f2ea860f",
            "filename": "third_party/xla/xla/backends/cpu/transforms/library_matcher.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_matcher.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_matcher.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_matcher.h?ref=081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2",
            "patch": "@@ -43,6 +43,9 @@ class LibraryMatcher {\n         case DebugOptions::LIBRARY_FUSION_TYPE_ELTWISE:\n           fuse_eltwise_ = true;\n           break;\n+        case DebugOptions::LIBRARY_FUSION_TYPE_REDUCE:\n+          fuse_reduce_ = true;\n+          break;\n         default:\n           LOG(ERROR) << \"Unsupported fusion type: \" << *it;\n       }\n@@ -80,9 +83,13 @@ class LibraryMatcher {\n   // Returns whether elementwise ops can start a fusion.\n   bool fuse_eltwise() const { return fuse_eltwise_; }\n \n+  // Returns whether reduce ops can start a fusion.\n+  bool fuse_reduce() const { return fuse_reduce_; }\n+\n  protected:\n   bool fuse_dot_ = false;\n   bool fuse_eltwise_ = false;\n+  bool fuse_reduce_ = false;\n   const TargetMachineFeatures* target_machine_features_;\n };\n "
        },
        {
            "sha": "faa943fa4ce929d1253e2a9ab2c6a06640779aeb",
            "filename": "third_party/xla/xla/backends/cpu/transforms/xnn_matcher.h",
            "status": "modified",
            "additions": 25,
            "deletions": 11,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_matcher.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_matcher.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_matcher.h?ref=081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n \n #include <string>\n \n+#include \"absl/base/no_destructor.h\"\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n@@ -39,17 +40,18 @@ class XnnMatcher : public LibraryMatcher {\n \n   // Returns the set of supported HLO instructions.\n   absl::flat_hash_set<HloOpcode> SupportedOps() const override {\n-    static const auto* kSupportedOps = []() {\n-      static auto* supported_ops =\n-          new absl::flat_hash_set<HloOpcode>{HloOpcode::kDot};\n-      for (const auto& [op, _] : GetXnnUnaryOpMap()) {\n-        supported_ops->insert(op);\n-      }\n-      for (const auto& [op, _] : GetXnnBinaryOpMap()) {\n-        supported_ops->insert(op);\n-      }\n-      return supported_ops;\n-    }();\n+    static const absl::NoDestructor<absl::flat_hash_set<HloOpcode>>\n+        kSupportedOps{[]() {\n+          absl::flat_hash_set<HloOpcode> supported_ops{\n+              HloOpcode::kDot, HloOpcode::kReduce, HloOpcode::kConstant};\n+          for (const auto& [op, _] : GetXnnUnaryOpMap()) {\n+            supported_ops.insert(op);\n+          }\n+          for (const auto& [op, _] : GetXnnBinaryOpMap()) {\n+            supported_ops.insert(op);\n+          }\n+          return supported_ops;\n+        }()};\n     return *kSupportedOps;\n   }\n \n@@ -60,9 +62,18 @@ class XnnMatcher : public LibraryMatcher {\n           instr->dot_dimension_numbers(), instr->operand(0)->shape(),\n           instr->operand(1)->shape(), instr->shape(), target_machine_features_);\n     }\n+    if (instr->opcode() == HloOpcode::kReduce) {\n+      return IsReduceOpSupportedByXnn(instr);\n+    }\n     if (instr->IsConstant()) {\n       return IsConstantSupportedByXnn(instr);\n     }\n+    // TODO(b/441837668): Need to get the reduction performance/cost model\n+    // right before enabling fusions. Fusions make performance analysis quite\n+    // challenging.\n+    if (fuse_reduce_) {\n+      return false;\n+    }\n     if (instr->IsElementwise()) {\n       return IsElementwiseOpSupportedByXnn(instr);\n     }\n@@ -76,6 +87,9 @@ class XnnMatcher : public LibraryMatcher {\n     if (fuse_dot_ && instr->opcode() == HloOpcode::kDot) {\n       return true;\n     }\n+    if (fuse_reduce_ && instr->opcode() == HloOpcode::kReduce) {\n+      return true;\n+    }\n     return fuse_eltwise_ && instr->IsElementwise();\n   }\n "
        },
        {
            "sha": "30473a0bc2ed9a0616ff3b00044aaaa7e6d21d0f",
            "filename": "third_party/xla/xla/backends/cpu/xnn_emitter.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_emitter.cc?ref=081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2",
            "patch": "@@ -456,11 +456,11 @@ static absl::StatusOr<XnnSubgraph> EmitXnnSubgraph(\n       } break;\n \n       case HloOpcode::kReduce: {\n-        if (!IsReduceOpSupportedByXnn(instr)) {\n-          return InvalidArgument(\n-              \"Unsupported reduce instruction in XNN fusion: %s\",\n-              instr->ToString());\n-        }\n+        // FIXME: Validate the reduce instruction.\n+        // One cannot directly use IsReduceOpSupportedByXnn since the invariant\n+        // value is not necessarily included into the same fusion. This might\n+        // happen if the original instruction has multiple users or was rejected\n+        // by the fusion compiler pass.\n         TF_ASSIGN_OR_RETURN(tensor_ids[instr],\n                             DefineReduceOp(subgraph.get(), tensor_ids, instr));\n       } break;"
        },
        {
            "sha": "e8087984ff317a7475c9d623cb6e521151448262",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2",
            "patch": "@@ -348,6 +348,7 @@ cc_library(\n         \"//xla/tsl/platform:status\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/protobuf:error_codes_proto_impl_cc\",\n+        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/base:dynamic_annotations\","
        },
        {
            "sha": "76b2b9eb8f22be21868c13e6dbe96c9baebe8004",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 21,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=081b32b0cb1e82c89d4bbbef00aaeb8d6f4a1bc2",
            "patch": "@@ -30,6 +30,8 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/algorithm/container.h\"\n+\n // IWYU pragma: no_include \"llvm/Config/Disassemblers.def.inc\"\n // IWYU pragma: no_include \"llvm/Config/Targets.def.inc\"\n \n@@ -488,9 +490,13 @@ std::unique_ptr<HloPassFix<HloPassPipeline>> CreateSimplificationPipeline(\n   }\n \n   if (module->config()\n-          .debug_options()\n-          .xla_cpu_experimental_xnn_graph_fusion_mode() !=\n-      DebugOptions::XNN_GRAPH_FUSION_MODE_GREEDY_SLINKY) {\n+              .debug_options()\n+              .xla_cpu_experimental_xnn_graph_fusion_mode() ==\n+          DebugOptions::XNN_GRAPH_FUSION_MODE_DISABLED &&\n+      !absl::c_contains(module->config()\n+                            .debug_options()\n+                            .xla_cpu_experimental_xnn_fusion_type(),\n+                        DebugOptions::LIBRARY_FUSION_TYPE_REDUCE)) {\n     // Needs to happen after algebraic simplifier.\n     pipeline->AddPass<TreeReductionRewriter>();\n   }\n@@ -585,24 +591,6 @@ absl::Status CpuCompiler::RunHloPassesThroughLayoutAssn(\n     TF_RETURN_IF_ERROR(subbyte_packer_pipeline.Run(module).status());\n   }\n \n-  // Guard this experimental pipeline with flags until we make sure that\n-  // calling `DotDecomposer` early is okay.\n-  DotLibraryRewriterOptions options = {\n-      /*use_onednn=*/module->config().debug_options().xla_cpu_use_onednn(),\n-      /*use_xnnpack=*/module->config().debug_options().xla_cpu_use_xnnpack(),\n-      /*onednn_fusion_types=*/\n-      &module->config()\n-           .debug_options()\n-           .xla_cpu_experimental_onednn_fusion_type(),\n-      /*xnn_fusion_types=*/\n-      &module->config().debug_options().xla_cpu_experimental_xnn_fusion_type()};\n-  if (options.use_onednn || options.use_xnnpack) {\n-    HloPassPipeline lib_pipeline(\"dot-library-passes\");\n-    lib_pipeline.AddPass<DotDecomposer>();\n-    lib_pipeline.AddPass<DotLibraryRewriter>(target_machine_features, options);\n-    TF_RETURN_IF_ERROR(lib_pipeline.Run(module).status());\n-  }\n-\n   HloPassPipeline pipeline(\"HLO passes through layout assignment\");\n   AddHloVerifier(&pipeline);\n   pipeline.AddPass<BatchedGatherScatterNormalizer>();\n@@ -911,6 +899,28 @@ absl::Status CpuCompiler::RunHloPassesAfterLayoutAssn(\n   }\n #endif  // INTEL_MKL\n \n+  // Guard this experimental pipeline with flags until we make sure that\n+  // calling `DotDecomposer` early is okay.\n+  //\n+  // XNNPACK ops availability checks depend on the layout information,\n+  // so until another solution is developed the passes creating XNNPACK fusions\n+  // have to run after layout assignment.\n+  DotLibraryRewriterOptions options = {\n+      /*use_onednn=*/module->config().debug_options().xla_cpu_use_onednn(),\n+      /*use_xnnpack=*/module->config().debug_options().xla_cpu_use_xnnpack(),\n+      /*onednn_fusion_types=*/\n+      &module->config()\n+           .debug_options()\n+           .xla_cpu_experimental_onednn_fusion_type(),\n+      /*xnn_fusion_types=*/\n+      &module->config().debug_options().xla_cpu_experimental_xnn_fusion_type()};\n+  if (options.use_onednn || options.use_xnnpack) {\n+    HloPassPipeline lib_pipeline(\"dot-library-passes\");\n+    lib_pipeline.AddPass<DotDecomposer>();\n+    lib_pipeline.AddPass<DotLibraryRewriter>(target_machine_features, options);\n+    TF_RETURN_IF_ERROR(lib_pipeline.Run(module).status());\n+  }\n+\n   if (debug_options.xla_cpu_experimental_xnn_graph_fusion_mode() !=\n       DebugOptions::XNN_GRAPH_FUSION_MODE_DISABLED) {\n     pipeline.AddPass<XnnGraphFusion>();"
        }
    ],
    "stats": {
        "total": 151,
        "additions": 109,
        "deletions": 42
    }
}