{
    "author": "tensorflower-gardener",
    "message": "[Autotuner] Add (de)serialization from/to string in cache.\n\n- This is required to port sharding from gemm_fusion_autotuner.\n\nPiperOrigin-RevId: 825045654",
    "sha": "da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4",
    "files": [
        {
            "sha": "dc4bf77ab55f1c7270ee15988a849e46ea4ba96e",
            "filename": "third_party/xla/xla/backends/autotuner/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD?ref=da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4",
            "patch": "@@ -128,6 +128,9 @@ cc_library(\n         \":autotuner_cache_proto_cc\",\n         \"//xla/hlo/ir:hlo\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/types:span\",\n     ],\n )\n "
        },
        {
            "sha": "09fa40dedb76daada245a3c504436baac288ca01",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner_cache_interface.h",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_cache_interface.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_cache_interface.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_cache_interface.h?ref=da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4",
            "patch": "@@ -20,6 +20,9 @@ limitations under the License.\n #include <string>\n \n #include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/autotuner/autotuner_cache.pb.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n \n@@ -42,6 +45,20 @@ class AutotunerCacheInterface {\n \n   virtual absl::Status Insert(const HloInstruction* instr,\n                               const Config& best_config) = 0;\n+\n+  // Serializes the cache to a string. If instructions are provided, only the\n+  // cache entries corresponding to the instructions will be serialized,\n+  // otherwise all cache entries will be serialized.\n+  virtual absl::StatusOr<std::string> Serialize(\n+      absl::Span<const HloInstruction* const> instructions_to_serialize) {\n+    return absl::UnimplementedError(\"Serialize is not implemented.\");\n+  };\n+\n+  // Deserializes the string and updates the cache, overwriting the keys if they\n+  // already exist.\n+  virtual absl::Status Deserialize(absl::string_view serialized_cache) {\n+    return absl::UnimplementedError(\"Deserialize is not implemented.\");\n+  };\n };\n \n }  // namespace xla"
        },
        {
            "sha": "206601e45f291fbc7d496e40ea450d442416d793",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD?ref=da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4",
            "patch": "@@ -776,10 +776,13 @@ cc_library(\n         \"//xla/service/gpu/autotuning:autotune_cache_key\",\n         \"//xla/service/gpu/autotuning:autotuner_util\",\n         \"//xla/stream_executor:device_description\",\n+        \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/protobuf:dnn_proto_cc\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/types:span\",\n         \"@com_google_protobuf//:duration_cc_proto\",\n     ],\n )\n@@ -797,8 +800,10 @@ xla_cc_test(\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:env\",\n+        \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/protobuf:dnn_proto_cc\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/types:span\",\n         \"@com_google_googletest//:gtest_main\",\n         \"@com_google_protobuf//:any_cc_proto\",\n         \"@local_tsl//tsl/platform:path\","
        },
        {
            "sha": "2e901605350aa374e40994fbd4170d503795f6b9",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/legacy_cache.cc",
            "status": "modified",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache.cc?ref=da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4",
            "patch": "@@ -16,14 +16,18 @@ limitations under the License.\n #include \"xla/backends/gpu/autotuner/legacy_cache.h\"\n \n #include <optional>\n+#include <string>\n \n #include \"google/protobuf/duration.pb.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/service/gpu/autotuning/autotune_cache_key.h\"\n #include \"xla/service/gpu/autotuning/autotuner_util.h\"\n+#include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/protobuf/dnn.pb.h\"\n \n namespace xla {\n@@ -63,6 +67,32 @@ absl::Status LegacyCache::Insert(const HloInstruction* instr,\n   return absl::OkStatus();\n }\n \n+void LegacyCache::ClearCache() { AutotunerUtil::ClearAutotuneResults(); }\n+\n+absl::StatusOr<std::string> LegacyCache::Serialize(\n+    absl::Span<const HloInstruction* const> instructions_to_serialize) {\n+  AutotuneCacheKeySet key_set;\n+  for (const HloInstruction* instr : instructions_to_serialize) {\n+    key_set.insert(GetAutotuneCacheKey(*instr));\n+  }\n+\n+  std::optional<const AutotuneCacheKeySet*> keys_to_send = std::nullopt;\n+  if (!key_set.empty()) {\n+    keys_to_send = &key_set;\n+  }\n+\n+  AutotuneResults results;\n+  TF_RETURN_IF_ERROR(\n+      AutotunerUtil::SerializeAutotuneResults(&results, keys_to_send));\n+  return AutotuneResultsToString(results, true);\n+}\n+\n+absl::Status LegacyCache::Deserialize(absl::string_view serialized_cache) {\n+  return AutotunerUtil::LoadAutotuneResults(serialized_cache,\n+                                            /*as_textproto=*/true,\n+                                            /*allow_override=*/true);\n+}\n+\n AutotuneCacheKey LegacyCache::GetAutotuneCacheKey(const HloInstruction& instr) {\n   AutotuneCacheKey key(device_desc_, instr);\n   return key;"
        },
        {
            "sha": "f9be4ee3f43ba55ed332f6e563e3630f73c7dc8e",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/legacy_cache.h",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache.h?ref=da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4",
            "patch": "@@ -21,6 +21,9 @@ limitations under the License.\n #include <utility>\n \n #include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/autotuning.pb.h\"\n #include \"xla/backends/autotuner/autotuner_cache_interface.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n@@ -45,6 +48,12 @@ class LegacyCache : public AutotunerCacheInterface {\n   absl::Status Insert(const HloInstruction* instr,\n                       const Config& best_config) override;\n \n+  absl::StatusOr<std::string> Serialize(absl::Span<const HloInstruction* const>\n+                                            instructions_to_serialize) override;\n+  absl::Status Deserialize(absl::string_view serialized_cache) override;\n+\n+  void ClearCache();\n+\n  private:\n   AutotuneCacheKey GetAutotuneCacheKey(const HloInstruction& instr);\n "
        },
        {
            "sha": "2217d3ff5eb75873c8ecc4c5476cdb29a0c03ed0",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/legacy_cache_test.cc",
            "status": "modified",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache_test.cc?ref=da8b9bf004b9461f2c3a65f56bdbd5c3d0aa02d4",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include <memory>\n #include <optional>\n #include <string>\n+#include <vector>\n \n #include \"google/protobuf/any.pb.h\"\n #include <gmock/gmock.h>\n@@ -33,6 +34,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/env.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/protobuf/dnn.pb.h\"\n \n namespace xla {\n@@ -232,6 +234,32 @@ TEST_F(LegacyCacheTest, OnlyInsertOncePerHlo) {\n   EXPECT_THAT(cache.Lookup(instr.get()), Optional(ConfigEq(config)));\n }\n \n+TEST_F(LegacyCacheTest, SerializeAndDeserialize) {\n+  LegacyCache cache(test_dir_, mode_, device_desc_);\n+  std::unique_ptr<HloInstruction> instr_1 = CreateDummyInstr(\"hlo9\");\n+  std::unique_ptr<HloInstruction> instr_2 = CreateDummyInstr(\"hlo10\");\n+  Config orig_config = CreateDummyTritonConfig();\n+  TF_ASSERT_OK(cache.Insert(instr_1.get(), orig_config));\n+  TF_ASSERT_OK(cache.Insert(instr_2.get(), orig_config));\n+\n+  // Serialize instr_1 to a string.\n+  std::vector<const HloInstruction*> instructions_to_serialize = {\n+      instr_1.get()};\n+  TF_ASSERT_OK_AND_ASSIGN(std::string serialized_cache,\n+                          cache.Serialize(instructions_to_serialize));\n+\n+  // Overwrite config for both instructions.\n+  cache.ClearCache();\n+  Config another_config = CreateDummyCublasConfig();\n+  TF_ASSERT_OK(cache.Insert(instr_1.get(), another_config));\n+  TF_ASSERT_OK(cache.Insert(instr_2.get(), another_config));\n+\n+  // Deserialize the cache, only instr_1 should be overwritten.\n+  TF_ASSERT_OK(cache.Deserialize(serialized_cache));\n+  EXPECT_THAT(cache.Lookup(instr_1.get()), Optional(ConfigEq(orig_config)));\n+  EXPECT_THAT(cache.Lookup(instr_2.get()), Optional(ConfigEq(another_config)));\n+}\n+\n }  // namespace\n }  // namespace gpu\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 92,
        "additions": 92,
        "deletions": 0
    }
}