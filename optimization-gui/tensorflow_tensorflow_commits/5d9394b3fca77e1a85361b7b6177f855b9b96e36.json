{
    "author": "tensorflower-gardener",
    "message": "[XLA:TPU] SPMD Partitioner should not change layout if no partition changes done\n\nPiperOrigin-RevId: 841806676",
    "sha": "5d9394b3fca77e1a85361b7b6177f855b9b96e36",
    "files": [
        {
            "sha": "052fe73912d8ba8f901871a1325a2d91c76fa8cb",
            "filename": "third_party/xla/xla/service/spmd/spmd_partitioner.cc",
            "status": "modified",
            "additions": 71,
            "deletions": 44,
            "changes": 115,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5d9394b3fca77e1a85361b7b6177f855b9b96e36/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5d9394b3fca77e1a85361b7b6177f855b9b96e36/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc?ref=5d9394b3fca77e1a85361b7b6177f855b9b96e36",
            "patch": "@@ -5488,6 +5488,26 @@ int64_t SpmdPartitioner::CommunicationCostInBytes(HloInstruction* hlo) {\n   module->set_spmd_output_sharding(entry_root->sharding());\n }\n \n+namespace {\n+\n+// Returns true if the old and the new entry layout shapes differ.\n+// NOTE: that we explicitly ignore the layout, since it is either defined\n+// beforehand or during layout assignment.\n+bool ShapeChangesBetween(const ComputationLayout& old_entry_layout,\n+                         const ProgramShape& new_program_shape) {\n+  for (int64_t i = 0; i < new_program_shape.parameters_size(); ++i) {\n+    if (!Shape::Equal().IgnoreLayout()(old_entry_layout.parameter_shape(i),\n+                                       new_program_shape.parameters(i))) {\n+      return true;\n+    }\n+  }\n+\n+  return !Shape::Equal().IgnoreLayout()(old_entry_layout.result_shape(),\n+                                        new_program_shape.result());\n+}\n+\n+}  // namespace\n+\n absl::StatusOr<bool> SpmdPartitioner::RunImpl(\n     HloModule* module,\n     const absl::flat_hash_set<absl::string_view>& execution_threads) {\n@@ -5582,57 +5602,64 @@ absl::StatusOr<bool> SpmdPartitioner::RunImpl(\n       }));\n \n   // For the entry computation, make sure that the root instruction and the\n-  // parameters preserve their signatures.\n+  // parameters preserve their signatures if there are any partitioning changes.\n   auto new_program_shape = module->entry_computation()->ComputeProgramShape();\n-  if (!options_.allow_module_signature_change) {\n-    if (!Shape::Equal()(program_shape.result(), new_program_shape.result())) {\n-      return absl::InvalidArgumentError(\n-          \"Result shape changed for the entry computation from: \" +\n-          program_shape.result().ToString() +\n-          \" to: \" + new_program_shape.result().ToString());\n-    }\n-    if (program_shape.parameters_size() !=\n-        new_program_shape.parameters_size()) {\n-      return absl::InvalidArgumentError(\n-          \"Parameter count changed for the entry computation from: \" +\n-          std::to_string(program_shape.parameters_size()) +\n-          \" to: \" + std::to_string(new_program_shape.parameters_size()));\n-    }\n-    for (int64_t i = 0; i < program_shape.parameters_size(); ++i) {\n-      if (!Shape::Equal()(program_shape.parameters(i),\n-                          new_program_shape.parameters(i))) {\n+  const ComputationLayout& old_entry_layout =\n+      module->entry_computation_layout();\n+  if (ShapeChangesBetween(old_entry_layout, new_program_shape)) {\n+    if (!options_.allow_module_signature_change) {\n+      if (!Shape::Equal()(program_shape.result(), new_program_shape.result())) {\n         return absl::InvalidArgumentError(\n-            \"Parameter shape changed for the entry computation parameter \" +\n-            std::to_string(i) +\n-            \" from: \" + program_shape.parameters(i).ToString() +\n-            \" to: \" + new_program_shape.parameters(i).ToString());\n+            \"Result shape changed for the entry computation from: \" +\n+            program_shape.result().ToString() +\n+            \" to: \" + new_program_shape.result().ToString());\n       }\n-    }\n-  } else {\n-    // Fix up some bad tiling in entry computation layout.\n-    auto update_shape = [this](Shape* subshape, const xla::ShapeIndex& index) {\n-      if (subshape->IsArray() && subshape->has_layout()) {\n-        UpdateLayout(subshape);\n+      if (program_shape.parameters_size() !=\n+          new_program_shape.parameters_size()) {\n+        return absl::InvalidArgumentError(\n+            \"Parameter count changed for the entry computation from: \" +\n+            std::to_string(program_shape.parameters_size()) +\n+            \" to: \" + std::to_string(new_program_shape.parameters_size()));\n       }\n-    };\n-    const auto& old_entry_layout = module->entry_computation_layout();\n-    // Shapes can change but the layout should still remain the same.\n-    for (int64_t i = 0; i < new_program_shape.parameters_size(); ++i) {\n+      for (int64_t i = 0; i < program_shape.parameters_size(); ++i) {\n+        if (!Shape::Equal()(program_shape.parameters(i),\n+                            new_program_shape.parameters(i))) {\n+          return absl::InvalidArgumentError(\n+              \"Parameter shape changed for the entry computation parameter \" +\n+              std::to_string(i) +\n+              \" from: \" + program_shape.parameters(i).ToString() +\n+              \" to: \" + new_program_shape.parameters(i).ToString());\n+        }\n+      }\n+    } else {\n+      // For the cases where we update the shape, also fix up some bad tiling in\n+      // entry computation layout.\n+      auto update_shape = [this](Shape* subshape,\n+                                 const xla::ShapeIndex& index) {\n+        if (subshape->IsArray() && subshape->has_layout()) {\n+          UpdateLayout(subshape);\n+        }\n+      };\n+      // Shapes can change but the layout should still remain the same.\n+      // If the shapes do not change, we shouldn't change the layout if pre-set.\n+      for (int64_t i = 0; i < new_program_shape.parameters_size(); ++i) {\n+        TF_RETURN_IF_ERROR(LayoutUtil::CopyLayoutBetweenShapes(\n+            old_entry_layout.parameter_shape(i),\n+            new_program_shape.mutable_parameters(i)));\n+        ShapeUtil::ForEachMutableSubshape(\n+            new_program_shape.mutable_parameters(i), update_shape);\n+      }\n+\n       TF_RETURN_IF_ERROR(LayoutUtil::CopyLayoutBetweenShapes(\n-          old_entry_layout.parameter_shape(i),\n-          new_program_shape.mutable_parameters(i)));\n-      ShapeUtil::ForEachMutableSubshape(new_program_shape.mutable_parameters(i),\n+          old_entry_layout.result_shape(), new_program_shape.mutable_result()));\n+      ShapeUtil::ForEachMutableSubshape(new_program_shape.mutable_result(),\n                                         update_shape);\n+\n+      HloModuleConfig config = module->config();\n+      *config.mutable_entry_computation_layout() =\n+          ComputationLayout(new_program_shape, /*ignore_layouts=*/false);\n+      module->set_config(config);\n     }\n-    TF_RETURN_IF_ERROR(LayoutUtil::CopyLayoutBetweenShapes(\n-        old_entry_layout.result_shape(), new_program_shape.mutable_result()));\n-    ShapeUtil::ForEachMutableSubshape(new_program_shape.mutable_result(),\n-                                      update_shape);\n-\n-    HloModuleConfig config = module->config();\n-    *config.mutable_entry_computation_layout() =\n-        ComputationLayout(new_program_shape, /*ignore_layouts=*/false);\n-    module->set_config(config);\n   }\n \n   XLA_VLOG_LINES(1, SpmdLogger::ReportAfterPartition("
        }
    ],
    "stats": {
        "total": 115,
        "additions": 71,
        "deletions": 44
    }
}