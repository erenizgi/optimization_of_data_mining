{
    "author": "unknown",
    "message": "Support for TFv2.20 to compile with CUDA v12.9.1",
    "sha": "c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc",
    "files": [
        {
            "sha": "b4fe8ae69771ca67574a176bb342488605837044",
            "filename": "tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc/tensorflow%2Fcore%2Fkernels%2Fconcat_lib_gpu_impl.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc/tensorflow%2Fcore%2Fkernels%2Fconcat_lib_gpu_impl.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconcat_lib_gpu_impl.cu.cc?ref=c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc",
            "patch": "@@ -70,7 +70,7 @@ __global__ void concat_variable_kernel(\n   IntType num_inputs = input_ptr_data.size;\n \n   // verbose declaration needed due to template\n-  GPU_DYNAMIC_SHARED_MEM_DECL(sizeof(T), unsigned char, smem);\n+  GPU_DYNAMIC_SHARED_MEM_DECL(8, unsigned char, smem);\n   IntType* smem_col_scan = reinterpret_cast<IntType*>(smem);\n \n   if (useSmem) {"
        },
        {
            "sha": "737e22e5b9fed0b3e49ae7cf229cb8d79c55b97f",
            "filename": "tensorflow/core/kernels/dynamic_partition_op_gpu.cu.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc/tensorflow%2Fcore%2Fkernels%2Fdynamic_partition_op_gpu.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc/tensorflow%2Fcore%2Fkernels%2Fdynamic_partition_op_gpu.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdynamic_partition_op_gpu.cu.cc?ref=c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc",
            "patch": "@@ -410,7 +410,11 @@ class DynamicPartitionOpGPU : public AsyncOpKernel {\n                                             num_partitions_);\n \n #if GOOGLE_CUDA\n-    cub::ConstantInputIterator<int32> values_in(1);\n+    #if THRUST_VERSION >= 200802\n+        thrust::constant_iterator<int32> values_in(1);\n+    #else\n+        cub::ConstantInputIterator<int32> values_in(1);\n+    #endif\n #elif TENSORFLOW_USE_ROCM\n     using ConstantInputIterator =\n         ::rocprim::constant_iterator<int32, ptrdiff_t>;"
        },
        {
            "sha": "37c0c73119c678e565866dee7b1767b6ac218e78",
            "filename": "tensorflow/core/kernels/gpu_prim.h",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc/tensorflow%2Fcore%2Fkernels%2Fgpu_prim.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc/tensorflow%2Fcore%2Fkernels%2Fgpu_prim.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fgpu_prim.h?ref=c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc",
            "patch": "@@ -37,8 +37,8 @@ namespace gpuprim = ::cub;\n \n // Required for sorting Eigen::half and bfloat16.\n namespace cub {\n-template <>\n-__device__ __forceinline__ void ThreadStoreVolatilePtr<Eigen::half>(\n+\n+__device__ __forceinline__ void ThreadStoreVolatilePtr(\n     Eigen::half *ptr, Eigen::half val, Int2Type<true> /*is_primitive*/) {\n   *reinterpret_cast<volatile uint16_t *>(ptr) =\n       Eigen::numext::bit_cast<uint16_t>(val);\n@@ -50,8 +50,7 @@ __device__ __forceinline__ Eigen::half ThreadLoadVolatilePointer(\n   return Eigen::numext::bit_cast<Eigen::half>(result);\n }\n \n-template <>\n-__device__ __forceinline__ void ThreadStoreVolatilePtr<Eigen::bfloat16>(\n+__device__ __forceinline__ void ThreadStoreVolatilePtr(\n     Eigen::bfloat16 *ptr, Eigen::bfloat16 val,\n     Int2Type<true> /*is_primitive*/) {\n   *reinterpret_cast<volatile uint16_t *>(ptr) ="
        },
        {
            "sha": "e395d4f12f5a3350ad5db30016417c8368175408",
            "filename": "tensorflow/core/kernels/split_lib_gpu.cu.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc/tensorflow%2Fcore%2Fkernels%2Fsplit_lib_gpu.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc/tensorflow%2Fcore%2Fkernels%2Fsplit_lib_gpu.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsplit_lib_gpu.cu.cc?ref=c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc",
            "patch": "@@ -120,7 +120,7 @@ __global__ void split_v_kernel(const T* __restrict__ input_ptr,\n   int num_outputs = output_ptr_data.size;\n \n   // verbose declaration needed due to template\n-  GPU_DYNAMIC_SHARED_MEM_DECL(sizeof(T), unsigned char, smem);\n+  GPU_DYNAMIC_SHARED_MEM_DECL(2, unsigned char, smem);\n   IntType* smem_col_scan = reinterpret_cast<IntType*>(smem);\n \n   if (useSmem) {"
        },
        {
            "sha": "3de25b7a82c8e12b78cc74a9f695aff993aa6f73",
            "filename": "tensorflow/core/kernels/where_op_gpu.cu.h",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc/tensorflow%2Fcore%2Fkernels%2Fwhere_op_gpu.cu.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc/tensorflow%2Fcore%2Fkernels%2Fwhere_op_gpu.cu.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fwhere_op_gpu.cu.h?ref=c59bd3fdce713f3427ddbfe2dc9fbb01490d0bdc",
            "patch": "@@ -233,6 +233,17 @@ class WhereOutputIterator {\n     return *(ptr_ + (valid ? (NDIM * n) : 0));\n   }\n \n+\n+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE reference operator*() const {\n+    // Dereference the current pointer\n+    return *ptr_;\n+  }\n+\n+\n+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE self_type operator+(std::ptrdiff_t n) const {\n+    return self_type(ptr_ + NDIM * n, max_row_);\n+  }\n+\n  private:\n   int64* ptr_;\n   const Eigen::DenseIndex max_row_;"
        }
    ],
    "stats": {
        "total": 28,
        "additions": 21,
        "deletions": 7
    }
}