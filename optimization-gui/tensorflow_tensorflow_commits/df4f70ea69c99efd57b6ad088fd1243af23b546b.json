{
    "author": "beckerhe",
    "message": "Remove `debug_info_` from xla::Executable.\n\nExecutable::debug_info_ is written from multiple compiler implementations but not read anywhere. Let's remove all of that.\nPiperOrigin-RevId: 839218697",
    "sha": "df4f70ea69c99efd57b6ad088fd1243af23b546b",
    "files": [
        {
            "sha": "a7d9949d804546b308118c7419635866991cb727",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/df4f70ea69c99efd57b6ad088fd1243af23b546b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/df4f70ea69c99efd57b6ad088fd1243af23b546b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=df4f70ea69c99efd57b6ad088fd1243af23b546b",
            "patch": "@@ -2102,10 +2102,6 @@ absl::StatusOr<std::unique_ptr<Executable>> CpuCompiler::RunBackend(\n       CompileCpuExecutable(std::move(module), thunk_emitter_options,\n                            std::move(ir_compiler)));\n \n-  AliasInfo alias_info;\n-  cpu_executable->set_debug_info(\n-      cpu_executable->buffer_assignment().StatsString(&alias_info));\n-\n   VLOG(1) << \"Compilation finished\";\n   cpu_executable->Finalize();\n "
        },
        {
            "sha": "14d47210631864eca09e6f0bc81d35b715dd3d48",
            "filename": "third_party/xla/xla/service/executable.h",
            "status": "modified",
            "additions": 1,
            "deletions": 8,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/df4f70ea69c99efd57b6ad088fd1243af23b546b/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/df4f70ea69c99efd57b6ad088fd1243af23b546b/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h?ref=df4f70ea69c99efd57b6ad088fd1243af23b546b",
            "patch": "@@ -275,7 +275,7 @@ class Executable {\n     CHECK_EQ(hlo_profile_printer_data_.get() == nullptr,\n              hlo_profile_index_map_.get() == nullptr);\n   }\n-  virtual ~Executable() {}\n+  virtual ~Executable() = default;\n \n   // Enqueues the compilation result on the provided stream, passing the given\n   // arguments. This call is blocking and returns after the execution is done.\n@@ -426,10 +426,6 @@ class Executable {\n                : nullptr;\n   }\n \n-  std::string& debug_info() { return debug_info_; }\n-  void set_debug_info(const std::string& debug_info) {\n-    debug_info_ = debug_info;\n-  }\n   // Gather unused but donated buffers, return them to the caller of this API.\n   // We don't free buffers inside this function since the caller could have\n   // different preferences for buffer deallocation. For example, in TensorFlow,\n@@ -472,9 +468,6 @@ class Executable {\n   std::unique_ptr<HloProfilePrinterData> hlo_profile_printer_data_;\n   std::unique_ptr<HloProfileIndexMap> hlo_profile_index_map_;\n \n-  // Generic debug information as a string.\n-  std::string debug_info_;\n-\n   // The serialized HLO proto. Non-null only if dumping snapshots is enabled.\n   // This field may also be only partially set: if only\n   // hlo_proto_->buffer_assignment is set and hlo_proto_->hlo_module isn't, the"
        },
        {
            "sha": "5236937e5fa6a6a1fd9ae5c9a43ba3fe6d368814",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/df4f70ea69c99efd57b6ad088fd1243af23b546b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/df4f70ea69c99efd57b6ad088fd1243af23b546b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=df4f70ea69c99efd57b6ad088fd1243af23b546b",
            "patch": "@@ -2563,7 +2563,6 @@ absl::StatusOr<std::unique_ptr<Executable>> GpuCompiler::RunBackend(\n   });\n \n   std::unique_ptr<GpuAliasInfo> alias_info = GetAliasInfo(gpu_device_info);\n-  const GpuAliasInfo* alias_info_ptr = alias_info.get();\n   TF_ASSIGN_OR_RETURN(\n       std::unique_ptr<GpuExecutable> gpu_executable,\n       GpuExecutable::Create(GpuExecutable::Params{\n@@ -2608,8 +2607,6 @@ absl::StatusOr<std::unique_ptr<Executable>> GpuCompiler::RunBackend(\n     *hlo_proto->mutable_buffer_assignment() =\n         gpu_executable->buffer_assignment()->ToProto();\n     gpu_executable->set_hlo_proto(std::move(hlo_proto));\n-    gpu_executable->set_debug_info(\n-        gpu_executable->buffer_assignment()->StatsString(alias_info_ptr));\n   }\n \n   return static_cast<std::unique_ptr<Executable>>(std::move(gpu_executable));"
        }
    ],
    "stats": {
        "total": 16,
        "additions": 1,
        "deletions": 15
    }
}