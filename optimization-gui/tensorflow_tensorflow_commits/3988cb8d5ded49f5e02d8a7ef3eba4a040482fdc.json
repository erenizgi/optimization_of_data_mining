{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 809525418",
    "sha": "3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc",
    "files": [
        {
            "sha": "2ebc04e03e928fb00f358c2dc2fe8269f17311e2",
            "filename": "tensorflow/core/data/service/snapshot/parallel_tfrecord_writer.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fparallel_tfrecord_writer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fparallel_tfrecord_writer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fparallel_tfrecord_writer.cc?ref=3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc",
            "patch": "@@ -70,7 +70,7 @@ ParallelTFRecordWriter::~ParallelTFRecordWriter() {\n \n absl::Status ParallelTFRecordWriter::Write(std::vector<Tensor> record)\n     ABSL_LOCKS_EXCLUDED(mu_) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   while (status_.ok() && !finalized_ && buffer_.size() >= buffer_size_) {\n     ready_to_push_.Wait(&mu_);\n   }\n@@ -88,14 +88,14 @@ absl::Status ParallelTFRecordWriter::Write(std::vector<Tensor> record)\n absl::StatusOr<ParallelTFRecordWriter::FileToStatsMap>\n ParallelTFRecordWriter::Finalize() ABSL_LOCKS_EXCLUDED(mu_) {\n   {\n-    absl::MutexLock l(&mu_);\n+    absl::MutexLock l(mu_);\n     finalized_ = true;\n     ready_to_push_.SignalAll();\n     ready_to_pop_.SignalAll();\n   }\n \n   thread_pool_.reset();\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   TF_RETURN_IF_ERROR(status_);\n   return file_stats_;\n }\n@@ -107,7 +107,7 @@ void ParallelTFRecordWriter::WriteFiles() {\n }\n \n bool ParallelTFRecordWriter::HasNext() const ABSL_LOCKS_EXCLUDED(mu_) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   if (!status_.ok()) {\n     return false;\n   }\n@@ -130,7 +130,7 @@ bool ParallelTFRecordWriter::ShouldWriteFile(const std::string& filename) const\n   if (!HasNext()) {\n     return false;\n   }\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   auto iterator = file_stats_.find(filename);\n   return iterator == file_stats_.end() ||\n          iterator->second.estimated_size < max_file_size_;\n@@ -153,7 +153,7 @@ absl::Status ParallelTFRecordWriter::WriteRecord(\n absl::StatusOr<std::optional<std::vector<Tensor>>>\n ParallelTFRecordWriter::GetNextRecord(const std::string& filename)\n     ABSL_LOCKS_EXCLUDED(mu_) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   while (status_.ok() && !finalized_ && buffer_.empty()) {\n     ready_to_pop_.Wait(&mu_);\n   }\n@@ -175,7 +175,7 @@ ParallelTFRecordWriter::GetNextRecord(const std::string& filename)\n \n absl::Status ParallelTFRecordWriter::DeleteEmptyFile(\n     const std::string& filename) ABSL_LOCKS_EXCLUDED(mu_) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   auto iterator = file_stats_.find(filename);\n   if (iterator != file_stats_.end() && iterator->second.num_records > 0) {\n     return absl::OkStatus();\n@@ -204,7 +204,7 @@ void ParallelTFRecordWriter::UpdateStatus(absl::Status status)\n   if (status.ok()) {\n     return;\n   }\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   status_.Update(std::move(status));\n   ready_to_push_.SignalAll();\n   ready_to_pop_.SignalAll();"
        },
        {
            "sha": "4323a1c6bf15fa38d7ebe42d30f2d11f031e7c90",
            "filename": "tensorflow/core/data/service/snapshot/prefetched_split_provider.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fprefetched_split_provider.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fprefetched_split_provider.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fprefetched_split_provider.cc?ref=3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc",
            "patch": "@@ -52,15 +52,15 @@ PrefetchedSplitProvider::PrefetchedSplitProvider(\n     UpdateStatus(std::move(status));\n     return;\n   }\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   thread_pool_ = RunPrefetchThreads();\n }\n \n PrefetchedSplitProvider::~PrefetchedSplitProvider() { Cancel(); }\n \n absl::StatusOr<std::optional<Tensor>> PrefetchedSplitProvider::GetNext(\n     const std::string& split_path) ABSL_LOCKS_EXCLUDED(mu_) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   while (status_.ok() &&\n          (buffer_.empty() || buffer_.begin()->index != split_index_to_read_) &&\n          (finished_threads_ < num_write_threads_ || reset_)) {\n@@ -109,15 +109,15 @@ void PrefetchedSplitProvider::PrefetchLoop() ABSL_LOCKS_EXCLUDED(mu_) {\n     }\n   }\n \n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   if (++finished_threads_ >= num_write_threads_) {\n     ready_to_pop_.SignalAll();\n   }\n }\n \n bool PrefetchedSplitProvider::ShouldPrefetchSplit() const\n     ABSL_LOCKS_EXCLUDED(mu_) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   return status_.ok() && !reset_;\n }\n \n@@ -134,15 +134,15 @@ absl::StatusOr<bool> PrefetchedSplitProvider::PrefetchSplit()\n       AtomicallyWriteTFRecords(split->SplitPath(directory_), {split->split},\n                                tsl::io::compression::kNone, env_));\n \n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   buffer_.insert(std::move(*split));\n   ready_to_pop_.Signal();\n   return true;\n }\n \n absl::StatusOr<std::optional<PrefetchedSplitProvider::SplitAndIndex>>\n PrefetchedSplitProvider::GetSplitFromProvider() ABSL_LOCKS_EXCLUDED(mu_) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   while (status_.ok() && buffer_.size() >= buffer_size_ && !reset_) {\n     ready_to_push_.Wait(&mu_);\n   }\n@@ -163,7 +163,7 @@ PrefetchedSplitProvider::GetSplitFromProvider() ABSL_LOCKS_EXCLUDED(mu_) {\n absl::Status PrefetchedSplitProvider::Reset() ABSL_LOCKS_EXCLUDED(mu_) {\n   std::unique_ptr<tsl::thread::ThreadPool> thread_pool;\n   {\n-    absl::MutexLock l(&mu_);\n+    absl::MutexLock l(mu_);\n     reset_ = true;\n     ready_to_push_.SignalAll();\n     ready_to_pop_.SignalAll();\n@@ -172,7 +172,7 @@ absl::Status PrefetchedSplitProvider::Reset() ABSL_LOCKS_EXCLUDED(mu_) {\n   thread_pool.reset();\n   TF_RETURN_IF_ERROR(split_provider_->Reset());\n \n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   TF_RETURN_IF_ERROR(status_);\n   reset_ = false;\n   split_index_to_read_ = 0;\n@@ -190,7 +190,7 @@ void PrefetchedSplitProvider::Cancel() {\n   // Finishes the in-flight threads.\n   std::unique_ptr<tsl::thread::ThreadPool> thread_pool;\n   {\n-    absl::MutexLock l(&mu_);\n+    absl::MutexLock l(mu_);\n     thread_pool = std::move(thread_pool_);\n   }\n }\n@@ -209,7 +209,7 @@ void PrefetchedSplitProvider::UpdateStatus(absl::Status status)\n   if (status.ok()) {\n     return;\n   }\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   status_.Update(std::move(status));\n   ready_to_push_.SignalAll();\n   ready_to_pop_.SignalAll();"
        },
        {
            "sha": "518220d4f9f523a52b71be900cd0f041acd3b1bd",
            "filename": "tensorflow/core/data/service/snapshot/prefetched_split_provider_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fprefetched_split_provider_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fprefetched_split_provider_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fprefetched_split_provider_test.cc?ref=3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc",
            "patch": "@@ -181,7 +181,7 @@ TEST_P(PrefetchedSplitProviderParamTest, ConcurrentGetSplits) {\n               std::vector<int64_t> splits_per_thread,\n               GetSplits<int64_t>(prefetched_split_provider, test_dirs[1 + i]));\n           EXPECT_TRUE(absl::c_is_sorted(splits_per_thread));\n-          absl::MutexLock l(&mu);\n+          absl::MutexLock l(mu);\n           absl::c_move(splits_per_thread, std::back_inserter(splits));\n         })));\n   }\n@@ -227,7 +227,7 @@ TEST_P(PrefetchedSplitProviderParamTest, ConcurrentGetSplitsAndReset) {\n           TF_ASSERT_OK_AND_ASSIGN(\n               std::vector<int64_t> splits_per_thread,\n               GetSplits<int64_t>(prefetched_split_provider, test_dirs[1 + i]));\n-          absl::MutexLock l(&mu);\n+          absl::MutexLock l(mu);\n           absl::c_move(splits_per_thread, std::back_inserter(splits));\n         })));\n   }"
        },
        {
            "sha": "b8c9e08c1b001033d4ff0ca278d2bb25e2a1c466",
            "filename": "tensorflow/core/data/service/snapshot/snapshot_chunk_provider.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fsnapshot_chunk_provider.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fsnapshot_chunk_provider.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fsnapshot_chunk_provider.cc?ref=3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc",
            "patch": "@@ -82,7 +82,7 @@ absl::Status SnapshotChunkProvider::GetNext(Tensor* split, bool* end_of_splits)\n     ABSL_LOCKS_EXCLUDED(mu_) {\n   for (int num_retries = 0;; ++num_retries) {\n     Backoff(num_retries, env_);\n-    absl::MutexLock l(&mu_);\n+    absl::MutexLock l(mu_);\n     TF_RETURN_IF_ERROR(snapshot_state_.status);\n     if (!chunks_unread_.empty()) {\n       std::string next_chunk = *chunks_unread_.begin();\n@@ -147,7 +147,7 @@ SnapshotChunkProvider::GetAvailableChunks() {\n }\n \n absl::Status SnapshotChunkProvider::Reset() {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   chunks_read_.clear();\n   chunks_unread_.clear();\n   return UpdateSnapshot();\n@@ -156,7 +156,7 @@ absl::Status SnapshotChunkProvider::Reset() {\n absl::Status SnapshotChunkProvider::Save(\n     std::function<std::string(std::string)> full_name,\n     IteratorStateWriter* writer) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   TF_RETURN_IF_ERROR(\n       writer->WriteScalar(full_name(kChunksRead), SetToString(chunks_read_)));\n   return absl::OkStatus();\n@@ -165,7 +165,7 @@ absl::Status SnapshotChunkProvider::Save(\n absl::Status SnapshotChunkProvider::Restore(\n     std::function<std::string(std::string)> full_name,\n     IteratorStateReader* reader) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   tsl::tstring chunks_read;\n   TF_RETURN_IF_ERROR(reader->ReadScalar(full_name(kChunksRead), &chunks_read));\n   chunks_read_ = SetFromString(chunks_read);\n@@ -177,7 +177,7 @@ int64_t SnapshotChunkProvider::Cardinality() const {\n }\n \n void SnapshotChunkProvider::Cancel() {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   if (snapshot_state_.snapshot_is_done || !snapshot_state_.status.ok()) {\n     return;\n   }"
        },
        {
            "sha": "8cb859c68da5e1f04c9eb313c7f42c63ccaf38f1",
            "filename": "tensorflow/core/data/service/snapshot/snapshot_chunk_provider_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fsnapshot_chunk_provider_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fsnapshot_chunk_provider_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fservice%2Fsnapshot%2Fsnapshot_chunk_provider_test.cc?ref=3988cb8d5ded49f5e02d8a7ef3eba4a040482fdc",
            "patch": "@@ -200,12 +200,12 @@ TEST(SnapshotChunkProviderTest, WaitForSnapshot) {\n                                                           tsl::Env::Default());\n             TF_ASSERT_OK_AND_ASSIGN(std::vector<std::string> chunks,\n                                     GetAllChunks(snapshot_chunk_provider));\n-            absl::MutexLock l(&mu);\n+            absl::MutexLock l(mu);\n             result = std::move(chunks);\n           }));\n \n   {  // The reader should wait when there are no chunks.\n-    absl::MutexLock l(&mu);\n+    absl::MutexLock l(mu);\n     EXPECT_TRUE(result.empty());\n   }\n \n@@ -216,7 +216,7 @@ TEST(SnapshotChunkProviderTest, WaitForSnapshot) {\n \n   // The reader should be able to get chunks now.\n   reader_thread.reset();\n-  absl::MutexLock l(&mu);\n+  absl::MutexLock l(mu);\n   EXPECT_THAT(result,\n               ElementsAreArray(JoinPaths(snapshot_path, {\"chunk_0_0_0\"})));\n }\n@@ -243,7 +243,7 @@ TEST(SnapshotChunkProviderTest, ConcurrentReadWrite) {\n             if (end_of_splits) {\n               break;\n             }\n-            absl::MutexLock l(&mu);\n+            absl::MutexLock l(mu);\n             result.push_back(split.unaligned_flat<tsl::tstring>().data()[0]);\n           }\n         })));"
        }
    ],
    "stats": {
        "total": 58,
        "additions": 29,
        "deletions": 29
    }
}