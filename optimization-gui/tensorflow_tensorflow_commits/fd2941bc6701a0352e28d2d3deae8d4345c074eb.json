{
    "author": "tensorflower-gardener",
    "message": "Update calls to `HloModule::CreateFromProto` in hlo_module_util to remap instruction ids by default. This should speed up compilation.\n\nPiperOrigin-RevId: 824521542",
    "sha": "fd2941bc6701a0352e28d2d3deae8d4345c074eb",
    "files": [
        {
            "sha": "b967f8ee038ff420fe0c23a7ba1dca83d8ca93e9",
            "filename": "third_party/xla/xla/service/hlo_module_util.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 5,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd2941bc6701a0352e28d2d3deae8d4345c074eb/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd2941bc6701a0352e28d2d3deae8d4345c074eb/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_util.cc?ref=fd2941bc6701a0352e28d2d3deae8d4345c074eb",
            "patch": "@@ -73,15 +73,20 @@ absl::StatusOr<std::unique_ptr<HloModule>> CreateModuleFromProto(\n   TF_ASSIGN_OR_RETURN(\n       HloModuleConfig config,\n       HloModule::CreateModuleConfigFromProto(proto, debug_options));\n-  return HloModule::CreateFromProto(proto, config);\n+  return HloModule::CreateFromProto(proto, config,\n+                                    /*buffer_assignment_proto=*/nullptr,\n+                                    /*preserve_instruction_ids=*/false);\n }\n \n absl::StatusOr<std::unique_ptr<HloModule>> CreateModuleFromProto(\n     const HloModuleProto& proto, const HloModuleConfig& module_config,\n     bool is_module_post_optimizations) {\n   VLOG(4) << proto.ShortDebugString();\n-  TF_ASSIGN_OR_RETURN(std::unique_ptr<HloModule> module,\n-                      HloModule::CreateFromProto(proto, module_config));\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<HloModule> module,\n+      HloModule::CreateFromProto(proto, module_config,\n+                                 /*buffer_assignment_proto=*/nullptr,\n+                                 /*preserve_instruction_ids=*/false));\n   TF_RETURN_IF_ERROR(\n       HloVerifier(/*layout_sensitive=*/false,\n                   /*allow_mixed_precision=*/is_module_post_optimizations)\n@@ -133,7 +138,9 @@ absl::StatusOr<std::unique_ptr<HloModule>> ReadModuleFromModuleBinaryProtofile(\n       HloModuleConfig module_config,\n       HloModule::CreateModuleConfigFromProto(module_proto, debug_options));\n \n-  return HloModule::CreateFromProto(module_proto, module_config);\n+  return HloModule::CreateFromProto(module_proto, module_config,\n+                                    /*buffer_assignment_proto=*/nullptr,\n+                                    /*preserve_instruction_ids=*/false);\n }\n \n absl::StatusOr<std::unique_ptr<HloModule>> ReadModuleFromModuleTextProtoFile(\n@@ -146,7 +153,9 @@ absl::StatusOr<std::unique_ptr<HloModule>> ReadModuleFromModuleTextProtoFile(\n       HloModuleConfig module_config,\n       HloModule::CreateModuleConfigFromProto(module_proto, debug_options));\n \n-  return HloModule::CreateFromProto(module_proto, module_config);\n+  return HloModule::CreateFromProto(module_proto, module_config,\n+                                    /*buffer_assignment_proto=*/nullptr,\n+                                    /*preserve_instruction_ids=*/false);\n }\n \n absl::StatusOr<std::unique_ptr<HloModuleConfig>> CreateModuleConfig("
        },
        {
            "sha": "177a38072140e3f4fbdac3e10af4e07ff4d47bb4",
            "filename": "third_party/xla/xla/tools/multihost_hlo_runner/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd2941bc6701a0352e28d2d3deae8d4345c074eb/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd2941bc6701a0352e28d2d3deae8d4345c074eb/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2FBUILD?ref=fd2941bc6701a0352e28d2d3deae8d4345c074eb",
            "patch": "@@ -256,6 +256,7 @@ xla_test(\n         \"//xla:status_macros\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:filecheck\",\n         \"//xla/pjrt:pjrt_client\",\n         \"//xla/pjrt:pjrt_executable\","
        },
        {
            "sha": "87c1a95970800058e8ab51861ae8e7fbb1582e8a",
            "filename": "third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner_test.cc",
            "status": "modified",
            "additions": 73,
            "deletions": 0,
            "changes": 73,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd2941bc6701a0352e28d2d3deae8d4345c074eb/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Ffunctional_hlo_runner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd2941bc6701a0352e28d2d3deae8d4345c074eb/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Ffunctional_hlo_runner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Ffunctional_hlo_runner_test.cc?ref=fd2941bc6701a0352e28d2d3deae8d4345c074eb",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include \"xla/tools/multihost_hlo_runner/functional_hlo_runner.h\"\n \n+#include <cstdint>\n #include <cstdlib>\n #include <memory>\n #include <random>\n@@ -33,6 +34,8 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"absl/time/time.h\"\n #include \"xla/debug_options_flags.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/testlib/filecheck.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_executable.h\"\n@@ -62,6 +65,11 @@ limitations under the License.\n namespace xla {\n namespace {\n \n+using ::testing::Each;\n+using ::testing::ElementsAre;\n+using ::testing::Eq;\n+using ::testing::Lt;\n+using ::testing::Property;\n using ::testing::SizeIs;\n using ::tsl::testing::IsOkAndHolds;\n using ::tsl::testing::StatusIs;\n@@ -795,6 +803,71 @@ TEST_F(FunctionalHloRunnerTest, ReadHloUnoptimizedSnapshot) {\n            hlo_module_and_arguments_from_binary.arguments.size());\n }\n \n+TEST_F(FunctionalHloRunnerTest,\n+       ReadHloModuleProtoDoesNotPreserveInstructionIds) {\n+  std::string path_to_text_hlo =\n+      GetHloPath(\"sharded_unoptimized_hlo_snapshot.pbtxt\");\n+\n+  tsl::Env* env = tsl::Env::Default();\n+\n+  // Read the text proto\n+  HloUnoptimizedSnapshot message;\n+  TF_ASSERT_OK(tsl::ReadTextProto(env, path_to_text_hlo, &message));\n+\n+  // Manually modify instruction ids in the proto.\n+  int64_t instruction_id_offset = 1000;\n+  for (HloComputationProto& computation :\n+       *message.mutable_hlo_module()->mutable_computations()) {\n+    for (HloInstructionProto& instruction :\n+         *computation.mutable_instructions()) {\n+      instruction.set_id(instruction.id() + instruction_id_offset);\n+      for (int64_t& operand_id : *instruction.mutable_operand_ids()) {\n+        operand_id += instruction_id_offset;\n+      }\n+    }\n+    computation.set_root_id(computation.root_id() + instruction_id_offset);\n+  }\n+\n+  // Dump message in the custom binary format\n+  std::string path_to_binary_hlo =\n+      tsl::io::JoinPath(std::getenv(\"TEST_UNDECLARED_OUTPUTS_DIR\"),\n+                        \"sharded_unoptimized_hlo_snapshot_modified_ids.pb\");\n+\n+  std::unique_ptr<tsl::WritableFile> file;\n+  TF_ASSERT_OK(env->NewWritableFile(path_to_binary_hlo, &file));\n+\n+  tsl::WritableFileCopyingOutputStream output(file.get());\n+\n+  tsl::protobuf::io::CopyingOutputStreamAdaptor adaptor(&output);\n+  EXPECT_TRUE(message.SerializeToZeroCopyStream(&adaptor));\n+  adaptor.Flush();\n+\n+  TF_ASSERT_OK(file->Close());\n+\n+  // Read HloModuleAndArguments from binary dump.\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      HloModuleAndArguments hlo_module_and_arguments_from_binary,\n+      FunctionalHloRunner::LoadHloModuleAndArguments(\n+          path_to_binary_hlo, InputFormat::kUnoptimizedSnapshotProtoBinary));\n+\n+  // Check if ids have been re-assigned in a compact way\n+  HloComputation* entry_computation =\n+      hlo_module_and_arguments_from_binary.hlo_module->entry_computation();\n+\n+  EXPECT_THAT(entry_computation->instructions(),\n+              ElementsAre(Property(&HloInstruction::local_id, Eq(0)),\n+                          Property(&HloInstruction::local_id, Eq(1)),\n+                          Property(&HloInstruction::local_id, Eq(2)),\n+                          Property(&HloInstruction::local_id, Eq(3))));\n+\n+  // Check that all operand ids are also within the re-assigned range.\n+  EXPECT_THAT(entry_computation->instructions(),\n+              Each(Property(&HloInstruction::operands,\n+                            Each(Property(&HloInstruction::local_id, Lt(4))))));\n+\n+  EXPECT_THAT(entry_computation->root_instruction()->local_id(), Eq(3));\n+}\n+\n TEST_F(FunctionalHloRunnerTest, FixFakeArguments) {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::PjRtClient> client,\n                           GetPjRtClient());"
        }
    ],
    "stats": {
        "total": 93,
        "additions": 88,
        "deletions": 5
    }
}