{
    "author": "ermilovmaxim",
    "message": "Add proto serialization for CollectivePermuteStartThunk\n\nPiperOrigin-RevId: 847846872",
    "sha": "b7650e843bf5d4ea5596a320cf750416c11df6fa",
    "files": [
        {
            "sha": "c89ff9384af67898c5b5e838f3b70e4eb83f18c2",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=b7650e843bf5d4ea5596a320cf750416c11df6fa",
            "patch": "@@ -1634,6 +1634,7 @@ cc_library(\n         \"//xla/core/collectives:rank_id\",\n         \"//xla/hlo/ir:collective_op_group_mode\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:buffer_assignment\",\n         \"//xla/service:computation_placer\",\n         \"//xla/service:rendezvous\",\n         \"//xla/service/gpu:backend_configs_cc\",\n@@ -1643,6 +1644,7 @@ cc_library(\n         \"//xla/stream_executor:stream\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:status_macros\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:core_headers\",\n@@ -1691,6 +1693,8 @@ xla_test(\n         \"//xla/tests:hlo_test_base\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n         \"@com_google_googletest//:gtest_main\",\n         \"@local_tsl//tsl/platform:casts\",\n     ],\n@@ -2922,6 +2926,7 @@ cc_library(\n         \":all_gather_thunk\",\n         \":all_reduce_thunk\",\n         \":all_to_all_thunk\",\n+        \":collective_permute_thunk\",\n         \":collective_thunk\",\n         \":conditional_thunk\",\n         \":convolution_reorder_thunk\","
        },
        {
            "sha": "469086398b05a66ac3a87c53d8be456ced702742",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.cc",
            "status": "modified",
            "additions": 101,
            "deletions": 3,
            "changes": 104,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc?ref=b7650e843bf5d4ea5596a320cf750416c11df6fa",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/time/time.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/collectives/gpu_communicator.h\"\n@@ -46,6 +47,7 @@ limitations under the License.\n #include \"xla/hlo/ir/collective_op_group_mode.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/transforms/collectives/collective_ops_utils.h\"\n #include \"xla/service/rendezvous.h\"\n@@ -56,6 +58,7 @@ limitations under the License.\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n #include \"tsl/platform/casts.h\"\n+#include \"xla/tsl/platform/status_macros.h\"\n \n namespace xla {\n namespace gpu {\n@@ -90,9 +93,22 @@ CollectivePermuteStartThunk::CollectivePermuteStartThunk(\n     int64_t replica_count, int64_t partition_count,\n     const std::vector<Buffer>& buffers, bool p2p_memcpy_enabled,\n     AsyncStreamKind stream_kind)\n-    : CollectiveThunk(Thunk::kCollectivePermuteStart, thunk_info,\n-                      IsGPUSyncCollective(*instr), stream_kind),\n-      config_(GetP2PConfig(instr, replica_count, partition_count)),\n+    : CollectivePermuteStartThunk(\n+          std::move(thunk_info),\n+          GetP2PConfig(instr, replica_count, partition_count),\n+          IsGPUSyncCollective(*instr)\n+              ? nullptr\n+              : std::make_shared<CollectiveThunk::AsyncEvents>(),\n+          buffers, p2p_memcpy_enabled, stream_kind) {}\n+\n+CollectivePermuteStartThunk::CollectivePermuteStartThunk(\n+    ThunkInfo thunk_info, const P2PConfig& config,\n+    std::shared_ptr<AsyncEvents> async_events,\n+    const std::vector<Buffer>& buffers, bool p2p_memcpy_enabled,\n+    AsyncStreamKind stream_kind)\n+    : CollectiveThunk(Thunk::kCollectivePermuteStart, thunk_info, async_events,\n+                      stream_kind),\n+      config_(config),\n       buffers_(buffers),\n       p2p_memcpy_enabled_(p2p_memcpy_enabled) {}\n \n@@ -230,6 +246,88 @@ bool operator==(const CallRendezvousKey& a, const CallRendezvousKey& b) {\n   return a.run_id == b.run_id;\n }\n \n+absl::StatusOr<std::unique_ptr<CollectivePermuteStartThunk>>\n+CollectivePermuteStartThunk::FromProto(\n+    ThunkInfo thunk_info, const CollectivePermuteStartThunkProto& thunk_proto,\n+    absl::Span<const BufferAllocation> buffer_allocations,\n+    CollectiveThunk::AsyncEventsMap& async_events_map) {\n+  std::vector<CollectiveThunk::Buffer> buffers;\n+  buffers.reserve(thunk_proto.buffers_size());\n+  for (const CollectiveBufferProto& proto : thunk_proto.buffers()) {\n+    ASSIGN_OR_RETURN(\n+        CollectiveThunk::Buffer buffer,\n+        CollectiveThunk::Buffer::FromProto(proto, buffer_allocations));\n+    buffers.push_back(buffer);\n+  }\n+\n+  std::shared_ptr<CollectiveThunk::AsyncEvents> async_events;\n+  if (thunk_proto.has_async_events_unique_id()) {\n+    std::shared_ptr<CollectiveThunk::AsyncEvents>& events =\n+        async_events_map[AsyncEventsUniqueId{\n+            thunk_proto.async_events_unique_id()}];\n+    if (!events) {\n+      events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+    }\n+    async_events = events;\n+  }\n+\n+  CollectiveConfig config =\n+      CollectiveConfig::FromProto(thunk_proto.collective_config());\n+\n+  P2PConfig::IdToSourceTargetMap id_to_source_target;\n+  for (const SourceTarget& source_target : thunk_proto.source_target_pairs()) {\n+    id_to_source_target.insert({source_target.target(), {}})\n+        .first->second.source = source_target.source();\n+    id_to_source_target.insert({source_target.source(), {}})\n+        .first->second.target = source_target.target();\n+  }\n+\n+  return std::make_unique<CollectivePermuteStartThunk>(\n+      std::move(thunk_info), P2PConfig{config, std::move(id_to_source_target)},\n+      async_events, std::move(buffers), thunk_proto.p2p_memcpy_enabled(),\n+      thunk_proto.async_stream_kind());\n+}\n+\n+absl::StatusOr<ThunkProto> CollectivePermuteStartThunk::ToProto() const {\n+  CHECK_EQ(config_.validation_kind, P2PConfig::ValidationKind::kValid);\n+  CHECK(config_.source_target_to_bounds.empty());\n+\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+\n+  CollectivePermuteStartThunkProto* thunk_proto =\n+      proto.mutable_collective_permute_start_thunk();\n+\n+  std::optional<AsyncEventsUniqueId> async_events_id = GetAsyncEventsUniqueId();\n+  if (async_events_id.has_value()) {\n+    thunk_proto->set_async_events_unique_id(async_events_id->value());\n+  }\n+\n+  for (const Buffer& buffer : buffers_) {\n+    ASSIGN_OR_RETURN(*thunk_proto->add_buffers(), buffer.ToProto());\n+  }\n+\n+  *thunk_proto->mutable_collective_config() = config_.config.ToProto();\n+  thunk_proto->set_p2p_memcpy_enabled(p2p_memcpy_enabled_);\n+\n+  std::vector<SourceTarget> source_target_pairs;\n+  source_target_pairs.reserve(config_.id_to_source_target.size() / 2);\n+  for (const auto& [key_id, map_entry] : config_.id_to_source_target) {\n+    SourceTarget pair;\n+    if (!map_entry.source.has_value()) {\n+      // Same pair is in the map with target/source switched.\n+      continue;\n+    }\n+    pair.set_source(*map_entry.source);\n+    pair.set_target(key_id);\n+    source_target_pairs.push_back(pair);\n+  }\n+  thunk_proto->mutable_source_target_pairs()->Assign(\n+      source_target_pairs.begin(), source_target_pairs.end());\n+\n+  return proto;\n+}\n+\n absl::StatusOr<bool> CollectivePermuteStartThunk::RunCollective(\n     const ExecuteParams& params, const GpuCliqueKey& clique_key,\n     se::Stream& stream, Communicator& comm) {"
        },
        {
            "sha": "c24369f2d85dbcaf4ad4c973a5eda2721d79c528",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.h",
            "status": "modified",
            "additions": 21,
            "deletions": 8,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.h?ref=b7650e843bf5d4ea5596a320cf750416c11df6fa",
            "patch": "@@ -1,4 +1,5 @@\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n+#include \"xla/service/buffer_assignment.h\"\n /* Copyright 2021 The OpenXLA Authors.\n \n Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -92,6 +93,18 @@ class CollectivePermuteStartThunk : public CollectiveThunk {\n         ABSL_GUARDED_BY(mutex_);\n   };\n \n+  CollectivePermuteStartThunk(ThunkInfo thunk_info,\n+                              const HloCollectivePermuteInstruction* instr,\n+                              int64_t replica_count, int64_t partition_count,\n+                              const std::vector<Buffer>& buffers,\n+                              bool p2p_memcpy_enabled,\n+                              AsyncStreamKind stream_kind);\n+  CollectivePermuteStartThunk(ThunkInfo thunk_info, const P2PConfig& config,\n+                              std::shared_ptr<AsyncEvents> async_events,\n+                              const std::vector<Buffer>& buffers,\n+                              bool p2p_memcpy_enabled,\n+                              AsyncStreamKind stream_kind);\n+\n   static P2PConfig GetP2PConfig(const HloCollectivePermuteInstruction* instr,\n                                 int64_t replica_count, int64_t partition_count);\n \n@@ -101,23 +114,23 @@ class CollectivePermuteStartThunk : public CollectiveThunk {\n   static CollectiveOpGroupMode GetGroupMode(\n       const HloCollectivePermuteInstruction* instr);\n \n-  CollectivePermuteStartThunk(ThunkInfo thunk_info,\n-                              const HloCollectivePermuteInstruction* instr,\n-                              int64_t replica_count, int64_t partition_count,\n-                              const std::vector<Buffer>& buffers,\n-                              bool p2p_memcpy_enabled,\n-                              AsyncStreamKind stream_kind);\n-\n   absl::Status Initialize(const InitializeParams& params) override;\n \n-  static const char* GetHloOpName() { return \"collective-permute-start\"; }\n+  static absl::string_view GetHloOpName() { return \"collective-permute-start\"; }\n \n   const CollectiveConfig& config() const override { return config_.config; }\n \n   absl::Span<const Buffer> buffers() const { return buffers_; }\n \n   const P2PConfig& p2p_config() const { return config_; }\n \n+  static absl::StatusOr<std::unique_ptr<CollectivePermuteStartThunk>> FromProto(\n+      ThunkInfo thunk_info, const CollectivePermuteStartThunkProto& thunk_proto,\n+      absl::Span<const BufferAllocation> buffer_allocations,\n+      CollectiveThunk::AsyncEventsMap& async_events_map);\n+\n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n  protected:\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n                                      const GpuCliqueKey& clique_key,"
        },
        {
            "sha": "e6796e68525e88c9c00e2936d3187d997ae98b31",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk_test.cc",
            "status": "modified",
            "additions": 77,
            "deletions": 0,
            "changes": 77,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk_test.cc?ref=b7650e843bf5d4ea5596a320cf750416c11df6fa",
            "patch": "@@ -46,6 +46,8 @@ limitations under the License.\n #include \"xla/tests/hlo_test_base.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n #include \"tsl/platform/casts.h\"\n@@ -55,6 +57,7 @@ namespace {\n \n using ::testing::ElementsAre;\n using Kind = Thunk::Kind;\n+using ::tsl::proto_testing::EqualsProto;\n \n class GpuCollectivePermuteTest : public HloTestBase {};\n \n@@ -212,5 +215,79 @@ ENTRY test_computation {\n   EXPECT_THAT(kinds, ElementsAre(Kind::kReplicaId, Kind::kKernel,\n                                  Kind::kCollectivePermuteStart));\n }\n+\n+TEST(CollectiveThunkTest, ProtoRoundTrip) {\n+  ThunkProto proto = tsl::proto_testing::ParseTextProtoOrDie<ThunkProto>(\n+      R\"pb(\n+        thunk_info {\n+          profile_annotation: \"partition_id_profile_annotation\"\n+          execution_stream_id: 2\n+        }\n+        collective_permute_start_thunk {\n+          async_events_unique_id: 3\n+          collective_config {}\n+          p2p_memcpy_enabled: true\n+          async_stream_kind: ASYNC_STREAM_KIND_COLLECTIVE\n+          source_target_pairs: { source: 1 target: 2 }\n+        }\n+      )pb\");\n+\n+  Thunk::ThunkInfo thunk_info;\n+  thunk_info.profile_annotation = proto.thunk_info().profile_annotation();\n+  thunk_info.execution_stream_id = xla::gpu::ExecutionStreamId{\n+      static_cast<xla::gpu::ExecutionStreamId::ValueType>(\n+          proto.thunk_info().execution_stream_id())};\n+\n+  CollectiveThunk::AsyncEventsMap async_events_map;\n+  std::vector<BufferAllocation> buffer_allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/4, /*color=*/0)};\n+\n+  ASSERT_OK_AND_ASSIGN(std::unique_ptr<CollectivePermuteStartThunk> thunk,\n+                       CollectivePermuteStartThunk::FromProto(\n+                           thunk_info, proto.collective_permute_start_thunk(),\n+                           buffer_allocations, async_events_map));\n+  ASSERT_NE(thunk->async_events(), nullptr);\n+\n+  ASSERT_OK_AND_ASSIGN(ThunkProto round_trip_proto, thunk->ToProto());\n+\n+  // Ids are unique and expected to differ.\n+  proto.mutable_collective_permute_start_thunk()->set_async_events_unique_id(\n+      round_trip_proto.collective_permute_start_thunk()\n+          .async_events_unique_id());\n+  EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n+}\n+\n+TEST(CollectiveThunkTest, SyncCollective) {\n+  ThunkProto proto = tsl::proto_testing::ParseTextProtoOrDie<ThunkProto>(\n+      R\"pb(\n+        thunk_info {\n+          profile_annotation: \"partition_id_profile_annotation\"\n+          execution_stream_id: 2\n+        }\n+        collective_permute_start_thunk {\n+          collective_config {}\n+          p2p_memcpy_enabled: true\n+          async_stream_kind: ASYNC_STREAM_KIND_COLLECTIVE\n+          source_target_pairs: { source: 1 target: 2 }\n+        }\n+      )pb\");\n+\n+  Thunk::ThunkInfo thunk_info;\n+  thunk_info.profile_annotation = proto.thunk_info().profile_annotation();\n+  thunk_info.execution_stream_id = xla::gpu::ExecutionStreamId{\n+      static_cast<xla::gpu::ExecutionStreamId::ValueType>(\n+          proto.thunk_info().execution_stream_id())};\n+\n+  CollectiveThunk::AsyncEventsMap async_events_map;\n+  std::vector<BufferAllocation> buffer_allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/4, /*color=*/0)};\n+\n+  ASSERT_OK_AND_ASSIGN(std::unique_ptr<CollectivePermuteStartThunk> thunk,\n+                       CollectivePermuteStartThunk::FromProto(\n+                           thunk_info, proto.collective_permute_start_thunk(),\n+                           buffer_allocations, async_events_map));\n+  ASSERT_EQ(thunk->async_events(), nullptr);\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "8cc71ce2e0b8d5c6b00c4a2318f00d9bcc04b326",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=b7650e843bf5d4ea5596a320cf750416c11df6fa",
            "patch": "@@ -446,6 +446,17 @@ message RaggedAllToAllStartThunkProto {\n   bool one_shot_kernel_enabled = 7;\n }\n \n+message CollectivePermuteStartThunkProto {\n+  optional uint64 async_events_unique_id = 1;\n+  repeated CollectiveBufferProto buffers = 2;\n+\n+  CollectiveConfigProto collective_config = 3;\n+  repeated SourceTarget source_target_pairs = 4;\n+\n+  AsyncStreamKind async_stream_kind = 5;\n+  bool p2p_memcpy_enabled = 6;\n+}\n+\n message CollectiveDoneThunkProto {\n   ThunkKindProto thunk_kind = 1;\n   AsyncStreamKind async_stream_kind = 2;\n@@ -495,6 +506,7 @@ message ThunkProto {\n     AllReduceStartThunkProto all_reduce_start_thunk = 39;\n     AllToAllStartThunkProto all_to_all_start_thunk = 40;\n     RaggedAllToAllStartThunkProto ragged_all_to_all_start_thunk = 41;\n+    CollectivePermuteStartThunkProto collective_permute_start_thunk = 42;\n   }\n }\n "
        },
        {
            "sha": "86ced1a02dd418eba216507bc242e3aebc1613a6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b7650e843bf5d4ea5596a320cf750416c11df6fa/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc?ref=b7650e843bf5d4ea5596a320cf750416c11df6fa",
            "patch": "@@ -31,6 +31,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/all_gather_thunk.h\"\n #include \"xla/backends/gpu/runtime/all_reduce_thunk.h\"\n #include \"xla/backends/gpu/runtime/all_to_all_thunk.h\"\n+#include \"xla/backends/gpu/runtime/collective_permute_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/conditional_thunk.h\"\n #include \"xla/backends/gpu/runtime/convolution_reorder_thunk.h\"\n@@ -262,6 +263,10 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n       return RaggedAllToAllStartThunk::FromProto(\n           std::move(thunk_info), thunk_proto.ragged_all_to_all_start_thunk(),\n           buffer_allocations, collective_async_events_map);\n+    case ThunkProto::kCollectivePermuteStartThunk:\n+      return CollectivePermuteStartThunk::FromProto(\n+          std::move(thunk_info), thunk_proto.collective_permute_start_thunk(),\n+          buffer_allocations, collective_async_events_map);\n     default:\n       std::optional<absl::string_view> unsupported_thunk_type =\n           GetStoredThunkTypeName(thunk_proto);"
        }
    ],
    "stats": {
        "total": 232,
        "additions": 221,
        "deletions": 11
    }
}