{
    "author": "ezhulenev",
    "message": "[xla:gpu] Switch to CollectiveCliques::GetComm API\n\nPiperOrigin-RevId: 838934328",
    "sha": "fed4c901c2659e667fc2ae2f88428f259dee6191",
    "files": [
        {
            "sha": "aff4798b48e39957a1cdb71007e749c15542abd0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=fed4c901c2659e667fc2ae2f88428f259dee6191",
            "patch": "@@ -88,6 +88,7 @@ cc_library(\n         \"//xla:util\",\n         \"//xla/backends/gpu/collectives:gpu_clique_key\",\n         \"//xla/backends/gpu/collectives:gpu_collectives\",\n+        \"//xla/core/collectives:communicator\",\n         \"//xla/ffi:attribute_map\",\n         \"//xla/ffi:call_frame\",\n         \"//xla/ffi:execution_state\",\n@@ -96,6 +97,7 @@ cc_library(\n         \"//xla/hlo/evaluator:hlo_evaluator\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/runtime:buffer_use\",\n+        \"//xla/runtime:device_id\",\n         \"//xla/runtime:execution_graph\",\n         \"//xla/runtime:object_pool\",\n         \"//xla/runtime:resource_use\","
        },
        {
            "sha": "0c183f63eaba85ec2257adce0e2f79cbb96d1715",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_to_all_thunk.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 6,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc?ref=fed4c901c2659e667fc2ae2f88428f259dee6191",
            "patch": "@@ -129,11 +129,13 @@ absl::Status AllToAllStartThunk::Initialize(const InitializeParams& params) {\n         GetGpuCliqueKey(*params.collective_params, config().replica_groups,\n                         config().group_mode, stream_kind));\n \n-    TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                        GetComm(*params.collective_params,\n-                                *params.collective_cliques, clique_key));\n+    TF_ASSIGN_OR_RETURN(\n+        Communicator * comm,\n+        params.collective_cliques->GetComm(\n+            clique_key, params.collective_params->global_device_id));\n+\n+    TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm->NumRanks());\n \n-    TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm_handle.comm->NumRanks());\n     se::StreamExecutor* executor = params.executor;\n     {\n       absl::MutexLock lock(pointer_maps_mutex_);\n@@ -155,7 +157,7 @@ absl::Status AllToAllStartThunk::Initialize(const InitializeParams& params) {\n       }\n     }\n     std::optional<RankId> rank =\n-        comm_handle.clique_key.rank(params.collective_params->global_device_id);\n+        clique_key.rank(params.collective_params->global_device_id);\n     size_t chunk_element_count = buffers_[0].element_count / num_ranks;\n     TF_ASSIGN_OR_RETURN(\n         std::vector<DeviceBufferPair> device_buffers,\n@@ -184,7 +186,7 @@ absl::Status AllToAllStartThunk::Initialize(const InitializeParams& params) {\n               rendezvous_results,\n           Rendezvous<std::vector<BufferRendezvousValue>>(\n               /*name=*/\"memcpy all-to-all address population\",\n-              /*key=*/comm_handle.clique_key,\n+              /*key=*/clique_key,\n               /*value=*/buffer_rendezvous_value,\n               /*num_threads=*/num_ranks,\n               [num_ranks]("
        },
        {
            "sha": "e454338f1d9db7e7d8a5f2d1359b99d987aecad4",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_execution.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 9,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.cc?ref=fed4c901c2659e667fc2ae2f88428f259dee6191",
            "patch": "@@ -130,13 +130,4 @@ absl::StatusOr<GpuCliqueKey> GetGpuCliqueKey(\n                       std::move(participant_groups), root_device, incarnations);\n }\n \n-absl::StatusOr<CommunicatorHandle> GetComm(\n-    const CollectiveParams& params, const CollectiveCliques& collective_cliques,\n-    const GpuCliqueKey& clique_key) {\n-  TF_ASSIGN_OR_RETURN(\n-      Communicator * comm,\n-      collective_cliques.GetComm(clique_key, params.global_device_id));\n-  return CommunicatorHandle(comm, std::move(clique_key));\n-}\n-\n }  // namespace xla::gpu"
        },
        {
            "sha": "3e66d8302530b998a0fb96bf3068c0cdff205504",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_execution.h",
            "status": "modified",
            "additions": 0,
            "deletions": 7,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.h?ref=fed4c901c2659e667fc2ae2f88428f259dee6191",
            "patch": "@@ -21,7 +21,6 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n-#include \"xla/backends/gpu/runtime/collective_cliques.h\"\n #include \"xla/backends/gpu/runtime/collective_params.h\"\n #include \"xla/core/collectives/communicator.h\"\n \n@@ -50,12 +49,6 @@ absl::StatusOr<GpuCliqueKey> GetGpuCliqueKey(\n     CollectiveOpGroupMode group_mode, AsyncStreamKind stream_kind,\n     bool include_participant_groups = true);\n \n-// Returns a communicator handle for the given `clique_key` and `params` from\n-// the set of cliques acquired before the XLA:GPU execution.\n-absl::StatusOr<CommunicatorHandle> GetComm(\n-    const CollectiveParams& params, const CollectiveCliques& collective_cliques,\n-    const GpuCliqueKey& clique_key);\n-\n }  // namespace xla::gpu\n \n #endif  // XLA_BACKENDS_GPU_RUNTIME_COLLECTIVE_EXECUTION_H_"
        },
        {
            "sha": "a0b88b6cdfd87def0cfc9241a80e3643d76a61be",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 11,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=fed4c901c2659e667fc2ae2f88428f259dee6191",
            "patch": "@@ -300,9 +300,10 @@ absl::Status CollectiveThunk::ExecuteOnStream(const ExecuteParams& params) {\n       GetGpuCliqueKey(*params.collective_params, config().replica_groups,\n                       config().group_mode, stream_kind));\n \n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(*params.collective_params,\n-                              *params.collective_cliques, clique_key));\n+  TF_ASSIGN_OR_RETURN(\n+      Communicator * comm,\n+      params.collective_cliques->GetComm(\n+          clique_key, params.collective_params->global_device_id));\n \n   se::StreamExecutor* executor = params.stream->parent();\n   int64_t async_stream_idx = static_cast<int64_t>(stream_kind);\n@@ -317,16 +318,17 @@ absl::Status CollectiveThunk::ExecuteOnStream(const ExecuteParams& params) {\n     TF_RETURN_IF_ERROR(async_stream.WaitFor(params.stream));\n \n     TF_ASSIGN_OR_RETURN(is_first_rendezvous_needed,\n-                        RunCollective(params, async_stream, comm_handle));\n+                        RunCollective(params, async_stream, clique_key, comm));\n \n     // Record collective operation completion.\n     TF_ASSIGN_OR_RETURN(se::Event * event, async_events_->GetEvent(executor));\n     TF_RETURN_IF_ERROR(async_stream.RecordEvent(event));\n \n   } else {\n     // Launch collective operation on a main stream.\n-    TF_ASSIGN_OR_RETURN(is_first_rendezvous_needed,\n-                        RunCollective(params, *params.stream, comm_handle));\n+    TF_ASSIGN_OR_RETURN(\n+        is_first_rendezvous_needed,\n+        RunCollective(params, *params.stream, clique_key, comm));\n   }\n \n   // After a first execution of this instance of collective operation do a\n@@ -335,7 +337,6 @@ absl::Status CollectiveThunk::ExecuteOnStream(const ExecuteParams& params) {\n   // ahead on one rank leads to deadlocks in NCCL.\n   if (is_first_rendezvous_needed &&\n       !first_call_rendezvous_flag_.IsCompleted()) {\n-    GpuCliqueKey clique_key = comm_handle.clique_key;\n     size_t num_local_participants = clique_key.num_local_participants();\n \n     auto global_device_id = params.collective_params->global_device_id;\n@@ -381,10 +382,11 @@ absl::StatusOr<std::vector<Communicator*>> CollectiveThunk::GetCommunicators(\n       GpuCliqueKey clique_key,\n       GetGpuCliqueKey(*params.collective_params, config().replica_groups,\n                       config().group_mode, stream_kind));\n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(*params.collective_params,\n-                              *params.collective_cliques, clique_key));\n-  return std::vector<Communicator*>{comm_handle.comm};\n+  TF_ASSIGN_OR_RETURN(\n+      Communicator * comm,\n+      params.collective_cliques->GetComm(\n+          clique_key, params.collective_params->global_device_id));\n+  return std::vector<Communicator*>{comm};\n }\n \n std::string CollectiveThunk::GetDeviceString("
        },
        {
            "sha": "cc3e7976b9d674aa9fa3b5952c75522aa2648898",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.h",
            "status": "modified",
            "additions": 11,
            "deletions": 3,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h?ref=fed4c901c2659e667fc2ae2f88428f259dee6191",
            "patch": "@@ -161,9 +161,17 @@ class CollectiveThunk : public Thunk {\n   // rendezvous on the SendThunk would cause a runtime deadlock.\n   //  Send(src_target={0,1})\n   //  Recv(src_target={0,1})\n-  virtual absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n-                                             se::Stream& stream,\n-                                             CommunicatorHandle comm) = 0;\n+  virtual absl::StatusOr<bool> RunCollective(\n+      const ExecuteParams& params, se::Stream& stream,\n+      CommunicatorHandle comm_handle) = 0;\n+\n+  absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n+                                     se::Stream& stream,\n+                                     const GpuCliqueKey& clique_key,\n+                                     Communicator* comm) {\n+    return RunCollective(params, stream, CommunicatorHandle(comm, clique_key));\n+  }\n+\n   virtual const CollectiveConfig& config() const = 0;\n   virtual AsyncStreamKind GetAsyncStreamKind() const { return stream_kind_; }\n   virtual CollectiveStreamId GetAsyncStreamId() const { return stream_id_; }"
        },
        {
            "sha": "9971d1372c7bb65d7d2028a912eaa90e1227625a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 38,
            "deletions": 33,
            "changes": 71,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fed4c901c2659e667fc2ae2f88428f259dee6191/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=fed4c901c2659e667fc2ae2f88428f259dee6191",
            "patch": "@@ -46,7 +46,6 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"llvm/ADT/STLExtras.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n-#include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/runtime/all_gather_thunk.h\"\n #include \"xla/backends/gpu/runtime/all_reduce_thunk.h\"\n #include \"xla/backends/gpu/runtime/all_to_all_thunk.h\"\n@@ -62,6 +61,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/while_thunk.h\"\n+#include \"xla/core/collectives/communicator.h\"\n #include \"xla/debug_options_flags.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/ffi/call_frame.h\"\n@@ -70,6 +70,7 @@ limitations under the License.\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n #include \"xla/runtime/buffer_use.h\"\n+#include \"xla/runtime/device_id.h\"\n #include \"xla/runtime/execution_graph.h\"\n #include \"xla/runtime/resource_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n@@ -2155,15 +2156,16 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllReduceCmd::Record(\n                       config().replica_groups, config().group_mode,\n                       AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n \n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(*execute_params.collective_params,\n-                              *execute_params.collective_cliques, clique_key));\n+  TF_ASSIGN_OR_RETURN(\n+      Communicator * comm,\n+      execute_params.collective_cliques->GetComm(\n+          clique_key, execute_params.collective_params->global_device_id));\n \n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n       [&](se::Stream* stream) {\n-        return RunAllReduce(reduction_kind_, device_buffers, *stream,\n-                            comm_handle.comm, config().use_symmetric_buffer);\n+        return RunAllReduce(reduction_kind_, device_buffers, *stream, comm,\n+                            config().use_symmetric_buffer);\n       });\n }\n \n@@ -2221,16 +2223,16 @@ absl::StatusOr<const se::CommandBuffer::Command*> ReduceScatterCmd::Record(\n                       config().replica_groups, config().group_mode,\n                       AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n \n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(*execute_params.collective_params,\n-                              *execute_params.collective_cliques, clique_key));\n+  TF_ASSIGN_OR_RETURN(\n+      Communicator * comm,\n+      execute_params.collective_cliques->GetComm(\n+          clique_key, execute_params.collective_params->global_device_id));\n \n   return RecordTracedCommand(execute_params, record_params, record_action,\n                              command_buffer, [&](se::Stream* stream) {\n                                return RunReduceScatter(\n                                    reduction_kind_, device_buffers, *stream,\n-                                   comm_handle.comm,\n-                                   config().use_symmetric_buffer);\n+                                   comm, config().use_symmetric_buffer);\n                              });\n }\n \n@@ -2288,16 +2290,17 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllToAllCmd::Record(\n                       config().replica_groups, config().group_mode,\n                       AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n \n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(*execute_params.collective_params,\n-                              *execute_params.collective_cliques, clique_key));\n+  TF_ASSIGN_OR_RETURN(\n+      Communicator * comm,\n+      execute_params.collective_cliques->GetComm(\n+          clique_key, execute_params.collective_params->global_device_id));\n \n   // MemCpy case is not currently supported in CommandBuffer.\n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n       [&](se::Stream* stream) {\n-        return RunAllToAll(has_split_dimension_, device_buffers, *stream,\n-                           comm_handle.comm, config().use_symmetric_buffer);\n+        return RunAllToAll(has_split_dimension_, device_buffers, *stream, comm,\n+                           config().use_symmetric_buffer);\n       });\n }\n \n@@ -2352,14 +2355,15 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllGatherCmd::Record(\n                       config().replica_groups, config().group_mode,\n                       AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n \n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(*execute_params.collective_params,\n-                              *execute_params.collective_cliques, clique_key));\n+  TF_ASSIGN_OR_RETURN(\n+      Communicator * comm,\n+      execute_params.collective_cliques->GetComm(\n+          clique_key, execute_params.collective_params->global_device_id));\n \n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n       [&](se::Stream* stream) {\n-        return RunAllGather(device_buffers, *stream, comm_handle.comm,\n+        return RunAllGather(device_buffers, *stream, comm,\n                             config().use_symmetric_buffer);\n       });\n }\n@@ -2416,16 +2420,16 @@ CollectiveBroadcastCmd::Record(const Thunk::ExecuteParams& execute_params,\n                       config().replica_groups, config().group_mode,\n                       AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n \n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(*execute_params.collective_params,\n-                              *execute_params.collective_cliques, clique_key));\n+  TF_ASSIGN_OR_RETURN(\n+      Communicator * comm,\n+      execute_params.collective_cliques->GetComm(\n+          clique_key, execute_params.collective_params->global_device_id));\n \n-  return RecordTracedCommand(execute_params, record_params,\n-                             std::move(record_action), command_buffer,\n-                             [&](se::Stream* stream) {\n-                               return RunCollectiveBroadcast(\n-                                   device_buffers, *stream, comm_handle.comm);\n-                             });\n+  return RecordTracedCommand(\n+      execute_params, record_params, std::move(record_action), command_buffer,\n+      [&](se::Stream* stream) {\n+        return RunCollectiveBroadcast(device_buffers, *stream, comm);\n+      });\n }\n \n CommandBufferCmd::BufferUseVector CollectiveBroadcastCmd::buffers() const {\n@@ -2481,9 +2485,10 @@ absl::StatusOr<const se::CommandBuffer::Command*> CollectivePermuteCmd::Record(\n                       config().replica_groups, config().group_mode,\n                       AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n \n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(*execute_params.collective_params,\n-                              *execute_params.collective_cliques, clique_key));\n+  TF_ASSIGN_OR_RETURN(\n+      Communicator * comm,\n+      execute_params.collective_cliques->GetComm(\n+          clique_key, execute_params.collective_params->global_device_id));\n \n   std::string device_string =\n       CollectiveThunk::GetDeviceString(*execute_params.collective_params);\n@@ -2501,7 +2506,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> CollectivePermuteCmd::Record(\n       execute_params, record_params, std::move(record_action), command_buffer,\n       [&](se::Stream* stream) {\n         return RunCollectivePermute(source_target, device_buffers, *stream,\n-                                    comm_handle.comm, device_string, current_id,\n+                                    comm, device_string, current_id,\n                                     /*use_memcpy=*/false,\n                                     /*recv_ptr_map=*/nullptr,\n                                     use_symmetric_buffer);"
        }
    ],
    "stats": {
        "total": 141,
        "additions": 72,
        "deletions": 69
    }
}