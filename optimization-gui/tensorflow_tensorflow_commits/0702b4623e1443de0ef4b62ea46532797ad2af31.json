{
    "author": "ermilovmaxim",
    "message": "Add Shape to ConvolutionThunk buffer_uses\n\nModify Thunk's serialization\n\nPiperOrigin-RevId: 845987211",
    "sha": "0702b4623e1443de0ef4b62ea46532797ad2af31",
    "files": [
        {
            "sha": "eff15f7bd6646ce43ef230a43a1bddbd3886ef3f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=0702b4623e1443de0ef4b62ea46532797ad2af31",
            "patch": "@@ -505,6 +505,7 @@ cc_library(\n     srcs = [\"convolution_thunk.cc\"],\n     hdrs = [\"convolution_thunk.h\"],\n     deps = [\n+        \":shaped_slice\",\n         \":thunk\",\n         \"//xla:util\",\n         \"//xla/runtime:buffer_use\","
        },
        {
            "sha": "d6d8da0379def088a71d6914ec0e34daab611085",
            "filename": "third_party/xla/xla/backends/gpu/runtime/convolution_thunk.cc",
            "status": "modified",
            "additions": 23,
            "deletions": 20,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk.cc?ref=0702b4623e1443de0ef4b62ea46532797ad2af31",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/gpu_conv_runner.h\"\n@@ -45,8 +46,8 @@ using buffer_assignment::BufferAllocationSliceProto;\n \n absl::StatusOr<std::unique_ptr<ConvolutionThunk>> ConvolutionThunk::Create(\n     ThunkInfo thunk_info, GpuConvDescriptor descriptor,\n-    std::vector<BufferAllocation::Slice> operand_slices,\n-    std::vector<BufferAllocation::Slice> result_slices,\n+    std::vector<ShapedSlice> operand_slices,\n+    std::vector<ShapedSlice> result_slices,\n     BufferAllocation::Slice scratch_slice) {\n   TF_ASSIGN_OR_RETURN(GpuConvConfig config,\n                       GetGpuConvConfig(descriptor, /*inst_as_string=*/\"\"));\n@@ -57,11 +58,12 @@ absl::StatusOr<std::unique_ptr<ConvolutionThunk>> ConvolutionThunk::Create(\n       std::move(operand_slices), std::move(result_slices), scratch_slice));\n }\n \n-ConvolutionThunk::ConvolutionThunk(\n-    ThunkInfo thunk_info, GpuConvDescriptor descriptor, GpuConvConfig config,\n-    std::vector<BufferAllocation::Slice> operand_slices,\n-    std::vector<BufferAllocation::Slice> result_slices,\n-    BufferAllocation::Slice scratch_slice)\n+ConvolutionThunk::ConvolutionThunk(ThunkInfo thunk_info,\n+                                   GpuConvDescriptor descriptor,\n+                                   GpuConvConfig config,\n+                                   std::vector<ShapedSlice> operand_slices,\n+                                   std::vector<ShapedSlice> result_slices,\n+                                   BufferAllocation::Slice scratch_slice)\n     : Thunk(Kind::kConvolution, thunk_info),\n       operand_buffers_(std::move(operand_slices)),\n       result_buffers_(std::move(result_slices)),\n@@ -87,13 +89,15 @@ absl::Status ConvolutionThunk::ExecuteOnStream(const ExecuteParams& params) {\n \n   std::vector<se::DeviceAddressBase> operand_se_buffers, result_se_buffers;\n   operand_se_buffers.reserve(operand_buffers_.size());\n-  for (BufferAllocation::Slice buffer : operand_buffers_) {\n-    operand_se_buffers.push_back(buffer_allocations.GetDeviceAddress(buffer));\n+  for (const ShapedSlice& buffer : operand_buffers_) {\n+    operand_se_buffers.push_back(\n+        buffer_allocations.GetDeviceAddress(buffer.slice));\n   }\n \n   result_se_buffers.reserve(result_buffers_.size());\n-  for (BufferAllocation::Slice buffer : result_buffers_) {\n-    result_se_buffers.push_back(buffer_allocations.GetDeviceAddress(buffer));\n+  for (const ShapedSlice& buffer : result_buffers_) {\n+    result_se_buffers.push_back(\n+        buffer_allocations.GetDeviceAddress(buffer.slice));\n   }\n \n   se::DeviceAddressBase scratch =\n@@ -150,21 +154,20 @@ absl::StatusOr<std::unique_ptr<ConvolutionThunk>> ConvolutionThunk::FromProto(\n   TF_ASSIGN_OR_RETURN(GpuConvDescriptor descriptor,\n                       GpuConvDescriptor::FromProto(proto.conv_descriptor()));\n \n-  std::vector<BufferAllocation::Slice> operand_slices;\n+  std::vector<ShapedSlice> operand_slices;\n   operand_slices.reserve(proto.operand_buffers_size());\n-  for (const BufferAllocationSliceProto& slice_proto :\n-       proto.operand_buffers()) {\n+  for (const ShapedSliceProto& slice_proto : proto.operand_buffers()) {\n     TF_ASSIGN_OR_RETURN(\n         operand_slices.emplace_back(),\n-        BufferAllocation::Slice::FromProto(slice_proto, buffer_allocations));\n+        ShapedSlice::FromProto(slice_proto, buffer_allocations));\n   }\n \n-  std::vector<BufferAllocation::Slice> result_slices;\n+  std::vector<ShapedSlice> result_slices;\n   result_slices.reserve(proto.result_buffers_size());\n-  for (const BufferAllocationSliceProto& slice_proto : proto.result_buffers()) {\n+  for (const ShapedSliceProto& slice_proto : proto.result_buffers()) {\n     TF_ASSIGN_OR_RETURN(\n         result_slices.emplace_back(),\n-        BufferAllocation::Slice::FromProto(slice_proto, buffer_allocations));\n+        ShapedSlice::FromProto(slice_proto, buffer_allocations));\n   }\n \n   TF_ASSIGN_OR_RETURN(BufferAllocation::Slice scratch_slice,\n@@ -183,10 +186,10 @@ absl::StatusOr<ThunkProto> ConvolutionThunk::ToProto() const {\n   ConvolutionThunkProto* conv_proto = proto.mutable_convolution_thunk();\n   *conv_proto->mutable_conv_descriptor() = descriptor_.ToProto();\n \n-  for (const BufferAllocation::Slice& slice : operand_buffers_) {\n+  for (const ShapedSlice& slice : operand_buffers_) {\n     TF_ASSIGN_OR_RETURN(*conv_proto->add_operand_buffers(), slice.ToProto());\n   }\n-  for (const BufferAllocation::Slice& slice : result_buffers_) {\n+  for (const ShapedSlice& slice : result_buffers_) {\n     TF_ASSIGN_OR_RETURN(*conv_proto->add_result_buffers(), slice.ToProto());\n   }\n   TF_ASSIGN_OR_RETURN(*conv_proto->mutable_scratch_buffer(),"
        },
        {
            "sha": "72845ff25d453686d7d6b320d471ff46e8cf6563",
            "filename": "third_party/xla/xla/backends/gpu/runtime/convolution_thunk.h",
            "status": "modified",
            "additions": 11,
            "deletions": 10,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk.h?ref=0702b4623e1443de0ef4b62ea46532797ad2af31",
            "patch": "@@ -25,6 +25,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n@@ -45,8 +46,8 @@ class ConvolutionThunk : public Thunk {\n   // operand_slices should be in the same order as cudnn_call->operands().\n   static absl::StatusOr<std::unique_ptr<ConvolutionThunk>> Create(\n       ThunkInfo thunk_info, GpuConvDescriptor descriptor,\n-      std::vector<BufferAllocation::Slice> operand_slices,\n-      std::vector<BufferAllocation::Slice> result_slices,\n+      std::vector<ShapedSlice> operand_slices,\n+      std::vector<ShapedSlice> result_slices,\n       BufferAllocation::Slice scratch_slice);\n \n   ConvolutionThunk(const ConvolutionThunk&) = delete;\n@@ -58,11 +59,11 @@ class ConvolutionThunk : public Thunk {\n     BufferUses res;\n     res.reserve(operand_buffers_.size() + result_buffers_.size() + 1);\n \n-    for (const BufferAllocation::Slice& slice : operand_buffers_) {\n-      res.push_back(BufferUse::Read(slice));\n+    for (const ShapedSlice& slice : operand_buffers_) {\n+      res.push_back(BufferUse::Read(slice.slice, slice.shape));\n     }\n-    for (const BufferAllocation::Slice& slice : result_buffers_) {\n-      res.push_back(BufferUse::Write(slice));\n+    for (const ShapedSlice& slice : result_buffers_) {\n+      res.push_back(BufferUse::Write(slice.slice, slice.shape));\n     }\n     res.emplace_back(scratch_buffer_, BufferUse::MemoryAccess::kWrite,\n                      BufferUse::ContentValidity::kUndefined);\n@@ -78,12 +79,12 @@ class ConvolutionThunk : public Thunk {\n  private:\n   ConvolutionThunk(ThunkInfo thunk_info, GpuConvDescriptor descriptor,\n                    GpuConvConfig config,\n-                   std::vector<BufferAllocation::Slice> operand_slices,\n-                   std::vector<BufferAllocation::Slice> result_slices,\n+                   std::vector<ShapedSlice> operand_slices,\n+                   std::vector<ShapedSlice> result_slices,\n                    BufferAllocation::Slice scratch_slice);\n \n-  std::vector<BufferAllocation::Slice> operand_buffers_;\n-  std::vector<BufferAllocation::Slice> result_buffers_;\n+  std::vector<ShapedSlice> operand_buffers_;\n+  std::vector<ShapedSlice> result_buffers_;\n   BufferAllocation::Slice scratch_buffer_;\n   GenericConvRunner& GetOrCreateRunner(const stream_executor::Stream* stream,\n                                        bool* runner_created);"
        },
        {
            "sha": "acfdf2cd39209c72e0c16c7cfcfd179d85a26f69",
            "filename": "third_party/xla/xla/backends/gpu/runtime/convolution_thunk_test.cc",
            "status": "modified",
            "additions": 36,
            "deletions": 3,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk_test.cc?ref=0702b4623e1443de0ef4b62ea46532797ad2af31",
            "patch": "@@ -108,9 +108,42 @@ TEST(ConvolutionThunkTest, ProtoRoundTrip) {\n           output_spatial_dimensions: [ 2, 3 ]\n         }\n       }\n-      operand_buffers { offset: 0 size: 4 buffer_allocation_index: 0 }\n-      operand_buffers { offset: 0 size: 4 buffer_allocation_index: 1 }\n-      result_buffers { offset: 0 size: 4 buffer_allocation_index: 2 }\n+      operand_buffers {\n+        slice { offset: 0 size: 4 buffer_allocation_index: 0 }\n+        shape {\n+          element_type: F32\n+          dimensions: [ 1, 1, 1, 1 ]\n+          layout {\n+            minor_to_major: [ 3, 2, 1, 0 ]\n+            tail_padding_alignment_in_elements: 1\n+          }\n+          is_dynamic_dimension: [ false, false, false, false ]\n+        }\n+      }\n+      operand_buffers {\n+        slice { offset: 0 size: 4 buffer_allocation_index: 1 }\n+        shape {\n+          element_type: F32\n+          dimensions: [ 1, 1, 1, 1 ]\n+          layout {\n+            minor_to_major: [ 3, 2, 1, 0 ]\n+            tail_padding_alignment_in_elements: 1\n+          }\n+          is_dynamic_dimension: [ false, false, false, false ]\n+        }\n+      }\n+      result_buffers {\n+        slice { offset: 0 size: 4 buffer_allocation_index: 2 }\n+        shape {\n+          element_type: F32\n+          dimensions: [ 1, 1, 1, 1 ]\n+          layout {\n+            minor_to_major: [ 3, 2, 1, 0 ]\n+            tail_padding_alignment_in_elements: 1\n+          }\n+          is_dynamic_dimension: [ false, false, false, false ]\n+        }\n+      }\n       scratch_buffer { offset: 0 size: 1024 buffer_allocation_index: 3 }\n     }\n   )pb\");"
        },
        {
            "sha": "a4d08af3e7d4b303df9871a05619129335c43de1",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=0702b4623e1443de0ef4b62ea46532797ad2af31",
            "patch": "@@ -338,8 +338,8 @@ message NormThunkProto {\n \n message ConvolutionThunkProto {\n   GpuConvDescriptorProto conv_descriptor = 1;\n-  repeated xla.buffer_assignment.BufferAllocationSliceProto operand_buffers = 2;\n-  repeated xla.buffer_assignment.BufferAllocationSliceProto result_buffers = 3;\n+  repeated ShapedSliceProto operand_buffers = 2;\n+  repeated ShapedSliceProto result_buffers = 3;\n   xla.buffer_assignment.BufferAllocationSliceProto scratch_buffer = 4;\n }\n "
        },
        {
            "sha": "5c1945d05b7343126e7a275b987e91114d737272",
            "filename": "third_party/xla/xla/service/buffer_assignment.cc",
            "status": "modified",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment.cc?ref=0702b4623e1443de0ef4b62ea46532797ad2af31",
            "patch": "@@ -578,6 +578,36 @@ absl::StatusOr<BufferAllocation::Slice> BufferAssignment::GetUniqueSlice(\n   return result;\n }\n \n+absl::StatusOr<Shape> BufferAssignment::GetShapeForUniqueSlice(\n+    const HloInstruction* instruction, const ShapeIndex& index) const {\n+  VLOG(3) << \"Trying to find shape for unique slice for \" << instruction->name()\n+          << \" [\" << index << \"]\";\n+  std::optional<Shape> result;\n+  for (const HloValue* value :\n+       dataflow_analysis().GetValueSet(instruction, index).values()) {\n+    VLOG(3) << \"Examining value \" << *value;\n+    if (HasAllocation(*value)) {\n+      VLOG(3) << \"Has allocation\";\n+      if (result == std::nullopt) {\n+        result = value->shape();\n+      } else if (result != value->shape()) {\n+        return FailedPrecondition(\n+            \"Shape for instruction %s at index %s cannot \"\n+            \"be determined at compile-time.\",\n+            instruction->name(), index.ToString());\n+      }\n+    } else {\n+      VLOG(3) << \"No allocation\";\n+    }\n+  }\n+  if (result == std::nullopt) {\n+    return FailedPrecondition(\n+        \"BufferAllocation::Slice not assigned for instruction %s at index %s\",\n+        instruction->name(), index.ToString());\n+  }\n+  return *result;\n+}\n+\n absl::StatusOr<BufferAllocation::Slice>\n BufferAssignment::GetUniqueTopLevelSlice(\n     const HloInstruction* instruction) const {"
        },
        {
            "sha": "67f6cfabfde934f6ea10f26e74233c208de61999",
            "filename": "third_party/xla/xla/service/buffer_assignment.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment.h?ref=0702b4623e1443de0ef4b62ea46532797ad2af31",
            "patch": "@@ -51,6 +51,7 @@ limitations under the License.\n #include \"xla/service/hlo_value.h\"\n #include \"xla/service/logical_buffer.h\"\n #include \"xla/service/memory_space_assignment/memory_space_assignment.h\"\n+#include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n \n namespace xla {\n@@ -493,6 +494,9 @@ class BufferAssignment {\n   // the slice cannot be determined at compile time then an error is returned.\n   absl::StatusOr<BufferAllocation::Slice> GetUniqueSlice(\n       const HloInstruction* instruction, const ShapeIndex& index) const;\n+  absl::StatusOr<Shape> GetShapeForUniqueSlice(\n+      const HloInstruction* instruction, const ShapeIndex& index) const;\n+\n   // Like GetUniqueSlice but fixes the index to the top-level of the shape\n   // (index = {}).\n   absl::StatusOr<BufferAllocation::Slice> GetUniqueTopLevelSlice("
        },
        {
            "sha": "56b5c5d34f8ab2ebc8067db0b4b1bc1d5d8c36ad",
            "filename": "third_party/xla/xla/service/buffer_assignment_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fbuffer_assignment_test.cc?ref=0702b4623e1443de0ef4b62ea46532797ad2af31",
            "patch": "@@ -2504,6 +2504,10 @@ TEST_F(WhileBufferAssignmentTest, TwoForwardWhileLoops) {\n   // Verify 'weights1' and read-only use while1{1} alias.\n   EXPECT_EQ(assignment->GetUniqueSlice(weights1, {}).value(),\n             assignment->GetUniqueSlice(while1, {1}).value());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Shape shape,\n+                          assignment->GetShapeForUniqueSlice(while1, {1}));\n+  EXPECT_EQ(shape, data_shape_);\n }\n \n // Tests that two colocated buffer sets are not merged if an entry parameter"
        },
        {
            "sha": "daa3908e799508eb77735986379c6e0a1e3c5722",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=0702b4623e1443de0ef4b62ea46532797ad2af31",
            "patch": "@@ -567,6 +567,7 @@ cc_library(\n         \"//xla/tools:hlo_decomposer_lib\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:status\",\n+        \"//xla/tsl/platform:status_macros\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/protobuf:dnn_proto_cc\",\n         \"@com_google_absl//absl/container:flat_hash_map\","
        },
        {
            "sha": "2519719f9a727f54437b6a6a99d1b43ce74c5884",
            "filename": "third_party/xla/xla/service/gpu/thunk_emitter.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 9,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc?ref=0702b4623e1443de0ef4b62ea46532797ad2af31",
            "patch": "@@ -153,7 +153,6 @@ limitations under the License.\n #include \"xla/service/llvm_ir/buffer_assignment_util.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n-#include \"xla/status_macros.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/gpu/gpu_blas_lt.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n@@ -168,6 +167,7 @@ limitations under the License.\n #include \"tsl/platform/casts.h\"\n #include \"tsl/platform/human_readable_json.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n+#include \"xla/tsl/platform/status_macros.h\"\n \n namespace xla::gpu {\n namespace {\n@@ -523,21 +523,20 @@ absl::StatusOr<ThunkSequence> ThunkEmitter::EmitCommandBufferThunk(\n \n absl::StatusOr<ThunkSequence> ThunkEmitter::EmitConvolutionThunk(\n     const HloCustomCallInstruction* instr) {\n-  std::vector<BufferAllocation::Slice> operand_slices;\n+  std::vector<ShapedSlice> operand_slices;\n   operand_slices.reserve(instr->operand_count());\n   for (const HloInstruction* operand : instr->operands()) {\n-    TF_ASSIGN_OR_RETURN(BufferAllocation::Slice slice,\n-                        GetAllocationSliceForHlo(operand, {}));\n+    ASSIGN_OR_RETURN(ShapedSlice slice, GetShapedSliceForHlo(operand, {}));\n     operand_slices.push_back(slice);\n   }\n \n   // The first and the last element in the result tuple for a convolution are\n   // always the result and the scratch buffer. It may have auxiliary results in\n   // addition to the main result.\n-  std::vector<BufferAllocation::Slice> result_slices;\n+  std::vector<ShapedSlice> result_slices;\n   for (int i = 0; i < instr->shape().tuple_shapes().size() - 1; i++) {\n-    TF_ASSIGN_OR_RETURN(BufferAllocation::Slice result_slice,\n-                        GetAllocationSliceForHlo(instr, {i}));\n+    ASSIGN_OR_RETURN(ShapedSlice result_slice,\n+                     GetShapedSliceForHlo(instr, {i}));\n     result_slices.push_back(result_slice);\n   }\n \n@@ -926,8 +925,18 @@ absl::StatusOr<ThunkSequence> ThunkEmitter::EmitPtxCustomCall(\n \n absl::StatusOr<BufferAllocation::Slice> ThunkEmitter::GetAllocationSliceForHlo(\n     const HloInstruction* instr, const ShapeIndex& index) const {\n-  return xla::gpu::GetAllocationSlice(ir_emitter_context_->buffer_assignment(),\n-                                      instr, index);\n+  return ir_emitter_context_->buffer_assignment().GetUniqueSlice(instr, index);\n+}\n+\n+absl::StatusOr<ShapedSlice> ThunkEmitter::GetShapedSliceForHlo(\n+    const HloInstruction* instr, const ShapeIndex& index) const {\n+  ASSIGN_OR_RETURN(BufferAllocation::Slice slice,\n+                   GetAllocationSliceForHlo(instr, index));\n+  ASSIGN_OR_RETURN(\n+      Shape shape,\n+      ir_emitter_context_->buffer_assignment().GetShapeForUniqueSlice(instr,\n+                                                                      index));\n+  return ShapedSlice{slice, shape};\n }\n \n absl::StatusOr<ThunkSequence> ThunkEmitter::EmitCubDeviceRadixSort("
        },
        {
            "sha": "0680fa2cd9c8c2ca5a041d0301d143ccf1a23642",
            "filename": "third_party/xla/xla/service/gpu/thunk_emitter.h",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0702b4623e1443de0ef4b62ea46532797ad2af31/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.h?ref=0702b4623e1443de0ef4b62ea46532797ad2af31",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/host_send_recv_thunk.h\"\n #include \"xla/backends/gpu/runtime/nvshmem_collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n@@ -214,7 +215,9 @@ class ThunkEmitter {\n   absl::Status AssertNonDeterminismIsOkay(const std::string& op_name);\n \n   absl::StatusOr<BufferAllocation::Slice> GetAllocationSliceForHlo(\n-      const HloInstruction* hlo, const ShapeIndex& index = {}) const;\n+      const HloInstruction* instr, const ShapeIndex& index = {}) const;\n+  absl::StatusOr<ShapedSlice> GetShapedSliceForHlo(\n+      const HloInstruction* instr, const ShapeIndex& index = {}) const;\n \n   CollectivesAsyncEvents& GetCollectivesAsyncEvents() {\n     return ir_emitter_context_->collectives_async_events();"
        }
    ],
    "stats": {
        "total": 179,
        "additions": 134,
        "deletions": 45
    }
}