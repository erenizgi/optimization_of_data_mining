{
    "author": "felixwqp",
    "message": "[XLA:GPU] Change logic for enabling the heuristic collective combiner. Heuristic collective combiner is enabled when meeting\n1. HLO is compiled for platforms for A100, H100, B200\n2. AND HLO is compiled for collective communicating beyond a single NVLink domain(identified by slice_size)\n\nEnabling on these platforms because they are the platforms of interest internally at Google. Users could extend to other platform if there is clear performance gain.\n\nPiperOrigin-RevId: 802580248",
    "sha": "8863774ba434d0247a98e4d65dcc6406062ea454",
    "files": [
        {
            "sha": "e6c7127e77e04dd9d029bfe6d6f832cc71b29b8b",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 6,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8863774ba434d0247a98e4d65dcc6406062ea454/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8863774ba434d0247a98e4d65dcc6406062ea454/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=8863774ba434d0247a98e4d65dcc6406062ea454",
            "patch": "@@ -1229,12 +1229,8 @@ void AddCollectiveCombinerPasses(\n     const GpuCompiler::CompileOptions& options) {\n   const DebugOptions& opts = module.config().debug_options();\n \n-  bool enable_heuristic_collective_combining =\n-      opts.xla_gpu_experimental_enable_heuristic_collective_combining() &&\n-      !IsNVLinkConnected(module.config(), device_description,\n-                         options.slice_size);\n-\n-  if (enable_heuristic_collective_combining) {\n+  if (EnableHeuristicCollectiveCombining(module.config(), device_description,\n+                                         options.slice_size)) {\n     pipeline.AddPass<CollectiveCombinerAnnotator>(device_description,\n                                                   alias_info, pointer_size);\n   }"
        },
        {
            "sha": "87cbe7e60944aebc1ef2ecaa819366db88ccd336",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_ops_utils.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 11,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8863774ba434d0247a98e4d65dcc6406062ea454/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8863774ba434d0247a98e4d65dcc6406062ea454/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.cc?ref=8863774ba434d0247a98e4d65dcc6406062ea454",
            "patch": "@@ -163,23 +163,31 @@ absl::StatusOr<GPUCommunicationType> CommunicationType(\n   return GPUCommunicationType::UNDEFINED;\n }\n \n-bool IsNVLinkConnected(const HloModuleConfig& config,\n-                       const se::DeviceDescription& device_description,\n-                       int64_t nvlink_slice_size) {\n+bool EnableHeuristicCollectiveCombining(\n+    const HloModuleConfig& config,\n+    const se::DeviceDescription& device_description,\n+    int64_t nvlink_slice_size) {\n+  if (!config.debug_options()\n+           .xla_gpu_experimental_enable_heuristic_collective_combining()) {\n+    return false;\n+  }\n   se::CudaComputeCapability cc = device_description.cuda_compute_capability();\n-  // NVLink is only available on Ampere/Hopper/Blackwell GPUs.\n-  if (!(cc.IsHopper() || cc.IsAmpere() || cc.IsBlackwell())) {\n+  // Heuristic collective combining is not turned on before Ampere GPUs.\n+  if (!cc.IsAtLeastAmpere()) {\n     return false;\n   }\n   int hlo_device_count = config.num_partitions() * config.replica_count();\n   if (hlo_device_count <= nvlink_slice_size) {\n-    VLOG(1) << \"NVLink connected: HLO device count \" << hlo_device_count\n-            << \" <= NVLink slice size \" << nvlink_slice_size;\n-    return true;\n+    VLOG(1) << \"Disabled heuristic collective combining for intra-NVLink \"\n+               \"domain communication: HLO device count \"\n+            << hlo_device_count << \" <= NVLink slice size \"\n+            << nvlink_slice_size;\n+    return false;\n   }\n-  VLOG(1) << \"Not NVLink connected: HLO device count \" << hlo_device_count\n-          << \" > NVLink slice size \" << nvlink_slice_size;\n-  return false;\n+  VLOG(1) << \"Enabled heuristic collective combining for inter-NVLink domain \"\n+             \"communication: HLO device count \"\n+          << hlo_device_count << \" > NVLink slice size \" << nvlink_slice_size;\n+  return true;\n }\n \n }  // namespace gpu"
        },
        {
            "sha": "ee30564790b22be8eecc6cc5bfadcb21ec97a406",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_ops_utils.h",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8863774ba434d0247a98e4d65dcc6406062ea454/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8863774ba434d0247a98e4d65dcc6406062ea454/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.h?ref=8863774ba434d0247a98e4d65dcc6406062ea454",
            "patch": "@@ -48,9 +48,12 @@ enum class GPUTopologyType {\n   MULTI_HOST = 2,\n };\n \n-bool IsNVLinkConnected(const HloModuleConfig& config,\n-                       const se::DeviceDescription& device_description,\n-                       int64_t nvlink_slice_size);\n+// Returns true if heuristic collective combining is enabled.\n+// Heuristic collective combining enables more aggressive optimizations based\n+// on the platform and HLO's topology.\n+bool EnableHeuristicCollectiveCombining(\n+    const HloModuleConfig& config,\n+    const se::DeviceDescription& device_description, int64_t nvlink_slice_size);\n \n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "4ea078660717c0c60a64a50cae8d45214a442b2e",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_ops_utils_test.cc",
            "status": "modified",
            "additions": 110,
            "deletions": 62,
            "changes": 172,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8863774ba434d0247a98e4d65dcc6406062ea454/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8863774ba434d0247a98e4d65dcc6406062ea454/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils_test.cc?ref=8863774ba434d0247a98e4d65dcc6406062ea454",
            "patch": "@@ -37,84 +37,132 @@ namespace {\n using ::absl_testing::IsOkAndHolds;\n using ::testing::Test;\n \n-bool IsNVLinkConnected(se::CudaComputeCapability compute_capability,\n-                       int num_partitions, int replica_count,\n-                       int64_t nvlink_slice_size) {\n+bool EnableHeuristicCollectiveCombining(\n+    se::CudaComputeCapability compute_capability, int num_partitions,\n+    int replica_count, int64_t nvlink_slice_size) {\n   HloModuleConfig config;\n+  config.mutable_debug_options()\n+      .set_xla_gpu_experimental_enable_heuristic_collective_combining(true);\n   config.set_num_partitions(num_partitions);\n   config.set_replica_count(replica_count);\n   se::DeviceDescription device_description =\n       TestGpuDeviceInfo::RTXA6000DeviceInfo(compute_capability);\n-  return xla::gpu::IsNVLinkConnected(config, device_description,\n-                                     nvlink_slice_size);\n+  return xla::gpu::EnableHeuristicCollectiveCombining(\n+      config, device_description, nvlink_slice_size);\n }\n \n-TEST(IsNVLinkConnectedTest, SingleHostSingleDevice) {\n-  // H100/B200\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Hopper(),\n-                                /*num_partitions=*/1, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/8));\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Blackwell(),\n-                                /*num_partitions=*/1, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/8));\n+TEST(EnableHeuristicCollectiveCombiningTest, SingleHostSingleDevice) {\n+  // B200\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Blackwell(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n+  // H100\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Hopper(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n   // A100\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Ampere(),\n-                                /*num_partitions=*/1, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/16));\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Ampere(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/16));\n }\n \n-TEST(IsNVLinkConnectedTest, SingleHostMultiDevices) {\n-  // H100/B200\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Hopper(),\n-                                /*num_partitions=*/8, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/8));\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Hopper(),\n-                                /*num_partitions=*/1, /*replica_count=*/8,\n-                                /*nvlink_slice_size=*/8));\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Blackwell(),\n-                                /*num_partitions=*/8, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/8));\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Blackwell(),\n-                                /*num_partitions=*/1, /*replica_count=*/8,\n-                                /*nvlink_slice_size=*/8));\n-\n+TEST(EnableHeuristicCollectiveCombiningTest, SingleHostMultiDevices) {\n+  // B200\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Blackwell(),\n+                                         /*num_partitions=*/8,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Blackwell(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/8,\n+                                         /*nvlink_slice_size=*/8));\n+  // H100\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Hopper(),\n+                                         /*num_partitions=*/8,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Hopper(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/8,\n+                                         /*nvlink_slice_size=*/8));\n   // A100\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Ampere(),\n-                                /*num_partitions=*/1, /*replica_count=*/16,\n-                                /*nvlink_slice_size=*/16));\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Ampere(),\n-                                /*num_partitions=*/16, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/16));\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Ampere(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/16,\n+                                         /*nvlink_slice_size=*/16));\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Ampere(),\n+                                         /*num_partitions=*/16,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/16));\n }\n \n-TEST(IsNVLinkConnectedTest, MultiHosts) {\n-  // H100/B200\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Hopper(),\n-                                 /*num_partitions=*/16, /*replica_count=*/1,\n-                                 /*nvlink_slice_size=*/8));\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Hopper(),\n-                                 /*num_partitions=*/1, /*replica_count=*/16,\n-                                 /*nvlink_slice_size=*/8));\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Blackwell(),\n-                                 /*num_partitions=*/16, /*replica_count=*/1,\n-                                 /*nvlink_slice_size=*/8));\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Blackwell(),\n-                                 /*num_partitions=*/1, /*replica_count=*/16,\n-                                 /*nvlink_slice_size=*/8));\n-\n+TEST(EnableHeuristicCollectiveCombiningTest, MultiHosts) {\n+  // B200\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Blackwell(),\n+                                         /*num_partitions=*/16,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Blackwell(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/16,\n+                                         /*nvlink_slice_size=*/8));\n+  // H100\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Hopper(),\n+                                         /*num_partitions=*/16,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Hopper(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/16,\n+                                         /*nvlink_slice_size=*/8));\n   // A100\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Ampere(),\n-                                 /*num_partitions=*/1, /*replica_count=*/32,\n-                                 /*nvlink_slice_size=*/16));\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Ampere(),\n-                                 /*num_partitions=*/32, /*replica_count=*/1,\n-                                 /*nvlink_slice_size=*/16));\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Ampere(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/32,\n+                                         /*nvlink_slice_size=*/16));\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Ampere(),\n+                                         /*num_partitions=*/32,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/16));\n+}\n+\n+TEST(EnableHeuristicCollectiveCombiningTest, UnsupportedGPU) {\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Volta(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n }\n \n-TEST(IsNVLinkConnectedTest, UnsupportedGPU) {\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Volta(),\n-                                 /*num_partitions=*/1, /*replica_count=*/1,\n-                                 /*nvlink_slice_size=*/8));\n+TEST(EnableHeuristicCollectiveCombiningTest, DisabledByFlag) {\n+  HloModuleConfig config;\n+  config.mutable_debug_options()\n+      .set_xla_gpu_experimental_enable_heuristic_collective_combining(false);\n+  config.set_num_partitions(16);\n+  config.set_replica_count(1);\n+  se::DeviceDescription device_description =\n+      TestGpuDeviceInfo::RTXA6000DeviceInfo(\n+          se::CudaComputeCapability::Blackwell());\n+  EXPECT_FALSE(xla::gpu::EnableHeuristicCollectiveCombining(\n+      config, device_description, /*nvlink_slice_size=*/8));\n }\n \n class CommunicationTypeTest : public Test {"
        }
    ],
    "stats": {
        "total": 219,
        "additions": 137,
        "deletions": 82
    }
}