{
    "author": "tensorflower-gardener",
    "message": "Improve logging and error messages from autotuner.\n\n- The VLOG messages are updated to more accurately describe whether the autotuner is finding a config in cache, using a default, or actively tuning for the best config.\n- The error contains the HLO instruction.\n\nPiperOrigin-RevId: 820640768",
    "sha": "51fc1ac0d51cb963f89bddfe36cd72179d2fb6a0",
    "files": [
        {
            "sha": "6f45171b0516eae3fd3cbd7a605d6a6ec0fc3708",
            "filename": "third_party/xla/xla/backends/autotuner/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51fc1ac0d51cb963f89bddfe36cd72179d2fb6a0/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51fc1ac0d51cb963f89bddfe36cd72179d2fb6a0/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD?ref=51fc1ac0d51cb963f89bddfe36cd72179d2fb6a0",
            "patch": "@@ -41,13 +41,10 @@ cc_library(\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:executable\",\n         \"//xla/service:shaped_buffer\",\n-        \"//xla/stream_executor:device_description\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\",\n-        \"//xla/tsl/platform:status\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/util/proto:proto_utils\",\n-        \"@com_google_absl//absl/base:no_destructor\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/functional:function_ref\",\n         \"@com_google_absl//absl/log\","
        },
        {
            "sha": "2c75068410e2e7ad8a70e6b9ed9db86bfdfb4f6e",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.cc",
            "status": "modified",
            "additions": 38,
            "deletions": 23,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51fc1ac0d51cb963f89bddfe36cd72179d2fb6a0/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51fc1ac0d51cb963f89bddfe36cd72179d2fb6a0/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc?ref=51fc1ac0d51cb963f89bddfe36cd72179d2fb6a0",
            "patch": "@@ -116,33 +116,33 @@ absl::Status Autotuner::Autotune(HloModule* module,\n     VLOG(1) << \"No instructions to autotune.\";\n     return absl::OkStatus();\n   }\n-  VLOG(1) << \"Autotuning \" << instrunctions_by_fingerprint.size()\n+  VLOG(1) << \"Finding configs for \" << instrunctions_by_fingerprint.size()\n           << \" unique instructions.\";\n   for (auto& [_, instructions] : instrunctions_by_fingerprint) {\n     CHECK(!instructions.empty());\n-    VLOG(1) << \"Autotuning instruction:\" << instructions[0]->ToString();\n-    TF_ASSIGN_OR_RETURN(Config best_config, GetConfig(instructions[0]));\n-    CodegenBackend* best_codegen_backend = best_config.codegen_backend;\n+    TF_ASSIGN_OR_RETURN(Config config, GetConfig(instructions[0]));\n+    CodegenBackend* codegen_backend = config.codegen_backend;\n     for (auto* instr : instructions) {\n-      TF_RETURN_IF_ERROR(best_codegen_backend->ApplyConfig(\n-          *instr, *best_config.backend_config));\n+      TF_RETURN_IF_ERROR(\n+          codegen_backend->ApplyConfig(*instr, *config.backend_config));\n     }\n   }\n   return DumpLogsToFile();\n }\n \n absl::Status Autotuner::Autotune(HloInstruction* instr) {\n-  VLOG(1) << \"Autotuning HLO: \" << instr->ToString();\n-  TF_ASSIGN_OR_RETURN(Config best_config, GetConfig(instr));\n-  CodegenBackend* best_codegen_backend = best_config.codegen_backend;\n+  TF_ASSIGN_OR_RETURN(Config config, GetConfig(instr));\n+  CodegenBackend* codegen_backend = config.codegen_backend;\n   TF_RETURN_IF_ERROR(\n-      best_codegen_backend->ApplyConfig(*instr, *best_config.backend_config));\n+      codegen_backend->ApplyConfig(*instr, *config.backend_config));\n   return DumpLogsToFile();\n }\n \n absl::StatusOr<Autotuner::Config> Autotuner::GetConfig(HloInstruction* instr) {\n+  VLOG(1) << \"Getting config for HLO: \" << instr->ToString();\n   std::optional<Config> cached_config = LookUp(instr);\n   if (cached_config.has_value()) {\n+    VLOG(1) << \"Using cached config: \" << cached_config->ToString();\n     return std::move(cached_config.value());\n   }\n \n@@ -152,11 +152,13 @@ absl::StatusOr<Autotuner::Config> Autotuner::GetConfig(HloInstruction* instr) {\n   }\n \n   if (autotune_config_.use_default_config) {\n-    return GetDefaultConfig(*instr);\n+    TF_ASSIGN_OR_RETURN(Config default_config, GetDefaultConfig(*instr));\n+    VLOG(1) << \"Using default config: \" << default_config.ToString();\n+    return default_config;\n   }\n \n-  Config best_config;\n-  TF_ASSIGN_OR_RETURN(best_config, TuneBestConfig(instr));\n+  VLOG(1) << \"Autotuning the HLO instruction to find best config.\";\n+  TF_ASSIGN_OR_RETURN(Config best_config, TuneBestConfig(instr));\n   Insert(instr, best_config);\n   return best_config;\n }\n@@ -166,7 +168,9 @@ absl::StatusOr<Autotuner::Config> Autotuner::TuneBestConfig(\n   TF_ASSIGN_OR_RETURN(std::vector<Config> supported_configs,\n                       GetSupportedConfigs(instr));\n   if (supported_configs.empty()) {\n-    return absl::InternalError(\"No supported configs found!\");\n+    return absl::InternalError(\n+        absl::StrCat(\"Autotuner could not find any supported configs for HLO: \",\n+                     instr->ToString()));\n   }\n   VLOG(1) << \"Found \" << supported_configs.size() << \" supported configs.\";\n \n@@ -180,25 +184,30 @@ absl::StatusOr<Autotuner::Config> Autotuner::TuneBestConfig(\n           {std::move(supported_configs[i]), std::move(executables[i].value())});\n     } else {\n       VLOG(4) << \"Compilation failed for config \"\n-              << supported_configs[i].codegen_backend->name() << \" : \"\n-              << UnpackedAnyShortDebugString(\n-                     *supported_configs[i].backend_config)\n+              << supported_configs[i].ToString()\n               << \" with status: \" << executables[i].status();\n     }\n   }\n \n   if (executable_candidates.empty()) {\n-    return absl::InternalError(\"No executable candidates to profile!\");\n+    return absl::InternalError(\n+        absl::StrCat(\"Autotuner could not compile any configs for HLO: \",\n+                     instr->ToString()));\n   }\n   VLOG(1) << \"Successfully compiled \" << executable_candidates.size()\n           << \" configs out of \" << supported_configs.size() << \" configs.\";\n \n   TF_ASSIGN_OR_RETURN(std::vector<ConfigResult> results,\n                       ProfileAll(executable_candidates));\n   LogConfigResults(*instr, results);\n-  TF_ASSIGN_OR_RETURN(auto best_result, PickBestConfig(results));\n-  VLOG(1) << \"Picked best config: \" << best_result.ToString();\n-  return std::move(best_result.config);\n+  absl::StatusOr<ConfigResult> best_result = PickBestConfig(results);\n+  if (!best_result.ok()) {\n+    return absl::InternalError(\n+        absl::StrCat(\"Autotuning failed for HLO: \", instr->ToString(),\n+                     \" with error: \", best_result.status().ToString()));\n+  }\n+  VLOG(1) << \"Picked best config: \" << best_result.value().ToString();\n+  return std::move(best_result.value().config);\n }\n \n Autotuner::InstructionsByFingerprint Autotuner::GetAutotuningCandidates(\n@@ -375,7 +384,7 @@ absl::StatusOr<Autotuner::ConfigResult> Autotuner::PickBestConfig(\n   }\n \n   if (best_result == nullptr) {\n-    return absl::InternalError(\"No valid config found!\");\n+    return absl::NotFoundError(\"No valid config found!\");\n   }\n   if (autotune_config_.select_first_config) {\n     return std::move(results[0]);\n@@ -400,7 +409,8 @@ absl::StatusOr<ScopedShapedBuffer> Autotuner::GetReferenceOutput(\n       return std::move(profile_result.value().output_buffer.value());\n     }\n   }\n-  return absl::InternalError(\"No reference output found!\");\n+  return absl::NotFoundError(\n+      \"No reference output found but correctness checking is enabled!\");\n }\n \n std::optional<Autotuner::Failure> Autotuner::CheckBuffers(\n@@ -519,4 +529,9 @@ AutotuneResult Autotuner::ConfigResult::ToProto() const {\n   return result;\n }\n \n+std::string Autotuner::Config::ToString() const {\n+  return absl::StrFormat(\"%s : %s\", codegen_backend->name(),\n+                         UnpackedAnyShortDebugString(*backend_config));\n+}\n+\n }  // namespace xla"
        },
        {
            "sha": "5c9472f59b6d7db9fb0271dd869a2da79b7798ad",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51fc1ac0d51cb963f89bddfe36cd72179d2fb6a0/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51fc1ac0d51cb963f89bddfe36cd72179d2fb6a0/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h?ref=51fc1ac0d51cb963f89bddfe36cd72179d2fb6a0",
            "patch": "@@ -111,6 +111,8 @@ class Autotuner {\n   struct Config {\n     CodegenBackend* codegen_backend;\n     std::unique_ptr<BackendConfig> backend_config;\n+\n+    std::string ToString() const;\n   };\n   struct ExecutableCandidate {\n     Config config;"
        }
    ],
    "stats": {
        "total": 66,
        "additions": 40,
        "deletions": 26
    }
}