{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 845682254",
    "sha": "8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f",
    "files": [
        {
            "sha": "6b888ab759ddcdce59773fb8c88b16ec620bea42",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc?ref=8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f",
            "patch": "@@ -52,13 +52,13 @@ class BufferDebugLogTest : public ::testing::Test {\n     TF_ASSERT_OK_AND_ASSIGN(executor_, platform_->ExecutorForDevice(0));\n     TF_ASSERT_OK_AND_ASSIGN(stream_, executor_->CreateStream(std::nullopt));\n     allocator_ =\n-        std::make_unique<StreamExecutorMemoryAllocator>(stream_->parent());\n+        std::make_unique<StreamExecutorAddressAllocator>(stream_->parent());\n   }\n \n   Platform* platform_;\n   StreamExecutor* executor_;\n   std::unique_ptr<Stream> stream_;\n-  std::unique_ptr<StreamExecutorMemoryAllocator> allocator_;\n+  std::unique_ptr<StreamExecutorAddressAllocator> allocator_;\n };\n \n TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_InitializesEmptyLog) {"
        },
        {
            "sha": "b038ecc139d9219d79406e1ebe55861fe1b0abef",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_executor_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor_test.cc?ref=8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f",
            "patch": "@@ -42,8 +42,8 @@ using GetPointerMemorySpaceTest = GpuExecutorTest;\n TEST_F(GetPointerMemorySpaceTest, Host) {\n   StreamExecutor* executor = GetPlatform()->ExecutorForDevice(0).value();\n   TF_ASSERT_OK_AND_ASSIGN(auto host_ptr, executor->HostMemoryAllocate(64));\n-  TF_ASSERT_OK_AND_ASSIGN(auto memory_space,\n-                          executor->GetPointerMemorySpace(host_ptr->opaque()));\n+  TF_ASSERT_OK_AND_ASSIGN(auto memory_space, executor->GetPointerMemorySpace(\n+                                                 host_ptr->address().opaque()));\n   EXPECT_EQ(memory_space, MemorySpace::kHost);\n }\n \n@@ -82,8 +82,9 @@ TEST_F(HostMemoryAllocateTest, Numa) {\n     TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<MemoryAllocation> host_ptr,\n                             executor->HostMemoryAllocate(kSize));\n     ASSERT_TRUE(host_ptr);\n-    EXPECT_NE(host_ptr->opaque(), nullptr);\n-    const int numa_node = tsl::port::NUMAGetMemAffinity(host_ptr->opaque());\n+    EXPECT_NE(host_ptr->address().opaque(), nullptr);\n+    const int numa_node =\n+        tsl::port::NUMAGetMemAffinity(host_ptr->address().opaque());\n     if (numa_node == tsl::port::kNUMANoAffinity) {\n       // Could be because `executor` could not determine its own NUMA node, in\n       // which case numa_node() will be -1 or 0, depending on the failure mode."
        },
        {
            "sha": "87dec701c5b2de049796b663eb2324b424481bfa",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_semaphore.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_semaphore.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_semaphore.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_semaphore.cc?ref=8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f",
            "patch": "@@ -35,6 +35,6 @@ DeviceAddress<GpuSemaphoreState> GpuSemaphore::device() {\n   // This assumes unified addressing, as we do not explicitly translate the\n   // host pointer into a device pointer.\n   return DeviceAddress<GpuSemaphoreState>::MakeFromByteSize(\n-      ptr_->opaque(), sizeof(GpuSemaphoreState));\n+      ptr_->address().opaque(), sizeof(GpuSemaphoreState));\n }\n }  // namespace stream_executor"
        },
        {
            "sha": "e7f34b002644341022ce5921a90b69e4264a2ff3",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_semaphore.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_semaphore.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_semaphore.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_semaphore.h?ref=8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f",
            "patch": "@@ -42,7 +42,7 @@ class GpuSemaphore {\n   explicit operator bool() const { return bool{ptr_}; }\n \n   GpuSemaphoreState& operator*() {\n-    return *static_cast<GpuSemaphoreState*>(ptr_->opaque());\n+    return *static_cast<GpuSemaphoreState*>(ptr_->address().opaque());\n   }\n   DeviceAddress<GpuSemaphoreState> device();\n "
        },
        {
            "sha": "4a94fe0d821fefa83059e2fa7d7f75c047c2e35d",
            "filename": "third_party/xla/xla/stream_executor/gpu/memcpy_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fmemcpy_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fmemcpy_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fmemcpy_test.cc?ref=8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f",
            "patch": "@@ -33,7 +33,7 @@ TEST(MemcpyTest, PinnedHostMemory) {\n \n   TF_ASSERT_OK_AND_ASSIGN(auto d_ptr,\n                           executor->HostMemoryAllocate(sizeof(int)));\n-  DeviceAddressBase d_mem(d_ptr->opaque(), sizeof(int));\n+  DeviceAddressBase d_mem(d_ptr->address().opaque(), sizeof(int));\n \n   int h_ptr;\n   TF_ASSERT_OK(stream->Memcpy(&h_ptr, d_mem, d_mem.size()));"
        },
        {
            "sha": "9d6fc02bdeb14e139beab89aa1b5cf208ba2d4de",
            "filename": "third_party/xla/xla/stream_executor/gpu/redzone_allocator.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fredzone_allocator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fredzone_allocator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fredzone_allocator.cc?ref=8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f",
            "patch": "@@ -85,7 +85,7 @@ absl::StatusOr<DeviceAddress<uint8_t>> RedzoneAllocator::AllocateBytes(\n \n   int64_t rhs_slop = RoundUpToNearest(byte_size, kRhsRedzoneAlign) - byte_size;\n   TF_ASSIGN_OR_RETURN(\n-      OwningDeviceAddress allocated_buffer,\n+      ScopedDeviceAddress<uint8_t> allocated_buffer,\n       memory_allocator_->Allocate(device_ordinal_,\n                                   byte_size + 2 * redzone_size_ + rhs_slop,\n                                   /*retry_on_failure=*/false));\n@@ -277,13 +277,13 @@ absl::StatusOr<RedzoneCheckStatus> RedzoneAllocator::CheckRedzones() const {\n \n   DeviceAddressHandle out_param(executor, executor->AllocateScalar<uint64_t>());\n   TF_RETURN_IF_ERROR(\n-      stream_->MemZero(out_param.memory_ptr(), sizeof(uint64_t)));\n+      stream_->MemZero(out_param.address_ptr(), sizeof(uint64_t)));\n \n   for (const auto& buf_and_size : allocated_buffers_) {\n     TF_ASSIGN_OR_RETURN(\n         RedzoneCheckStatus redzone_status,\n         CheckRedzonesForBuffer(stream_, *buf_and_size.first,\n-                               DeviceAddress<uint64_t>(out_param.memory()),\n+                               DeviceAddress<uint64_t>(out_param.address()),\n                                kernel, buf_and_size.second, redzone_size_,\n                                redzone_pattern_));\n     if (!redzone_status.ok()) {"
        },
        {
            "sha": "22e6953225fbfef26f598713df718ec4b6c71fb5",
            "filename": "third_party/xla/xla/stream_executor/gpu/redzone_allocator.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fredzone_allocator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fredzone_allocator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fredzone_allocator.h?ref=8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f",
            "patch": "@@ -136,7 +136,8 @@ class RedzoneAllocator : public ScratchAllocator {\n   //\n   // ScratchAllocators need to free all allocated memory on destruction so we\n   // use `OwningDeviceAddress` here.\n-  std::vector<std::pair<OwningDeviceAddress, int64_t>> allocated_buffers_;\n+  std::vector<std::pair<ScopedDeviceAddress<uint8_t>, int64_t>>\n+      allocated_buffers_;\n \n   int64_t allocated_bytes_excluding_redzones_ = 0;\n };"
        },
        {
            "sha": "c610d2304a0261acbd53f228210dd3ca2cd9794a",
            "filename": "third_party/xla/xla/stream_executor/gpu/redzone_allocator_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fredzone_allocator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fredzone_allocator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fredzone_allocator_test.cc?ref=8dbc66efecdffe52a4725ba6a48c8a24c1f4a20f",
            "patch": "@@ -60,7 +60,7 @@ TEST(RedzoneAllocatorTest, WriteToRedzone) {\n   Platform* platform =\n       PlatformManager::PlatformWithName(GpuPlatformName()).value();\n   StreamExecutor* stream_exec = platform->ExecutorForDevice(0).value();\n-  StreamExecutorMemoryAllocator se_allocator(platform, {stream_exec});\n+  StreamExecutorAddressAllocator se_allocator(platform, {stream_exec});\n \n   TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_exec->CreateStream());\n   RedzoneAllocator allocator(stream.get(), &se_allocator,\n@@ -134,7 +134,7 @@ TEST(RedzoneAllocatorTest, VeryLargeRedzone) {\n   Platform* platform =\n       PlatformManager::PlatformWithName(GpuPlatformName()).value();\n   StreamExecutor* stream_exec = platform->ExecutorForDevice(0).value();\n-  StreamExecutorMemoryAllocator se_allocator(platform, {stream_exec});\n+  StreamExecutorAddressAllocator se_allocator(platform, {stream_exec});\n   TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_exec->CreateStream());\n   RedzoneAllocator allocator(stream.get(), &se_allocator,\n                              /*memory_limit=*/(1LL << 32),"
        }
    ],
    "stats": {
        "total": 32,
        "additions": 17,
        "deletions": 15
    }
}