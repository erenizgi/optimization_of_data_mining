{
    "author": "majnemer",
    "message": "Refactor PRNG bit generation and float conversion.\n\nThis change refactors the Philox bit interleaving logic into a dedicated helper function, `InterleavePhiloxResults`, used by both 32-bit and 64-bit generation. It also improves the `SplitShapeIntoHalves` function by using standard algorithms for finding dimensions. For float conversions, it uses primitive utility functions to derive constants for F16 bit manipulation.\n\nPiperOrigin-RevId: 832411685",
    "sha": "daf925082885faf8916eff50c05af9786398333b",
    "files": [
        {
            "sha": "e059a9ae4a5f0187408c6129eeab360fc0c56bca",
            "filename": "third_party/xla/xla/hlo/builder/lib/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/daf925082885faf8916eff50c05af9786398333b/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/daf925082885faf8916eff50c05af9786398333b/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2FBUILD?ref=daf925082885faf8916eff50c05af9786398333b",
            "patch": "@@ -371,6 +371,7 @@ cc_library(\n         \"//xla/hlo/builder:xla_builder\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/types:span\",\n         \"@local_tsl//tsl/platform:statusor\","
        },
        {
            "sha": "2eae8d0092757df3c381861ce40c0e9b4242603d",
            "filename": "third_party/xla/xla/hlo/builder/lib/prng.cc",
            "status": "modified",
            "additions": 58,
            "deletions": 58,
            "changes": 116,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/daf925082885faf8916eff50c05af9786398333b/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fprng.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/daf925082885faf8916eff50c05af9786398333b/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fprng.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fprng.cc?ref=daf925082885faf8916eff50c05af9786398333b",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include <vector>\n \n #include \"absl/algorithm/container.h\"\n+#include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/types/span.h\"\n@@ -181,48 +182,39 @@ struct SplitShapePair {\n // Split the shape on a dimension > 1 into two halves.\n SplitShapePair SplitShapeIntoHalves(const Shape& shape) {\n   SplitShapePair pair;\n-  if (shape.dimensions().size() == 0) {\n+  const auto& dims = shape.dimensions();\n+  if (dims.empty()) {\n     pair.half_shape = ShapeUtil::MakeShape(shape.element_type(), {1});\n     pair.concat_shape = ShapeUtil::MakeShape(shape.element_type(), {2});\n     pair.split_dim = 0;\n     pair.new_concat_dim = 0;\n     return pair;\n   }\n-  pair.split_dim = -1;\n-  for (int64_t i = 0; i < shape.dimensions().size(); ++i) {\n-    if (shape.dimensions(i) % 2 == 0) {\n-      pair.split_dim = i;\n-      break;\n-    }\n-  }\n-  if (pair.split_dim == -1) {\n-    // No even dims. Find a dimension with maximum size.\n-    for (int64_t i = 0; i < shape.dimensions().size(); ++i) {\n-      if (pair.split_dim == -1 ||\n-          shape.dimensions(i) > shape.dimensions(pair.split_dim)) {\n-        pair.split_dim = i;\n-      }\n-    }\n-  }\n-  if (pair.split_dim < 0) {\n-    LOG(ERROR) << \"This point shouldn't have been reached.\";\n+\n+  if (auto it = absl::c_find_if(dims, [](int64_t dim) { return dim % 2 == 0; });\n+      it != dims.end()) {\n+    pair.split_dim = std::distance(dims.begin(), it);\n+  } else {\n+    pair.split_dim = std::distance(dims.begin(), absl::c_max_element(dims));\n   }\n+\n   std::vector<int64_t> half_shape_dims;\n   std::vector<int64_t> concat_shape_dims;\n-  const auto rank = shape.dimensions().size();\n+  const auto rank = dims.size();\n   half_shape_dims.reserve(rank + 1);\n   concat_shape_dims.reserve(rank + 1);\n   for (int64_t i = 0; i < rank; ++i) {\n     if (i == pair.split_dim) {\n       // Create a new trivial dim for the later concat, which is more friendly\n       // to sharding propagation.\n-      half_shape_dims.push_back(CeilOfRatio<int64_t>(shape.dimensions(i), 2));\n+      auto dim_size = CeilOfRatio<int64_t>(dims[i], 2);\n+      half_shape_dims.push_back(dim_size);\n       half_shape_dims.push_back(1);\n-      concat_shape_dims.push_back(half_shape_dims[i]);\n+      concat_shape_dims.push_back(dim_size);\n       concat_shape_dims.push_back(2);\n     } else {\n-      half_shape_dims.push_back(shape.dimensions(i));\n-      concat_shape_dims.push_back(shape.dimensions(i));\n+      half_shape_dims.push_back(dims[i]);\n+      concat_shape_dims.push_back(dims[i]);\n     }\n   }\n   pair.new_concat_dim = pair.split_dim + 1;\n@@ -236,7 +228,7 @@ SplitShapePair SplitShapeIntoHalves(const Shape& shape) {\n XlaOp CombineShapePair(absl::Span<const XlaOp> pair,\n                        const SplitShapePair& shape_pair,\n                        const Shape& original_shape) {\n-  if (original_shape.dimensions().size() == 0) {\n+  if (original_shape.dimensions().empty()) {\n     return Reshape(pair[0], {});\n   }\n   XlaBuilder* builder = pair[0].builder();\n@@ -433,6 +425,27 @@ std::pair<Philox4x32State, XlaOp> GeneratePhiloxBits(int64_t num_elems,\n   return std::make_pair(outputs, new_state);\n }\n \n+// Interleaves slices of Philox results in a round-robin fashion to align with\n+// non-XLA implementations.\n+XlaOp InterleavePhiloxResults(XlaBuilder* builder,\n+                              absl::Span<const XlaOp> results,\n+                              int64_t num_elems) {\n+  const int kNumResults = results.size();\n+  CHECK_GT(kNumResults, 0);\n+  int64_t bits_len = CeilOfRatio<int64_t>(num_elems, kNumResults);\n+  std::vector<XlaOp> reshaped_results;\n+  reshaped_results.reserve(kNumResults);\n+  for (const auto& result : results) {\n+    reshaped_results.push_back(Reshape(result, {bits_len, 1}));\n+  }\n+  XlaOp numbers = ConcatInDim(builder, reshaped_results,\n+                              /*dimension=*/1);\n+  numbers = Reshape(numbers, {bits_len * kNumResults});\n+  return Slice(numbers, /*start_indices=*/{0},\n+               /*limit_indices=*/{num_elems},\n+               /*strides=*/{1});\n+}\n+\n // Generates an array of primitive type U32 with the given shape containing\n // random bits generated by the Philox algorithm. Returns the array and the new\n // state of the random number generator.\n@@ -445,18 +458,7 @@ RngOutput PhiloxRngBit32(XlaOp op_key, XlaOp initial_state,\n   Philox4x32State bits;\n   XlaOp new_state;\n   std::tie(bits, new_state) = GeneratePhiloxBits(num_elems, initial_state, key);\n-  // Combining bits[i] in a round-robin fashion, to align with non-XLA\n-  // implementations\n-  int64_t bits_len = (num_elems + 3) / 4;\n-  for (auto i = 0; i < 4; ++i) {\n-    bits[i] = Reshape(bits[i], {bits_len, 1});\n-  }\n-  XlaOp numbers = ConcatInDim(builder, {bits[0], bits[1], bits[2], bits[3]},\n-                              /*dimension=*/1);\n-  numbers = Reshape(numbers, {bits_len * 4});\n-  numbers = Slice(numbers, /*start_indices=*/{0},\n-                  /*limit_indices=*/{num_elems},\n-                  /*strides=*/{1});\n+  XlaOp numbers = InterleavePhiloxResults(builder, bits, num_elems);\n   return {Reshape(numbers, shape.dimensions()), new_state};\n }\n \n@@ -488,25 +490,14 @@ RngOutput PhiloxRngBit64(XlaOp op_key, XlaOp initial_state,\n   Philox4x32Key key = Uint64ToUint32s(op_key);\n   Philox4x32State bits32;\n   XlaOp new_state;\n-  std::tie(bits32, new_state) =\n-      GeneratePhiloxBits(num_elems * 2, initial_state, key);\n+  constexpr int kNum32BitIntsFor64BitInt = sizeof(uint64_t) / sizeof(uint32_t);\n+  std::tie(bits32, new_state) = GeneratePhiloxBits(\n+      num_elems * kNum32BitIntsFor64BitInt, initial_state, key);\n \n   std::array<XlaOp, 2> bits64;\n   bits64[0] = Uint32sToUint64({bits32[0], bits32[1]});\n   bits64[1] = Uint32sToUint64({bits32[2], bits32[3]});\n-\n-  // Combining bits64[i] in a round-robin fashion, to align with non-XLA\n-  // implementations\n-  int64_t bits64_len = (num_elems + 1) / 2;\n-  for (auto i = 0; i < 2; ++i) {\n-    bits64[i] = Reshape(bits64[i], {bits64_len, 1});\n-  }\n-  XlaOp numbers = ConcatInDim(builder, {bits64[0], bits64[1]},\n-                              /*dimension=*/1);\n-  numbers = Reshape(numbers, {bits64_len * 2});\n-  numbers = Slice(numbers, /*start_indices=*/{0},\n-                  /*limit_indices=*/{num_elems},\n-                  /*strides=*/{1});\n+  XlaOp numbers = InterleavePhiloxResults(builder, bits64, num_elems);\n   return {Reshape(numbers, shape.dimensions()), new_state};\n }\n \n@@ -529,6 +520,7 @@ XlaOp ConvertRandomBitsToUniformFloatingPoint(XlaOp bits, XlaOp minval,\n           primitive_util::LowercasePrimitiveTypeName(bit_type));\n     }\n \n+    XlaOp values;\n     if (value_type == F16 && bit_type == U16) {\n       // This path follows the approach of the non-XLA kernels (see\n       // `tsl::random::Uint16ToHalf`). IEEE754 halfs are formatted as follows\n@@ -539,11 +531,19 @@ XlaOp ConvertRandomBitsToUniformFloatingPoint(XlaOp bits, XlaOp minval,\n       //    exponent == 15  -- an excess 15 representation of a zero exponent\n       //    mantissa == 10 random bits\n \n-      auto mantissa = bits & ScalarLike(bits, 0x3ffu);  // 10 bit mantissa\n-      auto exponent = ScalarLike(bits, static_cast<uint16_t>(15) << 10);\n+      const int trailing_significand_width =\n+          primitive_util::SignificandWidth(F16) - 1;\n+      const uint16_t trailing_significand_mask =\n+          LsbMask<uint16_t>(trailing_significand_width);\n+      auto mantissa =\n+          bits &\n+          ScalarLike(bits, trailing_significand_mask);  // 10 bit mantissa\n+      auto exponent = ScalarLike(\n+          bits, static_cast<uint16_t>(primitive_util::ExponentBias(F16))\n+                    << trailing_significand_width);\n       auto u16_result = exponent | mantissa;\n       auto result = BitcastConvertType(u16_result, F16);\n-      return result - ScalarLike(result, 1.0);\n+      values = result - ScalarLike(result, 1.0);\n     } else {\n       // TODO: b/256715195 - Consider using the approach in the F16 case.\n       // Form random mantissa bits for float/double, with a leading 1 bit.\n@@ -565,15 +565,15 @@ XlaOp ConvertRandomBitsToUniformFloatingPoint(XlaOp bits, XlaOp minval,\n \n       // We have an integer-valued floating point number in the range\n       // [0, 2**{num_mantissa_bits}).\n-      XlaOp values = ConvertElementType(bits, value_type);\n+      values = ConvertElementType(bits, value_type);\n \n       // Multiply by 2**{-num_mantissa_bits} to get a number in the range\n       // [0.0, 1.0).\n       values = values * ScalarLike(values, std::ldexp(1., -num_mantissa_bits));\n+    }\n \n       // Multiply and add to shift to the range [minval, maxval).\n-      return values * (maxval - minval) + minval;\n-    }\n+    return values * (maxval - minval) + minval;\n   });\n }\n "
        }
    ],
    "stats": {
        "total": 117,
        "additions": 59,
        "deletions": 58
    }
}