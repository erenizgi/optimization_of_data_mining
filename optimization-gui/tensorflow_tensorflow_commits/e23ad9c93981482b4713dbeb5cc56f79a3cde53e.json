{
    "author": "pschuh",
    "message": "Remove some read references to untuple_result.\n\nPiperOrigin-RevId: 811147353",
    "sha": "e23ad9c93981482b4713dbeb5cc56f79a3cde53e",
    "files": [
        {
            "sha": "bfbce6c4801ecf88b2563495a47a16ff8702c994",
            "filename": "third_party/xla/xla/service/hlo_runner_pjrt.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e23ad9c93981482b4713dbeb5cc56f79a3cde53e/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_pjrt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e23ad9c93981482b4713dbeb5cc56f79a3cde53e/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_pjrt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_pjrt.cc?ref=e23ad9c93981482b4713dbeb5cc56f79a3cde53e",
            "patch": "@@ -474,7 +474,7 @@ HloRunnerPjRt::ExecuteWithExecutable(OpaqueExecutable* executable,\n       continue;\n     }\n     results.push_back(TransferLiteralsFromDevice(\n-        *std::move(output_buffers), execute_options.untuple_result));\n+        *std::move(output_buffers), module.result_shape().IsTuple()));\n   }\n   return results;\n }"
        },
        {
            "sha": "5f977b6190a64a48756981015c2a9466f640b459",
            "filename": "third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 35,
            "changes": 37,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e23ad9c93981482b4713dbeb5cc56f79a3cde53e/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Ffunctional_hlo_runner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e23ad9c93981482b4713dbeb5cc56f79a3cde53e/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Ffunctional_hlo_runner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Ffunctional_hlo_runner.cc?ref=e23ad9c93981482b4713dbeb5cc56f79a3cde53e",
            "patch": "@@ -502,9 +502,6 @@ absl::StatusOr<PerDeviceLiteralVecType> RunInternal(\n   if (running_options.multi_slice_config != nullptr) {\n     execute_options.multi_slice_config = running_options.multi_slice_config;\n   }\n-  if (running_options.untuple_result.has_value()) {\n-    execute_options.untuple_result = *running_options.untuple_result;\n-  }\n   TF_ASSIGN_OR_RETURN(std::vector<std::shared_ptr<HloModule>> hlo_modules,\n                       executable->GetHloModules());\n   CHECK_EQ(hlo_modules.size(), 1);\n@@ -545,35 +542,7 @@ absl::StatusOr<PerDeviceLiteralVecType> RunInternal(\n   };\n \n   std::vector<std::vector<std::unique_ptr<PjRtBuffer>>> output_buffers;\n-  auto output_has_tuple_leaf_on_host_memory_space = [&module]() {\n-    if (!module.result_shape().IsTuple()) {\n-      return false;\n-    }\n-    return true;\n-  };\n-  // If any output leaf buffer is a tuple, PJRT requires untuple_result.\n-  bool must_untuple_result = output_has_tuple_leaf_on_host_memory_space();\n-  bool default_untuple_result =\n-      must_untuple_result || execute_options.untuple_result;\n-  switch (parameter_type) {\n-    case ParameterType::kOneTupleOfArrays:\n-      execute_options.arguments_are_tupled = false;\n-      execute_options.untuple_result =\n-          module.entry_computation()->root_instruction()->shape().IsTuple();\n-      break;\n-    case ParameterType::kOneListOfArrays:\n-      execute_options.arguments_are_tupled = false;\n-      execute_options.untuple_result =\n-          module.entry_computation()->root_instruction()->shape().IsTuple();\n-      break;\n-    case ParameterType::kOther:\n-      execute_options.arguments_are_tupled = false;\n-      execute_options.untuple_result = false;\n-      break;\n-  }\n-  if (must_untuple_result) {\n-    execute_options.untuple_result = true;\n-  }\n+  execute_options.arguments_are_tupled = false;\n   std::optional<std::vector<PjRtFuture<>>> futures;\n   futures.emplace();\n   std::vector<std::vector<std::unique_ptr<PjRtBuffer>>> device_buffers;\n@@ -600,9 +569,7 @@ absl::StatusOr<PerDeviceLiteralVecType> RunInternal(\n                                                 flatten_arguments));\n         argument_ptrs = CreateArgumentPointersFromDeviceBuffers(device_buffers);\n       }\n-      if (is_last_repeat) {\n-        execute_options.untuple_result = default_untuple_result;\n-      }\n+      execute_options.untuple_result = true;\n       execute_options.launch_id = repeat + 1 + running_options.base_run_id;\n       if (running_options.execution_profiles != nullptr) {\n         execute_options.execution_profile ="
        }
    ],
    "stats": {
        "total": 39,
        "additions": 3,
        "deletions": 36
    }
}