{
    "author": "felixwqp",
    "message": "Enable Blackwell support for SOL latency estimator and update NCCL cost model parameters.\n\nPiperOrigin-RevId: 797407264",
    "sha": "f53877cebe5b83e04fd651cee571eabc974bc825",
    "files": [
        {
            "sha": "637da8b18ee2ce78390c5b88889bdd8b55141ccc",
            "filename": "third_party/xla/xla/service/gpu/model/sol_gpu_cost_model.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f53877cebe5b83e04fd651cee571eabc974bc825/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f53877cebe5b83e04fd651cee571eabc974bc825/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model.cc?ref=f53877cebe5b83e04fd651cee571eabc974bc825",
            "patch": "@@ -57,6 +57,21 @@ static auto& device_to_cfg =\n                 /*chunk_size_bytes=*/kDefaultNcclCostModelChunkSizeBytes,\n             },\n         },\n+        {\n+            \"NVIDIA B200\",\n+            {\n+                /*nccl_op_launch_time=*/absl::Microseconds(\n+                    100.0f * kDefaultNcclCostModelCoeff),\n+                /*nic_speed_gbps=*/\n+                111.12f * kDefaultNcclCostModelCoeff,\n+                /*chunk_prep_time=*/\n+                absl::Microseconds(4.45f * kDefaultNcclCostModelCoeff),\n+                /*rtt=*/\n+                absl::Microseconds(46.67f * kDefaultNcclCostModelCoeff),\n+                /*gpus_per_node=*/8,\n+                /*chunk_size_bytes=*/kDefaultNcclCostModelChunkSizeBytes,\n+            },\n+        },\n         {\n             kUnknownKey,\n             {\n@@ -84,8 +99,11 @@ SolGPUCostModel::Config GetPlatformConfig(\n     const se::DeviceDescription& device_info) {\n   std::string key = device_info.name();\n   if (!device_to_cfg.contains(key)) {\n+    LOG(WARNING) << \"No SoL config found for device: \" << device_info.name()\n+                 << \". Using default config.\";\n     return device_to_cfg[kUnknownKey];\n   }\n+  VLOG(2) << \"[SoL] Using config for device: \" << device_info.name();\n   return device_to_cfg[key];\n }\n "
        },
        {
            "sha": "3adfda9b07671d41615571bbdec57c18279e057e",
            "filename": "third_party/xla/xla/service/gpu/model/sol_gpu_cost_model_test.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 1,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f53877cebe5b83e04fd651cee571eabc974bc825/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f53877cebe5b83e04fd651cee571eabc974bc825/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model_test.cc?ref=f53877cebe5b83e04fd651cee571eabc974bc825",
            "patch": "@@ -88,7 +88,28 @@ TEST(SolGPUCostModelGetConfigTest, ConfigForHopper) {\n   EXPECT_EQ(static_cast<int>(config.nic_speed_gbps), 25);\n }\n \n-TEST(SolGPUCostModelGetConfigTest, ConfigForNewerThanHopper) {\n+TEST(SolGPUCostModelGetConfigTest, ConfigForBlackwell) {\n+  constexpr absl::string_view kDummyModule = R\"(\n+    HloModule noop\n+\n+    ENTRY main {\n+      ROOT constant = f32[] constant(0)\n+    })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnUnverifiedModule(kDummyModule));\n+\n+  se::DeviceDescription device_info;\n+  device_info.set_name(\"NVIDIA B200\");\n+  SolGPUCostModel::Config config =\n+      SolGPUCostModel::GetConfig(module.get(), device_info);\n+  EXPECT_EQ(static_cast<int>(config.nic_speed_gbps), 50);\n+  // Allow a tolerance of 10 nanoseconds for chunk_prep_time\n+  EXPECT_LT(absl::AbsDuration(config.chunk_prep_time - absl::Microseconds(2)),\n+            absl::Nanoseconds(10));\n+}\n+\n+TEST(SolGPUCostModelGetConfigTest, ConfigForDefaultGPU) {\n   constexpr absl::string_view kDummyModule = R\"(\n     HloModule noop\n "
        },
        {
            "sha": "466475d6412b6f729e8cf1983f5ffad9adf1b9f5",
            "filename": "third_party/xla/xla/service/gpu/model/sol_latency_estimator.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 6,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f53877cebe5b83e04fd651cee571eabc974bc825/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_latency_estimator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f53877cebe5b83e04fd651cee571eabc974bc825/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_latency_estimator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_latency_estimator.cc?ref=f53877cebe5b83e04fd651cee571eabc974bc825",
            "patch": "@@ -341,10 +341,13 @@ SolLatencyEstimator::Create(\n \n /*static*/ bool SolLatencyEstimator::IsSupportedForModule(\n     const HloModule& module, const se::DeviceDescription& gpu_device_info) {\n+  bool is_supported_device =\n+      gpu_device_info.cuda_compute_capability().IsHopper() ||\n+      gpu_device_info.cuda_compute_capability().IsBlackwell();\n   if (IsPassEnabledAtOptimizationEffort<LatencyHidingScheduler>(module)) {\n     // If the user enabled opt effort we turn the estimator on if we're\n-    // compiling for Hopper.\n-    return gpu_device_info.cuda_compute_capability().IsHopper();\n+    // compiling for Hopper/Blackwell.\n+    return is_supported_device;\n   }\n   // If this flag is on by default then we provide users an escape hatch in case\n   // they find the new cost model less profitable than T-shirt sizes.\n@@ -353,10 +356,9 @@ SolLatencyEstimator::Create(\n            .xla_gpu_enable_analytical_sol_latency_estimator()) {\n     return false;\n   }\n-  // Otherwise we are more conservative and we turn it on only for Hopper and if\n-  // `module` contains only supported collectives.\n-  return gpu_device_info.cuda_compute_capability().IsHopper() &&\n-         HasOnlySupportedCollectives(module);\n+  // Otherwise we are more conservative and we turn it on only for\n+  // Hopper/Blackwell and if `module` contains only supported collectives.\n+  return is_supported_device && HasOnlySupportedCollectives(module);\n }\n \n LatencyEstimator::TimeCost SolLatencyEstimator::GetLatencyBetween("
        }
    ],
    "stats": {
        "total": 55,
        "additions": 48,
        "deletions": 7
    }
}