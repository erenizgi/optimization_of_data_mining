{
    "author": "pifon2a",
    "message": "[XLA:GPU] Add a utility to get GpuTargetConfig.\n\nPiperOrigin-RevId: 845808764",
    "sha": "55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
    "files": [
        {
            "sha": "b0a85c6ca377fce051c25e33e5952e9d2e4b105e",
            "filename": "third_party/xla/xla/backends/gpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 9,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2FBUILD?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -32,12 +32,3 @@ cc_library(\n         \"@com_google_absl//absl/base:core_headers\",\n     ],\n )\n-\n-filegroup(\n-    name = \"all_gpu_specs\",\n-    data = glob([\"specs/*.txtpb\"]),\n-)\n-\n-exports_files(glob([\n-    \"specs/*.txtpb\",\n-]))"
        },
        {
            "sha": "056bbb9d6c156033d15e0497519fa5de082dddd4",
            "filename": "third_party/xla/xla/backends/gpu/specs/gpu_target_config.cc",
            "status": "added",
            "additions": 87,
            "deletions": 0,
            "changes": 87,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fspecs%2Fgpu_target_config.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fspecs%2Fgpu_target_config.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fspecs%2Fgpu_target_config.cc?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -0,0 +1,87 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/specs/gpu_target_config.h\"\n+\n+#include <string>\n+\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"google/protobuf/text_format.h\"\n+#include \"xla/backends/gpu/specs/all_gpu_specs.h\"\n+#include \"xla/stream_executor/device_description.pb.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+absl::StatusOr<absl::string_view> GetEmbeddedGpuTargetConfigData(\n+    const std::string& gpu_model) {\n+  if (gpu_model == \"a100_pcie_80\") {\n+    return get_a100_pcie_80();\n+  }\n+  if (gpu_model == \"a100_sxm_40\") {\n+    return get_a100_sxm_40();\n+  }\n+  if (gpu_model == \"a100_sxm_80\") {\n+    return get_a100_sxm_80();\n+  }\n+  if (gpu_model == \"a6000\") {\n+    return get_a6000();\n+  }\n+  if (gpu_model == \"b200\") {\n+    return get_b200();\n+  }\n+  if (gpu_model == \"b300\") {\n+    return get_b300();\n+  }\n+  if (gpu_model == \"h100_pcie\") {\n+    return get_h100_pcie();\n+  }\n+  if (gpu_model == \"h100_sxm\") {\n+    return get_h100_sxm();\n+  }\n+  if (gpu_model == \"mi200\") {\n+    return get_mi200();\n+  }\n+  if (gpu_model == \"p100\") {\n+    return get_p100();\n+  }\n+  if (gpu_model == \"v100\") {\n+    return get_v100();\n+  }\n+  return absl::NotFoundError(\n+      absl::StrCat(\"Embedded file not found: \", gpu_model, \".txtpb\"));\n+}\n+\n+}  // namespace\n+\n+absl::StatusOr<stream_executor::GpuTargetConfigProto> GetGpuTargetConfig(\n+    const std::string& gpu_model) {\n+  TF_ASSIGN_OR_RETURN(absl::string_view gpu_spec,\n+                      GetEmbeddedGpuTargetConfigData(gpu_model));\n+\n+  stream_executor::GpuTargetConfigProto config;\n+  if (!google::protobuf::TextFormat::ParseFromString(std::string(gpu_spec), &config)) {\n+    return absl::InternalError(absl::StrCat(\n+        \"Failed to parse GpuTargetConfigProto from embedded data for: \",\n+        gpu_model));\n+  }\n+  return config;\n+}\n+\n+}  // namespace xla::gpu"
        },
        {
            "sha": "251cf4717792c5348ce90744c870896d20b9dfc8",
            "filename": "third_party/xla/xla/backends/gpu/target_config/BUILD",
            "status": "added",
            "additions": 65,
            "deletions": 0,
            "changes": 65,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2FBUILD?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -0,0 +1,65 @@\n+load(\"@bazel_skylib//:bzl_library.bzl\", \"bzl_library\")\n+load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n+load(\"//xla:xla.default.bzl\", \"xla_cc_test\")\n+load(\"//xla/backends/gpu/target_config:build_defs.bzl\", \"embed_files\")\n+\n+package(\n+    # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n+    default_visibility = [\n+        \"//xla:__subpackages__\",\n+    ],\n+    licenses = [\"notice\"],\n+)\n+\n+filegroup(\n+    name = \"all_gpu_specs\",\n+    data = glob([\"specs/*.txtpb\"]),\n+)\n+\n+exports_files(glob([\n+    \"specs/*.txtpb\",\n+]))\n+\n+embed_files(\n+    name = \"embed_gpu_specs\",\n+    srcs = glob([\"specs/*.txtpb\"]),\n+    cpp_namespace = \"xla::gpu\",\n+)\n+\n+cc_library(\n+    name = \"target_config\",\n+    srcs = [\"target_config.cc\"],\n+    hdrs = [\"target_config.h\"],\n+    deps = [\n+        \":embed_gpu_specs\",\n+        \"//xla/stream_executor:device_description_proto_cc\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_protobuf//:protobuf\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"target_config_test\",\n+    srcs = [\"target_config_test.cc\"],\n+    deps = [\n+        \":target_config\",\n+        \"//xla/stream_executor:device_description_proto_cc\",\n+        \"//xla/tsl/platform:status_matchers\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n+bzl_library(\n+    name = \"build_defs_bzl\",\n+    srcs = [\"build_defs.bzl\"],\n+    visibility = [\"//visibility:private\"],\n+    deps = [\n+        \"//xla/tsl:package_groups_bzl\",\n+        \"//xla/tsl:tsl_default_bzl\",\n+        \"//xla/tsl/platform:rules_cc_bzl\",\n+    ],\n+)"
        },
        {
            "sha": "8d15dbb7e52690d6d5e732bda2df449d77efecd0",
            "filename": "third_party/xla/xla/backends/gpu/target_config/README.md",
            "status": "renamed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2FREADME.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2FREADME.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2FREADME.md?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/README.md"
        },
        {
            "sha": "1105d747dd961cb55a7ac00a225902e5d29e1d54",
            "filename": "third_party/xla/xla/backends/gpu/target_config/build_defs.bzl",
            "status": "added",
            "additions": 112,
            "deletions": 0,
            "changes": 112,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fbuild_defs.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fbuild_defs.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fbuild_defs.bzl?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -0,0 +1,112 @@\n+\"\"\"Contains embed_files build rule.\"\"\"\n+\n+load(\"//xla/tsl:package_groups.bzl\", \"DEFAULT_LOAD_VISIBILITY\")\n+load(\"//xla/tsl:tsl.default.bzl\", \"get_compatible_with_portable\")\n+load(\"//xla/tsl/platform:rules_cc.bzl\", \"cc_library\")\n+\n+visibility(DEFAULT_LOAD_VISIBILITY)\n+\n+def embed_files(name, srcs, cpp_namespace = \"\", **kwargs):\n+    \"\"\"Compiles srcs into a cc_library with functions returning embedded file data.\n+\n+    Example:\n+        embed_files(\n+            name = \"embed_some_file\",\n+            srcs = [\"file1.txt\", \"file2.txt\"],\n+            cpp_namespace = \"my_namespace\",\n+        )\n+\n+    will generate a cc_library with the following functions:\n+\n+        const std::string& get_file1();\n+        const std::string& get_file2();\n+\n+    Args:\n+        name: name for the generated cc_library target\n+        srcs: files to embed\n+        cpp_namespace: If set, the generated code will be wrapped in this namespace\n+        **kwargs: keyword arguments passed onto the generated cc_library() rule.\n+    \"\"\"\n+\n+    namespace_open = \"\"\n+    namespace_close = \"\"\n+    if cpp_namespace:\n+        namespace_open = \"namespace \" + cpp_namespace + \" { \"\n+        namespace_close = \"}  // namespace \" + cpp_namespace + \"\\n\"\n+\n+    native.genrule(\n+        name = name + \"_gen\",\n+        srcs = srcs,\n+        outs = [\n+            name + \".cc\",\n+            name + \".h\",\n+        ],\n+        cmd = \"\"\"\n+            HDR_OUT=$(location {name}.h)\n+            CC_OUT=$(location {name}.cc)\n+            GUARD=\"{guard}\"\n+\n+            # 1. Start Header File\n+            echo \"#ifndef $${{GUARD}}\" > \"$${{HDR_OUT}}\"\n+            echo \"#define $${{GUARD}}\" >> \"$${{HDR_OUT}}\"\n+            echo \"#include <string>\" >> \"$${{HDR_OUT}}\"\n+            echo \"\" >> \"$${{HDR_OUT}}\"\n+            echo \"{namespace_open}\" >> \"$${{HDR_OUT}}\"\n+\n+            # 2. Start CC File\n+            # Include standard headers FIRST to avoid namespace issues if header is malformed\n+            echo \"#include <cstddef>\" > \"$${{CC_OUT}}\"\n+            echo \"#include <string>\" >> \"$${{CC_OUT}}\"\n+            echo '#include \"{name}.h\"' >> \"$${{CC_OUT}}\"\n+            echo \"\" >> \"$${{CC_OUT}}\"\n+            echo \"{namespace_open}\" >> \"$${{CC_OUT}}\"\n+\n+            # 3. Iterate over source files\n+            for src in $(SRCS); do\n+                # Extract filename without path\n+                FILENAME=$$(basename \"$${{src}}\")\n+                # Extract stem (filename without extension)\n+                STEM=$$(echo \"$${{FILENAME}}\" | sed 's/\\\\.[^.]*$$//')\n+                # Create C++ identifier safe names\n+                SAFE_STEM=$$(echo \"$${{STEM}}\" | sed 's/[^a-zA-Z0-9_]/_/g')\n+                FUNC_NAME=\"get_$${{SAFE_STEM}}\"\n+                VAR_NAME=\"$${{SAFE_STEM}}_data\"\n+\n+                # Header: Add function declaration\n+                echo \"const std::string& $${{FUNC_NAME}}();\" >> \"$${{HDR_OUT}}\"\n+\n+                # CC: Embed data using xxd\n+                xxd -i \"$${{src}}\" | \\\n+                sed -e \"s/^unsigned char [^[]*/static const unsigned char $${{VAR_NAME}}/\" \\\n+                    -e \"s/^unsigned int .*_len/static const size_t $${{VAR_NAME}}_size/\" \\\n+                    >> \"$${{CC_OUT}}\"\n+                echo \"\" >> \"$${{CC_OUT}}\"\n+\n+                # CC: Define the accessor function\n+                echo \"const std::string& $${{FUNC_NAME}}() {{\" >> \"$${{CC_OUT}}\"\n+                echo \"  static const std::string* const kInstance = new std::string(\" >> \"$${{CC_OUT}}\"\n+                echo \"      reinterpret_cast<const char*>($${{VAR_NAME}}), $${{VAR_NAME}}_size);\" >> \"$${{CC_OUT}}\"\n+                echo \"  return *kInstance;\" >> \"$${{CC_OUT}}\"\n+                echo \"}}\" >> \"$${{CC_OUT}}\"\n+                echo \"\" >> \"$${{CC_OUT}}\"\n+            done\n+\n+            # 4. Finish Header File\n+            echo \"{namespace_close}\" >> \"$${{HDR_OUT}}\"\n+            echo \"{namespace_close}\" >> \"$${{CC_OUT}}\"\n+            echo \"#endif  // $${{GUARD}}\" >> \"$${{HDR_OUT}}\"\n+        \"\"\".format(\n+            name = name,\n+            guard = name.upper() + \"_H_\",\n+            namespace_open = namespace_open,\n+            namespace_close = namespace_close,\n+        ),\n+        compatible_with = get_compatible_with_portable(),\n+    )\n+\n+    cc_library(\n+        name = name,\n+        srcs = [name + \".cc\"],\n+        hdrs = [name + \".h\"],\n+        **kwargs\n+    )"
        },
        {
            "sha": "3652ace77f781db3bfc6aeefd548ce72f7bb70f0",
            "filename": "third_party/xla/xla/backends/gpu/target_config/specs/a100_pcie_80.txtpb",
            "status": "renamed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa100_pcie_80.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa100_pcie_80.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa100_pcie_80.txtpb?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/a100_pcie_80.txtpb"
        },
        {
            "sha": "e46139481fc8b4731c6782ede14ca21038b43730",
            "filename": "third_party/xla/xla/backends/gpu/target_config/specs/a100_sxm_40.txtpb",
            "status": "renamed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa100_sxm_40.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa100_sxm_40.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa100_sxm_40.txtpb?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/a100_sxm_40.txtpb"
        },
        {
            "sha": "abe87b63d6bcafbf920e5f8b5165a8e8f03a9dbe",
            "filename": "third_party/xla/xla/backends/gpu/target_config/specs/a100_sxm_80.txtpb",
            "status": "renamed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa100_sxm_80.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa100_sxm_80.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa100_sxm_80.txtpb?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/a100_sxm_80.txtpb"
        },
        {
            "sha": "b864cee30fef2f59cc22a82f227d0483a5b7ae4b",
            "filename": "third_party/xla/xla/backends/gpu/target_config/specs/a6000.txtpb",
            "status": "renamed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa6000.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa6000.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fa6000.txtpb?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/a6000.txtpb"
        },
        {
            "sha": "e00f759fe6c6b75d4234562467e80bd73c72f101",
            "filename": "third_party/xla/xla/backends/gpu/target_config/specs/b200.txtpb",
            "status": "renamed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fb200.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fb200.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fb200.txtpb?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/b200.txtpb"
        },
        {
            "sha": "016292524680d415eaca463b5626c2e7bdb157fe",
            "filename": "third_party/xla/xla/backends/gpu/target_config/specs/b300.txtpb",
            "status": "renamed",
            "additions": 14,
            "deletions": 14,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fb300.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fb300.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fb300.txtpb?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,17 +1,17 @@\n-# Copyright 2025 The OpenXLA Authors.\r\n-#\r\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n-# you may not use this file except in compliance with the License.\r\n-# You may obtain a copy of the License at\r\n-#\r\n-#    http://www.apache.org/licenses/LICENSE-2.0\r\n-#\r\n-# Unless required by applicable law or agreed to in writing, software\r\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n-# See the License for the specific language governing permissions and\r\n-# limitations under the License.\r\n-{\n+# Copyright 2025 The OpenXLA Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+gpu_device_info {\n   threads_per_block_limit: 1024\n   threads_per_warp: 32\n   shared_memory_per_block: 49152",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/b300.txtpb"
        },
        {
            "sha": "6daee1e45ff81ac92eac070ffae49396590ad38a",
            "filename": "third_party/xla/xla/backends/gpu/target_config/specs/h100_pcie.txtpb",
            "status": "renamed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fh100_pcie.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fh100_pcie.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fh100_pcie.txtpb?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/h100_pcie.txtpb"
        },
        {
            "sha": "7760c5634d41aa3720fa96774c0517b5cf1e7103",
            "filename": "third_party/xla/xla/backends/gpu/target_config/specs/h100_sxm.txtpb",
            "status": "renamed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fh100_sxm.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fh100_sxm.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fh100_sxm.txtpb?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/h100_sxm.txtpb"
        },
        {
            "sha": "e72fa777e2ac34d8a503fc3b4555d19ef5bdbb4d",
            "filename": "third_party/xla/xla/backends/gpu/target_config/specs/mi200.txtpb",
            "status": "renamed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fmi200.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fmi200.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fmi200.txtpb?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/mi200.txtpb"
        },
        {
            "sha": "3aa8ce9352ebb1d8800628fe80b7cce3bcea63c3",
            "filename": "third_party/xla/xla/backends/gpu/target_config/specs/p100.txtpb",
            "status": "renamed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fp100.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fp100.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fp100.txtpb?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/p100.txtpb"
        },
        {
            "sha": "8474e435a882e2888e562564c860de1335d67aa1",
            "filename": "third_party/xla/xla/backends/gpu/target_config/specs/v100.txtpb",
            "status": "renamed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fv100.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fv100.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Fspecs%2Fv100.txtpb?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "previous_filename": "third_party/xla/xla/backends/gpu/specs/v100.txtpb"
        },
        {
            "sha": "778308bcbce48d1d2a86581e28ec6d505793e450",
            "filename": "third_party/xla/xla/backends/gpu/target_config/target_config.cc",
            "status": "added",
            "additions": 87,
            "deletions": 0,
            "changes": 87,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.cc?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -0,0 +1,87 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/target_config/target_config.h\"\n+\n+#include <string>\n+\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"google/protobuf/text_format.h\"\n+#include \"xla/backends/gpu/target_config/embed_gpu_specs.h\"\n+#include \"xla/stream_executor/device_description.pb.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+absl::StatusOr<absl::string_view> GetEmbeddedGpuTargetConfigData(\n+    const std::string& gpu_model) {\n+  if (gpu_model == \"a100_pcie_80\") {\n+    return get_a100_pcie_80();\n+  }\n+  if (gpu_model == \"a100_sxm_40\") {\n+    return get_a100_sxm_40();\n+  }\n+  if (gpu_model == \"a100_sxm_80\") {\n+    return get_a100_sxm_80();\n+  }\n+  if (gpu_model == \"a6000\") {\n+    return get_a6000();\n+  }\n+  if (gpu_model == \"b200\") {\n+    return get_b200();\n+  }\n+  if (gpu_model == \"b300\") {\n+    return get_b300();\n+  }\n+  if (gpu_model == \"h100_pcie\") {\n+    return get_h100_pcie();\n+  }\n+  if (gpu_model == \"h100_sxm\") {\n+    return get_h100_sxm();\n+  }\n+  if (gpu_model == \"mi200\") {\n+    return get_mi200();\n+  }\n+  if (gpu_model == \"p100\") {\n+    return get_p100();\n+  }\n+  if (gpu_model == \"v100\") {\n+    return get_v100();\n+  }\n+  return absl::NotFoundError(\n+      absl::StrCat(\"Embedded file not found: \", gpu_model, \".txtpb\"));\n+}\n+\n+}  // namespace\n+\n+absl::StatusOr<stream_executor::GpuTargetConfigProto> GetGpuTargetConfig(\n+    const std::string& gpu_model) {\n+  TF_ASSIGN_OR_RETURN(absl::string_view gpu_spec,\n+                      GetEmbeddedGpuTargetConfigData(gpu_model));\n+\n+  stream_executor::GpuTargetConfigProto config;\n+  if (!google::protobuf::TextFormat::ParseFromString(std::string(gpu_spec), &config)) {\n+    return absl::InternalError(absl::StrCat(\n+        \"Failed to parse GpuTargetConfigProto from embedded data for: \",\n+        gpu_model));\n+  }\n+  return config;\n+}\n+\n+}  // namespace xla::gpu"
        },
        {
            "sha": "eb4be618c2ce768a9a41c9c9601dc7170f2d281c",
            "filename": "third_party/xla/xla/backends/gpu/target_config/target_config.h",
            "status": "added",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config.h?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -0,0 +1,32 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_TARGET_CONFIG_TARGET_CONFIG_H_\n+#define XLA_BACKENDS_GPU_TARGET_CONFIG_TARGET_CONFIG_H_\n+\n+#include <string>\n+\n+#include \"absl/status/statusor.h\"\n+#include \"xla/stream_executor/device_description.pb.h\"\n+\n+namespace xla::gpu {\n+\n+// Returns the GpuTargetConfigProto for the given GPU model.\n+absl::StatusOr<stream_executor::GpuTargetConfigProto> GetGpuTargetConfig(\n+    const std::string& gpu_model);\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_BACKENDS_GPU_TARGET_CONFIG_TARGET_CONFIG_H_"
        },
        {
            "sha": "e94d8100f157f3e590e6974a28674c213898c258",
            "filename": "third_party/xla/xla/backends/gpu/target_config/target_config_test.cc",
            "status": "added",
            "additions": 76,
            "deletions": 0,
            "changes": 76,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Ftarget_config%2Ftarget_config_test.cc?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -0,0 +1,76 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/target_config/target_config.h\"\n+\n+#include <string>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/status/status.h\"\n+#include \"xla/stream_executor/device_description.pb.h\"\n+#include \"xla/tsl/platform/status_matchers.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+using ::testing::HasSubstr;\n+using ::tsl::testing::IsOk;\n+using ::tsl::testing::StatusIs;\n+\n+struct GpuTargetConfigTestCase {\n+  std::string test_name;\n+  std::string gpu_model;\n+  bool expect_ok;\n+};\n+\n+using GetGpuTargetConfigTest =\n+    ::testing::TestWithParam<GpuTargetConfigTestCase>;\n+\n+TEST_P(GetGpuTargetConfigTest, TestProtoRetrieval) {\n+  const GpuTargetConfigTestCase& test_case = GetParam();\n+  auto config = GetGpuTargetConfig(test_case.gpu_model);\n+\n+  if (test_case.expect_ok) {\n+    ASSERT_THAT(config, IsOk());\n+    EXPECT_TRUE(config->has_gpu_device_info());\n+    EXPECT_GT(config->gpu_device_info().threads_per_block_limit(), 0);\n+  } else {\n+    EXPECT_THAT(config, StatusIs(absl::StatusCode::kNotFound,\n+                                 HasSubstr(\"Embedded file not found\")));\n+  }\n+}\n+\n+INSTANTIATE_TEST_SUITE_P(\n+    GetGpuTargetConfigTests, GetGpuTargetConfigTest,\n+    ::testing::ValuesIn<GpuTargetConfigTestCase>({\n+        {\"A100_PCIE_80\", \"a100_pcie_80\", true},\n+        {\"A100_SXM_40\", \"a100_sxm_40\", true},\n+        {\"A100_SXM_80\", \"a100_sxm_80\", true},\n+        {\"A6000\", \"a6000\", true},\n+        {\"B200\", \"b200\", true},\n+        {\"B300\", \"b300\", true},\n+        {\"H100_PCIE\", \"h100_pcie\", true},\n+        {\"H100_SXM\", \"h100_sxm\", true},\n+        {\"MI200\", \"mi200\", true},\n+        {\"P100\", \"p100\", true},\n+        {\"V100\", \"v100\", true},\n+        {\"UnknownModel\", \"unknown_gpu\", false},\n+    }),\n+    [](const ::testing::TestParamInfo<GetGpuTargetConfigTest::ParamType>&\n+           info) { return info.param.test_name; });\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        },
        {
            "sha": "6412cf872001fcfba6ffa67186a47e1ca7fb3a12",
            "filename": "third_party/xla/xla/lit.bzl",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Flit.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Flit.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Flit.bzl?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -206,13 +206,7 @@ def lit_test_suite_for_gpus(\n             \"--param=GPU=%s\" % (gpu),\n         ]\n         gpu_data = data + [\n-            \"//xla/backends/gpu:specs/a100_pcie_80.txtpb\",\n-            \"//xla/backends/gpu:specs/a6000.txtpb\",\n-            \"//xla/backends/gpu:specs/b200.txtpb\",\n-            \"//xla/backends/gpu:specs/h100_sxm.txtpb\",\n-            \"//xla/backends/gpu:specs/mi200.txtpb\",\n-            \"//xla/backends/gpu:specs/p100.txtpb\",\n-            \"//xla/backends/gpu:specs/v100.txtpb\",\n+            \"//xla/backends/gpu/target_config:all_gpu_specs\",\n         ]\n         lit_test_suite(\n             \"%s_%s\" % (name, gpu),"
        },
        {
            "sha": "01f4c8fe62fd32d4154671f4e60df5f0e4c1b6a1",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -5817,34 +5817,34 @@ xla_aot_compile_cpu(\n xla_aot_compile_gpu(\n     name = \"xla_aot_compile_test_gpu_executable\",\n     autotune_results = \"xla_aot_compile_test_autotune_results.txtpb\",\n-    gpu_target_config = \"//xla/backends/gpu:specs/h100_sxm.txtpb\",\n+    gpu_target_config = \"//xla/backends/gpu/target_config:specs/h100_sxm.txtpb\",\n     module = \"xla_aot_compile_test.mlir\",\n )\n \n xla_aot_compile_gpu(\n     name = \"xla_aot_compile_test_gpu_executable_hlo\",\n     autotune_results = \"xla_aot_compile_test_autotune_results.txtpb\",\n-    gpu_target_config = \"//xla/backends/gpu:specs/h100_sxm.txtpb\",\n+    gpu_target_config = \"//xla/backends/gpu/target_config:specs/h100_sxm.txtpb\",\n     module = \"xla_aot_compile_test.hlo\",\n )\n \n xla_aot_compile_gpu(\n     name = \"xla_aot_compile_test_gpu_executable_constant\",\n     autotune_results = \"xla_aot_compile_test_autotune_results.txtpb\",\n-    gpu_target_config = \"//xla/backends/gpu:specs/h100_sxm.txtpb\",\n+    gpu_target_config = \"//xla/backends/gpu/target_config:specs/h100_sxm.txtpb\",\n     module = \"xla_aot_compile_test_constant.mlir\",\n )\n \n xla_aot_compile_gpu(\n     name = \"xla_aot_compile_test_gpu_executable_convolution\",\n     autotune_results = \"xla_aot_compile_test_autotune_results.txtpb\",\n-    gpu_target_config = \"//xla/backends/gpu:specs/h100_sxm.txtpb\",\n+    gpu_target_config = \"//xla/backends/gpu/target_config:specs/h100_sxm.txtpb\",\n     module = \"xla_aot_compile_test_convolution.mlir\",\n )\n \n xla_aot_compile_gpu_runtime_autotuning(\n     name = \"xla_aot_compile_test_gpu_executable_convolution_runtime_autotuning\",\n-    gpu_target_config = \"//xla/backends/gpu:specs/h100_sxm.txtpb\",\n+    gpu_target_config = \"//xla/backends/gpu/target_config:specs/h100_sxm.txtpb\",\n     module = \"xla_aot_compile_test_convolution.mlir\",\n )\n "
        },
        {
            "sha": "5ee867bd06f2114403dca7be325bb75274a85516",
            "filename": "third_party/xla/xla/service/gpu/autotuning/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 13,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -410,11 +410,7 @@ cc_library(\n xla_cc_test(\n     name = \"autotune_cache_key_test\",\n     srcs = [\"autotune_cache_key_test.cc\"],\n-    data = [\n-        \"//xla/backends/gpu:specs/a100_sxm_40.txtpb\",\n-        \"//xla/backends/gpu:specs/a100_sxm_80.txtpb\",\n-        \"//xla/backends/gpu:specs/mi200.txtpb\",\n-    ],\n+    data = [\"//xla/backends/gpu/target_config:all_gpu_specs\"],\n     deps = [\n         \":autotune_cache_key\",\n         \"//xla/hlo/ir:hlo\",\n@@ -677,14 +673,8 @@ tf_proto_library(\n xla_cc_test(\n     name = \"autotuner_util_test\",\n     srcs = [\"autotuner_util_test.cc\"],\n-    data = [\n-        \"//xla/backends/gpu:specs/a100_sxm_40.txtpb\",\n-        \"//xla/backends/gpu:specs/a100_sxm_80.txtpb\",\n-        \"//xla/backends/gpu:specs/mi200.txtpb\",\n-    ],\n-    tags = [\n-        \"gpu\",\n-    ],\n+    data = [\"//xla/backends/gpu/target_config:all_gpu_specs\"],\n+    tags = [\"gpu\"],\n     deps = [\n         \":autotune_cache_key\",\n         \":autotuner_status_key\","
        },
        {
            "sha": "9033896ccae947aa57f79055bf920097461b4e09",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotune_cache_key_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key_test.cc?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -66,8 +66,8 @@ TEST(AutotuneCacheKeyTest, DeviceDescriptionToCacheKey) {\n     std::string spec_string;\n     CHECK_OK(tsl::ReadFileToString(\n         tsl::Env::Default(),\n-        tsl::io::JoinPath(tsl::testing::XlaSrcRoot(), \"backends\", \"gpu\",\n-                          \"specs\", spec_file_name),\n+        tsl::io::JoinPath(tsl::testing::XlaSrcRoot(),\n+                          \"backends/gpu/target_config/specs\", spec_file_name),\n         &spec_string));\n     EXPECT_TRUE(\n         tsl::protobuf::TextFormat::ParseFromString(spec_string, &proto));"
        },
        {
            "sha": "54af8dd292eea61f52af210d8107ccee9c10e61a",
            "filename": "third_party/xla/xla/service/gpu/gpu_spmd_pipeline_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_spmd_pipeline_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_spmd_pipeline_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_spmd_pipeline_test.cc?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -60,7 +60,8 @@ class GpuSpmdPartitioningTest : public HloHardwareIndependentTestBase,\n     HloPassPipeline spmd_pipeline(\"spmd-partitioner\");\n     se::CudaComputeCapability ampere(8, 0);\n     AlgebraicSimplifierOptions alg_simplifier_options;\n-    // Ampere Core_count from tensorflow/compiler/xla/backends/gpu/specs/.\n+    // Ampere Core_count from\n+    // tensorflow/compiler/xla/backends/gpu/target_config/specs/.\n     AddSPMDPasses(module.get(), alg_simplifier_options, ampere, spmd_pipeline,\n                   std::nullopt);\n     TF_RETURN_IF_ERROR(spmd_pipeline.Run(module.get()).status());"
        },
        {
            "sha": "df82c8c89526ba260da76f1142906f41ceefd291",
            "filename": "third_party/xla/xla/service/gpu/tests/bitcast-convert.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fbitcast-convert.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fbitcast-convert.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fbitcast-convert.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck  %s\n+// RUN: hlo-opt %s --platform=gpu --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck  %s\n \n e {\n   a = s4[8,2]{1,0} parameter(0)"
        },
        {
            "sha": "5e91d5fa9974699b07f32ec4f8c9b09fefdb45d1",
            "filename": "third_party/xla/xla/service/gpu/tests/calling_convention.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fcalling_convention.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fcalling_convention.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fcalling_convention.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n \n // Arguments are passed separately.\n // Even constant arguments are passed as arguments."
        },
        {
            "sha": "da5ad41a3c177c8aa2fa52dc3cdc47078f71e03c",
            "filename": "third_party/xla/xla/service/gpu/tests/dot_bf16.hlo",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fdot_bf16.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fdot_bf16.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fdot_bf16.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,6 +1,6 @@\n-// RUN: %if !IS_ROCM %{ hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/v100.txtpb --split-input-file | FileCheck %s --check-prefixes=CHECK-SM70 %}\n-// RUN: %if !IS_ROCM %{ hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/a100_pcie_80.txtpb --split-input-file --xla_gpu_autotune_level=0 --xla_gpu_enable_triton_gemm=false | FileCheck %s --check-prefixes=CHECK-SM80 %}\n-// RUN: %if IS_ROCM %{ hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/mi200.txtpb --split-input-file --xla_gpu_autotune_level=0 --xla_gpu_enable_triton_gemm=false | FileCheck %s --check-prefixes=CHECK-SM80 %}\n+// RUN: %if !IS_ROCM %{ hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/v100.txtpb --split-input-file | FileCheck %s --check-prefixes=CHECK-SM70 %}\n+// RUN: %if !IS_ROCM %{ hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/a100_pcie_80.txtpb --split-input-file --xla_gpu_autotune_level=0 --xla_gpu_enable_triton_gemm=false | FileCheck %s --check-prefixes=CHECK-SM80 %}\n+// RUN: %if IS_ROCM %{ hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/mi200.txtpb --split-input-file --xla_gpu_autotune_level=0 --xla_gpu_enable_triton_gemm=false | FileCheck %s --check-prefixes=CHECK-SM80 %}\n \n \n // CHECK-SM70: %[[convert1:.+]] = f32[1536,6144]{1,0} fusion(%{{.+}})"
        },
        {
            "sha": "d3e2fb2a8de1ab25bf299790f1a5828effbf2aaa",
            "filename": "third_party/xla/xla/service/gpu/tests/kernel_reuse.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fkernel_reuse.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fkernel_reuse.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fkernel_reuse.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb --split-input-file | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb --split-input-file | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n \n // All fusions must reuse the same kernel:\n // CHECK-LABEL: target triple"
        },
        {
            "sha": "5e68f9853367e6fad5e5ab79a4ff5d63e1b50dc6",
            "filename": "third_party/xla/xla/service/gpu/tests/offload_scan_output.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Foffload_scan_output.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Foffload_scan_output.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Foffload_scan_output.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb --split-input-file | FileCheck --check-prefixes=CHECK %s\n+// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb --split-input-file | FileCheck --check-prefixes=CHECK %s\n \n HloModule jit_f, entry_computation_layout={()->(f32[4]{0:S(5)}, f32[4]{0})}, allow_spmd_sharding_propagation_to_output={true,true}\n "
        },
        {
            "sha": "0b8df6244c3b15ff1549863ed3b1d8a76688956c",
            "filename": "third_party/xla/xla/service/gpu/tests/pad_to_static.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fpad_to_static.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fpad_to_static.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fpad_to_static.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n \n // NOTE: Assertions have been autogenerated by utils/generate-test-checks.py\n "
        },
        {
            "sha": "e233780616d8a2f3f92476d6d7b53b4cc1be405b",
            "filename": "third_party/xla/xla/service/gpu/tests/reduce-precision.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Freduce-precision.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Freduce-precision.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Freduce-precision.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck  %s\n+// RUN: hlo-opt %s --platform=gpu --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck  %s\n \n e {\n   a = bf16[] parameter(0)"
        },
        {
            "sha": "48b73ef80dee868fb6d6dd128c77feb29fc098a6",
            "filename": "third_party/xla/xla/service/gpu/tests/reduce_fold_zero_add.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Freduce_fold_zero_add.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Freduce_fold_zero_add.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Freduce_fold_zero_add.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm-after-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb --split-input-file | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm-after-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb --split-input-file | FileCheck %s\n \n HloModule test\n "
        },
        {
            "sha": "30acdae0aef8e5819e7577dd254dec45f5bfe1e2",
            "filename": "third_party/xla/xla/service/gpu/tests/rng_get_and_update_state.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Frng_get_and_update_state.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Frng_get_and_update_state.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Frng_get_and_update_state.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck %s\n \n HloModule TestModule, is_scheduled=true\n "
        },
        {
            "sha": "31b2c4e34689ce06488f7ab356f34e770052f854",
            "filename": "third_party/xla/xla/service/gpu/tests/single_instruction.hlo",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsingle_instruction.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsingle_instruction.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsingle_instruction.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,6 +1,6 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=ptx --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb --split-input-file | FileCheck %s\n-// RUN: hlo-opt %s --platform=gpu --stage=ptx --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/a100_pcie_80.txtpb --split-input-file | FileCheck %s --check-prefixes=CHECK-SM80\n-// RUN: hlo-opt %s --platform=gpu --stage=ptx --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/h100_sxm.txtpb --split-input-file | FileCheck %s --check-prefixes=CHECK-SM90\n+// RUN: hlo-opt %s --platform=gpu --stage=ptx --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb --split-input-file | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=ptx --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/a100_pcie_80.txtpb --split-input-file | FileCheck %s --check-prefixes=CHECK-SM80\n+// RUN: hlo-opt %s --platform=gpu --stage=ptx --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/h100_sxm.txtpb --split-input-file | FileCheck %s --check-prefixes=CHECK-SM90\n \n // CHECK-DAG: sqrt.approx.f32\n "
        },
        {
            "sha": "cd0fabcf205468a083e11a2c8a7537c4010437a2",
            "filename": "third_party/xla/xla/service/gpu/tests/slice_to_dynamic.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fslice_to_dynamic.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fslice_to_dynamic.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fslice_to_dynamic.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n \n // NOTE: Assertions have been autogenerated by utils/generate-test-checks.py\n "
        },
        {
            "sha": "8585504b8557648bbbe5ea7a8c8b2e3e5e4af9fd",
            "filename": "third_party/xla/xla/service/gpu/tests/sorting.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsorting.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsorting.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsorting.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,5 +1,5 @@\n // NOTE: Assertions have been autogenerated by utils/generate-test-checks.py\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb --split-input-file | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb --split-input-file | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n \n HloModule TestModule, is_scheduled=true\n "
        },
        {
            "sha": "26fca0c7fb1d6a6ec05afae98471a612d352dec3",
            "filename": "third_party/xla/xla/service/gpu/tests/sub_byte_collectives.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsub_byte_collectives.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsub_byte_collectives.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsub_byte_collectives.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --split-input-file --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck  %s\n+// RUN: hlo-opt %s --platform=gpu --split-input-file --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck  %s\n \n e {\n   a = s4[4,16]{1,0:E(4)} parameter(0)"
        },
        {
            "sha": "1722fd44a349aef7c1cec29cf299ca157f1018ff",
            "filename": "third_party/xla/xla/service/gpu/tests/triton_calling_convention.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Ftriton_calling_convention.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Ftriton_calling_convention.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Ftriton_calling_convention.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK-%{PTX} %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK-%{PTX} %s\n \n // Verify that Triton kernels have the correct calling convention:\n // - PTX_KERNEL (71) for NVIDIA targets"
        },
        {
            "sha": "3ccf5bb83275037cf1f513b6b9a27f008176a778",
            "filename": "third_party/xla/xla/service/gpu/tests/triton_naming.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Ftriton_naming.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Ftriton_naming.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Ftriton_naming.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK-%{PTX} %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK-%{PTX} %s\n \n // CHECK-PTX: define ptx_kernel void @triton_gemm_r(\n // CHECK-GCN: define amdgpu_kernel void @triton_gemm_r("
        },
        {
            "sha": "d0897c286192caa72350eff795559c4e0deef40f",
            "filename": "third_party/xla/xla/service/gpu/tests/zero_clamp_abs_index.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fzero_clamp_abs_index.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fzero_clamp_abs_index.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fzero_clamp_abs_index.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck %s\n \n e {\n   p0 = s32[8,9] parameter(0)"
        },
        {
            "sha": "0b702ad9af2acb8dcd142f5d635aff78591af3a8",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1775,11 +1775,7 @@ lit_test_suite(\n         ],\n     ),\n     cfg = \"//xla:lit.cfg.py\",\n-    data = [\n-        \"//xla/backends/gpu:specs/a100_pcie_80.txtpb\",\n-        \"//xla/backends/gpu:specs/h100_sxm.txtpb\",\n-        \"//xla/backends/gpu:specs/v100.txtpb\",\n-    ],\n+    data = [\"//xla/backends/gpu/target_config:all_gpu_specs\"],\n     default_tags = tf_gpu_tests_tags(),\n     tools = [\n         \"//xla/tools:hlo-opt\","
        },
        {
            "sha": "0281e68b03e4ba619ebf8dd9bf6e645ed421f7f5",
            "filename": "third_party/xla/xla/service/gpu/transforms/layout_assignment_a100.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_a100.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_a100.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_a100.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/a100_pcie_80.txtpb --split-input-file | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/a100_pcie_80.txtpb --split-input-file | FileCheck %s\n \n // CHECK: fused_transpose\n // CHECK-NEXT: bf16[3,3,16,32]{3,2,1,0} parameter(0)"
        },
        {
            "sha": "10cc948cf6a288ac298da8c773a5aa4c2420c2fd",
            "filename": "third_party/xla/xla/service/gpu/transforms/layout_assignment_h100.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_h100.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_h100.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_h100.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/h100_sxm.txtpb --split-input-file | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/h100_sxm.txtpb --split-input-file | FileCheck %s\n \n // CHECK: fused_transpose\n // CHECK-NEXT: f8e4m3fn[3,3,16,32]{3,2,1,0} parameter(0)"
        },
        {
            "sha": "5ae06c318a1cf99159460e97fb6e5f7cb6a78c36",
            "filename": "third_party/xla/xla/service/gpu/transforms/layout_assignment_v100.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_v100.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_v100.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_v100.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/v100.txtpb --split-input-file | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/v100.txtpb --split-input-file | FileCheck %s\n \n // CHECK: fused_transpose\n // CHECK-NEXT: f16[3,3,16,32]{3,2,1,0} parameter(0)"
        },
        {
            "sha": "471b043735dcf899bbbda36053a4800045d8cc0e",
            "filename": "third_party/xla/xla/stream_executor/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 12,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -671,18 +671,7 @@ xla_test(\n     name = \"gpu_device_info_test\",\n     srcs = [\"gpu_device_info_test.cc\"],\n     backends = [\"gpu\"],\n-    data = [\n-        \"//xla/backends/gpu:specs/a100_pcie_80.txtpb\",\n-        \"//xla/backends/gpu:specs/a100_sxm_40.txtpb\",\n-        \"//xla/backends/gpu:specs/a100_sxm_80.txtpb\",\n-        \"//xla/backends/gpu:specs/a6000.txtpb\",\n-        \"//xla/backends/gpu:specs/b200.txtpb\",\n-        \"//xla/backends/gpu:specs/h100_pcie.txtpb\",\n-        \"//xla/backends/gpu:specs/h100_sxm.txtpb\",\n-        \"//xla/backends/gpu:specs/mi200.txtpb\",\n-        \"//xla/backends/gpu:specs/p100.txtpb\",\n-        \"//xla/backends/gpu:specs/v100.txtpb\",\n-    ],\n+    data = [\"//xla/backends/gpu/target_config:all_gpu_specs\"],\n     deps = [\n         \"//xla/service:platform_util\",\n         \"//xla/stream_executor:device_description\","
        },
        {
            "sha": "e6d057659da91155b5dd8a403957d105f7942840",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_device_info_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_device_info_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_device_info_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_device_info_test.cc?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -45,8 +45,9 @@ TEST(DeviceInfoTest, DeviceInfoMatches) {\n     std::string spec_string;\n     TF_ASSERT_OK(tsl::ReadFileToString(\n         tsl::Env::Default(),\n-        tsl::io::JoinPath(tsl::testing::XlaSrcRoot(), \"backends\", \"gpu\",\n-                          \"specs\", absl::StrCat(file_name, \".txtpb\")),\n+        tsl::io::JoinPath(tsl::testing::XlaSrcRoot(),\n+                          \"backends/gpu/target_config/specs\",\n+                          absl::StrCat(file_name, \".txtpb\")),\n         &spec_string));\n     ASSERT_TRUE(\n         tsl::protobuf::TextFormat::ParseFromString(spec_string, &proto));"
        },
        {
            "sha": "de88faf03904248bed4df17fb78a57e1621696cd",
            "filename": "third_party/xla/xla/tools/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2FBUILD?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1103,7 +1103,7 @@ xla_test(\n     ],\n     data = [\n         \":data/add.hlo\",\n-        \"//xla/backends/gpu:specs/h100_sxm.txtpb\",\n+        \"//xla/backends/gpu/target_config:all_gpu_specs\",\n         \"//xla/service/gpu:gpu_compiler_test_autotune_db.textproto\",\n     ],\n     deps = ["
        },
        {
            "sha": "27a4a69f7292c357cd88814f85c6a0b517850cc5",
            "filename": "third_party/xla/xla/tools/hlo_opt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2FBUILD?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -258,7 +258,7 @@ filegroup(\n     name = \"test_utilities\",\n     testonly = True,\n     data = [\n-        \"//xla/backends/gpu:all_gpu_specs\",\n+        \"//xla/backends/gpu/target_config:all_gpu_specs\",\n         \"//xla/tools:hlo-opt\",\n         \"@llvm-project//llvm:FileCheck\",\n     ],"
        },
        {
            "sha": "43ab1735faa499035b559b0551bee9e41c7cb0e5",
            "filename": "third_party/xla/xla/tools/hlo_opt/tests/gpu_hlo.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck %s\n \n HloModule module\n "
        },
        {
            "sha": "f1e4e166d7fed6a3d76ba50d558a31945d0513c5",
            "filename": "third_party/xla/xla/tools/hlo_opt/tests/gpu_hlo_backend.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_backend.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_backend.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_backend.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=hlo-backend --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=hlo-backend --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck %s\n \n HloModule module\n "
        },
        {
            "sha": "267720369ba9d96e0fc895af21cf6ce20aa6c8af",
            "filename": "third_party/xla/xla/tools/hlo_opt/tests/gpu_hlo_buffers.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_buffers.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_buffers.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_buffers.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=buffer-assignment --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=buffer-assignment --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck %s\n \n HloModule m\n "
        },
        {
            "sha": "ba200234183f5c26f4662e7c4436496d63eb9743",
            "filename": "third_party/xla/xla/tools/hlo_opt/tests/gpu_hlo_collective_cse.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_collective_cse.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_collective_cse.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_collective_cse.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=hlo --passes=schedule-aware-collective-cse --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb --xla_gpu_experimental_collective_cse_distance_threshold=100 | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=hlo --passes=schedule-aware-collective-cse --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb --xla_gpu_experimental_collective_cse_distance_threshold=100 | FileCheck %s\n \n HloModule m\n "
        },
        {
            "sha": "f53ec227451880ae3b37921de9ae8a50de4ca180",
            "filename": "third_party/xla/xla/tools/hlo_opt/tests/gpu_hlo_html.hlo",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_html.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_html.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_html.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=html --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --stage=html --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck %s\n \n // CHECK: <!DOCTYPE html>\n // CHECK: bitcast\n@@ -9,4 +9,4 @@ ENTRY computation {\n     c = f32[6000,5000] transpose(p), dimensions={1,0}\n     r = f32[300,20,5000] reshape(c)\n     ROOT out = (f32[5000,6000], f32[300,20,5000]) tuple(e,r)\n-}\n\\ No newline at end of file\n+}"
        },
        {
            "sha": "59416aa1821e6bb30880c394345b2f6a214b0d78",
            "filename": "third_party/xla/xla/tools/hlo_opt/tests/gpu_hlo_llvm.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_llvm.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_llvm.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_llvm.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb --split-input-file | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb --split-input-file | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n \n HloModule m\n "
        },
        {
            "sha": "95342aae192d093c48329295e150b39e16a2df46",
            "filename": "third_party/xla/xla/tools/hlo_opt/tests/gpu_hlo_pass.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_pass.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_pass.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_pass.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --passes=dot-algorithm-rewriter --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck %s\n+// RUN: hlo-opt %s --platform=gpu --passes=dot-algorithm-rewriter --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck %s\n \n HloModule Algorithm3xBF16\n // CHECK-LABEL: HloModule Algorithm3xBF16, entry_computation_layout={(f32[128,128]{1,0}, f32[128,128]{1,0})->f32[128,128]{1,0}}"
        },
        {
            "sha": "b4ba7b9549c7d00a1f4cf743fca9418488050133",
            "filename": "third_party/xla/xla/tools/hlo_opt/tests/gpu_hlo_ptx.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_ptx.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_ptx.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_ptx.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=CUDA --stage=ptx --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb --split-input-file | FileCheck %s\n+// RUN: hlo-opt %s --platform=CUDA --stage=ptx --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb --split-input-file | FileCheck %s\n \n HloModule m\n "
        },
        {
            "sha": "b0e6e7115dc157646d951e9887dfe17dcce2d4c4",
            "filename": "third_party/xla/xla/tools/hlo_opt/tests/gpu_hlo_unoptimized_llvm.hlo",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_unoptimized_llvm.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_unoptimized_llvm.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Ftests%2Fgpu_hlo_unoptimized_llvm.hlo?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n+// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK,CHECK-%{PTX} %s\n \n // CHECK-PTX:     define ptx_kernel void @fusion\n // CHECK-GCN:     define amdgpu_kernel void @fusion"
        },
        {
            "sha": "e8ac6bc0a14bdc6d6e5853912017c01621798aeb",
            "filename": "third_party/xla/xla/tools/xla_gpu_compile_lib_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fxla_gpu_compile_lib_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc/third_party%2Fxla%2Fxla%2Ftools%2Fxla_gpu_compile_lib_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fxla_gpu_compile_lib_test.cc?ref=55afa175b0d9970eaa3a6edfab27fd04d3bdf1dc",
            "patch": "@@ -71,8 +71,9 @@ TEST_F(XlaCompileLibTest, CompilesForGpuWithDevice) {\n }\n \n TEST_F(XlaCompileLibTest, CompilesForGpuWithoutDevice) {\n-  const std::string target_config_path = tsl::io::JoinPath(\n-      tsl::testing::XlaSrcRoot(), \"backends/gpu/specs\", \"h100_sxm.txtpb\");\n+  const std::string target_config_path =\n+      tsl::io::JoinPath(tsl::testing::XlaSrcRoot(),\n+                        \"backends/gpu/target_config/specs\", \"h100_sxm.txtpb\");\n   stream_executor::GpuTargetConfigProto target_config;\n   TF_ASSERT_OK(tsl::ReadTextProto(tsl::Env::Default(), target_config_path,\n                                   &target_config));"
        }
    ],
    "stats": {
        "total": 636,
        "additions": 529,
        "deletions": 107
    }
}