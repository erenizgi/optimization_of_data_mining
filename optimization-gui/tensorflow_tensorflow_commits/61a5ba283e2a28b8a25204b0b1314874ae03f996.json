{
    "author": "loislo",
    "message": "[XLA:GPU] Make BufferDebugLog generic over the entry type.\n\nThe goal of the cl is to make BufferDebugLog class entry type independent.\nIn the nearest future we would like to extend amount of data we collect on the device side by different buffer debug kernels. Checksum kernel needs only one value while NaN checker (would be renamed as FloatChecker in the future) requires a few more values.\n\nThis change templates `ReadFromDevice` and `GetDeviceEntries` in `BufferDebugLog` to allow different entry types to be used in the debug log. The `RequiredSizeForEntries` function is also updated to accept the size of each entry.\n\nPiperOrigin-RevId: 829586408",
    "sha": "61a5ba283e2a28b8a25204b0b1314874ae03f996",
    "files": [
        {
            "sha": "66eabca69917c9b4eb5c64740c14644fcce0c214",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_checksum_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc?ref=61a5ba283e2a28b8a25204b0b1314874ae03f996",
            "patch": "@@ -103,7 +103,7 @@ absl::Status BuffersDebugChecksumThunk::ExecuteOnStream(\n     TF_RETURN_IF_ERROR(kernel_->Launch(\n         thread_dim, se::BlockDim(1, 1, 1), params.stream, log_entry_id,\n         device_buffer, device_buffer.size(), buffer_debug_log.GetDeviceHeader(),\n-        buffer_debug_log.GetDeviceEntries()));\n+        buffer_debug_log.GetDeviceEntries<BufferDebugLogEntry>()));\n   }\n \n   return absl::OkStatus();"
        },
        {
            "sha": "adb62025183cd044f2e4e026c7326cb03af070ec",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_checksum_thunk_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc?ref=61a5ba283e2a28b8a25204b0b1314874ae03f996",
            "patch": "@@ -114,7 +114,8 @@ class BuffersDebugChecksumThunkTest : public ::testing::Test {\n };\n \n TEST_F(BuffersDebugChecksumThunkTest, CalculatesChecksums) {\n-  static constexpr size_t kLogSize = BufferDebugLog::RequiredSizeForEntries(10);\n+  static constexpr size_t kLogSize =\n+      BufferDebugLog::RequiredSizeForEntries(10, sizeof(BufferDebugLogEntry));\n   static constexpr size_t kInputSize = 1024;\n   static constexpr size_t kInputCount = 2;\n   static constexpr size_t kTotalDeviceMemoryBytes =\n@@ -137,7 +138,7 @@ TEST_F(BuffersDebugChecksumThunkTest, CalculatesChecksums) {\n   se::DeviceMemoryBase inputs1_mem = allocations.GetDeviceAddress(inputs[1]);\n   // Initialize the log in device memory\n   TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n-                          BufferDebugLog::CreateOnDevice(\n+                          BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n                               *stream_, se::DeviceMemory<uint8_t>(log_mem)));\n   // Fill inputs with some data\n   std::vector<uint32_t> zeros(1024, 0);\n@@ -164,8 +165,9 @@ TEST_F(BuffersDebugChecksumThunkTest, CalculatesChecksums) {\n   TF_ASSERT_OK(thunk.Initialize(init_params));\n   TF_ASSERT_OK(thunk.Prepare(Thunk::PrepareParams{}, resource_requests));\n   TF_ASSERT_OK(thunk.ExecuteOnStream(execute_params));\n-  TF_ASSERT_OK_AND_ASSIGN(std::vector<BufferDebugLogEntry> entries,\n-                          device_log.ReadFromDevice(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::vector<BufferDebugLogEntry> entries,\n+      device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n \n   // BuffersDebugChecksumThunk launches a kernel for each input buffer, they may\n   // complete in any order."
        },
        {
            "sha": "127738695f16532da5fc54812616f9f41a6d197c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_float_check_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk.cc?ref=61a5ba283e2a28b8a25204b0b1314874ae03f996",
            "patch": "@@ -112,15 +112,15 @@ absl::Status BuffersDebugFloatCheckThunk::ExecuteOnStream(\n       TF_RETURN_IF_ERROR(kernel_f32_->Launch(\n           thread_dim, se::BlockDim(1, 1, 1), params.stream, entry_id,\n           f32_buffer, f32_buffer.size(), buffer_debug_log.GetDeviceHeader(),\n-          buffer_debug_log.GetDeviceEntries()));\n+          buffer_debug_log.GetDeviceEntries<BufferDebugLogEntry>()));\n     } else if (buffer_type == PrimitiveType::BF16) {\n       VLOG(1) << \"BF16 buffer detected with id: \" << entry_id\n               << \" and size: \" << device_buffer.size();\n       se::DeviceMemory<Eigen::bfloat16> bf16_buffer(device_buffer);\n       TF_RETURN_IF_ERROR(kernel_bf16_->Launch(\n           thread_dim, se::BlockDim(1, 1, 1), params.stream, entry_id,\n           bf16_buffer, bf16_buffer.size(), buffer_debug_log.GetDeviceHeader(),\n-          buffer_debug_log.GetDeviceEntries()));\n+          buffer_debug_log.GetDeviceEntries<BufferDebugLogEntry>()));\n     } else {\n       VLOG(1) << \"Unsupported primitive type for float checking: \"\n               << PrimitiveType_Name(buffer_type);"
        },
        {
            "sha": "a0a961b3983f4c89578b3ba9690d015586c3584b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_float_check_thunk_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc?ref=61a5ba283e2a28b8a25204b0b1314874ae03f996",
            "patch": "@@ -98,7 +98,8 @@ class BuffersDebugFloatCheckThunkTest : public ::testing::Test {\n };\n \n TEST_F(BuffersDebugFloatCheckThunkTest, CalculatesNanCounts) {\n-  static constexpr size_t kLogSize = BufferDebugLog::RequiredSizeForEntries(10);\n+  static constexpr size_t kLogSize =\n+      BufferDebugLog::RequiredSizeForEntries(10, sizeof(BufferDebugLogEntry));\n   static constexpr size_t kInputElems = 1024;\n   static constexpr size_t kInputSizeInBytes = kInputElems * sizeof(float);\n   static constexpr size_t kTotalDeviceMemoryBytes =\n@@ -128,7 +129,7 @@ TEST_F(BuffersDebugFloatCheckThunkTest, CalculatesNanCounts) {\n   se::DeviceMemoryBase inputs1_mem = allocations.GetDeviceAddress(inputs[1]);\n   // Initialize the log in device memory\n   TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n-                          BufferDebugLog::CreateOnDevice(\n+                          BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n                               *stream_, se::DeviceMemory<uint8_t>(log_mem)));\n   // Fill inputs with some data\n   {\n@@ -162,8 +163,9 @@ TEST_F(BuffersDebugFloatCheckThunkTest, CalculatesNanCounts) {\n   TF_ASSERT_OK(thunk.Initialize(init_params));\n   TF_ASSERT_OK(thunk.Prepare(Thunk::PrepareParams{}, resource_requests));\n   TF_ASSERT_OK(thunk.ExecuteOnStream(execute_params));\n-  TF_ASSERT_OK_AND_ASSIGN(std::vector<BufferDebugLogEntry> entries,\n-                          device_log.ReadFromDevice(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::vector<BufferDebugLogEntry> entries,\n+      device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n \n   // BuffersDebugFloatCheckThunk launches a kernel for each input buffer, they\n   // may complete in any order."
        },
        {
            "sha": "53bcbe9086bbccbec4528c09db197578b08edf77",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_pass.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass.cc?ref=61a5ba283e2a28b8a25204b0b1314874ae03f996",
            "patch": "@@ -221,8 +221,9 @@ absl::Status DumpBufferDebugLog(\n   se::gpu::BufferDebugLog buffer_debug_log =\n       se::gpu::BufferDebugLog::FromDeviceMemoryUnchecked(\n           log_buffer.device_memory());\n-  TF_ASSIGN_OR_RETURN(std::vector<BufferDebugLogEntry> log_entries,\n-                      buffer_debug_log.ReadFromDevice(*stream));\n+  TF_ASSIGN_OR_RETURN(\n+      std::vector<BufferDebugLogEntry> log_entries,\n+      buffer_debug_log.ReadFromDevice<BufferDebugLogEntry>(*stream));\n   BufferDebugLogProto buffer_debug_log_proto =\n       metadata_store->EntriesToProto(log_entries);\n \n@@ -351,8 +352,8 @@ ThunkFilter CreateThunkFilter(const DebugOptions& debug_options) {\n XLA_FFI_DEFINE_HANDLER_SYMBOL(\n     kDebugLogInitHandler,\n     [](se::Stream* absl_nonnull stream, xla::ffi::Buffer<U8> log_buffer) {\n-      return se::gpu::BufferDebugLog::CreateOnDevice(*stream,\n-                                                     log_buffer.device_memory())\n+      return se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+                 *stream, log_buffer.device_memory())\n           .status();\n     },\n     xla::ffi::Ffi::Bind().Ctx<xla::ffi::Stream>().Arg<xla::ffi::Buffer<U8>>());"
        },
        {
            "sha": "ff80e530ef35e03172add1e629f227ba87f5aae1",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_float_check_kernel_cuda_test.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 11,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc?ref=61a5ba283e2a28b8a25204b0b1314874ae03f996",
            "patch": "@@ -49,6 +49,7 @@ namespace se = stream_executor;\n namespace stream_executor::cuda {\n namespace {\n \n+using xla::gpu::BufferDebugLogEntry;\n using xla::gpu::BufferDebugLogEntryId;\n using xla::gpu::ThunkId;\n \n@@ -101,11 +102,11 @@ class FloatCheckKernelTest : public ::testing::Test {\n     // Call kernel\n     TF_RETURN_IF_ERROR(stream_->Memcpy(&device_input, input.data(),\n                                        input.size() * sizeof(input[0])));\n-    TF_RETURN_IF_ERROR(kernel.Launch(dim, stream_executor::BlockDim(1, 1, 1),\n-                                     stream_.get(), entry_id, device_input,\n-                                     device_input.ElementCount() * sizeof(T),\n-                                     buffer_debug_log.GetDeviceHeader(),\n-                                     buffer_debug_log.GetDeviceEntries()));\n+    TF_RETURN_IF_ERROR(kernel.Launch(\n+        dim, stream_executor::BlockDim(1, 1, 1), stream_.get(), entry_id,\n+        device_input, device_input.ElementCount() * sizeof(T),\n+        buffer_debug_log.GetDeviceHeader(),\n+        buffer_debug_log.GetDeviceEntries<BufferDebugLogEntry>()));\n     TF_RETURN_IF_ERROR(stream_->BlockHostUntilDone());\n \n     // The result gets stored in `buffer_debug_log`.\n@@ -124,12 +125,14 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsForF32) {\n                               2.0f, std::numeric_limits<float>::quiet_NaN()};\n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+                                                                   mem));\n \n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckF32Kernel>(\n       BufferDebugLogEntryId{123}, input, device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].value, 2);\n }\n@@ -143,12 +146,14 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsForBf16) {\n       xla::bfloat16(std::numeric_limits<float>::quiet_NaN())};\n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+                                                                   mem));\n \n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckBf16Kernel>(\n       BufferDebugLogEntryId{0}, input, device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].value, 2);\n }\n@@ -162,14 +167,16 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsInParallel) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+                                                                   mem));\n \n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckF32Kernel>(\n       BufferDebugLogEntryId{0}, input, device_log, se::ThreadDim(2, 4, 8)));\n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckF32Kernel>(\n       BufferDebugLogEntryId{0}, input, device_log, se::ThreadDim(2, 4, 8)));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 2);\n   EXPECT_EQ(host_log[0].value, 3);\n   EXPECT_EQ(host_log[1].value, 3);"
        },
        {
            "sha": "4fba67f49409bc041c0f0bd10c5f7c805172a33f",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_xor_checksum_kernel_cuda_test.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 17,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc?ref=61a5ba283e2a28b8a25204b0b1314874ae03f996",
            "patch": "@@ -103,11 +103,11 @@ class ChecksumKernelTest : public ::testing::Test {\n     // Call kernel\n     TF_RETURN_IF_ERROR(stream_->Memcpy(&device_input, input.data(),\n                                        input.size() * sizeof(input[0])));\n-    TF_RETURN_IF_ERROR(kernel.Launch(dim, stream_executor::BlockDim(1, 1, 1),\n-                                     stream_.get(), entry_id, device_input,\n-                                     device_input.ElementCount(),\n-                                     buffer_debug_log.GetDeviceHeader(),\n-                                     buffer_debug_log.GetDeviceEntries()));\n+    TF_RETURN_IF_ERROR(kernel.Launch(\n+        dim, stream_executor::BlockDim(1, 1, 1), stream_.get(), entry_id,\n+        device_input, device_input.ElementCount(),\n+        buffer_debug_log.GetDeviceHeader(),\n+        buffer_debug_log.GetDeviceEntries<BufferDebugLogEntry>()));\n     TF_RETURN_IF_ERROR(stream_->BlockHostUntilDone());\n \n     // The result gets stored in `buffer_debug_log`.\n@@ -133,12 +133,14 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumForMultipleOf32Bit) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+                                                                   mem));\n \n   TF_EXPECT_OK(\n       AppendChecksumOnDevice(BufferDebugLogEntryId{0}, input, device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].value, kExpectedChecksum);\n }\n@@ -149,12 +151,14 @@ TEST_F(ChecksumKernelTest,\n   const std::vector<uint8_t> kInput = std::vector<uint8_t>(1023, 0x55);\n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+                                                                   mem));\n \n   TF_EXPECT_OK(\n       AppendChecksumOnDevice(BufferDebugLogEntryId{0}, kInput, device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   // Assumes the device uses little-endian byte order.\n   EXPECT_EQ(host_log[0].value, 0x55000000);\n@@ -169,12 +173,14 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallel) {\n   constexpr uint32_t kExpectedChecksum = 0x12345678;\n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+                                                                   mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{0}, input,\n                                       device_log, se::ThreadDim(2, 4, 8)));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].value, kExpectedChecksum);\n }\n@@ -188,12 +194,14 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallelWithMaxThreads) {\n   constexpr uint32_t kExpectedChecksum = 0x12345678;\n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+                                                                   mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{0}, input,\n                                       device_log, se::ThreadDim(128, 4, 2)));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].value, kExpectedChecksum);\n }\n@@ -205,7 +213,8 @@ TEST_F(ChecksumKernelTest, AppendsChecksumsToLog) {\n   constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+                                                                   mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{123}, kInput123,\n                                       device_log));\n@@ -214,7 +223,8 @@ TEST_F(ChecksumKernelTest, AppendsChecksumsToLog) {\n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{789}, kInput789,\n                                       device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 3);\n   EXPECT_EQ(host_log[0].entry_id, 123);\n   EXPECT_EQ(host_log[0].value, 0x01230123);\n@@ -232,7 +242,8 @@ TEST_F(ChecksumKernelTest, DiscardsOverflowingChecksums) {\n   constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice(*stream_, mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n+                                                                   mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{123}, kInput123,\n                                       device_log));\n@@ -242,7 +253,8 @@ TEST_F(ChecksumKernelTest, DiscardsOverflowingChecksums) {\n   TF_EXPECT_OK(AppendChecksumOnDevice(BufferDebugLogEntryId{789}, kInput789,\n                                       device_log));\n \n-  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 2);\n   EXPECT_EQ(host_log[0].entry_id, 123);\n   EXPECT_EQ(host_log[0].value, 0x01230123);"
        },
        {
            "sha": "359ed6c2753a02b4c45c1461fd8b6ac40ec3df8f",
            "filename": "third_party/xla/xla/stream_executor/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD?ref=61a5ba283e2a28b8a25204b0b1314874ae03f996",
            "patch": "@@ -956,6 +956,7 @@ cc_library(\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:str_format\","
        },
        {
            "sha": "c4d0ac097af92e3a8283a62bdf20f799cd5ae56d",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 11,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc?ref=61a5ba283e2a28b8a25204b0b1314874ae03f996",
            "patch": "@@ -36,13 +36,12 @@ using ::xla::gpu::BufferDebugLogEntry;\n using ::xla::gpu::BufferDebugLogHeader;\n \n absl::StatusOr<BufferDebugLog> BufferDebugLog::CreateOnDevice(\n-    Stream& stream, DeviceMemory<uint8_t> log_buffer) {\n+    Stream& stream, DeviceMemory<uint8_t> log_buffer, size_t entry_size) {\n   if (log_buffer.is_null()) {\n     return absl::InvalidArgumentError(\"Log buffer must be non-null\");\n   }\n \n-  static constexpr size_t kMinBufferSize =\n-      sizeof(BufferDebugLogHeader) + sizeof(BufferDebugLogEntry);\n+  size_t kMinBufferSize = sizeof(BufferDebugLogHeader) + entry_size;\n   if (log_buffer.size() < kMinBufferSize) {\n     return absl::InvalidArgumentError(\n         absl::StrFormat(\"Log buffer size %u is too small to hold any log \"\n@@ -70,24 +69,23 @@ absl::StatusOr<BufferDebugLogHeader> BufferDebugLog::ReadHeaderFromDevice(\n   return header;\n }\n \n-absl::StatusOr<std::vector<BufferDebugLogEntry>> BufferDebugLog::ReadFromDevice(\n-    Stream& stream) const {\n+absl::StatusOr<size_t> BufferDebugLog::ReadFromDevice(\n+    Stream& stream, size_t entry_size, void* entries_data) const {\n   std::vector<uint8_t> buffer(memory_.size());\n   TF_RETURN_IF_ERROR(stream.Memcpy(buffer.data(), memory_, memory_.size()));\n   TF_RETURN_IF_ERROR(stream.BlockHostUntilDone());\n \n   BufferDebugLogHeader header;\n   memcpy(&header, buffer.data(), sizeof(header));\n \n-  const uint32_t max_entries = (memory_.size() - sizeof(BufferDebugLogHeader)) /\n-                               sizeof(BufferDebugLogEntry);\n+  const uint32_t max_entries =\n+      (memory_.size() - sizeof(BufferDebugLogHeader)) / entry_size;\n   const size_t initialized_entries =\n       std::min(max_entries, std::min(header.capacity, header.write_idx));\n-  std::vector<BufferDebugLogEntry> entries(initialized_entries);\n-  memcpy(entries.data(), buffer.data() + sizeof(header),\n-         initialized_entries * sizeof(BufferDebugLogEntry));\n+  memcpy(entries_data, buffer.data() + sizeof(header),\n+         initialized_entries * entry_size);\n \n-  return entries;\n+  return initialized_entries;\n }\n \n }  // namespace stream_executor::gpu"
        },
        {
            "sha": "c1b6ec3a98d6cf3c69e1a5c36543a12c07962c83",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log.h",
            "status": "modified",
            "additions": 23,
            "deletions": 8,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h?ref=61a5ba283e2a28b8a25204b0b1314874ae03f996",
            "patch": "@@ -25,6 +25,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/stream.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n \n namespace stream_executor::gpu {\n \n@@ -37,9 +38,9 @@ class BufferDebugLog {\n  public:\n   // Returns the number of bytes required to store a log with `entries`\n   // entries.\n-  static constexpr size_t RequiredSizeForEntries(size_t entries) {\n-    return sizeof(xla::gpu::BufferDebugLogHeader) +\n-           sizeof(xla::gpu::BufferDebugLogEntry) * entries;\n+  static constexpr size_t RequiredSizeForEntries(size_t entries,\n+                                                 size_t entry_size) {\n+    return sizeof(xla::gpu::BufferDebugLogHeader) + entry_size * entries;\n   }\n \n   // Initializes an empty `BufferDebugLog` using a `log_buffer` allocated in\n@@ -52,8 +53,11 @@ class BufferDebugLog {\n   //\n   // Fails with `absl::StatusCode::kInvalidArgument` if `log_buffer` is too\n   // small to hold any entries.\n+  template <typename Entry>\n   static absl::StatusOr<BufferDebugLog> CreateOnDevice(\n-      Stream& stream, DeviceMemory<uint8_t> log_buffer);\n+      Stream& stream, DeviceMemory<uint8_t> log_buffer) {\n+    return CreateOnDevice(stream, log_buffer, sizeof(Entry));\n+  }\n \n   // Creates a `BufferDebugLog` from an already initialized device memory\n   // buffer.\n@@ -78,8 +82,14 @@ class BufferDebugLog {\n   //\n   // `stream` must be associated with the same device as the one used to create\n   // the log.\n-  absl::StatusOr<std::vector<xla::gpu::BufferDebugLogEntry>> ReadFromDevice(\n-      Stream& stream) const;\n+  template <typename Entry>\n+  absl::StatusOr<std::vector<Entry>> ReadFromDevice(Stream& stream) const {\n+    std::vector<Entry> entries(memory_.size() / sizeof(Entry), Entry{});\n+    TF_ASSIGN_OR_RETURN(size_t initialized_entries,\n+                        ReadFromDevice(stream, sizeof(Entry), entries.data()));\n+    entries.resize(initialized_entries);\n+    return entries;\n+  }\n \n   // Returns a view of the `BufferDebugLogHeader`.\n   //\n@@ -94,14 +104,19 @@ class BufferDebugLog {\n   //\n   // The returned `DeviceMemory` gets invalidated when the `BufferDebugLog` is\n   // destroyed.\n-  DeviceMemory<xla::gpu::BufferDebugLogEntry> GetDeviceEntries() const {\n-    return DeviceMemory<xla::gpu::BufferDebugLogEntry>(memory_.GetByteSlice(\n+  template <typename Entry>\n+  DeviceMemory<Entry> GetDeviceEntries() const {\n+    return DeviceMemory<Entry>(memory_.GetByteSlice(\n         sizeof(xla::gpu::BufferDebugLogHeader),\n         memory_.size() - sizeof(xla::gpu::BufferDebugLogHeader)));\n   }\n \n  private:\n   explicit BufferDebugLog(DeviceMemory<uint8_t> memory) : memory_(memory) {}\n+  absl::StatusOr<size_t> ReadFromDevice(Stream& stream, size_t entry_size,\n+                                        void* entries_data) const;\n+  static absl::StatusOr<BufferDebugLog> CreateOnDevice(\n+      Stream& stream, DeviceMemory<uint8_t> log_buffer, size_t entry_size);\n \n   DeviceMemory<uint8_t> memory_;\n };"
        },
        {
            "sha": "f1cfdbf3b74eac3fce14b5ad9f7415faa46598c7",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log_test.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 11,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/61a5ba283e2a28b8a25204b0b1314874ae03f996/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc?ref=61a5ba283e2a28b8a25204b0b1314874ae03f996",
            "patch": "@@ -65,8 +65,10 @@ TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_InitializesEmptyLog) {\n   DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(1024);\n \n   TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n-                          BufferDebugLog::CreateOnDevice(*stream_, log_buffer));\n-  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+                          BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+                              *stream_, log_buffer));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n \n   EXPECT_EQ(host_log.size(), 0);\n }\n@@ -81,19 +83,23 @@ TEST_F(BufferDebugLogTest,\n       kExpectedHeaderSize + kExpectedEntriesSize);\n \n   TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n-                          BufferDebugLog::CreateOnDevice(*stream_, log_buffer));\n+                          BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+                              *stream_, log_buffer));\n \n   EXPECT_EQ(device_log.GetDeviceHeader().size(), kExpectedHeaderSize);\n-  EXPECT_EQ(device_log.GetDeviceEntries().size(), kExpectedEntriesSize);\n+  EXPECT_EQ(device_log.GetDeviceEntries<BufferDebugLogEntry>().size(),\n+            kExpectedEntriesSize);\n }\n \n TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_InitializesHeader) {\n   constexpr size_t kMaxEntries = 123;\n-  DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n-      BufferDebugLog::RequiredSizeForEntries(kMaxEntries));\n+  DeviceMemory<uint8_t> log_buffer =\n+      executor_->AllocateArray<uint8_t>(BufferDebugLog::RequiredSizeForEntries(\n+          kMaxEntries, sizeof(BufferDebugLogEntry)));\n \n   TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n-                          BufferDebugLog::CreateOnDevice(*stream_, log_buffer));\n+                          BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+                              *stream_, log_buffer));\n   TF_ASSERT_OK_AND_ASSIGN(BufferDebugLogHeader header,\n                           device_log.ReadHeaderFromDevice(*stream_));\n \n@@ -102,17 +108,20 @@ TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_InitializesHeader) {\n }\n \n TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_FailsForNullBuffer) {\n-  EXPECT_THAT(BufferDebugLog::CreateOnDevice(*stream_, DeviceMemory<uint8_t>()),\n+  EXPECT_THAT(BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+                  *stream_, DeviceMemory<uint8_t>()),\n               absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n TEST_F(BufferDebugLogTest,\n        CreateBufferDebugLogOnDevice_FailsForTooSmallBuffer) {\n   DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n-      BufferDebugLog::RequiredSizeForEntries(1) - 1);\n+      BufferDebugLog::RequiredSizeForEntries(1, sizeof(BufferDebugLogEntry)) -\n+      1);\n \n-  EXPECT_THAT(BufferDebugLog::CreateOnDevice(*stream_, log_buffer),\n-              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+  EXPECT_THAT(\n+      BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_, log_buffer),\n+      absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n }  // namespace"
        }
    ],
    "stats": {
        "total": 193,
        "additions": 120,
        "deletions": 73
    }
}