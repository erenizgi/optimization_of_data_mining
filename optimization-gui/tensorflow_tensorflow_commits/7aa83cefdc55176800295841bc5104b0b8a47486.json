{
    "author": "seantalts",
    "message": "[XLA:CPU] Move F8e4m3fn conversion elemental_ir_emitter -> intrinsics.\n\nPiperOrigin-RevId: 797318325",
    "sha": "7aa83cefdc55176800295841bc5104b0b8a47486",
    "files": [
        {
            "sha": "680d8fe1ccfa1889ca955a00b73331dfc78cff9c",
            "filename": "third_party/xla/xla/backends/cpu/codegen/ir_compiler.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.cc?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -398,10 +398,11 @@ llvm::Error IrCompiler::RunIrPasses(llvm::Module& module,\n     }\n   }\n \n-  auto replaced_functions = intrinsic_lib.RewriteIntrinsicFunctions(module);\n+  auto replaced_functions = intrinsic_lib.DefineIntrinsicFunctions(module);\n   RewriteToPolynomialApproximations(&module, options_.fast_math_flags);\n   if (!replaced_functions.empty()) {\n-    codegen::intrinsic::RemoveFromCompilerUsed(module, replaced_functions);\n+    codegen::intrinsic::RemoveFromCompilerUsed(\n+        module, [&](auto n) { return intrinsic_lib.IsIntrinsicFunction(n); });\n     codegen::intrinsic::RunInlineAndOptPasses(module);\n   }\n "
        },
        {
            "sha": "8ad331286b9a9e3f5a40f64977bf035c558b0b27",
            "filename": "third_party/xla/xla/codegen/intrinsic/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -65,6 +65,7 @@ cc_library(\n         \":intrinsic\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/tsl/platform:errors\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status:statusor\",\n@@ -80,8 +81,12 @@ xla_cc_test(\n     deps = [\n         \":fptrunc\",\n         \":intrinsic\",\n+        \":simple_jit_runner\",\n         \"//xla:xla_data_proto_cc\",\n         \"@com_google_googletest//:gtest_main\",\n+        \"@llvm-project//llvm:Support\",\n+        \"@llvm-project//llvm:Target\",\n+        \"@llvm-project//llvm:ir_headers\",\n     ],\n )\n \n@@ -208,13 +213,15 @@ cc_library(\n     hdrs = [\"intrinsic_compiler_lib.h\"],\n     deps = [\n         \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/functional:function_ref\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@llvm-project//llvm:Analysis\",\n         \"@llvm-project//llvm:IPO\",\n         \"@llvm-project//llvm:InstCombine\",\n         \"@llvm-project//llvm:Passes\",\n         \"@llvm-project//llvm:Scalar\",\n         \"@llvm-project//llvm:Support\",\n+        \"@llvm-project//llvm:TransformUtils\",\n         \"@llvm-project//llvm:ir_headers\",\n     ],\n )"
        },
        {
            "sha": "0724237fada260403c5e5ed8d846e4a6cea7e18a",
            "filename": "third_party/xla/xla/codegen/intrinsic/fptrunc.cc",
            "status": "modified",
            "additions": 206,
            "deletions": 0,
            "changes": 206,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.cc?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"xla/codegen/intrinsic/fptrunc.h\"\n \n #include \"absl/log/check.h\"\n+#include \"llvm/ADT/APInt.h\"\n #include \"llvm/ADT/FloatingPointMode.h\"\n #include \"llvm/IR/Argument.h\"\n #include \"llvm/IR/BasicBlock.h\"\n@@ -27,6 +28,7 @@ limitations under the License.\n #include \"llvm/IR/Type.h\"\n #include \"llvm/Support/Casting.h\"\n #include \"xla/codegen/intrinsic/intrinsic.h\"\n+#include \"xla/service/llvm_ir/llvm_util.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -114,6 +116,204 @@ static llvm::Function* ExtendF8e5m2ToF16(llvm::Module* module, Type from,\n   return func;\n }\n \n+static llvm::Function* TruncateF16ToF8e4m3fn(llvm::Module* module, Type from,\n+                                             Type to) {\n+  llvm::LLVMContext& context = module->getContext();\n+  llvm::IRBuilder<> b(context);\n+  llvm::Function* func = CreateFunction(module, from, to);\n+  llvm::BasicBlock* entry_bb = llvm::BasicBlock::Create(context, \"entry\", func);\n+  b.SetInsertPoint(entry_bb);\n+  llvm::Value* f16_value = func->getArg(0);\n+\n+  using llvm::APInt;\n+  using llvm::Value;\n+\n+  llvm::Type* i8_ty = to.to_ir_type(context);\n+  llvm::Type* i16_ty = Type(U16, from.vector_width()).to_ir_type(context);\n+  auto i8_const = [&](int val) { return llvm::ConstantInt::get(i8_ty, val); };\n+  auto i16_const = [&](int val) { return llvm::ConstantInt::get(i16_ty, val); };\n+\n+  // Cast the input value to an integer for bitwise manipulation. Get the\n+  // absolute value of the input value.\n+  //   f16_as_int = bitcast(f16_value, int)\n+  //   f16_abs_bits = f16_as_int & 0x7FFF\n+  Value* f16_as_int = b.CreateBitCast(f16_value, i16_ty);\n+  llvm::Value* f16_abs_bits = b.CreateAnd(f16_as_int, i16_const(0x7FFF));\n+\n+  // Get the sign.\n+  //   f8_sign = (f16_as_int & 0x8000) >> 8\n+  Value* f16_sign = b.CreateAnd(f16_as_int, i16_const(0x8000));\n+  f16_sign = b.CreateLShr(f16_sign, i16_const(8));\n+  Value* f8_sign = b.CreateTrunc(f16_sign, i8_ty);\n+\n+  // Truncate the mantissa to 3 bits. ReducePrecision cannot deal with\n+  // f8E4M3FN's NaN representations, so don't use ReducePrecision to handle\n+  // exponent reduction. Denormal values are not handled properly here and are\n+  // dealt with later in this function.\n+  absl::StatusOr<Value*> f16_reduced_statusor =\n+      llvm_ir::EmitReducePrecisionIR(/*src_ty=*/F16, f16_value,\n+                                     /*dest_exponent_bits=*/5,\n+                                     /*dest_mantissa_bits=*/3,\n+                                     /*quiet_nans=*/false, &b);\n+  CHECK_OK(f16_reduced_statusor.status());  // Crash OK\n+  Value* f16_reduced = f16_reduced_statusor.value();\n+  f16_reduced = b.CreateBitCast(f16_reduced, i16_ty);\n+\n+  // Remove the sign bit.\n+  //   f16_reduced = f16_reduced & 0x7FFF\n+  f16_reduced = b.CreateAnd(f16_reduced, i16_const(0x7FFF));\n+\n+  // Bits of the F16 representation of the smallest F8 normal value.\n+  constexpr int min_normal_value = 0x2400;\n+\n+  // Round values smaller than the smallest F8 normal value up to the smallest\n+  // F8 normal value. The case where we round to a denormal value is handled\n+  // later.\n+  //    f16_reduced = max(f16_reduced, min_normal_value)\n+  f16_reduced =\n+      b.CreateSelect(b.CreateICmpULT(f16_reduced, i16_const(min_normal_value)),\n+                     i16_const(min_normal_value), f16_reduced);\n+\n+  constexpr int exponent_bias_difference = 15 - 7;\n+  constexpr int f8_exponent_bits = 4;\n+  constexpr int f16_mantissa_bits = 10;\n+  constexpr int f8_mantissa_bits = 3;\n+  constexpr int mantissa_bits_difference = f16_mantissa_bits - f8_mantissa_bits;\n+\n+  // Adjust the exponent by subtracting the difference in exponent bias.\n+  //   f16_reduced -= (exponent_bias_difference << f16_mantissa_bits)\n+  f16_reduced = b.CreateSub(\n+      f16_reduced, i16_const(exponent_bias_difference << f16_mantissa_bits));\n+\n+  // Shift to convert to F8.\n+  //   f8_bits = f16_reduced >> mantissa_bits_difference;\n+  Value* f8_bits =\n+      b.CreateLShr(f16_reduced, i16_const(mantissa_bits_difference));\n+  f8_bits = b.CreateTrunc(f8_bits, i8_ty);\n+\n+  // Bits of the highest F16 value that gets converted to a finite F8 value.\n+  // In binary: 0 10111 1101111111\n+  constexpr int max_finite_value = 0x5F7F;\n+\n+  // If we're above the maximum F8 value, output NaN.\n+  //   f8_bits = f16_abs_bits > max_finite_value ? 0x7F : f8_bits\n+  f8_bits =\n+      b.CreateSelect(b.CreateICmpUGT(f16_abs_bits, i16_const(max_finite_value)),\n+                     i8_const(0x7F), f8_bits);\n+\n+  // Handle F16 values that are halfway between denormal F8 values.\n+  f8_bits = llvm_ir::HandleHalfwayPointsFxToF8<F16, f8_exponent_bits>(\n+      f16_abs_bits, f8_bits, from.vector_width(), &b);\n+\n+  // Set the sign bit.\n+  //   f8_bits |= f8_sign\n+  f8_bits = b.CreateOr(f8_bits, f8_sign);\n+  b.CreateRet(f8_bits);\n+  return func;\n+}\n+\n+static llvm::Function* ExtendF8e4m3fnToF16(llvm::Module* module, Type from,\n+                                           Type to) {\n+  llvm::LLVMContext& context = module->getContext();\n+  llvm::IRBuilder<> b(context);\n+  llvm::Function* func = CreateFunction(module, from, to);\n+  llvm::BasicBlock* entry_bb = llvm::BasicBlock::Create(context, \"entry\", func);\n+  b.SetInsertPoint(entry_bb);\n+  llvm::Value* f8_value = func->getArg(0);\n+\n+  using llvm::APInt;\n+  using llvm::Value;\n+\n+  llvm::Type* i8_type = from.to_ir_type(context);\n+  llvm::Type* i16_type = Type(U16, to.vector_width()).to_ir_type(context);\n+  auto i8_const = [i8_type](int val) {\n+    return llvm::ConstantInt::get(i8_type, val);\n+  };\n+  auto i16_const = [i16_type](int val) {\n+    return llvm::ConstantInt::get(i16_type, val);\n+  };\n+\n+  // Cast the input value to an integer for bitwise manipulation. Get the\n+  // absolute value of the input value.\n+  //   f8_as_int = bitcast(f16_value, int)\n+  //   f8_abs_bits = f8_as_int & 0x7F\n+  Value* f8_as_int = b.CreateBitCast(f8_value, i8_type);\n+  Value* f8_abs_bits = b.CreateAnd(f8_as_int, i8_const(0x7F));\n+\n+  // We assume below that the value is neither NaN nor denormal. If it NaN or\n+  // denormal, the output is set to NaN or zero at the end using Select\n+  // instructions.\n+\n+  // Get the sign:\n+  //   f16_sign = (f8_as_int & 0x80) << 8\n+  Value* f8_sign = b.CreateAnd(f8_as_int, i8_const(0x80));\n+  Value* f16_sign = b.CreateZExt(f8_sign, i16_type);\n+  f16_sign = b.CreateShl(f16_sign, i16_const(8));\n+\n+  constexpr int exponent_bias_difference = 15 - 7;\n+  constexpr int f16_mantissa_bits = 10;\n+  constexpr int f8_mantissa_bits = 3;\n+  constexpr int mantissa_bits_difference = f16_mantissa_bits - f8_mantissa_bits;\n+  constexpr int f8_mantissa_mask = (1 << f8_mantissa_bits) - 1;\n+\n+  // Get the exponent:\n+  //   f8_exponent = (f8_as_int & 0x78) >> f8_mantissa_bits\n+  Value* f8_exponent_bits = b.CreateAnd(f8_as_int, i8_const(0x78));\n+  Value* f8_exponent =\n+      b.CreateLShr(f8_exponent_bits, i8_const(f8_mantissa_bits));\n+\n+  // Adjust the exponent by adding the difference in exponent bias:\n+  //   f16_exponent = (f8_exponent + exponent_bias_difference)\n+  //                  << f16_mantissa_bits\n+  Value* f16_exponent =\n+      b.CreateAdd(f8_exponent, i8_const(exponent_bias_difference));\n+  f16_exponent = b.CreateZExt(f16_exponent, i16_type);\n+  f16_exponent = b.CreateShl(f16_exponent, i16_const(f16_mantissa_bits));\n+\n+  // Get the mantissa:\n+  //   f16_mantissa = (f8_mantissa & f8_mantissa_mask)\n+  //                  << mantissa_bits_difference\n+  Value* f8_mantissa = b.CreateAnd(f8_as_int, i8_const(f8_mantissa_mask));\n+  Value* f16_mantissa = b.CreateZExt(f8_mantissa, i16_type);\n+  f16_mantissa = b.CreateShl(f16_mantissa, i16_const(mantissa_bits_difference));\n+\n+  // Combine the exponent and mantissa:\n+  //   f16_as_int = f16_exponent | f16_mantissa\n+  Value* f16_as_int = b.CreateOr(f16_exponent, f16_mantissa);\n+\n+  // Set output to NaN if input is NaN\n+  //   f16_as_int = f8_abs_bits == 0x7F ? 0x7E00 : f16_as_int\n+  Value* is_nan = b.CreateICmpEQ(f8_abs_bits, i8_const(0x7F));\n+  f16_as_int = b.CreateSelect(is_nan, i16_const(0x7E00), f16_as_int);\n+\n+  // Map from F8 denormal value to F16 value.\n+  int f8_denormal_to_f16[8] = {\n+      0x0000,  // 0\n+      0x1800,  // 1/8 * 2^-6\n+      0x1C00,  // 2/8 * 2^-6\n+      0x1E00,  // 3/8 * 2^-6\n+      0x2000,  // 4/8 * 2^-6\n+      0x2100,  // 5/8 * 2^-6\n+      0x2200,  // 6/8 * 2^-6\n+      0x2300,  // 7/8 * 2^-6\n+  };\n+\n+  // If the F8 value is denormal, use the map above to determine the correct F16\n+  // value.\n+  //    if (f8_abs_bits < 8) { f16_as_int = f8_denormal_to_f16[f8_abs_bits]; }\n+  for (int i = 0; i < 8; i++) {\n+    Value* is_denormal_value = b.CreateICmpEQ(f8_abs_bits, i8_const(i));\n+    f16_as_int = b.CreateSelect(is_denormal_value,\n+                                i16_const(f8_denormal_to_f16[i]), f16_as_int);\n+  }\n+\n+  // Set the sign bit.\n+  //   f16_as_int |= f16_sign\n+  f16_as_int = b.CreateOr(f16_as_int, f16_sign);\n+  b.CreateRet(b.CreateBitCast(f16_as_int, to.to_ir_type(context)));\n+  return func;\n+}\n+\n absl::StatusOr<llvm::Function*> FpTrunc::CreateDefinition(llvm::Module* module,\n                                                           Type from, Type to) {\n   TF_RETURN_IF_ERROR(Type::VerifySameWidth(from, to));\n@@ -124,6 +324,12 @@ absl::StatusOr<llvm::Function*> FpTrunc::CreateDefinition(llvm::Module* module,\n   if (from.element_type() == F8E5M2 && to.element_type() == F16) {\n     return ExtendF8e5m2ToF16(module, from, to);\n   }\n+  if (from.element_type() == F8E4M3FN && to.element_type() == F16) {\n+    return ExtendF8e4m3fnToF16(module, from, to);\n+  }\n+  if (from.element_type() == F16 && to.element_type() == F8E4M3FN) {\n+    return TruncateF16ToF8e4m3fn(module, from, to);\n+  }\n \n   return Internal(\"Unsupported fptrunc conversion: from=%s to=%s\", from.name(),\n                   to.name());"
        },
        {
            "sha": "be81608151e2d9f1718626993d1ad28a2c8985f5",
            "filename": "third_party/xla/xla/codegen/intrinsic/fptrunc.h",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.h?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -45,6 +45,14 @@ class FpTrunc : public Intrinsic<FpTrunc> {\n         {Type::V(F8E5M2, 2), Type::V(F16, 2)},\n         {Type::V(F8E5M2, 4), Type::V(F16, 4)},\n         {Type::V(F8E5M2, 8), Type::V(F16, 8)},\n+        {Type::S(F8E4M3FN), Type::S(F16)},\n+        {Type::V(F8E4M3FN, 2), Type::V(F16, 2)},\n+        {Type::V(F8E4M3FN, 4), Type::V(F16, 4)},\n+        {Type::V(F8E4M3FN, 8), Type::V(F16, 8)},\n+        {Type::S(F16), Type::S(F8E4M3FN)},\n+        {Type::V(F16, 2), Type::V(F8E4M3FN, 2)},\n+        {Type::V(F16, 4), Type::V(F8E4M3FN, 4)},\n+        {Type::V(F16, 8), Type::V(F8E4M3FN, 8)},\n     };\n   }\n "
        },
        {
            "sha": "dcb23a314c591cbc85c39d7b4af91bda5f991e3c",
            "filename": "third_party/xla/xla/codegen/intrinsic/fptrunc_test.cc",
            "status": "modified",
            "additions": 159,
            "deletions": 0,
            "changes": 159,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc_test.cc?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -15,11 +15,28 @@ limitations under the License.\n \n #include \"xla/codegen/intrinsic/fptrunc.h\"\n \n+#include <array>\n+#include <cstdint>\n+#include <memory>\n+#include <utility>\n+\n #include <gtest/gtest.h>\n+#include \"llvm/IR/BasicBlock.h\"\n+#include \"llvm/IR/DerivedTypes.h\"\n+#include \"llvm/IR/Function.h\"\n+#include \"llvm/IR/IRBuilder.h\"\n+#include \"llvm/IR/LLVMContext.h\"\n+#include \"llvm/IR/Module.h\"\n+#include \"llvm/IR/Value.h\"\n+#include \"llvm/IR/Verifier.h\"\n+#include \"llvm/Support/Casting.h\"\n+#include \"llvm/Target/TargetMachine.h\"\n #include \"xla/codegen/intrinsic/intrinsic.h\"\n+#include \"xla/codegen/intrinsic/simple_jit_runner.h\"\n #include \"xla/xla_data.pb.h\"\n \n namespace xla::codegen::intrinsics {\n+using ::xla::codegen::intrinsic::JitRunner;\n \n TEST(FpTruncTest, SclarIninsic) {\n   EXPECT_EQ(FpTrunc::Name(Type::S(F32), Type::S(BF16)),\n@@ -30,4 +47,146 @@ TEST(FpTruncTest, VectorIninsic) {\n   EXPECT_EQ(FpTrunc::Name(Type::V(F32, 4), Type::V(BF16, 4)),\n             \"xla.fptrunc.v4f32.to.v4bf16\");\n }\n+\n+// This function takes in an LLVM function that expects an fp argument and\n+// wraps it in a new function that takes in an integer argument of the same\n+// bit width as the fp argument and bitcasts it to the fp type.\n+// Because there's no great native C++ fp16 type, we need to pass integer\n+// values of the right bit width to the intrinsic. But because the calling\n+// convention looks for fp arguments in fp registers, the intrinsic won't see\n+// these arguments at all so we need to create a wrapper function that converts\n+// the integer arguments to fp for interop with C++ here in this test.\n+llvm::Function* CreateWrapperIntArgToFp(llvm::Function* func) {\n+  llvm::LLVMContext& context = func->getContext();\n+  llvm::IRBuilder<> builder(context);\n+  llvm::Value* wrapped_arg = func->getArg(0);\n+  llvm::Type* int_arg_type = llvm::IntegerType::get(\n+      context, wrapped_arg->getType()->getScalarSizeInBits());\n+  if (auto vec_type =\n+          llvm::dyn_cast<llvm::VectorType>(wrapped_arg->getType())) {\n+    int_arg_type =\n+        llvm::VectorType::get(int_arg_type, vec_type->getElementCount());\n+  }\n+  llvm::Function* wrapper = llvm::Function::Create(\n+      llvm::FunctionType::get(func->getReturnType(), {int_arg_type}, false),\n+      llvm::GlobalValue::ExternalLinkage, func->getName() + \"_itofp\",\n+      func->getParent());\n+  wrapper->copyAttributesFrom(func);\n+  llvm::BasicBlock* entry_bb =\n+      llvm::BasicBlock::Create(context, \"entry\", wrapper);\n+  builder.SetInsertPoint(entry_bb);\n+  llvm::Value* float_arg =\n+      builder.CreateBitCast(wrapper->getArg(0), wrapped_arg->getType());\n+  llvm::Value* ret = builder.CreateCall(func, {float_arg});\n+  builder.CreateRet(ret);\n+  return wrapper;\n+}\n+\n+llvm::Function* CreateWrapperFpRetToInt(llvm::Function* func) {\n+  llvm::LLVMContext& context = func->getContext();\n+  llvm::IRBuilder<> builder(context);\n+  llvm::Type* ret_type = func->getReturnType();\n+  llvm::Type* int_ret_type =\n+      llvm::IntegerType::get(context, ret_type->getScalarSizeInBits());\n+  if (auto vec_type = llvm::dyn_cast<llvm::VectorType>(ret_type)) {\n+    int_ret_type =\n+        llvm::VectorType::get(int_ret_type, vec_type->getElementCount());\n+  }\n+  llvm::Function* wrapper = llvm::Function::Create(\n+      llvm::FunctionType::get(int_ret_type, {func->getArg(0)->getType()},\n+                              false),\n+      llvm::GlobalValue::ExternalLinkage, func->getName() + \"_fptoi\",\n+      func->getParent());\n+  wrapper->copyAttributesFrom(func);\n+  llvm::BasicBlock* entry_bb =\n+      llvm::BasicBlock::Create(context, \"entry\", wrapper);\n+  builder.SetInsertPoint(entry_bb);\n+  llvm::Value* ret = builder.CreateCall(func, {wrapper->getArg(0)});\n+  ret = builder.CreateBitCast(ret, int_ret_type);\n+  builder.CreateRet(ret);\n+  return wrapper;\n+}\n+\n+JitRunner CreateJitRunner(Type from, Type to) {\n+  auto context = std::make_unique<llvm::LLVMContext>();\n+  auto module = std::make_unique<llvm::Module>(\"test_module\", *context);\n+\n+  llvm::Function* func =\n+      FpTrunc::CreateDefinition(module.get(), from, to).value();\n+  func->setLinkage(llvm::Function::ExternalLinkage);\n+  EXPECT_FALSE(llvm::verifyFunction(*func));\n+\n+  llvm::Function* wrapper = CreateWrapperIntArgToFp(func);\n+  wrapper->setLinkage(llvm::Function::ExternalLinkage);\n+  EXPECT_FALSE(llvm::verifyFunction(*wrapper));\n+\n+  llvm::Function* wrapper2 = CreateWrapperFpRetToInt(func);\n+  wrapper2->setLinkage(llvm::Function::ExternalLinkage);\n+  EXPECT_FALSE(llvm::verifyFunction(*wrapper2));\n+\n+  return JitRunner(std::move(module), std::move(context));\n+}\n+\n+TEST(FpTruncExecutionTest, F16ToF8e4m3fn) {\n+  JitRunner jit = CreateJitRunner(Type::S(F16), Type::S(F8E4M3FN));\n+  auto fptrunc = jit.GetScalarFn<int8_t(int16_t)>(\n+      FpTrunc::Name(Type::S(F16), Type::S(F8E4M3FN)) + \"_itofp\");\n+  EXPECT_EQ(fptrunc(0x7FFF), 0x7F);  // overflows\n+  EXPECT_EQ(fptrunc(0x0), 0x0);\n+  EXPECT_EQ(fptrunc(static_cast<int16_t>(0b1100000000000000)),\n+            static_cast<int8_t>(0b11000000));  // -2.0\n+  EXPECT_EQ(fptrunc(static_cast<int16_t>(0b0011100000000000)),\n+            0b00110000);  // 0.5\n+  EXPECT_EQ(fptrunc(static_cast<int16_t>(0b1011100000000000)),\n+            static_cast<int8_t>(0b10110000));  // -0.5\n+\n+  // Test denormals (exponent all 0s) round to 0 in fp8e4m3fn.\n+  EXPECT_EQ(fptrunc(static_cast<int16_t>(0b0000000100000000)),\n+            static_cast<int8_t>(0b00000000));\n+  EXPECT_EQ(fptrunc(static_cast<int16_t>(0b0000000010000000)),\n+            static_cast<int8_t>(0b00000000));\n+  EXPECT_EQ(fptrunc(static_cast<int16_t>(0b0000000001000000)),\n+            static_cast<int8_t>(0b00000000));\n+}\n+\n+TEST(FpTruncExecutionTest, F16ToF8e4m3fn_Vector4) {\n+  JitRunner jit = CreateJitRunner(Type::V(F16, 4), Type::V(F8E4M3FN, 4));\n+  auto fptrunc = jit.GetVectorizedFn<4, int8_t, int16_t>(\n+      FpTrunc::Name(Type::V(F16, 4), Type::V(F8E4M3FN, 4)) + \"_itofp\");\n+  std::array<int16_t, 4> vals = {0x7FFF, 0x0,\n+                                 static_cast<int16_t>(0b1100000000000000),\n+                                 static_cast<int16_t>(0b0011100000000000)};\n+  std::array<int8_t, 4> actuals = fptrunc(vals);\n+  EXPECT_EQ(actuals[0], 0x7F);\n+  EXPECT_EQ(actuals[1], 0x0);\n+  EXPECT_EQ(actuals[2], static_cast<int8_t>(0b11000000));\n+  EXPECT_EQ(actuals[3], static_cast<int8_t>(0b00110000));\n+}\n+\n+TEST(FpTruncExecutionTest, F8e4m3fnToF16) {\n+  JitRunner jit = CreateJitRunner(Type::S(F8E4M3FN), Type::S(F16));\n+  auto fptrunc = jit.GetScalarFn<int16_t(int8_t)>(\n+      FpTrunc::Name(Type::S(F8E4M3FN), Type::S(F16)) + \"_fptoi\");\n+  EXPECT_EQ(fptrunc(static_cast<int8_t>(0b11000000)),\n+            static_cast<int16_t>(0b1100000000000000));  // -2.0\n+  EXPECT_EQ(fptrunc(static_cast<int8_t>(0b00110000)),\n+            static_cast<int16_t>(0b0011100000000000));  // 0.5\n+  EXPECT_EQ(fptrunc(static_cast<int8_t>(0b10110000)),\n+            static_cast<int16_t>(0b1011100000000000));  // -0.5\n+}\n+\n+TEST(FpTruncExecutionTest, F8e4m3fnToF16_Vector4) {\n+  JitRunner jit = CreateJitRunner(Type::V(F8E4M3FN, 4), Type::V(F16, 4));\n+  auto fptrunc = jit.GetVectorizedFn<4, int16_t, int8_t>(\n+      FpTrunc::Name(Type::V(F8E4M3FN, 4), Type::V(F16, 4)) + \"_fptoi\");\n+  std::array<int8_t, 4> vals = {static_cast<int8_t>(0b11000000), 0x0,\n+                                static_cast<int8_t>(0b10110000),\n+                                static_cast<int8_t>(0b00110000)};\n+  std::array<int16_t, 4> actuals = fptrunc(vals);\n+  EXPECT_EQ(actuals[0], static_cast<int16_t>(0b1100000000000000));\n+  EXPECT_EQ(actuals[1], static_cast<int16_t>(0b0000000000000000));\n+  EXPECT_EQ(actuals[2], static_cast<int16_t>(0b1011100000000000));\n+  EXPECT_EQ(actuals[3], static_cast<int16_t>(0b0011100000000000));\n+}\n+\n }  // namespace xla::codegen::intrinsics"
        },
        {
            "sha": "1bdb29108dcdfeb06033bdb52190bf5f9224cfd6",
            "filename": "third_party/xla/xla/codegen/intrinsic/intrinsic_compiler_lib.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 60,
            "changes": 68,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic_compiler_lib.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic_compiler_lib.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic_compiler_lib.cc?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -16,15 +16,12 @@ limitations under the License.\n #include \"xla/codegen/intrinsic/intrinsic_compiler_lib.h\"\n \n #include <utility>\n-#include <vector>\n \n-#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/functional/function_ref.h\"\n #include \"absl/strings/string_view.h\"\n #include \"llvm/Analysis/CGSCCPassManager.h\"\n #include \"llvm/Analysis/LoopAnalysisManager.h\"\n #include \"llvm/IR/Constant.h\"\n-#include \"llvm/IR/Constants.h\"\n-#include \"llvm/IR/DerivedTypes.h\"\n #include \"llvm/IR/GlobalValue.h\"\n #include \"llvm/IR/GlobalVariable.h\"\n #include \"llvm/IR/Module.h\"\n@@ -36,6 +33,7 @@ limitations under the License.\n #include \"llvm/Transforms/InstCombine/InstCombine.h\"\n #include \"llvm/Transforms/Scalar/DCE.h\"\n #include \"llvm/Transforms/Scalar/EarlyCSE.h\"\n+#include \"llvm/Transforms/Utils/ModuleUtils.h\"\n \n namespace xla::codegen::intrinsic {\n \n@@ -66,65 +64,15 @@ void RunInlineAndOptPasses(llvm::Module& module) {\n   mpm.run(module, mam);\n }\n \n-constexpr absl::string_view kCompilerUsedName = \"llvm.compiler.used\";\n-\n void RemoveFromCompilerUsed(\n     llvm::Module& module,\n-    absl::flat_hash_set<absl::string_view> replaced_functions) {\n-  if (replaced_functions.empty()) {\n-    return;\n-  }\n-\n-  llvm::GlobalVariable* compiler_used =\n-      module.getNamedGlobal(kCompilerUsedName);\n-  if (!compiler_used) {\n-    return;\n-  }\n-\n-  llvm::ConstantArray* old_array =\n-      llvm::dyn_cast<llvm::ConstantArray>(compiler_used->getInitializer());\n-  if (!old_array) {\n-    return;\n-  }\n-\n-  // Collect the constants that should be kept.\n-  std::vector<llvm::Constant*> elements;\n-  elements.reserve(old_array->getNumOperands());\n-  for (int i = 0; i < old_array->getNumOperands(); ++i) {\n-    auto* operand = old_array->getOperand(i);\n-    llvm::GlobalValue* gv =\n-        llvm::dyn_cast<llvm::GlobalValue>(operand->stripPointerCasts());\n-\n-    if (gv && replaced_functions.contains(gv->getName())) {\n-      continue;\n+    absl::FunctionRef<bool(absl::string_view)> should_remove) {\n+  llvm::removeFromUsedLists(module, [&](llvm::Constant* c) {\n+    if (auto* f = llvm::dyn_cast<llvm::Function>(c)) {\n+      return should_remove(f->getName());\n     }\n-    elements.push_back(operand);\n-  }\n-\n-  // If all functions were removed, erase the global entirely.\n-  if (elements.empty()) {\n-    compiler_used->eraseFromParent();\n-    return;\n-  }\n-\n-  // If only some functions were removed, modify the existing global in-place.\n-  if (elements.size() < old_array->getNumOperands()) {\n-    llvm::ArrayType* new_array_type = llvm::ArrayType::get(\n-        old_array->getType()->getElementType(), elements.size());\n-    llvm::Constant* new_array_init =\n-        llvm::ConstantArray::get(new_array_type, elements);\n-\n-    // Create a new global llvm.compiler.used with the new contents.\n-    auto new_global =\n-        new llvm::GlobalVariable(module, new_array_type, false,\n-                                 compiler_used->getLinkage(), new_array_init);\n-    new_global->copyAttributesFrom(compiler_used);\n-    new_global->setSection(compiler_used->getSection());\n-    new_global->setAlignment(compiler_used->getAlign());\n-    new_global->takeName(compiler_used);\n-\n-    compiler_used->eraseFromParent();\n-  }\n+    return false;\n+  });\n }\n \n }  // namespace xla::codegen::intrinsic"
        },
        {
            "sha": "dfa0e6e81aedd8a64c8acdbfdbdbe23d21308908",
            "filename": "third_party/xla/xla/codegen/intrinsic/intrinsic_compiler_lib.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic_compiler_lib.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic_compiler_lib.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic_compiler_lib.h?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n #define XLA_CODEGEN_INTRINSIC_INTRINSIC_COMPILER_LIB_H_\n \n #include \"absl/container/flat_hash_set.h\"\n+#include \"absl/functional/function_ref.h\"\n #include \"absl/strings/string_view.h\"\n #include \"llvm/IR/Module.h\"\n \n@@ -34,7 +35,7 @@ void RunInlineAndOptPasses(llvm::Module& module);\n // removed by GlobalDCEPass.\n void RemoveFromCompilerUsed(\n     llvm::Module& module,\n-    absl::flat_hash_set<absl::string_view> replaced_functions);\n+    absl::FunctionRef<bool(absl::string_view)> should_remove);\n \n }  // namespace xla::codegen::intrinsic\n "
        },
        {
            "sha": "aa36fe0ccb6dad1d9fe4b528e84da4123586ba56",
            "filename": "third_party/xla/xla/codegen/intrinsic/intrinsic_compiler_lib_test.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 5,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic_compiler_lib_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic_compiler_lib_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic_compiler_lib_test.cc?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -103,7 +103,8 @@ TEST_F(RemoveFromCompilerUsedTest, RemovesSpecifiedFunctions) {\n   CreateCompilerUsedArray({\"func1\", \"func2\", \"func3\", \"func4\"});\n   absl::flat_hash_set<absl::string_view> to_remove = {\"func2\", \"func4\"};\n \n-  RemoveFromCompilerUsed(*module_, to_remove);\n+  RemoveFromCompilerUsed(*module_,\n+                         [&](auto n) { return to_remove.contains(n); });\n \n   std::vector<std::string> remaining = GetCompilerUsedFunctionNames();\n   EXPECT_EQ(remaining.size(), 2) << absl::StrJoin(remaining, \", \");\n@@ -117,7 +118,8 @@ TEST_F(RemoveFromCompilerUsedTest, RemovesEntireArrayWhenAllFunctionsRemoved) {\n   CreateCompilerUsedArray({\"func1\", \"func2\"});\n   absl::flat_hash_set<absl::string_view> to_remove = {\"func1\", \"func2\"};\n \n-  RemoveFromCompilerUsed(*module_, to_remove);\n+  RemoveFromCompilerUsed(*module_,\n+                         [&](auto n) { return to_remove.contains(n); });\n \n   EXPECT_EQ(module_->getNamedGlobal(\"llvm.compiler.used\"), nullptr);\n }\n@@ -127,7 +129,8 @@ TEST_F(RemoveFromCompilerUsedTest, HandlesNoCompilerUsedArray) {\n   absl::flat_hash_set<absl::string_view> to_remove = {\"func1\"};\n \n   // Act - should not crash\n-  RemoveFromCompilerUsed(*module_, to_remove);\n+  RemoveFromCompilerUsed(*module_,\n+                         [&](auto n) { return to_remove.contains(n); });\n \n   EXPECT_EQ(module_->getNamedGlobal(\"llvm.compiler.used\"), nullptr);\n }\n@@ -136,7 +139,8 @@ TEST_F(RemoveFromCompilerUsedTest, DoesNothingWhenNoMatches) {\n   CreateCompilerUsedArray({\"func1\", \"func2\"});\n   absl::flat_hash_set<absl::string_view> to_remove = {\"nonexistent\"};\n \n-  RemoveFromCompilerUsed(*module_, to_remove);\n+  RemoveFromCompilerUsed(*module_,\n+                         [&](auto n) { return to_remove.contains(n); });\n \n   std::vector<std::string> remaining = GetCompilerUsedFunctionNames();\n   EXPECT_EQ(remaining.size(), 2);\n@@ -150,7 +154,8 @@ TEST_F(RemoveFromCompilerUsedTest, HandlesEmptyRemovalSet) {\n   CreateCompilerUsedArray({\"func1\", \"func2\"});\n   absl::flat_hash_set<absl::string_view> to_remove = {};\n \n-  RemoveFromCompilerUsed(*module_, to_remove);\n+  RemoveFromCompilerUsed(*module_,\n+                         [&](auto n) { return to_remove.contains(n); });\n \n   std::vector<std::string> remaining = GetCompilerUsedFunctionNames();\n   EXPECT_EQ(remaining.size(), 2);"
        },
        {
            "sha": "704d604f6b3a118d600cc634c943d6ca1ac08472",
            "filename": "third_party/xla/xla/codegen/intrinsic_lib.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 4,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic_lib.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic_lib.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic_lib.cc?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -217,9 +217,11 @@ GetCalledApproximatableFunctions(\n   absl::flat_hash_map<absl::string_view, absl::flat_hash_set<absl::string_view>>\n       called_targets;\n   VisitFunctionCalls(module, [&](const llvm::CallInst& call) {\n-    if (auto it = targets.find(call.getCalledFunction()->getName());\n-        it != targets.end()) {\n-      called_targets[it->second].insert(it->first);\n+    if (call.getCalledFunction() != nullptr) {\n+      if (auto it = targets.find(call.getCalledFunction()->getName());\n+          it != targets.end()) {\n+        called_targets[it->second].insert(it->first);\n+      }\n     }\n   });\n   return called_targets;\n@@ -289,7 +291,7 @@ void CreateDefinitionAndReplaceDeclaration(llvm::Module& module,\n }\n \n absl::flat_hash_set<absl::string_view>\n-IntrinsicFunctionLib::RewriteIntrinsicFunctions(llvm::Module& module) {\n+IntrinsicFunctionLib::DefineIntrinsicFunctions(llvm::Module& module) {\n   // Find each called target function, generate the definition and insert it\n   // into the module.\n   // Keep track of the function names we replaced so we can remove them from\n@@ -313,4 +315,8 @@ IntrinsicFunctionLib::RewriteIntrinsicFunctions(llvm::Module& module) {\n   return replaced_functions;\n }\n \n+bool IntrinsicFunctionLib::IsIntrinsicFunction(\n+    absl::string_view function_name) const {\n+  return targets_.contains(function_name);\n+}\n }  // namespace xla::codegen"
        },
        {
            "sha": "cb49c88c8540c7ac51dd6e82aab1483c244c2f0e",
            "filename": "third_party/xla/xla/codegen/intrinsic_lib.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic_lib.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic_lib.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic_lib.h?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -85,9 +85,11 @@ class IntrinsicFunctionLib {\n   // Will insert definitions marked as always inline and then run LLVM inliner,\n   // constant propagation and early CSE passes to remove dead code.\n   // Returns the set of function names that were replaced.\n-  absl::flat_hash_set<absl::string_view> RewriteIntrinsicFunctions(\n+  absl::flat_hash_set<absl::string_view> DefineIntrinsicFunctions(\n       llvm::Module& module);\n \n+  bool IsIntrinsicFunction(absl::string_view function_name) const;\n+\n  private:\n   std::vector<std::unique_ptr<IntrinsicFunction>> intrinsic_functions_;\n   absl::flat_hash_map<absl::string_view, absl::string_view> targets_;"
        },
        {
            "sha": "55abb9eee1716d5ebc4b19010b47b8e2096fd66d",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -4172,6 +4172,7 @@ cc_library(\n         \"//xla/service/llvm_ir:llvm_loop\",\n         \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/service/llvm_ir:loop_emitter\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n@@ -4209,16 +4210,12 @@ xla_test(\n         \"//xla:types\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:test\",\n-        \"//xla/service/llvm_ir:ir_array\",\n-        \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/tests:hlo_test_base\",\n         \"//xla/tests:xla_internal_test_main\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n         \"@com_google_googletest//:gtest\",\n-        \"@llvm-project//llvm:ir_headers\",\n         \"@local_tsl//tsl/platform:ml_dtypes\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n "
        },
        {
            "sha": "6ad2ebf11db466f43d1f7234ab1fdf79fe4a7a61",
            "filename": "third_party/xla/xla/service/elemental_ir_emitter.cc",
            "status": "modified",
            "additions": 37,
            "deletions": 449,
            "changes": 486,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.cc?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include <functional>\n #include <limits>\n #include <memory>\n+#include <optional>\n #include <string>\n #include <tuple>\n #include <utility>\n@@ -71,6 +72,7 @@ limitations under the License.\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/types.h\"\n #include \"xla/util.h\"\n #include \"xla/window_util.h\"\n@@ -79,6 +81,7 @@ limitations under the License.\n namespace xla {\n \n using absl::StrCat;\n+using llvm_ir::EmitReducePrecisionIR;\n using llvm_ir::IrArray;\n using llvm_ir::IrName;\n using llvm_ir::SetToFirstInsertPoint;\n@@ -87,259 +90,8 @@ using xla::float8_fnuz_ir_emitter::EmitFloatingToF8fnuz;\n \n using IntrinsicType = xla::codegen::intrinsics::Type;\n \n-absl::StatusOr<llvm::Value*> EmitReducePrecisionIR(\n-    PrimitiveType src_ty, llvm::Value* x, int64_t dest_exponent_bits,\n-    int64_t dest_mantissa_bits, bool quiet_nans, llvm::IRBuilderBase* b) {\n-  using llvm::APInt;\n-\n-  if (!primitive_util::IsFloatingPointType(src_ty)) {\n-    return Unimplemented(\n-        \"ReducePrecision cannot accept non-floating-point type %s.\",\n-        PrimitiveType_Name(src_ty));\n-  }\n-\n-  // Integer and float types for casting and constant generation.\n-  llvm::Type* float_type = x->getType();\n-  int64_t nbits = float_type->getPrimitiveSizeInBits();\n-  llvm::IntegerType* int_type = b->getIntNTy(nbits);\n-\n-  // SignificandWidth includes the implicit extra bit.\n-  int src_mantissa_bits = primitive_util::SignificandWidth(src_ty) - 1;\n-  int src_exponent_bits = nbits - 1 - src_mantissa_bits;\n-\n-  // Cast the input value to an integer for bitwise manipulation.\n-  llvm::Value* x_as_int = b->CreateBitCast(x, int_type);\n-\n-  // Clear the sign bit, it does not participate in rounding and we will restore\n-  // it later.\n-  APInt sign_bit_mask(nbits, 1);\n-  sign_bit_mask <<= nbits - 1;\n-  llvm::Value* x_abs_bits =\n-      b->CreateAnd(x_as_int, llvm::ConstantInt::get(int_type, ~sign_bit_mask));\n-\n-  APInt exp_bits_mask(nbits, 1);\n-  exp_bits_mask = ((exp_bits_mask << src_exponent_bits) - 1)\n-                  << src_mantissa_bits;\n-  auto x_is_nan = b->CreateICmpUGT(\n-      x_abs_bits, llvm::ConstantInt::get(int_type, exp_bits_mask));\n-\n-  if (dest_mantissa_bits < src_mantissa_bits) {\n-    // Last remaining mantissa bit.\n-    APInt last_mantissa_bit_mask(nbits, 1);\n-    last_mantissa_bit_mask <<= src_mantissa_bits - dest_mantissa_bits;\n-\n-    // Compute rounding bias for round-to-nearest with ties to even.  This is\n-    // equal to a base value of 0111... plus one bit if the last remaining\n-    // mantissa bit is 1.\n-    APInt base_rounding_bias = last_mantissa_bit_mask.lshr(1) - 1;\n-    llvm::Value* x_last_mantissa_bit = b->CreateLShr(\n-        b->CreateAnd(x_as_int,\n-                     llvm::ConstantInt::get(int_type, last_mantissa_bit_mask)),\n-        (src_mantissa_bits - dest_mantissa_bits));\n-    llvm::Value* x_rounding_bias =\n-        b->CreateAdd(x_last_mantissa_bit,\n-                     llvm::ConstantInt::get(int_type, base_rounding_bias));\n-\n-    // Add rounding bias, and mask out truncated bits.  Note that the case\n-    // where adding the rounding bias overflows into the exponent bits is\n-    // correct; the non-masked mantissa bits will all be zero, and the\n-    // exponent will be incremented by one.\n-    APInt truncation_mask = ~(last_mantissa_bit_mask - 1);\n-    llvm::Value* x_rounded = b->CreateAdd(x_as_int, x_rounding_bias);\n-    x_rounded = b->CreateAnd(x_rounded,\n-                             llvm::ConstantInt::get(int_type, truncation_mask));\n-    if (quiet_nans) {\n-      x_as_int = b->CreateSelect(x_is_nan, x_as_int, x_rounded);\n-    } else {\n-      x_as_int = x_rounded;\n-    }\n-  }\n-\n-  if (dest_exponent_bits < src_exponent_bits) {\n-    // An exponent of 2^(n-1)-1 -- that is, 0111... with the zero in the most-\n-    // significant bit -- is equal to 1.0f for all exponent sizes.  Adding\n-    // 2^(n-1)-1 to this gives us the highest non-infinite exponent for a bit-\n-    // size of n, and subtracting 2^(n-1)-1 from this gives us the lowest'\n-    // exponent (corresponding to 0.0f).\n-    //\n-    // Thus, the f32 exponent corresponding to the highest non-infinite\n-    // exponent for a bit size of n is (2^7-1) + 2^(n-1)-1, and the f32\n-    // exponent corresponding to the lowest exponent for a bit size of n is\n-    // (2^7-1) - 2^(n-1)-1.\n-    //\n-    // Note that we have already checked that exponents_bits >= 1.\n-    APInt exponent_bias(nbits, 1);\n-    exponent_bias = (exponent_bias << (src_exponent_bits - 1)) - 1;\n-\n-    APInt reduced_exponent_bias(nbits, 1);\n-    reduced_exponent_bias =\n-        (reduced_exponent_bias << (dest_exponent_bits - 1)) - 1;\n-\n-    APInt reduced_max_exponent = exponent_bias + reduced_exponent_bias;\n-    APInt reduced_min_exponent = exponent_bias - reduced_exponent_bias;\n-\n-    // Do we overflow or underflow?\n-    llvm::Value* x_exponent =\n-        b->CreateAnd(x_as_int, llvm::ConstantInt::get(int_type, exp_bits_mask));\n-    llvm::Value* x_overflows = b->CreateICmpUGT(\n-        x_exponent, llvm::ConstantInt::get(\n-                        int_type, reduced_max_exponent << src_mantissa_bits));\n-    llvm::Value* x_underflows = b->CreateICmpULE(\n-        x_exponent, llvm::ConstantInt::get(\n-                        int_type, reduced_min_exponent << src_mantissa_bits));\n-\n-    // Compute appropriately-signed values of zero and infinity.\n-    llvm::Value* x_signed_zero =\n-        b->CreateAnd(x_as_int, llvm::ConstantInt::get(int_type, sign_bit_mask));\n-    llvm::Value* x_signed_inf = b->CreateOr(\n-        x_signed_zero, llvm::ConstantInt::get(int_type, exp_bits_mask));\n-\n-    // Force to zero or infinity if overflow or underflow.  (Note that this\n-    // truncates all denormal values to zero, rather than rounding them.)\n-    x_as_int = b->CreateSelect(x_overflows, x_signed_inf, x_as_int);\n-    x_as_int = b->CreateSelect(x_underflows, x_signed_zero, x_as_int);\n-  }\n-\n-  // Cast the result back to a floating-point type.\n-  llvm::Value* result = b->CreateBitCast(x_as_int, float_type);\n-\n-  // Correct result for NaN inputs.\n-  //\n-  // The exponent handling will \"normalize\" NaN values to infinities, which is\n-  // undesirable (except in the case with no mantissa bits, in which case it\n-  // is mandatory).  This logic also handles cases where mantissa-rounding\n-  // causes a NaN's mantissa to overflow into the exponent bits, which would\n-  // otherwise create an erroneous zero value.\n-\n-  if (dest_mantissa_bits > 0) {\n-    if (quiet_nans) {\n-      APInt qnan_mask(nbits, 1);\n-      qnan_mask <<= src_mantissa_bits - 1;\n-      llvm::Value* x_with_qnan_bit_set =\n-          b->CreateOr(x_as_int, llvm::ConstantInt::get(int_type, qnan_mask));\n-      x_with_qnan_bit_set = b->CreateBitCast(x_with_qnan_bit_set, float_type);\n-      result = b->CreateSelect(x_is_nan, x_with_qnan_bit_set, result);\n-    } else {\n-      result = b->CreateSelect(x_is_nan, x, result);\n-    }\n-  } else {\n-    result = b->CreateSelect(x_is_nan,\n-                             llvm::ConstantFP::getInfinity(float_type), result);\n-  }\n-\n-  return result;\n-}\n-\n namespace {\n \n-template <PrimitiveType fx_type, int f8_exponent_bits>\n-llvm::Value* handle_halfway_points_FxToF8(llvm::Value* fx_abs_bits,\n-                                          llvm::Value* f8_bits,\n-                                          llvm::IRBuilderBase* b) {\n-  using llvm::APFloat;\n-  using llvm::APInt;\n-  using llvm::Value;\n-  static_assert(fx_type == F16 || fx_type == F32 || fx_type == F64);\n-  static_assert(3 <= f8_exponent_bits && f8_exponent_bits <= 4);\n-\n-  const llvm::fltSemantics* fx_semantics;\n-  llvm::IntegerType* ix_type;\n-\n-  if constexpr (fx_type == F16) {\n-    fx_semantics = &llvm::APFloat::IEEEhalf();\n-    ix_type = b->getInt16Ty();\n-  } else if constexpr (fx_type == F32) {\n-    fx_semantics = &llvm::APFloat::IEEEsingle();\n-    ix_type = b->getInt32Ty();\n-  } else if constexpr (fx_type == F64) {\n-    fx_semantics = &llvm::APFloat::IEEEdouble();\n-    ix_type = b->getInt64Ty();\n-  }\n-\n-  auto ix_const = [fx_semantics, ix_type](APFloat val) {\n-    bool losesInfo;\n-    val.convert(*fx_semantics, llvm::RoundingMode::NearestTiesToEven,\n-                &losesInfo);\n-    return llvm::ConstantInt::get(ix_type, val.bitcastToAPInt());\n-  };\n-\n-  llvm::IntegerType* i8_type = b->getInt8Ty();\n-  auto i8_const = [i8_type](int val) {\n-    return llvm::ConstantInt::get(i8_type, val);\n-  };\n-\n-  // F16 values that are halfway between denormal F8 values. This is used to\n-  // determine how to round to denormal F8 values.\n-  const APFloat halfway_points_e4[8] = {\n-      APFloat(0x1.0p-10),  // halfway between [0/8 * 2^-6, 1/8 * 2^-6]\n-      APFloat(0x1.8p-9),   // halfway between [1/8 * 2^-6, 2/8 * 2^-6]\n-      APFloat(0x1.4p-8),   // halfway between [2/8 * 2^-6, 3/8 * 2^-6]\n-      APFloat(0x1.Cp-8),   // halfway between [3/8 * 2^-6, 4/8 * 2^-6]\n-      APFloat(0x1.2p-7),   // halfway between [4/8 * 2^-6, 5/8 * 2^-6]\n-      APFloat(0x1.6p-7),   // halfway between [5/8 * 2^-6, 6/8 * 2^-6]\n-      APFloat(0x1.Ap-7),   // halfway between [6/8 * 2^-6, 7/8 * 2^-6]\n-      APFloat(0x1.Ep-7)    // halfway between [7/8 * 2^-6, 8/8 * 2^-6]\n-  };\n-\n-  const APFloat halfway_points_e3[16] = {\n-      APFloat(0x1.0p-7),  // halfway between [0/16 * 2^-2, 1/16 * 2^-2]\n-      APFloat(0x1.8p-6),  // halfway between [1/16 * 2^-2, 2/16 * 2^-2]\n-      APFloat(0x1.4p-5),  // halfway between [2/16 * 2^-2, 3/16 * 2^-2]\n-      APFloat(0x1.Cp-5),  // halfway between [3/16 * 2^-2, 4/16 * 2^-2]\n-      APFloat(0x1.2p-4),  // halfway between [4/16 * 2^-2, 5/16 * 2^-2]\n-      APFloat(0x1.6p-4),  // halfway between [5/16 * 2^-2, 6/16 * 2^-2]\n-      APFloat(0x1.Ap-4),  // halfway between [6/16 * 2^-2, 7/16 * 2^-2]\n-      APFloat(0x1.Ep-4),  // halfway between [7/16 * 2^-2, 8/16 * 2^-2]\n-      APFloat(0x1.1p-3),  // halfway between [8/16 * 2^-2, 9/16 * 2^-2]\n-      APFloat(0x1.3p-3),  // halfway between [9/16 * 2^-2, 10/16 * 2^-2]\n-      APFloat(0x1.5p-3),  // halfway between [10/16 * 2^-2, 11/16 * 2^-2]\n-      APFloat(0x1.7p-3),  // halfway between [11/16 * 2^-2, 12/16 * 2^-2]\n-      APFloat(0x1.9p-3),  // halfway between [12/16 * 2^-2, 13/16 * 2^-2]\n-      APFloat(0x1.Bp-3),  // halfway between [13/16 * 2^-2, 14/16 * 2^-2]\n-      APFloat(0x1.Dp-3),  // halfway between [14/16 * 2^-2, 15/16 * 2^-2]\n-      APFloat(0x1.Fp-3),  // halfway between [15/16 * 2^-2, 16/16 * 2^-2]\n-  };\n-\n-  const APFloat* halfway_points;\n-  int arr_sz;\n-  if constexpr (f8_exponent_bits == 4) {\n-    halfway_points = halfway_points_e4;\n-    arr_sz = 8;\n-  } else if constexpr (f8_exponent_bits == 3) {\n-    halfway_points = halfway_points_e3;\n-    arr_sz = 16;\n-  }\n-\n-  // Handle case where output is denormal. If we're rounding to a denormal\n-  // value, ignore the current value of f8_bits and set it to the correct\n-  // denormal value. We emit the equivalent of the following:\n-  //\n-  //   if (f16_abs_bits <= halfway_points[0]) {\n-  //     f8_bits = 0;\n-  //   } else if (f16_abs_bits < halfway_points[1]) {\n-  //     f8_bits = 1;\n-  //   } else if (f16_abs_bits <= halfway_points[2]) {\n-  //   ...  // More if-else statements. The comparisons alternate between <=\n-  //   ...  // and < to handle round-to-even properly.\n-  //   } else if (f16_abs_bits < halfway_points[7])  {\n-  //     f8_bits = 7;\n-  //   }\n-  for (int i = arr_sz - 1; i >= 0; i--) {\n-    Value* comparison;\n-    llvm::Constant* half_way_point = ix_const(halfway_points[i]);\n-\n-    if (i % 2 == 0) {\n-      comparison = b->CreateICmpULE(fx_abs_bits, half_way_point);\n-    } else {\n-      comparison = b->CreateICmpULT(fx_abs_bits, half_way_point);\n-    }\n-\n-    f8_bits = b->CreateSelect(comparison, i8_const(i), f8_bits);\n-  }\n-\n-  return f8_bits;\n-}\n-\n absl::StatusOr<llvm::Value*> EmitF16ToF8e5m2(llvm::Value* f16_value,\n                                              llvm::IRBuilderBase* b) {\n   TF_ASSIGN_OR_RETURN(\n@@ -469,8 +221,8 @@ absl::StatusOr<llvm::Value*> EmitFxToF8e(llvm::Value* fx_value,\n   Value* f8_bits = b->CreateTrunc(fx_reduced, i8_type);\n \n   // Handle Fx values that are halfway between denormal F8 values.\n-  f8_bits = handle_halfway_points_FxToF8<fx_type, f8_exponent_bits>(fx_abs_bits,\n-                                                                    f8_bits, b);\n+  f8_bits = llvm_ir::HandleHalfwayPointsFxToF8<fx_type, f8_exponent_bits>(\n+      fx_abs_bits, f8_bits, std::nullopt, b);\n \n   // Set the sign bit.\n   //   f8_bits |= f8_sign\n@@ -608,192 +360,23 @@ llvm::Value* EmitToF16F8e(llvm::Value* f8_value, llvm::IRBuilderBase* b) {\n   return b->CreateBitCast(f16_as_int, b->getHalfTy());\n }\n \n-llvm::Value* EmitF16ToF8e4m3fn(llvm::Value* f16_value, llvm::IRBuilderBase* b) {\n-  using llvm::APInt;\n-  using llvm::Value;\n-\n-  llvm::IntegerType* i8_type = b->getInt8Ty();\n-  llvm::IntegerType* i16_type = b->getInt16Ty();\n-  auto i8_const = [i8_type](int val) {\n-    return llvm::ConstantInt::get(i8_type, val);\n-  };\n-  auto i16_const = [i16_type](int val) {\n-    return llvm::ConstantInt::get(i16_type, val);\n-  };\n-\n-  // Cast the input value to an integer for bitwise manipulation. Get the\n-  // absolute value of the input value.\n-  //   f16_as_int = bitcast(f16_value, int)\n-  //   f16_abs_bits = f16_as_int & 0x7FFF\n-  Value* f16_as_int = b->CreateBitCast(f16_value, i16_type);\n-  llvm::Value* f16_abs_bits = b->CreateAnd(f16_as_int, i16_const(0x7FFF));\n-\n-  // Get the sign.\n-  //   f8_sign = (f16_as_int & 0x8000) >> 8\n-  Value* f16_sign = b->CreateAnd(f16_as_int, i16_const(0x8000));\n-  f16_sign = b->CreateLShr(f16_sign, i16_const(8));\n-  Value* f8_sign = b->CreateTrunc(f16_sign, i8_type);\n-\n-  // Truncate the mantissa to 3 bits. ReducePrecision cannot deal with\n-  // f8E4M3FN's NaN representations, so don't use ReducePrecision to handle\n-  // exponent reduction. Denormal values are not handled properly here and are\n-  // dealt with later in this function.\n-  absl::StatusOr<Value*> f16_reduced_statusor = EmitReducePrecisionIR(\n-      /*src_ty=*/F16, f16_value,\n-      /*dest_exponent_bits=*/5,\n-      /*dest_mantissa_bits=*/3,\n-      /*quiet_nans=*/false, b);\n-  CHECK_OK(f16_reduced_statusor.status());  // Crash OK\n-  Value* f16_reduced = f16_reduced_statusor.value();\n-  f16_reduced = b->CreateBitCast(f16_reduced, i16_type);\n-\n-  // Remove the sign bit.\n-  //   f16_reduced = f16_reduced & 0x7FFF\n-  f16_reduced = b->CreateAnd(f16_reduced, i16_const(0x7FFF));\n-\n-  // Bits of the F16 representation of the smallest F8 normal value.\n-  constexpr int min_normal_value = 0x2400;\n-\n-  // Round values smaller than the smallest F8 normal value up to the smallest\n-  // F8 normal value. The case where we round to a denormal value is handled\n-  // later.\n-  //    f16_reduced = max(f16_reduced, min_normal_value)\n-  f16_reduced = b->CreateSelect(\n-      b->CreateICmpULT(f16_reduced, i16_const(min_normal_value)),\n-      i16_const(min_normal_value), f16_reduced);\n-\n-  constexpr int exponent_bias_difference = 15 - 7;\n-  constexpr int f8_exponent_bits = 4;\n-  constexpr int f16_mantissa_bits = 10;\n-  constexpr int f8_mantissa_bits = 3;\n-  constexpr int mantissa_bits_difference = f16_mantissa_bits - f8_mantissa_bits;\n-\n-  // Adjust the exponent by subtracting the difference in exponent bias.\n-  //   f16_reduced -= (exponent_bias_difference << f16_mantissa_bits)\n-  f16_reduced = b->CreateSub(\n-      f16_reduced, i16_const(exponent_bias_difference << f16_mantissa_bits));\n-\n-  // Shift to convert to F8.\n-  //   f8_bits = f16_reduced >> mantissa_bits_difference;\n-  Value* f8_bits =\n-      b->CreateLShr(f16_reduced, i16_const(mantissa_bits_difference));\n-  f8_bits = b->CreateTrunc(f8_bits, i8_type);\n-\n-  // Bits of the highest F16 value that gets converted to a finite F8 value.\n-  // In binary: 0 10111 1101111111\n-  constexpr int max_finite_value = 0x5F7F;\n-\n-  // If we're above the maximum F8 value, output NaN.\n-  //   f8_bits = f16_abs_bits > max_finite_value ? 0x7F : f8_bits\n-  f8_bits = b->CreateSelect(\n-      b->CreateICmpUGT(f16_abs_bits, i16_const(max_finite_value)),\n-      i8_const(0x7F), f8_bits);\n-\n-  // Handle F16 values that are halfway between denormal F8 values.\n-  f8_bits = handle_halfway_points_FxToF8<F16, f8_exponent_bits>(f16_abs_bits,\n-                                                                f8_bits, b);\n-\n-  // Set the sign bit.\n-  //   f8_bits |= f8_sign\n-  f8_bits = b->CreateOr(f8_bits, f8_sign);\n-  return f8_bits;\n+llvm::Value* EmitF16ToF8e4m3fn(llvm::Value* f16_value, llvm::Module* module,\n+                               llvm::IRBuilderBase* b) {\n+  llvm::Function* fptrunc =\n+      codegen::intrinsics::FpTrunc::GetOrInsertDeclaration(\n+          module, IntrinsicType::S(F16), IntrinsicType::S(F8E4M3FN));\n+  return b->CreateCall(fptrunc, {f16_value});\n }\n-\n-llvm::Value* EmitF8e4m3fnToF16(llvm::Value* f8_value, llvm::IRBuilderBase* b) {\n-  using llvm::APInt;\n-  using llvm::Value;\n-\n-  llvm::IntegerType* i8_type = b->getInt8Ty();\n-  llvm::IntegerType* i16_type = b->getInt16Ty();\n-  auto i8_const = [i8_type](int val) {\n-    return llvm::ConstantInt::get(i8_type, val);\n-  };\n-  auto i16_const = [i16_type](int val) {\n-    return llvm::ConstantInt::get(i16_type, val);\n-  };\n-\n-  // Cast the input value to an integer for bitwise manipulation. Get the\n-  // absolute value of the input value.\n-  //   f8_as_int = bitcast(f16_value, int)\n-  //   f8_abs_bits = f8_as_int & 0x7F\n-  Value* f8_as_int = b->CreateBitCast(f8_value, i8_type);\n-  Value* f8_abs_bits = b->CreateAnd(f8_as_int, i8_const(0x7F));\n-\n-  // We assume below that the value is neither NaN nor denormal. If it NaN or\n-  // denormal, the output is set to NaN or zero at the end using Select\n-  // instructions.\n-\n-  // Get the sign:\n-  //   f16_sign = (f8_as_int & 0x80) << 8\n-  Value* f8_sign = b->CreateAnd(f8_as_int, i8_const(0x80));\n-  Value* f16_sign = b->CreateZExt(f8_sign, i16_type);\n-  f16_sign = b->CreateShl(f16_sign, i16_const(8));\n-\n-  constexpr int exponent_bias_difference = 15 - 7;\n-  constexpr int f16_mantissa_bits = 10;\n-  constexpr int f8_mantissa_bits = 3;\n-  constexpr int mantissa_bits_difference = f16_mantissa_bits - f8_mantissa_bits;\n-  constexpr int f8_mantissa_mask = (1 << f8_mantissa_bits) - 1;\n-\n-  // Get the exponent:\n-  //   f8_exponent = (f8_as_int & 0x78) >> f8_mantissa_bits\n-  Value* f8_exponent_bits = b->CreateAnd(f8_as_int, i8_const(0x78));\n-  Value* f8_exponent =\n-      b->CreateLShr(f8_exponent_bits, i8_const(f8_mantissa_bits));\n-\n-  // Adjust the exponent by adding the difference in exponent bias:\n-  //   f16_exponent = (f8_exponent + exponent_bias_difference)\n-  //                  << f16_mantissa_bits\n-  Value* f16_exponent =\n-      b->CreateAdd(f8_exponent, i8_const(exponent_bias_difference));\n-  f16_exponent = b->CreateZExt(f16_exponent, i16_type);\n-  f16_exponent = b->CreateShl(f16_exponent, i16_const(f16_mantissa_bits));\n-\n-  // Get the mantissa:\n-  //   f16_mantissa = (f8_mantissa & f8_mantissa_mask)\n-  //                  << mantissa_bits_difference\n-  Value* f8_mantissa = b->CreateAnd(f8_as_int, i8_const(f8_mantissa_mask));\n-  Value* f16_mantissa = b->CreateZExt(f8_mantissa, i16_type);\n-  f16_mantissa =\n-      b->CreateShl(f16_mantissa, i16_const(mantissa_bits_difference));\n-\n-  // Combine the exponent and mantissa:\n-  //   f16_as_int = f16_exponent | f16_mantissa\n-  Value* f16_as_int = b->CreateOr(f16_exponent, f16_mantissa);\n-\n-  // Set output to NaN if input is NaN\n-  //   f16_as_int = f8_abs_bits == 0x7F ? 0x7E00 : f16_as_int\n-  Value* is_nan = b->CreateICmpEQ(f8_abs_bits, i8_const(0x7F));\n-  f16_as_int = b->CreateSelect(is_nan, i16_const(0x7E00), f16_as_int);\n-\n-  // Map from F8 denormal value to F16 value.\n-  int f8_denormal_to_f16[8] = {\n-      0x0000,  // 0\n-      0x1800,  // 1/8 * 2^-6\n-      0x1C00,  // 2/8 * 2^-6\n-      0x1E00,  // 3/8 * 2^-6\n-      0x2000,  // 4/8 * 2^-6\n-      0x2100,  // 5/8 * 2^-6\n-      0x2200,  // 6/8 * 2^-6\n-      0x2300,  // 7/8 * 2^-6\n-  };\n-\n-  // If the F8 value is denormal, use the map above to determine the correct F16\n-  // value.\n-  //    if (f8_abs_bits < 8) { f16_as_int = f8_denormal_to_f16[f8_abs_bits]; }\n-  for (int i = 0; i < ABSL_ARRAYSIZE(f8_denormal_to_f16); i++) {\n-    Value* is_denormal_value = b->CreateICmpEQ(f8_abs_bits, i8_const(i));\n-    f16_as_int = b->CreateSelect(is_denormal_value,\n-                                 i16_const(f8_denormal_to_f16[i]), f16_as_int);\n-  }\n-\n-  // Set the sign bit.\n-  //   f16_as_int |= f16_sign\n-  f16_as_int = b->CreateOr(f16_as_int, f16_sign);\n-  return b->CreateBitCast(f16_as_int, b->getHalfTy());\n+llvm::Value* EmitF8e4m3fnToF16(llvm::Value* f8_value, llvm::Module* module,\n+                               llvm::IRBuilderBase* b) {\n+  llvm::Function* fptrunc =\n+      codegen::intrinsics::FpTrunc::GetOrInsertDeclaration(\n+          module, IntrinsicType::S(F8E4M3FN), IntrinsicType::S(F16));\n+  return b->CreateCall(fptrunc, {f8_value});\n }\n \n llvm::Value* EmitF16ToF8e4m3b11fnuz(llvm::Value* f16_value,\n+                                    llvm::Module* module,\n                                     llvm::IRBuilderBase* b) {\n   using llvm::APInt;\n   using llvm::Value;\n@@ -813,7 +396,7 @@ llvm::Value* EmitF16ToF8e4m3b11fnuz(llvm::Value* f16_value,\n   // Re-scale the f16, then convert as-if it were e4m3fn.\n   f16_value = b->CreateFMul(\n       f16_value, llvm::ConstantFP::get(f16_value->getType(), 1 << (11 - 7)));\n-  auto* f8_value = EmitF16ToF8e4m3fn(f16_value, b);\n+  auto* f8_value = EmitF16ToF8e4m3fn(f16_value, module, b);\n \n   // e4m3b11 overflows to NaN.\n   f8_value = b->CreateSelect(no_overflow, f8_value, i8_const(0x80));\n@@ -822,7 +405,7 @@ llvm::Value* EmitF16ToF8e4m3b11fnuz(llvm::Value* f16_value,\n   return f8_value;\n }\n \n-llvm::Value* EmitF8e4m3b11fnuzToF16(llvm::Value* f8_value,\n+llvm::Value* EmitF8e4m3b11fnuzToF16(llvm::Value* f8_value, llvm::Module* module,\n                                     llvm::IRBuilderBase* b) {\n   using llvm::APInt;\n   using llvm::Value;\n@@ -842,7 +425,7 @@ llvm::Value* EmitF8e4m3b11fnuzToF16(llvm::Value* f8_value,\n   Value* f16_sign_bit =\n       b->CreateShl(b->CreateZExt(f8_sign_bit, i16_type), 16 - 8);\n \n-  auto* f16_value = EmitF8e4m3fnToF16(f8_value, b);\n+  auto* f16_value = EmitF8e4m3fnToF16(f8_value, module, b);\n   f16_value = b->CreateFMul(\n       f16_value,\n       llvm::ConstantFP::get(f16_value->getType(), 1.0 / (1 << (11 - 7))));\n@@ -1163,16 +746,15 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitIntegerUnaryOp(\n               b_);\n         }\n         if (to_type == F8E4M3FN) {\n-          return EmitF16ToF8e4m3fn(\n-              EmitIntegralToFloating(operand_value, from_type, F16, module_,\n-                                     b_),\n-              b_);\n+          operand_value = EmitIntegralToFloating(operand_value, from_type, F16,\n+                                                 module_, b_);\n+          return EmitF16ToF8e4m3fn(operand_value, module_, b_);\n         }\n         if (to_type == F8E4M3B11FNUZ) {\n           return EmitF16ToF8e4m3b11fnuz(\n               EmitIntegralToFloating(operand_value, from_type, F16, module_,\n                                      b_),\n-              b_);\n+              module_, b_);\n         }\n         if (to_type == F4E2M1FN) {\n           return EmitF16ToF4e2m1fn(\n@@ -1357,15 +939,18 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatUnaryOp(\n       }\n       if (from_type == F8E4M3FN) {\n         TF_RET_CHECK(to_type != F8E4M3FN);\n-        operand_value = EmitF8e4m3fnToF16(operand_value, b_);\n+        llvm::Function* fptrunc =\n+            codegen::intrinsics::FpTrunc::GetOrInsertDeclaration(\n+                module_, IntrinsicType::S(F8E4M3FN), IntrinsicType::S(F16));\n+        operand_value = b_->CreateCall(fptrunc, {operand_value});\n         from_type = F16;\n         if (from_type == to_type) {\n           return operand_value;\n         }\n       }\n       if (from_type == F8E4M3B11FNUZ) {\n         TF_RET_CHECK(to_type != F8E4M3B11FNUZ);\n-        operand_value = EmitF8e4m3b11fnuzToF16(operand_value, b_);\n+        operand_value = EmitF8e4m3b11fnuzToF16(operand_value, module_, b_);\n         from_type = F16;\n         if (from_type == to_type) {\n           return operand_value;\n@@ -1465,7 +1050,10 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatUnaryOp(\n               operand_value,\n               llvm_ir::PrimitiveTypeToIrType(F16, module_->getContext()));\n         }\n-        return EmitF16ToF8e4m3fn(operand_value, b_);\n+        llvm::Function* fptrunc =\n+            codegen::intrinsics::FpTrunc::GetOrInsertDeclaration(\n+                module_, IntrinsicType::S(F16), IntrinsicType::S(F8E4M3FN));\n+        return b_->CreateCall(fptrunc, {operand_value});\n       }\n       if (to_type == F8E4M3B11FNUZ) {\n         // Cast to F16 first. Casts to F8E4M3B11FNUZ must be from F16.\n@@ -1474,7 +1062,7 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatUnaryOp(\n               operand_value,\n               llvm_ir::PrimitiveTypeToIrType(F16, module_->getContext()));\n         }\n-        return EmitF16ToF8e4m3b11fnuz(operand_value, b_);\n+        return EmitF16ToF8e4m3b11fnuz(operand_value, module_, b_);\n       }\n       if (to_type == F4E2M1FN) {\n         // Cast to F16 first. Casts to F4E2M1FN must be from F16.\n@@ -2052,8 +1640,8 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatBinaryOp(\n         lhs_value = EmitToF16F8e<4>(lhs_value, b_);\n         rhs_value = EmitToF16F8e<4>(rhs_value, b_);\n       } else if (operand_type == F8E4M3FN) {\n-        lhs_value = EmitF8e4m3fnToF16(lhs_value, b_);\n-        rhs_value = EmitF8e4m3fnToF16(rhs_value, b_);\n+        lhs_value = EmitF8e4m3fnToF16(lhs_value, module_, b_);\n+        rhs_value = EmitF8e4m3fnToF16(rhs_value, module_, b_);\n       } else if (operand_type == F4E2M1FN) {\n         lhs_value = EmitF4e2m1fnToF16(lhs_value, b_);\n         rhs_value = EmitF4e2m1fnToF16(rhs_value, b_);"
        },
        {
            "sha": "036f1626cad8dd924778f53c61ce86d9ce352586",
            "filename": "third_party/xla/xla/service/elemental_ir_emitter.h",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.h?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -351,11 +351,6 @@ class ElementalIrEmitterForTests : public ElementalIrEmitter {\n \n   HloToElementGeneratorMap generator_map_;\n };\n-\n-absl::StatusOr<llvm::Value*> EmitReducePrecisionIR(\n-    PrimitiveType src_ty, llvm::Value* x, int64_t dest_exponent_bits,\n-    int64_t dest_mantissa_bits, bool quiet_nans, llvm::IRBuilderBase* b);\n-\n }  // namespace xla\n \n #endif  // XLA_SERVICE_ELEMENTAL_IR_EMITTER_H_"
        },
        {
            "sha": "7800b7542b392f4aff58275befdb3b6864e44b60",
            "filename": "third_party/xla/xla/service/elemental_ir_emitter_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 196,
            "changes": 196,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter_test.cc?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -27,33 +27,22 @@ limitations under the License.\n #include \"absl/strings/str_replace.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n-#include \"llvm/IR/IRBuilder.h\"\n-#include \"llvm/IR/LLVMContext.h\"\n-#include \"llvm/IR/Module.h\"\n #include \"xla/error_spec.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/testlib/test.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n #include \"xla/service/hlo_module_config.h\"\n-#include \"xla/service/llvm_ir/ir_array.h\"\n-#include \"xla/service/llvm_ir/llvm_util.h\"\n #include \"xla/tests/hlo_test_base.h\"\n #include \"xla/types.h\"\n #include \"tsl/platform/ml_dtypes.h\"\n-#include \"tsl/platform/statusor.h\"\n \n namespace xla {\n namespace {\n \n using std::nullopt;\n \n-struct EmitReducePrecisionIrTestCase {\n-  float input;\n-  std::string expected_res;\n-};\n-\n class ElementalIrEmitterExecutionTest : public HloTestBase {\n  protected:\n   void RunTest(const std::string& hlo_text, absl::Span<Literal* const> args) {\n@@ -130,191 +119,6 @@ ENTRY main {\n   RunTest(hlo_text, {&lhs, &rhs});\n }\n \n-TEST_F(ElementalIrEmitterExecutionTest, EmitReducePrecisionIR_F16ToF8e5m2) {\n-  llvm::LLVMContext llvm_context;\n-  llvm::IRBuilder<> builder(llvm_context);\n-  llvm::IRBuilderBase* b = &builder;\n-  llvm::Type* f16_type = b->getHalfTy();\n-\n-  float inf = std::numeric_limits<float>::infinity();\n-  float qnan = std::numeric_limits<float>::quiet_NaN();\n-  float snan = std::numeric_limits<float>::signaling_NaN();\n-\n-  EmitReducePrecisionIrTestCase test_cases[] = {\n-      // clang-format off\n-      {0.0, \"half 0xH0000\"},\n-      {0x1.0p-14, \"half 0xH0400\"},\n-      {0.250, \"half 0xH3400\"},\n-      {1.0, \"half 0xH3C00\"},\n-      {0x1.2p0, \"half 0xH3C00\"},\n-      {0x1.Cp15, \"half 0xH7B00\"},\n-      {-0x1.Cp15, \"half 0xHFB00\"},\n-      {0x1.Dp15, \"half 0xH7B00\"},\n-      {0x1.Ep15, \"half 0xH7C00\"},\n-      {0x1.0p16, \"half 0xH7C00\"},\n-      {inf, \"half 0xH7C00\"},\n-      {-inf, \"half 0xHFC00\"},\n-      {qnan, \"half 0xH7E00\"},\n-      {-qnan, \"half 0xHFE00\"},\n-      {snan, \"half 0xH7F00\"},\n-      {-snan, \"half 0xHFF00\"},\n-      // clang-format on\n-  };\n-\n-  for (auto tc : test_cases) {\n-    llvm::Value* c0 = llvm::ConstantFP::get(f16_type, tc.input);\n-\n-    absl::StatusOr<llvm::Value*> f16_reduced_statusor = EmitReducePrecisionIR(\n-        /*src_ty=*/F16, c0,\n-        /*dest_exponent_bits=*/primitive_util::ExponentWidth(F8E5M2),\n-        /*dest_mantissa_bits=*/primitive_util::SignificandWidth(F8E5M2) - 1,\n-        /*quiet_nans=*/true, b);\n-    CHECK(f16_reduced_statusor.ok());\n-    llvm::Value* f16_reduced = f16_reduced_statusor.value();\n-\n-    std::string res = llvm_ir::DumpToString(f16_reduced);\n-    EXPECT_EQ(res, tc.expected_res) << \"Wrong result for input \" << tc.input;\n-  }\n-}\n-\n-TEST_F(ElementalIrEmitterExecutionTest, EmitReducePrecisionIR_F16ToF8e4m3) {\n-  llvm::LLVMContext llvm_context;\n-  llvm::IRBuilder<> builder(llvm_context);\n-  llvm::IRBuilderBase* b = &builder;\n-  llvm::Type* f16_type = b->getHalfTy();\n-\n-  float inf = std::numeric_limits<float>::infinity();\n-  float qnan = std::numeric_limits<float>::quiet_NaN();\n-  float snan = std::numeric_limits<float>::signaling_NaN();\n-\n-  EmitReducePrecisionIrTestCase test_cases[] = {\n-      // clang-format off\n-      {0.0, \"half 0xH0000\"},\n-      {0x1.0p-6, \"half 0xH2400\"},\n-      {0.125, \"half 0xH3000\"},\n-      {1.0, \"half 0xH3C00\"},\n-      {0x1.1p0, \"half 0xH3C00\"},\n-      {0x1.Ep7, \"half 0xH5B80\"},\n-      {-0x1.Ep7, \"half 0xHDB80\"},\n-      {0x1.E8p7, \"half 0xH5B80\"},\n-      {0x1.Fp7, \"half 0xH7C00\"},\n-      {0x1.0p8, \"half 0xH7C00\"},\n-      {inf, \"half 0xH7C00\"},\n-      {-inf, \"half 0xHFC00\"},\n-      {qnan, \"half 0xH7E00\"},\n-      {-qnan, \"half 0xHFE00\"},\n-      {snan, \"half 0xH7E00\"},\n-      {-snan, \"half 0xHFE00\"},\n-      // clang-format on\n-  };\n-\n-  for (auto tc : test_cases) {\n-    llvm::Value* c0 = llvm::ConstantFP::get(f16_type, tc.input);\n-\n-    absl::StatusOr<llvm::Value*> f16_reduced_statusor = EmitReducePrecisionIR(\n-        /*src_ty=*/F16, c0,\n-        /*dest_exponent_bits=*/4,\n-        /*dest_mantissa_bits=*/3,\n-        /*quiet_nans=*/true, b);\n-    CHECK(f16_reduced_statusor.ok());\n-    llvm::Value* f16_reduced = f16_reduced_statusor.value();\n-\n-    std::string res = llvm_ir::DumpToString(f16_reduced);\n-    EXPECT_EQ(res, tc.expected_res) << \"Wrong result for input \" << tc.input;\n-  }\n-}\n-\n-TEST_F(ElementalIrEmitterExecutionTest, EmitReducePrecisionIR_F16ToF8e3m4) {\n-  llvm::LLVMContext llvm_context;\n-  llvm::IRBuilder<> builder(llvm_context);\n-  llvm::IRBuilderBase* b = &builder;\n-  llvm::Type* f16_type = b->getHalfTy();\n-\n-  float inf = std::numeric_limits<float>::infinity();\n-  float qnan = std::numeric_limits<float>::quiet_NaN();\n-  float snan = std::numeric_limits<float>::signaling_NaN();\n-\n-  EmitReducePrecisionIrTestCase test_cases[] = {\n-      // clang-format off\n-      {0.0, \"half 0xH0000\"},\n-      {0x1.0p-2, \"half 0xH3400\"},\n-      {0.5, \"half 0xH3800\"},\n-      {1.0, \"half 0xH3C00\"},\n-      {0x1.08p0, \"half 0xH3C00\"},\n-      {0x1.Fp3, \"half 0xH4BC0\"},\n-      {-0x1.Fp3, \"half 0xHCBC0\"},\n-      {0x1.F4p3, \"half 0xH4BC0\"},\n-      {0x1.F8p3, \"half 0xH7C00\"},\n-      {0x1.0p4, \"half 0xH7C00\"},\n-      {inf, \"half 0xH7C00\"},\n-      {-inf, \"half 0xHFC00\"},\n-      {qnan, \"half 0xH7E00\"},\n-      {-qnan, \"half 0xHFE00\"},\n-      {snan, \"half 0xH7E00\"},\n-      {-snan, \"half 0xHFE00\"},\n-      // clang-format on\n-  };\n-\n-  for (auto tc : test_cases) {\n-    llvm::Value* c0 = llvm::ConstantFP::get(f16_type, tc.input);\n-\n-    absl::StatusOr<llvm::Value*> f16_reduced_statusor = EmitReducePrecisionIR(\n-        /*src_ty=*/F16, c0,\n-        /*dest_exponent_bits=*/3,\n-        /*dest_mantissa_bits=*/4,\n-        /*quiet_nans=*/true, b);\n-    CHECK(f16_reduced_statusor.ok());\n-    llvm::Value* f16_reduced = f16_reduced_statusor.value();\n-\n-    std::string res = llvm_ir::DumpToString(f16_reduced);\n-    EXPECT_EQ(res, tc.expected_res) << \"Wrong result for input \" << tc.input;\n-  }\n-}\n-\n-TEST_F(ElementalIrEmitterExecutionTest, EmitReducePrecisionIR_F16ToF8e4m3fn) {\n-  llvm::LLVMContext llvm_context;\n-  llvm::IRBuilder<> builder(llvm_context);\n-  llvm::IRBuilderBase* b = &builder;\n-  llvm::Type* f16_type = b->getHalfTy();\n-\n-  float inf = std::numeric_limits<float>::infinity();\n-\n-  EmitReducePrecisionIrTestCase test_cases[] = {\n-      // clang-format off\n-      {0.0, \"half 0xH0000\"},\n-      {0x1.0p-6, \"half 0xH2400\"},\n-      {0.125, \"half 0xH3000\"},\n-      {1.0, \"half 0xH3C00\"},\n-      {0x1.1p0, \"half 0xH3C00\"},\n-      {0x1.Cp8, \"half 0xH5F00\"},\n-      {-0x1.Cp8, \"half 0xHDF00\"},\n-      {0x1.Dp8, \"half 0xH5F00\"},\n-      {0x1.Ep8, \"half 0xH5F80\"},\n-      {0x1.0p9, \"half 0xH6000\"},\n-      {inf, \"half 0xH7C00\"},\n-      {-inf, \"half 0xHFC00\"},\n-      // clang-format on\n-  };\n-\n-  for (auto tc : test_cases) {\n-    llvm::Value* c0 = llvm::ConstantFP::get(f16_type, tc.input);\n-\n-    // Truncate the mantissa to 3 bits. ReducePrecision cannot deal with\n-    // f8E4M3FN's NaN representations, so don't use ReducePrecision to handle\n-    // exponent reduction.\n-    absl::StatusOr<llvm::Value*> f16_reduced_statusor = EmitReducePrecisionIR(\n-        /*src_ty=*/F16, c0,\n-        /*dest_exponent_bits=*/5,\n-        /*dest_mantissa_bits=*/3,\n-        /*quiet_nans=*/false, b);\n-    CHECK(f16_reduced_statusor.ok());\n-    llvm::Value* f16_reduced = f16_reduced_statusor.value();\n-\n-    std::string res = llvm_ir::DumpToString(f16_reduced);\n-    EXPECT_EQ(res, tc.expected_res) << \"Wrong result for input \" << tc.input;\n-  }\n-}\n-\n TEST_F(ElementalIrEmitterExecutionTest, ScalarDotFusion) {\n   const char* hlo_text = R\"(\n HloModule ScalarDotFusion"
        },
        {
            "sha": "ec4be9c220972f5eaf7e1070f7da07072ff053d7",
            "filename": "third_party/xla/xla/service/gpu/llvm_gpu_backend/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2FBUILD?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -32,7 +32,10 @@ cc_library(\n         \":utils\",\n         \"//xla:util\",\n         \"//xla:xla_proto_cc\",\n+        \"//xla/codegen:intrinsic_lib\",\n+        \"//xla/codegen/intrinsic:intrinsic_compiler_lib\",\n         \"//xla/service/llvm_ir:llvm_type_conversion_util\",\n+        \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\","
        },
        {
            "sha": "59614b8e559f1dec9423392b959b911167c87fa5",
            "filename": "third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fgpu_backend_lib.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fgpu_backend_lib.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fgpu_backend_lib.cc?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"llvm/Analysis/CGSCCPassManager.h\"\n #include \"llvm/Analysis/LazyCallGraph.h\"\n #include \"llvm/Analysis/LoopAnalysisManager.h\"\n+#include \"llvm/Analysis/TargetLibraryInfo.h\"\n #include \"llvm/Analysis/TargetTransformInfo.h\"\n #include \"llvm/Bitcode/BitcodeReader.h\"\n #include \"llvm/Bitcode/BitcodeWriter.h\"\n@@ -57,9 +58,12 @@ limitations under the License.\n #include \"llvm/Transforms/IPO/AlwaysInliner.h\"\n #include \"llvm/Transforms/IPO/Internalize.h\"\n #include \"llvm/Transforms/Scalar.h\"\n+#include \"xla/codegen/intrinsic/intrinsic_compiler_lib.h\"\n+#include \"xla/codegen/intrinsic_lib.h\"\n #include \"xla/service/gpu/llvm_gpu_backend/load_ir_module.h\"\n #include \"xla/service/gpu/llvm_gpu_backend/utils.h\"\n #include \"xla/service/llvm_ir/llvm_type_conversion_util.h\"\n+#include \"xla/service/llvm_ir/llvm_util.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -258,8 +262,22 @@ absl::Status LinkAndOptimizeModule(\n   llvm::CGSCCAnalysisManager cgam;\n   llvm::ModuleAnalysisManager mam;\n \n+  codegen::IntrinsicFunctionLib intrinsic_lib(\n+      {target_machine ? target_machine->getTargetFeatureString().str() : \"\",\n+       /*disable_platform_dependent_math=*/true});\n+\n   if (target_machine) {\n     fam.registerPass([&] { return target_machine->getTargetIRAnalysis(); });\n+    {\n+      auto target_library_info_impl =\n+          std::make_unique<llvm::TargetLibraryInfoImpl>(\n+              target_machine->getTargetTriple());\n+      target_library_info_impl->addVectorizableFunctions(\n+          intrinsic_lib.Vectorizations());\n+      fam.registerPass([&] {\n+        return llvm::TargetLibraryAnalysis(*target_library_info_impl);\n+      });\n+    }\n   }\n \n   llvm::PipelineTuningOptions pto;\n@@ -320,6 +338,13 @@ absl::Status LinkAndOptimizeModule(\n \n   mpm.run(*module, mam);\n \n+  auto replaced_functions = intrinsic_lib.DefineIntrinsicFunctions(*module);\n+  if (!replaced_functions.empty()) {\n+    codegen::intrinsic::RemoveFromCompilerUsed(\n+        *module, [&](auto n) { return intrinsic_lib.IsIntrinsicFunction(n); });\n+    codegen::intrinsic::RunInlineAndOptPasses(*module);\n+  }\n+\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "470f379614ecaad5df42451d26b6cd75432818ab",
            "filename": "third_party/xla/xla/service/llvm_ir/BUILD",
            "status": "modified",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2FBUILD?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -331,3 +331,24 @@ xla_cc_test(\n         \"@llvm-project//llvm:ir_headers\",\n     ],\n )\n+\n+xla_cc_test(\n+    name = \"llvm_util_test\",\n+    srcs = [\"llvm_util_test.cc\"],\n+    deps = [\n+        \":llvm_util\",\n+        \"//xla:error_spec\",\n+        \"//xla:literal\",\n+        \"//xla:shape_util\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:hlo_module_config\",\n+        \"//xla/tests:hlo_test_base\",\n+        \"//xla/tests:xla_internal_test_main\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@com_google_googletest//:gtest\",\n+        \"@llvm-project//llvm:ir_headers\",\n+    ],\n+)"
        },
        {
            "sha": "95caa0439fcfe04672168e7f53a559924b9ecd0b",
            "filename": "third_party/xla/xla/service/llvm_ir/llvm_util.cc",
            "status": "modified",
            "additions": 149,
            "deletions": 0,
            "changes": 149,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.cc?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -56,6 +56,7 @@ limitations under the License.\n #include \"llvm/Support/Alignment.h\"\n #include \"llvm/Support/Casting.h\"\n #include \"llvm/Support/CodeGen.h\"\n+#include \"llvm/Support/TypeSize.h\"\n #include \"llvm/Support/raw_ostream.h\"\n #include \"llvm/TargetParser/Triple.h\"\n #include \"llvm/Transforms/Utils/Cloning.h\"\n@@ -898,5 +899,153 @@ void EmitEarlyReturn(llvm::Value* condition, llvm::IRBuilderBase* b,\n   b->SetInsertPoint(continued, continued->getFirstInsertionPt());\n }\n \n+absl::StatusOr<llvm::Value*> EmitReducePrecisionIR(\n+    PrimitiveType src_ty, llvm::Value* x, int64_t dest_exponent_bits,\n+    int64_t dest_mantissa_bits, bool quiet_nans, llvm::IRBuilderBase* b) {\n+  using llvm::APInt;\n+\n+  if (!primitive_util::IsFloatingPointType(src_ty)) {\n+    return Unimplemented(\n+        \"ReducePrecision cannot accept non-floating-point type %s.\",\n+        PrimitiveType_Name(src_ty));\n+  }\n+\n+  // Integer and float types for casting and constant generation.\n+  llvm::Type* const value_type = x->getType();\n+  llvm::Type* const float_scalar_type = value_type->getScalarType();\n+  const int nbits = float_scalar_type->getPrimitiveSizeInBits();\n+  llvm::Type* int_work_type = b->getIntNTy(nbits);\n+  unsigned width = 1;\n+  if (auto* vec_ty = llvm::dyn_cast<llvm::FixedVectorType>(value_type)) {\n+    width = vec_ty->getNumElements();\n+    int_work_type = llvm::VectorType::get(int_work_type,\n+                                          llvm::ElementCount::getFixed(width));\n+  }\n+\n+  // Helper to create a splatted vector constant. If the input is scalar, this\n+  // will just produce a scalar ConstantInt.\n+  auto int_const = [&](const APInt& val) -> llvm::Constant* {\n+    return llvm::ConstantInt::get(int_work_type, val);\n+  };\n+\n+  // SignificandWidth includes the implicit extra bit.\n+  int src_mantissa_bits = primitive_util::SignificandWidth(src_ty) - 1;\n+  int src_exponent_bits = nbits - 1 - src_mantissa_bits;\n+\n+  // Cast the input value to an integer for bitwise manipulation.\n+  llvm::Value* x_as_int = b->CreateBitCast(x, int_work_type);\n+\n+  // Clear the sign bit, it does not participate in rounding and we will restore\n+  // it later.\n+  APInt sign_bit_mask(nbits, 1);\n+  sign_bit_mask <<= nbits - 1;\n+  llvm::Value* x_abs_bits = b->CreateAnd(x_as_int, int_const(~sign_bit_mask));\n+\n+  APInt exp_bits_mask(nbits, 1);\n+  exp_bits_mask = ((exp_bits_mask << src_exponent_bits) - 1)\n+                  << src_mantissa_bits;\n+  auto x_is_nan = b->CreateICmpUGT(x_abs_bits, int_const(exp_bits_mask));\n+\n+  if (dest_mantissa_bits < src_mantissa_bits) {\n+    // Last remaining mantissa bit.\n+    APInt last_mantissa_bit_mask(nbits, 1);\n+    last_mantissa_bit_mask <<= src_mantissa_bits - dest_mantissa_bits;\n+\n+    // Compute rounding bias for round-to-nearest with ties to even.  This is\n+    // equal to a base value of 0111... plus one bit if the last remaining\n+    // mantissa bit is 1.\n+    APInt base_rounding_bias = last_mantissa_bit_mask.lshr(1) - 1;\n+    llvm::Value* x_last_mantissa_bit =\n+        b->CreateLShr(b->CreateAnd(x_as_int, int_const(last_mantissa_bit_mask)),\n+                      (src_mantissa_bits - dest_mantissa_bits));\n+    llvm::Value* x_rounding_bias =\n+        b->CreateAdd(x_last_mantissa_bit, int_const(base_rounding_bias));\n+\n+    // Add rounding bias, and mask out truncated bits.  Note that the case\n+    // where adding the rounding bias overflows into the exponent bits is\n+    // correct; the non-masked mantissa bits will all be zero, and the\n+    // exponent will be incremented by one.\n+    APInt truncation_mask = ~(last_mantissa_bit_mask - 1);\n+    llvm::Value* x_rounded = b->CreateAdd(x_as_int, x_rounding_bias);\n+    x_rounded = b->CreateAnd(x_rounded, int_const(truncation_mask));\n+    if (quiet_nans) {\n+      x_as_int = b->CreateSelect(x_is_nan, x_as_int, x_rounded);\n+    } else {\n+      x_as_int = x_rounded;\n+    }\n+  }\n+\n+  if (dest_exponent_bits < src_exponent_bits) {\n+    // An exponent of 2^(n-1)-1 -- that is, 0111... with the zero in the most-\n+    // significant bit -- is equal to 1.0f for all exponent sizes.  Adding\n+    // 2^(n-1)-1 to this gives us the highest non-infinite exponent for a bit-\n+    // size of n, and subtracting 2^(n-1)-1 from this gives us the lowest'\n+    // exponent (corresponding to 0.0f).\n+    //\n+    // Thus, the f32 exponent corresponding to the highest non-infinite\n+    // exponent for a bit size of n is (2^7-1) + 2^(n-1)-1, and the f32\n+    // exponent corresponding to the lowest exponent for a bit size of n is\n+    // (2^7-1) - 2^(n-1)-1.\n+    //\n+    // Note that we have already checked that exponents_bits >= 1.\n+    APInt exponent_bias(nbits, 1);\n+    exponent_bias = (exponent_bias << (src_exponent_bits - 1)) - 1;\n+\n+    APInt reduced_exponent_bias(nbits, 1);\n+    reduced_exponent_bias =\n+        (reduced_exponent_bias << (dest_exponent_bits - 1)) - 1;\n+\n+    APInt reduced_max_exponent = exponent_bias + reduced_exponent_bias;\n+    APInt reduced_min_exponent = exponent_bias - reduced_exponent_bias;\n+\n+    // Do we overflow or underflow?\n+    llvm::Value* x_exponent = b->CreateAnd(x_as_int, int_const(exp_bits_mask));\n+    llvm::Value* x_overflows = b->CreateICmpUGT(\n+        x_exponent, int_const(reduced_max_exponent << src_mantissa_bits));\n+    llvm::Value* x_underflows = b->CreateICmpULE(\n+        x_exponent, int_const(reduced_min_exponent << src_mantissa_bits));\n+\n+    // Compute appropriately-signed values of zero and infinity.\n+    llvm::Value* x_signed_zero =\n+        b->CreateAnd(x_as_int, int_const(sign_bit_mask));\n+    llvm::Value* x_signed_inf =\n+        b->CreateOr(x_signed_zero, int_const(exp_bits_mask));\n+\n+    // Force to zero or infinity if overflow or underflow.  (Note that this\n+    // truncates all denormal values to zero, rather than rounding them.)\n+    x_as_int = b->CreateSelect(x_overflows, x_signed_inf, x_as_int);\n+    x_as_int = b->CreateSelect(x_underflows, x_signed_zero, x_as_int);\n+  }\n+\n+  // Cast the result back to a floating-point type.\n+  llvm::Value* result = b->CreateBitCast(x_as_int, value_type);\n+\n+  // Correct result for NaN inputs.\n+  //\n+  // The exponent handling will \"normalize\" NaN values to infinities, which is\n+  // undesirable (except in the case with no mantissa bits, in which case it\n+  // is mandatory).  This logic also handles cases where mantissa-rounding\n+  // causes a NaN's mantissa to overflow into the exponent bits, which would\n+  // otherwise create an erroneous zero value.\n+\n+  if (dest_mantissa_bits > 0) {\n+    if (quiet_nans) {\n+      APInt qnan_mask(nbits, 1);\n+      qnan_mask <<= src_mantissa_bits - 1;\n+      llvm::Value* x_with_qnan_bit_set =\n+          b->CreateOr(x_as_int, int_const(qnan_mask));\n+      x_with_qnan_bit_set = b->CreateBitCast(x_with_qnan_bit_set, value_type);\n+      result = b->CreateSelect(x_is_nan, x_with_qnan_bit_set, result);\n+    } else {\n+      result = b->CreateSelect(x_is_nan, x, result);\n+    }\n+  } else {\n+    result = b->CreateSelect(x_is_nan,\n+                             llvm::ConstantFP::getInfinity(value_type), result);\n+  }\n+\n+  return result;\n+}\n+\n }  // namespace llvm_ir\n }  // namespace xla"
        },
        {
            "sha": "3fa3a70e58b6cc51badce7ae90c21ce370bcfea0",
            "filename": "third_party/xla/xla/service/llvm_ir/llvm_util.h",
            "status": "modified",
            "additions": 126,
            "deletions": 0,
            "changes": 126,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.h?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #ifndef XLA_SERVICE_LLVM_IR_LLVM_UTIL_H_\n #define XLA_SERVICE_LLVM_IR_LLVM_UTIL_H_\n \n+#include <cstddef>\n #include <cstdint>\n #include <map>\n #include <optional>\n@@ -25,7 +26,10 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n+#include \"llvm/ADT/APFloat.h\"\n+#include \"llvm/ADT/FloatingPointMode.h\"\n #include \"llvm/IR/BasicBlock.h\"\n+#include \"llvm/IR/DerivedTypes.h\"\n #include \"llvm/IR/FPEnv.h\"\n #include \"llvm/IR/GlobalVariable.h\"\n #include \"llvm/IR/IRBuilder.h\"\n@@ -34,6 +38,7 @@ limitations under the License.\n #include \"llvm/IR/LLVMContext.h\"\n #include \"llvm/IR/Module.h\"\n #include \"llvm/IR/Value.h\"\n+#include \"llvm/Support/TypeSize.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/Location.h\"\n #include \"mlir/IR/Operation.h\"\n@@ -340,6 +345,127 @@ llvm::BasicBlock* EmitReturnBlock(llvm::IRBuilderBase* b);\n void EmitEarlyReturn(llvm::Value* condition, llvm::IRBuilderBase* b,\n                      llvm::BasicBlock* return_block = nullptr);\n \n+absl::StatusOr<llvm::Value*> EmitReducePrecisionIR(\n+    PrimitiveType src_ty, llvm::Value* x, int64_t dest_exponent_bits,\n+    int64_t dest_mantissa_bits, bool quiet_nans, llvm::IRBuilderBase* b);\n+\n+template <PrimitiveType fx_type, int f8_exponent_bits>\n+llvm::Value* HandleHalfwayPointsFxToF8(llvm::Value* fx_abs_bits,\n+                                       llvm::Value* f8_bits,\n+                                       std::optional<size_t> vector_width,\n+                                       llvm::IRBuilderBase* b) {\n+  using llvm::APFloat;\n+  using llvm::APInt;\n+  using llvm::Value;\n+  static_assert(fx_type == F16 || fx_type == F32 || fx_type == F64);\n+  static_assert(3 <= f8_exponent_bits && f8_exponent_bits <= 4);\n+\n+  const llvm::fltSemantics* fx_semantics;\n+  llvm::Type* ix_type;\n+\n+  if constexpr (fx_type == F16) {\n+    fx_semantics = &llvm::APFloat::IEEEhalf();\n+    ix_type = b->getInt16Ty();\n+  } else if constexpr (fx_type == F32) {\n+    fx_semantics = &llvm::APFloat::IEEEsingle();\n+    ix_type = b->getInt32Ty();\n+  } else if constexpr (fx_type == F64) {\n+    fx_semantics = &llvm::APFloat::IEEEdouble();\n+    ix_type = b->getInt64Ty();\n+  }\n+\n+  llvm::Type* i8_type = b->getInt8Ty();\n+\n+  if (vector_width.has_value()) {\n+    ix_type = llvm::VectorType::get(\n+        ix_type, llvm::ElementCount::getFixed(*vector_width));\n+    i8_type = llvm::VectorType::get(\n+        i8_type, llvm::ElementCount::getFixed(*vector_width));\n+  }\n+\n+  auto ix_const = [fx_semantics, ix_type](APFloat val) {\n+    bool losesInfo;\n+    val.convert(*fx_semantics, llvm::RoundingMode::NearestTiesToEven,\n+                &losesInfo);\n+    return llvm::ConstantInt::get(ix_type, val.bitcastToAPInt());\n+  };\n+\n+  auto i8_const = [i8_type](int val) {\n+    return llvm::ConstantInt::get(i8_type, val);\n+  };\n+\n+  // F16 values that are halfway between denormal F8 values. This is used to\n+  // determine how to round to denormal F8 values.\n+  const APFloat halfway_points_e4[8] = {\n+      APFloat(0x1.0p-10),  // halfway between [0/8 * 2^-6, 1/8 * 2^-6]\n+      APFloat(0x1.8p-9),   // halfway between [1/8 * 2^-6, 2/8 * 2^-6]\n+      APFloat(0x1.4p-8),   // halfway between [2/8 * 2^-6, 3/8 * 2^-6]\n+      APFloat(0x1.Cp-8),   // halfway between [3/8 * 2^-6, 4/8 * 2^-6]\n+      APFloat(0x1.2p-7),   // halfway between [4/8 * 2^-6, 5/8 * 2^-6]\n+      APFloat(0x1.6p-7),   // halfway between [5/8 * 2^-6, 6/8 * 2^-6]\n+      APFloat(0x1.Ap-7),   // halfway between [6/8 * 2^-6, 7/8 * 2^-6]\n+      APFloat(0x1.Ep-7)    // halfway between [7/8 * 2^-6, 8/8 * 2^-6]\n+  };\n+\n+  const APFloat halfway_points_e3[16] = {\n+      APFloat(0x1.0p-7),  // halfway between [0/16 * 2^-2, 1/16 * 2^-2]\n+      APFloat(0x1.8p-6),  // halfway between [1/16 * 2^-2, 2/16 * 2^-2]\n+      APFloat(0x1.4p-5),  // halfway between [2/16 * 2^-2, 3/16 * 2^-2]\n+      APFloat(0x1.Cp-5),  // halfway between [3/16 * 2^-2, 4/16 * 2^-2]\n+      APFloat(0x1.2p-4),  // halfway between [4/16 * 2^-2, 5/16 * 2^-2]\n+      APFloat(0x1.6p-4),  // halfway between [5/16 * 2^-2, 6/16 * 2^-2]\n+      APFloat(0x1.Ap-4),  // halfway between [6/16 * 2^-2, 7/16 * 2^-2]\n+      APFloat(0x1.Ep-4),  // halfway between [7/16 * 2^-2, 8/16 * 2^-2]\n+      APFloat(0x1.1p-3),  // halfway between [8/16 * 2^-2, 9/16 * 2^-2]\n+      APFloat(0x1.3p-3),  // halfway between [9/16 * 2^-2, 10/16 * 2^-2]\n+      APFloat(0x1.5p-3),  // halfway between [10/16 * 2^-2, 11/16 * 2^-2]\n+      APFloat(0x1.7p-3),  // halfway between [11/16 * 2^-2, 12/16 * 2^-2]\n+      APFloat(0x1.9p-3),  // halfway between [12/16 * 2^-2, 13/16 * 2^-2]\n+      APFloat(0x1.Bp-3),  // halfway between [13/16 * 2^-2, 14/16 * 2^-2]\n+      APFloat(0x1.Dp-3),  // halfway between [14/16 * 2^-2, 15/16 * 2^-2]\n+      APFloat(0x1.Fp-3),  // halfway between [15/16 * 2^-2, 16/16 * 2^-2]\n+  };\n+\n+  const APFloat* halfway_points;\n+  int arr_sz;\n+  if constexpr (f8_exponent_bits == 4) {\n+    halfway_points = halfway_points_e4;\n+    arr_sz = 8;\n+  } else if constexpr (f8_exponent_bits == 3) {\n+    halfway_points = halfway_points_e3;\n+    arr_sz = 16;\n+  }\n+\n+  // Handle case where output is denormal. If we're rounding to a denormal\n+  // value, ignore the current value of f8_bits and set it to the correct\n+  // denormal value. We emit the equivalent of the following:\n+  //\n+  //   if (f16_abs_bits <= halfway_points[0]) {\n+  //     f8_bits = 0;\n+  //   } else if (f16_abs_bits < halfway_points[1]) {\n+  //     f8_bits = 1;\n+  //   } else if (f16_abs_bits <= halfway_points[2]) {\n+  //   ...  // More if-else statements. The comparisons alternate between <=\n+  //   ...  // and < to handle round-to-even properly.\n+  //   } else if (f16_abs_bits < halfway_points[7])  {\n+  //     f8_bits = 7;\n+  //   }\n+  for (int i = arr_sz - 1; i >= 0; i--) {\n+    Value* comparison;\n+    llvm::Constant* half_way_point = ix_const(halfway_points[i]);\n+\n+    if (i % 2 == 0) {\n+      comparison = b->CreateICmpULE(fx_abs_bits, half_way_point);\n+    } else {\n+      comparison = b->CreateICmpULT(fx_abs_bits, half_way_point);\n+    }\n+\n+    f8_bits = b->CreateSelect(comparison, i8_const(i), f8_bits);\n+  }\n+\n+  return f8_bits;\n+}\n+\n }  // namespace llvm_ir\n }  // namespace xla\n "
        },
        {
            "sha": "5e57393dc95cf2a6c56262ad76f531be5d768cb5",
            "filename": "third_party/xla/xla/service/llvm_ir/llvm_util_test.cc",
            "status": "added",
            "additions": 260,
            "deletions": 0,
            "changes": 260,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7aa83cefdc55176800295841bc5104b0b8a47486/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util_test.cc?ref=7aa83cefdc55176800295841bc5104b0b8a47486",
            "patch": "@@ -0,0 +1,260 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/llvm_ir/llvm_util.h\"\n+\n+#include <limits>\n+#include <memory>\n+#include <optional>\n+#include <string>\n+#include <utility>\n+\n+#include <gtest/gtest.h>\n+#include \"absl/log/check.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n+#include \"llvm/IR/Constants.h\"\n+#include \"llvm/IR/IRBuilder.h\"\n+#include \"llvm/IR/LLVMContext.h\"\n+#include \"llvm/IR/Module.h\"\n+#include \"llvm/IR/Type.h\"\n+#include \"llvm/IR/Value.h\"\n+#include \"xla/error_spec.h\"\n+#include \"xla/hlo/ir/hlo_clone_context.h\"\n+#include \"xla/literal.h\"\n+#include \"xla/primitive_util.h\"\n+#include \"xla/service/hlo_module_config.h\"\n+#include \"xla/tests/hlo_test_base.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla::llvm_ir {\n+namespace {\n+\n+using std::nullopt;\n+struct EmitReducePrecisionIrTestCase {\n+  float input;\n+  std::string expected_res;\n+};\n+\n+class EmitReducePrecisionIrExecutionTest : public HloTestBase {\n+ protected:\n+  void RunTest(const std::string& hlo_text, absl::Span<Literal* const> args) {\n+    HloModuleConfig config;\n+    config.set_debug_options(GetDebugOptionsForTest());\n+    TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                            ParseAndReturnVerifiedModule(hlo_text, config));\n+    EXPECT_TRUE(RunAndCompareNoHloPasses(std::move(module), args, nullopt));\n+  }\n+\n+  void RunTypeConversionTest(absl::string_view hlo_text) {\n+    HloModuleConfig config;\n+    auto debug_options = GetDebugOptionsForTest();\n+    debug_options.set_xla_cpu_fast_math_honor_nans(true);\n+    debug_options.set_xla_cpu_fast_math_honor_infs(true);\n+    config.set_debug_options(debug_options);\n+    TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                            ParseAndReturnVerifiedModule(hlo_text, config));\n+    EXPECT_TRUE(RunAndCompare(std::move(module), ErrorSpec{(0.)}));\n+  }\n+};\n+\n+TEST_F(EmitReducePrecisionIrExecutionTest, EmitReducePrecisionIR_F16ToF8e5m2) {\n+  llvm::LLVMContext llvm_context;\n+  llvm::IRBuilder<> builder(llvm_context);\n+  llvm::IRBuilderBase* b = &builder;\n+  llvm::Type* f16_type = b->getHalfTy();\n+\n+  float inf = std::numeric_limits<float>::infinity();\n+  float qnan = std::numeric_limits<float>::quiet_NaN();\n+  float snan = std::numeric_limits<float>::signaling_NaN();\n+\n+  EmitReducePrecisionIrTestCase test_cases[] = {\n+      // clang-format off\n+      {0.0, \"half 0xH0000\"},\n+      {0x1.0p-14, \"half 0xH0400\"},\n+      {0.250, \"half 0xH3400\"},\n+      {1.0, \"half 0xH3C00\"},\n+      {0x1.2p0, \"half 0xH3C00\"},\n+      {0x1.Cp15, \"half 0xH7B00\"},\n+      {-0x1.Cp15, \"half 0xHFB00\"},\n+      {0x1.Dp15, \"half 0xH7B00\"},\n+      {0x1.Ep15, \"half 0xH7C00\"},\n+      {0x1.0p16, \"half 0xH7C00\"},\n+      {inf, \"half 0xH7C00\"},\n+      {-inf, \"half 0xHFC00\"},\n+      {qnan, \"half 0xH7E00\"},\n+      {-qnan, \"half 0xHFE00\"},\n+      {snan, \"half 0xH7F00\"},\n+      {-snan, \"half 0xHFF00\"},\n+      // clang-format on\n+  };\n+\n+  for (auto tc : test_cases) {\n+    llvm::Value* c0 = llvm::ConstantFP::get(f16_type, tc.input);\n+\n+    absl::StatusOr<llvm::Value*> f16_reduced_statusor = EmitReducePrecisionIR(\n+        /*src_ty=*/F16, c0,\n+        /*dest_exponent_bits=*/primitive_util::ExponentWidth(F8E5M2),\n+        /*dest_mantissa_bits=*/primitive_util::SignificandWidth(F8E5M2) - 1,\n+        /*quiet_nans=*/true, b);\n+    CHECK(f16_reduced_statusor.ok());\n+    llvm::Value* f16_reduced = f16_reduced_statusor.value();\n+\n+    std::string res = llvm_ir::DumpToString(f16_reduced);\n+    EXPECT_EQ(res, tc.expected_res) << \"Wrong result for input \" << tc.input;\n+  }\n+}\n+\n+TEST_F(EmitReducePrecisionIrExecutionTest, EmitReducePrecisionIR_F16ToF8e4m3) {\n+  llvm::LLVMContext llvm_context;\n+  llvm::IRBuilder<> builder(llvm_context);\n+  llvm::IRBuilderBase* b = &builder;\n+  llvm::Type* f16_type = b->getHalfTy();\n+\n+  float inf = std::numeric_limits<float>::infinity();\n+  float qnan = std::numeric_limits<float>::quiet_NaN();\n+  float snan = std::numeric_limits<float>::signaling_NaN();\n+\n+  EmitReducePrecisionIrTestCase test_cases[] = {\n+      // clang-format off\n+      {0.0, \"half 0xH0000\"},\n+      {0x1.0p-6, \"half 0xH2400\"},\n+      {0.125, \"half 0xH3000\"},\n+      {1.0, \"half 0xH3C00\"},\n+      {0x1.1p0, \"half 0xH3C00\"},\n+      {0x1.Ep7, \"half 0xH5B80\"},\n+      {-0x1.Ep7, \"half 0xHDB80\"},\n+      {0x1.E8p7, \"half 0xH5B80\"},\n+      {0x1.Fp7, \"half 0xH7C00\"},\n+      {0x1.0p8, \"half 0xH7C00\"},\n+      {inf, \"half 0xH7C00\"},\n+      {-inf, \"half 0xHFC00\"},\n+      {qnan, \"half 0xH7E00\"},\n+      {-qnan, \"half 0xHFE00\"},\n+      {snan, \"half 0xH7E00\"},\n+      {-snan, \"half 0xHFE00\"},\n+      // clang-format on\n+  };\n+\n+  for (auto tc : test_cases) {\n+    llvm::Value* c0 = llvm::ConstantFP::get(f16_type, tc.input);\n+\n+    absl::StatusOr<llvm::Value*> f16_reduced_statusor = EmitReducePrecisionIR(\n+        /*src_ty=*/F16, c0,\n+        /*dest_exponent_bits=*/4,\n+        /*dest_mantissa_bits=*/3,\n+        /*quiet_nans=*/true, b);\n+    CHECK(f16_reduced_statusor.ok());\n+    llvm::Value* f16_reduced = f16_reduced_statusor.value();\n+\n+    std::string res = llvm_ir::DumpToString(f16_reduced);\n+    EXPECT_EQ(res, tc.expected_res) << \"Wrong result for input \" << tc.input;\n+  }\n+}\n+\n+TEST_F(EmitReducePrecisionIrExecutionTest, EmitReducePrecisionIR_F16ToF8e3m4) {\n+  llvm::LLVMContext llvm_context;\n+  llvm::IRBuilder<> builder(llvm_context);\n+  llvm::IRBuilderBase* b = &builder;\n+  llvm::Type* f16_type = b->getHalfTy();\n+\n+  float inf = std::numeric_limits<float>::infinity();\n+  float qnan = std::numeric_limits<float>::quiet_NaN();\n+  float snan = std::numeric_limits<float>::signaling_NaN();\n+\n+  EmitReducePrecisionIrTestCase test_cases[] = {\n+      // clang-format off\n+      {0.0, \"half 0xH0000\"},\n+      {0x1.0p-2, \"half 0xH3400\"},\n+      {0.5, \"half 0xH3800\"},\n+      {1.0, \"half 0xH3C00\"},\n+      {0x1.08p0, \"half 0xH3C00\"},\n+      {0x1.Fp3, \"half 0xH4BC0\"},\n+      {-0x1.Fp3, \"half 0xHCBC0\"},\n+      {0x1.F4p3, \"half 0xH4BC0\"},\n+      {0x1.F8p3, \"half 0xH7C00\"},\n+      {0x1.0p4, \"half 0xH7C00\"},\n+      {inf, \"half 0xH7C00\"},\n+      {-inf, \"half 0xHFC00\"},\n+      {qnan, \"half 0xH7E00\"},\n+      {-qnan, \"half 0xHFE00\"},\n+      {snan, \"half 0xH7E00\"},\n+      {-snan, \"half 0xHFE00\"},\n+      // clang-format on\n+  };\n+\n+  for (auto tc : test_cases) {\n+    llvm::Value* c0 = llvm::ConstantFP::get(f16_type, tc.input);\n+\n+    absl::StatusOr<llvm::Value*> f16_reduced_statusor = EmitReducePrecisionIR(\n+        /*src_ty=*/F16, c0,\n+        /*dest_exponent_bits=*/3,\n+        /*dest_mantissa_bits=*/4,\n+        /*quiet_nans=*/true, b);\n+    CHECK(f16_reduced_statusor.ok());\n+    llvm::Value* f16_reduced = f16_reduced_statusor.value();\n+\n+    std::string res = llvm_ir::DumpToString(f16_reduced);\n+    EXPECT_EQ(res, tc.expected_res) << \"Wrong result for input \" << tc.input;\n+  }\n+}\n+\n+TEST_F(EmitReducePrecisionIrExecutionTest,\n+       EmitReducePrecisionIR_F16ToF8e4m3fn) {\n+  llvm::LLVMContext llvm_context;\n+  llvm::IRBuilder<> builder(llvm_context);\n+  llvm::IRBuilderBase* b = &builder;\n+  llvm::Type* f16_type = b->getHalfTy();\n+\n+  float inf = std::numeric_limits<float>::infinity();\n+\n+  EmitReducePrecisionIrTestCase test_cases[] = {\n+      // clang-format off\n+      {0.0, \"half 0xH0000\"},\n+      {0x1.0p-6, \"half 0xH2400\"},\n+      {0.125, \"half 0xH3000\"},\n+      {1.0, \"half 0xH3C00\"},\n+      {0x1.1p0, \"half 0xH3C00\"},\n+      {0x1.Cp8, \"half 0xH5F00\"},\n+      {-0x1.Cp8, \"half 0xHDF00\"},\n+      {0x1.Dp8, \"half 0xH5F00\"},\n+      {0x1.Ep8, \"half 0xH5F80\"},\n+      {0x1.0p9, \"half 0xH6000\"},\n+      {inf, \"half 0xH7C00\"},\n+      {-inf, \"half 0xHFC00\"},\n+      // clang-format on\n+  };\n+\n+  for (auto tc : test_cases) {\n+    llvm::Value* c0 = llvm::ConstantFP::get(f16_type, tc.input);\n+\n+    // Truncate the mantissa to 3 bits. ReducePrecision cannot deal with\n+    // f8E4M3FN's NaN representations, so don't use ReducePrecision to handle\n+    // exponent reduction.\n+    absl::StatusOr<llvm::Value*> f16_reduced_statusor = EmitReducePrecisionIR(\n+        /*src_ty=*/F16, c0,\n+        /*dest_exponent_bits=*/5,\n+        /*dest_mantissa_bits=*/3,\n+        /*quiet_nans=*/false, b);\n+    CHECK(f16_reduced_statusor.ok());\n+    llvm::Value* f16_reduced = f16_reduced_statusor.value();\n+\n+    std::string res = llvm_ir::DumpToString(f16_reduced);\n+    EXPECT_EQ(res, tc.expected_res) << \"Wrong result for input \" << tc.input;\n+  }\n+}\n+}  // namespace\n+\n+}  // namespace xla::llvm_ir"
        }
    ],
    "stats": {
        "total": 1765,
        "additions": 1038,
        "deletions": 727
    }
}