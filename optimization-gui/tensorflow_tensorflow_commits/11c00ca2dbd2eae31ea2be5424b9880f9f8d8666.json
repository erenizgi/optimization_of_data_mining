{
    "author": "qukhan",
    "message": "If `--use_xnnpack` is specified, never use the default delegate in `benchmark_tflite_model`.\n\n**Without this change**, when using `--use_xnnpack`, either:\n\n1. `--use_xnnpack=true`: the **default resolver** (that automatically applies an XNNPack delegate) is used and an XNNPack delegate that follows the options that are given on the command line is explicitly applied.\n\n2. `--use_xnnpack=false`: the **resolver without the default XNNPack delegate** is used and no delegate is explicitly applied, i.e. no delegate is applied.\n\n3. No `--use_xnnpack` is specified: the **default resolver** (that automatically applies an XNNPack delegate) is used.\n\nCase 1 has issues because the custom and default delegates are applied and\nthese may interfere during the initialization.\n\n- Depending on the XNNPack options some operations may be delegated or not.\n- This leads to one or the other delegate to take the ops.\n- This makes the benchmarking of initialization completely wrong since two\n  delegates are applied.\n- This messes up with the XNNPack weight cache since it can never be enabled\n  for the default delegate.\n\nTo solve this, the new behaviour is:\n\n1. `--use_xnnpack=true`: the **resolver without the default XNNPack delegate**\n   is used **and** an XNNPack delegate that follows the options that are given on the command line is explicitly applied.\n\n2. `--use_xnnpack=false`: the **resolver without the default XNNPack delegate** is used and no delegate is explicitly applied, i.e. no delegate is applied.\n\n3. No `--use_xnnpack` is specified: the **default resolver** (that automatically applies an XNNPack delegate) is used.\n\nCases 2 and 3 are not affected by this change.\n\nPiperOrigin-RevId: 825018995",
    "sha": "11c00ca2dbd2eae31ea2be5424b9880f9f8d8666",
    "files": [
        {
            "sha": "9384380ca6037e4ffd6d07fc1d88ad3953da7fd8",
            "filename": "tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/11c00ca2dbd2eae31ea2be5424b9880f9f8d8666/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fbenchmark_tflite_model.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/11c00ca2dbd2eae31ea2be5424b9880f9f8d8666/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fbenchmark_tflite_model.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fbenchmark_tflite_model.cc?ref=11c00ca2dbd2eae31ea2be5424b9880f9f8d8666",
            "patch": "@@ -1357,12 +1357,11 @@ TfLiteStatus BenchmarkTfLiteModel::LoadModel() {\n std::unique_ptr<tflite::OpResolver> BenchmarkTfLiteModel::GetOpResolver()\n     const {\n   tflite::ops::builtin::BuiltinOpResolver* resolver = nullptr;\n-  // When --use_xnnpack is explicitly set to false, skip applying the default\n-  // XNNPACK delegate in TfLite runtime so that the original execution path\n-  // based on the unmodified model graph is still exercised.\n+  // When --use_xnnpack is explicitly set, skip applying the default XNNPACK\n+  // delegate in TfLite runtime so that the execution path either doesn't use\n+  // the XNNPack delegate or only uses the one applied explicitly.\n   if (params_.HasParam(\"use_xnnpack\") &&\n-      params_.HasValueSet<bool>(\"use_xnnpack\") &&\n-      !params_.Get<bool>(\"use_xnnpack\")) {\n+      params_.HasValueSet<bool>(\"use_xnnpack\")) {\n     resolver =\n         new tflite::ops::builtin::BuiltinOpResolverWithoutDefaultDelegates();\n   } else {"
        }
    ],
    "stats": {
        "total": 9,
        "additions": 4,
        "deletions": 5
    }
}