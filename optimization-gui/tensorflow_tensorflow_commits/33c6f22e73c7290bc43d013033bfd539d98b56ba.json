{
    "author": "hhb",
    "message": "Fix use-after-free in PjRtCApiClient\n\n`BufferMemoryLayoutData` and `device_layout_list` should be alive until the return of the api call.\n\nPiperOrigin-RevId: 842271572",
    "sha": "33c6f22e73c7290bc43d013033bfd539d98b56ba",
    "files": [
        {
            "sha": "a173d3c87e0674aa3c0c9d2e26a814442509cae9",
            "filename": "third_party/xla/xla/pjrt/c_api_client/pjrt_c_api_client.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 12,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/33c6f22e73c7290bc43d013033bfd539d98b56ba/third_party%2Fxla%2Fxla%2Fpjrt%2Fc_api_client%2Fpjrt_c_api_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/33c6f22e73c7290bc43d013033bfd539d98b56ba/third_party%2Fxla%2Fxla%2Fpjrt%2Fc_api_client%2Fpjrt_c_api_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc_api_client%2Fpjrt_c_api_client.cc?ref=33c6f22e73c7290bc43d013033bfd539d98b56ba",
            "patch": "@@ -1381,30 +1381,33 @@ PjRtCApiClient::CreateBuffersForAsyncHostToDevice(\n       PJRT_Client_CreateBuffersForAsyncHostToDevice_Args_STRUCT_SIZE;\n   args.extension_start = nullptr;\n   args.client = c_client_.get();\n+\n   args.num_shape_specs = shape_specs.size();\n-  args.shape_specs = new PJRT_ShapeSpec[shape_specs.size()];\n-  absl::Cleanup cleanup =\n-      absl::MakeCleanup([&args] { delete[] args.shape_specs; });\n-  const ShapeSpec* iterator = shape_specs.begin();\n-  for (int i = 0; i < shape_specs.size(); ++i) {\n-    args.shape_specs[i] = pjrt::ConvertToPjRtShapeSpec(*(iterator++));\n+  absl::InlinedVector<PJRT_ShapeSpec, 4> c_shape_specs;\n+  c_shape_specs.reserve(shape_specs.size());\n+  for (const ShapeSpec& shape_spec : shape_specs) {\n+    c_shape_specs.push_back(pjrt::ConvertToPjRtShapeSpec(shape_spec));\n   }\n+  args.shape_specs = c_shape_specs.data();\n+\n+  absl::InlinedVector<pjrt::BufferMemoryLayoutData, 4> layout_data_list;\n+  absl::InlinedVector<PJRT_Buffer_MemoryLayout*, 4> device_layout_list;\n   if (device_layouts.has_value()) {\n     args.num_device_layouts = device_layouts->size();\n-    auto device_layout_list =\n-        std::make_unique<std::vector<PJRT_Buffer_MemoryLayout*>>(\n-            device_layouts->size());\n+    device_layout_list.reserve(device_layouts->size());\n+    layout_data_list.reserve(device_layouts->size());\n     for (int i = 0; i < device_layouts->size(); ++i) {\n       if (device_layouts.has_value() && (*device_layouts)[i].has_value()) {\n         const Layout& layout = (*device_layouts)[i].value();\n         TF_ASSIGN_OR_RETURN(pjrt::BufferMemoryLayoutData c_layout_data,\n                             pjrt::ConvertToBufferMemoryLayoutData(layout));\n-        device_layout_list->emplace_back(&(c_layout_data.c_layout));\n+        layout_data_list.push_back(std::move(c_layout_data));\n+        device_layout_list.emplace_back(&(layout_data_list.back().c_layout));\n       } else {\n-        device_layout_list->emplace_back(nullptr);\n+        device_layout_list.emplace_back(nullptr);\n       }\n     }\n-    args.device_layouts = device_layout_list->data();\n+    args.device_layouts = device_layout_list.data();\n   } else {\n     args.num_device_layouts = 0;\n     args.device_layouts = nullptr;"
        }
    ],
    "stats": {
        "total": 27,
        "additions": 15,
        "deletions": 12
    }
}