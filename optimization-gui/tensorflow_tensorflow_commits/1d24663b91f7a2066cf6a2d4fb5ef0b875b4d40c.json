{
    "author": "beckerhe",
    "message": "NFC: Move AutotuneCacheKey to a separate target\n\nThis is following the one-class-per-file policy by moving the AutotuneCacheKey declaration into its own header file and target.\n\nCode has only been moved, but not changed.\n\nPiperOrigin-RevId: 800361842",
    "sha": "1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c",
    "files": [
        {
            "sha": "933f9f6444553770d74d661353569407cc6165c3",
            "filename": "third_party/xla/xla/service/gpu/autotuning/BUILD",
            "status": "modified",
            "additions": 44,
            "deletions": 4,
            "changes": 48,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD?ref=1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c",
            "patch": "@@ -397,12 +397,55 @@ cc_library(\n     deps = [\"@com_google_absl//absl/strings\"],\n )\n \n+cc_library(\n+    name = \"autotune_cache_key\",\n+    srcs = [\"autotune_cache_key.cc\"],\n+    hdrs = [\"autotune_cache_key.h\"],\n+    compatible_with = get_compatible_with_portable(),\n+    deps = [\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/stream_executor:device_description\",\n+        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"autotune_cache_key_test\",\n+    srcs = [\"autotune_cache_key_test.cc\"],\n+    data = [\n+        \"//xla/tools/hlo_opt:gpu_specs/a100_sxm_40.txtpb\",\n+        \"//xla/tools/hlo_opt:gpu_specs/a100_sxm_80.txtpb\",\n+        \"//xla/tools/hlo_opt:gpu_specs/mi200.txtpb\",\n+    ],\n+    deps = [\n+        \":autotune_cache_key\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/parser:hlo_parser\",\n+        \"//xla/stream_executor:device_description\",\n+        \"//xla/tsl/platform:env\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/platform:test\",\n+        \"@com_google_absl//absl/hash:hash_testing\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest_main\",\n+        \"@local_tsl//tsl/platform:path\",\n+        \"@local_tsl//tsl/platform:protobuf\",\n+    ],\n+)\n+\n cc_library(\n     name = \"autotuner_util\",\n     srcs = [\"autotuner_util.cc\"],\n     hdrs = [\"autotuner_util.h\"],\n     compatible_with = get_compatible_with_portable(),\n     deps = [\n+        \":autotune_cache_key\",\n         \":autotuner_status_key\",\n         \"//xla:autotune_results_proto_cc\",\n         \"//xla:autotuning_proto_cc\",\n@@ -422,7 +465,6 @@ cc_library(\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n-        \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n@@ -742,6 +784,7 @@ xla_cc_test(\n         \"gpu\",\n     ],\n     deps = [\n+        \":autotune_cache_key\",\n         \":autotuner_status_key\",\n         \":autotuner_util\",\n         \"//xla:autotune_results_proto_cc\",\n@@ -763,16 +806,13 @@ xla_cc_test(\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:status\",\n-        \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n-        \"@com_google_absl//absl/hash:hash_testing\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/strings\",\n-        \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_googletest//:gtest\",\n         \"@local_tsl//tsl/platform:path\",\n         \"@local_tsl//tsl/platform:protobuf\","
        },
        {
            "sha": "3d63efc55bc3531e5b2c039e796a53b909ad3f3b",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotune_cache_key.cc",
            "status": "added",
            "additions": 103,
            "deletions": 0,
            "changes": 103,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.cc?ref=1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c",
            "patch": "@@ -0,0 +1,103 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/autotuning/autotune_cache_key.h\"\n+\n+#include <cmath>\n+#include <string>\n+#include <variant>\n+\n+#include \"absl/log/check.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_print_options.h\"\n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+#include \"xla/stream_executor/device_description.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+std::string AutotuneCacheKey::HloInstructionToCanonicalString(\n+    const HloInstruction& instr) {\n+  auto options = HloPrintOptions::Canonical();\n+  if (instr.opcode() != HloOpcode::kFusion) {\n+    options.set_print_backend_config(true);\n+    options.set_sort_backend_config(true);\n+    return instr.ToString(options);\n+  }\n+  options.set_print_subcomputation_mode(\n+      HloPrintOptions::PrintSubcomputationMode::kOff);\n+  options.set_print_infeed_outfeed_config(false);\n+  options.set_print_only_essential_constants(true);\n+  options.set_print_operand_shape(true);\n+  options.set_print_ids(false);\n+  options.set_canonicalize_computations(true);\n+\n+  // TODO(b/266210099): This is unsound. We should probably do the fingerprint\n+  // of the HLO computation proto instead.\n+  return instr.called_computations()[0]->ToString(options);\n+}\n+\n+std::string AutotuneCacheKey::DeviceDescriptionToCacheKey(\n+    const se::DeviceDescription& device_description) {\n+  std::string compute_capability;\n+  if (auto* ccc = std::get_if<se::CudaComputeCapability>(\n+          &device_description.gpu_compute_capability())) {\n+    compute_capability = absl::StrCat(\"CUDA: \", ccc->major, \".\", ccc->minor);\n+  } else {\n+    auto* rcc = std::get_if<se::RocmComputeCapability>(\n+        &device_description.gpu_compute_capability());\n+    CHECK(rcc != nullptr) << \"Unknown compute capability type\";\n+    compute_capability = absl::StrCat(\"ROCM: \", rcc->gfx_version());\n+  }\n+\n+  // The string below should include only as much information as is needed to\n+  // make it a valid key. Information that should not be included is:\n+  // - specs that are directly derivable from the compute capability, e.g.\n+  //   shared memory size. For NVIDIA GPUs, you can see what is derivable from\n+  //   the SM version here:\n+  //   https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications-technical-specifications-per-compute-capability\n+  // - specs that are irrelevant for autotuning. E.g. the total available memory\n+  //   on a device is not relevant, because by itself, it does not affect the\n+  //   performance of single kernels.\n+  //\n+  // See b/344573710 for some discussion.\n+\n+  double memory_bandwidth = device_description.memory_bandwidth() / 1e9;\n+  // Round the memory bandwidth to make the final string nicer to read.\n+  // This will also cause minute differences in bandwidth to yield the same\n+  // cache key, but that's fine, since the difference is inconsequential.\n+  memory_bandwidth = std::round(memory_bandwidth);\n+\n+  constexpr double kBytesPerMegabyte = 1 << 20;\n+  double l2_cache_size = device_description.l2_cache_size() / kBytesPerMegabyte;\n+\n+  return absl::StrCat(compute_capability,\n+                      \", Cores: \", device_description.core_count(),\n+                      \", GPU clock: \", device_description.clock_rate_ghz(),\n+                      \" GHz, Memory bandwidth: \", memory_bandwidth,\n+                      \" GB/s, L2 cache: \", l2_cache_size, \" MB\");\n+}\n+\n+AutotuneCacheKey::AutotuneCacheKey(\n+    const se::DeviceDescription& device_description,\n+    const HloInstruction& instruction, int version)\n+    : AutotuneCacheKey(DeviceDescriptionToCacheKey(device_description),\n+                       HloInstructionToCanonicalString(instruction), version) {}\n+\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "17299cbc5c81b3607773f58a980c5e7d09845c07",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotune_cache_key.h",
            "status": "added",
            "additions": 91,
            "deletions": 0,
            "changes": 91,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.h?ref=1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c",
            "patch": "@@ -0,0 +1,91 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_SERVICE_GPU_AUTOTUNING_AUTOTUNE_CACHE_KEY_H_\n+#define XLA_SERVICE_GPU_AUTOTUNING_AUTOTUNE_CACHE_KEY_H_\n+\n+#include <string>\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/strings/str_format.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/stream_executor/device_description.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+class AutotuneCacheKey {\n+ public:\n+  // Tie a version to the cache key in order to invalidate the cache when\n+  // necessary. This should be incremented on triton upgrades or any other\n+  // changes that may affect the autotuning results.\n+  static constexpr int kCurrentVersion = 12;\n+\n+  AutotuneCacheKey(const se::DeviceDescription& device_description,\n+                   const HloInstruction& instruction,\n+                   int version = kCurrentVersion);\n+\n+  absl::string_view GetModelStr() const { return model_str_; }\n+\n+  absl::string_view GetHlo() const { return hlo_canonical_; }\n+\n+  int GetVersion() const { return version_; }\n+\n+  template <typename H>\n+  friend H AbslHashValue(H h, const AutotuneCacheKey& w) {\n+    return H::combine(std::move(h), w.model_str_, w.hlo_canonical_, w.version_);\n+  }\n+\n+  bool operator==(const AutotuneCacheKey& w) const {\n+    return model_str_ == w.model_str_ && hlo_canonical_ == w.hlo_canonical_ &&\n+           version_ == w.version_;\n+  }\n+\n+  std::string ToString() const {\n+    return absl::StrFormat(\"<key model='%s', hlo='%s', version=%d>\", model_str_,\n+                           hlo_canonical_, version_);\n+  }\n+\n+  static std::string DeviceDescriptionToCacheKey(\n+      const se::DeviceDescription& device_description);\n+\n+  static std::string HloInstructionToCanonicalString(\n+      const HloInstruction& instr);\n+\n+ private:\n+  friend class AutotunerUtil;\n+\n+  explicit AutotuneCacheKey(absl::string_view model_str,\n+                            absl::string_view hlo_canonical)\n+      : model_str_(model_str), hlo_canonical_(hlo_canonical) {}\n+\n+  explicit AutotuneCacheKey(absl::string_view model_str,\n+                            absl::string_view hlo_canonical, int version)\n+      : model_str_(model_str),\n+        hlo_canonical_(hlo_canonical),\n+        version_(version) {}\n+\n+  std::string model_str_;\n+  std::string hlo_canonical_;\n+  int version_ = kCurrentVersion;\n+};\n+\n+using AutotuneCacheKeySet = absl::flat_hash_set<AutotuneCacheKey>;\n+\n+}  // namespace gpu\n+}  // namespace xla\n+\n+#endif  // XLA_SERVICE_GPU_AUTOTUNING_AUTOTUNE_CACHE_KEY_H_"
        },
        {
            "sha": "1d790fd271e9bf065dcc9cf59c4e4b72e0929bc4",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotune_cache_key_test.cc",
            "status": "added",
            "additions": 126,
            "deletions": 0,
            "changes": 126,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key_test.cc?ref=1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c",
            "patch": "@@ -0,0 +1,126 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/autotuning/autotune_cache_key.h\"\n+\n+#include <memory>\n+#include <string>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/hash/hash_testing.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/strings/str_format.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_clone_context.h\"\n+#include \"xla/hlo/parser/hlo_parser.h\"\n+#include \"xla/stream_executor/device_description.h\"\n+#include \"xla/tsl/platform/env.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/test.h\"\n+#include \"tsl/platform/path.h\"\n+#include \"tsl/platform/protobuf.h\"\n+\n+namespace xla {\n+namespace gpu {\n+namespace {\n+using testing::HasSubstr;\n+\n+constexpr absl::string_view kDotFusionHloText = R\"hlo(\n+    HloModule module\n+    fused_computation {\n+          tmp_0 = f16[1,16,17,3]{3,2,1,0} parameter(0) \n+          tmp_1 = f16[16,51]{1,0} bitcast(f16[1,16,17,3]{3,2,1,0} tmp_0)\n+          tmp_2 = s8[16,17,3]{2,1,0} parameter(1)\n+          tmp_3 = s8[51,16]{0,1} bitcast(s8[16,17,3]{2,1,0} tmp_2)\n+          tmp_4 = f16[51,16]{0,1} convert(s8[51,16]{0,1} tmp_3)\n+          tmp_5 = f16[16,16]{1,0} dot(f16[16,51]{1,0} tmp_1, f16[51,16]{0,1} tmp_4), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+          ROOT tmp_6 = f16[1,16,16]{2,1,0} bitcast(f16[16,16]{1,0} tmp_5)\n+    }\n+    \n+    ENTRY main {\n+          p0 = f16[1,16,17,3]{3,2,1,0} parameter(0) \n+          p1 = s8[16,17,3]{2,1,0} parameter(1)\n+          ROOT fusion = f16[1,16,16]{2,1,0} fusion(p0, p1), kind=kCustom, calls=fused_computation\n+    }\n+  )hlo\";\n+\n+TEST(AutotuneCacheKeyTest, DeviceDescriptionToCacheKey) {\n+  auto device_description =\n+      [](absl::string_view spec_file_name) -> se::DeviceDescription {\n+    se::GpuTargetConfigProto proto;\n+    std::string spec_string;\n+    CHECK_OK(tsl::ReadFileToString(\n+        tsl::Env::Default(),\n+        tsl::io::JoinPath(tsl::testing::XlaSrcRoot(), \"tools\", \"hlo_opt\",\n+                          \"gpu_specs\", spec_file_name),\n+        &spec_string));\n+    EXPECT_TRUE(\n+        tsl::protobuf::TextFormat::ParseFromString(spec_string, &proto));\n+    absl::StatusOr<se::DeviceDescription> device_description =\n+        se::DeviceDescription::FromProto(proto.gpu_device_info());\n+    CHECK_OK(device_description.status());\n+    return *device_description;\n+  };\n+\n+  EXPECT_EQ(AutotuneCacheKey::DeviceDescriptionToCacheKey(\n+                device_description(\"a100_sxm_40.txtpb\")),\n+            \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: \"\n+            \"1555 GB/s, L2 cache: 40 MB\");\n+\n+  EXPECT_EQ(AutotuneCacheKey::DeviceDescriptionToCacheKey(\n+                device_description(\"a100_sxm_80.txtpb\")),\n+            \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: \"\n+            \"2039 GB/s, L2 cache: 40 MB\");\n+\n+  EXPECT_EQ(AutotuneCacheKey::DeviceDescriptionToCacheKey(\n+                device_description(\"mi200.txtpb\")),\n+            \"ROCM: gfx90a, Cores: 110, GPU clock: 1.7 GHz, Memory bandwidth: \"\n+            \"1638 GB/s, L2 cache: 8 MB\");\n+}\n+\n+TEST(AutotuneCacheKeyTest, VersionIsIncludedInCacheKey) {\n+  stream_executor::DeviceDescription empty_device_description;\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnUnverifiedModule(kDotFusionHloText));\n+  AutotuneCacheKey key =\n+      AutotuneCacheKey(empty_device_description,\n+                       *module->entry_computation()->root_instruction());\n+  EXPECT_THAT(key.ToString(),\n+              HasSubstr(absl::StrFormat(\"version=%d\", key.GetVersion())));\n+}\n+\n+TEST(AutotuneCacheKeyTest, VersionChangeInvalidateCacheKey) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnUnverifiedModule(kDotFusionHloText));\n+  stream_executor::DeviceDescription empty_device_description;\n+\n+  AutotuneCacheKey key0 = AutotuneCacheKey(\n+      empty_device_description,\n+      *module->entry_computation()->root_instruction(), /*version=*/0);\n+  AutotuneCacheKey key1 = AutotuneCacheKey(\n+      empty_device_description,\n+      *module->entry_computation()->root_instruction(), /*version=*/1);\n+  EXPECT_FALSE(key0 == key1);\n+  EXPECT_NE(key0.ToString(), key1.ToString());\n+  EXPECT_TRUE(absl::VerifyTypeImplementsAbslHashCorrectly({\n+      key0,\n+      key1,\n+  }));\n+}\n+\n+}  // namespace\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "bcf90073a19b81626d1b21cc40dd9e028fc05f2f",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_util.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 74,
            "changes": 75,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util.cc?ref=1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c",
            "patch": "@@ -17,12 +17,10 @@ limitations under the License.\n \n #include <algorithm>\n #include <array>\n-#include <cmath>\n #include <cstdint>\n #include <optional>\n #include <string>\n #include <utility>\n-#include <variant>\n \n #include \"absl/base/const_init.h\"\n #include \"absl/base/thread_annotations.h\"\n@@ -42,13 +40,10 @@ limitations under the License.\n #include \"xla/autotuning.pb.h\"\n #include \"xla/hlo/ir/hlo_clone_context.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n-#include \"xla/hlo/ir/hlo_opcode.h\"\n-#include \"xla/hlo/ir/hlo_print_options.h\"\n #include \"xla/service/dump.h\"\n+#include \"xla/service/gpu/autotuning/autotune_cache_key.h\"\n #include \"xla/service/gpu/autotuning/autotuner_status_key.h\"\n #include \"xla/status_macros.h\"\n-#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n-#include \"xla/stream_executor/device_description.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/logging.h\"\n@@ -298,68 +293,6 @@ void SerializeAutotuneEntry(AutotuneResults* results, const AutotuneCacheKey& k,\n   return autotune_cache.empty();\n }\n \n-std::string AutotuneCacheKey::HloInstructionToCanonicalString(\n-    const HloInstruction& instr) {\n-  auto options = HloPrintOptions::Canonical();\n-  if (instr.opcode() != HloOpcode::kFusion) {\n-    options.set_print_backend_config(true);\n-    options.set_sort_backend_config(true);\n-    return instr.ToString(options);\n-  }\n-  options.set_print_subcomputation_mode(\n-      HloPrintOptions::PrintSubcomputationMode::kOff);\n-  options.set_print_infeed_outfeed_config(false);\n-  options.set_print_only_essential_constants(true);\n-  options.set_print_operand_shape(true);\n-  options.set_print_ids(false);\n-  options.set_canonicalize_computations(true);\n-\n-  // TODO(b/266210099): This is unsound. We should probably do the fingerprint\n-  // of the HLO computation proto instead.\n-  return instr.called_computations()[0]->ToString(options);\n-}\n-\n-/*static*/ std::string AutotuneCacheKey::DeviceDescriptionToCacheKey(\n-    const se::DeviceDescription& device_description) {\n-  std::string compute_capability;\n-  if (auto* ccc = std::get_if<se::CudaComputeCapability>(\n-          &device_description.gpu_compute_capability())) {\n-    compute_capability = absl::StrCat(\"CUDA: \", ccc->major, \".\", ccc->minor);\n-  } else {\n-    auto* rcc = std::get_if<se::RocmComputeCapability>(\n-        &device_description.gpu_compute_capability());\n-    CHECK(rcc != nullptr) << \"Unknown compute capability type\";\n-    compute_capability = absl::StrCat(\"ROCM: \", rcc->gfx_version());\n-  }\n-\n-  // The string below should include only as much information as is needed to\n-  // make it a valid key. Information that should not be included is:\n-  // - specs that are directly derivable from the compute capability, e.g.\n-  //   shared memory size. For NVIDIA GPUs, you can see what is derivable from\n-  //   the SM version here:\n-  //   https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications-technical-specifications-per-compute-capability\n-  // - specs that are irrelevant for autotuning. E.g. the total available memory\n-  //   on a device is not relevant, because by itself, it does not affect the\n-  //   performance of single kernels.\n-  //\n-  // See b/344573710 for some discussion.\n-\n-  double memory_bandwidth = device_description.memory_bandwidth() / 1e9;\n-  // Round the memory bandwidth to make the final string nicer to read.\n-  // This will also cause minute differences in bandwidth to yield the same\n-  // cache key, but that's fine, since the difference is inconsequential.\n-  memory_bandwidth = std::round(memory_bandwidth);\n-\n-  constexpr double kBytesPerMegabyte = 1 << 20;\n-  double l2_cache_size = device_description.l2_cache_size() / kBytesPerMegabyte;\n-\n-  return absl::StrCat(compute_capability,\n-                      \", Cores: \", device_description.core_count(),\n-                      \", GPU clock: \", device_description.clock_rate_ghz(),\n-                      \" GHz, Memory bandwidth: \", memory_bandwidth,\n-                      \" GB/s, L2 cache: \", l2_cache_size, \" MB\");\n-}\n-\n namespace {\n enum class CacheType { kNone, kInMemory, kOnDisk };\n \n@@ -601,11 +534,5 @@ void AddVersionToAutotuneResults(AutotuneResults& results) {\n   }\n }\n \n-AutotuneCacheKey::AutotuneCacheKey(\n-    const se::DeviceDescription& device_description,\n-    const HloInstruction& instruction, int version)\n-    : AutotuneCacheKey(DeviceDescriptionToCacheKey(device_description),\n-                       HloInstructionToCanonicalString(instruction), version) {}\n-\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "aa638cfe609d25b4f59e27728822cd019fb15a7b",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_util.h",
            "status": "modified",
            "additions": 1,
            "deletions": 62,
            "changes": 63,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util.h?ref=1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c",
            "patch": "@@ -15,24 +15,21 @@ limitations under the License.\n #ifndef XLA_SERVICE_GPU_AUTOTUNING_AUTOTUNER_UTIL_H_\n #define XLA_SERVICE_GPU_AUTOTUNING_AUTOTUNER_UTIL_H_\n \n-#include <algorithm>\n #include <cstdint>\n #include <functional>\n #include <memory>\n #include <optional>\n #include <string>\n-#include <utility>\n #include <variant>\n \n-#include \"absl/container/flat_hash_set.h\"\n #include \"absl/log/check.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n-#include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/autotune_results.pb.h\"\n #include \"xla/autotuning.pb.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/service/gpu/autotuning/autotune_cache_key.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -107,64 +104,6 @@ class DeviceOrDevicelessConfig {\n   mutable std::unique_ptr<se::DeviceMemoryAllocator> allocator_;\n };\n \n-class AutotuneCacheKey {\n- public:\n-  // Tie a version to the cache key in order to invalidate the cache when\n-  // necessary. This should be incremented on triton upgrades or any other\n-  // changes that may affect the autotuning results.\n-  static constexpr int kCurrentVersion = 12;\n-\n-  AutotuneCacheKey(const se::DeviceDescription& device_description,\n-                   const HloInstruction& instruction,\n-                   int version = kCurrentVersion);\n-\n-  absl::string_view GetModelStr() const { return model_str_; }\n-\n-  absl::string_view GetHlo() const { return hlo_canonical_; }\n-\n-  int GetVersion() const { return version_; }\n-\n-  template <typename H>\n-  friend H AbslHashValue(H h, const AutotuneCacheKey& w) {\n-    return H::combine(std::move(h), w.model_str_, w.hlo_canonical_, w.version_);\n-  }\n-\n-  bool operator==(const AutotuneCacheKey& w) const {\n-    return model_str_ == w.model_str_ && hlo_canonical_ == w.hlo_canonical_ &&\n-           version_ == w.version_;\n-  }\n-\n-  std::string ToString() const {\n-    return absl::StrFormat(\"<key model='%s', hlo='%s', version=%d>\", model_str_,\n-                           hlo_canonical_, version_);\n-  }\n-\n-  static std::string DeviceDescriptionToCacheKey(\n-      const se::DeviceDescription& device_description);\n-\n-  static std::string HloInstructionToCanonicalString(\n-      const HloInstruction& instr);\n-\n- private:\n-  friend class AutotunerUtil;\n-\n-  explicit AutotuneCacheKey(absl::string_view model_str,\n-                            absl::string_view hlo_canonical)\n-      : model_str_(model_str), hlo_canonical_(hlo_canonical) {}\n-\n-  explicit AutotuneCacheKey(absl::string_view model_str,\n-                            absl::string_view hlo_canonical, int version)\n-      : model_str_(model_str),\n-        hlo_canonical_(hlo_canonical),\n-        version_(version) {}\n-\n-  std::string model_str_;\n-  std::string hlo_canonical_;\n-  int version_ = kCurrentVersion;\n-};\n-\n-using AutotuneCacheKeySet = absl::flat_hash_set<AutotuneCacheKey>;\n-\n class AutotuneConfig {\n  public:\n   bool should_init_buffers() const { return should_init_buffers_; }"
        },
        {
            "sha": "38675683e5edaa242f873db2fdeb40346c678fcc",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_util_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 66,
            "changes": 67,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util_test.cc?ref=1d24663b91f7a2066cf6a2d4fb5ef0b875b4d40c",
            "patch": "@@ -23,12 +23,10 @@ limitations under the License.\n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/container/flat_hash_set.h\"\n-#include \"absl/hash/hash_testing.h\"\n #include \"absl/log/check.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/status_matchers.h\"\n #include \"absl/strings/str_cat.h\"\n-#include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/autotune_results.pb.h\"\n #include \"xla/autotuning.pb.h\"\n@@ -39,6 +37,7 @@ limitations under the License.\n #include \"xla/hlo/parser/hlo_parser.h\"\n #include \"xla/hlo/utils/hlo_query.h\"\n #include \"xla/service/dump.h\"\n+#include \"xla/service/gpu/autotuning/autotune_cache_key.h\"\n #include \"xla/service/gpu/autotuning/autotuner_status_key.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n@@ -547,70 +546,6 @@ TEST_F(FileBasedCacheTest, RepeatedAddResultDoesNotWriteTheFileAgain) {\n   EXPECT_EQ(Read(cache_file_path), kPlaceholderContent);\n }\n \n-TEST(AutotuneCacheKeyTest, DeviceDescriptionToCacheKey) {\n-  auto device_description =\n-      [](absl::string_view spec_file_name) -> se::DeviceDescription {\n-    se::GpuTargetConfigProto proto;\n-    std::string spec_string;\n-    CHECK_OK(tsl::ReadFileToString(\n-        tsl::Env::Default(),\n-        tsl::io::JoinPath(tsl::testing::XlaSrcRoot(), \"tools\", \"hlo_opt\",\n-                          \"gpu_specs\", spec_file_name),\n-        &spec_string));\n-    EXPECT_TRUE(\n-        tsl::protobuf::TextFormat::ParseFromString(spec_string, &proto));\n-    absl::StatusOr<se::DeviceDescription> device_description =\n-        se::DeviceDescription::FromProto(proto.gpu_device_info());\n-    CHECK_OK(device_description.status());\n-    return *device_description;\n-  };\n-\n-  EXPECT_EQ(AutotuneCacheKey::DeviceDescriptionToCacheKey(\n-                device_description(\"a100_sxm_40.txtpb\")),\n-            \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: \"\n-            \"1555 GB/s, L2 cache: 40 MB\");\n-\n-  EXPECT_EQ(AutotuneCacheKey::DeviceDescriptionToCacheKey(\n-                device_description(\"a100_sxm_80.txtpb\")),\n-            \"CUDA: 8.0, Cores: 108, GPU clock: 1.41 GHz, Memory bandwidth: \"\n-            \"2039 GB/s, L2 cache: 40 MB\");\n-\n-  EXPECT_EQ(AutotuneCacheKey::DeviceDescriptionToCacheKey(\n-                device_description(\"mi200.txtpb\")),\n-            \"ROCM: gfx90a, Cores: 110, GPU clock: 1.7 GHz, Memory bandwidth: \"\n-            \"1638 GB/s, L2 cache: 8 MB\");\n-}\n-\n-TEST(AutotuneCacheKeyTest, VersionIsIncludedInCacheKey) {\n-  stream_executor::DeviceDescription empty_device_description;\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          ParseAndReturnUnverifiedModule(kDotFusionHloText));\n-  AutotuneCacheKey key =\n-      AutotuneCacheKey(empty_device_description,\n-                       *module->entry_computation()->root_instruction());\n-  EXPECT_THAT(key.ToString(),\n-              HasSubstr(absl::StrFormat(\"version=%d\", key.GetVersion())));\n-}\n-\n-TEST(AutotuneCacheKeyTest, VersionChangeInvalidateCacheKey) {\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          ParseAndReturnUnverifiedModule(kDotFusionHloText));\n-  stream_executor::DeviceDescription empty_device_description;\n-\n-  AutotuneCacheKey key0 = AutotuneCacheKey(\n-      empty_device_description,\n-      *module->entry_computation()->root_instruction(), /*version=*/0);\n-  AutotuneCacheKey key1 = AutotuneCacheKey(\n-      empty_device_description,\n-      *module->entry_computation()->root_instruction(), /*version=*/1);\n-  EXPECT_FALSE(key0 == key1);\n-  EXPECT_NE(key0.ToString(), key1.ToString());\n-  EXPECT_TRUE(absl::VerifyTypeImplementsAbslHashCorrectly({\n-      key0,\n-      key1,\n-  }));\n-}\n-\n TEST_F(FileBasedCacheTest, AddResultDoesNotWriteTheFileInReadMode) {\n   SetCacheMode(DebugOptions::AUTOTUNE_CACHE_MODE_READ);\n   TF_ASSERT_OK_AND_ASSIGN("
        }
    ],
    "stats": {
        "total": 573,
        "additions": 367,
        "deletions": 206
    }
}