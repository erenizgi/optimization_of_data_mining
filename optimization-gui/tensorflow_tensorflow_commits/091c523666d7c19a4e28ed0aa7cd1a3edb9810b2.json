{
    "author": "mgoldfarb-nvidia",
    "message": "PR #30706: Expose Multi-Host HLO Runner in Python\n\nImported from GitHub PR https://github.com/openxla/xla/pull/30706\n\nüìù Summary of Changes\nExposes the multi-host runner via nanobind interface for calling by Python programs that register custom calls.\n\nüéØ Justification\nHLOs containing custom calls are not executable because the custom call targets are not linked. This change provides a straightforward path by allowing for registration of calls from python.\n\nüöÄ Kind of Contribution\n‚ú® New Feature\n\nCopybara import of the project:\n\n--\nde1a373888ba85e0ef1c04b00009cd4cd1090e3a by Michael Goldfarb <mgoldfarb@nvidia.com>:\n\nExpose multihost runner to python.\n\n--\n797ee1c93931a4796099514c2292145fa74edb67 by Michael Goldfarb <mgoldfarb@nvidia.com>:\n\nCleanups.\n\n--\n22717611d143d39957a78caacb6204d9892bb2b9 by Michael Goldfarb <mgoldfarb@nvidia.com>:\n\nAdd type registration.\n\n--\nd67cf0dd25fe03f93205be04811bfa5954da2c02 by Michael Goldfarb <mgoldfarb@nvidia.com>:\n\nRemove ns.\n\n--\n3b8f477f6d6f939db47e1573e452cd3e0ebb29f3 by Michael Goldfarb <mgoldfarb@nvidia.com>:\n\nremove ffi registration from runner.\n\n--\ne121e98abf6ad9e6220d97839c0dbc8a47fb866d by Michael Goldfarb <mgoldfarb@nvidia.com>:\n\nAdd back python registration code.\n\nMerging this change closes #30706\n\nPiperOrigin-RevId: 803426356",
    "sha": "091c523666d7c19a4e28ed0aa7cd1a3edb9810b2",
    "files": [
        {
            "sha": "690fc663b070865ea2a04c83f64569a7d4a3edee",
            "filename": "third_party/xla/xla/tools/multihost_hlo_runner/BUILD",
            "status": "modified",
            "additions": 57,
            "deletions": 3,
            "changes": 60,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/091c523666d7c19a4e28ed0aa7cd1a3edb9810b2/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/091c523666d7c19a4e28ed0aa7cd1a3edb9810b2/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2FBUILD?ref=091c523666d7c19a4e28ed0aa7cd1a3edb9810b2",
            "patch": "@@ -4,6 +4,7 @@ load(\"@local_config_rocm//rocm:build_defs.bzl\", \"if_rocm\")\n load(\"//xla:xla.default.bzl\", \"xla_cc_binary\")\n load(\"//xla/tests:build_defs.bzl\", \"xla_test\")\n load(\"//xla/tsl:tsl.bzl\", \"if_cuda_or_rocm\", \"if_google\")\n+load(\"//xla/tsl:tsl.default.bzl\", \"tsl_pybind_extension\")\n load(\"//xla/tsl/platform:build_config_root.bzl\", \"tf_gpu_tests_tags\")\n load(\"//xla/tsl/platform:rules_cc.bzl\", \"cc_library\")\n \n@@ -37,9 +38,7 @@ cc_library(\n     testonly = True,\n     srcs = [\"hlo_runner_main.cc\"],\n     compatible_with = None,\n-    tags = [\n-        \"no_mac\",\n-    ],\n+    tags = [\"no_mac\"],\n     deps = [\n         \":create_client\",\n         \":functional_hlo_runner\",\n@@ -280,3 +279,58 @@ xla_test(\n         \"@local_tsl//tsl/platform:protobuf\",\n     ],\n )\n+\n+tsl_pybind_extension(\n+    name = \"py_hlo_multihost_runner\",\n+    srcs = [\"python_hlo_runner.cc\"],\n+    deps = [\n+        \":create_client\",\n+        \":functional_hlo_runner\",\n+        \":hlo_input_output_format\",\n+        \":profiler_interface\",\n+        \"//xla:debug_options_flags\",\n+        \"//xla:status_macros\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla/ffi\",\n+        \"//xla/ffi:ffi_api\",\n+        \"//xla/ffi/api:c_api\",\n+        \"//xla/pjrt:pjrt_client\",\n+        \"//xla/pjrt:status_casters\",\n+        \"//xla/pjrt/distributed\",\n+        \"//xla/pjrt/distributed:client\",\n+        \"//xla/pjrt/distributed:key_value_store_interface\",\n+        \"//xla/pjrt/distributed:service\",\n+        \"//xla/pjrt/plugin/xla_gpu:xla_gpu_allocator_config\",\n+        \"//xla/pjrt/plugin/xla_gpu:xla_gpu_client_options\",\n+        \"//xla/python:logging\",\n+        \"//xla/service:cpu_plugin\",\n+        \"//xla/service:custom_call_target_registry\",\n+        \"//xla/service:hlo_module_util\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util:command_line_flags\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/time\",\n+        \"@local_tsl//tsl/platform:errors\",\n+        \"@local_tsl//tsl/platform:logging\",\n+        \"@local_tsl//tsl/platform:platform_port\",\n+        \"@local_tsl//tsl/platform:status\",\n+        \"@local_tsl//tsl/platform:statusor\",\n+        \"@nanobind\",\n+    ] + if_cuda_or_rocm([\n+        \"//xla/service:gpu_plugin\",\n+        \"//xla/backends/profiler/gpu:cupti_tracer\",\n+        \"//xla/backends/profiler/gpu:device_tracer\",\n+    ]) + if_cuda([\n+        \"//xla/stream_executor:cuda_platform\",\n+    ] + if_google(\n+        [\n+            \"//third_party/py/jax/jaxlib/cuda:cuda_gpu_kernels\",  # fixdeps: keep\n+        ],\n+    )) + if_rocm([\n+        \"//xla/stream_executor:rocm_platform\",\n+    ]),\n+)"
        },
        {
            "sha": "e71110b21decb61dfb160e116bccdcb77f62690d",
            "filename": "third_party/xla/xla/tools/multihost_hlo_runner/python_hlo_runner.cc",
            "status": "added",
            "additions": 450,
            "deletions": 0,
            "changes": 450,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/091c523666d7c19a4e28ed0aa7cd1a3edb9810b2/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Fpython_hlo_runner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/091c523666d7c19a4e28ed0aa7cd1a3edb9810b2/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Fpython_hlo_runner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Fpython_hlo_runner.cc?ref=091c523666d7c19a4e28ed0aa7cd1a3edb9810b2",
            "patch": "@@ -0,0 +1,450 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <optional>\n+#include <string>\n+\n+#include \"nanobind/stl/shared_ptr.h\"  // IWYU pragma: keep\n+#include \"nanobind/stl/string.h\"  // IWYU pragma: keep\n+#include \"nanobind/stl/string_view.h\"  // IWYU pragma: keep\n+#include \"nanobind/stl/vector.h\"  // IWYU pragma: keep\n+#include \"xla/ffi/api/c_api.h\"\n+#include \"xla/ffi/ffi.h\"\n+#include \"xla/ffi/ffi_api.h\"\n+#include \"xla/pjrt/plugin/xla_gpu/xla_gpu_allocator_config.h\"\n+#include \"xla/pjrt/plugin/xla_gpu/xla_gpu_client_options.h\"\n+#include \"xla/pjrt/status_casters.h\"\n+#include \"xla/python/logging.h\"\n+#include \"xla/service/custom_call_target_registry.h\"\n+#include \"xla/tools/multihost_hlo_runner/create_client.h\"\n+#include \"xla/tools/multihost_hlo_runner/functional_hlo_runner.h\"\n+#include \"xla/tools/multihost_hlo_runner/hlo_input_output_format.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/xla_data.pb.h\"\n+\n+namespace nb = ::nanobind;\n+\n+namespace xla {\n+\n+enum DeviceType {\n+  kHost = 0,\n+  kGpu = 1,\n+};\n+\n+struct PyHloRunnerConfig {\n+  InputFormat input_format = InputFormat::kProtoText;\n+  FunctionalHloRunner::ModuleOutputMode output_mode =\n+      FunctionalHloRunner::ModuleOutputMode::kReturnOutputs;\n+  bool should_run = true;\n+  bool enable_mock_nccl = false;\n+  std::string dump_output_literal_to = \"\";\n+  int task_id = 0;\n+  int num_nodes = 1;\n+  DeviceType device_type = DeviceType::kGpu;\n+  std::string address = \"\";\n+  int32_t num_replicas = -1;\n+  int32_t num_partitions = 1;\n+  bool log_output = false;\n+  FunctionalHloRunner::HloPassesMode hlo_pass_mode =\n+      FunctionalHloRunner::HloPassesMode::kStandardCompile;\n+  FunctionalHloRunner::SpmdMode spmd_mode =\n+      FunctionalHloRunner::SpmdMode::kNotUseSpmdPartitioning;\n+  bool is_spmd_partitioned_module = false;\n+  std::string xla_dump_to = \"\";\n+  bool xla_dump_as_text = false;\n+  bool xla_dump_as_proto = false;\n+  FunctionalHloRunner::ModuleArgumentMode hlo_argument_mode =\n+      FunctionalHloRunner::ModuleArgumentMode::kUseRandomInputs;\n+  int32_t while_execution_count = -1;\n+  bool remove_infeed_outfeed = true;\n+  bool compile_as_stablehlo = false;\n+  bool use_layouts_from_hlo_module = false;\n+  bool force_auto_layout = false;\n+  int32_t num_repeats = 1;\n+  std::string execution_options_path = \"\";\n+  int64_t gpu_client_initialization_timeout_sec = 300;\n+  float gpu_client_mem_fraction = GpuAllocatorConfig{}.memory_fraction;\n+  bool profile_execution = false;\n+  std::string xla_gpu_dump_xspace_to = \"\";\n+};\n+\n+absl::StatusOr<FunctionalHloRunner::PreprocessingOptions>\n+PreprocessingOptionsFromFlags(const PyHloRunnerConfig& opts) {\n+  FunctionalHloRunner::PreprocessingOptions out;\n+  out.spmd_partitioned_mode =\n+      opts.is_spmd_partitioned_module\n+          ? FunctionalHloRunner::SpmdPartitionedMode::kIsSpmdPartitionedModule\n+          : FunctionalHloRunner::SpmdPartitionedMode::\n+                kIsNotSpmdPartitionedModule;\n+  out.while_execution_count =\n+      opts.while_execution_count > 0\n+          ? std::make_optional(opts.while_execution_count)\n+          : std::nullopt;\n+  out.remove_infeed_outfeed = opts.remove_infeed_outfeed;\n+  return out;\n+}\n+\n+absl::StatusOr<FunctionalHloRunner::RunningOptions> RunningOptionsFromFlags(\n+    const PyHloRunnerConfig& opts) {\n+  FunctionalHloRunner::RunningOptions out;\n+  out.module_argument_mode = opts.hlo_argument_mode;\n+  out.module_output_mode = opts.output_mode;\n+  out.num_repeats = static_cast<size_t>(opts.num_repeats);\n+  out.log_input_output_mode =\n+      opts.log_output ? FunctionalHloRunner::LogOutputMode::kLogOutput\n+                      : FunctionalHloRunner::LogOutputMode::kNotLogOutput;\n+  return out;\n+}\n+\n+absl::StatusOr<FunctionalHloRunner::RawCompileOptions>\n+RawCompileOptionsFromFlags(const PyHloRunnerConfig& opts) {\n+  FunctionalHloRunner::RawCompileOptions out;\n+  out.hlo_passes_mode = opts.hlo_pass_mode;\n+  out.spmd_mode = opts.spmd_mode;\n+  if (!opts.execution_options_path.empty()) {\n+    TF_ASSIGN_OR_RETURN(\n+        out.execution_options,\n+        FunctionalHloRunner::LoadExecutionOptions(opts.execution_options_path));\n+  }\n+  out.num_replicas = opts.num_replicas < 0\n+                         ? std::nullopt\n+                         : std::optional<int>(opts.num_replicas);\n+  out.num_partitions = opts.num_partitions < 0\n+                           ? std::nullopt\n+                           : std::optional<int>(opts.num_partitions);\n+  out.xla_dump_to = opts.xla_dump_to;\n+  out.xla_text_dump_mode =\n+      opts.xla_dump_as_text\n+          ? FunctionalHloRunner::XlaTextDumpMode::kDumpAsText\n+          : FunctionalHloRunner::XlaTextDumpMode::kNotDumpAsText;\n+  out.xla_proto_dump_mode =\n+      opts.xla_dump_as_proto\n+          ? FunctionalHloRunner::XlaProtoDumpMode::kDumpAsProto\n+          : FunctionalHloRunner::XlaProtoDumpMode::kNotDumpAsProto;\n+  out.xla_gpu_dump_xspace_to = opts.xla_gpu_dump_xspace_to;\n+  return out;\n+}\n+\n+absl::Status RunHloFiles(const std::vector<std::string>& hlo_files,\n+                         const PyHloRunnerConfig& opts) {\n+  TF_ASSIGN_OR_RETURN(FunctionalHloRunner::PreprocessingOptions preproc_options,\n+                      PreprocessingOptionsFromFlags(opts));\n+  preproc_options.annotate_while_loop_trip_count = true;\n+  TF_ASSIGN_OR_RETURN(\n+      FunctionalHloRunner::RawCompileOptions raw_compile_options,\n+      RawCompileOptionsFromFlags(opts));\n+  TF_ASSIGN_OR_RETURN(FunctionalHloRunner::RunningOptions running_options,\n+                      RunningOptionsFromFlags(opts));\n+\n+  // tsl::Flags::Parse() leaves unknown flags in argv, we assume that those are\n+  // HLO files to run. Note that argv[0] is the binary name and is excluded.\n+  if (hlo_files.size() == 0) {\n+    return absl::InvalidArgumentError(\"No HLO files provided.\");\n+  }\n+\n+  if (!opts.dump_output_literal_to.empty() && hlo_files.size() > 1) {\n+    return absl::InvalidArgumentError(\n+        \"Can only dump output literal when single input file is specified.\");\n+  }\n+\n+  if (opts.gpu_client_mem_fraction < 0.0 ||\n+      opts.gpu_client_mem_fraction > 1.0) {\n+    return absl::InvalidArgumentError(\n+        \"Invalid GPU client memory fraction. Must be in range [0.0, 1.0]\");\n+  }\n+\n+  PjRtEnvironment env;\n+  std::unique_ptr<HLORunnerProfiler> hlo_runner_profiler;\n+  if (opts.device_type == DeviceType::kGpu) {\n+    GpuClientOptions gpu_options;\n+    gpu_options.node_id = opts.task_id;\n+    gpu_options.num_nodes = opts.num_nodes;\n+    gpu_options.enable_mock_nccl = opts.enable_mock_nccl;\n+    gpu_options.allocator_config.memory_fraction = opts.gpu_client_mem_fraction;\n+    TF_ASSIGN_OR_RETURN(\n+        env, GetPjRtEnvironmentForGpu(\n+                 opts.address, gpu_options,\n+                 absl::Seconds(opts.gpu_client_initialization_timeout_sec)));\n+  } else {\n+    QCHECK(opts.device_type == DeviceType::kHost) << \"Invalid device type\";\n+    TF_ASSIGN_OR_RETURN(env, GetPjRtEnvironmentForHostCpu());\n+  }\n+\n+  CHECK(env.client != nullptr);\n+  if (!opts.xla_gpu_dump_xspace_to.empty()) {\n+    TF_ASSIGN_OR_RETURN(hlo_runner_profiler,\n+                        HLORunnerProfiler::Create(opts.xla_gpu_dump_xspace_to,\n+                                                  /*keep_xspace=*/false));\n+    running_options.profiler = hlo_runner_profiler.get();\n+  }\n+\n+  for (const auto& hlo_file : hlo_files) {\n+    std::vector<ExecutionProfile> execution_profiles;\n+    if (opts.profile_execution) {\n+      running_options.execution_profiles = &execution_profiles;\n+    }\n+    if (opts.should_run) {\n+      TF_RETURN_IF_ERROR(FunctionalHloRunner::LoadAndRunAndDump(\n+          *env.client, GetDebugOptionsFromFlags(), preproc_options,\n+          raw_compile_options, running_options, hlo_file, opts.input_format,\n+          opts.dump_output_literal_to, opts.task_id));\n+    } else {\n+      TF_RETURN_IF_ERROR(FunctionalHloRunner::LoadAndCompile(\n+          *env.client, GetDebugOptionsFromFlags(), preproc_options,\n+          raw_compile_options, hlo_file, opts.input_format, opts.task_id));\n+    }\n+    for (int i = 0; i < execution_profiles.size(); ++i) {\n+      LOG(INFO) << \"## Execution time, file=\" << hlo_file << \" repeat=\" << i\n+                << \" duration=\" << execution_profiles[i].compute_time_ns()\n+                << \"ns\";\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status RegisterCustomCallTarget(const std::string& fn_name, nb::object fn,\n+                                      const std::string& platform,\n+                                      int api_version,\n+                                      XLA_FFI_Handler_Traits traits) {\n+  // Register legacy custom call target (untyped void* API).\n+  if (api_version == 0) {\n+    if (traits != 0) {\n+      return absl::InvalidArgumentError(\n+          \"Custom call target registration with traits is not supported for \"\n+          \"api_version=0\");\n+    }\n+\n+    nb::capsule capsule;\n+    if (!nb::try_cast<nb::capsule>(fn, capsule)) {\n+      return absl::InvalidArgumentError(\n+          \"Custom call target registration with api_version=0 requires a \"\n+          \"PyCapsule fn object\");\n+    }\n+\n+    CustomCallTargetRegistry::Global()->Register(fn_name, capsule.data(),\n+                                                 platform);\n+    return absl::OkStatus();\n+  }\n+\n+  if (api_version == 1) {\n+    // Register a single execute handler\n+    nb::capsule capsule;\n+    if (nb::try_cast<nb::capsule>(fn, capsule)) {\n+      return ffi::TakeStatus(ffi::Ffi::RegisterStaticHandler(\n+          ffi::GetXlaFfiApi(), fn_name, platform,\n+          reinterpret_cast<XLA_FFI_Handler*>(capsule.data())));\n+    }\n+\n+    // Register a bundle of handlers\n+    nb::dict bundle;\n+    if (nb::try_cast<nb::dict>(fn, bundle)) {\n+      auto handler = [&](const char* name) -> absl::StatusOr<XLA_FFI_Handler*> {\n+        if (!bundle.contains(name)) {\n+          return nullptr;\n+        }\n+\n+        nb::capsule capsule;\n+        if (nb::try_cast<nb::capsule>(bundle[name], capsule)) {\n+          return reinterpret_cast<XLA_FFI_Handler*>(capsule.data());\n+        }\n+        return absl::InvalidArgumentError(\n+            \"Custom call target registration with api_version=1 requires a \"\n+            \"PyCapsule fn object for all dict keys\");\n+      };\n+\n+      XLA_FFI_Handler_Bundle bundle;\n+      TF_ASSIGN_OR_RETURN(bundle.instantiate, handler(\"instantiate\"));\n+      TF_ASSIGN_OR_RETURN(bundle.prepare, handler(\"prepare\"));\n+      TF_ASSIGN_OR_RETURN(bundle.initialize, handler(\"initialize\"));\n+      TF_ASSIGN_OR_RETURN(bundle.execute, handler(\"execute\"));\n+\n+      return ffi::TakeStatus(ffi::Ffi::RegisterStaticHandler(\n+          ffi::GetXlaFfiApi(), fn_name, platform, bundle, traits));\n+    }\n+\n+    return absl::InvalidArgumentError(\n+        \"Unsupported custom call target type for api_version=1\");\n+  }\n+\n+  return absl::UnimplementedError(absl::StrFormat(\n+      \"API version %d is not supported by RegisterCustomCallTarget. Supported \"\n+      \"versions are 0 and 1.\",\n+      api_version));\n+}\n+\n+nb::dict GetRegisteredCustomCallTargets(const std::string& platform) {\n+  nb::dict targets;\n+\n+  // version 0 handlers\n+  for (const auto& [name, target] :\n+       CustomCallTargetRegistry::Global()->registered_symbols(platform)) {\n+    targets[nb::str(name.data(), name.size())] = nb::capsule(target);\n+  }\n+\n+  // version 1 handlers\n+  auto ffi_handlers = ffi::StaticRegisteredHandlers(platform);\n+  if (!ffi_handlers.ok()) {\n+    return targets;\n+  }\n+\n+  for (const auto& [name, registration] : *ffi_handlers) {\n+    nb::dict bundle;\n+    auto export_handler = [&](absl::string_view name, XLA_FFI_Handler* h) {\n+      if (h != nullptr) {\n+        bundle[nb::str(name.data(), name.size())] =\n+            nb::capsule(reinterpret_cast<void*>(h));\n+      }\n+    };\n+    export_handler(\"instantiate\", registration.bundle.instantiate);\n+    export_handler(\"prepare\", registration.bundle.prepare);\n+    export_handler(\"initialize\", registration.bundle.initialize);\n+    export_handler(\"execute\", registration.bundle.execute);\n+    targets[nb::str(name.data(), name.size())] = std::move(bundle);\n+  }\n+  return targets;\n+}\n+\n+absl::Status RegisterCustomTypeId(absl::string_view type_name,\n+                                  nb::object type_id) {\n+  nb::capsule capsule;\n+  if (!nb::try_cast<nb::capsule>(type_id, capsule)) {\n+    return absl::InvalidArgumentError(\n+        \"The type_id argument to register_custom_call_type_id must be a \"\n+        \"PyCapsule object holding a pointer to a XLA_FFI_TypeId.\");\n+  }\n+  XLA_FFI_TypeId* type_id_ptr =\n+      reinterpret_cast<XLA_FFI_TypeId*>(static_cast<void*>(capsule.data()));\n+  return ffi::TakeStatus(ffi::Ffi::RegisterTypeId(xla::ffi::GetXlaFfiApi(),\n+                                                  type_name, type_id_ptr));\n+}\n+\n+NB_MODULE(py_hlo_multihost_runner, m) {\n+  InitializeAbslLogging();\n+\n+  m.def(\"RunHloFiles\", ThrowIfErrorWrapper(RunHloFiles));\n+  m.def(\n+      \"register_custom_call_target\",\n+      [](const std::string& fn_name, nb::object fn, const std::string& platform,\n+         int api_version, XLA_FFI_Handler_Traits traits) {\n+        ThrowIfError(RegisterCustomCallTarget(fn_name, std::move(fn), platform,\n+                                              api_version, traits));\n+      },\n+      nb::arg(\"fn_name\"), nb::arg(\"fn\"), nb::arg(\"platform\"),\n+      nb::arg(\"api_version\") = 0, nb::arg(\"traits\") = 0);\n+  m.def(\"custom_call_targets\", GetRegisteredCustomCallTargets,\n+        nb::arg(\"platform\"));\n+  m.def(\n+      \"register_custom_type_id\",\n+      [](absl::string_view type_name, nb::object type_id) {\n+        xla::ThrowIfError(RegisterCustomTypeId(type_name, type_id));\n+      },\n+      nb::arg(\"type_name\"), nb::arg(\"type_id\"));\n+\n+  nb::class_<PyHloRunnerConfig>(m, \"PyHloRunnerConfig\")\n+      .def(nb::init<>())\n+      .def_rw(\"input_format\", &PyHloRunnerConfig::input_format)\n+      .def_rw(\"output_mode\", &PyHloRunnerConfig::output_mode)\n+      .def_rw(\"should_run\", &PyHloRunnerConfig::should_run)\n+      .def_rw(\"enable_mock_nccl\", &PyHloRunnerConfig::enable_mock_nccl)\n+      .def_rw(\"dump_output_literal_to\",\n+              &PyHloRunnerConfig::dump_output_literal_to)\n+      .def_rw(\"task_id\", &PyHloRunnerConfig::task_id)\n+      .def_rw(\"num_nodes\", &PyHloRunnerConfig::num_nodes)\n+      .def_rw(\"device_type\", &PyHloRunnerConfig::device_type)\n+      .def_rw(\"address\", &PyHloRunnerConfig::address)\n+      .def_rw(\"num_replicas\", &PyHloRunnerConfig::num_replicas)\n+      .def_rw(\"num_partitions\", &PyHloRunnerConfig::num_partitions)\n+      .def_rw(\"log_output\", &PyHloRunnerConfig::log_output)\n+      .def_rw(\"hlo_pass_mode\", &PyHloRunnerConfig::hlo_pass_mode)\n+      .def_rw(\"spmd_mode\", &PyHloRunnerConfig::spmd_mode)\n+      .def_rw(\"is_spmd_partitioned_module\",\n+              &PyHloRunnerConfig::is_spmd_partitioned_module)\n+      .def_rw(\"xla_dump_to\", &PyHloRunnerConfig::xla_dump_to)\n+      .def_rw(\"xla_dump_as_text\", &PyHloRunnerConfig::xla_dump_as_text)\n+      .def_rw(\"xla_dump_as_proto\", &PyHloRunnerConfig::xla_dump_as_proto)\n+      .def_rw(\"hlo_argument_mode\", &PyHloRunnerConfig::hlo_argument_mode)\n+      .def_rw(\"while_execution_count\",\n+              &PyHloRunnerConfig::while_execution_count)\n+      .def_rw(\"remove_infeed_outfeed\",\n+              &PyHloRunnerConfig::remove_infeed_outfeed)\n+      .def_rw(\"compile_as_stablehlo\", &PyHloRunnerConfig::compile_as_stablehlo)\n+      .def_rw(\"use_layouts_from_hlo_module\",\n+              &PyHloRunnerConfig::use_layouts_from_hlo_module)\n+      .def_rw(\"force_auto_layout\", &PyHloRunnerConfig::force_auto_layout)\n+      .def_rw(\"num_repeats\", &PyHloRunnerConfig::num_repeats)\n+      .def_rw(\"gpu_client_initialization_timeout_sec\",\n+              &PyHloRunnerConfig::gpu_client_initialization_timeout_sec)\n+      .def_rw(\"gpu_client_mem_fraction\",\n+              &PyHloRunnerConfig::gpu_client_mem_fraction)\n+      .def_rw(\"profile_execution\", &PyHloRunnerConfig::profile_execution)\n+      .def_rw(\"xla_gpu_dump_xspace_to\",\n+              &PyHloRunnerConfig::xla_gpu_dump_xspace_to);\n+\n+  nb::enum_<InputFormat>(m, \"InputFormat\")\n+      .value(\"Text\", InputFormat::kText)\n+      .value(\"ProtoText\", InputFormat::kProtoText)\n+      .value(\"ProtoBinary\", InputFormat::kProtoBinary)\n+      .value(\"SnapshotProtoBinary\", InputFormat::kSnapshotProtoBinary)\n+      .value(\"UnoptimizedSnapshotProtoBinary\",\n+             InputFormat::kUnoptimizedSnapshotProtoBinary)\n+      .value(\"UnoptimizedSnapshotProtoText\",\n+             InputFormat::kUnoptimizedSnapshotProtoText)\n+      .value(\"SerializedPjrtExecutable\",\n+             InputFormat::kSerializedPjRtExecutable);\n+\n+  nb::enum_<FunctionalHloRunner::ModuleOutputMode>(m, \"ModuleOutputMode\")\n+      .value(\"ReturnOutputs\",\n+             FunctionalHloRunner::ModuleOutputMode::kReturnOutputs)\n+      .value(\"NotReturnOutputs\",\n+             FunctionalHloRunner::ModuleOutputMode::kNotReturnOutputs)\n+      .value(\"ReturnDevice0Outputs\",\n+             FunctionalHloRunner::ModuleOutputMode::kReturnDevice0Outputs);\n+\n+  nb::enum_<FunctionalHloRunner::ModuleArgumentMode>(m, \"ModuleArgumentMode\")\n+      .value(\"UseDeviceIdAsInput\",\n+             FunctionalHloRunner::ModuleArgumentMode::kUseDeviceIdAsInput)\n+      .value(\"UseRandomInputs\",\n+             FunctionalHloRunner::ModuleArgumentMode::kUseRandomInputs)\n+      .value(\"UseSharedRandomInputs\",\n+             FunctionalHloRunner::ModuleArgumentMode::kUseSharedRandomInputs)\n+      .value(\"UseZerosAsInput\",\n+             FunctionalHloRunner::ModuleArgumentMode::kUseZerosAsInput)\n+      .value(\"Uninitialized\",\n+             FunctionalHloRunner::ModuleArgumentMode::kUninitialized);\n+\n+  nb::enum_<FunctionalHloRunner::HloPassesMode>(m, \"HloPassesMode\")\n+      .value(\"RunXLABackendOnly\",\n+             FunctionalHloRunner::HloPassesMode::kRunXLABackendOnly)\n+      .value(\"DisableAllHloPasses\",\n+             FunctionalHloRunner::HloPassesMode::kDisableAllHloPasses)\n+      .value(\"StandardCompile\",\n+             FunctionalHloRunner::HloPassesMode::kStandardCompile);\n+\n+  nb::enum_<FunctionalHloRunner::SpmdMode>(m, \"SpmdMode\")\n+      .value(\"UseSpmdPartitioning\",\n+             FunctionalHloRunner::SpmdMode::kUseSpmdPartitioning)\n+      .value(\"UseShardyPartitioning\",\n+             FunctionalHloRunner::SpmdMode::kUseShardyPartitioning)\n+      .value(\"NotUseSpmdPartitioning\",\n+             FunctionalHloRunner::SpmdMode::kNotUseSpmdPartitioning);\n+\n+  nb::enum_<DeviceType>(m, \"DeviceType\")\n+      .value(\"Host\", DeviceType::kHost)\n+      .value(\"Gpu\", DeviceType::kGpu);\n+}\n+\n+}  // namespace xla"
        }
    ],
    "stats": {
        "total": 510,
        "additions": 507,
        "deletions": 3
    }
}