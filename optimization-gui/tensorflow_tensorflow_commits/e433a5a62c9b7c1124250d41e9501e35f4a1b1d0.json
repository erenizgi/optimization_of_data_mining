{
    "author": "ezhulenev",
    "message": "[xla:gpu] Remove unused op kind from CollectiveConfig\n\nPiperOrigin-RevId: 836512175",
    "sha": "e433a5a62c9b7c1124250d41e9501e35f4a1b1d0",
    "files": [
        {
            "sha": "46a39b248b8a63caf2753fad1743e933fff7f779",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e433a5a62c9b7c1124250d41e9501e35f4a1b1d0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e433a5a62c9b7c1124250d41e9501e35f4a1b1d0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc?ref=e433a5a62c9b7c1124250d41e9501e35f4a1b1d0",
            "patch": "@@ -163,8 +163,6 @@ CollectiveKernelThunkMetadata CreateCollectiveKernelThunk(\n       /*operand_count=*/1,\n       /*operand_element_type=*/{PrimitiveType::F32},\n       /*replica_groups=*/{replica_group},\n-      /*collective_op_kind=*/\n-      RendezvousKey::CollectiveOpKind::kCrossReplica,\n       /*op_id=*/0,\n       /*group_mode=*/\n       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA,"
        },
        {
            "sha": "4e248dcc218f2c07d84f6d096703416cbcfa95e4",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_metadata_thunk.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e433a5a62c9b7c1124250d41e9501e35f4a1b1d0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e433a5a62c9b7c1124250d41e9501e35f4a1b1d0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc?ref=e433a5a62c9b7c1124250d41e9501e35f4a1b1d0",
            "patch": "@@ -59,7 +59,6 @@ CollectiveConfig CollectiveMetadataThunk::GetCollectiveConfig(\n         hlo.operand(i)->shape().element_type());\n   }\n \n-  config.collective_op_kind = RendezvousKey::kCrossReplica;\n   config.op_id = static_cast<int64_t>(hlo.GetModule()->unique_id());\n   if (hlo.has_backend_config()) {\n     xla::gpu::GpuBackendConfig backend_config ="
        },
        {
            "sha": "995cd9b36056c1128b55114addd43d023adda21f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 10,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e433a5a62c9b7c1124250d41e9501e35f4a1b1d0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e433a5a62c9b7c1124250d41e9501e35f4a1b1d0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=e433a5a62c9b7c1124250d41e9501e35f4a1b1d0",
            "patch": "@@ -184,22 +184,17 @@ bool CollectiveConfig::IsDegenerate(int64_t replica_count,\n void CollectiveConfig::SetCollectiveOpKindAndID(\n     const HloCollectivePermuteInstruction* instr) {\n   if (instr->channel_id().has_value()) {\n-    collective_op_kind = RendezvousKey::kCrossModule;\n-    op_id = instr->channel_id().value();\n+    op_id = *instr->channel_id();\n   } else {\n-    collective_op_kind = RendezvousKey::kCrossReplica;\n     op_id = static_cast<int64_t>(instr->GetModule()->unique_id());\n   }\n }\n \n void CollectiveConfig::SetCollectiveOpKindAndID(\n     const HloSendRecvInstruction* instr) {\n-  int64_t channel_id = instr->channel_id().value_or(0);\n-  if (channel_id > 0) {\n-    collective_op_kind = RendezvousKey::kCrossModule;\n-    op_id = channel_id;\n+  if (instr->channel_id().has_value()) {\n+    op_id = *instr->channel_id();\n   } else {\n-    collective_op_kind = RendezvousKey::kCrossReplica;\n     op_id = static_cast<int64_t>(instr->GetModule()->unique_id());\n   }\n }\n@@ -216,10 +211,8 @@ CollectiveConfig GetCollectiveConfig(\n   config.replica_groups = hlo->replica_groups();\n \n   if (hlo->channel_id().has_value()) {\n-    config.collective_op_kind = RendezvousKey::kCrossModule;\n     config.op_id = *hlo->channel_id();\n   } else {\n-    config.collective_op_kind = RendezvousKey::kCrossReplica;\n     config.op_id = static_cast<int64_t>(hlo->GetModule()->unique_id());\n   }\n "
        },
        {
            "sha": "b2ef4180be000a66fc0e021afa934c2bf43a1285",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.h",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e433a5a62c9b7c1124250d41e9501e35f4a1b1d0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e433a5a62c9b7c1124250d41e9501e35f4a1b1d0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h?ref=e433a5a62c9b7c1124250d41e9501e35f4a1b1d0",
            "patch": "@@ -40,7 +40,6 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/service/buffer_assignment.h\"\n-#include \"xla/service/collective_ops_utils.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/llvm_ir/llvm_util.h\"\n #include \"xla/service/rendezvous.h\"\n@@ -53,17 +52,16 @@ limitations under the License.\n namespace xla::gpu {\n \n struct CollectiveConfig {\n+  void SetCollectiveOpKindAndID(const HloCollectivePermuteInstruction* instr);\n+  void SetCollectiveOpKindAndID(const HloSendRecvInstruction* instr);\n+  bool IsDegenerate(int64_t replica_count, int64_t partition_count) const;\n+\n   int64_t operand_count;\n   std::vector<PrimitiveType> operand_element_type;\n   std::vector<ReplicaGroup> replica_groups;\n-  RendezvousKey::CollectiveOpKind collective_op_kind;\n   int64_t op_id;\n   CollectiveOpGroupMode group_mode;\n   bool use_symmetric_buffer;\n-\n-  void SetCollectiveOpKindAndID(const HloCollectivePermuteInstruction* instr);\n-  void SetCollectiveOpKindAndID(const HloSendRecvInstruction* instr);\n-  bool IsDegenerate(int64_t replica_count, int64_t partition_count) const;\n };\n \n CollectiveConfig GetCollectiveConfig(const HloInstruction* hlo,"
        }
    ],
    "stats": {
        "total": 26,
        "additions": 7,
        "deletions": 19
    }
}