{
    "author": "felixwqp",
    "message": "Add the support for the collective-permute in perf-table generation tool, more specifically, the collective-permute will generate 3 patterns given a certain replica groups.\n\nTo minimize the variance of p2p op, the collective permute will be run 100 times. We take the average to calculate the bandwidth.\n\nPiperOrigin-RevId: 840771698",
    "sha": "f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123",
    "files": [
        {
            "sha": "c2939ffff5ff470d0e022e23df66462fe1d61b7b",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2FBUILD?ref=f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123",
            "patch": "@@ -94,6 +94,7 @@ cc_library(\n     name = \"collective_ops_utils\",\n     srcs = [\"collective_ops_utils.cc\"],\n     hdrs = [\"collective_ops_utils.h\"],\n+    # copybara:uncomment compatible_with = [\"//buildenv/target:non_prod\"],\n     deps = [\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/ir:hlo\","
        },
        {
            "sha": "5f422444fd55e970227f1dcedfdb4cdebe56b84d",
            "filename": "third_party/xla/xla/tools/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Ftools%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Ftools%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2FBUILD?ref=f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123",
            "patch": "@@ -766,6 +766,7 @@ cc_library(\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service/gpu/model:hlo_op_profile_proto_cc\",\n         \"//xla/service/gpu/model:hlo_op_profiles\",\n+        \"//xla/service/gpu/transforms/collectives:collective_ops_utils\",\n         \"//xla/tools/multihost_hlo_runner:create_client\",\n         \"//xla/tools/multihost_hlo_runner:functional_hlo_runner\",\n         \"//xla/tsl/platform:env\",\n@@ -863,8 +864,10 @@ xla_test(\n     deps = [\n         \":collective_perf_table_gen\",\n         \"//xla/service/gpu/model:hlo_op_profile_proto_cc\",\n+        \"//xla/service/gpu/transforms/collectives:collective_ops_utils\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/tests:hlo_test_base\",\n+        \"@com_google_absl//absl/log\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )"
        },
        {
            "sha": "96bed07273028e198260b4e3dc064660713dafce",
            "filename": "third_party/xla/xla/tools/collective_perf_table_gen.cc",
            "status": "modified",
            "additions": 148,
            "deletions": 20,
            "changes": 168,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen.cc?ref=f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123",
            "patch": "@@ -19,6 +19,7 @@ limitations under the License.\n #include <cstddef>\n #include <cstdint>\n #include <memory>\n+#include <optional>\n #include <string>\n #include <utility>\n #include <vector>\n@@ -30,6 +31,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/strings/match.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_join.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/strings/substitute.h\"\n #include \"absl/time/time.h\"\n@@ -43,6 +45,7 @@ limitations under the License.\n #include \"xla/service/backend.h\"\n #include \"xla/service/gpu/model/hlo_op_profile.pb.h\"\n #include \"xla/service/gpu/model/hlo_op_profiles.h\"\n+#include \"xla/service/gpu/transforms/collectives/collective_ops_utils.h\"\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/tools/multihost_hlo_runner/create_client.h\"\n #include \"xla/tools/multihost_hlo_runner/functional_hlo_runner.h\"\n@@ -64,11 +67,21 @@ constexpr uint8_t kBytesPerElem = 4;\n constexpr double kGpuMemFraction = 0.8;\n \n // # of profiling runs.\n-constexpr uint8_t kNumProfilingRuns = 5;\n+constexpr uint8_t kNumProfilingRuns = 20;\n \n struct StaticSpec {\n   CollectivePerfTableGen::CollectiveType collective_type;\n+  // For collective hlo instructions, the `replica_groups` is used to define\n+  // the replica_groups attribute of collective hlo instructions.\n+\n+  // For collective permute hlo instructions, the `replica_groups` is used to\n+  // define the number of devices participating in the collective permute.\n   IotaReplicaGroupList replica_groups;\n+\n+  // Defines the source-target pairs of a collective permute hlo instruction.\n+  // It is only used for collective permute hlo instructions, and is\n+  // std::nullopt for others.\n+  std::optional<CollectivePermuteCostModelType> collective_permute_pattern;\n   int64_t tensor_size_bytes;\n };\n \n@@ -124,6 +137,7 @@ int64_t GetInputDim(CollectivePerfTableGen::CollectiveType type,\n     case CollectivePerfTableGen::CollectiveType::ALL_REDUCE:\n     case CollectivePerfTableGen::CollectiveType::REDUCE_SCATTER:\n     case CollectivePerfTableGen::CollectiveType::ALL_TO_ALL:\n+    case CollectivePerfTableGen::CollectiveType::COLLECTIVE_PERMUTE:\n       dim_size = tensor_size_bytes / kBytesPerElem;\n       break;\n     case CollectivePerfTableGen::CollectiveType::ALL_GATHER:\n@@ -145,6 +159,7 @@ int64_t GetOutputDim(CollectivePerfTableGen::CollectiveType type,\n     case CollectivePerfTableGen::CollectiveType::ALL_REDUCE:\n     case CollectivePerfTableGen::CollectiveType::ALL_GATHER:\n     case CollectivePerfTableGen::CollectiveType::ALL_TO_ALL:\n+    case CollectivePerfTableGen::CollectiveType::COLLECTIVE_PERMUTE:\n       dim_size = tensor_size_bytes / kBytesPerElem;\n       break;\n     case CollectivePerfTableGen::CollectiveType::REDUCE_SCATTER:\n@@ -157,10 +172,13 @@ int64_t GetOutputDim(CollectivePerfTableGen::CollectiveType type,\n   return dim_size;\n }\n \n-std::string GetHlo(CollectivePerfTableGen::CollectiveType type,\n-                   int64_t input_dim, int64_t output_dim,\n-                   const IotaReplicaGroupList& replica_groups) {\n+std::string GetHlo(\n+    CollectivePerfTableGen::CollectiveType type, int64_t input_dim,\n+    int64_t output_dim, const IotaReplicaGroupList& replica_groups,\n+    std::optional<CollectivePermuteCostModelType> collective_permute_pattern) {\n   CHECK_EQ(kBytesPerElem, 4);\n+  CHECK(type != CollectivePerfTableGen::CollectiveType::COLLECTIVE_PERMUTE ||\n+        collective_permute_pattern.has_value());\n \n   std::string hlo;\n   switch (type) {\n@@ -229,6 +247,44 @@ std::string GetHlo(CollectivePerfTableGen::CollectiveType type,\n                              \"f32\", input_dim, output_dim,\n                              replica_groups.ToString());\n       break;\n+    case CollectivePerfTableGen::CollectiveType::COLLECTIVE_PERMUTE: {\n+      int num_devices = replica_groups.num_devices_per_group() *\n+                        replica_groups.num_replica_groups();\n+      std::string source_target_pairs =\n+          BuildSourceTargetPairs(*collective_permute_pattern, num_devices);\n+      hlo = absl::Substitute(\n+          R\"(\n+        HloModule collective-permute-while-loop-microbenchmark, num_partitions=$2\n+\n+        while_cond {\n+          iter = (f32[$0], u32[]) parameter(0)\n+          i = u32[] get-tuple-element(iter), index=1\n+          ub = u32[] constant(100)\n+          ROOT compare = pred[] compare(i, ub), direction=LT\n+        }\n+\n+        while_body {\n+          iter = (f32[$0], u32[]) parameter(0)\n+          i = u32[] get-tuple-element(iter), index=1\n+          arg = f32[$0] get-tuple-element(iter), index=0\n+          collective-permute = f32[$0] collective-permute(arg), channel_id=1, source_target_pairs=$1\n+          c1 = u32[] constant(1)\n+          i_next = u32[] add(i, c1)\n+          ROOT out = (f32[$0], u32[]) tuple(collective-permute, i_next)\n+        }\n+\n+        ENTRY main {\n+          arg = f32[$0] parameter(0)\n+          c0 = u32[] constant(0)\n+          cp_first_iter = f32[$0] collective-permute(arg), channel_id=1, source_target_pairs=$1\n+          init = (f32[$0], u32[]) tuple(cp_first_iter, c0)\n+          while = (f32[$0], u32[]) while(init), condition=while_cond, body=while_body\n+          ROOT result = f32[$0] get-tuple-element(while), index=0\n+        }\n+      )\",\n+          input_dim, source_target_pairs, num_devices);\n+      break;\n+    }\n     default:\n       LOG(FATAL) << \"Unsupported collective type.\";\n   }\n@@ -243,7 +299,8 @@ std::unique_ptr<HloModule> CreateCollectiveModule(const StaticSpec& spec) {\n       spec.collective_type, spec.tensor_size_bytes, spec.replica_groups);\n \n   std::string hlo =\n-      GetHlo(spec.collective_type, input_dim, output_dim, spec.replica_groups);\n+      GetHlo(spec.collective_type, input_dim, output_dim, spec.replica_groups,\n+             spec.collective_permute_pattern);\n \n   HloModuleConfig config;\n   config.set_num_partitions(spec.replica_groups.num_devices_per_group() *\n@@ -276,6 +333,48 @@ IotaReplicaGroupList GetCollectiveDeviceList(\n \n }  // namespace\n \n+// Generates source_target_pairs based on pattern.\n+std::string BuildSourceTargetPairs(CollectivePermuteCostModelType pattern,\n+                                   int num_devices) {\n+  std::vector<std::pair<int, int>> pairs_vec;\n+  switch (pattern) {\n+    case CollectivePermuteCostModelType::kIntraPartitionOneWay:\n+      // Pattern: {0->n/2, 1->n/2+1, ...}\n+      // Requires even number of devices.\n+      CHECK_EQ(num_devices % 2, 0);\n+      for (int i = 0; i < num_devices / 2; ++i) {\n+        pairs_vec.push_back({i, i + num_devices / 2});\n+      }\n+      break;\n+    case CollectivePermuteCostModelType::kIntraPartitionTwoWayAllMutual:\n+      // Pattern: {0->1, 1->0, 2->3, 3->2, ...}\n+      // Requires even number of devices.\n+      CHECK_EQ(num_devices % 2, 0);\n+      for (int i = 0; i < num_devices / 2; ++i) {\n+        pairs_vec.push_back({2 * i, 2 * i + 1});\n+        pairs_vec.push_back({2 * i + 1, 2 * i});\n+      }\n+      break;\n+    case CollectivePermuteCostModelType::kIntraPartitionTwoWayHasNonMutual:\n+      // Ring pattern: {0->1, 1->2, ..., n-1->0}\n+      for (int i = 0; i < num_devices; ++i) {\n+        pairs_vec.push_back({i, (i + 1) % num_devices});\n+      }\n+      break;\n+    default:\n+      LOG(FATAL) << \"Unsupported collective permute pattern.\";\n+  }\n+\n+  return absl::StrCat(\n+      \"{\",\n+      absl::StrJoin(pairs_vec, \",\",\n+                    [](std::string* out, const std::pair<int, int>& pair) {\n+                      absl::StrAppend(out, \"{\", pair.first, \",\", pair.second,\n+                                      \"}\");\n+                    }),\n+      \"}\");\n+}\n+\n /*static*/ std::unique_ptr<CollectivePerfTableGen>\n CollectivePerfTableGen::Create(CollectivePerfTableGen::Config config) {\n   return std::unique_ptr<CollectivePerfTableGen>(\n@@ -348,8 +447,7 @@ CollectivePerfTableGen::ProfilingData CollectivePerfTableGen::Profile(\n   if (config_.task_id == 0) {\n     std::vector<ExecutionProfile> profiles = Run(*executable);\n     return {\n-        /*runtime=*/absl::Nanoseconds(GetMedianRuntimeNs(std::move(profiles))),\n-    };\n+        /*runtime=*/absl::Nanoseconds(GetMedianRuntimeNs(std::move(profiles)))};\n   }\n   Run(*executable);\n   return {};\n@@ -375,13 +473,29 @@ DeviceHloInstructionProfiles CollectivePerfTableGen::ComputeTable() {\n     for (CollectiveType collective_type : config_.collective_types) {\n       for (absl::string_view replica_groups_raw : config_.replica_groups_list) {\n         CHECK(collective_type != CollectiveType::UNSPECIFIED);\n-\n-        StaticSpec spec{\n-            collective_type,\n-            GetCollectiveDeviceList(replica_groups_raw),\n-            tensor_size,\n-        };\n-        static_specs.push_back(spec);\n+        IotaReplicaGroupList replica_groups =\n+            GetCollectiveDeviceList(replica_groups_raw);\n+        int num_devices = replica_groups.num_devices_per_group() *\n+                          replica_groups.num_replica_groups();\n+\n+        if (collective_type != CollectiveType::COLLECTIVE_PERMUTE) {\n+          static_specs.push_back(\n+              {collective_type, replica_groups, std::nullopt, tensor_size});\n+          continue;\n+        }\n+        for (CollectivePermuteCostModelType pattern :\n+             config_.collective_permute_patterns) {\n+          // Skip patterns that require an even number of devices if n is odd.\n+          if (num_devices % 2 != 0 &&\n+              (pattern ==\n+                   CollectivePermuteCostModelType::kIntraPartitionOneWay ||\n+               pattern == CollectivePermuteCostModelType::\n+                              kIntraPartitionTwoWayAllMutual)) {\n+            continue;\n+          }\n+          static_specs.push_back(\n+              {collective_type, replica_groups, pattern, tensor_size});\n+        }\n       }\n     }\n   }\n@@ -397,7 +511,10 @@ DeviceHloInstructionProfiles CollectivePerfTableGen::ComputeTable() {\n     ExplicitSpec spec = GetExplicitSpec(static_spec);\n     std::string fingerprint = spec.module->GetFingerprint128();\n     HloInstruction* instr =\n-        spec.module->entry_computation()->root_instruction();\n+        static_spec.collective_type == CollectiveType::COLLECTIVE_PERMUTE\n+            ? spec.module->GetComputationWithName(\"while_body\")\n+                  ->GetInstructionWithName(\"collective-permute\")\n+            : spec.module->entry_computation()->root_instruction();\n     CHECK(hlo_query::IsCollectiveCommunicationOp(instr->opcode()));\n \n     HloInstructionProfile entry;\n@@ -411,6 +528,12 @@ DeviceHloInstructionProfiles CollectivePerfTableGen::ComputeTable() {\n       VLOG(1) << \"Size: \" << static_spec.tensor_size_bytes << \" too small.\";\n       continue;\n     }\n+    if (static_spec.collective_type == CollectiveType::COLLECTIVE_PERMUTE) {\n+      // collective permute template hlo runs in a 100x while loop to\n+      // average the variance. So we would need to divide the runtime\n+      // by 100 to get the runtime of a single iteration.\n+      profiled_data.runtime /= 100;\n+    }\n     entry.set_network_throughput_bytes_per_sec(GetNetworkThroughputBytesPerSec(\n         profiled_data.runtime, static_spec.tensor_size_bytes));\n \n@@ -491,17 +614,20 @@ DeviceHloInstructionProfiles CollectivePerfTableGen::Merge(\n \n     for (auto& [device_descriptor, data] : partial_profile.entries()) {\n       for (const HloInstructionProfile& profile : data.entries()) {\n-        CHECK(!profile.fingerprint().empty())\n-            << \"Expected fingerprint to deduplicate: \" << profile.DebugString();\n+        std::string fingerprint = profile.fingerprint();\n+        if (fingerprint.empty()) {\n+          fingerprint =\n+              absl::StrCat(\"no-fingerprint#\", profiling_results_counter);\n+        }\n \n         ProfilingResult profiling_result{\n             device_descriptor,\n-            std::move(profile.instruction()),\n+            profile.instruction(),\n             {\n                 profile.operands().begin(),\n                 profile.operands().end(),\n             },\n-            std::move(profile.fingerprint()),\n+            fingerprint,\n             profile.clock_cycles(),\n             profile.flops(),\n             profile.network_throughput_bytes_per_sec(),\n@@ -529,7 +655,9 @@ DeviceHloInstructionProfiles CollectivePerfTableGen::Merge(\n     }\n     profile_proto.set_flops(profiling_result.flops);\n     profile_proto.set_clock_cycles(profiling_result.clock_cycles);\n-    profile_proto.set_fingerprint(profiling_result.fingerprint);\n+    if (!absl::StartsWith(profiling_result.fingerprint, \"no-fingerprint#\")) {\n+      profile_proto.set_fingerprint(profiling_result.fingerprint);\n+    }\n     profile_proto.set_network_throughput_bytes_per_sec(\n         profiling_result.network_throughput);\n "
        },
        {
            "sha": "8cd145aa1278995b4caa5356b993590f6fca4ae3",
            "filename": "third_party/xla/xla/tools/collective_perf_table_gen.h",
            "status": "modified",
            "additions": 16,
            "deletions": 5,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen.h?ref=f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123",
            "patch": "@@ -30,6 +30,7 @@ limitations under the License.\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/service/backend.h\"\n #include \"xla/service/gpu/model/hlo_op_profile.pb.h\"\n+#include \"xla/service/gpu/transforms/collectives/collective_ops_utils.h\"\n #include \"xla/tools/multihost_hlo_runner/create_client.h\"\n #include \"xla/xla_data.pb.h\"\n \n@@ -54,6 +55,7 @@ class CollectivePerfTableGen {\n     ALL_GATHER,\n     REDUCE_SCATTER,\n     ALL_TO_ALL,\n+    COLLECTIVE_PERMUTE,\n   };\n \n   struct Config {\n@@ -62,10 +64,14 @@ class CollectivePerfTableGen {\n     // Search space.\n     StepSpec tensor_size_bytes_spec;\n     std::vector<CollectiveType> collective_types = {\n-        CollectiveType::ALL_REDUCE,\n-        CollectiveType::ALL_GATHER,\n-        CollectiveType::REDUCE_SCATTER,\n-        CollectiveType::ALL_TO_ALL,\n+        CollectiveType::ALL_REDUCE,         CollectiveType::ALL_GATHER,\n+        CollectiveType::REDUCE_SCATTER,     CollectiveType::ALL_TO_ALL,\n+        CollectiveType::COLLECTIVE_PERMUTE,\n+    };\n+    std::vector<CollectivePermuteCostModelType> collective_permute_patterns = {\n+        CollectivePermuteCostModelType::kIntraPartitionOneWay,\n+        CollectivePermuteCostModelType::kIntraPartitionTwoWayAllMutual,\n+        CollectivePermuteCostModelType::kIntraPartitionTwoWayHasNonMutual,\n     };\n     std::vector<std::string> replica_groups_list;\n \n@@ -79,7 +85,7 @@ class CollectivePerfTableGen {\n   };\n \n   struct ProfilingData {\n-    absl::Duration runtime = absl::Nanoseconds(42);\n+    absl::Duration runtime = absl::Nanoseconds(420);\n   };\n \n   // Factory method to create the perf table gen.\n@@ -122,6 +128,11 @@ class CollectivePerfTableGen {\n   std::unique_ptr<PjRtEnvironment> pjrt_env_;\n };\n \n+// Builds a string of source target pairs for collective permute.\n+// Right now, this only supports the intra-partition cases.\n+std::string BuildSourceTargetPairs(CollectivePermuteCostModelType pattern,\n+                                   int num_devices);\n+\n }  // namespace xla::gpu\n \n #endif  // XLA_TOOLS_COLLECTIVE_PERF_TABLE_GEN_H_"
        },
        {
            "sha": "7f8ca1015cdba0643ff8d51ac2273097a35b944e",
            "filename": "third_party/xla/xla/tools/collective_perf_table_gen_main.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen_main.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen_main.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen_main.cc?ref=f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123",
            "patch": "@@ -111,6 +111,11 @@ std::vector<CollectivePerfTableGen::CollectiveType> ParseCollectives(\n       types.push_back(CollectivePerfTableGen::CollectiveType::ALL_TO_ALL);\n       continue;\n     }\n+    if (token == \"COLLECTIVE_PERMUTE\") {\n+      types.push_back(\n+          CollectivePerfTableGen::CollectiveType::COLLECTIVE_PERMUTE);\n+      continue;\n+    }\n   }\n   CHECK_GT(types.size(), 0);\n   return types;\n@@ -186,7 +191,7 @@ int main(int argc, char* argv[]) {\n       tsl::Flag(\"collectives\", &collectives_unparsed,\n                 \"Comma separated list of collectives to generate perf table \"\n                 \"for. Allowed values: ALL_REDUCE, ALL_GATHER, REDUCE_SCATTER, \"\n-                \"ALL_TO_ALL.\"),\n+                \"ALL_TO_ALL, COLLECTIVE_PERMUTE.\"),\n       tsl::Flag(\"tensor_size_bytes_spec\", &tensor_size_bytes_spec_unparsed,\n                 \"Spec for a search sweep over transfer sizes. Format example: \"\n                 \"start=1,stop=8,factor=2 generates {1,2,4,8}.\"),"
        },
        {
            "sha": "ec7d5c0c17034a5a2f6a06c6ab63ddb3b3de9ccf",
            "filename": "third_party/xla/xla/tools/collective_perf_table_gen_test.cc",
            "status": "modified",
            "additions": 64,
            "deletions": 3,
            "changes": 67,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fcollective_perf_table_gen_test.cc?ref=f3fd4fc1bdc266b0d31bfcd2df5bd3cbb5d43123",
            "patch": "@@ -16,12 +16,12 @@ limitations under the License.\n #include \"xla/tools/collective_perf_table_gen.h\"\n \n #include <memory>\n-#include <variant>\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n+#include \"absl/log/log.h\"\n #include \"xla/service/gpu/model/hlo_op_profile.pb.h\"\n-#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+#include \"xla/service/gpu/transforms/collectives/collective_ops_utils.h\"\n #include \"xla/tests/hlo_test_base.h\"\n \n namespace xla::gpu {\n@@ -76,7 +76,7 @@ TEST_F(CollectivePerfTableGenTest, ConstantStepGeneratesConfigs) {\n   EXPECT_EQ(profiles.entries().begin()->second.entries_size(), 15);\n }\n \n-TEST_F(CollectivePerfTableGenTest, FactorStepGeneratesConfigs) {\n+TEST_F(CollectivePerfTableGenTest, FactorStepGeneratesConfigsForCollective) {\n   cfg_.collective_types = {\n       CollectivePerfTableGen::CollectiveType::ALL_REDUCE,\n       CollectivePerfTableGen::CollectiveType::ALL_GATHER,\n@@ -96,10 +96,40 @@ TEST_F(CollectivePerfTableGenTest, FactorStepGeneratesConfigs) {\n       CollectivePerfTableGen::Create(cfg_);\n \n   DeviceHloInstructionProfiles profiles = gen->ComputeTable();\n+  for (const auto& value : profiles.entries().begin()->second.entries()) {\n+    LOG(INFO) << \"  value: \" << value.DebugString();\n+  }\n   EXPECT_EQ(profiles.entries_size(), 1);\n+\n+  // 28 = 4 * (4 for collective + 1 for collective permute * 3)\n   EXPECT_EQ(profiles.entries().begin()->second.entries_size(), 16);\n }\n \n+TEST_F(CollectivePerfTableGenTest, FactorStepGeneratesConfigsForPermute) {\n+  cfg_.collective_types = {\n+      CollectivePerfTableGen::CollectiveType::COLLECTIVE_PERMUTE,\n+  };\n+  cfg_.replica_groups_list.emplace_back(\"[1,4]<=[4]\");\n+  CollectivePerfTableGen::StepSpec spec{\n+      /*start=*/4,\n+      /*stop=*/32,\n+      /*step=*/0,\n+      /*factor=*/2,\n+  };\n+  cfg_.tensor_size_bytes_spec = spec;\n+\n+  std::unique_ptr<CollectivePerfTableGen> gen =\n+      CollectivePerfTableGen::Create(cfg_);\n+\n+  DeviceHloInstructionProfiles profiles = gen->ComputeTable();\n+  for (const auto& value : profiles.entries().begin()->second.entries()) {\n+    LOG(INFO) << \"  value: \" << value.DebugString();\n+  }\n+  EXPECT_EQ(profiles.entries_size(), 1);\n+\n+  EXPECT_EQ(profiles.entries().begin()->second.entries_size(), 12);\n+}\n+\n TEST_F(CollectivePerfTableGenTest, HappyPathWorks) {\n   cfg_.collective_types = {\n       CollectivePerfTableGen::CollectiveType::ALL_REDUCE,\n@@ -125,5 +155,36 @@ TEST_F(CollectivePerfTableGenTest, HappyPathWorks) {\n                     Gt(0))));\n }\n \n+TEST_F(CollectivePerfTableGenTest, BuildSourceTargetPairsOneWay) {\n+  EXPECT_EQ(BuildSourceTargetPairs(\n+                CollectivePermuteCostModelType::kIntraPartitionOneWay, 4),\n+            \"{{0,2},{1,3}}\");\n+  EXPECT_EQ(BuildSourceTargetPairs(\n+                CollectivePermuteCostModelType::kIntraPartitionOneWay, 8),\n+            \"{{0,4},{1,5},{2,6},{3,7}}\");\n+}\n+\n+TEST_F(CollectivePerfTableGenTest, BuildSourceTargetPairsTwoWayAllMutual) {\n+  EXPECT_EQ(\n+      BuildSourceTargetPairs(\n+          CollectivePermuteCostModelType::kIntraPartitionTwoWayAllMutual, 4),\n+      \"{{0,1},{1,0},{2,3},{3,2}}\");\n+  EXPECT_EQ(\n+      BuildSourceTargetPairs(\n+          CollectivePermuteCostModelType::kIntraPartitionTwoWayAllMutual, 8),\n+      \"{{0,1},{1,0},{2,3},{3,2},{4,5},{5,4},{6,7},{7,6}}\");\n+}\n+\n+TEST_F(CollectivePerfTableGenTest, BuildSourceTargetPairsTwoWayHasNonMutual) {\n+  EXPECT_EQ(\n+      BuildSourceTargetPairs(\n+          CollectivePermuteCostModelType::kIntraPartitionTwoWayHasNonMutual, 4),\n+      \"{{0,1},{1,2},{2,3},{3,0}}\");\n+  EXPECT_EQ(\n+      BuildSourceTargetPairs(\n+          CollectivePermuteCostModelType::kIntraPartitionTwoWayHasNonMutual, 8),\n+      \"{{0,1},{1,2},{2,3},{3,4},{4,5},{5,6},{6,7},{7,0}}\");\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        }
    ],
    "stats": {
        "total": 267,
        "additions": 238,
        "deletions": 29
    }
}