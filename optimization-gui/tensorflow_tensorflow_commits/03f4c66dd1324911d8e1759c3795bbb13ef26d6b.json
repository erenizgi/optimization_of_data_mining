{
    "author": "GleasonK",
    "message": "[StableHLO Optim] Add CompareOp patterns and dont fold large converts.\n\nPiperOrigin-RevId: 825236477",
    "sha": "03f4c66dd1324911d8e1759c3795bbb13ef26d6b",
    "files": [
        {
            "sha": "c445b82e10ea63d580a5fab904cce8fdd0936736",
            "filename": "third_party/xla/third_party/stablehlo/temporary.patch",
            "status": "modified",
            "additions": 82,
            "deletions": 12,
            "changes": 94,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03f4c66dd1324911d8e1759c3795bbb13ef26d6b/third_party%2Fxla%2Fthird_party%2Fstablehlo%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03f4c66dd1324911d8e1759c3795bbb13ef26d6b/third_party%2Fxla%2Fthird_party%2Fstablehlo%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fstablehlo%2Ftemporary.patch?ref=03f4c66dd1324911d8e1759c3795bbb13ef26d6b",
            "patch": "@@ -248,12 +248,10 @@ diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.ml\n diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir b/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir\n --- stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir\n +++ stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir\n-@@ -132,6 +132,35 @@\n- \n-   // CHECK-NEXT: return [[R0]], [[R5]]\n+@@ -134,6 +134,35 @@\n    return %0, %5 : tensor<1x3x6xi32>, tensor<3x6x1xi32>\n-+}\n-+\n+ }\n+ \n +// CHECK-LABEL: func.func @broadcast_in_dim_prefer_nested_reshape\n +// CHECK-SAME:   ([[ARG0:%[^ ]+]]: tensor<3x4xi32>)\n +func.func @broadcast_in_dim_prefer_nested_reshape(%arg0: tensor<3x4xi32>) -> (tensor<2x3x4x3xi32>, tensor<2x3x4x3xi32>) {\n@@ -281,10 +279,31 @@ diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplific\n +\n +  // CHECK-DAG: return [[BROADCAST_OF_RESHAPE]], [[MERGED_BROADCAST]]\n +  return %1, %3 : tensor<2x3x4x3xi32>, tensor<2x3x4x3xi32>\n++}\n++\n+ // CHECK-LABEL: func.func @broadcast_in_dim_not_identity_broadcasts\n+ func.func @broadcast_in_dim_not_identity_broadcasts(%arg0: tensor<1x2xf32>) -> tensor<2x2xf32> {\n+   // CHECK: stablehlo.broadcast_in_dim\n+@@ -208,6 +237,18 @@\n+   // CHECK-NEXT: return [[C1]], [[C0]], [[C1]], [[C0]], [[R0]], [[R1]], [[R2]], [[R3]]\n+   return %0, %1, %2, %3, %4, %5, %6, %7 :\n+          tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>\n++}\n++\n++// CHECK-LABEL: func.func @compare_op_bool_simplify\n++// CHECK-SAME:   ([[ARG0:%.+]]: tensor<i1>)\n++func.func @compare_op_bool_simplify(%arg0: tensor<i1>) -> (tensor<i1>, tensor<i1>) {\n++  %false = stablehlo.constant dense<false> : tensor<i1>\n++  %true = stablehlo.constant dense<true> : tensor<i1>\n++  // CHECK-NOT: stablehlo.compare\n++  %0 = stablehlo.compare NE, %arg0, %false, UNSIGNED : (tensor<i1>, tensor<i1>) -> tensor<i1>\n++  %1 = stablehlo.compare EQ, %arg0, %true, UNSIGNED : (tensor<i1>, tensor<i1>) -> tensor<i1>\n++  // CHECK: return [[ARG0]], [[ARG0]]\n++  func.return %0, %1 : tensor<i1>, tensor<i1>\n  }\n  \n- // CHECK-LABEL: func.func @broadcast_in_dim_not_identity_broadcasts\n-@@ -1021,6 +1050,18 @@\n+ // -----\n+@@ -1021,6 +1062,18 @@\n    // CHECK-NOT: stablehlo.pad\n    %1 = stablehlo.pad %arg0, %0, low = [0, 0], high = [0, 0], interior = [0, 0] : (tensor<256x1024xbf16>, tensor<bf16>) -> tensor<256x1024xbf16>\n    return %1 : tensor<256x1024xbf16>\n@@ -303,7 +322,7 @@ diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplific\n  }\n  \n  // -----\n-@@ -1810,6 +1851,15 @@\n+@@ -1810,6 +1863,15 @@\n    return %0 : tensor<2x4x1x5xf32>\n  }\n  \n@@ -392,7 +411,17 @@ diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFold\n        return failure();\n  \n      SplatElementsAttr cstAttr;\n-@@ -1104,7 +1110,7 @@\n+@@ -825,7 +831,8 @@\n+     RankedTensorType resultType = op.getType();\n+ \n+     if (failed(validateStaticShapeResult(rewriter, op, resultType)) ||\n+-        failed(validateShapeFoldDtype(rewriter, op, resultType)))\n++        failed(validateShapeFoldDtype(rewriter, op, resultType)) ||\n++        failed(validateElementCountForFold(rewriter, op, resultType)))\n+       return failure();\n+ \n+     auto operandElemType = getElementTypeOrSelf(operand.getType());\n+@@ -1104,7 +1111,7 @@\n          failed(validateShapeFoldDtype(rewriter, op, resultType)))\n        return failure();\n  \n@@ -404,7 +433,7 @@ diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFold\n diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp\n --- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp\n +++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp\n-@@ -1309,6 +1309,17 @@\n+@@ -1309,10 +1309,20 @@\n  // TransposeOp\n  /////////////////////////////////\n  \n@@ -422,6 +451,10 @@ diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimp\n  // Pattern: transpose(X, [no_mem_layout_change...]) -> reshape(X)\n  struct TransposeIsReshape final : SimplifyOpRewritePattern<TransposeOp> {\n    using SimplifyOpRewritePattern::SimplifyOpRewritePattern;\n+-\n+   LogicalResult matchAndRewrite(TransposeOp op,\n+                                 PatternRewriter& rewriter) const override {\n+     auto input = op.getOperand();\n diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td\n --- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td\n +++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td\n@@ -488,7 +521,44 @@ diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimp\n  \n  // Pattern: broadcast_in_dim(X, [dims...]) -> transpose(X, [dims...])\n  //          [if same numel & rank]\n-@@ -424,9 +443,9 @@\n+@@ -197,6 +216,36 @@\n+   : Pat<(StableHLO_BroadcastInDimOp:$op $operand, $dims),\n+         (StableHLO_TransposeOp $operand, (InvertBroadcastDims $dims)),\n+         [(NumberOfElementsEqual $op, $operand), (RankEqual $op, $operand)]>;\n++\n++////////\n++// CompareOp\n++\n++// The canonical form has the constant operand as the RHS.\n++class StableHLO_ComparisonDirectionValue<string enumStr> :\n++  ConstantAttr<StableHLO_ComparisonDirectionAttr, \"::mlir::stablehlo::ComparisonDirection::\" # enumStr>;\n++\n++// Pattern: compare(NE, X, False) : i1 -> X\n++def CompareOp_NeBooleanFalse\n++  : Pat<(StableHLO_CompareOp\n++            $lhs,\n++            (StableHLO_ConstantOp:$cst IntZero:$value),\n++            StableHLO_ComparisonDirectionValue<\"NE\">,\n++            $type),\n++        (replaceWithValue $lhs),\n++        [(HLO_PredTensor $cst)]>;\n++\n++// Pattern: compare(EQ, X, True) : i1 -> X\n++def CompareOp_EqBooleanTrue\n++  : Pat<(StableHLO_CompareOp\n++            $lhs,\n++            (StableHLO_ConstantOp:$cst IntOne:$value),\n++            StableHLO_ComparisonDirectionValue<\"EQ\">,\n++            $type),\n++        (replaceWithValue $lhs),\n++        [(HLO_PredTensor $cst)]>;\n++\n++// TODO: compare(EQ, X, False) : i1 -> not(X)\n++// TODO: compare(NE, X, True) : i1 -> not(X)\n+ \n+ ////////\n+ // ConvertOp\n+@@ -424,9 +473,9 @@\n    : Pat<(StableHLO_PadOp:$pad\n              $operand,\n              $padding_value,\n@@ -501,7 +571,7 @@ diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimp\n          (replaceWithValue $operand),\n          [(TypesEqual $pad, $operand)]>;\n  \n-@@ -539,6 +558,12 @@\n+@@ -539,6 +588,12 @@\n    : Pat<(StableHLO_TransposeOp $lhs, IotaDims:$dims),\n          (replaceWithValue $lhs)>;\n  "
        }
    ],
    "stats": {
        "total": 94,
        "additions": 82,
        "deletions": 12
    }
}