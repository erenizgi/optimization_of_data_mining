{
    "author": "beckerhe",
    "message": "Refactor: Pass GpuComputeCapability to GetBlasComputationType\n\nThis change modifies `gpu::GetBlasComputationType` to accept a `GpuComputeCapability`. This allows the function to make platform-specific decisions, such as enabling TF32, without relying on preprocessor macros like `GOOGLE_CUDA`. Call sites are updated to pass the appropriate compute capability.\n\nPiperOrigin-RevId: 846617600",
    "sha": "458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e",
    "files": [
        {
            "sha": "751c5c75502d58f5b9782fcedabad30a86b2e897",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cublas.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc?ref=458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e",
            "patch": "@@ -104,7 +104,8 @@ CublasBackend::GetSupportedConfigs(const HloInstruction& instr) {\n       out_desc.compute_type,\n       se::gpu::GetBlasComputationType(\n           gemm_config.precision_algorithm, gemm_config.lhs_layout.dtype,\n-          gemm_config.output_layout.dtype, gemm_config.compute_precision));\n+          gemm_config.output_layout.dtype, gemm_config.compute_precision,\n+          target_config().device_description.gpu_compute_capability()));\n \n   se::blas::BlasSupport* blas = stream_executor()->AsBlas();\n   if (blas == nullptr) {"
        },
        {
            "sha": "a95d9dd9862b8af0d0a4c322cfa3320b1863e207",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e",
            "patch": "@@ -1121,15 +1121,15 @@ cc_library(\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/gpu:gpu_blas_lt\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n-        \"@local_tsl//tsl/platform:errors\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n "
        },
        {
            "sha": "464df1087303f3b1ccb5db82b47dad66299b9a46",
            "filename": "third_party/xla/xla/service/gpu/matmul_utils.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmatmul_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmatmul_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmatmul_utils.cc?ref=458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e",
            "patch": "@@ -31,7 +31,6 @@ limitations under the License.\n #include \"absl/strings/str_cat.h\"\n #include \"absl/types/span.h\"\n #include \"xla/autotuning.pb.h\"\n-#include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n@@ -50,11 +49,11 @@ limitations under the License.\n #include \"xla/stream_executor/gpu/gpu_blas_lt.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/types.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/errors.h\"\n-#include \"tsl/platform/statusor.h\"\n \n namespace xla {\n namespace gpu {\n@@ -479,7 +478,8 @@ bool IsTf32Allowed(PrecisionConfig::Algorithm algorithm,\n \n absl::StatusOr<GemmConfig::DescriptorsTuple> GemmConfig::GetMatrixDescriptors(\n     se::DeviceAddressBase lhs_buf, se::DeviceAddressBase rhs_buf,\n-    se::DeviceAddressBase out_buf) const {\n+    se::DeviceAddressBase out_buf,\n+    const se::GpuComputeCapability& gpu_version) const {\n   auto create_matrix_desc = [](const se::gpu::MatrixLayout& layout,\n                                se::DeviceAddressBase data)\n       -> absl::StatusOr<se::gpu::MatrixDescriptor> {\n@@ -512,7 +512,7 @@ absl::StatusOr<GemmConfig::DescriptorsTuple> GemmConfig::GetMatrixDescriptors(\n   TF_ASSIGN_OR_RETURN(out_desc.compute_type,\n                       se::gpu::GetBlasComputationType(\n                           PrecisionConfig::ALG_UNSET, lhs.dtype, out.dtype,\n-                          se::blas::kDefaultComputePrecision));\n+                          se::blas::kDefaultComputePrecision, gpu_version));\n \n   TF_ASSIGN_OR_RETURN(se::gpu::MatrixDescriptor lhs_desc,\n                       create_matrix_desc(lhs, lhs_buf));\n@@ -541,8 +541,9 @@ absl::Status DoGemmWithAlgorithm(const se::gpu::MatrixDescriptor& lhs,\n   PrimitiveType output_type = primitive_util::NativeToPrimitiveType<Output>();\n   TF_ASSIGN_OR_RETURN(\n       se::blas::ComputationType computation_type,\n-      se::gpu::GetBlasComputationType(precision_algorithm, lhs_type,\n-                                      output_type, compute_precision));\n+      se::gpu::GetBlasComputationType(\n+          precision_algorithm, lhs_type, output_type, compute_precision,\n+          stream->parent()->GetDeviceDescription().gpu_compute_capability()));\n   se::DeviceAddress<Output> output_data(output.data);\n \n   // Set a workspace for all Blas operations launched below.\n@@ -626,7 +627,9 @@ absl::Status RunGemm(const GemmConfig& config, se::DeviceAddressBase lhs_buffer,\n \n   TF_ASSIGN_OR_RETURN(\n       GemmConfig::DescriptorsTuple desc,\n-      config.GetMatrixDescriptors(lhs_buffer, rhs_buffer, output_buffer));\n+      config.GetMatrixDescriptors(\n+          lhs_buffer, rhs_buffer, output_buffer,\n+          stream->parent()->GetDeviceDescription().gpu_compute_capability()));\n \n   se::EngineOptions engine_options{\n       deterministic_ops,"
        },
        {
            "sha": "4c0a4de4dfdf9b44ee513f5cf6de6031fd750a0f",
            "filename": "third_party/xla/xla/service/gpu/matmul_utils.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmatmul_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmatmul_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmatmul_utils.h?ref=458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e",
            "patch": "@@ -35,6 +35,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/gpu/gpu_blas_lt.h\"\n+#include \"xla/stream_executor/stream.h\"\n #include \"xla/xla_data.pb.h\"\n \n namespace xla {\n@@ -146,7 +147,8 @@ struct GemmConfig : public se::gpu::GemmConfig {\n   };\n   absl::StatusOr<DescriptorsTuple> GetMatrixDescriptors(\n       se::DeviceAddressBase lhs_buf, se::DeviceAddressBase rhs_buf,\n-      se::DeviceAddressBase out_buf) const;\n+      se::DeviceAddressBase out_buf,\n+      const se::GpuComputeCapability& gpu_version) const;\n };\n \n // Run the given GEMM instruction `gemm` subject to the configuration"
        },
        {
            "sha": "e5ff188990e77881d9706f609963ebf5c43702f8",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_rewriter.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc?ref=458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e",
            "patch": "@@ -2095,7 +2095,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n         const se::blas::ComputationType compute_type,\n         se::gpu::GetBlasComputationType(\n             instr.precision_config().algorithm(), a_dtype, output_type,\n-            stream_executor::blas::kDefaultComputePrecision));\n+            stream_executor::blas::kDefaultComputePrecision, gpu_version_));\n     se::blas::DataType scale_type =\n         se::gpu::GetScaleType(output_dtype, compute_type);\n \n@@ -2193,10 +2193,10 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n       return false;\n     }\n \n-    TF_ASSIGN_OR_RETURN(\n-        const se::blas::ComputationType compute_type,\n-        se::gpu::GetBlasComputationType(\n-            algorithm, a_dtype, instr.shape().element_type(), max_precision));\n+    TF_ASSIGN_OR_RETURN(const se::blas::ComputationType compute_type,\n+                        se::gpu::GetBlasComputationType(\n+                            algorithm, a_dtype, instr.shape().element_type(),\n+                            max_precision, gpu_version_));\n     se::blas::DataType scale_type =\n         se::gpu::GetScaleType(output_dtype, compute_type);\n "
        },
        {
            "sha": "581abc2ca0966e87ae1890bce5e071011bf1e2e4",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_blas_lt.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_blas_lt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_blas_lt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_blas_lt.cc?ref=458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e",
            "patch": "@@ -318,10 +318,12 @@ auto BlasLt::GetMatmulPlan(const gpu::GemmConfig& cfg,\n \n   auto compute_type = cfg.compute_type;\n   if (!compute_type) {  // obtain compute_type unless provided by the user\n-    TF_ASSIGN_OR_RETURN(compute_type,\n-                        gpu::GetBlasComputationType(\n-                            cfg.precision_algorithm, lhs_layout.dtype,\n-                            output_layout.dtype, cfg.compute_precision));\n+    TF_ASSIGN_OR_RETURN(\n+        compute_type,\n+        gpu::GetBlasComputationType(\n+            cfg.precision_algorithm, lhs_layout.dtype, output_layout.dtype,\n+            cfg.compute_precision,\n+            parent_->GetDeviceDescription().gpu_compute_capability()));\n   }\n \n   // FP8 matmuls have a fast accumulation mode that is less precise than the"
        },
        {
            "sha": "707e8fbced5cded72e20b849101e1eb2c2396de9",
            "filename": "third_party/xla/xla/stream_executor/gpu/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD?ref=458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e",
            "patch": "@@ -409,7 +409,6 @@ cc_library(\n     name = \"gpu_blas_lt\",\n     srcs = [\"gpu_blas_lt.cc\"],\n     hdrs = [\"gpu_blas_lt.h\"],\n-    local_defines = if_cuda_is_configured([\"GOOGLE_CUDA=1\"]),\n     deps = [\n         \":gpu_blas_lt_proto_cc\",\n         \"//xla:shape_util\",\n@@ -420,8 +419,11 @@ cc_library(\n         \"//xla/service:algorithm_util\",\n         \"//xla/stream_executor:blas\",\n         \"//xla/stream_executor:device_address\",\n+        \"//xla/stream_executor:device_description\",\n+        \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor/cuda:cuda_platform_id\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/protobuf:dnn_proto_cc\",\n         \"@com_google_absl//absl/algorithm:container\",\n@@ -435,9 +437,8 @@ cc_library(\n         \"@com_google_absl//absl/synchronization\",\n         \"@com_google_absl//absl/types:span\",\n         \"@local_tsl//tsl/platform:statusor\",\n-    ] + if_cuda_is_configured([\n         \"@local_tsl//tsl/platform:tensor_float_32_hdr_lib\",\n-    ]) + if_static([\n+    ] + if_static([\n         \"@local_tsl//tsl/platform:tensor_float_32_utils\",\n     ]),\n )"
        },
        {
            "sha": "e024a9ddcb87e003cd31aea6ac2141e3caf73f27",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_blas_lt.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.cc?ref=458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e",
            "patch": "@@ -30,16 +30,15 @@ limitations under the License.\n #include \"xla/primitive_util.h\"\n #include \"xla/service/algorithm_util.h\"\n #include \"xla/stream_executor/blas.h\"\n+#include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/gpu/gpu_blas_lt.pb.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/protobuf/dnn.pb.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n-#if GOOGLE_CUDA\n #include \"tsl/platform/tensor_float_32_utils.h\"\n-#endif\n \n namespace stream_executor {\n \n@@ -205,7 +204,8 @@ xla::GemmConfigProto::MatrixLayout MatrixLayout::ToProto() const {\n \n absl::StatusOr<ComputationType> GetBlasComputationType(\n     xla::PrecisionConfig::Algorithm algorithm, xla::PrimitiveType lhs_dtype,\n-    xla::PrimitiveType output_dtype, int64_t compute_precision) {\n+    xla::PrimitiveType output_dtype, int64_t compute_precision,\n+    const GpuComputeCapability& cc) {\n   if (algorithm == xla::PrecisionConfig::ALG_UNSET) {\n     switch (output_dtype) {\n       case PrimitiveType::F8E5M2:      // fall-through\n@@ -222,14 +222,12 @@ absl::StatusOr<ComputationType> GetBlasComputationType(\n         return ComputationType::kF32;\n       case PrimitiveType::F32:  // fall-through\n       case PrimitiveType::C64:\n-#if GOOGLE_CUDA\n-        if (tsl::tensor_float_32_execution_enabled() &&\n+        if (cc.IsCuda() && tsl::tensor_float_32_execution_enabled() &&\n             compute_precision <= 1 && lhs_dtype == output_dtype) {\n           // CublasLt requires compute type to be F32 for F8 matmul.\n           // TF32 should only be chosen for FP32 or C64 gemm\n           return ComputationType::kTF32AsF32;\n         }\n-#endif\n         return ComputationType::kF32;\n       case PrimitiveType::F64:  // fall-through\n       case PrimitiveType::C128:"
        },
        {
            "sha": "963c28b3b9550deccedb21a5ecf3c5668ffa7ea8",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_blas_lt.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.h?ref=458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e",
            "patch": "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"absl/synchronization/mutex.h\"\n #include \"xla/stream_executor/blas.h\"\n #include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/gpu/gpu_blas_lt.pb.h\"\n #include \"xla/types.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -44,7 +45,8 @@ absl::StatusOr<xla::PrimitiveType> AsXlaPrimitiveType(blas::DataType dtype);\n \n absl::StatusOr<blas::ComputationType> GetBlasComputationType(\n     xla::PrecisionConfig::Algorithm algorithm, xla::PrimitiveType lhs_dtype,\n-    xla::PrimitiveType output_dtype, int64_t compute_precision);\n+    xla::PrimitiveType output_dtype, int64_t compute_precision,\n+    const GpuComputeCapability& cc);\n \n // Returns the type for the alpha and beta scalars.\n blas::DataType GetScaleType(blas::DataType c_type,"
        },
        {
            "sha": "ba22feb58ac6901413d7ea6009f78678f17c785c",
            "filename": "third_party/xla/xla/stream_executor/rocm/hip_blas_lt.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fhip_blas_lt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fhip_blas_lt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fhip_blas_lt.cc?ref=458fe6aa5a38bbd47e76c5e7328a2bdbfa009f1e",
            "patch": "@@ -33,7 +33,6 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/time/time.h\"\n-#include \"Eigen/Core\"\n #include \"rocm/include/hip/library_types.h\"\n #include \"rocm/include/hipblas/hipblas.h\"\n #include \"rocm/include/hipblaslt/hipblaslt.h\"\n@@ -55,7 +54,6 @@ limitations under the License.\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/types.h\"\n #include \"xla/util.h\"\n-#include \"tsl/platform/ml_dtypes.h\"\n \n #define SET_ATTR(setter, handle, attr, value) \\\n   ToStatus(setter(handle, attr, &value, sizeof(decltype(value))), #setter)\n@@ -326,10 +324,12 @@ auto BlasLt::GetMatmulPlan(const gpu::GemmConfig& cfg, Epilogue epilogue) const\n \n   auto compute_type = cfg.compute_type;\n   if (!compute_type) {  // obtain compute_type unless provided by the user\n-    TF_ASSIGN_OR_RETURN(compute_type,\n-                        gpu::GetBlasComputationType(\n-                            cfg.precision_algorithm, lhs_layout.dtype,\n-                            output_layout.dtype, cfg.compute_precision));\n+    TF_ASSIGN_OR_RETURN(\n+        compute_type,\n+        gpu::GetBlasComputationType(\n+            cfg.precision_algorithm, lhs_layout.dtype, output_layout.dtype,\n+            cfg.compute_precision,\n+            parent_->GetDeviceDescription().gpu_compute_capability()));\n   }\n \n   if (lhs_layout.order == gpu::MatrixLayout::Order::kRowMajor) {"
        }
    ],
    "stats": {
        "total": 83,
        "additions": 46,
        "deletions": 37
    }
}