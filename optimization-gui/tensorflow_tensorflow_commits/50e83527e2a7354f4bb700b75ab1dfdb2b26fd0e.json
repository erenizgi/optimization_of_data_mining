{
    "author": "zvikinoza",
    "message": "UnflattenCallGraph Pass for HLO Deduplication\n\n*  **Collect Calls:** Scans the module for all `kCall`ed computations.\n*  **Fingerprint & Hash:** For each computation, in parallel, generates 'highway hash'.\n*  **Identify Canonical:** For each hash value, the first computation encountered is selected as the canonical version.\n*  **Collision Validation:** To check for hash collisions a parallelized validation step compares all computations mapping to the same hash are identical.\n*  **Cleanup:** After re-routing calls, `HloModule::RemoveUnusedComputations` is invoked to clean the module of the now-unreferenced duplicate computation\n\nPiperOrigin-RevId: 800422802",
    "sha": "50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e",
    "files": [
        {
            "sha": "2714f33ed8e3ae8e862b5f2af0be1b9e4608cfc8",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/BUILD",
            "status": "modified",
            "additions": 43,
            "deletions": 0,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD?ref=50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e",
            "patch": "@@ -1705,3 +1705,46 @@ cc_library(\n         \"@local_tsl//tsl/platform:status\",\n     ],\n )\n+\n+cc_library(\n+    name = \"unflatten_call_graph\",\n+    srcs = [\"unflatten_call_graph.cc\"],\n+    hdrs = [\"unflatten_call_graph.h\"],\n+    deps = [\n+        \"//xla:util\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/pass:hlo_pass\",\n+        \"//xla/hlo/utils/concurrency:concurrency_utils\",\n+        \"//xla/hlo/utils/concurrency:tsl_task_executor\",\n+        \"//xla/service:call_graph\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@highwayhash\",\n+        \"@highwayhash//:arch_specific\",\n+        \"@highwayhash//:hh_types\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"unflatten_call_graph_test\",\n+    srcs = [\"unflatten_call_graph_test.cc\"],\n+    deps = [\n+        \":unflatten_call_graph\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/hlo/testlib:test\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)"
        },
        {
            "sha": "471c38efc0c499ef31bbfedb002a21ca630b27b5",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/unflatten_call_graph.cc",
            "status": "added",
            "additions": 204,
            "deletions": 0,
            "changes": 204,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Funflatten_call_graph.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Funflatten_call_graph.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Funflatten_call_graph.cc?ref=50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e",
            "patch": "@@ -0,0 +1,204 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/hlo/transforms/simplifiers/unflatten_call_graph.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"highwayhash/arch_specific.h\"\n+#include \"highwayhash/hh_types.h\"\n+#include \"highwayhash/highwayhash.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/utils/concurrency/concurrency_utils.h\"\n+#include \"xla/service/call_graph.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n+\n+namespace xla {\n+\n+namespace {\n+\n+// Struct to hold all call instructions and called computations in a module.\n+struct HloCalls {\n+  std::vector<HloInstruction*> call_sites;\n+  std::vector<HloComputation*> targets;\n+};\n+\n+// Iterates through all instructions in the module's computations\n+// and collects all `HloInstruction`s with opcode `kCall` into 'calls_sites'\n+// and all unique computations targeted by these calls into 'targets'.\n+HloCalls CollectHloCalls(\n+    HloModule* module,\n+    const absl::flat_hash_set<absl::string_view>& execution_threads) {\n+  std::unique_ptr<CallGraph> call_graph = CallGraph::Build(module);\n+  HloCalls calls;\n+  for (const CallGraphNode& node : call_graph->nodes()) {\n+    for (const CallSite& callsite : node.callsites()) {\n+      if (callsite.instruction()->opcode() == HloOpcode::kCall) {\n+        calls.call_sites.push_back(callsite.instruction());\n+        calls.targets.push_back(callsite.instruction()->to_apply());\n+      }\n+    }\n+  }\n+  return calls;\n+}\n+}  // namespace\n+\n+absl::StatusOr<std::vector<UnflattenCallGraph::ComputationHashResult>>\n+UnflattenCallGraph::HashComputations(\n+    const std::vector<HloComputation*>& called_computations) {\n+  auto hash_computation =\n+      [&](HloComputation* computation) -> ComputationHashResult {\n+    // Secret key used for hashing. Since we're not worried about attackers,\n+    // we can initialize to non-secret `openssl rand` generated values.\n+    static constexpr highwayhash::HHKey kHighwayHashKey = {\n+        0x787e1a69fdecd60b,\n+        0xe29d68c87b02eec8,\n+        0x0f6735946a0777ea,\n+        0x3444abc98410f39f,\n+    };\n+    highwayhash::HHStateT<HH_TARGET> state(kHighwayHashKey);\n+    std::string fingerprint = computation->ToString(print_options_);\n+    highwayhash::HHResult64 result;\n+    highwayhash::HighwayHashT(&state, fingerprint.data(), fingerprint.size(),\n+                              &result);\n+    return ComputationHashResult{\n+        result,\n+        std::move(fingerprint),\n+        computation,\n+    };\n+  };\n+\n+  // Hash all called computations in parallel.\n+  return (xla::concurrency::ForEach<ComputationHashResult>(\n+      called_computations.begin(), called_computations.end(), hash_computation,\n+      *task_executor_));\n+}\n+\n+absl::Status UnflattenCallGraph::ValidateComputationHashes(\n+    const std::vector<ComputationHashResult>& hash_results,\n+    const absl::flat_hash_map<uint64_t, const ComputationHashResult*>&\n+        hash_to_canonical) {\n+  auto validate_against_canonical = [&](const ComputationHashResult& result) {\n+    uint64_t candidate_hash = result.hash;\n+    const std::string& candidate_fingerprint = result.fingerprint;\n+    const std::string& canonical_fingerprint =\n+        hash_to_canonical.at(candidate_hash)->fingerprint;\n+\n+    if (candidate_fingerprint != canonical_fingerprint) {\n+      return absl::InternalError(\n+          absl::StrCat(\"Hash collision detected. Hash: \", candidate_hash, \"\\n\",\n+                       \"Hashes are equal but fingerprints are different.\\n\",\n+                       \"Computation 1:\\n\", candidate_fingerprint, \"\\n\",\n+                       \"Computation 2:\\n\", canonical_fingerprint, \"\\n\"));\n+    }\n+    return absl::OkStatus();\n+  };\n+\n+  // Validate all computations against their canonical versions in parallel.\n+  TF_RETURN_IF_ERROR(\n+      (xla::concurrency::ForEach(hash_results.begin(), hash_results.end(),\n+                                 validate_against_canonical, *task_executor_)));\n+\n+  return absl::OkStatus();\n+}\n+\n+absl::StatusOr<bool> UnflattenCallGraph::Run(\n+    HloModule* module,\n+    const absl::flat_hash_set<absl::string_view>& execution_threads) {\n+  VLOG(1) << \"Running UnflattenCallGraph on module \" << module->name();\n+\n+  XLA_SCOPED_LOGGING_TIMER_LEVEL(\n+      absl::StrCat(\"Ran UnflattenCallGraph on module: \", module->name()), 1);\n+\n+  // Find all call instructions and their unique computation targets\n+  const HloCalls calls = CollectHloCalls(module, execution_threads);\n+  if (calls.targets.empty()) {\n+    return false;\n+  }\n+  TF_ASSIGN_OR_RETURN(const std::vector<ComputationHashResult> hash_results,\n+                      HashComputations(calls.targets));\n+\n+  // Map computations to their hashes.\n+  // The HloComputation* keys are owned by the HloModule and are guaranteed to\n+  // be valid for the lifetime of this map.\n+  absl::flat_hash_map<HloComputation*, uint64_t> computation_to_hash;\n+  computation_to_hash.reserve(calls.targets.size());\n+  // Map each hash to the first computation encountered with that hash\n+  absl::flat_hash_map<uint64_t, const ComputationHashResult*> hash_to_canonical;\n+\n+  for (const ComputationHashResult& result : hash_results) {\n+    computation_to_hash[result.computation] = result.hash;\n+    hash_to_canonical.try_emplace(result.hash, &result);\n+  }\n+\n+  absl::Status validation_status =\n+      ValidateComputationHashes(hash_results, hash_to_canonical);\n+  if (!validation_status.ok()) {\n+    LOG(ERROR) << \"UnflattenCallGraph failed validation: \" << validation_status;\n+    return false;\n+  }\n+\n+  bool changed = false;\n+  // Lambda to find the canonical computation for a given computation.\n+  auto get_canonical_computation = [&](const HloComputation* original_called) {\n+    uint64_t hash = computation_to_hash.at(original_called);\n+    HloComputation* canonical_called = hash_to_canonical.at(hash)->computation;\n+\n+    if (original_called != canonical_called) {\n+      VLOG(1) << \"Replacing call to \" << original_called->name() << \" [\"\n+              << original_called << \"] with \" << canonical_called->name()\n+              << \" [\" << canonical_called << \"]\";\n+      changed = true;\n+    }\n+    return canonical_called;\n+  };\n+\n+  // Update all call sites to point to the canonical computations.\n+  for (HloInstruction* instruction : calls.call_sites) {\n+    instruction->ReplaceCalledComputations(get_canonical_computation);\n+  }\n+\n+  if (changed) {\n+    // Clean up any computations that are now no longer called.\n+    for (const ComputationHashResult& result : hash_results) {\n+      if (!hash_to_canonical.contains(result.hash)) {\n+        TF_RETURN_IF_ERROR(\n+            module->RemoveEmbeddedComputation(result.computation));\n+      }\n+    }\n+    TF_RETURN_IF_ERROR(module->RemoveUnusedComputations());\n+    module->CleanupComputations();\n+  }\n+\n+  return changed;\n+}\n+}  // namespace xla"
        },
        {
            "sha": "4111b4e8ccdce1ba85a0f16ad50ea9f78b92756a",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/unflatten_call_graph.h",
            "status": "added",
            "additions": 88,
            "deletions": 0,
            "changes": 88,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Funflatten_call_graph.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Funflatten_call_graph.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Funflatten_call_graph.h?ref=50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e",
            "patch": "@@ -0,0 +1,88 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_HLO_TRANSFORMS_SIMPLIFIERS_UNFLATTEN_CALL_GRAPH_H_\n+#define XLA_HLO_TRANSFORMS_SIMPLIFIERS_UNFLATTEN_CALL_GRAPH_H_\n+\n+#include <cstdint>\n+#include <memory>\n+#include <string>\n+#include <vector>\n+\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/ir/hlo_print_options.h\"\n+#include \"xla/hlo/pass/hlo_pass_interface.h\"\n+#include \"xla/hlo/utils/concurrency/tsl_task_executor.h\"\n+\n+namespace xla {\n+\n+// Unflatten a call graph. This pass will find called computations that are\n+// identical and replace them with calls to a single computation.\n+// Only computations called by kCall instructions will be unflattened.\n+class UnflattenCallGraph : public HloModulePass {\n+ public:\n+  UnflattenCallGraph()\n+      : print_options_(HloPrintOptions::Canonical()\n+                           .set_print_ids(false)\n+                           .set_print_metadata(true)\n+                           .set_print_backend_config(true)),\n+        task_executor_(std::make_unique<xla::concurrency::TslTaskExecutor>()) {}\n+\n+  absl::string_view name() const override { return \"unflatten-call-graph\"; }\n+\n+  // Find called computations that are identical and replace them with calls to\n+  // a single computation. Returns true if the module was changed.\n+  using HloPassInterface::Run;\n+  absl::StatusOr<bool> Run(\n+      HloModule* module,\n+      const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n+\n+ private:\n+  // Struct to hold the result of hashing a computation.\n+  struct ComputationHashResult {\n+    uint64_t hash;\n+    std::string fingerprint;\n+    HloComputation* computation;\n+  };\n+\n+  // Hashes computations to produce a fingerprint and hash value.\n+  // Uses canonical HLO text without IDs for stable, content-based hashing.\n+  absl::StatusOr<std::vector<ComputationHashResult>> HashComputations(\n+      const std::vector<HloComputation*>& called_computations);\n+\n+  // Verifies that computations with the same hash are identical to prevent\n+  // incorrect merging due to hash collisions, using progressively more\n+  // expensive checks.\n+  absl::Status ValidateComputationHashes(\n+      const std::vector<ComputationHashResult>& hash_results,\n+      const absl::flat_hash_map<uint64_t, const ComputationHashResult*>&\n+          hash_to_canonical);\n+\n+  HloPrintOptions print_options_;\n+  // Thread pool used for parallelizing computation hashing and collision\n+  // detection.\n+  std::unique_ptr<xla::concurrency::TslTaskExecutor> task_executor_;\n+};\n+\n+}  // namespace xla\n+\n+#endif  // XLA_HLO_TRANSFORMS_SIMPLIFIERS_UNFLATTEN_CALL_GRAPH_H_"
        },
        {
            "sha": "145d96e61fff9fa6ee41a168eb3c96270786db01",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/unflatten_call_graph_test.cc",
            "status": "added",
            "additions": 507,
            "deletions": 0,
            "changes": 507,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Funflatten_call_graph_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Funflatten_call_graph_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Funflatten_call_graph_test.cc?ref=50e83527e2a7354f4bb700b75ab1dfdb2b26fd0e",
            "patch": "@@ -0,0 +1,507 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/hlo/transforms/simplifiers/unflatten_call_graph.h\"\n+\n+#include <memory>\n+#include <string>\n+#include <vector>\n+\n+#include <gtest/gtest.h>\n+#include \"absl/algorithm/container.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/hlo/testlib/test.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla {\n+namespace {\n+\n+class UnflattenCallGraphTest : public HloHardwareIndependentTestBase {\n+ protected:\n+  absl::StatusOr<bool> RunUnflattenCallGraph(HloModule* module) {\n+    UnflattenCallGraph unflatten;\n+    return unflatten.Run(module);\n+  }\n+};\n+\n+// Tests that pass makes no changes when there are no duplicate computations.\n+// The graph is:\n+// main -> called_computation\n+TEST_F(UnflattenCallGraphTest, NoChange) {\n+  std::string hlo_string = R\"(\n+HloModule NoChange\n+\n+  %called_computation (param_0: f32[]) -> f32[] {\n+    ROOT %param_0 = f32[] parameter(0)\n+  }\n+\n+  ENTRY %main (a: f32[]) -> f32[] {\n+    %a = f32[] parameter(0)\n+    ROOT %call = f32[] call(%a), to_apply=%called_computation\n+  }\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  ASSERT_EQ(module->computation_count(), 2);\n+  TF_ASSERT_OK_AND_ASSIGN(bool result, RunUnflattenCallGraph(module.get()));\n+  EXPECT_FALSE(result);\n+  ASSERT_EQ(module->computation_count(), 2);\n+}\n+\n+// Tests that the pass merges simple duplicate computations.\n+// The initial graph is:\n+// main -> called_computation_1\n+//      -> called_computation_2\n+// where called_computation_1 and called_computation_2 are identical.\n+// The expected graph is:\n+// main -> called_computation_1\n+//      -> called_computation_1\n+TEST_F(UnflattenCallGraphTest, SimpleDuplicates) {\n+  std::string hlo_string =\n+      R\"(HloModule SimpleDuplicates, entry_computation_layout={(f32[])->(f32[], f32[])}\n+\n+  %called_computation_1 (param_0: f32[]) -> f32[] {\n+    ROOT %param_0 = f32[] parameter(0)\n+  }\n+\n+  %called_computation_2 (param_0: f32[]) -> f32[] {\n+    ROOT %param_0 = f32[] parameter(0)\n+  }\n+\n+  ENTRY %main (a: f32[], b: f32[]) -> (f32[], f32[]) {\n+    %a = f32[] parameter(0)\n+    %call1 = f32[] call(%a), to_apply=%called_computation_1\n+    %call2 = f32[] call(%a), to_apply=%called_computation_2\n+    ROOT %tuple = (f32[], f32[]) tuple(%call1, %call2)\n+  }\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  ASSERT_EQ(module->computation_count(), 3);\n+  TF_ASSERT_OK_AND_ASSIGN(bool result, RunUnflattenCallGraph(module.get()));\n+  EXPECT_TRUE(result);\n+  ASSERT_EQ(module->computation_count(), 2);\n+\n+  // Check that call1 and call2 now point to the same computation.\n+  auto call1 = FindInstruction(module.get(), \"call1\");\n+  auto call2 = FindInstruction(module.get(), \"call2\");\n+  EXPECT_EQ(call1->to_apply(), call2->to_apply());\n+\n+  // Check that one of the computations was removed.\n+  auto called_computation_1 =\n+      FindComputation(module.get(), \"called_computation_1\");\n+  auto called_computation_2 =\n+      FindComputation(module.get(), \"called_computation_2\");\n+  // Check that the only one computation is used and other is deleted\n+  ASSERT_NE(called_computation_1 == nullptr, called_computation_2 == nullptr);\n+}\n+\n+// Tests that the pass merges duplicate while loops that are nested in a call.\n+// including the body and condition computations.\n+// The initial graph is:\n+// main -> called_computation -> while_cond, while_body\n+//      -> called_computation.clone -> while_cond.clone, while_body.clone\n+// where called_computation is identical to called_computation.clone,\n+// while_cond to while_cond.clone, and while_body to while_body.clone.\n+// The expected graph is:\n+// main -> called_computation -> while_cond, while_body\n+//      -> called_computation -> while_cond, while_body\n+TEST_F(UnflattenCallGraphTest, DuplicatesInWhile) {\n+  std::string hlo_string = R\"(\n+HloModule WhileInCall, entry_computation_layout={(f32[4096]{0}, f32[4096]{0})->f32[4096]{0}}\n+\n+%while_body (p: (f32[4096])) -> (f32[4096]) {\n+  ROOT %p = (f32[4096]{0}) parameter(0)\n+}\n+\n+%while_cond (p.cond: (f32[4096])) -> pred[] {\n+  %p.cond = (f32[4096]{0}) parameter(0)\n+  ROOT %eq = pred[] constant(false)\n+}\n+\n+%called_computation (arg: f32[4096]) -> f32[4096] {\n+  %arg = f32[4096]{0} parameter(0)\n+  %while_init = (f32[4096]{0}) tuple(%arg)\n+  %while = (f32[4096]{0}) while(%while_init), condition=%while_cond, body=%while_body\n+  ROOT %get-tuple-element = f32[4096]{0} get-tuple-element(%while), index=0\n+}\n+\n+%while_body.clone (p.1: (f32[4096])) -> (f32[4096]) {\n+  ROOT %p.1 = (f32[4096]{0}) parameter(0)\n+}\n+\n+%while_cond.clone (p.cond.1: (f32[4096])) -> pred[] {\n+  %p.cond.1 = (f32[4096]{0}) parameter(0)\n+  ROOT %eq.1 = pred[] constant(false)\n+}\n+\n+%called_computation.clone (arg.1: f32[4096]) -> f32[4096] {\n+  %arg.1 = f32[4096]{0} parameter(0)\n+  %while_init.1 = (f32[4096]{0}) tuple(%arg.1)\n+  %while.1 = (f32[4096]{0}) while(%while_init.1), condition=%while_cond.clone, body=%while_body.clone\n+  ROOT %get-tuple-element.1 = f32[4096]{0} get-tuple-element(%while.1), index=0\n+}\n+\n+ENTRY %main (a: f32[4096], b: f32[4096]) -> f32[4096] {\n+  %a = f32[4096]{0} parameter(0)\n+  %call0 = f32[4096]{0} call(%a), to_apply=%called_computation\n+  %b = f32[4096]{0} parameter(1)\n+  %call1 = f32[4096]{0} call(%b), to_apply=%called_computation.clone\n+  ROOT %multiply = f32[4096]{0} multiply(%call0, %call1)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  ASSERT_EQ(module->computation_count(), 7);\n+  TF_ASSERT_OK_AND_ASSIGN(bool result, RunUnflattenCallGraph(module.get()));\n+  EXPECT_TRUE(result);\n+  ASSERT_EQ(module->computation_count(), 4);\n+\n+  // check that call0 and call1 now point to the same computation\n+  auto call0 = FindInstruction(module.get(), \"call0\");\n+  auto call1 = FindInstruction(module.get(), \"call1\");\n+  EXPECT_EQ(call0->to_apply(), call1->to_apply());\n+}\n+\n+// Tests that the pass handles multi-level nested calls with duplicates\n+// at different levels.\n+// Initial graph:\n+// Entry -> A.1 -> Scalar.1\n+//       |      -> Scalar.2\n+//       -> A.2 -> Scalar.3\n+//              -> Scalar.4\n+// All Scalar.X are identical to each other and A.1 is identical to A.2.\n+//\n+// Example of one of the expected graph:\n+// Entry -> A.1 -> Scalar.1\n+//       |      -> Scalar.1\n+//       -> A.1 -> Scalar.1\n+//              -> Scalar.1\n+TEST_F(UnflattenCallGraphTest, DuplicatedMultilevelNestedCalls) {\n+  std::string hlo_string = R\"(\n+HloModule NestedCalls, entry_computation_layout={(f32[])->f32[]}\n+\n+%Scalar.1 (param0: f32[]) -> f32[] {\n+  %param0 = f32[] parameter(0)\n+  ROOT %negate = f32[] negate(%param0)\n+}\n+\n+%Scalar.2 (param0.3: f32[]) -> f32[] {\n+  %param0.3 = f32[] parameter(0)\n+  ROOT %negate.1 = f32[] negate(%param0.3)\n+}\n+\n+%Scalar.3 (param0.5: f32[]) -> f32[] {\n+  %param0.5 = f32[] parameter(0)\n+  ROOT %negate.2 = f32[] negate(%param0.5)\n+}\n+\n+%Scalar.4 (param0.6: f32[]) -> f32[] {\n+  %param0.6 = f32[] parameter(0)\n+  ROOT %negate.3 = f32[] negate(%param0.6)\n+}\n+\n+%A.2 (param0.1: f32[]) -> f32[] {\n+  %param0.1 = f32[] parameter(0)\n+  %call = f32[] call(%param0.1), to_apply=%Scalar.3\n+  ROOT %call.1 = f32[] call(%call), to_apply=%Scalar.4\n+}\n+\n+%A.1 (param0.4: f32[]) -> f32[] {\n+  %param0.4 = f32[] parameter(0)\n+  %call.4 = f32[] call(%param0.4), to_apply=%Scalar.1\n+  ROOT %call.5 = f32[] call(%call.4), to_apply=%Scalar.2\n+}\n+\n+ENTRY %FlattenCalls.Entry (param0.2: f32[]) -> f32[] {\n+  %param0.2 = f32[] parameter(0)\n+  %call.2 = f32[] call(%param0.2), to_apply=%A.1\n+  ROOT %call.3 = f32[] call(%call.2), to_apply=%A.2\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  ASSERT_EQ(module->computation_count(), 7);\n+  TF_ASSERT_OK_AND_ASSIGN(bool result, RunUnflattenCallGraph(module.get()));\n+  EXPECT_TRUE(result);\n+  ASSERT_EQ(module->computation_count(), 3);\n+\n+  // Check that A.1 and A.2 are deduplicated.\n+  auto A1 = FindComputation(module.get(), \"A.1\");\n+  auto A2 = FindComputation(module.get(), \"A.2\");\n+  EXPECT_NE(A1 == nullptr, A2 == nullptr);\n+\n+  // Check that Scalar.X are deduplicated.\n+  std::vector<HloComputation*> deduped_computations = {\n+      FindComputation(module.get(), \"Scalar.1\"),\n+      FindComputation(module.get(), \"Scalar.2\"),\n+      FindComputation(module.get(), \"Scalar.3\"),\n+      FindComputation(module.get(), \"Scalar.4\")};\n+  EXPECT_EQ(absl::c_count(deduped_computations, nullptr), 3);\n+}\n+\n+// Tests that the pass handles multi-level nested calls with duplicates\n+// at different levels, where merging at a lower level enables further\n+// merging at higher levels.\n+//\n+// Initial graph structure:\n+// main -> A -> C -> E -> terminal\n+//      -> B -> D -> F -> terminal\n+//\n+// Duplicates:\n+// - E and F are identical (call terminal).\n+// - C and D become identical after E and F are merged\n+//       (add, then call the same computation).\n+// - A and B become identical after C and D are merged\n+//       (multiply, then call the same computation).\n+//\n+// The pass should first merge E and F. This makes C and D equivalent,\n+// so they are merged. Finally, this makes A and B equivalent, leading\n+// to their merge.\n+//\n+// Expected computation count reduction from 8 to 5.\n+TEST_F(UnflattenCallGraphTest, DuplicatedMultilevelNestedCalls2) {\n+  std::string hlo_string = R\"(\n+HloModule LinearChain, entry_computation_layout={(f32[])->f32[]}\n+\n+%terminal (param0: f32[]) -> f32[] {\n+  %param0 = f32[] parameter(0)\n+  ROOT %negate = f32[] negate(%param0)\n+}\n+\n+%F (param0: f32[]) -> f32[] {\n+  %Fparam0 = f32[] parameter(0)\n+  ROOT %Fterminal = f32[] call(%Fparam0), to_apply=%terminal\n+}\n+\n+%E (param0: f32[]) -> f32[] {\n+  %Eparam0 = f32[] parameter(0)\n+  ROOT %Eterminal = f32[] call(%Eparam0), to_apply=%terminal\n+}\n+\n+%D (param0: f32[]) -> f32[] {\n+  %Dparam0 = f32[] parameter(0)\n+  %Dadd = f32[] add(%Dparam0, %Dparam0)\n+  ROOT %call = f32[] call(%Dadd), to_apply=%F\n+}\n+\n+%C (param0: f32[]) -> f32[] {\n+  %Cparam = f32[] parameter(0)\n+  %Cadd = f32[] add(%Cparam, %Cparam)\n+  ROOT %call = f32[] call(%Cadd), to_apply=%E\n+}\n+\n+%B (param0: f32[]) -> f32[] {\n+  %notparam = f32[] parameter(0)\n+  %notmult = f32[] multiply(%notparam, %notparam)\n+  ROOT %call = f32[] call(%notmult), to_apply=%D\n+}\n+\n+%A (param0: f32[]) -> f32[] {\n+  %param0 = f32[] parameter(0)\n+  %mult = f32[] multiply(%param0, %param0)\n+  ROOT %call = f32[] call(%mult), to_apply=%C\n+}\n+\n+ENTRY %main (param0: f32[]) -> f32[] {\n+  %param0 = f32[] parameter(0)\n+  %call1 = f32[] call(%param0), to_apply=%A\n+  ROOT %call2 = f32[] call(%param0), to_apply=%B\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  ASSERT_EQ(module->computation_count(), 8);\n+  TF_ASSERT_OK_AND_ASSIGN(bool result, RunUnflattenCallGraph(module.get()));\n+\n+  EXPECT_TRUE(result);\n+  ASSERT_EQ(module->computation_count(), 5);\n+\n+  auto F = FindComputation(module.get(), \"F\");\n+  auto E = FindComputation(module.get(), \"E\");\n+  auto D = FindComputation(module.get(), \"D\");\n+  auto C = FindComputation(module.get(), \"C\");\n+  auto B = FindComputation(module.get(), \"B\");\n+  auto A = FindComputation(module.get(), \"A\");\n+\n+  // Check that following pairs are deduplicated (A and B, C and D, E and F)\n+  EXPECT_NE(A == nullptr, B == nullptr);\n+  EXPECT_NE(C == nullptr, D == nullptr);\n+  EXPECT_NE(E == nullptr, F == nullptr);\n+}\n+\n+// Tests that the pass merges duplicate computations even if the argument names\n+// in the computations are different.\n+// The initial graph is:\n+// main -> called_computation_1 (param_A)\n+//      -> called_computation_2 (param_B)\n+// where called_computation_1 and called_computation_2 are structurally\n+// identical but use different parameter names.\n+// The expected graph is:\n+// main -> called_computation_1 (param_A)\n+//      -> called_computation_1 (param_A)\n+TEST_F(UnflattenCallGraphTest, DifferentArgumentNames) {\n+  std::string hlo_string =\n+      R\"(HloModule DifferentArgumentNames, entry_computation_layout={(f32[])->(f32[], f32[])}\n+\n+  %called_computation_1 (param_A: f32[]) -> f32[] {\n+    ROOT %param_A = f32[] parameter(0)\n+  }\n+\n+  %called_computation_2 (param_B: f32[]) -> f32[] {\n+    ROOT %param_B = f32[] parameter(0)\n+  }\n+\n+  ENTRY %main (a: f32[], b: f32[]) -> (f32[], f32[]) {\n+    %a = f32[] parameter(0)\n+    %call1 = f32[] call(%a), to_apply=%called_computation_1\n+    %call2 = f32[] call(%a), to_apply=%called_computation_2\n+    ROOT %tuple = (f32[], f32[]) tuple(%call1, %call2)\n+  }\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  ASSERT_EQ(module->computation_count(), 3);\n+  TF_ASSERT_OK_AND_ASSIGN(bool result, RunUnflattenCallGraph(module.get()));\n+  EXPECT_TRUE(result);\n+  ASSERT_EQ(module->computation_count(), 2);\n+\n+  // Check that call1 and call2 now point to the same computation.\n+  auto call1 = FindInstruction(module.get(), \"call1\");\n+  auto call2 = FindInstruction(module.get(), \"call2\");\n+  EXPECT_EQ(call1->to_apply(), call2->to_apply());\n+\n+  // Check that one of the computations was removed.\n+  auto called_computation_1 =\n+      FindComputation(module.get(), \"called_computation_1\");\n+  auto called_computation_2 =\n+      FindComputation(module.get(), \"called_computation_2\");\n+  ASSERT_NE(called_computation_1 == nullptr, called_computation_2 == nullptr);\n+}\n+\n+// Tests that pass does not deduplicate conditional computations.\n+// The initial graph should not be changed.\n+TEST_F(UnflattenCallGraphTest, DontDeDuplicateInConditional) {\n+  std::string hlo_string = R\"(\n+HloModule DuplicatesInConditional\n+\n+  %branch_1 (param_0: f32[]) -> f32[] {\n+    ROOT %param_0 = f32[] parameter(0)\n+  }\n+\n+  %branch_2 (param_0: f32[]) -> f32[] {\n+    ROOT %param_0 = f32[] parameter(0)\n+  }\n+\n+  ENTRY %main (pred: pred[], a: f32[]) -> f32[] {\n+    %pred_0 = pred[] parameter(0)\n+    %a = f32[] parameter(1)\n+    ROOT %conditional = f32[] conditional(%pred_0, %a, %a), true_computation=%branch_1, false_computation=%branch_2\n+  }\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  ASSERT_EQ(module->computation_count(), 3);\n+  TF_ASSERT_OK_AND_ASSIGN(bool result, RunUnflattenCallGraph(module.get()));\n+  // No change expected.\n+  EXPECT_FALSE(result);\n+}\n+\n+// Test that the pass only deduplicates computations that are only kCalled.\n+// The initial graph is:\n+// main -> called_computation_1 (kCalled)\n+//      -> if pred { called_computation_1 } (kControlFlow)\n+//      -> else { called_computation_2 } (kControlFlow)\n+//      -> called_computation_2 (kCalled)\n+//      -> called_computation_1 (kMap)\n+//      -> called_computation_2 (kMap)\n+// The expected graph should change kCalled called_computation_1 and\n+// called_computation_2 to the same computation, but not kControlFlow or kMap.\n+// main -> called_computation_1 (kCalled)\n+//      -> if pred { called_computation_1 } (kControlFlow)\n+//      -> else { called_computation_2 }  (kControlFlow)\n+//      -> called_computation_1 (kCalled)\n+//      -> called_computation_1 (kMap)\n+//      -> called_computation_2 (kMap)\n+TEST_F(UnflattenCallGraphTest, OnlyDeduplicateCalledComputations) {\n+  std::string hlo_string = R\"(\n+HloModule OnlyDeduplicateCalledComputations\n+\n+  %called_computation_1 (param_0: f32[]) -> f32[] {\n+    ROOT %param_0 = f32[] parameter(0)\n+  }\n+\n+  %called_computation_2 (param_0: f32[]) -> f32[] {\n+    ROOT %param_0 = f32[] parameter(0)\n+  }\n+\n+  ENTRY %main (pred: pred[], a: f32[]) -> (f32[], f32[]) {\n+    %pred_0 = pred[] parameter(0)\n+    %a = f32[] parameter(1)\n+    %call1 = f32[] call(%a), to_apply=%called_computation_1\n+    %conditional = f32[] conditional(%pred_0, %a, %call1), true_computation=%called_computation_1, false_computation=%called_computation_2\n+    %call2 = f32[] call(%a), to_apply=%called_computation_2\n+    %map1 = f32[] map(%a), to_apply=%called_computation_1\n+    %map2 = f32[] map(%a), to_apply=%called_computation_2\n+    ROOT %tuple = (f32[], f32[]) tuple(%conditional, %map1)\n+  }\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  ASSERT_EQ(module->computation_count(), 3);\n+  TF_ASSERT_OK_AND_ASSIGN(bool result, RunUnflattenCallGraph(module.get()));\n+  EXPECT_TRUE(result);\n+\n+  // Check that computations did not get removed.\n+  auto called_computation_1 =\n+      FindComputation(module.get(), \"called_computation_1\");\n+  auto called_computation_2 =\n+      FindComputation(module.get(), \"called_computation_2\");\n+\n+  EXPECT_TRUE(called_computation_1 != nullptr);\n+  EXPECT_TRUE(called_computation_2 != nullptr);\n+\n+  // %call1 and %call2's called_computation be deduplicated.\n+  // They should be calling the  same computation.\n+  auto call1 = FindInstruction(module.get(), \"call1\");\n+  auto call2 = FindInstruction(module.get(), \"call2\");\n+  EXPECT_EQ(call2->to_apply(), call1->to_apply());\n+\n+  // Conditional should be unchanged and calling the same computations.\n+  auto conditional = FindInstruction(module.get(), \"conditional\");\n+  auto true_computation = conditional->called_computations()[0];\n+  auto false_computation = conditional->called_computations()[1];\n+  EXPECT_EQ(true_computation, called_computation_1);\n+  EXPECT_EQ(false_computation, called_computation_2);\n+\n+  // %map1 and %map2 should be calling the same computations.\n+  auto map1 = FindInstruction(module.get(), \"map1\");\n+  EXPECT_EQ(map1->to_apply(), called_computation_1);\n+  auto map2 = FindInstruction(module.get(), \"map2\");\n+  EXPECT_EQ(map2->to_apply(), called_computation_2);\n+}\n+\n+}  // namespace\n+}  // namespace xla"
        }
    ],
    "stats": {
        "total": 842,
        "additions": 842,
        "deletions": 0
    }
}