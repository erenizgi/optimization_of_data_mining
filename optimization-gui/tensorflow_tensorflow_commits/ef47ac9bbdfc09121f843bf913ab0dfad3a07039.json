{
    "author": "sergachev",
    "message": "PR #30864: [GPU] Disable priority and multi-output fusion of bitwidth-changing bitcasts.\n\nImported from GitHub PR https://github.com/openxla/xla/pull/30864\n\nThese better stay outside fusions to remain truly no-ops - inside fusions they can affect indexing and result in suboptimal access patterns.\nCopybara import of the project:\n\n--\ne122d603d332db00c26f00cf89368e4242016338 by Ilia Sergachev <isergachev@nvidia.com>:\n\n[GPU] Disable priority and multi-output fusion of bitwidth-changing bitcasts.\n\nThese better stay outside fusions to remain truly no-ops - inside\nfusions they can affect indexing and result in suboptimal access\npatterns.\n\nMerging this change closes #30864\n\nPiperOrigin-RevId: 803492821",
    "sha": "ef47ac9bbdfc09121f843bf913ab0dfad3a07039",
    "files": [
        {
            "sha": "b731d194f7b838d7f85411cda7d76c0d5505881c",
            "filename": "third_party/xla/xla/hlo/ir/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD?ref=ef47ac9bbdfc09121f843bf913ab0dfad3a07039",
            "patch": "@@ -291,8 +291,10 @@ cc_library(\n     hdrs = [\"hlo_instruction_utils.h\"],\n     deps = [\n         \":hlo\",\n+        \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/strings\",\n     ],\n )"
        },
        {
            "sha": "842e1540767920ca4fdd70752e5713ff3e78728b",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction_utils.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_utils.cc?ref=ef47ac9bbdfc09121f843bf913ab0dfad3a07039",
            "patch": "@@ -21,10 +21,12 @@ limitations under the License.\n #include <vector>\n \n #include \"absl/algorithm/container.h\"\n+#include \"absl/log/check.h\"\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_join.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/primitive_util.h\"\n #include \"xla/xla_data.pb.h\"\n \n namespace xla {\n@@ -37,6 +39,17 @@ bool IsUnstridedSlice(const HloInstruction* hlo) {\n                         [](int64_t stride) { return stride == 1; });\n }\n \n+bool KeepsBitwidth(const HloInstruction& hlo) {\n+  CHECK(hlo.shape().IsArray());\n+  if (absl::c_any_of(hlo.operands(), [&](const HloInstruction* operand) {\n+        return primitive_util::BitWidth(operand->shape().element_type()) !=\n+               primitive_util::BitWidth(hlo.shape().element_type());\n+      })) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n using Interval = std::pair<int64_t, int64_t>;\n void AddOrUpdateVectorOfPairsAsAttribute(HloInstruction* instr,\n                                          std::string attr_name,"
        },
        {
            "sha": "c4cd55784778c111708c674c7fd17c3757e0adee",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction_utils.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_utils.h?ref=ef47ac9bbdfc09121f843bf913ab0dfad3a07039",
            "patch": "@@ -29,6 +29,9 @@ namespace hlo_instruction_utils {\n // all dimensions.\n bool IsUnstridedSlice(const HloInstruction* hlo);\n \n+// Checks that all instruction operands have the same bitwidth as its output.\n+bool KeepsBitwidth(const HloInstruction&);\n+\n // Adds or updates the attributes for an instruction. If the attribute is\n // already present, then it is overwritten. Otherwise, this is added as another\n // attribute."
        },
        {
            "sha": "fb7fc571ee2dd3da237b1dc7535493185f7daeff",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction_utils_test.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 0,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_utils_test.cc?ref=ef47ac9bbdfc09121f843bf913ab0dfad3a07039",
            "patch": "@@ -56,6 +56,20 @@ TEST_F(HloInstructionUtilsTest, TestIsUnstridedSlice) {\n   EXPECT_FALSE(IsUnstridedSlice(strided_slice));\n }\n \n+TEST_F(HloInstructionUtilsTest, KeepsBitwidth) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> m,\n+                          ParseAndReturnVerifiedModule(R\"(\n+e {\n+  a = s8[2] parameter(0)\n+  b = s16[] bitcast(a)\n+  c = s16[] add(b, b)\n+})\"));\n+  const HloInstruction& root = *m->entry_computation()->root_instruction();\n+  EXPECT_TRUE(KeepsBitwidth(root));\n+  EXPECT_FALSE(KeepsBitwidth(*root.operand(0)));\n+  EXPECT_TRUE(KeepsBitwidth(*root.operand(0)->operand(0)));\n+}\n+\n TEST_F(HloInstructionUtilsTest, TestAddOrUpdateVectorOfPairsAsAttribute) {\n   const char* hlo = R\"(\n     HloModule test"
        },
        {
            "sha": "585b31ccaeb2a9003bcdcf04174b19f3658a4199",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=ef47ac9bbdfc09121f843bf913ab0dfad3a07039",
            "patch": "@@ -2578,6 +2578,7 @@ cc_library(\n         \"//xla:util\",\n         \"//xla/hlo/analysis:hlo_dataflow_analysis\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/ir:hlo_instruction_utils\",\n         \"//xla/hlo/utils:hlo_traversal\",\n         \"//xla/service:instruction_fusion\",\n         \"//xla/stream_executor:device_description\","
        },
        {
            "sha": "0c07533c3469e40b69c376f6ec81f7c42185e63c",
            "filename": "third_party/xla/xla/service/gpu/gpu_fusible.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 12,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_fusible.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_fusible.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_fusible.cc?ref=ef47ac9bbdfc09121f843bf913ab0dfad3a07039",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"xla/hlo/analysis/hlo_dataflow_analysis.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instruction_utils.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/utils/hlo_traversal.h\"\n #include \"xla/permutation_util.h\"\n@@ -391,6 +392,7 @@ bool IsUniversallyLoopFusible(const HloInstruction& instr) {\n       return instr.fusion_kind() == HloInstruction::FusionKind::kLoop;\n \n     case HloOpcode::kBitcast:\n+      return hlo_instruction_utils::KeepsBitwidth(instr);\n     case HloOpcode::kBroadcast:\n     case HloOpcode::kConcatenate:\n     case HloOpcode::kDynamicSlice:\n@@ -425,18 +427,6 @@ bool IsLoopFusibleAsProducer(const HloInstruction& instr) {\n   }\n }\n \n-static bool AllSatisfy(const HloInstruction& instr,\n-                       const HloPredicate& predicate) {\n-  if (instr.opcode() != HloOpcode::kFusion) {\n-    return predicate(&instr);\n-  }\n-\n-  return absl::c_all_of(\n-      instr.fused_instructions(), [&](const HloInstruction* i) {\n-        return i->opcode() == HloOpcode::kParameter || predicate(i);\n-      });\n-}\n-\n FusionDecision CanEmitInputFusedScatter(const HloInstruction& producer,\n                                         const HloInstruction& consumer) {\n   if (IsInputFusibleScatter(producer)) {"
        },
        {
            "sha": "c9c4c85b7af1017c4f2025cd61ddabb16b1fef50",
            "filename": "third_party/xla/xla/service/gpu/gpu_fusible_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_fusible_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_fusible_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_fusible_test.cc?ref=ef47ac9bbdfc09121f843bf913ab0dfad3a07039",
            "patch": "@@ -1281,6 +1281,17 @@ TEST_F(GpuFusibleTest, ProducerConsumerFusionInPlaceOperation) {\n   EXPECT_TRUE(ShapesCompatibleForMultiOutputFusion(*dus, *transpose));\n }\n \n+TEST_F(GpuFusibleTest, BitwidthChangingBitcastIsNotFusible) {\n+  auto module = ParseAndReturnVerifiedModule(R\"(\n+e {\n+  a = s32[7,2]{1,0} parameter(0)\n+  b = s16[7]{0} bitcast(a)\n+})\")\n+                    .value();\n+  EXPECT_FALSE(IsProducerMultiOutputFusible(\n+      *module->entry_computation()->root_instruction()));\n+}\n+\n TEST_F(GpuFusibleTest, ChooseFusionKind) {\n   auto module = ParseAndReturnVerifiedModule(R\"(\n HloModule module"
        },
        {
            "sha": "b336093d04e619606d994fdfc08b8b438494d004",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=ef47ac9bbdfc09121f843bf913ab0dfad3a07039",
            "patch": "@@ -2111,6 +2111,7 @@ cc_library(\n         \"//xla/backends/gpu/codegen/triton:support\",\n         \"//xla/hlo/analysis:hlo_dfs_reachability\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/ir:hlo_instruction_utils\",\n         \"//xla/hlo/pass:hlo_pass\",\n         \"//xla/hlo/utils:hlo_traversal\",\n         \"//xla/service:dump\","
        },
        {
            "sha": "b52ad2d5721377e2676fbec83020dfc8c675ee1d",
            "filename": "third_party/xla/xla/service/gpu/transforms/priority_fusion.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc?ref=ef47ac9bbdfc09121f843bf913ab0dfad3a07039",
            "patch": "@@ -46,6 +46,7 @@ limitations under the License.\n #include \"xla/hlo/analysis/hlo_dfs_reachability.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instruction_utils.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/ir/hlo_print_options.h\"\n #include \"xla/hlo/utils/hlo_traversal.h\"\n@@ -97,11 +98,12 @@ bool IsFusible(const HloInstruction& instr) {\n     case HloOpcode::kFusion:\n       return IsGenericTritonFusion(instr) ||\n              instr.fusion_kind() != HloInstruction::FusionKind::kCustom;\n+    case HloOpcode::kBitcast:\n+      return hlo_instruction_utils::KeepsBitwidth(instr);\n     case HloOpcode::kCopy:\n     case HloOpcode::kIota:\n     case HloOpcode::kConstant:\n     case HloOpcode::kReduce:\n-    case HloOpcode::kBitcast:\n     case HloOpcode::kBroadcast:\n     case HloOpcode::kConcatenate:\n     case HloOpcode::kDynamicSlice:"
        },
        {
            "sha": "f5d3b21d6f804286b172af708c34da876158a05a",
            "filename": "third_party/xla/xla/service/gpu/transforms/priority_fusion_test.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 0,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ef47ac9bbdfc09121f843bf913ab0dfad3a07039/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion_test.cc?ref=ef47ac9bbdfc09121f843bf913ab0dfad3a07039",
            "patch": "@@ -213,6 +213,20 @@ CHECK-NEXT: ROOT %{{.*}} = (f32[512]{0}, s32[512]{0}) tuple(%[[FUSION_F32]], %[[\n   )\");\n }\n \n+TEST_F(PriorityFusionTest, DoNotFuseBitWidthChangingBitcast) {\n+  EXPECT_TRUE(RunAndCheckHloRewrite(R\"(\n+e {\n+  a = s8[3,5,2]{2,1,0} parameter(0)\n+  n = s8[3,5,2]{2,1,0} negate(a)\n+  b = s16[3,5]{1,0} bitcast(n)\n+  m = s16[3,5]{1,0} multiply(b, b)\n+})\",\n+                                    std::move(priority_fusion_),\n+                                    /*expect_change=*/false)\n+                  .status()\n+                  .ok());\n+}\n+\n TEST_F(PriorityFusionTest, FuseConvertIntoReduce) {\n   absl::string_view kHlo = R\"(\n     HloModule test_module"
        }
    ],
    "stats": {
        "total": 77,
        "additions": 64,
        "deletions": 13
    }
}