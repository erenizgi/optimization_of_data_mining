{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Add multimem setup.\n\nPiperOrigin-RevId: 826391581",
    "sha": "d6d4e0224853aeea664a2e669247b5fe58c22c09",
    "files": [
        {
            "sha": "00503e46024338270694616fa277f14893a533ce",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=d6d4e0224853aeea664a2e669247b5fe58c22c09",
            "patch": "@@ -1251,6 +1251,7 @@ cc_library(\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/gpu:all_reduce_kernel\",\n         \"//xla/stream_executor/gpu:collective_kernel_metadata\",\n+        \"//xla/stream_executor/gpu:gpu_executor_header\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n@@ -1270,6 +1271,11 @@ cc_library(\n xla_test(\n     name = \"collective_kernel_thunk_test\",\n     srcs = [\"collective_kernel_thunk_test.cc\"],\n+    backend_tags = {\n+        \"gpu\": [\n+            \"multi_gpu\",\n+        ],\n+    },\n     backends = [\"h100\"],\n     deps = [\n         \":collective_kernel_thunk\",\n@@ -1278,6 +1284,7 @@ xla_test(\n         \"//xla:array\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/pjrt:worker_thread\",\n         \"//xla/runtime:device_id\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:collective_ops_utils\",\n@@ -1291,11 +1298,16 @@ xla_test(\n         \"//xla/stream_executor:platform_manager\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor/gpu:gpu_init\",\n+        \"//xla/tsl/concurrency:future\",\n         \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:env\",\n+        \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/synchronization\",\n         \"@com_google_absl//absl/types:span\",\n         \"@com_google_googletest//:gtest_main\",\n     ],"
        },
        {
            "sha": "53e8cef8b4d5168cb2d894de312a0aff44b3d94c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk.cc",
            "status": "modified",
            "additions": 75,
            "deletions": 18,
            "changes": 93,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc?ref=d6d4e0224853aeea664a2e669247b5fe58c22c09",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.*/\n #include \"xla/backends/gpu/runtime/collective_kernel_thunk.h\"\n \n #include <cstdint>\n+#include <cstring>\n #include <memory>\n #include <optional>\n #include <string>\n@@ -45,6 +46,7 @@ limitations under the License.*/\n #include \"xla/stream_executor/device_memory_handle.h\"\n #include \"xla/stream_executor/gpu/all_reduce_kernel.h\"\n #include \"xla/stream_executor/gpu/collective_kernel_metadata.h\"\n+#include \"xla/stream_executor/gpu/gpu_executor.h\"\n #include \"xla/stream_executor/kernel.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -85,10 +87,15 @@ absl::StatusOr<se::DeviceMemoryHandle> AllocateMemory(\n   return local_buffer_alloc;\n };\n \n-AllReduceStrategy GetAllReduceStrategy(int64_t input_size_bytes) {\n-  return input_size_bytes > kMaxOneShotAllReduceSizeBytes\n-             ? AllReduceStrategy::kTwoShot\n-             : AllReduceStrategy::kOneShot;\n+AllReduceStrategy GetAllReduceStrategy(int64_t input_size_bytes,\n+                                       bool is_multimem_enabled) {\n+  if (input_size_bytes > kMaxOneShotAllReduceSizeBytes) {\n+    return AllReduceStrategy::kTwoShot;\n+  }\n+  if (is_multimem_enabled) {\n+    return AllReduceStrategy::kMultimem;\n+  }\n+  return AllReduceStrategy::kOneShot;\n }\n \n int64_t GetMaxSupportedAllReduceSizeBytes(AllReduceStrategy strategy) {\n@@ -118,7 +125,8 @@ absl::StatusOr<bool> CollectiveKernelThunk::IsSupported(\n \n   const int64_t num_elements = buffers_[0].element_count;\n   const int64_t input_size_bytes = GetInputSizeBytes();\n-  const AllReduceStrategy strategy = GetAllReduceStrategy(input_size_bytes);\n+  const AllReduceStrategy strategy =\n+      GetAllReduceStrategy(input_size_bytes, is_multimem_enabled_);\n   // Custom all-reduce strategy is only supported for small inputs.\n   if (input_size_bytes > GetMaxSupportedAllReduceSizeBytes(strategy)) {\n     return false;\n@@ -162,8 +170,8 @@ struct BaseRangePtrRendezvousValue {\n };\n \n absl::Status CollectiveKernelThunk::ExchangeStateMetadata(\n-    const GpuCliqueKey& clique_key, StreamState& state,\n-    const InitializeParams& params) {\n+    const GpuCliqueKey& clique_key, const InitializeParams& params,\n+    StreamState& state) {\n   BaseRangePtrRendezvousValue rendezvous_value;\n   const std::optional<RankId> rank =\n       clique_key.rank(params.collective_params->global_device_id);\n@@ -191,8 +199,7 @@ absl::Status CollectiveKernelThunk::ExchangeStateMetadata(\n   TF_ASSIGN_OR_RETURN(std::shared_ptr<std::vector<BaseRangePtrRendezvousValue>>\n                           rendezvous_values,\n                       Rendezvous<std::vector<BaseRangePtrRendezvousValue>>(\n-                          /*name=*/\n-                          start_rendezvous_key, /*key=*/clique_key,\n+                          /*name=*/start_rendezvous_key, /*key=*/clique_key,\n                           /*value=*/rendezvous_value, /*num_threads=*/num_ranks,\n                           rendezvous_fn));\n \n@@ -204,12 +211,11 @@ absl::Status CollectiveKernelThunk::ExchangeStateMetadata(\n   CollectiveKernelMetadata metadata;\n   metadata.rank = rank.value().value();\n   for (int i = 0; i < rendezvous_values->size(); ++i) {\n-    metadata.buffer_root_ptrs[i] =\n-        (uint64_t)rendezvous_values->at(i).buffer_ptr.opaque();\n+    metadata.buffer_root_ptrs[i] = reinterpret_cast<uint64_t>(\n+        rendezvous_values->at(i).buffer_ptr.opaque());\n   }\n-\n-  // TODO(patrios): Add multicast setup.\n-  metadata.multicast_buffer_ptr = 0;\n+  metadata.multicast_buffer_ptr =\n+      reinterpret_cast<uint64_t>(state.multicast_device_ptr);\n \n   se::DeviceMemoryBase metadata_ptr =\n       params.executor->Allocate(sizeof(CollectiveKernelMetadata), 0);\n@@ -221,6 +227,51 @@ absl::Status CollectiveKernelThunk::ExchangeStateMetadata(\n   return absl::OkStatus();\n }\n \n+absl::Status Barrier(int device_number, const GpuCliqueKey& clique_key) {\n+  std::string start_rendezvous_key = absl::StrFormat(\n+      \"Barrier for device %d, \"\n+      \"clique %s\",\n+      device_number, clique_key.ToString());\n+  return Rendezvous(\n+      /*name=*/\n+      start_rendezvous_key, /*key=*/clique_key,\n+      /*num_threads=*/clique_key.num_local_participants());\n+}\n+\n+absl::Status CollectiveKernelThunk::SetupMultimem(\n+    const GpuCliqueKey& clique_key, const se::StreamExecutor* stream_executor,\n+    StreamState& state) {\n+  const stream_executor::gpu::GpuExecutor* gpu_executor =\n+      dynamic_cast<const stream_executor::gpu::GpuExecutor*>(stream_executor);\n+  if (gpu_executor == nullptr) {\n+    return absl::UnimplementedError(\"Multicast is not supported on device.\");\n+  }\n+\n+  size_t data_size = buffers_[0].source_buffer.size();\n+  int device_number = gpu_executor->device_ordinal();\n+\n+  if (device_number == 0) {\n+    TF_ASSIGN_OR_RETURN(multicast_memory_,\n+                        gpu_executor->CreateMulticastMemory(\n+                            data_size, clique_key.num_local_participants()));\n+  }\n+\n+  // Wait for all devices to create the multicast object.\n+  TF_RETURN_IF_ERROR(Barrier(device_number, clique_key));\n+\n+  // Add current devices to the multicast object.\n+  TF_RETURN_IF_ERROR(multicast_memory_->SubscribeDevice(device_number));\n+\n+  // Wait for all devices to register the multicast object.\n+  TF_RETURN_IF_ERROR(Barrier(device_number, clique_key));\n+\n+  TF_ASSIGN_OR_RETURN(\n+      state.multicast_device_ptr,\n+      multicast_memory_->MapMemory(state.local_buffer.memory(), gpu_executor));\n+\n+  return absl::OkStatus();\n+}\n+\n absl::Status CollectiveKernelThunk::Initialize(const InitializeParams& params) {\n   TF_ASSIGN_OR_RETURN(\n       const GpuCliqueKey clique_key,\n@@ -231,9 +282,10 @@ absl::Status CollectiveKernelThunk::Initialize(const InitializeParams& params) {\n   TF_RET_CHECK(rank.has_value())\n       << \"Device \" << params.collective_params->global_device_id\n       << \"is not in the clique.\";\n+  const AllReduceStrategy strategy =\n+      GetAllReduceStrategy(GetInputSizeBytes(), is_multimem_enabled_);\n   const LaunchDimensions launch_dimensions = AllReduceLaunchDimensions(\n-      buffers_[0].element_count, clique_key.num_local_participants(),\n-      GetAllReduceStrategy(GetInputSizeBytes()));\n+      buffers_[0].element_count, clique_key.num_local_participants(), strategy);\n \n   StreamState* state = nullptr;\n   {\n@@ -297,7 +349,11 @@ absl::Status CollectiveKernelThunk::Initialize(const InitializeParams& params) {\n   }\n \n   if (state != nullptr) {\n-    TF_RETURN_IF_ERROR(ExchangeStateMetadata(clique_key, *state, params));\n+    if (strategy == AllReduceStrategy::kMultimem) {\n+      se::StreamExecutor* stream_executor = params.executor;\n+      TF_RETURN_IF_ERROR(SetupMultimem(clique_key, stream_executor, *state));\n+    }\n+    TF_RETURN_IF_ERROR(ExchangeStateMetadata(clique_key, params, *state));\n   }\n \n   return absl::OkStatus();\n@@ -345,7 +401,8 @@ absl::Status CollectiveKernelThunk::ExecuteOnStream(\n   }\n \n   const uint32_t buffer_index = state->invocation_count % kNumBuffers;\n-  auto const strategy = GetAllReduceStrategy(GetInputSizeBytes());\n+  const AllReduceStrategy strategy =\n+      GetAllReduceStrategy(GetInputSizeBytes(), is_multimem_enabled_);\n   const LaunchDimensions launch_dimensions =\n       AllReduceLaunchDimensions(buffer.element_count, num_devices, strategy);\n   // In case of two-shot we want to increment in multiples of 2."
        },
        {
            "sha": "48567fedd8df3fe17a25b141a52450da108270fc",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk.h",
            "status": "modified",
            "additions": 19,
            "deletions": 4,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.h?ref=d6d4e0224853aeea664a2e669247b5fe58c22c09",
            "patch": "@@ -36,6 +36,7 @@ limitations under the License.*/\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_handle.h\"\n #include \"xla/stream_executor/gpu/all_reduce_kernel.h\"\n+#include \"xla/stream_executor/gpu/gpu_executor.h\"\n #include \"xla/stream_executor/kernel.h\"\n #include \"xla/stream_executor/stream.h\"\n \n@@ -60,14 +61,16 @@ class CollectiveKernelThunk : public Thunk {\n                         ReductionKind reduction_kind, bool is_async,\n                         absl::Span<const CollectiveThunk::Buffer> buffers,\n                         bool is_collective_kernel_enabled,\n-                        absl::string_view kernel_name = \"\")\n+                        absl::string_view kernel_name = \"\",\n+                        bool is_multimem_enabled = false)\n       : Thunk{Thunk::kCollectiveKernel, info},\n         collective_kernel_enabled_(is_collective_kernel_enabled),\n         is_async_(is_async),\n         collective_config_(std::move(collective_config)),\n         reduction_kind_(reduction_kind),\n         kernel_name_(kernel_name),\n-        buffers_(buffers) {\n+        buffers_(buffers),\n+        is_multimem_enabled_(is_multimem_enabled) {\n     per_stream_state_.reserve(kMaxNumExecutors);\n   }\n \n@@ -118,6 +121,8 @@ class CollectiveKernelThunk : public Thunk {\n     std::unique_ptr<se::Kernel> kernel;\n     uint32_t invocation_count = 0;\n \n+    void* multicast_device_ptr = nullptr;\n+\n     // Constructor to make OSS builds happy.\n     StreamState() = default;\n     StreamState(int device_ordinal_arg, RankId rank_arg,\n@@ -135,8 +140,15 @@ class CollectiveKernelThunk : public Thunk {\n   // Internal method to sync thread after Initialize.\n   // Returns the collective kernel metadata for the given clique key.\n   absl::Status ExchangeStateMetadata(const GpuCliqueKey& clique_key,\n-                                     StreamState& state,\n-                                     const InitializeParams& params);\n+                                     const InitializeParams& params,\n+                                     StreamState& state);\n+\n+  // Initializes and multimem memory. Each thunk participant should call this\n+  // method once. Multimem should be setup before usage when multimem strategy\n+  // is selected.\n+  absl::Status SetupMultimem(const GpuCliqueKey& clique_key,\n+                             const se::StreamExecutor* stream_executor,\n+                             StreamState& state);\n \n   // Whether the one-shot kernel is enabled.\n   const bool collective_kernel_enabled_;\n@@ -152,11 +164,14 @@ class CollectiveKernelThunk : public Thunk {\n   // Reference to the buffer related information required for the collective.\n   absl::Span<const CollectiveThunk::Buffer> buffers_;\n \n+  std::unique_ptr<stream_executor::gpu::GpuExecutor::MulticastMemory>\n+      multicast_memory_;\n   // Guard access to the stream state across different threads (which control\n   // different streams).\n   absl::Mutex mutex_;\n   absl::flat_hash_map<se::StreamExecutor*, std::unique_ptr<StreamState>>\n       per_stream_state_ ABSL_GUARDED_BY(mutex_);\n+  const bool is_multimem_enabled_;\n };\n }  // namespace xla::gpu\n "
        },
        {
            "sha": "afab4b10dcb3c4cd7f7a5fa70edf33daefd3c3ed",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk_test.cc",
            "status": "modified",
            "additions": 174,
            "deletions": 105,
            "changes": 279,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc?ref=d6d4e0224853aeea664a2e669247b5fe58c22c09",
            "patch": "@@ -26,8 +26,6 @@ limitations under the License.\n #include \"absl/log/log.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n-#include \"absl/types/span.h\"\n-#include \"xla/array.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/runtime/device_id.h\"\n@@ -37,14 +35,18 @@ limitations under the License.\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/gpu/gpu_constants.h\"\n #include \"xla/service/gpu/gpu_executable_run_options.h\"\n-#include \"xla/service/platform_util.h\"\n #include \"xla/service/service_executable_run_options.h\"\n #include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/gpu/gpu_init.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n+#include \"xla/tsl/platform/env.h\"\n+#include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/threadpool.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n \n@@ -132,136 +134,203 @@ static constexpr absl::string_view kKernelSource = R\"(\n   }\n )\";\n \n-absl::StatusOr<se::StreamExecutor*> GpuExecutor(int32_t device_ordinal) {\n-  TF_ASSIGN_OR_RETURN(auto name, PlatformUtil::CanonicalPlatformName(\"gpu\"));\n-  TF_ASSIGN_OR_RETURN(auto* platform,\n-                      se::PlatformManager::PlatformWithName(name));\n-  return platform->ExecutorForDevice(device_ordinal);\n+se::StreamExecutor* GetGpuExecutor(int64_t device_ordinal) {\n+  auto* platform =\n+      se::PlatformManager::PlatformWithName(se::GpuPlatformName()).value();\n+  return platform->ExecutorForDevice(device_ordinal).value();\n }\n \n-TEST(CollectiveKernelThunkTest, ExecutesPtxKernel) {\n-  using DataT = int64_t;\n-  static constexpr int64_t kNumElements = 128;\n-  static constexpr int64_t kInputSizeBytes = kNumElements * sizeof(DataT);\n-  static constexpr uint32_t kExpectedSignalValue = 1;\n+struct CollectiveKernelThunkMetadata {\n+  BufferAllocation buffer_allocation;\n+  std::unique_ptr<CollectiveKernelThunk> thunk;\n+  int64_t total_buffer_size;\n+  int64_t input_data_size_bytes;\n+  int64_t aligned_input_size_bytes;\n+  int64_t num_devices;\n+  std::vector<CollectiveThunk::Buffer> buffers;\n+};\n \n-  // --------------------\n-  // Arrange\n-  // --------------------\n-  // # Prepare input data and expected output data.\n-  Array<DataT> input_data({/*num_elements=*/kNumElements});\n-  input_data.FillRandom(5, 5, /*seed=*/12345);\n-  Array<DataT> expected_output_data({/*num_elements=*/kNumElements});\n-  expected_output_data.Each([&](absl::Span<const int64_t> indices, DataT* val) {\n-    *val = input_data(indices) + kExpectedSignalValue;\n-  });\n-  // # Prepare Infrastructure.\n-  TF_ASSERT_OK_AND_ASSIGN(se::StreamExecutor * executor0, GpuExecutor(0));\n-  Thunk::ThunkInfo thunk_info;\n-  thunk_info.profile_annotation = kProfileName;\n+CollectiveKernelThunkMetadata CreateCollectiveKernelThunk(\n+    int num_devices, int num_elements, bool is_multimem_enabled) {\n+  const int64_t input_size_bytes = num_elements * sizeof(uint64_t);\n   ReplicaGroup replica_group;\n-  replica_group.add_replica_ids(0);\n+\n+  for (int device_number = 0; device_number < num_devices; ++device_number) {\n+    replica_group.add_replica_ids(device_number);\n+  }\n+\n   CollectiveConfig collective_config{\n       /*operand_count=*/1,\n       /*operand_element_type=*/{PrimitiveType::F32},\n-      /* replica_groups=*/{replica_group},\n-      /* collective_op_kind=*/RendezvousKey::CollectiveOpKind::kCrossReplica,\n-      /* op_id=*/0,\n-      /* group_mode=*/\n+      /*replica_groups=*/{replica_group},\n+      /*collective_op_kind=*/\n+      RendezvousKey::CollectiveOpKind::kCrossReplica,\n+      /*op_id=*/0,\n+      /*group_mode=*/\n       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA,\n-      /* use_symmetric_buffer=*/false};\n+      /*use_symmetric_buffer=*/false};\n   const int64_t aligned_input_size_bytes =\n-      xla::RoundUpTo<uint64_t>(kInputSizeBytes, kXlaAllocatedBufferAlignBytes);\n-  // 2x because we have two buffers, one for input and one for output so we can\n-  // test output independently of input.\n+      xla::RoundUpTo<uint64_t>(input_size_bytes, kXlaAllocatedBufferAlignBytes);\n+  // 2x because we have two buffers, one for input and one for output so we\n+  // can test output independently of input.\n   const int64_t total_buffer_size = aligned_input_size_bytes * 2;\n-  // ## Create physical buffers.\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<se::Stream> stream,\n-                          executor0->CreateStream());\n-  std::vector<se::DeviceMemoryBase> allocated_buffers = {\n-      executor0->AllocateArray<DataT>(total_buffer_size)};\n-  std::vector<se::DeviceMemoryBase> input_buffers = {\n-      allocated_buffers[0].GetByteSlice(0, aligned_input_size_bytes)};\n-  std::vector<se::DeviceMemoryBase> output_buffers = {\n-      allocated_buffers[0].GetByteSlice(aligned_input_size_bytes,\n-                                        aligned_input_size_bytes)};\n-  BufferAllocations buffer_allocations(\n-      /*buffers=*/allocated_buffers,\n-      /*device_ordinal=*/0,\n-      /*memory_allocator=*/nullptr);\n-  TF_ASSERT_OK(\n-      stream->Memcpy(&input_buffers[0], input_data.data(), kInputSizeBytes));\n+  CollectiveKernelThunkMetadata result{\n+      BufferAllocation(/*index=*/0, /*size=*/total_buffer_size, /*color=*/0)};\n+  BufferAllocation::Slice input_slice(&result.buffer_allocation, /*offset=*/0,\n+                                      /*size=*/aligned_input_size_bytes);\n+  BufferAllocation::Slice output_slice(&result.buffer_allocation,\n+                                       aligned_input_size_bytes,\n+                                       aligned_input_size_bytes);\n+  result.buffers = {{/*element_count=*/num_elements,\n+                     /*source_buffer=*/input_slice,\n+                     /*destination_buffer=*/output_slice,\n+                     /*source_memory_space=*/0,\n+                     /*destination_memory_space=*/0}};\n+  Thunk::ThunkInfo thunk_info;\n+  thunk_info.profile_annotation = kProfileName;\n+  result.thunk = std::make_unique<CollectiveKernelThunk>(\n+      std::move(thunk_info), collective_config, ReductionKind::SUM,\n+      /*is_async=*/false, result.buffers,\n+      /*is_collective_kernel_enabled=*/true,\n+      /*kernel_name=*/kKernelName,\n+      /*is_multimem_enabled=*/is_multimem_enabled);\n+  result.total_buffer_size = total_buffer_size;\n+  result.num_devices = num_devices;\n+  result.aligned_input_size_bytes = aligned_input_size_bytes;\n+  result.input_data_size_bytes = input_size_bytes;\n+  return result;\n+}\n \n-  // ## Create Logical Buffers.\n+absl::StatusOr<se::DeviceMemoryBase> RunCollectiveKernelThunk(\n+    CollectiveKernelThunkMetadata& metadata, se::StreamExecutor* executor,\n+    std::vector<uint64_t> input_data) {\n   BufferAllocation buffer_allocation(\n-      /*index=*/0, /*size=*/total_buffer_size, /*color=*/0);\n-  BufferAllocation::Slice input_slice(&buffer_allocation, /*offset=*/0,\n-                                      /*size=*/aligned_input_size_bytes);\n-  BufferAllocation::Slice output_slice(\n-      &buffer_allocation, aligned_input_size_bytes, aligned_input_size_bytes);\n-  std::vector<CollectiveThunk::Buffer> buffers = {\n-      {/*element_count=*/kNumElements,\n-       /*source_buffer=*/input_slice,\n-       /*destination_buffer=*/output_slice,\n-       /*source_memory_space=*/0,\n-       /*destination_memory_space=*/0}};\n-\n-  // ## Setup device mapping.\n-  DeviceAssignment device_assignment(/*replica_count=*/1,\n-                                     /*computation_count=*/1);\n-  device_assignment(0, 0) = 0;\n+      /*index=*/0, /*size=*/metadata.total_buffer_size, /*color=*/0);\n   GpuExecutableRunOptions gpu_options;\n   gpu_options.set_gpu_global_device_ids(\n-      std::map{std::make_pair(0, GlobalDeviceId(0))});\n+      std::map{std::make_pair(0, GlobalDeviceId(0)),\n+               std::make_pair(1, GlobalDeviceId(1))});\n+\n+  TF_ASSIGN_OR_RETURN(auto stream, executor->CreateStream());\n   ServiceExecutableRunOptions run_options;\n   run_options.mutable_run_options()->set_stream(stream.get());\n+  DeviceAssignment device_assignment(/*replica_count=*/metadata.num_devices,\n+                                     /*computation_count=*/1);\n+\n+  for (int i = 0; i < metadata.num_devices; ++i) {\n+    device_assignment(i, 0) = i;\n+  }\n+\n   run_options.mutable_run_options()->set_device_assignment(&device_assignment);\n   run_options.mutable_run_options()->set_gpu_executable_run_options(\n       &gpu_options);\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto collective_params,\n-      Thunk::CollectiveExecuteParams::Create(run_options, /*async_streams=*/{},\n-                                             /*local_device_ordinal=*/0));\n-  // --------------------\n-  // Act\n-  // --------------------\n-  CollectiveKernelThunk thunk(std::move(thunk_info), collective_config,\n-                              ReductionKind::SUM,\n-                              /*is_async=*/false, buffers,\n-                              /*is_collective_kernel_enabled=*/true,\n-                              /*kernel_name=*/kKernelName);\n-\n-  // # Thunk::Initialize\n+\n+  TF_ASSIGN_OR_RETURN(auto collective_params,\n+                      Thunk::CollectiveExecuteParams::Create(\n+                          run_options, /*async_streams=*/{},\n+                          /*local_device_ordinal=*/executor->device_ordinal()));\n+  std::vector<se::DeviceMemoryBase> allocated_buffers = {\n+      executor->AllocateArray<uint64_t>(metadata.total_buffer_size)};\n+\n+  se::DeviceMemoryBase input_buffer =\n+      allocated_buffers[0].GetByteSlice(0, metadata.aligned_input_size_bytes);\n+  se::DeviceMemoryBase output_buffer = allocated_buffers[0].GetByteSlice(\n+      metadata.aligned_input_size_bytes, metadata.aligned_input_size_bytes);\n+  BufferAllocations buffer_allocations(\n+      /*buffers=*/allocated_buffers,\n+      /*device_ordinal=*/executor->device_ordinal(),\n+      /*memory_allocator=*/nullptr);\n+\n+  if (!input_data.empty()) {\n+    VLOG(3) << \"Copying input data to the device\";\n+    TF_RETURN_IF_ERROR(stream->Memcpy(&input_buffer, input_data.data(),\n+                                      metadata.input_data_size_bytes));\n+    TF_RETURN_IF_ERROR(stream->BlockHostUntilDone());\n+  }\n+\n   Thunk::InitializeParams initialize_params;\n-  initialize_params.executor = executor0;\n+  initialize_params.executor = executor;\n   initialize_params.stream = stream.get();\n   initialize_params.buffer_allocations = &buffer_allocations;\n   initialize_params.collective_params = &collective_params;\n   initialize_params.src = {kKernelSource};\n-  TF_ASSERT_OK(thunk.Initialize(initialize_params));\n-\n-  // # Thunk::Execute\n-  auto execute_params =\n-      Thunk::ExecuteParams::Create(run_options,                              //\n-                                   buffer_allocations,                       //\n-                                   stream.get(),                             //\n-                                   /*command_buffer_trace_stream=*/nullptr,  //\n-                                   &collective_params,                       //\n-                                   /*collective_cliques=*/nullptr            //\n-      );\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(execute_params));\n-\n-  // --------------------\n-  // Assert\n-  // --------------------\n-  Array<DataT> output_data({kNumElements});\n-  TF_ASSERT_OK(\n-      stream->Memcpy(output_data.data(), output_buffers[0], kInputSizeBytes));\n+  TF_RETURN_IF_ERROR(metadata.thunk->Initialize(initialize_params));\n+\n+  auto execute_params = Thunk::ExecuteParams::Create(\n+      run_options, buffer_allocations, stream.get(),\n+      /*command_buffer_trace_stream=*/nullptr, &collective_params,\n+      /*collective_cliques=*/nullptr);\n+  TF_RETURN_IF_ERROR(metadata.thunk->ExecuteOnStream(execute_params));\n+  return output_buffer;\n+}\n+\n+std::vector<absl::StatusOr<se::DeviceMemoryBase>>\n+RunCollectiveKernelThunkOnDevices(CollectiveKernelThunkMetadata& metadata) {\n+  tsl::thread::ThreadPool thread_pool(tsl::Env::Default(), \"device_threads\",\n+                                      metadata.num_devices);\n+  std::vector<tsl::Future<se::DeviceMemoryBase>> futures;\n+  for (int device_number = 0; device_number < metadata.num_devices;\n+       ++device_number) {\n+    futures.push_back(tsl::Future<se::DeviceMemoryBase>::MakeOn(\n+        *thread_pool.AsExecutor(), [&metadata, device_number] {\n+          return RunCollectiveKernelThunk(metadata,\n+                                          GetGpuExecutor(device_number), {});\n+        }));\n+  }\n+\n+  std::vector<absl::StatusOr<se::DeviceMemoryBase>> results;\n+  for (auto& future : futures) {\n+    results.push_back(std::move(future).Await());\n+  }\n+  return results;\n+}\n+\n+TEST(CollectiveKernelThunkTest, ExecutesPtxKernel) {\n+  static constexpr int64_t kNumElements = 128;\n+  static constexpr uint32_t kExpectedSignalValue = 1;\n+\n+  std::vector<uint64_t> input_data(kNumElements);\n+  for (int i = 0; i < kNumElements; ++i) {\n+    input_data[i] = i;\n+  }\n+\n+  std::vector<uint64_t> expected_output_data(kNumElements);\n+  for (int i = 0; i < kNumElements; ++i) {\n+    expected_output_data[i] = input_data[i] + kExpectedSignalValue;\n+  }\n+\n+  CollectiveKernelThunkMetadata metadata = CreateCollectiveKernelThunk(\n+      /*num_devices=*/1, /*num_elements=*/kNumElements,\n+      /*is_multimem_enabled=*/false);\n+\n+  se::StreamExecutor* executor0 = GetGpuExecutor(0);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      se::DeviceMemoryBase result_buffer,\n+      RunCollectiveKernelThunk(metadata, executor0, input_data));\n+\n+  std::vector<uint64_t> output_data(kNumElements);\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, executor0->CreateStream());\n+  TF_ASSERT_OK(stream->Memcpy(output_data.data(), result_buffer,\n+                              metadata.input_data_size_bytes));\n+  TF_ASSERT_OK(stream->BlockHostUntilDone());\n   for (auto i = 0; i < kNumElements; ++i) {\n-    ASSERT_EQ(expected_output_data(i), output_data(i))\n+    ASSERT_EQ(expected_output_data[i], output_data[i])\n         << \"comparison failed at i = \" << i;\n   }\n }\n \n+TEST(CollectiveKernelThunkTest, MultimemSetupTest) {\n+  static constexpr int kDevicesCount = 2;\n+  static constexpr int64_t kNumElements = 128;\n+\n+  CollectiveKernelThunkMetadata metadata = CreateCollectiveKernelThunk(\n+      /*num_devices=*/kDevicesCount, /*num_elements=*/kNumElements,\n+      /*is_multimem_enabled=*/true);\n+  for (absl::StatusOr<se::DeviceMemoryBase> result :\n+       RunCollectiveKernelThunkOnDevices(metadata)) {\n+    TF_ASSERT_OK(result);\n+  }\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "9b1c6d58d50e60dbfa746c60e6579210d50a7f02",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 7,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc?ref=d6d4e0224853aeea664a2e669247b5fe58c22c09",
            "patch": "@@ -742,7 +742,7 @@ static CUdeviceptr AsCudaDevicePtr(DeviceMemoryBase* gpu_mem) {\n }\n \n absl::StatusOr<DeviceMemoryBase> CudaExecutor::GetMemoryRange(\n-    const DeviceMemoryBase& location) {\n+    const DeviceMemoryBase& location) const {\n   CUdeviceptr device_pointer;\n   size_t size;\n   TF_RETURN_IF_ERROR(cuda::ToStatus(\n@@ -795,7 +795,7 @@ CudaExecutor::VmmMemoryHandle& CudaExecutor::VmmMemoryHandle::operator=(\n }\n \n absl::StatusOr<CudaExecutor::VmmMemoryHandle>\n-CudaExecutor::RetainVmmMemoryHandle(void* ptr) {\n+CudaExecutor::RetainVmmMemoryHandle(void* ptr) const {\n   if (!is_vmm_supported_) {\n     return absl::InternalError(\"VMM is not supported on this device.\");\n   }\n@@ -1808,7 +1808,7 @@ absl::StatusOr<TensorMap> CudaExecutor::CreateTensorMap(\n }\n \n absl::StatusOr<std::unique_ptr<GpuExecutor::MulticastMemory>>\n-CudaExecutor::CreateMulticastMemory(uint64_t size, int num_devices) {\n+CudaExecutor::CreateMulticastMemory(uint64_t size, int num_devices) const {\n   if (!is_multicast_supported_) {\n     return absl::FailedPreconditionError(\n         \"Multicast memory is not supported on this platform.\");\n@@ -1846,8 +1846,9 @@ CudaExecutor::CudaMulticastMemory::~CudaMulticastMemory() {\n }\n \n absl::Status CudaExecutor::CudaMulticastMemory::Initialize(\n-    uint64_t size, int num_devices, GpuExecutor* gpu_executor) {\n-  CudaExecutor* cuda_executor = dynamic_cast<CudaExecutor*>(gpu_executor);\n+    uint64_t size, int num_devices, const GpuExecutor* gpu_executor) {\n+  const CudaExecutor* cuda_executor =\n+      dynamic_cast<const CudaExecutor*>(gpu_executor);\n   if (cuda_executor == nullptr) {\n     return absl::InvalidArgumentError(\"GpuExecutor is not a CudaExecutor.\");\n   }\n@@ -1902,8 +1903,9 @@ absl::Status CudaExecutor::CudaMulticastMemory::SubscribeDevice(\n }\n \n absl::StatusOr<void*> CudaExecutor::CudaMulticastMemory::MapMemory(\n-    const DeviceMemoryBase& location, GpuExecutor* gpu_executor) {\n-  CudaExecutor* cuda_executor = dynamic_cast<CudaExecutor*>(gpu_executor);\n+    const DeviceMemoryBase& location, const GpuExecutor* gpu_executor) {\n+  const CudaExecutor* cuda_executor =\n+      dynamic_cast<const CudaExecutor*>(gpu_executor);\n   if (cuda_executor == nullptr) {\n     return absl::InvalidArgumentError(\"GpuExecutor is not a CudaExecutor.\");\n   }"
        },
        {
            "sha": "af50e08f25ecfda7e22d23aee0609171d9c00188",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.h",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h?ref=d6d4e0224853aeea664a2e669247b5fe58c22c09",
            "patch": "@@ -67,8 +67,7 @@ class CudaExecutor : public GpuExecutor {\n   absl::Status Init() override;\n   bool SynchronizeAllActivity() override;\n   absl::StatusOr<DeviceMemoryBase> GetMemoryRange(\n-      const DeviceMemoryBase& location) override;\n-\n+      const DeviceMemoryBase& location) const override;\n   absl::StatusOr<std::unique_ptr<EventBasedTimer>> CreateEventBasedTimer(\n       Stream* stream, bool use_delay_kernel) override;\n   absl::StatusOr<DeviceMemoryBase> GetSymbol(\n@@ -174,12 +173,12 @@ class CudaExecutor : public GpuExecutor {\n     absl::Status SubscribeDevice(int device_number) override;\n \n     absl::StatusOr<void*> MapMemory(const DeviceMemoryBase& location,\n-                                    GpuExecutor* gpu_executor) override;\n+                                    const GpuExecutor* gpu_executor) override;\n \n    private:\n     friend class CudaExecutor;\n     absl::Status Initialize(uint64_t size, int num_devices,\n-                            GpuExecutor* gpu_executor);\n+                            const GpuExecutor* gpu_executor);\n     CUmemGenericAllocationHandle handle_;\n     uint64_t padded_size_;\n     uint64_t granularity_;\n@@ -191,10 +190,10 @@ class CudaExecutor : public GpuExecutor {\n   };\n \n   absl::StatusOr<std::unique_ptr<MulticastMemory>> CreateMulticastMemory(\n-      uint64_t size, int num_devices) override;\n+      uint64_t size, int num_devices) const override;\n \n   // Returns a handle to the given memory if it was allocated with VMM API.\n-  absl::StatusOr<VmmMemoryHandle> RetainVmmMemoryHandle(void* ptr);\n+  absl::StatusOr<VmmMemoryHandle> RetainVmmMemoryHandle(void* ptr) const;\n \n   bool is_multicast_supported() const override {\n     return is_multicast_supported_;"
        },
        {
            "sha": "9f28a352859a485edae3b1b80f12bc7a05d2941e",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_executor.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor.h?ref=d6d4e0224853aeea664a2e669247b5fe58c22c09",
            "patch": "@@ -80,13 +80,13 @@ class GpuExecutor : public StreamExecutorCommon {\n     }\n \n     virtual absl::StatusOr<void*> MapMemory(const DeviceMemoryBase& location,\n-                                            GpuExecutor* gpu_executor) {\n+                                            const GpuExecutor* gpu_executor) {\n       return absl::UnimplementedError(\"MapMemory is not implemented.\");\n     }\n   };\n \n   virtual absl::StatusOr<std::unique_ptr<MulticastMemory>>\n-  CreateMulticastMemory(uint64_t size, int num_devices) {\n+  CreateMulticastMemory(uint64_t size, int num_devices) const {\n     return absl::UnimplementedError(\n         \"CreateMulticastMemory is not implemented.\");\n   };"
        },
        {
            "sha": "df1d94782425674018a522301f03ec468df2dd8d",
            "filename": "third_party/xla/xla/stream_executor/rocm/rocm_executor.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_executor.cc?ref=d6d4e0224853aeea664a2e669247b5fe58c22c09",
            "patch": "@@ -522,7 +522,7 @@ bool RocmExecutor::UnloadModule(ModuleHandle module_handle) {\n }\n \n absl::StatusOr<DeviceMemoryBase> RocmExecutor::GetMemoryRange(\n-    const DeviceMemoryBase& location) {\n+    const DeviceMemoryBase& location) const {\n   hipDeviceptr_t device_pointer;\n   size_t size;\n   hipError_t result = wrap::hipMemGetAddressRange("
        },
        {
            "sha": "d53ce5cca565058d3264390ef3440408268a55f4",
            "filename": "third_party/xla/xla/stream_executor/rocm/rocm_executor.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_executor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_executor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_executor.h?ref=d6d4e0224853aeea664a2e669247b5fe58c22c09",
            "patch": "@@ -84,7 +84,7 @@ class RocmExecutor : public GpuExecutor {\n       Stream* stream, absl::Span<const uint8_t> content) override;\n   DeviceMemoryBase Allocate(uint64_t size, int64_t memory_space) override;\n   absl::StatusOr<DeviceMemoryBase> GetMemoryRange(\n-      const DeviceMemoryBase& location) override;\n+      const DeviceMemoryBase& location) const override;\n   void Deallocate(DeviceMemoryBase* mem) override;\n   bool SynchronizeAllActivity() override;\n   absl::StatusOr<std::unique_ptr<EventBasedTimer>> CreateEventBasedTimer("
        },
        {
            "sha": "3fa3918de40fa79af05c9c303d0f4f7d8829b712",
            "filename": "third_party/xla/xla/stream_executor/stream_executor.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Fstream_executor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6d4e0224853aeea664a2e669247b5fe58c22c09/third_party%2Fxla%2Fxla%2Fstream_executor%2Fstream_executor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fstream_executor.h?ref=d6d4e0224853aeea664a2e669247b5fe58c22c09",
            "patch": "@@ -192,7 +192,7 @@ class StreamExecutor {\n   // for the given DeviceMemoryBase, such that location is contained within the\n   // returned range.\n   virtual absl::StatusOr<DeviceMemoryBase> GetMemoryRange(\n-      const DeviceMemoryBase& location) {\n+      const DeviceMemoryBase& location) const {\n     return absl::UnimplementedError(\"Not implemented for this executor.\");\n   }\n "
        }
    ],
    "stats": {
        "total": 444,
        "additions": 299,
        "deletions": 145
    }
}