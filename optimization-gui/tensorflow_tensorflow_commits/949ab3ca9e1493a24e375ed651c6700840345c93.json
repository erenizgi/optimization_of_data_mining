{
    "author": "mrguenther",
    "message": "Enable StablehloPrepareForHloExportPass.\n\nEnable the StableHLO equivalent of MHLO's similarly named pass, which runs right before lowering to HLO.\n\nPiperOrigin-RevId: 810575154",
    "sha": "949ab3ca9e1493a24e375ed651c6700840345c93",
    "files": [
        {
            "sha": "61aa6c61a785387564ddf97078c56f94729873de",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/949ab3ca9e1493a24e375ed651c6700840345c93/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/949ab3ca9e1493a24e375ed651c6700840345c93/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc?ref=949ab3ca9e1493a24e375ed651c6700840345c93",
            "patch": "@@ -6264,6 +6264,8 @@ absl::Status PrepareForExport(mlir::ModuleOp module) {\n   pm.enableVerifier(enableVerifier);\n \n   pm.addNestedPass<mlir::func::FuncOp>(mhlo::createPrepareForExportPass());\n+  pm.addNestedPass<mlir::func::FuncOp>(\n+      stablehlo_ext::createStablehloPrepareForHloExportPass());\n   if (hasShapeOps) {\n     // Experimental support for exporting dynamic MHLO programs to HLO.\n     // Only bounded dynamism is planned to be supported; unbounded dynamism"
        },
        {
            "sha": "988f5a681444c1ab7b87f454319f69a5f94828f9",
            "filename": "third_party/xla/xla/hlo/translate/tests/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/949ab3ca9e1493a24e375ed651c6700840345c93/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/949ab3ca9e1493a24e375ed651c6700840345c93/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Ftests%2FBUILD?ref=949ab3ca9e1493a24e375ed651c6700840345c93",
            "patch": "@@ -20,6 +20,7 @@ lit_test_suite(\n             \"simple.mlir\",\n             \"stablehlo.mlir\",\n             \"stablehlo_invalid.mlir\",\n+            \"stablehlo_prepare_for_export.mlir\",\n             \"stablehlo_unary_elementwise.mlir\",\n             \"stablehlo_while.mlir\",\n             \"stablehlo_while_free_vars.mlir\","
        },
        {
            "sha": "8fb3ea76a173d5a3ddabc686a2dd33765c3ff7f4",
            "filename": "third_party/xla/xla/hlo/translate/tests/stablehlo_prepare_for_export.mlir",
            "status": "added",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/949ab3ca9e1493a24e375ed651c6700840345c93/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Ftests%2Fstablehlo_prepare_for_export.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/949ab3ca9e1493a24e375ed651c6700840345c93/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Ftests%2Fstablehlo_prepare_for_export.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Ftests%2Fstablehlo_prepare_for_export.mlir?ref=949ab3ca9e1493a24e375ed651c6700840345c93",
            "patch": "@@ -0,0 +1,16 @@\n+// RUN: hlo-translate -mlir-to-hlo -split-input-file %s | FileCheck %s\n+\n+// Part of HLO lowering includes MLIR preprocessing for things that are allowed\n+// in MLIR HLO but not in HLO.\n+\n+// CHECK-LABEL: main\n+// [[ARG_0:%.*]] = f32[1,2,3] parameter(0)\n+// [[TRANSPOSE:%.*]] = f32[2,3,1] transpose([[ARG_0]]), dimensions={1,2,0}\n+// [[BROADCAST_0:%.*]] = f32[2,3,1,1] broadcast([[TRANSPOSE]]), dimensions={0,1,3}\n+// [[RESHAPE:%.*]] = f32[2,3,1] reshape([[BROADCAST_0]])\n+// ROOT %[[BROADCAST_1:%.*]] = f32[2,3,1,10] broadcast([[RESHAPE]]), dimensions={0,1,2}\n+\n+func.func @main(%arg0: tensor<1x2x3xf32>) -> tensor<2x3x1x10xf32> {\n+  %0 = stablehlo.broadcast_in_dim %arg0, dims = [3, 0, 1] : (tensor<1x2x3xf32>) -> tensor<2x3x1x10xf32>\n+  return %0 : tensor<2x3x1x10xf32>\n+}"
        },
        {
            "sha": "3e7c3c4a396db9d62d7848c68e06b9c2e1a0aaff",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/prepare_for_export/prepare_for_export.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/949ab3ca9e1493a24e375ed651c6700840345c93/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fprepare_for_export%2Fprepare_for_export.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/949ab3ca9e1493a24e375ed651c6700840345c93/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fprepare_for_export%2Fprepare_for_export.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fprepare_for_export%2Fprepare_for_export.cc?ref=949ab3ca9e1493a24e375ed651c6700840345c93",
            "patch": "@@ -49,17 +49,16 @@ constexpr char kShardingAttr[] = \"mhlo.sharding\";\n #include \"mhlo/transforms/mhlo_passes.h.inc\"\n \n namespace {\n+\n // Prepare module for export to XLA HLO.\n struct PrepareForExportPass\n     : public impl::PrepareForExportPassBase<PrepareForExportPass> {\n   void runOnOperation() override;\n };\n \n-}  // end namespace\n-\n // Materializes some splat before export because it may be more efficient in\n // HLOInstruction.\n-static void prepareConstantOp(Operation *op, SplatElementsAttr attr) {\n+void prepareConstantOp(Operation* op, SplatElementsAttr attr) {\n   // Arbitrarily chosen \"small\" number. This could be chosen based on the proto\n   // size too.\n   if (attr.getNumElements() < 32) return;\n@@ -86,7 +85,7 @@ static void prepareConstantOp(Operation *op, SplatElementsAttr attr) {\n   op->erase();\n }\n \n-static void prepareBroadcastInDim(BroadcastInDimOp bcast) {\n+void prepareBroadcastInDim(BroadcastInDimOp bcast) {\n   DenseIntElementsAttr dims = bcast.getBroadcastDimensions();\n   // If dimensions aren't sorted, there is a transpose fused into the op, which\n   // XLA Builder does not support, we unfuse here.\n@@ -115,7 +114,7 @@ static void prepareBroadcastInDim(BroadcastInDimOp bcast) {\n }\n \n // Make implicitly captured constant explicit before exporting\n-static void prepareExplicitCapturedConstants(Operation *op) {\n+void prepareExplicitCapturedConstants(Operation* op) {\n   for (Region &region : op->getRegions()) {\n     assert(region.getBlocks().size() == 1 &&\n            \"Only OPs with single block regions are allowed\");\n@@ -144,6 +143,8 @@ static void prepareExplicitCapturedConstants(Operation *op) {\n   }\n }\n \n+}  // namespace\n+\n void PrepareForExportPass::runOnOperation() {\n   getOperation().walk([&](Operation *op) {\n     mlir::SplatElementsAttr attr;"
        }
    ],
    "stats": {
        "total": 30,
        "additions": 25,
        "deletions": 5
    }
}