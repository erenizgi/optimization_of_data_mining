{
    "author": "ezhulenev",
    "message": "[stream_executor] Rename DeviceMemory to DeviceAddress and update documentation (remove ancient mentions of OpenCL)\n\nDeviceMemoryAllocator will be updated in next change\n\nPiperOrigin-RevId: 840426569",
    "sha": "5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
    "files": [
        {
            "sha": "059d01f68b7db5289ce7d807d156f4599a756df8",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffer_comparator.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_comparator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_comparator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_comparator.cc?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -65,7 +65,7 @@ static absl::StatusOr<bool> DeviceCompare(const ComparisonParams& params) {\n   se::DeviceMemoryHandle out(executor, executor->AllocateScalar<uint64_t>());\n \n   TF_RETURN_IF_ERROR(\n-      params.stream->MemZero(out.memory_ptr(), sizeof(uint64_t)));\n+      params.stream->MemZero(out.address_ptr(), sizeof(uint64_t)));\n   if (params.current.size() != params.expected.size()) {\n     return Internal(\"Mismatched buffer size: %d bytes vs. %d bytes\",\n                     params.current.size(), params.expected.size());\n@@ -95,16 +95,16 @@ static absl::StatusOr<bool> DeviceCompare(const ComparisonParams& params) {\n                    1, 1),\n       dim.thread_counts_per_block());\n \n-  se::DeviceMemory<uint64_t> as_uint64(out.memory());\n+  se::DeviceMemory<uint64_t> as_uint64(out.address());\n   TF_RETURN_IF_ERROR(comparison_kernel.Launch(\n       dim.thread_counts_per_block(), dim.block_counts(), params.stream,\n       current_typed, expected_typed, static_cast<float>(params.relative_tol),\n       buffer_size, as_uint64));\n \n   uint64_t result = -1;\n-  CHECK_EQ(out.memory().size(), sizeof(result));\n+  CHECK_EQ(out.address().size(), sizeof(result));\n   TF_RETURN_IF_ERROR(\n-      params.stream->Memcpy(&result, out.memory(), sizeof(result)));\n+      params.stream->Memcpy(&result, out.address(), sizeof(result)));\n   TF_RETURN_IF_ERROR(params.stream->BlockHostUntilDone());\n   return result == 0;\n }\n@@ -191,8 +191,7 @@ absl::StatusOr<bool> BufferComparator::CompareEqual(\n   auto do_compare = [&](auto cst_type) {\n     using ElementT = primitive_util::NativeTypeOf<cst_type>;\n     using ComparisonT =\n-        std::conditional_t<std::is_same_v<ElementT, double>,\n-                           double, float>;\n+        std::conditional_t<std::is_same_v<ElementT, double>, double, float>;\n     return CompareEqualParameterized<ElementT, ComparisonT>(params);\n   };\n "
        },
        {
            "sha": "7591a7a402e69fcb05c7b87b5bd301cfd9531038",
            "filename": "third_party/xla/xla/executable_run_options.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fexecutable_run_options.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fexecutable_run_options.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fexecutable_run_options.h?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -34,7 +34,7 @@ class Stream;\n class Event;\n class Platform;\n class DeviceMemoryAllocator;\n-class DeviceMemoryBase;\n+class DeviceAddressBase;\n }  // namespace stream_executor\n \n namespace Eigen {\n@@ -108,7 +108,7 @@ using ThenExecuteFunction =\n using SendDeviceMemoryFunction = std::function<\n     absl::StatusOr<tsl::AsyncValueRef<std::unique_ptr<stream_executor::Event>>>(\n         int64_t channel_id, stream_executor::Stream* stream, const Shape& shape,\n-        const stream_executor::DeviceMemoryBase& src,\n+        const stream_executor::DeviceAddressBase& src,\n         const absl::flat_hash_map<std::string, std::string>& frontend_attrs)>;\n \n // Callback for receiving device buffer from a channel. Returned event will be\n@@ -118,7 +118,7 @@ using SendDeviceMemoryFunction = std::function<\n using RecvDeviceMemoryFunction = std::function<\n     absl::StatusOr<tsl::AsyncValueRef<std::unique_ptr<stream_executor::Event>>>(\n         int64_t channel_id, stream_executor::Stream* stream, const Shape& shape,\n-        stream_executor::DeviceMemoryBase* dst,\n+        stream_executor::DeviceAddressBase* dst,\n         const absl::flat_hash_map<std::string, std::string>& frontend_attrs)>;\n \n // Class containing options for running a LocalExecutable."
        },
        {
            "sha": "1eeae56dd6070f882018e7dbfd73151f25d43f50",
            "filename": "third_party/xla/xla/service/gpu/infeed_manager.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Finfeed_manager.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Finfeed_manager.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Finfeed_manager.cc?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -59,7 +59,7 @@ static absl::StatusOr<se::DeviceMemoryHandle> CopyBufferToDevice(\n   se::StreamExecutor* executor = stream->parent();\n   se::DeviceMemoryHandle buffer(executor,\n                                 executor->AllocateArray<uint8_t>(size));\n-  TF_RETURN_IF_ERROR(stream->Memcpy(buffer.memory_ptr(), source, size));\n+  TF_RETURN_IF_ERROR(stream->Memcpy(buffer.address_ptr(), source, size));\n \n   return std::move(buffer);\n }"
        },
        {
            "sha": "02a80e2f0b75fadccbd26a4fa8bbaa374fa5a285",
            "filename": "third_party/xla/xla/stream_executor/BUILD",
            "status": "modified",
            "additions": 37,
            "deletions": 16,
            "changes": 53,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -73,22 +73,55 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"device_address\",\n+    hdrs = [\"device_address.h\"],\n+    deps = [\n+        \"//xla/tsl/platform:logging\",\n+        \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/log:check\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"device_address_handle\",\n+    srcs = [\"device_address_handle.cc\"],\n+    hdrs = [\"device_address_handle.h\"],\n+    deps = [\n+        \":device_address\",\n+        \":stream_executor_h\",\n+        \"@com_google_absl//absl/base:core_headers\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"device_address_handle_test\",\n+    srcs = [\"device_address_handle_test.cc\"],\n+    deps = [\n+        \":device_address\",\n+        \":device_address_handle\",\n+        \":mock_stream_executor\",\n+        \"@com_google_googletest//:gtest_main\",\n+        \"@local_tsl//tsl/platform:test\",\n+    ],\n+)\n+\n cc_library(\n     name = \"device_memory\",\n     hdrs = [\"device_memory.h\"],\n     deps = [\n-        \"//xla/tsl/platform:logging\",\n+        \":device_address\",\n+        \"//xla/stream_executor/gpu:tensor_map\",\n         \"@com_google_absl//absl/base:core_headers\",\n     ],\n )\n \n cc_library(\n     name = \"device_memory_handle\",\n-    srcs = [\"device_memory_handle.cc\"],\n     hdrs = [\"device_memory_handle.h\"],\n     deps = [\n-        \":device_memory\",\n-        \":stream_executor_h\",\n+        \":device_address_handle\",\n+        \"@com_google_absl//absl/base:core_headers\",\n     ],\n )\n \n@@ -1039,18 +1072,6 @@ xla_cc_test(\n     ],\n )\n \n-xla_cc_test(\n-    name = \"device_memory_handle_test\",\n-    srcs = [\"device_memory_handle_test.cc\"],\n-    deps = [\n-        \":device_memory\",\n-        \":device_memory_handle\",\n-        \":mock_stream_executor\",\n-        \"@com_google_googletest//:gtest_main\",\n-        \"@local_tsl//tsl/platform:test\",\n-    ],\n-)\n-\n xla_cc_test(\n     name = \"device_description_test\",\n     srcs = [\"device_description_test.cc\"],"
        },
        {
            "sha": "a2ac3d8ac020951db9aacdaf861ff3ae09a466e2",
            "filename": "third_party/xla/xla/stream_executor/device_address.h",
            "status": "added",
            "additions": 166,
            "deletions": 0,
            "changes": 166,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address.h?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -0,0 +1,166 @@\n+/* Copyright 2015 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_STREAM_EXECUTOR_DEVICE_ADDRESS_H_\n+#define XLA_STREAM_EXECUTOR_DEVICE_ADDRESS_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <tuple>\n+\n+#include \"absl/base/attributes.h\"\n+#include \"absl/log/check.h\"\n+\n+namespace stream_executor {\n+\n+// DeviceAddress is an addressable virtual memory region on device. It's backed\n+// by a physical memory allocation (which is not directly addressable by the\n+// user, as device access requires virtual memory mapping). Physical memory\n+// allocations are managed by the StreamExecutor and device allocator, and users\n+// interact with device memory through DeviceAddress.\n+\n+// DeviceAddressBase is a void*-analogous pointer to a device memory address,\n+// which comes with an optional size parameter. For typed pointers check the\n+// typed `DeviceAddress<T>` version below.\n+//\n+// IMPORTANT: Ideally `size` would be a mandatory parameter that tells the\n+// addressable range from the base pointer, however there are many existing use\n+// cases that rely on the default constructor and size is not set. Users should\n+// check for `opaque` being null to determine if the device address is null.\n+class DeviceAddressBase {\n+ public:\n+  // Default constructor instantiates a null-pointed, zero-sized device memory\n+  // region. An opaque pointer may be provided -- see header for details on the\n+  // opacity of that pointer.\n+  explicit DeviceAddressBase(void* opaque = nullptr, uint64_t size = 0)\n+      : opaque_(opaque), size_(size) {\n+    // TODO(b/336267585): This constructor dangerously encourages\n+    //                 DeviceAddressBase(mem) which would imply\n+    //                 DeviceAddressBase(mem, 0)\n+    //                 We should delete & resolve any dependencies.\n+    //  explicit DeviceAddressBase(void *opaque) = delete;\n+  }\n+\n+  // Returns whether the backing memory is the null pointer.\n+  // A `== nullptr` convenience method is also provided.\n+  bool is_null() const { return opaque_ == nullptr; }\n+\n+  bool operator==(std::nullptr_t other) const { return is_null(); }\n+  bool operator!=(std::nullptr_t other) const { return !is_null(); }\n+\n+  bool operator==(const DeviceAddressBase& other) const {\n+    return opaque_ == other.opaque_ && size_ == other.size_;\n+  }\n+\n+  // Provides a partial order between device memory values.\n+  //\n+  // This operator is provided so that this object can be used as a key in an\n+  // ordered map.\n+  bool operator<(const DeviceAddressBase& other) const {\n+    return std::tie(opaque_, size_) < std::tie(other.opaque_, other.size_);\n+  }\n+\n+  // Returns the size, in bytes, for the backing memory.\n+  uint64_t size() const { return size_; }\n+\n+  // Warning: note that the pointer returned is not necessarily directly to\n+  // device virtual address space, but is platform-dependent.\n+  void* opaque() const { return opaque_; }\n+\n+  // Returns the payload of this memory region.\n+  uint64_t payload() const { return payload_; }\n+\n+  // Sets payload to given value.\n+  void SetPayload(uint64_t payload) { payload_ = payload; }\n+\n+  // Returns whether the two DeviceAddressBase segments are identical (both in\n+  // their opaque pointer and size).\n+  bool IsSameAs(const DeviceAddressBase& other) const {\n+    return opaque() == other.opaque() && size() == other.size();\n+  }\n+\n+  // Creates a memory region (slice) inside another allocated memory region.\n+  // Offset and size are in bytes.\n+  ABSL_ATTRIBUTE_ALWAYS_INLINE DeviceAddressBase\n+  GetByteSlice(uint64_t offset_bytes, uint64_t size_bytes) const {\n+    DCHECK(offset_bytes + size_bytes <= size_)\n+        << \"requested slice allocation (offset + size) is greater \"\n+        << \"than parent allocation size: (\" << offset_bytes << \" + \"\n+        << size_bytes << \") vs. (\" << size_ << \")\";\n+\n+    return DeviceAddressBase(\n+        reinterpret_cast<std::byte*>(opaque_) + offset_bytes, size_bytes);\n+  }\n+\n+ private:\n+  void* opaque_;   // Platform-dependent value representing addressable memory.\n+  uint64_t size_;  // Size in bytes of this allocation.\n+  uint64_t payload_ = 0;  // Payload data associated with this allocation.\n+};\n+\n+// Typed wrapper around \"void *\"-like DeviceAddressBase.\n+//\n+// For example, DeviceAddress<int32_t> is a simple wrapper around\n+// DeviceAddressBase that represents one or more integers in Device memory.\n+template <typename T>\n+class DeviceAddress final : public DeviceAddressBase {\n+ public:\n+  // Default constructor instantiates a null-pointed, zero-sized memory region.\n+  DeviceAddress() : DeviceAddressBase(nullptr, 0) {}\n+  explicit DeviceAddress(std::nullptr_t) : DeviceAddress() {}\n+\n+  // Typed device memory regions may be constructed from untyped device memory\n+  // regions, this effectively amounts to a cast from a void*.\n+  explicit DeviceAddress(const DeviceAddressBase& other)\n+      : DeviceAddressBase(const_cast<DeviceAddressBase&>(other).opaque(),\n+                          other.size()) {\n+    SetPayload(other.payload());\n+  }\n+\n+  // Returns the number of elements of type T that constitute this\n+  // allocation.\n+  uint64_t ElementCount() const { return size() / sizeof(T); }\n+\n+  // Returns pointer to the allocated data\n+  T* base() const { return reinterpret_cast<T*>(opaque()); }\n+\n+  // Creates a typed area of DeviceAddress with a given opaque pointer and the\n+  // quantity of bytes in the allocation. This function is broken out to\n+  // distinguish bytes from an element count.\n+  static DeviceAddress<T> MakeFromByteSize(void* opaque, uint64_t bytes) {\n+    return DeviceAddress<T>(opaque, bytes);\n+  }\n+\n+  // Creates a memory region (slice) inside another allocated memory region.\n+  // Offset and size are specified in terms of T elements.\n+  DeviceAddress<T> GetSlice(uint64_t element_offset, uint64_t element_count) {\n+    return DeviceAddress<T>(\n+        GetByteSlice(sizeof(T) * element_offset, sizeof(T) * element_count));\n+  }\n+\n+ protected:\n+  // This is made protected because it accepts a byte-size instead of an element\n+  // count, which could potentially be misused given the ElementCount() nature\n+  // of this interface.\n+  //\n+  // In order to specify the desire to use byte size instead of element count\n+  // explicitly, use MakeFromByteSize.\n+  DeviceAddress(void* opaque, uint64_t size)\n+      : DeviceAddressBase(opaque, size) {}\n+};\n+\n+}  // namespace stream_executor\n+\n+#endif  // XLA_STREAM_EXECUTOR_DEVICE_ADDRESS_H_"
        },
        {
            "sha": "16e58a2e37ce4a56d91b129c10c2825c2a9bd141",
            "filename": "third_party/xla/xla/stream_executor/device_address_handle.cc",
            "status": "renamed",
            "additions": 17,
            "deletions": 16,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address_handle.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address_handle.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address_handle.cc?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -12,37 +12,38 @@ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n-#include \"xla/stream_executor/device_memory_handle.h\"\n+\n+#include \"xla/stream_executor/device_address_handle.h\"\n \n #include <utility>\n \n-#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n \n namespace stream_executor {\n \n-DeviceMemoryHandle::DeviceMemoryHandle(StreamExecutor *executor,\n-                                       DeviceMemoryBase memory)\n-    : memory_(std::move(memory)), executor_(executor) {}\n+DeviceAddressHandle::DeviceAddressHandle(StreamExecutor* executor,\n+                                         DeviceAddressBase address)\n+    : address_(std::move(address)), executor_(executor) {}\n \n-DeviceMemoryHandle::DeviceMemoryHandle(DeviceMemoryHandle &&other) noexcept\n-    : memory_(std::move(other.memory_)), executor_(other.executor_) {\n-  other.memory_ = DeviceMemoryBase();\n+DeviceAddressHandle::DeviceAddressHandle(DeviceAddressHandle&& other) noexcept\n+    : address_(std::move(other.address_)), executor_(other.executor_) {\n+  other.address_ = DeviceAddressBase();\n }\n \n-DeviceMemoryHandle::~DeviceMemoryHandle() { Free(); }\n+DeviceAddressHandle::~DeviceAddressHandle() { Free(); }\n \n-void DeviceMemoryHandle::Free() {\n-  if (!memory_.is_null()) {\n-    executor_->Deallocate(&memory_);\n+void DeviceAddressHandle::Free() {\n+  if (!address_.is_null()) {\n+    executor_->Deallocate(&address_);\n   }\n }\n \n-DeviceMemoryHandle &DeviceMemoryHandle::operator=(\n-    DeviceMemoryHandle &&other) noexcept {\n+DeviceAddressHandle& DeviceAddressHandle::operator=(\n+    DeviceAddressHandle&& other) noexcept {\n   Free();\n-  memory_ = std::move(other.memory_);\n-  other.memory_ = DeviceMemoryBase();\n+  address_ = std::move(other.address_);\n+  other.address_ = DeviceAddressBase();\n   executor_ = other.executor_;\n   return *this;\n }",
            "previous_filename": "third_party/xla/xla/stream_executor/device_memory_handle.cc"
        },
        {
            "sha": "35cf6dfc005223995cd153cedef62d073117ba48",
            "filename": "third_party/xla/xla/stream_executor/device_address_handle.h",
            "status": "added",
            "additions": 61,
            "deletions": 0,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address_handle.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address_handle.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address_handle.h?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -0,0 +1,61 @@\n+/* Copyright 2024 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_STREAM_EXECUTOR_DEVICE_ADDRESS_HANDLE_H_\n+#define XLA_STREAM_EXECUTOR_DEVICE_ADDRESS_HANDLE_H_\n+\n+#include \"absl/base/macros.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+\n+namespace stream_executor {\n+\n+// An RAII-style container for the DeviceAddress that is deallocated via the\n+// owning StreamExecutor when the handle is destroyed.\n+class DeviceAddressHandle {\n+ public:\n+  DeviceAddressHandle() : address_(), executor_(nullptr) {}\n+\n+  // A helper constructor to generate a scoped device address given an already\n+  // allocated address and a stream executor.\n+  DeviceAddressHandle(StreamExecutor* executor, DeviceAddressBase address);\n+  ~DeviceAddressHandle();\n+\n+  // Moves ownership of the address from other to the constructed\n+  // object.\n+  DeviceAddressHandle(DeviceAddressHandle&& other) noexcept;\n+\n+  // Moves ownership of the address from other to this object.\n+  DeviceAddressHandle& operator=(DeviceAddressHandle&& other) noexcept;\n+\n+  // Accessors for the DeviceAddressBase.\n+  const DeviceAddressBase& address() const { return address_; }\n+  DeviceAddressBase* address_ptr() { return &address_; }\n+\n+  ABSL_DEPRECATE_AND_INLINE()\n+  const DeviceAddressBase& memory() const { return address(); }\n+  ABSL_DEPRECATE_AND_INLINE()\n+  DeviceAddressBase* memory_ptr() { return address_ptr(); }\n+\n+ private:\n+  // Frees the associated address.\n+  void Free();\n+\n+  DeviceAddressBase address_;  // Value we wrap with scoped-release.\n+  StreamExecutor* executor_;   // Null if this object is inactive.\n+};\n+}  // namespace stream_executor\n+\n+#endif  // XLA_STREAM_EXECUTOR_DEVICE_ADDRESS_HANDLE_H_"
        },
        {
            "sha": "95315fdfb4f9fe8bd6ec35fe98ec4a4074bc2eb5",
            "filename": "third_party/xla/xla/stream_executor/device_address_handle_test.cc",
            "status": "renamed",
            "additions": 20,
            "deletions": 16,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address_handle_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address_handle_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_address_handle_test.cc?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -12,50 +12,54 @@ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n-#include \"xla/stream_executor/device_memory_handle.h\"\n+#include \"xla/stream_executor/device_address_handle.h\"\n \n #include <utility>\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n-#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/mock_stream_executor.h\"\n #include \"tsl/platform/test.h\"\n \n namespace stream_executor {\n namespace {\n \n-TEST(DeviceMemoryHandle, NullMemoryNoDeallocate) {\n-  DeviceMemoryBase null_memory;\n+TEST(DeviceAddressHandle, NullMemoryNoDeallocate) {\n+  DeviceAddressBase null_address;\n   MockStreamExecutor executor;\n   EXPECT_CALL(executor, Deallocate).Times(0);\n-  { DeviceMemoryHandle releaser(&executor, null_memory); }\n+  {\n+    DeviceAddressHandle releaser(&executor, null_address);\n+  }\n }\n \n-TEST(DeviceMemoryHandle, Deallocates) {\n+TEST(DeviceAddressHandle, Deallocates) {\n   MockStreamExecutor executor;\n-  DeviceMemoryBase memory(&executor, sizeof(executor));\n+  DeviceAddressBase memory(&executor, sizeof(executor));\n   EXPECT_CALL(executor, Deallocate).Times(1);\n-  { DeviceMemoryHandle releaser(&executor, memory); }\n+  {\n+    DeviceAddressHandle releaser(&executor, memory);\n+  }\n }\n \n-TEST(DeviceMemoryHandle, MoveDeallocatesOnce) {\n+TEST(DeviceAddressHandle, MoveDeallocatesOnce) {\n   MockStreamExecutor executor;\n-  DeviceMemoryBase memory(&executor, sizeof(executor));\n+  DeviceAddressBase memory(&executor, sizeof(executor));\n   EXPECT_CALL(executor, Deallocate).Times(1);\n   {\n-    DeviceMemoryHandle releaser(&executor, memory);\n-    DeviceMemoryHandle releaser_moved(std::move(releaser));\n+    DeviceAddressHandle releaser(&executor, memory);\n+    DeviceAddressHandle releaser_moved(std::move(releaser));\n   }\n }\n \n-TEST(DeviceMemoryHandle, MoveAssignmentDeallocatesOnce) {\n+TEST(DeviceAddressHandle, MoveAssignmentDeallocatesOnce) {\n   MockStreamExecutor executor;\n-  DeviceMemoryBase memory(&executor, sizeof(executor));\n+  DeviceAddressBase memory(&executor, sizeof(executor));\n   EXPECT_CALL(executor, Deallocate).Times(1);\n   {\n-    DeviceMemoryHandle releaser(&executor, memory);\n-    DeviceMemoryHandle releaser2;\n+    DeviceAddressHandle releaser(&executor, memory);\n+    DeviceAddressHandle releaser2;\n     releaser2 = std::move(releaser);\n   }\n }",
            "previous_filename": "third_party/xla/xla/stream_executor/device_memory_handle_test.cc"
        },
        {
            "sha": "4cfed8cd1e8bc5c833c9dba1a396551289bda25c",
            "filename": "third_party/xla/xla/stream_executor/device_memory.h",
            "status": "modified",
            "additions": 8,
            "deletions": 147,
            "changes": 155,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_memory.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_memory.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_memory.h?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -26,159 +26,20 @@ limitations under the License.\n \n #include <stddef.h>\n \n-#include <cstddef>\n-#include <cstdint>\n-#include <tuple>\n-\n-#include \"absl/base/attributes.h\"\n-#include \"xla/tsl/platform/logging.h\"\n+#include \"absl/base/macros.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/gpu/tensor_map.h\"\n \n namespace stream_executor {\n \n-// void*-analogous device memory allocation. For the typed variation, see\n-// DeviceMemory<T>.\n-//\n-// This is effectively a two-tuple of a pointer and size; however, note that the\n-// pointer may not be to the virtual address itself -- in OpenCL the pointer is\n-// to a cl_mem handle that describes the device allocation. Therefore,\n-// DeviceMemoryBase::opaque does not necessarily produce a pointer that can be\n-// referenced directly, so use it with caution.\n-//\n-// Thread-compatible.\n-class DeviceMemoryBase {\n- public:\n-  // Default constructor instantiates a null-pointed, zero-sized device memory\n-  // region. An opaque pointer may be provided -- see header for details on the\n-  // opacity of that pointer.\n-  explicit DeviceMemoryBase(void *opaque = nullptr, uint64_t size = 0)\n-      : opaque_(opaque), size_(size) {\n-    // TODO(b/336267585): This constructor dangerously encourages\n-    //                 DeviceMemoryBase(mem) which would imply\n-    //                 DeviceMemoryBase(mem, 0)\n-    //                 We should delete & resolve any dependencies.\n-    //  explicit DeviceMemoryBase(void *opaque) = delete;\n-  }\n-\n-  // Returns whether the backing memory is the null pointer.\n-  // A `== nullptr` convenience method is also provided.\n-  bool is_null() const { return opaque_ == nullptr; }\n-\n-  bool operator==(std::nullptr_t other) const { return is_null(); }\n-  bool operator!=(std::nullptr_t other) const { return !is_null(); }\n-\n-  bool operator==(const DeviceMemoryBase &other) const {\n-    return opaque_ == other.opaque_ && size_ == other.size_;\n-  }\n-\n-  // Provides a partial order between device memory values.\n-  //\n-  // This operator is provided so that this object can be used as a key in an\n-  // ordered map.\n-  bool operator<(const DeviceMemoryBase &other) const {\n-    return std::tie(opaque_, size_) < std::tie(other.opaque_, other.size_);\n-  }\n-\n-  // Returns the size, in bytes, for the backing memory.\n-  uint64_t size() const { return size_; }\n-\n-  // Warning: note that the pointer returned is not necessarily directly to\n-  // device virtual address space, but is platform-dependent.\n-  void *opaque() const { return opaque_; }\n-\n-  // Returns the payload of this memory region.\n-  uint64_t payload() const { return payload_; }\n-\n-  // Sets payload to given value.\n-  void SetPayload(uint64_t payload) { payload_ = payload; }\n+using DeviceMemoryBase ABSL_DEPRECATE_AND_INLINE() =\n+    ::stream_executor::DeviceAddressBase;\n \n-  // Returns whether the two DeviceMemoryBase segments are identical (both in\n-  // their opaque pointer and size).\n-  bool IsSameAs(const DeviceMemoryBase &other) const {\n-    return opaque() == other.opaque() && size() == other.size();\n-  }\n-\n-  // Creates a memory region (slice) inside another allocated memory region.\n-  // Offset and size are in bytes.\n-  ABSL_ATTRIBUTE_ALWAYS_INLINE DeviceMemoryBase\n-  GetByteSlice(uint64_t offset_bytes, uint64_t size_bytes) const {\n-    DCHECK(offset_bytes + size_bytes <= size_)\n-        << \"requested slice allocation (offset + size) is greater \"\n-        << \"than parent allocation size: (\" << offset_bytes << \" + \"\n-        << size_bytes << \") vs. (\" << size_ << \")\";\n-\n-    return DeviceMemoryBase(\n-        reinterpret_cast<std::byte *>(opaque_) + offset_bytes, size_bytes);\n-  }\n-\n- private:\n-  // Platform-dependent value representing allocated memory.\n-  //\n-  // User may also constructs the object with `kExternalAllocationMarker`\n-  // address and non-zero size, which indicates the case that buffer is\n-  // allocated externally (for Gpu backends we use it to allocate memory via\n-  // command buffer APIs).\n-  void *opaque_;\n-  uint64_t size_;         // Size in bytes of this allocation.\n-  uint64_t payload_ = 0;  // Payload data associated with this allocation.\n-};\n-\n-// Typed wrapper around \"void *\"-like DeviceMemoryBase.\n-//\n-// For example, DeviceMemory<int> is a simple wrapper around DeviceMemoryBase\n-// that represents one or more integers in Device memory.\n-//\n-// Thread-compatible.\n template <typename T>\n-class DeviceMemory final : public DeviceMemoryBase {\n- public:\n-  // Default constructor instantiates a null-pointed, zero-sized memory region.\n-  DeviceMemory() : DeviceMemoryBase(nullptr, 0) {}\n-  explicit DeviceMemory(std::nullptr_t) : DeviceMemory() {}\n-\n-  // Typed device memory regions may be constructed from untyped device memory\n-  // regions, this effectively amounts to a cast from a void*.\n-  explicit DeviceMemory(const DeviceMemoryBase &other)\n-      : DeviceMemoryBase(const_cast<DeviceMemoryBase &>(other).opaque(),\n-                         other.size()) {\n-    SetPayload(other.payload());\n-  }\n-\n-  // Returns the number of elements of type T that constitute this\n-  // allocation.\n-  uint64_t ElementCount() const { return size() / sizeof(T); }\n-\n-  // Returns pointer to the allocated data\n-  T *base() const { return reinterpret_cast<T *>(opaque()); }\n-\n-  // Creates a typed area of DeviceMemory with a given opaque pointer and the\n-  // quantity of bytes in the allocation. This function is broken out to\n-  // distinguish bytes from an element count.\n-  static DeviceMemory<T> MakeFromByteSize(void *opaque, uint64_t bytes) {\n-    return DeviceMemory<T>(opaque, bytes);\n-  }\n-\n-  // Creates a memory region (slice) inside another allocated memory region.\n-  // Offset and size are specified in terms of T elements.\n-  DeviceMemory<T> GetSlice(uint64_t element_offset, uint64_t element_count) {\n-    return DeviceMemory<T>(\n-        GetByteSlice(sizeof(T) * element_offset, sizeof(T) * element_count));\n-  }\n-\n- protected:\n-  // This is made protected because it accepts a byte-size instead of an element\n-  // count, which could potentially be misused given the ElementCount() nature\n-  // of this interface.\n-  //\n-  // In order to specify the desire to use byte size instead of element count\n-  // explicitly, use MakeFromByteSize.\n-  DeviceMemory(void *opaque, uint64_t size) : DeviceMemoryBase(opaque, size) {}\n-};\n+using DeviceMemory ABSL_DEPRECATE_AND_INLINE() =\n+    ::stream_executor::DeviceAddress<T>;\n \n-// TensorMap is a wrapper around a 128 bytes of storage. It is used to pass TMA\n-// descriptors to the kernel.\n-struct TensorMap {\n-  alignas(64) std::byte storage[128];\n-};\n+using TensorMap ABSL_DEPRECATE_AND_INLINE() = ::stream_executor::gpu::TensorMap;\n \n }  // namespace stream_executor\n "
        },
        {
            "sha": "78ada2f6be52181746ca8e1d7d38c6107ec4f73b",
            "filename": "third_party/xla/xla/stream_executor/device_memory_handle.h",
            "status": "modified",
            "additions": 6,
            "deletions": 32,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_memory_handle.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_memory_handle.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_memory_handle.h?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -1,4 +1,4 @@\n-/* Copyright 2024 The OpenXLA Authors.\n+/* Copyright 2025 The OpenXLA Authors.\n \n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n@@ -16,40 +16,14 @@ limitations under the License.\n #ifndef XLA_STREAM_EXECUTOR_DEVICE_MEMORY_HANDLE_H_\n #define XLA_STREAM_EXECUTOR_DEVICE_MEMORY_HANDLE_H_\n \n-\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/stream_executor.h\"\n+#include \"absl/base/macros.h\"\n+#include \"xla/stream_executor/device_address_handle.h\"\n \n namespace stream_executor {\n \n-// This class will deallocate the held DeviceMemoryBase upon destruction.\n-class DeviceMemoryHandle {\n- public:\n-  DeviceMemoryHandle() : memory_(), executor_(nullptr) {}\n-\n-  // A helper constructor to generate a scoped device memory given an already\n-  // allocated memory and a stream executor.\n-  DeviceMemoryHandle(StreamExecutor *executor, DeviceMemoryBase memory);\n-  ~DeviceMemoryHandle();\n-\n-  // Moves ownership of the memory from other to the constructed\n-  // object.\n-  DeviceMemoryHandle(DeviceMemoryHandle &&other) noexcept;\n-\n-  // Moves ownership of the memory from other to this object.\n-  DeviceMemoryHandle &operator=(DeviceMemoryHandle &&other) noexcept;\n-\n-  // Accessors for the DeviceMemoryBase.\n-  const DeviceMemoryBase &memory() const { return memory_; }\n-  DeviceMemoryBase *memory_ptr() { return &memory_; }\n-\n- private:\n-  // Frees the associated memory.\n-  void Free();\n+using DeviceMemoryHandle ABSL_DEPRECATE_AND_INLINE() =\n+    ::stream_executor::DeviceAddressHandle;\n \n-  DeviceMemoryBase memory_;            // Value we wrap with scoped-release.\n-  StreamExecutor *executor_;           // Null if this object is inactive.\n-};\n-}  // namespace stream_executor\n+}\n \n #endif  // XLA_STREAM_EXECUTOR_DEVICE_MEMORY_HANDLE_H_"
        },
        {
            "sha": "59820e123bc01528f2b32c7a938e9f96a33eb7d3",
            "filename": "third_party/xla/xla/stream_executor/fft.h",
            "status": "modified",
            "additions": 50,
            "deletions": 50,
            "changes": 100,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Ffft.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Ffft.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Ffft.h?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -23,9 +23,9 @@ limitations under the License.\n // Stream builder methods to entrain these operations \"under the hood\". For\n // example:\n //\n-//  DeviceMemory<std::complex<float>> x =\n+//  DeviceAddress<std::complex<float>> x =\n //    stream_exec->AllocateArray<std::complex<float>>(1024);\n-//  DeviceMemory<std::complex<float>> y =\n+//  DeviceAddress<std::complex<float>> y =\n //    stream_exec->AllocateArray<std::complex<float>>(1024);\n //  // ... populate x and y ...\n //  Stream stream{stream_exec};\n@@ -50,7 +50,7 @@ namespace stream_executor {\n \n class Stream;\n template <typename ElemT>\n-class DeviceMemory;\n+class DeviceAddress;\n class ScratchAllocator;\n \n namespace fft {\n@@ -106,11 +106,11 @@ class FftSupport {\n   // output_distance: Indicates the distance between the first element of two\n   //                  consecutive signals in a batch of the output data.\n   virtual std::unique_ptr<Plan> CreateBatchedPlanWithScratchAllocator(\n-      Stream *stream, int rank, uint64_t *elem_count, uint64_t *input_embed,\n-      uint64_t input_stride, uint64_t input_distance, uint64_t *output_embed,\n+      Stream* stream, int rank, uint64_t* elem_count, uint64_t* input_embed,\n+      uint64_t input_stride, uint64_t input_distance, uint64_t* output_embed,\n       uint64_t output_stride, uint64_t output_distance, Type type,\n       bool in_place_fft, int batch_count,\n-      ScratchAllocator *scratch_allocator) = 0;\n+      ScratchAllocator* scratch_allocator) = 0;\n \n   // Updates the plan's work area with space allocated by a new scratch\n   // allocator. This facilitates plan reuse with scratch allocators.\n@@ -119,72 +119,72 @@ class FftSupport {\n   // allocator, as otherwise scratch space will have been allocated internally\n   // by cuFFT.\n   virtual void UpdatePlanWithScratchAllocator(\n-      Stream *stream, Plan *plan, ScratchAllocator *scratch_allocator) = 0;\n+      Stream* stream, Plan* plan, ScratchAllocator* scratch_allocator) = 0;\n \n   // Computes complex-to-complex FFT in the transform direction as specified\n   // by direction parameter.\n-  virtual bool DoFft(Stream *stream, Plan *plan,\n-                     const DeviceMemory<std::complex<float>> &input,\n-                     DeviceMemory<std::complex<float>> *output) = 0;\n-  virtual bool DoFft(Stream *stream, Plan *plan,\n-                     const DeviceMemory<std::complex<double>> &input,\n-                     DeviceMemory<std::complex<double>> *output) = 0;\n+  virtual bool DoFft(Stream* stream, Plan* plan,\n+                     const DeviceAddress<std::complex<float>>& input,\n+                     DeviceAddress<std::complex<float>>* output) = 0;\n+  virtual bool DoFft(Stream* stream, Plan* plan,\n+                     const DeviceAddress<std::complex<double>>& input,\n+                     DeviceAddress<std::complex<double>>* output) = 0;\n \n   // Computes real-to-complex FFT in forward direction.\n-  virtual bool DoFft(Stream *stream, Plan *plan,\n-                     const DeviceMemory<float> &input,\n-                     DeviceMemory<std::complex<float>> *output) = 0;\n-  virtual bool DoFft(Stream *stream, Plan *plan,\n-                     const DeviceMemory<double> &input,\n-                     DeviceMemory<std::complex<double>> *output) = 0;\n+  virtual bool DoFft(Stream* stream, Plan* plan,\n+                     const DeviceAddress<float>& input,\n+                     DeviceAddress<std::complex<float>>* output) = 0;\n+  virtual bool DoFft(Stream* stream, Plan* plan,\n+                     const DeviceAddress<double>& input,\n+                     DeviceAddress<std::complex<double>>* output) = 0;\n \n   // Computes complex-to-real FFT in inverse direction.\n-  virtual bool DoFft(Stream *stream, Plan *plan,\n-                     const DeviceMemory<std::complex<float>> &input,\n-                     DeviceMemory<float> *output) = 0;\n-  virtual bool DoFft(Stream *stream, Plan *plan,\n-                     const DeviceMemory<std::complex<double>> &input,\n-                     DeviceMemory<double> *output) = 0;\n+  virtual bool DoFft(Stream* stream, Plan* plan,\n+                     const DeviceAddress<std::complex<float>>& input,\n+                     DeviceAddress<float>* output) = 0;\n+  virtual bool DoFft(Stream* stream, Plan* plan,\n+                     const DeviceAddress<std::complex<double>>& input,\n+                     DeviceAddress<double>* output) = 0;\n \n  protected:\n   FftSupport() {}\n \n  private:\n-  FftSupport(const FftSupport &) = delete;\n-  void operator=(const FftSupport &) = delete;\n+  FftSupport(const FftSupport&) = delete;\n+  void operator=(const FftSupport&) = delete;\n };\n \n // Macro used to quickly declare overrides for abstract virtuals in the\n // fft::FftSupport base class. Assumes that it's emitted somewhere inside the\n // ::stream_executor namespace.\n #define TENSORFLOW_STREAM_EXECUTOR_GPU_FFT_SUPPORT_OVERRIDES                   \\\n   std::unique_ptr<fft::Plan> CreateBatchedPlanWithScratchAllocator(            \\\n-      Stream *stream, int rank, uint64_t *elem_count, uint64_t *input_embed,   \\\n-      uint64_t input_stride, uint64_t input_distance, uint64_t *output_embed,  \\\n+      Stream* stream, int rank, uint64_t* elem_count, uint64_t* input_embed,   \\\n+      uint64_t input_stride, uint64_t input_distance, uint64_t* output_embed,  \\\n       uint64_t output_stride, uint64_t output_distance, fft::Type type,        \\\n-      bool in_place_fft, int batch_count, ScratchAllocator *scratch_allocator) \\\n+      bool in_place_fft, int batch_count, ScratchAllocator* scratch_allocator) \\\n       override;                                                                \\\n-  void UpdatePlanWithScratchAllocator(Stream *stream, fft::Plan *plan,         \\\n-                                      ScratchAllocator *scratch_allocator)     \\\n+  void UpdatePlanWithScratchAllocator(Stream* stream, fft::Plan* plan,         \\\n+                                      ScratchAllocator* scratch_allocator)     \\\n       override;                                                                \\\n-  bool DoFft(Stream *stream, fft::Plan *plan,                                  \\\n-             const DeviceMemory<std::complex<float>> &input,                   \\\n-             DeviceMemory<std::complex<float>> *output) override;              \\\n-  bool DoFft(Stream *stream, fft::Plan *plan,                                  \\\n-             const DeviceMemory<std::complex<double>> &input,                  \\\n-             DeviceMemory<std::complex<double>> *output) override;             \\\n-  bool DoFft(Stream *stream, fft::Plan *plan,                                  \\\n-             const DeviceMemory<float> &input,                                 \\\n-             DeviceMemory<std::complex<float>> *output) override;              \\\n-  bool DoFft(Stream *stream, fft::Plan *plan,                                  \\\n-             const DeviceMemory<double> &input,                                \\\n-             DeviceMemory<std::complex<double>> *output) override;             \\\n-  bool DoFft(Stream *stream, fft::Plan *plan,                                  \\\n-             const DeviceMemory<std::complex<float>> &input,                   \\\n-             DeviceMemory<float> *output) override;                            \\\n-  bool DoFft(Stream *stream, fft::Plan *plan,                                  \\\n-             const DeviceMemory<std::complex<double>> &input,                  \\\n-             DeviceMemory<double> *output) override;\n+  bool DoFft(Stream* stream, fft::Plan* plan,                                  \\\n+             const DeviceAddress<std::complex<float>>& input,                  \\\n+             DeviceAddress<std::complex<float>>* output) override;             \\\n+  bool DoFft(Stream* stream, fft::Plan* plan,                                  \\\n+             const DeviceAddress<std::complex<double>>& input,                 \\\n+             DeviceAddress<std::complex<double>>* output) override;            \\\n+  bool DoFft(Stream* stream, fft::Plan* plan,                                  \\\n+             const DeviceAddress<float>& input,                                \\\n+             DeviceAddress<std::complex<float>>* output) override;             \\\n+  bool DoFft(Stream* stream, fft::Plan* plan,                                  \\\n+             const DeviceAddress<double>& input,                               \\\n+             DeviceAddress<std::complex<double>>* output) override;            \\\n+  bool DoFft(Stream* stream, fft::Plan* plan,                                  \\\n+             const DeviceAddress<std::complex<float>>& input,                  \\\n+             DeviceAddress<float>* output) override;                           \\\n+  bool DoFft(Stream* stream, fft::Plan* plan,                                  \\\n+             const DeviceAddress<std::complex<double>>& input,                 \\\n+             DeviceAddress<double>* output) override;\n \n }  // namespace fft\n }  // namespace stream_executor"
        },
        {
            "sha": "e04f018da7751e981378733bba240398ad8747db",
            "filename": "third_party/xla/xla/stream_executor/gpu/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -338,6 +338,11 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"tensor_map\",\n+    hdrs = [\"tensor_map.h\"],\n+)\n+\n cc_library(\n     name = \"redzone_allocator\",\n     srcs = ["
        },
        {
            "sha": "6c2f90ac9b1f1c507f9e3597dcf4e18a484e4252",
            "filename": "third_party/xla/xla/stream_executor/gpu/tensor_map.h",
            "status": "added",
            "additions": 31,
            "deletions": 0,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Ftensor_map.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ad983fa5df5ec5c40079b7b89d9610af0f4fc37/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Ftensor_map.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Ftensor_map.h?ref=5ad983fa5df5ec5c40079b7b89d9610af0f4fc37",
            "patch": "@@ -0,0 +1,31 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_STREAM_EXECUTOR_GPU_TENSOR_MAP_H_\n+#define XLA_STREAM_EXECUTOR_GPU_TENSOR_MAP_H_\n+\n+#include <cstddef>\n+\n+namespace stream_executor::gpu {\n+\n+// TensorMap is a wrapper around a 128 bytes of storage. It is used to pass TMA\n+// descriptors to the kernel.\n+struct TensorMap {\n+  alignas(64) std::byte storage[128];\n+};\n+\n+}  // namespace stream_executor::gpu\n+\n+#endif  // XLA_STREAM_EXECUTOR_GPU_TENSOR_MAP_H_"
        }
    ],
    "stats": {
        "total": 697,
        "additions": 410,
        "deletions": 287
    }
}