{
    "author": "pschuh",
    "message": "Implement TrackedDeviceBuffer::GetReadyFuture, TrackedDeviceBuffer::Delete, and\nTrackedDeviceBuffer::CloneWithControlDependency.\n\nPiperOrigin-RevId: 822804278",
    "sha": "c3e202374c5ade99b1c937c871a257930f11fa53",
    "files": [
        {
            "sha": "22f905d9576df0f26c0b21c13a66631cbde13037",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 162,
            "changes": 162,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3e202374c5ade99b1c937c871a257930f11fa53/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3e202374c5ade99b1c937c871a257930f11fa53/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=c3e202374c5ade99b1c937c871a257930f11fa53",
            "patch": "@@ -674,63 +674,6 @@ bool PjRtStreamExecutorClient::IsOnCpu(PjRtMemorySpace* memory_space) {\n   return memory_space->kind() == PinnedHostMemorySpace::kKind;\n }\n \n-absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n-PjRtStreamExecutorBuffer::DonateWithControlDependency(Future<> dependency) {\n-  VLOG(1) << \"PjRtStreamExecutorBuffer::DonateWithControlDependency\";\n-  std::unique_ptr<PjRtBuffer> new_buffer;\n-\n-  auto hold = GetBufferWithHold(CommonPjRtBuffer::ScopedHold::kDonation);\n-\n-  if (!hold.ok()) {\n-    return InvalidArgument(\n-        \"Invalid buffer passed to DonateWithControlDependency: %s\",\n-        hold.status().ToString());\n-  }\n-\n-  auto* tracked_buffer =\n-      tensorflow::down_cast<TrackedDeviceBuffer*>(hold.buffer());\n-  // Copy all the data in the existing tracked_buffer.\n-  const auto& original_definition_events = tracked_buffer->definition_events();\n-  absl::InlinedVector<BufferSequencingEventRef, 4> definition_events;\n-  auto* se_client = tensorflow::down_cast<PjRtStreamExecutorClient*>(client());\n-\n-  auto definition_event_for_status =\n-      BufferSequencingEvent::Create(se_client->thread_pool());\n-  // definition_event_for_status must be the first one so that it blocks other\n-  // actions like D2H transfer from execution before the buffer is ready.\n-  definition_events.push_back(definition_event_for_status);\n-  definition_events.insert(definition_events.end(),\n-                           original_definition_events.begin(),\n-                           original_definition_events.end());\n-\n-  auto new_device_buffer = std::make_unique<TrackedDeviceBuffer>(\n-      device(), tracked_buffer->device_memory(), std::move(definition_events));\n-\n-  // Make the new buffer which is identical to the old, except for the new\n-  // definition event.\n-  new_buffer =\n-      std::unique_ptr<PjRtBuffer>(std::make_unique<PjRtStreamExecutorBuffer>(\n-          on_device_shape(), std::move(new_device_buffer), se_client, device(),\n-          device()->default_memory_space().value_or(nullptr)));\n-\n-  auto* device =\n-      tensorflow::down_cast<PjRtStreamExecutorDevice*>(this->device());\n-  LocalDeviceState* local_device = device->local_device_state();\n-  dependency.OnReady(\n-      [definition_event_for_status = std::move(definition_event_for_status),\n-       local_device, client = se_client](absl::Status status) mutable {\n-        // Forward the absl::Status from the supplied dependency to the\n-        // definition event.\n-        auto stream = local_device->BorrowStreamFromPool();\n-        TF_CHECK_OK(client->AllocateAndRecordEvent(definition_event_for_status,\n-                                                   local_device, stream.get()));\n-        local_device->ReturnStreamToPool(std::move(stream));\n-      });\n-\n-  hold.ConfirmDonation();\n-  return new_buffer;\n-}\n-\n absl::StatusOr<tsl::RCReference<PjRtDeviceEvent>>\n PjRtStreamExecutorClient::LinearizeHostBufferInto(\n     const void* data, PrimitiveType type, absl::Span<int64_t const> dims,\n@@ -1330,111 +1273,6 @@ PjRtStreamExecutorBuffer::Release(bool wait_for_operations_to_complete) {\n   return device_memory;\n }\n \n-void PjRtStreamExecutorBuffer::Delete() {\n-  VLOG(3) << \"PjRtStreamExecutorBuffer::Delete\";\n-\n-  // When wait_for_reads_to_complete is false, Release should never fail.\n-  //\n-  // The only usage events that\n-  // Release(/*wait_for_operations_to_complete=*/false) doesn't wait for are\n-  // events defined on the compute stream. All streams other than the compute\n-  // stream are expected to WaitFor compute stream before any write operations.\n-  TF_CHECK_OK(Release(/*wait_for_operations_to_complete=*/false).status());\n-}\n-\n-Future<> PjRtStreamExecutorBuffer::GetReadyFuture() {\n-  absl::InlinedVector<BufferSequencingEventRef, 2> definition_events;\n-  Promise<> definition_promise;\n-  Future<> definition_future;\n-  {\n-    absl::MutexLock lock(&mu_);\n-    if (device_buffer() == nullptr) {\n-      return Future<>(InvalidArgument(\n-          \"GetReadyFuture() called on deleted or donated buffer\"));\n-    }\n-    if (!definition_future_) {\n-      definition_events =\n-          tensorflow::down_cast<TrackedDeviceBuffer*>(device_buffer())\n-              ->definition_events();\n-      std::tie(definition_promise, definition_future_) =\n-          Future<>::MakePromise();\n-    }\n-    definition_future = definition_future_;\n-  }\n-\n-  if (!definition_events.empty()) {\n-    auto* se_device =\n-        tensorflow::down_cast<PjRtStreamExecutorDevice*>(device());\n-    LocalDeviceState* local_device_state = se_device->local_device_state();\n-    auto first_definition_event = definition_events[0];\n-    auto async_wait_for_events =\n-        [definition_events = std::move(definition_events),\n-         local_device_state = std::move(local_device_state),\n-         definition_promise = std::make_shared<Promise<>>(\n-             std::move(definition_promise))]() mutable {\n-          std::unique_ptr<se::Stream> stream;\n-          absl::Status defined_status =\n-              definition_events[0]->GetDefinedStatus();\n-          if (!defined_status.ok()) {\n-            definition_promise->Set(defined_status);\n-            return;\n-          }\n-          for (auto& event : definition_events) {\n-            if (!event->IsComplete()) {\n-              if (stream == nullptr) {\n-                stream = local_device_state->BorrowStreamFromPool();\n-              }\n-              event->WaitForEventOnStream(stream.get());\n-            }\n-          }\n-\n-          if (stream != nullptr) {\n-            auto* stream_ptr = stream.release();\n-            // We already borrowed a stream from the pool so we can safely do\n-            // the callback directly on that stream instead of bouncing through\n-            // local_device_state->ThenExecuteCallback. The direct callback\n-            // saves significant time.\n-            auto status = stream_ptr->DoHostCallback(\n-                [definition_promise, stream_ptr, local_device_state,\n-                 event_with_status = definition_events[0]]() mutable {\n-                  local_device_state->ReturnStreamToPool(\n-                      std::unique_ptr<se::Stream>(stream_ptr));\n-                  definition_promise->Set(\n-                      event_with_status->GetDefinedStatus());\n-                });\n-            if (!status.ok()) {\n-              definition_promise->Set(status);\n-              return;\n-            }\n-          } else {\n-            // All events are already complete; set the `definition_promise`\n-            // with the status of the buffer's first definition event which may\n-            // have error status to propagate.\n-            definition_promise->Set(definition_events[0]->GetDefinedStatus());\n-          }\n-        };\n-    first_definition_event->ExecuteOrAddToFutureTasks(\n-        absl::StrFormat(\"async_wait_for_events_%p\", &async_wait_for_events),\n-        std::move(async_wait_for_events));\n-  }\n-\n-  return FutureHelpers::WithProfiling(\n-      std::move(definition_future),\n-      /*on_block_start=*/\n-      [] {\n-        tsl::profiler::TraceMeProducer traceme(\n-            \"PjRtStreamExecutorBuffer::Await\");\n-        VLOG(3) << \"PjRtStreamExecutorBuffer::Await\";\n-        return FutureHelpers::ProfilingKeys(\n-            {/*traceme_context_id=*/traceme.GetContextId()});\n-      },\n-      /*on_block_end=*/\n-      [](FutureHelpers::ProfilingKeys keys) {\n-        tsl::profiler::TraceMeConsumer traceme(\n-            \"PjRtStreamExecutorBuffer::Await\", keys.traceme_context_id);\n-      });\n-}\n-\n namespace {\n \n // Helper struct for the tuple that is transiently constructed to hold the"
        },
        {
            "sha": "8b598737b35638dffe0c4674226afe994ef85418",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.h",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3e202374c5ade99b1c937c871a257930f11fa53/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3e202374c5ade99b1c937c871a257930f11fa53/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h?ref=c3e202374c5ade99b1c937c871a257930f11fa53",
            "patch": "@@ -539,18 +539,6 @@ class PjRtStreamExecutorBuffer : public CommonPjRtBufferImpl {\n   PjRtStreamExecutorBuffer& operator=(const PjRtStreamExecutorBuffer&) = delete;\n   PjRtStreamExecutorBuffer& operator=(PjRtStreamExecutorBuffer&&) = delete;\n \n-  // Drops the buffer's reference to its associated device memory, leaving the\n-  // buffer in an invalid state. The memory will be freed lazily when all async\n-  // operations using the buffer have completed, according to the allocation\n-  // semantics of the underlying platform. Delete may briefly block if another\n-  // thread is in the process of enqueuing an operation on this buffer, but it\n-  // will never block for a stream operation to complete. If an external\n-  // framework holds a reference to the TrackedDeviceBuffer via\n-  // GetBufferWithExternalReference, the memory will not be freed until the\n-  // external framework drops the reference.\n-  void Delete() override;\n-\n-  Future<> GetReadyFuture() override;\n \n   // Similar to Delete, drops the buffer's reference to its associated device\n   // memory, leaving the buffer in an invalid state, but returns the\n@@ -569,9 +557,6 @@ class PjRtStreamExecutorBuffer : public CommonPjRtBufferImpl {\n   // accesses via the buffer returned from Release.\n   absl::StatusOr<tsl::RCReference<RawSEDeviceMemory>> Release(\n       bool wait_for_operations_to_complete);\n-\n-  absl::StatusOr<std::unique_ptr<PjRtBuffer>> DonateWithControlDependency(\n-      Future<> dependency) override;\n };\n \n // Allocates the device buffers for a buffer that will be used as the"
        },
        {
            "sha": "bf346402a7fcbb33538cb9e11f0eae066ec10c10",
            "filename": "third_party/xla/xla/pjrt/se_raw_buffer.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3e202374c5ade99b1c937c871a257930f11fa53/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3e202374c5ade99b1c937c871a257930f11fa53/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc?ref=c3e202374c5ade99b1c937c871a257930f11fa53",
            "patch": "@@ -107,8 +107,9 @@ void PjRtStreamExecutorDeviceEventPromise::SetFromSEEvent(\n   event.AndThen([event = event_, original_event = event]() {\n     if (auto* error = original_event.GetErrorIfPresent()) {\n       event.SetError(*error);\n+    } else {\n+      event.SetStateConcrete();\n     }\n-    event.SetStateConcrete();\n   });\n }\n "
        },
        {
            "sha": "ae198731505ae844c7dfd53e30d651da7e06e801",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer.cc",
            "status": "modified",
            "additions": 80,
            "deletions": 0,
            "changes": 80,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3e202374c5ade99b1c937c871a257930f11fa53/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3e202374c5ade99b1c937c871a257930f11fa53/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc?ref=c3e202374c5ade99b1c937c871a257930f11fa53",
            "patch": "@@ -25,32 +25,40 @@ limitations under the License.\n #include <memory>\n #include <string>\n #include <utility>\n+#include <vector>\n \n #include \"absl/algorithm/container.h\"\n #include \"absl/container/flat_hash_set.h\"\n+#include \"absl/container/inlined_vector.h\"\n #include \"absl/functional/any_invocable.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/future.h\"\n+#include \"xla/pjrt/abstract_tracked_device_buffer.h\"\n #include \"xla/pjrt/buffer_sequencing_event.h\"\n #include \"xla/pjrt/device_event.h\"\n #include \"xla/pjrt/event_pool.h\"\n #include \"xla/pjrt/local_device_state.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_common.h\"\n+#include \"xla/pjrt/pjrt_stream_executor_client.h\"\n #include \"xla/pjrt/se_raw_buffer.h\"\n #include \"xla/service/shaped_buffer.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_tree.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/event.h\"\n+#include \"xla/tsl/concurrency/async_value.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/logging.h\"\n+#include \"xla/tsl/platform/status.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n+#include \"tsl/platform/casts.h\"\n #include \"tsl/profiler/lib/connected_traceme.h\"\n #include \"tsl/profiler/lib/context_types.h\"\n \n@@ -207,6 +215,78 @@ void TrackedDeviceBuffer::AddUsageEvent(BufferSequencingEventRef event,\n   usage_events_.push_back({event, reference_held});\n }\n \n+absl::StatusOr<std::unique_ptr<AbstractTrackedDeviceBuffer>>\n+TrackedDeviceBuffer::CloneWithControlDependency(PjRtMemorySpace* memory_space,\n+                                                Future<> dependency) {\n+  auto* se_client =\n+      tensorflow::down_cast<PjRtStreamExecutorClient*>(memory_space->client());\n+\n+  // Copy all the data in the existing tracked_buffer.\n+  const auto& original_definition_events = definition_events();\n+  absl::InlinedVector<BufferSequencingEventRef, 4> definition_events;\n+\n+  auto definition_event_for_status =\n+      BufferSequencingEvent::Create(se_client->thread_pool());\n+  // definition_event_for_status must be the first one so that it blocks other\n+  // actions like D2H transfer from execution before the buffer is ready.\n+  definition_events.push_back(definition_event_for_status);\n+  definition_events.insert(definition_events.end(),\n+                           original_definition_events.begin(),\n+                           original_definition_events.end());\n+\n+  auto new_device_buffer = std::make_unique<TrackedDeviceBuffer>(\n+      device_, device_memory(), std::move(definition_events));\n+\n+  auto* device = tensorflow::down_cast<PjRtStreamExecutorDevice*>(\n+      memory_space->devices()[0]);\n+  LocalDeviceState* local_device = device->local_device_state();\n+  dependency.OnReady(\n+      [definition_event_for_status = std::move(definition_event_for_status),\n+       local_device, client = se_client](absl::Status status) mutable {\n+        // Forward the absl::Status from the supplied dependency to the\n+        // definition event.\n+        if (!status.ok()) {\n+          client->SetEventAsError(definition_event_for_status, status);\n+          return;\n+        }\n+        auto stream = local_device->BorrowStreamFromPool();\n+        TF_CHECK_OK(client->AllocateAndRecordEvent(definition_event_for_status,\n+                                                   local_device, stream.get()));\n+        local_device->ReturnStreamToPool(std::move(stream));\n+      });\n+  return new_device_buffer;\n+}\n+\n+Future<> TrackedDeviceBuffer::GetReadyFuture(PjRtMemorySpace* memory_space) {\n+  auto [promise, future] = Future<>::MakePromise();\n+  std::vector<tsl::RCReference<tsl::AsyncValue>> definition_events;\n+  definition_events.reserve(definition_events_.size());\n+  for (const auto& event : definition_events_) {\n+    definition_events.push_back(event.CopyRCRef());\n+  }\n+  absl::Span<tsl::RCReference<tsl::AsyncValue> const> definition_events_span =\n+      definition_events;\n+  tsl::RunWhenReady(\n+      definition_events_span,\n+      [promise = std::move(promise),\n+       definition_events = std::move(definition_events)]() mutable {\n+        for (auto& event : definition_events) {\n+          if (const absl::Status* error = event->GetErrorIfPresent()) {\n+            promise.Set(*error);\n+            return;\n+          }\n+        }\n+        promise.Set();\n+      });\n+  return future;\n+}\n+\n+void TrackedDeviceBuffer::Delete(PjRtMemorySpace* memory_space) {\n+  std::unique_ptr<TrackedDeviceBuffer> device_buffer(this);\n+  // All events already hold onto refs to the buffer to ensure liveness so there\n+  // is no work to do.\n+}\n+\n TrackedDeviceBuffer::StreamAndEventContainer\n TrackedDeviceBuffer::LockUseAndTransferUsageEvents() {\n   CHECK(in_use_);"
        },
        {
            "sha": "24ed1db45010b4c153ce7355c873aae67df4d4ab",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer.h",
            "status": "modified",
            "additions": 7,
            "deletions": 3,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3e202374c5ade99b1c937c871a257930f11fa53/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3e202374c5ade99b1c937c871a257930f11fa53/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h?ref=c3e202374c5ade99b1c937c871a257930f11fa53",
            "patch": "@@ -180,9 +180,7 @@ class TrackedDeviceBuffer : public AbstractTrackedDeviceBuffer {\n \n   void AddUsageEvent(tsl::RCReference<PjRtDeviceEvent> event) override;\n \n-  void Delete(PjRtMemorySpace* memory_space) override {\n-    LOG(FATAL) << \"Implement\";\n-  }\n+  void Delete(PjRtMemorySpace* memory_space) override;\n \n   absl::Status WaitUntilBufferReadyOnStream(std::intptr_t stream) override {\n     for (const BufferSequencingEventRef& event : definition_events()) {\n@@ -191,6 +189,12 @@ class TrackedDeviceBuffer : public AbstractTrackedDeviceBuffer {\n     return absl::OkStatus();\n   }\n \n+  absl::StatusOr<std::unique_ptr<AbstractTrackedDeviceBuffer>>\n+  CloneWithControlDependency(PjRtMemorySpace* memory_space,\n+                             Future<> dependency) override;\n+\n+  Future<> GetReadyFuture(PjRtMemorySpace* memory_space) override;\n+\n  private:\n   PjRtDevice* device_;\n "
        }
    ],
    "stats": {
        "total": 270,
        "additions": 89,
        "deletions": 181
    }
}