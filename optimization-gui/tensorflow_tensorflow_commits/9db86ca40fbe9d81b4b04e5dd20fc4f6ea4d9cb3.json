{
    "author": "sohaibiftikhar",
    "message": "[XLA:GPU]: Add int64_t to KernelArgument\n\nAdds support for int64_t as a kernel argument.\nThe int64_t itself is stored as a Pod data type storage.\n\nPiperOrigin-RevId: 810819954",
    "sha": "9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3",
    "files": [
        {
            "sha": "70b4f1b5e61c732869c9d98abff4e41de5eef9e0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3",
            "patch": "@@ -1067,8 +1067,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> LaunchCmd::Record(\n         \"Kernel not loaded on a command buffer executor: \", kernel_name_));\n   }\n \n-  absl::InlinedVector<std::variant<se::DeviceMemoryBase, se::TensorMap>, 4>\n-      kernel_args_variant;\n+  absl::InlinedVector<se::KernelArgument, 4> kernel_args_variant;\n   stream_executor::gpu::TmaMetadata tma_metadata =\n       tma_metadata_.value_or(se::gpu::TmaMetadata{});\n   for (int idx = 0; idx < args_.size(); ++idx) {"
        },
        {
            "sha": "9cf394b3f8533f48b5d8d89c99eac0b4a60b1270",
            "filename": "third_party/xla/xla/backends/gpu/runtime/kernel_thunk.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc?ref=9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3",
            "patch": "@@ -186,6 +186,11 @@ void PrintBufferContents(se::Stream* stream, int input_idx,\n   VLOG(100) << \"BUF(\" << input_idx << \") = \" << buffer_contents;\n }\n \n+void PrintBufferContents(se::Stream*, int input_idx, int64_t int_arg) {\n+  VLOG(100) << \"INT(\" << input_idx << \") = \";\n+  VLOG(100) << absl::StrFormat(\"%x \", int_arg);\n+}\n+\n static void PrintBufferContents(\n     se::Stream* stream, absl::Span<const se::KernelArgument> kernel_args) {\n   for (const auto& [input_idx, arg] : llvm::enumerate(kernel_args)) {"
        },
        {
            "sha": "125835edb009224fb4ebe76005d850cf8826271b",
            "filename": "third_party/xla/xla/stream_executor/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD?ref=9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3",
            "patch": "@@ -588,7 +588,9 @@ cc_library(\n         \":device_memory\",\n         \":launch_dim\",\n         \":stream\",\n+        \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n+        \"@com_google_absl//absl/functional:overload\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/meta:type_traits\",\n         \"@com_google_absl//absl/status\",\n@@ -837,18 +839,15 @@ xla_cc_test(\n     deps = [\n         \":device_memory\",\n         \":kernel\",\n-        \":kernel_spec\",\n         \":platform\",\n         \":platform_manager\",\n         \":stream_executor_h\",\n-        \":typed_kernel_factory\",\n         \"//xla/stream_executor/host:host_platform\",\n+        \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test_main\",\n         \"@com_google_absl//absl/types:span\",\n         \"@com_google_benchmark//:benchmark\",\n         \"@com_google_googletest//:gtest\",\n-        \"@local_tsl//tsl/platform:test\",\n-        \"@local_tsl//tsl/platform:test_benchmark\",\n     ],\n )\n "
        },
        {
            "sha": "6a738ebe6c69439dfd3f9a584e2cf57410102c27",
            "filename": "third_party/xla/xla/stream_executor/kernel.h",
            "status": "modified",
            "additions": 58,
            "deletions": 32,
            "changes": 90,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h?ref=9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3",
            "patch": "@@ -81,7 +81,9 @@ limitations under the License.\n #include <utility>\n #include <variant>\n \n+#include \"absl/base/optimization.h\"\n #include \"absl/container/inlined_vector.h\"\n+#include \"absl/functional/overload.h\"\n #include \"absl/log/check.h\"\n #include \"absl/meta/type_traits.h\"\n #include \"absl/status/status.h\"\n@@ -404,13 +406,18 @@ namespace internal {\n \n // An empty storage for packing just the device memory arguments, that are\n // stored directly in the `KernelArgsPackedArray`.\n-class EmptyArgs {};\n+struct EmptyArgs {\n+  static constexpr size_t kSize = 0;\n+};\n \n // A storage for POD generic arguments that are smaller than `size` and require\n // alignment smaller or equal to `alignment`.\n template <size_t capacity, size_t size = 8,\n           size_t alignment = alignof(std::max_align_t)>\n class PodArgs {\n+ public:\n+  static constexpr size_t kSize = size;\n+\n  protected:\n   template <typename T>\n   const std::byte* add_pod_argument(const T& arg) {\n@@ -514,7 +521,7 @@ class KernelArgsPackedArray : public KernelArgsPackedArrayBase, ArgsStorage {\n   size_t number_of_argument_addresses_ = 0;\n };\n \n-using KernelArgument = std::variant<DeviceMemoryBase, TensorMap>;\n+using KernelArgument = std::variant<DeviceMemoryBase, TensorMap, int64_t>;\n \n namespace internal {\n template <int n>\n@@ -530,43 +537,62 @@ std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(\n   return packed;\n }\n \n-template <int n>\n-std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(\n+template <int n, typename ArgsStorage>\n+std::unique_ptr<KernelArgsPackedArray<n, ArgsStorage>> PackKernelArgsImpl(\n     absl::Span<const KernelArgument> args, uint32_t shared_mem_bytes) {\n-  auto contains_tensor_map = [](absl::Span<const KernelArgument> args) -> bool {\n-    return absl::c_any_of(args, [](const auto& arg) {\n-      return std::holds_alternative<TensorMap>(arg);\n-    });\n-  };\n-\n-  if (contains_tensor_map(args)) {\n-    auto packed =\n-        std::make_unique<KernelArgsPackedArray<n, PodArgs<n, 128, 64>>>();\n-    for (auto& buf : args) {\n-      if (std::holds_alternative<DeviceMemoryBase>(buf)) {\n-        // Buffer argument.\n-        packed->add_device_memory_argument(std::get<DeviceMemoryBase>(buf));\n-      } else {\n-        // TMA descriptor argument.\n-        packed->add_argument(std::get<TensorMap>(buf).storage);\n-      }\n-    }\n-    if (shared_mem_bytes > 0) {\n-      packed->add_shared_bytes(shared_mem_bytes);\n-    }\n-    return packed;\n-  }\n-\n-  // No TensorMap arguments -> Can use EmptyArgs.\n-  auto packed = std::make_unique<KernelArgsPackedArray<n, EmptyArgs>>();\n-  for (auto& buf : args) {\n-    packed->add_device_memory_argument(std::get<DeviceMemoryBase>(buf));\n+  auto packed = std::make_unique<KernelArgsPackedArray<n, ArgsStorage>>();\n+  for (const auto& arg : args) {\n+    std::visit(\n+        absl::Overload{\n+            [&](const DeviceMemoryBase& device_memory) {\n+              packed->add_device_memory_argument(device_memory);\n+            },\n+            [&](int64_t int_arg) {\n+              if constexpr (ArgsStorage::kSize >= sizeof(int64_t)) {\n+                packed->add_argument(int_arg);\n+              }\n+            },\n+            [&](const TensorMap& tensor_map) {\n+              if constexpr (ArgsStorage::kSize >= sizeof(tensor_map.storage)) {\n+                packed->add_argument(tensor_map.storage);\n+              }\n+            },\n+        },\n+        arg);\n   }\n   if (shared_mem_bytes > 0) {\n     packed->add_shared_bytes(shared_mem_bytes);\n   }\n   return packed;\n }\n+\n+template <int n>\n+std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(\n+    absl::Span<const KernelArgument> args, uint32_t shared_mem_bytes) {\n+  const int32_t pod_size = [](absl::Span<const KernelArgument> args) {\n+    bool has_int = false;\n+    for (const auto& arg : args) {\n+      if (std::holds_alternative<TensorMap>(arg)) {\n+        return 128;\n+      }\n+      if (std::holds_alternative<int64_t>(arg)) {\n+        has_int = true;\n+      }\n+    }\n+    return has_int ? 64 : 0;\n+  }(args);\n+\n+  switch (pod_size) {\n+    case 128:\n+      return PackKernelArgsImpl<n, PodArgs<n, 128, 64>>(args, shared_mem_bytes);\n+    case 64:\n+      return PackKernelArgsImpl<n, PodArgs<n, 64, 64>>(args, shared_mem_bytes);\n+    case 0:\n+      return PackKernelArgsImpl<n, EmptyArgs>(args, shared_mem_bytes);\n+    default:\n+      ABSL_UNREACHABLE();\n+  }\n+}\n }  // namespace internal\n \n template <typename ArgType>"
        },
        {
            "sha": "0e1b219c8de2853ef691dec92694379bf00036e3",
            "filename": "third_party/xla/xla/stream_executor/kernel_test.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 4,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_test.cc?ref=9db86ca40fbe9d81b4b04e5dd20fc4f6ea4d9cb3",
            "patch": "@@ -25,13 +25,10 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"benchmark/benchmark.h\"\n #include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/kernel_spec.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n-#include \"xla/stream_executor/typed_kernel_factory.h\"\n-#include \"tsl/platform/test.h\"\n-#include \"tsl/platform/test_benchmark.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n \n namespace stream_executor {\n \n@@ -121,6 +118,22 @@ TEST(KernelTest, PackTupleArguments) {\n   ASSERT_EQ(f64, 3.0);\n }\n \n+TEST(KernelTest, PackArgumentsWithInt64) {\n+  std::vector<KernelArgument> args;\n+  DeviceMemoryBase somemem(reinterpret_cast<void*>(0x12345678));\n+  int64_t someint64 = 1234;\n+  args.emplace_back(somemem);\n+  args.emplace_back(someint64);\n+  TF_ASSERT_OK_AND_ASSIGN(auto packed_args_ptr, PackKernelArgs<KernelArgument>(\n+                                                    args, KernelMetadata()));\n+  ASSERT_EQ(packed_args_ptr->number_of_arguments(), 2);\n+  ASSERT_EQ(packed_args_ptr->number_of_shared_bytes(), 0);\n+  const auto packed = packed_args_ptr->argument_addresses();\n+  ASSERT_EQ(packed.size(), 2);\n+  ASSERT_EQ(*reinterpret_cast<const void* const*>(packed[0]), somemem.opaque());\n+  ASSERT_EQ(*reinterpret_cast<const int64_t*>(packed[1]), someint64);\n+}\n+\n //===----------------------------------------------------------------------===//\n // Performance benchmarks below\n //===----------------------------------------------------------------------===//"
        }
    ],
    "stats": {
        "total": 126,
        "additions": 84,
        "deletions": 42
    }
}