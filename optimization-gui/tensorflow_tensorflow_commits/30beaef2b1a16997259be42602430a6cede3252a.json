{
    "author": "tensorflower-gardener",
    "message": "Integrate LLVM at llvm/llvm-project@2bc22ea02edd\n\nUpdates LLVM usage to match\n[2bc22ea02edd](https://github.com/llvm/llvm-project/commit/2bc22ea02edd)\n\nPiperOrigin-RevId: 829691657",
    "sha": "30beaef2b1a16997259be42602430a6cede3252a",
    "files": [
        {
            "sha": "a6f7fe5dc6ff6ab42150111d53281f87d913ad14",
            "filename": "third_party/xla/third_party/llvm/generated.patch",
            "status": "modified",
            "additions": 88,
            "deletions": 0,
            "changes": 88,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch?ref=30beaef2b1a16997259be42602430a6cede3252a",
            "patch": "@@ -1 +1,89 @@\n Auto generated patch. Do not edit or delete it, even if empty.\n+diff -ruN --strip-trailing-cr a/llvm/lib/Target/BPF/BPFAsmPrinter.cpp b/llvm/lib/Target/BPF/BPFAsmPrinter.cpp\n+--- a/llvm/lib/Target/BPF/BPFAsmPrinter.cpp\n++++ b/llvm/lib/Target/BPF/BPFAsmPrinter.cpp\n+@@ -176,10 +176,6 @@\n+         if (const GlobalValue *GV = Op.getGlobal())\n+           if (GV->getName() == BPF_TRAP)\n+             SawTrapCall = true;\n+-      } else if (Op.isSymbol()) {\n+-        if (const MCSymbol *Sym = Op.getMCSymbol())\n+-          if (Sym->getName() == BPF_TRAP)\n+-            SawTrapCall = true;\n+       }\n+     }\n+   }\n+diff -ruN --strip-trailing-cr a/llvm/test/Analysis/CostModel/AArch64/sincos.ll b/llvm/test/Analysis/CostModel/AArch64/sincos.ll\n+--- a/llvm/test/Analysis/CostModel/AArch64/sincos.ll\n++++ b/llvm/test/Analysis/CostModel/AArch64/sincos.ll\n+@@ -38,14 +38,14 @@\n+ ;\n+ ; SINCOS_STRET-LABEL: 'sincos'\n+ ; SINCOS_STRET:  Cost Model: Found an estimated cost of 1 for instruction: %f16 = call { half, half } @llvm.sincos.f16(half poison)\n+-; SINCOS_STRET:  Cost Model: Found an estimated cost of 2 for instruction: %f32 = call { float, float } @llvm.sincos.f32(float poison)\n+-; SINCOS_STRET:  Cost Model: Found an estimated cost of 2 for instruction: %f64 = call { double, double } @llvm.sincos.f64(double poison)\n++; SINCOS_STRET:  Cost Model: Found an estimated cost of 10 for instruction: %f32 = call { float, float } @llvm.sincos.f32(float poison)\n++; SINCOS_STRET:  Cost Model: Found an estimated cost of 10 for instruction: %f64 = call { double, double } @llvm.sincos.f64(double poison)\n+ ; SINCOS_STRET:  Cost Model: Found an estimated cost of 10 for instruction: %f128 = call { fp128, fp128 } @llvm.sincos.f128(fp128 poison)\n+ ; SINCOS_STRET:  Cost Model: Found an estimated cost of 36 for instruction: %v8f16 = call { <8 x half>, <8 x half> } @llvm.sincos.v8f16(<8 x half> poison)\n+-; SINCOS_STRET:  Cost Model: Found an estimated cost of 20 for instruction: %v4f32 = call { <4 x float>, <4 x float> } @llvm.sincos.v4f32(<4 x float> poison)\n+-; SINCOS_STRET:  Cost Model: Found an estimated cost of 8 for instruction: %v2f64 = call { <2 x double>, <2 x double> } @llvm.sincos.v2f64(<2 x double> poison)\n++; SINCOS_STRET:  Cost Model: Found an estimated cost of 52 for instruction: %v4f32 = call { <4 x float>, <4 x float> } @llvm.sincos.v4f32(<4 x float> poison)\n++; SINCOS_STRET:  Cost Model: Found an estimated cost of 24 for instruction: %v2f64 = call { <2 x double>, <2 x double> } @llvm.sincos.v2f64(<2 x double> poison)\n+ ; SINCOS_STRET:  Cost Model: Found an estimated cost of 10 for instruction: %v1f128 = call { <1 x fp128>, <1 x fp128> } @llvm.sincos.v1f128(<1 x fp128> poison)\n+-; SINCOS_STRET:  Cost Model: Found an estimated cost of 40 for instruction: %v8f32 = call { <8 x float>, <8 x float> } @llvm.sincos.v8f32(<8 x float> poison)\n++; SINCOS_STRET:  Cost Model: Found an estimated cost of 104 for instruction: %v8f32 = call { <8 x float>, <8 x float> } @llvm.sincos.v8f32(<8 x float> poison)\n+ ; SINCOS_STRET:  Cost Model: Invalid cost for instruction: %nxv8f16 = call { <vscale x 8 x half>, <vscale x 8 x half> } @llvm.sincos.nxv8f16(<vscale x 8 x half> poison)\n+ ; SINCOS_STRET:  Cost Model: Invalid cost for instruction: %nxv4f32 = call { <vscale x 4 x float>, <vscale x 4 x float> } @llvm.sincos.nxv4f32(<vscale x 4 x float> poison)\n+ ; SINCOS_STRET:  Cost Model: Invalid cost for instruction: %nxv2f64 = call { <vscale x 2 x double>, <vscale x 2 x double> } @llvm.sincos.nxv2f64(<vscale x 2 x double> poison)\n+diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp b/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp\n+--- a/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp\n++++ b/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp\n+@@ -2568,11 +2568,6 @@\n+     auto trailingReassocs = ArrayRef<int64_t>(reassoc).drop_front();\n+     auto stride = SaturatedInteger::wrap(resultStrides[resultStrideIndex--]);\n+     for (int64_t idx : llvm::reverse(trailingReassocs)) {\n+-      // Dimensions of size 1 should be skipped, because their strides are\n+-      // meaningless and could have any arbitrary value.\n+-      if (srcShape[idx - 1] == 1)\n+-        continue;\n+-\n+       stride = stride * SaturatedInteger::wrap(srcShape[idx]);\n+ \n+       // Both source and result stride must have the same static value. In that\n+@@ -2587,6 +2582,11 @@\n+       if (strict && (stride.saturated || srcStride.saturated))\n+         return failure();\n+ \n++      // Dimensions of size 1 should be skipped, because their strides are\n++      // meaningless and could have any arbitrary value.\n++      if (srcShape[idx - 1] == 1)\n++        continue;\n++\n+       if (!stride.saturated && !srcStride.saturated && stride != srcStride)\n+         return failure();\n+     }\n+diff -ruN --strip-trailing-cr a/mlir/test/Dialect/MemRef/ops.mlir b/mlir/test/Dialect/MemRef/ops.mlir\n+--- a/mlir/test/Dialect/MemRef/ops.mlir\n++++ b/mlir/test/Dialect/MemRef/ops.mlir\n+@@ -440,8 +440,7 @@\n+          %arg4: index,\n+          %arg5: index,\n+          %arg6: index,\n+-         %arg7: memref<4x?x4xf32>,\n+-         %arg8: memref<1x1x18x?xsi8, strided<[?, ?, ?, 1], offset: ?>>) {\n++         %arg7: memref<4x?x4xf32>) {\n+ //       CHECK:   memref.collapse_shape {{.*}} {{\\[}}[0, 1], [2]]\n+ //  CHECK-SAME:     memref<?x?x?xf32> into memref<?x?xf32>\n+   %0 = memref.collapse_shape %arg0 [[0, 1], [2]] :\n+@@ -490,10 +489,6 @@\n+ //       CHECK:   memref.expand_shape {{.*}} {{\\[}}[0, 1], [2], [3, 4]]\n+   %4 = memref.expand_shape %arg7 [[0, 1], [2], [3, 4]] output_shape [2, 2, %arg4, 2, 2]\n+         : memref<4x?x4xf32> into memref<2x2x?x2x2xf32>\n+-\n+-//       CHECK:   memref.collapse_shape {{.*}} {{\\[}}[0, 1], [2], [3]]\n+-//  CHECK-SAME:     memref<1x1x18x?xsi8, strided<[?, ?, ?, 1], offset: ?>> into memref<1x18x?xsi8, strided<[?, ?, 1], offset: ?>>\n+-  %5 = memref.collapse_shape %arg8 [[0, 1], [2], [3]] : memref<1x1x18x?xsi8, strided<[?, ?, ?, 1], offset: ?>> into memref<1x18x?xsi8, strided<[?, ?, 1], offset: ?>>\n+   return\n+ }\n+ "
        },
        {
            "sha": "abdee76004c3a160077283a929298a3bae89fee1",
            "filename": "third_party/xla/third_party/llvm/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl?ref=30beaef2b1a16997259be42602430a6cede3252a",
            "patch": "@@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n \n def repo(name):\n     \"\"\"Imports LLVM.\"\"\"\n-    LLVM_COMMIT = \"42a8ff877d47131ecb1280a1cc7e5e3c3bca6952\"\n-    LLVM_SHA256 = \"f768c5c3b987f68318b8ab3dd4530e54988dfe7d6bfb9b7c9c96acf503367d50\"\n+    LLVM_COMMIT = \"2bc22ea02edda5926f3e53f141def9bf212ac1db\"\n+    LLVM_SHA256 = \"4a034eda852b3c2d448d38e8661cbac45ae2233a29defeb55913fa5205cd29f7\"\n \n     tf_http_archive(\n         name = name,"
        },
        {
            "sha": "636fd137defad7ce952b3b14c8062e6c2a4dbdba",
            "filename": "third_party/xla/third_party/shardy/temporary.patch",
            "status": "modified",
            "additions": 1617,
            "deletions": 5,
            "changes": 1622,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch?ref=30beaef2b1a16997259be42602430a6cede3252a",
            "patch": "@@ -1,15 +1,1627 @@\n+diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch\n+index 509398d..a6f7fe5 100644\n+--- a/third_party/llvm/generated.patch\n++++ b/third_party/llvm/generated.patch\n+@@ -1 +1,89 @@\n+ Auto generated patch. Do not edit or delete it, even if empty.\n++diff -ruN --strip-trailing-cr a/llvm/lib/Target/BPF/BPFAsmPrinter.cpp b/llvm/lib/Target/BPF/BPFAsmPrinter.cpp\n++--- a/llvm/lib/Target/BPF/BPFAsmPrinter.cpp\n+++++ b/llvm/lib/Target/BPF/BPFAsmPrinter.cpp\n++@@ -176,10 +176,6 @@\n++         if (const GlobalValue *GV = Op.getGlobal())\n++           if (GV->getName() == BPF_TRAP)\n++             SawTrapCall = true;\n++-      } else if (Op.isSymbol()) {\n++-        if (const MCSymbol *Sym = Op.getMCSymbol())\n++-          if (Sym->getName() == BPF_TRAP)\n++-            SawTrapCall = true;\n++       }\n++     }\n++   }\n++diff -ruN --strip-trailing-cr a/llvm/test/Analysis/CostModel/AArch64/sincos.ll b/llvm/test/Analysis/CostModel/AArch64/sincos.ll\n++--- a/llvm/test/Analysis/CostModel/AArch64/sincos.ll\n+++++ b/llvm/test/Analysis/CostModel/AArch64/sincos.ll\n++@@ -38,14 +38,14 @@\n++ ;\n++ ; SINCOS_STRET-LABEL: 'sincos'\n++ ; SINCOS_STRET:  Cost Model: Found an estimated cost of 1 for instruction: %f16 = call { half, half } @llvm.sincos.f16(half poison)\n++-; SINCOS_STRET:  Cost Model: Found an estimated cost of 2 for instruction: %f32 = call { float, float } @llvm.sincos.f32(float poison)\n++-; SINCOS_STRET:  Cost Model: Found an estimated cost of 2 for instruction: %f64 = call { double, double } @llvm.sincos.f64(double poison)\n+++; SINCOS_STRET:  Cost Model: Found an estimated cost of 10 for instruction: %f32 = call { float, float } @llvm.sincos.f32(float poison)\n+++; SINCOS_STRET:  Cost Model: Found an estimated cost of 10 for instruction: %f64 = call { double, double } @llvm.sincos.f64(double poison)\n++ ; SINCOS_STRET:  Cost Model: Found an estimated cost of 10 for instruction: %f128 = call { fp128, fp128 } @llvm.sincos.f128(fp128 poison)\n++ ; SINCOS_STRET:  Cost Model: Found an estimated cost of 36 for instruction: %v8f16 = call { <8 x half>, <8 x half> } @llvm.sincos.v8f16(<8 x half> poison)\n++-; SINCOS_STRET:  Cost Model: Found an estimated cost of 20 for instruction: %v4f32 = call { <4 x float>, <4 x float> } @llvm.sincos.v4f32(<4 x float> poison)\n++-; SINCOS_STRET:  Cost Model: Found an estimated cost of 8 for instruction: %v2f64 = call { <2 x double>, <2 x double> } @llvm.sincos.v2f64(<2 x double> poison)\n+++; SINCOS_STRET:  Cost Model: Found an estimated cost of 52 for instruction: %v4f32 = call { <4 x float>, <4 x float> } @llvm.sincos.v4f32(<4 x float> poison)\n+++; SINCOS_STRET:  Cost Model: Found an estimated cost of 24 for instruction: %v2f64 = call { <2 x double>, <2 x double> } @llvm.sincos.v2f64(<2 x double> poison)\n++ ; SINCOS_STRET:  Cost Model: Found an estimated cost of 10 for instruction: %v1f128 = call { <1 x fp128>, <1 x fp128> } @llvm.sincos.v1f128(<1 x fp128> poison)\n++-; SINCOS_STRET:  Cost Model: Found an estimated cost of 40 for instruction: %v8f32 = call { <8 x float>, <8 x float> } @llvm.sincos.v8f32(<8 x float> poison)\n+++; SINCOS_STRET:  Cost Model: Found an estimated cost of 104 for instruction: %v8f32 = call { <8 x float>, <8 x float> } @llvm.sincos.v8f32(<8 x float> poison)\n++ ; SINCOS_STRET:  Cost Model: Invalid cost for instruction: %nxv8f16 = call { <vscale x 8 x half>, <vscale x 8 x half> } @llvm.sincos.nxv8f16(<vscale x 8 x half> poison)\n++ ; SINCOS_STRET:  Cost Model: Invalid cost for instruction: %nxv4f32 = call { <vscale x 4 x float>, <vscale x 4 x float> } @llvm.sincos.nxv4f32(<vscale x 4 x float> poison)\n++ ; SINCOS_STRET:  Cost Model: Invalid cost for instruction: %nxv2f64 = call { <vscale x 2 x double>, <vscale x 2 x double> } @llvm.sincos.nxv2f64(<vscale x 2 x double> poison)\n++diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp b/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp\n++--- a/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp\n+++++ b/mlir/lib/Dialect/MemRef/IR/MemRefOps.cpp\n++@@ -2568,11 +2568,6 @@\n++     auto trailingReassocs = ArrayRef<int64_t>(reassoc).drop_front();\n++     auto stride = SaturatedInteger::wrap(resultStrides[resultStrideIndex--]);\n++     for (int64_t idx : llvm::reverse(trailingReassocs)) {\n++-      // Dimensions of size 1 should be skipped, because their strides are\n++-      // meaningless and could have any arbitrary value.\n++-      if (srcShape[idx - 1] == 1)\n++-        continue;\n++-\n++       stride = stride * SaturatedInteger::wrap(srcShape[idx]);\n++ \n++       // Both source and result stride must have the same static value. In that\n++@@ -2587,6 +2582,11 @@\n++       if (strict && (stride.saturated || srcStride.saturated))\n++         return failure();\n++ \n+++      // Dimensions of size 1 should be skipped, because their strides are\n+++      // meaningless and could have any arbitrary value.\n+++      if (srcShape[idx - 1] == 1)\n+++        continue;\n+++\n++       if (!stride.saturated && !srcStride.saturated && stride != srcStride)\n++         return failure();\n++     }\n++diff -ruN --strip-trailing-cr a/mlir/test/Dialect/MemRef/ops.mlir b/mlir/test/Dialect/MemRef/ops.mlir\n++--- a/mlir/test/Dialect/MemRef/ops.mlir\n+++++ b/mlir/test/Dialect/MemRef/ops.mlir\n++@@ -440,8 +440,7 @@\n++          %arg4: index,\n++          %arg5: index,\n++          %arg6: index,\n++-         %arg7: memref<4x?x4xf32>,\n++-         %arg8: memref<1x1x18x?xsi8, strided<[?, ?, ?, 1], offset: ?>>) {\n+++         %arg7: memref<4x?x4xf32>) {\n++ //       CHECK:   memref.collapse_shape {{.*}} {{\\[}}[0, 1], [2]]\n++ //  CHECK-SAME:     memref<?x?x?xf32> into memref<?x?xf32>\n++   %0 = memref.collapse_shape %arg0 [[0, 1], [2]] :\n++@@ -490,10 +489,6 @@\n++ //       CHECK:   memref.expand_shape {{.*}} {{\\[}}[0, 1], [2], [3, 4]]\n++   %4 = memref.expand_shape %arg7 [[0, 1], [2], [3, 4]] output_shape [2, 2, %arg4, 2, 2]\n++         : memref<4x?x4xf32> into memref<2x2x?x2x2xf32>\n++-\n++-//       CHECK:   memref.collapse_shape {{.*}} {{\\[}}[0, 1], [2], [3]]\n++-//  CHECK-SAME:     memref<1x1x18x?xsi8, strided<[?, ?, ?, 1], offset: ?>> into memref<1x18x?xsi8, strided<[?, ?, 1], offset: ?>>\n++-  %5 = memref.collapse_shape %arg8 [[0, 1], [2], [3]] : memref<1x1x18x?xsi8, strided<[?, ?, ?, 1], offset: ?>> into memref<1x18x?xsi8, strided<[?, ?, 1], offset: ?>>\n++   return\n++ }\n++ \n diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl\n-index 0859165..32e6a7a 100644\n+index 32e6a7a..abdee76 100644\n --- a/third_party/llvm/workspace.bzl\n +++ b/third_party/llvm/workspace.bzl\n @@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n  \n  def repo(name):\n      \"\"\"Imports LLVM.\"\"\"\n--    LLVM_COMMIT = \"22079e3f3698d5c367c7b67f63de8c838791ae76\"\n--    LLVM_SHA256 = \"d5616e9c0f4b761f13da5535a0d9ec94acf4ae5226bbec3e47ac2929ea60cac2\"\n-+    LLVM_COMMIT = \"42a8ff877d47131ecb1280a1cc7e5e3c3bca6952\"\n-+    LLVM_SHA256 = \"f768c5c3b987f68318b8ab3dd4530e54988dfe7d6bfb9b7c9c96acf503367d50\"\n+-    LLVM_COMMIT = \"42a8ff877d47131ecb1280a1cc7e5e3c3bca6952\"\n+-    LLVM_SHA256 = \"f768c5c3b987f68318b8ab3dd4530e54988dfe7d6bfb9b7c9c96acf503367d50\"\n++    LLVM_COMMIT = \"2bc22ea02edda5926f3e53f141def9bf212ac1db\"\n++    LLVM_SHA256 = \"4a034eda852b3c2d448d38e8661cbac45ae2233a29defeb55913fa5205cd29f7\"\n  \n      tf_http_archive(\n          name = name,\n+diff --git a/third_party/stablehlo/temporary.patch b/third_party/stablehlo/temporary.patch\n+index 0778daf..a42cbd7 100755\n+--- a/third_party/stablehlo/temporary.patch\n++++ b/third_party/stablehlo/temporary.patch\n+@@ -1,70 +1,130 @@\n+-diff --ruN a/stablehlo/BUILD.bazel b/stablehlo/BUILD.bazel\n+---- stablehlo/BUILD.bazel\n+-+++ stablehlo/BUILD.bazel\n+-@@ -1105,6 +1105,24 @@\n+-     tblgen = \"@llvm-project//mlir:mlir-tblgen\",\n+-     td_file = \"stablehlo/transforms/Passes.td\",\n+-     deps = [\"@llvm-project//mlir:PassBaseTdFiles\"],\n+-+)\n+-+\n+-+cc_library(\n+-+    name = \"stablehlo_broadcast_lowering\",\n+-+    srcs = [\n+-+        \"stablehlo/transforms/StablehloBroadcastLowering.cpp\",\n+-+    ],\n+-+    hdrs = [\n+-+        \"stablehlo/transforms/StablehloBroadcastLowering.h\",\n+-+    ],\n+-+    strip_include_prefix = \".\",\n+-+    deps = [\n+-+        \":stablehlo_ops\",\n+-+        \"@llvm-project//llvm:Support\",\n+-+        \"@llvm-project//mlir:IR\",\n+-+        \"@llvm-project//mlir:ShapeDialect\",\n+-+        \"@llvm-project//mlir:Support\",\n+-+    ],\n+- )\n+- \n+- cc_library(\n++diff --ruN a/stablehlo/stablehlo/conversions/linalg/tests/miscellaneous.mlir b/stablehlo/stablehlo/conversions/linalg/tests/miscellaneous.mlir\n++--- stablehlo/stablehlo/conversions/linalg/tests/miscellaneous.mlir\n+++++ stablehlo/stablehlo/conversions/linalg/tests/miscellaneous.mlir\n++@@ -768,7 +768,7 @@\n++ // CHECK-PRIMITIVE: %[[MAP:.+]] = linalg.map\n++ // CHECK-PRIMITIVE-SAME: ins(%[[ARG0]], %[[ARG1]]\n++ // CHECK-PRIMITIVE-SAME: outs(%[[INIT]] : tensor<?xi1>)\n++-// CHECK-PRIMITIVE-NEXT: (%[[A:.+]]: complex<f32>, %[[B:.+]]: complex<f32>) {\n+++// CHECK-PRIMITIVE-NEXT: (%[[A:.+]]: complex<f32>, %[[B:.+]]: complex<f32>, %{{.+}}: i1) {\n++ // CHECK-PRIMITIVE: %[[RE1:.+]] = complex.re %[[A]] : complex<f32>\n++ // CHECK-PRIMITIVE: %[[RE2:.+]] = complex.re %[[B]] : complex<f32>\n++ // CHECK-PRIMITIVE: %[[CMP:.+]] = arith.cmpf oeq, %[[RE1]], %[[RE2]] : f32\n++diff --ruN a/stablehlo/stablehlo/conversions/linalg/tests/pointwise.mlir b/stablehlo/stablehlo/conversions/linalg/tests/pointwise.mlir\n++--- stablehlo/stablehlo/conversions/linalg/tests/pointwise.mlir\n+++++ stablehlo/stablehlo/conversions/linalg/tests/pointwise.mlir\n++@@ -714,7 +714,7 @@\n++ // CHECK-PRIMITIVE: linalg.map\n++ // CHECK-PRIMITIVE-SAME: ins(\n++ // CHECK-PRIMITIVE-SAME: outs(\n++-// CHECK-PRIMITIVE-NEXT: (%[[LHS_IN:[a-zA-Z0-9]*]]: bf16, %[[RHS_IN:.*]]: bf16) {\n+++// CHECK-PRIMITIVE-NEXT: (%[[LHS_IN:[a-zA-Z0-9]*]]: bf16, %[[RHS_IN:.*]]: bf16, %[[RESULT_OUT:.*]]: i1) {\n++ // CHECK-PRIMITIVE-NEXT:   %[[LHS_INT:.*]] = arith.bitcast %[[LHS_IN]] : bf16 to i16\n++ // CHECK-PRIMITIVE-NEXT:   %[[LHS_CMP:.*]] = arith.cmpi slt, %[[LHS_INT]], %[[C0]] : i16\n++ // CHECK-PRIMITIVE-NEXT:   %[[LHS_SUB:.*]] = arith.subi %[[C32767]], %[[LHS_INT]] : i16\n++@@ -937,7 +937,7 @@\n++ // CHECK-PRIMITIVE-SAME:   ins(%[[LHS]], %[[RHS]] : tensor<2x?xf32>, tensor<2x?xf32>)\n++ // CHECK-PRIMITIVE-SAME:   outs(%[[DST]] : tensor<2x?xf32>)\n++ // CHECK-PRIMITIVE-SAME:   {someattr}\n++-// CHECK-PRIMITIVE:      (%[[LHS_:.*]]: f32, %[[RHS_:.*]]: f32) {\n+++// CHECK-PRIMITIVE:      (%[[LHS_:.*]]: f32, %[[RHS_:.*]]: f32, %[[RESULT_OUT:.*]]: f32) {\n++ // CHECK-PRIMITIVE:        %[[RES:.*]] = arith.select %[[PRED_ELEM]], %[[LHS_]], %[[RHS_]] : f32\n++ // CHECK-PRIMITIVE:        linalg.yield %[[RES]]\n++ \n++@@ -978,7 +978,7 @@\n++ // CHECK-PRIMITIVE-SAME:   ins(%[[LHS]], %[[RHS]] : tensor<2x?xf32>, tensor<2x?xf32>)\n++ // CHECK-PRIMITIVE-SAME:   outs(%[[DST]] : tensor<2x?xf32>)\n++ // CHECK-PRIMITIVE-SAME:   {someattr}\n++-// CHECK-PRIMITIVE:      (%[[LHS_:.*]]: f32, %[[RHS_:.*]]: f32) {\n+++// CHECK-PRIMITIVE:      (%[[LHS_:.*]]: f32, %[[RHS_:.*]]: f32, %[[RESULT_OUT:.*]]: f32) {\n++ // CHECK-PRIMITIVE:        linalg.yield %[[LHS_]]\n++ \n++ // -----\n++@@ -1416,7 +1416,7 @@\n++ \n++ // CHECK-PRIMITIVE: %[[INIT:.*]] = tensor.empty\n++ // CHECK-PRIMITIVE: %[[RESULT:.*]] = linalg.map ins(%[[LB]], %[[X]], %[[UB]] : tensor<4xf32>, tensor<4xf32>, tensor<4xf32>) outs(%[[INIT]] : tensor<4xf32>)\n++-// CHECK-PRIMITIVE: (%[[SCALAR_LB:.*]]: f32, %[[SCALAR_X:.*]]: f32, %[[SCALAR_UB:.*]]: f32)\n+++// CHECK-PRIMITIVE: (%[[SCALAR_LB:.*]]: f32, %[[SCALAR_X:.*]]: f32, %[[SCALAR_UB:.*]]: f32, %[[RESULT_OUT:.*]]: f32)\n++ // CHECK-PRIMITIVE:   %[[MAX:.*]] = arith.maximumf %[[SCALAR_LB]], %[[SCALAR_X]] : f32\n++ // CHECK-PRIMITIVE:   %[[MIN:.*]] = arith.minimumf %[[MAX]], %[[SCALAR_UB]] : f32\n++ // CHECK-PRIMITIVE:   linalg.yield %[[MIN]]\n++@@ -1478,7 +1478,7 @@\n++ // CHECK-PRIMITIVE-DAG: %[[SCALAR_LB:.*]] = tensor.extract %[[LB]]\n++ // CHECK-PRIMITIVE-DAG: %[[SCALAR_UB:.*]] = tensor.extract %[[UB]]\n++ // CHECK-PRIMITIVE: %[[RESULT:.*]] = linalg.map ins(%[[X]] : tensor<?xf32>) outs(%[[INIT]] : tensor<?xf32>)\n++-// CHECK-PRIMITIVE: (%[[SCALAR_X:.*]]: f32)\n+++// CHECK-PRIMITIVE: (%[[SCALAR_X:.*]]: f32, %[[RESULT_OUT:.*]]: f32)\n++ // CHECK-PRIMITIVE:   %[[MAX:.*]] = arith.maximumf %[[SCALAR_LB]], %[[SCALAR_X]] : f32\n++ // CHECK-PRIMITIVE:   %[[MIN:.*]] = arith.minimumf %[[MAX]], %[[SCALAR_UB]] : f32\n++ // CHECK-PRIMITIVE:   linalg.yield %[[MIN]]\n++@@ -1554,7 +1554,7 @@\n++   // CHECK:   linalg.yield %[[V_NOT]] : i32\n++   // CHECK-PRIMITIVE: %[[CST_N1:.+]] = arith.constant -1 : i32\n++   // CHECK-PRIMITIVE: linalg.map\n++-  // CHECK-PRIMITIVE:   (%[[IN:.+]]: i32)\n+++  // CHECK-PRIMITIVE:   (%[[IN:.+]]: i32, %[[RESULT_OUT:.+]]: i32)\n++   // CHECK-PRIMITIVE:   %[[V_NOT:.+]] = arith.xori %[[IN]], %[[CST_N1]] : i32\n++   // CHECK-PRIMITIVE:   linalg.yield %[[V_NOT]] : i32\n++   %0 = \"stablehlo.not\"(%arg) : (tensor<2x2xi32>) -> tensor<2x2xi32>\n++diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/StablehloLegalizeToLinalg.cpp b/stablehlo/stablehlo/conversions/linalg/transforms/StablehloLegalizeToLinalg.cpp\n++--- stablehlo/stablehlo/conversions/linalg/transforms/StablehloLegalizeToLinalg.cpp\n+++++ stablehlo/stablehlo/conversions/linalg/transforms/StablehloLegalizeToLinalg.cpp\n++@@ -1748,6 +1748,12 @@\n++ \n++     rewriter.applySignatureConversion(&region.front(), signatureConverter,\n++                                       getTypeConverter());\n+++    auto& blocks = linalgOp.getMapper().getBlocks();\n+++    if (blocks.empty()) {\n+++      return rewriter.notifyMatchFailure(op, \"expected at least one block\");\n+++    }\n+++    blocks.front().addArgument(resultType.getElementType(), loc);\n+++\n++     auto result = rewriter.createOrFold<tensor::CastOp>(loc, resultType,\n++                                                         linalgOp.getResults());\n++     rewriter.replaceOp(op, result);\n++diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToArith.cpp b/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToArith.cpp\n++--- stablehlo/stablehlo/conversions/linalg/transforms/StablehloToArith.cpp\n+++++ stablehlo/stablehlo/conversions/linalg/transforms/StablehloToArith.cpp\n++@@ -33,6 +33,7 @@\n++ \n++ template <typename OpTy>\n++ struct ScalarHloToFuncPatterns final : OpConversionPattern<OpTy> {\n+++  // NOLINTNEXTLINE(clang-diagnostic-shadow-field)\n++   ScalarHloToFuncPatterns(TypeConverter& typeConverter, MLIRContext* context,\n++                           PatternBenefit benefit = 1)\n++       : OpConversionPattern<OpTy>(typeConverter, context, benefit) {}\n++@@ -51,6 +52,7 @@\n++ template <typename OpTy>\n++ struct ScalarHloToArithmeticPattern final : OpConversionPattern<OpTy> {\n++   ScalarHloToArithmeticPattern(\n+++      // NOLINTNEXTLINE(clang-diagnostic-shadow-field)\n++       TypeConverter& typeConverter, MLIRContext* context,\n++       llvm::function_ref<bool(Operation*)> filterFn = nullptr,\n++       PatternBenefit benefit = 1)\n++diff --ruN a/stablehlo/stablehlo/dialect/Base.td b/stablehlo/stablehlo/dialect/Base.td\n++--- stablehlo/stablehlo/dialect/Base.td\n+++++ stablehlo/stablehlo/dialect/Base.td\n++@@ -152,7 +152,7 @@\n++     AnyTypeOf<[HLO_PerAxisQuantizedSignedInt, HLO_PerAxisQuantizedUnsignedInt], \"per-axis integer quantized\">;\n++ \n++ // Token type.\n++-def HLO_Token : Type<CPred<\"::llvm::isa<::mlir::stablehlo::TokenType>($_self)\">, \"token\">;\n+++def HLO_Token : Type<CPred<\"::llvm::isa<TokenType>($_self)\">, \"token\">;\n++ \n++ // Any integer tensor types\n++ def HLO_IntTensor : RankedTensorOf<[HLO_Int]>;\n+ diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.cpp b/stablehlo/stablehlo/dialect/StablehloOps.cpp\n+ --- stablehlo/stablehlo/dialect/StablehloOps.cpp\n+ +++ stablehlo/stablehlo/dialect/StablehloOps.cpp\n+-@@ -3275,12 +3275,12 @@\n+- // Entry point for Attribute printing, TableGen generated code will handle the\n+- // dispatch to the individual classes.\n+- void StablehloDialect::printAttribute(Attribute attr,\n+--                                      DialectAsmPrinter& os) const {\n+-+                                      DialectAsmPrinter& printer) const {\n+-   if (auto type_extensions = dyn_cast<TypeExtensionsAttr>(attr)) {\n+--    hlo::printTypeExtensions(cast<hlo::BoundedAttrInterface>(attr), os);\n+-+    hlo::printTypeExtensions(cast<hlo::BoundedAttrInterface>(attr), printer);\n+-     return;\n+-   }\n+--  LogicalResult result = generatedAttributePrinter(attr, os);\n+-+  LogicalResult result = generatedAttributePrinter(attr, printer);\n+-   (void)result;\n+-   assert(succeeded(result));\n+- }\n+-diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.h b/stablehlo/stablehlo/dialect/StablehloOps.h\n+---- stablehlo/stablehlo/dialect/StablehloOps.h\n+-+++ stablehlo/stablehlo/dialect/StablehloOps.h\n+-@@ -93,13 +93,14 @@\n+-   Type parseType(DialectAsmParser& parser) const override;\n+- \n+-   // Prints a type registered to this dialect.\n+--  void printType(Type type, DialectAsmPrinter& os) const override;\n+-+  void printType(Type type, DialectAsmPrinter& printer) const override;\n+- \n+-   // Parses an attribute registered to this dialect.\n+-   Attribute parseAttribute(DialectAsmParser& parser, Type type) const override;\n+- \n+-   // Prints an attribute registered to this dialect.\n+--  void printAttribute(Attribute attr, DialectAsmPrinter& os) const override;\n+-+  void printAttribute(Attribute attr,\n+-+                      DialectAsmPrinter& printer) const override;\n+- \n+-   // Get the set dialect version.\n+-   std::optional<StablehloDialectVersion> getVersion() const;\n++@@ -3164,6 +3164,7 @@\n++ using mlir::hlo::printVariadicOperandWithAttribute;\n++ using mlir::hlo::printVariadicSameOperandsAndResultType;\n++ \n+++using mlir::stablehlo::TokenType;\n++ #define GET_OP_CLASSES\n++ #include \"stablehlo/dialect/StablehloOps.cpp.inc\"\n++ \n+ diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/AttrTypeBuilderUtilTest.cpp b/stablehlo/stablehlo/integrations/cpp/builder/AttrTypeBuilderUtilTest.cpp\n+ --- stablehlo/stablehlo/integrations/cpp/builder/AttrTypeBuilderUtilTest.cpp\n+ +++ stablehlo/stablehlo/integrations/cpp/builder/AttrTypeBuilderUtilTest.cpp\n+@@ -89,6 +149,71 @@ diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/MlirBuilderTest.cpp b/\n+  #include \"llvm/Support/raw_ostream.h\"\n+  #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+  #include \"mlir/IR/BuiltinOps.h\"\n++diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.cpp b/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.cpp\n++--- stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.cpp\n+++++ stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.cpp\n++@@ -29,9 +29,35 @@\n++ #include \"stablehlo/dialect/TypeInference.h\"\n++ #include \"stablehlo/integrations/cpp/builder/AttrTypeBuilderUtil.h\"\n++ #include \"stablehlo/integrations/cpp/builder/MlirBuilder.h\"\n+++#include \"third_party/llvm/llvm-project/mlir/include/mlir/IR/Attributes.h\"\n++ \n++ namespace mlir {\n++ namespace stablehlo {\n+++\n+++///////////////\n+++// Dialect Helpers\n+++///////////////\n+++\n+++MlirOp AttachFrontendAttribute(MlirBuilder& builder, MlirOp op, StringRef name,\n+++                               Attribute value) {\n+++  constexpr char kFrontendAttrName[] = \"mhlo.frontend_attributes\";\n+++  Operation* mlirOp = unwrap(op).getDefiningOp();\n+++  SmallVector<NamedAttribute> attrs;\n+++  DictionaryAttr frontendAttr =\n+++      mlirOp->getAttrOfType<DictionaryAttr>(kFrontendAttrName);\n+++  if (frontendAttr) {\n+++    for (NamedAttribute attr : frontendAttr.getValue()) {\n+++      // Populate all non-conflicting names.\n+++      if (attr.getName() != name) {\n+++        attrs.push_back(attr);\n+++      }\n+++    }\n+++  }\n+++  attrs.emplace_back(name, value);\n+++  mlirOp->setAttr(kFrontendAttrName,\n+++                  DictionaryAttr::get(&builder.getContext(), attrs));\n+++  return op;\n+++}\n++ \n++ /////////////////\n++ // MANUAL APIs\n++diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.h b/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.h\n++--- stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.h\n+++++ stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.h\n++@@ -27,9 +27,22 @@\n++ #include \"stablehlo/dialect/StablehloOps.h\"\n++ #include \"stablehlo/integrations/cpp/builder/AttrTypeBuilderUtil.h\"\n++ #include \"stablehlo/integrations/cpp/builder/MlirBuilder.h\"\n+++#include \"third_party/llvm/llvm-project/mlir/include/mlir/IR/Attributes.h\"\n++ \n++ namespace mlir {\n++ namespace stablehlo {\n+++\n+++///////////////\n+++// Dialect Helpers\n+++///////////////\n+++\n+++// Appends or overwrites an entry in the `mhlo.frontend_attributes` attribute\n+++//\n+++// of the given op.\n+++// Ex:\n+++//   stablehlo.abs %0 { mhlo.frontend_attributes = { \"foo\" = 123 } }\n+++MlirOp AttachFrontendAttribute(MlirBuilder& builder, MlirOp op, StringRef name,\n+++                               Attribute value);\n++ \n++ /////////////////\n++ // MANUAL APIs\n+ diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp b/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp\n+ --- stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp\n+ +++ stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp\n+@@ -101,818 +226,267 @@ diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.c\n+  #include \"mlir/IR/BuiltinAttributes.h\"\n+  #include \"mlir/IR/BuiltinOps.h\"\n+  #include \"mlir/IR/DialectRegistry.h\"\n+-diff --ruN a/stablehlo/stablehlo/tests/BUILD.bazel b/stablehlo/stablehlo/tests/BUILD.bazel\n+---- stablehlo/stablehlo/tests/BUILD.bazel\n+-+++ stablehlo/stablehlo/tests/BUILD.bazel\n+-@@ -102,6 +102,8 @@\n+-     deps = [\n+-         \":test_utils_inc_gen\",\n+-         \"//:stablehlo_assembly_format\",\n+-+        \"//:stablehlo_broadcast_lowering\",\n+-+        \"//:stablehlo_ops\",\n+-         \"@llvm-project//llvm:Support\",\n+-         \"@llvm-project//mlir:FuncDialect\",\n+-         \"@llvm-project//mlir:IR\",\n+-diff --ruN a/stablehlo/stablehlo/tests/TestUtils.cpp b/stablehlo/stablehlo/tests/TestUtils.cpp\n+---- stablehlo/stablehlo/tests/TestUtils.cpp\n+-+++ stablehlo/stablehlo/tests/TestUtils.cpp\n+-@@ -19,6 +19,7 @@\n+- #include <utility>\n+- \n+- #include \"llvm/ADT/STLExtras.h\"\n+-+#include \"llvm/ADT/SmallVector.h\"\n+- #include \"llvm/Support/Casting.h\"\n+- #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+- #include \"mlir/Dialect/Shape/IR/Shape.h\"\n+-@@ -35,11 +36,35 @@\n+- #include \"mlir/Support/LLVM.h\"\n+- #include \"mlir/Support/LogicalResult.h\"\n+- #include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+-+#include \"stablehlo/dialect/StablehloOps.h\"\n+-+#include \"stablehlo/transforms/StablehloBroadcastLowering.h\"\n+-+#include \"third_party/llvm/llvm-project/mlir/include/mlir/IR/TypeRange.h\"\n+- \n+- namespace mlir {\n+- namespace hlo {\n+- \n+- namespace {\n+-+\n+-+struct BroadcastValuesPattern : public RewritePattern {\n+-+  explicit BroadcastValuesPattern(MLIRContext* context)\n+-+      : RewritePattern(\"hlo_test_broadcast.numpy_broadcast\", 1, context) {}\n+-+  LogicalResult matchAndRewrite(Operation* op,\n+-+                                PatternRewriter& rewriter) const override {\n+-+    // Process all operands\n+-+    SmallVector<Value> operands = llvm::to_vector(op->getOperands());\n+-+    auto broadcastedOperands =\n+-+        stablehlo::numpyBroadcastIfNeeded(rewriter, operands);\n+-+    if (failed(broadcastedOperands)) return failure();\n+-+\n+-+    // Replace with custom call to avoid pattern reapplication\n+-+    auto customCall = stablehlo::CustomCallOp::create(\n+-+        rewriter, op->getLoc(), op->getResultTypes(), *broadcastedOperands);\n+-+    customCall.setCallTargetName(\"numpy_broadcasted\");\n+-+    customCall.setHasSideEffect(true);\n+-+    rewriter.replaceOp(op, customCall);\n+-+    return success();\n+-+  }\n+-+};\n++@@ -1592,5 +1592,57 @@\n++   EXPECT_EQ(expected, debugString(*module));\n++ }\n+  \n+- struct InferReturnTypesPattern : public RewritePattern {\n+-   explicit InferReturnTypesPattern(MLIRContext *context)\n+-@@ -137,36 +162,55 @@\n+-   }\n+- };\n+- \n+-+#define GEN_PASS_DEF_HLOTESTBROADCASTPASS\n+- #define GEN_PASS_DEF_HLOTESTINFERPASS\n+- #define GEN_PASS_DEF_HLOTESTSPECULATABILITYPASS\n+- #include \"stablehlo/tests/TestUtils.h.inc\"\n+- \n+-+struct HloTestBroadcastPass\n+-+    : public impl::HloTestBroadcastPassBase<HloTestBroadcastPass> {\n+-+  LogicalResult initialize(MLIRContext* context) override {\n+-+    RewritePatternSet patterns(context);\n+-+    patterns.add<BroadcastValuesPattern>(context);\n+-+    patterns_ = std::move(patterns);\n+-+    return success();\n+++TEST(MlirBuilderTest, FrontendAttributesAppend) {\n+++  std::string expected = R\"mlir(module {\n+++  func.func @main(%arg0: tensor<2xf32>) -> tensor<2xf32> {\n+++    %0 = stablehlo.exponential %arg0 {mhlo.frontend_attributes = {bar = \"hello\", foo = 123 : i32}} : tensor<2xf32>\n+++    return %0 : tensor<2xf32>\n+ +  }\n+-+\n+-+  void runOnOperation() override {\n+-+    if (failed(applyPatternsGreedily(getOperation(), std::move(patterns_))))\n+-+      return signalPassFailure();\n+++})mlir\";\n+++\n+++  StablehloModuleBuilder mb;\n+++  {\n+++    Location funcLoc = fileLineColLoc(mb->getContext(), \"main.mlir\", 1, 1);\n+++    func::FunctionBuilder fb(mb.get(), \"main\", funcLoc);\n+++    auto type = makeTensorType(fb.getContext(), {2}, ElementType::F32);\n+++    auto arg0 = func::Argument(fb, type);\n+++    auto exp = Exp(arg0);\n+++    stablehlo::AttachFrontendAttribute(\n+++        fb, exp, \"foo\", fb.getOpBuilder().getI32IntegerAttr(123));\n+++    stablehlo::AttachFrontendAttribute(\n+++        fb, exp, \"bar\", fb.getOpBuilder().getStringAttr(\"hello\"));\n+++    func::Return(fb, {exp});\n+ +  }\n+ +\n+-+ private:\n+-+  FrozenRewritePatternSet patterns_;\n+-+};\n+-+\n+- struct HloTestInferPass : public impl::HloTestInferPassBase<HloTestInferPass> {\n+-   LogicalResult initialize(MLIRContext *context) override {\n+--    RewritePatternSet patterns_(context);\n+--    patterns_.add<InferReturnTypesPattern>(context);\n+--    patterns_.add<ReifyReturnTypeShapesPattern>(context);\n+--    patterns = std::move(patterns_);\n+-+    RewritePatternSet patterns(context);\n+-+    patterns.add<InferReturnTypesPattern>(context);\n+-+    patterns.add<ReifyReturnTypeShapesPattern>(context);\n+-+    patterns_ = std::move(patterns);\n+-     return success();\n+-   }\n+- \n+-   void runOnOperation() override {\n+--    if (failed(applyPatternsGreedily(getOperation(), std::move(patterns))))\n+-+    if (failed(applyPatternsGreedily(getOperation(), std::move(patterns_))))\n+-       return signalPassFailure();\n+-   }\n+- \n+-  private:\n+--  FrozenRewritePatternSet patterns;\n+-+  FrozenRewritePatternSet patterns_;\n+- };\n+- \n+- struct HloTestSpeculatabilityPass\n+-     : public impl::HloTestSpeculatabilityPassBase<HloTestSpeculatabilityPass> {\n+-   LogicalResult initialize(MLIRContext *context) override {\n+--    RewritePatternSet patterns_(context);\n+--    patterns_.add<IsSpeculatablePattern>(context);\n+--    patterns_.add<IsNotSpeculatablePattern>(context);\n+--    patterns_.add<IsRecursivelySpeculatablePattern>(context);\n+--    patterns = std::move(patterns_);\n+-+    RewritePatternSet patterns(context);\n+-+    patterns.add<IsSpeculatablePattern>(context);\n+-+    patterns.add<IsNotSpeculatablePattern>(context);\n+-+    patterns.add<IsRecursivelySpeculatablePattern>(context);\n+-+    patterns_ = std::move(patterns);\n+-     return success();\n+-   }\n+- \n+-@@ -175,11 +219,11 @@\n+-     config.setMaxIterations(1)\n+-         .setUseTopDownTraversal(true)\n+-         .setRegionSimplificationLevel(GreedySimplifyRegionLevel::Disabled);\n+--    (void)applyPatternsGreedily(getOperation(), std::move(patterns));\n+-+    (void)applyPatternsGreedily(getOperation(), std::move(patterns_));\n+-   }\n+- \n+-  private:\n+--  FrozenRewritePatternSet patterns;\n+-+  FrozenRewritePatternSet patterns_;\n+- };\n+- \n+- #define GEN_PASS_REGISTRATION\n+-diff --ruN a/stablehlo/stablehlo/tests/TestUtils.td b/stablehlo/stablehlo/tests/TestUtils.td\n+---- stablehlo/stablehlo/tests/TestUtils.td\n+-+++ stablehlo/stablehlo/tests/TestUtils.td\n+-@@ -16,6 +16,11 @@\n+- \n+- include \"mlir/Pass/PassBase.td\"\n+- \n+-+def HloTestBroadcastPass : Pass<\"hlo-test-broadcast\", \"func::FuncOp\"> {\n+-+  let summary = \"Uses test ops to invoke BroadcastUtils methods.\";\n+-+  let dependentDialects = [\"stablehlo::StablehloDialect\"];\n+-+}\n+-+\n+- def HloTestInferPass : Pass<\"hlo-test-infer\", \"func::FuncOp\"> {\n+-   let summary = \"Uses test ops to invoke InferShapedTypeOpInterface methods.\";\n+-   let dependentDialects = [\"shape::ShapeDialect\"];\n+-diff --ruN a/stablehlo/stablehlo/tests/ops_broadcasting.mlir b/stablehlo/stablehlo/tests/ops_broadcasting.mlir\n+---- stablehlo/stablehlo/tests/ops_broadcasting.mlir\n+-+++ stablehlo/stablehlo/tests/ops_broadcasting.mlir\n+-@@ -0,0 +1,249 @@\n+-+// RUN: stablehlo-opt %s --hlo-test-broadcast --split-input-file --allow-unregistered-dialect | FileCheck %s\n+-+\n+-+/////////\n+-+// Scalar broadcast tests.\n+-+\n+-+// [] x [1] => [1]\n+-+// CHECK-LABEL: func @scalar_broadcast_scalar_x_1\n+-+func.func @scalar_broadcast_scalar_x_1(%arg0: tensor<f64>, %arg1: tensor<1xf64>) -> !stablehlo.token {\n+-+  // CHECK: %[[LHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<f64>) -> tensor<1xf64>\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%[[LHS_BCAST]], %arg1)\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<f64>, tensor<1xf64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+// [1] x [] => [1]\n+-+// CHECK-LABEL: func @scalar_broadcast_1_x_scalar\n+-+func.func @scalar_broadcast_1_x_scalar(%arg0: tensor<1xf64>, %arg1: tensor<f64>) -> !stablehlo.token {\n+-+  // CHECK: %[[RHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f64>) -> tensor<1xf64>\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%arg0, %[[RHS_BCAST]])\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<1xf64>, tensor<f64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+// [] x [10] => [10]\n+-+// CHECK-LABEL: func @scalar_broadcast_scalar_x_10\n+-+func.func @scalar_broadcast_scalar_x_10(%arg0: tensor<f64>, %arg1: tensor<10xf64>) -> !stablehlo.token {\n+-+  // CHECK: %[[LHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<f64>) -> tensor<10xf64>\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%[[LHS_BCAST]], %arg1)\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<f64>, tensor<10xf64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+++  OwningOpRef<ModuleOp> module = mb->build();\n+++  EXPECT_EQ(expected, debugString(*module));\n+ +}\n+ +\n+-+// -----\n+-+\n+-+// [<=10] x [] => [<=10]\n+-+// CHECK-LABEL: func @scalar_broadcast_b10_x_scalar\n+-+func.func @scalar_broadcast_b10_x_scalar(%arg0: tensor<?xf64, #stablehlo.bounds<10>>, %arg1: tensor<f64>) -> !stablehlo.token {\n+-+  // CHECK: %[[RHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f64>) -> tensor<10xf64>\n+-+  // CHECK: %[[DIM_SIZE:.+]] = stablehlo.get_dimension_size %arg0, dim = 0\n+-+  // CHECK: %[[RHS_BCAST_DYN:.+]] = stablehlo.set_dimension_size %[[RHS_BCAST]], %[[DIM_SIZE]], dim = 0\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%arg0, %[[RHS_BCAST_DYN]])\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<?xf64, #stablehlo.bounds<10>>, tensor<f64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+// [] x [<=10] => [<=10]\n+-+// CHECK-LABEL: func @scalar_broadcast_scalar_x_b10\n+-+func.func @scalar_broadcast_scalar_x_b10(%arg0: tensor<f64>, %arg1: tensor<?xf64, #stablehlo.bounds<10>>) -> !stablehlo.token {\n+-+  // CHECK: %[[LHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<f64>) -> tensor<10xf64>\n+-+  // CHECK: %[[DIM_SIZE:.+]] = stablehlo.get_dimension_size %arg1, dim = 0\n+-+  // CHECK: %[[LHS_BCAST_DYN:.+]] = stablehlo.set_dimension_size %[[LHS_BCAST]], %[[DIM_SIZE]], dim = 0\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%[[LHS_BCAST_DYN]], %arg1)\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<f64>, tensor<?xf64, #stablehlo.bounds<10>>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+// [] x [1, <=10, 1] => [1, <=10, 1]\n+-+// CHECK-LABEL: func @scalar_broadcast_scalar_x_1_b10_1\n+-+func.func @scalar_broadcast_scalar_x_1_b10_1(%arg0: tensor<f64>, %arg1: tensor<1x?x1xf64, #stablehlo.bounds<?, 10, ?>>) -> !stablehlo.token {\n+-+  // CHECK: %[[LHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<f64>) -> tensor<1x10x1xf64>\n+-+  // CHECK: %[[DIM_SIZE:.+]] = stablehlo.get_dimension_size %arg1, dim = 1\n+-+  // CHECK: %[[LHS_BCAST_DYN:.+]] = stablehlo.set_dimension_size %[[LHS_BCAST]], %[[DIM_SIZE]], dim = 1\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%[[LHS_BCAST_DYN]], %arg1)\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<f64>, tensor<1x?x1xf64, #stablehlo.bounds<?, 10, ?>>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// [10, 1, <=5] x [] => [10, 1, <=5]\n+-+// CHECK-LABEL: func @scalar_broadcast_10_1_b5_x_scalar\n+-+func.func @scalar_broadcast_10_1_b5_x_scalar(%arg0: tensor<10x1x?xf64, #stablehlo.bounds<?, ?, 5>>, %arg1: tensor<f64>) -> !stablehlo.token {\n+-+  // CHECK: %[[RHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f64>) -> tensor<10x1x5xf64>\n+-+  // CHECK: %[[DIM_SIZE:.+]] = stablehlo.get_dimension_size %arg0, dim = 2\n+-+  // CHECK: %[[RHS_BCAST_DYN:.+]] = stablehlo.set_dimension_size %[[RHS_BCAST]], %[[DIM_SIZE]], dim = 2\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%arg0, %[[RHS_BCAST_DYN]])\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<10x1x?xf64, #stablehlo.bounds<?, ?, 5>>, tensor<f64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+//////\n+-+// 1-D SCALAR TESTS\n+-+\n+-+// [1] x [1] => [1]\n+-+// [1] x [10] => [1]\n+-+// [<=10] x [1] => [<=10]\n+-+// [1] x [<=10] => [<=10]\n+-+// [1] x [1, <=10, 1] => [1, <=10, 1]\n+-+\n+-+\n+-+// [1] x [1] => [1]\n+-+// CHECK-LABEL: func @single_dim_scalar_1_x_1\n+-+func.func @single_dim_scalar_1_x_1(%arg0: tensor<1xf64>, %arg1: tensor<1xf64>) -> !stablehlo.token {\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%arg0, %arg1)\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<1xf64>, tensor<1xf64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+// [1] x [10] => [10]\n+-+// CHECK-LABEL: func @single_dim_scalar_1_x_10\n+-+func.func @single_dim_scalar_1_x_10(%arg0: tensor<1xf64>, %arg1: tensor<10xf64>) -> !stablehlo.token {\n+-+  // CHECK: %[[LHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg0, dims = [0] : (tensor<1xf64>) -> tensor<10xf64>\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%[[LHS_BCAST]], %arg1)\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<1xf64>, tensor<10xf64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+// [<=10] x [1] => [<=10]\n+-+// CHECK-LABEL: func @single_dim_scalar_b10_x_1\n+-+func.func @single_dim_scalar_b10_x_1(%arg0: tensor<?xf64, #stablehlo.bounds<10>>, %arg1: tensor<1xf64>) -> !stablehlo.token {\n+-+  // CHECK: %[[RHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg1, dims = [0] : (tensor<1xf64>) -> tensor<10xf64>\n+-+  // CHECK: %[[DIM_SIZE:.+]] = stablehlo.get_dimension_size %arg0, dim = 0\n+-+  // CHECK: %[[RHS_BCAST_DYN:.+]] = stablehlo.set_dimension_size %[[RHS_BCAST]], %[[DIM_SIZE]], dim = 0\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%arg0, %[[RHS_BCAST_DYN]])\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<?xf64, #stablehlo.bounds<10>>, tensor<1xf64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+// [1] x [<=10] => [<=10]\n+-+// CHECK-LABEL: func @single_dim_scalar_1_x_b10\n+-+func.func @single_dim_scalar_1_x_b10(%arg0: tensor<1xf64>, %arg1: tensor<?xf64, #stablehlo.bounds<10>>) -> !stablehlo.token {\n+-+  // CHECK: %[[LHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg0, dims = [0] : (tensor<1xf64>) -> tensor<10xf64>\n+-+  // CHECK: %[[DIM_SIZE:.+]] = stablehlo.get_dimension_size %arg1, dim = 0\n+-+  // CHECK: %[[LHS_BCAST_DYN:.+]] = stablehlo.set_dimension_size %[[LHS_BCAST]], %[[DIM_SIZE]], dim = 0\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%[[LHS_BCAST_DYN]], %arg1)\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<1xf64>, tensor<?xf64, #stablehlo.bounds<10>>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// [<=10] x [<=10] => [<=10] // PT layer must ensure these are identical!\n+-+// CHECK-LABEL: func @single_dim_scalar_b10_x_b10\n+-+func.func @single_dim_scalar_b10_x_b10(%arg0: tensor<?xf64, #stablehlo.bounds<10>>, %arg1: tensor<?xf64, #stablehlo.bounds<10>>) -> !stablehlo.token {\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%arg0, %arg1)\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<?xf64, #stablehlo.bounds<10>>, tensor<?xf64, #stablehlo.bounds<10>>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+// [1] x [1, <=10, 1] => [1, <=10, 1]\n+-+// CHECK-LABEL: func @single_dim_scalar_1_x_1_b10_1\n+-+func.func @single_dim_scalar_1_x_1_b10_1(%arg0: tensor<1xf64>, %arg1: tensor<1x?x1xf64, #stablehlo.bounds<?, 10, ?>>) -> !stablehlo.token {\n+-+  // CHECK: %[[LHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg0, dims = [2] : (tensor<1xf64>) -> tensor<1x10x1xf64>\n+-+  // CHECK: %[[DIM_SIZE:.+]] = stablehlo.get_dimension_size %arg1, dim = 1\n+-+  // CHECK: %[[LHS_BCAST_DYN:.+]] = stablehlo.set_dimension_size %[[LHS_BCAST]], %[[DIM_SIZE]], dim = 1\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%[[LHS_BCAST_DYN]], %arg1)\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<1xf64>, tensor<1x?x1xf64, #stablehlo.bounds<?, 10, ?>>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+// [10, 1, <=5] x [1] => [10, 1, <=5]\n+-+// CHECK-LABEL: func @single_dim_scalar_10_1_b5_x_1\n+-+func.func @single_dim_scalar_10_1_b5_x_1(%arg0: tensor<10x1x?xf64, #stablehlo.bounds<?, ?, 5>>, %arg1: tensor<1xf64>) -> !stablehlo.token {\n+-+  // CHECK: %[[RHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<1xf64>) -> tensor<10x1x5xf64>\n+-+  // CHECK: %[[DIM_SIZE:.+]] = stablehlo.get_dimension_size %arg0, dim = 2\n+-+  // CHECK: %[[RHS_BCAST_DYN:.+]] = stablehlo.set_dimension_size %[[RHS_BCAST]], %[[DIM_SIZE]], dim = 2\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%arg0, %[[RHS_BCAST_DYN]])\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<10x1x?xf64, #stablehlo.bounds<?, ?, 5>>, tensor<1xf64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+\n+-+//////\n+-+// N-D Tests\n+-+\n+-+// [1, 2] x [1, 2] => [1, 2]\n+-+// CHECK-LABEL: func @tensor_no_broadcast_match\n+-+func.func @tensor_no_broadcast_match(%arg0: tensor<1x2xf64>, %arg1: tensor<1x2xf64>) -> !stablehlo.token {\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%arg0, %arg1)\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<1x2xf64>, tensor<1x2xf64>) ->  !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// [10, 1] x [1, 1] => [10, 1]\n+-+// CHECK-LABEL: func @tensor_broadcast_10_1_x_1_1\n+-+func.func @tensor_broadcast_10_1_x_1_1(%arg0: tensor<10x1xf64>, %arg1: tensor<1x1xf64>) -> !stablehlo.token {\n+-+  // CHECK: %[[RHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg1, dims = [0, 1] : (tensor<1x1xf64>) -> tensor<10x1xf64>\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%arg0, %[[RHS_BCAST]])\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<10x1xf64>, tensor<1x1xf64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+// [<=10, 1] x [1, 10] => [<=10, 10]\n+-+// CHECK-LABEL: func @tensor_broadcast_b10_1_x_1_10\n+-+func.func @tensor_broadcast_b10_1_x_1_10(%arg0: tensor<?x1xf64, #stablehlo.bounds<10, ?>>, %arg1: tensor<1x10xf64>) -> !stablehlo.token {\n+-+  // CHECK: %[[LHS_BCAST:.+]] = stablehlo.broadcast_in_dim %arg0, dims = [0, 1] : (tensor<?x1xf64, #stablehlo.bounds<10, ?>>) -> tensor<?x10xf64, #stablehlo.bounds<10, ?>>\n+-+  // CHECK: %[[RHS_BCAST_STATIC:.+]] = stablehlo.broadcast_in_dim %arg1, dims = [0, 1] : (tensor<1x10xf64>) -> tensor<10x10xf64>\n+-+  // CHECK: %[[DIM_SIZE:.+]] = stablehlo.get_dimension_size %arg0, dim = 0\n+-+  // CHECK: %[[RHS_BCAST_DYN:.+]] = stablehlo.set_dimension_size %[[RHS_BCAST_STATIC]], %[[DIM_SIZE]], dim = 0\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%[[LHS_BCAST]], %[[RHS_BCAST_DYN]])\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (tensor<?x1xf64, #stablehlo.bounds<10, ?>>, tensor<1x10xf64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+// [<=10, 1] x [1, <=10] => [<=10, <=10]\n+-+// CHECK-LABEL: func @tensor_broadcast_b10_1_x_1_b10\n+-+func.func @tensor_broadcast_b10_1_x_1_b10(\n+-+  %arg0: tensor<?x1xf64, #stablehlo.bounds<10, ?>>,\n+-+  %arg1: tensor<1x?xf64, #stablehlo.bounds<?, 10>>\n+-+) -> !stablehlo.token {\n+-+  // CHECK: %[[LHS_BCAST_STATIC:.+]] = stablehlo.broadcast_in_dim %arg0, dims = [0, 1] : (tensor<?x1xf64, #stablehlo.bounds<10, ?>>) -> tensor<?x10xf64, #stablehlo.bounds<10, ?>>\n+-+  // CHECK: %[[ARG1_DIM1_SIZE:.+]] = stablehlo.get_dimension_size %arg1, dim = 1\n+-+  // CHECK: %[[LHS_BCAST_DYN:.+]] = stablehlo.set_dimension_size %[[LHS_BCAST_STATIC]], %[[ARG1_DIM1_SIZE]], dim = 1\n+-+  // CHECK: %[[RHS_BCAST_STATIC:.+]] = stablehlo.broadcast_in_dim %arg1, dims = [0, 1] : (tensor<1x?xf64, #stablehlo.bounds<?, 10>>) -> tensor<10x?xf64, #stablehlo.bounds<?, 10>>\n+-+  // CHECK: %[[ARG0_DIM0_SIZE:.+]] = stablehlo.get_dimension_size %arg0, dim = 0\n+-+  // CHECK: %[[RHS_BCAST_DYN:.+]] = stablehlo.set_dimension_size %[[RHS_BCAST_STATIC]], %[[ARG0_DIM0_SIZE]], dim = 0\n+-+  // CHECK-NEXT: stablehlo.custom_call @numpy_broadcasted(%[[LHS_BCAST_DYN]], %[[RHS_BCAST_DYN]])\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1) : (\n+-+    tensor<?x1xf64, #stablehlo.bounds<10, ?>>,\n+-+    tensor<1x?xf64, #stablehlo.bounds<?, 10>>\n+-+  ) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+-+}\n+-+\n+-+// -----\n+-+\n+-+//////\n+-+// N-ary broadcast tests.\n+-+\n+++TEST(MlirBuilderTest, FrontendAttributesOverwrite) {\n+++  std::string expected = R\"mlir(module {\n+++  func.func @main(%arg0: tensor<2xf32>) -> tensor<2xf32> {\n+++    %0 = stablehlo.exponential %arg0 {mhlo.frontend_attributes = {foo = 456 : i32}} : tensor<2xf32>\n+++    return %0 : tensor<2xf32>\n+++  }\n+++})mlir\";\n+++\n+++  StablehloModuleBuilder mb;\n+++  {\n+++    Location funcLoc = fileLineColLoc(mb->getContext(), \"main.mlir\", 1, 1);\n+++    func::FunctionBuilder fb(mb.get(), \"main\", funcLoc);\n+++    auto type = makeTensorType(fb.getContext(), {2}, ElementType::F32);\n+++    auto arg0 = func::Argument(fb, type);\n+++    auto exp = Exp(arg0);\n+++    stablehlo::AttachFrontendAttribute(\n+++        fb, exp, \"foo\", fb.getOpBuilder().getI32IntegerAttr(123));\n+++    stablehlo::AttachFrontendAttribute(\n+++        fb, exp, \"foo\", fb.getOpBuilder().getI32IntegerAttr(456));\n+++    func::Return(fb, {exp});\n+++  }\n+ +\n+-+// [<=10, 1] x [1, <=10] x [1] => [<=10, <=10]\n+-+// CHECK-LABEL: func @nary_broadcast_b10_1_x_1_b10_x_1\n+-+func.func @nary_broadcast_b10_1_x_1_b10_x_1(\n+-+  %arg0: tensor<?x1xf64, #stablehlo.bounds<10, ?>>,\n+-+  %arg1: tensor<1x?xf64, #stablehlo.bounds<?, 10>>,\n+-+  %arg2: tensor<1xf64>\n+-+) -> !stablehlo.token {\n+-+  %0 = \"hlo_test_broadcast.numpy_broadcast\"(%arg0, %arg1, %arg2) : (tensor<?x1xf64, #stablehlo.bounds<10, ?>>, tensor<1x?xf64, #stablehlo.bounds<?, 10>>, tensor<1xf64>) -> !stablehlo.token\n+-+  return %0 : !stablehlo.token\n+++  OwningOpRef<ModuleOp> module = mb->build();\n+++  EXPECT_EQ(expected, debugString(*module));\n+ +}\n+ +\n++ }  // namespace stablehlo\n++ }  // namespace mlir\n++diff --ruN a/stablehlo/stablehlo/reference/InterpreterOps.cpp b/stablehlo/stablehlo/reference/InterpreterOps.cpp\n++--- stablehlo/stablehlo/reference/InterpreterOps.cpp\n+++++ stablehlo/stablehlo/reference/InterpreterOps.cpp\n++@@ -46,6 +46,7 @@\n++ #include \"stablehlo/reference/ProcessGrid.h\"\n++ #include \"stablehlo/reference/Value.h\"\n++ \n+++using mlir::stablehlo::TokenType;\n++ #define GET_OP_CLASSES\n++ #include \"stablehlo/reference/InterpreterOps.cpp.inc\"\n++ \n+ diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir b/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir\n+ --- stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir\n+ +++ stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir\n+-@@ -576,16 +576,19 @@\n+- // ReshapeOp\n+- \n+- // CHECK-LABEL: func @reshape_fold\n+--func.func @reshape_fold() -> (tensor<1xi32>, tensor<2x2xi32>) {\n+--  %c0 = stablehlo.constant dense<2> : tensor<i32>\n+-+func.func @reshape_fold() -> (tensor<1xf32>, tensor<2x2xi32>, tensor<3x2xcomplex<f32>>) {\n+-+  %c0 = stablehlo.constant dense<2.0> : tensor<f32>\n+-   %c1 = stablehlo.constant dense<[1, 2, 3, 4]> : tensor<4xi32>\n+--  %0 = stablehlo.reshape %c0 : (tensor<i32>) -> tensor<1xi32>\n+-+  %c2 = stablehlo.constant dense<(1.0,2.0)> : tensor<2x3xcomplex<f32>>\n+-+  %0 = stablehlo.reshape %c0 : (tensor<f32>) -> tensor<1xf32>\n+-   %1 = stablehlo.reshape %c1 : (tensor<4xi32>) -> tensor<2x2xi32>\n++@@ -22,21 +22,24 @@\n++ // CHECK-LABEL: func.func @broadcast_in_dim_fold_splat\n++ // CHECK-SAME:   ([[ARG0:%.+]]: tensor<3x3xi32>)\n++ func.func @broadcast_in_dim_fold_splat(%arg0: tensor<3x3xi32>)\n++-  -> (tensor<6xi32>, tensor<3xf32>, tensor<3x3xi32>) {\n+++  -> (tensor<6xi32>, tensor<3xf32>, tensor<5xcomplex<f32>>, tensor<3x3xi32>) {\n++   %c0 = stablehlo.constant dense<5> : tensor<i32>\n++   %c1 = stablehlo.constant dense<3.0> : tensor<f32>\n++-  %c2 = stablehlo.constant dense<1> : tensor<1x3xi32>\n+++  %c2 = stablehlo.constant dense<(1.0,2.0)> : tensor<complex<f32>>\n+++  %c3 = stablehlo.constant dense<1> : tensor<1x3xi32>\n++ \n++   %0 = stablehlo.broadcast_in_dim %c0, dims = [] : (tensor<i32>) -> tensor<6xi32>\n++   %1 = stablehlo.broadcast_in_dim %c1, dims = [] : (tensor<f32>) -> tensor<3xf32>\n++-  %2 = stablehlo.broadcast_in_dim %c2, dims = [1, 0] : (tensor<1x3xi32>) -> tensor<3x3xi32>\n+++  %2 = stablehlo.broadcast_in_dim %c2, dims = [] : (tensor<complex<f32>>) -> tensor<5xcomplex<f32>>\n+++  %3 = stablehlo.broadcast_in_dim %c3, dims = [1, 0] : (tensor<1x3xi32>) -> tensor<3x3xi32>\n++ \n++   // CHECK-DAG:  [[R0:%.+]] = stablehlo.constant dense<5> : tensor<6xi32>\n++   // CHECK-DAG:  [[R1:%.+]] = stablehlo.constant dense<3.000000e+00> : tensor<3xf32>\n++-  // CHECK-DAG:  [[R2:%.+]] = stablehlo.constant dense<1> : tensor<3x3xi32>\n+ -\n+--  // CHECK-DAG:  [[CST1:%.+]] = stablehlo.constant dense<2> : tensor<1xi32>\n+--  // CHECK-DAG:  [[CST2:%.+]] = stablehlo.constant dense<{{\\[\\[1, 2\\], \\[3, 4\\]\\]}}> : tensor<2x2xi32>\n+--  // CHECK-NEXT: return [[CST1]], [[CST2]]\n+--  return %0, %1 : tensor<1xi32>, tensor<2x2xi32>\n+-+  %2 = stablehlo.reshape %c2 : (tensor<2x3xcomplex<f32>>) -> tensor<3x2xcomplex<f32>>\n++-  // CHECK-NEXT: return [[R0]], [[R1]], [[R2]]\n++-  return %0, %1, %2 : tensor<6xi32>, tensor<3xf32>, tensor<3x3xi32>\n+++  // CHECK-DAG:  [[R2:%.+]] = stablehlo.constant dense<(1.0{{.*}},2.0{{.*}})> : tensor<5xcomplex<f32>>\n+++  // CHECK-DAG:  [[R3:%.+]] = stablehlo.constant dense<1> : tensor<3x3xi32>\n+ +\n+-+  // CHECK-DAG:  [[RESULT0:%.+]] = stablehlo.constant dense<2.0{{.*}}> : tensor<1xf32>\n+-+  // CHECK-DAG:  [[RESULT1:%.+]] = stablehlo.constant dense<{{\\[\\[1, 2\\], \\[3, 4\\]\\]}}> : tensor<2x2xi32>\n+-+  // CHECK-DAG:  [[RESULT2:%.+]] = stablehlo.constant dense<(1.0{{.*}},2.0{{.*}})> : tensor<3x2xcomplex<f32>>\n+-+  // CHECK-NEXT: return [[RESULT0]], [[RESULT1]], [[RESULT2]]\n+-+  return %0, %1, %2 : tensor<1xf32>, tensor<2x2xi32>, tensor<3x2xcomplex<f32>>\n+++  // CHECK-NEXT: return [[R0]], [[R1]], [[R2]], [[R3]]\n+++  return %0, %1, %2, %3 : tensor<6xi32>, tensor<3xf32>, tensor<5xcomplex<f32>>, tensor<3x3xi32>\n+  }\n+  \n+  // -----\n+-diff --ruN a/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp b/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp\n+---- stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp\n+-+++ stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp\n+-@@ -0,0 +1,293 @@\n+-+/* Copyright 2025 The StableHLO Authors.\n+-+\n+-+Licensed under the Apache License, Version 2.0 (the \"License\");\n+-+you may not use this file except in compliance with the License.\n+-+You may obtain a copy of the License at\n+-+\n+-+    http://www.apache.org/licenses/LICENSE-2.0\n+-+\n+-+Unless required by applicable law or agreed to in writing, software\n+-+distributed under the License is distributed on an \"AS IS\" BASIS,\n+-+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+-+See the License for the specific language governing permissions and\n+-+limitations under the License.\n+-+==============================================================================*/\n+-+\n+-+#include \"stablehlo/transforms/StablehloBroadcastLowering.h\"\n+-+\n+-+#include <algorithm>\n+-+#include <cassert>\n+-+#include <cstddef>\n+-+#include <cstdint>\n+-+#include <string>\n+-+#include <utility>\n+-+\n+-+#include \"llvm/ADT/STLExtras.h\"\n+-+#include \"llvm/Support/Debug.h\"\n+-+#include \"llvm/Support/raw_ostream.h\"\n+-+#include \"mlir/IR/Builders.h\"\n+-+#include \"mlir/IR/BuiltinTypeInterfaces.h\"\n+-+#include \"mlir/IR/BuiltinTypes.h\"\n+-+#include \"mlir/IR/Diagnostics.h\"\n+-+#include \"mlir/IR/Location.h\"\n+-+#include \"mlir/IR/Types.h\"\n+-+#include \"mlir/IR/Value.h\"\n+-+#include \"mlir/Support/LLVM.h\"\n+-+#include \"stablehlo/dialect/StablehloOps.h\"\n+-+#include \"third_party/llvm/llvm-project/llvm/include/llvm/ADT/Sequence.h\"\n+-+#include \"third_party/llvm/llvm-project/llvm/include/llvm/ADT/SmallVector.h\"\n+-+\n+-+#define DEBUG_TYPE \"stablehlo-broadcast-lowering\"\n+-+\n+-+namespace mlir {\n+-+namespace stablehlo {\n+-+\n+-+/////\n+-+// Bounded dynamism broadcasting\n+-+\n+-+namespace {\n+-+\n+-+DimensionInfo getDimensionInfo(Value op, mlir::RankedTensorType tensorType,\n+-+                               TypeExtensionsAttr encoding,\n+-+                               int64_t dim) {\n+-+  if (!encoding || !mlir::ShapedType::isDynamic(tensorType.getDimSize(dim)))\n+-+    return DimensionInfo{tensorType.getDimSize(dim)};\n+-+\n+-+  return DimensionInfo{\n+-+      encoding.getBounds()[dim],\n+-+      op,\n+-+      dim,\n+-+  };\n+-+}\n+-+\n+-+FailureOr<Dimensions> getDimensions(Value op) {\n+-+  // Get tensor type\n+-+  mlir::RankedTensorType tensor_type = dyn_cast<RankedTensorType>(op.getType());\n+-+  if (!tensor_type)\n+-+    return emitError(op.getLoc(), \"expected ranked tensor type\");\n+-+\n+-+  auto encoding =\n+-+      mlir::dyn_cast_if_present<mlir::stablehlo::TypeExtensionsAttr>(\n+-+          tensor_type.getEncoding());\n+-+\n+-+  Dimensions dimensions;\n+-+  dimensions.reserve(tensor_type.getRank());\n+-+  for (size_t idx = 0; idx < tensor_type.getRank(); ++idx) {\n+-+    auto dimInfo = getDimensionInfo(op, tensor_type, encoding, idx);\n+-+    dimensions.push_back(dimInfo);\n+-+  }\n+-+  return dimensions;\n+-+}\n+-+\n+-+FailureOr<Dimensions> getNumpyBroadcastShapeWithBounds(\n+-+    const Dimensions& a, const Dimensions& b) {\n+-+  LLVM_DEBUG(llvm::dbgs() << \"[getNumpyBroadcastShapeWithBounds] inputs: \"\n+-+                          << toString(a) << \" * \" << toString(b));\n+-+  size_t max_rank = std::max(a.size(), b.size());\n+-+  Dimensions result(max_rank);\n+-+\n+-+  // Iterate from right to left (NumPy-style broadcasting)\n+-+  for (int i = 1; i <= max_rank; ++i) {\n+-+    size_t a_idx = a.size() - i;\n+-+    size_t b_idx = b.size() - i;\n+-+    size_t res_idx = max_rank - i;\n+-+\n+-+    // Get DimensionInfo for the current index, padding with size 1 if out of\n+-+    // bounds.\n+-+    DimensionInfo dim_a =\n+-+        (a_idx >= 0 && a_idx < a.size()) ? a[a_idx] : DimensionInfo{1};\n+-+    DimensionInfo dim_b =\n+-+        (b_idx >= 0 && b_idx < b.size()) ? b[b_idx] : DimensionInfo{1};\n+-+\n+-+    // Short circuit on size 1 dimensions.\n+-+    if (dim_a.size == 1) {\n+-+      result[res_idx] = dim_b;\n+-+      continue;\n+-+    }\n+-+    if (dim_b.size == 1) {\n+-+      result[res_idx] = dim_a;\n+-+      continue;\n+-+    }\n+-+\n+-+    // If both LHS and RHS are not 1, dim size must match.\n+-+    if (dim_a.size != dim_b.size) {\n+-+      return emitError(a[a_idx].boundOp.value().getLoc(),\n+-+                       \"incompatible shapes for broadcasting \")\n+-+             << dim_a.size << \" and \" << dim_b.size;\n+-+    }\n+-+\n+-+    // If bounded both must be bounded\n+-+    if (dim_a.boundOp.has_value() != dim_b.boundOp.has_value()) {\n+-+      return emitError(a[a_idx].boundOp.value().getLoc(),\n+-+                       \"cannot mix bounded and static dimensions in broadcast\");\n+-+    }\n+-+\n+-+    // LHS and RHS match, populate with one of the dimensions.\n+-+    result[res_idx] = dim_a;\n+-+  }\n+-+\n+-+  LLVM_DEBUG(llvm::dbgs() << \"[getNumpyBroadcastShapeWithBounds] result: \"\n+-+                          << toString(result));\n+-+  return result;\n+-+}\n+-+\n+-+mlir::RankedTensorType getRankedTensorType(const Dimensions& dims,\n+-+                                           mlir::Type element_type) {\n+-+  mlir::SmallVector<int64_t> shape;\n+-+  mlir::SmallVector<int64_t> bounds;\n+-+  shape.reserve(dims.size());\n+-+  for (const DimensionInfo& dim : dims) {\n+-+    if (dim.boundOp.has_value()) {\n+-+      shape.push_back(mlir::ShapedType::kDynamic);\n+-+      bounds.push_back(dim.size);\n+-+    } else {\n+-+      shape.push_back(dim.size);\n+-+      bounds.push_back(mlir::ShapedType::kDynamic);\n+-+    }\n+-+  }\n+-+  mlir::stablehlo::TypeExtensionsAttr encoding;\n+-+  if (!llvm::all_of(\n+-+          bounds, [](int64_t b) { return b == mlir::ShapedType::kDynamic; })) {\n+-+    encoding = mlir::stablehlo::TypeExtensionsAttr::get(\n+-+        element_type.getContext(), bounds);\n+-+  }\n+-+  return mlir::RankedTensorType::get(shape, element_type, encoding);\n+-+}\n+-+\n+-+}  // namespace\n+-+\n+-+\n+-+FailureOr<Dimensions> getNumpyBroadcastShape(ArrayRef<Value> ops) {\n+-+  if (ops.empty()) return failure();\n+-+\n+-+  Value first = ops[0];\n+-+  auto bcastShapeOrFail = getDimensions(first);\n+-+  if (failed(bcastShapeOrFail)) return failure();\n+-+  Dimensions bcastShape = std::move(*bcastShapeOrFail);\n+-+\n+-+  for (int i = 1; i < ops.size(); ++i) {\n+-+    Value currOp = ops[i];\n+-+    auto dims = getDimensions(currOp);\n+-+    if (failed(dims)) return failure();\n+-+    auto currBcastShapeOrFail =\n+-+        getNumpyBroadcastShapeWithBounds(bcastShape, *dims);\n+-+    if (failed(currBcastShapeOrFail)) return failure();\n+-+    bcastShape = std::move(*currBcastShapeOrFail);\n+-+  }\n+-+  return std::move(bcastShape);\n+-+}\n+-+\n+-+std::string toString(const Dimensions& dims) {\n+-+  std::string result;\n+-+  llvm::raw_string_ostream os(result);\n+-+  os << \"tensor<\";\n+-+  llvm::interleave(\n+-+      dims, os,\n+-+      [&](const DimensionInfo& dim) {\n+-+        os << (dim.boundOp.has_value() ? \"b\" : \"\") << dim.size;\n+-+      },\n+-+      \"x\");\n+-+  os << \">\";\n+-+  return result;\n++diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir b/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir\n++--- stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir\n+++++ stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir\n++@@ -134,6 +134,35 @@\n++   return %0, %5 : tensor<1x3x6xi32>, tensor<3x6x1xi32>\n++ }\n++ \n+++// CHECK-LABEL: func.func @broadcast_in_dim_prefer_nested_reshape\n+++// CHECK-SAME:   ([[ARG0:%[^ ]+]]: tensor<3x4xi32>)\n+++func.func @broadcast_in_dim_prefer_nested_reshape(%arg0: tensor<3x4xi32>) -> (tensor<2x3x4x3xi32>, tensor<2x3x4x3xi32>) {\n+++  // When `broadcast_in_dim(broadcast_in_dim(x))` could be optimized into either\n+++  // `broadcast_in_dim(reshape(x))` or `broadcast_in_dim(x)`, we want to select\n+++  // the former pattern.\n+++  //\n+++  // (We accomplish this by blocking the merge-composition pattern if the inner\n+++  // op can be replaced with a `reshape`. Simply adding benefit to the\n+++  // replace-with-reshape pattern isn't sufficient here because the outermost\n+++  // op, which only matches the merge-composition pattern, is traversed first.)\n+++\n+++  // CHECK-DAG: [[INNER_RESHAPE:%[^ ]+]] = stablehlo.reshape [[ARG0]] : (tensor<3x4xi32>) -> tensor<3x1x4xi32>\n+++  // CHECK-DAG: [[BROADCAST_OF_RESHAPE:%[^ ]+]] = stablehlo.broadcast_in_dim [[INNER_RESHAPE]], dims = [1, 0, 2] : (tensor<3x1x4xi32>) -> tensor<2x3x4x3xi32>\n+++  %0 = stablehlo.broadcast_in_dim %arg0, dims = [0, 2] : (tensor<3x4xi32>) -> tensor<3x1x4xi32>\n+++  %1 = stablehlo.broadcast_in_dim %0, dims = [1, 0, 2] : (tensor<3x1x4xi32>) -> tensor<2x3x4x3xi32>\n+++\n+++  // When the inner op doesn't qualify for replacement with a `reshape` op,\n+++  // however (particularly when it meets some conditions but not others), ensure\n+++  // that we allow the merge-composition pattern to match.\n+++\n+++  // CHECK-DAG: [[MERGED_BROADCAST:%[^ ]+]] = stablehlo.broadcast_in_dim [[ARG0]], dims = [3, 2] : (tensor<3x4xi32>) -> tensor<2x3x4x3xi32>\n+++  %2 = stablehlo.broadcast_in_dim %arg0, dims = [2, 1] : (tensor<3x4xi32>) -> tensor<1x4x3xi32>\n+++  %3 = stablehlo.broadcast_in_dim %2, dims = [0, 2, 3] : (tensor<1x4x3xi32>) -> tensor<2x3x4x3xi32>\n+++\n+++  // CHECK-DAG: return [[BROADCAST_OF_RESHAPE]], [[MERGED_BROADCAST]]\n+++  return %1, %3 : tensor<2x3x4x3xi32>, tensor<2x3x4x3xi32>\n+ +}\n+ +\n+-+FailureOr<SmallVector<Value>> numpyBroadcastIfNeeded(OpBuilder& builder,\n+-+                                                     ArrayRef<Value> operands) {\n+-+  // Figure out the broadcast shape\n+-+  auto bcastShapeOrFail = getNumpyBroadcastShape(operands);\n+-+  if (failed(bcastShapeOrFail)) return failure();\n+-+  Dimensions bcastShape = std::move(*bcastShapeOrFail);\n+-+\n+-+  // Apply to all operands\n+-+  SmallVector<Value> broadcastedOperands;\n+-+  for (auto operand : operands) {\n+-+    auto bcastOperand = numpyBroadcastIfNeeded(builder, operand, bcastShape);\n+-+    if (failed(bcastOperand)) return failure();\n+-+    broadcastedOperands.push_back(*bcastOperand);\n+-+  }\n+-+  return std::move(broadcastedOperands);\n++ // CHECK-LABEL: func.func @broadcast_in_dim_not_identity_broadcasts\n++ func.func @broadcast_in_dim_not_identity_broadcasts(%arg0: tensor<1x2xf32>) -> tensor<2x2xf32> {\n++   // CHECK: stablehlo.broadcast_in_dim\n++@@ -208,6 +237,18 @@\n++   // CHECK-NEXT: return [[C1]], [[C0]], [[C1]], [[C0]], [[R0]], [[R1]], [[R2]], [[R3]]\n++   return %0, %1, %2, %3, %4, %5, %6, %7 :\n++          tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>\n+ +}\n+ +\n+-+FailureOr<Value> numpyBroadcastIfNeeded(OpBuilder& builder, Value input,\n+-+                                        const Dimensions& shape) {\n+-+  LLVM_DEBUG(llvm::dbgs() << \"[BroadcastIfNeeded] input: \" << input\n+-+                          << \" shape: \" << toString(shape));\n+-+  auto loc = input.getLoc();\n+-+  mlir::RankedTensorType input_type =\n+-+      dyn_cast<RankedTensorType>(input.getType());\n+-+  if (!input_type) return emitError(input.getLoc(), \"expected tensor type\");\n+-+  mlir::RankedTensorType output_type =\n+-+      getRankedTensorType(shape, input_type.getElementType());\n+-+\n+-+  // Short circuit if no broadcasting is needed.\n+-+  if (input_type == output_type) return input;\n+-+\n+-+  int64_t input_rank = input_type.getRank();\n+-+  int64_t output_rank = output_type.getRank();\n+-+  if (input_rank > output_rank)\n+-+    return emitError(loc, \"input rank must be <= output rank, got \")\n+-+           << input_rank << \" vs \" << output_rank;\n+-+\n+-+  size_t rank_diff = output_rank - input_rank;\n+-+  SmallVector<int64_t> bcast_dims;\n+-+  bcast_dims.reserve(input_rank);\n+-+\n+-+  auto inputShapeOrFail = getDimensions(input);\n+-+  if (failed(inputShapeOrFail)) return failure();\n+-+  Dimensions inputShape = std::move(*inputShapeOrFail);\n+-+\n+-+  // Construct broadcast dimensions.\n+-+  auto broadcastDimensions = llvm::to_vector(\n+-+      llvm::seq<int64_t>(output_rank - input_rank, output_rank));\n+-+\n+-+  // Construct the result type of the broadcast\n+-+  //  - If input is static and target shape is static, use static shape.\n+-+  //  - If input has bounded dim, target shape must be bounded, use bounded dim.\n+-+  //  - If input is not bounded, but target shape is bounded, broadcast to\n+-+  //    the padded shape then call SetDimensionSize to make dynamic.\n+-+  auto bcastShape = shape;\n+-+  for (size_t i = 0; i < input_rank; ++i) {\n+-+    int64_t input_dim_size = inputShape[i].size;\n+-+    int64_t result_idx = i + rank_diff;\n+-+    int64_t result_dim_size = shape[result_idx].size;\n+-+    if (input_dim_size != 1 && input_dim_size != result_dim_size)\n+-+      return emitError(loc, \"Cannot broadcast input: \")\n+-+             << input_type << \" to target shape \" << toString(shape);\n+-+\n+-+    if (!inputShape[i].boundOp.has_value() &&\n+-+        shape[result_idx].boundOp.has_value()) {\n+-+      // Use padded shape in broadcast.\n+-+      bcastShape[result_idx] = DimensionInfo{shape[result_idx].size};\n+-+    }\n+-+    bcast_dims.push_back(result_idx);\n+-+  }\n+-+\n+-+  // Broadcast to padded size for remaining dimensions.\n+-+  for (size_t i = input_rank; i < shape.size(); ++i) {\n+-+    bcastShape[i] = DimensionInfo{shape[i].size};\n+-+  }\n+-+\n+-+  // Insert broadcast ops\n+-+  mlir::RankedTensorType bcast_type =\n+-+      getRankedTensorType(bcastShape, input_type.getElementType());\n+-+  Value bcast_op = stablehlo::BroadcastInDimOp::create(\n+-+      builder, loc, bcast_type, input, broadcastDimensions);\n+-+  if (bcast_op.getType() == output_type) return bcast_op;\n+-+\n+-+  // Mark the padded broadcast as dynamic where the result is bounded.\n+-+  // Inserts `GetDimSize(boundOp)->SetDimSize(inputBcast)` for any bounded\n+-+  // dimensions that required broadcasting.\n+-+  for (size_t i = 0; i < shape.size(); ++i) {\n+-+    if (!bcastShape[i].boundOp.has_value() && shape[i].boundOp.has_value()) {\n+-+      Value boundOp = shape[i].boundOp.value();\n+-+      auto dim_size = stablehlo::GetDimensionSizeOp::create(\n+-+          builder, loc, boundOp, shape[i].boundOpDim);\n+-+      bcast_op = stablehlo::SetDimensionSizeOp::create(builder, loc, bcast_op,\n+-+                                                       dim_size, i);\n+-+    }\n+-+  }\n+-+  return bcast_op;\n+++// CHECK-LABEL: func.func @compare_op_bool_simplify\n+++// CHECK-SAME:   ([[ARG0:%.+]]: tensor<i1>)\n+++func.func @compare_op_bool_simplify(%arg0: tensor<i1>) -> (tensor<i1>, tensor<i1>) {\n+++  %false = stablehlo.constant dense<false> : tensor<i1>\n+++  %true = stablehlo.constant dense<true> : tensor<i1>\n+++  // CHECK-NOT: stablehlo.compare\n+++  %0 = stablehlo.compare NE, %arg0, %false, UNSIGNED : (tensor<i1>, tensor<i1>) -> tensor<i1>\n+++  %1 = stablehlo.compare EQ, %arg0, %true, UNSIGNED : (tensor<i1>, tensor<i1>) -> tensor<i1>\n+++  // CHECK: return [[ARG0]], [[ARG0]]\n+++  func.return %0, %1 : tensor<i1>, tensor<i1>\n++ }\n++ \n++ // -----\n++@@ -1021,6 +1062,18 @@\n++   // CHECK-NOT: stablehlo.pad\n++   %1 = stablehlo.pad %arg0, %0, low = [0, 0], high = [0, 0], interior = [0, 0] : (tensor<256x1024xbf16>, tensor<bf16>) -> tensor<256x1024xbf16>\n++   return %1 : tensor<256x1024xbf16>\n+ +}\n+ +\n+-+}  // namespace stablehlo\n+-+}  // namespace mlir\n+-diff --ruN a/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h b/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h\n+---- stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h\n+-+++ stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h\n+-@@ -0,0 +1,68 @@\n+-+/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n+-+   Copyright 2022 The StableHLO Authors.\n+-+\n+-+Licensed under the Apache License, Version 2.0 (the \"License\");\n+-+you may not use this file except in compliance with the License.\n+-+You may obtain a copy of the License at\n+-+\n+-+    http://www.apache.org/licenses/LICENSE-2.0\n+-+\n+-+Unless required by applicable law or agreed to in writing, software\n+-+distributed under the License is distributed on an \"AS IS\" BASIS,\n+-+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+-+See the License for the specific language governing permissions and\n+-+limitations under the License.\n+-+==============================================================================*/\n+-+\n+-+\n+-+#ifndef STABLEHLO_TRANSFORMS_OPBROADCASTUTILS_H_\n+-+#define STABLEHLO_TRANSFORMS_OPBROADCASTUTILS_H_\n+-+\n+-+#include <cstdint>\n+-+#include <optional>\n+-+#include <string>\n+-+\n+-+#include \"mlir/IR/Builders.h\"\n+-+#include \"mlir/IR/Value.h\"\n+-+#include \"mlir/Support/LLVM.h\"\n+-+\n+-+namespace mlir {\n+-+namespace stablehlo {\n+-+\n+-+///////\n+-+// Numpy broadcasting with support for bounded dynamism.\n+-+\n+-+// Struct that represents a dim size of a tensor and possible dynamic value to\n+-+// match. If dimension is not dynamic, bound_op is set to std::nullopt. If\n+-+// dimension is bounded, the resulting dimension should be padded to `size` then\n+-+// marked dynamic using:\n+-+//   runtime_size = get_dimension_size(bound_op, dim=bound_op_dim)\n+-+//   T = set_dimension_size(T, dim=bound_op_dim, runtime_size)\n+++// We don't want to delete `pad` ops that move a tensor's values around without\n+++// affecting its dimensions.\n+ +//\n+-+struct DimensionInfo {\n+-+  int64_t size;\n+-+  std::optional<Value> boundOp = std::nullopt;\n+-+  int64_t boundOpDim = -1;\n+-+};\n+-+\n+-+using Dimensions = SmallVector<DimensionInfo>;\n+-+std::string toString(const Dimensions& dims);\n+-+\n+-+// Returns the common shape these ops would broadcast to, or an error if the\n+-+// ops are not broadcastable.\n+-+FailureOr<Dimensions> getNumpyBroadcastShape(ArrayRef<Value> ops);\n+-+\n+-+// Apply numpy broadcasting to the given operands, returning an error if any\n+-+// operands are not broadcastable.\n+-+FailureOr<SmallVector<Value>> numpyBroadcastIfNeeded(OpBuilder& builder,\n+-+                                                     ArrayRef<Value> operands);\n+-+\n+-+// Apply numpy broadcasting to the given operand, returning an error if the\n+-+// operand is not broadcastable.\n+-+FailureOr<Value> numpyBroadcastIfNeeded(OpBuilder& builder, Value input,\n+-+                                        const Dimensions& shape);\n+-+\n+-+}  // namespace stablehlo\n+-+}  // namespace mlir\n+++// CHECK-LABEL: @pad_rotate_tensor_no_dim_change\n+++func.func @pad_rotate_tensor_no_dim_change(%arg0: tensor<50x50xf32>) -> tensor<50x50xf32> {\n+++  // CHECK: %[[RES:.+]] = stablehlo.pad\n+++  // CHECK: return %[[RES]]\n+++  %cst = stablehlo.constant dense<0.0> : tensor<f32>\n+++  %0 = stablehlo.pad %arg0, %cst, low = [0, -1], high = [0, 1], interior = [0, 0] : (tensor<50x50xf32>, tensor<f32>) -> tensor<50x50xf32>\n+++  return %0 : tensor<50x50xf32>\n++ }\n++ \n++ // -----\n++@@ -1810,6 +1863,15 @@\n++   return %0 : tensor<2x4x1x5xf32>\n++ }\n++ \n+++// CHECK-LABEL: @transpose_of_transpose\n+++func.func @transpose_of_transpose(%arg0 : tensor<1x2x3x4xf32>) -> tensor<1x2x3x4xf32> {\n+++  %0 = stablehlo.transpose %arg0, dims = [3,2,1,0] : (tensor<1x2x3x4xf32>) -> tensor<4x3x2x1xf32>\n+++  %1 = stablehlo.transpose %0, dims = [3,2,1,0] : (tensor<4x3x2x1xf32>) -> tensor<1x2x3x4xf32>\n+++  // CHECK-NOT: stablehlo.transpose\n+++  // CHECK: return %arg0\n+++  return %1 : tensor<1x2x3x4xf32>\n+++}\n+ +\n+-+#endif  // STABLEHLO_TRANSFORMS_OPBROADCASTUTILS_H_\n++ // -----\n++ \n++ ////////\n++diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_refine_shapes.mlir b/stablehlo/stablehlo/tests/transforms/stablehlo_refine_shapes.mlir\n++--- stablehlo/stablehlo/tests/transforms/stablehlo_refine_shapes.mlir\n+++++ stablehlo/stablehlo/tests/transforms/stablehlo_refine_shapes.mlir\n++@@ -752,7 +752,7 @@\n++     %2 = call @refine_call_callee(%arg0_different_i32, %1) : (tensor<i32>, tensor<?xf32>) -> tensor<?xf32>\n++     return %2 : tensor<?xf32>\n++   }\n++-  // expected-error@+1{{'func.func' op refined with invompatible refinement keys}}\n+++  // expected-error@+1{{'func.func' op refined with incompatible refinement keys}}\n++   func.func @refine_call_callee(%arg0: tensor<i32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {\n++     return %arg1 : tensor<?xf32>\n++   }\n++@@ -770,7 +770,7 @@\n++     %2 = call @refine_call_callee(%arg0_different, %1) : (tensor<i32>, tensor<?xf32>) -> tensor<?xf32>\n++     return %2 : tensor<?xf32>\n++   }\n++-  // expected-error@+1{{'func.func' op refined with invompatible refinement keys}}\n+++  // expected-error@+1{{'func.func' op refined with incompatible refinement keys}}\n++   func.func @refine_call_callee(%arg0: tensor<i32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {\n++     return %arg1 : tensor<?xf32>\n++   }\n++@@ -789,7 +789,7 @@\n++     %4 = call @refine_call_callee(%arg0_new, %3) : (tensor<i32>, tensor<?xf32>) -> tensor<?xf32>\n++     return %4 : tensor<?xf32>\n++   }\n++-  // expected-error@+1{{'func.func' op refined with invompatible refinement keys}}\n+++  // expected-error@+1{{'func.func' op refined with incompatible refinement keys}}\n++   func.func @refine_call_callee(%arg0: tensor<i32>, %arg1: tensor<?xf32>) -> tensor<?xf32> {\n++     return %arg1 : tensor<?xf32>\n++   }\n++diff --ruN a/stablehlo/stablehlo/transforms/StablehloRefineShapes.cpp b/stablehlo/stablehlo/transforms/StablehloRefineShapes.cpp\n++--- stablehlo/stablehlo/transforms/StablehloRefineShapes.cpp\n+++++ stablehlo/stablehlo/transforms/StablehloRefineShapes.cpp\n++@@ -461,7 +461,7 @@\n++   LogicalResult emitDifferentRefinementContextError(func::FuncOp func,\n++                                                     RefinementKey key,\n++                                                     RefinementKey prevKey) {\n++-    return func.emitOpError() << \"refined with invompatible refinement keys:\"\n+++    return func.emitOpError() << \"refined with incompatible refinement keys:\"\n++                               << \"\\n  curr=\" << key.toString()\n++                               << \"\\n  prev=\" << prevKey.toString();\n++   }\n+ diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp\n+ --- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp\n+ +++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp\n+-@@ -1108,7 +1108,8 @@\n++@@ -530,10 +530,15 @@\n++   using FoldOpRewritePattern<OpType>::matchAndRewrite;\n++   using FoldOpRewritePattern<OpType>::options;\n++ \n+++  // TODO: Generalize all relevant folder patterns to support complex data\n+++  // types, then hard-code `allowComplex` to `true`.\n++   LogicalResult validateShapeFoldDtype(PatternRewriter& rewriter, OpType op,\n++-                                       ShapedType resultType) const {\n+++                                       ShapedType resultType,\n+++                                       bool allowComplex = false) const {\n++     if (resultType.getElementType().isInteger()) return success();\n++-    if (options.optimizeFloat && isa<FloatType>(resultType.getElementType()))\n+++    if (options.optimizeFloat &&\n+++        (allowComplex ? isa<FloatType, ComplexType>(resultType.getElementType())\n+++                      : isa<FloatType>(resultType.getElementType())))\n++       return success();\n++     return rewriter.notifyMatchFailure(op, \"skipping fold of shape op dtype\");\n++   }\n++@@ -605,7 +610,8 @@\n+                                  PatternRewriter& rewriter) const override {\n+      auto resultType = op.getType();\n+      if (failed(validateStaticShapeResult(rewriter, op, resultType)) ||\n+@@ -921,5 +495,178 @@ diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFold\n+ +                                      /*allowComplex=*/true)))\n+        return failure();\n+  \n+-     DenseElementsAttr attr;\n++     SplatElementsAttr cstAttr;\n++@@ -825,7 +831,8 @@\n++     RankedTensorType resultType = op.getType();\n++ \n++     if (failed(validateStaticShapeResult(rewriter, op, resultType)) ||\n++-        failed(validateShapeFoldDtype(rewriter, op, resultType)))\n+++        failed(validateShapeFoldDtype(rewriter, op, resultType)) ||\n+++        failed(validateElementCountForFold(rewriter, op, resultType)))\n++       return failure();\n++ \n++     auto operandElemType = getElementTypeOrSelf(operand.getType());\n++@@ -1104,7 +1111,7 @@\n++         failed(validateShapeFoldDtype(rewriter, op, resultType)))\n++       return failure();\n++ \n++-    DenseIntOrFPElementsAttr attr;\n+++    DenseElementsAttr attr;\n++     if (!matchPattern(op.getOperand(), m_Constant(&attr)))\n++       return rewriter.notifyMatchFailure(op, \"expected constant operand\");\n++     rewriter.replaceOpWithNewOp<ConstantOp>(op, attr.reshape(resultType));\n++diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp\n++--- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp\n+++++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp\n++@@ -1309,10 +1309,20 @@\n++ // TransposeOp\n++ /////////////////////////////////\n++ \n+++DenseI64ArrayAttr getMergedTransposePermutation(OpBuilder& b,\n+++                                                ArrayRef<int64_t> childPerm,\n+++                                                ArrayRef<int64_t> parentPerm) {\n+++  SmallVector<int64_t> mergedPerm;\n+++  mergedPerm.reserve(parentPerm.size());\n+++  for (int64_t parentIdx : parentPerm) {\n+++    mergedPerm.push_back(childPerm[parentIdx]);\n+++  }\n+++  return b.getDenseI64ArrayAttr(mergedPerm);\n+++}\n+++\n++ // Pattern: transpose(X, [no_mem_layout_change...]) -> reshape(X)\n++ struct TransposeIsReshape final : SimplifyOpRewritePattern<TransposeOp> {\n++   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;\n++-\n++   LogicalResult matchAndRewrite(TransposeOp op,\n++                                 PatternRewriter& rewriter) const override {\n++     auto input = op.getOperand();\n++diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td\n++--- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td\n+++++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td\n++@@ -43,6 +43,14 @@\n++     CPred<\"llvm::cast<ShapedType>($0.getType()).getNumElements() == llvm::cast<ShapedType>($1.getType()).getNumElements()\">,\n++     \"same number of elements\">;\n++ \n+++def BroadcastNotReducibleToReshape : Constraint<\n+++    CPred<\"llvm::isa<stablehlo::BroadcastInDimOp>($0.getDefiningOp()) && \"\n+++          \"!(\"\n+++            \"llvm::is_sorted($0.getDefiningOp<stablehlo::BroadcastInDimOp>().getBroadcastDimensions()) && \"\n+++            \"llvm::cast<ShapedType>($0.getType()).getNumElements() == llvm::cast<ShapedType>($1.getType()).getNumElements()\"\n+++          \")\">,\n+++    \"is a broadcast_in_dim op that cannot be simplified to a reshape op\">;\n+++\n++ def OperandsEqual : Constraint<CPred<\"$0 == $1\">, \"operands are equal\">;\n++ \n++ def RankEqual : Constraint<\n++@@ -61,6 +69,10 @@\n++ def AnyZero : AttrConstraint<\n++     CPred<\"::mlir::matchPattern($_self, m_AnyAttrOf(m_Zero(), m_AnyZeroFloat()))\">,\n++     \"is int or float zero\">;\n+++\n+++def ZeroArrayI64 : AttrConstraint<\n+++    CPred<\"::llvm::all_of(::llvm::cast<DenseI64ArrayAttr>($_self).asArrayRef(), [](int64_t val) { return val == 0; })\">,\n+++    \"is an array of zeros\">;\n++ \n++ def DenseIntElementsAttr : AttrConstraint<\n++     CPred<\"llvm::isa<DenseIntElementsAttr>($_self)\">,\n++@@ -120,6 +132,8 @@\n++ \n++ def MergeBroadcastDims : NativeCodeCall<\"getMergedBroadcastDimensions($_builder, $0, $1)\">;\n++ \n+++def MergePermutations : NativeCodeCall<\"getMergedTransposePermutation($_builder, $0, $1)\">;\n+++\n++ def StableHLO_ConvertOpWithShape : NativeCodeCall<\n++     \"$_builder.create<stablehlo::ConvertOp>($_loc, $0.getType(), $1)\">;\n++ \n++@@ -178,18 +192,23 @@\n++ \n++ // Pattern: broadcast_in_dim(broadcast_in_dim(X, [dimsA...]), [dimsB...])\n++ //       -> broadcast_in_dim(X, merge(dimsA, dimsB))\n+++//          [if the nested broadcast can't be simplified to a reshape]\n++ def BroadcastInDimOp_MergeComposition\n++-  : Pat<(StableHLO_BroadcastInDimOp\n++-            (StableHLO_BroadcastInDimOp $operand, $dims_parent), $dims),\n+++  : Pat<(StableHLO_BroadcastInDimOp:$outer_op\n+++            (StableHLO_BroadcastInDimOp:$inner_op $operand, $inner_dims),\n+++            $outer_dims),\n++         (StableHLO_BroadcastInDimOp\n++-            $operand, (MergeBroadcastDims $dims, $dims_parent))>;\n+++            $operand, (MergeBroadcastDims $outer_dims, $inner_dims)),\n+++        [(BroadcastNotReducibleToReshape $inner_op, $operand)]>;\n++ \n++ // Pattern: broadcast_in_dim(X, [sorted...]) -> reshape(X, [sorted...])\n++ //          [if same numel]\n++ def BroadcastInDimOp_ReplaceWithReshape\n++   : Pat<(StableHLO_BroadcastInDimOp:$op $operand, SortedDims:$dims),\n++         (StableHLO_ReshapeOpWithShape $op, $operand),\n++-        [(NumberOfElementsEqual $op, $operand)]>;\n+++        [(NumberOfElementsEqual $op, $operand)],\n+++        [],\n+++        (addBenefit 1)>;\n++ \n++ // Pattern: broadcast_in_dim(X, [dims...]) -> transpose(X, [dims...])\n++ //          [if same numel & rank]\n++@@ -197,6 +216,36 @@\n++   : Pat<(StableHLO_BroadcastInDimOp:$op $operand, $dims),\n++         (StableHLO_TransposeOp $operand, (InvertBroadcastDims $dims)),\n++         [(NumberOfElementsEqual $op, $operand), (RankEqual $op, $operand)]>;\n+++\n+++////////\n+++// CompareOp\n+++\n+++// The canonical form has the constant operand as the RHS.\n+++class StableHLO_ComparisonDirectionValue<string enumStr> :\n+++  ConstantAttr<StableHLO_ComparisonDirectionAttr, \"::mlir::stablehlo::ComparisonDirection::\" # enumStr>;\n+++\n+++// Pattern: compare(NE, X, False) : i1 -> X\n+++def CompareOp_NeBooleanFalse\n+++  : Pat<(StableHLO_CompareOp\n+++            $lhs,\n+++            (StableHLO_ConstantOp:$cst IntZero:$value),\n+++            StableHLO_ComparisonDirectionValue<\"NE\">,\n+++            $type),\n+++        (replaceWithValue $lhs),\n+++        [(HLO_PredTensor $cst)]>;\n+++\n+++// Pattern: compare(EQ, X, True) : i1 -> X\n+++def CompareOp_EqBooleanTrue\n+++  : Pat<(StableHLO_CompareOp\n+++            $lhs,\n+++            (StableHLO_ConstantOp:$cst IntOne:$value),\n+++            StableHLO_ComparisonDirectionValue<\"EQ\">,\n+++            $type),\n+++        (replaceWithValue $lhs),\n+++        [(HLO_PredTensor $cst)]>;\n+++\n+++// TODO: compare(EQ, X, False) : i1 -> not(X)\n+++// TODO: compare(NE, X, True) : i1 -> not(X)\n++ \n++ ////////\n++ // ConvertOp\n++@@ -424,9 +473,9 @@\n++   : Pat<(StableHLO_PadOp:$pad\n++             $operand,\n++             $padding_value,\n++-            $edge_padding_low,\n++-            $edge_padding_high,\n++-            $interior_padding),\n+++            ZeroArrayI64:$edge_padding_low,\n+++            ZeroArrayI64:$edge_padding_high,\n+++            ZeroArrayI64:$interior_padding),\n++         (replaceWithValue $operand),\n++         [(TypesEqual $pad, $operand)]>;\n++ \n++@@ -539,6 +588,12 @@\n++   : Pat<(StableHLO_TransposeOp $lhs, IotaDims:$dims),\n++         (replaceWithValue $lhs)>;\n++ \n+++// Pattern: transpose(transpose(X)) -> transpose(X)\n+++def TransposeOp_TransposeOfTranspose\n+++  : Pat<(StableHLO_TransposeOp\n+++          (StableHLO_TransposeOp $child, $child_dims), $dims),\n+++        (StableHLO_TransposeOp $child, (MergePermutations $child_dims, $dims))>;\n+++\n++ ////////\n++ // GetTupleElementOp\n++ \n+ \n+diff --git a/third_party/stablehlo/workspace.bzl b/third_party/stablehlo/workspace.bzl\n+index 1c05593..db43355 100644\n+--- a/third_party/stablehlo/workspace.bzl\n++++ b/third_party/stablehlo/workspace.bzl\n+@@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n+ \n+ def repo():\n+     #\n+-    STABLEHLO_COMMIT = \"3f27c53c20b9021ccab8b5f673e2c72e5b9cd6aa\"\n+-    STABLEHLO_SHA256 = \"915e05e79d9764c048557a929c64e090ab58a5c7334da2c2650cd6378aa4d166\"\n++    STABLEHLO_COMMIT = \"baaf7475f8925cb0c5f9580408b3c0385f888487\"\n++    STABLEHLO_SHA256 = \"c4b96f94d9d4aaa8b2dc88104579aab662aa33d59b79e77a9b75c8e0af3d9461\"\n+     #\n+ \n+     tf_http_archive("
        },
        {
            "sha": "e0075b22d31fc26ec24a0100ec9dec9835d21500",
            "filename": "third_party/xla/third_party/shardy/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl?ref=30beaef2b1a16997259be42602430a6cede3252a",
            "patch": "@@ -3,8 +3,8 @@\n load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n \n def repo():\n-    SHARDY_COMMIT = \"e269b4c1968c930518c42c02bfdcdf0d921793de\"\n-    SHARDY_SHA256 = \"bdf22ae5d5a1ecacdca762da892e2291a7f82ddc42a23b1ca096dadb490d6068\"\n+    SHARDY_COMMIT = \"615332f5ff861554dd6f6dc30ad2652a3ae0b962\"\n+    SHARDY_SHA256 = \"aadd9b247dd34dc16c7358e247938f119d7b970cab6088247700b966299a995f\"\n \n     tf_http_archive(\n         name = \"shardy\","
        },
        {
            "sha": "2c12f164868aec68f06db4d62171433b545e7b39",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl828494580.patch",
            "status": "added",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl828494580.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl828494580.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl828494580.patch?ref=30beaef2b1a16997259be42602430a6cede3252a",
            "patch": "@@ -0,0 +1,12 @@\n+\n+--- a/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/ElementwiseOpToLLVM.cpp\t2025-08-29 00:00:16.000000000 -0700\n++++ b/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/ElementwiseOpToLLVM.cpp\t2025-11-05 09:23:21.000000000 -0800\n+@@ -655,7 +655,7 @@\n+     Value prod = b.fmul(f32_ty, operands[0][0], b.f32_val(log2e));\n+ \n+     Type resultTy = operands[0][0].getType();\n+-    StringRef name = \"llvm.nvvm.ex2.approx.f\";\n++    StringRef name = \"llvm.nvvm.ex2.approx.f32\";\n+     auto callOp =\n+         LLVM::createLLVMIntrinsicCallOp(rewriter, loc, name, resultTy, {prod});\n+     return {callOp.getResult(0)};"
        },
        {
            "sha": "23e8b3c624c1fc1fd8c0addcf2a614a279a3709e",
            "filename": "third_party/xla/third_party/triton/llvm_integration/series.bzl",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/30beaef2b1a16997259be42602430a6cede3252a/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl?ref=30beaef2b1a16997259be42602430a6cede3252a",
            "patch": "@@ -10,5 +10,6 @@ LLVM nor MLIR integrator, please do not add any patches to this list.\n llvm_patch_list = [\n     \"//third_party/triton:llvm_integration/cl823109577.patch\",\n     \"//third_party/triton:llvm_integration/cl825373861.patch\",\n+    \"//third_party/triton:llvm_integration/cl828494580.patch\",\n     # Add new patches just above this line\n ]"
        }
    ],
    "stats": {
        "total": 1731,
        "additions": 1722,
        "deletions": 9
    }
}