{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Allow configurable memory sizes for CollectiveOpsE2ETestBase.\n\nPiperOrigin-RevId: 840101743",
    "sha": "0e6499ebb7c80aeaef817a72e3d1bf0b305f2431",
    "files": [
        {
            "sha": "33aad38269cee9a09dd74527f3192d2a4983c360",
            "filename": "third_party/xla/xla/tests/collective_metadata_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_metadata_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_metadata_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_metadata_test.cc?ref=0e6499ebb7c80aeaef817a72e3d1bf0b305f2431",
            "patch": "@@ -31,6 +31,10 @@ namespace {\n \n class CollectiveMetadataTest : public CollectiveOpsE2ETestBase {\n  protected:\n+  CollectiveMetadataTest()\n+      : CollectiveOpsE2ETestBase(/*memory_size=*/32 * kMB,\n+                                 /*collectives_memory_size=*/1 * kMB) {}\n+\n   void SetUp() override {\n     CollectiveOpsE2ETestBase::SetUp();\n     if (!IsHopperAndHigher()) {"
        },
        {
            "sha": "1191df40032c41161a0fb5b2e5672e85071ea7a0",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 6,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc?ref=0e6499ebb7c80aeaef817a72e3d1bf0b305f2431",
            "patch": "@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include <cmath>\n+#include <cstddef>\n #include <cstdint>\n #include <memory>\n #include <string>\n@@ -77,6 +78,10 @@ bool IsAsync(const HloInstruction* inst) {\n \n class CollectiveOpsTestE2E : public CollectiveOpsE2ETestBase {\n  public:\n+  explicit CollectiveOpsTestE2E(size_t memory_size = 32 * kMB,\n+                                size_t collectives_memory_size = 0)\n+      : CollectiveOpsE2ETestBase(memory_size, collectives_memory_size) {}\n+\n   bool HasFp8Support() {\n     if (Capability().IsCuda()) {\n       return Capability().cuda_compute_capability()->IsAtLeast(8, 9);\n@@ -119,24 +124,31 @@ class AsyncCollectiveOps : public CollectiveOpsWithFlagsBase,\n  public:\n   AsyncCollectiveOps()\n       : CollectiveOpsWithFlagsBase(/*enable_async=*/GetParam(),\n-                                   /*enable_p2p_memcpy=*/false) {}\n+                                   /*enable_p2p_memcpy=*/false,\n+                                   /*memory_size=*/8 * kGB,\n+                                   /*collectives_memory_size=*/0) {}\n };\n \n class MemcpyCollectiveOps : public CollectiveOpsWithFlagsBase,\n                             public ::testing::WithParamInterface<bool> {\n  public:\n   MemcpyCollectiveOps()\n       : CollectiveOpsWithFlagsBase(/*enable_async=*/true,\n-                                   /*enable_p2p_memcpy=*/GetParam()) {}\n+                                   /*enable_p2p_memcpy=*/GetParam(),\n+                                   /*memory_size=*/32 * kMB,\n+                                   /*collectives_memory_size=*/0) {}\n };\n \n class AsyncMemcpyCollectiveOps\n     : public CollectiveOpsWithFlagsBase,\n       public ::testing::WithParamInterface<std::tuple<bool, bool>> {\n  public:\n   AsyncMemcpyCollectiveOps()\n-      : CollectiveOpsWithFlagsBase(std::get<0>(GetParam()),\n-                                   std::get<1>(GetParam())) {}\n+      : CollectiveOpsWithFlagsBase(\n+            /*enable_async=*/std::get<0>(GetParam()),\n+            /*enable_p2p_memcpy=*/std::get<1>(GetParam()),\n+            /*memory_size=*/32 * kMB,\n+            /*collectives_memory_size=*/0) {}\n };\n \n std::string GetAsyncTestName(bool is_async) {\n@@ -1264,6 +1276,10 @@ TEST_F(CollectiveOpsTestE2E, HostMemoryOffloadingWithDonation) {\n // E2E tests comparing the results of windowed einsum and non-windowed cases.\n class CollectiveOpsTestE2EWindowedNonWindowed : public CollectiveOpsTestE2E {\n  public:\n+  CollectiveOpsTestE2EWindowedNonWindowed()\n+      : CollectiveOpsTestE2E(/*memory_size=*/4 * kGB,\n+                             /*collectives_memory_size=*/0) {}\n+\n   void CollectiveOpsCompareWindowedNonWindowed(\n       absl::string_view hlo_text, bool disable_dot_merger = false,\n       bool enable_a2a_rewrite = false) {\n@@ -2375,8 +2391,10 @@ class AllReduceTest\n   };\n \n   AllReduceTest()\n-      : CollectiveOpsWithFlagsBase(std::get<0>(GetParam()),\n-                                   /*enable_p2p_memcpy=*/false) {}\n+      : CollectiveOpsWithFlagsBase(/*enable_async=*/std::get<0>(GetParam()),\n+                                   /*enable_p2p_memcpy=*/false,\n+                                   /*memory_size=*/32 * kMB,\n+                                   /*collectives_memory_size=*/0) {}\n \n  protected:\n   DebugOptions GetDebugOptionsForTest() const override {"
        },
        {
            "sha": "775007fa085eec1a0b709fa121e890542f1c9ad5",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test_base.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.cc?ref=0e6499ebb7c80aeaef817a72e3d1bf0b305f2431",
            "patch": "@@ -82,26 +82,23 @@ Type CheckStatus(absl::StatusOr<Type> result) {\n \n }  // namespace\n \n-CollectiveOpsE2ETestBase::CollectiveOpsE2ETestBase() {\n+void CollectiveOpsE2ETestBase::SetupHloRunner(size_t memory_size,\n+                                              size_t collectives_memory_size) {\n   se::Platform* platform = CheckStatus(PlatformUtil::GetPlatform(\"GPU\"));\n   se::Platform* reference_platform =\n       CheckStatus(PlatformUtil::GetPlatform(\"GPU\"));\n \n   std::vector<se::MultiDeviceAdapter::AllocatorInfo> allocators;\n-  constexpr int64_t kGB = 1024LL * 1024LL * 1024LL;\n-  size_t common_buffers_size = 8 * kGB;   // 8GB\n-  size_t collectives_buffers_size = kGB;  // 1GB\n   for (int64_t i = 0; i < platform->VisibleDeviceCount(); ++i) {\n     se::StreamExecutor* executor = CheckStatus(platform->ExecutorForDevice(i));\n     // Common memory allocator for device i.\n     allocators.emplace_back(\n-        CreateAllocator(executor, i, /*is_collective=*/false,\n-                        common_buffers_size),\n+        CreateAllocator(executor, i, /*is_collective=*/false, memory_size),\n         nullptr, 0, i, platform);\n \n     // Collectives and symmetric memory allocator for device i.\n     allocators.emplace_back(CreateAllocator(executor, i, /*is_collective=*/true,\n-                                            collectives_buffers_size),\n+                                            collectives_memory_size),\n                             nullptr, (int)gpu::MemorySpaceColor::kCollective, i,\n                             platform);\n   }"
        },
        {
            "sha": "93190cc0e7c85c61e7303152528740f7ecb8c8ac",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test_base.h",
            "status": "modified",
            "additions": 15,
            "deletions": 3,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.h?ref=0e6499ebb7c80aeaef817a72e3d1bf0b305f2431",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #ifndef XLA_TESTS_COLLECTIVE_OPS_E2E_TEST_BASE_H_\n #define XLA_TESTS_COLLECTIVE_OPS_E2E_TEST_BASE_H_\n \n+#include <cstddef>\n #include <cstdint>\n #include <memory>\n #include <vector>\n@@ -40,9 +41,14 @@ limitations under the License.\n \n namespace xla {\n \n+inline constexpr size_t kMB = 1024LL * 1024LL;\n+inline constexpr size_t kGB = 1024LL * kMB;\n+\n class CollectiveOpsE2ETestBase : public HloHardwareIndependentTestBase {\n  public:\n-  CollectiveOpsE2ETestBase();\n+  CollectiveOpsE2ETestBase(size_t memory_size, size_t collectives_memory_size) {\n+    SetupHloRunner(memory_size, collectives_memory_size);\n+  }\n \n   struct ExecutionResult {\n     std::unique_ptr<OpaqueExecutable> executable;\n@@ -77,6 +83,9 @@ class CollectiveOpsE2ETestBase : public HloHardwareIndependentTestBase {\n  protected:\n   std::unique_ptr<HloRunner> hlo_runner_;\n   std::unique_ptr<HloRunner> reference_hlo_runner_;\n+\n+ private:\n+  void SetupHloRunner(size_t memory_size, size_t collectives_memory_size);\n };\n \n // E2E tests for collective ops. These will generally verify some HLO transform\n@@ -88,8 +97,11 @@ class CollectiveOpsE2ETestBase : public HloHardwareIndependentTestBase {\n // flag. Subclasses pass in constructor arguments based on GetParam().\n class CollectiveOpsWithFlagsBase : public CollectiveOpsE2ETestBase {\n  public:\n-  CollectiveOpsWithFlagsBase(bool enable_async, bool enable_p2p_memcpy)\n-      : enable_async_(enable_async), enable_p2p_memcpy_(enable_p2p_memcpy) {}\n+  CollectiveOpsWithFlagsBase(bool enable_async, bool enable_p2p_memcpy,\n+                             size_t memory_size, size_t collectives_memory_size)\n+      : CollectiveOpsE2ETestBase(memory_size, collectives_memory_size),\n+        enable_async_(enable_async),\n+        enable_p2p_memcpy_(enable_p2p_memcpy) {}\n \n  protected:\n   DebugOptions GetDebugOptionsForTest() const override;"
        },
        {
            "sha": "f56ef7045eca7bab8d35939f1389eabe2e331045",
            "filename": "third_party/xla/xla/tests/collective_ops_ffi_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_ffi_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_ffi_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_ffi_test.cc?ref=0e6499ebb7c80aeaef817a72e3d1bf0b305f2431",
            "patch": "@@ -43,7 +43,12 @@ limitations under the License.\n \n namespace xla::gpu {\n \n-class CollectiveOpsTestFFI : public CollectiveOpsE2ETestBase {};\n+class CollectiveOpsTestFFI : public CollectiveOpsE2ETestBase {\n+ public:\n+  CollectiveOpsTestFFI()\n+      : CollectiveOpsE2ETestBase(/*memory_size=*/1 * kMB,\n+                                 /*collectives_memory_size=*/0) {}\n+};\n \n static constexpr int64_t kNumReplicas = 2;\n "
        },
        {
            "sha": "523a50f4552a50e03ac483aa2300c326b31ad95d",
            "filename": "third_party/xla/xla/tests/collective_ops_sharded_unsharded_e2e_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_sharded_unsharded_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_sharded_unsharded_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_sharded_unsharded_e2e_test.cc?ref=0e6499ebb7c80aeaef817a72e3d1bf0b305f2431",
            "patch": "@@ -49,6 +49,10 @@ namespace {\n // E2E tests comparing the results of sharded and unsharded execution.\n class CollectiveOpsTestE2EShardedUnsharded : public CollectiveOpsE2ETestBase {\n  public:\n+  CollectiveOpsTestE2EShardedUnsharded()\n+      : CollectiveOpsE2ETestBase(/*memory_size=*/64 * kMB,\n+                                 /*collectives_memory_size=*/0) {}\n+\n   void CollectiveOpsCompareShardedUnsharded(\n       const std::string& hlo_text, const int64_t num_partitions = 2,\n       bool enable_enzyme_comms_opt = false) {"
        },
        {
            "sha": "cad950b9f08c83d7a156feed804eda19392c1fa0",
            "filename": "third_party/xla/xla/tests/ragged_all_to_all_e2e_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fragged_all_to_all_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e6499ebb7c80aeaef817a72e3d1bf0b305f2431/third_party%2Fxla%2Fxla%2Ftests%2Fragged_all_to_all_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fragged_all_to_all_e2e_test.cc?ref=0e6499ebb7c80aeaef817a72e3d1bf0b305f2431",
            "patch": "@@ -62,7 +62,9 @@ enum class RaggedAllToAllImplType {\n class RaggedAllToAllTestBase : public CollectiveOpsWithFlagsBase {\n  public:\n   RaggedAllToAllTestBase(bool enable_async, RaggedAllToAllImplType impl_type)\n-      : CollectiveOpsWithFlagsBase(enable_async, /*enable_p2p_memcpy=*/false),\n+      : CollectiveOpsWithFlagsBase(enable_async, /*enable_p2p_memcpy=*/false,\n+                                   /*memory_size=*/64 * kMB,\n+                                   /*collectives_memory_size=*/0),\n         impl_type_(impl_type) {}\n \n   // Creates random test data for a ragged-all-to-all."
        }
    ],
    "stats": {
        "total": 78,
        "additions": 60,
        "deletions": 18
    }
}