{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 809483549",
    "sha": "4f01d1f05f07bba9979319e61c90b73fffd916b6",
    "files": [
        {
            "sha": "aaccefd00edc10e89970b61853ee7b9e86e61267",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_util.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4f01d1f05f07bba9979319e61c90b73fffd916b6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4f01d1f05f07bba9979319e61c90b73fffd916b6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_util.cc?ref=4f01d1f05f07bba9979319e61c90b73fffd916b6",
            "patch": "@@ -101,7 +101,7 @@ absl::StatusOr<std::string> GetCacheFilePath(absl::string_view cache_dir,\n ResultAndInserted AddResultToInMemoryCache(const AutotuneCacheKey& key,\n                                            AutotuneResult result)\n     ABSL_LOCKS_EXCLUDED(autotune_cache_mu) {\n-  absl::MutexLock lock(&autotune_cache_mu);\n+  absl::MutexLock lock(autotune_cache_mu);\n   auto [it, inserted] = autotune_cache.emplace(key, std::move(result));\n   return {it->second, inserted};\n }\n@@ -151,7 +151,7 @@ absl::Status AddResultToFileBasedCacheIfEnabled(\n \n std::optional<AutotuneResult> TryToFindInInMemoryCache(\n     const AutotuneCacheKey& key) ABSL_LOCKS_EXCLUDED(autotune_cache_mu) {\n-  absl::MutexLock lock(&autotune_cache_mu);\n+  absl::MutexLock lock(autotune_cache_mu);\n   auto it = autotune_cache.find(key);\n   if (it == autotune_cache.end()) {\n     return std::nullopt;\n@@ -230,7 +230,7 @@ void SerializeAutotuneEntry(AutotuneResults* results, const AutotuneCacheKey& k,\n \n /*static*/ absl::Status AutotunerUtil::SerializeAutotuneResults(\n     AutotuneResults* results, std::optional<const AutotuneCacheKeySet*> keys) {\n-  absl::MutexLock lock(&autotune_cache_mu);\n+  absl::MutexLock lock(autotune_cache_mu);\n   for (const auto& [k, result] : autotune_cache) {\n     if (!keys.has_value() || keys.value()->contains(k)) {\n       SerializeAutotuneEntry(results, k, &result);\n@@ -245,7 +245,7 @@ void SerializeAutotuneEntry(AutotuneResults* results, const AutotuneCacheKey& k,\n \n /*static*/ absl::Status AutotunerUtil::LoadAutotuneResults(\n     const AutotuneResults& results, bool allow_override) {\n-  absl::MutexLock lock(&autotune_cache_mu);\n+  absl::MutexLock lock(autotune_cache_mu);\n   for (const AutotuneResults::Entry& result : results.results()) {\n     AutotuneCacheKey key(result.device(), result.hlo(), result.version());\n     if (allow_override) {\n@@ -262,12 +262,12 @@ void SerializeAutotuneEntry(AutotuneResults* results, const AutotuneCacheKey& k,\n }\n \n /*static*/ void AutotunerUtil::ClearAutotuneResults() {\n-  absl::MutexLock lock(&autotune_cache_mu);\n+  absl::MutexLock lock(autotune_cache_mu);\n   autotune_cache.clear();\n }\n \n /*static*/ bool AutotunerUtil::ResultCacheIsEmpty() {\n-  absl::MutexLock lock(&autotune_cache_mu);\n+  absl::MutexLock lock(autotune_cache_mu);\n   return autotune_cache.empty();\n }\n \n@@ -391,7 +391,7 @@ absl::StatusOr<std::optional<AutotuneResult>> AutotunerUtil::TryFindInCache(\n \n   {\n     auto cache_hit = cached.second.has_value();\n-    absl::MutexLock lock(&autotune_cache_mu);\n+    absl::MutexLock lock(autotune_cache_mu);\n     autotune_cache_stats.cache_hits += cache_hit ? 1 : 0;\n     autotune_cache_stats.cache_misses += cache_hit ? 0 : 1;\n   }\n@@ -507,12 +507,12 @@ bool IsTextProtoPath(absl::string_view file_path) {\n }\n \n /*static*/ AutotunerUtil::CacheStats AutotunerUtil::GetCacheStats() {\n-  absl::MutexLock lock(&autotune_cache_mu);\n+  absl::MutexLock lock(autotune_cache_mu);\n   return autotune_cache_stats;\n }\n \n /*static*/ void AutotunerUtil::ClearCacheStats() {\n-  absl::MutexLock lock(&autotune_cache_mu);\n+  absl::MutexLock lock(autotune_cache_mu);\n   autotune_cache_stats = CacheStats();\n }\n "
        },
        {
            "sha": "816dba9169da09023fe974c0c476da325e30a113",
            "filename": "third_party/xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4f01d1f05f07bba9979319e61c90b73fffd916b6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4f01d1f05f07bba9979319e61c90b73fffd916b6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc?ref=4f01d1f05f07bba9979319e61c90b73fffd916b6",
            "patch": "@@ -408,7 +408,7 @@ absl::StatusOr<AutotuneResult> GpuConvAlgorithmPicker::PickBestAlgorithmNoCache(\n   // Putting the lock in here rather than in PickBestAlgorithmNoCache lets us\n   // avoid ever doing duplicate work.  If we have a cache miss, only one thread\n   // will run PickBestAlgorithmImpl for a particular device.\n-  absl::MutexLock lock(&GetGpuMutex(stream_exec));\n+  absl::MutexLock lock(GetGpuMutex(stream_exec));\n \n   // Make sure any previous activity on this executor is done. We don't want\n   // other work still running on the GPU to interfere with autotuning."
        },
        {
            "sha": "529cc5fe5c89124c2a023812fa5adfd57fd5c596",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4f01d1f05f07bba9979319e61c90b73fffd916b6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4f01d1f05f07bba9979319e61c90b73fffd916b6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc?ref=4f01d1f05f07bba9979319e61c90b73fffd916b6",
            "patch": "@@ -1034,7 +1034,7 @@ GemmFusionAutotunerImpl::CompileAll(AutotunerCompileUtil& compile_util,\n               << fusion->fused_instructions_computation()->ToString();\n           log(*executable != nullptr);\n           if (*executable != nullptr) {\n-            absl::MutexLock lock(&results_mu);\n+            absl::MutexLock lock(results_mu);\n             results[fusion].push_back({config, std::move(*executable)});\n           } else {\n             VLOG(10) << \"no executable for config: \" << ConfigToString(config);"
        }
    ],
    "stats": {
        "total": 22,
        "additions": 11,
        "deletions": 11
    }
}