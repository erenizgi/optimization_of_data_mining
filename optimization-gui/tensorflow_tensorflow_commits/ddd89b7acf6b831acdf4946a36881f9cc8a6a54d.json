{
    "author": "ezhulenev",
    "message": "[xla:cpu] Wire custom CpuMemory allocation function into PjRt CPU client\n\nPiperOrigin-RevId: 802781992",
    "sha": "ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
    "files": [
        {
            "sha": "52a6070f0a51c3741f249afa3fbd406040738918",
            "filename": "third_party/xla/xla/pjrt/cpu/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD?ref=ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
            "patch": "@@ -146,6 +146,7 @@ cc_library(\n         \"//xla:cpu_function_runtime\",\n         \"//xla:debug_options_flags\",\n         \"//xla:executable_run_options\",\n+        \"//xla:execution_options_util\",\n         \"//xla:literal\",\n         \"//xla:literal_util\",\n         \"//xla:shape_util\",\n@@ -164,6 +165,7 @@ cc_library(\n         \"//xla/hlo/builder:xla_computation\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/ir:hlo_module_group\",\n+        \"//xla/pjrt:abstract_tracked_device_buffer\",\n         \"//xla/pjrt:async_work_runner\",\n         \"//xla/pjrt:common_pjrt_client\",\n         \"//xla/pjrt:device_event\",\n@@ -185,6 +187,7 @@ cc_library(\n         \"//xla/pjrt/dump\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_client_options\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_execute_options\",\n+        \"//xla/pjrt/plugin/xla_cpu:cpu_memory\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_topology\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_topology_description\",\n         \"//xla/pjrt/proto:compile_options_proto_cc\",\n@@ -257,6 +260,7 @@ xla_cc_test(\n         \"//xla/pjrt:pjrt_client\",\n         \"//xla/pjrt:pjrt_executable\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_client_options\",\n+        \"//xla/pjrt/plugin/xla_cpu:cpu_memory\",\n         \"//xla/pjrt/plugin/xla_cpu:xla_cpu_pjrt_client\",\n         \"//xla/service:hlo_proto_cc\",\n         \"//xla/tests:literal_test_util\",\n@@ -271,6 +275,7 @@ xla_cc_test(\n         \"//xla/tsl/platform:test_main\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/synchronization\",\n         \"@com_google_googletest//:gtest\","
        },
        {
            "sha": "7f5c1f29955817a70626596a67d62b2b049d2b30",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client.cc",
            "status": "modified",
            "additions": 70,
            "deletions": 26,
            "changes": 96,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc?ref=ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
            "patch": "@@ -54,7 +54,6 @@ limitations under the License.\n #include \"xla/backends/cpu/runtime/thunk_executor.h\"\n #include \"xla/backends/cpu/runtime/xfeed_manager.h\"\n #include \"xla/client/executable_build_options.h\"\n-#include \"xla/cpu_function_runtime.h\"\n #include \"xla/debug_options_flags.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n@@ -66,6 +65,7 @@ limitations under the License.\n #include \"xla/layout_util.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n+#include \"xla/pjrt/abstract_tracked_device_buffer.h\"\n #include \"xla/pjrt/common_pjrt_client.h\"\n #include \"xla/pjrt/cpu/abstract_cpu_buffer.h\"\n #include \"xla/pjrt/cpu/cpu_async_execution_tracker.h\"\n@@ -81,13 +81,13 @@ limitations under the License.\n #include \"xla/pjrt/layout_mode.h\"\n #include \"xla/pjrt/mlir_to_hlo.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n-#include \"xla/pjrt/pjrt_client_utils.h\"\n #include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_executable.h\"\n #include \"xla/pjrt/pjrt_future.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_client_options.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_execute_options.h\"\n+#include \"xla/pjrt/plugin/xla_cpu/cpu_memory.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_topology.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_topology_description.h\"\n #include \"xla/pjrt/proto/compile_options.pb.h\"\n@@ -96,15 +96,12 @@ limitations under the License.\n #include \"xla/pjrt/thread_pool_async_work_runner.h\"\n #include \"xla/pjrt/transpose.h\"\n #include \"xla/pjrt/utils.h\"\n-#include \"xla/primitive_util.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/compiler.h\"\n #include \"xla/service/computation_placer.h\"\n #include \"xla/service/cpu/cpu_compiler.h\"\n #include \"xla/service/cpu/cpu_executable.h\"\n #include \"xla/service/cpu/cpu_executable_run_options.h\"\n-#include \"xla/service/custom_call_status.h\"\n-#include \"xla/service/custom_call_status_internal.h\"\n #include \"xla/service/dump.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/hlo.pb.h\"\n@@ -131,8 +128,6 @@ limitations under the License.\n #include \"tsl/platform/denormal.h\"\n #include \"tsl/platform/fingerprint.h\"\n #include \"tsl/platform/setround.h\"\n-#include \"tsl/profiler/lib/connected_traceme.h\"\n-#include \"tsl/profiler/lib/context_types.h\"\n #include \"tsl/profiler/lib/traceme.h\"\n \n #define EIGEN_USE_THREADS\n@@ -147,6 +142,46 @@ static int CpuDeviceCount() {\n   return GetDebugOptionsFromFlags().xla_force_host_platform_device_count();\n }\n \n+namespace {\n+\n+// A custom memory allocator function passed via the CPU client options.\n+using CustomAllocatorFn =\n+    std::function<absl::StatusOr<std::unique_ptr<CpuMemory>>(size_t size_bytes,\n+                                                             size_t alignment)>;\n+\n+// A custom raw memory that wraps a CpuMemory allocated by the user.\n+class CustomMemory final : public CpuDeviceMemory::RawMemory {\n+ public:\n+  explicit CustomMemory(std::unique_ptr<CpuMemory> mem)\n+      : mem_(std::move(mem)) {}\n+\n+  void* base() const final { return mem_->base(); }\n+  size_t size_bytes() const final { return mem_->size_bytes(); }\n+\n+ private:\n+  std::unique_ptr<CpuMemory> mem_;\n+};\n+\n+// A custom raw memory allocator that wraps an allocation function passed via\n+// the client options.\n+class CustomAllocator final : public CpuDeviceMemory::Allocator {\n+ public:\n+  explicit CustomAllocator(CustomAllocatorFn allocator_fn)\n+      : allocator_fn_(std::move(allocator_fn)) {}\n+\n+  absl::StatusOr<std::unique_ptr<CpuDeviceMemory::RawMemory>> Allocate(\n+      size_t size_bytes, size_t alignment) const final {\n+    TF_ASSIGN_OR_RETURN(std::unique_ptr<CpuMemory> mem,\n+                        allocator_fn_(size_bytes, alignment));\n+    return std::make_unique<CustomMemory>(std::move(mem));\n+  }\n+\n+ private:\n+  CustomAllocatorFn allocator_fn_;\n+};\n+\n+}  // namespace\n+\n absl::StatusOr<std::unique_ptr<PjRtClient>> GetPjRtCpuClient(\n     CpuClientOptions options) {\n   // Need at least CpuDeviceCount threads to launch one collective.\n@@ -161,9 +196,13 @@ absl::StatusOr<std::unique_ptr<PjRtClient>> GetPjRtCpuClient(\n     devices.push_back(std::move(device));\n   }\n \n+  std::unique_ptr<CpuDeviceMemory::Allocator> allocator =\n+      options.allocator ? std::make_unique<CustomAllocator>(options.allocator)\n+                        : CpuDeviceMemory::MakeDefaultAllocator();\n+\n   return std::unique_ptr<PjRtClient>(new PjRtCpuClient(\n-      options.process_id, std::move(devices), std::move(options.collectives),\n-      num_threads, options.asynchronous,\n+      options.process_id, std::move(devices), std::move(allocator),\n+      std::move(options.collectives), num_threads, options.asynchronous,\n       std::move(options.customize_hlo_module_config)));\n }\n \n@@ -197,12 +236,14 @@ static std::vector<CpuTopology::CpuDevice> GetCpuDevices(\n \n PjRtCpuClient::PjRtCpuClient(\n     int process_index, std::vector<std::unique_ptr<PjRtCpuDevice>> devices,\n+    std::shared_ptr<CpuDeviceMemory::Allocator> allocator,\n     std::shared_ptr<cpu::CpuCollectives> collectives, size_t num_threads,\n     bool asynchronous,\n     std::function<void(HloModuleConfig&)> customize_hlo_module_config)\n     : process_index_(process_index),\n       owned_devices_(std::move(devices)),\n       computation_placer_(std::make_unique<ComputationPlacer>()),\n+      allocator_(std::move(allocator)),\n       eigen_intraop_pool_(new tsl::thread::ThreadPool(\n           tsl::Env::Default(), GetThreadOptions(), \"XLAEigen\",\n           std::min(num_threads, kMaxIntraOpThreads))),\n@@ -857,8 +898,9 @@ absl::StatusOr<std::unique_ptr<PjRtBuffer>> PjRtCpuClient::CreateErrorBuffer(\n   }\n   // Create a dummy buffer because the rest of the code expects a buffer\n   // regardless of whether the definition event is an error.\n-  TF_ASSIGN_OR_RETURN(auto buffer,\n-                      CpuDeviceMemory::Allocate(ShapeUtil::ByteSizeOf(shape)));\n+  TF_ASSIGN_OR_RETURN(\n+      auto buffer,\n+      CpuDeviceMemory::Allocate(ShapeUtil::ByteSizeOf(shape), *allocator_));\n   return std::make_unique<CommonPjRtBufferImpl>(\n       shape,\n       std::make_unique<TrackedCpuDeviceBuffer>(\n@@ -964,7 +1006,8 @@ PjRtCpuClient::AllocateRawBuffer(PjRtMemorySpace* memory_space,\n                                  tsl::AsyncValueRef<bool> allocate_after) {\n   CHECK(allocate_after == nullptr) << \"allocate_after is not supported for \"\n                                       \"PjRtCpuClient.\";\n-  return xla::CpuRawBuffer::Allocate(memory_space, on_device_bytes_count);\n+  return xla::CpuRawBuffer::Allocate(memory_space, on_device_bytes_count,\n+                                     *allocator_);\n }\n \n absl::StatusOr<int64_t> PjRtCpuClient::GetOnDeviceBytesCount(\n@@ -1077,10 +1120,10 @@ struct BufferAlloc {\n   absl::InlinedVector<tsl::AsyncValueRef<CpuDeviceMemory>, 4> buffers;\n   absl::InlinedVector<size_t, 4> allocation_sizes;\n \n-  void Allocate() {\n+  void Allocate(const CpuDeviceMemory::Allocator& allocator) {\n     for (int i = 0; i < buffers.size(); ++i) {\n-      auto status = CpuDeviceMemory::AllocateInto(allocation_sizes[i],\n-                                                  buffers[i].AsPtr());\n+      auto status = CpuDeviceMemory::AllocateInto(\n+          allocation_sizes[i], buffers[i].AsPtr(), allocator);\n       if (!status.ok()) {\n         buffers[i].SetError(status);\n         return;\n@@ -1097,10 +1140,10 @@ struct BufferAllocAndCopy {\n   absl::InlinedVector<tsl::AsyncValueRef<CpuDeviceMemory>, 4> dst_buffers;\n   absl::InlinedVector<size_t, 4> allocation_sizes;\n \n-  void AllocateAndCopy() {\n+  void AllocateAndCopy(const CpuDeviceMemory::Allocator& allocator) {\n     for (int i = 0; i < src_buffers.size(); ++i) {\n-      auto status = CpuDeviceMemory::AllocateInto(allocation_sizes[i],\n-                                                  dst_buffers[i].AsPtr());\n+      auto status = CpuDeviceMemory::AllocateInto(\n+          allocation_sizes[i], dst_buffers[i].AsPtr(), allocator);\n       if (!status.ok()) {\n         dst_buffers[i].SetError(status);\n         return;\n@@ -1413,12 +1456,12 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n     tuple_index_table = CpuDeviceMemory::CreateDelayedMemory();\n     tsl::RunWhenReady(\n         absl::MakeConstSpan(leaf_buffers),\n-        [buffers = leaf_buffers,\n-         tuple_index_table = tuple_index_table]() mutable {\n+        [buffers = leaf_buffers, tuple_index_table,\n+         allocator = client()->allocator()]() mutable {\n           size_t index_table_byte_size = buffers.size() * sizeof(void*);\n           // We assume tuple table allocations will not fail.\n-          CHECK_OK(CpuDeviceMemory::AllocateInto(index_table_byte_size,\n-                                                 tuple_index_table.AsPtr()));\n+          CHECK_OK(CpuDeviceMemory::AllocateInto(\n+              index_table_byte_size, tuple_index_table.AsPtr(), *allocator));\n           uintptr_t* index_table =\n               reinterpret_cast<uintptr_t*>(tuple_index_table->untyped_data());\n           for (int i = 0; i < buffers.size(); ++i) {\n@@ -1529,8 +1572,8 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n     tsl::AsyncValueRef<cpu::Thunk::ExecuteEvent> thunks_execute_event;\n \n     // Immediately allocate memory and prepare for computation.\n-    buffer_alloc.Allocate();\n-    buffer_alloc_and_copy.AllocateAndCopy();\n+    buffer_alloc.Allocate(*client()->allocator());\n+    buffer_alloc_and_copy.AllocateAndCopy(*client()->allocator());\n     for (const auto& buffer_info : buffer_table) {\n       CHECK(buffer_info.buffer.IsAvailable());\n       if (buffer_info.buffer.IsError()) {\n@@ -1644,13 +1687,14 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n          donation_transactions = std::move(donation_transactions),\n          scoped_async_execution = std::move(scoped_async_execution),\n          input_deps_avs = std::move(input_deps_avs_copy),\n+         allocator = client()->allocator(),\n          eigen_device = client()->eigen_intraop_device()]() mutable {\n           // Because `input_deps` contains the definition events of all inputs,\n           // when it is ready, all input buffers must have been allocated. So,\n           // we are safe to allocate and copy memory here. Since `execute_event`\n           // may error out, we need to do it early.\n-          buffer_alloc.Allocate();\n-          buffer_alloc_and_copy.AllocateAndCopy();\n+          buffer_alloc.Allocate(*allocator);\n+          buffer_alloc_and_copy.AllocateAndCopy(*allocator);\n \n           for (const auto& av : input_deps_avs) {\n             if (auto* error = av->GetErrorIfPresent()) {"
        },
        {
            "sha": "8104de7d126472a9e4c55d48cacd186482d24c59",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client.h",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.h?ref=ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
            "patch": "@@ -47,17 +47,18 @@ limitations under the License.\n #include \"xla/literal.h\"\n #include \"xla/pjrt/async_work_runner.h\"\n #include \"xla/pjrt/common_pjrt_client.h\"\n-#include \"xla/pjrt/cpu/abstract_cpu_buffer.h\"\n #include \"xla/pjrt/cpu/cpu_device.h\"\n #include \"xla/pjrt/cpu/cpu_event.h\"\n #include \"xla/pjrt/cpu/tracked_cpu_device_buffer.h\"\n+#include \"xla/pjrt/device_event.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_executable.h\"\n #include \"xla/pjrt/pjrt_future.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_client_options.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_topology_description.h\"\n+#include \"xla/pjrt/raw_buffer.h\"\n #include \"xla/pjrt/transpose.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/compiler.h\"\n@@ -68,7 +69,7 @@ limitations under the License.\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/shape.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n-#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -246,6 +247,7 @@ class PjRtCpuClient final : public CommonPjRtClient {\n \n   PjRtCpuClient(\n       int process_index, std::vector<std::unique_ptr<PjRtCpuDevice>> devices,\n+      std::shared_ptr<CpuDeviceMemory::Allocator> allocator,\n       std::shared_ptr<cpu::CpuCollectives> collectives, size_t num_threads,\n       bool asynchronous,\n       std::function<void(HloModuleConfig&)> customize_hlo_module_config);\n@@ -257,6 +259,8 @@ class PjRtCpuClient final : public CommonPjRtClient {\n       CompileOptions options,\n       const AotCompilationOptions* absl_nullable aot_options = nullptr);\n \n+  CpuDeviceMemory::Allocator* allocator() const { return allocator_.get(); }\n+\n   int process_index_;\n   // Includes all devices, including non-addressable devices.\n   std::vector<std::unique_ptr<PjRtCpuDevice>> owned_devices_;\n@@ -273,6 +277,10 @@ class PjRtCpuClient final : public CommonPjRtClient {\n   // Pointers to `owned_memory_spaces_`.\n   std::vector<PjRtMemorySpace*> memory_spaces_;\n \n+  // A memory allocator used to allocate host memory for PjRtBuffers, and\n+  // temporary allocations passed to XLA:CPU executable.\n+  std::shared_ptr<CpuDeviceMemory::Allocator> allocator_;\n+\n   // TODO(zhangqiaorjc): Use tsl::compat::EigenHostContextThreadPool.\n   std::unique_ptr<tsl::thread::ThreadPool> eigen_intraop_pool_;\n   std::unique_ptr<Eigen::ThreadPoolDevice> eigen_intraop_device_;"
        },
        {
            "sha": "8f9d0c0d8cdb66b7ad743d824ca3b4d5b0b76471",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client_test.cc",
            "status": "modified",
            "additions": 39,
            "deletions": 1,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc?ref=ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
            "patch": "@@ -13,6 +13,10 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include <array>\n+\n+#include \"absl/status/status_matchers.h\"\n+#include \"xla/pjrt/plugin/xla_cpu/cpu_memory.h\"\n #ifndef _WIN32\n #include <unistd.h>\n #endif\n@@ -70,7 +74,6 @@ using ::testing::ElementsAre;\n using ::testing::ElementsAreArray;\n using ::testing::HasSubstr;\n using ::testing::IsFalse;\n-using ::tsl::testing::IsOkAndHolds;\n \n static absl::Status TestError(ffi::AnyBuffer, ffi::Result<ffi::AnyBuffer>,\n                               ffi::Result<ffi::AnyBuffer>) {\n@@ -987,6 +990,41 @@ TEST(PjRtCpuClientTest, SubByteLiteralToBufferRoundtrip) {\n   EXPECT_TRUE(LiteralTestUtil::Equal(literal, literal_result));\n }\n \n+TEST(PjRtCpuClientTest, CustomAllocator) {\n+  alignas(64) std::array<float, 4> data;\n+\n+  class CustomMemory : public CpuMemory {\n+   public:\n+    CustomMemory(void* base, size_t size_bytes)\n+        : base_(base), size_bytes_(size_bytes) {}\n+\n+    void* base() const final { return base_; }\n+    size_t size_bytes() const final { return size_bytes_; }\n+\n+   private:\n+    void* base_;\n+    size_t size_bytes_;\n+  };\n+\n+  CpuClientOptions options;\n+  options.allocator = [&](size_t size_bytes, size_t alignment) {\n+    return std::make_unique<CustomMemory>(&data, sizeof(data));\n+  };\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto client, GetPjRtCpuClient(options));\n+  xla::Shape shape = xla::ShapeUtil::MakeShape(F32, {4});\n+  TF_ASSERT_OK_AND_ASSIGN(auto literal, xla::MakeFakeLiteral(shape));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto buffer,\n+      client->BufferFromHostLiteral(literal, client->memory_spaces()[0]));\n+  TF_ASSERT_OK_AND_ASSIGN(auto received_literal, buffer->ToLiteralSync());\n+\n+  // Check that buffer was constructed in the data array provided by the custom\n+  // allocator.\n+  EXPECT_THAT(data, ElementsAreArray(literal.data<float>()));\n+}\n+\n }  // namespace\n \n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "8244bf3d89ddf1cca468bac2eeaaae7a7d84b18a",
            "filename": "third_party/xla/xla/pjrt/cpu/raw_buffer.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.cc?ref=ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"absl/strings/str_format.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/backends/cpu/alignment.h\"\n #include \"xla/cpu_function_runtime.h\"\n #include \"xla/layout.h\"\n #include \"xla/layout_util.h\"\n@@ -104,8 +105,10 @@ PjRtFuture<> CpuTrackedDeviceEvent::GetReadyFuture() {\n }\n \n /*static*/ absl::StatusOr<tsl::RCReference<CpuRawBuffer>>\n-CpuRawBuffer::Allocate(PjRtMemorySpace* memory_space, size_t size_bytes) {\n-  TF_ASSIGN_OR_RETURN(auto memory, CpuDeviceMemory::Allocate(size_bytes));\n+CpuRawBuffer::Allocate(PjRtMemorySpace* memory_space, size_t size_bytes,\n+                       const CpuDeviceMemory::Allocator& allocator) {\n+  TF_ASSIGN_OR_RETURN(auto memory,\n+                      CpuDeviceMemory::Allocate(size_bytes, allocator));\n   return tsl::MakeRef<CpuRawBuffer>(memory_space, std::move(memory));\n }\n "
        },
        {
            "sha": "c98e0ef05081337a0cc4642bead8654337983f62",
            "filename": "third_party/xla/xla/pjrt/cpu/raw_buffer.h",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.h?ref=ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n \n #include <cstddef>\n #include <cstdint>\n+#include <optional>\n #include <utility>\n \n #include \"absl/functional/any_invocable.h\"\n@@ -32,6 +33,7 @@ limitations under the License.\n #include \"xla/pjrt/cpu/cpu_event.h\"\n #include \"xla/pjrt/cpu/tracked_cpu_device_buffer.h\"\n #include \"xla/pjrt/device_event.h\"\n+#include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_future.h\"\n #include \"xla/pjrt/raw_buffer.h\"\n #include \"xla/pjrt/transpose.h\"\n@@ -96,7 +98,9 @@ class CpuRawBuffer : public CommonPjRtRawBuffer {\n \n   // Allocates owning memory.\n   static absl::StatusOr<tsl::RCReference<CpuRawBuffer>> Allocate(\n-      PjRtMemorySpace* memory_space, size_t size_bytes);\n+      PjRtMemorySpace* memory_space, size_t size_bytes,\n+      const CpuDeviceMemory::Allocator& allocator =\n+          CpuDeviceMemory::DefaultAllocator());\n \n   // Imports foreign memory.\n   static absl::StatusOr<tsl::RCReference<CpuRawBuffer>> ImportForeignMemory("
        },
        {
            "sha": "8d2ae5382969c55bfaf4b771dae046c46f0cd92d",
            "filename": "third_party/xla/xla/pjrt/cpu/tracked_cpu_device_buffer.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.cc?ref=ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
            "patch": "@@ -109,6 +109,11 @@ CpuDeviceMemory::Allocator& CpuDeviceMemory::DefaultAllocator() {\n   return *allocator;\n }\n \n+std::unique_ptr<CpuDeviceMemory::Allocator>\n+CpuDeviceMemory::MakeDefaultAllocator() {\n+  return std::make_unique<AlignedAllocator>();\n+}\n+\n //===----------------------------------------------------------------------===//\n // CpuDeviceMemory implementations.\n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "e5754d1443591c929e29da2af53de78341779543",
            "filename": "third_party/xla/xla/pjrt/cpu/tracked_cpu_device_buffer.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.h?ref=ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
            "patch": "@@ -104,6 +104,9 @@ class CpuDeviceMemory {\n   // Default allocator uses aligned allocation and free APIs from tsl.\n   static Allocator& DefaultAllocator();\n \n+  // Returns a new instance of the default allocator.\n+  static std::unique_ptr<Allocator> MakeDefaultAllocator();\n+\n   // A raw memory allocation that can be used to construct a CpuDeviceMemory.\n   class RawMemory {\n    public:"
        },
        {
            "sha": "353c839aefdad95109472f9b4928761c7b7e03a2",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 6,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2FBUILD?ref=ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
            "patch": "@@ -10,11 +10,10 @@ package(\n \n cc_library(\n     name = \"xla_cpu_pjrt_client\",\n-    srcs = [\n-        \"xla_cpu_pjrt_client.cc\",\n-    ],\n+    srcs = [\"xla_cpu_pjrt_client.cc\"],\n     hdrs = [\"xla_cpu_pjrt_client.h\"],\n     deps = [\n+        \":cpu_client_options\",\n         \"//xla/pjrt:pjrt_client\",\n         \"//xla/pjrt/cpu:cpu_client\",\n         \"@com_google_absl//absl/status:statusor\",\n@@ -36,13 +35,11 @@ xla_cc_test(\n \n cc_library(\n     name = \"cpu_memory\",\n-    srcs = [],\n     hdrs = [\"cpu_memory.h\"],\n )\n \n cc_library(\n     name = \"cpu_client_options\",\n-    srcs = [],\n     hdrs = [\"cpu_client_options.h\"],\n     deps = [\n         \":cpu_memory\",\n@@ -68,7 +65,6 @@ cc_library(\n \n cc_library(\n     name = \"cpu_execute_options\",\n-    srcs = [],\n     hdrs = [\"cpu_execute_options.h\"],\n     deps = [\n         \"//xla/backends/cpu/collectives:cpu_collectives\","
        },
        {
            "sha": "46bba270f027494472d9971032a22718f2186bfd",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/xla_cpu_pjrt_client.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.cc?ref=ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"xla/pjrt/cpu/cpu_client.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n+#include \"xla/pjrt/plugin/xla_cpu/cpu_client_options.h\"\n \n namespace xla {\n "
        },
        {
            "sha": "17a2ce2fa29a6d16bb627f4440e13975ab215e23",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/xla_cpu_pjrt_client.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddd89b7acf6b831acdf4946a36881f9cc8a6a54d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.h?ref=ddd89b7acf6b831acdf4946a36881f9cc8a6a54d",
            "patch": "@@ -19,8 +19,8 @@ limitations under the License.\n #include <memory>\n \n #include \"absl/status/statusor.h\"\n-#include \"xla/pjrt/cpu/cpu_client.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n+#include \"xla/pjrt/plugin/xla_cpu/cpu_client_options.h\"\n \n namespace xla {\n "
        }
    ],
    "stats": {
        "total": 185,
        "additions": 146,
        "deletions": 39
    }
}