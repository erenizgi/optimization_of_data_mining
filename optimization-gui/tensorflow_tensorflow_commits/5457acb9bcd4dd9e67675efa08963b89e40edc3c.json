{
    "author": "unknown",
    "message": "[XLA] Add missing semicolons after TF_ASSERT_OK_AND_ASSIGN\n\nTo get the behavior in line with internal ASSERT_OK_AND_ASSIGN.\nUnlike the non-TF_ counterpart, the macro expands to code that already\nincludes the trailing semicolon so it happens to work.\n\nAttempts to replace it with an internal variant as part of b/444419873\nmake it not work anymore, until the missing semicolons are added.\n\nPiperOrigin-RevId: 837461910",
    "sha": "5457acb9bcd4dd9e67675efa08963b89e40edc3c",
    "files": [
        {
            "sha": "0818c8013e534e65c418198ff78386973368284a",
            "filename": "tensorflow/compiler/mlir/quantization/stablehlo/passes/bridge/convert_tf_quant_to_mhlo_int_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5457acb9bcd4dd9e67675efa08963b89e40edc3c/tensorflow%2Fcompiler%2Fmlir%2Fquantization%2Fstablehlo%2Fpasses%2Fbridge%2Fconvert_tf_quant_to_mhlo_int_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5457acb9bcd4dd9e67675efa08963b89e40edc3c/tensorflow%2Fcompiler%2Fmlir%2Fquantization%2Fstablehlo%2Fpasses%2Fbridge%2Fconvert_tf_quant_to_mhlo_int_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Fquantization%2Fstablehlo%2Fpasses%2Fbridge%2Fconvert_tf_quant_to_mhlo_int_test.cc?ref=5457acb9bcd4dd9e67675efa08963b89e40edc3c",
            "patch": "@@ -246,8 +246,8 @@ class ConvertTfQuantToMhloIntTest : public Test {\n     // Convert to double for comparison. This is needed for comparing integers\n     // since it LiteralTestUtil asserts different integers even if it is within\n     // error_spec.\n-    TF_ASSERT_OK_AND_ASSIGN(auto expected_double, expected->Convert(xla::F64))\n-    TF_ASSERT_OK_AND_ASSIGN(auto result_double, result->Convert(xla::F64))\n+    TF_ASSERT_OK_AND_ASSIGN(auto expected_double, expected->Convert(xla::F64));\n+    TF_ASSERT_OK_AND_ASSIGN(auto result_double, result->Convert(xla::F64));\n     EXPECT_TRUE(xla::LiteralTestUtil::Near(expected_double, result_double,\n                                            xla::ErrorSpec(error_tolerance)));\n   }"
        },
        {
            "sha": "8c70265bbe2b0674d6aa536a203d4d0267330546",
            "filename": "third_party/xla/xla/hlo/parser/hlo_parser_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc?ref=5457acb9bcd4dd9e67675efa08963b89e40edc3c",
            "patch": "@@ -4111,7 +4111,7 @@ TEST_F(HloParserTest, ParseFrontendAttributes) {\n TEST_F(HloParserTest, ParseWindow) {\n   Window original = window_util::MakeWindow({1, 2, 3});\n   TF_ASSERT_OK_AND_ASSIGN(Window parsed,\n-                          ParseWindow(window_util::ToString(original)))\n+                          ParseWindow(window_util::ToString(original)));\n   EXPECT_EQ(window_util::ToString(original), window_util::ToString(parsed));\n }\n "
        },
        {
            "sha": "39c840fdae3e29847d622668f90e4a8d8e44d9f5",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc?ref=5457acb9bcd4dd9e67675efa08963b89e40edc3c",
            "patch": "@@ -1250,7 +1250,7 @@ TEST(StreamExecutorGpuClientTest, GetAllocatorStatsTest) {\n \n   for (auto device : client->addressable_devices()) {\n     const xla::Literal literal = xla::LiteralUtil::CreateR0<int32_t>(0);\n-    TF_ASSERT_OK_AND_ASSIGN(auto* memory_space, device->default_memory_space())\n+    TF_ASSERT_OK_AND_ASSIGN(auto* memory_space, device->default_memory_space());\n     TF_ASSERT_OK_AND_ASSIGN(\n         std::unique_ptr<PjRtBuffer> buffer,\n         client->BufferFromHostLiteral(literal, memory_space));"
        },
        {
            "sha": "73b30b99146e82e1620d2469c5cf990113915137",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_client_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client_test.cc?ref=5457acb9bcd4dd9e67675efa08963b89e40edc3c",
            "patch": "@@ -1411,7 +1411,7 @@ TEST(TfrtGpuClientTest, ExecutePinnedHostOutputTest) {\n   EXPECT_EQ(memory_stats.host_output_size_in_bytes, 16);\n \n   TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<Literal> literal,\n-                          result_buffers[0]->ToLiteralSync())\n+                          result_buffers[0]->ToLiteralSync());\n   EXPECT_THAT(literal->data<int32_t>(), ElementsAreArray(kData));\n }\n \n@@ -1448,10 +1448,10 @@ TEST(TfrtGpuClientTest, ExecutePinnedHostOutputTupleTest) {\n   EXPECT_EQ(result_buffers[1]->memory_space()->kind(), \"pinned_host\");\n \n   TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<Literal> literal,\n-                          result_buffers[0]->ToLiteralSync())\n+                          result_buffers[0]->ToLiteralSync());\n   EXPECT_THAT(literal->data<int32_t>(), ElementsAreArray(kData));\n   TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<Literal> another_literal,\n-                          result_buffers[1]->ToLiteralSync())\n+                          result_buffers[1]->ToLiteralSync());\n   EXPECT_THAT(another_literal->data<int32_t>(), ElementsAreArray(kData));\n }\n "
        },
        {
            "sha": "ebc774166ff38be2bf650cd85a160a99f96c8f2c",
            "filename": "third_party/xla/xla/service/call_inliner_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner_test.cc?ref=5457acb9bcd4dd9e67675efa08963b89e40edc3c",
            "patch": "@@ -467,7 +467,7 @@ TEST_F(CallInlinerTest, DontInlineCallWithAttributeInlineableFalse) {\n     })\";\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(hloString));\n   module->mutable_config().set_use_shardy_partitioner(true);\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, CallInliner().Run(module.get()))\n+  TF_ASSERT_OK_AND_ASSIGN(bool changed, CallInliner().Run(module.get()));\n   // The single call in the module is not inlined.\n   EXPECT_FALSE(changed);\n \n@@ -588,7 +588,7 @@ TEST_F(CallInlinerTest, UseShardManualComputationBodySurroundedNotInlined) {\n     })\";\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(hloString));\n   module->mutable_config().set_use_shardy_partitioner(true);\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, CallInliner().Run(module.get()))\n+  TF_ASSERT_OK_AND_ASSIGN(bool changed, CallInliner().Run(module.get()));\n   // The single call in the module is not inlined.\n   EXPECT_FALSE(changed);\n "
        },
        {
            "sha": "88a5511d75f79e54cee5556f432bb0049b1e77a2",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_test.cc?ref=5457acb9bcd4dd9e67675efa08963b89e40edc3c",
            "patch": "@@ -1089,7 +1089,7 @@ TEST_F(GemmFusionAutotunerTest, SplitKFLoatNormalization) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       AutotunerCompileUtil compile_util,\n       AutotunerCompileUtil::Create(autotune_config.DeviceConfig(),\n-                                   GetDebugOptionsForTest()))\n+                                   GetDebugOptionsForTest()));\n \n   std::unique_ptr<VerifiedHloModule> module = ParseAndReturnVerifiedModule(R\"(\n HloModule module"
        },
        {
            "sha": "bb9658608e4067a8176b3d37f2953d50791288a4",
            "filename": "third_party/xla/xla/service/shape_inference_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fservice%2Fshape_inference_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fservice%2Fshape_inference_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fshape_inference_test.cc?ref=5457acb9bcd4dd9e67675efa08963b89e40edc3c",
            "patch": "@@ -853,7 +853,7 @@ TEST_F(ShapeInferenceTest, ConvolveWithBF16_F16) {\n       ShapeInference::InferConvolveShape(\n           args.lhs_shape, args.rhs_shape, /*feature_group_count=*/1,\n           /*batch_group_count=*/1, args.window, args.dnums,\n-          /*preferred_element_type=*/std::nullopt))\n+          /*preferred_element_type=*/std::nullopt));\n   ASSERT_TRUE(ShapeUtil::Equal(ShapeUtil::MakeShape(BF16, {10, 12, 2, 3}),\n                                inferred_shape));\n }\n@@ -865,7 +865,7 @@ TEST_F(ShapeInferenceTest, ConvolveWithF16_BF16) {\n       ShapeInference::InferConvolveShape(\n           args.lhs_shape, args.rhs_shape, /*feature_group_count=*/1,\n           /*batch_group_count=*/1, args.window, args.dnums,\n-          /*preferred_element_type=*/std::nullopt))\n+          /*preferred_element_type=*/std::nullopt));\n   ASSERT_TRUE(ShapeUtil::Equal(ShapeUtil::MakeShape(BF16, {10, 12, 2, 3}),\n                                inferred_shape));\n }\n@@ -877,7 +877,7 @@ TEST_F(ShapeInferenceTest, ConvolveWithS32_U32) {\n       ShapeInference::InferConvolveShape(\n           args.lhs_shape, args.rhs_shape, /*feature_group_count=*/1,\n           /*batch_group_count=*/1, args.window, args.dnums,\n-          /*preferred_element_type=*/std::nullopt))\n+          /*preferred_element_type=*/std::nullopt));\n   ASSERT_TRUE(ShapeUtil::Equal(ShapeUtil::MakeShape(S32, {10, 12, 2, 3}),\n                                inferred_shape));\n }\n@@ -889,7 +889,7 @@ TEST_F(ShapeInferenceTest, ConvolveWithU32_S32) {\n       ShapeInference::InferConvolveShape(\n           args.lhs_shape, args.rhs_shape, /*feature_group_count=*/1,\n           /*batch_group_count=*/1, args.window, args.dnums,\n-          /*preferred_element_type=*/std::nullopt))\n+          /*preferred_element_type=*/std::nullopt));\n   ASSERT_TRUE(ShapeUtil::Equal(ShapeUtil::MakeShape(S32, {10, 12, 2, 3}),\n                                inferred_shape));\n }\n@@ -901,7 +901,7 @@ TEST_F(ShapeInferenceTest, ConvolveWithPreferredElementType) {\n       ShapeInference::InferConvolveShape(\n           args.lhs_shape, args.rhs_shape, /*feature_group_count=*/1,\n           /*batch_group_count=*/1, args.window, args.dnums,\n-          /*preferred_element_type=*/S16))\n+          /*preferred_element_type=*/S16));\n   ASSERT_TRUE(ShapeUtil::Equal(ShapeUtil::MakeShape(S16, {10, 12, 2, 3}),\n                                inferred_shape));\n }\n@@ -913,7 +913,7 @@ TEST_F(ShapeInferenceTest, ConvolveWithPreferredElementTypeSameAsInferredType) {\n       ShapeInference::InferConvolveShape(\n           args.lhs_shape, args.rhs_shape, /*feature_group_count=*/1,\n           /*batch_group_count=*/1, args.window, args.dnums,\n-          /*preferred_element_type=*/S32))\n+          /*preferred_element_type=*/S32));\n   ASSERT_TRUE(ShapeUtil::Equal(ShapeUtil::MakeShape(S32, {10, 12, 2, 3}),\n                                inferred_shape));\n }\n@@ -926,7 +926,7 @@ TEST_F(ShapeInferenceTest,\n       ShapeInference::InferConvolveShape(\n           args.lhs_shape, args.rhs_shape, /*feature_group_count=*/1,\n           /*batch_group_count=*/1, args.window, args.dnums,\n-          /*preferred_element_type=*/BF16))\n+          /*preferred_element_type=*/BF16));\n   ASSERT_TRUE(ShapeUtil::Equal(ShapeUtil::MakeShape(BF16, {10, 12, 2, 3}),\n                                inferred_shape));\n }"
        },
        {
            "sha": "cae9b82293d0e89d2b93a7a387576cf19cdca30e",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_executor_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor_test.cc?ref=5457acb9bcd4dd9e67675efa08963b89e40edc3c",
            "patch": "@@ -43,7 +43,7 @@ TEST_F(GetPointerMemorySpaceTest, Host) {\n   StreamExecutor* executor = GetPlatform()->ExecutorForDevice(0).value();\n   TF_ASSERT_OK_AND_ASSIGN(auto host_ptr, executor->HostMemoryAllocate(64));\n   TF_ASSERT_OK_AND_ASSIGN(auto memory_space,\n-                          executor->GetPointerMemorySpace(host_ptr->opaque()))\n+                          executor->GetPointerMemorySpace(host_ptr->opaque()));\n   EXPECT_EQ(memory_space, MemoryType::kHost);\n }\n \n@@ -53,7 +53,7 @@ TEST_F(GetPointerMemorySpaceTest, HostAllocatedWithMemoryKind) {\n       64, static_cast<int64_t>(stream_executor::MemoryType::kHost));\n   EXPECT_FALSE(host_ptr.is_null());\n   TF_ASSERT_OK_AND_ASSIGN(MemoryType memory_space,\n-                          executor->GetPointerMemorySpace(host_ptr.opaque()))\n+                          executor->GetPointerMemorySpace(host_ptr.opaque()));\n   EXPECT_EQ(memory_space, MemoryType::kHost);\n   executor->Deallocate(&host_ptr);\n }\n@@ -63,7 +63,7 @@ TEST_F(GetPointerMemorySpaceTest, Device) {\n   auto mem = executor->Allocate(64);\n   ASSERT_NE(mem, nullptr);\n   TF_ASSERT_OK_AND_ASSIGN(auto memory_space,\n-                          executor->GetPointerMemorySpace(mem.opaque()))\n+                          executor->GetPointerMemorySpace(mem.opaque()));\n   EXPECT_EQ(memory_space, MemoryType::kDevice);\n   executor->Deallocate(&mem);\n }"
        },
        {
            "sha": "5d072e2404447148239b384892441af43b1449a2",
            "filename": "third_party/xla/xla/stream_executor/integrations/tf_allocator_adapter_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fintegrations%2Ftf_allocator_adapter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5457acb9bcd4dd9e67675efa08963b89e40edc3c/third_party%2Fxla%2Fxla%2Fstream_executor%2Fintegrations%2Ftf_allocator_adapter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fintegrations%2Ftf_allocator_adapter_test.cc?ref=5457acb9bcd4dd9e67675efa08963b89e40edc3c",
            "patch": "@@ -75,7 +75,7 @@ TEST(MultiDeviceAdapter, UsesCorrectAllocator) {\n   TF_ASSERT_OK_AND_ASSIGN(auto* platform,\n                           xla::PlatformUtil::GetDefaultPlatform());\n   TF_ASSERT_OK_AND_ASSIGN(std::vector<StreamExecutor*> executors,\n-                          xla::PlatformUtil::GetStreamExecutors(platform))\n+                          xla::PlatformUtil::GetStreamExecutors(platform));\n   TF_ASSERT_OK_AND_ASSIGN(auto stream, executors[0]->CreateStream());\n \n   std::vector<MultiDeviceAdapter::AllocatorInfo> infos;"
        }
    ],
    "stats": {
        "total": 42,
        "additions": 21,
        "deletions": 21
    }
}