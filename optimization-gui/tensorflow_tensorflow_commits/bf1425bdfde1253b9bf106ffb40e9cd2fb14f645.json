{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] add special handling for NCCL grouped send and recv\n\nPiperOrigin-RevId: 803301109",
    "sha": "bf1425bdfde1253b9bf106ffb40e9cd2fb14f645",
    "files": [
        {
            "sha": "cdba67ae3b5a89f9dea397b7bb5e49f5127efd15",
            "filename": "third_party/xla/xla/service/hlo_verifier.cc",
            "status": "modified",
            "additions": 55,
            "deletions": 31,
            "changes": 86,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bf1425bdfde1253b9bf106ffb40e9cd2fb14f645/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bf1425bdfde1253b9bf106ffb40e9cd2fb14f645/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc?ref=bf1425bdfde1253b9bf106ffb40e9cd2fb14f645",
            "patch": "@@ -2754,37 +2754,6 @@ bool IsOtherCollective(const HloInstruction* instruction) {\n   }\n }\n \n-absl::Status VerifyNoCollectiveDeadlocksRecursive(\n-    const HloComputation* computation, DfaState& current_state,\n-    absl::flat_hash_set<const HloSendInstruction*>& send_instructions,\n-    absl::flat_hash_set<const HloRecvInstruction*>& recv_instructions) {\n-  for (const HloInstruction* instruction : computation->instructions()) {\n-    if (instruction->called_computations().empty()) {\n-      if (instruction->opcode() == HloOpcode::kSend) {\n-        TF_RETURN_IF_ERROR(CheckDeadlocksForSend(\n-            DynCast<HloSendInstruction>(instruction), current_state,\n-            send_instructions, recv_instructions));\n-      } else if (instruction->opcode() == HloOpcode::kRecv) {\n-        TF_RETURN_IF_ERROR(CheckDeadlocksForRecv(\n-            DynCast<HloRecvInstruction>(instruction), current_state,\n-            send_instructions, recv_instructions));\n-      } else if (IsOtherCollective(instruction)) {\n-        TF_RETURN_IF_ERROR(CheckDeadlocksForOtherCollectives(\n-            instruction, current_state, send_instructions, recv_instructions));\n-      } else {\n-        continue;\n-      }\n-    } else {\n-      for (const HloComputation* computation :\n-           instruction->called_computations()) {\n-        TF_RETURN_IF_ERROR(VerifyNoCollectiveDeadlocksRecursive(\n-            computation, current_state, send_instructions, recv_instructions));\n-      }\n-    }\n-  }\n-  return absl::OkStatus();\n-}\n-\n absl::Status CheckPendingSendRecvDeadlocks(\n     absl::flat_hash_set<const HloSendInstruction*>& send_instructions,\n     absl::flat_hash_set<const HloRecvInstruction*>& recv_instructions) {\n@@ -2822,6 +2791,61 @@ absl::Status CheckPendingSendRecvDeadlocks(\n   return absl::OkStatus();\n }\n \n+absl::Status VerifyNoCollectiveDeadlocksRecursive(\n+    const HloComputation* computation, DfaState& current_state,\n+    absl::flat_hash_set<const HloSendInstruction*>& send_instructions,\n+    absl::flat_hash_set<const HloRecvInstruction*>& recv_instructions) {\n+  for (const HloInstruction* instruction : computation->instructions()) {\n+    if (instruction->called_computations().empty()) {\n+      if (instruction->opcode() == HloOpcode::kSend) {\n+        TF_RETURN_IF_ERROR(CheckDeadlocksForSend(\n+            DynCast<HloSendInstruction>(instruction), current_state,\n+            send_instructions, recv_instructions));\n+      } else if (instruction->opcode() == HloOpcode::kRecv) {\n+        TF_RETURN_IF_ERROR(CheckDeadlocksForRecv(\n+            DynCast<HloRecvInstruction>(instruction), current_state,\n+            send_instructions, recv_instructions));\n+      } else if (IsOtherCollective(instruction)) {\n+        TF_RETURN_IF_ERROR(CheckDeadlocksForOtherCollectives(\n+            instruction, current_state, send_instructions, recv_instructions));\n+      } else {\n+        continue;\n+      }\n+    } else {\n+      for (const HloComputation* computation :\n+           instruction->called_computations()) {\n+        // special handling for grouped multi-op async collectives\n+        if (computation->IsAsyncComputation() &&\n+            !computation->CanExpandIntoSingleInstruction()) {\n+          // Reset the state machine for async-grouped send and recv. This block\n+          // essentially calls the main VerifyNoCollectiveDeadlocks function\n+          // on the async computation without recursion. This is necessary for\n+          // async-wrapped send and recv instructions that are sandwiched in\n+          // between partially pipelined collectives.\n+          DfaState async_comp_current_state = DfaState::kNoExpectation;\n+          absl::flat_hash_set<const HloSendInstruction*>\n+              async_comp_send_instructions;\n+          absl::flat_hash_set<const HloRecvInstruction*>\n+              async_comp_recv_instructions;\n+          TF_RETURN_IF_ERROR(VerifyNoCollectiveDeadlocksRecursive(\n+              computation, async_comp_current_state,\n+              async_comp_send_instructions, async_comp_recv_instructions));\n+          if (current_state != DfaState::kNoExpectation) {\n+            TF_RETURN_IF_ERROR(CheckPendingSendRecvDeadlocks(\n+                async_comp_send_instructions, async_comp_recv_instructions));\n+          }\n+        } else {\n+          // normal case\n+          TF_RETURN_IF_ERROR(VerifyNoCollectiveDeadlocksRecursive(\n+              computation, current_state, send_instructions,\n+              recv_instructions));\n+        }\n+      }\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n absl::Status VerifyNoCollectiveDeadlocks(const HloModule& module) {\n   DfaState current_state = DfaState::kNoExpectation;\n   absl::flat_hash_set<const HloSendInstruction*> send_instructions;"
        },
        {
            "sha": "496f56bc3e85de7fdf440e86544aa0ce962a4ac5",
            "filename": "third_party/xla/xla/service/hlo_verifier_test.cc",
            "status": "modified",
            "additions": 68,
            "deletions": 0,
            "changes": 68,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bf1425bdfde1253b9bf106ffb40e9cd2fb14f645/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bf1425bdfde1253b9bf106ffb40e9cd2fb14f645/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier_test.cc?ref=bf1425bdfde1253b9bf106ffb40e9cd2fb14f645",
            "patch": "@@ -4676,6 +4676,74 @@ ENTRY main {\n   EXPECT_THAT(verifier().Run(module.get()), IsOkAndHolds(false));\n }\n \n+TEST_F(HloVerifierTestForCollectiveDeadlocks,\n+       VerifyAsyncComputationPartiallyPipelined) {\n+  const char* const hlo = R\"(\n+HloModule nccl_group_send_recv_no_loop_x4, is_scheduled=true\n+\n+wrapped_send_recv {\n+  param0 = f32[] parameter(0)\n+  param1 = token[] parameter(1)\n+  send1 = (f32[], u32[], token[]) send(param0, param1), channel_id=0,\n+    frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2}}}\n+  param2 = f32[] parameter(2)\n+  param3 = token[] parameter(3)\n+  send2 = (f32[], u32[], token[]) send(param2, param3), channel_id=0,\n+    frontend_attributes={_xla_send_recv_source_target_pairs={{2,3}}}\n+  param4 = token[] parameter(4)\n+  recv1 = (f32[], u32[], token[]) recv(param4), channel_id=0,\n+    frontend_attributes={_xla_send_recv_source_target_pairs={{0,1},{1,2}}}\n+  param5 = token[] parameter(5)\n+  recv2 = (f32[], u32[], token[]) recv(param5), channel_id=0,\n+    frontend_attributes={_xla_send_recv_source_target_pairs={{2,3}}}\n+  ROOT out = ((f32[], u32[], token[]), (f32[], u32[], token[]),\n+    (f32[], u32[], token[]), (f32[], u32[], token[]))\n+    tuple(send1, send2, recv1, recv2)\n+}\n+\n+ENTRY main {\n+  data1 = f32[] constant(10)\n+  after-all1 = token[] after-all()\n+  data2 = f32[] constant(20)\n+  after-all2 = token[] after-all()\n+  data3 = f32[] constant(30)\n+  after-all3 = token[] after-all()\n+  bwd_send = (f32[], u32[], token[]) send(data3, after-all3), channel_id=0,\n+    frontend_attributes={_xla_send_recv_source_target_pairs={{1,0}}}\n+  bwd_send_done = token[] send-done(bwd_send), channel_id=0\n+  async-comp-start = ((f32[], token[], f32[], token[], token[], token[]),\n+    ((f32[], u32[], token[]), (f32[], u32[], token[]), (f32[], u32[], token[]),\n+    (f32[], u32[], token[])), s32[]) async-start(data1, after-all1,\n+    data2, after-all2, after-all1, after-all2), calls=wrapped_send_recv\n+  async-comp-done = ((f32[], u32[], token[]), (f32[], u32[], token[]),\n+    (f32[], u32[], token[]), (f32[], u32[], token[])) async-done(async-comp-start)\n+  bwd_recv = (f32[], u32[], token[]) recv(after-all3), channel_id=0,\n+    frontend_attributes={_xla_send_recv_source_target_pairs={{1,0}}}\n+  bwd_recv_done = (f32[], token[]) recv-done(bwd_recv), channel_id=0\n+  unpack-recv-done1 = (f32[], u32[], token[]) get-tuple-element(async-comp-done), index=2\n+  recv-done-data1 = f32[] get-tuple-element(unpack-recv-done1), index=0\n+  recv-done-token1 = token[] get-tuple-element(unpack-recv-done1), index=2\n+  recv-done1 = (f32[], token[]) tuple(recv-done-data1, recv-done-token1),\n+    control-predecessors={async-comp-start}\n+  data-out1 = f32[] get-tuple-element(recv-done1), index=0\n+  unpack-recv-done2 = (f32[], u32[], token[]) get-tuple-element(async-comp-done), index=3\n+  recv-done-data2 = f32[] get-tuple-element(unpack-recv-done2), index=0\n+  recv-done-token2 = token[] get-tuple-element(unpack-recv-done2), index=2\n+  recv-done2 = (f32[], token[]) tuple(recv-done-data2, recv-done-token2),\n+    control-predecessors={async-comp-start}\n+  data-out2 = f32[] get-tuple-element(recv-done2), index=0\n+  ROOT out = (f32[], f32[]) tuple(data-out1, data-out2)\n+  unpack-send-done1 = (f32[], u32[], token[]) get-tuple-element(async-comp-done), index=0\n+  send-done1 = token[] get-tuple-element(unpack-send-done1), index=2\n+  unpack-send-done2 = (f32[], u32[], token[]) get-tuple-element(async-comp-done), index=1\n+  send-done2 = token[] get-tuple-element(unpack-send-done2), index=2\n+}\n+  )\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,\n+                          ParseAndReturnUnverifiedModule(hlo));\n+  EXPECT_THAT(verifier().Run(module.get()), IsOkAndHolds(false));\n+}\n+\n TEST_F(HloVerifierTest, VerifyMatchingSendSameChannel) {\n   const char* const hlo = R\"(\n   HloModule module"
        }
    ],
    "stats": {
        "total": 154,
        "additions": 123,
        "deletions": 31
    }
}