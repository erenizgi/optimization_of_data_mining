{
    "author": "unknown",
    "message": "[XLA:GPU] Enable chlo.atanh -> kAtanh HloInstruction lowering.\n\nPiperOrigin-RevId: 812739773",
    "sha": "b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
    "files": [
        {
            "sha": "42cb2a0a7d11ea4db25defd8562430455e169e17",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/transforms/optimize_loops.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 2,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Foptimize_loops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Foptimize_loops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Foptimize_loops.cc?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -47,8 +47,17 @@ namespace gpu {\n namespace {\n \n bool IsExpensiveToUnroll(mlir::Operation* op) {\n-  return mlir::isa<mlir::func::CallOp, mlir::scf::ForOp, mlir::math::AcoshOp,\n-                   mlir::math::AcosOp>(op);\n+  return mlir::isa<\n+      // clang-format off\n+      // go/keep-sorted start\n+      mlir::func::CallOp,\n+      mlir::math::AcosOp,\n+      mlir::math::AcoshOp,\n+      mlir::math::AtanhOp,\n+      mlir::scf::ForOp\n+      // go/keep-sorted end\n+      // clang-format on\n+      >(op);\n }\n \n int GetUnrollingFactor(mlir::scf::ForOp op) {"
        },
        {
            "sha": "2d10b035b5b2f6db4063404f3b48ceaf059f8dd0",
            "filename": "third_party/xla/xla/hlo/builder/lib/math.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -1331,7 +1331,11 @@ XlaOp Asinh(XlaOp x) {\n \n // atanh(x) = 0.5 * log((1 + x) / (1 - x)) if abs(x) <= 1\n // atanh(x) = nan                          otherwise\n-XlaOp Atanh(XlaOp x) {\n+XlaOp Atanh(XlaOp x, const std::optional<ResultAccuracy>& result_accuracy,\n+            bool expand) {\n+  if (!expand) {\n+    return x.builder()->UnaryOp(HloOpcode::kAtanh, x, result_accuracy);\n+  }\n   XlaBuilder* b = x.builder();\n   auto do_it = [&](XlaOp x) -> absl::StatusOr<XlaOp> {\n     TF_ASSIGN_OR_RETURN(auto shape, b->GetShape(x));"
        },
        {
            "sha": "2ef1753befe000cf322a6e420f8468c0d96b6435",
            "filename": "third_party/xla/xla/hlo/builder/lib/math.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -105,7 +105,9 @@ XlaOp Acosh(XlaOp x,\n XlaOp Asinh(XlaOp x);\n \n // Computes the inverse hyperbolic tangent of 'x'.\n-XlaOp Atanh(XlaOp x);\n+XlaOp Atanh(XlaOp x,\n+            const std::optional<ResultAccuracy>& result_accuracy = std::nullopt,\n+            bool expand = true);\n \n // Computes the hyperbolic cosine of 'x'.\n XlaOp Cosh(XlaOp x);"
        },
        {
            "sha": "7a7a2683193b8255698b3e9b6f8a43482ddb37ea",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/gen_hlo_op_writer.td",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -206,6 +206,7 @@ defvar CustomHloConverterOps = [\n   MHLO_AsyncDoneOp,\n   MHLO_AsyncStartOp,\n   MHLO_AsyncUpdateOp,\n+  MHLO_AtanhOp,\n   MHLO_BatchNormGradOp,\n   MHLO_BatchNormTrainingOp,\n   MHLO_BitcastConvertOp,"
        },
        {
            "sha": "6a58fa7a3496fb5298dd166512bf06f8d5f6333b",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 10,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -5201,26 +5201,30 @@ LogicalResult ExportXlaOp(UniformDequantizeOp op, OpLoweringContext ctx) {\n   return failure();\n }\n \n-LogicalResult ExportXlaOp(AcosOp op, OpLoweringContext ctx) {\n+template <typename Op,\n+          xla::XlaOp OpFunc(xla::XlaOp,\n+                            const std::optional<xla::ResultAccuracy>&, bool)>\n+LogicalResult ExportElementwiseXlaOp(Op op, OpLoweringContext ctx) {\n   auto& value_map = *ctx.values;\n   xla::XlaOp operand;\n   if (failed(GetXlaOp(op.getOperand(), value_map, &operand, op))) {\n     return failure();\n   }\n   value_map[op] =\n-      xla::Acos(operand, /*result_accuracy=*/std::nullopt, /*expand=*/false);\n+      OpFunc(operand, /*result_accuracy=*/std::nullopt, /*expand=*/false);\n   return success();\n }\n \n+LogicalResult ExportXlaOp(AcosOp op, OpLoweringContext ctx) {\n+  return ExportElementwiseXlaOp<AcosOp, xla::Acos>(op, ctx);\n+}\n+\n LogicalResult ExportXlaOp(AcoshOp op, OpLoweringContext ctx) {\n-  auto& value_map = *ctx.values;\n-  xla::XlaOp operand;\n-  if (failed(GetXlaOp(op.getOperand(), value_map, &operand, op))) {\n-    return failure();\n-  }\n-  value_map[op] =\n-      xla::Acosh(operand, /*result_accuracy=*/std::nullopt, /*expand=*/false);\n-  return success();\n+  return ExportElementwiseXlaOp<AcoshOp, xla::Acosh>(op, ctx);\n+}\n+\n+LogicalResult ExportXlaOp(AtanhOp op, OpLoweringContext ctx) {\n+  return ExportElementwiseXlaOp<AtanhOp, xla::Atanh>(op, ctx);\n }\n \n LogicalResult ExportXlaOp(TopKOp op, OpLoweringContext ctx) {"
        },
        {
            "sha": "52dd1c61649df390b928ff5e9882a3985cf6d150",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/tests/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -13,6 +13,7 @@ lit_test_suite(\n             \"acos.mlir\",\n             \"acosh.mlir\",\n             \"add.mlir\",\n+            \"atanh.mlir\",\n             \"attributes.mlir\",\n             \"call.mlir\",\n             \"case.mlir\","
        },
        {
            "sha": "2d68c838cabf62f4ee83dc46420feff0799484e0",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/tests/atanh.mlir",
            "status": "added",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fatanh.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fatanh.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fatanh.mlir?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -0,0 +1,7 @@\n+// RUN: xla-translate -mlir-hlo-to-hlo-text %s | FileCheck %s\n+\n+func.func @main(%arg0: tensor<4xf32>) -> tensor<4xf32> {\n+  // CHECK: f32[4] atanh\n+  %0 = \"mhlo.atanh\"(%arg0) : (tensor<4xf32>) -> tensor<4xf32>\n+  func.return %0 : tensor<4xf32>\n+}\n\\ No newline at end of file"
        },
        {
            "sha": "92f2f86d7b0e98c574595207ccc8e9f64667b169",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/chlo_legalize_to_hlo/chlo_legalize_to_hlo_pass.cc",
            "status": "modified",
            "additions": 40,
            "deletions": 10,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -50,19 +50,25 @@ namespace mhlo {\n namespace {\n \n ChloLegalizeToHighLevelMhloPassOptions FromPassOptions(bool enableAcosh,\n-                                                       bool enableAcos) {\n+                                                       bool enableAcos,\n+                                                       bool enableAtanh) {\n   ChloLegalizeToHighLevelMhloPassOptions options;\n   options.enable_acosh_ = enableAcosh;\n   options.enable_acos_ = enableAcos;\n+  options.enable_atanh_ = enableAtanh;\n   return options;\n }\n \n-static bool isLegalAcosh(chlo::AcoshOp op) {\n-  return !llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n+static bool qualifiesForDirectMhloLoweringAcosh(chlo::AcoshOp op) {\n+  return llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n }\n \n-static bool isLegalAcos(chlo::AcosOp op) {\n-  return !llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n+static bool qualifiesForDirectMhloLoweringAcos(chlo::AcosOp op) {\n+  return llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n+}\n+\n+static bool qualifiesForDirectMhloLoweringAtanh(chlo::AtanhOp op) {\n+  return llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n }\n \n struct ChloLegalizeToHighLevelMhloPass\n@@ -81,16 +87,27 @@ struct ChloLegalizeToHighLevelMhloPass\n \n     chlo::populateChloToHighLevelMhloOpPatterns(\n         &context, &conversionPatterns,\n-        FromPassOptions(enable_acosh_, enable_acos_));\n+        FromPassOptions(enable_acosh_, enable_acos_, enable_atanh_));\n \n     // Consider the mhlo dialect legal for tests. Also add helper dialects\n     // that are needed by the patterns.\n     conversionTarget.addLegalDialect<chlo::ChloDialect, mhlo::MhloDialect>();\n     if (enable_acosh_) {\n-      conversionTarget.addDynamicallyLegalOp<chlo::AcoshOp>(isLegalAcosh);\n+      conversionTarget.addDynamicallyLegalOp<chlo::AcoshOp>(\n+          [](chlo::AcoshOp op) {\n+            return !qualifiesForDirectMhloLoweringAcosh(op);\n+          });\n     }\n     if (enable_acos_) {\n-      conversionTarget.addDynamicallyLegalOp<chlo::AcosOp>(isLegalAcos);\n+      conversionTarget.addDynamicallyLegalOp<chlo::AcosOp>([](chlo::AcosOp op) {\n+        return !qualifiesForDirectMhloLoweringAcos(op);\n+      });\n+    }\n+    if (enable_atanh_) {\n+      conversionTarget.addDynamicallyLegalOp<chlo::AtanhOp>(\n+          [](chlo::AtanhOp op) {\n+            return !qualifiesForDirectMhloLoweringAtanh(op);\n+          });\n     }\n     conversionTarget\n         .addIllegalOp<chlo::TopKOp, chlo::ErfOp, chlo::RaggedDotOp>();\n@@ -191,7 +208,7 @@ LogicalResult convertRaggedDotChloToMhlo(chlo::RaggedDotOp raggedDotOp,\n \n LogicalResult convertAcoshChloToMhlo(chlo::AcoshOp op,\n                                      PatternRewriter& rewriter) {\n-  if (mhlo::isLegalAcosh(op)) {\n+  if (!mhlo::qualifiesForDirectMhloLoweringAcosh(op)) {\n     return failure();\n   }\n   rewriter.replaceOpWithNewOp<mhlo::AcoshOp>(op, op->getOperands());\n@@ -200,13 +217,22 @@ LogicalResult convertAcoshChloToMhlo(chlo::AcoshOp op,\n \n LogicalResult convertAcosChloToMhlo(chlo::AcosOp op,\n                                     PatternRewriter& rewriter) {\n-  if (mhlo::isLegalAcos(op)) {\n+  if (!mhlo::qualifiesForDirectMhloLoweringAcos(op)) {\n     return failure();\n   }\n   rewriter.replaceOpWithNewOp<mhlo::AcosOp>(op, op->getOperands());\n   return success();\n }\n \n+LogicalResult convertAtanhChloToMhlo(chlo::AtanhOp op,\n+                                     PatternRewriter& rewriter) {\n+  if (!mhlo::qualifiesForDirectMhloLoweringAtanh(op)) {\n+    return failure();\n+  }\n+  rewriter.replaceOpWithNewOp<mhlo::AtanhOp>(op, op->getOperands());\n+  return success();\n+}\n+\n }  // namespace\n \n ChloLegalizeToHighLevelMhloPassOptions getDefaultChloToHighLevelMhloOptions() {\n@@ -217,6 +243,7 @@ ChloLegalizeToHighLevelMhloPassOptions getGpuChloToHighLevelMhloOptions() {\n   ChloLegalizeToHighLevelMhloPassOptions opts;\n   opts.enable_acosh_ = true;\n   opts.enable_acos_ = true;\n+  opts.enable_atanh_ = true;\n   return opts;\n }\n \n@@ -237,6 +264,9 @@ void populateChloToHighLevelMhloOpPatterns(\n   if (options.enable_acos_) {\n     patterns->add(mhlo::convertAcosChloToMhlo, kBenefit);\n   }\n+  if (options.enable_atanh_) {\n+    patterns->add(mhlo::convertAtanhChloToMhlo, kBenefit);\n+  }\n   patterns->add(mhlo::convertRaggedDotChloToMhlo, kBenefit);\n   populateWithGenerated(*patterns);\n }"
        },
        {
            "sha": "baa9db25ff25a41da94ec310b304dd17da8b5253",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/hlo_legalize_to_arithmetic/hlo_legalize_to_arithmetic.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_arithmetic%2Fhlo_legalize_to_arithmetic.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_arithmetic%2Fhlo_legalize_to_arithmetic.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_arithmetic%2Fhlo_legalize_to_arithmetic.cc?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -199,6 +199,7 @@ void populateScalarHloToArithmeticConversionPatterns(\n       ScalarHloToArithmeticPattern<mhlo::AddOp>,\n       ScalarHloToArithmeticPattern<mhlo::AndOp>,\n       ScalarHloToArithmeticPattern<mhlo::Atan2Op>,\n+      ScalarHloToArithmeticPattern<mhlo::AtanhOp>,\n       ScalarHloToArithmeticPattern<mhlo::BitcastConvertOp>,\n       ScalarHloToArithmeticPattern<mhlo::CbrtOp>,\n       ScalarHloToArithmeticPattern<mhlo::CeilOp>,"
        },
        {
            "sha": "bdfc06f67c73e69235d53f492f3469f282eeaa02",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/hlo_legalize_to_stablehlo/hlo_legalize_to_stablehlo.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 2,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -122,6 +122,11 @@ std::optional<int64_t> getPublicFeaturesNotInStablehlo(HloOpTy hloOp) {\n     // Version 1: Initial version for AcosOp.\n     return 1;\n   }\n+  // StableHLO doesn't support Atanh yet.\n+  if constexpr (std::is_same<HloOpTy, mhlo::AtanhOp>::value) {\n+    // Version 1: Initial version for AtanhOp.\n+    return 1;\n+  }\n   return std::nullopt;\n }\n \n@@ -450,6 +455,7 @@ LogicalResult convertAttributes(ConversionPatternRewriter& rewriter,\n     // Handle DenseElements --> DenseArray for certain StableHLO ops\n     if constexpr (!std::is_same<HloOpTy, mhlo::AcosOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::AcoshOp>::value &&\n+                  !std::is_same<HloOpTy, mhlo::AtanhOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::ErfOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::TopKOp>::value) {\n       if (!stablehloAttr)\n@@ -736,8 +742,8 @@ void populateHloToStablehloPatterns(RewritePatternSet* patterns,\n       patterns, converter, context, allowExperimentalFeatures,\n       allowXlaFeatures);\n \n-  populateHloToStablehloCustomCallPatterns<mhlo::AcosOp, mhlo::AcoshOp,\n-                                           mhlo::ErfOp, mhlo::TopKOp>(\n+  populateHloToStablehloCustomCallPatterns<\n+      mhlo::AcosOp, mhlo::AcoshOp, mhlo::AtanhOp, mhlo::ErfOp, mhlo::TopKOp>(\n       patterns, converter, context, allowExperimentalFeatures);\n }\n "
        },
        {
            "sha": "a56a1b2a897008ad71667f7e99d239bba989d841",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/mhlo_passes.td",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -26,7 +26,9 @@ def ChloLegalizeToHighLevelMhloPass : Pass<\"chlo-legalize-to-high-level-mhlo\", \"\n     Option<\"enable_acosh_\", \"enable-acosh\", \"bool\", /*default=*/\"false\",\n            \"Enable chlo.acosh to mhlo.acosh lowering.\">,\n     Option<\"enable_acos_\", \"enable-acos\", \"bool\", /*default=*/\"false\",\n-           \"Enable chlo.acos to mhlo.acos lowering.\">\n+           \"Enable chlo.acos to mhlo.acos lowering.\">,\n+    Option<\"enable_atanh_\", \"enable-atanh\", \"bool\", /*default=*/\"false\",\n+           \"Enable chlo.atanh to mhlo.atanh lowering.\">\n   ];\n   let dependentDialects = [\"mhlo::MhloDialect\"];\n }"
        },
        {
            "sha": "7e88bd323df05dc205af41a461a805924f31455d",
            "filename": "third_party/xla/xla/mlir_hlo/stablehlo_ext/transforms/chlo_preserve_high_level_ops.cpp",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -248,6 +248,15 @@ struct AcosOpToCustomCallPattern : public OpRewritePattern<chlo::AcosOp> {\n   }\n };\n \n+struct AtanhOpToCustomCallPattern : public OpRewritePattern<chlo::AtanhOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(chlo::AtanhOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return wrapChloOperationInCustomCall(rewriter, op, \"mhlo.atanh\",\n+                                         /*version=*/1);\n+  }\n+};\n+\n ///////\n // CHLO to CompositeOp Patterns\n ///////\n@@ -307,6 +316,14 @@ struct AcosOpToCompositePattern : public OpRewritePattern<chlo::AcosOp> {\n   }\n };\n \n+struct AtanhOpToCompositePattern : public OpRewritePattern<chlo::AtanhOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(chlo::AtanhOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return wrapChloOpInComposite(op, /*version=*/1, rewriter);\n+  }\n+};\n+\n }  // namespace\n \n struct ChloPreserveHighLevelOpsPass\n@@ -332,13 +349,15 @@ struct ChloPreserveHighLevelOpsPass\n       patterns.add<\n         AcosOpToCustomCallPattern,\n         AcoshOpToCustomCallPattern,\n+        AtanhOpToCustomCallPattern,\n         ErfOpToCustomCallPattern,\n         RaggedDotOpToCustomCallPattern,\n         TopKOpToCustomCallPattern>(ctx);\n     } else {\n       patterns.add<\n         AcosOpToCompositePattern,\n         AcoshOpToCompositePattern,\n+        AtanhOpToCompositePattern,\n         ErfOpToCompositePattern,\n         RaggedDotOpToCompositePattern,\n         TopKOpToCompositePattern>(ctx);"
        },
        {
            "sha": "c8e762f9f73e6bcb651070eb4f73e3652d5b68be",
            "filename": "third_party/xla/xla/mlir_hlo/stablehlo_ext/transforms/chlo_recompose_ops.cpp",
            "status": "modified",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -280,6 +280,22 @@ struct AcosOpRecomposePattern\n   }\n };\n \n+struct AtanhOpRecomposePattern\n+    : public OpRewritePattern<stablehlo::CompositeOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(stablehlo::CompositeOp op,\n+                                PatternRewriter& rewriter) const override {\n+    if (op.getName() != \"chlo.atanh\") {\n+      return rewriter.notifyMatchFailure(op, \"not a chlo.atanh\");\n+    }\n+    if (op.getVersion() != 1) {\n+      return rewriter.notifyMatchFailure(\n+          op, \"unsupported version for chlo.atanh composite\");\n+    }\n+    return recomposeChloOpFromCompositeOp<chlo::AtanhOp>(op, rewriter);\n+  }\n+};\n+\n struct ErfOpRecomposePattern : public OpRewritePattern<stablehlo::CompositeOp> {\n   using OpRewritePattern::OpRewritePattern;\n   LogicalResult matchAndRewrite(stablehlo::CompositeOp op,\n@@ -389,6 +405,16 @@ struct AcosOpCustomCallRecomposePattern\n   }\n };\n \n+struct AtanhOpCustomCallRecomposePattern\n+    : public OpRewritePattern<stablehlo::CustomCallOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(stablehlo::CustomCallOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return recomposeChloOpFromCustomCall<chlo::AtanhOp>(\n+        op, {\"mhlo.atanh\", \"chlo.atanh\"}, rewriter);\n+  }\n+};\n+\n }  // namespace\n \n struct ChloRecomposeOpsPass\n@@ -411,6 +437,7 @@ struct ChloRecomposeOpsPass\n     patterns.add<\n       AcosOpCustomCallRecomposePattern,\n       AcoshOpCustomCallRecomposePattern,\n+      AtanhOpCustomCallRecomposePattern,\n       ErfOpCustomCallRecomposePattern,\n       RaggedDotOpCustomCallRecomposePattern,\n       TanOpCustomCallRecomposePattern,\n@@ -420,6 +447,7 @@ struct ChloRecomposeOpsPass\n     patterns.add<\n       AcosOpRecomposePattern,\n       AcoshOpRecomposePattern,\n+      AtanhOpRecomposePattern,\n       ErfOpRecomposePattern,\n       RaggedDotOpRecomposePattern,\n       TopKOpRecomposePattern>(ctx);"
        },
        {
            "sha": "54b781811a3360679b04784cc84671c7dd97c904",
            "filename": "third_party/xla/xla/mlir_hlo/tests/Dialect/chlo/chlo_legalize_to_mhlo.mlir",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -1,5 +1,5 @@\n // RUN: mlir-hlo-opt --chlo-legalize-to-hlo --split-input-file -verify-diagnostics %s | FileCheck %s --dump-input-context=20\n-// RUN: mlir-hlo-opt --chlo-legalize-to-high-level-mhlo=\"enable-acosh enable-acos\" --split-input-file -verify-diagnostics %s | FileCheck %s --check-prefix=CHECK-HIGH-LEVEL\n+// RUN: mlir-hlo-opt --chlo-legalize-to-high-level-mhlo=\"enable-acosh enable-acos enable-atanh\" --split-input-file -verify-diagnostics %s | FileCheck %s --check-prefix=CHECK-HIGH-LEVEL\n \n // CHECK-LABEL: func.func @asin_bf16(\n // CHECK-SAME:    %[[TMP_arg0:.*]]: tensor<bf16>\n@@ -2736,6 +2736,7 @@ func.func @atanh_f32(%arg : tensor<f32>) -> tensor<f32> {\n   %result = \"chlo.atanh\"(%arg) : (tensor<f32>) -> tensor<f32>\n   func.return %result : tensor<f32>\n }\n+// CHECK-HIGH-LEVEL: mhlo.atanh\n \n // -----\n \n@@ -2814,6 +2815,7 @@ func.func @atanh_complex_f32(%arg : tensor<complex<f32>>) -> tensor<complex<f32>\n   %result = \"chlo.atanh\"(%arg) : (tensor<complex<f32>>) -> tensor<complex<f32>>\n   func.return %result : tensor<complex<f32>>\n }\n+// CHECK-HIGH-LEVEL-NOT: mhlo.atanh\n \n // -----\n "
        },
        {
            "sha": "57502870083a9e81e49bdbc52c4fa50b48d1bbec",
            "filename": "third_party/xla/xla/mlir_hlo/tests/stablehlo_ext/chlo_preserve_high_level_ops.mlir",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -93,6 +93,16 @@ func.func @acos_preserve(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n \n // -----\n \n+// CHECK-LABEL: func @atanh_preserve\n+func.func @atanh_preserve(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK-CC: stablehlo.custom_call @mhlo.atanh(%arg0) {mhlo.attributes = {}, mhlo.version = 1 : i64} : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  // CHECK: stablehlo.composite \"chlo.atanh\" %arg0 {decomposition = @chlo.atanh.impl, version = 1 : i32}\n+  %0 = chlo.atanh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @tan_no_preserve\n func.func @tan_no_preserve(%arg0: tensor<16xf32>) -> tensor<?xf32> {\n   // CHECK: chlo.tan"
        },
        {
            "sha": "4b6d699c8ebffee8e39b76298f902f25ff9f9baf",
            "filename": "third_party/xla/xla/mlir_hlo/tests/stablehlo_ext/chlo_recompose_ops.mlir",
            "status": "modified",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -33,6 +33,21 @@ func.func private @chlo.acosh.impl(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x2\n \n // -----\n \n+// CHECK-LABEL: func @atanh_recompose_composite\n+func.func @atanh_recompose_composite(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK-NEXT: chlo.atanh\n+  // CHECK-NOT: stablehlo.composite\n+  %0 = stablehlo.composite \"chlo.atanh\" %arg0 {decomposition = @chlo.atanh.impl, version = 1 : i32} : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+// CHECK-NOT: @chlo.atanh.imp\n+func.func private @chlo.atanh.impl(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  %0 = chlo.atanh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @acos_recompose_composite\n func.func @acos_recompose_composite(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n   // CHECK-NEXT: chlo.acos\n@@ -123,6 +138,20 @@ func.func @acos_recompose_cc(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16\n \n // -----\n \n+// CHECK-LABEL: @atanh_recompose_cc\n+func.func @atanh_recompose_cc(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK: %0 = chlo.atanh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  %0 = \"stablehlo.custom_call\"(%arg0) {\n+    backend_config = \"\",\n+    call_target_name = \"mhlo.atanh\",\n+    mhlo.attributes = {},\n+    mhlo.version = 1 : i64\n+  } : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  func.return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @ragged_dot_recompose_cc\n func.func @ragged_dot_recompose_cc(%arg0: tensor<2x11x5xf32>, %arg1: tensor<3x2x5x7xf32>, %arg2: tensor<3xi64>) -> tensor<2x11x7xf32> {\n   // CHECK: \"chlo.ragged_dot\"(%arg0, %arg1, %arg2) <{precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>], ragged_dot_dimension_numbers = #chlo.ragged_dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [1], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [2], lhs_ragged_dimensions = [1], rhs_group_dimensions = [0]>}> : (tensor<2x11x5xf32>, tensor<3x2x5x7xf32>, tensor<3xi64>) -> tensor<2x11x7xf32>"
        },
        {
            "sha": "e3c5f4187e4ce5dc6fce09065e996dcb6a5fe90e",
            "filename": "third_party/xla/xla/tests/exhaustive/exhaustive_unary_test_ops.inc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97a945e7039b98a99815d4a5a81d3bd3c3b8092/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc?ref=b97a945e7039b98a99815d4a5a81d3bd3c3b8092",
            "patch": "@@ -200,7 +200,9 @@ DEFINE_UNARY_TEST_OP(\n     AcoshOp, { return [](XlaOp x) { return Acosh(x); }; },\n     { return std::acosh; });\n DEFINE_UNARY_TEST_OP(AsinhOp, { return Asinh; }, { return std::asinh; });\n-DEFINE_UNARY_TEST_OP(AtanhOp, { return Atanh; }, { return std::atanh; });\n+DEFINE_UNARY_TEST_OP(\n+    AtanhOp, { return [](XlaOp x) { return Atanh(x); }; },\n+    { return std::atanh; });\n DEFINE_UNARY_TEST_OP(\n     AcosOp, { return [](XlaOp x) { return Acos(x); }; }, { return std::acos; });\n DEFINE_UNARY_TEST_OP(AsinOp, { return Asin; }, { return std::asin; });"
        }
    ],
    "stats": {
        "total": 215,
        "additions": 186,
        "deletions": 29
    }
}