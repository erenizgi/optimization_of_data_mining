{
    "author": "KanishAnand",
    "message": "(3/N) Add support for `NamedSharding` in existing `HloSharding` methods. Remaining methods will be updated in follow up cl's.\n\nPiperOrigin-RevId: 842918400",
    "sha": "95a9086a3545a0a0fd4c562b162acef4b573fb0c",
    "files": [
        {
            "sha": "289c93a6640964fe1167410975837fc4f5b41186",
            "filename": "third_party/xla/xla/hlo/ir/hlo_sharding.h",
            "status": "modified",
            "additions": 15,
            "deletions": 2,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.h?ref=95a9086a3545a0a0fd4c562b162acef4b573fb0c",
            "patch": "@@ -489,10 +489,18 @@ class HloSharding {\n   }\n \n   // Returns the number of dimensions.\n-  int64_t num_dimensions() const { return tile_assignment().num_dimensions(); }\n+  int64_t num_dimensions() const {\n+    if (UseNamedShardingLeaf()) {\n+      return named_sharding_->num_dimensions();\n+    }\n+    return tile_assignment().num_dimensions();\n+  }\n \n   // Returns number of shards in the given dimension.\n   int64_t dimension(int64_t dim_index) const {\n+    if (UseNamedShardingLeaf()) {\n+      return named_sharding_->dimension(dim_index);\n+    }\n     return tile_assignment().dim(dim_index);\n   }\n \n@@ -502,7 +510,12 @@ class HloSharding {\n   }\n \n   // Returns the total number of devices used by sharding.\n-  int64_t num_devices() const { return tile_assignment().num_elements(); }\n+  int64_t num_devices() const {\n+    if (UseNamedShardingLeaf()) {\n+      return named_sharding_->num_devices();\n+    }\n+    return tile_assignment().num_elements();\n+  }\n \n   // Gets the subgroup types array.\n   // REQUIRES: !IsTuple()"
        },
        {
            "sha": "ae638cd8d9bdc3b65386f414daba55c6ed101e0a",
            "filename": "third_party/xla/xla/hlo/ir/mesh_and_axis.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fmesh_and_axis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fmesh_and_axis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fmesh_and_axis.cc?ref=95a9086a3545a0a0fd4c562b162acef4b573fb0c",
            "patch": "@@ -309,6 +309,14 @@ bool AxisRef::CanCoexistWithoutOverlap(const AxisRef& other) const {\n   return max_pre_size % min_next_pre_size == 0;\n }\n \n+int64_t AxisRef::size(const Mesh& mesh) const {\n+  if (sub_axis_info_.has_value()) {\n+    return sub_axis_info_->size;\n+  }\n+\n+  return mesh.axis_size(mesh_axis_index_);\n+}\n+\n bool AxesCanCoexistWithoutOverlap(absl::Span<const AxisRef> axes) {\n   for (int64_t i = 0; i < axes.size() - 1; ++i) {\n     for (int64_t j = i + 1; j < axes.size(); ++j) {"
        },
        {
            "sha": "f6190d038ff62588f2851b8a538e621fdac7d7c8",
            "filename": "third_party/xla/xla/hlo/ir/mesh_and_axis.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fmesh_and_axis.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fmesh_and_axis.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fmesh_and_axis.h?ref=95a9086a3545a0a0fd4c562b162acef4b573fb0c",
            "patch": "@@ -202,6 +202,8 @@ class AxisRef {\n   int64_t mesh_axis_index() const { return mesh_axis_index_; }\n   std::optional<SubAxis> sub_axis_info() const { return sub_axis_info_; }\n \n+  int64_t size(const Mesh& mesh) const;\n+\n  private:\n   absl::Status ValidateAxisRef();\n };"
        },
        {
            "sha": "1bc5b9896b90a6fcdac3b270aa5bf915e88bb71b",
            "filename": "third_party/xla/xla/hlo/ir/mesh_and_axis_test.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 1,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fmesh_and_axis_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fmesh_and_axis_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fmesh_and_axis_test.cc?ref=95a9086a3545a0a0fd4c562b162acef4b573fb0c",
            "patch": "@@ -16,7 +16,6 @@ limitations under the License.\n #include \"xla/hlo/ir/mesh_and_axis.h\"\n \n #include <cstdint>\n-#include <string>\n #include <vector>\n \n #include <gmock/gmock.h>\n@@ -350,4 +349,17 @@ TEST(MeshAndAxisTest, MaximalMesh) {\n   EXPECT_EQ(maximal_mesh, Mesh::FromProto(maximal_mesh.ToProto()));\n }\n \n+TEST(MeshAndAxisTest, AxisRefSize) {\n+  Mesh mesh({2 * 7, 3 * 11, 5 * 13}, {\"a\", \"b\", \"c\"});\n+  EXPECT_EQ(AxisRef(0).size(mesh), 14);\n+  EXPECT_EQ(AxisRef(1).size(mesh), 33);\n+  EXPECT_EQ(AxisRef(2).size(mesh), 65);\n+  EXPECT_EQ(AxisRef(0, {1, 2}).size(mesh), 2);\n+  EXPECT_EQ(AxisRef(0, {2, 7}).size(mesh), 7);\n+  EXPECT_EQ(AxisRef(1, {1, 3}).size(mesh), 3);\n+  EXPECT_EQ(AxisRef(1, {3, 11}).size(mesh), 11);\n+  EXPECT_EQ(AxisRef(2, {1, 5}).size(mesh), 5);\n+  EXPECT_EQ(AxisRef(2, {5, 13}).size(mesh), 13);\n+}\n+\n }  // namespace xla"
        },
        {
            "sha": "efdecbcea0fa16f905caee3b1b1e8dc698072b0a",
            "filename": "third_party/xla/xla/hlo/ir/named_sharding.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fnamed_sharding.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fnamed_sharding.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fnamed_sharding.cc?ref=95a9086a3545a0a0fd4c562b162acef4b573fb0c",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n \n #include <cstdint>\n #include <map>\n+#include <numeric>\n #include <string>\n #include <utility>\n #include <vector>\n@@ -27,6 +28,14 @@ limitations under the License.\n \n namespace xla {\n \n+int64_t NamedSharding::DimensionSharding::getShardedSize(\n+    const Mesh& mesh) const {\n+  return std::accumulate(axes_.begin(), axes_.end(), 1,\n+                         [&mesh](int64_t cur, const AxisRef& axis) {\n+                           return cur * axis.size(mesh);\n+                         });\n+}\n+\n namespace test_utils {\n // Construct sharding with given mesh. 'dim_shardings', 'replicated_axes',\n // 'unreduced_axes' refer to axis names in the mesh."
        },
        {
            "sha": "35919d7b4befa3e74063fe47a0ae350ada4ee94e",
            "filename": "third_party/xla/xla/hlo/ir/named_sharding.h",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fnamed_sharding.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fnamed_sharding.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fnamed_sharding.h?ref=95a9086a3545a0a0fd4c562b162acef4b573fb0c",
            "patch": "@@ -47,6 +47,8 @@ class NamedSharding {\n \n     absl::Span<const AxisRef> axes() const { return axes_; }\n \n+    int64_t getShardedSize(const Mesh& mesh) const;\n+\n    private:\n     std::vector<AxisRef> axes_;\n     bool is_closed_;\n@@ -84,6 +86,19 @@ class NamedSharding {\n   absl::Span<const AxisRef> unreduced_axes() const { return unreduced_axes_; }\n   absl::Span<const OpMetadata> metadata() const { return metadata_; }\n \n+  // Returns number of dimensions.\n+  int64_t num_dimensions() const { return dim_shardings_.size(); }\n+\n+  // Returns size of the given dimension.\n+  int64_t dimension(int64_t dim) const {\n+    return dim_shardings_[dim].getShardedSize(mesh_);\n+  }\n+\n+  // Returns the total number of devices used by sharding.\n+  int64_t num_devices() const {\n+    return mesh_.device_assignment().num_elements();\n+  }\n+\n  private:\n   friend class HloSharding;\n "
        },
        {
            "sha": "22930e733aca5d098d2c3c27b442a3f8db469492",
            "filename": "third_party/xla/xla/hlo/ir/named_sharding_test.cc",
            "status": "modified",
            "additions": 56,
            "deletions": 0,
            "changes": 56,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fnamed_sharding_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/95a9086a3545a0a0fd4c562b162acef4b573fb0c/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fnamed_sharding_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fnamed_sharding_test.cc?ref=95a9086a3545a0a0fd4c562b162acef4b573fb0c",
            "patch": "@@ -109,5 +109,61 @@ TEST(NamedShardingTest, Equality) {\n             NamedSharding(mesh_diff_shape, {ds_ab, ds_dc}, {axis_b}, {axis_c}));\n }\n \n+TEST(NamedShardingTest, GetShardedSize) {\n+  Mesh mesh({2, 4, 3, 8}, {\"a\", \"b\", \"c\", \"d\"});\n+\n+  AxisRef axis_a(0);\n+  AxisRef axis_b(1, {2, 2});\n+  AxisRef axis_c(2);\n+  AxisRef axis_d(3, {4, 2});\n+\n+  DimensionSharding ds_ab({axis_a, axis_b}, /*is_closed=*/true);\n+  EXPECT_EQ(ds_ab.getShardedSize(mesh), 2 * 2);\n+\n+  DimensionSharding ds_dc({axis_d, axis_c}, /*is_closed=*/true);\n+  EXPECT_EQ(ds_dc.getShardedSize(mesh), 2 * 3);\n+\n+  DimensionSharding ds_b({axis_b}, /*is_closed=*/true);\n+  EXPECT_EQ(ds_b.getShardedSize(mesh), 2);\n+\n+  DimensionSharding ds_empty({}, /*is_closed=*/true);\n+  EXPECT_EQ(ds_empty.getShardedSize(mesh), 1);\n+}\n+\n+TEST(NamedShardingTest, Dimension) {\n+  Mesh mesh({2, 4, 3, 8}, {\"a\", \"b\", \"c\", \"d\"});\n+\n+  AxisRef axis_a(0);\n+  AxisRef axis_b(1, {2, 2});\n+  AxisRef axis_c(2);\n+  AxisRef axis_d(3, {4, 2});\n+\n+  DimensionSharding ds_ab({axis_a, axis_b}, /*is_closed=*/true);\n+  DimensionSharding ds_dc({axis_d, axis_c}, /*is_closed=*/true);\n+\n+  NamedSharding sharding(mesh, /*dim_shardings=*/{ds_ab, ds_dc});\n+\n+  EXPECT_EQ(sharding.dimension(0), 2 * 2);\n+  EXPECT_EQ(sharding.dimension(1), 2 * 3);\n+  EXPECT_EQ(sharding.num_dimensions(), 2);\n+\n+  NamedSharding empty_sharding(mesh, /*dim_shardings=*/{});\n+  EXPECT_EQ(empty_sharding.num_dimensions(), 0);\n+}\n+\n+TEST(NamedShardingTest, NumDevices) {\n+  Mesh mesh({2, 4, 3, 8}, {\"a\", \"b\", \"c\", \"d\"});\n+  NamedSharding sharding(mesh, {});\n+  EXPECT_EQ(sharding.num_devices(), 2 * 4 * 3 * 8);\n+\n+  Mesh maximal_mesh(5);\n+  NamedSharding maximal_sharding(maximal_mesh);\n+  EXPECT_EQ(maximal_sharding.num_devices(), 1);\n+\n+  Mesh empty_mesh;\n+  NamedSharding empty_sharding(empty_mesh);\n+  EXPECT_EQ(empty_sharding.num_devices(), 0);\n+}\n+\n }  // namespace\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 121,
        "additions": 118,
        "deletions": 3
    }
}