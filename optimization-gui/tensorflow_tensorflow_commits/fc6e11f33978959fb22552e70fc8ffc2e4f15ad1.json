{
    "author": "ezhulenev",
    "message": "[xla:ffi] Move GPU FFI implementation to backends/gpu\n\nTo avoid bringing GPU dependencies with default FFI target, split GPU-specific context decoding into backends/gpu:ffi\n\nPiperOrigin-RevId: 837342185",
    "sha": "fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
    "files": [
        {
            "sha": "89c120f26bf5e5916245e40319ce544f6458c7ad",
            "filename": "third_party/xla/xla/backends/gpu/BUILD",
            "status": "added",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2FBUILD?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -0,0 +1,29 @@\n+load(\"//xla/tsl/platform:rules_cc.bzl\", \"cc_library\")\n+\n+package(\n+    # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n+    default_visibility = [\":friends\"],\n+    licenses = [\"notice\"],\n+)\n+\n+package_group(\n+    name = \"friends\",\n+    includes = [\n+        \"//xla:friends\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"ffi\",\n+    hdrs = [\"ffi.h\"],\n+    visibility = [\"//visibility:public\"],\n+    deps = [\n+        \"//xla/ffi:api\",\n+        \"//xla/ffi/api:c_api\",\n+        \"//xla/ffi/api:c_api_internal\",\n+        \"//xla/stream_executor:device_memory_allocator\",\n+        \"//xla/stream_executor:scratch_allocator\",\n+        \"//xla/stream_executor:stream\",\n+        \"@com_google_absl//absl/base:core_headers\",\n+    ],\n+)"
        },
        {
            "sha": "2cda5f919ea0941b332f8f1324ad1f456b96055b",
            "filename": "third_party/xla/xla/backends/gpu/ffi.h",
            "status": "added",
            "additions": 127,
            "deletions": 0,
            "changes": 127,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fffi.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fffi.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fffi.h?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -0,0 +1,127 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_FFI_H_\n+#define XLA_BACKENDS_GPU_FFI_H_\n+\n+#include <cstdint>\n+#include <optional>\n+\n+#include \"absl/base/optimization.h\"\n+#include \"xla/ffi/api/c_api.h\"\n+#include \"xla/ffi/api/c_api_internal.h\"  // IWYU pragma: keep\n+#include \"xla/ffi/api/api.h\"  // IWYU pragma: export\n+#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/scratch_allocator.h\"\n+#include \"xla/stream_executor/stream.h\"\n+\n+namespace xla::ffi {\n+\n+//===----------------------------------------------------------------------===//\n+// Type tags to bind parameters passed via execution context to FFI handler\n+//===----------------------------------------------------------------------===//\n+\n+struct Stream {};            // binds `se::Stream*`\n+struct Allocator {};         // binds `se::DeviceMemoryAllocator*`\n+struct ScratchAllocator {};  // binds `se::OwningScratchAllocator`\n+\n+template <typename T>\n+struct PlatformStream {};  // binds a platform stream, e.g. `cudaStream_t`\n+\n+//===----------------------------------------------------------------------===//\n+// Context decoding\n+//===----------------------------------------------------------------------===//\n+\n+template <>\n+struct CtxDecoding<Stream> {\n+  using Type = stream_executor::Stream*;\n+\n+  static std::optional<Type> Decode(const XLA_FFI_Api* api,\n+                                    XLA_FFI_ExecutionContext* ctx,\n+                                    DiagnosticEngine& diagnostic) {\n+    void* stream = nullptr;\n+    if (XLA_FFI_Error* error =\n+            api->internal_api->XLA_FFI_INTERNAL_Stream_Get(ctx, &stream);\n+        ABSL_PREDICT_FALSE(error)) {\n+      diagnostic.Emit(\"Failed to get stream: \")\n+          << internal::GetErrorMessage(api, error);\n+      internal::DestroyError(api, error);\n+      return std::nullopt;\n+    }\n+    return reinterpret_cast<Type>(stream);\n+  }\n+};\n+\n+template <>\n+struct CtxDecoding<Allocator> {\n+  using Type = stream_executor::DeviceMemoryAllocator*;\n+\n+  static std::optional<Type> Decode(const XLA_FFI_Api* api,\n+                                    XLA_FFI_ExecutionContext* ctx,\n+                                    DiagnosticEngine& diagnostic) {\n+    void* device_allocator = nullptr;\n+    if (XLA_FFI_Error* error =\n+            api->internal_api->XLA_FFI_INTERNAL_DeviceMemoryAllocator_Get(\n+                ctx, &device_allocator);\n+        ABSL_PREDICT_FALSE(error)) {\n+      diagnostic.Emit(\"Failed to get device memory allocator: \")\n+          << internal::GetErrorMessage(api, error);\n+      internal::DestroyError(api, error);\n+      return std::nullopt;\n+    }\n+    return reinterpret_cast<Type>(device_allocator);\n+  }\n+};\n+\n+template <>\n+struct CtxDecoding<ScratchAllocator> {\n+  using Type = stream_executor::OwningScratchAllocator<>;\n+\n+  static std::optional<Type> Decode(const XLA_FFI_Api* api,\n+                                    XLA_FFI_ExecutionContext* ctx,\n+                                    DiagnosticEngine& diagnostic) {\n+    int32_t device_ordinal =\n+        api->internal_api->XLA_FFI_INTERNAL_DeviceOrdinal_Get(ctx);\n+\n+    auto device_allocator =\n+        CtxDecoding<Allocator>::Decode(api, ctx, diagnostic);\n+    if (ABSL_PREDICT_FALSE(!device_allocator)) {\n+      return std::nullopt;\n+    }\n+\n+    return stream_executor::OwningScratchAllocator<>(device_ordinal,\n+                                                     *device_allocator);\n+  }\n+};\n+\n+template <typename T>\n+struct CtxDecoding<PlatformStream<T>> {\n+  using Type = T;\n+  static_assert(std::is_pointer_v<T>, \"platform stream type must be a pointer\");\n+\n+  static std::optional<Type> Decode(const XLA_FFI_Api* api,\n+                                    XLA_FFI_ExecutionContext* ctx,\n+                                    DiagnosticEngine& diagnostic) {\n+    if (auto stream = CtxDecoding<Stream>::Decode(api, ctx, diagnostic)) {\n+      return reinterpret_cast<Type>(\n+          stream.value()->platform_specific_handle().stream);\n+    }\n+    return std::nullopt;\n+  }\n+};\n+\n+}  // namespace xla::ffi\n+\n+#endif  // XLA_BACKENDS_GPU_FFI_H_"
        },
        {
            "sha": "c1290e7665499b18b67cb14cf8a78c61f3509192",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -3154,6 +3154,7 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n+        \"//xla/backends/gpu:ffi\",\n         \"//xla/ffi\",\n         \"//xla/ffi:attribute_map\",\n         \"//xla/ffi/api:c_api\",\n@@ -3224,6 +3225,7 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/backends/gpu:ffi\",\n         \"//xla/ffi\",\n         \"//xla/ffi:ffi_api\",\n         \"//xla/service:collective_ops_utils\","
        },
        {
            "sha": "884157fd5f85f1af615cb2fd84104de5234ff7ea",
            "filename": "third_party/xla/xla/backends/gpu/runtime/runtime_intrinsics.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fruntime_intrinsics.cc?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -31,6 +31,7 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"absl/strings/substitute.h\"\n #include \"absl/synchronization/mutex.h\"\n+#include \"xla/backends/gpu/ffi.h\"\n #include \"xla/ffi/ffi.h\"\n #include \"xla/ffi/ffi_api.h\"\n #include \"xla/layout_util.h\""
        },
        {
            "sha": "3031cbc9df9c4a841b91a6269bd00a5acc872b2a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_checksum.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_checksum.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_checksum.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_checksum.cc?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -30,6 +30,7 @@ limitations under the License.\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"xla/backends/gpu/ffi.h\"\n #include \"xla/backends/gpu/runtime/buffer_debug_log.pb.h\"\n #include \"xla/backends/gpu/runtime/buffer_debug_log_entry_metadata_store.h\"\n #include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\""
        },
        {
            "sha": "7a6aebc10f12e7bb252487e66d85fa0fa7fc0a92",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_float_check.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_float_check.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_float_check.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_float_check.cc?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"xla/backends/gpu/ffi.h\"\n #include \"xla/backends/gpu/runtime/buffer_debug_log.pb.h\"\n #include \"xla/backends/gpu/runtime/buffer_debug_log_entry_metadata_store.h\"\n #include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\""
        },
        {
            "sha": "eb091eaabb7bb9093fa69e7e8734674b294c2989",
            "filename": "third_party/xla/xla/ffi/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fffi%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fffi%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fffi%2FBUILD?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -9,7 +9,10 @@ package(\n \n package_group(\n     name = \"ffi_internal\",\n-    packages = [\"//xla/backends/cpu\"],\n+    packages = [\n+        \"//xla/backends/cpu\",\n+        \"//xla/backends/gpu\",\n+    ],\n )\n \n cc_library(\n@@ -140,13 +143,11 @@ cc_library(\n         \"//xla:types\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/backends/gpu:ffi\",\n         \"//xla/ffi/api:c_api\",\n         \"//xla/ffi/api:c_api_internal\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/stream_executor:device_memory\",\n-        \"//xla/stream_executor:device_memory_allocator\",\n-        \"//xla/stream_executor:scratch_allocator\",\n-        \"//xla/stream_executor:stream\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:core_headers\",\n@@ -292,6 +293,7 @@ xla_cc_test(\n         \"//xla:executable_run_options\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/backends/cpu:ffi\",\n+        \"//xla/backends/gpu:ffi\",\n         \"//xla/ffi/api:c_api\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:stream\","
        },
        {
            "sha": "6f3a8af8eae108effc1bcb0825b86ea0cd749f28",
            "filename": "third_party/xla/xla/ffi/ffi.h",
            "status": "modified",
            "additions": 3,
            "deletions": 86,
            "changes": 89,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fffi%2Fffi.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fffi%2Fffi.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fffi%2Fffi.h?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -51,27 +51,21 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/primitive_util.h\"\n #include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n-#include \"xla/stream_executor/scratch_allocator.h\"\n-#include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/chain.h\"\n #include \"xla/types.h\"  // IWYU pragma: keep\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n \n+// TODO(ezhulenev): Remove this once JAX is migrated to the new header.\n+#include \"xla/backends/gpu/ffi.h\"\n+\n namespace xla::ffi {\n \n // Type tags to bind parameters passed via execution context to FFI handler.\n-struct Stream {};             // binds `se::Stream*`\n struct DeviceOrdinal {};      // binds `int32_t` with device ordinal\n-struct Allocator {};          // binds `se::DeviceMemoryAllocator*`\n-struct ScratchAllocator {};   // binds `se::OwningScratchAllocator`\n struct CalledComputation {};  // binds `HloComputation*`\n \n-template <typename T>\n-struct PlatformStream {};  // binds a platform stream, e.g. `cudaStream_t`\n-\n //===----------------------------------------------------------------------===//\n // Arguments\n //===----------------------------------------------------------------------===//\n@@ -551,26 +545,6 @@ struct CtxDecoding<Context> {\n // Context decoding\n //===----------------------------------------------------------------------===//\n \n-template <>\n-struct CtxDecoding<Stream> {\n-  using Type = se::Stream*;\n-\n-  static std::optional<Type> Decode(const XLA_FFI_Api* api,\n-                                    XLA_FFI_ExecutionContext* ctx,\n-                                    DiagnosticEngine& diagnostic) {\n-    void* stream = nullptr;\n-    if (XLA_FFI_Error* error =\n-            api->internal_api->XLA_FFI_INTERNAL_Stream_Get(ctx, &stream);\n-        ABSL_PREDICT_FALSE(error)) {\n-      diagnostic.Emit(\"Failed to get stream: \")\n-          << internal::GetErrorMessage(api, error);\n-      internal::DestroyError(api, error);\n-      return std::nullopt;\n-    }\n-    return reinterpret_cast<Type>(stream);\n-  }\n-};\n-\n template <>\n struct CtxDecoding<DeviceOrdinal> {\n   using Type = int32_t;\n@@ -582,47 +556,6 @@ struct CtxDecoding<DeviceOrdinal> {\n   }\n };\n \n-template <>\n-struct CtxDecoding<Allocator> {\n-  using Type = se::DeviceMemoryAllocator*;\n-\n-  static std::optional<Type> Decode(const XLA_FFI_Api* api,\n-                                    XLA_FFI_ExecutionContext* ctx,\n-                                    DiagnosticEngine& diagnostic) {\n-    void* device_allocator = nullptr;\n-    if (XLA_FFI_Error* error =\n-            api->internal_api->XLA_FFI_INTERNAL_DeviceMemoryAllocator_Get(\n-                ctx, &device_allocator);\n-        ABSL_PREDICT_FALSE(error)) {\n-      diagnostic.Emit(\"Failed to get device memory allocator: \")\n-          << internal::GetErrorMessage(api, error);\n-      internal::DestroyError(api, error);\n-      return std::nullopt;\n-    }\n-    return reinterpret_cast<Type>(device_allocator);\n-  }\n-};\n-\n-template <>\n-struct CtxDecoding<ScratchAllocator> {\n-  using Type = se::OwningScratchAllocator<>;\n-\n-  static std::optional<Type> Decode(const XLA_FFI_Api* api,\n-                                    XLA_FFI_ExecutionContext* ctx,\n-                                    DiagnosticEngine& diagnostic) {\n-    int32_t device_ordinal =\n-        api->internal_api->XLA_FFI_INTERNAL_DeviceOrdinal_Get(ctx);\n-\n-    auto device_allocator =\n-        CtxDecoding<Allocator>::Decode(api, ctx, diagnostic);\n-    if (ABSL_PREDICT_FALSE(!device_allocator)) {\n-      return std::nullopt;\n-    }\n-\n-    return se::OwningScratchAllocator<>(device_ordinal, *device_allocator);\n-  }\n-};\n-\n template <>\n struct CtxDecoding<CalledComputation> {\n   using Type = const HloComputation*;\n@@ -635,22 +568,6 @@ struct CtxDecoding<CalledComputation> {\n   }\n };\n \n-template <typename T>\n-struct CtxDecoding<PlatformStream<T>> {\n-  using Type = T;\n-  static_assert(std::is_pointer_v<T>, \"platform stream type must be a pointer\");\n-\n-  static std::optional<Type> Decode(const XLA_FFI_Api* api,\n-                                    XLA_FFI_ExecutionContext* ctx,\n-                                    DiagnosticEngine& diagnostic) {\n-    if (auto stream = CtxDecoding<Stream>::Decode(api, ctx, diagnostic)) {\n-      return reinterpret_cast<Type>(\n-          stream.value()->platform_specific_handle().stream);\n-    }\n-    return std::nullopt;\n-  }\n-};\n-\n template <>\n struct CtxDecoding<RunId> {\n   using Type = RunId;"
        },
        {
            "sha": "8f0b00244c0a93df844a1eda322dcaec8dde9b2a",
            "filename": "third_party/xla/xla/ffi/ffi_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fffi%2Fffi_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fffi%2Fffi_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fffi%2Fffi_test.cc?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/cpu/ffi.h\"\n+#include \"xla/backends/gpu/ffi.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/ffi/api/c_api.h\"\n #include \"xla/ffi/attribute_map.h\""
        },
        {
            "sha": "9910dabc7ab1e921290ac083d01a481f59b75fe2",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -203,6 +203,7 @@ xla_test(\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/backends/gpu:ffi\",\n         \"//xla/ffi\",\n         \"//xla/ffi:execution_context\",\n         \"//xla/ffi:ffi_api\","
        },
        {
            "sha": "0e9ef621b3f53e6a93039c0c4374394c3c22d9bb",
            "filename": "third_party/xla/xla/service/gpu/custom_call_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_call_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_call_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_call_test.cc?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -42,6 +42,7 @@ limitations under the License.\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/backends/gpu/ffi.h\"\n #include \"xla/ffi/execution_context.h\"\n #include \"xla/ffi/ffi.h\"\n #include \"xla/ffi/ffi_api.h\""
        },
        {
            "sha": "c98a5b5e2f36dce0d05c179931b52d0f838f795b",
            "filename": "third_party/xla/xla/service/gpu/tests/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -86,6 +86,7 @@ xla_test(\n         [\n             \"//xla:error_spec\",\n             \"//xla:shape_util\",\n+            \"//xla/backends/gpu:ffi\",\n             \"//xla/ffi\",\n             \"//xla/ffi:ffi_api\",\n             \"@com_google_absl//absl/algorithm:container\","
        },
        {
            "sha": "789f5e65fcedbeb4f77f41225c429e56f2b6781a",
            "filename": "third_party/xla/xla/service/gpu/tests/dynamic_slice_fusion_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fdynamic_slice_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fdynamic_slice_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fdynamic_slice_fusion_test.cc?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include <utility>\n \n #include \"absl/status/status.h\"\n+#include \"xla/backends/gpu/ffi.h\"\n #include \"xla/error_spec.h\"\n #include \"xla/ffi/ffi.h\"\n #include \"xla/ffi/ffi_api.h\""
        },
        {
            "sha": "2df0bb9513d30541a990b906e35896261e1c3abf",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -1287,6 +1287,7 @@ xla_cc_test(\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n+        \"//xla/backends/gpu:ffi\",\n         \"//xla/ffi\",\n         \"//xla/ffi:ffi_api\",\n         \"//xla/hlo/builder:xla_builder\","
        },
        {
            "sha": "bb5eb3ee9fd26ea6db65cc4685e699558d050351",
            "filename": "third_party/xla/xla/service/gpu/transforms/dynamic_slice_fusion_rewriter_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdynamic_slice_fusion_rewriter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdynamic_slice_fusion_rewriter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdynamic_slice_fusion_rewriter_test.cc?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n \n #include <gtest/gtest.h>\n #include \"absl/status/status.h\"\n+#include \"xla/backends/gpu/ffi.h\"\n #include \"xla/ffi/ffi.h\"\n #include \"xla/ffi/ffi_api.h\"\n #include \"xla/hlo/builder/lib/constants.h\""
        },
        {
            "sha": "aa5b016d652e552826e3c3c266e6bbd6821bfa7e",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -2336,6 +2336,7 @@ cuda_library(\n     ],\n     deps = [\n         \":cub_sort_kernel_cuda_impl_{}\".format(typename),\n+        \"//xla/backends/gpu:ffi\",\n         \"//xla/ffi\",\n         \"//xla/ffi:ffi_api\",\n         \"//xla/stream_executor/cuda:cuda_status\","
        },
        {
            "sha": "28cbf55076784e8eff1acd41a96db726871e7890",
            "filename": "third_party/xla/xla/stream_executor/cuda/cub_sort_kernel_cuda.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcub_sort_kernel_cuda.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcub_sort_kernel_cuda.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcub_sort_kernel_cuda.cc?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"third_party/gpus/cuda/include/cuda.h\"\n #include \"third_party/gpus/cuda/include/cuda_fp16.h\"  // IWYU pragma: keep\n+#include \"xla/backends/gpu/ffi.h\"\n #include \"xla/ffi/ffi.h\"\n #include \"xla/ffi/ffi_api.h\"  // IWYU pragma: keep\n #include \"xla/stream_executor/cuda/cuda_status.h\""
        },
        {
            "sha": "29ad816ab03114a7d6ae397b3e5e4e2759679674",
            "filename": "third_party/xla/xla/stream_executor/rocm/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2FBUILD?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -1150,6 +1150,7 @@ rocm_library(\n         \"rocm-only\",\n     ],\n     deps = [\n+        \"//xla/backends/gpu:ffi\",\n         \"//xla/ffi\",\n         \"//xla/ffi:ffi_api\",\n         \"//xla/stream_executor/rocm:rocm_status\","
        },
        {
            "sha": "30baa5d6ce286accedc02f6ce35306aee42f4351",
            "filename": "third_party/xla/xla/stream_executor/rocm/cub_sort_kernel_rocm.cu.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fcub_sort_kernel_rocm.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc6e11f33978959fb22552e70fc8ffc2e4f15ad1/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fcub_sort_kernel_rocm.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fcub_sort_kernel_rocm.cu.cc?ref=fc6e11f33978959fb22552e70fc8ffc2e4f15ad1",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"rocm/include/rocprim/thread/radix_key_codec.hpp\"\n #include \"rocm/include/rocprim/type_traits.hpp\"\n #include \"rocm/rocm_config.h\"\n+#include \"xla/backends/gpu/ffi.h\"\n #include \"xla/ffi/ffi.h\"\n #include \"xla/ffi/ffi_api.h\"  // IWYU pragma: keep\n #include \"xla/stream_executor/rocm/rocm_status.h\""
        }
    ],
    "stats": {
        "total": 271,
        "additions": 181,
        "deletions": 90
    }
}