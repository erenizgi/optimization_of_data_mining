{
    "author": "mkuperst",
    "message": "[XLA] Make CompileAheadOfTime a single-module API, rather than ModuleGroup.\n\nModule groups are unused in practice, and every existing callsite of this wraps a single module in a module-group.\n\nPiperOrigin-RevId: 815696232",
    "sha": "373c1e06c44664fc13f7f39209fd11fb36925999",
    "files": [
        {
            "sha": "a83d0334376373751b34b3a2e76f7b25e48d542d",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/native_emitter_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -205,7 +205,7 @@ class MockCompiler : public Compiler {\n   MOCK_METHOD(\n       absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>,\n       CompileAheadOfTime,\n-      (std::unique_ptr<HloModuleGroup> module_group,\n+      (std::unique_ptr<HloModule> hlo_module,\n        const AotCompilationOptions& options),\n       (override));\n   MOCK_METHOD(HloCostAnalysis::ShapeSizeFunction, ShapeSizeBytesFunction, (),"
        },
        {
            "sha": "bf4ab0d6ebd4e3230b5feb7aed82aff1ffa0bc0e",
            "filename": "third_party/xla/xla/backends/interpreter/compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fbackends%2Finterpreter%2Fcompiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fbackends%2Finterpreter%2Fcompiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Finterpreter%2Fcompiler.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -173,7 +173,7 @@ InterpreterCompiler::Compile(\n \n absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n InterpreterCompiler::CompileAheadOfTime(\n-    std::unique_ptr<HloModuleGroup> module_group,\n+    std::unique_ptr<HloModule> hlo_module,\n     const AotCompilationOptions& aot_options) {\n   return tsl::errors::InvalidArgument(\n       \"AOT compilation not supported on Interpreter\");"
        },
        {
            "sha": "47551a61828cc7a6562b34787e0d6b9fff35a778",
            "filename": "third_party/xla/xla/backends/interpreter/compiler.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fbackends%2Finterpreter%2Fcompiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fbackends%2Finterpreter%2Fcompiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Finterpreter%2Fcompiler.h?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -56,7 +56,7 @@ class InterpreterCompiler : public Compiler {\n       const CompileOptions& options) override;\n \n   absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n-  CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n+  CompileAheadOfTime(std::unique_ptr<HloModule> hlo_module,\n                      const AotCompilationOptions& aot_options) override;\n \n   HloCostAnalysis::ShapeSizeFunction ShapeSizeBytesFunction() const override;"
        },
        {
            "sha": "216c6b3ed5feca498f0ae1e8423e2f95bfbfb025",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 6,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -617,15 +617,10 @@ static absl::StatusOr<std::unique_ptr<xla::Executable>> CompileAheadOfTime(\n \n   cpu::CpuCompiler compiler;\n   // TODO (basioli): honor build_options.run_backend_only() for AOT.\n-\n-  auto hlo_module_group =\n-      std::make_unique<HloModuleGroup>(std::move(hlo_module));\n-\n   // Compile AOT.\n   TF_ASSIGN_OR_RETURN(\n       std::vector<std::unique_ptr<AotCompilationResult>> aot_results,\n-      compiler.CompileAheadOfTime(std::move(hlo_module_group),\n-                                  compile_options));\n+      compiler.CompileAheadOfTime(std::move(hlo_module), compile_options));\n \n   if (aot_results.size() != 1) {\n     return Internal(\"Expected 1 AOT compilation result, got %d.\","
        },
        {
            "sha": "8084f148d4ff9aa1581fa6fea9a13d046c6b8619",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -180,12 +180,9 @@ StreamExecutorGpuCompiler::Compile(CompileOptions options,\n   const int num_partitions = hlo_module->config().num_partitions();\n   const std::string name = hlo_module->name();\n   const std::string fingerprint = hlo_module->GetFingerprint128();\n-  auto unique_module_group =\n-      std::make_unique<HloModuleGroup>(std::move(hlo_module));\n   TF_ASSIGN_OR_RETURN(\n       std::vector<std::unique_ptr<AotCompilationResult>> aot_results,\n-      gpu_compiler->CompileAheadOfTime(std::move(unique_module_group),\n-                                       aot_options));\n+      gpu_compiler->CompileAheadOfTime(std::move(hlo_module), aot_options));\n   return std::make_unique<StreamExecutorExecutable>(\n       std::move(input_options), std::move(aot_results), num_replicas,\n       num_partitions, name, fingerprint,"
        },
        {
            "sha": "9639d9dd33b7db2ea18a0a491f07e897f22fab09",
            "filename": "third_party/xla/xla/service/compile_only_service.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcompile_only_service.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcompile_only_service.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcompile_only_service.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -132,9 +132,8 @@ CompileOnlyService::CompileAheadOfTime(\n       HloModule::CreateFromProto(computation.computation, *module_config));\n   DumpHloModuleIfEnabled(*hlo_module, \"before_optimizations\");\n \n-  return compiler_->CompileAheadOfTime(\n-      std::make_unique<HloModuleGroup>(std::move(hlo_module)), options,\n-      metadata);\n+  return compiler_->CompileAheadOfTime(std::move(hlo_module), options,\n+                                       metadata);\n }\n \n }  // namespace xla"
        },
        {
            "sha": "b44ba9037d3042661fed0685f8a3dd6c5aaa6618",
            "filename": "third_party/xla/xla/service/compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -102,15 +102,14 @@ std::unique_ptr<tsl::protobuf::Message> Compiler::ComputeDefaultBackendConfig(\n // Define a default version where metadata is not used.\n absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n Compiler::CompileAheadOfTime(\n-    std::unique_ptr<HloModuleGroup> module_group,\n-    const AotCompilationOptions& options,\n+    std::unique_ptr<HloModule> hlo_module, const AotCompilationOptions& options,\n     std::unique_ptr<AotCompilationMetadata>* metadata) {\n   if (metadata != nullptr) {\n     return Unimplemented(\n         \"Populating AotCompilationMetadata is not implemented on this \"\n         \"compiler.\");\n   }\n-  return CompileAheadOfTime(std::move(module_group), options);\n+  return CompileAheadOfTime(std::move(hlo_module), options);\n }\n \n /* static */ absl::flat_hash_map<se::Platform::Id, Compiler::CompilerFactory>*"
        },
        {
            "sha": "92b61b8cea3b8e61e71d4070d013a8077a0097f7",
            "filename": "third_party/xla/xla/service/compiler.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.h?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -289,16 +289,16 @@ class Compiler {\n   virtual std::unique_ptr<tsl::protobuf::Message> ComputeDefaultBackendConfig(\n       const HloInstruction& hlo, se::StreamExecutor* executor) const;\n \n-  // Compiles the HLO module group for ahead-of-time execution.  This is\n-  // intended for use in static compilation.\n+  // Compiles the HLO module for ahead-of-time execution.  This is intended for\n+  // use in static compilation.\n   virtual absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n-  CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n+  CompileAheadOfTime(std::unique_ptr<HloModule> module,\n                      const AotCompilationOptions& options) = 0;\n \n   // Similar to CompileAheadOfTime above but AotCompilationMetadata\n   // has an argument that can be populated during compilation.\n   virtual absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n-  CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n+  CompileAheadOfTime(std::unique_ptr<HloModule> module,\n                      const AotCompilationOptions& options,\n                      std::unique_ptr<AotCompilationMetadata>* metadata);\n "
        },
        {
            "sha": "92dbd751a9201526a955b52b222d20eb832acab1",
            "filename": "third_party/xla/xla/service/cpu/cpu_aot_compiler_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compiler_test.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -92,10 +92,9 @@ ENTRY e {\n     SCOPED_TRACE(test_name);\n     TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                             ParseAndReturnVerifiedModule(hlo));\n-    auto module_group = std::make_unique<HloModuleGroup>(std::move(module));\n     TF_ASSERT_OK_AND_ASSIGN(\n         std::vector<std::unique_ptr<AotCompilationResult>> aot_results,\n-        compiler->CompileAheadOfTime(std::move(module_group), *aot_options));\n+        compiler->CompileAheadOfTime(std::move(module), *aot_options));\n \n     TF_ASSERT_OK_AND_ASSIGN(std::string serialized_aot_result,\n                             aot_results[0]->SerializeAsString());"
        },
        {
            "sha": "2fd9ff24c4eea06824df59c77feb1376b5469811",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 50,
            "changes": 66,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -2033,45 +2033,13 @@ absl::StatusOr<std::unique_ptr<Executable>> CpuCompiler::RunBackend(\n }\n \n absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n-CpuCompiler::CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n+CpuCompiler::CompileAheadOfTime(std::unique_ptr<HloModule> hlo_module,\n                                 const AotCompilationOptions& aot_options) {\n-  TF_RET_CHECK(!module_group->empty());\n-  std::vector<std::unique_ptr<HloModule>> modules =\n-      module_group->ConsumeModules();\n-\n   auto llvm_options = llvm_ir::ExtractXlaBackendExtraOptions(\n-      modules[0]->config().debug_options().xla_backend_extra_options());\n-  VlogMaxIsa(modules[0]->config().debug_options().xla_cpu_max_isa());\n+      hlo_module->config().debug_options().xla_backend_extra_options());\n+  VlogMaxIsa(hlo_module->config().debug_options().xla_cpu_max_isa());\n   llvm_ir::LLVMCommandLineOptionsLock llvm_lock(llvm_options);\n \n-  // We can pass just one llvm::TargetOptions when we compile the LLVM module,\n-  // so we bail if the configs have conflicting flags. At the moment, the only\n-  // flags that need to be consistent are for fast-math.\n-  for (const auto& fn_and_name :\n-       {std::make_pair(&DebugOptions::xla_cpu_enable_fast_math,\n-                       \"xla_cpu_enable_fast_math\"),\n-        std::make_pair(&DebugOptions::xla_cpu_fast_math_honor_infs,\n-                       \"xla_cpu_fast_math_honor_infs\"),\n-        std::make_pair(&DebugOptions::xla_cpu_fast_math_honor_nans,\n-                       \"xla_cpu_fast_math_honor_nans\")}) {\n-    // This only works because each of the method pointers above returns a\n-    // bool. Otherwise we'd have to do some template magic.\n-    const auto& field_method_ptr = fn_and_name.first;\n-    const auto& field_name = fn_and_name.second;\n-    bool first_module_val =\n-        (modules[0]->config().debug_options().*field_method_ptr)();\n-    for (int64_t i = 0; i < modules.size(); ++i) {\n-      bool cur_module_val =\n-          (modules[i]->config().debug_options().*field_method_ptr)();\n-      if (first_module_val != cur_module_val) {\n-        return InvalidArgument(\n-            \"All HLO module configs must have the same value for %s, but \"\n-            \"module 0 and %d have different values (%d vs %d).\",\n-            field_name, i, first_module_val, cur_module_val);\n-      }\n-    }\n-  }\n-\n   if (aot_options.PlatformId() != se::host::kHostPlatformId) {\n     return InvalidArgument(\"Incompatible AOT compilation platform\");\n   }\n@@ -2116,9 +2084,9 @@ CpuCompiler::CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n       break;\n   }\n   llvm::CodeGenOptLevel opt_level =\n-      IrCompiler::GetCodeGenOptLevel(modules[0]->config());\n+      IrCompiler::GetCodeGenOptLevel(hlo_module->config());\n   llvm::TargetOptions target_options =\n-      CompilerTargetOptions(modules[0]->config());\n+      CompilerTargetOptions(hlo_module->config());\n   auto target_machine_builder = [&]() {\n     return absl::WrapUnique(target->createTargetMachine(\n         triple, options.cpu_name(), options.features(), target_options,\n@@ -2129,21 +2097,19 @@ CpuCompiler::CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n       target_machine_builder();\n \n   std::vector<std::unique_ptr<AotCompilationResult>> results;\n-  for (auto& hlo_module : modules) {\n-    VLOG(1) << \"Compiling ahead-of-time: \" << hlo_module->name();\n-    if (hlo_module->has_schedule()) {\n-      continue;\n-    }\n+  VLOG(1) << \"Compiling ahead-of-time: \" << hlo_module->name();\n+  if (hlo_module->has_schedule()) {\n+    return results;\n+  }\n \n-    TF_RETURN_IF_ERROR(RunHloPasses(hlo_module.get(), /*is_aot_compile=*/true,\n-                                    target_machine.get(),\n-                                    /*dummy*/ CompileOptions{}));\n+  TF_RETURN_IF_ERROR(RunHloPasses(hlo_module.get(), /*is_aot_compile=*/true,\n+                                  target_machine.get(),\n+                                  /*dummy*/ CompileOptions{}));\n \n-    TF_ASSIGN_OR_RETURN(\n-        results.emplace_back(),\n-        CompileAheadOfTimeThunks(std::move(hlo_module), target_machine_builder,\n-                                 options, triple, pic_level, pie_level));\n-  }\n+  TF_ASSIGN_OR_RETURN(\n+      results.emplace_back(),\n+      CompileAheadOfTimeThunks(std::move(hlo_module), target_machine_builder,\n+                               options, triple, pic_level, pie_level));\n \n   VLOG(1) << \"Compilation finished\";\n   return std::move(results);"
        },
        {
            "sha": "b289b3c9b1c0ad414c89130f246c3e58e4fc980c",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.h?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -75,7 +75,7 @@ class CpuCompiler : public LLVMCompiler {\n       const CompileOptions& options) override;\n \n   absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n-  CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n+  CompileAheadOfTime(std::unique_ptr<HloModule> hlo_module,\n                      const AotCompilationOptions& options) override;\n \n   se::Platform::Id PlatformId() const override;"
        },
        {
            "sha": "20e109d1d5b9ac5a88ece1995a509efb02baeb3a",
            "filename": "third_party/xla/xla/service/cpu/vectorized_reduce_with_no_vector_registers_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fvectorized_reduce_with_no_vector_registers_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fvectorized_reduce_with_no_vector_registers_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fvectorized_reduce_with_no_vector_registers_test.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -92,7 +92,6 @@ ENTRY main {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> hlo_module,\n                           ParseAndReturnVerifiedModule(text));\n   cpu::CpuCompiler cpu_compiler;\n-  auto module_group = std::make_unique<HloModuleGroup>(std::move(hlo_module));\n \n   // Check that the GetTargetVectorRegisterByteSize is itself working.\n   TF_ASSERT_OK_AND_ASSIGN(\n@@ -120,7 +119,7 @@ ENTRY main {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<std::unique_ptr<AotCompilationResult>> aot_compilation_result,\n-      cpu_compiler.CompileAheadOfTime(std::move(module_group),\n+      cpu_compiler.CompileAheadOfTime(std::move(hlo_module),\n                                       aot_compilation_options));\n   EXPECT_EQ(aot_compilation_result.size(), 1);\n }"
        },
        {
            "sha": "6d44b7f07224c6b9cfbc8636b445573713e0f84c",
            "filename": "third_party/xla/xla/service/gpu/gpu_aot_compilation_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 7,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_test.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -64,13 +64,12 @@ ENTRY main {\n                           platform->ExecutorForDevice(0));\n \n   // Compile AOT.\n-  auto module_group = std::make_unique<HloModuleGroup>(std::move(module));\n   AotCompilationOptions aot_options(compiler->PlatformId());\n   aot_options.set_executor(stream_exec);\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<std::unique_ptr<AotCompilationResult>> aot_results,\n-      compiler->CompileAheadOfTime(std::move(module_group), aot_options));\n+      compiler->CompileAheadOfTime(std::move(module), aot_options));\n \n   // Serialize-deserialize AOT compilation result.\n   TF_ASSERT_OK_AND_ASSIGN(std::string serialized_aot_result,\n@@ -105,16 +104,14 @@ ENTRY main {\n   TF_ASSERT_OK_AND_ASSIGN(se::StreamExecutor * stream_exec,\n                           platform->ExecutorForDevice(0));\n \n-  auto module_group = std::make_unique<HloModuleGroup>(std::move(module));\n-\n   // Stream executor is not passed as an option.\n   Compiler::TargetConfig gpu_target_config(stream_exec);\n   AotCompilationOptions aot_options(compiler->PlatformId());\n   aot_options.set_target_config(gpu_target_config);\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<std::unique_ptr<AotCompilationResult>> aot_results,\n-      compiler->CompileAheadOfTime(std::move(module_group), aot_options));\n+      compiler->CompileAheadOfTime(std::move(module), aot_options));\n \n   // Serialize-deserialize AOT compilation result.\n   TF_ASSERT_OK_AND_ASSIGN(std::string serialized_aot_result,\n@@ -222,13 +219,12 @@ TEST_F(GpuAotCompilationTest, ExportAndLoadExecutableWithTriton) {\n                           platform->ExecutorForDevice(0));\n \n   // Compile AOT.\n-  auto module_group = std::make_unique<HloModuleGroup>(std::move(module));\n   AotCompilationOptions aot_options(compiler->PlatformId());\n   aot_options.set_executor(stream_exec);\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<std::unique_ptr<AotCompilationResult>> aot_results,\n-      compiler->CompileAheadOfTime(std::move(module_group), aot_options));\n+      compiler->CompileAheadOfTime(std::move(module), aot_options));\n \n   // Serialize-deserialize AOT compilation result.\n   TF_ASSERT_OK_AND_ASSIGN(std::string serialized_aot_result,"
        },
        {
            "sha": "2cad6da5639980262e073adcd7e5a95799cb40c2",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 39,
            "changes": 68,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -2771,39 +2771,30 @@ absl::StatusOr<std::unique_ptr<Executable>> GpuCompiler::RunBackend(\n }\n \n absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n-GpuCompiler::CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n+GpuCompiler::CompileAheadOfTime(std::unique_ptr<HloModule> hlo_module,\n                                 const AotCompilationOptions& options) {\n   tsl::profiler::TraceMe traceme(\"CompileAheadOfTime\");\n   // Check that we are on the platform (CUDA or ROCm) that was chosen for AOT\n   // compilation.\n   CHECK_EQ(options.PlatformId(), PlatformId());\n \n-  std::vector<std::unique_ptr<HloModule>> modules =\n-      module_group->ConsumeModules();\n-\n-  std::vector<std::unique_ptr<HloModule>> optimized_modules;\n-  optimized_modules.reserve(modules.size());\n-\n-  for (std::unique_ptr<HloModule>& module : modules) {\n-    if (!module->has_schedule()) {\n-      tsl::profiler::ScopedAnnotation annotation{[&] {\n-        return absl::StrFormat(\"XlaCompile:#module=%s,program_id=%d#\",\n-                               module->name(), module->unique_id());\n-      }};\n-      CompileOptions compile_options;\n-      compile_options.device_allocator = options.device_allocator();\n-      compile_options.target_config = options.target_config();\n-      TF_ASSIGN_OR_RETURN(\n-          std::unique_ptr<HloModule> optimized_module,\n-          RunHloPasses(std::move(module), options.executor(), compile_options));\n-      optimized_modules.push_back(std::move(optimized_module));\n-    } else {\n-      optimized_modules.push_back(std::move(module));\n-    }\n+  std::unique_ptr<HloModule> optimized_module;\n+\n+  if (!hlo_module->has_schedule()) {\n+    tsl::profiler::ScopedAnnotation annotation{[&] {\n+      return absl::StrFormat(\"XlaCompile:#module=%s,program_id=%d#\",\n+                             hlo_module->name(), hlo_module->unique_id());\n+    }};\n+    CompileOptions compile_options;\n+    compile_options.device_allocator = options.device_allocator();\n+    compile_options.target_config = options.target_config();\n+    TF_ASSIGN_OR_RETURN(optimized_module,\n+                        RunHloPasses(std::move(hlo_module), options.executor(),\n+                                     compile_options));\n+  } else {\n+    optimized_module = std::move(hlo_module);\n   }\n \n-  modules = std::move(optimized_modules);\n-\n   std::vector<std::unique_ptr<AotCompilationResult>> results;\n \n   const std::optional<Compiler::TargetConfig>& target_config =\n@@ -2812,21 +2803,20 @@ GpuCompiler::CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n   const se::DeviceDescription& gpu_device_info =\n       target_config.has_value() ? target_config->device_description\n                                 : options.executor()->GetDeviceDescription();\n-  for (const std::unique_ptr<HloModule>& module : modules) {\n-    llvm::LLVMContext llvm_context;\n-    TF_ASSIGN_OR_RETURN(\n-        CompileResultWithMetadata res,\n-        CompileToBackendResult(module.get(), &llvm_context,\n-                               {options.device_allocator()}, gpu_device_info));\n+  llvm::LLVMContext llvm_context;\n+  TF_ASSIGN_OR_RETURN(\n+      CompileResultWithMetadata res,\n+      CompileToBackendResult(optimized_module.get(), &llvm_context,\n+                             {options.device_allocator()}, gpu_device_info));\n \n-    // Create GpuThunkAotCompilationResult if thunk runtime is enabled.\n-    TF_ASSIGN_OR_RETURN(\n-        results.emplace_back(),\n-        GpuThunkAotCompilationResult::FromModule(\n-            module.get(), res.compile_module_results.buffer_assignment.get(),\n-            res.backend_result.asm_text, res.backend_result.binary,\n-            res.backend_result.dnn_compiled_graphs, pointer_size_));\n-  }\n+  // Create GpuThunkAotCompilationResult if thunk runtime is enabled.\n+  TF_ASSIGN_OR_RETURN(\n+      results.emplace_back(),\n+      GpuThunkAotCompilationResult::FromModule(\n+          optimized_module.get(),\n+          res.compile_module_results.buffer_assignment.get(),\n+          res.backend_result.asm_text, res.backend_result.binary,\n+          res.backend_result.dnn_compiled_graphs, pointer_size_));\n \n   return std::move(results);\n }"
        },
        {
            "sha": "d5ee8d6a9f369fe18dc8ac8c632bf90cf9071ff9",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -79,7 +79,7 @@ class GpuCompiler : public LLVMCompiler {\n       const CompileOptions& options) override;\n \n   absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n-  CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n+  CompileAheadOfTime(std::unique_ptr<HloModule> hlo_module,\n                      AotCompilationOptions const& options) override;\n \n   se::Platform::Id PlatformId() const override { return platform_id_; }"
        },
        {
            "sha": "ec93001ddb2f0790ee1ffc485d4a79149b759a6c",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -1041,10 +1041,9 @@ ENTRY e {\n                                               int expected_result) {\n     TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                             ParseAndReturnVerifiedModule(hlo));\n-    auto module_group = std::make_unique<HloModuleGroup>(std::move(module));\n     TF_ASSERT_OK_AND_ASSIGN(\n         std::vector<std::unique_ptr<AotCompilationResult>> aot_results,\n-        compiler->CompileAheadOfTime(std::move(module_group), aot_options));\n+        compiler->CompileAheadOfTime(std::move(module), aot_options));\n \n     TF_ASSERT_OK_AND_ASSIGN(std::string serialized_aot_result,\n                             aot_results[0]->SerializeAsString());"
        },
        {
            "sha": "d0ae6891c28af0f07f67c8dd9062f4029aec586d",
            "filename": "third_party/xla/xla/service/local_service.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Flocal_service.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Flocal_service.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flocal_service.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -138,16 +138,14 @@ LocalService::CompileAotResults(\n       se::StreamExecutor * executor,\n       execute_backend_->stream_executor(build_options.device_ordinal()));\n \n-  std::vector<std::unique_ptr<HloModuleConfig>> module_configs;\n-  module_configs.push_back(std::move(module_config));\n   // BuildAotResults uses the executors length to determine the number of\n   // cores per module, but otherwise only uses the first executor.\n   std::vector<se::StreamExecutor*> executors(build_options.num_partitions(),\n                                              executor);\n \n   return BuildAotResults(\n-      /*module_protos=*/{&computation.proto()}, std::move(module_configs),\n-      execute_backend_.get(), {executors},\n+      &computation.proto(), std::move(module_config), execute_backend_.get(),\n+      {executors},\n       Compiler::CompileOptions{build_options.device_allocator(),\n                                build_options.compile_thread_pool()},\n       build_options.run_backend_only());"
        },
        {
            "sha": "bb74f618bf0e233baf96b24b24e8d32199f796c3",
            "filename": "third_party/xla/xla/service/service.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 20,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fservice.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fservice.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fservice.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -306,28 +306,18 @@ Service::BuildExecutables(\n \n absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n Service::BuildAotResults(\n-    const std::vector<const HloModuleProto*>& module_protos,\n-    std::vector<std::unique_ptr<HloModuleConfig>> module_configs,\n-    Backend* backend, std::vector<std::vector<se::StreamExecutor*>> executors,\n+    const HloModuleProto* module_proto,\n+    std::unique_ptr<HloModuleConfig> module_config, Backend* backend,\n+    std::vector<std::vector<se::StreamExecutor*>> executors,\n     const Compiler::CompileOptions& options, bool run_backend_only) {\n   VLOG(1) << StrFormat(\"BuildAotResults on service %p\", this);\n \n-  VLOG(1) << \"Computations:\";\n-  for (const HloModuleProto* proto : module_protos) {\n-    VLOG(1) << proto->name();\n-  }\n+  VLOG(1) << \"Computation: \" << module_proto->name();\n \n-  CHECK_EQ(module_protos.size(), module_configs.size());\n-  auto module_group =\n-      std::make_unique<HloModuleGroup>(module_protos[0]->name());\n-  for (int64_t i = 0, end = module_protos.size(); i < end; ++i) {\n-    const HloModuleProto* proto = module_protos[i];\n-    const HloModuleConfig& config = *module_configs[i];\n-    TF_ASSIGN_OR_RETURN(\n-        auto module, CreateModuleFromProto(*proto, config, run_backend_only));\n-    DumpHloModuleIfEnabled(*module, kBeforeOptimizationsDumpName);\n-    module_group->push_back(std::move(module));\n-  }\n+  TF_ASSIGN_OR_RETURN(\n+      auto module,\n+      CreateModuleFromProto(*module_proto, *module_config, run_backend_only));\n+  DumpHloModuleIfEnabled(*module, kBeforeOptimizationsDumpName);\n \n   AotCompilationOptions aot_options(backend->compiler()->PlatformId());\n   aot_options.set_executor(executors[0][0]);\n@@ -336,8 +326,7 @@ Service::BuildAotResults(\n \n   TF_ASSIGN_OR_RETURN(\n       std::vector<std::unique_ptr<AotCompilationResult>> aot_results,\n-      backend->compiler()->CompileAheadOfTime(std::move(module_group),\n-                                              aot_options));\n+      backend->compiler()->CompileAheadOfTime(std::move(module), aot_options));\n   return std::move(aot_results);\n }\n "
        },
        {
            "sha": "350dbfd901839234a1c44f50196291bd3c650b78",
            "filename": "third_party/xla/xla/service/service.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fservice.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fservice%2Fservice.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fservice.h?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -306,8 +306,8 @@ class Service {\n   // AotCompilationResult(s), which can be persisted to later load Executable\n   // objects.\n   absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n-  BuildAotResults(const std::vector<const HloModuleProto*>& module_protos,\n-                  std::vector<std::unique_ptr<HloModuleConfig>> module_configs,\n+  BuildAotResults(const HloModuleProto* module_proto,\n+                  std::unique_ptr<HloModuleConfig> module_config,\n                   Backend* backend,\n                   std::vector<std::vector<se::StreamExecutor*>> executors,\n                   const Compiler::CompileOptions& options,"
        },
        {
            "sha": "b18343258d3275cb621f210303f1d9e0b7ce9020",
            "filename": "third_party/xla/xla/stream_executor/tpu/tpu_on_demand_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fstream_executor%2Ftpu%2Ftpu_on_demand_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Fstream_executor%2Ftpu%2Ftpu_on_demand_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Ftpu%2Ftpu_on_demand_compiler.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -188,7 +188,7 @@ class TpuCompiler : public Compiler {\n   // Compiles the HLO module group for ahead-of-time execution.  This is\n   // intended for use in static compilation.\n   absl::StatusOr<std::vector<std::unique_ptr<AotCompilationResult>>>\n-  CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n+  CompileAheadOfTime(std::unique_ptr<HloModule> hlo_module,\n                      const AotCompilationOptions& options) override {\n     return Unimplemented(\"This compiler does not support CompileAheadOfTime.\");\n   }"
        },
        {
            "sha": "c4a56308074b754df7a72c0cdfd5cd0aa1e698b0",
            "filename": "third_party/xla/xla/tests/codegen_test_base.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Ftests%2Fcodegen_test_base.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Ftests%2Fcodegen_test_base.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcodegen_test_base.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -37,11 +37,9 @@ absl::StatusOr<std::unique_ptr<AotCompilationResult>>\n CodegenTestBase::CompileToAotCompilationResult(\n     std::unique_ptr<HloModule> hlo_module,\n     const AotCompilationOptions& options) {\n-  auto module_group = std::make_unique<HloModuleGroup>(std::move(hlo_module));\n   TF_ASSIGN_OR_RETURN(\n       std::vector<std::unique_ptr<AotCompilationResult>> results,\n-      backend().compiler()->CompileAheadOfTime(std::move(module_group),\n-                                               options));\n+      backend().compiler()->CompileAheadOfTime(std::move(hlo_module), options));\n   return std::move(results.front());\n }\n "
        },
        {
            "sha": "627d57fa058bb6554e81817021f51915348ad631",
            "filename": "third_party/xla/xla/tools/xla_compile_lib.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Ftools%2Fxla_compile_lib.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373c1e06c44664fc13f7f39209fd11fb36925999/third_party%2Fxla%2Fxla%2Ftools%2Fxla_compile_lib.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fxla_compile_lib.cc?ref=373c1e06c44664fc13f7f39209fd11fb36925999",
            "patch": "@@ -100,8 +100,6 @@ static absl::StatusOr<std::string> CompileGpuExecutable(\n \n   TF_ASSIGN_OR_RETURN(auto gpu_compiler, Compiler::GetForPlatform(platform));\n \n-  auto module_group = std::make_unique<HloModuleGroup>(std::move(hlo_module));\n-\n   if (aot) {\n     AotCompilationOptions aot_options(platform->id());\n     aot_options.set_target_config(*target_config);\n@@ -110,14 +108,15 @@ static absl::StatusOr<std::string> CompileGpuExecutable(\n \n     TF_ASSIGN_OR_RETURN(\n         std::vector<std::unique_ptr<AotCompilationResult>> aot_results,\n-        gpu_compiler->CompileAheadOfTime(std::move(module_group), aot_options));\n+        gpu_compiler->CompileAheadOfTime(std::move(hlo_module), aot_options));\n     TF_ASSIGN_OR_RETURN(std::string compile_result,\n                         aot_results[0]->SerializeAsString());\n     *result.mutable_hlo_module() =\n         aot_results[0]->optimized_module()->ToProto();\n     return compile_result;\n   }\n \n+  auto module_group = std::make_unique<HloModuleGroup>(std::move(hlo_module));\n   Compiler::CompileOptions compile_options;\n   TF_ASSIGN_OR_RETURN(stream_executor::StreamExecutor * stream_executor,\n                       platform->ExecutorForDevice(0));"
        }
    ],
    "stats": {
        "total": 243,
        "additions": 83,
        "deletions": 160
    }
}