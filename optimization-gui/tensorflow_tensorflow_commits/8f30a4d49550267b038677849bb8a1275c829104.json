{
    "author": "tensorflower-gardener",
    "message": "Integrate LLVM at llvm/llvm-project@26362c68579d\n\nUpdates LLVM usage to match\n[26362c68579d](https://github.com/llvm/llvm-project/commit/26362c68579d)\n\nPiperOrigin-RevId: 836692850",
    "sha": "8f30a4d49550267b038677849bb8a1275c829104",
    "files": [
        {
            "sha": "e25178eecf44fa63bf718b65d58bc859a9875ecb",
            "filename": "third_party/xla/third_party/llvm/generated.patch",
            "status": "modified",
            "additions": 16,
            "deletions": 19,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f30a4d49550267b038677849bb8a1275c829104/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f30a4d49550267b038677849bb8a1275c829104/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch?ref=8f30a4d49550267b038677849bb8a1275c829104",
            "patch": "@@ -1,20 +1,17 @@\n Auto generated patch. Do not edit or delete it, even if empty.\n-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n---- a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n-+++ b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n-@@ -1563,7 +1563,6 @@\n-         \":basic\",\n-         \":config\",\n-         \":driver_options_inc_gen\",\n--        \":frontend\",\n-         \":lex\",\n-         \":options\",\n-         \":parse\",\n-@@ -1719,6 +1718,7 @@\n-         \":ast\",\n-         \":basic\",\n-         \":config\",\n-+        \":driver\",\n-         \":driver_options_inc_gen\",\n-         \":edit\",\n-         \":lex\",\n+diff -ruN --strip-trailing-cr a/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp b/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp\n+--- a/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp\n++++ b/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp\n+@@ -4095,6 +4095,12 @@\n+   llvm::SmallVector<size_t> occludedChildren;\n+   llvm::sort(\n+       indices.begin(), indices.end(), [&](const size_t a, const size_t b) {\n++        // Bail early if we are asked to look at the same index. If we do not\n++        // bail early, we can end up mistakenly adding indices to\n++        // occludedChildren. This can occur with some types of libc++ hardening.\n++        if (a == b)\n++          return false;\n++\n+         auto memberIndicesA = cast<ArrayAttr>(indexAttr[a]);\n+         auto memberIndicesB = cast<ArrayAttr>(indexAttr[b]);\n+ "
        },
        {
            "sha": "215fe72ea23a026d759edac8503179beb0e197f4",
            "filename": "third_party/xla/third_party/llvm/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f30a4d49550267b038677849bb8a1275c829104/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f30a4d49550267b038677849bb8a1275c829104/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl?ref=8f30a4d49550267b038677849bb8a1275c829104",
            "patch": "@@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n \n def repo(name):\n     \"\"\"Imports LLVM.\"\"\"\n-    LLVM_COMMIT = \"dea330b38d9c18b68219abdb52baaa72c9f1103d\"\n-    LLVM_SHA256 = \"0f00dd4e0d61e49051b09169450af0c5ca364bf7e3f015794089455ae8c8555c\"\n+    LLVM_COMMIT = \"26362c68579dd4375198aae4651b4d5f8a36c715\"\n+    LLVM_SHA256 = \"1b81809d98940d0a6d4f19ef9e0bf72cd5847b9bbed47bc3517fcf8a40d38fd9\"\n \n     tf_http_archive(\n         name = name,"
        },
        {
            "sha": "5c4c30d10c50f01220a148f181da8b7820042309",
            "filename": "third_party/xla/third_party/shardy/temporary.patch",
            "status": "modified",
            "additions": 133,
            "deletions": 340,
            "changes": 473,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f30a4d49550267b038677849bb8a1275c829104/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f30a4d49550267b038677849bb8a1275c829104/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch?ref=8f30a4d49550267b038677849bb8a1275c829104",
            "patch": "@@ -1,354 +1,147 @@\n+diff --git a/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc b/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc\n+index f8e9369..f1bece8 100644\n+--- a/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc\n++++ b/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc\n+@@ -330,8 +330,7 @@ int64_t getCommunicationCost(const ShardingProjection& shardingProjection,\n+                              OpShardingRuleAttr shardingRule,\n+                              ArrayRef<int64_t> tensorSizes,\n+                              ArrayRef<int64_t> localTensorSizes, MeshAttr mesh,\n+-                             const FactorAxesPair& factorAxesPair,\n+-                             const int64_t expandedShardingSize) {\n++                             const FactorAxesPair& factorAxesPair) {\n+   // The relative cost of collective operations.\n+   constexpr int64_t allToAllCost = 1;\n+   constexpr int64_t collectivePermuteCost = 2;\n+@@ -408,14 +407,10 @@ int64_t getCommunicationCost(const ShardingProjection& shardingProjection,\n+   // If the result contains this factor, we need\n+   // 1. all-to-all to move AX from this factor to other factors.\n+   // 2. all-gather to shrink the sharding size after the all-to-all above.\n+-  for (const auto& [localTensorSize, tensorFactorSharding] : llvm::zip_equal(\n++  for (const auto& [tensorSize, tensorFactorSharding] : llvm::zip_equal(\n+            localTensorSizes.drop_front(shardingProjection.getNumOperands()),\n+            shardingProjection.getResults())) {\n+-    // A candidate factor axes (factorAxesPair) is guaranteed to be an expansion\n+-    // of its existing sharding and `localTensorSize` has already taken into its\n+-    // existing sharding. In order to avoid double counting, it needs to shard\n+-    // further on the expanded sharding size only.\n+-    int64_t shardedTensorSize = localTensorSize / expandedShardingSize;\n++    int64_t shardedTensorSize = tensorSize / axesXSize;\n+     auto [axesA, axesB] = getShardingAxesInOtherAndThisFactor(\n+         tensorFactorSharding, factorAxesPair.factorIndex);\n+ \n+@@ -533,16 +528,9 @@ class FactorAxesCandidateBag {\n+ \n+     FactorAxesCandidate bestCandidate;\n+     for (FactorAxesCandidate& candidate : candidates) {\n+-      // NOTE: The axes on replication factors are distributed to batching\n+-      // dimensions after the common axes are found for all non-replication\n+-      // factors. The communication cost calculation does not take this into\n+-      // account yet and hence is not ready for cases that sharding rule has\n+-      // replication factors.\n+-      if (shardingRule.getNeedReplicationFactors().empty()) {\n+-        candidate.communicationCost = getCommunicationCost(\n+-            shardingProjection, shardingRule, tensorSizes, localTensorSizes,\n+-            mesh, candidate.factorAxes, candidate.shardingSize);\n+-      }\n++      candidate.communicationCost =\n++          getCommunicationCost(shardingProjection, shardingRule, tensorSizes,\n++                               localTensorSizes, mesh, candidate.factorAxes);\n+       if (isValid(candidate)) {\n+         bestCandidate = std::max(bestCandidate, candidate);\n+       }\n+diff --git a/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards/cholesky_triangular_solve.mlir b/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards/cholesky_triangular_solve.mlir\n+index 8b9401e..bb14074 100644\n+--- a/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards/cholesky_triangular_solve.mlir\n++++ b/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards/cholesky_triangular_solve.mlir\n+@@ -147,12 +147,12 @@ func.func @cholesky_cholesky_dims_shardings_can_merge(%arg0: tensor<16x8x8x8xf32\n+   return %0 :  tensor<16x8x8x8xf32>\n+ }\n+ \n++// TODO(zixuanjiang). We may want to keep 'x' due to its larger size.\n+ // CHECK-LABEL: func @cholesky_sharded_cholesky_dim_input_only_batch_dim_both_but_input_sharding_larger\n+ func.func @cholesky_sharded_cholesky_dim_input_only_batch_dim_both_but_input_sharding_larger(%arg0: tensor<8x4x8x8xf32> {sdy.sharding = #sdy.sharding<@mesh_xyz, [{\"x\"}, {}, {}, {\"z\"}]>}) -> (tensor<8x4x8x8xf32> {sdy.sharding = #sdy.sharding<@mesh_xyz, [{\"y\"}, {}, {}, {}]>}){\n+-  // CHECK-NEXT: %[[RESHARD1:.*]] = sdy.reshard %arg0 <@mesh_xyz, [{\"x\"}, {}, {}, {}]> : tensor<8x4x8x8xf32>\n+-  // CHECK-NEXT: %[[CHOLESKY:.*]] = stablehlo.cholesky %[[RESHARD1]], lower = true {sdy.sharding = #sdy.sharding_per_value<[<@mesh_xyz, [{\"x\"}, {}, {}, {}]>]>} : tensor<8x4x8x8xf32>\n+-  // CHECK-NEXT: %[[RESHARD2:.*]] = sdy.reshard %[[CHOLESKY]] <@mesh_xyz, [{\"y\"}, {}, {}, {}]> : tensor<8x4x8x8xf32>\n+-  // CHECK-NEXT: return %[[RESHARD2]] : tensor<8x4x8x8xf32>\n++  // CHECK: %[[RESHARD1:.*]] = sdy.reshard %arg0 <@mesh_xyz, [{\"y\"}, {}, {}, {}]> : tensor<8x4x8x8xf32>\n++  // CHECK-NEXT: %[[CHOLESKY:.*]] = stablehlo.cholesky %[[RESHARD1]], lower = true {sdy.sharding = #sdy.sharding_per_value<[<@mesh_xyz, [{\"y\"}, {}, {}, {}]>]>} : tensor<8x4x8x8xf32>\n++  // CHECK-NEXT: return %[[CHOLESKY]] : tensor<8x4x8x8xf32>\n+   %0 = stablehlo.cholesky %arg0, lower = true {sdy.sharding = #sdy.sharding_per_value<[<@mesh_xyz, [{\"y\"}, {}, {}, {}]>]>} : (tensor<8x4x8x8xf32>) -> tensor<8x4x8x8xf32>\n+   return %0 :  tensor<8x4x8x8xf32>\n+ }\n+diff --git a/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards/dynamic_slice_dynamic_update_slice.mlir b/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards/dynamic_slice_dynamic_update_slice.mlir\n+index 904d776..c12086a 100644\n+--- a/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards/dynamic_slice_dynamic_update_slice.mlir\n++++ b/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards/dynamic_slice_dynamic_update_slice.mlir\n+@@ -42,10 +42,10 @@ func.func @dynamic_update_slice(%arg0: tensor<32x4x8xf32> {sdy.sharding = #sdy.s\n+ \n+ // CHECK-LABEL: func @dynamic_update_slice_different_input_and_output_sharding\n+ func.func @dynamic_update_slice_different_input_and_output_sharding(%arg0: tensor<32x4x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}, {\"x\"}, {\"y\"}]>}, %arg1: tensor<32x1x2xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}, {}, {\"y\"}]>}, %arg2: tensor<i32>, %arg3: tensor<i32>, %arg4: tensor<i32>) -> (tensor<32x4x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{}, {\"y\"}, {\"x\"}]>}){\n+-  // CHECK-NEXT: %[[RESHARD0:.*]] = sdy.reshard %arg0 <@mesh, [{}, {\"y\"}, {\"x\"}]> : tensor<32x4x8xf32>\n+-  // CHECK-NEXT: %[[RESHARD1:.*]] = sdy.reshard %arg1 <@mesh, [{}, {}, {}]> : tensor<32x1x2xf32>\n+-  // CHECK-NEXT: %[[DYNAMIC_UPDATE_SLICE:.*]] = stablehlo.dynamic_update_slice %[[RESHARD0]], %[[RESHARD1]], %arg2, %arg3, %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{}, {\"y\"}, {\"x\"}]>]>} : (tensor<32x4x8xf32>, tensor<32x1x2xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x8xf32>\n+-  // CHECK-NEXT: return %[[DYNAMIC_UPDATE_SLICE]] : tensor<32x4x8xf32>\n++  // CHECK-NEXT: %[[REPLICATED_UPDATE:.*]] = sdy.reshard %arg1 <@mesh, [{}, {}, {}]> : tensor<32x1x2xf32>\n++  // CHECK-NEXT: %[[DYNAMIC_UPDATE_SLICE:.*]] = stablehlo.dynamic_update_slice %arg0, %[[REPLICATED_UPDATE]], %arg2, %arg3, %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{}, {\"x\"}, {\"y\"}]>]>} : (tensor<32x4x8xf32>, tensor<32x1x2xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x8xf32>\n++  // CHECK-NEXT: %[[RESHARD:.*]] = sdy.reshard %[[DYNAMIC_UPDATE_SLICE]] <@mesh, [{}, {\"y\"}, {\"x\"}]> : tensor<32x4x8xf32>\n++  // CHECK-NEXT: return %[[RESHARD]] : tensor<32x4x8xf32>\n+   %0 = stablehlo.dynamic_update_slice %arg0, %arg1, %arg2, %arg3, %arg4 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{}, {\"y\"}, {\"x\"}]>]>} : (tensor<32x4x8xf32>, tensor<32x1x2xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x8xf32>\n+   return %0 : tensor<32x4x8xf32>\n+ }\n diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch\n-index 2eff859..8327093 100644\n+index 8327093..e25178e 100644\n --- a/third_party/llvm/generated.patch\n +++ b/third_party/llvm/generated.patch\n-@@ -1,315 +1,20 @@\n+@@ -1,20 +1,17 @@\n  Auto generated patch. Do not edit or delete it, even if empty.\n--diff -ruN --strip-trailing-cr a/clang/test/OpenMP/parallel_default_variableCategory_codegen.cpp b/clang/test/OpenMP/parallel_default_variableCategory_codegen.cpp\n----- a/clang/test/OpenMP/parallel_default_variableCategory_codegen.cpp\n--+++ b/clang/test/OpenMP/parallel_default_variableCategory_codegen.cpp\n--@@ -1,4 +1,4 @@\n---// RUN: %clangxx -Xclang -verify -Wno-vla -fopenmp -fopenmp-version=60 -x c++ -S -emit-llvm %s -o - | FileCheck %s\n--+// RUN: %clang_cc1 -verify -fopenmp -fopenmp-version=60 -x c++ -emit-llvm %s -o - | FileCheck %s\n-- // expected-no-diagnostics\n-- #ifndef HEADER\n-- #define HEADER\n--diff -ruN --strip-trailing-cr a/libcxx/docs/ReleaseNotes/22.rst b/libcxx/docs/ReleaseNotes/22.rst\n----- a/libcxx/docs/ReleaseNotes/22.rst\n--+++ b/libcxx/docs/ReleaseNotes/22.rst\n--@@ -67,8 +67,8 @@\n--   by up to 2.5x\n-- - The performance of ``erase(iterator, iterator)`` in the unordered containers has been improved by up to 1.9x\n-- - The performance of ``map::insert_or_assign`` has been improved by up to 2x\n---- ``ofstream::write`` and ``ifstream::read`` have been optimized to pass through large reads and writes to system calls\n---  directly instead of copying them in chunks.\n--+- ``ofstream::write`` has been optimized to pass through large strings to system calls directly instead of copying them\n--+  in chunks into a buffer.\n-- - Multiple internal types have been refactored to use ``[[no_unique_address]]``, resulting in faster compile times and\n--   reduced debug information.\n-- \n--diff -ruN --strip-trailing-cr a/libcxx/include/fstream b/libcxx/include/fstream\n----- a/libcxx/include/fstream\n--+++ b/libcxx/include/fstream\n--@@ -308,25 +308,6 @@\n--     return basic_streambuf<_CharT, _Traits>::xsputn(__str, __len);\n--   }\n-- \n---  _LIBCPP_HIDE_FROM_ABI_VIRTUAL streamsize xsgetn(char_type* __str, streamsize __len) override {\n---    if (__always_noconv_) {\n---      const streamsize __n = std::min(this->egptr() - this->gptr(), __len);\n---      if (__n != 0) {\n---        traits_type::copy(__str, this->gptr(), __n);\n---        this->__gbump_ptrdiff(__n);\n---      }\n---      const streamsize __remainder    = __len - __n;\n---      const streamsize __buffer_space = this->egptr() - this->eback();\n---\n---      if (__remainder >= __buffer_space)\n---        return std::fread(__str + __n, sizeof(char_type), __remainder, __file_) + __n;\n---      else if (__remainder > 0)\n---        return basic_streambuf<_CharT, _Traits>::xsgetn(__str + __n, __remainder) + __n;\n---      return __n;\n---    }\n---    return basic_streambuf<_CharT, _Traits>::xsgetn(__str, __len);\n---  }\n---\n-- private:\n--   char* __extbuf_;\n--   const char* __extbufnext_;\n--diff -ruN --strip-trailing-cr a/libcxx/test/benchmarks/streams/fstream.bench.cpp b/libcxx/test/benchmarks/streams/fstream.bench.cpp\n----- a/libcxx/test/benchmarks/streams/fstream.bench.cpp\n--+++ b/libcxx/test/benchmarks/streams/fstream.bench.cpp\n--@@ -1,43 +0,0 @@\n---//===----------------------------------------------------------------------===//\n---//\n---// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n---// See https://llvm.org/LICENSE.txt for license information.\n---// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n---//\n---//===----------------------------------------------------------------------===//\n---\n---#include <fstream>\n---#include <vector>\n---\n---#include <benchmark/benchmark.h>\n---\n---static void bm_ofstream_write(benchmark::State& state) {\n---  std::vector<char> buffer;\n---  buffer.resize(16384);\n---\n---  std::ofstream stream(\"/dev/null\");\n---\n---  for (auto _ : state)\n---    stream.write(buffer.data(), buffer.size());\n---}\n---BENCHMARK(bm_ofstream_write);\n---\n---static void bm_ifstream_read(benchmark::State& state) {\n---  std::vector<char> buffer;\n---  buffer.resize(16384);\n---\n---  std::ofstream gen_testfile(\"testfile\");\n---  gen_testfile.write(buffer.data(), buffer.size());\n---\n---  std::ifstream stream(\"testfile\");\n---  assert(stream);\n---\n---  for (auto _ : state) {\n---    stream.read(buffer.data(), buffer.size());\n---    benchmark::DoNotOptimize(buffer);\n---    stream.seekg(0);\n---  }\n---}\n---BENCHMARK(bm_ifstream_read);\n---\n---BENCHMARK_MAIN();\n--diff -ruN --strip-trailing-cr a/libcxx/test/benchmarks/streams/ofstream.bench.cpp b/libcxx/test/benchmarks/streams/ofstream.bench.cpp\n----- a/libcxx/test/benchmarks/streams/ofstream.bench.cpp\n--+++ b/libcxx/test/benchmarks/streams/ofstream.bench.cpp\n--@@ -0,0 +1,25 @@\n--+//===----------------------------------------------------------------------===//\n--+//\n--+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n--+// See https://llvm.org/LICENSE.txt for license information.\n--+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n--+//\n--+//===----------------------------------------------------------------------===//\n--+\n--+#include <fstream>\n--+#include <vector>\n--+\n--+#include <benchmark/benchmark.h>\n--+\n--+static void bm_write(benchmark::State& state) {\n--+  std::vector<char> buffer;\n--+  buffer.resize(16384);\n--+\n--+  std::ofstream stream(\"/dev/null\");\n--+\n--+  for (auto _ : state)\n--+    stream.write(buffer.data(), buffer.size());\n--+}\n--+BENCHMARK(bm_write);\n--+\n--+BENCHMARK_MAIN();\n--diff -ruN --strip-trailing-cr a/libcxx/test/libcxx/input.output/file.streams/fstreams/filebuf/traits_mismatch.verify.cpp b/libcxx/test/libcxx/input.output/file.streams/fstreams/filebuf/traits_mismatch.verify.cpp\n----- a/libcxx/test/libcxx/input.output/file.streams/fstreams/filebuf/traits_mismatch.verify.cpp\n--+++ b/libcxx/test/libcxx/input.output/file.streams/fstreams/filebuf/traits_mismatch.verify.cpp\n--@@ -19,4 +19,4 @@\n-- \n-- std::basic_filebuf<char, std::char_traits<wchar_t> > f;\n-- // expected-error-re@*:* {{static assertion failed{{.*}}traits_type::char_type must be the same type as CharT}}\n---// expected-error@*:* 11 {{only virtual member functions can be marked 'override'}}\n--+// expected-error@*:* 10 {{only virtual member functions can be marked 'override'}}\n--diff -ruN --strip-trailing-cr a/libcxx/test/libcxx/input.output/file.streams/fstreams/traits_mismatch.verify.cpp b/libcxx/test/libcxx/input.output/file.streams/fstreams/traits_mismatch.verify.cpp\n----- a/libcxx/test/libcxx/input.output/file.streams/fstreams/traits_mismatch.verify.cpp\n--+++ b/libcxx/test/libcxx/input.output/file.streams/fstreams/traits_mismatch.verify.cpp\n--@@ -21,7 +21,7 @@\n-- // expected-error-re@*:* {{static assertion failed{{.*}}traits_type::char_type must be the same type as CharT}}\n-- // expected-error-re@*:* {{static assertion failed{{.*}}traits_type::char_type must be the same type as CharT}}\n-- \n---// expected-error@*:* 13 {{only virtual member functions can be marked 'override'}}\n--+// expected-error@*:* 12 {{only virtual member functions can be marked 'override'}}\n-- \n-- // FIXME: As of commit r324062 Clang incorrectly generates a diagnostic about mismatching\n-- // exception specifications for types which are already invalid for one reason or another.\n--diff -ruN --strip-trailing-cr a/lldb/unittests/Editline/EditlineTest.cpp b/lldb/unittests/Editline/EditlineTest.cpp\n----- a/lldb/unittests/Editline/EditlineTest.cpp\n--+++ b/lldb/unittests/Editline/EditlineTest.cpp\n--@@ -9,6 +9,8 @@\n-- #include \"lldb/Host/Config.h\"\n-- #include \"lldb/Host/File.h\"\n-- #include \"lldb/Host/HostInfo.h\"\n--+#include \"lldb/lldb-forward.h\"\n--+#include \"llvm/Testing/Support/Error.h\"\n-- \n-- #if LLDB_ENABLE_LIBEDIT\n-- \n--@@ -25,7 +27,6 @@\n-- #include \"TestingSupport/SubsystemRAII.h\"\n-- #include \"lldb/Host/Editline.h\"\n-- #include \"lldb/Host/FileSystem.h\"\n---#include \"lldb/Host/Pipe.h\"\n-- #include \"lldb/Host/PseudoTerminal.h\"\n-- #include \"lldb/Host/StreamFile.h\"\n-- #include \"lldb/Utility/Status.h\"\n--@@ -37,27 +38,6 @@\n-- const size_t TIMEOUT_MILLIS = 5000;\n-- }\n-- \n---class FilePointer {\n---public:\n---  FilePointer() = delete;\n---\n---  FilePointer(const FilePointer &) = delete;\n---\n---  FilePointer(FILE *file_p) : _file_p(file_p) {}\n---\n---  ~FilePointer() {\n---    if (_file_p != nullptr) {\n---      const int close_result = fclose(_file_p);\n---      EXPECT_EQ(0, close_result);\n---    }\n---  }\n---\n---  operator FILE *() { return _file_p; }\n---\n---private:\n---  FILE *_file_p;\n---};\n---\n-- /**\n--  Wraps an Editline class, providing a simple way to feed\n--  input (as if from the keyboard) and receive output from Editline.\n--@@ -90,44 +70,39 @@\n--   std::recursive_mutex output_mutex;\n--   std::unique_ptr<lldb_private::Editline> _editline_sp;\n-- \n---  PseudoTerminal _pty;\n---  int _pty_primary_fd = -1;\n---  int _pty_secondary_fd = -1;\n---\n---  std::unique_ptr<FilePointer> _el_secondary_file;\n--+  lldb::FileSP _el_primary_file;\n--+  lldb::FileSP _el_secondary_file;\n-- };\n-- \n---EditlineAdapter::EditlineAdapter()\n---    : _editline_sp(), _pty(), _el_secondary_file() {\n--+EditlineAdapter::EditlineAdapter() : _editline_sp(), _el_secondary_file() {\n--   lldb_private::Status error;\n--+  PseudoTerminal pty;\n-- \n--   // Open the first primary pty available.\n---  EXPECT_THAT_ERROR(_pty.OpenFirstAvailablePrimary(O_RDWR), llvm::Succeeded());\n--+  EXPECT_THAT_ERROR(pty.OpenFirstAvailablePrimary(O_RDWR), llvm::Succeeded());\n--+  // Open the corresponding secondary pty.\n--+  EXPECT_THAT_ERROR(pty.OpenSecondary(O_RDWR), llvm::Succeeded());\n-- \n--   // Grab the primary fd.  This is a file descriptor we will:\n--   // (1) write to when we want to send input to editline.\n--   // (2) read from when we want to see what editline sends back.\n---  _pty_primary_fd = _pty.GetPrimaryFileDescriptor();\n---\n---  // Open the corresponding secondary pty.\n---  EXPECT_THAT_ERROR(_pty.OpenSecondary(O_RDWR), llvm::Succeeded());\n---  _pty_secondary_fd = _pty.GetSecondaryFileDescriptor();\n---\n---  _el_secondary_file.reset(new FilePointer(fdopen(_pty_secondary_fd, \"rw\")));\n---  EXPECT_FALSE(nullptr == *_el_secondary_file);\n---  if (*_el_secondary_file == nullptr)\n---    return;\n--+  _el_primary_file.reset(\n--+      new NativeFile(pty.ReleasePrimaryFileDescriptor(),\n--+                     lldb_private::NativeFile::eOpenOptionReadWrite, true));\n--+\n--+  _el_secondary_file.reset(\n--+      new NativeFile(pty.ReleaseSecondaryFileDescriptor(),\n--+                     lldb_private::NativeFile::eOpenOptionReadWrite, true));\n-- \n--   lldb::LockableStreamFileSP output_stream_sp =\n---      std::make_shared<LockableStreamFile>(*_el_secondary_file,\n---                                           NativeFile::Unowned, output_mutex);\n--+      std::make_shared<LockableStreamFile>(_el_secondary_file, output_mutex);\n--   lldb::LockableStreamFileSP error_stream_sp =\n---      std::make_shared<LockableStreamFile>(*_el_secondary_file,\n---                                           NativeFile::Unowned, output_mutex);\n--+      std::make_shared<LockableStreamFile>(_el_secondary_file, output_mutex);\n-- \n--   // Create an Editline instance.\n--   _editline_sp.reset(new lldb_private::Editline(\n---      \"gtest editor\", *_el_secondary_file, output_stream_sp, error_stream_sp,\n--+      \"gtest editor\", _el_secondary_file->GetStream(), output_stream_sp,\n--+      error_stream_sp,\n--       /*color=*/false));\n--   _editline_sp->SetPrompt(\"> \");\n-- \n--@@ -140,7 +115,7 @@\n-- \n-- void EditlineAdapter::CloseInput() {\n--   if (_el_secondary_file != nullptr)\n---    _el_secondary_file.reset(nullptr);\n--+    _el_secondary_file->Close();\n-- }\n-- \n-- bool EditlineAdapter::SendLine(const std::string &line) {\n--@@ -148,19 +123,14 @@\n--   if (!IsValid())\n--     return false;\n-- \n--+  std::string out = line + \"\\n\";\n--+\n--   // Write the line out to the pipe connected to editline's input.\n---  ssize_t input_bytes_written =\n---      ::write(_pty_primary_fd, line.c_str(),\n---              line.length() * sizeof(std::string::value_type));\n---\n---  const char *eoln = \"\\n\";\n---  const size_t eoln_length = strlen(eoln);\n---  input_bytes_written =\n---      ::write(_pty_primary_fd, eoln, eoln_length * sizeof(char));\n---\n---  EXPECT_NE(-1, input_bytes_written) << strerror(errno);\n---  EXPECT_EQ(eoln_length * sizeof(char), size_t(input_bytes_written));\n---  return eoln_length * sizeof(char) == size_t(input_bytes_written);\n--+  size_t num_bytes = out.length() * sizeof(std::string::value_type);\n--+  EXPECT_THAT_ERROR(_el_primary_file->Write(out.c_str(), num_bytes).takeError(),\n--+                    llvm::Succeeded());\n--+  EXPECT_EQ(num_bytes, out.length() * sizeof(std::string::value_type));\n--+  return true;\n-- }\n-- \n-- bool EditlineAdapter::SendLines(const std::vector<std::string> &lines) {\n--@@ -215,7 +185,7 @@\n-- }\n-- \n-- void EditlineAdapter::ConsumeAllOutput() {\n---  FilePointer output_file(fdopen(_pty_primary_fd, \"r\"));\n--+  FILE *output_file = _el_primary_file->GetStream();\n-- \n--   int ch;\n--   while ((ch = fgetc(output_file)) != EOF) {\n--diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/AMDGPU/rewrite-vgpr-mfma-scale-to-agpr.mir b/llvm/test/CodeGen/AMDGPU/rewrite-vgpr-mfma-scale-to-agpr.mir\n----- a/llvm/test/CodeGen/AMDGPU/rewrite-vgpr-mfma-scale-to-agpr.mir\n--+++ b/llvm/test/CodeGen/AMDGPU/rewrite-vgpr-mfma-scale-to-agpr.mir\n--@@ -1,4 +1,4 @@\n---# RUN: not llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx950 -run-pass=greedy,amdgpu-rewrite-agpr-copy-mfma -verify-machineinstrs -o - %s 2>&1 | FileCheck %s\n--+# RUN: not --crash llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx950 -run-pass=greedy,amdgpu-rewrite-agpr-copy-mfma -verify-machineinstrs -o - %s 2>&1 | FileCheck %s\n-- # CHECK: Illegal virtual register for instruction\n-- # CHECK: Expected a VGPR_32 register, but got a AGPR_32 register\n--  \n-+diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n-+--- a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n-++++ b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n-+@@ -1563,7 +1563,6 @@\n-+         \":basic\",\n-+         \":config\",\n-+         \":driver_options_inc_gen\",\n-+-        \":frontend\",\n-+         \":lex\",\n-+         \":options\",\n-+         \":parse\",\n-+@@ -1719,6 +1718,7 @@\n-+         \":ast\",\n-+         \":basic\",\n-+         \":config\",\n-++        \":driver\",\n-+         \":driver_options_inc_gen\",\n-+         \":edit\",\n-+         \":lex\",\n+-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n+---- a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n+-+++ b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n+-@@ -1563,7 +1563,6 @@\n+-         \":basic\",\n+-         \":config\",\n+-         \":driver_options_inc_gen\",\n+--        \":frontend\",\n+-         \":lex\",\n+-         \":options\",\n+-         \":parse\",\n+-@@ -1719,6 +1718,7 @@\n+-         \":ast\",\n+-         \":basic\",\n+-         \":config\",\n+-+        \":driver\",\n+-         \":driver_options_inc_gen\",\n+-         \":edit\",\n+-         \":lex\",\n++diff -ruN --strip-trailing-cr a/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp b/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp\n++--- a/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp\n+++++ b/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp\n++@@ -4095,6 +4095,12 @@\n++   llvm::SmallVector<size_t> occludedChildren;\n++   llvm::sort(\n++       indices.begin(), indices.end(), [&](const size_t a, const size_t b) {\n+++        // Bail early if we are asked to look at the same index. If we do not\n+++        // bail early, we can end up mistakenly adding indices to\n+++        // occludedChildren. This can occur with some types of libc++ hardening.\n+++        if (a == b)\n+++          return false;\n+++\n++         auto memberIndicesA = cast<ArrayAttr>(indexAttr[a]);\n++         auto memberIndicesB = cast<ArrayAttr>(indexAttr[b]);\n++ \n diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl\n-index 1157959..8e6cbc9 100644\n+index 8e6cbc9..215fe72 100644\n --- a/third_party/llvm/workspace.bzl\n +++ b/third_party/llvm/workspace.bzl\n @@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n  \n  def repo(name):\n      \"\"\"Imports LLVM.\"\"\"\n--    LLVM_COMMIT = \"f2cb5d7a05bacb3e39df8dd355b2fbd16f96c856\"\n--    LLVM_SHA256 = \"57cb1ed943a6b62a62a1a239db81bf4ae93ba252022aef2d0efb8f8d8a46f404\"\n-+    LLVM_COMMIT = \"dea330b38d9c18b68219abdb52baaa72c9f1103d\"\n-+    LLVM_SHA256 = \"0f00dd4e0d61e49051b09169450af0c5ca364bf7e3f015794089455ae8c8555c\"\n+-    LLVM_COMMIT = \"dea330b38d9c18b68219abdb52baaa72c9f1103d\"\n+-    LLVM_SHA256 = \"0f00dd4e0d61e49051b09169450af0c5ca364bf7e3f015794089455ae8c8555c\"\n++    LLVM_COMMIT = \"26362c68579dd4375198aae4651b4d5f8a36c715\"\n++    LLVM_SHA256 = \"1b81809d98940d0a6d4f19ef9e0bf72cd5847b9bbed47bc3517fcf8a40d38fd9\"\n  \n      tf_http_archive(\n          name = name,"
        },
        {
            "sha": "957a83feb04acfaf133d160206fcb4536c7330ac",
            "filename": "third_party/xla/third_party/shardy/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8f30a4d49550267b038677849bb8a1275c829104/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8f30a4d49550267b038677849bb8a1275c829104/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl?ref=8f30a4d49550267b038677849bb8a1275c829104",
            "patch": "@@ -3,8 +3,8 @@\n load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n \n def repo():\n-    SHARDY_COMMIT = \"43786fc5cef24be5dedbeec7210f75fa0d1ee404\"\n-    SHARDY_SHA256 = \"49e69cd4b492629fe413a63fe0be84441c976e3616aa289bde9e7a7ca58c256c\"\n+    SHARDY_COMMIT = \"3f7332e771ff5eba89bb0e1113aceeef8116a181\"\n+    SHARDY_SHA256 = \"7535e2823590036ee898324a0d360e2bbd8dd741cb383f84b089c56d66b0b562\"\n \n     tf_http_archive(\n         name = \"shardy\","
        }
    ],
    "stats": {
        "total": 516,
        "additions": 153,
        "deletions": 363
    }
}