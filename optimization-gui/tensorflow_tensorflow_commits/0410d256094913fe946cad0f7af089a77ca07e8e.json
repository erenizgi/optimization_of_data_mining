{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 828882648",
    "sha": "0410d256094913fe946cad0f7af089a77ca07e8e",
    "files": [
        {
            "sha": "a9ebb6f4c3559d49cb6c2698a5b39602086b719e",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device.cc?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -242,7 +242,7 @@ absl::Status PluggableDevice::Init(const SessionOptions& options) {\n   // callback instead of GPU environment variables: TF_GPU_THREAD_MODE,\n   // TF_GPU_THREAD_COUNT, TF_FORCE_GPU_ALLOC_GROWTH,\n   // TF_ENABLE_GPU_GARBAGE_COLLECTION, and TF_GPU_HOST_MEM_LIMIT_IN_MB.\n-  string device_thread_mode;\n+  std::string device_thread_mode;\n   TF_RETURN_IF_ERROR(ReadStringFromEnvVar(\"TF_GPU_THREAD_MODE\", \"global\",\n                                           &device_thread_mode));\n   device_thread_mode = absl::AsciiStrToLower(device_thread_mode);\n@@ -256,19 +256,19 @@ absl::Status PluggableDevice::Init(const SessionOptions& options) {\n       thread_pool_ = std::make_unique<thread::ThreadPool>(\n           options.env, ThreadOptions(),\n           absl::StrCat(\"gpu_private_\", tf_device_id_.value()),\n-          static_cast<int32>(device_thread_count),\n+          static_cast<int32_t>(device_thread_count),\n           !options.config.experimental().disable_thread_spinning(),\n           /*allocator=*/nullptr);\n       set_tensorflow_device_thread_pool(thread_pool_.get());\n     } else if (device_thread_mode == \"gpu_shared\") {\n       static thread::ThreadPool* thread_pool = new thread::ThreadPool(\n           options.env, ThreadOptions(), \"gpu_shared\",\n-          static_cast<int32>(device_thread_count),\n+          static_cast<int32_t>(device_thread_count),\n           !options.config.experimental().disable_thread_spinning(),\n           /*allocator=*/nullptr);\n       set_tensorflow_device_thread_pool(thread_pool);\n     } else {\n-      string error_message =\n+      std::string error_message =\n           absl::StrCat(\"Invalid gpu_thread_mode: \", device_thread_mode);\n       LOG(WARNING) << error_message;\n       return errors::InvalidArgument(error_message);\n@@ -293,8 +293,8 @@ Allocator* PluggableDevice::GetAllocator(AllocatorAttributes attr) {\n   }\n }\n \n-string PluggableDevice::ComputeOpKernelDebugString(const OpKernel& op_kernel,\n-                                                   const int stream_id) {\n+std::string PluggableDevice::ComputeOpKernelDebugString(\n+    const OpKernel& op_kernel, const int stream_id) {\n   return strings::StrCat(op_kernel.name(), \" op \", op_kernel.type_string(),\n                          \" on \", platform_name_, tf_device_id_.value(),\n                          \" stream[\", stream_id, \"]\");"
        },
        {
            "sha": "9ccdc04192e071a6d9f270fc261c7058cf0fe458",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device.h?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -48,9 +48,9 @@ namespace tensorflow {\n class PluggableDevice : public LocalDevice {\n  public:\n   PluggableDevice(const SessionOptions& options, const std::string& name,\n-                  const string& device_type, const string& platform_name,\n-                  Bytes memory_limit, const DeviceLocality& locality,\n-                  TfDeviceId tf_device_id,\n+                  const std::string& device_type,\n+                  const std::string& platform_name, Bytes memory_limit,\n+                  const DeviceLocality& locality, TfDeviceId tf_device_id,\n                   const std::string& physical_device_desc,\n                   Allocator* device_allocator, Allocator* cpu_allocator,\n                   bool sync_every_op);\n@@ -99,7 +99,7 @@ class PluggableDevice : public LocalDevice {\n   // TODO(penpornk): Investigate renaming `GpuDeviceInfo` to `DeviceInfo`.\n   DeviceBase::AcceleratorDeviceInfo* pluggable_device_info_ = nullptr;\n   TfDeviceId tf_device_id_;\n-  const string platform_name_;\n+  const std::string platform_name_;\n   const bool sync_every_op_ = false;\n   EventMgr* em_ = nullptr;\n   std::unique_ptr<thread::ThreadPool> thread_pool_;"
        },
        {
            "sha": "ac2488d0b57664a8d9fc42eae16f9c99a1f8f934",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_bfc_allocator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_bfc_allocator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_bfc_allocator.cc?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -94,14 +94,14 @@ bool PluggableDeviceBFCAllocator::GetGarbageCollectionValue() {\n }\n \n PluggableDeviceBFCAllocator::PluggableDeviceBFCAllocator(\n-    tsl::SubAllocator* sub_allocator, size_t total_memory, const string& name,\n-    bool force_memory_growth_requested)\n+    tsl::SubAllocator* sub_allocator, size_t total_memory,\n+    const std::string& name, bool force_memory_growth_requested)\n     : PluggableDeviceBFCAllocator(sub_allocator, total_memory, GPUOptions(),\n                                   name, force_memory_growth_requested) {}\n \n PluggableDeviceBFCAllocator::PluggableDeviceBFCAllocator(\n     tsl::SubAllocator* sub_allocator, size_t total_memory,\n-    const GPUOptions& gpu_options, const string& name,\n+    const GPUOptions& gpu_options, const std::string& name,\n     bool force_memory_growth_requested)\n     : BFCAllocator(absl::WrapUnique(sub_allocator), total_memory, name, [&] {\n         BFCAllocator::Options o;"
        },
        {
            "sha": "9e87b2612343a6f6eb082edf25e71de88a85b03c",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.h",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_bfc_allocator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_bfc_allocator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_bfc_allocator.h?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -30,11 +30,12 @@ namespace tensorflow {\n class PluggableDeviceBFCAllocator : public BFCAllocator {\n  public:\n   PluggableDeviceBFCAllocator(tsl::SubAllocator* sub_allocator,\n-                              size_t total_memory, const string& name,\n+                              size_t total_memory, const std::string& name,\n                               bool force_memory_growth_requested);\n   PluggableDeviceBFCAllocator(tsl::SubAllocator* sub_allocator,\n                               size_t total_memory,\n-                              const GPUOptions& gpu_options, const string& name,\n+                              const GPUOptions& gpu_options,\n+                              const std::string& name,\n                               bool force_memory_growth_requested);\n   ~PluggableDeviceBFCAllocator() override = default;\n "
        },
        {
            "sha": "855e796ee7903dcfab7ffe73c9f2f323286e5aab",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_factory.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_factory.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_factory.cc?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -82,7 +82,7 @@ int64_t MinSystemMemory(int64_t available_memory) {\n // Get the memory limit for the virtual device being created on PluggableDevice\n // with 'platform_device_id', when that virtual device is the only\n // virtual device being created on that PluggableDevice.\n-absl::Status SingleVirtualDeviceMemoryLimit(const string& platform_name,\n+absl::Status SingleVirtualDeviceMemoryLimit(const std::string& platform_name,\n                                             const GPUOptions& device_options,\n                                             PlatformDeviceId platform_device_id,\n                                             int64_t* memory_limit) {\n@@ -119,18 +119,18 @@ absl::Status SingleVirtualDeviceMemoryLimit(const string& platform_name,\n }\n }  // namespace\n \n-PluggableDeviceFactory::PluggableDeviceFactory(const string& device_type,\n-                                               const string& platform_name)\n+PluggableDeviceFactory::PluggableDeviceFactory(const std::string& device_type,\n+                                               const std::string& platform_name)\n     : device_type_(device_type), platform_name_(platform_name) {}\n \n absl::Status PluggableDeviceFactory::ListPhysicalDevices(\n-    std::vector<string>* devices) {\n+    std::vector<std::string>* devices) {\n   TF_RETURN_IF_ERROR(ValidatePluggableDeviceMachineManager(platform_name_));\n   se::Platform* platform = PluggableDeviceMachineManager(platform_name_);\n \n   int device_count = platform->VisibleDeviceCount();\n   for (int i = 0; i < device_count; ++i) {\n-    const string device_name =\n+    const std::string device_name =\n         absl::StrCat(\"/physical_device:\", device_type_, \":\", i);\n     devices->push_back(device_name);\n   }\n@@ -139,7 +139,7 @@ absl::Status PluggableDeviceFactory::ListPhysicalDevices(\n }\n \n absl::Status PluggableDeviceFactory::GetDeviceDetails(\n-    int device_index, std::unordered_map<string, string>* details) {\n+    int device_index, std::unordered_map<std::string, std::string>* details) {\n   TF_RETURN_IF_ERROR(ValidatePluggableDeviceMachineManager(platform_name_));\n   se::Platform* platform = PluggableDeviceMachineManager(platform_name_);\n   if (platform == nullptr) {\n@@ -163,7 +163,7 @@ absl::Status PluggableDeviceFactory::GetDeviceDetails(\n }\n \n absl::Status PluggableDeviceFactory::CreateDevices(\n-    const SessionOptions& options, const string& name_prefix,\n+    const SessionOptions& options, const std::string& name_prefix,\n     std::vector<std::unique_ptr<Device>>* devices) {\n   TF_RETURN_IF_ERROR(ValidatePluggableDeviceMachineManager(platform_name_));\n   se::Platform* platform = PluggableDeviceMachineManager(platform_name_);\n@@ -214,20 +214,20 @@ absl::Status PluggableDeviceFactory::CreateDevices(\n   return absl::OkStatus();\n }\n \n-static string GetShortDeviceDescription(PlatformDeviceId platform_device_id,\n-                                        const se::DeviceDescription& desc) {\n+static std::string GetShortDeviceDescription(\n+    PlatformDeviceId platform_device_id, const se::DeviceDescription& desc) {\n   return strings::StrCat(\"device: \", platform_device_id.value(),\n                          \", name: \", desc.name(),\n                          \", pci bus id: \", desc.pci_bus_id());\n }\n \n absl::Status PluggableDeviceFactory::CreatePluggableDevice(\n-    const SessionOptions& options, const string& name_prefix,\n+    const SessionOptions& options, const std::string& name_prefix,\n     TfDeviceId tf_device_id, int64_t memory_limit,\n     const DeviceLocality& dev_locality,\n     std::vector<std::unique_ptr<Device>>* devices) {\n   DCHECK_GE(tf_device_id.value(), 0);\n-  const string device_name = strings::StrCat(\n+  const std::string device_name = strings::StrCat(\n       name_prefix, \"/device:\", device_type_, \":\", tf_device_id.value());\n \n   se::Platform* platform = PluggableDeviceMachineManager(platform_name_);"
        },
        {
            "sha": "92a145080a0ba4b1be15e253be06ab449973df8d",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.h",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_factory.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_factory.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_factory.h?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -34,14 +34,15 @@ limitations under the License.\n namespace tensorflow {\n class PluggableDeviceFactory : public DeviceFactory {\n  public:\n-  PluggableDeviceFactory(const string& device_type,\n-                         const string& platform_name);\n-  absl::Status ListPhysicalDevices(std::vector<string>* devices) override;\n+  PluggableDeviceFactory(const std::string& device_type,\n+                         const std::string& platform_name);\n+  absl::Status ListPhysicalDevices(std::vector<std::string>* devices) override;\n   absl::Status CreateDevices(\n       const SessionOptions& options, const std::string& name_prefix,\n       std::vector<std::unique_ptr<Device>>* devices) override;\n   absl::Status GetDeviceDetails(\n-      int device_index, std::unordered_map<string, string>* details) override;\n+      int device_index,\n+      std::unordered_map<std::string, std::string>* details) override;\n \n  private:\n   // Populates *device_localities with the DeviceLocality descriptor for\n@@ -57,8 +58,8 @@ class PluggableDeviceFactory : public DeviceFactory {\n       const DeviceLocality& dev_locality,\n       std::vector<std::unique_ptr<Device>>* devices);\n \n-  const string device_type_;\n-  const string platform_name_;\n+  const std::string device_type_;\n+  const std::string platform_name_;\n };\n \n }  // namespace tensorflow"
        },
        {
            "sha": "696248aba12122ae0efc48d70160621b65f39463",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device_init.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_init.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_init.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_init.cc?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -25,11 +25,11 @@ limitations under the License.\n namespace tensorflow {\n \n absl::Status ValidatePluggableDeviceMachineManager(\n-    const string& platform_name) {\n+    const std::string& platform_name) {\n   return se::PlatformManager::PlatformWithName(platform_name).status();\n }\n \n-se::Platform* PluggableDeviceMachineManager(const string& platform_name) {\n+se::Platform* PluggableDeviceMachineManager(const std::string& platform_name) {\n   auto result = se::PlatformManager::PlatformWithName(platform_name);\n   if (!result.ok()) {\n     LOG(FATAL) << \"Could not find platform with name \"  // Crash OK"
        },
        {
            "sha": "6d385ac31c435d8c559751699a306a64259fec49",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device_init.h",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_init.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_init.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_init.h?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -30,15 +30,16 @@ namespace tensorflow {\n \n // Initializes the PluggableDevice platform and returns OK if the\n // PluggableDevice platform could be initialized.\n-absl::Status ValidatePluggableDeviceMachineManager(const string& platform_name);\n+absl::Status ValidatePluggableDeviceMachineManager(\n+    const std::string& platform_name);\n \n // Returns the PluggableDevice machine manager singleton, creating it and\n // initializing the PluggableDevices on the machine if needed the first time it\n // is called.  Must only be called when there is a valid PluggableDevice\n // environment in the process (e.g., ValidatePluggableDeviceMachineManager()\n // returns OK).\n stream_executor::Platform* PluggableDeviceMachineManager(\n-    const string& platform_name);\n+    const std::string& platform_name);\n \n }  // namespace tensorflow\n "
        },
        {
            "sha": "d348c678a15ea3e613778ddd23519fbe158ffe6d",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device_plugin_init.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_plugin_init.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_plugin_init.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_plugin_init.cc?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -49,7 +49,7 @@ static absl::Status InitDeviceModule(stream_executor::SEInitPluginFn init_fn) {\n     return absl::OkStatus();\n   }\n \n-  string device_type, platform_name;\n+  std::string device_type, platform_name;\n   TF_RETURN_IF_ERROR(stream_executor::InitStreamExecutorPlugin(\n       init_fn, &device_type, &platform_name));\n "
        },
        {
            "sha": "01f6aa0e97bb0097a8f8b8dc246d38baca290fb8",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device_process_state.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_process_state.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_process_state.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_process_state.cc?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -57,9 +57,9 @@ limitations under the License.\n namespace tensorflow {\n \n /*static*/ PluggableDeviceProcessState* PluggableDeviceProcessState::singleton(\n-    const string& device_type, const string& platform_name) {\n+    const std::string& device_type, const std::string& platform_name) {\n   using ProcessStateMap =\n-      std::unordered_map<string, PluggableDeviceProcessState*>;\n+      std::unordered_map<std::string, PluggableDeviceProcessState*>;\n   static ProcessStateMap* process_state_map = new ProcessStateMap;\n   auto iter = process_state_map->find(platform_name);\n   if (iter != process_state_map->end()) {\n@@ -71,7 +71,7 @@ namespace tensorflow {\n }\n \n PluggableDeviceProcessState::PluggableDeviceProcessState(\n-    const string& device_type, const string& platform_name)\n+    const std::string& device_type, const std::string& platform_name)\n     : pluggable_device_enabled_(false),\n       device_type_(device_type),\n       platform_name_(platform_name) {\n@@ -93,7 +93,7 @@ int PluggableDeviceProcessState::BusIdForPluggableDevice(\n Allocator* PluggableDeviceProcessState::GetPluggableDeviceAllocator(\n     const GPUOptions& options, TfDeviceId tf_device_id, size_t total_bytes) {\n   DCHECK(process_state_);\n-  const string& allocator_type = options.allocator_type();\n+  const std::string& allocator_type = options.allocator_type();\n   se::Platform* platform = PluggableDeviceMachineManager(platform_name_);\n   mutex_lock lock(mu_);\n   tsl::CheckValidTfDeviceId(DeviceType(device_type_),"
        },
        {
            "sha": "6afb0daa77a2da9be47fd74cd0f99f77f74787ce",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device_process_state.h",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_process_state.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_process_state.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_process_state.h?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -43,8 +43,8 @@ class PluggableDeviceProcessState {\n  public:\n   // Singleton that manages each platform's per-process state. e.g. allocation\n   // of shared resource.\n-  static PluggableDeviceProcessState* singleton(const string& device_type,\n-                                                const string& platform_name);\n+  static PluggableDeviceProcessState* singleton(\n+      const std::string& device_type, const std::string& platform_name);\n \n   // Query whether any PluggableDevice has been created so far.\n   // Disable thread safety analysis since a race is benign here.\n@@ -89,8 +89,8 @@ class PluggableDeviceProcessState {\n  protected:\n   // PluggableDeviceProcessState is a singleton that should not normally be\n   // deleted except at process shutdown.\n-  PluggableDeviceProcessState(const string& device_type,\n-                              const string& platform_name);\n+  PluggableDeviceProcessState(const std::string& device_type,\n+                              const std::string& platform_name);\n   virtual ~PluggableDeviceProcessState() = default;\n \n   ProcessState::MDMap* mem_desc_map() {\n@@ -101,8 +101,8 @@ class PluggableDeviceProcessState {\n   static PluggableDeviceProcessState* instance_;\n   ProcessState* process_state_;  // Not owned.\n   bool pluggable_device_enabled_;\n-  const string device_type_;\n-  const string platform_name_;\n+  const std::string device_type_;\n+  const std::string platform_name_;\n   mutex mu_;\n \n   struct AllocatorParts {"
        },
        {
            "sha": "b7e9424982b22a2989803e120334cc1b173aae27",
            "filename": "tensorflow/core/common_runtime/pluggable_device/pluggable_device_simple_allocator.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_simple_allocator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0410d256094913fe946cad0f7af089a77ca07e8e/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_simple_allocator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fpluggable_device%2Fpluggable_device_simple_allocator.h?ref=0410d256094913fe946cad0f7af089a77ca07e8e",
            "patch": "@@ -35,7 +35,7 @@ class PluggableDeviceSimpleAllocator : public Allocator {\n   void DeallocateRaw(void* ptr) override;\n \n   bool TracksAllocationSizes() const override { return false; }\n-  string Name() override { return \"Simple allocator\"; }\n+  std::string Name() override { return \"Simple allocator\"; }\n   std::optional<AllocatorStats> GetStats() override;\n \n   AllocatorMemoryType GetMemoryType() const override {"
        }
    ],
    "stats": {
        "total": 99,
        "additions": 51,
        "deletions": 48
    }
}