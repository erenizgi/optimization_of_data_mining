{
    "author": "lukebaumann",
    "message": "Implement IFRT Proxy support for ReshardArrays.\n\nThis change adds the ReshardArrays RPC to the IFRT Proxy client and server, allowing arrays to be reshared via the proxy.\n\nPiperOrigin-RevId: 850557902",
    "sha": "e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
    "files": [
        {
            "sha": "84ed8f390d70c12ad3dc38146f73d02c8c79e19c",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2FBUILD?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -184,6 +184,7 @@ cc_library(\n         \"//xla/python/pjrt_ifrt:pjrt_attribute_map_util\",\n         \"//xla/tsl/concurrency:future\",\n         \"//xla/tsl/concurrency:ref_count\",\n+        \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n@@ -292,6 +293,7 @@ cc_library(\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/synchronization\",\n         \"@com_google_absl//absl/types:span\",\n+        \"@com_google_protobuf//:protobuf_lite\",\n         \"@llvm-project//llvm:Support\",\n         \"@local_tsl//tsl/profiler/lib:traceme\",\n     ],"
        },
        {
            "sha": "d5d45997ed1d565caedc28b4ede7b5a6f27d1eb3",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/array.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Farray.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Farray.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Farray.cc?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -39,6 +39,7 @@\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"llvm/Support/Casting.h\"\n+#include \"google/protobuf/repeated_field.h\"\n #include \"xla/pjrt/pjrt_layout.h\"\n #include \"xla/python/ifrt/array.h\"\n #include \"xla/python/ifrt/array_spec.h\"\n@@ -698,6 +699,24 @@ absl::StatusOr<std::vector<xla::ifrt::ArrayRef>> Array::RemapArrays(\n   return result;\n }\n \n+absl::StatusOr<::google::protobuf::RepeatedField<uint64_t>> Array::GetHandles(\n+    absl::Span<xla::ifrt::ArrayRef> arrays, ArrayCopySemantics semantics) {\n+  ::google::protobuf::RepeatedField<uint64_t> handles;\n+  handles.Reserve(arrays.size());\n+  for (const auto& array : arrays) {\n+    if (auto* proxy_array =\n+            llvm::dyn_cast<xla::ifrt::proxy::Array>(array.get())) {\n+      TF_ASSIGN_OR_RETURN(ArrayHandle handle,\n+                          proxy_array->GetHandle(semantics));\n+      handles.Add(handle.handle);\n+    } else {\n+      return absl::InvalidArgumentError(\n+          \"Operation only supports arrays created via IFRT Proxy client\");\n+    }\n+  }\n+  return handles;\n+}\n+\n absl::StatusOr<std::vector<xla::ifrt::ArrayRef>>\n Array::DisassembleIntoSingleDeviceArrays(\n     ArrayCopySemantics array_copy_semantics,"
        },
        {
            "sha": "c246b1901fb9d66d631a9d31129ff96f23a5bf62",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/array.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Farray.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Farray.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Farray.h?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -32,6 +32,7 @@\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"llvm/Support/ExtensibleRTTI.h\"\n+#include \"google/protobuf/repeated_field.h\"\n #include \"xla/pjrt/pjrt_layout.h\"\n #include \"xla/python/ifrt/array.h\"\n #include \"xla/python/ifrt/array_spec.h\"\n@@ -96,6 +97,10 @@ class Array final : public llvm::RTTIExtends<Array, xla::ifrt::Array> {\n       const RemapPlan& plan, absl::Span<xla::ifrt::ArrayRef> arrays,\n       ArrayCopySemantics semantics);\n \n+  // Gets handles from an array span.\n+  static absl::StatusOr<::google::protobuf::RepeatedField<uint64_t>> GetHandles(\n+      absl::Span<xla::ifrt::ArrayRef> arrays, ArrayCopySemantics semantics);\n+\n   // Destructs the array associated with the given handle. The corresponding\n   // array becomes unusable afterwards.\n   static void Destruct(RpcHelper* rpc_helper, ArrayHandle handle);"
        },
        {
            "sha": "03dc6dfe7647497b31c0e0a7f47de8541ec167e5",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/client.cc",
            "status": "modified",
            "additions": 48,
            "deletions": 11,
            "changes": 59,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient.cc?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -31,6 +31,7 @@\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"llvm/Support/Casting.h\"\n@@ -59,6 +60,7 @@\n #include \"xla/python/pjrt_ifrt/pjrt_attribute_map_util.h\"\n #include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n+#include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/xla_data.pb.h\"\n #include \"tsl/platform/casts.h\"\n@@ -304,17 +306,8 @@ absl::StatusOr<std::vector<xla::ifrt::ArrayRef>> Client::CopyArrays(\n   }\n \n   auto req = std::make_unique<CopyArraysRequest>();\n-  for (const auto& array : arrays) {\n-    if (auto* proxy_array =\n-            llvm::dyn_cast<xla::ifrt::proxy::Array>(array.get())) {\n-      TF_ASSIGN_OR_RETURN(ArrayHandle handle,\n-                          proxy_array->GetHandle(semantics));\n-      req->add_array_handles(handle.handle);\n-    } else {\n-      return absl::InvalidArgumentError(\n-          \"CopyArrays only supports arrays created via IFRT Proxy client\");\n-    }\n-  }\n+  TF_ASSIGN_OR_RETURN(*req->mutable_array_handles(),\n+                      Array::GetHandles(arrays, semantics));\n   if (devices.has_value()) {\n     for (auto* const device : (*devices)->devices()) {\n       req->add_device_ids(device->Id().value());\n@@ -375,6 +368,50 @@ absl::StatusOr<std::vector<xla::ifrt::ArrayRef>> Client::RemapArrays(\n   return Array::RemapArrays(this, rpc_helper_, plan, arrays, semantics);\n }\n \n+absl::StatusOr<std::vector<xla::ifrt::ArrayRef>> Client::ReshardArrays(\n+    absl::Span<ArrayRef> arrays, absl::Span<const ArraySpec> specs,\n+    ArrayCopySemantics semantics) {\n+  if (arrays.size() != specs.size()) {\n+    return absl::InvalidArgumentError(absl::StrCat(\n+        \"ReshardArrays requires arrays and specs to have same size, but got \",\n+        arrays.size(), \" vs \", specs.size()));\n+  }\n+\n+  auto req = std::make_unique<ReshardArraysRequest>();\n+  TF_ASSIGN_OR_RETURN(*req->mutable_array_handles(),\n+                      Array::GetHandles(arrays, semantics));\n+  for (const auto& spec : specs) {\n+    TF_RETURN_IF_ERROR(spec.ToProto(*req->add_array_specs(),\n+                                    rpc_helper_->ifrt_serdes_version()));\n+  }\n+  req->set_copy_semantics(ToArrayCopySemanticsProto(semantics));\n+\n+  auto result_handles = std::make_shared<std::vector<uint64_t>>();\n+  result_handles->reserve(arrays.size());\n+  for ([[maybe_unused]] const auto& array : arrays) {\n+    result_handles->push_back(rpc_helper_->NextHandle());\n+    req->add_result_handles(result_handles->back());\n+  }\n+  rpc_helper_->ReshardArrays(std::move(req))\n+      .OnReady([result_handles](\n+                   absl::StatusOr<std::shared_ptr<ReshardArraysResponse>> r) {\n+        if (r.ok()) {\n+          for (int i = 0; i < result_handles->size(); ++i) {\n+            CHECK_EQ((*r)->array_handles(i), (*result_handles)[i]);\n+          }\n+        }\n+      });\n+\n+  std::vector<xla::ifrt::ArrayRef> new_arrays;\n+  new_arrays.reserve(arrays.size());\n+  for (int i = 0; i < result_handles->size(); ++i) {\n+    new_arrays.push_back(tsl::MakeRef<Array>(\n+        this, rpc_helper_, arrays[i]->dtype(), arrays[i]->shape(),\n+        specs[i].sharding, ArrayHandle{(*result_handles)[i]}, specs[i].layout));\n+  }\n+  return new_arrays;\n+}\n+\n tsl::Future<> Client::GetReadyFuture(\n     absl::Span<const xla::ifrt::ValueRef> values) {\n   tsl::profiler::TraceMe traceme_ifrt_entrypoint([n_values = values.size()]() {"
        },
        {
            "sha": "dbf005c38af91dd807ce8366e514d181a7b9055b",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/client.h",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient.h?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -98,10 +98,7 @@ class Client final : public llvm::RTTIExtends<Client, xla::ifrt::Client> {\n \n   absl::StatusOr<std::vector<xla::ifrt::ArrayRef>> ReshardArrays(\n       absl::Span<ArrayRef> arrays, absl::Span<const ArraySpec> specs,\n-      ArrayCopySemantics semantics) override {\n-    return absl::UnimplementedError(\n-        \"ReshardArrays is not supported for the IFRT proxy client.\");\n-  }\n+      ArrayCopySemantics semantics) override;\n \n   tsl::Future<> GetReadyFuture(absl::Span<const ValueRef> values) override;\n "
        },
        {
            "sha": "b181d3b7e2bf335c4980c329d0fe9fc116f3e4c9",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/client_test.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient_test.cc?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -31,6 +31,7 @@\n #include \"xla/layout_util.h\"\n #include \"xla/pjrt/pjrt_layout.h\"\n #include \"xla/python/ifrt/array.h\"\n+#include \"xla/python/ifrt/array_spec.h\"\n #include \"xla/python/ifrt/attribute_map.h\"\n #include \"xla/python/ifrt/device.h\"\n #include \"xla/python/ifrt/device_list.h\"\n@@ -465,6 +466,37 @@ TEST_P(ClientTest, GetDefaultDeviceAssignmentFailure) {\n               Not(absl_testing::IsOk()));\n }\n \n+TEST_P(ClientTest, ReshardArraysSuccess) {\n+  std::shared_ptr<xla::ifrt::SingleDeviceSharding> sharding =\n+      xla::ifrt::SingleDeviceSharding::Create(device_, xla::ifrt::MemoryKind());\n+  auto array = tsl::MakeRef<Array>(client_.get(), rpc_helper_,\n+                                   DType(DType::kF64), Shape({1, 2, 3}),\n+                                   sharding, ArrayHandle{1234}, layout_1_);\n+\n+  IfrtResponse response;\n+  response.mutable_reshard_arrays_response()->add_array_handles(1);\n+\n+  EXPECT_CALL(*session_,\n+              Enqueue(IfrtRequestOfType(IfrtRequest::kReshardArraysRequest)))\n+      .WillOnce(MockClientSessionReturnResponse(response));\n+  EXPECT_CALL(*session_,\n+              Enqueue(IfrtRequestOfType(IfrtRequest::kDestructArrayRequest)))\n+      .WillRepeatedly(MockClientSessionReturnResponse(IfrtResponse()));\n+\n+  std::vector<tsl::RCReference<xla::ifrt::Array>> arrays = {array};\n+  std::vector<xla::ifrt::ArraySpec> specs;\n+  specs.push_back({array->dtype(), array->shape(), sharding, layout_2_});\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto reshared_arrays,\n+      client_->ReshardArrays(absl::MakeSpan(arrays), absl::MakeSpan(specs),\n+                             ArrayCopySemantics::kAlwaysCopy));\n+  ASSERT_THAT(reshared_arrays, SizeIs(1));\n+  TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<const xla::PjRtLayout> layout,\n+                          reshared_arrays[0]->pjrt_layout());\n+  EXPECT_EQ(layout->ToString(), layout_2_->ToString());\n+}\n+\n INSTANTIATE_TEST_SUITE_P(\n     ClientTestWithAllVersions, ClientTest,\n     testing::Range(kClientMinVersion, kClientMaxVersion + 1),"
        },
        {
            "sha": "ca4127f87476cd2147848d3758f34317a15304b7",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/rpc_helper.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Frpc_helper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Frpc_helper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Frpc_helper.cc?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -462,6 +462,7 @@ RPC(MakeErrorArrays, make_error_arrays);\n RPC(AssembleArrayFromSingleDeviceArrays,\n     assemble_array_from_single_device_arrays);\n RPC(RemapArrays, remap_arrays);\n+RPC(ReshardArrays, reshard_arrays);\n RPC(DisassembleIntoSingleDeviceArrays, disassemble_into_single_device_arrays);\n RPC(CopyToHostBuffer, copy_to_host_buffer);\n RPC(IsArrayDeleted, is_array_deleted);"
        },
        {
            "sha": "df40e4c715305ccbad9c08d444d34c984ff9a188",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/rpc_helper.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Frpc_helper.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Frpc_helper.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Frpc_helper.h?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -118,6 +118,8 @@ class RpcHelper {\n       std::unique_ptr<AssembleArrayFromSingleDeviceArraysRequest> req);\n   ResponseFuture<RemapArraysResponse> RemapArrays(\n       std::unique_ptr<RemapArraysRequest> req);\n+  ResponseFuture<ReshardArraysResponse> ReshardArrays(\n+      std::unique_ptr<ReshardArraysRequest> req);\n   ResponseFuture<DisassembleIntoSingleDeviceArraysResponse>\n   DisassembleIntoSingleDeviceArrays(\n       std::unique_ptr<DisassembleIntoSingleDeviceArraysRequest> req);"
        },
        {
            "sha": "3cefdba60d5c1b32728421dde4a44b1f6d8624da",
            "filename": "third_party/xla/xla/python/ifrt_proxy/common/ifrt_service.proto",
            "status": "modified",
            "additions": 16,
            "deletions": 2,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fcommon%2Fifrt_service.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fcommon%2Fifrt_service.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fcommon%2Fifrt_service.proto?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -37,7 +37,7 @@ message IfrtProxyVersion {\n   int32 ifrt_serdes_version_number = 2;\n }\n \n-// Next ID: 33.\n+// Next ID: 34.\n message IfrtRequest {\n   RequestMetadata request_metadata = 1;\n \n@@ -58,6 +58,7 @@ message IfrtRequest {\n     AssembleArrayFromSingleDeviceArraysRequest\n         assemble_array_from_single_device_arrays_request = 5;\n     RemapArraysRequest remap_arrays_request = 23;\n+    ReshardArraysRequest reshard_arrays_request = 33;\n     CopyToHostBufferRequest copy_to_host_buffer_request = 6;\n     DisassembleIntoSingleDeviceArraysRequest\n         disassemble_into_single_device_arrays_request = 7;\n@@ -104,7 +105,7 @@ message IfrtRequest {\n   reserved 10;\n }\n \n-// Next ID: 33.\n+// Next ID: 34.\n message IfrtResponse {\n   ResponseMetadata response_metadata = 1;\n \n@@ -125,6 +126,7 @@ message IfrtResponse {\n     AssembleArrayFromSingleDeviceArraysResponse\n         assemble_array_from_single_device_arrays_response = 5;\n     RemapArraysResponse remap_arrays_response = 23;\n+    ReshardArraysResponse reshard_arrays_response = 33;\n     CopyToHostBufferResponse copy_to_host_buffer_response = 6;\n     DisassembleIntoSingleDeviceArraysResponse\n         disassemble_into_single_device_arrays_response = 7;\n@@ -389,6 +391,18 @@ message RemapArraysResponse {\n   repeated fixed64 array_handles = 1;\n }\n \n+// Reshards the given IFRT arrays to new IFRT arrays.\n+// Equivalent to ifrt::Client::ReshardArrays.\n+message ReshardArraysRequest {\n+  repeated fixed64 array_handles = 1;\n+  repeated xla.ifrt.ArraySpecProto array_specs = 2;\n+  proto.ArrayCopySemantics copy_semantics = 3;\n+  repeated fixed64 result_handles = 4;\n+}\n+message ReshardArraysResponse {\n+  repeated fixed64 array_handles = 1;\n+}\n+\n // Reads the contents of a given IFRT Array.\n // Equivalent to ifrt::Array::CopyToHostBuffer.\n message CopyToHostBufferRequest {"
        },
        {
            "sha": "5e275c6ed7127338fe4b7a28640f886064decbf9",
            "filename": "third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.cc",
            "status": "modified",
            "additions": 36,
            "deletions": 0,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend.cc?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -582,6 +582,11 @@ tsl::Future<BackendInterface::Response> IfrtBackend::ProcessInternal(\n                   &array_store_);\n       return tsl::Future<Response>(asr->ProcessResponse(\n           HandleRemapArraysRequest(*asr, std::move(request))));\n+    case IfrtRequest::RequestCase::kReshardArraysRequest:\n+      asr.emplace(request->reshard_arrays_request().result_handles(),\n+                  &array_store_);\n+      return tsl::Future<Response>(asr->ProcessResponse(\n+          HandleReshardArraysRequest(*asr, std::move(request))));\n     case IfrtRequest::RequestCase::kCopyToHostBufferRequest:\n       return HandleCopyToHostBufferRequest(std::move(request));\n     case IfrtRequest::RequestCase::kDisassembleIntoSingleDeviceArraysRequest:\n@@ -1102,6 +1107,37 @@ IfrtBackend::HandleRemapArraysRequest(ArrayStore::Reservation& asr,\n   return response;\n }\n \n+absl::StatusOr<BackendInterface::Response>\n+IfrtBackend::HandleReshardArraysRequest(ArrayStore::Reservation& asr,\n+                                        std::unique_ptr<IfrtRequest> request) {\n+  const auto& reshard_request = request->reshard_arrays_request();\n+\n+  TF_ASSIGN_OR_RETURN(std::vector<IfrtArrayRef> arrays,\n+                      array_store_.Find(reshard_request.array_handles()));\n+\n+  std::vector<ArraySpec> array_specs;\n+  array_specs.reserve(reshard_request.array_specs_size());\n+  for (const auto& array_spec_proto : reshard_request.array_specs()) {\n+    TF_ASSIGN_OR_RETURN(auto array_spec,\n+                        ArraySpec::FromProto(client_.get(), array_spec_proto));\n+    array_specs.push_back(std::move(array_spec));\n+  }\n+  TF_ASSIGN_OR_RETURN(auto semantics, FromArrayCopySemanticsProto(\n+                                          reshard_request.copy_semantics()));\n+\n+  TF_ASSIGN_OR_RETURN(\n+      auto out_arrays,\n+      client_->ReshardArrays(absl::MakeSpan(arrays), array_specs, semantics));\n+\n+  std::vector<uint64_t> response_handles = asr.Fill(std::move(out_arrays));\n+\n+  std::unique_ptr<IfrtResponse> response =\n+      NewIfrtResponse(request->request_metadata().op_id());\n+  response->mutable_reshard_arrays_response()->mutable_array_handles()->Assign(\n+      response_handles.begin(), response_handles.end());\n+  return response;\n+}\n+\n tsl::Future<BackendInterface::Response>\n IfrtBackend::HandleCopyToStringHostBufferRequest(\n     std::unique_ptr<IfrtRequest> request) {"
        },
        {
            "sha": "70b46b85dd31bcac6e8ed64d608e75291ec6d0ea",
            "filename": "third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend.h?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -200,6 +200,8 @@ class IfrtBackend final : public BackendInterface {\n       ArrayStore::Reservation& asr, std::unique_ptr<IfrtRequest> request);\n   absl::StatusOr<Response> HandleRemapArraysRequest(\n       ArrayStore::Reservation& asr, std::unique_ptr<IfrtRequest> request);\n+  absl::StatusOr<Response> HandleReshardArraysRequest(\n+      ArrayStore::Reservation& asr, std::unique_ptr<IfrtRequest> request);\n   tsl::Future<Response> HandleCopyToHostBufferRequest(\n       std::unique_ptr<IfrtRequest> request);\n   absl::StatusOr<Response> HandleDisassembleIntoSingleDeviceArraysRequest("
        },
        {
            "sha": "0f50cc69e40960a05a3843a9b6036184bfbe7762",
            "filename": "third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend_test.cc",
            "status": "modified",
            "additions": 56,
            "deletions": 0,
            "changes": 56,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend_test.cc?ref=e14e91cfe7a1e1ad6819cba00d6a86f58e1d33d9",
            "patch": "@@ -51,6 +51,7 @@\n #include \"xla/pjrt/pjrt_layout.h\"\n #include \"xla/pjrt/profiling/device_time_measurement.h\"\n #include \"xla/python/ifrt/array.h\"\n+#include \"xla/python/ifrt/array_spec.h\"\n #include \"xla/python/ifrt/attribute_map.h\"\n #include \"xla/python/ifrt/basic_device_list.h\"\n #include \"xla/python/ifrt/compiler.h\"\n@@ -947,6 +948,61 @@ TEST_P(IfrtBackendHandlerTest, CopyArrays) {\n               SizeIs(copied_arrays.size()));\n }\n \n+TEST_P(IfrtBackendHandlerTest, ReshardArrays) {\n+  auto layout1 = std::make_shared<const xla::PjRtLayout>(\n+      xla::LayoutUtil::MakeDescendingLayout(1));\n+  auto layout2 = std::make_shared<const xla::PjRtLayout>(\n+      xla::LayoutUtil::MakeDescendingLayout(2));\n+\n+  auto mock_array = tsl::MakeRef<xla::ifrt::MockArray>();\n+  ON_CALL(*mock_array, dtype()).WillByDefault(Return(DType(DType::kF32)));\n+  Shape shape({2, 2});\n+  ON_CALL(*mock_array, shape()).WillByDefault(ReturnRef(shape));\n+  ON_CALL(*mock_array, pjrt_layout()).WillByDefault(Return(layout1));\n+\n+  const std::vector<xla::ifrt::ArrayRef> src_arrays{{mock_array}};\n+\n+  auto reshared_array = tsl::MakeRef<xla::ifrt::MockArray>();\n+  ON_CALL(*reshared_array, pjrt_layout()).WillByDefault(Return(layout2));\n+  std::vector<xla::ifrt::ArrayRef> result_arrays;\n+  result_arrays.push_back(reshared_array);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Device * device,\n+                          mock_client_->LookupDevice(DeviceId(0)));\n+  ShardingRef sharding(SingleDeviceSharding::Create(device, MemoryKind()));\n+\n+  std::vector<ArraySpec> specs{{DType(DType::kF32), shape, sharding, layout2}};\n+\n+  EXPECT_CALL(*mock_client_, ReshardArrays(ElementsAreArray(src_arrays), _,\n+                                           ArrayCopySemantics::kAlwaysCopy))\n+      .WillOnce(Return(result_arrays));\n+\n+  auto ifrt_request = NewIfrtRequest(NewOpId());\n+  ReshardArraysRequest* reshard_arrays_request =\n+      ifrt_request->mutable_reshard_arrays_request();\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto src_array_handle, MakeTestArray(mock_array));\n+  reshard_arrays_request->add_array_handles(src_array_handle);\n+\n+  for (const auto& spec : specs) {\n+    TF_ASSERT_OK(spec.ToProto(*reshard_arrays_request->add_array_specs(),\n+                              ifrt_serdes_version()));\n+  }\n+  reshard_arrays_request->set_copy_semantics(\n+      proto::ARRAY_COPY_SEMANTICS_ALWAYS_COPY);\n+  if (Version().protocol_version() >=\n+      protocol_version::kClientHandlesOptimization2) {\n+    reshard_arrays_request->add_result_handles(1);\n+  }\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto response, CallBackend(std::move(ifrt_request)));\n+\n+  ASSERT_THAT(tsl::StatusFromProto(response->response_metadata().status()),\n+              absl_testing::IsOk());\n+  EXPECT_THAT(response->reshard_arrays_response().array_handles(),\n+              SizeIs(result_arrays.size()));\n+}\n+\n TEST_P(IfrtBackendHandlerTest, FullyReplicatedShardSuccess) {\n   auto fully_replicated_mock_array = tsl::MakeRef<xla::ifrt::MockArray>();\n   auto resultant_array = tsl::MakeRef<xla::ifrt::MockArray>();"
        }
    ],
    "stats": {
        "total": 237,
        "additions": 220,
        "deletions": 17
    }
}