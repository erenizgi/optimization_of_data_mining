{
    "author": "pschuh",
    "message": "Update PjRtStreamExecutorClient::BufferFromHostBuffer to use raw buffers.\n\nPiperOrigin-RevId: 797876575",
    "sha": "1078239fdb0d79f3ee29e081dec1b51e089a8523",
    "files": [
        {
            "sha": "783d033f9137595b3f17cf9368a85a3f9c6cb21f",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 26,
            "deletions": 55,
            "changes": 81,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1078239fdb0d79f3ee29e081dec1b51e089a8523/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1078239fdb0d79f3ee29e081dec1b51e089a8523/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=1078239fdb0d79f3ee29e081dec1b51e089a8523",
            "patch": "@@ -833,60 +833,46 @@ PjRtStreamExecutorBuffer::DonateWithControlDependency(PjRtFuture<> dependency) {\n   return new_buffer;\n }\n \n-// BufferFromHostBuffer() is used to create a buffer either for a device, or\n-// for a host memory, depending on `memory_space`. The memory copy is needed\n-// for both cases, either from the unpinned host memory to device, or from\n-// the unpinned host memory to the pinned host memory.\n-absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n-PjRtStreamExecutorClient::BufferFromHostBufferInternal(\n+absl::StatusOr<tsl::RCReference<PjRtDeviceEvent>>\n+PjRtStreamExecutorClient::LinearizeHostBufferInto(\n     const void* data, PrimitiveType type, absl::Span<int64_t const> dims,\n     std::optional<absl::Span<int64_t const>> byte_strides,\n     HostBufferSemantics host_buffer_semantics,\n-    absl::AnyInvocable<void() &&> on_done_with_host_buffer, PjRtDevice* device,\n-    const Layout* device_layout, PjRtMemorySpace* memory_space) {\n+    absl::AnyInvocable<void() &&> on_done_with_host_buffer,\n+    const xla::Shape& device_shape,\n+    tsl::RCReference<CommonPjRtRawBuffer> raw_buffer) {\n   tsl::profiler::TraceMe traceme(\n-      \"PjRtStreamExecutorClient::BufferFromHostBuffer\");\n-  Shape device_shape = ShapeUtil::MakeShape(type, dims);\n-  VLOG(1) << \"PjRtStreamExecutorClient::BufferFromHostBuffer: shape: \"\n-          << device_shape.ToString() << \" device: \" << device->DebugString();\n+      \"PjRtStreamExecutorClient::LinearizeHostBufferInto\");\n+  PjRtMemorySpace* memory_space = raw_buffer->memory_space();\n+  PjRtDevice* device = memory_space->devices()[0];\n   TF_ASSIGN_OR_RETURN(LocalDeviceState * local_device,\n                       tensorflow::down_cast<PjRtStreamExecutorDevice*>(device)\n                           ->GetLocalDeviceState());\n \n+  Shape on_host_shape = ShapeUtil::MakeShape(type, dims);\n   absl::InlinedVector<int64_t, 4> tmp_strides;\n   if (!byte_strides) {\n     tmp_strides.resize(dims.size());\n     TF_RETURN_IF_ERROR(\n-        ShapeUtil::ByteStrides(device_shape, absl::MakeSpan(tmp_strides)));\n+        ShapeUtil::ByteStrides(on_host_shape, absl::MakeSpan(tmp_strides)));\n     byte_strides = tmp_strides;\n   }\n-  int64_t size = ShapeUtil::ByteSizeOf(device_shape);\n+  int64_t size = ShapeUtil::ByteSizeOf(on_host_shape);\n \n   TransferManager* transfer_manager = client()->backend().transfer_manager();\n-  if (device_layout != nullptr) {\n-    *(device_shape.mutable_layout()) = *device_layout;\n-  } else {\n-    TF_ASSIGN_OR_RETURN(\n-        device_shape,\n-        transfer_manager->ChooseCompactLayoutForShape(device_shape));\n-  }\n+\n   absl::InlinedVector<int64_t, 4> shape_strides(\n       device_shape.dimensions().size());\n   TF_RETURN_IF_ERROR(\n       ShapeUtil::ByteStrides(device_shape, absl::MakeSpan(shape_strides)));\n   bool host_and_device_strides_equal =\n       (size == 0 || *byte_strides == shape_strides);\n \n-  TF_ASSIGN_OR_RETURN(\n-      std::unique_ptr<PjRtStreamExecutorBuffer> py_buffer,\n-      AllocateDestinationBuffer(device_shape, device, local_device,\n-                                local_device->host_to_device_stream(),\n-                                /*is_uninitialized_create=*/false, this,\n-                                /*definition_event=*/nullptr, memory_space));\n+  auto* copy_stream = local_device->host_to_device_stream();\n \n-  PjRtStreamExecutorBuffer::ScopedHold device_buffer(\n-      py_buffer->GetBufferWithUsageHold());\n-  CHECK(device_buffer.ok());\n+  WaitForAllocation(copy_stream, *raw_buffer);\n+  auto definition_event = tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(\n+      BufferSequencingEvent::Create(thread_pool()));\n \n   std::shared_ptr<TransposePlan> transpose;\n   if (!host_and_device_strides_equal) {\n@@ -963,19 +949,15 @@ PjRtStreamExecutorClient::BufferFromHostBufferInternal(\n     }\n   }\n \n-  BufferSequencingEventRef event = device_buffer->definition_events()[0];\n+  BufferSequencingEventRef event = definition_event->event();\n \n   // The host to device transfer is performed on a thread pool, mostly because\n-  // it includes linearization that may be slow. It is OK to capture the\n-  // py_buffer pointer because the py_buffer can't be deleted until all the\n-  // usage holds have gone away.\n+  // it includes linearization that may be slow.\n   // TODO(misard) assess if it would be preferable to introduce a heuristic to\n   // put the transfer into the calling thread for small literals.\n   auto transfer_h2d =\n       [this, local_client = client(), local_device, data, size, type,\n-       packed_size, event, device_memory_owned = device_buffer->device_memory(),\n-       device_shape, should_pack, py_buffer{py_buffer.get()},\n-       on_device_shape{py_buffer->on_device_shape()},\n+       packed_size, event, raw_buffer, should_pack,\n        staging_buffer{std::move(staging_buffer)},\n        on_done_with_host_buffer =\n            on_done_with_host_buffer\n@@ -989,7 +971,11 @@ PjRtStreamExecutorClient::BufferFromHostBufferInternal(\n         // memory that has already been allocated, and a possible Event\n         // allocation.\n \n-        se::DeviceMemoryBase device_memory = device_memory_owned->mem();\n+        se::DeviceMemoryBase device_memory =\n+            tensorflow::down_cast<PjRtStreamExecutorRawBuffer*>(\n+                raw_buffer.get())\n+                ->device_buffer()\n+                ->mem();\n \n         // If applicable on the backend, stage the transfer via host memory\n         // allocated via the host_memory_allocator. On GPU, this is pinned\n@@ -1031,7 +1017,7 @@ PjRtStreamExecutorClient::BufferFromHostBufferInternal(\n         TF_CHECK_OK(AddDestinationBufferSynchronization(\n             this, local_device, event, local_device->host_to_device_stream()));\n \n-        event.AndThen([device_memory_owned = std::move(device_memory_owned),\n+        event.AndThen([raw_buffer = std::move(raw_buffer),\n                        staging_buffer{std::move(staging_buffer)},\n                        on_done_with_host_buffer{\n                            std::move(on_done_with_host_buffer)}]() mutable {\n@@ -1041,22 +1027,7 @@ PjRtStreamExecutorClient::BufferFromHostBufferInternal(\n         });\n       };\n   thread_pool()->Schedule(WrapClosureAsCopyable(std::move(transfer_h2d)));\n-  RecordUsage(std::move(device_buffer), local_device, local_device, event,\n-              local_device->host_to_device_stream());\n-  return std::unique_ptr<PjRtBuffer>(std::move(py_buffer));\n-}\n-\n-absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n-PjRtStreamExecutorClient::BufferFromHostBuffer(\n-    const void* data, PrimitiveType type, absl::Span<int64_t const> dims,\n-    std::optional<absl::Span<int64_t const>> byte_strides,\n-    HostBufferSemantics host_buffer_semantics,\n-    absl::AnyInvocable<void() &&> on_done_with_host_buffer,\n-    PjRtMemorySpace* memory_space, const Layout* device_layout) {\n-  return BufferFromHostBufferInternal(\n-      data, type, dims, byte_strides, host_buffer_semantics,\n-      std::move(on_done_with_host_buffer), memory_space->devices()[0],\n-      device_layout, memory_space);\n+  return definition_event;\n }\n \n absl::StatusOr<std::unique_ptr<PjRtBuffer>>"
        },
        {
            "sha": "32d774a28d8dad42ed7c7f9d68e9f821c34c11b6",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.h",
            "status": "modified",
            "additions": 8,
            "deletions": 15,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1078239fdb0d79f3ee29e081dec1b51e089a8523/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1078239fdb0d79f3ee29e081dec1b51e089a8523/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h?ref=1078239fdb0d79f3ee29e081dec1b51e089a8523",
            "patch": "@@ -331,13 +331,6 @@ class PjRtStreamExecutorClient : public CommonPjRtClient {\n   absl::StatusOr<std::unique_ptr<PjRtBuffer>> CreateErrorBuffer(\n       absl::Status error, const Shape& shape, PjRtMemorySpace* memory) override;\n \n-  absl::StatusOr<std::unique_ptr<PjRtBuffer>> BufferFromHostBuffer(\n-      const void* data, PrimitiveType type, absl::Span<int64_t const> dims,\n-      std::optional<absl::Span<int64_t const>> byte_strides,\n-      HostBufferSemantics host_buffer_semantics,\n-      absl::AnyInvocable<void() &&> on_done_with_host_buffer,\n-      PjRtMemorySpace* memory_space, const Layout* device_layout) override;\n-\n   using PjRtClient::BufferFromHostLiteral;\n   absl::StatusOr<std::unique_ptr<PjRtBuffer>> BufferFromHostLiteral(\n       const LiteralSlice& literal, PjRtMemorySpace* memory_space,\n@@ -420,6 +413,14 @@ class PjRtStreamExecutorClient : public CommonPjRtClient {\n           definition_device_events,\n       bool raw_buffer_is_mutable) override;\n \n+  absl::StatusOr<tsl::RCReference<PjRtDeviceEvent>> LinearizeHostBufferInto(\n+      const void* data, PrimitiveType type, absl::Span<int64_t const> dims,\n+      std::optional<absl::Span<int64_t const>> byte_strides,\n+      HostBufferSemantics host_buffer_semantics,\n+      absl::AnyInvocable<void() &&> on_done_with_host_buffer,\n+      const xla::Shape& device_shape,\n+      tsl::RCReference<CommonPjRtRawBuffer> raw_buffer) override;\n+\n   void WaitForAllocation(se::Stream* stream,\n                          const CommonPjRtRawBuffer& raw_buffer);\n \n@@ -509,14 +510,6 @@ class PjRtStreamExecutorClient : public CommonPjRtClient {\n       std::vector<std::unique_ptr<LocalExecutable>> local_executables,\n       CompileOptions compile_options);\n \n-  absl::StatusOr<std::unique_ptr<PjRtBuffer>> BufferFromHostBufferInternal(\n-      const void* data, PrimitiveType type, absl::Span<int64_t const> dims,\n-      std::optional<absl::Span<int64_t const>> byte_strides,\n-      HostBufferSemantics host_buffer_semantics,\n-      absl::AnyInvocable<void() &&> on_done_with_host_buffer,\n-      PjRtDevice* device, const Layout* device_layout,\n-      PjRtMemorySpace* memory_space);\n-\n   const PjRtPlatformId platform_id_;\n   const std::string platform_name_;\n   LocalClient* client_;"
        }
    ],
    "stats": {
        "total": 104,
        "additions": 34,
        "deletions": 70
    }
}