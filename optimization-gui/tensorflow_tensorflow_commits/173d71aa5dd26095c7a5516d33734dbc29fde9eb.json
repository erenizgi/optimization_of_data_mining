{
    "author": "amd-songpiao",
    "message": "PR #34250: [ROCm] bugfix - consider the situation where the best time is infinite\n\nImported from GitHub PR https://github.com/openxla/xla/pull/34250\n\nðŸ› Bug Fix\n\nit occasionally happens in [TryFindBestTilingForFusion](https://github.com/openxla/xla/blob/b111957fcb2e2e91839c5e70c6b23216416ca99f/xla/service/gpu/model/gpu_indexing_performance_model.cc#L637C42-L637C68), best_tiled_run_time_data contains Infinite. Such situation leads to an unexpected computed_fusion with tile size[1,1] as below, which leads to performance degression due to register spilling (Tested both on MI300x and H100). This bugfix skips tiles with infinite runtime.\n\n```\nHloModule m\n%region_2.260.clone.19 (Arg_0.55: f32[], Arg_1.55: f32[]) -> f32[] {\n  %Arg_0.55 = f32[] parameter(0)\n  %Arg_1.55 = f32[] parameter(1)\n  ROOT %add.492.0 = f32[] add(%Arg_0.55, %Arg_1.55)\n}\n\n%region_2.260.clone.8 (Arg_0.44: f32[], Arg_1.44: f32[]) -> f32[] {\n  %Arg_0.44 = f32[] parameter(0)\n  %Arg_1.44 = f32[] parameter(1)\n  ROOT %add.481.0 = f32[] add(%Arg_0.44, %Arg_1.44)\n}\n\n%region_2.260.clone.7 (Arg_0.43: f32[], Arg_1.43: f32[]) -> f32[] {\n  %Arg_0.43 = f32[] parameter(0)\n  %Arg_1.43 = f32[] parameter(1)\n  ROOT %add.480.0 = f32[] add(%Arg_0.43, %Arg_1.43)\n}\n\n%fused_computation.337 (param_0.1730: bf16[1,16384,4096], param_1.1795: bf16[16384,4096]) -> f32[128,4096] {\n  %param_0.1730 = bf16[1,16384,4096]{2,1,0} parameter(0)\n  %convert.113.32 = f32[1,16384,4096]{2,1,0} convert(%param_0.1730)\n  %bitcast.1893 = f32[16384,4096]{1,0} bitcast(%convert.113.32)\n  %constant_2184 = f32[] constant(0)\n  %reduce.310 = f32[16384]{0} reduce(%bitcast.1893, %constant_2184), dimensions={1}, to_apply=%region_2.260.clone.7\n  %bitcast.1892 = f32[1,16384]{1,0} bitcast(%reduce.310)\n  %constant_2183 = f32[] constant(0.000244140625)\n  %broadcast.1035 = f32[1,16384]{1,0} broadcast(%constant_2183), dimensions={}\n  %multiply.520 = f32[1,16384]{1,0} multiply(%bitcast.1892, %broadcast.1035)\n  %bitcast.1891 = f32[16384]{0} bitcast(%multiply.520)\n  %broadcast.1034 = f32[1,16384,4096]{2,1,0} broadcast(%bitcast.1891), dimensions={1}\n  %subtract.183 = f32[1,16384,4096]{2,1,0} subtract(%convert.113.32, %broadcast.1034)\n  %multiply.261.15 = f32[1,16384,4096]{2,1,0} multiply(%subtract.183, %subtract.183)\n  %bitcast.1136.15 = f32[16384,4096]{1,0} bitcast(%multiply.261.15)\n  %reduce.127.15 = f32[16384]{0} reduce(%bitcast.1136.15, %constant_2184), dimensions={1}, to_apply=%region_2.260.clone.8\n  %bitcast.1137.13 = f32[1,16384]{1,0} bitcast(%reduce.127.15)\n  %multiply.262.13 = f32[1,16384]{1,0} multiply(%bitcast.1137.13, %broadcast.1035)\n  %constant_1233_1 = f32[] constant(1e-05)\n  %broadcast.449.11 = f32[1,16384]{1,0} broadcast(%constant_1233_1), dimensions={}\n  %add.350.11 = f32[1,16384]{1,0} add(%multiply.262.13, %broadcast.449.11)\n  %bitcast.213.16 = f32[1,16384,1]{2,1,0} bitcast(%add.350.11)\n  %rsqrt.14.5 = f32[1,16384,1]{2,1,0} rsqrt(%bitcast.213.16)\n  %bitcast.215.7 = f32[16384]{0} bitcast(%rsqrt.14.5)\n  %broadcast.472.7 = f32[1,16384,4096]{2,1,0} broadcast(%bitcast.215.7), dimensions={1}\n  %param_1.1795 = bf16[16384,4096]{1,0} parameter(1)\n  %bitcast.211.19 = bf16[1,16384,4096]{2,1,0} bitcast(%param_1.1795)\n  %convert.201.19 = f32[1,16384,4096]{2,1,0} convert(%bitcast.211.19)\n  %multiply.267.5 = f32[1,16384,4096]{2,1,0} multiply(%subtract.183, %convert.201.19)\n  %multiply.282.3 = f32[1,16384,4096]{2,1,0} multiply(%broadcast.472.7, %multiply.267.5)\n  %bitcast.1210.1 = f32[128,128,4096]{2,1,0} bitcast(%multiply.282.3)\n  ROOT %reduce.180.1 = f32[128,4096]{1,0} reduce(%bitcast.1210.1, %constant_2184), dimensions={1}, to_apply=%region_2.260.clone.19\n}\nENTRY main {\n  p0 = bf16[1,16384,4096] parameter(0)\n  p1 = bf16[16384,4096] parameter(1)\n  ROOT fusion = f32[128,4096] fusion(p0, p1), kind=kCustom,\n    calls=%fused_computation.337, backend_config={\n      \"fusion_backend_config\":{\n      \"kind\":\"__triton\",\n      \"block_level_fusion_config\":{\n        \"output_tiles\":[{\"sizes\":[\"1\",\"1\"]}],\n        \"num_warps\":\"8\",\n        \"num_ctas\":\"1\",\n        \"num_stages\":\"1\"}}}\n}\n```\n\nrelevant PR https://github.com/openxla/xla/pull/33777#pullrequestreview-3487884860\n\n@xla-rotation could you review my PR, please?\n\nCopybara import of the project:\n\n--\naf2b30aeadb71e1b058d7c9e56267b19d8e02f54 by Songlin Piao <Songlin.Piao@amd.com>:\n\nbugfix - consider the situation where the best time is infinite\n\n--\ndd3417221bb00e1df4fd83c8b0145e0c7e6b2205 by Songlin Piao <Songlin.Piao@amd.com>:\n\nadded an unit test where best_tiled_run_time_data contains Infinite.\n\nMerging this change closes #34250\n\nPiperOrigin-RevId: 842716246",
    "sha": "173d71aa5dd26095c7a5516d33734dbc29fde9eb",
    "files": [
        {
            "sha": "8d0ae07cc7f7afedcd28bf91fe4bdb5942dc5237",
            "filename": "third_party/xla/xla/service/gpu/model/gpu_indexing_performance_model.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/173d71aa5dd26095c7a5516d33734dbc29fde9eb/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fgpu_indexing_performance_model.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/173d71aa5dd26095c7a5516d33734dbc29fde9eb/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fgpu_indexing_performance_model.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fgpu_indexing_performance_model.cc?ref=173d71aa5dd26095c7a5516d33734dbc29fde9eb",
            "patch": "@@ -680,6 +680,11 @@ GpuPerformanceModelWithIndexingAnalysis::TryFindBestTilingForFusion(\n         EstimateRunTimeForTiledHloComputation(\n             fusion_adaptor, tiled_hlo_computation, launch_dimensions));\n \n+    // Skip tilings with infinite runtime (e.g., due to register spilling).\n+    if (estimate_run_time_data.exec_time == absl::InfiniteDuration()) {\n+      continue;\n+    }\n+\n     if (!best_tiled_run_time_data.has_value() ||\n         estimate_run_time_data.exec_time <\n             best_tiled_run_time_data->runtime_data.exec_time) {"
        },
        {
            "sha": "f3253d1a1257b76c9f2253610085b3a436456e6d",
            "filename": "third_party/xla/xla/service/gpu/transforms/priority_fusion_test.cc",
            "status": "modified",
            "additions": 117,
            "deletions": 0,
            "changes": 117,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/173d71aa5dd26095c7a5516d33734dbc29fde9eb/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/173d71aa5dd26095c7a5516d33734dbc29fde9eb/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion_test.cc?ref=173d71aa5dd26095c7a5516d33734dbc29fde9eb",
            "patch": "@@ -1292,6 +1292,123 @@ TEST_F(PriorityFusionTest, DoNotFuseInsideReducer) {\n               absl_testing::IsOkAndHolds(false));\n }\n \n+TEST_F(PriorityFusionTest, SkipsTilingsWithInfiniteRuntime) {\n+  // This test verifies the fix in TryFindBestTilingForFusion that skips\n+  // tilings with infinite runtime estimates.\n+  //\n+  // The fix: After estimating runtime for each tiling candidate, check if\n+  // exec_time == absl::InfiniteDuration() and skip those tilings.\n+  //\n+  // Background: DoesComputationFitInRegisters() returns false when tiles are\n+  // too large to fit in registers (tile_size > 0.4 * registers_per_block).\n+  // When this happens, EstimateRunTimeForTiledHloComputation() returns\n+  // EstimateRunTimeData::Infinite() with exec_time = absl::InfiniteDuration().\n+  //\n+  // Without the fix: If all tilings have infinite runtime, the first one\n+  // would be selected as \"best\" by default, leading to certain register\n+  // spilling and poor performance.\n+  //\n+  // With the fix: Infinite-runtime tilings are skipped during evaluation,\n+  // allowing:\n+  // 1. Selection of tilings that actually fit in registers, OR\n+  // 2. Return FusionDecision::Forbid(\"No valid tilings found\") if all fail\n+  //\n+  // Test structure: LayerNorm-like computation with reductions that can\n+  // trigger problematic tile sizes on certain input shapes.\n+  const std::string kHloText = R\"(\n+HloModule m\n+%region_2.260.clone.19 (Arg_0.55: f32[], Arg_1.55: f32[]) -> f32[] {\n+  %Arg_0.55 = f32[] parameter(0)\n+  %Arg_1.55 = f32[] parameter(1)\n+  ROOT %add.492.0 = f32[] add(%Arg_0.55, %Arg_1.55)\n+}\n+\n+%region_2.260.clone.8 (Arg_0.44: f32[], Arg_1.44: f32[]) -> f32[] {\n+  %Arg_0.44 = f32[] parameter(0)\n+  %Arg_1.44 = f32[] parameter(1)\n+  ROOT %add.481.0 = f32[] add(%Arg_0.44, %Arg_1.44)\n+}\n+\n+%region_2.260.clone.7 (Arg_0.43: f32[], Arg_1.43: f32[]) -> f32[] {\n+  %Arg_0.43 = f32[] parameter(0)\n+  %Arg_1.43 = f32[] parameter(1)\n+  ROOT %add.480.0 = f32[] add(%Arg_0.43, %Arg_1.43)\n+}\n+\n+%producer_computation (param_0: bf16[16384,4096]) -> bf16[16384,4096] {\n+  %param_0 = bf16[16384,4096]{1,0} parameter(0)\n+  %constant_0 = bf16[] constant(1e-03)\n+  %broadcast_0 = bf16[16384,4096]{1,0} broadcast(%constant_0), dimensions={}\n+  ROOT %add_0 = bf16[16384,4096]{1,0} add(%param_0, %broadcast_0)\n+}\n+\n+%fused_computation.337 (param_0.1730: bf16[1,16384,4096], param_1.1795: bf16[16384,4096]) -> f32[128,4096] {\n+  %param_0.1730 = bf16[1,16384,4096]{2,1,0} parameter(0)\n+  %convert.113.32 = f32[1,16384,4096]{2,1,0} convert(%param_0.1730)\n+  %bitcast.1893 = f32[16384,4096]{1,0} bitcast(%convert.113.32)\n+  %constant_2184 = f32[] constant(0)\n+  %reduce.310 = f32[16384]{0} reduce(%bitcast.1893, %constant_2184), dimensions={1}, to_apply=%region_2.260.clone.7\n+  %bitcast.1892 = f32[1,16384]{1,0} bitcast(%reduce.310)\n+  %constant_2183 = f32[] constant(0.000244140625)\n+  %broadcast.1035 = f32[1,16384]{1,0} broadcast(%constant_2183), dimensions={}\n+  %multiply.520 = f32[1,16384]{1,0} multiply(%bitcast.1892, %broadcast.1035)\n+  %bitcast.1891 = f32[16384]{0} bitcast(%multiply.520)\n+  %broadcast.1034 = f32[1,16384,4096]{2,1,0} broadcast(%bitcast.1891), dimensions={1}\n+  %subtract.183 = f32[1,16384,4096]{2,1,0} subtract(%convert.113.32, %broadcast.1034)\n+  %multiply.261.15 = f32[1,16384,4096]{2,1,0} multiply(%subtract.183, %subtract.183)\n+  %bitcast.1136.15 = f32[16384,4096]{1,0} bitcast(%multiply.261.15)\n+  %reduce.127.15 = f32[16384]{0} reduce(%bitcast.1136.15, %constant_2184), dimensions={1}, to_apply=%region_2.260.clone.8\n+  %bitcast.1137.13 = f32[1,16384]{1,0} bitcast(%reduce.127.15)\n+  %multiply.262.13 = f32[1,16384]{1,0} multiply(%bitcast.1137.13, %broadcast.1035)\n+  %constant_1233_1 = f32[] constant(1e-05)\n+  %broadcast.449.11 = f32[1,16384]{1,0} broadcast(%constant_1233_1), dimensions={}\n+  %add.350.11 = f32[1,16384]{1,0} add(%multiply.262.13, %broadcast.449.11)\n+  %bitcast.213.16 = f32[1,16384,1]{2,1,0} bitcast(%add.350.11)\n+  %rsqrt.14.5 = f32[1,16384,1]{2,1,0} rsqrt(%bitcast.213.16)\n+  %bitcast.215.7 = f32[16384]{0} bitcast(%rsqrt.14.5)\n+  %broadcast.472.7 = f32[1,16384,4096]{2,1,0} broadcast(%bitcast.215.7), dimensions={1}\n+  %param_1.1795 = bf16[16384,4096]{1,0} parameter(1)\n+  %bitcast.211.19 = bf16[1,16384,4096]{2,1,0} bitcast(%param_1.1795)\n+  %convert.201.19 = f32[1,16384,4096]{2,1,0} convert(%bitcast.211.19)\n+  %multiply.267.5 = f32[1,16384,4096]{2,1,0} multiply(%subtract.183, %convert.201.19)\n+  %multiply.282.3 = f32[1,16384,4096]{2,1,0} multiply(%broadcast.472.7, %multiply.267.5)\n+  %bitcast.1210.1 = f32[128,128,4096]{2,1,0} bitcast(%multiply.282.3)\n+  ROOT %reduce.180.1 = f32[128,4096]{1,0} reduce(%bitcast.1210.1, %constant_2184), dimensions={1}, to_apply=%region_2.260.clone.19\n+}\n+ENTRY main {\n+  p0 = bf16[1,16384,4096] parameter(0)\n+  p1 = bf16[16384,4096] parameter(1)\n+  producer_fusion = bf16[16384,4096]{1,0} fusion(p1), kind=kLoop, calls=%producer_computation\n+\n+  ROOT fusion = f32[128,4096] fusion(p0, producer_fusion), kind=kCustom,\n+    calls=%fused_computation.337, backend_config={\n+      \"fusion_backend_config\":{\n+      \"kind\":\"__triton\",\n+      \"block_level_fusion_config\":{\n+        \"output_tiles\":[{\"sizes\":[\"1\",\"1\"]}],\n+        \"num_warps\":\"8\",\n+        \"num_ctas\":\"1\",\n+        \"num_stages\":\"1\"}}}\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(kHloText));\n+\n+  module->mutable_config()\n+      .mutable_debug_options()\n+      .set_xla_gpu_enable_triton_gemm(false);\n+\n+  module->mutable_config().mutable_debug_options().set_xla_gpu_autotune_level(\n+      0);\n+\n+  // VLOG(2) << module->ToString() << std::endl;\n+\n+  // Run priority fusion - it should not fuse producer into\n+  // %fused_computation.337.\n+  EXPECT_THAT(priority_fusion_.Run(module.get()),\n+              absl_testing::IsOkAndHolds(false));\n+}\n+\n class PriorityFusionWithTritonEnabledTest : public PriorityFusionTest {\n  public:\n   DebugOptions GetDebugOptionsForTest() const override {"
        },
        {
            "sha": "8f3da454abe41dc172f34b2037430054f625dfaf",
            "filename": "third_party/xla/xla/service/gpu/transforms/softmax_rewriter_triton_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 9,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/173d71aa5dd26095c7a5516d33734dbc29fde9eb/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsoftmax_rewriter_triton_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/173d71aa5dd26095c7a5516d33734dbc29fde9eb/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsoftmax_rewriter_triton_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsoftmax_rewriter_triton_test.cc?ref=173d71aa5dd26095c7a5516d33734dbc29fde9eb",
            "patch": "@@ -1066,8 +1066,7 @@ ENTRY main {\n   EXPECT_FALSE(fusion_rewriter_.Run(module.get()).value());\n }\n \n-TEST_F(SoftmaxRewriterTritonTest,\n-       DoNotFuseNormalizationWithVeryLongRowsIfProfitabilityCheckIsEnabled) {\n+TEST_F(SoftmaxRewriterTritonTest, DoesNotFuseNormalizationWithVeryLongRows) {\n   const std::string hlo_string = R\"(\n HloModule softmax\n max_computation {\n@@ -1084,19 +1083,16 @@ ENTRY main {\n })\";\n \n   {\n-    // Verify that SoftmaxRewriterTriton without Cost Model will fuse the\n-    // normalization diamond.\n+    // Verify that SoftmaxRewriterTriton without Cost Model will not fuse the\n+    // normalization diamond, because the row size is too large to fit in\n+    // registers.\n     SoftmaxRewriterTriton fusion_rewriter_without_cost_model{\n         device_info_, HloCostAnalysis::DefaultShapeSize, &alias_info_,\n         &mlir_context_,\n         /*only_fuse_if_profitable=*/false};\n \n     auto module = ParseAndReturnVerifiedModule(hlo_string).value();\n-    EXPECT_TRUE(fusion_rewriter_without_cost_model.Run(module.get()).value());\n-    EXPECT_TRUE(verifier().Run(module.get()).status().ok());\n-    EXPECT_THAT(module->entry_computation()->root_instruction(),\n-                GmockMatch(m::Fusion(m::Parameter())\n-                               .WithPredicate(HasBlockLevelFusionConfig)));\n+    EXPECT_FALSE(fusion_rewriter_without_cost_model.Run(module.get()).value());\n   }\n \n   {"
        }
    ],
    "stats": {
        "total": 136,
        "additions": 127,
        "deletions": 9
    }
}