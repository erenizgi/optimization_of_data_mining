{
    "author": "nputikhin",
    "message": "Reverts deb256b360c624f8d476d888eb5dc1f902210fac\n\nPiperOrigin-RevId: 845202732",
    "sha": "a8ad7b1565df6a2e737756f7fa55002be3d58b98",
    "files": [
        {
            "sha": "c77d76d6954aed56941694885583da7f0e96886e",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_fusion_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 52,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a8ad7b1565df6a2e737756f7fa55002be3d58b98/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a8ad7b1565df6a2e737756f7fa55002be3d58b98/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion_test.cc?ref=a8ad7b1565df6a2e737756f7fa55002be3d58b98",
            "patch": "@@ -227,58 +227,6 @@ ENTRY e {\n   EXPECT_TRUE(GemmFusion(cc).Run(module.get()).value());\n }\n \n-TEST_F(GemmFusionTest, FuseSliceWithOtherUsersWhenDotHasSmallK) {\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n-                          ParseAndReturnVerifiedModule(R\"(\n-ENTRY e {\n-  p0 = bf16[512,3584]{1,0} parameter(0)\n-  p1 = bf16[3584,14400]{0,1} parameter(1)\n-  p2 = bf16[64,14336]{1,0} parameter(2)\n-\n-  d0 = bf16[512,14400]{1,0} dot(p0, p1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-  sl0 = bf16[512,14336]{1,0} slice(d0), slice={[0:512], [0:14336]}\n-\n-  sl1 = bf16[512,64]{1,0} slice(d0), slice={[0:512], [14336:14400]}\n-  d1 = bf16[512,14336]{1,0} dot(sl1, p2), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-  ROOT a0 = bf16[512,14336]{1,0} add(sl0, d1)\n-})\"));\n-\n-  const se::CudaComputeCapability cc{se::CudaComputeCapability::kHopper, 0};\n-  EXPECT_TRUE(GemmFusion(cc).Run(module.get()).value());\n-\n-  // Check that the second dot is fused and the fusion contains sl1.\n-  // We make no assumptions about other fusions.\n-  constexpr absl::string_view kExpectedHloText = R\"(\n-    CHECK: %[[FUSION_DOT:.*]] (\n-    CHECK:   %[[SLICE:.*]] = bf16[512,64]{1,0} slice(%parameter_0), slice={[0:512], [14336:14400]}\n-    CHECK:   ROOT {{.*}} = bf16[512,14336]{1,0} dot(%[[SLICE]], %parameter_1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-    CHECK: ENTRY\n-    CHECK-DAG: %[[FUSION_D1:.*]] = bf16[512,14336]{1,0} fusion({{.*}}, {{.*}}), kind=kCustom, calls=%[[FUSION_DOT]]\n-    CHECK-DAG: ROOT %a0 = bf16[512,14336]{1,0} add({{.*}}, %[[FUSION_D1]])\n-  )\";\n-  MatchHloModule(*module, kExpectedHloText);\n-}\n-\n-TEST_F(GemmFusionTest, DoNotFuseSliceWithOtherUsersWhenDotHasLargeK) {\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n-                          ParseAndReturnVerifiedModule(R\"(\n-ENTRY e {\n-  p0 = bf16[512,3584]{1,0} parameter(0)\n-  p1 = bf16[3584,14400]{0,1} parameter(1)\n-  p2 = bf16[1400,14336]{1,0} parameter(2)\n-\n-  d0 = bf16[512,14400]{1,0} dot(p0, p1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-  sl0 = bf16[512,14336]{1,0} slice(d0), slice={[0:512], [0:14336]}\n-  sl1 = bf16[512,1400]{1,0} slice(d0), slice={[0:512], [13000:14400]}\n-\n-  d1 = bf16[512,14336]{1,0} dot(sl1, p2), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-  ROOT a0 = bf16[512,14336]{1,0} add(sl0, d1)\n-})\"));\n-\n-  const se::CudaComputeCapability cc{se::CudaComputeCapability::kHopper, 0};\n-  EXPECT_FALSE(GemmFusion(cc).Run(module.get()).value());\n-}\n-\n TEST_F(GemmFusionTest, DoNotFuseSliceOfMixedDimensions) {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n                           ParseAndReturnVerifiedModule(R\"("
        },
        {
            "sha": "cfc47a333955d02ca8e9125d25604794927e6876",
            "filename": "third_party/xla/xla/service/gpu/triton_fusion_analysis.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 24,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a8ad7b1565df6a2e737756f7fa55002be3d58b98/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a8ad7b1565df6a2e737756f7fa55002be3d58b98/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis.cc?ref=a8ad7b1565df6a2e737756f7fa55002be3d58b98",
            "patch": "@@ -57,16 +57,6 @@ using triton_fusion::GetPropagatedDimOrdersAndRequirements;\n using triton_fusion::kNoSplitRequirement;\n using triton_fusion::TransformDirection;\n \n-int64_t GetContractingDimSize(const HloInstruction& dot) {\n-  const auto& contracting_dims =\n-      ContractingDimensionsForOperand(dot, /*operand_number=*/0);\n-  int64_t contracting_dim_size = 1;\n-  for (int64_t dim : contracting_dims) {\n-    contracting_dim_size *= dot.operand(0)->shape().dimensions(dim);\n-  }\n-  return contracting_dim_size;\n-}\n-\n }  // namespace\n \n namespace triton_fusion {\n@@ -91,13 +81,9 @@ namespace triton_fusion {\n           0) {\n     splittable_dimension_index = non_contracting_dimension_index;\n   }\n-\n-  int64_t contracting_size = GetContractingDimSize(dot);\n-\n-  FusionContext context(\n-      DotProperties{non_contracting_dimension_index, splittable_dimension_index,\n-                    contracting_size},\n-      DotRequirements(kNoSplitRequirement));\n+  FusionContext context(DotProperties{non_contracting_dimension_index,\n+                                      splittable_dimension_index},\n+                        DotRequirements(kNoSplitRequirement));\n   context.dim_orders_[dot.operand(operand_number)] =\n       DimensionOrder::FromDotOperandOrOutput(*dot.operand(operand_number),\n                                              split_k_dimension_index);\n@@ -116,13 +102,9 @@ namespace triton_fusion {\n     // LHS non-contracting follows (batch is absent in this case).\n     splittable_dimension_index = (split_k > 1) ? 1 : 0;\n   }\n-\n-  int64_t contracting_size = GetContractingDimSize(dot);\n-\n-  FusionContext context(\n-      DotProperties{/*noncontracting_dimension=*/-1, splittable_dimension_index,\n-                    contracting_size},\n-      std::move(requirements));\n+  FusionContext context(DotProperties{/*noncontracting_dimension=*/-1,\n+                                      splittable_dimension_index},\n+                        std::move(requirements));\n   context.dim_orders_[&dot] = DimensionOrder::FromDotOperandOrOutput(dot);\n   return context;\n }"
        },
        {
            "sha": "926307d6f0c0e7423d473b7766bea7cda22c8711",
            "filename": "third_party/xla/xla/service/gpu/triton_tiling_propagation.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 24,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a8ad7b1565df6a2e737756f7fa55002be3d58b98/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_tiling_propagation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a8ad7b1565df6a2e737756f7fa55002be3d58b98/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_tiling_propagation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_tiling_propagation.cc?ref=a8ad7b1565df6a2e737756f7fa55002be3d58b98",
            "patch": "@@ -992,16 +992,11 @@ bool CanNotBeFusedIntoAUser(const HloInstruction& hlo) {\n                           hlo.users()[0]->opcode() == HloOpcode::kTuple);\n }\n \n-// Maximum contracting dimension size for which slice fusion is allowed when\n-// the operand has multiple users.\n-constexpr int kMaxContractingDimSizeForSliceFusion = 1024;\n-\n // Let input and output data volumes of a fusion grow by small amounts.\n constexpr int kIoToleranceBytes = 1024;\n \n // Tells that fusing an instruction as an input is efficient.\n-bool IsInputWorthFusing(const HloInstruction& hlo,\n-                        const DotProperties& properties) {\n+bool IsInputWorthFusing(const HloInstruction& hlo) {\n   std::optional<int64_t> input_minus_output_bytes = InputMinusOutputBytes(hlo);\n   if (!input_minus_output_bytes.has_value()) {\n     return false;\n@@ -1016,30 +1011,15 @@ bool IsInputWorthFusing(const HloInstruction& hlo,\n       hlo_query::AllOperandsAreParametersOrConstants(hlo)) {\n     return true;\n   }\n-  // Explanation:\n-  // * Operand user count > 1 - if the producer of the slice has a single user\n-  //   the slice can be fused into the producer instead of here.\n-  // * contracting_dim_size < 1024 - fusing slices disables split-K rewriter,\n-  //   which may outweigh the benefit of fusing it in the first place. Small\n-  //   contracting dimension almost never benefits from splitting it, so we\n-  //   allow the fusion.\n-\n-  // TODO: b/393299275 - Remove the contracting dim size restriction once the\n-  // new emitter lands and we can support slices in contracting dimension with\n-  // splits.\n-  if (hlo.opcode() == HloOpcode::kSlice && hlo.operand(0)->user_count() > 1 &&\n-      properties.contracting_dim_size <= kMaxContractingDimSizeForSliceFusion) {\n-    return true;\n-  }\n   const bool enable_subchannel_dequantisation_fusion =\n       hlo.GetModule()\n           ->config()\n           .debug_options()\n           .xla_gpu_experimental_enable_subchannel_dequantisation_fusion();\n   if (hlo.opcode() == HloOpcode::kMultiply) {\n     return enable_subchannel_dequantisation_fusion &&\n-           IsInputWorthFusing(*hlo.operand(0), properties) &&\n-           IsInputWorthFusing(*hlo.operand(1), properties);\n+           IsInputWorthFusing(*hlo.operand(0)) &&\n+           IsInputWorthFusing(*hlo.operand(1));\n   }\n   return hlo_query::AllOperandsAreParametersOrConstantsWithSingleUser(hlo);\n }\n@@ -1159,7 +1139,7 @@ GetPropagatedDimOrdersAndRequirementsIfProfitablyFusible(\n         }\n       }\n     }\n-    if (!accepted && !IsInputWorthFusing(hlo, properties)) {\n+    if (!accepted && !IsInputWorthFusing(hlo)) {\n       return FusionDecision::Forbid(\n           \"Not obviously profitable to fuse as input.\");\n     }"
        },
        {
            "sha": "a83dd9c976f8c4b4a96c662b12cb18284ce8b213",
            "filename": "third_party/xla/xla/service/gpu/triton_tiling_propagation.h",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a8ad7b1565df6a2e737756f7fa55002be3d58b98/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_tiling_propagation.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a8ad7b1565df6a2e737756f7fa55002be3d58b98/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_tiling_propagation.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_tiling_propagation.h?ref=a8ad7b1565df6a2e737756f7fa55002be3d58b98",
            "patch": "@@ -249,8 +249,6 @@ struct DotProperties {\n   // Index of dot dimension that can be split.\n   // Currently typically LHS non-contracting one.\n   const int splittable_dimension_index;\n-  // Size of the contracting dimension (K).\n-  const int64_t contracting_dim_size;\n };\n \n // A special value for splittable_dimension_major_part_size."
        }
    ],
    "stats": {
        "total": 112,
        "additions": 10,
        "deletions": 102
    }
}