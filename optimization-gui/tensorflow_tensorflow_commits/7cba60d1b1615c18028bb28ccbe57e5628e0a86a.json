{
    "author": "tensorflower-gardener",
    "message": "[Autotuner] Adapt DebugOptions for Autotuning.\n\n- Disable parallelism and other optimizations which we don't want to measure in autotuning.\n- The change is taken from autotuner_compile_util.cc\n\nPiperOrigin-RevId: 810922029",
    "sha": "7cba60d1b1615c18028bb28ccbe57e5628e0a86a",
    "files": [
        {
            "sha": "a604831e176602574dff227e1f7a312fa5f45ae8",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_codegen_backend.h",
            "status": "modified",
            "additions": 12,
            "deletions": 5,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7cba60d1b1615c18028bb28ccbe57e5628e0a86a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_codegen_backend.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7cba60d1b1615c18028bb28ccbe57e5628e0a86a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_codegen_backend.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_codegen_backend.h?ref=7cba60d1b1615c18028bb28ccbe57e5628e0a86a",
            "patch": "@@ -68,11 +68,18 @@ class GpuCodegenBackend : public CodegenBackend {\n     TF_RETURN_IF_ERROR(ApplyConfig(*root_instruction, config));\n \n     hlo_module->mutable_config().set_debug_options(debug_options_);\n-    hlo_module->mutable_config().mutable_debug_options().set_xla_enable_dumping(\n-        false);\n-    hlo_module->mutable_config()\n-        .mutable_debug_options()\n-        .clear_xla_gpu_enable_command_buffer();\n+    DebugOptions& opts = hlo_module->mutable_config().mutable_debug_options();\n+    opts.set_xla_enable_dumping(false);\n+    // Avoid using another thread pool.\n+    opts.set_xla_gpu_force_compilation_parallelism(1);\n+    opts.set_xla_gpu_enable_llvm_module_compilation_parallelism(false);\n+    // Avoid using GPU graphs as we don't want to measure graph construction\n+    // time.\n+    opts.clear_xla_gpu_enable_command_buffer();\n+    // Avoid using async dot as we don't want to measure event overheads.\n+    opts.set_xla_gpu_async_dot(false);\n+    opts.set_xla_embed_ir_in_executable(false);\n+    opts.set_xla_gpu_kernel_cache_file(\"\");\n \n     Compiler::CompileOptions options;\n     options.is_autotuning_compilation = true;"
        }
    ],
    "stats": {
        "total": 17,
        "additions": 12,
        "deletions": 5
    }
}