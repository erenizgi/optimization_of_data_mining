{
    "author": "mkuperst",
    "message": "[XLA] Add initial version of call splitter.\n\nThis pass allows splitting a single function call into two calls to two functions, where the original called computation is split across a specified boundary.\n\nIt's not quite production ready yet, landing it to have something to keep working off.\n\nPiperOrigin-RevId: 830430731",
    "sha": "006b29324e6fc25450146aa4cf8166c7f8a26851",
    "files": [
        {
            "sha": "4db8e3b4c9739c837f0878e4d500d7f42f2f4b04",
            "filename": "third_party/xla/xla/hlo/transforms/BUILD",
            "status": "modified",
            "additions": 46,
            "deletions": 0,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/006b29324e6fc25450146aa4cf8166c7f8a26851/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/006b29324e6fc25450146aa4cf8166c7f8a26851/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD?ref=006b29324e6fc25450146aa4cf8166c7f8a26851",
            "patch": "@@ -566,3 +566,49 @@ cc_library(\n         \"@local_tsl//tsl/platform:errors\",\n     ],\n )\n+\n+cc_library(\n+    name = \"call_splitter\",\n+    srcs = [\"call_splitter.cc\"],\n+    hdrs = [\"call_splitter.h\"],\n+    deps = [\n+        \"//xla:util\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/pass:hlo_pass\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/types:span\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"call_splitter_test\",\n+    srcs = [\"call_splitter_test.cc\"],\n+    deps = [\n+        \":call_splitter\",\n+        \"//xla:util\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/hlo/testlib:pattern_matcher_gmock\",\n+        \"//xla/hlo/testlib:test\",\n+        \"//xla/hlo/transforms/simplifiers:call_parameter_cleanup\",\n+        \"//xla/hlo/transforms/simplifiers:hlo_dce\",\n+        \"//xla/hlo/transforms/simplifiers:tuple_simplifier\",\n+        \"//xla/service:call_inliner\",\n+        \"//xla/service:pattern_matcher\",\n+        \"//xla/tsl/platform:status\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_googletest//:gtest\",\n+        \"@com_google_googletest//:gtest_main\",  # fixdeps: keep\n+    ],\n+)"
        },
        {
            "sha": "5e6e7acd03dc6f1a9eadb9b2ddffe53d5db530ae",
            "filename": "third_party/xla/xla/hlo/transforms/call_splitter.cc",
            "status": "added",
            "additions": 282,
            "deletions": 0,
            "changes": 282,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/006b29324e6fc25450146aa4cf8166c7f8a26851/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcall_splitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/006b29324e6fc25450146aa4cf8166c7f8a26851/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcall_splitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcall_splitter.cc?ref=006b29324e6fc25450146aa4cf8166c7f8a26851",
            "patch": "@@ -0,0 +1,282 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/hlo/transforms/call_splitter.h\"\n+\n+#include <algorithm>\n+#include <memory>\n+#include <vector>\n+\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n+#include \"xla/hlo/ir/hlo_clone_context.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n+\n+namespace xla {\n+\n+namespace {\n+\n+// Returns all instructions in the body that match the boundary predicate.\n+std::vector<HloInstruction*> GetBoundaryInstructions(\n+    HloComputation* body, HloPredicate boundary_predicate) {\n+  std::vector<HloInstruction*> boundary_instructions;\n+  for (HloInstruction* instruction : body->instructions()) {\n+    if (boundary_predicate(instruction)) {\n+      boundary_instructions.push_back(instruction);\n+    }\n+  }\n+  return boundary_instructions;\n+}\n+\n+// Returns all instructions that must go into the second call, because they\n+// depend on the boundary instructions.\n+absl::flat_hash_set<HloInstruction*> GetSecondCallInstructions(\n+    HloComputation* body,\n+    const std::vector<HloInstruction*>& boundary_instructions) {\n+  absl::flat_hash_set<HloInstruction*> second_call_instructions(\n+      boundary_instructions.begin(), boundary_instructions.end());\n+  std::vector<HloInstruction*> worklist(boundary_instructions.begin(),\n+                                        boundary_instructions.end());\n+  while (!worklist.empty()) {\n+    HloInstruction* curr = worklist.back();\n+    worklist.pop_back();\n+    auto process = [&](HloInstruction* user) {\n+      if (second_call_instructions.contains(user)) {\n+        return;\n+      }\n+      second_call_instructions.insert(user);\n+      worklist.push_back(user);\n+    };\n+    for (HloInstruction* user : curr->users()) {\n+      process(user);\n+    }\n+    for (HloInstruction* successor : curr->control_successors()) {\n+      process(successor);\n+    }\n+  }\n+  return second_call_instructions;\n+}\n+\n+absl::StatusOr<bool> SplitCall(HloInstruction* call,\n+                               HloPredicate boundary_predicate) {\n+  // We need to do several things here:\n+  // 1. Figure out which instructions go into the first call and which into the\n+  // second. In particular:\n+  //    a) The boundary instructions go into the second call.\n+  //    b) Anything that consumes the results of the boundary instructions goes\n+  //    into the second call.\n+  //    c) Anything that feeds the instructions from (a) and (b) goes into the\n+  //    first call.\n+  //    d) The remaining instructions go into the first call.\n+  // 2. Figure out the outputs of the first call and the inputs to the second\n+  // call, and how to connect them.\n+  // 3. Materialized the two new computations and the calls, and put them in the\n+  // enclosing computation.\n+\n+  // TODO(mkuper): This splits \"down\". We also want a version that splits \"up\",\n+  // i.e. the boundary ends up in the first call, and the \"irrelevant\"\n+  // instructions end up in the second one.\n+\n+  HloComputation* body = call->to_apply();\n+  HloComputation* enclosing_computation = call->parent();\n+  HloModule* module = body->parent();\n+\n+  std::vector<HloInstruction*> boundary_instructions =\n+      GetBoundaryInstructions(body, boundary_predicate);\n+  if (boundary_instructions.empty()) {\n+    return false;\n+  }\n+\n+  absl::flat_hash_set<HloInstruction*> second_call_instructions =\n+      GetSecondCallInstructions(body, boundary_instructions);\n+\n+  absl::flat_hash_set<HloInstruction*> first_call_instructions;\n+  for (HloInstruction* instruction : body->instructions()) {\n+    if (!second_call_instructions.contains(instruction)) {\n+      first_call_instructions.insert(instruction);\n+    }\n+  }\n+  if (first_call_instructions.empty() || second_call_instructions.empty()) {\n+    return false;\n+  }\n+\n+  if (VLOG_IS_ON(1)) {\n+    VLOG(1) << \"First call instructions: \";\n+    for (HloInstruction* instruction : first_call_instructions) {\n+      VLOG(1) << instruction->ToString();\n+    }\n+    VLOG(1) << \"Second call instructions: \";\n+    for (HloInstruction* instruction : second_call_instructions) {\n+      VLOG(1) << instruction->ToString();\n+    }\n+  }\n+\n+  // The outputs of the first call are instructions that will be in the first\n+  // call that are directly used by instructions that will be in the second\n+  // call. It's convenient to have both a set and a vector representation. We\n+  // could use a single ordered associative container, but this is simpler.\n+  absl::flat_hash_set<HloInstruction*> first_call_outputs;\n+  for (HloInstruction* instruction : second_call_instructions) {\n+    for (HloInstruction* control_pred : instruction->control_predecessors()) {\n+      // Don't break the function if it would create a control edge that needs\n+      // to be threaded between the two new functions.\n+      if (first_call_instructions.contains(control_pred)) {\n+        return false;\n+      }\n+    }\n+    for (HloInstruction* data_pred : instruction->operands()) {\n+      if (first_call_instructions.contains(data_pred)) {\n+        first_call_outputs.insert(data_pred);\n+      }\n+    }\n+  }\n+\n+  // Make sure the order of outputs is deterministic.\n+  std::vector<HloInstruction*> first_call_outputs_vec(\n+      first_call_outputs.begin(), first_call_outputs.end());\n+  std::sort(first_call_outputs_vec.begin(), first_call_outputs_vec.end(),\n+            [](HloInstruction* a, HloInstruction* b) {\n+              return a->unique_id() < b->unique_id();\n+            });\n+  if (VLOG_IS_ON(1)) {\n+    VLOG(1) << \"First call outputs: \";\n+    for (HloInstruction* instruction : first_call_outputs_vec) {\n+      VLOG(1) << instruction->ToString();\n+    }\n+  }\n+\n+  // Construct the first call body. We delete everything that goes into the\n+  // second call from the call body, and construct a new output tuple based on\n+  // the inputs the second call needs.\n+  absl::flat_hash_map<const HloInstruction*, std::unique_ptr<HloInstruction>>\n+      first_call_replacements;\n+  for (HloInstruction* instruction : second_call_instructions) {\n+    first_call_replacements.insert({instruction, nullptr});\n+  }\n+  HloComputation* first_call_computation =\n+      module->AddEmbeddedComputation(body->CloneWithReplacements(\n+          &first_call_replacements, /*extra_parameters=*/{},\n+          /*context=*/nullptr, /*suffix=*/\"first\", first_call_outputs_vec));\n+\n+  // Now construct the second call body. In the call body, the first call\n+  // instruction that are directly used are replaced by parameters, and the rest\n+  // are deleted.\n+  absl::flat_hash_map<const HloInstruction*, std::unique_ptr<HloInstruction>>\n+      second_call_replacements;\n+  for (int i = 0; i < first_call_outputs_vec.size(); ++i) {\n+    second_call_replacements.insert(\n+        {first_call_outputs_vec[i],\n+         HloInstruction::CreateParameter(i, first_call_outputs_vec[i]->shape(),\n+                                         absl::StrCat(\"first_output_\", i))});\n+  }\n+  for (HloInstruction* instruction : first_call_instructions) {\n+    if (first_call_outputs.contains(instruction)) {\n+      continue;\n+    }\n+    second_call_replacements.insert({instruction, nullptr});\n+  }\n+  HloComputation* second_call_computation =\n+      module->AddEmbeddedComputation(body->CloneWithReplacements(\n+          &second_call_replacements, /*extra_parameters=*/{},\n+          /*context=*/nullptr, /*suffix=*/\"second\", /*new_root=*/nullptr));\n+\n+  // Now actually create the call ops, connect them together, and splice them\n+  // where the original call was.\n+  HloInstruction* first_call =\n+      enclosing_computation->AddInstruction(call->CloneWithNewOperands(\n+          first_call_computation->root_instruction()->shape(),\n+          call->operands()));\n+  first_call->set_to_apply(first_call_computation);\n+  std::vector<HloInstruction*> first_call_output_gtes;\n+  first_call_output_gtes.reserve(first_call_outputs_vec.size());\n+  for (int i = 0; i < first_call_outputs_vec.size(); ++i) {\n+    first_call_output_gtes.push_back(enclosing_computation->AddInstruction(\n+        HloInstruction::CreateGetTupleElement(first_call, i)));\n+  }\n+  HloInstruction* second_call =\n+      enclosing_computation->AddInstruction(call->CloneWithNewOperands(\n+          second_call_computation->root_instruction()->shape(),\n+          first_call_output_gtes));\n+  second_call->set_to_apply(second_call_computation);\n+  TF_RETURN_IF_ERROR(call->ReplaceAllUsesWith(second_call));\n+  return true;\n+}\n+\n+}  // namespace\n+\n+absl::StatusOr<bool> CallSplitter::RunImpl(\n+    HloModule* module,\n+    const absl::flat_hash_set<absl::string_view>& execution_threads) {\n+  bool changed = false;\n+  // Find all the call instructions that match the predicate. We don't process\n+  // them immediately since we're going to change their enclosing computation.\n+  // process all calls in a computation together. Note that we want to process\n+  // them in the same order as we encounter them, because for nested calls, we\n+  // want to process the deeper call first.\n+\n+  // TODO(mkuper): Support unflattened graphs properly - if a function has\n+  // several callsites, we should only split it once, and then reuse the\n+  // resulting computations.\n+  std::vector<HloInstruction*> calls_to_process;\n+  for (HloComputation* computation :\n+       module->MakeComputationPostOrder(execution_threads)) {\n+    for (HloInstruction* instruction :\n+         computation->MakeInstructionPostOrder()) {\n+      if (instruction->opcode() != HloOpcode::kCall) {\n+        continue;\n+      }\n+      // TODO(mkuper): Support calls with control dependencies, if that appears\n+      // useful.\n+      if (instruction->HasControlDependencies()) {\n+        continue;\n+      }\n+      if (!execution_threads.empty() &&\n+          !execution_threads.contains(\n+              instruction->to_apply()->execution_thread())) {\n+        continue;\n+      }\n+      // TODO(mkuper): We could support removing dead parameters from non-tuple\n+      // shaped calls. We could also potentially support pass-through for\n+      // tuple-shaped calls where the root *instruction* is not kTuple by doing\n+      // more complex analysis.\n+      if (instruction->to_apply()->root_instruction()->opcode() !=\n+          HloOpcode::kTuple) {\n+        continue;\n+      }\n+      VLOG(1) << \"Found matching call: \" << instruction->ToString();\n+      calls_to_process.push_back(instruction);\n+    }\n+  }\n+\n+  for (HloInstruction* call : calls_to_process) {\n+    TF_ASSIGN_OR_RETURN(bool split, SplitCall(call, boundary_predicate_));\n+    changed |= split;\n+  }\n+\n+  return changed;\n+}\n+\n+}  // namespace xla"
        },
        {
            "sha": "e13445130d9ec50a43441cdb2343d33d88c66e1d",
            "filename": "third_party/xla/xla/hlo/transforms/call_splitter.h",
            "status": "added",
            "additions": 88,
            "deletions": 0,
            "changes": 88,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/006b29324e6fc25450146aa4cf8166c7f8a26851/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcall_splitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/006b29324e6fc25450146aa4cf8166c7f8a26851/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcall_splitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcall_splitter.h?ref=006b29324e6fc25450146aa4cf8166c7f8a26851",
            "patch": "@@ -0,0 +1,88 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_HLO_TRANSFORMS_CALL_SPLITTER_H_\n+#define XLA_HLO_TRANSFORMS_CALL_SPLITTER_H_\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/pass/hlo_pass_interface.h\"\n+#include \"xla/util.h\"\n+\n+namespace xla {\n+\n+// This pass allows splitting a single function call into two calls to two\n+// functions, where the original called computation is split across a specified\n+// boundary.\n+//\n+// For example, given the call\n+//\n+// (x) = call(a, b, c), to_apply={(mul(p0, (add(p1, p2)))}\n+//\n+// with the boundary predicate \"opcode == kMultiply\" we will get:\n+//\n+// (t) = call(b, c), to_apply={(add(p0, p1))}\n+// (y) = call(a, t), to_apply={(mul(p0, p1))}\n+//\n+// This also allow splitting functions \"vertically\" as opposed to \"horizontally\"\n+// e.g. for the same predicated, given:\n+//\n+// (x, y) = call(a, b, c), to_apply={(add(p0, p1), mul(p1, p2))}\n+//\n+// we should get:\n+//\n+// (x) = call(a, b), to_apply={(add(p0, p1))}\n+// (y) = call(b, c), to_apply={(mul(p0, p1))}\n+//\n+// More precisely:\n+//\n+// a) The instructions matching the boundary predicate go into the second call.\n+// b) Anything that consumes the results of the boundary instructions goes\n+//    into the second call.\n+// c) Anything that feeds the instructions from (a) and (b) goes into the\n+//    first call.\n+// d) The remaining instructions go into the first call.\n+// TODO(mkuper): This is not quite ready for production use yet.\n+class CallSplitter : public HloModulePass {\n+ public:\n+  // The `call_predicate` is used to select the calls that should be split. The\n+  // `boundary_predicate` is used to select the instructions that form the\n+  // boundary between the two calls.\n+  explicit CallSplitter(const HloPredicate& call_predicate,\n+                        const HloPredicate& boundary_predicate)\n+      : call_predicate_(call_predicate),\n+        boundary_predicate_(boundary_predicate) {}\n+\n+  ~CallSplitter() override = default;\n+\n+  static constexpr absl::string_view kName = \"call-splitter\";\n+  absl::string_view name() const override { return kName; }\n+\n+ protected:\n+  // Runs the pass on the given module. Returns whether the module was changed.\n+  absl::StatusOr<bool> RunImpl(\n+      HloModule* module,\n+      const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n+\n+ protected:\n+  HloPredicate call_predicate_;\n+  HloPredicate boundary_predicate_;\n+};\n+}  // namespace xla\n+\n+#endif  // XLA_HLO_TRANSFORMS_CALL_SPLITTER_H_"
        },
        {
            "sha": "912e053d634aa184d85202b7fb2496a3710fb536",
            "filename": "third_party/xla/xla/hlo/transforms/call_splitter_test.cc",
            "status": "added",
            "additions": 286,
            "deletions": 0,
            "changes": 286,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/006b29324e6fc25450146aa4cf8166c7f8a26851/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcall_splitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/006b29324e6fc25450146aa4cf8166c7f8a26851/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcall_splitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcall_splitter_test.cc?ref=006b29324e6fc25450146aa4cf8166c7f8a26851",
            "patch": "@@ -0,0 +1,286 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/hlo/transforms/call_splitter.h\"\n+\n+#include <memory>\n+#include <string>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/log/log.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/hlo/testlib/pattern_matcher_gmock.h\"\n+#include \"xla/hlo/testlib/test.h\"\n+#include \"xla/hlo/transforms/simplifiers/call_parameter_cleanup.h\"\n+#include \"xla/hlo/transforms/simplifiers/hlo_dce.h\"\n+#include \"xla/hlo/transforms/simplifiers/tuple_simplifier.h\"\n+#include \"xla/service/call_inliner.h\"\n+#include \"xla/service/pattern_matcher.h\"\n+#include \"xla/tsl/platform/status.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n+#include \"xla/xla_data.pb.h\"\n+\n+namespace xla {\n+\n+class CallSplitterTest : public HloHardwareIndependentTestBase {\n+ protected:\n+  CallSplitterTest()\n+      : HloHardwareIndependentTestBase(\n+            /*verifier_layout_sensitive=*/false,\n+            /*allow_mixed_precision_in_hlo_verifier=*/true) {}\n+};\n+\n+namespace {\n+\n+namespace m = ::xla::match;\n+\n+TEST_F(CallSplitterTest, SplitDownOneInstructionBasic) {\n+  const std::string module_str = R\"hlo(\n+HloModule module\n+\n+addmul {\n+  a = s32[] parameter(0)\n+  b = s32[] parameter(1)\n+  c = s32[] parameter(2)\n+  add = s32[] add(a, b)\n+  mul = s32[] multiply(add, c)\n+  ROOT tuple = (s32[]) tuple(mul)\n+}\n+\n+ENTRY entry {\n+  p0 = s32[] parameter(0)\n+  p1 = s32[] parameter(1)\n+  p2 = s32[] parameter(2)\n+  ROOT call = (s32[]) call(p0, p1, p2), to_apply=addmul\n+}\n+\n+)hlo\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(module_str));\n+\n+  auto split = [](const HloInstruction* instruction) -> bool {\n+    return instruction->opcode() == HloOpcode::kMultiply;\n+  };\n+\n+  CallSplitter splitter(/*call_predicate=*/HloPredicateTrue,\n+                        /*boundary_predicate=*/split);\n+  EXPECT_TRUE(splitter.Run(module.get()).value());\n+\n+  CallParameterCleanup cleanup;\n+  HloDCE dce;\n+  TupleSimplifier tuple_simplifier;\n+  TF_CHECK_OK(cleanup.Run(module.get()).status());\n+  TF_CHECK_OK(dce.Run(module.get()).status());\n+  TF_CHECK_OK(tuple_simplifier.Run(module.get()).status());\n+\n+  // Verify we got the two-call structure, with the mul in the second call.\n+  HloInstruction* call1;\n+  HloInstruction* call2;\n+  EXPECT_THAT(module->entry_computation()->root_instruction(),\n+              GmockMatch(m::Call(&call2, m::Parameter(2),\n+                                 m::GetTupleElement(m::Call(&call1), 0))));\n+  EXPECT_THAT(call1->to_apply()->root_instruction(),\n+              GmockMatch(m::Tuple(m::Add())));\n+  EXPECT_THAT(call2->to_apply()->root_instruction(),\n+              GmockMatch(m::Tuple(m::Multiply())));\n+\n+  // Verify we hooked up all the parameters correctly by simplifying again and\n+  // making sure it's equivalent to what we had in the beginning.\n+  CallInliner call_inliner;\n+  TF_CHECK_OK(call_inliner.Run(module.get()).status());\n+  TF_CHECK_OK(tuple_simplifier.Run(module.get()).status());\n+\n+  EXPECT_THAT(module->entry_computation()->root_instruction(),\n+              GmockMatch(m::Tuple(m::Multiply(\n+                  m::Add(m::Parameter(0), m::Parameter(1)), m::Parameter(2)))));\n+}\n+\n+TEST_F(CallSplitterTest, SplitDownOneInstructionIndependent) {\n+  const std::string module_str = R\"hlo(\n+HloModule module\n+\n+addmul {\n+  a = s32[] parameter(0)\n+  b = s32[] parameter(1)\n+  c = s32[] parameter(2)\n+  add = s32[] add(a, b)\n+  mul = s32[] multiply(b, c)\n+  ROOT tuple = (s32[], s32[]) tuple(add, mul)\n+}\n+\n+ENTRY entry {\n+  p0 = s32[] parameter(0)\n+  p1 = s32[] parameter(1)\n+  p2 = s32[] parameter(2)\n+  ROOT call = (s32[], s32[]) call(p0, p1, p2), to_apply=addmul\n+}\n+\n+)hlo\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(module_str));\n+\n+  auto split = [](const HloInstruction* instruction) -> bool {\n+    return instruction->opcode() == HloOpcode::kMultiply;\n+  };\n+\n+  CallSplitter splitter(/*call_predicate=*/HloPredicateTrue,\n+                        /*boundary_predicate=*/split);\n+  EXPECT_TRUE(splitter.Run(module.get()).value());\n+\n+  CallParameterCleanup cleanup;\n+  HloDCE dce;\n+  TupleSimplifier tuple_simplifier;\n+  TF_CHECK_OK(cleanup.Run(module.get()).status());\n+  TF_CHECK_OK(dce.Run(module.get()).status());\n+  TF_CHECK_OK(tuple_simplifier.Run(module.get()).status());\n+\n+  HloInstruction* call1;\n+  HloInstruction* call2;\n+  EXPECT_THAT(module->entry_computation()->root_instruction(),\n+              GmockMatch(m::Tuple(m::GetTupleElement(m::Call(&call1), 0),\n+                                  m::GetTupleElement(m::Call(&call2), 0))));\n+  EXPECT_THAT(call1->to_apply()->root_instruction(),\n+              GmockMatch(m::Tuple(m::Add(m::Parameter(0), m::Parameter(1)))));\n+  EXPECT_THAT(\n+      call2->to_apply()->root_instruction(),\n+      GmockMatch(m::Tuple(m::Multiply(m::Parameter(0), m::Parameter(1)))));\n+}\n+\n+TEST_F(CallSplitterTest, SplitDownMultipleInstructionsParallel) {\n+  const std::string module_str = R\"hlo(\n+HloModule module\n+\n+func {\n+  a = s32[] parameter(0)\n+  b = s32[] parameter(1)\n+  c = s32[] parameter(2)\n+  d = s32[] parameter(3)\n+  x = s32[] add(a, b)\n+  y = s32[] add(c, d)\n+  mul = s32[] multiply(x, x)\n+  sub = s32[] subtract(y, y)\n+  add = s32[] add(mul, sub)\n+  ROOT tuple = (s32[], s32[], s32[]) tuple(mul, sub, add)\n+}\n+\n+ENTRY entry {\n+  p0 = s32[] parameter(0)\n+  p1 = s32[] parameter(1)\n+  p2 = s32[] parameter(2)\n+  p3 = s32[] parameter(3)\n+  ROOT call = (s32[], s32[], s32[]) call(p0, p1, p2, p3), to_apply=func\n+}\n+)hlo\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(module_str));\n+\n+  auto split = [](const HloInstruction* instruction) -> bool {\n+    return instruction->opcode() == HloOpcode::kMultiply ||\n+           instruction->opcode() == HloOpcode::kSubtract;\n+  };\n+\n+  CallSplitter splitter(/*call_predicate=*/HloPredicateTrue,\n+                        /*boundary_predicate=*/split);\n+  EXPECT_TRUE(splitter.Run(module.get()).value());\n+\n+  CallParameterCleanup cleanup;\n+  HloDCE dce;\n+  TupleSimplifier tuple_simplifier;\n+  TF_CHECK_OK(cleanup.Run(module.get()).status());\n+  TF_CHECK_OK(dce.Run(module.get()).status());\n+  TF_CHECK_OK(tuple_simplifier.Run(module.get()).status());\n+\n+  HloInstruction* call1;\n+  HloInstruction* call1_copy;\n+  HloInstruction* call2;\n+  EXPECT_THAT(module->entry_computation()->root_instruction(),\n+              GmockMatch(m::Call(&call2, m::GetTupleElement(m::Call(&call1), 0),\n+                                 m::GetTupleElement(m::Call(&call1_copy), 1))));\n+  EXPECT_EQ(call1, call1_copy);\n+  EXPECT_THAT(call1->to_apply()->root_instruction(),\n+              GmockMatch(m::Tuple(m::Add(m::Parameter(0), m::Parameter(1)),\n+                                  m::Add(m::Parameter(2), m::Parameter(3)))));\n+}\n+\n+TEST_F(CallSplitterTest, SplitDownMultipleInstructionsDependent) {\n+  const std::string module_str = R\"hlo(\n+HloModule module\n+\n+func {\n+  a = s32[] parameter(0)\n+  b = s32[] parameter(1)\n+  c = s32[] parameter(2)\n+  d = s32[] parameter(3)\n+  x = s32[] add(a, b)\n+  y = s32[] add(c, d)\n+  mul = s32[] multiply(x, x)\n+  sub = s32[] subtract(mul, y)\n+  ROOT tuple = (s32[], s32[]) tuple(mul, sub)\n+}\n+\n+ENTRY entry {\n+  p0 = s32[] parameter(0)\n+  p1 = s32[] parameter(1)\n+  p2 = s32[] parameter(2)\n+  p3 = s32[] parameter(3)\n+  ROOT call = (s32[], s32[]) call(p0, p1, p2, p3), to_apply=func\n+}\n+)hlo\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(module_str));\n+\n+  auto split = [](const HloInstruction* instruction) -> bool {\n+    return instruction->opcode() == HloOpcode::kMultiply ||\n+           instruction->opcode() == HloOpcode::kSubtract;\n+  };\n+\n+  CallSplitter splitter(/*call_predicate=*/HloPredicateTrue,\n+                        /*boundary_predicate=*/split);\n+  EXPECT_TRUE(splitter.Run(module.get()).value());\n+\n+  CallParameterCleanup cleanup;\n+  HloDCE dce;\n+  TupleSimplifier tuple_simplifier;\n+  TF_CHECK_OK(cleanup.Run(module.get()).status());\n+  TF_CHECK_OK(dce.Run(module.get()).status());\n+  TF_CHECK_OK(tuple_simplifier.Run(module.get()).status());\n+\n+  HloInstruction* call1;\n+  HloInstruction* call1_copy;\n+  HloInstruction* call2;\n+  EXPECT_THAT(module->entry_computation()->root_instruction(),\n+              GmockMatch(m::Call(&call2, m::GetTupleElement(m::Call(&call1), 0),\n+                                 m::GetTupleElement(m::Call(&call1_copy), 1))));\n+  EXPECT_EQ(call1, call1_copy);\n+  EXPECT_THAT(call1->to_apply()->root_instruction(),\n+              GmockMatch(m::Tuple(m::Add(m::Parameter(0), m::Parameter(1)),\n+                                  m::Add(m::Parameter(2), m::Parameter(3)))));\n+  EXPECT_THAT(call2->to_apply()->root_instruction(),\n+              GmockMatch(m::Tuple(m::Multiply(), m::Subtract())));\n+}\n+\n+}  // namespace\n+\n+}  // namespace xla"
        }
    ],
    "stats": {
        "total": 702,
        "additions": 702,
        "deletions": 0
    }
}