{
    "author": "pavithraes",
    "message": "PR #33820: Update `shapes.md` with example and memory location info\n\nImported from GitHub PR https://github.com/openxla/xla/pull/33820\n\n**üìù Summary of Changes**\n\n- Added an example for how to read an Op, derived from [JAX scaling book](https://jax-ml.github.io/scaling-book/profiling/#how-to-read-an-xla-op).\n- Added description for Memory Space Identifier (also derived from the book), because it was not documented in the XLA docs.\n- Added relevant cross-links between pages.\n\n**üéØ Justification**\n\nWhile there are notes about Shape, Layout, and Tiling, there was some gap in contextualizing this information with an example. Additionally, there was no information about Memory Space Identifiers.\n\nThese were originally noted/flagged by @GleasonK and @harini-sridhar.\n\n**üöÄ Kind of Contribution**\n\nüìö Documentation\n\nCopybara import of the project:\n\n--\nd011b9f22cbf4456633feeb6554f8cd5b6bf008a by Pavithra Eswaramoorthy <pavithraes@outlook.com>:\n\nAdd example, and describe memory space identifier\n\n--\n3a397678507cf7cb0c0e61fb42b26a8306ccf3bb by Pavithra Eswaramoorthy <pavithraes@outlook.com>:\n\nAdd link to shapes.md & tiled_layout.md\n\n--\n5c5c6e2aefc664b59c53f15fb085f7e6223871bc by Pavithra Eswaramoorthy <pavithraes@outlook.com>:\n\nAddress review comments: Add attributes, clean up descriptions\n\n--\n8608b1e8ce1ac11b6f58bea262b4a3218f8dac6b by Pavithra Eswaramoorthy <pavithraes@outlook.com>:\n\nAdd note about % sign in Op name\n\n--\ncc810bf413bebed9fdf0a4582aebb76af96f3334 by Pavithra Eswaramoorthy <pavithraes@outlook.com>:\n\nAdd a new example, spilt explanations\n\nMerging this change closes #33820\n\nPiperOrigin-RevId: 839214407",
    "sha": "a9732391861093f36043be75dd06a1f352603e38",
    "files": [
        {
            "sha": "b142850afcd857c98e74201b3d40cc2656677943",
            "filename": "third_party/xla/docs/operation_semantics.md",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a9732391861093f36043be75dd06a1f352603e38/third_party%2Fxla%2Fdocs%2Foperation_semantics.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a9732391861093f36043be75dd06a1f352603e38/third_party%2Fxla%2Fdocs%2Foperation_semantics.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Foperation_semantics.md?ref=a9732391861093f36043be75dd06a1f352603e38",
            "patch": "@@ -13,6 +13,9 @@ arbitrary-dimensional array. For convenience, special cases have more specific\n and familiar names; for example a *vector* is a 1-dimensional array and a\n *matrix* is a 2-dimensional array.\n \n+Learn more about the structure of an Op in [*Shapes and layout*](shapes.md) and\n+[*Tiled Layout*](tiled_layout.md).\n+\n ## Abs\n \n See also"
        },
        {
            "sha": "9ea8dbbc7fdce1114eef677f8c99952767b24f48",
            "filename": "third_party/xla/docs/shapes.md",
            "status": "modified",
            "additions": 66,
            "deletions": 1,
            "changes": 67,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a9732391861093f36043be75dd06a1f352603e38/third_party%2Fxla%2Fdocs%2Fshapes.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a9732391861093f36043be75dd06a1f352603e38/third_party%2Fxla%2Fdocs%2Fshapes.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Fshapes.md?ref=a9732391861093f36043be75dd06a1f352603e38",
            "patch": "@@ -1,11 +1,65 @@\n # Shapes and layout\n \n+## Structure of an XLA Op\n+\n+Consider an example HLO:\n+\n+```\n+add.936 = bf16[8,1,1280,16384]{3,2,0,1:T(8,128)(2,1)}\n+          add(exponential.183, broadcast.3115)\n+```\n+\n+This consists of the following components:\n+\n+*   Op Name: `add.936`\n+    *   This is the unique name for the operation.\n+*   Shape: `bf16[8,1,1280,16384]`\n+    *   This is the output shape of the Op. Here the dtype is\n+        [bf316](https://en.wikipedia.org/wiki/Bfloat16_floating-point_format)\n+        and the shape is `[8,1,1280,16384]`.\n+*   Layout (with Tiling): `3,2,0,1:T(8,128)(2,1)`\n+    *   This describes how the array is stored in memory. `3,2,0,1` denotes the\n+        order of the axes in memory (i.e., column major, row major, etc.) and\n+        `T(8,128)(2,1)` denotes the tiling & padding used.\n+    *   Layout is optional. If not specified, there is no tiling and the\n+        dimensions are assumed to be ordered from most-major to most-minor.\n+*   Operation: `add`\n+    *   The operation being performed. Here, it is\n+        [Add](operation_semantics.md#add), which is also mentioned in the Op\n+        name.\n+*   Arguments: `exponential.183`, `broadcast.3115`\n+    *   This operation takes two arguments, specified with their unique names.\n+\n+Let's consider another example, a fusion Op:\n+\n+```\n+%fusion.3 = bf16[32,32,4096]{2,1,0:T(8,128)(2,1)S(1)}\n+            fusion(bf16[32,32,8192]{2,1,0:T(8,128)(2,1)S(1)} %fusion.32),\n+            kind=kCustom, calls=%all-reduce-scatter.3\n+```\n+\n+In addition to the previously described components, this consists of:\n+\n+*   Attributes: `kind` and `calls`\n+    *   These provide more information about the operation being performed, in\n+        this case: fusion.\n+*   Memory location (memory space identifier): `S(1)`\n+    *   This denotes the memory space/location where the array is stored. `S(1)`\n+        here denotes this array lives in VMEM (on a TPU).\n+*   Shape and layout details for the input argument `%fusion.32`\n+\n+The following sections describe Shapes, [Layout](#layout), and\n+[Memory Space Identifiers](#memory-space-identifiers). You can learn more about\n+Tiling in [Tiled Layout](tiled_layout.md).\n+\n+## Shapes\n+\n The XLA `ShapeProto` proto\n ([xla_data.proto](https://github.com/openxla/xla/tree/main/xla/xla_data.proto))\n describes the number of dimensions, size, and data type of an N-dimensional\n array (*array* in short).\n \n-## Terminology, notation, and conventions\n+### Terminology, notation, and conventions\n \n NOTE: in the past, XLA has used the term \"rank\" to mean the number of dimensions\n of an array. We have stopped this usage as it's inconsistent with the matrix\n@@ -137,3 +191,14 @@ index for each dimension. Linear indices are a single `int64` value which\n indexes into the buffer holding the array. See `shape_util.h` and\n `layout_util.h` in the same directory for utilities that simplify creation and\n manipulation of shapes and layouts.\n+\n+## Memory Space Identifiers\n+\n+In HLO, each array may be annotated with a memory space identifier, written as\n+S(n).\n+\n+*   `S(0)` (often omitted) denotes device high bandwidth memory (HBM).\n+*   `S(1)` represents on device virtual memory (VMEM).\n+*   `S(2)`, `S(3)`, etc., correspond to additional device specific memory\n+    spaces.\n+*   `S(5)` indicates host memory."
        }
    ],
    "stats": {
        "total": 70,
        "additions": 69,
        "deletions": 1
    }
}