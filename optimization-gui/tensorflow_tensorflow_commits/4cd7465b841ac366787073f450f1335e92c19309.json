{
    "author": "sergachev",
    "message": "PR #32388: [GPU] Sub-byte collective normalization: support collectives with non-minor-most last dimension.\n\nImported from GitHub PR https://github.com/openxla/xla/pull/32388\n\nüìù Summary of Changes\nSupport collectives with non-minor-most last dimension in the sub-byte collective normalization pass.\n\nüéØ Justification\nMakes more collectives efficient, not require type conversion.\n\nüöÄ Kind of Contribution\nPerformance Improvement.\n\nüìä Benchmark (for Performance Improvements)\n```\nBefore:\n\n## Execution time, file=u4_all_gather_1x8.hlo repeat=1 duration=68384ns\n## Execution time, file=u4_all_gather_1x8.hlo repeat=2 duration=67744ns\n## Execution time, file=u4_all_gather_1x8.hlo repeat=3 duration=66976ns\n## Execution time, file=u4_all_gather_1x8.hlo repeat=4 duration=67040ns\n## Execution time, file=u4_all_gather_1x8.hlo repeat=5 duration=66816ns\n\nAfter:\n\n## Execution time, file=u4_all_gather_1x8.hlo repeat=1 duration=41216ns\n## Execution time, file=u4_all_gather_1x8.hlo repeat=2 duration=40960ns\n## Execution time, file=u4_all_gather_1x8.hlo repeat=3 duration=40960ns\n## Execution time, file=u4_all_gather_1x8.hlo repeat=4 duration=41056ns\n## Execution time, file=u4_all_gather_1x8.hlo repeat=5 duration=40960ns\n```\nMeasured on 8xH100 DGX.\n\nüß™ Unit Tests:\nyes\n\nüß™ Execution Tests:\nyes\nCopybara import of the project:\n\n--\na3777523ffffbcc59da285544e3fb5575d098b9c by Ilia Sergachev <isergachev@nvidia.com>:\n\n[GPU] Sub-byte collective normalization: support collectives with non-minor-most last dimension.\n\nMerging this change closes #32388\n\nPiperOrigin-RevId: 820585923",
    "sha": "4cd7465b841ac366787073f450f1335e92c19309",
    "files": [
        {
            "sha": "0d21d11fdc1de2c2f6ed0d6d7f02306b1a50f548",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/sub_byte_collective_normalization.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4cd7465b841ac366787073f450f1335e92c19309/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fsub_byte_collective_normalization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4cd7465b841ac366787073f450f1335e92c19309/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fsub_byte_collective_normalization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fsub_byte_collective_normalization.cc?ref=4cd7465b841ac366787073f450f1335e92c19309",
            "patch": "@@ -47,7 +47,7 @@ HloInstruction* ReshapeAndCastToWiderType(HloInstruction* input,\n \n   std::vector<int64_t> bitcast_dimensions(input_shape.dimensions().begin(),\n                                           input_shape.dimensions().end());\n-  bitcast_dimensions.back() /= ratio;\n+  bitcast_dimensions[input_shape.layout().minor_to_major(0)] /= ratio;\n   bitcast_dimensions.push_back(ratio);\n   Shape bitcast_shape =\n       ShapeUtil::MakeShape(input_shape.element_type(), bitcast_dimensions);\n@@ -97,10 +97,9 @@ bool CanBeRepresentedAs(const Shape& shape, const PrimitiveType casted_type) {\n   const int64_t ratio = primitive_util::BitWidth(casted_type) /\n                         primitive_util::BitWidth(shape.element_type());\n   return primitive_util::IsSubByteNonPredType(shape.element_type()) &&\n-         ShapeUtil::LastDimIsMinorMost(shape) &&\n          shape.layout().element_size_in_bits() ==\n              primitive_util::BitWidth(shape.element_type()) &&\n-         shape.dimensions().back() % ratio == 0;\n+         shape.dimensions(shape.layout().minor_to_major(0)) % ratio == 0;\n }\n \n class SubByteCollectiveNormalizationVisitor : public DfsHloRewriteVisitor {\n@@ -173,7 +172,7 @@ SubByteCollectiveNormalizationVisitor::ProcessCollectiveInstruction(\n \n   std::vector<int64_t> new_collective_dimensions(\n       hlo.shape().dimensions().begin(), hlo.shape().dimensions().end());\n-  new_collective_dimensions.back() /= ratio;\n+  new_collective_dimensions[hlo.shape().layout().minor_to_major(0)] /= ratio;\n   Shape new_collective_shape =\n       ShapeUtil::MakeShape(casted_type_, new_collective_dimensions);\n   if (hlo.shape().has_layout()) {"
        },
        {
            "sha": "92be90bbaa391c4b1a752942ad3aba79b91ccac6",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/sub_byte_collective_normalization_test.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 10,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4cd7465b841ac366787073f450f1335e92c19309/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fsub_byte_collective_normalization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4cd7465b841ac366787073f450f1335e92c19309/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fsub_byte_collective_normalization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fsub_byte_collective_normalization_test.cc?ref=4cd7465b841ac366787073f450f1335e92c19309",
            "patch": "@@ -44,16 +44,6 @@ e {\n                                      /*expect_change=*/false));\n }\n \n-TEST_F(SubByteCollectiveNormalizationTest, SkipNonMinorMost) {\n-  TF_ASSERT_OK(RunAndCheckHloRewrite(R\"(\n-e {\n- a = s4[32,16]{0,1:E(4)} parameter(0)\n- b = s4[32,16]{0,1:E(4)} all-gather(a), dimensions={0}\n-})\",\n-                                     SubByteCollectiveNormalization(),\n-                                     /*expect_change=*/false));\n-}\n-\n TEST_F(SubByteCollectiveNormalizationTest, SkipOddElementCount) {\n   TF_ASSERT_OK(RunAndCheckHloRewrite(R\"(\n e {\n@@ -91,6 +81,23 @@ CHECK-NEXT: s4[8,8]{1,0:E(4)} bitcast\n )\");\n }\n \n+TEST_F(SubByteCollectiveNormalizationTest,\n+       TransformAllGatherWithNonMinorMostLastDim) {\n+  RunAndFilecheckHloRewrite(R\"(\n+e {\n+ a = s4[32,16]{0,1:E(4)} parameter(0)\n+ b = s4[32,16]{0,1:E(4)} all-gather(a), dimensions={0}\n+})\",\n+                            SubByteCollectiveNormalization(), R\"(\n+CHECK: s4[32,16]{0,1:E(4)} parameter\n+CHECK-NEXT: s4[16,16,2]{2,0,1:E(4)} bitcast\n+CHECK-NEXT: s8[16,16]{0,1} bitcast-convert\n+CHECK-NEXT: s8[16,16]{0,1} all-gather\n+CHECK-NEXT: s4[16,16,2]{2,0,1:E(4)} bitcast-convert\n+CHECK-NEXT: s4[32,16]{0,1:E(4)} bitcast\n+)\");\n+}\n+\n TEST_F(SubByteCollectiveNormalizationTest, SkipTinyAllToAll) {\n   TF_ASSERT_OK(RunAndCheckHloRewrite(R\"(\n HloModule m, replica_count=2"
        },
        {
            "sha": "74a24914d4b7186c6411ea21a8826a1993bee082",
            "filename": "third_party/xla/xla/service/gpu/tests/sub_byte_collectives.hlo",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4cd7465b841ac366787073f450f1335e92c19309/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsub_byte_collectives.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4cd7465b841ac366787073f450f1335e92c19309/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsub_byte_collectives.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fsub_byte_collectives.hlo?ref=4cd7465b841ac366787073f450f1335e92c19309",
            "patch": "@@ -12,6 +12,21 @@ e {\n \n // -----\n \n+e {\n+  a = s4[4,2]{1,0:E(4)} parameter(0)\n+  b = s4[4,4]{1,0:E(4)} all-gather(a), dimensions={1}\n+}\n+\n+// CHECK-NOT: convert\n+// CHECK:      s4[4,2]{1,0:E(4)} parameter\n+// CHECK-NEXT: s4[2,4]{1,0:E(4)} transpose\n+// CHECK-NEXT: s8[2,2]{0,1} bitcast\n+// CHECK:      s8[2,4]{0,1} all-gather-done\n+// CHECK-NEXT: s4[4,4]{1,0:E(4)} bitcast\n+// CHECK-NEXT: s4[4,4]{1,0:E(4)} transpose\n+\n+// -----\n+\n e {\n   a = f4e2m1fn[80,20]{1,0:E(4)} parameter(0)\n   b = f4e2m1fn[80,20]{1,0:E(4)} all-to-all(a), dimensions={0}"
        },
        {
            "sha": "b8b886f4483de08e46c832aff40255ef69b69ad4",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test.cc",
            "status": "modified",
            "additions": 45,
            "deletions": 1,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4cd7465b841ac366787073f450f1335e92c19309/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4cd7465b841ac366787073f450f1335e92c19309/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc?ref=4cd7465b841ac366787073f450f1335e92c19309",
            "patch": "@@ -4476,7 +4476,7 @@ TEST_P(AllReduceTest, AsyncAllReduce_8GPUs_2ReplicasPerGroup) {\n   }\n }\n \n-TEST_F(CollectiveOpsTestE2E, OptimizedSubByteAllGatherOutputIsCorrect) {\n+TEST_F(CollectiveOpsTestE2E, OptimizedSubByteAllGatherOnDim0OutputIsCorrect) {\n   constexpr int kNumReplicas = 2;\n   ASSERT_GE(hlo_runner_->device_count(), kNumReplicas)\n       << \"Test requires at least \" << kNumReplicas << \" devices (\"\n@@ -4517,6 +4517,50 @@ TEST_F(CollectiveOpsTestE2E, OptimizedSubByteAllGatherOutputIsCorrect) {\n   }\n }\n \n+TEST_F(CollectiveOpsTestE2E, OptimizedSubByteAllGatherOnDim1OutputIsCorrect) {\n+  constexpr int kNumReplicas = 2;\n+  ASSERT_GE(hlo_runner_->device_count(), kNumReplicas)\n+      << \"Test requires at least \" << kNumReplicas << \" devices (\"\n+      << hlo_runner_->device_count() << \" available)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto unoptimized_module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+    HloModule m, replica_count=2\n+\n+    e {\n+      a = s4[4,2]{1,0:E(4)} constant({{0,1},{2,3},{4,5},{5,4}})\n+      b = s4[4,4]{1,0:E(4)} all-gather(a), dimensions={1}\n+    })\"));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto executable, hlo_runner_->CreateExecutable(\n+                                               std::move(unoptimized_module),\n+                                               /*run_hlo_passes=*/true));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(const HloModule* const module,\n+                          hlo_runner_->HloModuleFromWrapped(executable.get()));\n+\n+  const HloInstruction* root = module->entry_computation()->root_instruction();\n+  EXPECT_THAT(root, GmockMatch(m::Fusion(\n+                        m::Bitcast(m::AllGatherDone().WithShape(S8, {2, 4})))));\n+  EXPECT_THAT(root->fused_expression_root(),\n+              GmockMatch(m::Transpose(m::Parameter())));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::vector<Literal> result,\n+                          ExecuteReplicated(executable.get(), kNumReplicas));\n+\n+  const Literal expected_result =\n+      LiteralUtil::CreateR2<s4>({{s4(0), s4(1), s4(0), s4(1)},\n+                                 {s4(2), s4(3), s4(2), s4(3)},\n+                                 {s4(4), s4(5), s4(4), s4(5)},\n+                                 {s4(5), s4(4), s4(5), s4(4)}});\n+\n+  ASSERT_EQ(result.size(), kNumReplicas);\n+  for (int i = 0; i < kNumReplicas; ++i) {\n+    EXPECT_TRUE(LiteralTestUtil::Equal(expected_result, result[i]))\n+        << \"Results differ at replica \" << i;\n+  }\n+}\n+\n INSTANTIATE_TEST_SUITE_P(\n     AllReduceTest, AllReduceTest,\n     ::testing::Combine(::testing::Bool(), ::testing::Bool()),"
        },
        {
            "sha": "970ba9d91512d7b70d62aa9507170885431e8aac",
            "filename": "third_party/xla/xla/tools/benchmarks/hlo/u4_all_gather_1x8.hlo",
            "status": "added",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4cd7465b841ac366787073f450f1335e92c19309/third_party%2Fxla%2Fxla%2Ftools%2Fbenchmarks%2Fhlo%2Fu4_all_gather_1x8.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4cd7465b841ac366787073f450f1335e92c19309/third_party%2Fxla%2Fxla%2Ftools%2Fbenchmarks%2Fhlo%2Fu4_all_gather_1x8.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fbenchmarks%2Fhlo%2Fu4_all_gather_1x8.hlo?ref=4cd7465b841ac366787073f450f1335e92c19309",
            "patch": "@@ -0,0 +1,4 @@\n+e {\n+  a = u4[1024,512]{1,0:E(4)} parameter(0)\n+  b = u4[1024,4096]{1,0:E(4)} all-gather(a), dimensions={1}\n+}"
        }
    ],
    "stats": {
        "total": 99,
        "additions": 84,
        "deletions": 15
    }
}