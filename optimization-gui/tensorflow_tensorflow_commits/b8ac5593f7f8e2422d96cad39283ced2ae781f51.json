{
    "author": "ezhulenev",
    "message": "[xla:jit] Optimize building XLA arguments\n\nResizing out vector ahead of time leads to running expensive default constructor for shape: (1) use std::monostate as a default value (2) emplace XLA arguments one by one\n\nPiperOrigin-RevId: 806182797",
    "sha": "b8ac5593f7f8e2422d96cad39283ced2ae781f51",
    "files": [
        {
            "sha": "c65bb6c44b10797817cc1426fafdbdd0f7b1fd1e",
            "filename": "tensorflow/compiler/jit/BUILD",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b8ac5593f7f8e2422d96cad39283ced2ae781f51/tensorflow%2Fcompiler%2Fjit%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b8ac5593f7f8e2422d96cad39283ced2ae781f51/tensorflow%2Fcompiler%2Fjit%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2FBUILD?ref=b8ac5593f7f8e2422d96cad39283ced2ae781f51",
            "patch": "@@ -633,6 +633,7 @@ cc_library(\n         \":xla_tensor\",\n         \"//tensorflow/compiler/tf2xla:common\",\n         \"//tensorflow/compiler/tf2xla:xla_compiler\",\n+        \"//tensorflow/compiler/tf2xla:xla_resource\",\n         \"//tensorflow/core:core_cpu_internal\",\n         \"//tensorflow/core:framework\",\n         \"//tensorflow/core:framework_internal\",\n@@ -647,17 +648,31 @@ cc_library(\n         \"@com_google_absl//absl/cleanup\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n         \"@local_xla//xla:shape_util\",\n         \"@local_xla//xla:status_macros\",\n+        \"@local_xla//xla:util\",\n         \"@local_xla//xla/client:local_client\",\n+        \"@local_xla//xla/hlo/ir:hlo\",\n         \"@local_xla//xla/pjrt:pjrt_client\",\n         \"@local_xla//xla/pjrt:pjrt_common\",\n+        \"@local_xla//xla/pjrt:pjrt_executable\",\n         \"@local_xla//xla/pjrt:pjrt_future\",\n+        \"@local_xla//xla/service:executable\",\n+        \"@local_xla//xla/service:maybe_owning_device_memory\",\n         \"@local_xla//xla/service:shaped_buffer\",\n+        \"@local_xla//xla/service:transfer_manager\",\n+        \"@local_xla//xla/stream_executor:device_memory\",\n         \"@local_xla//xla/stream_executor:device_memory_allocator\",\n+        \"@local_xla//xla/stream_executor:event\",\n+        \"@local_xla//xla/stream_executor:platform\",\n         \"@local_xla//xla/stream_executor:platform_manager\",\n+        \"@local_xla//xla/stream_executor/host:host_platform_id\",\n         \"@local_xla//xla/tsl/framework:device_id_utils\",\n         \"@local_xla//xla/tsl/framework:serving_device_selector_policies\",\n     ],"
        },
        {
            "sha": "f26fcd34df75839f3a29a6a3cfab4ccf8e19c803",
            "filename": "tensorflow/compiler/jit/xla_launch_util.cc",
            "status": "modified",
            "additions": 36,
            "deletions": 14,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b8ac5593f7f8e2422d96cad39283ced2ae781f51/tensorflow%2Fcompiler%2Fjit%2Fxla_launch_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b8ac5593f7f8e2422d96cad39283ced2ae781f51/tensorflow%2Fcompiler%2Fjit%2Fxla_launch_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fxla_launch_util.cc?ref=b8ac5593f7f8e2422d96cad39283ced2ae781f51",
            "patch": "@@ -15,53 +15,76 @@ limitations under the License.\n \n #include \"tensorflow/compiler/jit/xla_launch_util.h\"\n \n+#include <cstddef>\n #include <cstdint>\n #include <memory>\n #include <optional>\n-#include <set>\n+#include <string>\n #include <utility>\n #include <vector>\n \n #include \"absl/algorithm/container.h\"\n #include \"absl/cleanup/cleanup.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/flat_hash_set.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_join.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n #include \"tensorflow/compiler/jit/pjrt_tensor_buffer.h\"\n #include \"tensorflow/compiler/jit/pjrt_tensor_buffer_util.h\"\n #include \"tensorflow/compiler/jit/variable_info.h\"\n #include \"tensorflow/compiler/jit/variable_info_util.h\"\n+#include \"tensorflow/compiler/jit/xla_tensor.h\"\n #include \"tensorflow/compiler/tf2xla/const_analysis.h\"\n #include \"tensorflow/compiler/tf2xla/shape_util.h\"\n #include \"tensorflow/compiler/tf2xla/xla_compiler.h\"\n+#include \"tensorflow/compiler/tf2xla/xla_helpers.h\"\n+#include \"tensorflow/compiler/tf2xla/xla_resource.h\"\n #include \"xla/client/local_client.h\"\n+#include \"xla/hlo/ir/hlo_input_output_alias_config.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_common.h\"\n+#include \"xla/pjrt/pjrt_executable.h\"\n #include \"xla/pjrt/pjrt_future.h\"\n+#include \"xla/service/executable.h\"\n+#include \"xla/service/maybe_owning_device_memory.h\"\n+#include \"xla/service/shaped_buffer.h\"\n+#include \"xla/service/transfer_manager.h\"\n+#include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/event.h\"\n+#include \"xla/stream_executor/host/host_platform_id.h\"\n+#include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n #include \"xla/tsl/framework/device_id_utils.h\"\n #include \"xla/tsl/framework/serving_device_selector_policies.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/status.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n #include \"tensorflow/core/common_runtime/dma_helper.h\"\n #include \"tensorflow/core/common_runtime/gpu/gpu_serving_device_selector.h\"\n #include \"tensorflow/core/common_runtime/gpu_device_context.h\"\n #include \"tensorflow/core/framework/allocator.h\"\n-#include \"tensorflow/core/framework/op.h\"\n+#include \"tensorflow/core/framework/device_base.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/resource_handle.h\"\n #include \"tensorflow/core/framework/resource_mgr.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n #include \"tensorflow/core/lib/core/refcount.h\"\n #include \"tensorflow/core/platform/errors.h\"\n #include \"tensorflow/core/platform/status.h\"\n-#include \"tensorflow/core/platform/statusor.h\"\n #include \"tensorflow/core/tfrt/common/async_value_tensor.h\"\n-#include \"tensorflow/core/util/stream_executor_util.h\"\n-#include \"tsl/platform/status.h\"\n-#include \"tsl/platform/statusor.h\"\n \n namespace tensorflow {\n namespace {\n@@ -343,7 +366,7 @@ absl::StatusOr<std::vector<VariableInfo>> GatherVariableInfo(\n         compilation_result.resource_updates[i];\n     int actual_input_index = write.input_index - missing_ctx_input_prefix;\n     if (actual_input_index < 0 || actual_input_index >= ctx->num_inputs()) {\n-      return errors::Internal(\"Invalid input index for variable write.\");\n+      return xla::Internal(\"Invalid input index for variable write.\");\n     }\n \n     const ResourceHandle handle = HandleFromInput(ctx, actual_input_index);\n@@ -381,8 +404,8 @@ absl::Status XlaComputationLaunchContext::PopulateOutputs(\n         xla::ShapeUtil::MakeTupleShape({nontuple_buffer.on_device_shape()}),\n         output.device_ordinal());\n     buffer.buffers().CopySubtreeFrom(nontuple_buffer.buffers(),\n-                                     /*source_base_index=*/{},\n-                                     /*target_base_index=*/{0});\n+                                     /*src_index=*/{},\n+                                     /*dst_index=*/{0});\n     output = ScopedShapedBuffer(std::move(buffer), output.memory_allocator());\n   }\n \n@@ -394,7 +417,7 @@ absl::Status XlaComputationLaunchContext::PopulateOutputs(\n \n   for (const XlaOutputDescription& descr : compilation_result->outputs) {\n     if (descr.type == DT_VARIANT) {\n-      return errors::Unimplemented(\n+      return xla::Unimplemented(\n           \"Support for TensorList crossing the XLA/TF boundary \"\n           \"is not implemented\");\n     }\n@@ -519,7 +542,7 @@ XlaComputationLaunchContext::BuildXlaCompilerArguments(\n           << absl::StrJoin(must_be_constant_idxs, \",\") << \"} out of \"\n           << inputs.size() << \" args\";\n   std::vector<XlaCompiler::Argument> out;\n-  out.resize(inputs.size());\n+  out.reserve(inputs.size());\n \n   // TODO(cheshire): Avoid duplication with framework/op_kernel.h\n   DeviceContext* device_context = nullptr;\n@@ -542,8 +565,8 @@ XlaComputationLaunchContext::BuildXlaCompilerArguments(\n   TF_CHECK_OK(CreateVariableInfoLookup(variable_args, variable_info_lookup));\n   for (int64_t input_num = 0; input_num < inputs.size(); ++input_num) {\n     const Tensor* input = inputs[input_num];\n+    XlaCompiler::Argument& arg = out.emplace_back();\n \n-    XlaCompiler::Argument& arg = out[input_num];\n     if (variable_info_lookup.count(input_num) && device != nullptr) {\n       // Handles resource variables.\n       TF_RET_CHECK(input->dtype() == DT_RESOURCE);\n@@ -809,8 +832,7 @@ xla::ExecuteOptions GetPjRtExecuteOptions(\n }\n \n DeviceType GetDeviceType(OpKernelContext* ctx) {\n-  auto* device =\n-      tensorflow::down_cast<Device*>(ctx->device()->UnderlyingDevice());\n+  auto* device = tsl::down_cast<Device*>(ctx->device()->UnderlyingDevice());\n   return DeviceType(device->device_type());\n }\n "
        },
        {
            "sha": "8cb797a9a9b214570c67b145ca83bd1a1bc2ba3f",
            "filename": "tensorflow/compiler/mlir/tf2xla/api/v1/compile_mlir_util_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b8ac5593f7f8e2422d96cad39283ced2ae781f51/tensorflow%2Fcompiler%2Fmlir%2Ftf2xla%2Fapi%2Fv1%2Fcompile_mlir_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b8ac5593f7f8e2422d96cad39283ced2ae781f51/tensorflow%2Fcompiler%2Fmlir%2Ftf2xla%2Fapi%2Fv1%2Fcompile_mlir_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftf2xla%2Fapi%2Fv1%2Fcompile_mlir_util_test.cc?ref=b8ac5593f7f8e2422d96cad39283ced2ae781f51",
            "patch": "@@ -39,6 +39,7 @@ limitations under the License.\n #include \"tensorflow/compiler/tf2xla/xla_helpers.h\"\n #include \"xla/hlo/builder/xla_builder.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n+#include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -259,7 +260,8 @@ absl::StatusOr<xla::XlaComputation> BuildHloFromGraph(\n   mlir::MLIRContext mlir_context;\n   llvm::SmallVector<xla::XlaOp, 4> xla_params;\n   for (int i = 0; i < xla_args.size(); ++i) {\n-    xla_params.push_back(Parameter(&builder, i, std::get<1>(xla_args[i].shape),\n+    xla_params.push_back(Parameter(&builder, i,\n+                                   std::get<xla::Shape>(xla_args[i].shape),\n                                    \"arg\" + std::to_string(i)));\n   }\n   std::vector<xla::XlaOp> returns(1);"
        },
        {
            "sha": "5ca74d2def69502a71c482bbc7524fb29627aff5",
            "filename": "tensorflow/compiler/tf2xla/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b8ac5593f7f8e2422d96cad39283ced2ae781f51/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b8ac5593f7f8e2422d96cad39283ced2ae781f51/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD?ref=b8ac5593f7f8e2422d96cad39283ced2ae781f51",
            "patch": "@@ -836,9 +836,10 @@ cc_library(\n         \":host_compute_metadata_proto_cc\",\n         \":xla_resource\",\n         \"//tensorflow/core:framework\",\n-        \"@com_google_absl//absl/types:optional\",\n+        \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//llvm:Support\",\n+        \"@local_xla//xla:shape_util\",\n         \"@local_xla//xla/hlo/builder:xla_builder\",\n         \"@local_xla//xla/hlo/ir:hlo\",\n     ],"
        },
        {
            "sha": "68a736f71e713d57ec330f7b2550fb71fc096d98",
            "filename": "tensorflow/compiler/tf2xla/xla_argument.h",
            "status": "modified",
            "additions": 17,
            "deletions": 9,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b8ac5593f7f8e2422d96cad39283ced2ae781f51/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_argument.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b8ac5593f7f8e2422d96cad39283ced2ae781f51/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_argument.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_argument.h?ref=b8ac5593f7f8e2422d96cad39283ced2ae781f51",
            "patch": "@@ -16,13 +16,21 @@ limitations under the License.\n #ifndef TENSORFLOW_COMPILER_TF2XLA_XLA_ARGUMENT_H_\n #define TENSORFLOW_COMPILER_TF2XLA_XLA_ARGUMENT_H_\n \n-#include \"absl/types/optional.h\"\n+#include <cstdint>\n+#include <optional>\n+#include <set>\n+#include <string>\n+#include <variant>\n+#include <vector>\n+\n+#include \"absl/container/inlined_vector.h\"\n #include \"absl/types/span.h\"\n #include \"tensorflow/compiler/tf2xla/host_compute_metadata.pb.h\"\n #include \"tensorflow/compiler/tf2xla/xla_resource.h\"\n-#include \"xla/hlo/builder/xla_builder.h\"\n-#include \"xla/hlo/ir/hlo_sharding.h\"\n+#include \"xla/shape.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n+#include \"tensorflow/core/util/managed_stack_trace.h\"\n \n namespace tensorflow {\n \n@@ -70,7 +78,7 @@ struct XlaArgument {\n   // * an initialized TensorArray or Stack resource: the shape of an entry in\n   //   the TensorArray/Stack. Note this is the size of a single entry, not the\n   //   XLA data structure that represents the complete stack/array.\n-  absl::variant<TensorShape, xla::Shape> shape;\n+  std::variant<std::monostate, TensorShape, xla::Shape> shape;\n \n   // The value of the argument, if it is a compile-time constant. Must be a\n   // host-memory tensor.\n@@ -83,10 +91,10 @@ struct XlaArgument {\n   std::optional<Tensor> value_dynamism;\n \n   // The name of this argument, used for debugging.\n-  string name;\n+  std::string name;\n \n   // The name of TensorFlow _Arg node, used for debugging.\n-  string node_name;\n+  std::string node_name;\n \n   // For a kResource, what kind of resource is it?\n   XlaResource::Kind resource_kind = XlaResource::kInvalid;\n@@ -104,22 +112,22 @@ struct XlaArgument {\n   // TensorArray resource parameters are passed as (array, gradient array 0,\n   // ..., gradient array k), where the gradient arrays are in the same order\n   // as `tensor_array_gradients`.\n-  std::set<string> tensor_array_gradients;\n+  std::set<std::string> tensor_array_gradients;\n \n   // Whether this argument will receive the same data across all replicas.\n   bool is_same_data_across_replicas = false;\n \n   bool operator==(const XlaArgument& other) const;\n \n   // Returns a human-readable summary of the argument.\n-  string HumanString() const;\n+  std::string HumanString() const;\n \n   // Returns the dimension sizes for either TensorShape or xla::Shape.\n   std::vector<int64_t> DimensionSizes() const;\n   absl::InlinedVector<int64_t, 4> DimensionSizesAsInlinedVector() const;\n \n   // Returns the human-readable string for either TensorShape or xla::Shape.\n-  string ShapeHumanString() const;\n+  std::string ShapeHumanString() const;\n \n   // Whether to broadcast this parameter to all replicas before use.\n   // When true, xla_compiler should input/output alias this arg to prevent"
        }
    ],
    "stats": {
        "total": 98,
        "additions": 73,
        "deletions": 25
    }
}