{
    "author": "WillFroom",
    "message": "[XLA:CPU] Remove unneeded propagate-alias-scopes pass\n\nPiperOrigin-RevId: 802178552",
    "sha": "d5cd09f782218f1b6ff323fb1881ee8a77e57ecf",
    "files": [
        {
            "sha": "b555bacc6f55e48b719f813992b2eb40cc3c03a8",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d5cd09f782218f1b6ff323fb1881ee8a77e57ecf/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d5cd09f782218f1b6ff323fb1881ee8a77e57ecf/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=d5cd09f782218f1b6ff323fb1881ee8a77e57ecf",
            "patch": "@@ -132,7 +132,6 @@ static void AddLoopTransformationPasses(mlir::OpPassManager& pm,\n   pm.addPass(mlir::mhlo::createConvertToSignlessPass());\n   pm.addPass(emitters::CreatePropagateSliceIndicesPass());\n   pm.addPass(emitters::CreateFlattenTensorsPass());\n-  pm.addPass(emitters::createPropagateAliasScopesPass());\n   // We need LICM before unswitching loops, because our loop unswitcher only\n   // detects for loops with a single if inside them.\n   pm.addPass(mlir::createLoopInvariantCodeMotionPass());"
        },
        {
            "sha": "99853eb64a26f052972e27816d4476de54d9dd85",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d5cd09f782218f1b6ff323fb1881ee8a77e57ecf/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d5cd09f782218f1b6ff323fb1881ee8a77e57ecf/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2FBUILD?ref=d5cd09f782218f1b6ff323fb1881ee8a77e57ecf",
            "patch": "@@ -62,7 +62,6 @@ cc_library(\n         \":atomic_rmw_utils\",\n         \":convert_pure_call_ops_pass\",\n         \":passes_inc_gen\",\n-        \":propagate_alias_scopes\",  # buildcleaner: keep\n         \":simplify_affine_pass\",\n         \":simplify_arith_pass\",\n         \"//xla:shape_util\",\n@@ -199,25 +198,6 @@ cc_library(\n     ],\n )\n \n-cc_library(\n-    name = \"propagate_alias_scopes\",\n-    srcs = [\"propagate_alias_scopes.cc\"],\n-    deps = [\n-        \":passes_inc_gen\",\n-        \"@com_google_absl//absl/container:flat_hash_map\",\n-        \"@com_google_absl//absl/strings\",\n-        \"@llvm-project//llvm:Support\",\n-        \"@llvm-project//mlir:CallOpInterfaces\",\n-        \"@llvm-project//mlir:FuncDialect\",\n-        \"@llvm-project//mlir:IR\",\n-        \"@llvm-project//mlir:LLVMDialect\",\n-        \"@llvm-project//mlir:Pass\",\n-        \"@llvm-project//mlir:SCFDialect\",\n-        \"@llvm-project//mlir:Support\",\n-        \"@llvm-project//mlir:TensorDialect\",\n-    ],\n-)\n-\n cc_library(\n     name = \"pass_pipelines\",\n     srcs = [\"pass_pipelines.cc\"],"
        },
        {
            "sha": "a4affb0c614cecf5682b7c61e3bd66be7d02ea20",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/passes.td",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d5cd09f782218f1b6ff323fb1881ee8a77e57ecf/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d5cd09f782218f1b6ff323fb1881ee8a77e57ecf/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.td?ref=d5cd09f782218f1b6ff323fb1881ee8a77e57ecf",
            "patch": "@@ -203,20 +203,6 @@ def MergePointersToSameSlicePass :\n   let constructor = \"CreateMergePointersToSameSlicePass()\";\n }\n \n-def PropagateAliasScopesPass :\n-   Pass<\"xla-propagate-alias-scopes\", \"mlir::ModuleOp\"> {\n-  let summary = \"Propagates alias scopes from function args to tensor modifications.\";\n-\n-  let description = [{\n-      Propagates alias scopes from function args to tensor modifications.\n-  }];\n-\n-  let dependentDialects = [\n-    \"mlir::func::FuncDialect\",\n-    \"mlir::LLVM::LLVMDialect\",\n-  ];\n-}\n-\n def PropagateSliceIndicesPass :\n    Pass<\"xla-propagate-slice-indices\", \"mlir::ModuleOp\"> {\n   let summary = \"Propagates slice indices from the entry function to all callees.\";"
        },
        {
            "sha": "2f2710bad1854132f4c3597cbf24636fdc5cc763",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/propagate_alias_scopes.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 262,
            "changes": 262,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpropagate_alias_scopes.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpropagate_alias_scopes.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpropagate_alias_scopes.cc?ref=7bbbb8785a76d9a220de5646d835a3e9975cfd35",
            "patch": "@@ -1,262 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include <cstdint>\n-#include <vector>\n-\n-#include \"absl/container/flat_hash_map.h\"\n-#include \"absl/strings/str_cat.h\"\n-#include \"llvm/ADT/STLExtras.h\"\n-#include \"llvm/ADT/SmallVector.h\"\n-#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n-#include \"mlir/Dialect/LLVMIR/LLVMAttrs.h\"\n-#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n-#include \"mlir/Dialect/SCF/IR/SCF.h\"\n-#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n-#include \"mlir/IR/Attributes.h\"\n-#include \"mlir/IR/BuiltinAttributes.h\"\n-#include \"mlir/IR/BuiltinOps.h\"\n-#include \"mlir/IR/MLIRContext.h\"\n-#include \"mlir/IR/Value.h\"\n-#include \"mlir/IR/Visitors.h\"\n-#include \"mlir/Interfaces/CallInterfaces.h\"\n-#include \"mlir/Pass/Pass.h\"  // IWYU pragma: keep\n-#include \"mlir/Support/LLVM.h\"\n-\n-namespace xla::emitters {\n-\n-#define GEN_PASS_DECL_PROPAGATEALIASSCOPESPASS\n-#define GEN_PASS_DEF_PROPAGATEALIASSCOPESPASS\n-#include \"xla/codegen/emitters/transforms/passes.h.inc\"\n-\n-auto kSliceIndexAttrName = \"xla.slice_index\";\n-auto kInvariantAttrName = \"xla.invariant\";\n-\n-class PropagateAliasScopesPass final\n-    : public impl::PropagateAliasScopesPassBase<PropagateAliasScopesPass> {\n- public:\n-  using PropagateAliasScopesPassBase::PropagateAliasScopesPassBase;\n-\n-  void runOnOperation() override;\n-\n- private:\n-  // Main callback for the walking the ops withing the function.\n-  mlir::WalkResult WalkCallback(mlir::Operation* op);\n-  // Propagate the slice index to the arguments of the function.\n-  mlir::WalkResult WalkCall(mlir::CallOpInterface call_op);\n-  // Propagate the slice index to the iter-args of the for loop.\n-  mlir::WalkResult WalkFor(mlir::scf::ForOp for_op);\n-  // Add the noalias scope to the extract op.\n-  mlir::WalkResult WalkExtract(mlir::tensor::ExtractOp extract_op);\n-  // Add the alias & noalias scope to the insert op.\n-  mlir::WalkResult WalkInsert(mlir::tensor::InsertOp insert_op);\n-\n-  // Initialize mapping from value to slice index and slice index to alias\n-  // scope.\n-  void InitializeBookeeping(mlir::func::FuncOp func_op);\n-  void InitializeAliasScopeBookeeping(mlir::func::FuncOp func_op);\n-  void InitializeNoAliasScopeBookeeping(mlir::MLIRContext* context);\n-\n- private:\n-  // Value to the slice index of the function argument.\n-  llvm::DenseMap<mlir::Value, int64_t> value_to_index_;\n-  // Slice index to the alias scope attribute.\n-  absl::flat_hash_map<int64_t, mlir::LLVM::AliasScopeAttr> index_to_alias_;\n-  // Slice index to the set of no alias scope attributes.\n-  absl::flat_hash_map<int64_t, mlir::ArrayAttr> index_to_no_alias_;\n-};\n-\n-static void SetAliasScopeMetadata(\n-    mlir::Operation& op, const mlir::LLVM::AliasScopeAttr& alias_scope) {\n-  op.setAttr(mlir::LLVM::LLVMDialect::getAliasScopesAttrName(),\n-             mlir::ArrayAttr::get(op.getContext(), alias_scope));\n-}\n-\n-static void SetNoAliasScopeMetadata(mlir::Operation& op,\n-                                    mlir::ArrayAttr alias_scopes) {\n-  if (alias_scopes.empty()) {\n-    return;\n-  }\n-  op.setAttr(mlir::LLVM::LLVMDialect::getNoAliasAttrName(), alias_scopes);\n-}\n-\n-void PropagateAliasScopesPass::runOnOperation() {\n-  mlir::ModuleOp module_op = getOperation();\n-\n-  mlir::func::FuncOp entry;\n-  for (auto func : getOperation().getOps<mlir::func::FuncOp>()) {\n-    if (func->getAttr(\"xla.entry\")) {\n-      entry = func;\n-      break;\n-    }\n-  }\n-\n-  if (!entry) {\n-    getOperation()->emitOpError(\"No entry function found.\");\n-    signalPassFailure();\n-    return;\n-  }\n-\n-  InitializeBookeeping(entry);\n-\n-  module_op->walk<mlir::WalkOrder::PreOrder>(\n-      [this](mlir::Operation* op) { return WalkCallback(op); });\n-}\n-\n-mlir::WalkResult PropagateAliasScopesPass::WalkCallback(mlir::Operation* op) {\n-  if (auto call_op = mlir::dyn_cast_or_null<mlir::CallOpInterface>(op)) {\n-    return WalkCall(call_op);\n-  }\n-\n-  if (auto for_op = mlir::dyn_cast_or_null<mlir::scf::ForOp>(op)) {\n-    return WalkFor(for_op);\n-  }\n-\n-  if (auto insert_op = mlir::dyn_cast_or_null<mlir::tensor::InsertOp>(op)) {\n-    return WalkInsert(insert_op);\n-  }\n-\n-  if (auto extract_op = mlir::dyn_cast_or_null<mlir::tensor::ExtractOp>(op)) {\n-    return WalkExtract(extract_op);\n-  }\n-\n-  return mlir::WalkResult::advance();\n-}\n-\n-mlir::WalkResult PropagateAliasScopesPass::WalkCall(\n-    mlir::CallOpInterface call_op) {\n-  mlir::func::FuncOp callee =\n-      mlir::dyn_cast<mlir::func::FuncOp>(call_op.resolveCallable());\n-  if (!callee) {\n-    // Could be a call to an external function.\n-    return mlir::WalkResult::advance();\n-  }\n-\n-  // Forward the slice index to the arguments of the callee.\n-  for (auto [arg, operand] :\n-       llvm::zip(callee.getArguments(), call_op.getArgOperands())) {\n-    auto slice_index_itr = value_to_index_.find(operand);\n-    if (slice_index_itr != value_to_index_.end()) {\n-      value_to_index_.insert({arg, slice_index_itr->second});\n-    }\n-  }\n-\n-  return mlir::WalkResult::advance();\n-}\n-\n-mlir::WalkResult PropagateAliasScopesPass::WalkFor(mlir::scf::ForOp for_op) {\n-  // Forward the slice index to the iter-args of the for loop.\n-  for (auto [arg, operand] :\n-       llvm::zip(for_op.getRegionIterArgs(), for_op.getInitArgs())) {\n-    auto slice_index_itr = value_to_index_.find(operand);\n-    if (slice_index_itr != value_to_index_.end()) {\n-      value_to_index_.insert({arg, slice_index_itr->second});\n-    }\n-  }\n-\n-  return mlir::WalkResult::advance();\n-}\n-\n-mlir::WalkResult PropagateAliasScopesPass::WalkExtract(\n-    mlir::tensor::ExtractOp extract_op) {\n-  auto index_itr = value_to_index_.find(extract_op.getTensor());\n-  if (index_itr == value_to_index_.end()) {\n-    return mlir::WalkResult::advance();\n-  }\n-\n-  int64_t slice_index = index_itr->second;\n-\n-  if (auto no_alias_itr = index_to_no_alias_.find(slice_index);\n-      no_alias_itr != index_to_no_alias_.end()) {\n-    SetNoAliasScopeMetadata(*extract_op, no_alias_itr->second);\n-  }\n-\n-  return mlir::WalkResult::advance();\n-}\n-\n-mlir::WalkResult PropagateAliasScopesPass::WalkInsert(\n-    mlir::tensor::InsertOp insert_op) {\n-  auto index_itr = value_to_index_.find(insert_op.getDest());\n-  if (index_itr == value_to_index_.end()) {\n-    return mlir::WalkResult::advance();\n-  }\n-\n-  int64_t slice_index = index_itr->second;\n-\n-  if (const auto alias_itr = index_to_alias_.find(slice_index);\n-      alias_itr != index_to_alias_.end()) {\n-    SetAliasScopeMetadata(*insert_op, alias_itr->second);\n-  }\n-\n-  if (auto no_alias_itr = index_to_no_alias_.find(slice_index);\n-      no_alias_itr != index_to_no_alias_.end()) {\n-    SetNoAliasScopeMetadata(*insert_op, no_alias_itr->second);\n-  }\n-\n-  return mlir::WalkResult::advance();\n-}\n-\n-void PropagateAliasScopesPass::InitializeBookeeping(\n-    mlir::func::FuncOp func_op) {\n-  InitializeAliasScopeBookeeping(func_op);\n-  InitializeNoAliasScopeBookeeping(func_op.getContext());\n-}\n-\n-void PropagateAliasScopesPass::InitializeAliasScopeBookeeping(\n-    mlir::func::FuncOp func_op) {\n-  value_to_index_.clear();\n-  index_to_alias_.clear();\n-\n-  auto domain = mlir::LLVM::AliasScopeDomainAttr::get(func_op.getContext());\n-  for (mlir::BlockArgument arg : func_op.getArguments()) {\n-    auto slice_index_attr = func_op.getArgAttrOfType<mlir::IntegerAttr>(\n-        arg.getArgNumber(), kSliceIndexAttrName);\n-    if (!slice_index_attr) {\n-      continue;\n-    }\n-\n-    value_to_index_.insert({arg, slice_index_attr.getInt()});\n-\n-    // We only need to set the alias scope for arguments that are written to.\n-    if (func_op.getArgAttr(arg.getArgNumber(), kInvariantAttrName)) {\n-      continue;\n-    }\n-\n-    int64_t slice_index = slice_index_attr.getInt();\n-    auto scope = mlir::LLVM::AliasScopeAttr::get(\n-        domain, mlir::StringAttr::get(\n-                    func_op.getContext(),\n-                    absl::StrCat(kSliceIndexAttrName, \"=\", slice_index)));\n-    index_to_alias_.insert({slice_index, scope});\n-  }\n-}\n-\n-void PropagateAliasScopesPass::InitializeNoAliasScopeBookeeping(\n-    mlir::MLIRContext* context) {\n-  index_to_no_alias_.clear();\n-\n-  for (const auto& [value, slice_index] : value_to_index_) {\n-    std::vector<mlir::Attribute> no_alias;\n-    for (const auto& [inner_slice_index, no_alias_scope] : index_to_alias_) {\n-      if (inner_slice_index != slice_index) {\n-        no_alias.push_back(no_alias_scope);\n-      }\n-    }\n-    index_to_no_alias_.insert(\n-        {slice_index, mlir::ArrayAttr::get(context, no_alias)});\n-  }\n-}\n-\n-}  // namespace xla::emitters"
        },
        {
            "sha": "f221ba99db070fcae2f9fc2b0e1a0343ecf0b840",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/tests/propagate_alias_scopes.mlir",
            "status": "removed",
            "additions": 0,
            "deletions": 97,
            "changes": 97,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fpropagate_alias_scopes.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fpropagate_alias_scopes.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fpropagate_alias_scopes.mlir?ref=7bbbb8785a76d9a220de5646d835a3e9975cfd35",
            "patch": "@@ -1,97 +0,0 @@\n-// RUN: emitters_opt %s -split-input-file -xla-propagate-alias-scopes | FileCheck %s\n-\n-func.func @nested_for(\n-    %arg0: tensor<8x128xf32> {xla.invariant, xla.slice_index = 0 : index},\n-    %arg1: tensor<128x8xf32> {xla.slice_index = 1 : index}) -> tensor<128x8xf32>\n-    attributes { xla.entry }\n-{\n-  %c0 = arith.constant 0 : index\n-  %c1 = arith.constant 1 : index\n-  %c8 = arith.constant 8 : index\n-  %c128 = arith.constant 128 : index\n-  %0 = scf.for %arg2 = %c0 to %c128 step %c1\n-      iter_args(%arg3 = %arg1) -> (tensor<128x8xf32>) {\n-    %1 = scf.for %arg4 = %c0 to %c8 step %c1\n-        iter_args(%arg5 = %arg3) -> (tensor<128x8xf32>) {\n-      %extracted = tensor.extract %arg0[%arg4, %arg2] : tensor<8x128xf32>\n-      %inserted = tensor.insert %extracted into\n-        %arg5[%arg2, %arg4] : tensor<128x8xf32>\n-      scf.yield %inserted : tensor<128x8xf32>\n-    }\n-    scf.yield %1 : tensor<128x8xf32>\n-  }\n-  func.return %0 : tensor<128x8xf32>\n-}\n-// CHECK-LABEL: func.func @nested_for\n-// CHECK: tensor.extract {{.*}}llvm.noalias = [#[[ALIAS_SCOPE:[a-z0-9_]+]]\n-// CHECK: tensor.insert {{.*}}alias_scopes = [#[[ALIAS_SCOPE]]\n-\n-// -----\n-\n-func.func @multi_output(\n-    %arg0: tensor<8x128xf32> {xla.invariant, xla.slice_index = 0 : index},\n-    %arg1: tensor<128x8xf32> {xla.slice_index = 1 : index},\n-    %arg2: tensor<128x8xf32> {xla.slice_index = 2 : index}\n-  ) -> (tensor<128x8xf32>, tensor<128x8xf32>) attributes { xla.entry }\n-{\n-  %c0 = arith.constant 0 : index\n-  %c1 = arith.constant 1 : index\n-  %c8 = arith.constant 8 : index\n-  %c128 = arith.constant 128 : index\n-  %outer_res_0, %outer_res_1 = scf.for %outer_idx = %c0 to %c128 step %c1\n-      iter_args(%arg1_0 = %arg1, %arg2_0 = %arg2)\n-      -> (tensor<128x8xf32>, tensor<128x8xf32>) {\n-    %inner_res_0, %inner_res_1 = scf.for %inner_idx = %c0 to %c8 step %c1\n-        iter_args(%arg1_1 = %arg1_0, %arg2_1 = %arg2_0)\n-        -> (tensor<128x8xf32>, tensor<128x8xf32>) {\n-      %extracted = tensor.extract %arg0[%inner_idx, %outer_idx] : tensor<8x128xf32>\n-      %inserted_0 = tensor.insert %extracted into\n-        %arg1_1[%outer_idx, %inner_idx] : tensor<128x8xf32>\n-      %inserted_1 = tensor.insert %extracted into\n-        %arg2_1[%outer_idx, %inner_idx] : tensor<128x8xf32>\n-      scf.yield %inserted_0, %inserted_1 : tensor<128x8xf32>, tensor<128x8xf32>\n-    }\n-    scf.yield %inner_res_0, %inner_res_1 : tensor<128x8xf32>, tensor<128x8xf32>\n-  }\n-  func.return %outer_res_0, %outer_res_1 : tensor<128x8xf32>, tensor<128x8xf32>\n-}\n-// CHECK-LABEL: func.func @multi_output\n-// CHECK: tensor.extract {{.*}}llvm.noalias = [#[[ALIAS_SCOPE_1:[a-z0-9_]+]],\n-// CHECK-SAME: #[[ALIAS_SCOPE_2:[a-z0-9_]+]]\n-// CHECK-DAG : tensor.insert {{.*}}alias_scopes = [#[[ALIAS_SCOPE_1]]],\n-// CHECK-DAG-SAME: llvm.noalias = [#[[ALIAS_SCOPE_2]]]\n-// CHECK-DAG : tensor.insert {{.*}}alias_scopes = [#[[ALIAS_SCOPE_2]]],\n-// CHECK-DAG-SAME: llvm.noalias = [#[[ALIAS_SCOPE_1]]]\n-\n-// -----\n-\n-func.func @sub_call(\n-    %arg0: tensor<128xf32> {xla.invariant, xla.slice_index = 0 : index},\n-    %arg1: tensor<128xf32> {xla.slice_index = 1 : index}) -> tensor<128xf32>\n-    attributes { xla.entry }\n-{\n-  %c0 = arith.constant 0 : index\n-  %c1 = arith.constant 1 : index\n-  %c128 = arith.constant 128 : index\n-  %0 = scf.for %index = %c0 to %c128 step %c1\n-      iter_args(%arg3 = %arg1) -> (tensor<128xf32>) {\n-    %result = xla.pure_call @sub_call_sub(%index, %arg0, %arg1)\n-      : (index, tensor<128xf32>, tensor<128xf32>) -> tensor<128xf32>\n-    scf.yield %result : tensor<128xf32>\n-  }\n-  func.return %0 : tensor<128xf32>\n-}\n-\n-func.func @sub_call_sub(\n-    %index: index, %arg0: tensor<128xf32>, %arg1: tensor<128xf32>\n-  ) -> tensor<128xf32>\n-{\n-  %extracted = tensor.extract %arg0[%index] : tensor<128xf32>\n-  %inserted = tensor.insert %extracted into %arg1[%index] : tensor<128xf32>\n-  func.return %inserted : tensor<128xf32>\n-}\n-\n-// CHECK-LABEL: func.func @sub_call\n-// CHECK-LABEL: func.func @sub_call_sub\n-// CHECK: tensor.extract {{.*}}llvm.noalias = [#[[ALIAS_SCOPE:[a-z0-9_]+]]\n-// CHECK: tensor.insert {{.*}}alias_scopes = [#[[ALIAS_SCOPE]]"
        }
    ],
    "stats": {
        "total": 394,
        "additions": 0,
        "deletions": 394
    }
}