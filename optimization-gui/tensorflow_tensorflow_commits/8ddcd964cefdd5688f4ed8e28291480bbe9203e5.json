{
    "author": "basioli-k",
    "message": "[XLA:CPU] Unify JIT and AOT compilation paths.\n\nPiperOrigin-RevId: 812711375",
    "sha": "8ddcd964cefdd5688f4ed8e28291480bbe9203e5",
    "files": [
        {
            "sha": "915af457dddbbf672222bc01d6c0089f87026048",
            "filename": "third_party/xla/xla/backends/cpu/codegen/ir_compiler.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8ddcd964cefdd5688f4ed8e28291480bbe9203e5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8ddcd964cefdd5688f4ed8e28291480bbe9203e5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.h?ref=8ddcd964cefdd5688f4ed8e28291480bbe9203e5",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include <memory>\n #include <optional>\n #include <string>\n+#include <utility>\n #include <vector>\n \n #include \"absl/base/thread_annotations.h\"\n@@ -131,6 +132,11 @@ class IrCompiler : public llvm::orc::IRCompileLayer::IRCompiler {\n   absl::StatusOr<std::unique_ptr<llvm::TargetMachine>> build_target_machine()\n       const;\n \n+  void register_compilation_hooks(CompilationHooks hooks) {\n+    absl::MutexLock lock(mutex_);\n+    hooks_ = std::move(hooks);\n+  }\n+\n  private:\n   TargetMachineBuilder target_machine_builder_;\n   Options options_;"
        },
        {
            "sha": "e4458b2a615b050ecb34c5e5f07c3389df3009c1",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8ddcd964cefdd5688f4ed8e28291480bbe9203e5/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8ddcd964cefdd5688f4ed8e28291480bbe9203e5/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=8ddcd964cefdd5688f4ed8e28291480bbe9203e5",
            "patch": "@@ -470,6 +470,7 @@ cc_library(\n         \"cpu_compiler_pure\",\n         \":cpu_aot_compilation_result\",\n         \":executable_proto_cc\",\n+        \":thunk_emitter\",\n         \"//xla:util\",\n         \"//xla/backends/cpu/codegen:ir_compiler\",\n         \"//xla/backends/cpu/codegen:target_machine_features\","
        },
        {
            "sha": "bd96689b6e2ea3116205a7ceda620f27d1a33d58",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 220,
            "deletions": 301,
            "changes": 521,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8ddcd964cefdd5688f4ed8e28291480bbe9203e5/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8ddcd964cefdd5688f4ed8e28291480bbe9203e5/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=8ddcd964cefdd5688f4ed8e28291480bbe9203e5",
            "patch": "@@ -1462,8 +1462,116 @@ static void AddXlaBackendExtraOptionsAsModuleFlag(\n                              options_mdstring);\n }\n \n+namespace {\n+\n+// We have to clone the LLVM module into a local\n+// context to be able to link it with the other modules. This enables us to\n+// have one object file for all the kernels.\n+absl::StatusOr<std::unique_ptr<llvm::Module>> CopyLlvmModuleToLocalContext(\n+    llvm::LLVMContext& llvm_context, const llvm::Module& module) {\n+  // There is no way to clone a module from one context to another, so we\n+  // need to serialize the module to bitcode and parse it back into the\n+  // new context.\n+  llvm::SmallString<0> bc;\n+  llvm::raw_svector_ostream bcos(bc);\n+  llvm::WriteBitcodeToFile(module, bcos);\n+\n+  // Parse module back into its own LLVM context.\n+  auto cloned_module = llvm::parseBitcodeFile(\n+      llvm::MemoryBufferRef(\n+          llvm::StringRef(bc.data(), bc.size()),\n+          absl::StrFormat(\"%s_cloned_to_local_context\", kXlaModuleIdentifier)),\n+      llvm_context);\n+\n+  if (!cloned_module) {\n+    return Internal(\"Failed to copy LLVM module to local context.\");\n+  }\n+\n+  return std::move(*cloned_module);\n+};\n+\n+class LlvmMultipleModuleCompiler {\n+ public:\n+  virtual ~LlvmMultipleModuleCompiler() = default;\n+  virtual absl::Status AddModule(llvm::orc::ThreadSafeModule tsm,\n+                                 size_t dylib_index) = 0;\n+  virtual absl::StatusOr<std::unique_ptr<FunctionLibrary>> Compile(\n+      absl::Span<const FunctionLibrary::Symbol> compiled_symbols) && = 0;\n+};\n+\n+class JitLlvmMultipleModuleCompiler : public LlvmMultipleModuleCompiler {\n+ public:\n+  explicit JitLlvmMultipleModuleCompiler(JitCompiler jit_compiler)\n+      : jit_compiler_(std::move(jit_compiler)) {}\n+\n+  absl::Status AddModule(llvm::orc::ThreadSafeModule tsm,\n+                         size_t dylib_index) override {\n+    return jit_compiler_.AddModule(std::move(tsm), dylib_index);\n+  }\n+\n+  absl::StatusOr<std::unique_ptr<FunctionLibrary>> Compile(\n+      absl::Span<const FunctionLibrary::Symbol> compiled_symbols) &&\n+      override {\n+    return std::move(jit_compiler_).Compile(compiled_symbols);\n+  }\n+\n+ private:\n+  JitCompiler jit_compiler_;\n+};\n+\n+class AotLlvmMultipleModuleCompiler : public LlvmMultipleModuleCompiler {\n+ public:\n+  explicit AotLlvmMultipleModuleCompiler(\n+      const llvm::Module* llvm_module, std::unique_ptr<IrCompiler> ir_compiler)\n+      : llvm_context_(std::make_unique<llvm::LLVMContext>()),\n+        ir_compiler_(std::move(ir_compiler)) {}\n+\n+  absl::Status AddModule(llvm::orc::ThreadSafeModule tsm,\n+                         size_t dylib_index) override {\n+    // We don't need to link in the module if it is the same as the one we\n+    // are currently linking.\n+    if (llvm_module_ == nullptr) {\n+      // We assume the first module is the main module to link into.\n+      TF_ASSIGN_OR_RETURN(\n+          llvm_module_, CopyLlvmModuleToLocalContext(*llvm_context_,\n+                                                     *tsm.getModuleUnlocked()));\n+      linker_ = std::make_unique<llvm::Linker>(*llvm_module_);\n+      return absl::OkStatus();\n+    }\n+\n+    TF_ASSIGN_OR_RETURN(\n+        auto cloned_module,\n+        CopyLlvmModuleToLocalContext(*llvm_context_, *tsm.getModuleUnlocked()));\n+\n+    // Match data layouts to avoid warning messages.\n+    cloned_module->setDataLayout(llvm_module_->getDataLayout());\n+    linker_->linkInModule(std::move(cloned_module));\n+    return absl::OkStatus();\n+  }\n+\n+  absl::StatusOr<std::unique_ptr<FunctionLibrary>> Compile(\n+      absl::Span<const FunctionLibrary::Symbol> compiled_symbols) &&\n+      override {\n+    cantFail((*ir_compiler_)(*llvm_module_));\n+    return nullptr;\n+  }\n+\n+ private:\n+  std::unique_ptr<llvm::LLVMContext> llvm_context_;\n+  std::unique_ptr<llvm::Module> llvm_module_;\n+  std::unique_ptr<llvm::Linker> linker_;\n+  std::unique_ptr<IrCompiler> ir_compiler_;\n+};\n+\n+}  // namespace\n+\n absl::StatusOr<std::unique_ptr<CpuExecutable>>\n-CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n+CpuCompiler::CompileCpuExecutable(\n+    std::unique_ptr<HloModule> module,\n+    const ThunkEmitter::Options& thunk_emitter_options,\n+    std::unique_ptr<IrCompiler> ir_compiler,\n+    const llvm::PICLevel::Level& pic_level,\n+    const llvm::PIELevel::Level& pie_level) {\n   TraceMe trace([&] {\n     return TraceMeEncode(\"CpuCompiler::CompileCpuExecutable\",\n                          {{\"name\", module->name()}});\n@@ -1480,6 +1588,17 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n   auto llvm_context = std::make_unique<llvm::LLVMContext>();\n   auto llvm_module =\n       std::make_unique<llvm::Module>(kXlaModuleIdentifier, *llvm_context);\n+  TF_ASSIGN_OR_RETURN(std::unique_ptr<llvm::TargetMachine> target_machine,\n+                      ir_compiler->build_target_machine());\n+\n+  llvm_module->setDataLayout(target_machine->createDataLayout());\n+\n+  if (pic_level != llvm::PICLevel::NotPIC) {\n+    llvm_module->setPICLevel(pic_level);\n+  }\n+  if (pie_level != llvm::PIELevel::Default) {\n+    llvm_module->setPIELevel(pie_level);\n+  }\n \n   const DebugOptions& debug_options = module->config().debug_options();\n \n@@ -1493,49 +1612,40 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n       debug_options.xla_cpu_parallel_codegen_split_count();\n   VlogMaxIsa(debug_options.xla_cpu_max_isa());\n \n-  const HloModuleConfig& config = module->config();\n-\n-  // Options for compiling LLVM IR to machine code.\n-  IrCompiler::Options ir_compiler_options{\n-      /*optimization_level=*/IrCompiler::GetCodeGenOptLevel(config),\n-      /*optimize_for_size=*/options::OptimizeForSizeRequested(config),\n-      /*max_cpu_isa=*/CpuFeatureFromString(debug_options.xla_cpu_max_isa()),\n-      /*fast_math_flags=*/llvm_ir::GetCpuFastMathFlags(config),\n-      /*disable_expensive_passes=*/\n-      debug_options.xla_llvm_disable_expensive_passes(),\n-      /*slp_vectorizer_disabled=*/options::SlpVectorizerDisabled(config),\n-      /*disable_loop_unrolling=*/options::DisableLoopUnrolling(config),\n-      /*disable_platform_dependent_math=*/\n-      options::DisablePlatformDependentMath(config),\n-  };\n-\n   // Compiler hooks to intercept compiled LLVM IR modules.\n   IrCompiler::CompilationHooks ir_compiler_hooks{\n       pre_optimization_ir_hook,\n       post_optimization_ir_hook,\n       CreateOrcJITPostCompilationHook(module.get(), &obj_files),\n   };\n \n+  ir_compiler->register_compilation_hooks(std::move(ir_compiler_hooks));\n+\n   // Definition generator to link with XLA:CPU host runtime symbols.\n   ExecutionEngine::DefinitionGenerator definition_generator =\n       [](const llvm::DataLayout& data_layout) {\n         return std::make_unique<RuntimeSymbolGenerator>(data_layout);\n       };\n \n-  // Options for orchestrating the JIT compilation process.\n-  JitCompiler::Options jit_compiler_options{\n-      /*num_dylibs=*/parallel_codegen_split_count,\n-      /*definition_generator=*/std::move(definition_generator),\n-  };\n-\n-  std::unique_ptr<IrCompiler> ir_compiler = IrCompiler::Create(\n-      CompilerTargetOptions(module->config()), std::move(ir_compiler_options),\n-      std::move(ir_compiler_hooks));\n+  std::unique_ptr<LlvmMultipleModuleCompiler> llvm_module_compiler;\n \n-  TF_ASSIGN_OR_RETURN(\n-      JitCompiler jit_compiler,\n-      JitCompiler::Create(std::move(jit_compiler_options),\n-                          std::move(ir_compiler), GetCompilationTaskRunner()));\n+  // We don't want to JIT in AOT compilation mode.\n+  if (!thunk_emitter_options.is_aot_compilation) {\n+    // Options for orchestrating the JIT compilation process.\n+    JitCompiler::Options jit_compiler_options{\n+        /*num_dylibs=*/parallel_codegen_split_count,\n+        /*definition_generator=*/std::move(definition_generator),\n+    };\n+    TF_ASSIGN_OR_RETURN(auto jit_compiler,\n+                        JitCompiler::Create(std::move(jit_compiler_options),\n+                                            std::move(ir_compiler),\n+                                            GetCompilationTaskRunner()));\n+    llvm_module_compiler = std::make_unique<JitLlvmMultipleModuleCompiler>(\n+        std::move(jit_compiler));\n+  } else {\n+    llvm_module_compiler = std::make_unique<AotLlvmMultipleModuleCompiler>(\n+        llvm_module.get(), std::move(ir_compiler));\n+  }\n \n   absl::flat_hash_map<const HloInstruction*, int64_t>\n       instruction_to_profile_idx;\n@@ -1576,7 +1686,7 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n     return cpu_executable;\n   };\n \n-  TargetMachineFeatures target_machine_features(jit_compiler.target_machine());\n+  TargetMachineFeatures target_machine_features(target_machine.get());\n \n   // TODO(ezhulenev): Once we fully migrate to Thunks current IrEmitter should\n   // be renamed to NestedIrEmitter and be used only for emitting nested (aka\n@@ -1612,7 +1722,8 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n   // resolved kernels in the compiled LLVM module and execute them together\n   // with Thunks implemented as library calls (e.g. oneDNN or Eigen).\n   ThunkEmitter thunk_emitter(ir_emitter2, *GetCompilationThreadPool(),\n-                             *assignment, target_machine_features, *module);\n+                             *assignment, target_machine_features, *module,\n+                             thunk_emitter_options);\n   TF_ASSIGN_OR_RETURN(ThunkSequence thunks,\n                       thunk_emitter.EmitEntryComputation(*module));\n \n@@ -1694,7 +1805,8 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n           << \" comparators\";\n \n   int dylib_index = 0;\n-  auto add_jit_module = [&](std::unique_ptr<llvm::Module> llvm_module_part) {\n+  auto add_module_for_compilation =\n+      [&](std::unique_ptr<llvm::Module> llvm_module_part) -> absl::Status {\n     // Collect symbols that are compiled in this LLVM module part.\n     RemoveUnusedSymbols(*llvm_module_part);\n     compiled_parts.push_back(\n@@ -1706,7 +1818,11 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n     // Clone LLVM module part into its own thread safe context.\n     auto tsm =\n         CloneAsThreadSafeModule(dylib_index, std::move(llvm_module_part));\n-    TF_CHECK_OK(jit_compiler.AddModule(std::move(tsm), dylib_index++));\n+\n+    TF_RETURN_IF_ERROR(\n+        llvm_module_compiler->AddModule(std::move(tsm), dylib_index++));\n+\n+    return absl::OkStatus();\n   };\n \n   // If there are extra parts, compile them first, since we must\n@@ -1722,12 +1838,14 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n                           ExtractKernelsFromModule(llvm_module.get(), kernels));\n       AddXlaBackendExtraOptionsAsModuleFlag(new_module.get(),\n                                             backend_extra_options);\n-      add_jit_module(std::move(new_module));\n+      TF_RETURN_IF_ERROR(add_module_for_compilation(std::move(new_module)));\n     }\n   }\n \n-  if (HasLargeConstants(*llvm_module)) {\n-    VLOG(3) << \"Skip parallel compilation due to large constants\";\n+  if (HasLargeConstants(*llvm_module) ||\n+      thunk_emitter_options.is_aot_compilation) {\n+    VLOG(3) << \"Skip parallel compilation due to large constants or AOT \"\n+               \"compilation\";\n     num_default_parts = 1;\n   }\n \n@@ -1741,19 +1859,26 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n                            {{\"num_default_parts\", num_default_parts}});\n     });\n \n-    llvm::SplitModule(*llvm_module, num_default_parts, add_jit_module,\n+    auto add_module_for_compilation_no_status =\n+        [&](std::unique_ptr<llvm::Module> llvm_module_part) -> void {\n+      CHECK_OK(add_module_for_compilation(std::move(llvm_module_part)));\n+    };\n+\n+    llvm::SplitModule(*llvm_module, num_default_parts,\n+                      add_module_for_compilation_no_status,\n                       /*PreserveLocals=*/true, /*RoundRobin=*/true);\n     // Free resources used by the original LLVM module.\n     llvm_module.reset();\n     llvm_context.reset();\n-\n   } else {\n     VLOG(3) << \"Compile LLVM module without splitting (max split count: \"\n             << parallel_codegen_split_count << \")\";\n     compiled_parts.push_back(\n         CollectCompiledSymbolsPart(ir_emitter2, *llvm_module));\n-    TF_CHECK_OK(jit_compiler.AddModule(llvm::orc::ThreadSafeModule(\n-        std::move(llvm_module), std::move(llvm_context))));\n+    TF_RETURN_IF_ERROR(llvm_module_compiler->AddModule(\n+        llvm::orc::ThreadSafeModule(std::move(llvm_module),\n+                                    std::move(llvm_context)),\n+        /*dylib_index=*/0));\n   }\n \n   // Collect compiled symbols from all LLVM module parts.\n@@ -1772,8 +1897,8 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n         FunctionLibrary::Sym<FunctionLibrary::Kernel>(name));\n     symbol_type_id_to_function_type_id.emplace(compiled_symbols.back().type_id,\n                                                SymbolProto::KERNEL);\n-    TF_CHECK_OK(jit_compiler.AddModule(std::move(module),\n-                                       num_extra_parts + kernel_dylib_index));\n+    TF_RETURN_IF_ERROR(llvm_module_compiler->AddModule(\n+        std::move(module), num_extra_parts + kernel_dylib_index));\n     // Simply roundrobin the default kernel dylibs\n     kernel_dylib_index = (kernel_dylib_index + 1) % num_default_parts;\n   }\n@@ -1802,8 +1927,9 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n                           {\"num_compiled_functions\", num_compiled_functions}});\n   });\n \n-  TF_ASSIGN_OR_RETURN(std::unique_ptr<FunctionLibrary> function_library,\n-                      std::move(jit_compiler).Compile(compiled_symbols));\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<FunctionLibrary> function_library,\n+      std::move(*llvm_module_compiler).Compile(compiled_symbols));\n \n   // Create constant allocations from the buffer assignment.\n   TF_ASSIGN_OR_RETURN(std::vector<ConstantAllocation> constants,\n@@ -1856,8 +1982,36 @@ absl::StatusOr<std::unique_ptr<Executable>> CpuCompiler::RunBackend(\n       module->config().debug_options().xla_backend_extra_options());\n   llvm_ir::LLVMCommandLineOptionsLock llvm_lock(llvm_options);\n \n-  std::unique_ptr<CpuExecutable> cpu_executable;\n-  TF_ASSIGN_OR_RETURN(cpu_executable, CompileCpuExecutable(std::move(module)));\n+  // Options for compiling LLVM IR to machine code.\n+  IrCompiler::Options ir_compiler_options{\n+      /*optimization_level=*/IrCompiler::GetCodeGenOptLevel(module->config()),\n+      /*optimize_for_size=*/options::OptimizeForSizeRequested(module->config()),\n+      /*max_cpu_isa=*/\n+      CpuFeatureFromString(module->config().debug_options().xla_cpu_max_isa()),\n+      /*fast_math_flags=*/llvm_ir::GetCpuFastMathFlags(module->config()),\n+      /*disable_expensive_passes=*/\n+      module->config().debug_options().xla_llvm_disable_expensive_passes(),\n+      /*slp_vectorizer_disabled=*/\n+      options::SlpVectorizerDisabled(module->config()),\n+      /*disable_loop_unrolling=*/\n+      options::DisableLoopUnrolling(module->config()),\n+      /*disable_platform_dependent_math=*/\n+      options::DisablePlatformDependentMath(module->config()),\n+  };\n+\n+  ThunkEmitter::Options thunk_emitter_options = {\n+      /*compile_copy_as_llvm_kernel=*/false,\n+      /*is_aot_compilation=*/false};\n+\n+  auto ir_compiler = IrCompiler::Create(CompilerTargetOptions(module->config()),\n+                                        std::move(ir_compiler_options), {});\n+\n+  // Since we are JIT compiling, we don't need a triple or target machine\n+  // features as those will be inferred.s\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<CpuExecutable> cpu_executable,\n+      CompileCpuExecutable(std::move(module), thunk_emitter_options,\n+                           std::move(ir_compiler)));\n \n   AliasInfo alias_info;\n   cpu_executable->set_debug_info(\n@@ -1965,10 +2119,6 @@ CpuCompiler::CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n   std::unique_ptr<llvm::TargetMachine> target_machine =\n       target_machine_builder();\n \n-  // Compile must be thread-safe so create a new LLVM context for the module.\n-  mlir::MLIRContext mlir_context;\n-  llvm::LLVMContext llvm_context;\n-\n   std::vector<std::unique_ptr<AotCompilationResult>> results;\n   for (auto& hlo_module : modules) {\n     VLOG(1) << \"Compiling ahead-of-time: \" << hlo_module->name();\n@@ -2001,147 +2151,20 @@ CpuCompiler::CompileAheadOfTimeThunks(\n     return TraceMeEncode(\"CpuCompiler::CompileAheadOfTimeThunks\",\n                          {{\"name\", module->name()}});\n   });\n-  // Compile must be thread-safe so create a new LLVM context for the module.\n-  mlir::MLIRContext mlir_context;\n-  auto llvm_context = std::make_unique<llvm::LLVMContext>();\n-\n-  const DebugOptions& debug_options = module->config().debug_options();\n-\n-  TF_ASSIGN_OR_RETURN(HloSchedule schedule, CreateHloSchedule(*module));\n-  TF_RETURN_IF_ERROR(module->set_schedule(schedule));\n-\n-  TF_ASSIGN_OR_RETURN(std::unique_ptr<BufferAssignment> assignment,\n-                      CreateBufferAssignment(*module));\n-  DumpHloModuleIfEnabled(*module, *assignment,\n-                         absl::StrCat(\"cpu_aot_\", kAfterOptimizationsDumpName));\n-\n-  // TODO profiling related, probably delete this\n-  absl::flat_hash_map<const HloInstruction*, int64_t>\n-      instruction_to_profile_idx;\n-  absl::flat_hash_map<const HloComputation*, int64_t>\n-      computation_to_profile_idx;\n-  std::unique_ptr<HloProfileIndexMap> hlo_profile_index_map;\n-  std::unique_ptr<HloProfilePrinterData> hlo_profile_printer_data;\n-  if (module->config().hlo_profiling_enabled()) {\n-    TF_RETURN_IF_ERROR(CreateHloProfilingArtifacts(\n-        *module, &instruction_to_profile_idx, &computation_to_profile_idx,\n-        &hlo_profile_index_map, &hlo_profile_printer_data));\n-  }\n-  // probably delete this end\n \n   TF_ASSIGN_OR_RETURN(std::unique_ptr<llvm::TargetMachine> target_machine,\n                       target_machine_builder());\n-  TargetMachineFeatures target_machine_features(target_machine.get());\n-\n-  auto llvm_module =\n-      std::make_unique<llvm::Module>(kXlaModuleIdentifier, *llvm_context);\n-\n-  llvm_module->setDataLayout(target_machine->createDataLayout());\n-  llvm_module->setTargetTriple(triple);\n-  if (pic_level != llvm::PICLevel::NotPIC) {\n-    llvm_module->setPICLevel(pic_level);\n-  }\n-  if (pie_level != llvm::PIELevel::Default) {\n-    llvm_module->setPIELevel(pie_level);\n-  }\n-\n-  // Emitting part\n-  // TODO(ezhulenev): Once we fully migrate to Thunks current IrEmitter should\n-  // be renamed to NestedIrEmitter and be used only for emitting nested (aka\n-  // thread local or embedded) computations (reductions, maps, etc.).\n-\n-  // (Nested) IrEmitter is responsible for building LLVM module with functions\n-  // for all HLO computations. In thunk execution mode we only build LLVM\n-  // functions for embedded computations (e.g. reduction computations) and all\n-  // high-level operations (fusions, elementwise, etc.) are lowered to kernel\n-  // functions (which are also LLVM functions, but use a HostKernel ABI).\n-  IrEmitter nested_ir_emitter(\n-      &mlir_context, *module, *assignment, llvm_module.get(),\n-      std::move(instruction_to_profile_idx),\n-      std::move(computation_to_profile_idx),\n-      ModuleComputationsTransitivelyContainCustomCall(*module),\n-      &target_machine_features,\n-      // TODO(b/66051036): Run full msan for AOT.\n-      /*emit_code_for_msan=*/false);\n-\n-  // The thunk runtime manages large constants, therefore we only emit\n-  // small ones.\n-  TF_RETURN_IF_ERROR(nested_ir_emitter.EmitSmallConstantGlobals());\n-\n-  // IR emitter is responsible for building LLVM module with host kernels for\n-  // corresponding HLO instructions (fusions, elemental instructions, etc.).\n-  IrEmitter2 ir_emitter2(*module, llvm_module.get(), &nested_ir_emitter);\n \n   ThunkEmitter::Options thunk_emitter_options = {\n       /*compile_copy_as_llvm_kernel=*/aot_options.compile_copy_as_llvm_kernel(),\n       /*is_aot_compilation=*/true};\n-  // Thunk emitter is responsible for building a Thunk sequence that will\n-  // resolved kernels in the compiled LLVM module and execute them together\n-  // with Thunks implemented as library calls (e.g. oneDNN or Eigen).\n-  ThunkEmitter thunk_emitter(ir_emitter2, *GetCompilationThreadPool(),\n-                             *assignment, target_machine_features, *module,\n-                             thunk_emitter_options);\n-  TF_ASSIGN_OR_RETURN(ThunkSequence thunks,\n-                      thunk_emitter.EmitEntryComputation(*module));\n-  TF_ASSIGN_OR_RETURN(std::vector<ThunkEmitter::EmittedKernel> kernels,\n-                      thunk_emitter.ConsumeKernels());\n-\n-  // Cache these flags here since we'll want to access them after the module's\n-  // ownership is std::moved.\n-  const bool embed_ir_in_executable =\n-      debug_options.xla_embed_ir_in_executable();\n-\n-  std::string ir_module_string;\n-  if (embed_ir_in_executable) {\n-    std::string emitter2_ir = llvm_ir::DumpToString(llvm_module.get());\n-\n-    auto thunk_kernel_fmt = [](std::string* out,\n-                               const ThunkEmitter::EmittedKernel& kernel) {\n-      absl::StrAppend(out,\n-                      llvm_ir::DumpToString(kernel.module.getModuleUnlocked()));\n-    };\n-    std::string thunks_ir = absl::StrJoin(kernels, \"\\n\", thunk_kernel_fmt);\n-\n-    ir_module_string = absl::StrCat(emitter2_ir, \"\\n\", thunks_ir);\n-  }\n-\n-  TF_RETURN_IF_ERROR(VerifyLlvmModule(*llvm_module));\n-  for (const auto& [name, module] : kernels) {\n-    TF_RETURN_IF_ERROR(VerifyLlvmModule(*module.getModuleUnlocked()));\n-  }\n-\n-  // Compilation part\n-  ModuleHook pre_optimization_ir_hook;\n-  ModuleHook post_optimization_ir_hook;\n-  std::tie(pre_optimization_ir_hook, post_optimization_ir_hook) =\n-      GetIRModuleHooks(*module, user_pre_optimization_hook_,\n-                       user_post_optimization_hook_);\n-\n-  std::vector<ObjFileProto> obj_files;\n-  auto post_codegen_hook = [&](const llvm::Module& llvm_module,\n-                               const llvm::object::ObjectFile& obj_file) {\n-    ObjFileProto obj_file_proto;\n-    obj_file_proto.set_name(obj_file.getFileName().str());\n-    obj_file_proto.set_contents(obj_file.getData().str());\n-    obj_files.push_back(std::move(obj_file_proto));\n-\n-    if (!DumpingEnabledForHloModule(*module)) {\n-      return;\n-    }\n-    absl::string_view id = llvm_module.getModuleIdentifier();\n-    size_t pos = std::min(id.size(), 1 + kXlaModuleIdentifier.size());\n-    DumpToFileInDir(\n-        *module, /*file_prefix=*/\"\",\n-        /*file_suffix=*/absl::StrCat(\"obj-file.\", id.substr(pos), \".o\"),\n-        absl::string_view(obj_file.getData().data(),\n-                          obj_file.getData().size()));\n-  };\n \n   IrCompiler::Options ir_compiler_options = {\n       /*optimization_level=*/target_machine->getOptLevel(),\n       /*optimize_for_size=*/\n       options::OptimizeForSizeRequested(module->config()),\n-      /*max_cpu_isa=*/CpuFeatureFromString(debug_options.xla_cpu_max_isa()),\n+      /*max_cpu_isa=*/\n+      CpuFeatureFromString(module->config().debug_options().xla_cpu_max_isa()),\n       /*fast_math_flags=*/llvm_ir::GetCpuFastMathFlags(module->config()),\n       /*disable_expensive_passes=*/\n       module->config().debug_options().xla_llvm_disable_expensive_passes(),\n@@ -2154,130 +2177,14 @@ CpuCompiler::CompileAheadOfTimeThunks(\n       /*dfsan_enabled=*/aot_options.sanitize_dataflow(),\n       /*dfsan_abilists_enabled=*/aot_options.sanitize_abilists_dataflow()};\n \n-  IrCompiler::CompilationHooks ir_compiler_hooks = {\n-      pre_optimization_ir_hook,\n-      post_optimization_ir_hook,\n-      post_codegen_hook,\n-  };\n-\n-  IrCompiler ir_compiler(std::move(target_machine_builder),\n-                         std::move(ir_compiler_options),\n-                         std::move(ir_compiler_hooks));\n-\n-  // For simplicity no parallel compilation is used.\n-  std::vector<CompiledSymbolsPart> compiled_parts;\n-  compiled_parts.push_back(\n-      CollectCompiledSymbolsPart(ir_emitter2, *llvm_module));\n-\n-  // Collect compiled symbols from all LLVM module parts.\n-  std::vector<FunctionLibrary::Symbol> compiled_symbols;\n-\n-  absl::flat_hash_map<FunctionLibrary::TypeId, SymbolProto::FunctionTypeId>\n-      symbol_type_id_to_function_type_id;\n-\n-  VLOG(3) << \"Compiling \" << kernels.size() << \" thunk kernels.\";\n-\n-  // We have to clone the LLVM module into a local context to be able to link\n-  // it with the other modules. This enables us to have one object file for all\n-  // the kernels.\n-  auto copy_llvm_module_to_local_context =\n-      [&llvm_context](llvm::Module& module) {\n-        // There is no way to clone a module from one context to another, so we\n-        // need to serialize the module to bitcode and parse it back into the\n-        // new context.\n-        llvm::SmallString<0> bc;\n-        llvm::raw_svector_ostream bcos(bc);\n-        llvm::WriteBitcodeToFile(module, bcos);\n-\n-        // Parse module back into its own LLVM context.\n-        auto clone_module = llvm::parseBitcodeFile(\n-            llvm::MemoryBufferRef(llvm::StringRef(bc.data(), bc.size()),\n-                                  absl::StrFormat(\"%s_cloned_to_local_context\",\n-                                                  kXlaModuleIdentifier)),\n-            *llvm_context);\n-\n-        return clone_module;\n-      };\n-\n-  llvm::Linker linker(*llvm_module);\n-\n-  for (auto& [name, module] : kernels) {\n-    compiled_symbols.push_back(\n-        FunctionLibrary::Sym<FunctionLibrary::Kernel>(name));\n-    symbol_type_id_to_function_type_id.emplace(compiled_symbols.back().type_id,\n-                                               SymbolProto::KERNEL);\n-    auto cloned_module =\n-        copy_llvm_module_to_local_context(*module.getModuleUnlocked());\n-    if (!cloned_module) {\n-      return Internal(\"Failed to clone LLVM module.\");\n-    }\n-    // Match data layouts to avoid warning messages.\n-    cloned_module->get()->setDataLayout(llvm_module->getDataLayout());\n-    linker.linkInModule(std::move(cloned_module.get()));\n-  }\n-\n-  cantFail(ir_compiler(*llvm_module));\n-\n-  for (const CompiledSymbolsPart& part : compiled_parts) {\n-    for (const IrEmitter2::KernelInfo& kernel : part.kernels) {\n-      compiled_symbols.push_back(\n-          FunctionLibrary::Sym<FunctionLibrary::Kernel>(kernel.name));\n-      symbol_type_id_to_function_type_id.emplace(\n-          compiled_symbols.back().type_id, SymbolProto::KERNEL);\n-    }\n-    for (const IrEmitter2::ComparatorInfo& comparator : part.comparators) {\n-      compiled_symbols.push_back(\n-          FunctionLibrary::Sym<FunctionLibrary::Comparator>(comparator.name));\n-      symbol_type_id_to_function_type_id.emplace(\n-          compiled_symbols.back().type_id, SymbolProto::COMPARATOR);\n-    }\n-  }\n-\n-  VLOG(3) << \"Collected \" << compiled_symbols.size() << \" compiled symbols\";\n-\n-  // Create constant allocations from the buffer assignment.\n-  TF_ASSIGN_OR_RETURN(std::vector<ConstantAllocation> constants,\n-                      CreateConstantAllocations(*assignment));\n+  auto ir_compiler = std::make_unique<IrCompiler>(\n+      std::move(target_machine_builder), ir_compiler_options,\n+      IrCompiler::CompilationHooks{});\n \n   TF_ASSIGN_OR_RETURN(\n       auto cpu_executable,\n-      CpuExecutable::Create(\n-          /*function_library=*/nullptr,  // NOTE: We don't need to generate a\n-                                         // function library as the only purpose\n-                                         // of this executable is to get\n-                                         // exported.\n-          std::move(assignment), std::move(module), std::move(thunks),\n-          std::move(constants), std::move(hlo_profile_printer_data),\n-          std::move(hlo_profile_index_map)));\n-\n-  // Save compiled symbols to be able to export them to AOT compilation\n-  // result.\n-  cpu_executable->set_compiled_symbols(std::move(compiled_symbols));\n-\n-  // Save mapping between symbol type id and function type id to be able to\n-  // export them to AOT compilation result.\n-  cpu_executable->set_symbol_type_id_to_function_type_id(\n-      symbol_type_id_to_function_type_id);\n-\n-  if (embed_ir_in_executable) {\n-    cpu_executable->set_ir_module_string(ir_module_string);\n-  }\n-\n-  // Dump computation proto state and buffer assignment for\n-  // GetCompiledMemoryStats results.\n-  auto with_hlo_proto = [&](std::unique_ptr<CpuExecutable> cpu_executable) {\n-    if (embed_ir_in_executable) {\n-      auto hlo_proto = std::make_unique<HloProto>();\n-      *hlo_proto->mutable_hlo_module() = cpu_executable->module().ToProto();\n-      *hlo_proto->mutable_buffer_assignment() =\n-          cpu_executable->buffer_assignment().ToProto();\n-      StripPayloadFromLiteralProto(*hlo_proto);\n-      cpu_executable->set_hlo_proto(std::move(hlo_proto));\n-    }\n-    return cpu_executable;\n-  };\n-\n-  cpu_executable = with_hlo_proto(std::move(cpu_executable));\n+      CompileCpuExecutable(std::move(module), thunk_emitter_options,\n+                           std::move(ir_compiler), pic_level, pie_level));\n \n   const ThunkSequence& thunk_sequence =\n       cpu_executable->thunks().thunk_sequence();\n@@ -2288,6 +2195,18 @@ CpuCompiler::CompileAheadOfTimeThunks(\n                 cpu_executable->hlo_profile_printer_data())\n           : nullptr;\n \n+  if (cpu_executable->obj_files().size() > 1) {\n+    return Internal(\n+        \"Expected at most one object file for AOT compilation, but got %d\",\n+        cpu_executable->obj_files().size());\n+  }\n+\n+  std::vector<ObjFileProto> obj_files;\n+\n+  for (const auto& obj_file : cpu_executable->obj_files()) {\n+    obj_files.push_back(obj_file);\n+  }\n+\n   return CpuAotCompilationResult::Create(\n       &cpu_executable->module(), &cpu_executable->buffer_assignment(),\n       cpu_executable->module_name(), std::move(obj_files),"
        },
        {
            "sha": "8ccbf415614d0484e0d938b6d9305146a9167a5a",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.h",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8ddcd964cefdd5688f4ed8e28291480bbe9203e5/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8ddcd964cefdd5688f4ed8e28291480bbe9203e5/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.h?ref=8ddcd964cefdd5688f4ed8e28291480bbe9203e5",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"xla/service/compiler.h\"\n #include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/service/cpu/executable.pb.h\"\n+#include \"xla/service/cpu/thunk_emitter.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/service/hlo_cost_analysis.h\"\n@@ -117,7 +118,11 @@ class CpuCompiler : public LLVMCompiler {\n       const CompileOptions& compile_options);\n \n   absl::StatusOr<std::unique_ptr<CpuExecutable>> CompileCpuExecutable(\n-      std::unique_ptr<HloModule> module);\n+      std::unique_ptr<HloModule> module,\n+      const ThunkEmitter::Options& thunk_emitter_options,\n+      std::unique_ptr<IrCompiler> ir_compiler,\n+      const llvm::PICLevel::Level& pic_level = llvm::PICLevel::NotPIC,\n+      const llvm::PIELevel::Level& pie_level = llvm::PIELevel::Default);\n \n   absl::StatusOr<std::unique_ptr<AotCompilationResult>>\n   CompileAheadOfTimeThunks("
        }
    ],
    "stats": {
        "total": 535,
        "additions": 233,
        "deletions": 302
    }
}