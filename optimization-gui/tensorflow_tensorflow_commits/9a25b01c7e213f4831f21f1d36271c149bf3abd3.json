{
    "author": "AleksaArsic",
    "message": "PR #32283: [ROCm] Change misleading method name RocmComputeCapability::has_amd_matrix_core()\n\nImported from GitHub PR https://github.com/openxla/xla/pull/32283\n\nüìù Summary of Changes\nChange misleading method name RocmComputeCapability::has_amd_matrix_core() to more suitable name has_amd_mat_acc_instructions() as gfx11xx do not have matrix cores, but support matrix acceleration instruction set known as WMMA.\n\nüéØ Justification\nRocmComputeCapability::has_amd_matrix_core() is misleading as gfx11xx do not have matrix cores but still support matrix acceleration instruction set - WMMA.\n\nüöÄ Kind of Contribution\n‚ôªÔ∏è Cleanup\n\n@xla-rotation please review my changes.\n\nCopybara import of the project:\n\n--\n23cf1ab79fdcc4ee2ee4996973dee2c103d2762a by Aleksa Arsic <aleksa.arsic@amd.com>:\n\nChange misleading method name RocmComputeCapability::has_amd_matrix_core() to more suitable name has_amd_mat_acc_instructions() as gfx11xx do not have matrix cores, but support matrix acceleration instruction set known as WMMA.\n\nMerging this change closes #32283\n\nPiperOrigin-RevId: 819652238",
    "sha": "9a25b01c7e213f4831f21f1d36271c149bf3abd3",
    "files": [
        {
            "sha": "bf122c7ea130eb49a697081fe0161477eb99ceea",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/compilation_pipeline_rocm.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9a25b01c7e213f4831f21f1d36271c149bf3abd3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline_rocm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9a25b01c7e213f4831f21f1d36271c149bf3abd3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline_rocm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline_rocm.cc?ref=9a25b01c7e213f4831f21f1d36271c149bf3abd3",
            "patch": "@@ -80,7 +80,7 @@ static void MakeTTGIR(mlir::OpPassManager* pm,\n   pm->addPass(mlir::createLoopInvariantCodeMotionPass());\n   pm->addPass(mlir::createCanonicalizerPass());\n \n-  if (rocm_cc.has_amd_matrix_core()) {\n+  if (rocm_cc.has_amd_matrix_instr()) {\n     pm->addPass(mlir::createTritonAMDGPUStreamPipeline(\n         {num_stages, /*global_prefetch=*/0, /*local_prefetch=*/0,\n          /*use_async_copy=*/false, /*use_block_pingpong=*/false}));\n@@ -100,7 +100,7 @@ static void MakeTTGIR(mlir::OpPassManager* pm,\n     pm->addPass(mlir::createTritonAMDGPUInThreadTranspose());\n     pm->addPass(mt::gpu::createTritonGPURemoveLayoutConversions());\n   }\n-  if (rocm_cc.has_amd_matrix_core()) {\n+  if (rocm_cc.has_amd_matrix_instr()) {\n     pm->addPass(mt::gpu::createTritonGPUReorderInstructions());\n   }\n   if (/*use_block_pingpong=*/false) {"
        },
        {
            "sha": "40e484bca7214eb5381031233d1911fbc31154e9",
            "filename": "third_party/xla/xla/stream_executor/rocm/rocm_compute_capability.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9a25b01c7e213f4831f21f1d36271c149bf3abd3/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_compute_capability.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9a25b01c7e213f4831f21f1d36271c149bf3abd3/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_compute_capability.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_compute_capability.h?ref=9a25b01c7e213f4831f21f1d36271c149bf3abd3",
            "patch": "@@ -156,7 +156,7 @@ class RocmComputeCapability {\n \n   bool has_mfma_instr_support() const { return gfx9_mi100_or_later(); }\n \n-  bool has_amd_matrix_core() const {\n+  bool has_amd_matrix_instr() const {\n     return gfx9_mi100_or_later() || gfx12() || gfx11();\n   }\n "
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}