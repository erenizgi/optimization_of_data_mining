{
    "author": "WillFroom",
    "message": "[XLA:GPU] Unconditionally emit func.func from triton emitter.\n\nPiperOrigin-RevId: 820175948",
    "sha": "deac36865fcc2e11e7eb96bf3f90fa9a30c475d7",
    "files": [
        {
            "sha": "945590ac090b162dfe0a8e0fc56cbb9fbbf3f4b0",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 32,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/deac36865fcc2e11e7eb96bf3f90fa9a30c475d7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/deac36865fcc2e11e7eb96bf3f90fa9a30c475d7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=deac36865fcc2e11e7eb96bf3f90fa9a30c475d7",
            "patch": "@@ -1902,35 +1902,6 @@ void AppendFuncArgType(absl::Span<const int64_t> dims, Type ir_type,\n       static_cast<unsigned>(mlir::NVVM::NVVMMemorySpace::Global)));\n }\n \n-// Legacy emitter works with tt.func. New emitter works with func.func.\n-// TODO(b/393299275): Remove legacy optionality once migration is complete.\n-mlir::FunctionOpInterface CreateFuncOp(EmitterLocOpBuilder b,\n-                                       absl::string_view fn_name,\n-                                       absl::string_view fusion_kind,\n-                                       SmallVector<Type>& fn_arg_types) {\n-  if (fusion_kind != kTritonGemmFusionKind) {\n-    return b.create<mlir::func::FuncOp>(fn_name,\n-                                        b.getFunctionType(fn_arg_types, {}));\n-  }\n-  auto func = b.create<ttir::FuncOp>(\n-      fn_name, b.getFunctionType(fn_arg_types, mlir::TypeRange()));\n-  auto divisibility_attr = b.getI32IntegerAttr(16);\n-  for (int i = 0; i < func.getNumArguments(); ++i) {\n-    func.setArgAttr(i, \"tt.divisibility\", divisibility_attr);\n-  }\n-  return func;\n-}\n-\n-// Legacy emitter works with tt.return. New emitter works with func.return.\n-// TODO(b/393299275): Remove legacy optionality once migration is complete.\n-void EmitReturnOp(EmitterLocOpBuilder b, absl::string_view fusion_kind) {\n-  if (fusion_kind == kTritonGemmFusionKind) {\n-    b.create<ttir::ReturnOp>();\n-  } else {\n-    b.create<mlir::func::ReturnOp>();\n-  }\n-}\n-\n absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> CreateTritonModule(\n     absl::string_view fn_name, const HloFusionInstruction* fusion,\n     const se::DeviceDescription& device_info,\n@@ -2276,8 +2247,8 @@ absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> EmitXTileModule(\n     AppendFuncArgType(s.shape.dimensions(), triton_ty, fn_arg_types);\n   }\n \n-  mlir::FunctionOpInterface fn =\n-      CreateFuncOp(b, fn_name, fusion_kind, fn_arg_types);\n+  mlir::FunctionOpInterface fn = b.create<mlir::func::FuncOp>(\n+      fn_name, b.getFunctionType(fn_arg_types, {}));\n \n   fn.addEntryBlock();\n   b.setInsertionPointToStart(&fn.front());\n@@ -2306,7 +2277,7 @@ absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> EmitXTileModule(\n     return Internal(\"Unsupported fusion kind: %s\", fusion_kind);\n   }\n \n-  EmitReturnOp(b, fusion_kind);\n+  b.create<mlir::func::ReturnOp>();\n \n   return triton_module;\n }"
        },
        {
            "sha": "b54741884bd85fc69aee38df519b40ee8e01bb78",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/deac36865fcc2e11e7eb96bf3f90fa9a30c475d7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/deac36865fcc2e11e7eb96bf3f90fa9a30c475d7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc?ref=deac36865fcc2e11e7eb96bf3f90fa9a30c475d7",
            "patch": "@@ -264,7 +264,7 @@ ENTRY e {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheckForDot(this, kHloText, \"triton_gemm_r\", R\"(\n-CHECK:    tt.func @triton_fn(%[[LHS:.*]]: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %[[RHS:.*]]: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %[[OUT:.*]]: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n+CHECK:    func.func @triton_fn(%[[LHS:.*]]: !tt.ptr<i8>, %[[RHS:.*]]: !tt.ptr<f32>, %[[OUT:.*]]: !tt.ptr<f32>) {\n CHECK-DAG:  %[[ZERO_KN:.*]] = arith.constant dense<0.000000e+00> : tensor<32x64xf32>\n CHECK-DAG:  %[[ZERO_MK:.*]] = arith.constant dense<0.000000e+00> : tensor<16x32xf32>\n CHECK-DAG:  %[[ZERO_MN:.*]] = arith.constant dense<0.000000e+00> : tensor<16x64xf32>\n@@ -327,7 +327,7 @@ CHECK:      }\n CHECK:      %[[OUT_PTR:.*]] = tt.make_tensor_ptr %[[OUT]], [%[[C80]], %[[SIZE_M]]], [%[[SIZE_M]], %[[C1]]], [%[[C0]], %[[C0]]] {order = array<i32: 1, 0>} : <tensor<16x64xf32>>\n CHECK:      %[[OUT_OFFSET:.*]] = tt.advance %[[OUT_PTR]], [%[[TILE_OFFSET_M_LHS]], %[[TILE_OFFSET_N_RHS]]] : <tensor<16x64xf32>>\n CHECK:      tt.store %[[OUT_OFFSET]], %[[FOR]]#2 {boundaryCheck = array<i32: 1>} : !tt.ptr<tensor<16x64xf32>>\n-CHECK:      tt.return\n+CHECK:      return\n CHECK:    }\n )\"));\n }\n@@ -356,7 +356,7 @@ ENTRY e {\n \n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheckForDot(this, kHloText, \"triton_dot\", R\"(\n-CHECK:    tt.func @triton_fn(%[[LHS:.*]]: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %[[RHS:.*]]: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %[[OUT:.*]]: !tt.ptr<f32> {tt.divisibility = 16 : i32}) {\n+CHECK:    func.func @triton_fn(%[[LHS:.*]]: !tt.ptr<f32>, %[[RHS:.*]]: !tt.ptr<f32>, %[[OUT:.*]]: !tt.ptr<f32>) {\n CHECK-DAG:  %[[ZERO_KN:.*]] = arith.constant dense<0.000000e+00> : tensor<32x16xf32>\n CHECK-DAG:  %[[ZERO_MK:.*]] = arith.constant dense<0.000000e+00> : tensor<16x32xf32>\n CHECK-DAG:  %[[ZERO_MN:.*]] = arith.constant dense<0.000000e+00> : tensor<16x16xf32>\n@@ -417,7 +417,7 @@ CHECK:    }\n CHECK:    %[[OUT_PTR:.*]] = tt.make_tensor_ptr %[[OUT]], [%[[SIZE_M]], %[[C1]]], [%[[C1]], %[[C1]]], [%[[C0]], %[[C0]]] {order = array<i32: 1, 0>} : <tensor<16x16xf32>>\n CHECK:    %[[OUT_OFFSET:.*]] = tt.advance %[[OUT_PTR]], [%[[TILE_OFFSET_M_LHS]], %[[TILE_OFFSET_N_RHS]]] : <tensor<16x16xf32>>\n CHECK:    tt.store %[[OUT_OFFSET]], %[[FOR]]#2 {boundaryCheck = array<i32: 0, 1>} : !tt.ptr<tensor<16x16xf32>>\n-CHECK:    tt.return\n+CHECK:    return\n CHECK:  }\n )\"));\n }\n@@ -491,7 +491,7 @@ ENTRY e {\n \n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheckForDot(this, kHloText, \"triton_gemm\", R\"(\n-CHECK:   tt.func @triton_fn(%[[P0:[^:]*]]: !tt.ptr<f32>\n+CHECK:   func.func @triton_fn(%[[P0:[^:]*]]: !tt.ptr<f32>\n CHECK-SAME:                 %[[P1:[^:]*]]: !tt.ptr<f32>\n CHECK-SAME:                 %[[P2:[^:]*]]: !tt.ptr<f32>\n CHECK-DAG: %[[ARG_PTR:.*]] = arith.select %[[CONCAT_COND:.*]], %[[P1]], %[[P2]]\n@@ -538,7 +538,7 @@ ENTRY e {\n \n   ASSERT_THAT(\n       CreateTritonIrAndFileCheckForDot(this, kHloText, \"triton_gemm\", R\"(\n-CHECK:     tt.func @triton_fn({{[^,]*}}, %[[DYNAMIC_SLICE_INPUT:[^:]*]]: !tt.ptr<f32> {{[^,]*}}, %[[START_INDEX0_PTR:[^:]*]]: !tt.ptr<i32>\n+CHECK:     func.func @triton_fn({{[^,]*}}, %[[DYNAMIC_SLICE_INPUT:[^:]*]]: !tt.ptr<f32>, %[[START_INDEX0_PTR:[^:]*]]: !tt.ptr<i32>\n CHECK-DAG:   %[[C0_i32:.*]] = arith.constant 0 : i32\n CHECK-DAG:   %[[C1_i64:.*]] = arith.constant 1 : i64\n CHECK-DAG:   %[[C2_i64:.*]] = arith.constant 2 : i64\n@@ -1230,7 +1230,7 @@ ENTRY e {\n })\";\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheckForDot(this, kHloText, \"triton_gemm_r\", R\"(\n-CHECK:    tt.func @triton_fn\n+CHECK:    func.func @triton_fn\n CHECK-DAG:      %[[ZERO:.*]] = arith.constant dense<0>\n CHECK-DAG:      %[[FMIN:.*]] = arith.constant dense<-1.280000e+02>\n CHECK-DAG:      %[[IMIN:.*]] = arith.constant dense<-128>"
        }
    ],
    "stats": {
        "total": 49,
        "additions": 10,
        "deletions": 39
    }
}