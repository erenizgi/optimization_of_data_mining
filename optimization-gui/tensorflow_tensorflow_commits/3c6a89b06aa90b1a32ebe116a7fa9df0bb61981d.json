{
    "author": "sohaibiftikhar",
    "message": "[XLA:GPU] Prepare collective kernel thunk to work with emitted kernels.\n\n- Changes number of arguments passed in.\n- Adds logic for getting slices from the collective metadata pointer.\n- Fixes shared memory declaration during kernel creation.\n\nPiperOrigin-RevId: 838698198",
    "sha": "3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d",
    "files": [
        {
            "sha": "12099410b567db5abd5897d65c15c26e20cd5b66",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 10,
            "deletions": 1,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d",
            "patch": "@@ -1247,6 +1247,7 @@ cc_library(\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:device_memory_handle\",\n         \"//xla/stream_executor:kernel\",\n+        \"//xla/stream_executor:kernel_args\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/gpu:all_reduce_kernel\",\n@@ -1277,12 +1278,12 @@ xla_test(\n     backends = [\"h100\"],\n     deps = [\n         \":collective_kernel_thunk\",\n+        \":collective_params\",\n         \":collective_thunk\",\n         \":thunk\",\n         \"//xla:array\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n-        \"//xla/backends/gpu/runtime:collective_params\",\n         \"//xla/pjrt:worker_thread\",\n         \"//xla/runtime:device_id\",\n         \"//xla/service:buffer_assignment\",\n@@ -1293,10 +1294,18 @@ xla_test(\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/service/gpu:gpu_constants\",\n         \"//xla/service/gpu:gpu_executable_run_options\",\n+        \"//xla/service/gpu:ptx_compile_options_from_debug_options\",\n+        \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:platform_manager\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor/cuda:assemble_compilation_provider\",\n+        \"//xla/stream_executor/cuda:compilation_options\",\n+        \"//xla/stream_executor/cuda:compilation_provider\",\n+        \"//xla/stream_executor/cuda:compilation_provider_options\",\n+        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n+        \"//xla/stream_executor/cuda:cuda_platform\",\n         \"//xla/stream_executor/gpu:gpu_init\",\n         \"//xla/tsl/concurrency:future\",\n         \"//xla/tsl/lib/core:status_test_util\","
        },
        {
            "sha": "79ac8fd0474d916aa046f8fba39027f863c7557f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk.cc",
            "status": "modified",
            "additions": 39,
            "deletions": 27,
            "changes": 66,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc?ref=3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d",
            "patch": "@@ -14,6 +14,7 @@ limitations under the License.*/\n \n #include \"xla/backends/gpu/runtime/collective_kernel_thunk.h\"\n \n+#include <array>\n #include <cstdint>\n #include <cstring>\n #include <memory>\n@@ -46,6 +47,7 @@ limitations under the License.*/\n #include \"xla/stream_executor/gpu/all_reduce_kernel.h\"\n #include \"xla/stream_executor/gpu/collective_kernel_metadata.h\"\n #include \"xla/stream_executor/kernel.h\"\n+#include \"xla/stream_executor/kernel_args.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -57,18 +59,15 @@ namespace xla::gpu {\n namespace {\n using se::gpu::AllReduceStrategy;\n \n-static constexpr int64_t kMaxOneShotAllReduceSizeBytes = 256 * 1024;  // 256 KB\n-static constexpr int64_t kMaxTwoShotAllReduceSizeBytes =\n-    2 * 1024 * 1024;  // 2 MB\n // Number of arguments for the all-reduce kernel.\n-// - Metadata pointer.\n // - Input buffer pointer.\n // - Output buffer pointer.\n-// - Num elements.\n-// - Num elements per rank.\n-// - Rank offset.\n+// - Rank\n // - Signal value.\n-static constexpr int kAllReduceArgsCount = 7;\n+// - Signal buffers\n+// - Remote buffers\n+static constexpr int32_t kAllReduceArgsCount = 6;\n+static constexpr int32_t kNumParameters = 2;\n \n // Helper for allocating memory on the device.\n absl::StatusOr<se::DeviceMemoryHandle> AllocateMemory(\n@@ -145,9 +144,10 @@ absl::Status CollectiveKernelThunk::ExchangeStateMetadata(\n       << \"Device \" << params.collective_params->global_device_id\n       << \"is not in the clique.\";\n \n-  std::vector<se::DeviceMemoryBase> parameters;\n-  parameters.push_back(state.local_buffers_handle.memory());\n-  parameters.push_back(state.signal_buffers_handle.memory());\n+  std::vector<se::DeviceMemoryBase> parameters{\n+      state.local_buffers_handle.memory(),\n+      state.signal_buffers_handle.memory()};\n+  TF_RET_CHECK(parameters.size() == kNumParameters);\n \n   const size_t param_to_peers_ptrs_size_bytes =\n       parameters.size() * clique_key.num_devices() * sizeof(uint64_t);\n@@ -194,7 +194,7 @@ absl::Status CollectiveKernelThunk::Initialize(const InitializeParams& params) {\n \n       TF_ASSIGN_OR_RETURN(\n           se::DeviceMemoryHandle signal_buffers_handle,\n-          AllocateMemory(params.executor, kLocalBufferSize * kNumBuffers,\n+          AllocateMemory(params.executor, kSignalBufferSize * kNumBuffers,\n                          \"Signal buffers\"));\n \n       // Step2: We needs 1 atomic flag per block per device on each device.\n@@ -208,12 +208,19 @@ absl::Status CollectiveKernelThunk::Initialize(const InitializeParams& params) {\n           signal_buffers_handle.memory().size()));\n       // Create a kernel for execution.\n       std::unique_ptr<se::Kernel> kernel = nullptr;\n-      // If PTX is provided, we create a kernel from it.\n       if (!kernel_name_.empty()) {\n-        VLOG(3) << \"Creating kernel from PTX.\" << params.src.text;\n-        TF_ASSIGN_OR_RETURN(kernel,\n-                            CreateKernel(kernel_name_, kAllReduceArgsCount,\n-                                         params.src.text, params.executor, 0));\n+        if (!params.src.binary.empty()) {\n+          TF_ASSIGN_OR_RETURN(\n+              kernel,\n+              CreateKernel(kernel_name_, kAllReduceArgsCount, params.src.binary,\n+                           params.executor, shmem_bytes_));\n+\n+        } else {\n+          TF_ASSIGN_OR_RETURN(\n+              kernel,\n+              CreateKernel(kernel_name_, kAllReduceArgsCount, params.src.text,\n+                           params.executor, shmem_bytes_));\n+        }\n       }\n       // Step3: Emplace into the stream state.\n       per_stream_state_.emplace(\n@@ -319,18 +326,23 @@ absl::Status CollectiveKernelThunk::ExecuteOnStream(\n           << \"(block x threadsPerBlock)\";\n \n   if (state->kernel != nullptr) {\n-    // NB: The assumption is one-shot all-reduce (for now).\n-    std::vector<se::KernelArgument> kernel_args = {\n-        state->metadata,\n+    TF_ASSIGN_OR_RETURN(se::DeviceMemoryBase remote_buffers,\n+                        CollectiveMetadataThunk::GetParameterDeviceMemoryBase(\n+                            state->metadata, /*num_parameters=*/kNumParameters,\n+                            /*num_devices=*/num_devices,\n+                            /*parameter_index=*/0));\n+    TF_ASSIGN_OR_RETURN(se::DeviceMemoryBase signal_buffers,\n+                        CollectiveMetadataThunk::GetParameterDeviceMemoryBase(\n+                            state->metadata, /*num_parameters=*/kNumParameters,\n+                            /*num_devices=*/num_devices,\n+                            /*parameter_index=*/1));\n+    std::array<se::KernelArgument, kAllReduceArgsCount> kernel_args = {\n         source_buffer,\n         destination_buffer,\n-        buffer.element_count,\n-        /*num_elements_per_rank=*/buffer.element_count / num_devices,\n-        /*rank_offset=*/0,\n-        state->invocation_count};\n-    TF_RET_CHECK(kernel_args.size() == kAllReduceArgsCount)\n-        << \"Kernel argument size mismatch.\" << kernel_args.size()\n-        << \" != \" << kAllReduceArgsCount;\n+        static_cast<int32_t>(state->rank.value()),\n+        /* signal_value= */ state->invocation_count,\n+        signal_buffers,\n+        remote_buffers};\n     return ExecuteKernelOnStream(*state->kernel, kernel_args, launch_dimensions,\n                                  /*cluster_dim=*/std::nullopt, stream);\n   }"
        },
        {
            "sha": "4e06fa758fd6f11f6b0f07a820584f7bf08daaaf",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.h?ref=3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d",
            "patch": "@@ -63,13 +63,15 @@ class CollectiveKernelThunk : public Thunk {\n                         std::vector<CollectiveThunk::Buffer> buffers,\n                         bool is_collective_kernel_enabled,\n                         absl::string_view kernel_name = \"\",\n+                        int32_t shmem_bytes = 0,\n                         bool is_multimem_enabled = false)\n       : Thunk{Thunk::kCollectiveKernel, info},\n         collective_kernel_enabled_(is_collective_kernel_enabled),\n         is_async_(is_async),\n         collective_config_(std::move(collective_config)),\n         reduction_kind_(reduction_kind),\n         kernel_name_(kernel_name),\n+        shmem_bytes_(shmem_bytes),\n         buffers_(std::move(buffers)),\n         is_multimem_enabled_(is_multimem_enabled) {\n     per_stream_state_.reserve(kMaxNumExecutors);\n@@ -160,6 +162,9 @@ class CollectiveKernelThunk : public Thunk {\n   // Kernel name to execute. Required when Codegen/PTX kernel is used.\n   // Must match the kernel name in the generated PTX kernel.\n   const std::string kernel_name_;\n+  // Number of bytes of shared memory used by the kernel.\n+  // Only useful when the codegen kernel is used.\n+  const int32_t shmem_bytes_;\n   // Reference to the buffer related information required for the collective.\n   std::vector<CollectiveThunk::Buffer> buffers_;\n "
        },
        {
            "sha": "cc0d13ae1bd1efb187fb481fc52028090f5687f4",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk_test.cc",
            "status": "modified",
            "additions": 105,
            "deletions": 60,
            "changes": 165,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc?ref=3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d",
            "patch": "@@ -35,7 +35,14 @@ limitations under the License.\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/gpu/gpu_constants.h\"\n #include \"xla/service/gpu/gpu_executable_run_options.h\"\n+#include \"xla/service/gpu/ptx_compile_options_from_debug_options.h\"\n #include \"xla/service/service_executable_run_options.h\"\n+#include \"xla/stream_executor/cuda/assemble_compilation_provider.h\"\n+#include \"xla/stream_executor/cuda/compilation_options.h\"\n+#include \"xla/stream_executor/cuda/compilation_provider.h\"\n+#include \"xla/stream_executor/cuda/compilation_provider_options.h\"\n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+#include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/gpu/gpu_init.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n@@ -54,25 +61,23 @@ namespace xla::gpu {\n namespace {\n \n static constexpr absl::string_view kProfileName = \"test_kernel_profiler\";\n-static constexpr absl::string_view kKernelName = \"seven_argument_kernel\";\n+static constexpr absl::string_view kKernelName = \"six_argument_kernel\";\n+static constexpr int64_t kNumElements = 128;\n \n // Test kernel was compiled using following CUDA source:\n-// __global__ void seven_argument_kernel(void* metadata,                 // 1\n-//                                       int64_t* input_buffer,          // 2\n-//                                       int64_t* output_buffer,         // 3\n-//                                       int64_t num_elements,           // 4\n-//                                       int64_t num_elements_per_rank,  // 5\n-//                                       int64_t rank_offset,            // 6\n-//                                       int64_t signal_value            // 7\n+// __global__ void six_argument_kernel(int64_t* input_buffer,          // 1\n+//                                     int64_t* output_buffer,         // 2\n+//                                     int64_t rank,                   // 3\n+//                                     int64_t signal_value            // 4\n+//                                     int64_t* signal_buffers,        // 5\n+//                                     int64_t* remote_buffers,        // 6\n // ) {\n-//   (void)num_elements;\n-//   (void)num_elements_per_rank;\n-//   (void)rank_offset;\n-//   (void)signal_value;\n-//   (void)metadata;\n+//   (void)rank;\n+//   (void)signal_buffers;\n+//   (void)remote_buffers;\n //   int64_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n-//   for (int i = idx; i < num_elements; i += gridDim.x * blockDim.x) {\n-//     if (i < num_elements) {\n+//   for (int i = idx; i < kNumElements; i += gridDim.x * blockDim.x) {\n+//     if (i < kNumElements) {\n //       output_buffer[i] = input_buffer[i] + signal_value;\n //     }\n //   }\n@@ -82,57 +87,47 @@ static constexpr absl::string_view kKernelSource = R\"(\n   .target sm_90\n   .address_size 64\n \n-  //\n-  //\n-  .visible .entry seven_argument_kernel(\n-  .param .u64 .ptr .align 1 metadata,\n+  .visible .entry six_argument_kernel(\n   .param .u64 .ptr .align 1 input_buffer,\n   .param .u64 .ptr .align 1 output_buffer,\n-  .param .u64 num_elements,\n-  .param .u64 num_elements_per_rank,\n-  .param .u64 rank_offset,\n-  .param .u64 signal_value\n+  .param .u64 rank,\n+  .param .u64 signal_value,\n+  .param .u64 .ptr .align 1 signal_buffers,\n+  .param .u64 .ptr .align 1 remote_buffers\n   )\n   {\n   .reg .pred %p<3>;\n-  .reg .b32 %r<12>;\n-  .reg .b64 %rd<16>;\n-\n-  //\n-  ld.param.b64 %rd6, [num_elements];\n-  ld.param.b64 %rd8, [input_buffer];\n-  cvta.to.global.u64 %rd1, %rd8;\n-  ld.param.b64 %rd9, [output_buffer];\n-  cvta.to.global.u64 %rd2, %rd9;\n-  mov.u32 %r1, %ctaid.x;\n-  mov.u32 %r2, %ntid.x;\n-  mov.u32 %r3, %tid.x;\n-  mad.lo.s32 %r8, %r1, %r2, %r3;\n-  cvt.s64.s32 %rd15, %r8;\n-  setp.le.s64 %p1, %rd6, %rd15;\n+  .reg .b32 %r<7>;\n+  .reg .b64 %rd<11>;\n+\n+  ld.param.b64 %rd4, [input_buffer];\n+  cvta.to.global.u64 %rd1, %rd4;\n+  ld.param.b64 %rd5, [output_buffer];\n+  cvta.to.global.u64 %rd2, %rd5;\n+  mov.u32 %r3, %ctaid.x;\n+  mov.u32 %r1, %ntid.x;\n+  mov.u32 %r4, %tid.x;\n+  mad.lo.s32 %r6, %r3, %r1, %r4;\n+  setp.gt.s32 %p1, %r6, 127;\n   @%p1 bra $L__BB0_3;\n   //\n-  ld.param.b64 %rd7, [signal_value];\n-  mov.u32 %r9, %nctaid.x;\n-  mul.lo.s32 %r4, %r9, %r2;\n-  add.s32 %r10, %r9, %r1;\n-  mad.lo.s32 %r11, %r2, %r10, %r3;\n+  ld.param.b64 %rd3, [signal_value];\n+  mov.u32 %r5, %nctaid.x;\n+  mul.lo.s32 %r2, %r5, %r1;\n   $L__BB0_2: //\n-  shl.b64 %rd10, %rd15, 3;\n-  add.s64 %rd11, %rd1, %rd10;\n-  ld.global.b64 %rd12, [%rd11];\n-  add.s64 %rd13, %rd12, %rd7;\n-  add.s64 %rd14, %rd2, %rd10;\n-  st.global.b64 [%rd14], %rd13;\n-  cvt.s64.s32 %rd15, %r11;\n-  setp.gt.s64 %p2, %rd6, %rd15;\n-  add.s32 %r11, %r11, %r4;\n+  mul.wide.s32 %rd6, %r6, 8;\n+  add.s64 %rd7, %rd1, %rd6;\n+  ld.global.b64 %rd8, [%rd7];\n+  add.s64 %rd9, %rd8, %rd3;\n+  add.s64 %rd10, %rd2, %rd6;\n+  st.global.b64 [%rd10], %rd9;\n+  add.s32 %r6, %r6, %r2;\n+  setp.lt.s32 %p2, %r6, 128;\n   @%p2 bra $L__BB0_2;\n   $L__BB0_3:\n   ret;\n-  //\n   }\n-)\";\n+  )\";\n \n se::StreamExecutor* GetGpuExecutor(int64_t device_ordinal) {\n   auto* platform =\n@@ -147,11 +142,14 @@ struct CollectiveKernelThunkMetadata {\n   int64_t input_data_size_bytes;\n   int64_t aligned_input_size_bytes;\n   int64_t num_devices;\n+  // If true, the PTX is not compiled into CUBIN and is passed to the thunk as\n+  // a string.\n+  bool use_ptx;\n   std::vector<CollectiveThunk::Buffer> buffers;\n };\n \n CollectiveKernelThunkMetadata CreateCollectiveKernelThunk(\n-    int num_devices, int num_elements, bool is_multimem_enabled) {\n+    int num_devices, int num_elements, bool is_multimem_enabled, bool use_ptx) {\n   const int64_t input_size_bytes = num_elements * sizeof(uint64_t);\n   ReplicaGroup replica_group;\n \n@@ -189,14 +187,44 @@ CollectiveKernelThunkMetadata CreateCollectiveKernelThunk(\n       /*is_async=*/false, result.buffers,\n       /*is_collective_kernel_enabled=*/true,\n       /*kernel_name=*/kKernelName,\n+      /*shmem_bytes=*/0,\n       /*is_multimem_enabled=*/is_multimem_enabled);\n   result.total_buffer_size = total_buffer_size;\n   result.num_devices = num_devices;\n   result.aligned_input_size_bytes = aligned_input_size_bytes;\n   result.input_data_size_bytes = input_size_bytes;\n+  result.use_ptx = use_ptx;\n   return result;\n }\n \n+// Compiles a PTX string to a CUBIN using the NVPTXCompiler.\n+//\n+// Args:\n+//   ptx_string: The PTX code to compile.\n+//   device_description: The description of the target GPU device.\n+//   debug_options: The debug options for configuring the compilation.\n+//\n+// Returns:\n+//   A StatusOr containing the compiled CUBIN as a vector of bytes.\n+absl::StatusOr<std::vector<uint8_t>> CompilePtxToCubin(\n+    const absl::string_view ptx_string,\n+    const se::DeviceDescription& device_description,\n+    const DebugOptions& debug_options) {\n+  se::cuda::CompilationProviderOptions options =\n+      se::cuda::CompilationProviderOptions::FromDebugOptions(debug_options);\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<se::cuda::CompilationProvider> compilation_provider,\n+      se::cuda::AssembleCompilationProvider(options));\n+  se::CudaComputeCapability cc =\n+      *device_description.gpu_compute_capability().cuda_compute_capability();\n+  se::cuda::CompilationOptions compilation_options =\n+      PtxCompileOptionsFromDebugOptions(debug_options);\n+  TF_ASSIGN_OR_RETURN(\n+      se::cuda::Assembly assembly,\n+      compilation_provider->Compile(cc, ptx_string, compilation_options));\n+  return std::move(assembly.cubin);\n+}\n+\n absl::StatusOr<se::DeviceMemoryBase> RunCollectiveKernelThunk(\n     CollectiveKernelThunkMetadata& metadata, se::StreamExecutor* executor,\n     std::vector<uint64_t> input_data) {\n@@ -250,6 +278,15 @@ absl::StatusOr<se::DeviceMemoryBase> RunCollectiveKernelThunk(\n   initialize_params.buffer_allocations = &buffer_allocations;\n   initialize_params.collective_params = &collective_params;\n   initialize_params.src = {kKernelSource};\n+\n+  std::vector<uint8_t> cubin;\n+  if (!metadata.use_ptx) {\n+    TF_ASSIGN_OR_RETURN(\n+        cubin,\n+        CompilePtxToCubin(kKernelSource, executor->GetDeviceDescription(),\n+                          DebugOptions()));\n+    initialize_params.src.binary = cubin;\n+  }\n   TF_RETURN_IF_ERROR(metadata.thunk->Initialize(initialize_params));\n \n   auto execute_params = Thunk::ExecuteParams::Create(\n@@ -281,8 +318,10 @@ RunCollectiveKernelThunkOnDevices(CollectiveKernelThunkMetadata& metadata) {\n   return results;\n }\n \n-TEST(CollectiveKernelThunkTest, ExecutesPtxKernel) {\n-  static constexpr int64_t kNumElements = 128;\n+class CollectiveKernelThunkParameterizedTest\n+    : public ::testing::TestWithParam<bool> {};\n+\n+TEST_P(CollectiveKernelThunkParameterizedTest, ExecutesPtxKernel) {\n   static constexpr uint32_t kExpectedSignalValue = 1;\n \n   std::vector<uint64_t> input_data(kNumElements);\n@@ -297,7 +336,7 @@ TEST(CollectiveKernelThunkTest, ExecutesPtxKernel) {\n \n   CollectiveKernelThunkMetadata metadata = CreateCollectiveKernelThunk(\n       /*num_devices=*/1, /*num_elements=*/kNumElements,\n-      /*is_multimem_enabled=*/false);\n+      /*is_multimem_enabled=*/false, /*use_ptx=*/GetParam());\n \n   se::StreamExecutor* executor0 = GetGpuExecutor(0);\n   TF_ASSERT_OK_AND_ASSIGN(\n@@ -315,13 +354,19 @@ TEST(CollectiveKernelThunkTest, ExecutesPtxKernel) {\n   }\n }\n \n+INSTANTIATE_TEST_SUITE_P(\n+    CollectiveKernelThunkParameterizedTest,\n+    CollectiveKernelThunkParameterizedTest, ::testing::Bool(),\n+    [](const ::testing::TestParamInfo<bool>& use_ptx) -> std::string {\n+      return use_ptx.param ? \"UsingPtx\" : \"UsingCubin\";\n+    });\n+\n TEST(CollectiveKernelThunkTest, MultimemSetupTest) {\n   static constexpr int kDevicesCount = 2;\n-  static constexpr int64_t kNumElements = 128;\n \n   CollectiveKernelThunkMetadata metadata = CreateCollectiveKernelThunk(\n       /*num_devices=*/kDevicesCount, /*num_elements=*/kNumElements,\n-      /*is_multimem_enabled=*/true);\n+      /*is_multimem_enabled=*/true, /*use_ptx=*/true);\n   for (absl::StatusOr<se::DeviceMemoryBase> result :\n        RunCollectiveKernelThunkOnDevices(metadata)) {\n     TF_ASSERT_OK(result);"
        },
        {
            "sha": "758ef0ec1a4573e44650034c8576ac8329f96f90",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_metadata_thunk.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 1,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc?ref=3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d",
            "patch": "@@ -143,7 +143,7 @@ absl::Status CollectiveMetadataThunk::ConstructCollectiveMetadata(\n     }\n   }\n \n-  const int param_to_peers_ptrs_size =\n+  const int64_t param_to_peers_ptrs_size =\n       param_to_peers_ptrs.size() * sizeof(void*);\n   se::DeviceMemoryBase param_to_peers_ptrs_buffer = destination.GetByteSlice(\n       sizeof(CollectiveKernelMetadata), param_to_peers_ptrs_size);\n@@ -159,6 +159,25 @@ absl::Status CollectiveMetadataThunk::ConstructCollectiveMetadata(\n   return stream->BlockHostUntilDone();\n }\n \n+/* static */ absl::StatusOr<se::DeviceMemoryBase>\n+CollectiveMetadataThunk::GetParameterDeviceMemoryBase(\n+    const se::DeviceMemoryBase metadata, const int64_t num_parameters,\n+    const int64_t num_devices, const int64_t parameter_index) {\n+  TF_RET_CHECK(parameter_index >= 0 && parameter_index < num_parameters)\n+      << \"Parameter index \" << parameter_index << \" is out of bounds [0, \"\n+      << num_parameters << \")\";\n+  // The pointer table is a flattened array laid out in parameter major order.\n+  // P0R0 P0R1 ... P0Rn P1R0\n+  // P1R1 ... P1Rn ... PnRn\n+  // Where Pn is the parameter index and Rn is the rank.\n+  se::DeviceMemoryBase ptr_table_base = metadata.GetByteSlice(\n+      sizeof(CollectiveKernelMetadata),\n+      /*size_bytes=*/num_parameters * num_devices * sizeof(void*));\n+  return ptr_table_base.GetByteSlice(\n+      (parameter_index * num_devices) * sizeof(void*),\n+      /*size_bytes=*/num_devices * sizeof(void*));\n+}\n+\n absl::Status CollectiveMetadataThunk::Initialize(\n     const InitializeParams& params) {\n   TF_ASSIGN_OR_RETURN("
        },
        {
            "sha": "7b306e333d7821a8567fae1ab21c02ae84ce698d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_metadata_thunk.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.h?ref=3c6a89b06aa90b1a32ebe116a7fa9df0bb61981d",
            "patch": "@@ -81,6 +81,12 @@ class CollectiveMetadataThunk : public Thunk {\n       const GpuCliqueKey& clique_key, void* multimem_address_space,\n       int device_ordinal, se::DeviceMemoryBase destination);\n \n+  // Calculate the device memory base for the given parameter index.\n+  // The size of the returned memory is num_devices pointers.\n+  static absl::StatusOr<se::DeviceMemoryBase> GetParameterDeviceMemoryBase(\n+      se::DeviceMemoryBase metadata, int64_t num_parameters,\n+      int64_t num_devices, int64_t parameter_index);\n+\n   absl::StatusOr<void*> SetupMultimem(const GpuCliqueKey& clique_key,\n                                       const InitializeParams& params);\n "
        }
    ],
    "stats": {
        "total": 274,
        "additions": 185,
        "deletions": 89
    }
}