{
    "author": "mwhittaker",
    "message": "Don't construct GPU cliques with stale incarnations.\n\nRecall that every process in a multi-controller JAX program is given a global\nunique incarnation id. If the task fails and restarts, it is given a new\nincarnation id.\n\nPreviously, when we detected the failure of a process with incarnation id x, we\naborted all collectives where process x was a participant. In other words, if a\ntask failed after forming a clique, things worked great. However, we didn't\nhandle the case where a task fails before forming a clique. This is illustrated\nby the following scenario:\n\n- live_devices is called and returns incarnations x, y and z.\n- x fails.\n- All cliques with x are aborted, but there are none.\n- A clique is formed with incarnations x, y, and z.\n- Things get stuck :(\n\nThis commit tracks the latest set of incarnations. If any of these incarnations\ndies, the corresponding cliques are aborted. And, if we attempt to construct a\nclique with a stale incarnation, it fails.\n\nThis is also a roll-forward of https://github.com/openxla/xla/pull/31843.\nPreviously, `gpu_cliques.cc` was holding a lock while creating a communicator,\nwhich was slow. This roll-forward fixes that by releasing the lock while\ncreating a communicator.\n\nPiperOrigin-RevId: 814016528",
    "sha": "835244af8a0ec3d853135b17fe6a2b7ac45261e7",
    "files": [
        {
            "sha": "d5dacb3f2ce698732e9eb2d158809136fd4a3155",
            "filename": "third_party/xla/xla/backends/gpu/collectives/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/835244af8a0ec3d853135b17fe6a2b7ac45261e7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/835244af8a0ec3d853135b17fe6a2b7ac45261e7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD?ref=835244af8a0ec3d853135b17fe6a2b7ac45261e7",
            "patch": "@@ -165,6 +165,7 @@ cc_library(\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:btree\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/container:node_hash_map\",\n         \"@com_google_absl//absl/functional:function_ref\","
        },
        {
            "sha": "136ae7a1c5f71ba4b90a78e4ba03a549ece0c09a",
            "filename": "third_party/xla/xla/backends/gpu/collectives/gpu_cliques.cc",
            "status": "modified",
            "additions": 152,
            "deletions": 8,
            "changes": 160,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/835244af8a0ec3d853135b17fe6a2b7ac45261e7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_cliques.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/835244af8a0ec3d853135b17fe6a2b7ac45261e7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_cliques.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_cliques.cc?ref=835244af8a0ec3d853135b17fe6a2b7ac45261e7",
            "patch": "@@ -27,6 +27,7 @@ limitations under the License.\n #include \"absl/algorithm/container.h\"\n #include \"absl/base/thread_annotations.h\"\n #include \"absl/container/btree_map.h\"\n+#include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/container/node_hash_map.h\"\n #include \"absl/functional/function_ref.h\"\n@@ -100,6 +101,8 @@ namespace {\n struct ProcessGpuCliques {\n   absl::Mutex mu;\n   absl::node_hash_map<GpuCliqueKey, LockableGpuClique> map ABSL_GUARDED_BY(mu);\n+  std::vector<tensorflow::CoordinatedTaskStateInfo> task_state_infos\n+      ABSL_GUARDED_BY(mu);\n };\n }  // namespace\n \n@@ -225,6 +228,43 @@ static absl::StatusOr<bool> EnablePeerAccess(\n   return true;\n }\n \n+// Returns a non-ok status if the provided clique key is \"stale\". A clique key\n+// is stale if its incarnations don't match the latest incarnations or if any of\n+// the tasks specified in the clique key have failed.\n+//\n+// REQUIRES: GetProcessGpuCliques().mu held\n+static absl::Status CheckCliqueKeyIsntStale(\n+    absl::Span<const tensorflow::CoordinatedTaskStateInfo> task_state_infos,\n+    const GpuCliqueKey& clique_key) {\n+  if (task_state_infos.empty()) {\n+    // If we don't have any task state info, assume the clique key isn't stale.\n+    return absl::OkStatus();\n+  }\n+\n+  // Create an index from incarnation id to task state info.\n+  using Info = tensorflow::CoordinatedTaskStateInfo;\n+  absl::flat_hash_map<IncarnationId, const Info*> incarnation_to_info;\n+  for (const Info& info : task_state_infos) {\n+    incarnation_to_info[IncarnationId(info.incarnation())] = &info;\n+  }\n+\n+  // Check that every incarnation is fresh.\n+  for (IncarnationId id : clique_key.incarnations()) {\n+    auto it = incarnation_to_info.find(id);\n+    if (it == incarnation_to_info.end()) {\n+      return FailedPrecondition(\"Incarnation id %d is stale\", id.value());\n+    }\n+    const auto& [unused, info] = *it;\n+    if (info->state() !=\n+        tensorflow::CoordinatedTaskState::TASKSTATE_CONNECTED) {\n+      return FailedPrecondition(\"Task with incarnation id %d is not connected\",\n+                                id.value());\n+    }\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n // Joins a GpuClique initialization rendezvous for a `clique_key` and returns\n // a lock that gives an access to initialized clique (access is shared between\n // all participating ranks that own a shared pointer).\n@@ -300,6 +340,13 @@ InitializeGpuClique(GpuCollectives* collectives, se::StreamExecutor* device,\n         clique_key.ToString(), DeviceRanksToString(ranks), nroots,\n         clique_ids.fingerprint(), peer_access_enabled);\n \n+    ProcessGpuCliques& cliques = GetProcessGpuCliques();\n+    {\n+      absl::MutexLock lock(cliques.mu);\n+      TF_RETURN_IF_ERROR(\n+          CheckCliqueKeyIsntStale(cliques.task_state_infos, clique_key));\n+    }\n+\n     TF_ASSIGN_OR_RETURN(\n         std::vector<std::unique_ptr<Communicator>> created_comms,\n         collectives->CreateCommunicators(clique_key, clique_ids, ranks,\n@@ -316,8 +363,17 @@ InitializeGpuClique(GpuCollectives* collectives, se::StreamExecutor* device,\n         clique_key.ToString(), DeviceRanksToString(ranks), nroots,\n         clique_ids.fingerprint(), peer_access_enabled);\n \n-    ProcessGpuCliques& cliques = GetProcessGpuCliques();\n     absl::MutexLock lock(cliques.mu);\n+    if (absl::Status s =\n+            CheckCliqueKeyIsntStale(cliques.task_state_infos, clique_key);\n+        !s.ok()) {\n+      LOG(WARNING) << \"Clique key \" << clique_key.ToString()\n+                   << \" is stale. Aborting recently created communicators.\";\n+      for (std::unique_ptr<Communicator>& comm : created_comms) {\n+        TF_RETURN_IF_ERROR(comm->Abort());\n+      }\n+      return s;\n+    }\n \n     // Create a new clique with given clique key and communicators.\n     auto emplaced =\n@@ -473,6 +529,13 @@ InitializeGpuClique(GpuCollectives* collectives, se::StreamExecutor* device,\n         peer_access_enabled,\n         absl::StrJoin(rank_mapping, \",\", rank_mapping_formatter));\n \n+    ProcessGpuCliques& cliques = GetProcessGpuCliques();\n+    {\n+      absl::MutexLock lock(cliques.mu);\n+      TF_RETURN_IF_ERROR(\n+          CheckCliqueKeyIsntStale(cliques.task_state_infos, clique_key));\n+    }\n+\n     TF_ASSIGN_OR_RETURN(\n         auto splitted_comms,\n         collectives->SplitCommunicators(parent_comms, color, keys, config));\n@@ -490,8 +553,17 @@ InitializeGpuClique(GpuCollectives* collectives, se::StreamExecutor* device,\n         peer_access_enabled,\n         absl::StrJoin(rank_mapping, \",\", rank_mapping_formatter));\n \n-    ProcessGpuCliques& cliques = GetProcessGpuCliques();\n     absl::MutexLock lock(cliques.mu);\n+    if (absl::Status s =\n+            CheckCliqueKeyIsntStale(cliques.task_state_infos, clique_key);\n+        !s.ok()) {\n+      LOG(WARNING) << \"Clique key \" << clique_key.ToString()\n+                   << \" is stale. Aborting recently split communicators.\";\n+      for (std::unique_ptr<Communicator>& comm : splitted_comms) {\n+        TF_RETURN_IF_ERROR(comm->Abort());\n+      }\n+      return s;\n+    }\n \n     // Create a new clique with given clique key and communicators.\n     auto emplaced =\n@@ -564,7 +636,10 @@ absl::StatusOr<std::shared_ptr<LockableGpuClique::Lock>> AcquireGpuClique(\n             auto lockable_clique = [&]() -> LockableGpuClique* {\n               absl::MutexLock lock(cliques.mu);\n               auto it = cliques.map.find(clique_key);\n-              return it == cliques.map.end() ? nullptr : &it->second;\n+              absl::Status stale =\n+                  CheckCliqueKeyIsntStale(cliques.task_state_infos, clique_key);\n+              return it == cliques.map.end() || !stale.ok() ? nullptr\n+                                                            : &it->second;\n             }();\n \n             return lockable_clique ? lockable_clique->Acquire()\n@@ -617,7 +692,14 @@ bool CliqueKeyContainsIncarnation(\n                         });\n }\n \n-absl::Status AbortCliquesWithIncarnations(\n+// Aborts and invalidates all cliques that have been created via\n+// AcquireGpuClique with any of the provided incarnations. For example, if\n+// incarnations is [1, 2], then all cliques with a clique key that includes\n+// incarnations 1 or 2 will be aborted.\n+//\n+// REQUIRES: GetProcessGpuCliques().mu held\n+static absl::Status AbortCliquesWithIncarnations(\n+    absl::node_hash_map<GpuCliqueKey, LockableGpuClique>& map,\n     absl::Span<const IncarnationId> incarnations) {\n   VLOG(1) << \"Aborting GPU cliques for incarnations \"\n           << absl::StrJoin(incarnations, \", \",\n@@ -626,10 +708,8 @@ absl::Status AbortCliquesWithIncarnations(\n                            });\n   const absl::flat_hash_set<IncarnationId> incarnation_set(incarnations.begin(),\n                                                            incarnations.end());\n-  ProcessGpuCliques& cliques = GetProcessGpuCliques();\n-  absl::MutexLock lock(cliques.mu);\n   absl::Status result;\n-  for (auto it = cliques.map.begin(); it != cliques.map.end();) {\n+  for (auto it = map.begin(); it != map.end();) {\n     auto copy = it++;\n     auto& [key, lockable_clique] = *copy;\n     if (!CliqueKeyContainsIncarnation(key, incarnation_set)) {\n@@ -641,9 +721,73 @@ absl::Status AbortCliquesWithIncarnations(\n       LOG(ERROR) << \"Error aborting GPU clique \" << key.ToString() << \": \" << s;\n       result = std::move(s);\n     }\n-    cliques.map.erase(copy);\n+    map.erase(copy);\n   }\n   return result;\n }\n \n+// Aborts all NCCL collectives when a task fails, as reported by the\n+// UpdateGlobalProcessInfo.\n+//\n+// REQUIRES: GetProcessGpuCliques().mu held\n+static absl::Status AbortOnFailure(\n+    absl::node_hash_map<GpuCliqueKey, LockableGpuClique>& map,\n+    absl::Span<const tensorflow::CoordinatedTaskStateInfo> previous_state,\n+    absl::Span<const tensorflow::CoordinatedTaskStateInfo> current_state) {\n+  if (previous_state.empty()) {\n+    // When a job first starts, there is no previous job state.\n+    return absl::OkStatus();\n+  }\n+\n+  // We expect previous_state and current_state to have the same size, and we\n+  // expect for every i, previous_state[i] and current_state[i] correspond to\n+  // the same task.\n+  if (previous_state.size() != current_state.size()) {\n+    return FailedPrecondition(\n+        \"Previous and current job states have different sizes: %d vs %d\",\n+        previous_state.size(), current_state.size());\n+  }\n+\n+  std::vector<IncarnationId> failed_incarnations;\n+  for (int i = 0; i < previous_state.size(); ++i) {\n+    const tensorflow::CoordinatedTaskStateInfo& previous = previous_state[i];\n+    const tensorflow::CoordinatedTaskStateInfo& current = current_state[i];\n+    if (previous.task().task_id() != current.task().task_id()) {\n+      return FailedPrecondition(\n+          \"Previous and current job states have mismatched task ids: %d vs %d\",\n+          previous.task().task_id(), current.task().task_id());\n+    }\n+    if (previous.state() !=\n+        tensorflow::CoordinatedTaskState::TASKSTATE_CONNECTED) {\n+      // A task that was not previously connected cannot fail.\n+      continue;\n+    }\n+    if (current.state() !=\n+            tensorflow::CoordinatedTaskState::TASKSTATE_CONNECTED ||\n+        previous.incarnation() != current.incarnation()) {\n+      // The task is either failed, or restarted with a different incarnation.\n+      VLOG(1) << \"Task \" << previous.task().task_id() << \" (incarnation \"\n+              << previous.incarnation() << \") failed\";\n+      failed_incarnations.push_back(IncarnationId(previous.incarnation()));\n+    }\n+  }\n+\n+  if (!failed_incarnations.empty()) {\n+    return AbortCliquesWithIncarnations(map, failed_incarnations);\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status UpdateGlobalProcessInfo(\n+    absl::Span<tensorflow::CoordinatedTaskStateInfo> infos) {\n+  ProcessGpuCliques& cliques = GetProcessGpuCliques();\n+  absl::MutexLock lock(&cliques.mu);\n+  absl::Status s = AbortOnFailure(cliques.map, cliques.task_state_infos, infos);\n+  if (!s.ok()) {\n+    LOG(WARNING) << s;\n+  }\n+  cliques.task_state_infos = {infos.begin(), infos.end()};\n+  return s;\n+}\n+\n }  // namespace xla::gpu"
        },
        {
            "sha": "bf55b51caff98b6e4fa6f08e1bc0dc994643bad7",
            "filename": "third_party/xla/xla/backends/gpu/collectives/gpu_cliques.h",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/835244af8a0ec3d853135b17fe6a2b7ac45261e7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_cliques.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/835244af8a0ec3d853135b17fe6a2b7ac45261e7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_cliques.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_cliques.h?ref=835244af8a0ec3d853135b17fe6a2b7ac45261e7",
            "patch": "@@ -69,12 +69,11 @@ absl::StatusOr<std::shared_ptr<LockableGpuClique::Lock>> AcquireGpuClique(\n     const GpuCollectives::CliqueIdCallback& clique_id_callback, RankId rank,\n     const AcquiredCliquesMap& acquired_cliques, int64_t max_nchannels = 0);\n \n-// Aborts and invalidates all cliques that have been created via\n-// AcquireGpuClique with any of the provided incarnations. For example, if\n-// incarnations is [1, 2], then all cliques with a clique key that includes\n-// incarnations 1 or 2 will be aborted.\n-absl::Status AbortCliquesWithIncarnations(\n-    absl::Span<const IncarnationId> incarnations);\n+// Updates the global set of task state information. This function aborts and\n+// invalidates all cliques that were created via AcquireGpuClique with\n+// incarnations that have become stale.\n+absl::Status UpdateGlobalProcessInfo(\n+    absl::Span<tensorflow::CoordinatedTaskStateInfo> infos);\n \n }  // namespace xla::gpu\n "
        },
        {
            "sha": "dd0cb124831b27d7a72a238013451a9fd756e4c5",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 54,
            "changes": 57,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/835244af8a0ec3d853135b17fe6a2b7ac45261e7/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/835244af8a0ec3d853135b17fe6a2b7ac45261e7/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=835244af8a0ec3d853135b17fe6a2b7ac45261e7",
            "patch": "@@ -567,55 +567,6 @@ static absl::flat_hash_map<std::string, PjRtDeviceAttribute> GetAttrsForDevices(\n   return attrs;\n }\n \n-// Aborts all NCCL collectives when a task fails, as reported by the\n-// JobStateUpdate.\n-absl::Status AbortOnFailure(\n-    absl::Span<const tensorflow::CoordinatedTaskStateInfo> previous_state,\n-    absl::Span<const tensorflow::CoordinatedTaskStateInfo> current_state) {\n-  if (previous_state.empty()) {\n-    // When a job first starts, there is no previous job state.\n-    return absl::OkStatus();\n-  }\n-\n-  // We expect previous_state and current_state to have the same size, and we\n-  // expect for every i, previous_state[i] and current_state[i] correspond to\n-  // the same task.\n-  if (previous_state.size() != current_state.size()) {\n-    return FailedPrecondition(\n-        \"Previous and current job states have different sizes: %d vs %d\",\n-        previous_state.size(), current_state.size());\n-  }\n-\n-  std::vector<IncarnationId> failed_incarnations;\n-  for (int i = 0; i < previous_state.size(); ++i) {\n-    const tensorflow::CoordinatedTaskStateInfo& previous = previous_state[i];\n-    const tensorflow::CoordinatedTaskStateInfo& current = current_state[i];\n-    if (previous.task().task_id() != current.task().task_id()) {\n-      return FailedPrecondition(\n-          \"Previous and current job states have mismatched task ids: %d vs %d\",\n-          previous.task().task_id(), current.task().task_id());\n-    }\n-    if (previous.state() !=\n-        tensorflow::CoordinatedTaskState::TASKSTATE_CONNECTED) {\n-      // A task that was not previously connected cannot fail.\n-      continue;\n-    }\n-    if (current.state() !=\n-            tensorflow::CoordinatedTaskState::TASKSTATE_CONNECTED ||\n-        previous.incarnation() != current.incarnation()) {\n-      // The task is either failed, or restarted with a different incarnation.\n-      VLOG(1) << \"Task \" << previous.task().task_id() << \" (incarnation \"\n-              << previous.incarnation() << \") failed\";\n-      failed_incarnations.push_back(IncarnationId(previous.incarnation()));\n-    }\n-  }\n-\n-  if (!failed_incarnations.empty()) {\n-    return xla::gpu::AbortCliquesWithIncarnations(failed_incarnations);\n-  }\n-  return absl::OkStatus();\n-}\n-\n StreamExecutorGpuClient::StreamExecutorGpuClient(\n     std::string platform_name, LocalClient* client,\n     std::vector<std::unique_ptr<PjRtStreamExecutorDevice>> devices,\n@@ -698,12 +649,10 @@ void StreamExecutorGpuClient::UpdateGlobalProcessInfo(\n   if (!abort_collectives_on_failure_) {\n     return;\n   }\n-\n-  absl::MutexLock lock(task_state_infos_mu_);\n-  if (absl::Status s = AbortOnFailure(task_state_infos_, infos); !s.ok()) {\n-    LOG(ERROR) << s;\n+  absl::Status s = ::xla::gpu::UpdateGlobalProcessInfo(infos);\n+  if (!s.ok()) {\n+    LOG(WARNING) << s;\n   }\n-  task_state_infos_ = {infos.begin(), infos.end()};\n }\n \n absl::StatusOr<std::unique_ptr<PjRtClient::AsyncHostToDeviceTransferManager>>"
        },
        {
            "sha": "b1feb2062eee54fe9682c1c8a51e9065313ad71c",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/835244af8a0ec3d853135b17fe6a2b7ac45261e7/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/835244af8a0ec3d853135b17fe6a2b7ac45261e7/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h?ref=835244af8a0ec3d853135b17fe6a2b7ac45261e7",
            "patch": "@@ -186,10 +186,6 @@ class StreamExecutorGpuClient : public xla::PjRtStreamExecutorClient {\n   const bool abort_collectives_on_failure_ = false;\n   std::optional<xla::StreamExecutorGpuTopologyDescription> topology_;\n   std::shared_ptr<KeyValueStoreInterface> kv_store_;\n-\n-  absl::Mutex task_state_infos_mu_;\n-  std::vector<tensorflow::CoordinatedTaskStateInfo> task_state_infos_\n-      ABSL_GUARDED_BY(task_state_infos_mu_);\n };\n \n std::vector<std::unique_ptr<PjRtStreamExecutorDevice>> BuildLocalDevices("
        }
    ],
    "stats": {
        "total": 233,
        "additions": 161,
        "deletions": 72
    }
}