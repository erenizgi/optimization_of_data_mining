{
    "author": "basioli-k",
    "message": "[XLA:GPU][codegen] Emit stablehlo for iota and implement lowering of stablehlo.iota to tt.make_range\n\nPiperOrigin-RevId: 819934458",
    "sha": "dd90f5fa764a146df23215c5f58ecb563a9dc2d9",
    "files": [
        {
            "sha": "84c3d2f63e6230daa807287d648619eceb0f6ef6",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=dd90f5fa764a146df23215c5f58ecb563a9dc2d9",
            "patch": "@@ -334,9 +334,10 @@ ScalarOrTensor BroadcastInDims(EmitterLocOpBuilder b, ScalarOrTensor value,\n   return Broadcast(b, input_tensor, output_shape);\n }\n \n-ScalarOrTensor Range(EmitterLocOpBuilder b, int32_t limit) {\n+ScalarOrTensor Iota(EmitterLocOpBuilder b, int32_t limit) {\n   auto type = mlir::RankedTensorType::get(limit, b.getI32Type());\n-  return ScalarOrTensor(b.create<ttir::MakeRangeOp>(type, 0, limit));\n+  return ScalarOrTensor(\n+      b.create<stablehlo::IotaOp>(type, /*iota_dimension=*/0));\n }\n \n ScalarOrTensor EmitParameterExtract(EmitterLocOpBuilder b,\n@@ -398,7 +399,7 @@ absl::StatusOr<ScalarOrTensor> EmitReduce(\n   int64_t input_reduction_dimension_size = input_shape[reduction_dimension];\n   if (input_reduction_dimension_size !=\n       source_tensor_reduction_dimension_size) {\n-    ScalarOrTensor range = Range(b, input_reduction_dimension_size);\n+    ScalarOrTensor range = Iota(b, input_reduction_dimension_size);\n     ScalarOrTensor bcast =\n         BroadcastInDims(b, range, input_shape, {reduction_dimension});\n     ScalarOrTensor constant = CreateConst(\n@@ -538,7 +539,7 @@ absl::StatusOr<ScalarOrTensor> EmitTiledIota(\n \n   // First, stride as needed between the iota components.\n   Value range = b.create<arith::MulIOp>(\n-      Range(b, padded_tile_sizes[iota_dim]).UnwrapTensor(),\n+      Iota(b, padded_tile_sizes[iota_dim]).UnwrapTensor(),\n       Splat(b,\n             CreateConst(b, b.getI32Type(), tiled_iota.tile_strides()[iota_dim]),\n             padded_tile_sizes[iota_dim])\n@@ -826,7 +827,7 @@ absl::StatusOr<Value> MaskDotOperand(EmitterLocOpBuilder b,\n       // operand = select(broadcast(mask, operand.shape), operand, 0)\n       Value tile_offset = b.create<arith::MulIOp>(\n           contracting_dimension_tile_index, tile_size_value);\n-      Value range = Range(b, tile_size).UnwrapTensor();\n+      Value range = Iota(b, tile_size).UnwrapTensor();\n       Value broadcasted_tile_offset =\n           Splat(b, ScalarOrTensor(tile_offset), {tile_size}).UnwrapTensor();\n       Value indices = b.create<arith::AddIOp>(range, broadcasted_tile_offset);\n@@ -1389,7 +1390,7 @@ absl::StatusOr<ScalarOrTensor> EmitPad(\n     }\n \n     // LHS for the compare is an iota broadcasted to the output shape.\n-    ScalarOrTensor range = Range(b, pad_output_dim_size);\n+    ScalarOrTensor range = Iota(b, pad_output_dim_size);\n     ScalarOrTensor bcast = BroadcastInDims(b, range, padded_tile_sizes,\n                                            {static_cast<int64_t>(dim_index)});\n "
        },
        {
            "sha": "d2a8dd131a4cd5160fa247fde92a12f40d13a291",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 118,
            "deletions": 18,
            "changes": 136,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=dd90f5fa764a146df23215c5f58ecb563a9dc2d9",
            "patch": "@@ -870,12 +870,24 @@ ENTRY main {\n         \"num_ctas\":\"1\",\n         \"num_stages\":\"1\"}}}\n })\";\n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText,\n-                                          \"triton_reduction_computation\", R\"(\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"triton_reduction_computation\",\n+                                R\"(\n+CHECK:  stablehlo.iota\n+CHECK-COUNT-4:  tt.expand_dims\n+CHECK:  \"tt.reduce\"(%[[SELECT:.*]]) <{axis = 2 : i32}>\n+          )\"));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n CHECK:  tt.make_range\n CHECK-COUNT-4:  tt.expand_dims\n CHECK:  \"tt.reduce\"(%[[SELECT:.*]]) <{axis = 2 : i32}>\n-)\"));\n+  )\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_reduction_computation\")));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n@@ -908,8 +920,27 @@ ENTRY main {\n           \"num_ctas\":\"1\",\n           \"num_stages\":\"1\"}}}\n })\";\n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText,\n-                                          \"triton_reduction_computation\", R\"(\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"triton_reduction_computation\",\n+                                R\"(\n+; Make sure input reduction tile is padded with a neutral value.\n+CHECK:  %[[LOAD:.*]] = triton_xla.extract\n+CHECK:  %[[RANGE:.*]] = stablehlo.iota\n+CHECK:  %[[EXPAND:.*]] = tt.expand_dims %[[RANGE]]\n+CHECK:  %[[BROADCAST:.*]] = tt.broadcast %[[EXPAND]]\n+CHECK:  %[[CMPI:.*]] = arith.cmpi slt, %[[BROADCAST]]\n+CHECK:  %[[SELECT:.*]] = arith.select %[[CMPI]], %[[LOAD]]\n+CHECK:  \"tt.reduce\"(%[[SELECT]]) <{axis = 0 : i32}>\n+CHECK:  ^bb0(%[[ARG2:.*]]: f32, %[[ARG3:.*]]: f32):\n+CHECK:    %[[MAXIMUM:.*]] = arith.maximumf %[[ARG2]], %[[ARG3]] : f32\n+CHECK:    tt.reduce.return %[[MAXIMUM]] : f32\n+CHECK:  })\n+          )\"));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n ; Make sure input reduction tile is padded with a neutral value.\n CHECK:  %[[LOAD:.*]] = triton_xla.extract\n CHECK:  %[[RANGE:.*]] = tt.make_range\n@@ -922,7 +953,9 @@ CHECK:  ^bb0(%[[ARG2:.*]]: f32, %[[ARG3:.*]]: f32):\n CHECK:    %[[MAXIMUM:.*]] = arith.maximumf %[[ARG2]], %[[ARG3]] : f32\n CHECK:    tt.reduce.return %[[MAXIMUM]] : f32\n CHECK:  })\n-)\"));\n+  )\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_reduction_computation\")));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n@@ -1797,8 +1830,32 @@ ENTRY main {\n           \"num_ctas\":\"1\",\n           \"num_stages\":\"1\"}}}\n })\";\n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\",\n-                                          R\"(\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+// #xla.indexing_map<\"(pid_0) -> (pid_0 * 32), domain: pid_0 in [0, 1]\n+\n+// CHECK: func @{{.*}}(%[[IN:.*]]: !tt.ptr<f32>, %[[OUT:.*]]: !tt.ptr<f32>)\n+\n+// CHECK: %[[EXTRACT:.*]] = triton_xla.extract from %[[IN]] {{.*}}\n+// CHECK: %[[PAD_VALUE:.*]] = arith.constant 1.000000e+00 : f32\n+// CHECK: %[[TILE_OFFSET:.*]] = xla.apply_indexing\n+// CHECK: %[[IOTA_VAL:.*]] = stablehlo.iota dim = 0 : tensor<32xi32>\n+// CHECK: %[[IOTA:.*]] = tt.broadcast %[[IOTA_VAL]] : tensor<32xi32> -> tensor<32xi32>\n+// CHECK: %[[TILE_OFFSET_I32:.*]] = arith.index_cast %[[TILE_OFFSET]]\n+// CHECK: %[[C17:.*]] = arith.constant 17 : i32\n+// CHECK: %[[THRESHOLD:.*]] = arith.subi %[[C17]], %[[TILE_OFFSET_I32]]\n+// CHECK: %[[THRESHOLD_SPLAT:.*]] = tt.splat %[[THRESHOLD]]\n+// CHECK: %[[MASK:.*]] = arith.cmpi slt, %[[IOTA]], %[[THRESHOLD_SPLAT]]\n+// CHECK: %[[PAD_SPLAT:.*]] = tt.splat %[[PAD_VALUE]] : f32 -> tensor<32xf32>\n+// CHECK: %[[SELECT:.*]] = arith.select %[[MASK]], %[[EXTRACT]], %[[PAD_SPLAT]]\n+\n+// CHECK:   triton_xla.insert %[[SELECT]] into %[[OUT]]\n+          )\"));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n // #xla.indexing_map<\"(pid_0) -> (pid_0 * 32), domain: pid_0 in [0, 1]\n \n // CHECK: func @{{.*}}(%[[IN:.*]]: !tt.ptr<f32>, %[[OUT:.*]]: !tt.ptr<f32>)\n@@ -1819,7 +1876,9 @@ ENTRY main {\n \n // CHECK:   triton_xla.insert %[[SELECT]] into %[[OUT]]\n // CHECK-SAME: [%[[TILE_OFFSET]]] [32] [1] : tensor<32xf32>\n-  )\"));\n+  )\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_computation\")));\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n \n@@ -1843,8 +1902,25 @@ ENTRY main {\n           \"num_ctas\":\"1\",\n           \"num_stages\":\"1\"}}}\n })\";\n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\",\n-                                          R\"(\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+// CHECK: triton_xla.extract {{.*}} : tensor<32x16xf32>\n+// CHECK: stablehlo.iota dim = 0 : tensor<32xi32>\n+// CHECK: tt.expand_dims\n+// CHECK: tt.broadcast\n+// CHECK: arith.cmpi\n+// CHECK: stablehlo.iota dim = 0 : tensor<16xi32>\n+// CHECK: tt.expand_dims\n+// CHECK: tt.broadcast\n+// CHECK: arith.cmpi slt\n+// CHECK: arith.andi\n+// CHECK: arith.select\n+          )\"));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n // CHECK: triton_xla.extract {{.*}} : tensor<32x16xf32>\n // CHECK: tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32>\n // CHECK: tt.expand_dims\n@@ -1856,7 +1932,9 @@ ENTRY main {\n // CHECK: arith.cmpi slt\n // CHECK: arith.andi\n // CHECK: arith.select\n-  )\"));\n+  )\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_computation\")));\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n \n@@ -2540,11 +2618,20 @@ ENTRY main {\n         \"num_stages\":\"1\"}}}\n })\";\n \n-  TF_EXPECT_OK(\n-      CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+CHECK:      %[[RANGE:.*]] = stablehlo.iota dim = 0 : tensor<64xi32>\n+CHECK:      arith.muli{{.*}} %[[RANGE]]\n+          )\"));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n CHECK:      %[[RANGE:.*]] = tt.make_range {{.*}} : tensor<64xi32>\n CHECK:      arith.muli{{.*}} %[[RANGE]]\n-)\"));\n+  )\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_computation\")));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n@@ -2574,14 +2661,27 @@ ENTRY main {\n })\",\n                        primitive_util::LowercasePrimitiveTypeName(data_type));\n \n-  TF_EXPECT_OK(\n-      CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+CHECK:      %[[RANGE:.*]] = stablehlo.iota dim = 0 : tensor<64xi32>\n+CHECK:      %[[MUL:.*]] = arith.muli %[[RANGE]], {{.*}} : tensor<64xi32>\n+CHECK:      arith.addi{{.*}} %[[MUL]]\n+            // Omit the data type below, since it depends on a test parameter\n+            // and is not abbreviated the same as in HLO.\n+CHECK:      tt.broadcast {{.*}} -> tensor<1x2x64x8x\n+          )\"));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n CHECK:      %[[RANGE:.*]] = tt.make_range {{.*}} : tensor<64xi32>\n CHECK:      arith.addi{{.*}} %[[RANGE]]\n             // Omit the data type below, since it depends on a test parameter\n             // and is not abbreviated the same as in HLO.\n CHECK:      tt.broadcast {{.*}} -> tensor<1x2x64x8x\n-)\"));\n+  )\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_computation\")));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }"
        },
        {
            "sha": "51dc00bf5862d09bcccc0740c709e5e3e284f649",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_shared_dialect_test.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc?ref=dd90f5fa764a146df23215c5f58ecb563a9dc2d9",
            "patch": "@@ -97,6 +97,33 @@ CHECK: %[[RES:.*]] = tensor.bitcast %[[ARG:.*]] : tensor<16x32xf32> to tensor<16\n )\"));\n }\n \n+TEST_F(XTileDialectTest, TestEmittingStableHloIota) {\n+  constexpr absl::string_view kHloText = R\"(\n+HloModule t, is_scheduled=true\n+\n+iota_fusion {\n+  ROOT iota = s32[256] iota(), iota_dimension=0\n+}\n+\n+ENTRY e {\n+  ROOT custom-call = s32[256] fusion(), kind=kCustom,\n+    calls=iota_fusion,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton\"}}\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(kHloText));\n+\n+  BlockLevelParameters block_level_parameters;\n+  block_level_parameters.output_tile_sizes = {{16}};\n+\n+  TF_EXPECT_OK(CreateXTileIrAndFileCheck(\n+      this, *module->GetComputationWithName(\"iota_fusion\"),\n+      block_level_parameters,\n+      R\"(\n+CHECK: %[[RES:.*]] = stablehlo.iota dim = 0 : tensor<16xi32>\n+)\"));\n+}\n+\n }  // namespace\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "a612d6993d061c1ca86e3cded90385daf0e5dc92",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD?ref=dd90f5fa764a146df23215c5f58ecb563a9dc2d9",
            "patch": "@@ -63,6 +63,7 @@ cc_library(\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\","
        },
        {
            "sha": "f03ad5920684b48cc06d219948e14786cfc45af0",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/stablehlo_lower_to_triton.cc",
            "status": "modified",
            "additions": 36,
            "deletions": 0,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc?ref=dd90f5fa764a146df23215c5f58ecb563a9dc2d9",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"llvm/ADT/SmallVector.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n+#include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/Diagnostics.h\"\n #include \"mlir/IR/PatternMatch.h\"\n #include \"mlir/IR/Value.h\"\n@@ -56,13 +57,48 @@ class LowerTranspose : public mlir::OpRewritePattern<stablehlo::TransposeOp> {\n   }\n };\n \n+class LowerIotaToMakeRange : public mlir::OpRewritePattern<stablehlo::IotaOp> {\n+ public:\n+  using OpRewritePattern::OpRewritePattern;\n+\n+ private:\n+  mlir::LogicalResult matchAndRewrite(\n+      stablehlo::IotaOp op, mlir::PatternRewriter& rewriter) const override {\n+    auto result_type = op.getResult().getType();\n+\n+    if (result_type.getRank() != 1) {\n+      return rewriter.notifyMatchFailure(\n+          op->getLoc(), \"tt.make_range is only supported for 1D outputs.\");\n+    }\n+\n+    if (!result_type.getElementType().isInteger(32)) {\n+      return rewriter.notifyMatchFailure(\n+          op->getLoc(), \"tt.make_range is only supported for integer types.\");\n+    }\n+\n+    if (result_type.getElementType().isUnsignedInteger(32)) {\n+      return rewriter.notifyMatchFailure(\n+          op->getLoc(),\n+          \"lowering to tt.make_range is only supported for 32 bit signed \"\n+          \"integers.\");\n+    }\n+\n+    auto iota_end = result_type.getDimSize(0);\n+\n+    rewriter.replaceOpWithNewOp<ttir::MakeRangeOp>(op, result_type,\n+                                                   /*start=*/0, iota_end);\n+    return mlir::success();\n+  }\n+};\n+\n class StableHLOLowerToTritonPass\n     : public impl::StableHLOLowerToTritonPassBase<StableHLOLowerToTritonPass> {\n  public:\n   void runOnOperation() override {\n     mlir::MLIRContext* mlir_context = &getContext();\n     mlir::RewritePatternSet patterns(mlir_context);\n     patterns.add<LowerTranspose>(mlir_context);\n+    patterns.add<LowerTranspose, LowerIotaToMakeRange>(mlir_context);\n \n     if (mlir::failed(\n             mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {"
        },
        {
            "sha": "e03f2622b6e563c67ca48882afc0f5cb64477e4a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/stable_hlo_to_triton_lowering.mlir",
            "status": "modified",
            "additions": 25,
            "deletions": 1,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd90f5fa764a146df23215c5f58ecb563a9dc2d9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir?ref=dd90f5fa764a146df23215c5f58ecb563a9dc2d9",
            "patch": "@@ -8,4 +8,28 @@ func.func @lower_transpose(%arg0: tensor<2x4x8xf32>) -> tensor<8x2x4xf32> {\n   %0 = stablehlo.transpose %arg0, dims = [2, 0, 1] : (tensor<2x4x8xf32>) -> tensor<8x2x4xf32>\n   // CHECK: return %[[RES]] : tensor<8x2x4xf32>\n   return %0 : tensor<8x2x4xf32>\n-}\n\\ No newline at end of file\n+}\n+\n+// CHECK: func @lower_iota_to_make_range() -> tensor<16xi32>\n+func.func @lower_iota_to_make_range() -> tensor<16xi32> {\n+  // CHECK: %[[RES:.*]] = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32>\n+  %0 = stablehlo.iota dim = 0 : tensor<16xi32>\n+  // CHECK: return %[[RES]] : tensor<16xi32>\n+  return %0 : tensor<16xi32>\n+}\n+\n+// CHECK: func @lower_iota_on_multidimensional_tensor_falls_back_to_stablehlo() -> tensor<16x32xi32>\n+func.func @lower_iota_on_multidimensional_tensor_falls_back_to_stablehlo() -> tensor<16x32xi32> {\n+  // CHECK: %[[RES:.*]] = stablehlo.iota dim = 0 : tensor<16x32xi32>\n+  %0 = stablehlo.iota dim = 0 : tensor<16x32xi32>\n+  // CHECK: return %[[RES]] : tensor<16x32xi32>\n+  return %0 : tensor<16x32xi32>\n+}\n+\n+// CHECK: func @lower_iota_on_non_signed_32_bit_tensor_falls_back_to_stablehlo() -> tensor<8xui32>\n+func.func @lower_iota_on_non_signed_32_bit_tensor_falls_back_to_stablehlo() -> tensor<8xui32> {\n+  // CHECK: %[[RES:.*]] = stablehlo.iota dim = 0 : tensor<8xui32>\n+  %0 = stablehlo.iota dim = 0 : tensor<8xui32>\n+  // CHECK: return %[[RES]] : tensor<8xui32>\n+  return %0 : tensor<8xui32>\n+}"
        }
    ],
    "stats": {
        "total": 239,
        "additions": 214,
        "deletions": 25
    }
}