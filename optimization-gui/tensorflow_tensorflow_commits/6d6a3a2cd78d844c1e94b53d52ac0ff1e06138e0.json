{
    "author": "akuegel",
    "message": "[XLA:GPU] Move code out of coalescing_analysis.cc (NFC)\n\nWe want to reuse this code for determining possible unroll factors. Since\ncoalescing_analysis depends on fusion emitters, and we want to compute unroll\nfactors in fusion emitters, we need to make sure the extracted code has no\ndependency on fusion emitters. Therefore we need to also adapt the function\nsignature of GetThreadIdToInputMemoryLayoutsMaps.\n\nPiperOrigin-RevId: 810842014",
    "sha": "6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0",
    "files": [
        {
            "sha": "b556d0c55d160ff0151d2ce4dd33f52414e4d35b",
            "filename": "third_party/xla/xla/hlo/analysis/indexing_analysis.cc",
            "status": "modified",
            "additions": 87,
            "deletions": 0,
            "changes": 87,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc?ref=6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0",
            "patch": "@@ -1547,6 +1547,93 @@ GroupedByOpIndexing ComputeGroupedOutputToInputIndexing(\n   return grouped_indexing_maps;\n }\n \n+namespace {\n+// Returns a linearized shape, i.e. tensor<num_elements(input) x element_type>.\n+Shape GetLinearizedShape(const Shape& shape) {\n+  if (shape.dimensions().empty()) {\n+    return shape;\n+  }\n+  std::vector<int64_t> dims{ShapeUtil::ElementsIn(shape)};\n+  auto result = Shape(shape.element_type(), dims);\n+  *result.mutable_layout() = xla::Layout({0});\n+  return result;\n+}\n+}  // namespace\n+\n+llvm::SmallVector<IndexingMap, 4> MapLogicalToLinearizedPhysicalShape(\n+    absl::Span<const HloInstruction* const> operands,\n+    mlir::MLIRContext* mlir_context) {\n+  llvm::SmallVector<IndexingMap, 4> indexing_maps;\n+  // For every operand compute thread ID -> physical layout of operand\n+  // indexing map.\n+  for (const HloInstruction* operand : operands) {\n+    const Shape& operand_shape = operand->shape();\n+\n+    IndexingMap operand_logical_to_physical_map =\n+        GetIndexingMapFromLogicalToPhysicalLayout(operand_shape, mlir_context);\n+    IndexingMap operand_physical_to_linearized_shape = GetBitcastMap(\n+        ShapeUtil::MakeShapeWithDescendingLayoutAndSamePhysicalLayout(\n+            operand_shape),\n+        GetLinearizedShape(operand_shape), mlir_context);\n+    IndexingMap operand_logical_to_linearized_physical_shape =\n+        operand_logical_to_physical_map * operand_physical_to_linearized_shape;\n+    operand_logical_to_linearized_physical_shape.Simplify();\n+    indexing_maps.push_back(\n+        std::move(operand_logical_to_linearized_physical_shape));\n+  }\n+  return indexing_maps;\n+}\n+\n+void GetThreadIdToInputMemoryLayoutsMaps(\n+    const HloFusionAdaptor& fusion_adaptor,\n+    absl::Span<const IndexingMap> hero_indexing_maps,\n+    const HloInstructionAdaptor& hero,\n+    absl::Span<const HloInstruction* const> operands,\n+    absl::Span<const IndexingMap> operand_logical_to_linearized_physical_maps,\n+    MLIRContext* mlir_context, GroupedByOpIndexingMap& result) {\n+  for (const auto& [hero_operand_index, hero_operand] :\n+       llvm::enumerate(hero.GetOperands())) {\n+    if (hero_operand.shape().dimensions().empty()) {\n+      continue;\n+    }\n+    // Compute thread ID -> hero operand indexing map.\n+    const IndexingMap& thread_id_to_hero_operand_map =\n+        hero_indexing_maps[hero_operand_index];\n+    // Compute indexing from output to inputs for logical layout.\n+    GroupedByOpIndexing instr_indexing_keyed_by_operands =\n+        ComputeGroupedOutputToInputIndexing(fusion_adaptor, hero_operand,\n+                                            mlir_context);\n+    // For every operand compute thread ID -> physical layout of operand\n+    // indexing map.\n+    for (auto&& [operand, operand_linarized_physical_map] :\n+         llvm::zip(operands, operand_logical_to_linearized_physical_maps)) {\n+      auto operand_indexing_maps_it =\n+          instr_indexing_keyed_by_operands.find(operand);\n+      if (operand_indexing_maps_it == instr_indexing_keyed_by_operands.end()) {\n+        continue;\n+      }\n+\n+      for (const OperandIndexing& operand_indexing :\n+           operand_indexing_maps_it->second) {\n+        const IndexingMap& operand_indexing_map = operand_indexing.map();\n+        // If one of the indexing maps for the operand is undefined, we remove\n+        // all indexing maps for it and store only the undefined one.\n+        if (operand_indexing_map.IsUndefined()) {\n+          result[operand] = {operand_indexing_map};\n+          break;\n+        }\n+        IndexingMap logical_output_to_linearized_physical_input_map =\n+            operand_indexing_map * operand_linarized_physical_map;\n+        IndexingMap thread_id_to_linearized_physical_input_map =\n+            thread_id_to_hero_operand_map *\n+            logical_output_to_linearized_physical_input_map;\n+        thread_id_to_linearized_physical_input_map.Simplify();\n+        result[operand].insert(thread_id_to_linearized_physical_input_map);\n+      }\n+    }\n+  }\n+}\n+\n HloInstructionIndexing ComputeOutputToInputAllGatherOpIndexing(\n     const HloAllGatherInstruction* instr, MLIRContext* ctx) {\n   // CHECK_EQ(instr->all_gather_dimension(), 0);"
        },
        {
            "sha": "301e8f8080c9b2b14b4cce9c1f211ec07f7a58c9",
            "filename": "third_party/xla/xla/hlo/analysis/indexing_analysis.h",
            "status": "modified",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.h?ref=6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0",
            "patch": "@@ -208,6 +208,24 @@ GroupedByOpIndexing ComputeGroupedOutputToInputIndexing(\n     const HloFusionAdaptor& fusion_adaptor, HloInstructionAdaptor target_instr,\n     mlir::MLIRContext* ctx);\n \n+// Returns the indexing map from logical to linearized physical shape for each\n+// operand.\n+llvm::SmallVector<IndexingMap, 4> MapLogicalToLinearizedPhysicalShape(\n+    absl::Span<const HloInstruction* const> operands,\n+    mlir::MLIRContext* mlir_context);\n+\n+// Computes the indexing map from logical to linearized physical shape for each\n+// operand and adds them to `result`. `result` may be non-empty when this\n+// function is called and can be used to accumulate results from several calls\n+// of this function (e.g. with different `root_index`).\n+void GetThreadIdToInputMemoryLayoutsMaps(\n+    const HloFusionAdaptor& fusion_adaptor,\n+    absl::Span<const IndexingMap> hero_indexing_maps,\n+    const HloInstructionAdaptor& hero,\n+    absl::Span<const HloInstruction* const> operands,\n+    absl::Span<const IndexingMap> operand_logical_to_linearized_physical_maps,\n+    mlir::MLIRContext* mlir_context, GroupedByOpIndexingMap& result);\n+\n // Groups indexing maps by instructions.\n GroupedByOpIndexing GroupIndexingMapsByProducers(\n     const HloInstructionIndexing& indexing, const HloInstruction* instr);"
        },
        {
            "sha": "4118a80bb9053793e0de152398356eb46c6b58e4",
            "filename": "third_party/xla/xla/service/gpu/model/coalescing_analysis.cc",
            "status": "modified",
            "additions": 36,
            "deletions": 111,
            "changes": 147,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcoalescing_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcoalescing_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcoalescing_analysis.cc?ref=6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0",
            "patch": "@@ -219,87 +219,6 @@ bool EstimateCoalescingViaMemoryTransactionsCount(\n          memory_transactions * kIsCoalescedThreshold;\n }\n \n-// Returns a linearized shape, i.e. tensor<num_elements(input) x element_type>.\n-Shape GetLinearizedShape(const Shape& shape) {\n-  if (shape.dimensions().empty()) {\n-    return shape;\n-  }\n-  std::vector<int64_t> dims{ShapeUtil::ElementsIn(shape)};\n-  auto result = Shape(shape.element_type(), dims);\n-  *result.mutable_layout() = xla::Layout({0});\n-  return result;\n-}\n-\n-// Returns thread ID to linearized physical layout indexing map for each operand\n-// of the fusion.\n-std::optional<GroupedByOpIndexingMap> GetThreadIdToInputMemoryLayoutsMaps(\n-    const HloFusionAnalysis& fusion_analysis,\n-    absl::Span<const HloInstruction* const> operands,\n-    MLIRContext* mlir_context) {\n-  auto emitter = GetFusionEmitter(\n-      PreBufferAssignmentFusionInfo{fusion_analysis}, mlir_context);\n-  const auto* fusion_interface =\n-      dynamic_cast<const KernelFusionInterface*>(emitter.get());\n-\n-  if (fusion_interface == nullptr) {\n-    return std::nullopt;\n-  }\n-  llvm::SmallVector<IndexingMap, 4>\n-      operand_logical_to_linearized_physical_maps =\n-          MapLogicalToLinearizedPhysicalShape(operands, mlir_context);\n-  GroupedByOpIndexingMap result;\n-  for (const auto& [root_index, hero] :\n-       llvm::enumerate(fusion_analysis.fusion_heroes())) {\n-    for (const auto& [hero_operand_index, hero_operand] :\n-         llvm::enumerate(hero.GetOperands())) {\n-      if (hero_operand.shape().dimensions().empty()) {\n-        continue;\n-      }\n-      // Compute thread ID -> hero operand indexing map.\n-      std::optional<IndexingMap> thread_id_to_hero_operand_map =\n-          fusion_interface->ComputeThreadIdToInputIndexing(\n-              root_index, hero_operand_index, mlir_context);\n-      if (!thread_id_to_hero_operand_map.has_value()) {\n-        return std::nullopt;\n-      }\n-      // Compute indexing from output to inputs for logical layout.\n-      GroupedByOpIndexing instr_indexing_keyed_by_operands =\n-          ComputeGroupedOutputToInputIndexing(fusion_analysis.fusion(),\n-                                              hero_operand, mlir_context);\n-      // For every operand compute thread ID -> physical layout of operand\n-      // indexing map.\n-      for (auto&& [operand, operand_linarized_physical_map] :\n-           llvm::zip(operands, operand_logical_to_linearized_physical_maps)) {\n-        auto operand_indexing_maps_it =\n-            instr_indexing_keyed_by_operands.find(operand);\n-        if (operand_indexing_maps_it ==\n-            instr_indexing_keyed_by_operands.end()) {\n-          continue;\n-        }\n-\n-        for (const OperandIndexing& operand_indexing :\n-             operand_indexing_maps_it->second) {\n-          const IndexingMap& operand_indexing_map = operand_indexing.map();\n-          // If one of the indexing maps for the operand is undefined, we remove\n-          // all indexing maps for it and store only the undefined one.\n-          if (operand_indexing_map.IsUndefined()) {\n-            result[operand] = {operand_indexing_map};\n-            break;\n-          }\n-          IndexingMap logical_output_to_linearized_physical_input_map =\n-              operand_indexing_map * operand_linarized_physical_map;\n-          IndexingMap thread_id_to_linearized_physical_input_map =\n-              *thread_id_to_hero_operand_map *\n-              logical_output_to_linearized_physical_input_map;\n-          thread_id_to_linearized_physical_input_map.Simplify();\n-          result[operand].insert(thread_id_to_linearized_physical_input_map);\n-        }\n-      }\n-    }\n-  }\n-  return result;\n-}\n-\n // Replaces RTVars with the midpoints of the feasible intervals.\n void AssignValuesToRTVars(IndexingMap* indexing_map) {\n   // If RTVars are present, replace them with constants.\n@@ -615,12 +534,42 @@ std::optional<CoalescingMap> ComputeCoalescingForAllOperands(\n     const HloFusionAnalysis& fusion_analysis,\n     absl::Span<const HloInstruction* const> operands,\n     MLIRContext* mlir_context) {\n-  std::optional<GroupedByOpIndexingMap> thread_id_to_input_memory_layouts =\n-      GetThreadIdToInputMemoryLayoutsMaps(fusion_analysis, operands,\n-                                          mlir_context);\n-  if (!thread_id_to_input_memory_layouts.has_value()) {\n+  auto emitter = GetFusionEmitter(\n+      PreBufferAssignmentFusionInfo{fusion_analysis}, mlir_context);\n+  const auto* fusion_interface =\n+      dynamic_cast<const KernelFusionInterface*>(emitter.get());\n+\n+  if (fusion_interface == nullptr) {\n     return std::nullopt;\n   }\n+  llvm::SmallVector<IndexingMap, 4>\n+      operand_logical_to_linearized_physical_maps =\n+          MapLogicalToLinearizedPhysicalShape(operands, mlir_context);\n+  GroupedByOpIndexingMap thread_id_to_input_memory_layouts;\n+  for (const auto& [root_index, hero] :\n+       llvm::enumerate(fusion_analysis.fusion_heroes())) {\n+    std::vector<IndexingMap> hero_indexing_maps;\n+    hero_indexing_maps.reserve(hero.GetOperands().size());\n+    // Compute thread ID -> hero operand indexing maps.\n+    for (int64_t hero_operand_index = 0;\n+         hero_operand_index < hero.GetOperands().size(); ++hero_operand_index) {\n+      // TODO(b/447057917): This can be improved to just a single call to\n+      // ComputeThreadIdToInputIndexing (without the outer for loop). The maps\n+      // for all operands are computed, anyway.\n+      std::optional<IndexingMap> thread_id_to_hero_operand_map =\n+          fusion_interface->ComputeThreadIdToInputIndexing(\n+              root_index, hero_operand_index, mlir_context);\n+      if (!thread_id_to_hero_operand_map.has_value()) {\n+        return std::nullopt;\n+      }\n+      hero_indexing_maps.push_back(thread_id_to_hero_operand_map.value());\n+    }\n+    GetThreadIdToInputMemoryLayoutsMaps(\n+        fusion_analysis.fusion(), hero_indexing_maps,\n+        fusion_analysis.fusion_hero(root_index), operands,\n+        operand_logical_to_linearized_physical_maps, mlir_context,\n+        thread_id_to_input_memory_layouts);\n+  }\n \n   CoalescingMap coalescing_per_operand;\n   for (const HloInstruction* operand : operands) {\n@@ -629,10 +578,10 @@ std::optional<CoalescingMap> ComputeCoalescingForAllOperands(\n       continue;\n     }\n     auto operand_indexing_maps =\n-        thread_id_to_input_memory_layouts->find(operand);\n+        thread_id_to_input_memory_layouts.find(operand);\n     // If there is no indexing map for the operand, it means that it is not used\n     // in the fusion cluster.\n-    if (operand_indexing_maps == thread_id_to_input_memory_layouts->end()) {\n+    if (operand_indexing_maps == thread_id_to_input_memory_layouts.end()) {\n       coalescing_per_operand.insert({operand, true});\n       continue;\n     }\n@@ -654,30 +603,6 @@ std::optional<CoalescingMap> ComputeCoalescingForAllOperands(\n \n }  // namespace\n \n-llvm::SmallVector<IndexingMap, 4> MapLogicalToLinearizedPhysicalShape(\n-    absl::Span<const HloInstruction* const> operands,\n-    MLIRContext* mlir_context) {\n-  llvm::SmallVector<IndexingMap, 4> indexing_maps;\n-  // For every operand compute thread ID -> physical layout of operand\n-  // indexing map.\n-  for (const HloInstruction* operand : operands) {\n-    const Shape& operand_shape = operand->shape();\n-\n-    IndexingMap operand_logical_to_physical_map =\n-        GetIndexingMapFromLogicalToPhysicalLayout(operand_shape, mlir_context);\n-    IndexingMap operand_physical_to_linearized_shape = GetBitcastMap(\n-        ShapeUtil::MakeShapeWithDescendingLayoutAndSamePhysicalLayout(\n-            operand_shape),\n-        GetLinearizedShape(operand_shape), mlir_context);\n-    IndexingMap operand_logical_to_linearized_physical_shape =\n-        operand_logical_to_physical_map * operand_physical_to_linearized_shape;\n-    operand_logical_to_linearized_physical_shape.Simplify();\n-    indexing_maps.push_back(\n-        std::move(operand_logical_to_linearized_physical_shape));\n-  }\n-  return indexing_maps;\n-}\n-\n /*static*/\n CoalescingAnalysis CoalescingAnalysis::Create(\n     const HloInstruction* instr,"
        },
        {
            "sha": "43784cdce7ee2612ea0da324d8d42e2f2410bab1",
            "filename": "third_party/xla/xla/service/gpu/model/coalescing_analysis.h",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcoalescing_analysis.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcoalescing_analysis.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcoalescing_analysis.h?ref=6d6a3a2cd78d844c1e94b53d52ac0ff1e06138e0",
            "patch": "@@ -99,12 +99,6 @@ double BandwidthUtilizationRateHeuristicForTiledMemoryAccess(\n bool IsTiledReadCoalescedHeuristic(const TiledHloInstruction& operand,\n                                    const se::DeviceDescription& device_info);\n \n-// Returns the indexing map from logical to linearized physical shape for each\n-// operand.\n-llvm::SmallVector<IndexingMap, 4> MapLogicalToLinearizedPhysicalShape(\n-    absl::Span<const HloInstruction* const> operands,\n-    mlir::MLIRContext* mlir_context);\n-\n }  // namespace xla::gpu\n \n #endif  // XLA_SERVICE_GPU_MODEL_COALESCING_ANALYSIS_H_"
        }
    ],
    "stats": {
        "total": 258,
        "additions": 141,
        "deletions": 117
    }
}