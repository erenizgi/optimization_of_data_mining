{
    "author": "hawkinsp",
    "message": "[XLA] Delete hlo_module_group_metadata, which is unused.\n\nPiperOrigin-RevId: 815947381",
    "sha": "e7146b5a3a83c4b01432ecdf7b6d17796c12cbfe",
    "files": [
        {
            "sha": "a6b688e3dbd82187a5a48165e7e0a8467a28bfcc",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 19,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e7146b5a3a83c4b01432ecdf7b6d17796c12cbfe/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e7146b5a3a83c4b01432ecdf7b6d17796c12cbfe/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=e7146b5a3a83c4b01432ecdf7b6d17796c12cbfe",
            "patch": "@@ -1848,25 +1848,6 @@ xla_cc_test(\n     ],\n )\n \n-cc_library(\n-    name = \"hlo_module_group_metadata\",\n-    srcs = [\"hlo_module_group_metadata.cc\"],\n-    hdrs = [\"hlo_module_group_metadata.h\"],\n-    deps = [\n-        \"//xla:shape_util\",\n-        \"//xla:status_macros\",\n-        \"//xla:util\",\n-        \"//xla/hlo/ir:hlo\",\n-        \"@com_google_absl//absl/container:flat_hash_map\",\n-        \"@com_google_absl//absl/container:flat_hash_set\",\n-        \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/status:statusor\",\n-        \"@local_tsl//tsl/platform:errors\",\n-        \"@local_tsl//tsl/platform:logging\",\n-        \"@local_tsl//tsl/platform:status\",\n-    ],\n-)\n-\n cc_library(\n     name = \"hlo_module_util\",\n     srcs = [\"hlo_module_util.cc\"],"
        },
        {
            "sha": "1b064ebbada97b70dda58ad14714f18105a95fee",
            "filename": "third_party/xla/xla/service/hlo_module_group_metadata.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 567,
            "changes": 567,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/77fd9546fd5f278d86c11ab367a28b96913a661c/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_group_metadata.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/77fd9546fd5f278d86c11ab367a28b96913a661c/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_group_metadata.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_group_metadata.cc?ref=77fd9546fd5f278d86c11ab367a28b96913a661c",
            "patch": "@@ -1,567 +0,0 @@\n-/* Copyright 2018 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/hlo_module_group_metadata.h\"\n-\n-#include <memory>\n-#include <sstream>\n-#include <string>\n-#include <utility>\n-\n-#include \"absl/container/flat_hash_set.h\"\n-#include \"xla/hlo/ir/dfs_hlo_visitor_with_default.h\"\n-#include \"xla/hlo/ir/hlo_casting_utils.h\"\n-#include \"xla/hlo/ir/hlo_instructions.h\"\n-#include \"xla/shape_util.h\"\n-#include \"xla/status_macros.h\"\n-#include \"xla/util.h\"\n-#include \"tsl/platform/errors.h\"\n-#include \"tsl/platform/logging.h\"\n-\n-namespace xla {\n-\n-std::string HloModuleGroupMetadata::TrackedInstruction::ToString() const {\n-  std::string repr =\n-      (instruction_ != nullptr) ? instruction_->ToShortString() : \"NULL\";\n-  switch (kind_) {\n-    case ComputationKind::kInvalid:\n-      repr += \":INVALID\";\n-      break;\n-    case ComputationKind::kWhileCondition:\n-      repr += \":WHILE_CONDITION\";\n-      break;\n-    case ComputationKind::kWhileBody:\n-      repr += \":WHILE_BODY\";\n-      break;\n-    case ComputationKind::kConditionalBranch:\n-      repr += absl::StrCat(\":CONDITIONAL_BRANCH_\", index_);\n-      break;\n-    case ComputationKind::kCallFunction:\n-      repr += \":CALL\";\n-      break;\n-  }\n-  return repr;\n-}\n-\n-/* static */ absl::StatusOr<std::unique_ptr<HloModuleGroupMetadata>>\n-HloModuleGroupMetadata::Build(absl::Span<HloModule* const> modules) {\n-  auto metadata = std::make_unique<HloModuleGroupMetadata>(modules);\n-  TF_RETURN_IF_ERROR(metadata->Build());\n-  return std::move(metadata);\n-}\n-\n-absl::Status HloModuleGroupMetadata::Build() {\n-  TF_RETURN_IF_ERROR(RecordInstructions());\n-  TF_RETURN_IF_ERROR(VerifyChannelInstructions());\n-\n-  // Record all companion while instructions.\n-  const auto visitor = [this](HloInstruction* hlo) -> absl::Status {\n-    // We only need to process if the instruction is within the computation\n-    // of a companion instruction, like in the condition or body computation\n-    // of a While.\n-    const TrackedInstruction* tracked = GetTrackedInstruction(hlo->parent());\n-    if (tracked == nullptr) {\n-      return absl::OkStatus();\n-    }\n-\n-    if (IsChannelInstruction(hlo) || IsNonSpmdCrossModuleAllReduce(hlo)) {\n-      std::vector<HloComputation*> peers;\n-      if (IsChannelInstruction(hlo)) {\n-        peers.push_back(PeerComputation(hlo));\n-      } else if (IsNonSpmdCrossModuleAllReduce(hlo)) {\n-        for (HloInstruction* instr : GetAllReduceGroup(*hlo->channel_id())) {\n-          if (instr == hlo) {\n-            continue;\n-          }\n-          peers.push_back(instr->parent());\n-        }\n-      }\n-\n-      // Add the parent computation of this channel (or all-reduce) instruction\n-      // and its peer computation(s) (both must be while computations) as\n-      // companions.\n-      for (HloComputation* peer_computation : peers) {\n-        const TrackedInstruction* peer_tracked =\n-            GetTrackedInstruction(peer_computation);\n-        if (peer_tracked == nullptr) {\n-          continue;\n-        }\n-        TF_RET_CHECK(*tracked == *peer_tracked)\n-            << \"Peer instruction does not match the computation kind\";\n-        TF_RETURN_IF_ERROR(\n-            AddCompanion(tracked->instruction(), peer_tracked->instruction()));\n-        tracked_instructions_comms_[tracked->instruction()].push_back(hlo);\n-      }\n-    } else if (IsCompanionInstruction(hlo)) {\n-      // Add the parents of companion instructions (they must be all of the same\n-      // kind of instructions, opcode wise) as companions.\n-      for (HloInstruction* companion : Companions(hlo)) {\n-        const TrackedInstruction* companion_tracked =\n-            GetTrackedInstruction(companion->parent());\n-        TF_RET_CHECK(companion_tracked != nullptr);\n-        TF_RET_CHECK(*tracked == *companion_tracked);\n-        TF_RETURN_IF_ERROR(AddCompanion(tracked->instruction(),\n-                                        companion_tracked->instruction()));\n-      }\n-    }\n-\n-    return absl::OkStatus();\n-  };\n-\n-  // Visit the computations in postorder so that the companion information grows\n-  // from inner computations to outer ones.\n-  for (HloModule* module : modules_) {\n-    FunctionVisitor function_visitor(visitor);\n-    for (HloComputation* computation : module->MakeComputationPostOrder()) {\n-      TF_RETURN_IF_ERROR(computation->Accept(&function_visitor));\n-    }\n-  }\n-\n-  // While building the companion sets, initial sets may be removed by inserting\n-  // nullptr in companion_sets_. Prune those removed sets to compact.\n-  std::vector<std::unique_ptr<std::vector<HloInstruction*>>> sets;\n-  for (int64_t i = 0; i < companion_sets_.size(); ++i) {\n-    if (companion_sets_[i] == nullptr) {\n-      continue;\n-    }\n-    sets.push_back(std::move(companion_sets_[i]));\n-    for (HloInstruction* hlo : *sets.back()) {\n-      companion_set_index_[hlo] = sets.size() - 1;\n-    }\n-  }\n-  companion_sets_ = std::move(sets);\n-\n-  TF_RETURN_IF_ERROR(VerifyCompanionSets());\n-  if (VLOG_IS_ON(4)) {\n-    DumpCollectedStats();\n-  }\n-  return absl::OkStatus();\n-}\n-\n-absl::Status HloModuleGroupMetadata::VerifyCompanionSets() const {\n-  for (const auto& companions : companion_sets_) {\n-    // A companion set must be composed at most of an instruction per\n-    // device/module.\n-    absl::flat_hash_set<int64_t> devices;\n-    for (HloInstruction* instruction : *companions) {\n-      // Go through all the communicating instructions (send, recv) of the given\n-      // companion, and record their device.\n-      auto it = tracked_instructions_comms_.find(instruction);\n-      if (it == tracked_instructions_comms_.end()) {\n-        // Companions can be added even if they have no communicating\n-        // instructions, if they are parent of companions.\n-        continue;\n-      }\n-      absl::flat_hash_set<int64_t> comm_devices;\n-      for (HloInstruction* comm_instruction : it->second) {\n-        auto device = GetInstructionDevice(*comm_instruction);\n-        TF_RET_CHECK(device) << \"Instruction \" << comm_instruction->ToString()\n-                             << \" does not have a device\";\n-        comm_devices.insert(*device);\n-      }\n-      for (int64_t device : comm_devices) {\n-        if (!devices.insert(device).second) {\n-          std::stringstream ss;\n-          ss << \"Companion set:\" << std::endl;\n-          for (HloInstruction* hlo : *companions) {\n-            ss << \"  \" << hlo->name() << std::endl;\n-          }\n-          ss << \"has multiple instructions on the same device\";\n-          return FailedPrecondition(\"%s\", ss.str());\n-        }\n-      }\n-    }\n-  }\n-  return absl::OkStatus();\n-}\n-\n-bool HloModuleGroupMetadata::IsChannelInstruction(\n-    const HloInstruction* instruction) const {\n-  switch (instruction->opcode()) {\n-    case HloOpcode::kSend:\n-    case HloOpcode::kRecv:\n-    case HloOpcode::kSendDone:\n-    case HloOpcode::kRecvDone: {\n-      const HloSendRecvInstruction* send_recv_instr =\n-          DynCast<HloSendRecvInstruction>(instruction);\n-      CHECK(send_recv_instr != nullptr);\n-      return !send_recv_instr->is_host_transfer();\n-    }\n-    default:\n-      return false;\n-  }\n-}\n-\n-bool HloModuleGroupMetadata::IsCompanionInstruction(HloInstruction* hlo) const {\n-  return companion_set_index_.contains(hlo);\n-}\n-\n-bool HloModuleGroupMetadata::IsNonSpmdCrossModuleAllReduce(\n-    HloInstruction* hlo) const {\n-  return hlo->IsCrossModuleAllReduce() &&\n-         !hlo->GetModule()->config().use_spmd_partitioning();\n-}\n-\n-bool HloModuleGroupMetadata::InstructionCommunicates(\n-    HloInstruction* hlo) const {\n-  return IsChannelInstruction(hlo) || IsCompanionInstruction(hlo) ||\n-         IsNonSpmdCrossModuleAllReduce(hlo);\n-}\n-\n-const HloModuleGroupMetadata::Channel& HloModuleGroupMetadata::GetChannel(\n-    int64_t channel_id) const {\n-  CHECK(channel_id_map_.find(channel_id) != channel_id_map_.end());\n-  return channels_[channel_id_map_.at(channel_id)];\n-}\n-\n-bool HloModuleGroupMetadata::HasChannel(int64_t channel_id) const {\n-  return channel_id_map_.find(channel_id) != channel_id_map_.end();\n-}\n-\n-HloComputation* HloModuleGroupMetadata::PeerComputation(\n-    const HloInstruction* instruction) const {\n-  CHECK(IsChannelInstruction(instruction));\n-  const Channel& channel = GetChannel(*instruction->channel_id());\n-  switch (instruction->opcode()) {\n-    case HloOpcode::kSend:\n-    case HloOpcode::kSendDone:\n-      return channel.recv->parent();\n-    case HloOpcode::kRecv:\n-    case HloOpcode::kRecvDone:\n-      return channel.send->parent();\n-    default:\n-      LOG(FATAL) << \"opcode not supported\";\n-  }\n-}\n-\n-const std::vector<HloInstruction*>& HloModuleGroupMetadata::GetAllReduceGroup(\n-    int64_t channel_id) const {\n-  auto it = all_reduce_map_.find(channel_id);\n-  CHECK(it != all_reduce_map_.end());\n-  return it->second;\n-}\n-\n-std::vector<HloModuleGroupMetadata::TrackedInstruction>\n-HloModuleGroupMetadata::GetCompanionsPath(const HloInstruction* hlo) const {\n-  std::vector<TrackedInstruction> path;\n-  const HloComputation* parent = hlo->parent();\n-  const TrackedInstruction* companion;\n-  while ((companion = GetTrackedInstruction(parent)) != nullptr) {\n-    parent = companion->instruction()->parent();\n-    path.push_back(*companion);\n-  }\n-  return path;\n-}\n-\n-bool HloModuleGroupMetadata::CheckCompanionPathsCompatibility(\n-    const std::vector<TrackedInstruction>& path0,\n-    const std::vector<TrackedInstruction>& path1) const {\n-  if (path0.size() != path1.size()) {\n-    VLOG(5) << \"Companion path size do not match: \" << path0.size()\n-            << \" != \" << path1.size();\n-    return false;\n-  }\n-  for (int64_t i = 0; i < path0.size(); ++i) {\n-    if (path0[i] != path1[i]) {\n-      VLOG(5) << \"Companion instructions at path index \" << i\n-              << \" do not have the same opcode: \" << path0[i].ToString()\n-              << \" vs \" << path1[i].ToString();\n-      return false;\n-    }\n-  }\n-  return true;\n-}\n-\n-int64_t HloModuleGroupMetadata::GetModuleId(const HloModule* module) const {\n-  for (int64_t i = 0; i < modules_.size(); ++i) {\n-    if (modules_[i] == module) {\n-      return i;\n-    }\n-  }\n-  LOG(FATAL) << \"unknown module\";\n-}\n-\n-std::optional<int64_t> HloModuleGroupMetadata::GetInstructionDevice(\n-    const HloInstruction& instruction) const {\n-  // The module group metadata can be created in both \"single module, multiple\n-  // devices\" and \"multiple modules, no explicit devices\" fashions.\n-  // The API returns an optional even though the current implementation always\n-  // returns a device, to account for cases where we cannot guess a device.\n-  // In such cases the VerifyChannelInstructions() will return proper errors.\n-  std::optional<int64_t> device = instruction.sharding_unique_device();\n-  if (!device) {\n-    device = GetModuleId(instruction.GetModule());\n-  }\n-  return device;\n-}\n-\n-int64_t HloModuleGroupMetadata::GetDeviceModulesCount() const {\n-  return modules_.size();\n-}\n-\n-absl::Status HloModuleGroupMetadata::RecordInstructions() {\n-  const auto visitor = [this](HloInstruction* hlo) -> absl::Status {\n-    if (hlo->opcode() == HloOpcode::kWhile) {\n-      tracked_instructions_[hlo->while_condition()] =\n-          TrackedInstruction(hlo, ComputationKind::kWhileCondition);\n-      tracked_instructions_[hlo->while_body()] =\n-          TrackedInstruction(hlo, ComputationKind::kWhileBody);\n-    } else if (hlo->opcode() == HloOpcode::kConditional) {\n-      for (int b = 0; b < hlo->branch_count(); ++b) {\n-        tracked_instructions_[hlo->branch_computation(b)] =\n-            TrackedInstruction(hlo, ComputationKind::kConditionalBranch, b);\n-      }\n-    } else if (hlo->opcode() == HloOpcode::kCall) {\n-      tracked_instructions_[hlo->to_apply()] =\n-          TrackedInstruction(hlo, ComputationKind::kCallFunction);\n-    }\n-\n-    // Group cross module all-reduce instructions by the channel id.\n-    if (IsNonSpmdCrossModuleAllReduce(hlo)) {\n-      TF_RET_CHECK(channel_id_map_.find(*hlo->channel_id()) ==\n-                   channel_id_map_.end())\n-          << \"channel_id \" << *hlo->channel_id()\n-          << \" is already used by a send/recv instruction\";\n-      all_reduce_map_[*hlo->channel_id()].push_back(hlo);\n-      max_channel_id_ = std::max(max_channel_id_, *hlo->channel_id());\n-      return absl::OkStatus();\n-    }\n-\n-    if (!IsChannelInstruction(hlo)) {\n-      return absl::OkStatus();\n-    }\n-\n-    TF_RET_CHECK(all_reduce_map_.find(*hlo->channel_id()) ==\n-                 all_reduce_map_.end())\n-        << \"channel id \" << *hlo->channel_id()\n-        << \" is already used by an all-reduce instruction\";\n-\n-    // Add a new channel if needed.\n-    if (channel_id_map_.find(*hlo->channel_id()) == channel_id_map_.end()) {\n-      channels_.emplace_back();\n-      channels_.back().id = *hlo->channel_id();\n-      channel_id_map_[*hlo->channel_id()] = channels_.size() - 1;\n-      max_channel_id_ = std::max(max_channel_id_, *hlo->channel_id());\n-    }\n-    Channel& channel = channels_[channel_id_map_[*hlo->channel_id()]];\n-\n-    if (hlo->opcode() == HloOpcode::kSend) {\n-      TF_RET_CHECK(channel.send == nullptr)\n-          << \"channel id \" << *hlo->channel_id()\n-          << \" is used by multiple send instructions\";\n-      channel.send = hlo;\n-    }\n-    if (hlo->opcode() == HloOpcode::kRecv) {\n-      TF_RET_CHECK(channel.recv == nullptr)\n-          << \"channel id \" << *hlo->channel_id()\n-          << \" is used by multiple recv instructions\";\n-      channel.recv = hlo;\n-    }\n-    if (hlo->opcode() == HloOpcode::kSendDone) {\n-      TF_RET_CHECK(channel.send_done == nullptr)\n-          << \"channel id \" << *hlo->channel_id()\n-          << \" is used by multiple send-done instructions\";\n-      channel.send_done = hlo;\n-    }\n-    if (hlo->opcode() == HloOpcode::kRecvDone) {\n-      TF_RET_CHECK(channel.recv_done == nullptr)\n-          << \"channel id \" << *hlo->channel_id()\n-          << \" is used by multiple recv-done instructions\";\n-      channel.recv_done = hlo;\n-    }\n-    return absl::OkStatus();\n-  };\n-\n-  for (HloModule* module : modules_) {\n-    FunctionVisitor function_visitor(visitor);\n-    for (auto* computation : module->computations()) {\n-      TF_RETURN_IF_ERROR(computation->Accept(&function_visitor));\n-    }\n-  }\n-  VLOG(2) << \"Created \" << channels_.size() << \" channels\";\n-  VLOG(2) << \"Created \" << all_reduce_map_.size() << \" all-reduce groups\";\n-  return absl::OkStatus();\n-}\n-\n-absl::Status HloModuleGroupMetadata::AddCompanion(\n-    HloInstruction* instruction1, HloInstruction* instruction2) {\n-  TF_RET_CHECK(instruction1->opcode() == HloOpcode::kWhile ||\n-               instruction1->opcode() == HloOpcode::kConditional ||\n-               instruction1->opcode() == HloOpcode::kCall);\n-  VLOG(2) << \"adding as companions:\" << instruction1->ToString() << \" and \"\n-          << instruction2->ToString();\n-  if (instruction1 == instruction2) {\n-    return absl::OkStatus();\n-  } else if (!ContainsKey(companion_set_index_, instruction1) &&\n-             !ContainsKey(companion_set_index_, instruction2)) {\n-    companion_sets_.push_back(std::make_unique<std::vector<HloInstruction*>>());\n-    auto companion_set = companion_sets_.back().get();\n-    companion_set->push_back(instruction1);\n-    companion_set->push_back(instruction2);\n-    companion_set_index_[instruction1] = companion_sets_.size() - 1;\n-    companion_set_index_[instruction2] = companion_sets_.size() - 1;\n-  } else if (!ContainsKey(companion_set_index_, instruction1)) {\n-    companion_sets_[companion_set_index_[instruction2]]->push_back(\n-        instruction1);\n-    companion_set_index_[instruction1] = companion_set_index_[instruction2];\n-  } else if (!ContainsKey(companion_set_index_, instruction2)) {\n-    companion_sets_[companion_set_index_[instruction1]]->push_back(\n-        instruction2);\n-    companion_set_index_[instruction2] = companion_set_index_[instruction1];\n-  } else if (companion_set_index_[instruction1] !=\n-             companion_set_index_[instruction2]) {\n-    // At any point while building the companion sets, each instruction belongs\n-    // to at most 1 companion set, so the union of two companion sets is\n-    // concatenating two disjoint sets.\n-    absl::c_copy(Companions(instruction2),\n-                 std::back_inserter(\n-                     *companion_sets_[companion_set_index_[instruction1]]));\n-    int64_t index_to_remove = companion_set_index_[instruction2];\n-    for (HloInstruction* hlo : Companions(instruction2)) {\n-      companion_set_index_[hlo] = companion_set_index_[instruction1];\n-    }\n-    // We can't remove the set from the vector because companion_set_index_\n-    // references sets by their index in this vector, so we reset to nullptr\n-    // instead.\n-    companion_sets_[index_to_remove].reset(nullptr);\n-  }\n-  return absl::OkStatus();\n-}\n-\n-absl::Status HloModuleGroupMetadata::VerifyChannelInstructions() {\n-  for (const Channel& channel : channels_) {\n-    if (channel.send == nullptr) {\n-      return FailedPrecondition(\"missing send for id : %d\", channel.id);\n-    }\n-    if (channel.recv == nullptr) {\n-      return FailedPrecondition(\"missing recv for id : %d\", channel.id);\n-    }\n-    if (channel.send_done == nullptr) {\n-      return FailedPrecondition(\"missing send-done for id : %d\", channel.id);\n-    }\n-    if (channel.recv_done == nullptr) {\n-      return FailedPrecondition(\"missing recv-done for id : %d\", channel.id);\n-    }\n-  }\n-\n-  // Check if the shapes match for each channel.\n-  for (const Channel& channel : channels_) {\n-    const Shape& send_shape = channel.send->operand(0)->shape();\n-    const Shape& recv_shape =\n-        ShapeUtil::GetTupleElementShape(channel.recv_done->shape(), 0);\n-    if (!ShapeUtil::Compatible(send_shape, recv_shape)) {\n-      return FailedPrecondition(\"send/recv shapes do not match\");\n-    }\n-    auto send_device = GetInstructionDevice(*channel.send);\n-    auto send_done_device = GetInstructionDevice(*channel.send_done);\n-    if (!send_device) {\n-      return FailedPrecondition(\"send instruction must have a device: %s\",\n-                                channel.send->ToString());\n-    }\n-    if (!send_done_device) {\n-      return FailedPrecondition(\"send_done instruction must have a device: %s\",\n-                                channel.send_done->ToString());\n-    }\n-    if (*send_device != *send_done_device) {\n-      return FailedPrecondition(\n-          \"send and send-done (channel=%d) must be on the same device: %d \"\n-          \"vs. %d\",\n-          channel.id, *send_device, *send_done_device);\n-    }\n-    auto recv_device = GetInstructionDevice(*channel.recv);\n-    auto recv_done_device = GetInstructionDevice(*channel.recv_done);\n-    if (!recv_done_device) {\n-      return FailedPrecondition(\"recv_done instruction must have a device: %s\",\n-                                channel.recv_done->ToString());\n-    }\n-    if (*recv_device != *recv_done_device) {\n-      return FailedPrecondition(\n-          \"recv and recv-done (channel=%d) must be on the same device: %d \"\n-          \"vs. %d\",\n-          channel.id, *recv_device, *recv_done_device);\n-    }\n-    if (*send_device == *recv_device) {\n-      return FailedPrecondition(\n-          \"send and recv (channel=%d) must be on different devices: %d\",\n-          channel.id, *send_device);\n-    }\n-  }\n-\n-  for (const Channel& channel : channels_) {\n-    TF_RETURN_IF_ERROR(CheckCommunicatingInstruction(channel.send));\n-    TF_RETURN_IF_ERROR(CheckCommunicatingInstruction(channel.send_done));\n-    TF_RETURN_IF_ERROR(CheckCommunicatingInstruction(channel.recv));\n-    TF_RETURN_IF_ERROR(CheckCommunicatingInstruction(channel.recv_done));\n-  }\n-  // Check if the nest levels match for each channel.\n-  for (const Channel& channel : channels_) {\n-    std::vector<TrackedInstruction> path = GetCompanionsPath(channel.send);\n-    if (!CheckCompanionPathsCompatibility(\n-            path, GetCompanionsPath(channel.send_done)) ||\n-        !CheckCompanionPathsCompatibility(path,\n-                                          GetCompanionsPath(channel.recv)) ||\n-        !CheckCompanionPathsCompatibility(\n-            path, GetCompanionsPath(channel.recv_done))) {\n-      return FailedPrecondition(\n-          \"Nest companion paths do not match for channel %d\", channel.id);\n-    }\n-  }\n-  return absl::OkStatus();\n-}\n-\n-absl::Status HloModuleGroupMetadata::CheckCommunicatingInstruction(\n-    HloInstruction* instruction) const {\n-  HloComputation* computation = instruction->parent();\n-  const HloModule* module = computation->parent();\n-  if (module->entry_computation() == computation ||\n-      tracked_instructions_.contains(computation)) {\n-    return absl::OkStatus();\n-  }\n-  return FailedPrecondition(\"channel is used in disallowed computation\");\n-}\n-\n-void HloModuleGroupMetadata::DumpCollectedStats() const {\n-  std::map<std::pair<int64_t, int64_t>, int64_t> communication_histogram;\n-  for (auto& channel : channels_) {\n-    auto from_device = GetInstructionDevice(*channel.send);\n-    auto to_device = GetInstructionDevice(*channel.recv);\n-    LOG(INFO) << \"Channel \" << channel.id << \": from_device=\" << *from_device\n-              << \" to_device=\" << *to_device << \" send=\" << channel.send->name()\n-              << \" send_done=\" << channel.send_done->name()\n-              << \" recv=\" << channel.recv->name()\n-              << \" recv_done=\" << channel.recv_done->name();\n-    communication_histogram[std::pair<int64_t, int64_t>(*from_device,\n-                                                        *to_device)] += 1;\n-  }\n-  for (auto& fromto_count : communication_histogram) {\n-    LOG(INFO) << \"From \" << fromto_count.first.first << \" to \"\n-              << fromto_count.first.second << \": \" << fromto_count.second;\n-  }\n-  for (auto& companion_set : companion_sets_) {\n-    LOG(INFO) << \"Companion set:\";\n-    for (HloInstruction* instruction : *companion_set) {\n-      LOG(INFO) << \"  \" << instruction->name();\n-    }\n-  }\n-  for (auto& instruction_comm : tracked_instructions_comms_) {\n-    LOG(INFO) << \"Communicating instruction \" << instruction_comm.first->name();\n-    for (HloInstruction* instruction : instruction_comm.second) {\n-      auto device = GetInstructionDevice(*instruction);\n-      LOG(INFO) << \"  \" << instruction->name() << \" on device \" << *device;\n-    }\n-  }\n-}\n-\n-}  // namespace xla"
        },
        {
            "sha": "b60dec69f3e71464ebd05261a494fcb91353e6c3",
            "filename": "third_party/xla/xla/service/hlo_module_group_metadata.h",
            "status": "removed",
            "additions": 0,
            "deletions": 286,
            "changes": 286,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/77fd9546fd5f278d86c11ab367a28b96913a661c/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_group_metadata.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/77fd9546fd5f278d86c11ab367a28b96913a661c/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_group_metadata.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_group_metadata.h?ref=77fd9546fd5f278d86c11ab367a28b96913a661c",
            "patch": "@@ -1,286 +0,0 @@\n-/* Copyright 2018 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_SERVICE_HLO_MODULE_GROUP_METADATA_H_\n-#define XLA_SERVICE_HLO_MODULE_GROUP_METADATA_H_\n-\n-#include <memory>\n-#include <optional>\n-#include <set>\n-#include <string>\n-#include <vector>\n-\n-#include \"absl/container/flat_hash_map.h\"\n-#include \"absl/status/status.h\"\n-#include \"absl/status/statusor.h\"\n-#include \"xla/hlo/ir/hlo_computation.h\"\n-#include \"xla/hlo/ir/hlo_instruction.h\"\n-#include \"xla/hlo/ir/hlo_module.h\"\n-#include \"tsl/platform/status.h\"\n-\n-namespace xla {\n-\n-// Class for bookkeeping the information on the given modules, in particular on\n-// the interaction between computations.\n-//\n-// Companion instructions are one piece of information collected as we build the\n-// metadata. For example, for each While instruction, companion instructions\n-// refer to a set of While instructions in other computations that communicate\n-// with each other.\n-// In the example below with 3 modules, {While_0, While_2, While_5}, {While_1,\n-// While_4}, {While_3, While_6} are companion sets.\n-//\n-// <Module 0>               <Module 1>                 <Module 2>\n-// While_0() {              While_2() {                While_5() {\n-//   While_1() { Send(0) }    While_3() { Send(1) }      While_6() { Recv(1) }\n-// }                          While_4() { Recv(0) }\n-//                          }\n-//\n-// Each instruction can belong to at most one companion set: While_0 and While_5\n-// are in the same set even though they don't communicate with each other,\n-// because they both communicate with While_2.\n-//\n-// A send and the matching recv must both have the same level of nesting of\n-// companion instructions.\n-//\n-// Companion instructions are used to detect cycles in the graph and also for\n-// global scheduling.\n-class HloModuleGroupMetadata {\n- public:\n-  // The kind of companion computation a given instruction can be within.\n-  enum class ComputationKind {\n-    kInvalid,\n-    kWhileCondition,\n-    kWhileBody,\n-    kConditionalBranch,\n-    kCallFunction,\n-  };\n-\n-  // Tracks the instruction mapped to a given computation, and the computation\n-  // kind.\n-  // For example, a body computation of a while instruction, will generate a\n-  // TrackedInstruction with instruction being the while instruction, and\n-  // kind being ComputationKind::kWhileBody.\n-  class TrackedInstruction {\n-   public:\n-    TrackedInstruction() = default;\n-    TrackedInstruction(HloInstruction* instruction, ComputationKind kind,\n-                       int index = -1)\n-        : instruction_(instruction), kind_(kind), index_(index) {}\n-\n-    bool operator==(const TrackedInstruction& rhs) const {\n-      return instruction_->opcode() == rhs.instruction_->opcode() &&\n-             kind_ == rhs.kind_ && index_ == rhs.index_;\n-    }\n-    bool operator!=(const TrackedInstruction& rhs) const {\n-      return !operator==(rhs);\n-    }\n-\n-    HloInstruction* instruction() const { return instruction_; }\n-\n-    std::string ToString() const;\n-\n-   private:\n-    HloInstruction* instruction_ = nullptr;\n-    ComputationKind kind_ = ComputationKind::kInvalid;\n-    int index_ = -1;\n-  };\n-\n-  // Represents a channel and the instructions that form the channel.\n-  struct Channel {\n-    int64_t id = -1;\n-    HloInstruction* send = nullptr;\n-    HloInstruction* recv = nullptr;\n-    HloInstruction* send_done = nullptr;\n-    HloInstruction* recv_done = nullptr;\n-  };\n-\n-  explicit HloModuleGroupMetadata(absl::Span<HloModule* const> modules)\n-      : modules_(modules.begin(), modules.end()) {}\n-\n-  ~HloModuleGroupMetadata() = default;\n-\n-  // Build and return the metadata for the given modules.\n-  static absl::StatusOr<std::unique_ptr<HloModuleGroupMetadata>> Build(\n-      absl::Span<HloModule* const> modules);\n-\n-  // Returns true if the instruction is one of the 4 channel instructions (Send,\n-  // Recv, SendDone, RecvDone).\n-  bool IsChannelInstruction(const HloInstruction* instruction) const;\n-\n-  // Returns true if the instruction is a companion instruction. See the class\n-  // comment above on companion instructions.\n-  bool IsCompanionInstruction(HloInstruction* hlo) const;\n-\n-  // Returns true if the instruction is either a cross-module all-reduce\n-  // instruction in a non-spmd module.\n-  bool IsNonSpmdCrossModuleAllReduce(HloInstruction* hlo) const;\n-\n-  // Returns true if the instruction is either a channel instruction, a\n-  // cross-module non-spmd all-reduce instruction, or a companion instruction.\n-  bool InstructionCommunicates(HloInstruction* hlo) const;\n-\n-  // Returns the Channel instance for the given channel id.\n-  const Channel& GetChannel(int64_t channel_id) const;\n-\n-  // Returns if the given channel id exists in metadata.\n-  bool HasChannel(int64_t channel_id) const;\n-\n-  // Returns the all-reduce instructions with the same channel_id.\n-  const std::vector<HloInstruction*>& GetAllReduceGroup(\n-      int64_t channel_id) const;\n-\n-  // Returns the computation that contains the peer channel instructions for\n-  // the given instruction.\n-  //\n-  // Precondition: IsChannelInstruction(instruction) is true.\n-  HloComputation* PeerComputation(const HloInstruction* instruction) const;\n-\n-  // Returns the path of the nested companion instructions, in terms of HLO\n-  // instructions. The path goes from inner to outer companions.\n-  // The returned path does not include the input hlo instruction, in case it\n-  // is a companion instruction.\n-  std::vector<TrackedInstruction> GetCompanionsPath(\n-      const HloInstruction* hlo) const;\n-\n-  // Checks whether two companion paths (as returned by the GetCompanionsPath()\n-  // API) are compatible. The two paths are compatible if the sequence of\n-  // opcodes, and the companion kinds, of the two paths matches.\n-  bool CheckCompanionPathsCompatibility(\n-      const std::vector<TrackedInstruction>& path0,\n-      const std::vector<TrackedInstruction>& path1) const;\n-\n-  // Returns the unique integer for each module. The returned id is the index of\n-  // the module in the module vector.\n-  int64_t GetModuleId(const HloModule* module) const;\n-\n-  // Retrieves the device an instruction is assigned to. Either from the\n-  // sharding information, or from the ordinal of the module the instruction\n-  // is in.\n-  std::optional<int64_t> GetInstructionDevice(\n-      const HloInstruction& instruction) const;\n-\n-  // Returns the number of modules for devices (excluding the host module).\n-  int64_t GetDeviceModulesCount() const;\n-\n-  // Returns the companion set for the given instruction, including the\n-  // instruction itself.\n-  //\n-  // Precondition: IsCompanionWhile(instruction) is true.\n-  const std::vector<HloInstruction*>& Companions(\n-      const HloInstruction* instruction) const {\n-    CHECK(companion_set_index_.contains(instruction));\n-    return companion_set(companion_set_index_.at(instruction));\n-  }\n-\n-  // Returns the companion set at the given index.\n-  const std::vector<HloInstruction*>& companion_set(int64_t index) const {\n-    CHECK_LT(index, companion_sets_.size());\n-    return *companion_sets_[index];\n-  }\n-\n-  // Returns the companion set index of the given instruction.\n-  int64_t companion_set_index(HloInstruction* instruction) const {\n-    return companion_set_index_.at(instruction);\n-  }\n-\n-  // Returns the list of all companion sets in the HLO module group. Each\n-  // returned set contains at least one HloInstruction.\n-  const std::vector<std::unique_ptr<std::vector<HloInstruction*>>>&\n-  companion_sets() const {\n-    return companion_sets_;\n-  }\n-\n-  // Returns all channels in the module group.\n-  const std::vector<Channel>& channels() const { return channels_; }\n-\n-  // Returns the maximum channel id used in the module group.\n-  int64_t max_channel_id() const { return max_channel_id_; }\n-\n- private:\n-  absl::Status Build();\n-\n-  // Record all channel instructions, cross-module AllReduce instructions, and\n-  // While/Conditional/Call instructions.\n-  absl::Status RecordInstructions();\n-\n-  // Verifies the given HloModules are well-formed and follow the specification,\n-  // in particular with respect to using channel instructions.\n-  //\n-  // * Each channel has all 4 instructions (Send, Recv, SendDone, RecvDone).\n-  // * The shape of channel instructions match.\n-  // * The nest level of channel instructions match.\n-  // * Channel instructions are used in allowed computations, i.e., in the\n-  //   entry computation of the module or condition/body of While computations.\n-  absl::Status VerifyChannelInstructions();\n-\n-  // Adds metadata that the given two instructions are companions.\n-  absl::Status AddCompanion(HloInstruction* instruction1,\n-                            HloInstruction* instruction2);\n-\n-  // Checks whether a communicating instruction is placed in a valid position\n-  // within the graph.\n-  absl::Status CheckCommunicatingInstruction(HloInstruction* instruction) const;\n-\n-  // Performs a consistency check on the companion sets built for the input\n-  // modules. Checks that each instruction in a companion set is in a different\n-  // module/device.\n-  absl::Status VerifyCompanionSets() const;\n-\n-  // Retrieves a pointer to the stored TrackedInstruction associated with a\n-  // tracked computation, or nullptr in case such computation is not tracked.\n-  const TrackedInstruction* GetTrackedInstruction(\n-      const HloComputation* computation) const {\n-    auto it = tracked_instructions_.find(computation);\n-    return it != tracked_instructions_.end() ? &it->second : nullptr;\n-  }\n-\n-  // Dump all the collected module group statistics to the logs.\n-  void DumpCollectedStats() const;\n-\n-  // List of all companion instructions sets in the module.\n-  std::vector<std::unique_ptr<std::vector<HloInstruction*>>> companion_sets_;\n-\n-  // Map from each companion while instruction to the index into companion_set_.\n-  absl::flat_hash_map<const HloInstruction*, int64_t> companion_set_index_;\n-\n-  // Map from computation to the instruction using it (a kWhile, kConditional).\n-  absl::flat_hash_map<const HloComputation*, TrackedInstruction>\n-      tracked_instructions_;\n-\n-  // Maps tracked instructions (kWhile, kConditional, kCall, ...) to the set of\n-  // communicating instructions within the proper called computation(s).\n-  absl::flat_hash_map<HloInstruction*, std::vector<HloInstruction*>>\n-      tracked_instructions_comms_;\n-\n-  // All channels in the module.\n-  std::vector<Channel> channels_;\n-\n-  // Map from channel ids to the index in channels_.\n-  absl::flat_hash_map<int64_t, int64_t> channel_id_map_;\n-\n-  // Map from all-reduce ids to the all reduce instructions.\n-  absl::flat_hash_map<int64_t, std::vector<HloInstruction*>> all_reduce_map_;\n-\n-  // The maximum channel id used in the module group.\n-  int64_t max_channel_id_ = -1;\n-\n-  // The modules that this metadata was built from.\n-  const std::vector<HloModule*> modules_;\n-};\n-\n-}  // namespace xla\n-\n-#endif  // XLA_SERVICE_HLO_MODULE_GROUP_METADATA_H_"
        }
    ],
    "stats": {
        "total": 872,
        "additions": 0,
        "deletions": 872
    }
}