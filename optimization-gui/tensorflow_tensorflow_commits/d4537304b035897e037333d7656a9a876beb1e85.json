{
    "author": "krishnaharidasan",
    "message": "Upstream ExecutableSerialization test to IFRT\n\nPiperOrigin-RevId: 805123718",
    "sha": "d4537304b035897e037333d7656a9a876beb1e85",
    "files": [
        {
            "sha": "5f46e1d6c5672731507f091a592a9103fd0e8ec5",
            "filename": "third_party/xla/xla/python/pjrt_ifrt/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d4537304b035897e037333d7656a9a876beb1e85/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d4537304b035897e037333d7656a9a876beb1e85/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2FBUILD?ref=d4537304b035897e037333d7656a9a876beb1e85",
            "patch": "@@ -145,6 +145,8 @@ cc_library(\n     testonly = True,\n     srcs = [\"xla_executable_impl_test_lib.cc\"],\n     deps = [\n+        \":executable_metadata_proto_cc\",\n+        \":pjrt_layout\",\n         \":xla_ifrt\",\n         \"//xla/client:executable_build_options\",\n         \"//xla/pjrt:mlir_to_hlo\",\n@@ -154,17 +156,18 @@ cc_library(\n         \"//xla/python/ifrt:user_context\",\n         \"//xla/python/ifrt/hlo:hlo_program\",\n         \"//xla/tsl/lib/core:status_test_util\",\n-        \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n         \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//mlir:IR\",\n+        \"@local_tsl//tsl/platform:protobuf\",\n     ],\n     alwayslink = True,\n )"
        },
        {
            "sha": "aa858484ac35e3308c7a96fe28a5fc10fd91814a",
            "filename": "third_party/xla/xla/python/pjrt_ifrt/pjrt_executable_impl_test_cpu.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d4537304b035897e037333d7656a9a876beb1e85/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_executable_impl_test_cpu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d4537304b035897e037333d7656a9a876beb1e85/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_executable_impl_test_cpu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fpjrt_executable_impl_test_cpu.cc?ref=d4537304b035897e037333d7656a9a876beb1e85",
            "patch": "@@ -18,9 +18,9 @@ limitations under the License.\n #include \"xla/python/ifrt/test_util.h\"\n \n int main(int argc, char** argv) {\n-  // PjRtCpuExecutable::IsDeleted() always returns false.\n+  // This implementation does not export executables in the standard format yet.\n   static constexpr absl::string_view kFilter =\n-      \"-LoadedExecutableImplTest.IsDeleted\";\n+      \"-ExecutableTest.ExecutableSerialization\";\n   xla::ifrt::test_util::SetTestFilterIfNotUserSpecified(kFilter);\n \n   testing::InitGoogleTest(&argc, argv);"
        },
        {
            "sha": "e4d2435cdc3162eeb6842c47a60703e811cdba58",
            "filename": "third_party/xla/xla/python/pjrt_ifrt/xla_executable_impl_test_lib.cc",
            "status": "modified",
            "additions": 285,
            "deletions": 1,
            "changes": 286,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d4537304b035897e037333d7656a9a876beb1e85/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fxla_executable_impl_test_lib.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d4537304b035897e037333d7656a9a876beb1e85/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fxla_executable_impl_test_lib.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fxla_executable_impl_test_lib.cc?ref=d4537304b035897e037333d7656a9a876beb1e85",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/container/flat_hash_set.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/status_matchers.h\"\n@@ -42,17 +43,20 @@ limitations under the License.\n #include \"xla/python/ifrt/executable.h\"\n #include \"xla/python/ifrt/future.h\"\n #include \"xla/python/ifrt/hlo/hlo_program.h\"\n+#include \"xla/python/ifrt/layout.h\"\n #include \"xla/python/ifrt/memory.h\"\n #include \"xla/python/ifrt/shape.h\"\n #include \"xla/python/ifrt/sharding.h\"\n #include \"xla/python/ifrt/test_util.h\"\n #include \"xla/python/ifrt/user_context.h\"\n+#include \"xla/python/pjrt_ifrt/executable_metadata.pb.h\"\n+#include \"xla/python/pjrt_ifrt/pjrt_layout.h\"\n #include \"xla/python/pjrt_ifrt/xla_compiler.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n-#include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n #include \"xla/tsl/util/proto/proto_matchers.h\"\n+#include \"tsl/platform/protobuf.h\"\n \n namespace xla {\n namespace ifrt {\n@@ -82,6 +86,24 @@ static const char* const module_add_one =\n   }\n })\";\n \n+static const char* const module_add_sub = R\"(\n+module @add_sub attributes {\n+  mhlo.num_replicas = 1 : i32,\n+  mhlo.num_partitions = 2 : i32\n+} {\n+  func.func @main(\n+    %arg0: tensor<2x3xi32> {mhlo.sharding = \"{devices=[2,1]<=[2]}\"},\n+    %arg1: tensor<2x3xi32> {mhlo.sharding = \"{replicated}\"}\n+  ) -> (\n+    tensor<2x3xi32> {mhlo.sharding = \"{replicated}\"},\n+    tensor<2x3xi32> {mhlo.sharding = \"{devices=[2,1]<=[2]}\"}\n+  ) {\n+    %0 = stablehlo.add %arg0, %arg1 : tensor<2x3xi32>\n+    %1 = stablehlo.subtract %arg0, %arg1 : tensor<2x3xi32>\n+    return %0, %1 : tensor<2x3xi32>, tensor<2x3xi32>\n+  }\n+})\";\n+\n // Compiles an MLIR module on specified devices. If devices is empty, compiles\n // it as a portable executable.\n // If `serialize` is true, serializes the compiled executable, deserializes it,\n@@ -581,6 +603,268 @@ INSTANTIATE_TEST_SUITE_P(\n       return std::string(info.param ? \"SerializeAndLoad\" : \"DirectLoad\");\n     });\n \n+TEST(ExecutableTest, ExecutableSerialization) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto client, xla::ifrt::test_util::GetClient());\n+  xla::ifrt::Compiler* compiler = client->GetDefaultCompiler();\n+\n+  std::vector<xla::ifrt::Device*> devices = {\n+      client->addressable_devices().at(0), client->addressable_devices().at(1)};\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto loaded_executable,\n+      CompileOnDevices(client.get(), compiler, module_add_sub, devices,\n+                       /*replicated=*/false, /*serialize=*/false));\n+\n+  auto serialized_executable = loaded_executable->Serialize();\n+  if (absl::IsUnimplemented(serialized_executable.status())) {\n+    GTEST_SKIP() << \"Serialization is not supported on this platform.\";\n+  }\n+  TF_ASSERT_OK(serialized_executable);\n+\n+  xla::ifrt::SerializedXlaExecutableMetadata metadata;\n+  tsl::protobuf::io::ArrayInputStream input_stream(\n+      serialized_executable->data(), serialized_executable->size());\n+  ASSERT_TRUE(google::protobuf::util::ParseDelimitedFromZeroCopyStream(\n+      &metadata, &input_stream, nullptr));\n+\n+  // TODO(b/409317760): Compare version number to the runtime version number\n+  // when version query API is available.\n+  EXPECT_EQ(metadata.ifrt_version_number(), 0);\n+  EXPECT_FALSE(metadata.runtime_abi_version().empty());\n+\n+  EXPECT_NE(metadata.platform_id(), 0);\n+  EXPECT_EQ(metadata.computation_name(), \"add_sub\");\n+\n+  int kNumOutputs = 2;\n+  TF_ASSERT_OK_AND_ASSIGN(auto output_memory_kinds,\n+                          loaded_executable->GetOutputMemoryKinds());\n+  ASSERT_EQ(output_memory_kinds.size(), 1);\n+  ASSERT_EQ(output_memory_kinds.at(0).size(), kNumOutputs);\n+  ASSERT_EQ(metadata.output_specs_size(), kNumOutputs);\n+\n+  auto output_shardings = loaded_executable->GetOutputShardings();\n+  ASSERT_TRUE(output_shardings.has_value());\n+  ASSERT_EQ(output_shardings->size(), kNumOutputs);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto output_layouts,\n+                          loaded_executable->GetOutputLayouts());\n+  ASSERT_EQ(output_layouts.size(), kNumOutputs);\n+\n+  for (int i = 0; i < kNumOutputs; ++i) {\n+    EXPECT_EQ(metadata.output_specs(i).memory_kind(),\n+              output_memory_kinds.at(0).at(i));\n+    EXPECT_EQ(static_cast<int32_t>(metadata.output_specs(i).dtype().kind()),\n+              static_cast<int32_t>(xla::ifrt::DType::kS32));\n+    EXPECT_THAT(metadata.output_specs(i).op_sharding(),\n+                tsl::proto_testing::EqualsProto(output_shardings->at(i)));\n+\n+    // Verify that layout field behavior: if layout field is present,\n+    // it should match the expected layout. Otherwise it represents a default\n+    // layout.\n+    if (metadata.output_specs(i).has_layout()) {\n+      TF_ASSERT_OK_AND_ASSIGN(\n+          xla::ifrt::CustomLayoutRef output_layout,\n+          xla::ifrt::PjRtLayout::FromProto(metadata.output_specs(i).layout()));\n+      TF_ASSERT_OK_AND_ASSIGN(\n+          xla::ifrt::DType dtype,\n+          xla::ifrt::DType::FromProto(metadata.output_specs(i).dtype()));\n+      TF_ASSERT_OK_AND_ASSIGN(\n+          xla::ifrt::Shape ifrt_shard_shape,\n+          xla::ifrt::Shape::FromProto(metadata.output_specs(i).shard_shape()));\n+      TF_ASSERT_OK_AND_ASSIGN(\n+          auto pjrt_layout,\n+          xla::ifrt::ToPjRtLayout(dtype, ifrt_shard_shape, output_layout));\n+      EXPECT_EQ(pjrt_layout->ToString(), output_layouts[i]->ToString());\n+    }\n+  }\n+\n+  int kNumParameters = 2;\n+  auto parameter_shardings = loaded_executable->GetParameterShardings();\n+  ASSERT_TRUE(parameter_shardings.has_value());\n+  ASSERT_EQ(parameter_shardings->size(), kNumParameters);\n+  ASSERT_EQ(metadata.parameter_specs_size(), kNumParameters);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto parameter_layouts,\n+                          loaded_executable->GetParameterLayouts());\n+  ASSERT_EQ(parameter_layouts.size(), kNumParameters);\n+  ASSERT_EQ(metadata.parameter_specs_size(), kNumParameters);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto donated_input_indices,\n+                          loaded_executable->GetDonatableInputIndices());\n+  absl::flat_hash_set<int> donated_input_indices_set(\n+      donated_input_indices.begin(), donated_input_indices.end());\n+\n+  // Dummy shard shape and dtype for parameter layouts conversion.\n+  xla::ifrt::DType dummy_dtype(xla::ifrt::DType::kInvalid);\n+  xla::ifrt::Shape dummy_shape = xla::ifrt::Shape({});\n+  for (int i = 0; i < kNumParameters; ++i) {\n+    EXPECT_THAT(metadata.parameter_specs(i).op_sharding(),\n+                tsl::proto_testing::EqualsProto(parameter_shardings->at(i)));\n+    // Verify that layout field behavior: if layout field is present,\n+    // it should match the expected layout. Otherwise it represents a default\n+    // layout.\n+    if (metadata.parameter_specs(i).has_layout()) {\n+      TF_ASSERT_OK_AND_ASSIGN(xla::ifrt::CustomLayoutRef parameter_layout,\n+                              xla::ifrt::PjRtLayout::FromProto(\n+                                  metadata.parameter_specs(i).layout()));\n+      TF_ASSERT_OK_AND_ASSIGN(\n+          auto pjrt_layout,\n+          xla::ifrt::ToPjRtLayout(dummy_dtype, dummy_shape, parameter_layout));\n+      EXPECT_EQ(pjrt_layout->ToString(), parameter_layouts[i]->ToString());\n+    }\n+\n+    // Verify donated_input field\n+    bool expected_donated = donated_input_indices_set.contains(i);\n+    EXPECT_EQ(metadata.parameter_specs(i).donated_input(), expected_donated);\n+  }\n+\n+  absl::string_view serialized_pjrt_executable = *serialized_executable;\n+  serialized_pjrt_executable.remove_prefix(input_stream.ByteCount());\n+\n+  ASSERT_FALSE(serialized_pjrt_executable.empty());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(xla::ifrt::DeviceListRef device_list,\n+                          client->MakeDeviceList(devices));\n+  auto options = std::make_unique<xla::ifrt::XlaDeserializeExecutableOptions>();\n+  options->devices = device_list;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto deserialized_executable,\n+      client->GetDefaultCompiler()->DeserializeLoadedExecutable(\n+          *serialized_executable, std::move(options)));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto loaded_output_layouts,\n+                          loaded_executable->GetOutputLayouts());\n+  TF_ASSERT_OK_AND_ASSIGN(auto deserialized_output_layouts,\n+                          deserialized_executable->GetOutputLayouts());\n+  ASSERT_EQ(loaded_output_layouts.size(), deserialized_output_layouts.size());\n+  for (int i = 0; i < loaded_output_layouts.size(); ++i) {\n+    EXPECT_EQ(loaded_output_layouts[i]->ToString(),\n+              deserialized_output_layouts[i]->ToString());\n+  }\n+\n+  auto loaded_output_shardings = loaded_executable->GetOutputShardings();\n+  auto deserialized_output_shardings =\n+      deserialized_executable->GetOutputShardings();\n+  ASSERT_TRUE(loaded_output_shardings.has_value());\n+  ASSERT_TRUE(deserialized_output_shardings.has_value());\n+  ASSERT_EQ(loaded_output_shardings->size(),\n+            deserialized_output_shardings->size());\n+  for (int i = 0; i < loaded_output_shardings->size(); ++i) {\n+    EXPECT_THAT(\n+        (*loaded_output_shardings)[i],\n+        tsl::proto_testing::EqualsProto((*deserialized_output_shardings)[i]));\n+  }\n+\n+  auto loaded_parameter_shardings = loaded_executable->GetParameterShardings();\n+  auto deserialized_parameter_shardings =\n+      deserialized_executable->GetParameterShardings();\n+  ASSERT_TRUE(loaded_parameter_shardings.has_value());\n+  ASSERT_TRUE(deserialized_parameter_shardings.has_value());\n+  ASSERT_EQ(loaded_parameter_shardings->size(),\n+            deserialized_parameter_shardings->size());\n+  for (int i = 0; i < loaded_parameter_shardings->size(); ++i) {\n+    EXPECT_THAT((*loaded_parameter_shardings)[i],\n+                tsl::proto_testing::EqualsProto(\n+                    (*deserialized_parameter_shardings)[i]));\n+  }\n+  EXPECT_EQ(deserialized_executable->name(), \"add_sub\");\n+\n+  // Execute the deserialized executable.\n+  xla::ifrt::DType dtype(xla::ifrt::DType::kS32);\n+  xla::ifrt::Shape shard_shape({1, 3});\n+  xla::ifrt::Shape shape({2, 3});\n+  std::vector<int32_t> data(6);\n+  std::iota(data.begin(), data.end(), 0);\n+  std::vector<xla::ifrt::ArrayRef> input_arrays;\n+\n+  // Input 1 : [0, 1, 2, 3, 4, 5] sharded on device 0 and 1.\n+  xla::ifrt::ShardingRef shard_sharding0 =\n+      xla::ifrt::SingleDeviceSharding::Create(\n+          client->addressable_devices().at(0), xla::ifrt::MemoryKind());\n+  xla::ifrt::ShardingRef shard_sharding1 =\n+      xla::ifrt::SingleDeviceSharding::Create(\n+          client->addressable_devices().at(1), xla::ifrt::MemoryKind());\n+  xla::ifrt::ShardingRef input1_sharding =\n+      xla::ifrt::ConcreteEvenSharding::Create(\n+          device_list, xla::ifrt::MemoryKind(), shape, shard_shape,\n+          /*is_fully_replicated=*/false);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto array_shard0,\n+      client->MakeArrayFromHostBuffer(\n+          data.data(), dtype, shard_shape,\n+          /*byte_strides=*/std::nullopt, shard_sharding0,\n+          xla::ifrt::Client::HostBufferSemantics::kImmutableOnlyDuringCall,\n+          /*on_done_with_host_buffer=*/{}));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto array_shard1,\n+      client->MakeArrayFromHostBuffer(\n+          data.data() + 3, dtype, shard_shape,\n+          /*byte_strides=*/std::nullopt, shard_sharding1,\n+          xla::ifrt::Client::HostBufferSemantics::kImmutableOnlyDuringCall,\n+          /*on_done_with_host_buffer=*/{}));\n+  std::vector<xla::ifrt::ArrayRef> shards = {array_shard0, array_shard1};\n+  TF_ASSERT_OK_AND_ASSIGN(input_arrays.emplace_back(),\n+                          client->AssembleArrayFromSingleDeviceArrays(\n+                              shape, input1_sharding, absl::MakeSpan(shards),\n+                              xla::ifrt::ArrayCopySemantics::kDonateInput));\n+\n+  // Input 2 : [0, 1, 2, 3, 4, 5] replicated on device 0 and 1.\n+  xla::ifrt::ShardingRef input2_sharding =\n+      xla::ifrt::ConcreteEvenSharding::Create(\n+          std::move(device_list), xla::ifrt::MemoryKind(), shape, shape,\n+          /*is_fully_replicated=*/true);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      input_arrays.emplace_back(),\n+      client->MakeArrayFromHostBuffer(\n+          data.data(), dtype, shape,\n+          /*byte_strides=*/std::nullopt, input2_sharding,\n+          xla::ifrt::Client::HostBufferSemantics::kImmutableOnlyDuringCall,\n+          /*on_done_with_host_buffer=*/nullptr));\n+\n+  xla::ifrt::LoadedExecutable::ExecuteOptions execute_options;\n+  execute_options.fill_status = true;\n+  TF_ASSERT_OK_AND_ASSIGN(xla::ifrt::LoadedExecutable::ExecuteResult result,\n+                          deserialized_executable->Execute(\n+                              absl::MakeSpan(input_arrays), execute_options,\n+                              /*devices=*/std::nullopt));\n+  TF_ASSERT_OK(result.status.Await());\n+  EXPECT_THAT(result.outputs, SizeIs(2));\n+\n+  {\n+    std::vector<int32_t> out_data(6);\n+    xla::ifrt::Future<> future = result.outputs[0]->CopyToHostBuffer(\n+        out_data.data(), /*byte_strides=*/std::nullopt,\n+        xla::ifrt::ArrayCopySemantics::kAlwaysCopy);\n+    TF_ASSERT_OK(future.Await());\n+    EXPECT_THAT(out_data, ElementsAre(0, 2, 4, 6, 8, 10));\n+  }\n+\n+  {\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto output_shards,\n+        result.outputs[1]->DisassembleIntoSingleDeviceArrays(\n+            xla::ifrt::ArrayCopySemantics::kDonateInput,\n+            xla::ifrt::SingleDeviceShardSemantics::kAddressableShards));\n+    ASSERT_THAT(output_shards, SizeIs(2));\n+    {\n+      std::vector<int32_t> out_data(3);\n+      auto future = output_shards[0]->CopyToHostBuffer(\n+          out_data.data(), /*byte_strides=*/std::nullopt,\n+          xla::ifrt::ArrayCopySemantics::kAlwaysCopy);\n+      TF_ASSERT_OK(future.Await());\n+      EXPECT_THAT(out_data, testing::Each(0));\n+    }\n+    {\n+      std::vector<float> out_data(3);\n+      auto future = output_shards[1]->CopyToHostBuffer(\n+          out_data.data(), /*byte_strides=*/std::nullopt,\n+          xla::ifrt::ArrayCopySemantics::kAlwaysCopy);\n+      TF_ASSERT_OK(future.Await());\n+      EXPECT_THAT(out_data, testing::Each(0));\n+    }\n+  }\n+}\n+\n }  // namespace\n }  // namespace ifrt\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 295,
        "additions": 291,
        "deletions": 4
    }
}