{
    "author": "vwbaker",
    "message": "[xla:gpu] Make GpuProfiler::CheckOutputBuffer support tuple shapes.\n\nPiperOrigin-RevId: 814281729",
    "sha": "ac8c4f7d95e38e62427dd4af679aff375325229a",
    "files": [
        {
            "sha": "4c60c1b72d02a9fdda02f4a72d0492d3c9ebf0ae",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 10,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ac8c4f7d95e38e62427dd4af679aff375325229a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ac8c4f7d95e38e62427dd4af679aff375325229a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc?ref=ac8c4f7d95e38e62427dd4af679aff375325229a",
            "patch": "@@ -206,16 +206,22 @@ absl::Status GpuProfiler::CheckInputBuffers(InputBuffers& buffers) {\n absl::Status GpuProfiler::CheckOutputBuffer(ScopedShapedBuffer& output,\n                                             ScopedShapedBuffer& reference,\n                                             float rtol) {\n-  BufferComparator comparator(output.on_device_shape(), rtol,\n-                              /*verbose=*/false);\n-\n-  TF_ASSIGN_OR_RETURN(bool outputs_match,\n-                      comparator.CompareEqual(stream_, output.root_buffer(),\n-                                              reference.root_buffer()));\n-  if (outputs_match) {\n-    return absl::OkStatus();\n-  }\n-  return absl::InternalError(\"Output buffer does not match reference buffer.\");\n+  return ShapeUtil::ForEachLeafShapeWithStatus(\n+      reference.on_device_shape(),\n+      [&](const Shape& subshape, const ShapeIndex& index) -> absl::Status {\n+        BufferComparator comparator(subshape, rtol,\n+                                    /*verbose=*/false);\n+\n+        TF_ASSIGN_OR_RETURN(\n+            bool outputs_match,\n+            comparator.CompareEqual(stream_, output.buffer(index),\n+                                    reference.buffer(index)));\n+        if (outputs_match) {\n+          return absl::OkStatus();\n+        }\n+        return absl::InternalError(\n+            \"Output buffer does not match reference buffer.\");\n+      });\n }\n \n }  // namespace gpu"
        },
        {
            "sha": "22e4c5102d383e2df39e57141ce6900aca731c38",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler_test.cc",
            "status": "modified",
            "additions": 67,
            "deletions": 0,
            "changes": 67,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ac8c4f7d95e38e62427dd4af679aff375325229a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ac8c4f7d95e38e62427dd4af679aff375325229a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc?ref=ac8c4f7d95e38e62427dd4af679aff375325229a",
            "patch": "@@ -103,6 +103,25 @@ absl::StatusOr<ScopedShapedBuffer> CreateTestBuffer(\n   return output;\n }\n \n+absl::StatusOr<ScopedShapedBuffer> CreateTupleTestBuffer(\n+    se::DeviceMemoryAllocator* allocator, se::StreamExecutor* stream_exec,\n+    se::Stream* stream, int32_t value1, int32_t value2) {\n+  Shape test_shape = ShapeUtil::MakeShape(S32, {});\n+  Shape test_shape_tuple = ShapeUtil::MakeTupleShape({test_shape, test_shape});\n+  TF_ASSIGN_OR_RETURN(auto* transfer_manager, TransferManager::GetForPlatform(\n+                                                  stream_exec->GetPlatform()));\n+  TF_ASSIGN_OR_RETURN(\n+      ScopedShapedBuffer output,\n+      transfer_manager->AllocateScopedShapedBuffer(\n+          test_shape_tuple, allocator, stream_exec->device_ordinal()));\n+  Literal literal1 = LiteralUtil::CreateR0<int32_t>(value1);\n+  Literal literal2 = LiteralUtil::CreateR0<int32_t>(value2);\n+  Literal tuple_literal = LiteralUtil::MakeTuple({&literal1, &literal2});\n+  TF_RETURN_IF_ERROR(\n+      transfer_manager->TransferLiteralToDevice(stream, tuple_literal, output));\n+  return output;\n+}\n+\n class GpuProfilerTest : public HloHardwareIndependentTestBase {\n  public:\n   GpuProfilerTest() {\n@@ -240,6 +259,54 @@ TEST_F(GpuProfilerTest, CheckOutputBufferWhenBuffersAreDifferent) {\n               StatusIs(absl::StatusCode::kInternal));\n }\n \n+TEST_F(GpuProfilerTest, CheckOutputBufferWithTupleShapeAreSame) {\n+  ProfileOptions options;\n+  auto profiler = GpuProfiler::Create(stream_exec_, options, allocator_.get());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_exec_->CreateStream());\n+  auto allocator =\n+      std::make_unique<stream_executor::StreamExecutorMemoryAllocator>(\n+          stream_exec_);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      ScopedShapedBuffer output,\n+      CreateTupleTestBuffer(allocator.get(), stream_exec_, stream.get(),\n+                            /*value1=*/1, /*value2=*/2));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      ScopedShapedBuffer reference,\n+      CreateTupleTestBuffer(allocator.get(), stream_exec_, stream.get(),\n+                            /*value1=*/1, /*value2=*/2));\n+  EXPECT_THAT(profiler->CheckOutputBuffer(output, reference, /*rtol=*/0.0),\n+              StatusIs(absl::StatusCode::kOk));\n+}\n+\n+TEST_F(GpuProfilerTest, CheckOutputBufferWithTupleShapeAreDifferent) {\n+  ProfileOptions options;\n+  auto profiler = GpuProfiler::Create(stream_exec_, options, allocator_.get());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_exec_->CreateStream());\n+  auto allocator =\n+      std::make_unique<stream_executor::StreamExecutorMemoryAllocator>(\n+          stream_exec_);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      ScopedShapedBuffer reference,\n+      CreateTupleTestBuffer(allocator.get(), stream_exec_, stream.get(),\n+                            /*value1=*/1, /*value2=*/2));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      ScopedShapedBuffer output_error_in_first_element,\n+      CreateTupleTestBuffer(allocator.get(), stream_exec_, stream.get(),\n+                            /*value1=*/0, /*value2=*/2));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      ScopedShapedBuffer output_error_in_second_element,\n+      CreateTupleTestBuffer(allocator.get(), stream_exec_, stream.get(),\n+                            /*value1=*/1, /*value2=*/3));\n+  EXPECT_THAT(profiler->CheckOutputBuffer(output_error_in_first_element,\n+                                          reference, /*rtol=*/0.0),\n+              StatusIs(absl::StatusCode::kInternal));\n+  EXPECT_THAT(profiler->CheckOutputBuffer(output_error_in_second_element,\n+                                          reference, /*rtol=*/0.0),\n+              StatusIs(absl::StatusCode::kInternal));\n+}\n+\n TEST_F(GpuProfilerTest, CheckScratchBytesArePopulatedUsingBufferAssignment) {\n   constexpr absl::string_view kHloModule = R\"(\n HloModule gemm_fusion_dot.1, is_scheduled=true, entry_computation_layout={(bf16[32,120,6,512]{3,2,1,0}, f32[3072,512]{1,0})->bf16[3840,512]{1,0}}, frontend_attributes={fingerprint_before_lhs=\"40f912baf5b53a4f75b1ba9b3442042f\"}"
        }
    ],
    "stats": {
        "total": 93,
        "additions": 83,
        "deletions": 10
    }
}