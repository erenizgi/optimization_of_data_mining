{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 850889069",
    "sha": "d81228508ca92100ce766023d38192bef2117510",
    "files": [
        {
            "sha": "01ff9cb5b7b5ac84a58e4767bb18a8a08e8f5e4f",
            "filename": "tensorflow/core/kernels/linalg/determinant_op.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d81228508ca92100ce766023d38192bef2117510/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fdeterminant_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d81228508ca92100ce766023d38192bef2117510/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fdeterminant_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fdeterminant_op.cc?ref=d81228508ca92100ce766023d38192bef2117510",
            "patch": "@@ -188,7 +188,7 @@ class DeterminantOpGpu : public AsyncOpKernel {\n     // Prepare pointer arrays for cuBlas' batch interface.\n     // TODO(rmlarsen): Find a way to encode pointer arrays in pinned host memory\n     // without the ugly casting.\n-    auto input_copy_ptrs = solver->GetScratchSpace<uint8>(\n+    auto input_copy_ptrs = solver->GetScratchSpace<uint8_t>(\n         sizeof(Scalar*) * batch_size, \"input_copy_ptrs\",\n         /* on_host */ true);\n     auto output_reshaped = out->template flat_inner_dims<Scalar, 1>();\n@@ -235,7 +235,7 @@ class DeterminantOpGpu : public AsyncOpKernel {\n \n     // Register callback to check info after kernels finish.\n     auto info_checker = [context, done](\n-                            const Status& status,\n+                            const absl::Status& status,\n                             const std::vector<HostLapackInfo>& host_infos) {\n       if (!status.ok() && absl::IsInvalidArgument(status) &&\n           !host_infos.empty()) {\n@@ -332,7 +332,7 @@ class LogDeterminantOpGpu : public AsyncOpKernel {\n     // Prepare pointer arrays for cuBlas' batch interface.\n     // TODO(rmlarsen): Find a way to encode pointer arrays in pinned host memory\n     // without the ugly casting.\n-    auto input_copy_ptrs = solver->GetScratchSpace<uint8>(\n+    auto input_copy_ptrs = solver->GetScratchSpace<uint8_t>(\n         sizeof(Scalar*) * batch_size, \"input_copy_ptrs\",\n         /* on_host */ true);\n \n@@ -381,7 +381,7 @@ class LogDeterminantOpGpu : public AsyncOpKernel {\n \n     // Register callback to check info after kernels finish.\n     auto info_checker = [context, done](\n-                            const Status& status,\n+                            const absl::Status& status,\n                             const std::vector<HostLapackInfo>& host_infos) {\n       if (!status.ok() && absl::IsInvalidArgument(status) &&\n           !host_infos.empty()) {"
        },
        {
            "sha": "e4d4f5b3a7d3ebd6977a1cad46cfbada46d0ba4f",
            "filename": "tensorflow/core/kernels/linalg/matrix_solve_op.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d81228508ca92100ce766023d38192bef2117510/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d81228508ca92100ce766023d38192bef2117510/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_op.cc?ref=d81228508ca92100ce766023d38192bef2117510",
            "patch": "@@ -221,7 +221,7 @@ class MatrixSolveOpGpu : public AsyncOpKernel {\n     // 1. Compute the partially pivoted LU factorization(s) of the\n     // matrix/matrices.\n     std::vector<DeviceLapackInfo> dev_info;\n-    auto input_copy_ptrs = solver->GetScratchSpace<uint8>(\n+    auto input_copy_ptrs = solver->GetScratchSpace<uint8_t>(\n         sizeof(Scalar*) * batch_size, \"input_copt_ptrs\",\n         /* on_host */ true);\n     const int kMaxMatrixSizeToBatchSizeRatio = 128;\n@@ -301,10 +301,10 @@ class MatrixSolveOpGpu : public AsyncOpKernel {\n     // fly. (This means that we actually use the LU-factorization of A^T in that\n     // case, but that is equally good for solving AX=B). This way we save an\n     // explicit transpose in the more common case of adjoint_ == false.\n-    auto input_copy_ptr_array = solver->GetScratchSpace<uint8>(\n+    auto input_copy_ptr_array = solver->GetScratchSpace<uint8_t>(\n         sizeof(Scalar*) * batch_size, \"input_copy_ptr_array\",\n         /* on_host */ true);\n-    auto transposed_rhs_ptr_array = solver->GetScratchSpace<uint8>(\n+    auto transposed_rhs_ptr_array = solver->GetScratchSpace<uint8_t>(\n         sizeof(Scalar*) * batch_size, \"transposed_rhs_ptr_array\",\n         /* on_host */ true);\n     auto transposed_rhs_reshaped =\n@@ -367,7 +367,7 @@ class MatrixSolveOpGpu : public AsyncOpKernel {\n     // kernels run. TODO(rmlarsen): Use move capture once C++14 becomes\n     // available.\n     auto info_checker = [context, done, dev_info](\n-                            const Status& status,\n+                            const absl::Status& status,\n                             const std::vector<HostLapackInfo>& host_infos) {\n       if (!status.ok() && absl::IsInvalidArgument(status) &&\n           !host_infos.empty()) {"
        }
    ],
    "stats": {
        "total": 16,
        "additions": 8,
        "deletions": 8
    }
}