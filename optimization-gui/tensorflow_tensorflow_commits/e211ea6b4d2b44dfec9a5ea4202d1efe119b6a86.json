{
    "author": "ezhulenev",
    "message": "[xla:cpu] Remove legacy runtime_matmul headers and source\n\nPiperOrigin-RevId: 834378768",
    "sha": "e211ea6b4d2b44dfec9a5ea4202d1efe119b6a86",
    "files": [
        {
            "sha": "23a03b76a923e23381857a0d3ba7ec7d7fb39cf3",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e211ea6b4d2b44dfec9a5ea4202d1efe119b6a86/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e211ea6b4d2b44dfec9a5ea4202d1efe119b6a86/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=e211ea6b4d2b44dfec9a5ea4202d1efe119b6a86",
            "patch": "@@ -62,13 +62,6 @@ filegroup(\n         \"runtime_single_threaded_matmul_s32.cc\",\n         \"runtime_single_threaded_matmul_u8.cc\",\n         # Multi-threaded support.\n-        \"runtime_matmul_c128.cc\",\n-        \"runtime_matmul_c64.cc\",\n-        \"runtime_matmul_common.h\",\n-        \"runtime_matmul_f16.cc\",\n-        \"runtime_matmul_f32.cc\",\n-        \"runtime_matmul_f64.cc\",\n-        \"runtime_matmul_s32.cc\",\n         \"//xla/backends/cpu/runtime:runtime_srcs\",\n     ],\n     visibility = internal_visibility([\":friends\"]),\n@@ -81,7 +74,6 @@ filegroup(\n         \"runtime_single_threaded_matmul.h\",\n         # Multi-threaded support.\n         \"runtime_lightweight_check.h\",\n-        \"runtime_matmul.h\",\n         \"//xla/backends/cpu/runtime:runtime_hdrs\",\n     ],\n     visibility = internal_visibility([\":friends\"]),\n@@ -1050,27 +1042,6 @@ cc_library(\n \n cc_library(\n     name = \"runtime_matmul\",\n-    srcs = [\n-        \"runtime_matmul_c128.cc\",\n-        \"runtime_matmul_c64.cc\",\n-        \"runtime_matmul_common.h\",\n-        \"runtime_matmul_f16.cc\",\n-        \"runtime_matmul_f32.cc\",\n-        \"runtime_matmul_f64.cc\",\n-        \"runtime_matmul_s32.cc\",\n-    ],\n-    hdrs = [\"runtime_matmul.h\"],\n-    copts = runtime_copts(),\n-    visibility = [\"//visibility:public\"],\n-    deps = [\n-        \":runtime_lightweight_check\",\n-        \"//xla:executable_run_options\",\n-        \"//xla/tsl/framework/contraction:eigen_contraction_kernel\",\n-        \"@com_google_absl//absl/base:core_headers\",\n-        \"@com_google_absl//absl/base:dynamic_annotations\",\n-        \"@com_google_absl//absl/synchronization\",  # build_cleaner: keep\n-        \"@eigen_archive//:eigen3\",\n-    ],\n )\n \n cc_library("
        },
        {
            "sha": "a7d79bf1c0e580626f91da2c885935559ac88e01",
            "filename": "third_party/xla/xla/service/cpu/runtime_matmul.h",
            "status": "removed",
            "additions": 0,
            "deletions": 68,
            "changes": 68,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul.h?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -1,68 +0,0 @@\n-/* Copyright 2017 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_SERVICE_CPU_RUNTIME_MATMUL_H_\n-#define XLA_SERVICE_CPU_RUNTIME_MATMUL_H_\n-\n-#include <stdint.h>\n-\n-#include <complex>\n-\n-#include \"Eigen/Core\"\n-\n-extern \"C\" {\n-\n-// Performs a multi-threaded matrix multiplication using Eigen. 'lhs' and 'rhs'\n-// are pointers to buffers containing input matrices in column-major\n-// order. 'out' is a pointer to a buffer sufficiently large to hold the result\n-// of the operation. Following standard nomenclature: lhs is m x k,\n-// rhs is k x n, and out is m x n.\n-extern void __xla_cpu_runtime_EigenMatMulF16(\n-    const void* /* xla::ExecutableRunOptions* */ run_options_ptr,\n-    Eigen::half* out, Eigen::half* lhs, Eigen::half* rhs, int64_t m, int64_t n,\n-    int64_t k, int32_t transpose_lhs, int32_t transpose_rhs);\n-\n-extern void __xla_cpu_runtime_EigenMatMulF32(\n-    const void* /* xla::ExecutableRunOptions* */ run_options_ptr, float* out,\n-    float* lhs, float* rhs, int64_t m, int64_t n, int64_t k,\n-    int32_t transpose_lhs, int32_t transpose_rhs);\n-\n-extern void __xla_cpu_runtime_EigenMatMulF64(\n-    const void* /* xla::ExecutableRunOptions* */ run_options_ptr, double* out,\n-    double* lhs, double* rhs, int64_t m, int64_t n, int64_t k,\n-    int32_t transpose_lhs, int32_t transpose_rhs);\n-\n-extern void __xla_cpu_runtime_EigenMatMulC64(\n-    const void* run_options_ptr, std::complex<float>* out,\n-    std::complex<float>* lhs, std::complex<float>* rhs, int64_t m, int64_t n,\n-    int64_t k, int32_t transpose_lhs, int32_t transpose_rhs);\n-\n-extern void __xla_cpu_runtime_EigenMatMulC128(\n-    const void* run_options_ptr, std::complex<double>* out,\n-    std::complex<double>* lhs, std::complex<double>* rhs, int64_t m, int64_t n,\n-    int64_t k, int32_t transpose_lhs, int32_t transpose_rhs);\n-\n-extern void __xla_cpu_runtime_EigenMatMulS32(\n-    const void* /* xla::ExecutableRunOptions* */ run_options_ptr, int32_t* out,\n-    int32_t* lhs, int32_t* rhs, int64_t m, int64_t n, int64_t k,\n-    int32_t transpose_lhs, int32_t transpose_rhs);\n-\n-extern void __xla_cpu_runtime_EigenBatchMatMulF32(\n-    const void* /* xla::ExecutableRunOptions* */ run_options_ptr, float* out,\n-    float* lhs, float* rhs, int64_t m, int64_t n, int64_t k, int64_t batch_size,\n-    int32_t transpose_lhs, int32_t transpose_rhs);\n-}  // extern \"C\"\n-\n-#endif  // XLA_SERVICE_CPU_RUNTIME_MATMUL_H_"
        },
        {
            "sha": "0890c1c6599426d59a6d35346300f3afd6d449f0",
            "filename": "third_party/xla/xla/service/cpu/runtime_matmul_c128.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_c128.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_c128.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_c128.cc?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -1,30 +0,0 @@\n-/* Copyright 2017 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/cpu/runtime_matmul.h\"\n-\n-#include <complex>\n-#include <cstdint>\n-\n-#include \"absl/base/attributes.h\"\n-#include \"xla/service/cpu/runtime_matmul_common.h\"\n-\n-ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_EigenMatMulC128(\n-    const void* run_options_ptr, std::complex<double>* out,\n-    std::complex<double>* lhs, std::complex<double>* rhs, int64_t m, int64_t n,\n-    int64_t k, int32_t transpose_lhs, int32_t transpose_rhs) {\n-  xla::MatMulDispatch<std::complex<double>>(run_options_ptr, out, lhs, rhs, m,\n-                                            n, k, transpose_lhs, transpose_rhs);\n-}"
        },
        {
            "sha": "0152cf74927f1d62dddca56c24334fd17d4483c9",
            "filename": "third_party/xla/xla/service/cpu/runtime_matmul_c64.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_c64.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_c64.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_c64.cc?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -1,30 +0,0 @@\n-/* Copyright 2017 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/cpu/runtime_matmul.h\"\n-\n-#include <complex>\n-#include <cstdint>\n-\n-#include \"absl/base/attributes.h\"\n-#include \"xla/service/cpu/runtime_matmul_common.h\"\n-\n-ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_EigenMatMulC64(\n-    const void* run_options_ptr, std::complex<float>* out,\n-    std::complex<float>* lhs, std::complex<float>* rhs, int64_t m, int64_t n,\n-    int64_t k, int32_t transpose_lhs, int32_t transpose_rhs) {\n-  xla::MatMulDispatch<std::complex<float>>(run_options_ptr, out, lhs, rhs, m, n,\n-                                           k, transpose_lhs, transpose_rhs);\n-}"
        },
        {
            "sha": "069915aad64d1dfe90614b74f08bcb5da2ac75b7",
            "filename": "third_party/xla/xla/service/cpu/runtime_matmul_common.h",
            "status": "removed",
            "additions": 0,
            "deletions": 154,
            "changes": 154,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_common.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_common.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_common.h?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -1,154 +0,0 @@\n-/* Copyright 2017 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_SERVICE_CPU_RUNTIME_MATMUL_COMMON_H_\n-#define XLA_SERVICE_CPU_RUNTIME_MATMUL_COMMON_H_\n-\n-#include <cstdint>\n-\n-#define EIGEN_USE_THREADS\n-\n-#include \"absl/base/dynamic_annotations.h\"\n-#include \"unsupported/Eigen/CXX11/Tensor\"\n-#include \"xla/executable_run_options.h\"\n-#include \"xla/service/cpu/runtime_lightweight_check.h\"\n-\n-#if defined(TENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL)\n-#include \"xla/tsl/framework/contraction/eigen_contraction_kernel.h\"\n-#endif\n-\n-namespace xla {\n-\n-static inline bool Is16BytesAligned(void* ptr) {\n-  return reinterpret_cast<uintptr_t>(ptr) % 16 == 0;\n-}\n-\n-template <typename T, Eigen::AlignmentType Alignment>\n-void MatMul(const void* run_options_ptr, T* out, T* lhs, T* rhs, int64_t m,\n-            int64_t n, int64_t k, int32_t transpose_lhs,\n-            int32_t transpose_rhs) {\n-  const xla::ExecutableRunOptions* run_options =\n-      static_cast<const xla::ExecutableRunOptions*>(run_options_ptr);\n-\n-  int64_t lhs_rows = m;\n-  int64_t lhs_cols = k;\n-  if (transpose_lhs) {\n-    std::swap(lhs_rows, lhs_cols);\n-  }\n-\n-  int64_t rhs_rows = k;\n-  int64_t rhs_cols = n;\n-  if (transpose_rhs) {\n-    std::swap(rhs_rows, rhs_cols);\n-  }\n-\n-  const Eigen::TensorMap<Eigen::Tensor<const T, 2>, Alignment> A(lhs, lhs_rows,\n-                                                                 lhs_cols);\n-  const Eigen::TensorMap<Eigen::Tensor<const T, 2>, Alignment> B(rhs, rhs_rows,\n-                                                                 rhs_cols);\n-  Eigen::TensorMap<Eigen::Tensor<T, 2>, Alignment> C(out, m, n);\n-\n-  typedef typename Eigen::Tensor<T, 2>::DimensionPair DimPair;\n-  int lhs_contract_dim = transpose_lhs ? 0 : 1;\n-  int rhs_contract_dim = transpose_rhs ? 1 : 0;\n-  const Eigen::array<DimPair, 1> dims(\n-      {DimPair(lhs_contract_dim, rhs_contract_dim)});\n-\n-  // Matrix multiply is a special case of the \"contract\" operation where\n-  // the contraction is performed along dimension 1 of the lhs and dimension\n-  // 0 of the rhs.\n-  XLA_LIGHTWEIGHT_CHECK(run_options->intra_op_thread_pool() != nullptr);\n-  C.device(*run_options->intra_op_thread_pool()) = A.contract(B, dims);\n-}\n-\n-template <typename T, Eigen::AlignmentType Alignment>\n-void MatMul_Batch(const void* run_options_ptr, T* out, T* lhs, T* rhs,\n-                  int64_t m, int64_t n, int64_t k, Eigen::Index batch_size,\n-                  int32_t transpose_lhs, int32_t transpose_rhs) {\n-  const xla::ExecutableRunOptions* run_options =\n-      static_cast<const xla::ExecutableRunOptions*>(run_options_ptr);\n-\n-  int64_t lhs_rows = m;\n-  int64_t lhs_cols = k;\n-  if (transpose_lhs) {\n-    std::swap(lhs_rows, lhs_cols);\n-  }\n-\n-  int64_t rhs_rows = k;\n-  int64_t rhs_cols = n;\n-  if (transpose_rhs) {\n-    std::swap(rhs_rows, rhs_cols);\n-  }\n-\n-  const Eigen::TensorMap<Eigen::Tensor<const T, 3>, Alignment> A(\n-      lhs, lhs_rows, lhs_cols, batch_size);\n-  const Eigen::TensorMap<Eigen::Tensor<const T, 3>, Alignment> B(\n-      rhs, rhs_rows, rhs_cols, batch_size);\n-  Eigen::TensorMap<Eigen::Tensor<T, 3>, Alignment> C(out, m, n, batch_size);\n-\n-  typedef typename Eigen::Tensor<T, 2>::DimensionPair DimPair;\n-  int lhs_contract_dim = transpose_lhs ? 0 : 1;\n-  int rhs_contract_dim = transpose_rhs ? 1 : 0;\n-\n-  const Eigen::array<DimPair, 1> dims(\n-      {DimPair(lhs_contract_dim, rhs_contract_dim)});\n-\n-  // Matrix multiply is a special case of the \"contract\" operation where\n-  // the contraction is performed along dimension 1 of the lhs and dimension\n-  // 0 of the rhs.\n-  XLA_LIGHTWEIGHT_CHECK(run_options->intra_op_thread_pool() != nullptr);\n-\n-  for (int64_t i = 0; i < batch_size; ++i) {\n-    C.chip(i, 2).device(*run_options->intra_op_thread_pool()) =\n-        A.chip(i, 2).contract(B.chip(i, 2), dims);\n-  }\n-}\n-\n-template <typename T>\n-void MatMulDispatch(const void* run_options_ptr, T* out, T* lhs, T* rhs,\n-                    int64_t m, int64_t n, int64_t k, int32_t transpose_lhs,\n-                    int32_t transpose_rhs) {\n-  bool all_buffers_16b_aligned =\n-      Is16BytesAligned(out) && Is16BytesAligned(lhs) && Is16BytesAligned(rhs);\n-\n-  if (!all_buffers_16b_aligned) {\n-    MatMul<T, Eigen::Unaligned>(run_options_ptr, out, lhs, rhs, m, n, k,\n-                                transpose_lhs, transpose_rhs);\n-    return;\n-  }\n-\n-  MatMul<T, Eigen::Aligned16>(run_options_ptr, out, lhs, rhs, m, n, k,\n-                              transpose_lhs, transpose_rhs);\n-}\n-\n-template <typename T>\n-void BatchMatMulDispatch(const void* run_options_ptr, T* out, T* lhs, T* rhs,\n-                         int64_t m, int64_t n, int64_t k, int64_t batch_size,\n-                         int32_t transpose_lhs, int32_t transpose_rhs) {\n-  bool all_buffers_16b_aligned =\n-      Is16BytesAligned(out) && Is16BytesAligned(lhs) && Is16BytesAligned(rhs);\n-\n-  if (!all_buffers_16b_aligned) {\n-    MatMul_Batch<T, Eigen::Unaligned>(run_options_ptr, out, lhs, rhs, m, n, k,\n-                                      batch_size, transpose_lhs, transpose_rhs);\n-    return;\n-  }\n-  MatMul_Batch<T, Eigen::Aligned16>(run_options_ptr, out, lhs, rhs, m, n, k,\n-                                    batch_size, transpose_lhs, transpose_rhs);\n-}\n-\n-}  // namespace xla\n-\n-#endif  // XLA_SERVICE_CPU_RUNTIME_MATMUL_COMMON_H_"
        },
        {
            "sha": "31f21424ccc7e88928f68c40cd8f611392ce2348",
            "filename": "third_party/xla/xla/service/cpu/runtime_matmul_f16.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 30,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_f16.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_f16.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_f16.cc?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -1,30 +0,0 @@\n-/* Copyright 2017 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/cpu/runtime_matmul.h\"\n-\n-#include <cstdint>\n-\n-#include \"absl/base/attributes.h\"\n-#include \"Eigen/Core\"\n-#include \"xla/service/cpu/runtime_matmul_common.h\"\n-\n-ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_EigenMatMulF16(\n-    const void* run_options_ptr, Eigen::half* out, Eigen::half* lhs,\n-    Eigen::half* rhs, int64_t m, int64_t n, int64_t k, int32_t transpose_lhs,\n-    int32_t transpose_rhs) {\n-  xla::MatMulDispatch<Eigen::half>(run_options_ptr, out, lhs, rhs, m, n, k,\n-                                   transpose_lhs, transpose_rhs);\n-}"
        },
        {
            "sha": "e49e53c0de3e3288fcc22be9ab40f633aeeb77c5",
            "filename": "third_party/xla/xla/service/cpu/runtime_matmul_f32.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 36,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_f32.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_f32.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_f32.cc?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -1,36 +0,0 @@\n-/* Copyright 2017 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/cpu/runtime_matmul.h\"\n-\n-#include <cstdint>\n-\n-#include \"absl/base/attributes.h\"\n-#include \"xla/service/cpu/runtime_matmul_common.h\"\n-\n-ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_EigenMatMulF32(\n-    const void* run_options_ptr, float* out, float* lhs, float* rhs, int64_t m,\n-    int64_t n, int64_t k, int32_t transpose_lhs, int32_t transpose_rhs) {\n-  xla::MatMulDispatch<float>(run_options_ptr, out, lhs, rhs, m, n, k,\n-                             transpose_lhs, transpose_rhs);\n-}\n-\n-ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_EigenBatchMatMulF32(\n-    const void* run_options_ptr, float* out, float* lhs, float* rhs, int64_t m,\n-    int64_t n, int64_t k, int64_t batch_size, int32_t transpose_lhs,\n-    int32_t transpose_rhs) {\n-  xla::BatchMatMulDispatch<float>(run_options_ptr, out, lhs, rhs, m, n, k,\n-                                  batch_size, transpose_lhs, transpose_rhs);\n-}"
        },
        {
            "sha": "318ef91babe69bc67d84ffff07b16932b8ac3590",
            "filename": "third_party/xla/xla/service/cpu/runtime_matmul_f64.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_f64.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_f64.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_f64.cc?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -1,29 +0,0 @@\n-/* Copyright 2017 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/cpu/runtime_matmul.h\"\n-\n-#include <cstdint>\n-\n-#include \"absl/base/attributes.h\"\n-#include \"xla/service/cpu/runtime_matmul_common.h\"\n-\n-ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_EigenMatMulF64(\n-    const void* run_options_ptr, double* out, double* lhs, double* rhs,\n-    int64_t m, int64_t n, int64_t k, int32_t transpose_lhs,\n-    int32_t transpose_rhs) {\n-  xla::MatMulDispatch<double>(run_options_ptr, out, lhs, rhs, m, n, k,\n-                              transpose_lhs, transpose_rhs);\n-}"
        },
        {
            "sha": "6bc5a9bb2abd71f1c035154a865f3b8a7ef60164",
            "filename": "third_party/xla/xla/service/cpu/runtime_matmul_s32.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_s32.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbc6d5a129b3ba08a514568c95f6a1ced83e52fe/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_s32.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fruntime_matmul_s32.cc?ref=dbc6d5a129b3ba08a514568c95f6a1ced83e52fe",
            "patch": "@@ -1,29 +0,0 @@\n-/* Copyright 2017 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/cpu/runtime_matmul.h\"\n-\n-#include <cstdint>\n-\n-#include \"absl/base/attributes.h\"\n-#include \"xla/service/cpu/runtime_matmul_common.h\"\n-\n-ABSL_ATTRIBUTE_NO_SANITIZE_MEMORY void __xla_cpu_runtime_EigenMatMulS32(\n-    const void* run_options_ptr, int32_t* out, int32_t* lhs, int32_t* rhs,\n-    int64_t m, int64_t n, int64_t k, int32_t transpose_lhs,\n-    int32_t transpose_rhs) {\n-  xla::MatMulDispatch<int32_t>(run_options_ptr, out, lhs, rhs, m, n, k,\n-                               transpose_lhs, transpose_rhs);\n-}"
        }
    ],
    "stats": {
        "total": 435,
        "additions": 0,
        "deletions": 435
    }
}