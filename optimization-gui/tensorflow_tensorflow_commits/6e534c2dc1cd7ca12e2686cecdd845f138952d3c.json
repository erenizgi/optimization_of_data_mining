{
    "author": "Tixxx",
    "message": "PR #32389: [NVIDIA GPU] Change collective pipeliner to honor opt-barrier\n\nImported from GitHub PR https://github.com/openxla/xla/pull/32389\n\nüìù Summary of Changes\nThe current collective pipeliners don't honor opt-barrier in their user/producer chain.\nThis pr changes the behavior to teach collective pipeliners to use acceptable_formatting function to filter out what cannot be pipelined.\nüéØ Justification\nWithout this, opt-barriers connected with target collectives will be peeled and pipelined to other loop iterations which changes the semantic of the whole program.\n\nüöÄ Kind of Contribution\n üêõ Bug Fix\n\nüìä Benchmark (for Performance Improvements)\nNA\n\nüß™ Unit Tests:\nAdded unit tests\n\nüß™ Execution Tests:\nNA\n\nCopybara import of the project:\n\n--\n4273b194da9ca66b4ebcaa959bcc8119d8c3eff7 by TJ Xu <tjx@nvidia.com>:\n\nChange collective pipeliner to honor opt-barrier\n\nMerging this change closes #32389\n\nPiperOrigin-RevId: 817286398",
    "sha": "6e534c2dc1cd7ca12e2686cecdd845f138952d3c",
    "files": [
        {
            "sha": "fbe77cc48ec3473086ab0c05b7c533e6ef0cefd4",
            "filename": "third_party/xla/xla/service/collective_pipeliner.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 4,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6e534c2dc1cd7ca12e2686cecdd845f138952d3c/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6e534c2dc1cd7ca12e2686cecdd845f138952d3c/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.cc?ref=6e534c2dc1cd7ca12e2686cecdd845f138952d3c",
            "patch": "@@ -514,7 +514,8 @@ std::optional<std::vector<HloInstruction*>> CollectIndependentOperandChain(\n     HloPredicate should_allow_loop_variant_parameter_in_chain,\n     const absl::flat_hash_set<const HloInstruction*>&\n         loop_invariant_instructions,\n-    bool should_add_loop_invariant_op_in_chain) {\n+    bool should_add_loop_invariant_op_in_chain,\n+    HloPredicate acceptable_formatting) {\n   std::vector<HloInstruction*> chain;\n   absl::flat_hash_set<const HloInstruction*> visited_set({instr});\n   std::vector<std::pair<HloInstruction*, int>> stack(1, {instr, 0});\n@@ -549,6 +550,9 @@ std::optional<std::vector<HloInstruction*>> CollectIndependentOperandChain(\n     }\n   }\n   for (auto* chain_instr : chain) {\n+    if (!acceptable_formatting(chain_instr)) {\n+      return std::nullopt;\n+    }\n     // Allow tokens in the chain.\n     if (chain_instr->opcode() == HloOpcode::kAfterAll) {\n       continue;\n@@ -600,14 +604,15 @@ std::optional<std::vector<HloInstruction*>> CollectChainsToPushBackwards(\n     bool should_allow_control_dependencies,\n     const absl::flat_hash_set<const HloInstruction*>&\n         loop_invariant_instructions,\n-    bool should_add_loop_invariant_op_in_chain) {\n+    bool should_add_loop_invariant_op_in_chain,\n+    HloPredicate acceptable_formatting) {\n   if (instr->HasControlDependencies() && !should_allow_control_dependencies) {\n     return std::nullopt;\n   }\n   return CollectIndependentOperandChain(\n       instr, loop_iter, loop_invariant_params,\n       should_allow_loop_variant_parameter_in_chain, loop_invariant_instructions,\n-      should_add_loop_invariant_op_in_chain);\n+      should_add_loop_invariant_op_in_chain, acceptable_formatting);\n }\n \n // Given a dynamic-update-slice find the output index of the loop we feed into.\n@@ -1478,7 +1483,7 @@ void WhileLoopAnalysis::CollectCollectivesToMove(\n           invariant_loop_parameters_,\n           should_allow_loop_variant_parameter_in_chain,\n           should_allow_control_dependencies, invariant_loop_instructions_,\n-          should_add_loop_invariant_op_in_chain);\n+          should_add_loop_invariant_op_in_chain, acceptable_formatting);\n       if (!chain_collected.has_value()) {\n         VLOG(5) << \"Skipping \" << instr->name()\n                 << \" because didn't find compatible slice of parameter\";"
        },
        {
            "sha": "5b93a77053a6603735150df8d83fb655afaf995c",
            "filename": "third_party/xla/xla/service/collective_pipeliner_test.cc",
            "status": "modified",
            "additions": 69,
            "deletions": 0,
            "changes": 69,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6e534c2dc1cd7ca12e2686cecdd845f138952d3c/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6e534c2dc1cd7ca12e2686cecdd845f138952d3c/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner_test.cc?ref=6e534c2dc1cd7ca12e2686cecdd845f138952d3c",
            "patch": "@@ -5281,5 +5281,74 @@ ENTRY entry {\n   EXPECT_EQ(fusion_count, 4);\n }\n \n+TEST_F(CollectivePipelinerTest, barrier) {\n+  constexpr absl::string_view hlo_string = R\"(\n+HloModule module\n+\n+while_cond {\n+param = (s32[], bf16[1,8,2048,32768]{3,2,1,0}, bf16[1,8,2048,32768]{3,2,1,0}) parameter(0)\n+gte = s32[] get-tuple-element(param), index=0\n+constant.1 = s32[] constant(3)\n+ROOT cmp = pred[] compare(gte, constant.1), direction=LT\n+}\n+\n+while_body {\n+param = (s32[], bf16[1,8,2048,32768]{3,2,1,0}, bf16[1,8,2048,32768]{3,2,1,0}) parameter(0)\n+get-tuple-element.394 = s32[] get-tuple-element(param), index=0\n+get-tuple-element.395 = bf16[1,8,2048,32768]{3,2,1,0} get-tuple-element(param), index=1\n+get-tuple-element.397 = bf16[1,8,2048,32768]{3,2,1,0} get-tuple-element(param), index=2\n+\n+constant.1 = bf16[] constant(2)\n+broadcast.3593 = bf16[1,8,2048,32768]{3,2,1,0} broadcast(constant.1), dimensions={}\n+\n+add.2 = bf16[1,8,2048,32768]{3,2,1,0} add(broadcast.3593, get-tuple-element.395)\n+tuple.39 = (bf16[1,8,2048,32768]{3,2,1,0}) tuple(add.2)\n+opt-barrier.13 = (bf16[1,8,2048,32768]{3,2,1,0}) opt-barrier(%tuple.39)\n+get-tuple-element.937 = bf16[1,8,2048,32768]{3,2,1,0} get-tuple-element(%opt-barrier.13), index=0\n+\n+all-gather.1 = bf16[1,64,2048,32768]{3,2,1,0} all-gather(get-tuple-element.937), channel_id=1, dimensions={1}, replica_groups={}\n+slice.2 = bf16[1,8,2048,32768]{3,2,1,0} slice(all-gather.1), slice={[0:1], [8:16], [0:2048], [0:32768]}\n+tuple.40 = (bf16[1,8,2048,32768]{3,2,1,0}) tuple(slice.2)\n+opt-barrier.14 = (bf16[1,8,2048,32768]{3,2,1,0}) opt-barrier(tuple.40)\n+get-tuple-element.938 = bf16[1,8,2048,32768]{3,2,1,0} get-tuple-element(opt-barrier.14), index=0\n+\n+constant.2 = s32[] constant(1)\n+add.230 = s32[] add(get-tuple-element.394, constant.2)\n+ROOT tuple = (s32[], bf16[1,8,2048,32768]{3,2,1,0}, bf16[1,8,2048,32768]{3,2,1,0}) tuple(add.230, add.2, get-tuple-element.938)\n+}\n+\n+ENTRY entry {\n+c0 = s32[] constant(0)\n+p0 = bf16[1,8,2048,32768]{3,2,1,0} parameter(0)\n+p1 = bf16[1,8,2048,32768]{3,2,1,0} parameter(1)\n+\n+tuple = (s32[], bf16[1,8,2048,32768]{3,2,1,0}, bf16[1,8,2048,32768]{3,2,1,0}) tuple(c0, p0, p1)\n+while = (s32[], bf16[1,8,2048,32768]{3,2,1,0}, bf16[1,8,2048,32768]{3,2,1,0}) while(tuple), condition=while_cond, body=while_body\n+ROOT gte1 = bf16[1,8,2048,32768]{3,2,1,0} get-tuple-element(while), index=1\n+}\n+)\";\n+\n+  auto module = ParseAndReturnUnverifiedModule(hlo_string, config_).value();\n+\n+  // We don't expect the graph to change as the all-gather has an opt-barrier\n+  // in the producer chain.\n+  EXPECT_FALSE(\n+      RunOptimizer(\n+          module.get(), /*last_run=*/true, 0,\n+          /*pipeline_use_tree=*/false,\n+          /*process_different_sized_ops=*/false,\n+          /*direction=*/\n+          collective_pipeliner_utils::PipeliningDirection::kBackward,\n+          /*should_process=*/IsAllGather,\n+          /*acceptable_formatting=*/\n+          HloPredicateIsNotOp<HloOpcode::kOptimizationBarrier>,\n+          /*reuse_pipelined_op_buffer=*/HloPredicateTrue,\n+          /*should_allow_loop_variant_parameter_in_chain=*/HloPredicateTrue,\n+          /*postprocess_backward_peeled=*/{},\n+          /*postprocess_backward_rotated=*/{},\n+          /*postprocess_backward_peeled_trailing=*/{},\n+          /*should_add_loop_invariant_op_in_chain=*/true)\n+          .value());\n+}\n }  // namespace\n }  // namespace xla"
        },
        {
            "sha": "a0ff6f970b78aa3751c4ab33b4f025b9103318b3",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6e534c2dc1cd7ca12e2686cecdd845f138952d3c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6e534c2dc1cd7ca12e2686cecdd845f138952d3c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=6e534c2dc1cd7ca12e2686cecdd845f138952d3c",
            "patch": "@@ -1045,7 +1045,8 @@ absl::Status RunCollectiveOptimizationPasses(\n         /*pipelining_direction=*/\n         collective_pipeliner_utils::PipeliningDirection::kForward,\n         /*should_process=*/HloPredicateIsOp<HloOpcode::kAllReduce>,\n-        /*acceptable_formatting=*/HloPredicateTrue,\n+        /*acceptable_formatting=*/\n+        HloPredicateIsNotOp<HloOpcode::kOptimizationBarrier>,\n         /*reuse_pipelined_op_buffer=*/HloPredicateFalse,\n         /*should_allow_loop_variant_parameter_in_chain=*/HloPredicateFalse,\n         /*should_allow_control_dependencies=*/false,\n@@ -1068,7 +1069,8 @@ absl::Status RunCollectiveOptimizationPasses(\n         /*pipelining_direction=*/\n         collective_pipeliner_utils::PipeliningDirection::kBackward,\n         /*should_process=*/HloPredicateIsOp<HloOpcode::kAllGather>,\n-        /*acceptable_formatting=*/HloPredicateTrue,\n+        /*acceptable_formatting=*/\n+        HloPredicateIsNotOp<HloOpcode::kOptimizationBarrier>,\n         /*reuse_pipelined_op_buffer=*/HloPredicateFalse,\n         /*should_allow_loop_variant_parameter_in_chain=*/HloPredicateFalse,\n         /*should_allow_control_dependencies=*/false,\n@@ -1091,7 +1093,8 @@ absl::Status RunCollectiveOptimizationPasses(\n         /*pipelining_direction=*/\n         collective_pipeliner_utils::PipeliningDirection::kForward,\n         /*should_process=*/HloPredicateIsOp<HloOpcode::kReduceScatter>,\n-        /*acceptable_formatting=*/HloPredicateTrue,\n+        /*acceptable_formatting=*/\n+        HloPredicateIsNotOp<HloOpcode::kOptimizationBarrier>,\n         /*reuse_pipelined_op_buffer=*/HloPredicateFalse,\n         /*should_allow_loop_variant_parameter_in_chain=*/HloPredicateFalse,\n         /*should_allow_control_dependencies=*/false,"
        }
    ],
    "stats": {
        "total": 91,
        "additions": 84,
        "deletions": 7
    }
}