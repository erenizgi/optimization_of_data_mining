{
    "author": "pschuh",
    "message": "Implement CommonPjRtLoadedExecutable::Execute,\nCommonPjRtLoadedExecutable::ExecutePortable and\nCommonPjRtLoadedExecutable::ExecuteSharded.\n\nPiperOrigin-RevId: 845898855",
    "sha": "26ebc05f4f9498c99400a6c8e88378ef689255d4",
    "files": [
        {
            "sha": "8c187f326821f121957681b7800a64993279d0be",
            "filename": "third_party/xla/xla/pjrt/common_pjrt_client.cc",
            "status": "modified",
            "additions": 258,
            "deletions": 0,
            "changes": 258,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/26ebc05f4f9498c99400a6c8e88378ef689255d4/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/26ebc05f4f9498c99400a6c8e88378ef689255d4/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc?ref=26ebc05f4f9498c99400a6c8e88378ef689255d4",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/base/thread_annotations.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/functional/any_invocable.h\"\n@@ -867,6 +868,263 @@ PjRtLoadedExecutable::Result CommonPjRtLoadedExecutable::ExecuteLaunch(\n            launch_args.is_predetermined_error)});\n }\n \n+absl::Status CommonPjRtLoadedExecutable::ExecutePrepareWithOomRetries(\n+    std::optional<ExecuteLaunchArgs>& launch_args,\n+    absl::Span<PjRtBuffer* const> argument_handles, int replica, int partition,\n+    const ExecuteOptions& options, size_t host_callback_idx,\n+    PjRtDevice* device) const {\n+  absl::Status prepare_status;\n+  int attempts = 0;\n+  while (true) {\n+    launch_args.emplace();\n+    prepare_status =\n+        ExecutePrepare(*launch_args, argument_handles, replica, partition,\n+                       options, host_callback_idx, device);\n+    ++attempts;\n+    if (!absl::IsResourceExhausted(prepare_status)) {\n+      break;\n+    }\n+    if (!ShouldRetryOnOom(attempts, launch_args->device, prepare_status)) {\n+      break;\n+    }\n+  }\n+  return prepare_status;\n+}\n+\n+static absl::Status ValidateHostTransferCallbacks(\n+    absl::Span<const std::vector<SendCallback>> send_callbacks,\n+    absl::Span<const std::vector<RecvCallback>> recv_callbacks,\n+    size_t num_devices) {\n+  if (!send_callbacks.empty() && send_callbacks.size() != num_devices) {\n+    return InvalidArgument(\n+        \"The number of send callback vectors does not match the number of \"\n+        \"devices\");\n+  }\n+  if (!recv_callbacks.empty() && recv_callbacks.size() != num_devices) {\n+    return InvalidArgument(\n+        \"The number of recv callback vectors does not match the number of \"\n+        \"devices\");\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::StatusOr<PjRtLoadedExecutable::Result>\n+CommonPjRtLoadedExecutable::ExecuteHelperOnSingleDevice(\n+    absl::Span<PjRtBuffer* const> argument_handles, int replica, int partition,\n+    const ExecuteOptions& options, bool fill_future, PjRtDevice* device) const {\n+  tsl::profiler::TraceMe traceme(\n+      \"CommonPjRtLoadedExecutable::ExecuteHelperOnSingleDevice\");\n+  std::optional<ExecuteLaunchArgs> launch_args;\n+  TF_RETURN_IF_ERROR(ExecutePrepareWithOomRetries(\n+      launch_args, argument_handles, replica, partition, options,\n+      /*host_callback_idx=*/0, device));\n+  return ExecuteLaunch(*launch_args, fill_future);\n+}\n+\n+absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n+CommonPjRtLoadedExecutable::ExecuteSharded(\n+    absl::Span<PjRtBuffer* const> argument_handles, PjRtDevice* device,\n+    const ExecuteOptions& options,\n+    std::optional<tsl::Future<void>>& returned_future, bool fill_future) const {\n+  tsl::profiler::TraceMe traceme(\"CommonPjRtLoadedExecutable::ExecuteSharded\");\n+  for (int i = 0; i < addressable_devices_.size(); ++i) {\n+    if (addressable_devices_[i] == device) {\n+      TF_RETURN_IF_ERROR(ValidateHostTransferCallbacks(\n+          options.send_callbacks, options.recv_callbacks, /*num_devices=*/1));\n+      TF_ASSIGN_OR_RETURN(\n+          auto result,\n+          ExecuteHelperOnSingleDevice(\n+              argument_handles, addressable_device_logical_ids_[i].replica,\n+              addressable_device_logical_ids_[i].partition, options,\n+              fill_future));\n+      returned_future = std::move(result.future);\n+      return std::move(result.buffers);\n+    }\n+  }\n+  return InvalidArgument(\n+      \"ExecuteShard attempted to execute on device id %d which is not \"\n+      \"addressable by this client\",\n+      device->global_device_id().value());\n+}\n+\n+absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n+CommonPjRtLoadedExecutable::ExecutePortable(\n+    absl::Span<PjRtBuffer* const> argument_handles, PjRtDevice* device,\n+    const ExecuteOptions& options,\n+    std::optional<tsl::Future<void>>& returned_future, bool fill_future) const {\n+  tsl::profiler::TraceMe traceme(\"CommonPjRtLoadedExecutable::ExecutePortable\");\n+  if (num_replicas() != 1 || num_partitions() != 1) {\n+    return InvalidArgument(\n+        \"ExecutePortable expects a single-core executable but gets \"\n+        \"one with %d replica %d partition\",\n+        num_replicas(), num_partitions());\n+  }\n+  if (device == nullptr) {\n+    return InvalidArgument(\"ExecutePortable expects a device to be specified\");\n+  }\n+\n+  TF_RETURN_IF_ERROR(ValidateHostTransferCallbacks(\n+      options.send_callbacks, options.recv_callbacks, /*num_devices=*/1));\n+  VLOG(1) << \"ExecutePortable executes single-core portable executable \"\n+          << name();\n+  TF_ASSIGN_OR_RETURN(\n+      auto result, ExecuteHelperOnSingleDevice(argument_handles, /*replica=*/0,\n+                                               /*partition=*/0, options,\n+                                               fill_future, device));\n+  returned_future = std::move(result.future);\n+  return std::move(result.buffers);\n+}\n+\n+absl::StatusOr<std::vector<std::vector<std::unique_ptr<PjRtBuffer>>>>\n+CommonPjRtLoadedExecutable::Execute(\n+    absl::Span<const std::vector<PjRtBuffer*>> argument_handles,\n+    const ExecuteOptions& options,\n+    std::optional<std::vector<tsl::Future<void>>>& returned_futures) const {\n+  tsl::profiler::TraceMe traceme(\"CommonPjRtLoadedExecutable::Execute\");\n+  VLOG(1) << \"CommonPjRtLoadedExecutable::Execute\";\n+  if (!client()->allows_recursion() && ThisThreadIsInsideHostCallback()) {\n+    // Because TPU is single threaded, and the host callback currently blocking\n+    // the TPU, we should not initiate any outstanding computations because that\n+    // risks deadlocking the TPU.\n+    return InvalidArgument(\"Execute() called from inside host callback.\");\n+  }\n+\n+  tsl::profiler::TraceMeProducer producer(\"CommonPjRtLoadedExecutable::Execute\",\n+                                          tsl::profiler::ContextType::kPjRt);\n+\n+  const int num_addressable_devices = addressable_devices_.size();\n+\n+  if (argument_handles.size() != num_addressable_devices) {\n+    return InvalidArgument(\n+        \"Attempted to execute with %d argument lists when local device \"\n+        \"count is %d (total replica count: %d, partition count: %d)\",\n+        argument_handles.size(), num_addressable_devices, num_replicas(),\n+        num_partitions());\n+  }\n+\n+  VLOG(1) << \"Executing computation \" << name()\n+          << \"; num_replicas=\" << num_replicas()\n+          << \" num_partitions=\" << num_partitions()\n+          << \" num_addressable_devices=\" << num_addressable_devices;\n+\n+  TF_RETURN_IF_ERROR(ValidateHostTransferCallbacks(\n+      options.send_callbacks, options.recv_callbacks,\n+      addressable_devices_.size()));\n+\n+  std::vector<absl::StatusOr<Result>> results(num_addressable_devices);\n+  if (num_addressable_devices == 1) {\n+    // Fast-path if there is only one device â€” run the computation on the\n+    // current thread.\n+    const int replica = addressable_device_logical_ids_[0].replica;\n+    const int partition = addressable_device_logical_ids_[0].partition;\n+    results[0] =\n+        ExecuteHelperOnSingleDevice(argument_handles[0], replica, partition,\n+                                    options, returned_futures.has_value());\n+  } else {\n+    absl::Mutex mu;\n+    int preparing = num_addressable_devices;\n+    int launching = num_addressable_devices;\n+    int failed = 0;\n+    absl::Status first_failure_status;\n+\n+    {\n+      // The gang_schedule mutex ensures that all calls to Schedule() happen\n+      // atomically and cannot interleave with calls to Execute on other\n+      // threads. If calls to Schedule are not atomic, then the threads can get\n+      // stuck waiting for done_preparing to become true.\n+      absl::MutexLock gang_schedule(client()->gang_scheduler());\n+      auto context_id = producer.GetContextId();\n+      for (int i = 0; i < num_addressable_devices; ++i) {\n+        const int replica = addressable_device_logical_ids_[i].replica;\n+        const int partition = addressable_device_logical_ids_[i].partition;\n+        PjRtDevice* device = addressable_devices_[i];\n+        LaunchOnDevice(device, [&, replica, partition, i, context_id] {\n+          tsl::profiler::TraceMeConsumer consumer(\n+              \"Scheduled CommonPjRtLoadedExecutable::Execute\",\n+              tsl::profiler::ContextType::kPjRt, context_id);\n+\n+          // Two phase launch. Phase 1: Prepare on all cores. Abort\n+          // launch on prepare failure.\n+          std::optional<ExecuteLaunchArgs> launch_args;\n+          absl::Status launch_status = ExecutePrepareWithOomRetries(\n+              launch_args, argument_handles[i], replica, partition, options,\n+              /*host_callback_idx=*/i);\n+          // Wait for prepare to finish on all cores.\n+          {\n+            absl::MutexLock lock(mu);\n+            preparing--;\n+            auto done_preparing = [&]() ABSL_EXCLUSIVE_LOCKS_REQUIRED(mu) {\n+              return preparing == 0;\n+            };\n+            mu.Await(absl::Condition(&done_preparing));\n+            if (!launch_status.ok()) {\n+              if (failed == 0) {\n+                first_failure_status = launch_status;\n+              }\n+              failed++;\n+            }\n+            if (failed > 0) {\n+              // Poison results for all cores.\n+              results[i] = first_failure_status;\n+              // Abort phase 2 if Prepare fails for any core.\n+              --launching;\n+              return;\n+            }\n+          }\n+\n+          // Phase 2: Launch. It cannot fail.\n+          results[i] =\n+              ExecuteLaunch(*launch_args, returned_futures.has_value());\n+\n+          absl::MutexLock lock(mu);\n+          --launching;\n+        });\n+      }\n+    }\n+\n+    // Wait until we either fail Phase 1 or completes two phases.\n+    auto done = [&]() ABSL_EXCLUSIVE_LOCKS_REQUIRED(mu) {\n+      return launching == 0;\n+    };\n+    absl::MutexLock lock(mu);\n+    mu.Await(absl::Condition(&done));\n+  }\n+  VLOG(3) << \"Replicated execution complete.\";\n+\n+  std::vector<std::vector<std::unique_ptr<PjRtBuffer>>> wrapped_results(\n+      num_addressable_devices);\n+  if (returned_futures.has_value()) {\n+    returned_futures->reserve(num_addressable_devices);\n+  }\n+  for (int i = 0; i < num_addressable_devices; ++i) {\n+    const int replica = addressable_device_logical_ids_[i].replica;\n+    const int partition = addressable_device_logical_ids_[i].partition;\n+    auto& statusor = results[i];\n+    if (!statusor.ok()) {\n+      if (absl::IsResourceExhausted(statusor.status())) {\n+        client()->CallOomHandlers();\n+      }\n+      if (returned_futures.has_value()) {\n+        returned_futures->clear();\n+      }\n+      if (num_addressable_devices == 1) {\n+        return statusor.status();\n+      }\n+      return AppendStatus(\n+          statusor.status(),\n+          absl::StrFormat(\"while running replica %d and partition %d of a \"\n+                          \"replicated computation (other \"\n+                          \"replicas may have failed as well).\",\n+                          replica, partition));\n+    }\n+    wrapped_results[i] = std::move(statusor->buffers);\n+    if (returned_futures.has_value()) {\n+      returned_futures->push_back(*std::move(statusor->future));\n+    }\n+  }\n+  return wrapped_results;\n+}\n+\n absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n CommonPjRtBufferImpl::CopyToCpuMemorySpace(const xla::Shape& dst_shape,\n                                            PjRtMemorySpace* dst_memory_space) {"
        },
        {
            "sha": "27084fbc94e1b6813fa034eccbf495fa9a8c8dd7",
            "filename": "third_party/xla/xla/pjrt/common_pjrt_client.h",
            "status": "modified",
            "additions": 64,
            "deletions": 6,
            "changes": 70,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/26ebc05f4f9498c99400a6c8e88378ef689255d4/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/26ebc05f4f9498c99400a6c8e88378ef689255d4/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h?ref=26ebc05f4f9498c99400a6c8e88378ef689255d4",
            "patch": "@@ -62,6 +62,9 @@ class CommonPjRtClient : public PjRtClient {\n   // callbacks. Those clients should return false here.\n   virtual bool allows_recursion() const { return true; }\n \n+  // Backend specific handlers for when an oom is detected during execute.\n+  virtual void CallOomHandlers() const {}\n+\n   // Computes the memory requirements for storing shape on memory_space.\n   // TODO(parkers): make pure virtual and update all clients.\n   virtual absl::StatusOr<int64_t> GetOnDeviceBytesCount(\n@@ -266,6 +269,11 @@ class CommonPjRtClient : public PjRtClient {\n       absl::InlinedVector<tsl::RCReference<CommonPjRtRawBuffer>, 4>\n           output_leaf_buffers,\n       bool is_predetermined_error);\n+\n+  absl::Mutex& gang_scheduler() const { return gang_scheduler_mu_; }\n+\n+ private:\n+  mutable absl::Mutex gang_scheduler_mu_;\n };\n \n // Represents the launch state for a loaded executable. This state must be\n@@ -293,22 +301,45 @@ class PjRtRawLoadedExecutable {\n \n class CommonPjRtLoadedExecutable : public PjRtLoadedExecutable {\n  public:\n-  CommonPjRtLoadedExecutable(CommonPjRtClient* client,\n-                             std::vector<Shape> parameter_device_shapes,\n-                             Shape output_device_shape,\n-                             std::vector<int> output_memory_space_kind_ids,\n-                             std::vector<PjRtDevice*> addressable_devices)\n+  CommonPjRtLoadedExecutable(\n+      CommonPjRtClient* client, std::vector<Shape> parameter_device_shapes,\n+      Shape output_device_shape, std::vector<int> output_memory_space_kind_ids,\n+      std::vector<PjRtDevice*> addressable_devices,\n+      std::vector<LogicalDeviceIds> addressable_device_logical_ids)\n       : parameter_device_shapes_(std::move(parameter_device_shapes)),\n         output_device_shape_(std::move(output_device_shape)),\n         output_memory_space_kind_ids_(std::move(output_memory_space_kind_ids)),\n-        addressable_devices_(std::move(addressable_devices)) {}\n+        addressable_devices_(std::move(addressable_devices)),\n+        addressable_device_logical_ids_(\n+            std::move(addressable_device_logical_ids)) {}\n \n   CommonPjRtClient* client() const override = 0;\n \n   absl::Span<PjRtDevice* const> addressable_devices() const override {\n     return addressable_devices_;\n   }\n \n+  using PjRtLoadedExecutable::Execute;\n+  absl::StatusOr<std::vector<std::vector<std::unique_ptr<PjRtBuffer>>>> Execute(\n+      absl::Span<const std::vector<PjRtBuffer*>> argument_handles,\n+      const ExecuteOptions& options,\n+      std::optional<std::vector<tsl::Future<void>>>& returned_futures)\n+      const override;\n+\n+  using PjRtLoadedExecutable::ExecuteSharded;\n+  absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>> ExecuteSharded(\n+      absl::Span<PjRtBuffer* const> argument_handles, PjRtDevice* device,\n+      const ExecuteOptions& options,\n+      std::optional<tsl::Future<void>>& returned_future,\n+      bool fill_future) const override;\n+\n+  using PjRtLoadedExecutable::ExecutePortable;\n+  absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>> ExecutePortable(\n+      absl::Span<PjRtBuffer* const> argument_handles, PjRtDevice* device,\n+      const ExecuteOptions& options,\n+      std::optional<tsl::Future<void>>& returned_future,\n+      bool fill_future) const override;\n+\n  protected:\n   // Execute is split into Prepare and Launch.\n   // Prepare can fail and be retried, while Launch is guaranteed to succeed.\n@@ -350,6 +381,26 @@ class CommonPjRtLoadedExecutable : public PjRtLoadedExecutable {\n                               size_t host_callback_idx,\n                               PjRtDevice* device) const;\n \n+  // Run Prepare and Launch phases on a single device.\n+  absl::StatusOr<Result> ExecuteHelperOnSingleDevice(\n+      absl::Span<PjRtBuffer* const> argument_handles, int replica,\n+      int partition, const ExecuteOptions& options, bool fill_future,\n+      PjRtDevice* device = nullptr) const;\n+\n+  absl::Status ExecutePrepareWithOomRetries(\n+      std::optional<ExecuteLaunchArgs>& launch_args,\n+      absl::Span<PjRtBuffer* const> argument_handles, int replica,\n+      int partition, const ExecuteOptions& options, size_t host_callback_idx,\n+      PjRtDevice* device = nullptr) const;\n+\n+  virtual void LaunchOnDevice(PjRtDevice* device,\n+                              absl::AnyInvocable<void()> execute_fn) const = 0;\n+\n+  virtual bool ShouldRetryOnOom(int attempts, PjRtDevice* device,\n+                                absl::Status perpare_status) const {\n+    return false;\n+  }\n+\n   Result ExecuteLaunch(ExecuteLaunchArgs& launch_args, bool fill_future) const;\n \n   // Parameter shapes.\n@@ -368,6 +419,13 @@ class CommonPjRtLoadedExecutable : public PjRtLoadedExecutable {\n   // addressable_device_logical_ids_[i] is assigned. shared_ptrs instead of\n   // unique_ptrs to play well with the Python bindings (see xla.cc).\n   std::vector<PjRtDevice*> addressable_devices_;\n+  // The replica and partition indices of device_assignment_ to be run by this\n+  // client. On single-host platforms without partitioning, this is all\n+  // replicas (i.e. addressable_device_logical_ids_[i] = (i, 0)), but this may\n+  // not be the case on multi-host platforms. If there are 4 replicas and 2\n+  // partitions on a single host platform, size of\n+  // addressable_device_logical_ids_ is 4*2 = 8.\n+  std::vector<LogicalDeviceIds> addressable_device_logical_ids_;\n };\n \n // TODO(parkers): Merge everything here into CommonPjRtBuffer."
        }
    ],
    "stats": {
        "total": 328,
        "additions": 322,
        "deletions": 6
    }
}