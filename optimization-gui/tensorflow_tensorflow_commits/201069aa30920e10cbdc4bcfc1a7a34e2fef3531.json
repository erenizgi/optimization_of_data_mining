{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 850241315",
    "sha": "201069aa30920e10cbdc4bcfc1a7a34e2fef3531",
    "files": [
        {
            "sha": "f9d31a9233a3d4eeb5cfcc2b7d24485344d9a590",
            "filename": "tensorflow/core/nccl/nccl_manager.h",
            "status": "modified",
            "additions": 13,
            "deletions": 12,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/201069aa30920e10cbdc4bcfc1a7a34e2fef3531/tensorflow%2Fcore%2Fnccl%2Fnccl_manager.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/201069aa30920e10cbdc4bcfc1a7a34e2fef3531/tensorflow%2Fcore%2Fnccl%2Fnccl_manager.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fnccl%2Fnccl_manager.h?ref=201069aa30920e10cbdc4bcfc1a7a34e2fef3531",
            "patch": "@@ -53,7 +53,7 @@ namespace tensorflow {\n // management and stream synchronization.\n class NcclManager {\n  public:\n-  typedef std::function<void(Status)> DoneCallback;\n+  typedef std::function<void(absl::Status)> DoneCallback;\n   NcclManager();\n   ~NcclManager();\n \n@@ -66,7 +66,7 @@ class NcclManager {\n   // Calls `ncclGetUniqueId` and returns the id as a string.  The returned value\n   // may be shared with other participants on different nodes and passed in to\n   // multi-node collective invocations.\n-  string GenerateCommunicatorKey();\n+  std::string GenerateCommunicatorKey();\n \n   // A participant in a Collective.\n   struct Participant {\n@@ -137,8 +137,8 @@ class NcclManager {\n   // Data that provides context for the collective operation, including the\n   // operation key, number of participants, and communicator key.\n   struct Context {\n-    Context(const string& collective_key, int num_local_devices,\n-            int num_global_devices, const string& communicator_key,\n+    Context(const std::string& collective_key, int num_local_devices,\n+            int num_global_devices, const std::string& communicator_key,\n             int source_rank)\n         : collective_key(collective_key),\n           num_local_devices(num_local_devices),\n@@ -147,7 +147,7 @@ class NcclManager {\n           source_rank(source_rank) {}\n \n     // Unique key for this collective instance\n-    const string& collective_key;\n+    const std::string& collective_key;\n \n     // Devices local to this node\n     int num_local_devices;\n@@ -161,7 +161,7 @@ class NcclManager {\n     // `communicator_key` to the `NcclManager` functions.\n     // `communicator_key` is not required for single-node collectives and can be\n     // empty.\n-    const string& communicator_key;\n+    const std::string& communicator_key;\n \n     // Rank of broadcast source.\n     int source_rank;\n@@ -203,11 +203,11 @@ class NcclManager {\n   // This should only be called for multi-node collectives; single-node\n   // collectives are implicitly ready when all participants have called Add*\n   // function.\n-  void SignalMultiNodeReady(const string& collective_key);\n+  void SignalMultiNodeReady(const std::string& collective_key);\n \n   // Aborts all collectives. After abortion, no further collectives can be\n   // launched with this NcclManager.\n-  void StartAbort(const Status& s);\n+  void StartAbort(const absl::Status& s);\n \n   // Resets a previously aborted NcclManager, making it available for future\n   // collectives.\n@@ -233,7 +233,8 @@ class NcclManager {\n   // This may involve creating CUDA streams and NCCL initialization.  If a NCCL\n   // or CUDA error occurs in the process, this returns an INTERNAL error with\n   // the corresponding NCCL/CUDA error string.\n-  Status GetCommunicator(Collective* collective, Communicator** communicator);\n+  absl::Status GetCommunicator(Collective* collective,\n+                               Communicator** communicator);\n \n   // Adds a participant device to the local `Collective` instance corresponding\n   // to `collective_key`.  Launches the `Collective` if it is ready, which it\n@@ -250,7 +251,7 @@ class NcclManager {\n   // A collective is ready to run when all local participants have called Add*\n   // function, and the collective is signalled globally ready via\n   // `SetMultiNodeReady`.\n-  bool CheckReady(const string& collective_key, Collective* collective)\n+  bool CheckReady(const std::string& collective_key, Collective* collective)\n       TF_EXCLUSIVE_LOCKS_REQUIRED(mu_);\n \n   // Run <collective>.  This calls takes ownership of <collective>.\n@@ -260,7 +261,7 @@ class NcclManager {\n   mutex mu_;\n \n   // Maps key to collectives currently being assembled or run.\n-  absl::flat_hash_map<string, Collective*> collectives_ TF_GUARDED_BY(mu_);\n+  absl::flat_hash_map<std::string, Collective*> collectives_ TF_GUARDED_BY(mu_);\n \n   // Maps a device to the communication streams that make up its collective.\n   // This is used to share the stream across different communicators that\n@@ -270,7 +271,7 @@ class NcclManager {\n \n   std::vector<std::unique_ptr<Communicator>> communicators_ TF_GUARDED_BY(mu_);\n \n-  Status status_ TF_GUARDED_BY(mu_);\n+  absl::Status status_ TF_GUARDED_BY(mu_);\n \n   NcclManager(const NcclManager&) = delete;\n   void operator=(const NcclManager&) = delete;"
        },
        {
            "sha": "1078c74b24521f1176c4e8a7840a78ec12517528",
            "filename": "tensorflow/core/nccl/nccl_manager_test.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 13,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/201069aa30920e10cbdc4bcfc1a7a34e2fef3531/tensorflow%2Fcore%2Fnccl%2Fnccl_manager_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/201069aa30920e10cbdc4bcfc1a7a34e2fef3531/tensorflow%2Fcore%2Fnccl%2Fnccl_manager_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fnccl%2Fnccl_manager_test.cc?ref=201069aa30920e10cbdc4bcfc1a7a34e2fef3531",
            "patch": "@@ -60,7 +60,7 @@ class NcclManagerTest : public ::testing::Test {\n     const int num_ranks_per_node;\n \n     mutex mu;\n-    Status final_status;\n+    absl::Status final_status;\n     int num_completed TF_GUARDED_BY(mu) = 0;\n     condition_variable done_cv;\n   };\n@@ -81,7 +81,7 @@ class NcclManagerTest : public ::testing::Test {\n     ASSERT_NE(work_queue_, nullptr);\n   }\n \n-  static int32 NumGPUs() { return static_cast<int32>(devices_->size()); }\n+  static int32_t NumGPUs() { return static_cast<int32_t>(devices_->size()); }\n \n   // Let N = #GPUs.  When N is even, num_nodes=2 and num_ranks_per_node=N/2.\n   // When N is odd, num_nodes=2 and num_ranks_per_node=(N-1)/2.\n@@ -285,7 +285,7 @@ class NcclManagerTest : public ::testing::Test {\n   }\n \n   NcclManager::DoneCallback CreateDoneCallback(TestCase* test_case) {\n-    return [this, test_case](Status s) {\n+    return [this, test_case](absl::Status s) {\n       mutex_lock l(test_case->mu);\n       test_case->final_status.Update(s);\n       if (++test_case->num_completed == test_case->outs.size()) {\n@@ -309,14 +309,14 @@ class NcclManagerTest : public ::testing::Test {\n                                  const int num_ranks_per_node) {\n     const int num_nodes = node_states.size();\n     const int num_global_ranks = num_nodes * num_ranks_per_node;\n-    const string collective_key = \"allreduce\";\n+    const std::string collective_key = \"allreduce\";\n     // The NcclManagers in this test synchronize in real-time, so we need to run\n     // each node's code in a separate thread.\n     // Specifically, the call to ncclGroupEnd() after calling ncclCommInitRank\n     // waits for all communicators before returning.\n \n     // First, initialize the communicator_key used for this collective.\n-    const string communicator_key =\n+    const std::string communicator_key =\n         node_states[0].nccl_manager.GenerateCommunicatorKey();\n \n     for (int op = 0; op < 4; ++op) {\n@@ -365,9 +365,9 @@ class NcclManagerTest : public ::testing::Test {\n                                  const bool in_place) {\n     const int num_global_ranks = num_nodes * num_ranks_per_node;\n     const int src_global_rank = src_node * num_ranks_per_node + src_local_rank;\n-    const string collective_key = \"broadcast\";\n+    const std::string collective_key = \"broadcast\";\n     std::vector<NodeState> node_states(num_nodes);\n-    const string communicator_key =\n+    const std::string communicator_key =\n         node_states[0].nccl_manager.GenerateCommunicatorKey();\n     std::unique_ptr<TestCase> test_case(this->MakeBroadcastTestCase(\n         num_nodes, num_ranks_per_node, TensorShape({5, 6}), src_node,\n@@ -437,7 +437,8 @@ class NcclManagerTest : public ::testing::Test {\n   }\n \n   static se::DeviceMemory<Scalar> AsDeviceMemory(const Scalar* cuda_memory) {\n-    se::DeviceMemoryBase wrapped(const_cast<Scalar*>(cuda_memory));\n+    stream_executor::DeviceAddressBase wrapped(\n+        const_cast<Scalar*>(cuda_memory));\n     se::DeviceMemory<Scalar> typed(wrapped);\n     return typed;\n   }\n@@ -550,7 +551,7 @@ TYPED_TEST(NcclManagerTest, MultipleCallers) {\n             this->CreateDoneCallback(test_case));\n         NcclManager::instance()->AddToAllReduce(\n             std::move(participant),\n-            {strings::StrCat(\"allreduce\", test_num),\n+            {absl::StrCat(\"allreduce\", test_num),\n              /*num_local_devices=*/num_ranks,\n              /*num_global_devices=*/num_ranks,\n              /*communicator_key=*/\"\", /*source_rank=*/-1},\n@@ -633,7 +634,7 @@ TYPED_TEST(NcclManagerTest, BroadcastWithDifferentRanks) {\n // Multi-node NCCL tests.\n \n TEST(NcclManagerTest, CommunicatorKey) {\n-  const string communicator_key =\n+  const std::string communicator_key =\n       NcclManager::instance()->GenerateCommunicatorKey();\n   EXPECT_EQ(communicator_key.size(), NCCL_UNIQUE_ID_BYTES);\n }\n@@ -871,10 +872,10 @@ TYPED_TEST(NcclManagerTest, AbortThenReset) {\n   // multiple communicators.\n   this->RunMultiNodeAllReduceTest(nodes, /* num_ranks_per_node */ 1);\n \n-  const string collective_key = \"allreduce\";\n+  const std::string collective_key = \"allreduce\";\n   ncclRedOp_t reduction_op = static_cast<ncclRedOp_t>(0);\n   auto node_fn = [&](TestCase* test_case, int node,\n-                     const string& communicator_key) {\n+                     const std::string& communicator_key) {\n     auto* device = this->GetDevice(/* num_ranks_per_node */ 1, node,\n                                    /* local_rank */ 0);\n     auto* info = device->tensorflow_accelerator_device_info();\n@@ -893,7 +894,8 @@ TYPED_TEST(NcclManagerTest, AbortThenReset) {\n   };\n \n   // Use a new communicator_key, which uses a new set of ncclComm underneath.\n-  string communicator_key = nodes[0].nccl_manager.GenerateCommunicatorKey();\n+  std::string communicator_key =\n+      nodes[0].nccl_manager.GenerateCommunicatorKey();\n   // Do a normal all-reduce with this communicator key to initialize ncclComm.\n   // This is because ncclCommInitRank waits for all ranks and is blocking.\n   {"
        },
        {
            "sha": "292a954b48f4aa35acba87eb86815e1a09c09cba",
            "filename": "tensorflow/core/nccl/nccl_rewrite.cc",
            "status": "modified",
            "additions": 23,
            "deletions": 24,
            "changes": 47,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/201069aa30920e10cbdc4bcfc1a7a34e2fef3531/tensorflow%2Fcore%2Fnccl%2Fnccl_rewrite.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/201069aa30920e10cbdc4bcfc1a7a34e2fef3531/tensorflow%2Fcore%2Fnccl%2Fnccl_rewrite.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fnccl%2Fnccl_rewrite.cc?ref=201069aa30920e10cbdc4bcfc1a7a34e2fef3531",
            "patch": "@@ -28,15 +28,15 @@ namespace {\n \n // Replaces NcclReduce node with _NcclReduceRecv reusing one input of same\n // device, adds one _NcclReduceSend for each other input.\n-Status ReplaceReduce(Graph* graph, Node* node) {\n-  string reduction;\n+absl::Status ReplaceReduce(Graph* graph, Node* node) {\n+  std::string reduction;\n   TF_RETURN_IF_ERROR(GetNodeAttr(node->attrs(), \"reduction\", &reduction));\n   DataType dtype;\n   TF_RETURN_IF_ERROR(GetNodeAttr(node->attrs(), \"T\", &dtype));\n   int num_devices = node->num_inputs();\n-  string shared_name = node->name();\n-  auto make_builder = [&](StringPiece op_name, StringPiece suffix) {\n-    return NodeBuilder(strings::StrCat(shared_name, suffix), op_name)\n+  std::string shared_name = node->name();\n+  auto make_builder = [&](absl::string_view op_name, absl::string_view suffix) {\n+    return NodeBuilder(absl::StrCat(shared_name, suffix), op_name)\n         .Attr(\"reduction\", reduction)\n         .Attr(\"num_devices\", num_devices)\n         .Attr(\"shared_name\", shared_name)\n@@ -68,10 +68,10 @@ Status ReplaceReduce(Graph* graph, Node* node) {\n       recv_input_set = true;\n       continue;\n     }\n-    auto send_builder = make_builder(\"_NcclReduceSend\",\n-                                     strings::StrCat(\"Send_\", ++send_counter))\n-                            .Input(src_node)\n-                            .ControlInputs(control_inputs);\n+    auto send_builder =\n+        make_builder(\"_NcclReduceSend\", absl::StrCat(\"Send_\", ++send_counter))\n+            .Input(src_node)\n+            .ControlInputs(control_inputs);\n     Node* send_node = nullptr;\n     TF_RETURN_IF_ERROR(send_builder.Finalize(graph, &send_node));\n     send_node->set_assigned_device_name_index(send_dev);\n@@ -98,7 +98,7 @@ Status ReplaceReduce(Graph* graph, Node* node) {\n       graph->AddEdge(recv_node, 0, out_node.node, out_node.index);\n     }\n   }\n-  return OkStatus();\n+  return absl::OkStatus();\n }\n \n TensorProto TensorFromShape(const TensorShapeProto& shape) {\n@@ -114,7 +114,7 @@ TensorProto TensorFromShape(const TensorShapeProto& shape) {\n // Replaces NcclBroadcast node with _NcclBroadcastSend, connects the input to\n // all outputs of same device, adds one _NcclBroadcastRecv for each other output\n // device.\n-Status ReplaceBroadcast(Graph* graph, Node* node) {\n+absl::Status ReplaceBroadcast(Graph* graph, Node* node) {\n   DataType dtype;\n   TF_RETURN_IF_ERROR(GetNodeAttr(node->attrs(), \"T\", &dtype));\n   int send_dev = node->assigned_device_name_index();\n@@ -155,12 +155,12 @@ Status ReplaceBroadcast(Graph* graph, Node* node) {\n         }\n       }\n     }\n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n \n-  string shared_name = node->name();\n-  auto make_builder = [&](StringPiece op_name, StringPiece suffix) {\n-    return NodeBuilder(strings::StrCat(shared_name, suffix), op_name)\n+  std::string shared_name = node->name();\n+  auto make_builder = [&](absl::string_view op_name, absl::string_view suffix) {\n+    return NodeBuilder(absl::StrCat(shared_name, suffix), op_name)\n         .Attr(\"num_devices\", num_devices)\n         .Attr(\"shared_name\", shared_name)\n         .Attr(\"T\", dtype);\n@@ -202,7 +202,7 @@ Status ReplaceBroadcast(Graph* graph, Node* node) {\n \n   TensorProto tensor_proto = TensorFromShape(shape_proto);\n   bool is_fully_defined = TensorShape(shape_proto).IsFullyDefined();\n-  string shape_name = strings::StrCat(in_node.node->name(), \"/Shape\");\n+  std::string shape_name = absl::StrCat(in_node.node->name(), \"/Shape\");\n   Node* shape_node = nullptr;\n   if (!is_fully_defined) {\n     NodeBuilder shape_builder(shape_name, \"Shape\");\n@@ -219,15 +219,14 @@ Status ReplaceBroadcast(Graph* graph, Node* node) {\n     int recv_index = recv_index_map[recv_dev];\n     if (is_fully_defined) {\n       // If the shape is fully defined, define one const node per device.\n-      NodeBuilder shape_builder(strings::StrCat(shape_name, recv_index),\n-                                \"Const\");\n+      NodeBuilder shape_builder(absl::StrCat(shape_name, recv_index), \"Const\");\n       shape_builder.Attr(\"value\", tensor_proto).Attr(\"dtype\", DT_INT32);\n       TF_RETURN_IF_ERROR(shape_builder.Finalize(graph, &shape_node));\n       shape_node->set_assigned_device_name_index(recv_dev);\n     }\n     Node* recv_node;\n     TF_RETURN_IF_ERROR(\n-        make_builder(\"_NcclBroadcastRecv\", strings::StrCat(\"Recv_\", recv_index))\n+        make_builder(\"_NcclBroadcastRecv\", absl::StrCat(\"Recv_\", recv_index))\n             .Input(shape_node)\n             .Finalize(graph, &recv_node));\n     recv_node->set_assigned_device_name_index(recv_dev);\n@@ -236,16 +235,16 @@ Status ReplaceBroadcast(Graph* graph, Node* node) {\n     }\n   }\n \n-  return OkStatus();\n+  return absl::OkStatus();\n }\n \n // Replaces occurrences of Nccl{Reduce, Broadcast}Input/Output with their\n // _Nccl...Send/Recv counterparts and removes data dependencies between them.\n class NcclReplacePass : public GraphOptimizationPass {\n  public:\n-  Status Run(const GraphOptimizationPassOptions& options) override {\n+  absl::Status Run(const GraphOptimizationPassOptions& options) override {\n     if (options.graph == nullptr) {\n-      return OkStatus();\n+      return absl::OkStatus();\n     }\n     Graph* graph = options.graph->get();\n     if (graph == nullptr) {\n@@ -255,7 +254,7 @@ class NcclReplacePass : public GraphOptimizationPass {\n     }\n     // Find reduction and broadcast ops and replace them with Send/Recv ops.\n     for (Node* node : graph->op_nodes()) {\n-      StringPiece type = node->type_string();\n+      absl::string_view type = node->type_string();\n       if (!absl::StartsWith(type, \"Nccl\")) {\n         continue;\n       }\n@@ -266,7 +265,7 @@ class NcclReplacePass : public GraphOptimizationPass {\n         TF_RETURN_IF_ERROR(ReplaceBroadcast(graph, node));\n       }\n     }\n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n };\n REGISTER_OPTIMIZATION(OptimizationPassRegistry::POST_PLACEMENT, 0,"
        }
    ],
    "stats": {
        "total": 100,
        "additions": 51,
        "deletions": 49
    }
}