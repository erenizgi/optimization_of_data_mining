{
    "author": "tensorflower-gardener",
    "message": "Reverts 78fe7e96e512ee95ef71699f596f8e62a4c420eb\n\nPiperOrigin-RevId: 797729707",
    "sha": "2816b067b5471ba5bf6de7154b9ff11e1865db02",
    "files": [
        {
            "sha": "0fb880296f35027abd6f2230c01246b1b60e9599",
            "filename": "third_party/xla/xla/service/spmd/spmd_partitioner.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 45,
            "changes": 74,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2816b067b5471ba5bf6de7154b9ff11e1865db02/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2816b067b5471ba5bf6de7154b9ff11e1865db02/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc?ref=2816b067b5471ba5bf6de7154b9ff11e1865db02",
            "patch": "@@ -2545,20 +2545,24 @@ std::vector<ReplicaGroup> SpmdPartitioningVisitor::CreateReplicaGroups(\n \n absl::Status SpmdPartitioningVisitor::HandleCall(HloInstruction* hlo) {\n   std::vector<HloInstruction*> call_args;\n-  call_args.reserve(hlo->operand_count());\n+  HloComputation* computation = hlo->called_computations()[0];\n   for (int64_t i = 0; i < hlo->operand_count(); ++i) {\n+    // Shardings of the computation parameter and its argument must be\n+    // the same.\n+    computation->parameter_instruction(i)->set_sharding(\n+        hlo->operand(i)->sharding());\n     call_args.push_back(GetPartitionedHlo(hlo->operand(i)).hlo());\n   }\n \n-  TF_RETURN_IF_ERROR(\n-      partitioner_\n-          ->PartitionComputation(hlo->to_apply(), hlo->sharding(),\n-                                 next_channel_id_, logger_, call_graph_)\n-          .status());\n+  TF_RETURN_IF_ERROR(partitioner_\n+                         ->PartitionComputation(computation, hlo->sharding(),\n+                                                next_channel_id_, logger_,\n+                                                call_graph_)\n+                         .status());\n   SetPartitionedHlo(hlo, [&] {\n     auto* call = b_.AddInstruction(HloInstruction::CreateCall(\n         MakePartitionedShape(hlo->shape(), hlo->sharding()), call_args,\n-        hlo->to_apply()));\n+        hlo->called_computations()[0]));\n     call->set_raw_backend_config_string(hlo->raw_backend_config_string());\n     return call;\n   });\n@@ -4276,8 +4280,18 @@ absl::Status SpmdPartitioningVisitor::HandleReverse(HloInstruction* hlo) {\n \n absl::Status SpmdPartitioningVisitor::HandleWhile(HloInstruction* hlo) {\n   const HloSharding& sharding = hlo->sharding();\n+\n+  // Shardings for the body parameter, body root, and cond parameter must be\n+  // the same.\n+  hlo->while_condition()->parameter_instruction(0)->set_sharding(sharding);\n+  hlo->while_body()->parameter_instruction(0)->set_sharding(sharding);\n+\n+  // The condition root must be replicated so that all partitions follow the\n+  // same control flow.\n   HloInstruction* cond_root = hlo->while_condition()->root_instruction();\n-  const HloSharding cond_root_sharding = cond_root->sharding();\n+  const HloSharding cond_root_sharding =\n+      hlo_sharding_util::ReplicateAllDataDims(cond_root->sharding());\n+  cond_root->set_sharding(cond_root_sharding);\n   TF_RETURN_IF_ERROR(\n       partitioner_\n           ->PartitionComputation(hlo->while_condition(), cond_root_sharding,\n@@ -4301,6 +4315,12 @@ absl::Status SpmdPartitioningVisitor::HandleWhile(HloInstruction* hlo) {\n absl::Status SpmdPartitioningVisitor::HandleConditional(HloInstruction* hlo) {\n   std::vector<HloInstruction*> branch_args;\n   for (int64_t i = 0; i < hlo->branch_count(); ++i) {\n+    HloComputation* computation = hlo->branch_computation(i);\n+\n+    // Shardings of the branch computation parameter and its argument must be\n+    // the same.\n+    computation->parameter_instruction(0)->set_sharding(\n+        hlo->operand(i + 1)->sharding());\n     branch_args.push_back(GetPartitionedHlo(hlo->operand(i + 1)).hlo());\n   }\n \n@@ -4907,7 +4927,7 @@ absl::StatusOr<bool> SpmdPartitioningVisitor::DoPartition(\n     const SpmdPartitionerOptions& options) {\n   VLOG(2) << \"Partitioning computation \" << computation->name() << \" for \"\n           << num_replicas_ << \" replicas and \" << num_partitions_\n-          << \" partitions\" << \" with root sharding \" << root_sharding;\n+          << \" partitions\";\n   TF_RETURN_IF_ERROR(computation->Accept(this));\n \n   HloModule* module = computation->parent();\n@@ -5634,42 +5654,6 @@ absl::Status SpmdPartitioner::PreprocessSharding(\n               HloSharding::Single(hlo->shape(), HloSharding::Replicate()));\n         }\n       }\n-\n-      // For control-flow constructs, we must make sure that the inputs and\n-      // outputs of the called computation have the same sharding as the\n-      // arguments being passed in.\n-      switch (hlo->opcode()) {\n-        case HloOpcode::kWhile: {\n-          hlo->while_condition()->parameter_instruction(0)->set_sharding(\n-              hlo->sharding());\n-          hlo->while_body()->parameter_instruction(0)->set_sharding(\n-              hlo->sharding());\n-          // The condition root must be replicated so that all partitions follow\n-          // the same control flow.\n-          HloInstruction* cond_root =\n-              hlo->while_condition()->root_instruction();\n-          const HloSharding cond_root_sharding =\n-              hlo_sharding_util::ReplicateAllDataDims(cond_root->sharding());\n-          cond_root->set_sharding(cond_root_sharding);\n-          break;\n-        }\n-        case HloOpcode::kConditional: {\n-          for (int64_t i = 0; i < hlo->branch_count(); ++i) {\n-            hlo->branch_computation(i)->parameter_instruction(0)->set_sharding(\n-                hlo->operand(i + 1)->sharding());\n-          }\n-          break;\n-        }\n-        case HloOpcode::kCall: {\n-          for (int64_t i = 0; i < hlo->operand_count(); ++i) {\n-            hlo->to_apply()->parameter_instruction(i)->set_sharding(\n-                hlo->operand(i)->sharding());\n-          }\n-          break;\n-        }\n-        default:\n-          break;\n-      }\n     }\n   }\n "
        }
    ],
    "stats": {
        "total": 74,
        "additions": 29,
        "deletions": 45
    }
}