{
    "author": "EusebioDM",
    "message": "Merge the `CompilationResultProto` and `GpuExecutableProto` protos\n\nBoth of these currently represent a compiled `GpuExecutable`, and need to be serialized and deserealized in the same path, so having a single protos makes this easier and cleaner.\n\nFrom the `CompilationResultProto`'s perpective nothing is changing except the generated class names, since the fields and types are identical. This means there's no actual behavior change in the paths using the `CompilationResultProto` (i.e. the legacy AOT compilation).\n\nThe current (before this CL) `GpuExecutableProto` isn't actually being used anywhere so its safe for us to change the definition around.\n\nAlso renamed the `executable.proto` file be more descriptive of what it actually contains.\n\nPiperOrigin-RevId: 832205012",
    "sha": "05d2b10d3341a16669312f89b8a90003f8b9f68b",
    "files": [
        {
            "sha": "6fc389668f2b96ee306c70e87bdf915cee18f9a5",
            "filename": "third_party/xla/xla/pjrt/gpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -477,7 +477,6 @@ cc_library(\n         \"//xla/service:hlo_proto_cc\",\n         \"//xla/service:local_service_utils\",\n         \"//xla/service:platform_util\",\n-        \"//xla/service/gpu:executable_proto_cc\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:platform_manager\",\n         \"//xla/tsl/platform:errors\","
        },
        {
            "sha": "11bc1f865433d381fd314d30984aa3031966dac1",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_compiler.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_compiler.cc?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -40,7 +40,6 @@ limitations under the License.\n #include \"xla/pjrt/utils.h\"\n #include \"xla/service/compiler.h\"\n #include \"xla/service/dump.h\"\n-#include \"xla/service/gpu/executable.pb.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/service/hlo_module_util.h\""
        },
        {
            "sha": "ede1ffc6a4d6ab5bc67c74ed549bbda63aec6369",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -5740,7 +5740,6 @@ xla_cc_binary(\n     ] + if_cuda_or_rocm_is_configured([\n         # keep sorted\n         \":gpu_plugin\",\n-        \"//xla/service/gpu:executable_proto_cc\",\n         \"//xla/service/gpu:gpu_compiler\",\n         \"//xla/stream_executor/gpu:gpu_init\",\n     ]) + if_cuda_is_configured(["
        },
        {
            "sha": "e26876d5342af4138324f409bca27cfa0eaa0e99",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 9,
            "deletions": 15,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -123,7 +123,6 @@ cc_library(\n         \"@com_google_absl//absl/base:no_destructor\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/strings\",\n     ],\n )\n \n@@ -796,7 +795,6 @@ cc_library(\n         \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:status\",\n         \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/base:nullability\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n@@ -1181,7 +1179,6 @@ cc_library(\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/gpu:gpu_blas_lt\",\n-        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n@@ -1422,8 +1419,8 @@ cc_library(\n )\n \n tf_proto_library(\n-    name = \"executable_proto\",\n-    srcs = [\"executable.proto\"],\n+    name = \"kernel_reuse_cache_proto\",\n+    srcs = [\"kernel_reuse_cache.proto\"],\n     protodeps = [\n         \"//xla/service:hlo_proto\",\n         \"//xla:xla_proto\",\n@@ -1507,13 +1504,13 @@ cc_library(\n     tags = [\"gpu\"],\n     deps = [\n         \":alias_info\",\n-        \":executable_proto_cc\",\n         \":execution_stream_assignment\",\n         \":gpu_constants\",\n         \":gpu_executable\",\n         \":gpu_memory_space_assignment\",\n         \":ir_emitter_context\",\n         \":ir_emitter_unnested\",\n+        \":kernel_reuse_cache_proto_cc\",\n         \":metrics\",\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n@@ -1636,7 +1633,6 @@ cc_library(\n         \":compile_module_to_llvm_ir\",\n         \":conv_layout_normalization\",\n         \":cublas_cudnn\",\n-        \":executable_proto_cc\",\n         \":execution_stream_assignment\",\n         \":flag_utils\",\n         \":fusion_dispatch_pipeline\",\n@@ -2028,8 +2024,7 @@ cc_library(\n     # gpu_compiler.\n     visibility = [],\n     deps = [\n-        \":executable_proto_cc\",\n-        \":gpu_executable\",\n+        \":gpu_executable_proto_cc\",\n         \":gpu_latency_hiding_scheduler\",\n         \":ir_emission_utils\",\n         \"//xla:util\",\n@@ -2536,6 +2531,7 @@ cc_library(\n         \":backend_configs_cc\",\n         \":flag_utils\",\n         \":gpu_latency_hiding_scheduler\",\n+        \":hlo_fusion_analysis\",\n         \":ir_emission_utils\",\n         \"//xla:shape_util\",\n         \"//xla:util\",\n@@ -2551,7 +2547,6 @@ cc_library(\n         \"//xla/service:legalize_scheduling_annotations\",\n         \"//xla/service:p2p_schedule_preparation\",\n         \"//xla/service:profile_guided_latency_estimator\",\n-        \"//xla/service/gpu:hlo_fusion_analysis\",\n         \"//xla/service/gpu/model:analytical_latency_estimator\",\n         \"//xla/service/gpu/model:gpu_hlo_cost_analysis\",\n         \"//xla/service/gpu/model:sol_latency_estimator\",\n@@ -2922,7 +2917,6 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:side_effect_util\",\n         \"//xla:util\",\n-        \"//xla/codegen:ir_emission_utils\",\n         \"//xla/hlo/analysis:hlo_dataflow_analysis\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/ir:hlo_instruction_utils\",\n@@ -3071,7 +3065,6 @@ xla_cc_test(\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest_main\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n \n@@ -3186,7 +3179,8 @@ cc_library(\n     srcs = [\"kernel_reuse_cache.cc\"],\n     hdrs = [\"kernel_reuse_cache.h\"],\n     deps = [\n-        \":executable_proto_cc\",\n+        \":gpu_executable_proto_cc\",\n+        \":kernel_reuse_cache_proto_cc\",\n         \":launch_dimensions\",\n         \"//xla:status_macros\",\n         \"//xla:util\",\n@@ -3208,7 +3202,6 @@ xla_cc_test(\n     name = \"kernel_reuse_cache_test\",\n     srcs = [\"kernel_reuse_cache_test.cc\"],\n     deps = [\n-        \":executable_proto_cc\",\n         \":kernel_reuse_cache\",\n         \"//xla/tests:xla_internal_test_main\",\n         \"//xla/tsl/lib/core:status_test_util\",\n@@ -3468,7 +3461,6 @@ cc_library(\n     ]),\n     deps = [\n         \":intel_gpu_compiler_impl\",\n-        \"//xla/service:compiler\",\n         \"//xla/stream_executor/sycl:sycl_platform_id\",\n     ],\n     alwayslink = True,  # Contains compiler registration\n@@ -3494,8 +3486,10 @@ cc_library(\n     deps = [\n         \":gpu_compiler\",\n         \":target_constants\",\n+        \"//xla:debug_options_flags\",\n         \"//xla/hlo/analysis:hlo_dataflow_analysis\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:dump\",\n         \"//xla/service/gpu/llvm_gpu_backend:spirv_backend\",\n         \"//xla/stream_executor:semantic_version\",\n         \"//xla/stream_executor:stream_executor_h\","
        },
        {
            "sha": "5c7f2756f7f7e966f86ff68ba63b2b28b00a3a63",
            "filename": "third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.h?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -31,10 +31,10 @@ limitations under the License.\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/buffer_value.h\"\n #include \"xla/service/gpu/alias_info.h\"\n-#include \"xla/service/gpu/executable.pb.h\"\n #include \"xla/service/gpu/execution_stream_assignment.h\"\n #include \"xla/service/gpu/gpu_executable.h\"\n #include \"xla/service/gpu/ir_emitter_context.h\"\n+#include \"xla/service/gpu/kernel_reuse_cache.pb.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\""
        },
        {
            "sha": "ce72861d1adccac52a75674a16d13de1e4df8c2c",
            "filename": "third_party/xla/xla/service/gpu/gpu_aot_compilation_result.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result.h?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -43,9 +43,9 @@ class GpuAotCompilationResult : public AotCompilationResult {\n  public:\n   static absl::StatusOr<std::unique_ptr<GpuAotCompilationResult>> Create(\n       GpuExecutableProto executable) {\n-    TF_ASSIGN_OR_RETURN(\n-        std::unique_ptr<HloModule> module,\n-        HloModule::CreateFromProtoWithConfig(executable.hlo_module()));\n+    TF_ASSIGN_OR_RETURN(std::unique_ptr<HloModule> module,\n+                        HloModule::CreateFromProtoWithConfig(\n+                            executable.hlo_module_with_config()));\n \n     return absl::WrapUnique(\n         new GpuAotCompilationResult(std::move(executable), std::move(module)));"
        },
        {
            "sha": "1aa4c3ce29c884319ec85a0d78008d7d051400ad",
            "filename": "third_party/xla/xla/service/gpu/gpu_aot_compilation_result_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_aot_compilation_result_test.cc?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -155,8 +155,12 @@ TEST_F(GpuAotCompilationResultTest, LoadExecutable) {\n                           gpu_executable->ToProto());\n   // HLO module is re-created from proto, and will have a new ID, so we clear\n   // it for comparison purposes.\n-  executable_proto.mutable_hlo_module()->mutable_hlo_module()->clear_id();\n-  reference_executable.mutable_hlo_module()->mutable_hlo_module()->clear_id();\n+  executable_proto.mutable_hlo_module_with_config()\n+      ->mutable_hlo_module()\n+      ->clear_id();\n+  reference_executable.mutable_hlo_module_with_config()\n+      ->mutable_hlo_module()\n+      ->clear_id();\n   EXPECT_THAT(executable_proto, EqualsProto(reference_executable));\n }\n "
        },
        {
            "sha": "fd019a055f821a76d75422473994c46c8312b27e",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -167,7 +167,6 @@ limitations under the License.\n #include \"xla/service/gpu/compile_module_to_llvm_ir.h\"\n #include \"xla/service/gpu/conv_layout_normalization.h\"\n #include \"xla/service/gpu/cublas_cudnn.h\"\n-#include \"xla/service/gpu/executable.pb.h\"\n #include \"xla/service/gpu/execution_stream_assignment.h\"\n #include \"xla/service/gpu/flag_utils.h\"\n #include \"xla/service/gpu/fusion_dispatch_pipeline.h\"\n@@ -2967,8 +2966,7 @@ GpuCompiler::LoadExecutableFromAotResult(\n     return Internal(\n         \"AotCompilationResult is not a GpuThunkAotCompilationResult.\");\n   }\n-  const CompilationResultProto& proto =\n-      gpu_aot_result->GetCompilationResultProto();\n+  const GpuExecutableProto& proto = gpu_aot_result->GetGpuExecutableProto();\n \n   // Recreate HloModule+HloModuleConfig from proto.\n   TF_ASSIGN_OR_RETURN("
        },
        {
            "sha": "fb4d3cef622fb46cae3837a6f53069b5f6123e0c",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.h",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -37,7 +37,6 @@ limitations under the License.\n #include \"xla/service/gpu/alias_info.h\"\n #include \"xla/service/gpu/autotuning/autotuner_util.h\"\n #include \"xla/service/gpu/compile_module_to_llvm_ir.h\"\n-#include \"xla/service/gpu/executable.pb.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/service/hlo_cost_analysis.h\""
        },
        {
            "sha": "8f05f57635799394d01dbfb58cc1b942f8daa08e",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 7,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -1198,13 +1198,15 @@ absl::StatusOr<GpuExecutableProto> GpuExecutable::ToProto() const {\n   *proto.mutable_program_shape() = program_shape_.ToProto();\n \n   absl::Span<const BufferAllocation* const> allocations = GetAllocations();\n-  proto.mutable_buffer_allocations()->Reserve(allocations.size());\n+  proto.mutable_buffer_allocations()->mutable_values()->Reserve(\n+      allocations.size());\n   for (const auto& allocation : allocations) {\n-    proto.mutable_buffer_allocations()->Add(allocation->ToProto());\n+    proto.mutable_buffer_allocations()->mutable_values()->Add(\n+        allocation->ToProto());\n   }\n \n   if (hlo_module_ != nullptr) {\n-    *proto.mutable_hlo_module() = hlo_module_->ToProtoWithConfig();\n+    *proto.mutable_hlo_module_with_config() = hlo_module_->ToProtoWithConfig();\n   }\n \n   proto.mutable_output_info_map()->Reserve(output_info_.size());\n@@ -1232,16 +1234,16 @@ absl::StatusOr<std::unique_ptr<GpuExecutable>> GpuExecutable::FromProto(\n   const std::string& binary = proto.binary();\n   params.binary.assign(binary.begin(), binary.end());\n   params.buffer_assignment = nullptr;\n-  if (proto.has_hlo_module()) {\n+  if (proto.has_hlo_module_with_config()) {\n     TF_ASSIGN_OR_RETURN(\n         params.debug_module,\n-        HloModule::CreateFromProtoWithConfig(proto.hlo_module()));\n+        HloModule::CreateFromProtoWithConfig(proto.hlo_module_with_config()));\n   }\n \n   params.mlir_allocations.emplace();\n-  params.mlir_allocations->reserve(proto.buffer_allocations().size());\n+  params.mlir_allocations->reserve(proto.buffer_allocations().values_size());\n   for (const BufferAllocationProto& allocation_proto :\n-       proto.buffer_allocations()) {\n+       proto.buffer_allocations().values()) {\n     params.mlir_allocations->push_back(\n         BufferAllocation::FromProto(allocation_proto));\n   }"
        },
        {
            "sha": "8a898ce36c5ab6cb91307ae3402f92fc7a8e51c2",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.proto",
            "status": "modified",
            "additions": 33,
            "deletions": 17,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.proto?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -10,39 +10,55 @@ import \"xla/stream_executor/device_description.proto\";\n import \"xla/xla.proto\";\n import \"xla/xla_data.proto\";\n \n+// Serialized representation of a GPU executable, used for AOT compilation.\n+//\n+// There's a legacy and a new verions of this proto, see\n+// `xla::gpu::LegacyGpuAotCompilationResult` and\n+// `xla::gpu::GpuAotCompilationResult` respectively for more details.\n+//\n+// If `thunk` is set, then this is the new format. Otherwise, it's the legacy\n+// format.\n message GpuExecutableProto {\n+  // The HLO module of the executable - for debugging purposes only.\n+  xla.HloModuleProtoWithConfig hlo_module_with_config = 1;\n+\n+  // Wrapper around repeated BufferAllocationProto to allow using it in a oneof.\n+  message RepeatedBufferAllocations {\n+    repeated BufferAllocationProto values = 1;\n+  }\n+\n+  // Used in the legacy format.\n+  BufferAssignmentProto buffer_assignment = 2;\n+  // The buffer allocations of the executable, used in the new format.\n+  RepeatedBufferAllocations buffer_allocations = 10;\n+\n+  // The PTX of the executable. (Only applicable to CUDA)\n+  string asm_text = 3;\n+\n   // The binary of the executable.\n   //\n   // For CUDA, this is a cubin binary.\n   // For ROCm, this is a hsaco binary.\n-  bytes binary = 1;\n-\n-  // The PTX of the executable. (Only applicable to CUDA)\n-  string asm_text = 2;\n+  bytes binary = 4;\n \n   // The DNN compiled graphs of the executable.\n   //\n   // The key is the DNN kernel name, and the value is the compiled graph\n   // serialized to JSON. (Only applicable to cuDNN)\n-  map<string, string> dnn_compiled_graphs = 3;\n+  map<string, bytes> dnn_compiled_graphs = 5;\n \n   // The target compute capability of the executable.\n-  stream_executor.GpuComputeCapabilityProto gpu_compute_capability = 4;\n-\n-  // The HLO module of the executable - for debugging purposes only.\n-  xla.HloModuleProtoWithConfig hlo_module = 5;\n+  stream_executor.GpuComputeCapabilityProto gpu_compute_capability = 6;\n \n   // The thunk tree of the executable.\n-  ThunkProto thunk = 6;\n+  // Not set in the legacy format.\n+  optional ThunkProto thunk = 7;\n \n   // The name of the HLO module - for debugging purposes only.\n-  string module_name = 7;\n+  string module_name = 8;\n \n   // The shape of the program (parameters and result).\n-  xla.ProgramShapeProto program_shape = 8;\n-\n-  // The buffer allocations of the executable.\n-  repeated BufferAllocationProto buffer_allocations = 9;\n+  xla.ProgramShapeProto program_shape = 9;\n \n   message OutputInfoProto {\n     // This output is part of the following buffer allocation\n@@ -61,7 +77,7 @@ message GpuExecutableProto {\n   }\n \n   // Map from output shape index to output info.\n-  repeated OutputInfoMapEntry output_info_map = 10;\n+  repeated OutputInfoMapEntry output_info_map = 11;\n \n   message ConstantInfoProto {\n     // The name of the constant in the HLO module.\n@@ -75,5 +91,5 @@ message GpuExecutableProto {\n   }\n \n   // The constants used by the executable.\n-  repeated ConstantInfoProto constants = 11;\n+  repeated ConstantInfoProto constants = 12;\n }"
        },
        {
            "sha": "903589fc63a62debe37bfae7b9d4d3191354e4a7",
            "filename": "third_party/xla/xla/service/gpu/kernel_reuse_cache.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache.cc?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -27,7 +27,6 @@ limitations under the License.\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n-#include \"xla/service/gpu/executable.pb.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n #include \"xla/status_macros.h\"\n #include \"xla/stream_executor/launch_dim.h\""
        },
        {
            "sha": "4347a899e1c6213347291545e3a98cff7f23de53",
            "filename": "third_party/xla/xla/service/gpu/kernel_reuse_cache.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache.h?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -29,7 +29,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n-#include \"xla/service/gpu/executable.pb.h\"\n+#include \"xla/service/gpu/kernel_reuse_cache.pb.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n #include \"xla/stream_executor/gpu/tma_metadata.h\"\n #include \"xla/stream_executor/launch_dim.h\""
        },
        {
            "sha": "1a0888f6c795c1aed903261016351849e7e55f38",
            "filename": "third_party/xla/xla/service/gpu/kernel_reuse_cache.proto",
            "status": "renamed",
            "additions": 2,
            "deletions": 10,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache.proto?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -17,16 +17,8 @@ syntax = \"proto3\";\n \n package xla.gpu;\n \n-import \"xla/service/hlo.proto\";\n-import \"xla/xla.proto\";\n-\n-message CompilationResultProto {\n-  HloModuleProtoWithConfig hlo_module_with_config = 1;\n-  BufferAssignmentProto buffer_assignment = 2;\n-  string asm_text = 3;\n-  bytes binary = 4;\n-  map<string, bytes> dnn_compiled_graphs = 5;\n-}\n+option java_outer_classname = \"KernelReuseCache\";\n+option java_multiple_files = true;\n \n message CompilationCacheEntryProto {\n   message LaunchDimensionsProto {",
            "previous_filename": "third_party/xla/xla/service/gpu/executable.proto"
        },
        {
            "sha": "5a0421a4dac33922714a5860fc58c03284620f4d",
            "filename": "third_party/xla/xla/service/gpu/kernel_reuse_cache_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_reuse_cache_test.cc?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -16,7 +16,6 @@ limitations under the License.\n \n #include <gtest/gtest.h>\n #include \"absl/log/check.h\"\n-#include \"xla/service/gpu/executable.pb.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"tsl/platform/env.h\"\n "
        },
        {
            "sha": "67e3ecfcc86c41172d76268b68703f6c16c6fdc7",
            "filename": "third_party/xla/xla/service/gpu/legacy_gpu_aot_compilation_result.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.cc?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -29,7 +29,7 @@ limitations under the License.\n #include \"xla/service/buffer_value.h\"\n #include \"xla/service/compiler.h\"\n #include \"xla/service/executable.h\"\n-#include \"xla/service/gpu/executable.pb.h\"\n+#include \"xla/service/gpu/gpu_executable.pb.h\"\n #include \"xla/service/gpu/gpu_latency_hiding_scheduler.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -46,7 +46,7 @@ LegacyGpuAotCompilationResult::FromModule(\n     absl::string_view asm_text, absl::Span<const uint8_t> binary,\n     const BinaryMap& dnn_compiled_graphs, int pointer_size) {\n   tsl::profiler::TraceMe traceme(\"ResultFromModule\");\n-  CompilationResultProto proto;\n+  GpuExecutableProto proto;\n   *proto.mutable_hlo_module_with_config() = hlo_module->ToProtoWithConfig();\n   *proto.mutable_buffer_assignment() = buffer_assignment->ToProto();\n   proto.set_asm_text(asm_text);\n@@ -62,7 +62,7 @@ absl::StatusOr<std::unique_ptr<LegacyGpuAotCompilationResult>>\n LegacyGpuAotCompilationResult::FromString(const std::string& serialized,\n                                           int pointer_size) {\n   tsl::profiler::TraceMe traceme(\"ResultFromString\");\n-  CompilationResultProto proto;\n+  GpuExecutableProto proto;\n   if (!proto.ParseFromString(serialized)) {\n     return Internal(\"Failed to parse serialized GpuThunkAotCompilationResult.\");\n   }"
        },
        {
            "sha": "cbbaecdc964857d38a1b66442d3e75f104158c8a",
            "filename": "third_party/xla/xla/service/gpu/legacy_gpu_aot_compilation_result.h",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Flegacy_gpu_aot_compilation_result.h?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -28,7 +28,7 @@ limitations under the License.\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/compiler.h\"\n #include \"xla/service/executable.h\"\n-#include \"xla/service/gpu/executable.pb.h\"\n+#include \"xla/service/gpu/gpu_executable.pb.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n \n@@ -69,19 +69,17 @@ class LegacyGpuAotCompilationResult : public AotCompilationResult {\n   absl::StatusOr<std::unique_ptr<BufferAssignment>> buffer_assignment()\n       const override;\n \n-  const CompilationResultProto& GetCompilationResultProto() const {\n-    return proto_;\n-  }\n+  const GpuExecutableProto& GetGpuExecutableProto() const { return proto_; }\n \n  private:\n   LegacyGpuAotCompilationResult(std::unique_ptr<HloModule> module,\n-                                CompilationResultProto proto, int pointer_size)\n+                                GpuExecutableProto proto, int pointer_size)\n       : module_(std::move(module)),\n         proto_(std::move(proto)),\n         pointer_size_(pointer_size) {}\n \n   std::unique_ptr<HloModule> module_;\n-  CompilationResultProto proto_;\n+  GpuExecutableProto proto_;\n   int pointer_size_;\n };\n "
        },
        {
            "sha": "40a6803f5fe67b4605f3e83c956749aedbd4af79",
            "filename": "third_party/xla/xla/tools/hlo_opt/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2FBUILD?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -102,7 +102,6 @@ cc_library(\n         \"//xla/service:platform_util\",\n         \"//xla/service/gpu:alias_info\",\n         \"//xla/service/gpu:compile_module_to_llvm_ir\",\n-        \"//xla/service/gpu:executable_proto_cc\",\n         \"//xla/service/gpu:gpu_compiler\",\n         \"//xla/service/gpu:gpu_hlo_schedule\",\n         \"//xla/service/gpu:gpu_spmd_pipeline\","
        },
        {
            "sha": "aa7ce7e948ced2983e9ce5ac418527ac80fd68f6",
            "filename": "third_party/xla/xla/tools/hlo_opt/gpu_opt.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Fgpu_opt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/05d2b10d3341a16669312f89b8a90003f8b9f68b/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Fgpu_opt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fhlo_opt%2Fgpu_opt.cc?ref=05d2b10d3341a16669312f89b8a90003f8b9f68b",
            "patch": "@@ -37,7 +37,6 @@ limitations under the License.\n #include \"xla/service/executable.h\"\n #include \"xla/service/gpu/alias_info.h\"\n #include \"xla/service/gpu/compile_module_to_llvm_ir.h\"\n-#include \"xla/service/gpu/executable.pb.h\"\n #include \"xla/service/gpu/gpu_compiler.h\"\n #include \"xla/service/gpu/gpu_executable.h\"\n #include \"xla/service/gpu/gpu_hlo_schedule.h\""
        }
    ],
    "stats": {
        "total": 148,
        "additions": 72,
        "deletions": 76
    }
}