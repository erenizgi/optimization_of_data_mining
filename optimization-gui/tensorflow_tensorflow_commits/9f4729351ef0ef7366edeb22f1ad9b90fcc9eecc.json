{
    "author": "mtsokol",
    "message": "PR #30894: Fix MD table in `flags_guidance.md`\n\nImported from GitHub PR https://github.com/openxla/xla/pull/30894\n\nüìù Summary of Changes\n\nFixed MD table generation in `flags_guidance.md`.\n\nüéØ Justification\n Documentation update.\n\nüöÄ Kind of Contribution\nPlease remove what does not apply: üìö Documentation\nCopybara import of the project:\n\n--\nc8153a78c0dd44ddb714b428677243aa4c56dbd3 by Mateusz Sok√≥≈Ç <8431159+mtsokol@users.noreply.github.com>:\n\nFix md table in `flags_guidance.md`\n\nMerging this change closes #30894\n\nPiperOrigin-RevId: 809899648",
    "sha": "9f4729351ef0ef7366edeb22f1ad9b90fcc9eecc",
    "files": [
        {
            "sha": "dabcfc357016b39591672b91523df5f5803fecd0",
            "filename": "third_party/xla/docs/flags_guidance.md",
            "status": "modified",
            "additions": 18,
            "deletions": 26,
            "changes": 44,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9f4729351ef0ef7366edeb22f1ad9b90fcc9eecc/third_party%2Fxla%2Fdocs%2Fflags_guidance.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9f4729351ef0ef7366edeb22f1ad9b90fcc9eecc/third_party%2Fxla%2Fdocs%2Fflags_guidance.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Fflags_guidance.md?ref=9f4729351ef0ef7366edeb22f1ad9b90fcc9eecc",
            "patch": "@@ -18,32 +18,24 @@ Flag                            | Description\n The following flags are instrumental in enhancing runtime performance.\n Experimenting with these settings may lead to considerable performance gains.\n \n-Flag                                                                                                                                                                     | Description                                                                                                                                                                                                                                        | Default Values                                                                                                                                                                 | Suggested Values                                                                                                                                                            | Candidate Values\n-:----------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------\n-**Pipelining** <br> 1. `xla_should_allow_loop_variant_parameter_in_chain` <br> 2. `xla_should_add_loop_invariant_op_in_chain` <br> 3. `xla_tpu_enable_ici_ag_pipelining` | These 3 flags should be used in conjunction to enable collective pipelining of ICI(Interchip-Interconnect) all-gather operations, which creates more opportunities for overlapping execution.                                                      | 1. `xla_should_allow_loop_variant_parameter_in_chain=kDisabled` <br> 2. `xla_should_add_loop_invariant_op_in_chain=kDisabled` <br> 3. `xla_tpu_enable_ici_ag_pipelining=false` | 1. `xla_should_allow_loop_variant_parameter_in_chain=kEnabled` <br> 2. `xla_should_add_loop_invariant_op_in_chain=kEnabled` <br> 3. `xla_tpu_enable_ici_ag_pipelining=true` | 1. `xla_should_allow_loop_variant_parameter_in_chain=kDisabled/kEnabled/kAuto` <br> 2. `xla_should_add_loop_invariant_op_in_chain=kDisabled/kEnabled/kAuto` <br> 3. `xla_tpu_enable_ici_ag_pipelining=true/false`\n-**v5e/Async** <br> `xla_enable_async_all_gather` <br> `xla_tpu_enable_async_collective_fusion` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_gather`             | These 3 flags should be used in conjunction to activate asynchronous all-gather operations on v5e.                                                                                                                                                 | `xla_enable_async_all_gather=kAuto` <br> `xla_tpu_enable_async_collective_fusion=true` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_gather=true`                      | `xla_enable_async_all_gather=kAuto` <br> `xla_tpu_enable_async_collective_fusion=true` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_gather=true`                   | `xla_enable_async_all_gather=kDisabled/kEnabled/kAuto` <br> `xla_tpu_enable_async_collective_fusion=true/false` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_gather=true/false`\n-**v5e/Async** <br> `xla_tpu_enable_async_collective_fusion` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_reduce`                                                | These 2 flags should be used in conjunction to activate asynchronous all-reduce operations on v5e.                                                                                                                                                 | `xla_tpu_enable_async_collective_fusion=true` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_reduce=false`                                                              | `xla_tpu_enable_async_collective_fusion=true` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_reduce=true`                                                            | `xla_tpu_enable_async_collective_fusion=true/false` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_reduce=true/false`\n-**Async** <br> `xla_tpu_enable_async_all_to_all`                                                                                                                         | This flag enables asynchronous all-to-all communication.                                                                                                                                                                                           | `xla_tpu_enable_async_all_to_all=false`                                                                                                                                        | `xla_tpu_enable_async_all_to_all=true`                                                                                                                                      | `xla_tpu_enable_async_all_to_all=true/false`\n-**Latency-bound** <br> `xla_all_gather_latency_bound_threshold_in_bytes`                                                                                                 | This flag is intended for latency-bound (i.e., small-sized) all-gather operations. Enabling this triggers specific optimizations that can reduce execution time for latency-bound all-gathers. Typically it‚Äôs used in inference workloads.         | `xla_all_gather_latency_bound_threshold_in_bytes=-1` <br> (which is not enabled)                                                                                               | `4~16Mb(i.e. 4~16 * 1024 * 1024)`                                                                                                                                           | `[0, 9223372036854775807]`\n-**Latency-bound** <br> `xla_all_reduce_latency_bound_threshold_in_bytes`                                                                                                 | This flag is intended for latency-bound (i.e., small-sized) all-gather operations. Enabling this triggers specific optimizations that can reduce execution time for latency-bound all-reduces. Typically it‚Äôs used in inference workloads.         | `xla_all_reduce_latency_bound_threshold_in_bytes=-1` <br> (which is not enabled)                                                                                               | `4~16Mb(i.e. 4~16 * 1024 * 1024)`                                                                                                                                           | `[0, 9223372036854775807]`\n-**Latency-bound** <br> `xla_collective_permute_latency_bound_threshold_in_bytes`                                                                                         | This flag is intended for latency-bound (i.e., small-sized) all-gather operations. Enabling this triggers specific optimizations that can reduce execution time for latency-bound collective-permutes. Typically it‚Äôs used in inference workloads. | `xla_collective_permute_latency_bound_threshold_in_bytes=-1` <br> (which is not enabled)                                                                                       | `4~16Mb(i.e. 4~16 * 1024 * 1024)`                                                                                                                                           | `[0, 9223372036854775807]`\n-**Latency-bound** <br> `xla_all_to_all_latency_bound_threshold_in_bytes`                                                                                                 | This flag is intended for latency-bound (i.e., small-sized) all-gather operations. Enabling this triggers specific optimizations that can reduce execution time for latency-bound all-to-all. Typically it‚Äôs used in inference workloads.          | `xla_all_to_all_latency_bound_threshold_in_bytes=-1` <br> (which is not enabled)                                                                                               | `4~16Mb(i.e. 4~16 * 1024 * 1024)`                                                                                                                                           | `[0, 9223372036854775807]`\n-`xla_enable_async_collective_permute`                                                                                                 | Rewrites all collective-permute operations to their asynchronous variants.  When set to `auto`, XLA can turn on async collective based on other configurations or conditions automatically.          | `xla_enable_async_collective_permute=kAuto`                                                                                     | `xla_enable_async_collective_permute=kAuto`                                                                                                                                           | `xla_enable_async_collective_permute=kAuto/kEnabled/kDisabled`\n-**Compute centric** <br>\n-`xla_tpu_enable_dot_strength_reduction` | This flag rewrites non-compute intensive dots as multiply + reduce operations. | `xla_tpu_enable_dot_strength_reduction=true`  | `xla_tpu_enable_dot_strength_reduction=true` | `xla_tpu_enable_dot_strength_reduction=true/false`\n-<br>\n-<br>\n-`xla_tpu_dot_dot_fusion`                    |  This flag enables dot-dot fusion, which fuses a producer-dot operation with a consumer-dot operation. On doing so, the producer-dot's output is not manifested in slow/main memory driving down memory footprint.     |        `xla_tpu_dot_dot_fusion=true`  |                                                                                                                                           `xla_tpu_dot_dot_fusion=true`                  | `xla_tpu_dot_dot_fusion=true/false`\n-<br>\n-`xla_jf_enable_multi_output_fusion`   | This flag enables fusions that fuse multiple consumers (i.e. the resultant fusion will have multiple outputs) | `xla_jf_enable_multi_output_fusion=true` | `xla_jf_enable_multi_output_fusion=true` | `xla_jf_enable_multi_output_fusion=true/false`\n-<br>\n-`xla_tpu_scoped_vmem_limit_kib` |  This flag sets the amount of scratchpad VMEM available to per op for local usage in KiloBytes. Rest of the VMEM is used as buffer space. | `xla_tpu_scoped_vmem_limit_kib=16384` | `xla_tpu_scoped_vmem_limit_kib=16384` | `xla_tpu_scoped_vmem_limit_kib=[4096, VMEM size of the architecture - 1024]`\n-<br>\n-`xla_tpu_async_copy_bandwidth_scaling_factor` | Scales effective bandwidth for async copies. This is used when making prefetch decisions and deciding which tensors should live in VMEM. | `xla_tpu_async_copy_bandwidth_scaling_factor=1` | `xla_tpu_async_copy_bandwidth_scaling_factor=1` | `xla_tpu_async_copy_bandwidth_scaling_factor=(0, 1]`\n-<br>\n-`xla_msa_enable_cross_program_prefetch_freeing` | Enables freeing optimization for cross-program-prefetched buffers. | `xla_msa_enable_cross_program_prefetch_freeing=enabled` | `xla_msa_enable_cross_program_prefetch_freeing=enabled` | `xla_msa_enable_cross_program_prefetch_freeing=enabled/disabled`\n-<br>\n-`xla_tpu_msa_inefficient_use_to_copy_ratio` | The ratio of use bytes to copy bytes for a given allocation site below which we consider the site to be inefficient. This is used while making VMEM placement decisions. A value of 0 would treat all sites as efficient and a value of 1 would require the amount of bytes used at the site to be at least as much as the async copy bytes. | `xla_tpu_msa_inefficient_use_to_copy_ratio=0.5` | `xla_tpu_msa_inefficient_use_to_copy_ratio=0.5` | `xla_tpu_msa_inefficient_use_to_copy_ratio=[0, 1]`\n+Flag                                                                                                                                                                     | Description                                                                                                                                                                                                                                                                                                                                  | Default Values                                                                                                                                                                 | Suggested Values                                                                                                                                                            | Candidate Values\n+:----------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------\n+**Pipelining** <br> 1. `xla_should_allow_loop_variant_parameter_in_chain` <br> 2. `xla_should_add_loop_invariant_op_in_chain` <br> 3. `xla_tpu_enable_ici_ag_pipelining` | These 3 flags should be used in conjunction to enable collective pipelining of ICI(Interchip-Interconnect) all-gather operations, which creates more opportunities for overlapping execution.                                                                                                                                                | 1. `xla_should_allow_loop_variant_parameter_in_chain=kDisabled` <br> 2. `xla_should_add_loop_invariant_op_in_chain=kDisabled` <br> 3. `xla_tpu_enable_ici_ag_pipelining=false` | 1. `xla_should_allow_loop_variant_parameter_in_chain=kEnabled` <br> 2. `xla_should_add_loop_invariant_op_in_chain=kEnabled` <br> 3. `xla_tpu_enable_ici_ag_pipelining=true` | 1. `xla_should_allow_loop_variant_parameter_in_chain=kDisabled/kEnabled/kAuto` <br> 2. `xla_should_add_loop_invariant_op_in_chain=kDisabled/kEnabled/kAuto` <br> 3. `xla_tpu_enable_ici_ag_pipelining=true/false`\n+**v5e/Async** <br> `xla_enable_async_all_gather` <br> `xla_tpu_enable_async_collective_fusion` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_gather`             | These 3 flags should be used in conjunction to activate asynchronous all-gather operations on v5e.                                                                                                                                                                                                                                           | `xla_enable_async_all_gather=kAuto` <br> `xla_tpu_enable_async_collective_fusion=true` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_gather=true`                      | `xla_enable_async_all_gather=kAuto` <br> `xla_tpu_enable_async_collective_fusion=true` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_gather=true`                   | `xla_enable_async_all_gather=kDisabled/kEnabled/kAuto` <br> `xla_tpu_enable_async_collective_fusion=true/false` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_gather=true/false`\n+**v5e/Async** <br> `xla_tpu_enable_async_collective_fusion` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_reduce`                                                | These 2 flags should be used in conjunction to activate asynchronous all-reduce operations on v5e.                                                                                                                                                                                                                                           | `xla_tpu_enable_async_collective_fusion=true` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_reduce=false`                                                              | `xla_tpu_enable_async_collective_fusion=true` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_reduce=true`                                                            | `xla_tpu_enable_async_collective_fusion=true/false` <br> `xla_tpu_enable_async_collective_fusion_fuse_all_reduce=true/false`\n+**Async** <br> `xla_tpu_enable_async_all_to_all`                                                                                                                         | This flag enables asynchronous all-to-all communication.                                                                                                                                                                                                                                                                                     | `xla_tpu_enable_async_all_to_all=false`                                                                                                                                        | `xla_tpu_enable_async_all_to_all=true`                                                                                                                                      | `xla_tpu_enable_async_all_to_all=true/false`\n+**Latency-bound** <br> `xla_all_gather_latency_bound_threshold_in_bytes`                                                                                                 | This flag is intended for latency-bound (i.e., small-sized) all-gather operations. Enabling this triggers specific optimizations that can reduce execution time for latency-bound all-gathers. Typically it‚Äôs used in inference workloads.                                                                                                   | `xla_all_gather_latency_bound_threshold_in_bytes=-1` <br> (which is not enabled)                                                                                               | `4~16Mb(i.e. 4~16 * 1024 * 1024)`                                                                                                                                           | `[0, 9223372036854775807]`\n+**Latency-bound** <br> `xla_all_reduce_latency_bound_threshold_in_bytes`                                                                                                 | This flag is intended for latency-bound (i.e., small-sized) all-gather operations. Enabling this triggers specific optimizations that can reduce execution time for latency-bound all-reduces. Typically it‚Äôs used in inference workloads.                                                                                                   | `xla_all_reduce_latency_bound_threshold_in_bytes=-1` <br> (which is not enabled)                                                                                               | `4~16Mb(i.e. 4~16 * 1024 * 1024)`                                                                                                                                           | `[0, 9223372036854775807]`\n+**Latency-bound** <br> `xla_collective_permute_latency_bound_threshold_in_bytes`                                                                                         | This flag is intended for latency-bound (i.e., small-sized) all-gather operations. Enabling this triggers specific optimizations that can reduce execution time for latency-bound collective-permutes. Typically it‚Äôs used in inference workloads.                                                                                           | `xla_collective_permute_latency_bound_threshold_in_bytes=-1` <br> (which is not enabled)                                                                                       | `4~16Mb(i.e. 4~16 * 1024 * 1024)`                                                                                                                                           | `[0, 9223372036854775807]`\n+**Latency-bound** <br> `xla_all_to_all_latency_bound_threshold_in_bytes`                                                                                                 | This flag is intended for latency-bound (i.e., small-sized) all-gather operations. Enabling this triggers specific optimizations that can reduce execution time for latency-bound all-to-all. Typically it‚Äôs used in inference workloads.                                                                                                    | `xla_all_to_all_latency_bound_threshold_in_bytes=-1` <br> (which is not enabled)                                                                                               | `4~16Mb(i.e. 4~16 * 1024 * 1024)`                                                                                                                                           | `[0, 9223372036854775807]`\n+`xla_enable_async_collective_permute`                                                                                                                                    | Rewrites all collective-permute operations to their asynchronous variants. When set to `auto`, XLA can turn on async collective based on other configurations or conditions automatically.                                                                                                                                                   | `xla_enable_async_collective_permute=kAuto`                                                                                                                                    | `xla_enable_async_collective_permute=kAuto`                                                                                                                                 | `xla_enable_async_collective_permute=kAuto/kEnabled/kDisabled`\n+**Compute centric** <br> `xla_tpu_enable_dot_strength_reduction`                                                                                                         | This flag rewrites non-compute intensive dots as multiply + reduce operations.                                                                                                                                                                                                                                                               | **Compute centric** <br> `xla_tpu_enable_dot_strength_reduction=true`                                                                                                          | `xla_tpu_enable_dot_strength_reduction=true`                                                                                                                                | `xla_tpu_enable_dot_strength_reduction=true/false`\n+**Compute centric** <br> `xla_tpu_dot_dot_fusion`                                                                                                                        | This flag enables dot-dot fusion, which fuses a producer-dot operation with a consumer-dot operation. On doing so, the producer-dot's output is not manifested in slow/main memory driving down memory footprint.                                                                                                                            | `xla_tpu_dot_dot_fusion=true`                                                                                                                                                  | `xla_tpu_dot_dot_fusion=true`                                                                                                                                               | `xla_tpu_dot_dot_fusion=true/false`\n+**Compute centric** <br> `xla_jf_enable_multi_output_fusion`                                                                                                             | This flag enables fusions that fuse multiple consumers (i.e. the resultant fusion will have multiple outputs)                                                                                                                                                                                                                                | `xla_jf_enable_multi_output_fusion=true`                                                                                                                                       | `xla_jf_enable_multi_output_fusion=true`                                                                                                                                    | `xla_jf_enable_multi_output_fusion=true/false`\n+**Compute centric** <br> `xla_tpu_scoped_vmem_limit_kib`                                                                                                                 | This flag sets the amount of scratchpad VMEM available to per op for local usage in KiloBytes. Rest of the VMEM is used as buffer space.                                                                                                                                                                                                     | `xla_tpu_scoped_vmem_limit_kib=16384`                                                                                                                                          | `xla_tpu_scoped_vmem_limit_kib=16384`                                                                                                                                       | `xla_tpu_scoped_vmem_limit_kib=[4096, VMEM size of the architecture - 1024]`\n+**Compute centric** <br> `xla_tpu_async_copy_bandwidth_scaling_factor`                                                                                                   | Scales effective bandwidth for async copies. This is used when making prefetch decisions and deciding which tensors should live in VMEM.                                                                                                                                                                                                     | `xla_tpu_async_copy_bandwidth_scaling_factor=1`                                                                                                                                | `xla_tpu_async_copy_bandwidth_scaling_factor=1`                                                                                                                             | `xla_tpu_async_copy_bandwidth_scaling_factor=(0, 1]`\n+**Compute centric** <br> `xla_msa_enable_cross_program_prefetch_freeing`                                                                                                 | Enables freeing optimization for cross-program-prefetched buffers.                                                                                                                                                                                                                                                                           | `xla_msa_enable_cross_program_prefetch_freeing=enabled`                                                                                                                        | `xla_msa_enable_cross_program_prefetch_freeing=enabled`                                                                                                                     | `xla_msa_enable_cross_program_prefetch_freeing=enabled/disabled`\n+**Compute centric** <br> `xla_tpu_msa_inefficient_use_to_copy_ratio`                                                                                                     | The ratio of use bytes to copy bytes for a given allocation site below which we consider the site to be inefficient. This is used while making VMEM placement decisions. A value of 0 would treat all sites as efficient and a value of 1 would require the amount of bytes used at the site to be at least as much as the async copy bytes. | `xla_tpu_msa_inefficient_use_to_copy_ratio=0.5`                                                                                                                                | `xla_tpu_msa_inefficient_use_to_copy_ratio=0.5`                                                                                                                             | `xla_tpu_msa_inefficient_use_to_copy_ratio=[0, 1]`\n \n ## Memory Flags\n "
        }
    ],
    "stats": {
        "total": 44,
        "additions": 18,
        "deletions": 26
    }
}