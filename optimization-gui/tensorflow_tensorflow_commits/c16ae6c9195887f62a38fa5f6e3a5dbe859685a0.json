{
    "author": "ermilovmaxim",
    "message": "Add proto serialization for SendThunk\n\nPiperOrigin-RevId: 848297480",
    "sha": "c16ae6c9195887f62a38fa5f6e3a5dbe859685a0",
    "files": [
        {
            "sha": "1545c1fd615a667c7b7e201e3eab88011535177e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=c16ae6c9195887f62a38fa5f6e3a5dbe859685a0",
            "patch": "@@ -1993,16 +1993,35 @@ cc_library(\n         \"//xla/hlo/ir:collective_op_group_mode\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/runtime:device_id\",\n+        \"//xla/service:buffer_assignment\",\n         \"//xla/service:computation_placer\",\n         \"//xla/stream_executor:device_address\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:status_macros\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/types:span\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"send_thunk_test\",\n+    srcs = [\"send_thunk_test.cc\"],\n+    deps = [\n+        \":collective_thunk\",\n+        \":send_thunk\",\n+        \":thunk\",\n+        \":thunk_proto_cc\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_googletest//:gtest_main\",\n     ],\n )\n \n@@ -2953,6 +2972,7 @@ cc_library(\n         \":outfeed_thunk\",\n         \":ragged_all_to_all_thunk\",\n         \":replica_id_thunk\",\n+        \":send_thunk\",\n         \":sequential_thunk\",\n         \":thunk\",\n         \":thunk_proto_cc\","
        },
        {
            "sha": "035a9bb85932f161dbe723f6f755d3edfc8a1019",
            "filename": "third_party/xla/xla/backends/gpu/runtime/p2p_thunk_common.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fp2p_thunk_common.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fp2p_thunk_common.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fp2p_thunk_common.cc?ref=c16ae6c9195887f62a38fa5f6e3a5dbe859685a0",
            "patch": "@@ -127,8 +127,7 @@ P2PConfig GetP2PConfigForSendRecv(const HloSendRecvInstruction* instr,\n   }\n \n   std::vector<ReplicaGroup> replica_groups = statusor.value();\n-  P2PConfig::ValidationKind validation_kind = P2PConfig::ValidationKind::kValid;\n-  p2p_config.validation_kind = validation_kind;\n+  p2p_config.validation_kind = P2PConfig::ValidationKind::kValid;\n   for (const ReplicaGroup& replica_group : replica_groups) {\n     int64_t source = replica_group.replica_ids(0);\n     int64_t target = replica_group.replica_ids(1);"
        },
        {
            "sha": "a2144f91b4c924ae84faf56dfecb74079d5d59c8",
            "filename": "third_party/xla/xla/backends/gpu/runtime/send_thunk.cc",
            "status": "modified",
            "additions": 84,
            "deletions": 5,
            "changes": 89,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc?ref=c16ae6c9195887f62a38fa5f6e3a5dbe859685a0",
            "patch": "@@ -16,15 +16,18 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/send_thunk.h\"\n \n #include <cstdint>\n+#include <memory>\n #include <optional>\n #include <string>\n #include <utility>\n #include <vector>\n \n+#include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n@@ -35,30 +38,40 @@ limitations under the License.\n #include \"xla/hlo/ir/collective_op_group_mode.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/runtime/device_id.h\"\n+#include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/computation_placer.h\"\n #include \"xla/status_macros.h\"\n #include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/xla_data.pb.h\"\n+#include \"xla/tsl/platform/status_macros.h\"\n \n namespace xla {\n namespace gpu {\n \n SendThunk::SendThunk(ThunkInfo thunk_info, const HloSendInstruction* instr,\n                      int64_t replica_count, int64_t partition_count,\n                      const Buffer& buffer)\n-    : CollectiveThunk(Thunk::kSend, thunk_info,\n-                      /*is_sync=*/false, GetStreamKindForP2P(instr)),\n-      config_(GetP2PConfigForSendRecv(instr, instr->operand(0)->shape(),\n-                                      replica_count, partition_count)),\n+    : SendThunk(std::move(thunk_info),\n+                GetP2PConfigForSendRecv(instr, instr->operand(0)->shape(),\n+                                        replica_count, partition_count),\n+                std::make_shared<CollectiveThunk::AsyncEvents>(),\n+                GetStreamKindForP2P(instr), buffer, instr->name()) {}\n+\n+SendThunk::SendThunk(ThunkInfo thunk_info, const P2PConfig& config,\n+                     std::shared_ptr<AsyncEvents> async_events,\n+                     AsyncStreamKind stream_kind, const Buffer& buffer,\n+                     absl::string_view instr_name)\n+    : CollectiveThunk(Thunk::kSend, thunk_info, async_events, stream_kind),\n+      config_(config),\n       buffer_(buffer),\n       execution_counters_(config_.validation_kind ==\n                                   P2PConfig::ValidationKind::kConditional\n                               ? new ExecutionCounters()\n                               : nullptr),\n-      hlo_name_(instr->name()) {}\n+      hlo_name_(instr_name) {}\n \n absl::Status SendThunk::Initialize(const InitializeParams& params) {\n   TF_RETURN_IF_ERROR(CollectiveThunk::Initialize(params));\n@@ -69,6 +82,72 @@ absl::Status SendThunk::Initialize(const InitializeParams& params) {\n   return absl::OkStatus();\n }\n \n+absl::StatusOr<std::unique_ptr<SendThunk>> SendThunk::FromProto(\n+    ThunkInfo thunk_info, const SendThunkProto& thunk_proto,\n+    absl::Span<const BufferAllocation> buffer_allocations,\n+    CollectiveThunk::AsyncEventsMap& async_events_map) {\n+  std::shared_ptr<CollectiveThunk::AsyncEvents>& async_events =\n+      async_events_map[AsyncEventsUniqueId{\n+          thunk_proto.async_events_unique_id()}];\n+  if (!async_events) {\n+    async_events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+  }\n+\n+  ASSIGN_OR_RETURN(CollectiveThunk::Buffer buffer,\n+                   CollectiveThunk::Buffer::FromProto(thunk_proto.buffer(),\n+                                                      buffer_allocations));\n+\n+  CollectiveConfig config =\n+      CollectiveConfig::FromProto(thunk_proto.collective_config());\n+\n+  P2PConfig::IdToSourceTargetMap id_to_source_target;\n+  for (const SourceTarget& source_target : thunk_proto.source_target_pairs()) {\n+    id_to_source_target.insert({source_target.target(), {}})\n+        .first->second.source = source_target.source();\n+    id_to_source_target.insert({source_target.source(), {}})\n+        .first->second.target = source_target.target();\n+  }\n+\n+  return std::make_unique<SendThunk>(\n+      std::move(thunk_info), P2PConfig{config, std::move(id_to_source_target)},\n+      async_events, thunk_proto.async_stream_kind(), buffer,\n+      thunk_proto.instruction_name());\n+}\n+\n+absl::StatusOr<ThunkProto> SendThunk::ToProto() const {\n+  CHECK_EQ(config_.validation_kind, P2PConfig::ValidationKind::kValid);\n+  CHECK(config_.source_target_to_bounds.empty());\n+\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+\n+  SendThunkProto* thunk_proto = proto.mutable_send_thunk();\n+\n+  std::optional<AsyncEventsUniqueId> async_events_id = GetAsyncEventsUniqueId();\n+  CHECK(async_events_id.has_value());\n+  thunk_proto->set_async_events_unique_id(async_events_id->value());\n+\n+  *thunk_proto->mutable_collective_config() = config_.config.ToProto();\n+  std::vector<SourceTarget> source_target_pairs;\n+  source_target_pairs.reserve(config_.id_to_source_target.size() / 2);\n+  for (const auto& [key_id, map_entry] : config_.id_to_source_target) {\n+    if (!map_entry.source.has_value()) {\n+      // Same pair is in the map with target/source switched.\n+      continue;\n+    }\n+    SourceTarget pair;\n+    pair.set_source(*map_entry.source);\n+    pair.set_target(key_id);\n+    source_target_pairs.push_back(pair);\n+  }\n+  thunk_proto->mutable_source_target_pairs()->Assign(\n+      source_target_pairs.begin(), source_target_pairs.end());\n+\n+  thunk_proto->set_async_stream_kind(GetAsyncStreamKind());\n+  thunk_proto->set_instruction_name(hlo_name_);\n+  return proto;\n+}\n+\n absl::StatusOr<bool> SendThunk::RunCollective(const ExecuteParams& params,\n                                               const GpuCliqueKey&,\n                                               se::Stream& stream,"
        },
        {
            "sha": "3651dba6c580ba46ee0e61a67ff3c49f7425b38d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/send_thunk.h",
            "status": "modified",
            "additions": 14,
            "deletions": 0,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.h?ref=c16ae6c9195887f62a38fa5f6e3a5dbe859685a0",
            "patch": "@@ -23,12 +23,14 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/p2p_thunk_common.h\"\n #include \"xla/core/collectives/communicator.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/stream.h\"\n \n namespace xla {\n@@ -40,8 +42,20 @@ class SendThunk : public CollectiveThunk {\n   SendThunk(ThunkInfo thunk_info, const HloSendInstruction* instr,\n             int64_t replica_count, int64_t partition_count,\n             const Buffer& buffer);\n+  SendThunk(ThunkInfo thunk_info, const P2PConfig& config,\n+            std::shared_ptr<AsyncEvents> async_events,\n+            AsyncStreamKind stream_kind, const Buffer& buffer,\n+            absl::string_view instr_name);\n+\n   absl::Status Initialize(const InitializeParams& params) override;\n \n+  static absl::StatusOr<std::unique_ptr<SendThunk>> FromProto(\n+      ThunkInfo thunk_info, const SendThunkProto& thunk_proto,\n+      absl::Span<const BufferAllocation> buffer_allocations,\n+      CollectiveThunk::AsyncEventsMap& async_events_map);\n+\n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n  protected:\n   const CollectiveConfig& config() const override { return config_.config; }\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,"
        },
        {
            "sha": "79516ce955ec6bc250fd8aaf2f84859ac806a452",
            "filename": "third_party/xla/xla/backends/gpu/runtime/send_thunk_test.cc",
            "status": "added",
            "additions": 75,
            "deletions": 0,
            "changes": 75,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk_test.cc?ref=c16ae6c9195887f62a38fa5f6e3a5dbe859685a0",
            "patch": "@@ -0,0 +1,75 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/send_thunk.h\"\n+\n+#include <memory>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"xla/backends/gpu/runtime/collective_thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+using ::tsl::proto_testing::EqualsProto;\n+\n+TEST(CollectiveThunkTest, ProtoRoundTrip) {\n+  ThunkProto proto = tsl::proto_testing::ParseTextProtoOrDie<ThunkProto>(\n+      R\"pb(\n+        thunk_info {\n+          profile_annotation: \"partition_id_profile_annotation\"\n+          execution_stream_id: 2\n+        }\n+        send_thunk {\n+          async_events_unique_id: 3\n+          collective_config {}\n+          async_stream_kind: ASYNC_STREAM_KIND_COLLECTIVE\n+          source_target_pairs: { source: 1 target: 2 }\n+        }\n+      )pb\");\n+\n+  Thunk::ThunkInfo thunk_info;\n+  thunk_info.profile_annotation = proto.thunk_info().profile_annotation();\n+  thunk_info.execution_stream_id = xla::gpu::ExecutionStreamId{\n+      static_cast<xla::gpu::ExecutionStreamId::ValueType>(\n+          proto.thunk_info().execution_stream_id())};\n+\n+  CollectiveThunk::AsyncEventsMap async_events_map;\n+  std::vector<BufferAllocation> buffer_allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/4, /*color=*/0)};\n+\n+  ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<SendThunk> thunk,\n+      SendThunk::FromProto(thunk_info, proto.send_thunk(), buffer_allocations,\n+                           async_events_map));\n+  ASSERT_NE(thunk->async_events(), nullptr);\n+\n+  ASSERT_OK_AND_ASSIGN(ThunkProto round_trip_proto, thunk->ToProto());\n+\n+  // Ids are unique and expected to differ.\n+  proto.mutable_send_thunk()->set_async_events_unique_id(\n+      round_trip_proto.send_thunk().async_events_unique_id());\n+  EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        },
        {
            "sha": "72f9af4f5c9871b9420e642b5127eb6424e2553b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=c16ae6c9195887f62a38fa5f6e3a5dbe859685a0",
            "patch": "@@ -457,6 +457,17 @@ message CollectivePermuteStartThunkProto {\n   bool p2p_memcpy_enabled = 6;\n }\n \n+message SendThunkProto {\n+  uint64 async_events_unique_id = 1;\n+  CollectiveBufferProto buffer = 2;\n+\n+  CollectiveConfigProto collective_config = 3;\n+  repeated SourceTarget source_target_pairs = 4;\n+\n+  AsyncStreamKind async_stream_kind = 5;\n+  string instruction_name = 6;\n+}\n+\n message CollectiveDoneThunkProto {\n   ThunkKindProto thunk_kind = 1;\n   AsyncStreamKind async_stream_kind = 2;\n@@ -507,6 +518,7 @@ message ThunkProto {\n     AllToAllStartThunkProto all_to_all_start_thunk = 40;\n     RaggedAllToAllStartThunkProto ragged_all_to_all_start_thunk = 41;\n     CollectivePermuteStartThunkProto collective_permute_start_thunk = 42;\n+    SendThunkProto send_thunk = 43;\n   }\n }\n "
        },
        {
            "sha": "7ba384ee90c936fe7ffc2c60a1ac382d3b67c409",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c16ae6c9195887f62a38fa5f6e3a5dbe859685a0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc?ref=c16ae6c9195887f62a38fa5f6e3a5dbe859685a0",
            "patch": "@@ -54,6 +54,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/outfeed_thunk.h\"\n #include \"xla/backends/gpu/runtime/ragged_all_to_all_thunk.h\"\n #include \"xla/backends/gpu/runtime/replica_id_thunk.h\"\n+#include \"xla/backends/gpu/runtime/send_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n@@ -267,6 +268,10 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n       return CollectivePermuteStartThunk::FromProto(\n           std::move(thunk_info), thunk_proto.collective_permute_start_thunk(),\n           buffer_allocations, collective_async_events_map);\n+    case ThunkProto::kSendThunk:\n+      return SendThunk::FromProto(std::move(thunk_info),\n+                                  thunk_proto.send_thunk(), buffer_allocations,\n+                                  collective_async_events_map);\n     default:\n       std::optional<absl::string_view> unsupported_thunk_type =\n           GetStoredThunkTypeName(thunk_proto);"
        }
    ],
    "stats": {
        "total": 218,
        "additions": 211,
        "deletions": 7
    }
}