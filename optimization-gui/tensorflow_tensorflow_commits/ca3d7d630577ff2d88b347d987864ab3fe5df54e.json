{
    "author": "tensorflower-gardener",
    "message": "Integrate LLVM at llvm/llvm-project@028bfa255e90\n\nUpdates LLVM usage to match\n[028bfa255e90](https://github.com/llvm/llvm-project/commit/028bfa255e90)\n\nPiperOrigin-RevId: 825670183",
    "sha": "ca3d7d630577ff2d88b347d987864ab3fe5df54e",
    "files": [
        {
            "sha": "8473682e60e08cf418ad2bcc27554596ed4ad53f",
            "filename": "tensorflow/compiler/mlir/lite/ir/tfl_ops.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -4962,7 +4962,7 @@ void IfOp::getSuccessorRegions(RegionBranchPoint point,\n                                SmallVectorImpl<RegionSuccessor>& regions) {\n   // The `then` and the `else` region branch back to the parent operation.\n   if (!point.isParent()) {\n-    regions.push_back(RegionSuccessor(getResults()));\n+    regions.push_back(RegionSuccessor(getOperation(), getResults()));\n     return;\n   }\n "
        },
        {
            "sha": "4104cf412acfd829a5b32ee9ffeae5886e0f9558",
            "filename": "tensorflow/compiler/mlir/tensorflow/ir/tf_ops.td",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Fir%2Ftf_ops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Fir%2Ftf_ops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Fir%2Ftf_ops.td?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -335,7 +335,6 @@ def TF_IfRegionOp : TF_Op<\"IfRegion\",\n            \"areTypesCompatible\",\n            \"getEntrySuccessorOperands\",\n            \"getRegionInvocationBounds\",\n-           \"getSuccessorRegions\"\n        ]>\n       ]> {\n   let summary = \"output = cond ? then_branch output : else_branch output\";\n@@ -395,7 +394,6 @@ def TF_GeneratorDatasetRegionOp : TF_Op<\"GeneratorDatasetRegion\",\n            \"areTypesCompatible\",\n            \"getEntrySuccessorOperands\",\n            \"getRegionInvocationBounds\",\n-           \"getSuccessorRegions\"\n        ]>,\n        SingleBlockImplicitTerminator<\"YieldOp\">,\n        TF_GeneratorOpSideEffect,"
        },
        {
            "sha": "6382f325a4750567c5c642224ae4e8ab71533cfe",
            "filename": "tensorflow/compiler/mlir/tensorflow/ir/tf_ops_a_m.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 14,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Fir%2Ftf_ops_a_m.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Fir%2Ftf_ops_a_m.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Fir%2Ftf_ops_a_m.cc?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -3003,14 +3003,14 @@ void GeneratorDatasetRegionOp::getRegionInvocationBounds(\n }\n \n OperandRange GeneratorDatasetRegionOp::getEntrySuccessorOperands(\n-    RegionBranchPoint point) {\n+    RegionSuccessor successor) {\n   auto end = this->getOperation()->operand_end();\n-  if (point.isParent()) {\n+  if (successor.isParent()) {\n     // The op itself doesn't branch back to itself.\n     return ::mlir::OperandRange(end, end);\n-  } else if (point.getRegionOrNull() == &getInit()) {\n+  } else if (successor.getSuccessor() == &getInit()) {\n     return getInitFuncOtherArgs();\n-  } else if (point.getRegionOrNull() == &getNext()) {\n+  } else if (successor.getSuccessor() == &getNext()) {\n     return getNextFuncOtherArgs();\n   } else /* finalize region */ {\n     return getFinalizeFuncOtherArgs();\n@@ -3024,13 +3024,15 @@ void GeneratorDatasetRegionOp::getSuccessorRegions(\n     // The op itself branches to `init` first.\n     regions.push_back(\n         RegionSuccessor(&getInit(), getInit().front().getArguments()));\n-  } else if (point.getRegionOrNull() == &getInit()) {\n+  } else if (point.getTerminatorPredecessorOrNull()->getParentRegion() ==\n+             &getInit()) {\n     // `init` branches to `next`, passing along the arguments given to `init`'s\n     // yield. Said arguments precede the \"other args\".\n     n = getInitFuncOtherArgs().size();\n     regions.push_back(RegionSuccessor(\n         &getNext(), getNext().front().getArguments().drop_back(n)));\n-  } else if (point.getRegionOrNull() == &getNext()) {\n+  } else if (point.getTerminatorPredecessorOrNull()->getParentRegion() ==\n+             &getNext()) {\n     // `next` branches to itself, or to `finalize`, passing all arguments given\n     // to `next`s yield.\n \n@@ -3045,7 +3047,8 @@ void GeneratorDatasetRegionOp::getSuccessorRegions(\n         &getFinalize(), getFinalize().front().getArguments().slice(0, num)));\n   } else {\n     // `finalize` branches back to the op itself, not passing any arguments.\n-    regions.push_back(RegionSuccessor());\n+    regions.push_back(RegionSuccessor(\n+        point.getTerminatorPredecessorOrNull()->getParentRegion()));\n   }\n }\n \n@@ -3261,11 +3264,12 @@ void IfRegionOp::getRegionInvocationBounds(\n   invocationBounds.assign(2, {0, 1});\n }\n \n-OperandRange IfRegionOp::getEntrySuccessorOperands(RegionBranchPoint point) {\n+OperandRange IfRegionOp::getEntrySuccessorOperands(RegionSuccessor successor) {\n   // IfRegionOp currently only allows one op (the condition), so there are no\n   // remaining operands for the successor.\n-  assert((point.isParent() ||\n-          (point == (*this)->getRegion(0) || point == (*this)->getRegion(1))) &&\n+  assert((successor.isParent() ||\n+          (successor.getSuccessor() == &(*this)->getRegion(0) ||\n+           successor.getSuccessor() == &(*this)->getRegion(1))) &&\n          \"Invalid IfRegionOp region index.\");\n   auto end = this->getOperation()->operand_end();\n   return ::mlir::OperandRange(end, end);\n@@ -3275,16 +3279,20 @@ void IfRegionOp::getSuccessorRegions(\n     RegionBranchPoint point, SmallVectorImpl<RegionSuccessor>& regions) {\n   if (!point.isParent()) {\n     // The `then` and the `else` region branch back to the parent operation.\n-    regions.push_back(RegionSuccessor(getResults()));\n+    regions.push_back(\n+        RegionSuccessor(point.getTerminatorPredecessorOrNull(), getResults()));\n     return;\n   } else {\n     // The parent can branch to either `then` or `else`.\n-    regions.push_back(RegionSuccessor(&getThenBranch()));\n+    regions.push_back(\n+        RegionSuccessor(&getThenBranch(), getThenBranch().getArguments()));\n     Region* elseRegion = &this->getElseBranch();\n     if (!elseRegion->empty())\n-      regions.push_back(RegionSuccessor(elseRegion));\n+      regions.push_back(\n+          RegionSuccessor(elseRegion, elseRegion->getArguments()));\n     else\n-      regions.push_back(RegionSuccessor());\n+      regions.push_back(RegionSuccessor(\n+          point.getTerminatorPredecessorOrNull()->getParentRegion()));\n   }\n }\n "
        },
        {
            "sha": "7135bb553edd5cbe37b623119894781a31a0d8fd",
            "filename": "tensorflow/compiler/mlir/tensorflow/ir/tf_ops_n_z.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 7,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Fir%2Ftf_ops_n_z.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Fir%2Ftf_ops_n_z.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Fir%2Ftf_ops_n_z.cc?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -3611,8 +3611,8 @@ SmallVector<Region *> WhileRegionOp::getLoopRegions() { return {&getBody()}; }\n //===----------------------------------------------------------------------===//\n \n OperandRange WhileRegionOp::getEntrySuccessorOperands(\n-    RegionBranchPoint point) {\n-  if (point.isParent()) {\n+    RegionSuccessor successor) {\n+  if (successor.isParent()) {\n     // WhileRegionOp branches to the condition, which branches to the body. But\n     // the op itself doesn't branch back to itself. So this range is empty.\n     auto end = this->getOperation()->operand_end();\n@@ -3628,21 +3628,29 @@ OperandRange WhileRegionOp::getEntrySuccessorOperands(\n \n void WhileRegionOp::getSuccessorRegions(\n     RegionBranchPoint point, SmallVectorImpl<RegionSuccessor> &regions) {\n-  if (!point.isParent() && point == (*this)->getRegion(0)) {\n+  if (!point.isParent() &&\n+      (point.getTerminatorPredecessorOrNull() &&\n+       point.getTerminatorPredecessorOrNull()->getParentRegion() ==\n+           &(*this)->getRegion(0))) {\n     // 'cond' branches to the body or returns.\n     Operation *yield = getCond().front().getTerminator();\n     if (yield->getOperands().size() ==\n         1 + this->getOperation()->getOperands().size()) {\n       regions.push_back(\n           RegionSuccessor(&getBody(), getBody().front().getArguments()));\n-      regions.push_back(getResults());\n+      regions.push_back(RegionSuccessor(getOperation(), getResults()));\n     } else {\n       // For compatibility with older code, we allow the \"yield\" in a condition\n       // to only yield a single boolean. In that case we can't forward any args.\n       regions.push_back(RegionSuccessor(&getBody()));\n-      regions.push_back(RegionSuccessor());  // branch back to parent, no args\n+      regions.push_back(RegionSuccessor(\n+          point.getTerminatorPredecessorOrNull()\n+              ->getParentRegion()));  // branch back to parent, no args\n     }\n-  } else if (!point.isParent() && point == (*this)->getRegion(1)) {\n+  } else if (!point.isParent() &&\n+             (point.getTerminatorPredecessorOrNull() &&\n+              point.getTerminatorPredecessorOrNull()->getParentRegion() ==\n+                  &(*this)->getRegion(1))) {\n     // 'body' branches back to 'cond'.\n     regions.push_back(\n         RegionSuccessor(&getCond(), getCond().front().getArguments()));\n@@ -4510,7 +4518,7 @@ LogicalResult UniformQuantizedClipByValueOp::verify() {\n //===----------------------------------------------------------------------===//\n \n MutableOperandRange YieldOp::getMutableSuccessorOperands(\n-    RegionBranchPoint point) {\n+    RegionSuccessor successor) {\n   if (auto whileOp =\n           llvm::dyn_cast<WhileRegionOp>(this->getOperation()->getParentOp())) {\n     if (&whileOp.getCond() == this->getOperation()->getParentRegion()) {"
        },
        {
            "sha": "a3305eef8a081972c422dab35c9aa99d7511d893",
            "filename": "tensorflow/compiler/mlir/tensorflow/tests/tf-ops.mlir",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Ftf-ops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Ftf-ops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Ftf-ops.mlir?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -1317,7 +1317,7 @@ func.func @testIfRegionElseTerminator(%arg0: tensor<i1>, %arg1: tensor<2xf32>) -\n \n // tf.Region yield number of results should match op number of results\n func.func @testIfRegionThenResultCount(%arg0: tensor<i1>, %arg1: tensor<2xf32>) -> tensor<2xf32> {\n-  // expected-error @+1 {{'tf.IfRegion' op region control flow edge from Region #0 to parent results: source has 2 operands, but target successor needs 1}}\n+  // expected-error @+1 {{'tf.IfRegion' op region control flow edge from Operation tf.Yield to parent results: source has 2 operands, but target successor <to parent> needs 1}}\n   %0 = \"tf.IfRegion\"(%arg0) ({\n      %t = \"tf.Abs\"(%arg1) : (tensor<2xf32>) -> tensor<2xf32>\n      \"tf.Yield\"(%t, %t) : (tensor<2xf32>, tensor<2xf32>) -> ()\n@@ -1332,7 +1332,7 @@ func.func @testIfRegionThenResultCount(%arg0: tensor<i1>, %arg1: tensor<2xf32>)\n // -----\n \n func.func @testIfRegionElseResultCount(%arg0: tensor<i1>, %arg1: tensor<2xf32>) -> tensor<2xf32> {\n-  // expected-error @+1 {{'tf.IfRegion' op region control flow edge from Region #1 to parent results: source has 2 operands, but target successor needs 1}}\n+  // expected-error @+1 {{'tf.IfRegion' op region control flow edge from Operation tf.Yield to parent results: source has 2 operands, but target successor <to parent> needs 1}}\n   %0 = \"tf.IfRegion\"(%arg0) ({\n      %t = \"tf.Abs\"(%arg1) : (tensor<2xf32>) -> tensor<2xf32>\n      \"tf.Yield\"(%t) : (tensor<2xf32>) -> ()"
        },
        {
            "sha": "057aad050762d32d51050b606332cac1f486042a",
            "filename": "tensorflow/core/ir/ops.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 10,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcore%2Fir%2Fops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcore%2Fir%2Fops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fir%2Fops.cc?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -1155,7 +1155,7 @@ static LogicalResult VerifyPreservedAttrs(Operation* op,\n       num_rets = 1;\n     } else {\n       num_rets = cast<RegionBranchTerminatorOpInterface>(terminator)\n-                     .getMutableSuccessorOperands(region)\n+                     .getMutableSuccessorOperands(RegionSuccessor(&region))\n                      .size();\n     }\n     if (num_rets != attrs.getResAttrs().size()) {\n@@ -1171,7 +1171,7 @@ static LogicalResult VerifyPreservedAttrs(Operation* op,\n // YieldOp\n \n MutableOperandRange YieldOp::getMutableSuccessorOperands(\n-    RegionBranchPoint point) {\n+    RegionSuccessor successor) {\n   // Get the subrange of non-control operands.\n   return getArgsMutable();\n }\n@@ -1212,10 +1212,10 @@ template <typename IfLikeRegionOp>\n void GetIfLikeRegionOpSuccessorRegions(\n     IfLikeRegionOp op, RegionBranchPoint point,\n     SmallVectorImpl<RegionSuccessor>& regions) {\n-  // Both regions branch back to the parent op.\n   if (!point.isParent()) {\n     // Ignore the control token.\n     regions.emplace_back(\n+        op.getOperation(),\n         ResultRange(op->result_begin(), std::prev(op->result_end())));\n   } else {\n     // Unknown successor.\n@@ -1296,6 +1296,7 @@ void GetCaseLikeRegionOpSuccessorRegions(\n   if (!point.isParent()) {\n     // Ignore the control token.\n     regions.emplace_back(\n+        op.getOperation(),\n         ResultRange(op->result_begin(), std::prev(op->result_end())));\n   } else {\n     // Unknown successor. Add all of them.\n@@ -1325,7 +1326,7 @@ void GetCaseLikeRegionOpEntrySuccessorRegions(\n // ConditionOp\n \n MutableOperandRange ConditionOp::getMutableSuccessorOperands(\n-    RegionBranchPoint point) {\n+    RegionSuccessor successor) {\n   // Get the subrange of non-control operands that are forwarded to the\n   // successor region.\n   return getArgsMutable();\n@@ -1380,12 +1381,18 @@ static void GetWhileLikeRegionOpSuccessorRegions(\n     WhileLikeRegionOp op, RegionBranchPoint point ,\n     SmallVectorImpl<RegionSuccessor>& regions) {\n   // The parent op and the body region always branch to the condition region.\n-  if (point.isParent() || point == op.getRegion(1)) {\n+  if (point.isParent() ||\n+      (point.getTerminatorPredecessorOrNull() &&\n+       point.getTerminatorPredecessorOrNull()->getParentRegion() ==\n+           &op.getRegion(1))) {\n     regions.emplace_back(&op.getCondRegion(),\n                          GetLoopRegionDataArgs(op.getCondRegion()));\n     return;\n   }\n-  assert(point == op->getRegion(0) && \"invalid region index\");\n+  assert((point.getTerminatorPredecessorOrNull() &&\n+          point.getTerminatorPredecessorOrNull()->getParentRegion() ==\n+              &op.getRegion(0)) &&\n+         \"invalid region index\");\n   // The condition regions branches to the loop body or back to the parent.\n   // Try to narrow the condition value to a constant.\n   auto condition =\n@@ -1399,7 +1406,7 @@ static void GetWhileLikeRegionOpSuccessorRegions(\n   }\n   if (!cond || !*cond) {\n     // Drop the control token.\n-    regions.emplace_back(op.getResults().drop_back());\n+    regions.emplace_back(op.getOperation(), op.getResults().drop_back());\n   }\n }\n \n@@ -1427,8 +1434,7 @@ LogicalResult ForRegionOp::verify() {\n   return VerifyPreservedAttrs(*this, {getRegionAttrsAttr()});\n }\n \n-OperandRange ForRegionOp::getEntrySuccessorOperands(\n-    RegionBranchPoint point) {\n+OperandRange ForRegionOp::getEntrySuccessorOperands(RegionSuccessor successor) {\n   return getInit();\n }\n \n@@ -1440,7 +1446,7 @@ void ForRegionOp::getSuccessorRegions(\n                        GetLoopRegionDataArgs(getBodyRegion()).drop_front());\n   if (point.isParent()) return;\n   // The body might branch back to the parent. Drop the control token.\n-  regions.emplace_back((*this)->getResults().drop_back());\n+  regions.emplace_back(getOperation(), getResults().drop_back());\n }\n \n BlockArgument ForRegionOp::getDataValueOf(BlockArgument ctl) {"
        },
        {
            "sha": "d54d2f58eefd7f02fa81648299dfa9ce3eafea7b",
            "filename": "tensorflow/core/ir/ops.td",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcore%2Fir%2Fops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/tensorflow%2Fcore%2Fir%2Fops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fir%2Fops.td?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -864,7 +864,7 @@ class TFGraph_WhileLikeRegionOp<string mnemonic> : TFGraph_RegionOp<\n     }\n \n     OperandRange $cppClass::getEntrySuccessorOperands(\n-         ::mlir::RegionBranchPoint point) {\n+         ::mlir::RegionSuccessor successor) {\n       return getInit();\n     }\n     void $cppClass::getSuccessorRegions("
        },
        {
            "sha": "75d72f7e1d41067fa573d6d43acb3c51ac6fc7e1",
            "filename": "third_party/xla/third_party/llvm/generated.patch",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -1 +1,12 @@\n Auto generated patch. Do not edit or delete it, even if empty.\n+diff -ruN --strip-trailing-cr a/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h b/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n+--- a/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n++++ b/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n+@@ -18,7 +18,6 @@\n+ #include \"mlir/IR/Operation.h\"\n+ #include \"llvm/ADT/PointerUnion.h\"\n+ #include \"llvm/ADT/STLExtras.h\"\n+-#include \"llvm/Support/DebugLog.h\"\n+ #include \"llvm/Support/raw_ostream.h\"\n+ \n+ namespace mlir {"
        },
        {
            "sha": "655dc5434457f0eb1b225328c64fef8a4095c192",
            "filename": "third_party/xla/third_party/llvm/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n \n def repo(name):\n     \"\"\"Imports LLVM.\"\"\"\n-    LLVM_COMMIT = \"29c830cbf8c65fcab7f96f92c8466cbcc9924dd1\"\n-    LLVM_SHA256 = \"a717cad48a81fcc96b310e5bd953a20c8c569a08e2a95594206bd8900a1df32d\"\n+    LLVM_COMMIT = \"028bfa255e90581d1c08237a66c20b25096277e8\"\n+    LLVM_SHA256 = \"b1e5fbb1ed51e8e22e1ecdf0d74e7b28b1c554bb507326df2172c0c4707de0f8\"\n \n     tf_http_archive(\n         name = name,"
        },
        {
            "sha": "7a253160db881c0ec62c4c04e8436f5d5718c3c9",
            "filename": "third_party/xla/third_party/shardy/temporary.patch",
            "status": "modified",
            "additions": 150,
            "deletions": 5,
            "changes": 155,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -1,15 +1,160 @@\n+diff --git a/docs/sdy_dialect.md b/docs/sdy_dialect.md\n+index 8051d9c..72b3aa5 100755\n+--- a/docs/sdy_dialect.md\n++++ b/docs/sdy_dialect.md\n+@@ -1101,39 +1101,36 @@ Syntax:\n+ A mesh is a list of axes and an optional list of device IDs specifying the\n+ device ordering.\n+ \n+-If the list of axes is empty\n+-  - If the `device_ids` is not provided, it is an empty mesh.\n+-  - If the `device_ids` is provided, it must be a single non-negative\n+-    integer, we call it a **maximal-sharding mesh**.\n+-\n+-If the list of axes is provided\n+-  - If a device ID list is specified, the product of the axis sizes should\n+-    match the number of devices.\n+-  - If a device ID list is not specified, the implicit device ID list is\n+-    iota(product(axes)). For simplicity, we also disallow specifying a\n+-    device ID list that is the same as iota(product(axes)); in this case, a\n+-    device ID list shouldn't be specified.\n+-  - It is not a maximal-sharding mesh even if the total size of axes is 1.\n++If the list of axes is empty, the mesh has an implicit unnamed axis of\n++size 1. In this case, if a device ID list is not provided, the implicit\n++device ID list is [0]; if a device ID list is provided, it must\n++contains a single integer of any non-negative value. We call this\n++maximal-sharding case.\n++\n++For all non-maximal-sharding cases, if a device ID list is specified, the\n++product of the axis sizes should match the number of devices. If a device ID\n++list is not specified, the implicit device ID list is iota(product(axes)).\n++For simplicity, we also disallow specifying a device ID list that is the\n++same as iota(product(axes)); in this case, a device ID list shouldn't be\n++specified.\n+ \n+ Here are some examples of meshes:\n+ \n+ - An empty mesh represents a placeholder mesh that can be replaced during\n+   propagation: <[]>\n+-- A mesh without axes list and a single non-negative device ID, which is a\n+-  maximal-sharding mesh: <[], device_ids=[3]>\n++- A mesh with an unnamed axis and an explicit device ID, which is typically\n++  used to represent maximal sharding: <[], device_ids=[3]>\n+ - A mesh with two axes and implicit device IDs iota(6): <[\"a\"=2, \"b\"=3]>\n+ - A mesh with two axes and explicit device IDs specifying the device\n+   ordering: <[\"a\"=3, \"b\"=2], device_ids=[0, 2, 4, 1, 3, 5]>\n+ \n+ **Constraints:**\n+-- Elements in `device_ids` should be non-negative.\n+-- If `axes` is empty, the size of `device_ids` can be 0 (empty mesh) or 1\n+-  (maximal-sharding mesh).\n+-- If `axes` is not empty,\n+-    - Elements in `axes` must not have duplicate names.\n+-    - If `device_ids` is specified, the original `device_ids` is not\n+-      `iota(product(axis_sizes))` and the sorted `device_ids` is\n+-      `iota(product(axis_sizes))`.\n++- Elements in `axes` must not have duplicate names.\n++- If `device_ids` is specified:\n++  * The product of axis sizes must match the number of devices.\n++  * All of its elements must be non-negative.\n++  * `device_ids` should not be equal to `iota(product(axis_sizes))`.\n++  * Sorted `device_ids` must be `iota(product(axis_sizes))`.\n+ \n+ #### Parameters:\n+ \n+diff --git a/shardy/dialect/sdy/ir/attrs.td b/shardy/dialect/sdy/ir/attrs.td\n+index cde47d2..5bca49c 100644\n+--- a/shardy/dialect/sdy/ir/attrs.td\n++++ b/shardy/dialect/sdy/ir/attrs.td\n+@@ -54,39 +54,36 @@ def Sdy_Mesh : AttrDef<Sdy_Dialect, \"Mesh\"> {\n+     A mesh is a list of axes and an optional list of device IDs specifying the\n+     device ordering.\n+ \n+-    If the list of axes is empty\n+-      - If the `device_ids` is not provided, it is an empty mesh.\n+-      - If the `device_ids` is provided, it must be a single non-negative\n+-        integer, we call it a **maximal-sharding mesh**.\n+-\n+-    If the list of axes is provided\n+-      - If a device ID list is specified, the product of the axis sizes should\n+-        match the number of devices.\n+-      - If a device ID list is not specified, the implicit device ID list is\n+-        iota(product(axes)). For simplicity, we also disallow specifying a\n+-        device ID list that is the same as iota(product(axes)); in this case, a\n+-        device ID list shouldn't be specified.\n+-      - It is not a maximal-sharding mesh even if the total size of axes is 1.\n++    If the list of axes is empty, the mesh has an implicit unnamed axis of\n++    size 1. In this case, if a device ID list is not provided, the implicit\n++    device ID list is [0]; if a device ID list is provided, it must\n++    contains a single integer of any non-negative value. We call this\n++    maximal-sharding case.\n++\n++    For all non-maximal-sharding cases, if a device ID list is specified, the\n++    product of the axis sizes should match the number of devices. If a device ID\n++    list is not specified, the implicit device ID list is iota(product(axes)).\n++    For simplicity, we also disallow specifying a device ID list that is the\n++    same as iota(product(axes)); in this case, a device ID list shouldn't be\n++    specified.\n+ \n+     Here are some examples of meshes:\n+ \n+     - An empty mesh represents a placeholder mesh that can be replaced during\n+       propagation: <[]>\n+-    - A mesh without axes list and a single non-negative device ID, which is a\n+-      maximal-sharding mesh: <[], device_ids=[3]>\n++    - A mesh with an unnamed axis and an explicit device ID, which is typically\n++      used to represent maximal sharding: <[], device_ids=[3]>\n+     - A mesh with two axes and implicit device IDs iota(6): <[\"a\"=2, \"b\"=3]>\n+     - A mesh with two axes and explicit device IDs specifying the device\n+       ordering: <[\"a\"=3, \"b\"=2], device_ids=[0, 2, 4, 1, 3, 5]>\n+ \n+     **Constraints:**\n+-    - Elements in `device_ids` should be non-negative.\n+-    - If `axes` is empty, the size of `device_ids` can be 0 (empty mesh) or 1\n+-      (maximal-sharding mesh).\n+-    - If `axes` is not empty,\n+-        - Elements in `axes` must not have duplicate names.\n+-        - If `device_ids` is specified, the original `device_ids` is not\n+-          `iota(product(axis_sizes))` and the sorted `device_ids` is\n+-          `iota(product(axis_sizes))`.\n++    - Elements in `axes` must not have duplicate names.\n++    - If `device_ids` is specified:\n++      * The product of axis sizes must match the number of devices.\n++      * All of its elements must be non-negative.\n++      * `device_ids` should not be equal to `iota(product(axis_sizes))`.\n++      * Sorted `device_ids` must be `iota(product(axis_sizes))`.\n+   }];\n+   let parameters = (ins\n+       OptionalArrayRefParameter<\"MeshAxisAttr\", \"mesh axes\">:$axes,\n+diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch\n+index 509398d..75d72f7 100644\n+--- a/third_party/llvm/generated.patch\n++++ b/third_party/llvm/generated.patch\n+@@ -1 +1,12 @@\n+ Auto generated patch. Do not edit or delete it, even if empty.\n++diff -ruN --strip-trailing-cr a/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h b/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n++--- a/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n+++++ b/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n++@@ -18,7 +18,6 @@\n++ #include \"mlir/IR/Operation.h\"\n++ #include \"llvm/ADT/PointerUnion.h\"\n++ #include \"llvm/ADT/STLExtras.h\"\n++-#include \"llvm/Support/DebugLog.h\"\n++ #include \"llvm/Support/raw_ostream.h\"\n++ \n++ namespace mlir {\n diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl\n-index 93e7894..35aaef5 100644\n+index 35aaef5..655dc54 100644\n --- a/third_party/llvm/workspace.bzl\n +++ b/third_party/llvm/workspace.bzl\n @@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n  \n  def repo(name):\n      \"\"\"Imports LLVM.\"\"\"\n--    LLVM_COMMIT = \"d0a7411cb840d253f58a627cc3957fc7b5263a3d\"\n--    LLVM_SHA256 = \"b8bc83aa8b5ead53af8425786bba4aab9fb6c901d97dc33dc89924824d943234\"\n-+    LLVM_COMMIT = \"29c830cbf8c65fcab7f96f92c8466cbcc9924dd1\"\n-+    LLVM_SHA256 = \"a717cad48a81fcc96b310e5bd953a20c8c569a08e2a95594206bd8900a1df32d\"\n+-    LLVM_COMMIT = \"29c830cbf8c65fcab7f96f92c8466cbcc9924dd1\"\n+-    LLVM_SHA256 = \"a717cad48a81fcc96b310e5bd953a20c8c569a08e2a95594206bd8900a1df32d\"\n++    LLVM_COMMIT = \"028bfa255e90581d1c08237a66c20b25096277e8\"\n++    LLVM_SHA256 = \"b1e5fbb1ed51e8e22e1ecdf0d74e7b28b1c554bb507326df2172c0c4707de0f8\"\n  \n      tf_http_archive(\n          name = name,"
        },
        {
            "sha": "95aa87ecec76ee218e21d2263b2848645abe4b92",
            "filename": "third_party/xla/third_party/shardy/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -3,8 +3,8 @@\n load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n \n def repo():\n-    SHARDY_COMMIT = \"0d9d6e17427f801ec774316b07c4af8447b64700\"\n-    SHARDY_SHA256 = \"45af0f281bebd454395c33d518cdb64082d4bed2acb4bd99aed29b1f1ca64b24\"\n+    SHARDY_COMMIT = \"87e67beaafc4acde7f684d11ed813419597e7fc4\"\n+    SHARDY_SHA256 = \"76093dba30c6b21aeee349bfc6c6a3118cc35d31c46d7f38dcabaa3ae13f562e\"\n \n     tf_http_archive(\n         name = \"shardy\","
        },
        {
            "sha": "807507cbce4b75ad41e21f424895cf07ea9e314a",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl825373861.patch",
            "status": "added",
            "additions": 102,
            "deletions": 0,
            "changes": 102,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl825373861.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl825373861.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl825373861.patch?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -0,0 +1,102 @@\n+\n+--- a/lib/Analysis/Allocation.cpp\t2025-10-15 10:11:13.000000000 -0700\n++++ b/lib/Analysis/Allocation.cpp\t2025-10-28 22:48:41.000000000 -0700\n+@@ -16,6 +16,8 @@\n+ #include \"llvm/Support/Debug.h\"\n+ #include \"llvm/Support/raw_ostream.h\"\n+ \n++#undef LDBG\n++\n+ #define DEBUG_TYPE \"allocation-shared-memory\"\n+ #define DBGS() (llvm::dbgs() << \"[\" DEBUG_TYPE \"]: \")\n+ #define LDBG(X) LLVM_DEBUG(DBGS() << X << \"\\n\")\n+\n+--- a/lib/Analysis/AxisInfo.cpp\t2025-10-15 10:11:13.000000000 -0700\n++++ b/lib/Analysis/AxisInfo.cpp\t2025-10-28 22:48:41.000000000 -0700\n+@@ -9,6 +9,8 @@\n+ \n+ #include <numeric>\n+ \n++#undef LDBG\n++\n+ #define DEBUG_TYPE \"axis-info\"\n+ #define DBGS() (llvm::dbgs() << \"[\" DEBUG_TYPE \"]: \")\n+ #define LDBG(X) LLVM_DEBUG(DBGS() << X << \"\\n\")\n+\n+--- a/lib/Dialect/TritonGPU/IR/Ops.cpp\t2025-10-15 10:11:13.000000000 -0700\n++++ b/lib/Dialect/TritonGPU/IR/Ops.cpp\t2025-10-28 22:48:42.000000000 -0700\n+@@ -903,8 +903,9 @@\n+     return;\n+   }\n+   // And the default region branches transparently back to the parent.\n+-  assert(src.getRegionOrNull() == &getDefaultRegion());\n+-  successors.push_back(RegionSuccessor(getResults()));\n++  assert(src.getTerminatorPredecessorOrNull()->getParentRegion() ==\n++         &getDefaultRegion());\n++  successors.push_back(RegionSuccessor(getOperation(), getResults()));\n+ }\n+ \n+ LogicalResult WarpSpecializeOp::verify() {\n+\n+--- a/lib/Dialect/TritonGPU/Transforms/Utility.cpp\t2025-10-15 10:11:13.000000000 -0700\n++++ b/lib/Dialect/TritonGPU/Transforms/Utility.cpp\t2025-10-28 22:48:42.000000000 -0700\n+@@ -15,6 +15,8 @@\n+ #include \"triton/Dialect/TritonNvidiaGPU/IR/Dialect.h\"\n+ #include \"llvm/Support/Debug.h\"\n+ \n++#undef LDBG\n++\n+ #define DEBUG_TYPE \"ttg-utility\"\n+ #define DBGS() (llvm::dbgs() << \"[\" DEBUG_TYPE \"]: \")\n+ #define LDBG(X) LLVM_DEBUG(DBGS() << X << \"\\n\")\n+\n+--- a/lib/Dialect/TritonNvidiaGPU/Transforms/Utility.cpp\t2025-07-31 00:13:23.000000000 -0700\n++++ b/lib/Dialect/TritonNvidiaGPU/Transforms/Utility.cpp\t2025-10-28 22:48:42.000000000 -0700\n+@@ -1,5 +1,7 @@\n+ #include \"triton/Dialect/TritonNvidiaGPU/Transforms/Utility.h\"\n+ \n++#undef LDBG\n++\n+ #define DEBUG_TYPE \"ttng-utility\"\n+ #define DBGS() (llvm::dbgs() << \"[\" DEBUG_TYPE \"]: \")\n+ #define LDBG(X) LLVM_DEBUG(DBGS() << X << \"\\n\")\n+\n+--- a/third_party/amd/include/Analysis/RangeAnalysis.h\t2025-04-30 09:57:08.000000000 -0700\n++++ b/third_party/amd/include/Analysis/RangeAnalysis.h\t2025-10-29 06:16:49.000000000 -0700\n+@@ -78,7 +78,7 @@\n+   /// the loop operands and all users and all users of the results of the loop.\n+   void visitRegionSuccessors(\n+       ProgramPoint *point, RegionBranchOpInterface branch,\n+-      RegionBranchPoint successor,\n++      RegionSuccessor successor,\n+       ArrayRef<dataflow::AbstractSparseLattice *> abstractLattices) override;\n+ \n+   /// Collect all operands that participate in assumptions (see description of\n+\n+--- a/third_party/amd/lib/Analysis/RangeAnalysis.cpp\t2025-10-15 10:11:13.000000000 -0700\n++++ b/third_party/amd/lib/Analysis/RangeAnalysis.cpp\t2025-10-29 06:16:50.000000000 -0700\n+@@ -471,7 +471,7 @@\n+ \n+ void TritonIntegerRangeAnalysis::visitRegionSuccessors(\n+     ProgramPoint *point, RegionBranchOpInterface branch,\n+-    RegionBranchPoint successor,\n++    RegionSuccessor successor,\n+     ArrayRef<dataflow::AbstractSparseLattice *> abstractLattices) {\n+   LLVM_DEBUG({\n+     DBGS() << \"Inferring ranges for \";\n+@@ -535,10 +535,11 @@\n+         if (!inputs.empty()) {\n+           firstIndex = cast<OpResult>(inputs.front()).getResultNumber();\n+         }\n+-        visitNonControlFlowArguments(branch,\n+-                                     RegionSuccessor(branch->getResults().slice(\n+-                                         firstIndex, inputs.size())),\n+-                                     lattices, firstIndex);\n++        visitNonControlFlowArguments(\n++            branch,\n++            RegionSuccessor(\n++                branch, branch->getResults().slice(firstIndex, inputs.size())),\n++            lattices, firstIndex);\n+       } else {\n+         if (!inputs.empty()) {\n+           firstIndex = cast<BlockArgument>(inputs.front()).getArgNumber();"
        },
        {
            "sha": "77645a6c6417559ea6d188db3993b74d20a8711b",
            "filename": "third_party/xla/third_party/triton/llvm_integration/series.bzl",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -9,5 +9,6 @@ LLVM nor MLIR integrator, please do not add any patches to this list.\n \n llvm_patch_list = [\n     \"//third_party/triton:llvm_integration/cl823109577.patch\",\n+    \"//third_party/triton:llvm_integration/cl825373861.patch\",\n     # Add new patches just above this line\n ]"
        },
        {
            "sha": "6b598b2371cd3047bf217698d2ad240b4000ee99",
            "filename": "third_party/xla/xla/mlir_hlo/deallocation/transforms/buffer_reuse.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fdeallocation%2Ftransforms%2Fbuffer_reuse.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fdeallocation%2Ftransforms%2Fbuffer_reuse.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fdeallocation%2Ftransforms%2Fbuffer_reuse.cc?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -452,7 +452,9 @@ bool simplifyLoopDeallocs(Block& block) {\n \n     getAliases(RegionBranchPoint::parent());\n     for (auto& region : rbi->getRegions()) {\n-      getAliases(region);\n+      if (region.empty()) continue;\n+      getAliases(RegionBranchPoint(cast<RegionBranchTerminatorOpInterface>(\n+          region.front().getTerminator())));\n     }\n \n     for (auto it = eq.begin(), e = eq.end(); it != e; ++it) {"
        },
        {
            "sha": "dc5014afc09bd039168638a829ccaef99e5130de",
            "filename": "third_party/xla/xla/mlir_hlo/deallocation/utils/util.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 7,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fdeallocation%2Futils%2Futil.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ca3d7d630577ff2d88b347d987864ab3fe5df54e/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fdeallocation%2Futils%2Futil.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fdeallocation%2Futils%2Futil.cc?ref=ca3d7d630577ff2d88b347d987864ab3fe5df54e",
            "patch": "@@ -23,8 +23,13 @@ namespace deallocation {\n SmallVector<RegionEdge> getSuccessorRegions(RegionBranchOpInterface op,\n                                             RegionBranchPoint point) {\n   SmallVector<RegionEdge> edges;\n-  if (Region* region = point.getRegionOrNull()) {\n-    if (region->empty()) {\n+  auto* parentRegion =\n+      point.getTerminatorPredecessorOrNull()\n+          ? point.getTerminatorPredecessorOrNull()->getParentRegion()\n+          : nullptr;\n+\n+  if (parentRegion) {\n+    if (parentRegion->empty()) {\n       return edges;\n     }\n   }\n@@ -35,9 +40,8 @@ SmallVector<RegionEdge> getSuccessorRegions(RegionBranchOpInterface op,\n   for (const auto& successor : successors) {\n     auto& edge = edges.emplace_back();\n     edge.predecessorRegionPoint = point;\n-    auto* region = point.getRegionOrNull();\n-    edge.predecessorOp =\n-        region ? region->front().getTerminator() : op.getOperation();\n+    edge.predecessorOp = parentRegion ? parentRegion->front().getTerminator()\n+                                      : op.getOperation();\n     edge.predecessorOperandIndex = edge.predecessorOp->getNumOperands() -\n                                    successor.getSuccessorInputs().size();\n \n@@ -46,7 +50,9 @@ SmallVector<RegionEdge> getSuccessorRegions(RegionBranchOpInterface op,\n       edge.successorOpOrRegion = op.getOperation();\n       edge.successorValueIndex = 0;\n     } else {\n-      edge.successorRegionPoint = successor.getSuccessor();\n+      edge.successorRegionPoint =\n+          RegionBranchPoint(cast<RegionBranchTerminatorOpInterface>(\n+              successor.getSuccessor()->front().getTerminator()));\n       edge.successorOpOrRegion = successor.getSuccessor();\n       edge.successorValueIndex = llvm::isa<scf::ForOp>(op) ? 1 : 0;\n     }\n@@ -68,7 +74,8 @@ SmallVector<RegionEdge> getPredecessorRegions(RegionBranchOpInterface op,\n   };\n   checkPredecessor(point.parent());\n   for (Region& region : op->getRegions()) {\n-    checkPredecessor(region);\n+    checkPredecessor(RegionBranchPoint(cast<RegionBranchTerminatorOpInterface>(\n+        region.front().getTerminator())));\n   }\n   return result;\n }"
        }
    ],
    "stats": {
        "total": 396,
        "additions": 342,
        "deletions": 54
    }
}