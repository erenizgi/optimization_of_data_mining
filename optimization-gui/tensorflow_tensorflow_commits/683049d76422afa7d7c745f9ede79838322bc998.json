{
    "author": "ZixuanJiang",
    "message": "Refactor `PatternMatchMergeOrSplitSharding` by collecting two vectors of indices.\n\nPreviously, we use a switch to distinguish two cases, which is less readable. The new implementation is clearer and more readable.\n\nCognitive complexity: 38 -> 30\n\nPiperOrigin-RevId: 799780867",
    "sha": "683049d76422afa7d7c745f9ede79838322bc998",
    "files": [
        {
            "sha": "850022fd1a2604e23966b172fab974545443bbcb",
            "filename": "third_party/xla/xla/service/spmd/spmd_partitioner.cc",
            "status": "modified",
            "additions": 52,
            "deletions": 67,
            "changes": 119,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/683049d76422afa7d7c745f9ede79838322bc998/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/683049d76422afa7d7c745f9ede79838322bc998/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc?ref=683049d76422afa7d7c745f9ede79838322bc998",
            "patch": "@@ -2021,19 +2021,27 @@ PartitionedHlo PartitionedHlo::TryMultipleSourceTargetDims(\n \n namespace {\n \n-// Matching the following patterns, where X, Y, cannot be 1, Z can be 1.\n+std::tuple<HloSharding, HloSharding, int64_t> CreateSplitShardingTuple(\n+    const HloSharding& source, const HloSharding& target, int64_t dim,\n+    int64_t new_dim_size) {\n+  HloSharding split_source =\n+      hlo_sharding_util::SplitShardingDimension(source, dim, new_dim_size);\n+  HloSharding split_target =\n+      hlo_sharding_util::SplitShardingDimension(target, dim, new_dim_size);\n+  return std::make_tuple(std::move(split_source), std::move(split_target), dim);\n+}\n+\n+// Matching the following patterns, where X and Y cannot be 1, Z can be 1.\n // 1. [..,X,..,Y,..] -> [..,X*Y,..,1,..]\n // 2. [..,Y,..,X,..] -> [..,1,..,X*Y,..]\n-// 3. [..,X*Y,..,Z,..] -> [..,X,..,Y*Z,..]\n-// 4. [..,Z,..,X*Y,..] -> [..,Y*Z,..,X,..]\n+// 3. [..,X*Y,..,Z,..] -> [..,X,..,Y,..]\n+// 4. [..,Z,..,X*Y,..] -> [..,Y,..,X,..]\n // Output tuple:\n-// - HloSharding: The original sharding with an extra dimension added of size 1\n-// or Y.\n-// - HloSharding: The sharding with the new dimension added moved in the place\n-// where we expect the target dimension to be.\n+// - HloSharding: Split source sharding with the new dimension added.\n+// - HloSharding: Split target sharding with the new dimension added.\n // - int64_t: The index of X.\n std::optional<std::tuple<HloSharding, HloSharding, int64_t>>\n-PatternMatchMergeOrSplitSharding(const Shape& shape, const Shape& base_shape,\n+PatternMatchMergeOrSplitSharding(const Shape& base_shape,\n                                  const HloSharding& source,\n                                  const HloSharding& target) {\n   if (!source.IsTiled() || !target.IsTiled()) {\n@@ -2049,7 +2057,11 @@ PatternMatchMergeOrSplitSharding(const Shape& shape, const Shape& base_shape,\n     return std::nullopt;\n   }\n \n-  std::vector<int64_t> diff_index;\n+  // Collect dimension indices with different tile assignment sizes.\n+  // 1. diff_index_1: one of the source/target tile_assignment dimension is 1.\n+  // 2. diff_index_2: two tile assignment dimensions are not 1.\n+  std::vector<int64_t> diff_index_1;\n+  std::vector<int64_t> diff_index_2;\n   for (int64_t i = 0; i < target.TiledDataRank(); ++i) {\n     int64_t si = source.tile_assignment().dim(i);\n     int64_t ti = target.tile_assignment().dim(i);\n@@ -2058,7 +2070,7 @@ PatternMatchMergeOrSplitSharding(const Shape& shape, const Shape& base_shape,\n     }\n     auto [min, max] = std::minmax(si, ti);\n     if (min == 1) {\n-      diff_index.push_back(i);\n+      diff_index_1.push_back(i);\n       continue;\n     }\n     if (max % min != 0) {\n@@ -2067,63 +2079,36 @@ PatternMatchMergeOrSplitSharding(const Shape& shape, const Shape& base_shape,\n     if (CeilOfRatio(base_shape.dimensions(i), min) * min % max != 0) {\n       continue;\n     }\n-    diff_index.push_back(i);\n-  }\n-\n-  // Iterate every pair of elements in diff_index.\n-  for (int64_t diff_index_i = 0; diff_index_i < diff_index.size();\n-       ++diff_index_i) {\n-    for (int64_t diff_index_j = diff_index_i + 1;\n-         diff_index_j < diff_index.size(); ++diff_index_j) {\n-      int64_t i = diff_index[diff_index_i];\n-      int64_t j = diff_index[diff_index_j];\n-      const std::vector<bool> is_one = {source.tile_assignment().dim(i) == 1,\n-                                        source.tile_assignment().dim(j) == 1,\n-                                        target.tile_assignment().dim(i) == 1,\n-                                        target.tile_assignment().dim(j) == 1};\n-      int64_t new_dim_size;\n-      switch (std::count(is_one.begin(), is_one.end(), true)) {\n-        case 1: {\n-          if (source.tile_assignment().dim(i) *\n-                  source.tile_assignment().dim(j) !=\n-              target.tile_assignment().dim(i) *\n-                  target.tile_assignment().dim(j)) {\n-            continue;\n-          }\n-          if (source.tile_assignment().dim(i) == 1 ||\n-              target.tile_assignment().dim(i) == 1) {\n-            std::swap(i, j);\n-            // After the swap, we always have the following.\n-            // i is the dimension without size 1 in either source or target\n-            // j is the dimension with size 1 in either source or target\n-          }\n-          new_dim_size = std::min(source.tile_assignment().dim(i),\n-                                  target.tile_assignment().dim(i));\n-          break;\n-        }\n-        case 0: {\n-          if (source.tile_assignment().dim(i) <\n-              target.tile_assignment().dim(i)) {\n-            std::swap(i, j);\n-          }\n-          if (source.tile_assignment().dim(i) !=\n-              target.tile_assignment().dim(i) *\n-                  target.tile_assignment().dim(j)) {\n-            continue;\n-          }\n-          new_dim_size = target.tile_assignment().dim(i);\n-          break;\n-        }\n-        default:\n-          continue;\n+    diff_index_2.push_back(i);\n+  }\n+\n+  // Iterate combination of diff_index_1 and diff_index_2.\n+  for (int64_t i : diff_index_2) {\n+    for (int64_t j : diff_index_1) {\n+      if (source.tile_assignment().dim(i) * source.tile_assignment().dim(j) !=\n+          target.tile_assignment().dim(i) * target.tile_assignment().dim(j)) {\n+        continue;\n       }\n+      int64_t new_dim_size = std::min(source.tile_assignment().dim(i),\n+                                      target.tile_assignment().dim(i));\n+      return CreateSplitShardingTuple(source, target, i, new_dim_size);\n+    }\n+  }\n \n-      HloSharding reshaped_sharding =\n-          hlo_sharding_util::SplitShardingDimension(source, i, new_dim_size);\n-      HloSharding new_sharding =\n-          hlo_sharding_util::SplitShardingDimension(target, i, new_dim_size);\n-      return std::make_tuple(std::move(reshaped_sharding),\n-                             std::move(new_sharding), i);\n+  // Iterate combination of diff_index_2 and diff_index_2.\n+  for (auto it_i = diff_index_2.begin(); it_i != diff_index_2.end(); ++it_i) {\n+    for (auto it_j = std::next(it_i); it_j != diff_index_2.end(); ++it_j) {\n+      int64_t i = *it_i;\n+      int64_t j = *it_j;\n+      if (source.tile_assignment().dim(i) < target.tile_assignment().dim(i)) {\n+        std::swap(i, j);\n+      }\n+      if (source.tile_assignment().dim(i) !=\n+          target.tile_assignment().dim(i) * target.tile_assignment().dim(j)) {\n+        continue;\n+      }\n+      return CreateSplitShardingTuple(source, target, i,\n+                                      target.tile_assignment().dim(i));\n     }\n   }\n \n@@ -2218,8 +2203,8 @@ std::optional<PartitionedHlo> PartitionedHlo::TryComplexReshardHandling(\n   const bool is_source_partially_replicated =\n       sharding().ReplicateOnLastTileDim();\n   const bool is_target_partially_replicated = target.ReplicateOnLastTileDim();\n-  if (auto reshape = PatternMatchMergeOrSplitSharding(\n-          this->hlo()->shape(), this->base_shape(), sharding(), target)) {\n+  if (auto reshape = PatternMatchMergeOrSplitSharding(this->base_shape(),\n+                                                      sharding(), target)) {\n     auto& [before_sharding, new_reshaped_sharding, source_dim] = *reshape;\n     PartitionedHlo reshaped = SplitReshapeHelper(\n         *this, source_dim, this->hlo()->shape().dimensions(source_dim),"
        }
    ],
    "stats": {
        "total": 119,
        "additions": 52,
        "deletions": 67
    }
}