{
    "author": "hawkinsp",
    "message": "[PJRT] Remove the .start field on transpose plan Nodes.\n\nInstead, accumulate a per-chunk offset and apply that once at the start of execution.\n\nThis is also intended as a refactoring, but it may have small impacts on transpose performance since we have essentially moved some scalar math out of the inner loops.\n\nPiperOrigin-RevId: 846484673",
    "sha": "968bb7de374fc0a279e6d460c85f6b04a78053dc",
    "files": [
        {
            "sha": "6ad578d667866e94dc7ae7776b51f0ee66627df2",
            "filename": "third_party/xla/xla/pjrt/transpose.cc",
            "status": "modified",
            "additions": 54,
            "deletions": 64,
            "changes": 118,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/968bb7de374fc0a279e6d460c85f6b04a78053dc/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/968bb7de374fc0a279e6d460c85f6b04a78053dc/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.cc?ref=968bb7de374fc0a279e6d460c85f6b04a78053dc",
            "patch": "@@ -120,9 +120,8 @@ static constexpr int kMaxInnerBlockSizeBytes = 16;\n // A plan is a data structure that describes a loop nest.\n // TODO(phawkins): consider shrinking Node so it fits in a cache line.\n struct TransposePlan::Node {\n-  // The loop should iterate over the index space range(start, end, inc).\n+  // The loop should iterate over the index space range(0, end, inc).\n   // These fields are ignored by the macrokernel.\n-  int64_t start;\n   int64_t end;  // For the inner loop of a memcpy loop nest, this is the size of\n                 // the transfer.\n   int64_t inc;  // The transpose sentinel node has inc < 0.\n@@ -203,7 +202,6 @@ void Transpose(const char* __restrict a, int outer_bs_a, char* __restrict b,\n   DVLOG(10) << \"Transpose \" << outer_bs_a << \" \" << outer_bs_b;\n   DCHECK_GT(outer_bs_a, 0);\n   DCHECK_GT(outer_bs_b, 0);\n-  const int64_t start = node->start;\n   const int64_t end = node->end;\n   const int64_t stop = node->end - (node->inc - 1);\n   const int64_t lda = node->lda;\n@@ -217,7 +215,7 @@ void Transpose(const char* __restrict a, int outer_bs_a, char* __restrict b,\n     const int64_t lda_block = next_node->lda;\n     const int64_t ldb_block = next_node->ldb;\n     int64_t i;\n-    for (i = start; i < stop; i += inc) {\n+    for (i = 0; i < stop; i += inc) {\n       MacroKernel<T, inner_bs, transformation>(a + i * lda, lda_block,\n                                                outer_bs_a, b + i * ldb,\n                                                ldb_block, outer_bs_b, scratch);\n@@ -281,7 +279,7 @@ void Transpose(const char* __restrict a, int outer_bs_a, char* __restrict b,\n     // inner loops. Structurally this code is identical to the previous case,\n     // but we call Transpose() recursively instead of MacroKernel().\n     int64_t i;\n-    for (i = start; i < stop; i += inc) {\n+    for (i = 0; i < stop; i += inc) {\n       Transpose<T, inner_bs, transformation>(\n           a + i * lda, outer_bs_a, b + i * ldb, outer_bs_b, next_node, scratch);\n     }\n@@ -335,59 +333,44 @@ void Transpose(const char* __restrict a, int outer_bs_a, char* __restrict b,\n \n void TransposeConstStride1(const char* __restrict a, char* __restrict b,\n                            TransposePlan::Node const* __restrict node) {\n-  a += node[0].start * node[0].lda;\n-  b += node[0].start * node[0].ldb;\n   if (node[0].is_inner_dim_in_a) {\n     int64_t num_bytes = node->end;\n     std::memcpy(b, a, num_bytes);\n   } else if (node[1].is_inner_dim_in_a) {\n-    int64_t offset_a = node[1].start * node[1].lda;\n-    int64_t offset_b = node[1].start * node[1].ldb;\n     int64_t num_bytes = node[1].end;\n-    a += offset_a;\n-    b += offset_b;\n-    for (int64_t i = node[0].start; i < node[0].end; ++i) {\n+    for (int64_t i = 0; i < node[0].end; ++i) {\n       std::memcpy(b, a, num_bytes);\n       a += node[0].lda;\n       b += node[0].ldb;\n     }\n     if (node[0].trailing_tile_next_node_inc) {\n-      TransposeConstStride1(a - offset_a, b - offset_b,\n-                            node + node[0].trailing_tile_next_node_inc);\n+      TransposeConstStride1(a, b, node + node[0].trailing_tile_next_node_inc);\n     }\n   } else if (node[2].is_inner_dim_in_a) {\n     int64_t num_bytes = node[2].end;\n-    int64_t offset_a1 = node[1].start * node[1].lda;\n-    int64_t offset_b1 = node[1].start * node[1].ldb;\n-    int64_t offset_a2 = node[2].start * node[2].lda;\n-    int64_t offset_b2 = node[2].start * node[2].ldb;\n-    a += offset_a1 + offset_a2;\n-    b += offset_b1 + offset_b2;\n-    for (int64_t i = node[0].start; i < node[0].end; ++i) {\n+    for (int64_t i = 0; i < node[0].end; ++i) {\n       const char* a1 = a;\n       char* b1 = b;\n-      for (int64_t j = node[1].start; j < node[1].end; ++j) {\n+      for (int64_t j = 0; j < node[1].end; ++j) {\n         std::memcpy(b1, a1, num_bytes);\n         a1 += node[1].lda;\n         b1 += node[1].ldb;\n       }\n       if (node[1].trailing_tile_next_node_inc) {\n-        TransposeConstStride1(a1 - offset_a2, b1 - offset_b2,\n+        TransposeConstStride1(a1, b1,\n                               &node[1] + node[1].trailing_tile_next_node_inc);\n       }\n       a += node[0].lda;\n       b += node[0].ldb;\n     }\n     if (node[0].trailing_tile_next_node_inc) {\n-      TransposeConstStride1(a - offset_a1 - offset_a2,\n-                            b - offset_b1 - offset_b2,\n-                            node + node[0].trailing_tile_next_node_inc);\n+      TransposeConstStride1(a, b, node + node[0].trailing_tile_next_node_inc);\n     }\n   } else {\n-    for (int64_t i = node[0].start; i < node[0].end; ++i) {\n-      const char* a1 = a + node[1].start * node[1].lda;\n-      char* b1 = b + node[1].start * node[1].ldb;\n-      for (int64_t j = node[1].start; j < node[1].end; ++j) {\n+    for (int64_t i = 0; i < node[0].end; ++i) {\n+      const char* a1 = a;\n+      char* b1 = b;\n+      for (int64_t j = 0; j < node[1].end; ++j) {\n         TransposeConstStride1(a1, b1, node + 2);\n         a1 += node[1].lda;\n         b1 += node[1].ldb;\n@@ -468,10 +451,12 @@ void TransposePlan::Execute(\n   }\n   tsl::profiler::TraceMe traceme(\"Transpose::Execute\", /*level=*/2);\n \n-  const char* ac = static_cast<const char*>(a);\n-  char* bc = static_cast<char*>(b);\n+  auto execute_by_type = [&](int chunk_id) {\n+    const char* ac =\n+        static_cast<const char*>(a) + input_offset_bytes_[chunk_id];\n+    char* bc = static_cast<char*>(b) + output_offset_bytes_[chunk_id];\n \n-  auto execute_by_type = [&](absl::Span<Node const> nodes) {\n+    absl::Span<Node const> nodes = nodes_[chunk_id];\n     if (inner_kernel_is_memcpy_) {\n       DCHECK(transformation_ == Transformation::kNone);\n       // Memcpy-based plans all assume element size 1 (i.e., bytes).\n@@ -506,20 +491,19 @@ void TransposePlan::Execute(\n   };\n \n   if (!schedule_work || nodes_.size() <= 1) {\n-    for (const auto& nodes : nodes_) {\n-      execute_by_type(nodes);\n+    for (int i = 0; i < nodes_.size(); ++i) {\n+      execute_by_type(i);\n     }\n   } else {\n     absl::BlockingCounter counter(nodes_.size() - 1);\n-    for (size_t i = 1; i < nodes_.size(); ++i) {\n-      absl::Span<Node const> nodes = nodes_[i];\n-      (*schedule_work)([&, nodes]() {\n-        execute_by_type(nodes);\n+    for (int i = 1; i < nodes_.size(); ++i) {\n+      (*schedule_work)([&, i]() {\n+        execute_by_type(i);\n         counter.DecrementCount();\n       });\n     }\n     // Run the first chunk inline in this thread.\n-    execute_by_type(nodes_[0]);\n+    execute_by_type(0);\n     counter.Wait();\n   }\n }\n@@ -634,7 +618,7 @@ void TransposePlan::BuildPlanNodes(int chunk_id,\n                       absl::InlinedVector<bool, 4>(ndim, false)});\n \n   auto loop_has_trivial_iteration_space = [](const Node& node) {\n-    return node.start == 0 && node.start + node.inc == node.end;\n+    return node.inc == node.end;\n   };\n \n   while (!agenda.empty()) {\n@@ -655,7 +639,7 @@ void TransposePlan::BuildPlanNodes(int chunk_id,\n       // value, that describes the striding of the inner transpose kernel.\n       if (!inner_kernel_is_memcpy_) {\n         Node node;\n-        node.start = node.end = node.inc = -1;\n+        node.end = node.inc = -1;\n         node.lda = sentinel_lda_;\n         node.ldb = sentinel_ldb_;\n         nodes.push_back(node);\n@@ -689,11 +673,10 @@ void TransposePlan::BuildPlanNodes(int chunk_id,\n       CHECK(loop.start % node.inc == 0)\n           << \"loop.start=\" << loop.start\n           << \" must be aligned to node.inc=\" << node.inc;\n-      node.start = loop.start;\n-      node.end = std::min<int64_t>(size, loop.end);\n+      node.end = std::min<int64_t>(size, loop.end) - loop.start;\n \n       if (node.is_inner_dim_in_a && inner_kernel_is_memcpy_) {\n-        node.end = (node.end - node.start) * elem_size_in_bytes_;\n+        node.end *= elem_size_in_bytes_;\n       }\n \n       if (!loop_has_trivial_iteration_space(node) ||\n@@ -736,11 +719,10 @@ void TransposePlan::BuildPlanNodes(int chunk_id,\n \n       // loop.start and loop.end are in tile units.\n       int64_t num_tiles = partial ? 1 : num_complete_tiles;\n-      node.start = loop.start;\n-      node.end = std::min<int64_t>(num_tiles, loop.end);\n+      node.end = std::min<int64_t>(num_tiles, loop.end) - loop.start;\n \n       if (node.is_inner_dim_in_a && inner_kernel_is_memcpy_) {\n-        node.end = (node.end - node.start) * elem_size_in_bytes_;\n+        node.end *= elem_size_in_bytes_;\n       }\n \n       // If this loop has a trivial iteration space, drop it.\n@@ -1110,7 +1092,8 @@ void TransposePlan::Initialize() {\n       << ToString();\n \n   int num_chunks = ChooseParallelizationStrategy(loop_order);\n-  chunk_loops_ = PartitionLoops(num_chunks, loop_order);\n+  PartitionLoops(num_chunks, loop_order, chunk_loops_, input_offset_bytes_,\n+                 output_offset_bytes_);\n   nodes_.resize(num_chunks);\n   for (int chunk_id = 0; chunk_id < num_chunks; ++chunk_id) {\n     BuildPlanNodes(chunk_id, nodes_[chunk_id]);\n@@ -1203,13 +1186,16 @@ int TransposePlan::ChooseParallelizationStrategy(\n   return num_chunks;\n }\n \n-std::vector<std::vector<TransposePlan::Loop>> TransposePlan::PartitionLoops(\n-    int num_chunks, const std::vector<Loop>& loop_order) {\n-  std::vector<std::vector<Loop>> result(num_chunks);\n+/*static*/ void TransposePlan::PartitionLoops(\n+    int num_chunks, const std::vector<Loop>& loop_order,\n+    std::vector<std::vector<TransposePlan::Loop>>& result,\n+    std::vector<int64_t>& input_offset_bytes,\n+    std::vector<int64_t>& output_offset_bytes) {\n+  // Copy the base loop order for each chunk.\n+  result.resize(num_chunks, loop_order);\n+  input_offset_bytes.resize(num_chunks);\n+  output_offset_bytes.resize(num_chunks);\n   for (int chunk_id = 0; chunk_id < num_chunks; ++chunk_id) {\n-    // Copy the base loop order for this chunk.\n-    result[chunk_id] = loop_order;\n-\n     // For each loop, narrow the start/end bounds to this chunk's portion.\n     int task_id_remaining = chunk_id;\n     int num_tasks_remaining = num_chunks;\n@@ -1233,10 +1219,10 @@ std::vector<std::vector<TransposePlan::Loop>> TransposePlan::PartitionLoops(\n       chunk_loop.end =\n           base_loop.start +\n           std::min(iterations, (task_id + 1) * iterations_per_task);\n+      input_offset_bytes[chunk_id] += chunk_loop.start * chunk_loop.lda;\n+      output_offset_bytes[chunk_id] += chunk_loop.start * chunk_loop.ldb;\n     }\n   }\n-\n-  return result;\n }\n \n std::string TransposePlan::ToString() const {\n@@ -1249,9 +1235,9 @@ std::string TransposePlan::ToString() const {\n                   absl::StrAppendFormat(\n                       out,\n                       \"    \"\n-                      \"Node(start=%d,end=%d,inc=%d,lda=%\"\n+                      \"Node(end=%d,inc=%d,lda=%\"\n                       \"d,ldb=%d,next_trailing=%d,inner_a=%s,inner_b=%s)\",\n-                      node.start, node.end, node.inc, node.lda, node.ldb,\n+                      node.end, node.inc, node.lda, node.ldb,\n                       node.trailing_tile_next_node_inc,\n                       node.is_inner_dim_in_a ? \"y\" : \"n\",\n                       node.is_inner_dim_in_b ? \"y\" : \"n\");\n@@ -1262,11 +1248,15 @@ std::string TransposePlan::ToString() const {\n                           loop.tile_interior ? \"[tile]\" : \"\", loop.start,\n                           loop.end, loop.parallelism);\n   };\n-  std::string chunk_loops_str = absl::StrJoin(\n-      chunk_loops_, \"\\n\",\n-      [&](std::string* out, const std::vector<Loop>& loops) {\n-        absl::StrAppend(out, \"    \", absl::StrJoin(loops, \", \", format_loop));\n-      });\n+  std::vector<std::string> chunk_strings;\n+  chunk_strings.reserve(chunk_loops_.size());\n+  for (int i = 0; i < chunk_loops_.size(); ++i) {\n+    chunk_strings.push_back(absl::StrFormat(\n+        \"    chunk %d: input_offset=%d output_offset=%d loops=%s\", i,\n+        input_offset_bytes_[i], output_offset_bytes_[i],\n+        absl::StrJoin(chunk_loops_[i], \", \", format_loop)));\n+  }\n+  std::string chunk_loops_str = absl::StrJoin(chunk_strings, \"\\n\");\n   std::string transformation_str;\n   switch (transformation_) {\n     case Transformation::kNone:"
        },
        {
            "sha": "44926cfe82ae62e5d357081328a69b435018df61",
            "filename": "third_party/xla/xla/pjrt/transpose.h",
            "status": "modified",
            "additions": 9,
            "deletions": 2,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/968bb7de374fc0a279e6d460c85f6b04a78053dc/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/968bb7de374fc0a279e6d460c85f6b04a78053dc/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.h?ref=968bb7de374fc0a279e6d460c85f6b04a78053dc",
            "patch": "@@ -200,8 +200,11 @@ class TransposePlan {\n   // Creates per-chunk loop vectors by splitting loop_order_ into per-chunk\n   // loops. Returns a vector of loop vectors, one per chunk. Each chunk's\n   // loops have their start/end bounds narrowed to represent that chunk's work.\n-  std::vector<std::vector<Loop>> PartitionLoops(\n-      int num_chunks, const std::vector<Loop>& loop_order);\n+  static void PartitionLoops(\n+      int num_chunks, const std::vector<Loop>& loop_order,\n+      std::vector<std::vector<TransposePlan::Loop>>& result,\n+      std::vector<int64_t>& input_offset_bytes,\n+      std::vector<int64_t>& output_offset_bytes);\n \n   // The signature of ExecuteTyped uses char* pointers because we perform\n   // address calculations with strides in bytes; the strides need not be\n@@ -252,6 +255,10 @@ class TransposePlan {\n   // representing one chunk of the work.\n   std::vector<std::vector<Loop>> chunk_loops_;\n \n+  // Per-chunk byte offsets into the input and output arrays.\n+  std::vector<int64_t> input_offset_bytes_;\n+  std::vector<int64_t> output_offset_bytes_;\n+\n   // Root nodes of the plan, i.e., pointing to the outermost loops in the loop\n   // nest. The outer vector is indexed on the thread ID.\n   absl::InlinedVector<std::vector<Node>, 1> nodes_;"
        }
    ],
    "stats": {
        "total": 129,
        "additions": 63,
        "deletions": 66
    }
}