{
    "author": "basioli-k",
    "message": "[XLA:GPU][host offloading] Ignore memory spaces in shapes when constructing call frame.\n\nPiperOrigin-RevId: 797787456",
    "sha": "b26565fba773bda682279512427d4056b0d83155",
    "files": [
        {
            "sha": "41222d80ce4a56788f814d94fa09be34a2f7fd53",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_execute_thunk.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 3,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b26565fba773bda682279512427d4056b0d83155/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b26565fba773bda682279512427d4056b0d83155/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc?ref=b26565fba773bda682279512427d4056b0d83155",
            "patch": "@@ -78,6 +78,16 @@ bool IsBufferOnDevice(se::Stream* stream, const void* ptr) {\n   return memory_type.ok() && *memory_type == se::MemoryType::kDevice;\n }\n \n+// We ignore memory spaces in shape comparison since the memory can be on device\n+// or host, and both are valid for the host offloading case.\n+// If the memory is on device we copy it to host memory, and if it is on host\n+// memory we use it as is.\n+bool CompareShapesIgnoringMemorySpace(const Shape& shape1,\n+                                      const Shape& shape2) {\n+  auto eq = Shape::Equal().IgnoreMemorySpaceInLayout();\n+  return eq(shape1, shape2);\n+}\n+\n class HostExecuteCallFrame {\n  public:\n   static absl::StatusOr<HostExecuteCallFrame> Create(\n@@ -133,7 +143,8 @@ absl::Status HostExecuteCallFrame::ValidateArgsAndResults(\n   }\n \n   for (int i = 0; i < args.size(); ++i) {\n-    if (args[i].shape != program_shape.parameters(i)) {\n+    if (!CompareShapesIgnoringMemorySpace(args[i].shape,\n+                                          program_shape.parameters(i))) {\n       return InvalidArgument(\n           \"Argument shape %s does not match program shape %s.\",\n           args[i].shape.ToString(/*print_layout=*/true),\n@@ -145,7 +156,8 @@ absl::Status HostExecuteCallFrame::ValidateArgsAndResults(\n \n   if (program_result_shape.IsTuple()) {\n     for (int i = 0; i < results.size(); ++i) {\n-      if (results[i].shape != program_result_shape.tuple_shapes(i)) {\n+      if (!CompareShapesIgnoringMemorySpace(\n+              results[i].shape, program_result_shape.tuple_shapes(i))) {\n         return InvalidArgument(\n             \"Result shape %s does not match program shape %s at index %d.\",\n             results[i].shape.ToString(/*print_layout=*/true),\n@@ -167,7 +179,8 @@ absl::Status HostExecuteCallFrame::ValidateArgsAndResults(\n         program_result_shape.ToString(/*print_layout=*/true), results.size());\n   }\n \n-  if (results[0].shape != program_shape.result()) {\n+  if (!CompareShapesIgnoringMemorySpace(results[0].shape,\n+                                        program_shape.result())) {\n     return InvalidArgument(\n         \"Result shape %s does not match program shape %s.\",\n         results[0].shape.ToString(/*print_layout=*/true),"
        }
    ],
    "stats": {
        "total": 19,
        "additions": 16,
        "deletions": 3
    }
}