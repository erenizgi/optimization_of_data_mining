{
    "author": "tensorflower-gardener",
    "message": "* Adds flag `tf_serialize_mlir_to_compressed_bytecode` to serialize to compressed bytecode.\n* Deserializing MLIR modules still tries to parse as string first as thats the default, on failure it tries to uncompress and parse.\n\nPiperOrigin-RevId: 820396326",
    "sha": "1f3321fa67ff21702a3a818a9e22342afd11d82a",
    "files": [
        {
            "sha": "f0fba59ec47b121b6d3d1767f53d053b7a455bec",
            "filename": "tensorflow/compiler/jit/flags.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fjit%2Fflags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fjit%2Fflags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fflags.cc?ref=1f3321fa67ff21702a3a818a9e22342afd11d82a",
            "patch": "@@ -291,6 +291,7 @@ void AllocateAndParseFlags() {\n   // Dump graphs in TFG dialect.\n   bool use_tfg_graph_dumper = false;\n   bool enable_tpu_variable_runtime_reformatting_pass = true;\n+  bool enable_serialize_mlir_to_compressed_bytecode = false;\n \n   flag_list = new std::vector<Flag>(\n       {Flag(\"tf_xla_enable_lazy_compilation\",\n@@ -405,7 +406,10 @@ void AllocateAndParseFlags() {\n             &enable_tpu_variable_runtime_reformatting_pass,\n             \"Enables TPUVariableRuntimeReformatting pass for MLIR-Based \"\n             \"TensorFlow Compiler Bridge. This enables weight update sharding \"\n-            \"and creates TPUReshardVariables ops.\")});\n+            \"and creates TPUReshardVariables ops.\")}),\n+  Flag(\"tf_serialize_mlir_to_compressed_bytecode\",\n+       &enable_serialize_mlir_to_compressed_bytecode,\n+       \"If true, serialize MLIR to compressed bytecode.\");\n \n   AppendMarkForCompilationPassFlagsInternal(flag_list);\n   xla::ParseFlagsFromEnvAndDieIfUnknown(\"TF_XLA_FLAGS\", *flag_list);\n@@ -434,6 +438,8 @@ void AllocateAndParseFlags() {\n       enable_mlir_multiple_local_cpu_devices;\n   mlir_flags->tf_mlir_enable_debug_info_serialization =\n       enable_mlir_debug_info_serialization;\n+  mlir_flags->tf_serialize_mlir_to_compressed_bytecode =\n+      enable_serialize_mlir_to_compressed_bytecode;\n \n   if (use_tfg_graph_dumper) {\n     UseMlirForGraphDump(MlirDumpConfig{}.elide_large_attributes().emit_dialect("
        },
        {
            "sha": "3561551f363ac6ce50ab66e1bedb25c4bb149890",
            "filename": "tensorflow/compiler/jit/flags.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fjit%2Fflags.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fjit%2Fflags.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fflags.h?ref=1f3321fa67ff21702a3a818a9e22342afd11d82a",
            "patch": "@@ -299,6 +299,7 @@ struct MlirCommonFlags {\n   // with different local CPU devices settings.\n   bool tf_mlir_enable_multiple_local_cpu_devices;\n   bool tf_mlir_enable_debug_info_serialization;\n+  bool tf_serialize_mlir_to_compressed_bytecode;\n };\n \n // Flags for the JitRt pipeline -- see tf_jitrt_pipeline.h for details."
        },
        {
            "sha": "cbd6bc3b2835046ee23b6a6a4a8bcb4460ba4b70",
            "filename": "tensorflow/compiler/mlir/tensorflow/BUILD",
            "status": "modified",
            "additions": 19,
            "deletions": 2,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2FBUILD?ref=1f3321fa67ff21702a3a818a9e22342afd11d82a",
            "patch": "@@ -962,12 +962,18 @@ cc_library(\n     hdrs = [\"utils/deserialize_mlir_module_utils.h\"],\n     deps = [\n         \":error_util\",\n-        \"//tensorflow/core/platform:status\",\n+        \"//tensorflow/core:lib\",\n+        \"//tensorflow/core:lib_headers_for_pybind\",\n+        \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/strings\",\n         \"@llvm-project//llvm:Support\",\n         \"@llvm-project//mlir:IR\",\n         \"@llvm-project//mlir:Parser\",\n         \"@local_xla//xla:status_macros\",\n+        \"@local_xla//xla/tsl/lib/io:inputstream_interface\",\n+        \"@local_xla//xla/tsl/lib/io:zlib_compression_options\",\n+        \"@local_xla//xla/tsl/lib/io:zlib_inputstream\",\n     ],\n )\n \n@@ -976,17 +982,28 @@ cc_library(\n     srcs = [\"utils/serialize_mlir_module_utils.cc\"],\n     hdrs = [\"utils/serialize_mlir_module_utils.h\"],\n     deps = [\n-        \"//tensorflow/compiler/jit:flags\",\n         \"//tensorflow/compiler/jit:flags_headers\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:string_view\",\n         \"@llvm-project//llvm:Support\",\n+        \"@llvm-project//mlir:BytecodeWriter\",\n         \"@llvm-project//mlir:IR\",\n+        \"@llvm-project//mlir:Support\",\n+        \"@local_xla//xla/tsl/lib/io:zlib_compression_options\",\n+        \"@local_xla//xla/tsl/lib/io:zlib_outputbuffer\",\n+        \"@local_xla//xla/tsl/platform:env\",\n+        \"@local_xla//xla/tsl/platform:errors\",\n     ],\n )\n \n tf_cc_test(\n     name = \"serialize_mlir_module_utils_test\",\n     srcs = [\"utils/serialize_mlir_module_utils_test.cc\"],\n     deps = [\n+        \":deserialize_mlir_module_utils\",\n         \":serialize_mlir_module_utils\",\n         \"//tensorflow/compiler/jit:flags\",\n         \"//tensorflow/core:test\","
        },
        {
            "sha": "bcd3164cd10f7c0023d42f2d8b925d207e9d0681",
            "filename": "tensorflow/compiler/mlir/tensorflow/utils/deserialize_mlir_module_utils.cc",
            "status": "modified",
            "additions": 93,
            "deletions": 7,
            "changes": 100,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fdeserialize_mlir_module_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fdeserialize_mlir_module_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fdeserialize_mlir_module_utils.cc?ref=1f3321fa67ff21702a3a818a9e22342afd11d82a",
            "patch": "@@ -15,16 +15,71 @@ limitations under the License.\n \n #include \"tensorflow/compiler/mlir/tensorflow/utils/deserialize_mlir_module_utils.h\"\n \n+#include <climits>\n+#include <cstddef>\n+#include <cstdint>\n+#include <cstring>\n+#include <memory>\n+#include <string>\n+\n+#include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/strings/str_cat.h\"\n #include \"llvm/ADT/StringRef.h\"\n #include \"mlir/IR/BuiltinOps.h\"  // from @llvm-project\n #include \"mlir/IR/MLIRContext.h\"  // from @llvm-project\n #include \"mlir/IR/OwningOpRef.h\"  // from @llvm-project\n #include \"mlir/Parser/Parser.h\"  // from @llvm-project\n #include \"tensorflow/compiler/mlir/tensorflow/utils/error_util.h\"\n #include \"xla/status_macros.h\"\n+#include \"tensorflow/core/lib/io/inputstream_interface.h\"\n+#include \"tensorflow/core/lib/io/zlib_compression_options.h\"\n+#include \"tensorflow/core/lib/io/zlib_inputstream.h\"\n+#include \"tensorflow/core/platform/tstring.h\"\n \n namespace tensorflow {\n+namespace {\n+// Wrap memory buffer into InputStreamInterface\n+class MemoryInputStream : public tensorflow::io::InputStreamInterface {\n+ public:\n+  explicit MemoryInputStream(const char* buffer, size_t length)\n+      : buf_(buffer), len_(length), pos_(0) {}\n+\n+  ~MemoryInputStream() override = default;\n+\n+  absl::Status ReadNBytes(int64_t bytes_to_read, tstring* result) override {\n+    result->clear();\n+    if (bytes_to_read < 0) {\n+      return absl::InvalidArgumentError(absl::StrCat(\n+          \"Can't read a negative number of bytes: \", bytes_to_read));\n+    }\n+    absl::Status status = absl::OkStatus();\n+    int64_t bytes = bytes_to_read;\n+    if (pos_ + bytes_to_read > len_) {\n+      bytes = len_ - pos_;\n+      status = absl::OutOfRangeError(\"Reached end of file\");\n+    }\n+    if (bytes > 0) {\n+      result->resize(bytes);\n+      memcpy(&(*result)[0], &buf_[pos_], bytes);\n+      pos_ += bytes;\n+    }\n+    return status;\n+  }\n+\n+  int64_t Tell() const override { return pos_; }\n+\n+  absl::Status Reset() override {\n+    pos_ = 0;\n+    return absl::OkStatus();\n+  }\n+\n+ private:\n+  const char* buf_;  // Not owned.\n+  int64_t len_;\n+  int64_t pos_ = 0;  // Tracks where we are in the file.\n+};\n+}  // namespace\n \n absl::Status DeserializeMlirModule(\n     llvm::StringRef serialized_mlir_module, mlir::MLIRContext* mlir_context,\n@@ -37,13 +92,44 @@ absl::Status DeserializeMlirModule(\n   // error reporting system.\n   mlir::StatusScopedDiagnosticHandler error_handler(mlir_context);\n \n-  // Parse the module.\n-  *mlir_module = mlir::parseSourceString<mlir::ModuleOp>(serialized_mlir_module,\n-                                                         mlir_context);\n-  if (!*mlir_module)\n-    return error_handler.Combine(\n-        absl::InvalidArgumentError(\"could not parse MLIR module\"));\n-\n+  // Look for the GZIP magic number to check if this is a compressed bytecode.\n+  if (serialized_mlir_module.starts_with(\"\\x1f\\x8b\")) {\n+    // Try to uncompress the and parse the bytecode.\n+    auto input_stream = std::make_unique<MemoryInputStream>(\n+        serialized_mlir_module.data(), serialized_mlir_module.size());\n+    io::ZlibCompressionOptions options = io::ZlibCompressionOptions::GZIP();\n+    auto zlib_stream = std::make_unique<tensorflow::io::ZlibInputStream>(\n+        input_stream.get(), options.input_buffer_size,\n+        options.output_buffer_size, options);\n+    tstring uncompressed_bytecode;\n+    absl::Status s = zlib_stream->ReadNBytes(/*bytes_to_read=*/INT_MAX,\n+                                             &uncompressed_bytecode);\n+    // OK status means the decompression is successful.\n+    // OutOfRange error means the decompression is successful but end of input\n+    // was reached before *bytes_to_read* bytes were read.\n+    if (!s.ok() && !absl::IsOutOfRange(s)) {\n+      // Failed to uncompress the bytecode and it is not the end of the input.\n+      return error_handler.Combine(absl::InvalidArgumentError(\n+          absl::StrCat(\"Failed to uncompress MLIR module\", s.message())));\n+    }\n+    // Parse the uncompressed bytecode.\n+    auto uncompressed_bytecode_str =\n+        std::string(uncompressed_bytecode.data(), uncompressed_bytecode.size());\n+    *mlir_module = mlir::parseSourceString<mlir::ModuleOp>(\n+        uncompressed_bytecode_str, mlir_context);\n+    if (!*mlir_module) {\n+      // Uncompressing was successful but the parsed MLIR module is invalid.\n+      return error_handler.Combine(absl::InvalidArgumentError(\n+          \"Failed to parse MLIR module after uncompressing\"));\n+    }\n+  } else {\n+    *mlir_module = mlir::parseSourceString<mlir::ModuleOp>(\n+        serialized_mlir_module, mlir_context);\n+    if (!*mlir_module) {\n+      return error_handler.Combine(\n+          absl::InvalidArgumentError(\"could not parse MLIR module\"));\n+    }\n+  }\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "e960de8acc494e8a595251a903b65b92661d7c69",
            "filename": "tensorflow/compiler/mlir/tensorflow/utils/serialize_mlir_module_utils.cc",
            "status": "modified",
            "additions": 65,
            "deletions": 0,
            "changes": 65,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fserialize_mlir_module_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fserialize_mlir_module_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fserialize_mlir_module_utils.cc?ref=1f3321fa67ff21702a3a818a9e22342afd11d82a",
            "patch": "@@ -18,12 +18,77 @@ limitations under the License.\n #include <string>\n #include <utility>\n \n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"llvm/Support/raw_ostream.h\"\n+#include \"mlir/Bytecode/BytecodeWriter.h\"  // from @llvm-project\n+#include \"mlir/IR/BuiltinOps.h\"  // from @llvm-project\n #include \"mlir/IR/OperationSupport.h\"  // from @llvm-project\n+#include \"mlir/Support/LLVM.h\"  // from @llvm-project\n #include \"tensorflow/compiler/jit/flags.h\"\n+#include \"xla/tsl/lib/io/zlib_compression_options.h\"\n+#include \"xla/tsl/lib/io/zlib_outputbuffer.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/file_system.h\"\n+\n namespace tensorflow {\n+namespace {\n+class WritableStringFile : public tsl::WritableFile {\n+ public:\n+  explicit WritableStringFile(std::string* data) : data_(data) {};\n+  ~WritableStringFile() override = default;\n+\n+  absl::Status Append(absl::string_view data) override {\n+    absl::StrAppend(data_, data);\n+    return absl::OkStatus();\n+  }\n+\n+  absl::Status Close() override { return absl::OkStatus(); }\n+  absl::Status Flush() override { return absl::OkStatus(); }\n+  absl::Status Sync() override { return absl::OkStatus(); }\n+\n+ private:\n+  std::string* data_;\n+};\n+}  // namespace\n+\n+absl::StatusOr<std::string> SerializeMlirModuleToCompressedBytecode(\n+    mlir::ModuleOp module_op) {\n+  std::string bytecode;\n+  llvm::raw_string_ostream os(bytecode);\n+  mlir::BytecodeWriterConfig config;\n+  if (mlir::failed(mlir::writeBytecodeToFile(module_op, os, config))) {\n+    return absl::InternalError(\"Failed to serialize MLIR module to bytecode.\");\n+  }\n+  std::string compressed_bytecode;\n+  WritableStringFile f(&compressed_bytecode);\n+\n+  tsl::io::ZlibCompressionOptions options =\n+      tsl::io::ZlibCompressionOptions::GZIP();\n+  tsl::io::ZlibOutputBuffer buffer(&f, options.input_buffer_size,\n+                                   options.output_buffer_size, options);\n+  TF_RETURN_IF_ERROR(buffer.Init());\n+  TF_RETURN_IF_ERROR(buffer.Append(bytecode));\n+  TF_RETURN_IF_ERROR(buffer.Close());\n+  return compressed_bytecode;\n+}\n \n std::string SerializeMlirModule(mlir::ModuleOp module_op) {\n+  if (GetMlirCommonFlags()->tf_serialize_mlir_to_compressed_bytecode) {\n+    auto compressed_bytecode =\n+        SerializeMlirModuleToCompressedBytecode(module_op);\n+    if (compressed_bytecode.ok()) {\n+      return compressed_bytecode.value();\n+    }\n+    LOG_IF(ERROR, !compressed_bytecode.ok())\n+        << \"Failed to serialize MLIR module to \"\n+           \"compressed bytecode.\"\n+        << compressed_bytecode.status();\n+    return \"\";\n+  }\n   std::string serialized_mlir_module;\n   llvm::raw_string_ostream os(serialized_mlir_module);\n   mlir::OpPrintingFlags print_flags;"
        },
        {
            "sha": "4e264c5f566a9c03cc12626c110803289c6f85d6",
            "filename": "tensorflow/compiler/mlir/tensorflow/utils/serialize_mlir_module_utils.h",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fserialize_mlir_module_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fserialize_mlir_module_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fserialize_mlir_module_utils.h?ref=1f3321fa67ff21702a3a818a9e22342afd11d82a",
            "patch": "@@ -18,10 +18,13 @@ limitations under the License.\n \n #include <string>\n \n+#include \"absl/status/statusor.h\"\n #include \"mlir/IR/BuiltinOps.h\"  // from @llvm-project\n \n namespace tensorflow {\n-\n+// Serializes a MLIR module `module_op` to a compressed bytecode string.\n+absl::StatusOr<std::string> SerializeMlirModuleToCompressedBytecode(\n+    mlir::ModuleOp module_op);\n // Prints a MLIR module `module_op` and returns it as a string.\n std::string SerializeMlirModule(mlir::ModuleOp module_op);\n "
        },
        {
            "sha": "d373e38cbaacbfd17138a52a8cc1a214cf84287a",
            "filename": "tensorflow/compiler/mlir/tensorflow/utils/serialize_mlir_module_utils_test.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fserialize_mlir_module_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fserialize_mlir_module_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Futils%2Fserialize_mlir_module_utils_test.cc?ref=1f3321fa67ff21702a3a818a9e22342afd11d82a",
            "patch": "@@ -23,6 +23,7 @@ limitations under the License.\n #include \"mlir/IR/MLIRContext.h\"  // from @llvm-project\n #include \"mlir/IR/OwningOpRef.h\"  // from @llvm-project\n #include \"tensorflow/compiler/jit/flags.h\"\n+#include \"tensorflow/compiler/mlir/tensorflow/utils/deserialize_mlir_module_utils.h\"\n #include \"tensorflow/core/platform/test.h\"\n \n namespace tensorflow {\n@@ -42,5 +43,17 @@ TEST(SerializeMlirModuleUtilsTest, DebugInfoSerialization) {\n   EXPECT_FALSE(absl::StrContains(serialized_module, \"loc(\"));\n }\n \n+TEST(SerializeMlirModuleUtilsTest, CompressedBytecodeSerializationRoundTrip) {\n+  GetMlirCommonFlags()->tf_serialize_mlir_to_compressed_bytecode = true;\n+  mlir::MLIRContext context;\n+  mlir::OwningOpRef<mlir::ModuleOp> module_ref =\n+      mlir::ModuleOp::create(mlir::UnknownLoc::get(&context));\n+  std::string mlir_module_str = tensorflow::SerializeMlirModule(*module_ref);\n+  mlir::OwningOpRef<mlir::ModuleOp> deserialized_module;\n+  EXPECT_TRUE(tensorflow::DeserializeMlirModule(mlir_module_str, &context,\n+                                                &deserialized_module)\n+                  .ok());\n+}\n+\n }  // namespace\n }  // namespace tensorflow"
        },
        {
            "sha": "243a53cd22d3b46da277157a1629316b64a30caa",
            "filename": "tensorflow/dtensor/python/tests/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fdtensor%2Fpython%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f3321fa67ff21702a3a818a9e22342afd11d82a/tensorflow%2Fdtensor%2Fpython%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fdtensor%2Fpython%2Ftests%2FBUILD?ref=1f3321fa67ff21702a3a818a9e22342afd11d82a",
            "patch": "@@ -38,7 +38,6 @@ pytype_strict_library(\n     deps = [\n         \"//tensorflow/dtensor/python:api\",\n         \"//tensorflow/dtensor/python:config\",\n-        \"//tensorflow/dtensor/python:dtensor_device\",\n         \"//tensorflow/dtensor/python:layout\",\n         \"//tensorflow/dtensor/python:numpy_util\",\n         \"//tensorflow/dtensor/python:tpu_util\",\n@@ -65,6 +64,7 @@ pytype_strict_library(\n         \"//tensorflow/python/util:numpy_compat\",\n         \"//third_party/py/numpy\",\n         \"@absl_py//absl/flags\",\n+        \"@absl_py//absl/logging\",\n         \"@absl_py//absl/testing:parameterized\",\n     ],\n )\n@@ -724,6 +724,7 @@ dtensor_test(\n         \"//tensorflow/python/platform:client_testlib\",\n         \"//tensorflow/python/util:nest\",\n         \"//third_party/py/numpy\",\n+        \"@absl_py//absl/logging\",\n         \"@absl_py//absl/testing:parameterized\",\n     ],\n )"
        },
        {
            "sha": "6b125ae2f0c0591b9aaec4e14c52e705f9ff5b5c",
            "filename": "third_party/xla/xla/tsl/lib/io/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1f3321fa67ff21702a3a818a9e22342afd11d82a/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Fio%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1f3321fa67ff21702a3a818a9e22342afd11d82a/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Fio%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Flib%2Fio%2FBUILD?ref=1f3321fa67ff21702a3a818a9e22342afd11d82a",
            "patch": "@@ -22,6 +22,7 @@ package(\n         \"//tensorflow/core/profiler:__subpackages__\",\n         \"//tensorflow/python/profiler/internal:__pkg__\",\n         \"//third_party/xprof:__subpackages__\",\n+        \"//tensorflow/compiler/mlir/tensorflow:__subpackages__\",\n     ]),\n     licenses = [\"notice\"],\n )"
        }
    ],
    "stats": {
        "total": 217,
        "additions": 205,
        "deletions": 12
    }
}