{
    "author": "seherellis",
    "message": "[XLA] Refactor HloSchedule::Verify to allow per-computation verification.\n\nPiperOrigin-RevId: 822796366",
    "sha": "6bd65b3630aa54ccfe636d7e1c8dd1e3e670cbb0",
    "files": [
        {
            "sha": "6ce39f9d7de31940564434cffd7111cd1c823a6c",
            "filename": "third_party/xla/xla/hlo/ir/hlo_schedule.cc",
            "status": "modified",
            "additions": 36,
            "deletions": 34,
            "changes": 70,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6bd65b3630aa54ccfe636d7e1c8dd1e3e670cbb0/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6bd65b3630aa54ccfe636d7e1c8dd1e3e670cbb0/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.cc?ref=6bd65b3630aa54ccfe636d7e1c8dd1e3e670cbb0",
            "patch": "@@ -355,45 +355,47 @@ absl::Status HloSchedule::Verify() const {\n     // For each computation verify the set of instructions is the same and\n     // that each dependency and control edge is honored.\n     for (const HloComputation* computation : nonfusion_computations) {\n-      absl::flat_hash_map<const HloInstruction*, int> instruction_position;\n-      int pos = 0;\n-      for (const HloInstruction* instruction :\n-           sequence(computation).instructions()) {\n-        TF_RET_CHECK(instruction_position.insert({instruction, pos}).second)\n-            << \"Instruction \" << instruction->name()\n-            << \" appears more than once in the schedule\";\n-        pos++;\n-      }\n+      TF_RETURN_IF_ERROR(Verify(computation));\n+    }\n+  }\n \n-      TF_RET_CHECK(instruction_position.size() ==\n-                   computation->instruction_count())\n-          << \"Schedule for computation \" << computation->name() << \" has \"\n-          << instruction_position.size() << \" instructions, expected \"\n-          << computation->instruction_count();\n-      for (const HloInstruction* instruction : computation->instructions()) {\n-        TF_RET_CHECK(instruction_position.contains(instruction))\n-            << \"Instruction \" << instruction->name() << \" is not in schedule\";\n-      }\n+  return absl::OkStatus();\n+}\n \n-      for (const HloInstruction* instruction : computation->instructions()) {\n-        for (const HloInstruction* operand : instruction->operands()) {\n-          TF_RET_CHECK(instruction_position.at(operand) <\n-                       instruction_position.at(instruction))\n-              << \"Instruction \" << instruction->name()\n-              << \" is not scheduled after its operand \" << operand->name();\n-        }\n+absl::Status HloSchedule::Verify(const HloComputation* computation) const {\n+  absl::flat_hash_map<const HloInstruction*, int> instruction_position;\n+  int pos = 0;\n+  for (const HloInstruction* instruction :\n+       sequence(computation).instructions()) {\n+    TF_RET_CHECK(instruction_position.insert({instruction, pos}).second)\n+        << \"Instruction \" << instruction->name()\n+        << \" appears more than once in the schedule\";\n+    pos++;\n+  }\n+  TF_RET_CHECK(instruction_position.size() == computation->instruction_count())\n+      << \"Schedule for computation \" << computation->name() << \" has \"\n+      << instruction_position.size() << \" instructions, expected \"\n+      << computation->instruction_count();\n+  for (const HloInstruction* instruction : computation->instructions()) {\n+    TF_RET_CHECK(instruction_position.contains(instruction))\n+        << \"Instruction \" << instruction->name() << \" is not in schedule\";\n+  }\n \n-        for (const HloInstruction* pred : instruction->control_predecessors()) {\n-          TF_RET_CHECK(instruction_position.at(pred) <\n-                       instruction_position.at(instruction))\n-              << \"Instruction \" << instruction->name()\n-              << \" is not scheduled after its control predecessor \"\n-              << pred->name();\n-        }\n-      }\n+  for (const HloInstruction* instruction : computation->instructions()) {\n+    for (const HloInstruction* operand : instruction->operands()) {\n+      TF_RET_CHECK(instruction_position.at(operand) <\n+                   instruction_position.at(instruction))\n+          << \"Instruction \" << instruction->name()\n+          << \" is not scheduled after its operand \" << operand->name();\n     }\n-  }\n \n+    for (const HloInstruction* pred : instruction->control_predecessors()) {\n+      TF_RET_CHECK(instruction_position.at(pred) <\n+                   instruction_position.at(instruction))\n+          << \"Instruction \" << instruction->name()\n+          << \" is not scheduled after its control predecessor \" << pred->name();\n+    }\n+  }\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "aef51e1e44791eb673bb8dca23b8d33db6fd813c",
            "filename": "third_party/xla/xla/hlo/ir/hlo_schedule.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6bd65b3630aa54ccfe636d7e1c8dd1e3e670cbb0/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6bd65b3630aa54ccfe636d7e1c8dd1e3e670cbb0/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_schedule.h?ref=6bd65b3630aa54ccfe636d7e1c8dd1e3e670cbb0",
            "patch": "@@ -242,6 +242,9 @@ class HloSchedule {\n   // satisfied in the schedule.\n   absl::Status Verify() const;\n \n+  // Verifies that the given schedule is valid for the given computation.\n+  absl::Status Verify(const HloComputation* computation) const;\n+\n   std::string ToString() const;\n \n   bool empty() const { return sequences_.empty(); }"
        }
    ],
    "stats": {
        "total": 73,
        "additions": 39,
        "deletions": 34
    }
}