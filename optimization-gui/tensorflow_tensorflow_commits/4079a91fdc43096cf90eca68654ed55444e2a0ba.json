{
    "author": "derdrdirk",
    "message": "[Autotuner] Enable to modify xla_gpu_experimental_autotuner_cache_dir DebugOption via a flag.\n\nPiperOrigin-RevId: 817136170",
    "sha": "4079a91fdc43096cf90eca68654ed55444e2a0ba",
    "files": [
        {
            "sha": "568100b1489d8c518f4def42d9e3dd9427fc528e",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4079a91fdc43096cf90eca68654ed55444e2a0ba/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4079a91fdc43096cf90eca68654ed55444e2a0ba/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=4079a91fdc43096cf90eca68654ed55444e2a0ba",
            "patch": "@@ -2248,6 +2248,12 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n       \"cache. Supported modes: read (provides readonly access to \"\n       \"the cache), update (loads if the cache exists, runs autotuning \"\n       \"and dumps the result otherwise). Default: update.\"));\n+  flag_list->push_back(tsl::Flag(\n+      \"xla_gpu_experimental_autotuner_cache_dir\",\n+      string_setter_for(\n+          &DebugOptions::set_xla_gpu_experimental_autotuner_cache_dir),\n+      debug_options->xla_gpu_experimental_autotuner_cache_dir(),\n+      \"Experimental: Specify the directory to read/write autotuner cache to.\"));\n   flag_list->push_back(tsl::Flag(\n       \"xla_enable_command_buffers_during_profiling\",\n       bool_setter_for("
        }
    ],
    "stats": {
        "total": 6,
        "additions": 6,
        "deletions": 0
    }
}