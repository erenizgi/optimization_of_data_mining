{
    "author": "shawnwang18",
    "message": "PR #30721: [XLA:GPU] Command buffer allows multiple CommandBufferCmdExecutor to be recorded into one command buffer\n\nImported from GitHub PR https://github.com/openxla/xla/pull/30721\n\nðŸ“ Summary of Changes\nIn Current implementation, one command buffer (cuda graph) can only be recorded from one command sequence (CommandBufferCmdExecutor), i.e, command buffer will be finalized after recording the last command from the command sequence.  But in some cases, we may want to recording multiple command sequence into the same command buffer.  This PR enables this feature.\n\nthe new CommandBufferCmdExecutor::Record function will have the prototype:\n```\n  absl::Status Record(const Thunk::ExecuteParams& execute_params,\n                      const RecordParams& record_params,\n                      CommandBufferCmd::RecordAction record_action,\n                      se::CommandBuffer* command_buffer, bool finalize = true);\n```\n\n`record_action` is the dependency sets for source command of current sequence, `finalize` is a flag to indicate whether to finalize the cuda-graph after recording current sequence.\n\nFor example, if we have 3 command sequences: A , B, C, and we want include them into one cuda-graph, the recorded order is A -> B -> C, where B's source commands depend on A's sink commands, and C's source commands depend on B's sink commands.\n\nðŸŽ¯ Justification\n\nThis new record pattern will make constructing cuda-graph more easily in some cases.  For example, if we want to unroll the loop (do not use cuda-graph while node to modeling the loop), we can just recorded the loop body sequence into one command buffer in sequence very easily:  Iteration1.Record() -> Iteration2.Record() -> ....\n\nðŸš€ Kind of Contribution\nâœ¨ New Feature\n\nðŸ“Š Benchmark (for Performance Improvements)\nThis is a pre-requisite feature for command buffer loop unrolling, so no perf number in this PR\n\nðŸ§ª Unit Tests:\ncommand_buffer_cmd_test.cc: CommandBufferCmdTest.RecordExecutorsWithDependencies\n\nCopybara import of the project:\n\n--\nf6695fc1f85538acf86bae6bec5774a8da08daf5 by Shawn Wang <shawnw@nvidia.com>:\n\nCommand buffer allows multiple CommandBufferCmdExecutor to be recorded into one command buffer\n\nMerging this change closes #30721\n\nPiperOrigin-RevId: 800854457",
    "sha": "fc1eab0c338a8c874c61c3f192aba47446b81f9f",
    "files": [
        {
            "sha": "95dfd43d834e289caf1471e3c0da6a559a9b68be",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 55,
            "deletions": 6,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc1eab0c338a8c874c61c3f192aba47446b81f9f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc1eab0c338a8c874c61c3f192aba47446b81f9f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=fc1eab0c338a8c874c61c3f192aba47446b81f9f",
            "patch": "@@ -450,7 +450,8 @@ absl::Status CommandBufferCmdExecutor::Initialize(\n absl::Status CommandBufferCmdExecutor::Record(\n     const Thunk::ExecuteParams& execute_params,\n     const CommandBufferCmd::RecordParams& record_params,\n-    se::CommandBuffer* command_buffer) {\n+    CommandBufferCmd::RecordAction record_action,\n+    se::CommandBuffer* command_buffer, bool finalize) {\n   VLOG(3) << \"Record \" << commands_.size() << \" commands into command buffer\";\n \n   if (command_buffer->state() == se::CommandBuffer::State::kFinalized) {\n@@ -461,12 +462,16 @@ absl::Status CommandBufferCmdExecutor::Record(\n     TF_RETURN_IF_ERROR(\n         RecordUpdate(execute_params, record_params, command_buffer));\n   } else {\n-    TF_RETURN_IF_ERROR(\n-        RecordCreate(execute_params, record_params, command_buffer, {})\n-            .status());\n+    auto* create = std::get_if<CommandBufferCmd::RecordCreate>(&record_action);\n+    CHECK(create);\n+    TF_RETURN_IF_ERROR(RecordCreate(execute_params, record_params,\n+                                    command_buffer, create->dependencies)\n+                           .status());\n   }\n-\n-  return command_buffer->Finalize();\n+  if (finalize) {\n+    return command_buffer->Finalize();\n+  }\n+  return absl::OkStatus();\n }\n \n absl::StatusOr<std::vector<const se::CommandBuffer::Command*>>\n@@ -658,6 +663,48 @@ bool CommandBufferCmdExecutor::IsSink(CommandId id) const {\n                           : id + 1 == commands_.size();\n }\n \n+std::vector<const se::CommandBuffer::Command*>\n+CommandBufferCmdExecutor::SinkCommands(\n+    const RecordParams& record_params,\n+    se::CommandBuffer* command_buffer) const {\n+  std::vector<CommandId> sink_ids;\n+  if (execution_graph_) {\n+    auto sink_span = execution_graph_->sink();\n+    sink_ids.assign(sink_span.begin(), sink_span.end());\n+  } else {\n+    sink_ids.push_back(commands_.size() - 1);\n+  }\n+\n+  std::vector<const se::CommandBuffer::Command*> sink_commands;\n+  for (CommandId id : sink_ids) {\n+    auto* record_state = record_params.state.GetOrNull<RecordState>(\n+        commands_[id].get(), command_buffer);\n+    sink_commands.push_back(record_state->command);\n+  }\n+  return sink_commands;\n+}\n+\n+std::vector<const se::CommandBuffer::Command*>\n+CommandBufferCmdExecutor::SourceCommands(\n+    const RecordParams& record_params,\n+    se::CommandBuffer* command_buffer) const {\n+  std::vector<CommandId> source_ids;\n+  if (execution_graph_) {\n+    auto source_span = execution_graph_->source();\n+    source_ids.assign(source_span.begin(), source_span.end());\n+  } else {\n+    source_ids.push_back(0);\n+  }\n+\n+  std::vector<const se::CommandBuffer::Command*> source_commands;\n+  for (CommandId id : source_ids) {\n+    auto* record_state = record_params.state.GetOrNull<RecordState>(\n+        commands_[id].get(), command_buffer);\n+    source_commands.push_back(record_state->command);\n+  }\n+  return source_commands;\n+}\n+\n std::vector<const se::CommandBuffer::Command*>\n CommandBufferCmdExecutor::Dependencies(const RecordParams& record_params,\n                                        se::CommandBuffer* command_buffer,\n@@ -1285,6 +1332,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> ChildCmd::Record(\n   VLOG(5) << \"Record ChildCmd \" << child_commands_.size() << \" commands\";\n   CHECK(child_command_buffer_ != nullptr);\n   TF_RETURN_IF_ERROR(child_commands_.Record(execute_params, record_params,\n+                                            CommandBufferCmd::RecordCreate{},\n                                             child_command_buffer_.get()));\n   return Handle(\n       std::move(record_action),\n@@ -2419,6 +2467,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> DynamicSliceFusionCmd::Record(\n           ->CreateCommandBuffer(se::CommandBuffer::Mode::kNested)\n           .value();\n   TF_RETURN_IF_ERROR(embedded_commands_.Record(new_params, record_params,\n+                                               CommandBufferCmd::RecordCreate{},\n                                                nested_command_buffer.get()));\n \n   return Handle("
        },
        {
            "sha": "688bb2d49ea9b887d000712c648552cef1fd345e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.h",
            "status": "modified",
            "additions": 28,
            "deletions": 4,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc1eab0c338a8c874c61c3f192aba47446b81f9f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc1eab0c338a8c874c61c3f192aba47446b81f9f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h?ref=fc1eab0c338a8c874c61c3f192aba47446b81f9f",
            "patch": "@@ -412,12 +412,26 @@ class CommandBufferCmdExecutor {\n \n   // Records commands into the command buffer. This method automatically\n   // switches between `RecordCreate` or `RecordUpdate` depending on the command\n-  // buffer state. This method assumes that no other command buffer sequence is\n-  // recorded into the same command buffer, and doesn't set up initial\n-  // dependencies for recorded commands.\n+  // buffer state.\n+\n+  // This Record function allows multiple CommandbufferCmdEXecutor to be\n+  // recorded into a single command buffer. e.g. we can have Executor A, B, C to\n+  // be recorded into the same command buffer in the order of A -> B -> C. In\n+  // this pattern, B's source commands will depend on A's sink commands, and C's\n+  // source commands will also depend on B's sink commands.\n+\n+  // If record_action is `RecordCreate`, it will set up initial\n+  // dependencies for recorded commands by the `dependencies` parameter.\n+  // If record_action is `RecordUpdate`, it will only update previously\n+  // recorded commands' dependencies, no other actions.\n+\n+  // If finalize is true, it will finalize the command buffer after recording,\n+  // if not, this allows the command_buffer to further record other executors\n+  // into the this command buffer.\n   absl::Status Record(const Thunk::ExecuteParams& execute_params,\n                       const RecordParams& record_params,\n-                      se::CommandBuffer* command_buffer);\n+                      CommandBufferCmd::RecordAction record_action,\n+                      se::CommandBuffer* command_buffer, bool finalize = true);\n \n   // Records command creation into the command buffer. Command buffer must be\n   // in create state. The next command sequence recorded into the same command\n@@ -454,6 +468,16 @@ class CommandBufferCmdExecutor {\n                           [](const auto& cmd) { return cmd->force_update(); });\n   }\n \n+  // Returns all source commands for current command executor.\n+  std::vector<const se::CommandBuffer::Command*> SourceCommands(\n+      const RecordParams& record_params,\n+      se::CommandBuffer* command_buffer) const;\n+\n+  // Returns all sink commands for current command executor.\n+  std::vector<const se::CommandBuffer::Command*> SinkCommands(\n+      const RecordParams& record_params,\n+      se::CommandBuffer* command_buffer) const;\n+\n   // Renders the execution graph using default renderer. Returns url of the\n   // rendered graph, or an error if rendering failed.\n   absl::StatusOr<std::string> RenderExecutionGraph();"
        },
        {
            "sha": "bb9634c15624e31dbe61b0666a0b4b83a0148bce",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd_test.cc",
            "status": "modified",
            "additions": 120,
            "deletions": 4,
            "changes": 124,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc1eab0c338a8c874c61c3f192aba47446b81f9f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc1eab0c338a8c874c61c3f192aba47446b81f9f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc?ref=fc1eab0c338a8c874c61c3f192aba47446b81f9f",
            "patch": "@@ -266,7 +266,9 @@ TEST(CommandBufferCmdTest, MemcpyCmd) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto command_buffer,\n       stream_executor->CreateCommandBuffer(se::CommandBuffer::Mode::kPrimary));\n-  TF_ASSERT_OK(executor.Record(params, record_params, command_buffer.get()));\n+  TF_ASSERT_OK(executor.Record(params, record_params,\n+                               CommandBufferCmd::RecordCreate{},\n+                               command_buffer.get()));\n \n   // Execute command buffer and verify that it copied the memory.\n   TF_ASSERT_OK(command_buffer->Submit(stream.get()));\n@@ -335,7 +337,9 @@ TEST(CommandBufferCmdTest, LaunchCmd) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto command_buffer,\n       stream_executor->CreateCommandBuffer(se::CommandBuffer::Mode::kPrimary));\n-  TF_ASSERT_OK(executor.Record(params, record_params, command_buffer.get()));\n+  TF_ASSERT_OK(executor.Record(params, record_params,\n+                               CommandBufferCmd::RecordCreate{},\n+                               command_buffer.get()));\n \n   // Execute command buffer and verify that it copied the memory.\n   TF_ASSERT_OK(command_buffer->Submit(stream.get()));\n@@ -406,7 +410,9 @@ TEST(CommandBufferCmdTest, LaunchCmdWithPriority) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto command_buffer,\n       stream_executor->CreateCommandBuffer(se::CommandBuffer::Mode::kPrimary));\n-  TF_ASSERT_OK(executor.Record(params, record_params, command_buffer.get()));\n+  TF_ASSERT_OK(executor.Record(params, record_params,\n+                               CommandBufferCmd::RecordCreate{},\n+                               command_buffer.get()));\n \n   // Execute command buffer and verify that it copied the memory.\n   TF_ASSERT_OK(command_buffer->Submit(stream.get()));\n@@ -465,7 +471,9 @@ TEST(CommandBufferCmdTest, DynamicSliceCopyFusionCmd) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto command_buffer,\n       stream_executor->CreateCommandBuffer(se::CommandBuffer::Mode::kPrimary));\n-  TF_ASSERT_OK(executor.Record(params, record_params, command_buffer.get()));\n+  TF_ASSERT_OK(executor.Record(params, record_params,\n+                               CommandBufferCmd::RecordCreate{},\n+                               command_buffer.get()));\n \n   // Execute command buffer and verify that it copied the memory.\n   TF_ASSERT_OK(command_buffer->Submit(stream.get()));\n@@ -569,6 +577,114 @@ TEST(TracedCommandBuffer, GetOrUpdateCommandBuffer) {\n   run_traced_test(3);\n }\n \n+TEST(CommandBufferCmdTest, RecordExecutorsWithDependencies) {\n+  se::StreamExecutor* stream_executor = GpuExecutor();\n+\n+  auto stream = stream_executor->CreateStream().value();\n+  int64_t length = 4;\n+  int64_t byte_length = sizeof(int32_t) * length;\n+\n+  // Device buffers: a, b, c\n+  se::DeviceMemory<int32_t> a =\n+      stream_executor->AllocateArray<int32_t>(length, 0);\n+  se::DeviceMemory<int32_t> b =\n+      stream_executor->AllocateArray<int32_t>(length, 0);\n+  se::DeviceMemory<int32_t> c =\n+      stream_executor->AllocateArray<int32_t>(length, 0);\n+\n+  // Initialize to zero.\n+  TF_ASSERT_OK(stream->MemZero(&a, byte_length));\n+  TF_ASSERT_OK(stream->MemZero(&b, byte_length));\n+  TF_ASSERT_OK(stream->MemZero(&c, byte_length));\n+\n+  // Buffer allocations for recording.\n+  BufferAllocation alloc_a(/*index=*/0, byte_length, /*color=*/0);\n+  BufferAllocation alloc_b(/*index=*/1, byte_length, /*color=*/0);\n+  BufferAllocation alloc_c(/*index=*/2, byte_length, /*color=*/0);\n+\n+  BufferAllocation::Slice slice_a(&alloc_a, 0, byte_length);\n+  BufferAllocation::Slice slice_b(&alloc_b, 0, byte_length);\n+  BufferAllocation::Slice slice_c(&alloc_c, 0, byte_length);\n+\n+  // Executor A: a = 1 (memset)\n+  CommandBufferCmdSequence seq_a;\n+  seq_a.Emplace<Memset32Cmd>(slice_a, /*bit_pattern=*/1);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      CommandBufferCmdExecutor exec_a,\n+      CommandBufferCmdExecutor::Create(std::move(seq_a), serialize));\n+\n+  // Executor B: b = a + a (launch kernel AddI32)\n+  CommandBufferCmdSequence seq_b;\n+  {\n+    auto args = {slice_a, slice_a, slice_b};\n+    auto args_access = {BufferUse::kRead, MemoryAccess::kRead,\n+                        BufferUse::kWrite};\n+    seq_b.Emplace<LaunchCmd>(\"AddI32\", args, args_access,\n+                             LaunchDimensions(1, 4), /*shmem_bytes=*/0);\n+  }\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      CommandBufferCmdExecutor exec_b,\n+      CommandBufferCmdExecutor::Create(std::move(seq_b), serialize));\n+\n+  // Executor C: c = b (memcpy)\n+  CommandBufferCmdSequence seq_c;\n+  seq_c.Emplace<MemcpyDeviceToDeviceCmd>(slice_c, slice_b, byte_length);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      CommandBufferCmdExecutor exec_c,\n+      CommandBufferCmdExecutor::Create(std::move(seq_c), serialize));\n+\n+  // Initialize executors (B needs kernel fatbin).\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::vector<uint8_t> fatbin,\n+      se::gpu::GetGpuTestKernelsFatbin(stream_executor->GetPlatform()->Name()));\n+  Thunk::ExecutableSource source_empty = {/*text=*/{}, /*binary=*/{}};\n+  Thunk::ExecutableSource source_fatbin = {/*text=*/{}, /*binary=*/fatbin};\n+\n+  CommandBufferCmd::StateManager state;\n+  TF_ASSERT_OK(exec_a.Initialize({stream_executor, source_empty}, state));\n+  TF_ASSERT_OK(exec_b.Initialize({stream_executor, source_fatbin}, state));\n+  TF_ASSERT_OK(exec_c.Initialize({stream_executor, source_empty}, state));\n+\n+  // Execute params and allocations mapping indices 0=a,1=b,2=c\n+  ServiceExecutableRunOptions run_options;\n+  se::StreamExecutorMemoryAllocator allocator(stream_executor);\n+  BufferAllocations allocations({a, b, c}, 0, &allocator);\n+\n+  Thunk::ExecuteParams exec_params = Thunk::ExecuteParams::Create(\n+      run_options, allocations, stream.get(), stream.get(), nullptr, nullptr);\n+  CommandBufferCmd::RecordParams record_params = {state};\n+\n+  // Create a primary command buffer and record A -> B -> C with dependencies.\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto command_buffer,\n+      stream_executor->CreateCommandBuffer(se::CommandBuffer::Mode::kPrimary));\n+\n+  // Record A (no deps)\n+  // Record A, B, C with dependencies using the Record API; finalize on B.\n+  TF_ASSERT_OK(exec_a.Record(exec_params, record_params,\n+                             CommandBufferCmd::RecordCreate{},\n+                             command_buffer.get(), /*finalize=*/false));\n+\n+  auto a_sinks = exec_a.SinkCommands(record_params, command_buffer.get());\n+  TF_ASSERT_OK(\n+      exec_b.Record(exec_params, record_params,\n+                    CommandBufferCmd::RecordCreate{absl::MakeSpan(a_sinks)},\n+                    command_buffer.get(), /*finalize=*/false));\n+\n+  auto b_sinks = exec_b.SinkCommands(record_params, command_buffer.get());\n+  TF_ASSERT_OK(\n+      exec_c.Record(exec_params, record_params,\n+                    CommandBufferCmd::RecordCreate{absl::MakeSpan(b_sinks)},\n+                    command_buffer.get(), /*finalize=*/true));\n+\n+  // Submit and verify c == 2 for all elements.\n+  TF_ASSERT_OK(command_buffer->Submit(stream.get()));\n+\n+  std::vector<int32_t> dst(length, 0);\n+  TF_ASSERT_OK(stream->Memcpy(dst.data(), c, byte_length));\n+  ASSERT_EQ(dst, std::vector<int32_t>(length, 2));\n+}\n+\n //===----------------------------------------------------------------------===//\n // Performance benchmarks below\n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "7dab14e15c6e8eb0ea0136774071afae116cb4fd",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fc1eab0c338a8c874c61c3f192aba47446b81f9f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fc1eab0c338a8c874c61c3f192aba47446b81f9f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk.cc?ref=fc1eab0c338a8c874c61c3f192aba47446b81f9f",
            "patch": "@@ -201,6 +201,7 @@ absl::Status CommandBufferThunk::Initialize(const InitializeParams& params) {\n                                                     std::move(updated_allocs),\n                                                     /*is_initialization=*/true};\n     TF_RETURN_IF_ERROR(commands_.Record(execute_params, record_params,\n+                                        CommandBufferCmd::RecordCreate{},\n                                         cmd_buffer->command_buffer.get()));\n \n     uint64_t end_micros = tsl::Env::Default()->NowMicros();\n@@ -261,6 +262,7 @@ absl::Status CommandBufferThunk::ExecuteOnStream(const ExecuteParams& params) {\n     CommandBufferCmd::RecordParams record_params = {cmd_buffer->state,\n                                                     std::move(updated_allocs)};\n     TF_RETURN_IF_ERROR(commands_.Record(params, record_params,\n+                                        CommandBufferCmd::RecordCreate{},\n                                         cmd_buffer->command_buffer.get()));\n \n     uint64_t end_micros = tsl::Env::Default()->NowMicros();"
        }
    ],
    "stats": {
        "total": 219,
        "additions": 205,
        "deletions": 14
    }
}