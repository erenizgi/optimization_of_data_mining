{
    "author": "apivovarov",
    "message": "Add support for CollectiveBroadcastThunk in Command Buffer.\n\nThis change integrates `CollectiveBroadcastStartThunk` and `CollectiveBroadcastDoneThunk` into the command buffer execution framework, allowing them to be converted into command buffer commands. It also includes a minor fix to an error message.\n\nPiperOrigin-RevId: 819432425",
    "sha": "e5c6a2b8ae942078dfd82a4889a47e120db53d24",
    "files": [
        {
            "sha": "0c81fb4bda4430e543f5532190ef82fcefb7b8c1",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 36,
            "deletions": 0,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e5c6a2b8ae942078dfd82a4889a47e120db53d24/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e5c6a2b8ae942078dfd82a4889a47e120db53d24/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=e5c6a2b8ae942078dfd82a4889a47e120db53d24",
            "patch": "@@ -177,6 +177,7 @@ cc_library(\n         \":all_gather_thunk\",\n         \":all_reduce_thunk\",\n         \":all_to_all_thunk\",\n+        \":collective_broadcast_thunk\",\n         \":collective_thunk\",\n         \":command_buffer_cmd\",\n         \":conditional_thunk\",\n@@ -1424,6 +1425,41 @@ cc_library(\n     ],\n )\n \n+xla_test(\n+    name = \"collective_broadcast_thunk_test\",\n+    srcs = [\"collective_broadcast_thunk_test.cc\"],\n+    backends = [\"gpu\"],\n+    deps = [\n+        \":collective_broadcast_thunk\",\n+        \":collective_thunk\",\n+        \":command_buffer_cmd\",\n+        \":command_buffer_cmd_emitter\",\n+        \":command_buffer_thunk\",\n+        \":sequential_thunk\",\n+        \":thunk\",\n+        \":thunk_proto_cc\",\n+        \"//xla:util\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla/backends/gpu/collectives:gpu_clique_key\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:verified_hlo_module\",\n+        \"//xla/service:backend\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/service:executable\",\n+        \"//xla/service:hlo_module_config\",\n+        \"//xla/service/gpu:gpu_constants\",\n+        \"//xla/service/gpu:gpu_executable\",\n+        \"//xla/stream_executor:platform\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tests:hlo_test_base\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/platform:test\",\n+        \"@com_google_googletest//:gtest_main\",\n+        \"@local_tsl//tsl/platform:casts\",\n+    ],\n+)\n+\n cc_library(\n     name = \"collective_permute_thunk\",\n     srcs = [\"collective_permute_thunk.cc\"],"
        },
        {
            "sha": "54dab0bdd7ee1d73e80bc035fe84d64490e99c1e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_broadcast_thunk_test.cc",
            "status": "added",
            "additions": 216,
            "deletions": 0,
            "changes": 216,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e5c6a2b8ae942078dfd82a4889a47e120db53d24/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e5c6a2b8ae942078dfd82a4889a47e120db53d24/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk_test.cc?ref=e5c6a2b8ae942078dfd82a4889a47e120db53d24",
            "patch": "@@ -0,0 +1,216 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/collective_broadcast_thunk.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n+#include \"xla/backends/gpu/runtime/collective_thunk.h\"\n+#include \"xla/backends/gpu/runtime/command_buffer_cmd.h\"\n+#include \"xla/backends/gpu/runtime/command_buffer_cmd_emitter.h\"\n+#include \"xla/backends/gpu/runtime/command_buffer_thunk.h\"\n+#include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/testlib/verified_hlo_module.h\"\n+#include \"xla/service/backend.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/executable.h\"\n+#include \"xla/service/gpu/gpu_constants.h\"\n+#include \"xla/service/gpu/gpu_executable.h\"\n+#include \"xla/service/hlo_module_config.h\"\n+#include \"xla/stream_executor/platform.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tests/hlo_test_base.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/test.h\"\n+#include \"xla/util.h\"\n+#include \"xla/xla_data.pb.h\"\n+#include \"tsl/platform/casts.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+using ::testing::ElementsAre;\n+using Kind = Thunk::Kind;\n+\n+class GpuCollectiveBroadcastTest : public HloTestBase {};\n+\n+TEST_F(GpuCollectiveBroadcastTest, TestConvertToCommands) {\n+  // Generate HLO text with parameters substituted.\n+  std::string hlo_text = R\"(\n+HloModule test, replica_count=2\n+ENTRY test_computation {\n+  p = u32[4] parameter(0)\n+  ROOT res = u32[4] collective-broadcast(p), replica_groups={{1, 0}}\n+}\n+)\";\n+\n+  // Configure module with debug options for command buffer.\n+  HloModuleConfig config;\n+  DebugOptions debug_options = GetDebugOptionsForTest();\n+  debug_options.set_xla_gpu_graph_min_graph_size(1);\n+  debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::COLLECTIVES);\n+  config.set_debug_options(debug_options);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_text, config));\n+\n+  // Get CollectiveBroadcast Instruction\n+  const HloInstruction* root_instr =\n+      module->entry_computation()->root_instruction();\n+  ASSERT_EQ(root_instr->opcode(), HloOpcode::kCollectiveBroadcast);\n+  const HloCollectiveBroadcastInstruction* cb_instr =\n+      tensorflow::down_cast<const HloCollectiveBroadcastInstruction*>(\n+          root_instr);\n+  ASSERT_NE(cb_instr, nullptr);\n+\n+  // Buffer and Allocation Setup\n+  using DataT = int32_t;\n+  constexpr int64_t kNumElements = 4;\n+  constexpr int64_t kAlignmentBytes = kXlaAllocatedBufferAlignBytes;\n+\n+  const int64_t kElementSize = sizeof(DataT);\n+  const int64_t kTotalDataBytes = kNumElements * kElementSize;\n+\n+  // Use RoundUpTo to calculate the actual size needed for one buffer.\n+  const int64_t kAlignedSliceBytes =\n+      xla::RoundUpTo<uint64_t>(kTotalDataBytes, kAlignmentBytes);\n+\n+  // The total buffer size must accommodate input and output slices.\n+  const int64_t kTotalBufferBytes = 2 * kAlignedSliceBytes;\n+\n+  BufferAllocation buffer_allocation(/*index=*/0, kTotalBufferBytes,\n+                                     /*color=*/0);\n+  BufferAllocation::Slice input_slice(&buffer_allocation, /*offset=*/0,\n+                                      kAlignedSliceBytes);\n+  BufferAllocation::Slice output_slice(&buffer_allocation, kAlignedSliceBytes,\n+                                       kAlignedSliceBytes);\n+\n+  // Use designated initializers if possible, or format for clarity.\n+  std::vector<CollectiveThunk::Buffer> buffers = {\n+      {/*element_count=*/kNumElements,\n+       /*source_buffer=*/input_slice,\n+       /*destination_buffer=*/output_slice,\n+       /*source_memory_space=*/0,\n+       /*destination_memory_space=*/0},\n+  };\n+\n+  // ThunkSequence Creation\n+  std::shared_ptr<CollectiveThunk::AsyncEvents> async_events =\n+      std::make_shared<CollectiveThunk::AsyncEvents>();\n+\n+  auto cb_start_thunk = std::make_unique<CollectiveBroadcastStartThunk>(\n+      Thunk::ThunkInfo{}, cb_instr, std::move(buffers));\n+\n+  cb_start_thunk->set_async_events(async_events);\n+\n+  auto cb_done_thunk = std::make_unique<CollectiveDoneThunk>(\n+      Kind::kCollectiveBroadcastDone, Thunk::ThunkInfo{}, async_events,\n+      AsyncStreamKind::kCollective);\n+\n+  ThunkSequence thunk_sequence;\n+  thunk_sequence.push_back(std::move(cb_start_thunk));\n+  thunk_sequence.push_back(std::move(cb_done_thunk));\n+\n+  // Convert to Commands and Verification\n+  ConvertToCommandsOptions conv_options;\n+  // Use LHS synchronization mode to append Done command\n+  conv_options.synchronization_mode =\n+      CommandBufferCmdExecutor::SynchronizationMode::kLHS;\n+  TF_ASSERT_OK_AND_ASSIGN(CommandBufferCmdExecutor cb_cmd_executor,\n+                          ConvertToCommands(thunk_sequence, conv_options));\n+\n+  // Check that we have two commands: start and done.\n+  EXPECT_EQ(cb_cmd_executor.size(), 2);\n+}\n+\n+TEST_F(GpuCollectiveBroadcastTest,\n+       TestCommandBufferThunkContainsCorrectThunks) {\n+  // Generate HLO text with parameters substituted.\n+  std::string hlo_text = R\"(\n+HloModule test, replica_count=2\n+ENTRY test_computation {\n+  replica = u32[] replica-id()\n+  p = u32[4] broadcast(replica), dimensions={}\n+  ROOT res = u32[4] collective-broadcast(p), replica_groups={{1, 0}}\n+}\n+)\";\n+\n+  // Configure module with debug options for command buffer.\n+  HloModuleConfig config;\n+  DebugOptions debug_options = GetDebugOptionsForTest();\n+  debug_options.set_xla_gpu_graph_min_graph_size(1);\n+  debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::COLLECTIVES);\n+  config.set_debug_options(debug_options);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_text, config));\n+\n+  se::StreamExecutor* executor = backend().default_stream_executor();\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<HloModule> compiled_module,\n+      backend().compiler()->RunHloPasses(module->Clone(), executor,\n+                                         /*device_allocator=*/nullptr));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<Executable> executable,\n+      backend().compiler()->RunBackend(std::move(compiled_module), executor,\n+                                       {/*device_allocator=*/nullptr,\n+                                        /*thread_pool=*/nullptr,\n+                                        /*layout_canonicalization_callback=*/{},\n+                                        /*is_autotuning_compilation=*/false}));\n+\n+  // Downcast to GPU executable\n+  xla::gpu::GpuExecutable* gpu_executable =\n+      tensorflow::down_cast<xla::gpu::GpuExecutable*>(executable.get());\n+  ASSERT_NE(gpu_executable, nullptr);\n+\n+  // Get the thunk sequence and check its size and type\n+  const SequentialThunk& seq_thunk = gpu_executable->GetThunk();\n+  ASSERT_EQ(seq_thunk.thunks().size(), 1);\n+\n+  const std::unique_ptr<Thunk>& thunk = seq_thunk.thunks().front();\n+  ASSERT_EQ(thunk->kind(), Thunk::kCommandBuffer);\n+\n+  CommandBufferThunk* cmd_buffer_thunk =\n+      tensorflow::down_cast<CommandBufferThunk*>(thunk.get());\n+  ASSERT_NE(cmd_buffer_thunk, nullptr);\n+\n+  std::vector<Kind> kinds;\n+  const auto& inner_thunks = cmd_buffer_thunk->thunks()->thunks();\n+  kinds.reserve(inner_thunks.size());\n+  for (const auto& thunk : inner_thunks) {\n+    kinds.push_back(thunk->kind());\n+  }\n+  EXPECT_THAT(kinds, ElementsAre(Kind::kReplicaId, Kind::kKernel,\n+                                 Kind::kCollectiveBroadcastStart,\n+                                 Kind::kCollectiveBroadcastDone));\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        },
        {
            "sha": "74fe78c46ebb7a4b8b51e6864f0f1c16fadd3d7e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e5c6a2b8ae942078dfd82a4889a47e120db53d24/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e5c6a2b8ae942078dfd82a4889a47e120db53d24/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=e5c6a2b8ae942078dfd82a4889a47e120db53d24",
            "patch": "@@ -2203,7 +2203,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllToAllCmd::Record(\n \n   if (!execute_params.collective_params || !execute_params.collective_cliques) {\n     return absl::InvalidArgumentError(\n-        \"ReduceScatterCmd requires collective parameters and cliques\");\n+        \"AllToAllCmd requires collective parameters and cliques\");\n   }\n \n   TF_ASSIGN_OR_RETURN(GpuCollectives * collectives,"
        },
        {
            "sha": "9cb965bbd79100a18f3690cab944a9db22b7f707",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd_emitter.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 5,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e5c6a2b8ae942078dfd82a4889a47e120db53d24/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e5c6a2b8ae942078dfd82a4889a47e120db53d24/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc?ref=e5c6a2b8ae942078dfd82a4889a47e120db53d24",
            "patch": "@@ -31,6 +31,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/all_gather_thunk.h\"\n #include \"xla/backends/gpu/runtime/all_reduce_thunk.h\"\n #include \"xla/backends/gpu/runtime/all_to_all_thunk.h\"\n+#include \"xla/backends/gpu/runtime/collective_broadcast_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/command_buffer_cmd.h\"\n #include \"xla/backends/gpu/runtime/conditional_thunk.h\"\n@@ -183,6 +184,12 @@ static absl::StatusOr<Command> Convert(const AllGatherStartThunk& thunk) {\n                                         thunk.async_events());\n }\n \n+static absl::StatusOr<Command> Convert(\n+    const CollectiveBroadcastStartThunk& thunk) {\n+  return std::make_unique<CollectiveBroadcastCmd>(\n+      thunk.config(), thunk.buffers(), thunk.async_events());\n+}\n+\n static absl::StatusOr<Command> Convert(\n     const DynamicSliceThunk& thunk, const ConvertToCommandsOptions& options) {\n   TF_ASSIGN_OR_RETURN(\n@@ -218,11 +225,10 @@ static absl::StatusOr<Command> Convert(const CustomCallThunk& thunk) {\n         thunk.target_name(), bundle->execute, thunk.operands(), thunk.results(),\n         *thunk.call_frame(),\n         /*called_computation=*/nullptr);  // TODO(b/342285364)\n-  } else {\n-    return std::make_unique<CustomCallCmd>(\n-        thunk.target_name(), thunk.call_target(), thunk.operands(),\n-        thunk.results(), thunk.opaque());\n   }\n+  return std::make_unique<CustomCallCmd>(thunk.target_name(),\n+                                         thunk.call_target(), thunk.operands(),\n+                                         thunk.results(), thunk.opaque());\n }\n \n static absl::StatusOr<Command> Convert(const CuDnnThunk& thunk) {\n@@ -288,6 +294,8 @@ static absl::Status AppendCommands(CommandBufferCmdSequence& cmd_sequence,\n       return append(Convert<ReduceScatterStartThunk>(thunk));\n     case Thunk::Kind::kAllToAllStart:\n       return append(Convert<AllToAllStartThunk>(thunk));\n+    case Thunk::Kind::kCollectiveBroadcastStart:\n+      return append(Convert<CollectiveBroadcastStartThunk>(thunk));\n     case Thunk::Kind::kPartitionId:\n       return append(Convert<PartitionIdThunk>(thunk));\n     case Thunk::Kind::kReplicaId:\n@@ -308,8 +316,9 @@ static absl::Status AppendCommands(CommandBufferCmdSequence& cmd_sequence,\n \n     case Thunk::Kind::kAllGatherDone:\n     case Thunk::Kind::kAllReduceDone:\n-    case Thunk::Kind::kReduceScatterDone:\n     case Thunk::Kind::kAllToAllDone:\n+    case Thunk::Kind::kCollectiveBroadcastDone:\n+    case Thunk::Kind::kReduceScatterDone:\n       if (options.synchronization_mode ==\n           CommandBufferCmdExecutor::SynchronizationMode::kLHS) {\n         return append(absl::StatusOr<Command>(std::make_unique<AsyncDoneCmd>("
        }
    ],
    "stats": {
        "total": 273,
        "additions": 267,
        "deletions": 6
    }
}