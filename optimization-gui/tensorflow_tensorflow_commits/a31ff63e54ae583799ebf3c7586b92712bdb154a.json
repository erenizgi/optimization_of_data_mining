{
    "author": "tensorflower-gardener",
    "message": "Refactor resource tracking logic done in GetResourcesForInstructionImpl.\n\nPiperOrigin-RevId: 821957518",
    "sha": "a31ff63e54ae583799ebf3c7586b92712bdb154a",
    "files": [
        {
            "sha": "16cfd49f8f0aa6e991079ecc53b7faef2eb30fd2",
            "filename": "third_party/xla/xla/service/latency_hiding_scheduler.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 30,
            "changes": 62,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a31ff63e54ae583799ebf3c7586b92712bdb154a/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a31ff63e54ae583799ebf3c7586b92712bdb154a/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc?ref=a31ff63e54ae583799ebf3c7586b92712bdb154a",
            "patch": "@@ -226,12 +226,6 @@ CanonicalAsyncOp DefaultGetCanonicalAsyncOp(const HloInstruction& hlo) {\n   switch (hlo.opcode()) {\n     case HloOpcode::kAsyncStart:\n     case HloOpcode::kAsyncDone:\n-      if (hlo.async_wrapped_opcode() == HloOpcode::kCall) {\n-        return {hlo.opcode(), hlo.async_wrapped_instruction()\n-                                  ->called_computations()[0]\n-                                  ->root_instruction()\n-                                  ->opcode()};\n-      }\n       return {hlo.opcode(), hlo.async_wrapped_opcode()};\n     case HloOpcode::kAllReduceStart:\n       return {HloOpcode::kAsyncStart, HloOpcode::kAllReduce};\n@@ -353,33 +347,34 @@ bool AsyncTracker::IsSupportedAsyncStart(const HloInstruction& hlo) const {\n   return false;\n }\n \n+ResourceType AsyncTracker::GetResourceTypeForOp(HloOpcode op) {\n+  switch (op) {\n+    case HloOpcode::kAllReduce:\n+      return ResourceType::kAllReduce;\n+    case HloOpcode::kAllGather:\n+      return ResourceType::kAllGather;\n+    case HloOpcode::kAllToAll:\n+      return ResourceType::kAllToAll;\n+    case HloOpcode::kRaggedAllToAll:\n+      return ResourceType::kRaggedAllToAll;\n+    case HloOpcode::kCollectiveBroadcast:\n+      return ResourceType::kCollectiveBroadcast;\n+    case HloOpcode::kCollectivePermute:\n+      return ResourceType::kCollectivePermute;\n+    case HloOpcode::kCopy:\n+      return ResourceType::kCopy;\n+    case HloOpcode::kReduceScatter:\n+      return ResourceType::kReduceScatter;\n+    default:\n+      return ResourceType::kNoResource;\n+  }\n+}\n+\n ResourcesVector AsyncTracker::GetResourcesFromInstructionImpl(\n     const HloInstruction& hlo) const {\n   CanonicalAsyncOp op = GetCanonicalAsyncOp(hlo);\n-  auto get_resource_for_op = [](HloOpcode op) -> ResourceType {\n-    switch (op) {\n-      case HloOpcode::kAllReduce:\n-        return ResourceType::kAllReduce;\n-      case HloOpcode::kAllGather:\n-        return ResourceType::kAllGather;\n-      case HloOpcode::kAllToAll:\n-        return ResourceType::kAllToAll;\n-      case HloOpcode::kRaggedAllToAll:\n-        return ResourceType::kRaggedAllToAll;\n-      case HloOpcode::kCollectiveBroadcast:\n-        return ResourceType::kCollectiveBroadcast;\n-      case HloOpcode::kCollectivePermute:\n-        return ResourceType::kCollectivePermute;\n-      case HloOpcode::kCopy:\n-        return ResourceType::kCopy;\n-      case HloOpcode::kReduceScatter:\n-        return ResourceType::kReduceScatter;\n-      default:\n-        return ResourceType::kNoResource;\n-    }\n-  };\n   if (op.outer == HloOpcode::kAsyncStart || op.outer == HloOpcode::kAsyncDone) {\n-    ResourceType type = get_resource_for_op(op.inner);\n+    ResourceType type = GetResourceTypeForOp(op.inner);\n     if (type == ResourceType::kNoResource) {\n       return {};\n     }\n@@ -469,7 +464,7 @@ ResourcesVector AsyncTracker::GetResourcesFromInstructionImpl(\n       // kResourceOccupy and a kResourceRelease that follows immediately after.\n       ResourcesVector res;\n       if (config_.track_sync_op_resource_usage) {\n-        ResourceType type = get_resource_for_op(hlo.opcode());\n+        ResourceType type = GetResourceTypeForOp(hlo.opcode());\n         if (type != ResourceType::kNoResource) {\n           res.push_back(std::make_pair(ResourceTypeToIndex(type),\n                                        ResourceUsageType::kResourceOccupy));\n@@ -3340,6 +3335,7 @@ LatencyHidingScheduler::LatencyHidingStatistics(\n     kSend,\n     kRecv,\n     kCollectiveBroadcast,\n+    kCall,\n   };\n   auto opcode_to_async_kind = [](HloOpcode opcode) {\n     switch (opcode) {\n@@ -3361,6 +3357,8 @@ LatencyHidingScheduler::LatencyHidingStatistics(\n         return AsyncKind::kSend;\n       case HloOpcode::kRecv:\n         return AsyncKind::kRecv;\n+      case HloOpcode::kCall:\n+        return AsyncKind::kCall;\n       default:\n         return AsyncKind::kNotAsync;\n     }\n@@ -3474,6 +3472,7 @@ LatencyHidingScheduler::LatencyHidingStatistics(\n       wasted_time_per_collective[AsyncKind::kReduceScatter],\n       /*send_wasted_cycles=*/wasted_time_per_collective[AsyncKind::kSend],\n       /*recv_wasted_cycles=*/wasted_time_per_collective[AsyncKind::kRecv],\n+      /*call_wasted_cycles=*/wasted_time_per_collective[AsyncKind::kCall],\n       /*total_cycles=*/current_time,\n       /*memory_pressure_peak=*/\n       memory_pressure_state\n@@ -3510,6 +3509,8 @@ std::string LatencyHidingScheduler::SchedulerStatistics::ToString() const {\n                   \"\\n\");\n   absl::StrAppend(&result, \"Wasted cycles for recv: \", this->recv_wasted_cycles,\n                   \"\\n\");\n+  absl::StrAppend(&result, \"Wasted cycles for asynchronous call: \",\n+                  this->call_wasted_cycles, \"\\n\");\n   absl::StrAppend(&result, \"Total cycles: \", this->total_cycles, \"\\n\");\n   absl::StrAppend(&result,\n                   \"Memory pressure peak (bytes): \", this->memory_pressure_peak,\n@@ -3529,6 +3530,7 @@ LatencyHidingScheduler::SchedulerStatistics::ToProto() const {\n   proto.set_reduce_scatter_wasted_cycles(reduce_scatter_wasted_cycles);\n   proto.set_send_wasted_cycles(send_wasted_cycles);\n   proto.set_recv_wasted_cycles(recv_wasted_cycles);\n+  proto.set_call_wasted_cycles(call_wasted_cycles);\n   proto.set_total_wasted_cycles(this->GetTotalWastedCycles());\n   proto.set_total_cycles(total_cycles);\n   proto.set_memory_pressure_peak(memory_pressure_peak);"
        },
        {
            "sha": "41f4d61662d4c46431ed90fd77f2996997d1ae17",
            "filename": "third_party/xla/xla/service/latency_hiding_scheduler.h",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a31ff63e54ae583799ebf3c7586b92712bdb154a/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a31ff63e54ae583799ebf3c7586b92712bdb154a/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h?ref=a31ff63e54ae583799ebf3c7586b92712bdb154a",
            "patch": "@@ -245,6 +245,9 @@ class AsyncTracker {\n   virtual ResourcesVector GetResourcesFromInstructionImpl(\n       const HloInstruction& hlo) const;\n \n+  // Gets the resource type associated with the given op.\n+  static ResourceType GetResourceTypeForOp(HloOpcode op);\n+\n   // Returns resources used (i.e., occupied or released) by this instruction\n   absl::Span<const ResourcePair> GetResourcesFromInstruction(\n       const HloInstruction& hlo) const;\n@@ -1784,6 +1787,7 @@ class LatencyHidingScheduler : public HloModulePass {\n     double reduce_scatter_wasted_cycles = 0;\n     double send_wasted_cycles = 0;\n     double recv_wasted_cycles = 0;\n+    double call_wasted_cycles = 0;\n     double total_cycles = 0;\n     int64_t memory_pressure_peak = 0;\n \n@@ -1792,7 +1796,7 @@ class LatencyHidingScheduler : public HloModulePass {\n              collective_broadcast_wasted_cycles +\n              collective_permute_wasted_cycles + all_to_all_wasted_cycles +\n              ragged_all_to_all_wasted_cycles + reduce_scatter_wasted_cycles +\n-             send_wasted_cycles + recv_wasted_cycles;\n+             send_wasted_cycles + recv_wasted_cycles + call_wasted_cycles;\n     }\n \n     ScheduleProto::SchedulerStatisticsProto ToProto() const;"
        },
        {
            "sha": "80459772c7bbaecfb9e915a6e8b3d301bf4386a8",
            "filename": "third_party/xla/xla/xla.proto",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a31ff63e54ae583799ebf3c7586b92712bdb154a/third_party%2Fxla%2Fxla%2Fxla.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a31ff63e54ae583799ebf3c7586b92712bdb154a/third_party%2Fxla%2Fxla%2Fxla.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fxla.proto?ref=a31ff63e54ae583799ebf3c7586b92712bdb154a",
            "patch": "@@ -1675,9 +1675,10 @@ message ScheduleProto {\n     double reduce_scatter_wasted_cycles = 7;\n     double send_wasted_cycles = 8;\n     double recv_wasted_cycles = 9;\n-    double total_wasted_cycles = 10;\n-    double total_cycles = 11;\n-    int64 memory_pressure_peak = 12;\n+    double call_wasted_cycles = 10;\n+    double total_wasted_cycles = 11;\n+    double total_cycles = 12;\n+    int64 memory_pressure_peak = 13;\n   }\n \n   message ComputationScheduleProto {"
        }
    ],
    "stats": {
        "total": 75,
        "additions": 41,
        "deletions": 34
    }
}