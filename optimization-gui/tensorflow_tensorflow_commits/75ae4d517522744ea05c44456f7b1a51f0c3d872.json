{
    "author": "WillFroom",
    "message": "[XLA:CPU/GPU][XTile] Split tiled emitting and lowering into two separate targets.\n\nThis will allow the CPU pipeline to use the tiled emitter without depending on the whole world.\n\nNote: this is purely code movement - there is no functional change.\nPiperOrigin-RevId: 837105665",
    "sha": "75ae4d517522744ea05c44456f7b1a51f0c3d872",
    "files": [
        {
            "sha": "a58c5b3ec286fa03d54e0bfd73ee19b27eb6b401",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/BUILD",
            "status": "modified",
            "additions": 91,
            "deletions": 12,
            "changes": 103,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -36,6 +36,7 @@ cc_library(\n     ],\n     deps = [\n         \":fusion_emitter\",\n+        \":xtile_compiler\",\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla:util\",\n@@ -245,12 +246,83 @@ xla_cc_test(\n \n cc_library(\n     name = \"fusion_emitter\",\n+    srcs = [\"fusion_emitter.cc\"],\n+    hdrs = [\"fusion_emitter.h\"],\n+    deps = [\n+        \":collective_emitter\",  # TODO(willfroom): Migrate to using stablehlo.allreduce etc.\n+        \":dot_algorithms\",\n+        \":emitter_helpers\",\n+        \"//xla:autotuning_proto_cc\",\n+        \"//xla:permutation_util\",\n+        \"//xla:shape_util\",\n+        \"//xla:status_macros\",\n+        \"//xla:util\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla:xla_proto_cc\",\n+        \"//xla/backends/gpu/codegen/triton/ir:triton_xla\",\n+        \"//xla/codegen:emitter_loc_op_builder\",\n+        \"//xla/codegen/emitters:elemental_hlo_to_mlir\",\n+        \"//xla/codegen/emitters/ir:xla\",\n+        \"//xla/codegen/tiling:symbolic_tile_analysis\",\n+        \"//xla/codegen/tiling:tiled_hlo_computation\",\n+        \"//xla/codegen/tiling:tiled_hlo_fusion_instruction\",\n+        \"//xla/codegen/tiling:tiled_hlo_instruction\",\n+        \"//xla/codegen/tiling:tiled_hlo_schedule\",\n+        \"//xla/codegen/tiling:tiling_specification\",\n+        \"//xla/codegen/xtile/ir:xtile\",\n+        \"//xla/hlo/analysis:indexing_analysis\",\n+        \"//xla/hlo/builder:xla_builder\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/translate/hlo_to_mhlo:hlo_function_importer\",\n+        \"//xla/mlir_hlo\",\n+        \"//xla/service:hlo_module_config\",\n+        \"//xla/service:instruction_fusion\",\n+        \"//xla/service/gpu:backend_configs_cc\",\n+        \"//xla/service/gpu:ir_emission_utils\",\n+        \"//xla/service/gpu/model:block_level_parameters\",\n+        \"//xla/service/llvm_ir:llvm_util\",\n+        \"//xla/tools:hlo_decomposer_lib\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/container:inlined_vector\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@llvm-project//llvm:Support\",\n+        \"@llvm-project//llvm:ir_headers\",\n+        \"@llvm-project//mlir:AffineToStandard\",\n+        \"@llvm-project//mlir:ArithDialect\",\n+        \"@llvm-project//mlir:BuiltinToLLVMIRTranslation\",\n+        \"@llvm-project//mlir:FunctionInterfaces\",\n+        \"@llvm-project//mlir:IR\",\n+        \"@llvm-project//mlir:LLVMToLLVMIRTranslation\",\n+        \"@llvm-project//mlir:NVVMToLLVMIRTranslation\",\n+        \"@llvm-project//mlir:Pass\",\n+        \"@llvm-project//mlir:ROCDLToLLVMIRTranslation\",\n+        \"@llvm-project//mlir:SCFDialect\",\n+        \"@llvm-project//mlir:Support\",\n+        \"@llvm-project//mlir:TensorDialect\",\n+        \"@llvm-project//mlir:ToLLVMIRTranslation\",\n+        \"@local_tsl//tsl/platform:path\",\n+        \"@stablehlo//:stablehlo_ops\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"xtile_compiler\",\n     # Using if_cuda_or_rocm_is_configured guard to prevent sycl target build / link errors.\n     srcs = if_cuda_or_rocm_is_configured(\n-        [\"fusion_emitter.cc\"],\n-        [\"fusion_emitter_stub.cc\"],\n+        [\"xtile_compiler.cc\"],\n+        [\"xtile_compiler_stub.cc\"],\n     ),\n-    hdrs = [\"fusion_emitter.h\"],\n+    hdrs = [\"xtile_compiler.h\"],\n     compatible_with = get_compatible_with_portable(),\n     deps = [\n         \"//xla:autotuning_proto_cc\",\n@@ -283,6 +355,7 @@ cc_library(\n         \"@stablehlo//:stablehlo_ops\",\n         \"@triton//:TritonDialects\",\n     ] + if_cuda_or_rocm_is_configured([\n+        \":fusion_emitter\",\n         \":lowering_util\",\n         \":compilation_pipeline\",\n         \":collective_emitter\",\n@@ -366,6 +439,7 @@ cc_library(\n     name = \"dot_algorithms\",\n     srcs = [\"dot_algorithms.cc\"],\n     hdrs = [\"dot_algorithms.h\"],\n+    compatible_with = get_compatible_with_portable(),\n     deps = [\n         \":emitter_helpers\",\n         \"//xla:xla_data_proto_cc\",\n@@ -395,13 +469,14 @@ cc_library(\n )\n \n cc_library(\n-    name = \"fusion_emitter_stub_for_testing\",\n+    name = \"xtile_compiler_stub_for_testing\",\n     srcs = [\n-        \"fusion_emitter_stub.cc\",\n+        \"xtile_compiler_stub.cc\",\n     ],\n     hdrs = [\n-        \"fusion_emitter.h\",\n+        \"xtile_compiler.h\",\n     ],\n+    visibility = [\"//visibility:private\"],\n     deps = [\n         \":emitter_helpers\",\n         \":support\",\n@@ -438,10 +513,10 @@ cc_library(\n )\n \n xla_cc_test(\n-    name = \"fusion_emitter_stub_test\",\n-    srcs = [\"fusion_emitter_stub_test.cc\"],\n+    name = \"xtile_compiler_stub_test\",\n+    srcs = [\"xtile_compiler_stub_test.cc\"],\n     deps = [\n-        \":fusion_emitter_stub_for_testing\",\n+        \":xtile_compiler_stub_for_testing\",\n         \"//xla:literal\",\n         \"//xla:literal_util\",\n         \"//xla/codegen:emitter_loc_op_builder\",\n@@ -461,10 +536,9 @@ xla_cc_test(\n     srcs = [\"fusion_emitter_deviceless_test.cc\"],\n     tags = [\"no_oss\"],  # Doesn't pass in OSS when building with the `fusion_emitter_stub`.\n     deps = [\n-        \":fusion_emitter\",\n+        \":xtile_compiler\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/codegen:emitter_loc_op_builder\",\n-        \"//xla/hlo/analysis:symbolic_expr\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:filecheck\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n@@ -500,6 +574,7 @@ xla_test(\n     deps = [\n         \":fusion_emitter\",\n         \":test_utils\",\n+        \":xtile_compiler\",\n         \"//xla:autotuning_proto_cc\",\n         \"//xla:error_spec\",\n         \"//xla:xla_data_proto_cc\",\n@@ -657,6 +732,7 @@ xla_test(\n         \":fusion_emitter\",\n         \":support\",\n         \":test_utils\",\n+        \":xtile_compiler\",\n         \"//xla:autotuning_proto_cc\",\n         \"//xla:error_spec\",\n         \"//xla:literal\",\n@@ -710,6 +786,7 @@ cc_library(\n     hdrs = [\"test_utils.h\"],\n     deps = [\n         \":fusion_emitter\",\n+        \":xtile_compiler\",\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla:xla_data_proto_cc\",\n@@ -876,6 +953,7 @@ xla_cc_test(\n         \":fusion_emitter\",\n         \":support\",\n         \":test_utils\",\n+        \":xtile_compiler\",\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n@@ -911,6 +989,7 @@ xla_test(\n         \":fusion_emitter\",\n         \":support\",\n         \":test_utils\",\n+        \":xtile_compiler\",\n         \"//xla:error_spec\",\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n@@ -996,7 +1075,7 @@ xla_cc_test(\n     deps = [\n         \":collective_emitter\",\n         \":fusion\",\n-        \":fusion_emitter\",\n+        \":xtile_compiler\",\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla/backends/gpu/codegen:fusion_emitter\","
        },
        {
            "sha": "112a6b0eaa11954741120091ed2761bdd1e61de2",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/collective_emitter_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcollective_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcollective_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcollective_emitter_test.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -32,7 +32,7 @@ limitations under the License.\n #include \"xla/backends/gpu/codegen/fusion_emitter.h\"\n #include \"xla/backends/gpu/codegen/fusions.h\"\n #include \"xla/backends/gpu/codegen/triton/fusion.h\"\n-#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\""
        },
        {
            "sha": "bd35774d17058561a9023f27af42dbb7f2bbc7b4",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion.h?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -1,3 +1,4 @@\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n /* Copyright 2024 The OpenXLA Authors.\n \n Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -21,7 +22,6 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"llvm/IR/Module.h\"\n #include \"xla/backends/gpu/codegen/fusion_emitter.h\"\n-#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n #include \"xla/codegen/tiling/tiled_hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/service/gpu/hlo_fusion_analysis.h\""
        },
        {
            "sha": "d3f76d8c06fb604377e1aaecc776cbfc9dbd9e09",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 504,
            "changes": 505,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -19,7 +19,6 @@ limitations under the License.\n #include <memory>\n #include <optional>\n #include <string>\n-#include <system_error>  // NOLINT\n #include <utility>\n #include <variant>\n #include <vector>\n@@ -40,30 +39,10 @@ limitations under the License.\n #include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/SmallVector.h\"\n #include \"llvm/IR/LLVMContext.h\"\n-#include \"llvm/IR/Metadata.h\"\n-#include \"llvm/IR/Module.h\"\n-#include \"llvm/Linker/Linker.h\"\n-#include \"llvm/Support/Debug.h\"\n-#include \"llvm/Support/FileSystem.h\"\n-#include \"llvm/Support/LogicalResult.h\"\n-#include \"llvm/Support/raw_ostream.h\"\n-#include \"llvm/TargetParser/Triple.h\"\n #include \"mlir/Conversion/AffineToStandard/AffineToStandard.h\"\n-#include \"mlir/Conversion/ArithToLLVM/ArithToLLVM.h\"\n-#include \"mlir/Conversion/ControlFlowToLLVM/ControlFlowToLLVM.h\"\n-#include \"mlir/Conversion/IndexToLLVM/IndexToLLVM.h\"\n-#include \"mlir/Conversion/SCFToControlFlow/SCFToControlFlow.h\"\n-#include \"mlir/Dialect/Affine/IR/AffineOps.h\"\n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n-#include \"mlir/Dialect/Func/Extensions/InlinerExtension.h\"\n-#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n-#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n-#include \"mlir/Dialect/LLVMIR/LLVMTypes.h\"\n-#include \"mlir/Dialect/LLVMIR/NVVMDialect.h\"\n-#include \"mlir/Dialect/LLVMIR/Transforms/InlinerInterfaceImpl.h\"\n #include \"mlir/Dialect/SCF/IR/SCF.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n-#include \"mlir/ExecutionEngine/OptUtils.h\"\n #include \"mlir/IR/AffineExpr.h\"\n #include \"mlir/IR/Attributes.h\"\n #include \"mlir/IR/Builders.h\"\n@@ -72,7 +51,6 @@ limitations under the License.\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/Diagnostics.h\"\n-#include \"mlir/IR/DialectRegistry.h\"\n #include \"mlir/IR/Location.h\"\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/IR/OwningOpRef.h\"\n@@ -82,38 +60,27 @@ limitations under the License.\n #include \"mlir/IR/ValueRange.h\"\n #include \"mlir/IR/Verifier.h\"\n #include \"mlir/Interfaces/FunctionInterfaces.h\"\n-#include \"mlir/Pass/Pass.h\"\n #include \"mlir/Pass/PassManager.h\"\n #include \"mlir/Support/LLVM.h\"\n-#include \"mlir/Support/LogicalResult.h\"\n #include \"mlir/Target/LLVMIR/Dialect/Builtin/BuiltinToLLVMIRTranslation.h\"\n #include \"mlir/Target/LLVMIR/Dialect/LLVMIR/LLVMToLLVMIRTranslation.h\"\n #include \"mlir/Target/LLVMIR/Dialect/NVVM/NVVMToLLVMIRTranslation.h\"\n #include \"mlir/Target/LLVMIR/Dialect/ROCDL/ROCDLToLLVMIRTranslation.h\"\n #include \"mlir/Target/LLVMIR/Export.h\"\n-#include \"mlir/Transforms/Passes.h\"\n #include \"stablehlo/dialect/StablehloOps.h\"\n-#include \"xla/backends/gpu/codegen/emitters/ir/xla_gpu_ops.h\"\n #include \"xla/backends/gpu/codegen/triton/collective_emitter.h\"\n-#include \"xla/backends/gpu/codegen/triton/compilation_pipeline.h\"\n #include \"xla/backends/gpu/codegen/triton/dot_algorithms.h\"\n #include \"xla/backends/gpu/codegen/triton/emitter_helpers.h\"\n #include \"xla/backends/gpu/codegen/triton/ir/triton_xla_ops.h\"\n-#include \"xla/backends/gpu/codegen/triton/lowering_util.h\"\n-#include \"xla/backends/gpu/codegen/triton/support.h\"\n-#include \"xla/backends/gpu/codegen/triton/transforms/passes.h\"\n #include \"xla/codegen/emitter_loc_op_builder.h\"\n #include \"xla/codegen/emitters/elemental_hlo_to_mlir.h\"\n-#include \"xla/codegen/emitters/ir/xla_dialect.h\"\n #include \"xla/codegen/emitters/ir/xla_ops.h\"\n-#include \"xla/codegen/emitters/transforms/passes.h\"\n #include \"xla/codegen/tiling/symbolic_tile_analysis.h\"\n #include \"xla/codegen/tiling/tiled_hlo_computation.h\"\n #include \"xla/codegen/tiling/tiled_hlo_fusion_instruction.h\"\n #include \"xla/codegen/tiling/tiled_hlo_instruction.h\"\n #include \"xla/codegen/tiling/tiled_hlo_schedule.h\"\n-#include \"xla/codegen/xtile/ir/transforms/passes.h\"\n-#include \"xla/codegen/xtile/ir/xtile_dialect.h\"\n+#include \"xla/codegen/tiling/tiling_specification.h\"\n #include \"xla/codegen/xtile/ir/xtile_ops.h\"\n #include \"xla/hlo/analysis/indexing_map.h\"\n #include \"xla/hlo/builder/xla_builder.h\"\n@@ -129,41 +96,28 @@ limitations under the License.\n #include \"xla/mlir_hlo/mhlo/IR/hlo_ops.h\"\n #include \"xla/permutation_util.h\"\n #include \"xla/primitive_util.h\"\n-#include \"xla/service/dump.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n-#include \"xla/service/gpu/llvm_gpu_backend/nvptx_libdevice_path.h\"\n #include \"xla/service/gpu/model/block_level_parameters.h\"\n-#include \"xla/service/gpu/model/triton_emitter_constraints.h\"\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/service/instruction_fusion.h\"\n #include \"xla/service/llvm_ir/llvm_util.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n-#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n-#include \"xla/stream_executor/device_description.h\"\n-#include \"xla/stream_executor/gpu/tma_metadata.h\"\n-#include \"xla/stream_executor/launch_dim.h\"\n #include \"xla/tools/hlo_decomposer.h\"\n-#include \"xla/tsl/framework/mlir/status_scoped_diagnostic_handler.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n #include \"xla/xla.pb.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/path.h\"\n-#include \"triton/Dialect/Triton/IR/Dialect.h\"\n-#include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n \n namespace xla {\n namespace gpu {\n \n namespace arith = ::mlir::arith;\n-namespace ttir = ::mlir::triton;\n namespace mtx = ::mlir::triton::xla;\n namespace stablehlo = ::mlir::stablehlo;\n-namespace xgt = ::xla::gpu::triton;\n \n using ::llvm::SmallVector;\n using ::mlir::AffineMap;\n@@ -1381,7 +1335,6 @@ absl::StatusOr<Tiling> TilingFromAnnotatedFusion(\n }  // namespace ir_emitter_triton_internal\n \n namespace {\n-using ::xla::gpu::ir_emitter_triton_internal::DumpTritonIR;\n \n absl::Status EmitGeneric(\n     mlir::OpBuilder builder,\n@@ -1507,58 +1460,6 @@ absl::Status EmitGeneric(\n \n }  // namespace\n \n-void LoadMlirDialectsForTriton(mlir::MLIRContext& mlir_context) {\n-  mlir_context.loadDialect<\n-      ttir::TritonDialect, ttir::gpu::TritonGPUDialect,\n-      mlir::arith::ArithDialect, mlir::affine::AffineDialect,\n-      mlir::LLVM::LLVMDialect, xla::XlaDialect, xla::gpu::XlaGpuDialect,\n-      ttir::xla::XlaTritonDialect, mlir::func::FuncDialect,\n-      mlir::tensor::TensorDialect, xla::xtile::XTileDialect,\n-      mlir::NVVM::NVVMDialect, stablehlo::StablehloDialect>();\n-  mlir::DialectRegistry registry;\n-  mlir::func::registerInlinerExtension(registry);\n-  mlir::LLVM::registerInlinerInterface(registry);\n-  mlir_context.appendDialectRegistry(registry);\n-}\n-\n-// Simplified copy of translateLLVMToLLVMIR which in addition takes\n-// path to libdevice directly as an argument.\n-absl::StatusOr<std::unique_ptr<llvm::Module>> TranslateLLVMToLLVMIR(\n-    llvm::LLVMContext* llvmContext, mlir::ModuleOp module) {\n-  mlir::DialectRegistry registry;\n-  mlir::registerBuiltinDialectTranslation(registry);\n-  mlir::registerLLVMDialectTranslation(registry);\n-  mlir::registerNVVMDialectTranslation(registry);\n-  mlir::registerROCDLDialectTranslation(registry);\n-  module->getContext()->appendDialectRegistry(registry);\n-\n-  std::unique_ptr<llvm::Module> llvmModule =\n-      mlir::translateModuleToLLVMIR(module, *llvmContext);\n-  if (!llvmModule) {\n-    return Internal(\"Failed to emit LLVM IR.\");\n-  }\n-  // TODO: b/363203060 - Upstream Triton sets specific flags for the LLVM\n-  // optimizer to get best performance. Figure out if we can gain any of it by\n-  // propagating these flags to\n-  // xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc.\n-  return llvmModule;\n-}\n-\n-absl::Status CreateInternalError(absl::string_view message,\n-                                 const HloFusionInstruction* fusion,\n-                                 mlir::ModuleOp triton_module) {\n-  std::string err;\n-  llvm::raw_string_ostream os(err);\n-  os << message << \"\\n\";\n-  os << \"fusion instruction: \" << fusion->ToString() << \"\\n\";\n-  os << \"HLO module to reproduce:\\n\"\n-     << ExtractInstructionIntoNewModule(*fusion)->ToString();\n-  os << \"triton_module>>>\\n\";\n-  triton_module->print(os, mlir::OpPrintingFlags().enableDebugInfo(true, true));\n-  os << \"<<<triton_module\\n\";\n-  return absl::InternalError(err);\n-}\n-\n mlir::MemRefType GetMemRefType(const Shape& shape, mlir::Type element_type) {\n   mlir::MLIRContext* context = element_type.getContext();\n   mlir::Type storage_type = StorageType(element_type);\n@@ -1576,343 +1477,6 @@ mlir::MemRefType GetMemRefType(const Shape& shape, mlir::Type element_type) {\n   return mlir::MemRefType::get(shape.dimensions(), storage_type, layout);\n }\n \n-absl::Status IsTritonSupportedFusion(const HloFusionInstruction& fusion,\n-                                     const se::DeviceDescription& device_info) {\n-  const HloComputation* computation = fusion.fused_instructions_computation();\n-  for (const HloInstruction* hlo : computation->instructions()) {\n-    // Skip generating nested fusions, they are emitted by their consumer.\n-    if (hlo->parent()->IsFusionComputation() &&\n-        hlo->opcode() == HloOpcode::kFusion) {\n-      if (hlo->GetModule()\n-              ->config()\n-              .debug_options()\n-              .xla_gpu_experimental_scaled_dot_with_triton()) {\n-        continue;\n-      }\n-      CodegenDecision decision = IsTritonSupportedInstruction(\n-          *hlo, device_info.gpu_compute_capability());\n-      if (!decision.CanFuse()) {\n-        return absl::FailedPreconditionError(\n-            absl::StrCat(\"Fusion \", hlo->ToString(),\n-                         \" is not supported: \", decision.Explain()));\n-      }\n-      VLOG(1) << \"Skipping nested fusion: \" << hlo->ToString();\n-      continue;\n-    }\n-\n-    if (hlo->opcode() == HloOpcode::kPad) {\n-      if (!IsTritonSupportedInstruction(*hlo,\n-                                        device_info.gpu_compute_capability())) {\n-        return absl::FailedPreconditionError(\n-            absl::StrCat(\"Pad is not supported: \", hlo->ToString()));\n-      }\n-    }\n-\n-    if (hlo->opcode() == HloOpcode::kReduce && hlo->dimensions().size() != 1) {\n-      return absl::FailedPreconditionError(\n-          absl::StrCat(\"Reduction with only a single dimension is supported: \",\n-                       hlo->ToString()));\n-    }\n-  }\n-\n-  return absl::OkStatus();\n-}\n-\n-absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> CreateTritonModule(\n-    absl::string_view fn_name, const HloFusionInstruction* fusion,\n-    const se::DeviceDescription& device_info,\n-    const BlockLevelParameters& block_level_parameters,\n-    MLIRContext& mlir_context) {\n-  TF_RETURN_IF_ERROR(IsTritonSupportedFusion(*fusion, device_info));\n-\n-  // TODO: b/451959933 - Use reference or check pointer.\n-\n-  TF_ASSIGN_OR_RETURN(\n-      auto triton_module,\n-      ir_emitter_triton_internal::EmitXTileModule(\n-          fn_name, TritonEmitterConstraints::GetBuilder(device_info), fusion,\n-          block_level_parameters, mlir_context));\n-\n-  const HloComputation* hlo_computation =\n-      fusion->fused_instructions_computation();\n-\n-  const auto debug_options = fusion->GetModule()->config().debug_options();\n-\n-  if (DumpingEnabledForHloModule(*hlo_computation->parent()) &&\n-      DumpingEnabledForEmitter(\"triton-fusion\", debug_options)) {\n-    auto suffix = absl::StrCat(fusion->name(), \".before_validation.ttir.txt\");\n-    DumpToFileInDirOrStdout(\n-        *hlo_computation->parent(), \"\", suffix,\n-        DumpTritonIR(triton_module.get(),\n-                     fusion->GetModule()\n-                         ->config()\n-                         .debug_options()\n-                         .xla_gpu_unsupported_annotate_with_emitter_loc()));\n-    std::string fusion_suffix = absl::StrCat(fusion->name(), \".hlo\");\n-    DumpToFileInDirOrStdout(\n-        *hlo_computation->parent(), \"\", fusion_suffix,\n-        ExtractInstructionIntoNewModule(*fusion)->ToString());\n-  }\n-\n-  TF_RETURN_IF_ERROR(ir_emitter_triton_internal::LowerXTileToTriton(\n-      triton_module.get(), mlir_context, *fusion, device_info));\n-\n-  VLOG(6) << DumpTritonIR(triton_module.get(),\n-                          fusion->GetModule()\n-                              ->config()\n-                              .debug_options()\n-                              .xla_gpu_unsupported_annotate_with_emitter_loc());\n-  if (DumpingEnabledForHloModule(*hlo_computation->parent()) &&\n-      DumpingEnabledForEmitter(\"triton-fusion\", debug_options)) {\n-    std::string suffix = absl::StrCat(fusion->name(), \".ttir.txt\");\n-    DumpToFileInDirOrStdout(\n-        *hlo_computation->parent(), \"\", suffix,\n-        DumpTritonIR(triton_module.get(),\n-                     fusion->GetModule()\n-                         ->config()\n-                         .debug_options()\n-                         .xla_gpu_unsupported_annotate_with_emitter_loc()));\n-  }\n-\n-  return std::move(triton_module);\n-}\n-\n-absl::Status CheckAtLeastAmpere(const se::GpuComputeCapability& gpu_cc) {\n-  if (auto* cuda_cc = gpu_cc.cuda_compute_capability();\n-      cuda_cc != nullptr && !cuda_cc->IsAtLeastAmpere()) {\n-    return absl::FailedPreconditionError(\n-        absl::StrCat(\"Triton support is only enabled for Ampere GPUs (compute \",\n-                     \"capability 8.0) and up, but got compute capability \",\n-                     cuda_cc->ToString(), \".\"));\n-  }\n-  return absl::OkStatus();\n-}\n-\n-absl::StatusOr<TritonWrapperResult> TritonWrapper(\n-    absl::string_view fn_name, const HloFusionInstruction* fusion,\n-    const se::GpuComputeCapability& gpu_cc,\n-    const se::DeviceDescription& device_info,\n-    const BlockLevelParameters& block_level_parameters,\n-    llvm::Module* llvm_module, MLIRContext& mlir_context) {\n-  TF_RETURN_IF_ERROR(CheckAtLeastAmpere(gpu_cc));\n-\n-  TF_ASSIGN_OR_RETURN(mlir::OwningOpRef<mlir::ModuleOp> triton_module,\n-                      CreateTritonModule(fn_name, fusion, device_info,\n-                                         block_level_parameters, mlir_context));\n-\n-  VLOG(3) << fusion->ToString(HloPrintOptions::ShortParsable());\n-  VLOG(3) << fusion->fused_instructions_computation()->ToString(\n-      HloPrintOptions::ShortParsable());\n-\n-  // Compile Triton kernel to LLVM.\n-  const HloModule* hlo_module = fusion->GetModule();\n-  return CompileTritonToLLVM(fn_name, *hlo_module, device_info,\n-                             block_level_parameters, triton_module.get(),\n-                             llvm_module, mlir_context,\n-                             /*is_xla_fusion=*/true);\n-}\n-\n-absl::StatusOr<TritonWrapperResult> CompileTritonToLLVM(\n-    absl::string_view kernel_name, const HloModule& hlo_module,\n-    const se::DeviceDescription& device_info,\n-    const BlockLevelParameters& block_level_parameters,\n-    mlir::ModuleOp triton_module, llvm::Module* llvm_module,\n-    mlir::MLIRContext& mlir_context, bool is_xla_fusion, bool emit_kernel) {\n-  const auto& gpu_cc = device_info.gpu_compute_capability();\n-  TF_RETURN_IF_ERROR(CheckAtLeastAmpere(gpu_cc));\n-  std::string arch_name = gpu_cc.ToString();\n-\n-  const HloModuleConfig& hlo_config = hlo_module.config();\n-\n-  bool should_verify =\n-      (hlo_config.debug_options().xla_gpu_llvm_verification_level() >= 1);\n-#ifndef NDEBUG\n-  should_verify = true;\n-#endif\n-\n-  bool should_dump_mlir_passes =\n-      hlo_config.debug_options().xla_enable_dumping() &&\n-      DumpingEnabledForHloModule(hlo_module) &&\n-      DumpingEnabledForEmitter(\"triton-fusion\", hlo_config.debug_options());\n-\n-  mlir::PassManager pm(&mlir_context);\n-  pm.enableVerifier(should_verify);\n-\n-  std::optional<llvm::raw_fd_ostream> log_stream;\n-  if (should_dump_mlir_passes) {\n-    std::string outputs_dir = hlo_config.debug_options().xla_dump_to();\n-    if (outputs_dir == \"sponge\") {\n-      if (!tsl::io::GetTestUndeclaredOutputsDir(&outputs_dir)) {\n-        LOG(ERROR) << \"Failed to get test undeclared outputs dir. Lets skip \"\n-                      \"dumping triton passes.\";\n-        outputs_dir = \"\";\n-      }\n-    }\n-    if (!outputs_dir.empty()) {\n-      const std::string basename =\n-          absl::StrCat(absl::string_view(tsl::io::Basename(hlo_module.name())),\n-                       \".\", kernel_name, \".triton-passes.log\");\n-      std::string path = tsl::io::JoinPath(outputs_dir, basename);\n-      std::error_code err;\n-      log_stream.emplace(path, err, llvm::sys::fs::OF_None);\n-      if (err) {\n-        log_stream.reset();\n-        LOG(ERROR) << \"Failed to dump triton passes to \" << path << \": \"\n-                   << err.message();\n-      } else {\n-        pm.getContext()->disableMultithreading();\n-        auto print_always = [](mlir::Pass*, mlir::Operation*) { return true; };\n-        pm.enableIRPrinting(/*shouldPrintBeforePass=*/print_always,\n-                            /*shouldPrintAfterPass=*/print_always,\n-                            /*printModuleScope=*/true,\n-                            /*printAfterOnlyOnChange=*/false,\n-                            /*printAfterOnlyOnFailure=*/true, *log_stream);\n-      }\n-    } else {\n-      LOG(ERROR)\n-          << \"--xla_dump_emitter_re=triton-fusion is set, but neither \"\n-          << \"the environment variable TEST_UNDECLARED_OUTPUTS_DIR nor the \"\n-          << \"flag --xla_dump_to is set, so the llvm dumps are disabled.\";\n-    }\n-  }\n-\n-  CreateTritonXlaPipeline(&pm, gpu_cc, /*rewrite_int4=*/is_xla_fusion,\n-                          block_level_parameters.is_tma_allowed,\n-                          block_level_parameters.num_stages);\n-\n-  int num_warps = block_level_parameters.num_warps;\n-  int num_ctas = block_level_parameters.num_ctas;\n-  int num_stages = block_level_parameters.num_stages;\n-  if (num_warps <= 0 || num_ctas <= 0 || num_stages <= 0) {\n-    return absl::FailedPreconditionError(absl::StrCat(\n-        \"(num_warps, num_ctas, num_stages) must be positive, but got: (\",\n-        num_warps, \", \", num_ctas, \", \", num_stages, \")\"));\n-  }\n-  mlir::triton::nvidia_gpu::ClusterInfo cluster_info;\n-  CreateTritonPipeline(&pm, gpu_cc, num_warps, num_ctas, num_stages,\n-                       cluster_info);\n-\n-  // Triton generates pointers to the global address space, while XLA needs a\n-  // kernel signature with pointers to the generic address space.\n-  pm.addPass(mlir::triton::xla::CreateGeneralizeKernelSignaturePass());\n-  // llvm::Linker::linkModules() segfaults if we don't strip locations.\n-  pm.addPass(mlir::createStripDebugInfoPass());\n-\n-  if (failed(pm.run(triton_module))) {\n-    return Internal(\"Failed to compile Triton kernel.\");\n-  }\n-\n-  const int shared_mem_bytes =\n-      triton_module->getAttrOfType<mlir::IntegerAttr>(\"ttg.shared\").getInt();\n-  VLOG(2) << \"Shared memory usage: \" << shared_mem_bytes << \" B\";\n-  if (shared_mem_bytes > device_info.shared_memory_per_block_optin()) {\n-    return absl::ResourceExhaustedError(absl::StrFormat(\n-        \"Shared memory size limit exceeded: requested %d, available: %d\",\n-        shared_mem_bytes, device_info.shared_memory_per_block_optin()));\n-  }\n-\n-  if (auto* cuda_cc = gpu_cc.cuda_compute_capability();\n-      cuda_cc != nullptr && cuda_cc->IsBlackwell()) {\n-    // https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-memory\n-    constexpr int kTensorMemoryColumns = 512;\n-    const int tensor_mem_columns =\n-        triton_module\n-            ->getAttrOfType<mlir::IntegerAttr>(\"ttg.tensor_memory_size\")\n-            .getInt();\n-    if (tensor_mem_columns > 0) {\n-      VLOG(2) << \"Tensor memory usage: \" << tensor_mem_columns << \" columns\";\n-    }\n-    if (tensor_mem_columns > kTensorMemoryColumns) {\n-      return absl::ResourceExhaustedError(absl::StrFormat(\n-          \"Tensor memory size limit exceeded: requested %d, available: %d\",\n-          tensor_mem_columns, kTensorMemoryColumns));\n-    }\n-  }\n-\n-  std::vector<llvm::Metadata*> captured_nvvm_annotations;\n-  if (emit_kernel) {\n-    TF_ASSIGN_OR_RETURN(\n-        std::unique_ptr<llvm::Module> ll_triton_module,\n-        TranslateLLVMToLLVMIR(&llvm_module->getContext(), triton_module));\n-\n-    XLA_VLOG_LINES(5, llvm_ir::DumpToString(ll_triton_module.get()));\n-    if (should_verify) {\n-      VerifyModule(*ll_triton_module);\n-    }\n-\n-    // Integrate LLVM matmul kernel into XLA's LLVM module.\n-    captured_nvvm_annotations =\n-        xgt::ExtractNvvmAnnotations(ll_triton_module.get());\n-    ll_triton_module->setDataLayout(llvm_module->getDataLayout());\n-    ll_triton_module->setTargetTriple(llvm_module->getTargetTriple());\n-    // Use override flag because libdevice functions can be present in both.\n-    TF_RET_CHECK(\n-        !llvm::Linker::linkModules(*llvm_module, std::move(ll_triton_module),\n-                                   llvm::Linker::Flags::OverrideFromSrc));\n-\n-    XLA_VLOG_LINES(5, llvm_ir::DumpToString(llvm_module));\n-    if (should_verify) {\n-      VerifyModule(*llvm_module);\n-    }\n-  }\n-\n-  // `cluster_info` must be read after pm.run().\n-  std::optional<se::ClusterDim> cluster_dim;\n-  if (block_level_parameters.num_ctas > 1) {\n-    VLOG(3) << \"num_ctas: \" << block_level_parameters.num_ctas\n-            << \", cluster_info: \" << cluster_info.clusterDimX << \",\"\n-            << cluster_info.clusterDimY << \",\" << cluster_info.clusterDimZ;\n-    if (cluster_info.clusterDimX > 1 || cluster_info.clusterDimY > 1 ||\n-        cluster_info.clusterDimZ > 1) {\n-      cluster_dim =\n-          se::ClusterDim(cluster_info.clusterDimX, cluster_info.clusterDimY,\n-                         cluster_info.clusterDimZ);\n-    }\n-  } else {\n-    TF_RET_CHECK(cluster_info.clusterDimX == 1 &&\n-                 cluster_info.clusterDimY == 1 &&\n-                 cluster_info.clusterDimZ == 1);\n-  }\n-\n-  SmallVector<mlir::LLVM::LLVMFuncOp> func_ops;\n-  for (auto func : triton_module.getOps<mlir::LLVM::LLVMFuncOp>()) {\n-    // Custom calls will also match to LLVMFuncOp, so we are only interested in\n-    // the entry function.\n-    if (func.getName().str() == kernel_name) {\n-      func_ops.push_back(func);\n-    }\n-  }\n-  CHECK_EQ(func_ops.size(), 1)\n-      << \"Expected a single LLVMFuncOp in the module for the entry function.\";\n-  mlir::LLVM::LLVMFuncOp func_op = func_ops[0];\n-\n-  TF_ASSIGN_OR_RETURN(se::ThreadDim thread_dims,\n-                      xgt::ExtractThreadDims(triton_module, func_op));\n-  TF_ASSIGN_OR_RETURN(stream_executor::gpu::TmaMetadata tma_metadata,\n-                      xgt::ExtractTmaMetadata(func_op));\n-\n-  // Propagate the following extracted information from the Triton module:\n-  // - TMA metadata.\n-  // - Total threads per block. Computed from module attributes.\n-  // - Captured NVVM annotations.\n-  TritonWrapperResult result = {\n-      shared_mem_bytes,          cluster_dim, tma_metadata, thread_dims,\n-      captured_nvvm_annotations,\n-  };\n-  return result;\n-}\n-\n-std::string GetLibdevicePath(const HloModuleConfig& hlo_config,\n-                             const se::DeviceDescription& device_info) {\n-  if (device_info.gpu_compute_capability().IsCuda()) {\n-    return nvptx::LibDevicePath(\n-        hlo_config.debug_options().xla_gpu_cuda_data_dir());\n-  }\n-  return \"\";\n-}\n-\n-namespace ir_emitter_triton_internal {\n-\n // TODO(b/447133106): Contrary to the name, this function still does a lot of\n // triton specific things. It should be migrated to use non-triton specific\n // utilities.\n@@ -1922,7 +1486,6 @@ absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> EmitXTileModule(\n     const HloFusionInstruction* fusion,\n     const BlockLevelParameters& block_level_parameters,\n     MLIRContext& mlir_context) {\n-  LoadMlirDialectsForTriton(mlir_context);\n   const auto debug_options = fusion->GetModule()->config().debug_options();\n \n   const HloComputation* hlo_computation =\n@@ -2011,71 +1574,5 @@ absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> EmitXTileModule(\n   return triton_module;\n }\n \n-absl::Status LowerXTileToTriton(mlir::ModuleOp xtile_dialect_module,\n-                                mlir::MLIRContext& mlir_context,\n-                                const HloFusionInstruction& fusion,\n-                                const se::DeviceDescription& device_info) {\n-  {\n-    // Convert xTile ops to Triton ops.\n-    mlir::PassManager pm(&mlir_context);\n-    // Disable verifier because the Triton code may be invalid due to the\n-    // unsupported types.\n-    pm.enableVerifier(/*enabled=*/false);\n-    pm.addPass(xtile::createConvertElementwise0DTensorToScalarPass());\n-    pm.addPass(mlir::triton::xla::CreateArithFP8ConversionToTritonPass());\n-    pm.addPass(mlir::triton::xla::CreateTensorLowerToTritonPass());\n-    pm.addPass(mlir::triton::xla::CreateStableHLOLowerToTritonPass());\n-    pm.addPass(mlir::triton::xla::CreateXTileLowerToTritonPass());\n-\n-    std::string libdevice_path =\n-        GetLibdevicePath(fusion.GetModule()->config(), device_info);\n-    absl::string_view triple = device_info.gpu_compute_capability().IsRocm()\n-                                   ? \"amdgcn-unknown-unknown\"\n-                                   : \"nvptx64-unknown-unknown\";\n-    pm.addPass(mlir::triton::xla::CreateTritonXLAMathToLibdevicePass(\n-        libdevice_path, triple));\n-\n-    tsl::StatusScopedDiagnosticHandler diagnostic_handler(&mlir_context);\n-    if (absl::Status status =\n-            diagnostic_handler.consumeStatus(pm.run(xtile_dialect_module));\n-        !status.ok()) {\n-      return CreateInternalError(\n-          \"Failed to lower from shared dialect to Triton.\", &fusion,\n-          xtile_dialect_module);\n-    }\n-  }\n-\n-  if (fusion.GetModule()\n-          ->config()\n-          .debug_options()\n-          .xla_gpu_experimental_scaled_dot_with_triton()) {\n-    // Convert unsupported types before verification.\n-    mlir::PassManager pm(&mlir_context);\n-    pm.addPass(mlir::triton::xla::CreateTritonXLAConvertUnsupportedTypesPass());\n-    if (mlir::failed(pm.run(xtile_dialect_module))) {\n-      return CreateInternalError(\n-          \"Failed to fix unsupported types in Triton module for fusion:\",\n-          &fusion, xtile_dialect_module);\n-    }\n-  }\n-\n-  if (mlir::failed(mlir::verify(xtile_dialect_module))) {\n-    return CreateInternalError(\"Failed to verify Triton module for fusion:\",\n-                               &fusion, xtile_dialect_module);\n-  }\n-  mlir::PassManager pm(&mlir_context);\n-\n-  pm.addPass(mlir::createCanonicalizerPass());\n-  pm.addPass(mlir::createCSEPass());\n-  if (mlir::failed(pm.run(xtile_dialect_module))) {\n-    return CreateInternalError(\"Failed to create Triton module for fusion:\",\n-                               &fusion, xtile_dialect_module);\n-  }\n-\n-  return absl::OkStatus();\n-}\n-\n-}  // namespace ir_emitter_triton_internal\n-\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "19804ffb78a139aa10965c07d175fe15f0f7b5e8",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.h",
            "status": "modified",
            "additions": 2,
            "deletions": 131,
            "changes": 133,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.h?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -16,135 +16,18 @@ limitations under the License.\n #ifndef XLA_BACKENDS_GPU_CODEGEN_TRITON_FUSION_EMITTER_H_\n #define XLA_BACKENDS_GPU_CODEGEN_TRITON_FUSION_EMITTER_H_\n \n-#include <cstdint>\n-#include <optional>\n-\n-#include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n-#include \"absl/types/span.h\"\n-#include \"llvm/ADT/SmallVector.h\"\n-#include \"llvm/IR/Metadata.h\"\n-#include \"llvm/IR/Module.h\"\n-#include \"llvm/Support/raw_ostream.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/IR/OwningOpRef.h\"\n-#include \"mlir/IR/Value.h\"\n #include \"mlir/Pass/PassManager.h\"\n #include \"xla/autotuning.pb.h\"\n-#include \"xla/codegen/emitter_loc_op_builder.h\"\n #include \"xla/codegen/tiling/symbolic_tile_analysis.h\"\n-#include \"xla/codegen/xtile/ir/xtile_ops.h\"\n-#include \"xla/hlo/analysis/symbolic_expr.h\"\n-#include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n-#include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/service/gpu/model/block_level_parameters.h\"\n-#include \"xla/service/hlo_module_config.h\"\n-#include \"xla/stream_executor/device_description.h\"\n-#include \"xla/stream_executor/gpu/tma_metadata.h\"\n-#include \"xla/stream_executor/launch_dim.h\"\n-\n-namespace mlir {\n-namespace triton {\n-namespace nvidia_gpu {\n-struct ClusterInfo;\n-}\n-}  // namespace triton\n-}  // namespace mlir\n-\n-namespace xla {\n-namespace gpu {\n-\n-struct TritonWrapperResult {\n-  int64_t shmem_bytes = 0;\n-  std::optional<se::ClusterDim> cluster_dim;\n-  se::gpu::TmaMetadata tma_metadata;\n-  se::ThreadDim thread_dims;\n-\n-  // The captured nvvm.annotations from the lowest level LLVM IR coming from\n-  // Triton. We need to propagate them because we later create the kernel and\n-  // splice the impl_fn into it.\n-  std::vector<llvm::Metadata*> nvvm_annotations;\n-};\n \n-// Load the MLIR dialects required for Triton IR generation.\n-void LoadMlirDialectsForTriton(mlir::MLIRContext& mlir_context);\n-\n-// Generate Triton IR by running the provided generator and compile it into LLVM\n-// IR.\n-absl::StatusOr<TritonWrapperResult> TritonWrapper(\n-    absl::string_view fn_name, const HloFusionInstruction* fusion,\n-    const se::GpuComputeCapability& cc,\n-    const se::DeviceDescription& device_info,\n-    const BlockLevelParameters& block_level_parameters,\n-    llvm::Module* llvm_module, mlir::MLIRContext& mlir_context);\n-\n-// Creates the initial Triton module for the given fusion. Visible for testing,\n-// use TritonWrapper instead.\n-absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> CreateTritonModule(\n-    absl::string_view fn_name, const HloFusionInstruction* fusion,\n-    const se::DeviceDescription& device_info,\n-    const BlockLevelParameters& block_level_parameters,\n-    mlir::MLIRContext& mlir_context);\n-\n-// Compiles a given Triton module to LLVM IR.\n-// If `emit_kernels` is false, then the function skips emitting\n-// the kernels, but it still returns correctly filled TritonWrapperResult.\n-// That is useful when deserializing from the compilation cache.\n-absl::StatusOr<TritonWrapperResult> CompileTritonToLLVM(\n-    absl::string_view kernel_name, const HloModule& hlo_module,\n-    const se::DeviceDescription& device_info,\n-    const BlockLevelParameters& block_level_parameters,\n-    mlir::ModuleOp triton_module, llvm::Module* llvm_module,\n-    mlir::MLIRContext& mlir_context, bool is_xla_fusion,\n-    bool emit_kernel = true);\n-\n-std::string GetLibdevicePath(const HloModuleConfig& hlo_config,\n-                             const se::DeviceDescription& device_info);\n-\n-// TODO(b/406472229): Move the contents of this namespace to a helpers file\n-// to avoid polluting `fusion_emitter.h`.\n-// Exposed for testing and experimental purposes only. Do not use.\n-namespace ir_emitter_triton_internal {\n-\n-// Computes the transformation from a 1-d program_id to a tile multi-index.\n-llvm::SmallVector<mlir::Value, 3> ComputeDelinearizedTileIndex(\n-    EmitterLocOpBuilder b, absl::Span<const int64_t> num_output_tiles_per_dim);\n-\n-// Dumps the Triton IR to a string.\n-//\n-// If `dump_annotations` is true, then the function also dumps the loc\n-// attributes of the instructions. Otherwise, it dumps the IR without\n-// annotations.\n-inline std::string DumpTritonIR(mlir::ModuleOp triton_module,\n-                                bool dump_annotations) {\n-  std::string triton_ir;\n-  llvm::raw_string_ostream os(triton_ir);\n-  triton_module.print(os, mlir::OpPrintingFlags().enableDebugInfo(\n-                              dump_annotations, dump_annotations));\n-  if (dump_annotations) {\n-    return EmitterLocOpBuilder::FormatTritonIrWithAnnotations(triton_ir);\n-  }\n-  return triton_ir;\n-}\n-\n-// Given a tiling specification for a fusion and an annotated fusion, derives a\n-// tiling for the annotated fusion.\n-//\n-// Note that the tiling extracted here is voluntarily not checked against the\n-// specification, which means that it could be invalid. This should only be the\n-// case, though, if this logic gets stale, or if the fusion does not contain\n-// the required annotations. Checking constraints is not cheap, so we left it up\n-// to the caller to decide when to check the constraints.\n-//\n-// TODO(b/421837868): this belongs near/in `BlockLevelParameters`, but we start\n-// with this here in order to allow an incremental replacement.\n-absl::StatusOr<Tiling> TilingFromAnnotatedFusion(\n-    const HloFusionInstruction* fusion,\n-    const SymbolicTileAnalysis& symbolic_tile_analysis,\n-    const BlockLevelParameters& block_level_parameters);\n+namespace xla::gpu {\n \n // This function (or its future equivalent) should emit the MLIR module in the\n // shared dialect between XLA:CPU and XLA:GPU. At the moment it is still\n@@ -158,18 +41,6 @@ absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> EmitXTileModule(\n     const BlockLevelParameters& block_level_parameters,\n     mlir::MLIRContext& mlir_context);\n \n-// This function lowers the shared dialect module to Triton. It is exposed for\n-// testing with the same motivation as EmitXTileModule.\n-//\n-// The `fusion` instruction should be the one that was used to create the shared\n-// dialect module.\n-absl::Status LowerXTileToTriton(mlir::ModuleOp xtile_dialect_module,\n-                                mlir::MLIRContext& mlir_context,\n-                                const HloFusionInstruction& fusion,\n-                                const se::DeviceDescription& device_info);\n-\n-}  // namespace ir_emitter_triton_internal\n-}  // namespace gpu\n-}  // namespace xla\n+}  // namespace xla::gpu\n \n #endif  // XLA_BACKENDS_GPU_CODEGEN_TRITON_FUSION_EMITTER_H_"
        },
        {
            "sha": "285aa18e7f853b7ebc3966399863ca45fe3715ba",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_port_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"xla/autotuning.pb.h\"\n #include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n #include \"xla/backends/gpu/codegen/triton/test_utils.h\"\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/error_spec.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_computation.h\""
        },
        {
            "sha": "bb4dc244c58d478c9d2734558c8c9ff088088b60",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -38,9 +38,9 @@ limitations under the License.\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/Pass/PassManager.h\"\n #include \"xla/autotuning.pb.h\"\n-#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n #include \"xla/backends/gpu/codegen/triton/support.h\"\n #include \"xla/backends/gpu/codegen/triton/test_utils.h\"\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/error_spec.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_computation.h\""
        },
        {
            "sha": "5c7ba14840ae34c345e2e152d9dcedda4b436e19",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_deviceless_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_deviceless_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_deviceless_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_deviceless_test.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -23,7 +23,7 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"llvm/IR/LLVMContext.h\"\n #include \"mlir/IR/MLIRContext.h\"\n-#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/codegen/emitter_loc_op_builder.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\""
        },
        {
            "sha": "5deccb9b8ba61e087452a2f143883bc8df840539",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/support_legacy_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_legacy_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_legacy_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_legacy_test.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -30,6 +30,7 @@ limitations under the License.\n #include \"absl/strings/substitute.h\"\n #include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n #include \"xla/backends/gpu/codegen/triton/test_utils.h\"\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/error_spec.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\""
        },
        {
            "sha": "c5bc005541c389352b42f7b832c28093021a70a8",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/support_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_test.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -36,6 +36,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n #include \"xla/backends/gpu/codegen/triton/test_utils.h\"\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/primitive_util.h\""
        },
        {
            "sha": "6673811c7c6b31d99a560e96b9461b0800867d70",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/test_utils.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftest_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftest_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftest_utils.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -37,6 +37,7 @@ limitations under the License.\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/IR/OwningOpRef.h\"\n #include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n@@ -165,14 +166,13 @@ absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> CreateXTileIrAndFileCheck(\n     const BlockLevelParameters& block_level_parameters,\n     absl::string_view filecheck_pattern) {\n   auto* fusion = Cast<HloFusionInstruction>(computation.FusionInstruction());\n-\n+  LoadMlirDialectsForTriton(*test->mlir_context());\n   TF_ASSIGN_OR_RETURN(\n       mlir::OwningOpRef<mlir::ModuleOp> xtile_dialect_module,\n-      ir_emitter_triton_internal::EmitXTileModule(\n-          \"xtile_dialect_fn\",\n-          TritonEmitterConstraints::GetBuilder(\n-              TestGpuDeviceInfo::RTXA6000DeviceInfo()),\n-          fusion, block_level_parameters, *test->mlir_context()));\n+      EmitXTileModule(\"xtile_dialect_fn\",\n+                      TritonEmitterConstraints::GetBuilder(\n+                          TestGpuDeviceInfo::RTXA6000DeviceInfo()),\n+                      fusion, block_level_parameters, *test->mlir_context()));\n \n   std::string out;\n   llvm::raw_string_ostream os(out);"
        },
        {
            "sha": "db82096ad2f6ecdb115c6675514bdb0fa698b2e6",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/xtile_compiler.cc",
            "status": "added",
            "additions": 592,
            "deletions": 0,
            "changes": 592,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -0,0 +1,592 @@\n+/* Copyright 2023 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n+\n+#include <memory>\n+#include <optional>\n+#include <string>\n+#include <system_error>  // NOLINT\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_format.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n+#include \"llvm/ADT/SmallVector.h\"\n+#include \"llvm/IR/LLVMContext.h\"\n+#include \"llvm/IR/Metadata.h\"\n+#include \"llvm/IR/Module.h\"\n+#include \"llvm/Linker/Linker.h\"\n+#include \"llvm/Support/Debug.h\"\n+#include \"llvm/Support/FileSystem.h\"\n+#include \"llvm/Support/LogicalResult.h\"\n+#include \"llvm/Support/raw_ostream.h\"\n+#include \"llvm/TargetParser/Triple.h\"\n+#include \"mlir/Conversion/AffineToStandard/AffineToStandard.h\"\n+#include \"mlir/Conversion/ArithToLLVM/ArithToLLVM.h\"\n+#include \"mlir/Conversion/ControlFlowToLLVM/ControlFlowToLLVM.h\"\n+#include \"mlir/Conversion/IndexToLLVM/IndexToLLVM.h\"\n+#include \"mlir/Conversion/SCFToControlFlow/SCFToControlFlow.h\"\n+#include \"mlir/Dialect/Affine/IR/AffineOps.h\"\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/Func/Extensions/InlinerExtension.h\"\n+#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n+#include \"mlir/Dialect/LLVMIR/LLVMTypes.h\"\n+#include \"mlir/Dialect/LLVMIR/NVVMDialect.h\"\n+#include \"mlir/Dialect/LLVMIR/Transforms/InlinerInterfaceImpl.h\"\n+#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n+#include \"mlir/ExecutionEngine/OptUtils.h\"\n+#include \"mlir/IR/AffineExpr.h\"\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/BuiltinOps.h\"\n+#include \"mlir/IR/BuiltinTypeInterfaces.h\"\n+#include \"mlir/IR/Diagnostics.h\"\n+#include \"mlir/IR/DialectRegistry.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/IR/OwningOpRef.h\"\n+#include \"mlir/IR/Value.h\"\n+#include \"mlir/IR/Verifier.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Pass/PassManager.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Support/LogicalResult.h\"\n+#include \"mlir/Target/LLVMIR/Dialect/Builtin/BuiltinToLLVMIRTranslation.h\"\n+#include \"mlir/Target/LLVMIR/Dialect/LLVMIR/LLVMToLLVMIRTranslation.h\"\n+#include \"mlir/Target/LLVMIR/Dialect/NVVM/NVVMToLLVMIRTranslation.h\"\n+#include \"mlir/Target/LLVMIR/Dialect/ROCDL/ROCDLToLLVMIRTranslation.h\"\n+#include \"mlir/Target/LLVMIR/Export.h\"\n+#include \"mlir/Transforms/Passes.h\"\n+#include \"stablehlo/dialect/StablehloOps.h\"\n+#include \"xla/backends/gpu/codegen/emitters/ir/xla_gpu_ops.h\"\n+#include \"xla/backends/gpu/codegen/triton/compilation_pipeline.h\"\n+#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n+#include \"xla/backends/gpu/codegen/triton/ir/triton_xla_ops.h\"\n+#include \"xla/backends/gpu/codegen/triton/lowering_util.h\"\n+#include \"xla/backends/gpu/codegen/triton/support.h\"\n+#include \"xla/backends/gpu/codegen/triton/transforms/passes.h\"\n+#include \"xla/codegen/emitters/ir/xla_dialect.h\"\n+#include \"xla/codegen/emitters/transforms/passes.h\"\n+#include \"xla/codegen/xtile/ir/transforms/passes.h\"\n+#include \"xla/codegen/xtile/ir/xtile_dialect.h\"\n+#include \"xla/hlo/builder/xla_builder.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_print_options.h\"\n+#include \"xla/hlo/translate/hlo_to_mhlo/hlo_function_importer.h\"\n+#include \"xla/service/dump.h\"\n+#include \"xla/service/gpu/backend_configs.pb.h\"\n+#include \"xla/service/gpu/ir_emission_utils.h\"\n+#include \"xla/service/gpu/llvm_gpu_backend/nvptx_libdevice_path.h\"\n+#include \"xla/service/gpu/model/block_level_parameters.h\"\n+#include \"xla/service/gpu/model/triton_emitter_constraints.h\"\n+#include \"xla/service/hlo_module_config.h\"\n+#include \"xla/service/llvm_ir/llvm_util.h\"\n+#include \"xla/status_macros.h\"\n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+#include \"xla/stream_executor/device_description.h\"\n+#include \"xla/stream_executor/gpu/tma_metadata.h\"\n+#include \"xla/stream_executor/launch_dim.h\"\n+#include \"xla/tools/hlo_decomposer.h\"\n+#include \"xla/tsl/framework/mlir/status_scoped_diagnostic_handler.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n+#include \"xla/xla.pb.h\"\n+#include \"xla/xla_data.pb.h\"\n+#include \"tsl/platform/path.h\"\n+#include \"triton/Dialect/Triton/IR/Dialect.h\"\n+#include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+namespace ttir = ::mlir::triton;\n+namespace stablehlo = ::mlir::stablehlo;\n+namespace xgt = ::xla::gpu::triton;\n+\n+using ::llvm::SmallVector;\n+using ::mlir::MLIRContext;\n+\n+using ::xla::gpu::ir_emitter_triton_internal::DumpTritonIR;\n+\n+void LoadMlirDialectsForTriton(mlir::MLIRContext& mlir_context) {\n+  mlir_context.loadDialect<\n+      ttir::TritonDialect, ttir::gpu::TritonGPUDialect,\n+      mlir::arith::ArithDialect, mlir::affine::AffineDialect,\n+      mlir::LLVM::LLVMDialect, xla::XlaDialect, xla::gpu::XlaGpuDialect,\n+      ttir::xla::XlaTritonDialect, mlir::func::FuncDialect,\n+      mlir::tensor::TensorDialect, xla::xtile::XTileDialect,\n+      mlir::NVVM::NVVMDialect, stablehlo::StablehloDialect>();\n+  mlir::DialectRegistry registry;\n+  mlir::func::registerInlinerExtension(registry);\n+  mlir::LLVM::registerInlinerInterface(registry);\n+  mlir_context.appendDialectRegistry(registry);\n+}\n+\n+// Simplified copy of translateLLVMToLLVMIR which in addition takes\n+// path to libdevice directly as an argument.\n+absl::StatusOr<std::unique_ptr<llvm::Module>> TranslateLLVMToLLVMIR(\n+    llvm::LLVMContext* llvmContext, mlir::ModuleOp module) {\n+  mlir::DialectRegistry registry;\n+  mlir::registerBuiltinDialectTranslation(registry);\n+  mlir::registerLLVMDialectTranslation(registry);\n+  mlir::registerNVVMDialectTranslation(registry);\n+  mlir::registerROCDLDialectTranslation(registry);\n+  module->getContext()->appendDialectRegistry(registry);\n+\n+  std::unique_ptr<llvm::Module> llvmModule =\n+      mlir::translateModuleToLLVMIR(module, *llvmContext);\n+  if (!llvmModule) {\n+    return Internal(\"Failed to emit LLVM IR.\");\n+  }\n+  // TODO: b/363203060 - Upstream Triton sets specific flags for the LLVM\n+  // optimizer to get best performance. Figure out if we can gain any of it by\n+  // propagating these flags to\n+  // xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc.\n+  return llvmModule;\n+}\n+\n+absl::Status CreateInternalError(absl::string_view message,\n+                                 const HloFusionInstruction* fusion,\n+                                 mlir::ModuleOp triton_module) {\n+  std::string err;\n+  llvm::raw_string_ostream os(err);\n+  os << message << \"\\n\";\n+  os << \"fusion instruction: \" << fusion->ToString() << \"\\n\";\n+  os << \"HLO module to reproduce:\\n\"\n+     << ExtractInstructionIntoNewModule(*fusion)->ToString();\n+  os << \"triton_module>>>\\n\";\n+  triton_module->print(os, mlir::OpPrintingFlags().enableDebugInfo(true, true));\n+  os << \"<<<triton_module\\n\";\n+  return absl::InternalError(err);\n+}\n+\n+absl::Status IsTritonSupportedFusion(const HloFusionInstruction& fusion,\n+                                     const se::DeviceDescription& device_info) {\n+  const HloComputation* computation = fusion.fused_instructions_computation();\n+  for (const HloInstruction* hlo : computation->instructions()) {\n+    // Skip generating nested fusions, they are emitted by their consumer.\n+    if (hlo->parent()->IsFusionComputation() &&\n+        hlo->opcode() == HloOpcode::kFusion) {\n+      if (hlo->GetModule()\n+              ->config()\n+              .debug_options()\n+              .xla_gpu_experimental_scaled_dot_with_triton()) {\n+        continue;\n+      }\n+      CodegenDecision decision = IsTritonSupportedInstruction(\n+          *hlo, device_info.gpu_compute_capability());\n+      if (!decision.CanFuse()) {\n+        return absl::FailedPreconditionError(\n+            absl::StrCat(\"Fusion \", hlo->ToString(),\n+                         \" is not supported: \", decision.Explain()));\n+      }\n+      VLOG(1) << \"Skipping nested fusion: \" << hlo->ToString();\n+      continue;\n+    }\n+\n+    if (hlo->opcode() == HloOpcode::kPad) {\n+      if (!IsTritonSupportedInstruction(*hlo,\n+                                        device_info.gpu_compute_capability())) {\n+        return absl::FailedPreconditionError(\n+            absl::StrCat(\"Pad is not supported: \", hlo->ToString()));\n+      }\n+    }\n+\n+    if (hlo->opcode() == HloOpcode::kReduce && hlo->dimensions().size() != 1) {\n+      return absl::FailedPreconditionError(\n+          absl::StrCat(\"Reduction with only a single dimension is supported: \",\n+                       hlo->ToString()));\n+    }\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n+absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> CreateTritonModule(\n+    absl::string_view fn_name, const HloFusionInstruction* fusion,\n+    const se::DeviceDescription& device_info,\n+    const BlockLevelParameters& block_level_parameters,\n+    MLIRContext& mlir_context) {\n+  TF_RETURN_IF_ERROR(IsTritonSupportedFusion(*fusion, device_info));\n+\n+  LoadMlirDialectsForTriton(mlir_context);\n+\n+  // TODO: b/451959933 - Use reference or check pointer.\n+\n+  TF_ASSIGN_OR_RETURN(\n+      auto triton_module,\n+      EmitXTileModule(fn_name,\n+                      TritonEmitterConstraints::GetBuilder(device_info), fusion,\n+                      block_level_parameters, mlir_context));\n+\n+  const HloComputation* hlo_computation =\n+      fusion->fused_instructions_computation();\n+\n+  const auto debug_options = fusion->GetModule()->config().debug_options();\n+\n+  if (DumpingEnabledForHloModule(*hlo_computation->parent()) &&\n+      DumpingEnabledForEmitter(\"triton-fusion\", debug_options)) {\n+    auto suffix = absl::StrCat(fusion->name(), \".before_validation.ttir.txt\");\n+    DumpToFileInDirOrStdout(\n+        *hlo_computation->parent(), \"\", suffix,\n+        DumpTritonIR(triton_module.get(),\n+                     fusion->GetModule()\n+                         ->config()\n+                         .debug_options()\n+                         .xla_gpu_unsupported_annotate_with_emitter_loc()));\n+    std::string fusion_suffix = absl::StrCat(fusion->name(), \".hlo\");\n+    DumpToFileInDirOrStdout(\n+        *hlo_computation->parent(), \"\", fusion_suffix,\n+        ExtractInstructionIntoNewModule(*fusion)->ToString());\n+  }\n+\n+  TF_RETURN_IF_ERROR(ir_emitter_triton_internal::LowerXTileToTriton(\n+      triton_module.get(), mlir_context, *fusion, device_info));\n+\n+  VLOG(6) << DumpTritonIR(triton_module.get(),\n+                          fusion->GetModule()\n+                              ->config()\n+                              .debug_options()\n+                              .xla_gpu_unsupported_annotate_with_emitter_loc());\n+  if (DumpingEnabledForHloModule(*hlo_computation->parent()) &&\n+      DumpingEnabledForEmitter(\"triton-fusion\", debug_options)) {\n+    std::string suffix = absl::StrCat(fusion->name(), \".ttir.txt\");\n+    DumpToFileInDirOrStdout(\n+        *hlo_computation->parent(), \"\", suffix,\n+        DumpTritonIR(triton_module.get(),\n+                     fusion->GetModule()\n+                         ->config()\n+                         .debug_options()\n+                         .xla_gpu_unsupported_annotate_with_emitter_loc()));\n+  }\n+\n+  return std::move(triton_module);\n+}\n+\n+absl::Status CheckAtLeastAmpere(const se::GpuComputeCapability& gpu_cc) {\n+  if (auto* cuda_cc = gpu_cc.cuda_compute_capability();\n+      cuda_cc != nullptr && !cuda_cc->IsAtLeastAmpere()) {\n+    return absl::FailedPreconditionError(\n+        absl::StrCat(\"Triton support is only enabled for Ampere GPUs (compute \",\n+                     \"capability 8.0) and up, but got compute capability \",\n+                     cuda_cc->ToString(), \".\"));\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::StatusOr<TritonWrapperResult> TritonWrapper(\n+    absl::string_view fn_name, const HloFusionInstruction* fusion,\n+    const se::GpuComputeCapability& gpu_cc,\n+    const se::DeviceDescription& device_info,\n+    const BlockLevelParameters& block_level_parameters,\n+    llvm::Module* llvm_module, MLIRContext& mlir_context) {\n+  TF_RETURN_IF_ERROR(CheckAtLeastAmpere(gpu_cc));\n+\n+  TF_ASSIGN_OR_RETURN(mlir::OwningOpRef<mlir::ModuleOp> triton_module,\n+                      CreateTritonModule(fn_name, fusion, device_info,\n+                                         block_level_parameters, mlir_context));\n+\n+  VLOG(3) << fusion->ToString(HloPrintOptions::ShortParsable());\n+  VLOG(3) << fusion->fused_instructions_computation()->ToString(\n+      HloPrintOptions::ShortParsable());\n+\n+  // Compile Triton kernel to LLVM.\n+  const HloModule* hlo_module = fusion->GetModule();\n+  return CompileTritonToLLVM(fn_name, *hlo_module, device_info,\n+                             block_level_parameters, triton_module.get(),\n+                             llvm_module, mlir_context,\n+                             /*is_xla_fusion=*/true);\n+}\n+\n+absl::StatusOr<TritonWrapperResult> CompileTritonToLLVM(\n+    absl::string_view kernel_name, const HloModule& hlo_module,\n+    const se::DeviceDescription& device_info,\n+    const BlockLevelParameters& block_level_parameters,\n+    mlir::ModuleOp triton_module, llvm::Module* llvm_module,\n+    mlir::MLIRContext& mlir_context, bool is_xla_fusion, bool emit_kernel) {\n+  const auto& gpu_cc = device_info.gpu_compute_capability();\n+  TF_RETURN_IF_ERROR(CheckAtLeastAmpere(gpu_cc));\n+  std::string arch_name = gpu_cc.ToString();\n+\n+  const HloModuleConfig& hlo_config = hlo_module.config();\n+\n+  bool should_verify =\n+      (hlo_config.debug_options().xla_gpu_llvm_verification_level() >= 1);\n+#ifndef NDEBUG\n+  should_verify = true;\n+#endif\n+\n+  bool should_dump_mlir_passes =\n+      hlo_config.debug_options().xla_enable_dumping() &&\n+      DumpingEnabledForHloModule(hlo_module) &&\n+      DumpingEnabledForEmitter(\"triton-fusion\", hlo_config.debug_options());\n+\n+  mlir::PassManager pm(&mlir_context);\n+  pm.enableVerifier(should_verify);\n+\n+  std::optional<llvm::raw_fd_ostream> log_stream;\n+  if (should_dump_mlir_passes) {\n+    std::string outputs_dir = hlo_config.debug_options().xla_dump_to();\n+    if (outputs_dir == \"sponge\") {\n+      if (!tsl::io::GetTestUndeclaredOutputsDir(&outputs_dir)) {\n+        LOG(ERROR) << \"Failed to get test undeclared outputs dir. Lets skip \"\n+                      \"dumping triton passes.\";\n+        outputs_dir = \"\";\n+      }\n+    }\n+    if (!outputs_dir.empty()) {\n+      const std::string basename =\n+          absl::StrCat(absl::string_view(tsl::io::Basename(hlo_module.name())),\n+                       \".\", kernel_name, \".triton-passes.log\");\n+      std::string path = tsl::io::JoinPath(outputs_dir, basename);\n+      std::error_code err;\n+      log_stream.emplace(path, err, llvm::sys::fs::OF_None);\n+      if (err) {\n+        log_stream.reset();\n+        LOG(ERROR) << \"Failed to dump triton passes to \" << path << \": \"\n+                   << err.message();\n+      } else {\n+        pm.getContext()->disableMultithreading();\n+        auto print_always = [](mlir::Pass*, mlir::Operation*) { return true; };\n+        pm.enableIRPrinting(/*shouldPrintBeforePass=*/print_always,\n+                            /*shouldPrintAfterPass=*/print_always,\n+                            /*printModuleScope=*/true,\n+                            /*printAfterOnlyOnChange=*/false,\n+                            /*printAfterOnlyOnFailure=*/true, *log_stream);\n+      }\n+    } else {\n+      LOG(ERROR)\n+          << \"--xla_dump_emitter_re=triton-fusion is set, but neither \"\n+          << \"the environment variable TEST_UNDECLARED_OUTPUTS_DIR nor the \"\n+          << \"flag --xla_dump_to is set, so the llvm dumps are disabled.\";\n+    }\n+  }\n+\n+  CreateTritonXlaPipeline(&pm, gpu_cc, /*rewrite_int4=*/is_xla_fusion,\n+                          block_level_parameters.is_tma_allowed,\n+                          block_level_parameters.num_stages);\n+\n+  int num_warps = block_level_parameters.num_warps;\n+  int num_ctas = block_level_parameters.num_ctas;\n+  int num_stages = block_level_parameters.num_stages;\n+  if (num_warps <= 0 || num_ctas <= 0 || num_stages <= 0) {\n+    return absl::FailedPreconditionError(absl::StrCat(\n+        \"(num_warps, num_ctas, num_stages) must be positive, but got: (\",\n+        num_warps, \", \", num_ctas, \", \", num_stages, \")\"));\n+  }\n+  mlir::triton::nvidia_gpu::ClusterInfo cluster_info;\n+  CreateTritonPipeline(&pm, gpu_cc, num_warps, num_ctas, num_stages,\n+                       cluster_info);\n+\n+  // Triton generates pointers to the global address space, while XLA needs a\n+  // kernel signature with pointers to the generic address space.\n+  pm.addPass(mlir::triton::xla::CreateGeneralizeKernelSignaturePass());\n+  // llvm::Linker::linkModules() segfaults if we don't strip locations.\n+  pm.addPass(mlir::createStripDebugInfoPass());\n+\n+  if (failed(pm.run(triton_module))) {\n+    return Internal(\"Failed to compile Triton kernel.\");\n+  }\n+\n+  const int shared_mem_bytes =\n+      triton_module->getAttrOfType<mlir::IntegerAttr>(\"ttg.shared\").getInt();\n+  VLOG(2) << \"Shared memory usage: \" << shared_mem_bytes << \" B\";\n+  if (shared_mem_bytes > device_info.shared_memory_per_block_optin()) {\n+    return absl::ResourceExhaustedError(absl::StrFormat(\n+        \"Shared memory size limit exceeded: requested %d, available: %d\",\n+        shared_mem_bytes, device_info.shared_memory_per_block_optin()));\n+  }\n+\n+  if (auto* cuda_cc = gpu_cc.cuda_compute_capability();\n+      cuda_cc != nullptr && cuda_cc->IsBlackwell()) {\n+    // https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-memory\n+    constexpr int kTensorMemoryColumns = 512;\n+    const int tensor_mem_columns =\n+        triton_module\n+            ->getAttrOfType<mlir::IntegerAttr>(\"ttg.tensor_memory_size\")\n+            .getInt();\n+    if (tensor_mem_columns > 0) {\n+      VLOG(2) << \"Tensor memory usage: \" << tensor_mem_columns << \" columns\";\n+    }\n+    if (tensor_mem_columns > kTensorMemoryColumns) {\n+      return absl::ResourceExhaustedError(absl::StrFormat(\n+          \"Tensor memory size limit exceeded: requested %d, available: %d\",\n+          tensor_mem_columns, kTensorMemoryColumns));\n+    }\n+  }\n+\n+  std::vector<llvm::Metadata*> captured_nvvm_annotations;\n+  if (emit_kernel) {\n+    TF_ASSIGN_OR_RETURN(\n+        std::unique_ptr<llvm::Module> ll_triton_module,\n+        TranslateLLVMToLLVMIR(&llvm_module->getContext(), triton_module));\n+\n+    XLA_VLOG_LINES(5, llvm_ir::DumpToString(ll_triton_module.get()));\n+    if (should_verify) {\n+      VerifyModule(*ll_triton_module);\n+    }\n+\n+    // Integrate LLVM matmul kernel into XLA's LLVM module.\n+    captured_nvvm_annotations =\n+        xgt::ExtractNvvmAnnotations(ll_triton_module.get());\n+    ll_triton_module->setDataLayout(llvm_module->getDataLayout());\n+    ll_triton_module->setTargetTriple(llvm_module->getTargetTriple());\n+    // Use override flag because libdevice functions can be present in both.\n+    TF_RET_CHECK(\n+        !llvm::Linker::linkModules(*llvm_module, std::move(ll_triton_module),\n+                                   llvm::Linker::Flags::OverrideFromSrc));\n+\n+    XLA_VLOG_LINES(5, llvm_ir::DumpToString(llvm_module));\n+    if (should_verify) {\n+      VerifyModule(*llvm_module);\n+    }\n+  }\n+\n+  // `cluster_info` must be read after pm.run().\n+  std::optional<se::ClusterDim> cluster_dim;\n+  if (block_level_parameters.num_ctas > 1) {\n+    VLOG(3) << \"num_ctas: \" << block_level_parameters.num_ctas\n+            << \", cluster_info: \" << cluster_info.clusterDimX << \",\"\n+            << cluster_info.clusterDimY << \",\" << cluster_info.clusterDimZ;\n+    if (cluster_info.clusterDimX > 1 || cluster_info.clusterDimY > 1 ||\n+        cluster_info.clusterDimZ > 1) {\n+      cluster_dim =\n+          se::ClusterDim(cluster_info.clusterDimX, cluster_info.clusterDimY,\n+                         cluster_info.clusterDimZ);\n+    }\n+  } else {\n+    TF_RET_CHECK(cluster_info.clusterDimX == 1 &&\n+                 cluster_info.clusterDimY == 1 &&\n+                 cluster_info.clusterDimZ == 1);\n+  }\n+\n+  SmallVector<mlir::LLVM::LLVMFuncOp> func_ops;\n+  for (auto func : triton_module.getOps<mlir::LLVM::LLVMFuncOp>()) {\n+    // Custom calls will also match to LLVMFuncOp, so we are only interested in\n+    // the entry function.\n+    if (func.getName().str() == kernel_name) {\n+      func_ops.push_back(func);\n+    }\n+  }\n+  CHECK_EQ(func_ops.size(), 1)\n+      << \"Expected a single LLVMFuncOp in the module for the entry function.\";\n+  mlir::LLVM::LLVMFuncOp func_op = func_ops[0];\n+\n+  TF_ASSIGN_OR_RETURN(se::ThreadDim thread_dims,\n+                      xgt::ExtractThreadDims(triton_module, func_op));\n+  TF_ASSIGN_OR_RETURN(stream_executor::gpu::TmaMetadata tma_metadata,\n+                      xgt::ExtractTmaMetadata(func_op));\n+\n+  // Propagate the following extracted information from the Triton module:\n+  // - TMA metadata.\n+  // - Total threads per block. Computed from module attributes.\n+  // - Captured NVVM annotations.\n+  TritonWrapperResult result = {\n+      shared_mem_bytes,          cluster_dim, tma_metadata, thread_dims,\n+      captured_nvvm_annotations,\n+  };\n+  return result;\n+}\n+\n+std::string GetLibdevicePath(const HloModuleConfig& hlo_config,\n+                             const se::DeviceDescription& device_info) {\n+  if (device_info.gpu_compute_capability().IsCuda()) {\n+    return nvptx::LibDevicePath(\n+        hlo_config.debug_options().xla_gpu_cuda_data_dir());\n+  }\n+  return \"\";\n+}\n+\n+namespace ir_emitter_triton_internal {\n+\n+absl::Status LowerXTileToTriton(mlir::ModuleOp xtile_dialect_module,\n+                                mlir::MLIRContext& mlir_context,\n+                                const HloFusionInstruction& fusion,\n+                                const se::DeviceDescription& device_info) {\n+  {\n+    // Convert xTile ops to Triton ops.\n+    mlir::PassManager pm(&mlir_context);\n+    // Disable verifier because the Triton code may be invalid due to the\n+    // unsupported types.\n+    pm.enableVerifier(/*enabled=*/false);\n+    pm.addPass(xtile::createConvertElementwise0DTensorToScalarPass());\n+    pm.addPass(mlir::triton::xla::CreateArithFP8ConversionToTritonPass());\n+    pm.addPass(mlir::triton::xla::CreateTensorLowerToTritonPass());\n+    pm.addPass(mlir::triton::xla::CreateStableHLOLowerToTritonPass());\n+    pm.addPass(mlir::triton::xla::CreateXTileLowerToTritonPass());\n+\n+    std::string libdevice_path =\n+        GetLibdevicePath(fusion.GetModule()->config(), device_info);\n+    absl::string_view triple = device_info.gpu_compute_capability().IsRocm()\n+                                   ? \"amdgcn-unknown-unknown\"\n+                                   : \"nvptx64-unknown-unknown\";\n+    pm.addPass(mlir::triton::xla::CreateTritonXLAMathToLibdevicePass(\n+        libdevice_path, triple));\n+\n+    tsl::StatusScopedDiagnosticHandler diagnostic_handler(&mlir_context);\n+    if (absl::Status status =\n+            diagnostic_handler.consumeStatus(pm.run(xtile_dialect_module));\n+        !status.ok()) {\n+      return CreateInternalError(\n+          \"Failed to lower from shared dialect to Triton.\", &fusion,\n+          xtile_dialect_module);\n+    }\n+  }\n+\n+  if (fusion.GetModule()\n+          ->config()\n+          .debug_options()\n+          .xla_gpu_experimental_scaled_dot_with_triton()) {\n+    // Convert unsupported types before verification.\n+    mlir::PassManager pm(&mlir_context);\n+    pm.addPass(mlir::triton::xla::CreateTritonXLAConvertUnsupportedTypesPass());\n+    if (mlir::failed(pm.run(xtile_dialect_module))) {\n+      return CreateInternalError(\n+          \"Failed to fix unsupported types in Triton module for fusion:\",\n+          &fusion, xtile_dialect_module);\n+    }\n+  }\n+\n+  if (mlir::failed(mlir::verify(xtile_dialect_module))) {\n+    return CreateInternalError(\"Failed to verify Triton module for fusion:\",\n+                               &fusion, xtile_dialect_module);\n+  }\n+  mlir::PassManager pm(&mlir_context);\n+\n+  pm.addPass(mlir::createCanonicalizerPass());\n+  pm.addPass(mlir::createCSEPass());\n+  if (mlir::failed(pm.run(xtile_dialect_module))) {\n+    return CreateInternalError(\"Failed to create Triton module for fusion:\",\n+                               &fusion, xtile_dialect_module);\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n+}  // namespace ir_emitter_triton_internal\n+\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "d1e2ec2aaf000f18b84057c3e6c2a3fcb4fc0b32",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/xtile_compiler.h",
            "status": "added",
            "additions": 163,
            "deletions": 0,
            "changes": 163,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler.h?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -0,0 +1,163 @@\n+/* Copyright 2023 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_CODEGEN_TRITON_XTILE_COMPILER_H_\n+#define XLA_BACKENDS_GPU_CODEGEN_TRITON_XTILE_COMPILER_H_\n+\n+#include <cstdint>\n+#include <optional>\n+\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n+#include \"llvm/ADT/SmallVector.h\"\n+#include \"llvm/IR/Metadata.h\"\n+#include \"llvm/IR/Module.h\"\n+#include \"llvm/Support/raw_ostream.h\"\n+#include \"mlir/IR/BuiltinOps.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/IR/OwningOpRef.h\"\n+#include \"mlir/IR/Value.h\"\n+#include \"mlir/Pass/PassManager.h\"\n+#include \"xla/autotuning.pb.h\"\n+#include \"xla/codegen/emitter_loc_op_builder.h\"\n+#include \"xla/codegen/tiling/symbolic_tile_analysis.h\"\n+#include \"xla/codegen/xtile/ir/xtile_ops.h\"\n+#include \"xla/hlo/analysis/symbolic_expr.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/service/gpu/model/block_level_parameters.h\"\n+#include \"xla/service/hlo_module_config.h\"\n+#include \"xla/stream_executor/device_description.h\"\n+#include \"xla/stream_executor/gpu/tma_metadata.h\"\n+#include \"xla/stream_executor/launch_dim.h\"\n+\n+namespace mlir {\n+namespace triton {\n+namespace nvidia_gpu {\n+struct ClusterInfo;\n+}\n+}  // namespace triton\n+}  // namespace mlir\n+\n+namespace xla {\n+namespace gpu {\n+\n+struct TritonWrapperResult {\n+  int64_t shmem_bytes = 0;\n+  std::optional<se::ClusterDim> cluster_dim;\n+  se::gpu::TmaMetadata tma_metadata;\n+  se::ThreadDim thread_dims;\n+\n+  // The captured nvvm.annotations from the lowest level LLVM IR coming from\n+  // Triton. We need to propagate them because we later create the kernel and\n+  // splice the impl_fn into it.\n+  std::vector<llvm::Metadata*> nvvm_annotations;\n+};\n+\n+// Load the MLIR dialects required for Triton IR generation.\n+void LoadMlirDialectsForTriton(mlir::MLIRContext& mlir_context);\n+\n+// Generate Triton IR by running the provided generator and compile it into LLVM\n+// IR.\n+absl::StatusOr<TritonWrapperResult> TritonWrapper(\n+    absl::string_view fn_name, const HloFusionInstruction* fusion,\n+    const se::GpuComputeCapability& cc,\n+    const se::DeviceDescription& device_info,\n+    const BlockLevelParameters& block_level_parameters,\n+    llvm::Module* llvm_module, mlir::MLIRContext& mlir_context);\n+\n+// Creates the initial Triton module for the given fusion. Visible for testing,\n+// use TritonWrapper instead.\n+absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> CreateTritonModule(\n+    absl::string_view fn_name, const HloFusionInstruction* fusion,\n+    const se::DeviceDescription& device_info,\n+    const BlockLevelParameters& block_level_parameters,\n+    mlir::MLIRContext& mlir_context);\n+\n+// Compiles a given Triton module to LLVM IR.\n+// If `emit_kernels` is false, then the function skips emitting\n+// the kernels, but it still returns correctly filled TritonWrapperResult.\n+// That is useful when deserializing from the compilation cache.\n+absl::StatusOr<TritonWrapperResult> CompileTritonToLLVM(\n+    absl::string_view kernel_name, const HloModule& hlo_module,\n+    const se::DeviceDescription& device_info,\n+    const BlockLevelParameters& block_level_parameters,\n+    mlir::ModuleOp triton_module, llvm::Module* llvm_module,\n+    mlir::MLIRContext& mlir_context, bool is_xla_fusion,\n+    bool emit_kernel = true);\n+\n+std::string GetLibdevicePath(const HloModuleConfig& hlo_config,\n+                             const se::DeviceDescription& device_info);\n+\n+// TODO(b/406472229): Move the contents of this namespace to a helpers file\n+// to avoid polluting `fusion_emitter.h`.\n+// Exposed for testing and experimental purposes only. Do not use.\n+namespace ir_emitter_triton_internal {\n+\n+// Computes the transformation from a 1-d program_id to a tile multi-index.\n+llvm::SmallVector<mlir::Value, 3> ComputeDelinearizedTileIndex(\n+    EmitterLocOpBuilder b, absl::Span<const int64_t> num_output_tiles_per_dim);\n+\n+// Dumps the Triton IR to a string.\n+//\n+// If `dump_annotations` is true, then the function also dumps the loc\n+// attributes of the instructions. Otherwise, it dumps the IR without\n+// annotations.\n+inline std::string DumpTritonIR(mlir::ModuleOp triton_module,\n+                                bool dump_annotations) {\n+  std::string triton_ir;\n+  llvm::raw_string_ostream os(triton_ir);\n+  triton_module.print(os, mlir::OpPrintingFlags().enableDebugInfo(\n+                              dump_annotations, dump_annotations));\n+  if (dump_annotations) {\n+    return EmitterLocOpBuilder::FormatTritonIrWithAnnotations(triton_ir);\n+  }\n+  return triton_ir;\n+}\n+\n+// Given a tiling specification for a fusion and an annotated fusion, derives a\n+// tiling for the annotated fusion.\n+//\n+// Note that the tiling extracted here is voluntarily not checked against the\n+// specification, which means that it could be invalid. This should only be the\n+// case, though, if this logic gets stale, or if the fusion does not contain\n+// the required annotations. Checking constraints is not cheap, so we left it up\n+// to the caller to decide when to check the constraints.\n+//\n+// TODO(b/421837868): this belongs near/in `BlockLevelParameters`, but we start\n+// with this here in order to allow an incremental replacement.\n+absl::StatusOr<Tiling> TilingFromAnnotatedFusion(\n+    const HloFusionInstruction* fusion,\n+    const SymbolicTileAnalysis& symbolic_tile_analysis,\n+    const BlockLevelParameters& block_level_parameters);\n+\n+// This function lowers the shared dialect module to Triton. It is exposed for\n+// testing with the same motivation as EmitXTileModule.\n+//\n+// The `fusion` instruction should be the one that was used to create the shared\n+// dialect module.\n+absl::Status LowerXTileToTriton(mlir::ModuleOp xtile_dialect_module,\n+                                mlir::MLIRContext& mlir_context,\n+                                const HloFusionInstruction& fusion,\n+                                const se::DeviceDescription& device_info);\n+\n+}  // namespace ir_emitter_triton_internal\n+}  // namespace gpu\n+}  // namespace xla\n+\n+#endif  // XLA_BACKENDS_GPU_CODEGEN_TRITON_XTILE_COMPILER_H_"
        },
        {
            "sha": "c619671a2a9cb10a69d6eed39dfe8007d2ea3fca",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/xtile_compiler_stub.cc",
            "status": "renamed",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler_stub.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler_stub.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler_stub.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -24,7 +24,7 @@ limitations under the License.\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/IR/OwningOpRef.h\"\n #include \"mlir/Pass/PassManager.h\"\n-#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/hlo/ir/hlo_clone_context.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/service/hlo_module_config.h\"",
            "previous_filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_stub.cc"
        },
        {
            "sha": "8cb78ad98edb2cd5ee9aeda8b92f766a1b18f61a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/xtile_compiler_stub_test.cc",
            "status": "renamed",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler_stub_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler_stub_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fxtile_compiler_stub_test.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -16,7 +16,7 @@ limitations under the License.\n #include <gtest/gtest.h>\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/Pass/PassManager.h\"\n-#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/codegen/tiling/tiled_hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_module.h\"",
            "previous_filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_stub_test.cc"
        },
        {
            "sha": "ce1e83c95b227b9c11891ee1d7d9cb1a9da42a6b",
            "filename": "third_party/xla/xla/codegen/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2FBUILD?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -44,7 +44,7 @@ xla_cc_test(\n     tags = [\"gpu\"],\n     deps = [\n         \":emitter_loc_op_builder\",\n-        \"//xla/backends/gpu/codegen/triton:fusion_emitter\",\n+        \"//xla/backends/gpu/codegen/triton:xtile_compiler\",\n         \"//xla/hlo/testlib:filecheck\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n         \"//xla/service/llvm_ir:llvm_util\","
        },
        {
            "sha": "1b440f5c009c9d3884f8defcc7d2403402546565",
            "filename": "third_party/xla/xla/codegen/emitter_loc_op_builder_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fcodegen%2Femitter_loc_op_builder_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fcodegen%2Femitter_loc_op_builder_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitter_loc_op_builder_test.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -27,7 +27,7 @@ limitations under the License.\n #include \"mlir/IR/Location.h\"\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/IR/OwningOpRef.h\"\n-#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/hlo/testlib/filecheck.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n #include \"xla/service/llvm_ir/llvm_util.h\""
        },
        {
            "sha": "103703c3d4455529b08d4e188dd4fa33de3c7dd0",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -480,6 +480,7 @@ cc_library(\n         \"//xla/backends/gpu/codegen:fusion_emitter\",\n         \"//xla/backends/gpu/codegen:fusions\",\n         \"//xla/backends/gpu/codegen/triton:fusion_emitter\",\n+        \"//xla/backends/gpu/codegen/triton:xtile_compiler\",\n         \"//xla/backends/gpu/collectives:gpu_clique_key\",\n         \"//xla/backends/gpu/runtime:all_gather_thunk\",\n         \"//xla/backends/gpu/runtime:all_reduce_thunk\","
        },
        {
            "sha": "d85c7fc653c7ab15f4a054746d4217930c46a990",
            "filename": "third_party/xla/xla/service/gpu/thunk_emitter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/75ae4d517522744ea05c44456f7b1a51f0c3d872/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc?ref=75ae4d517522744ea05c44456f7b1a51f0c3d872",
            "patch": "@@ -74,7 +74,7 @@ limitations under the License.\n #include \"mlir/Target/LLVMIR/Export.h\"\n #include \"xla/backends/gpu/codegen/fusion_emitter.h\"\n #include \"xla/backends/gpu/codegen/fusions.h\"\n-#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n+#include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/backends/gpu/runtime/all_gather_thunk.h\"\n #include \"xla/backends/gpu/runtime/all_reduce_thunk.h\"\n #include \"xla/backends/gpu/runtime/all_to_all_thunk.h\""
        }
    ],
    "stats": {
        "total": 1530,
        "additions": 868,
        "deletions": 662
    }
}