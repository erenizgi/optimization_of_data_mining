{
    "author": "beckerhe",
    "message": "Refactor: Dynamically register custom call targets in custom_call_test.cc\n\nThis change updates custom_call_test.cc to dynamically register custom call targets and FFI handlers using the runtime-determined platform name (CUDA or ROCM). This replaces the use of static registration macros, allowing the tests to run correctly across different GPU platforms and the reference interpreter.\n\nThis way we can avoid compile time branches like `#ifdef GOOGLE_CUDA` and similar.\n\nAlso:\n\n1. Converts usage of raw CUDA driver API functions to StreamExecutor functionality\n2. Replaces some legacy CustomCalls by FFI\n3. Converts the while test target to HloRunnerPjRt\n4. Removes a test case from the Token tests with a nested type in the output type, since that's not supported by our PjRt implementation.\n\nPiperOrigin-RevId: 846196106",
    "sha": "6d5546d597e9bec3a25c7a53942dd050554156b9",
    "files": [
        {
            "sha": "6c9258ca18a55ce31da555eec47ded05c0930370",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 14,
            "deletions": 18,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d5546d597e9bec3a25c7a53942dd050554156b9/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d5546d597e9bec3a25c7a53942dd050554156b9/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=6d5546d597e9bec3a25c7a53942dd050554156b9",
            "patch": "@@ -193,14 +193,15 @@ xla_test(\n     name = \"custom_call_test\",\n     srcs = [\"custom_call_test.cc\"],\n     backends = [\"gpu\"],\n-    local_defines = if_cuda_is_configured([\"GOOGLE_CUDA=1\"]) + if_rocm_is_configured([\"TENSORFLOW_USE_ROCM=1\"]),\n-    tags = [\"no-oneapi\"],  # TODO(intel-tf): Remove it when macro substitutions for SYCL are available in xla/stream_executor/sycl/*.\n+    tags = [\n+        # TODO(intel-tf): Remove it when macro substitutions for SYCL are available in xla/stream_executor/sycl/*.\n+        \"no-oneapi\",\n+        \"test_migrated_to_hlo_runner_pjrt\",\n+    ],\n     deps = [\n-        \"//xla:debug_options_flags\",\n         \"//xla:literal\",\n         \"//xla:literal_util\",\n         \"//xla:shape_util\",\n-        \"//xla:status_macros\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/backends/gpu:ffi\",\n         \"//xla/ffi\",\n@@ -210,37 +211,32 @@ xla_test(\n         \"//xla/hlo/builder/lib:constants\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/parser:hlo_parser\",\n-        \"//xla/hlo/testlib:test_helpers\",\n         \"//xla/service:custom_call_status\",\n         \"//xla/service:custom_call_target_registry\",\n-        \"//xla/service:executable\",\n         \"//xla/service:hlo_module_config\",\n+        \"//xla/service:hlo_runner_interface\",\n         \"//xla/stream_executor:device_address\",\n-        \"//xla/stream_executor:device_address_allocator\",\n         \"//xla/stream_executor:scratch_allocator\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/tests:client_library_test_runner_mixin\",\n-        \"//xla/tests:hlo_test_base\",\n-        \"//xla/tests:xla_internal_test_main\",  # fixdeps: keep\n+        \"//xla/tests:hlo_pjrt_interpreter_reference_mixin\",\n+        \"//xla/tests:hlo_pjrt_test_base\",\n         \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n-        \"//xla/tsl/platform:test\",\n-        \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/base:no_destructor\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n+        \"@com_google_absl//absl/synchronization\",\n         \"@com_google_absl//absl/types:span\",\n-        \"@local_tsl//tsl/platform:statusor\",\n-        \"@local_tsl//tsl/platform:test\",\n-    ] + if_cuda_is_configured([\n-        \"@local_config_cuda//cuda:cuda_headers\",\n-    ]) + if_rocm_is_configured([\n-        \"@local_config_rocm//rocm:rocm_headers\",\n-    ]),\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n )\n \n xla_cc_test("
        },
        {
            "sha": "d29efd3a727dbdf92d410e7b8aea2a37b1375eaa",
            "filename": "third_party/xla/xla/service/gpu/custom_call_test.cc",
            "status": "modified",
            "additions": 213,
            "deletions": 139,
            "changes": 352,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d5546d597e9bec3a25c7a53942dd050554156b9/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_call_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d5546d597e9bec3a25c7a53942dd050554156b9/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_call_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_call_test.cc?ref=6d5546d597e9bec3a25c7a53942dd050554156b9",
            "patch": "@@ -16,31 +16,26 @@ limitations under the License.\n #include <cstddef>\n #include <cstdint>\n #include <memory>\n+#include <optional>\n #include <sstream>\n #include <string>\n #include <utility>\n #include <vector>\n \n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/base/const_init.h\"\n #include \"absl/base/no_destructor.h\"\n+#include \"absl/base/thread_annotations.h\"\n #include \"absl/container/flat_hash_map.h\"\n-#include \"xla/literal_util.h\"\n-\n-#if GOOGLE_CUDA\n-#include \"third_party/gpus/cuda/include/cuda.h\"  // IWYU pragma: keep\n-#include \"third_party/gpus/cuda/include/cuda_runtime_api.h\"\n-#include \"third_party/gpus/cuda/include/driver_types.h\"\n-#define PLATFORM \"CUDA\"\n-#elif TENSORFLOW_USE_ROCM\n-#include \"rocm/include/hip/hip_runtime.h\"\n-#define PLATFORM \"ROCM\"\n-#endif\n-\n+#include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/status_matchers.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/ffi.h\"\n #include \"xla/ffi/execution_context.h\"\n@@ -53,39 +48,24 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/parser/hlo_parser.h\"\n #include \"xla/literal.h\"\n+#include \"xla/literal_util.h\"\n #include \"xla/service/custom_call_status.h\"\n #include \"xla/service/custom_call_target_registry.h\"\n #include \"xla/service/hlo_module_config.h\"\n+#include \"xla/service/hlo_runner_interface.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tests/client_library_test_runner_mixin.h\"\n-#include \"xla/tests/hlo_test_base.h\"\n+#include \"xla/tests/hlo_pjrt_interpreter_reference_mixin.h\"\n+#include \"xla/tests/hlo_pjrt_test_base.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n+#include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n-#include \"xla/tsl/platform/test.h\"\n #include \"xla/xla_data.pb.h\"\n \n-#if GOOGLE_CUDA\n-#define gpuSuccess cudaSuccess\n-#define gpuMemcpyAsync cudaMemcpyAsync\n-#define gpuMemcpyDeviceToDevice cudaMemcpyDeviceToDevice\n-#define gpuMemcpy cudaMemcpy\n-#define gpuMemcpyDeviceToHost cudaMemcpyDeviceToHost\n-#define gpuMemcpyHostToDevice cudaMemcpyHostToDevice\n-#define gpuStream CUstream\n-#elif TENSORFLOW_USE_ROCM\n-#define gpuSuccess hipSuccess\n-#define gpuMemcpyAsync hipMemcpyAsync\n-#define gpuMemcpyDeviceToDevice hipMemcpyDeviceToDevice\n-#define gpuMemcpy hipMemcpy\n-#define gpuMemcpyDeviceToHost hipMemcpyDeviceToHost\n-#define gpuMemcpyHostToDevice hipMemcpyHostToDevice\n-#define gpuStream hipStream_t\n-#endif\n-\n namespace xla {\n \n struct Range {\n@@ -105,7 +85,19 @@ namespace {\n using ::absl_testing::StatusIs;\n using ::testing::HasSubstr;\n \n-using CustomCallTest = ClientLibraryTestRunnerMixin<HloTestBase>;\n+class CustomCallTest : public ClientLibraryTestRunnerMixin<\n+                           HloPjRtInterpreterReferenceMixin<HloPjRtTestBase>> {\n+ public:\n+  std::string PlatformName() {\n+    if (test_runner().HasProperty(HloRunnerPropertyTag::kUsingGpuCuda)) {\n+      return \"CUDA\";\n+    }\n+    if (test_runner().HasProperty(HloRunnerPropertyTag::kUsingGpuRocm)) {\n+      return \"ROCM\";\n+    }\n+    LOG(FATAL) << TestName() << \" was executed on an unsupported platform.\";\n+  }\n+};\n \n // The test case for custom call with tokens encodes the arguments and result\n // type using a string with A(=Array), T(=Token) and {} for Tuples. It also\n@@ -124,32 +116,17 @@ struct TokenTestCase {\n   std::string opaque;\n };\n \n-void Callback_Tokens(gpuStream stream, void** buffers, const char* opaque,\n-                     size_t opaque_len) {\n-  for (int i = 0; i < opaque_len; ++i) {\n-    char c = opaque[i];\n-    ASSERT_TRUE(c == 'A' || c == 'T');\n-    if (c == 'A') {\n-      ASSERT_NE(buffers[i], nullptr);\n-    } else {\n-      ASSERT_EQ(buffers[i], nullptr);\n-    }\n-  }\n-}\n-\n-XLA_REGISTER_CUSTOM_CALL_TARGET(Callback_Tokens, PLATFORM);\n-\n std::vector<TokenTestCase> GetTokenTestCases() {\n-  return {{\"{AT}{AT}\", \"{A{AT}A}\", \"ATATAATA\"},  // tokens in input and output\n-          {\"{A}\", \"T\", \"AT\"},                    // single token as output\n-          {\"{{T}}\", \"A\", \"TA\"},                  // single token as input\n+  return {{\"{AT}{AT}\", \"{AATA}\", \"ATATAATA\"},  // tokens in input and output\n+          {\"{A}\", \"T\", \"AT\"},                  // single token as output\n+          {\"{{T}}\", \"A\", \"TA\"},                // single token as input\n           {\"AA\", \"{TA}\", \"AATA\"},\n           {\"TA{TA{TA}}\", \"{AA}\", \"TATATAAA\"}};\n }\n \n class CustomCallTokensTest\n     : public ::testing::WithParamInterface<TokenTestCase>,\n-      public ClientLibraryTestRunnerMixin<HloTestBase> {\n+      public CustomCallTest {\n  public:\n   static std::vector<XlaOp> BuildInputs(XlaBuilder& b,\n                                         std::istringstream& str) {\n@@ -191,14 +168,23 @@ class CustomCallTokensTest\n   }\n };\n \n-void Callback_WithStatusSucceeded(gpuStream /*stream*/, void** /*buffers*/,\n+void Callback_WithStatusSucceeded(void* /*stream*/, void** /*buffers*/,\n                                   const char* /*opaque*/, size_t /*opaque_len*/,\n                                   XlaCustomCallStatus* status) {\n   XlaCustomCallStatusSetSuccess(status);\n }\n-XLA_REGISTER_CUSTOM_CALL_TARGET(Callback_WithStatusSucceeded, PLATFORM);\n+\n+void Callback_WithStatusFailed(void* /*stream*/, void** /*buffers*/,\n+                               const char* /*opaque*/, size_t /*opaque_len*/,\n+                               XlaCustomCallStatus* status) {\n+  XlaCustomCallStatusSetFailure(status, \"Failed\", 6);\n+}\n \n TEST_F(CustomCallTest, WithStatusSucceeded) {\n+  CustomCallTargetRegistry::Global()->Register(\n+      \"Callback_WithStatusSucceeded\",\n+      reinterpret_cast<void*>(Callback_WithStatusSucceeded), PlatformName());\n+\n   XlaBuilder b(TestName());\n   CustomCall(\n       &b, \"Callback_WithStatusSucceeded\", /*operands=*/{},\n@@ -210,14 +196,11 @@ TEST_F(CustomCallTest, WithStatusSucceeded) {\n   TF_ASSERT_OK(ExecuteAndTransfer(&b, {}).status());\n }\n \n-void Callback_WithStatusFailed(gpuStream /*stream*/, void** /*buffers*/,\n-                               const char* /*opaque*/, size_t /*opaque_len*/,\n-                               XlaCustomCallStatus* status) {\n-  XlaCustomCallStatusSetFailure(status, \"Failed\", 6);\n-}\n-XLA_REGISTER_CUSTOM_CALL_TARGET(Callback_WithStatusFailed, PLATFORM);\n-\n TEST_F(CustomCallTest, WithStatusFailed) {\n+  CustomCallTargetRegistry::Global()->Register(\n+      \"Callback_WithStatusFailed\",\n+      reinterpret_cast<void*>(Callback_WithStatusFailed), PlatformName());\n+\n   XlaBuilder b(TestName());\n   CustomCall(\n       &b, \"Callback_WithStatusFailed\", /*operands=*/{},\n@@ -244,10 +227,12 @@ XLA_FFI_DEFINE_HANDLER(kAlwaysFail, AlwaysFail,\n                            .Ret<ffi::AnyBuffer>()   //\n                            .Attr<int32_t>(\"value\")  // value\n );\n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"__xla_test$$always_fail\",\n-                         PLATFORM, kAlwaysFail);\n \n TEST_F(CustomCallTest, RuntimeCustomCallAlwaysFail) {\n+  xla::ffi::Ffi::RegisterStaticHandler(ffi::GetXlaFfiApi(),\n+                                       \"__xla_test$$always_fail\",\n+                                       PlatformName(), kAlwaysFail);\n+\n   XlaBuilder b(TestName());\n   CustomCall(&b, \"__xla_test$$always_fail\", /*operands=*/{},\n              ShapeUtil::MakeShape(F32, {}), /*opaque=*/\"{value = 42 : i32}\",\n@@ -263,6 +248,10 @@ TEST_F(CustomCallTest, RuntimeCustomCallAlwaysFail) {\n // Same as the above test but just pass attribute through\n // the backend config proto string instead.\n TEST_F(CustomCallTest, PassAttributesByBackendConfig) {\n+  xla::ffi::Ffi::RegisterStaticHandler(ffi::GetXlaFfiApi(),\n+                                       \"__xla_test$$always_fail\",\n+                                       PlatformName(), kAlwaysFail);\n+\n   XlaBuilder b(TestName());\n   CustomCall(\n       &b, \"__xla_test$$always_fail\", /*operands=*/{},\n@@ -291,10 +280,10 @@ XLA_FFI_DEFINE_HANDLER(kMemcpy, Memcpy,\n                            .Ret<ffi::AnyBuffer>(),  // dst\n                        {ffi::Traits::kCmdBufferCompatible});\n \n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"__xla_test$$memcpy\", PLATFORM,\n-                         kMemcpy);\n-\n TEST_F(CustomCallTest, ExportedFfiMemcpy) {\n+  xla::ffi::Ffi::RegisterStaticHandler(\n+      ffi::GetXlaFfiApi(), \"__xla_test$$memcpy\", PlatformName(), kMemcpy);\n+\n   XlaBuilder b(TestName());\n   CustomCall(&b, \"__xla_test$$memcpy\",\n              /*operands=*/{Broadcast(ConstantR0WithType(&b, F32, 42.0), {128})},\n@@ -317,10 +306,11 @@ XLA_FFI_DEFINE_HANDLER(kHandleUserPointer, HandleUserPointer,\n                            .Ret<ffi::AnyBuffer>()  // buffer for result\n                            .Attr<ffi::Pointer<std::string>>(\"message\"));\n \n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"__xla_test$$user_data\", PLATFORM,\n-                         kHandleUserPointer);\n-\n TEST_F(CustomCallTest, PassUserPointerWithAttrs) {\n+  xla::ffi::Ffi::RegisterStaticHandler(ffi::GetXlaFfiApi(),\n+                                       \"__xla_test$$user_data\", PlatformName(),\n+                                       kHandleUserPointer);\n+\n   std::string message = \"User-defined message\";\n   auto ptr = reinterpret_cast<uintptr_t>(&message);\n \n@@ -347,10 +337,10 @@ XLA_FFI_DEFINE_HANDLER(\n     kIsInvoked, IsInvoked,\n     ffi::Ffi::Bind().Ret<ffi::AnyBuffer>());  // Buffer for result (unused).\n \n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"__xla_test$$isinvoked\", PLATFORM,\n-                         kIsInvoked);\n-\n TEST_F(CustomCallTest, ExportedFfiIsInvoked) {\n+  xla::ffi::Ffi::RegisterStaticHandler(\n+      ffi::GetXlaFfiApi(), \"__xla_test$$isinvoked\", PlatformName(), kIsInvoked);\n+\n   XlaBuilder b(TestName());\n   CustomCall(&b, \"__xla_test$$isinvoked\", /*operands=*/{},\n              ShapeUtil::MakeShape(F32, {}), /*opaque=*/\"\",\n@@ -400,10 +390,10 @@ XLA_FFI_DEFINE_HANDLER(kOpaque, Opaque,\n                            .Ret<ffi::AnyBuffer>()  // Dummy result buffer.\n                            .Attr<ffi::Pointer<std::string>>(\"opaque\"));\n \n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"__xla_test$$opaque\", PLATFORM,\n-                         kOpaque);\n-\n TEST_F(CustomCallTest, ExportedFfiOpaque) {\n+  xla::ffi::Ffi::RegisterStaticHandler(\n+      ffi::GetXlaFfiApi(), \"__xla_test$$opaque\", PlatformName(), kOpaque);\n+\n   XlaBuilder b(TestName());\n   const std::string opaque = absl::StrFormat(\n       \"{opaque = %d : i64}\", reinterpret_cast<uintptr_t>(&kExpectedOpaque));\n@@ -461,10 +451,10 @@ XLA_FFI_DEFINE_HANDLER(\n     ffi::Ffi::Bind().RemainingArgs().RemainingRets().Attr<absl::string_view>(\n         \"pattern\"));\n \n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"__xla_test$$tokens\", PLATFORM,\n-                         kFfiTokens);\n-\n TEST_P(CustomCallTokensTest, ExportedTokensTest) {\n+  xla::ffi::Ffi::RegisterStaticHandler(\n+      ffi::GetXlaFfiApi(), \"__xla_test$$tokens\", PlatformName(), kFfiTokens);\n+\n   const TokenTestCase& tc = GetParam();\n   XlaBuilder b(TestName());\n   std::istringstream input(tc.input);\n@@ -498,10 +488,11 @@ static absl::Status AlwaysSucceed(ffi::Result<ffi::AnyBuffer>) {\n XLA_FFI_DEFINE_HANDLER(kAlwaysSucceed, AlwaysSucceed,\n                        ffi::Ffi::Bind().Ret<ffi::AnyBuffer>());\n \n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"__xla_test$$always_succeed\",\n-                         PLATFORM, kAlwaysSucceed);\n-\n TEST_F(CustomCallTest, ExportedFfiWithStatusSucceeded) {\n+  xla::ffi::Ffi::RegisterStaticHandler(ffi::GetXlaFfiApi(),\n+                                       \"__xla_test$$always_succeed\",\n+                                       PlatformName(), kAlwaysSucceed);\n+\n   XlaBuilder b(TestName());\n   CustomCall(&b, \"__xla_test$$always_succeed\", /*operands=*/{},\n              ShapeUtil::MakeShape(F32, {}), /*opaque=*/\"\",\n@@ -541,10 +532,11 @@ XLA_FFI_DEFINE_HANDLER(kFfiAttributes, FfiAttributes,\n                            .Attr<absl::Span<const int32_t>>(\"i32_arr\")\n                            .Attr<Range>(\"range\"));\n \n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"xla.gpu.ffi_attributes\",\n-                         PLATFORM, kFfiAttributes);\n-\n TEST_F(CustomCallTest, FfiAttributes) {\n+  xla::ffi::Ffi::RegisterStaticHandler(ffi::GetXlaFfiApi(),\n+                                       \"xla.gpu.ffi_attributes\", PlatformName(),\n+                                       kFfiAttributes);\n+\n   XlaBuilder b(TestName());\n   CustomCall(&b, \"xla.gpu.ffi_attributes\", /*operands=*/{},\n              ShapeUtil::MakeShape(F32, {}),\n@@ -598,11 +590,11 @@ XLA_FFI_DEFINE_HANDLER(kMemcpyWithCalledComputation,\n                            .Ret<ffi::AnyBuffer>()         // dst\n                            .Ctx<ffi::CalledComputation>());\n \n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(),\n-                         \"xla.gpu.ext.memcpy_with_called_computation\", PLATFORM,\n-                         kMemcpyWithCalledComputation);\n-\n TEST_F(CustomCallTest, WithCalledComputation) {\n+  xla::ffi::Ffi::RegisterStaticHandler(\n+      ffi::GetXlaFfiApi(), \"xla.gpu.ext.memcpy_with_called_computation\",\n+      PlatformName(), kMemcpyWithCalledComputation);\n+\n   auto shape = ShapeUtil::MakeShape(F32, {128});\n \n   // Build a called computation which is just a copy instruction.\n@@ -625,6 +617,10 @@ TEST_F(CustomCallTest, WithCalledComputation) {\n }\n \n TEST_F(CustomCallTest, WithCalledComputationAndLayouts) {\n+  xla::ffi::Ffi::RegisterStaticHandler(\n+      ffi::GetXlaFfiApi(), \"xla.gpu.ext.memcpy_with_called_computation\",\n+      PlatformName(), kMemcpyWithCalledComputation);\n+\n   auto shape = ShapeUtil::MakeShapeWithDenseLayout(F32, {128, 128}, {0, 1});\n   // Build a called computation which is just a copy instruction.\n   XlaBuilder copy(\"copy\");\n@@ -643,10 +639,43 @@ TEST_F(CustomCallTest, WithCalledComputationAndLayouts) {\n   TF_ASSERT_OK_AND_ASSIGN(auto result, ExecuteAndTransfer(&b, {}, &shape));\n   EXPECT_THAT(result.data<float>(), ::testing::Each(42));\n }\n+\n //===----------------------------------------------------------------------===//\n // XLA:FFI handler with execution context\n //===----------------------------------------------------------------------===//\n \n+// HloRunnerPjRt doesn't offer a way to provide the execution context for the\n+// execution. Therefore we use a global static variable to pass the execution\n+// context to the custom call handler.\n+absl::Mutex execution_context_mutex(absl::kConstInit);\n+ffi::ExecutionContext* global_execution_context\n+    ABSL_GUARDED_BY(execution_context_mutex) = nullptr;\n+absl::NoDestructor<std::optional<ffi::internal::ScopedExecutionContext>>\n+    scoped_execution_context;\n+\n+template <ffi::ExecutionStage stage>\n+absl::Status ExecutionContextRegister(ffi::Result<ffi::AnyBuffer>) {\n+  if constexpr (stage != ffi::ExecutionStage::kPrepare) {\n+    return absl::OkStatus();\n+  }\n+\n+  absl::MutexLock lock(execution_context_mutex);\n+  // ScopedExecutionContext needs to be constructed on the same thread as the\n+  // execution context is used. Therefore we use the prepare callback to\n+  // create the execution context.\n+  scoped_execution_context->emplace(global_execution_context);\n+  return absl::OkStatus();\n+};\n+\n+XLA_FFI_DEFINE_HANDLER(\n+    kExecutionContextRegisterPrepare,\n+    ExecutionContextRegister<ffi::ExecutionStage::kPrepare>,\n+    ffi::Ffi::Bind<ffi::ExecutionStage::kPrepare>().Ret<ffi::AnyBuffer>());\n+XLA_FFI_DEFINE_HANDLER(\n+    kExecutionContextRegisterExecute,\n+    ExecutionContextRegister<ffi::ExecutionStage::kExecute>,\n+    ffi::Ffi::Bind<ffi::ExecutionStage::kExecute>().Ret<ffi::AnyBuffer>());\n+\n // Arbitrary user-defined context passed via the execution context side channel\n // to a custom call handlers.\n struct SomeExtraContext {\n@@ -658,7 +687,8 @@ struct SomeExtraContext {\n };\n \n template <ffi::ExecutionStage stage>\n-static absl::Status ExecutionContext(ffi::Result<ffi::AnyBuffer>,\n+static absl::Status ExecutionContext(ffi::AnyBuffer,\n+                                     ffi::Result<ffi::AnyBuffer>,\n                                      SomeExtraContext* ctx) {\n   if (ctx->value != 42) {\n     return absl::InternalError(\"Unexpected value\");\n@@ -679,33 +709,59 @@ static absl::Status ExecutionContext(ffi::Result<ffi::AnyBuffer>,\n XLA_FFI_DEFINE_HANDLER(kExecutionContextPrepare,\n                        ExecutionContext<ffi::ExecutionStage::kPrepare>,\n                        ffi::Ffi::Bind<ffi::ExecutionStage::kPrepare>()\n+                           .Arg<ffi::AnyBuffer>()\n                            .Ret<ffi::AnyBuffer>()\n                            .Ctx<ffi::UserData<SomeExtraContext>>());\n \n XLA_FFI_DEFINE_HANDLER(kExecutionContextInitialize,\n                        ExecutionContext<ffi::ExecutionStage::kInitialize>,\n                        ffi::Ffi::Bind<ffi::ExecutionStage::kInitialize>()\n+                           .Arg<ffi::AnyBuffer>()\n                            .Ret<ffi::AnyBuffer>()\n                            .Ctx<ffi::UserData<SomeExtraContext>>());\n \n XLA_FFI_DEFINE_HANDLER(kExecutionContextExecute,\n                        ExecutionContext<ffi::ExecutionStage::kExecute>,\n                        ffi::Ffi::Bind<ffi::ExecutionStage::kExecute>()\n+                           .Arg<ffi::AnyBuffer>()\n                            .Ret<ffi::AnyBuffer>()\n                            .Ctx<ffi::UserData<SomeExtraContext>>());\n \n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"xla.gpu.ffi_execution_context\",\n-                         PLATFORM,\n-                         {\n-                             /*instantiate=*/nullptr,\n-                             /*prepare=*/kExecutionContextPrepare,\n-                             /*initialize=*/kExecutionContextInitialize,\n-                             /*execute=*/kExecutionContextExecute,\n-                         });\n-\n TEST_F(CustomCallTest, FfiExecutionContext) {\n+  xla::ffi::Ffi::RegisterStaticHandler(\n+      ffi::GetXlaFfiApi(), \"xla.gpu.register_ffi_execution_context\",\n+      PlatformName(),\n+      {\n+          /*instantiate=*/nullptr,\n+          /*prepare=*/kExecutionContextRegisterPrepare,\n+          /*initialize=*/nullptr,\n+          /*execute=*/kExecutionContextRegisterExecute,\n+      });\n+\n+  xla::ffi::Ffi::RegisterStaticHandler(\n+      ffi::GetXlaFfiApi(), \"xla.gpu.ffi_execution_context\", PlatformName(),\n+      {\n+          /*instantiate=*/nullptr,\n+          /*prepare=*/kExecutionContextPrepare,\n+          /*initialize=*/kExecutionContextInitialize,\n+          /*execute=*/kExecutionContextExecute,\n+      });\n+\n   XlaBuilder b(TestName());\n-  CustomCall(&b, \"xla.gpu.ffi_execution_context\", /*operands=*/{},\n+\n+  // This custom call users ScopedExecutionContext to register the execution\n+  // context for the duration of the current XLA computation.\n+  // Usually the execution context is passed in via ExecutionOptions, but that's\n+  // not supported in HloRunnerPjRt.\n+  XlaOp output =\n+      CustomCall(&b, \"xla.gpu.register_ffi_execution_context\",\n+                 /*operands=*/{}, ShapeUtil::MakeShape(F32, {}),\n+                 /*opaque=*/\"\",\n+                 /*has_side_effect=*/true,\n+                 /*output_operand_aliasing=*/{}, /*literal=*/nullptr,\n+                 /*schedule=*/CustomCallSchedule::SCHEDULE_NONE,\n+                 /*api_version=*/CustomCallApiVersion::API_VERSION_TYPED_FFI);\n+  CustomCall(&b, \"xla.gpu.ffi_execution_context\", /*operands=*/{output},\n              ShapeUtil::MakeShape(F32, {}),\n              /*opaque=*/\"\",\n              /*has_side_effect=*/false,\n@@ -715,9 +771,10 @@ TEST_F(CustomCallTest, FfiExecutionContext) {\n \n   ffi::ExecutionContext execution_context;\n   TF_ASSERT_OK(execution_context.Emplace<SomeExtraContext>(42));\n-\n-  ffi::internal::ScopedExecutionContext scoped_execution_context(\n-      &execution_context);\n+  {\n+    absl::MutexLock lock(execution_context_mutex);\n+    global_execution_context = &execution_context;\n+  }\n \n   TF_ASSERT_OK(ExecuteAndTransfer(&b, {}).status());\n \n@@ -760,16 +817,16 @@ XLA_FFI_DEFINE_HANDLER(\n     kGetState, GetState,\n     ffi::Ffi::Bind().Ret<ffi::AnyBuffer>().Ctx<ffi::State<SomeState>>());\n \n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"xla.gpu.ffi_execution_state\",\n-                         PLATFORM,\n-                         {\n-                             /*instantiate=*/kInstantiateState,\n-                             /*prepare=*/nullptr,\n-                             /*initialize=*/nullptr,\n-                             /*execute=*/kGetState,\n-                         });\n-\n TEST_F(CustomCallTest, FfiExecutionState) {\n+  xla::ffi::Ffi::RegisterStaticHandler(\n+      ffi::GetXlaFfiApi(), \"xla.gpu.ffi_execution_state\", PlatformName(),\n+      {\n+          /*instantiate=*/kInstantiateState,\n+          /*prepare=*/nullptr,\n+          /*initialize=*/nullptr,\n+          /*execute=*/kGetState,\n+      });\n+\n   XlaBuilder b(TestName());\n   CustomCall(&b, \"xla.gpu.ffi_execution_state\", /*operands=*/{},\n              ShapeUtil::MakeShape(F32, {}),\n@@ -831,17 +888,20 @@ XLA_FFI_DEFINE_HANDLER(\n     kAsyncStartCustomCall, AsyncStartCustomCall,\n     ffi::Ffi::Bind().Arg<ffi::AnyBuffer>().Ret<ffi::AnyBuffer>().Attr<int32_t>(\n         \"channel\"));\n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"xla.gpu.async_start_custom_call\",\n-                         PLATFORM, kAsyncStartCustomCall);\n \n XLA_FFI_DEFINE_HANDLER(\n     kAsyncDoneCustomCall, AsyncDoneCustomCall,\n     ffi::Ffi::Bind().Arg<ffi::AnyBuffer>().Ret<ffi::AnyBuffer>().Attr<int32_t>(\n         \"channel\"));\n-XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"xla.gpu.async_done_custom_call\",\n-                         PLATFORM, kAsyncDoneCustomCall);\n \n TEST_F(CustomCallTest, AsyncCustomCalls) {\n+  xla::ffi::Ffi::RegisterStaticHandler(ffi::GetXlaFfiApi(),\n+                                       \"xla.gpu.async_start_custom_call\",\n+                                       PlatformName(), kAsyncStartCustomCall);\n+  xla::ffi::Ffi::RegisterStaticHandler(ffi::GetXlaFfiApi(),\n+                                       \"xla.gpu.async_done_custom_call\",\n+                                       PlatformName(), kAsyncDoneCustomCall);\n+\n   auto shape = ShapeUtil::MakeShape(F32, {});\n \n   XlaBuilder b(TestName());\n@@ -872,40 +932,51 @@ TEST_F(CustomCallTest, AsyncCustomCalls) {\n // Testing the use of buffers in custom calls.\n //===----------------------------------------------------------------------===//\n \n-class CustomCallHloTest : public HloTestBase {};\n+using CustomCallHloTest = CustomCallTest;\n \n-void CallBack_AddOne(gpuStream stream, void** buffers, const char* /*opaque*/,\n-                     size_t /*opaque_len*/) {\n-  // Expect that the input and output buffers are the same.\n-  if (buffers[0] != buffers[1]) {\n-    return;\n+static absl::Status AddOne(se::Stream* stream, ffi::AnyBuffer src,\n+                           ffi::Result<ffi::AnyBuffer> ret) {\n+  if (src.untyped_data() != ret->untyped_data()) {\n+    return absl::InternalError(\"Input and output buffers must be the same.\");\n   }\n-  int32_t dst[2];\n-  auto err = gpuMemcpy(dst, buffers[0], /*count=*/sizeof(int32_t) * 2,\n-                       gpuMemcpyDeviceToHost);\n-  ASSERT_EQ(err, gpuSuccess);\n-  dst[0] += 1;\n-  dst[1] += 1;\n-  err = gpuMemcpy(buffers[1], dst, /*count=*/sizeof(int32_t) * 2,\n-                  gpuMemcpyHostToDevice);\n+\n+  int32_t data[2];\n+  se::DeviceAddressBase buffer_mem = ret->device_memory();\n+  TF_RETURN_IF_ERROR(stream->Memcpy(data, buffer_mem, sizeof(data)));\n+  TF_RETURN_IF_ERROR(stream->BlockHostUntilDone());\n+\n+  data[0] += 1;\n+  data[1] += 1;\n+\n+  TF_RETURN_IF_ERROR(stream->Memcpy(&buffer_mem, data, sizeof(data)));\n+  TF_RETURN_IF_ERROR(stream->BlockHostUntilDone());\n+\n+  return absl::OkStatus();\n }\n-XLA_REGISTER_CUSTOM_CALL_TARGET(CallBack_AddOne, PLATFORM);\n+\n+XLA_FFI_DEFINE_HANDLER(kAddOne, AddOne,\n+                       ffi::Ffi::Bind()\n+                           .Ctx<ffi::Stream>()\n+                           .Arg<ffi::AnyBuffer>()\n+                           .Ret<ffi::AnyBuffer>());\n \n TEST_F(CustomCallHloTest, HloBufferStraightLine) {\n-  const char* const kModuleStr = R\"(\n+  xla::ffi::Ffi::RegisterStaticHandler(ffi::GetXlaFfiApi(), \"xla.gpu.add_one\",\n+                                       PlatformName(), kAddOne);\n \n+  const char* const kModuleStr = R\"(\n   HloModule test\n   ENTRY test_computation {\n     c1 = s32[] constant(1)\n     init = s32[2] broadcast(c1), dimensions={}\n     b0 = b(s32[2]) custom-call(init), custom_call_target=\"Pin\",\n       output_to_operand_aliasing={{}: (0, {})}\n-    b1 = b(s32[2]) custom-call(b0), custom_call_target=\"CallBack_AddOne\",\n+    b1 = b(s32[2]) custom-call(b0), custom_call_target=\"xla.gpu.add_one\",\n       output_to_operand_aliasing={{}: (0, {})},\n-      api_version=API_VERSION_STATUS_RETURNING\n-    b2 = b(s32[2]) custom-call(b1), custom_call_target=\"CallBack_AddOne\",\n+      api_version=API_VERSION_TYPED_FFI\n+    b2 = b(s32[2]) custom-call(b1), custom_call_target=\"xla.gpu.add_one\",\n       output_to_operand_aliasing={{}: (0, {})},\n-      api_version=API_VERSION_STATUS_RETURNING\n+      api_version=API_VERSION_TYPED_FFI\n     ROOT v = s32[2] custom-call(b2), custom_call_target=\"Unpin\",\n       output_to_operand_aliasing={{}: (0, {})}\n   })\";\n@@ -925,6 +996,9 @@ TEST_F(CustomCallHloTest, HloBufferStraightLine) {\n }\n \n TEST_F(CustomCallHloTest, HloBufferRotated) {\n+  xla::ffi::Ffi::RegisterStaticHandler(ffi::GetXlaFfiApi(), \"xla.gpu.add_one\",\n+                                       PlatformName(), kAddOne);\n+\n   const char* const kModuleStr = R\"(\n \n   HloModule test\n@@ -942,12 +1016,12 @@ TEST_F(CustomCallHloTest, HloBufferRotated) {\n \n     c1 = s32[] constant(1)\n     new_count = s32[] add(count, c1)\n-    b4 = b(s32[2]) custom-call(b3), custom_call_target=\"CallBack_AddOne\",\n+    b4 = b(s32[2]) custom-call(b3), custom_call_target=\"xla.gpu.add_one\",\n       output_to_operand_aliasing={{}: (0, {})},\n-      api_version=API_VERSION_STATUS_RETURNING\n-    b5 = b(s32[2]) custom-call(b4), custom_call_target=\"CallBack_AddOne\",\n+      api_version=API_VERSION_TYPED_FFI\n+    b5 = b(s32[2]) custom-call(b4), custom_call_target=\"xla.gpu.add_one\",\n       output_to_operand_aliasing={{}: (0, {})},\n-      api_version=API_VERSION_STATUS_RETURNING\n+      api_version=API_VERSION_TYPED_FFI\n     v0 = s32[2] custom-call(b5), custom_call_target=\"Unpin\",\n       output_to_operand_aliasing={{}: (0, {})}\n     c1_broadcast = s32[2] broadcast(c1), dimensions={}"
        }
    ],
    "stats": {
        "total": 384,
        "additions": 227,
        "deletions": 157
    }
}