{
    "author": "serach24",
    "message": "PR #26236: Support the Execute Device Kernel feature in XLA\n\nImported from GitHub PR https://github.com/openxla/xla/pull/26236\n\n ExecuteDeviceKernel is a proposed enhancement to XLA that enables users to embed and execute device-specific code (starting with PTX, with future support for other formats) directly within JAX programs. It allows users to inject custom kernels with specific launch configurations, streamlining performance optimizations and reducing reliance on external toolchains. By supporting dynamic compilation during JIT, ExecuteDeviceKernel simplifies the integration and reproduction of custom kernels within a stand-alone HLO module.\n\nDesign Doc: https://docs.google.com/document/d/1wn75eJEXQ8EkNH0LemVAIqmudpLgcNBqajE8Ml-vkYg/edit?tab=t.0\nCopybara import of the project:\n\n--\n03cca61555d4184f353a43d93ddc842842b05638 by Chenhao Jiang <chenhaoj@nvidia.com>:\n\nSupport the execute_device_kernel\n\nMerging this change closes #26236\n\nPiperOrigin-RevId: 814619479",
    "sha": "471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
    "files": [
        {
            "sha": "574689879b17e34c93d5fd5521f29488734df5e8",
            "filename": "third_party/xla/xla/codegen/emitters/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2FBUILD?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -203,10 +203,12 @@ cc_library(\n         \"//xla/service:buffer_assignment\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/types:span\",\n     ],\n )\n \n@@ -218,13 +220,16 @@ xla_cc_test(\n         \"//xla:shape_util\",\n         \"//xla/hlo/analysis:alias_info\",\n         \"//xla/hlo/analysis:hlo_ordering\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n         \"//xla/hlo/testlib:verified_hlo_module\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:buffer_value\",\n         \"//xla/service:logical_buffer\",\n         \"//xla/service/gpu:gpu_constants\",\n         \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest_main\",\n     ],"
        },
        {
            "sha": "91597ee8adfc46060a5de5f8c3481bd986d020bd",
            "filename": "third_party/xla/xla/codegen/emitters/kernel_arguments.cc",
            "status": "modified",
            "additions": 102,
            "deletions": 13,
            "changes": 115,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fkernel_arguments.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fkernel_arguments.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fkernel_arguments.cc?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -16,14 +16,17 @@ limitations under the License.\n \n #include <cstddef>\n #include <cstdint>\n+#include <iterator>\n #include <optional>\n #include <utility>\n #include <vector>\n \n+#include \"absl/algorithm/container.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/shape.h\"\n@@ -109,6 +112,33 @@ void FillKernelArgumentAttributes(\n   }\n }\n \n+struct OutputArguments {\n+  std::vector<KernelArgument> output_arguments;\n+  absl::flat_hash_set<BufferAllocation::Slice> buffers_written;\n+};\n+\n+// Extract output arguments from an instruction's shape and return both\n+// the arguments and the set of written buffer slices\n+absl::StatusOr<OutputArguments> ExtractOutputArguments(\n+    const BufferAssignment& buffer_assignment,\n+    const HloInstruction* hlo_instruction) {\n+  OutputArguments result;\n+  TF_RETURN_IF_ERROR(ShapeUtil::ForEachSubshapeWithStatus(\n+      hlo_instruction->shape(),\n+      [&](const Shape& subshape, const ShapeIndex& index) {\n+        if (!subshape.IsArray()) return absl::OkStatus();\n+\n+        TF_ASSIGN_OR_RETURN(\n+            BufferAllocation::Slice slice,\n+            buffer_assignment.GetUniqueSlice(hlo_instruction, index));\n+\n+        result.output_arguments.emplace_back(KernelArgument(subshape, slice));\n+        result.buffers_written.insert(slice);\n+        return absl::OkStatus();\n+      }));\n+  return result;\n+}\n+\n }  // namespace\n \n absl::StatusOr<KernelArguments> KernelArguments::Create(\n@@ -122,25 +152,84 @@ absl::StatusOr<KernelArguments> KernelArguments::Create(\n     kernel_arguments.emplace_back(KernelArgument(operand->shape(), slice));\n   }\n \n-  absl::flat_hash_set<BufferAllocation::Slice> buffers_written;\n-  TF_RETURN_IF_ERROR(ShapeUtil::ForEachSubshapeWithStatus(\n-      hlo_instruction->shape(),\n-      [&](const Shape& subshape, const ShapeIndex& index) {\n-        if (!subshape.IsArray()) return absl::OkStatus();\n+  TF_ASSIGN_OR_RETURN(\n+      OutputArguments output_result,\n+      ExtractOutputArguments(buffer_assignment, hlo_instruction));\n \n-        TF_ASSIGN_OR_RETURN(\n-            BufferAllocation::Slice slice,\n-            buffer_assignment.GetUniqueSlice(hlo_instruction, index));\n+  absl::c_move(output_result.output_arguments,\n+               std::back_inserter(kernel_arguments));\n+  FillKernelArgumentAttributes(kernel_arguments, buffer_alignment,\n+                               output_result.buffers_written);\n \n-        kernel_arguments.emplace_back(KernelArgument(subshape, slice));\n-        buffers_written.insert(slice);\n-        return absl::OkStatus();\n-      }));\n+  return KernelArguments(std::move(kernel_arguments));\n+}\n+\n+absl::StatusOr<KernelArguments> KernelArguments::Create(\n+    const BufferAssignment& buffer_assignment,\n+    const BufferAlignment& buffer_alignment,\n+    const HloInstruction* hlo_instruction,\n+    absl::Span<const int32_t> interleaved_output_indices) {\n+  if (interleaved_output_indices.empty()) {\n+    // Fall back to regular Create method when no interleaving is requested\n+    return KernelArguments::Create(buffer_assignment, buffer_alignment,\n+                                   hlo_instruction);\n+  }\n+\n+  const auto& operands = hlo_instruction->operands();\n+\n+  TF_ASSIGN_OR_RETURN(\n+      OutputArguments output_result,\n+      ExtractOutputArguments(buffer_assignment, hlo_instruction));\n+  auto& [output_arguments, buffers_written] = output_result;\n+\n+  // Check bounds: all output indices must be valid positions\n+  size_t total_positions = operands.size() + output_arguments.size();\n+  for (int32_t idx : interleaved_output_indices) {\n+    if (idx < 0 || static_cast<size_t>(idx) >= total_positions) {\n+      return absl::InvalidArgumentError(\"Output index out of bounds\");\n+    }\n+  }\n+\n+  std::vector<KernelArgument> kernel_arguments;\n+  kernel_arguments.reserve(total_positions);\n+\n+  // Interleave the inputs and outputs according to the indices\n+  size_t arg_idx = 0;\n+  size_t output_pos = 0;\n+\n+  for (size_t i = 0; i < total_positions; ++i) {\n+    if (output_pos < interleaved_output_indices.size() &&\n+        interleaved_output_indices[output_pos] == static_cast<int32_t>(i)) {\n+      // Place output at this position\n+      if (output_pos >= output_arguments.size()) {\n+        return absl::InvalidArgumentError(\"Invalid output position index\");\n+      }\n+      kernel_arguments.emplace_back(output_arguments[output_pos]);\n+      ++output_pos;\n+    } else {\n+      // Place input at this position\n+      if (arg_idx >= operands.size()) {\n+        return absl::InvalidArgumentError(\n+            \"Not enough inputs for remaining positions\");\n+      }\n+      TF_ASSIGN_OR_RETURN(\n+          BufferAllocation::Slice slice,\n+          buffer_assignment.GetUniqueSlice(operands[arg_idx], {}));\n+      kernel_arguments.emplace_back(\n+          KernelArgument(operands[arg_idx]->shape(), slice));\n+      ++arg_idx;\n+    }\n+  }\n+\n+  // Verify we used all inputs and outputs\n+  if (arg_idx != operands.size() || output_pos != output_arguments.size()) {\n+    return absl::InvalidArgumentError(\"Did not use all inputs/outputs\");\n+  }\n \n   FillKernelArgumentAttributes(kernel_arguments, buffer_alignment,\n                                buffers_written);\n \n-  return KernelArguments{std::move(kernel_arguments)};\n+  return KernelArguments(std::move(kernel_arguments));\n }\n \n }  // namespace xla::emitters"
        },
        {
            "sha": "f3c6d4a52962f7dd0f98c6f13b110e0409a66e3d",
            "filename": "third_party/xla/xla/codegen/emitters/kernel_arguments.h",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fkernel_arguments.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fkernel_arguments.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fkernel_arguments.h?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -84,6 +84,19 @@ class KernelArguments {\n       const BufferAlignment& buffer_alignment,\n       const HloInstruction* hlo_instruction);\n \n+  // Certain kernels require output arguments to be interleaved with input\n+  // arguments. This function creates a KernelArguments object where the output\n+  // arguments are interleaved with the input arguments according to the\n+  // provided indices.\n+  // Example: If hlo_instruction->operands() has 3 elements and hlo_instruction\n+  // shape yields 2 output arguments, and interleaved_output_indices = {1, 4}:\n+  // - Final argument order will be: input0, output0, input1, input2, output1\n+  static absl::StatusOr<KernelArguments> Create(\n+      const BufferAssignment& buffer_assignment,\n+      const BufferAlignment& buffer_alignment,\n+      const HloInstruction* hlo_instruction,\n+      absl::Span<const int32_t> interleaved_output_indices);\n+\n   explicit KernelArguments(std::vector<KernelArgument>&& args)\n       : args_(std::move(args)) {}\n "
        },
        {
            "sha": "af5b70b2612107b0933b10704bc20f4337ab9b67",
            "filename": "third_party/xla/xla/codegen/emitters/kernel_arguments_test.cc",
            "status": "modified",
            "additions": 219,
            "deletions": 0,
            "changes": 219,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fkernel_arguments_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fkernel_arguments_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Fkernel_arguments_test.cc?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -18,12 +18,16 @@ limitations under the License.\n #include <cstddef>\n #include <cstdint>\n #include <memory>\n+#include <vector>\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n+#include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/hlo/analysis/alias_info.h\"\n #include \"xla/hlo/analysis/hlo_ordering.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n #include \"xla/hlo/testlib/verified_hlo_module.h\"\n #include \"xla/service/buffer_assignment.h\"\n@@ -36,7 +40,9 @@ limitations under the License.\n \n namespace xla::emitters {\n namespace {\n+using ::absl_testing::StatusIs;\n using ::testing::ElementsAre;\n+using ::testing::HasSubstr;\n using ::testing::SizeIs;\n \n using KernelArgumentsTest = HloHardwareIndependentTestBase;\n@@ -94,5 +100,218 @@ TEST_F(KernelArgumentsTest, GetArgumentBufferSlices) {\n               ElementsAre(false, false, true));\n }\n \n+TEST_F(KernelArgumentsTest, InterleavedOutputIndicesTest) {\n+  const absl::string_view hlo_string = R\"(\n+HloModule TestModule\n+\n+ENTRY main {\n+  param0 = f32[10] parameter(0)\n+  param1 = f32[20] parameter(1)\n+  param2 = f32[30] parameter(2)\n+\n+  ROOT tuple_result = (f32[10], f32[20]) tuple(param0, param1)\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* root = module->entry_computation()->root_instruction();\n+\n+  AliasInfo alias_info;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<BufferAssignment> buffer_assignment,\n+      BufferAssigner::Run(\n+          module.get(), std::make_unique<DependencyHloOrdering>(module.get()),\n+          [](const BufferValue& buffer) {\n+            return ShapeUtil::ByteSizeOf(buffer.shape(), sizeof(void*));\n+          },\n+          &alias_info, [](LogicalBuffer::Color) { return 1; },\n+          /*allocate_buffers_for_constants=*/true));\n+\n+  KernelArguments::BufferAlignment buffer_alignment;\n+  buffer_alignment.entry_parameter_align_bytes = 1;\n+  buffer_alignment.constant_buffer_align_bytes = 1;\n+  buffer_alignment.xla_allocated_buffer_align_bytes = 1;\n+\n+  // Test 1: Create regular (non-interleaved) arguments for baseline\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelArguments regular_args,\n+      KernelArguments::Create(*buffer_assignment, buffer_alignment, root, {}));\n+\n+  // Test 2: Create interleaved arguments\n+  // Expected order: input0, output0, input1, output1\n+  std::vector<int32_t> interleaved_indices = {1, 3};\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelArguments interleaved_args,\n+      KernelArguments::Create(*buffer_assignment, buffer_alignment, root,\n+                              interleaved_indices));\n+\n+  // Get buffer slices for comparison\n+  auto regular_slices = regular_args.GetArgumentBufferSlices();\n+  auto interleaved_slices = interleaved_args.GetArgumentBufferSlices();\n+\n+  // Verify sizes\n+  ASSERT_EQ(regular_slices.size(), 4);      // 2 inputs + 2 outputs\n+  ASSERT_EQ(interleaved_slices.size(), 4);  // same total count\n+\n+  // Verify interleaving worked by comparing buffer slices:\n+  // Regular order:     [input0, input1, output0, output1]\n+  // Interleaved order: [input0, output0, input1, output1]\n+  EXPECT_EQ(interleaved_slices[0],\n+            regular_slices[0]);  // input0 stays at position 0\n+  EXPECT_EQ(interleaved_slices[1],\n+            regular_slices[2]);  // output0 moves to position 1\n+  EXPECT_EQ(interleaved_slices[2],\n+            regular_slices[1]);  // input1 moves to position 2\n+  EXPECT_EQ(interleaved_slices[3],\n+            regular_slices[3]);  // output1 moves to position 3\n+}\n+\n+TEST_F(KernelArgumentsTest, InterleavedOutputIndicesEdgeCases) {\n+  const absl::string_view hlo_string = R\"(\n+HloModule TestModule\n+\n+ENTRY main {\n+  param0 = f32[5] parameter(0)\n+\n+  ROOT tuple_result = (f32[5]) tuple(param0)\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* root = module->entry_computation()->root_instruction();\n+\n+  AliasInfo alias_info;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<BufferAssignment> buffer_assignment,\n+      BufferAssigner::Run(\n+          module.get(), std::make_unique<DependencyHloOrdering>(module.get()),\n+          &BufferSizeBytes, &alias_info, [](LogicalBuffer::Color) { return 1; },\n+          /*allocate_buffers_for_constants=*/true));\n+\n+  KernelArguments::BufferAlignment buffer_alignment;\n+  buffer_alignment.entry_parameter_align_bytes = 1;\n+  buffer_alignment.constant_buffer_align_bytes = 1;\n+  buffer_alignment.xla_allocated_buffer_align_bytes = 1;\n+\n+  // Test 1: Create regular (non-interleaved) arguments for baseline\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelArguments regular_args,\n+      KernelArguments::Create(*buffer_assignment, buffer_alignment, root, {}));\n+\n+  // Test 2: Create interleaved arguments - output at beginning (position 0)\n+  // Expected order: output0, input0 (instead of input0, output0)\n+  std::vector<int32_t> interleaved_indices = {0};\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelArguments interleaved_args,\n+      KernelArguments::Create(*buffer_assignment, buffer_alignment, root,\n+                              interleaved_indices));\n+\n+  // Get buffer slices for comparison\n+  auto regular_slices = regular_args.GetArgumentBufferSlices();\n+  auto interleaved_slices = interleaved_args.GetArgumentBufferSlices();\n+\n+  // Verify sizes\n+  ASSERT_EQ(regular_slices.size(), 2);      // 1 input + 1 output\n+  ASSERT_EQ(interleaved_slices.size(), 2);  // same total count\n+\n+  // Verify interleaving worked by comparing buffer slices:\n+  // Regular order:     [input0, output0]\n+  // Interleaved order: [output0, input0]\n+  EXPECT_EQ(interleaved_slices[0],\n+            regular_slices[1]);  // output0 moves to position 0\n+  EXPECT_EQ(interleaved_slices[1],\n+            regular_slices[0]);  // input0 moves to position 1\n+\n+  // Also verify by checking shapes\n+  const auto& interleaved_shapes = interleaved_args.args();\n+\n+  // Both should be f32[5] but in different order\n+  EXPECT_EQ(interleaved_shapes[0].shape(),\n+            ShapeUtil::MakeShape(F32, {5}));  // output0 at position 0\n+  EXPECT_EQ(interleaved_shapes[1].shape(),\n+            ShapeUtil::MakeShape(F32, {5}));  // input0 at position 1\n+}\n+\n+TEST_F(KernelArgumentsTest, InterleavedOutputIndicesErrorCases) {\n+  const absl::string_view hlo_string = R\"(\n+HloModule TestModule\n+\n+ENTRY main {\n+  param0 = f32[5] parameter(0)\n+\n+  ROOT result = f32[5] add(param0, param0)\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* root = module->entry_computation()->root_instruction();\n+\n+  AliasInfo alias_info;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<BufferAssignment> buffer_assignment,\n+      BufferAssigner::Run(\n+          module.get(), std::make_unique<DependencyHloOrdering>(module.get()),\n+          &BufferSizeBytes, &alias_info, [](LogicalBuffer::Color) { return 1; },\n+          /*allocate_buffers_for_constants=*/true));\n+\n+  KernelArguments::BufferAlignment buffer_alignment;\n+  buffer_alignment.entry_parameter_align_bytes = 1;\n+  buffer_alignment.constant_buffer_align_bytes = 1;\n+  buffer_alignment.xla_allocated_buffer_align_bytes = 1;\n+\n+  // Test case: Output index out of bounds\n+  // root->operands() = {param0, param0} (2 operands, but same parameter used\n+  // twice) outputs = {result} (1 output) Total positions = 3, so index 5 is out\n+  // of bounds\n+  std::vector<int32_t> invalid_indices = {5};\n+  EXPECT_THAT(KernelArguments::Create(*buffer_assignment, buffer_alignment,\n+                                      root, invalid_indices),\n+              StatusIs(absl::StatusCode::kInvalidArgument,\n+                       HasSubstr(\"Output index out of bounds\")));\n+}\n+\n+TEST_F(KernelArgumentsTest, EmptyInterleavedIndicesFallback) {\n+  const absl::string_view hlo_string = R\"(\n+HloModule TestModule\n+\n+ENTRY main {\n+  param0 = f32[5] parameter(0)\n+  ROOT result = f32[5] add(param0, param0)\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* root = module->entry_computation()->root_instruction();\n+\n+  AliasInfo alias_info;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<BufferAssignment> buffer_assignment,\n+      BufferAssigner::Run(\n+          module.get(), std::make_unique<DependencyHloOrdering>(module.get()),\n+          &BufferSizeBytes, &alias_info, [](LogicalBuffer::Color) { return 1; },\n+          /*allocate_buffers_for_constants=*/true));\n+\n+  KernelArguments::BufferAlignment buffer_alignment;\n+  buffer_alignment.entry_parameter_align_bytes = 1;\n+  buffer_alignment.constant_buffer_align_bytes = 1;\n+  buffer_alignment.xla_allocated_buffer_align_bytes = 1;\n+\n+  // Test case: Empty interleaved indices should fall back to regular Create\n+  std::vector<int32_t> empty_indices = {};\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelArguments kernel_args,\n+      KernelArguments::Create(*buffer_assignment, buffer_alignment, root,\n+                              empty_indices));\n+\n+  // Should succeed and create arguments in regular order: inputs first, then\n+  // outputs\n+  ASSERT_EQ(kernel_args.args().size(), 3);  // 2 inputs + 1 output\n+}\n+\n }  // namespace\n }  // namespace xla::emitters"
        },
        {
            "sha": "60de50e9fe45dcd5a320b232849a217876a47207",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 94,
            "deletions": 1,
            "changes": 95,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -332,6 +332,60 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"ptx_custom_kernel_emitter_cuda\",\n+    srcs = [\"custom_kernel_emitter_cuda.cc\"],\n+    hdrs = [\"custom_kernel_emitter.h\"],\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+    ],\n+    deps = [\n+        \":gpu_constants\",\n+        \":ir_emitter_context\",\n+        \":kernel_call\",\n+        \"//xla/backends/gpu/runtime:kernel_thunk\",\n+        \"//xla/codegen/emitters:kernel_arguments\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/service/gpu/kernels:custom_kernel\",\n+        \"//xla/service/gpu/kernels:ptx_custom_kernel\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"ptx_custom_kernel_emitter_rocm\",\n+    srcs = [\"custom_kernel_emitter_rocm.cc\"],\n+    hdrs = [\"custom_kernel_emitter.h\"],\n+    tags = [\n+        \"gpu\",\n+        \"rocm-only\",\n+    ],\n+    deps = [\n+        \":ir_emitter_context\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"ptx_custom_kernel_emitter\",\n+    hdrs = [\"custom_kernel_emitter.h\"],\n+    tags = [\"gpu\"],\n+    deps = if_cuda_is_configured([\n+        \":ptx_custom_kernel_emitter_cuda\",\n+    ]) + if_rocm_is_configured([\n+        \":ptx_custom_kernel_emitter_rocm\",\n+    ]) + [\n+        \"//xla/hlo/ir:hlo\",\n+        \"@com_google_absl//absl/status:statusor\",\n+    ],\n+)\n+\n cc_library(\n     name = \"ir_emitter_context\",\n     srcs = [\"ir_emitter_context.cc\"],\n@@ -369,17 +423,20 @@ cc_library(\n         \":backend_configs_cc\",\n         \":cublas_cudnn\",\n         \":execution_stream_assignment\",\n+        \":gpu_asm_opts_util\",\n         \":gpu_constants\",\n         \":gpu_conv_runner\",\n         \":gpu_norm_runner\",\n         \":hlo_fusion_analysis\",\n         \":ir_emission_utils\",\n         \":ir_emitter\",\n         \":ir_emitter_context\",\n+        \":kernel_call\",\n         \":kernel_reuse_cache\",\n         \":launch_dimensions\",\n         \":matmul_utils\",\n         \":parallel_loop_emitter\",\n+        \":ptx_custom_kernel_emitter\",\n         \":stream_executor_util\",\n         \":triton_call\",\n         \"//xla:autotuning_proto_cc\",\n@@ -467,6 +524,7 @@ cc_library(\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n+        \"//xla/stream_executor/gpu:gpu_asm_opts\",\n         \"//xla/stream_executor/gpu:gpu_blas_lt\",\n         \"//xla/stream_executor/gpu:tma_metadata\",\n         \"//xla/stream_executor/platform:platform_object_registry\",\n@@ -502,7 +560,9 @@ cc_library(\n         \"@local_tsl//tsl/platform:casts\",\n         \"@local_tsl//tsl/platform:human_readable_json\",\n         \"@triton//:TritonDialects\",\n-    ],\n+    ] + if_cuda_is_configured([\n+        \"//xla/service/gpu/kernels:ptx_custom_kernel\",\n+    ]),\n )\n \n cc_library(\n@@ -548,6 +608,39 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"kernel_call\",\n+    srcs = [\"kernel_call.cc\"],\n+    hdrs = [\"kernel_call.h\"],\n+    deps = [\n+        \"//xla/stream_executor:launch_dim\",\n+        \"//xla/tsl/platform:logging\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@llvm-project//llvm:Support\",\n+        \"@llvm-project//mlir:AsmParser\",\n+        \"@llvm-project//mlir:IR\",\n+        \"@llvm-project//mlir:Parser\",\n+        \"@llvm-project//mlir:Support\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"kernel_call_test\",\n+    srcs = [\"kernel_call_test.cc\"],\n+    deps = [\n+        \":kernel_call\",\n+        \"//xla/tests:xla_internal_test_main\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest\",\n+        \"@llvm-project//mlir:IR\",\n+    ],\n+)\n+\n cc_library(\n     name = \"triton_call\",\n     srcs = [\"triton_call.cc\"],"
        },
        {
            "sha": "509a4fca045abd503b77827bc5d1921b53122981",
            "filename": "third_party/xla/xla/service/gpu/custom_kernel_emitter.h",
            "status": "added",
            "additions": 42,
            "deletions": 0,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_kernel_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_kernel_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_kernel_emitter.h?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -0,0 +1,42 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_SERVICE_GPU_CUSTOM_KERNEL_EMITTER_H_\n+#define XLA_SERVICE_GPU_CUSTOM_KERNEL_EMITTER_H_\n+\n+#include <memory>\n+\n+#include \"absl/status/statusor.h\"\n+\n+namespace xla {\n+\n+// Forward declaration to avoid heavy includes.\n+class HloCustomCallInstruction;\n+\n+namespace gpu {\n+\n+class Thunk;\n+class IrEmitterContext;\n+\n+// Emit a platform-specific custom kernel thunk for PTX custom calls.\n+// This function has separate implementations for CUDA and ROCm backends,\n+// selected at build time via conditional compilation in BUILD rules.\n+absl::StatusOr<std::unique_ptr<Thunk>> EmitPtxCustomKernelThunk(\n+    const HloCustomCallInstruction* instr, IrEmitterContext* context);\n+\n+}  // namespace gpu\n+}  // namespace xla\n+\n+#endif  // XLA_SERVICE_GPU_CUSTOM_KERNEL_EMITTER_H_"
        },
        {
            "sha": "53ea119163965f1a56b6487fa5b9c9517690c950",
            "filename": "third_party/xla/xla/service/gpu/custom_kernel_emitter_cuda.cc",
            "status": "added",
            "additions": 69,
            "deletions": 0,
            "changes": 69,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_kernel_emitter_cuda.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_kernel_emitter_cuda.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_kernel_emitter_cuda.cc?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -0,0 +1,69 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <memory>\n+\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/backends/gpu/runtime/kernel_thunk.h\"\n+#include \"xla/codegen/emitters/kernel_arguments.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/service/gpu/custom_kernel_emitter.h\"\n+#include \"xla/service/gpu/gpu_constants.h\"\n+#include \"xla/service/gpu/ir_emitter_context.h\"\n+#include \"xla/service/gpu/kernel_call.h\"\n+#include \"xla/service/gpu/kernels/custom_kernel.h\"\n+#include \"xla/service/gpu/kernels/ptx_custom_kernel.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+absl::StatusOr<std::unique_ptr<Thunk>> EmitPtxCustomKernelThunk(\n+    const HloCustomCallInstruction* instr, IrEmitterContext* context) {\n+  absl::string_view backend_config_str = instr->raw_backend_config_string();\n+  if (backend_config_str.empty()) {\n+    return absl::InvalidArgumentError(\n+        \"PTX custom call backend config is empty\");\n+  }\n+\n+  TF_ASSIGN_OR_RETURN(\n+      KernelCall call,\n+      KernelCall::Parse(backend_config_str, context->mlir_context()));\n+  if (call.kernel_type != KernelCall::KernelType::kPtxSource) {\n+    return absl::InvalidArgumentError(\n+        \"PTX custom call backend config is not a PTX source\");\n+  }\n+\n+  emitters::KernelArguments::BufferAlignment buffer_alignment =\n+      GetDefaultBufferAlignment();\n+  TF_ASSIGN_OR_RETURN(emitters::KernelArguments kernel_arguments,\n+                      emitters::KernelArguments::Create(\n+                          context->buffer_assignment(), buffer_alignment, instr,\n+                          call.output_indices));\n+\n+  TF_ASSIGN_OR_RETURN(\n+      CustomKernel ptx_custom_kernel,\n+      kernel::GetOwnedPtxCustomKernel(\n+          call.name, call.kernel_data, kernel_arguments.args().size(),\n+          call.block_dim, call.thread_dim, call.shared_mem));\n+\n+  return std::make_unique<CustomKernelThunk>(\n+      instr, ptx_custom_kernel, kernel_arguments, context->GetNextThunkId());\n+}\n+\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "96ae477e08c566e37432dfdbb8fb8c83e387f5e4",
            "filename": "third_party/xla/xla/service/gpu/custom_kernel_emitter_rocm.cc",
            "status": "added",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_kernel_emitter_rocm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_kernel_emitter_rocm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_kernel_emitter_rocm.cc?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -0,0 +1,34 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <memory>\n+\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/service/gpu/custom_kernel_emitter.h\"\n+#include \"xla/service/gpu/ir_emitter_context.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+absl::StatusOr<std::unique_ptr<Thunk>> EmitPtxCustomKernelThunk(\n+    const HloCustomCallInstruction* instr, IrEmitterContext* /*context*/) {\n+  return absl::UnimplementedError(\n+      \"ROCm custom kernel emitter is not yet implemented for PTX custom calls\");\n+}\n+\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "3cf8d687b4f7f4c68f6a19cd0185d2a361e2a24f",
            "filename": "third_party/xla/xla/service/gpu/ir_emission_utils.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emission_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emission_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emission_utils.cc?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -146,6 +146,11 @@ bool IsCustomCallToTopK(const HloInstruction& hlo) {\n          hlo.custom_call_target() == kTopKCustomCallTarget;\n }\n \n+bool IsCustomCallToPtxKernel(const HloInstruction& hlo) {\n+  return hlo.opcode() == HloOpcode::kCustomCall &&\n+         hlo.custom_call_target() == \"__gpu$xla.gpu.ptx\";\n+}\n+\n static bool IsContiguousSlice(\n     const Shape& orig, const Shape& sliced,\n     std::optional<absl::Span<const int64_t>> slice_strides) {"
        },
        {
            "sha": "f8c4fbd0c535f563f2cfc3610bcc58324ee206d7",
            "filename": "third_party/xla/xla/service/gpu/ir_emission_utils.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emission_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emission_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emission_utils.h?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -155,6 +155,10 @@ bool IsCustomCallToCusolver(const HloInstruction& hlo);\n // Returns true if `hlo` will be implemented as a call to a TopK routine.\n bool IsCustomCallToTopK(const HloInstruction& hlo);\n \n+// Returns true if `hlo` will be implmented as a call to a custom PTX kernel\n+// implementation.\n+bool IsCustomCallToPtxKernel(const HloInstruction& hlo);\n+\n // Cholesky decomposition. Takes a (batched) matrix as input, and returns a\n // tuple of (result, workspace, info), where result is the result of the\n // Cholesky decomposition, workspace is scratch space for cuSolver, and info"
        },
        {
            "sha": "cab5015dc6e40d85e4af2085790576bda96ed13b",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -144,6 +144,7 @@ limitations under the License.\n #include \"xla/service/global_device_id.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/cublas_cudnn.h\"\n+#include \"xla/service/gpu/custom_kernel_emitter.h\"\n #include \"xla/service/gpu/execution_stream_assignment.h\"\n #include \"xla/service/gpu/gpu_constants.h\"\n #include \"xla/service/gpu/gpu_conv_runner.h\"\n@@ -1036,6 +1037,14 @@ absl::Status IrEmitterUnnested::EmitCuDnnThunk(\n   return absl::OkStatus();\n }\n \n+absl::Status IrEmitterUnnested::EmitPtxCustomCall(\n+    const HloCustomCallInstruction* instr) {\n+  TF_ASSIGN_OR_RETURN(auto thunk,\n+                      EmitPtxCustomKernelThunk(instr, ir_emitter_context_));\n+  AddThunkToThunkSequence(std::move(thunk));\n+  return absl::OkStatus();\n+}\n+\n absl::StatusOr<BufferAllocation::Slice>\n IrEmitterUnnested::GetAllocationSliceForHlo(const HloInstruction* instr,\n                                             const ShapeIndex& index) const {\n@@ -3349,6 +3358,9 @@ absl::Status IrEmitterUnnested::EmitHloInstruction(\n           IsCustomCallToBlockScaledDot(*instr)) {\n         return EmitCuDnnThunk(custom_call);\n       }\n+      if (IsCustomCallToPtxKernel(*instr)) {\n+        return EmitPtxCustomCall(custom_call);\n+      }\n       if (IsCustomCallToTopK(*instr)) {\n         return EmitTopKCustomCall(custom_call);\n       }"
        },
        {
            "sha": "9273537d8af225082aaf3ca32a8bf5fd1eb05933",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.h?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -124,6 +124,7 @@ class IrEmitterUnnested : public IrEmitter {\n       const HloCustomCallInstruction* instr);\n   absl::Status EmitNormThunk(const HloCustomCallInstruction* instr);\n   absl::Status EmitCuDnnThunk(const HloCustomCallInstruction* instr);\n+  absl::Status EmitPtxCustomCall(const HloCustomCallInstruction* instr);\n   absl::Status EmitCubDeviceRadixSort(const HloCustomCallInstruction* instr);\n   absl::Status EmitCholeskyThunk(const HloInstruction* instr);\n   absl::Status EmitCustomCallThunk(const HloCustomCallInstruction* instr);"
        },
        {
            "sha": "0038faa9153d93da380d01283257c33723961bc4",
            "filename": "third_party/xla/xla/service/gpu/kernel_call.cc",
            "status": "added",
            "additions": 140,
            "deletions": 0,
            "changes": 140,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_call.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_call.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_call.cc?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -0,0 +1,140 @@\n+/* Copyright 2025 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/kernel_call.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"llvm/Support/raw_ostream.h\"\n+#include \"mlir/AsmParser/AsmParser.h\"\n+#include \"mlir/IR/Attributes.h\"\n+#include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/Parser/Parser.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"xla/stream_executor/launch_dim.h\"\n+#include \"xla/tsl/platform/logging.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla::gpu {\n+\n+// Helper function to parse kernel type string into enum\n+absl::StatusOr<KernelCall::KernelType> ParseKernelType(\n+    const std::string& kernel_type_str) {\n+  if (kernel_type_str == \"ptx\") {\n+    return KernelCall::KernelType::kPtxSource;\n+  } else if (kernel_type_str == \"cubin\") {\n+    return KernelCall::KernelType::kCudaBinary;\n+  } else {\n+    return absl::InvalidArgumentError(\n+        absl::StrCat(\"Unknown kernel type: \", kernel_type_str,\n+                     \". Supported types: 'ptx', 'cubin'\"));\n+  }\n+}\n+\n+absl::StatusOr<KernelCall> KernelCall::Parse(absl::string_view backend_config,\n+                                             mlir::MLIRContext* mlir_context) {\n+  auto attrs = mlir::cast<mlir::DictionaryAttr>(\n+      mlir::parseAttribute(backend_config, mlir_context));\n+\n+  // Check for required \"name\" field\n+  auto name_attr = attrs.getAs<mlir::StringAttr>(\"name\");\n+  if (!name_attr) {\n+    return absl::InvalidArgumentError(\n+        \"Missing required field 'name' in backend_config\");\n+  }\n+  auto name = name_attr.getValue().str();\n+\n+  // Check for required \"kernel_type\" field\n+  auto kernel_type_attr = attrs.getAs<mlir::StringAttr>(\"kernel_type\");\n+  if (!kernel_type_attr) {\n+    return absl::InvalidArgumentError(\n+        \"Missing required field 'kernel_type' in backend_config\");\n+  }\n+  auto kernel_type_str = kernel_type_attr.getValue().str();\n+  TF_ASSIGN_OR_RETURN(KernelCall::KernelType kernel_type,\n+                      ParseKernelType(kernel_type_str));\n+\n+  // Check for required \"kernel_data\" field\n+  auto kernel_data_attr = attrs.getAs<mlir::StringAttr>(\"kernel_data\");\n+  if (!kernel_data_attr) {\n+    return absl::InvalidArgumentError(\n+        \"Missing required field 'kernel_data' in backend_config\");\n+  }\n+  auto kernel_data = kernel_data_attr.getValue().str();\n+\n+  if (VLOG_IS_ON(2)) {\n+    LOG(INFO) << \"Kernel Call backend_config:\";\n+    for (const auto& namedAttr : attrs) {\n+      std::string value_str;\n+      llvm::raw_string_ostream os(value_str);\n+      namedAttr.getValue().print(os);\n+      LOG(INFO) << \"  \" << namedAttr.getName().str() << \": \" << value_str;\n+    }\n+  }\n+\n+  auto get_int32_attr =\n+      [&attrs](const char* attr_name) -> absl::StatusOr<int32_t> {\n+    auto attr = attrs.getAs<mlir::IntegerAttr>(attr_name);\n+    if (!attr) {\n+      return absl::InvalidArgumentError(absl::StrCat(\n+          \"Missing required field '\", attr_name, \"' in backend_config\"));\n+    }\n+    return static_cast<int32_t>(attr.getValue().getSExtValue());\n+  };\n+\n+  TF_ASSIGN_OR_RETURN(int32_t grid_x, get_int32_attr(\"grid_x\"));\n+  TF_ASSIGN_OR_RETURN(int32_t grid_y, get_int32_attr(\"grid_y\"));\n+  TF_ASSIGN_OR_RETURN(int32_t grid_z, get_int32_attr(\"grid_z\"));\n+  TF_ASSIGN_OR_RETURN(int32_t block_x, get_int32_attr(\"block_x\"));\n+  TF_ASSIGN_OR_RETURN(int32_t block_y, get_int32_attr(\"block_y\"));\n+  TF_ASSIGN_OR_RETURN(int32_t block_z, get_int32_attr(\"block_z\"));\n+  TF_ASSIGN_OR_RETURN(int32_t shared_mem, get_int32_attr(\"shared_mem_bytes\"));\n+\n+  // Optional output_indices field\n+  mlir::ArrayAttr output_indices =\n+      attrs.getAs<mlir::ArrayAttr>(\"output_indices\");\n+  std::vector<int32_t> output_indices_vec;\n+  if (output_indices) {\n+    for (const mlir::Attribute& index : output_indices) {\n+      auto int_attr = mlir::dyn_cast<mlir::IntegerAttr>(index);\n+      if (!int_attr) {\n+        return absl::InvalidArgumentError(\n+            \"Invalid output_indices: all elements must be integers\");\n+      }\n+      output_indices_vec.push_back(int_attr.getValue().getSExtValue());\n+    }\n+  }\n+\n+  return KernelCall{\n+      std::move(name),\n+      std::move(kernel_data),\n+      kernel_type,\n+      stream_executor::BlockDim(grid_x, grid_y, grid_z),\n+      stream_executor::ThreadDim(block_x, block_y, block_z),\n+      static_cast<size_t>(shared_mem),\n+      std::move(output_indices_vec),\n+  };\n+}\n+\n+}  // namespace xla::gpu"
        },
        {
            "sha": "c158bbf9cd30c02981b7a9938d48d4ee3dbc82fe",
            "filename": "third_party/xla/xla/service/gpu/kernel_call.h",
            "status": "added",
            "additions": 50,
            "deletions": 0,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_call.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_call.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_call.h?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -0,0 +1,50 @@\n+/* Copyright 2025 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_SERVICE_GPU_KERNEL_CALL_H_\n+#define XLA_SERVICE_GPU_KERNEL_CALL_H_\n+\n+#include <cstdint>\n+#include <string>\n+#include <vector>\n+\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"xla/stream_executor/launch_dim.h\"\n+\n+namespace xla::gpu {\n+\n+struct KernelCall {\n+  std::string name;\n+  std::string kernel_data;\n+  enum class KernelType {\n+    kPtxSource,\n+    kCudaBinary,\n+  } kernel_type;\n+\n+  stream_executor::BlockDim block_dim;\n+  stream_executor::ThreadDim thread_dim;\n+  size_t shared_mem;\n+  std::vector<int32_t> output_indices;\n+\n+  // Parse the metadata of a __gpu$xla.gpu.ptx call.\n+  static absl::StatusOr<KernelCall> Parse(absl::string_view backend_config,\n+                                          mlir::MLIRContext* mlir_context);\n+};\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_SERVICE_GPU_KERNEL_CALL_H_"
        },
        {
            "sha": "de0c4c66ea25d65dcf90bf0a25acdb64db252c27",
            "filename": "third_party/xla/xla/service/gpu/kernel_call_test.cc",
            "status": "added",
            "additions": 244,
            "deletions": 0,
            "changes": 244,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_call_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_call_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernel_call_test.cc?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -0,0 +1,244 @@\n+/* Copyright 2025 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/kernel_call.h\"\n+\n+#include <memory>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/strings/string_view.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+using ::testing::ElementsAre;\n+using ::testing::HasSubstr;\n+\n+class KernelCallTest : public ::testing::Test {\n+ protected:\n+  void SetUp() override {\n+    mlir_context_ = std::make_unique<mlir::MLIRContext>();\n+  }\n+\n+  std::unique_ptr<mlir::MLIRContext> mlir_context_;\n+};\n+\n+TEST_F(KernelCallTest, ParseBasicConfiguration) {\n+  absl::string_view backend_config = R\"({\n+    name = \"test_kernel\",\n+    kernel_type = \"ptx\",\n+    kernel_data = \".version 7.0\\n.target sm_70\\n.entry test_kernel() { ret; }\",\n+    grid_x = 1,\n+    grid_y = 2,\n+    grid_z = 3,\n+    block_x = 4,\n+    block_y = 5,\n+    block_z = 6,\n+    shared_mem_bytes = 1024\n+  })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelCall kernel_call,\n+      KernelCall::Parse(backend_config, mlir_context_.get()));\n+\n+  EXPECT_EQ(kernel_call.name, \"test_kernel\");\n+  EXPECT_EQ(kernel_call.kernel_data,\n+            \".version 7.0\\n.target sm_70\\n.entry test_kernel() { ret; }\");\n+  EXPECT_EQ(kernel_call.block_dim.x, 1);\n+  EXPECT_EQ(kernel_call.block_dim.y, 2);\n+  EXPECT_EQ(kernel_call.block_dim.z, 3);\n+  EXPECT_EQ(kernel_call.thread_dim.x, 4);\n+  EXPECT_EQ(kernel_call.thread_dim.y, 5);\n+  EXPECT_EQ(kernel_call.thread_dim.z, 6);\n+  EXPECT_EQ(kernel_call.shared_mem, 1024);\n+  EXPECT_TRUE(kernel_call.output_indices.empty());\n+}\n+\n+TEST_F(KernelCallTest, ParseWithOutputIndices) {\n+  absl::string_view backend_config = R\"({\n+    name = \"kernel_with_outputs\",\n+    kernel_type = \"ptx\",\n+    kernel_data = \".version 7.0\\n.target sm_70\\n.entry kernel_with_outputs() { ret; }\",\n+    grid_x = 10,\n+    grid_y = 20,\n+    grid_z = 1,\n+    block_x = 32,\n+    block_y = 1,\n+    block_z = 1,\n+    shared_mem_bytes = 0,\n+    output_indices = [1, 3, 5]\n+  })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelCall kernel_call,\n+      KernelCall::Parse(backend_config, mlir_context_.get()));\n+\n+  EXPECT_EQ(kernel_call.name, \"kernel_with_outputs\");\n+  EXPECT_EQ(kernel_call.block_dim.x, 10);\n+  EXPECT_EQ(kernel_call.block_dim.y, 20);\n+  EXPECT_EQ(kernel_call.block_dim.z, 1);\n+  EXPECT_EQ(kernel_call.thread_dim.x, 32);\n+  EXPECT_EQ(kernel_call.thread_dim.y, 1);\n+  EXPECT_EQ(kernel_call.thread_dim.z, 1);\n+  EXPECT_EQ(kernel_call.shared_mem, 0);\n+\n+  ASSERT_EQ(kernel_call.output_indices.size(), 3);\n+  EXPECT_EQ(kernel_call.output_indices[0], 1);\n+  EXPECT_EQ(kernel_call.output_indices[1], 3);\n+  EXPECT_EQ(kernel_call.output_indices[2], 5);\n+}\n+\n+TEST_F(KernelCallTest, ParseMinimalConfiguration) {\n+  absl::string_view backend_config = R\"({\n+    name = \"minimal_kernel\",\n+    kernel_type = \"ptx\",\n+    kernel_data = \".entry minimal_kernel() { ret; }\",\n+    grid_x = 1,\n+    grid_y = 1,\n+    grid_z = 1,\n+    block_x = 1,\n+    block_y = 1,\n+    block_z = 1,\n+    shared_mem_bytes = 0\n+  })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelCall kernel_call,\n+      KernelCall::Parse(backend_config, mlir_context_.get()));\n+\n+  EXPECT_EQ(kernel_call.name, \"minimal_kernel\");\n+  EXPECT_EQ(kernel_call.kernel_data, \".entry minimal_kernel() { ret; }\");\n+  EXPECT_EQ(kernel_call.block_dim.x, 1);\n+  EXPECT_EQ(kernel_call.block_dim.y, 1);\n+  EXPECT_EQ(kernel_call.block_dim.z, 1);\n+  EXPECT_EQ(kernel_call.thread_dim.x, 1);\n+  EXPECT_EQ(kernel_call.thread_dim.y, 1);\n+  EXPECT_EQ(kernel_call.thread_dim.z, 1);\n+  EXPECT_EQ(kernel_call.shared_mem, 0);\n+  EXPECT_TRUE(kernel_call.output_indices.empty());\n+}\n+\n+TEST_F(KernelCallTest, ParseLargeDimensions) {\n+  absl::string_view backend_config = R\"({\n+    name = \"large_kernel\",\n+    kernel_type = \"ptx\",\n+    kernel_data = \".entry large_kernel() { ret; }\",\n+    grid_x = 65535,\n+    grid_y = 65535,\n+    grid_z = 65535,\n+    block_x = 1024,\n+    block_y = 1024,\n+    block_z = 64,\n+    shared_mem_bytes = 49152\n+  })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelCall kernel_call,\n+      KernelCall::Parse(backend_config, mlir_context_.get()));\n+\n+  EXPECT_EQ(kernel_call.name, \"large_kernel\");\n+  EXPECT_EQ(kernel_call.block_dim.x, 65535);\n+  EXPECT_EQ(kernel_call.block_dim.y, 65535);\n+  EXPECT_EQ(kernel_call.block_dim.z, 65535);\n+  EXPECT_EQ(kernel_call.thread_dim.x, 1024);\n+  EXPECT_EQ(kernel_call.thread_dim.y, 1024);\n+  EXPECT_EQ(kernel_call.thread_dim.z, 64);\n+  EXPECT_EQ(kernel_call.shared_mem, 49152);\n+}\n+\n+TEST_F(KernelCallTest, ParseEmptyOutputIndices) {\n+  absl::string_view backend_config = R\"({\n+    name = \"no_outputs\",\n+    kernel_type = \"ptx\",\n+    kernel_data = \".entry no_outputs() { ret; }\",\n+    grid_x = 1,\n+    grid_y = 1,\n+    grid_z = 1,\n+    block_x = 32,\n+    block_y = 1,\n+    block_z = 1,\n+    shared_mem_bytes = 512,\n+    output_indices = []\n+  })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelCall kernel_call,\n+      KernelCall::Parse(backend_config, mlir_context_.get()));\n+\n+  EXPECT_EQ(kernel_call.name, \"no_outputs\");\n+  EXPECT_EQ(kernel_call.shared_mem, 512);\n+  EXPECT_TRUE(kernel_call.output_indices.empty());\n+}\n+\n+TEST_F(KernelCallTest, ParseSingleOutputIndex) {\n+  absl::string_view backend_config = R\"({\n+    name = \"single_output\",\n+    kernel_type = \"ptx\",\n+    kernel_data = \".entry single_output() { ret; }\",\n+    grid_x = 2,\n+    grid_y = 1,\n+    grid_z = 1,\n+    block_x = 64,\n+    block_y = 1,\n+    block_z = 1,\n+    shared_mem_bytes = 256,\n+    output_indices = [0]\n+  })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelCall kernel_call,\n+      KernelCall::Parse(backend_config, mlir_context_.get()));\n+\n+  EXPECT_EQ(kernel_call.name, \"single_output\");\n+  EXPECT_EQ(kernel_call.shared_mem, 256);\n+  ASSERT_EQ(kernel_call.output_indices.size(), 1);\n+  EXPECT_EQ(kernel_call.output_indices[0], 0);\n+}\n+\n+TEST_F(KernelCallTest, ParseComplexkernel_data) {\n+  absl::string_view backend_config = R\"({\n+    name = \"complex_kernel\",\n+    kernel_type = \"ptx\",\n+    kernel_data = \".version 7.5\\n.target sm_80\\n.address_size 64\\n\\n.entry complex_kernel(.param .u64 ptr) {\\n  .reg .u64 %r1;\\n  ld.param.u64 %r1, [ptr];\\n  ret;\\n}\",\n+    grid_x = 100,\n+    grid_y = 50,\n+    grid_z = 1,\n+    block_x = 256,\n+    block_y = 1,\n+    block_z = 1,\n+    shared_mem_bytes = 8192,\n+    output_indices = [2, 4, 6, 8]\n+  })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      KernelCall kernel_call,\n+      KernelCall::Parse(backend_config, mlir_context_.get()));\n+\n+  EXPECT_EQ(kernel_call.name, \"complex_kernel\");\n+  EXPECT_THAT(kernel_call.kernel_data, HasSubstr(\".version 7.5\"));\n+  EXPECT_THAT(kernel_call.kernel_data, HasSubstr(\".target sm_80\"));\n+  EXPECT_THAT(kernel_call.kernel_data, HasSubstr(\"complex_kernel\"));\n+  EXPECT_EQ(kernel_call.block_dim.x, 100);\n+  EXPECT_EQ(kernel_call.block_dim.y, 50);\n+  EXPECT_EQ(kernel_call.thread_dim.x, 256);\n+  EXPECT_EQ(kernel_call.shared_mem, 8192);\n+  EXPECT_THAT(kernel_call.output_indices, ElementsAre(2, 4, 6, 8));\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        },
        {
            "sha": "f8cc932bba080d7b26bfdfd40524c86a60936460",
            "filename": "third_party/xla/xla/service/gpu/kernels/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2FBUILD?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -375,6 +375,7 @@ cc_library(\n         \"cuda-only\",\n         \"gpu\",\n     ],\n+    visibility = [\":friends\"],\n     deps = [\n         \":custom_kernel\",\n         \"//xla/stream_executor:device_memory\","
        },
        {
            "sha": "705adfd953daaf1ffd0b4833eb2ec61a56e078b7",
            "filename": "third_party/xla/xla/service/gpu/kernels/ptx_custom_kernel.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 6,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fptx_custom_kernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fptx_custom_kernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fptx_custom_kernel.cc?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -33,8 +33,8 @@ namespace xla::gpu::kernel {\n namespace se = ::stream_executor;\n \n absl::StatusOr<std::unique_ptr<se::KernelArgsPackedArrayBase>>\n-KernelArgsPacking(const se::Kernel &kernel, const se::KernelArgs &args) {\n-  auto *mem_args = se::Cast<se::KernelArgsDeviceMemoryArray>(&args);\n+KernelArgsPacking(const se::Kernel& kernel, const se::KernelArgs& args) {\n+  auto* mem_args = se::Cast<se::KernelArgsDeviceMemoryArray>(&args);\n \n   return se::PackKernelArgs<se::DeviceMemoryBase>(\n       mem_args->device_memory_args(), mem_args->number_of_shared_bytes());\n@@ -53,8 +53,7 @@ absl::StatusOr<CustomKernel> GetPtxCustomKernel(std::string kernel_name,\n       se::KernelLoaderSpec::CreateCudaPtxInMemorySpec(\n           ptx, kernel_name, /*arity=*/num_args, KernelArgsPacking);\n   return CustomKernel(std::move(kernel_name), kernel_spec, block_dim,\n-                      thread_dim,\n-                      /*shared_memory_bytes=*/shared_memory_bytes);\n+                      thread_dim, shared_memory_bytes);\n };\n \n absl::StatusOr<CustomKernel> GetPtxCustomKernel(\n@@ -65,8 +64,18 @@ absl::StatusOr<CustomKernel> GetPtxCustomKernel(\n       se::KernelLoaderSpec::CreateCudaPtxInMemorySpec(\n           ptx, kernel_name, /*arity=*/num_args, KernelArgsPacking);\n   return CustomKernel(std::move(kernel_name), kernel_spec, block_dim,\n-                      thread_dim, cluster_dim,\n-                      /*shared_memory_bytes=*/shared_memory_bytes);\n+                      thread_dim, cluster_dim, shared_memory_bytes);\n+};\n+\n+absl::StatusOr<CustomKernel> GetOwnedPtxCustomKernel(\n+    std::string kernel_name, std::string ptx, int num_args,\n+    se::BlockDim block_dim, se::ThreadDim thread_dim,\n+    size_t shared_memory_bytes) {\n+  se::KernelLoaderSpec kernel_spec =\n+      se::KernelLoaderSpec::CreateOwningCudaPtxInMemorySpec(\n+          ptx, kernel_name, /*arity=*/num_args, KernelArgsPacking);\n+  return CustomKernel(std::move(kernel_name), kernel_spec, block_dim,\n+                      thread_dim, shared_memory_bytes);\n };\n \n }  // namespace xla::gpu::kernel"
        },
        {
            "sha": "7398ef75a3ab3854fbf7b46e925b2828f60a20fd",
            "filename": "third_party/xla/xla/service/gpu/kernels/ptx_custom_kernel.h",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fptx_custom_kernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fptx_custom_kernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fptx_custom_kernel.h?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -37,6 +37,11 @@ absl::StatusOr<CustomKernel> GetPtxCustomKernel(\n     std::string kernel_name, absl::string_view ptx, int num_args,\n     se::BlockDim block_dim, se::ThreadDim thread_dim,\n     se::ClusterDim cluster_dim, size_t shared_memory_bytes = 0);\n-}  // namespace xla::gpu::kernel\n \n+absl::StatusOr<CustomKernel> GetOwnedPtxCustomKernel(\n+    std::string kernel_name, std::string ptx, int num_args,\n+    se::BlockDim block_dim, se::ThreadDim thread_dim,\n+    size_t shared_memory_bytes = 0);\n+\n+}  // namespace xla::gpu::kernel\n #endif  // XLA_SERVICE_GPU_KERNELS_PTX_CUSTOM_KERNEL_H_"
        },
        {
            "sha": "af0c23cd694e5b2b7f5dcacb640298544a07d8f3",
            "filename": "third_party/xla/xla/service/gpu/kernels/ptx_custom_kernel_test.cc",
            "status": "modified",
            "additions": 83,
            "deletions": 2,
            "changes": 85,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fptx_custom_kernel_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fptx_custom_kernel_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fptx_custom_kernel_test.cc?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -17,8 +17,10 @@ limitations under the License.\n \n #include <cstdint>\n #include <memory>\n+#include <string>\n #include <vector>\n \n+#include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/strings/string_view.h\"\n #include \"xla/service/gpu/kernels/custom_kernel.h\"\n@@ -33,6 +35,8 @@ limitations under the License.\n #include \"xla/tsl/platform/test.h\"\n \n namespace xla::gpu::kernel {\n+namespace {\n+using ::testing::ElementsAre;\n \n namespace se = ::stream_executor;\n \n@@ -149,10 +153,87 @@ TEST(PtxCustomKernelTest, GetPtxCustomKernelWithClusterDim) {\n   std::vector<int32_t> dst(4, 42);\n   TF_CHECK_OK(stream->Memcpy(dst.data(), c, byte_length));\n \n-  std::vector<int32_t> expected = {3, 3, 3, 3};\n-  ASSERT_EQ(dst, expected);\n+  ASSERT_THAT(dst, ElementsAre(3, 3, 3, 3));\n   ASSERT_EQ(custom_kernel.ToString(),\n             \"AddI32 grid: [4, 1, 1] threads: [1, 1, 1] cluster: [2, 1, 1] \"\n             \"shared_memory: 16 bytes\");\n }\n+\n+TEST(PtxCustomKernelTest, GetOwnedPtxCustomKernel) {\n+  std::string kAddI32KernelPtx = R\"(\n+.version 4.0\n+.target sm_50\n+.address_size 64\n+\n+.visible .entry AddI32(\n+        .param .u64 AddI32_param_0,\n+        .param .u64 AddI32_param_1,\n+        .param .u64 AddI32_param_2\n+)\n+{\n+        .reg .b32       %r<8>;\n+        .reg .b64       %rd<11>;\n+        .loc    1 1 0\n+\n+        ld.param.u64    %rd1, [AddI32_param_0];\n+        ld.param.u64    %rd2, [AddI32_param_1];\n+        ld.param.u64    %rd3, [AddI32_param_2];\n+        .loc    1 3 3\n+        cvta.to.global.u64      %rd4, %rd3;\n+        cvta.to.global.u64      %rd5, %rd2;\n+        cvta.to.global.u64      %rd6, %rd1;\n+        mov.u32         %r1, %tid.x;\n+        mov.u32         %r2, %ctaid.x;\n+        mov.u32         %r3, %ntid.x;\n+        mad.lo.s32      %r4, %r2, %r3, %r1;\n+        .loc    1 4 3\n+        mul.wide.s32    %rd7, %r4, 4;\n+        add.s64         %rd8, %rd6, %rd7;\n+        ld.global.u32   %r5, [%rd8];\n+        add.s64         %rd9, %rd5, %rd7;\n+        ld.global.u32   %r6, [%rd9];\n+        add.s32         %r7, %r6, %r5;\n+        add.s64         %rd10, %rd4, %rd7;\n+        st.global.u32   [%rd10], %r7;\n+        .loc    1 5 1\n+        ret;\n+\n+})\";\n+  int64_t length = 4;\n+  int64_t byte_length = sizeof(int32_t) * length;\n+  se::gpu::CudaPlatform platform;\n+  TF_ASSERT_OK_AND_ASSIGN(se::StreamExecutor * executor,\n+                          platform.ExecutorForDevice(0));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      CustomKernel custom_kernel,\n+      GetOwnedPtxCustomKernel(\"AddI32\", kAddI32KernelPtx, 3, se::BlockDim(4),\n+                              se::ThreadDim(1), byte_length));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<se::Kernel> kernel,\n+                          executor->LoadKernel(custom_kernel.kernel_spec()));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<se::Stream> stream,\n+                          executor->CreateStream());\n+  se::DeviceMemory<int32_t> a = executor->AllocateArray<int32_t>(length, 0);\n+  se::DeviceMemory<int32_t> b = executor->AllocateArray<int32_t>(length, 0);\n+  se::DeviceMemory<int32_t> c = executor->AllocateArray<int32_t>(length, 0);\n+  TF_CHECK_OK(stream->Memset32(&a, 1, byte_length));\n+  TF_CHECK_OK(stream->Memset32(&b, 2, byte_length));\n+  TF_CHECK_OK(stream->MemZero(&c, byte_length));\n+\n+  se::KernelArgsDeviceMemoryArray args(\n+      std::vector<se::DeviceMemoryBase>({a, b, c}),\n+      custom_kernel.shared_memory_bytes());\n+  TF_CHECK_OK(kernel->Launch(custom_kernel.thread_dims(),\n+                             custom_kernel.block_dims(), stream.get(), args));\n+\n+  TF_CHECK_OK(stream->BlockHostUntilDone());\n+\n+  std::vector<int32_t> dst(4, 42);\n+  TF_CHECK_OK(stream->Memcpy(dst.data(), c, byte_length));\n+\n+  ASSERT_THAT(dst, ElementsAre(3, 3, 3, 3));\n+}\n+\n+}  // namespace\n }  // namespace xla::gpu::kernel"
        },
        {
            "sha": "07c2b6fa978f529e48c981b1869e2155cf20e8b2",
            "filename": "third_party/xla/xla/service/gpu/tests/BUILD",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -980,3 +980,20 @@ xla_test(\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )\n+\n+xla_test(\n+    name = \"ptx_kernel_test\",\n+    srcs = [\"ptx_kernel_test.cc\"],\n+    backends = [\"gpu\"],\n+    tags = [\n+        \"cuda-only\",\n+        \"test_migrated_to_hlo_runner_pjrt\",\n+    ],\n+    deps = [\n+        \"//xla:literal\",\n+        \"//xla/tests:hlo_pjrt_test_base\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)"
        },
        {
            "sha": "e8f4611ee770a5510bb62dda8761b4502b982bca",
            "filename": "third_party/xla/xla/service/gpu/tests/ptx_kernel_test.cc",
            "status": "added",
            "additions": 147,
            "deletions": 0,
            "changes": 147,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fptx_kernel_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fptx_kernel_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fptx_kernel_test.cc?ref=471b0ec2729a89b5c9cd55f46f857fdb5ff6b56c",
            "patch": "@@ -0,0 +1,147 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <utility>\n+\n+#include <gtest/gtest.h>\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/literal.h\"\n+#include \"xla/tests/hlo_pjrt_test_base.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla {\n+namespace gpu {\n+namespace {\n+\n+class PtxKernelE2ETest : public HloPjRtTestBase {};\n+\n+TEST_F(PtxKernelE2ETest, ScalarAdd) {\n+  absl::string_view module_str = R\"(\n+    HloModule ptx_test\n+\n+    ENTRY main {\n+      a = f32[] constant(3.0)\n+      b = f32[] constant(4.0)\n+      ROOT out = f32[] custom-call(a, b),\n+        custom_call_target=\"__gpu$xla.gpu.ptx\",\n+        backend_config=\"{\n+          name = \\\"add_kernel\\\",\n+          kernel_type = \\\"ptx\\\",\n+          kernel_data = \\\".version 7.0\\\\n.target sm_70\\\\n.address_size 64\\\\n\\\\n.visible .entry add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 input_b,\\\\n    .param .u64 output)\\\\n{\\\\n  .reg .f32 a, b, c;\\\\n  .reg .u64 addr_a, addr_b, addr_out;\\\\n  \\\\n  ld.param.u64 addr_a, [input_a];\\\\n  ld.param.u64 addr_b, [input_b];\\\\n  ld.param.u64 addr_out, [output];\\\\n  \\\\n  ld.global.f32 a, [addr_a];\\\\n  ld.global.f32 b, [addr_b];\\\\n  add.f32 c, a, b;\\\\n  st.global.f32 [addr_out], c;\\\\n  \\\\n  ret;\\\\n}\\\",\n+          grid_x = 1, grid_y = 1, grid_z = 1,\n+          block_x = 1, block_y = 1, block_z = 1,\n+          shared_mem_bytes = 0,\n+          output_indices = [2]\n+        }\"\n+    })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(module_str));\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Execute(std::move(module), {}));\n+  EXPECT_EQ(result.Get<float>({}), 7.0f);\n+}\n+\n+TEST_F(PtxKernelE2ETest, TensorAdd) {\n+  absl::string_view module_str = R\"(\n+    HloModule ptx_tensor_test\n+\n+    ENTRY main {\n+      a = f32[4] constant({1.0, 2.0, 3.0, 4.0})\n+      b = f32[4] constant({5.0, 6.0, 7.0, 8.0})\n+      ROOT out = f32[4] custom-call(a, b),\n+        custom_call_target=\"__gpu$xla.gpu.ptx\",\n+        backend_config=\"{\n+          name = \\\"tensor_add_kernel\\\",\n+          kernel_type = \\\"ptx\\\",\n+          kernel_data = \\\".version 7.0\\\\n.target sm_70\\\\n.address_size 64\\\\n\\\\n.visible .entry tensor_add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 input_b,\\\\n    .param .u64 output)\\\\n{\\\\n  // Get base pointers\\\\n  .reg .u64 a_base, b_base, out_base;\\\\n  ld.param.u64 a_base, [input_a];\\\\n  ld.param.u64 b_base, [input_b];\\\\n  ld.param.u64 out_base, [output];\\\\n  \\\\n  // Thread ID calculation - just use thread ID directly for this simple case\\\\n  .reg .u32 tid;\\\\n  mov.u32 tid, %tid.x;\\\\n  \\\\n  // Hard-coded array size = 4\\\\n  .reg .pred p;\\\\n  setp.ge.u32 p, tid, 4;\\\\n  @p bra done;\\\\n  \\\\n  // Calculate byte offset (4 bytes per float)\\\\n  .reg .u64 offset;\\\\n  cvt.u64.u32 offset, tid;  // Convert tid to 64-bit\\\\n  mul.lo.u64 offset, offset, 4;  // Each float is 4 bytes\\\\n  \\\\n  // Calculate element addresses\\\\n  .reg .u64 a_addr, b_addr, out_addr;\\\\n  add.u64 a_addr, a_base, offset;\\\\n  add.u64 b_addr, b_base, offset;\\\\n  add.u64 out_addr, out_base, offset;\\\\n  \\\\n  // Load input values\\\\n  .reg .f32 a_val, b_val, result;\\\\n  ld.global.f32 a_val, [a_addr];\\\\n  ld.global.f32 b_val, [b_addr];\\\\n  \\\\n  // Perform addition\\\\n  add.f32 result, a_val, b_val;\\\\n  \\\\n  // Store result\\\\n  st.global.f32 [out_addr], result;\\\\n  \\\\ndone:\\\\n  ret;\\\\n}\\\",\n+          grid_x = 1, grid_y = 1, grid_z = 1,\n+          block_x = 4, block_y = 1, block_z = 1,\n+          shared_mem_bytes = 0,\n+          output_indices = [2]\n+        }\"\n+    })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(module_str));\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Execute(std::move(module), {}));\n+\n+  EXPECT_EQ(result.Get<float>({0}), 6.0f);\n+  EXPECT_EQ(result.Get<float>({1}), 8.0f);\n+  EXPECT_EQ(result.Get<float>({2}), 10.0f);\n+  EXPECT_EQ(result.Get<float>({3}), 12.0f);\n+}\n+\n+TEST_F(PtxKernelE2ETest, TensorAddWithoutOutputIndices) {\n+  absl::string_view module_str = R\"(\n+    HloModule ptx_tensor_test\n+\n+    ENTRY main {\n+      a = f32[4] constant({1.0, 2.0, 3.0, 4.0})\n+      b = f32[4] constant({5.0, 6.0, 7.0, 8.0})\n+      ROOT out = f32[4] custom-call(a, b),\n+        custom_call_target=\"__gpu$xla.gpu.ptx\",\n+        backend_config=\"{\n+          name = \\\"tensor_add_kernel\\\",\n+          kernel_type = \\\"ptx\\\",\n+          kernel_data = \\\".version 7.0\\\\n.target sm_70\\\\n.address_size 64\\\\n\\\\n.visible .entry tensor_add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 input_b,\\\\n    .param .u64 output)\\\\n{\\\\n  // Get base pointers\\\\n  .reg .u64 a_base, b_base, out_base;\\\\n  ld.param.u64 a_base, [input_a];\\\\n  ld.param.u64 b_base, [input_b];\\\\n  ld.param.u64 out_base, [output];\\\\n  \\\\n  // Thread ID calculation - just use thread ID directly for this simple case\\\\n  .reg .u32 tid;\\\\n  mov.u32 tid, %tid.x;\\\\n  \\\\n  // Hard-coded array size = 4\\\\n  .reg .pred p;\\\\n  setp.ge.u32 p, tid, 4;\\\\n  @p bra done;\\\\n  \\\\n  // Calculate byte offset (4 bytes per float)\\\\n  .reg .u64 offset;\\\\n  cvt.u64.u32 offset, tid;  // Convert tid to 64-bit\\\\n  mul.lo.u64 offset, offset, 4;  // Each float is 4 bytes\\\\n  \\\\n  // Calculate element addresses\\\\n  .reg .u64 a_addr, b_addr, out_addr;\\\\n  add.u64 a_addr, a_base, offset;\\\\n  add.u64 b_addr, b_base, offset;\\\\n  add.u64 out_addr, out_base, offset;\\\\n  \\\\n  // Load input values\\\\n  .reg .f32 a_val, b_val, result;\\\\n  ld.global.f32 a_val, [a_addr];\\\\n  ld.global.f32 b_val, [b_addr];\\\\n  \\\\n  // Perform addition\\\\n  add.f32 result, a_val, b_val;\\\\n  \\\\n  // Store result\\\\n  st.global.f32 [out_addr], result;\\\\n  \\\\ndone:\\\\n  ret;\\\\n}\\\",\n+          grid_x = 1, grid_y = 1, grid_z = 1,\n+          block_x = 4, block_y = 1, block_z = 1,\n+          shared_mem_bytes = 0\n+        }\"\n+    })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(module_str));\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Execute(std::move(module), {}));\n+\n+  EXPECT_EQ(result.Get<float>({0}), 6.0f);\n+  EXPECT_EQ(result.Get<float>({1}), 8.0f);\n+  EXPECT_EQ(result.Get<float>({2}), 10.0f);\n+  EXPECT_EQ(result.Get<float>({3}), 12.0f);\n+}\n+\n+TEST_F(PtxKernelE2ETest, TensorAddWithNonTrivialOutputIndices) {\n+  absl::string_view module_str = R\"(\n+    HloModule ptx_tensor_test\n+\n+    ENTRY main {\n+      a = f32[4] constant({1.0, 2.0, 3.0, 4.0})\n+      b = f32[4] constant({5.0, 6.0, 7.0, 8.0})\n+      ROOT out = f32[4] custom-call(a, b),\n+        custom_call_target=\"__gpu$xla.gpu.ptx\",\n+        backend_config=\"{\n+          name = \\\"tensor_add_kernel\\\",\n+          kernel_type = \\\"ptx\\\",\n+          kernel_data = \\\".version 7.0\\\\n.target sm_70\\\\n.address_size 64\\\\n\\\\n.visible .entry tensor_add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 output,\\\\n    .param .u64 input_b\\\\n    )\\\\n{\\\\n  // Get base pointers\\\\n  .reg .u64 a_base, b_base, out_base;\\\\n  ld.param.u64 a_base, [input_a];\\\\n  ld.param.u64 out_base, [output];\\\\n  ld.param.u64 b_base, [input_b];\\\\n  \\\\n  // Thread ID calculation - just use thread ID directly for this simple case\\\\n  .reg .u32 tid;\\\\n  mov.u32 tid, %tid.x;\\\\n  \\\\n  // Hard-coded array size = 4\\\\n  .reg .pred p;\\\\n  setp.ge.u32 p, tid, 4;\\\\n  @p bra done;\\\\n  \\\\n  // Calculate byte offset (4 bytes per float)\\\\n  .reg .u64 offset;\\\\n  cvt.u64.u32 offset, tid;  // Convert tid to 64-bit\\\\n  mul.lo.u64 offset, offset, 4;  // Each float is 4 bytes\\\\n  \\\\n  // Calculate element addresses\\\\n  .reg .u64 a_addr, b_addr, out_addr;\\\\n  add.u64 a_addr, a_base, offset;\\\\n  add.u64 b_addr, b_base, offset;\\\\n  add.u64 out_addr, out_base, offset;\\\\n  \\\\n  // Load input values\\\\n  .reg .f32 a_val, b_val, result;\\\\n  ld.global.f32 a_val, [a_addr];\\\\n  ld.global.f32 b_val, [b_addr];\\\\n  \\\\n  // Perform addition\\\\n  add.f32 result, a_val, b_val;\\\\n  \\\\n  // Store result\\\\n  st.global.f32 [out_addr], result;\\\\n  \\\\ndone:\\\\n  ret;\\\\n}\\\",\n+          grid_x = 1, grid_y = 1, grid_z = 1,\n+          block_x = 4, block_y = 1, block_z = 1,\n+          shared_mem_bytes = 0,\n+          output_indices = [1]\n+        }\"\n+    })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(module_str));\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Execute(std::move(module), {}));\n+\n+  EXPECT_EQ(result.Get<float>({0}), 6.0f);\n+  EXPECT_EQ(result.Get<float>({1}), 8.0f);\n+  EXPECT_EQ(result.Get<float>({2}), 10.0f);\n+  EXPECT_EQ(result.Get<float>({3}), 12.0f);\n+}\n+\n+}  // namespace\n+}  // namespace gpu\n+}  // namespace xla"
        }
    ],
    "stats": {
        "total": 1326,
        "additions": 1303,
        "deletions": 23
    }
}