{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 812274883",
    "sha": "31184fd418517308ab240d7e2e6387fa0b8a492b",
    "files": [
        {
            "sha": "4b750408547e711107f27e9e5e96eb6b3eb30886",
            "filename": "third_party/xla/xla/service/gpu/transforms/priority_fusion.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 18,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/31184fd418517308ab240d7e2e6387fa0b8a492b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/31184fd418517308ab240d7e2e6387fa0b8a492b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc?ref=31184fd418517308ab240d7e2e6387fa0b8a492b",
            "patch": "@@ -279,7 +279,7 @@ class PriorityFusionQueue {\n \n   std::optional<HloInstruction*> GetPreferredConsumer(\n       HloInstruction* producer) {\n-    absl::MutexLock lock(&preferred_consumer_mutex_);\n+    absl::MutexLock lock(preferred_consumer_mutex_);\n     auto it = preferred_consumer_.find(producer);\n     if (it == preferred_consumer_.end()) {\n       return std::nullopt;\n@@ -355,7 +355,7 @@ class PriorityFusionQueue {\n     }\n \n     {\n-      absl::MutexLock lock(&block_level_parameters_cache_mutex_);\n+      absl::MutexLock lock(block_level_parameters_cache_mutex_);\n       block_level_parameters_cache_.erase(instruction);\n       for (const HloInstruction* operand : instruction->operands()) {\n         auto it = block_level_parameters_cache_.find(operand);\n@@ -421,12 +421,12 @@ class PriorityFusionQueue {\n                            int64_t original_consumer_unique_id) {\n     bool creates_multi_output_fusion = false;\n     {\n-      absl::MutexLock lock(&preferred_consumer_mutex_);\n+      absl::MutexLock lock(preferred_consumer_mutex_);\n       creates_multi_output_fusion =\n           preferred_consumer_.contains(original_producer);\n     }\n     {\n-      absl::MutexLock lock(&fusion_deduplication_cache_mutex_);\n+      absl::MutexLock lock(fusion_deduplication_cache_mutex_);\n       fusion_deduplication_cache_.UpdateFusedInstructionId(\n           fusion, original_producer, original_consumer,\n           original_consumer_operand_index, creates_multi_output_fusion);\n@@ -453,7 +453,7 @@ class PriorityFusionQueue {\n     if (fusion == original_consumer) {\n       // We need to check again whether we can use `original_consumer` as a\n       // producer for a ProducerConsumer multi-output fusion.\n-      absl::MutexLock lock(&preferred_consumer_mutex_);\n+      absl::MutexLock lock(preferred_consumer_mutex_);\n       preferred_consumer_.erase(original_consumer);\n     } else {\n       // The original consumer was replaced with the fusion, but it's pointer\n@@ -491,7 +491,7 @@ class PriorityFusionQueue {\n \n       // We may need to reset `preferred_consumer_`, as we don't know yet\n       // whether that fusion would still be valid.\n-      absl::MutexLock lock(&preferred_consumer_mutex_);\n+      absl::MutexLock lock(preferred_consumer_mutex_);\n       auto it = preferred_consumer_.find(operand);\n       if (it != preferred_consumer_.end() && it->second == original_consumer) {\n         preferred_consumer_.erase(it);\n@@ -514,15 +514,15 @@ class PriorityFusionQueue {\n     }\n     producer_priority_queue_.erase(reverse_it->second);\n     reverse_map_.erase(reverse_it);\n-    absl::MutexLock lock(&preferred_consumer_mutex_);\n+    absl::MutexLock lock(preferred_consumer_mutex_);\n     preferred_consumer_.erase(instruction);\n   }\n \n   // Returns a map from consumer to BlockLevelParameters. This is used to\n   // determine if a producer-consumer fusion is a Triton fusion.\n   absl::flat_hash_map<const HloInstruction*, BlockLevelParameters>\n   GetBlockLevelParametersMap(const HloInstruction* producer) {\n-    absl::MutexLock lock(&block_level_parameters_cache_mutex_);\n+    absl::MutexLock lock(block_level_parameters_cache_mutex_);\n     auto it = block_level_parameters_cache_.find(producer);\n     if (it == block_level_parameters_cache_.end()) {\n       return {};\n@@ -543,7 +543,7 @@ class PriorityFusionQueue {\n     // First cleanup any potentially remaining preferred consumer. We will\n     // recompute it here.\n     {\n-      absl::MutexLock lock(&preferred_consumer_mutex_);\n+      absl::MutexLock lock(preferred_consumer_mutex_);\n       preferred_consumer_.erase(producer);\n     }\n     // Bitcasts should always be fused first, since they are no-ops.\n@@ -569,13 +569,13 @@ class PriorityFusionQueue {\n             gpu_performance_model_.EstimateRunTimes(\n                 producer, &cost_analysis_,\n                 /*fused_consumers=*/possible_consumers);\n-        absl::MutexLock lock(&preferred_consumer_mutex_);\n+        absl::MutexLock lock(preferred_consumer_mutex_);\n         preferred_consumer_[producer] = possible_consumers[0];\n         return run_times.time_unfused - run_times.time_fused;\n       }\n       // Don't fuse if we can't fuse in all users.\n       if (fusion_process_dump_) {\n-        absl::MutexLock lock(&fusion_process_dump_mutex_);\n+        absl::MutexLock lock(fusion_process_dump_mutex_);\n         auto* step = fusion_process_dump_->add_fusion_steps()\n                          ->mutable_producer_ineligible();\n         step->set_producer_name(producer->name());\n@@ -611,7 +611,7 @@ class PriorityFusionQueue {\n     }\n \n     if (fusion_process_dump_) {\n-      absl::MutexLock lock(&fusion_process_dump_mutex_);\n+      absl::MutexLock lock(fusion_process_dump_mutex_);\n       auto* step =\n           fusion_process_dump_->add_fusion_steps()->mutable_update_priority();\n       step->set_producer_name(producer->name());\n@@ -650,13 +650,13 @@ class PriorityFusionQueue {\n       const HloInstruction* producer, const HloInstruction* consumer,\n       bool use_multi_output_fusion = false) {\n     FusionDeduplicationCache::FusionId fusion_id = [&]() {\n-      absl::MutexLock lock(&fusion_deduplication_cache_mutex_);\n+      absl::MutexLock lock(fusion_deduplication_cache_mutex_);\n       return fusion_deduplication_cache_.GetFusionId(producer, consumer,\n                                                      use_multi_output_fusion);\n     }();\n \n     {\n-      absl::MutexLock lock(&tiled_run_time_data_cache_mutex_);\n+      absl::MutexLock lock(tiled_run_time_data_cache_mutex_);\n \n       auto it = tiled_run_time_data_cache_.find(fusion_id);\n       if (it != tiled_run_time_data_cache_.end()) {\n@@ -690,7 +690,7 @@ class PriorityFusionQueue {\n                        fusion_decision->Explain()));\n     }\n \n-    absl::MutexLock lock(&tiled_run_time_data_cache_mutex_);\n+    absl::MutexLock lock(tiled_run_time_data_cache_mutex_);\n     tiled_run_time_data_cache_.emplace(fusion_id, tiled_run_time_data_or_error);\n     return tiled_run_time_data_or_error;\n   }\n@@ -751,7 +751,7 @@ class PriorityFusionQueue {\n     gpu_performance_model_cache_.Set(\n         *producer, *consumer, tiled_run_time_data.runtime_data.exec_time);\n     {\n-      absl::MutexLock lock(&block_level_parameters_cache_mutex_);\n+      absl::MutexLock lock(block_level_parameters_cache_mutex_);\n       block_level_parameters_cache_[producer][consumer] =\n           tiled_run_time_data.block_level_parameters;\n     }\n@@ -867,7 +867,7 @@ class PriorityFusionQueue {\n   FusionDecision CanFuseCached(HloInstruction* producer,\n                                HloInstruction* consumer) {\n     {\n-      absl::MutexLock lock(&can_fuse_cache_mutex_);\n+      absl::MutexLock lock(can_fuse_cache_mutex_);\n       auto& producer_cache = can_fuse_cache_[producer];\n \n       auto it = producer_cache.find(consumer);\n@@ -882,7 +882,7 @@ class PriorityFusionQueue {\n     // concurrently for the same producer, so it's guaranteed that we don't\n     // override any value.\n     {\n-      absl::MutexLock lock(&can_fuse_cache_mutex_);\n+      absl::MutexLock lock(can_fuse_cache_mutex_);\n       can_fuse_cache_[producer].insert_or_assign(consumer, fusion_decision);\n     }\n "
        }
    ],
    "stats": {
        "total": 36,
        "additions": 18,
        "deletions": 18
    }
}