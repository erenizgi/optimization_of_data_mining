{
    "author": "tensorflower-gardener",
    "message": "Integrate LLVM at llvm/llvm-project@14c00c05c13a\n\nUpdates LLVM usage to match\n[14c00c05c13a](https://github.com/llvm/llvm-project/commit/14c00c05c13a)\n\nPiperOrigin-RevId: 850765800",
    "sha": "eab591b778ab3400d835d0417562a9c692673f81",
    "files": [
        {
            "sha": "d3f5351523355b3293730165fdb3e1de1d73182b",
            "filename": "third_party/xla/third_party/llvm/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/eab591b778ab3400d835d0417562a9c692673f81/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/eab591b778ab3400d835d0417562a9c692673f81/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl?ref=eab591b778ab3400d835d0417562a9c692673f81",
            "patch": "@@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n \n def repo(name):\n     \"\"\"Imports LLVM.\"\"\"\n-    LLVM_COMMIT = \"3ecf4d2ebfb8f84cffb42ff6c220ecdb3d5acbce\"\n-    LLVM_SHA256 = \"205e48cd5a7212ddcb65485c4dbe1dd9aaeafd0fa614d4a87b84eee5967bf84e\"\n+    LLVM_COMMIT = \"14c00c05c13af8fa5c56852dce958b4259935fa8\"\n+    LLVM_SHA256 = \"5831226924cd42e9fb535becd04ca7c2f2aa4049f2877b45c80248c6e1429477\"\n \n     tf_http_archive(\n         name = name,"
        },
        {
            "sha": "d818713467dabb798ddaa9c24790e922b7d743d3",
            "filename": "third_party/xla/third_party/shardy/temporary.patch",
            "status": "modified",
            "additions": 5,
            "deletions": 1804,
            "changes": 1809,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/eab591b778ab3400d835d0417562a9c692673f81/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/eab591b778ab3400d835d0417562a9c692673f81/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch?ref=eab591b778ab3400d835d0417562a9c692673f81",
            "patch": "@@ -1,1814 +1,15 @@\n-diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch\n-index 7972fe3..509398d 100644\n---- a/third_party/llvm/generated.patch\n-+++ b/third_party/llvm/generated.patch\n-@@ -1,1794 +1 @@\n- Auto generated patch. Do not edit or delete it, even if empty.\n--diff -ruN --strip-trailing-cr a/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h b/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\n----- a/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\n--+++ b/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\n--@@ -1,122 +0,0 @@\n---//===- ACCSpecializePatterns.h - Common ACC Specialization Patterns ------===//\n---//\n---// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n---// See https://llvm.org/LICENSE.txt for license information.\n---// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n---//\n---//===----------------------------------------------------------------------===//\n---//\n---// This file contains common rewrite pattern templates used by both\n---// ACCSpecializeForHost and ACCSpecializeForDevice passes.\n---//\n---// The patterns provide the following transformations:\n---//\n---// - ACCOpReplaceWithVarConversion<OpTy>: Replaces a data entry operation\n---//   with its var operand. Used for ops like acc.copyin, acc.create, etc.\n---//\n---// - ACCOpEraseConversion<OpTy>: Simply erases an operation. Used for\n---//   data exit ops like acc.copyout, acc.delete, and runtime ops.\n---//\n---// - ACCRegionUnwrapConversion<OpTy>: Inlines the region of an operation\n---//   and erases the wrapper. Used for structured data constructs\n---//   (acc.data, acc.host_data) and compute constructs (acc.parallel, etc.)\n---//\n---// - ACCDeclareEnterOpConversion: Erases acc.declare_enter and its\n---//   associated acc.declare_exit operation.\n---//\n---//===----------------------------------------------------------------------===//\n---\n---#ifndef MLIR_DIALECT_OPENACC_TRANSFORMS_ACCSPECIALIZEPATTERNS_H\n---#define MLIR_DIALECT_OPENACC_TRANSFORMS_ACCSPECIALIZEPATTERNS_H\n---\n---#include \"mlir/Dialect/OpenACC/OpenACC.h\"\n---#include \"mlir/IR/PatternMatch.h\"\n---\n---namespace mlir {\n---namespace acc {\n---\n---//===----------------------------------------------------------------------===//\n---// Generic pattern templates for ACC specialization\n---//===----------------------------------------------------------------------===//\n---\n---/// Pattern to replace an ACC op with its var operand.\n---/// Used for data entry ops like acc.copyin, acc.create, acc.attach, etc.\n---template <typename OpTy>\n---class ACCOpReplaceWithVarConversion : public OpRewritePattern<OpTy> {\n---  using OpRewritePattern<OpTy>::OpRewritePattern;\n---\n---public:\n---  LogicalResult matchAndRewrite(OpTy op,\n---                                PatternRewriter &rewriter) const override {\n---    // Replace this op with its var operand; it's possible the op has no uses\n---    // if the op that had previously used it was already converted.\n---    if (op->use_empty())\n---      rewriter.eraseOp(op);\n---    else\n---      rewriter.replaceOp(op, op.getVar());\n---    return success();\n---  }\n---};\n---\n---/// Pattern to simply erase an ACC op (for ops with no results).\n---/// Used for data exit ops like acc.copyout, acc.delete, acc.detach, etc.\n---template <typename OpTy>\n---class ACCOpEraseConversion : public OpRewritePattern<OpTy> {\n---  using OpRewritePattern<OpTy>::OpRewritePattern;\n---\n---public:\n---  LogicalResult matchAndRewrite(OpTy op,\n---                                PatternRewriter &rewriter) const override {\n---    assert(op->getNumResults() == 0 && \"expected op with no results\");\n---    rewriter.eraseOp(op);\n---    return success();\n---  }\n---};\n---\n---/// Pattern to unwrap a region from an ACC op and erase the wrapper.\n---/// Moves the region's contents to the parent block and removes the wrapper op.\n---/// Used for structured data constructs (acc.data, acc.host_data,\n---/// acc.kernel_environment, acc.declare) and compute constructs (acc.parallel,\n---/// acc.serial, acc.kernels).\n---template <typename OpTy>\n---class ACCRegionUnwrapConversion : public OpRewritePattern<OpTy> {\n---  using OpRewritePattern<OpTy>::OpRewritePattern;\n---\n---public:\n---  LogicalResult matchAndRewrite(OpTy op,\n---                                PatternRewriter &rewriter) const override {\n---    assert(op.getRegion().hasOneBlock() && \"expected one block\");\n---    Block *block = &op.getRegion().front();\n---    // Erase the terminator (acc.yield or acc.terminator) before unwrapping\n---    rewriter.eraseOp(block->getTerminator());\n---    rewriter.inlineBlockBefore(block, op);\n---    rewriter.eraseOp(op);\n---    return success();\n---  }\n---};\n---\n---/// Pattern to erase acc.declare_enter and its associated acc.declare_exit.\n---/// The declare_enter produces a token that is consumed by declare_exit.\n---class ACCDeclareEnterOpConversion\n---    : public OpRewritePattern<acc::DeclareEnterOp> {\n---  using OpRewritePattern<acc::DeclareEnterOp>::OpRewritePattern;\n---\n---public:\n---  LogicalResult matchAndRewrite(acc::DeclareEnterOp op,\n---                                PatternRewriter &rewriter) const override {\n---    // If the enter token is used by an exit, erase exit first.\n---    if (!op->use_empty()) {\n---      assert(op->hasOneUse() && \"expected one use\");\n---      auto exitOp = dyn_cast<acc::DeclareExitOp>(*op->getUsers().begin());\n---      assert(exitOp && \"expected declare exit op\");\n---      rewriter.eraseOp(exitOp);\n---    }\n---    rewriter.eraseOp(op);\n---    return success();\n---  }\n---};\n---\n---} // namespace acc\n---} // namespace mlir\n---\n---#endif // MLIR_DIALECT_OPENACC_TRANSFORMS_ACCSPECIALIZEPATTERNS_H\n--diff -ruN --strip-trailing-cr a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h\n----- a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h\n--+++ b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h\n--@@ -12,7 +12,6 @@\n-- #include \"mlir/Dialect/Arith/IR/Arith.h\"\n-- #include \"mlir/Dialect/MemRef/IR/MemRef.h\"\n-- #include \"mlir/Dialect/OpenACC/OpenACC.h\"\n---#include \"mlir/Dialect/SCF/IR/SCF.h\"\n-- #include \"mlir/Pass/Pass.h\"\n-- \n-- namespace mlir {\n--@@ -23,40 +22,9 @@\n-- \n-- namespace acc {\n-- \n---class OpenACCSupport;\n---\n-- #define GEN_PASS_DECL\n-- #include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n-- \n---//===----------------------------------------------------------------------===//\n---// ACCSpecializeForDevice patterns\n---//===----------------------------------------------------------------------===//\n---\n---/// Populates all patterns for device specialization.\n---/// In specialized device code (such as specialized acc routine), many ACC\n---/// operations do not make sense because they are host-side constructs. This\n---/// function adds patterns to remove or transform them.\n---void populateACCSpecializeForDevicePatterns(RewritePatternSet &patterns);\n---\n---//===----------------------------------------------------------------------===//\n---// ACCSpecializeForHost patterns\n---//===----------------------------------------------------------------------===//\n---\n---/// Populates patterns for converting orphan ACC operations to host.\n---/// All patterns check that the operation is NOT inside or associated with a\n---/// compute region before converting.\n---/// @param enableLoopConversion Whether to convert orphan acc.loop operations.\n---void populateACCOrphanToHostPatterns(RewritePatternSet &patterns,\n---                                     OpenACCSupport &accSupport,\n---                                     bool enableLoopConversion = true);\n---\n---/// Populates all patterns for host fallback path (when `if` clause evaluates\n---/// to false). In this mode, ALL ACC operations should be converted or removed.\n---/// @param enableLoopConversion Whether to convert orphan acc.loop operations.\n---void populateACCHostFallbackPatterns(RewritePatternSet &patterns,\n---                                     OpenACCSupport &accSupport,\n---                                     bool enableLoopConversion = true);\n---\n-- /// Generate the code for registering conversion passes.\n-- #define GEN_PASS_REGISTRATION\n-- #include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n--diff -ruN --strip-trailing-cr a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td\n----- a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td\n--+++ b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td\n--@@ -194,62 +194,4 @@\n--   ];\n-- }\n-- \n---def ACCSpecializeForDevice : Pass<\"acc-specialize-for-device\", \"mlir::func::FuncOp\"> {\n---  let summary = \"Strip OpenACC constructs inside device code\";\n---  let description = [{\n---    In a specialized acc routine or compute construct, many OpenACC operations\n---    do not make sense because they are host-side constructs. This pass removes\n---    or transforms these operations appropriately.\n---\n---    The following operations are handled:\n---    - Data entry ops (replaced with var): acc.attach, acc.copyin, acc.create,\n---      acc.declare_device_resident, acc.declare_link, acc.deviceptr,\n---      acc.get_deviceptr, acc.nocreate, acc.present, acc.update_device,\n---      acc.use_device\n---    - Data exit ops (erased): acc.copyout, acc.delete, acc.detach,\n---      acc.update_host\n---    - Structured data (inline region): acc.data, acc.host_data,\n---      acc.kernel_environment\n---    - Unstructured data (erased): acc.enter_data, acc.exit_data, acc.update,\n---      acc.declare_enter, acc.declare_exit\n---    - Compute constructs (inline region): acc.parallel, acc.serial, acc.kernels\n---    - Runtime ops (erased): acc.init, acc.shutdown, acc.set, acc.wait\n---  }];\n---  let dependentDialects = [\"mlir::acc::OpenACCDialect\"];\n---}\n---\n---def ACCSpecializeForHost : Pass<\"acc-specialize-for-host\", \"mlir::func::FuncOp\"> {\n---  let summary = \"Convert OpenACC operations for host execution\";\n---  let description = [{\n---    This pass converts OpenACC operations to host-compatible representations.\n---    It serves as a conversion pass that transforms ACC constructs to enable\n---    execution on the host rather than on accelerator devices.\n---\n---    There are two modes of operation:\n---\n---    1. Default mode (orphan operations only): Only orphan operations that are\n---       not allowed outside compute regions are converted. Structured/unstructured\n---       data constructs, compute constructs, and their associated data operations\n---       are NOT removed.\n---\n---    2. Host fallback mode (enableHostFallback=true): ALL ACC operations within\n---       the region are converted to host equivalents. This is used when the `if`\n---       clause evaluates to false at runtime.\n---\n---    The following operations are handled:\n---    - Atomic ops: converted to load/store operations\n---    - Loop ops: converted to scf.for or scf.execute_region\n---    - Data entry ops (orphan): replaced with var operand\n---    - In host fallback mode: all data, compute, and runtime ops are removed\n---  }];\n---  let dependentDialects = [\"mlir::acc::OpenACCDialect\",\n---      \"mlir::scf::SCFDialect\"];\n---  let options = [\n---    Option<\"enableHostFallback\", \"enable-host-fallback\", \"bool\", \"false\",\n---           \"Enable host fallback mode which converts ALL ACC operations, \"\n---           \"not just orphan operations. Use this when the `if` clause \"\n---           \"evaluates to false.\">\n---  ];\n---}\n---\n-- #endif // MLIR_DIALECT_OPENACC_TRANSFORMS_PASSES\n--diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp\n----- a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp\n--+++ b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp\n--@@ -1,172 +0,0 @@\n---//===- ACCSpecializeForDevice.cpp -----------------------------------------===//\n---//\n---// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n---// See https://llvm.org/LICENSE.txt for license information.\n---// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n---//\n---//===----------------------------------------------------------------------===//\n---//\n---// This pass strips OpenACC constructs that are invalid or unnecessary inside\n---// device code (specialized acc routines or compute construct regions).\n---//\n---// Overview:\n---// ---------\n---// In a specialized acc routine or compute construct, many OpenACC operations\n---// do not make sense because they are host-side constructs. This pass removes\n---// or transforms these operations appropriately:\n---//\n---// - Data operations that manage device memory from host perspective\n---// - Compute constructs that launch kernels (we're already on device)\n---// - Runtime operations like init/shutdown/set/wait\n---//\n---// Transformations:\n---// ----------------\n---// The pass applies the following transformations:\n---//\n---// 1. Data Entry Ops (replaced with var operand):\n---//    acc.attach, acc.copyin, acc.create, acc.declare_device_resident,\n---//    acc.declare_link, acc.deviceptr, acc.get_deviceptr, acc.nocreate,\n---//    acc.present, acc.update_device, acc.use_device\n---//\n---// 2. Data Exit Ops (erased):\n---//    acc.copyout, acc.delete, acc.detach, acc.update_host\n---//\n---// 3. Structured Data/Compute Constructs (region inlined):\n---//    acc.data, acc.host_data, acc.kernel_environment, acc.parallel,\n---//    acc.serial, acc.kernels\n---//\n---// 4. Unstructured Data Ops (erased):\n---//    acc.enter_data, acc.exit_data, acc.update, acc.declare_enter,\n---//    acc.declare_exit\n---//\n---// 5. Runtime Ops (erased):\n---//    acc.init, acc.shutdown, acc.set, acc.wait\n---//\n---// Scope of Application:\n---// ---------------------\n---// - For functions with `acc.specialized_routine` attribute: patterns are\n---//   applied to the entire function body.\n---// - For non-specialized functions: patterns are applied only to ACC\n---//   operations INSIDE compute constructs (parallel, serial, kernels),\n---//   not to the compute constructs themselves or their data operands.\n---//\n---// Note: acc.cache, acc.private, acc.reduction, acc.firstprivate are NOT\n---// transformed by this pass as they are valid in device code.\n---//\n---//===----------------------------------------------------------------------===//\n---\n---#include \"mlir/Dialect/OpenACC/Transforms/Passes.h\"\n---\n---#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n---#include \"mlir/Dialect/OpenACC/OpenACC.h\"\n---#include \"mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\"\n---#include \"mlir/IR/PatternMatch.h\"\n---#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n---\n---namespace mlir {\n---namespace acc {\n---#define GEN_PASS_DEF_ACCSPECIALIZEFORDEVICE\n---#include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n---} // namespace acc\n---} // namespace mlir\n---\n---using namespace mlir;\n---using namespace mlir::acc;\n---\n---namespace {\n---\n---class ACCSpecializeForDevice\n---    : public acc::impl::ACCSpecializeForDeviceBase<ACCSpecializeForDevice> {\n---public:\n---  using ACCSpecializeForDeviceBase<\n---      ACCSpecializeForDevice>::ACCSpecializeForDeviceBase;\n---\n---  void runOnOperation() override {\n---    func::FuncOp func = getOperation();\n---\n---    RewritePatternSet patterns(&getContext());\n---    acc::populateACCSpecializeForDevicePatterns(patterns);\n---    GreedyRewriteConfig config;\n---    config.setUseTopDownTraversal(true);\n---\n---    if (acc::isSpecializedAccRoutine(func)) {\n---      // For specialized acc routines, apply patterns to the entire function\n---      (void)applyPatternsGreedily(func, std::move(patterns), config);\n---    } else {\n---      // For non-specialized functions, apply patterns only to ACC operations\n---      // inside compute constructs (not to the compute constructs themselves).\n---      SmallVector<Operation *> opsToTransform;\n---      func.walk([&](Operation *op) {\n---        if (isa<ACC_COMPUTE_CONSTRUCT_OPS>(op)) {\n---          // Walk inside the compute construct and collect ACC ops\n---          op->walk([&](Operation *innerOp) {\n---            // Skip the compute construct itself\n---            if (innerOp == op)\n---              return;\n---            if (isa<acc::OpenACCDialect>(innerOp->getDialect()))\n---              opsToTransform.push_back(innerOp);\n---          });\n---        }\n---      });\n---      if (!opsToTransform.empty())\n---        (void)applyOpPatternsGreedily(opsToTransform, std::move(patterns),\n---                                      config);\n---    }\n---  }\n---};\n---\n---} // namespace\n---\n---//===----------------------------------------------------------------------===//\n---// Pattern population functions\n---//===----------------------------------------------------------------------===//\n---\n---void mlir::acc::populateACCSpecializeForDevicePatterns(\n---    RewritePatternSet &patterns) {\n---  MLIRContext *context = patterns.getContext();\n---\n---  // Declare patterns - erase declare_enter and its associated declare_exit\n---  patterns.insert<ACCDeclareEnterOpConversion>(context);\n---\n---  // Data entry ops - replaced with their var operand\n---  // Note: acc.cache, acc.private, acc.reduction, acc.firstprivate are NOT\n---  // included here - they are valid in device code\n---  patterns.insert<ACCOpReplaceWithVarConversion<acc::AttachOp>,\n---                  ACCOpReplaceWithVarConversion<acc::CopyinOp>,\n---                  ACCOpReplaceWithVarConversion<acc::CreateOp>,\n---                  ACCOpReplaceWithVarConversion<acc::DeclareDeviceResidentOp>,\n---                  ACCOpReplaceWithVarConversion<acc::DeclareLinkOp>,\n---                  ACCOpReplaceWithVarConversion<acc::DevicePtrOp>,\n---                  ACCOpReplaceWithVarConversion<acc::GetDevicePtrOp>,\n---                  ACCOpReplaceWithVarConversion<acc::NoCreateOp>,\n---                  ACCOpReplaceWithVarConversion<acc::PresentOp>,\n---                  ACCOpReplaceWithVarConversion<acc::UpdateDeviceOp>,\n---                  ACCOpReplaceWithVarConversion<acc::UseDeviceOp>>(context);\n---\n---  // Data exit ops - simply erased (no results)\n---  patterns.insert<ACCOpEraseConversion<acc::CopyoutOp>,\n---                  ACCOpEraseConversion<acc::DeleteOp>,\n---                  ACCOpEraseConversion<acc::DetachOp>,\n---                  ACCOpEraseConversion<acc::UpdateHostOp>>(context);\n---\n---  // Structured data constructs - unwrap their regions\n---  patterns.insert<ACCRegionUnwrapConversion<acc::DataOp>,\n---                  ACCRegionUnwrapConversion<acc::HostDataOp>,\n---                  ACCRegionUnwrapConversion<acc::KernelEnvironmentOp>>(context);\n---\n---  // Compute constructs - unwrap their regions\n---  patterns.insert<ACCRegionUnwrapConversion<acc::ParallelOp>,\n---                  ACCRegionUnwrapConversion<acc::SerialOp>,\n---                  ACCRegionUnwrapConversion<acc::KernelsOp>>(context);\n---\n---  // Unstructured data operations - erase them\n---  patterns.insert<ACCOpEraseConversion<acc::EnterDataOp>,\n---                  ACCOpEraseConversion<acc::ExitDataOp>,\n---                  ACCOpEraseConversion<acc::UpdateOp>>(context);\n---\n---  // Runtime operations - erase them\n---  patterns.insert<\n---      ACCOpEraseConversion<acc::InitOp>, ACCOpEraseConversion<acc::ShutdownOp>,\n---      ACCOpEraseConversion<acc::SetOp>, ACCOpEraseConversion<acc::WaitOp>>(\n---      context);\n---}\n--diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp\n----- a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp\n--+++ b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp\n--@@ -1,471 +0,0 @@\n---//===- ACCSpecializeForHost.cpp -------------------------------------------===//\n---//\n---// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n---// See https://llvm.org/LICENSE.txt for license information.\n---// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n---//\n---//===----------------------------------------------------------------------===//\n---//\n---// This pass converts OpenACC operations to host-compatible representations,\n---// enabling execution on the host rather than on accelerator devices.\n---//\n---// Overview:\n---// ---------\n---// The pass operates in two modes depending on the `enableHostFallback` option:\n---//\n---// 1. Default Mode (Orphan Operations Only):\n---//    Only converts \"orphan\" ACC operations that are not inside or attached to\n---//    compute regions. This is used for host routines (acc routine marked for\n---//    host) where structured/unstructured data constructs, compute constructs,\n---//    and their associated data operations should be preserved.\n---//\n---// 2. Host Fallback Mode (enableHostFallback=true):\n---//    Converts ALL ACC operations within the region to host equivalents. This\n---//    is used when the `if` clause evaluates to false at runtime and the\n---//    entire ACC region needs to fall back to host execution.\n---//\n---// Transformations (Orphan Mode):\n---// ------------------------------\n---// The following orphan operations are converted:\n---//\n---// 1. Atomic Ops (converted to load/store):\n---//    acc.atomic.update -> load + compute + store\n---//    acc.atomic.read -> load + store (copy)\n---//    acc.atomic.write -> store\n---//    acc.atomic.capture -> inline region contents\n---//\n---// 2. Loop Ops (converted to SCF):\n---//    acc.loop (structured) -> scf.for\n---//    acc.loop (unstructured) -> scf.execute_region\n---//\n---// 3. Orphan Data Entry Ops (replaced with var operand):\n---//    acc.cache, acc.private, acc.firstprivate, acc.reduction\n---//    (only if NOT connected to compute constructs or loop)\n---//\n---// Transformations (Host Fallback Mode):\n---// -------------------------------------\n---// In addition to orphan transformations, ALL of the following are converted:\n---//\n---// 1. Data Entry Ops (replaced with var operand):\n---//    acc.copyin, acc.create, acc.attach, acc.present, acc.deviceptr,\n---//    acc.get_deviceptr, acc.nocreate, acc.declare_device_resident,\n---//    acc.declare_link, acc.use_device, acc.update_device\n---//\n---// 2. Data Exit Ops (erased):\n---//    acc.copyout, acc.delete, acc.detach, acc.update_host\n---//\n---// 3. Structured Data/Compute Constructs (region inlined):\n---//    acc.data, acc.host_data, acc.kernel_environment, acc.declare,\n---//    acc.parallel, acc.serial, acc.kernels\n---//\n---// 4. Unstructured Data Ops (erased):\n---//    acc.enter_data, acc.exit_data, acc.update\n---//\n---// 5. Declare Ops (erased):\n---//    acc.declare_enter, acc.declare_exit\n---//\n---// 6. Runtime Ops (erased):\n---//    acc.init, acc.shutdown, acc.set, acc.wait, acc.terminator\n---//\n---// Requirements:\n---// -------------\n---// For atomic operation conversion, variables must implement the\n---// `acc::PointerLikeType` interface to enable generating load/store operations.\n---//\n---// The pass uses `OpenACCSupport::emitNYI()` to report unsupported cases.\n---//\n---//===----------------------------------------------------------------------===//\n---\n---#include \"mlir/Dialect/OpenACC/Transforms/Passes.h\"\n---\n---#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n---#include \"mlir/Dialect/OpenACC/Analysis/OpenACCSupport.h\"\n---#include \"mlir/Dialect/OpenACC/OpenACC.h\"\n---#include \"mlir/Dialect/OpenACC/OpenACCUtilsLoop.h\"\n---#include \"mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\"\n---#include \"mlir/IR/BuiltinAttributes.h\"\n---#include \"mlir/IR/BuiltinOps.h\"\n---#include \"mlir/IR/BuiltinTypes.h\"\n---#include \"mlir/IR/Operation.h\"\n---#include \"mlir/IR/PatternMatch.h\"\n---#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n---\n---namespace mlir {\n---namespace acc {\n---#define GEN_PASS_DEF_ACCSPECIALIZEFORHOST\n---#include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n---} // namespace acc\n---} // namespace mlir\n---\n---#define DEBUG_TYPE \"acc-specialize-for-host\"\n---\n---using namespace mlir;\n---using namespace mlir::acc;\n---\n---/// Check if an operation is inside an ACC compute construct.\n---static bool isInsideACCComputeConstruct(Operation *op) {\n---  while ((op = op->getParentOp()))\n---    if (isa<ACC_COMPUTE_CONSTRUCT_OPS>(op))\n---      return true;\n---  return false;\n---}\n---\n---namespace {\n---\n---// Lower orphan acc.atomic.update by: load from addr, clone region expr with\n---// the loaded value, then store the computed result back to addr.\n---// Only matches if NOT inside a compute region.\n---class ACCOrphanAtomicUpdateOpConversion\n---    : public OpRewritePattern<acc::AtomicUpdateOp> {\n---public:\n---  ACCOrphanAtomicUpdateOpConversion(MLIRContext *ctx, OpenACCSupport &support)\n---      : OpRewritePattern<acc::AtomicUpdateOp>(ctx), accSupport(support) {}\n---\n---  LogicalResult matchAndRewrite(acc::AtomicUpdateOp atomicUpdateOp,\n---                                PatternRewriter &rewriter) const override {\n---    // Only convert if this op is not inside an ACC compute construct\n---    if (isInsideACCComputeConstruct(atomicUpdateOp))\n---      return failure();\n---\n---    Value x = atomicUpdateOp.getX();\n---    Type type = x.getType();\n---    auto ptrLikeType = dyn_cast<acc::PointerLikeType>(type);\n---    if (ptrLikeType) {\n---      auto xTyped = cast<TypedValue<acc::PointerLikeType>>(x);\n---      rewriter.setInsertionPointAfter(atomicUpdateOp);\n---      Value loadOp =\n---          ptrLikeType.genLoad(rewriter, atomicUpdateOp.getLoc(), xTyped, {});\n---      if (!loadOp) {\n---        accSupport.emitNYI(atomicUpdateOp.getLoc(),\n---                           \"failed to generate load for atomic update\");\n---        return failure();\n---      }\n---      IRMapping mapping;\n---      mapping.map(atomicUpdateOp.getRegion().front().getArgument(0), loadOp);\n---      Operation *expr = rewriter.clone(*atomicUpdateOp.getFirstOp(), mapping);\n---      if (!ptrLikeType.genStore(rewriter, atomicUpdateOp.getLoc(),\n---                                expr->getResult(0), xTyped)) {\n---        accSupport.emitNYI(atomicUpdateOp.getLoc(),\n---                           \"failed to generate store for atomic update\");\n---        return failure();\n---      }\n---      rewriter.eraseOp(atomicUpdateOp);\n---    } else {\n---      accSupport.emitNYI(atomicUpdateOp.getLoc(),\n---                         \"unsupported type for atomic update\");\n---      return failure();\n---    }\n---    return success();\n---  }\n---\n---private:\n---  OpenACCSupport &accSupport;\n---};\n---\n---// Lower orphan acc.atomic.read by: load from src, then store into dst.\n---// Only matches if NOT inside an ACC compute construct.\n---class ACCOrphanAtomicReadOpConversion\n---    : public OpRewritePattern<acc::AtomicReadOp> {\n---public:\n---  ACCOrphanAtomicReadOpConversion(MLIRContext *ctx, OpenACCSupport &support)\n---      : OpRewritePattern<acc::AtomicReadOp>(ctx), accSupport(support) {}\n---\n---  LogicalResult matchAndRewrite(acc::AtomicReadOp readOp,\n---                                PatternRewriter &rewriter) const override {\n---    // Only convert if this op is not inside an ACC compute construct\n---    if (isInsideACCComputeConstruct(readOp))\n---      return failure();\n---\n---    Value x = readOp.getX();\n---    Value v = readOp.getV();\n---    auto xPtrType = dyn_cast<acc::PointerLikeType>(x.getType());\n---    auto vPtrType = dyn_cast<acc::PointerLikeType>(v.getType());\n---    if (xPtrType && vPtrType) {\n---      auto xTyped = cast<TypedValue<acc::PointerLikeType>>(x);\n---      auto vTyped = cast<TypedValue<acc::PointerLikeType>>(v);\n---      rewriter.setInsertionPointAfter(readOp);\n---\n---      // Use genCopy which does load + store\n---      if (!xPtrType.genCopy(rewriter, readOp.getLoc(), vTyped, xTyped, {})) {\n---        accSupport.emitNYI(readOp.getLoc(),\n---                           \"failed to generate copy for atomic read\");\n---        return failure();\n---      }\n---      rewriter.eraseOp(readOp);\n---    } else {\n---      accSupport.emitNYI(readOp.getLoc(), \"unsupported type for atomic read\");\n---      return failure();\n---    }\n---    return success();\n---  }\n---\n---private:\n---  OpenACCSupport &accSupport;\n---};\n---\n---// Lower orphan acc.atomic.write by: store value into addr.\n---// Only matches if NOT inside an ACC compute construct.\n---class ACCOrphanAtomicWriteOpConversion\n---    : public OpRewritePattern<acc::AtomicWriteOp> {\n---public:\n---  ACCOrphanAtomicWriteOpConversion(MLIRContext *ctx, OpenACCSupport &support)\n---      : OpRewritePattern<acc::AtomicWriteOp>(ctx), accSupport(support) {}\n---\n---  LogicalResult matchAndRewrite(acc::AtomicWriteOp writeOp,\n---                                PatternRewriter &rewriter) const override {\n---    // Only convert if this op is not inside an ACC compute construct\n---    if (isInsideACCComputeConstruct(writeOp))\n---      return failure();\n---\n---    Value x = writeOp.getX();\n---    Value expr = writeOp.getExpr();\n---    auto ptrLikeType = dyn_cast<acc::PointerLikeType>(x.getType());\n---    if (ptrLikeType) {\n---      auto xTyped = cast<TypedValue<acc::PointerLikeType>>(x);\n---      rewriter.setInsertionPointAfter(writeOp);\n---      if (!ptrLikeType.genStore(rewriter, writeOp.getLoc(), expr, xTyped)) {\n---        accSupport.emitNYI(writeOp.getLoc(),\n---                           \"failed to generate store for atomic write\");\n---        return failure();\n---      }\n---      rewriter.eraseOp(writeOp);\n---    } else {\n---      accSupport.emitNYI(writeOp.getLoc(), \"unsupported type for atomic write\");\n---      return failure();\n---    }\n---    return success();\n---  }\n---\n---private:\n---  OpenACCSupport &accSupport;\n---};\n---\n---// Lower orphan acc.atomic.capture by: unwrap the capture region and erase the\n---// wrapper; inner ops are lowered in-order (e.g., read+update becomes load/store\n---// to dst then load/compute/store to addr).\n---// Only matches if NOT inside an ACC compute construct.\n---class ACCOrphanAtomicCaptureOpConversion\n---    : public OpRewritePattern<acc::AtomicCaptureOp> {\n---  using OpRewritePattern<acc::AtomicCaptureOp>::OpRewritePattern;\n---\n---  LogicalResult matchAndRewrite(acc::AtomicCaptureOp captureOp,\n---                                PatternRewriter &rewriter) const override {\n---    // Only convert if this op is not inside an ACC compute construct\n---    if (isInsideACCComputeConstruct(captureOp))\n---      return failure();\n---\n---    assert(captureOp.getRegion().hasOneBlock() && \"expected one block\");\n---    Block *block = &captureOp.getRegion().front();\n---    // Remove the terminator before inlining\n---    rewriter.eraseOp(block->getTerminator());\n---    rewriter.inlineBlockBefore(block, captureOp);\n---    rewriter.eraseOp(captureOp);\n---    return success();\n---  }\n---};\n---\n---// Convert orphan acc.loop to scf.for or scf.execute_region.\n---// Only matches if NOT inside an ACC compute construct.\n---class ACCOrphanLoopOpConversion : public OpRewritePattern<acc::LoopOp> {\n---  using OpRewritePattern<acc::LoopOp>::OpRewritePattern;\n---\n---  LogicalResult matchAndRewrite(acc::LoopOp loopOp,\n---                                PatternRewriter &rewriter) const override {\n---    // Only convert if this op is not inside an ACC compute construct\n---    if (isInsideACCComputeConstruct(loopOp))\n---      return failure();\n---\n---    if (loopOp.getUnstructured()) {\n---      auto executeRegion =\n---          acc::convertUnstructuredACCLoopToSCFExecuteRegion(loopOp, rewriter);\n---      if (!executeRegion)\n---        return failure();\n---      rewriter.replaceOp(loopOp, executeRegion);\n---    } else {\n---      auto forOp =\n---          acc::convertACCLoopToSCFFor(loopOp, /*enableCollapse=*/false);\n---      if (!forOp)\n---        return failure();\n---      rewriter.replaceOp(loopOp, forOp);\n---    }\n---    return success();\n---  }\n---};\n---\n---/// Check if an operation is used by a compute construct or loop op\n---static bool isUsedByComputeOrLoop(Operation *op) {\n---  for (auto *user : op->getUsers())\n---    if (isa<acc::ParallelOp, acc::SerialOp, acc::KernelsOp, acc::LoopOp>(user))\n---      return true;\n---  return false;\n---}\n---\n---/// Orphan data entry ops - only match if NOT connected to compute/loop and\n---/// NOT inside a compute region. Used for acc.cache, acc.private,\n---/// acc.firstprivate, acc.reduction.\n---template <typename OpTy>\n---class ACCOrphanDataEntryConversion : public OpRewritePattern<OpTy> {\n---  using OpRewritePattern<OpTy>::OpRewritePattern;\n---\n---  LogicalResult matchAndRewrite(OpTy op,\n---                                PatternRewriter &rewriter) const override {\n---    // Only convert if this op is not used by a compute construct or loop,\n---    // and not inside an ACC compute construct.\n---    if (isUsedByComputeOrLoop(op) || isInsideACCComputeConstruct(op))\n---      return failure();\n---\n---    if (op->use_empty())\n---      rewriter.eraseOp(op);\n---    else\n---      rewriter.replaceOp(op, op.getVar());\n---    return success();\n---  }\n---};\n---\n---class ACCSpecializeForHost\n---    : public acc::impl::ACCSpecializeForHostBase<ACCSpecializeForHost> {\n---public:\n---  using ACCSpecializeForHostBase<\n---      ACCSpecializeForHost>::ACCSpecializeForHostBase;\n---\n---  void runOnOperation() override {\n---    LLVM_DEBUG(llvm::dbgs() << \"Enter ACCSpecializeForHost()\\n\");\n---\n---    func::FuncOp funcOp = getOperation();\n---    if (!acc::isSpecializedAccRoutine(funcOp)) {\n---      // Convert orphan operations to host, or all ACC operations if\n---      // host fallback patterns are enabled.\n---      auto *context = &getContext();\n---      RewritePatternSet patterns(context);\n---      OpenACCSupport &accSupport = getAnalysis<OpenACCSupport>();\n---      if (enableHostFallback)\n---        populateACCHostFallbackPatterns(patterns, accSupport);\n---      else\n---        populateACCOrphanToHostPatterns(patterns, accSupport);\n---      GreedyRewriteConfig config;\n---      config.setUseTopDownTraversal(true);\n---      if (failed(applyPatternsGreedily(funcOp, std::move(patterns), config)))\n---        signalPassFailure();\n---    }\n---\n---    LLVM_DEBUG(llvm::dbgs() << \"Exit ACCSpecializeForHost()\\n\");\n---  }\n---};\n---} // namespace\n---\n---//===----------------------------------------------------------------------===//\n---// Pattern population functions\n---//===----------------------------------------------------------------------===//\n---\n---void mlir::acc::populateACCOrphanToHostPatterns(RewritePatternSet &patterns,\n---                                                OpenACCSupport &accSupport,\n---                                                bool enableLoopConversion) {\n---  MLIRContext *context = patterns.getContext();\n---\n---  // For host routines (acc routine marked for host), we only convert orphan\n---  // operations that are not allowed outside compute regions. All patterns\n---  // here check that the operation is NOT inside a compute region before\n---  // converting:\n---  // - acc.atomic.* -> load/store operations\n---  // - acc.loop -> scf.for or scf.execute_region\n---  // - acc.cache -> replaced with var\n---  // - acc.private, acc.reduction, acc.firstprivate -> replaced with var\n---  //   (only if NOT connected to compute constructs or loop)\n---  //\n---  // We do NOT remove structured/unstructured data constructs, compute\n---  // constructs, or their associated data operations - those are valid\n---  // in host routines and will be processed by other passes.\n---\n---  // Loop conversion (orphan only)\n---  if (enableLoopConversion)\n---    patterns.insert<ACCOrphanLoopOpConversion>(context);\n---\n---  // Atomic operations - convert to non-atomic load/store (orphan only)\n---  patterns.insert<ACCOrphanAtomicUpdateOpConversion>(context, accSupport);\n---  patterns.insert<ACCOrphanAtomicReadOpConversion>(context, accSupport);\n---  patterns.insert<ACCOrphanAtomicWriteOpConversion>(context, accSupport);\n---  patterns.insert<ACCOrphanAtomicCaptureOpConversion>(context);\n---\n---  // Orphan data entry ops - only convert if NOT connected to compute/loop\n---  // and NOT inside a compute region\n---  patterns.insert<ACCOrphanDataEntryConversion<acc::CacheOp>,\n---                  ACCOrphanDataEntryConversion<acc::PrivateOp>,\n---                  ACCOrphanDataEntryConversion<acc::FirstprivateOp>,\n---                  ACCOrphanDataEntryConversion<acc::ReductionOp>>(context);\n---}\n---\n---void mlir::acc::populateACCHostFallbackPatterns(RewritePatternSet &patterns,\n---                                                OpenACCSupport &accSupport,\n---                                                bool enableLoopConversion) {\n---  MLIRContext *context = patterns.getContext();\n---\n---  // For host fallback path (when `if` clause evaluates to false), ALL ACC\n---  // operations within the region should be converted to host equivalents.\n---  // This includes structured/unstructured data, compute constructs, and\n---  // their associated data operations.\n---\n---  // Loop conversion - OK to use the orphan loop conversion pattern here\n---  // because the parent compute constructs will also be converted.\n---  if (enableLoopConversion)\n---    patterns.insert<ACCOrphanLoopOpConversion>(context);\n---\n---  // Atomic operations - convert to non-atomic load/store. OK to use the orphan\n---  // atomic conversion patterns here because the parent compute constructs will\n---  // also be converted.\n---  patterns.insert<ACCOrphanAtomicUpdateOpConversion>(context, accSupport);\n---  patterns.insert<ACCOrphanAtomicReadOpConversion>(context, accSupport);\n---  patterns.insert<ACCOrphanAtomicWriteOpConversion>(context, accSupport);\n---  patterns.insert<ACCOrphanAtomicCaptureOpConversion>(context);\n---\n---  // acc.cache - convert ALL cache ops (including those inside compute regions)\n---  patterns.insert<ACCOpReplaceWithVarConversion<acc::CacheOp>>(context);\n---\n---  // Privatization ops - convert ALL (including those attached to compute/loop)\n---  patterns.insert<ACCOpReplaceWithVarConversion<acc::PrivateOp>,\n---                  ACCOpReplaceWithVarConversion<acc::FirstprivateOp>,\n---                  ACCOpReplaceWithVarConversion<acc::ReductionOp>>(context);\n---\n---  // Data entry ops - replaced with their var operand\n---  patterns.insert<ACCOpReplaceWithVarConversion<acc::CopyinOp>,\n---                  ACCOpReplaceWithVarConversion<acc::CreateOp>,\n---                  ACCOpReplaceWithVarConversion<acc::AttachOp>,\n---                  ACCOpReplaceWithVarConversion<acc::PresentOp>,\n---                  ACCOpReplaceWithVarConversion<acc::DevicePtrOp>,\n---                  ACCOpReplaceWithVarConversion<acc::GetDevicePtrOp>,\n---                  ACCOpReplaceWithVarConversion<acc::NoCreateOp>,\n---                  ACCOpReplaceWithVarConversion<acc::DeclareDeviceResidentOp>,\n---                  ACCOpReplaceWithVarConversion<acc::DeclareLinkOp>,\n---                  ACCOpReplaceWithVarConversion<acc::UseDeviceOp>,\n---                  ACCOpReplaceWithVarConversion<acc::UpdateDeviceOp>>(context);\n---\n---  // Data exit ops - simply erased (no results)\n---  patterns.insert<ACCOpEraseConversion<acc::CopyoutOp>,\n---                  ACCOpEraseConversion<acc::DeleteOp>,\n---                  ACCOpEraseConversion<acc::DetachOp>,\n---                  ACCOpEraseConversion<acc::UpdateHostOp>>(context);\n---\n---  // Structured data constructs - unwrap their regions\n---  patterns.insert<ACCRegionUnwrapConversion<acc::DataOp>,\n---                  ACCRegionUnwrapConversion<acc::HostDataOp>,\n---                  ACCRegionUnwrapConversion<acc::KernelEnvironmentOp>>(context);\n---\n---  // Declare ops\n---  patterns.insert<ACCDeclareEnterOpConversion,\n---                  ACCRegionUnwrapConversion<acc::DeclareOp>>(context);\n---\n---  // Unstructured data operations - erase them\n---  patterns.insert<ACCOpEraseConversion<acc::EnterDataOp>,\n---                  ACCOpEraseConversion<acc::ExitDataOp>,\n---                  ACCOpEraseConversion<acc::UpdateOp>>(context);\n---\n---  // Runtime operations - erase them\n---  patterns.insert<\n---      ACCOpEraseConversion<acc::InitOp>, ACCOpEraseConversion<acc::ShutdownOp>,\n---      ACCOpEraseConversion<acc::SetOp>, ACCOpEraseConversion<acc::WaitOp>,\n---      ACCOpEraseConversion<acc::TerminatorOp>>(context);\n---\n---  // Compute constructs - unwrap their regions\n---  patterns.insert<ACCRegionUnwrapConversion<acc::ParallelOp>,\n---                  ACCRegionUnwrapConversion<acc::SerialOp>,\n---                  ACCRegionUnwrapConversion<acc::KernelsOp>>(context);\n---}\n--diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt b/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt\n----- a/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt\n--+++ b/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt\n--@@ -4,8 +4,6 @@\n--   ACCImplicitDeclare.cpp\n--   ACCImplicitRoutine.cpp\n--   ACCLegalizeSerial.cpp\n---  ACCSpecializeForDevice.cpp\n---  ACCSpecializeForHost.cpp\n--   LegalizeDataValues.cpp\n-- \n--   ADDITIONAL_HEADER_DIRS\n--@@ -28,7 +26,6 @@\n--   MLIRFuncDialect\n--   MLIRIR\n--   MLIRPass\n---  MLIRSCFDialect\n--   MLIRSupport\n--   MLIRTransforms\n-- )\n--diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp b/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp\n----- a/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp\n--+++ b/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp\n--@@ -31,27 +31,6 @@\n--   }\n-- };\n-- \n---struct CollapseShapeOpInterface\n---    : public ValueBoundsOpInterface::ExternalModel<CollapseShapeOpInterface,\n---                                                   CollapseShapeOp> {\n---  void populateBoundsForShapedValueDim(Operation *op, Value value, int64_t dim,\n---                                       ValueBoundsConstraintSet &cstr) const {\n---    auto collapseOp = cast<CollapseShapeOp>(op);\n---    assert(value == collapseOp.getResult() && \"invalid value\");\n---\n---    // Multiply the expressions for the dimensions in the reassociation group.\n---    const ReassociationIndices &reassocIndices =\n---        collapseOp.getReassociationIndices()[dim];\n---    AffineExpr productExpr =\n---        cstr.getExpr(collapseOp.getSrc(), reassocIndices[0]);\n---    for (size_t i = 1; i < reassocIndices.size(); ++i) {\n---      productExpr =\n---          productExpr * cstr.getExpr(collapseOp.getSrc(), reassocIndices[i]);\n---    }\n---    cstr.bound(value)[dim] == productExpr;\n---  }\n---};\n---\n-- struct DimOpInterface\n--     : public ValueBoundsOpInterface::ExternalModel<DimOpInterface, DimOp> {\n--   void populateBoundsForIndexValue(Operation *op, Value value,\n--@@ -78,17 +57,6 @@\n--   }\n-- };\n-- \n---struct ExpandShapeOpInterface\n---    : public ValueBoundsOpInterface::ExternalModel<ExpandShapeOpInterface,\n---                                                   ExpandShapeOp> {\n---  void populateBoundsForShapedValueDim(Operation *op, Value value, int64_t dim,\n---                                       ValueBoundsConstraintSet &cstr) const {\n---    auto expandOp = cast<ExpandShapeOp>(op);\n---    assert(value == expandOp.getResult() && \"invalid value\");\n---    cstr.bound(value)[dim] == expandOp.getMixedOutputShape()[dim];\n---  }\n---};\n---\n-- struct ExtractSliceOpInterface\n--     : public ValueBoundsOpInterface::ExternalModel<ExtractSliceOpInterface,\n--                                                    ExtractSliceOp> {\n--@@ -149,12 +117,8 @@\n--     DialectRegistry &registry) {\n--   registry.addExtension(+[](MLIRContext *ctx, tensor::TensorDialect *dialect) {\n--     tensor::CastOp::attachInterface<tensor::CastOpInterface>(*ctx);\n---    tensor::CollapseShapeOp::attachInterface<tensor::CollapseShapeOpInterface>(\n---        *ctx);\n--     tensor::DimOp::attachInterface<tensor::DimOpInterface>(*ctx);\n--     tensor::EmptyOp::attachInterface<tensor::EmptyOpInterface>(*ctx);\n---    tensor::ExpandShapeOp::attachInterface<tensor::ExpandShapeOpInterface>(\n---        *ctx);\n--     tensor::ExtractSliceOp::attachInterface<tensor::ExtractSliceOpInterface>(\n--         *ctx);\n--     tensor::PadOp::attachInterface<tensor::PadOpInterface>(*ctx);\n--diff -ruN --strip-trailing-cr a/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir b/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir\n----- a/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir\n--+++ b/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir\n--@@ -1,204 +0,0 @@\n---// RUN: mlir-opt %s -acc-specialize-for-device | FileCheck %s\n---\n---//===----------------------------------------------------------------------===//\n---// Data entry ops in specialized routines\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_0 func(@attach) seq\n---// CHECK-LABEL: func.func @attach\n---// CHECK-NOT:   acc.attach\n---func.func @attach(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_0, <seq>, \"attach\">} {\n---  %c0 = arith.constant 0 : i32\n---  %0 = acc.attach varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  memref.store %c0, %0[] : memref<i32>\n---  return\n---}\n---\n---acc.routine @acc_routine_1 func(@copyin) seq\n---// CHECK-LABEL: func.func @copyin\n---// CHECK-NOT:   acc.copyin\n---func.func @copyin(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_1, <seq>, \"copyin\">} {\n---  %c0 = arith.constant 0 : i32\n---  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  memref.store %c0, %0[] : memref<i32>\n---  return\n---}\n---\n---acc.routine @acc_routine_2 func(@create) seq\n---// CHECK-LABEL: func.func @create\n---// CHECK-NOT:   acc.create\n---func.func @create(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_2, <seq>, \"create\">} {\n---  %c0 = arith.constant 0 : i32\n---  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  memref.store %c0, %0[] : memref<i32>\n---  return\n---}\n---\n---acc.routine @acc_routine_3 func(@present) seq\n---// CHECK-LABEL: func.func @present\n---// CHECK-NOT:   acc.present\n---func.func @present(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_3, <seq>, \"present\">} {\n---  %c0 = arith.constant 0 : i32\n---  %0 = acc.present varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  memref.store %c0, %0[] : memref<i32>\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Data entry ops INSIDE compute constructs (non-specialized functions)\n---//===----------------------------------------------------------------------===//\n---\n---// CHECK-LABEL: func.func @copyin_inside_parallel\n---// CHECK:       acc.parallel\n---// CHECK-NOT:   acc.copyin\n---// CHECK:       acc.yield\n---func.func @copyin_inside_parallel(%arg0 : memref<i32>) {\n---  %c0 = arith.constant 0 : i32\n---  acc.parallel {\n---    %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n---    memref.store %c0, %0[] : memref<i32>\n---    acc.yield\n---  }\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Data entry ops OUTSIDE compute constructs should NOT be removed\n---//===----------------------------------------------------------------------===//\n---\n---// CHECK-LABEL: func.func @copyin_outside_parallel\n---// CHECK:       acc.copyin\n---// CHECK:       acc.parallel\n---func.func @copyin_outside_parallel(%arg0 : memref<i32>) {\n---  %c0 = arith.constant 0 : i32\n---  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  acc.parallel dataOperands(%0 : memref<i32>) {\n---    memref.store %c0, %0[] : memref<i32>\n---    acc.yield\n---  }\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Data exit ops in specialized routines\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_copyout func(@copyout) worker\n---// CHECK-LABEL: func.func @copyout\n---// CHECK-NOT:   acc.copyout\n---func.func @copyout(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_copyout, <worker>, \"copyout\">} {\n---  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  acc.copyout accPtr(%0 : memref<i32>) to varPtr(%arg0 : memref<i32>)\n---  return\n---}\n---\n---acc.routine @acc_routine_delete func(@delete) worker\n---// CHECK-LABEL: func.func @delete\n---// CHECK-NOT:   acc.delete\n---func.func @delete(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_delete, <worker>, \"delete\">} {\n---  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  acc.delete accPtr(%0 : memref<i32>)\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Erase ops (unstructured data and runtime ops)\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_enter_data func(@enter_data) worker\n---// CHECK-LABEL: func.func @enter_data\n---// CHECK-NOT:   acc.enter_data\n---func.func @enter_data(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_enter_data, <worker>, \"enter_data\">} {\n---  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  acc.enter_data dataOperands(%0 : memref<i32>)\n---  return\n---}\n---\n---acc.routine @acc_routine_init func(@init_op) worker\n---// CHECK-LABEL: func.func @init_op\n---// CHECK-NOT:   acc.init\n---func.func @init_op() attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_init, <worker>, \"init_op\">} {\n---  acc.init\n---  return\n---}\n---\n---acc.routine @acc_routine_wait func(@wait_op) worker\n---// CHECK-LABEL: func.func @wait_op\n---// CHECK-NOT:   acc.wait\n---func.func @wait_op() attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_wait, <worker>, \"wait_op\">} {\n---  acc.wait\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Region unwrap (structured data and compute constructs)\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_data func(@data_construct) worker\n---// CHECK-LABEL: func.func @data_construct\n---// CHECK-NOT:   acc.data\n---// CHECK:       arith.constant 42\n---func.func @data_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_data, <worker>, \"data_construct\">} {\n---  %d = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  acc.data dataOperands(%d : memref<i32>) {\n---    %c42 = arith.constant 42 : i32\n---    memref.store %c42, %arg0[] : memref<i32>\n---    acc.terminator\n---  }\n---  return\n---}\n---\n---acc.routine @acc_routine_parallel func(@parallel_construct) worker\n---// CHECK-LABEL: func.func @parallel_construct\n---// CHECK-NOT:   acc.parallel\n---// CHECK:       arith.constant 44\n---func.func @parallel_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_parallel, <worker>, \"parallel_construct\">} {\n---  acc.parallel {\n---    %c44 = arith.constant 44 : i32\n---    memref.store %c44, %arg0[] : memref<i32>\n---    acc.yield\n---  }\n---  return\n---}\n---\n---acc.routine @acc_routine_serial func(@serial_construct) worker\n---// CHECK-LABEL: func.func @serial_construct\n---// CHECK-NOT:   acc.serial\n---// CHECK:       arith.constant 45\n---func.func @serial_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_serial, <worker>, \"serial_construct\">} {\n---  acc.serial {\n---    %c45 = arith.constant 45 : i32\n---    memref.store %c45, %arg0[] : memref<i32>\n---    acc.yield\n---  }\n---  return\n---}\n---\n---acc.routine @acc_routine_kernels func(@kernels_construct) worker\n---// CHECK-LABEL: func.func @kernels_construct\n---// CHECK-NOT:   acc.kernels\n---// CHECK:       arith.constant 46\n---func.func @kernels_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_kernels, <worker>, \"kernels_construct\">} {\n---  acc.kernels {\n---    %c46 = arith.constant 46 : i32\n---    memref.store %c46, %arg0[] : memref<i32>\n---    acc.terminator\n---  }\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Declare enter/exit strip in device routines\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_declare func(@dev_routine_declare) worker\n---// CHECK-LABEL: func.func @dev_routine_declare\n---// CHECK-NOT: acc.declare_enter\n---// CHECK-NOT: acc.declare_exit\n---func.func @dev_routine_declare() attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_declare, <worker>, \"dev_routine_declare\">} {\n---  %var = memref.alloca() : memref<f32>\n---  %c = acc.create varPtr(%var : memref<f32>) -> memref<f32>\n---  %t = acc.declare_enter dataOperands(%c : memref<f32>)\n---  acc.declare_exit token(%t) dataOperands(%c : memref<f32>)\n---  return\n---}\n--diff -ruN --strip-trailing-cr a/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir b/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir\n----- a/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir\n--+++ b/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir\n--@@ -1,157 +0,0 @@\n---// RUN: mlir-opt %s --pass-pipeline='builtin.module(func.func(acc-specialize-for-host{enable-host-fallback=true}))' | FileCheck %s\n---\n---//===----------------------------------------------------------------------===//\n---// Data entry ops - replaced with var (host fallback)\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_create func(@create) seq\n---// CHECK-LABEL: func.func @create\n---// CHECK-NOT:   acc.create\n---func.func @create(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_create]>} {\n---  %c0 = arith.constant 0 : i32\n---  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  memref.store %c0, %0[] : memref<i32>\n---  return\n---}\n---\n---acc.routine @acc_routine_copyin func(@copyin) seq\n---// CHECK-LABEL: func.func @copyin\n---// CHECK-NOT:   acc.copyin\n---func.func @copyin(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_copyin]>} {\n---  %c0 = arith.constant 0 : i32\n---  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  memref.store %c0, %0[] : memref<i32>\n---  return\n---}\n---\n---acc.routine @acc_routine_present func(@present) seq\n---// CHECK-LABEL: func.func @present\n---// CHECK-NOT:   acc.present\n---func.func @present(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_present]>} {\n---  %c0 = arith.constant 0 : i32\n---  %0 = acc.present varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  memref.store %c0, %0[] : memref<i32>\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Data exit ops - erased (host fallback)\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_copyout func(@copyout) seq\n---// CHECK-LABEL: func.func @copyout\n---// CHECK-NOT:   acc.copyout\n---func.func @copyout(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_copyout]>} {\n---  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  acc.copyout accPtr(%0 : memref<i32>) to varPtr(%arg0 : memref<i32>)\n---  return\n---}\n---\n---acc.routine @acc_routine_delete func(@delete) seq\n---// CHECK-LABEL: func.func @delete\n---// CHECK-NOT:   acc.delete\n---func.func @delete(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_delete]>} {\n---  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  acc.delete accPtr(%0 : memref<i32>)\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Runtime operations - erased (host fallback)\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_init func(@init_op) seq\n---// CHECK-LABEL: func.func @init_op\n---// CHECK-NOT:   acc.init\n---func.func @init_op() attributes {acc.routine_info = #acc.routine_info<[@acc_routine_init]>} {\n---  acc.init\n---  return\n---}\n---\n---acc.routine @acc_routine_shutdown func(@shutdown_op) seq\n---// CHECK-LABEL: func.func @shutdown_op\n---// CHECK-NOT:   acc.shutdown\n---func.func @shutdown_op() attributes {acc.routine_info = #acc.routine_info<[@acc_routine_shutdown]>} {\n---  acc.shutdown\n---  return\n---}\n---\n---acc.routine @acc_routine_wait func(@wait_op) seq\n---// CHECK-LABEL: func.func @wait_op\n---// CHECK-NOT:   acc.wait\n---func.func @wait_op() attributes {acc.routine_info = #acc.routine_info<[@acc_routine_wait]>} {\n---  acc.wait\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Structured data and compute constructs - unwrap regions (host fallback)\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_data func(@data_construct) seq\n---// CHECK-LABEL: func.func @data_construct\n---// CHECK-NOT:   acc.data\n---// CHECK:       arith.constant 42\n---func.func @data_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_data]>} {\n---  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  acc.data dataOperands(%0 : memref<i32>) {\n---    %c42 = arith.constant 42 : i32\n---    memref.store %c42, %arg0[] : memref<i32>\n---    acc.terminator\n---  }\n---  return\n---}\n---\n---acc.routine @acc_routine_parallel func(@parallel_construct) seq\n---// CHECK-LABEL: func.func @parallel_construct\n---// CHECK-NOT:   acc.parallel\n---// CHECK:       arith.constant 44\n---func.func @parallel_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_parallel]>} {\n---  acc.parallel {\n---    %c44 = arith.constant 44 : i32\n---    memref.store %c44, %arg0[] : memref<i32>\n---    acc.yield\n---  }\n---  return\n---}\n---\n---acc.routine @acc_routine_serial func(@serial_construct) seq\n---// CHECK-LABEL: func.func @serial_construct\n---// CHECK-NOT:   acc.serial\n---// CHECK:       arith.constant 45\n---func.func @serial_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_serial]>} {\n---  acc.serial {\n---    %c45 = arith.constant 45 : i32\n---    memref.store %c45, %arg0[] : memref<i32>\n---    acc.yield\n---  }\n---  return\n---}\n---\n---acc.routine @acc_routine_kernels func(@kernels_construct) seq\n---// CHECK-LABEL: func.func @kernels_construct\n---// CHECK-NOT:   acc.kernels\n---// CHECK:       arith.constant 46\n---func.func @kernels_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_kernels]>} {\n---  acc.kernels {\n---    %c46 = arith.constant 46 : i32\n---    memref.store %c46, %arg0[] : memref<i32>\n---    acc.terminator\n---  }\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Declare enter/exit - erased (host fallback)\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_declare func(@declare_enter_exit) seq\n---// CHECK-LABEL: func.func @declare_enter_exit\n---// CHECK-NOT:   acc.declare_enter\n---// CHECK-NOT:   acc.declare_exit\n---func.func @declare_enter_exit(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_declare]>} {\n---  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  %token = acc.declare_enter dataOperands(%0 : memref<i32>)\n---  acc.declare_exit token(%token) dataOperands(%0 : memref<i32>)\n---  return\n---}\n--diff -ruN --strip-trailing-cr a/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir b/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir\n----- a/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir\n--+++ b/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir\n--@@ -1,404 +0,0 @@\n---// RUN: mlir-opt %s -acc-specialize-for-host | FileCheck %s\n---\n---// Recipe definitions\n---acc.private.recipe @privatization_memref_i32 : memref<i32> init {\n---^bb0(%arg0: memref<i32>):\n---  %0 = memref.alloca() : memref<i32>\n---  acc.yield %0 : memref<i32>\n---}\n---\n---acc.firstprivate.recipe @firstprivatization_memref_i32 : memref<i32> init {\n---^bb0(%arg0: memref<i32>):\n---  %0 = memref.alloca() : memref<i32>\n---  acc.yield %0 : memref<i32>\n---} copy {\n---^bb0(%arg0: memref<i32>, %arg1: memref<i32>):\n---  %0 = memref.load %arg0[] : memref<i32>\n---  memref.store %0, %arg1[] : memref<i32>\n---  acc.terminator\n---}\n---\n---acc.reduction.recipe @reduction_add_memref_i32 : memref<i32> reduction_operator <add> init {\n---^bb0(%arg0: memref<i32>):\n---  %c0_i32 = arith.constant 0 : i32\n---  %0 = memref.alloca() : memref<i32>\n---  memref.store %c0_i32, %0[] : memref<i32>\n---  acc.yield %0 : memref<i32>\n---} combiner {\n---^bb0(%arg0: memref<i32>, %arg1: memref<i32>):\n---  %0 = memref.load %arg0[] : memref<i32>\n---  %1 = memref.load %arg1[] : memref<i32>\n---  %2 = arith.addi %0, %1 : i32\n---  memref.store %2, %arg0[] : memref<i32>\n---  acc.yield %arg0 : memref<i32>\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Orphan data entry ops - replaced with var\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_private func(@private) seq\n---// CHECK-LABEL: func.func @private\n---// CHECK-NOT:   acc.private\n---func.func @private(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_private]>} {\n---  %c0 = arith.constant 0 : i32\n---  %0 = acc.private varPtr(%arg0 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n---  memref.store %c0, %0[] : memref<i32>\n---  return\n---}\n---\n---acc.routine @acc_routine_cache func(@cache) seq\n---// CHECK-LABEL: func.func @cache\n---// CHECK-NOT:   acc.cache\n---func.func @cache(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_cache]>} {\n---  %c0 = arith.constant 0 : i32\n---  %0 = acc.cache varPtr(%arg0 : memref<i32>) -> memref<i32>\n---  memref.store %c0, %0[] : memref<i32>\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Orphan atomic operations - converted to load/store\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_atomic func(@orphan_atomic_update) seq\n---// CHECK-LABEL: func.func @orphan_atomic_update\n---// CHECK-NOT:   acc.atomic.update\n---// CHECK:       memref.load\n---// CHECK:       arith.addi\n---// CHECK:       memref.store\n---func.func @orphan_atomic_update(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic]>} {\n---  acc.atomic.update %arg0 : memref<i32> {\n---  ^bb0(%arg1: i32):\n---    %c1 = arith.constant 1 : i32\n---    %1 = arith.addi %arg1, %c1 : i32\n---    acc.yield %1 : i32\n---  }\n---  return\n---}\n---\n---acc.routine @acc_routine_atomic_read func(@orphan_atomic_read) seq\n---// CHECK-LABEL: func.func @orphan_atomic_read\n---// CHECK-NOT:   acc.atomic.read\n---// CHECK:       memref.copy %arg0, %arg1\n---func.func @orphan_atomic_read(%arg0 : memref<i32>, %arg1 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_read]>} {\n---  acc.atomic.read %arg1 = %arg0 : memref<i32>, memref<i32>, i32\n---  return\n---}\n---\n---acc.routine @acc_routine_atomic_write func(@orphan_atomic_write) seq\n---// CHECK-LABEL: func.func @orphan_atomic_write\n---// CHECK-NOT:   acc.atomic.write\n---// CHECK:       memref.store %arg1, %arg0[]\n---func.func @orphan_atomic_write(%arg0 : memref<i32>, %arg1 : i32) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_write]>} {\n---  acc.atomic.write %arg0 = %arg1 : memref<i32>, i32\n---  return\n---}\n---\n---acc.routine @acc_routine_atomic_capture func(@orphan_atomic_capture) seq\n---// CHECK-LABEL: func.func @orphan_atomic_capture\n---// CHECK-NOT:   acc.atomic.capture\n---// CHECK:       memref.copy %arg0, %arg1\n---// CHECK:       [[LOAD:%.*]] = memref.load %arg0[]\n---// CHECK:       [[INC:%.*]] = arith.addi [[LOAD]]\n---// CHECK:       memref.store [[INC]], %arg0[]\n---func.func @orphan_atomic_capture(%arg0 : memref<i32>, %arg1 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_capture]>} {\n---  %c1_i32 = arith.constant 1 : i32\n---  acc.atomic.capture {\n---    acc.atomic.read %arg1 = %arg0 : memref<i32>, memref<i32>, i32\n---    acc.atomic.update %arg0 : memref<i32> {\n---    ^bb0(%v: i32):\n---      %r = arith.addi %v, %c1_i32 : i32\n---      acc.yield %r : i32\n---    }\n---    acc.terminator\n---  }\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Negative tests - ops that should NOT be converted\n---//===----------------------------------------------------------------------===//\n---\n---// acc.private attached to acc.parallel should NOT be removed\n---acc.routine @acc_routine_private_parallel func(@private_attached_to_parallel) seq\n---// CHECK-LABEL: func.func @private_attached_to_parallel\n---// CHECK:       acc.private\n---// CHECK:       acc.parallel\n---func.func @private_attached_to_parallel(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_private_parallel]>} {\n---  %0 = acc.private varPtr(%arg0 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n---  acc.parallel private(%0 : memref<i32>) {\n---    %c1 = arith.constant 1 : i32\n---    memref.store %c1, %0[] : memref<i32>\n---    acc.yield\n---  }\n---  return\n---}\n---\n---// acc.atomic.update inside acc.parallel should NOT be converted\n---acc.routine @acc_routine_atomic_parallel func(@atomic_inside_parallel) seq\n---// CHECK-LABEL: func.func @atomic_inside_parallel\n---// CHECK:       acc.parallel\n---// CHECK:       acc.atomic.update\n---func.func @atomic_inside_parallel(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_parallel]>} {\n---  acc.parallel {\n---    acc.atomic.update %arg0 : memref<i32> {\n---    ^bb0(%arg1: i32):\n---      %c1 = arith.constant 1 : i32\n---      %1 = arith.addi %arg1, %c1 : i32\n---      acc.yield %1 : i32\n---    }\n---    acc.yield\n---  }\n---  return\n---}\n---\n---// acc.loop inside acc.parallel should NOT be converted\n---acc.routine @acc_routine_loop_parallel func(@loop_inside_parallel) seq\n---// CHECK-LABEL: func.func @loop_inside_parallel\n---// CHECK:       acc.parallel\n---// CHECK:       acc.loop\n---func.func @loop_inside_parallel(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_loop_parallel]>} {\n---  %c0 = arith.constant 0 : index\n---  %c10 = arith.constant 10 : index\n---  %c1 = arith.constant 1 : index\n---  acc.parallel {\n---    acc.loop control(%iv : index) = (%c0 : index) to (%c10 : index) step (%c1 : index) {\n---      %c5 = arith.constant 5 : i32\n---      memref.store %c5, %arg0[] : memref<i32>\n---      acc.yield\n---    } attributes {inclusiveUpperbound = array<i1: true>, seq = [#acc.device_type<none>]}\n---    acc.yield\n---  }\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Positive tests - orphan ops attached to orphan loop (both should convert)\n---//===----------------------------------------------------------------------===//\n---\n---// acc.private attached to orphan acc.loop - BOTH should be removed\n---acc.routine @acc_routine_private_loop func(@private_attached_to_loop) seq\n---// CHECK-LABEL: func.func @private_attached_to_loop\n---// CHECK-NOT:   acc.private\n---// CHECK-NOT:   acc.loop\n---// CHECK:       scf.for\n---func.func @private_attached_to_loop(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_private_loop]>} {\n---  %c0 = arith.constant 0 : i32\n---  %c10 = arith.constant 10 : i32\n---  %c1 = arith.constant 1 : i32\n---  %0 = acc.private varPtr(%arg0 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n---  acc.loop private(%0 : memref<i32>) control(%iv : i32) = (%c0 : i32) to (%c10 : i32) step (%c1 : i32) {\n---    %c1_i32 = arith.constant 1 : i32\n---    memref.store %c1_i32, %0[] : memref<i32>\n---    acc.yield\n---  } attributes {inclusiveUpperbound = array<i1: true>, seq = [#acc.device_type<none>]}\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Orphan loop conversion tests\n---//===----------------------------------------------------------------------===//\n---\n---// Orphan acc.loop should be converted to scf.for\n---acc.routine @acc_routine_loop func(@orphan_loop) seq\n---// CHECK-LABEL: func.func @orphan_loop\n---// CHECK-NOT:   acc.loop\n---// CHECK:       scf.for\n---func.func @orphan_loop(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_loop]>} {\n---  %c0 = arith.constant 0 : i32\n---  %c10 = arith.constant 10 : i32\n---  %c1 = arith.constant 1 : i32\n---  acc.loop control(%iv : i32) = (%c0 : i32) to (%c10 : i32) step (%c1 : i32) {\n---    memref.store %iv, %arg0[] : memref<i32>\n---    acc.yield\n---  } attributes {inclusiveUpperbound = array<i1: true>, seq = [#acc.device_type<none>]}\n---  return\n---}\n---\n---// Nested orphan acc.loop should be converted to nested scf.for\n---acc.routine @acc_routine_nested_loop func(@nested_orphan_loop) seq\n---// CHECK-LABEL: func.func @nested_orphan_loop\n---// CHECK-NOT:   acc.loop\n---// CHECK:       scf.for\n---// CHECK:       scf.for\n---func.func @nested_orphan_loop(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_nested_loop]>} {\n---  %c0 = arith.constant 0 : i32\n---  %c10 = arith.constant 10 : i32\n---  %c1 = arith.constant 1 : i32\n---  acc.loop control(%iv0 : i32, %iv1 : i32) = (%c0, %c0 : i32, i32) to (%c10, %c10 : i32, i32) step (%c1, %c1 : i32, i32) {\n---    %sum = arith.addi %iv0, %iv1 : i32\n---    memref.store %sum, %arg0[] : memref<i32>\n---    acc.yield\n---  } attributes {inclusiveUpperbound = array<i1: true, true>, seq = [#acc.device_type<none>]}\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Unstructured orphan loop - converted to scf.execute_region\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_unstructured func(@orphan_unstructured_loop) seq\n---// CHECK-LABEL: func.func @orphan_unstructured_loop\n---// CHECK-NOT:   acc.loop\n---// CHECK-NOT:   acc.private\n---// CHECK:       scf.execute_region\n---// CHECK:       ^bb{{[0-9]+}}:\n---// CHECK:       cf.cond_br\n---// CHECK:       scf.yield\n---func.func @orphan_unstructured_loop(%arg0 : memref<32xi32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_unstructured]>} {\n---  %c32_i32 = arith.constant 32 : i32\n---  %c2_i32 = arith.constant 2 : i32\n---  %c0_i32 = arith.constant 0 : i32\n---  %c1_i32 = arith.constant 1 : i32\n---  %iter_var = memref.alloca() : memref<i32>\n---  %priv = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n---  acc.loop private(%priv : memref<i32>) {\n---    %limit = memref.alloca() : memref<i32>\n---    memref.store %c32_i32, %limit[] : memref<i32>\n---    memref.store %c1_i32, %priv[] : memref<i32>\n---    cf.br ^bb1\n---  ^bb1:\n---    %count = memref.load %limit[] : memref<i32>\n---    %cond = arith.cmpi sgt, %count, %c0_i32 : i32\n---    cf.cond_br %cond, ^bb2, ^bb3\n---  ^bb2:\n---    %idx = memref.load %priv[] : memref<i32>\n---    %idx_idx = arith.index_cast %idx : i32 to index\n---    %val = memref.load %arg0[%idx_idx] : memref<32xi32>\n---    %new_val = arith.divsi %val, %c2_i32 : i32\n---    memref.store %new_val, %arg0[%idx_idx] : memref<32xi32>\n---    %new_count = arith.subi %count, %c1_i32 : i32\n---    memref.store %new_count, %limit[] : memref<i32>\n---    %new_idx = arith.addi %idx, %c1_i32 : i32\n---    memref.store %new_idx, %priv[] : memref<i32>\n---    cf.br ^bb1\n---  ^bb3:\n---    acc.yield\n---  } attributes {independent = [#acc.device_type<none>], unstructured}\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Orphan loop with reduction - both converted\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_loop_reduction func(@orphan_loop_with_reduction) seq\n---// CHECK-LABEL: func.func @orphan_loop_with_reduction\n---// CHECK-NOT:   acc.loop\n---// CHECK-NOT:   acc.reduction\n---// CHECK-NOT:   acc.private\n---// CHECK:       scf.for\n---func.func @orphan_loop_with_reduction(%arg0 : memref<i32>, %arg1 : memref<100xi32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_loop_reduction]>} {\n---  %c100_i32 = arith.constant 100 : i32\n---  %c1_i32 = arith.constant 1 : i32\n---  %iter_var = memref.alloca() : memref<i32>\n---  %red = acc.reduction varPtr(%arg0 : memref<i32>) recipe(@reduction_add_memref_i32) -> memref<i32>\n---  %priv = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n---  acc.loop vector private(%priv : memref<i32>) reduction(%red : memref<i32>) control(%arg2 : i32) = (%c1_i32 : i32) to (%c100_i32 : i32) step (%c1_i32 : i32) {\n---    memref.store %arg2, %priv[] : memref<i32>\n---    %idx = memref.load %priv[] : memref<i32>\n---    %idx_cast = arith.index_cast %idx : i32 to index\n---    %elem = memref.load %arg1[%idx_cast] : memref<100xi32>\n---    %r_val = memref.load %arg0[] : memref<i32>\n---    %new_r = arith.addi %r_val, %elem : i32\n---    memref.store %new_r, %arg0[] : memref<i32>\n---    acc.yield\n---  } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Orphan loop with variable bounds\n---//===----------------------------------------------------------------------===//\n---\n---acc.routine @acc_routine_var_bounds func(@orphan_loop_variable_bounds) seq\n---// CHECK-LABEL: func.func @orphan_loop_variable_bounds\n---// CHECK-NOT:   acc.loop\n---// CHECK:       [[LB:%.*]] = memref.load %arg0[]\n---// CHECK:       [[UB:%.*]] = memref.load %arg1[]\n---// CHECK:       scf.for\n---func.func @orphan_loop_variable_bounds(%arg0 : memref<i32>, %arg1 : memref<i32>, %arg2 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_var_bounds]>} {\n---  %c1 = arith.constant 1 : i32\n---  %lb = memref.load %arg0[] : memref<i32>\n---  %ub = memref.load %arg1[] : memref<i32>\n---  acc.loop vector control(%iv : i32) = (%lb : i32) to (%ub : i32) step (%c1 : i32) {\n---    memref.store %iv, %arg2[] : memref<i32>\n---    acc.yield\n---  } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n---  return\n---}\n---\n---//===----------------------------------------------------------------------===//\n---// Orphan loop between compute regions - only orphan converted\n---//===----------------------------------------------------------------------===//\n---\n---acc.reduction.recipe @reduction_mul_memref_i32 : memref<i32> reduction_operator <mul> init {\n---^bb0(%arg0: memref<i32>):\n---  %c1_i32 = arith.constant 1 : i32\n---  %0 = memref.alloca() : memref<i32>\n---  memref.store %c1_i32, %0[] : memref<i32>\n---  acc.yield %0 : memref<i32>\n---} combiner {\n---^bb0(%arg0: memref<i32>, %arg1: memref<i32>):\n---  %0 = memref.load %arg0[] : memref<i32>\n---  %1 = memref.load %arg1[] : memref<i32>\n---  %2 = arith.muli %0, %1 : i32\n---  memref.store %2, %arg0[] : memref<i32>\n---  acc.yield %arg0 : memref<i32>\n---}\n---\n---// Orphan loop sandwiched between compute regions - only orphan should convert\n---// CHECK-LABEL: func.func @orphan_between_compute_regions\n---// CHECK:       acc.parallel\n---// CHECK:       acc.yield\n---// CHECK-NOT:   acc.private varPtr\n---// CHECK-NOT:   acc.reduction varPtr\n---// CHECK:       scf.for\n---// CHECK:       acc.parallel\n---func.func @orphan_between_compute_regions(%arg0 : memref<i32>, %arg1 : memref<8xi32>, %arg2 : memref<i32>) {\n---  %c2_i32 = arith.constant 2 : i32\n---  %c8_i32 = arith.constant 8 : i32\n---  %c1_i32 = arith.constant 1 : i32\n---  %iter_var = memref.alloca() : memref<i32>\n---\n---  // First compute region - should NOT be converted\n---  acc.parallel combined(loop) {\n---    %priv1 = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n---    acc.loop combined(parallel) private(%priv1 : memref<i32>) control(%iv : i32) = (%c1_i32 : i32) to (%c8_i32 : i32) step (%c1_i32 : i32) {\n---      memref.store %iv, %priv1[] : memref<i32>\n---      %idx = arith.index_cast %iv : i32 to index\n---      memref.store %c1_i32, %arg1[%idx] : memref<8xi32>\n---      acc.yield\n---    } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n---    acc.yield\n---  }\n---\n---  // Orphan loop - SHOULD be converted\n---  %priv_orphan = acc.private varPtr(%arg2 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n---  %red_orphan = acc.reduction varPtr(%arg0 : memref<i32>) recipe(@reduction_mul_memref_i32) -> memref<i32>\n---  %priv_iv = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n---  acc.loop private(%priv_orphan, %priv_iv : memref<i32>, memref<i32>) reduction(%red_orphan : memref<i32>) control(%iv : i32) = (%c1_i32 : i32) to (%c8_i32 : i32) step (%c1_i32 : i32) {\n---    memref.store %iv, %priv_iv[] : memref<i32>\n---    %idx = arith.index_cast %iv : i32 to index\n---    %elem = memref.load %arg1[%idx] : memref<8xi32>\n---    memref.store %elem, %priv_orphan[] : memref<i32>\n---    %t = memref.load %priv_orphan[] : memref<i32>\n---    %mul = arith.muli %t, %c2_i32 : i32\n---    memref.store %mul, %arg0[] : memref<i32>\n---    acc.yield\n---  } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n---\n---  // Second compute region - should NOT be converted\n---  acc.parallel combined(loop) {\n---    %priv2 = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n---    acc.loop combined(parallel) private(%priv2 : memref<i32>) control(%iv : i32) = (%c1_i32 : i32) to (%c8_i32 : i32) step (%c1_i32 : i32) {\n---      memref.store %iv, %priv2[] : memref<i32>\n---      %idx = arith.index_cast %iv : i32 to index\n---      memref.store %iv, %arg1[%idx] : memref<8xi32>\n---      acc.yield\n---    } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n---    acc.yield\n---  }\n---  return\n---}\n--diff -ruN --strip-trailing-cr a/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir b/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir\n----- a/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir\n--+++ b/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir\n--@@ -230,35 +230,3 @@\n--   %1 = \"test.reify_bound\"(%padded) {dim = 1, constant} : (tensor<1x?x64xf32>) -> (index)\n--   return\n-- }\n---\n---// -----\n---\n---//       CHECK: #[[$MAP:.+]] = affine_map<()[s0] -> (s0 * 2)>\n---// CHECK-LABEL: func @tensor_collapse(\n---//  CHECK-SAME:     %[[sz0:.*]]: index\n---//   CHECK-DAG:   %[[c2:.*]] = arith.constant 2 : index\n---//   CHECK-DAG:   %[[c12:.*]] = arith.constant 12 : index\n---//       CHECK:   %[[dim:.*]] = tensor.dim %{{.*}}, %[[c2]] : tensor<3x4x?x2xf32>\n---//       CHECK:   %[[mul:.*]] = affine.apply #[[$MAP]]()[%[[dim]]]\n---//       CHECK:   return %[[c12]], %[[mul]]\n---func.func @tensor_collapse(%sz0: index) -> (index, index) {\n---  %0 = tensor.empty(%sz0) : tensor<3x4x?x2xf32>\n---  %1 = tensor.collapse_shape %0 [[0, 1], [2, 3]] : tensor<3x4x?x2xf32> into tensor<12x?xf32>\n---  %2 = \"test.reify_bound\"(%1) {dim = 0} : (tensor<12x?xf32>) -> (index)\n---  %3 = \"test.reify_bound\"(%1) {dim = 1} : (tensor<12x?xf32>) -> (index)\n---  return %2, %3 : index, index\n---}\n---\n---// -----\n---\n---// CHECK-LABEL: func @tensor_expand(\n---//  CHECK-SAME:     %[[t:[a-zA-Z0-9]+]]: tensor<?xf32>\n---//  CHECK-SAME:     %[[sz:[a-zA-Z0-9]+]]: index\n---//       CHECK:   %[[c4:.*]] = arith.constant 4 : index\n---//       CHECK:   return %[[c4]], %[[sz]]\n---func.func @tensor_expand(%t: tensor<?xf32>, %sz: index) -> (index, index) {\n---  %0 = tensor.expand_shape %t [[0, 1]] output_shape [4, %sz] : tensor<?xf32> into tensor<4x?xf32>\n---  %1 = \"test.reify_bound\"(%0) {dim = 0} : (tensor<4x?xf32>) -> (index)\n---  %2 = \"test.reify_bound\"(%0) {dim = 1} : (tensor<4x?xf32>) -> (index)\n---  return %1, %2 : index, index\n---}\n diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl\n-index 55a1ce3..4aeaa50 100644\n+index 4aeaa50..d3f5351 100644\n --- a/third_party/llvm/workspace.bzl\n +++ b/third_party/llvm/workspace.bzl\n @@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n  \n  def repo(name):\n      \"\"\"Imports LLVM.\"\"\"\n--    LLVM_COMMIT = \"0812f41cd68d63d10a4c3a02271b0ea8276dbe57\"\n--    LLVM_SHA256 = \"c5bbfd7e6accbb4bfbeeb990666aa64654a667c6569366e90aa1f8d8b28dbf8c\"\n-+    LLVM_COMMIT = \"3ecf4d2ebfb8f84cffb42ff6c220ecdb3d5acbce\"\n-+    LLVM_SHA256 = \"205e48cd5a7212ddcb65485c4dbe1dd9aaeafd0fa614d4a87b84eee5967bf84e\"\n+-    LLVM_COMMIT = \"3ecf4d2ebfb8f84cffb42ff6c220ecdb3d5acbce\"\n+-    LLVM_SHA256 = \"205e48cd5a7212ddcb65485c4dbe1dd9aaeafd0fa614d4a87b84eee5967bf84e\"\n++    LLVM_COMMIT = \"14c00c05c13af8fa5c56852dce958b4259935fa8\"\n++    LLVM_SHA256 = \"5831226924cd42e9fb535becd04ca7c2f2aa4049f2877b45c80248c6e1429477\"\n  \n      tf_http_archive(\n          name = name,"
        },
        {
            "sha": "6b2c29177047009a4a953716121d6ff4f3dc0e72",
            "filename": "third_party/xla/third_party/shardy/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/eab591b778ab3400d835d0417562a9c692673f81/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/eab591b778ab3400d835d0417562a9c692673f81/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl?ref=eab591b778ab3400d835d0417562a9c692673f81",
            "patch": "@@ -3,8 +3,8 @@\n load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n \n def repo():\n-    SHARDY_COMMIT = \"16693e931e4417c66ed06d10d8cd189c9dff2433\"\n-    SHARDY_SHA256 = \"a9eae4de86b873e793643063f464ccc50f04906c6d2d143fdfd39a0cdc9121b2\"\n+    SHARDY_COMMIT = \"74bd59e45f2bcec7ad7100075bdd65595fdfc03b\"\n+    SHARDY_SHA256 = \"492dcb56a460ef8f6af4d457054410eda99864e9b13b76e67ee79593f94fdcff\"\n \n     tf_http_archive(\n         name = \"shardy\","
        }
    ],
    "stats": {
        "total": 1817,
        "additions": 9,
        "deletions": 1808
    }
}