{
    "author": "seantalts",
    "message": "[XLA:CPU] Add `DeviceType` to `IntrinsicOptions`.\n\nThis change introduces a `DeviceType` enum to specify the target hardware platform (e.g., AMD CPU, Nvidia GPU) within `IntrinsicOptions`, allowing for platform-specific intrinsic code generation.\n\nPiperOrigin-RevId: 799282767",
    "sha": "9d5479f83ea0cd5fa0e8a14702306e3120cec16b",
    "files": [
        {
            "sha": "8e81c25b6ff04d2ec48394610082c331f9706ae9",
            "filename": "third_party/xla/xla/backends/cpu/codegen/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD?ref=9d5479f83ea0cd5fa0e8a14702306e3120cec16b",
            "patch": "@@ -65,6 +65,7 @@ cc_library(\n         \"//xla:util\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/codegen:intrinsic_lib\",\n+        \"//xla/codegen/intrinsic\",\n         \"//xla/codegen/intrinsic:intrinsic_compiler_lib\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service/cpu:backend_config_proto_cc\","
        },
        {
            "sha": "288d5e6ce7bff9ad358b24cb6b9088c166635627",
            "filename": "third_party/xla/xla/backends/cpu/codegen/ir_compiler.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 3,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.cc?ref=9d5479f83ea0cd5fa0e8a14702306e3120cec16b",
            "patch": "@@ -66,6 +66,7 @@ limitations under the License.\n #include \"xla/backends/cpu/codegen/cpu_features.h\"\n #include \"xla/backends/cpu/codegen/kernel_api_ir_builder.h\"\n #include \"xla/backends/cpu/codegen/polynomial_approximations.h\"\n+#include \"xla/codegen/intrinsic/intrinsic.h\"\n #include \"xla/codegen/intrinsic/intrinsic_compiler_lib.h\"\n #include \"xla/codegen/intrinsic_lib.h\"\n #include \"xla/service/cpu/backend_config.pb.h\"\n@@ -345,10 +346,30 @@ llvm::Error IrCompiler::RunIrPasses(llvm::Module& module,\n       std::make_unique<llvm::TargetLibraryInfoImpl>(target_triple);\n   target_library_info_impl->addVectorizableFunctions(\n       PolynomialApproximationsVectorization());\n+\n+  xla::codegen::intrinsics::DeviceType device_type;\n+  if (target_triple.isX86()) {\n+    // As a heuristic, we check for SSE4a to determine if we are on AMD.\n+    // This feature was added in 2007 and is set on all AMD CPUs since then, and\n+    // no intel cpus. This is a bit of a hack though, as there is no strict link\n+    // between increased precision and SSE4a; Intel could decide to add it in\n+    // the future but they are very unlikely to do so as they haven't in the\n+    // past 18 years.\n+    if (target_machine->getTargetFeatureString().contains(\"+sse4a\")) {\n+      device_type = xla::codegen::intrinsics::DeviceType::kAmdCpu;\n+    } else {\n+      device_type = xla::codegen::intrinsics::DeviceType::kIntelCpu;\n+    }\n+  } else if (target_triple.isAArch64() || target_triple.isARM()) {\n+    device_type = xla::codegen::intrinsics::DeviceType::kArmCpu;\n+  } else {\n+    LOG(FATAL) << \"Unsupported CPU type: \" << target_triple.str();\n+  }\n+\n   codegen::IntrinsicFunctionLib intrinsic_lib(\n-      {target_machine->getTargetFeatureString().str(),\n-       /*disable_platform_dependent_math=*/options_\n-           .disable_platform_dependent_math});\n+      {target_machine->getTargetFeatureString().str(), device_type,\n+       /*disable_platform_dependent_math=*/\n+       options_.disable_platform_dependent_math});\n   target_library_info_impl->addVectorizableFunctions(\n       intrinsic_lib.Vectorizations());\n "
        },
        {
            "sha": "96ca56cc111d7c677f7461dbe12a1a96e242aa19",
            "filename": "third_party/xla/xla/codegen/intrinsic/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD?ref=9d5479f83ea0cd5fa0e8a14702306e3120cec16b",
            "patch": "@@ -393,8 +393,8 @@ xla_cc_test(\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/tsl/platform:test_benchmark\",\n         \"//xla/tsl/platform:test_main\",\n+        \"@com_google_absl//absl/strings\",\n         \"@llvm-project//llvm:Target\",\n-        \"@llvm-project//llvm:TargetParser\",\n         \"@llvm-project//llvm:ir_headers\",\n     ],\n )"
        },
        {
            "sha": "c8b1c19575a4fea13202b1c8aad6c4fba6d2d4f7",
            "filename": "third_party/xla/xla/codegen/intrinsic/intrinsic.h",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic.h?ref=9d5479f83ea0cd5fa0e8a14702306e3120cec16b",
            "patch": "@@ -99,9 +99,20 @@ class Type : public std::variant<Scalar, Vec> {\n   static Type FromName(absl::string_view name);\n };\n \n+enum class DeviceType {\n+  kAmdCpu,\n+  kIntelCpu,\n+  kArmCpu,\n+  kNvidiaGpu,\n+  kAmdGpu,\n+};\n+\n struct IntrinsicOptions {\n   // CPU features available on the target machine.\n   std::string features;\n+\n+  // The type of device the target machine is running on.\n+  DeviceType device_type;\n   // Disables math functions that do not have the same results across e.g.\n   // AMD vs. Intel CPUs.\n   bool disable_platform_dependent_math = false;"
        },
        {
            "sha": "25d1975dd261e86065accf76d8909c37540ea335",
            "filename": "third_party/xla/xla/codegen/intrinsic/rsqrt.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt.cc?ref=9d5479f83ea0cd5fa0e8a14702306e3120cec16b",
            "patch": "@@ -200,13 +200,7 @@ absl::StatusOr<llvm::Function*> Rsqrt::CreateDefinition(\n       options.Contains(\"+avx512f\") &&\n       (type.element_type() == F64 ||\n        (type.element_type() == F32 && type.vector_width().value_or(1) > 8));\n-  // As a heuristic, we check for SSE4a to determine if we are on AMD.\n-  // This feature was added in 2007 and is set on all AMD CPUs since then, and\n-  // no intel cpus. This is a bit of a hack though, as there is no strict link\n-  // between increased precision and SSE4a; Intel could decide to add it in the\n-  // future but they are very unlikely to do so as they haven't in the past 18\n-  // years.\n-  const bool is_amd = options.Contains(\"+sse4a\");\n+  const bool is_amd = options.device_type == DeviceType::kAmdCpu;\n   const size_t num_steps = (is_amd && !using_avx512) ? 1 : 2;\n   llvm::Value* refined_result =\n       NewtonRaphsonRsqrtIteration(builder, x, y_approx, input_type, num_steps);"
        },
        {
            "sha": "c98b8d56264349083426632615e9de8308e381a5",
            "filename": "third_party/xla/xla/codegen/intrinsic/rsqrt_benchmark_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_benchmark_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_benchmark_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_benchmark_test.cc?ref=9d5479f83ea0cd5fa0e8a14702306e3120cec16b",
            "patch": "@@ -19,6 +19,7 @@ limitations under the License.\n #include <string>\n #include <utility>\n \n+#include \"absl/strings/match.h\"\n #include \"llvm/IR/BasicBlock.h\"\n #include \"llvm/IR/Constants.h\"\n #include \"llvm/IR/DerivedTypes.h\"\n@@ -41,6 +42,7 @@ limitations under the License.\n \n namespace xla::codegen::intrinsic {\n \n+using ::xla::codegen::intrinsics::DeviceType;\n using ::xla::codegen::intrinsics::Rsqrt;\n using ::xla::codegen::intrinsics::Type;\n \n@@ -65,10 +67,13 @@ JitRunner CreateJitRunnerWithRsqrt(Type type) {\n   auto module = std::make_unique<llvm::Module>(\"test_module\", *context);\n   std::unique_ptr<llvm::TargetMachine> target_machine =\n       xla::codegen::intrinsic::CreateHostTargetMachine();\n+  const auto features = target_machine->getTargetFeatureString().str();\n+  DeviceType device_type = absl::StrContains(features, \"+sse4a\")\n+                               ? DeviceType::kAmdCpu\n+                               : DeviceType::kIntelCpu;\n   llvm::Function* rsqrt_func =\n-      Rsqrt::CreateDefinition(\n-          module.get(), {target_machine->getTargetFeatureString().str(), false},\n-          type)\n+      Rsqrt::CreateDefinition(module.get(), {features, device_type, false},\n+                              type)\n           .value();\n   rsqrt_func->setLinkage(llvm::Function::ExternalLinkage);\n   CreateOneOverSqrt(*context, *module, Type::TypeToIrType(type, *context));"
        },
        {
            "sha": "3c7640a16ddf70a425252c6c1c0066f5e9cc44b5",
            "filename": "third_party/xla/xla/codegen/intrinsic/rsqrt_test.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 8,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_test.cc?ref=9d5479f83ea0cd5fa0e8a14702306e3120cec16b",
            "patch": "@@ -73,17 +73,25 @@ void AddOneOverSqrt(llvm::LLVMContext& context, llvm::Module& module,\n   builder.CreateRet(one_over_sqrt);\n }\n \n+llvm::StringMap<bool> GetHostCPUFeatures() {\n+  static const absl::NoDestructor<llvm::StringMap<bool>> features(\n+      llvm::sys::getHostCPUFeatures());\n+  return *features;\n+}\n+bool isAmd() { return GetHostCPUFeatures().lookup(\"sse4a\"); }\n JitRunner CreateJitRunnerWithRsqrt(\n     Type type, bool disable_platform_dependent_math = false) {\n   auto context = std::make_unique<llvm::LLVMContext>();\n   auto module = std::make_unique<llvm::Module>(\"test_module\", *context);\n \n   std::unique_ptr<llvm::TargetMachine> target_machine =\n       xla::codegen::intrinsic::CreateHostTargetMachine();\n+  DeviceType device_type =\n+      isAmd() ? DeviceType::kAmdCpu : DeviceType::kIntelCpu;\n   llvm::Function* rsqrt_func =\n       Rsqrt::CreateDefinition(module.get(),\n                               {target_machine->getTargetFeatureString().str(),\n-                               disable_platform_dependent_math},\n+                               device_type, disable_platform_dependent_math},\n                               type)\n           .value();\n   rsqrt_func->setLinkage(llvm::Function::ExternalLinkage);\n@@ -93,15 +101,8 @@ JitRunner CreateJitRunnerWithRsqrt(\n   return JitRunner(std::move(module), std::move(context));\n }\n \n-llvm::StringMap<bool> GetHostCPUFeatures() {\n-  static const absl::NoDestructor<llvm::StringMap<bool>> features(\n-      llvm::sys::getHostCPUFeatures());\n-  return *features;\n-}\n-\n bool hasAvx() { return GetHostCPUFeatures().lookup(\"avx\"); }\n bool hasAvx512Support() { return GetHostCPUFeatures().lookup(\"avx512f\"); }\n-bool isAmd() { return GetHostCPUFeatures().lookup(\"sse4a\"); }\n \n TEST(FeaturesTest, HostFeatures) {\n   std::cout << \"CPU: \" << llvm::sys::getHostCPUName().str() << \"\\n\";"
        },
        {
            "sha": "099a0d9e6757ac1cb5a867bd166ef929f5da9b42",
            "filename": "third_party/xla/xla/service/gpu/llvm_gpu_backend/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2FBUILD?ref=9d5479f83ea0cd5fa0e8a14702306e3120cec16b",
            "patch": "@@ -33,10 +33,12 @@ cc_library(\n         \"//xla:util\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/codegen:intrinsic_lib\",\n+        \"//xla/codegen/intrinsic\",\n         \"//xla/codegen/intrinsic:intrinsic_compiler_lib\",\n         \"//xla/service/llvm_ir:llvm_type_conversion_util\",\n         \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/stream_executor:device_description\",\n+        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\",\n         \"@com_google_absl//absl/log\","
        },
        {
            "sha": "018c744f374c2ff981d815ff319a28410def5430",
            "filename": "third_party/xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fgpu_backend_lib.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9d5479f83ea0cd5fa0e8a14702306e3120cec16b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fgpu_backend_lib.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fllvm_gpu_backend%2Fgpu_backend_lib.cc?ref=9d5479f83ea0cd5fa0e8a14702306e3120cec16b",
            "patch": "@@ -58,12 +58,14 @@ limitations under the License.\n #include \"llvm/Transforms/IPO/AlwaysInliner.h\"\n #include \"llvm/Transforms/IPO/Internalize.h\"\n #include \"llvm/Transforms/Scalar.h\"\n+#include \"xla/codegen/intrinsic/intrinsic.h\"\n #include \"xla/codegen/intrinsic/intrinsic_compiler_lib.h\"\n #include \"xla/codegen/intrinsic_lib.h\"\n #include \"xla/service/gpu/llvm_gpu_backend/load_ir_module.h\"\n #include \"xla/service/gpu/llvm_gpu_backend/utils.h\"\n #include \"xla/service/llvm_ir/llvm_type_conversion_util.h\"\n #include \"xla/service/llvm_ir/llvm_util.h\"\n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -262,8 +264,18 @@ absl::Status LinkAndOptimizeModule(\n   llvm::CGSCCAnalysisManager cgam;\n   llvm::ModuleAnalysisManager mam;\n \n+  xla::codegen::intrinsics::DeviceType device_type;\n+  if (std::holds_alternative<se::CudaComputeCapability>(gpu_version)) {\n+    device_type = xla::codegen::intrinsics::DeviceType::kNvidiaGpu;\n+  } else if (std::holds_alternative<se::RocmComputeCapability>(gpu_version)) {\n+    device_type = xla::codegen::intrinsics::DeviceType::kAmdGpu;\n+  } else {\n+    LOG(FATAL) << \"Unsupported GPU type\";\n+  }\n+\n   codegen::IntrinsicFunctionLib intrinsic_lib(\n       {target_machine ? target_machine->getTargetFeatureString().str() : \"\",\n+       device_type,\n        /*disable_platform_dependent_math=*/true});\n \n   if (target_machine) {"
        }
    ],
    "stats": {
        "total": 91,
        "additions": 69,
        "deletions": 22
    }
}