{
    "author": "beckerhe",
    "message": "Remove AsGpuStreamValue and split NCCL/RCCL targets\n\nThis splits the NCCL collective targets into NCCL and RCCL implementations. It's the last little bit of code that has not yet been separated.\n\nIt's also the last user of gpu_stream.h which can also be deleted.\n\nAPI Changes:\n- `GpuCollectives::Default` now takes a platform as an argument. Previously we've been using \"gpu\" as the platform name, but I'm now migrating this to CUDA and ROCM which are the platform names that we use anywhere else.\n- I also moved NvshmemCollectives onto the CUDA platform\n\nPiperOrigin-RevId: 845209298",
    "sha": "3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
    "files": [
        {
            "sha": "291f156d5000d5e5b535366bff633fc97c1898e9",
            "filename": "third_party/xla/xla/backends/gpu/collectives/BUILD",
            "status": "modified",
            "additions": 185,
            "deletions": 69,
            "changes": 254,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -19,14 +19,25 @@ package_group(\n     ],\n )\n \n+alias(\n+    # Since RCCL reimplements the NCCL API and there is no way to disable that,\n+    # we need to make sure that we only link either NCCL or RCCL.\n+    name = \"nccl_or_rccl_collectives\",\n+    actual = if_rocm_is_configured(\n+        \":rccl_collectives\",\n+        \":nccl_collectives\",\n+    ),\n+    tags = [\"manual\"],\n+)\n+\n # Build target that registers all available GPU collectives implementations with the collectives\n # registry at link time.\n cc_library(\n     name = \"gpu_collectives_plugin\",\n     deps = [\n         \":gpu_collectives_stub\",\n     ] + if_cuda_or_rocm_is_configured([\n-        \":nccl_collectives\",\n+        \":nccl_or_rccl_collectives\",\n     ]) + if_cuda_is_configured([\n         \":nvshmem_collectives_if_supported\",\n     ]),\n@@ -192,6 +203,7 @@ cc_library(\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n         \"@local_tsl//tsl/platform:casts\",\n     ],\n@@ -237,13 +249,30 @@ cc_library(\n     name = \"nccl_errors\",\n     srcs = [\"nccl_errors.cc\"],\n     hdrs = [\"nccl_errors.h\"],\n-    local_defines =\n-        if_rocm_is_configured([\n-            \"TENSORFLOW_USE_ROCM=1\",\n-        ]),\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+        \"no-oneapi\",\n+    ],\n+    visibility = [\"//visibility:private\"],\n+    deps = [\n+        \"//xla:util\",\n+        \"//xla/tsl/cuda:nccl\",\n+        \"//xla/tsl/platform:logging\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/time\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"rccl_errors\",\n+    srcs = [\"rccl_errors.cc\"],\n+    hdrs = [\"rccl_errors.h\"],\n     tags = [\n         \"gpu\",\n         \"no-oneapi\",\n+        \"rocm-only\",\n     ],\n     visibility = [\"//visibility:private\"],\n     deps = [\n@@ -253,35 +282,27 @@ cc_library(\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/time\",\n-    ] + if_cuda_is_configured([\n-        \"//xla/tsl/cuda:nccl\",\n-    ]) + if_rocm_is_configured([\n-        \"@local_config_rocm//rocm:rocm_headers\",\n         \"@local_config_rocm//rocm:rccl\",\n-    ]),\n+        \"@local_config_rocm//rocm:rocm_headers\",\n+    ],\n )\n \n cc_library(\n     name = \"nccl_collectives\",\n     srcs = [\"nccl_collectives.cc\"],\n     hdrs = [\"nccl_collectives.h\"],\n-    local_defines =\n-        if_rocm_is_configured([\n-            \"TENSORFLOW_USE_ROCM=1\",\n-        ]),\n     tags = [\n+        \"cuda-only\",\n         \"gpu\",\n         \"no-oneapi\",\n     ],\n     visibility = [\"//visibility:private\"],\n     deps = [\n         \":gpu_clique_key\",\n         \":gpu_collectives\",\n-        \":gpu_communicator\",\n         \":nccl_communicator\",\n         \":nccl_errors\",\n         \"//xla:debug_options_flags\",\n-        \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla:util\",\n         \"//xla/core/collectives\",\n@@ -292,51 +313,90 @@ cc_library(\n         \"//xla/core/collectives:rank_id\",\n         \"//xla/pjrt/distributed:key_value_store_interface\",\n         \"//xla/runtime:device_id\",\n-        \"//xla/service:collective_ops_utils\",\n         \"//xla/service/gpu:gpu_executable_run_options\",\n-        \"//xla/stream_executor:device_address\",\n-        \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n-        \"//xla/stream_executor/gpu:gpu_stream\",\n+        \"//xla/stream_executor/cuda:nccl_memory_allocator\",  # buildcleaner: keep (static registration)\n+        \"//xla/tsl/cuda:nccl\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base\",\n         \"@com_google_absl//absl/base:core_headers\",\n-        \"@com_google_absl//absl/cleanup\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n-        \"@com_google_absl//absl/container:inlined_vector\",\n-        \"@com_google_absl//absl/debugging:leak_check\",\n-        \"@com_google_absl//absl/functional:any_invocable\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/synchronization\",\n+        \"@com_google_absl//absl/time\",\n         \"@com_google_absl//absl/types:span\",\n         \"@local_tsl//tsl/platform:casts\",\n         \"@local_tsl//tsl/platform:numbers\",\n-    ] + if_cuda_is_configured([\n-        \"//xla/tsl/cuda:nccl\",\n-        \"//xla/stream_executor/cuda:nccl_memory_allocator\",  # buildcleaner: keep (static registration)\n-    ]) + if_rocm_is_configured([\n+    ],\n+    alwayslink = True,  # registers collectives implementation\n+)\n+\n+cc_library(\n+    name = \"rccl_collectives\",\n+    srcs = [\"rccl_collectives.cc\"],\n+    hdrs = [\"rccl_collectives.h\"],\n+    tags = [\n+        \"gpu\",\n+        \"no-oneapi\",\n+        \"rocm-only\",\n+    ],\n+    visibility = [\"//visibility:private\"],\n+    deps = [\n+        \":gpu_clique_key\",\n+        \":gpu_collectives\",\n+        \":rccl_communicator\",\n+        \":rccl_errors\",\n+        \"//xla:debug_options_flags\",\n+        \"//xla:status_macros\",\n+        \"//xla:util\",\n+        \"//xla/core/collectives\",\n+        \"//xla/core/collectives:clique_id\",\n+        \"//xla/core/collectives:clique_key\",\n+        \"//xla/core/collectives:collectives_registry\",\n+        \"//xla/core/collectives:communicator\",\n+        \"//xla/core/collectives:rank_id\",\n+        \"//xla/pjrt/distributed:key_value_store_interface\",\n+        \"//xla/runtime:device_id\",\n+        \"//xla/service/gpu:gpu_executable_run_options\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tsl/platform:env\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:logging\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/base\",\n+        \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/synchronization\",\n+        \"@com_google_absl//absl/time\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@local_config_rocm//rocm:rccl\",  # buildcleaner: keep\n         \"@local_config_rocm//rocm:rocm_headers\",\n-        \"@local_config_rocm//rocm:rccl\",\n-    ]),\n+        \"@local_tsl//tsl/platform:casts\",\n+        \"@local_tsl//tsl/platform:numbers\",\n+    ],\n     alwayslink = True,  # registers collectives implementation\n )\n \n cc_library(\n     name = \"nccl_communicator\",\n     srcs = [\"nccl_communicator.cc\"],\n     hdrs = [\"nccl_communicator.h\"],\n-    local_defines = if_rocm_is_configured([\n-        \"TENSORFLOW_USE_ROCM=1\",\n-    ]),\n     tags = [\n+        \"cuda-only\",\n         \"gpu\",\n         \"no-oneapi\",\n     ],\n@@ -348,53 +408,83 @@ cc_library(\n         \":single_threaded_executor\",\n         \"//xla:future\",\n         \"//xla:shape_util\",\n-        \"//xla:status_macros\",\n         \"//xla:util\",\n-        \"//xla/core/collectives\",\n-        \"//xla/core/collectives:clique_id\",\n-        \"//xla/core/collectives:clique_key\",\n-        \"//xla/core/collectives:collectives_registry\",\n         \"//xla/core/collectives:communicator\",\n         \"//xla/core/collectives:rank_id\",\n-        \"//xla/pjrt/distributed:key_value_store_interface\",\n-        \"//xla/runtime:device_id\",\n-        \"//xla/service:collective_ops_utils\",\n-        \"//xla/service/gpu:gpu_executable_run_options\",\n+        \"//xla/core/collectives:reduction_kind\",\n         \"//xla/stream_executor:device_address\",\n-        \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n-        \"//xla/stream_executor/gpu:gpu_stream\",\n-        \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/concurrency:executor\",\n+        \"//xla/tsl/cuda:nccl\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/base\",\n         \"@com_google_absl//absl/base:core_headers\",\n-        \"@com_google_absl//absl/cleanup\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n-        \"@com_google_absl//absl/debugging:leak_check\",\n         \"@com_google_absl//absl/functional:any_invocable\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/memory\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n-        \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/synchronization\",\n         \"@com_google_absl//absl/types:span\",\n+        \"@local_config_cuda//cuda:cuda_headers\",\n         \"@local_tsl//tsl/platform:casts\",\n-        \"@local_tsl//tsl/platform:numbers\",\n-    ] + if_cuda_is_configured([\n-        \"//xla/tsl/cuda:nccl\",\n-    ]) + if_rocm_is_configured([\n+    ],\n+)\n+\n+cc_library(\n+    name = \"rccl_communicator\",\n+    srcs = [\"rccl_communicator.cc\"],\n+    hdrs = [\"rccl_communicator.h\"],\n+    tags = [\n+        \"gpu\",\n+        \"no-oneapi\",\n+        \"rocm-only\",\n+    ],\n+    visibility = [\"//visibility:private\"],\n+    deps = [\n+        \":gpu_collectives\",\n+        \":gpu_communicator\",\n+        \":rccl_errors\",\n+        \":single_threaded_executor\",\n+        \"//xla:future\",\n+        \"//xla:shape_util\",\n+        \"//xla:util\",\n+        \"//xla/core/collectives:communicator\",\n+        \"//xla/core/collectives:rank_id\",\n+        \"//xla/core/collectives:reduction_kind\",\n+        \"//xla/stream_executor:device_address\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tsl/concurrency:executor\",\n+        \"//xla/tsl/platform:env\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:logging\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/base\",\n+        \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/container:inlined_vector\",\n+        \"@com_google_absl//absl/functional:any_invocable\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/memory\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+        \"@com_google_absl//absl/synchronization\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@local_config_rocm//rocm:rccl\",  # buildcleaner: keep\n         \"@local_config_rocm//rocm:rocm_headers\",\n-        \"@local_config_rocm//rocm:rccl\",\n-    ]),\n+        \"@local_tsl//tsl/platform:casts\",\n+    ],\n )\n \n cc_library(\n@@ -424,15 +514,16 @@ cc_library(\n         \"//xla/core/collectives:collectives_registry\",\n         \"//xla/core/collectives:communicator\",\n         \"//xla/core/collectives:rank_id\",\n+        \"//xla/core/collectives:reduction_kind\",\n         \"//xla/service:collective_ops_utils\",\n         \"//xla/stream_executor:device_address\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor/cuda:nvshmem\",\n         \"//xla/stream_executor/cuda:nvshmem_memory_allocator\",  # buildcleaner: keep (static registration)\n-        \"//xla/stream_executor/gpu:gpu_stream\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/base\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n@@ -479,10 +570,6 @@ xla_test(\n     name = \"nccl_communicator_test\",\n     srcs = [\"nccl_communicator_test.cc\"],\n     backends = [\"gpu\"],\n-    local_defines =\n-        if_rocm_is_configured([\n-            \"TENSORFLOW_USE_ROCM=1\",\n-        ]),\n     tags = [\n         # Stop chloroxylenol from running this test with msan because msan does\n         # not work with CUDA.\n@@ -493,6 +580,7 @@ xla_test(\n         \"no-oneapi\",\n         # TODO(b/435404154): Reenable once this is fixed.\n         \"no_oss\",\n+        \"cuda-only\",\n     ],\n     visibility = [\"//visibility:private\"],\n     deps = [\n@@ -501,8 +589,40 @@ xla_test(\n         \":nccl_communicator\",\n         \":nccl_errors\",\n         \"//xla:future\",\n+        \"//xla/core/collectives:rank_id\",\n+        \"//xla/core/collectives:reduction_kind\",\n+        \"//xla/stream_executor:device_address\",\n+        \"//xla/tsl/cuda:nccl\",\n+        \"//xla/tsl/platform:errors\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n+xla_test(\n+    name = \"rccl_communicator_test\",\n+    srcs = [\"rccl_communicator_test.cc\"],\n+    backends = [\"gpu\"],\n+    tags = [\n+        \"no-oneapi\",\n+        # TODO(b/435404154): Reenable once this is fixed.\n+        \"no_oss\",\n+        \"rocm-only\",\n+    ],\n+    visibility = [\"//visibility:private\"],\n+    deps = [\n+        \":gpu_collectives\",\n+        \":rccl_collectives\",\n+        \":rccl_communicator\",\n+        \":rccl_errors\",\n+        \"//xla:future\",\n         \"//xla/core/collectives:communicator\",\n         \"//xla/core/collectives:rank_id\",\n+        \"//xla/core/collectives:reduction_kind\",\n         \"//xla/service:collective_ops_utils\",\n         \"//xla/stream_executor:device_address\",\n         \"//xla/tsl/concurrency:async_value\",\n@@ -515,12 +635,9 @@ xla_test(\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/utility\",\n         \"@com_google_googletest//:gtest_main\",\n-    ] + if_cuda_is_configured([\n-        \"//xla/tsl/cuda:nccl\",\n-    ]) + if_rocm_is_configured([\n-        \"@local_config_rocm//rocm:rocm_headers\",\n         \"@local_config_rocm//rocm:rccl\",\n-    ]),\n+        \"@local_config_rocm//rocm:rocm_headers\",\n+    ],\n )\n \n xla_test(\n@@ -549,12 +666,14 @@ xla_test(\n     },\n     tags = [\"cuda-only\"],\n     deps = [\n+        \":nvshmem_collectives\",\n         \"//xla:debug_options_flags\",\n         \"//xla:status_macros\",\n         \"//xla/core/collectives:communicator\",\n         \"//xla/pjrt/distributed\",\n         \"//xla/pjrt/distributed:client\",\n         \"//xla/pjrt/distributed:service\",\n+        \"//xla/stream_executor/cuda:nvshmem\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:status\",\n         \"//xla/tsl/platform:statusor\",\n@@ -566,10 +685,7 @@ xla_test(\n         \"@com_google_absl//absl/time\",\n         \"@com_google_googletest//:gtest\",\n         \"@local_config_cuda//cuda:cuda_headers\",\n-    ] + if_cuda_is_configured([\n-        \":nvshmem_collectives\",\n-        \"//xla/stream_executor/cuda:nvshmem\",\n-    ]),\n+    ],\n )\n \n cc_library("
        },
        {
            "sha": "ca98b036a35dd8cec489c5483b822602cd479c24",
            "filename": "third_party/xla/xla/backends/gpu/collectives/gpu_collectives.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_collectives.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_collectives.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_collectives.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"xla/core/collectives/collectives.h\"\n #include \"xla/core/collectives/collectives_registry.h\"\n #include \"xla/shape_util.h\"\n@@ -31,9 +32,9 @@ limitations under the License.\n \n namespace xla::gpu {\n \n-GpuCollectives* GpuCollectives::Default() {\n+GpuCollectives* GpuCollectives::Default(absl::string_view platform_name) {\n   absl::StatusOr<Collectives*> collectives =\n-      CollectivesRegistry::Default(\"gpu\");\n+      CollectivesRegistry::Default(platform_name);\n   CHECK_OK(collectives) << \"Failed to get GPU collectives\";  // Crash OK\n \n   if (auto* gpu_collectives = tsl::down_cast<GpuCollectives*>(*collectives)) {"
        },
        {
            "sha": "7297b98d6e27413769212c7c20ffdb6964cfef3c",
            "filename": "third_party/xla/xla/backends/gpu/collectives/gpu_collectives.h",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_collectives.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_collectives.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_collectives.h?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -27,6 +27,7 @@ limitations under the License.\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n #include \"xla/core/collectives/clique_id.h\"\n #include \"xla/core/collectives/clique_key.h\"\n@@ -46,8 +47,8 @@ namespace xla::gpu {\n // XLA:GPU extension of the Collectives interface with GPU-specific APIs.\n class GpuCollectives : public Collectives {\n  public:\n-  // Returns the default collectives implementation for GPU backend.\n-  static GpuCollectives* Default();\n+  // Returns the default collectives implementation for the given platform.\n+  static GpuCollectives* Default(absl::string_view platform_name);\n \n   // A callback to get a unique clique id.\n   using CliqueIdCallback =  // NOLINT"
        },
        {
            "sha": "b887bbb24e4e78ca1f9ca4918e62515a9148d591",
            "filename": "third_party/xla/xla/backends/gpu/collectives/nccl_collectives.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 17,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_collectives.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_collectives.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_collectives.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -35,7 +35,9 @@ limitations under the License.\n #include \"absl/strings/str_join.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n+#include \"absl/time/time.h\"\n #include \"absl/types/span.h\"\n+#include \"third_party/nccl/nccl.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/collectives/nccl_communicator.h\"\n@@ -61,17 +63,6 @@ limitations under the License.\n #include \"tsl/platform/casts.h\"\n #include \"tsl/platform/numbers.h\"\n \n-#if TENSORFLOW_USE_ROCM\n-#include \"rocm/rocm_config.h\"\n-#if (TF_ROCM_VERSION >= 50200)\n-#include \"rocm/include/rccl/rccl.h\"\n-#else\n-#include \"rocm/include/rccl.h\"\n-#endif  // TF_ROCM_VERSION >= 50200\n-#else\n-#include \"third_party/nccl/nccl.h\"\n-#endif  // TENSORFLOW_USE_ROCM\n-\n namespace xla::gpu {\n \n static ncclComm_t Cast(const Communicator* comm) {\n@@ -343,7 +334,8 @@ class NcclIdStore {\n         device_to_node_(std::move(device_to_node)),\n         kv_store_(std::move(kv_store)) {}\n \n-  absl::StatusOr<CliqueId> GetNcclUniqueId(const CliqueKey& key) {\n+  absl::StatusOr<CliqueId> GetNcclUniqueId(const CliqueKey& key,\n+                                           NcclCollectives& nccl_collectives) {\n     auto* gpu_key = tsl::down_cast<const gpu::GpuCliqueKey*>(&key);\n     if (gpu_key == nullptr) {\n       return InvalidArgument(\"Expected GPU clique key\");\n@@ -362,8 +354,7 @@ class NcclIdStore {\n     CliqueId clique_id;\n     int primary_node_id = device_to_node_.at(gpu_key->root_device());\n     if (node_id_ == primary_node_id) {\n-      TF_ASSIGN_OR_RETURN(\n-          clique_id, gpu::GpuCollectives::Default()->CreateUniqueCliqueId());\n+      TF_ASSIGN_OR_RETURN(clique_id, nccl_collectives.CreateUniqueCliqueId());\n       TF_RETURN_IF_ERROR(\n           kv_store_->Set(gpu_key->ToString(), clique_id.ToString()));\n     } else {\n@@ -399,13 +390,13 @@ absl::Status NcclCollectives::InitializeTopology(\n         topology.node_id, topology.device_id_to_node_id,\n         std::move(topology.kv_store));\n     topology.gpu_executable_run_options->set_clique_id_callback(\n-        [nccl_id_store](const CliqueKey& key) {\n-          return nccl_id_store->GetNcclUniqueId(key);\n+        [nccl_id_store, this](const CliqueKey& key) {\n+          return nccl_id_store->GetNcclUniqueId(key, *this);\n         });\n   }\n   return absl::OkStatus();\n }\n }  // namespace xla::gpu\n \n-XLA_COLLECTIVES_REGISTER(\"gpu\", \"nccl\", 1,\n+XLA_COLLECTIVES_REGISTER(\"CUDA\", \"nccl\", 1,\n                          std::make_unique<xla::gpu::NcclCollectives>());"
        },
        {
            "sha": "3c4b043ad1287d51256471d4575c5439038549cd",
            "filename": "third_party/xla/xla/backends/gpu/collectives/nccl_communicator.cc",
            "status": "modified",
            "additions": 26,
            "deletions": 31,
            "changes": 57,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/base/casts.h\"\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/functional/any_invocable.h\"\n #include \"absl/memory/memory.h\"\n@@ -33,17 +34,18 @@ limitations under the License.\n #include \"absl/strings/str_join.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n+#include \"third_party/gpus/cuda/include/cuda.h\"\n+#include \"third_party/nccl/nccl.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/collectives/gpu_communicator.h\"\n #include \"xla/backends/gpu/collectives/nccl_errors.h\"\n #include \"xla/backends/gpu/collectives/single_threaded_executor.h\"\n #include \"xla/core/collectives/communicator.h\"\n #include \"xla/core/collectives/rank_id.h\"\n+#include \"xla/core/collectives/reduction_kind.h\"\n #include \"xla/future.h\"\n #include \"xla/primitive_util.h\"\n-#include \"xla/service/collective_ops_utils.h\"\n #include \"xla/stream_executor/device_address.h\"\n-#include \"xla/stream_executor/gpu/gpu_stream.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/concurrency/executor.h\"\n@@ -54,20 +56,13 @@ limitations under the License.\n #include \"xla/util.h\"\n #include \"tsl/platform/casts.h\"\n \n-#if TENSORFLOW_USE_ROCM\n-#include \"rocm/rocm_config.h\"\n-#if (TF_ROCM_VERSION >= 50200)\n-#include \"rocm/include/rccl/rccl.h\"\n-#else\n-#include \"rocm/include/rccl.h\"\n-#endif  // TF_ROCM_VERSION >= 50200\n-#else\n-#include \"third_party/nccl/nccl.h\"\n-#endif  // TENSORFLOW_USE_ROCM\n-\n namespace xla::gpu {\n namespace {\n \n+CUstream AsCudaStream(se::Stream* stream) {\n+  return absl::bit_cast<CUstream>(stream->platform_specific_handle().stream);\n+}\n+\n se::Stream* ToStream(const Communicator::Executor& executor) {\n   return tsl::down_cast<const GpuCollectives::Executor&>(executor).stream();\n }\n@@ -556,7 +551,7 @@ absl::Status NcclCommunicator::LaunchAllReduce(\n   TF_RETURN_IF_ERROR(XLA_NCCL_STATUS(ncclAllReduce(\n       send_buffer.opaque(), recv_buffer.opaque(), ToNcclCount(dtype, count),\n       nccl_dtype, ToNcclReduction(reduction_kind), comm_,\n-      se::gpu::AsGpuStreamValue(stream))));\n+      AsCudaStream(stream))));\n   if (group_nesting_level_ == 0) {\n     TF_RETURN_IF_ERROR(PollUntilDone());\n   }\n@@ -583,7 +578,7 @@ absl::Status NcclCommunicator::LaunchBroadcast(\n \n   TF_RETURN_IF_ERROR(XLA_NCCL_STATUS(ncclBroadcast(\n       send_buffer.opaque(), recv_buffer.opaque(), ToNcclCount(dtype, count),\n-      nccl_dtype, root.value(), comm_, se::gpu::AsGpuStreamValue(stream))));\n+      nccl_dtype, root.value(), comm_, AsCudaStream(stream))));\n   if (group_nesting_level_ == 0) {\n     TF_RETURN_IF_ERROR(PollUntilDone());\n   }\n@@ -612,7 +607,7 @@ absl::Status NcclCommunicator::LaunchReduceScatter(\n   TF_RETURN_IF_ERROR(XLA_NCCL_STATUS(ncclReduceScatter(\n       send_buffer.opaque(), recv_buffer.opaque(), ToNcclCount(dtype, count),\n       nccl_dtype, ToNcclReduction(reduction_kind), comm_,\n-      se::gpu::AsGpuStreamValue(stream))));\n+      AsCudaStream(stream))));\n   if (group_nesting_level_ == 0) {\n     TF_RETURN_IF_ERROR(PollUntilDone());\n   }\n@@ -638,7 +633,7 @@ absl::Status NcclCommunicator::LaunchAllGather(\n \n   TF_RETURN_IF_ERROR(XLA_NCCL_STATUS(ncclAllGather(\n       send_buffer.opaque(), recv_buffer.opaque(), ToNcclCount(dtype, count),\n-      nccl_dtype, comm_, se::gpu::AsGpuStreamValue(stream))));\n+      nccl_dtype, comm_, AsCudaStream(stream))));\n   if (group_nesting_level_ == 0) {\n     TF_RETURN_IF_ERROR(PollUntilDone());\n   }\n@@ -688,13 +683,13 @@ absl::Status NcclCommunicator::LaunchAllToAll(\n     se::DeviceAddressBase send_buffer = send_buffers[i];\n     se::DeviceAddressBase recv_buffer = recv_buffers[i];\n \n-    XLA_NCCL_RETURN_IF_ERROR(\n-        ncclSend(send_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype, i,\n-                 comm_, se::gpu::AsGpuStreamValue(stream)));\n+    XLA_NCCL_RETURN_IF_ERROR(ncclSend(send_buffer.opaque(),\n+                                      ToNcclCount(dtype, count), nccl_dtype, i,\n+                                      comm_, AsCudaStream(stream)));\n \n-    XLA_NCCL_RETURN_IF_ERROR(\n-        ncclRecv(recv_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype, i,\n-                 comm_, se::gpu::AsGpuStreamValue(stream)));\n+    XLA_NCCL_RETURN_IF_ERROR(ncclRecv(recv_buffer.opaque(),\n+                                      ToNcclCount(dtype, count), nccl_dtype, i,\n+                                      comm_, AsCudaStream(stream)));\n   }\n   TF_RETURN_IF_ERROR(GroupEnd());\n   return absl::OkStatus();\n@@ -732,15 +727,15 @@ absl::Status NcclCommunicator::LaunchCollectivePermute(\n   TF_RETURN_IF_ERROR(GroupStart());\n \n   if (source_rank) {\n-    XLA_NCCL_RETURN_IF_ERROR(ncclRecv(\n-        recv_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype,\n-        source_rank->value(), comm_, se::gpu::AsGpuStreamValue(stream)));\n+    XLA_NCCL_RETURN_IF_ERROR(\n+        ncclRecv(recv_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype,\n+                 source_rank->value(), comm_, AsCudaStream(stream)));\n   }\n \n   for (auto target_rank : target_ranks) {\n-    XLA_NCCL_RETURN_IF_ERROR(ncclSend(\n-        send_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype,\n-        target_rank.value(), comm_, se::gpu::AsGpuStreamValue(stream)));\n+    XLA_NCCL_RETURN_IF_ERROR(\n+        ncclSend(send_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype,\n+                 target_rank.value(), comm_, AsCudaStream(stream)));\n   }\n \n   TF_RETURN_IF_ERROR(GroupEnd());\n@@ -768,7 +763,7 @@ absl::Status NcclCommunicator::LaunchSend(se::DeviceAddressBase send_buffer,\n \n   TF_RETURN_IF_ERROR(XLA_NCCL_STATUS(\n       ncclSend(send_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype,\n-               peer.value(), comm_, se::gpu::AsGpuStreamValue(stream))));\n+               peer.value(), comm_, AsCudaStream(stream))));\n   if (group_nesting_level_ == 0) {\n     TF_RETURN_IF_ERROR(PollUntilDone());\n   }\n@@ -795,7 +790,7 @@ absl::Status NcclCommunicator::LaunchRecv(se::DeviceAddressBase recv_buffer,\n \n   TF_RETURN_IF_ERROR(XLA_NCCL_STATUS(\n       ncclRecv(recv_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype,\n-               peer.value(), comm_, se::gpu::AsGpuStreamValue(stream))));\n+               peer.value(), comm_, AsCudaStream(stream))));\n   if (group_nesting_level_ == 0) {\n     TF_RETURN_IF_ERROR(PollUntilDone());\n   }"
        },
        {
            "sha": "3c1d5cbd805f077360319cff2f6a2c76c1172e24",
            "filename": "third_party/xla/xla/backends/gpu/collectives/nccl_communicator.h",
            "status": "modified",
            "additions": 1,
            "deletions": 13,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.h?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -32,27 +32,15 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n+#include \"third_party/nccl/nccl.h\"\n #include \"xla/backends/gpu/collectives/gpu_communicator.h\"\n #include \"xla/core/collectives/communicator.h\"\n #include \"xla/core/collectives/rank_id.h\"\n #include \"xla/future.h\"\n-#include \"xla/service/collective_ops_utils.h\"\n #include \"xla/stream_executor/device_address.h\"\n-#include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/executor.h\"\n #include \"xla/tsl/platform/env.h\"\n \n-#if TENSORFLOW_USE_ROCM\n-#include \"rocm/rocm_config.h\"\n-#if (TF_ROCM_VERSION >= 50200)\n-#include \"rocm/include/rccl/rccl.h\"\n-#else\n-#include \"rocm/include/rccl.h\"\n-#endif  // TF_ROCM_VERSION >= 50200\n-#else\n-#include \"third_party/nccl/nccl.h\"\n-#endif  // TENSORFLOW_USE_ROCM\n-\n namespace xla::gpu {\n \n // XLA collectives communicator wrapping an NCCL communicator."
        },
        {
            "sha": "bc0e49a2a907958bebd16180afce6c426df2de97",
            "filename": "third_party/xla/xla/backends/gpu/collectives/nccl_communicator_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 12,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator_test.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -26,25 +26,15 @@ limitations under the License.\n #include \"absl/status/status_matchers.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"third_party/nccl/nccl.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/collectives/nccl_errors.h\"\n #include \"xla/core/collectives/rank_id.h\"\n+#include \"xla/core/collectives/reduction_kind.h\"\n #include \"xla/future.h\"\n-#include \"xla/service/collective_ops_utils.h\"\n #include \"xla/stream_executor/device_address.h\"\n #include \"xla/tsl/platform/errors.h\"\n \n-#if TENSORFLOW_USE_ROCM\n-#include \"rocm/rocm_config.h\"\n-#if (TF_ROCM_VERSION >= 50200)\n-#include \"rocm/include/rccl/rccl.h\"\n-#else\n-#include \"rocm/include/rccl.h\"\n-#endif  // TF_ROCM_VERSION >= 50200\n-#else\n-#include \"third_party/nccl/nccl.h\"\n-#endif  // TENSORFLOW_USE_ROCM\n-\n namespace xla::gpu {\n namespace {\n "
        },
        {
            "sha": "4716280de16b6bb8a73e483beecbeece3ce2d485",
            "filename": "third_party/xla/xla/backends/gpu/collectives/nccl_errors.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 11,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_errors.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_errors.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_errors.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -20,18 +20,8 @@ limitations under the License.\n #include \"absl/log/log.h\"\n #include \"absl/time/clock.h\"\n #include \"absl/time/time.h\"\n-#include \"xla/util.h\"\n-\n-#if TENSORFLOW_USE_ROCM\n-#include \"rocm/rocm_config.h\"\n-#if (TF_ROCM_VERSION >= 50200)\n-#include \"rocm/include/rccl/rccl.h\"\n-#else\n-#include \"rocm/include/rccl.h\"\n-#endif  // TF_ROCM_VERSION >= 50200\n-#else\n #include \"third_party/nccl/nccl.h\"\n-#endif  // TENSORFLOW_USE_ROCM\n+#include \"xla/util.h\"\n \n namespace xla::gpu {\n "
        },
        {
            "sha": "5806ebf2e395828da43f08eb683b2ff4c3e34588",
            "filename": "third_party/xla/xla/backends/gpu/collectives/nccl_errors.h",
            "status": "modified",
            "additions": 1,
            "deletions": 13,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_errors.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_errors.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_errors.h?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -19,20 +19,8 @@ limitations under the License.\n #include <atomic>\n \n #include \"absl/status/status.h\"\n-#include \"absl/strings/str_format.h\"  // IWYU pragma: keep\n-#include \"xla/tsl/platform/logging.h\"  // IWYU pragma: keep\n-#include \"xla/util.h\"  // IWYU pragma: keep\n-                                                       //\n-#if TENSORFLOW_USE_ROCM\n-#include \"rocm/rocm_config.h\"\n-#if (TF_ROCM_VERSION >= 50200)\n-#include \"rocm/include/rccl/rccl.h\"\n-#else\n-#include \"rocm/include/rccl.h\"\n-#endif  // TF_ROCM_VERSION >= 50200\n-#else\n #include \"third_party/nccl/nccl.h\"\n-#endif  // TENSORFLOW_USE_ROCM\n+#include \"xla/tsl/platform/logging.h\"\n \n //===----------------------------------------------------------------------===//\n // Collection of helper macros for handling NCCL errors."
        },
        {
            "sha": "df73c5b8b0e892e720437f1147548db8229d1477",
            "filename": "third_party/xla/xla/backends/gpu/collectives/nvshmem_collectives.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnvshmem_collectives.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnvshmem_collectives.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnvshmem_collectives.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -48,7 +48,7 @@ bool NvshmemCollectives::IsInitialized() const {\n \n NvshmemCollectives* NvshmemCollectives::Default() {\n   absl::StatusOr<Collectives*> collectives =\n-      CollectivesRegistry::Get(\"gpu\", \"nvshmem\");\n+      CollectivesRegistry::Get(\"CUDA\", \"nvshmem\");\n   CHECK_OK(collectives) << \"Failed to get NVSHMEM collectives\";  // Crash OK\n \n   if (auto* nvshmem_collectives =\n@@ -98,5 +98,5 @@ NvshmemCollectives::CreateCommunicator() {\n \n // NvshmemCollectives currently does not implement GpuCollectives, so it cannot\n // be used as a host-side collectives library. Therefore, set priority to -100.\n-XLA_COLLECTIVES_REGISTER(\"gpu\", \"nvshmem\", -100,\n+XLA_COLLECTIVES_REGISTER(\"CUDA\", \"nvshmem\", -100,\n                          std::make_unique<xla::gpu::NvshmemCollectives>());"
        },
        {
            "sha": "585302fa25fb3ebaaa73e6a8f02c5b2304da059e",
            "filename": "third_party/xla/xla/backends/gpu/collectives/nvshmem_communicator.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 34,
            "changes": 66,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnvshmem_communicator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnvshmem_communicator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnvshmem_communicator.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -16,11 +16,13 @@ limitations under the License.\n #include <cstdint>\n #include <string>\n \n+#include \"absl/base/casts.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"third_party/gpus/cuda/include/cuda.h\"\n #include \"third_party/gpus/cuda/include/cuda_bf16.h\"\n #include \"third_party/gpus/cuda/include/cuda_fp16.h\"\n #include \"third_party/nvshmem/nvshmem.h\"   // IWYU pragma: keep\n@@ -29,11 +31,10 @@ limitations under the License.\n #include \"xla/backends/gpu/collectives/nvshmem_collectives.h\"\n #include \"xla/core/collectives/communicator.h\"\n #include \"xla/core/collectives/rank_id.h\"\n+#include \"xla/core/collectives/reduction_kind.h\"\n #include \"xla/future.h\"\n #include \"xla/primitive_util.h\"\n-#include \"xla/service/collective_ops_utils.h\"\n #include \"xla/stream_executor/device_address.h\"\n-#include \"xla/stream_executor/gpu/gpu_stream.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -47,10 +48,14 @@ namespace xla::gpu {\n // NVSHMEM Utility Functions\n //==-----------------------------------------------------------------------===//\n \n-size_t ToRealCount(PrimitiveType dtype, size_t count) {\n+static size_t ToRealCount(PrimitiveType dtype, size_t count) {\n   return primitive_util::IsComplexType(dtype) ? count * 2 : count;\n }\n \n+static CUstream AsCudaStream(se::Stream* stream) {\n+  return absl::bit_cast<CUstream>(stream->platform_specific_handle().stream);\n+}\n+\n //==-----------------------------------------------------------------------===//\n // NVSHMEM Templated APIs\n //==-----------------------------------------------------------------------===//\n@@ -130,7 +135,7 @@ size_t ToRealCount(PrimitiveType dtype, size_t count) {\n                          num_elements, stream)                            \\\n   nvshmemx_##TYPENAME##_##op##_nbi_on_stream(                             \\\n       (TYPE*)dest_ptr, (const TYPE*)source_ptr, num_elements, pe.value(), \\\n-      se::gpu::AsGpuStreamValue(stream))\n+      AsCudaStream(stream))\n \n //==-----------------------------------------------------------------------===//\n // NVSHMEM Communicator\n@@ -169,7 +174,7 @@ absl::Status NvshmemCommunicator::Barrier(\n \n   TF_ASSIGN_OR_RETURN(se::Stream * stream, ToStream(executor));\n \n-  auto gpu_stream = se::gpu::AsGpuStreamValue(stream);\n+  auto gpu_stream = AsCudaStream(stream);\n \n   if (nvshmemx_barrier_on_stream(NVSHMEM_TEAM_SHARED, gpu_stream) != 0) {\n     return absl::InternalError(\"Nvshmem team barrier failed.\");\n@@ -239,69 +244,62 @@ Future<> NvshmemCommunicator::AllReduce(\n   switch (dtype) {\n     case PrimitiveType::F64: {\n       CALL_NVSHMEM_REDUCTION_DATATYPE(double, double, NVSHMEM_TEAM_SHARED,\n-                                      se::gpu::AsGpuStreamValue(stream),\n-                                      reduction_kind, source_ptr, dest_ptr,\n-                                      count);\n+                                      AsCudaStream(stream), reduction_kind,\n+                                      source_ptr, dest_ptr, count);\n       break;\n     }\n     case PrimitiveType::F16: {\n-      CALL_NVSHMEM_REDUCTION_DATATYPE(\n-          half, __half, NVSHMEM_TEAM_SHARED, se::gpu::AsGpuStreamValue(stream),\n-          reduction_kind, source_ptr, dest_ptr, count);\n+      CALL_NVSHMEM_REDUCTION_DATATYPE(half, __half, NVSHMEM_TEAM_SHARED,\n+                                      AsCudaStream(stream), reduction_kind,\n+                                      source_ptr, dest_ptr, count);\n       break;\n     }\n     case PrimitiveType::F32: {\n-      CALL_NVSHMEM_REDUCTION_DATATYPE(\n-          float, float, NVSHMEM_TEAM_SHARED, se::gpu::AsGpuStreamValue(stream),\n-          reduction_kind, source_ptr, dest_ptr, count);\n+      CALL_NVSHMEM_REDUCTION_DATATYPE(float, float, NVSHMEM_TEAM_SHARED,\n+                                      AsCudaStream(stream), reduction_kind,\n+                                      source_ptr, dest_ptr, count);\n       break;\n     }\n     case PrimitiveType::BF16: {\n       CALL_NVSHMEM_REDUCTION_DATATYPE(\n-          bfloat16, __nv_bfloat16, NVSHMEM_TEAM_SHARED,\n-          se::gpu::AsGpuStreamValue(stream), reduction_kind, source_ptr,\n-          dest_ptr, count);\n+          bfloat16, __nv_bfloat16, NVSHMEM_TEAM_SHARED, AsCudaStream(stream),\n+          reduction_kind, source_ptr, dest_ptr, count);\n       break;\n     }\n     case PrimitiveType::S32: {\n       CALL_NVSHMEM_BITWISE_REDUCTION_DATATYPE(\n-          int32, int32_t, NVSHMEM_TEAM_SHARED,\n-          se::gpu::AsGpuStreamValue(stream), reduction_kind, source_ptr,\n-          dest_ptr, count);\n+          int32, int32_t, NVSHMEM_TEAM_SHARED, AsCudaStream(stream),\n+          reduction_kind, source_ptr, dest_ptr, count);\n       break;\n     }\n     case PrimitiveType::S64: {\n       CALL_NVSHMEM_BITWISE_REDUCTION_DATATYPE(\n-          int64, int64_t, NVSHMEM_TEAM_SHARED,\n-          se::gpu::AsGpuStreamValue(stream), reduction_kind, source_ptr,\n-          dest_ptr, count);\n+          int64, int64_t, NVSHMEM_TEAM_SHARED, AsCudaStream(stream),\n+          reduction_kind, source_ptr, dest_ptr, count);\n       break;\n     }\n     case PrimitiveType::U32: {\n       CALL_NVSHMEM_BITWISE_REDUCTION_DATATYPE(\n-          uint32, uint32_t, NVSHMEM_TEAM_SHARED,\n-          se::gpu::AsGpuStreamValue(stream), reduction_kind, source_ptr,\n-          dest_ptr, count);\n+          uint32, uint32_t, NVSHMEM_TEAM_SHARED, AsCudaStream(stream),\n+          reduction_kind, source_ptr, dest_ptr, count);\n       break;\n     }\n     case PrimitiveType::U64: {\n       CALL_NVSHMEM_BITWISE_REDUCTION_DATATYPE(\n-          uint64, uint64_t, NVSHMEM_TEAM_SHARED,\n-          se::gpu::AsGpuStreamValue(stream), reduction_kind, source_ptr,\n-          dest_ptr, count);\n+          uint64, uint64_t, NVSHMEM_TEAM_SHARED, AsCudaStream(stream),\n+          reduction_kind, source_ptr, dest_ptr, count);\n       break;\n     }\n     case PrimitiveType::PRED:\n     case PrimitiveType::U8: {\n       CALL_NVSHMEM_BITWISE_REDUCTION_DATATYPE(\n-          uint8, uint8_t, NVSHMEM_TEAM_SHARED,\n-          se::gpu::AsGpuStreamValue(stream), reduction_kind, source_ptr,\n-          dest_ptr, count);\n+          uint8, uint8_t, NVSHMEM_TEAM_SHARED, AsCudaStream(stream),\n+          reduction_kind, source_ptr, dest_ptr, count);\n       break;\n     }\n     case PrimitiveType::S8: {\n       CALL_NVSHMEM_BITWISE_REDUCTION_DATATYPE(\n-          int8, int8_t, NVSHMEM_TEAM_SHARED, se::gpu::AsGpuStreamValue(stream),\n+          int8, int8_t, NVSHMEM_TEAM_SHARED, AsCudaStream(stream),\n           reduction_kind, source_ptr, dest_ptr, count);\n       break;\n     }\n@@ -492,7 +490,7 @@ absl::Status NvshmemCommunicator::Quiet(const Executor& executor) {\n   }\n \n   TF_ASSIGN_OR_RETURN(se::Stream * stream, ToStream(executor));\n-  nvshmemx_quiet_on_stream(se::gpu::AsGpuStreamValue(stream));\n+  nvshmemx_quiet_on_stream(AsCudaStream(stream));\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "974e36d9b4916a8af2a8cb980dc6fe4cfac818ff",
            "filename": "third_party/xla/xla/backends/gpu/collectives/rccl_collectives.cc",
            "status": "added",
            "additions": 407,
            "deletions": 0,
            "changes": 407,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_collectives.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_collectives.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_collectives.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -0,0 +1,407 @@\n+/* Copyright 2024 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/collectives/rccl_collectives.h\"\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <cstdlib>\n+#include <functional>\n+#include <memory>\n+#include <optional>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/algorithm/container.h\"\n+#include \"absl/base/call_once.h\"\n+#include \"absl/base/thread_annotations.h\"\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_format.h\"\n+#include \"absl/strings/str_join.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/synchronization/mutex.h\"\n+#include \"absl/time/time.h\"\n+#include \"absl/types/span.h\"\n+#include \"rocm/rocm_config.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n+#include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n+#include \"xla/backends/gpu/collectives/rccl_communicator.h\"\n+#include \"xla/backends/gpu/collectives/rccl_errors.h\"\n+#include \"xla/core/collectives/clique_id.h\"\n+#include \"xla/core/collectives/clique_key.h\"\n+#include \"xla/core/collectives/collectives.h\"\n+#include \"xla/core/collectives/collectives_registry.h\"\n+#include \"xla/core/collectives/communicator.h\"\n+#include \"xla/core/collectives/rank_id.h\"\n+#include \"xla/debug_options_flags.h\"\n+#include \"xla/pjrt/distributed/key_value_store_interface.h\"\n+#include \"xla/runtime/device_id.h\"\n+#include \"xla/service/gpu/gpu_executable_run_options.h\"\n+#include \"xla/status_macros.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/platform/env.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/logging.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/threadpool.h\"\n+#include \"xla/util.h\"\n+#include \"tsl/platform/casts.h\"\n+#include \"tsl/platform/numbers.h\"\n+\n+#if (TF_ROCM_VERSION >= 50200)\n+#include \"rocm/include/rccl/rccl.h\"\n+#else\n+#include \"rocm/include/rccl.h\"\n+#endif  // TF_ROCM_VERSION >= 50200\n+\n+namespace xla::gpu {\n+\n+static ncclComm_t Cast(const Communicator* comm) {\n+  auto* nccl_communicator = tsl::down_cast<const RcclCommunicator*>(comm);\n+  CHECK(nccl_communicator != nullptr) << \"Unsupported XLA communicator\";\n+  return nccl_communicator->comm();\n+}\n+\n+absl::StatusOr<CliqueId> RcclCollectives::CreateUniqueCliqueId() const {\n+  VLOG(3) << \"Create NCCL unique clique id\";\n+  ncclUniqueId id;\n+  XLA_RCCL_RETURN_IF_ERROR(ncclGetUniqueId(&id));\n+  return CliqueId(absl::string_view(id.internal, NCCL_UNIQUE_ID_BYTES));\n+}\n+\n+bool RcclCollectives::IsGlobalConfig() const {\n+  static const char* const nccl_comm_id = std::getenv(\"NCCL_COMM_ID\");\n+  return nccl_comm_id != nullptr;\n+}\n+\n+absl::StatusOr<const RcclCollectives::CliqueIdCallback*>\n+RcclCollectives::GetCliqueIdCallback(const CliqueIdCallback* clique_id_callback,\n+                                     bool is_local) {\n+  if (clique_id_callback != nullptr) {\n+    return clique_id_callback;\n+  }\n+\n+  TF_RET_CHECK(is_local || IsGlobalConfig())\n+      << \"If non-local devices are taking part of a collective API on \"\n+         \"GPU, the clique_id_callback must be provided by the client.\";\n+\n+  static auto* const local_callback = new CliqueIdCallback(\n+      [this](const CliqueKey&) { return CreateUniqueCliqueId(); });\n+  return local_callback;\n+}\n+\n+static absl::StatusOr<ncclConfig_t> AsRcclConfig(\n+    const GpuCollectives::Config& config,\n+    const se::StreamExecutor* stream_executor) {\n+  ncclConfig_t comm_config = NCCL_CONFIG_INITIALIZER;\n+  comm_config.blocking = config.blocking_communicators ? 1 : 0;\n+#if !defined(TENSORFLOW_USE_ROCM) || TF_ROCM_VERSION > 50700\n+  comm_config.splitShare = config.split_share;\n+#endif\n+  int nccl_version;\n+  XLA_RCCL_RETURN_IF_ERROR(ncclGetVersion(&nccl_version));\n+  if (config.max_nchannels > 0) {\n+    VLOG(1) << \"Maximum number of channels is set to: \" << comm_config.maxCTAs;\n+    comm_config.maxCTAs = config.max_nchannels;\n+  } else if (stream_executor->GetDeviceDescription()\n+                 .cuda_compute_capability()\n+                 .IsBlackwell() &&\n+             nccl_version >= NCCL_VERSION(2, 28, 0)) {\n+    // Future NCCL versions will reduce the default max number of channels on\n+    // Blackwell to 16. We need to manually set it to 32 here to avoid surprise\n+    // perf regressions.\n+    VLOG(1) << \"Setting max number of channels to 32 on Blackwell.\";\n+    comm_config.maxCTAs = 32;\n+  }\n+  return comm_config;\n+}\n+\n+static absl::StatusOr<ncclUniqueId> AsRcclUniqueId(const CliqueId& clique_id) {\n+  if (clique_id.size() != NCCL_UNIQUE_ID_BYTES) {\n+    return Internal(\n+        \"CliqueId size is not equal to NCCL_UNIQUE_ID_BYTES: %d vs %d\",\n+        clique_id.size(), NCCL_UNIQUE_ID_BYTES);\n+  }\n+  ncclUniqueId id;\n+  absl::c_copy(clique_id.data(), id.internal);\n+  return id;\n+}\n+\n+absl::StatusOr<std::vector<std::unique_ptr<Communicator>>>\n+RcclCollectives::CreateCommunicatorsWithCancel(\n+    const CliqueKey& clique_key, const std::optional<CliqueIds>& clique_ids,\n+    absl::Span<const DeviceRank> ranks, const Collectives::Config& config,\n+    std::atomic_bool* cancel) {\n+  // Validate clique ids. With the NCCL backend, we rely on the host to exchange\n+  // unique clique ids.\n+  if (!clique_ids.has_value() || clique_ids->data().empty()) {\n+    return InvalidArgument(\"CliqueId is required to create NCCL communicators\");\n+  }\n+  if (clique_ids->data().size() != 1) {\n+    return InvalidArgument(\n+        \"CliqueIds size must be 1 for NCCL communicator initialization\");\n+  }\n+  VLOG(1) << \"Initialize NCCL communicator for \" << ranks.size() << \" devices\"\n+          << \"; fingerprint(id)=\" << clique_ids->fingerprint();\n+\n+  const auto& gpu_config =\n+      tsl::down_cast<const GpuCollectives::Config&>(config);\n+  if (!gpu_config.blocking_communicators && !gpu_config.async_execution) {\n+    return FailedPrecondition(\n+        \"GpuCollectives::Config blocking_communicators is false, but \"\n+        \"async_execution is false. Non-blocking communicators require \"\n+        \"asynchronous execution.\");\n+  }\n+\n+  // make_comm returns a new ncclComm_t.\n+  auto make_comm = [&](int i) -> absl::StatusOr<ncclComm_t> {\n+    VLOG(1) << \"Initialize NCCL communicator for rank #\" << ranks[i].rank\n+            << \" of \" << clique_key.num_devices()\n+            << \"; fingerprint(id)=\" << clique_ids->fingerprint()\n+            << \"; size(id)=\" << clique_ids->data().size();\n+    auto* device = tsl::down_cast<GpuCollectives::Device*>(ranks[i].device);\n+    TF_RET_CHECK(device != nullptr);\n+    auto activate_context = device->stream_executor()->Activate();\n+\n+    TF_ASSIGN_OR_RETURN(ncclConfig_t comm_config,\n+                        AsRcclConfig(gpu_config, device->stream_executor()));\n+\n+    TF_ASSIGN_OR_RETURN(auto nccl_unique_id, AsRcclUniqueId(clique_ids->at(0)));\n+    ncclComm_t comm;\n+    XLA_RCCL_RETURN_IF_ERROR(\n+        ncclCommInitRankConfig(&comm, clique_key.num_devices(), nccl_unique_id,\n+                               ranks[i].rank.value(), &comm_config));\n+    return comm;\n+  };\n+\n+  // Create all communicators. Each communicator is created on its own thread.\n+  std::vector<std::unique_ptr<Communicator>> comms(ranks.size());\n+  absl::Status status;\n+  absl::once_flag once;\n+  {\n+    tsl::thread::ThreadPool pool(tsl::Env::Default(), \"CreateCommunicators\",\n+                                 ranks.size());\n+    for (size_t i = 0; i < ranks.size(); ++i) {\n+      pool.Schedule([&, i]() {\n+        absl::StatusOr<std::unique_ptr<RcclCommunicator>> comm =\n+            RcclCommunicator::Create(std::bind(make_comm, i),\n+                                     gpu_config.async_execution, cancel);\n+        if (!comm.ok()) {\n+          absl::call_once(once, [&] { status = comm.status(); });\n+          return;\n+        }\n+        comms[i] = *std::move(comm);\n+      });\n+    }\n+  }  // pool's destructor blocks until all scheduled work is done.\n+  TF_RETURN_IF_ERROR(status);\n+  return comms;\n+}\n+\n+absl::StatusOr<std::vector<std::unique_ptr<Communicator>>>\n+RcclCollectives::SplitCommunicatorsWithCancel(\n+    absl::Span<const Communicator* const> comms, int32_t color,\n+    absl::Span<const RankId> keys, const Collectives::Config& config,\n+    absl::Span<const DeviceRank> ranks, std::atomic_bool* cancel) {\n+  auto rank_formatter = [](std::string* str, RankId rank) {\n+    absl::StrAppend(str, rank.value());\n+  };\n+\n+  VLOG(1) << absl::StreamFormat(\n+      \"Split %d NCCL communicators using color %d and keys: [%s]\", comms.size(),\n+      color, absl::StrJoin(keys, \",\", rank_formatter));\n+\n+  if (keys.size() != comms.size()) {\n+    return absl::InvalidArgumentError(\n+        absl::StrFormat(\"Comms and keys must have the same size, but %d != %d\",\n+                        comms.size(), keys.size()));\n+  }\n+\n+  const auto& gpu_config =\n+      tsl::down_cast<const GpuCollectives::Config&>(config);\n+\n+#if !defined(TENSORFLOW_USE_ROCM) || TF_ROCM_VERSION >= 60000\n+  auto make_comm = [&](int i) -> absl::StatusOr<ncclComm_t> {\n+    auto* device = tsl::down_cast<GpuCollectives::Device*>(ranks[i].device);\n+    TF_RET_CHECK(device != nullptr);\n+\n+    TF_ASSIGN_OR_RETURN(ncclConfig_t comm_config,\n+                        AsRcclConfig(gpu_config, device->stream_executor()));\n+\n+    VLOG(1) << \"Split NCCL communicator \" << comms[i] << \" with color \" << color\n+            << \" and key \" << keys[i];\n+    ncclComm_t split_comm;\n+    XLA_RCCL_RETURN_IF_ERROR(ncclCommSplit(\n+        Cast(comms[i]), color, keys[i].value(), &split_comm, &comm_config));\n+    return split_comm;\n+  };\n+\n+  std::vector<std::unique_ptr<Communicator>> split_comms(comms.size());\n+  absl::Status status;\n+  absl::once_flag once;\n+  {\n+    tsl::thread::ThreadPool pool(tsl::Env::Default(), \"SplitCommunicators\",\n+                                 comms.size());\n+    for (size_t i = 0; i < comms.size(); ++i) {\n+      pool.Schedule([&, i]() {\n+        absl::StatusOr<std::unique_ptr<RcclCommunicator>> comm =\n+            RcclCommunicator::Create(std::bind(make_comm, i),\n+                                     gpu_config.async_execution, cancel);\n+        if (!comm.ok()) {\n+          absl::call_once(once, [&] { status = comm.status(); });\n+          return;\n+        }\n+        split_comms[i] = *std::move(comm);\n+      });\n+    }\n+  }  // pool's destructor blocks until all scheduled work is done.\n+  TF_RETURN_IF_ERROR(status);\n+  return split_comms;\n+#else\n+  return absl::UnimplementedError(\n+      absl::StrFormat(\"%s:%d: NCCL operation ncclCommSplit not implemented\",\n+                      __FILE__, __LINE__));\n+#endif  // !defined(TENSORFLOW_USE_ROCM) || TF_ROCM_VERSION >= 60000\n+}\n+\n+static absl::StatusOr<xla::gpu::GpuCollectives*> GetNvshmemCollectives() {\n+  TF_ASSIGN_OR_RETURN(xla::Collectives * collectives,\n+                      xla::CollectivesRegistry::Get(\"gpu\", \"nvshmem\"));\n+  xla::gpu::GpuCollectives* nvshmem_collectives =\n+      tsl::down_cast<xla::gpu::GpuCollectives*>(collectives);\n+  if (nvshmem_collectives == nullptr) {\n+    return absl::InternalError(\"Failed to get NVSHMEM collectives\");\n+  }\n+\n+  return nvshmem_collectives;\n+}\n+\n+absl::StatusOr<void*> RcclCollectives::Allocate(uint64_t bytes) {\n+  if (xla::GetDebugOptionsFromFlags().xla_gpu_experimental_enable_nvshmem()) {\n+    TF_ASSIGN_OR_RETURN(auto* nvshmem_collectives, GetNvshmemCollectives());\n+    return nvshmem_collectives->Allocate(bytes);\n+  }\n+\n+  void* ptr = nullptr;\n+  ncclResult_t res = ncclMemAlloc(&ptr, bytes);\n+  if (res != ncclSuccess) {\n+    return absl::InternalError(absl::StrFormat(\n+        \"failed to allocate %s (%llu bytes) from device collective memory: %s, \"\n+        \"Last NCCL warning(error) log entry (may be unrelated): %s\",\n+        tsl::strings::HumanReadableNumBytes(bytes), bytes,\n+        ncclGetErrorString(res), ncclGetLastError(nullptr)));\n+  }\n+  VLOG(2) << \"Allocated collective memory \" << ptr << \" of \" << bytes\n+          << \" bytes\";\n+  return ptr;\n+}\n+\n+absl::Status RcclCollectives::Deallocate(void* location) {\n+  if (xla::GetDebugOptionsFromFlags().xla_gpu_experimental_enable_nvshmem()) {\n+    TF_ASSIGN_OR_RETURN(auto* nvshmem_collectives, GetNvshmemCollectives());\n+    return nvshmem_collectives->Deallocate(location);\n+  }\n+\n+  ncclResult_t res = ncclMemFree(location);\n+  if (res != ncclSuccess) {\n+    return absl::InternalError(absl::StrFormat(\n+        \"failed to free device collective memory at %p; result: %s, Last NCCL \"\n+        \"warning(error) log entry (may be unrelated): %s\",\n+        location, ncclGetErrorString(res), ncclGetLastError(nullptr)));\n+  }\n+\n+  VLOG(2) << \"Deallocated collective memory \" << location;\n+  return absl::OkStatus();\n+}\n+\n+class RcclIdStore {\n+ public:\n+  RcclIdStore(int node_id,\n+              absl::flat_hash_map<GlobalDeviceId, int> device_to_node,\n+              std::shared_ptr<KeyValueStoreInterface> kv_store)\n+      : node_id_(node_id),\n+        device_to_node_(std::move(device_to_node)),\n+        kv_store_(std::move(kv_store)) {}\n+\n+  absl::StatusOr<CliqueId> GetRcclUniqueId(const CliqueKey& key,\n+                                           RcclCollectives& rccl_collectives) {\n+    auto* gpu_key = tsl::down_cast<const gpu::GpuCliqueKey*>(&key);\n+    if (gpu_key == nullptr) {\n+      return InvalidArgument(\"Expected GPU clique key\");\n+    }\n+\n+    // The caller must ensure that threads calling this method concurrently have\n+    // unique keys, otherwise the global key-value store may hold the wrong\n+    // value.\n+    {\n+      absl::MutexLock lock(mu_);\n+      auto it = cache_.find(*gpu_key);\n+      if (it != cache_.end()) {\n+        return it->second;\n+      }\n+    }\n+    CliqueId clique_id;\n+    int primary_node_id = device_to_node_.at(gpu_key->root_device());\n+    if (node_id_ == primary_node_id) {\n+      TF_ASSIGN_OR_RETURN(clique_id, rccl_collectives.CreateUniqueCliqueId());\n+      TF_RETURN_IF_ERROR(\n+          kv_store_->Set(gpu_key->ToString(), clique_id.ToString()));\n+    } else {\n+      TF_ASSIGN_OR_RETURN(\n+          std::string id_str,\n+          kv_store_->Get(gpu_key->ToString(), absl::Minutes(10)));\n+      clique_id = CliqueId(id_str);\n+    }\n+    absl::MutexLock lock(mu_);\n+    auto result = cache_.emplace(*gpu_key, std::move(clique_id));\n+    TF_RET_CHECK(result.second) << \"Unique ID already in cache.\";\n+    return result.first->second;\n+  }\n+\n+ private:\n+  const int node_id_;\n+  const absl::flat_hash_map<GlobalDeviceId, int> device_to_node_;\n+  const std::shared_ptr<KeyValueStoreInterface> kv_store_;\n+\n+  absl::Mutex mu_;\n+  absl::flat_hash_map<gpu::GpuCliqueKey, CliqueId> cache_ ABSL_GUARDED_BY(mu_);\n+};\n+\n+absl::Status RcclCollectives::InitializeTopology(\n+    RcclCollectives::Topology topology) {\n+  if (xla::GetDebugOptionsFromFlags().xla_gpu_experimental_enable_nvshmem()) {\n+    TF_ASSIGN_OR_RETURN(auto* nvshmem_collectives, GetNvshmemCollectives());\n+    TF_RETURN_IF_ERROR(nvshmem_collectives->InitializeTopology(topology));\n+  }\n+\n+  if (topology.num_nodes > 1) {\n+    auto nccl_id_store = std::make_shared<RcclIdStore>(\n+        topology.node_id, topology.device_id_to_node_id,\n+        std::move(topology.kv_store));\n+    topology.gpu_executable_run_options->set_clique_id_callback(\n+        [nccl_id_store, this](const CliqueKey& key) {\n+          return nccl_id_store->GetRcclUniqueId(key, *this);\n+        });\n+  }\n+  return absl::OkStatus();\n+}\n+}  // namespace xla::gpu\n+\n+XLA_COLLECTIVES_REGISTER(\"ROCM\", \"nccl\", 1,\n+                         std::make_unique<xla::gpu::RcclCollectives>());"
        },
        {
            "sha": "0b7f274686a0617fd85e2754e0605925d15a55c9",
            "filename": "third_party/xla/xla/backends/gpu/collectives/rccl_collectives.h",
            "status": "added",
            "additions": 93,
            "deletions": 0,
            "changes": 93,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_collectives.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_collectives.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_collectives.h?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -0,0 +1,93 @@\n+/* Copyright 2024 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_COLLECTIVES_RCCL_COLLECTIVES_H_\n+#define XLA_BACKENDS_GPU_COLLECTIVES_RCCL_COLLECTIVES_H_\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include <optional>\n+#include <vector>\n+\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/types/span.h\"\n+#include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n+#include \"xla/core/collectives/clique_id.h\"\n+#include \"xla/core/collectives/clique_key.h\"\n+#include \"xla/core/collectives/collectives.h\"\n+#include \"xla/core/collectives/communicator.h\"\n+#include \"xla/core/collectives/rank_id.h\"\n+\n+namespace xla::gpu {\n+\n+// XLA host-initiated collectives implemented on top of NCCL.\n+class RcclCollectives : public GpuCollectives {\n+ public:\n+  bool IsImplemented() const final { return true; }\n+\n+  bool IsGlobalConfig() const final;\n+\n+  absl::StatusOr<const CliqueIdCallback*> GetCliqueIdCallback(\n+      const CliqueIdCallback* clique_id_callback, bool is_local) final;\n+\n+  absl::StatusOr<CliqueId> CreateUniqueCliqueId() const final;\n+\n+  absl::StatusOr<std::vector<std::unique_ptr<Communicator>>>\n+  CreateCommunicators(const CliqueKey& clique_key,\n+                      const std::optional<CliqueIds>& clique_ids,\n+                      absl::Span<const DeviceRank> ranks,\n+                      const Collectives::Config& config) final {\n+    return CreateCommunicatorsWithCancel(clique_key, clique_ids, ranks, config,\n+                                         nullptr);\n+  }\n+\n+  absl::StatusOr<std::vector<std::unique_ptr<Communicator>>>\n+  CreateCommunicatorsWithCancel(const CliqueKey& clique_key,\n+                                const std::optional<CliqueIds>& clique_ids,\n+                                absl::Span<const DeviceRank> ranks,\n+                                const Collectives::Config& config,\n+                                std::atomic_bool* cancel) final;\n+\n+  absl::StatusOr<std::vector<std::unique_ptr<Communicator>>> SplitCommunicators(\n+      absl::Span<const Communicator* const> comms, int32_t color,\n+      absl::Span<const RankId> keys, const Collectives::Config& config,\n+      absl::Span<const DeviceRank> ranks) final {\n+    return SplitCommunicatorsWithCancel(comms, color, keys, config, ranks,\n+                                        nullptr);\n+  }\n+\n+  absl::StatusOr<std::vector<std::unique_ptr<Communicator>>>\n+  SplitCommunicatorsWithCancel(absl::Span<const Communicator* const> comms,\n+                               int32_t color, absl::Span<const RankId> keys,\n+                               const Collectives::Config& config,\n+                               absl::Span<const DeviceRank> ranks,\n+                               std::atomic_bool* cancel) final;\n+\n+  absl::StatusOr<std::unique_ptr<Communicator>> CreateCommunicator() final {\n+    return absl::UnimplementedError(\"Not implemented.\");\n+  }\n+\n+  absl::StatusOr<void*> Allocate(uint64_t bytes) final;\n+\n+  absl::Status Deallocate(void* location) final;\n+\n+  absl::Status InitializeTopology(Topology topology) final;\n+};\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_BACKENDS_GPU_COLLECTIVES_RCCL_COLLECTIVES_H_"
        },
        {
            "sha": "1135391d0c43704e7f419ce4a6e0d35e0443dc75",
            "filename": "third_party/xla/xla/backends/gpu/collectives/rccl_communicator.cc",
            "status": "added",
            "additions": 831,
            "deletions": 0,
            "changes": 831,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_communicator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_communicator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_communicator.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -0,0 +1,831 @@\n+/* Copyright 2024 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/collectives/rccl_communicator.h\"\n+\n+#include <atomic>\n+#include <cstddef>\n+#include <cstdint>\n+#include <memory>\n+#include <optional>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/base/casts.h\"\n+#include \"absl/container/inlined_vector.h\"\n+#include \"absl/functional/any_invocable.h\"\n+#include \"absl/memory/memory.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_format.h\"\n+#include \"absl/strings/str_join.h\"\n+#include \"absl/synchronization/mutex.h\"\n+#include \"absl/types/span.h\"\n+#include \"rocm/include/hip/hip_runtime.h\"\n+#include \"rocm/rocm_config.h\"  // IWYU pragma: keep\n+#include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n+#include \"xla/backends/gpu/collectives/gpu_communicator.h\"\n+#include \"xla/backends/gpu/collectives/rccl_errors.h\"\n+#include \"xla/backends/gpu/collectives/single_threaded_executor.h\"\n+#include \"xla/core/collectives/communicator.h\"\n+#include \"xla/core/collectives/rank_id.h\"\n+#include \"xla/core/collectives/reduction_kind.h\"\n+#include \"xla/future.h\"\n+#include \"xla/primitive_util.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/concurrency/executor.h\"\n+#include \"xla/tsl/platform/env.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/logging.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n+#include \"tsl/platform/casts.h\"\n+\n+#if (TF_ROCM_VERSION >= 50200)\n+#include \"rocm/include/rccl/rccl.h\"\n+#else\n+#include \"rocm/include/rccl.h\"\n+#endif  // TF_ROCM_VERSION >= 50200\n+\n+namespace xla::gpu {\n+namespace {\n+\n+hipStream_t AsHipStream(se::Stream* stream) {\n+  return absl::bit_cast<hipStream_t>(stream->platform_specific_handle().stream);\n+}\n+\n+se::Stream* ToStream(const Communicator::Executor& executor) {\n+  return tsl::down_cast<const GpuCollectives::Executor&>(executor).stream();\n+}\n+\n+//==-----------------------------------------------------------------------===//\n+// Conversions between XLA and RCCL data types\n+//==-----------------------------------------------------------------------===//\n+\n+static size_t ToNcclCount(PrimitiveType dtype, size_t count) {\n+  return primitive_util::IsComplexType(dtype) ? count * 2 : count;\n+}\n+\n+static absl::StatusOr<ncclDataType_t> ToNcclDataType(PrimitiveType dtype,\n+                                                     bool is_reduction_op) {\n+  switch (dtype) {\n+    case S8:\n+    case F8E5M2:\n+    case F8E4M3FN:\n+    case F8E5M2FNUZ:\n+    case F8E4M3FNUZ:\n+    case F8E8M0FNU:\n+      return ncclInt8;\n+    case PRED:\n+    case U8:\n+      return ncclUint8;\n+    case S32:\n+      return ncclInt32;\n+    case U32:\n+      return ncclUint32;\n+    case S64:\n+      return ncclInt64;\n+    case U64:\n+      return ncclUint64;\n+    case F16:\n+      return ncclFloat16;\n+    case F32:\n+    case C64:\n+      return ncclFloat32;\n+    case F64:\n+    case C128:\n+      return ncclFloat64;\n+    case S16:\n+    case U16:\n+      // For reductions we expect 16 bit integer types to be promoted to 32-bit.\n+      if (is_reduction_op) {\n+        return absl::InvalidArgumentError(\n+            absl::StrFormat(\"Unsupported data type for reduction operation: %s\",\n+                            primitive_util::LowercasePrimitiveTypeName(dtype)));\n+      }\n+      // For collectives that just move data around, we can use ncclFloat16 for\n+      // 16-bit integer data types.\n+      return ncclFloat16;\n+    case BF16:\n+      return ncclBfloat16;\n+    default:\n+      return absl::InvalidArgumentError(\n+          absl::StrFormat(\"Unsupported data type: %s\",\n+                          primitive_util::LowercasePrimitiveTypeName(dtype)));\n+  }\n+}\n+\n+static ncclRedOp_t ToNcclReduction(ReductionKind kind) {\n+  switch (kind) {\n+    case ReductionKind::SUM:\n+      return ncclSum;\n+    case ReductionKind::PRODUCT:\n+      return ncclProd;\n+    case ReductionKind::MIN:\n+      return ncclMin;\n+    case ReductionKind::MAX:\n+      return ncclMax;\n+  }\n+}\n+\n+}  // namespace\n+\n+//==-----------------------------------------------------------------------===//\n+// RCCL Registered Buffer Handle\n+//==-----------------------------------------------------------------------===//\n+\n+// An RAII handle for user buffers registered with an RCCL communicator.\n+class RcclCommunicator::RcclRegisteredBufferHandle\n+    : public Communicator::RegisteredBufferHandle {\n+ public:\n+  RcclRegisteredBufferHandle(RcclCommunicator& comm, void* handle,\n+                             tsl::Executor* executor, bool symmetric_handle,\n+                             int device_ordinal)\n+      : comm_(comm),\n+        handle_(handle),\n+        symmetric_handle_(symmetric_handle),\n+        device_ordinal_(device_ordinal) {}\n+\n+  ~RcclRegisteredBufferHandle() override {\n+    if (auto status = Unregister(); !status.ok()) {\n+      LOG(ERROR) << status.message();\n+    }\n+  }\n+\n+  absl::Status Unregister() final {\n+    VLOG(3) << absl::StreamFormat(\n+        \"[%d] Deregister buffer for RCCL communicator; handle=%p; comm=%p\",\n+        device_ordinal_, handle_, comm_.comm_);\n+    if (!symmetric_handle_) {\n+#if (NCCL_VERSION_CODE >= 21901)\n+      auto f = [this]() -> absl::Status {\n+        if (comm_.canceling_.load()) {\n+          return FailedPrecondition(\"[%d] RcclCommunicator aborted\",\n+                                    device_ordinal_);\n+        }\n+        XLA_RCCL_RETURN_IF_ERROR(ncclCommDeregister(comm_.comm_, handle_));\n+        return comm_.PollUntilDone();\n+      };\n+      return executor_ ? Future<>::MakeOn(*executor_, f).Await() : f();\n+#else\n+      return Unimplemented(\n+          \"[%d] RCCL version does not support ncclCommDeregister\",\n+          device_ordinal_);\n+#endif  // NCCL_VERSION_CODE >= 21901\n+    } else {\n+      VLOG(3) << absl::StreamFormat(\n+          \"[%d] Deregister symmetric buffer for RCCL communicator; handle=%p; \"\n+          \"comm=%p\",\n+          device_ordinal_, handle_, comm_.comm());\n+#if (NCCL_VERSION_CODE >= 22700)\n+      auto f = [this]() -> absl::Status {\n+        if (comm_.canceling_.load()) {\n+          return FailedPrecondition(\"[%d] RcclCommunicator aborted\",\n+                                    device_ordinal_);\n+        }\n+        XLA_RCCL_RETURN_IF_ERROR(\n+            ncclCommWindowDeregister(comm_.comm_, *(ncclWindow_t*)(handle_)));\n+        return comm_.PollUntilDone();\n+      };\n+      return executor_ ? Future<>::MakeOn(*executor_, f).Await() : f();\n+#else\n+      return Unimplemented(\n+          \"[%d] RCCL version does not support ncclCommWindowDeregister\",\n+          device_ordinal_);\n+#endif  // NCCL_VERSION_CODE >= 22700\n+    }\n+  }\n+\n+ private:\n+  RcclCommunicator& comm_;\n+  void* handle_;\n+  bool symmetric_handle_;\n+  tsl::Executor* executor_;\n+  int device_ordinal_;\n+};\n+\n+//==-----------------------------------------------------------------------===//\n+// RCCL Communicator\n+//==-----------------------------------------------------------------------===//\n+\n+absl::StatusOr<std::unique_ptr<RcclCommunicator>> RcclCommunicator::Create(\n+    absl::AnyInvocable<absl::StatusOr<ncclComm_t>()> make_comm, bool is_async,\n+    std::atomic_bool* cancel, tsl::Env& env) {\n+  auto f = [cancel, &make_comm]() -> absl::StatusOr<ncclComm_t> {\n+    TF_ASSIGN_OR_RETURN(ncclComm_t comm, make_comm());\n+    if (cancel) {\n+      TF_RETURN_IF_ERROR(::xla::gpu::PollUntilDone(comm, *cancel));\n+    } else {\n+      std::atomic_bool never_cancelled;\n+      TF_RETURN_IF_ERROR(::xla::gpu::PollUntilDone(comm, never_cancelled));\n+    }\n+    return comm;\n+  };\n+\n+  if (!is_async) {\n+    // If this RcclCommunicator is synchronous, construct ncclComm_t in the\n+    // calling thread.\n+    TF_ASSIGN_OR_RETURN(ncclComm_t comm, f());\n+    return absl::WrapUnique(new RcclCommunicator(comm, nullptr));\n+  }\n+\n+  // If this RcclCommunicator is asynchronous, then all operations on the\n+  // underlying ncclComm_t, including its creation, must take place on the\n+  // single threaded executor.\n+  auto executor = std::make_unique<SingleThreadedExecutor>(env);\n+  TF_ASSIGN_OR_RETURN(ncclComm_t comm,\n+                      Future<ncclComm_t>::MakeOn(*executor, f).Await());\n+  return absl::WrapUnique(new RcclCommunicator(comm, std::move(executor)));\n+}\n+\n+RcclCommunicator::~RcclCommunicator() {\n+  auto f = [this]() -> absl::Status {\n+    if (comm_ == nullptr) {\n+      VLOG(1) << \"Skipping destruction; null comm_ \" << *this;\n+      return absl::OkStatus();\n+    }\n+\n+    if (aborted_) {\n+      VLOG(1) << \"Skipping destruction; already aborted \" << *this;\n+      return absl::OkStatus();\n+    }\n+\n+    // Note that we intentionally don't call PollUntilDone. Once comm_ has been\n+    // destroyed, we can no longer safely touch it.\n+    VLOG(1) << \"Destroy \" << *this;\n+    return XLA_RCCL_STATUS(ncclCommDestroy(comm_));\n+  };\n+\n+  if (absl::Status s = Execute(f).Await(); !s.ok()) {\n+    LOG(ERROR) << \"RcclCommunicator::~RcclCommunicator: \" << s;\n+  }\n+}\n+\n+absl::Status RcclCommunicator::Abort() {\n+  // By setting canceling_ to true, all pending collectives scheduled on\n+  // executor_ will cancel. This will allow the aborting lambda below to run.\n+  canceling_.store(true);\n+\n+  return ExecuteAwait([this]() -> absl::Status {\n+    VLOG(1) << \"Abort RCCL communicator: \" << *this;\n+    if (aborted_) {\n+      return FailedPrecondition(\"RcclCommunicator already aborted\");\n+    }\n+    aborted_ = true;\n+    // Note that we intentionally don't call PollUntilDone. Once comm_\n+    // has been aborted, we can no longer safely touch it.\n+    return XLA_RCCL_STATUS(ncclCommAbort(comm_));\n+  });\n+}\n+\n+absl::Status RcclCommunicator::HealthCheck() const {\n+  return ExecuteAwait([this]() -> absl::Status {\n+    VLOG(5) << \"Get last async error for RCCL communicator: \" << *this;\n+    if (canceling_.load()) {\n+      return absl::FailedPreconditionError(\"RcclCommunicator aborted\");\n+    }\n+\n+    ncclResult_t async_err;\n+    XLA_RCCL_RETURN_IF_ERROR(ncclCommGetAsyncError(comm_, &async_err));\n+    if (async_err == ncclSuccess) {\n+      return absl::OkStatus();\n+    }\n+\n+    return Internal(\"%s. Last RCCL error (maybe unrelated): %s\",\n+                    ncclGetLastError(comm_), ncclGetErrorString(async_err));\n+  });\n+}\n+\n+absl::StatusOr<size_t> RcclCommunicator::NumRanks() const {\n+  return ExecuteAwait<size_t>([this]() -> absl::StatusOr<size_t> {\n+    VLOG(5) << \"Get the number of ranks in RCCL communicator: \" << *this;\n+    if (canceling_.load()) {\n+      return absl::FailedPreconditionError(\"RcclCommunicator aborted\");\n+    }\n+\n+    // We intentionally don't call PollUntilDone. ncclCommCount is\n+    // blocking.\n+    int32_t count = 0;\n+    XLA_RCCL_RETURN_IF_ERROR(ncclCommCount(comm_, &count));\n+    return count;\n+  });\n+}\n+\n+absl::Status RcclCommunicator::RegisterBufferOnce(\n+    se::DeviceAddressBase buffer_range, int device_ordinal,\n+    bool use_symmetric_buffer) {\n+  bool need_reg = false;\n+  {\n+    absl::MutexLock lock(registered_buffers_.mu);\n+    if (!registered_buffers_.range_to_handle.contains(buffer_range.opaque())) {\n+      need_reg = true;\n+    } else {\n+      XLA_VLOG_DEVICE(5, device_ordinal)\n+          << \"Buffer range: \" << buffer_range.opaque()\n+          << \" with size: \" << buffer_range.size() << \" is already registered.\";\n+    }\n+  }\n+  if (need_reg) {\n+    XLA_VLOG_DEVICE(5, device_ordinal)\n+        << \"Registering \" << buffer_range.opaque()\n+        << \" with size: \" << buffer_range.size()\n+        << \", is symmetric: \" << (use_symmetric_buffer ? \"true\" : \"false\");\n+    // Symmetric buffer registration is a collective operation,\n+    // we need to do that before locking on a global.\n+    TF_ASSIGN_OR_RETURN(\n+        auto handle,\n+        RegisterBuffer(buffer_range, device_ordinal, use_symmetric_buffer));\n+    absl::MutexLock lock(registered_buffers_.mu);\n+    registered_buffers_.range_to_handle[buffer_range.opaque()] =\n+        std::move(handle);\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::StatusOr<std::unique_ptr<Communicator::RegisteredBufferHandle>>\n+RcclCommunicator::RegisterBuffer(stream_executor::DeviceAddressBase buffer,\n+                                 int device_ordinal,\n+                                 bool use_symmetric_buffer) {\n+#if (NCCL_VERSION_CODE >= 21901)\n+  using Handle = std::unique_ptr<Communicator::RegisteredBufferHandle>;\n+\n+  if (!use_symmetric_buffer) {\n+    return ExecuteAwait<Handle>(\n+        [&buffer, device_ordinal, this]() -> absl::StatusOr<Handle> {\n+          VLOG(3) << absl::StreamFormat(\n+              \"[%d] Register buffer for RCCL communicator; buffer=%p; \"\n+              \"size=%d; \"\n+              \"comm=%p\",\n+              device_ordinal, buffer.opaque(), buffer.size(), comm_);\n+          if (canceling_.load()) {\n+            return absl::FailedPreconditionError(\"RcclCommunicator aborted\");\n+          }\n+          void* handle = nullptr;\n+          XLA_RCCL_RETURN_IF_ERROR(\n+              ncclCommRegister(comm_, buffer.opaque(), buffer.size(), &handle));\n+          if (group_nesting_level_ == 0) {\n+            TF_RETURN_IF_ERROR(PollUntilDone());\n+          }\n+          return std::make_unique<RcclRegisteredBufferHandle>(\n+              *this, handle, executor_.get(), /*symmetric_buffer= */ false,\n+              device_ordinal);\n+        });\n+#else\n+  return Unimplemented(\"[%d] RCCL version does not support ncclCommRegister\",\n+                       device_ordinal);\n+#endif  // RCCL_VERSION_CODE >= 21901\n+  } else {\n+#if (NCCL_VERSION_CODE >= 22700)\n+    return ExecuteAwait<Handle>(\n+        [&buffer, device_ordinal, this]() -> absl::StatusOr<Handle> {\n+          VLOG(3) << absl::StreamFormat(\n+              \"[%d] Register symmetric buffer for RCCL communicator; \"\n+              \"buffer=%p; size=%d; comm=%p\",\n+              device_ordinal, buffer.opaque(), buffer.size(), comm_);\n+          void* handle = nullptr;\n+          XLA_RCCL_RETURN_IF_ERROR(ncclGroupStart());\n+          XLA_RCCL_RETURN_IF_ERROR(ncclCommWindowRegister(\n+              comm_, buffer.opaque(), buffer.size(), (ncclWindow_t*)&handle,\n+              RCCL_WIN_COLL_SYMMETRIC));\n+          XLA_RCCL_RETURN_IF_ERROR(ncclGroupEnd());\n+          if (group_nesting_level_ == 0) {\n+            TF_RETURN_IF_ERROR(PollUntilDone());\n+          }\n+          return std::make_unique<RcclRegisteredBufferHandle>(\n+              *this, handle, executor_.get(),\n+              /*symmetric_buffer= */ true, device_ordinal);\n+        });\n+#else\n+  return Unimplemented(\n+      \"[%d] RCCL version does not support ncclCommWindowRegister\",\n+      device_ordinal);\n+#endif  // RCCL_VERSION_CODE >= 22700\n+  }\n+}\n+\n+Future<> RcclCommunicator::GroupExecute(\n+    absl::AnyInvocable<absl::Status(GpuCommunicator*)> f) {\n+  return Execute([f = std::move(f), this]() mutable -> absl::Status {\n+    TF_RETURN_IF_ERROR(GroupStart());\n+    TF_RETURN_IF_ERROR(f(this));\n+    TF_RETURN_IF_ERROR(GroupEnd());\n+    return absl::OkStatus();\n+  });\n+}\n+\n+Future<> RcclCommunicator::AllReduce(se::DeviceAddressBase send_buffer,\n+                                     se::DeviceAddressBase recv_buffer,\n+                                     PrimitiveType dtype, size_t count,\n+                                     ReductionKind reduction_kind,\n+                                     const Communicator::Executor& executor) {\n+  return Execute([send_buffer, recv_buffer, dtype, count, reduction_kind,\n+                  &executor, this]() -> absl::Status {\n+    return LaunchAllReduce(send_buffer, recv_buffer, dtype, count,\n+                           reduction_kind, executor);\n+  });\n+}\n+\n+Future<> RcclCommunicator::Broadcast(se::DeviceAddressBase send_buffer,\n+                                     se::DeviceAddressBase recv_buffer,\n+                                     PrimitiveType dtype, size_t count,\n+                                     RankId root, const Executor& executor) {\n+  return Execute(\n+      [send_buffer, recv_buffer, dtype, count, root, &executor, this]() {\n+        return LaunchBroadcast(send_buffer, recv_buffer, dtype, count, root,\n+                               executor);\n+      });\n+}\n+\n+Future<> RcclCommunicator::ReduceScatter(se::DeviceAddressBase send_buffer,\n+                                         se::DeviceAddressBase recv_buffer,\n+                                         PrimitiveType dtype, size_t count,\n+                                         ReductionKind reduction_kind,\n+                                         const Executor& executor) {\n+  return Execute([send_buffer, recv_buffer, dtype, count, reduction_kind,\n+                  &executor, this]() {\n+    return LaunchReduceScatter(send_buffer, recv_buffer, dtype, count,\n+                               reduction_kind, executor);\n+  });\n+}\n+\n+Future<> RcclCommunicator::AllGather(se::DeviceAddressBase send_buffer,\n+                                     se::DeviceAddressBase recv_buffer,\n+                                     PrimitiveType dtype, size_t count,\n+                                     const Executor& executor) {\n+  return Execute([send_buffer, recv_buffer, dtype, count, &executor, this]() {\n+    return LaunchAllGather(send_buffer, recv_buffer, dtype, count, executor);\n+  });\n+}\n+\n+Future<> RcclCommunicator::AllToAll(\n+    absl::InlinedVector<se::DeviceAddressBase, 4> send_buffers,\n+    absl::InlinedVector<se::DeviceAddressBase, 4> recv_buffers,\n+    PrimitiveType dtype, size_t count, const Executor& executor) {\n+  return Execute([send_buffers, recv_buffers, dtype, count, &executor, this]() {\n+    return LaunchAllToAll(send_buffers, recv_buffers, dtype, count, executor);\n+  });\n+}\n+\n+Future<> RcclCommunicator::CollectivePermute(\n+    se::DeviceAddressBase send_buffer, se::DeviceAddressBase recv_buffer,\n+    PrimitiveType dtype, size_t count, std::optional<RankId> source_rank,\n+    absl::Span<const RankId> target_ranks, const Executor& executor) {\n+  std::vector<RankId> owned_target_ranks(target_ranks.begin(),\n+                                         target_ranks.end());\n+  return Execute([send_buffer, recv_buffer, dtype, count, source_rank,\n+                  owned_target_ranks = std::move(owned_target_ranks), &executor,\n+                  this]() {\n+    return LaunchCollectivePermute(send_buffer, recv_buffer, dtype, count,\n+                                   source_rank, owned_target_ranks, executor);\n+  });\n+}\n+\n+Future<> RcclCommunicator::Send(se::DeviceAddressBase send_buffer,\n+                                PrimitiveType dtype, size_t count, RankId peer,\n+                                const Executor& executor) {\n+  return Execute([send_buffer, dtype, count, peer, &executor, this]() {\n+    return LaunchSend(send_buffer, dtype, count, peer, executor);\n+  });\n+}\n+\n+Future<> RcclCommunicator::Recv(se::DeviceAddressBase recv_buffer,\n+                                PrimitiveType dtype, size_t count, RankId peer,\n+                                const Executor& executor) {\n+  return Execute([recv_buffer, dtype, count, peer, &executor, this]() {\n+    return LaunchRecv(recv_buffer, dtype, count, peer, executor);\n+  });\n+}\n+\n+absl::Status RcclCommunicator::GroupStart() {\n+  VLOG(5) << \"Start RCCL group\";\n+  XLA_RCCL_RETURN_IF_ERROR(ncclGroupStart());\n+  group_nesting_level_++;\n+  return absl::OkStatus();\n+}\n+\n+absl::Status RcclCommunicator::GroupEnd() {\n+  VLOG(5) << \"End RCCL group\";\n+  XLA_RCCL_RETURN_IF_ERROR(ncclGroupEnd());\n+  group_nesting_level_--;\n+  if (group_nesting_level_ > 0) {\n+    // Though NCCL allows groups to be nested, no operations are actually\n+    // performed until the outermost group ends. The inner calls to\n+    // GroupStart() and GroupEnd() are effectively noops.\n+    //\n+    // https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/usage/groups.html\n+    return absl::OkStatus();\n+  }\n+  // Wait for the communicator to finish.\n+  return PollUntilDone();\n+}\n+\n+absl::Status RcclCommunicator::LaunchAllReduce(\n+    se::DeviceAddressBase send_buffer, se::DeviceAddressBase recv_buffer,\n+    PrimitiveType dtype, size_t count, ReductionKind reduction_kind,\n+    const Communicator::Executor& executor) {\n+  if (canceling_.load()) {\n+    return FailedPrecondition(\"RcclCommunicator aborted\");\n+  }\n+  se::Stream* stream = ToStream(executor);\n+\n+  VLOG(3) << absl::StreamFormat(\n+      \"[%d] Launch RCCL AllReduce operation; send_buffer=%p; \"\n+      \"recv_buffer=%p; dtype=%s; count=%d; reduction_kind=%v; comm=%p; \"\n+      \"stream=%p\",\n+      stream->parent()->device_ordinal(), send_buffer.opaque(),\n+      recv_buffer.opaque(), primitive_util::LowercasePrimitiveTypeName(dtype),\n+      count, reduction_kind, comm_, stream);\n+\n+  TF_ASSIGN_OR_RETURN(ncclDataType_t nccl_dtype, ToNcclDataType(dtype, false));\n+\n+  TF_RETURN_IF_ERROR(XLA_RCCL_STATUS(ncclAllReduce(\n+      send_buffer.opaque(), recv_buffer.opaque(), ToNcclCount(dtype, count),\n+      nccl_dtype, ToNcclReduction(reduction_kind), comm_,\n+      AsHipStream(stream))));\n+  if (group_nesting_level_ == 0) {\n+    TF_RETURN_IF_ERROR(PollUntilDone());\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status RcclCommunicator::LaunchBroadcast(\n+    se::DeviceAddressBase send_buffer, se::DeviceAddressBase recv_buffer,\n+    PrimitiveType dtype, size_t count, RankId root, const Executor& executor) {\n+  if (canceling_.load()) {\n+    return absl::FailedPreconditionError(\"RcclCommunicator aborted\");\n+  }\n+  se::Stream* stream = ToStream(executor);\n+\n+  VLOG(3) << absl::StreamFormat(\n+      \"[%d] Launch RCCL Broadcast operation; send_buffer=%p; \"\n+      \"recv_buffer=%p; dtype=%s; count=%d; root=%d; comm=%p; \"\n+      \"stream=%p\",\n+      stream->parent()->device_ordinal(), send_buffer.opaque(),\n+      recv_buffer.opaque(), primitive_util::LowercasePrimitiveTypeName(dtype),\n+      count, root.value(), comm_, stream);\n+\n+  TF_ASSIGN_OR_RETURN(ncclDataType_t nccl_dtype, ToNcclDataType(dtype, false));\n+\n+  TF_RETURN_IF_ERROR(XLA_RCCL_STATUS(ncclBroadcast(\n+      send_buffer.opaque(), recv_buffer.opaque(), ToNcclCount(dtype, count),\n+      nccl_dtype, root.value(), comm_, AsHipStream(stream))));\n+  if (group_nesting_level_ == 0) {\n+    TF_RETURN_IF_ERROR(PollUntilDone());\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status RcclCommunicator::LaunchReduceScatter(\n+    se::DeviceAddressBase send_buffer, se::DeviceAddressBase recv_buffer,\n+    PrimitiveType dtype, size_t count, ReductionKind reduction_kind,\n+    const Executor& executor) {\n+  if (canceling_.load()) {\n+    return absl::FailedPreconditionError(\"RcclCommunicator aborted\");\n+  }\n+  se::Stream* stream = ToStream(executor);\n+\n+  VLOG(3) << absl::StreamFormat(\n+      \"[%d] Launch RCCL ReduceScatter operation; send_buffer=%p; \"\n+      \"recv_buffer=%p; dtype=%s; count=%d; reduction_kind=%v; comm=%p; \"\n+      \"stream=%p\",\n+      stream->parent()->device_ordinal(), send_buffer.opaque(),\n+      recv_buffer.opaque(), primitive_util::LowercasePrimitiveTypeName(dtype),\n+      count, reduction_kind, comm_, stream);\n+\n+  TF_ASSIGN_OR_RETURN(ncclDataType_t nccl_dtype, ToNcclDataType(dtype, false));\n+\n+  TF_RETURN_IF_ERROR(XLA_RCCL_STATUS(ncclReduceScatter(\n+      send_buffer.opaque(), recv_buffer.opaque(), ToNcclCount(dtype, count),\n+      nccl_dtype, ToNcclReduction(reduction_kind), comm_,\n+      AsHipStream(stream))));\n+  if (group_nesting_level_ == 0) {\n+    TF_RETURN_IF_ERROR(PollUntilDone());\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status RcclCommunicator::LaunchAllGather(\n+    se::DeviceAddressBase send_buffer, se::DeviceAddressBase recv_buffer,\n+    PrimitiveType dtype, size_t count, const Executor& executor) {\n+  if (canceling_.load()) {\n+    return absl::FailedPreconditionError(\"RcclCommunicator aborted\");\n+  }\n+  se::Stream* stream = ToStream(executor);\n+\n+  VLOG(3) << absl::StreamFormat(\n+      \"[%d] Launch RCCL AllGather operation; send_buffer=%p; \"\n+      \"recv_buffer=%p; dtype=%s; count=%d; comm=%p; stream=%p\",\n+      stream->parent()->device_ordinal(), send_buffer.opaque(),\n+      recv_buffer.opaque(), primitive_util::LowercasePrimitiveTypeName(dtype),\n+      count, comm_, stream);\n+\n+  TF_ASSIGN_OR_RETURN(ncclDataType_t nccl_dtype, ToNcclDataType(dtype, false));\n+\n+  TF_RETURN_IF_ERROR(XLA_RCCL_STATUS(ncclAllGather(\n+      send_buffer.opaque(), recv_buffer.opaque(), ToNcclCount(dtype, count),\n+      nccl_dtype, comm_, AsHipStream(stream))));\n+  if (group_nesting_level_ == 0) {\n+    TF_RETURN_IF_ERROR(PollUntilDone());\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status RcclCommunicator::LaunchAllToAll(\n+    absl::InlinedVector<se::DeviceAddressBase, 4> send_buffers,\n+    absl::InlinedVector<se::DeviceAddressBase, 4> recv_buffers,\n+    PrimitiveType dtype, size_t count, const Executor& executor) {\n+  if (canceling_.load()) {\n+    return absl::FailedPreconditionError(\"RcclCommunicator aborted\");\n+  }\n+  se::Stream* stream = ToStream(executor);\n+\n+  auto buffer_formatter = [](std::string* out, se::DeviceAddressBase buffer) {\n+    absl::StrAppendFormat(out, \"%p\", buffer.opaque());\n+  };\n+\n+  VLOG(3) << absl::StreamFormat(\n+      \"[%d] Launch RCCL AllToAll operation; send_buffers=[%s]; \"\n+      \"recv_buffers=[%s]; dtype=%s; count=%d; comm=%p; stream=%p\",\n+      stream->parent()->device_ordinal(),\n+      absl::StrJoin(send_buffers, \", \", buffer_formatter),\n+      absl::StrJoin(recv_buffers, \", \", buffer_formatter),\n+      primitive_util::LowercasePrimitiveTypeName(dtype), count, comm_, stream);\n+\n+  if (send_buffers.size() != recv_buffers.size()) {\n+    return InvalidArgument(\n+        \"Number of send buffers must match number of recv buffers: %d != %d\",\n+        send_buffers.size(), recv_buffers.size());\n+  }\n+\n+  int32_t num_ranks;\n+  XLA_RCCL_RETURN_IF_ERROR(ncclCommCount(comm_, &num_ranks));\n+\n+  if (send_buffers.size() != num_ranks) {\n+    return InvalidArgument(\n+        \"Number of send buffers must match number of ranks: %d != %d\",\n+        send_buffers.size(), num_ranks);\n+  }\n+\n+  TF_ASSIGN_OR_RETURN(ncclDataType_t nccl_dtype, ToNcclDataType(dtype, false));\n+\n+  TF_RETURN_IF_ERROR(GroupStart());\n+  for (size_t i = 0; i < send_buffers.size(); ++i) {\n+    se::DeviceAddressBase send_buffer = send_buffers[i];\n+    se::DeviceAddressBase recv_buffer = recv_buffers[i];\n+\n+    XLA_RCCL_RETURN_IF_ERROR(ncclSend(send_buffer.opaque(),\n+                                      ToNcclCount(dtype, count), nccl_dtype, i,\n+                                      comm_, AsHipStream(stream)));\n+\n+    XLA_RCCL_RETURN_IF_ERROR(ncclRecv(recv_buffer.opaque(),\n+                                      ToNcclCount(dtype, count), nccl_dtype, i,\n+                                      comm_, AsHipStream(stream)));\n+  }\n+  TF_RETURN_IF_ERROR(GroupEnd());\n+  return absl::OkStatus();\n+}\n+\n+absl::Status RcclCommunicator::LaunchCollectivePermute(\n+    se::DeviceAddressBase send_buffer, se::DeviceAddressBase recv_buffer,\n+    PrimitiveType dtype, size_t count, std::optional<RankId> source_rank,\n+    absl::Span<const RankId> target_ranks, const Executor& executor) {\n+  if (canceling_.load()) {\n+    return FailedPrecondition(\"RcclCommunicator aborted\");\n+  }\n+  se::Stream* stream = ToStream(executor);\n+\n+  auto rank_formatter = [](std::string* out, RankId rank) {\n+    absl::StrAppendFormat(out, \"%d\", rank.value());\n+  };\n+\n+  VLOG(3) << absl::StreamFormat(\n+      \"[%d] Launch RCCL CollectivePermute operation; send_buffer=%p; \"\n+      \"recv_buffer=%p; dtype=%s; source_rank=%s; target_ranks=[%s]; count=%d; \"\n+      \"comm=%p; stream=%p\",\n+      stream->parent()->device_ordinal(), send_buffer.opaque(),\n+      recv_buffer.opaque(), primitive_util::LowercasePrimitiveTypeName(dtype),\n+      source_rank ? absl::StrCat(source_rank->value()) : \"<empty>\",\n+      absl::StrJoin(target_ranks, \", \", rank_formatter), count, comm_, stream);\n+\n+  TF_ASSIGN_OR_RETURN(ncclDataType_t nccl_dtype, ToNcclDataType(dtype, false));\n+\n+  // Short-circuit if there is no source or target rank.\n+  if (!source_rank && target_ranks.empty()) {\n+    return absl::OkStatus();\n+  }\n+\n+  TF_RETURN_IF_ERROR(GroupStart());\n+\n+  if (source_rank) {\n+    XLA_RCCL_RETURN_IF_ERROR(\n+        ncclRecv(recv_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype,\n+                 source_rank->value(), comm_, AsHipStream(stream)));\n+  }\n+\n+  for (auto target_rank : target_ranks) {\n+    XLA_RCCL_RETURN_IF_ERROR(\n+        ncclSend(send_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype,\n+                 target_rank.value(), comm_, AsHipStream(stream)));\n+  }\n+\n+  TF_RETURN_IF_ERROR(GroupEnd());\n+\n+  return absl::OkStatus();\n+}\n+\n+absl::Status RcclCommunicator::LaunchSend(se::DeviceAddressBase send_buffer,\n+                                          PrimitiveType dtype, size_t count,\n+                                          RankId peer,\n+                                          const Executor& executor) {\n+  if (canceling_.load()) {\n+    return absl::FailedPreconditionError(\"RcclCommunicator aborted\");\n+  }\n+  se::Stream* stream = ToStream(executor);\n+\n+  VLOG(3) << absl::StreamFormat(\n+      \"[%d] Launch RCCL Send operation; send_buffer=%p; dtype=%s; \"\n+      \"count=%d; peer=%d; comm=%p; stream=%p\",\n+      stream->parent()->device_ordinal(), send_buffer.opaque(),\n+      primitive_util::LowercasePrimitiveTypeName(dtype), count, peer.value(),\n+      comm_, stream);\n+\n+  TF_ASSIGN_OR_RETURN(ncclDataType_t nccl_dtype, ToNcclDataType(dtype, false));\n+\n+  TF_RETURN_IF_ERROR(XLA_RCCL_STATUS(\n+      ncclSend(send_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype,\n+               peer.value(), comm_, AsHipStream(stream))));\n+  if (group_nesting_level_ == 0) {\n+    TF_RETURN_IF_ERROR(PollUntilDone());\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status RcclCommunicator::LaunchRecv(se::DeviceAddressBase recv_buffer,\n+                                          PrimitiveType dtype, size_t count,\n+                                          RankId peer,\n+                                          const Executor& executor) {\n+  if (canceling_.load()) {\n+    return absl::FailedPreconditionError(\"RcclCommunicator aborted\");\n+  }\n+  se::Stream* stream = ToStream(executor);\n+\n+  VLOG(3) << absl::StreamFormat(\n+      \"[%d] Launch RCCL Recv operation; recv_buffer=%p; dtype=%s; \"\n+      \"count=%d; peer=%d; comm=%p; stream=%p\",\n+      stream->parent()->device_ordinal(), recv_buffer.opaque(),\n+      primitive_util::LowercasePrimitiveTypeName(dtype), count, peer.value(),\n+      comm_, stream);\n+\n+  TF_ASSIGN_OR_RETURN(ncclDataType_t nccl_dtype, ToNcclDataType(dtype, false));\n+\n+  TF_RETURN_IF_ERROR(XLA_RCCL_STATUS(\n+      ncclRecv(recv_buffer.opaque(), ToNcclCount(dtype, count), nccl_dtype,\n+               peer.value(), comm_, AsHipStream(stream))));\n+  if (group_nesting_level_ == 0) {\n+    TF_RETURN_IF_ERROR(PollUntilDone());\n+  }\n+  return absl::OkStatus();\n+}\n+\n+std::string RcclCommunicator::ToString() const {\n+  // comm_ should not be \"touched\" outside of executor_, but we are printing the\n+  // pointer itself and not touching the value, so this is safe.\n+  return absl::StrFormat(\"RcclCommunicator(ncclComm_t=%p)\", comm_);\n+}\n+\n+absl::Status RcclCommunicator::PollUntilDone() const {\n+  if (canceling_.load()) {\n+    return FailedPrecondition(\"RcclCommunicator aborted\");\n+  }\n+  return ::xla::gpu::PollUntilDone(comm_, canceling_);\n+}\n+\n+Future<> RcclCommunicator::Execute(\n+    absl::AnyInvocable<absl::Status() &&> f) const {\n+  return executor_ ? Future<>::MakeOn(*executor_, std::move(f))\n+                   : Future<>(std::move(f)());\n+}\n+\n+template <typename T>\n+Future<T> RcclCommunicator::Execute(\n+    absl::AnyInvocable<absl::StatusOr<T>() &&> f) const {\n+  return executor_ ? Future<T>::MakeOn(*executor_, std::move(f))\n+                   : Future<T>(std::move(f)());\n+}\n+\n+}  // namespace xla::gpu"
        },
        {
            "sha": "d9b853fc918ec5f5f0f4998db6a9e52483fa10fb",
            "filename": "third_party/xla/xla/backends/gpu/collectives/rccl_communicator.h",
            "status": "added",
            "additions": 254,
            "deletions": 0,
            "changes": 254,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_communicator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_communicator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_communicator.h?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -0,0 +1,254 @@\n+/* Copyright 2024 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_COLLECTIVES_RCCL_COMMUNICATOR_H_\n+#define XLA_BACKENDS_GPU_COLLECTIVES_RCCL_COMMUNICATOR_H_\n+\n+#include <atomic>\n+#include <cstddef>\n+#include <memory>\n+#include <optional>\n+#include <string>\n+#include <utility>\n+\n+#include \"absl/base/thread_annotations.h\"\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/container/inlined_vector.h\"\n+#include \"absl/functional/any_invocable.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/synchronization/mutex.h\"\n+#include \"absl/types/span.h\"\n+#include \"rocm/rocm_config.h\"  // IWYU pragma: keep\n+#include \"xla/backends/gpu/collectives/gpu_communicator.h\"\n+#include \"xla/core/collectives/communicator.h\"\n+#include \"xla/core/collectives/rank_id.h\"\n+#include \"xla/core/collectives/reduction_kind.h\"\n+#include \"xla/future.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/tsl/concurrency/executor.h\"\n+#include \"xla/tsl/platform/env.h\"\n+\n+#if (TF_ROCM_VERSION >= 50200)\n+#include \"rocm/include/rccl/rccl.h\"\n+#else\n+#include \"rocm/include/rccl.h\"\n+#endif  // TF_ROCM_VERSION >= 50200\n+\n+namespace xla::gpu {\n+\n+// XLA collectives communicator wrapping an RCCL communicator.\n+class RcclCommunicator : public GpuCommunicator {\n+ public:\n+  // Creates a RCCL communicator.\n+  //\n+  // make_comm should construct and return a new ncclComm_t. For example, it\n+  // could call ncclCommInitRank. make_comm should not return a ncclComm_t that\n+  // was created by a different thread.\n+  //\n+  // If is_async is true, all collective methods (e.g., AllReduce) are performed\n+  // asynchronously on a separate thread. Otherwise, they are performed\n+  // synchronously on the calling thread.\n+  static absl::StatusOr<std::unique_ptr<RcclCommunicator>> Create(\n+      absl::AnyInvocable<absl::StatusOr<ncclComm_t>()> make_comm,\n+      bool is_async = false, std::atomic_bool* cancel = nullptr,\n+      tsl::Env& env = *tsl::Env::Default());\n+\n+  ~RcclCommunicator() override;\n+\n+  // RcclCommunicator is not copyable or movable.\n+  RcclCommunicator(const RcclCommunicator&) = delete;\n+  RcclCommunicator(RcclCommunicator&&) = delete;\n+  RcclCommunicator& operator=(const RcclCommunicator&) = delete;\n+  RcclCommunicator& operator=(RcclCommunicator&&) = delete;\n+\n+  absl::Status Abort() final;\n+  absl::Status HealthCheck() const final;\n+  absl::StatusOr<size_t> NumRanks() const final;\n+\n+  // Since each XLA buffer is a slice into a larger BFCAllocator chunk, first\n+  // get the base address of buffer. We will use the base address to keep track\n+  // of which chunks we have registered.\n+  absl::Status RegisterBufferOnce(se::DeviceAddressBase buffer_range,\n+                                  int device_ordinal,\n+                                  bool use_symmetric_buffer) final;\n+\n+  Future<> GroupExecute(\n+      absl::AnyInvocable<absl::Status(GpuCommunicator*)> f) final;\n+\n+  Future<> AllReduce(se::DeviceAddressBase send_buffer,\n+                     se::DeviceAddressBase recv_buffer, PrimitiveType dtype,\n+                     size_t count, ReductionKind reduction_kind,\n+                     const Executor& executor) final;\n+\n+  Future<> Broadcast(se::DeviceAddressBase send_buffer,\n+                     se::DeviceAddressBase recv_buffer, PrimitiveType dtype,\n+                     size_t count, RankId root, const Executor& executor) final;\n+\n+  Future<> ReduceScatter(se::DeviceAddressBase send_buffer,\n+                         se::DeviceAddressBase recv_buffer, PrimitiveType dtype,\n+                         size_t count, ReductionKind reduction_kind,\n+                         const Executor& executor) final;\n+\n+  Future<> AllGather(se::DeviceAddressBase send_buffer,\n+                     se::DeviceAddressBase recv_buffer, PrimitiveType dtype,\n+                     size_t count, const Executor& executor) final;\n+\n+  Future<> AllToAll(absl::InlinedVector<se::DeviceAddressBase, 4> send_buffers,\n+                    absl::InlinedVector<se::DeviceAddressBase, 4> recv_buffers,\n+                    PrimitiveType dtype, size_t count,\n+                    const Executor& executor) final;\n+\n+  Future<> CollectivePermute(se::DeviceAddressBase send_buffer,\n+                             se::DeviceAddressBase recv_buffer,\n+                             PrimitiveType dtype, size_t count,\n+                             std::optional<RankId> source_rank,\n+                             absl::Span<const RankId> target_ranks,\n+                             const Executor& executor) final;\n+\n+  Future<> Send(se::DeviceAddressBase send_buffer, PrimitiveType dtype,\n+                size_t count, RankId peer, const Executor& executor) final;\n+\n+  Future<> Recv(se::DeviceAddressBase recv_buffer, PrimitiveType dtype,\n+                size_t count, RankId peer, const Executor& executor) final;\n+\n+  std::string ToString() const final;\n+\n+  ncclComm_t comm() const { return comm_; }\n+\n+ private:\n+  absl::StatusOr<std::unique_ptr<RegisteredBufferHandle>> RegisterBuffer(\n+      se::DeviceAddressBase buffer, int device_ordinal,\n+      bool use_symmetric_buffer);\n+\n+  class RcclRegisteredBufferHandle;\n+\n+  explicit RcclCommunicator(ncclComm_t comm,\n+                            std::unique_ptr<tsl::Executor> executor)\n+      : comm_(comm), executor_(std::move(executor)) {\n+    VLOG(1) << \"Created \" << *this;\n+  }\n+\n+  absl::Status GroupStart();\n+  absl::Status GroupEnd();\n+\n+  absl::Status LaunchAllReduce(se::DeviceAddressBase send_buffer,\n+                               se::DeviceAddressBase recv_buffer,\n+                               PrimitiveType dtype, size_t count,\n+                               ReductionKind reduction_kind,\n+                               const Executor& executor) final;\n+\n+  absl::Status LaunchBroadcast(se::DeviceAddressBase send_buffer,\n+                               se::DeviceAddressBase recv_buffer,\n+                               PrimitiveType dtype, size_t count, RankId root,\n+                               const Executor& executor) final;\n+\n+  absl::Status LaunchReduceScatter(se::DeviceAddressBase send_buffer,\n+                                   se::DeviceAddressBase recv_buffer,\n+                                   PrimitiveType dtype, size_t count,\n+                                   ReductionKind reduction_kind,\n+                                   const Executor& executor) final;\n+\n+  absl::Status LaunchAllGather(se::DeviceAddressBase send_buffer,\n+                               se::DeviceAddressBase recv_buffer,\n+                               PrimitiveType dtype, size_t count,\n+                               const Executor& executor) final;\n+\n+  absl::Status LaunchAllToAll(\n+      absl::InlinedVector<se::DeviceAddressBase, 4> send_buffers,\n+      absl::InlinedVector<se::DeviceAddressBase, 4> recv_buffers,\n+      PrimitiveType dtype, size_t count, const Executor& executor) final;\n+\n+  absl::Status LaunchCollectivePermute(se::DeviceAddressBase send_buffer,\n+                                       se::DeviceAddressBase recv_buffer,\n+                                       PrimitiveType dtype, size_t count,\n+                                       std::optional<RankId> source_rank,\n+                                       absl::Span<const RankId> target_ranks,\n+                                       const Executor& executor) final;\n+\n+  absl::Status LaunchSend(se::DeviceAddressBase send_buffer,\n+                          PrimitiveType dtype, size_t count, RankId peer,\n+                          const Executor& executor) final;\n+\n+  absl::Status LaunchRecv(se::DeviceAddressBase recv_buffer,\n+                          PrimitiveType dtype, size_t count, RankId peer,\n+                          const Executor& executor) final;\n+\n+  // Polls the communicator until any pending non-blocking operations are \"done\"\n+  // or aborted.\n+  absl::Status PollUntilDone() const;\n+\n+  // Executes f on executor_, or calls f directly if executor_ is null.\n+  Future<> Execute(absl::AnyInvocable<absl::Status() &&> f) const;\n+\n+  // Executes f on executor_, or calls f directly if executor_ is null.\n+  template <typename T>\n+  Future<T> Execute(absl::AnyInvocable<absl::StatusOr<T>() &&> f) const;\n+\n+  absl::Status ExecuteAwait(absl::AnyInvocable<absl::Status() &&> f) const {\n+    return Execute(std::move(f)).Await();\n+  }\n+\n+  template <typename T>\n+  absl::StatusOr<T> ExecuteAwait(\n+      absl::AnyInvocable<absl::StatusOr<T>() &&> f) const {\n+    return Execute<T>(std::move(f)).Await();\n+  }\n+\n+  // Underlying RCCL communicator.\n+  ncclComm_t comm_;\n+\n+  // If not null, used to execute methods.\n+  //\n+  // RCCL communicators (instances of ncclComm_t) are not thread safe. Thus,\n+  // multiple threads cannot concurrently access the same ncclComm_t. This is\n+  // not surprising. What is very surprising is that multiple threads cannot\n+  // serially access the same ncclComm_t. In fact, a ncclComm_t must be created\n+  // by, live on, and be destroyed by a single thread. A ncclComm_t cannot be\n+  // accessed by any thread except the one that created it. To accomplish this,\n+  // we perform all comm_ operations on executor_, if it is not null.\n+  //\n+  // Concretely, the lack of thread safety comes from the fact that the RCCL\n+  // code uses thread-local variables that do not work properly when a\n+  // ncclComm_t is accessed from multiple threads. Emperically, the lack of\n+  // thread safety only manifests as buggy behavior when using non-blocking\n+  // communicators.\n+  std::unique_ptr<tsl::Executor> executor_;\n+\n+  // Should all pending collectives cancel?\n+  std::atomic_bool canceling_ = false;\n+\n+  // Has comm_ been aborted?\n+  bool aborted_ = false;\n+\n+  // Nesting level of current RCCL group\n+  int group_nesting_level_ = 0;\n+\n+  // Keep track of which communicators we have registered for already.\n+  // Each ncclMemAlloc'd buffer needs to be registered once per comm.\n+  struct RegisteredBuffers {\n+    absl::Mutex mu;\n+    // Buffer range to the registered buffer handle.\n+    absl::flat_hash_map<void*,\n+                        std::unique_ptr<Communicator::RegisteredBufferHandle>>\n+        range_to_handle ABSL_GUARDED_BY(mu);\n+  };\n+  RegisteredBuffers registered_buffers_;\n+};\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_BACKENDS_GPU_COLLECTIVES_RCCL_COMMUNICATOR_H_"
        },
        {
            "sha": "1d21082326f7473bec519ba02e0e574093d6f0fe",
            "filename": "third_party/xla/xla/backends/gpu/collectives/rccl_communicator_test.cc",
            "status": "added",
            "additions": 162,
            "deletions": 0,
            "changes": 162,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_communicator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_communicator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_communicator_test.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -0,0 +1,162 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/collectives/rccl_communicator.h\"\n+\n+#include <cstddef>\n+#include <memory>\n+#include <optional>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n+#include \"xla/backends/gpu/collectives/rccl_errors.h\"\n+#include \"xla/core/collectives/rank_id.h\"\n+#include \"xla/core/collectives/reduction_kind.h\"\n+#include \"xla/future.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+\n+#if (TF_ROCM_VERSION >= 50200)\n+#include \"rocm/include/rccl/rccl.h\"\n+#else\n+#include \"rocm/include/rccl.h\"\n+#endif  // TF_ROCM_VERSION >= 50200\n+\n+namespace xla::gpu {\n+namespace {\n+\n+using ::testing::HasSubstr;\n+\n+constexpr absl::string_view kCudaError = \"unhandled cuda error\";\n+\n+void AssertAborted(absl::Status s) {\n+  ASSERT_THAT(s, absl_testing::StatusIs(absl::StatusCode::kFailedPrecondition,\n+                                        HasSubstr(\"aborted\")));\n+};\n+\n+void AssertEventAborted(Future<> future) {\n+  ASSERT_THAT(future.Await(),\n+              absl_testing::StatusIs(absl::StatusCode::kFailedPrecondition,\n+                                     HasSubstr(\"aborted\")));\n+};\n+\n+// Creates a non-blocking NCCL communicator.\n+absl::StatusOr<std::unique_ptr<RcclCommunicator>> CreateCommunicator(\n+    bool blocking) {\n+  auto f = [blocking]() -> absl::StatusOr<ncclComm_t> {\n+    // Create a unique NCCL Id.\n+    ncclUniqueId id;\n+    TF_RETURN_IF_ERROR(XLA_RCCL_STATUS(ncclGetUniqueId(&id)));\n+\n+    // Initialize a communicator.\n+    ncclConfig_t config = NCCL_CONFIG_INITIALIZER;\n+    config.blocking = blocking ? 1 : 0;\n+    ncclComm_t comm;\n+    ncclResult_t r =\n+        ncclCommInitRankConfig(&comm, /*nranks=*/1, id, /*rank=*/0, &config);\n+    if (r == ncclUnhandledCudaError) {\n+      // If this test runs on a machine without any CUDA-capable devices\n+      // available, we get a ncclUnhandledCudaError. We return a specific error\n+      // and skip the test.\n+      LOG(ERROR) << XLA_RCCL_STATUS(r);\n+      return absl::FailedPreconditionError(kCudaError);\n+    }\n+    if (r != ncclSuccess && r != ncclInProgress) {\n+      return XLA_RCCL_STATUS(r);\n+    }\n+\n+    // Wait for the communicator to finish initializing.\n+    ncclResult_t state = ncclInProgress;\n+    while (state == ncclInProgress) {\n+      TF_RETURN_IF_ERROR(XLA_RCCL_STATUS(ncclCommGetAsyncError(comm, &state)));\n+    }\n+    TF_RETURN_IF_ERROR(XLA_RCCL_STATUS(state));\n+    return comm;\n+  };\n+  bool is_async = !blocking;\n+  return RcclCommunicator::Create(f, is_async);\n+}\n+\n+TEST(RcclCommunicator, AbortSucceeds) {\n+  for (const bool blocking : {true, false}) {\n+    absl::StatusOr<std::unique_ptr<RcclCommunicator>> comm =\n+        CreateCommunicator(blocking);\n+    if (comm.status().message() == kCudaError) {\n+      GTEST_SKIP() << \"unhandled cuda error\";\n+    }\n+    ASSERT_THAT(comm, absl_testing::IsOk());\n+    ASSERT_THAT((*comm)->Abort(), absl_testing::IsOk());\n+  }\n+}\n+\n+TEST(RcclCommunicator, DoubleAbortFails) {\n+  for (const bool blocking : {true, false}) {\n+    absl::StatusOr<std::unique_ptr<RcclCommunicator>> comm =\n+        CreateCommunicator(blocking);\n+    if (comm.status().message() == kCudaError) {\n+      GTEST_SKIP() << \"unhandled cuda error\";\n+    }\n+    ASSERT_THAT(comm.status(), absl_testing::IsOk());\n+    ASSERT_THAT((*comm)->Abort(), absl_testing::IsOk());\n+    ASSERT_THAT((*comm)->Abort(),\n+                absl_testing::StatusIs(absl::StatusCode::kFailedPrecondition,\n+                                       HasSubstr(\"aborted\")));\n+  }\n+}\n+\n+TEST(RcclCommunicator, OperationsFailAfterAbort) {\n+  for (const bool blocking : {true, false}) {\n+    // Declare placeholder variables to make the operations below compile.\n+    se::DeviceAddressBase buf;\n+    PrimitiveType dtype = PrimitiveType::U64;\n+    size_t count = 0;\n+    ReductionKind rk = ReductionKind::SUM;\n+    GpuCollectives::Executor executor(nullptr);\n+\n+    // Execute RcclCommunicator operations. They should all immediately fail\n+    // because the communicator has been aborted.\n+    absl::StatusOr<std::unique_ptr<RcclCommunicator>> comm =\n+        CreateCommunicator(blocking);\n+    if (comm.status().message() == kCudaError) {\n+      GTEST_SKIP() << \"unhandled cuda error\";\n+    }\n+    ASSERT_THAT(comm.status(), absl_testing::IsOk());\n+    ASSERT_THAT((*comm)->Abort(), absl_testing::IsOk());\n+    AssertAborted((*comm)->HealthCheck());\n+    AssertAborted((*comm)->NumRanks().status());\n+    AssertAborted((*comm)->RegisterBufferOnce(buf, 0, false));\n+    AssertEventAborted(\n+        (*comm)->AllReduce(buf, buf, dtype, count, rk, executor));\n+    AssertEventAborted(\n+        (*comm)->Broadcast(buf, buf, dtype, count, RankId(0), executor));\n+    AssertEventAborted(\n+        (*comm)->ReduceScatter(buf, buf, dtype, count, rk, executor));\n+    AssertEventAborted((*comm)->AllGather(buf, buf, dtype, count, executor));\n+    AssertEventAborted((*comm)->AllToAll({}, {}, dtype, count, executor));\n+    AssertEventAborted(\n+        (*comm)->CollectivePermute(buf, buf, dtype, count, {}, {}, executor));\n+    AssertEventAborted((*comm)->Send(buf, dtype, count, RankId(0), executor));\n+    AssertEventAborted((*comm)->Recv(buf, dtype, count, RankId(0), executor));\n+  }\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        },
        {
            "sha": "c79483e1126fa6ec5810f8fa3d99e88bf6cb15a7",
            "filename": "third_party/xla/xla/backends/gpu/collectives/rccl_errors.cc",
            "status": "added",
            "additions": 59,
            "deletions": 0,
            "changes": 59,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_errors.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_errors.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_errors.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -0,0 +1,59 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/collectives/rccl_errors.h\"\n+\n+#include <atomic>\n+\n+#include \"absl/log/log.h\"\n+#include \"absl/time/clock.h\"\n+#include \"absl/time/time.h\"\n+#include \"rocm/rocm_config.h\"  // IWYU pragma: keep\n+#include \"xla/util.h\"\n+\n+#if (TF_ROCM_VERSION >= 50200)\n+#include \"rocm/include/rccl/rccl.h\"\n+#else\n+#include \"rocm/include/rccl.h\"\n+#endif  // TF_ROCM_VERSION >= 50200\n+\n+namespace xla::gpu {\n+\n+absl::Status PollUntilDone(ncclComm_t comm, const std::atomic_bool& aborted) {\n+  auto poll = [](ncclComm_t comm,\n+                 const std::atomic_bool& aborted) -> absl::Status {\n+    ncclResult_t state = ncclInProgress;\n+    while (state == ncclInProgress && !aborted.load()) {\n+      XLA_RCCL_RETURN_IF_ERROR(ncclCommGetAsyncError(comm, &state));\n+    }\n+    if (aborted.load()) {\n+      return Cancelled(\"NcclCommunicator aborted\");\n+    }\n+    return XLA_RCCL_STATUS(state);\n+  };\n+\n+  if (!VLOG_IS_ON(1)) {\n+    return poll(comm, aborted);\n+  }\n+\n+  absl::Time start = absl::Now();\n+  absl::Status s = poll(comm, aborted);\n+  absl::Time stop = absl::Now();\n+  VLOG(1) << \"Polled RCCL communicator \" << comm << \" for \" << (stop - start)\n+          << \": \" << s;\n+  return s;\n+}\n+\n+}  // namespace xla::gpu"
        },
        {
            "sha": "90384b5700f0dbfea3f5debbdd5d5563a7083c4b",
            "filename": "third_party/xla/xla/backends/gpu/collectives/rccl_errors.h",
            "status": "added",
            "additions": 83,
            "deletions": 0,
            "changes": 83,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_errors.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_errors.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Frccl_errors.h?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -0,0 +1,83 @@\n+/* Copyright 2024 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_COLLECTIVES_RCCL_ERRORS_H_\n+#define XLA_BACKENDS_GPU_COLLECTIVES_RCCL_ERRORS_H_\n+\n+#include <atomic>\n+\n+#include \"absl/status/status.h\"\n+#include \"rocm/rocm_config.h\"  // IWYU pragma: keep\n+#include \"xla/tsl/platform/logging.h\"\n+\n+#if (TF_ROCM_VERSION >= 50200)\n+#include \"rocm/include/rccl/rccl.h\"\n+#else\n+#include \"rocm/include/rccl.h\"\n+#endif  // TF_ROCM_VERSION >= 50200\n+\n+//===----------------------------------------------------------------------===//\n+// Collection of helper macros for handling RCCL errors.\n+//===----------------------------------------------------------------------===//\n+\n+#define XLA_RCCL_STATUS(expr)                                         \\\n+  [](ncclResult_t s, absl::string_view str) -> absl::Status {         \\\n+    if (s == ncclSuccess || s == ncclInProgress) {                    \\\n+      return absl::OkStatus();                                        \\\n+    }                                                                 \\\n+    return xla::Internal(                                             \\\n+        \"RCCL operation %s failed: %s. Last RCCL warning(error) log \" \\\n+        \"entry (may be unrelated) '%s'.\",                             \\\n+        str, ncclGetErrorString(s), ncclGetLastError(nullptr));       \\\n+  }(expr, #expr)\n+\n+#define XLA_RCCL_RETURN_IF_ERROR(expr)      \\\n+  do {                                      \\\n+    absl::Status s = XLA_RCCL_STATUS(expr); \\\n+    if (!s.ok()) {                          \\\n+      return s;                             \\\n+    }                                       \\\n+  } while (0)\n+\n+#define XLA_RCCL_LOG_IF_ERROR(expr)         \\\n+  do {                                      \\\n+    absl::Status s = XLA_RCCL_STATUS(expr); \\\n+    if (!s.ok()) {                          \\\n+      LOG(ERROR) << s.ToString();           \\\n+    }                                       \\\n+  } while (0)\n+\n+#define XLA_RCCL_CHECK(expr) CHECK(XLA_RCCL_STATUS(expr).ok())\n+\n+namespace xla::gpu {\n+\n+// Polls the provided communicator until it is \"done\" or aborted.\n+//\n+// RCCL communicators can be blocking or non-blocking. Operations performed on\n+// non-blocking communicators return immediately, and it is the responsibility\n+// of the programmer to repeatedly call ncclCommGetAsyncError on the\n+// communicator until ncclCommGetAsyncError no long returns inProgress. That is\n+// what PollUntilDone does.\n+//\n+// Note, however, that the semantics of RCCL collectives are a bit subtle. For\n+// example, a collective operation may report itself as done when it is\n+// scheduled on the GPU but has not yet executed. Refer to the RCCL\n+// documentation and exercise caution when reasoning about whether an operation\n+// is really \"done\".\n+absl::Status PollUntilDone(ncclComm_t comm, const std::atomic_bool& aborted);\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_BACKENDS_GPU_COLLECTIVES_RCCL_ERRORS_H_"
        },
        {
            "sha": "7a1f1791d3d911b6b17e5530f9208cc4ed8661bd",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_params.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_params.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_params.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_params.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/collective_params.h\"\n \n #include <cstdint>\n+#include <string>\n \n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/status/statusor.h\"\n@@ -60,9 +61,11 @@ absl::StatusOr<CollectiveParams> CollectiveParams::Create(\n   const GpuExecutableRunOptions* gpu_options =\n       run_options.run_options().gpu_executable_run_options();\n \n+  const std::string& platform_name =\n+      run_options.run_options().stream()->parent()->GetPlatform()->Name();\n   auto* collectives = gpu_options && gpu_options->collectives()\n                           ? gpu_options->collectives()\n-                          : GpuCollectives::Default();\n+                          : GpuCollectives::Default(platform_name);\n \n   auto* device_id_map = gpu_options && gpu_options->gpu_global_device_ids()\n                             ? &*gpu_options->gpu_global_device_ids()"
        },
        {
            "sha": "d4a9ae9085c66ead01d92854f379e2d75d2db5a2",
            "filename": "third_party/xla/xla/pjrt/gpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -178,7 +178,6 @@ cc_library(\n     ]) + if_cuda([\n         # keep sorted\n         \"//xla/stream_executor/gpu:gpu_cudamallocasync_allocator\",\n-        \"//xla/stream_executor/gpu:gpu_stream\",\n         \"@local_config_cuda//cuda:cuda_headers\",\n     ]) + if_rocm([\n         # keep sorted"
        },
        {
            "sha": "be168f000824561abf82af66f8888750aef9fe7b",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -759,7 +759,8 @@ void StreamExecutorGpuClient::ScheduleSendsOnLocalDevice(\n   auto setup_sends = [&]() -> absl::Status {\n     TF_ASSIGN_OR_RETURN(local_device_state, GetLocalDeviceState(device));\n     stream = local_device_state->GetDeviceToDeviceStream();\n-    gpu::GpuCollectives* gpu_collectives = gpu::GpuCollectives::Default();\n+    gpu::GpuCollectives* gpu_collectives =\n+        gpu::GpuCollectives::Default(stream->parent()->GetPlatform()->Name());\n     usage_event = tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(\n         BufferSequencingEvent::Create(this->thread_pool()));\n \n@@ -974,7 +975,8 @@ StreamExecutorGpuClient::CrossHostReceiveBuffers(\n     stream = local_device_state->GetDeviceToDeviceStream();\n     TF_ASSIGN_OR_RETURN(PjRtMemorySpace * memory_space,\n                         device->default_memory_space());\n-    gpu::GpuCollectives* gpu_collectives = gpu::GpuCollectives::Default();\n+    gpu::GpuCollectives* gpu_collectives =\n+        gpu::GpuCollectives::Default(stream->parent()->GetPlatform()->Name());\n     definition_event = tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(\n         BufferSequencingEvent::Create(this->thread_pool()));\n "
        },
        {
            "sha": "33f0ab94a82627bf23a17ff7a7cbf45fddab7b62",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -2322,9 +2322,7 @@ xla_cc_test(\n         \"no_oss\",\n         \"nomsan\",  # Pulls in precompiled NVIDIA libraries which cause false positives in msan.\n         \"requires-gpu-nvidia\",\n-    ] + if_google([\n-        \"ignore_for_dep=third_party/tensorflow/compiler/xla/service/gpu/amdgpu_compiler.h\",\n-    ]),\n+    ],\n     deps = if_cuda_is_configured([\n         \":nvptx_compiler_impl\",\n         \"//xla/stream_executor:cuda_platform\",\n@@ -2365,7 +2363,6 @@ cc_library(\n     ],\n     tags = [\n         \"gpu\",\n-        \"manual\",\n         \"rocm-only\",\n     ],\n     deps = [\n@@ -2386,7 +2383,6 @@ cc_library(\n     ],\n     tags = [\n         \"gpu\",\n-        \"manual\",\n         \"rocm-only\",\n     ],\n     deps = ["
        },
        {
            "sha": "f2126b3e9ad1bae51d49757a97e6a2ddb5106638",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -1594,14 +1594,13 @@ cc_library(\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/gpu:gpu_semaphore\",\n-        \"//xla/stream_executor/gpu:gpu_stream\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/time\",\n         \"@local_config_cuda//cuda:cuda_headers\",\n-        \"@local_tsl//tsl/platform:errors\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n "
        },
        {
            "sha": "89c2018dfeaf1287d4f2961851ca224edd81088f",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_timer.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_timer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_timer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_timer.cc?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -28,9 +28,10 @@ limitations under the License.\n #include \"xla/stream_executor/cuda/cuda_status.h\"\n #include \"xla/stream_executor/cuda/delay_kernel.h\"\n #include \"xla/stream_executor/gpu/gpu_semaphore.h\"\n-#include \"xla/stream_executor/gpu/gpu_stream.h\"\n-#include \"tsl/platform/errors.h\"\n-#include \"tsl/platform/statusor.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n \n namespace stream_executor::gpu {\n "
        },
        {
            "sha": "0529fdcdcf0e891e0b05f6a8cfd11008d5051fa3",
            "filename": "third_party/xla/xla/stream_executor/gpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 13,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3bff94579443c830b19fe0a176fb4b1d8b12a4ce/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD?ref=3bff94579443c830b19fe0a176fb4b1d8b12a4ce",
            "patch": "@@ -241,19 +241,6 @@ tsl_gpu_library(\n     alwayslink = True,\n )\n \n-cc_library(\n-    name = \"gpu_stream\",\n-    srcs = [\"gpu_stream.cc\"],\n-    hdrs = [\"gpu_stream.h\"],\n-    tags = [\"gpu\"],\n-    deps = [\n-        \":gpu_types_header\",\n-        \"//xla/stream_executor:stream\",\n-        \"@com_google_absl//absl/base\",\n-        \"@com_google_absl//absl/log:check\",\n-    ],\n-)\n-\n cc_library(\n     name = \"gpu_semaphore\",\n     srcs = [\"gpu_semaphore.cc\"],"
        },
        {
            "sha": "ee9b15487bab65bdd85b36ec3af6f5e4ef952cf5",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_stream.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 33,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62020f04ae210ab456ed7c88b3079861522a2f6b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_stream.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62020f04ae210ab456ed7c88b3079861522a2f6b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_stream.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_stream.cc?ref=62020f04ae210ab456ed7c88b3079861522a2f6b",
            "patch": "@@ -1,33 +0,0 @@\n-/* Copyright 2019 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/stream_executor/gpu/gpu_stream.h\"\n-\n-#include \"absl/base/casts.h\"\n-#include \"absl/log/check.h\"\n-#include \"xla/stream_executor/gpu/gpu_types.h\"\n-#include \"xla/stream_executor/stream.h\"\n-\n-namespace stream_executor {\n-namespace gpu {\n-\n-GpuStreamHandle AsGpuStreamValue(Stream* stream) {\n-  DCHECK(stream != nullptr);\n-  return absl::bit_cast<GpuStreamHandle>(\n-      stream->platform_specific_handle().stream);\n-}\n-\n-}  // namespace gpu\n-}  // namespace stream_executor"
        },
        {
            "sha": "ec95ec50e25226642878913d85d58dc45c63aa51",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_stream.h",
            "status": "removed",
            "additions": 0,
            "deletions": 33,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62020f04ae210ab456ed7c88b3079861522a2f6b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_stream.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62020f04ae210ab456ed7c88b3079861522a2f6b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_stream.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_stream.h?ref=62020f04ae210ab456ed7c88b3079861522a2f6b",
            "patch": "@@ -1,33 +0,0 @@\n-/* Copyright 2019 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-// Defines the GpuStream type - the CUDA-specific implementation of the generic\n-// StreamExecutor Stream interface.\n-\n-#ifndef XLA_STREAM_EXECUTOR_GPU_GPU_STREAM_H_\n-#define XLA_STREAM_EXECUTOR_GPU_GPU_STREAM_H_\n-\n-#include \"xla/stream_executor/gpu/gpu_types.h\"\n-#include \"xla/stream_executor/stream.h\"\n-\n-namespace stream_executor {\n-namespace gpu {\n-\n-// Extracts a GpuStreamHandle from a GpuStream-backed Stream object.\n-GpuStreamHandle AsGpuStreamValue(Stream* stream);\n-}  // namespace gpu\n-}  // namespace stream_executor\n-\n-#endif  // XLA_STREAM_EXECUTOR_GPU_GPU_STREAM_H_"
        }
    ],
    "stats": {
        "total": 2468,
        "additions": 2168,
        "deletions": 300
    }
}