{
    "author": "ermilovmaxim",
    "message": "override Thunk::buffer_uses where needed. Part 2\n\nPiperOrigin-RevId: 839927678",
    "sha": "f11dcacc6d794a9b43e7c9db4e65511ab7a125c0",
    "files": [
        {
            "sha": "d1652a9c42933e6394beac5f4912262e5d06a028",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=f11dcacc6d794a9b43e7c9db4e65511ab7a125c0",
            "patch": "@@ -706,6 +706,7 @@ cc_library(\n         \"//xla/ffi:ffi_api\",\n         \"//xla/ffi/api:c_api\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/runtime:object_pool\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:custom_call_status\",\n@@ -784,6 +785,7 @@ cc_library(\n         \"//xla:types\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:buffer_assignment_proto_cc\",\n         \"//xla/stream_executor:blas\",\n@@ -1182,6 +1184,7 @@ cc_library(\n     hdrs = [\"memset_thunk.h\"],\n     deps = [\n         \":thunk\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/tsl/platform:statusor\",\n@@ -1916,6 +1919,7 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla:util\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/service/gpu:gpu_transfer_manager\",\n@@ -2047,6 +2051,7 @@ cc_library(\n         \":thunk_proto_cc\",\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/runtime:device_id\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/stream_executor:device_memory\","
        },
        {
            "sha": "c2dc3122ea6a84baabad1444c0a056c1296fc7bc",
            "filename": "third_party/xla/xla/backends/gpu/runtime/custom_call_thunk.h",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.h?ref=f11dcacc6d794a9b43e7c9db4e65511ab7a125c0",
            "patch": "@@ -41,6 +41,7 @@ limitations under the License.\n #include \"xla/ffi/ffi.h\"\n #include \"xla/ffi/ffi_api.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/runtime/object_pool.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/custom_call_status.h\"\n@@ -154,6 +155,18 @@ class CustomCallThunk : public Thunk {\n \n   absl::string_view opaque() const { return opaque_; }\n \n+  BufferUses buffer_uses() const override {\n+    BufferUses res;\n+    res.reserve(operands_.size() + results_.size());\n+    for (const NullableShapedSlice& shaped_slice : operands_) {\n+      if (!shaped_slice.has_value()) {\n+        continue;\n+      }\n+      res.push_back(BufferUse::Read(shaped_slice->slice, shaped_slice->shape));\n+    }\n+    return res;\n+  }\n+\n   absl::StatusOr<ThunkProto> ToProto() const override;\n \n   static absl::StatusOr<std::unique_ptr<CustomCallThunk>> FromProto("
        },
        {
            "sha": "a77909ba727d3509d3d4d9b0c8ab4bef40aec1a1",
            "filename": "third_party/xla/xla/backends/gpu/runtime/fft_thunk.h",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Ffft_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Ffft_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Ffft_thunk.h?ref=f11dcacc6d794a9b43e7c9db4e65511ab7a125c0",
            "patch": "@@ -28,6 +28,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/shape.h\"\n #include \"xla/stream_executor/device_memory.h\"\n@@ -84,6 +85,13 @@ class FftThunk : public Thunk {\n   // Does the FFT for the thunk on \"stream\".\n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Read(input_buffer_, input_shape_),\n+        BufferUse::Write(output_buffer_, output_shape_),\n+    };\n+  }\n+\n   static absl::StatusOr<std::unique_ptr<FftThunk>> FromProto(\n       ThunkInfo thunk_info, const FftThunkProto& proto,\n       absl::Span<const BufferAllocation> buffer_allocations);"
        },
        {
            "sha": "d8639dae23291bc061d499e873813bdf867179a7",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_send_recv_thunk.h",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_send_recv_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_send_recv_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_send_recv_thunk.h?ref=f11dcacc6d794a9b43e7c9db4e65511ab7a125c0",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"absl/synchronization/mutex.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/runtime/device_id.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/shape.h\"\n@@ -105,6 +106,12 @@ class HostSendThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Read(buffer_, shape_),\n+    };\n+  }\n+\n   absl::StatusOr<ThunkProto> ToProto() const override;\n \n   std::optional<AsyncEventsUniqueId> GetAsyncEventsUniqueId() const override;\n@@ -171,6 +178,12 @@ class HostRecvThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Write(buffer_, shape_),\n+    };\n+  }\n+\n   absl::StatusOr<ThunkProto> ToProto() const override;\n \n   std::optional<AsyncEventsUniqueId> GetAsyncEventsUniqueId() const override;"
        },
        {
            "sha": "27fa71fb272202020363b9c00e5ea0538137f95f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/memset_thunk.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fmemset_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fmemset_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fmemset_thunk.h?ref=f11dcacc6d794a9b43e7c9db4e65511ab7a125c0",
            "patch": "@@ -23,6 +23,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n \n // This file contains thunks that set a buffer's elements to a particular value.\n@@ -67,6 +68,12 @@ class Memset32BitValueThunk : public Thunk {\n   const BufferAllocation::Slice& destination() const { return dest_; }\n   uint32_t value() const { return value_; }\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Write(dest_),\n+    };\n+  }\n+\n   static absl::StatusOr<std::unique_ptr<Memset32BitValueThunk>> FromProto(\n       ThunkInfo thunk_info, const Memset32BitValueThunkProto& thunk_proto,\n       absl::Span<const BufferAllocation> buffer_allocations);"
        },
        {
            "sha": "de0904648b7a7b5a5698a678f87c2b6949c59a79",
            "filename": "third_party/xla/xla/backends/gpu/runtime/outfeed_thunk.h",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Foutfeed_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f11dcacc6d794a9b43e7c9db4e65511ab7a125c0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Foutfeed_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Foutfeed_thunk.h?ref=f11dcacc6d794a9b43e7c9db4e65511ab7a125c0",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n \n namespace xla {\n@@ -43,6 +44,15 @@ class OutfeedThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  BufferUses buffer_uses() const override {\n+    BufferUses res;\n+    res.reserve(source_slices_.size());\n+    for (const ShapedSlice& shaped_slice : source_slices_) {\n+      res.push_back(BufferUse::Read(shaped_slice.slice, shaped_slice.shape));\n+    }\n+    return res;\n+  }\n+\n   // Deserializes an `OutfeedThunk` that will copy the data from the given\n   // `source_allocations` to the host-side outfeed queue.\n   // The `source_allocations` must outlive the returned `OutfeedThunk`."
        }
    ],
    "stats": {
        "total": 56,
        "additions": 56,
        "deletions": 0
    }
}