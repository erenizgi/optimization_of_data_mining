{
    "author": "olegshyshkov",
    "message": "[XLA:GPU] Add ExecuteReplicated override that returns executable, optimized module and literals.\n\nPiperOrigin-RevId: 837843890",
    "sha": "623c126a182c186cd18ad1dae89aacaca3f4de7e",
    "files": [
        {
            "sha": "2d5d052196fd99a06c1a8671c30c9f24a70b7fe3",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/623c126a182c186cd18ad1dae89aacaca3f4de7e/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/623c126a182c186cd18ad1dae89aacaca3f4de7e/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc?ref=623c126a182c186cd18ad1dae89aacaca3f4de7e",
            "patch": "@@ -3475,7 +3475,7 @@ TEST_F(CollectiveMetadataTest, ConstructCollectiveMetadata) {\n   const std::array<Literal, 2> arguments = {\n       LiteralUtil::CreateR1<float>({1.0f, 2.0f, 3.0f, 4.0f}),\n       LiteralUtil::CreateR1<float>({1.0f, 2.0f, 3.0f, 4.0f})};\n-  DeviceAssignment device_assignment = MakeDeviceAssn(kNumReplicas);\n+  DeviceAssignment device_assignment = MakeDeviceAssignment(kNumReplicas);\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> result,\n       ExecuteReplicated(\n@@ -3544,7 +3544,7 @@ TEST_F(CollectiveMetadataTest, ConstructCollectiveMetadataWithReplicaGroup) {\n   const std::array<Literal, 2> arguments = {\n       LiteralUtil::CreateR1<float>({1.0f, 2.0f, 3.0f, 4.0f}),\n       LiteralUtil::CreateR1<float>({1.0f, 2.0f, 3.0f, 4.0f})};\n-  DeviceAssignment device_assignment = MakeDeviceAssn(kNumReplicas);\n+  DeviceAssignment device_assignment = MakeDeviceAssignment(kNumReplicas);\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::vector<Literal> result,\n       ExecuteReplicated("
        },
        {
            "sha": "5f35db821e34af427c7af88002fe3b4f9379e0c3",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test_base.cc",
            "status": "modified",
            "additions": 40,
            "deletions": 1,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/623c126a182c186cd18ad1dae89aacaca3f4de7e/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/623c126a182c186cd18ad1dae89aacaca3f4de7e/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.cc?ref=623c126a182c186cd18ad1dae89aacaca3f4de7e",
            "patch": "@@ -177,10 +177,49 @@ CollectiveOpsE2ETestBase::ExecuteReplicated(\n       /*device_assignment=*/device_assignment);\n }\n \n+absl::StatusOr<CollectiveOpsE2ETestBase::ExecutionResult>\n+CollectiveOpsE2ETestBase::ExecuteReplicated(\n+    std::unique_ptr<HloModule> module,\n+    const std::vector<std::vector<Literal*>> arguments, int64_t num_replicas,\n+    int64_t num_partitions, bool run_hlo_passes) {\n+  CHECK(num_replicas > 0 && \"expect at least one replica\");\n+  CHECK(num_partitions > 0 && \"expect at least one partition\");\n+  CHECK(num_replicas == arguments.size() &&\n+        \"expect arguments for each replica and partition\");\n+\n+  DeviceAssignment device_assignment =\n+      MakeDeviceAssignment(num_replicas, num_partitions);\n+\n+  ExecutionResult execution_result;\n+\n+  TF_ASSIGN_OR_RETURN(\n+      execution_result.executable,\n+      hlo_runner_->CreateExecutable(std::move(module), run_hlo_passes));\n+\n+  TF_ASSIGN_OR_RETURN(\n+      execution_result.optimized_module,\n+      hlo_runner_->HloModuleFromWrapped(execution_result.executable.get()));\n+\n+  TF_ASSIGN_OR_RETURN(\n+      execution_result.results,\n+      ExecuteReplicated(\n+          /*executable_provider=*/\n+          [&](int64_t) { return execution_result.executable.get(); },\n+          /*argument_count_provider=*/\n+          [&](int64_t) { return arguments.front().size(); },\n+          /*argument_provider=*/\n+          [&](int64_t replica_idx, int64_t argument_idx) -> const Literal* {\n+            return arguments[replica_idx][argument_idx];\n+          },\n+          num_replicas, /*run_hlo_passes=*/run_hlo_passes,\n+          /*device_assignment=*/&device_assignment));\n+  return execution_result;\n+}\n+\n absl::StatusOr<std::vector<Literal>>\n CollectiveOpsE2ETestBase::ExecuteReplicated(OpaqueExecutable* executable,\n                                             int64_t num_replicas) {\n-  DeviceAssignment device_assignment = MakeDeviceAssn(num_replicas);\n+  DeviceAssignment device_assignment = MakeDeviceAssignment(num_replicas);\n   return ExecuteReplicated(\n       /*executable_provider*/ [&](int64_t) { return executable; },\n       /*argument_count_provider*/ [](int64_t) { return 0; },"
        },
        {
            "sha": "94396f033cc7d3601ef2eabb6da95c56cd9bc175",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test_base.h",
            "status": "modified",
            "additions": 18,
            "deletions": 4,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/623c126a182c186cd18ad1dae89aacaca3f4de7e/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/623c126a182c186cd18ad1dae89aacaca3f4de7e/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test_base.h?ref=623c126a182c186cd18ad1dae89aacaca3f4de7e",
            "patch": "@@ -48,6 +48,12 @@ class CollectiveOpsE2ETestBase : public HloHardwareIndependentTestBase {\n  public:\n   CollectiveOpsE2ETestBase();\n \n+  struct ExecutionResult {\n+    std::unique_ptr<OpaqueExecutable> executable;\n+    std::vector<Literal> results;\n+    const HloModule* optimized_module;\n+  };\n+\n   absl::StatusOr<std::vector<Literal>> ExecuteReplicated(\n       absl::AnyInvocable<OpaqueExecutable*(int64_t)> executable_provider,\n       absl::AnyInvocable<int64_t(int64_t)> argument_count_provider,\n@@ -69,6 +75,11 @@ class CollectiveOpsE2ETestBase : public HloHardwareIndependentTestBase {\n   absl::StatusOr<std::vector<Literal>> ExecuteReplicated(\n       OpaqueExecutable* executable, int64_t num_replicas);\n \n+  absl::StatusOr<ExecutionResult> ExecuteReplicated(\n+      std::unique_ptr<HloModule> module,\n+      std::vector<std::vector<Literal*>> arguments, int64_t num_replicas,\n+      int64_t num_partitions, bool run_hlo_passes = true);\n+\n   const se::GpuComputeCapability& Capability() {\n     return hlo_runner_->backend()\n         .default_stream_executor()\n@@ -81,12 +92,15 @@ class CollectiveOpsE2ETestBase : public HloHardwareIndependentTestBase {\n            Capability().cuda_compute_capability()->IsAtLeastHopper();\n   }\n \n-  // Makes a DeviceAssignment device#i to replica_id #i.\n-  DeviceAssignment MakeDeviceAssn(int64_t num_replicas) {\n+  // Makes an iota device assignment.\n+  DeviceAssignment MakeDeviceAssignment(int64_t num_replicas,\n+                                        int64_t num_partitions = 1) {\n     DeviceAssignment assn(/*replica_count=*/num_replicas,\n-                          /*computation_count=*/1);\n+                          /*computation_count=*/num_partitions);\n     for (int64_t i = 0; i < num_replicas; ++i) {\n-      assn(i, 0) = i;\n+      for (int64_t j = 0; j < num_partitions; ++j) {\n+        assn(i, j) = i * num_partitions + j;\n+      }\n     }\n     return assn;\n   }"
        },
        {
            "sha": "54375d747be87a137ec1ed6b0420698e287ddb8f",
            "filename": "third_party/xla/xla/tests/ragged_all_to_all_e2e_test.cc",
            "status": "modified",
            "additions": 71,
            "deletions": 45,
            "changes": 116,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/623c126a182c186cd18ad1dae89aacaca3f4de7e/third_party%2Fxla%2Fxla%2Ftests%2Fragged_all_to_all_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/623c126a182c186cd18ad1dae89aacaca3f4de7e/third_party%2Fxla%2Fxla%2Ftests%2Fragged_all_to_all_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fragged_all_to_all_e2e_test.cc?ref=623c126a182c186cd18ad1dae89aacaca3f4de7e",
            "patch": "@@ -353,11 +353,13 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs) {\n                                                      /*replica_1=*/{3, 1}}));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n+\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -409,11 +411,22 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_S4) {\n       {{s4(2), s4(2)}, {s4(6), s4(6)}, {s4(-1), s4(-1)}, {s4(-1), s4(-1)}});\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  // Check that ragged-all-to-all on S4 was converted to S8.\n+  // Skip this check for decomposer test, because there ragged-all-to-all was\n+  // lowered to all-to-all.\n+  if (std::get<1>(GetParam()) != RaggedAllToAllImplType::kDecomposer) {\n+    HloInstruction* ragged_all_to_all = FindInstruction(\n+        execution_result.optimized_module, HloOpcode::kRaggedAllToAll);\n+    ASSERT_NE(ragged_all_to_all, nullptr);\n+    EXPECT_EQ(ragged_all_to_all->shape().element_type(), S8);\n+  }\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -451,11 +464,12 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_InputBufferLargerThanOutput) {\n                                                      /*replica_1=*/{4, 3}}));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -493,11 +507,12 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_OutputBufferLargerThanInput) {\n                                                      /*replica_1=*/{5, 11}}));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -535,11 +550,12 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_MultipleUpdates) {\n                                      /*replica_1=*/{{3, 1}, {1, 1}}}));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -578,11 +594,12 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_MultiDimData) {\n                                                      /*replica_1=*/{2, 5}}));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n@@ -621,11 +638,12 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_Degenerate) {\n                                                      /*replica_1=*/{3}}));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -668,11 +686,12 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_2GPUs_NonDefaultLayout) {\n                                                      /*replica_1=*/{2, 5}}));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n@@ -712,11 +731,12 @@ TEST_P(RaggedAllToAllTest,\n                                                      /*replica_1=*/{3, 1}}));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[0], results[0]));\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[1], results[1]));\n@@ -760,11 +780,12 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_8GPUs) {\n   TF_ASSERT_OK(CreateRandomTestData(module.get(), input_sizes));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   for (int i = 0; i < kNumReplicas; ++i) {\n@@ -811,11 +832,12 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_8GPUs_2ReplicasPerGroups) {\n   TF_ASSERT_OK(CreateRandomTestData(module.get(), input_sizes));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   for (int i = 0; i < kNumReplicas; ++i) {\n@@ -862,11 +884,12 @@ TEST_P(RaggedAllToAllTest, RaggedAllToAll_8GPUs_4ReplicasPerGroups) {\n   TF_ASSERT_OK(CreateRandomTestData(module.get(), input_sizes));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   for (int i = 0; i < kNumReplicas; ++i) {\n@@ -963,11 +986,12 @@ TEST_P(RaggedAllToAllMultiHostDecomposerTest, RaggedAllToAll_2GPUs_SliceSize1) {\n   TF_ASSERT_OK(CreateRandomTestData(module.get(), input_sizes));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   for (int i = 0; i < kNumReplicas; ++i) {\n@@ -1020,11 +1044,12 @@ TEST_P(RaggedAllToAllMultiHostDecomposerTest, RaggedAllToAll_8GPUs_SliceSize4) {\n   TF_ASSERT_OK(CreateRandomTestData(module.get(), input_sizes));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   for (int i = 0; i < kNumReplicas; ++i) {\n@@ -1079,11 +1104,12 @@ TEST_P(RaggedAllToAllMultiHostDecomposerTest,\n   TF_ASSERT_OK(CreateRandomTestData(module.get(), input_sizes));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<Literal> results,\n+      ExecutionResult execution_result,\n       ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n-                        /*device_assignment=*/nullptr,\n                         /*num_replicas=*/kNumReplicas,\n-                        /*run_hlo_passes=*/true));\n+                        /*num_partitions=*/kNumPartitions));\n+\n+  const std::vector<Literal>& results = execution_result.results;\n   ASSERT_EQ(results.size(), kNumReplicas);\n \n   for (int i = 0; i < kNumReplicas; ++i) {"
        }
    ],
    "stats": {
        "total": 183,
        "additions": 131,
        "deletions": 52
    }
}