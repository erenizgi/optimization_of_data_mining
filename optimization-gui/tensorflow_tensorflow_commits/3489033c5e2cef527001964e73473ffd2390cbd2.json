{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 809665690",
    "sha": "3489033c5e2cef527001964e73473ffd2390cbd2",
    "files": [
        {
            "sha": "af769b30dd25d25d3789a2f2994ac97e5715adf7",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3489033c5e2cef527001964e73473ffd2390cbd2/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3489033c5e2cef527001964e73473ffd2390cbd2/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=3489033c5e2cef527001964e73473ffd2390cbd2",
            "patch": "@@ -252,7 +252,7 @@ class GpuAsyncHostToDeviceTransferManager\n       return transfers_in_flight_ == 0;\n     };\n     {\n-      absl::MutexLock l(&mu_);\n+      absl::MutexLock l(mu_);\n       // Make sure we don't leave dangling pointers in cleanup routines even\n       // if the client lets the object go out of scope.\n       mu_.Await(absl::Condition(&transfers_finished));\n@@ -288,7 +288,7 @@ class GpuAsyncHostToDeviceTransferManager\n \n     tsl::RCReference<RawSEDeviceMemory> buffer;\n     {\n-      absl::MutexLock l(&mu_);\n+      absl::MutexLock l(mu_);\n \n       DCHECK_LT(buffer_index, buffer_ptrs_.size());\n       if (last_transfer_started_[buffer_index]) {\n@@ -384,7 +384,7 @@ class GpuAsyncHostToDeviceTransferManager\n           });\n     }\n \n-    absl::ReleasableMutexLock l(&mu_);\n+    absl::ReleasableMutexLock l(mu_);\n     DCHECK_LT(buffer_index, buffer_ptrs_.size());\n     if (last_transfer_started_[buffer_index]) {\n       return InvalidArgument(\n@@ -451,7 +451,7 @@ class GpuAsyncHostToDeviceTransferManager\n   void SetBufferError(int buffer_index, absl::Status error) override {\n     BufferSequencingEventRef event;\n     {\n-      absl::MutexLock l(&mu_);\n+      absl::MutexLock l(mu_);\n       // For a given buffer_index, SetBufferError can't be called twice, or\n       // called after the last transfer has been enqueued.\n       event = std::move(definition_events_[buffer_index]);\n@@ -501,7 +501,7 @@ class GpuAsyncHostToDeviceTransferManager\n                absl::AnyInvocable<void() &&> on_done) {\n     BufferSequencingEventRef event;\n     {\n-      absl::MutexLock l(&mu_);\n+      absl::MutexLock l(mu_);\n \n       CHECK_GT(transfers_in_flight_, 0);\n       --transfers_in_flight_;\n@@ -701,7 +701,7 @@ void StreamExecutorGpuClient::UpdateGlobalProcessInfo(\n     return;\n   }\n \n-  absl::MutexLock lock(&task_state_infos_mu_);\n+  absl::MutexLock lock(task_state_infos_mu_);\n   if (absl::Status s = AbortOnFailure(task_state_infos_, infos); !s.ok()) {\n     LOG(ERROR) << s;\n   }"
        },
        {
            "sha": "576a35ab5626127f7e7a04dd0c7c3a69863a9c69",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 13,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3489033c5e2cef527001964e73473ffd2390cbd2/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3489033c5e2cef527001964e73473ffd2390cbd2/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc?ref=3489033c5e2cef527001964e73473ffd2390cbd2",
            "patch": "@@ -608,14 +608,14 @@ TEST(StreamExecutorGpuClientTest, ToLiteralAsync) {\n       transfer_manager->TransferLiteralToBuffer(0, src_literal, [&]() {}));\n \n   buffer->ToLiteral(literal.get()).OnReady([&](absl::Status s) {\n-    absl::MutexLock l(&mu);\n+    absl::MutexLock l(mu);\n     TF_ASSERT_OK(s);\n     got_literal = true;\n   });\n   buffer.reset();\n \n   {\n-    absl::MutexLock l(&mu);\n+    absl::MutexLock l(mu);\n     mu.Await(absl::Condition(&got_literal));\n   }\n \n@@ -754,7 +754,7 @@ TEST(StreamExecutorGpuClientTest, ToLiteralAsyncBeforeBufferReady) {\n   bool got_literal = false;\n \n   buffer->ToLiteral(literal.get()).OnReady([&](absl::Status s) {\n-    absl::MutexLock l(&mu);\n+    absl::MutexLock l(mu);\n     TF_ASSERT_OK(s);\n     got_literal = true;\n   });\n@@ -767,7 +767,7 @@ TEST(StreamExecutorGpuClientTest, ToLiteralAsyncBeforeBufferReady) {\n   buffer.reset();\n \n   {\n-    absl::MutexLock l(&mu);\n+    absl::MutexLock l(mu);\n     mu.Await(absl::Condition(&got_literal));\n   }\n \n@@ -815,12 +815,12 @@ TEST(StreamExecutorGpuClientTest, FromHostAsync) {\n     literals.push_back(std::make_shared<Literal>(\n         ShapeUtil::DeviceShapeToHostShape(buffer->on_device_shape())));\n     buffer->ToLiteral(literals.back().get()).OnReady([&](absl::Status s) {\n-      absl::MutexLock l(&mu);\n+      absl::MutexLock l(mu);\n       TF_ASSERT_OK(s);\n       ++got_literal_count;\n     });\n     buffer->GetReadyFuture().OnReady([&](absl::Status s) {\n-      absl::MutexLock l(&mu);\n+      absl::MutexLock l(mu);\n       TF_ASSERT_OK(s);\n       ++got_callback_count;\n     });\n@@ -832,7 +832,7 @@ TEST(StreamExecutorGpuClientTest, FromHostAsync) {\n       return got_literal_count == src_literals.size() &&\n              got_callback_count == src_literals.size();\n     };\n-    absl::MutexLock l(&mu);\n+    absl::MutexLock l(mu);\n     mu.Await(absl::Condition(&done));\n   }\n \n@@ -887,12 +887,12 @@ TEST(StreamExecutorGpuClientTest, FromHostAsyncPinnedHost) {\n     literals.push_back(std::make_shared<Literal>(\n         ShapeUtil::DeviceShapeToHostShape(buffer->on_device_shape())));\n     buffer->ToLiteral(literals.back().get()).OnReady([&](absl::Status s) {\n-      absl::MutexLock l(&mu);\n+      absl::MutexLock l(mu);\n       TF_ASSERT_OK(s);\n       ++got_literal_count;\n     });\n     buffer->GetReadyFuture().OnReady([&](absl::Status s) {\n-      absl::MutexLock l(&mu);\n+      absl::MutexLock l(mu);\n       TF_ASSERT_OK(s);\n       ++got_callback_count;\n     });\n@@ -904,7 +904,7 @@ TEST(StreamExecutorGpuClientTest, FromHostAsyncPinnedHost) {\n       return got_literal_count == src_literals.size() &&\n              got_callback_count == src_literals.size();\n     };\n-    absl::MutexLock l(&mu);\n+    absl::MutexLock l(mu);\n     mu.Await(absl::Condition(&done));\n   }\n \n@@ -1155,7 +1155,7 @@ TEST(StreamExecutorGpuClientTest, CreateMixOfErrorBuffers) {\n       TF_ASSERT_OK(transfer_manager->TransferLiteralToBuffer(i, src_literals[i],\n                                                              [&]() {}));\n       buffer->GetReadyFuture().OnReady([&](absl::Status s) {\n-        absl::MutexLock l(&mu);\n+        absl::MutexLock l(mu);\n         TF_ASSERT_OK(s);\n         ++got_callback_count;\n       });\n@@ -1164,7 +1164,7 @@ TEST(StreamExecutorGpuClientTest, CreateMixOfErrorBuffers) {\n       transfer_manager->SetBufferError(i, error);\n       buffer->GetReadyFuture().OnReady(\n           [error, &mu, &got_callback_count](absl::Status s) {\n-            absl::MutexLock l(&mu);\n+            absl::MutexLock l(mu);\n             ASSERT_EQ(s, error);\n             ++got_callback_count;\n           });\n@@ -1174,7 +1174,7 @@ TEST(StreamExecutorGpuClientTest, CreateMixOfErrorBuffers) {\n \n   {\n     auto done = [&]() { return got_callback_count == src_literals.size(); };\n-    absl::MutexLock l(&mu);\n+    absl::MutexLock l(mu);\n     QCHECK(mu.AwaitWithTimeout(absl::Condition(&done), absl::Seconds(60)));\n   }\n }"
        }
    ],
    "stats": {
        "total": 38,
        "additions": 19,
        "deletions": 19
    }
}