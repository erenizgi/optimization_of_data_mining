{
    "author": "unknown",
    "message": "PR #31855: [DOC] New document - hlo_pass\n\nImported from GitHub PR https://github.com/openxla/xla/pull/31855\n\nüìù Summary of Changes\n-  New document Hlo_pass, gives an overview of HLO passes.\n\nUpdate to terminology.md\n- Added \"High Level Optimizer\" to HLO\n\nüöÄ Kind of Contribution\nüìö Documentation\nCopybara import of the project:\n\n--\nc95ef8b0b2068ad9247993b62161c0a42b36f0cf by Amelia Thurdekoos <athurdekoos@quansight.com>:\n\ncreating hlo_pass doc\n\n--\n183cc0fd5f770dd18f54388d830d3a6334e8ff36 by Amelia Thurdekoos <athurdekoos@quansight.com>:\n\nhlo_pass doc\n\n--\ndf3cbbd234108da557a5388bf4eff80114a8f918 by Amelia Thurdekoos <athurdekoos@quansight.com>:\n\nresolved comments and minor update to terminology.md\n\nMerging this change closes #31855\n\nPiperOrigin-RevId: 814817223",
    "sha": "32519f7156b4261ebb104858d88de23726fede0a",
    "files": [
        {
            "sha": "be64bd1da36e9c2bfa3fc9cfc17146f393134400",
            "filename": "third_party/xla/docs/hlo_passes.md",
            "status": "added",
            "additions": 233,
            "deletions": 0,
            "changes": 233,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32519f7156b4261ebb104858d88de23726fede0a/third_party%2Fxla%2Fdocs%2Fhlo_passes.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32519f7156b4261ebb104858d88de23726fede0a/third_party%2Fxla%2Fdocs%2Fhlo_passes.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Fhlo_passes.md?ref=32519f7156b4261ebb104858d88de23726fede0a",
            "patch": "@@ -0,0 +1,233 @@\n+# HLO Passes\n+\n+This document outlines the [HLO](https://openxla.org/xla/terminology)\n+optimizations and transformations passes in the\n+[XLA compiler](https://openxla.org/xla/architecture).\n+\n+## Introduction\n+\n+A single HLO Pass can be comprised of one or many compiler optimizations and\n+transformations, and XLA provides several hundred such passes. HLO focuses only\n+on the shape (e.g. a 3x4 matrix) and the\n+[operation semantics](https://openxla.org/xla/operation_semantics) of the arrays\n+to make the optimization or transformation easier.\n+\n+For example:\n+\n+*   [`AlgebraicSimplifier`:](https://github.com/openxla/xla/blob/c37fc6a383b870f43cef82280418fcefcc90b0f8/xla/hlo/transforms/simplifiers/algebraic_simplifier.h#L417)\n+    A pass that performs a number of mostly arithmetic simplifications and\n+    optimizations. Including:\n+\n+    *   When dividing by a constant, an optimization is performed to transform\n+        the operation to multiplication by the inversion of the constant.\n+\n+*   [`HloRematerialization`:](https://github.com/openxla/xla/tree/main/xla/hlo/transforms/simplifiers/hlo_rematerialization.h)\n+    A pass that recomputes selected expressions in the computation to reduce\n+    memory pressure caused by long live ranges of array-shaped values.\n+\n+## Developer details\n+\n+The base class for HLO passes can be found in\n+[`xla/hlo/pass/hlo_pass_interface.h`](https://github.com/openxla/xla/blob/main/xla/hlo/pass/hlo_pass_interface.h).\n+HLO pass should not extend this class directly but instead should extend\n+[`HloModulePass`](https://github.com/openxla/xla/blob/main/xla/hlo/pass/hlo_pass_interface.h#L142)\n+or\n+[`HloModuleGroupPass`](https://github.com/openxla/xla/blob/main/xla/hlo/pass/hlo_pass_interface.h#L172).\n+\n+See also\n+[XLA HLO Pass Framework](https://github.com/openxla/xla/tree/main/xla/hlo/pass#readme).\n+\n+### Tooling and Testing\n+\n+XLA comes with multiple command line tools, including the hlo-opt tool. This\n+tool allows execution of an individual pass independent of the given platform\n+compilation stages. For more information see\n+[Tooling](https://openxla.org/xla/tools#hlo-opt_hlo_pass_development_and_debugging).\n+\n+For information on writing unit tests for HLO Passes see\n+[Testing HLO Passes](https://openxla.org/xla/test_hlo_passes).\n+\n+## Hardware-independent HLO Pass Examples\n+\n+This section describes a few examples of passes shared across XLA backends. Some\n+passes may be specialized for specific backends, but the high-level\n+functionality is similar.\n+\n+Shared passes or hardware-independent passes can be found in\n+[`xla/hlo/transforms`](https://github.com/openxla/xla/tree/main/xla/hlo/transforms).\n+\n+### Rematerialization\n+\n+See also\n+[`HloRematerialization`](https://github.com/openxla/xla/blob/main/xla/hlo/transforms/simplifiers/hlo_rematerialization.h).\n+\n+Selectively recomputes expressions within the HLO graph to reduce memory usage.\n+Trades off higher compute for lower memory usage. Can reduce memory usage by\n+tens of percent and is required to run many large models.\n+\n+### Algebraic Simplifier\n+\n+See also\n+[`AlgebraicSimplifier`](https://github.com/openxla/xla/blob/main/xla/hlo/transforms/simplifiers/algebraic_simplifier.h).\n+\n+A grab bag of simplifications, optimizations, and canonicalizations. Analogous\n+to\n+[LLVM‚Äôs `instcombine` pass](https://llvm.org/docs/Passes.html#instcombine-combine-redundant-instructions).\n+\n+### Constant Folding\n+\n+See also\n+[`HloConstantFolding`](https://github.com/openxla/xla/blob/main/xla/hlo/transforms/simplifiers/hlo_constant_folding.h).\n+\n+Replaces expressions which can be evaluated at compile time with their constant\n+equivalent.\n+\n+### Dead Code Elimination\n+\n+See also\n+[`HloDCE`](https://github.com/openxla/xla/blob/main/xla/hlo/transforms/simplifiers/hlo_dce.h)\n+.\n+\n+Removes operations with unused results (fast implementation).\n+\n+### Call Graph Flattening\n+\n+See also\n+[`FlattenCallGraph`](https://github.com/openxla/xla/blob/main/xla/hlo/transforms/simplifiers/flatten_call_graph.h).\n+\n+A legalization pass which converts the HLO call graph into a tree by cloning\n+computations. Required because memory is statically assigned to HLO operations\n+and not based on dynamic call context.\n+\n+### Reshape Mover\n+\n+See also\n+[`ReshapeMover`](https://github.com/openxla/xla/blob/main/xla/hlo/transforms/simplifiers/reshape_mover.h).\n+\n+Reshapes and transposes can be expensive, especially on TPU. This pass moves and\n+reshapes and transposes across elementwise operations enabling the operations to\n+be merged or eliminated.\n+\n+### Zero-sized HLO Elimination\n+\n+See also\n+[`ZeroSizedHloElimination`](https://github.com/openxla/xla/blob/main/xla/hlo/transforms/simplifiers/zero_sized_hlo_elimination.h).\n+\n+HLO supports arrays of zero size (one or more dimensions has a bound of zero).\n+This pass simplifies the graph by replacing zero-sized operations with\n+zero-sized constants.\n+\n+## TPU-specific HLO Pass Examples\n+\n+Passes specific to the TPU backend.\n+\n+### Model parallelism\n+\n+The partitioning of an XLA program across multiple cores is performed at the HLO\n+level and the TPU HLO pipeline includes a number of passes for supporting\n+multi-core execution.\n+\n+#### Spatial partitioning\n+\n+See also\n+[`ShardingPropagation`](https://github.com/openxla/xla/blob/main/xla/service/sharding_propagation.h).\n+\n+Pass to support dividing operations across devices along non-batch dimensions.\n+\n+### Handling of bfloat16\n+\n+See also\n+[`BFloat16ConversionFolding`](https://github.com/openxla/xla/blob/main/xla/hlo/transforms/simplifiers/bfloat16_conversion_folding.h),\n+[`BFloat16MixedPrecisionRemoval`](https://github.com/openxla/xla/blob/main/xla/hlo/transforms/simplifiers/float_normalization.h),\n+and\n+[`BFloat16Propagation`](https://github.com/openxla/xla/blob/main/xla/hlo/transforms/bfloat16_propagation.h).\n+\n+TPUs support bfloat16 as a lower-precision, more compact floating-point\n+representation than 32-bit floats. Using bfloat16 reduces memory footprint and\n+memory bandwidth. The TPU HLO pipeline includes various passes for replacing\n+floats with bfloat16 into the program and propagating the precision through the\n+graph.\n+\n+### Legalization passes\n+\n+See also\n+[`GatherExpander`](https://github.com/openxla/xla/blob/main/xla/service/gather_expander.h),\n+and\n+[`BatchNormExpander`](https://github.com/openxla/xla/blob/main/xla/service/batchnorm_expander.h).\n+\n+Passes which transform unsupported HLO into a form which the backend can emit or\n+for which the backend produces a more efficient lowering.\n+\n+## GPU-specific HLO Pass Example\n+\n+Passes specific to the GPU backend are found in\n+[`xla/service/gpu`](https://github.com/openxla/xla/tree/main/xla/service/gpu).\n+These passes can be identified as classes defined in `namespace gpu`.\n+\n+### cuDNN Rewriter\n+\n+See also\n+[`CudnnFusedConvRewriter`](https://github.com/openxla/xla/blob/main/xla/service/gpu/transforms/cudnn_fused_conv_rewriter.h)\n+and\n+[`CudnnNormRewriter`](https://github.com/openxla/xla/blob/main/xla/service/gpu/transforms/cudnn_norm_rewriter.h).\n+\n+Rewrites fused convolution and norm operations into their respective library\n+calls in cuDNN.\n+\n+## CPU-specific HLO Pass Examples\n+\n+Passes specific to the CPU backend are found in\n+[`xla/service/cpu`](https://github.com/openxla/xla/tree/main/xla/service/cpu).\n+These passes can be identified as classes defined in `namespace cpu`.\n+\n+### Convolution Canonicalization\n+\n+See also\n+[`ConvCanonicalization`](https://github.com/openxla/xla/blob/main/xla/service/cpu/conv_canonicalization.h).\n+\n+Canonicalizes convolutions so that they can be lowered to a fast implementation\n+in Eigen.\n+\n+### Operation Parallelization\n+\n+See also\n+[`ParallelTaskAssigner`](https://github.com/openxla/xla/blob/main/xla/service/cpu/parallel_task_assignment.h).\n+\n+Partitions HLOs into tasks to run on separate threads.\n+\n+## Analysis passes\n+\n+Analysis passes are not considered \"HLO passes\" since they do not transform HLO\n+and may not extend `HloModulePass` or `HloModuleGroupPass`. Shared analyses are\n+found in\n+[`xla/hlo/analysis`](https://github.com/openxla/xla/tree/main/xla/hlo/analysis).\n+\n+### Analysis Pass Examples\n+\n+#### Dataflow Analysis\n+\n+See also\n+[`HloDataflowAnalysis`](https://github.com/openxla/xla/tree/main/xla/hlo/analysis/hlo_dataflow_analysis.h).\n+\n+Identifies all HLO values in the graph and their uses.\n+\n+#### Alias Analysis\n+\n+See also\n+[`HloAliasAnalysis`](https://github.com/openxla/xla/tree/main/xla/hlo/analysis/hlo_alias_analysis.h).\n+\n+Identifies must-alias relationships between values in the program.\n+\n+#### Computation Cost Analysis\n+\n+See also\n+[`HloCostAnalysis`](https://github.com/openxla/xla/tree/main/xla/service/hlo_cost_analysis.h).\n+\n+Computes FLOP count and memory usage for all operations in the program.\n+\n+#### HLO Verification\n+\n+See also\n+[`HloVerifier`](https://github.com/openxla/xla/tree/main/xla/service/hlo_verifier.h).\n+\n+Verifies various invariants of the HLO graph."
        },
        {
            "sha": "feb8202a04a43b2c132591af2c8ab631b55d8b45",
            "filename": "third_party/xla/docs/terminology.md",
            "status": "modified",
            "additions": 62,
            "deletions": 58,
            "changes": 120,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32519f7156b4261ebb104858d88de23726fede0a/third_party%2Fxla%2Fdocs%2Fterminology.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32519f7156b4261ebb104858d88de23726fede0a/third_party%2Fxla%2Fdocs%2Fterminology.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Fterminology.md?ref=32519f7156b4261ebb104858d88de23726fede0a",
            "patch": "@@ -4,61 +4,65 @@ There are several terms that are used in the context of XLA, MLIR, LLVM, and\n other related technologies. Below is a partial list of these terms and their\n definitions.\n \n-- **OpenXLA**\n-  - OpenXLA is an open ecosystem of performant, portable, and extensible machine\n-  learning (ML) infrastructure\n-  components that simplify ML development by defragmenting the tools between\n-  frontend frameworks and hardware backends. It includes the XLA compiler,\n-  StableHLO, VHLO, [PJRT](https://openxla.org/xla/pjrt) and other\n-  components.\n-- **XLA**\n-  - XLA (Accelerated Linear Algebra) is an open source compiler for machine\n-  learning. The XLA compiler takes models from popular frameworks such as\n-  PyTorch, TensorFlow, and JAX, and optimizes the models for high-performance\n-  execution across different hardware platforms including GPUs, CPUs, and ML\n-  accelerators. The XLA compiler outputs some code to LLVM, some to \"standard\"\n-  MLIR, and some to [Triton MLIR](https://triton-lang.org/main/dialects/dialects.html)\n-  that is processed by (MLIR-based) OpenAI Triton compiler.\n-- **PJRT**\n-  - [PJRT](https://github.com/openxla/xla/blob/main/xla/pjrt/c/pjrt_c_api.h) is\n-  a uniform Device API that simplifies the growing complexity of ML workload\n-  execution across hardware and frameworks. It provides a hardware and framework\n-  independent interface for compilers and runtimes.\n-- **StableHLO**\n-  - StableHLO is the public interface to OpenXLA, it is a standardized MLIR\n-  dialect that may be used by different frameworks and compilers in the OpenXLA\n-  ecosystem. XLA supports StableHLO, and immediately converts it to HLO on the\n-  input. There are some [StableHLO to StableHLO](https://openxla.org/stablehlo/generated/stablehlo_passes)\n-  passes implemented using the MLIR framework. It is also possible to convert\n-  StableHLO to other compilers' IR without using HLO, for example in cases where\n-  an existing IR is more appropriate.\n-- **CHLO**\n-  - CHLO is a collection of higher level operations which are optionally\n-  decomposable to StableHLO.\n-- **VHLO**\n-  - The [VHLO Dialect](https://openxla.org/stablehlo/vhlo) is a MLIR dialect\n-  that is a compatibility layer on top of StableHLO. It provides a snapshot of\n-  the StableHLO dialect at a given point in time by versioning individual\n-  program elements, and is used for serialization and stability.\n-- **MHLO**\n-  - MHLO is a standalone MLIR-based representation of XLA's HLO IR. The dialect\n-  is being evaluated for deprecation, and new users of the dialect should prefer\n-  to use StableHLO instead.\n-- **HLO**\n-  - HLO is an internal graph representation (IR) for the XLA compiler (and also\n-  supported input). It is **not** based on MLIR, and has its own textual syntax\n-  and binary (protobuf based) representation.\n-- **MLIR**\n-    - [MLIR](https://mlir.llvm.org) is a hybrid IR infrastructure that\n-    allows users to define \"dialects\" of operations at varying degrees of\n-    abstraction, and gradually lower between these opsets, performing\n-    transformations at each level of granularity. StableHLO and CHLO are two\n-    examples of MLIR dialects.\n-- **LLVM**\n-    - [LLVM](https://llvm.org/) is a compiler backend, and a language that it\n-    takes as an input. Many compilers generate LLVM code as a first step, and\n-    then LLVM generates machine code from it. This allows developers to reuse\n-    code that is similar in different compilers, and also makes supporting\n-    different target platforms easier. XLA:GPU and CPU backends have\n-    [LLVM IR emitters](https://github.com/openxla/xla/tree/main/xla/service/llvm_ir)\n-    for targeting specific hardware.\n+-   **OpenXLA**\n+    -   OpenXLA is an open ecosystem of performant, portable, and extensible\n+        machine learning (ML) infrastructure components that simplify ML\n+        development by defragmenting the tools between frontend frameworks and\n+        hardware backends. It includes the XLA compiler, StableHLO, VHLO,\n+        [PJRT](https://openxla.org/xla/pjrt) and other components.\n+-   **XLA**\n+    -   XLA (Accelerated Linear Algebra) is an open source compiler for machine\n+        learning. The XLA compiler takes models from popular frameworks such as\n+        PyTorch, TensorFlow, and JAX, and optimizes the models for\n+        high-performance execution across different hardware platforms including\n+        GPUs, CPUs, and ML accelerators. The XLA compiler outputs some code to\n+        LLVM, some to \"standard\" MLIR, and some to\n+        [Triton MLIR](https://triton-lang.org/main/dialects/dialects.html) that\n+        is processed by (MLIR-based) OpenAI Triton compiler.\n+-   **PJRT**\n+    -   [PJRT](https://github.com/openxla/xla/blob/main/xla/pjrt/c/pjrt_c_api.h)\n+        is a uniform Device API that simplifies the growing complexity of ML\n+        workload execution across hardware and frameworks. It provides a\n+        hardware and framework independent interface for compilers and runtimes.\n+-   **StableHLO**\n+    -   StableHLO is the public interface to OpenXLA, it is a standardized MLIR\n+        dialect that may be used by different frameworks and compilers in the\n+        OpenXLA ecosystem. XLA supports StableHLO, and immediately converts it\n+        to HLO on the input. There are some\n+        [StableHLO to StableHLO](https://openxla.org/stablehlo/generated/stablehlo_passes)\n+        passes implemented using the MLIR framework. It is also possible to\n+        convert StableHLO to other compilers' IR without using HLO, for example\n+        in cases where an existing IR is more appropriate.\n+-   **CHLO**\n+    -   CHLO is a collection of higher level operations which are optionally\n+        decomposable to StableHLO.\n+-   **VHLO**\n+    -   The [VHLO Dialect](https://openxla.org/stablehlo/vhlo) is a MLIR dialect\n+        that is a compatibility layer on top of StableHLO. It provides a\n+        snapshot of the StableHLO dialect at a given point in time by versioning\n+        individual program elements, and is used for serialization and\n+        stability.\n+-   **MHLO**\n+    -   MHLO is a standalone MLIR-based representation of XLA's HLO IR. The\n+        dialect is being evaluated for deprecation, and new users of the dialect\n+        should prefer to use StableHLO instead.\n+-   **HLO**\n+    -   HLO (High Level Optimizer) is an internal graph representation (IR) for\n+        the XLA compiler (and also supported input). It is **not** based on\n+        MLIR, and has its own textual syntax and binary (protobuf based)\n+        representation.\n+-   **MLIR**\n+    -   [MLIR](https://mlir.llvm.org) is a hybrid IR infrastructure that allows\n+        users to define \"dialects\" of operations at varying degrees of\n+        abstraction, and gradually lower between these opsets, performing\n+        transformations at each level of granularity. StableHLO and CHLO are two\n+        examples of MLIR dialects.\n+-   **LLVM**\n+    -   [LLVM](https://llvm.org/) is a compiler backend, and a language that it\n+        takes as an input. Many compilers generate LLVM code as a first step,\n+        and then LLVM generates machine code from it. This allows developers to\n+        reuse code that is similar in different compilers, and also makes\n+        supporting different target platforms easier. XLA:GPU and CPU backends\n+        have\n+        [LLVM IR emitters](https://github.com/openxla/xla/tree/main/xla/service/llvm_ir)\n+        for targeting specific hardware."
        }
    ],
    "stats": {
        "total": 353,
        "additions": 295,
        "deletions": 58
    }
}