{
    "author": "olegshyshkov",
    "message": "[XLA:GPU] Change template parameter on vector size in bytes.\n\nInstead of passing a primitive type. This way the kernel can be more flexible and in the future we'll be able to make a decision of we want bigger vector size or unrolling.\n\nPiperOrigin-RevId: 802982408",
    "sha": "aeb53525b8214e94e3cd64a0342ac384a052b5f3",
    "files": [
        {
            "sha": "3ea99af65d570eaeb6572160619e1d1638c22a88",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 19,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aeb53525b8214e94e3cd64a0342ac384a052b5f3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aeb53525b8214e94e3cd64a0342ac384a052b5f3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all.cc?ref=aeb53525b8214e94e3cd64a0342ac384a052b5f3",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n #include <array>\n #include <cstddef>\n #include <cstdint>\n+#include <type_traits>\n \n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n@@ -37,7 +38,7 @@ namespace xla::gpu {\n \n namespace {\n \n-template <typename T>\n+template <int64_t kVectorSize>\n absl::Status LaunchTypedKernel(\n     se::Stream* stream, se::StreamExecutor* executor,\n     const se::ThreadDim& thread_dims, const se::BlockDim& block_dims,\n@@ -50,8 +51,9 @@ absl::Status LaunchTypedKernel(\n     se::DeviceMemoryBase output_offsets_buffer, int64_t num_updates_per_output,\n     int64_t num_row_elements) {\n   TF_ASSIGN_OR_RETURN(\n-      auto kernel, se::gpu::GpuKernelRegistry::GetGlobalRegistry()\n-                       .LoadKernel<se::gpu::RaggedAllToAllKernel<T>>(executor));\n+      auto kernel,\n+      se::gpu::GpuKernelRegistry::GetGlobalRegistry()\n+          .LoadKernel<se::gpu::RaggedAllToAllKernel<kVectorSize>>(executor));\n \n   return kernel.Launch(thread_dims, block_dims, stream, input_buffer,\n                        output_ptrs, input_offsets_buffer, send_sizes_buffer,\n@@ -63,11 +65,10 @@ absl::Status LaunchTypedKernel(\n \n bool IsRaggedAllToAllKernelSupported(int64_t num_outputs,\n                                      PrimitiveType element_type) {\n-  int bit_width = primitive_util::BitWidth(element_type);\n-\n   return num_outputs <= stream_executor::gpu::kMaxNumRaggedAllToAllOutputPtrs &&\n-         (bit_width == 8 || bit_width == 16 || bit_width == 32 ||\n-          bit_width == 64);\n+         // Currently, the kernel doesn't support data types that are smaller\n+         // than 1 byte.\n+         primitive_util::BitWidth(element_type) % 8 == 0;\n }\n \n absl::Status RunRaggedAllToAllKernel(\n@@ -94,11 +95,11 @@ absl::Status RunRaggedAllToAllKernel(\n   int64_t num_blocks_x = num_updates_per_output * num_outputs;\n \n   int64_t num_vectorized_row_elements = num_row_elements;\n-  int64_t vectorized_bitwidth = xla::primitive_util::BitWidth(element_type);\n+  int64_t vector_size_bytes = xla::primitive_util::BitWidth(element_type) / 8;\n \n-  while (num_vectorized_row_elements % 2 == 0 && vectorized_bitwidth < 64) {\n+  while (num_vectorized_row_elements % 2 == 0 && vector_size_bytes < 8) {\n     num_vectorized_row_elements /= 2;\n-    vectorized_bitwidth *= 2;\n+    vector_size_bytes *= 2;\n   }\n \n   // blockIdx.y and threadIdx.x are used to iterate over the elements of the\n@@ -122,21 +123,21 @@ absl::Status RunRaggedAllToAllKernel(\n \n   auto launch_kernel = [&](auto type) -> absl::Status {\n     using T = decltype(type);\n-    return LaunchTypedKernel<T>(\n+    return LaunchTypedKernel<T::value>(\n         stream, executor, thread_dims, block_dims, input_buffer, output_ptrs,\n         input_offsets_buffer, send_sizes_buffer, output_offsets_buffer,\n         num_updates_per_output, num_vectorized_row_elements);\n   };\n \n-  switch (vectorized_bitwidth) {\n+  switch (vector_size_bytes) {\n+    case 1:\n+      return launch_kernel(std::integral_constant<int64_t, 1>{});\n+    case 2:\n+      return launch_kernel(std::integral_constant<int64_t, 2>{});\n+    case 4:\n+      return launch_kernel(std::integral_constant<int64_t, 4>{});\n     case 8:\n-      return launch_kernel(uint8_t{});\n-    case 16:\n-      return launch_kernel(uint16_t{});\n-    case 32:\n-      return launch_kernel(uint32_t{});\n-    case 64:\n-      return launch_kernel(uint64_t{});\n+      return launch_kernel(std::integral_constant<int64_t, 8>{});\n     default:\n       return absl::InvalidArgumentError(absl::StrCat(\n           \"Unsupported element type: \","
        },
        {
            "sha": "62b353ba4462bcac970afe69f685a6fe462b1116",
            "filename": "third_party/xla/xla/stream_executor/cuda/ragged_all_to_all_kernel_cuda.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 14,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aeb53525b8214e94e3cd64a0342ac384a052b5f3/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fragged_all_to_all_kernel_cuda.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aeb53525b8214e94e3cd64a0342ac384a052b5f3/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fragged_all_to_all_kernel_cuda.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fragged_all_to_all_kernel_cuda.cc?ref=aeb53525b8214e94e3cd64a0342ac384a052b5f3",
            "patch": "@@ -14,27 +14,26 @@ limitations under the License.\n ==============================================================================*/\n \n #include <cstddef>\n-#include <cstdint>\n \n #include \"absl/base/casts.h\"\n #include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n #include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n #include \"xla/stream_executor/gpu/ragged_all_to_all_kernel.h\"\n #include \"xla/stream_executor/gpu/ragged_all_to_all_kernel_lib.cu.h\"\n \n-#define REGISTER_RAGGED_ALL_TO_ALL_KERNEL(TYPE, BITS)                        \\\n-  GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(                            \\\n-      RaggedAllToAllKernelCudaUInt##BITS,                                    \\\n-      stream_executor::gpu::RaggedAllToAllKernel<TYPE>,                      \\\n-      stream_executor::cuda::kCudaPlatformId, ([](size_t arity) {            \\\n-        return stream_executor::KernelLoaderSpec::CreateInProcessSymbolSpec( \\\n-            absl::bit_cast<void*>(                                           \\\n-                &stream_executor::gpu::RaggedAllToAllKernelImpl<TYPE>),      \\\n-            \"ragged_all_to_all_kernel_uint\" #BITS, arity);                   \\\n+#define REGISTER_RAGGED_ALL_TO_ALL_KERNEL(VECTOR_SIZE)                         \\\n+  GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(                              \\\n+      RaggedAllToAllKernelCuda##VECTOR_SIZE##Bytes,                            \\\n+      stream_executor::gpu::RaggedAllToAllKernel<VECTOR_SIZE>,                 \\\n+      stream_executor::cuda::kCudaPlatformId, ([](size_t arity) {              \\\n+        return stream_executor::KernelLoaderSpec::CreateInProcessSymbolSpec(   \\\n+            absl::bit_cast<void*>(                                             \\\n+                &stream_executor::gpu::RaggedAllToAllKernelImpl<VECTOR_SIZE>), \\\n+            \"ragged_all_to_all_kernel_\" #VECTOR_SIZE \"_bytes\", arity);         \\\n       }));\n \n // Register the kernel for different integer types using the macro\n-REGISTER_RAGGED_ALL_TO_ALL_KERNEL(uint8_t, 8);\n-REGISTER_RAGGED_ALL_TO_ALL_KERNEL(uint16_t, 16);\n-REGISTER_RAGGED_ALL_TO_ALL_KERNEL(uint32_t, 32);\n-REGISTER_RAGGED_ALL_TO_ALL_KERNEL(uint64_t, 64);\n+REGISTER_RAGGED_ALL_TO_ALL_KERNEL(1);\n+REGISTER_RAGGED_ALL_TO_ALL_KERNEL(2);\n+REGISTER_RAGGED_ALL_TO_ALL_KERNEL(4);\n+REGISTER_RAGGED_ALL_TO_ALL_KERNEL(8);"
        },
        {
            "sha": "d9d02457157e5d0b1244364f946174926574b117",
            "filename": "third_party/xla/xla/stream_executor/gpu/ragged_all_to_all_kernel.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aeb53525b8214e94e3cd64a0342ac384a052b5f3/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fragged_all_to_all_kernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aeb53525b8214e94e3cd64a0342ac384a052b5f3/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fragged_all_to_all_kernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fragged_all_to_all_kernel.h?ref=aeb53525b8214e94e3cd64a0342ac384a052b5f3",
            "patch": "@@ -29,7 +29,7 @@ inline constexpr int64_t kMaxNumRaggedAllToAllOutputPtrs = 8;\n \n // Defines a trait for the RaggedAllToAll kernel that can be used to register\n // and look up the kernel in the GPU kernel registry.\n-template <typename ElementT>\n+template <int64_t kVectorSize>\n struct RaggedAllToAllKernel {\n   using KernelType = stream_executor::TypedKernel<\n       stream_executor::DeviceMemoryBase,"
        },
        {
            "sha": "6d434ed91e0ad65110103216e28bd192454ae3f5",
            "filename": "third_party/xla/xla/stream_executor/gpu/ragged_all_to_all_kernel_lib.cu.h",
            "status": "modified",
            "additions": 13,
            "deletions": 3,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aeb53525b8214e94e3cd64a0342ac384a052b5f3/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fragged_all_to_all_kernel_lib.cu.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aeb53525b8214e94e3cd64a0342ac384a052b5f3/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fragged_all_to_all_kernel_lib.cu.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fragged_all_to_all_kernel_lib.cu.h?ref=aeb53525b8214e94e3cd64a0342ac384a052b5f3",
            "patch": "@@ -23,6 +23,12 @@ limitations under the License.\n \n namespace stream_executor::gpu {\n \n+// A helper structure to load and store data of fixed number of bytes.\n+template <int64_t kSize>\n+struct alignas(kSize) Vec {\n+  uint8_t data[kSize];\n+};\n+\n // RaggedAllToAll instruction performs a collective AllToAll operation on ragged\n // tensors. For the semantics of each operand see the documentation of\n // `RaggedAllToAll` HLO instruction.\n@@ -50,17 +56,20 @@ namespace stream_executor::gpu {\n // Launch parameters:\n //  - Block grid: (N*num_updates_per_rank, num_blocks_per_update, 1)\n //  - Thread grid: (num_threads_per_update, 1, 1)\n-template <typename T>\n+template <int64_t kVectorSize>\n __global__ void __launch_bounds__(128) RaggedAllToAllKernelImpl(\n-    const T* __restrict__ input_ptr,\n+    const void* __restrict__ input_ptr,\n     std::array<void* __restrict__, kMaxNumRaggedAllToAllOutputPtrs> output_ptrs,\n     const int64_t* __restrict__ input_offsets_ptr,\n     const int64_t* __restrict__ send_sizes_ptr,\n     const int64_t* __restrict__ output_offsets_ptr,\n     int64_t num_updates_per_replica, int64_t num_row_elements) {\n+  using T = Vec<kVectorSize>;\n+\n   int64_t update_idx = blockIdx.x;\n   int64_t output_idx = update_idx / num_updates_per_replica;\n \n+  const T* typed_input_ptr = static_cast<const T* __restrict__>(input_ptr);\n   T* output_ptr = static_cast<T* __restrict__>(output_ptrs[output_idx]);\n \n   int64_t input_offset = input_offsets_ptr[update_idx];\n@@ -74,7 +83,8 @@ __global__ void __launch_bounds__(128) RaggedAllToAllKernelImpl(\n \n   for (int64_t i = threadIdx.x + blockIdx.y * blockDim.x; i < update_size;\n        i += blockDim.x * gridDim.y) {\n-    output_ptr[output_offset_start + i] = input_ptr[input_offset_start + i];\n+    output_ptr[output_offset_start + i] =\n+        typed_input_ptr[input_offset_start + i];\n   }\n }\n }  // namespace stream_executor::gpu"
        },
        {
            "sha": "48f30fdef147f83e5db65cd09914e68eec5f7a43",
            "filename": "third_party/xla/xla/stream_executor/rocm/ragged_all_to_all_kernel_rocm.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 15,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/aeb53525b8214e94e3cd64a0342ac384a052b5f3/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fragged_all_to_all_kernel_rocm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/aeb53525b8214e94e3cd64a0342ac384a052b5f3/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fragged_all_to_all_kernel_rocm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Fragged_all_to_all_kernel_rocm.cc?ref=aeb53525b8214e94e3cd64a0342ac384a052b5f3",
            "patch": "@@ -13,28 +13,26 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include <array>\n #include <cstddef>\n-#include <cstdint>\n \n #include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n #include \"xla/stream_executor/gpu/ragged_all_to_all_kernel.h\"\n #include \"xla/stream_executor/gpu/ragged_all_to_all_kernel_lib.cu.h\"\n #include \"xla/stream_executor/rocm/rocm_platform_id.h\"\n \n-#define REGISTER_RAGGED_ALL_TO_ALL_KERNEL(TYPE, BITS)                        \\\n-  GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(                            \\\n-      RaggedAllToAllKernelRocmUInt##BITS,                                    \\\n-      stream_executor::gpu::RaggedAllToAllKernel<TYPE>,                      \\\n-      stream_executor::rocm::kROCmPlatformId, ([](size_t arity) {            \\\n-        return stream_executor::KernelLoaderSpec::CreateInProcessSymbolSpec( \\\n-            absl::bit_cast<void*>(                                           \\\n-                &stream_executor::gpu::RaggedAllToAllKernelImpl<TYPE>),      \\\n-            \"ragged_all_to_all_kernel_uint\" #BITS, arity);                   \\\n+#define REGISTER_RAGGED_ALL_TO_ALL_KERNEL(VECTOR_SIZE)                         \\\n+  GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(                              \\\n+      RaggedAllToAllKernelRocm##VECTOR_SIZE##Bytes,                            \\\n+      stream_executor::gpu::RaggedAllToAllKernel<VECTOR_SIZE>,                 \\\n+      stream_executor::rocm::kROCmPlatformId, ([](size_t arity) {              \\\n+        return stream_executor::KernelLoaderSpec::CreateInProcessSymbolSpec(   \\\n+            absl::bit_cast<void*>(                                             \\\n+                &stream_executor::gpu::RaggedAllToAllKernelImpl<VECTOR_SIZE>), \\\n+            \"ragged_all_to_all_kernel_\" #VECTOR_SIZE \"_bytes\", arity);         \\\n       }));\n \n // Register the kernel for different integer types using the macro\n-REGISTER_RAGGED_ALL_TO_ALL_KERNEL(uint8_t, 8);\n-REGISTER_RAGGED_ALL_TO_ALL_KERNEL(uint16_t, 16);\n-REGISTER_RAGGED_ALL_TO_ALL_KERNEL(uint32_t, 32);\n-REGISTER_RAGGED_ALL_TO_ALL_KERNEL(uint64_t, 64);\n+REGISTER_RAGGED_ALL_TO_ALL_KERNEL(1);\n+REGISTER_RAGGED_ALL_TO_ALL_KERNEL(2);\n+REGISTER_RAGGED_ALL_TO_ALL_KERNEL(4);\n+REGISTER_RAGGED_ALL_TO_ALL_KERNEL(8);"
        }
    ],
    "stats": {
        "total": 112,
        "additions": 60,
        "deletions": 52
    }
}