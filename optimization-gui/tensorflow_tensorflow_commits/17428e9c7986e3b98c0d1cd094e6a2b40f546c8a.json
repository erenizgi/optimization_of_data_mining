{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 845650168",
    "sha": "17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
    "files": [
        {
            "sha": "e7700d1076c1329ecd6ddadcde39f72f8a843483",
            "filename": "tensorflow/core/common_runtime/eager/attr_builder.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 12,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fattr_builder.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fattr_builder.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fattr_builder.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -35,13 +35,14 @@ namespace {\n \n mutex g_op_name_to_attr_type_map_lock(LINKER_INITIALIZED);\n \n-tensorflow::gtl::FlatMap<string, const AttrTypeMap*>* OpNameToAttrTypeMap() {\n+tensorflow::gtl::FlatMap<std::string, const AttrTypeMap*>*\n+OpNameToAttrTypeMap() {\n   static auto* const m =\n-      new tensorflow::gtl::FlatMap<string, const AttrTypeMap*>;\n+      new tensorflow::gtl::FlatMap<std::string, const AttrTypeMap*>;\n   return m;\n }\n \n-const uint32 kIsList = 1U << 31;\n+const uint32_t kIsList = 1U << 31;\n \n AttrTypeMap* DefaultFunctionAttrTypeMap() {\n   AttrTypeMap* map = new AttrTypeMap();\n@@ -57,7 +58,7 @@ const AttrTypeMap* GetDefaultFunctionAttrTypeMap() {\n \n }  // namespace\n \n-absl::Status OpDefForOp(const string& op_name, const OpDef** op_def) {\n+absl::Status OpDefForOp(const std::string& op_name, const OpDef** op_def) {\n   const OpRegistrationData* op_reg_data = nullptr;\n   absl::Status s = OpRegistry::Global()->LookUp(op_name, &op_reg_data);\n   if (s.ok()) {\n@@ -102,12 +103,12 @@ absl::Status AttrTypeMapForOp(const char* op_name, const AttrTypeMap** out,\n   // TODO(agarwal): Avoid having to create this \"registry\" at runtime,\n   // perhaps can be done at op registration time?\n   for (const auto& attr : op_def->attr()) {\n-    string type = attr.type();\n+    std::string type = attr.type();\n     const bool is_list = (type.length() > 6 && type.compare(0, 4, \"list\") == 0);\n     if (is_list) {\n       type = type.substr(5, type.length() - 6);\n     }\n-    uint32 t = is_list ? kIsList : 0;\n+    uint32_t t = is_list ? kIsList : 0;\n     if (type == \"string\") {\n       t |= TF_ATTR_STRING;\n     } else if (type == \"int\") {\n@@ -163,7 +164,7 @@ DEFINE_GET_ATTR(tensorflow::DataType, type, \"type\");\n template <>\n absl::Status AttrBuilder::Get(absl::string_view attr_name,\n                               absl::InlinedVector<DataType, 4>* value) const {\n-  auto it = encoded_attrs_.find(string(attr_name));\n+  auto it = encoded_attrs_.find(std::string(attr_name));\n   if (it == encoded_attrs_.end()) {\n     return errors::NotFound(\"No attr named '\", attr_name,\n                             \"' found in AttrBuilder for \", op_name_);\n@@ -207,7 +208,7 @@ void AttrBuilder::FillAttrValueMap(AttrValueMap* m) const {\n \n namespace {\n \n-bool ValueMatchesDefault(const OpDef* op_def, const string& attr_name,\n+bool ValueMatchesDefault(const OpDef* op_def, const std::string& attr_name,\n                          const AttrValue& attr_value) {\n   // TODO(iga): It might make sense to augment OpRegistrationData with a\n   // {attr_name -> default_attr_value} FlatMap to avoid the loop here.\n@@ -238,7 +239,7 @@ void AttrBuilder::FillAttrValueMapWithoutDefaults(AttrValueMap* m) const {\n \n void AttrBuilder::AddAttrIfNotPresent(absl::string_view attr_name,\n                                       const AttrValue& value) {\n-  encoded_attrs_.emplace(string(attr_name), value.SerializeAsString());\n+  encoded_attrs_.emplace(std::string(attr_name), value.SerializeAsString());\n }\n \n const NodeDef& AttrBuilder::BuildNodeDef() {\n@@ -260,7 +261,7 @@ void AttrBuilder::CopyAttributes(const AttrBuilder& other) {\n                         other.encoded_attrs_.end());\n }\n \n-absl::Status AttrTypeByName(const AttrTypeMap& m, const string& attr_name,\n+absl::Status AttrTypeByName(const AttrTypeMap& m, const std::string& attr_name,\n                             TF_AttrType* out, unsigned char* is_list) {\n   auto* t = gtl::FindOrNull(m, attr_name);\n   if (t == nullptr) {\n@@ -290,7 +291,7 @@ inline tensorflow::Fprint128 CacheKeyHelper(absl::string_view s,\n   return FingerprintCat128(a, b);\n }\n \n-inline tensorflow::Fprint128 CacheKeyHelper(absl::string_view s, uint64 b) {\n+inline tensorflow::Fprint128 CacheKeyHelper(absl::string_view s, uint64_t b) {\n   return CacheKeyHelper(s, {b, b});\n }\n \n@@ -299,7 +300,7 @@ inline tensorflow::Fprint128 CacheKeyHelper(absl::string_view s, uint64 b) {\n tensorflow::Fprint128 AttrBuilder::CacheKey(const absl::string_view device) {\n   if (!cached_cache_key_ || device != device_for_cached_cache_key_) {\n     cached_cache_key_ = BuildCacheKeyForDevice(device);\n-    device_for_cached_cache_key_ = string(device);\n+    device_for_cached_cache_key_ = std::string(device);\n   }\n \n   return *cached_cache_key_;"
        },
        {
            "sha": "bdd644a6331ca6aee10e7e61632d628edd617abb",
            "filename": "tensorflow/core/common_runtime/eager/attr_builder.h",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fattr_builder.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fattr_builder.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fattr_builder.h?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -40,10 +40,10 @@ namespace tensorflow {\n // If the type is not a list type, the value is the same as the TF_AttrType type\n // of the value. Else, the highest order bit is on, and the rest of the bits\n // represent the TF_AttrType type of the values in the list.\n-typedef std::unordered_map<string, uint32> AttrTypeMap;\n+typedef std::unordered_map<std::string, uint32_t> AttrTypeMap;\n \n // Look up OpDef for `op_name`.\n-absl::Status OpDefForOp(const string& op_name, const OpDef** op_def);\n+absl::Status OpDefForOp(const std::string& op_name, const OpDef** op_def);\n \n // Returns the AttrTypeMap for the TensorFlow operation named op_name.\n // If op_name is not registered in global op registry, AttrTypeMapForOp assumes\n@@ -53,7 +53,7 @@ absl::Status AttrTypeMapForOp(const char* op_name, const AttrTypeMap** out,\n                               bool* is_function);\n \n // Looks for 'attr_name' in 'm' and sets 'out' and 'is_list'.\n-absl::Status AttrTypeByName(const AttrTypeMap& m, const string& attr_name,\n+absl::Status AttrTypeByName(const AttrTypeMap& m, const std::string& attr_name,\n                             TF_AttrType* out, unsigned char* is_list);\n \n // KernelAndDevice::Init needs a NodeDef only to pass the attribute map through.\n@@ -111,8 +111,8 @@ class AttrBuilder : public AbstractOpAttrs {\n     device_for_cached_cache_key_.clear();\n   }\n \n-  const string& op_name() const { return op_name_; }\n-  void set_op_name(const string& name) { op_name_ = name; }\n+  const std::string& op_name() const { return op_name_; }\n+  void set_op_name(const std::string& name) { op_name_ = name; }\n \n   // Needed to work around call to ValidateNodeDef in CreateOpKernel.\n   AttrBuilder& NumInputs(int n);\n@@ -186,7 +186,7 @@ class AttrBuilder : public AbstractOpAttrs {\n   tensorflow::Fprint128 BuildCacheKeyForDevice(absl::string_view device) const;\n \n   template <class T>\n-  void SetInAttrValueMap(AttrValueMap* m, const string& attr_name,\n+  void SetInAttrValueMap(AttrValueMap* m, const std::string& attr_name,\n                          T&& value) const {\n     DCHECK(!node_def_finalized_)\n         << \"Calling SetInAttrValueMap after BuildNodeDef.\";\n@@ -196,17 +196,17 @@ class AttrBuilder : public AbstractOpAttrs {\n \n   void AddAttrIfNotPresent(absl::string_view attr_name, const AttrValue& value);\n \n-  gtl::FlatMap<string, string> encoded_attrs_;\n+  gtl::FlatMap<std::string, std::string> encoded_attrs_;\n   mutable AttrValue attr_tmp_;  // For encoding\n \n-  string op_name_;\n+  std::string op_name_;\n   int num_inputs_;\n   NodeDef node_def_;\n   bool node_def_initialized_;\n   bool node_def_finalized_;\n \n   std::optional<tensorflow::Fprint128> cached_cache_key_;\n-  string device_for_cached_cache_key_;\n+  std::string device_for_cached_cache_key_;\n };\n \n template <>"
        },
        {
            "sha": "e0a35cfc59c524e6fd8dc4eac850f65108ae6c6c",
            "filename": "tensorflow/core/common_runtime/eager/attr_builder_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fattr_builder_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fattr_builder_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fattr_builder_test.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -85,8 +85,8 @@ TEST(AttrTypeMap, CacheKey) {\n   ASSERT_FALSE(cache_key == a.CacheKey(\"cpu:0\"));\n }\n \n-string ToString(const AttrValueMap& m) {\n-  std::vector<string> strs;\n+std::string ToString(const AttrValueMap& m) {\n+  std::vector<std::string> strs;\n   for (const auto& e : m) {\n     strs.push_back(absl::StrCat(e.first, \" -> \", e.second.DebugString()));\n   }"
        },
        {
            "sha": "358c51f22c098e4712a4011fca9b4cf0b1556734",
            "filename": "tensorflow/core/common_runtime/eager/context.cc",
            "status": "modified",
            "additions": 63,
            "deletions": 56,
            "changes": 119,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -150,7 +150,8 @@ EagerContext::EagerContext(\n       allow_soft_placement_(opts.config.allow_soft_placement()),\n       num_active_steps_(0),\n       step_container_(std::make_unique<ScopedStepContainer>(\n-          0, [this](const string& name) { ClearResourceContainer(name); })),\n+          0,\n+          [this](const std::string& name) { ClearResourceContainer(name); })),\n       default_executor_(async,\n                         /*enable_streaming_enqueue=*/!opts.config.experimental()\n                             .disable_eager_executor_streaming_enqueue()),\n@@ -198,7 +199,7 @@ AbstractTensorInterface* EagerContext::CreateInt64Scalar(int64_t value) {\n   return new TensorInterface(Tensor(value));\n }\n \n-AbstractTensorInterface* EagerContext::CreateUint64Scalar(uint64 value) {\n+AbstractTensorInterface* EagerContext::CreateUint64Scalar(uint64_t value) {\n   return new TensorInterface(Tensor(value));\n }\n \n@@ -285,18 +286,19 @@ void EagerContext::InitPrioritizedDeviceTypeList() {\n namespace {\n // Using absl::StrJoin with lambda does not work in tf-lite builds.\n // TODO(b/148160441): Replace with absl::StrJoin once DeviceBase has operator<<.\n-std::vector<string> DevicesToString(const PrioritizedDeviceVector& devices) {\n-  std::vector<string> v;\n+std::vector<std::string> DevicesToString(\n+    const PrioritizedDeviceVector& devices) {\n+  std::vector<std::string> v;\n   v.reserve(devices.size());\n   for (const auto& p : devices) {\n     v.push_back(p.first->name());\n   }\n   return v;\n }\n \n-std::vector<string> DeviceTypesToString(\n+std::vector<std::string> DeviceTypesToString(\n     const PrioritizedDeviceTypeVector& types) {\n-  std::vector<string> v;\n+  std::vector<std::string> v;\n   v.reserve(types.size());\n   for (const auto& p : types) {\n     v.push_back(p.first.type_string());\n@@ -316,8 +318,8 @@ std::vector<string> DeviceTypesToString(\n Device* SelectBestMatchingDevice(const DeviceNameUtils::ParsedName& pattern,\n                                  const PrioritizedDeviceVector& existing,\n                                  const PrioritizedDeviceTypeVector& supported) {\n-  for (const std::pair<DeviceType, int32>& prioritized_type : supported) {\n-    for (const std::pair<Device*, int32>& prioritized_device : existing) {\n+  for (const std::pair<DeviceType, int32_t>& prioritized_type : supported) {\n+    for (const std::pair<Device*, int32_t>& prioritized_device : existing) {\n       Device* dev = prioritized_device.first;\n       if (DeviceType(dev->attributes().device_type()) ==\n               prioritized_type.first &&\n@@ -485,7 +487,7 @@ void EagerContext::ClearCachesAndDefaultExecutor() {\n   {\n     mutex_lock ml(metadata_mu_);\n     step_container_ = std::make_unique<ScopedStepContainer>(\n-        0, [this](const string& name) { ClearResourceContainer(name); });\n+        0, [this](const std::string& name) { ClearResourceContainer(name); });\n   }\n }\n \n@@ -509,7 +511,7 @@ ContextDevicePlacementPolicy EagerContext::GetDevicePlacementPolicy() const {\n }\n \n #if !defined(IS_MOBILE_PLATFORM)\n-std::vector<string> EagerContext::GetRemoteContexts() {\n+std::vector<std::string> EagerContext::GetRemoteContexts() {\n   tf_shared_lock l(remote_state_mu_);\n   return remote_contexts_;\n }\n@@ -520,9 +522,9 @@ bool EagerContext::IsRemoteContextsEmpty() {\n }\n \n void EagerContext::CloseAndClearAllRemoteContexts() {\n-  uint64 context_id;\n-  uint64 context_view_id;\n-  std::vector<string> remote_contexts_copy;\n+  uint64_t context_id;\n+  uint64_t context_view_id;\n+  std::vector<std::string> remote_contexts_copy;\n   {\n     mutex_lock l(remote_state_mu_);\n     if (!is_master_) return;\n@@ -541,8 +543,8 @@ void EagerContext::CloseAndClearAllRemoteContexts() {\n }\n \n void EagerContext::CloseRemoteContexts(\n-    const std::vector<string>& remote_contexts, uint64 context_id,\n-    uint64 context_view_id) {\n+    const std::vector<std::string>& remote_contexts, uint64_t context_id,\n+    uint64_t context_view_id) {\n   // Close all remote contexts.\n   eager::CloseContextRequest request;\n   request.set_context_id(context_id);\n@@ -689,21 +691,22 @@ EagerContext::~EagerContext() {\n   }\n }\n \n-bool EagerContext::FindFunctionByName(const string& name) const {\n+bool EagerContext::FindFunctionByName(const std::string& name) const {\n   return func_lib_def_.Find(name) != nullptr;\n }\n \n absl::Status EagerContext::FindFunctionOpData(\n-    const string& name, const tensorflow::OpRegistrationData** op_data) {\n+    const std::string& name, const tensorflow::OpRegistrationData** op_data) {\n   return func_lib_def_.LookUp(name, op_data);\n }\n \n-const FunctionDef* EagerContext::FindFunctionDef(const string& name) const {\n+const FunctionDef* EagerContext::FindFunctionDef(\n+    const std::string& name) const {\n   return func_lib_def_.Find(name);\n }\n \n core::RefCountPtr<FunctionRecord> EagerContext::FindRecord(\n-    const string& name) const {\n+    const std::string& name) const {\n   return func_lib_def_.FindRecord(name);\n }\n \n@@ -763,7 +766,7 @@ std::vector<Device*> EagerContext::ListAllTfDevices() {\n   // Since remote_device_mgr may also contain local devices, make sure no\n   // duplicated device is returned.\n   std::vector<Device*> devices;\n-  std::unordered_set<string> dev_names;\n+  std::unordered_set<std::string> dev_names;\n \n   if (local_device_mgr()) {\n     for (const auto& dev : local_device_mgr()->ListDevices()) {\n@@ -832,7 +835,7 @@ void EagerContext::EndStep() {\n     // TODO(b/139809335): This does not properly clean up remote resources\n     // Clean up the previous step container and create a new one.\n     step_container_ = std::make_unique<ScopedStepContainer>(\n-        0, [this](const string& name) { ClearResourceContainer(name); });\n+        0, [this](const std::string& name) { ClearResourceContainer(name); });\n   }\n }\n \n@@ -880,7 +883,7 @@ absl::Status EagerContext::MaybeRegisterFunctionRemotely(\n }\n \n absl::Status EagerContext::MaybeRemoveFunctionRemotely(\n-    const string& function_name) {\n+    const std::string& function_name) {\n   // Only client context can remove function on remote worker context.\n   if (!remote_device_manager_.Owned()) {\n     return absl::OkStatus();\n@@ -917,10 +920,10 @@ absl::Status EagerContext::MaybeRemoveFunctionRemotely(\n }\n \n absl::Status EagerContext::RegisterExistingFunctionsOnRemoteWorkers(\n-    const std::vector<string>& remote_workers) {\n+    const std::vector<std::string>& remote_workers) {\n #if !defined(IS_MOBILE_PLATFORM)\n   // Register multiple functions on selected remote workers.\n-  uint64 context_id = GetContextId();\n+  uint64_t context_id = GetContextId();\n   FunctionDefLibrary function_defs = func_lib_def_.ToProto();\n   std::vector<std::shared_ptr<eager::EnqueueRequest>> requests(\n       function_defs.function_size());\n@@ -1079,16 +1082,17 @@ absl::Status EagerContext::AddComponentFunction(\n   return absl::OkStatus();\n }\n \n-const FunctionDef* EagerContext::GetFunctionDef(const string& function_name) {\n+const FunctionDef* EagerContext::GetFunctionDef(\n+    const std::string& function_name) {\n   return func_lib_def_.Find(function_name);\n }\n \n-std::vector<string> EagerContext::ListFunctionNames() {\n+std::vector<std::string> EagerContext::ListFunctionNames() {\n   return func_lib_def_.ListFunctionNames();\n }\n \n absl::Status EagerContext::AddRemoveFunctionNotifier(\n-    const string& func, std::function<void()> notifier) {\n+    const std::string& func, std::function<void()> notifier) {\n   mutex_lock l(remove_function_notifiers_mu_);\n   auto iter = remove_function_notifiers_.find(func);\n   if (iter != remove_function_notifiers_.end()) {\n@@ -1122,7 +1126,7 @@ EagerContext::GetCacheStats() {\n   return stats;\n }\n \n-absl::Status EagerContext::RemoveFunction(const string& func) {\n+absl::Status EagerContext::RemoveFunction(const std::string& func) {\n   // TODO(mdan): The context owns these functions. Why check refcount then?\n   std::vector<std::function<void()>> notifiers;\n   bool is_last_ref = false;\n@@ -1308,14 +1312,14 @@ absl::Status EagerContext::FindCompositeDeviceFromName(\n   return errors::NotFound(\"Unknown composite device: \", device_name);\n }\n \n-bool EagerContext::IsCustomDevice(const string& device_name) {\n+bool EagerContext::IsCustomDevice(const std::string& device_name) {\n   CustomDevice* device = nullptr;\n   return custom_device_op_handler_.FindCustomDeviceFromName(device_name,\n                                                             &device);\n }\n \n absl::Status EagerContext::RegisterCustomDevice(\n-    const string& device_name, std::unique_ptr<CustomDevice> device) {\n+    const std::string& device_name, std::unique_ptr<CustomDevice> device) {\n   Device* existing_physical_device = nullptr;\n   if (FindDeviceFromName(device_name.c_str(), &existing_physical_device).ok()) {\n     return errors::AlreadyExists(device_name,\n@@ -1326,14 +1330,15 @@ absl::Status EagerContext::RegisterCustomDevice(\n }\n \n absl::Status EagerContext::FindOrCreateCompositeDevice(\n-    const std::vector<string>& underlying_devices, const string& device_name,\n-    CompositeDevice** composite_device) {\n+    const std::vector<std::string>& underlying_devices,\n+    const std::string& device_name, CompositeDevice** composite_device) {\n   if (!device_name.empty() &&\n       FindCompositeDeviceFromName(device_name, composite_device).ok()) {\n     return absl::OkStatus();\n   }\n \n-  const uint64 hash_key = Fingerprint64(absl::StrJoin(underlying_devices, \",\"));\n+  const uint64_t hash_key =\n+      Fingerprint64(absl::StrJoin(underlying_devices, \",\"));\n \n   mutex_lock l(composite_devices_mu_);\n   auto iter = composite_devices_.find(hash_key);\n@@ -1371,14 +1376,14 @@ bool EagerContext::OnSameTask(const Device* first, const Device* second) const {\n // Gets the CPU device on the task of device.\n absl::Status EagerContext::CPUDeviceOnTask(const Device* device,\n                                            Device** cpu_device) const {\n-  string cpu_device_name;\n+  std::string cpu_device_name;\n   TF_RETURN_IF_ERROR(DeviceNameUtils::DeviceNameToCpuDeviceName(\n       device->name(), &cpu_device_name));\n \n   return FindDeviceFromName(cpu_device_name.c_str(), cpu_device);\n }\n \n-void EagerContext::ClearResourceContainer(const string& name) {\n+void EagerContext::ClearResourceContainer(const std::string& name) {\n   // TODO(b/139809335): This does not properly clean up remote resources\n   auto local_devices = local_device_mgr()->ListDevices();\n   for (Device* device : local_devices) {\n@@ -1406,8 +1411,8 @@ void EagerContext::UpdateGlobalRendezvousDeviceManager(\n }\n \n namespace {\n-absl::Status GetTaskName(Device* d, string* task_name) {\n-  string ignored;\n+absl::Status GetTaskName(Device* d, std::string* task_name) {\n+  std::string ignored;\n   if (!DeviceNameUtils::SplitDeviceName(d->name(), task_name, &ignored)) {\n     return errors::InvalidArgument(\"Unable to parse device name: \", d->name());\n   }\n@@ -1425,7 +1430,7 @@ absl::Status EagerContext::GetClient(\n absl::Status EagerContext::GetClient(\n     const DeviceNameUtils::ParsedName& device_name,\n     core::RefCountPtr<eager::EagerClient>* client) {\n-  string device_task_name;\n+  std::string device_task_name;\n   if (!DeviceNameUtils::GetTaskName(device_name, &device_task_name)) {\n     return errors::InvalidArgument(\n         \"Task is not fully specified in device name: \",\n@@ -1457,7 +1462,8 @@ absl::Status EagerContext::GetClient(\n }\n \n absl::Status EagerContext::GetClient(\n-    const string& remote_task, core::RefCountPtr<eager::EagerClient>* client) {\n+    const std::string& remote_task,\n+    core::RefCountPtr<eager::EagerClient>* client) {\n   {\n     tf_shared_lock l(remote_state_mu_);\n     if (remote_eager_workers_ == nullptr) {\n@@ -1474,12 +1480,12 @@ absl::Status EagerContext::GetClient(\n   return absl::OkStatus();\n }\n \n-uint64 EagerContext::GetContextId() const {\n+uint64_t EagerContext::GetContextId() const {\n   tf_shared_lock l(remote_state_mu_);\n   return context_id_;\n }\n \n-uint64 EagerContext::GetContextViewId() const {\n+uint64_t EagerContext::GetContextViewId() const {\n   tf_shared_lock l(remote_state_mu_);\n   return context_view_id_;\n }\n@@ -1544,9 +1550,10 @@ absl::Status EagerContext::StoreCollectiveOpsServer(\n }\n \n absl::Status EagerContext::SetRemoteDeviceFilters(\n-    const string& remote_worker, const std::vector<string>& device_filters) {\n+    const std::string& remote_worker,\n+    const std::vector<std::string>& device_filters) {\n   // Get fully specified task name for remote worker\n-  string remote_worker_task_name;\n+  std::string remote_worker_task_name;\n   DeviceNameUtils::ParsedName pw;\n   if (!DeviceNameUtils::ParseFullName(remote_worker, &pw)) {\n     return tensorflow::errors::InvalidArgument(\n@@ -1583,7 +1590,7 @@ absl::Status EagerContext::SetRemoteDeviceFilters(\n }\n \n void EagerContext::FilterDevicesForRemoteWorkers(\n-    const string& remote_worker,\n+    const std::string& remote_worker,\n     const protobuf::RepeatedPtrField<DeviceAttributes>& device_attrs,\n     std::vector<bool>* filtered_device_mask) {\n   filtered_device_mask->resize(device_attrs.size());\n@@ -1634,7 +1641,7 @@ absl::Status EagerContext::InitializeRemoteMaster(\n     std::shared_ptr<WorkerSession> worker_session,\n     std::unique_ptr<eager::EagerClientCache> remote_eager_workers,\n     std::unique_ptr<DynamicDeviceMgr> remote_device_manager,\n-    const std::vector<string>& remote_contexts, uint64 context_id,\n+    const std::vector<std::string>& remote_contexts, uint64_t context_id,\n     tsl::core::RefCountPtr<Rendezvous> r, DeviceMgr* local_device_mgr,\n     int keep_alive_secs, DistributedFunctionLibraryRuntime* cluster_flr,\n     std::unique_ptr<eager::RemoteMgr, std::function<void(eager::RemoteMgr*)>>\n@@ -1661,10 +1668,10 @@ absl::Status EagerContext::InitializeRemoteMaster(\n }\n \n absl::Status EagerContext::UpdateRemoteMaster(\n-    uint64 context_id,\n+    uint64_t context_id,\n     std::unique_ptr<eager::EagerClientCache> remote_eager_workers,\n-    const std::vector<string>& add_remote_contexts,\n-    const std::vector<string>& remove_remote_contexts) {\n+    const std::vector<std::string>& add_remote_contexts,\n+    const std::vector<std::string>& remove_remote_contexts) {\n   {\n     tf_shared_lock l(remote_state_mu_);\n     if (context_id != context_id_) {\n@@ -1682,7 +1689,7 @@ absl::Status EagerContext::UpdateRemoteMaster(\n     // a larger view id and ignores this request.\n     CloseRemoteContexts(remove_remote_contexts, context_id, GetContextViewId());\n     mutex_lock l(remote_state_mu_);\n-    for (const string& remote_context : remove_remote_contexts) {\n+    for (const std::string& remote_context : remove_remote_contexts) {\n       remote_contexts_.erase(\n           std::remove(remote_contexts_.begin(), remote_contexts_.end(),\n                       remote_context),\n@@ -1731,10 +1738,10 @@ absl::Status EagerContext::SetMasterContextState(\n     std::unique_ptr<ServerInterface> server, WorkerEnv* worker_env,\n     std::shared_ptr<WorkerSession> worker_session,\n     std::unique_ptr<eager::EagerClientCache> remote_eager_workers,\n-    std::unique_ptr<DynamicDeviceMgr> remote_device_manager, uint64 context_id,\n-    uint64 context_view_id, tsl::core::RefCountPtr<Rendezvous> r,\n-    DeviceMgr* local_device_mgr, int keep_alive_secs,\n-    DistributedFunctionLibraryRuntime* cluster_flr,\n+    std::unique_ptr<DynamicDeviceMgr> remote_device_manager,\n+    uint64_t context_id, uint64_t context_view_id,\n+    tsl::core::RefCountPtr<Rendezvous> r, DeviceMgr* local_device_mgr,\n+    int keep_alive_secs, DistributedFunctionLibraryRuntime* cluster_flr,\n     std::unique_ptr<eager::RemoteMgr, std::function<void(eager::RemoteMgr*)>>\n         remote_mgr) {\n   mutex_lock l(remote_state_mu_);\n@@ -1852,8 +1859,8 @@ absl::Status EagerContext::SetMasterContextState(\n absl::Status EagerContext::InitializeRemoteWorker(\n     std::unique_ptr<eager::EagerClientCache> remote_eager_workers,\n     DynamicDeviceMgr* remote_device_mgr,\n-    const std::vector<string>& remote_contexts, uint64 context_id,\n-    uint64 context_view_id,\n+    const std::vector<std::string>& remote_contexts, uint64_t context_id,\n+    uint64_t context_view_id,\n     std::function<tsl::core::RefCountPtr<Rendezvous>(const int64_t)>\n         rendezvous_creator,\n     DistributedFunctionLibraryRuntime* cluster_flr,\n@@ -1908,7 +1915,7 @@ absl::Status EagerContext::InitializeRemoteWorker(\n \n absl::Status EagerContext::UpdateRemoteWorker(\n     std::unique_ptr<eager::EagerClientCache> remote_eager_workers,\n-    const std::vector<string>& remote_contexts, uint64 context_id) {\n+    const std::vector<std::string>& remote_contexts, uint64_t context_id) {\n   {\n     mutex_lock l(remote_state_mu_);\n     if (context_id != context_id_) {"
        },
        {
            "sha": "1013cc17bf95fed175b7fdaf032cd711018472cb",
            "filename": "tensorflow/core/common_runtime/eager/context.h",
            "status": "modified",
            "additions": 46,
            "deletions": 44,
            "changes": 90,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext.h?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -86,10 +86,10 @@ bool SkipRemoteHandleWaitReady();\n \n class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n  public:\n-  static constexpr uint64 kInvalidContextId = 0;\n+  static constexpr uint64_t kInvalidContextId = 0;\n \n-  static uint64 NewContextId() {\n-    uint64 context_id = random::New64();\n+  static uint64_t NewContextId() {\n+    uint64_t context_id = random::New64();\n     while (context_id == kInvalidContextId) {\n       context_id = random::New64();\n     }\n@@ -108,7 +108,7 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   void Release() override { Unref(); }\n \n   AbstractTensorInterface* CreateInt64Scalar(int64_t value) override;\n-  AbstractTensorInterface* CreateUint64Scalar(uint64 value) override;\n+  AbstractTensorInterface* CreateUint64Scalar(uint64_t value) override;\n   AbstractTensorInterface* CreateInt32Scalar(int32_t value) override;\n   AbstractTensorInterface* CreateFloatScalar(float value) override;\n   AbstractTensorInterface* CreateDoubleScalar(double value) override;\n@@ -208,14 +208,14 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n                             const NodeDef& ndef, Device** out) const;\n \n   // TODO(mdan): Rename to ContainsFunction.\n-  bool FindFunctionByName(const string& name) const;\n+  bool FindFunctionByName(const std::string& name) const;\n \n   absl::Status FindFunctionOpData(\n-      const string& name, const tensorflow::OpRegistrationData** op_data);\n+      const std::string& name, const tensorflow::OpRegistrationData** op_data);\n \n-  const FunctionDef* FindFunctionDef(const string& name) const override;\n+  const FunctionDef* FindFunctionDef(const std::string& name) const override;\n   core::RefCountPtr<FunctionRecord> FindRecord(\n-      const string& name) const override;\n+      const std::string& name) const override;\n \n   Device* HostCPU() const { return host_cpu_device_; }\n   Device* CanonicalDevice(Device* d) const {\n@@ -225,7 +225,7 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n     return HostCPU()->parsed_name();\n   }\n \n-  const string& HostCPUName() const override { return HostCPU()->name(); }\n+  const std::string& HostCPUName() const override { return HostCPU()->name(); }\n \n   GraphCollector* GetGraphCollector() { return &graph_collector_; }\n \n@@ -263,14 +263,14 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   absl::Status AddComponentFunction(const FunctionDef& fdef,\n                                     const FunctionDefLibrary& library);\n \n-  const FunctionDef* GetFunctionDef(const string& function_name);\n+  const FunctionDef* GetFunctionDef(const std::string& function_name);\n \n-  std::vector<string> ListFunctionNames() override;\n+  std::vector<std::string> ListFunctionNames() override;\n   tensorflow::ImmediateExecutionContext::CacheStats GetCacheStats() override;\n \n-  absl::Status RemoveFunction(const string& func) override;\n+  absl::Status RemoveFunction(const std::string& func) override;\n   absl::Status AddRemoveFunctionNotifier(\n-      const string& func, std::function<void()> notifier) override;\n+      const std::string& func, std::function<void()> notifier) override;\n \n   // Wait for pending nodes to be finished in local executors (including context\n   // default executor and thread executors) and executors on remote workers.\n@@ -401,7 +401,7 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   const FunctionLibraryDefinition* FuncLibDef() const { return &func_lib_def_; }\n \n   FunctionLibraryDefinition* GetComponentFunctionFunctionLibraryDefinition(\n-      const string& function_name) {\n+      const std::string& function_name) {\n     tf_shared_lock lock(cache_mu_);\n     auto iter = component_function_libraries_.find(function_name);\n     if (iter != component_function_libraries_.end()) {\n@@ -421,11 +421,11 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n                          core::RefCountPtr<eager::EagerClient>* client);\n   absl::Status GetClient(const DeviceNameUtils::ParsedName& device_name,\n                          core::RefCountPtr<eager::EagerClient>* client);\n-  absl::Status GetClient(const string& remote_task,\n+  absl::Status GetClient(const std::string& remote_task,\n                          core::RefCountPtr<eager::EagerClient>* client);\n \n-  uint64 GetContextId() const;\n-  uint64 GetContextViewId() const;\n+  uint64_t GetContextId() const;\n+  uint64_t GetContextViewId() const;\n   void IncrementContextViewId();\n \n   absl::Status EnableCollectiveOps(const ServerDef& server_def) override;\n@@ -450,7 +450,7 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n       std::shared_ptr<WorkerSession> worker_session,\n       std::unique_ptr<eager::EagerClientCache> remote_eager_workers,\n       std::unique_ptr<DynamicDeviceMgr> remote_device_manager,\n-      const std::vector<string>& remote_contexts, uint64 context_id,\n+      const std::vector<std::string>& remote_contexts, uint64_t context_id,\n       tsl::core::RefCountPtr<Rendezvous> r,\n       /*const*/ DeviceMgr* local_device_mgr, int keep_alive_secs,\n       DistributedFunctionLibraryRuntime* cluster_flr,\n@@ -464,18 +464,18 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   // can still be accessed, and will automatically register existing functions\n   // if there are newly added hosts.\n   absl::Status UpdateRemoteMaster(\n-      uint64 context_id,\n+      uint64_t context_id,\n       std::unique_ptr<eager::EagerClientCache> remote_eager_workers,\n-      const std::vector<string>& add_remote_contexts,\n-      const std::vector<string>& remove_remote_contexts);\n+      const std::vector<std::string>& add_remote_contexts,\n+      const std::vector<std::string>& remove_remote_contexts);\n \n   // Similar with InitializeRemoteMaster but this context will not kill remote\n   // contexts in shutdown.\n   absl::Status InitializeRemoteWorker(\n       std::unique_ptr<eager::EagerClientCache> remote_eager_workers,\n       DynamicDeviceMgr* remote_device_mgr,\n-      const std::vector<string>& remote_contexts, uint64 context_id,\n-      uint64 context_view_id,\n+      const std::vector<std::string>& remote_contexts, uint64_t context_id,\n+      uint64_t context_view_id,\n       std::function<tsl::core::RefCountPtr<Rendezvous>(const int64_t)>\n           rendezvous_creator,\n       DistributedFunctionLibraryRuntime* cluster_flr,\n@@ -487,15 +487,16 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   // increment context_view_id.\n   absl::Status UpdateRemoteWorker(\n       std::unique_ptr<eager::EagerClientCache> remote_eager_workers,\n-      const std::vector<string>& remote_contexts, uint64 context_id);\n+      const std::vector<std::string>& remote_contexts, uint64_t context_id);\n \n   absl::Status StoreCollectiveOpsServer(\n       std::unique_ptr<ServerInterface> new_server, DeviceMgr* device_mgr,\n       CollectiveExecutorMgrInterface* rpc_collective_executor_mgr);\n \n   // For the specified remote worker, preprocess and set its device filters.\n   absl::Status SetRemoteDeviceFilters(\n-      const string& remote_worker, const std::vector<string>& device_filters);\n+      const std::string& remote_worker,\n+      const std::vector<std::string>& device_filters);\n \n   // For the specified remote worker, apply the stored device filters to the\n   // list of device attributes following these rules:\n@@ -507,7 +508,7 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   // filtered_device_mask) indicating whether each of the devices is visible to\n   // the remote worker.\n   void FilterDevicesForRemoteWorkers(\n-      const string& remote_worker,\n+      const std::string& remote_worker,\n       const protobuf::RepeatedPtrField<DeviceAttributes>& device_attrs,\n       std::vector<bool>* filtered_device_mask);\n \n@@ -567,10 +568,10 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   absl::Status FindCompositeDeviceFromName(absl::string_view device_name,\n                                            CompositeDevice** device) const;\n \n-  bool IsCustomDevice(const string& device_name) override;\n+  bool IsCustomDevice(const std::string& device_name) override;\n \n   absl::Status RegisterCustomDevice(\n-      const string& name, std::unique_ptr<CustomDevice> device) override;\n+      const std::string& name, std::unique_ptr<CustomDevice> device) override;\n \n   CustomDeviceOpHandler& GetCustomDeviceOpHandler() override {\n     return custom_device_op_handler_;\n@@ -579,8 +580,8 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   // Find or create a composite device with the given `underlying_devices` and\n   // `device_name` (if not empty).\n   absl::Status FindOrCreateCompositeDevice(\n-      const std::vector<string>& underlying_devices, const string& device_name,\n-      CompositeDevice** composite_device);\n+      const std::vector<std::string>& underlying_devices,\n+      const std::string& device_name, CompositeDevice** composite_device);\n \n   bool OnSameTask(const Device* first, const Device* second) const;\n   // Gets the CPU device on the task of device.\n@@ -667,9 +668,9 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   ~EagerContext() override;\n \n   absl::Status MaybeRegisterFunctionRemotely(const FunctionDef& fdef);\n-  absl::Status MaybeRemoveFunctionRemotely(const string& function_name);\n+  absl::Status MaybeRemoveFunctionRemotely(const std::string& function_name);\n   absl::Status RegisterExistingFunctionsOnRemoteWorkers(\n-      const std::vector<string>& remote_workers);\n+      const std::vector<std::string>& remote_workers);\n \n   void ResetPFLR(const DeviceMgr* device_mgr, Env* env,\n                  const ConfigProto* config, int graph_def_version,\n@@ -681,7 +682,7 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   void ResetClusterFLR(DistributedFunctionLibraryRuntime* cluster_flr);\n   void UpdateGlobalRendezvousDeviceManager(tensorflow::DeviceMgr* device_mgr);\n \n-  void ClearResourceContainer(const string& name);\n+  void ClearResourceContainer(const std::string& name);\n \n   template <typename T>\n   struct OwnedOrUnownedHelper {\n@@ -750,7 +751,7 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   // Maps from the fingerprint of a set of device names to a virtual\n   // CompositeDevice.\n   // TODO(b/145922293): Consider taking device names as keys.\n-  absl::flat_hash_map<uint64, std::unique_ptr<CompositeDevice>>\n+  absl::flat_hash_map<uint64_t, std::unique_ptr<CompositeDevice>>\n       composite_devices_ ABSL_GUARDED_BY(composite_devices_mu_);\n \n   FunctionLibraryDefinition func_lib_def_{OpRegistry::Global(),\n@@ -780,10 +781,10 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   std::unordered_map<Fprint128, core::RefCountPtr<KernelAndDevice>,\n                      Fprint128Hasher>\n       kernel_cache_ TF_GUARDED_BY(cache_mu_);\n-  std::unordered_map<string, RegisteredFunction*> registered_functions_\n+  std::unordered_map<std::string, RegisteredFunction*> registered_functions_\n       TF_GUARDED_BY(cache_mu_);\n \n-  std::unordered_map<string, std::unique_ptr<FunctionLibraryDefinition>>\n+  std::unordered_map<std::string, std::unique_ptr<FunctionLibraryDefinition>>\n       component_function_libraries_ TF_GUARDED_BY(cache_mu_);\n   absl::flat_hash_map<Fprint128, Device*, Fprint128Hasher> device_cache_\n       TF_GUARDED_BY(device_cache_mu_);\n@@ -830,19 +831,20 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   OwnedOrUnownedHelper<CollectiveExecutorMgrInterface> collective_executor_mgr_;\n \n #if !defined(IS_MOBILE_PLATFORM)\n-  std::vector<string> GetRemoteContexts() TF_LOCKS_EXCLUDED(remote_state_mu_);\n+  std::vector<std::string> GetRemoteContexts()\n+      TF_LOCKS_EXCLUDED(remote_state_mu_);\n   bool IsRemoteContextsEmpty() TF_LOCKS_EXCLUDED(remote_state_mu_);\n   void CloseAndClearAllRemoteContexts();\n-  void CloseRemoteContexts(const std::vector<string>& remote_contexts,\n-                           uint64 context_id, uint64 context_view_id);\n+  void CloseRemoteContexts(const std::vector<std::string>& remote_contexts,\n+                           uint64_t context_id, uint64_t context_view_id);\n \n   // TODO(b/184375824): clean up parameter order for better readability.\n   absl::Status SetMasterContextState(\n       std::unique_ptr<ServerInterface> server, WorkerEnv* worker_env,\n       std::shared_ptr<WorkerSession> worker_session,\n       std::unique_ptr<eager::EagerClientCache> remote_eager_workers,\n       std::unique_ptr<DynamicDeviceMgr> remote_device_manager,\n-      uint64 context_id, uint64 context_view_id,\n+      uint64_t context_id, uint64_t context_view_id,\n       tsl::core::RefCountPtr<Rendezvous> r,\n       /*const*/ DeviceMgr* local_device_mgr, int keep_alive_secs,\n       DistributedFunctionLibraryRuntime* cluster_flr,\n@@ -858,12 +860,12 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n \n   mutable mutex remote_state_mu_;\n \n-  uint64 context_id_ TF_GUARDED_BY(remote_state_mu_);\n+  uint64_t context_id_ TF_GUARDED_BY(remote_state_mu_);\n   // The view id of an eager context should be set to 0 when context is created,\n   // and continuously incremented when context with the same context_id gets\n   // updated. The view id should be consistent between master and workers.\n-  uint64 context_view_id_ TF_GUARDED_BY(remote_state_mu_);\n-  std::vector<string> remote_contexts_ TF_GUARDED_BY(remote_state_mu_);\n+  uint64_t context_view_id_ TF_GUARDED_BY(remote_state_mu_);\n+  std::vector<std::string> remote_contexts_ TF_GUARDED_BY(remote_state_mu_);\n   std::unique_ptr<eager::EagerClientCache> remote_eager_workers_\n       TF_GUARDED_BY(remote_state_mu_);\n \n@@ -880,7 +882,7 @@ class EagerContext : public ImmediateExecutionContext, public core::RefCounted {\n   bool is_master_ TF_GUARDED_BY(remote_state_mu_);\n \n   // Maps from a remote worker to a list of parsed device filters.\n-  std::unordered_map<string, std::vector<DeviceNameUtils::ParsedName>>\n+  std::unordered_map<std::string, std::vector<DeviceNameUtils::ParsedName>>\n       cluster_device_filters_ TF_GUARDED_BY(remote_state_mu_);\n \n   // A distributed manager that helps setup, update, and check liveness of"
        },
        {
            "sha": "deeab20af15aea0f076e92266185e585c631a3ea",
            "filename": "tensorflow/core/common_runtime/eager/context_distributed_manager.cc",
            "status": "modified",
            "additions": 59,
            "deletions": 57,
            "changes": 116,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext_distributed_manager.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext_distributed_manager.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext_distributed_manager.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -362,7 +362,7 @@ bool AreLocalDevicesCompatible(const EagerContext* context,\n }\n \n absl::Status AddRemoteDevicesToMgr(\n-    const std::vector<string>& added_remote_workers,\n+    const std::vector<std::string>& added_remote_workers,\n     WorkerCacheInterface* worker_cache, DynamicDeviceMgr* remote_device_mgr) {\n   std::vector<std::unique_ptr<Device>> remote_devices;\n   mutex remote_devices_mu;\n@@ -394,7 +394,7 @@ absl::Status AddRemoteDevicesToMgr(\n }\n \n absl::Status GetAllRemoteDevices(\n-    const std::vector<string>& remote_workers,\n+    const std::vector<std::string>& remote_workers,\n     WorkerCacheInterface* worker_cache,\n     std::unique_ptr<DynamicDeviceMgr>* device_mgr) {\n   auto remote_device_mgr = std::make_unique<DynamicDeviceMgr>();\n@@ -405,13 +405,13 @@ absl::Status GetAllRemoteDevices(\n }\n \n absl::Status RemoveRemoteDevicesFromMgr(\n-    const std::vector<string>& removed_remote_workers,\n+    const std::vector<std::string>& removed_remote_workers,\n     DynamicDeviceMgr* remote_device_mgr) {\n   const std::vector<Device*> remote_devices =\n       (remote_device_mgr->ListDevices());\n   std::vector<Device*> devices_to_remove;\n   for (Device* d : remote_devices) {\n-    for (const string& remote_worker : removed_remote_workers) {\n+    for (const std::string& remote_worker : removed_remote_workers) {\n       if (DeviceNameUtils::IsSameAddressSpace(remote_worker, d->name())) {\n         devices_to_remove.emplace_back(d);\n         break;\n@@ -423,31 +423,31 @@ absl::Status RemoveRemoteDevicesFromMgr(\n }\n \n absl::Status ListRemoteWorkers(ServerInterface* server,\n-                               const string& local_worker,\n-                               std::vector<string>* remote_workers) {\n+                               const std::string& local_worker,\n+                               std::vector<std::string>* remote_workers) {\n   server->master_env()->worker_cache->ListWorkers(remote_workers);\n   remote_workers->erase(\n       std::remove(remote_workers->begin(), remote_workers->end(), local_worker),\n       remote_workers->end());\n   return absl::OkStatus();\n }\n \n-void DifferentiateWorkerLists(const std::vector<string>* current_list,\n-                              const std::vector<string>* new_list,\n-                              std::vector<string>* added,\n-                              std::vector<string>* removed,\n-                              std::vector<string>* existing) {\n+void DifferentiateWorkerLists(const std::vector<std::string>* current_list,\n+                              const std::vector<std::string>* new_list,\n+                              std::vector<std::string>* added,\n+                              std::vector<std::string>* removed,\n+                              std::vector<std::string>* existing) {\n   // Get STL set_difference and set_intersection with one list traversal.\n   // Similar to the set_difference library function, the input lists\n   // (`current_list` and `new_list`) must be sorted before calling the function.\n   added->resize(new_list->size());\n   removed->resize(current_list->size());\n   existing->resize(current_list->size());\n-  std::vector<string>::const_iterator curr_it = current_list->begin();\n-  std::vector<string>::const_iterator new_it = new_list->begin();\n-  std::vector<string>::iterator added_it = added->begin();\n-  std::vector<string>::iterator removed_it = removed->begin();\n-  std::vector<string>::iterator existing_it = existing->begin();\n+  std::vector<std::string>::const_iterator curr_it = current_list->begin();\n+  std::vector<std::string>::const_iterator new_it = new_list->begin();\n+  std::vector<std::string>::iterator added_it = added->begin();\n+  std::vector<std::string>::iterator removed_it = removed->begin();\n+  std::vector<std::string>::iterator existing_it = existing->begin();\n   while (curr_it != current_list->end() && new_it != new_list->end()) {\n     if (*curr_it < *new_it) {\n       *removed_it++ = *curr_it++;\n@@ -466,10 +466,10 @@ void DifferentiateWorkerLists(const std::vector<string>* current_list,\n }\n \n absl::Status GetReplacedFromExistingWorkers(\n-    const std::vector<string>* existing_workers, uint64 context_id,\n-    uint64 context_view_id, const ServerDef& server_def,\n+    const std::vector<std::string>* existing_workers, uint64_t context_id,\n+    uint64_t context_view_id, const ServerDef& server_def,\n     eager::EagerClientCache* client_cache,\n-    std::vector<string>* replaced_workers) {\n+    std::vector<std::string>* replaced_workers) {\n   BlockingCounter counter(existing_workers->size());\n   std::vector<absl::Status> statuses(existing_workers->size());\n   eager::KeepAliveRequest request;\n@@ -505,16 +505,16 @@ absl::Status GetReplacedFromExistingWorkers(\n }\n \n absl::Status CreateRemoteContexts(\n-    EagerContext* context, const std::vector<string>& remote_workers,\n-    uint64 context_id, uint64 context_view_id, int keep_alive_secs,\n+    EagerContext* context, const std::vector<std::string>& remote_workers,\n+    uint64_t context_id, uint64_t context_view_id, int keep_alive_secs,\n     const ServerDef& server_def, eager::EagerClientCache* remote_eager_workers,\n     bool async, const eager::CreateContextRequest& base_request,\n     int64_t init_timeout_in_ms, int retries, bool clear_existing_contexts) {\n   int num_remote_workers = remote_workers.size();\n   BlockingCounter counter(num_remote_workers);\n   std::vector<absl::Status> statuses(num_remote_workers);\n   for (int i = 0; i < num_remote_workers; i++) {\n-    const string& remote_worker = remote_workers[i];\n+    const std::string& remote_worker = remote_workers[i];\n     DeviceNameUtils::ParsedName parsed_name;\n     if (!DeviceNameUtils::ParseFullName(remote_worker, &parsed_name)) {\n       statuses[i] = errors::InvalidArgument(\"Unable to parse \", remote_worker,\n@@ -583,19 +583,19 @@ absl::Status CreateRemoteContexts(\n }\n \n absl::Status UpdateRemoteContexts(\n-    EagerContext* context, const std::vector<string>& remote_workers,\n-    const std::vector<string>& added_workers,\n-    const std::vector<string>& removed_workers, uint64 context_id,\n-    uint64 context_view_id, const ServerDef& server_def,\n+    EagerContext* context, const std::vector<std::string>& remote_workers,\n+    const std::vector<std::string>& added_workers,\n+    const std::vector<std::string>& removed_workers, uint64_t context_id,\n+    uint64_t context_view_id, const ServerDef& server_def,\n     eager::EagerClientCache* remote_eager_workers,\n     const eager::CreateContextRequest& base_request) {\n   int num_remote_workers = remote_workers.size();\n   BlockingCounter counter(num_remote_workers);\n   std::vector<absl::Status> statuses(num_remote_workers);\n \n   int cluster_device_count = base_request.cluster_device_attributes_size();\n-  std::unordered_set<string> added_or_removed(added_workers.begin(),\n-                                              added_workers.end());\n+  std::unordered_set<std::string> added_or_removed(added_workers.begin(),\n+                                                   added_workers.end());\n   std::copy(removed_workers.begin(), removed_workers.end(),\n             std::inserter(added_or_removed, added_or_removed.end()));\n   // Whether each device is in the updated (added or removed) workers\n@@ -604,15 +604,15 @@ absl::Status UpdateRemoteContexts(\n     const auto& da = base_request.cluster_device_attributes().at(i);\n     DeviceNameUtils::ParsedName pn;\n     DeviceNameUtils::ParseFullName(da.name(), &pn);\n-    string task_name;\n+    std::string task_name;\n     DeviceNameUtils::GetTaskName(pn, &task_name);\n     if (added_or_removed.find(task_name) != added_or_removed.end()) {\n       device_added_or_removed[i] = true;\n     }\n   }\n \n   for (int i = 0; i < num_remote_workers; i++) {\n-    const string& remote_worker = remote_workers[i];\n+    const std::string& remote_worker = remote_workers[i];\n     DeviceNameUtils::ParsedName parsed_name;\n     if (!DeviceNameUtils::ParseFullName(remote_worker, &parsed_name)) {\n       statuses[i] = errors::InvalidArgument(\"Unable to parse \", remote_worker,\n@@ -689,15 +689,15 @@ absl::Status UpdateContextWithServerDef(EagerContext* context,\n                                         bool reset_context, int keep_alive_secs,\n                                         int64_t init_timeout_in_ms, int retries,\n                                         bool clear_existing_contexts = false) {\n-  string worker_name =\n-      strings::StrCat(\"/job:\", server_def.job_name(),\n-                      \"/replica:0/task:\", server_def.task_index());\n+  std::string worker_name =\n+      absl::StrCat(\"/job:\", server_def.job_name(),\n+                   \"/replica:0/task:\", server_def.task_index());\n \n   // List of current remote workers before updating server_def. Unused if\n   // resetting the server_def.\n-  std::vector<string> curr_remote_workers;\n+  std::vector<std::string> curr_remote_workers;\n   // List of updated remote workers.\n-  std::vector<string> remote_workers;\n+  std::vector<std::string> remote_workers;\n \n   // New server created for new server_def. Unused if updating server_def.\n   std::unique_ptr<ServerInterface> new_server;\n@@ -722,10 +722,10 @@ absl::Status UpdateContextWithServerDef(EagerContext* context,\n         ListRemoteWorkers(server, worker_name, &remote_workers));\n   }\n \n-  uint64 context_id = context->GetContextId();\n+  uint64_t context_id = context->GetContextId();\n   // TODO(b/291142876) Check for invalid context id here (instead of in the C\n   // API).\n-  uint64 context_view_id = context->GetContextViewId();\n+  uint64_t context_view_id = context->GetContextViewId();\n   if (reset_context) {\n     context_id = EagerContext::NewContextId();\n     context_view_id = 0;\n@@ -757,10 +757,10 @@ absl::Status UpdateContextWithServerDef(EagerContext* context,\n   // * existing_workers: set(curr_remote_workers) intersect set(remote_workers)\n   // * replaced_workers: workers with the same task names and potentially the\n   //     same `hostname:port`s, but replaced by different processes\n-  std::vector<string> added_workers;\n-  std::vector<string> removed_workers;\n-  std::vector<string> existing_workers;\n-  std::vector<string> replaced_workers;\n+  std::vector<std::string> added_workers;\n+  std::vector<std::string> removed_workers;\n+  std::vector<std::string> existing_workers;\n+  std::vector<std::string> replaced_workers;\n \n   // New remote device manager created for new server_def. Unused if updating\n   // server_def.\n@@ -791,10 +791,11 @@ absl::Status UpdateContextWithServerDef(EagerContext* context,\n         remote_eager_workers.get(), &replaced_workers));\n     if (VLOG_IS_ON(1)) {\n       VLOG(1) << \"Updating cluster with following changes\";\n-      for (const string& w : added_workers) VLOG(1) << \"  Added worker \" << w;\n-      for (const string& w : removed_workers)\n+      for (const std::string& w : added_workers)\n+        VLOG(1) << \"  Added worker \" << w;\n+      for (const std::string& w : removed_workers)\n         VLOG(1) << \"  Removed worker \" << w;\n-      for (const string& w : replaced_workers)\n+      for (const std::string& w : replaced_workers)\n         VLOG(1) << \"  Replaced worker \" << w;\n     }\n     if (!replaced_workers.empty()) {\n@@ -804,7 +805,7 @@ absl::Status UpdateContextWithServerDef(EagerContext* context,\n                              replaced_workers.end());\n       added_workers.insert(added_workers.end(), replaced_workers.begin(),\n                            replaced_workers.end());\n-      for (const string& w : replaced_workers) {\n+      for (const std::string& w : replaced_workers) {\n         existing_workers.erase(\n             std::remove(existing_workers.begin(), existing_workers.end(), w),\n             existing_workers.end());\n@@ -868,7 +869,7 @@ absl::Status UpdateContextWithServerDef(EagerContext* context,\n     }\n     if (!existing_workers.empty()) {\n       if (VLOG_IS_ON(1)) {\n-        for (const string& w : existing_workers) {\n+        for (const std::string& w : existing_workers) {\n           VLOG(1) << \"Updating cluster with existing worker \" << w;\n         }\n       }\n@@ -883,7 +884,7 @@ absl::Status UpdateContextWithServerDef(EagerContext* context,\n     }\n   }\n \n-  auto session_name = strings::StrCat(\"eager_\", context_id);\n+  auto session_name = absl::StrCat(\"eager_\", context_id);\n   auto* session_mgr = server->worker_env()->session_mgr;\n   if (reset_context) {\n     tsl::core::RefCountPtr<RemoteRendezvous> r =\n@@ -937,15 +938,16 @@ absl::Status EagerContextDistributedManager::SetOrUpdateServerDef(\n     if (reset_context) {\n       const auto& cdf = server_def.cluster_device_filters();\n       for (const auto& jdf : cdf.jobs()) {\n-        const string remote_prefix = \"/job:\" + jdf.name() + \"/task:\";\n+        const std::string remote_prefix = \"/job:\" + jdf.name() + \"/task:\";\n         for (const auto& tdf : jdf.tasks()) {\n           const int32_t task_index = tdf.first;\n-          std::vector<string> device_filters(tdf.second.device_filters_size());\n+          std::vector<std::string> device_filters(\n+              tdf.second.device_filters_size());\n           for (int i = 0; i < tdf.second.device_filters_size(); i++) {\n             device_filters[i] = tdf.second.device_filters(i);\n           }\n-          const string remote_worker =\n-              strings::StrCat(remote_prefix, task_index);\n+          const std::string remote_worker =\n+              absl::StrCat(remote_prefix, task_index);\n           TF_RETURN_IF_ERROR(\n               context_->SetRemoteDeviceFilters(remote_worker, device_filters));\n         }\n@@ -973,9 +975,9 @@ absl::Status EagerContextDistributedManager::SetOrUpdateServerDef(\n \n absl::Status EagerContextDistributedManager::InitializeLocalOnlyContext(\n     const ServerDef& server_def, int keep_alive_secs) {\n-  string worker_name =\n-      strings::StrCat(\"/job:\", server_def.job_name(),\n-                      \"/replica:0/task:\", server_def.task_index());\n+  std::string worker_name =\n+      absl::StrCat(\"/job:\", server_def.job_name(),\n+                   \"/replica:0/task:\", server_def.task_index());\n   // New server created for new server_def. Unused if updating server_def.\n   std::unique_ptr<ServerInterface> new_server;\n   ServerInterface* server;\n@@ -985,7 +987,7 @@ absl::Status EagerContextDistributedManager::InitializeLocalOnlyContext(\n   LOG_AND_RETURN_IF_ERROR(\n       NewServerWithOptions(server_def, {device_mgr}, &new_server));\n   server = new_server.get();\n-  uint64 context_id = EagerContext::NewContextId();\n+  uint64_t context_id = EagerContext::NewContextId();\n   // Make master eager context accessible by local eager service, which might\n   // receive send tensor requests from remote workers.\n   LOG_AND_RETURN_IF_ERROR(\n@@ -995,7 +997,7 @@ absl::Status EagerContextDistributedManager::InitializeLocalOnlyContext(\n   server->worker_env()->device_mgr->ListDeviceAttributes(\n       &local_device_attributes);\n \n-  auto session_name = strings::StrCat(\"eager_\", context_id);\n+  auto session_name = absl::StrCat(\"eager_\", context_id);\n   auto* session_mgr = server->worker_env()->session_mgr;\n   tsl::core::RefCountPtr<RemoteRendezvous> r =\n       server->worker_env()->rendezvous_mgr->Find(context_id);\n@@ -1054,7 +1056,7 @@ absl::Status EagerContextDistributedManager::EnableCollectiveOps(\n     const bool enable_coordination =\n         !config.experimental().coordination_config().service_type().empty();\n     if (enable_coordination) {\n-      auto session_name = strings::StrCat(\"eager_\", context_->GetContextId());\n+      auto session_name = absl::StrCat(\"eager_\", context_->GetContextId());\n       std::shared_ptr<WorkerSession> worker_session;\n       auto* session_mgr = server->worker_env()->session_mgr;\n       // Start coordination service within session if this is the leader."
        },
        {
            "sha": "590abf83871f67d4a6cb78b8ee1d5613b15a2f58",
            "filename": "tensorflow/core/common_runtime/eager/context_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcontext_test.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -50,7 +50,7 @@ using ::testing::HasSubstr;\n typedef FunctionDefHelper FDH;\n \n // Return a fake device.\n-static Device* CreateDevice(const string& type, int n) {\n+static Device* CreateDevice(const std::string& type, int n) {\n   class FakeDevice : public Device {\n    public:\n     explicit FakeDevice(const DeviceAttributes& attr) : Device(nullptr, attr) {}\n@@ -99,7 +99,7 @@ class EagerContextTest : public ::testing::Test {\n \n TEST_F(EagerContextTest, CompositeDevice) {\n   InitContext(SessionOptions(), DEVICE_PLACEMENT_EXPLICIT);\n-  std::vector<string> underlying_devices = {\n+  std::vector<std::string> underlying_devices = {\n       \"/job:worker/replica:0/task:0/device:CPU:0\",\n       \"/job:worker/replica:0/task:0/device:CPU:1\"};\n   CompositeDevice* composite_device_0 = nullptr;\n@@ -134,10 +134,10 @@ TEST_F(EagerContextTest, CompositeDevice) {\n \n TEST_F(EagerContextTest, CompositeDeviceWithGivenName) {\n   InitContext(SessionOptions(), DEVICE_PLACEMENT_EXPLICIT);\n-  const std::vector<string> underlying_devices_0 = {\n+  const std::vector<std::string> underlying_devices_0 = {\n       \"/job:worker/replica:0/task:0/device:CPU:0\",\n       \"/job:worker/replica:0/task:0/device:CPU:1\"};\n-  const string composite_device_name =\n+  const std::string composite_device_name =\n       \"/job:worker1/replica:0/task:0/device:COMPOSITE:5\";\n   // Create a CompositeDevice with the given name.\n   CompositeDevice* composite_device_0 = nullptr;\n@@ -150,7 +150,7 @@ TEST_F(EagerContextTest, CompositeDeviceWithGivenName) {\n       context()->FindCompositeDeviceFromName(composite_device_name, &device));\n   EXPECT_EQ(device, composite_device_0);\n \n-  std::vector<string> underlying_devices_1 = {\n+  std::vector<std::string> underlying_devices_1 = {\n       \"/job:worker/replica:0/task:0/device:CPU:1\",\n       \"/job:worker/replica:0/task:0/device:CPU:2\"};\n   // Find a CompositeDevice with the given name."
        },
        {
            "sha": "d12f4965e1fded7127137a82b0f9f8e8499e3d54",
            "filename": "tensorflow/core/common_runtime/eager/copy_to_device_node.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcopy_to_device_node.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcopy_to_device_node.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcopy_to_device_node.h?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -71,8 +71,8 @@ class CopyToDeviceNode : public EagerNode {\n \n   void Abort(absl::Status status) override { dst_->Poison(status, dstd_); }\n \n-  string DebugString() const override {\n-    string out = \"[CopyToDeviceNode]\";\n+  std::string DebugString() const override {\n+    std::string out = \"[CopyToDeviceNode]\";\n     absl::StrAppend(&out, \" src_tensor: \", src_->DebugString());\n     absl::StrAppend(&out, \", dst_tensor: \", dst_->DebugString());\n     absl::StrAppend(&out, \", dst_device: \", dstd_ ? dstd_->name() : \"[]\");"
        },
        {
            "sha": "f72f76b0f5a7caff72c808ef262f4cfe806504e5",
            "filename": "tensorflow/core/common_runtime/eager/custom_device.h",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcustom_device.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcustom_device.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcustom_device.h?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -37,13 +37,14 @@ class CustomDeviceTensorHandle;\n class CustomDevice {\n  public:\n   virtual ~CustomDevice() = default;\n-  virtual const string& name() = 0;\n+  virtual const std::string& name() = 0;\n   virtual absl::Status CopyTensorToDevice(\n       ImmediateExecutionTensorHandle* tensor,\n       ImmediateExecutionTensorHandle** result) = 0;\n \n   virtual absl::Status CopyTensorFromDevice(\n-      ImmediateExecutionTensorHandle* tensor, const string& target_device_name,\n+      ImmediateExecutionTensorHandle* tensor,\n+      const std::string& target_device_name,\n       ImmediateExecutionTensorHandle** result) = 0;\n \n   virtual absl::Status Execute(const ImmediateExecutionOperation* op,"
        },
        {
            "sha": "2a736e67bae7897f6b529772ef18538ec5bf5745",
            "filename": "tensorflow/core/common_runtime/eager/custom_device_op_handler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcustom_device_op_handler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcustom_device_op_handler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcustom_device_op_handler.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -26,7 +26,7 @@ namespace tensorflow {\n void CustomDeviceOpHandler::Clear() { custom_devices_.clear(); }\n \n absl::Status CustomDeviceOpHandler::RegisterCustomDevice(\n-    const string& device_name, std::unique_ptr<CustomDevice> device) {\n+    const std::string& device_name, std::unique_ptr<CustomDevice> device) {\n   DeviceNameUtils::ParsedName parsed;\n   if (!DeviceNameUtils::ParseFullName(device_name, &parsed) ||\n       !parsed.has_job || !parsed.has_replica || !parsed.has_task ||\n@@ -46,7 +46,7 @@ absl::Status CustomDeviceOpHandler::RegisterCustomDevice(\n }\n \n bool CustomDeviceOpHandler::FindCustomDeviceFromName(\n-    const string& name, CustomDevice** device) const {\n+    const std::string& name, CustomDevice** device) const {\n   auto dev_it = custom_devices_.find(name);\n   if (dev_it == custom_devices_.end()) {\n     return false;"
        },
        {
            "sha": "66d186014b21764c5290821c07cce6a0c5073b7c",
            "filename": "tensorflow/core/common_runtime/eager/custom_device_op_handler.h",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcustom_device_op_handler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcustom_device_op_handler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fcustom_device_op_handler.h?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -29,11 +29,11 @@ class CustomDeviceOpHandler {\n  public:\n   ~CustomDeviceOpHandler() = default;\n   // Register a new custom device.\n-  absl::Status RegisterCustomDevice(const string& device_name,\n+  absl::Status RegisterCustomDevice(const std::string& device_name,\n                                     std::unique_ptr<CustomDevice> device);\n \n   // Find the custom device from given name. Return true if it finds one.\n-  bool FindCustomDeviceFromName(const string& name,\n+  bool FindCustomDeviceFromName(const std::string& name,\n                                 CustomDevice** device) const;\n \n   absl::Status Execute(ImmediateExecutionOperation* op,\n@@ -53,7 +53,8 @@ class CustomDeviceOpHandler {\n   void Clear();\n \n  private:\n-  std::unordered_map<string, std::unique_ptr<CustomDevice>> custom_devices_;\n+  std::unordered_map<std::string, std::unique_ptr<CustomDevice>>\n+      custom_devices_;\n };\n }  // namespace tensorflow\n "
        },
        {
            "sha": "02f8eae99fb80a2295e4ca46fae2edf34eb3095f",
            "filename": "tensorflow/core/common_runtime/eager/eager_executor.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_executor.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -117,7 +117,7 @@ absl::Status EagerExecutor::SyncExecute(EagerNode* node) {\n   }\n   // NOTE: SyncExecute runs every node regardless of error status in executor.\n \n-  uint64 id = next_node_id_++;\n+  uint64_t id = next_node_id_++;\n \n   absl::Status s = node->Prepare();\n   if (!s.ok()) {\n@@ -312,9 +312,9 @@ void EagerExecutor::NodeDone(const core::RefCountPtr<NodeItem>& item,\n   // a deadlock.\n }\n \n-void EagerExecutor::NotifyWaiters(uint64 id) {\n+void EagerExecutor::NotifyWaiters(uint64_t id) {\n   if (!node_done_notifications_.empty()) {\n-    uint64 upperbound_id = 0;\n+    uint64_t upperbound_id = 0;\n     if (!unfinished_nodes_.empty()) {\n       upperbound_id = unfinished_nodes_.begin()->first - 1;\n     } else if (!node_queue_.empty()) {"
        },
        {
            "sha": "ff8ce9cbc7322c65f872f927ff6d36f2afba3742",
            "filename": "tensorflow/core/common_runtime/eager/eager_executor.h",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_executor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_executor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_executor.h?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -76,7 +76,7 @@ class EagerNode {\n   virtual AsyncEagerNode* AsAsync() { return nullptr; }\n   virtual AsyncRemoteExecuteNode* AsAsyncRemoteExecuteNode() { return nullptr; }\n \n-  virtual string DebugString() const = 0;\n+  virtual std::string DebugString() const = 0;\n \n   // Indicates whether a node failure should make the executor unusable.\n   virtual bool Fatal() const { return true; }\n@@ -193,7 +193,7 @@ class EagerExecutor {\n   struct NodeItem : core::RefCounted {\n     // Unique id generated in EagerExecutor::Add(). If item1.id < item2.id, it\n     // means item1.node is added before item2.node.\n-    uint64 id;\n+    uint64_t id;\n     std::unique_ptr<EagerNode> node;\n     NodeState state;\n   };\n@@ -203,7 +203,8 @@ class EagerExecutor {\n \n   void NodeDone(const core::RefCountPtr<NodeItem>& item,\n                 const absl::Status& status, bool from_queue);\n-  void NotifyWaiters(uint64 id) TF_EXCLUSIVE_LOCKS_REQUIRED(node_queue_mutex_);\n+  void NotifyWaiters(uint64_t id)\n+      TF_EXCLUSIVE_LOCKS_REQUIRED(node_queue_mutex_);\n \n   // Starts execution of pending EagerNodes. This function loops till executor\n   // state_ is set to kShutDown. If any errors are encountered, these are set\n@@ -220,9 +221,9 @@ class EagerExecutor {\n   absl::Status WaitForAllPendingNodesLocked(mutex_lock* lock)\n       TF_EXCLUSIVE_LOCKS_REQUIRED(node_queue_mutex_);\n \n-  absl::Status WaitImpl(bool wait_all, uint64 node_id);\n+  absl::Status WaitImpl(bool wait_all, uint64_t node_id);\n \n-  std::atomic<uint64> next_node_id_;\n+  std::atomic<uint64_t> next_node_id_;\n \n   mutable mutex node_queue_mutex_;\n \n@@ -236,7 +237,7 @@ class EagerExecutor {\n       TF_GUARDED_BY(node_queue_mutex_);\n \n   // Ordered by NodeItem::id.\n-  std::map<uint64, core::RefCountPtr<NodeItem>, std::less<uint64>>\n+  std::map<uint64_t, core::RefCountPtr<NodeItem>, std::less<uint64_t>>\n       unfinished_nodes_ TF_GUARDED_BY(node_queue_mutex_);\n \n   // `status_` is set based on any errors raised during execution of a\n@@ -248,7 +249,7 @@ class EagerExecutor {\n   // These condition_variables are notified and removed when that EagerNode is\n   // done executing, or if an error is found in execution of any EagerNode.\n   // The map is ordered by id.\n-  std::multimap<uint64, condition_variable*, std::less<uint64>>\n+  std::multimap<uint64_t, condition_variable*, std::less<uint64_t>>\n       node_done_notifications_ TF_GUARDED_BY(node_queue_mutex_);\n \n   // thread_exited_notification_ is notified by the `thread_` right before it"
        },
        {
            "sha": "acaba8320ed871051e7d55f9169a0daa3f0fc613",
            "filename": "tensorflow/core/common_runtime/eager/eager_executor_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_executor_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_executor_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_executor_test.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -63,7 +63,7 @@ class TestEagerNode : public EagerNode {\n   };\n \n   void Abort(absl::Status status) override {}\n-  string DebugString() const override { return \"testEagerNode\"; }\n+  std::string DebugString() const override { return \"testEagerNode\"; }\n \n  private:\n   TestState* state_;\n@@ -94,7 +94,7 @@ class TestAsyncEagerNode : public AsyncEagerNode {\n   };\n \n   void Abort(absl::Status status) override {}\n-  string DebugString() const override { return \"testAsyncEagerNode\"; }\n+  std::string DebugString() const override { return \"testAsyncEagerNode\"; }\n \n  private:\n   TestState* state_;"
        },
        {
            "sha": "221d30d98518f6edada2b56e1b29f698633468a5",
            "filename": "tensorflow/core/common_runtime/eager/eager_op_rewrite_registry.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_op_rewrite_registry.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_op_rewrite_registry.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_op_rewrite_registry.h?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -28,7 +28,7 @@ namespace tensorflow {\n // implement the Run method.\n class EagerOpRewrite {\n  public:\n-  EagerOpRewrite(string name, string file, string line) {\n+  EagerOpRewrite(std::string name, std::string file, std::string line) {\n     debug_info_.name = name;\n     debug_info_.file = file;\n     debug_info_.line = line;\n@@ -43,7 +43,7 @@ class EagerOpRewrite {\n \n   // Holds information about the rewrite registration.\n   struct DebugInfo {\n-    string name, file, line;\n+    std::string name, file, line;\n   };\n \n   // Returns information about the registered Eager op rewrite.\n@@ -75,7 +75,7 @@ class EagerOpRewriteRegistry {\n  private:\n   static constexpr int32_t kNumPhases = 2;\n   // Holds all the registered Eager op rewrites and their ordinal numbers.\n-  std::array<std::list<std::pair<std::unique_ptr<EagerOpRewrite>, int32>>,\n+  std::array<std::list<std::pair<std::unique_ptr<EagerOpRewrite>, int32_t>>,\n              kNumPhases>\n       rewrites_;\n };"
        },
        {
            "sha": "e76627a3680daf6c63eeef017688112729bebd66",
            "filename": "tensorflow/core/common_runtime/eager/eager_op_rewrite_registry_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_op_rewrite_registry_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_op_rewrite_registry_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_op_rewrite_registry_test.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -23,7 +23,7 @@ namespace tensorflow {\n \n class TestEagerOpRewrite : public EagerOpRewrite {\n  public:\n-  TestEagerOpRewrite(string name, string file, string line)\n+  TestEagerOpRewrite(std::string name, std::string file, std::string line)\n       : EagerOpRewrite(name, file, line),\n         executor_(/*async=*/false, /*enable_streaming_enqueue=*/true) {}\n   static int count_;"
        },
        {
            "sha": "d730df6b608b069d91a06d7d66a78a45f11c56a0",
            "filename": "tensorflow/core/common_runtime/eager/eager_operation.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_operation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_operation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_operation.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -473,7 +473,7 @@ absl::Status EagerOperation::MutableTensorHandleInputs(\n }\n \n absl::Status EagerOperation::SetDeviceName(const char* c_name) {\n-  string name(c_name != nullptr ? c_name : \"\");\n+  std::string name(c_name != nullptr ? c_name : \"\");\n   if (name != last_set_device_name_) {\n     if (!DeviceNameUtils::ParseFullName(name, &device_parsed_name_)) {\n       return errors::InvalidArgument(\"Malformed device specification '\", name,\n@@ -498,7 +498,7 @@ bool EagerOperation::IsLocal() const {\n          device_parsed_name_.task == host_cpu_name.task;\n }\n \n-string VariantDeviceDebugString(VariantDevice device) {\n+std::string VariantDeviceDebugString(VariantDevice device) {\n   if (device == kVariantDeviceNull) {\n     return \"[]\";\n   } else if (std::holds_alternative<CustomDevice*>(device)) {\n@@ -513,8 +513,8 @@ void EagerOperation::AddAttrs(const AbstractOpAttrs* op_attrs) {\n   attrs_.CopyAttributes(*(down_cast<const AttrBuilder*>(op_attrs)));\n }\n \n-string EagerOperation::DebugString() const {\n-  string out;\n+std::string EagerOperation::DebugString() const {\n+  std::string out;\n   VLOG(1) << \"EagerOperation::DebugString() over \" << this;\n \n   absl::StrAppend(&out, \"Name: \", Name(), \"\\n\");"
        },
        {
            "sha": "b51e098413685da4c7f757c4cbfcee1e02153e94",
            "filename": "tensorflow/core/common_runtime/eager/eager_operation.h",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_operation.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_operation.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_operation.h?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -57,9 +57,9 @@ class EagerOperation : public ImmediateExecutionOperation {\n     return Reset(op, raw_device_name, false, nullptr);\n   }\n \n-  const string& Name() const override { return attrs_.op_name(); }\n+  const std::string& Name() const override { return attrs_.op_name(); }\n \n-  const string& DeviceName() const override { return device_name_; }\n+  const std::string& DeviceName() const override { return device_name_; }\n \n   ImmediateExecutionContext* GetContext() const override { return &ctx_; }\n \n@@ -196,7 +196,7 @@ class EagerOperation : public ImmediateExecutionOperation {\n \n   // This is useful if we want the EagerOperation to point to a different\n   // function.\n-  void UpdateName(const string& name) {\n+  void UpdateName(const std::string& name) {\n     attrs_.set_op_name(name);\n     op_name_ = attrs_.op_name();\n   }\n@@ -242,7 +242,7 @@ class EagerOperation : public ImmediateExecutionOperation {\n \n   EagerExecutor& Executor() { return *executor_; }\n \n-  string DebugString() const;\n+  std::string DebugString() const;\n \n   const absl::optional<EagerFunctionParams>& eager_func_params() const {\n     return eager_func_params_;\n@@ -289,12 +289,12 @@ class EagerOperation : public ImmediateExecutionOperation {\n   // The last device name given to SetDeviceName.\n   // This is used to avoid having to re-process the same device in repeated\n   // calls to SetDeviceName.\n-  string last_set_device_name_;\n+  std::string last_set_device_name_;\n \n   // The operation's device name.\n   // This contains the named passed to SetDeviceName until device_ is set,\n   // at which point it contains the device_ name.\n-  string device_name_;\n+  std::string device_name_;\n \n   // The parsed device name.\n   // This will always contain the result of"
        },
        {
            "sha": "2ff6952eb0d17e6ca46070204a86cc4ec40dfb38",
            "filename": "tensorflow/core/common_runtime/eager/eager_operation_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_operation_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_operation_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Feager_operation_test.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -68,7 +68,7 @@ TEST(EagerOperationTest, EagerFunctionParamsAndStepId) {\n   auto op = new EagerOperation(ctx);\n   EXPECT_FALSE(op->eager_func_params().has_value());\n \n-  string device_name = \"/job:localhost/replica:0/task:0/device:CPU:0\";\n+  std::string device_name = \"/job:localhost/replica:0/task:0/device:CPU:0\";\n   TF_ASSERT_OK(op->SetDeviceName(device_name.c_str()));\n   TF_ASSERT_OK(op->Reset(\"DummyFunction\", device_name.c_str()));\n "
        },
        {
            "sha": "547336cdeb6d7607ac5865ee2f97040b1656d9cd",
            "filename": "tensorflow/core/common_runtime/eager/execute.cc",
            "status": "modified",
            "additions": 50,
            "deletions": 43,
            "changes": 93,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fexecute.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fexecute.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fexecute.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -132,8 +132,8 @@ bool SendAsProtosWhenPossible() {\n   return send_as_protos_when_possible;\n }\n \n-const string& DeviceNameOrUnspecified(Device* device) {\n-  static string* unspecified_string = new string(\"<unspecified>\");\n+const std::string& DeviceNameOrUnspecified(Device* device) {\n+  static std::string* unspecified_string = new std::string(\"<unspecified>\");\n   return (device == nullptr) ? *unspecified_string : device->name();\n }\n \n@@ -158,7 +158,7 @@ absl::Status CopyInputToExpectedDevice(EagerContext* ctx, EagerOperation* op,\n   // Should only be called when these don't match\n   DCHECK(expected_input_device != handle_device);\n   *result = nullptr;\n-  const string& op_device_name = DeviceNameOrUnspecified(op_device);\n+  const std::string& op_device_name = DeviceNameOrUnspecified(op_device);\n \n   switch (ctx->GetDevicePlacementPolicy()) {\n     case DEVICE_PLACEMENT_SILENT_FOR_INT32:\n@@ -314,7 +314,7 @@ absl::Status GetDeviceForInput(const EagerOperation& op,\n                                const bool is_host_memory_arg,\n                                TensorHandle* tensor_handle, Device** result) {\n   Device* cpu_device = ctx.HostCPU();\n-  string device_name;\n+  std::string device_name;\n   if (tensor_handle->Type() != TensorHandle::LOCAL) {\n     Device* device = tensor_handle->device();\n     device_name = device != nullptr ? device->name() : cpu_device->name();\n@@ -473,7 +473,7 @@ absl::Status MustCompileWithXLA(const EagerOperation* op,\n // `has_jit_compile` and `device`.\n absl::Status HasNestedJitCompile(const EagerOperation& op,\n                                  const EagerContext& ctx, bool* has_jit_compile,\n-                                 string* device) {\n+                                 std::string* device) {\n   *has_jit_compile = false;\n \n   const std::string kStatefulPartitionedCallOp = \"StatefulPartitionedCall\";\n@@ -488,7 +488,7 @@ absl::Status HasNestedJitCompile(const EagerOperation& op,\n   const FunctionLibraryDefinition* func_lib_def = op.FuncLibDef();\n \n   while (!function_names.empty()) {\n-    const string& function_name = function_names.front();\n+    const std::string& function_name = function_names.front();\n \n     const FunctionDef* function_def = func_lib_def->Find(function_name);\n     if (function_def == nullptr) {\n@@ -518,8 +518,8 @@ absl::Status HasNestedJitCompile(const EagerOperation& op,\n   return absl::OkStatus();\n }\n \n-string CanonicalizeDeviceType(std::string_view device_type) {\n-  string canonical_device_type = \"Unknown\";\n+std::string CanonicalizeDeviceType(std::string_view device_type) {\n+  std::string canonical_device_type = \"Unknown\";\n   if (device_type == \"XLA_CPU\" || device_type == tensorflow::DEVICE_CPU) {\n     canonical_device_type = tensorflow::DEVICE_CPU;\n   }\n@@ -542,11 +542,12 @@ absl::Status UpdateCompileCounter(const EagerOperation* op,\n     return absl::OkStatus();\n   }\n \n-  string device_type = CanonicalizeDeviceType(op->GetDeviceParsedName().type);\n-  string compilation_option = kDisabled;\n+  std::string device_type =\n+      CanonicalizeDeviceType(op->GetDeviceParsedName().type);\n+  std::string compilation_option = kDisabled;\n   if (!compile_with_xla) {\n     bool nested_jit_compile = false;\n-    string device;\n+    std::string device;\n     if (!ctx.FuncLibDef()->HasOptimizedFunctionGraph(op->Name())) {\n       TF_RETURN_IF_ERROR(\n           HasNestedJitCompile(*op, ctx, &nested_jit_compile, &device));\n@@ -586,14 +587,14 @@ absl::Status UpdateCompileCounter(const EagerOperation* op,\n \n using ProtoArgListType = protobuf::RepeatedPtrField<OpDef_ArgDef>;\n \n-string EscapeOrigName(const string& orig_name) {\n+std::string EscapeOrigName(const std::string& orig_name) {\n   // Replace _ with __ in the original name to avoid name conflicts.\n   return absl::StrReplaceAll(orig_name, {{\"_\", \"__\"}});\n }\n \n // Variadic args are flattened during wrapping. This utility returns the name\n // of a flattened arg/attr.\n-string GetFlatName(const string orig_name, int index) {\n+std::string GetFlatName(const std::string orig_name, int index) {\n   return absl::StrCat(EscapeOrigName(orig_name), \"_\", index);\n }\n \n@@ -607,13 +608,14 @@ string GetFlatName(const string orig_name, int index) {\n // IdentityN[T:[DT_FLOAT, DT_INT64]] -> __wrapped__IdentityN_T_2\n // Concat[N:2, T:DT_FLOAT] -> __wrapped__Concat_N_2\n absl::Status BuildWrappedOpName(EagerOperation* op, const OpDef& opdef,\n-                                const AbstractOpAttrs* op_attrs, string* name) {\n-  string fname = absl::StrCat(\"__wrapped__\", EscapeOrigName(op->Name()));\n+                                const AbstractOpAttrs* op_attrs,\n+                                std::string* name) {\n+  std::string fname = absl::StrCat(\"__wrapped__\", EscapeOrigName(op->Name()));\n   // For every variadic arg in `args`, populates `attr_to_len` with\n   // (attr_name, len(arg)).\n   auto FillAttrToLen = [op_attrs, op](\n                            const ProtoArgListType& args,\n-                           absl::btree_map<string, int>* attr_to_len) {\n+                           absl::btree_map<std::string, int>* attr_to_len) {\n     for (const auto& arg : args) {\n       if (!arg.type_list_attr().empty()) {\n         absl::InlinedVector<DataType, 4UL> type_list;\n@@ -631,7 +633,7 @@ absl::Status BuildWrappedOpName(EagerOperation* op, const OpDef& opdef,\n     }\n     return absl::OkStatus();\n   };\n-  absl::btree_map<string, int> attr_to_len;\n+  absl::btree_map<std::string, int> attr_to_len;\n   TF_RETURN_IF_ERROR(FillAttrToLen(opdef.input_arg(), &attr_to_len));\n   TF_RETURN_IF_ERROR(FillAttrToLen(opdef.output_arg(), &attr_to_len));\n   for (auto& name_len : attr_to_len) {\n@@ -768,7 +770,8 @@ absl::Status BuildWrappedOpName(EagerOperation* op, const OpDef& opdef,\n // Note that the N attr is preserved so that it can get copied to the\n // inner op via a placeholder. This allows additional verification.\n absl::Status BuildWrappedOpSignature(EagerOperation* op, const OpDef& opdef,\n-                                     const string& fname, OpDef& signature) {\n+                                     const std::string& fname,\n+                                     OpDef& signature) {\n   signature = opdef;\n   signature.clear_input_arg();\n   signature.clear_output_arg();\n@@ -777,7 +780,7 @@ absl::Status BuildWrappedOpSignature(EagerOperation* op, const OpDef& opdef,\n   auto FillSignatureArgs = [op_attrs, op](\n                                const ProtoArgListType& opdef_args,\n                                ProtoArgListType* sig_args,\n-                               absl::flat_hash_set<string>& new_attrs) {\n+                               absl::flat_hash_set<std::string>& new_attrs) {\n     for (const auto& arg : opdef_args) {\n       if (!arg.type_list_attr().empty()) {\n         absl::InlinedVector<DataType, 4UL> type_list;\n@@ -817,7 +820,7 @@ absl::Status BuildWrappedOpSignature(EagerOperation* op, const OpDef& opdef,\n     }\n     return absl::OkStatus();\n   };\n-  absl::flat_hash_set<string> new_attrs;\n+  absl::flat_hash_set<std::string> new_attrs;\n   TF_RETURN_IF_ERROR(FillSignatureArgs(\n       opdef.input_arg(), signature.mutable_input_arg(), new_attrs));\n   TF_RETURN_IF_ERROR(FillSignatureArgs(\n@@ -838,7 +841,7 @@ absl::Status AddMixedTypeListAttrs(EagerOperation* wrapped_op,\n                                    const OpDef& opdef) {\n   auto FillAttrsToAdd =\n       [op_attrs](const ProtoArgListType& opdef_args,\n-                 absl::flat_hash_map<string, DataType>* attrs_to_add) {\n+                 absl::flat_hash_map<std::string, DataType>* attrs_to_add) {\n         for (const auto& arg : opdef_args) {\n           if (!arg.type_list_attr().empty()) {\n             absl::InlinedVector<DataType, 4UL> type_list;\n@@ -852,7 +855,7 @@ absl::Status AddMixedTypeListAttrs(EagerOperation* wrapped_op,\n         }\n         return absl::OkStatus();\n       };\n-  absl::flat_hash_map<string, DataType> attrs_to_add;\n+  absl::flat_hash_map<std::string, DataType> attrs_to_add;\n   TF_RETURN_IF_ERROR(FillAttrsToAdd(opdef.input_arg(), &attrs_to_add));\n   TF_RETURN_IF_ERROR(FillAttrsToAdd(opdef.output_arg(), &attrs_to_add));\n   for (auto& name_type : attrs_to_add) {\n@@ -867,7 +870,8 @@ absl::Status AddMixedTypeListAttrs(EagerOperation* wrapped_op,\n // outputs which need to be flattened.\n absl::Status PopulateRetMap(FunctionDef* fdef, const AbstractOpAttrs* op_attrs,\n                             const EagerOperation* op, const OpDef& opdef,\n-                            const OpDef& signature, const string& node_name) {\n+                            const OpDef& signature,\n+                            const std::string& node_name) {\n   int next_sig_output = 0;\n   for (size_t i = 0; i < opdef.output_arg_size(); i++) {\n     const auto& output_arg = opdef.output_arg(i);\n@@ -916,7 +920,7 @@ absl::Status WrapInCallOp(EagerOperation* op, EagerOperation** wrapped_op) {\n   // TODO(srbs): Support list inputs/outputs.\n   auto verify_wrappable_in_call_op = [](const OpDef& opdef,\n                                         EagerOperation* op) -> absl::Status {\n-    absl::flat_hash_set<string> opdef_attrs;\n+    absl::flat_hash_set<std::string> opdef_attrs;\n     for (const auto& attr : opdef.attr()) {\n       opdef_attrs.insert(attr.name());\n     }\n@@ -941,7 +945,7 @@ absl::Status WrapInCallOp(EagerOperation* op, EagerOperation** wrapped_op) {\n   // This can be avoided by introducing a dict in EagerContext that stores a\n   // mapping from the eager op's name to its unique FunctionDef name.\n   auto op_attrs = op->GetOpAttrs();\n-  string fname;\n+  std::string fname;\n   TF_RETURN_IF_ERROR(BuildWrappedOpName(op, opdef, op_attrs, &fname));\n   if (!op->EagerContext().GetFunctionDef(fname)) {\n     FunctionDef fdef;\n@@ -1168,7 +1172,8 @@ absl::StatusOr<Fprint128> GetKernelCacheKey(\n absl::Status ExtractFunctionInputInfo(\n     EagerOperation* op, const KernelDef* kernel_def,\n     std::vector<Device*>& input_device_ptrs,\n-    absl::flat_hash_map<string, const std::vector<string>*>& composite_devices,\n+    absl::flat_hash_map<std::string, const std::vector<std::string>*>&\n+        composite_devices,\n     std::unordered_map<int, DtypeAndPartialTensorShape>&\n         input_resource_variable_dtypes_and_shapes) {\n   tsl::profiler::TraceMe activity(\"EagerCopyToDevice\",\n@@ -1268,7 +1273,7 @@ absl::Status GetOrCreateKernelAndDevice(\n   if (is_small_constant_optimization_enabled(*op)) {\n     TF_ASSIGN_OR_RETURN(BoolTensorInputs bool_inputs,\n                         GetBoolInputs(op, /*delete_inputs=*/false));\n-    string folded_name = op->Name();\n+    std::string folded_name = op->Name();\n     for (const auto& [input_name, input_value] : bool_inputs) {\n       folded_name = small_constants_optimizer::FoldedFunctionName(\n           folded_name, input_name, input_value);\n@@ -1320,7 +1325,8 @@ absl::Status GetOrCreateKernelAndDevice(\n       (ctx.RunEagerOpAsFunction() && !op->is_function());\n \n   std::vector<Device*> input_device_ptrs;\n-  absl::flat_hash_map<string, const std::vector<string>*> composite_devices;\n+  absl::flat_hash_map<std::string, const std::vector<std::string>*>\n+      composite_devices;\n   std::unordered_map<int, DtypeAndPartialTensorShape>\n       input_resource_variable_dtypes_and_shapes;\n   const KernelDef* kernel_def = nullptr;\n@@ -1380,7 +1386,7 @@ absl::Status GetOrCreateKernelAndDevice(\n     bool run_function_with_flr = false;\n     bool function_runs_at_most_once = FunctionRunsAtMostOnce(op, ctx);\n \n-    std::optional<string> xla_compile_device_type;\n+    std::optional<std::string> xla_compile_device_type;\n     if (op->is_function()) {\n       bool compile_with_xla;\n       // By default we should run functions with FunctionLibraryRuntime.\n@@ -1474,7 +1480,8 @@ absl::Status GetOrCreateKernelAndDevice(\n         // Check if any of the Op's output_arg(s) are pinned to Host.\n         if (kernel_def == nullptr) return false;\n         const OpDef& op_def = OpRegistry::Global()->LookUp(op->Name())->op_def;\n-        for (const string& host_memory_arg : kernel_def->host_memory_arg()) {\n+        for (const std::string& host_memory_arg :\n+             kernel_def->host_memory_arg()) {\n           for (const auto& output_arg : op_def.output_arg()) {\n             if (output_arg.name() == host_memory_arg) {\n               return false;\n@@ -1613,7 +1620,7 @@ absl::Status CreateUnshapedOutput(\n     return errors::InvalidArgument(\n         \"Unable to find a remote op id for a remote output of \", kernel.name());\n   }\n-  string remote_task;\n+  std::string remote_task;\n   if (!DeviceNameUtils::GetTaskName(output_device->parsed_name(),\n                                     &remote_task)) {\n     return errors::InvalidArgument(\n@@ -1762,8 +1769,8 @@ absl::Status EagerLocalExecute(EagerOperation* op, TensorHandle** retvals,\n   TF_RETURN_IF_ERROR(ValidateInputTypeAndPlacement(&ctx, op, kernel));\n \n   if (ctx.LogDevicePlacement() || VLOG_IS_ON(1)) {\n-    string msg = absl::StrCat(\"Executing op \", op->Name(), \" in device \",\n-                              kernel->device()->name());\n+    std::string msg = absl::StrCat(\"Executing op \", op->Name(), \" in device \",\n+                                   kernel->device()->name());\n     if (!logging::LogToListeners(msg)) {\n       LOG(INFO) << msg;\n     }\n@@ -1828,15 +1835,15 @@ absl::Status EagerRemoteExecute(EagerOperation* op, TensorHandle** retvals,\n   // TODO(fishx): Remove following code when lazy tensor copy is ready.\n   if (op->Device() == kVariantDeviceNull) {\n     tensorflow::Device* device = nullptr;\n-    string device_name = op->DeviceName();\n+    std::string device_name = op->DeviceName();\n     TF_RETURN_IF_ERROR(ctx.FindDeviceFromName(device_name.c_str(), &device));\n     op->SetDevice(device);\n   }\n \n   core::RefCountPtr<eager::EagerClient> eager_client;\n-  uint64 context_id = ctx.GetContextId();\n+  uint64_t context_id = ctx.GetContextId();\n   TF_RETURN_IF_ERROR(ctx.GetClient(op->GetDeviceParsedName(), &eager_client));\n-  string remote_task;\n+  std::string remote_task;\n   if (!DeviceNameUtils::GetTaskName(op->GetDeviceParsedName(), &remote_task)) {\n     return errors::InvalidArgument(\n         \"Unable to find remote task corresponding to device \",\n@@ -1859,7 +1866,7 @@ absl::Status EagerRemoteExecute(EagerOperation* op, TensorHandle** retvals,\n       tensorflow::TensorHandle* input = (*inputs)[i];\n       tensorflow::Device* input_device = input->device();\n       tensorflow::Device* input_device_or_cpu = input->DeviceOrHostCPU(ctx);\n-      const string* input_device_name = &input_device_or_cpu->name();\n+      const std::string* input_device_name = &input_device_or_cpu->name();\n       bool serialize_resource_dtype_and_shape = false;\n       if (op_device != input_device &&\n           // If the expected and actual devices are on the same task, don't\n@@ -1986,7 +1993,7 @@ absl::Status EagerRemoteExecute(EagerOperation* op, TensorHandle** retvals,\n   }\n   *num_retvals = num_outputs;\n \n-  const tensorflow::uint64 id = remote_op->id();\n+  const uint64_t id = remote_op->id();\n   for (size_t i = 0; i < num_outputs; ++i) {\n     // TODO(nareshmodi): Change the callback to instead add the decref to a\n     // list of pending decrefs that we can send as a batch with the next\n@@ -2048,7 +2055,7 @@ absl::Status EagerRemoteExecute(EagerOperation* op, TensorHandle** retvals,\n       {retvals, num_outputs}));\n \n   if (op->EagerContext().LogDevicePlacement() || VLOG_IS_ON(1)) {\n-    string msg = absl::StrCat(\n+    std::string msg = absl::StrCat(\n         \"Executing op \", op->Name(), \" on task \",\n         DeviceNameUtils::ParsedNameToString(op->GetDeviceParsedName()));\n     if (!logging::LogToListeners(msg)) {\n@@ -2362,7 +2369,7 @@ absl::Status EagerCopyToDevice(TensorHandle* h, EagerContext* ctx,\n     return errors::Unimplemented(\n         \"Eager's remote execution is not available on mobile devices.\");\n #else   // !IS_MOBILE_PLATFORM\n-    uint64 recv_op_id = 0;\n+    uint64_t recv_op_id = 0;\n     if (receiver_is_local) {\n       Device* d = ctx->CanonicalDevice(device);\n       // TODO(gjn): Need to add support for async execution. Note if receiver\n@@ -2403,7 +2410,7 @@ absl::Status EagerCopyToDevice(TensorHandle* h, EagerContext* ctx,\n           return absl::OkStatus();\n         }\n       }\n-      string remote_task;\n+      std::string remote_task;\n       if (!DeviceNameUtils::GetTaskName(device->parsed_name(), &remote_task)) {\n         return errors::InvalidArgument(\n             \"Unable to find remote task corresponding to device \",\n@@ -2523,8 +2530,8 @@ void EagerLocalExecuteAsync(EagerOperation* op, TensorHandle** retvals,\n   }\n \n   if (ctx.LogDevicePlacement() || VLOG_IS_ON(1)) {\n-    string msg = absl::StrCat(\"Executing op \", op->Name(), \" in device \",\n-                              kernel->device()->name());\n+    std::string msg = absl::StrCat(\"Executing op \", op->Name(), \" in device \",\n+                                   kernel->device()->name());\n     if (!logging::LogToListeners(msg)) {\n       LOG(INFO) << msg;\n     }"
        },
        {
            "sha": "a8fb4fc308affe25878fb5f6d3abd616294fd43c",
            "filename": "tensorflow/core/common_runtime/eager/execute_node.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fexecute_node.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fexecute_node.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fexecute_node.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -23,7 +23,7 @@ namespace tensorflow {\n #if !defined(IS_MOBILE_PLATFORM)\n bool ExecuteNodeArgs::IsRemote(EagerContext* ctx, Device* input_device,\n                                TensorHandle* handle) {\n-  uint64 context_view_id = ctx->GetContextViewId();\n+  uint64_t context_view_id = ctx->GetContextViewId();\n   if (handle->Type() == TensorHandle::REMOTE ||\n       handle->HasRemoteMirror(input_device, context_view_id)) {\n     if (!has_remote_inputs_) {"
        },
        {
            "sha": "5427851f3d8b3f951a8dd38fdf06a16e75acd1ab",
            "filename": "tensorflow/core/common_runtime/eager/execute_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fexecute_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fexecute_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fexecute_test.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -70,7 +70,7 @@ TEST(ExecuteTest, SimpleFunction) {\n       false, &device_mgr, false, nullptr, nullptr);\n \n   const Tensor kTwo = test::AsScalar<int64_t>(2);\n-  const string function_name = \"XTimesTwo\";\n+  const std::string function_name = \"XTimesTwo\";\n   const FunctionDef x_times_two = FunctionDefHelper::Define(\n       // Name\n       function_name,\n@@ -125,7 +125,7 @@ TEST(ExecuteTest, SimpleFunctionInt32BadFullType) {\n       /*run_eager_op_as_function=*/true);\n \n   const Tensor kTwo = test::AsScalar<int32_t>(2);\n-  const string function_name = \"XTimesTwo\";\n+  const std::string function_name = \"XTimesTwo\";\n   const FunctionDef x_times_two = FunctionDefHelper::Define(\n       // Name\n       function_name,\n@@ -188,7 +188,7 @@ TEST(ExecuteTest, CompiledFunction) {\n       false, &device_mgr, false, nullptr, nullptr);\n \n   const Tensor kTwo = test::AsScalar<int64_t>(2);\n-  const string function_name = \"XTimesTwo\";\n+  const std::string function_name = \"XTimesTwo\";\n   const FunctionDef x_times_two = FunctionDefHelper::Define(\n       // Name\n       function_name,\n@@ -245,7 +245,7 @@ TEST(ExecuteTest, NestedCompiledFunction) {\n       false, &device_mgr, false, nullptr, nullptr);\n \n   const Tensor kTwo = test::AsScalar<int64_t>(2);\n-  const string function_name = \"XTimesTwo\";\n+  const std::string function_name = \"XTimesTwo\";\n   const FunctionDef x_times_two = FunctionDefHelper::Define(\n       // Name\n       function_name,\n@@ -266,7 +266,7 @@ TEST(ExecuteTest, NestedCompiledFunction) {\n       });\n   TF_ASSERT_OK(ctx->AddFunctionDef(x_times_two));\n \n-  const string call_function_name = \"FunctionCall\";\n+  const std::string call_function_name = \"FunctionCall\";\n   const FunctionDef function_call = FunctionDefHelper::Define(\n       // Name\n       call_function_name,\n@@ -325,7 +325,7 @@ TEST(ExecuteTest, MultipleNestedCompiledFunction) {\n       false, &device_mgr, false, nullptr, nullptr);\n \n   const Tensor kTwo = test::AsScalar<int64_t>(2);\n-  const string function_name = \"XTimesTwo\";\n+  const std::string function_name = \"XTimesTwo\";\n   const FunctionDef x_times_two = FunctionDefHelper::Define(\n       // Name\n       function_name,\n@@ -346,7 +346,7 @@ TEST(ExecuteTest, MultipleNestedCompiledFunction) {\n       });\n   TF_ASSERT_OK(ctx->AddFunctionDef(x_times_two));\n \n-  const string call_function_name = \"FunctionCall\";\n+  const std::string call_function_name = \"FunctionCall\";\n   FunctionDef function_call = FunctionDefHelper::Define(\n       // Name\n       call_function_name,\n@@ -379,7 +379,7 @@ TEST(ExecuteTest, MultipleNestedCompiledFunction) {\n \n   TF_ASSERT_OK(ctx->AddFunctionDef(function_call));\n \n-  const string call_function_name2 = \"FunctionCall2\";\n+  const std::string call_function_name2 = \"FunctionCall2\";\n   const FunctionDef function_call2 = FunctionDefHelper::Define(\n       // Name\n       call_function_name2,"
        },
        {
            "sha": "ba437b5df5e37da552f64abc2ea2df7517ad2234",
            "filename": "tensorflow/core/common_runtime/eager/kernel_and_device.h",
            "status": "modified",
            "additions": 11,
            "deletions": 9,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fkernel_and_device.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fkernel_and_device.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fkernel_and_device.h?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -193,7 +193,7 @@ class KernelAndDevice : public core::RefCounted {\n \n   virtual int num_inputs() const = 0;\n   virtual int num_outputs() const = 0;\n-  virtual const string& name() const = 0;\n+  virtual const std::string& name() const = 0;\n \n  protected:\n   std::function<void(std::function<void()>)>* get_runner() const;\n@@ -262,7 +262,7 @@ class KernelAndDeviceOp final : public KernelAndDevice {\n   }\n   int num_inputs() const override { return kernel_->num_inputs(); }\n   int num_outputs() const override { return kernel_->num_outputs(); }\n-  const string& name() const override { return kernel_->name(); }\n+  const std::string& name() const override { return kernel_->name(); }\n \n  private:\n   std::unique_ptr<OpKernel> kernel_;\n@@ -286,19 +286,20 @@ class KernelAndDeviceFunc : public KernelAndDevice {\n   KernelAndDeviceFunc(\n       FunctionLibraryRuntime* flr, ProcessFunctionLibraryRuntime* pflr,\n       std::vector<Device*> input_devices,\n-      absl::flat_hash_map<string, const std::vector<string>*> composite_devices,\n+      absl::flat_hash_map<std::string, const std::vector<std::string>*>\n+          composite_devices,\n       std::unordered_map<int, DtypeAndPartialTensorShape>\n           input_resource_dtypes_and_shapes,\n       std::function<void(std::function<void()>)>* runner,\n       std::unique_ptr<CollectiveExecutor::Handle> collective_executor,\n-      Device* host_cpu_device, const string& name,\n+      Device* host_cpu_device, const std::string& name,\n       const bool outputs_on_op_device,\n       const bool allow_small_function_optimizations,\n       const bool allow_control_flow_sync_execution,\n       const bool shape_inference_on_tfe_dialect_import,\n       const bool int_args_and_retvals_on_device,\n       const bool function_runs_at_most_once,\n-      std::optional<string> xla_compile_device_type,\n+      std::optional<std::string> xla_compile_device_type,\n       const bool allow_soft_placement, Rendezvous::Factory rendezvous_factory,\n       std::function<int64_t()> get_op_id)\n       : KernelAndDevice(flr, runner, std::move(collective_executor),\n@@ -366,7 +367,7 @@ class KernelAndDeviceFunc : public KernelAndDevice {\n   }\n   int num_inputs() const override { return input_dtypes_.size(); }\n   int num_outputs() const override { return output_dtypes_.size(); }\n-  const string& name() const override { return name_; };\n+  const std::string& name() const override { return name_; };\n \n  private:\n   std::shared_ptr<FunctionLibraryRuntime::Options> PrepareForRun(\n@@ -402,7 +403,7 @@ class KernelAndDeviceFunc : public KernelAndDevice {\n \n   const bool function_runs_at_most_once_;\n \n-  const absl::optional<string> xla_compile_device_type_;\n+  const absl::optional<std::string> xla_compile_device_type_;\n \n   const bool allow_soft_placement_;\n \n@@ -413,13 +414,14 @@ class KernelAndDeviceFunc : public KernelAndDevice {\n   // devices.\n   std::vector<Device*> input_devices_;\n   // Maps from a CompositeDevice name to a list of physical device names.\n-  absl::flat_hash_map<string, const std::vector<string>*> composite_devices_;\n+  absl::flat_hash_map<std::string, const std::vector<std::string>*>\n+      composite_devices_;\n   std::unordered_map<int, DtypeAndPartialTensorShape>\n       input_resource_dtypes_and_shapes_;\n \n   DataTypeVector input_dtypes_;\n   DataTypeVector output_dtypes_;\n-  string name_;\n+  std::string name_;\n \n   Rendezvous::Factory rendezvous_factory_;\n   std::function<int64_t()> get_op_id_;"
        },
        {
            "sha": "9b6e0e66a72a64b427718596f1c308aaf9ba15af",
            "filename": "tensorflow/core/common_runtime/eager/placement_utils.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 12,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fplacement_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fplacement_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fplacement_utils.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -34,19 +34,20 @@ namespace eager {\n // generate and then copy the data instead of just generating the data on the\n // device directly.\n static bool IsPinnableOp(absl::string_view op_name) {\n-  static const gtl::FlatSet<string>* unpinnable_ops = new gtl::FlatSet<string>({\n-      \"RandomUniform\",\n-      \"RandomUniformInt\",\n-      \"RandomStandardNormal\",\n-      \"StatelessRandomUniform\",\n-      \"StatelessRandomUniformInt\",\n-      \"StatelessRandomUniformFullInt\",\n-      \"StatelessRandomNormal\",\n-  });\n+  static const gtl::FlatSet<std::string>* unpinnable_ops =\n+      new gtl::FlatSet<std::string>({\n+          \"RandomUniform\",\n+          \"RandomUniformInt\",\n+          \"RandomStandardNormal\",\n+          \"StatelessRandomUniform\",\n+          \"StatelessRandomUniformInt\",\n+          \"StatelessRandomUniformFullInt\",\n+          \"StatelessRandomNormal\",\n+      });\n \n   // XRT ops refer to per-device handles that are not safe to move between\n   // devices.\n-  return unpinnable_ops->find(string(op_name)) == unpinnable_ops->end() &&\n+  return unpinnable_ops->find(std::string(op_name)) == unpinnable_ops->end() &&\n          !absl::StartsWith(op_name, \"XRT\");\n }\n // Validate if the remote device with the given incarnation is valid in the\n@@ -64,12 +65,12 @@ static absl::Status ValidateTensorHandleRemoteDevice(\n \n bool IsColocationExempt(absl::string_view op_name) {\n   const auto& exempt_ops = InputColocationExemptionRegistry::Global()->Get();\n-  return exempt_ops.find(string(op_name)) != exempt_ops.end();\n+  return exempt_ops.find(std::string(op_name)) != exempt_ops.end();\n }\n \n bool IsFunction(absl::string_view op_name) {\n   const OpDef* op_def = nullptr;\n-  absl::Status s = OpDefForOp(string(op_name), &op_def);\n+  absl::Status s = OpDefForOp(std::string(op_name), &op_def);\n   if (!s.ok()) {\n     if (!absl::IsNotFound(s)) {\n       LOG(WARNING) << \"Looking up OpDef failed with error: \" << s;"
        },
        {
            "sha": "aadec6deab8eb8572b0833d7023b2f4e2f3608b9",
            "filename": "tensorflow/core/common_runtime/eager/placement_utils_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fplacement_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fplacement_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Fplacement_utils_test.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -94,7 +94,7 @@ struct MaybePinSmallOpsToCpuTestCase {\n   std::string test_name;\n   DataType dtype;\n   TensorShape shape;\n-  string op_name;\n+  std::string op_name;\n   const char* device;\n   bool expect;\n };\n@@ -152,7 +152,7 @@ INSTANTIATE_TEST_SUITE_P(\n struct MaybePinToResourceDeviceTestCase {\n   std::string test_name;\n   DataType dtype;\n-  string op_name;\n+  std::string op_name;\n   const char* device;\n   bool expect;\n };"
        },
        {
            "sha": "583a8f15a657f4e1b83ca99aa275299895b7b74c",
            "filename": "tensorflow/core/common_runtime/eager/tensor_handle.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 21,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -60,7 +60,7 @@ int64_t GetRemoteDeviceIncarnation(Device* device) {\n   return device->attributes().incarnation();\n }\n \n-string SafeDeviceDebugString(Device* device) {\n+std::string SafeDeviceDebugString(Device* device) {\n   if (device == nullptr) {\n     return \"[]\";\n   } else {\n@@ -150,8 +150,8 @@ void TensorHandle::PackedTensorHandleData::Poison(absl::Status status) {\n   is_poisoned_ = status;\n }\n \n-string TensorHandle::PackedTensorHandleData::DebugString() const {\n-  string debug_str = \"PackedTensorHandleData: \";\n+std::string TensorHandle::PackedTensorHandleData::DebugString() const {\n+  std::string debug_str = \"PackedTensorHandleData: \";\n   for (const auto* handle : handles_) {\n     debug_str.append(\n         absl::StrCat(std::visit([](auto& data) { return data.DebugString(); },\n@@ -308,7 +308,7 @@ TensorHandle::TensorHandle(Device* d, Device* op_device,\n \n absl::Status TensorHandle::CreatePackedHandle(\n     std::vector<TensorHandle*>&& handles, const tensorflow::DataType dtype,\n-    const tensorflow::TensorShape& shape, const string& device_name,\n+    const tensorflow::TensorShape& shape, const std::string& device_name,\n     EagerContext* ctx, TensorHandle** packed_handle) {\n   if (handles.empty()) {\n     return errors::InvalidArgument(\"Handles should not be empty.\");\n@@ -319,7 +319,7 @@ absl::Status TensorHandle::CreatePackedHandle(\n     TF_RETURN_IF_ERROR(\n         handles.at(0)->GetResourceHandleDtypesAndShapes(&dtypes_and_shapes));\n   }\n-  std::vector<string> devices;\n+  std::vector<std::string> devices;\n   devices.reserve(handles.size());\n   for (auto* handle : handles) {\n     devices.push_back(handle->op_device() ? handle->op_device()->name()\n@@ -372,15 +372,15 @@ TensorHandle::TensorHandle(std::vector<TensorHandle*>&& handles, Device* device,\n \n #if !defined(IS_MOBILE_PLATFORM)\n TensorHandle* TensorHandle::CreateUnshapedRemoteHandle(\n-    int64_t op_id, int32_t output_num, const string& remote_task,\n+    int64_t op_id, int32_t output_num, const std::string& remote_task,\n     tensorflow::DataType dtype, Device* d, EagerContext* ctx,\n     const bool unknown_device) {\n   return new TensorHandle(op_id, output_num, remote_task, dtype, d, ctx,\n                           unknown_device);\n }\n \n TensorHandle::TensorHandle(int64_t op_id, int32_t output_num,\n-                           const string& remote_task,\n+                           const std::string& remote_task,\n                            tensorflow::DataType dtype, Device* d,\n                            EagerContext* ctx, const bool unknown_device)\n     : ImmediateExecutionTensorHandle(kEager),\n@@ -450,7 +450,7 @@ TensorHandle::HandleType TensorHandle::Type() const {\n   }\n }\n \n-string TensorHandle::TypeString() const {\n+std::string TensorHandle::TypeString() const {\n   if (data_.index() == 0) {\n     return \"LOCAL\";\n   } else if (data_.index() == 1) {\n@@ -713,7 +713,7 @@ absl::Status TensorHandle::AddEmptyLocalMirror(const Device* d) {\n absl::Status TensorHandle::RemoteAddress(const Device* d,\n                                          const bool wait_until_ready,\n                                          int64_t* op_id,\n-                                         int32* output_num) const {\n+                                         int32_t* output_num) const {\n   DVLOG(3) << \"RemoteAddress on TensorHandle: \" << this << \" device: \" << d\n            << \" \" << d->name();\n \n@@ -759,7 +759,7 @@ absl::Status TensorHandle::RemoteAddress(const Device* d,\n }\n \n bool TensorHandle::HasRemoteMirror(const Device* d,\n-                                   uint64 context_view_id) const {\n+                                   uint64_t context_view_id) const {\n   DVLOG(3) << \"HasRemoteMirror on TensorHandle: \" << this << \" device: \" << d\n            << \" \" << d->name();\n \n@@ -777,7 +777,7 @@ bool TensorHandle::HasRemoteMirror(const Device* d,\n }\n \n bool TensorHandle::HasResourceShapeMirror(const Device* d,\n-                                          uint64 context_view_id) const {\n+                                          uint64_t context_view_id) const {\n   DVLOG(3) << \"HasResourceShapeMirror on TensorHandle: \" << this\n            << \" device: \" << d << \" \" << d->name();\n \n@@ -793,11 +793,9 @@ bool TensorHandle::HasResourceShapeMirror(const Device* d,\n   return false;\n }\n \n-absl::Status TensorHandle::AddUnshapedRemoteMirror(const Device* d,\n-                                                   int64_t op_id,\n-                                                   int output_num,\n-                                                   const string& remote_task,\n-                                                   EagerContext* ctx) {\n+absl::Status TensorHandle::AddUnshapedRemoteMirror(\n+    const Device* d, int64_t op_id, int output_num,\n+    const std::string& remote_task, EagerContext* ctx) {\n   DVLOG(3) << \"AddUnshapedRemoteMirror on TensorHandle: \" << this\n            << \" device: \" << d << \" \" << d->name() << \" op_id: \" << op_id\n            << \" output_num: \" << output_num;\n@@ -856,14 +854,14 @@ absl::Status TensorHandle::AddResourceShapeMirror(const Device* d,\n \n absl::Status TensorHandle::SetRemoteShape(const TensorShape& shape,\n                                           const Device* d,\n-                                          uint64 context_view_id) {\n+                                          uint64_t context_view_id) {\n   return SetRemoteShapeAndDevice(shape, d, context_view_id, /*op_device=*/\"\");\n }\n \n absl::Status TensorHandle::SetRemoteShapeAndDevice(const TensorShape& shape,\n                                                    const Device* d,\n-                                                   uint64 context_view_id,\n-                                                   string op_device) {\n+                                                   uint64_t context_view_id,\n+                                                   std::string op_device) {\n   DVLOG(3) << \"SetRemoteShape on TensorHandle: \" << this << \" device: \" << d\n            << \" \" << d->name();\n \n@@ -930,7 +928,7 @@ absl::Status TensorHandle::SetRemoteShapeAndDevice(const TensorShape& shape,\n     resource_device_ = dtype == DT_RESOURCE ? device : nullptr;\n     resource_remote_device_incarnation_ =\n         GetRemoteDeviceIncarnation(resource_device_);\n-    string remote_task;\n+    std::string remote_task;\n     if (!DeviceNameUtils::GetTaskName(device->parsed_name(), &remote_task)) {\n       return errors::InvalidArgument(\n           \"Unable to find remote task corresponding to device \",\n@@ -948,7 +946,7 @@ absl::Status TensorHandle::SetRemoteShapeAndDevice(const TensorShape& shape,\n }\n \n void TensorHandle::PoisonRemote(absl::Status status, const Device* d,\n-                                uint64 context_view_id) {\n+                                uint64_t context_view_id) {\n   DVLOG(3) << \"PoisonRemote on TensorHandle: \" << this << \" device: \" << d\n            << \" \" << d->name();\n "
        },
        {
            "sha": "e2fdb872c317a277072c500da81116f9b4cae461",
            "filename": "tensorflow/core/common_runtime/eager/tensor_handle.h",
            "status": "modified",
            "additions": 22,
            "deletions": 23,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle.h?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -66,9 +66,9 @@ class TensorHandle : public ImmediateExecutionTensorHandle {\n                tensorflow::DataType dtype, EagerContext* ctx);\n \n #if !defined(IS_MOBILE_PLATFORM)\n-  TensorHandle(int64_t op_id, int32_t output_num, const string& remote_task,\n-               tensorflow::DataType dtype, Device* device, EagerContext* ctx,\n-               bool unknown_device);\n+  TensorHandle(int64_t op_id, int32_t output_num,\n+               const std::string& remote_task, tensorflow::DataType dtype,\n+               Device* device, EagerContext* ctx, bool unknown_device);\n   TensorHandle(int64_t op_id, int32_t output_num, tensorflow::DataType dtype,\n                Device* device, bool is_ready, EagerContext* ctx);\n #endif  // IS_MOBILE_PLATFORM\n@@ -97,7 +97,7 @@ class TensorHandle : public ImmediateExecutionTensorHandle {\n   static absl::Status CreatePackedHandle(std::vector<TensorHandle*>&& handles,\n                                          tensorflow::DataType dtype,\n                                          const tensorflow::TensorShape& shape,\n-                                         const string& device_name,\n+                                         const std::string& device_name,\n                                          EagerContext* ctx,\n                                          TensorHandle** packed_handle);\n   static absl::Status CreatePackedHandle(std::vector<TensorHandle*>&& handles,\n@@ -108,12 +108,10 @@ class TensorHandle : public ImmediateExecutionTensorHandle {\n   // An unshaped remote handle refers to a tensor on a remote worker. It's not\n   // ready until the shape is set. It controls the lifetime of the remote\n   // tensor.\n-  static TensorHandle* CreateUnshapedRemoteHandle(int64_t op_id,\n-                                                  int32_t output_num,\n-                                                  const string& remote_task,\n-                                                  tensorflow::DataType dtype,\n-                                                  Device* d, EagerContext* ctx,\n-                                                  bool unknown_device = false);\n+  static TensorHandle* CreateUnshapedRemoteHandle(\n+      int64_t op_id, int32_t output_num, const std::string& remote_task,\n+      tensorflow::DataType dtype, Device* d, EagerContext* ctx,\n+      bool unknown_device = false);\n   // A lazy remote handle refers to a tensor on a remote worker. The lifetime of\n   // the remote tensor is controlled by the remote worker, but not by the lazy\n   // remote handle. Lazy handles are normally created on a default function\n@@ -189,12 +187,12 @@ class TensorHandle : public ImmediateExecutionTensorHandle {\n   absl::Status AddLocalMirror(tensorflow::Tensor&& tensor, const Device* d);\n \n #if !defined(IS_MOBILE_PLATFORM)\n-  bool HasRemoteMirror(const Device* d, uint64 context_view_id) const;\n-  bool HasResourceShapeMirror(const Device* d, uint64 context_view_id) const;\n+  bool HasRemoteMirror(const Device* d, uint64_t context_view_id) const;\n+  bool HasResourceShapeMirror(const Device* d, uint64_t context_view_id) const;\n \n   absl::Status AddUnshapedRemoteMirror(const Device* d, int64_t op_id,\n                                        int output_num,\n-                                       const string& remote_task,\n+                                       const std::string& remote_task,\n                                        EagerContext* ctx);\n   absl::Status AddResourceShapeMirror(const Device* d, int64_t op_id,\n                                       int output_num, EagerContext* ctx);\n@@ -203,7 +201,7 @@ class TensorHandle : public ImmediateExecutionTensorHandle {\n   // If wait_until_ready is true, block until the remote tensor is ready on the\n   // given remote worker.\n   absl::Status RemoteAddress(const Device* d, bool wait_until_ready,\n-                             int64_t* op_id, int32* output_num) const;\n+                             int64_t* op_id, int32_t* output_num) const;\n \n   // Called on an async remote tensor once it's shape has been determined. This\n   // transitions the tensor handle from a non-ready to a ready state by\n@@ -213,20 +211,21 @@ class TensorHandle : public ImmediateExecutionTensorHandle {\n   // This method or Poison must be called exactly once for remote tensors that\n   // were created without a known shape.\n   absl::Status SetRemoteShape(const TensorShape& shape, const Device* d,\n-                              uint64 context_view_id);\n+                              uint64_t context_view_id);\n   // If op_device is not empty, reset the devices of a remote tensor which is\n   // created without known devices (e.g. function outputs).\n   absl::Status SetRemoteShapeAndDevice(const TensorShape& shape,\n-                                       const Device* d, uint64 context_view_id,\n-                                       string op_device);\n+                                       const Device* d,\n+                                       uint64_t context_view_id,\n+                                       std::string op_device);\n \n   // Poisons either this handle or a remote mirror with error `status`.\n   // Poisoning means that the handle will become ready and methods trying\n   // to access the remote shape will return this error `status`.\n   // Exactly one of SetRemoteShape or PoisonRemote methods must be called on a\n   // unshaped handle on a remote device.\n   void PoisonRemote(absl::Status status, const Device* d,\n-                    uint64 context_view_id);\n+                    uint64_t context_view_id);\n #endif\n \n   // Sets the `tensor` for this async non-ready handle making it ready.\n@@ -260,7 +259,7 @@ class TensorHandle : public ImmediateExecutionTensorHandle {\n   enum HandleType { LOCAL = 0, PACKED = 1, REMOTE = 2 };\n \n   HandleType Type() const;\n-  string TypeString() const;\n+  std::string TypeString() const;\n \n   void SetResourceHandleDtypeAndShape(\n       std::vector<DtypeAndPartialTensorShape> dtypes_and_shapes);\n@@ -330,9 +329,9 @@ class TensorHandle : public ImmediateExecutionTensorHandle {\n   // TODO(yujingzhang): Remove resource_shape_mirrors_ once scalable per-replica\n   // variable is ready, since we could get the shape locally without remote copy\n   // then.\n-  std::unordered_map<string, RemoteTensorHandleData> resource_shape_mirrors_\n-      TF_GUARDED_BY(mu_);\n-  std::unordered_map<string, RemoteTensorHandleData> remote_mirrors_\n+  std::unordered_map<std::string, RemoteTensorHandleData>\n+      resource_shape_mirrors_ TF_GUARDED_BY(mu_);\n+  std::unordered_map<std::string, RemoteTensorHandleData> remote_mirrors_\n       TF_GUARDED_BY(mu_);\n #endif\n \n@@ -371,7 +370,7 @@ class TensorHandle : public ImmediateExecutionTensorHandle {\n     bool IsReady() const;\n     absl::Status WaitReady(const char* caller) const;\n     void Poison(absl::Status status);\n-    string DebugString() const;\n+    std::string DebugString() const;\n \n     // Number of packed handles.\n     int NumPackedHandles() const;"
        },
        {
            "sha": "b0a089874dd74408ffc2d20aa5cc5675c676e6db",
            "filename": "tensorflow/core/common_runtime/eager/tensor_handle_data.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle_data.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle_data.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle_data.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -96,7 +96,7 @@ absl::Status LocalTensorHandleData::SetTensor(tensorflow::Tensor&& t) {\n   return absl::OkStatus();\n }\n \n-string LocalTensorHandleData::DebugString() const {\n+std::string LocalTensorHandleData::DebugString() const {\n   if (IsReady()) {\n     return tensor_.DeviceSafeDebugString();\n   } else {"
        },
        {
            "sha": "73a20425871156503e79610a3d23c4f0e3fc98b7",
            "filename": "tensorflow/core/common_runtime/eager/tensor_handle_data.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle_data.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle_data.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle_data.h?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -60,7 +60,7 @@ class LocalTensorHandleData {\n \n   absl::Status SetTensor(tensorflow::Tensor&& t);\n \n-  string DebugString() const;\n+  std::string DebugString() const;\n \n  private:\n   tensorflow::Tensor tensor_;"
        },
        {
            "sha": "0bd94f635f0f00a74bd654a23456520d2d6b1533",
            "filename": "tensorflow/core/common_runtime/eager/tensor_handle_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17428e9c7986e3b98c0d1cd094e6a2b40f546c8a/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Feager%2Ftensor_handle_test.cc?ref=17428e9c7986e3b98c0d1cd094e6a2b40f546c8a",
            "patch": "@@ -44,7 +44,7 @@ TEST(TensorHandle_ShapeTest, AsyncShape) {\n   EXPECT_TRUE(t.shape().IsSameSize(TensorShape({2, 2})));\n   for (int64_t a = 0; a < t.shape().dim_size(0); a++) {\n     for (int64_t b = 0; b < t.shape().dim_size(1); b++) {\n-      t.matrix<uint16>()(a, b) = uint16(a * b);\n+      t.matrix<uint16_t>()(a, b) = uint16_t(a * b);\n     }\n   }\n \n@@ -181,7 +181,7 @@ TEST_F(PackedTensorHandleTest, PackedHandle) {\n   handles.push_back(h1);\n \n   // Create 2 remote TensorHandles (not ready).\n-  const string remote_task = \"/job:worker/replica:0/task:1\";\n+  const std::string remote_task = \"/job:worker/replica:0/task:1\";\n   Device* d2 = ListGPUDevices().at(2);\n   TensorHandle* h2 = TensorHandle::CreateUnshapedRemoteHandle(\n       /*op_id=*/0, /*output_num=*/0, remote_task, dtype, d2, context());\n@@ -439,7 +439,7 @@ TEST_F(RemoteTensorHandleTest, UnknownRemoteDevice) {\n   tensorflow::DataType dtype = DT_FLOAT;\n   TensorShape shape = {};\n \n-  const string remote_task = \"/job:worker/replica:0/task:1\";\n+  const std::string remote_task = \"/job:worker/replica:0/task:1\";\n   Device* d1 = device_mgr.ListDevices().at(1);\n   TensorHandle* h = TensorHandle::CreateUnshapedRemoteHandle(\n       /*op_id=*/0, /*output_num=*/0, remote_task, dtype, d1, context,\n@@ -478,7 +478,7 @@ TEST_F(RemoteTensorHandleTest, PoisonRemote) {\n   tensorflow::DataType dtype = DT_FLOAT;\n   TensorShape shape = {};\n \n-  const string remote_task = \"/job:worker/replica:0/task:1\";\n+  const std::string remote_task = \"/job:worker/replica:0/task:1\";\n   Device* d1 = device_mgr.ListDevices().at(1);\n   TensorHandle* h = TensorHandle::CreateUnshapedRemoteHandle(\n       /*op_id=*/0, /*output_num=*/0, remote_task, dtype, d1, context,\n@@ -519,7 +519,7 @@ TEST_F(RemoteTensorHandleTest, PoisonRemoteMirror) {\n   tensorflow::DataType dtype = DT_FLOAT;\n   TensorShape shape = {};\n \n-  const string remote_task = \"/job:worker/replica:0/task:1\";\n+  const std::string remote_task = \"/job:worker/replica:0/task:1\";\n   Device* d1 = device_mgr.ListDevices().at(1);\n   TensorHandle* h = TensorHandle::CreateUnshapedRemoteHandle(\n       /*op_id=*/0, /*output_num=*/0, remote_task, dtype, d1, context,\n@@ -565,7 +565,7 @@ TEST_F(RemoteTensorHandleTest, SetRemoteTensorHandleShapeTwice) {\n   tensorflow::DataType dtype = DT_FLOAT;\n   TensorShape shape = {};\n \n-  const string remote_task = \"/job:worker/replica:0/task:1\";\n+  const std::string remote_task = \"/job:worker/replica:0/task:1\";\n   Device* d1 = device_mgr.ListDevices().at(1);\n   TensorHandle* h = TensorHandle::CreateUnshapedRemoteHandle(\n       /*op_id=*/0, /*output_num=*/0, remote_task, dtype, d1, context,\n@@ -623,7 +623,7 @@ TEST_F(RemoteTensorHandleTest, SetRemoteMirrorShapeTwice) {\n   tensorflow::DataType dtype = DT_FLOAT;\n   TensorShape shape = {};\n \n-  const string remote_task = \"/job:worker/replica:0/task:1\";\n+  const std::string remote_task = \"/job:worker/replica:0/task:1\";\n   Device* d1 = device_mgr.ListDevices().at(1);\n   TensorHandle* h = TensorHandle::CreateUnshapedRemoteHandle(\n       /*op_id=*/0, /*output_num=*/0, remote_task, dtype, d1, context,"
        }
    ],
    "stats": {
        "total": 720,
        "additions": 371,
        "deletions": 349
    }
}