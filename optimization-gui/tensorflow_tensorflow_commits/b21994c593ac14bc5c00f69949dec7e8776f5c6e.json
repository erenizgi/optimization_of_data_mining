{
    "author": "KanishAnand",
    "message": "Set frontend attributes in mlir to hlo conversion regardless of entry function.\n\nPiperOrigin-RevId: 811804555",
    "sha": "b21994c593ac14bc5c00f69949dec7e8776f5c6e",
    "files": [
        {
            "sha": "29e718fa7b1f150642a2dde5c023763778532cb9",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b21994c593ac14bc5c00f69949dec7e8776f5c6e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b21994c593ac14bc5c00f69949dec7e8776f5c6e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc?ref=b21994c593ac14bc5c00f69949dec7e8776f5c6e",
            "patch": "@@ -5937,8 +5937,8 @@ LogicalResult ConvertToHloModule::RunOnFunction(mlir::func::FuncOp f) {\n     // means no replication. This avoids the need for unrelated tests to handle\n     // this field.\n     if (!any_arg_replicated) entry_args_same_across_replicas.clear();\n-    ExtractFrontendAttributesFromFunction(f, &arg_fe_attrs);\n   }\n+  ExtractFrontendAttributesFromFunction(f, &arg_fe_attrs);\n   ExtractShardingsFromFunction(f, &arg_shardings, &ret_shardings,\n                                entry_function);\n   xla::XlaComputationId computation;"
        },
        {
            "sha": "3e31c266189be57938e5efb5eaa2f7cf7f92f922",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/tests/shardy.mlir",
            "status": "modified",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b21994c593ac14bc5c00f69949dec7e8776f5c6e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fshardy.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b21994c593ac14bc5c00f69949dec7e8776f5c6e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fshardy.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fshardy.mlir?ref=b21994c593ac14bc5c00f69949dec7e8776f5c6e",
            "patch": "@@ -117,3 +117,37 @@ module @sdy_frontend_attributes_inlined_meshes {\n         // CHECK-SAME{LITERAL}: sharding={{devices=[8,4]<=[32]}, {replicated}}\n       }\n     }\n+\n+// -----\n+\n+// Ensure frontend attributes are propagated to nested functions.\n+// CHECK-LABEL: HloModule non_main_func_frontend_attributes{{.*}}frontend_attributes={xla.sdy.meshes={mesh = #sdy.mesh<[\"x\"=2, \"y\"=4, \"z\"=4]>}\n+module @non_main_func_frontend_attributes attributes {mhlo.frontend_attributes = {xla.sdy.meshes =\n+      \"{mesh = #sdy.mesh<[\\\"x\\\"=2, \\\"y\\\"=4, \\\"z\\\"=4]>}\"\n+    }} {\n+      func.func @called_func(\n+          %arg0: tensor<8x8xf32> {mhlo.sharding = \"{devices=[1,4,8]<=[2,4,4]T(1,0,2) last_tile_dim_replicate}\",\n+                                  mhlo.frontend_attributes = {xla.sdy.sharding = \"#sdy.sharding<@mesh, [{}, {\\\"y\\\"}]>\"}}\n+      ) -> tensor<8x8xf32> {\n+      // CHECK: %[[ARG:.*]] = f32[8,8] parameter(0), sharding={devices=[1,4,8]<=[2,4,4]T(1,0,2) last_tile_dim_replicate}\n+      // CHECK-SAME: frontend_attributes={xla.sdy.sharding=\"#sdy.sharding<@mesh, [{}, {\\\"y\\\"}]>\"}\n+        %0 = mhlo.add %arg0, %arg0 : tensor<8x8xf32>\n+        return %0 : tensor<8x8xf32>\n+      }\n+\n+      func.func @main(\n+          %arg0: tensor<8x8xf32> {mhlo.sharding = \"{devices=[2,1,16]<=[32] last_tile_dim_replicate}\",\n+                                  mhlo.frontend_attributes = {xla.sdy.sharding = \"#sdy.sharding<@mesh, [{\\\"x\\\"}, {}]>\"}},\n+          %arg1: tensor<8x8xf32> {mhlo.sharding = \"{devices=[1,4,8]<=[2,4,4]T(1,0,2) last_tile_dim_replicate}\",\n+                                  mhlo.frontend_attributes = {xla.sdy.sharding = \"#sdy.sharding<@mesh, [{}, {\\\"y\\\"}]>\"}}\n+      ) -> tensor<8x8xf32> {\n+      // CHECK: %[[ARG:.*]] = f32[8,8] parameter(0)\n+      // CHECK-SAME: sharding={devices=[2,1,16]<=[32] last_tile_dim_replicate}\n+      // CHECK-SAME: frontend_attributes={xla.sdy.sharding=\"#sdy.sharding<@mesh, [{\\\"x\\\"}, {}]>\"}\n+      // CHECK-NEXT: %[[ARG:.*]] = f32[8,8] parameter(1)\n+      // CHECK-SAME: sharding={devices=[1,4,8]<=[2,4,4]T(1,0,2) last_tile_dim_replicate}\n+      // CHECK-SAME: frontend_attributes={xla.sdy.sharding=\"#sdy.sharding<@mesh, [{}, {\\\"y\\\"}]>\"}\n+        %0 = call @called_func(%arg1) : (tensor<8x8xf32>) -> tensor<8x8xf32>\n+        return %0 : tensor<8x8xf32>\n+      }\n+    }"
        }
    ],
    "stats": {
        "total": 36,
        "additions": 35,
        "deletions": 1
    }
}