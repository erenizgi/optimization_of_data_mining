{
    "author": "khasanovaa",
    "message": "Add de/serialization for `Host{Send|Recv}[Done]Thunk(s)`\n\nPiperOrigin-RevId: 831740352",
    "sha": "ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee",
    "files": [
        {
            "sha": "d9f7edc91dd53ad1b2e5424b8b0bb4e2026cb029",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee",
            "patch": "@@ -1829,6 +1829,7 @@ cc_library(\n     hdrs = [\"host_send_recv_thunk.h\"],\n     deps = [\n         \":thunk\",\n+        \":thunk_proto_cc\",\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/service:buffer_assignment\",\n@@ -1849,6 +1850,7 @@ cc_library(\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/synchronization\",\n+        \"@com_google_absl//absl/types:span\",\n         \"@local_tsl//tsl/profiler/lib:traceme\",\n     ],\n )\n@@ -2538,6 +2540,7 @@ cc_library(\n         \":gemm_thunk\",\n         \":gpublas_lt_matmul_thunk\",\n         \":host_execute_thunk\",\n+        \":host_send_recv_thunk\",\n         \":infeed_thunk\",\n         \":kernel_thunk\",\n         \":memset_thunk\",\n@@ -2571,6 +2574,7 @@ xla_cc_test(\n         \":conditional_thunk\",\n         \":copy_thunk\",\n         \":host_execute_thunk\",\n+        \":host_send_recv_thunk\",\n         \":sequential_thunk\",\n         \":thunk\",\n         \":thunk_proto_cc\","
        },
        {
            "sha": "cce2f2795712a1b3faa1c571185f3cee8d4a7024",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_send_recv_thunk.cc",
            "status": "modified",
            "additions": 173,
            "deletions": 1,
            "changes": 174,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_send_recv_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_send_recv_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_send_recv_thunk.cc?ref=ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/global_device_id.h\"\n@@ -112,6 +113,53 @@ HostSendThunk::HostSendThunk(\n       frontend_attrs_(std::move(frontend_attrs)),\n       device_constraint_(device_constraint) {}\n \n+absl::StatusOr<ThunkProto> HostSendThunk::ToProto() const {\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+  HostSendThunkProto& host_send_thunk_proto = *proto.mutable_host_send_thunk();\n+  *host_send_thunk_proto.mutable_shape() = shape_.ToProto();\n+  TF_ASSIGN_OR_RETURN(*host_send_thunk_proto.mutable_buffer(),\n+                      buffer_.ToProto());\n+  host_send_thunk_proto.set_channel_id(channel_id_);\n+  for (const auto& [key, value] : frontend_attrs_) {\n+    host_send_thunk_proto.mutable_frontend_attrs()->insert({key, value});\n+  }\n+  if (device_constraint_.has_value()) {\n+    host_send_thunk_proto.set_device_constraint(device_constraint_->value());\n+  }\n+  std::optional<AsyncEventsUniqueId> async_events_unique_id =\n+      GetAsyncEventsUniqueId();\n+  if (!async_events_unique_id.has_value()) {\n+    return absl::InternalError(\"HostSendThunk has no paired Done event\");\n+  }\n+  host_send_thunk_proto.set_async_events_unique_id(\n+      async_events_unique_id.value().value());\n+  return proto;\n+}\n+\n+absl::StatusOr<std::unique_ptr<HostSendThunk>> HostSendThunk::FromProto(\n+    ThunkInfo thunk_info, const HostSendThunkProto& proto,\n+    absl::Span<const BufferAllocation> allocations,\n+    HostSendRecvAsyncEventsMap& async_events_map) {\n+  TF_ASSIGN_OR_RETURN(Shape shape, Shape::FromProto(proto.shape()));\n+  TF_ASSIGN_OR_RETURN(\n+      BufferAllocation::Slice buffer,\n+      BufferAllocation::Slice::FromProto(proto.buffer(), allocations));\n+  std::optional<GlobalDeviceId> device_constraint;\n+  if (proto.has_device_constraint()) {\n+    device_constraint = GlobalDeviceId(proto.device_constraint());\n+  }\n+  absl::flat_hash_map<std::string, std::string> frontend_attrs(\n+      proto.frontend_attrs().begin(), proto.frontend_attrs().end());\n+\n+  auto [async_event_it, _] = async_events_map.try_emplace(\n+      AsyncEventsUniqueId(proto.async_events_unique_id()),\n+      std::make_shared<HostSendRecvAsyncEvents>());\n+  return std::make_unique<HostSendThunk>(\n+      thunk_info, std::move(shape), buffer, proto.channel_id(),\n+      async_event_it->second, std::move(frontend_attrs), device_constraint);\n+}\n+\n absl::Status HostSendThunk::ExecuteOnStream(const ExecuteParams& params) {\n   VLOG(3) << \"Send buffer: channel_id=\" << channel_id_\n           << \"; shape=\" << shape_.ToString();\n@@ -168,6 +216,44 @@ HostSendDoneThunk::HostSendDoneThunk(\n       events_(std::move(events)),\n       device_constraint_(device_constraint) {}\n \n+absl::StatusOr<ThunkProto> HostSendDoneThunk::ToProto() const {\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+  HostSendDoneThunkProto& host_send_done_thunk_proto =\n+      *proto.mutable_host_send_done_thunk();\n+  host_send_done_thunk_proto.set_channel_id(channel_id_);\n+  if (device_constraint_.has_value()) {\n+    host_send_done_thunk_proto.set_device_constraint(\n+        device_constraint_->value());\n+  }\n+  std::optional<AsyncEventsUniqueId> async_events_unique_id =\n+      GetAsyncEventsUniqueId();\n+  if (!async_events_unique_id.has_value()) {\n+    return absl::InternalError(\"HostSendDoneThunk has no paired Start event\");\n+  }\n+  host_send_done_thunk_proto.set_async_events_unique_id(\n+      async_events_unique_id.value().value());\n+  return proto;\n+}\n+\n+absl::StatusOr<std::unique_ptr<HostSendDoneThunk>> HostSendDoneThunk::FromProto(\n+    ThunkInfo thunk_info, const HostSendDoneThunkProto& proto,\n+    absl::Span<const BufferAllocation> allocations,\n+    HostSendRecvAsyncEventsMap& async_events_map) {\n+  std::optional<GlobalDeviceId> device_constraint;\n+  if (proto.has_device_constraint()) {\n+    device_constraint = GlobalDeviceId(proto.device_constraint());\n+  }\n+\n+  auto [async_event_it, _] = async_events_map.try_emplace(\n+      AsyncEventsUniqueId(proto.async_events_unique_id()),\n+      std::make_shared<HostSendRecvAsyncEvents>());\n+\n+  return std::make_unique<HostSendDoneThunk>(thunk_info, proto.channel_id(),\n+                                             std::move(async_event_it->second),\n+                                             device_constraint);\n+}\n+\n absl::Status HostSendDoneThunk::ExecuteOnStream(const ExecuteParams& params) {\n   VLOG(3) << \"Wait for send completion: channel_id=\" << channel_id_;\n \n@@ -217,6 +303,53 @@ HostRecvThunk::HostRecvThunk(\n       frontend_attrs_(std::move(frontend_attrs)),\n       device_constraint_(device_constraint) {}\n \n+absl::StatusOr<ThunkProto> HostRecvThunk::ToProto() const {\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+  HostRecvThunkProto& host_recv_thunk_proto = *proto.mutable_host_recv_thunk();\n+  *host_recv_thunk_proto.mutable_shape() = shape_.ToProto();\n+  TF_ASSIGN_OR_RETURN(*host_recv_thunk_proto.mutable_buffer(),\n+                      buffer_.ToProto());\n+  host_recv_thunk_proto.set_channel_id(channel_id_);\n+  for (const auto& [key, value] : frontend_attrs_) {\n+    host_recv_thunk_proto.mutable_frontend_attrs()->insert({key, value});\n+  }\n+  if (device_constraint_.has_value()) {\n+    host_recv_thunk_proto.set_device_constraint(device_constraint_->value());\n+  }\n+  std::optional<AsyncEventsUniqueId> async_events_unique_id =\n+      GetAsyncEventsUniqueId();\n+  if (!async_events_unique_id.has_value()) {\n+    return absl::InternalError(\"HostRecvThunk has no paired Done event\");\n+  }\n+  host_recv_thunk_proto.set_async_events_unique_id(\n+      async_events_unique_id.value().value());\n+  return proto;\n+}\n+\n+absl::StatusOr<std::unique_ptr<HostRecvThunk>> HostRecvThunk::FromProto(\n+    ThunkInfo thunk_info, const HostRecvThunkProto& proto,\n+    absl::Span<const BufferAllocation> allocations,\n+    HostSendRecvAsyncEventsMap& async_events_map) {\n+  TF_ASSIGN_OR_RETURN(Shape shape, Shape::FromProto(proto.shape()));\n+  TF_ASSIGN_OR_RETURN(\n+      BufferAllocation::Slice buffer,\n+      BufferAllocation::Slice::FromProto(proto.buffer(), allocations));\n+  std::optional<GlobalDeviceId> device_constraint;\n+  if (proto.has_device_constraint()) {\n+    device_constraint = GlobalDeviceId(proto.device_constraint());\n+  }\n+  absl::flat_hash_map<std::string, std::string> frontend_attrs(\n+      proto.frontend_attrs().begin(), proto.frontend_attrs().end());\n+\n+  auto [async_event_it, _] = async_events_map.try_emplace(\n+      AsyncEventsUniqueId(proto.async_events_unique_id()),\n+      std::make_shared<HostSendRecvAsyncEvents>());\n+  return std::make_unique<HostRecvThunk>(\n+      thunk_info, std::move(shape), buffer, proto.channel_id(),\n+      async_event_it->second, std::move(frontend_attrs), device_constraint);\n+}\n+\n absl::Status HostRecvThunk::ExecuteOnStream(const ExecuteParams& params) {\n   VLOG(3) << \"Recv buffer: channel_id=\" << channel_id_\n           << \"; shape=\" << shape_.ToString();\n@@ -270,7 +403,46 @@ HostRecvDoneThunk::HostRecvDoneThunk(\n     std::optional<GlobalDeviceId> device_constraint)\n     : Thunk(Thunk::kHostRecvDone, thunk_info),\n       channel_id_(channel_id),\n-      events_(std::move(events)) {}\n+      events_(std::move(events)),\n+      device_constraint_(device_constraint) {}\n+\n+absl::StatusOr<ThunkProto> HostRecvDoneThunk::ToProto() const {\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+  HostRecvDoneThunkProto& host_recv_done_thunk_proto =\n+      *proto.mutable_host_recv_done_thunk();\n+  host_recv_done_thunk_proto.set_channel_id(channel_id_);\n+  if (device_constraint_.has_value()) {\n+    host_recv_done_thunk_proto.set_device_constraint(\n+        device_constraint_->value());\n+  }\n+  std::optional<AsyncEventsUniqueId> async_events_unique_id =\n+      GetAsyncEventsUniqueId();\n+  if (!async_events_unique_id.has_value()) {\n+    return absl::InternalError(\"HostRecvDoneThunk has no paired Start event\");\n+  }\n+  host_recv_done_thunk_proto.set_async_events_unique_id(\n+      async_events_unique_id.value().value());\n+  return proto;\n+}\n+\n+absl::StatusOr<std::unique_ptr<HostRecvDoneThunk>> HostRecvDoneThunk::FromProto(\n+    ThunkInfo thunk_info, const HostRecvDoneThunkProto& proto,\n+    absl::Span<const BufferAllocation> allocations,\n+    HostSendRecvAsyncEventsMap& async_events_map) {\n+  std::optional<GlobalDeviceId> device_constraint;\n+  if (proto.has_device_constraint()) {\n+    device_constraint = GlobalDeviceId(proto.device_constraint());\n+  }\n+\n+  auto [async_event_it, _] = async_events_map.try_emplace(\n+      AsyncEventsUniqueId(proto.async_events_unique_id()),\n+      std::make_shared<HostSendRecvAsyncEvents>());\n+\n+  return std::make_unique<HostRecvDoneThunk>(thunk_info, proto.channel_id(),\n+                                             std::move(async_event_it->second),\n+                                             device_constraint);\n+}\n \n absl::Status HostRecvDoneThunk::ExecuteOnStream(const ExecuteParams& params) {\n   VLOG(3) << \"Wait for recv completion: channel_id=\" << channel_id_;"
        },
        {
            "sha": "ca86059a10c358259d5bd70b67fbf64e64fe3f56",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_send_recv_thunk.h",
            "status": "modified",
            "additions": 36,
            "deletions": 0,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_send_recv_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_send_recv_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_send_recv_thunk.h?ref=ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee",
            "patch": "@@ -28,6 +28,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/global_device_id.h\"\n #include \"xla/shape.h\"\n@@ -78,12 +79,24 @@ class HostSendRecvAsyncEvents {\n       events_ ABSL_GUARDED_BY(mutex_);\n };\n \n+// A map from a unique id to a shared pointer to HostSendRecvAsyncEvents.\n+// This is used to match the pairs of HostSend/Recv and HostSend/RecvDone thunks\n+// during deserialization.\n+using HostSendRecvAsyncEventsMap =\n+    absl::flat_hash_map<AsyncEventsUniqueId,\n+                        std::shared_ptr<HostSendRecvAsyncEvents>>;\n+\n //===----------------------------------------------------------------------===//\n // HostSendThunk\n //===----------------------------------------------------------------------===//\n \n class HostSendThunk : public Thunk {\n  public:\n+  static absl::StatusOr<std::unique_ptr<HostSendThunk>> FromProto(\n+      ThunkInfo thunk_info, const HostSendThunkProto& proto,\n+      absl::Span<const BufferAllocation> allocations,\n+      HostSendRecvAsyncEventsMap& async_events_map);\n+\n   HostSendThunk(ThunkInfo thunk_info, Shape shape,\n                 BufferAllocation::Slice buffer, int64_t channel_id,\n                 std::shared_ptr<HostSendRecvAsyncEvents> events,\n@@ -92,6 +105,8 @@ class HostSendThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n   std::optional<AsyncEventsUniqueId> GetAsyncEventsUniqueId() const override;\n \n   bool IsAsyncStart() const override { return events_ != nullptr; }\n@@ -113,12 +128,19 @@ class HostSendThunk : public Thunk {\n \n class HostSendDoneThunk : public Thunk {\n  public:\n+  static absl::StatusOr<std::unique_ptr<HostSendDoneThunk>> FromProto(\n+      ThunkInfo thunk_info, const HostSendDoneThunkProto& proto,\n+      absl::Span<const BufferAllocation> allocations,\n+      HostSendRecvAsyncEventsMap& async_events_map);\n+\n   HostSendDoneThunk(ThunkInfo thunk_info, int64_t channel_id,\n                     std::shared_ptr<HostSendRecvAsyncEvents> events,\n                     std::optional<GlobalDeviceId> device_constraint);\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n   std::optional<AsyncEventsUniqueId> GetAsyncEventsUniqueId() const override;\n \n   bool IsAsyncDone() const override { return events_ != nullptr; }\n@@ -136,6 +158,11 @@ class HostSendDoneThunk : public Thunk {\n \n class HostRecvThunk : public Thunk {\n  public:\n+  static absl::StatusOr<std::unique_ptr<HostRecvThunk>> FromProto(\n+      ThunkInfo thunk_info, const HostRecvThunkProto& proto,\n+      absl::Span<const BufferAllocation> allocations,\n+      HostSendRecvAsyncEventsMap& async_events_map);\n+\n   HostRecvThunk(ThunkInfo thunk_info, Shape shape,\n                 BufferAllocation::Slice buffer, int64_t channel_id,\n                 std::shared_ptr<HostSendRecvAsyncEvents> events,\n@@ -144,6 +171,8 @@ class HostRecvThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n   std::optional<AsyncEventsUniqueId> GetAsyncEventsUniqueId() const override;\n \n   bool IsAsyncStart() const override { return events_ != nullptr; }\n@@ -165,12 +194,19 @@ class HostRecvThunk : public Thunk {\n \n class HostRecvDoneThunk : public Thunk {\n  public:\n+  static absl::StatusOr<std::unique_ptr<HostRecvDoneThunk>> FromProto(\n+      ThunkInfo thunk_info, const HostRecvDoneThunkProto& proto,\n+      absl::Span<const BufferAllocation> allocations,\n+      HostSendRecvAsyncEventsMap& async_events_map);\n+\n   HostRecvDoneThunk(ThunkInfo thunk_info, int64_t channel_id,\n                     std::shared_ptr<HostSendRecvAsyncEvents> events,\n                     std::optional<GlobalDeviceId> device_constraint);\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n   std::optional<AsyncEventsUniqueId> GetAsyncEventsUniqueId() const override;\n \n   bool IsAsyncDone() const override { return events_ != nullptr; }"
        },
        {
            "sha": "c9be2a3abd8b38cb11b8234b2160c7e416bf9a59",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee",
            "patch": "@@ -135,6 +135,36 @@ message CudnnThunkProto {\n   optional int64 sdpa_dropout_seed = 3;\n }\n \n+message HostSendThunkProto {\n+  xla.ShapeProto shape = 1;\n+  xla.buffer_assignment.BufferAllocationSliceProto buffer = 2;\n+  int64 channel_id = 3;\n+  map<string, string> frontend_attrs = 4;\n+  optional int64 device_constraint = 5;\n+  uint64 async_events_unique_id = 6;\n+}\n+\n+message HostSendDoneThunkProto {\n+  int64 channel_id = 1;\n+  optional int64 device_constraint = 2;\n+  uint64 async_events_unique_id = 3;\n+}\n+\n+message HostRecvThunkProto {\n+  xla.ShapeProto shape = 1;\n+  xla.buffer_assignment.BufferAllocationSliceProto buffer = 2;\n+  int64 channel_id = 3;\n+  map<string, string> frontend_attrs = 4;\n+  optional int64 device_constraint = 5;\n+  uint64 async_events_unique_id = 6;\n+}\n+\n+message HostRecvDoneThunkProto {\n+  int64 channel_id = 1;\n+  optional int64 device_constraint = 2;\n+  uint64 async_events_unique_id = 3;\n+}\n+\n message HostExecuteStartThunkProto {\n   HostOffloadingExecutableProto executable_proto = 1;\n   repeated ShapedSliceProto args = 2;\n@@ -294,6 +324,10 @@ message ThunkProto {\n     Memset32BitValueThunkProto memset32bit_value_thunk = 28;\n     CustomCallThunkProto custom_call_thunk = 30;\n     CubSortThunkProto cub_sort_thunk = 31;\n+    HostSendThunkProto host_send_thunk = 32;\n+    HostSendDoneThunkProto host_send_done_thunk = 33;\n+    HostRecvThunkProto host_recv_thunk = 34;\n+    HostRecvDoneThunkProto host_recv_done_thunk = 35;\n   }\n }\n "
        },
        {
            "sha": "f8aa780bc4d84d2a0b1501b5bc6652da0bd61045",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 10,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc?ref=ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee",
            "patch": "@@ -40,6 +40,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/gemm_thunk.h\"\n #include \"xla/backends/gpu/runtime/gpublas_lt_matmul_thunk.h\"\n #include \"xla/backends/gpu/runtime/host_execute_thunk.h\"\n+#include \"xla/backends/gpu/runtime/host_send_recv_thunk.h\"\n #include \"xla/backends/gpu/runtime/infeed_thunk.h\"\n #include \"xla/backends/gpu/runtime/kernel_thunk.h\"\n #include \"xla/backends/gpu/runtime/memset_thunk.h\"\n@@ -82,15 +83,17 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n     const ThunkProto& thunk_proto,\n     absl::Span<const BufferAllocation> buffer_allocations,\n     const HloModule* absl_nullable hlo_module, absl::string_view platform_name,\n-    HostExecuteAsyncEventsMap& host_executable_async_events_map) {\n+    HostExecuteAsyncEventsMap& host_executable_async_events_map,\n+    HostSendRecvAsyncEventsMap& host_send_recv_async_events_map) {\n   TF_ASSIGN_OR_RETURN(Thunk::ThunkInfo thunk_info,\n                       Thunk::ThunkInfo::FromProto(thunk_proto.thunk_info()));\n   auto deserializer =\n       [&buffer_allocations, &hlo_module, &platform_name,\n-       &host_executable_async_events_map](const ThunkProto& thunk_proto) {\n-        return DeserializeThunkProtoImpl(thunk_proto, buffer_allocations,\n-                                         hlo_module, platform_name,\n-                                         host_executable_async_events_map);\n+       &host_executable_async_events_map,\n+       &host_send_recv_async_events_map](const ThunkProto& thunk_proto) {\n+        return DeserializeThunkProtoImpl(\n+            thunk_proto, buffer_allocations, hlo_module, platform_name,\n+            host_executable_async_events_map, host_send_recv_async_events_map);\n       };\n \n   switch (thunk_proto.impl_case()) {\n@@ -179,12 +182,14 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n           buffer_allocations);\n     case ThunkProto::kDynamicSliceThunk: {\n       auto deserializer =\n-          [hlo_module, platform_name, &host_executable_async_events_map](\n+          [hlo_module, platform_name, &host_executable_async_events_map,\n+           &host_send_recv_async_events_map](\n               const ThunkProto& thunk_proto,\n               absl::Span<const BufferAllocation> custom_allocations) {\n             return DeserializeThunkProtoImpl(thunk_proto, custom_allocations,\n                                              hlo_module, platform_name,\n-                                             host_executable_async_events_map);\n+                                             host_executable_async_events_map,\n+                                             host_send_recv_async_events_map);\n           };\n       return DynamicSliceThunk::FromProto(std::move(thunk_info),\n                                           thunk_proto.dynamic_slice_thunk(),\n@@ -206,6 +211,22 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n       return HostExecuteDoneThunk::FromProto(\n           std::move(thunk_info), thunk_proto.host_execute_done_thunk(),\n           buffer_allocations, host_executable_async_events_map);\n+    case ThunkProto::kHostSendThunk:\n+      return HostSendThunk::FromProto(\n+          std::move(thunk_info), thunk_proto.host_send_thunk(),\n+          buffer_allocations, host_send_recv_async_events_map);\n+    case ThunkProto::kHostSendDoneThunk:\n+      return HostSendDoneThunk::FromProto(\n+          std::move(thunk_info), thunk_proto.host_send_done_thunk(),\n+          buffer_allocations, host_send_recv_async_events_map);\n+    case ThunkProto::kHostRecvThunk:\n+      return HostRecvThunk::FromProto(\n+          std::move(thunk_info), thunk_proto.host_recv_thunk(),\n+          buffer_allocations, host_send_recv_async_events_map);\n+    case ThunkProto::kHostRecvDoneThunk:\n+      return HostRecvDoneThunk::FromProto(\n+          std::move(thunk_info), thunk_proto.host_recv_done_thunk(),\n+          buffer_allocations, host_send_recv_async_events_map);\n     case ThunkProto::kOutfeedThunk:\n       return OutfeedThunk::FromProto(std::move(thunk_info),\n                                      thunk_proto.outfeed_thunk(),\n@@ -236,9 +257,10 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProto(\n     const HloModule* absl_nullable hlo_module,\n     absl::string_view platform_name) {\n   HostExecuteAsyncEventsMap host_executable_async_events_map;\n-  return DeserializeThunkProtoImpl(thunk_proto, buffer_allocations, hlo_module,\n-                                   platform_name,\n-                                   host_executable_async_events_map);\n+  HostSendRecvAsyncEventsMap host_send_recv_async_events_map;\n+  return DeserializeThunkProtoImpl(\n+      thunk_proto, buffer_allocations, hlo_module, platform_name,\n+      host_executable_async_events_map, host_send_recv_async_events_map);\n }\n \n }  // namespace xla::gpu"
        },
        {
            "sha": "070bb7cc9d9d92e97a8a6fe416855b234b0af3f0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization_test.cc",
            "status": "modified",
            "additions": 105,
            "deletions": 0,
            "changes": 105,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc?ref=ce31fc77f9ddfe35f2d57392f9a0c337a3d0d4ee",
            "patch": "@@ -27,6 +27,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/conditional_thunk.h\"\n #include \"xla/backends/gpu/runtime/copy_thunk.h\"\n #include \"xla/backends/gpu/runtime/host_execute_thunk.h\"\n+#include \"xla/backends/gpu/runtime/host_send_recv_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n@@ -593,6 +594,110 @@ TEST(ThunkProtoDeserializationTest, EmptyThunkImplReturnsAnError) {\n               absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n+TEST(ThunkProtoDeserializationTest, HostSendRecvThunksRoundTrip) {\n+  ThunkProto proto = ParseTextProtoOrDie<ThunkProto>(\n+      R\"pb(\n+        thunk_info { execution_stream_id: 7 }\n+        sequential_thunk {\n+          thunks {\n+            thunk_info { execution_stream_id: 7 }\n+            host_send_thunk {\n+              shape {\n+                element_type: F32\n+                dimensions: [ 10 ]\n+                is_dynamic_dimension: false\n+              }\n+              buffer { buffer_allocation_index: 0 }\n+              channel_id: 123\n+              async_events_unique_id: 1\n+            }\n+          }\n+          thunks {\n+            thunk_info { execution_stream_id: 7 }\n+            host_send_done_thunk { channel_id: 123 async_events_unique_id: 1 }\n+          }\n+          thunks {\n+            thunk_info { execution_stream_id: 7 }\n+            host_recv_thunk {\n+              shape {\n+                element_type: F32\n+                dimensions: [ 10 ]\n+                is_dynamic_dimension: false\n+\n+              }\n+              buffer { buffer_allocation_index: 0 }\n+              channel_id: 456\n+              async_events_unique_id: 2\n+            }\n+          }\n+          thunks {\n+            thunk_info { execution_stream_id: 7 }\n+            host_recv_done_thunk { channel_id: 456 async_events_unique_id: 2 }\n+          }\n+        }\n+      )pb\");\n+\n+  std::vector<BufferAllocation> buffer_allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/1024, /*color=*/0)};\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<Thunk> thunk,\n+      DeserializeThunkProto(proto, buffer_allocations,\n+                            /*hlo_module=*/nullptr, kTestPlatformName));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(ThunkProto round_trip_proto, thunk->ToProto());\n+\n+  const auto* sequential_thunk = dynamic_cast<SequentialThunk*>(thunk.get());\n+  ASSERT_NE(sequential_thunk, nullptr);\n+  ASSERT_EQ(sequential_thunk->thunks().size(), 4);\n+\n+  const auto* send_thunk =\n+      dynamic_cast<HostSendThunk*>(sequential_thunk->thunks()[0].get());\n+  ASSERT_NE(send_thunk, nullptr);\n+\n+  const auto* send_done_thunk =\n+      dynamic_cast<HostSendDoneThunk*>(sequential_thunk->thunks()[1].get());\n+  ASSERT_NE(send_done_thunk, nullptr);\n+\n+  const auto* recv_thunk =\n+      dynamic_cast<HostRecvThunk*>(sequential_thunk->thunks()[2].get());\n+  ASSERT_NE(recv_thunk, nullptr);\n+\n+  const auto* recv_done_thunk =\n+      dynamic_cast<HostRecvDoneThunk*>(sequential_thunk->thunks()[3].get());\n+  ASSERT_NE(recv_done_thunk, nullptr);\n+\n+  EXPECT_TRUE(send_thunk->GetAsyncEventsUniqueId().has_value());\n+  EXPECT_TRUE(send_done_thunk->GetAsyncEventsUniqueId().has_value());\n+  EXPECT_EQ(send_thunk->GetAsyncEventsUniqueId(),\n+            send_done_thunk->GetAsyncEventsUniqueId());\n+\n+  EXPECT_TRUE(recv_thunk->GetAsyncEventsUniqueId().has_value());\n+  EXPECT_TRUE(recv_done_thunk->GetAsyncEventsUniqueId().has_value());\n+  EXPECT_EQ(recv_thunk->GetAsyncEventsUniqueId(),\n+            recv_done_thunk->GetAsyncEventsUniqueId());\n+\n+  // The unique id is regenerated on deserialization. Overwrite it with the\n+  // original value for the purpose of the roundtrip test.\n+  round_trip_proto.mutable_sequential_thunk()\n+      ->mutable_thunks(0)\n+      ->mutable_host_send_thunk()\n+      ->set_async_events_unique_id(1);\n+  round_trip_proto.mutable_sequential_thunk()\n+      ->mutable_thunks(1)\n+      ->mutable_host_send_done_thunk()\n+      ->set_async_events_unique_id(1);\n+  round_trip_proto.mutable_sequential_thunk()\n+      ->mutable_thunks(2)\n+      ->mutable_host_recv_thunk()\n+      ->set_async_events_unique_id(2);\n+  round_trip_proto.mutable_sequential_thunk()\n+      ->mutable_thunks(3)\n+      ->mutable_host_recv_done_thunk()\n+      ->set_async_events_unique_id(2);\n+  EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n+}\n+\n TEST(ThunkProtoDeserializationTest, HostExecuteThunksRoundTrip) {\n   ThunkProto proto = ParseTextProtoOrDie<ThunkProto>(\n       R\"pb("
        }
    ],
    "stats": {
        "total": 395,
        "additions": 384,
        "deletions": 11
    }
}