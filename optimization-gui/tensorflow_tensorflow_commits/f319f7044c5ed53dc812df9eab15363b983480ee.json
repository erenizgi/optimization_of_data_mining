{
    "author": "rewu93",
    "message": "Add support for kTfLiteInt4 output in the Quantize kernel.\n\nPiperOrigin-RevId: 811592774",
    "sha": "f319f7044c5ed53dc812df9eab15363b983480ee",
    "files": [
        {
            "sha": "4f4dc835c91d6ce7cfaa611f531ecdd2729ea54d",
            "filename": "tensorflow/compiler/mlir/lite/tools/versioning/runtime_version.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftools%2Fversioning%2Fruntime_version.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftools%2Fversioning%2Fruntime_version.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftools%2Fversioning%2Fruntime_version.cc?ref=f319f7044c5ed53dc812df9eab15363b983480ee",
            "patch": "@@ -365,6 +365,7 @@ std::string FindMinimumRuntimeVersionForOp(tflite::BuiltinOperator op_code,\n               {{BuiltinOperator_QUANTIZE, 1}, \"1.14.0\"},\n               {{BuiltinOperator_QUANTIZE, 2}, \"1.15.0\"},\n               {{BuiltinOperator_QUANTIZE, 3}, \"2.7.0\"},\n+              {{BuiltinOperator_QUANTIZE, 4}, \"2.21.0\"},\n               {{BuiltinOperator_ROUND, 1}, \"1.14.0\"},\n               {{BuiltinOperator_RELU, 1}, \"1.5.0\"},\n               {{BuiltinOperator_RELU, 2}, \"2.1.0\"},"
        },
        {
            "sha": "a905b09c98601ce82a82f5c9935c3f07fec3825b",
            "filename": "tensorflow/lite/core/kernels/register.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Flite%2Fcore%2Fkernels%2Fregister.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Flite%2Fcore%2Fkernels%2Fregister.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fcore%2Fkernels%2Fregister.cc?ref=f319f7044c5ed53dc812df9eab15363b983480ee",
            "patch": "@@ -309,7 +309,7 @@ BuiltinOpResolver::BuiltinOpResolver() {\n   AddBuiltin(BuiltinOperator_MATRIX_DIAG, Register_MATRIX_DIAG());\n   AddBuiltin(BuiltinOperator_QUANTIZE, Register_QUANTIZE(),\n              /* min_version = */ 1,\n-             /* max_version = */ 3);\n+             /* max_version = */ 4);\n   AddBuiltin(BuiltinOperator_MATRIX_SET_DIAG, Register_MATRIX_SET_DIAG());\n   AddBuiltin(BuiltinOperator_IF, tflite::ops::builtin::Register_IF());\n   AddBuiltin(BuiltinOperator_WHILE, tflite::ops::builtin::Register_WHILE());"
        },
        {
            "sha": "9da18896842306cbee74d46c1dfdff40eb31ecec",
            "filename": "tensorflow/lite/kernels/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Flite%2Fkernels%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Flite%2Fkernels%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fkernels%2FBUILD?ref=f319f7044c5ed53dc812df9eab15363b983480ee",
            "patch": "@@ -3021,8 +3021,10 @@ cc_test(\n     srcs = [\"quantize_test.cc\"],\n     tags = [\"tflite_nnapi\"],\n     deps = [\n+        \":kernel_util\",\n         \":test_main\",\n         \":test_util\",\n+        \"//tensorflow/lite/kernels/internal:tensor_utils\",\n         \"//tensorflow/lite/kernels/internal:types\",\n         \"//tensorflow/lite/schema:schema_fbs\",\n         \"@com_google_googletest//:gtest\","
        },
        {
            "sha": "7e451a3be99b0e66d563b4e8959b45b923e8a64d",
            "filename": "tensorflow/lite/kernels/quantize.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 1,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Flite%2Fkernels%2Fquantize.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Flite%2Fkernels%2Fquantize.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fkernels%2Fquantize.cc?ref=f319f7044c5ed53dc812df9eab15363b983480ee",
            "patch": "@@ -25,6 +25,7 @@ limitations under the License.\n #include \"tensorflow/lite/kernels/internal/reference/requantize.h\"\n #include \"tensorflow/lite/kernels/internal/tensor.h\"\n #include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n+#include \"tensorflow/lite/kernels/internal/tensor_utils.h\"\n #include \"tensorflow/lite/kernels/internal/types.h\"\n #include \"tensorflow/lite/kernels/kernel_util.h\"\n \n@@ -87,6 +88,31 @@ static inline void Requantize(const input_type* input_data, int32_t size,\n   }\n }\n \n+void AffineQuantizeToInt4(const tflite::QuantizationParams& op_params,\n+                          const RuntimeShape& input_shape,\n+                          const float* input_data,\n+                          const RuntimeShape& output_shape,\n+                          int8_t* output_data) {\n+  const int32_t zero_point = op_params.zero_point;\n+  const double scale = op_params.scale;\n+  const int flat_size = MatchingFlatSize(input_shape, output_shape);\n+  // Signed int4 has range [-8, 7]. Narrow range ([-7, 7]) is not needed here\n+  // since we will unpack int4 to int8 for computation\n+  constexpr int32_t min_val = -8;\n+  constexpr int32_t max_val = 7;\n+  std::vector<int8_t> quantized_buffer(flat_size);\n+  for (int i = 0; i < flat_size; i++) {\n+    const float val = input_data[i];\n+    int32_t unclamped =\n+        static_cast<int32_t>(TfLiteRound(val / static_cast<float>(scale))) +\n+        zero_point;\n+    int32_t clamped = std::min(std::max(unclamped, min_val), max_val);\n+    quantized_buffer[i] = clamped;\n+  }\n+  tensor_utils::PackInt8IntoDenseInt4(quantized_buffer.data(), flat_size,\n+                                      output_data);\n+}\n+\n void ReportError(TfLiteContext* context, TfLiteType input_type,\n                  TfLiteType output_type) {\n   TF_LITE_KERNEL_LOG(\n@@ -121,7 +147,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Quantize use case.\n     TF_LITE_ENSURE(context, output->type == kTfLiteUInt8 ||\n                                 output->type == kTfLiteInt8 ||\n-                                output->type == kTfLiteInt16);\n+                                output->type == kTfLiteInt16 ||\n+                                output->type == kTfLiteInt4);\n   } else {\n     // Requantize use case.\n     if (input->type == kTfLiteInt16) {\n@@ -217,6 +244,11 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n         op_params.scale = output->params.scale;\n \n         switch (output->type) {\n+          case kTfLiteInt4: {\n+            AffineQuantizeToInt4(op_params, input_shape, input_data,\n+                                 output_shape, GetTensorData<int8_t>(output));\n+            return kTfLiteOk;\n+          }\n           case kTfLiteInt8:\n             AffineQuantize<kernel_type>(op_params, input_shape, input_data,\n                                         output_shape,"
        },
        {
            "sha": "ff629a28b2826008db9daa9d2787e7fbff6fa692",
            "filename": "tensorflow/lite/kernels/quantize_test.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 0,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Flite%2Fkernels%2Fquantize_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Flite%2Fkernels%2Fquantize_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fkernels%2Fquantize_test.cc?ref=f319f7044c5ed53dc812df9eab15363b983480ee",
            "patch": "@@ -19,7 +19,9 @@ limitations under the License.\n \n #include <gtest/gtest.h>\n #include \"flatbuffers/flatbuffers.h\"  // from @flatbuffers\n+#include \"tensorflow/lite/kernels/internal/tensor_utils.h\"\n #include \"tensorflow/lite/kernels/internal/types.h\"\n+#include \"tensorflow/lite/kernels/kernel_util.h\"\n #include \"tensorflow/lite/kernels/test_util.h\"\n #include \"tensorflow/lite/schema/schema_generated.h\"\n \n@@ -55,6 +57,15 @@ class QuantizeOpModel : public SingleOpModel {\n     return ExtractVector<T>(output_);\n   }\n \n+  std::vector<int8_t> GetOutputUnpackedInt4() {\n+    TfLiteTensor* t = interpreter_->tensor(output_);\n+    int num_elements = NumElements(t);\n+    std::vector<int8_t> unpacked_output(num_elements);\n+    tensor_utils::UnpackDenseInt4IntoInt8(t->data.int8, num_elements,\n+                                          unpacked_output.data());\n+    return unpacked_output;\n+  }\n+\n  protected:\n   int input_;\n   int output_;\n@@ -123,6 +134,17 @@ TEST(QuantizeOpTest, INT16) {\n               ElementsAreArray({-12700, -12600, -600, -400, -200, 200, 400, 600,\n                                 12700, 12800}));\n }\n+TEST(QuantizeOpTest, INT4) {\n+  // [-3.5, 4] -> scale=0.5, zero_point=0 for INT4\n+  QuantizeOpModel m({TensorType_FLOAT32, {2, 5}},\n+                    {TensorType_INT4, {2, 5}, 0, 0, 0.5, 0});\n+\n+  m.SetInput({-4.5, -3, -2.5, -2, -1.5, 2, 2.5, 3, 3.5, 4});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  // Range of int4 is [-8, 7]. Values over the range are clamped to the range.\n+  EXPECT_THAT(m.GetOutputUnpackedInt4(),\n+              ElementsAreArray({-8, -6, -5, -4, -3, 4, 5, 6, 7, 7}));\n+}\n \n // Per-channel quantization tests.\n "
        },
        {
            "sha": "9118ddd43f74861837215c16c8429d4289a86845",
            "filename": "tensorflow/lite/kernels/register_ref.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Flite%2Fkernels%2Fregister_ref.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f319f7044c5ed53dc812df9eab15363b983480ee/tensorflow%2Flite%2Fkernels%2Fregister_ref.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fkernels%2Fregister_ref.cc?ref=f319f7044c5ed53dc812df9eab15363b983480ee",
            "patch": "@@ -506,7 +506,7 @@ BuiltinRefOpResolver::BuiltinRefOpResolver() {\n   AddBuiltin(BuiltinOperator_MATRIX_DIAG, Register_MATRIX_DIAG());\n   AddBuiltin(BuiltinOperator_QUANTIZE, Register_QUANTIZE_REF(),\n              /* min_version = */ 1,\n-             /* max_version = */ 3);\n+             /* max_version = */ 4);\n   AddBuiltin(BuiltinOperator_MATRIX_SET_DIAG, Register_MATRIX_SET_DIAG());\n   AddBuiltin(BuiltinOperator_IF, Register_IF());\n   AddBuiltin(BuiltinOperator_WHILE, Register_WHILE());"
        }
    ],
    "stats": {
        "total": 63,
        "additions": 60,
        "deletions": 3
    }
}