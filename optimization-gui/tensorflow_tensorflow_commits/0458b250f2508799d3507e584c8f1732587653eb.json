{
    "author": "tensorflower-gardener",
    "message": "Remove no-op flag xla_gpu_enable_triton_hopper\n\nPiperOrigin-RevId: 810897863",
    "sha": "0458b250f2508799d3507e584c8f1732587653eb",
    "files": [
        {
            "sha": "1fb996ae88dcb4ab3564fd6e931af5877cb52eb7",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0458b250f2508799d3507e584c8f1732587653eb/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0458b250f2508799d3507e584c8f1732587653eb/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=0458b250f2508799d3507e584c8f1732587653eb",
            "patch": "@@ -362,7 +362,6 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n   opts.set_xla_gpu_threshold_for_windowed_einsum_mib(100000);\n   opts.set_xla_gpu_operand_bytes_threshold_for_windowed_einsum(-1);\n \n-  opts.set_xla_gpu_enable_triton_hopper(false);\n   opts.set_xla_gpu_experimental_enable_fusion_block_level_rewriter(false);\n \n   opts.set_xla_gpu_enable_llvm_module_compilation_parallelism(false);\n@@ -2112,11 +2111,6 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n       \"If set >= 0, xla_gpu_threshold_for_windowed_einsum_mib is ignored.\"\n       \"Default is -1\"));\n \n-  flag_list->push_back(tsl::Flag(\n-      \"xla_gpu_enable_triton_hopper\",\n-      bool_setter_for(&DebugOptions::set_xla_gpu_enable_triton_hopper),\n-      debug_options->xla_gpu_enable_triton_hopper(),\n-      \"Currently used to enable MMA_V3 for Hopper in Triton\"));\n   flag_list->push_back(tsl::Flag(\n       \"xla_gpu_experimental_enable_fusion_block_level_rewriter\",\n       bool_setter_for("
        },
        {
            "sha": "8d240a65aefcec1fb4e361cf88025a94f10680b6",
            "filename": "third_party/xla/xla/xla.proto",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0458b250f2508799d3507e584c8f1732587653eb/third_party%2Fxla%2Fxla%2Fxla.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0458b250f2508799d3507e584c8f1732587653eb/third_party%2Fxla%2Fxla%2Fxla.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fxla.proto?ref=0458b250f2508799d3507e584c8f1732587653eb",
            "patch": "@@ -549,9 +549,6 @@ message DebugOptions {\n \n   optional bool xla_gpu_enable_triton_gemm = 188;\n \n-  // Enables currently disabled features within Triton for Hopper.\n-  optional bool xla_gpu_enable_triton_hopper = 266;\n-\n   // Enable double buffering for loops.\n   optional bool xla_gpu_enable_while_loop_double_buffering = 248;\n \n@@ -916,6 +913,7 @@ message DebugOptions {\n   // go/keep-sorted end\n \n   reserved 167;  // xla_gpu_redzone_scratch_max_megabytes\n+  reserved 266;  // xla_gpu_enable_triton_hopper\n   reserved 276;  // xla_gpu_enable_nccl_per_stream_comms\n   reserved 226;  // xla_gpu_triton_gemm_disable_reduced_precision_reduction\n   reserved 385;  // xla_gpu_experimental_enable_dynamic_dot_search_space"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 1,
        "deletions": 9
    }
}