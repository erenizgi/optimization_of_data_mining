{
    "author": "basioli-k",
    "message": "[XLA][host offloading] Add API for loading HostOffloadingNanortExecutable from HostOffloadingExecutableProto.\n\nPiperOrigin-RevId: 811710723",
    "sha": "07be026cd7a13c2026a2ce6c983b70d8b38bf347",
    "files": [
        {
            "sha": "7b3deaeac71ae88d9bead813b02e381106647296",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=07be026cd7a13c2026a2ce6c983b70d8b38bf347",
            "patch": "@@ -2445,6 +2445,7 @@ cc_library(\n         \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/memory\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:str_format\",\n@@ -2468,11 +2469,16 @@ xla_test(\n         \"//xla:shape_util\",\n         \"//xla:util\",\n         \"//xla/backends/cpu:alignment\",\n+        \"//xla/backends/cpu/nanort:nanort_client\",\n+        \"//xla/backends/cpu/nanort:nanort_executable\",\n         \"//xla/core/host_offloading:host_offloading_executable\",\n+        \"//xla/hlo/builder:xla_computation\",\n         \"//xla/hlo/parser:hlo_parser\",\n         \"//xla/service:buffer_assignment\",\n+        \"//xla/service:compiler\",\n         \"//xla/service:executable\",\n         \"//xla/service:platform_util\",\n+        \"//xla/service/cpu:cpu_aot_compilation_result\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:platform_manager\",\n@@ -2483,9 +2489,12 @@ xla_test(\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_googletest//:gtest_main\",\n+        \"@local_tsl//tsl/platform:casts\",\n     ],\n )\n "
        },
        {
            "sha": "944700effd333a3630f4f93aa7e0471f46794a9c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_execute_thunk.cc",
            "status": "modified",
            "additions": 50,
            "deletions": 5,
            "changes": 55,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc?ref=07be026cd7a13c2026a2ce6c983b70d8b38bf347",
            "patch": "@@ -28,6 +28,7 @@ limitations under the License.\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n+#include \"absl/memory/memory.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_format.h\"\n@@ -354,6 +355,37 @@ HostExecuteAsyncEvents::ExtractEvent(se::StreamExecutor* executor,\n \n // HostExecuteStartThunk\n \n+absl::StatusOr<std::unique_ptr<HostExecuteStartThunk>>\n+HostExecuteStartThunk::Create(\n+    Thunk::ThunkInfo thunk_info,\n+    const HostOffloadingExecutableProto& host_offloading_executable_proto,\n+    absl::InlinedVector<HostExecuteStartThunk::SliceAndShape, 4> args,\n+    absl::InlinedVector<HostExecuteStartThunk::SliceAndShape, 4> results) {\n+  auto thunk = absl::WrapUnique(new HostExecuteStartThunk(\n+      std::move(thunk_info), host_offloading_executable_proto, std::move(args),\n+      std::move(results)));\n+  if (host_offloading_executable_proto.has_aot_compilation_result()) {\n+    TF_RETURN_IF_ERROR(thunk->LoadExecutable());\n+  }\n+  return thunk;\n+}\n+\n+absl::Status HostExecuteStartThunk::LoadExecutable() {\n+  if (executable_ != nullptr) {\n+    return Internal(\"Host offloading executable was already loaded.\");\n+  }\n+  if (!executable_proto_.has_aot_compilation_result()) {\n+    return Internal(\n+        \"Host offloading executable proto does not have aot \"\n+        \"compilation result.\");\n+  }\n+\n+  TF_ASSIGN_OR_RETURN(\n+      executable_,\n+      HostOffloadingNanoRtExecutable::LoadFromProto(executable_proto_));\n+  return absl::OkStatus();\n+}\n+\n HostExecuteStartThunk::HostExecuteStartThunk(\n     Thunk::ThunkInfo thunk_info, const HloModule& hlo_module,\n     absl::InlinedVector<HostExecuteStartThunk::SliceAndShape, 4> args,\n@@ -369,6 +401,17 @@ HostExecuteStartThunk::HostExecuteStartThunk(\n   executable_proto_ = std::move(host_offloading_executable_proto);\n }\n \n+HostExecuteStartThunk::HostExecuteStartThunk(\n+    Thunk::ThunkInfo thunk_info,\n+    const HostOffloadingExecutableProto& host_offloading_executable_proto,\n+    absl::InlinedVector<HostExecuteStartThunk::SliceAndShape, 4> args,\n+    absl::InlinedVector<HostExecuteStartThunk::SliceAndShape, 4> results)\n+    : Thunk(Thunk::Kind::kHostExecuteStart, std::move(thunk_info)),\n+      args_(std::move(args)),\n+      results_(std::move(results)),\n+      executable_proto_(host_offloading_executable_proto),\n+      async_events_(std::make_shared<HostExecuteAsyncEvents>()) {}\n+\n std::string HostExecuteStartThunk::ToString(int indent) const { return \"\"; }\n \n absl::StatusOr<ThunkProto> HostExecuteStartThunk::ToProto() const {\n@@ -397,11 +440,13 @@ absl::Status HostExecuteStartThunk::Initialize(const InitializeParams& params) {\n   // when locking llvm command line options.\n   absl::Status initialization_status = absl::OkStatus();\n   absl::call_once(executable_init_flag_, [this, &initialization_status]() {\n-    auto executable_or_status =\n-        HostOffloadingNanoRtExecutable::LoadFromProto(executable_proto_);\n-    initialization_status = executable_or_status.status();\n-    if (initialization_status.ok()) {\n-      executable_ = std::move(executable_or_status.value());\n+    if (executable_ == nullptr) {\n+      auto executable_or_status =\n+          HostOffloadingNanoRtExecutable::LoadFromProto(executable_proto_);\n+      initialization_status = executable_or_status.status();\n+      if (initialization_status.ok()) {\n+        executable_ = std::move(executable_or_status.value());\n+      }\n     }\n   });\n "
        },
        {
            "sha": "4771fad13cc8901721bcf94abe71680b830826ed",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_execute_thunk.h",
            "status": "modified",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.h?ref=07be026cd7a13c2026a2ce6c983b70d8b38bf347",
            "patch": "@@ -81,6 +81,13 @@ class HostExecuteStartThunk : public Thunk {\n                         const HloModule& hlo_module,\n                         absl::InlinedVector<SliceAndShape, 4> args,\n                         absl::InlinedVector<SliceAndShape, 4> results);\n+\n+  static absl::StatusOr<std::unique_ptr<HostExecuteStartThunk>> Create(\n+      Thunk::ThunkInfo thunk_info,\n+      const HostOffloadingExecutableProto& host_offloading_executable_proto,\n+      absl::InlinedVector<SliceAndShape, 4> args,\n+      absl::InlinedVector<SliceAndShape, 4> results);\n+\n   HostExecuteStartThunk(const HostExecuteStartThunk&) = delete;\n   HostExecuteStartThunk& operator=(const HostExecuteStartThunk&) = delete;\n   ~HostExecuteStartThunk() override = default;\n@@ -101,6 +108,23 @@ class HostExecuteStartThunk : public Thunk {\n     return async_events_;\n   }\n \n+  absl::Status LoadExecutable();\n+\n+  const HostOffloadingExecutableProto& executable_proto() const {\n+    return executable_proto_;\n+  }\n+\n+  HostOffloadingExecutableProto* mutable_executable_proto() {\n+    return &executable_proto_;\n+  }\n+\n+ protected:\n+  HostExecuteStartThunk(\n+      Thunk::ThunkInfo thunk_info,\n+      const HostOffloadingExecutableProto& host_offloading_executable_proto,\n+      absl::InlinedVector<SliceAndShape, 4> args,\n+      absl::InlinedVector<SliceAndShape, 4> results);\n+\n  private:\n   absl::once_flag executable_init_flag_;\n   std::unique_ptr<HostOffloadingExecutable> executable_;"
        },
        {
            "sha": "30ea8468eb2ecb9d5bc35d150a109355e9a6616a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_execute_thunk_test.cc",
            "status": "modified",
            "additions": 78,
            "deletions": 28,
            "changes": 106,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk_test.cc?ref=07be026cd7a13c2026a2ce6c983b70d8b38bf347",
            "patch": "@@ -22,16 +22,23 @@ limitations under the License.\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n+#include \"absl/container/inlined_vector.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n #include \"absl/strings/ascii.h\"\n #include \"xla/backends/cpu/alignment.h\"\n+#include \"xla/backends/cpu/nanort/nanort_client.h\"\n+#include \"xla/backends/cpu/nanort/nanort_executable.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/core/host_offloading/host_offloading_executable.h\"\n #include \"xla/executable_run_options.h\"\n+#include \"xla/hlo/builder/xla_computation.h\"\n #include \"xla/hlo/parser/hlo_parser.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n #include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/compiler.h\"\n+#include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/platform_util.h\"\n #include \"xla/service/service_executable_run_options.h\"\n@@ -46,6 +53,7 @@ limitations under the License.\n #include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n+#include \"tsl/platform/casts.h\"\n \n namespace xla {\n namespace gpu {\n@@ -58,6 +66,38 @@ se::StreamExecutor* GpuExecutor() {\n   return platform->ExecutorForDevice(0).value();\n }\n \n+absl::StatusOr<std::unique_ptr<HostExecuteStartThunk>>\n+CreateHostExecuteStartThunk(\n+    Thunk::ThunkInfo thunk_info, const HloModule& hlo_module,\n+    absl::InlinedVector<HostExecuteStartThunk::SliceAndShape, 4> args,\n+    absl::InlinedVector<HostExecuteStartThunk::SliceAndShape, 4> results) {\n+  HostOffloadingExecutableProto host_offloading_executable_proto;\n+  *host_offloading_executable_proto.mutable_hlo_module() = hlo_module.ToProto();\n+  host_offloading_executable_proto.set_executable_type(\n+      HostOffloadingExecutableProto::EXECUTABLE_TYPE_NANORT);\n+\n+  xla::cpu::NanoRtClient client;\n+  XlaComputation host_computation(\n+      *host_offloading_executable_proto.mutable_hlo_module());\n+\n+  TF_ASSIGN_OR_RETURN(std::unique_ptr<xla::cpu::NanoRtExecutable> executable,\n+                      client.Compile(host_computation));\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<AotCompilationResult> aot_compilation_result,\n+      client.Export(executable.get()));\n+\n+  xla::cpu::CpuAotCompilationResult* cpu_aot_compilation_result =\n+      tsl::down_cast<xla::cpu::CpuAotCompilationResult*>(\n+          aot_compilation_result.get());\n+\n+  *host_offloading_executable_proto.mutable_aot_compilation_result() =\n+      cpu_aot_compilation_result->proto();\n+\n+  return HostExecuteStartThunk::Create(\n+      std::move(thunk_info), std::move(host_offloading_executable_proto),\n+      std::move(args), std::move(results));\n+}\n+\n TEST(HostExecuteStartThunkTest, SingleArgSingleResult) {\n   se::StreamExecutor* stream_executor = GpuExecutor();\n   TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_executor->CreateStream());\n@@ -86,9 +126,11 @@ TEST(HostExecuteStartThunkTest, SingleArgSingleResult) {\n   BufferAllocation::Slice slice_arg(&alloc_arg, 0, 4);\n   BufferAllocation::Slice slice_result(&alloc_result, 0, 4);\n \n-  HostExecuteStartThunk thunk(Thunk::ThunkInfo(), *hlo_module,\n+  TF_ASSERT_OK_AND_ASSIGN(auto thunk,\n+                          CreateHostExecuteStartThunk(\n+                              Thunk::ThunkInfo(), *hlo_module,\n                               {{slice_arg, ShapeUtil::MakeShape(S32, {})}},\n-                              {{slice_result, ShapeUtil::MakeShape(S32, {})}});\n+                              {{slice_result, ShapeUtil::MakeShape(S32, {})}}));\n \n   se::StreamExecutorMemoryAllocator allocator(stream_executor);\n   ExecutableRunOptions executable_run_options;\n@@ -104,11 +146,11 @@ TEST(HostExecuteStartThunkTest, SingleArgSingleResult) {\n       nullptr, nullptr);\n \n   TF_ASSERT_OK(\n-      thunk.Initialize(Thunk::InitializeParams{/*executor=*/stream_executor}));\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+      thunk->Initialize(Thunk::InitializeParams{/*executor=*/stream_executor}));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto execute_event,\n-                          thunk.async_events()->ExtractEvent(\n+                          thunk->async_events()->ExtractEvent(\n                               stream_executor, RunId(params.execution_id)));\n \n   tsl::BlockUntilReady(execute_event);\n@@ -162,11 +204,13 @@ TEST(HostExecuteStartThunkTest, MultiArgMultipleResult) {\n   BufferAllocation::Slice slice_arg1(&alloc_arg1, 0, 4);\n   BufferAllocation::Slice slice_result1(&alloc_result1, 0, 4);\n \n-  HostExecuteStartThunk thunk(Thunk::ThunkInfo(), *hlo_module,\n-                              {{slice_arg0, ShapeUtil::MakeShape(S32, {})},\n-                               {slice_arg1, ShapeUtil::MakeShape(S32, {})}},\n-                              {{slice_result0, ShapeUtil::MakeShape(S32, {})},\n-                               {slice_result1, ShapeUtil::MakeShape(S32, {})}});\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto thunk, CreateHostExecuteStartThunk(\n+                      Thunk::ThunkInfo(), *hlo_module,\n+                      {{slice_arg0, ShapeUtil::MakeShape(S32, {})},\n+                       {slice_arg1, ShapeUtil::MakeShape(S32, {})}},\n+                      {{slice_result0, ShapeUtil::MakeShape(S32, {})},\n+                       {slice_result1, ShapeUtil::MakeShape(S32, {})}}));\n \n   se::StreamExecutorMemoryAllocator allocator(stream_executor);\n   ExecutableRunOptions executable_run_options;\n@@ -181,11 +225,11 @@ TEST(HostExecuteStartThunkTest, MultiArgMultipleResult) {\n       nullptr, nullptr);\n \n   TF_ASSERT_OK(\n-      thunk.Initialize(Thunk::InitializeParams{/*executor=*/stream_executor}));\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+      thunk->Initialize(Thunk::InitializeParams{/*executor=*/stream_executor}));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto execute_event,\n-                          thunk.async_events()->ExtractEvent(\n+                          thunk->async_events()->ExtractEvent(\n                               stream_executor, RunId(params.execution_id)));\n \n   tsl::BlockUntilReady(execute_event);\n@@ -244,9 +288,11 @@ TEST(HostExecuteStartThunkTest, ArgAndResultPinnedOnHost) {\n   BufferAllocation::Slice slice_arg(&alloc_arg, 0, 4);\n   BufferAllocation::Slice slice_result(&alloc_result, 0, 4);\n \n-  HostExecuteStartThunk thunk(Thunk::ThunkInfo(), *hlo_module,\n+  TF_ASSERT_OK_AND_ASSIGN(auto thunk,\n+                          CreateHostExecuteStartThunk(\n+                              Thunk::ThunkInfo(), *hlo_module,\n                               {{slice_arg, ShapeUtil::MakeShape(S32, {})}},\n-                              {{slice_result, ShapeUtil::MakeShape(S32, {})}});\n+                              {{slice_result, ShapeUtil::MakeShape(S32, {})}}));\n \n   se::StreamExecutorMemoryAllocator allocator(stream_executor);\n   ExecutableRunOptions executable_run_options;\n@@ -261,11 +307,11 @@ TEST(HostExecuteStartThunkTest, ArgAndResultPinnedOnHost) {\n       nullptr, nullptr);\n \n   TF_ASSERT_OK(\n-      thunk.Initialize(Thunk::InitializeParams{/*executor=*/stream_executor}));\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+      thunk->Initialize(Thunk::InitializeParams{/*executor=*/stream_executor}));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto execute_event,\n-                          thunk.async_events()->ExtractEvent(\n+                          thunk->async_events()->ExtractEvent(\n                               stream_executor, RunId(params.execution_id)));\n   tsl::BlockUntilReady(execute_event);\n   EXPECT_FALSE(execute_event.IsError());\n@@ -303,9 +349,11 @@ TEST(HostExecuteStartThunkTest, ArgAndResultNonRegisteredHostMemory) {\n   BufferAllocation::Slice slice_arg(&alloc_arg, 0, 4);\n   BufferAllocation::Slice slice_result(&alloc_result, 0, 4);\n \n-  HostExecuteStartThunk thunk(Thunk::ThunkInfo(), *hlo_module,\n+  TF_ASSERT_OK_AND_ASSIGN(auto thunk,\n+                          CreateHostExecuteStartThunk(\n+                              Thunk::ThunkInfo(), *hlo_module,\n                               {{slice_arg, ShapeUtil::MakeShape(S32, {})}},\n-                              {{slice_result, ShapeUtil::MakeShape(S32, {})}});\n+                              {{slice_result, ShapeUtil::MakeShape(S32, {})}}));\n \n   se::StreamExecutorMemoryAllocator allocator(stream_executor);\n   ExecutableRunOptions executable_run_options;\n@@ -320,11 +368,11 @@ TEST(HostExecuteStartThunkTest, ArgAndResultNonRegisteredHostMemory) {\n       nullptr, nullptr);\n \n   TF_ASSERT_OK(\n-      thunk.Initialize(Thunk::InitializeParams{/*executor=*/stream_executor}));\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+      thunk->Initialize(Thunk::InitializeParams{/*executor=*/stream_executor}));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto execute_event,\n-                          thunk.async_events()->ExtractEvent(\n+                          thunk->async_events()->ExtractEvent(\n                               stream_executor, RunId(params.execution_id)));\n   tsl::BlockUntilReady(execute_event);\n   EXPECT_FALSE(execute_event.IsError());\n@@ -370,9 +418,11 @@ TEST(HostExecuteStartThunkTest, TestErrorPropagationFromExecuteEvent) {\n   BufferAllocation::Slice slice_arg(&alloc_arg, 0, 4);\n   BufferAllocation::Slice slice_result(&alloc_result, 0, 4);\n \n-  HostExecuteStartThunk thunk(Thunk::ThunkInfo(), *hlo_module,\n+  TF_ASSERT_OK_AND_ASSIGN(auto thunk,\n+                          CreateHostExecuteStartThunk(\n+                              Thunk::ThunkInfo(), *hlo_module,\n                               {{slice_arg, ShapeUtil::MakeShape(S32, {})}},\n-                              {{slice_result, ShapeUtil::MakeShape(S32, {})}});\n+                              {{slice_result, ShapeUtil::MakeShape(S32, {})}}));\n \n   se::StreamExecutorMemoryAllocator allocator(stream_executor);\n   ExecutableRunOptions executable_run_options;\n@@ -387,11 +437,11 @@ TEST(HostExecuteStartThunkTest, TestErrorPropagationFromExecuteEvent) {\n       nullptr, nullptr);\n \n   TF_ASSERT_OK(\n-      thunk.Initialize(Thunk::InitializeParams{/*executor=*/stream_executor}));\n-  TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n+      thunk->Initialize(Thunk::InitializeParams{/*executor=*/stream_executor}));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto execute_event,\n-                          thunk.async_events()->ExtractEvent(\n+                          thunk->async_events()->ExtractEvent(\n                               stream_executor, RunId(params.execution_id)));\n   tsl::BlockUntilReady(execute_event);\n   EXPECT_TRUE(execute_event.IsError());"
        },
        {
            "sha": "2a6734b47792f3de9e2a80869b80b7271e1f1f0d",
            "filename": "third_party/xla/xla/core/host_offloading/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2FBUILD?ref=07be026cd7a13c2026a2ce6c983b70d8b38bf347",
            "patch": "@@ -118,7 +118,10 @@ tf_proto_library(\n     name = \"host_offloading_executable_proto\",\n     srcs = [\"host_offloading_executable.proto\"],\n     compatible_with = get_compatible_with_libtpu_portable(),\n-    deps = [\"//xla/service:hlo_proto\"],\n+    deps = [\n+        \"//xla/service:hlo_proto\",\n+        \"//xla/service/cpu:executable_proto\",\n+    ],\n )\n \n cc_library(\n@@ -238,11 +241,14 @@ strict_cc_test(\n         \"//xla:literal_util\",\n         \"//xla:shape_tree\",\n         \"//xla:shape_util\",\n+        \"//xla/backends/cpu/nanort:nanort_client\",\n         \"//xla/backends/cpu/nanort:nanort_executable\",\n         \"//xla/ffi\",\n         \"//xla/ffi:ffi_api\",\n+        \"//xla/hlo/builder:xla_computation\",\n         \"//xla/hlo/parser:hlo_parser\",\n         \"//xla/service:hlo_module_config\",\n+        \"//xla/service/cpu:cpu_aot_compilation_result\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:statusor\",\n@@ -252,7 +258,6 @@ strict_cc_test(\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n-        \"@com_google_absl//absl/synchronization\",\n         \"@com_google_absl//absl/types:span\",\n         \"@com_google_googletest//:gtest\",\n         \"@local_tsl//tsl/platform:casts\","
        },
        {
            "sha": "f8af50e69bffa8fc1c9920879c59844fbbf70cd9",
            "filename": "third_party/xla/xla/core/host_offloading/host_offloading_executable.proto",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhost_offloading_executable.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhost_offloading_executable.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhost_offloading_executable.proto?ref=07be026cd7a13c2026a2ce6c983b70d8b38bf347",
            "patch": "@@ -17,6 +17,7 @@ syntax = \"proto3\";\n \n package xla;\n \n+import \"xla/service/cpu/executable.proto\";\n import \"xla/service/hlo.proto\";\n \n message HostOffloadingExecutableProto {\n@@ -28,4 +29,6 @@ message HostOffloadingExecutableProto {\n \n   HloModuleProto hlo_module = 1;\n   ExecutableType executable_type = 2;\n+  // Only used for NanoRt executables.\n+  optional xla.cpu.CompilationResultProto aot_compilation_result = 3;\n }"
        },
        {
            "sha": "5adc718780b43838232b12fc69fde4133f63c803",
            "filename": "third_party/xla/xla/core/host_offloading/host_offloading_executable_test.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 1,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhost_offloading_executable_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhost_offloading_executable_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhost_offloading_executable_test.cc?ref=07be026cd7a13c2026a2ce6c983b70d8b38bf347",
            "patch": "@@ -27,16 +27,19 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/backends/cpu/nanort/nanort_client.h\"\n #include \"xla/backends/cpu/nanort/nanort_executable.h\"\n #include \"xla/core/host_offloading/host_offloading_buffer.h\"\n #include \"xla/core/host_offloading/host_offloading_executable.pb.h\"\n #include \"xla/core/host_offloading/host_offloading_nanort_executable.h\"\n #include \"xla/core/host_offloading/host_offloading_pjrt_executable.h\"\n #include \"xla/ffi/ffi.h\"\n #include \"xla/ffi/ffi_api.h\"\n+#include \"xla/hlo/builder/xla_computation.h\"\n #include \"xla/hlo/parser/hlo_parser.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n+#include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_tree.h\"\n@@ -61,8 +64,22 @@ absl::StatusOr<std::unique_ptr<HostOffloadingExecutable>> CompileFromString(\n   executable_proto.set_executable_type(executable_type);\n \n   switch (executable_type) {\n-    case HostOffloadingExecutableProto::EXECUTABLE_TYPE_NANORT:\n+    case HostOffloadingExecutableProto::EXECUTABLE_TYPE_NANORT: {\n+      xla::cpu::NanoRtClient client;\n+      XlaComputation computation(module->ToProto());\n+      TF_ASSIGN_OR_RETURN(auto executable, client.Compile(computation));\n+      TF_ASSIGN_OR_RETURN(auto aot_compilation_result,\n+                          client.Export(executable.get()));\n+\n+      xla::cpu::CpuAotCompilationResult* cpu_aot_compilation_result =\n+          tsl::down_cast<xla::cpu::CpuAotCompilationResult*>(\n+              aot_compilation_result.get());\n+\n+      *executable_proto.mutable_aot_compilation_result() =\n+          cpu_aot_compilation_result->proto();\n       return HostOffloadingNanoRtExecutable::LoadFromProto(executable_proto);\n+    }\n+\n     case HostOffloadingExecutableProto::EXECUTABLE_TYPE_PJRT:\n       return HostOffloadingPjRtExecutable::LoadFromProto(executable_proto);\n     default:"
        },
        {
            "sha": "ebfe4489505a2c2099759efcc7181221af2c6ef8",
            "filename": "third_party/xla/xla/core/host_offloading/host_offloading_nanort_executable.cc",
            "status": "modified",
            "additions": 35,
            "deletions": 28,
            "changes": 63,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhost_offloading_nanort_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhost_offloading_nanort_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcore%2Fhost_offloading%2Fhost_offloading_nanort_executable.cc?ref=07be026cd7a13c2026a2ce6c983b70d8b38bf347",
            "patch": "@@ -142,42 +142,49 @@ HostOffloadingNanoRtExecutable::LoadFromProto(\n   TF_RET_CHECK(proto.executable_type() ==\n                HostOffloadingExecutableProto::EXECUTABLE_TYPE_NANORT);\n \n+  auto& hlo_module_proto = proto.hlo_module();\n+\n   VLOG(3) << \"Load NanoRt host offloading executable: name=\"\n-          << proto.hlo_module().name();\n+          << hlo_module_proto.name();\n \n   TraceMe trace([&] {\n     return TraceMeEncode(\"HostOffloadingNanoRtExecutable::LoadFromProto\",\n-                         {{\"name\", proto.hlo_module().name()}});\n+                         {{\"name\", hlo_module_proto.name()}});\n   });\n \n   // We keep program shape and alias config of the original HLO module and not\n   // the destination-passing-style module with extra output parameters.\n-  TF_ASSIGN_OR_RETURN(\n-      ProgramShape program_shape,\n-      ProgramShape::FromProto(proto.hlo_module().host_program_shape()));\n-  TF_ASSIGN_OR_RETURN(\n-      auto alias_config,\n-      HloInputOutputAliasConfig::CreateFromProto(\n-          program_shape.result(), proto.hlo_module().input_output_alias()));\n-\n-  TF_ASSIGN_OR_RETURN(std::unique_ptr<HloModule> hlo_module,\n-                      HloModule::CreateFromProto(\n-                          proto.hlo_module(), HloModuleConfig(program_shape)));\n-\n-  XlaComputation computation;\n-  computation = XlaComputation(proto.hlo_module());\n-\n-  TF_ASSIGN_OR_RETURN(\n-      bool needs_layout_conversion,\n-      HostOffloadingLayoutAnalysis::NeedsLayoutConversion(hlo_module.get()));\n-\n-  TF_ASSIGN_OR_RETURN(xla::cpu::NanoRtClient * client,\n-                      GetHostOffloadingNanoRtClient());\n+  TF_ASSIGN_OR_RETURN(ProgramShape program_shape,\n+                      ProgramShape::FromProto(proto.aot_compilation_result()\n+                                                  .hlo_module()\n+                                                  .hlo_module()\n+                                                  .host_program_shape()));\n+\n+  TF_ASSIGN_OR_RETURN(auto alias_config,\n+                      HloInputOutputAliasConfig::CreateFromProto(\n+                          program_shape.result(), proto.aot_compilation_result()\n+                                                      .hlo_module()\n+                                                      .hlo_module()\n+                                                      .input_output_alias()));\n+\n+  std::unique_ptr<xla::cpu::NanoRtExecutable> executable;\n+\n+  if (proto.has_aot_compilation_result()) {\n+    TF_ASSIGN_OR_RETURN(executable,\n+                        xla::cpu::NanoRtExecutable::Create(\n+                            proto.aot_compilation_result(), program_shape));\n+  } else {\n+    XlaComputation computation;\n+    computation = XlaComputation(proto.hlo_module());\n+\n+    TF_ASSIGN_OR_RETURN(xla::cpu::NanoRtClient * client,\n+                        GetHostOffloadingNanoRtClient());\n+\n+    TF_ASSIGN_OR_RETURN(executable, client->Compile(computation));\n+  }\n \n   // TODO(basioli): Add support for compile options.\n   CompileOptions compile_options;\n-  TF_ASSIGN_OR_RETURN(std::unique_ptr<xla::cpu::NanoRtExecutable> executable,\n-                      client->Compile(computation));\n \n   std::shared_ptr<DeviceAssignment> device_assignment;\n   int num_replicas;\n@@ -192,11 +199,11 @@ HostOffloadingNanoRtExecutable::LoadFromProto(\n       &num_replicas, &num_partitions, &device_assignment));\n \n   return absl::WrapUnique(new HostOffloadingNanoRtExecutable(\n-      proto.hlo_module().name(),\n+      hlo_module_proto.name(),\n       executable->program_shape() ? *executable->program_shape()\n                                   : program_shape,\n-      std::move(alias_config), std::move(executable), needs_layout_conversion,\n-      std::move(device_assignment)));\n+      std::move(alias_config), std::move(executable),\n+      /*needs_layout_conversion=*/false, std::move(device_assignment)));\n }\n \n tsl::AsyncValueRef<HostOffloadingExecutable::ExecuteEvent>"
        },
        {
            "sha": "2ec905d5d969bd798c3d6aa28a0f8a7bdfc003a5",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07be026cd7a13c2026a2ce6c983b70d8b38bf347/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=07be026cd7a13c2026a2ce6c983b70d8b38bf347",
            "patch": "@@ -1555,7 +1555,10 @@ cc_library(\n     name = \"compiler\",\n     srcs = [\"compiler.cc\"],\n     hdrs = [\"compiler.h\"],\n-    visibility = internal_visibility([\"//xla/internal:hwi_internal\"]),\n+    visibility = internal_visibility([\n+        \"//xla/internal:hwi_internal\",\n+        \"//xla/backends/gpu/runtime:__subpackages__\",\n+    ]),\n     deps = [\n         \":buffer_assignment\",\n         \":buffer_value\","
        }
    ],
    "stats": {
        "total": 293,
        "additions": 228,
        "deletions": 65
    }
}