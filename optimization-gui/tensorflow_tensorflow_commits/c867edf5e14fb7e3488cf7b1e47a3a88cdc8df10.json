{
    "author": "olegshyshkov",
    "message": "[XLA:GPU] Move ShardedUnsharded tests into a separate target.\n\nPiperOrigin-RevId: 838856982",
    "sha": "c867edf5e14fb7e3488cf7b1e47a3a88cdc8df10",
    "files": [
        {
            "sha": "e819c613f082032b6e86ca2b331fcaf8b128fe7e",
            "filename": "third_party/xla/xla/tests/BUILD",
            "status": "modified",
            "additions": 47,
            "deletions": 20,
            "changes": 67,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c867edf5e14fb7e3488cf7b1e47a3a88cdc8df10/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c867edf5e14fb7e3488cf7b1e47a3a88cdc8df10/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2FBUILD?ref=c867edf5e14fb7e3488cf7b1e47a3a88cdc8df10",
            "patch": "@@ -2888,7 +2888,6 @@ cc_library(\n         \"//xla/stream_executor/integrations:device_mem_allocator\",\n         \"//xla/stream_executor/integrations:stream_executor_allocator\",\n         \"//xla/stream_executor/integrations:tf_allocator_adapter\",\n-        \"//xla/tsl/framework:allocator\",\n         \"//xla/tsl/framework:bfc_allocator\",\n         \"//xla/tsl/framework:device_id_impl\",\n         \"//xla/tsl/platform:statusor\",\n@@ -2899,7 +2898,11 @@ cc_library(\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n-    ],\n+    ] + if_google([\n+        # In OSS this dependency is added automatically for xla_test targets. See\n+        # third_party/tensorflow/compiler/xla/xla.default.bzl.\n+        \"//xla/tsl/framework:allocator\",\n+    ]),\n )\n \n xla_test(\n@@ -2930,33 +2933,20 @@ xla_test(\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/parser:hlo_parser\",\n-        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n         \"//xla/hlo/testlib:pattern_matcher_gmock\",\n         \"//xla/hlo/testlib:verified_hlo_module\",\n         \"//xla/hlo/utils:hlo_matchers\",\n-        \"//xla/service:backend\",\n         \"//xla/service:computation_placer_hdr\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service:hlo_runner\",\n         \"//xla/service:hlo_runner_interface\",\n         \"//xla/service:pattern_matcher\",\n-        \"//xla/service:platform_util\",\n         \"//xla/service/gpu:backend_configs_cc\",\n-        \"//xla/service/gpu:gpu_memory_space_assignment\",\n         \"//xla/stream_executor:device_description\",\n-        \"//xla/stream_executor:platform\",\n-        \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n-        \"//xla/stream_executor/integrations:device_mem_allocator\",\n-        \"//xla/stream_executor/integrations:stream_executor_allocator\",\n-        \"//xla/stream_executor/integrations:tf_allocator_adapter\",\n-        \"//xla/tsl/framework:bfc_allocator\",\n-        \"//xla/tsl/framework:device_id\",\n         \"//xla/tsl/lib/core:status_test_util\",\n-        \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n-        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/functional:any_invocable\",\n         \"@com_google_absl//absl/log\",\n@@ -2967,12 +2957,49 @@ xla_test(\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n+    ],\n+)\n+\n+xla_test(\n+    name = \"collective_ops_sharded_unsharded_e2e_test\",\n+    srcs = [\"collective_ops_sharded_unsharded_e2e_test.cc\"],\n+    backend_tags = {\n+        \"gpu\": [\n+            \"multi_gpu\",\n+        ],\n+        \"nvgpu_any\": [\n+            \"broken\",\n+            \"no_oss\",\n+        ],\n+    },\n+    backends = [\n+        \"gpu\",\n+    ],\n+    deps = [\n+        \":collective_ops_e2e_test_base\",\n+        \":literal_test_util\",\n+        \":test_utils\",\n+        \":xla_internal_test_main\",\n+        \"//xla:array\",\n+        \"//xla:error_spec\",\n+        \"//xla:literal\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/parser:hlo_parser\",\n+        \"//xla/hlo/testlib:verified_hlo_module\",\n+        \"//xla/service:computation_placer_hdr\",\n+        \"//xla/service:hlo_module_config\",\n+        \"//xla/service:hlo_runner\",\n+        \"//xla/service/gpu:backend_configs_cc\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/platform:test\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_absl//absl/types:span\",\n         \"@local_tsl//tsl/platform:regexp\",\n-    ] + if_google([\n-        # In OSS this dependency is added automatically for xla_test targets. See\n-        # third_party/tensorflow/compiler/xla/xla.default.bzl.\n-        \"//xla/tsl/framework:allocator\",\n-    ]),\n+    ],\n )\n \n xla_test("
        },
        {
            "sha": "3b41521d3da677b08ecf9d0b51dfe8381381772e",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 445,
            "changes": 445,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c867edf5e14fb7e3488cf7b1e47a3a88cdc8df10/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c867edf5e14fb7e3488cf7b1e47a3a88cdc8df10/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc?ref=c867edf5e14fb7e3488cf7b1e47a3a88cdc8df10",
            "patch": "@@ -13,11 +13,9 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include <algorithm>\n #include <array>\n #include <cmath>\n #include <cstdint>\n-#include <functional>\n #include <memory>\n #include <string>\n #include <tuple>\n@@ -44,7 +42,6 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n-#include \"xla/hlo/ir/hlo_sharding.h\"\n #include \"xla/hlo/parser/hlo_parser.h\"\n #include \"xla/hlo/testlib/pattern_matcher_gmock.h\"\n #include \"xla/hlo/testlib/verified_hlo_module.h\"\n@@ -67,7 +64,6 @@ limitations under the License.\n #include \"xla/tsl/platform/test.h\"\n #include \"xla/types.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/regexp.h\"\n \n namespace xla {\n namespace {\n@@ -1289,447 +1285,6 @@ TEST_F(CollectiveOpsTestE2E, HostMemoryOffloadingWithDonation) {\n       << \"of aliased parameter 0 at index {} (f32[128,128])\" << error_message;\n }\n \n-// E2E tests comparing the results of sharded and unsharded execution.\n-class CollectiveOpsTestE2EShardedUnsharded : public CollectiveOpsTestE2E {\n- public:\n-  void CollectiveOpsCompareShardedUnsharded(\n-      const std::string& hlo_text, const int64_t num_partitions = 2,\n-      bool enable_enzyme_comms_opt = false) {\n-    const int64_t num_replicas = 1;\n-    if (hlo_runner_->device_count() < num_replicas * num_partitions) {\n-      GTEST_SKIP() << \"Test requires at least \" << num_replicas * num_partitions\n-                   << \" devices (\" << hlo_runner_->device_count()\n-                   << \" available)\";\n-    }\n-\n-    TF_ASSERT_OK_AND_ASSIGN(std::vector<Literal> ref_results,\n-                            ExecuteUnsharded(hlo_text));\n-    ASSERT_EQ(ref_results.size(), 1);\n-\n-    TF_ASSERT_OK_AND_ASSIGN(\n-        std::vector<Literal> results,\n-        ExecuteSharded(hlo_text, num_partitions, enable_enzyme_comms_opt));\n-    ASSERT_EQ(results.size(), num_partitions);\n-\n-    ErrorSpec error_spec{1e-4, 1e-4};\n-    CompareShardedUnsharded(hlo_text, num_partitions, ref_results, results,\n-                            error_spec);\n-  }\n-\n- private:\n-  // Execute the unsharded case.\n-  absl::StatusOr<std::vector<Literal>> ExecuteUnsharded(\n-      const std::string& hlo_text) {\n-    // Create the unsharded reference case by removing the sharding metadata\n-    // from the HLO string.\n-    std::string hlo_text_ref = hlo_text;\n-    RE2::GlobalReplace(&hlo_text_ref, R\"(, sharding=\\{devices=\\[[0-9,]*\\].*\\})\",\n-                       \"\");\n-    RE2::GlobalReplace(&hlo_text_ref, R\"(, sharding=\\{replicated\\})\", \"\");\n-\n-    HloModuleConfig ref_config = GetModuleConfigForTest();\n-    DebugOptions ref_opts = GetDebugOptionsForTest();\n-    ref_opts.set_xla_gpu_enable_triton_gemm(false);\n-    ref_config.set_debug_options(ref_opts);\n-    ref_config.set_num_partitions(1);\n-    TF_ASSIGN_OR_RETURN(std::unique_ptr<VerifiedHloModule> ref_module,\n-                        ParseAndReturnVerifiedModule(hlo_text_ref, ref_config));\n-    const int64_t num_params =\n-        ref_module->entry_computation()->num_parameters();\n-\n-    auto fake_args = xla::MakeFakeArguments(ref_module.get()).value();\n-    std::vector<Literal*> ref_fake_ptrs(num_params);\n-    for (int i = 0; i < num_params; ++i) {\n-      ref_fake_ptrs[i] = &fake_args[i];\n-    }\n-\n-    DeviceAssignment ref_assn(/*replica_count=*/1,\n-                              /*computation_count=*/1);\n-    ref_assn(0, 0) = 0;\n-    return ExecuteReplicated(std::move(ref_module), ref_fake_ptrs,\n-                             /*num_replicas=*/1, &ref_assn,\n-                             /*run_hlo_passes=*/true,\n-                             /*use_threads=*/true);\n-  }\n-\n-  // Execute the sharded case.\n-  absl::StatusOr<std::vector<Literal>> ExecuteSharded(\n-      const std::string& hlo_text, int64_t num_partitions,\n-      bool enable_enzyme_comms_opt = false) {\n-    HloModuleConfig config = GetModuleConfigForTest();\n-    DebugOptions opts = GetDebugOptionsForTest();\n-    opts.set_xla_gpu_enable_triton_gemm(false);\n-    config.set_debug_options(opts);\n-    config.set_num_partitions(num_partitions);\n-    if (enable_enzyme_comms_opt) {\n-      config.mutable_debug_options().set_xla_enable_enzyme_comms_opt(true);\n-    }\n-    TF_ASSIGN_OR_RETURN(std::unique_ptr<VerifiedHloModule> module,\n-                        ParseAndReturnVerifiedModule(hlo_text, config));\n-    const int64_t num_params = module->entry_computation()->num_parameters();\n-\n-    std::vector<std::vector<int64_t>> param_dims(num_params);\n-    std::vector<std::vector<int64_t>> param_dims_per_shard(num_params);\n-    std::vector<std::vector<int64_t>> param_sharded_dims(num_params);\n-    for (int i = 0; i < num_params; ++i) {\n-      auto dimensions = module->entry_computation()\n-                            ->parameter_instruction(i)\n-                            ->shape()\n-                            .dimensions();\n-      param_dims[i] = std::vector(dimensions.begin(), dimensions.end());\n-      param_dims_per_shard[i] = param_dims[i];\n-      HloSharding parameter_sharding =\n-          module->entry_computation()->parameter_instruction(i)->sharding();\n-      EvaluateShardedDims(param_dims_per_shard[i], param_sharded_dims[i],\n-                          parameter_sharding);\n-    }\n-\n-    // Slice the tiled inputs to match the prescribed sharding.\n-    auto fake_args = xla::MakeFakeArguments(module.get()).value();\n-    std::vector<std::vector<Literal>> fake_args_sliced(num_params);\n-    std::vector<std::vector<Literal*>> fake_ptrs(num_partitions);\n-    for (int k = 0; k < num_params; ++k) {\n-      if (!param_sharded_dims[k].empty()) {\n-        std::vector<int64_t> lower(param_dims_per_shard[k].size(), 0);\n-        std::vector<int64_t> upper(param_dims_per_shard[k].begin(),\n-                                   param_dims_per_shard[k].end());\n-        for (int i = 0; i < num_partitions; ++i) {\n-          fake_args_sliced[k].push_back(fake_args[k].Slice(lower, upper));\n-          for (int m = param_sharded_dims[k].size() - 1; m >= 0; --m) {\n-            if (upper[param_sharded_dims[k][m]] <\n-                param_dims[k][param_sharded_dims[k][m]]) {\n-              upper[param_sharded_dims[k][m]] +=\n-                  param_dims_per_shard[k][param_sharded_dims[k][m]];\n-              break;\n-            }\n-            upper[param_sharded_dims[k][m]] =\n-                param_dims_per_shard[k][param_sharded_dims[k][m]];\n-          }\n-          std::transform(upper.begin(), upper.end(),\n-                         param_dims_per_shard[k].begin(), lower.begin(),\n-                         std::minus<int64_t>());\n-        }\n-      } else {\n-        fake_args_sliced[k].push_back(fake_args[k].Clone());\n-      }\n-    }\n-    for (int k = 0; k < num_params; ++k) {\n-      for (int i = 0; i < num_partitions; ++i) {\n-        if (!param_sharded_dims[k].empty()) {\n-          fake_ptrs[i].push_back(&fake_args_sliced[k][i]);\n-        } else {\n-          fake_ptrs[i].push_back(&fake_args_sliced[k][0]);\n-        }\n-      }\n-    }\n-\n-    DeviceAssignment assn(/*replica_count=*/1,\n-                          /*computation_count=*/num_partitions);\n-    for (int64_t i = 0; i < num_partitions; ++i) {\n-      assn(0, i) = i;\n-    }\n-    return ExecuteReplicated(std::move(module), fake_ptrs, &assn,\n-                             num_partitions,\n-                             /*run_hlo_passes=*/true);\n-  }\n-\n-  // Slice the unsharded reference results and compare to the sharded case.\n-  void CompareShardedUnsharded(const std::string& hlo_text,\n-                               int64_t num_partitions,\n-                               std::vector<Literal>& ref_results,\n-                               std::vector<Literal>& results,\n-                               ErrorSpec& error_spec) {\n-    HloModuleConfig config = GetModuleConfigForTest();\n-    DebugOptions opts = GetDebugOptionsForTest();\n-    opts.set_xla_gpu_enable_triton_gemm(false);\n-    config.set_debug_options(opts);\n-    config.set_num_partitions(num_partitions);\n-    TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n-                            ParseAndReturnVerifiedModule(hlo_text, config));\n-    auto dimensions =\n-        module->entry_computation()->root_instruction()->shape().dimensions();\n-    std::vector<int64_t> root_dims(dimensions.begin(), dimensions.end());\n-    std::vector<int64_t> root_dims_per_shard = root_dims;\n-    std::vector<int64_t> root_sharded_dims;\n-    {\n-      HloSharding root_sharding =\n-          module->entry_computation()->root_instruction()->sharding();\n-      EvaluateShardedDims(root_dims_per_shard, root_sharded_dims,\n-                          root_sharding);\n-    }\n-    if (!root_sharded_dims.empty()) {\n-      std::vector<int64_t> lower(root_dims_per_shard.size(), 0);\n-      std::vector<int64_t> upper(root_dims_per_shard.begin(),\n-                                 root_dims_per_shard.end());\n-      for (const Literal& result : results) {\n-        Literal ref_results_slice = ref_results[0].Slice(lower, upper);\n-        EXPECT_TRUE(\n-            LiteralTestUtil::Near(ref_results_slice, result, error_spec));\n-        for (int m = root_sharded_dims.size() - 1; m >= 0; --m) {\n-          if (upper[root_sharded_dims[m]] < root_dims[root_sharded_dims[m]]) {\n-            upper[root_sharded_dims[m]] +=\n-                root_dims_per_shard[root_sharded_dims[m]];\n-            break;\n-          }\n-          upper[root_sharded_dims[m]] =\n-              root_dims_per_shard[root_sharded_dims[m]];\n-        }\n-        std::transform(upper.begin(), upper.end(), root_dims_per_shard.begin(),\n-                       lower.begin(), std::minus<int64_t>());\n-      }\n-    } else {\n-      EXPECT_TRUE(\n-          LiteralTestUtil::Near(ref_results[0], results[0], error_spec));\n-    }\n-  }\n-\n-  void EvaluateShardedDims(std::vector<int64_t>& dims_per_shard,\n-                           std::vector<int64_t>& sharded_dims,\n-                           const HloSharding& sharding) {\n-    if (!sharding.IsReplicated()) {\n-      for (int k = 0; k < sharding.tile_assignment().num_dimensions(); ++k) {\n-        if (sharding.dimension(k) > 1) {\n-          dims_per_shard[k] /= sharding.dimension(k);\n-          sharded_dims.push_back(k);\n-        }\n-      }\n-    }\n-  }\n-};\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotBatchAndBatch) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f32[4,16,8]{2,1,0}, f32[4,4,8]{2,1,0})->f32[4,16,4]{2,1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f32[4,16,8]{2,1,0} parameter(0), sharding={devices=[2,1,1]<=[2]}\n-  rhs = f32[4,4,8]{2,1,0} parameter(1), sharding={devices=[2,1,1]<=[2]}\n-  ROOT dot = f32[4,16,4]{2,1,0} dot(lhs, rhs), lhs_batch_dims={0}, rhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_contracting_dims={2}, sharding={devices=[1,2,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-// This is an execution test for the example in Option 2 in go/dus-spmd. This\n-// test should pass regardless of which DUS SPMD implementation option is used.\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n-       DusSingleDimensionInPartitionMode) {\n-  const std::string hlo_text = R\"(\n-    HloModule module, entry_computation_layout={(s32[16]{0}, s32[8]{0})->s32[16]{0}}, num_partitions=4\n-\n-    ENTRY entry {\n-      %input = s32[16] parameter(0), sharding={devices=[4]<=[4]}\n-      %update = s32[8] parameter(1), sharding={devices=[4]<=[4]}\n-      %c3 = s32[] constant(3)\n-      ROOT %dynamic-update-slice = s32[16] dynamic-update-slice(%input, %update, %c3), sharding={devices=[4]<=[4]}\n-    })\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/4,\n-                                       /*enable_enzyme_comms_opt=*/true);\n-  // This test should pass regardless if enzyme comms opt is enabled or not.\n-  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/4,\n-                                       /*enable_enzyme_comms_opt=*/false);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n-       KeepPartitionedNonSlicedDimensionWithConstantIndices) {\n-  const std::string hlo_text = R\"(\n-    HloModule module, entry_computation_layout={(bf16[2,24,24,32]{3,2,1,0}, bf16[2,4,4,32]{3,2,1,0})->bf16[2,56,56,32]{3,2,1,0}}, num_partitions=8\n-\n-    ENTRY entry {\n-      p1 = bf16[2,24,24,32]{3,2,1,0} parameter(0), sharding={replicated}\n-      p2 = bf16[2,4,4,32]{3,2,1,0} parameter(1), sharding={replicated}\n-      c1 = bf16[2,24,24,32]{3,2,1,0} copy(p1), sharding={devices=[2,2,2,1]<=[8]}\n-      c2 = bf16[2,4,4,32]{3,2,1,0} copy(p2), sharding={devices=[2,2,2,1]<=[8]}\n-      constant.1163 = bf16[] constant(0), sharding={replicated}\n-      constant.1165 = s32[] constant(0), sharding={replicated}\n-      pad.179 = bf16[2,56,56,32]{3,2,1,0} pad(c1, constant.1163), padding=0_0x16_16x16_16x0_0, sharding={devices=[2,2,2,1]<=[8]}\n-      add.439 = bf16[2,4,4,32]{3,2,1,0} add(c2, c2), sharding={devices=[2,2,2,1]<=[8]}\n-      constant.1070 = s32[] constant(48), sharding={replicated}\n-      dynamic-update-slice.128 = bf16[2,56,56,32]{3,2,1,0} dynamic-update-slice(pad.179, add.439, constant.1165, constant.1070, constant.1070, /*index=5*/constant.1165), sharding={devices=[2,2,2,1]<=[8]}\n-      ROOT c = bf16[2,56,56,32]{3,2,1,0} copy(dynamic-update-slice.128), sharding={devices=[2,2,2,1]<=[8]}\n-    })\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/8,\n-                                       /*enable_enzyme_comms_opt=*/true);\n-  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/8,\n-                                       /*enable_enzyme_comms_opt=*/false);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotBatchAndNonContracting) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f32[4,16,8]{2,1,0}, f32[4,4,8]{2,1,0})->f32[4,16,4]{2,1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f32[4,16,8]{2,1,0} parameter(0), sharding={devices=[2,1,1]<=[2]}\n-  rhs = f32[4,4,8]{2,1,0} parameter(1), sharding={devices=[1,2,1]<=[2]}\n-  ROOT dot = f32[4,16,4]{2,1,0} dot(lhs, rhs), lhs_batch_dims={0}, rhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_contracting_dims={2}, sharding={devices=[2,1,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotContractingAndContracting) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f32[16,8]{1,0}, f32[4,8]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f32[16,8]{1,0} parameter(0), sharding={devices=[1,2]<=[2]}\n-  rhs = f32[4,8]{1,0} parameter(1), sharding={devices=[1,2]<=[2]}\n-  ROOT dot = f32[16,4]{1,0} dot(lhs, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={1}, sharding={devices=[2,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotNonContractingAndContracting) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f32[16,8]{1,0}, f32[4,8]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f32[16,8]{1,0} parameter(0), sharding={devices=[2,1]<=[2]}\n-  rhs = f32[4,8]{1,0} parameter(1), sharding={devices=[1,2]<=[2]}\n-  ROOT dot = f32[16,4]{1,0} dot(lhs, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={1}, sharding={devices=[2,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotContractingAndReplicated) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f32[16,8]{1,0}, f32[4,8]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f32[16,8]{1,0} parameter(0), sharding={devices=[1,2]<=[2]}\n-  rhs = f32[4,8]{1,0} parameter(1), sharding={replicated}\n-  ROOT dot = f32[16,4]{1,0} dot(lhs, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={1}, sharding={devices=[2,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotReplicatedAndReplicated) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f32[4,4]{1,0}, f32[1,4]{1,0})->f32[4,1]{1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f32[4,4]{1,0} parameter(0), sharding={replicated}\n-  rhs = f32[1,4]{1,0} parameter(1), sharding={replicated}\n-  ROOT dot = f32[4,1]{1,0} dot(lhs, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={1}, sharding={devices=[2,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n-       DotContractingNonContractingAndContractingNonContracting) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f32[16,8]{1,0}, f32[4,8]{1,0})->f32[16,4]{1,0}}, num_partitions=4\n-\n-ENTRY entry {\n-  lhs = f32[16,8]{1,0} parameter(0), sharding={devices=[2,2]<=[4]}\n-  rhs = f32[4,8]{1,0} parameter(1), sharding={devices=[2,2]<=[4]}\n-  ROOT dot = f32[16,4]{1,0} dot(lhs, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={1}, sharding={devices=[2,2]<=[4]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/4);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded, BlockScaledDotBatchAndBatch) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f8e4m3fn[4,16,64]{2,1,0}, f8e8m0fnu[4,16,2]{2,1,0}, f8e4m3fn[4,4,64]{2,1,0}, f8e8m0fnu[4,4,2]{2,1,0})->f32[4,16,4]{2,1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f8e4m3fn[4,16,64]{2,1,0} parameter(0), sharding={devices=[2,1,1]<=[2]}\n-  lhs_scale = f8e8m0fnu[4,16,2]{2,1,0} parameter(1), sharding={devices=[2,1,1]<=[2]}\n-  rhs = f8e4m3fn[4,4,64]{2,1,0} parameter(2), sharding={devices=[2,1,1]<=[2]}\n-  rhs_scale = f8e8m0fnu[4,4,2]{2,1,0} parameter(3), sharding={devices=[2,1,1]<=[2]}\n-  ROOT block_scaled_dot = f32[4,16,4]{2,1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[1,2,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n-       BlockScaledDotBatchAndNonContracting) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f8e4m3fn[4,16,64]{2,1,0}, f8e8m0fnu[4,16,2]{2,1,0}, f8e4m3fn[4,4,64]{2,1,0}, f8e8m0fnu[4,4,2]{2,1,0})->f32[4,16,4]{2,1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f8e4m3fn[4,16,64]{2,1,0} parameter(0), sharding={devices=[2,1,1]<=[2]}\n-  lhs_scale = f8e8m0fnu[4,16,2]{2,1,0} parameter(1), sharding={devices=[2,1,1]<=[2]}\n-  rhs = f8e4m3fn[4,4,64]{2,1,0} parameter(2), sharding={devices=[1,2,1]<=[2]}\n-  rhs_scale = f8e8m0fnu[4,4,2]{2,1,0} parameter(3), sharding={devices=[1,2,1]<=[2]}\n-  ROOT block_scaled_dot = f32[4,16,4]{2,1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,1,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n-       BlockScaledDotContractingAndContracting) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f8e4m3fn[16,64]{1,0}, f8e8m0fnu[16,2]{1,0}, f8e4m3fn[4,64]{1,0}, f8e8m0fnu[4,2]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f8e4m3fn[16,64]{1,0} parameter(0), sharding={devices=[1,2]<=[2]}\n-  lhs_scale = f8e8m0fnu[16,2]{1,0} parameter(1), sharding={devices=[1,2]<=[2]}\n-  rhs = f8e4m3fn[4,64]{1,0} parameter(2), sharding={devices=[1,2]<=[2]}\n-  rhs_scale = f8e8m0fnu[4,2]{1,0} parameter(3), sharding={devices=[1,2]<=[2]}\n-  ROOT block_scaled_dot = f32[16,4]{1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n-       BlockScaledDotNonContractingAndContracting) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f8e4m3fn[16,128]{1,0}, f8e8m0fnu[16,4]{1,0}, f8e4m3fn[4,128]{1,0}, f8e8m0fnu[4,4]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f8e4m3fn[16,128]{1,0} parameter(0), sharding={devices=[2,1]<=[2]}\n-  lhs_scale = f8e8m0fnu[16,4]{1,0} parameter(1), sharding={devices=[2,1]<=[2]}\n-  rhs = f8e4m3fn[4,128]{1,0} parameter(2), sharding={devices=[1,2]<=[2]}\n-  rhs_scale = f8e8m0fnu[4,4]{1,0} parameter(3), sharding={devices=[1,2]<=[2]}\n-  ROOT block_scaled_dot = f32[16,4]{1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n-       BlockScaledDotContractingAndReplicated) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f8e4m3fn[16,128]{1,0}, f8e8m0fnu[16,4]{1,0}, f8e4m3fn[4,128]{1,0}, f8e8m0fnu[4,4]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f8e4m3fn[16,128]{1,0} parameter(0), sharding={devices=[1,2]<=[2]}\n-  lhs_scale = f8e8m0fnu[16,4]{1,0} parameter(1), sharding={devices=[1,2]<=[2]}\n-  rhs = f8e4m3fn[4,128]{1,0} parameter(2), sharding={replicated}\n-  rhs_scale = f8e8m0fnu[4,4]{1,0} parameter(3), sharding={replicated}\n-  ROOT block_scaled_dot = f32[16,4]{1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n-       BlockScaledDotReplicatedAndReplicated) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f8e4m3fn[4,128]{1,0}, f8e8m0fnu[4,4], f8e4m3fn[1,128]{1,0}, f8e8m0fnu[1,4]{1,0})->f32[4,1]{1,0}}, num_partitions=2\n-\n-ENTRY entry {\n-  lhs = f8e4m3fn[4,128]{1,0} parameter(0), sharding={replicated}\n-  lhs_scale = f8e8m0fnu[4,4]{1,0} parameter(1), sharding={replicated}\n-  rhs = f8e4m3fn[1,128]{1,0} parameter(2), sharding={replicated}\n-  rhs_scale = f8e8m0fnu[1,4]{1,0} parameter(3), sharding={replicated}\n-  ROOT block_scaled_dot = f32[4,1]{1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,1]<=[2]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text);\n-}\n-\n-TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n-       BlockScaledDotContractingNonContractingAndContractingNonContracting) {\n-  const std::string hlo_text = R\"(\n-HloModule module, entry_computation_layout={(f8e4m3fn[8,128]{1,0}, f8e8m0fnu[8,4]{1,0}, f8e4m3fn[4,128]{1,0}, f8e8m0fnu[4,4]{1,0})->f32[8,4]{1,0}}, num_partitions=4\n-\n-ENTRY entry {\n-  lhs = f8e4m3fn[8,128]{1,0} parameter(0), sharding={devices=[2,2]<=[4]}\n-  lhs_scale = f8e8m0fnu[8,4]{1,0} parameter(1), sharding={devices=[2,2]<=[4]}\n-  rhs = f8e4m3fn[4,128]{1,0} parameter(2), sharding={devices=[2,2]<=[4]}\n-  rhs_scale = f8e8m0fnu[4,4]{1,0} parameter(3), sharding={devices=[2,2]<=[4]}\n-  ROOT dot = f32[8,4]{1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,2]<=[4]}\n-})\";\n-  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/4);\n-}\n-\n // E2E tests comparing the results of windowed einsum and non-windowed cases.\n class CollectiveOpsTestE2EWindowedNonWindowed : public CollectiveOpsTestE2E {\n  public:"
        },
        {
            "sha": "ebcf3585c2cfe36901c92e9d9d535fd5c64c1a4c",
            "filename": "third_party/xla/xla/tests/collective_ops_sharded_unsharded_e2e_test.cc",
            "status": "added",
            "additions": 493,
            "deletions": 0,
            "changes": 493,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c867edf5e14fb7e3488cf7b1e47a3a88cdc8df10/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_sharded_unsharded_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c867edf5e14fb7e3488cf7b1e47a3a88cdc8df10/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_sharded_unsharded_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_sharded_unsharded_e2e_test.cc?ref=c867edf5e14fb7e3488cf7b1e47a3a88cdc8df10",
            "patch": "@@ -0,0 +1,493 @@\n+/* Copyright 2023 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <functional>\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n+#include \"xla/array.h\"\n+#include \"xla/error_spec.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_sharding.h\"\n+#include \"xla/hlo/parser/hlo_parser.h\"\n+#include \"xla/hlo/testlib/verified_hlo_module.h\"\n+#include \"xla/literal.h\"\n+#include \"xla/service/computation_placer.h\"\n+#include \"xla/service/gpu/backend_configs.pb.h\"\n+#include \"xla/service/hlo_module_config.h\"\n+#include \"xla/service/hlo_runner.h\"\n+#include \"xla/tests/collective_ops_e2e_test_base.h\"\n+#include \"xla/tests/literal_test_util.h\"\n+#include \"xla/tests/test_utils.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/test.h\"\n+#include \"xla/xla_data.pb.h\"\n+#include \"tsl/platform/regexp.h\"\n+\n+namespace xla {\n+namespace {\n+\n+// E2E tests comparing the results of sharded and unsharded execution.\n+class CollectiveOpsTestE2EShardedUnsharded : public CollectiveOpsE2ETestBase {\n+ public:\n+  void CollectiveOpsCompareShardedUnsharded(\n+      const std::string& hlo_text, const int64_t num_partitions = 2,\n+      bool enable_enzyme_comms_opt = false) {\n+    const int64_t num_replicas = 1;\n+    if (hlo_runner_->device_count() < num_replicas * num_partitions) {\n+      GTEST_SKIP() << \"Test requires at least \" << num_replicas * num_partitions\n+                   << \" devices (\" << hlo_runner_->device_count()\n+                   << \" available)\";\n+    }\n+\n+    TF_ASSERT_OK_AND_ASSIGN(std::vector<Literal> ref_results,\n+                            ExecuteUnsharded(hlo_text));\n+    ASSERT_EQ(ref_results.size(), 1);\n+\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        std::vector<Literal> results,\n+        ExecuteSharded(hlo_text, num_partitions, enable_enzyme_comms_opt));\n+    ASSERT_EQ(results.size(), num_partitions);\n+\n+    ErrorSpec error_spec{1e-4, 1e-4};\n+    CompareShardedUnsharded(hlo_text, num_partitions, ref_results, results,\n+                            error_spec);\n+  }\n+\n+ private:\n+  // Execute the unsharded case.\n+  absl::StatusOr<std::vector<Literal>> ExecuteUnsharded(\n+      const std::string& hlo_text) {\n+    // Create the unsharded reference case by removing the sharding metadata\n+    // from the HLO string.\n+    std::string hlo_text_ref = hlo_text;\n+    RE2::GlobalReplace(&hlo_text_ref, R\"(, sharding=\\{devices=\\[[0-9,]*\\].*\\})\",\n+                       \"\");\n+    RE2::GlobalReplace(&hlo_text_ref, R\"(, sharding=\\{replicated\\})\", \"\");\n+\n+    HloModuleConfig ref_config = GetModuleConfigForTest();\n+    DebugOptions ref_opts = GetDebugOptionsForTest();\n+    ref_opts.set_xla_gpu_enable_triton_gemm(false);\n+    ref_config.set_debug_options(ref_opts);\n+    ref_config.set_num_partitions(1);\n+    TF_ASSIGN_OR_RETURN(std::unique_ptr<VerifiedHloModule> ref_module,\n+                        ParseAndReturnVerifiedModule(hlo_text_ref, ref_config));\n+    const int64_t num_params =\n+        ref_module->entry_computation()->num_parameters();\n+\n+    auto fake_args = xla::MakeFakeArguments(ref_module.get()).value();\n+    std::vector<Literal*> ref_fake_ptrs(num_params);\n+    for (int i = 0; i < num_params; ++i) {\n+      ref_fake_ptrs[i] = &fake_args[i];\n+    }\n+\n+    DeviceAssignment ref_assn(/*replica_count=*/1,\n+                              /*computation_count=*/1);\n+    ref_assn(0, 0) = 0;\n+    return ExecuteReplicated(std::move(ref_module), ref_fake_ptrs,\n+                             /*num_replicas=*/1, &ref_assn,\n+                             /*run_hlo_passes=*/true,\n+                             /*use_threads=*/true);\n+  }\n+\n+  // Execute the sharded case.\n+  absl::StatusOr<std::vector<Literal>> ExecuteSharded(\n+      const std::string& hlo_text, int64_t num_partitions,\n+      bool enable_enzyme_comms_opt = false) {\n+    HloModuleConfig config = GetModuleConfigForTest();\n+    DebugOptions opts = GetDebugOptionsForTest();\n+    opts.set_xla_gpu_enable_triton_gemm(false);\n+    config.set_debug_options(opts);\n+    config.set_num_partitions(num_partitions);\n+    if (enable_enzyme_comms_opt) {\n+      config.mutable_debug_options().set_xla_enable_enzyme_comms_opt(true);\n+    }\n+    TF_ASSIGN_OR_RETURN(std::unique_ptr<VerifiedHloModule> module,\n+                        ParseAndReturnVerifiedModule(hlo_text, config));\n+    const int64_t num_params = module->entry_computation()->num_parameters();\n+\n+    std::vector<std::vector<int64_t>> param_dims(num_params);\n+    std::vector<std::vector<int64_t>> param_dims_per_shard(num_params);\n+    std::vector<std::vector<int64_t>> param_sharded_dims(num_params);\n+    for (int i = 0; i < num_params; ++i) {\n+      auto dimensions = module->entry_computation()\n+                            ->parameter_instruction(i)\n+                            ->shape()\n+                            .dimensions();\n+      param_dims[i] = std::vector(dimensions.begin(), dimensions.end());\n+      param_dims_per_shard[i] = param_dims[i];\n+      HloSharding parameter_sharding =\n+          module->entry_computation()->parameter_instruction(i)->sharding();\n+      EvaluateShardedDims(param_dims_per_shard[i], param_sharded_dims[i],\n+                          parameter_sharding);\n+    }\n+\n+    // Slice the tiled inputs to match the prescribed sharding.\n+    auto fake_args = xla::MakeFakeArguments(module.get()).value();\n+    std::vector<std::vector<Literal>> fake_args_sliced(num_params);\n+    std::vector<std::vector<Literal*>> fake_ptrs(num_partitions);\n+    for (int k = 0; k < num_params; ++k) {\n+      if (!param_sharded_dims[k].empty()) {\n+        std::vector<int64_t> lower(param_dims_per_shard[k].size(), 0);\n+        std::vector<int64_t> upper(param_dims_per_shard[k].begin(),\n+                                   param_dims_per_shard[k].end());\n+        for (int i = 0; i < num_partitions; ++i) {\n+          fake_args_sliced[k].push_back(fake_args[k].Slice(lower, upper));\n+          for (int m = param_sharded_dims[k].size() - 1; m >= 0; --m) {\n+            if (upper[param_sharded_dims[k][m]] <\n+                param_dims[k][param_sharded_dims[k][m]]) {\n+              upper[param_sharded_dims[k][m]] +=\n+                  param_dims_per_shard[k][param_sharded_dims[k][m]];\n+              break;\n+            }\n+            upper[param_sharded_dims[k][m]] =\n+                param_dims_per_shard[k][param_sharded_dims[k][m]];\n+          }\n+          std::transform(upper.begin(), upper.end(),\n+                         param_dims_per_shard[k].begin(), lower.begin(),\n+                         std::minus<int64_t>());\n+        }\n+      } else {\n+        fake_args_sliced[k].push_back(fake_args[k].Clone());\n+      }\n+    }\n+    for (int k = 0; k < num_params; ++k) {\n+      for (int i = 0; i < num_partitions; ++i) {\n+        if (!param_sharded_dims[k].empty()) {\n+          fake_ptrs[i].push_back(&fake_args_sliced[k][i]);\n+        } else {\n+          fake_ptrs[i].push_back(&fake_args_sliced[k][0]);\n+        }\n+      }\n+    }\n+\n+    DeviceAssignment assn(/*replica_count=*/1,\n+                          /*computation_count=*/num_partitions);\n+    for (int64_t i = 0; i < num_partitions; ++i) {\n+      assn(0, i) = i;\n+    }\n+    return ExecuteReplicated(std::move(module), fake_ptrs, &assn,\n+                             num_partitions,\n+                             /*run_hlo_passes=*/true);\n+  }\n+\n+  // Slice the unsharded reference results and compare to the sharded case.\n+  void CompareShardedUnsharded(const std::string& hlo_text,\n+                               int64_t num_partitions,\n+                               std::vector<Literal>& ref_results,\n+                               std::vector<Literal>& results,\n+                               ErrorSpec& error_spec) {\n+    HloModuleConfig config = GetModuleConfigForTest();\n+    DebugOptions opts = GetDebugOptionsForTest();\n+    opts.set_xla_gpu_enable_triton_gemm(false);\n+    config.set_debug_options(opts);\n+    config.set_num_partitions(num_partitions);\n+    TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                            ParseAndReturnVerifiedModule(hlo_text, config));\n+    auto dimensions =\n+        module->entry_computation()->root_instruction()->shape().dimensions();\n+    std::vector<int64_t> root_dims(dimensions.begin(), dimensions.end());\n+    std::vector<int64_t> root_dims_per_shard = root_dims;\n+    std::vector<int64_t> root_sharded_dims;\n+    {\n+      HloSharding root_sharding =\n+          module->entry_computation()->root_instruction()->sharding();\n+      EvaluateShardedDims(root_dims_per_shard, root_sharded_dims,\n+                          root_sharding);\n+    }\n+    if (!root_sharded_dims.empty()) {\n+      std::vector<int64_t> lower(root_dims_per_shard.size(), 0);\n+      std::vector<int64_t> upper(root_dims_per_shard.begin(),\n+                                 root_dims_per_shard.end());\n+      for (const Literal& result : results) {\n+        Literal ref_results_slice = ref_results[0].Slice(lower, upper);\n+        EXPECT_TRUE(\n+            LiteralTestUtil::Near(ref_results_slice, result, error_spec));\n+        for (int m = root_sharded_dims.size() - 1; m >= 0; --m) {\n+          if (upper[root_sharded_dims[m]] < root_dims[root_sharded_dims[m]]) {\n+            upper[root_sharded_dims[m]] +=\n+                root_dims_per_shard[root_sharded_dims[m]];\n+            break;\n+          }\n+          upper[root_sharded_dims[m]] =\n+              root_dims_per_shard[root_sharded_dims[m]];\n+        }\n+        std::transform(upper.begin(), upper.end(), root_dims_per_shard.begin(),\n+                       lower.begin(), std::minus<int64_t>());\n+      }\n+    } else {\n+      EXPECT_TRUE(\n+          LiteralTestUtil::Near(ref_results[0], results[0], error_spec));\n+    }\n+  }\n+\n+  void EvaluateShardedDims(std::vector<int64_t>& dims_per_shard,\n+                           std::vector<int64_t>& sharded_dims,\n+                           const HloSharding& sharding) {\n+    if (!sharding.IsReplicated()) {\n+      for (int k = 0; k < sharding.tile_assignment().num_dimensions(); ++k) {\n+        if (sharding.dimension(k) > 1) {\n+          dims_per_shard[k] /= sharding.dimension(k);\n+          sharded_dims.push_back(k);\n+        }\n+      }\n+    }\n+  }\n+};\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotBatchAndBatch) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f32[4,16,8]{2,1,0}, f32[4,4,8]{2,1,0})->f32[4,16,4]{2,1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f32[4,16,8]{2,1,0} parameter(0), sharding={devices=[2,1,1]<=[2]}\n+  rhs = f32[4,4,8]{2,1,0} parameter(1), sharding={devices=[2,1,1]<=[2]}\n+  ROOT dot = f32[4,16,4]{2,1,0} dot(lhs, rhs), lhs_batch_dims={0}, rhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_contracting_dims={2}, sharding={devices=[1,2,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+// This is an execution test for the example in Option 2 in go/dus-spmd. This\n+// test should pass regardless of which DUS SPMD implementation option is used.\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n+       DusSingleDimensionInPartitionMode) {\n+  const std::string hlo_text = R\"(\n+    HloModule module, entry_computation_layout={(s32[16]{0}, s32[8]{0})->s32[16]{0}}, num_partitions=4\n+\n+    ENTRY entry {\n+      %input = s32[16] parameter(0), sharding={devices=[4]<=[4]}\n+      %update = s32[8] parameter(1), sharding={devices=[4]<=[4]}\n+      %c3 = s32[] constant(3)\n+      ROOT %dynamic-update-slice = s32[16] dynamic-update-slice(%input, %update, %c3), sharding={devices=[4]<=[4]}\n+    })\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/4,\n+                                       /*enable_enzyme_comms_opt=*/true);\n+  // This test should pass regardless if enzyme comms opt is enabled or not.\n+  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/4,\n+                                       /*enable_enzyme_comms_opt=*/false);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n+       KeepPartitionedNonSlicedDimensionWithConstantIndices) {\n+  const std::string hlo_text = R\"(\n+    HloModule module, entry_computation_layout={(bf16[2,24,24,32]{3,2,1,0}, bf16[2,4,4,32]{3,2,1,0})->bf16[2,56,56,32]{3,2,1,0}}, num_partitions=8\n+\n+    ENTRY entry {\n+      p1 = bf16[2,24,24,32]{3,2,1,0} parameter(0), sharding={replicated}\n+      p2 = bf16[2,4,4,32]{3,2,1,0} parameter(1), sharding={replicated}\n+      c1 = bf16[2,24,24,32]{3,2,1,0} copy(p1), sharding={devices=[2,2,2,1]<=[8]}\n+      c2 = bf16[2,4,4,32]{3,2,1,0} copy(p2), sharding={devices=[2,2,2,1]<=[8]}\n+      constant.1163 = bf16[] constant(0), sharding={replicated}\n+      constant.1165 = s32[] constant(0), sharding={replicated}\n+      pad.179 = bf16[2,56,56,32]{3,2,1,0} pad(c1, constant.1163), padding=0_0x16_16x16_16x0_0, sharding={devices=[2,2,2,1]<=[8]}\n+      add.439 = bf16[2,4,4,32]{3,2,1,0} add(c2, c2), sharding={devices=[2,2,2,1]<=[8]}\n+      constant.1070 = s32[] constant(48), sharding={replicated}\n+      dynamic-update-slice.128 = bf16[2,56,56,32]{3,2,1,0} dynamic-update-slice(pad.179, add.439, constant.1165, constant.1070, constant.1070, /*index=5*/constant.1165), sharding={devices=[2,2,2,1]<=[8]}\n+      ROOT c = bf16[2,56,56,32]{3,2,1,0} copy(dynamic-update-slice.128), sharding={devices=[2,2,2,1]<=[8]}\n+    })\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/8,\n+                                       /*enable_enzyme_comms_opt=*/true);\n+  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/8,\n+                                       /*enable_enzyme_comms_opt=*/false);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotBatchAndNonContracting) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f32[4,16,8]{2,1,0}, f32[4,4,8]{2,1,0})->f32[4,16,4]{2,1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f32[4,16,8]{2,1,0} parameter(0), sharding={devices=[2,1,1]<=[2]}\n+  rhs = f32[4,4,8]{2,1,0} parameter(1), sharding={devices=[1,2,1]<=[2]}\n+  ROOT dot = f32[4,16,4]{2,1,0} dot(lhs, rhs), lhs_batch_dims={0}, rhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_contracting_dims={2}, sharding={devices=[2,1,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotContractingAndContracting) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f32[16,8]{1,0}, f32[4,8]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f32[16,8]{1,0} parameter(0), sharding={devices=[1,2]<=[2]}\n+  rhs = f32[4,8]{1,0} parameter(1), sharding={devices=[1,2]<=[2]}\n+  ROOT dot = f32[16,4]{1,0} dot(lhs, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={1}, sharding={devices=[2,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotNonContractingAndContracting) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f32[16,8]{1,0}, f32[4,8]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f32[16,8]{1,0} parameter(0), sharding={devices=[2,1]<=[2]}\n+  rhs = f32[4,8]{1,0} parameter(1), sharding={devices=[1,2]<=[2]}\n+  ROOT dot = f32[16,4]{1,0} dot(lhs, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={1}, sharding={devices=[2,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotContractingAndReplicated) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f32[16,8]{1,0}, f32[4,8]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f32[16,8]{1,0} parameter(0), sharding={devices=[1,2]<=[2]}\n+  rhs = f32[4,8]{1,0} parameter(1), sharding={replicated}\n+  ROOT dot = f32[16,4]{1,0} dot(lhs, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={1}, sharding={devices=[2,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded, DotReplicatedAndReplicated) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f32[4,4]{1,0}, f32[1,4]{1,0})->f32[4,1]{1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f32[4,4]{1,0} parameter(0), sharding={replicated}\n+  rhs = f32[1,4]{1,0} parameter(1), sharding={replicated}\n+  ROOT dot = f32[4,1]{1,0} dot(lhs, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={1}, sharding={devices=[2,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n+       DotContractingNonContractingAndContractingNonContracting) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f32[16,8]{1,0}, f32[4,8]{1,0})->f32[16,4]{1,0}}, num_partitions=4\n+\n+ENTRY entry {\n+  lhs = f32[16,8]{1,0} parameter(0), sharding={devices=[2,2]<=[4]}\n+  rhs = f32[4,8]{1,0} parameter(1), sharding={devices=[2,2]<=[4]}\n+  ROOT dot = f32[16,4]{1,0} dot(lhs, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={1}, sharding={devices=[2,2]<=[4]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/4);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded, BlockScaledDotBatchAndBatch) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f8e4m3fn[4,16,64]{2,1,0}, f8e8m0fnu[4,16,2]{2,1,0}, f8e4m3fn[4,4,64]{2,1,0}, f8e8m0fnu[4,4,2]{2,1,0})->f32[4,16,4]{2,1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f8e4m3fn[4,16,64]{2,1,0} parameter(0), sharding={devices=[2,1,1]<=[2]}\n+  lhs_scale = f8e8m0fnu[4,16,2]{2,1,0} parameter(1), sharding={devices=[2,1,1]<=[2]}\n+  rhs = f8e4m3fn[4,4,64]{2,1,0} parameter(2), sharding={devices=[2,1,1]<=[2]}\n+  rhs_scale = f8e8m0fnu[4,4,2]{2,1,0} parameter(3), sharding={devices=[2,1,1]<=[2]}\n+  ROOT block_scaled_dot = f32[4,16,4]{2,1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[1,2,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n+       BlockScaledDotBatchAndNonContracting) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f8e4m3fn[4,16,64]{2,1,0}, f8e8m0fnu[4,16,2]{2,1,0}, f8e4m3fn[4,4,64]{2,1,0}, f8e8m0fnu[4,4,2]{2,1,0})->f32[4,16,4]{2,1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f8e4m3fn[4,16,64]{2,1,0} parameter(0), sharding={devices=[2,1,1]<=[2]}\n+  lhs_scale = f8e8m0fnu[4,16,2]{2,1,0} parameter(1), sharding={devices=[2,1,1]<=[2]}\n+  rhs = f8e4m3fn[4,4,64]{2,1,0} parameter(2), sharding={devices=[1,2,1]<=[2]}\n+  rhs_scale = f8e8m0fnu[4,4,2]{2,1,0} parameter(3), sharding={devices=[1,2,1]<=[2]}\n+  ROOT block_scaled_dot = f32[4,16,4]{2,1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,1,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n+       BlockScaledDotContractingAndContracting) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f8e4m3fn[16,64]{1,0}, f8e8m0fnu[16,2]{1,0}, f8e4m3fn[4,64]{1,0}, f8e8m0fnu[4,2]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f8e4m3fn[16,64]{1,0} parameter(0), sharding={devices=[1,2]<=[2]}\n+  lhs_scale = f8e8m0fnu[16,2]{1,0} parameter(1), sharding={devices=[1,2]<=[2]}\n+  rhs = f8e4m3fn[4,64]{1,0} parameter(2), sharding={devices=[1,2]<=[2]}\n+  rhs_scale = f8e8m0fnu[4,2]{1,0} parameter(3), sharding={devices=[1,2]<=[2]}\n+  ROOT block_scaled_dot = f32[16,4]{1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n+       BlockScaledDotNonContractingAndContracting) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f8e4m3fn[16,128]{1,0}, f8e8m0fnu[16,4]{1,0}, f8e4m3fn[4,128]{1,0}, f8e8m0fnu[4,4]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f8e4m3fn[16,128]{1,0} parameter(0), sharding={devices=[2,1]<=[2]}\n+  lhs_scale = f8e8m0fnu[16,4]{1,0} parameter(1), sharding={devices=[2,1]<=[2]}\n+  rhs = f8e4m3fn[4,128]{1,0} parameter(2), sharding={devices=[1,2]<=[2]}\n+  rhs_scale = f8e8m0fnu[4,4]{1,0} parameter(3), sharding={devices=[1,2]<=[2]}\n+  ROOT block_scaled_dot = f32[16,4]{1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n+       BlockScaledDotContractingAndReplicated) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f8e4m3fn[16,128]{1,0}, f8e8m0fnu[16,4]{1,0}, f8e4m3fn[4,128]{1,0}, f8e8m0fnu[4,4]{1,0})->f32[16,4]{1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f8e4m3fn[16,128]{1,0} parameter(0), sharding={devices=[1,2]<=[2]}\n+  lhs_scale = f8e8m0fnu[16,4]{1,0} parameter(1), sharding={devices=[1,2]<=[2]}\n+  rhs = f8e4m3fn[4,128]{1,0} parameter(2), sharding={replicated}\n+  rhs_scale = f8e8m0fnu[4,4]{1,0} parameter(3), sharding={replicated}\n+  ROOT block_scaled_dot = f32[16,4]{1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n+       BlockScaledDotReplicatedAndReplicated) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f8e4m3fn[4,128]{1,0}, f8e8m0fnu[4,4], f8e4m3fn[1,128]{1,0}, f8e8m0fnu[1,4]{1,0})->f32[4,1]{1,0}}, num_partitions=2\n+\n+ENTRY entry {\n+  lhs = f8e4m3fn[4,128]{1,0} parameter(0), sharding={replicated}\n+  lhs_scale = f8e8m0fnu[4,4]{1,0} parameter(1), sharding={replicated}\n+  rhs = f8e4m3fn[1,128]{1,0} parameter(2), sharding={replicated}\n+  rhs_scale = f8e8m0fnu[1,4]{1,0} parameter(3), sharding={replicated}\n+  ROOT block_scaled_dot = f32[4,1]{1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,1]<=[2]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text);\n+}\n+\n+TEST_F(CollectiveOpsTestE2EShardedUnsharded,\n+       BlockScaledDotContractingNonContractingAndContractingNonContracting) {\n+  const std::string hlo_text = R\"(\n+HloModule module, entry_computation_layout={(f8e4m3fn[8,128]{1,0}, f8e8m0fnu[8,4]{1,0}, f8e4m3fn[4,128]{1,0}, f8e8m0fnu[4,4]{1,0})->f32[8,4]{1,0}}, num_partitions=4\n+\n+ENTRY entry {\n+  lhs = f8e4m3fn[8,128]{1,0} parameter(0), sharding={devices=[2,2]<=[4]}\n+  lhs_scale = f8e8m0fnu[8,4]{1,0} parameter(1), sharding={devices=[2,2]<=[4]}\n+  rhs = f8e4m3fn[4,128]{1,0} parameter(2), sharding={devices=[2,2]<=[4]}\n+  rhs_scale = f8e8m0fnu[4,4]{1,0} parameter(3), sharding={devices=[2,2]<=[4]}\n+  ROOT dot = f32[8,4]{1,0} custom-call(lhs, rhs, lhs_scale, rhs_scale), custom_call_target=\"__op$block_scaled_dot\", sharding={devices=[2,2]<=[4]}\n+})\";\n+  CollectiveOpsCompareShardedUnsharded(hlo_text, /*num_partitions=*/4);\n+}\n+\n+}  // namespace\n+}  // namespace xla"
        }
    ],
    "stats": {
        "total": 1005,
        "additions": 540,
        "deletions": 465
    }
}