{
    "author": "chunnienc",
    "message": "Fix flatbuffer import for large models\n\nPiperOrigin-RevId: 831567953",
    "sha": "a062ff39b7d9f55714c325e78e4b14b33e1918d6",
    "files": [
        {
            "sha": "1b82ca5b0e61dc9a95e812258cc3d949c1e6e3d3",
            "filename": "tensorflow/compiler/mlir/lite/utils/const_tensor_utils.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a062ff39b7d9f55714c325e78e4b14b33e1918d6/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Fconst_tensor_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a062ff39b7d9f55714c325e78e4b14b33e1918d6/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Fconst_tensor_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Fconst_tensor_utils.cc?ref=a062ff39b7d9f55714c325e78e4b14b33e1918d6",
            "patch": "@@ -74,7 +74,7 @@ llvm::SmallVector<mlir::APInt> ReadAsHostEndian(ArrayRef<uint8_t> bytes) {\n   ret.reserve(elem_count);\n \n   const char* data_ptr = reinterpret_cast<const char*>(bytes.data());\n-  for (int i = 0; i < elem_count; i++) {\n+  for (size_t i = 0; i < elem_count; i++) {\n     T val = llvm::support::endian::readNext<T, llvm::endianness::native,\n                                             llvm::support::unaligned>(data_ptr);\n     ret.push_back(mlir::APInt(sizeof(T) * 8, val));\n@@ -362,15 +362,15 @@ StatusOr<mlir::ElementsAttr> ConvertFloatBuffer(\n       assert(bytes_len % 2 == 0);\n       // Supports both BF16 and F16.\n       assert(elem_type.isF16() || elem_type.isBF16());\n-      int elem_count = bytes_len / 2;\n+      size_t elem_count = bytes_len / 2;\n \n       if (elem_type.isF16()) {\n         std::vector<Eigen::half> values;\n         values.reserve(elem_count);\n \n         const char* data = reinterpret_cast<const char*>(buffer.data());\n \n-        for (int i = 0; i < elem_count; i++) {\n+        for (size_t i = 0; i < elem_count; i++) {\n           uint16_t bit_repr = llvm::support::endian::readNext<\n               uint16_t, llvm::endianness::native, llvm::support::unaligned>(\n               data);\n@@ -385,7 +385,7 @@ StatusOr<mlir::ElementsAttr> ConvertFloatBuffer(\n \n         const char* data = reinterpret_cast<const char*>(buffer.data());\n \n-        for (int i = 0; i < elem_count; i++) {\n+        for (size_t i = 0; i < elem_count; i++) {\n           uint16_t bit_repr = llvm::support::endian::readNext<\n               uint16_t, llvm::endianness::native, llvm::support::unaligned>(\n               data);\n@@ -398,13 +398,13 @@ StatusOr<mlir::ElementsAttr> ConvertFloatBuffer(\n     }\n     case 32: {\n       assert(bytes_len % 4 == 0);\n-      int elem_count = bytes_len / 4;\n+      size_t elem_count = bytes_len / 4;\n       std::vector<float> values;\n       values.reserve(elem_count);\n \n       const char* data = reinterpret_cast<const char*>(buffer.data());\n \n-      for (int i = 0; i < elem_count; i++) {\n+      for (size_t i = 0; i < elem_count; i++) {\n         uint32_t bit_repr =\n             llvm::support::endian::readNext<uint32_t, llvm::endianness::native,\n                                             llvm::support::unaligned>(data);\n@@ -415,13 +415,13 @@ StatusOr<mlir::ElementsAttr> ConvertFloatBuffer(\n     }\n     case 64: {\n       assert(bytes_len % 8 == 0);\n-      int elem_count = bytes_len / 8;\n+      size_t elem_count = bytes_len / 8;\n       std::vector<double> values;\n       values.reserve(elem_count);\n \n       const char* data = reinterpret_cast<const char*>(buffer.data());\n \n-      for (int i = 0; i < elem_count; i++) {\n+      for (size_t i = 0; i < elem_count; i++) {\n         uint64_t bit_repr =\n             llvm::support::endian::readNext<uint64_t, llvm::endianness::native,\n                                             llvm::support::unaligned>(data);"
        }
    ],
    "stats": {
        "total": 16,
        "additions": 8,
        "deletions": 8
    }
}