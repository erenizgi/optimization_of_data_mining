{
    "author": "dimvar",
    "message": "PR #33106: Rename NumericOptions to EngineOptions and add field to only select cuDNN plans that support CUDA graphs.\n\nImported from GitHub PR https://github.com/openxla/xla/pull/33106\n\nDefaults to false.\n\nThis fixes two test failures on GB200 and Spark,\n//xla/backends/gpu/runtime:cuda_command_buffer_thunk_test_nvgpu_any //xla/stream_executor/cuda:cuda_command_buffer_test_nvgpu_any where cuDNN was selecting the cuBLAS backend that does not support CUDA graph.\n\nAlso, in cuda_dnn.cc, moves the notes after the call to create_execution_plans, otherwise they have no effect.\n\nThanks to Emil Gilliam from the cuDNN team for guidance.\n\nCopybara import of the project:\n\n--\nb9b116a5ad05a42fd6b0e42bb90cfda33d71763d by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:\n\nAdd field to NumericOptions to only select cuDNN plans that support CUDA graphs.\nDefaults to false.\n\nThis fixes two test failures on GB200 and Spark,\n//xla/backends/gpu/runtime:cuda_command_buffer_thunk_test_nvgpu_any\n//xla/stream_executor/cuda:cuda_command_buffer_test_nvgpu_any\nwhere cuDNN was selecting the cuBLAS backend that does not support CUDA graph.\n\nAlso, in cuda_dnn.cc, moves the notes after the call to create_execution_plans,\notherwise they have no effect.\n\nThanks to Emil Gilliam from the cuDNN team for guidance.\n\n--\nb2f357e89343eaf5325df9b88b68acd04f6fdf87 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:\n\nRename NumericOptions to EngineOptions.\n\nMerging this change closes #33106\n\nPiperOrigin-RevId: 828847346",
    "sha": "c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
    "files": [
        {
            "sha": "90ab35035425c8c30728751c2d14a90d569811a2",
            "filename": "tensorflow/core/kernels/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/tensorflow%2Fcore%2Fkernels%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/tensorflow%2Fcore%2Fkernels%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2FBUILD?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -565,7 +565,7 @@ cc_library(\n         \"//tensorflow/core/platform:tensor_float_32_hdr_lib\",\n         \"//tensorflow/core/util:determinism_for_kernels\",\n         \"//tensorflow/core/util:env_var\",\n-        \"@local_xla//xla/stream_executor:numeric_options\",\n+        \"@local_xla//xla/stream_executor:engine_options\",\n         \"@local_xla//xla/tsl/util:determinism_for_kernels\",\n     ] + if_static([\"//tensorflow/core/platform:tensor_float_32_utils\"]),\n )"
        },
        {
            "sha": "3c4caf81522f87c519ae6c4ecb7b7cd4fe507384",
            "filename": "tensorflow/core/kernels/numeric_options_utils.h",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/tensorflow%2Fcore%2Fkernels%2Fnumeric_options_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/tensorflow%2Fcore%2Fkernels%2Fnumeric_options_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fnumeric_options_utils.h?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -16,28 +16,29 @@ limitations under the License.\n #ifndef TENSORFLOW_CORE_KERNELS_NUMERIC_OPTIONS_UTILS_H_\n #define TENSORFLOW_CORE_KERNELS_NUMERIC_OPTIONS_UTILS_H_\n \n-#include \"xla/stream_executor/numeric_options.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/tsl/util/determinism.h\"\n #include \"tensorflow/core/util/env_var.h\"\n #include \"tsl/platform/tensor_float_32_utils.h\"\n \n namespace tensorflow {\n \n-inline stream_executor::NumericOptions GetNumericOptions() {\n-  return stream_executor::NumericOptions{\n+inline stream_executor::EngineOptions GetNumericOptions() {\n+  return stream_executor::EngineOptions{\n       /*require_determinism=*/tsl::OpDeterminismRequired(),\n-      /*allow_tf32=*/tsl::tensor_float_32_execution_enabled()};\n+      /*allow_tf32=*/tsl::tensor_float_32_execution_enabled(),\n+      /*require_command_buffer=*/false};\n }\n \n-inline stream_executor::NumericOptions GetNumericOptionsForCuDnn() {\n+inline stream_executor::EngineOptions GetNumericOptionsForCuDnn() {\n   static bool cudnn_deterministic_env_var = [] {\n     bool cudnn_deterministic = false;\n     TF_CHECK_OK(ReadBoolFromEnvVar(\"TF_CUDNN_DETERMINISTIC\",\n                                    /*default_val=*/false,\n                                    &cudnn_deterministic));\n     return cudnn_deterministic;\n   }();\n-  stream_executor::NumericOptions result = GetNumericOptions();\n+  stream_executor::EngineOptions result = GetNumericOptions();\n   result.require_determinism |= cudnn_deterministic_env_var;\n   return result;\n }"
        },
        {
            "sha": "57e42fef58a1cc6bd930a07a3f56b5854d43fd72",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -300,7 +300,7 @@ cc_library(\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:dnn\",\n-        \"//xla/stream_executor:numeric_options\",\n+        \"//xla/stream_executor:engine_options\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor:stream_executor_memory_allocator\","
        },
        {
            "sha": "ed16280d5e7669ae54e5d9d3fb4911b87cd476bf",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cudnn.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 9,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -44,7 +44,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/dnn.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n@@ -159,7 +159,7 @@ absl::StatusOr<std::vector<CudnnBackendConfig>> GetAlgorithms(\n     se::dnn::DnnSupport* dnn, se::dnn::ConvolutionKind conv_kind,\n     se::dnn::DataType input_type, se::dnn::DataType output_type,\n     se::Stream* stream, const GpuConvConfig& gpu_conv_config,\n-    const se::NumericOptions& numeric_options, bool use_fallback) {\n+    const se::EngineOptions& engine_options, bool use_fallback) {\n   std::vector<std::unique_ptr<const se::dnn::ConvRunner>> conv_runners;\n   std::vector<std::unique_ptr<const se::dnn::FusedConvRunner>>\n       fused_conv_runners;\n@@ -180,15 +180,15 @@ absl::StatusOr<std::vector<CudnnBackendConfig>> GetAlgorithms(\n           gpu_conv_config.input_descriptor, gpu_conv_config.filter_descriptor,\n           gpu_conv_config.bias_descriptor, gpu_conv_config.output_descriptor,\n           gpu_conv_config.conv_desc, use_fallback, gpu_conv_config.fusion->mode,\n-          numeric_options, &fused_conv_runners));\n+          engine_options, &fused_conv_runners));\n       break;\n     }\n     case se::dnn::ConvolutionKind::FORWARD_GRAPH: {\n       TF_RETURN_IF_ERROR(dnn->GetGraphConvolveRunners(\n           conv_kind, input_type, output_type, stream,\n           gpu_conv_config.input_descriptor, gpu_conv_config.filter_descriptor,\n           gpu_conv_config.output_descriptor, gpu_conv_config.conv_desc,\n-          use_fallback, numeric_options, &graph_conv_runners,\n+          use_fallback, engine_options, &graph_conv_runners,\n           gpu_conv_config.serialized_graph));\n       break;\n     }\n@@ -204,7 +204,7 @@ absl::StatusOr<std::vector<CudnnBackendConfig>> GetAlgorithms(\n           gpu_conv_config.output_descriptor,\n           /*output_data=*/se::DeviceMemoryBase(nullptr),\n           gpu_conv_config.conv_desc, use_fallback,\n-          /*scratch_allocator=*/nullptr, numeric_options, &conv_runners));\n+          /*scratch_allocator=*/nullptr, engine_options, &conv_runners));\n       break;\n     }\n     default:\n@@ -269,22 +269,23 @@ GetConvolutionCustomCallConfigs(const HloCustomCallInstruction* instr,\n   bool allow_tf32 = absl::c_all_of(\n       instr->precision_config().operand_precision(),\n       [](int precision) { return precision <= PrecisionConfig::HIGH; });\n-  const se::NumericOptions numeric_options{\n-      RequireDeterminism(instr->GetModule()->config()), allow_tf32};\n+  const se::EngineOptions engine_options{\n+      RequireDeterminism(instr->GetModule()->config()), allow_tf32,\n+      /*require_command_buffer=*/false};\n \n   // Try to get algorithms without fallback first, as fallback algorithms can be\n   // very slow.\n   std::vector<CudnnBackendConfig> algorithm_configs;\n   TF_ASSIGN_OR_RETURN(\n       algorithm_configs,\n       GetAlgorithms(dnn, conv_kind, input_type, output_type, stream,\n-                    gpu_conv_config, numeric_options, /*use_fallback=*/false));\n+                    gpu_conv_config, engine_options, /*use_fallback=*/false));\n \n   if (algorithm_configs.empty()) {\n     TF_ASSIGN_OR_RETURN(\n         algorithm_configs,\n         GetAlgorithms(dnn, conv_kind, input_type, output_type, stream,\n-                      gpu_conv_config, numeric_options, /*use_fallback=*/true));\n+                      gpu_conv_config, engine_options, /*use_fallback=*/true));\n   }\n \n   std::vector<std::unique_ptr<BackendConfig>> configs;"
        },
        {
            "sha": "ecd6c0f9167a6fdceedbb32411f5792287a75f25",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -459,8 +459,8 @@ xla_test(\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:dnn\",\n+        \"//xla/stream_executor:engine_options\",\n         \"//xla/stream_executor:kernel_spec\",\n-        \"//xla/stream_executor:numeric_options\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:platform_manager\",\n         \"//xla/stream_executor:stream_executor_h\","
        },
        {
            "sha": "863cb97b8dced18cce98f516bb56c89681823a1a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/cuda_command_buffer_thunk_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcuda_command_buffer_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcuda_command_buffer_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcuda_command_buffer_thunk_test.cc?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -46,8 +46,8 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/dnn.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -115,7 +115,10 @@ TEST(CommandBufferThunkTest, CuDnnCmd) {\n     return graph;\n   }());\n   int64_t workspace_size = graph.Graph().get_workspace_size();\n-  TF_ASSERT_OK(graph.Prepare(dnn_support, se::NumericOptions{}));\n+  TF_ASSERT_OK(graph.Prepare(\n+      dnn_support, se::EngineOptions{/*require_determinism=*/false,\n+                                     /*allow_tf32=*/true,\n+                                     /*require_command_buffer=*/true}));\n   TF_ASSERT_OK(graph.Build(dnn_support, /*plan_id=*/std::nullopt));\n   EXPECT_THAT(graph.SupportsExplicitCommandBufferConstruction(),\n               absl_testing::IsOkAndHolds(true));"
        },
        {
            "sha": "f7af9f90810beb5860ed0a94f2e9161328f016b3",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -1156,7 +1156,7 @@ cc_library(\n         \"//xla/stream_executor:blas\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:device_memory\",\n-        \"//xla/stream_executor:numeric_options\",\n+        \"//xla/stream_executor:engine_options\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/gpu:gpu_blas_lt\","
        },
        {
            "sha": "1e1f1af2414719eb25386210f82fa27f2a46ea9f",
            "filename": "third_party/xla/xla/service/gpu/autotuning/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -582,8 +582,8 @@ cc_library(\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:dnn\",\n+        \"//xla/stream_executor:engine_options\",\n         \"//xla/stream_executor:lazy_op_runner\",\n-        \"//xla/stream_executor:numeric_options\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:scratch_allocator\",\n         \"//xla/stream_executor:stream\","
        },
        {
            "sha": "f3bf2ea74e631e8bf2b8fdaf9d802ccdc633327d",
            "filename": "third_party/xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 15,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -62,9 +62,9 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/dnn.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/gpu/redzone_allocator.h\"\n #include \"xla/stream_executor/lazy_op_runner.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/rocm/rocm_platform_id.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n@@ -155,7 +155,7 @@ absl::StatusOr<se::DeviceMemory<uint8_t>> ScratchAllocator::AllocateBytes(\n \n absl::StatusOr<std::vector<GenericConvRunner>> GetAlgorithms(\n     const GpuConvConfig& config, se::Stream* stream, bool use_fallback,\n-    const se::NumericOptions& numeric_options) {\n+    const se::EngineOptions& engine_options) {\n   TF_ASSIGN_OR_RETURN(se::dnn::DataType input_type,\n                       GetDNNDataTypeFromPrimitiveType(config.input_type));\n \n@@ -189,7 +189,7 @@ absl::StatusOr<std::vector<GenericConvRunner>> GetAlgorithms(\n           /* leakyrelu_alpha = */ config.fusion->leakyrelu_alpha, stream,\n           config.input_descriptor, config.filter_descriptor,\n           config.bias_descriptor, config.output_descriptor, config.conv_desc,\n-          use_fallback, config.fusion->mode, numeric_options, &runners));\n+          use_fallback, config.fusion->mode, engine_options, &runners));\n       for (auto& runner : runners) {\n         TF_ASSIGN_OR_RETURN(\n             auto runner_cache,\n@@ -207,7 +207,7 @@ absl::StatusOr<std::vector<GenericConvRunner>> GetAlgorithms(\n       TF_RETURN_IF_ERROR(dnn->GetGraphConvolveRunners(\n           kind, input_type, output_type, stream, config.input_descriptor,\n           config.filter_descriptor, config.output_descriptor, config.conv_desc,\n-          use_fallback, numeric_options, &runners, config.serialized_graph));\n+          use_fallback, engine_options, &runners, config.serialized_graph));\n       for (auto& runner : runners) {\n         TF_ASSIGN_OR_RETURN(\n             auto runner_cache,\n@@ -231,7 +231,7 @@ absl::StatusOr<std::vector<GenericConvRunner>> GetAlgorithms(\n           /* filter_data = */ DeviceMemoryBase(nullptr),\n           config.output_descriptor,\n           /* output_data = */ DeviceMemoryBase(nullptr), config.conv_desc,\n-          use_fallback, nullptr, numeric_options, &runners));\n+          use_fallback, nullptr, engine_options, &runners));\n \n       for (auto& runner : runners) {\n         TF_ASSIGN_OR_RETURN(\n@@ -253,7 +253,7 @@ GetMIOpenAlgorithms(const HloCustomCallInstruction* instr,\n                     absl::Span<se::DeviceMemoryBase> result_buffers,\n                     se::StreamExecutor* stream_exec,\n                     ScratchAllocator* scratch_allocator, se::Stream* stream,\n-                    const se::NumericOptions& numeric_options) {\n+                    const se::EngineOptions& engine_options) {\n   TF_ASSIGN_OR_RETURN(GpuConvConfig config, GetGpuConvConfig(instr));\n \n   TF_ASSIGN_OR_RETURN(se::dnn::DataType dtype,\n@@ -274,8 +274,7 @@ GetMIOpenAlgorithms(const HloCustomCallInstruction* instr,\n       params.config->filter_descriptor, params.filter_buf,\n       params.config->output_descriptor, params.output_buf,\n       params.config->conv_desc,\n-      /* use_fallback = */ false, scratch_allocator, numeric_options,\n-      &runners));\n+      /* use_fallback = */ false, scratch_allocator, engine_options, &runners));\n \n   return runners;\n }\n@@ -812,8 +811,9 @@ GpuConvAlgorithmPicker::PickBestAlgorithmNoCacheCuda(\n         instr->precision_config().operand_precision(),\n         [](int precision) { return precision <= PrecisionConfig::HIGH; });\n   }\n-  const se::NumericOptions numeric_options{\n-      RequireDeterminism(instr->GetModule()->config()), allow_tf32};\n+  const se::EngineOptions engine_options{\n+      RequireDeterminism(instr->GetModule()->config()), allow_tf32,\n+      /*require_command_buffer=*/false};\n \n   // Use the first algorithm that's supported as reference. There isn't a\n   // particular reason to use it, as any algorithm suffices. It doesn't make\n@@ -827,7 +827,7 @@ GpuConvAlgorithmPicker::PickBestAlgorithmNoCacheCuda(\n   TF_ASSIGN_OR_RETURN(\n       std::vector<GenericConvRunner> runners,\n       GetAlgorithms(runtime_arguments.gpu_conv_config, stream,\n-                    /* use_fallback = */ false, numeric_options));\n+                    /* use_fallback = */ false, engine_options));\n \n   std::vector<AutotuneResult> profile_results;\n   for (auto& runner_cache : runners) {\n@@ -850,7 +850,7 @@ GpuConvAlgorithmPicker::PickBestAlgorithmNoCacheCuda(\n     TF_ASSIGN_OR_RETURN(\n         std::vector<GenericConvRunner> fallback_runners,\n         GetAlgorithms(runtime_arguments.gpu_conv_config, stream,\n-                      /* use_fallback = */ true, numeric_options));\n+                      /* use_fallback = */ true, engine_options));\n \n     for (auto& runner_cache : fallback_runners) {\n       TF_ASSIGN_OR_RETURN(\n@@ -915,8 +915,9 @@ GpuConvAlgorithmPicker::PickBestAlgorithmNoCacheRocm(\n   const bool allow_tf32 = absl::c_all_of(\n       instr->precision_config().operand_precision(),\n       [](int precision) { return precision <= PrecisionConfig::HIGH; });\n-  const se::NumericOptions numeric_options{\n-      RequireDeterminism(instr->GetModule()->config()), allow_tf32};\n+  const se::EngineOptions engine_options{\n+      RequireDeterminism(instr->GetModule()->config()), allow_tf32,\n+      /*require_command_buffer=*/false};\n \n   se::StreamExecutor* stream_exec = config_.GetExecutor();\n   const auto device_ordinal = stream_exec->device_ordinal();\n@@ -970,7 +971,7 @@ GpuConvAlgorithmPicker::PickBestAlgorithmNoCacheRocm(\n       std::vector<std::unique_ptr<const se::dnn::ConvRunner>> runners,\n       GetMIOpenAlgorithms(instr, absl::MakeSpan(operand_buffers),\n                           absl::MakeSpan(result_buffers), stream_exec,\n-                          &scratch_allocator, stream, numeric_options));\n+                          &scratch_allocator, stream, engine_options));\n \n   std::vector<AutotuneResult> profile_results;\n "
        },
        {
            "sha": "ab19182b57a5fe2449f9966ed9344b174eef3776",
            "filename": "third_party/xla/xla/service/gpu/matmul_utils.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 15,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmatmul_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmatmul_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmatmul_utils.cc?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -47,8 +47,8 @@ limitations under the License.\n #include \"xla/stream_executor/blas.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/gpu/gpu_blas_lt.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/types.h\"\n@@ -534,7 +534,7 @@ absl::Status DoGemmWithAlgorithm(const se::gpu::MatrixDescriptor& lhs,\n                                  PrecisionConfig::Algorithm precision_algorithm,\n                                  se::blas::AlgorithmType algorithm,\n                                  se::blas::ComputePrecision compute_precision,\n-                                 const se::NumericOptions& numeric_options,\n+                                 const se::EngineOptions& engine_options,\n                                  se::blas::ProfileResult* profile_result,\n                                  se::blas::CallContext context) {\n   CHECK(output.transpose == se::blas::Transpose::kNoTranspose);\n@@ -560,14 +560,14 @@ absl::Status DoGemmWithAlgorithm(const se::gpu::MatrixDescriptor& lhs,\n         alpha, lhs.cast<Input>(), lhs.leading_dim_stride, lhs.batch_stride,\n         rhs.cast<Input>(), rhs.leading_dim_stride, rhs.batch_stride, beta,\n         &output_data, output.leading_dim_stride, output.batch_stride,\n-        output.batch_size, computation_type, algorithm, numeric_options,\n+        output.batch_size, computation_type, algorithm, engine_options,\n         profile_result, context);\n   }\n   return blas->BlasGemmWithAlgorithm(\n       stream, lhs.transpose, rhs.transpose, output.m, output.n, output.k, alpha,\n       lhs.cast<Input>(), lhs.leading_dim_stride, rhs.cast<Input>(),\n       rhs.leading_dim_stride, beta, &output_data, output.leading_dim_stride,\n-      computation_type, algorithm, numeric_options, profile_result, context);\n+      computation_type, algorithm, engine_options, profile_result, context);\n }\n \n template <typename Scale, typename Input, typename Output>\n@@ -579,7 +579,7 @@ absl::Status DoGemm(const se::gpu::MatrixDescriptor& lhs,\n                     PrecisionConfig::Algorithm precision_algorithm,\n                     std::optional<se::blas::AlgorithmType> algorithm,\n                     se::blas::ComputePrecision compute_precision,\n-                    const se::NumericOptions& numeric_options,\n+                    const se::EngineOptions& engine_options,\n                     se::blas::ProfileResult* profile_result,\n                     se::blas::CallContext context) {\n   CHECK(output.transpose == se::blas::Transpose::kNoTranspose);\n@@ -592,8 +592,7 @@ absl::Status DoGemm(const se::gpu::MatrixDescriptor& lhs,\n   if (algorithm) {\n     return DoGemmWithAlgorithm<Scale, Input, Output>(\n         lhs, rhs, output, workspace, alpha, beta, stream, precision_algorithm,\n-        *algorithm, compute_precision, numeric_options, profile_result,\n-        context);\n+        *algorithm, compute_precision, engine_options, profile_result, context);\n   }\n \n   // Set a workspace for all Blas operations launched below.\n@@ -605,14 +604,14 @@ absl::Status DoGemm(const se::gpu::MatrixDescriptor& lhs,\n         alpha, lhs.cast<Input>(), lhs.leading_dim_stride, lhs.batch_stride,\n         rhs.cast<Input>(), rhs.leading_dim_stride, rhs.batch_stride, beta,\n         &output_data, output.leading_dim_stride, output.batch_stride,\n-        output.batch_size, numeric_options, context);\n+        output.batch_size, engine_options, context);\n   }\n \n   return blas->BlasGemm(stream, lhs.transpose, rhs.transpose, output.m,\n                         output.n, output.k, alpha, lhs.cast<Input>(),\n                         lhs.leading_dim_stride, rhs.cast<Input>(),\n                         rhs.leading_dim_stride, beta, &output_data,\n-                        output.leading_dim_stride, numeric_options, context);\n+                        output.leading_dim_stride, engine_options, context);\n }\n \n }  // namespace\n@@ -630,10 +629,11 @@ absl::Status RunGemm(const GemmConfig& config, se::DeviceMemoryBase lhs_buffer,\n       GemmConfig::DescriptorsTuple desc,\n       config.GetMatrixDescriptors(lhs_buffer, rhs_buffer, output_buffer));\n \n-  se::NumericOptions numeric_options{\n+  se::EngineOptions engine_options{\n       deterministic_ops,\n-      /*allow_tf32=*/IsTf32Allowed(config.precision_algorithm,\n-                                   config.compute_precision)};\n+      /*allow_tf32=*/\n+      IsTf32Allowed(config.precision_algorithm, config.compute_precision),\n+      /*require_command_buffer=*/false};\n \n   if (!algorithm) {\n     algorithm = config.algorithm;\n@@ -673,7 +673,7 @@ absl::Status RunGemm(const GemmConfig& config, se::DeviceMemoryBase lhs_buffer,\n         static_cast<NativeScaleType>(config.alpha.real()),                  \\\n         static_cast<NativeScaleType>(config.beta), stream,                  \\\n         config.precision_algorithm, algorithm, config.compute_precision,    \\\n-        numeric_options, profile_result, context);                          \\\n+        engine_options, profile_result, context);                           \\\n   }\n \n #define TYPED_GEMM_COMPLEX(SCALENTYPE, ATYPE, BTYPE, CTYPE)                 \\\n@@ -687,7 +687,7 @@ absl::Status RunGemm(const GemmConfig& config, se::DeviceMemoryBase lhs_buffer,\n         static_cast<NativeScaleType>(config.alpha),                         \\\n         static_cast<NativeScaleType>(config.beta), stream,                  \\\n         config.precision_algorithm, algorithm, config.compute_precision,    \\\n-        numeric_options, profile_result, context);                          \\\n+        engine_options, profile_result, context);                           \\\n   }\n \n   if (config.output_layout.dtype == S32) {\n@@ -700,7 +700,7 @@ absl::Status RunGemm(const GemmConfig& config, se::DeviceMemoryBase lhs_buffer,\n         desc.lhs, desc.rhs, desc.output, workspace_buffer,\n         static_cast<int32_t>(config.alpha.real()),\n         static_cast<int32_t>(config.beta), stream, PrecisionConfig::ALG_UNSET,\n-        *algorithm, se::blas::kDefaultComputePrecision, numeric_options,\n+        *algorithm, se::blas::kDefaultComputePrecision, engine_options,\n         profile_result, context);\n   }\n "
        },
        {
            "sha": "782cf4b75254f97f7ad2bef0f7491dbf13d497ef",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -777,7 +777,7 @@ cc_library(\n         \"@local_tsl//tsl/platform:statusor\",\n     ]) + [\n         \"//xla/service:matmul_indexing_utils\",\n-        \"//xla/stream_executor:numeric_options\",\n+        \"//xla/stream_executor:engine_options\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/strings\","
        },
        {
            "sha": "9b586a82b72c3a4ac9d06efae914e4c567a53eee",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_fusion_compiler.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -865,9 +865,9 @@ absl::StatusOr<se::gpu::CudnnGraph> PrepareGraph(\n     return absl::InternalError(\"Construction of cuDNN graph failed.\");\n   }\n   TF_RETURN_IF_ERROR(graph->Prepare(\n-      dnn_support,\n-      se::NumericOptions{RequireDeterminism(hlo.GetModule()->config()),\n-                         /*allow_tf32=*/true}));\n+      dnn_support, se::EngineOptions{\n+                       RequireDeterminism(hlo.GetModule()->config()),\n+                       /*allow_tf32=*/true, /*require_command_buffer=*/false}));\n   return *graph;\n }\n "
        },
        {
            "sha": "7c391254e9a8db942a4c8cad90896c422f74bc61",
            "filename": "third_party/xla/xla/stream_executor/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -319,8 +319,8 @@ cc_library(\n )\n \n cc_library(\n-    name = \"numeric_options\",\n-    hdrs = [\"numeric_options.h\"],\n+    name = \"engine_options\",\n+    hdrs = [\"engine_options.h\"],\n )\n \n cc_library(\n@@ -346,7 +346,7 @@ cc_library(\n         \":blas_proto_cc\",\n         \":data_type\",\n         \":device_memory\",\n-        \":numeric_options\",\n+        \":engine_options\",\n         \":scratch_allocator\",\n         \":stream\",\n         \"//xla/tsl/protobuf:dnn_proto_cc\",\n@@ -367,7 +367,7 @@ cc_library(\n         \":data_type\",\n         \":device_description_proto_cc\",\n         \":device_memory\",\n-        \":numeric_options\",\n+        \":engine_options\",\n         \":scratch_allocator\",\n         \":stream\",\n         \"//xla:util\","
        },
        {
            "sha": "b1b1a2ab1ae24c1011ba4eaea1b7ea3814cbdb4a",
            "filename": "third_party/xla/xla/stream_executor/blas.h",
            "status": "modified",
            "additions": 186,
            "deletions": 185,
            "changes": 371,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fblas.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fblas.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fblas.h?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -35,7 +35,7 @@ limitations under the License.\n #include \"xla/stream_executor/blas.pb.h\"\n #include \"xla/stream_executor/data_type.h\"\n #include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/protobuf/dnn.pb.h\"\n@@ -296,12 +296,14 @@ class BlasSupport {\n   //\n   // Alpha/beta type matches `dtype`, unless `dtype` is `Eigen::half`, in that\n   // case the expected alpha/beta type is `float`.\n-  virtual absl::Status DoBlasGemm(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n-      uint64_t m, uint64_t n, uint64_t k, DataType dtype, const void *alpha,\n-      const DeviceMemoryBase &a, int lda, const DeviceMemoryBase &b, int ldb,\n-      const void *beta, DeviceMemoryBase *c, int ldc,\n-      const NumericOptions &numeric_options, blas::CallContext context) = 0;\n+  virtual absl::Status DoBlasGemm(Stream* stream, blas::Transpose transa,\n+                                  blas::Transpose transb, uint64_t m,\n+                                  uint64_t n, uint64_t k, DataType dtype,\n+                                  const void* alpha, const DeviceMemoryBase& a,\n+                                  int lda, const DeviceMemoryBase& b, int ldb,\n+                                  const void* beta, DeviceMemoryBase* c,\n+                                  int ldc, const EngineOptions& engine_options,\n+                                  blas::CallContext context) = 0;\n \n   // Gets a list of supported algorithms for DoBlasGemmWithAlgorithm.\n   virtual bool GetBlasGemmAlgorithms(\n@@ -322,95 +324,95 @@ class BlasSupport {\n   // choosing the best algorithm among many (some of which may fail) without\n   // creating a new Stream for each attempt.\n   virtual absl::Status DoBlasGemmWithAlgorithm(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n-      uint64_t m, uint64_t n, uint64_t k, const void *alpha,\n-      const DeviceMemoryBase &a, DataType type_a, int lda,\n-      const DeviceMemoryBase &b, DataType type_b, int ldb, const void *beta,\n-      DeviceMemoryBase *c, DataType type_c, int ldc,\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,\n+      uint64_t m, uint64_t n, uint64_t k, const void* alpha,\n+      const DeviceMemoryBase& a, DataType type_a, int lda,\n+      const DeviceMemoryBase& b, DataType type_b, int ldb, const void* beta,\n+      DeviceMemoryBase* c, DataType type_c, int ldc,\n       ComputationType computation_type, AlgorithmType algorithm,\n-      const NumericOptions &numeric_options,\n-      ProfileResult *output_profile_result, blas::CallContext context) = 0;\n+      const EngineOptions& engine_options, ProfileResult* output_profile_result,\n+      blas::CallContext context) = 0;\n   virtual absl::Status DoBlasGemmStridedBatchedWithAlgorithm(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n-      uint64_t m, uint64_t n, uint64_t k, const void *alpha,\n-      const DeviceMemoryBase &a, DataType type_a, int lda, int64_t stride_a,\n-      const DeviceMemoryBase &b, DataType type_b, int ldb, int64_t stride_b,\n-      const void *beta, DeviceMemoryBase *c, DataType type_c, int ldc,\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,\n+      uint64_t m, uint64_t n, uint64_t k, const void* alpha,\n+      const DeviceMemoryBase& a, DataType type_a, int lda, int64_t stride_a,\n+      const DeviceMemoryBase& b, DataType type_b, int ldb, int64_t stride_b,\n+      const void* beta, DeviceMemoryBase* c, DataType type_c, int ldc,\n       int64_t stride_c, int batch_count, ComputationType computation_type,\n-      AlgorithmType algorithm, const NumericOptions &numeric_options,\n-      ProfileResult *output_profile_result, blas::CallContext context) = 0;\n+      AlgorithmType algorithm, const EngineOptions& engine_options,\n+      ProfileResult* output_profile_result, blas::CallContext context) = 0;\n \n   // Computes a batch of matrix-matrix product with general matrices.\n   // This is a batched version of DoBlasGemm.\n   // The batched GEMM computes matrix product for each input/output in a, b,\n   // and c, which contain batch_count DeviceMemory objects.\n-  virtual bool DoBlasGemmBatched(Stream *stream, blas::Transpose transa,\n+  virtual bool DoBlasGemmBatched(Stream* stream, blas::Transpose transa,\n                                  blas::Transpose transb, uint64_t m, uint64_t n,\n                                  uint64_t k, float alpha,\n                                  DeviceMemorySlice<Eigen::half> a, int lda,\n                                  DeviceMemorySlice<Eigen::half> b, int ldb,\n                                  float beta, DeviceMemorySlice<Eigen::half> c,\n                                  int ldc, int batch_count,\n-                                 const NumericOptions &numeric_options,\n-                                 ScratchAllocator *scratch_allocator,\n+                                 const EngineOptions& engine_options,\n+                                 ScratchAllocator* scratch_allocator,\n                                  blas::CallContext context) = 0;\n   virtual bool DoBlasGemmBatched(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,\n       uint64_t m, uint64_t n, uint64_t k, float alpha,\n       DeviceMemorySlice<Eigen::bfloat16> a, int lda,\n       DeviceMemorySlice<Eigen::bfloat16> b, int ldb, float beta,\n       DeviceMemorySlice<Eigen::bfloat16> c, int ldc, int batch_count,\n-      const NumericOptions &numeric_options,\n-      ScratchAllocator *scratch_allocator, blas::CallContext context) = 0;\n+      const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n+      blas::CallContext context) = 0;\n   virtual bool DoBlasGemmBatched(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,\n       uint64_t m, uint64_t n, uint64_t k, float alpha,\n       DeviceMemorySlice<float> a, int lda, DeviceMemorySlice<float> b, int ldb,\n       float beta, DeviceMemorySlice<float> c, int ldc, int batch_count,\n-      const NumericOptions &numeric_options,\n-      ScratchAllocator *scratch_allocator, blas::CallContext context) = 0;\n+      const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n+      blas::CallContext context) = 0;\n   virtual bool DoBlasGemmBatched(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,\n       uint64_t m, uint64_t n, uint64_t k, double alpha,\n       DeviceMemorySlice<double> a, int lda, DeviceMemorySlice<double> b,\n       int ldb, double beta, DeviceMemorySlice<double> c, int ldc,\n-      int batch_count, const NumericOptions &numeric_options,\n-      ScratchAllocator *scratch_allocator, blas::CallContext context) = 0;\n+      int batch_count, const EngineOptions& engine_options,\n+      ScratchAllocator* scratch_allocator, blas::CallContext context) = 0;\n   virtual bool DoBlasGemmBatched(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,\n       uint64_t m, uint64_t n, uint64_t k, std::complex<float> alpha,\n       DeviceMemorySlice<std::complex<float>> a, int lda,\n       DeviceMemorySlice<std::complex<float>> b, int ldb,\n       std::complex<float> beta, DeviceMemorySlice<std::complex<float>> c,\n-      int ldc, int batch_count, const NumericOptions &numeric_options,\n-      ScratchAllocator *scratch_allocator, blas::CallContext context) = 0;\n+      int ldc, int batch_count, const EngineOptions& engine_options,\n+      ScratchAllocator* scratch_allocator, blas::CallContext context) = 0;\n   virtual bool DoBlasGemmBatched(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,\n       uint64_t m, uint64_t n, uint64_t k, std::complex<double> alpha,\n       DeviceMemorySlice<std::complex<double>> a, int lda,\n       DeviceMemorySlice<std::complex<double>> b, int ldb,\n       std::complex<double> beta, DeviceMemorySlice<std::complex<double>> c,\n-      int ldc, int batch_count, const NumericOptions &numeric_options,\n-      ScratchAllocator *scratch_allocator, blas::CallContext context) = 0;\n+      int ldc, int batch_count, const EngineOptions& engine_options,\n+      ScratchAllocator* scratch_allocator, blas::CallContext context) = 0;\n   // Batched gemm with strides instead of pointer arrays.\n   virtual absl::Status DoBlasGemmStridedBatched(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n-      uint64_t m, uint64_t n, uint64_t k, DataType dtype, const void *alpha,\n-      const DeviceMemoryBase &a, int lda, int64_t stride_a,\n-      const DeviceMemoryBase &b, int ldb, int64_t stride_b, const void *beta,\n-      DeviceMemoryBase *c, int ldc, int64_t stride_c, int batch_count,\n-      const NumericOptions &numeric_options, blas::CallContext context) = 0;\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,\n+      uint64_t m, uint64_t n, uint64_t k, DataType dtype, const void* alpha,\n+      const DeviceMemoryBase& a, int lda, int64_t stride_a,\n+      const DeviceMemoryBase& b, int ldb, int64_t stride_b, const void* beta,\n+      DeviceMemoryBase* c, int ldc, int64_t stride_c, int batch_count,\n+      const EngineOptions& engine_options, blas::CallContext context) = 0;\n \n   template <typename InputType, typename OutputType, typename ConstantType>\n   absl::Status BlasGemmStridedBatchedWithAlgorithm(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,\n       uint64_t m, uint64_t n, uint64_t k, ConstantType alpha,\n-      const DeviceMemory<InputType> &a, int lda, int64_t stride_a,\n-      const DeviceMemory<InputType> &b, int ldb, int64_t stride_b,\n-      ConstantType beta, DeviceMemory<OutputType> *c, int ldc, int64_t stride_c,\n+      const DeviceMemory<InputType>& a, int lda, int64_t stride_a,\n+      const DeviceMemory<InputType>& b, int ldb, int64_t stride_b,\n+      ConstantType beta, DeviceMemory<OutputType>* c, int ldc, int64_t stride_c,\n       int batch_count, blas::ComputationType computation_type,\n-      blas::AlgorithmType algorithm, const NumericOptions &numeric_options,\n-      blas::ProfileResult *output_profile_result, blas::CallContext context) {\n+      blas::AlgorithmType algorithm, const EngineOptions& engine_options,\n+      blas::ProfileResult* output_profile_result, blas::CallContext context) {\n     TF_RETURN_IF_ERROR(\n         CheckTypesForExtendedBlas<InputType, OutputType, ConstantType>(\n             computation_type));\n@@ -425,7 +427,7 @@ class BlasSupport {\n         blas::ToDataType<InputType>::value, lda, stride_a, b,\n         blas::ToDataType<InputType>::value, ldb, stride_b, beta_ptr, c,\n         blas::ToDataType<OutputType>::value, ldc, stride_c, batch_count,\n-        computation_type, algorithm, numeric_options, output_profile_result,\n+        computation_type, algorithm, engine_options, output_profile_result,\n         context);\n     if (output_profile_result) {\n       // The error is recorded in the profile.\n@@ -435,13 +437,13 @@ class BlasSupport {\n   }\n \n   template <typename InputType, typename OutputType, typename ConstantType>\n-  absl::Status BlasGemm(Stream *stream, blas::Transpose transa,\n+  absl::Status BlasGemm(Stream* stream, blas::Transpose transa,\n                         blas::Transpose transb, uint64_t m, uint64_t n,\n                         uint64_t k, ConstantType alpha,\n-                        const DeviceMemory<InputType> &a, int lda,\n-                        const DeviceMemory<InputType> &b, int ldb,\n-                        ConstantType beta, DeviceMemory<OutputType> *c, int ldc,\n-                        const NumericOptions &numeric_options,\n+                        const DeviceMemory<InputType>& a, int lda,\n+                        const DeviceMemory<InputType>& b, int ldb,\n+                        ConstantType beta, DeviceMemory<OutputType>* c, int ldc,\n+                        const EngineOptions& engine_options,\n                         blas::CallContext context) {\n     static_assert(\n         detail::is_any_of<InputType, int8_t, Eigen::half, Eigen::bfloat16,\n@@ -466,33 +468,33 @@ class BlasSupport {\n \n     return DoBlasGemm(stream, transa, transb, m, n, k,\n                       blas::ToDataType<InputType>::value, alpha_ptr, a, lda, b,\n-                      ldb, beta_ptr, c, ldc, numeric_options, context);\n+                      ldb, beta_ptr, c, ldc, engine_options, context);\n   }\n \n   template <typename InputType, typename OutputType>\n-  absl::Status BlasGemm(Stream *stream, blas::Transpose transa,\n+  absl::Status BlasGemm(Stream* stream, blas::Transpose transa,\n                         blas::Transpose transb, uint64_t m, uint64_t n,\n-                        uint64_t k, const DeviceMemory<InputType> &a, int lda,\n-                        const DeviceMemory<InputType> &b, int ldb,\n-                        DeviceMemory<OutputType> *c, int ldc,\n-                        const NumericOptions &numeric_options,\n+                        uint64_t k, const DeviceMemory<InputType>& a, int lda,\n+                        const DeviceMemory<InputType>& b, int ldb,\n+                        DeviceMemory<OutputType>* c, int ldc,\n+                        const EngineOptions& engine_options,\n                         blas::CallContext context) {\n     InputType alpha{1.0};\n     InputType beta{0.0};\n     return BlasGemm(stream, transa, transb, m, n, k, alpha, a, lda, b, ldb,\n-                    beta, c, ldc, numeric_options, context);\n+                    beta, c, ldc, engine_options, context);\n   }\n \n   template <typename InputType, typename OutputType, typename ConstantType>\n   absl::Status BlasGemmWithAlgorithm(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,\n       uint64_t m, uint64_t n, uint64_t k, ConstantType alpha,\n-      const DeviceMemory<InputType> &a, int lda,\n-      const DeviceMemory<InputType> &b, int ldb, ConstantType beta,\n-      DeviceMemory<OutputType> *c, int ldc,\n+      const DeviceMemory<InputType>& a, int lda,\n+      const DeviceMemory<InputType>& b, int ldb, ConstantType beta,\n+      DeviceMemory<OutputType>* c, int ldc,\n       blas::ComputationType computation_type, blas::AlgorithmType algorithm,\n-      const NumericOptions &numeric_options,\n-      blas::ProfileResult *output_profile_result, blas::CallContext context) {\n+      const EngineOptions& engine_options,\n+      blas::ProfileResult* output_profile_result, blas::CallContext context) {\n     TF_RETURN_IF_ERROR(\n         CheckTypesForExtendedBlas<InputType, OutputType, ConstantType>(\n             computation_type));\n@@ -508,7 +510,7 @@ class BlasSupport {\n         blas::ToDataType<InputType>::value, lda, b,\n         blas::ToDataType<InputType>::value, ldb, beta_ptr, c,\n         blas::ToDataType<OutputType>::value, ldc, computation_type, algorithm,\n-        numeric_options, output_profile_result, context);\n+        engine_options, output_profile_result, context);\n \n     if (output_profile_result) {\n       // The error is recorded in the profile.\n@@ -530,18 +532,18 @@ class BlasSupport {\n \n     return BlasGemmWithAlgorithm(stream, transa, transb, m, n, k, alpha, a, lda,\n                                  b, ldb, beta, c, ldc, computation_type,\n-                                 algorithm, NumericOptions{},\n+                                 algorithm, EngineOptions{},\n                                  output_profile_result, context);\n   }\n \n   template <typename InputType, typename OutputType, typename ConstantType>\n   absl::Status BlasGemmStridedBatched(\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,\n       uint64_t m, uint64_t n, uint64_t k, ConstantType alpha,\n-      const DeviceMemory<InputType> &a, int lda, int64_t stride_a,\n-      const DeviceMemory<InputType> &b, int ldb, int64_t stride_b,\n-      ConstantType beta, DeviceMemory<OutputType> *c, int ldc, int64_t stride_c,\n-      int batch_count, const NumericOptions &numeric_options,\n+      const DeviceMemory<InputType>& a, int lda, int64_t stride_a,\n+      const DeviceMemory<InputType>& b, int ldb, int64_t stride_b,\n+      ConstantType beta, DeviceMemory<OutputType>* c, int ldc, int64_t stride_c,\n+      int batch_count, const EngineOptions& engine_options,\n       blas::CallContext context) {\n     static_assert(\n         detail::is_any_of<InputType, int8_t, float, Eigen::half,\n@@ -563,7 +565,7 @@ class BlasSupport {\n     return DoBlasGemmStridedBatched(\n         stream, transa, transb, m, n, k, blas::ToDataType<InputType>::value,\n         alpha_ptr, a, lda, stride_a, b, ldb, stride_b, beta_ptr, c, ldc,\n-        stride_c, batch_count, numeric_options, context);\n+        stride_c, batch_count, engine_options, context);\n   }\n \n   // Solves a triangular matrix equation.\n@@ -740,176 +742,175 @@ class BlasSupport {\n // BlasSupport base class.\n #define TENSORFLOW_STREAM_EXECUTOR_GPU_BLAS_SUPPORT_OVERRIDES                  \\\n   absl::StatusOr<bool> IsMainStreamSet() const override;                       \\\n-  bool DoBlasScal(Stream *stream, uint64_t elem_count, float alpha,            \\\n-                  DeviceMemory<float> *x, int incx) override;                  \\\n-  bool DoBlasScal(Stream *stream, uint64_t elem_count, double alpha,           \\\n-                  DeviceMemory<double> *x, int incx) override;                 \\\n-  bool DoBlasScal(Stream *stream, uint64_t elem_count, float alpha,            \\\n-                  DeviceMemory<std::complex<float>> *x, int incx) override;    \\\n-  bool DoBlasScal(Stream *stream, uint64_t elem_count, double alpha,           \\\n-                  DeviceMemory<std::complex<double>> *x, int incx) override;   \\\n-  bool DoBlasScal(Stream *stream, uint64_t elem_count,                         \\\n+  bool DoBlasScal(Stream* stream, uint64_t elem_count, float alpha,            \\\n+                  DeviceMemory<float>* x, int incx) override;                  \\\n+  bool DoBlasScal(Stream* stream, uint64_t elem_count, double alpha,           \\\n+                  DeviceMemory<double>* x, int incx) override;                 \\\n+  bool DoBlasScal(Stream* stream, uint64_t elem_count, float alpha,            \\\n+                  DeviceMemory<std::complex<float>>* x, int incx) override;    \\\n+  bool DoBlasScal(Stream* stream, uint64_t elem_count, double alpha,           \\\n+                  DeviceMemory<std::complex<double>>* x, int incx) override;   \\\n+  bool DoBlasScal(Stream* stream, uint64_t elem_count,                         \\\n                   std::complex<float> alpha,                                   \\\n-                  DeviceMemory<std::complex<float>> *x, int incx) override;    \\\n-  bool DoBlasScal(Stream *stream, uint64_t elem_count,                         \\\n+                  DeviceMemory<std::complex<float>>* x, int incx) override;    \\\n+  bool DoBlasScal(Stream* stream, uint64_t elem_count,                         \\\n                   std::complex<double> alpha,                                  \\\n-                  DeviceMemory<std::complex<double>> *x, int incx) override;   \\\n-  bool DoBlasGemv(Stream *stream, blas::Transpose trans, uint64_t m,           \\\n-                  uint64_t n, float alpha, const DeviceMemory<float> &a,       \\\n-                  int lda, const DeviceMemory<float> &x, int incx, float beta, \\\n-                  DeviceMemory<float> *y, int incy) override;                  \\\n-  bool DoBlasGemv(Stream *stream, blas::Transpose trans, uint64_t m,           \\\n-                  uint64_t n, double alpha, const DeviceMemory<double> &a,     \\\n-                  int lda, const DeviceMemory<double> &x, int incx,            \\\n-                  double beta, DeviceMemory<double> *y, int incy) override;    \\\n-  bool DoBlasGemv(Stream *stream, blas::Transpose trans, uint64_t m,           \\\n+                  DeviceMemory<std::complex<double>>* x, int incx) override;   \\\n+  bool DoBlasGemv(Stream* stream, blas::Transpose trans, uint64_t m,           \\\n+                  uint64_t n, float alpha, const DeviceMemory<float>& a,       \\\n+                  int lda, const DeviceMemory<float>& x, int incx, float beta, \\\n+                  DeviceMemory<float>* y, int incy) override;                  \\\n+  bool DoBlasGemv(Stream* stream, blas::Transpose trans, uint64_t m,           \\\n+                  uint64_t n, double alpha, const DeviceMemory<double>& a,     \\\n+                  int lda, const DeviceMemory<double>& x, int incx,            \\\n+                  double beta, DeviceMemory<double>* y, int incy) override;    \\\n+  bool DoBlasGemv(Stream* stream, blas::Transpose trans, uint64_t m,           \\\n                   uint64_t n, std::complex<float> alpha,                       \\\n-                  const DeviceMemory<std::complex<float>> &a, int lda,         \\\n-                  const DeviceMemory<std::complex<float>> &x, int incx,        \\\n+                  const DeviceMemory<std::complex<float>>& a, int lda,         \\\n+                  const DeviceMemory<std::complex<float>>& x, int incx,        \\\n                   std::complex<float> beta,                                    \\\n-                  DeviceMemory<std::complex<float>> *y, int incy) override;    \\\n-  bool DoBlasGemv(Stream *stream, blas::Transpose trans, uint64_t m,           \\\n+                  DeviceMemory<std::complex<float>>* y, int incy) override;    \\\n+  bool DoBlasGemv(Stream* stream, blas::Transpose trans, uint64_t m,           \\\n                   uint64_t n, std::complex<double> alpha,                      \\\n-                  const DeviceMemory<std::complex<double>> &a, int lda,        \\\n-                  const DeviceMemory<std::complex<double>> &x, int incx,       \\\n+                  const DeviceMemory<std::complex<double>>& a, int lda,        \\\n+                  const DeviceMemory<std::complex<double>>& x, int incx,       \\\n                   std::complex<double> beta,                                   \\\n-                  DeviceMemory<std::complex<double>> *y, int incy) override;   \\\n+                  DeviceMemory<std::complex<double>>* y, int incy) override;   \\\n   absl::Status DoBlasGemm(                                                     \\\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,          \\\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,          \\\n       uint64_t m, uint64_t n, uint64_t k, blas::DataType dtype,                \\\n-      const void *alpha, const DeviceMemoryBase &a, int lda,                   \\\n-      const DeviceMemoryBase &b, int ldb, const void *beta,                    \\\n-      DeviceMemoryBase *c, int ldc, const NumericOptions &numeric_options,     \\\n+      const void* alpha, const DeviceMemoryBase& a, int lda,                   \\\n+      const DeviceMemoryBase& b, int ldb, const void* beta,                    \\\n+      DeviceMemoryBase* c, int ldc, const EngineOptions& engine_options,       \\\n       blas::CallContext context) override;                                     \\\n   bool GetBlasGemmAlgorithms(                                                  \\\n-      Stream *stream, const gpu::MatrixDescriptor &a,                          \\\n-      const gpu::MatrixDescriptor &b, gpu::OutputMatrixDescriptor *c,          \\\n-      const void *alpha, const void *beta,                                     \\\n-      std::vector<blas::AlgorithmType> *out_algorithms) override;              \\\n+      Stream* stream, const gpu::MatrixDescriptor& a,                          \\\n+      const gpu::MatrixDescriptor& b, gpu::OutputMatrixDescriptor* c,          \\\n+      const void* alpha, const void* beta,                                     \\\n+      std::vector<blas::AlgorithmType>* out_algorithms) override;              \\\n   absl::Status DoBlasGemmWithAlgorithm(                                        \\\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,          \\\n-      uint64_t m, uint64_t n, uint64_t k, const void *alpha,                   \\\n-      const DeviceMemoryBase &a, blas::DataType type_a, int lda,               \\\n-      const DeviceMemoryBase &b, blas::DataType type_b, int ldb,               \\\n-      const void *beta, DeviceMemoryBase *c, blas::DataType type_c, int ldc,   \\\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,          \\\n+      uint64_t m, uint64_t n, uint64_t k, const void* alpha,                   \\\n+      const DeviceMemoryBase& a, blas::DataType type_a, int lda,               \\\n+      const DeviceMemoryBase& b, blas::DataType type_b, int ldb,               \\\n+      const void* beta, DeviceMemoryBase* c, blas::DataType type_c, int ldc,   \\\n       blas::ComputationType computation_type, blas::AlgorithmType algorithm,   \\\n-      const NumericOptions &numeric_options,                                   \\\n-      blas::ProfileResult *output_profile_result, blas::CallContext context)   \\\n+      const EngineOptions& engine_options,                                     \\\n+      blas::ProfileResult* output_profile_result, blas::CallContext context)   \\\n       override;                                                                \\\n   bool DoBlasGemmBatched(                                                      \\\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,          \\\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,          \\\n       uint64_t m, uint64_t n, uint64_t k, float alpha,                         \\\n       DeviceMemorySlice<Eigen::half> a, int lda,                               \\\n       DeviceMemorySlice<Eigen::half> b, int ldb, float beta,                   \\\n       DeviceMemorySlice<Eigen::half> c, int ldc, int batch_count,              \\\n-      const NumericOptions &numeric_options,                                   \\\n-      ScratchAllocator *scratch_allocator, blas::CallContext context)          \\\n+      const EngineOptions& engine_options,                                     \\\n+      ScratchAllocator* scratch_allocator, blas::CallContext context)          \\\n       override;                                                                \\\n   bool DoBlasGemmBatched(                                                      \\\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,          \\\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,          \\\n       uint64_t m, uint64_t n, uint64_t k, float alpha,                         \\\n       DeviceMemorySlice<Eigen::bfloat16> a, int lda,                           \\\n       DeviceMemorySlice<Eigen::bfloat16> b, int ldb, float beta,               \\\n       DeviceMemorySlice<Eigen::bfloat16> c, int ldc, int batch_count,          \\\n-      const NumericOptions &numeric_options,                                   \\\n-      ScratchAllocator *scratch_allocator, blas::CallContext context)          \\\n-      override;                                                                \\\n-  bool DoBlasGemmBatched(                                                      \\\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,          \\\n-      uint64_t m, uint64_t n, uint64_t k, float alpha,                         \\\n-      DeviceMemorySlice<float> a, int lda, DeviceMemorySlice<float> b,         \\\n-      int ldb, float beta, DeviceMemorySlice<float> c, int ldc,                \\\n-      int batch_count, const NumericOptions &numeric_options,                  \\\n-      ScratchAllocator *scratch_allocator, blas::CallContext context)          \\\n+      const EngineOptions& engine_options,                                     \\\n+      ScratchAllocator* scratch_allocator, blas::CallContext context)          \\\n       override;                                                                \\\n+  bool DoBlasGemmBatched(Stream* stream, blas::Transpose transa,               \\\n+                         blas::Transpose transb, uint64_t m, uint64_t n,       \\\n+                         uint64_t k, float alpha, DeviceMemorySlice<float> a,  \\\n+                         int lda, DeviceMemorySlice<float> b, int ldb,         \\\n+                         float beta, DeviceMemorySlice<float> c, int ldc,      \\\n+                         int batch_count, const EngineOptions& engine_options, \\\n+                         ScratchAllocator* scratch_allocator,                  \\\n+                         blas::CallContext context) override;                  \\\n   bool DoBlasGemmBatched(                                                      \\\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,          \\\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,          \\\n       uint64_t m, uint64_t n, uint64_t k, double alpha,                        \\\n       DeviceMemorySlice<double> a, int lda, DeviceMemorySlice<double> b,       \\\n       int ldb, double beta, DeviceMemorySlice<double> c, int ldc,              \\\n-      int batch_count, const NumericOptions &numeric_options,                  \\\n-      ScratchAllocator *scratch_allocator, blas::CallContext context)          \\\n+      int batch_count, const EngineOptions& engine_options,                    \\\n+      ScratchAllocator* scratch_allocator, blas::CallContext context)          \\\n       override;                                                                \\\n   bool DoBlasGemmBatched(                                                      \\\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,          \\\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,          \\\n       uint64_t m, uint64_t n, uint64_t k, std::complex<float> alpha,           \\\n       DeviceMemorySlice<std::complex<float>> a, int lda,                       \\\n       DeviceMemorySlice<std::complex<float>> b, int ldb,                       \\\n       std::complex<float> beta, DeviceMemorySlice<std::complex<float>> c,      \\\n-      int ldc, int batch_count, const NumericOptions &numeric_options,         \\\n-      ScratchAllocator *scratch_allocator, blas::CallContext context)          \\\n+      int ldc, int batch_count, const EngineOptions& engine_options,           \\\n+      ScratchAllocator* scratch_allocator, blas::CallContext context)          \\\n       override;                                                                \\\n   bool DoBlasGemmBatched(                                                      \\\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,          \\\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,          \\\n       uint64_t m, uint64_t n, uint64_t k, std::complex<double> alpha,          \\\n       DeviceMemorySlice<std::complex<double>> a, int lda,                      \\\n       DeviceMemorySlice<std::complex<double>> b, int ldb,                      \\\n       std::complex<double> beta, DeviceMemorySlice<std::complex<double>> c,    \\\n-      int ldc, int batch_count, const NumericOptions &numeric_options,         \\\n-      ScratchAllocator *scratch_allocator, blas::CallContext context)          \\\n+      int ldc, int batch_count, const EngineOptions& engine_options,           \\\n+      ScratchAllocator* scratch_allocator, blas::CallContext context)          \\\n       override;                                                                \\\n   absl::Status DoBlasGemmStridedBatched(                                       \\\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,          \\\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,          \\\n       uint64_t m, uint64_t n, uint64_t k, blas::DataType dtype,                \\\n-      const void *alpha, const DeviceMemoryBase &a, int lda, int64_t stride_a, \\\n-      const DeviceMemoryBase &b, int ldb, int64_t stride_b, const void *beta,  \\\n-      DeviceMemoryBase *c, int ldc, int64_t stride_c, int batch_count,         \\\n-      const NumericOptions &numeric_options, blas::CallContext context)        \\\n+      const void* alpha, const DeviceMemoryBase& a, int lda, int64_t stride_a, \\\n+      const DeviceMemoryBase& b, int ldb, int64_t stride_b, const void* beta,  \\\n+      DeviceMemoryBase* c, int ldc, int64_t stride_c, int batch_count,         \\\n+      const EngineOptions& engine_options, blas::CallContext context)          \\\n       override;                                                                \\\n   absl::Status DoBlasGemmStridedBatchedWithAlgorithm(                          \\\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,          \\\n-      uint64_t m, uint64_t n, uint64_t k, const void *alpha,                   \\\n-      const DeviceMemoryBase &a, blas::DataType type_a, int lda,               \\\n-      int64_t stride_a, const DeviceMemoryBase &b, blas::DataType type_b,      \\\n-      int ldb, int64_t stride_b, const void *beta, DeviceMemoryBase *c,        \\\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,          \\\n+      uint64_t m, uint64_t n, uint64_t k, const void* alpha,                   \\\n+      const DeviceMemoryBase& a, blas::DataType type_a, int lda,               \\\n+      int64_t stride_a, const DeviceMemoryBase& b, blas::DataType type_b,      \\\n+      int ldb, int64_t stride_b, const void* beta, DeviceMemoryBase* c,        \\\n       blas::DataType type_c, int ldc, int64_t stride_c, int batch_count,       \\\n       blas::ComputationType computation_type, blas::AlgorithmType algorithm,   \\\n-      const NumericOptions &numeric_options,                                   \\\n-      blas::ProfileResult *output_profile_result, blas::CallContext context)   \\\n+      const EngineOptions& engine_options,                                     \\\n+      blas::ProfileResult* output_profile_result, blas::CallContext context)   \\\n       override;                                                                \\\n-  bool DoBlasTrsm(Stream *stream, blas::Side side, blas::UpperLower uplo,      \\\n+  bool DoBlasTrsm(Stream* stream, blas::Side side, blas::UpperLower uplo,      \\\n                   blas::Transpose transa, blas::Diagonal diag, uint64_t m,     \\\n-                  uint64_t n, float alpha, const DeviceMemory<float> &a,       \\\n-                  int lda, DeviceMemory<float> *b, int ldb) override;          \\\n-  bool DoBlasTrsm(Stream *stream, blas::Side side, blas::UpperLower uplo,      \\\n+                  uint64_t n, float alpha, const DeviceMemory<float>& a,       \\\n+                  int lda, DeviceMemory<float>* b, int ldb) override;          \\\n+  bool DoBlasTrsm(Stream* stream, blas::Side side, blas::UpperLower uplo,      \\\n                   blas::Transpose transa, blas::Diagonal diag, uint64_t m,     \\\n-                  uint64_t n, double alpha, const DeviceMemory<double> &a,     \\\n-                  int lda, DeviceMemory<double> *b, int ldb) override;         \\\n-  bool DoBlasTrsm(Stream *stream, blas::Side side, blas::UpperLower uplo,      \\\n+                  uint64_t n, double alpha, const DeviceMemory<double>& a,     \\\n+                  int lda, DeviceMemory<double>* b, int ldb) override;         \\\n+  bool DoBlasTrsm(Stream* stream, blas::Side side, blas::UpperLower uplo,      \\\n                   blas::Transpose transa, blas::Diagonal diag, uint64_t m,     \\\n                   uint64_t n, std::complex<float> alpha,                       \\\n-                  const DeviceMemory<std::complex<float>> &a, int lda,         \\\n-                  DeviceMemory<std::complex<float>> *b, int ldb) override;     \\\n-  bool DoBlasTrsm(Stream *stream, blas::Side side, blas::UpperLower uplo,      \\\n+                  const DeviceMemory<std::complex<float>>& a, int lda,         \\\n+                  DeviceMemory<std::complex<float>>* b, int ldb) override;     \\\n+  bool DoBlasTrsm(Stream* stream, blas::Side side, blas::UpperLower uplo,      \\\n                   blas::Transpose transa, blas::Diagonal diag, uint64_t m,     \\\n                   uint64_t n, std::complex<double> alpha,                      \\\n-                  const DeviceMemory<std::complex<double>> &a, int lda,        \\\n-                  DeviceMemory<std::complex<double>> *b, int ldb) override;    \\\n+                  const DeviceMemory<std::complex<double>>& a, int lda,        \\\n+                  DeviceMemory<std::complex<double>>* b, int ldb) override;    \\\n   bool DoBlasTrsmBatched(                                                      \\\n-      Stream *stream, blas::Side side, blas::UpperLower uplo,                  \\\n+      Stream* stream, blas::Side side, blas::UpperLower uplo,                  \\\n       blas::Transpose transa, blas::Diagonal diag, uint64_t m, uint64_t n,     \\\n-      float alpha, const DeviceMemory<float *> &as, int lda,                   \\\n-      DeviceMemory<float *> *bs, int ldb, int batch_count) override;           \\\n+      float alpha, const DeviceMemory<float*>& as, int lda,                    \\\n+      DeviceMemory<float*>* bs, int ldb, int batch_count) override;            \\\n   bool DoBlasTrsmBatched(                                                      \\\n-      Stream *stream, blas::Side side, blas::UpperLower uplo,                  \\\n+      Stream* stream, blas::Side side, blas::UpperLower uplo,                  \\\n       blas::Transpose transa, blas::Diagonal diag, uint64_t m, uint64_t n,     \\\n-      double alpha, const DeviceMemory<double *> &as, int lda,                 \\\n-      DeviceMemory<double *> *bs, int ldb, int batch_count) override;          \\\n-  bool DoBlasTrsmBatched(Stream *stream, blas::Side side,                      \\\n-                         blas::UpperLower uplo, blas::Transpose transa,        \\\n-                         blas::Diagonal diag, uint64_t m, uint64_t n,          \\\n-                         std::complex<float> alpha,                            \\\n-                         const DeviceMemory<std::complex<float> *> &as,        \\\n-                         int lda, DeviceMemory<std::complex<float> *> *bs,     \\\n-                         int ldb, int batch_count) override;                   \\\n-  bool DoBlasTrsmBatched(Stream *stream, blas::Side side,                      \\\n+      double alpha, const DeviceMemory<double*>& as, int lda,                  \\\n+      DeviceMemory<double*>* bs, int ldb, int batch_count) override;           \\\n+  bool DoBlasTrsmBatched(                                                      \\\n+      Stream* stream, blas::Side side, blas::UpperLower uplo,                  \\\n+      blas::Transpose transa, blas::Diagonal diag, uint64_t m, uint64_t n,     \\\n+      std::complex<float> alpha, const DeviceMemory<std::complex<float>*>& as, \\\n+      int lda, DeviceMemory<std::complex<float>*>* bs, int ldb,                \\\n+      int batch_count) override;                                               \\\n+  bool DoBlasTrsmBatched(Stream* stream, blas::Side side,                      \\\n                          blas::UpperLower uplo, blas::Transpose transa,        \\\n                          blas::Diagonal diag, uint64_t m, uint64_t n,          \\\n                          std::complex<double> alpha,                           \\\n-                         const DeviceMemory<std::complex<double> *> &as,       \\\n-                         int lda, DeviceMemory<std::complex<double> *> *bs,    \\\n+                         const DeviceMemory<std::complex<double>*>& as,        \\\n+                         int lda, DeviceMemory<std::complex<double>*>* bs,     \\\n                          int ldb, int batch_count) override;                   \\\n-  absl::Status GetVersion(std::string *version) override;\n+  absl::Status GetVersion(std::string* version) override;\n \n }  // namespace blas\n }  // namespace stream_executor"
        },
        {
            "sha": "ad3e8bf0d28d6adb12ef2b07feffda6669030f04",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -280,9 +280,9 @@ cc_library(\n         \"//xla/stream_executor:blas\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:engine_options\",\n         \"//xla/stream_executor:event_based_timer\",\n         \"//xla/stream_executor:host_or_device_scalar\",\n-        \"//xla/stream_executor:numeric_options\",\n         \"//xla/stream_executor:plugin_registry\",\n         \"//xla/stream_executor:scratch_allocator\",\n         \"//xla/stream_executor:stream\",\n@@ -551,8 +551,8 @@ cc_library(\n         \"//xla/stream_executor:data_type\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:dnn\",\n+        \"//xla/stream_executor:engine_options\",\n         \"//xla/stream_executor:event_based_timer\",\n-        \"//xla/stream_executor:numeric_options\",\n         \"//xla/stream_executor:plugin_registry\",\n         \"//xla/stream_executor:scratch_allocator\",\n         \"//xla/stream_executor:semantic_version\",\n@@ -1575,7 +1575,7 @@ xla_test(\n         \"//xla/stream_executor:command_buffer\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:dnn\",\n-        \"//xla/stream_executor:numeric_options\",\n+        \"//xla/stream_executor:engine_options\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:platform_manager\",\n         \"//xla/stream_executor:stream\","
        },
        {
            "sha": "0844a5ed982d8a5bbeb90776ac819ea0ea313c3f",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_blas.cc",
            "status": "modified",
            "additions": 62,
            "deletions": 61,
            "changes": 123,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_blas.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_blas.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_blas.cc?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -48,9 +48,9 @@ limitations under the License.\n #include \"xla/stream_executor/cuda/cuda_helpers.h\"\n #include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n #include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/event_based_timer.h\"\n #include \"xla/stream_executor/gpu/gpu_helpers.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n #include \"xla/stream_executor/platform/initialize.h\"\n #include \"xla/stream_executor/plugin_registry.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n@@ -515,12 +515,14 @@ bool CUDABlas::DoBlasGemv(Stream *stream, blas::Transpose trans, uint64_t m,\n                         CUDAComplex(GpuMemoryMutable(y)), incy);\n }\n \n-absl::Status CUDABlas::DoBlasGemm(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n-    uint64_t n, uint64_t k, blas::DataType dtype, const void *alpha,\n-    const DeviceMemoryBase &a, int lda, const DeviceMemoryBase &b, int ldb,\n-    const void *beta, DeviceMemoryBase *c, int ldc,\n-    const NumericOptions &numeric_options, blas::CallContext context) {\n+absl::Status CUDABlas::DoBlasGemm(Stream* stream, blas::Transpose transa,\n+                                  blas::Transpose transb, uint64_t m,\n+                                  uint64_t n, uint64_t k, blas::DataType dtype,\n+                                  const void* alpha, const DeviceMemoryBase& a,\n+                                  int lda, const DeviceMemoryBase& b, int ldb,\n+                                  const void* beta, DeviceMemoryBase* c,\n+                                  int ldc, const EngineOptions& engine_options,\n+                                  blas::CallContext context) {\n   cublasMath_t math_type = CUBLAS_DEFAULT_MATH;\n \n #if CUDA_VERSION < 11000\n@@ -530,7 +532,7 @@ absl::Status CUDABlas::DoBlasGemm(\n #else\n   if (dtype == blas::DataType::kFloat) {\n     math_type = CUBLAS_TF32_TENSOR_OP_MATH;\n-    if (!numeric_options.allow_tf32) {\n+    if (!engine_options.allow_tf32) {\n       math_type = CUBLAS_DEFAULT_MATH;\n     }\n   }\n@@ -643,8 +645,8 @@ static bool UsesTensorOps(blas::AlgorithmType algo) {\n }\n \n static absl::StatusOr<cublasMath_t> GetMathTypeForGemmEx(\n-    Stream *stream, blas::AlgorithmType algorithm, blas::DataType type_a,\n-    blas::DataType type_b, const NumericOptions &numeric_options) {\n+    Stream* stream, blas::AlgorithmType algorithm, blas::DataType type_a,\n+    blas::DataType type_b, const EngineOptions& engine_options) {\n   if (type_a != type_b) {\n     return absl::InternalError(\"Types of inputs mismatch\");\n   }\n@@ -688,7 +690,7 @@ static absl::StatusOr<cublasMath_t> GetMathTypeForGemmEx(\n                        \" uses tensor ops which are not supported for input\"));\n     }\n   }\n-  if (!numeric_options.allow_tf32) {\n+  if (!engine_options.allow_tf32) {\n     math_type = CUBLAS_DEFAULT_MATH;\n   }\n \n@@ -709,16 +711,16 @@ static absl::Status PopulateProfileFromTimer(\n }\n \n absl::Status CUDABlas::DoBlasGemmWithAlgorithm(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n-    uint64_t n, uint64_t k, const void *alpha, const DeviceMemoryBase &a,\n-    blas::DataType type_a, int lda, const DeviceMemoryBase &b,\n-    blas::DataType type_b, int ldb, const void *beta, DeviceMemoryBase *c,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    uint64_t n, uint64_t k, const void* alpha, const DeviceMemoryBase& a,\n+    blas::DataType type_a, int lda, const DeviceMemoryBase& b,\n+    blas::DataType type_b, int ldb, const void* beta, DeviceMemoryBase* c,\n     blas::DataType type_c, int ldc, blas::ComputationType computation_type,\n-    blas::AlgorithmType algorithm, const NumericOptions &numeric_options,\n-    blas::ProfileResult *output_profile_result, blas::CallContext context) {\n+    blas::AlgorithmType algorithm, const EngineOptions& engine_options,\n+    blas::ProfileResult* output_profile_result, blas::CallContext context) {\n   TF_ASSIGN_OR_RETURN(\n       cublasMath_t math_type,\n-      GetMathTypeForGemmEx(stream, algorithm, type_a, type_b, numeric_options));\n+      GetMathTypeForGemmEx(stream, algorithm, type_a, type_b, engine_options));\n \n   std::unique_ptr<EventBasedTimer> timer;\n   if (output_profile_result != nullptr) {\n@@ -744,17 +746,17 @@ absl::Status CUDABlas::DoBlasGemmWithAlgorithm(\n }\n \n absl::Status CUDABlas::DoBlasGemmStridedBatchedWithAlgorithm(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n-    uint64_t n, uint64_t k, const void *alpha, const DeviceMemoryBase &a,\n-    blas::DataType type_a, int lda, int64_t stride_a, const DeviceMemoryBase &b,\n-    blas::DataType type_b, int ldb, int64_t stride_b, const void *beta,\n-    DeviceMemoryBase *c, blas::DataType type_c, int ldc, int64_t stride_c,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    uint64_t n, uint64_t k, const void* alpha, const DeviceMemoryBase& a,\n+    blas::DataType type_a, int lda, int64_t stride_a, const DeviceMemoryBase& b,\n+    blas::DataType type_b, int ldb, int64_t stride_b, const void* beta,\n+    DeviceMemoryBase* c, blas::DataType type_c, int ldc, int64_t stride_c,\n     int batch_count, blas::ComputationType computation_type,\n-    blas::AlgorithmType algorithm, const NumericOptions &numeric_options,\n-    blas::ProfileResult *output_profile_result, blas::CallContext context) {\n+    blas::AlgorithmType algorithm, const EngineOptions& engine_options,\n+    blas::ProfileResult* output_profile_result, blas::CallContext context) {\n   TF_ASSIGN_OR_RETURN(\n       cublasMath_t math_type,\n-      GetMathTypeForGemmEx(stream, algorithm, type_a, type_b, numeric_options));\n+      GetMathTypeForGemmEx(stream, algorithm, type_a, type_b, engine_options));\n   std::unique_ptr<EventBasedTimer> timer;\n   if (output_profile_result != nullptr) {\n     TF_ASSIGN_OR_RETURN(timer,\n@@ -912,13 +914,12 @@ T inline CUDAComplexValue(T v) {\n \n template <typename T, typename Scalar, typename FuncT>\n absl::Status CUDABlas::DoBlasGemmBatchedInternal(\n-    FuncT cublas_func, Stream *stream, blas::Transpose transa,\n+    FuncT cublas_func, Stream* stream, blas::Transpose transa,\n     blas::Transpose transb, uint64_t m, uint64_t n, uint64_t k, Scalar alpha,\n-    const DeviceMemorySlice<T> &a_ptrs_to_wrappers, int lda,\n-    const DeviceMemorySlice<T> &b_ptrs_to_wrappers, int ldb, Scalar beta,\n-    const DeviceMemorySlice<T> &c_ptrs_to_wrappers, int ldc, int batch_count,\n-    const NumericOptions &numeric_options,\n-    ScratchAllocator *scratch_allocator) {\n+    const DeviceMemorySlice<T>& a_ptrs_to_wrappers, int lda,\n+    const DeviceMemorySlice<T>& b_ptrs_to_wrappers, int ldb, Scalar beta,\n+    const DeviceMemorySlice<T>& c_ptrs_to_wrappers, int ldc, int batch_count,\n+    const EngineOptions& engine_options, ScratchAllocator* scratch_allocator) {\n   std::vector<T *> a_raw_ptrs, b_raw_ptrs, c_raw_ptrs;\n   for (int i = 0; i < batch_count; ++i) {\n     a_raw_ptrs.push_back(static_cast<T *>(a_ptrs_to_wrappers[i]->opaque()));\n@@ -968,7 +969,7 @@ absl::Status CUDABlas::DoBlasGemmBatchedInternal(\n       algo = CUBLAS_GEMM_DFALT_TENSOR_OP;\n #if CUBLAS_VER_MAJOR >= 11\n     } else if (data_type == CUDA_R_32F) {\n-      if (numeric_options.allow_tf32 &&\n+      if (engine_options.allow_tf32 &&\n           tsl::tensor_float_32_execution_enabled()) {\n         math_type = CUBLAS_TENSOR_OP_MATH;\n         algo = CUBLAS_GEMM_DFALT_TENSOR_OP;\n@@ -1016,25 +1017,25 @@ absl::Status CUDABlas::DoBlasGemmBatchedInternal(\n       DeviceMemory<T> *c_matrix = c_ptrs_to_wrappers[b];\n       TF_RETURN_IF_ERROR(DoBlasGemm(\n           stream, transa, transb, m, n, k, blas::ToDataType<T>::value, &alpha,\n-          a_matrix, lda, b_matrix, ldb, &beta, c_matrix, ldc, numeric_options,\n+          a_matrix, lda, b_matrix, ldb, &beta, c_matrix, ldc, engine_options,\n           blas::CallContext::kNone));\n     }\n     return absl::OkStatus();\n   }\n }\n \n bool CUDABlas::DoBlasGemmBatched(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n     uint64_t n, uint64_t k, float alpha, DeviceMemorySlice<Eigen::half> a_array,\n     int lda, DeviceMemorySlice<Eigen::half> b_array, int ldb, float beta,\n     DeviceMemorySlice<Eigen::half> c_array, int ldc, int batch_count,\n-    const NumericOptions &numeric_options, ScratchAllocator *scratch_allocator,\n+    const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n     blas::CallContext context) {\n   // Note: The func passed here (cublasSgemmBatched) is not actually called,\n   // due to special handling of fp16 inside DoBlasGemmBatchedInternal.\n   absl::Status status = DoBlasGemmBatchedInternal(\n       cublasSgemmBatched, stream, transa, transb, m, n, k, alpha, a_array, lda,\n-      b_array, ldb, beta, c_array, ldc, batch_count, numeric_options,\n+      b_array, ldb, beta, c_array, ldc, batch_count, engine_options,\n       scratch_allocator);\n   if (!status.ok()) {\n     LOG(ERROR) << status;\n@@ -1043,18 +1044,18 @@ bool CUDABlas::DoBlasGemmBatched(\n }\n \n bool CUDABlas::DoBlasGemmBatched(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n     uint64_t n, uint64_t k, float alpha,\n     DeviceMemorySlice<Eigen::bfloat16> a_array, int lda,\n     DeviceMemorySlice<Eigen::bfloat16> b_array, int ldb, float beta,\n     DeviceMemorySlice<Eigen::bfloat16> c_array, int ldc, int batch_count,\n-    const NumericOptions &numeric_options, ScratchAllocator *scratch_allocator,\n+    const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n     blas::CallContext context) {\n   // Note: The func passed here (cublasSgemmBatched) is not actually called,\n   // due to special handling of bf16 inside DoBlasGemmBatchedInternal.\n   absl::Status status = DoBlasGemmBatchedInternal(\n       cublasSgemmBatched, stream, transa, transb, m, n, k, alpha, a_array, lda,\n-      b_array, ldb, beta, c_array, ldc, batch_count, numeric_options,\n+      b_array, ldb, beta, c_array, ldc, batch_count, engine_options,\n       scratch_allocator);\n   if (!status.ok()) {\n     LOG(ERROR) << status;\n@@ -1063,15 +1064,15 @@ bool CUDABlas::DoBlasGemmBatched(\n }\n \n bool CUDABlas::DoBlasGemmBatched(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n     uint64_t n, uint64_t k, float alpha, DeviceMemorySlice<float> a_array,\n     int lda, DeviceMemorySlice<float> b_array, int ldb, float beta,\n     DeviceMemorySlice<float> c_array, int ldc, int batch_count,\n-    const NumericOptions &numeric_options, ScratchAllocator *scratch_allocator,\n+    const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n     blas::CallContext context) {\n   absl::Status status = DoBlasGemmBatchedInternal(\n       cublasSgemmBatched, stream, transa, transb, m, n, k, alpha, a_array, lda,\n-      b_array, ldb, beta, c_array, ldc, batch_count, numeric_options,\n+      b_array, ldb, beta, c_array, ldc, batch_count, engine_options,\n       scratch_allocator);\n   if (!status.ok()) {\n     LOG(ERROR) << status;\n@@ -1080,15 +1081,15 @@ bool CUDABlas::DoBlasGemmBatched(\n }\n \n bool CUDABlas::DoBlasGemmBatched(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n     uint64_t n, uint64_t k, double alpha, DeviceMemorySlice<double> a_array,\n     int lda, DeviceMemorySlice<double> b_array, int ldb, double beta,\n     DeviceMemorySlice<double> c_array, int ldc, int batch_count,\n-    const NumericOptions &numeric_options, ScratchAllocator *scratch_allocator,\n+    const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n     blas::CallContext context) {\n   absl::Status status = DoBlasGemmBatchedInternal(\n       cublasDgemmBatched, stream, transa, transb, m, n, k, alpha, a_array, lda,\n-      b_array, ldb, beta, c_array, ldc, batch_count, numeric_options,\n+      b_array, ldb, beta, c_array, ldc, batch_count, engine_options,\n \n       scratch_allocator);\n   if (!status.ok()) {\n@@ -1098,16 +1099,16 @@ bool CUDABlas::DoBlasGemmBatched(\n }\n \n bool CUDABlas::DoBlasGemmBatched(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n     uint64_t n, uint64_t k, std::complex<float> alpha,\n     DeviceMemorySlice<std::complex<float>> a_array, int lda,\n     DeviceMemorySlice<std::complex<float>> b_array, int ldb,\n     std::complex<float> beta, DeviceMemorySlice<std::complex<float>> c_array,\n-    int ldc, int batch_count, const NumericOptions &numeric_options,\n-    ScratchAllocator *scratch_allocator, blas::CallContext context) {\n+    int ldc, int batch_count, const EngineOptions& engine_options,\n+    ScratchAllocator* scratch_allocator, blas::CallContext context) {\n   absl::Status status = DoBlasGemmBatchedInternal(\n       cublasCgemmBatched, stream, transa, transb, m, n, k, alpha, a_array, lda,\n-      b_array, ldb, beta, c_array, ldc, batch_count, numeric_options,\n+      b_array, ldb, beta, c_array, ldc, batch_count, engine_options,\n \n       scratch_allocator);\n   if (!status.ok()) {\n@@ -1117,16 +1118,16 @@ bool CUDABlas::DoBlasGemmBatched(\n }\n \n bool CUDABlas::DoBlasGemmBatched(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n     uint64_t n, uint64_t k, std::complex<double> alpha,\n     DeviceMemorySlice<std::complex<double>> a_array, int lda,\n     DeviceMemorySlice<std::complex<double>> b_array, int ldb,\n     std::complex<double> beta, DeviceMemorySlice<std::complex<double>> c_array,\n-    int ldc, int batch_count, const NumericOptions &numeric_options,\n-    ScratchAllocator *scratch_allocator, blas::CallContext context) {\n+    int ldc, int batch_count, const EngineOptions& engine_options,\n+    ScratchAllocator* scratch_allocator, blas::CallContext context) {\n   absl::Status status = DoBlasGemmBatchedInternal(\n       cublasZgemmBatched, stream, transa, transb, m, n, k, alpha, a_array, lda,\n-      b_array, ldb, beta, c_array, ldc, batch_count, numeric_options,\n+      b_array, ldb, beta, c_array, ldc, batch_count, engine_options,\n       scratch_allocator);\n   if (!status.ok()) {\n     LOG(ERROR) << status;\n@@ -1135,19 +1136,19 @@ bool CUDABlas::DoBlasGemmBatched(\n }\n \n absl::Status CUDABlas::DoBlasGemmStridedBatched(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n-    uint64_t n, uint64_t k, blas::DataType dtype, const void *alpha,\n-    const DeviceMemoryBase &a, int lda, int64_t stride_a,\n-    const DeviceMemoryBase &b, int ldb, int64_t stride_b, const void *beta,\n-    DeviceMemoryBase *c, int ldc, int64_t stride_c, int batch_count,\n-    const NumericOptions &numeric_options, blas::CallContext context) {\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    uint64_t n, uint64_t k, blas::DataType dtype, const void* alpha,\n+    const DeviceMemoryBase& a, int lda, int64_t stride_a,\n+    const DeviceMemoryBase& b, int ldb, int64_t stride_b, const void* beta,\n+    DeviceMemoryBase* c, int ldc, int64_t stride_c, int batch_count,\n+    const EngineOptions& engine_options, blas::CallContext context) {\n   cublasMath_t math_type = CUBLAS_DEFAULT_MATH;\n #if CUDA_VERSION < 11000\n   if (dtype == dnn::kHalf) {\n     math_type = CUBLAS_TENSOR_OP_MATH;\n   }\n #else\n-  if (dtype == dnn::kFloat && numeric_options.allow_tf32) {\n+  if (dtype == dnn::kFloat && engine_options.allow_tf32) {\n     math_type = CUBLAS_TF32_TENSOR_OP_MATH;\n   }\n #endif"
        },
        {
            "sha": "eb1ad5c6f82b8aeff0f3d8fca700403b1231404f",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_blas.h",
            "status": "modified",
            "additions": 6,
            "deletions": 7,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_blas.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_blas.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_blas.h?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -29,7 +29,7 @@ limitations under the License.\n #include \"third_party/gpus/cuda/include/driver_types.h\"\n #include \"xla/stream_executor/blas.h\"\n #include \"xla/stream_executor/cuda/cuda_blas_lt.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -97,13 +97,12 @@ class CUDABlas : public blas::BlasSupport {\n   // types.\n   template <typename T, typename Scalar, typename FuncT>\n   absl::Status DoBlasGemmBatchedInternal(\n-      FuncT cublas_func, Stream *stream, blas::Transpose transa,\n+      FuncT cublas_func, Stream* stream, blas::Transpose transa,\n       blas::Transpose transb, uint64_t m, uint64_t n, uint64_t k, Scalar alpha,\n-      const DeviceMemorySlice<T> &a_array, int lda,\n-      const DeviceMemorySlice<T> &b_array, int ldb, Scalar beta,\n-      const DeviceMemorySlice<T> &c_array, int ldc, int batch_count,\n-      const NumericOptions &numeric_options,\n-      ScratchAllocator *scratch_allocator);\n+      const DeviceMemorySlice<T>& a_array, int lda,\n+      const DeviceMemorySlice<T>& b_array, int ldb, Scalar beta,\n+      const DeviceMemorySlice<T>& c_array, int ldc, int batch_count,\n+      const EngineOptions& engine_options, ScratchAllocator* scratch_allocator);\n \n   // Guards the cuBLAS handle for this device.\n   mutable absl::Mutex mu_;"
        },
        {
            "sha": "7a735b5384949ab8e933540a2888337a579184a9",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_command_buffer_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_command_buffer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_command_buffer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_command_buffer_test.cc?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -32,7 +32,7 @@ limitations under the License.\n #include \"xla/stream_executor/cuda/cuda_dnn.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/dnn.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n #include \"xla/stream_executor/stream.h\"\n@@ -94,7 +94,10 @@ TEST(CudaCommandBufferTest, CuDnnExplicitConstructionAndUpdateWork) {\n         .set_uid(3);\n     return graph;\n   }());\n-  TF_ASSERT_OK(graph.Prepare(dnn_support, NumericOptions{}));\n+  TF_ASSERT_OK(graph.Prepare(dnn_support,\n+                             EngineOptions{/*require_determinism=*/false,\n+                                           /*allow_tf32=*/true,\n+                                           /*require_command_buffer=*/true}));\n   TF_ASSERT_OK(graph.Build(dnn_support, /*plan_id=*/std::nullopt));\n   EXPECT_THAT(graph.SupportsExplicitCommandBufferConstruction(),\n               absl_testing::IsOkAndHolds(true));"
        },
        {
            "sha": "d22e9c6ac714e63c9cabd22e3d9c18950a0d7c6d",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc",
            "status": "modified",
            "additions": 62,
            "deletions": 53,
            "changes": 115,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_dnn.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_dnn.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_dnn.cc?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -63,8 +63,8 @@ limitations under the License.\n #include \"xla/stream_executor/data_type.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/dnn.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/event_based_timer.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n #include \"xla/stream_executor/platform/initialize.h\"\n #include \"xla/stream_executor/plugin_registry.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n@@ -945,7 +945,7 @@ class CudnnPoolingDescriptor {\n  public:\n   explicit CudnnPoolingDescriptor(\n       const dnn::PoolingDescriptor& pooling_descriptor,\n-      const NumericOptions& numeric_options)\n+      const EngineOptions& engine_options)\n       : handle_(CreatePoolingDescriptor()) {\n     absl::Span<const int64_t> strides64 = pooling_descriptor.strides();\n     absl::Span<const int64_t> padding64 = pooling_descriptor.padding();\n@@ -962,7 +962,7 @@ class CudnnPoolingDescriptor {\n     std::transform(shape64.cbegin(), shape64.cend(), shape.begin(),\n                    &CheckedNarrowing<int64_t, int>);\n     bool propagate_nans = pooling_descriptor.propagate_nans();\n-    const auto cudnn_max_pooling_mode = numeric_options.require_determinism\n+    const auto cudnn_max_pooling_mode = engine_options.require_determinism\n                                             ? CUDNN_POOLING_MAX_DETERMINISTIC\n                                             : CUDNN_POOLING_MAX;\n     CHECK_CUDNN_OK(cudnnSetPoolingNdDescriptor(\n@@ -1301,7 +1301,7 @@ class CudnnRnnDescriptor : public dnn::RnnDescriptor {\n       cudnnDirectionMode_t direction_mode, cudnnRNNMode_t rnn_mode,\n       cudnnDataType_t data_type, cudnnDataType_t compute_type,\n       const dnn::AlgorithmConfig& algorithm_config,\n-      const NumericOptions& numeric_options, float dropout, uint64_t seed,\n+      const EngineOptions& engine_options, float dropout, uint64_t seed,\n       ScratchAllocator* state_allocator, bool use_padded_io) {\n     TF_ASSIGN_OR_RETURN(\n         CudnnDropoutDescriptor dropout_desc,\n@@ -1324,8 +1324,8 @@ class CudnnRnnDescriptor : public dnn::RnnDescriptor {\n     // TODO(csigg): Minimal support cuDNN version is 7.3, clean up.\n     bool allow_tensor_ops = data_type == CUDNN_DATA_HALF;\n     if (data_type == CUDNN_DATA_FLOAT)\n-      allow_tensor_ops = numeric_options.allow_tf32 &&\n-                         tsl::tensor_float_32_execution_enabled();\n+      allow_tensor_ops =\n+          engine_options.allow_tf32 && tsl::tensor_float_32_execution_enabled();\n     bool use_tensor_ops =\n         algorithm_config.algorithm().has_value()\n             ? algorithm_config.algorithm()->tensor_ops_enabled()\n@@ -2263,7 +2263,7 @@ CudnnSupport::CreateRnnDescriptor(\n     int batch_size, dnn::RnnInputMode input_mode,\n     dnn::RnnDirectionMode direction_mode, dnn::RnnMode rnn_mode,\n     dnn::DataType data_type, const dnn::AlgorithmConfig& algorithm_config,\n-    const NumericOptions& numeric_options, float dropout, uint64_t seed,\n+    const EngineOptions& engine_options, float dropout, uint64_t seed,\n     ScratchAllocator* state_allocator, bool use_padded_io) {\n   // Setting up a cudnnRNNDescriptor requires a cuDNN handle, but because it's\n   // not enqueueing anything into a stream, we pass in the null stream.\n@@ -2275,7 +2275,7 @@ CudnnSupport::CreateRnnDescriptor(\n           ToCudnnRnnInputMode(input_mode),\n           ToCudnnRnnDirectionMode(direction_mode), ToCudnnRnnMode(rnn_mode),\n           ToCudnnDataType(data_type), GetRnnComputeType(data_type),\n-          algorithm_config, numeric_options, dropout, seed, state_allocator,\n+          algorithm_config, engine_options, dropout, seed, state_allocator,\n           use_padded_io));\n   return std::unique_ptr<dnn::RnnDescriptor>(\n       new CudnnRnnDescriptor(std::move(rnn_desc)));\n@@ -4245,8 +4245,9 @@ absl::StatusOr<CudnnGraph> GetCudnnFlashAttentionOperationGraph(\n   }\n   CudnnGraph cudnnGraph(std::move(graph));\n   TF_RETURN_IF_ERROR(cudnnGraph.Prepare(\n-      dnn_support, NumericOptions{/*require_determinism=*/false,\n-                                  /*allow_tf32=*/true}));\n+      dnn_support, EngineOptions{/*require_determinism=*/false,\n+                                 /*allow_tf32=*/true,\n+                                 /*require_command_buffer=*/false}));\n   TF_RETURN_IF_ERROR(cudnnGraph.Build(dnn_support, /*plan_id=*/std::nullopt));\n \n   VLOG(4) << \"\\b flash attention operation graph: \" << cudnnGraph.Graph();\n@@ -4391,8 +4392,9 @@ absl::StatusOr<CudnnGraph> GetCudnnFlashAttentionF8OperationGraph(\n   }\n   CudnnGraph cudnnGraph(std::move(graph));\n   TF_RETURN_IF_ERROR(cudnnGraph.Prepare(\n-      dnn_support, NumericOptions{/*require_determinism=*/false,\n-                                  /*allow_tf32=*/true}));\n+      dnn_support, EngineOptions{/*require_determinism=*/false,\n+                                 /*allow_tf32=*/true,\n+                                 /*require_command_buffer=*/false}));\n   TF_RETURN_IF_ERROR(cudnnGraph.Build(dnn_support, /*plan_id=*/std::nullopt));\n \n   VLOG(4) << \"\\b workspace size:\" << cudnnGraph.Graph().get_workspace_size();\n@@ -4580,8 +4582,9 @@ absl::StatusOr<CudnnGraph> GetCudnnFlashAttentionBackwardF8OperationGraph(\n \n   CudnnGraph cudnnGraph(std::move(graph));\n   TF_RETURN_IF_ERROR(cudnnGraph.Prepare(\n-      dnn_support, NumericOptions{/*require_determinism=*/false,\n-                                  /*allow_tf32=*/true}));\n+      dnn_support, EngineOptions{/*require_determinism=*/false,\n+                                 /*allow_tf32=*/true,\n+                                 /*require_command_buffer=*/false}));\n   TF_RETURN_IF_ERROR(cudnnGraph.Build(dnn_support, /*plan_id=*/std::nullopt));\n \n   VLOG(4) << \"\\b workspace size:\" << cudnnGraph.Graph().get_workspace_size();\n@@ -4686,8 +4689,9 @@ absl::StatusOr<CudnnGraph> GetCudnnBlockScaledDotOperationGraph(\n \n   CudnnGraph cudnnGraph(std::move(graph));\n   TF_RETURN_IF_ERROR(cudnnGraph.Prepare(\n-      dnn_support, NumericOptions{/*require_determinism=*/false,\n-                                  /*allow_tf32=*/true}));\n+      dnn_support, EngineOptions{/*require_determinism=*/false,\n+                                 /*allow_tf32=*/true,\n+                                 /*require_command_buffer=*/false}));\n   TF_RETURN_IF_ERROR(cudnnGraph.Build(dnn_support, /*plan_id=*/std::nullopt));\n \n   VLOG(4) << \"\\b workspace size:\" << cudnnGraph.Graph().get_workspace_size();\n@@ -4978,9 +4982,10 @@ absl::StatusOr<CudnnGraph> GetCudnnFlashAttentionBackwardOperationGraph(\n   }\n \n   CudnnGraph cudnnGraph(std::move(graph));\n-  TF_RETURN_IF_ERROR(\n-      cudnnGraph.Prepare(dnn_support, NumericOptions{force_deterministic,\n-                                                     /*allow_tf32=*/true}));\n+  TF_RETURN_IF_ERROR(cudnnGraph.Prepare(\n+      dnn_support, EngineOptions{force_deterministic,\n+                                 /*allow_tf32=*/true,\n+                                 /*require_command_buffer=*/false}));\n   TF_RETURN_IF_ERROR(cudnnGraph.Build(dnn_support, /*plan_id=*/std::nullopt));\n \n   VLOG(4) << \"\\b flash attention operation backward graph: \"\n@@ -5377,19 +5382,19 @@ absl::Status CreateOpRunners(\n     dnn::ConvolutionKind kind, dnn::DataType input_type,\n     absl::Span<const int64_t> input_uids, bool use_fallback,\n     std::vector<std::unique_ptr<const dnn::OpRunner<Sig>>>* out_runners,\n-    bool need_side_input, const NumericOptions& numeric_options) {\n+    bool need_side_input, const EngineOptions& engine_options) {\n   cudnn_frontend::EngineConfigList filtered_configs;\n   const bool disable_winograd = !CudnnEnvVar<WinogradNonfused>::IsEnabled();\n   const bool disable_tensor_core =\n-      !IsTensorMathEnabled(stream, input_type, numeric_options.allow_tf32);\n+      !IsTensorMathEnabled(stream, input_type, engine_options.allow_tf32);\n   auto generic_filter_fn = [=](cudnnBackendDescriptor_t engine_config) -> bool {\n     return GenericEngineFilter(engine_config, disable_winograd,\n-                               numeric_options.require_determinism,\n+                               engine_options.require_determinism,\n                                disable_tensor_core);\n   };\n   VLOG(4) << \"Filtering engine configs with disable_winograd=\"\n           << disable_winograd\n-          << \", disable_nondeterminism=\" << numeric_options.require_determinism\n+          << \", disable_nondeterminism=\" << engine_options.require_determinism\n           << \", disable_tensor_core=\" << disable_tensor_core;\n \n   std::array<std::string, 1> heur_mode = {use_fallback ? \"heuristics_fallback\"\n@@ -5473,7 +5478,7 @@ absl::Status CreateOpRunners(\n         std::move(runner_or).value()));\n \n     // We will use the first working plan when determinism is required.\n-    if (numeric_options.require_determinism) {\n+    if (engine_options.require_determinism) {\n       break;\n     }\n   }\n@@ -5496,7 +5501,7 @@ absl::Status CudnnSupport::GetConvolveRunners(\n     DeviceMemoryBase /*output_data*/,\n     const dnn::ConvolutionDescriptor& convolution_descriptor, bool use_fallback,\n     ScratchAllocator* /*scratch_allocator*/,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     std::vector<std::unique_ptr<const dnn::ConvRunner>>* out_exec_plans) {\n   auto cudnn = cudnn_->GetHandle(parent_, stream);\n   TF_ASSIGN_OR_RETURN(\n@@ -5508,7 +5513,7 @@ absl::Status CudnnSupport::GetConvolveRunners(\n   return CreateOpRunners<dnn::ConvSignature>(\n       stream, cudnn, parent_, cudnn_.get(), std::move(op_graph), kind,\n       input_type, {'x', 'w', 'y'}, use_fallback, out_exec_plans,\n-      /*need_side_input=*/false, numeric_options);\n+      /*need_side_input=*/false, engine_options);\n }\n \n absl::Status CudnnSupport::GetGraphConvolveRunners(\n@@ -5518,7 +5523,7 @@ absl::Status CudnnSupport::GetGraphConvolveRunners(\n     const dnn::FilterDescriptor& filter_descriptor,\n     const dnn::BatchDescriptor& output_descriptor,\n     const dnn::ConvolutionDescriptor& convolution_descriptor, bool use_fallback,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     std::vector<std::unique_ptr<const dnn::GraphConvRunner>>* out_exec_plans,\n     std::string serialized_graph) {\n   auto cudnn = cudnn_->GetHandle(parent_, stream);\n@@ -5530,7 +5535,7 @@ absl::Status CudnnSupport::GetGraphConvolveRunners(\n   return CreateOpRunners<dnn::GraphConvSignature>(\n       stream, cudnn, parent_, cudnn_.get(), std::move(op_graph_and_uids.first),\n       kind, input_type, op_graph_and_uids.second, use_fallback, out_exec_plans,\n-      /*need_side_input=*/false, numeric_options);\n+      /*need_side_input=*/false, engine_options);\n }\n \n absl::StatusOr<std::unique_ptr<const dnn::ConvRunner>>\n@@ -5635,7 +5640,7 @@ absl::Status CudnnSupport::GetFusedConvolveRunners(\n     const dnn::BatchDescriptor& output_descriptor,\n     const dnn::ConvolutionDescriptor& convolution_descriptor, bool use_fallback,\n     const dnn::ActivationMode activation_mode,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     std::vector<std::unique_ptr<const dnn::FusedConvRunner>>* out_exec_plans) {\n   // Fused convolutions with identity activations are broken in that they\n   // implicitly do ReLU on some engines, and we can't reliably detect which\n@@ -5674,15 +5679,15 @@ absl::Status CudnnSupport::GetFusedConvolveRunners(\n   return CreateOpRunners<dnn::FusedConvSignature>(\n       stream, cudnn, parent_, cudnn_.get(), std::move(op_graph), kind,\n       input_type, {'x', 'w', 'z', 'b', 'y'}, use_fallback, out_exec_plans,\n-      need_side_input, numeric_options);\n+      need_side_input, engine_options);\n }\n \n absl::Status CudnnSupport::GetFusedMatmulRunners(\n     dnn::DataType input_type, dnn::DataType bias_type,\n     dnn::DataType output_type, Stream* stream, bool trans_a, bool trans_b,\n     uint64_t m, uint64_t n, uint64_t k, int64_t lda, int64_t ldb, int64_t ldc,\n     dnn::ActivationMode activation_mode, bool use_fallback,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     std::vector<std::unique_ptr<const dnn::FusedMatmulRunner>>*\n         out_exec_plans) {\n   auto cudnn = cudnn_->GetHandle(parent_, stream);\n@@ -5702,17 +5707,17 @@ absl::Status CudnnSupport::GetFusedMatmulRunners(\n   return CreateOpRunners<dnn::FusedMatmulSignature>(\n       stream, cudnn, parent_, cudnn_.get(), std::move(op_graph),\n       dnn::ConvolutionKind::INVALID, input_type, {'a', 'b', 'z', 'c'},\n-      use_fallback, out_exec_plans, /*need_side_input=*/true, numeric_options);\n+      use_fallback, out_exec_plans, /*need_side_input=*/true, engine_options);\n }\n \n bool CudnnSupport::GetConvolveAlgorithms(\n     CudaComputeCapability cuda_compute_capability, dnn::DataType input_type,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     std::vector<dnn::AlgorithmDesc>* out_algorithms) {\n   PreloadCudnnSubLibs(PreloadCudnnType::ConvFwd);\n \n   bool tensor_op_math_available = IsTensorMathEnabled(\n-      cuda_compute_capability, input_type, numeric_options.allow_tf32);\n+      cuda_compute_capability, input_type, engine_options.allow_tf32);\n   out_algorithms->clear();\n \n   std::vector<dnn::AlgorithmDesc::Index> algo_types;\n@@ -5914,12 +5919,12 @@ bool CudnnSupport::GetRnnAlgorithms(\n \n bool CudnnSupport::GetConvolveBackwardDataAlgorithms(\n     CudaComputeCapability cuda_compute_capability, dnn::DataType input_type,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     std::vector<dnn::AlgorithmDesc>* out_algorithms) {\n   PreloadCudnnSubLibs(PreloadCudnnType::ConvBwdData);\n \n   bool tensor_op_math_available = IsTensorMathEnabled(\n-      cuda_compute_capability, input_type, numeric_options.allow_tf32);\n+      cuda_compute_capability, input_type, engine_options.allow_tf32);\n   out_algorithms->clear();\n \n   std::vector<dnn::AlgorithmDesc::Index> algo_types = {\n@@ -5933,7 +5938,7 @@ bool CudnnSupport::GetConvolveBackwardDataAlgorithms(\n   if (CudnnEnvVar<WinogradNonfused>::IsEnabled()) {\n     algo_types.push_back(CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED);\n   }\n-  if (numeric_options.require_determinism) {\n+  if (engine_options.require_determinism) {\n     algo_types.push_back(CUDNN_CONVOLUTION_BWD_DATA_ALGO_0);\n   }\n \n@@ -5950,12 +5955,12 @@ bool CudnnSupport::GetConvolveBackwardDataAlgorithms(\n \n bool CudnnSupport::GetConvolveBackwardFilterAlgorithms(\n     CudaComputeCapability cuda_compute_capability, dnn::DataType input_type,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     std::vector<dnn::AlgorithmDesc>* out_algorithms) {\n   PreloadCudnnSubLibs(PreloadCudnnType::ConvBwdFilter);\n \n   bool tensor_op_math_available = IsTensorMathEnabled(\n-      cuda_compute_capability, input_type, numeric_options.allow_tf32);\n+      cuda_compute_capability, input_type, engine_options.allow_tf32);\n   out_algorithms->clear();\n \n   std::vector<dnn::AlgorithmDesc::Index> algo_types = {\n@@ -5973,7 +5978,7 @@ bool CudnnSupport::GetConvolveBackwardFilterAlgorithms(\n   if (CudnnEnvVar<WinogradNonfused>::IsEnabled()) {\n     algo_types.push_back(CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED);\n   }\n-  if (!numeric_options.require_determinism) {\n+  if (!engine_options.require_determinism) {\n     algo_types.push_back(CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0);\n     algo_types.push_back(CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3);\n   }\n@@ -6425,7 +6430,7 @@ absl::Status CudnnSupport::DoPrepareForCtcLoss(\n     absl::Span<const int> labels_data,\n     absl::Span<const int> labels_lengths_data,\n     absl::Span<const int> input_lengths_data,\n-    const NumericOptions& numeric_options, ScratchAllocator* scratch_allocator,\n+    const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n     DeviceMemory<uint8_t>* scratch_memory, int* ctc_loss_algo_id) {\n   auto cudnn = cudnn_->GetHandle(parent_, stream);\n   // Query the workspace size.\n@@ -6439,7 +6444,7 @@ absl::Status CudnnSupport::DoPrepareForCtcLoss(\n   // Try running with `algo`, if successful then pick it. The\n   // non-deterministic algorithm is first and thus preferentially picked\n   // when determinism is not required.\n-  auto algo = numeric_options.require_determinism\n+  auto algo = engine_options.require_determinism\n                   ? CUDNN_CTC_LOSS_ALGO_DETERMINISTIC\n                   : CUDNN_CTC_LOSS_ALGO_NON_DETERMINISTIC;\n   cudnnStatus_t status = cudnnGetCTCLossWorkspaceSize(\n@@ -6451,7 +6456,7 @@ absl::Status CudnnSupport::DoPrepareForCtcLoss(\n       /*algo=*/algo,\n       /*ctcLossDesc=*/cudnn_ctc_loss_desc.handle(),\n       /*sizeInBytes=*/&workspace_size_in_bytes);\n-  if (numeric_options.require_determinism) {\n+  if (engine_options.require_determinism) {\n     RETURN_IF_CUDNN_ERROR(status);\n   }\n \n@@ -6596,14 +6601,14 @@ absl::Status CudnnSupport::DoPoolForward(\n     const dnn::BatchDescriptor& output_dimensions, DeviceMemoryBase output_data,\n     ScratchAllocator* workspace_allocator) {\n   return DoPoolForward(element_type, stream, pooling_dimensions,\n-                       NumericOptions{}, input_dimensions, input_data,\n+                       EngineOptions{}, input_dimensions, input_data,\n                        output_dimensions, output_data, workspace_allocator);\n }\n \n absl::Status CudnnSupport::DoPoolForward(\n     dnn::DataType element_type, Stream* stream,\n     const dnn::PoolingDescriptor& pooling_dimensions,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     const dnn::BatchDescriptor& input_dimensions, DeviceMemoryBase input_data,\n     const dnn::BatchDescriptor& output_dimensions, DeviceMemoryBase output_data,\n     ScratchAllocator* workspace_allocator) {\n@@ -6624,7 +6629,7 @@ absl::Status CudnnSupport::DoPoolForward(\n       ToCudnnDataType(element_type, input_dimensions.layout());\n   cudnnDataType_t cudnn_output_type =\n       ToCudnnDataType(element_type, output_dimensions.layout());\n-  CudnnPoolingDescriptor pooling_desc(pooling_dimensions, numeric_options);\n+  CudnnPoolingDescriptor pooling_desc(pooling_dimensions, engine_options);\n   auto cudnn = cudnn_->GetHandle(parent_, stream);\n \n   auto cudnn_launcher = [&](CudnnTensorDescriptor& src_desc,\n@@ -6675,15 +6680,15 @@ absl::Status CudnnSupport::DoPoolBackward(\n     DeviceMemoryBase input_diff_data, DeviceMemoryBase output_diff_data,\n     ScratchAllocator* workspace_allocator) {\n   return DoPoolBackward(element_type, stream, pooling_dimensions,\n-                        NumericOptions{}, input_dimensions, input_data,\n+                        EngineOptions{}, input_dimensions, input_data,\n                         output_dimensions, output_data, input_diff_data,\n                         output_diff_data, workspace_allocator);\n }\n \n absl::Status CudnnSupport::DoPoolBackward(\n     dnn::DataType element_type, Stream* stream,\n     const dnn::PoolingDescriptor& pooling_dimensions,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     const dnn::BatchDescriptor& input_dimensions, DeviceMemoryBase input_data,\n     const dnn::BatchDescriptor& output_dimensions, DeviceMemoryBase output_data,\n     DeviceMemoryBase input_diff_data, DeviceMemoryBase output_diff_data,\n@@ -6705,7 +6710,7 @@ absl::Status CudnnSupport::DoPoolBackward(\n       ToCudnnDataType(element_type, input_dimensions.layout());\n   cudnnDataType_t cudnn_output_type =\n       ToCudnnDataType(element_type, output_dimensions.layout());\n-  CudnnPoolingDescriptor pooling_desc(pooling_dimensions, numeric_options);\n+  CudnnPoolingDescriptor pooling_desc(pooling_dimensions, engine_options);\n   auto cudnn = cudnn_->GetHandle(parent_, stream);\n \n   auto cudnn_launcher = [&](CudnnTensorDescriptor& src_desc,\n@@ -6864,18 +6869,22 @@ absl::StatusOr<std::unique_ptr<dnn::DnnGraph>> CudnnSupport::DeserializeGraph(\n }\n \n absl::Status CudnnGraph::Prepare(dnn::DnnSupport& dnn_support,\n-                                 const NumericOptions& numeric_options) {\n+                                 const EngineOptions& engine_options) {\n   const CudnnSupport& cudnn_support = static_cast<CudnnSupport&>(dnn_support);\n   TF_ASSIGN_OR_RETURN(auto cudnn_handle,\n                       cudnn_support.cudnn_->GetCompilationHandle());\n   RETURN_IF_CUDNN_FRONTEND_ERROR(graph_.validate());\n   RETURN_IF_CUDNN_FRONTEND_ERROR(graph_.build_operation_graph(cudnn_handle));\n-  if (numeric_options.require_determinism) {\n+  RETURN_IF_CUDNN_FRONTEND_ERROR(\n+      graph_.create_execution_plans({cudnn_frontend::HeurMode_t::A}));\n+  if (engine_options.require_determinism) {\n     graph_.deselect_numeric_notes(\n         {cudnn_frontend::NumericalNote_t::NONDETERMINISTIC});\n   }\n-  RETURN_IF_CUDNN_FRONTEND_ERROR(\n-      graph_.create_execution_plans({cudnn_frontend::HeurMode_t::A}));\n+  if (engine_options.require_command_buffer) {\n+    graph_.select_behavior_notes(\n+        {cudnn_frontend::BehaviorNote_t::SUPPORTS_CUDA_GRAPH_NATIVE_API});\n+  }\n   RETURN_CUDNN_FRONTEND_STATUS(graph_.check_support(cudnn_handle));\n }\n "
        },
        {
            "sha": "e651bf34895ca7ae705424bb491a02f3f583c408",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_dnn.h",
            "status": "modified",
            "additions": 13,
            "deletions": 14,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_dnn.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_dnn.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_dnn.h?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -35,7 +35,7 @@ limitations under the License.\n #include \"xla/stream_executor/cuda/cudnn_sdpa_score_mod.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/dnn.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/protobuf/dnn.pb.h\"\n@@ -58,7 +58,7 @@ class CudnnGraph : public dnn::DnnGraph {\n   explicit CudnnGraph(cudnn_frontend::graph::Graph&& graph)\n       : graph_(std::move(graph)) {}\n   // Prepares a graph and checks whether it is generally supported.\n-  absl::Status Prepare(dnn::DnnSupport&, const NumericOptions&) override;\n+  absl::Status Prepare(dnn::DnnSupport&, const EngineOptions&) override;\n   // Builds single plan of the graph with given ID.\n   absl::Status Build(dnn::DnnSupport&, std::optional<int64_t> plan_id) override;\n   // Builds all the plans\n@@ -106,7 +106,7 @@ class CudnnSupport : public dnn::DnnSupport {\n       int batch_size, dnn::RnnInputMode input_mode,\n       dnn::RnnDirectionMode direction_mode, dnn::RnnMode rnn_mode,\n       dnn::DataType data_type, const dnn::AlgorithmConfig& algorithm_config,\n-      const NumericOptions& numeric_options, float dropout, uint64_t seed,\n+      const EngineOptions& engine_options, float dropout, uint64_t seed,\n       ScratchAllocator* state_allocator, bool use_padded_io) override;\n \n   absl::StatusOr<std::unique_ptr<dnn::RnnSequenceTensorDescriptor>>\n@@ -270,7 +270,7 @@ class CudnnSupport : public dnn::DnnSupport {\n       DeviceMemoryBase output_data,\n       const dnn::ConvolutionDescriptor& convolution_descriptor,\n       bool use_fallback, ScratchAllocator* scratch_allocator,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       std::vector<std::unique_ptr<const dnn::ConvRunner>>* out_exec_plans)\n       override;\n \n@@ -289,7 +289,7 @@ class CudnnSupport : public dnn::DnnSupport {\n       const dnn::FilterDescriptor& filter_descriptor,\n       const dnn::BatchDescriptor& output_descriptor,\n       const dnn::ConvolutionDescriptor& convolution_descriptor,\n-      bool use_fallback, const NumericOptions& numeric_options,\n+      bool use_fallback, const EngineOptions& engine_options,\n       std::vector<std::unique_ptr<const dnn::GraphConvRunner>>* out_exec_plans,\n       std::string serialized_graph) override;\n \n@@ -313,7 +313,7 @@ class CudnnSupport : public dnn::DnnSupport {\n       const dnn::BatchDescriptor& output_descriptor,\n       const dnn::ConvolutionDescriptor& convolution_descriptor,\n       bool use_fallback, dnn::ActivationMode activation_mode,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       std::vector<std::unique_ptr<const dnn::FusedConvRunner>>* out_exec_plans)\n       override;\n \n@@ -322,7 +322,7 @@ class CudnnSupport : public dnn::DnnSupport {\n       dnn::DataType output_type, Stream* stream, bool trans_a, bool trans_b,\n       uint64_t m, uint64_t n, uint64_t k, int64_t lda, int64_t ldb, int64_t ldc,\n       dnn::ActivationMode activation_mode, bool use_fallback,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       std::vector<std::unique_ptr<const dnn::FusedMatmulRunner>>*\n           out_exec_plans) override;\n \n@@ -486,7 +486,7 @@ class CudnnSupport : public dnn::DnnSupport {\n \n   absl::Status DoPoolForward(dnn::DataType element_type, Stream* stream,\n                              const dnn::PoolingDescriptor& pooling_dimensions,\n-                             const NumericOptions& numeric_options,\n+                             const EngineOptions& engine_options,\n                              const dnn::BatchDescriptor& input_dimensions,\n                              DeviceMemoryBase input_data,\n                              const dnn::BatchDescriptor& output_dimensions,\n@@ -505,7 +505,7 @@ class CudnnSupport : public dnn::DnnSupport {\n \n   absl::Status DoPoolBackward(dnn::DataType element_type, Stream* stream,\n                               const dnn::PoolingDescriptor& pooling_dimensions,\n-                              const NumericOptions& numeric_options,\n+                              const EngineOptions& engine_options,\n                               const dnn::BatchDescriptor& input_dimensions,\n                               DeviceMemoryBase input_data,\n                               const dnn::BatchDescriptor& output_dimensions,\n@@ -573,17 +573,17 @@ class CudnnSupport : public dnn::DnnSupport {\n \n   bool GetConvolveAlgorithms(CudaComputeCapability cuda_compute_capability,\n                              dnn::DataType input_type,\n-                             const NumericOptions& numeric_options,\n+                             const EngineOptions& engine_options,\n                              std::vector<dnn::AlgorithmDesc>* out_algorithms);\n \n   bool GetConvolveBackwardDataAlgorithms(\n       CudaComputeCapability cuda_compute_capability, dnn::DataType input_type,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       std::vector<dnn::AlgorithmDesc>* out_algorithms);\n \n   bool GetConvolveBackwardFilterAlgorithms(\n       CudaComputeCapability cuda_compute_capability, dnn::DataType input_type,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       std::vector<dnn::AlgorithmDesc>* out_algorithms);\n \n   template <class T, class U>\n@@ -692,8 +692,7 @@ class CudnnSupport : public dnn::DnnSupport {\n       absl::Span<const int> labels_data,\n       absl::Span<const int> labels_lengths_data,\n       absl::Span<const int> input_lengths_data,\n-      const NumericOptions& numeric_options,\n-      ScratchAllocator* scratch_allocator,\n+      const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n       DeviceMemory<uint8_t>* scratch_memory, int* ctc_loss_algo_id) override;\n \n   CudnnSupport(const CudnnSupport&) = delete;"
        },
        {
            "sha": "3c39aa8272840bf3e5861aa306062bd6b48cf2c1",
            "filename": "third_party/xla/xla/stream_executor/dnn.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdnn.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdnn.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdnn.cc?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -40,7 +40,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/stream_executor/data_type.h\"\n #include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/lib/strings/proto_serialization.h\"\n@@ -144,7 +144,7 @@ absl::Status DnnSupport::GetConvolveRunners(\n     DeviceMemoryBase /*output_data*/,\n     const dnn::ConvolutionDescriptor& /*convolution_descriptor*/,\n     bool /*use_fallback*/, ScratchAllocator* /*scratch_allocator*/,\n-    const NumericOptions& /*numeric_options*/,\n+    const EngineOptions& /*engine_options*/,\n     std::vector<std::unique_ptr<const dnn::ConvRunner>>* /*exec_plans*/) {\n   return absl::UnimplementedError(\"GetConvolveRunners not implemented.\");\n }\n@@ -167,7 +167,7 @@ absl::Status DnnSupport::GetGraphConvolveRunners(\n     const dnn::FilterDescriptor& /*filter_descriptor*/,\n     const dnn::BatchDescriptor& /*output_descriptor*/,\n     const dnn::ConvolutionDescriptor& /*convolution_descriptor*/,\n-    bool /*use_fallback*/, const NumericOptions& /*numeric_options*/,\n+    bool /*use_fallback*/, const EngineOptions& /*engine_options*/,\n     std::vector<std::unique_ptr<const dnn::GraphConvRunner>>* /*exec_plans*/,\n     std::string /*serialized_graph*/) {\n   return absl::UnimplementedError(\"GetGraphConvolveRunners not implemented.\");\n@@ -195,7 +195,7 @@ absl::Status DnnSupport::GetFusedConvolveRunners(\n     const dnn::BatchDescriptor& bias_descriptor,\n     const dnn::BatchDescriptor& output_descriptor,\n     const dnn::ConvolutionDescriptor& convolution_descriptor, bool use_fallback,\n-    dnn::ActivationMode activation_mode, const NumericOptions& numeric_options,\n+    dnn::ActivationMode activation_mode, const EngineOptions& engine_options,\n     std::vector<std::unique_ptr<const dnn::FusedConvRunner>>* out_exec_plans) {\n   return absl::UnimplementedError(\"GetFusedConvolveRunners not implemented.\");\n }\n@@ -205,7 +205,7 @@ absl::Status DnnSupport::GetFusedMatmulRunners(\n     dnn::DataType output_type, Stream* stream, bool trans_a, bool trans_b,\n     uint64_t m, uint64_t n, uint64_t k, int64_t lda, int64_t ldb, int64_t ldc,\n     dnn::ActivationMode activation_mode, bool use_fallback,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     std::vector<std::unique_ptr<const dnn::FusedMatmulRunner>>*\n         out_exec_plans) {\n   return absl::UnimplementedError(\"GetFusedMatmulRunners not implemented.\");\n@@ -265,7 +265,7 @@ bool DnnSupport::GetRnnAlgorithms(std::vector<AlgorithmDesc>* out_algorithms) {\n absl::Status DnnSupport::DoPoolForward(\n     DataType element_type, Stream* stream,\n     const dnn::PoolingDescriptor& pooling_dimensions,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     const dnn::BatchDescriptor& input_dimensions, DeviceMemoryBase input_data,\n     const dnn::BatchDescriptor& output_dimensions, DeviceMemoryBase output_data,\n     ScratchAllocator* workspace_allocator) {\n@@ -278,7 +278,7 @@ absl::Status DnnSupport::DoPoolForward(\n absl::Status DnnSupport::DoPoolBackward(\n     DataType element_type, Stream* stream,\n     const dnn::PoolingDescriptor& pooling_dimensions,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     const dnn::BatchDescriptor& input_dimensions, DeviceMemoryBase input_data,\n     const dnn::BatchDescriptor& output_dimensions, DeviceMemoryBase output_data,\n     DeviceMemoryBase input_diff_data, DeviceMemoryBase output_diff_data,"
        },
        {
            "sha": "20209254aa245983ab1fce59d4072176b4e84e23",
            "filename": "third_party/xla/xla/stream_executor/dnn.h",
            "status": "modified",
            "additions": 16,
            "deletions": 18,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdnn.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdnn.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdnn.h?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -43,7 +43,7 @@ limitations under the License.\n #include \"xla/stream_executor/data_type.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n #include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/protobuf/dnn.pb.h\"\n@@ -1092,7 +1092,7 @@ class DnnGraph {\n   DnnGraph() = default;\n   virtual ~DnnGraph() = default;\n \n-  virtual absl::Status Prepare(DnnSupport&, const NumericOptions&) = 0;\n+  virtual absl::Status Prepare(DnnSupport&, const EngineOptions&) = 0;\n   virtual absl::Status Build(DnnSupport&, std::optional<int64_t> plan_id) = 0;\n   virtual absl::Status Execute(Stream& stream,\n                                absl::Span<DeviceMemoryBase> operands,\n@@ -1491,8 +1491,7 @@ class DnnSupport {\n       DeviceMemoryBase filter_data, const BatchDescriptor& output_descriptor,\n       DeviceMemoryBase output_data,\n       const ConvolutionDescriptor& convolution_descriptor, bool use_fallback,\n-      ScratchAllocator* scratch_allocator,\n-      const NumericOptions& numeric_options,\n+      ScratchAllocator* scratch_allocator, const EngineOptions& engine_options,\n       std::vector<std::unique_ptr<const ConvRunner>>* out_exec_plans);\n \n   virtual absl::StatusOr<std::unique_ptr<const ConvRunner>>\n@@ -1510,7 +1509,7 @@ class DnnSupport {\n       const FilterDescriptor& filter_descriptor,\n       const BatchDescriptor& output_descriptor,\n       const ConvolutionDescriptor& convolution_descriptor, bool use_fallback,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       std::vector<std::unique_ptr<const GraphConvRunner>>* out_exec_plans,\n       std::string serialized_graph);\n \n@@ -1533,15 +1532,15 @@ class DnnSupport {\n       const BatchDescriptor& bias_descriptor,\n       const BatchDescriptor& output_descriptor,\n       const ConvolutionDescriptor& convolution_descriptor, bool use_fallback,\n-      ActivationMode activation_mode, const NumericOptions& numeric_options,\n+      ActivationMode activation_mode, const EngineOptions& engine_options,\n       std::vector<std::unique_ptr<const FusedConvRunner>>* out_exec_plans);\n \n   virtual absl::Status GetFusedMatmulRunners(\n       DataType element_type, DataType bias_type, DataType output_type,\n       Stream* stream, bool trans_a, bool trans_b, uint64_t m, uint64_t n,\n       uint64_t k, int64_t lda, int64_t ldb, int64_t ldc,\n       ActivationMode activation_mode, bool use_fallback,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       std::vector<std::unique_ptr<const FusedMatmulRunner>>* out_exec_plans);\n \n   virtual absl::StatusOr<std::unique_ptr<const FusedConvRunner>>\n@@ -1591,22 +1590,22 @@ class DnnSupport {\n   template <typename ElementType>\n   absl::Status PoolForward(Stream* stream,\n                            const PoolingDescriptor& pooling_dimensions,\n-                           const NumericOptions& numeric_options,\n+                           const EngineOptions& engine_options,\n                            const BatchDescriptor& input_dimensions,\n                            const DeviceMemory<ElementType>& input_data,\n                            const BatchDescriptor& output_dimensions,\n                            DeviceMemory<ElementType>* output_data,\n                            ScratchAllocator* workspace_allocator = nullptr) {\n     return DoPoolForward(ToDataType<ElementType>::value, stream,\n-                         pooling_dimensions, numeric_options, input_dimensions,\n+                         pooling_dimensions, engine_options, input_dimensions,\n                          input_data, output_dimensions, *output_data,\n                          workspace_allocator);\n   }\n \n   template <typename ElementType>\n   absl::Status PoolBackward(Stream* stream,\n                             const PoolingDescriptor& pooling_dimensions,\n-                            const NumericOptions& numeric_options,\n+                            const EngineOptions& engine_options,\n                             const BatchDescriptor& input_dimensions,\n                             const DeviceMemory<ElementType>& input_data,\n                             const BatchDescriptor& output_dimensions,\n@@ -1616,7 +1615,7 @@ class DnnSupport {\n                             ScratchAllocator* workspace_allocator = nullptr) {\n     return DoPoolBackward(\n         ToDataType<ElementType>::value, stream, pooling_dimensions,\n-        numeric_options, input_dimensions, input_data, output_dimensions,\n+        engine_options, input_dimensions, input_data, output_dimensions,\n         output_data, input_diff_data, *output_diff_data, workspace_allocator);\n   }  // Performs a forward pooling operation on input_data, writing to\n   // output_data. See PoolingDescriptor for how to configure the\n@@ -1641,7 +1640,7 @@ class DnnSupport {\n   virtual absl::Status DoPoolForward(\n       DataType element_type, Stream* stream,\n       const PoolingDescriptor& pooling_dimensions,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       const BatchDescriptor& input_dimensions, DeviceMemoryBase input_data,\n       const BatchDescriptor& output_dimensions, DeviceMemoryBase output_data,\n       ScratchAllocator* workspace_allocator);\n@@ -1658,7 +1657,7 @@ class DnnSupport {\n   virtual absl::Status DoPoolBackward(\n       DataType element_type, Stream* stream,\n       const PoolingDescriptor& pooling_dimensions,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       const BatchDescriptor& input_dimensions, DeviceMemoryBase input_data,\n       const BatchDescriptor& output_dimensions, DeviceMemoryBase output_data,\n       DeviceMemoryBase input_diff_data, DeviceMemoryBase output_diff_data,\n@@ -1725,7 +1724,7 @@ class DnnSupport {\n       int batch_size, RnnInputMode input_mode, RnnDirectionMode direction_mode,\n       RnnMode rnn_mode, DataType data_type,\n       const AlgorithmConfig& algorithm_config,\n-      const NumericOptions& numeric_options, float dropout, uint64_t seed,\n+      const EngineOptions& engine_options, float dropout, uint64_t seed,\n       ScratchAllocator* state_allocator, bool use_padded_io) {\n     return absl::UnimplementedError(\"CreateRnnDescriptor is unimplemented\");\n   }\n@@ -1992,13 +1991,13 @@ class DnnSupport {\n                                  absl::Span<const int> labels_data,\n                                  absl::Span<const int> labels_lengths_data,\n                                  absl::Span<const int> input_lengths_data,\n-                                 const NumericOptions& numeric_options,\n+                                 const EngineOptions& engine_options,\n                                  ScratchAllocator* workspace_allocator,\n                                  DeviceMemory<uint8_t>* scratch_memory,\n                                  int* ctc_loss_algo_id) {\n     return DoPrepareForCtcLoss(\n         stream, ToDataType<ElementType>::value, probs_desc, grads_desc,\n-        labels_data, labels_lengths_data, input_lengths_data, numeric_options,\n+        labels_data, labels_lengths_data, input_lengths_data, engine_options,\n         workspace_allocator, scratch_memory, ctc_loss_algo_id);\n   }\n \n@@ -2101,8 +2100,7 @@ class DnnSupport {\n       absl::Span<const int> labels_data,\n       absl::Span<const int> labels_lengths_data,\n       absl::Span<const int> input_lengths_data,\n-      const NumericOptions& numeric_options,\n-      ScratchAllocator* scratch_allocator,\n+      const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n       DeviceMemory<uint8_t>* scratch_memory, int* ctc_loss_algo_id) {\n     *scratch_memory = {};\n     return absl::OkStatus();"
        },
        {
            "sha": "1b0eae8774fe3d7cbf3757be5f77d585f89e5047",
            "filename": "third_party/xla/xla/stream_executor/engine_options.h",
            "status": "renamed",
            "additions": 18,
            "deletions": 9,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fengine_options.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Fengine_options.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fengine_options.h?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -13,25 +13,34 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ------------------------------------------------------------------------------*/\n \n-#ifndef XLA_STREAM_EXECUTOR_NUMERIC_OPTIONS_H_\n-#define XLA_STREAM_EXECUTOR_NUMERIC_OPTIONS_H_\n+#ifndef XLA_STREAM_EXECUTOR_ENGINE_OPTIONS_H_\n+#define XLA_STREAM_EXECUTOR_ENGINE_OPTIONS_H_\n \n namespace stream_executor {\n \n-// Options that specify the numeric behavior of operations like matrix\n-// multiplications and convolutions\n-struct NumericOptions {\n-  NumericOptions(bool require_determinism, bool allow_tf32)\n-      : require_determinism(require_determinism), allow_tf32(allow_tf32) {}\n+// Options (used when calling math libraries) that specify the behavior of\n+// operations like matrix multiplications and convolutions.\n+struct EngineOptions {\n+  EngineOptions(bool require_determinism, bool allow_tf32,\n+                bool require_command_buffer)\n+      : require_determinism(require_determinism),\n+        allow_tf32(allow_tf32),\n+        require_command_buffer(require_command_buffer) {}\n \n-  NumericOptions() : require_determinism(false), allow_tf32(true) {}\n+  EngineOptions()\n+      : require_determinism(false),\n+        allow_tf32(true),\n+        require_command_buffer(false) {}\n \n   // If true, the op must be deterministic\n   bool require_determinism;\n   // If true, float32 inputs can be rounded to TensorFloat-32 precision\n   bool allow_tf32;\n+  // If true, the execution plan selected must support command buffer\n+  // construction.\n+  bool require_command_buffer;\n };\n \n }  // namespace stream_executor\n \n-#endif  // XLA_STREAM_EXECUTOR_NUMERIC_OPTIONS_H_\n+#endif  // XLA_STREAM_EXECUTOR_ENGINE_OPTIONS_H_",
            "previous_filename": "third_party/xla/xla/stream_executor/numeric_options.h"
        },
        {
            "sha": "889bab67fdee3e6a21ca65fc0a6f2874f333b869",
            "filename": "third_party/xla/xla/stream_executor/rocm/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2FBUILD?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -378,9 +378,9 @@ cc_library(\n         \"//xla/stream_executor:blas\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:engine_options\",\n         \"//xla/stream_executor:event_based_timer\",\n         \"//xla/stream_executor:host_or_device_scalar\",\n-        \"//xla/stream_executor:numeric_options\",\n         \"//xla/stream_executor:plugin_registry\",\n         \"//xla/stream_executor:scratch_allocator\",\n         \"//xla/stream_executor:stream_executor_h\",\n@@ -517,8 +517,8 @@ cc_library(\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:dnn\",\n+        \"//xla/stream_executor:engine_options\",\n         \"//xla/stream_executor:event_based_timer\",\n-        \"//xla/stream_executor:numeric_options\",\n         \"//xla/stream_executor:plugin_registry\",\n         \"//xla/stream_executor:scratch_allocator\",\n         \"//xla/stream_executor:stream\","
        },
        {
            "sha": "f74c91a5bd312dc31e8eece34bf565a1e69591ad",
            "filename": "third_party/xla/xla/stream_executor/rocm/rocm_blas.cc",
            "status": "modified",
            "additions": 36,
            "deletions": 34,
            "changes": 70,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_blas.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_blas.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_blas.cc?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -42,10 +42,10 @@ limitations under the License.\n #include \"xla/stream_executor/blas.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/event_based_timer.h\"\n #include \"xla/stream_executor/gpu/gpu_blas_lt.h\"\n #include \"xla/stream_executor/gpu/gpu_helpers.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n #include \"xla/stream_executor/platform/initialize.h\"\n #include \"xla/stream_executor/plugin_registry.h\"\n #include \"xla/stream_executor/rocm/rocblas_wrapper.h\"\n@@ -471,12 +471,14 @@ void ROCMBlas::MaybeLogGemmOp(GemmCallTrace::GemmType op,\n       parent_->RecordApiTrace(GemmCallTrace{op, (int)context, size1, size2});\n }\n \n-absl::Status ROCMBlas::DoBlasGemm(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n-    uint64_t n, uint64_t k, blas::DataType dtype, const void *alpha,\n-    const DeviceMemoryBase &a, int lda, const DeviceMemoryBase &b, int ldb,\n-    const void *beta, DeviceMemoryBase *c, int ldc,\n-    const NumericOptions &numeric_options, blas::CallContext context) {\n+absl::Status ROCMBlas::DoBlasGemm(Stream* stream, blas::Transpose transa,\n+                                  blas::Transpose transb, uint64_t m,\n+                                  uint64_t n, uint64_t k, blas::DataType dtype,\n+                                  const void* alpha, const DeviceMemoryBase& a,\n+                                  int lda, const DeviceMemoryBase& b, int ldb,\n+                                  const void* beta, DeviceMemoryBase* c,\n+                                  int ldc, const EngineOptions& engine_options,\n+                                  blas::CallContext context) {\n   MaybeLogGemmOp(GemmCallTrace::GemmType::kPlain, context,\n                  m * k * DtypeSize(dtype), n * k * DtypeSize(dtype));\n \n@@ -557,13 +559,13 @@ absl::Status ROCMBlas::DoBlasGemm(\n }\n \n absl::Status ROCMBlas::DoBlasGemmWithAlgorithm(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n-    uint64_t n, uint64_t k, const void *alpha, const DeviceMemoryBase &a,\n-    blas::DataType type_a, int lda, const DeviceMemoryBase &b,\n-    blas::DataType type_b, int ldb, const void *beta, DeviceMemoryBase *c,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    uint64_t n, uint64_t k, const void* alpha, const DeviceMemoryBase& a,\n+    blas::DataType type_a, int lda, const DeviceMemoryBase& b,\n+    blas::DataType type_b, int ldb, const void* beta, DeviceMemoryBase* c,\n     blas::DataType type_c, int ldc, blas::ComputationType computation_type,\n-    blas::AlgorithmType algorithm, const NumericOptions &numeric_options,\n-    blas::ProfileResult *profile_result, blas::CallContext context) {\n+    blas::AlgorithmType algorithm, const EngineOptions& engine_options,\n+    blas::ProfileResult* profile_result, blas::CallContext context) {\n   if (type_a != type_b) {\n     return absl::InternalError(absl::StrFormat(\n         \"DoBlasGemmWithAlgorithm: different \"\n@@ -580,7 +582,7 @@ absl::Status ROCMBlas::DoBlasGemmWithAlgorithm(\n   if (algorithm == blas::kDefaultAlgorithm && type_a == type_c) {\n     TF_RETURN_IF_ERROR(DoBlasGemm(stream, transa, transb, m, n, k, type_a,\n                                   alpha, a, lda, b, ldb, beta, c, ldc,\n-                                  numeric_options, context));\n+                                  engine_options, context));\n \n   } else {\n     MaybeLogGemmOp(GemmCallTrace::GemmType::kPlain, context,\n@@ -617,14 +619,14 @@ absl::Status ROCMBlas::DoBlasGemmWithAlgorithm(\n }\n \n absl::Status ROCMBlas::DoBlasGemmStridedBatchedWithAlgorithm(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n-    uint64_t n, uint64_t k, const void *alpha, const DeviceMemoryBase &a,\n-    blas::DataType type_a, int lda, int64_t stride_a, const DeviceMemoryBase &b,\n-    blas::DataType type_b, int ldb, int64_t stride_b, const void *beta,\n-    DeviceMemoryBase *c, blas::DataType type_c, int ldc, int64_t stride_c,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    uint64_t n, uint64_t k, const void* alpha, const DeviceMemoryBase& a,\n+    blas::DataType type_a, int lda, int64_t stride_a, const DeviceMemoryBase& b,\n+    blas::DataType type_b, int ldb, int64_t stride_b, const void* beta,\n+    DeviceMemoryBase* c, blas::DataType type_c, int ldc, int64_t stride_c,\n     int batch_count, blas::ComputationType computation_type,\n-    blas::AlgorithmType algorithm, const NumericOptions &numeric_options,\n-    blas::ProfileResult *profile_result, blas::CallContext context) {\n+    blas::AlgorithmType algorithm, const EngineOptions& engine_options,\n+    blas::ProfileResult* profile_result, blas::CallContext context) {\n   if (type_a != type_b) {\n     return absl::InternalError(absl::StrFormat(\n         \"DoBlasGemmStridedBatchedWithAlgorithm: different \"\n@@ -641,7 +643,7 @@ absl::Status ROCMBlas::DoBlasGemmStridedBatchedWithAlgorithm(\n   if (algorithm == blas::kDefaultAlgorithm && type_a == type_c) {\n     TF_RETURN_IF_ERROR(DoBlasGemmStridedBatched(\n         stream, transa, transb, m, n, k, type_a, alpha, a, lda, stride_a, b,\n-        ldb, stride_b, beta, c, ldc, stride_c, batch_count, numeric_options,\n+        ldb, stride_b, beta, c, ldc, stride_c, batch_count, engine_options,\n         context));\n   } else {\n     MaybeLogGemmOp(GemmCallTrace::GemmType::kStridedBatched, context, a.size(),\n@@ -1070,11 +1072,11 @@ class rocblas_gemm_strided_batched_bf16 {\n const char *rocblas_gemm_strided_batched_bf16::kName =\n     \"rocblas_gemm_strided_batched_bf16\";\n bool ROCMBlas::DoBlasGemmBatched(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n     uint64_t n, uint64_t k, float alpha, DeviceMemorySlice<Eigen::half> a,\n     int lda, DeviceMemorySlice<Eigen::half> b, int ldb, float beta,\n     DeviceMemorySlice<Eigen::half> c, int ldc, int batch_count,\n-    const NumericOptions &numeric_options, ScratchAllocator *scratch_allocator,\n+    const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n     blas::CallContext context) {\n   MaybeLogGemmOp(GemmCallTrace::GemmType::kBatched, context, a.size(),\n                  b.size());\n@@ -1105,12 +1107,12 @@ bool ROCMBlas::DoBlasGemmBatched(\n }\n \n bool ROCMBlas::DoBlasGemmBatched(\n-    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n+    Stream* stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n     uint64_t n, uint64_t k, float alpha,\n     DeviceMemorySlice<Eigen::bfloat16> a_array, int lda,\n     DeviceMemorySlice<Eigen::bfloat16> b_array, int ldb, float beta,\n     DeviceMemorySlice<Eigen::bfloat16> c_array, int ldc, int batch_count,\n-    const NumericOptions &numeric_options, ScratchAllocator *scratch_allocator,\n+    const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n     blas::CallContext context) {\n   MaybeLogGemmOp(GemmCallTrace::GemmType::kBatched, context, a_array.size(),\n                  b_array.size());\n@@ -1129,12 +1131,12 @@ bool ROCMBlas::DoBlasGemmBatched(\n \n #define IMPL_DoBlasGemmBatched(T, Fun)                                         \\\n   bool ROCMBlas::DoBlasGemmBatched(                                            \\\n-      Stream *stream, blas::Transpose transa, blas::Transpose transb,          \\\n+      Stream* stream, blas::Transpose transa, blas::Transpose transb,          \\\n       uint64_t m, uint64_t n, uint64_t k, T alpha,                             \\\n       DeviceMemorySlice<T> a_array, int lda, DeviceMemorySlice<T> b_array,     \\\n       int ldb, T beta, DeviceMemorySlice<T> c_array, int ldc, int batch_count, \\\n-      const NumericOptions &numeric_options,                                   \\\n-      ScratchAllocator *scratch_allocator, blas::CallContext context) {        \\\n+      const EngineOptions& engine_options,                                     \\\n+      ScratchAllocator* scratch_allocator, blas::CallContext context) {        \\\n     MaybeLogGemmOp(GemmCallTrace::GemmType::kBatched, context, a_array.size(), \\\n                    b_array.size());                                            \\\n     absl::Status status = DoBlasGemmBatchedInternal(                           \\\n@@ -1190,12 +1192,12 @@ IMPL_DoBlasGemmBatched(float, wrap::rocblas_sgemm_strided_batched)\n \n                                 absl::Status\n     ROCMBlas::DoBlasGemmStridedBatched(\n-        Stream *stream, blas::Transpose transa, blas::Transpose transb,\n+        Stream* stream, blas::Transpose transa, blas::Transpose transb,\n         uint64_t m, uint64_t n, uint64_t k, blas::DataType dtype,\n-        const void *alpha, const DeviceMemoryBase &a, int lda, int64_t stride_a,\n-        const DeviceMemoryBase &b, int ldb, int64_t stride_b, const void *beta,\n-        DeviceMemoryBase *c, int ldc, int64_t stride_c, int batch_count,\n-        const NumericOptions &numeric_options, blas::CallContext context) {\n+        const void* alpha, const DeviceMemoryBase& a, int lda, int64_t stride_a,\n+        const DeviceMemoryBase& b, int ldb, int64_t stride_b, const void* beta,\n+        DeviceMemoryBase* c, int ldc, int64_t stride_c, int batch_count,\n+        const EngineOptions& engine_options, blas::CallContext context) {\n   VLOG(1) << absl::StreamFormat(\n       \"doing rocBLAS GEMM Strided Batched: at=%d bt=%d m=%u n=%u \"\n       \"k=%llu alpha=%p a=%p lda=%d b=%p ldb=%d beta=%p \""
        },
        {
            "sha": "6ae864b7d129ccd77ccca7a9ce28220b14e058f9",
            "filename": "third_party/xla/xla/stream_executor/rocm/rocm_dnn.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_dnn.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_dnn.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_dnn.cc?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -52,8 +52,8 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/dnn.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/event_based_timer.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n #include \"xla/stream_executor/platform/initialize.h\"\n #include \"xla/stream_executor/plugin_registry.h\"\n #include \"xla/stream_executor/rocm/rocm_platform_id.h\"\n@@ -2800,7 +2800,7 @@ absl::Status MIOpenSupport::DoPrepareForCtcLoss(\n     absl::Span<const int> labels_data,\n     absl::Span<const int> labels_lengths_data,\n     absl::Span<const int> input_lengths_data,\n-    const NumericOptions& numeric_options, ScratchAllocator* scratch_allocator,\n+    const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n     DeviceMemory<uint8_t>* scratch_memory, int* ctc_loss_algo_id) {\n   auto miopen = miopen_->GetHandle(parent_, stream);\n \n@@ -2922,7 +2922,7 @@ MIOpenSupport::CreateRnnDescriptor(\n     int batch_size, dnn::RnnInputMode input_mode,\n     dnn::RnnDirectionMode direction_mode, dnn::RnnMode rnn_mode,\n     dnn::DataType data_type, const dnn::AlgorithmConfig& algorithm_config,\n-    const NumericOptions& numeric_options, float dropout, uint64_t seed,\n+    const EngineOptions& engine_options, float dropout, uint64_t seed,\n     ScratchAllocator* state_allocator, bool use_padded_io) {\n   // ROCM TODO: batch_size is used in dynamic persistent RNN algorithm and is\n   // not supported by MIOpen now.\n@@ -3488,7 +3488,7 @@ absl::Status MIOpenSupport::GetConvolveRunners(\n     DeviceMemoryBase filter_data, const dnn::BatchDescriptor& output_descriptor,\n     DeviceMemoryBase output_data,\n     const dnn::ConvolutionDescriptor& convolution_descriptor, bool use_fallback,\n-    ScratchAllocator* scratch_allocator, const NumericOptions& numeric_options,\n+    ScratchAllocator* scratch_allocator, const EngineOptions& engine_options,\n     std::vector<std::unique_ptr<const dnn::ConvRunner>>* out_runners) {\n   if (input_type != output_type) {\n     return absl::UnimplementedError(\n@@ -4270,7 +4270,7 @@ absl::Status ROCmFusedMatmulRunner::gemm(Stream* stream,\n                               static_cast<DeviceMemory<T>>(b_data), _ldb,\n                               static_cast<DeviceMemory<T>>(a_data), _lda,\n                               static_cast<DeviceMemory<T>*>(&c_data), _ldc,\n-                              NumericOptions{}, blas::CallContext::kNone);\n+                              EngineOptions{}, blas::CallContext::kNone);\n }\n \n template <typename T, typename Tbias = T>\n@@ -4348,7 +4348,7 @@ absl::Status MIOpenSupport::GetFusedMatmulRunners(\n     dnn::DataType output_type, Stream* stream, bool trans_a, bool trans_b,\n     uint64_t m, uint64_t n, uint64_t k, int64_t lda, int64_t ldb, int64_t ldc,\n     dnn::ActivationMode activation_mode, bool use_fallback,\n-    const NumericOptions& numeric_options,\n+    const EngineOptions& engine_options,\n     std::vector<std::unique_ptr<const dnn::FusedMatmulRunner>>*\n         out_exec_plans) {\n   out_exec_plans->clear();\n@@ -5167,7 +5167,7 @@ absl::Status MIOpenSupport::GetFusedConvolveRunners(\n     const dnn::BatchDescriptor& bias_descriptor,\n     const dnn::BatchDescriptor& output_descriptor,\n     const dnn::ConvolutionDescriptor& convolution_descriptor, bool use_fallback,\n-    dnn::ActivationMode activation_mode, const NumericOptions& numeric_options,\n+    dnn::ActivationMode activation_mode, const EngineOptions& engine_options,\n     std::vector<std::unique_ptr<const dnn::FusedConvRunner>>* out_exec_plans) {\n   VLOG(2) << \"MIOpenSupport::GetFusedConvolveRunners\";\n   VLOG(2) << \"filter_descriptor \" << filter_descriptor.ndims();"
        },
        {
            "sha": "63c8f8666c4c92c43fa4eade821db4d6ee02131d",
            "filename": "third_party/xla/xla/stream_executor/rocm/rocm_dnn.h",
            "status": "modified",
            "additions": 6,
            "deletions": 7,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_dnn.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c0ed3936799c451d96b0daeee060b8ca18b6d6ba/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_dnn.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Frocm%2Frocm_dnn.h?ref=c0ed3936799c451d96b0daeee060b8ca18b6d6ba",
            "patch": "@@ -32,7 +32,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/dnn.h\"\n-#include \"xla/stream_executor/numeric_options.h\"\n+#include \"xla/stream_executor/engine_options.h\"\n #include \"xla/stream_executor/plugin_registry.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -92,7 +92,7 @@ class MIOpenSupport : public dnn::DnnSupport {\n       int batch_size, dnn::RnnInputMode input_mode,\n       dnn::RnnDirectionMode direction_mode, dnn::RnnMode rnn_mode,\n       dnn::DataType data_type, const dnn::AlgorithmConfig& algorithm_config,\n-      const NumericOptions& numeric_options, float dropout, uint64_t seed,\n+      const EngineOptions& engine_options, float dropout, uint64_t seed,\n       ScratchAllocator* state_allocator, bool use_padded_io) override;\n \n   absl::StatusOr<std::unique_ptr<dnn::RnnSequenceTensorDescriptor>>\n@@ -249,7 +249,7 @@ class MIOpenSupport : public dnn::DnnSupport {\n       DeviceMemoryBase output_data,\n       const dnn::ConvolutionDescriptor& convolution_descriptor,\n       bool use_fallback, ScratchAllocator* scratch_allocator,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       std::vector<std::unique_ptr<const dnn::ConvRunner>>* out_runners)\n       override;\n \n@@ -432,7 +432,7 @@ class MIOpenSupport : public dnn::DnnSupport {\n       dnn::DataType output_type, Stream* stream, bool trans_a, bool trans_b,\n       uint64_t m, uint64_t n, uint64_t k, int64_t lda, int64_t ldb, int64_t ldc,\n       dnn::ActivationMode activation_mode, bool use_fallback,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       std::vector<std::unique_ptr<const dnn::FusedMatmulRunner>>*\n           out_exec_plans) override;\n \n@@ -446,7 +446,7 @@ class MIOpenSupport : public dnn::DnnSupport {\n       const dnn::BatchDescriptor& output_descriptor,\n       const dnn::ConvolutionDescriptor& convolution_descriptor,\n       bool use_fallback, dnn::ActivationMode activation_mode,\n-      const NumericOptions& numeric_options,\n+      const EngineOptions& engine_options,\n       std::vector<std::unique_ptr<const dnn::FusedConvRunner>>* out_exec_plans)\n       override;\n \n@@ -626,8 +626,7 @@ class MIOpenSupport : public dnn::DnnSupport {\n       absl::Span<const int> labels_data,\n       absl::Span<const int> labels_lengths_data,\n       absl::Span<const int> input_lengths_data,\n-      const NumericOptions& numeric_options,\n-      ScratchAllocator* scratch_allocator,\n+      const EngineOptions& engine_options, ScratchAllocator* scratch_allocator,\n       DeviceMemory<uint8_t>* scratch_memory, int* ctc_loss_algo_id) override;\n \n   MIOpenSupport(const MIOpenSupport&) = delete;"
        }
    ],
    "stats": {
        "total": 964,
        "additions": 495,
        "deletions": 469
    }
}