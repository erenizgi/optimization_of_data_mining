{
    "author": "pschuh",
    "message": "Isolate memory allocation logic and switch over to using new shape computation logic in AllocateDestinationBuffer.\n\nPiperOrigin-RevId: 811510222",
    "sha": "37f31de72131052aafd2f91fea6d48865a0d7784",
    "files": [
        {
            "sha": "f3ee0700e11a7ad89b39afd52619bbd652d1832c",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 57,
            "deletions": 37,
            "changes": 94,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/37f31de72131052aafd2f91fea6d48865a0d7784/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/37f31de72131052aafd2f91fea6d48865a0d7784/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=37f31de72131052aafd2f91fea6d48865a0d7784",
            "patch": "@@ -608,51 +608,76 @@ AllocateDestinationBuffer(const Shape& on_host_shape, PjRtDevice* device,\n         \"Cannot allocate a PjRtStreamExecutorBuffer for a tuple.\");\n   }\n \n-  PjRtMemorySpace* default_memory_space =\n-      device->default_memory_space().value_or(nullptr);\n   if (!memory_space) {\n-    memory_space = default_memory_space;\n-  }\n-  bool is_pinned_host_memory =\n-      memory_space && (memory_space->kind() == PinnedHostMemorySpace::kKind);\n-  // Only allow pinned host memory or device memory.\n-  if (memory_space != default_memory_space && !is_pinned_host_memory) {\n-    return InvalidArgument(\"Buffer allocation: invalid memory space\");\n+    memory_space = device->default_memory_space().value_or(nullptr);\n   }\n \n-  auto* se_client = tensorflow::down_cast<PjRtStreamExecutorClient*>(client);\n-  TransferManager* transfer_manager =\n-      se_client->client()->backend().transfer_manager();\n+  TF_ASSIGN_OR_RETURN(\n+      Shape on_device_shape,\n+      client->MakeDefaultShapeForMemorySpace(\n+          memory_space, on_host_shape,\n+          on_host_shape.has_layout() ? &on_host_shape.layout() : nullptr));\n+  TF_ASSIGN_OR_RETURN(\n+      size_t on_device_bytes_count,\n+      client->GetOnDeviceBytesCount(memory_space, on_device_shape));\n+  tsl::RCReference<RawSEDeviceMemory> mem;\n+  {\n+    bool is_pinned_host_memory =\n+        memory_space && (memory_space->kind() == PinnedHostMemorySpace::kKind);\n+    // Only allow pinned host memory or device memory.\n+    PjRtMemorySpace* default_memory_space =\n+        device->default_memory_space().value_or(nullptr);\n+    if (memory_space != default_memory_space && !is_pinned_host_memory) {\n+      return InvalidArgument(\"Buffer allocation: invalid memory space\");\n+    }\n+\n+    auto* se_client = tensorflow::down_cast<PjRtStreamExecutorClient*>(client);\n+    TransferManager* transfer_manager =\n+        se_client->client()->backend().transfer_manager();\n+\n+    // Communicate the desired memory space to the allocator via the shape\n+    // callback.\n+    auto memory_space_shape_fn = [is_pinned_host_memory,\n+                                  transfer_manager](const Shape& shape) {\n+      Shape result = transfer_manager->HostShapeToDeviceShape(shape);\n+      if (is_pinned_host_memory) {\n+        result.mutable_layout()->set_memory_space(Layout::kHostMemorySpace);\n+      }\n+      return result;\n+    };\n \n-  // Communicate the desired memory space to the allocator via the shape\n-  // callback.\n-  auto memory_space_shape_fn = [is_pinned_host_memory,\n-                                transfer_manager](const Shape& shape) {\n-    Shape result = transfer_manager->HostShapeToDeviceShape(shape);\n-    if (is_pinned_host_memory) {\n-      result.mutable_layout()->set_memory_space(Layout::kHostMemorySpace);\n+    TF_ASSIGN_OR_RETURN(\n+        ScopedShapedBuffer dst_buffer,\n+        transfer_manager->AllocateScopedShapedBuffer(\n+            on_host_shape, se_client->allocator(),\n+            local_device->local_device_id().value(),\n+            local_device->local_hardware_id().value(), memory_space_shape_fn));\n+    Shape old_on_device_shape = dst_buffer.on_device_shape();\n+    DCHECK_EQ(on_device_shape, old_on_device_shape)\n+        << on_device_shape.ToString(true) << \" vs \"\n+        << old_on_device_shape.ToString(true);\n+    DCHECK_EQ(on_device_bytes_count, dst_buffer.buffer({}).size());\n+    mem = RawSEDeviceMemory::Create(dst_buffer.buffer({}),\n+                                    device->local_device_id(),\n+                                    dst_buffer.memory_allocator());\n+    dst_buffer.clear();\n+    if (local_device->allocation_model() !=\n+        LocalDeviceState::kComputeSynchronized) {\n+      DCHECK(client->client()\n+                 ->backend()\n+                 .transfer_manager()\n+                 ->CanBufferBeAccessedNow(\n+                     local_device->compute_stream()->parent(), mem->mem()));\n     }\n-    return result;\n-  };\n-\n-  TF_ASSIGN_OR_RETURN(\n-      ScopedShapedBuffer dst_buffer,\n-      transfer_manager->AllocateScopedShapedBuffer(\n-          on_host_shape, se_client->allocator(),\n-          local_device->local_device_id().value(),\n-          local_device->local_hardware_id().value(), memory_space_shape_fn));\n+  }\n   if (local_device->allocation_model() ==\n       LocalDeviceState::kComputeSynchronized) {\n     if (copy_stream == nullptr) {\n       CHECK(is_uninitialized_create);\n     } else {\n       CHECK(copy_stream->WaitFor(local_device->compute_stream()).ok());\n     }\n-  } else {\n-    DCHECK(transfer_manager->CanShapedBufferBeAccessedNow(\n-        local_device->compute_stream()->parent(), dst_buffer));\n   }\n-  Shape on_device_shape = dst_buffer.on_device_shape();\n \n   absl::InlinedVector<BufferSequencingEventRef, 2> definition_events;\n   if (is_uninitialized_create) {\n@@ -685,11 +710,6 @@ AllocateDestinationBuffer(const Shape& on_host_shape, PjRtDevice* device,\n     }\n   }\n \n-  auto mem = RawSEDeviceMemory::Create(dst_buffer.buffer({}),\n-                                       device->local_device_id(),\n-                                       dst_buffer.memory_allocator());\n-  dst_buffer.clear();\n-\n   auto dst_device_buffer = std::make_unique<TrackedDeviceBuffer>(\n       device, std::move(mem), definition_events);\n "
        }
    ],
    "stats": {
        "total": 94,
        "additions": 57,
        "deletions": 37
    }
}