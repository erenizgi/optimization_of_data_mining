{
    "author": "IllogicalMoose",
    "message": "Update cuda subprocess_compilation fatbinary use to be cuda13 compatible.\n\n-image arg is deprecated.\n\nPiperOrigin-RevId: 797962562",
    "sha": "b835989e57b935e2012c01b029097814b9e3003e",
    "files": [
        {
            "sha": "7b3625103efc1f8d797433d513e502569443dd08",
            "filename": "tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b835989e57b935e2012c01b029097814b9e3003e/tensorflow%2Fcompiler%2Fmlir%2Ftools%2Fkernel_gen%2Ftransforms%2Fgpu_kernel_to_blob_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b835989e57b935e2012c01b029097814b9e3003e/tensorflow%2Fcompiler%2Fmlir%2Ftools%2Fkernel_gen%2Ftransforms%2Fgpu_kernel_to_blob_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftools%2Fkernel_gen%2Ftransforms%2Fgpu_kernel_to_blob_pass.cc?ref=b835989e57b935e2012c01b029097814b9e3003e",
            "patch": "@@ -178,8 +178,7 @@ class GpuKernelToBlobPass\n       if (!is_compute_profile) {\n         auto gpu_asm = tensorflow::se::CompileGpuAsm(cc, ptx, gpu_asm_opts);\n         if (gpu_asm.ok()) {\n-          images.push_back(\n-              {absl::StrCat(\"sm_\", arch), std::move(gpu_asm.value())});\n+          images.push_back({/*is_ptx=*/false, cc, std::move(gpu_asm.value())});\n         } else {\n #ifdef PLATFORM_GOOGLE\n           // Require compilation with ptxas.\n@@ -197,8 +196,7 @@ class GpuKernelToBlobPass\n         ptx_bytes.reserve(ptx.size() + 1);\n         std::copy(ptx.begin(), ptx.end(), std::back_inserter(ptx_bytes));\n         ptx_bytes.push_back('\\0');\n-        images.push_back(\n-            {absl::StrCat(\"compute_\", arch), std::move(ptx_bytes)});\n+        images.push_back({/*is_ptx=*/true, cc, std::move(ptx_bytes)});\n       }\n     }\n "
        },
        {
            "sha": "cef8c96859c7de8c3f07350a2c5c21d2330b014c",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 21,
            "deletions": 1,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b835989e57b935e2012c01b029097814b9e3003e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b835989e57b935e2012c01b029097814b9e3003e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=b835989e57b935e2012c01b029097814b9e3003e",
            "patch": "@@ -1387,6 +1387,7 @@ xla_test(\n cc_library(\n     name = \"cubin_or_ptx_image\",\n     hdrs = [\"cubin_or_ptx_image.h\"],\n+    deps = [\":cuda_compute_capability\"],\n )\n \n cc_library(\n@@ -1419,7 +1420,6 @@ cc_library(\n         \":ptx_compiler_helpers\",\n         \"//xla:status_macros\",\n         \"//xla:util\",\n-        \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:semantic_version\",\n         \"//xla/stream_executor/gpu:gpu_asm_opts\",\n         \"//xla/tsl/platform:env\",\n@@ -1476,6 +1476,26 @@ stage_in_bin_subdirectory(\n     data = [\":dummy_cuda_binary\"],\n )\n \n+xla_cc_test(\n+    name = \"subprocess_compilation_no_fakes_test\",\n+    srcs = [\"subprocess_compilation_no_fakes_test.cc\"],\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+    ],\n+    deps = [\n+        \":cubin_or_ptx_image\",\n+        \":cuda_compute_capability\",\n+        \":subprocess_compilation\",\n+        \"//xla/stream_executor/gpu:gpu_asm_opts\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest_main\",\n+        \"@local_tsl//tsl/platform:path\",\n+    ],\n+)\n+\n xla_cc_test(\n     name = \"subprocess_compilation_test\",\n     srcs = [\"subprocess_compilation_test.cc\"],"
        },
        {
            "sha": "0a777ec0b97ee892fc378761ae5a98c4d77dcd3a",
            "filename": "third_party/xla/xla/stream_executor/cuda/cubin_or_ptx_image.h",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b835989e57b935e2012c01b029097814b9e3003e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcubin_or_ptx_image.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b835989e57b935e2012c01b029097814b9e3003e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcubin_or_ptx_image.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcubin_or_ptx_image.h?ref=b835989e57b935e2012c01b029097814b9e3003e",
            "patch": "@@ -20,13 +20,14 @@ limitations under the License.\n #include <string>\n #include <vector>\n \n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+\n namespace stream_executor {\n // This is the input to various PTX compilation and linking functions. The\n-// struct holds either PTX or CUBIN in `bytes` and a compilation profile in\n-// `profile`. `profile` can either be a compile profile `compute_XY` or a SASS\n-// profile `sm_XY`.\n+// struct holds either PTX or CUBIN in `bytes`.\n struct CubinOrPTXImage {\n-  std::string profile;\n+  bool is_ptx;\n+  CudaComputeCapability cc;\n   std::vector<uint8_t> bytes;\n };\n }  // namespace stream_executor"
        },
        {
            "sha": "cb5b77ac552d99a9fbe6b7ba73a9afaebc1cc29b",
            "filename": "third_party/xla/xla/stream_executor/cuda/subprocess_compilation.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b835989e57b935e2012c01b029097814b9e3003e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsubprocess_compilation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b835989e57b935e2012c01b029097814b9e3003e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsubprocess_compilation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsubprocess_compilation.cc?ref=b835989e57b935e2012c01b029097814b9e3003e",
            "patch": "@@ -40,6 +40,7 @@ limitations under the License.\n #include \"absl/strings/str_join.h\"\n #include \"absl/strings/str_split.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"absl/strings/strip.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/status_macros.h\"\n@@ -426,8 +427,13 @@ absl::StatusOr<std::vector<uint8_t>> BundleGpuAsmUsingFatbin(\n   }\n   assert(images.size() == image_paths.size());\n   for (int i = 0; i < images.size(); i++) {\n+    absl::string_view kind = images[i].is_ptx ? \"ptx\" : \"elf\";\n     fatbinary_args.push_back(absl::StrFormat(\n-        \"--image=profile=%s,file=%s\", images[i].profile, image_paths[i]));\n+        \"--image3=kind=%s,sm=%s,file=%s\", kind,\n+        absl::StripPrefix(images[i].cc.GetPtxAsTargetName(\n+                              CudaComputeCapability::CompileMode::kSass),\n+                          \"sm_\"),\n+        image_paths[i]));\n   }\n   if (VLOG_IS_ON(3)) {\n     VLOG(3) << absl::StrJoin(fatbinary_args, \" \");"
        },
        {
            "sha": "0dc8c9be777a4d24bd60e054335b872a756ba9b0",
            "filename": "third_party/xla/xla/stream_executor/cuda/subprocess_compilation_no_fakes_test.cc",
            "status": "added",
            "additions": 79,
            "deletions": 0,
            "changes": 79,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b835989e57b935e2012c01b029097814b9e3003e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsubprocess_compilation_no_fakes_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b835989e57b935e2012c01b029097814b9e3003e/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsubprocess_compilation_no_fakes_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsubprocess_compilation_no_fakes_test.cc?ref=b835989e57b935e2012c01b029097814b9e3003e",
            "patch": "@@ -0,0 +1,79 @@\n+/* Copyright 2024 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdint>\n+#include <string>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/status/status_matchers.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/stream_executor/cuda/cubin_or_ptx_image.h\"\n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+#include \"xla/stream_executor/cuda/subprocess_compilation.h\"\n+#include \"xla/stream_executor/gpu/gpu_asm_opts.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"tsl/platform/path.h\"\n+\n+namespace stream_executor {\n+namespace {\n+\n+TEST(SubprocessCompilationTest, BundleGpuAsmUsingFatbinWorks) {\n+  std::string cuda_dir;\n+  if (!tsl::io::GetTestWorkspaceDir(&cuda_dir)) {\n+    GTEST_SKIP() << \"No test workspace directory found which means we can't \"\n+                    \"run this test. Was this called in a Bazel environment?\";\n+  }\n+\n+  const absl::string_view ptx = R\"(\n+// A minimal PTX kernel to add two constants: 42 + 100\n+.version 8.0\n+.target sm_90\n+.address_size 64\n+\n+.visible .entry add_constants()\n+{\n+    // Declare three 32-bit registers\n+    .reg .s32 %r_a, %r_b, %r_result;\n+\n+    // Move the constant values into registers\n+    mov.s32 %r_a, 42;\n+    mov.s32 %r_b, 100;\n+\n+    // Add the two registers and store in the result register\n+    add.s32 %r_result, %r_a, %r_b; // %r_result will now hold 142\n+\n+    // End of kernel\n+    ret;\n+}\n+)\";\n+\n+  GpuAsmOpts opts;\n+  tensorflow::se::CudaComputeCapability cc{9, 0};\n+  std::vector<CubinOrPTXImage> images;\n+\n+  std::vector<uint8_t> bytes(ptx.begin(), ptx.end());\n+  images.push_back({/*is_ptx=*/true, cc, bytes});\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto assembly,\n+                          CompileGpuAsmUsingPtxAs(cc, ptx, opts, false, false));\n+  images.push_back({/*is_ptx=*/false, cc, assembly.cubin});\n+\n+  EXPECT_THAT(BundleGpuAsmUsingFatbin(images, opts), absl_testing::IsOk());\n+}\n+\n+}  // namespace\n+}  // namespace stream_executor"
        }
    ],
    "stats": {
        "total": 124,
        "additions": 114,
        "deletions": 10
    }
}