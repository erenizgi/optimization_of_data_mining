{
    "author": "derdrdirk",
    "message": "Add more logs to the CuDNN autotuner backend.\n\nPiperOrigin-RevId: 846629554",
    "sha": "b9853f94c32cd1a83c2ce7416ba50abdc2aeba96",
    "files": [
        {
            "sha": "f311ea3e0deb0ea581e85deabd048900cba865cc",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cudnn.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b9853f94c32cd1a83c2ce7416ba50abdc2aeba96/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b9853f94c32cd1a83c2ce7416ba50abdc2aeba96/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc?ref=b9853f94c32cd1a83c2ce7416ba50abdc2aeba96",
            "patch": "@@ -239,6 +239,7 @@ GetCudnnFusionConfigs(const HloInstruction& instr,\n   std::vector<std::unique_ptr<BackendConfig>> configs;\n   int plan_count = CuDnnFusionCompiler::GetAvailablePlanCount(\n       *stream_executor, *DynCast<HloFusionInstruction>(&instr));\n+  VLOG(2) << \"Found \" << plan_count << \" plans for cudnn fusion.\";\n   configs.reserve(plan_count);\n   for (int plan_id = 0; plan_id < plan_count; ++plan_id) {\n     CudnnBackendConfig config;"
        }
    ],
    "stats": {
        "total": 1,
        "additions": 1,
        "deletions": 0
    }
}