{
    "author": "pschuh",
    "message": "Update TfrtGpuExecutable::ExecuteHelper to force untupling to at least be true whenever the result is a tuple (to match other backends).\n\nPiperOrigin-RevId: 817897232",
    "sha": "738dacb09b43ccad8fe0315aa32fc2903575a6a4",
    "files": [
        {
            "sha": "2a285cef797ce03d8b9594c0b840a79e3a1249f0",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_client_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/738dacb09b43ccad8fe0315aa32fc2903575a6a4/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/738dacb09b43ccad8fe0315aa32fc2903575a6a4/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client_test.cc?ref=738dacb09b43ccad8fe0315aa32fc2903575a6a4",
            "patch": "@@ -238,12 +238,14 @@ ENTRY %Add.6 (a.1: f32[], b.2: f32[]) -> (f32[], f32[]) {\n   TF_ASSERT_OK_AND_ASSIGN(auto executable,\n                           CompileExecutable(kAddProgram, *client));\n \n+  ExecuteOptions options;\n+  options.untuple_result = true;\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto result,\n-      executable->Execute({{buffer.get(), buffer.get()}}, /*options=*/{}));\n+      executable->Execute({{buffer.get(), buffer.get()}}, /*options=*/options));\n \n   ASSERT_EQ(result.size(), 1);\n-  ASSERT_EQ(result[0].size(), 1);\n+  ASSERT_EQ(result[0].size(), 2);\n   EXPECT_EQ(result[0][0]->GetReadyFuture().Await(), input_error);\n }\n "
        },
        {
            "sha": "37f3b22d16578ecb45d606f048f1cb9757a881ce",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_executable.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/738dacb09b43ccad8fe0315aa32fc2903575a6a4/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/738dacb09b43ccad8fe0315aa32fc2903575a6a4/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_executable.cc?ref=738dacb09b43ccad8fe0315aa32fc2903575a6a4",
            "patch": "@@ -394,6 +394,13 @@ absl::StatusOr<PjRtLoadedExecutable::Result> TfrtGpuExecutable::ExecuteHelper(\n   // SPMD sharding produces a single executable for multiple partitions.\n   int executable_idx = executables_.size() > 1 ? partition : 0;\n \n+  TF_ASSIGN_OR_RETURN(std::vector<Shape> output_shapes, GetOutputShapes());\n+  const Shape& result_shape = output_shapes[executable_idx];\n+  if (!options.untuple_result && result_shape.IsTuple()) {\n+    return InvalidArgument(\n+        \"Tuple results must be untupled using ExecuteOptions::untuple_result.\");\n+  }\n+\n   // `scheduled_event` indicates whether gpu computation is dispatched to the\n   // stream and whether there was an error.\n   auto scheduled_event = tsl::MakeConstructedAsyncValueRef<GpuEvent>();\n@@ -523,8 +530,6 @@ absl::StatusOr<PjRtLoadedExecutable::Result> TfrtGpuExecutable::ExecuteHelper(\n   std::vector<tsl::AsyncValueRef<GpuDeviceMemory>> output_buffers;\n   std::vector<std::unique_ptr<PjRtBuffer>> outputs;\n   auto gpu_executable = executables_[executable_idx];\n-  TF_ASSIGN_OR_RETURN(std::vector<Shape> output_shapes, GetOutputShapes());\n-  const Shape& result_shape = output_shapes[executable_idx];\n   bool untuple_result = options.untuple_result;\n   bool result_is_tuple = result_shape.IsTuple();\n   if (options.untuple_result && result_shape.IsTuple()) {"
        }
    ],
    "stats": {
        "total": 15,
        "additions": 11,
        "deletions": 4
    }
}