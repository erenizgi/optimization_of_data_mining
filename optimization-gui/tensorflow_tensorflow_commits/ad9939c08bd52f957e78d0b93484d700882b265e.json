{
    "author": "ILCSFNO",
    "message": "Merge branch 'tensorflow:master' into patch-1",
    "sha": "ad9939c08bd52f957e78d0b93484d700882b265e",
    "files": [
        {
            "sha": "2f3b1ed4e761e92d4d9a9f4a025f04c8040ffd4d",
            "filename": ".bazelrc",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/.bazelrc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/.bazelrc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.bazelrc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -277,17 +277,14 @@ build:mkl_threadpool --define=tensorflow_mkldnn_contraction_kernel=0\n build:mkl_threadpool --define=build_with_mkl_opensource=true\n build:mkl_threadpool -c opt\n \n-# Config setting to build oneDNN with Compute Library for the Arm Architecture (ACL).\n-build:mkl_aarch64 --define=build_with_mkl_aarch64=true\n-build:mkl_aarch64 --define=build_with_openmp=true\n-build:mkl_aarch64 --define=build_with_acl=true\n-build:mkl_aarch64 -c opt\n-\n # Config setting to build oneDNN with Compute Library for the Arm Architecture (ACL).\n # with Eigen threadpool support\n build:mkl_aarch64_threadpool --define=build_with_mkl_aarch64=true\n build:mkl_aarch64_threadpool -c opt\n \n+# This is an alias for the mkl_aarch64_threadpool build.\n+build:mkl_aarch64 --config=mkl_aarch64_threadpool\n+\n # Default CUDA, CUDNN and NVSHMEM versions.\n build:cuda_version --repo_env=HERMETIC_CUDA_VERSION=\"12.5.1\"\n build:cuda_version --repo_env=HERMETIC_CUDNN_VERSION=\"9.3.0\""
        },
        {
            "sha": "3bd61fa793789d8a8f0c38f77736d76f6c6d2100",
            "filename": "tensorflow/compiler/mlir/lite/ir/tfl_ops.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -989,6 +989,26 @@ int64_t AddOp::GetArithmeticCount(Operation* op) {\n   return -1;\n }\n \n+//===----------------------------------------------------------------------===//\n+// CeilOp\n+//===----------------------------------------------------------------------===//\n+\n+OpFoldResult CeilOp::fold(FoldAdaptor adaptor) {\n+  if (!ShouldFoldOperation(this->getOperation())) return {};\n+\n+  auto operands = adaptor.getOperands();\n+  auto result_type = getType();\n+  if (!IsF32ShapedType(result_type)) return {};\n+\n+  auto compute = [](APFloat value) -> APFloat {\n+    float f = value.convertToFloat();\n+    float result = std::ceil(f);\n+    return APFloat(result);\n+  };\n+\n+  return ConstFoldUnaryOp(result_type, operands[0], compute);\n+}\n+\n //===----------------------------------------------------------------------===//\n // FloorOp\n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "a6940719fc36e9d999416526bc6a0bd5ceb65654",
            "filename": "tensorflow/compiler/mlir/lite/ir/tfl_ops.td",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -828,6 +828,8 @@ def TFL_CeilOp: TFL_Op<\"ceil\", [\n \n   let results = (outs TFL_FpTensor:$y);\n \n+  let hasFolder = 1;\n+\n   let extraClassDeclaration = [{\n     // Returns whether the return types are compatible.\n     static bool isCompatibleReturnTypes(TypeRange l, TypeRange r) {\n@@ -5528,6 +5530,7 @@ def TFL_BroadcastToOp : TFL_Op<\"broadcast_to\", [\n     PredOpTrait<\"input and output must have same element type\",\n       TFL_TCresVTEtIsSameAsOp<0, 0>>,\n     TFL_OperandHasRankAtMost<0, 8>,\n+    SameOperandsAndResultsScale,\n     TFL_OperandHasRank<1, 1>,\n     PredOpTrait<\"output dimension count must be at most 8\",\n       Or<[TFL_OperandIsUnrankedPred<1>,\n@@ -5575,6 +5578,11 @@ subsequent operation and then be optimized away, however.)\n     TFL_TensorOf<[F32, I32, I1, TFL_I4, I8, QI8, UI8, UI32, QUI8, I16, QI16, I64, Complex<F<32>>]>:$output\n   );\n \n+  let extraClassDeclaration = [{\n+    // Quantized axes are verified in the Verify function.\n+    bool RequiredSameQuantizedAxes() { return false; }\n+  }];\n+\n   let hasCanonicalizer = 1;\n }\n "
        },
        {
            "sha": "950439bfc14bcdfb3abdcab3d26bb4da70cc59a0",
            "filename": "tensorflow/compiler/mlir/lite/schema/conversion_metadata_generated.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fconversion_metadata_generated.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fconversion_metadata_generated.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fconversion_metadata_generated.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -22,9 +22,9 @@ limitations under the License.\n \n // Ensure the included flatbuffers.h is the same version as when this file was\n // generated, otherwise it may not be compatible.\n-static_assert(FLATBUFFERS_VERSION_MAJOR == 24 &&\n-              FLATBUFFERS_VERSION_MINOR == 3 &&\n-              FLATBUFFERS_VERSION_REVISION == 25,\n+static_assert(FLATBUFFERS_VERSION_MAJOR == 25 &&\n+              FLATBUFFERS_VERSION_MINOR == 2 &&\n+              FLATBUFFERS_VERSION_REVISION == 10,\n              \"Non-compatible flatbuffers version included\");\n \n namespace tflite {"
        },
        {
            "sha": "a8275936736d5e0a89cc2c0c4aa75600bb74097d",
            "filename": "tensorflow/compiler/mlir/lite/schema/schema_generated.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fschema_generated.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fschema_generated.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fschema_generated.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -22,9 +22,9 @@ limitations under the License.\n \n // Ensure the included flatbuffers.h is the same version as when this file was\n // generated, otherwise it may not be compatible.\n-static_assert(FLATBUFFERS_VERSION_MAJOR == 24 &&\n-              FLATBUFFERS_VERSION_MINOR == 3 &&\n-              FLATBUFFERS_VERSION_REVISION == 25,\n+static_assert(FLATBUFFERS_VERSION_MAJOR == 25 &&\n+              FLATBUFFERS_VERSION_MINOR == 2 &&\n+              FLATBUFFERS_VERSION_REVISION == 10,\n              \"Non-compatible flatbuffers version included\");\n \n namespace tflite {"
        },
        {
            "sha": "fd76b1a2666fe3933573df2cfcd3b3fa6f96ff72",
            "filename": "tensorflow/compiler/mlir/lite/tests/const-fold.mlir",
            "status": "modified",
            "additions": 16,
            "deletions": 3,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fconst-fold.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fconst-fold.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fconst-fold.mlir?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1602,16 +1602,30 @@ func.func @select_float() -> tensor<4xf32> {\n \n   func.return %2 : tensor<4xf32>\n }\n-\n // CHECK: %cst = arith.constant dense<[1.000000e+00, 2.000000e+00, -3.000000e+00, -4.000000e+00]> : tensor<4xf32\n \n+// CHECK-LABEL: ceil\n+func.func @ceil() -> tensor<3xf32> {\n+  %cst = arith.constant dense<[-1.0, 0.0, 0.99]> : tensor<3xf32>\n+  %0 = \"tfl.ceil\"(%cst) : (tensor<3xf32>) -> tensor<3xf32>\n+  func.return %0 : tensor<3xf32>\n+}\n+// CHECK: %cst = arith.constant dense<[-1.000000e+00, 0.000000e+00, 1.000000e+00]> : tensor<3xf32>\n+\n+// CHECK-LABEL: ceil_f64\n+func.func @ceil_f64() -> tensor<3xf64> {\n+  %cst = arith.constant dense<[-1.0, 0.0, 0.99]> : tensor<3xf64>\n+  %0 = \"tfl.ceil\"(%cst) : (tensor<3xf64>) -> tensor<3xf64>\n+  func.return %0 : tensor<3xf64>\n+}\n+// CHECK: tfl.ceil\n+\n // CHECK-LABEL: floor\n func.func @floor() -> tensor<3xf32> {\n   %cst = arith.constant dense<[-1.0, 0.0, 0.99]> : tensor<3xf32>\n   %0 = \"tfl.floor\"(%cst) : (tensor<3xf32>) -> tensor<3xf32>\n   func.return %0 : tensor<3xf32>\n }\n-\n // CHECK: %cst = arith.constant dense<[-1.000000e+00, 0.000000e+00, 0.000000e+00]> : tensor<3xf32>\n \n // CHECK-LABEL: floor_f64\n@@ -1620,7 +1634,6 @@ func.func @floor_f64() -> tensor<3xf64> {\n   %0 = \"tfl.floor\"(%cst) : (tensor<3xf64>) -> tensor<3xf64>\n   func.return %0 : tensor<3xf64>\n }\n-\n // CHECK: tfl.floor\n \n // CHECK-LABEL: exp"
        },
        {
            "sha": "ffce22b25161e82e6163d60fc107685ca56d8cee",
            "filename": "tensorflow/compiler/mlir/lite/tests/optimize.mlir",
            "status": "modified",
            "additions": 46,
            "deletions": 0,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Foptimize.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Foptimize.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Foptimize.mlir?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1881,6 +1881,52 @@ func.func @InvalidL2NormalizePattern(%arg0: tensor<2xf32>, %arg1: tensor<2xf32>)\n   // CHECK: return %3\n }\n \n+// CHECK-LABEL: @L2NormalizePattern4_Mul\n+func.func @L2NormalizePattern4_Mul(%arg0: tensor<1x2xf32>) -> tensor<1x2xf32> {\n+  %cst = arith.constant dense<[1]> : tensor<1xi32>\n+  %cst_shape = arith.constant dense<[1, 1]> : tensor<2xi32>\n+  %0 = \"tfl.mul\"(%arg0, %arg0) {fused_activation_function = \"NONE\"} : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<1x2xf32>\n+  %1 = \"tfl.sum\"(%0, %cst) {keep_dims = false} : (tensor<1x2xf32>, tensor<1xi32>) -> tensor<1xf32>\n+  %2 = \"tfl.rsqrt\"(%1) : (tensor<1xf32>) -> tensor<1xf32>\n+  %3 = \"tfl.reshape\"(%2, %cst_shape) : (tensor<1xf32>, tensor<2xi32>) -> tensor<1x1xf32>\n+  %4 = \"tfl.mul\"(%arg0, %3) {fused_activation_function = \"NONE\"} : (tensor<1x2xf32>, tensor<1x1xf32>) -> tensor<1x2xf32>\n+  func.return %4: tensor<1x2xf32>\n+  // CHECK: %[[RES:[0-9].*]] = \"tfl.l2_normalization\"([[INPUT:%.*]]) <{fused_activation_function = \"NONE\"}> : (tensor<1x2xf32>) -> tensor<1x2xf32>\n+  // CHECK: return %[[RES]]\n+}\n+\n+// CHECK-LABEL: @L2NormalizePattern5_Mul\n+func.func @L2NormalizePattern5_Mul(%arg0: tensor<1x2xf32>) -> tensor<1x2xf32> {\n+  %cst = arith.constant dense<[1]> : tensor<1xi32>\n+  %cst_1 = arith.constant dense<[1.0e-4]> : tensor<1xf32>\n+  %cst_shape = arith.constant dense<[1, 1]> : tensor<2xi32>\n+  %0 = \"tfl.mul\"(%arg0, %arg0) {fused_activation_function = \"NONE\"} : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<1x2xf32>\n+  %1 = \"tfl.sum\"(%0, %cst) {keep_dims = false} : (tensor<1x2xf32>, tensor<1xi32>) -> tensor<1xf32>\n+  %2 = \"tfl.rsqrt\"(%1) : (tensor<1xf32>) -> tensor<1xf32>\n+  %3 = \"tfl.add\"(%2, %cst_1) {fused_activation_function = \"NONE\"} : (tensor<1xf32>, tensor<1xf32>) -> tensor<1xf32>\n+  %4 = \"tfl.reshape\"(%3, %cst_shape) : (tensor<1xf32>, tensor<2xi32>) -> tensor<1x1xf32>\n+  %5 = \"tfl.mul\"(%arg0, %4) {fused_activation_function = \"NONE\"} : (tensor<1x2xf32>, tensor<1x1xf32>) -> tensor<1x2xf32>\n+  func.return %5: tensor<1x2xf32>\n+  // CHECK: %[[RES:[0-9].*]] = \"tfl.l2_normalization\"([[INPUT:%.*]]) <{fused_activation_function = \"NONE\"}> : (tensor<1x2xf32>) -> tensor<1x2xf32>\n+  // CHECK: return %[[RES]]\n+}\n+\n+// CHECK-LABEL: @L2NormalizePattern6_Mul\n+func.func @L2NormalizePattern6_Mul(%arg0: tensor<1x2xf32>) -> tensor<1x2xf32> {\n+  %cst = arith.constant dense<[1]> : tensor<1xi32>\n+  %cst_1 = arith.constant dense<[1.0e-4]> : tensor<1xf32>\n+  %cst_shape = arith.constant dense<[1, 1]> : tensor<2xi32>\n+  %0 = \"tfl.mul\"(%arg0, %arg0) {fused_activation_function = \"NONE\"} : (tensor<1x2xf32>, tensor<1x2xf32>) -> tensor<1x2xf32>\n+  %1 = \"tfl.sum\"(%0, %cst) {keep_dims = false} : (tensor<1x2xf32>, tensor<1xi32>) -> tensor<1xf32>\n+  %2 = \"tfl.rsqrt\"(%1) : (tensor<1xf32>) -> tensor<1xf32>\n+  %3 = \"tfl.maximum\"(%2, %cst_1) : (tensor<1xf32>, tensor<1xf32>) -> tensor<1xf32>\n+  %4 = \"tfl.reshape\"(%3, %cst_shape) : (tensor<1xf32>, tensor<2xi32>) -> tensor<1x1xf32>\n+  %5 = \"tfl.mul\"(%arg0, %4) {fused_activation_function = \"NONE\"} : (tensor<1x2xf32>, tensor<1x1xf32>) -> tensor<1x2xf32>\n+  func.return %5: tensor<1x2xf32>\n+  // CHECK: %[[RES:[0-9].*]] = \"tfl.l2_normalization\"([[INPUT:%.*]]) <{fused_activation_function = \"NONE\"}> : (tensor<1x2xf32>) -> tensor<1x2xf32>\n+  // CHECK: return %[[RES]]\n+}\n+\n // CHECK-LABEL: @InvalidL2NormalizePattern2\n // Epsilon in the add must be < 1e-3\n func.func @InvalidL2NormalizePattern2(%arg0: tensor<2xf32>, %arg1: tensor<2xf32>) -> tensor<2xf32> {"
        },
        {
            "sha": "f737e850d4836d1121135df21cd53b00052fb49b",
            "filename": "tensorflow/compiler/mlir/lite/tests/prepare-quantize.mlir",
            "status": "modified",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fprepare-quantize.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fprepare-quantize.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fprepare-quantize.mlir?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -934,6 +934,27 @@ func.func @ReturnQuantizedResult(%arg0: tensor<1x224x224x3xf32>, %arg1: tensor<3\n \n // -----\n \n+// QDQ-LABEL: BroadcastToPerTensorQuantizationPropagation\n+func.func @BroadcastToPerTensorQuantizationPropagation() -> tensor<2x5xf32> {\n+  %shape = arith.constant dense<[2, 5]> : tensor<2xi32>\n+  %cst = arith.constant dense<1.0> : tensor<5xf32>\n+  %q = \"tfl.quantize\"(%cst) {qtype = tensor<5x!quant.uniform<i8<-127:127>:f32, 1.113490e-03>>} : (tensor<5xf32>) -> tensor<5x!quant.uniform<i8<-127:127>:f32, 1.113490e-03>>\n+  %dq = \"tfl.dequantize\"(%q) : (tensor<5x!quant.uniform<i8<-127:127>:f32, 1.113490e-03>>) -> tensor<5xf32>\n+  %t = \"tfl.broadcast_to\"(%dq, %shape) : (tensor<5xf32>, tensor<2xi32>) -> tensor<2x5xf32>\n+  func.return %t : tensor<2x5xf32>\n+\n+  // QDQ: %[[shape:.*]] = arith.constant dense<[2, 5]> : tensor<2xi32>\n+  // QDQ-NEXT: %[[w:.*]] = arith.constant dense<1.000000e+00> : tensor<5xf32>\n+  // QDQ-NEXT: %[[qw:.*]] = \"tfl.quantize\"(%[[w]]) <{qtype = tensor<5x!quant.uniform<i8<-127:127>:f32, 1.113490e-03>>}> : (tensor<5xf32>) -> tensor<5x!quant.uniform<i8<-127:127>:f32, 1.113490e-03>>\n+  // QDQ-NEXT: %[[dqw:.*]] = \"tfl.dequantize\"(%[[qw]]) : (tensor<5x!quant.uniform<i8<-127:127>:f32, 1.113490e-03>>) -> tensor<5xf32>\n+  // QDQ-NEXT: %[[bt:.*]] = \"tfl.broadcast_to\"(%[[dqw]], %[[shape]]) : (tensor<5xf32>, tensor<2xi32>) -> tensor<2x5xf32>\n+  // QDQ-NEXT: %[[qtw:.*]] = \"tfl.quantize\"(%[[bt]]) <{qtype = tensor<2x5x!quant.uniform<i8<-127:127>:f32, 1.113490e-03>>}> {volatile} : (tensor<2x5xf32>) -> tensor<2x5x!quant.uniform<i8<-127:127>:f32, 1.113490e-03>>\n+  // QDQ-NEXT: %[[dqtw:.*]] = \"tfl.dequantize\"(%[[qtw]]) : (tensor<2x5x!quant.uniform<i8<-127:127>:f32, 1.113490e-03>>) -> tensor<2x5xf32>\n+  // QDQ-NEXT: return %[[dqtw]] : tensor<2x5xf32>\n+}\n+\n+// -----\n+\n // QDQ-LABEL: TransposePerTensorQuantizationPropagation\n func.func @TransposePerTensorQuantizationPropagation() -> tensor<2x5xf32> {\n   %perm = arith.constant dense<[1, 0]> : tensor<2xi32>"
        },
        {
            "sha": "5c321a39d8c89031ee671a74a40b1ad9dc6889d8",
            "filename": "tensorflow/compiler/mlir/lite/tests/quantize-strict.mlir",
            "status": "modified",
            "additions": 22,
            "deletions": 0,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fquantize-strict.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fquantize-strict.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fquantize-strict.mlir?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -18,6 +18,28 @@ func.func @QuantizeConvDRQ(%arg0: tensor<1x4x4x3xf32>) -> (tensor<1x4x4x1xf32>)\n \n // -----\n \n+// CHECK-LABEL: QuantizeConvDrqWithPad\n+func.func @QuantizeConvDrqWithPad(%arg0: tensor<1x4x4x3xf32>) -> (tensor<1x6x6x1xf32>) {\n+  %cst = arith.constant dense<0.000000e+00> : tensor<1xf32>\n+  %cst_0 = arith.constant dense<[[[[1.76285899, -0.257785767, 0.20429258], [1.16310906, 0.23124367, 0.529797196]], [[0.348971426, -0.319283515, -0.772461354], [0.316666812, 1.88180697, -1.78054631]]]]> : tensor<1x2x2x3xf32>\n+  %0 = stablehlo.composite \"quant.fake_quant\" %arg0 {composite_attributes = {dtype = \"i8\", narrow_range = false, quantization_dimension = 0 : i32, scale = dense<> : tensor<0xf64>, zero_point = dense<> : tensor<0xi64>}, decomposition = @XlaCallModule_quant.fake_quant.impl_0} : (tensor<1x4x4x3xf32>) -> tensor<1x4x4x3xf32>\n+  %paddings = arith.constant dense<[[0, 0], [1, 1], [1, 1], [0, 0]]> : tensor<4x2xi32>\n+  %1 = \"tfl.pad\"(%0, %paddings) : (tensor<1x4x4x3xf32>, tensor<4x2xi32>) -> tensor<1x6x6x3xf32>\n+  %2 = \"tfl.quantize\"(%cst_0) <{qtype = tensor<1x2x2x3x!quant.uniform<i8:f32, 0.014817377552390099>>}> : (tensor<1x2x2x3xf32>) -> tensor<1x2x2x3x!quant.uniform<i8:f32, 0.014817377552390099>>\n+  %3 = \"tfl.dequantize\"(%2) : (tensor<1x2x2x3x!quant.uniform<i8:f32, 0.014817377552390099>>) -> tensor<1x2x2x3xf32>\n+  %4 = \"tfl.conv_2d\"(%1, %3, %cst) <{dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32}> : (tensor<1x6x6x3xf32>, tensor<1x2x2x3xf32>, tensor<1xf32>) -> tensor<1x6x6x1xf32>\n+  return %4 : tensor<1x6x6x1xf32>\n+\n+// CHECK-LITERAL:    %cst = arith.constant dense<[[0, 0], [1, 1], [1, 1], [0, 0]]> : tensor<4x2xi32>\n+// CHECK:    %cst_0 = arith.constant dense<0.000000e+00> : tensor<1xf32>\n+// CHECK:    %0 = \"tfl.pad\"(%arg0, %cst) : (tensor<1x4x4x3xf32>, tensor<4x2xi32>) -> tensor<1x6x6x3xf32>\n+// CHECK{LITERAL}:    %1 = \"tfl.pseudo_qconst\"() <{qtype = tensor<1x2x2x3x!quant.uniform<i8:f32, 0.014817377552390099>>, value = dense<[[[[119, -17, 14], [78, 16, 36]], [[24, -22, -52], [21, 127, -120]]]]> : tensor<1x2x2x3xi8>}> : () -> tensor<1x2x2x3x!quant.uniform<i8:f32, 0.014817377552390099>>\n+// CHECK:    %2 = \"tfl.conv_2d\"(%0, %1, %cst_0) <{dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32}> : (tensor<1x6x6x3xf32>, tensor<1x2x2x3x!quant.uniform<i8:f32, 0.014817377552390099>>, tensor<1xf32>) -> tensor<1x6x6x1xf32>\n+// CHECK:    return %2 : tensor<1x6x6x1xf32>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: QuantizeConvWithBiasDRQ\n func.func @QuantizeConvWithBiasDRQ(%arg0: tensor<1x4x4x3xf32>) -> (tensor<1x4x4x1xf32>) {\n   %cst = arith.constant dense<1.14751196> : tensor<1xf32>"
        },
        {
            "sha": "0fa79202b63fbd6bd1925be8c371627ad3c7ea14",
            "filename": "tensorflow/compiler/mlir/lite/transforms/optimize_pass.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Foptimize_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Foptimize_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Foptimize_pass.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -121,6 +121,31 @@ bool L2NormalizeReduceAxis(Value sq_op, DenseElementsAttr axis) {\n   return true;\n }\n \n+// Checks if a ReshapeOp is equivalent to a `keep_dims=true` reduction by\n+// adding a trailing dimension of size 1. In the L2 normalization pattern, a\n+// `Sum` op reduces along the last axis, and this reshape is used to add back\n+// the reduced dimension to keep the original rank. This is used in declarative\n+// patterns to fuse L2 normalization operations.\n+bool IsL2NormalizationKeepDimsReshape(Value reshape_output) {\n+  auto producer = reshape_output.getDefiningOp<TFL::ReshapeOp>();\n+  if (!producer) {\n+    return false;\n+  }\n+\n+  auto input_type = mlir::dyn_cast<ShapedType>(producer.getInput().getType());\n+  auto output_type = mlir::dyn_cast<ShapedType>(reshape_output.getType());\n+  if (!input_type || !output_type || !input_type.hasRank() ||\n+      !output_type.hasRank()) {\n+    return false;\n+  }\n+\n+  const auto input_shape = input_type.getShape();\n+  const auto output_shape = output_type.getShape();\n+\n+  return output_shape.size() == input_shape.size() + 1 &&\n+         output_shape.back() == 1 && output_shape.drop_back() == input_shape;\n+}\n+\n // Is rankx2xi32 padding array \"balanced\"\n // i.e. 0 <= [d][1] - [d][0] <= 1 for all spatial dims d (and 0 elsewhere).\n template <typename T>"
        },
        {
            "sha": "3e9cc005dafe014c96a9ce62180132c2d719465b",
            "filename": "tensorflow/compiler/mlir/lite/transforms/optimize_patterns.td",
            "status": "modified",
            "additions": 74,
            "deletions": 3,
            "changes": 77,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Foptimize_patterns.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Foptimize_patterns.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Foptimize_patterns.td?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -389,14 +389,17 @@ def ConstAPFloatNegLargestOrNegInfinity : Constraint<CPred<\n def L2NormValidReduceIndex : Constraint<CPred<\n   \"L2NormalizeReduceAxis($0, llvm::cast<DenseElementsAttr>($1))\">>;\n \n+// Checks if the ReshapeOp adds a trailing dimension of size 1.\n+def IsL2NormalizationKeepDimsReshape\n+    : Constraint<CPred<\"IsL2NormalizationKeepDimsReshape($0)\">>;\n+\n // Currently L2Normalization doesn't support activation function\n // in TFLite.\n // TODO(karimnosseir): Add constraints that the kernel code assumes.\n // constraint on axis and depth.\n multiclass L2NormalizePatterns<Op FirstOp, Op SecondOp> {\n-  // This pattern constructs L2NormalizationOp from\n-  // Mul->Rsqrt->Sum->Square Or\n-  // Div->sqrt->Sum->Square\n+  // Fuses `(x * rsqrt(sum(square(x))))` or `(x / sqrt(sum(square(x))))`\n+  // into a L2NormalizationOp.\n   def L2NormalizePattern1#FirstOp#SecondOp : Pat<\n                   (FirstOp $x,\n                      (SecondOp\n@@ -438,6 +441,74 @@ multiclass L2NormalizePatterns<Op FirstOp, Op SecondOp> {\n            [(L2NormValidReduceIndex $sq_op, $axis),\n             (ConstDoubleValueLessThan<\"1e-3\"> $epsilon)]>;\n \n+  // Fuses L2 norm with Mul(x,x) instead of Square(x) and a reshape that\n+  // emulates keep_dims.\n+  def L2NormalizePattern4#FirstOp#SecondOp : Pat<\n+      (FirstOp $x,\n+          (TFL_ReshapeOp:$reshape_op\n+              (SecondOp\n+                  (TFL_SumOp\n+                      (TFL_MulOp:$mul_op $x, $x, TFL_AF_None),\n+                      (Arith_ConstantOp I32ElementsAttr:$axis),\n+                      ConstBoolAttrFalse\n+                  )\n+              ),\n+              (Arith_ConstantOp $shape)\n+          ),\n+          TFL_AF_None\n+      ),\n+      (TFL_L2NormalizationOp $x, TFL_AF_None),\n+      [(L2NormValidReduceIndex $mul_op, $axis), \n+       (IsL2NormalizationKeepDimsReshape $reshape_op)]\n+  >;\n+\n+  // Fuses L2 norm with Mul(x,x), a reshape, and a small constant add for\n+  // numerical stability.\n+  def L2NormalizePattern5#FirstOp#SecondOp : Pat<\n+      (FirstOp $x,\n+          (TFL_ReshapeOp:$reshape_op\n+              (TFL_AddOp\n+                  (SecondOp\n+                    (TFL_SumOp\n+                        (TFL_MulOp:$mul_op $x, $x, TFL_AF_None),\n+                        (Arith_ConstantOp I32ElementsAttr:$axis),\n+                        ConstBoolAttrFalse\n+                    )\n+                  ), (Arith_ConstantOp $epsilon), TFL_AF_None\n+              ),\n+              (Arith_ConstantOp $shape)\n+          ),\n+          TFL_AF_None\n+      ),\n+      (TFL_L2NormalizationOp $x, TFL_AF_None),\n+      [(L2NormValidReduceIndex $mul_op, $axis), \n+       (IsL2NormalizationKeepDimsReshape $reshape_op),\n+       (ConstDoubleValueLessThan<\"1e-3\"> $epsilon)]\n+  >;\n+\n+  // Fuses L2 norm with Mul(x,x), a reshape, and a small constant maximum for\n+  // numerical stability.\n+  def L2NormalizePattern6#FirstOp#SecondOp : Pat<\n+      (FirstOp $x,\n+          (TFL_ReshapeOp:$reshape_op\n+              (TFL_MaximumOp\n+                  (SecondOp\n+                    (TFL_SumOp\n+                        (TFL_MulOp:$mul_op $x, $x, TFL_AF_None),\n+                        (Arith_ConstantOp I32ElementsAttr:$axis),\n+                        ConstBoolAttrFalse\n+                    )\n+                  ), (Arith_ConstantOp $epsilon)\n+              ),\n+              (Arith_ConstantOp $shape)\n+          ),\n+          TFL_AF_None\n+      ),\n+      (TFL_L2NormalizationOp $x, TFL_AF_None),\n+      [(L2NormValidReduceIndex $mul_op, $axis), \n+       (IsL2NormalizationKeepDimsReshape $reshape_op),\n+       (ConstDoubleValueLessThan<\"1e-3\"> $epsilon)]\n+  >;\n }\n \n foreach L2NormalizePairs = [[TFL_MulOp, TFL_RsqrtOp], [TFL_DivOp, TFL_SqrtOp]]"
        },
        {
            "sha": "d0c143d73914c96d4007fddf38d7fecea0639cca",
            "filename": "tensorflow/compiler/mlir/lite/transforms/quantize.cc",
            "status": "modified",
            "additions": 53,
            "deletions": 1,
            "changes": 54,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Fquantize.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Fquantize.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Fquantize.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -176,6 +176,57 @@ class RemoveUnusedFQ : public OpRewritePattern<stablehlo::CompositeOp> {\n   }\n };\n \n+// Pushes a drq fake quant op forward through a pad op.\n+// This is to allow DRQ FQ to be fused into the DRQ op.\n+// drq_fake_quant(input) -> pad -> output\n+// becomes\n+// input -> pad -> drq_fake_quant -> output\n+class PushForwardDrqFQ : public OpRewritePattern<stablehlo::CompositeOp> {\n+ public:\n+  using OpRewritePattern<stablehlo::CompositeOp>::OpRewritePattern;\n+\n+  LogicalResult matchAndRewrite(stablehlo::CompositeOp drq_fq_op,\n+                                PatternRewriter& rewriter) const final {\n+    if (!IsDrqFakeQuant(drq_fq_op)) {\n+      return rewriter.notifyMatchFailure(drq_fq_op,\n+                                         \"is not a drq fake quant op.\");\n+    }\n+\n+    if (!drq_fq_op.getResult(0).hasOneUse()) {\n+      return rewriter.notifyMatchFailure(\n+          drq_fq_op, \"drq fake quant op does not have one use.\");\n+    }\n+    auto pad_op =\n+        llvm::dyn_cast<TFL::PadOp>(*drq_fq_op.getResult(0).user_begin());\n+    if (!pad_op) {\n+      return rewriter.notifyMatchFailure(drq_fq_op,\n+                                         \"user is not a tfl.pad op.\");\n+    }\n+\n+    // The input to the new pad op is the float input to the drq fake quant op.\n+    Value float_input = drq_fq_op.getOperand(drq_fq_op.getNumOperands() - 1);\n+\n+    // Create a new pad op.\n+    auto new_pad_op = rewriter.create<TFL::PadOp>(\n+        pad_op.getLoc(), pad_op.getType(), float_input, pad_op.getPadding());\n+\n+    // Create a new drq fake quant op.\n+    // Operands are the same, except for the last one.\n+    SmallVector<Value> new_drq_operands;\n+    for (Value operand : drq_fq_op.getOperands().drop_back()) {\n+      new_drq_operands.push_back(operand);\n+    }\n+    new_drq_operands.push_back(new_pad_op.getResult());\n+\n+    auto new_drq_fq_op = rewriter.create<stablehlo::CompositeOp>(\n+        drq_fq_op.getLoc(), pad_op.getType(), new_drq_operands,\n+        drq_fq_op->getAttrs());\n+\n+    rewriter.replaceOp(pad_op, new_drq_fq_op.getResult(0));\n+    return success();\n+  }\n+};\n+\n class StrictQuantizationPattern : public RewritePattern {\n  public:\n   using BaseType = StrictQuantizationPattern;\n@@ -693,7 +744,8 @@ void QuantizePass::runOnOperation() {\n \n   if (quant_specs.qdq_conversion_mode == QDQConversionMode::kQDQStrict) {\n     patterns.add<StrictQuantizationPattern>(ctx, quant_params);\n-    patterns.add<RemoveUnusedFQ, SquashDqQ, FuseDqQToRequant>(ctx);\n+    patterns.add<RemoveUnusedFQ, SquashDqQ, FuseDqQToRequant, PushForwardDrqFQ>(\n+        ctx);\n   } else if (quant_specs.weight_quantization ||\n              quant_specs.use_fake_quant_num_bits ||\n              quant_specs.qdq_conversion_mode =="
        },
        {
            "sha": "9ec71c36687c65b31849970c75d12e688a17fcef",
            "filename": "tensorflow/compiler/mlir/tensorflow/tests/cannonicalize_ops_outside_compilation.mlir",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fcannonicalize_ops_outside_compilation.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fcannonicalize_ops_outside_compilation.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fcannonicalize_ops_outside_compilation.mlir?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -6,10 +6,7 @@\n \n // Reshape should not be executed on TPU as all are marked by outside\n // compilation. And there should be no host-device communication.\n-// CHECK: tf._TPUCompile\n-// CHECK-NOT: tf.Reshape\n-// CHECK: launch{{.*}}CPU\n-// CHECK: tf.TPUCompileSucceeded\n+// CHECK: tf._TPUCompileMlir\n // CHECK-NOT: tf.Reshape\n // CHECK-NOT: tf._XlaHostComputeMlir\n "
        },
        {
            "sha": "8c1920efd9432d2edd4a3605bd28214464fbc82b",
            "filename": "tensorflow/compiler/mlir/tensorflow/tests/ici_weight_distribution_spmd_mlir_end_to_end.mlir",
            "status": "modified",
            "additions": 19,
            "deletions": 20,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fici_weight_distribution_spmd_mlir_end_to_end.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fici_weight_distribution_spmd_mlir_end_to_end.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftests%2Fici_weight_distribution_spmd_mlir_end_to_end.mlir?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1,32 +1,31 @@\n // RUN: tf-opt %s -tf-replicated-clustering-bridge-v2 -tfrt-lower-cluster-to-runtime-ops-tpu -tf-dialect-to-executor-v2 | FileCheck %s\n \n // CHECK-LABEL: func.func @main\n-// CHECK: %outputs:5, %control = tf_executor.island wraps \"tf._TPUCompileMlir\"()\n-// CHECK: %outputs_0, %control_1 = tf_executor.island wraps \"tf.ReadVariableOp\"(%arg3) : (tensor<*x!tf_type.resource<tensor<128x1024xf32>>>) -> tensor<128x1024xf32>\n-// CHECK: %outputs_2, %control_3 = tf_executor.island wraps \"tf.ReadVariableOp\"(%arg4) : (tensor<*x!tf_type.resource<tensor<1024xf32>>>) -> tensor<1024xf32>\n-// CHECK: %outputs_4, %control_5 = tf_executor.island wraps \"tf.TPUDummyInput\"() <{shape = #tf_type.shape<128x1024>}> {_ici_weight_distribution_mlir_bridge_marker = true} : () -> tensor<128x1024xf32>\n-// CHECK: %outputs_6, %control_7 = tf_executor.island wraps \"tf.TPUDummyInput\"() <{shape = #tf_type.shape<1024>}> {_ici_weight_distribution_mlir_bridge_marker = true} : () -> tensor<1024xf32>\n-// CHECK: %outputs_8, %control_9 = tf_executor.island wraps \"tf.Identity\"(%outputs#0) {device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<!tf_type.string>) -> tensor<!tf_type.string>\n+// CHECK: %outputs, %control = tf_executor.island wraps \"tf.ReadVariableOp\"(%arg3) : (tensor<*x!tf_type.resource<tensor<128x1024xf32>>>) -> tensor<128x1024xf32>\n+// CHECK: %outputs_0, %control_1 = tf_executor.island wraps \"tf.ReadVariableOp\"(%arg4) : (tensor<*x!tf_type.resource<tensor<1024xf32>>>) -> tensor<1024xf32>\n+// CHECK: %outputs_2, %control_3 = tf_executor.island wraps \"tf.TPUDummyInput\"() <{shape = #tf_type.shape<128x1024>}> {_ici_weight_distribution_mlir_bridge_marker = true} : () -> tensor<128x1024xf32>\n+// CHECK: %outputs_4, %control_5 = tf_executor.island wraps \"tf.TPUDummyInput\"() <{shape = #tf_type.shape<1024>}> {_ici_weight_distribution_mlir_bridge_marker = true} : () -> tensor<1024xf32>\n+// CHECK: %outputs_6:5, %control_7 = tf_executor.island wraps \"tf._TPUCompileMlir\"()\n+// CHECK: %outputs_8, %control_9 = tf_executor.island wraps \"tf.Identity\"(%outputs_6#0) {device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<!tf_type.string>) -> tensor<!tf_type.string>\n // CHECK: %control_10 = tf_executor.island wraps \"tf.TPUCompileSucceededAssert\"(%outputs_8) {device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<!tf_type.string>) -> ()\n // CHECK: %outputs_11, %control_12 = tf_executor.island wraps \"tf.Const\"() <{value = dense<0> : tensor<i32>}> {_ici_weight_distribution_mlir_bridge_marker = true} : () -> tensor<i32>\n-// CHECK: %outputs_13, %control_14 = tf_executor.island wraps \"tf.Identity\"(%outputs_0) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<128x1024xf32>) -> tensor<128x1024xf32>\n-// CHECK: %outputs_15, %control_16 = tf_executor.island wraps \"tf.Identity\"(%outputs_2) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<1024xf32>) -> tensor<1024xf32>\n+// CHECK: %outputs_13, %control_14 = tf_executor.island wraps \"tf.Identity\"(%outputs) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<128x1024xf32>) -> tensor<128x1024xf32>\n+// CHECK: %outputs_15, %control_16 = tf_executor.island wraps \"tf.Identity\"(%outputs_0) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"} : (tensor<1024xf32>) -> tensor<1024xf32>\n // CHECK: %outputs_17:4, %control_18 = tf_executor.island wraps \"tf.Split\"(%outputs_11, %outputs_13) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:0\", num_split = 4 : i32} : (tensor<i32>, tensor<128x1024xf32>) -> (tensor<32x1024xf32>, tensor<32x1024xf32>, tensor<32x1024xf32>, tensor<32x1024xf32>)\n-// CHECK: %outputs_19, %control_20 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#0, %outputs_15, %outputs#1) {_parallel_execution_ids = \"r0:0,p0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_21, %control_22 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#1, %outputs_15, %outputs#2) {_parallel_execution_ids = \"r0:0,p0:1\", device = \"/job:tpu_host_worker/replica:0/task:0/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_23, %control_24 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#2, %outputs_15, %outputs#3) {_parallel_execution_ids = \"r0:0,p0:2\", device = \"/job:tpu_host_worker/replica:0/task:1/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_25, %control_26 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#3, %outputs_15, %outputs#4) {_parallel_execution_ids = \"r0:0,p0:3\", device = \"/job:tpu_host_worker/replica:0/task:1/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_27, %control_28 = tf_executor.island wraps \"tf.Identity\"(%outputs_4) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"} : (tensor<128x1024xf32>) -> tensor<128x1024xf32>\n-// CHECK: %outputs_29, %control_30 = tf_executor.island wraps \"tf.Identity\"(%outputs_6) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"} : (tensor<1024xf32>) -> tensor<1024xf32>\n+// CHECK: %outputs_19, %control_20 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#0, %outputs_15, %outputs_6#1) {_parallel_execution_ids = \"r0:0,p0:0\", device = \"/job:tpu_host_worker/replica:0/task:0/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_21, %control_22 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#1, %outputs_15, %outputs_6#2) {_parallel_execution_ids = \"r0:0,p0:1\", device = \"/job:tpu_host_worker/replica:0/task:0/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_23, %control_24 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#2, %outputs_15, %outputs_6#3) {_parallel_execution_ids = \"r0:0,p0:2\", device = \"/job:tpu_host_worker/replica:0/task:1/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_25, %control_26 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_17#3, %outputs_15, %outputs_6#4) {_parallel_execution_ids = \"r0:0,p0:3\", device = \"/job:tpu_host_worker/replica:0/task:1/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_27, %control_28 = tf_executor.island wraps \"tf.Identity\"(%outputs_2) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"} : (tensor<128x1024xf32>) -> tensor<128x1024xf32>\n+// CHECK: %outputs_29, %control_30 = tf_executor.island wraps \"tf.Identity\"(%outputs_4) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"} : (tensor<1024xf32>) -> tensor<1024xf32>\n // CHECK: %outputs_31:4, %control_32 = tf_executor.island wraps \"tf.Split\"(%outputs_11, %outputs_27) {_ici_weight_distribution_mlir_bridge_marker = true, _parallel_execution_ids = \"r0:1\", num_split = 4 : i32} : (tensor<i32>, tensor<128x1024xf32>) -> (tensor<32x1024xf32>, tensor<32x1024xf32>, tensor<32x1024xf32>, tensor<32x1024xf32>)\n-// CHECK: %outputs_33, %control_34 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#0, %outputs_29, %outputs#1) {_parallel_execution_ids = \"r0:1,p0:0\", device = \"/job:tpu_host_worker/replica:0/task:2/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_35, %control_36 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#1, %outputs_29, %outputs#2) {_parallel_execution_ids = \"r0:1,p0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_37, %control_38 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#2, %outputs_29, %outputs#3) {_parallel_execution_ids = \"r0:1,p0:2\", device = \"/job:tpu_host_worker/replica:0/task:3/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n-// CHECK: %outputs_39, %control_40 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#3, %outputs_29, %outputs#4) {_parallel_execution_ids = \"r0:1,p0:3\", device = \"/job:tpu_host_worker/replica:0/task:3/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_33, %control_34 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#0, %outputs_29, %outputs_6#1) {_parallel_execution_ids = \"r0:1,p0:0\", device = \"/job:tpu_host_worker/replica:0/task:2/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_35, %control_36 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#1, %outputs_29, %outputs_6#2) {_parallel_execution_ids = \"r0:1,p0:1\", device = \"/job:tpu_host_worker/replica:0/task:2/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_37, %control_38 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#2, %outputs_29, %outputs_6#3) {_parallel_execution_ids = \"r0:1,p0:2\", device = \"/job:tpu_host_worker/replica:0/task:3/device:TPU:0\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n+// CHECK: %outputs_39, %control_40 = tf_executor.island wraps \"tf.TPUExecute\"(%outputs_31#3, %outputs_29, %outputs_6#4) {_parallel_execution_ids = \"r0:1,p0:3\", device = \"/job:tpu_host_worker/replica:0/task:3/device:TPU:1\"} : (tensor<32x1024xf32>, tensor<1024xf32>, tensor<3x!tf_type.string>) -> tensor<*xf32>\n // CHECK: %outputs_41, %control_42 = tf_executor.island wraps \"tf.ReadVariableOp\"(%arg2) {device = \"\"} : (tensor<*x!tf_type.resource<tensor<i64>>>) -> tensor<i64>\n // CHECK: %outputs_43, %control_44 = tf_executor.island wraps \"tf.Identity\"(%outputs_41) {device = \"\"} : (tensor<i64>) -> tensor<i64>\n-// CHECK: tf_executor.fetch %outputs_43, %control_1, %control_3, %control_20, %control_22, %control_24, %control_26, %control_34, %control_36, %control_38, %control_40, %control_42 : tensor<i64>, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control\n-\n+// CHECK: tf_executor.fetch %outputs_43, %control, %control_1, %control_20, %control_22, %control_24, %control_26, %control_34, %control_36, %control_38, %control_40, %control_42 : tensor<i64>, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control, !tf_executor.control\n \n module attributes {tf.devices = {\"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\", \"/job:tpu_host_worker/replica:0/task:0/device:TPU:0\", \"/job:tpu_host_worker/replica:0/task:0/device:TPU:1\", \"/job:tpu_host_worker/replica:0/task:0/device:TPU_SYSTEM:0\", \"/job:tpu_host_worker/replica:0/task:1/device:CPU:0\", \"/job:tpu_host_worker/replica:0/task:1/device:TPU:0\", \"/job:tpu_host_worker/replica:0/task:1/device:TPU:1\", \"/job:tpu_host_worker/replica:0/task:1/device:TPU_SYSTEM:0\", \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\", \"/job:tpu_host_worker/replica:0/task:2/device:TPU:0\", \"/job:tpu_host_worker/replica:0/task:2/device:TPU:1\", \"/job:tpu_host_worker/replica:0/task:2/device:TPU_SYSTEM:0\", \"/job:tpu_host_worker/replica:0/task:3/device:CPU:0\", \"/job:tpu_host_worker/replica:0/task:3/device:TPU:0\", \"/job:tpu_host_worker/replica:0/task:3/device:TPU:1\", \"/job:tpu_host_worker/replica:0/task:3/device:TPU_SYSTEM:0\"}, tf.versions = {bad_consumers = [], min_consumer = 0 : i32, producer = 1857 : i32}} {\n   func.func @main(%arg0: tensor<i32> {tf._user_specified_name = \"steps\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg1: tensor<*x!tf_type.resource<tensor<i64>>> {tf._user_specified_name = \"899\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg2: tensor<*x!tf_type.resource<tensor<i64>>> {tf._user_specified_name = \"901\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg3: tensor<*x!tf_type.resource<tensor<128x1024xf32>>> {tf._user_specified_name = \"903\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg4: tensor<*x!tf_type.resource<tensor<1024xf32>>> {tf._user_specified_name = \"905\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg5: tensor<*x!tf_type.resource<tensor<1024x1xf32>>> {tf._user_specified_name = \"907\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg6: tensor<*x!tf_type.resource<tensor<i64>>> {tf._user_specified_name = \"909\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg7: tensor<*x!tf_type.resource<tensor<25001x64xf32>>> {tf._user_specified_name = \"911\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg8: tensor<*x!tf_type.resource<tensor<25001x64xf32>>> {tf._user_specified_name = \"913\", tf.device = \"/job:tpu_host_worker/replica:0/task:1/device:CPU:0\"}, %arg9: tensor<*x!tf_type.resource<tensor<25001x64xf32>>> {tf._user_specified_name = \"915\", tf.device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"}, %arg10: tensor<*x!tf_type.resource<tensor<25001x64xf32>>> {tf._user_specified_name = \"917\", tf.device = \"/job:tpu_host_worker/replica:0/task:3/device:CPU:0\"}, %arg11: tensor<*x!tf_type.resource<tensor<25001x32xf32>>> {tf._user_specified_name = \"919\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg12: tensor<*x!tf_type.resource<tensor<25001x32xf32>>> {tf._user_specified_name = \"921\", tf.device = \"/job:tpu_host_worker/replica:0/task:1/device:CPU:0\"}, %arg13: tensor<*x!tf_type.resource<tensor<25001x32xf32>>> {tf._user_specified_name = \"923\", tf.device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"}, %arg14: tensor<*x!tf_type.resource<tensor<25001x32xf32>>> {tf._user_specified_name = \"925\", tf.device = \"/job:tpu_host_worker/replica:0/task:3/device:CPU:0\"}, %arg15: tensor<*x!tf_type.resource<tensor<6x32xf32>>> {tf._user_specified_name = \"927\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg16: tensor<*x!tf_type.resource<tensor<6x32xf32>>> {tf._user_specified_name = \"929\", tf.device = \"/job:tpu_host_worker/replica:0/task:1/device:CPU:0\"}, %arg17: tensor<*x!tf_type.resource<tensor<6x32xf32>>> {tf._user_specified_name = \"931\", tf.device = \"/job:tpu_host_worker/replica:0/task:2/device:CPU:0\"}, %arg18: tensor<*x!tf_type.resource<tensor<6x32xf32>>> {tf._user_specified_name = \"933\", tf.device = \"/job:tpu_host_worker/replica:0/task:3/device:CPU:0\"}, %arg19: tensor<*x!tf_type.resource<tensor<128x1024xf32>>> {tf._user_specified_name = \"935\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg20: tensor<*x!tf_type.resource<tensor<1024xf32>>> {tf._user_specified_name = \"937\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}, %arg21: tensor<*x!tf_type.resource<tensor<1024x1xf32>>> {tf._user_specified_name = \"939\", tf.device = \"/job:tpu_host_worker/replica:0/task:0/device:CPU:0\"}) -> tensor<*xi64> attributes {allow_soft_placement = false, tf.entry_function = {control_outputs = \"\", inputs = \"steps,unknown,unknown_0,unknown_1,unknown_2,unknown_3,unknown_4,unknown_5,unknown_6,unknown_7,unknown_8,unknown_9,unknown_10,unknown_11,unknown_12,unknown_13,unknown_14,unknown_15,unknown_16,unknown_17,unknown_18,unknown_19\", outputs = \"statefulpartitionedcall_RetVal\"}} {"
        },
        {
            "sha": "266e95e74e8e80ba947ac3669888296d1e1fa65e",
            "filename": "tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/lower_cluster_to_runtime_ops.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -79,7 +79,6 @@ void AddTPULowerClusterToRuntimeOpsPassPipeline(OpPassManager& pm,\n   pm.addPass(mlir::createSymbolDCEPass());\n   pm.addNestedPass<FuncOp>(\n       mlir::TFDevice::CreateReplicateInvariantOpHoistingPass());\n-  pm.addPass(mlir::TF::CreateOrderForProgramKeyPass());\n   pm.addNestedPass<FuncOp>(mlir::TFDevice::CreateEmbeddingProgramKeyPass());\n   pm.addPass(mlir::TFTPU::CreateTPUMergeVariablesWithExecutePass());\n   pm.addNestedPass<FuncOp>("
        },
        {
            "sha": "0130e7a63c70bc3368e317e07e656bf75f9d43d8",
            "filename": "tensorflow/compiler/mlir/tensorflow/transforms/host_runtime/lower_cluster_to_runtime_ops_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fhost_runtime%2Flower_cluster_to_runtime_ops_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -191,7 +191,7 @@ TEST_F(LowerClusterToRuntimeOpsTest, DumpsPipelinePasses) {\n       *mlir_module_, DeviceType(DEVICE_TPU_XLA_JIT)));\n \n   TF_ASSERT_OK(env_->GetChildren(test_dir_, &files));\n-  EXPECT_THAT(files, ::testing::SizeIs(16));\n+  EXPECT_THAT(files, ::testing::SizeIs(15));\n }\n \n }  // namespace"
        },
        {
            "sha": "d590a953232018fe6a0792aeba31db9df84ed1d5",
            "filename": "tensorflow/compiler/mlir/tools/kernel_gen/transforms/copy_cleanup_pass.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Ftools%2Fkernel_gen%2Ftransforms%2Fcopy_cleanup_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Fmlir%2Ftools%2Fkernel_gen%2Ftransforms%2Fcopy_cleanup_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftools%2Fkernel_gen%2Ftransforms%2Fcopy_cleanup_pass.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -104,10 +104,12 @@ void RemoveCopyIfTargetOnlyRead(func::FuncOp func) {\n       SmallVector<MemoryEffects::EffectInstance, 2> effects;\n       effect_interface.getEffects<MemoryEffects::Write>(effects);\n       for (auto effect : effects) {\n-        if (auto alloc = effect.getValue().getDefiningOp<memref::AllocOp>()) {\n-          if (alloc->getBlock() == copy->getBlock() &&\n-              copy->isBeforeInBlock(alloc)) {\n-            continue;\n+        if (effect.getValue() != nullptr) {\n+          if (auto alloc = effect.getValue().getDefiningOp<memref::AllocOp>()) {\n+            if (alloc->getBlock() == copy->getBlock() &&\n+                copy->isBeforeInBlock(alloc)) {\n+              continue;\n+            }\n           }\n         }\n         source_is_mutated = true;"
        },
        {
            "sha": "3b37da874b585be9f91c164857fff7ac72d95f7c",
            "filename": "tensorflow/compiler/tf2xla/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -369,12 +369,10 @@ cc_library(\n #         \"@local_xla//xla/tsl/platform/default:context\",\n #         \"@local_xla//xla/tsl/platform/default:cord\",\n #         \"@local_xla//xla/tsl/platform/default:env_time\",\n-#         \"@local_xla//xla/tsl/platform/default:logging\",\n #         \"@local_xla//xla/tsl/platform/default:types\",\n #         \"@local_xla//xla/tsl/platform/google:context\",\n #         \"@local_xla//xla/tsl/platform/google:cord\",\n #         \"@local_xla//xla/tsl/platform/google:env_time\",\n-#         \"@local_xla//xla/tsl/platform/google:logging\",\n #         \"@local_xla//xla/tsl/platform/google:types\",\n #         \"@local_xla//xla/tsl/platform/windows:env_time\",\n #         \"//tensorflow/core/platform:bfloat16\","
        },
        {
            "sha": "8fde99e62ff656217a167b922d579c03842edcbc",
            "filename": "tensorflow/core/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -495,7 +495,6 @@ cc_library(\n         \"@local_xla//xla/tsl/framework:numeric_types.h\",\n         \"@local_xla//xla/tsl/framework:type_traits.h\",\n         \"@local_xla//xla/tsl/platform/default:integral_types.h\",\n-        \"@local_xla//xla/tsl/platform/default:logging.h\",\n     ],\n     visibility = [\"//visibility:public\"],\n     deps = [\n@@ -1539,7 +1538,6 @@ cc_library(\n         \"//tensorflow/core/platform:tflite_portable_logging_hdrs\",\n         \"@local_tsl//tsl/platform:tflite_portable_logging_hdrs\",\n         \"@local_xla//xla/tsl/platform/default:integral_types.h\",\n-        \"@local_xla//xla/tsl/platform/default:logging.h\",\n     ],\n     compatible_with = get_compatible_with_portable(),\n     copts = tf_copts(),"
        },
        {
            "sha": "cd0445931fc156c311241684033c7b9192f14495",
            "filename": "tensorflow/core/common_runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fcommon_runtime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fcommon_runtime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -2755,6 +2755,7 @@ tf_cuda_cc_test(\n         \"//tensorflow/core:test_main\",\n         \"//tensorflow/core:testlib\",\n         \"//tensorflow/core/kernels:cast_op\",\n+        \"@com_google_absl//absl/status\",\n     ],\n )\n "
        },
        {
            "sha": "26f414c14204cee1650b94b405468c688a712c11",
            "filename": "tensorflow/core/common_runtime/memory_types_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fcommon_runtime%2Fmemory_types_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fcommon_runtime%2Fmemory_types_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fmemory_types_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -52,7 +52,7 @@ TEST(MemoryTypeChecker, Int32NotOk) {\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n   // There is no kernel for casting int32/host memory to float/device\n   // memory.\n-  EXPECT_TRUE(errors::IsInternal(ValidateMemoryTypes(DEVICE_GPU, g)));\n+  EXPECT_TRUE(absl::IsInternal(ValidateMemoryTypes(DEVICE_GPU, g)));\n \n   // But we can insert _HostSend/_HostRecv to ensure the invariant.\n   TF_EXPECT_OK(EnsureMemoryTypes(DEVICE_GPU, \"/device:GPU:0\", g));"
        },
        {
            "sha": "e23d6445fadaabc52bf9f427ce41941c761ccff1",
            "filename": "tensorflow/core/common_runtime/next_pluggable_device/c_plugin_coordination_service_agent_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fcommon_runtime%2Fnext_pluggable_device%2Fc_plugin_coordination_service_agent_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fcommon_runtime%2Fnext_pluggable_device%2Fc_plugin_coordination_service_agent_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fnext_pluggable_device%2Fc_plugin_coordination_service_agent_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -102,6 +102,10 @@ class TestCoordinationClient : public CoordinationClient {\n               (const TryGetKeyValueRequest*, TryGetKeyValueResponse*,\n                StatusCallback),\n               (override));\n+  MOCK_METHOD(void, IncrementKeyValueAsync,\n+              (const IncrementKeyValueRequest*, IncrementKeyValueResponse*,\n+               StatusCallback),\n+              (override));\n   MOCK_METHOD(void, InsertKeyValueAsync,\n               (const InsertKeyValueRequest*, InsertKeyValueResponse*,\n                StatusCallback),"
        },
        {
            "sha": "0f495b17a69544ee28d5380d4af9445bf6899b1d",
            "filename": "tensorflow/core/framework/common_shape_fns.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fframework%2Fcommon_shape_fns.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fframework%2Fcommon_shape_fns.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fframework%2Fcommon_shape_fns.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -710,7 +710,7 @@ absl::Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n     absl::Status s = c->GetAttr(\"explicit_paddings\", &explicit_paddings);\n     // Use the default value, which is an empty list, if the attribute is not\n     // found. Otherwise return the error to the caller.\n-    if (!s.ok() && !errors::IsNotFound(s)) {\n+    if (!s.ok() && !absl::IsNotFound(s)) {\n       return s;\n     }\n     TF_RETURN_IF_ERROR(CheckValidPadding(padding, explicit_paddings,\n@@ -724,7 +724,7 @@ absl::Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n     // `padding_list` attribute is used by Fused int8 convolutions to support\n     // explicit paddings.\n     absl::Status s_p_list = c->GetAttr(\"padding_list\", &p_list);\n-    if (!s_p_list.ok() && !errors::IsNotFound(s_p_list)) {\n+    if (!s_p_list.ok() && !absl::IsNotFound(s_p_list)) {\n       return s_p_list;\n     }\n     if (s_p_list.ok() && !p_list.empty()) {\n@@ -1872,7 +1872,7 @@ absl::Status MaxPoolShapeImpl(shape_inference::InferenceContext* c,\n     absl::Status status = c->GetAttr(\"explicit_paddings\", &explicit_paddings);\n     // Use the default value, which is an empty list, if the attribute is not\n     // found. Otherwise return the error to the caller.\n-    if (!status.ok() && !errors::IsNotFound(status)) {\n+    if (!status.ok() && !absl::IsNotFound(status)) {\n       return status;\n     }\n     TF_RETURN_IF_ERROR(CheckValidPadding(padding, explicit_paddings,"
        },
        {
            "sha": "af17a62947d66774564c1bdc674dfb4064390009",
            "filename": "tensorflow/core/kernels/linalg/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -279,6 +279,7 @@ tf_kernel_library(\n         \"//tensorflow/core:framework\",\n         \"//tensorflow/core:lib\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n+        \"@com_google_absl//absl/status\",\n         \"@eigen_archive//:eigen3\",\n     ],\n )"
        },
        {
            "sha": "bd9582d9a5cc10e183de0057a98e8b33ff9500a3",
            "filename": "tensorflow/core/kernels/linalg/cholesky_op_gpu.cu.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fcholesky_op_gpu.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fcholesky_op_gpu.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fcholesky_op_gpu.cu.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -195,7 +195,7 @@ class CholeskyOpGpu : public AsyncOpKernel {\n     auto info_checker = [context, done, n](\n                             const Status& status,\n                             const std::vector<HostLapackInfo>& host_infos) {\n-      if (!status.ok() && errors::IsInvalidArgument(status) &&\n+      if (!status.ok() && absl::IsInvalidArgument(status) &&\n           !host_infos.empty()) {\n         Tensor* output = context->mutable_output(0);\n         auto output_reshaped = output->template flat_inner_dims<Scalar, 3>();"
        },
        {
            "sha": "e4590f8def21dec001b738199bab4456c587c65e",
            "filename": "tensorflow/core/kernels/linalg/determinant_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fdeterminant_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fdeterminant_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fdeterminant_op.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -237,7 +237,7 @@ class DeterminantOpGpu : public AsyncOpKernel {\n     auto info_checker = [context, done](\n                             const Status& status,\n                             const std::vector<HostLapackInfo>& host_infos) {\n-      if (!status.ok() && errors::IsInvalidArgument(status) &&\n+      if (!status.ok() && absl::IsInvalidArgument(status) &&\n           !host_infos.empty()) {\n         for (int i = 0; i < host_infos[0].size(); ++i) {\n           // It is OK for a matrix to be singular (signaled by info > 0),\n@@ -383,7 +383,7 @@ class LogDeterminantOpGpu : public AsyncOpKernel {\n     auto info_checker = [context, done](\n                             const Status& status,\n                             const std::vector<HostLapackInfo>& host_infos) {\n-      if (!status.ok() && errors::IsInvalidArgument(status) &&\n+      if (!status.ok() && absl::IsInvalidArgument(status) &&\n           !host_infos.empty()) {\n         for (int i = 0; i < host_infos[0].size(); ++i) {\n           // It is OK for a matrix to be singular (signaled by info > 0),"
        },
        {
            "sha": "74004c7147a96902d75284e336f3e69b790dae93",
            "filename": "tensorflow/core/kernels/linalg/lu_op_gpu.cu.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2Flu_op_gpu.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2Flu_op_gpu.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Flu_op_gpu.cu.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -19,6 +19,7 @@ limitations under the License.\n #include <algorithm>\n #include <vector>\n \n+#include \"absl/status/status.h\"\n #include \"unsupported/Eigen/CXX11/Tensor\"  // from @eigen_archive\n #include \"tensorflow/core/framework/kernel_def_builder.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n@@ -238,7 +239,7 @@ class LuOpGpu : public AsyncOpKernel {\n     auto info_checker = [context, done, dev_info](\n                             const Status& status,\n                             const std::vector<HostLapackInfo>& host_infos) {\n-      if (!status.ok() && errors::IsInvalidArgument(status) &&\n+      if (!status.ok() && absl::IsInvalidArgument(status) &&\n           !host_infos.empty()) {\n         for (int i = 0; i < host_infos[0].size(); ++i) {\n           // Match the CPU error message for singular matrices. Otherwise"
        },
        {
            "sha": "e542b838d3754c5f9a34d6b8543701e6ef0cb461",
            "filename": "tensorflow/core/kernels/linalg/matrix_inverse_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_inverse_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_inverse_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_inverse_op.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -292,7 +292,7 @@ class MatrixInverseOpGpu : public AsyncOpKernel {\n     auto info_checker = [context, done](\n                             const Status& status,\n                             const std::vector<HostLapackInfo>& host_infos) {\n-      if (!status.ok() && errors::IsInvalidArgument(status)) {\n+      if (!status.ok() && absl::IsInvalidArgument(status)) {\n         for (const auto& host_info : host_infos) {\n           for (int i = 0; i < host_info.size(); ++i) {\n             // Match the CPU error message for singular matrices. Otherwise"
        },
        {
            "sha": "5b88e5d89a05b51aba30bb03dc4580b7a8f558f9",
            "filename": "tensorflow/core/kernels/linalg/matrix_solve_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Flinalg%2Fmatrix_solve_op.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -367,7 +367,7 @@ class MatrixSolveOpGpu : public AsyncOpKernel {\n     auto info_checker = [context, done, dev_info](\n                             const Status& status,\n                             const std::vector<HostLapackInfo>& host_infos) {\n-      if (!status.ok() && errors::IsInvalidArgument(status) &&\n+      if (!status.ok() && absl::IsInvalidArgument(status) &&\n           !host_infos.empty()) {\n         for (int i = 0; i < host_infos[0].size(); ++i) {\n           // Match the CPU error message for singular matrices. Otherwise"
        },
        {
            "sha": "8c27edc30dcc7c097bbb1a28649d60c093070b0e",
            "filename": "tensorflow/core/lib/gif/BUILD",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Flib%2Fgif%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Flib%2Fgif%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Flib%2Fgif%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -53,18 +53,26 @@ cc_library(\n         \"//tensorflow/core/platform:gif_internal_hdrs\",\n         \"@local_tsl//tsl/platform:gif_internal_hdrs\",\n         \"@local_xla//xla/tsl/platform/default:integral_types.h\",\n-        \"@local_xla//xla/tsl/platform/default:logging.h\",\n     ],\n     copts = tf_copts(),\n     features = [\"-layering_check\"],\n     linkopts = if_android([\"-ldl\"]),\n     deps = [\n+        \"//tensorflow/core/platform:byte_order\",\n+        \"//tensorflow/core/platform:cord\",\n         \"//tensorflow/core/platform:dynamic_annotations\",\n         \"//tensorflow/core/platform:gif\",\n         \"//tensorflow/core/platform:logging\",\n         \"//tensorflow/core/platform:stringpiece\",\n         \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/base:dynamic_annotations\",\n         \"@com_google_absl//absl/strings\",\n+        \"@eigen_archive//:eigen3\",\n+        \"@gif\",\n+        \"@local_tsl//tsl/platform:logging\",\n+        \"@local_tsl//tsl/platform:tstring\",\n+        \"@local_tsl//tsl/platform:types\",\n+        \"@local_xla//xla/tsl/platform:types\",\n     ],\n )\n "
        },
        {
            "sha": "628b027ad9f6581b57106d2c5808f4ec62166110",
            "filename": "tensorflow/core/lib/jpeg/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Flib%2Fjpeg%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Flib%2Fjpeg%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Flib%2Fjpeg%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -62,7 +62,6 @@ cc_library(\n         \"//tensorflow/core/platform:jpeg_internal_hdrs\",\n         \"@local_tsl//tsl/platform:jpeg_internal_hdrs\",\n         \"@local_xla//xla/tsl/platform/default:integral_types.h\",\n-        \"@local_xla//xla/tsl/platform/default:logging.h\",\n     ],\n     copts = tf_copts(),\n     linkopts = if_android([\"-ldl\"]),"
        },
        {
            "sha": "21e07095b6ba80462dfb671cffd7119fe06814ac",
            "filename": "tensorflow/core/platform/build_config.bzl",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fplatform%2Fbuild_config.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fplatform%2Fbuild_config.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fplatform%2Fbuild_config.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -17,7 +17,6 @@ load(\n     _tf_google_mobile_srcs_only_runtime = \"tf_google_mobile_srcs_only_runtime\",\n     _tf_jspb_proto_library = \"tf_jspb_proto_library\",\n     _tf_lib_proto_parsing_deps = \"tf_lib_proto_parsing_deps\",\n-    _tf_logging_deps = \"tf_logging_deps\",\n     _tf_platform_alias = \"tf_platform_alias\",\n     _tf_platform_deps = \"tf_platform_deps\",\n     _tf_portable_deps_no_runtime = \"tf_portable_deps_no_runtime\",\n@@ -58,7 +57,6 @@ tf_google_mobile_srcs_no_runtime = _tf_google_mobile_srcs_no_runtime\n tf_google_mobile_srcs_only_runtime = _tf_google_mobile_srcs_only_runtime\n tf_jspb_proto_library = _tf_jspb_proto_library\n tf_lib_proto_parsing_deps = _tf_lib_proto_parsing_deps\n-tf_logging_deps = _tf_logging_deps\n tf_platform_alias = _tf_platform_alias\n tf_platform_deps = _tf_platform_deps\n tf_portable_proto_lib = _tf_portable_proto_lib"
        },
        {
            "sha": "a964dd3c13774baff4731bf7cbbbf19001b9c469",
            "filename": "tensorflow/core/public/version.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fpublic%2Fversion.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Fpublic%2Fversion.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fpublic%2Fversion.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -93,7 +93,7 @@ limitations under the License.\n \n #define TF_GRAPH_DEF_VERSION_MIN_PRODUCER 0\n #define TF_GRAPH_DEF_VERSION_MIN_CONSUMER 0\n-#define TF_GRAPH_DEF_VERSION 2327  // Updated: 2025/8/22\n+#define TF_GRAPH_DEF_VERSION 2333  // Updated: 2025/8/28\n \n // Checkpoint compatibility versions (the versions field in SavedSliceMeta).\n //"
        },
        {
            "sha": "35e1d22295f26193bde085e9133a439a822a7953",
            "filename": "tensorflow/core/tfrt/saved_model/saved_model.cc",
            "status": "modified",
            "additions": 59,
            "deletions": 36,
            "changes": 95,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Ftfrt%2Fsaved_model%2Fsaved_model.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fcore%2Ftfrt%2Fsaved_model%2Fsaved_model.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fsaved_model%2Fsaved_model.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -287,20 +287,24 @@ absl::Status RunBefInitializers(\n absl::Status IsInputSpecsCorrect(absl::string_view name,\n                                  const internal::Signature& signature,\n                                  absl::Span<const tensorflow::Tensor> inputs) {\n-  TF_RET_CHECK(signature.input_specs.size() == inputs.size())\n-      << \"signature \" << name\n-      << \" input size is wrong, expected: \" << signature.input_specs.size()\n-      << \", actual: \" << inputs.size();\n+  if (signature.input_specs.size() != inputs.size()) {\n+    return absl::InvalidArgumentError(absl::StrCat(\n+        \"signature \", name, \" input size is wrong, expected: \",\n+        signature.input_specs.size(), \", actual: \", inputs.size()));\n+  }\n   for (size_t i = 0; i < inputs.size(); ++i) {\n     const auto& expected_input_spec = signature.input_specs[i];\n-    TF_RET_CHECK(expected_input_spec.dtype == inputs[i].dtype())\n-        << \"signature \" << name\n-        << \" input dtype is wrong, expected: \" << expected_input_spec.dtype\n-        << \", actual: \" << inputs[i].dtype();\n-    TF_RET_CHECK(expected_input_spec.shape.IsCompatibleWith(inputs[i].shape()))\n-        << \"signature \" << name\n-        << \" input shape is wrong, expected : \" << expected_input_spec.shape\n-        << \", actual: \" << inputs[i].shape();\n+    if (expected_input_spec.dtype != inputs[i].dtype()) {\n+      return absl::InvalidArgumentError(absl::StrCat(\n+          \"signature \", name, \" input dtype is wrong, expected: \",\n+          expected_input_spec.dtype, \", actual: \", inputs[i].dtype()));\n+    }\n+    if (!expected_input_spec.shape.IsCompatibleWith(inputs[i].shape())) {\n+      return absl::InvalidArgumentError(\n+          absl::StrCat(\"signature \", name, \" input shape is wrong, expected : \",\n+                       expected_input_spec.shape.DebugString(),\n+                       \", actual: \", inputs[i].shape().DebugString()));\n+    }\n   }\n   return absl::OkStatus();\n }\n@@ -348,10 +352,11 @@ absl::Status PreprocessSignature(\n   TF_RETURN_IF_ERROR(CheckInputSpecs(model_metadata, run_options,\n                                      signature_name, signature, input_tensors));\n \n-  TF_RET_CHECK(input_tensors.size() == signature_def.inputs().size())\n-      << \"Incorrect input size for signature: \" << signature_name\n-      << \": expected \" << signature_def.inputs().size() << \", but got \"\n-      << input_tensors.size();\n+  if (input_tensors.size() != signature_def.inputs().size()) {\n+    return absl::InvalidArgumentError(absl::StrCat(\n+        \"Incorrect input size for signature: \", signature_name, \": expected \",\n+        signature_def.inputs().size(), \", but got \", input_tensors.size()));\n+  }\n   DCHECK_EQ(input_names.size(), signature_def.inputs().size());\n \n   // Then we find out the corresponding tensor names (ie.\n@@ -365,9 +370,11 @@ absl::Status PreprocessSignature(\n     // TODO(b/184675681): Support other encoding cases.\n     //\n     // TODO(b/184679394): Add unit test for this check.\n-    TF_RET_CHECK(tensor_info.encoding_case() == tensorflow::TensorInfo::kName)\n-        << \"Only dense tensor is supported, but got encoding case \"\n-        << tensor_info.encoding_case();\n+    if (tensor_info.encoding_case() != tensorflow::TensorInfo::kName) {\n+      return absl::UnimplementedError(\n+          absl::StrCat(\"Only dense tensor is supported, but got encoding case \",\n+                       tensor_info.encoding_case()));\n+    }\n \n     const auto& tensor_name = tensor_info.name();\n \n@@ -387,9 +394,11 @@ absl::Status PreprocessSignature(\n     VLOG(1) << \"Importing Signature Output: output_key = \" << output_key\n             << \", tensor_info = \" << tensor_info.DebugString();\n \n-    TF_RET_CHECK(tensor_info.encoding_case() == tensorflow::TensorInfo::kName)\n-        << \"Only dense tensor is supported, but got encoding case \"\n-        << tensor_info.encoding_case();\n+    if (tensor_info.encoding_case() != tensorflow::TensorInfo::kName) {\n+      return absl::UnimplementedError(\n+          absl::StrCat(\"Only dense tensor is supported, but got encoding case \",\n+                       tensor_info.encoding_case()));\n+    }\n \n     output_tensor_names.push_back(tensor_info.name());\n   }\n@@ -927,12 +936,16 @@ absl::Status SavedModelImpl::Run(const RunOptions& run_options,\n                                  absl::string_view name,\n                                  absl::Span<const tensorflow::Tensor> inputs,\n                                  std::vector<tensorflow::Tensor>* outputs) {\n-  TF_RET_CHECK(outputs) << \"outputs must be provided\";\n+  if (!outputs) {\n+    return absl::InvalidArgumentError(\"outputs must be provided\");\n+  }\n   outputs->clear();\n \n   auto sig_iter = signatures_.find(name);\n-  TF_RET_CHECK(sig_iter != signatures_.end())\n-      << \"failed to find signature \" << name << \" in the graph\";\n+  if (sig_iter == signatures_.end()) {\n+    return absl::NotFoundError(\n+        absl::StrCat(\"failed to find signature \", name, \" in the graph\"));\n+  }\n   const auto& signature = sig_iter->second;\n   const auto& signature_def = meta_graph_def_.signature_def().at(name);\n   const tensorflow::SessionMetadata& model_metadata =\n@@ -1035,9 +1048,13 @@ absl::Status SavedModelImpl::RunMultipleSignatures(\n     const RunOptions& run_options, absl::Span<const std::string> names,\n     absl::Span<const std::vector<tensorflow::Tensor>> multi_inputs,\n     std::vector<std::vector<tensorflow::Tensor>>* multi_outputs) {\n-  TF_RET_CHECK(names.size() == multi_inputs.size())\n-      << \"the sizes of names and inputs should be the same\";\n-  TF_RET_CHECK(multi_outputs) << \"outputs must be provided\";\n+  if (names.size() != multi_inputs.size()) {\n+    return absl::InvalidArgumentError(\n+        \"the sizes of names and inputs should be the same\");\n+  }\n+  if (!multi_outputs) {\n+    return absl::InvalidArgumentError(\"outputs must be provided\");\n+  }\n   multi_outputs->clear();\n \n   // Due to possible overlapping of feed nodes among user-specified inputs, We\n@@ -1059,8 +1076,10 @@ absl::Status SavedModelImpl::RunMultipleSignatures(\n     auto sig_iter = signature_defs.find(signature_name);\n \n     // Early out if any signature can't be found.\n-    TF_RET_CHECK(sig_iter != signature_defs.end())\n-        << \"failed to find signature in the graph\";\n+    if (sig_iter == signature_defs.end()) {\n+      return absl::NotFoundError(absl::StrCat(\"failed to find signature \",\n+                                              signature_name, \" in the graph\"));\n+    }\n     const auto& signature_def = sig_iter->second;\n \n     // `signatures_` keeps the user-specified input names that is in the same\n@@ -1173,9 +1192,11 @@ absl::StatusOr<JoinedSignature> JoinSignatures(\n       // TODO(b/184675681): Support other encoding cases.\n       //\n       // TODO(b/184679394): Add unit test for this check.\n-      TF_RET_CHECK(tensor_info.encoding_case() == tensorflow::TensorInfo::kName)\n-          << \"Only dense tensor is supported, but got encoding case \"\n-          << tensor_info.encoding_case();\n+      if (tensor_info.encoding_case() != tensorflow::TensorInfo::kName) {\n+        return absl::UnimplementedError(absl::StrCat(\n+            \"Only dense tensor is supported, but got encoding case \",\n+            tensor_info.encoding_case()));\n+      }\n \n       VLOG(1) << \"Importing Signature Input: input_key = \" << iter.first\n               << \", tensor_info = \" << tensor_info.DebugString();\n@@ -1205,9 +1226,11 @@ absl::StatusOr<JoinedSignature> JoinSignatures(\n       VLOG(1) << \"Importing Signature Output: output_key = \" << output_key\n               << \", tensor_info = \" << tensor_info.DebugString();\n \n-      TF_RET_CHECK(tensor_info.encoding_case() == tensorflow::TensorInfo::kName)\n-          << \"Only dense tensor is supported, but got encoding case \"\n-          << tensor_info.encoding_case();\n+      if (tensor_info.encoding_case() != tensorflow::TensorInfo::kName) {\n+        return absl::UnimplementedError(absl::StrCat(\n+            \"Only dense tensor is supported, but got encoding case \",\n+            tensor_info.encoding_case()));\n+      }\n \n       joined_signature.output_nodes.push_back(tensor_info.name());\n     }"
        },
        {
            "sha": "20c51c5f4d8da3bd969f86df4c91a8395a03ec91",
            "filename": "tensorflow/distribute/experimental/rpc/kernels/oss/grpc_credentials.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fdistribute%2Fexperimental%2Frpc%2Fkernels%2Foss%2Fgrpc_credentials.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fdistribute%2Fexperimental%2Frpc%2Fkernels%2Foss%2Fgrpc_credentials.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fdistribute%2Fexperimental%2Frpc%2Fkernels%2Foss%2Fgrpc_credentials.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -21,12 +21,12 @@ limitations under the License.\n namespace tensorflow {\n namespace rpc {\n \n-// Returns LOAS credentials for use when creating a gRPC server inside Google.\n+// Returns insecure credentials for use when creating a gRPC server.\n std::shared_ptr<::grpc::ServerCredentials> GetDefaultServerCredentials() {\n   return ::grpc::InsecureServerCredentials();\n }\n \n-// Returns LOAS credentials for use when creating a gRPC channel.\n+// Returns insecure credentials for use when creating a gRPC channel.\n std::shared_ptr<::grpc::ChannelCredentials> GetDefaultChannelCredentials() {\n   return ::grpc::InsecureChannelCredentials();\n }"
        },
        {
            "sha": "1249b5c01e321f718c814d6426389d2adb9d8a99",
            "filename": "tensorflow/lite/CMakeLists.txt",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2FCMakeLists.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2FCMakeLists.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2FCMakeLists.txt?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -841,6 +841,9 @@ set(TFLITE_GENERATED_HEADERS_DIR ${CMAKE_BINARY_DIR}/tensorflow/lite)\n # Add the profiling proto directory.\n add_subdirectory(${TFLITE_SOURCE_DIR}/profiling/proto)\n \n+# Add the benchmark result proto directory.\n+add_subdirectory(${TFLITE_SOURCE_DIR}/tools/benchmark/proto)\n+\n # Add the tf example directory.\n add_subdirectory(${TF_SOURCE_DIR}/core/example ${CMAKE_BINARY_DIR}/example_proto_generated)\n "
        },
        {
            "sha": "1f607290338ae3776fde616629c683468938ded5",
            "filename": "tensorflow/lite/acceleration/configuration/configuration_generated.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Facceleration%2Fconfiguration%2Fconfiguration_generated.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Facceleration%2Fconfiguration%2Fconfiguration_generated.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Facceleration%2Fconfiguration%2Fconfiguration_generated.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -22,9 +22,9 @@ limitations under the License.\n \n // Ensure the included flatbuffers.h is the same version as when this file was\n // generated, otherwise it may not be compatible.\n-static_assert(FLATBUFFERS_VERSION_MAJOR == 24 &&\n-              FLATBUFFERS_VERSION_MINOR == 3 &&\n-              FLATBUFFERS_VERSION_REVISION == 25,\n+static_assert(FLATBUFFERS_VERSION_MAJOR == 25 &&\n+              FLATBUFFERS_VERSION_MINOR == 2 &&\n+              FLATBUFFERS_VERSION_REVISION == 10,\n              \"Non-compatible flatbuffers version included\");\n \n namespace tflite {"
        },
        {
            "sha": "676670f1e8bd034c56ba4988ea52d77ffe2aab46",
            "filename": "tensorflow/lite/delegates/gpu/cl/compiled_program_cache_generated.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcl%2Fcompiled_program_cache_generated.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcl%2Fcompiled_program_cache_generated.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcl%2Fcompiled_program_cache_generated.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -22,9 +22,9 @@ limitations under the License.\n \n // Ensure the included flatbuffers.h is the same version as when this file was\n // generated, otherwise it may not be compatible.\n-static_assert(FLATBUFFERS_VERSION_MAJOR == 24 &&\n-              FLATBUFFERS_VERSION_MINOR == 3 &&\n-              FLATBUFFERS_VERSION_REVISION == 25,\n+static_assert(FLATBUFFERS_VERSION_MAJOR == 25 &&\n+              FLATBUFFERS_VERSION_MINOR == 2 &&\n+              FLATBUFFERS_VERSION_REVISION == 10,\n              \"Non-compatible flatbuffers version included\");\n \n namespace tflite {"
        },
        {
            "sha": "fa9356613dfe395e789efb80085086e41ce85234",
            "filename": "tensorflow/lite/delegates/gpu/cl/serialization_generated.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcl%2Fserialization_generated.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcl%2Fserialization_generated.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcl%2Fserialization_generated.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -22,9 +22,9 @@ limitations under the License.\n \n // Ensure the included flatbuffers.h is the same version as when this file was\n // generated, otherwise it may not be compatible.\n-static_assert(FLATBUFFERS_VERSION_MAJOR == 24 &&\n-              FLATBUFFERS_VERSION_MINOR == 3 &&\n-              FLATBUFFERS_VERSION_REVISION == 25,\n+static_assert(FLATBUFFERS_VERSION_MAJOR == 25 &&\n+              FLATBUFFERS_VERSION_MINOR == 2 &&\n+              FLATBUFFERS_VERSION_REVISION == 10,\n              \"Non-compatible flatbuffers version included\");\n \n #include \"gpu_model_generated.h\""
        },
        {
            "sha": "4ad3e77129873373b1959e8114ce04e0959d973f",
            "filename": "tensorflow/lite/delegates/gpu/common/gpu_model_generated.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcommon%2Fgpu_model_generated.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcommon%2Fgpu_model_generated.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcommon%2Fgpu_model_generated.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -21,9 +21,9 @@ limitations under the License.\n \n // Ensure the included flatbuffers.h is the same version as when this file was\n // generated, otherwise it may not be compatible.\n-static_assert(FLATBUFFERS_VERSION_MAJOR == 24 &&\n-              FLATBUFFERS_VERSION_MINOR == 3 &&\n-              FLATBUFFERS_VERSION_REVISION == 25,\n+static_assert(FLATBUFFERS_VERSION_MAJOR == 25 &&\n+              FLATBUFFERS_VERSION_MINOR == 2 &&\n+              FLATBUFFERS_VERSION_REVISION == 10,\n              \"Non-compatible flatbuffers version included\");\n \n #include \"tflite_serialization_base_generated.h\""
        },
        {
            "sha": "3e50db9e38f6d08f61a8413b1749e55886214ca5",
            "filename": "tensorflow/lite/delegates/gpu/common/task/tflite_serialization_base_generated.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcommon%2Ftask%2Ftflite_serialization_base_generated.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcommon%2Ftask%2Ftflite_serialization_base_generated.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcommon%2Ftask%2Ftflite_serialization_base_generated.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -22,9 +22,9 @@ limitations under the License.\n \n // Ensure the included flatbuffers.h is the same version as when this file was\n // generated, otherwise it may not be compatible.\n-static_assert(FLATBUFFERS_VERSION_MAJOR == 24 &&\n-              FLATBUFFERS_VERSION_MINOR == 3 &&\n-              FLATBUFFERS_VERSION_REVISION == 25,\n+static_assert(FLATBUFFERS_VERSION_MAJOR == 25 &&\n+              FLATBUFFERS_VERSION_MINOR == 2 &&\n+              FLATBUFFERS_VERSION_REVISION == 10,\n              \"Non-compatible flatbuffers version included\");\n \n namespace tflite {"
        },
        {
            "sha": "faa27bf331fda090746885cece641875a7f78eb2",
            "filename": "tensorflow/lite/delegates/xnnpack/weight_cache.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -420,7 +420,7 @@ bool MMapWeightCacheProvider::Load() {\n       header.buffer_list_size == mmap_handle.size() - header.buffer_list_offset,\n       \"invalid size for buffer list descriptor.\");\n \n-  // Verifiy the flabuffer part of the file.\n+  // Verify the flatbuffer part of the file.\n   flatbuffers::Verifier verifier(mmap_handle.data() + header.buffer_list_offset,\n                                  header.buffer_list_size);\n   XNNPACK_RETURN_CHECK(cache::schema::VerifyBufferListBuffer(verifier),"
        },
        {
            "sha": "ab2f789d4094592a21b9105a1576fc206bbebed8",
            "filename": "tensorflow/lite/experimental/acceleration/configuration/configuration_generated.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fexperimental%2Facceleration%2Fconfiguration%2Fconfiguration_generated.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Fexperimental%2Facceleration%2Fconfiguration%2Fconfiguration_generated.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fexperimental%2Facceleration%2Fconfiguration%2Fconfiguration_generated.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -22,9 +22,9 @@ limitations under the License.\n \n // Ensure the included flatbuffers.h is the same version as when this file was\n // generated, otherwise it may not be compatible.\n-static_assert(FLATBUFFERS_VERSION_MAJOR == 24 &&\n-              FLATBUFFERS_VERSION_MINOR == 3 &&\n-              FLATBUFFERS_VERSION_REVISION == 25,\n+static_assert(FLATBUFFERS_VERSION_MAJOR == 25 &&\n+              FLATBUFFERS_VERSION_MINOR == 2 &&\n+              FLATBUFFERS_VERSION_REVISION == 10,\n              \"Non-compatible flatbuffers version included\");\n \n namespace tflite {"
        },
        {
            "sha": "aee420c6a52b9f678eaef9cab87cab5f7198e09e",
            "filename": "tensorflow/lite/tools/benchmark/CMakeLists.txt",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Ftools%2Fbenchmark%2FCMakeLists.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Ftools%2Fbenchmark%2FCMakeLists.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Ftools%2Fbenchmark%2FCMakeLists.txt?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -51,6 +51,7 @@ list(APPEND TFLITE_BENCHMARK_LIBS\n   feature_proto\n   example_proto\n   model_runtime_info_proto\n+  benchmark_result_proto\n   protobuf::libprotobuf\n   absl::log\n )"
        },
        {
            "sha": "9eff6982b4d1ad4ff7405edc891e7c701e1d6179",
            "filename": "tensorflow/lite/tools/benchmark/proto/BUILD",
            "status": "added",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fproto%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fproto%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fproto%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,34 @@\n+# Placeholder: load py_proto_library\n+# Placeholder: load proto_library\n+load(\"//tensorflow:tensorflow.default.bzl\", \"get_compatible_with_portable\")\n+load(\n+    \"//tensorflow/core/platform:build_config.bzl\",\n+    \"tf_proto_library\",\n+)\n+\n+package(\n+    # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n+    default_visibility = [\"//visibility:public\"],\n+    licenses = [\"notice\"],\n+)\n+\n+proto_library(\n+    name = \"benchmark_result_proto\",\n+    srcs = [\"benchmark_result.proto\"],\n+    compatible_with = get_compatible_with_portable(),\n+    visibility = [\"//visibility:public\"],\n+)\n+\n+tf_proto_library(\n+    name = \"benchmark_result\",  # bzl adds _py for python proto library\n+    srcs = [\"benchmark_result.proto\"],\n+    visibility = [\"//visibility:public\"],\n+)\n+\n+# copybara:uncomment_begin(google-only)\n+# py_proto_library(\n+#     name = \"benchmark_result_py_pb2\",\n+#     compatible_with = get_compatible_with_portable(),\n+#     deps = [\":benchmark_result_proto\"],\n+# )\n+# copybara:uncomment_end"
        },
        {
            "sha": "12a7e577bd3277c4308e438e98173ddeea90b3e9",
            "filename": "tensorflow/lite/tools/benchmark/proto/CMakeLists.txt",
            "status": "added",
            "additions": 36,
            "deletions": 0,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fproto%2FCMakeLists.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fproto%2FCMakeLists.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fproto%2FCMakeLists.txt?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,36 @@\n+#\n+# Copyright 2025 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      https://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+find_package(Protobuf REQUIRED)\n+\n+add_library(benchmark_result_proto benchmark_result.proto)\n+\n+list(APPEND benchmark_result_generated_files\n+    ${CMAKE_BINARY_DIR}/tflite/tools/benchmark/proto/benchmark_result.pb.cc\n+    ${CMAKE_BINARY_DIR}/tflite/tools/benchmark/proto/benchmark_result.pb.h)\n+\n+# Generate benchmark_result.pb.cc and benchmark_result.pb.h from\n+# benchmark_result.proto using protoc. Once the protobuf package version is\n+# upgraded, we can use protobuf_generate_cpp/protobuf_generate here directly.\n+add_custom_command(\n+    OUTPUT ${benchmark_result_generated_files}\n+    COMMAND ${Protobuf_PROTOC_EXECUTABLE}\n+    ARGS --cpp_out=${CMAKE_BINARY_DIR} --proto_path=${CMAKE_CURRENT_SOURCE_DIR}/../../../.. tflite/tools/benchmark/proto/benchmark_result.proto\n+    DEPENDS ${Protobuf_PROTOC_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/benchmark_result.proto\n+)\n+\n+set_source_files_properties(${benchmark_result_generated_files} PROPERTIES GENERATED TRUE)\n+target_sources(benchmark_result_proto PRIVATE ${benchmark_result_generated_files})\n+target_link_libraries(benchmark_result_proto protobuf::libprotobuf)\n+target_include_directories(benchmark_result_proto PUBLIC ${CMAKE_BINARY_DIR})"
        },
        {
            "sha": "ab0c5d2588eb8ce82918350aa3c8f3201b51500f",
            "filename": "tensorflow/lite/tools/benchmark/proto/benchmark_result.proto",
            "status": "added",
            "additions": 58,
            "deletions": 0,
            "changes": 58,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fproto%2Fbenchmark_result.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fproto%2Fbenchmark_result.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Ftools%2Fbenchmark%2Fproto%2Fbenchmark_result.proto?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,58 @@\n+syntax = \"proto2\";\n+\n+package tflite.tools.benchmark;\n+\n+option java_multiple_files = true;\n+option java_package = \"tflite.tools.benchmark\";\n+\n+// Next ID: 11\n+message LatencyMetrics {\n+  // Note all fields defined here refers to wall time by default.\n+  optional float avg_ms = 1;\n+  optional float min_ms = 2;\n+  optional float max_ms = 3;\n+  optional float stddev_ms = 4;\n+  optional float median_ms = 5;\n+  optional float p5_ms = 6;\n+  optional float p95_ms = 7;\n+  optional float init_ms = 8;\n+  optional float first_inference_ms = 9;\n+  optional float average_warm_up_ms = 10;\n+}\n+\n+// Next ID: 4\n+message MemoryMetrics {\n+  // The amount of memory allocated during model initialization. This is the\n+  // delta of memory footprint after the model has been loaded and interpreter\n+  // has been created, compared to the memory footprint at the beginning of the\n+  // benchmark tool.\n+  optional int64 init_footprint_kb = 1;\n+\n+  // The memory allocated during the model initialization and execution.\n+  // This is the delta of memory footprint after the model has been intialized\n+  // and executed, compared to the memory footprint at the beginning of the\n+  // benchmark tool.\n+  optional int64 overall_footprint_kb = 2;\n+\n+  // Peak memory usage (in megabytes).\n+  optional float peak_mem_mb = 3;\n+}\n+\n+// Next ID: 5\n+message MiscMetrics {\n+  optional float model_size_mb = 1;\n+  optional int32 num_runs = 2;\n+  optional int32 num_warmup_runs = 3;\n+  // Model throughput in megabytes per second. This is the average throughput\n+  // of the model over all the inferences.\n+  optional float model_throughput_in_mb_per_sec = 4;\n+}\n+\n+// Next ID: 5\n+message BenchmarkResult {\n+  // The name representing the configuration of the benchmark run.\n+  optional string name = 1;\n+  optional LatencyMetrics latency_metrics = 2;\n+  optional MemoryMetrics memory_metrics = 3;\n+  optional MiscMetrics misc_metrics = 4;\n+}"
        },
        {
            "sha": "94bfea8541c2672def291ecbba9f553ece8a3b87",
            "filename": "tensorflow/lite/tools/cmake/modules/xnnpack.cmake",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Ftools%2Fcmake%2Fmodules%2Fxnnpack.cmake",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Flite%2Ftools%2Fcmake%2Fmodules%2Fxnnpack.cmake",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Ftools%2Fcmake%2Fmodules%2Fxnnpack.cmake?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -23,7 +23,7 @@ OverridableFetchContent_Declare(\n   xnnpack\n   GIT_REPOSITORY https://github.com/google/XNNPACK\n   # Sync with tensorflow/workspace2.bzl\n-  GIT_TAG 45bf06030727ce049793ce6749e943cc2ea896fe\n+  GIT_TAG e757940dbdcf465fd9eb7901ce73f4ff21387663\n   GIT_PROGRESS TRUE\n   PREFIX \"${CMAKE_BINARY_DIR}\"\n   SOURCE_DIR \"${CMAKE_BINARY_DIR}/xnnpack\""
        },
        {
            "sha": "f180d5bda473f7f5ee3c93c3c3a123d482133f53",
            "filename": "tensorflow/python/_pywrap_tensorflow.def",
            "status": "modified",
            "additions": 3,
            "deletions": 10,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fpython%2F_pywrap_tensorflow.def",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fpython%2F_pywrap_tensorflow.def",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2F_pywrap_tensorflow.def?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -44,7 +44,6 @@ EXPORTS\n   ??0CalibrationOptions@quantization@stablehlo@@IEAA@PEAVArena@protobuf@google@@@Z\n   ??0CalibrationStatistics@calibrator@tensorflow@@IEAA@PEAVArena@protobuf@google@@@Z\n   ??0CancellationManager@tsl@@QEAA@XZ\n-  ??0CheckOpMessageBuilder@internal@tsl@@QEAA@PEBD@Z\n   ??0CheckpointReader@checkpoint@tensorflow@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAUTSL_Status@@@Z\n   ??0ConfigProto@tensorflow@@IEAA@PEAVArena@protobuf@google@@@Z\n   ??0ConfigProto@tensorflow@@IEAA@PEAVArena@protobuf@google@@AEBV01@@Z\n@@ -73,9 +72,7 @@ EXPORTS\n   ??0Impl@MakeErrorStream@status_macros@xla@@QEAA@PEBDHW4Code@error@tensorflow@@PEAV123@_N@Z\n   ??0LayoutProto@dtensor@tensorflow@@IEAA@PEAVArena@protobuf@google@@@Z\n   ??0LayoutProto@dtensor@tensorflow@@IEAA@PEAVArena@protobuf@google@@AEBV012@@Z\n-  ??0LogMessage@internal@tsl@@QEAA@PEBDHW4LogSeverity@lts_20250512@absl@@@Z\n   ??0LogMessage@log_internal@lts_20250512@absl@@QEAA@PEBDHUInfoTag@0123@@Z\n-  ??0LogMessageFatal@internal@tsl@@QEAA@PEBDH@Z\n   ??0LogMessageFatal@log_internal@lts_20250512@absl@@QEAA@PEBDH0@Z\n   ??0LogMessageFatal@log_internal@lts_20250512@absl@@QEAA@PEBDH@Z\n   ??0MLIRContext@mlir@@QEAA@AEBVDialectRegistry@1@W4Threading@01@@Z\n@@ -95,6 +92,7 @@ EXPORTS\n   ??0OpKernel@tensorflow@@QEAA@PEAVOpKernelConstruction@1@@Z\n   ??0OpLevelCostEstimator@grappler@tensorflow@@QEAA@XZ\n   ??0OpPerformanceList@tensorflow@@IEAA@PEAVArena@protobuf@google@@@Z\n+  ??0OstreamView@LogMessage@log_internal@lts_20250512@absl@@QEAA@AEAULogMessageData@1234@@Z\n   ??0PyInstanceChecker@py_dispatch@tensorflow@@QEAA@AEBV?$vector@PEAU_object@@V?$allocator@PEAU_object@@@std@@@std@@@Z\n   ??0PySignatureChecker@py_dispatch@tensorflow@@QEAA@V?$vector@U?$pair@HV?$shared_ptr@VPyTypeChecker@py_dispatch@tensorflow@@@std@@@std@@V?$allocator@U?$pair@HV?$shared_ptr@VPyTypeChecker@py_dispatch@tensorflow@@@std@@@std@@@2@@std@@@Z\n   ??0PythonAPIDispatcher@py_dispatch@tensorflow@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$Span@PEBD@lts_20250512@absl@@V?$Span@PEAU_object@@@67@@Z\n@@ -133,7 +131,6 @@ EXPORTS\n   ??1CalibrationOptions@quantization@stablehlo@@UEAA@XZ\n   ??1CalibrationStatistics@calibrator@tensorflow@@UEAA@XZ\n   ??1CancellationManager@tsl@@QEAA@XZ\n-  ??1CheckOpMessageBuilder@internal@tsl@@QEAA@XZ\n   ??1ConfigProto@tensorflow@@UEAA@XZ\n   ??1CoordinatedTask@tensorflow@@UEAA@XZ\n   ??1DataServiceMetadata@data@tensorflow@@UEAA@XZ\n@@ -151,9 +148,7 @@ EXPORTS\n   ??1Impl@MakeErrorStream@status_macros@xla@@QEAA@XZ\n   ??1KernelDefBuilder@tensorflow@@QEAA@XZ\n   ??1LayoutProto@dtensor@tensorflow@@UEAA@XZ\n-  ??1LogMessage@internal@tsl@@UEAA@XZ\n   ??1LogMessage@log_internal@lts_20250512@absl@@QEAA@XZ\n-  ??1LogMessageFatal@internal@tsl@@UEAA@XZ\n   ??1LogMessageFatal@log_internal@lts_20250512@absl@@QEAA@XZ\n   ??1MLIRContext@mlir@@QEAA@XZ\n   ??1MeshProto@dtensor@tensorflow@@UEAA@XZ\n@@ -165,6 +160,7 @@ EXPORTS\n   ??1OpInfo_TensorProperties@tensorflow@@UEAA@XZ\n   ??1OpKernel@tensorflow@@UEAA@XZ\n   ??1OpPerformanceList@tensorflow@@UEAA@XZ\n+  ??1OstreamView@LogMessage@log_internal@lts_20250512@absl@@UEAA@XZ\n   ??1ProfilerServer@profiler@tsl@@QEAA@XZ\n   ??1ProfilerSession@tsl@@QEAA@XZ\n   ??1PyContextManager@tensorflow@@QEAA@XZ\n@@ -270,7 +266,6 @@ EXPORTS\n   ?CreateMesh@Mesh@dtensor@tensorflow@@SA?AV123@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@5@AEBV?$vector@_JV?$allocator@_J@std@@@5@2121_N@Z\n   ?CreateRecordReaderOptions@RecordReaderOptions@io@tsl@@SA?AU123@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z\n   ?CreateRecordWriterOptions@RecordWriterOptions@io@tsl@@SA?AU123@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z\n-  ?CreateTypeInfoAndReturnTypeIdImpl@AsyncValue@tsl@@CAGAEBUTypeInfo@12@@Z\n   ?CtxFailure@OpKernelConstruction@tensorflow@@QEAAXPEBDHAEBVStatus@lts_20250512@absl@@@Z\n   ?CtxFailure@OpKernelContext@tensorflow@@QEAAXPEBDHAEBVStatus@lts_20250512@absl@@@Z\n   ?CtxFailureWithWarning@OpKernelConstruction@tensorflow@@QEAAXPEBDHAEBVStatus@lts_20250512@absl@@@Z\n@@ -352,7 +347,6 @@ EXPORTS\n   ?FlushExecutionFiles@DebugEventsWriter@tfdbg@tensorflow@@QEAA?AVStatus@lts_20250512@absl@@XZ\n   ?FlushNonExecutionFiles@DebugEventsWriter@tfdbg@tensorflow@@QEAA?AVStatus@lts_20250512@absl@@XZ\n   ?ForEachPayload@StatusRep@status_internal@lts_20250512@absl@@QEBAXV?$FunctionRef@$$A6AXV?$basic_string_view@DU?$char_traits@D@std@@@std@@AEBVCord@lts_20250512@absl@@@Z@34@@Z\n-  ?ForVar2@CheckOpMessageBuilder@internal@tsl@@QEAAPEAV?$basic_ostream@DU?$char_traits@D@std@@@std@@XZ\n   ?FormatConvertImpl@str_format_internal@lts_20250512@absl@@YA?AU?$ArgConvertResult@$0IAAAE@@123@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@VFormatConversionSpecImpl@123@PEAVFormatSinkImpl@123@@Z\n   ?FormatPack@str_format_internal@lts_20250512@absl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@VUntypedFormatSpecImpl@123@V?$Span@$$CBVFormatArgImpl@str_format_internal@lts_20250512@absl@@@23@@Z\n   ?FromProto@Layout@dtensor@tensorflow@@SA?AV?$StatusOr@VLayout@dtensor@tensorflow@@@lts_20250512@absl@@AEBVLayoutProto@23@@Z\n@@ -535,7 +529,6 @@ EXPORTS\n   ?NewDispatchServer@data@tensorflow@@YA?AVStatus@lts_20250512@absl@@AEBVDispatcherConfig@experimental@12@AEAV?$unique_ptr@VDispatchGrpcDataServer@data@tensorflow@@U?$default_delete@VDispatchGrpcDataServer@data@tensorflow@@@std@@@std@@@Z\n   ?NewProfiler@tfprof@tensorflow@@YA_NPEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@0@Z\n   ?NewRandomAccessFile@Env@tsl@@QEAA?AVStatus@lts_20250512@absl@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAV?$unique_ptr@VRandomAccessFile@tsl@@U?$default_delete@VRandomAccessFile@tsl@@@std@@@7@@Z\n-  ?NewString@CheckOpMessageBuilder@internal@tsl@@QEAAPEAV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@XZ\n   ?NewWorkerServer@data@tensorflow@@YA?AVStatus@lts_20250512@absl@@AEBVWorkerConfig@experimental@12@AEAV?$unique_ptr@VWorkerGrpcDataServer@data@tensorflow@@U?$default_delete@VWorkerGrpcDataServer@data@tensorflow@@@std@@@std@@@Z\n   ?NewWritableFile@Env@tsl@@QEAA?AVStatus@lts_20250512@absl@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAV?$unique_ptr@VWritableFile@tsl@@U?$default_delete@VWritableFile@tsl@@@std@@@7@@Z\n   ?NotFoundError@lts_20250512@absl@@YA?AVStatus@12@V?$basic_string_view@DU?$char_traits@D@std@@@std@@@Z\n@@ -776,7 +769,6 @@ EXPORTS\n   ?UpdateEdge@tensorflow@@YAXPEAUTF_Graph@@UTF_Output@@UTF_Input@@PEAUTSL_Status@@@Z\n   ?ValidateType@ResourceHandle@tensorflow@@QEBA?AVStatus@lts_20250512@absl@@AEBVTypeIndex@2@@Z\n   ?Vector@InferenceContext@shape_inference@tensorflow@@QEAA?AVShapeHandle@23@UDimensionOrConstant@23@@Z\n-  ?VmoduleActivated@LogMessage@internal@tsl@@SA_NPEBDH@Z\n   ?WaitCommon@CondVar@lts_20250512@absl@@AEAA_NPEAVMutex@23@VKernelTimeout@synchronization_internal@23@@Z\n   ?Watch@Tape@gradients@tensorflow@@QEAAXPEBVAbstractTensorHandle@3@@Z\n   ?WithRank@InferenceContext@shape_inference@tensorflow@@QEAA?AVStatus@lts_20250512@absl@@VShapeHandle@23@_JPEAV723@@Z\n@@ -846,6 +838,7 @@ EXPORTS\n   ?set_requested_device@Node@tensorflow@@QEAAXAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z\n   ?set_tf2_execution@tensorflow@@YAX_N@Z\n   ?sharding_spec_strs@Layout@dtensor@tensorflow@@QEBA?AV?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@std@@XZ\n+  ?stream@OstreamView@LogMessage@log_internal@lts_20250512@absl@@QEAAAEAV?$basic_ostream@DU?$char_traits@D@std@@@std@@XZ\n   ?tensor_data@Tensor@tensorflow@@QEBA?AV?$basic_string_view@DU?$char_traits@D@std@@@std@@XZ\n   ?tensor_float_32_execution_enabled@tsl@@YA_NXZ\n   ?tf2_execution_enabled@tensorflow@@YA_NXZ"
        },
        {
            "sha": "fe8a901a9a24687c435f29494aa5227ebe3dfce3",
            "filename": "tensorflow/python/compat/compat.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fpython%2Fcompat%2Fcompat.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fpython%2Fcompat%2Fcompat.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fcompat%2Fcompat.py?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -29,7 +29,7 @@\n # This value changes every day with an automatic CL. It can be modified in code\n # via `forward_compatibility_horizon()` or with the environment variable\n # TF_FORWARD_COMPATIBILITY_DELTA_DAYS, which is added to the compatibility date.\n-_FORWARD_COMPATIBILITY_HORIZON = datetime.date(2025, 8, 22)\n+_FORWARD_COMPATIBILITY_HORIZON = datetime.date(2025, 8, 28)\n _FORWARD_COMPATIBILITY_DELTA_DAYS_VAR_NAME = \"TF_FORWARD_COMPATIBILITY_DELTA_DAYS\"\n _FORWARD_COMPATIBILITY_DATE_NUMBER = None\n "
        },
        {
            "sha": "2018c782c74d27a952460b51b9f2cbc8bff8cc83",
            "filename": "tensorflow/python/eager/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fpython%2Feager%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fpython%2Feager%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Feager%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1003,7 +1003,10 @@ tf_py_strict_test(\n py_strict_library(\n     name = \"wrap_function\",\n     srcs = [\"wrap_function.py\"],\n-    visibility = [\"//tensorflow:internal\"],\n+    visibility = [\n+        \"//tensorflow:internal\",\n+        \"//third_party/py/orbax/export:__subpackages__\",\n+    ],\n     deps = [\n         \":context\",\n         \":function\","
        },
        {
            "sha": "1a7b0e6a55d236c0469d935b575d7bf175ca7ae5",
            "filename": "tensorflow/python/tpu/tpu_embedding_v3_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fpython%2Ftpu%2Ftpu_embedding_v3_utils.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fpython%2Ftpu%2Ftpu_embedding_v3_utils.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Ftpu%2Ftpu_embedding_v3_utils.py?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -58,8 +58,8 @@ def unshuffle_from_sc_to_cpu(\n   # checkpoints value to meet this requirement.\n   if t.shape[0] % num_sparse_cores != 0:\n     raise ValueError(\n-        \"The dim of table ({}) should be multiple of number of sparse cores\"\n-        \" ({})\".format(t.shape[1], num_sparse_cores)\n+        \"The first dim of the table ({}) should be multiple of number of sparse\"\n+        \" cores ({})\".format(t.shape[0], num_sparse_cores)\n     )\n   # get shards in the input t\n   shards_t = array_ops.reshape("
        },
        {
            "sha": "87019a4cbabc0677ad401b74c45dd9661012b726",
            "filename": "tensorflow/tensorflow.bzl",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Ftensorflow.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Ftensorflow.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftensorflow.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -21,7 +21,6 @@ load(\n     \"if_mkl\",\n     \"if_mkl_ml\",\n     \"if_mkldnn_aarch64_acl\",\n-    \"if_mkldnn_aarch64_acl_openmp\",\n     \"if_mkldnn_openmp\",\n     \"onednn_v3_define\",\n )\n@@ -467,7 +466,6 @@ def tf_copts(\n         if_mkldnn_openmp([\"-DENABLE_ONEDNN_OPENMP\"]) +\n         onednn_v3_define() +\n         if_mkldnn_aarch64_acl([\"-DDNNL_AARCH64_USE_ACL=1\"]) +\n-        if_mkldnn_aarch64_acl_openmp([\"-DENABLE_ONEDNN_OPENMP\"]) +\n         if_zendnn([\"-DAMD_ZENDNN\"]) +\n         if_enable_acl([\"-DXLA_CPU_USE_ACL=1\", \"-fexceptions\"]) +\n         if_llvm_aarch32_available([\"-DTF_LLVM_AARCH32_AVAILABLE=1\"]) +"
        },
        {
            "sha": "9e31bd33ac42ce58edcba3d53ba93954fe9cca32",
            "filename": "tensorflow/tools/ci_build/release/requirements_common.txt",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Ftools%2Fci_build%2Frelease%2Frequirements_common.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Ftools%2Fci_build%2Frelease%2Frequirements_common.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftools%2Fci_build%2Frelease%2Frequirements_common.txt?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -3,7 +3,7 @@\n # This will change in the future.\n absl-py ~= 1.0.0\n astunparse ~= 1.6.3\n-flatbuffers ~= 24.3.25\n+flatbuffers ~= 25.2.10\n google_pasta ~= 0.2\n h5py ~= 3.10.0  # Earliest version for Python 3.12\n ml_dtypes ~= 0.5.1"
        },
        {
            "sha": "457cb5a1463f59a7f9986e8ad2e975555f3f828f",
            "filename": "tensorflow/tools/pip_package/setup.py.tpl",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Ftools%2Fpip_package%2Fsetup.py.tpl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Ftools%2Fpip_package%2Fsetup.py.tpl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftools%2Fpip_package%2Fsetup.py.tpl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -81,7 +81,7 @@ def standard_or_nightly(standard, nightly):\n REQUIRED_PACKAGES = [\n     'absl-py >= 1.0.0',\n     'astunparse >= 1.6.0',\n-    'flatbuffers >= 24.3.25',\n+    'flatbuffers >= 25.2.10',\n     'gast >=0.2.1,!=0.5.0,!=0.5.1,!=0.5.2',\n     'google_pasta >= 0.1.1',\n     'libclang >= 13.0.0',"
        },
        {
            "sha": "deb23bf29bb2fbe24527d7c99d4a9eaeeec6e369",
            "filename": "tensorflow/tools/tf_sig_build_dockerfiles/devel.requirements.txt",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Ftools%2Ftf_sig_build_dockerfiles%2Fdevel.requirements.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Ftools%2Ftf_sig_build_dockerfiles%2Fdevel.requirements.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftools%2Ftf_sig_build_dockerfiles%2Fdevel.requirements.txt?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -6,7 +6,7 @@\n # This will change in the future.\n absl-py ~= 1.0.0\n astunparse ~= 1.6.3\n-flatbuffers ~= 24.3.25\n+flatbuffers ~= 25.2.10\n google_pasta ~= 0.2\n h5py ~= 3.11.0 # Earliest version for NumPy 2.0\n ml_dtypes ~= 0.5.1 # Earliest version with mxfloat types"
        },
        {
            "sha": "c30ce9be39e9009f19e4a328b76fb192dc80e723",
            "filename": "tensorflow/workspace2.bzl",
            "status": "modified",
            "additions": 11,
            "deletions": 18,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fworkspace2.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/tensorflow%2Fworkspace2.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fworkspace2.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -238,33 +238,26 @@ def _tf_repositories():\n         name = \"mkl_dnn_acl_compatible\",\n         build_file = \"@local_xla//third_party/mkl_dnn:mkldnn_acl.BUILD\",\n         patch_file = [\n-            \"@local_xla//third_party/mkl_dnn:onednn_acl_threadcap.patch\",\n-            \"@local_xla//third_party/mkl_dnn:onednn_acl_reorder.patch\",\n-            \"@local_xla//third_party/mkl_dnn:onednn_acl_thread_local_scheduler.patch\",\n-            \"@local_xla//third_party/mkl_dnn:onednn_acl_fp32_bf16_reorder.patch\",\n-            \"@local_xla//third_party/mkl_dnn:onednn_acl_bf16_capability_detection_for_ubuntu20.04.patch\",\n-            \"@local_xla//third_party/mkl_dnn:onednn_acl_indirect_conv.patch\",\n-            \"@local_xla//third_party/mkl_dnn:onednn_acl_allow_blocked_weight_format_for_matmul_primitive.patch\",\n-            \"@local_xla//third_party/mkl_dnn:onednn_acl_fix_segfault_during_postop_execute.patch\",\n-            \"@local_xla//third_party/mkl_dnn:onednn_acl_add_bf16_platform_support_check.patch\",\n-            \"@local_xla//third_party/mkl_dnn:onednn_acl_add_sbgemm_matmul_primitive_definition.patch\",\n+            \"@local_xla//third_party/mkl_dnn:onednn_acl_lock_fixed_format_matmul.patch\",\n+            \"@local_xla//third_party/mkl_dnn:onednn_acl_threadpool_default_max.patch\",\n         ],\n-        sha256 = \"2f76b407ef8893cca71340f88cd800019a1f14f8ac1bbdbb89a84be1370b52e3\",\n-        strip_prefix = \"oneDNN-3.2.1\",\n-        urls = tf_mirror_urls(\"https://github.com/oneapi-src/oneDNN/archive/refs/tags/v3.2.1.tar.gz\"),\n+        sha256 = \"5792cbc07764c6e25c459ff68efb5cfcd7f4a0ba66dca6a4a2c681cd7a644596\",\n+        strip_prefix = \"oneDNN-3.7\",\n+        urls = tf_mirror_urls(\"https://github.com/oneapi-src/oneDNN/archive/refs/tags/v3.7.zip\"),\n     )\n \n     tf_http_archive(\n         name = \"compute_library\",\n         patch_file = [\n+            \"@local_xla//third_party/compute_library:acl_gemm_scheduling_heuristic.patch\",\n+            \"@local_xla//third_party/compute_library:acl_stateless_gemm_workspace.patch\",\n             \"@local_xla//third_party/compute_library:compute_library.patch\",\n-            \"@local_xla//third_party/compute_library:acl_thread_local_scheduler.patch\",\n             \"@local_xla//third_party/compute_library:exclude_omp_scheduler.patch\",\n             \"@local_xla//third_party/compute_library:include_string.patch\",\n         ],\n-        sha256 = \"c4ca329a78da380163b2d86e91ba728349b6f0ee97d66e260a694ef37f0b0d93\",\n-        strip_prefix = \"ComputeLibrary-23.05.1\",\n-        urls = tf_mirror_urls(\"https://github.com/ARM-software/ComputeLibrary/archive/v23.05.1.tar.gz\"),\n+        sha256 = \"8273f68cd0bb17e9231a11a6618d245eb6d623884ae681c00e7a4eabca2dad42\",\n+        strip_prefix = \"ComputeLibrary-24.12\",\n+        urls = tf_mirror_urls(\"https://github.com/ARM-software/ComputeLibrary/archive/refs/tags/v24.12.tar.gz\"),\n     )\n \n     tf_http_archive(\n@@ -398,7 +391,7 @@ def _tf_repositories():\n \n     tf_http_archive(\n         name = \"com_google_protobuf\",\n-        patch_file = [\"@local_xla//third_party/protobuf:protobuf-6.31.1.patch\"],\n+        patch_file = [\"@local_xla//third_party/protobuf:protobuf.patch\"],\n         sha256 = \"6e09bbc950ba60c3a7b30280210cd285af8d7d8ed5e0a6ed101c72aff22e8d88\",\n         strip_prefix = \"protobuf-6.31.1\",\n         urls = tf_mirror_urls(\"https://github.com/protocolbuffers/protobuf/archive/refs/tags/v6.31.1.zip\"),"
        },
        {
            "sha": "16c70e587af19c9857868063c1b45dbf78f453bc",
            "filename": "third_party/flatbuffers/workspace.bzl",
            "status": "modified",
            "additions": 5,
            "deletions": 8,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fflatbuffers%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fflatbuffers%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fflatbuffers%2Fworkspace.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -2,20 +2,17 @@\n \n load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n \n-# _FLATBUFFERS_GIT_COMMIT / _FLATBUFFERS_SHA256 were added due to an urgent change being made to\n-# Flatbuffers that needed to be updated in order for Flatbuffers/TfLite be compatible with Android\n-# API level >= 23. They can be removed next flatbuffers offical release / update.\n-_FLATBUFFERS_GIT_COMMIT = \"e6463926479bd6b330cbcf673f7e917803fd5831\"\n+_FLATBUFFERS_VERSION = \"25.2.10\"\n \n-# curl -L https://github.com/google/flatbuffers/archive/<_FLATBUFFERS_GIT_COMMIT>.tar.gz | shasum -a 256\n-_FLATBUFFERS_SHA256 = \"c9c6b8653597ed7ee5c62243979010bd0f09b29a46be414505bc5b58a874bb17\"\n+# curl -L https://github.com/google/flatbuffers/archive/<_FLATBUFFERS_VERSION>.tar.gz | shasum -a 256\n+_FLATBUFFERS_SHA256 = \"b9c2df49707c57a48fc0923d52b8c73beb72d675f9d44b2211e4569be40a7421\"\n \n def repo():\n     tf_http_archive(\n         name = \"flatbuffers\",\n-        strip_prefix = \"flatbuffers-%s\" % _FLATBUFFERS_GIT_COMMIT,\n+        strip_prefix = \"flatbuffers-%s\" % _FLATBUFFERS_VERSION,\n         sha256 = _FLATBUFFERS_SHA256,\n-        urls = tf_mirror_urls(\"https://github.com/google/flatbuffers/archive/%s.tar.gz\" % _FLATBUFFERS_GIT_COMMIT),\n+        urls = tf_mirror_urls(\"https://github.com/google/flatbuffers/archive/v%s.tar.gz\" % _FLATBUFFERS_VERSION),\n         build_file = \"//third_party/flatbuffers:flatbuffers.BUILD\",\n         system_build_file = \"//third_party/flatbuffers:BUILD.system\",\n         link_files = {"
        },
        {
            "sha": "635a0bffc39ef7b0249bafd47068c48cd8f8b7aa",
            "filename": "third_party/xla/.github/workflows/benchmarks/compare_with_baseline.py",
            "status": "modified",
            "additions": 54,
            "deletions": 24,
            "changes": 78,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2F.github%2Fworkflows%2Fbenchmarks%2Fcompare_with_baseline.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2F.github%2Fworkflows%2Fbenchmarks%2Fcompare_with_baseline.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2F.github%2Fworkflows%2Fbenchmarks%2Fcompare_with_baseline.py?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -95,14 +95,23 @@ def compare_metrics(\n   # {\n   #   ...,\n   #   \"metrics\": {\n-  #     \"GPU_DEVICE_TIME\": { \"value_ms\": 150.0, \"unit\": \"ms\", ... },\n-  #     \"GPU_DEVICE_MEMCPY_TIME\": { \"value_ms\": 1.2, \"unit\": \"ms\", ... },\n+  #     \"GPU_DEVICE_TIME\": { \"value\": 150.0, \"unit\": \"ms\", ... },\n+  #     \"GPU_DEVICE_MEMCPY_TIME\": { \"value\": 1.2, \"unit\": \"ms\", ... },\n+  #     \"PEAK_GPU_MEMORY\": { \"value\": 12.45, \"unit\": \"GB\", ... },\n   #     ...\n   #   }\n   # }\n   # If your actual results.json structure is different, you MUST adapt this\n   # section.\n   actual_metrics_container = results_data.get(\"metrics\")\n+  metric_to_baseline_key = {\n+      \"WALL_TIME\": \"baseline_ms\",\n+      \"GPU_DEVICE_TIME\": \"baseline_ms\",\n+      \"GPU_DEVICE_MEMCPY_TIME\": \"baseline_ms\",\n+      \"CPU_TIME\": \"baseline_ms\",\n+      \"PEAK_CPU_MEMORY\": \"baseline_gb\",\n+      \"PEAK_GPU_MEMORY\": \"baseline_gb\",\n+  }\n \n   if not actual_metrics_container or not isinstance(\n       actual_metrics_container, dict\n@@ -119,33 +128,44 @@ def compare_metrics(\n     sys.exit(0)  # Exit cleanly if no metrics to compare\n \n   for metric_name, baseline_info in config_baselines.items():\n-    if not isinstance(baseline_info, dict) or not all(\n-        key in baseline_info for key in [\"baseline_ms\", \"threshold\"]\n+    if (\n+        not isinstance(baseline_info, dict)\n+        or \"threshold\" not in baseline_info\n+        or not {\"baseline_ms\", \"baseline_gb\"}.intersection(baseline_info.keys())\n     ):\n       summary_messages.append(\n           f\"::warning title=Malformed Baseline::Metric '{metric_name}' in\"\n-          f\" baseline for '{config_id}' is missing 'baseline_ms' or\"\n-          \" 'threshold', or is not structured as a dictionary. Skipping.\"\n+          f\" baseline for '{config_id}' is missing 'threshold', or is missing\"\n+          \" both 'baseline_ms' and 'baseline_gb', or is not structured as a\"\n+          \" dictionary. Skipping.\"\n+      )\n+      continue\n+\n+    baseline_key = metric_to_baseline_key.get(metric_name)\n+    if not baseline_key:\n+      summary_messages.append(\n+          f\"::warning title=Unsupported Metric::Metric '{metric_name}' is not\"\n+          \" supported by this script. Skipping.\"\n       )\n       continue\n \n     try:\n-      baseline_value_ms = float(baseline_info[\"baseline_ms\"])\n+      baseline_value = float(baseline_info[baseline_key])\n       threshold_percentage = float(baseline_info[\"threshold\"])\n     except ValueError:\n       summary_messages.append(\n           f\"::warning title=Invalid Baseline Value::Metric '{metric_name}' in\"\n-          f\" baseline for '{config_id}' has non-numeric 'baseline_ms' or\"\n+          f\" baseline for '{config_id}' has non-numeric '{baseline_key}' or\"\n           \" 'threshold'. Skipping.\"\n       )\n       continue\n \n     # Extract the actual metric value from results.json\n     actual_metric_entry = actual_metrics_container.get(metric_name)\n \n-    if not actual_metric_entry or \"value_ms\" not in actual_metric_entry:\n+    if not actual_metric_entry or \"value\" not in actual_metric_entry:\n       summary_messages.append(\n-          f\"Metric '{metric_name}': Actual value or 'value_ms' key not found in\"\n+          f\"Metric '{metric_name}': Actual value or 'value' key not found in\"\n           \" results, or not a dictionary. Skipping.\"\n       )\n       # For debugging:\n@@ -161,50 +181,60 @@ def compare_metrics(\n       continue\n \n     try:\n-      actual_value_ms = float(actual_metric_entry[\"value_ms\"])\n+      actual_value = float(actual_metric_entry[\"value\"])\n     except (ValueError, TypeError):\n       summary_messages.append(\n           f\"Metric '{metric_name}': Actual value\"\n-          f\" '{actual_metric_entry['value_ms']}' is not a valid number.\"\n+          f\" '{actual_metric_entry['value']}' is not a valid number.\"\n+          \" Skipping.\"\n+      )\n+      continue\n+\n+    actual_unit = actual_metric_entry.get(\"unit\")\n+    if not actual_unit:\n+      summary_messages.append(\n+          f\"Metric '{metric_name}': Actual value unit is not specified.\"\n           \" Skipping.\"\n       )\n       continue\n \n     summary_messages.append(f\"\\nComparing metric: {metric_name}\")\n-    summary_messages.append(f\"  Actual Value: {actual_value_ms:.3f} ms\")\n-    summary_messages.append(f\"  Baseline Value: {baseline_value_ms:.3f} ms\")\n+    summary_messages.append(f\"  Actual Value: {actual_value:.3f} {actual_unit}\")\n+    summary_messages.append(\n+        f\"  Baseline Value: {baseline_value:.3f} {actual_unit}\"\n+    )\n     summary_messages.append(\n         f\"  Allowed Threshold: {threshold_percentage*100:.1f}%\"\n     )\n \n     # Higher value is worse for time-based metrics\n-    allowed_upper_bound = baseline_value_ms * (1.0 + threshold_percentage)\n+    allowed_upper_bound = baseline_value * (1.0 + threshold_percentage)\n     summary_messages.append(\n         \"  Allowed Upper Bound (Baseline * (1 + Threshold)):\"\n-        f\" {allowed_upper_bound:.3f} ms\"\n+        f\" {allowed_upper_bound:.3f} {actual_unit}\"\n     )\n \n-    if actual_value_ms > allowed_upper_bound:\n+    if actual_value > allowed_upper_bound:\n       percentage_diff = 0.0\n       if (\n-          abs(baseline_value_ms) > 1e-9\n+          abs(baseline_value) > 1e-9\n       ):  # Avoid division by zero for very small baselines\n         percentage_diff = (\n-            (actual_value_ms - baseline_value_ms) / baseline_value_ms\n+            (actual_value - baseline_value) / baseline_value\n         ) * 100.0\n       elif (\n-          actual_value_ms > 0\n+          actual_value > 0\n       ):  # If baseline is effectively zero, any positive value is infinitely\n         # worse.\n         percentage_diff = float(\"inf\")\n \n       # Use GitHub Actions error annotation for better visibility\n       error_title = f\"REGRESSION: {metric_name}\"\n       error_details = (\n-          f\"Value {actual_value_ms:.3f} ms is {percentage_diff:.2f}% worse than\"\n-          f\" baseline {baseline_value_ms:.3f} ms. Exceeds threshold of\"\n-          f\" {threshold_percentage*100:.1f}% (max allowed:\"\n-          f\" {allowed_upper_bound:.3f} ms).\"\n+          f\"Value {actual_value:.3f} {actual_unit} is {percentage_diff:.2f}%\"\n+          f\" worse than baseline {baseline_value:.3f} {actual_unit}. Exceeds\"\n+          f\" threshold of {threshold_percentage*100:.1f}% (max allowed:\"\n+          f\" {allowed_upper_bound:.3f} {actual_unit}).\"\n       )\n       summary_messages.append(\n           \"  ::error\""
        },
        {
            "sha": "f579831c0c41b86823c5816c93a37f8676ee279e",
            "filename": "third_party/xla/.github/workflows/benchmarks/run_benchmark.sh",
            "status": "modified",
            "additions": 47,
            "deletions": 39,
            "changes": 86,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2F.github%2Fworkflows%2Fbenchmarks%2Frun_benchmark.sh",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2F.github%2Fworkflows%2Fbenchmarks%2Frun_benchmark.sh",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2F.github%2Fworkflows%2Fbenchmarks%2Frun_benchmark.sh?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -128,49 +128,57 @@ if [ -f \"$XSPACE_FILE_PATH\" ] && [ $RUNNER_EXIT_CODE -eq 0 ]; then\n         key=$(echo \"$key\" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')\n         value=$(echo \"$value\" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')\n \n-        # Expecting lines like \"Metric Name: 123.45 us\"\n-        if [[ \"$value\" == *us ]]; then\n-            num_value=$(echo \"$value\" | sed 's/ us$//')\n-            # Convert microseconds to milliseconds using awk\n-            ms_value=$(LC_ALL=C awk -v num=\"$num_value\" 'BEGIN { printf \"%.3f\", num / 1000 }')\n-\n-            # Sanitize base metric key (e.g., \"Device Time\" -> \"DEVICE_TIME\")\n-            base_metric_key=$(echo \"$key\" | tr ' ' '_' | tr '[:lower:]' '[:upper:]')\n-            final_metric_key=\"\"\n-\n-            # Determine the final metric key based on HARDWARE_CATEGORY for baseline matching\n-            if [[ \"$HARDWARE_CATEGORY\" == GPU* ]]; then\n-                if [[ \"$base_metric_key\" == \"DEVICE_TIME\" ]]; then\n-                    final_metric_key=\"GPU_DEVICE_TIME\"\n-                elif [[ \"$base_metric_key\" == \"DEVICE_MEMCPY_TIME\" ]]; then\n-                    final_metric_key=\"GPU_DEVICE_MEMCPY_TIME\"\n-                # Add other specific GPU mappings here if needed\n-                # else\n-                #    final_metric_key=\"GPU_${base_metric_key}\" # Generic prefix\n-                else\n-                    final_metric_key=\"$base_metric_key\" # If no specific GPU mapping, use base\n-                fi\n-            elif [[ \"$HARDWARE_CATEGORY\" == CPU* ]]; then\n-                if [[ \"$base_metric_key\" == \"CPU_TIME\" ]] || [[ \"$base_metric_key\" == \"TIME\" ]]; then # Handle \"CPU Time\" or just \"Time\"\n-                    final_metric_key=\"CPU_TIME\"\n-                elif [[ \"$base_metric_key\" == \"WALL_TIME\" ]]; then\n-                    final_metric_key=\"WALL_TIME\" # Wall time is generic\n-                # Add other specific CPU mappings here if needed\n-                # else\n-                #    final_metric_key=\"CPU_${base_metric_key}\" # Generic prefix\n-                else\n-                    final_metric_key=\"$base_metric_key\" # If no specific CPU mapping, use base\n-                fi\n+        # Sanitize base metric key (e.g., \"Device Time\" -> \"DEVICE_TIME\")\n+        base_metric_key=$(echo \"$key\" | tr ' ' '_' | tr '[:lower:]' '[:upper:]')\n+        final_metric_key=\"\"\n+\n+        # Determine the final metric key based on HARDWARE_CATEGORY for baseline matching\n+        if [[ \"$HARDWARE_CATEGORY\" == GPU* ]]; then\n+            if [[ \"$base_metric_key\" == \"DEVICE_TIME\" ]]; then\n+                final_metric_key=\"GPU_DEVICE_TIME\"\n+            elif [[ \"$base_metric_key\" == \"DEVICE_MEMCPY_TIME\" ]]; then\n+                final_metric_key=\"GPU_DEVICE_MEMCPY_TIME\"\n+            elif  [[ \"$base_metric_key\" == \"PEAK_MEMORY\" ]]; then\n+                final_metric_key=\"PEAK_GPU_MEMORY\"\n+            # Add other specific GPU mappings here if needed\n+            # else\n+            #    final_metric_key=\"GPU_${base_metric_key}\" # Generic prefix\n             else\n-                final_metric_key=\"$base_metric_key\" # For unknown/other categories\n+                final_metric_key=\"$base_metric_key\" # If no specific GPU mapping, use base\n             fi\n+        elif [[ \"$HARDWARE_CATEGORY\" == CPU* ]]; then\n+            if [[ \"$base_metric_key\" == \"CPU_TIME\" ]] || [[ \"$base_metric_key\" == \"TIME\" ]]; then # Handle \"CPU Time\" or just \"Time\"\n+                final_metric_key=\"CPU_TIME\"\n+            elif [[ \"$base_metric_key\" == \"WALL_TIME\" ]]; then\n+                final_metric_key=\"WALL_TIME\" # Wall time is generic\n+            # Add other specific CPU mappings here if needed\n+            # else\n+            #    final_metric_key=\"CPU_${base_metric_key}\" # Generic prefix\n+            else\n+                final_metric_key=\"$base_metric_key\" # If no specific CPU mapping, use base\n+            fi\n+        else\n+            final_metric_key=\"$base_metric_key\" # For unknown/other categories\n+        fi\n \n-            echo \"INFO: Parsed metric: OriginalKey='$key', BaseKey='$base_metric_key', FinalKey='$final_metric_key', ValueMs='$ms_value'\"\n-\n-            if ! $first_metric; then metrics_obj_str+=\",\"; fi\n-            metrics_obj_str+=\"\\\"$final_metric_key\\\": {\\\"value_ms\\\": $ms_value, \\\"unit\\\": \\\"ms\\\"}\"\n-            first_metric=false\n+        # Expecting lines like \"Metric Name: 123.45 us\" or \"Metric Name: 12345 bytes\"\n+        read number unit <<< $(echo \"$value\" | sed -E 's/([0-9]+\\.?[0-9]*)\\s*([a-zA-Z]+).*/\\1 \\2/')\n+        # Convert microseconds to milliseconds\n+        if [[ \"$unit\" == \"us\" ]]; then\n+            final_metric_value=$(LC_ALL=C awk -v num=\"$number\" 'BEGIN { printf \"%.3f\", num / 1000 }')\n+            final_unit=\"ms\"\n+        elif [[ \"$unit\" == \"bytes\" ]]; then\n+            # Convert bytes to GB\n+            final_metric_value=$(echo \"$number\" | awk '{printf \"%.2f\", $1/1024^3}')\n+            final_unit=\"GB\"\n+        else\n+          echo \"::warning::Skipping unsupported unit: $unit\"\n+          continue\n         fi\n+        if ! $first_metric; then metrics_obj_str+=\",\"; fi\n+        metrics_obj_str+=\"\\\"$final_metric_key\\\": {\\\"value\\\": $final_metric_value, \\\"unit\\\": \\\"$final_unit\\\"}\"\n+        first_metric=false\n+        echo \"INFO: Parsed metric: OriginalKey='$key', BaseKey='$base_metric_key', FinalKey='$final_metric_key', Value='$final_metric_value $final_unit'\"\n     done <<< \"$STATS_OUTPUT\"\n     metrics_obj_str+=\"}\"\n "
        },
        {
            "sha": "72a9ee851d1cb28c306b32742a0eae8f91f9005e",
            "filename": "third_party/xla/.github/workflows/scorecards-analysis.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2F.github%2Fworkflows%2Fscorecards-analysis.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2F.github%2Fworkflows%2Fscorecards-analysis.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2F.github%2Fworkflows%2Fscorecards-analysis.yml?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -67,6 +67,6 @@ jobs:\n       # Upload the results to GitHub's code scanning dashboard (optional).\n       # Commenting out will disable upload of results to your repo's Code Scanning dashboard\n       - name: \"Upload to code-scanning\"\n-        uses: github/codeql-action/upload-sarif@96f518a34f7a870018057716cc4d7a5c014bd61c # v3.29.5\n+        uses: github/codeql-action/upload-sarif@3c3833e0f8c1c83d449a7478aa59c036a9165498 # v3.29.5\n         with:\n           sarif_file: results.sarif"
        },
        {
            "sha": "7ac815ada9d5e270758ae26fa8699dd6c0e3c00d",
            "filename": "third_party/xla/WORKSPACE",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2FWORKSPACE",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2FWORKSPACE",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2FWORKSPACE?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -9,10 +9,10 @@ load(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\")\n # Details: https://github.com/google-ml-infra/rules_ml_toolchain\n http_archive(\n     name = \"rules_ml_toolchain\",\n-    sha256 = \"9a3e9b3e1f5e8368ab5dfa7d4ec17688810ceeb521b637c975c53d8ade65d513\",\n-    strip_prefix = \"rules_ml_toolchain-087c24520fa94fcded738b8a3cd1113566629140\",\n+    sha256 = \"e7e44c4e349a1c1f31398bd2257c51432e73ea0e7e24cce67090b68b0b50007e\",\n+    strip_prefix = \"rules_ml_toolchain-55dcd0a52c7e0f9eec9927a32512229c09ac3b3e\",\n     urls = [\n-        \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/087c24520fa94fcded738b8a3cd1113566629140.tar.gz\",\n+        \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/55dcd0a52c7e0f9eec9927a32512229c09ac3b3e.tar.gz\",\n     ],\n )\n "
        },
        {
            "sha": "afacda10c6c2ca777db968755936fa056fbd489e",
            "filename": "third_party/xla/build_tools/rocm/run_xla.sh",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fbuild_tools%2Frocm%2Frun_xla.sh",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fbuild_tools%2Frocm%2Frun_xla.sh",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fbuild_tools%2Frocm%2Frun_xla.sh?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -51,7 +51,7 @@ fi\n export PYTHON_BIN_PATH=`which python3`\n export TF_NEED_ROCM=1\n export ROCM_PATH=$ROCM_INSTALL_DIR\n-TAGS_FILTER=\"gpu,requires-gpu-amd,-requires-gpu-nvidia,-requires-gpu-intel,-no_oss,-oss_excluded,-oss_serial,-no_gpu,-cuda-only,-oneapi-only\"\n+TAGS_FILTER=\"gpu,requires-gpu-amd,-multi_gpu,-requires-gpu-nvidia,-requires-gpu-intel,-no_oss,-oss_excluded,-oss_serial,-no_gpu,-cuda-only,-oneapi-only\"\n UNSUPPORTED_GPU_TAGS=\"$(echo -requires-gpu-sm{60,70,80,86,89,90}{,-only})\"\n TAGS_FILTER=\"${TAGS_FILTER},${UNSUPPORTED_GPU_TAGS// /,}\"\n "
        },
        {
            "sha": "3f18028cf6c9ea709946892693405801886e7f04",
            "filename": "third_party/xla/docs/_toc.yaml",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fdocs%2F_toc.yaml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fdocs%2F_toc.yaml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2F_toc.yaml?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -51,6 +51,11 @@ toc:\n     path: /xla/flags_guidance\n   - title: XLA Tooling\n     path: /xla/tools\n+- title: Debugging\n+  section:\n+  # This is the default tab for the Debugging section.\n+  - title: Dump HLO Computations\n+    path: /xla/hlo_dumps\n - title: Contributing\n   # These should be in alphabetical order unless otherwise noted.\n   section:"
        },
        {
            "sha": "d834b437b4ae78feac29b6baaa24d05f6438ed8b",
            "filename": "third_party/xla/docs/hlo_dumps.md",
            "status": "added",
            "additions": 260,
            "deletions": 0,
            "changes": 260,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fdocs%2Fhlo_dumps.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fdocs%2Fhlo_dumps.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Fhlo_dumps.md?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,260 @@\n+# Dump HLO Computations\n+\n+An HLO dump is a textual representation of the HLO modules at different stages\n+of the computation. It is useful for debugging, and you often need to include it\n+in bug reports. This is typically a human-readable **text file** that lists the\n+HLO instructions and their properties. Sometimes, HLO modules are dumped as:\n+\n+-   **HloProto:** Protocol buffer files, which are a more structured,\n+    machine-readable format.\n+-   **HloSnapshot**: HLO module plus its inputs. For replaying HLOs, you\n+    sometimes require the actual inputs fed to a given computation rather than\n+    random data.\n+\n+You can use XLA flags to specify and get dumps. In most cases, you can set it\n+with an environment variable. JAX also offers a programmatic way to print the\n+HLO dump.\n+\n+## Local Execution\n+\n+### Using Environment Variables\n+\n+You can set the `XLA_FLAGS` environment variable with the necessary flags to get\n+dumps. This works for JAX, TensorFlow, and PyTorch/XLA.\n+\n+To dump HLO modules and other debugging information to a specific directory, run\n+your program with the `--xla_dump_to` flag:\n+\n+```shell\n+XLA_FLAGS=\"--xla_dump_to=DIRECTORY_PATH\"\n+```\n+\n+For example, you can use `/tmp` or `/tmp/xladump` as the paths.\n+\n+By default, this dumps HLO modules as text, at the very beginning and end of the\n+optimization pipeline.\n+\n+You can also explicitly specify the format:\n+\n+1.  Text dumps\n+\n+```shell\n+XLA_FLAGS=\"--xla_dump_hlo_as_text --xla_dump_to=DIRECTORY_PATH\"\n+```\n+\n+1.  HLO protos\n+\n+```shell\n+XLA_FLAGS=\"--xla_dump_hlo_as_proto --xla_dump_to=DIRECTORY_PATH\"\n+```\n+\n+1.  HLO Snapshots\n+\n+```shell\n+XLA_FLAGS=\"--xla_dump_hlo_snapshots --xla_dump_to=DIRECTORY_PATH\"\n+```\n+\n+1.  Graph render with graphviz server (only works well for small graphs)\n+\n+```shell\n+XLA_FLAGS=\"--xla_dump_hlo_as_url --xla_dump_to=DIRECTORY_PATH\"\n+```\n+\n+1.  Graph render to HTML file (only works well for small graphs)\n+\n+```shell\n+XLA_FLAGS=\"--xla_dump_hlo_as_html --xla_dump_to=DIRECTORY_PATH\"\n+```\n+\n+For larger graphs, you can use `interactive_graphviz` to visualize parts of the\n+graph.\n+\n+**Note:** If `--xla_dump_to` is not specified but another dumping flag is\n+specified, it will dump to stdout. But the dump will not include binary data,\n+e.g., proto files, to stdout.\n+\n+## Dump Specific Intermediate Passes\n+\n+In addition to the standard pre-optimized / final-optimized HLOs, you can also\n+dump the state of HLOs after a particular compiler pass.\n+\n+```shell\n+XLA_FLAGS=\"--xla_dump_hlo_pass_re=regex --xla_dump_to=DIRECTORY_PATH\"\n+```\n+\n+HLO modules will be dumped for the passes whose names match the regular\n+expression (regex). For example, you can observe the HLOs resulting from passes\n+related to SPMD partitioning with:\n+\n+```shell\n+XLA_FLAGS=\"--xla_dump_to=DIRECTORY_PATH --xla_dump_hlo_pass_re=spmd|propagation\"\n+```\n+\n+To dump the result after every XLA pass (this will result in a lot of files),\n+you can set:\n+\n+```shell\n+XLA_FLAGS=\"--xla_dump_to=DIRECTORY_PATH --xla_dump_hlo_pass_re=.*\"\n+```\n+\n+### JAX-specific Options\n+\n+#### Programmatically in JAX\n+\n+Instead of passing flags or environment variables, you can also programmatically\n+dump HLO using JAXs `lower` and `compile` APIs.\n+\n+Locally fetch the unoptimized original lowered HLO with:\n+\n+```python\n+jax.jit(f).lower(*args).as_text('hlo')\n+```\n+\n+For dumping to files during HLO compilation passes, specify:\n+\n+```python\n+compilation_args = {\n+    'xla_dump_to': DIRECTORY_PATH,\n+    'xla_dump_hlo_pass_re': 'spmd|propagation', # or some other pass filter\n+    ...\n+    }\n+\n+jax.jit(f).lower(*args).compile(compilation_args)\n+```\n+\n+#### Dump jaxprs\n+\n+[`jaxpr`s](https://docs.jax.dev/en/latest/jaxpr.html) are JAX's intermediate\n+representation for program traces. To dump this, set the environment variables:\n+\n+```shell\n+JAX_DUMP_IR_TO=\"DIRECTORY_PATH\" JAX_DUMP_IR_MODES=jaxpr\n+```\n+\n+Learn more in JAX documentation on\n+[Exporting and serializing staged-out computations: Debugging](https://docs.jax.dev/en/latest/export/export.html#debugging).\n+\n+## Google Colab\n+\n+### Environment variables\n+\n+In the first executed cell of your notebook (because environment variables and\n+command-line flags are usually only processed once, e.g., at module-import time\n+or XLA backend initialization time), add the `XLA_FLAGS` detailed above with\n+`os.environ`, for example:\n+\n+```python\n+import os\n+os.environ['XLA_FLAGS'] = \"--xla_dump_to=DIRECTORY_PATH\"\n+```\n+\n+This will dump the computation to `DIRECTORY_PATH`, for example `/tmp`. On\n+Colab, navigate to the \"Files\" browser in the left sidebar, to view and access\n+this directory.\n+\n+You can use all the flags mentioned in the Local Execution section.\n+\n+### JAX-specific options\n+\n+Similar to local execution; for live, interactive introspection you can directly\n+print a computations pre-optimized HLO:\n+\n+```python\n+def f(x):\n+    return jax.numpy.sin(jax.numpy.cos(x))\n+\n+c = jax.jit(f).lower(3.).compiler_ir('hlo')\n+\n+print(c.as_hlo_text())\n+```\n+\n+You can also directly print a computations optimized HLO:\n+\n+```python\n+def optimized_HLO(f, *args, platform=None):\n+    print(jax.jit(f).lower(*args).compile().as_text())\n+\n+def f(x):\n+    return jax.numpy.sin(jax.numpy.cos(x))\n+\n+optimized_HLO(f, 1.0)\n+```\n+\n+#### Dumping All/Small Computations\n+\n+If you want to see everything in a dump including all small compilations, set\n+the JAX environment variable:\n+\n+```shell\n+JAX_COMPILER_DETAILED_LOGGING_MIN_OPS=0\n+```\n+\n+#### Mosaic\n+\n+Mosaic is a compiler for the Pallas TPU backend, and the experimental Pallas GPU\n+backend. To dump mosaic computation, set the following flag:\n+\n+```shell\n+--xla_mosaic_dump_to=/tmp/mosaic_dumps\n+```\n+\n+Or, set TPU init arguments as an environment variable:\n+\n+```shell\n+export LIBTPU_INIT_ARGS=\"--xla_mosaic_dump_to=/tmp/mosaic_dumps\"\n+```\n+\n+Check out the\n+[JAX documentation on Pallas and Mosaic](https://docs.jax.dev/en/latest/pallas/index.html)\n+to learn more.\n+\n+## More with HLO Dumps\n+\n+### Finding the right computation\n+\n+Usually, many computations get dumped. The dumped files are explicitly named\n+with the JAX, Tensorflow, or PyTorch/XLA \"computation name that are called out\n+in the logs, making it easy to identify the relevant HLO files. For example:\n+\n+```\n+1624325116260738.module_0065.pmap__unnamed_wrapped_function_.186875.before_optimizations.txt\n+```\n+\n+Otherwise, you can use `ripgrep` to quickly identify which module holds\n+particular symbols or computations.\n+\n+**Tip:** Include the 3 dumped before/after/buffer-assignment files of interest\n+in your bug reports.\n+\n+### HLO Conversion\n+\n+A tool called `hlo-opt` that can translate between HLOProto and text formats.\n+It's useful in cases where you have one format, but need the other for\n+debugging.\n+\n+Learn to use it:\n+[XLA Tooling documentation: hlo-opt](tools.md#hlo-opt-convert-hlo-module-formats).\n+\n+### Replay\n+\n+You can run (replay) the dumped computations on a specified XLA backend with\n+fake data or input snapshots. This is a convenient way to reproduce, iterate,\n+and debug issues in XLA.\n+\n+The following commands use fake data. If you have saved HLO Snapshots, you can\n+pass those in instead, and the data from the snapshot will be used. To still use\n+fake data while running the snapshot, pass the flag `--force_fake_data`.\n+\n+CPU backend:\n+\n+```shell\n+bazel run -c opt //xla/hlo/tools:run_hlo_module -- --platform=cpu\n+ /tmp/xladump/module_4561.before_optimizations.txt\n+```\n+\n+GPU backend:\n+\n+```shell\n+bazel run -c opt //xla/hlo/tools:run_hlo_module -- --platform=CUDA\n+ /tmp/xladump/module_4561.before_optimizations.txt\n+```"
        },
        {
            "sha": "679a9d5fbfe2cf3f8e5039aaee87dcf22d21d580",
            "filename": "third_party/xla/tensorflow.bazelrc",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Ftensorflow.bazelrc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Ftensorflow.bazelrc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Ftensorflow.bazelrc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -172,17 +172,14 @@ build:mkl_threadpool --define=tensorflow_mkldnn_contraction_kernel=0\n build:mkl_threadpool --define=build_with_mkl_opensource=true\n build:mkl_threadpool -c opt\n \n-# Config setting to build oneDNN with Compute Library for the Arm Architecture (ACL).\n-build:mkl_aarch64 --define=build_with_mkl_aarch64=true\n-build:mkl_aarch64 --define=build_with_openmp=true\n-build:mkl_aarch64 --define=build_with_acl=true\n-build:mkl_aarch64 -c opt\n-\n # Config setting to build oneDNN with Compute Library for the Arm Architecture (ACL).\n # with Eigen threadpool support\n build:mkl_aarch64_threadpool --define=build_with_mkl_aarch64=true\n build:mkl_aarch64_threadpool -c opt\n \n+# This is an alias for the mkl_aarch64_threadpool build.\n+build:mkl_aarch64 --config=mkl_aarch64_threadpool\n+\n # Default CUDA, CUDNN and NVSHMEM versions.\n build:cuda_version --repo_env=HERMETIC_CUDA_VERSION=\"12.9.1\"\n build:cuda_version --repo_env=HERMETIC_CUDNN_VERSION=\"9.8.0\""
        },
        {
            "sha": "cfd54bfdc6a1865d1db518f1dff57ad96b1acc33",
            "filename": "third_party/xla/third_party/compute_library/acl_gemm_scheduling_heuristic.patch",
            "status": "added",
            "additions": 145,
            "deletions": 0,
            "changes": 145,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Facl_gemm_scheduling_heuristic.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Facl_gemm_scheduling_heuristic.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Facl_gemm_scheduling_heuristic.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,145 @@\n+# Copyright 2025 The OpenXLA Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+diff --git a/src/cpu/kernels/assembly/arm_gemm.hpp b/src/cpu/kernels/assembly/arm_gemm.hpp\n+index cbc8be416..e65bc00a0 100644\n+--- a/src/cpu/kernels/assembly/arm_gemm.hpp\n++++ b/src/cpu/kernels/assembly/arm_gemm.hpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2018-2022, 2024 Arm Limited.\n++ * Copyright (c) 2018-2022, 2024-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -44,9 +44,7 @@ enum class GemmMethod\n+     GEMM_NATIVE,\n+     GEMM_HYBRID,\n+     GEMM_INTERLEAVED,\n+-    GEMM_INTERLEAVED_2D,\n+     QUANTIZE_WRAPPER,\n+-    QUANTIZE_WRAPPER_2D,\n+     GEMM_HYBRID_QUANTIZED\n+ };\n+ \n+diff --git a/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp b/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n+index fc106140f..ec2039207 100644\n+--- a/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n++++ b/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2018-2024 Arm Limited.\n++ * Copyright (c) 2018-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -137,34 +137,6 @@ Params extract_parameters(const ITensorInfo *a, const ITensorInfo *b, const ITen\n+     return p;\n+ }\n+ \n+-IScheduler::Hints scheduling_hint_heuristic(arm_gemm::GemmMethod method, DataType data_type)\n+-{\n+-    // Schedule assembly kernel\n+-    const int         granule_threshold = 200;\n+-    IScheduler::Hints scheduling_hint   = IScheduler::Hints(Window::DimX);\n+-    if (method == arm_gemm::GemmMethod::GEMM_INTERLEAVED && data_type == DataType::F32)\n+-    {\n+-        scheduling_hint = IScheduler::Hints(Window::DimX, IScheduler::StrategyHint::DYNAMIC, granule_threshold);\n+-    }\n+-    else if (method == arm_gemm::GemmMethod::GEMM_INTERLEAVED_2D &&\n+-             (data_type == DataType::F32 || data_type == DataType::F16 || data_type == DataType::U8 ||\n+-              data_type == DataType::S8))\n+-    {\n+-        //GEMM_INTERLEAVED supports 2D parallelism, IScheduler::split_dimensions_all signals to parallelise over all window dimensions\n+-        scheduling_hint =\n+-            IScheduler::Hints(IScheduler::split_dimensions_all, IScheduler::StrategyHint::STATIC, granule_threshold);\n+-    }\n+-    else if (method == arm_gemm::GemmMethod::QUANTIZE_WRAPPER_2D &&\n+-             (data_type == DataType::QASYMM8 || data_type == DataType::QASYMM8_SIGNED))\n+-    {\n+-        //special case for QASYMM8 to support 2D parallelism, scheduler here may be tweaked differently compared to FP32 case\n+-        scheduling_hint =\n+-            IScheduler::Hints(IScheduler::split_dimensions_all, IScheduler::StrategyHint::STATIC, granule_threshold);\n+-    }\n+-\n+-    return scheduling_hint;\n+-}\n+-\n+ /** Fallback in case ACL doesn't have a function */\n+ template <typename TypeInput, typename TypeWeight, typename TypeOutput, class OutputStage = arm_gemm::Nothing>\n+ class Fallback : public CpuGemmAssemblyDispatch::IFallback\n+@@ -300,8 +272,6 @@ private:\n+     bool _is_prepared{false};\n+     /** GEMM meta-data */\n+     AsmGemmInfo _gemm_info{};\n+-    /** GEMM kernel description */\n+-    arm_gemm::KernelDescription _kernel_info{};\n+     /** Per channel quantization shifts */\n+     std::vector<int32_t> _shifts{};\n+     std::vector<int32_t> right_shifts{};\n+@@ -760,7 +730,20 @@ void Fallback<TypeInput, TypeWeight, TypeOutput, OutputStage>::run(ITensorPack &\n+         }\n+     }\n+ \n+-    const auto scheduling_hint = scheduling_hint_heuristic(_kernel_info.method, d->info()->data_type());\n++    // The scheduling_hint needs to be compatible with the window exposed by arm_gemm\n++    // The default case is when we split among the X dimension\n++    IScheduler::Hints scheduling_hint = IScheduler::Hints(Window::DimX);\n++    // If arm_gemm exposes a 2D window, perform 2D scheduling\n++    if (_optimised_kernel->window().num_iterations(Window::DimY) > 1 &&\n++        _optimised_kernel->window().num_iterations(Window::DimX) > 1)\n++    {\n++        scheduling_hint = IScheduler::Hints(IScheduler::split_dimensions_all);\n++    }\n++    // Split among Y\n++    else if (_optimised_kernel->window().num_iterations(Window::DimY) > 1)\n++    {\n++        scheduling_hint = IScheduler::Hints(Window::DimY);\n++    }\n+ \n+     // Set workspace if needed and reset number of threads as buffer manager gets re-created with max_threads\n+     CpuAuxTensorHandler workspace(offset_int_vec(AsmGemmWorkspace), _workspace_info, tensors, false);\n+diff --git a/src/runtime/IScheduler.cpp b/src/runtime/IScheduler.cpp\n+index 2dd87310a..9fa815fbd 100644\n+--- a/src/runtime/IScheduler.cpp\n++++ b/src/runtime/IScheduler.cpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2016-2024 Arm Limited.\n++ * Copyright (c) 2016-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -69,9 +69,20 @@ void IScheduler::schedule_common(ICPPKernel *kernel, const Hints &hints, const W\n+         const std::size_t m = max_window.num_iterations(Window::DimX);\n+         const std::size_t n = max_window.num_iterations(Window::DimY);\n+ \n++        const unsigned int num_iterations = m * n;\n++        const unsigned int num_threads    = std::min(num_iterations, this->num_threads());\n++\n+         //in c++17 this can be swapped for   auto [ m_threads, n_threads ] = split_2d(...\n+         unsigned m_threads, n_threads;\n+-        std::tie(m_threads, n_threads) = scheduler_utils::split_2d(this->num_threads(), m, n);\n++        std::tie(m_threads, n_threads) = scheduler_utils::split_2d(num_threads, m, n);\n++\n++        // Clamp m_threads and n_threads if not all threads have work to do\n++        unsigned int max_parallelism = std::min<unsigned int>(m, m_threads) * std::min<unsigned int>(n, n_threads);\n++        if (max_parallelism < num_threads)\n++        {\n++            m_threads = std::min<unsigned int>(m, m_threads);\n++            n_threads = std::min<unsigned int>(n, n_threads);\n++        }\n+ \n+         std::vector<IScheduler::Workload> workloads;\n+         for (unsigned int ni = 0; ni != n_threads; ++ni)"
        },
        {
            "sha": "4abc4380b32c1e8340ea0ee123cc735154ad8ed1",
            "filename": "third_party/xla/third_party/compute_library/acl_stateless_gemm_workspace.patch",
            "status": "added",
            "additions": 1463,
            "deletions": 0,
            "changes": 1463,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Facl_stateless_gemm_workspace.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Facl_stateless_gemm_workspace.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Facl_stateless_gemm_workspace.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,1463 @@\n+# Copyright 2025 The OpenXLA Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+diff --git a/arm_compute/runtime/experimental/low_level/CpuGemmAssemblyDispatch.h b/arm_compute/runtime/experimental/low_level/CpuGemmAssemblyDispatch.h\n+index 759ff120e..dbbc663c5 100644\n+--- a/arm_compute/runtime/experimental/low_level/CpuGemmAssemblyDispatch.h\n++++ b/arm_compute/runtime/experimental/low_level/CpuGemmAssemblyDispatch.h\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2018-2024 Arm Limited.\n++ * Copyright (c) 2018-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -26,7 +26,6 @@\n+ #define ACL_ARM_COMPUTE_RUNTIME_EXPERIMENTAL_LOW_LEVEL_CPUGEMMASSEMBLYDISPATCH_H\n+ \n+ #include \"arm_compute/core/ITensorPack.h\"\n+-#include \"arm_compute/core/TensorInfo.h\"\n+ #include \"arm_compute/function_info/GEMMInfo.h\"\n+ #include \"arm_compute/runtime/IOperator.h\"\n+ \n+@@ -150,6 +149,11 @@ public:\n+                                const GEMMInfo            &gemm_info = GEMMInfo());\n+ \n+     /** Indicates whether or not there is a implementation for the configured GEMM\n++     *\n++     * @deprecated All fixed-format kernels are now stateless.\n++     * For now this function will always return true, but it will be removed\n++     * completely in a future release.\n++     *\n+      * @return a bool: true if the implementation is stateless; false if not.\n+      */\n+     bool has_stateless_impl() const;\n+diff --git a/src/core/NEON/kernels/arm_gemm/.clang-format b/src/core/NEON/kernels/arm_gemm/.clang-format\n+new file mode 100644\n+index 000000000..bd90a154e\n+--- /dev/null\n++++ b/src/core/NEON/kernels/arm_gemm/.clang-format\n+@@ -0,0 +1,25 @@\n++# Copyright (c) 2025 Arm Limited.\n++#\n++# SPDX-License-Identifier: MIT\n++#\n++# Permission is hereby granted, free of charge, to any person obtaining a copy\n++# of this software and associated documentation files (the \"Software\"), to\n++# deal in the Software without restriction, including without limitation the\n++# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n++# sell copies of the Software, and to permit persons to whom the Software is\n++# furnished to do so, subject to the following conditions:\n++#\n++# The above copyright notice and this permission notice shall be included in all\n++# copies or substantial portions of the Software.\n++#\n++# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n++# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n++# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n++# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n++# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n++# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n++# SOFTWARE.\n++---\n++# Disabling clang-format for this directory to reduce the diff-noise when\n++# porting changes from arm_gemm\n++DisableFormat: true\n+diff --git a/src/core/NEON/kernels/arm_gemm/gemm_hybrid.hpp b/src/core/NEON/kernels/arm_gemm/gemm_hybrid.hpp\n+index ec8731994..15cca5c79 100644\n+--- a/src/core/NEON/kernels/arm_gemm/gemm_hybrid.hpp\n++++ b/src/core/NEON/kernels/arm_gemm/gemm_hybrid.hpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2017-2021, 2024 Arm Limited.\n++ * Copyright (c) 2017-2021, 2024-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -30,7 +30,6 @@\n+ #include \"bias_adder.hpp\"\n+ #include \"ndrange.hpp\"\n+ #include \"performance_parameters.hpp\"\n+-#include \"transform.hpp\"\n+ #include \"utils.hpp\"\n+ \n+ #ifdef CYCLE_PROFILING\n+@@ -145,8 +144,8 @@ public:\n+         return true;\n+     }\n+ \n+-    // Stateless execute\n+-    void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &, int, GemmArrays<To, To, Tr>& g_array) override {\n++    // Common execution logic.\n++    void execute_common(const ndcoord_t &work_range, const ndcoord_t &, int, GemmArrays<To, To, Tr>& g_arrays) {\n+ #ifdef CYCLE_PROFILING\n+         profiler prof;\n+ #endif\n+@@ -190,27 +189,33 @@ public:\n+                 auto p = prof.ScopedProfiler(PROFILE_KERNEL, (unsigned long)(m_end - m_start) * kern_k * roundup(nmax-n0, strategy::out_width()));\n+ #endif\n+ \n+-                strat.kernel(g_array._Aptr + (multi * g_array._A_multi_stride) + (batch * g_array._A_batch_stride) + (m_start * g_array._lda) + k0, g_array._lda,\n++                strat.kernel(g_arrays._Aptr + (multi * g_arrays._A_multi_stride) + (batch * g_arrays._A_batch_stride) + (m_start * g_arrays._lda) + k0, g_arrays._lda,\n+                              b_panel,\n+-                             g_array._Cptr + (multi * g_array._C_multi_stride) + (batch * g_array._C_batch_stride) + (m_start * g_array._ldc) + n0, g_array._ldc,\n++                             g_arrays._Cptr + (multi * g_arrays._C_multi_stride) + (batch * g_arrays._C_batch_stride) + (m_start * g_arrays._ldc) + n0, g_arrays._ldc,\n+                              (m_end - m_start), (nmax - n0), kmax-k0,\n+-                             (strategy::supports_bias() && first_pass && g_array._bias) ? g_array._bias + (multi * g_array._bias_multi_stride) + n0 : nullptr,\n++                             (strategy::supports_bias() && first_pass && g_arrays._bias) ? g_arrays._bias + (multi * g_arrays._bias_multi_stride) + n0 : nullptr,\n+                              last_pass ? _act : Activation(), !first_pass);\n+ \n+                 // Add bias externally if needed\n+-                if (!strategy::supports_bias() && g_array._bias && first_pass) {\n+-                    bias_adder(g_array._Cptr + (multi * g_array._C_multi_stride) + (batch * g_array._C_batch_stride) + (m_start * g_array._ldc) + n0, g_array._ldc,\n+-                               g_array._bias + (multi * g_array._bias_multi_stride) + n0,\n++                if (!strategy::supports_bias() && g_arrays._bias && first_pass) {\n++                    bias_adder(g_arrays._Cptr + (multi * g_arrays._C_multi_stride) + (batch * g_arrays._C_batch_stride) + (m_start * g_arrays._ldc) + n0, g_arrays._ldc,\n++                               g_arrays._bias + (multi * g_arrays._bias_multi_stride) + n0,\n+                                (m_end - m_start), (nmax - n0));\n+                 }\n+ \n+             } while (p.next_dim1());\n+         }\n++\n++    }\n++\n++    // Stateless execute\n++    void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &thread_locator, int threadid, GemmArrays<To, To, Tr> &g_arrays) override {\n++        return execute_common(work_range, thread_locator, threadid, g_arrays);\n+     }\n+ \n+     // Execute\n+     void execute(const ndcoord_t &work_range, const ndcoord_t & thread_locator, int threadid) override {\n+-        execute_stateless(work_range, thread_locator, threadid, this->_gemm_array);\n++        execute_common(work_range, thread_locator, threadid, this->_gemm_arrays);\n+     }\n+ \n+     // Interface implementation - pretransposed\n+diff --git a/src/core/NEON/kernels/arm_gemm/gemm_hybrid_indirect.hpp b/src/core/NEON/kernels/arm_gemm/gemm_hybrid_indirect.hpp\n+index 4d11f042e..9f4b6da33 100644\n+--- a/src/core/NEON/kernels/arm_gemm/gemm_hybrid_indirect.hpp\n++++ b/src/core/NEON/kernels/arm_gemm/gemm_hybrid_indirect.hpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2017-2024 Arm Limited.\n++ * Copyright (c) 2017-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -31,12 +31,10 @@\n+ #include <cassert>\n+ \n+ #include \"arm_gemm.hpp\"\n+-#include \"bias_adder.hpp\"\n+ #include \"convolver.hpp\"\n+ #include \"kernel_weight_format.hpp\"\n+ #include \"ndrange.hpp\"\n+ #include \"performance_parameters.hpp\"\n+-#include \"transform.hpp\"\n+ #include \"utils.hpp\"\n+ \n+ #ifdef CYCLE_PROFILING\n+@@ -423,8 +421,8 @@ public:\n+         return true;\n+     }\n+ \n+-    // Stateless execute\n+-    void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &, int, GemmArrays<To, Tw, Tr>& g_array) override {\n++    // Common execution logic.\n++    void execute_common(const ndcoord_t &work_range, const ndcoord_t &, int, GemmArrays<To, Tw, Tr>& g_arrays) {\n+ #ifdef CYCLE_PROFILING\n+         profiler prof;\n+ #endif\n+@@ -452,7 +450,6 @@ public:\n+         /* Make sure we've been set up correctly. */\n+         assert(FixedFormat || _B_transposed);\n+         static_assert(std::is_same<To, Tloi>::value, \"gemm_native: Operand types must be the same.\");\n+-//        static_assert(std::is_same<Tr, Tri>::value, \"gemm_native: Result types must be the same.\");\n+ \n+         /* For now, each work item implies all the K for a given output\n+          * pixel (so we don't need to synchronize access to the output\n+@@ -504,9 +501,9 @@ public:\n+ \n+                 const Troi *b_panel;\n+                 if (FixedFormat) {\n+-                    b_panel = reinterpret_cast<const Troi *>(g_array._Bptr) +\n+-                               (multi * g_array._B_multi_stride) +\n+-                               ((n0 / stripe_width<strategy, FixedFormat>::get()) * g_array._ldb) +\n++                    b_panel = reinterpret_cast<const Troi *>(g_arrays._Bptr) +\n++                               (multi * g_arrays._B_multi_stride) +\n++                               ((n0 / stripe_width<strategy, FixedFormat>::get()) * g_arrays._ldb) +\n+                                (k0 * stripe_width<strategy, FixedFormat>::get());\n+                 } else {\n+                     b_panel = _B_transposed +\n+@@ -515,7 +512,7 @@ public:\n+                                (n0 * kern_k);\n+                 }\n+ \n+-                IndirectOutputArg<Tr> out_arg(g_array._Cptr + (multi * g_array._C_multi_stride) + (batch * g_array._C_batch_stride) + (m_start * g_array._ldc) + n0, g_array._ldc);\n++                IndirectOutputArg<Tr> out_arg(g_arrays._Cptr + (multi * g_arrays._C_multi_stride) + (batch * g_arrays._C_batch_stride) + (m_start * g_arrays._ldc) + n0, g_arrays._ldc);\n+ \n+ #ifdef CYCLE_PROFILING\n+                 auto p = prof.ScopedProfiler(PROFILE_KERNEL, (unsigned long)(m_end - m_start) * kern_k * roundup(nmax-n0, strategy::out_width()));\n+@@ -527,14 +524,14 @@ public:\n+ #endif\n+                                  strat, sections, string_lengths.data(),\n+                                  IndirectInputArg<To>(_indirect_buf + (multi * _args._nbatches * _args._Ksections) + (batch * _args._Ksections) + first_section, m_start, first_offset),\n+-                                 (m_end - m_start), (nmax - n0), kern_k, b_panel, g_array._ldb, out_arg,\n+-                                 (g_array._bias && first_pass) ? g_array._bias + (multi * g_array._bias_multi_stride) + n0 : nullptr,\n++                                 (m_end - m_start), (nmax - n0), kern_k, b_panel, g_arrays._ldb, out_arg,\n++                                 (g_arrays._bias && first_pass) ? g_arrays._bias + (multi * g_arrays._bias_multi_stride) + n0 : nullptr,\n+                                  last_pass ? _args._act : Activation(),\n+                                  !first_pass || _args._accumulate,\n+                                  // Quantization parameters\n+                                  _os, _col_bias+(multi * _args._Nsize), n0);\n+                 } else if (_convolver) {\n+-                    auto conv_cols = _convolver->process_columns(g_array._Aptr + (multi * g_array._A_multi_stride) + (batch * g_array._A_batch_stride), g_array._lda, k0, kmax, _rounded_Ksize);\n++                    auto conv_cols = _convolver->process_columns(g_arrays._Aptr + (multi * g_arrays._A_multi_stride) + (batch * g_arrays._A_batch_stride), g_arrays._lda, k0, kmax, _rounded_Ksize);\n+ \n+                     unsigned int pos=0;\n+                     auto conv_rows = conv_cols.process_rows(m_start, m_end - m_start);\n+@@ -560,8 +557,8 @@ public:\n+ #endif\n+                                  strat, sections, string_lengths.data(),\n+                                  IndirectInputArg<To>(in_row_strings.data(), 0, first_offset),\n+-                                 (m_end - m_start), (nmax - n0), kern_k, b_panel, g_array._ldb, out_arg,\n+-                                 (g_array._bias && first_pass) ? g_array._bias + (multi * g_array._bias_multi_stride) + n0 : nullptr,\n++                                 (m_end - m_start), (nmax - n0), kern_k, b_panel, g_arrays._ldb, out_arg,\n++                                 (g_arrays._bias && first_pass) ? g_arrays._bias + (multi * g_arrays._bias_multi_stride) + n0 : nullptr,\n+                                  last_pass ? _args._act : Activation(),\n+                                  !first_pass || _args._accumulate,\n+                                  // Quantization parameters\n+@@ -575,9 +572,9 @@ public:\n+                                  prof,\n+ #endif\n+                                  strat, 1, &len,\n+-                                 IndirectInputArg<To>(g_array._Aptr + (multi * g_array._A_multi_stride) + (batch * g_array._A_batch_stride) + m_start * g_array._lda + k0, g_array._lda),\n+-                                 (m_end - m_start), (nmax - n0), kern_k, b_panel, g_array._ldb, out_arg,\n+-                                 (g_array._bias && first_pass) ? g_array._bias + (multi * g_array._bias_multi_stride) + n0 : nullptr,\n++                                 IndirectInputArg<To>(g_arrays._Aptr + (multi * g_arrays._A_multi_stride) + (batch * g_arrays._A_batch_stride) + m_start * g_arrays._lda + k0, g_arrays._lda),\n++                                 (m_end - m_start), (nmax - n0), kern_k, b_panel, g_arrays._ldb, out_arg,\n++                                 (g_arrays._bias && first_pass) ? g_arrays._bias + (multi * g_arrays._bias_multi_stride) + n0 : nullptr,\n+                                  last_pass ? _args._act : Activation(),\n+                                  !first_pass || _args._accumulate,\n+                                  // Quantization parameters\n+@@ -587,9 +584,14 @@ public:\n+         }\n+     }\n+ \n++    // Stateless execute\n++    void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &thread_locator, int threadid, GemmArrays<To, Tw, Tr>& g_arrays) override {\n++        return execute_common(work_range, thread_locator, threadid, g_arrays);\n++    }\n++\n+     // Execute\n+     void execute(const ndcoord_t &work_range, const ndcoord_t & thread_locator, int threadid) override {\n+-        execute_stateless(work_range, thread_locator, threadid, this->_gemm_array);\n++        execute_common(work_range, thread_locator, threadid, this->_gemm_arrays);\n+     }\n+ \n+     // Interface implementation - pretransposed\n+diff --git a/src/core/NEON/kernels/arm_gemm/gemm_hybrid_quantized.hpp b/src/core/NEON/kernels/arm_gemm/gemm_hybrid_quantized.hpp\n+index 073012e5a..1993f7d4d 100644\n+--- a/src/core/NEON/kernels/arm_gemm/gemm_hybrid_quantized.hpp\n++++ b/src/core/NEON/kernels/arm_gemm/gemm_hybrid_quantized.hpp\n+@@ -31,9 +31,6 @@\n+ #include \"ndrange.hpp\"\n+ #include \"utils.hpp\"\n+ \n+-#include \"mergeresults.hpp\"\n+-#include \"transform.hpp\"\n+-\n+ #ifdef CYCLE_PROFILING\n+ #include \"profiler.hpp\"\n+ #endif\n+@@ -70,8 +67,6 @@ class GemmHybridQuantized : public GemmCommon<To, To, Tr> {\n+     int32_t *row_bias = nullptr;\n+     int32_t *col_bias = nullptr;\n+ \n+-    void *working_space = nullptr;\n+-\n+     unsigned int _nthreads;\n+ \n+     unsigned int get_col_sum_size() const {\n+@@ -171,20 +166,17 @@ public:\n+         return true;\n+     }\n+ \n+-    // Stateless execute\n+-    // TODO: Make this actually stateless. This still uses the stateful\n+-    // execution data because it requires a workspace which would also need to\n+-    // be handled statelessly.\n+-    void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &, int threadid, GemmArrays<To, To, Tr> &) override {\n+-        auto& g_array = this->_gemm_array;\n++    // Common execution logic.\n++    void execute_common(const ndcoord_t &work_range, const ndcoord_t &, int threadid, GemmArrays<To, To, Tr> &g_arrays) {\n+ #ifdef CYCLE_PROFILING\n+         profiler prof;\n+ #endif\n+         strategy strat(_ci);\n+ \n+-        uintptr_t working_int = reinterpret_cast<uintptr_t>(working_space);\n++        void *working_space = g_arrays._workspace;\n++        auto working_int = reinterpret_cast<uintptr_t>(working_space);\n+ \n+-        Tri *result_buffer = reinterpret_cast<Tri *>(working_int + (threadid * strategy::out_height() * _Nsize * sizeof(Tri)));\n++        auto *result_buffer = reinterpret_cast<Tri *>(working_int + (threadid * strategy::out_height() * _Nsize * sizeof(Tri)));\n+ \n+         /* Make sure we've been set up correctly. */\n+         assert(_B_transposed);\n+@@ -222,7 +214,7 @@ public:\n+ #ifdef CYCLE_PROFILING\n+                     auto p = prof.ScopedProfiler(PROFILE_KERNEL, (m_end - m_start) * kern_k * roundup(nmax-n0, strategy::out_width()));\n+ #endif\n+-                    strat.kernel(g_array._Aptr + (multi * g_array._A_multi_stride) + (batch * g_array._A_batch_stride) + (m_start * g_array._lda) + k0, g_array._lda,\n++                    strat.kernel(g_arrays._Aptr + (multi * g_arrays._A_multi_stride) + (batch * g_arrays._A_batch_stride) + (m_start * g_arrays._lda) + k0, g_arrays._lda,\n+                                  b_panel,\n+                                  result_buffer, (nmax-n0),\n+                                  (m_end - m_start), (nmax - n0), kern_k,\n+@@ -234,7 +226,7 @@ public:\n+                     auto p = prof.ScopedProfiler(PROFILE_ROWSUMS, (m_end - m_start) * _Ksize);\n+ #endif\n+                     compute_row_sums(_qp, _Ksize, (m_end - m_start),\n+-                                     g_array._Aptr + (multi * g_array._A_multi_stride) + (batch * g_array._A_batch_stride) + (m_start * g_array._lda), g_array._lda,\n++                                     g_arrays._Aptr + (multi * g_arrays._A_multi_stride) + (batch * g_arrays._A_batch_stride) + (m_start * g_arrays._lda), g_arrays._lda,\n+                                      local_row_sums);\n+                 }\n+ \n+@@ -244,16 +236,21 @@ public:\n+ #endif\n+ \n+                     requantize_block_32(_qp, (nmax - n0), (m_end - m_start), result_buffer, (nmax - n0),\n+-                                        g_array._Cptr + (multi * g_array._C_multi_stride) + (batch * g_array._C_batch_stride) + (m_start * g_array._ldc) + n0, g_array._ldc,\n++                                        g_arrays._Cptr + (multi * g_arrays._C_multi_stride) + (batch * g_arrays._C_batch_stride) + (m_start * g_arrays._ldc) + n0, g_arrays._ldc,\n+                                         local_row_sums, col_bias + (multi * _Nsize) + n0, n0);\n+                 }\n+             } while (p.next_dim0());\n+         }\n+     }\n+ \n++    // Stateless execute\n++    void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &thread_locator, int threadid, GemmArrays<To, To, Tr> &g_arrays) override {\n++        return execute_common(work_range, thread_locator, threadid, g_arrays);\n++    }\n++\n+     // Execute\n+     void execute(const ndcoord_t &work_range, const ndcoord_t & thread_locator, int threadid) override {\n+-        execute_stateless(work_range, thread_locator, threadid, this->_gemm_array);\n++        execute_common(work_range, thread_locator, threadid, this->_gemm_arrays);\n+     }\n+ \n+     // Working space needed for intermediate result buffers.\n+@@ -262,7 +259,7 @@ public:\n+     }\n+ \n+     void set_working_space(void *buffer) override {\n+-        working_space = buffer;\n++        this->_gemm_arrays._workspace = buffer;\n+     }\n+ \n+     // Interface implementation - pretransposed\n+diff --git a/src/core/NEON/kernels/arm_gemm/gemm_interleaved.hpp b/src/core/NEON/kernels/arm_gemm/gemm_interleaved.hpp\n+index 6e1ea6589..5da2ed352 100644\n+--- a/src/core/NEON/kernels/arm_gemm/gemm_interleaved.hpp\n++++ b/src/core/NEON/kernels/arm_gemm/gemm_interleaved.hpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2017-2024 Arm Limited.\n++ * Copyright (c) 2017-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -31,10 +31,8 @@\n+ #include \"convolver.hpp\"\n+ #include \"kernel_traits.hpp\"\n+ #include \"kernel_weight_format.hpp\"\n+-#include \"mergeresults.hpp\"\n+ #include \"performance_parameters.hpp\"\n+ #include \"quantized.hpp\"\n+-#include \"transform.hpp\"\n+ #include \"utils.hpp\"\n+ \n+ #ifdef CYCLE_PROFILING\n+@@ -418,6 +416,11 @@ struct get_kernel_weight_format<strategy, true, Tro> {\n+     }\n+ };\n+ \n++// Calculate the offset needed if the address is not a multiple of cache-line length\n++inline size_t get_cache_align_offset(uintptr_t addr) {\n++    return (addr & 0x3F) ? 0x40 - (addr & 0x3F) : 0;\n++}\n++\n+ } // anonymous namespace\n+ \n+ template<typename strategy, typename Tlo, typename Tro, typename Tr, typename OutputStage=Nothing, bool MergeStep=true, bool FixedFormat=false, bool ForceThreadColumns=false, bool ForceFloatAccumulate=false>\n+@@ -455,9 +458,6 @@ class GemmInterleaved : public GemmCommon<Tlo, Tro, Tr> {\n+ \n+     /* Working space, pretransposed buffer, buffer manager */\n+     const Troi *_B_transposed=nullptr;\n+-    void *_working_space=nullptr;\n+-\n+-    Tab *_accumulation_buffer=nullptr;\n+ \n+     /* Output stage */\n+     OutputStage  _os;\n+@@ -600,10 +600,25 @@ class GemmInterleaved : public GemmCommon<Tlo, Tro, Tr> {\n+         return num_buffers * size_per_buffer;\n+     }\n+ \n++    // Set up accumulation buffer\n++    Tab *get_accumulation_buffer_offset(void *working_space) const {\n++        Tab *accumulation_buffer = nullptr;\n++\n++        auto working_space_addr = reinterpret_cast<uintptr_t>(working_space);\n++\n++        if (get_accumulation_buffer_size() > 0) {\n++            auto acc_buff_addr = working_space_addr + get_a_working_size() + (get_c_working_size() * _maxthreads);\n++            acc_buff_addr += get_cache_align_offset(acc_buff_addr);\n++            accumulation_buffer = reinterpret_cast<Tab *>(acc_buff_addr);\n++        }\n++\n++        return accumulation_buffer;\n++    }\n++\n+     // Get pointer into accumulation buffer\n+-    Tab *get_accumulation_buffer(unsigned int M, unsigned int N, unsigned int batch, unsigned int multi) const {\n++    Tab *get_accumulation_buffer(Tab *accumulation_buffer, unsigned int M, unsigned int N, unsigned int batch, unsigned int multi) const {\n+         // Don't do anything if there's no buffer.\n+-        if (_accumulation_buffer == nullptr) {\n++        if (accumulation_buffer == nullptr) {\n+             return nullptr;\n+         }\n+ \n+@@ -623,7 +638,7 @@ class GemmInterleaved : public GemmCommon<Tlo, Tro, Tr> {\n+ \n+         size_t buffer_index = multi * buffers_per_multi + batch * buffers_per_batch + row * buffer_cols + col;\n+ \n+-        return _accumulation_buffer + (buffer_index * size_per_buffer);\n++        return accumulation_buffer + (buffer_index * size_per_buffer);\n+     }\n+ \n+     int32_t row_sum_multiplier() const {\n+@@ -806,7 +821,7 @@ public:\n+                       _Ksections(args._Ksections), _Ktotal(get_ktotal(args)),\n+                       _rounded_Ksize(roundup(_Ksize, strategy::k_unroll())),\n+                       _nbatches(args._nbatches), _nmulti(args._nmulti), _thread_columns(is_thread_columns(args)),\n+-                      _act(args._act), _accumulate(args._accumulate),  _maxthreads(args._maxthreads), _nthreads(args._maxthreads),\n++                      _act(args._act), _accumulate(args._accumulate), _maxthreads(args._maxthreads), _nthreads(args._maxthreads),\n+                       _k_block(get_k_block_size(args)), _x_block(get_x_block_size(args)), _Mround(roundup(args._Msize, strategy::out_height())),\n+                       _os() { }\n+ \n+@@ -832,27 +847,25 @@ public:\n+         _nthreads = std::min(nthreads, _maxthreads);\n+     }\n+ \n+-    // Stateless execute\n+-    // TODO: Make this actually stateless. This still uses the stateful\n+-    // execution data because it requires a workspace which would also need to\n+-    // be handled statelessly.\n+-    void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &, int threadid, GemmArrays<Tlo, Tro, Tr> &) override {\n+-        auto& g_array = this->_gemm_array;\n++    // Common execution logic.\n++    void execute_common(const ndcoord_t &work_range, const ndcoord_t &, int threadid, GemmArrays<Tlo, Tro, Tr> &g_arrays) {\n+ #ifdef CYCLE_PROFILING\n+         profiler prof;\n+ #endif\n+ \n+-        /* Make sure we've been set up correctly. */\n++        void *working_space = g_arrays._workspace;\n++\n++        // Make sure we've been set up correctly.\n+         assert(FixedFormat || _B_transposed);\n+-        assert(_working_space);\n+-        int8_t *working_space_bytes = reinterpret_cast<int8_t *>(_working_space);\n+-\n+-        /* Align if needed */\n+-        intptr_t working_space_v = reinterpret_cast<intptr_t>(_working_space);\n+-        if (working_space_v & 0x3f) {\n+-            intptr_t alignment_offset = 0x40 - (working_space_v & 0x3f);\n+-            working_space_bytes += alignment_offset;\n+-        }\n++        assert(working_space);\n++\n++        // Align if needed.\n++        auto *working_space_bytes = reinterpret_cast<int8_t *>(working_space);\n++        auto working_space_addr = reinterpret_cast<uintptr_t>(working_space);\n++        working_space_bytes += get_cache_align_offset(working_space_addr);\n++        working_space = reinterpret_cast<void *>(working_space_bytes);\n++\n++        auto *accumulation_buffer = get_accumulation_buffer_offset(working_space);\n+ \n+         strategy strat(_ci);\n+ \n+@@ -890,8 +903,8 @@ public:\n+                     unsigned int kern_k = roundup(kmax - k0, strategy::k_unroll());\n+ \n+                     const Troi *b_ptr = FixedFormat ?\n+-                        reinterpret_cast<const Troi *>(g_array._Bptr) + (multi * g_array._B_multi_stride) +\n+-                                                     ((start_x / get_stripe_width<strategy, FixedFormat>::get()) * g_array._ldb) +\n++                        reinterpret_cast<const Troi *>(g_arrays._Bptr) + (multi * g_arrays._B_multi_stride) +\n++                                                     ((start_x / get_stripe_width<strategy, FixedFormat>::get()) * g_arrays._ldb) +\n+                                                      (k0 * get_stripe_width<strategy, FixedFormat>::get()) :\n+                         _B_transposed + (rounded_width * _Ktotal * multi) + (k0 * rounded_width) + (start_x * kern_k);\n+ \n+@@ -916,19 +929,19 @@ public:\n+                                                              _rounded_Ksize, start_row, end_row, k0, kmax, row_sum_multiplier());\n+                             } else if (_convolver) {\n+                                 transforms.PrepareA_convolution(a_panel,\n+-                                                                g_array._Aptr + (batch * g_array._A_batch_stride) + (multi * g_array._A_multi_stride),\n+-                                                                g_array._lda, *_convolver, _rounded_Ksize, start_row, end_row, k0, kmax, row_sum_multiplier());\n++                                                                g_arrays._Aptr + (batch * g_arrays._A_batch_stride) + (multi * g_arrays._A_multi_stride),\n++                                                                g_arrays._lda, *_convolver, _rounded_Ksize, start_row, end_row, k0, kmax, row_sum_multiplier());\n+                             } else {\n+                                 transforms.PrepareA(a_panel,\n+-                                                    g_array._Aptr + (batch * g_array._A_batch_stride) + (multi * g_array._A_multi_stride),\n+-                                                    g_array._lda, start_row, end_row, k0, std::min(kmax, _Ksize), row_sum_multiplier());\n++                                                    g_arrays._Aptr + (batch * g_arrays._A_batch_stride) + (multi * g_arrays._A_multi_stride),\n++                                                    g_arrays._lda, start_row, end_row, k0, std::min(kmax, _Ksize), row_sum_multiplier());\n+                             }\n+                         }\n+ \n+-                        Tr *result_ptr = g_array._Cptr + (batch * g_array._C_batch_stride) + (multi * g_array._C_multi_stride);\n++                        Tr *result_ptr = g_arrays._Cptr + (batch * g_arrays._C_batch_stride) + (multi * g_arrays._C_multi_stride);\n+ \n+                         // If we are using an accumulation buffer and this isn't the last pass, don't pass a result pointer.\n+-                        if (_accumulation_buffer && !last_pass) {\n++                        if (accumulation_buffer && !last_pass) {\n+                             result_ptr = nullptr;\n+                         }\n+ \n+@@ -938,19 +951,19 @@ public:\n+                             prof,\n+                         #endif\n+                             // Strategy and panel pointers\n+-                            strat, a_panel, b_ptr, g_array._ldb, c_panel,\n++                            strat, a_panel, b_ptr, g_arrays._ldb, c_panel,\n+                             // Result buffer pointers\n+-                            result_ptr, g_array._ldc,\n++                            result_ptr, g_arrays._ldc,\n+                             // K size, and M/N ranges\n+                             kern_k, start_row, end_row, start_x, end_x,\n+                             // Only do bias on the first pass\n+-                            ((bias_pass && g_array._bias) ? g_array._bias + (multi * g_array._bias_multi_stride) : nullptr),\n++                            ((bias_pass && g_arrays._bias) ? g_arrays._bias + (multi * g_arrays._bias_multi_stride) : nullptr),\n+                             // Only do activation on the last pass, and accumulation on any non-first pass.\n+                             (last_pass ? _act : Activation()), (!first_pass || _accumulate),\n+                             // Pass in quantization parameters for requantizing kernels (others will ignore)\n+                             _os, col_bias + (multi * _Nsize),\n+                             // Accumulation buffer\n+-                            get_accumulation_buffer(start_row, start_x, batch, multi));\n++                            get_accumulation_buffer(accumulation_buffer, start_row, start_x, batch, multi));\n+ \n+                         /* Increment to the next block */\n+                         start_row += strategy::out_height();\n+@@ -1013,12 +1026,12 @@ public:\n+                                                       _rounded_Ksize, first_m, last_m, current.k0(), current.kmax(), row_sum_multiplier());\n+                         } else if (_convolver) {\n+                             transforms.PrepareA_convolution(a_panel + ((batch * _Mround + first_m) * get_total_k_depth()),\n+-                                                      g_array._Aptr + (batch * g_array._A_batch_stride) + (current.multi() * g_array._A_multi_stride),\n+-                                                      g_array._lda, *_convolver, _rounded_Ksize, first_m, last_m, current.k0(), current.kmax(), row_sum_multiplier());\n++                                                      g_arrays._Aptr + (batch * g_arrays._A_batch_stride) + (current.multi() * g_arrays._A_multi_stride),\n++                                                      g_arrays._lda, *_convolver, _rounded_Ksize, first_m, last_m, current.k0(), current.kmax(), row_sum_multiplier());\n+                         } else {\n+                             transforms.PrepareA(a_panel + ((batch * _Mround + first_m) * get_total_k_depth()),\n+-                                                      g_array._Aptr + (batch * g_array._A_batch_stride) + (current.multi() * g_array._A_multi_stride),\n+-                                                      g_array._lda, first_m, last_m, current.k0(), std::min(_Ksize, current.kmax()), row_sum_multiplier());\n++                                                      g_arrays._Aptr + (batch * g_arrays._A_batch_stride) + (current.multi() * g_arrays._A_multi_stride),\n++                                                      g_arrays._lda, first_m, last_m, current.k0(), std::min(_Ksize, current.kmax()), row_sum_multiplier());\n+                         }\n+                     }\n+ \n+@@ -1038,8 +1051,8 @@ public:\n+ \n+                 // For FixedFormat cases, figure out the B pointer.  The loop below moves through batches and vertically through the output so this will be the same throughout.\n+                 if (FixedFormat) {\n+-                    b_panel = reinterpret_cast<const Troi *>(g_array._Bptr) + (current.multi() * g_array._B_multi_stride) +\n+-                                                                           ((current.x0() / get_stripe_width<strategy, FixedFormat>::get()) * g_array._ldb) +\n++                    b_panel = reinterpret_cast<const Troi *>(g_arrays._Bptr) + (current.multi() * g_arrays._B_multi_stride) +\n++                                                                           ((current.x0() / get_stripe_width<strategy, FixedFormat>::get()) * g_arrays._ldb) +\n+                                                                            (current.k0() * get_stripe_width<strategy, FixedFormat>::get());\n+                 }\n+ \n+@@ -1061,7 +1074,7 @@ public:\n+ \n+                     // But in the case where we have an accumulation buffer, we can't do that after all, unless\n+                     // there is no N blocking.\n+-                    if (_accumulation_buffer && ((current.x0() != 0) || (current.xmax() < _Nsize))) {\n++                    if (accumulation_buffer && ((current.x0() != 0) || (current.xmax() < _Nsize))) {\n+                         m_step = strategy::out_height();\n+                     }\n+ \n+@@ -1075,11 +1088,11 @@ public:\n+                         const bool bias_pass = (std::is_same<OutputStage, DequantizeFloat>::value && !MergeStep) ? last_pass : first_pass;\n+ \n+                         // Pointer to appropriate part of result array.\n+-                        Tr *result_ptr = g_array._Cptr + (batch * g_array._C_batch_stride) + (current.multi() * g_array._C_multi_stride);\n++                        Tr *result_ptr = g_arrays._Cptr + (batch * g_arrays._C_batch_stride) + (current.multi() * g_arrays._C_multi_stride);\n+ \n+                         // If we are using an accumulation buffer, we don't pass the result buffer to ask the kernel\n+                         // to write things into the accumulation buffer instead, except on the last pass.\n+-                        if (_accumulation_buffer && !last_pass) {\n++                        if (accumulation_buffer && !last_pass) {\n+                             result_ptr = nullptr;\n+                         }\n+ \n+@@ -1089,19 +1102,19 @@ public:\n+                             prof,\n+                         #endif\n+                             // Strategy and panel pointers\n+-                            strat, a_ptr, b_panel, g_array._ldb, c_panel,\n++                            strat, a_ptr, b_panel, g_arrays._ldb, c_panel,\n+                             // Result buffer pointers\n+-                            result_ptr, g_array._ldc,\n++                            result_ptr, g_arrays._ldc,\n+                             // K size, and M/N ranges\n+                             kern_k, y, ymax, current.x0(), current.xmax(),\n+                             // Only do bias on the first pass\n+-                            ((bias_pass && g_array._bias) ? g_array._bias + (current.multi() * g_array._bias_multi_stride) : nullptr),\n++                            ((bias_pass && g_arrays._bias) ? g_arrays._bias + (current.multi() * g_arrays._bias_multi_stride) : nullptr),\n+                             // Only do activation on the last pass, and accumulation on any non-first pass.\n+                             (last_pass ? _act : Activation()), (!first_pass || _accumulate),\n+                             // Pass in quantization parameters for requantizing kernels (others will ignore)\n+                             _os, col_bias + (current.multi() * _Nsize),\n+                             // Accumulation buffer\n+-                            get_accumulation_buffer(y, current.x0(), batch, current.multi()) );\n++                            get_accumulation_buffer(accumulation_buffer, y, current.x0(), batch, current.multi()) );\n+ \n+                         a_ptr += (strategy::out_height() * a_panel_stride);\n+                     }\n+@@ -1114,9 +1127,14 @@ public:\n+         }\n+     }\n+ \n++    // Stateless execute\n++    void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &thread_locator, int threadid, GemmArrays<Tlo, Tro, Tr> &g_arrays) override {\n++        return execute_common(work_range, thread_locator, threadid, g_arrays);\n++    }\n++\n+     // Execute\n+     void execute(const ndcoord_t &work_range, const ndcoord_t & thread_locator, int threadid) override {\n+-        execute_stateless(work_range, thread_locator, threadid, this->_gemm_array);\n++        execute_common(work_range, thread_locator, threadid, this->_gemm_arrays);\n+     }\n+ \n+     // Interface implementation - working space\n+@@ -1131,32 +1149,12 @@ public:\n+ \n+     void set_working_space(void *working_space) override {\n+         // Make sure everything ends up cache line aligned\n+-        int8_t *working_space_bytes = reinterpret_cast<int8_t *>(working_space);\n+-        intptr_t working_space_int = reinterpret_cast<intptr_t>(working_space);\n+-\n+-        size_t diff=0;\n+-\n+-        if (working_space_int & 0x3F) {\n+-            diff = 0x40 - (working_space_int & 0x3F);\n+-        }\n+-\n+-        working_space_bytes += diff;\n+-        working_space_int += diff;\n++        auto *working_space_bytes = reinterpret_cast<int8_t *>(working_space);\n++        auto  working_space_addr = reinterpret_cast<uintptr_t>(working_space);\n++        working_space_bytes += get_cache_align_offset(working_space_addr);\n+ \n+         // Pretransposed case: just set internal pointer to parameter value.\n+-        _working_space = reinterpret_cast<void *>(working_space_bytes);\n+-\n+-        // Set up accumulation buffer\n+-        if (get_accumulation_buffer_size() > 0) {\n+-            intptr_t acc_buff_int = working_space_int + get_a_working_size() + (get_c_working_size() * _maxthreads);\n+-            // Make sure the accumulation buffer is aligned (needed if the other blocks are not a multiple of cache line length)\n+-            if (acc_buff_int & 0x3F) {\n+-                acc_buff_int += (0x40 - (acc_buff_int & 0x3F));\n+-            }\n+-            _accumulation_buffer = reinterpret_cast<Tab *>(acc_buff_int);\n+-        } else {\n+-            _accumulation_buffer = nullptr;\n+-        }\n++        this->_gemm_arrays._workspace = reinterpret_cast<void *>(working_space_bytes);\n+     }\n+ \n+     // Interface implementation - pretransposed\n+diff --git a/src/core/NEON/kernels/arm_gemm/gemm_q8_mixed.cpp b/src/core/NEON/kernels/arm_gemm/gemm_q8_mixed.cpp\n+index a48244cb3..1c33f56a1 100644\n+--- a/src/core/NEON/kernels/arm_gemm/gemm_q8_mixed.cpp\n++++ b/src/core/NEON/kernels/arm_gemm/gemm_q8_mixed.cpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2024 Arm Limited.\n++ * Copyright (c) 2024-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -39,10 +39,8 @@\n+ #endif // ARM_COMPUTE_ENABLE_SVE\n+ \n+ #include \"gemm_hybrid_indirect.hpp\"\n+-#include \"gemm_hybrid_quantized.hpp\"\n++#include \"gemm_implementation.hpp\"\n+ #include \"gemm_interleaved.hpp\"\n+-#include \"gemv_pretransposed.hpp\"\n+-#include \"quantize_wrapper.hpp\"\n+ #include \"utils.hpp\"\n+ \n+ namespace arm_gemm {\n+diff --git a/src/core/NEON/kernels/arm_gemm/gemm_qint8.cpp b/src/core/NEON/kernels/arm_gemm/gemm_qint8.cpp\n+index 18008e713..eb4c947b9 100644\n+--- a/src/core/NEON/kernels/arm_gemm/gemm_qint8.cpp\n++++ b/src/core/NEON/kernels/arm_gemm/gemm_qint8.cpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2019-2020, 2022-2024 Arm Limited.\n++ * Copyright (c) 2019-2020, 2022-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -58,9 +58,9 @@\n+ \n+ #include \"gemm_hybrid_indirect.hpp\"\n+ #include \"gemm_hybrid_quantized.hpp\"\n++#include \"gemm_implementation.hpp\"\n+ #include \"gemm_interleaved.hpp\"\n+ #include \"gemv_pretransposed.hpp\"\n+-#include \"quantize_wrapper.hpp\"\n+ #include \"utils.hpp\"\n+ \n+ namespace arm_gemm {\n+@@ -241,13 +241,6 @@ GemmImplementation<int8_t, int8_t, int8_t, Requantize32>::with_estimate(\n+     [](const GemmArgs &args, const Requantize32 &) { return GemmInterleavedQuantized<cls_a64_gemm_s8_4x4, int8_t, int8_t, int8_t>::estimate_cycles<int8_t>(args); },\n+     [](const GemmArgs &args, const Requantize32 &qp) { return new GemmInterleavedQuantized<cls_a64_gemm_s8_4x4, int8_t, int8_t, int8_t>(args, qp); }\n+ ),\n+-{\n+-    GemmMethod::QUANTIZE_WRAPPER,\n+-    \"quantized_wrapper\",\n+-    [](const GemmArgs &args, const Requantize32 &) { return !args._indirect_input; },\n+-    [](const GemmArgs &, const Requantize32 &) { return false; },\n+-    [](const GemmArgs &args, const Requantize32 &qp) { return new QuantizeWrapper<int8_t, int8_t, int32_t>(args, qp); }\n+-},\n+ {\n+     GemmMethod::DEFAULT,\n+     \"\",\n+diff --git a/src/core/NEON/kernels/arm_gemm/gemm_quint8.cpp b/src/core/NEON/kernels/arm_gemm/gemm_quint8.cpp\n+index 7c182b677..c6ee7bff1 100644\n+--- a/src/core/NEON/kernels/arm_gemm/gemm_quint8.cpp\n++++ b/src/core/NEON/kernels/arm_gemm/gemm_quint8.cpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2019-2020, 2022-2024 Arm Limited.\n++ * Copyright (c) 2019-2020, 2022-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -54,9 +54,9 @@\n+ \n+ #include \"gemm_hybrid_indirect.hpp\"\n+ #include \"gemm_hybrid_quantized.hpp\"\n++#include \"gemm_implementation.hpp\"\n+ #include \"gemm_interleaved.hpp\"\n+ #include \"gemv_pretransposed.hpp\"\n+-#include \"quantize_wrapper.hpp\"\n+ \n+ namespace arm_gemm {\n+ \n+@@ -209,13 +209,6 @@ GemmImplementation<uint8_t, uint8_t, uint8_t, Requantize32>::with_estimate(\n+     [](const GemmArgs &args, const Requantize32 &) { return GemmInterleavedQuantized<cls_a64_gemm_u8_4x4, uint8_t, uint8_t, uint8_t>::estimate_cycles<uint8_t>(args); },\n+     [](const GemmArgs &args, const Requantize32 &qp) { return new GemmInterleavedQuantized<cls_a64_gemm_u8_4x4, uint8_t, uint8_t, uint8_t>(args, qp); }\n+ ),\n+-{\n+-    GemmMethod::QUANTIZE_WRAPPER,\n+-    \"quantized_wrapper\",\n+-    [](const GemmArgs &args, const Requantize32 &) { return !args._indirect_input; },\n+-    [](const GemmArgs &, const Requantize32 &) { return false; },\n+-    [](const GemmArgs &args, const Requantize32 &qp) { return new QuantizeWrapper<uint8_t, uint8_t, uint32_t>(args, qp); }\n+-},\n+ {\n+     GemmMethod::DEFAULT,\n+     \"\",\n+diff --git a/src/core/NEON/kernels/arm_gemm/gemm_u8s8fp32.cpp b/src/core/NEON/kernels/arm_gemm/gemm_u8s8fp32.cpp\n+index 606b422b0..d90245f9a 100644\n+--- a/src/core/NEON/kernels/arm_gemm/gemm_u8s8fp32.cpp\n++++ b/src/core/NEON/kernels/arm_gemm/gemm_u8s8fp32.cpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2024 Arm Limited.\n++ * Copyright (c) 2024-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -40,9 +40,9 @@\n+ \n+ #include \"gemm_hybrid_indirect.hpp\"\n+ #include \"gemm_hybrid_quantized.hpp\"\n++#include \"gemm_implementation.hpp\"\n+ #include \"gemm_interleaved.hpp\"\n+ #include \"gemv_pretransposed.hpp\"\n+-#include \"quantize_wrapper.hpp\"\n+ #include \"utils.hpp\"\n+ \n+ namespace arm_gemm {\n+diff --git a/src/core/NEON/kernels/arm_gemm/gemv_batched.hpp b/src/core/NEON/kernels/arm_gemm/gemv_batched.hpp\n+index 0ba7b7870..15941252f 100644\n+--- a/src/core/NEON/kernels/arm_gemm/gemv_batched.hpp\n++++ b/src/core/NEON/kernels/arm_gemm/gemv_batched.hpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2017-2021, 2024 Arm Limited.\n++ * Copyright (c) 2017-2021, 2024-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -64,15 +64,12 @@ public:\n+         _subgemm->set_nthreads(nthreads);\n+     }\n+ \n+-    // TODO: Make this actually stateless. This still uses the stateful\n+-    // execution data because it requires a workspace which would also need to\n+-    // be handled statelessly.\n+     void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &thread_locator, int threadid, GemmArrays<To, To, Tr> &) override {\n+         _subgemm->execute(work_range, thread_locator, threadid);\n+     }\n+ \n+     void execute(const ndcoord_t &work_range, const ndcoord_t &thread_locator, int threadid) override {\n+-        execute_stateless(work_range, thread_locator, threadid, this->_gemm_array);\n++        execute_stateless(work_range, thread_locator, threadid, this->_gemm_arrays);\n+     }\n+ \n+     size_t get_working_size() const override {\n+diff --git a/src/core/NEON/kernels/arm_gemm/gemv_pretransposed.hpp b/src/core/NEON/kernels/arm_gemm/gemv_pretransposed.hpp\n+index 08c419252..fb94dd9c3 100644\n+--- a/src/core/NEON/kernels/arm_gemm/gemv_pretransposed.hpp\n++++ b/src/core/NEON/kernels/arm_gemm/gemv_pretransposed.hpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2017-2022, 2024 Arm Limited.\n++ * Copyright (c) 2017-2022, 2024-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -26,9 +26,6 @@\n+ #include <stdio.h>\n+ \n+ #include \"arm_gemm.hpp\"\n+-#include \"bias_adder.hpp\"\n+-#include \"mergeresults.hpp\"\n+-#include \"transform.hpp\"\n+ \n+ #ifdef CYCLE_PROFILING\n+ #include \"profiler.hpp\"\n+@@ -139,8 +136,8 @@ public:\n+         return { iceildiv(_args._Nsize, strategy::out_width()) * _args._nmulti };\n+     }\n+ \n+-    // Use the stateless interface to execute the GEMV.\n+-    void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &, int, GemmArrays<To, To, Tr>& g_array) override {\n++    // Common execution logic.\n++    void execute_common(const ndcoord_t &work_range, const ndcoord_t &, int, GemmArrays<To, To, Tr>& g_arrays) {\n+ #ifdef CYCLE_PROFILING\n+         profiler prof;\n+ #endif\n+@@ -175,11 +172,11 @@ public:\n+ #ifdef CYCLE_PROFILING\n+                     auto p = prof.ScopedProfiler(PROFILE_KERNEL, (kmax-k0) * (nmax-n));\n+ #endif\n+-                    run_gemv_kernel<OutputStage>::run(strat, g_array._Aptr + (multi * g_array._A_multi_stride) + k0,\n++                    run_gemv_kernel<OutputStage>::run(strat, g_arrays._Aptr + (multi * g_arrays._A_multi_stride) + k0,\n+                                  _B_pretransposed + (multi * _buffer_per_multi) + (n * roundup(_args._Ksize, strategy::k_unroll())) + (k0 * strategy::out_width()),\n+-                                 g_array._Cptr + (multi * g_array._C_multi_stride) + n,\n++                                 g_arrays._Cptr + (multi * g_arrays._C_multi_stride) + n,\n+                                  (nmax - n), (kmax-k0),\n+-                                 g_array._bias ? g_array._bias + (multi * g_array._bias_multi_stride) + n : nullptr,\n++                                 g_arrays._bias ? g_arrays._bias + (multi * g_arrays._bias_multi_stride) + n : nullptr,\n+                                  _args._act, (k0 != 0) || _args._accumulate,\n+                                  _os, col_bias, n + (_args._Nsize * multi));\n+                 }\n+@@ -187,9 +184,14 @@ public:\n+         }\n+     }\n+ \n++    // Stateless execute\n++    void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &thread_locator, int threadid, GemmArrays<To, To, Tr> &g_arrays) override {\n++        return execute_common(work_range, thread_locator, threadid, g_arrays);\n++    }\n++\n+     // Actually execute the GEMV.\n+     void execute(const ndcoord_t &work_range, const ndcoord_t &thread_locator, int threadid) override {\n+-        execute_stateless(work_range, thread_locator, threadid, this->_gemm_array);\n++        execute_common(work_range, thread_locator, threadid, this->_gemm_arrays);\n+     }\n+ \n+     /* Pretransposed interface implementation */\n+diff --git a/src/core/NEON/kernels/arm_gemm/quantize_wrapper.hpp b/src/core/NEON/kernels/arm_gemm/quantize_wrapper.hpp\n+deleted file mode 100644\n+index 90604e941..000000000\n+--- a/src/core/NEON/kernels/arm_gemm/quantize_wrapper.hpp\n++++ /dev/null\n+@@ -1,247 +0,0 @@\n+-/*\n+- * Copyright (c) 2019-2021, 2024 Arm Limited.\n+- *\n+- * SPDX-License-Identifier: MIT\n+- *\n+- * Permission is hereby granted, free of charge, to any person obtaining a copy\n+- * of this software and associated documentation files (the \"Software\"), to\n+- * deal in the Software without restriction, including without limitation the\n+- * rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n+- * sell copies of the Software, and to permit persons to whom the Software is\n+- * furnished to do so, subject to the following conditions:\n+- *\n+- * The above copyright notice and this permission notice shall be included in all\n+- * copies or substantial portions of the Software.\n+- *\n+- * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n+- * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n+- * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n+- * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n+- * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n+- * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n+- * SOFTWARE.\n+- */\n+-\n+-#pragma once\n+-\n+-#include \"arm_gemm.hpp\"\n+-\n+-#include \"barrier.hpp\"\n+-#include \"gemm_implementation.hpp\"\n+-#include \"quantized.hpp\"\n+-\n+-namespace arm_gemm {\n+-\n+-/* Quantized wrapper - do an integer GEMM and wrap around the quantization. */\n+-\n+-template<typename To, typename Tr, typename Tgemm>\n+-class QuantizeWrapper : public GemmCommon<To, To, Tr> {\n+-private:\n+-    UniqueGemmCommon<To, To, Tgemm>  _subgemm = nullptr;\n+-    int32_t                     *_row_sums = nullptr;\n+-    int32_t                     *_col_sums = nullptr;\n+-    Requantize32                 _params;\n+-    GemmArgs                     _args;\n+-    barrier                      _barrier;\n+-\n+-    void *working_space = nullptr;\n+-    bool  arrays_set = false;\n+-\n+-    /* We need a subgemm which outputs the 32-bit intermediates - how much space is needed for that? */\n+-    size_t subgemm_output_size() const {\n+-        return (_args._Msize * _args._Nsize * _args._nbatches * _args._nmulti * sizeof(int32_t));\n+-    }\n+-\n+-    size_t col_sum_size() const {\n+-        return (_args._Nsize * _args._nmulti * sizeof(int32_t));\n+-    }\n+-\n+-    size_t row_sum_size() const {\n+-        return (_args._Msize * _args._nbatches * _args._nmulti * sizeof(int32_t));\n+-    }\n+-\n+-    /* Local working space: We need space for the subgemm output (above) and\n+-     * the row sums.  */\n+-    size_t local_working_size() const {\n+-        return subgemm_output_size() + row_sum_size();\n+-    }\n+-\n+-    void set_child_arrays() {\n+-        if (working_space == nullptr || arrays_set == false)\n+-            return;\n+-\n+-        auto& g_array = this->_gemm_array;\n+-        /* Use the first part of our working space for the subgemm result, pass the operand details straight through. */\n+-        _subgemm->set_arrays(g_array._Aptr, g_array._lda, g_array._A_batch_stride, g_array._A_multi_stride,\n+-                             g_array._Bptr, g_array._ldb,                          g_array._B_multi_stride,\n+-                             reinterpret_cast<Tgemm *>(working_space), _args._Nsize, (_args._Nsize * _args._Msize), (_args._Nsize * _args._Msize * _args._nbatches),\n+-                             nullptr, 0);\n+-    }\n+-\n+-    void col_sums_pretransposed(const To *B, const int ldb, const int B_multi_stride) {\n+-        for (unsigned int multi=0; multi<_args._nmulti; multi++) {\n+-            compute_col_sums(_params, _args._Nsize, _args._Ksize, B + (multi * B_multi_stride), ldb, _col_sums + (multi * _args._Nsize), _args._Ksize, multi, 0);\n+-        }\n+-    }\n+-\n+-    void requantize_runtime(unsigned int threadid) {\n+-        unsigned int first_row = (threadid * _args._Msize) / _args._maxthreads;\n+-        unsigned int last_row = ((threadid+1) * _args._Msize) / _args._maxthreads;\n+-        auto& g_array = this->_gemm_array;\n+-\n+-        for (unsigned int multi=0; multi<_args._nmulti; multi++) {\n+-            for (unsigned int batch=0; batch<_args._nbatches; batch++) {\n+-                /* Compute row sums now */\n+-                compute_row_sums(_params, _args._Ksize, (last_row - first_row), g_array._Aptr + (multi * g_array._A_multi_stride) +\n+-                                    (batch * g_array._A_batch_stride) + (first_row * g_array._lda), g_array._lda, _row_sums +\n+-                                    (multi * _args._nbatches * _args._Msize) + (batch * _args._Msize) + first_row);\n+-                // If we don't care about negative values, call the version of this function that doesn't correct before shifting.\n+-                // 'c_offset' represents zero, so if the lowest possible quantized output value is the same or more than that we will not output negative numbers.\n+-                requantize_block_32(_params, _args._Nsize, (last_row - first_row), reinterpret_cast<Tgemm *>(working_space) +\n+-                                        (multi * (_args._Msize * _args._Nsize * _args._nbatches)) + (batch * (_args._Msize * _args._Nsize)) +\n+-                                        (first_row * _args._Nsize), _args._Nsize, g_array._Cptr + (multi * g_array._C_multi_stride) +\n+-                                        (batch * g_array._C_batch_stride) + (first_row * g_array._ldc), g_array._ldc, _row_sums +\n+-                                        (multi * _args._nbatches * _args._Msize) + (batch * _args._Msize) + first_row, _col_sums +\n+-                                        (multi * _args._Nsize), 0);\n+-            }\n+-        }\n+-    }\n+-\n+-\n+-public:\n+-    QuantizeWrapper(const QuantizeWrapper &) = delete;\n+-    QuantizeWrapper operator=(const QuantizeWrapper &) = delete;\n+-\n+-    QuantizeWrapper(const GemmArgs &args, const Requantize32 &qp) : _params(qp), _args(args), _barrier(args._maxthreads) {\n+-        GemmArgs newargs = GemmArgs(args._ci, args._Msize, args._Nsize, args._Ksize, args._Ksections, args._nbatches, args._nmulti, args._indirect_input, Activation(), args._maxthreads);\n+-        _subgemm = gemm<To, To, Tgemm>(newargs);\n+-\n+-        if (_subgemm == nullptr) {\n+-            return;\n+-        }\n+-    }\n+-\n+-    void set_arrays(const To *A, const int lda, const int A_batch_stride, const int A_multi_stride,\n+-                    const To *B, const int ldb, const int B_multi_stride,\n+-                          Tr *C, const int ldc, const int C_batch_stride, const int C_multi_stride,\n+-                    const Tr *bias, const int bias_multi_stride) override {\n+-        GemmCommon<To, To, Tr>::set_arrays(A, lda, A_batch_stride, A_multi_stride, B, ldb, B_multi_stride, C, ldc, C_batch_stride, C_multi_stride, bias, bias_multi_stride);\n+-\n+-        arrays_set = true;\n+-        set_child_arrays();\n+-    }\n+-\n+-    ndrange_t get_window_size() const override {\n+-        return { _subgemm->get_window_size() };\n+-    }\n+-\n+-    void set_nthreads(int nthreads) override {\n+-        _subgemm->set_nthreads(nthreads);\n+-        _barrier.set_nthreads(nthreads);\n+-        _args._maxthreads = nthreads;\n+-    }\n+-\n+-    // TODO: Make this actually stateless. This still uses the stateful\n+-    // execution data because it requires a workspace which would also need to\n+-    // be handled statelessly.\n+-    void execute_stateless(const ndcoord_t &work_range, const ndcoord_t &thread_locator, int threadid, GemmArrays<To, To, Tr> &) override {\n+-        _subgemm->execute(work_range, thread_locator, threadid);\n+-\n+-        _barrier.arrive_and_wait();\n+-\n+-        requantize_runtime(threadid);\n+-    }\n+-\n+-    void execute(const ndcoord_t &work_range, const ndcoord_t &thread_locator, int threadid) override {\n+-        execute_stateless(work_range, thread_locator, threadid, this->_gemm_array);\n+-    }\n+-\n+-    size_t get_working_size() const override {\n+-        return _subgemm->get_working_size() + local_working_size();\n+-    }\n+-\n+-    // Space arrangement:\n+-\n+-    // ptr\n+-    // V\n+-    // | subgemm output | row_sums | subgemm working space |\n+-    void set_working_space(void *space) override {\n+-        uintptr_t space_int = reinterpret_cast<uintptr_t>(space);\n+-\n+-        working_space = space;\n+-        _subgemm->set_working_space(reinterpret_cast<void *>(space_int + local_working_size()));\n+-\n+-        _row_sums = reinterpret_cast<int32_t *>(space_int + subgemm_output_size());\n+-\n+-        set_child_arrays();\n+-    }\n+-\n+-    bool B_is_pretransposed() const override {\n+-        /* We clear this flag if the subgemm isn't pretransposed, so just return its value */\n+-        return _subgemm->B_is_pretransposed();\n+-    }\n+-\n+-    bool B_pretranspose_required() const override {\n+-        return _subgemm->B_pretranspose_required();\n+-    }\n+-\n+-    size_t get_B_pretransposed_array_size() const override {\n+-        return _subgemm->get_B_pretransposed_array_size() + col_sum_size();\n+-    }\n+-\n+-    void requantize_bias(void *in_buffer, const To *B, const int ldb, const int B_multi_stride) override {\n+-        _col_sums = reinterpret_cast<int32_t *>(in_buffer);\n+-        col_sums_pretransposed(B, ldb, B_multi_stride);\n+-    }\n+-\n+-    void pretranspose_B_array(void *buffer, const To *B, const int ldb, const int B_multi_stride, bool transposed) override {\n+-        assert(!transposed);\n+-\n+-        uintptr_t buffer_int = reinterpret_cast<uintptr_t>(buffer);\n+-        _subgemm->pretranspose_B_array(reinterpret_cast<void *>(buffer_int + col_sum_size()), B, ldb, B_multi_stride, transposed);\n+-\n+-        requantize_bias(buffer, B, ldb, B_multi_stride);\n+-    }\n+-\n+-    void set_pretransposed_B_data(void *buffer) override {\n+-        uintptr_t buffer_int = reinterpret_cast<uintptr_t>(buffer);\n+-        _subgemm->set_pretransposed_B_data(reinterpret_cast<void *>(buffer_int + col_sum_size()));\n+-        _col_sums = reinterpret_cast<int32_t *>(buffer);\n+-    }\n+-\n+-    void set_quantized_bias(const int32_t *bias, size_t bias_multi_stride) override {\n+-        _params.bias = bias;\n+-        _params.bias_multi_stride = bias_multi_stride;\n+-    }\n+-\n+-    GemmConfig get_config() override {\n+-        GemmConfig c = _subgemm->get_config();\n+-\n+-        std::string n = \"quantize_wrapper[\";\n+-        n.append(c.filter);\n+-        n.append(\"]\");\n+-\n+-        c.method = GemmMethod::QUANTIZE_WRAPPER;\n+-        c.filter = n;\n+-\n+-        return c;\n+-    }\n+-\n+-    void update_quantization_parameters(const Requantize32 &re) override {\n+-        _params.bias = re.bias;\n+-        _params.a_offset = re.a_offset;\n+-        _params.b_offset = re.b_offset;\n+-        _params.c_offset = re.c_offset;\n+-        _params.per_layer_left_shift = re.per_layer_left_shift;\n+-        _params.per_layer_right_shift = re.per_layer_right_shift;\n+-        _params.per_layer_mul = re.per_layer_mul;\n+-        _params.per_channel_requant = re.per_channel_requant;\n+-        _params.per_channel_left_shifts = re.per_channel_left_shifts;\n+-        _params.per_channel_right_shifts = re.per_channel_right_shifts;\n+-        _params.per_channel_muls = re.per_channel_muls;\n+-        _params.minval = re.minval;\n+-        _params.maxval = re.maxval;\n+-    }\n+-};\n+-\n+-} // namespace arm_gemm\n+diff --git a/src/cpu/kernels/assembly/.clang-format b/src/cpu/kernels/assembly/.clang-format\n+new file mode 100644\n+index 000000000..bd90a154e\n+--- /dev/null\n++++ b/src/cpu/kernels/assembly/.clang-format\n+@@ -0,0 +1,25 @@\n++# Copyright (c) 2025 Arm Limited.\n++#\n++# SPDX-License-Identifier: MIT\n++#\n++# Permission is hereby granted, free of charge, to any person obtaining a copy\n++# of this software and associated documentation files (the \"Software\"), to\n++# deal in the Software without restriction, including without limitation the\n++# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n++# sell copies of the Software, and to permit persons to whom the Software is\n++# furnished to do so, subject to the following conditions:\n++#\n++# The above copyright notice and this permission notice shall be included in all\n++# copies or substantial portions of the Software.\n++#\n++# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n++# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n++# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n++# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n++# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n++# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n++# SOFTWARE.\n++---\n++# Disabling clang-format for this directory to reduce the diff-noise when\n++# porting changes from arm_gemm\n++DisableFormat: true\n+diff --git a/src/cpu/kernels/assembly/CpuGemmAssemblyWrapperKernel.h b/src/cpu/kernels/assembly/CpuGemmAssemblyWrapperKernel.h\n+index c3a1799e1..219d77a57 100644\n+--- a/src/cpu/kernels/assembly/CpuGemmAssemblyWrapperKernel.h\n++++ b/src/cpu/kernels/assembly/CpuGemmAssemblyWrapperKernel.h\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2018-2022, 2024 Arm Limited.\n++ * Copyright (c) 2018-2022, 2024-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -104,10 +104,11 @@ public:\n+         ARM_COMPUTE_ERROR_ON_NULLPTR((reinterpret_cast<void *>(_kernel)));\n+         ARM_COMPUTE_ERROR_ON_UNCONFIGURED_KERNEL(this);\n+ \n+-        const auto *Aptr = reinterpret_cast<const TypeInput *>(tensors.get_tensor(ACL_SRC_0)->buffer());\n+-        const auto *Bptr = reinterpret_cast<const TypeWeight *>(tensors.get_tensor(ACL_SRC_1)->buffer());\n+-        const auto *bias = reinterpret_cast<const TypeOutput *>(tensors.get_tensor(ACL_SRC_2)->buffer());\n+-        auto       *Cptr = reinterpret_cast<TypeOutput *>(tensors.get_tensor(ACL_DST)->buffer());\n++        const auto *Aptr      = reinterpret_cast<const TypeInput *>(tensors.get_tensor(ACL_SRC_0)->buffer());\n++        const auto *Bptr      = reinterpret_cast<const TypeWeight *>(tensors.get_tensor(ACL_SRC_1)->buffer());\n++        const auto *bias      = reinterpret_cast<const TypeOutput *>(tensors.get_tensor(ACL_SRC_2)->buffer());\n++        void       *workspace = tensors.get_tensor(ACL_SRC_3)->buffer();\n++        auto       *Cptr      = reinterpret_cast<TypeOutput *>(tensors.get_tensor(ACL_DST)->buffer());\n+ \n+         ARM_COMPUTE_ERROR_ON_NULLPTR(Aptr, Cptr);\n+ \n+@@ -119,6 +120,7 @@ public:\n+         ga._Bptr = Bptr;\n+         ga._bias = bias;\n+         ga._Cptr = Cptr;\n++        ga.set_working_space(workspace);\n+ \n+         auto win = arm_gemm::to_ndcoord(window);\n+ \n+diff --git a/src/cpu/kernels/assembly/arm_gemm.hpp b/src/cpu/kernels/assembly/arm_gemm.hpp\n+index e65bc00a0..ea8566652 100644\n+--- a/src/cpu/kernels/assembly/arm_gemm.hpp\n++++ b/src/cpu/kernels/assembly/arm_gemm.hpp\n+@@ -44,7 +44,6 @@ enum class GemmMethod\n+     GEMM_NATIVE,\n+     GEMM_HYBRID,\n+     GEMM_INTERLEAVED,\n+-    QUANTIZE_WRAPPER,\n+     GEMM_HYBRID_QUANTIZED\n+ };\n+ \n+diff --git a/src/cpu/kernels/assembly/gemm_arrays.hpp b/src/cpu/kernels/assembly/gemm_arrays.hpp\n+index 2d4f7e1a0..0b4d79462 100644\n+--- a/src/cpu/kernels/assembly/gemm_arrays.hpp\n++++ b/src/cpu/kernels/assembly/gemm_arrays.hpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2024 Arm Limited.\n++ * Copyright (c) 2024-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -52,6 +52,8 @@ struct IGemmArrays\n+                                     const void *bias,\n+                                     const int   bias_multi_stride) = 0; /* no row or batch stride needed */\n+ \n++    virtual void set_working_space(void *workspace) = 0;\n++\n+     virtual ~IGemmArrays() = default;\n+ };\n+ \n+@@ -71,6 +73,7 @@ struct GemmArrays : public IGemmArrays\n+     int       _C_multi_stride    = 0;\n+     const Tr *_bias              = nullptr;\n+     int       _bias_multi_stride = 0;\n++    void     *_workspace         = nullptr;\n+ \n+     GemmArrays() = default;\n+ \n+@@ -159,6 +162,11 @@ struct GemmArrays : public IGemmArrays\n+                    B_multi_stride, static_cast<Tr *>(C), ldc, C_batch_stride, C_multi_stride,\n+                    static_cast<const Tr *>(bias), bias_multi_stride);\n+     }\n++\n++    void set_working_space(void *workspace) override\n++    {\n++        _workspace = workspace;\n++    }\n+ };\n+ } // namespace arm_gemm\n+ \n+diff --git a/src/cpu/kernels/assembly/gemm_common.hpp b/src/cpu/kernels/assembly/gemm_common.hpp\n+index ce1873a49..c26c7a59b 100644\n+--- a/src/cpu/kernels/assembly/gemm_common.hpp\n++++ b/src/cpu/kernels/assembly/gemm_common.hpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2017-2021,2023-2024 Arm Limited.\n++ * Copyright (c) 2017-2021,2023-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -201,21 +201,21 @@ template <typename To, typename Tw, typename Tr>\n+ class GemmCommon : public IGemmCommon\n+ {\n+ protected:\n+-    GemmArrays<To, Tw, Tr> _gemm_array{};\n++    GemmArrays<To, Tw, Tr> _gemm_arrays{};\n+ \n+ public:\n+-    /* Pass in the pointers to the arrays to be operated on and their\n+-     * strides (templated version with appropriate types). */\n+     void set_gemm_arrays(GemmArrays<To, Tw, Tr> &ga)\n+     {\n+-        _gemm_array = ga;\n++        _gemm_arrays = ga;\n+     }\n+ \n+     const GemmArrays<To, Tw, Tr> &get_gemm_arrays() const\n+     {\n+-        return _gemm_array;\n++        return _gemm_arrays;\n+     }\n+ \n++    /* Pass in the pointers to the arrays to be operated on and their\n++     * strides (templated version with appropriate types). */\n+     virtual void set_arrays(const To                                     *A,\n+                             const int                                     lda,\n+                             const int                                     A_batch_stride,\n+@@ -230,8 +230,8 @@ public:\n+                             const Tr                                     *bias,\n+                             /* no row or batch stride needed */ const int bias_multi_stride)\n+     {\n+-        _gemm_array.set_arrays(A, lda, A_batch_stride, A_multi_stride, B, ldb, B_multi_stride, C, ldc, C_batch_stride,\n+-                               C_multi_stride, bias, bias_multi_stride);\n++        _gemm_arrays.set_arrays(A, lda, A_batch_stride, A_multi_stride, B, ldb, B_multi_stride, C, ldc, C_batch_stride,\n++                                C_multi_stride, bias, bias_multi_stride);\n+     }\n+ \n+     /* Implementation of the void * overload which casts its arguments to the appropriate type. */\n+diff --git a/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp b/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n+index ec2039207..eaceff52e 100644\n+--- a/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n++++ b/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n+@@ -29,7 +29,6 @@\n+ \n+ #include \"src/core/CPP/Validate.h\"\n+ #include \"src/core/helpers/MemoryHelpers.h\"\n+-#include \"src/core/NEON/kernels/arm_gemm/utils.hpp\"\n+ #include \"src/core/utils/AssemblyUtils.h\"\n+ #include \"src/cpu/kernels/assembly/arm_gemm.hpp\"\n+ #include \"src/cpu/kernels/assembly/CpuGemmAssemblyWrapperKernel.h\"\n+@@ -231,11 +230,6 @@ public:\n+         _is_prepared = is_prepared;\n+     }\n+ \n+-    bool has_stateless_impl() const override\n+-    {\n+-        return _gemm_kernel_asm->get_working_size() == 0;\n+-    }\n+-\n+ private:\n+     enum AuxTensorIdx\n+     {\n+@@ -806,8 +800,11 @@ void Fallback<TypeInput, TypeWeight, TypeOutput, OutputStage>::run(ITensorPack &\n+     out_tensor.allocator()->init(*(d->info()));\n+     out_tensor.allocator()->import_memory(out_ptr);\n+ \n+-    ITensorPack gemm_pack{\n+-        {ACL_SRC_0, &in0_tensor}, {ACL_SRC_1, &in1_tensor}, {ACL_SRC_2, &bias_tensor}, {ACL_DST, &out_tensor}};\n++    ITensorPack gemm_pack{{ACL_SRC_0, &in0_tensor},\n++                          {ACL_SRC_1, &in1_tensor},\n++                          {ACL_SRC_2, &bias_tensor},\n++                          {ACL_SRC_3, workspace.get()},\n++                          {ACL_DST, &out_tensor}};\n+ \n+     // Set gemm parameters\n+     _gemm_kernel_asm->set_arrays(in0_ptr, lda, batch_stride_a, multi_stride_a, in1_ptr, ldb, multi_stride_b, out_ptr,\n+@@ -1037,11 +1034,6 @@ Status CpuGemmAssemblyDispatch::has_opt_impl(arm_compute::WeightFormat &expected\n+     return Status{};\n+ }\n+ \n+-bool CpuGemmAssemblyDispatch::has_stateless_impl() const\n+-{\n+-    return _arm_gemm->has_stateless_impl();\n+-}\n+-\n+ Status CpuGemmAssemblyDispatch::validate(\n+     const ITensorInfo *a, const ITensorInfo *b, const ITensorInfo *c, const ITensorInfo *d, const AsmGemmInfo &info)\n+ {\n+diff --git a/src/cpu/operators/internal/CpuGemmAssemblyDispatch.h b/src/cpu/operators/internal/CpuGemmAssemblyDispatch.h\n+index 84420f776..b45ce664b 100644\n+--- a/src/cpu/operators/internal/CpuGemmAssemblyDispatch.h\n++++ b/src/cpu/operators/internal/CpuGemmAssemblyDispatch.h\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2018-2024 Arm Limited.\n++ * Copyright (c) 2018-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -28,7 +28,6 @@\n+ \n+ #include \"src/core/common/Macros.h\"\n+ #include \"src/cpu/ICpuOperator.h\"\n+-#include \"src/cpu/kernels/assembly/arm_gemm.hpp\"\n+ \n+ namespace arm_compute\n+ {\n+@@ -93,7 +92,6 @@ public:\n+                                                                                 const bool,\n+                                                                                 const bool) = 0;\n+         virtual ~IFallback()                                                                = default;\n+-        virtual bool has_stateless_impl() const                                             = 0;\n+     };\n+ \n+ public:\n+@@ -172,17 +170,6 @@ public:\n+                                const ITensorInfo         *d,\n+                                const AsmGemmInfo         &info);\n+ \n+-    /** Checks if a stateless implementation is supported\n+-     *\n+-     * The arm_gemm kernels that have been made stateless so far are those that\n+-     * do not require any working space. Once all kernels have been made\n+-     * stateless we can deprecate it by always returning true, and eventually\n+-     * removing it completely\n+-     *\n+-     * @return True if stateless execution is supported else false\n+-     */\n+-    bool has_stateless_impl() const;\n+-\n+     /** Checks if activation is supported by the gemm assembly dispatcher\n+      *\n+      * @param[in] activation Activation to check\n+diff --git a/src/runtime/IScheduler.cpp b/src/runtime/IScheduler.cpp\n+index 9fa815fbd..d0d226d9f 100644\n+--- a/src/runtime/IScheduler.cpp\n++++ b/src/runtime/IScheduler.cpp\n+@@ -90,7 +90,7 @@ void IScheduler::schedule_common(ICPPKernel *kernel, const Hints &hints, const W\n+             for (unsigned int mi = 0; mi != m_threads; ++mi)\n+             {\n+                 workloads.push_back(\n+-                    [ni, mi, m_threads, n_threads, &max_window, &kernel](const ThreadInfo &info)\n++                    [ni, mi, m_threads, n_threads, &max_window, &kernel, &tensors](const ThreadInfo &info)\n+                     {\n+                         //narrow the window to our mi-ni workload\n+                         Window win = max_window.split_window(Window::DimX, mi, m_threads)\n+@@ -104,7 +104,14 @@ void IScheduler::schedule_common(ICPPKernel *kernel, const Hints &hints, const W\n+ \n+                         thread_locator.validate();\n+ \n+-                        kernel->run_nd(win, info, thread_locator);\n++                        if (tensors.empty())\n++                        {\n++                            kernel->run_nd(win, info, thread_locator);\n++                        }\n++                        else\n++                        {\n++                            kernel->run_op(tensors, win, info);\n++                        }\n+                     });\n+             }\n+         }\n+diff --git a/src/runtime/experimental/low_level/CpuGemmAssemblyDispatch.cpp b/src/runtime/experimental/low_level/CpuGemmAssemblyDispatch.cpp\n+index 6021d1330..93b65e31d 100644\n+--- a/src/runtime/experimental/low_level/CpuGemmAssemblyDispatch.cpp\n++++ b/src/runtime/experimental/low_level/CpuGemmAssemblyDispatch.cpp\n+@@ -1,5 +1,5 @@\n+ /*\n+- * Copyright (c) 2024 Arm Limited.\n++ * Copyright (c) 2024-2025 Arm Limited.\n+  *\n+  * SPDX-License-Identifier: MIT\n+  *\n+@@ -122,7 +122,7 @@ bool CpuGemmAssemblyDispatch::has_stateless_impl() const\n+ {\n+     ARM_COMPUTE_ERROR_ON_MSG(!is_configured(), \"calling has_stateless_impl() on unconfigured CpuGemmAssemblyDispatch\");\n+ \n+-    return _impl->cpu_gemm_assembly_dispatch->has_stateless_impl();\n++    return true;\n+ }\n+ \n+ bool CpuGemmAssemblyDispatch::is_activation_supported(const ActivationLayerInfo &activation)\n\\ No newline at end of file"
        },
        {
            "sha": "9ebf6b71fdb44a38fa54169c0ad956d861cbbe99",
            "filename": "third_party/xla/third_party/compute_library/acl_thread_local_scheduler.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 98,
            "changes": 98,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Facl_thread_local_scheduler.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Facl_thread_local_scheduler.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Facl_thread_local_scheduler.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,98 +0,0 @@\n-diff --git a/arm_compute/runtime/Scheduler.h b/arm_compute/runtime/Scheduler.h\n-index 9e8add1f9..cf5e2bf4c 100644\n---- a/arm_compute/runtime/Scheduler.h\n-+++ b/arm_compute/runtime/Scheduler.h\n-@@ -75,7 +75,7 @@ public:\n-\n- private:\n-     static Type                        _scheduler_type;\n--    static std::shared_ptr<IScheduler> _custom_scheduler;\n-+    static thread_local std::shared_ptr<IScheduler> _custom_scheduler;\n-     static std::map<Type, std::unique_ptr<IScheduler>> _schedulers;\n-\n-     Scheduler();\n-diff --git a/src/cpu/operators/CpuDepthwiseConv2dAssemblyDispatch.cpp b/src/cpu/operators/CpuDepthwiseConv2dAssemblyDispatch.cpp\n-index a5b9eca56..d1ab19397 100644\n---- a/src/cpu/operators/CpuDepthwiseConv2dAssemblyDispatch.cpp\n-+++ b/src/cpu/operators/CpuDepthwiseConv2dAssemblyDispatch.cpp\n-@@ -60,8 +60,8 @@ void CpuDepthwiseConv2dAssemblyDispatch::configure(const ITensorInfo     *src,\n-                                                    const ConvolutionInfo &info)\n- {\n-     ARM_COMPUTE_LOG_PARAMS(src, weights, bias, dst, info);\n--    const CPUInfo     &ci          = NEScheduler::get().cpu_info();\n--    const unsigned int num_threads = NEScheduler::get().num_threads();\n-+    const CPUInfo     &ci          = CPUInfo::get();\n-+    const unsigned int num_threads = CPUInfo::get().get_cpu_num();\n-     _pImpl->is_prepared            = false;\n-     _pImpl->are_weights_const      = weights->are_values_constant();\n-\n-diff --git a/src/cpu/operators/CpuPool2d.cpp b/src/cpu/operators/CpuPool2d.cpp\n-index 722cd36ee..03aef1632 100644\n---- a/src/cpu/operators/CpuPool2d.cpp\n-+++ b/src/cpu/operators/CpuPool2d.cpp\n-@@ -66,8 +66,8 @@ void CpuPool2d::configure(ITensorInfo *src, ITensorInfo *dst, const PoolingLayer\n-\n-     if(run_optimised)\n-     {\n--        const CPUInfo     &ci          = NEScheduler::get().cpu_info();\n--        const unsigned int num_threads = NEScheduler::get().num_threads();\n-+        const CPUInfo     &ci          = CPUInfo::get();\n-+        const unsigned int num_threads = CPUInfo::get().get_cpu_num();\n-\n-         auto pooling_wrapper = std::make_unique<kernels::CpuPool2dAssemblyWrapperKernel>();\n-         ARM_COMPUTE_ERROR_ON(pooling_wrapper == nullptr);\n-diff --git a/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp b/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n- *******************************************************************************\n- Copyright 2023 Arm Limited and affiliates.\n- SPDX-License-Identifier: Apache-2.0\n-\n- Licensed under the Apache License, Version 2.0 (the \"License\");\n- you may not use this file except in compliance with the License.\n- You may obtain a copy of the License at\n-\n-     http://www.apache.org/licenses/LICENSE-2.0\n-\n- Unless required by applicable law or agreed to in writing, software\n- distributed under the License is distributed on an \"AS IS\" BASIS,\n- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- See the License for the specific language governing permissions and\n- limitations under the License.\n- *******************************************************************************\n-index 9c8563140..f7771945a 100644\n---- a/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n-+++ b/src/cpu/operators/internal/CpuGemmAssemblyDispatch.cpp\n-@@ -623,8 +623,8 @@ void create_arm_gemm(std::unique_ptr<CpuGemmAssemblyDispatch::IFallback> &arm_ge\n-                      arm_gemm::Activation activation, const AsmGemmInfo &info)\n- {\n-     Params         p           = extract_parameters(a, b, d, info);\n--    const CPUInfo &ci          = NEScheduler::get().cpu_info();\n--    unsigned int   num_threads = NEScheduler::get().num_threads();\n-+    const CPUInfo &ci          = CPUInfo::get();\n-+    unsigned int   num_threads = CPUInfo::get().get_cpu_num();\n-\n-     arm_gemm::GemmConfig cfg;\n-     cfg.weight_format = assembly_utils::map_to_arm_gemm_weight_format(info.weight_format);\n-@@ -696,8 +696,8 @@ Status CpuGemmAssemblyDispatch::has_opt_impl(arm_compute::WeightFormat &expected\n-     ARM_COMPUTE_UNUSED(c);\n-     arm_gemm::Activation act         = assembly_utils::map_to_arm_gemm_activation(info.activation_info);\n-     Params               p           = extract_parameters(a, b, d, info);\n--    const CPUInfo       &ci          = NEScheduler::get().cpu_info();\n--    unsigned int         num_threads = NEScheduler::get().num_threads();\n-+    const CPUInfo       &ci          = CPUInfo::get();\n-+    unsigned int         num_threads = CPUInfo::get().get_cpu_num();\n-     arm_gemm::GemmConfig cfg;\n-     cfg.weight_format                           = assembly_utils::map_to_arm_gemm_weight_format(info.weight_format);\n-     arm_gemm::WeightFormat arm_gemm_expected_wf = assembly_utils::map_to_arm_gemm_weight_format(expected_weight_format);\n-diff --git a/src/runtime/Scheduler.cpp b/src/runtime/Scheduler.cpp\n-index 0713b9a2a..f15ac2e22 100644\n---- a/src/runtime/Scheduler.cpp\n-+++ b/src/runtime/Scheduler.cpp\n-@@ -47,7 +47,7 @@ Scheduler::Type Scheduler::_scheduler_type = Scheduler::Type::CPP;\n- Scheduler::Type Scheduler::_scheduler_type = Scheduler::Type::ST;\n- #endif /* ARM_COMPUTE_*_SCHEDULER */\n-\n--std::shared_ptr<IScheduler> Scheduler::_custom_scheduler = nullptr;\n-+thread_local std::shared_ptr<IScheduler> Scheduler::_custom_scheduler = nullptr;\n-\n- namespace\n- {"
        },
        {
            "sha": "5f03fdcc59d7bc4cf7681f523c02a302e451d222",
            "filename": "third_party/xla/third_party/compute_library/exclude_omp_scheduler.patch",
            "status": "modified",
            "additions": 21,
            "deletions": 7,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Fexclude_omp_scheduler.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Fexclude_omp_scheduler.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fcompute_library%2Fexclude_omp_scheduler.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1,23 +1,37 @@\n+# Copyright 2025 The OpenXLA Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n diff --git a/src/BUILD.bazel b/src/BUILD.bazel\n-index bf71e534e2..22377f1a32 100644\n+index 547c98576..a31301230 100644\n --- a/src/BUILD.bazel\n +++ b/src/BUILD.bazel\n-@@ -971,7 +971,6 @@ filegroup(\n+@@ -1029,7 +1029,6 @@ filegroup(\n  \t\"runtime/NEON/functions/NETranspose.cpp\",\n  \t\"runtime/NEON/functions/NEUnstack.cpp\",\n  \t\"runtime/NEON/functions/NEWinogradConvolutionLayer.cpp\",\n -\t\"runtime/OMP/OMPScheduler.cpp\",\n  \t\"runtime/OffsetLifetimeManager.cpp\",\n  \t\"runtime/OffsetMemoryPool.cpp\",\n  \t\"runtime/OperatorTensor.cpp\",\n-@@ -984,6 +983,10 @@ filegroup(\n- \t\"runtime/Tensor.cpp\",\n- \t\"runtime/TensorAllocator.cpp\",\n- \t\"runtime/Utils.cpp\"]  +\n+@@ -1058,6 +1057,10 @@ filegroup(\n+ \t\"runtime/experimental/operators/CpuSub.cpp\",\n+ \t\"runtime/experimental/operators/CpuTranspose.cpp\",\n+ \t\"runtime/experimental/operators/CpuWinogradConv2d.cpp\"]  +\n +    select({\n +        \"//:openmp_flag\": [\"runtime/OMP/OMPScheduler.cpp\"],\n +        \"//conditions:default\": [],\n +    }) +\n      glob([\"**/*.h\",\n      \"**/*.hpp\",\n-     \"**/*.inl\"]),\n+     \"**/*.inl\"]),\n\\ No newline at end of file"
        },
        {
            "sha": "cc558415f2b3d22e6e29586e495b47e8efc9be5a",
            "filename": "third_party/xla/third_party/fmt/BUILD",
            "status": "added",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Ffmt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Ffmt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ffmt%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1 @@\n+# copybara:uncomment package(default_applicable_licenses = [\"//third_party/tensorflow:license\"])"
        },
        {
            "sha": "3b470ed4383742e53a774b2fdf671fc9fdd22d28",
            "filename": "third_party/xla/third_party/fmt/fmt.BUILD",
            "status": "added",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Ffmt%2Ffmt.BUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Ffmt%2Ffmt.BUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ffmt%2Ffmt.BUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,30 @@\n+# fmt is an open-source formatting library providing a fast and safe alternative to C stdio and C++ iostreams.\n+licenses([\"notice\"])  # MIT\n+\n+exports_files([\"LICENSE\"])\n+\n+cc_library(\n+    name = \"fmt\",\n+    hdrs = glob([\"include/fmt/*.h\"]),\n+    copts = [\"-fexceptions\"],\n+    defines = [\n+        \"FMT_HEADER_ONLY=1\",\n+        \"FMT_USE_USER_DEFINED_LITERALS=0\",\n+    ],\n+    features = [\"-use_header_modules\"],\n+    includes = [\"include\"],\n+    visibility = [\"//visibility:public\"],\n+)\n+\n+cc_test(\n+    name = \"fmt_smoke_test\",\n+    srcs = [\n+        \"test/assert-test.cc\",\n+        \"test/header-only-test.cc\",\n+        \"test/test-main.cc\",\n+    ],\n+    deps = [\n+        \":fmt\",\n+        \"@com_google_googletest//:gtest\",\n+    ],\n+)"
        },
        {
            "sha": "f0038631b7205028936e08193f0c0f87081779ae",
            "filename": "third_party/xla/third_party/fmt/workspace.bzl",
            "status": "added",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Ffmt%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Ffmt%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ffmt%2Fworkspace.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,17 @@\n+\"\"\"Provides the repository macro to import fmt.\"\"\"\n+\n+load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n+\n+def repo():\n+    \"\"\"Imports fmt.\"\"\"\n+\n+    FMT_VERSION = \"8.1.1\"\n+    FMT_SHA256 = \"3d794d3cf67633b34b2771eb9f073bde87e846e0d395d254df7b211ef1ec7346\"\n+\n+    tf_http_archive(\n+        name = \"fmt\",\n+        sha256 = FMT_SHA256,\n+        strip_prefix = \"fmt-{version}\".format(version = FMT_VERSION),\n+        urls = tf_mirror_urls(\"https://github.com/fmtlib/fmt/archive/refs/tags/{version}.tar.gz\".format(version = FMT_VERSION)),\n+        build_file = \"//third_party/fmt:fmt.BUILD\",\n+    )"
        },
        {
            "sha": "cc558415f2b3d22e6e29586e495b47e8efc9be5a",
            "filename": "third_party/xla/third_party/kokkos/BUILD",
            "status": "added",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fkokkos%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fkokkos%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fkokkos%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1 @@\n+# copybara:uncomment package(default_applicable_licenses = [\"//third_party/tensorflow:license\"])"
        },
        {
            "sha": "ca1f7128e9a144c1911789b07609bc0cb85f8a7a",
            "filename": "third_party/xla/third_party/kokkos/kokkos.BUILD",
            "status": "added",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fkokkos%2Fkokkos.BUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fkokkos%2Fkokkos.BUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fkokkos%2Fkokkos.BUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,21 @@\n+# Kokkos C++ Performance Portability Programming Ecosystem: The Programming Model - Parallel Execution and Memory Abstraction\n+licenses([\"notice\"])  # Apache 2.0\n+\n+exports_files([\"LICENSE\"])\n+\n+cc_library(\n+    name = \"mdspan\",\n+    hdrs = glob([\"tpls/mdspan/include/**/*.hpp\"]),\n+    copts = [\"-fexceptions\"],\n+    includes = [\"tpls/mdspan/include\"],\n+    visibility = [\"//visibility:public\"],\n+)\n+\n+cc_test(\n+    name = \"smoke_test\",\n+    srcs = [\"smoke_test.cc\"],\n+    copts = [\"-fexceptions\"],\n+    deps = [\n+        \":mdspan\",\n+    ],\n+)"
        },
        {
            "sha": "3e1bed2974d7a6a7bb9db39949b13111c12508e0",
            "filename": "third_party/xla/third_party/kokkos/smoke_test.cc.patch",
            "status": "added",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fkokkos%2Fsmoke_test.cc.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fkokkos%2Fsmoke_test.cc.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fkokkos%2Fsmoke_test.cc.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,32 @@\n+--- /dev/null\t2025-08-20 16:29:02.164000374 +0000\n++++ b/smoke_test.cc\t2025-08-20 21:02:15.000000000 +0000\n+@@ -0,0 +1,29 @@\n++#include <iostream>\n++#include <mdspan/mdspan.hpp>\n++\n++int main() {\n++  constexpr size_t N = 3, M = 4;\n++\n++  // Flattened storage\n++  double data[N * M] = {1.0, 2.0, 3.0, 4.0,  5.0,  6.0,\n++                        7.0, 8.0, 9.0, 10.0, 11.0, 12.0};\n++\n++  // Create mdspan over flat data\n++  Kokkos::mdspan<double, Kokkos::extents<size_t, N, M>> view(data);\n++\n++  // Access elements\n++  std::cout << \"Original array via mdspan:\\n\";\n++  for (size_t i = 0; i < N; ++i) {\n++    for (size_t j = 0; j < M; ++j) {\n++      std::cout << view(i, j) << \" \";\n++    }\n++    std::cout << \"\\n\";\n++  }\n++\n++  // Modify a value\n++  view(1, 2) = 42.0;\n++  std::cout << \"\\nAfter modification:\\n\";\n++  std::cout << \"view(1,2) = \" << view(1, 2) << \"\\n\";\n++\n++  return 0;\n++}"
        },
        {
            "sha": "7929cc751ceb18b2e9de10f31a7f889a8389e2e5",
            "filename": "third_party/xla/third_party/kokkos/workspace.bzl",
            "status": "added",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fkokkos%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fkokkos%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fkokkos%2Fworkspace.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,18 @@\n+\"\"\"Provides the repository macro to import kokkos.\"\"\"\n+\n+load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n+\n+def repo():\n+    \"\"\"Imports kokkos.\"\"\"\n+\n+    KOKKOS_VERSION = \"4.4.01\"\n+    KOKKOS_SHA256 = \"3f7096d17eaaa4004c7497ac082bf1ae3ff47b5104149e54af021a89414c3682\"\n+\n+    tf_http_archive(\n+        name = \"kokkos\",\n+        sha256 = KOKKOS_SHA256,\n+        strip_prefix = \"kokkos-{version}\".format(version = KOKKOS_VERSION),\n+        urls = tf_mirror_urls(\"https://github.com/kokkos/kokkos/archive/refs/tags/{version}.tar.gz\".format(version = KOKKOS_VERSION)),\n+        build_file = \"//third_party/kokkos:kokkos.BUILD\",\n+        patch_file = [\"//third_party/kokkos:smoke_test.cc.patch\"],\n+    )"
        },
        {
            "sha": "651f0a4189010d29f532946049de8633e70127e9",
            "filename": "third_party/xla/third_party/mkl_dnn/mkldnn_acl.BUILD",
            "status": "modified",
            "additions": 26,
            "deletions": 60,
            "changes": 86,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fmkldnn_acl.BUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fmkldnn_acl.BUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fmkldnn_acl.BUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -9,13 +9,6 @@ _DNNL_COPTS_THREADPOOL = [\n     \"-UUSE_CBLAS\",\n ]\n \n-_DNNL_COPTS_OMP = [\n-    \"-fopenmp\",\n-    \"-fexceptions\",\n-    \"-UUSE_MKL\",\n-    \"-UUSE_CBLAS\",\n-]\n-\n _DNNL_RUNTIME_THREADPOOL = {\n     \"#cmakedefine DNNL_CPU_THREADING_RUNTIME DNNL_RUNTIME_${DNNL_CPU_THREADING_RUNTIME}\": \"#define DNNL_CPU_THREADING_RUNTIME DNNL_RUNTIME_THREADPOOL\",\n     \"#cmakedefine DNNL_CPU_RUNTIME DNNL_RUNTIME_${DNNL_CPU_RUNTIME}\": \"#define DNNL_CPU_RUNTIME DNNL_RUNTIME_THREADPOOL\",\n@@ -63,61 +56,24 @@ _DNNL_RUNTIME_THREADPOOL = {\n     \"#cmakedefine01 BUILD_XEHPG\": \"#define BUILD_XEHPG 0\",\n     \"#cmakedefine01 BUILD_XEHPC\": \"#define BUILD_XEHPC 0\",\n     \"#cmakedefine01 BUILD_XEHP\": \"#define BUILD_XEHP 0\",\n-}\n-\n-_DNNL_RUNTIME_OMP = {\n-    \"#cmakedefine DNNL_CPU_THREADING_RUNTIME DNNL_RUNTIME_${DNNL_CPU_THREADING_RUNTIME}\": \"#define DNNL_CPU_THREADING_RUNTIME DNNL_RUNTIME_OMP\",\n-    \"#cmakedefine DNNL_CPU_RUNTIME DNNL_RUNTIME_${DNNL_CPU_RUNTIME}\": \"#define DNNL_CPU_RUNTIME DNNL_RUNTIME_OMP\",\n-    \"#cmakedefine DNNL_GPU_RUNTIME DNNL_RUNTIME_${DNNL_GPU_RUNTIME}\": \"#define DNNL_GPU_RUNTIME DNNL_RUNTIME_NONE\",\n-    \"#cmakedefine DNNL_USE_RT_OBJECTS_IN_PRIMITIVE_CACHE\": \"#undef DNNL_USE_RT_OBJECTS_IN_PRIMITIVE_CACHE\",\n-    \"#cmakedefine DNNL_WITH_SYCL\": \"#undef DNNL_WITH_SYCL\",\n-    \"#cmakedefine DNNL_WITH_LEVEL_ZERO\": \"#undef DNNL_WITH_LEVEL_ZERO\",\n-    \"#cmakedefine DNNL_SYCL_CUDA\": \"#undef DNNL_SYCL_CUDA\",\n-    \"#cmakedefine DNNL_SYCL_HIP\": \"#undef DNNL_SYCL_HIP\",\n-    \"#cmakedefine DNNL_ENABLE_STACK_CHECKER\": \"#undef DNNL_ENABLE_STACK_CHECKER\",\n-    \"#cmakedefine DNNL_EXPERIMENTAL\": \"#undef DNNL_EXPERIMENTAL\",\n-    \"#cmakedefine ONEDNN_BUILD_GRAPH\": \"#define ONEDNN_BUILD_GRAPH\",\n-    \"#cmakedefine01 BUILD_TRAINING\": \"#define BUILD_TRAINING 1\",\n-    \"#cmakedefine01 BUILD_INFERENCE\": \"#define BUILD_INFERENCE 0\",\n-    \"#cmakedefine01 BUILD_PRIMITIVE_ALL\": \"#define BUILD_PRIMITIVE_ALL 1\",\n-    \"#cmakedefine01 BUILD_BATCH_NORMALIZATION\": \"#define BUILD_BATCH_NORMALIZATION 0\",\n-    \"#cmakedefine01 BUILD_BINARY\": \"#define BUILD_BINARY 0\",\n-    \"#cmakedefine01 BUILD_CONCAT\": \"#define BUILD_CONCAT 0\",\n-    \"#cmakedefine01 BUILD_CONVOLUTION\": \"#define BUILD_CONVOLUTION 0\",\n-    \"#cmakedefine01 BUILD_DECONVOLUTION\": \"#define BUILD_DECONVOLUTION 0\",\n-    \"#cmakedefine01 BUILD_ELTWISE\": \"#define BUILD_ELTWISE 0\",\n-    \"#cmakedefine01 BUILD_INNER_PRODUCT\": \"#define BUILD_INNER_PRODUCT 0\",\n-    \"#cmakedefine01 BUILD_LAYER_NORMALIZATION\": \"#define BUILD_LAYER_NORMALIZATION 0\",\n-    \"#cmakedefine01 BUILD_LRN\": \"#define BUILD_LRN 0\",\n-    \"#cmakedefine01 BUILD_MATMUL\": \"#define BUILD_MATMUL 0\",\n-    \"#cmakedefine01 BUILD_POOLING\": \"#define BUILD_POOLING 0\",\n-    \"#cmakedefine01 BUILD_PRELU\": \"#define BUILD_PRELU 0\",\n-    \"#cmakedefine01 BUILD_REDUCTION\": \"#define BUILD_REDUCTION 0\",\n-    \"#cmakedefine01 BUILD_REORDER\": \"#define BUILD_REORDER 0\",\n-    \"#cmakedefine01 BUILD_RESAMPLING\": \"#define BUILD_RESAMPLING 0\",\n-    \"#cmakedefine01 BUILD_RNN\": \"#define BUILD_RNN 0\",\n-    \"#cmakedefine01 BUILD_SHUFFLE\": \"#define BUILD_SHUFFLE 0\",\n-    \"#cmakedefine01 BUILD_SOFTMAX\": \"#define BUILD_SOFTMAX 0\",\n-    \"#cmakedefine01 BUILD_SUM\": \"#define BUILD_SUM 0\",\n-    \"#cmakedefine01 BUILD_PRIMITIVE_CPU_ISA_ALL\": \"#define BUILD_PRIMITIVE_CPU_ISA_ALL 0\",\n-    \"#cmakedefine01 BUILD_SSE41\": \"#define BUILD_SSE41 0\",\n-    \"#cmakedefine01 BUILD_AVX2\": \"#define BUILD_AVX2 0\",\n-    \"#cmakedefine01 BUILD_AVX512\": \"#define BUILD_AVX512 0\",\n-    \"#cmakedefine01 BUILD_AMX\": \"#define BUILD_AMX 0\",\n-    \"#cmakedefine01 BUILD_PRIMITIVE_GPU_ISA_ALL\": \"#define BUILD_PRIMITIVE_GPU_ISA_ALL 0\",\n-    \"#cmakedefine01 BUILD_GEN9\": \"#define BUILD_GEN9 0\",\n-    \"#cmakedefine01 BUILD_GEN11\": \"#define BUILD_GEN11 0\",\n-    \"#cmakedefine01 BUILD_XELP\": \"#define BUILD_XELP 0\",\n-    \"#cmakedefine01 BUILD_XEHPG\": \"#define BUILD_XEHPG 0\",\n-    \"#cmakedefine01 BUILD_XEHPC\": \"#define BUILD_XEHPC 0\",\n-    \"#cmakedefine01 BUILD_XEHP\": \"#define BUILD_XEHP 0\",\n+    \"#cmakedefine01 BUILD_GROUP_NORMALIZATION\": \"#define BUILD_GROUP_NORMALIZATION 0\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_ALL\": \"#define BUILD_GEMM_KERNELS_ALL 1\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_NONE\": \"#define BUILD_GEMM_KERNELS_NONE 0\",\n+    \"#cmakedefine01 BUILD_GEMM_SSE41\": \"#define BUILD_GEMM_SSE41 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX2\": \"#define BUILD_GEMM_AVX2 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX512\": \"#define BUILD_GEMM_AVX512 0\",\n+    \"#cmakedefine DNNL_GPU_VENDOR\": \"#define DNNL_GPU_VENDOR INTEL\",\n+    \"#cmakedefine DNNL_SYCL_GENERIC\": \"#undef DNNL_SYCL_GENERIC\",\n+    \"#cmakedefine DNNL_DISABLE_GPU_REF_KERNELS\": \"#undef DNNL_DISABLE_GPU_REF_KERNELS\",\n+    \"#cmakedefine01 BUILD_SDPA\": \"#define BUILD_SDPA 0\",\n+    \"#cmakedefine01 BUILD_XE2\": \"#define BUILD_XE2 0\",\n+    \"#cmakedefine01 BUILD_XE3\": \"#define BUILD_XE3 0\",\n }\n \n expand_template(\n     name = \"dnnl_config_h\",\n     out = \"include/oneapi/dnnl/dnnl_config.h\",\n     substitutions = select({\n-        \"@local_xla//xla/tsl/mkl:build_with_mkl_aarch64_openmp\": _DNNL_RUNTIME_OMP,\n         \"//conditions:default\": _DNNL_RUNTIME_THREADPOOL,\n     }),\n     template = \"include/oneapi/dnnl/dnnl_config.h.in\",\n@@ -128,13 +84,21 @@ expand_template(\n     out = \"include/oneapi/dnnl/dnnl_version.h\",\n     substitutions = {\n         \"@DNNL_VERSION_MAJOR@\": \"3\",\n-        \"@DNNL_VERSION_MINOR@\": \"2\",\n-        \"@DNNL_VERSION_PATCH@\": \"1\",\n-        \"@DNNL_VERSION_HASH@\": \"N/A\",\n+        \"@DNNL_VERSION_MINOR@\": \"7\",\n+        \"@DNNL_VERSION_PATCH@\": \"0\",\n     },\n     template = \"include/oneapi/dnnl/dnnl_version.h.in\",\n )\n \n+expand_template(\n+    name = \"dnnl_version_hash_h\",\n+    out = \"include/oneapi/dnnl/dnnl_version_hash.h\",\n+    substitutions = {\n+        \"@DNNL_VERSION_HASH@\": \"N/A\",\n+    },\n+    template = \"include/oneapi/dnnl/dnnl_version_hash.h.in\",\n+)\n+\n cc_library(\n     name = \"mkl_dnn_acl\",\n     srcs = glob(\n@@ -156,10 +120,11 @@ cc_library(\n         exclude = [\n             \"src/cpu/x64/**\",\n             \"src/cpu/rv64/**\",\n+            \"src/cpu/sycl/**\",\n+            \"src/xpu/**\",\n         ],\n     ),\n     copts = select({\n-        \"@local_xla//xla/tsl/mkl:build_with_mkl_aarch64_openmp\": _DNNL_COPTS_OMP,\n         \"//conditions:default\": _DNNL_COPTS_THREADPOOL,\n     }),\n     defines = [\"DNNL_AARCH64_USE_ACL=1\"],\n@@ -185,6 +150,7 @@ cc_library(\n     ) + [\n         \":dnnl_config_h\",\n         \":dnnl_version_h\",\n+        \":dnnl_version_hash_h\",\n     ],\n     visibility = [\"//visibility:public\"],\n     deps = ["
        },
        {
            "sha": "42dd262323b577da1954e3ae34723a6c7c07e1f2",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_add_bf16_platform_support_check.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_add_bf16_platform_support_check.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_add_bf16_platform_support_check.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_add_bf16_platform_support_check.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,31 +0,0 @@\n-/* Copyright 2024 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-diff --git a/src/cpu/platform.cpp b/src/cpu/platform.cpp\n-index 65b887ea21..eabdb827bd 100644\n---- a/src/cpu/platform.cpp\n-+++ b/src/cpu/platform.cpp\n-@@ -117,6 +117,8 @@ bool has_data_type_support(data_type_t data_type) {\n- #if defined(USE_CBLAS) && defined(BLAS_HAS_SBGEMM) && defined(__MMA__)\n-             return true;\n- #endif\n-+#elif DNNL_AARCH64_USE_ACL\n-+            return arm_compute::CPUInfo::get().has_bf16();\n- #else\n-             return false;\n- #endif\n--- \n-2.34.1\n-"
        },
        {
            "sha": "779608a68058d2a7d50b95f23c2e8eb4770d0989",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_add_sbgemm_matmul_primitive_definition.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 44,
            "changes": 44,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_add_sbgemm_matmul_primitive_definition.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_add_sbgemm_matmul_primitive_definition.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_add_sbgemm_matmul_primitive_definition.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,44 +0,0 @@\n-/* Copyright 2024 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-diff --git a/src/cpu/aarch64/matmul/acl_matmul.hpp b/src/cpu/aarch64/matmul/acl_matmul.hpp\n-index ab13efb9b2..ec261e156d 100644\n---- a/src/cpu/aarch64/matmul/acl_matmul.hpp\n-+++ b/src/cpu/aarch64/matmul/acl_matmul.hpp\n-@@ -78,11 +78,21 @@ struct acl_matmul_t : public primitive_t {\n-                     = utils::everyone_is(data_type::f16, src_md()->data_type,\n-                               weights_md()->data_type, dst_md()->data_type)\n-                     && platform::has_data_type_support(data_type::f16);\n-+            const bool is_fp32_bf16_ok\n-+                    = (utils::everyone_is(data_type::f32, src_md()->data_type,\n-+                               dst_md()->data_type, desc()->accum_data_type)\n-+                            && platform::has_data_type_support(data_type::f32)\n-+                            && utils::everyone_is(\n-+                                    data_type::bf16, weights_md()->data_type)\n-+                            && platform::has_data_type_support(\n-+                                    data_type::bf16));\n-+\n-             const bool is_weights_md_format_ok\n-                     = utils::one_of(weights_format_kind_received,\n-                             format_kind::any, format_kind::blocked);\n-             bool ok = is_dense_data()\n--                    && utils::one_of(true, is_fp32_ok, is_fp16_ok)\n-+                    && utils::one_of(\n-+                            true, is_fp32_ok, is_fp16_ok, is_fp32_bf16_ok)\n-                     && !has_zero_dim_memory() && is_weights_md_format_ok\n-                     && set_default_formats()\n-                     && attr()->has_default_values(\n--- \n-2.34.1"
        },
        {
            "sha": "ec2cb97f5131ba75bf6bf55f9475279dbb400d63",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_allow_blocked_weight_format_for_matmul_primitive.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 100,
            "changes": 100,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_allow_blocked_weight_format_for_matmul_primitive.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_allow_blocked_weight_format_for_matmul_primitive.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_allow_blocked_weight_format_for_matmul_primitive.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,100 +0,0 @@\n-/* Copyright 2024 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-diff --git a/src/cpu/aarch64/matmul/acl_matmul.hpp b/src/cpu/aarch64/matmul/acl_matmul.hpp\n-index 451cc78d52..ab13efb9b2 100644\n---- a/src/cpu/aarch64/matmul/acl_matmul.hpp\n-+++ b/src/cpu/aarch64/matmul/acl_matmul.hpp\n-@@ -67,6 +67,8 @@ struct acl_matmul_t : public primitive_t {\n- \n-         status_t init(engine_t *engine) {\n-             using smask_t = primitive_attr_t::skip_mask_t;\n-+            const format_kind_t weights_format_kind_received\n-+                    = weights_md_.format_kind;\n-             const bool is_fp32_ok\n-                     = utils::everyone_is(data_type::f32, src_md()->data_type,\n-                               weights_md()->data_type, dst_md()->data_type,\n-@@ -76,18 +78,20 @@ struct acl_matmul_t : public primitive_t {\n-                     = utils::everyone_is(data_type::f16, src_md()->data_type,\n-                               weights_md()->data_type, dst_md()->data_type)\n-                     && platform::has_data_type_support(data_type::f16);\n-+            const bool is_weights_md_format_ok\n-+                    = utils::one_of(weights_format_kind_received,\n-+                            format_kind::any, format_kind::blocked);\n-             bool ok = is_dense_data()\n-                     && utils::one_of(true, is_fp32_ok, is_fp16_ok)\n--                    && !has_zero_dim_memory()\n--                    && weights_md_.format_kind == format_kind::any\n-+                    && !has_zero_dim_memory() && is_weights_md_format_ok\n-                     && set_default_formats()\n-                     && attr()->has_default_values(\n-                             smask_t::oscale | smask_t::post_ops)\n-                     && attr_oscale_ok() && !has_runtime_dims_or_strides();\n-             if (!ok) return status::unimplemented;\n- \n--            CHECK(acl_matmul_utils::init_conf_matmul(\n--                    amp_, src_md_, weights_md_, dst_md_, *desc(), *attr()));\n-+            CHECK(acl_matmul_utils::init_conf_matmul(amp_, src_md_, weights_md_,\n-+                    dst_md_, *desc(), *attr(), weights_format_kind_received));\n- \n-             arm_compute::ActivationLayerInfo act_info;\n-             CHECK(post_ops.init(engine, attr_.post_ops_, dst_md_, act_info));\n-diff --git a/src/cpu/aarch64/matmul/acl_matmul_utils.cpp b/src/cpu/aarch64/matmul/acl_matmul_utils.cpp\n-index a314d96384..027f915a8a 100644\n---- a/src/cpu/aarch64/matmul/acl_matmul_utils.cpp\n-+++ b/src/cpu/aarch64/matmul/acl_matmul_utils.cpp\n-@@ -27,7 +27,8 @@ namespace acl_matmul_utils {\n- \n- status_t init_conf_matmul(acl_matmul_conf_t &amp, memory_desc_t &src_md,\n-         memory_desc_t &wei_md, memory_desc_t &dst_md, const matmul_desc_t &md,\n--        const primitive_attr_t &attr) {\n-+        const primitive_attr_t &attr,\n-+        format_kind_t weights_format_kind_received) {\n- \n-     const memory_desc_wrapper src_d(&src_md);\n-     const memory_desc_wrapper wei_d(&wei_md);\n-@@ -128,9 +129,16 @@ status_t init_conf_matmul(acl_matmul_conf_t &amp, memory_desc_t &src_md,\n-     for (dim_t i = K_dim - 1; i >= 0; --i)\n-         batch_dims.push_back(i);\n- \n-+    const memory_desc_t weights_md_received = wei_md;\n-     acl_utils::reorder_to_weight_format(amp.wei_tensor_info, wei_md,\n-             expected_weight_format, K_dim, N_dim, {}, batch_dims);\n- \n-+    ACL_CHECK_SUPPORT((weights_format_kind_received == format_kind::blocked)\n-+                    && !(dnnl_memory_desc_equal(&weights_md_received, &wei_md)),\n-+            \"specified blocked format not supported by ACL, use \"\n-+            \"format_kind_t::any to find a supported blocked format for \"\n-+            \"your platform\");\n-+\n-     return status::success;\n- }\n- \n-diff --git a/src/cpu/aarch64/matmul/acl_matmul_utils.hpp b/src/cpu/aarch64/matmul/acl_matmul_utils.hpp\n-index 67bb2e78eb..5ba4241abc 100644\n---- a/src/cpu/aarch64/matmul/acl_matmul_utils.hpp\n-+++ b/src/cpu/aarch64/matmul/acl_matmul_utils.hpp\n-@@ -52,7 +52,8 @@ namespace acl_matmul_utils {\n- \n- status_t init_conf_matmul(acl_matmul_conf_t &amp, memory_desc_t &src_md,\n-         memory_desc_t &wei_md, memory_desc_t &dst_md, const matmul_desc_t &md,\n--        const primitive_attr_t &attr);\n-+        const primitive_attr_t &attr,\n-+        format_kind_t weights_format_kind_received);\n- \n- } // namespace acl_matmul_utils\n- \n--- \n-2.34.1"
        },
        {
            "sha": "6d6f0c0eaabb133b2e58b3774dd96e53b043fd82",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_bf16_capability_detection_for_ubuntu20.04.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 50,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_bf16_capability_detection_for_ubuntu20.04.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_bf16_capability_detection_for_ubuntu20.04.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_bf16_capability_detection_for_ubuntu20.04.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,50 +0,0 @@\n-From 9a9430c7db870b78c6402d786a67921af4a66334 Mon Sep 17 00:00:00 2001\n-From: Kentaro Kawakami <kawakami.k@fujitsu.com>\n-Date: Fri, 26 May 2023 10:58:36 +0900\n-Subject: [PATCH] cpu: aarch64: xbyak_aarch64: BF16 capability detection for\n- Ubuntu 20.04\n-\n----\n- .../aarch64/xbyak_aarch64/src/util_impl_linux.h   | 15 ++++++++++++---\n- 1 file changed, 12 insertions(+), 3 deletions(-)\n-\n-diff --git a/src/cpu/aarch64/xbyak_aarch64/src/util_impl_linux.h b/src/cpu/aarch64/xbyak_aarch64/src/util_impl_linux.h\n-index 743843bae50..3db37e972d1 100644\n---- a/src/cpu/aarch64/xbyak_aarch64/src/util_impl_linux.h\n-+++ b/src/cpu/aarch64/xbyak_aarch64/src/util_impl_linux.h\n-@@ -39,6 +39,13 @@\n- #include <asm/hwcap.h>\n- #endif\n- \n-+/* Linux kernel used in Ubuntu 20.04 does not have HWCAP2_BF16 definition. */\n-+#ifdef AT_HWCAP2\n-+#ifndef HWCAP2_BF16\n-+#define HWCAP2_BF16 (1UL << 14)\n-+#endif\n-+#endif\n-+\n- namespace Xbyak_aarch64 {\n- namespace util {\n- #define XBYAK_AARCH64_ERROR_ fprintf(stderr, \"%s, %d, Error occurrs during read cache infomation.\\n\", __FILE__, __LINE__);\n-@@ -383,7 +390,7 @@ class CpuInfoLinux : public CpuInfo {\n-   }\n- \n-   void setHwCap() {\n--    unsigned long hwcap = getauxval(AT_HWCAP);\n-+    const unsigned long hwcap = getauxval(AT_HWCAP);\n-     if (hwcap & HWCAP_ATOMICS)\n-       type_ |= (Type)XBYAK_AARCH64_HWCAP_ATOMIC;\n- \n-@@ -391,8 +398,10 @@ class CpuInfoLinux : public CpuInfo {\n-       type_ |= (Type)XBYAK_AARCH64_HWCAP_FP;\n-     if (hwcap & HWCAP_ASIMD)\n-       type_ |= (Type)XBYAK_AARCH64_HWCAP_ADVSIMD;\n--#ifdef HWCAP2_BF16\n--    if (hwcap & HWCAP2_BF16)\n-+\n-+#ifdef AT_HWCAP2\n-+    const unsigned long hwcap2 = getauxval(AT_HWCAP2);\n-+    if (hwcap2 & HWCAP2_BF16)\n-       type_ |= (Type)XBYAK_AARCH64_HWCAP_BF16;\n- #endif\n- "
        },
        {
            "sha": "39f7e74345e08b9ba811b482e2b486ea5bb78f1d",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_fix_segfault_during_postop_execute.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 96,
            "changes": 96,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_fix_segfault_during_postop_execute.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_fix_segfault_during_postop_execute.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_fix_segfault_during_postop_execute.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,96 +0,0 @@\n-/* Copyright 2024 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-diff --git a/src/cpu/aarch64/acl_post_ops.cpp b/src/cpu/aarch64/acl_post_ops.cpp\n-index ea4bb200ec..3eb53b81bd 100644\n---- a/src/cpu/aarch64/acl_post_ops.cpp\n-+++ b/src/cpu/aarch64/acl_post_ops.cpp\n-@@ -24,7 +24,7 @@ namespace aarch64 {\n- \n- status_t acl_post_ops_t::execute(const exec_ctx_t &ctx, void *src_orig) const {\n- \n--    int post_op_index = 0;\n-+    int post_op_index = post_op_start_index_;\n- \n-     // As these are post ops, this src will also be our dst. If we have a sum\n-     // post op, the src/dst will start off in a temporary, then change to\n-diff --git a/src/cpu/aarch64/acl_post_ops.hpp b/src/cpu/aarch64/acl_post_ops.hpp\n-index 7b59ad71d3..ceaa95b73a 100644\n---- a/src/cpu/aarch64/acl_post_ops.hpp\n-+++ b/src/cpu/aarch64/acl_post_ops.hpp\n-@@ -32,7 +32,9 @@ struct acl_post_ops_t {\n-     // init the acl_post_ops_t. Note that this function modifies the passed in\n-     // post ops by setting the preferred memory formats\n-     status_t init(engine_t *engine, post_ops_t &post_ops,\n--            const memory_desc_t &dst_md) {\n-+            const memory_desc_t &dst_md, int post_op_start_index = 0) {\n-+\n-+        post_op_start_index_ = post_op_start_index;\n- \n-         CHECK(post_ops.set_default_formats(&dst_md));\n-         dst_data_type = dst_md.data_type;\n-@@ -41,7 +43,7 @@ struct acl_post_ops_t {\n-         sum_index = -1;\n-         post_op_primitives = {};\n- \n--        for (int i = 0; i < post_ops.len(); i++) {\n-+        for (int i = post_op_start_index; i < post_ops.len(); i++) {\n-             auto &po = post_ops.entry_[i];\n- \n-             if (po.is_sum()) {\n-@@ -135,7 +137,8 @@ struct acl_post_ops_t {\n-     // formats\n-     status_t init(engine_t *engine, post_ops_t &base_post_ops,\n-             const memory_desc_t &dst_md,\n--            arm_compute::ActivationLayerInfo &act_info_to_fuse) {\n-+            arm_compute::ActivationLayerInfo &act_info_to_fuse,\n-+            int post_op_start_index = 0) {\n- \n-         CHECK(base_post_ops.set_default_formats(&dst_md));\n-         dst_data_type = dst_md.data_type;\n-@@ -149,18 +152,11 @@ struct acl_post_ops_t {\n-                     \"eltwise post op scale must be 1 (no scale)\");\n-             CHECK(acl_utils::convert_to_acl_act(first_po, act_info_to_fuse));\n- \n--            // Copy all but the first, because it has been fused\n--            post_ops_t post_ops;\n--            for (int idx = 1; idx < base_post_ops.len(); ++idx) {\n--                // Construct empty entry then copy, so that we can check for failure\n--                post_ops.entry_.emplace_back();\n--                post_ops.entry_.back().copy_from(base_post_ops.entry_[idx]);\n--            }\n--            return init(engine, post_ops, dst_md);\n--\n-+             // post_op_start_index + 1 to skip the fused eltwise\n-+              return init(engine, base_post_ops, dst_md, post_op_start_index + 1);\n-         } else {\n-             // Nothing to fuse, just copy all post ops\n--            return init(engine, base_post_ops, dst_md);\n-+            return init(engine, base_post_ops, dst_md, post_op_start_index);\n-         }\n-     }\n- \n-@@ -179,6 +175,9 @@ struct acl_post_ops_t {\n- private:\n-     // Index of the sum post op if there is one, < 0 means no sum\n-     int sum_index = -1;\n-+    // Index of the first post op this primitive executes. This is typically the\n-+    // number of post ops which were fused.\n-+    int post_op_start_index_ = 0;\n-     data_type_t dst_data_type;\n-     // Vector of primitives used to execute the post ops. They are constructed\n-     // in init to be either acl_binary_t (for sum, add, sub, div, mul, min and\n--- \n-2.34.1"
        },
        {
            "sha": "202902a1894a86f7e14e3b137893098c932e1494",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_fp32_bf16_reorder.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 111,
            "changes": 111,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_fp32_bf16_reorder.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_fp32_bf16_reorder.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_fp32_bf16_reorder.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,111 +0,0 @@\n- *******************************************************************************\n- Copyright 2023 Arm Limited and affiliates.\n- SPDX-License-Identifier: Apache-2.0\n-\n- Licensed under the Apache License, Version 2.0 (the \"License\");\n- you may not use this file except in compliance with the License.\n- You may obtain a copy of the License at\n-\n-     http://www.apache.org/licenses/LICENSE-2.0\n-\n- Unless required by applicable law or agreed to in writing, software\n- distributed under the License is distributed on an \"AS IS\" BASIS,\n- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- See the License for the specific language governing permissions and\n- limitations under the License.\n- *******************************************************************************\n-diff --git a/src/cpu/aarch64/cpu_isa_traits.hpp b/src/cpu/aarch64/cpu_isa_traits.hpp\n-index 4a43b24c5..1a5cfe590 100644\n---- a/src/cpu/aarch64/cpu_isa_traits.hpp\n-+++ b/src/cpu/aarch64/cpu_isa_traits.hpp\n-@@ -1,6 +1,7 @@\n- /*******************************************************************************\n- * Copyright 2018-2023 Intel Corporation\n- * Copyright 2020-2023 FUJITSU LIMITED\n-+* Copyright 2023 Arm Ltd. and affiliates\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n-@@ -211,10 +212,10 @@ static inline bool mayiuse_atomic() {\n-     return cpu().isAtomicSupported();\n- }\n- \n--inline bool isa_has_bf16(cpu_isa_t isa) {\n--    return false;\n-+static inline bool mayiuse_bf16() {\n-+    using namespace Xbyak_aarch64::util;\n-+    return cpu().isBf16Supported();\n- }\n--\n- } // namespace\n- \n- /* whatever is required to generate string literals... */\n-diff --git a/src/cpu/aarch64/jit_uni_reorder.cpp b/src/cpu/aarch64/jit_uni_reorder.cpp\n-index 6bd259ec2..5541bb702 100644\n---- a/src/cpu/aarch64/jit_uni_reorder.cpp\n-+++ b/src/cpu/aarch64/jit_uni_reorder.cpp\n-@@ -1,7 +1,7 @@\n- /*******************************************************************************\n- * Copyright 2018-2023 Intel Corporation\n- * Copyright 2020-2023 FUJITSU LIMITED\n--* Copyright 2022 Arm Ltd. and affiliates\n-+* Copyright 2022-2023 Arm Ltd. and affiliates\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n-@@ -163,11 +163,11 @@ struct jit_uni_reorder_kernel_f32_t : public kernel_t, public jit_generator {\n- \n-         bool ok = true && p.ndims > 0\n-                 && utils::one_of(p.itype, f32, s32, data_type::s8, u8)\n--                && utils::one_of(p.otype, f32, s32, data_type::s8, u8)\n-+                && utils::one_of(p.otype, f32, bf16, s32, data_type::s8, u8)\n-                 && utils::everyone_is(0, p.ioff, p.ooff) /* do we need this? */\n-                 && utils::one_of(p.beta, 0.f, 1.f) /* anything else? */\n--                && simple_impl_desc_init(p, nullptr)\n--                && prb_has_small_strides(p);\n-+                && simple_impl_desc_init(p, nullptr) && prb_has_small_strides(p)\n-+                && ((p.otype != bf16) || (p.itype == f32 && mayiuse_bf16()));\n- \n-         return ok;\n-     }\n-@@ -648,6 +648,9 @@ struct jit_uni_reorder_kernel_f32_t : public kernel_t, public jit_generator {\n-                         cvt_v_s32_u8(startIdx, regNum);\n-                     if (idt == data_type::s8) cvt_v_s8_u8(startIdx, regNum);\n-                     break;\n-+                case bf16:\n-+                    if (idt == f32) cvt_v_f32_bf16(startIdx, regNum);\n-+                    break;\n-                 default: assert(!\"unreachable\");\n-             }\n-         };\n-@@ -1677,6 +1680,10 @@ struct jit_uni_reorder_kernel_f32_t : public kernel_t, public jit_generator {\n-         UNROLL_INST(fcvtzs, VReg4S, tmp, tmp);\n-     }\n- \n-+    void cvt_v_f32_bf16(const size_t startIdx, const size_t regNum) {\n-+        UNROLL_INST2(bfcvtn, VReg4H(i), VReg4S(i));\n-+    }\n-+\n-     void cvt_z_s8_s32(const size_t startIdx, const size_t regNum) {\n-         cvt_z_b_s(startIdx, regNum);\n-         UNROLL_INST(sxtb, ZRegS, tmp, P_ALL_ONE / T_m, tmp);\n-diff --git a/src/cpu/reorder/cpu_reorder_regular_f32_bf16.cpp b/src/cpu/reorder/cpu_reorder_regular_f32_bf16.cpp\n-index ba5499ba9..d4e21d316 100644\n---- a/src/cpu/reorder/cpu_reorder_regular_f32_bf16.cpp\n-+++ b/src/cpu/reorder/cpu_reorder_regular_f32_bf16.cpp\n-@@ -1,5 +1,6 @@\n- /*******************************************************************************\n- * Copyright 2020-2022 Intel Corporation\n-+* Copyright 2023 Arm Ltd. and affiliates\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n-@@ -34,6 +35,8 @@ const impl_list_map_t &regular_f32_bf16_impl_list_map() {\n-             DNNL_NON_X64_ONLY(REG_SR_BIDIR(f32, any, bf16, nChw16c))\n-             DNNL_NON_X64_ONLY(REG_SR_BIDIR(f32, any, bf16, nCdhw16c))\n- \n-+            DNNL_AARCH64_ONLY(CPU_REORDER_INSTANCE(aarch64::jit_uni_reorder_t))\n-+\n-             DNNL_NON_X64_ONLY(REG_SR(f32, oihw, bf16, OIhw8i16o2i, fmt_order::keep))\n-             DNNL_NON_X64_ONLY(REG_SR(f32, goihw, bf16, gOIhw8i16o2i, fmt_order::keep))\n-             DNNL_NON_X64_ONLY(REG_SR(f32, oihw, bf16, OIhw8o16i2o, fmt_order::keep))"
        },
        {
            "sha": "217e668352de5c37c7decbc6af67ed5ea910c76f",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_indirect_conv.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_indirect_conv.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_indirect_conv.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_indirect_conv.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,31 +0,0 @@\n- *******************************************************************************\n- Copyright 2024 Arm Limited and affiliates.\n- SPDX-License-Identifier: Apache-2.0\n-\n- Licensed under the Apache License, Version 2.0 (the \"License\");\n- you may not use this file except in compliance with the License.\n- You may obtain a copy of the License at\n-\n-     http://www.apache.org/licenses/LICENSE-2.0\n-\n- Unless required by applicable law or agreed to in writing, software\n- distributed under the License is distributed on an \"AS IS\" BASIS,\n- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- See the License for the specific language governing permissions and\n- limitations under the License.\n- *******************************************************************************\n-diff --git a/src/cpu/aarch64/acl_convolution_utils.cpp b/src/cpu/aarch64/acl_convolution_utils.cpp\n-index f043fee4bc..0384cce757 100644\n---- a/src/cpu/aarch64/acl_convolution_utils.cpp\n-+++ b/src/cpu/aarch64/acl_convolution_utils.cpp\n-@@ -313,10 +313,6 @@ status_t init_conf_indirect_gemm(acl_conv_conf_t &acp, memory_desc_t &src_md,\n-\n-     CHECK(acl_init_conf(acp, src_md, weights_md, dst_md, bias_md, cd, attr));\n-\n--    // Indirect is slower than gemm for low thread counts, except for fast math\n--    if (dnnl_get_max_threads() < 28 && !acp.fast_math)\n--        return status::unimplemented;\n--\n-     // If we do not need to pad input channels for fast math mode then it would\n-     // be faster to run convolution with im2row instead of using indirect kernel\n-     int block_by = arm_compute::block_by(acp.weights_info.weight_format());"
        },
        {
            "sha": "d0e87414f8e9675de151792af752f03763b2ecf7",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_lock_fixed_format_matmul.patch",
            "status": "added",
            "additions": 33,
            "deletions": 0,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_lock_fixed_format_matmul.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_lock_fixed_format_matmul.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_lock_fixed_format_matmul.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,33 @@\n+# Copyright 2025 The OpenXLA Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+diff --git a/src/cpu/aarch64/matmul/acl_matmul.cpp b/src/cpu/aarch64/matmul/acl_matmul.cpp\n+index 380a0a3843..61cd2af4b7 100644\n+--- a/src/cpu/aarch64/matmul/acl_matmul.cpp\n++++ b/src/cpu/aarch64/matmul/acl_matmul.cpp\n+@@ -178,11 +178,9 @@ status_t acl_matmul_t::execute_forward(const exec_ctx_t &ctx) const {\n+\n+     std::unique_lock<std::mutex> locker {mtx_, std::defer_lock};\n+\n+-    // Some of the underlying kernels used by ACL still require some state and\n+-    // are not safe to be called in parallel with different execution contexts.\n+-    // Eventually when all kernels are truly stateless, this guard can be\n+-    // removed.\n+-    if (!acl_obj_->asm_gemm.has_stateless_impl()) { locker.lock(); }\n++    // Non-fixed-format kernels in ACL hold shared state and are not safe to be\n++    // called in parallel with different execution contexts.\n++    if (!IsFixedFormat) { locker.lock(); }\n+\n+     bool is_transA = amp.is_transA;\n+     bool is_transB = amp.is_transB;\n\\ No newline at end of file"
        },
        {
            "sha": "5da6756c70a2753ce3990337e08206357fb096ac",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_reorder.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 371,
            "changes": 371,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_reorder.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_reorder.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_reorder.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,371 +0,0 @@\n- *******************************************************************************\n- Copyright 2023 Arm Limited and affiliates.\n- SPDX-License-Identifier: Apache-2.0\n-\n- Licensed under the Apache License, Version 2.0 (the \"License\");\n- you may not use this file except in compliance with the License.\n- You may obtain a copy of the License at\n-\n-     http://www.apache.org/licenses/LICENSE-2.0\n-\n- Unless required by applicable law or agreed to in writing, software\n- distributed under the License is distributed on an \"AS IS\" BASIS,\n- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- See the License for the specific language governing permissions and\n- limitations under the License.\n- *******************************************************************************\n-diff --git a/src/cpu/aarch64/acl_reorder.cpp b/src/cpu/aarch64/acl_reorder.cpp\n-new file mode 100644\n-index 000000000..061751b55\n---- /dev/null\n-+++ b/src/cpu/aarch64/acl_reorder.cpp\n-@@ -0,0 +1,52 @@\n-+/*******************************************************************************\n-+* Copyright 2023 Arm Ltd. and affiliates\n-+*\n-+* Licensed under the Apache License, Version 2.0 (the \"License\");\n-+* you may not use this file except in compliance with the License.\n-+* You may obtain a copy of the License at\n-+*\n-+*     http://www.apache.org/licenses/LICENSE-2.0\n-+*\n-+* Unless required by applicable law or agreed to in writing, software\n-+* distributed under the License is distributed on an \"AS IS\" BASIS,\n-+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-+* See the License for the specific language governing permissions and\n-+* limitations under the License.\n-+*******************************************************************************/\n-+\n-+#include \"cpu/aarch64/acl_reorder.hpp\"\n-+\n-+namespace dnnl {\n-+namespace impl {\n-+namespace cpu {\n-+namespace aarch64 {\n-+\n-+status_t acl_reorder_fwd_t::execute_forward(const exec_ctx_t &ctx) const {\n-+    // Lock here is needed because resource_mapper does not support\n-+    // concurrent multithreaded access.\n-+    std::lock_guard<std::mutex> _lock {this->mtx};\n-+\n-+    auto src = CTX_IN_MEM(const void *, DNNL_ARG_FROM);\n-+    auto dst = CTX_OUT_MEM(void *, DNNL_ARG_TO);\n-+\n-+    // Retrieve primitive resource and configured Compute Library objects\n-+    auto *acl_resource\n-+            = ctx.get_resource_mapper()->get<acl_reorder_resource_t>(this);\n-+\n-+    acl_reorder_obj_t &acl_obj = acl_resource->get_acl_obj();\n-+\n-+    acl_obj.src_tensor.allocator()->import_memory(const_cast<void *>(src));\n-+    acl_obj.dst_tensor.allocator()->import_memory(dst);\n-+\n-+    acl_obj.reorder.run();\n-+\n-+    acl_obj.src_tensor.allocator()->free();\n-+    acl_obj.dst_tensor.allocator()->free();\n-+\n-+    return status::success;\n-+}\n-+\n-+} // namespace aarch64\n-+} // namespace cpu\n-+} // namespace impl\n-+} // namespace dnnl\n-diff --git a/src/cpu/aarch64/acl_reorder.hpp b/src/cpu/aarch64/acl_reorder.hpp\n-new file mode 100644\n-index 0000000000..edbc38914d\n---- /dev/null\n-+++ b/src/cpu/aarch64/acl_reorder.hpp\n-@@ -0,0 +1,262 @@\n-+/*******************************************************************************\n-+* Copyright 2023 Arm Ltd. and affiliates\n-+*\n-+* Licensed under the Apache License, Version 2.0 (the \"License\");\n-+* you may not use this file except in compliance with the License.\n-+* You may obtain a copy of the License at\n-+*\n-+*     http://www.apache.org/licenses/LICENSE-2.0\n-+*\n-+* Unless required by applicable law or agreed to in writing, software\n-+* distributed under the License is distributed on an \"AS IS\" BASIS,\n-+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-+* See the License for the specific language governing permissions and\n-+* limitations under the License.\n-+*******************************************************************************/\n-+#ifndef CPU_AARCH64_ACL_REORDER_HPP\n-+#define CPU_AARCH64_ACL_REORDER_HPP\n-+\n-+#include \"cpu/aarch64/acl_utils.hpp\"\n-+#include \"cpu/reorder/cpu_reorder_pd.hpp\"\n-+#include \"arm_compute/core/Types.h\"\n-+#include \"common/utils.hpp\"\n-+\n-+namespace dnnl {\n-+namespace impl {\n-+namespace cpu {\n-+namespace aarch64 {\n-+\n-+struct acl_reorder_obj_t {\n-+    arm_compute::NEReorderLayer reorder;\n-+    arm_compute::Tensor src_tensor;\n-+    arm_compute::Tensor dst_tensor;\n-+    arm_compute::WeightFormat src_wf;\n-+    arm_compute::WeightFormat dst_wf;\n-+};\n-+\n-+struct acl_reorder_conf_t {\n-+    arm_compute::TensorInfo src_info;\n-+    arm_compute::TensorInfo dst_info;\n-+    arm_compute::WeightFormat src_wf;\n-+    arm_compute::WeightFormat dst_wf;\n-+};\n-+\n-+struct acl_reorder_resource_t : public resource_t {\n-+    acl_reorder_resource_t() : acl_obj_(utils::make_unique<acl_reorder_obj_t>()) {}\n-+\n-+    status_t configure(const acl_reorder_conf_t &app) {\n-+        if (!acl_obj_) return status::out_of_memory;\n-+\n-+        // Init Compute Library tensors based on info from descriptor\n-+        acl_obj_->src_tensor.allocator()->init(app.src_info);\n-+        acl_obj_->dst_tensor.allocator()->init(app.dst_info);\n-+\n-+        // clang-format off\n-+        acl_obj_->reorder.configure(\n-+            &acl_obj_->src_tensor,\n-+            &acl_obj_->dst_tensor,\n-+            app.src_wf,\n-+            app.dst_wf\n-+            );\n-+        // clang-format on\n-+\n-+        return status::success;\n-+    }\n-+\n-+    acl_reorder_obj_t &get_acl_obj() const { return *acl_obj_; }\n-+    DNNL_DISALLOW_COPY_AND_ASSIGN(acl_reorder_resource_t);\n-+\n-+private:\n-+    std::unique_ptr<acl_reorder_obj_t> acl_obj_;\n-+}; // acl_reorder_resource_t\n-+\n-+struct acl_reorder_fwd_t : public primitive_t {\n-+    using primitive_t::primitive_t;\n-+    struct pd_t : public cpu_reorder_pd_t {\n-+\n-+        using cpu_reorder_pd_t::cpu_reorder_pd_t;\n-+\n-+        DECLARE_COMMON_PD_T(\"acl\", acl_reorder_fwd_t);\n-+\n-+        static status_t create(reorder_pd_t **reorder_pd, engine_t *engine,\n-+                const primitive_attr_t *attr, engine_t *src_engine,\n-+                const memory_desc_t *src_md, engine_t *dst_engine,\n-+                const memory_desc_t *dst_md) {\n-+\n-+            using namespace acl_utils;\n-+            // using skip_mask_t = dnnl_primitive_attr::skip_mask_t;\n-+\n-+            bool ok = src_md->data_type\n-+                            == dst_md->data_type // ACL only supports matching src/dst data types\n-+                    && utils::one_of(src_md->data_type,\n-+                            data_type::f32) // Only supports f32 for now\n-+                    && attr->has_default_values();\n-+            if (!ok) return status::unimplemented;\n-+\n-+            int mask = -1;\n-+            bool is_set = false;\n-+            // CHECK(attr->scales_.get(DNNL_ARG_DST, &mask, &is_set));\n-+            const memory_desc_wrapper input_d(src_md);\n-+            if (input_d.has_runtime_dims_or_strides() && is_set && mask > 0)\n-+                return status::unimplemented;\n-+\n-+            // Create and check primitive descriptor\n-+            auto _pd = new pd_t(attr, src_engine->kind(), src_md,\n-+                    dst_engine->kind(), dst_md);\n-+            if (_pd == nullptr) return status::out_of_memory;\n-+            if (_pd->init(engine, src_engine, dst_engine) != status::success) {\n-+                delete _pd;\n-+                return status::unimplemented;\n-+            }\n-+\n-+            const memory_desc_wrapper src_d(*src_md);\n-+            const memory_desc_wrapper dst_d(*dst_md);\n-+\n-+            const int ndims = src_d.ndims();\n-+\n-+            auto src_tag = memory_desc_matches_one_of_tag(\n-+                            *src_md, format_tag::ba, format_tag::cdba);\n-+            ACL_CHECK_SUPPORT(\n-+                            utils::one_of(format_tag::undef, src_tag),\n-+                            \"\");\n-+\n-+            arm_compute::TensorShape acl_tensor_shape_in;\n-+            arm_compute::TensorShape acl_tensor_shape_out;\n-+            // Need even amount of dims in dim 0 for ACL kernel (eg mulitple of 8 rows when blocking by 8)\n-+            int dim_0_rounded_up;\n-+\n-+            // Switch for 2 or 4 dim tensors\n-+            switch(ndims)\n-+            {\n-+                // Currently for Ab4a and Ab8a\n-+                // No format_tag for these, have to deduce from stride\n-+                case 2:\n-+                    {\n-+                        if(dst_md->dims[0] == 1 || dst_md->dims[1] == 1){\n-+                            return status::unimplemented;\n-+                        }\n-+                        int dst_dim_1 = dst_md->dims[1];\n-+                        int dst_dim_0_stride = dst_md->format_desc.blocking.strides[0];\n-+                        int dst_dim_1_stride = dst_md->format_desc.blocking.strides[1];\n-+                        // Interleave of 4 or 8 that stride for dim 1\n-+                        if (dst_dim_1_stride != 4 && dst_dim_1_stride != 8){\n-+                            return status::unimplemented;\n-+                        }\n-+                        // Check to ensure it's a blocking transpose\n-+                        if (dst_dim_1 * dst_dim_1_stride != dst_dim_0_stride){\n-+                            return status::unimplemented;\n-+                        }\n-+                        if(dst_dim_1_stride == 4){\n-+                            // Set Dest WeightFormat\n-+                            _pd->app_.dst_wf = arm_compute::WeightFormat::OHWIo4;\n-+                            dim_0_rounded_up\n-+                                    = utils::rnd_up(src_md->dims[0], 4);\n-+                        } else {\n-+                            // Set Dest WeightFormat\n-+                            _pd->app_.dst_wf = arm_compute::WeightFormat::OHWIo8;\n-+                            dim_0_rounded_up\n-+                                    = utils::rnd_up(src_md->dims[0], 8);\n-+                        }\n-+                        acl_tensor_shape_in = arm_compute::TensorShape(src_md->dims[1], src_md->dims[0]);\n-+                        acl_tensor_shape_out = arm_compute::TensorShape(src_md->dims[1], dim_0_rounded_up);\n-+\n-+                        break;\n-+                    }\n-+                // Currently for Acdb4a and Acdb8a\n-+                case 4:\n-+                    { \n-+\n-+                        auto dst_tag = memory_desc_matches_one_of_tag(\n-+                            *dst_md, format_tag::Acdb4a, format_tag::Acdb8a);\n-+                        ACL_CHECK_SUPPORT(\n-+                            utils::one_of(format_tag::undef, dst_tag),\n-+                            \"\");\n-+                        if(dst_tag == format_tag::Acdb4a){\n-+                            // Set Dest WeightFormat\n-+                            _pd->app_.dst_wf = arm_compute::WeightFormat::OHWIo4;\n-+                            dim_0_rounded_up\n-+                                    = utils::rnd_up(src_md->dims[0], 4);\n-+                        }\n-+                        else{\n-+                            // Set Dest WeightFormat\n-+                            _pd->app_.dst_wf = arm_compute::WeightFormat::OHWIo8;\n-+                            dim_0_rounded_up\n-+                                    = utils::rnd_up(src_md->dims[0], 8);\n-+                        }\n-+                        // Currently only supporting AxBx1x1 cases\n-+                        if(dst_md->dims[2] != 1 || dst_md->dims[3] != 1){\n-+                            return status::unimplemented;\n-+                        }\n-+                        if(dst_md->dims[0] == 1 || dst_md->dims[1] == 1){\n-+                            return status::unimplemented;\n-+                        }\n-+                        acl_tensor_shape_in = arm_compute::TensorShape(src_md->dims[3], src_md->dims[2], src_md->dims[1], src_md->dims[0]);\n-+                        acl_tensor_shape_out = arm_compute::TensorShape(src_md->dims[3], src_md->dims[2], src_md->dims[1], dim_0_rounded_up);\n-+                        break;\n-+                    }\n-+                default:\n-+                    return status::unimplemented;\n-+            }\n-+\n-+            // Choose the data layout\n-+            // bool is_nspc = utils::one_of(src_tag, format_tag::nhwc);\n-+            const auto acl_layout = arm_compute::DataLayout::NCHW;\n-+\n-+            // Set Source WeightFormat\n-+            _pd->app_.src_wf = arm_compute::WeightFormat::OHWI;\n-+\n-+            // Create ACL tensor infos\n-+            const data_type_t data_type = src_d.data_type();\n-+            const arm_compute::DataType acl_data_t\n-+                    = acl_utils::get_acl_data_t(data_type);\n-+            _pd->app_.src_info = arm_compute::TensorInfo(\n-+                        acl_tensor_shape_in, 1, acl_data_t, acl_layout);\n-+            _pd->app_.dst_info = arm_compute::TensorInfo(\n-+                        acl_tensor_shape_out, 1, acl_data_t, acl_layout);\n-+\n-+            // Init scratch memory, not used so 0 in this implementation\n-+            _pd->init_scratchpad_md();\n-+\n-+            return safe_ptr_assign(*reorder_pd, _pd);\n-+        } // create \n-+\n-+        friend dnnl::impl::impl_list_item_t;\n-+        acl_reorder_conf_t app_;\n-+\n-+    }; // pd_t\n-+\n-+    acl_reorder_fwd_t(const pd_t *apd) : primitive_t(apd) {}\n-+\n-+    status_t create_resource(\n-+            engine_t *engine, resource_mapper_t &mapper) const override {\n-+        if (mapper.has_resource(this)) return status::success;\n-+\n-+        auto r = utils::make_unique<acl_reorder_resource_t>();\n-+        if (!r) return status::out_of_memory;\n-+\n-+        // Configure the resource based on information from primitive descriptor\n-+        CHECK(r->configure(pd()->app_));\n-+\n-+        mapper.add(this, std::move(r));\n-+        return status::success;\n-+    }\n-+\n-+    status_t execute(const exec_ctx_t &ctx) const override {\n-+        return execute_forward(ctx);\n-+    }\n-+\n-+private:\n-+    // To guard the const execute_forward, the mutex must be 'mutable'\n-+    mutable std::mutex mtx;\n-+    status_t execute_forward(const exec_ctx_t &ctx) const;\n-+    const pd_t *pd() const { return (const pd_t *)primitive_t::pd().get(); }\n-+\n-+\n-+}; // acl_reorder_fwd_t\n-+\n-+} // namespace aarch64\n-+} // namespace cpu\n-+} // namespace impl\n-+} // namespace dnnl\n-+\n-+#endif // CPU_AARCH64_ACL_REORDER_HPP\n-diff --git a/src/cpu/reorder/cpu_reorder_regular_f32_f32.cpp b/src/cpu/reorder/cpu_reorder_regular_f32_f32.cpp\n-index a4150b619..f4d6b4de3 100644\n---- a/src/cpu/reorder/cpu_reorder_regular_f32_f32.cpp\n-+++ b/src/cpu/reorder/cpu_reorder_regular_f32_f32.cpp\n-@@ -16,6 +16,7 @@\n- *******************************************************************************/\n- \n- #include \"cpu/reorder/cpu_reorder.hpp\"\n-+#include \"cpu/aarch64/acl_reorder.hpp\"\n- \n- namespace dnnl {\n- namespace impl {\n-@@ -28,6 +29,7 @@ const impl_list_map_t &regular_f32_f32_impl_list_map() {\n-         // f32 -> f32\n-         {{f32, f32, 0}, {\n-             REG_FAST_DIRECT_COPY_F32_F32\n-+            DNNL_AARCH64_ONLY(CPU_REORDER_INSTANCE(aarch64::acl_reorder_fwd_t))\n- \n-             DNNL_X64_ONLY(CPU_REORDER_INSTANCE(x64::brgemm_matmul_matrix_B_reorder_t))\n-             DNNL_X64_ONLY(CPU_REORDER_INSTANCE(x64::jit_blk_reorder_t))\n-@@ -69,6 +71,8 @@ const impl_list_map_t &regular_f32_f32_impl_list_map() {\n-             nullptr,\n-         }},\n-         {{f32, f32, 4}, {\n-+\n-+            DNNL_AARCH64_ONLY(CPU_REORDER_INSTANCE(aarch64::acl_reorder_fwd_t))\n-             CPU_REORDER_INSTANCE(rnn_weights_reorder_t<f32, f32>)\n- \n-             REG_FAST_DIRECT_COPY_F32_F32"
        },
        {
            "sha": "9583308396dd1df55b4636d386cbee4bd1620c61",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_thread_local_scheduler.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 97,
            "changes": 97,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_thread_local_scheduler.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_thread_local_scheduler.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_thread_local_scheduler.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,97 +0,0 @@\n- *******************************************************************************\n- Copyright 2023 Arm Limited and affiliates.\n- SPDX-License-Identifier: Apache-2.0\n-\n- Licensed under the Apache License, Version 2.0 (the \"License\");\n- you may not use this file except in compliance with the License.\n- You may obtain a copy of the License at\n-\n-     http://www.apache.org/licenses/LICENSE-2.0\n-\n- Unless required by applicable law or agreed to in writing, software\n- distributed under the License is distributed on an \"AS IS\" BASIS,\n- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- See the License for the specific language governing permissions and\n- limitations under the License.\n- *******************************************************************************\n-diff --git a/src/cpu/aarch64/acl_thread.cpp b/src/cpu/aarch64/acl_thread.cpp\n-index fd2c76d01..bd7bed837 100644\n---- a/src/cpu/aarch64/acl_thread.cpp\n-+++ b/src/cpu/aarch64/acl_thread.cpp\n-@@ -55,14 +55,17 @@ void acl_set_benchmark_scheduler_default() {\n- #endif\n- \n- #if DNNL_CPU_THREADING_RUNTIME == DNNL_RUNTIME_THREADPOOL\n--void acl_set_tp_scheduler() {\n--    static std::once_flag flag_once;\n--    // Create threadpool scheduler\n--    std::shared_ptr<arm_compute::IScheduler> threadpool_scheduler\n--            = std::make_unique<ThreadpoolScheduler>();\n-+void acl_set_tp_scheduler(int intra_threads = 0) {\n-+    static thread_local std::once_flag flag_once;\n-     // set CUSTOM scheduler in ACL\n-     std::call_once(flag_once,\n--            [&]() { arm_compute::Scheduler::set(threadpool_scheduler); });\n-+            [&]() {\n-+                    // Create threadpool scheduler\n-+                    std::shared_ptr<arm_compute::IScheduler> threadpool_scheduler\n-+                        = std::make_unique<ThreadpoolScheduler>();\n-+                    threadpool_scheduler->set_num_threads(intra_threads);\n-+\n-+                    arm_compute::Scheduler::set(threadpool_scheduler); });\n- }\n- \n- void acl_set_threadpool_num_threads() {\n-@@ -102,14 +105,6 @@ void set_acl_threading() {\n-         acl_set_benchmark_scheduler_default();\n-     }\n- #endif\n--#if DNNL_CPU_THREADING_RUNTIME == DNNL_RUNTIME_THREADPOOL\n--    if (verbose_has_profile_externals()) {\n--        acl_set_tp_benchmark_scheduler();\n--    } else {\n--        acl_set_tp_scheduler();\n--    }\n--\n--#endif\n- }\n- \n- } // namespace acl_thread_utils\n-diff --git a/src/cpu/aarch64/acl_thread.hpp b/src/cpu/aarch64/acl_thread.hpp\n-index f073376e6..654a2aa5d 100644\n---- a/src/cpu/aarch64/acl_thread.hpp\n-+++ b/src/cpu/aarch64/acl_thread.hpp\n-@@ -40,7 +40,7 @@ void acl_set_benchmark_scheduler_default();\n- \n- #if DNNL_CPU_THREADING_RUNTIME == DNNL_RUNTIME_THREADPOOL\n- // Retrieve threadpool size during primitive execution and set ThreadpoolScheduler num_threads\n--void acl_set_tp_scheduler();\n-+void acl_set_tp_scheduler(int intra_threads);\n- void acl_set_threadpool_num_threads();\n- // Swap BenchmarkScheduler for custom scheduler builds (i.e. ThreadPoolScheduler) for DNNL_VERBOSE=profile,profile_externals\n- void acl_set_tp_benchmark_scheduler();\n-diff --git a/src/cpu/aarch64/acl_threadpool_scheduler.cpp b/src/cpu/aarch64/acl_threadpool_scheduler.cpp\n-index 439ca862e..6656c37a5 100644\n---- a/src/cpu/aarch64/acl_threadpool_scheduler.cpp\n-+++ b/src/cpu/aarch64/acl_threadpool_scheduler.cpp\n-@@ -102,8 +102,6 @@ void ThreadpoolScheduler::schedule_op(ICPPKernel *kernel, const Hints &hints,\n- void ThreadpoolScheduler::run_workloads(\n-         std::vector<arm_compute::IScheduler::Workload> &workloads) {\n- \n--    arm_compute::lock_guard<std::mutex> lock(this->_run_workloads_mutex);\n--\n-     const unsigned int num_threads\n-             = std::min(static_cast<unsigned int>(_num_threads),\n-                     static_cast<unsigned int>(workloads.size()));\n-diff --git a/src/cpu/cpu_engine.cpp b/src/cpu/cpu_engine.cpp\n-index 0bfec3871..7207b2b60 100644\n---- a/src/cpu/cpu_engine.cpp\n-+++ b/src/cpu/cpu_engine.cpp\n-@@ -47,6 +47,7 @@ status_t cpu_engine_t::create_stream(stream_t **stream, unsigned flags) {\n- #if DNNL_CPU_RUNTIME == DNNL_RUNTIME_THREADPOOL\n- status_t cpu_engine_t::create_stream(stream_t **stream,\n-         dnnl::threadpool_interop::threadpool_iface *threadpool) {\n-+    dnnl::impl::cpu::aarch64::acl_thread_utils::acl_set_tp_scheduler(threadpool->get_num_threads());\n-     return safe_ptr_assign<stream_t>(\n-             *stream, new cpu_stream_t(this, threadpool));\n- }"
        },
        {
            "sha": "3a33af153e917c7d262e192b6136bc800bf00464",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_threadcap.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 43,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_threadcap.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_threadcap.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_threadcap.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,43 +0,0 @@\n- *******************************************************************************\n- Copyright 2023 Arm Limited and affiliates.\n- SPDX-License-Identifier: Apache-2.0\n-\n- Licensed under the Apache License, Version 2.0 (the \"License\");\n- you may not use this file except in compliance with the License.\n- You may obtain a copy of the License at\n-\n-     http://www.apache.org/licenses/LICENSE-2.0\n-\n- Unless required by applicable law or agreed to in writing, software\n- distributed under the License is distributed on an \"AS IS\" BASIS,\n- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- See the License for the specific language governing permissions and\n- limitations under the License.\n- *******************************************************************************\n-diff --git a/src/cpu/aarch64/acl_thread.cpp b/src/cpu/aarch64/acl_thread.cpp\n-index fd2c76d01..2d7c76d48 100644\n---- a/src/cpu/aarch64/acl_thread.cpp\n-+++ b/src/cpu/aarch64/acl_thread.cpp\n-@@ -17,6 +17,8 @@\n- #include \"cpu/aarch64/acl_thread.hpp\"\n- #if DNNL_CPU_THREADING_RUNTIME == DNNL_RUNTIME_THREADPOOL\n- #include \"cpu/aarch64/acl_threadpool_scheduler.hpp\"\n-+#elif DNNL_CPU_THREADING_RUNTIME == DNNL_RUNTIME_OMP\n-+#include <thread>\n- #endif\n- #include \"cpu/aarch64/acl_benchmark_scheduler.hpp\"\n- \n-@@ -30,9 +32,10 @@ namespace acl_thread_utils {\n- #if DNNL_CPU_THREADING_RUNTIME == DNNL_RUNTIME_OMP\n- void acl_thread_bind() {\n-     static std::once_flag flag_once;\n--    // The threads in Compute Library are bound for the cores 0..max_threads-1\n--    // dnnl_get_max_threads() returns OMP_NUM_THREADS\n--    const int max_threads = dnnl_get_max_threads();\n-+    // Cap the number of threads to 90% of the total core count\n-+    // to ensure Compute Library doesn't use too much resource\n-+    int capped_threads = (int)std::floor(0.9*std::thread::hardware_concurrency());\n-+    const int max_threads = std::min(capped_threads, dnnl_get_max_threads());\n-     // arm_compute::Scheduler does not support concurrent access thus a\n-     // workaround here restricts it to only one call\n-     std::call_once(flag_once, [&]() {"
        },
        {
            "sha": "78dd2462094cc582ec24d6fc1c04dbc06fe8341e",
            "filename": "third_party/xla/third_party/mkl_dnn/onednn_acl_threadpool_default_max.patch",
            "status": "added",
            "additions": 178,
            "deletions": 0,
            "changes": 178,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_threadpool_default_max.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_threadpool_default_max.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fmkl_dnn%2Fonednn_acl_threadpool_default_max.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,178 @@\n+# Copyright 2025 The OpenXLA Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+diff --git a/src/cpu/aarch64/acl_thread.cpp b/src/cpu/aarch64/acl_thread.cpp\n+index 53175a05f9..89731cb356 100644\n+--- a/src/cpu/aarch64/acl_thread.cpp\n++++ b/src/cpu/aarch64/acl_thread.cpp\n+@@ -1,5 +1,5 @@\n+ /*******************************************************************************\n+-* Copyright 2022-2024 Arm Ltd. and affiliates\n++* Copyright 2022-2025 Arm Ltd. and affiliates\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+@@ -83,17 +83,20 @@ void acl_set_threadpool_num_threads() {\n+ }\n+ // Swap BenchmarkScheduler for custom scheduler builds (i.e. ThreadPoolScheduler)\n+ void acl_set_tp_benchmark_scheduler() {\n+-    static std::once_flag flag_once;\n+-    // Create threadpool scheduler\n+-    std::unique_ptr<arm_compute::IScheduler> threadpool_scheduler\n+-            = std::make_unique<ThreadpoolScheduler>();\n+-    arm_compute::IScheduler *_real_scheduler = nullptr;\n+-    _real_scheduler = threadpool_scheduler.release();\n+-    // Create benchmark scheduler and set TP as real scheduler\n+-    std::shared_ptr<arm_compute::IScheduler> benchmark_scheduler\n+-            = std::make_unique<BenchmarkScheduler>(*_real_scheduler);\n+-    std::call_once(flag_once,\n+-            [&]() { arm_compute::Scheduler::set(benchmark_scheduler); });\n++    static thread_local std::once_flag flag_once;\n++    std::call_once(flag_once, [&]() {\n++        // Create threadpool scheduler\n++        std::unique_ptr<arm_compute::IScheduler> threadpool_scheduler\n++                = std::make_unique<ThreadpoolScheduler>();\n++        arm_compute::IScheduler *_real_scheduler = nullptr;\n++        _real_scheduler = threadpool_scheduler.release();\n++\n++        // Create benchmark scheduler and set TP as real scheduler\n++        std::shared_ptr<arm_compute::IScheduler> benchmark_scheduler\n++                = std::make_unique<BenchmarkScheduler>(*_real_scheduler);\n++\n++        arm_compute::Scheduler::set(benchmark_scheduler);\n++    });\n+ }\n+ #endif\n+ \n+diff --git a/src/cpu/aarch64/acl_threadpool_scheduler.cpp b/src/cpu/aarch64/acl_threadpool_scheduler.cpp\n+index 30910398d9..34cf44b7e2 100644\n+--- a/src/cpu/aarch64/acl_threadpool_scheduler.cpp\n++++ b/src/cpu/aarch64/acl_threadpool_scheduler.cpp\n+@@ -1,5 +1,5 @@\n+ /*******************************************************************************\n+-* Copyright 2022-2024 Arm Ltd. and affiliates\n++* Copyright 2022-2025 Arm Ltd. and affiliates\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+@@ -18,24 +18,17 @@\n+ \n+ #if DNNL_CPU_THREADING_RUNTIME == DNNL_RUNTIME_THREADPOOL\n+ \n+-#include \"cpu/aarch64/acl_thread.hpp\"\n+-\n+ #include \"common/counting_barrier.hpp\"\n+ #include \"common/dnnl_thread.hpp\"\n++#include \"cpu/aarch64/acl_thread.hpp\"\n+ \n+ #include \"arm_compute/core/CPP/ICPPKernel.h\"\n+ #include \"arm_compute/core/Error.h\"\n+-#include \"arm_compute/core/Helpers.h\"\n+-#include \"arm_compute/core/Utils.h\"\n+ #include \"arm_compute/runtime/IScheduler.h\"\n+ \n+-// BARRIER\n+ #include <atomic>\n+ #include <cassert>\n+-#include <chrono>\n+ #include <mutex>\n+-#include <thread>\n+-#include <condition_variable>\n+ \n+ namespace dnnl {\n+ namespace impl {\n+@@ -51,7 +44,7 @@ public:\n+ \n+     /// Function to check the next element in the range if there is one.\n+     bool get_next(unsigned int &next) {\n+-        next = atomic_fetch_add_explicit(\n++        next = std::atomic_fetch_add_explicit(\n+                 &_atomic_counter, 1u, std::memory_order_relaxed);\n+         return next < _end;\n+     }\n+@@ -70,11 +63,8 @@ void process_workloads(std::vector<IScheduler::Workload> &workloads,\n+     } while (feeder.get_next(workload_index));\n+ }\n+ \n+-ThreadpoolScheduler::ThreadpoolScheduler() {\n+-    using namespace dnnl::impl::threadpool_utils;\n+-    // Set number of threads to one when threadpool is not available.\n+-    _num_threads = get_active_threadpool() == nullptr ? 1 : num_threads_hint();\n+-}\n++ThreadpoolScheduler::ThreadpoolScheduler()\n++    : _num_threads(dnnl_get_max_threads()) {}\n+ \n+ ThreadpoolScheduler::~ThreadpoolScheduler() = default;\n+ \n+@@ -83,8 +73,8 @@ unsigned int ThreadpoolScheduler::num_threads() const {\n+ }\n+ \n+ void ThreadpoolScheduler::set_num_threads(unsigned int num_threads) {\n+-    arm_compute::lock_guard<std::mutex> lock(this->_run_workloads_mutex);\n+-    _num_threads = num_threads == 0 ? num_threads_hint() : num_threads;\n++    std::lock_guard<std::mutex> lock(this->_mtx);\n++    _num_threads = num_threads == 0 ? dnnl_get_max_threads() : num_threads;\n+ }\n+ \n+ void ThreadpoolScheduler::schedule(ICPPKernel *kernel, const Hints &hints) {\n+@@ -104,7 +94,7 @@ void ThreadpoolScheduler::schedule_op(ICPPKernel *kernel, const Hints &hints,\n+ void ThreadpoolScheduler::run_workloads(\n+         std::vector<arm_compute::IScheduler::Workload> &workloads) {\n+ \n+-    arm_compute::lock_guard<std::mutex> lock(this->_run_workloads_mutex);\n++    std::lock_guard<std::mutex> lock(this->_mtx);\n+ \n+     const unsigned int num_threads\n+             = std::min(static_cast<unsigned int>(_num_threads),\n+diff --git a/src/cpu/aarch64/acl_threadpool_scheduler.hpp b/src/cpu/aarch64/acl_threadpool_scheduler.hpp\n+index e9ba21c803..384dfec1b9 100644\n+--- a/src/cpu/aarch64/acl_threadpool_scheduler.hpp\n++++ b/src/cpu/aarch64/acl_threadpool_scheduler.hpp\n+@@ -1,5 +1,5 @@\n+ /*******************************************************************************\n+-* Copyright 2022 Arm Ltd. and affiliates\n++* Copyright 2022, 2025 Arm Ltd. and affiliates\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+@@ -22,7 +22,8 @@\n+ #if DNNL_CPU_THREADING_RUNTIME == DNNL_RUNTIME_THREADPOOL\n+ \n+ #include \"arm_compute/runtime/IScheduler.h\"\n+-#include \"support/Mutex.h\"\n++\n++#include <mutex>\n+ \n+ namespace dnnl {\n+ namespace impl {\n+@@ -32,7 +33,7 @@ namespace aarch64 {\n+ class ThreadpoolScheduler final : public arm_compute::IScheduler {\n+ public:\n+     ThreadpoolScheduler();\n+-    ~ThreadpoolScheduler();\n++    ~ThreadpoolScheduler() override;\n+ \n+     /// Sets the number of threads the scheduler will use to run the kernels.\n+     void set_num_threads(unsigned int num_threads) override;\n+@@ -54,8 +55,8 @@ protected:\n+     void run_workloads(std::vector<Workload> &workloads) override;\n+ \n+ private:\n+-    uint _num_threads {};\n+-    arm_compute::Mutex _run_workloads_mutex {};\n++    unsigned int _num_threads {};\n++    std::mutex _mtx;\n+ };\n+ \n+ } // namespace aarch64\n\\ No newline at end of file"
        },
        {
            "sha": "5100d91c25ad164a583cf508e11d7e784e650114",
            "filename": "third_party/xla/third_party/protobuf/protobuf-6.31.1.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 201,
            "changes": 201,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fprotobuf%2Fprotobuf-6.31.1.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Fprotobuf%2Fprotobuf-6.31.1.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fprotobuf%2Fprotobuf-6.31.1.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,201 +0,0 @@\n-diff --git a/BUILD.bazel b/BUILD.bazel\n---- a/BUILD.bazel\n-+++ b/BUILD.bazel\n-@@ -555,7 +555,8 @@ proto_lang_toolchain(\n-         \"//:cpp_features_proto\",\n-         \"//:descriptor_proto\",\n-     ],\n--    command_line = \"--cpp_out=$(OUT)\",\n-+    command_line = \"--cpp_out=dllexport_decl=PROTOBUF_EXPORT:$(OUT)\",\n-+#    command_line = \"--cpp_out=$(OUT)\",\n-     runtime = \"//src/google/protobuf\",\n-     visibility = [\"//visibility:public\"],\n- )\n-diff --git a/build_defs/BUILD.bazel b/build_defs/BUILD.bazel\n---- a/build_defs/BUILD.bazel\n-+++ b/build_defs/BUILD.bazel\n-@@ -1,6 +1,7 @@\n- # Internal Starlark definitions for Protobuf.\n- \n- load(\"@bazel_skylib//lib:selects.bzl\", \"selects\")\n-+load(\"@bazel_skylib//rules:common_settings.bzl\", \"bool_flag\")\n- load(\"@rules_pkg//pkg:mappings.bzl\", \"pkg_files\", \"strip_prefix\")\n- load(\"//bazel:cc_proto_library.bzl\", starlark_cc_proto_library = \"cc_proto_library\")\n- load(\":cc_proto_blacklist_test.bzl\", \"cc_proto_blacklist_test\")\n-@@ -13,6 +14,20 @@ package(\n-     ],\n- )\n- \n-+bool_flag(\n-+    name = \"use_dlls\",\n-+    build_setting_default = False,\n-+    visibility = [\"//visibility:public\"],\n-+)\n-+\n-+config_setting(\n-+    name = \"config_use_dlls\",\n-+    flag_values = {\n-+        \":use_dlls\": \"True\",\n-+    },\n-+    visibility = [\"//visibility:public\"],\n-+)\n-+\n- create_compiler_config_setting(\n-     name = \"config_msvc_cl\",\n-     value = \"msvc-cl\",\n-diff --git a/python/dist/system_python.bzl b/python/dist/system_python.bzl\n---- a/python/dist/system_python.bzl\n-+++ b/python/dist/system_python.bzl\n-@@ -73,11 +73,10 @@ load(\"@bazel_skylib//lib:selects.bzl\", \"selects\")\n- load(\"@bazel_skylib//rules:common_settings.bzl\", \"string_flag\")\n- load(\"@bazel_tools//tools/python:toolchain.bzl\", \"py_runtime_pair\")\n- \n--cc_library(\n--   name = \"python_headers\",\n--   hdrs = glob([\"python/**/*.h\"], allow_empty = True),\n--   includes = [\"python\"],\n--   visibility = [\"//visibility:public\"],\n-+alias(\n-+    name = \"python_headers\",\n-+    actual = \"@python//:python_headers\",\n-+    visibility = [\"//visibility:public\"],\n- )\n- \n- string_flag(\n-@@ -219,7 +218,7 @@ def _system_python_impl(repository_ctx):\n-     python3 = repository_ctx.which(\"python3\")\n-     python_version = _get_python_version(repository_ctx)\n- \n--    if path and python_version[0] == \"3\":\n-+    if False:\n-         _populate_package(repository_ctx, path, python3, python_version)\n-     else:\n-         # buildifier: disable=print\n-diff --git a/python/google/protobuf/__init__.py b/python/google/protobuf/__init__.py\n---- a/python/google/protobuf/__init__.py\n-+++ b/python/google/protobuf/__init__.py\n-@@ -8,3 +8,9 @@\n- # Copyright 2007 Google Inc. All Rights Reserved.\n- \n- __version__ = '6.31.1'\n-+\n-+if __name__ != '__main__':\n-+  try:\n-+    __import__('pkg_resources').declare_namespace(__name__)\n-+  except ImportError:\n-+    __path__ = __import__('pkgutil').extend_path(__path__, __name__)\n-diff --git a/src/google/protobuf/BUILD.bazel b/src/google/protobuf/BUILD.bazel\n---- a/src/google/protobuf/BUILD.bazel\n-+++ b/src/google/protobuf/BUILD.bazel\n-@@ -525,6 +525,13 @@ cc_library(\n-         \"serial_arena.h\",\n-         \"thread_safe_arena.h\",\n-     ],\n-+    local_defines = select({\n-+        \"//build_defs:config_use_dlls\": [\n-+            \"PROTOBUF_USE_DLLS\",\n-+            \"LIBPROTOBUF_EXPORTS\",\n-+        ],\n-+        \"//conditions:default\": [],\n-+    }),\n-     strip_include_prefix = \"/src\",\n-     visibility = [\n-         \"//:__subpackages__\",\n-@@ -657,7 +664,15 @@ cc_library(\n-         \"serial_arena.h\",\n-         \"thread_safe_arena.h\",\n-         \"wire_format_lite.h\",\n-+        \"port.h\",\n-     ],\n-+    local_defines = select({\n-+        \"//build_defs:config_use_dlls\": [\n-+            \"PROTOBUF_USE_DLLS\",\n-+            \"LIBPROTOBUF_EXPORTS\",\n-+        ],\n-+        \"//conditions:default\": [],\n-+    }),\n-     copts = COPTS + select({\n-         \"//build_defs:config_msvc\": [],\n-         \"//conditions:default\": [\n-@@ -767,6 +782,13 @@ cc_library(\n-     ],\n-     hdrs = PROTOBUF_HEADERS,\n-     copts = COPTS,\n-+    local_defines = select({\n-+        \"//build_defs:config_use_dlls\": [\n-+            \"PROTOBUF_USE_DLLS\",\n-+            \"LIBPROTOBUF_EXPORTS\",\n-+        ],\n-+        \"//conditions:default\": [],\n-+    }),\n-     linkopts = LINK_OPTS,\n-     strip_include_prefix = \"/src\",\n-     visibility = [\n-diff --git a/src/google/protobuf/arena.cc b/src/google/protobuf/arena.cc\n---- a/src/google/protobuf/arena.cc\n-+++ b/src/google/protobuf/arena.cc\n-@@ -547,7 +547,7 @@ ThreadSafeArena::ThreadCache& ThreadSafeArena::thread_cache() {\n-       new internal::ThreadLocalStorage<ThreadCache>();\n-   return *thread_cache_->Get();\n- }\n--#elif defined(PROTOBUF_USE_DLLS) && defined(_WIN32)\n-+#elif defined(_WIN32)\n- ThreadSafeArena::ThreadCache& ThreadSafeArena::thread_cache() {\n-   static PROTOBUF_THREAD_LOCAL ThreadCache thread_cache;\n-   return thread_cache;\n-diff --git a/src/google/protobuf/io/BUILD.bazel b/src/google/protobuf/io/BUILD.bazel\n---- a/src/google/protobuf/io/BUILD.bazel\n-+++ b/src/google/protobuf/io/BUILD.bazel\n-@@ -22,6 +22,13 @@ cc_library(\n-         \"zero_copy_stream_impl.h\",\n-         \"zero_copy_stream_impl_lite.h\",\n-     ],\n-+    local_defines = select({\n-+        \"//build_defs:config_use_dlls\": [\n-+            \"PROTOBUF_USE_DLLS\",\n-+            \"LIBPROTOBUF_EXPORTS\",\n-+        ],\n-+        \"//conditions:default\": [],\n-+    }),\n-     copts = COPTS,\n-     strip_include_prefix = \"/src\",\n-     deps = [\n-diff --git a/src/google/protobuf/message_lite.h b/src/google/protobuf/message_lite.h\n---- a/src/google/protobuf/message_lite.h\n-+++ b/src/google/protobuf/message_lite.h\n-@@ -282,7 +282,11 @@ template <typename T>\n- using MessageTraits = decltype(MessageTraitsImpl::value<T>);\n- \n- struct EnumTraitsImpl {\n-+#ifdef __CUDACC__\n-+  struct Undefined{};\n-+#else\n-   struct Undefined;\n-+#endif\n-   template <typename T>\n-   static Undefined value;\n- };\n-diff --git a/src/google/protobuf/port_def.inc b/src/google/protobuf/port_def.inc\n---- a/src/google/protobuf/port_def.inc\n-+++ b/src/google/protobuf/port_def.inc\n-@@ -421,7 +421,7 @@ static_assert(PROTOBUF_ABSL_MIN(20230125, 3),\n- #endif\n- \n- // Lexan sets both MSV_VER and clang, so handle it with the clang path.\n--#if defined(_MSC_VER) && !defined(__clang__)\n-+#if defined(_MSC_VER)\n- // MSVC 17 currently seems to raise an error about constant-initialized pointers.\n- # if PROTOBUF_MSC_VER_MIN(1930)\n- #  define PROTOBUF_CONSTINIT\n-diff --git a/src/google/protobuf/thread_safe_arena.h b/src/google/protobuf/thread_safe_arena.h\n---- a/src/google/protobuf/thread_safe_arena.h\n-+++ b/src/google/protobuf/thread_safe_arena.h\n-@@ -249,7 +249,7 @@ class PROTOBUF_EXPORT ThreadSafeArena {\n-   // iOS does not support __thread keyword so we use a custom thread local\n-   // storage class we implemented.\n-   static ThreadCache& thread_cache();\n--#elif defined(PROTOBUF_USE_DLLS) && defined(_WIN32)\n-+#elif defined(_WIN32)\n-   // Thread local variables cannot be exposed through MSVC DLL interface but we\n-   // can wrap them in static functions.\n-   static ThreadCache& thread_cache();"
        },
        {
            "sha": "d02ba25380563601a1511bf80fd9ae69cc3f36cc",
            "filename": "third_party/xla/third_party/protobuf/protobuf.patch",
            "status": "modified",
            "additions": 104,
            "deletions": 101,
            "changes": 205,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fprotobuf%2Fprotobuf.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fprotobuf%2Fprotobuf.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fprotobuf%2Fprotobuf.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1,18 +1,19 @@\n-diff --git a/src/google/protobuf/map_field.h b/src/google/protobuf/map_field.h\n---- a/src/google/protobuf/map_field.h\t(revision 5fda5abda3dee5f7a102c85860594bff8d8610bd)\n-+++ b/src/google/protobuf/map_field.h\t(date 1748033655723)\n-@@ -710,7 +710,7 @@\n-   typedef MapField<T, Key, Value, kKeyFieldType, kValueFieldType> MapFieldType;\n- };\n-\n--class PROTOBUF_EXPORT DynamicMapField final\n-+class DynamicMapField final\n-     : public TypeDefinedMapFieldBase<MapKey, MapValueRef> {\n-  public:\n-   explicit DynamicMapField(const Message* default_entry);\n+diff --git a/BUILD.bazel b/BUILD.bazel\n+--- a/BUILD.bazel\n++++ b/BUILD.bazel\n+@@ -555,7 +555,8 @@ proto_lang_toolchain(\n+         \"//:cpp_features_proto\",\n+         \"//:descriptor_proto\",\n+     ],\n+-    command_line = \"--cpp_out=$(OUT)\",\n++    command_line = \"--cpp_out=dllexport_decl=PROTOBUF_EXPORT:$(OUT)\",\n++#    command_line = \"--cpp_out=$(OUT)\",\n+     runtime = \"//src/google/protobuf\",\n+     visibility = [\"//visibility:public\"],\n+ )\n diff --git a/build_defs/BUILD.bazel b/build_defs/BUILD.bazel\n---- a/build_defs/BUILD.bazel\t(revision 5fda5abda3dee5f7a102c85860594bff8d8610bd)\n-+++ b/build_defs/BUILD.bazel\t(date 1748034990268)\n+--- a/build_defs/BUILD.bazel\n++++ b/build_defs/BUILD.bazel\n @@ -1,6 +1,7 @@\n  # Internal Starlark definitions for Protobuf.\n \n@@ -21,7 +22,7 @@ diff --git a/build_defs/BUILD.bazel b/build_defs/BUILD.bazel\n  load(\"@rules_pkg//pkg:mappings.bzl\", \"pkg_files\", \"strip_prefix\")\n  load(\"//bazel:cc_proto_library.bzl\", starlark_cc_proto_library = \"cc_proto_library\")\n  load(\":cc_proto_blacklist_test.bzl\", \"cc_proto_blacklist_test\")\n-@@ -13,6 +14,20 @@\n+@@ -13,6 +14,20 @@ package(\n      ],\n  )\n \n@@ -43,9 +44,9 @@ diff --git a/build_defs/BUILD.bazel b/build_defs/BUILD.bazel\n      name = \"config_msvc_cl\",\n      value = \"msvc-cl\",\n diff --git a/python/dist/system_python.bzl b/python/dist/system_python.bzl\n---- a/python/dist/system_python.bzl\t(revision 5fda5abda3dee5f7a102c85860594bff8d8610bd)\n-+++ b/python/dist/system_python.bzl\t(date 1746939979885)\n-@@ -73,11 +73,10 @@\n+--- a/python/dist/system_python.bzl\n++++ b/python/dist/system_python.bzl\n+@@ -73,11 +73,10 @@ load(\"@bazel_skylib//lib:selects.bzl\", \"selects\")\n  load(\"@bazel_skylib//rules:common_settings.bzl\", \"string_flag\")\n  load(\"@bazel_tools//tools/python:toolchain.bzl\", \"py_runtime_pair\")\n \n@@ -61,7 +62,7 @@ diff --git a/python/dist/system_python.bzl b/python/dist/system_python.bzl\n  )\n \n  string_flag(\n-@@ -219,7 +218,7 @@\n+@@ -219,7 +218,7 @@ def _system_python_impl(repository_ctx):\n      python3 = repository_ctx.which(\"python3\")\n      python_version = _get_python_version(repository_ctx)\n \n@@ -70,76 +71,23 @@ diff --git a/python/dist/system_python.bzl b/python/dist/system_python.bzl\n          _populate_package(repository_ctx, path, python3, python_version)\n      else:\n          # buildifier: disable=print\n-diff --git a/src/google/protobuf/arena.cc b/src/google/protobuf/arena.cc\n---- a/src/google/protobuf/arena.cc\t(revision 5fda5abda3dee5f7a102c85860594bff8d8610bd)\n-+++ b/src/google/protobuf/arena.cc\t(date 1748042877047)\n-@@ -554,7 +554,7 @@\n-       new internal::ThreadLocalStorage<ThreadCache>();\n-   return *thread_cache_->Get();\n- }\n--#elif defined(PROTOBUF_USE_DLLS) && defined(_WIN32)\n-+#elif defined(_WIN32)\n- ThreadSafeArena::ThreadCache& ThreadSafeArena::thread_cache() {\n-   static PROTOBUF_THREAD_LOCAL ThreadCache thread_cache;\n-   return thread_cache;\n-diff --git a/BUILD.bazel b/BUILD.bazel\n---- a/BUILD.bazel\t(revision 5fda5abda3dee5f7a102c85860594bff8d8610bd)\n-+++ b/BUILD.bazel\t(date 1746940994484)\n-@@ -424,7 +424,8 @@\n-         \"//:cpp_features_proto\",\n-         \"//:descriptor_proto\",\n-     ],\n--    command_line = \"--cpp_out=$(OUT)\",\n-+    command_line = \"--cpp_out=dllexport_decl=PROTOBUF_EXPORT:$(OUT)\",\n-+#    command_line = \"--cpp_out=$(OUT)\",\n-     runtime = \"//src/google/protobuf\",\n-     visibility = [\"//visibility:public\"],\n- )\n-diff --git a/src/google/protobuf/io/BUILD.bazel b/src/google/protobuf/io/BUILD.bazel\n---- a/src/google/protobuf/io/BUILD.bazel\t(revision 5fda5abda3dee5f7a102c85860594bff8d8610bd)\n-+++ b/src/google/protobuf/io/BUILD.bazel\t(date 1748038681727)\n-@@ -22,6 +22,13 @@\n-         \"zero_copy_stream_impl.h\",\n-         \"zero_copy_stream_impl_lite.h\",\n-     ],\n-+    local_defines = select({\n-+        \"//build_defs:config_use_dlls\": [\n-+            \"PROTOBUF_USE_DLLS\",\n-+            \"LIBPROTOBUF_EXPORTS\",\n-+        ],\n-+        \"//conditions:default\": [],\n-+    }),\n-     copts = COPTS,\n-     strip_include_prefix = \"/src\",\n-     deps = [\n-diff --git a/src/google/protobuf/port_def.inc b/src/google/protobuf/port_def.inc\n---- a/src/google/protobuf/port_def.inc\t(revision 5fda5abda3dee5f7a102c85860594bff8d8610bd)\n-+++ b/src/google/protobuf/port_def.inc\t(date 1748019340115)\n-@@ -456,7 +456,7 @@\n- #endif\n+diff --git a/python/google/protobuf/__init__.py b/python/google/protobuf/__init__.py\n+--- a/python/google/protobuf/__init__.py\n++++ b/python/google/protobuf/__init__.py\n+@@ -8,3 +8,9 @@\n+ # Copyright 2007 Google Inc. All Rights Reserved.\n \n- // Lexan sets both MSV_VER and clang, so handle it with the clang path.\n--#if defined(_MSC_VER) && !defined(__clang__)\n-+#if defined(_MSC_VER)\n- // MSVC 17 currently seems to raise an error about constant-initialized pointers.\n- # if PROTOBUF_MSC_VER_MIN(1930)\n- #  define PROTOBUF_CONSTINIT\n-diff --git a/src/google/protobuf/thread_safe_arena.h b/src/google/protobuf/thread_safe_arena.h\n---- a/src/google/protobuf/thread_safe_arena.h\t(revision 5fda5abda3dee5f7a102c85860594bff8d8610bd)\n-+++ b/src/google/protobuf/thread_safe_arena.h\t(date 1748042886641)\n-@@ -248,7 +248,7 @@\n-   // iOS does not support __thread keyword so we use a custom thread local\n-   // storage class we implemented.\n-   static ThreadCache& thread_cache();\n--#elif defined(PROTOBUF_USE_DLLS) && defined(_WIN32)\n-+#elif defined(_WIN32)\n-   // Thread local variables cannot be exposed through MSVC DLL interface but we\n-   // can wrap them in static functions.\n-   static ThreadCache& thread_cache();\n+ __version__ = '6.31.1'\n++\n++if __name__ != '__main__':\n++  try:\n++    __import__('pkg_resources').declare_namespace(__name__)\n++  except ImportError:\n++    __path__ = __import__('pkgutil').extend_path(__path__, __name__)\n diff --git a/src/google/protobuf/BUILD.bazel b/src/google/protobuf/BUILD.bazel\n---- a/src/google/protobuf/BUILD.bazel\t(revision 5fda5abda3dee5f7a102c85860594bff8d8610bd)\n-+++ b/src/google/protobuf/BUILD.bazel\t(date 1748038617126)\n-@@ -411,6 +411,13 @@\n+--- a/src/google/protobuf/BUILD.bazel\n++++ b/src/google/protobuf/BUILD.bazel\n+@@ -525,6 +525,13 @@ cc_library(\n          \"serial_arena.h\",\n          \"thread_safe_arena.h\",\n      ],\n@@ -153,7 +101,7 @@ diff --git a/src/google/protobuf/BUILD.bazel b/src/google/protobuf/BUILD.bazel\n      strip_include_prefix = \"/src\",\n      visibility = [\n          \"//:__subpackages__\",\n-@@ -509,7 +516,15 @@\n+@@ -657,7 +664,15 @@ cc_library(\n          \"serial_arena.h\",\n          \"thread_safe_arena.h\",\n          \"wire_format_lite.h\",\n@@ -169,7 +117,7 @@ diff --git a/src/google/protobuf/BUILD.bazel b/src/google/protobuf/BUILD.bazel\n      copts = COPTS + select({\n          \"//build_defs:config_msvc\": [],\n          \"//conditions:default\": [\n-@@ -615,6 +630,13 @@\n+@@ -767,6 +782,13 @@ cc_library(\n      ],\n      hdrs = PROTOBUF_HEADERS,\n      copts = COPTS,\n@@ -183,16 +131,71 @@ diff --git a/src/google/protobuf/BUILD.bazel b/src/google/protobuf/BUILD.bazel\n      linkopts = LINK_OPTS,\n      strip_include_prefix = \"/src\",\n      visibility = [\n-diff --git a/python/google/protobuf/__init__.py b/python/google/protobuf/__init__.py\n---- a/python/google/protobuf/__init__.py\t(revision 5fda5abda3dee5f7a102c85860594bff8d8610bd)\n-+++ b/python/google/protobuf/__init__.py\t(date 1746939979902)\n-@@ -8,3 +8,9 @@\n- # Copyright 2007 Google Inc. All Rights Reserved.\n+diff --git a/src/google/protobuf/arena.cc b/src/google/protobuf/arena.cc\n+--- a/src/google/protobuf/arena.cc\n++++ b/src/google/protobuf/arena.cc\n+@@ -547,7 +547,7 @@ ThreadSafeArena::ThreadCache& ThreadSafeArena::thread_cache() {\n+       new internal::ThreadLocalStorage<ThreadCache>();\n+   return *thread_cache_->Get();\n+ }\n+-#elif defined(PROTOBUF_USE_DLLS) && defined(_WIN32)\n++#elif defined(_WIN32)\n+ ThreadSafeArena::ThreadCache& ThreadSafeArena::thread_cache() {\n+   static PROTOBUF_THREAD_LOCAL ThreadCache thread_cache;\n+   return thread_cache;\n+diff --git a/src/google/protobuf/io/BUILD.bazel b/src/google/protobuf/io/BUILD.bazel\n+--- a/src/google/protobuf/io/BUILD.bazel\n++++ b/src/google/protobuf/io/BUILD.bazel\n+@@ -22,6 +22,13 @@ cc_library(\n+         \"zero_copy_stream_impl.h\",\n+         \"zero_copy_stream_impl_lite.h\",\n+     ],\n++    local_defines = select({\n++        \"//build_defs:config_use_dlls\": [\n++            \"PROTOBUF_USE_DLLS\",\n++            \"LIBPROTOBUF_EXPORTS\",\n++        ],\n++        \"//conditions:default\": [],\n++    }),\n+     copts = COPTS,\n+     strip_include_prefix = \"/src\",\n+     deps = [\n+diff --git a/src/google/protobuf/message_lite.h b/src/google/protobuf/message_lite.h\n+--- a/src/google/protobuf/message_lite.h\n++++ b/src/google/protobuf/message_lite.h\n+@@ -282,7 +282,11 @@ template <typename T>\n+ using MessageTraits = decltype(MessageTraitsImpl::value<T>);\n \n- __version__ = '5.28.3'\n-+\n-+if __name__ != '__main__':\n-+  try:\n-+    __import__('pkg_resources').declare_namespace(__name__)\n-+  except ImportError:\n-+    __path__ = __import__('pkgutil').extend_path(__path__, __name__)\n+ struct EnumTraitsImpl {\n++#ifdef __CUDACC__\n++  struct Undefined{};\n++#else\n+   struct Undefined;\n++#endif\n+   template <typename T>\n+   static Undefined value;\n+ };\n+diff --git a/src/google/protobuf/port_def.inc b/src/google/protobuf/port_def.inc\n+--- a/src/google/protobuf/port_def.inc\n++++ b/src/google/protobuf/port_def.inc\n+@@ -421,7 +421,7 @@ static_assert(PROTOBUF_ABSL_MIN(20230125, 3),\n+ #endif\n+\n+ // Lexan sets both MSV_VER and clang, so handle it with the clang path.\n+-#if defined(_MSC_VER) && !defined(__clang__)\n++#if defined(_MSC_VER)\n+ // MSVC 17 currently seems to raise an error about constant-initialized pointers.\n+ # if PROTOBUF_MSC_VER_MIN(1930)\n+ #  define PROTOBUF_CONSTINIT\n+diff --git a/src/google/protobuf/thread_safe_arena.h b/src/google/protobuf/thread_safe_arena.h\n+--- a/src/google/protobuf/thread_safe_arena.h\n++++ b/src/google/protobuf/thread_safe_arena.h\n+@@ -249,7 +249,7 @@ class PROTOBUF_EXPORT ThreadSafeArena {\n+   // iOS does not support __thread keyword so we use a custom thread local\n+   // storage class we implemented.\n+   static ThreadCache& thread_cache();\n+-#elif defined(PROTOBUF_USE_DLLS) && defined(_WIN32)\n++#elif defined(_WIN32)\n+   // Thread local variables cannot be exposed through MSVC DLL interface but we\n+   // can wrap them in static functions.\n+   static ThreadCache& thread_cache();"
        },
        {
            "sha": "cc558415f2b3d22e6e29586e495b47e8efc9be5a",
            "filename": "third_party/xla/third_party/raft/BUILD",
            "status": "added",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fraft%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1 @@\n+# copybara:uncomment package(default_applicable_licenses = [\"//third_party/tensorflow:license\"])"
        },
        {
            "sha": "fff854a35a94e274b392185d9f6292cecefe0e18",
            "filename": "third_party/xla/third_party/raft/logger_macros.hpp.patch",
            "status": "added",
            "additions": 70,
            "deletions": 0,
            "changes": 70,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Flogger_macros.hpp.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Flogger_macros.hpp.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fraft%2Flogger_macros.hpp.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,70 @@\n+--- /dev/null\n++++ b/cpp/include/raft/core/logger_macros.hpp\n+@@ -0,0 +1,67 @@\n++/*\n++ * Copyright (c) 2025, NVIDIA CORPORATION.\n++ *\n++ * Licensed under the Apache License, Version 2.0 (the \"License\");\n++ * you may not use this file except in compliance with the License.\n++ * You may obtain a copy of the License at\n++ *\n++ *     http://www.apache.org/licenses/LICENSE-2.0\n++ *\n++ * Unless required by applicable law or agreed to in writing, software\n++ * distributed under the License is distributed on an \"AS IS\" BASIS,\n++ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n++ * See the License for the specific language governing permissions and\n++ * limitations under the License.\n++ */\n++\n++#pragma once\n++\n++#include <rapids_logger/log_levels.h>\n++\n++// Default to info level if not specified.\n++#if !defined(RAFT_LOG_ACTIVE_LEVEL)\n++#define RAFT_LOG_ACTIVE_LEVEL RAPIDS_LOGGER_LOG_LEVEL_INFO\n++#endif\n++\n++// Macros for easier logging, similar to spdlog.\n++#define RAFT_LOGGER_CALL(logger, level, ...) (logger).log(level, __VA_ARGS__)\n++\n++#if RAFT_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_TRACE\n++#define RAFT_LOG_TRACE(...) \\\n++  RAFT_LOGGER_CALL(raft::default_logger(), rapids_logger::level_enum::trace, __VA_ARGS__)\n++#else\n++#define RAFT_LOG_TRACE(...) (void)0\n++#endif\n++\n++#if RAFT_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_DEBUG\n++#define RAFT_LOG_DEBUG(...) \\\n++  RAFT_LOGGER_CALL(raft::default_logger(), rapids_logger::level_enum::debug, __VA_ARGS__)\n++#else\n++#define RAFT_LOG_DEBUG(...) (void)0\n++#endif\n++\n++#if RAFT_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_INFO\n++#define RAFT_LOG_INFO(...) RAFT_LOGGER_CALL(raft::default_logger(), rapids_logger::level_enum::info, __VA_ARGS__)\n++#else\n++#define RAFT_LOG_INFO(...) (void)0\n++#endif\n++\n++#if RAFT_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_WARN\n++#define RAFT_LOG_WARN(...) RAFT_LOGGER_CALL(raft::default_logger(), rapids_logger::level_enum::warn, __VA_ARGS__)\n++#else\n++#define RAFT_LOG_WARN(...) (void)0\n++#endif\n++\n++#if RAFT_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_ERROR\n++#define RAFT_LOG_ERROR(...) \\\n++  RAFT_LOGGER_CALL(raft::default_logger(), rapids_logger::level_enum::error, __VA_ARGS__)\n++#else\n++#define RAFT_LOG_ERROR(...) (void)0\n++#endif\n++\n++#if RAFT_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_CRITICAL\n++#define RAFT_LOG_CRITICAL(...) \\\n++  RAFT_LOGGER_CALL(raft::default_logger(), rapids_logger::level_enum::critical, __VA_ARGS__)\n++#else\n++#define RAFT_LOG_CRITICAL(...) (void)0\n++#endif"
        },
        {
            "sha": "b40d86d97a60dd659899aa90e9ea6001b2d7aace",
            "filename": "third_party/xla/third_party/raft/raft.BUILD",
            "status": "added",
            "additions": 61,
            "deletions": 0,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Fraft.BUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Fraft.BUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fraft%2Fraft.BUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,61 @@\n+load(\"@local_config_cuda//cuda:build_defs.bzl\", \"cuda_library\")\n+\n+licenses([\"notice\"])  # Apache 2.0\n+\n+exports_files([\"LICENSE\"])\n+\n+BASE_COPTS = [\n+    \"-fexceptions\",\n+    \"-Wno-unused-variable\",\n+    \"-Wno-ctad-maybe-unsupported\",\n+    \"-Wno-reorder-ctor\",\n+    \"-Wno-non-virtual-dtor\",\n+    \"-Wno-uninitialized\",\n+    \"-Wno-pass-failed\",\n+    \"-DLIBCUDACXX_ENABLE_EXPERIMENTAL_MEMORY_RESOURCE\",\n+    \"-DRAFT_SYSTEM_LITTLE_ENDIAN\",\n+]\n+\n+cuda_library(\n+    name = \"raft_matrix\",\n+    copts = BASE_COPTS,\n+    includes = [\n+        \"cpp/include\",\n+        \"cpp/internal\",\n+    ],\n+    textual_hdrs = glob([\n+        \"cpp/include/**/*.cuh\",\n+        \"cpp/include/**/*.hpp\",\n+        \"cpp/internal/**/*.cuh\",\n+    ]) + [\n+        \"cpp/include/raft/thirdparty/mdspan/include/experimental/mdarray\",\n+        \"cpp/include/raft/thirdparty/mdspan/include/experimental/mdspan\",\n+    ],\n+    visibility = [\"//visibility:public\"],\n+    deps = [\n+        \"@kokkos//:mdspan\",\n+        \"@rapids_logger\",\n+        \"@rmm\",\n+    ],\n+)\n+\n+cuda_library(\n+    name = \"select_k_runner\",\n+    srcs = [\"select_k_runner.cu.cc\"],\n+    hdrs = [\"select_k_runner.hpp\"],\n+    copts = BASE_COPTS,\n+    visibility = [\"//visibility:public\"],\n+    deps = [\n+        \":raft_matrix\",\n+    ],\n+)\n+\n+cc_test(\n+    name = \"select_k_smoke_test\",\n+    srcs = [\"select_k_smoke_test.cu.cc\"],\n+    copts = BASE_COPTS,\n+    deps = [\n+        \":select_k_runner\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)"
        },
        {
            "sha": "0dd9d16b649c5ab811ed733c62af7192a4f960b8",
            "filename": "third_party/xla/third_party/raft/select_k_runner.cu.cc.patch",
            "status": "added",
            "additions": 36,
            "deletions": 0,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Fselect_k_runner.cu.cc.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Fselect_k_runner.cu.cc.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fraft%2Fselect_k_runner.cu.cc.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,36 @@\n+--- /dev/null\t2025-08-20 16:29:02.164000374 +0000\n++++ b/select_k_runner.cu.cc\t2025-08-20 20:47:12.000000000 +0000\n+@@ -0,0 +1,33 @@\n++#include <cstdint>\n++#include <optional>\n++\n++#include \"raft/core/resources.hpp\"\n++#include \"raft/matrix/select_k.cuh\"\n++\n++namespace myraft {\n++\n++// Simple wrapper around raft::matrix::select_k\n++void run_select_k(raft::resources const& res, const float* d_data_in,\n++                  float* d_data_out, std::uint32_t* d_indices_out,\n++                  std::uint32_t batch, std::uint32_t n, std::uint32_t k,\n++                  bool select_min, bool sorted) {\n++  auto input_view =\n++      raft::make_device_matrix_view<const float, uint32_t, raft::row_major>(\n++          d_data_in, batch, n);\n++\n++  auto output_values_view =\n++      raft::make_device_matrix_view<float, uint32_t, raft::row_major>(\n++          d_data_out, batch, k);\n++\n++  auto output_indices_view =\n++      raft::make_device_matrix_view<uint32_t, uint32_t, raft::row_major>(\n++          d_indices_out, batch, k);\n++\n++  raft::matrix::SelectAlgo algo = raft::matrix::SelectAlgo::kWarpDistributedShm;\n++\n++  raft::matrix::select_k<float, uint32_t>(\n++      res, input_view, std::nullopt, output_values_view, output_indices_view,\n++      select_min, sorted, algo);\n++}\n++\n++}  // namespace myraft"
        },
        {
            "sha": "d8ed11d7103f0020f853bddbe8ac30e9835bfee3",
            "filename": "third_party/xla/third_party/raft/select_k_runner.hpp.patch",
            "status": "added",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Fselect_k_runner.hpp.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Fselect_k_runner.hpp.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fraft%2Fselect_k_runner.hpp.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,17 @@\n+--- /dev/null\t2025-08-20 16:29:02.164000374 +0000\n++++ b/select_k_runner.hpp\t2025-08-20 20:47:22.000000000 +0000\n+@@ -0,0 +1,14 @@\n++#pragma once\n++\n++#include <cstdint>\n++\n++#include \"raft/core/resources.hpp\"\n++\n++namespace myraft {\n++\n++void run_select_k(raft::resources const& res, const float* d_data_in,\n++                  float* d_data_out, std::uint32_t* d_indices_out,\n++                  std::uint32_t batch, std::uint32_t n, std::uint32_t k,\n++                  bool select_min, bool sorted);\n++\n++}  // namespace myraft"
        },
        {
            "sha": "b82906656d6ad5cb6121879edf9393c8a0e4975b",
            "filename": "third_party/xla/third_party/raft/select_k_smoke_test.cu.cc.patch",
            "status": "added",
            "additions": 44,
            "deletions": 0,
            "changes": 44,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Fselect_k_smoke_test.cu.cc.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Fselect_k_smoke_test.cu.cc.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fraft%2Fselect_k_smoke_test.cu.cc.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,44 @@\n+--- /dev/null\t2025-08-20 16:29:02.164000374 +0000\n++++ b/select_k_smoke_test.cu.cc\t2025-08-20 20:54:24.000000000 +0000\n+@@ -0,0 +1,41 @@\n++#include <cuda_runtime.h>\n++#include <gtest/gtest.h>\n++\n++#include \"select_k_runner.hpp\"\n++\n++TEST(SelectKWrapperTest, BasicTopK) {\n++  raft::resources res;\n++\n++  const uint32_t batch = 8;\n++  const uint32_t n = 8192;\n++  const uint32_t k = 16;\n++\n++  float* d_data_in = nullptr;\n++  float* d_data_out = nullptr;\n++  uint32_t* d_indices_out = nullptr;\n++\n++  ASSERT_EQ(cudaMalloc(&d_data_in, batch * n * sizeof(float)), cudaSuccess);\n++  ASSERT_EQ(cudaMalloc(&d_data_out, batch * k * sizeof(float)), cudaSuccess);\n++  ASSERT_EQ(cudaMalloc(&d_indices_out, batch * k * sizeof(uint32_t)),\n++            cudaSuccess);\n++\n++  // host input: 0..n-1\n++  std::vector<float> h_data_in(batch * n);\n++  for (uint32_t row = 0; row < batch; ++row) {\n++    for (uint32_t col = 0; col < n; ++col) {\n++      h_data_in[row * n + col] = static_cast<float>(col);\n++    }\n++  }\n++  ASSERT_EQ(\n++      cudaMemcpy(d_data_in, h_data_in.data(), h_data_in.size() * sizeof(float),\n++                 cudaMemcpyHostToDevice),\n++      cudaSuccess);\n++\n++  // call wrapper\n++  myraft::run_select_k(res, d_data_in, d_data_out, d_indices_out, batch, n, k,\n++                       /*select_min=*/false, /*sorted=*/true);\n++\n++  cudaFree(d_data_in);\n++  cudaFree(d_data_out);\n++  cudaFree(d_indices_out);\n++}"
        },
        {
            "sha": "b0e3f6ed91f1ec959a232688b8aa5207590aaa21",
            "filename": "third_party/xla/third_party/raft/workspace.bzl",
            "status": "added",
            "additions": 23,
            "deletions": 0,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fraft%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fraft%2Fworkspace.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,23 @@\n+\"\"\"Provides the repository macro to import raft.\"\"\"\n+\n+load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n+\n+def repo():\n+    \"\"\"Imports raft.\"\"\"\n+\n+    RAFT_VERSION = \"25.08.00\"\n+    RAFT_SHA256 = \"032dce57b297e121352a1556bd9021410be30fcf319e158592f615e1990b2e58\"\n+\n+    tf_http_archive(\n+        name = \"raft\",\n+        sha256 = RAFT_SHA256,\n+        strip_prefix = \"raft-{version}\".format(version = RAFT_VERSION),\n+        urls = tf_mirror_urls(\"https://github.com/rapidsai/raft/archive/refs/tags/v{version}.tar.gz\".format(version = RAFT_VERSION)),\n+        build_file = \"//third_party/raft:raft.BUILD\",\n+        patch_file = [\n+            \"//third_party/raft:logger_macros.hpp.patch\",\n+            \"//third_party/raft:select_k_runner.hpp.patch\",\n+            \"//third_party/raft:select_k_runner.cu.cc.patch\",\n+            \"//third_party/raft:select_k_smoke_test.cu.cc.patch\",\n+        ],\n+    )"
        },
        {
            "sha": "cc558415f2b3d22e6e29586e495b47e8efc9be5a",
            "filename": "third_party/xla/third_party/rapids_logger/BUILD",
            "status": "added",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frapids_logger%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frapids_logger%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Frapids_logger%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1 @@\n+# copybara:uncomment package(default_applicable_licenses = [\"//third_party/tensorflow:license\"])"
        },
        {
            "sha": "dc0a5c2046eb33361563a842830d7a812516b2c9",
            "filename": "third_party/xla/third_party/rapids_logger/rapids_logger.BUILD",
            "status": "added",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frapids_logger%2Frapids_logger.BUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frapids_logger%2Frapids_logger.BUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Frapids_logger%2Frapids_logger.BUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,30 @@\n+# The rapids-logger project defines an easy way to produce a project-specific logger using the excellent spdlog package\n+licenses([\"notice\"])  # Apache 2.0\n+\n+exports_files([\"LICENSE\"])\n+\n+cc_library(\n+    name = \"rapids_logger\",\n+    srcs = [\"src/logger.cpp\"],\n+    hdrs = glob([\"include/rapids_logger/*.h*\"]),\n+    copts = [\n+        \"-std=c++17\",\n+        \"-fexceptions\",\n+    ],\n+    features = [\"-use_header_modules\"],\n+    includes = [\"include\"],\n+    visibility = [\"//visibility:public\"],\n+    deps = [\n+        \"@spdlog\",\n+    ],\n+)\n+\n+cc_test(\n+    name = \"smoke_test\",\n+    srcs = [\"smoke_test.cc\"],\n+    deps = [\n+        \":rapids_logger\",\n+        \"@com_google_googletest//:gtest\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)"
        },
        {
            "sha": "781ee83cd418c05b90f31bf5c0061817c1bcc83b",
            "filename": "third_party/xla/third_party/rapids_logger/smoke_test.cc.patch",
            "status": "added",
            "additions": 41,
            "deletions": 0,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frapids_logger%2Fsmoke_test.cc.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frapids_logger%2Fsmoke_test.cc.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Frapids_logger%2Fsmoke_test.cc.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,41 @@\n+--- /dev/null\t2025-08-20 16:29:02.164000374 +0000\n++++ b/smoke_test.cc\t2025-08-20 21:00:53.000000000 +0000\n+@@ -0,0 +1,38 @@\n++#include <gtest/gtest.h>\n++\n++#include <memory>\n++#include <sstream>\n++#include <string>\n++\n++#include \"rapids_logger/logger.hpp\"\n++\n++struct LoggerTest : public ::testing::Test {\n++  LoggerTest()\n++      : oss{},\n++        logger_{\"logger_test\",\n++                {std::make_shared<rapids_logger::ostream_sink_mt>(oss)}} {\n++    // Remove extra formatting to simplify validation of outputs.\n++    logger_.set_pattern(\"%v\");\n++  }\n++\n++  void clear_sink() { oss.str(\"\"); }\n++  std::string sink_content() { return oss.str(); }\n++\n++  std::ostringstream oss;\n++  rapids_logger::logger logger_;\n++};\n++\n++TEST_F(LoggerTest, DefaultLevel) {\n++  // The default level should not change without suitable warning to consumers.\n++  EXPECT_EQ(logger_.level(), rapids_logger::level_enum::info);\n++}\n++\n++TEST_F(LoggerTest, DefaultLevelLogs) {\n++  logger_.trace(\"trace\");\n++  logger_.debug(\"debug\");\n++  logger_.info(\"info\");\n++  logger_.warn(\"warn\");\n++  logger_.error(\"error\");\n++  logger_.critical(\"critical\");\n++  EXPECT_EQ(this->sink_content(), \"info\\nwarn\\nerror\\ncritical\\n\");\n++}"
        },
        {
            "sha": "929d99382fa178b6c2adcea6cf74abf3dbafd585",
            "filename": "third_party/xla/third_party/rapids_logger/workspace.bzl",
            "status": "added",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frapids_logger%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frapids_logger%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Frapids_logger%2Fworkspace.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,18 @@\n+\"\"\"Provides the repository macro to import rapids_logger.\"\"\"\n+\n+load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n+\n+def repo():\n+    \"\"\"Imports rapids_logger.\"\"\"\n+\n+    RAPIDS_LOGGER_VERSION = \"0.1.1\"\n+    RAPIDS_LOGGER_SHA256 = \"9ef22efcc3e00affed254bf12b52c6775050bb55e93e010067c2fcd9620163c9\"\n+\n+    tf_http_archive(\n+        name = \"rapids_logger\",\n+        sha256 = RAPIDS_LOGGER_SHA256,\n+        strip_prefix = \"rapids-logger-{version}\".format(version = RAPIDS_LOGGER_VERSION),\n+        urls = tf_mirror_urls(\"https://github.com/rapidsai/rapids-logger/archive/refs/tags/v{version}.tar.gz\".format(version = RAPIDS_LOGGER_VERSION)),\n+        build_file = \"//third_party/rapids_logger:rapids_logger.BUILD\",\n+        patch_file = [\"//third_party/rapids_logger:smoke_test.cc.patch\"],\n+    )"
        },
        {
            "sha": "cc558415f2b3d22e6e29586e495b47e8efc9be5a",
            "filename": "third_party/xla/third_party/rmm/BUILD",
            "status": "added",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frmm%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frmm%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Frmm%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1 @@\n+# copybara:uncomment package(default_applicable_licenses = [\"//third_party/tensorflow:license\"])"
        },
        {
            "sha": "e0b437b221bbb2e0a8c467347df065f2f77cd67a",
            "filename": "third_party/xla/third_party/rmm/logger_macros.hpp.patch",
            "status": "added",
            "additions": 70,
            "deletions": 0,
            "changes": 70,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frmm%2Flogger_macros.hpp.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frmm%2Flogger_macros.hpp.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Frmm%2Flogger_macros.hpp.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,70 @@\n+--- /dev/null\n++++ b/cpp/include/rmm/logger_macros.hpp\n+@@ -0,0 +1,67 @@\n++/*\n++ * Copyright (c) 2025, NVIDIA CORPORATION.\n++ *\n++ * Licensed under the Apache License, Version 2.0 (the \"License\");\n++ * you may not use this file except in compliance with the License.\n++ * You may obtain a copy of the License at\n++ *\n++ *     http://www.apache.org/licenses/LICENSE-2.0\n++ *\n++ * Unless required by applicable law or agreed to in writing, software\n++ * distributed under the License is distributed on an \"AS IS\" BASIS,\n++ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n++ * See the License for the specific language governing permissions and\n++ * limitations under the License.\n++ */\n++\n++#pragma once\n++\n++#include <rapids_logger/log_levels.h>\n++\n++// Default to info level if not specified.\n++#if !defined(RMM_LOG_ACTIVE_LEVEL)\n++#define RMM_LOG_ACTIVE_LEVEL RAPIDS_LOGGER_LOG_LEVEL_INFO\n++#endif\n++\n++// Macros for easier logging, similar to spdlog.\n++#define RMM_LOGGER_CALL(logger, level, ...) (logger).log(level, __VA_ARGS__)\n++\n++#if RMM_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_TRACE\n++#define RMM_LOG_TRACE(...) \\\n++  RMM_LOGGER_CALL(rmm::default_logger(), rapids_logger::level_enum::trace, __VA_ARGS__)\n++#else\n++#define RMM_LOG_TRACE(...) (void)0\n++#endif\n++\n++#if RMM_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_DEBUG\n++#define RMM_LOG_DEBUG(...) \\\n++  RMM_LOGGER_CALL(rmm::default_logger(), rapids_logger::level_enum::debug, __VA_ARGS__)\n++#else\n++#define RMM_LOG_DEBUG(...) (void)0\n++#endif\n++\n++#if RMM_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_INFO\n++#define RMM_LOG_INFO(...) RMM_LOGGER_CALL(rmm::default_logger(), rapids_logger::level_enum::info, __VA_ARGS__)\n++#else\n++#define RMM_LOG_INFO(...) (void)0\n++#endif\n++\n++#if RMM_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_WARN\n++#define RMM_LOG_WARN(...) RMM_LOGGER_CALL(rmm::default_logger(), rapids_logger::level_enum::warn, __VA_ARGS__)\n++#else\n++#define RMM_LOG_WARN(...) (void)0\n++#endif\n++\n++#if RMM_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_ERROR\n++#define RMM_LOG_ERROR(...) \\\n++  RMM_LOGGER_CALL(rmm::default_logger(), rapids_logger::level_enum::error, __VA_ARGS__)\n++#else\n++#define RMM_LOG_ERROR(...) (void)0\n++#endif\n++\n++#if RMM_LOG_ACTIVE_LEVEL <= RAPIDS_LOGGER_LOG_LEVEL_CRITICAL\n++#define RMM_LOG_CRITICAL(...) \\\n++  RMM_LOGGER_CALL(rmm::default_logger(), rapids_logger::level_enum::critical, __VA_ARGS__)\n++#else\n++#define RMM_LOG_CRITICAL(...) (void)0\n++#endif"
        },
        {
            "sha": "6bbe135e20c711f73727a412ccc2a36dd9453c5a",
            "filename": "third_party/xla/third_party/rmm/rmm.BUILD",
            "status": "added",
            "additions": 44,
            "deletions": 0,
            "changes": 44,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frmm%2Frmm.BUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frmm%2Frmm.BUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Frmm%2Frmm.BUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,44 @@\n+load(\"@local_config_cuda//cuda:build_defs.bzl\", \"cuda_library\")\n+\n+licenses([\"notice\"])  # Apache 2.0\n+\n+exports_files([\"LICENSE\"])\n+\n+BASE_COPTS = [\n+    \"-Wno-unused-result\",\n+    \"-Wno-ctad-maybe-unsupported\",\n+    \"-Wno-self-move\",\n+    \"-Wno-pragma-once-outside-header\",\n+    \"-fexceptions\",\n+    \"-DLIBCUDACXX_ENABLE_EXPERIMENTAL_MEMORY_RESOURCE\",\n+]\n+\n+cuda_library(\n+    name = \"rmm\",\n+    srcs = glob([\n+        \"cpp/src/*.cpp\",\n+    ]),\n+    copts = BASE_COPTS,\n+    features = [\"-use_header_modules\"],\n+    includes = [\"cpp/include\"],\n+    textual_hdrs = glob([\n+        \"cpp/include/rmm/**/*.h\",\n+        \"cpp/include/rmm/**/*.hpp\",\n+    ]),\n+    visibility = [\"//visibility:public\"],\n+    deps = [\n+        \"@local_config_cuda//cuda:cuda_headers\",\n+        \"@local_config_cuda//cuda:cudart\",\n+        \"@rapids_logger\",\n+    ],\n+)\n+\n+cc_test(\n+    name = \"cuda_stream_tests\",\n+    srcs = [\"cpp/tests/cuda_stream_tests.cpp\"],\n+    copts = BASE_COPTS,\n+    deps = [\n+        \":rmm\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)"
        },
        {
            "sha": "357b9d5123286e66765f04ef1c99445ee3147fa9",
            "filename": "third_party/xla/third_party/rmm/workspace.bzl",
            "status": "added",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frmm%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Frmm%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Frmm%2Fworkspace.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,18 @@\n+\"\"\"Provides the repository macro to import rmm.\"\"\"\n+\n+load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n+\n+def repo():\n+    \"\"\"Imports rmm.\"\"\"\n+\n+    RMM_VERSION = \"25.08.00\"\n+    RMM_SHA256 = \"6931f4de923b617af8c3b97505d79fd3b7b6b5492c1b5a8cd8bcfdc147cdf458\"\n+\n+    tf_http_archive(\n+        name = \"rmm\",\n+        sha256 = RMM_SHA256,\n+        strip_prefix = \"rmm-{version}\".format(version = RMM_VERSION),\n+        urls = tf_mirror_urls(\"https://github.com/rapidsai/rmm/archive/refs/tags/v{version}.tar.gz\".format(version = RMM_VERSION)),\n+        build_file = \"//third_party/rmm:rmm.BUILD\",\n+        patch_file = [\"//third_party/rmm:logger_macros.hpp.patch\"],\n+    )"
        },
        {
            "sha": "cc558415f2b3d22e6e29586e495b47e8efc9be5a",
            "filename": "third_party/xla/third_party/spdlog/BUILD",
            "status": "added",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fspdlog%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fspdlog%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fspdlog%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1 @@\n+# copybara:uncomment package(default_applicable_licenses = [\"//third_party/tensorflow:license\"])"
        },
        {
            "sha": "a6f33fd4cc7c08730d6226dee7dca39ece8def6b",
            "filename": "third_party/xla/third_party/spdlog/smoke_test.cc.patch",
            "status": "added",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fspdlog%2Fsmoke_test.cc.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fspdlog%2Fsmoke_test.cc.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fspdlog%2Fsmoke_test.cc.patch?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,30 @@\n+--- /dev/null\n++++ b/smoke_test.cc\n+@@ -0,0 +1,27 @@\n++#include \"spdlog/spdlog.h\"\n++#include \"spdlog/sinks/basic_file_sink.h\"\n++#include <iostream>\n++\n++int main() {\n++  try {\n++    // Log to stdout\n++    spdlog::info(\"Hello from spdlog smoke test!\");\n++\n++    // Log with formatting\n++    int answer = 42;\n++    spdlog::warn(\"The answer is {}\", answer);\n++\n++    // Create a file logger\n++    auto file_logger = spdlog::basic_logger_mt(\"file_logger\", \"smoke_test.log\");\n++    file_logger->info(\"Logging to a file from smoke test\");\n++\n++    // Flush and shutdown\n++    spdlog::shutdown();\n++\n++    std::cout << \"spdlog smoke test passed.\" << std::endl;\n++    return 0;  // success\n++  } catch (const spdlog::spdlog_ex& ex) {\n++    std::cerr << \"spdlog smoke test failed: \" << ex.what() << std::endl;\n++    return 1;  // failure\n++  }\n++}"
        },
        {
            "sha": "61d56ec3b7ff3efe04f91e3be619e852c3ea1367",
            "filename": "third_party/xla/third_party/spdlog/spdlog.BUILD",
            "status": "added",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fspdlog%2Fspdlog.BUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fspdlog%2Fspdlog.BUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fspdlog%2Fspdlog.BUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,34 @@\n+# Fast C++ logging library. Header-only.\n+licenses([\"notice\"])  # MIT\n+\n+exports_files([\"LICENSE\"])\n+\n+cc_library(\n+    name = \"spdlog\",\n+    hdrs = glob([\"include/spdlog/**/*.h\"]),\n+    defines = [\n+        \"SPDLOG_FMT_EXTERNAL\",\n+    ],\n+    features = [\"-parse_headers\"],\n+    includes = [\"include\"],\n+    visibility = [\"//visibility:public\"],\n+    deps = [\n+        \"@com_google_absl//absl/container:node_hash_map\",\n+        \"@fmt\",\n+    ],\n+)\n+\n+cc_test(\n+    name = \"smoke_test\",\n+    srcs = [\n+        \"smoke_test.cc\",  # lightweight test file\n+    ],\n+    copts = [\n+        \"-DSPDLOG_FMT_EXTERNAL\",\n+        \"-fexceptions\",\n+    ],\n+    deps = [\n+        \":spdlog\",\n+        \"@fmt\",\n+    ],\n+)"
        },
        {
            "sha": "813777ed3fb80d45a89a499f971f4551a6bc0f92",
            "filename": "third_party/xla/third_party/spdlog/workspace.bzl",
            "status": "added",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fspdlog%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Fspdlog%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fspdlog%2Fworkspace.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,18 @@\n+\"\"\"Provides the repository macro to import spdlog.\"\"\"\n+\n+load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n+\n+def repo():\n+    \"\"\"Imports spdlog.\"\"\"\n+\n+    SPDLOG_VERSION = \"1.15.2\"\n+    SPDLOG_SHA256 = \"7a80896357f3e8e920e85e92633b14ba0f229c506e6f978578bdc35ba09e9a5d\"\n+\n+    tf_http_archive(\n+        name = \"spdlog\",\n+        sha256 = SPDLOG_SHA256,\n+        strip_prefix = \"spdlog-{version}\".format(version = SPDLOG_VERSION),\n+        urls = tf_mirror_urls(\"https://github.com/gabime/spdlog/archive/refs/tags/v{version}.tar.gz\".format(version = SPDLOG_VERSION)),\n+        build_file = \"//third_party/spdlog:spdlog.BUILD\",\n+        patch_file = [\"//third_party/spdlog:smoke_test.cc.patch\"],\n+    )"
        },
        {
            "sha": "6863f76f3a931e91bcae2648a907e7c4a9a04786",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl776164071.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 101,
            "changes": 101,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl776164071.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl776164071.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl776164071.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,101 +0,0 @@\n-\n---- a/include/triton/Conversion/TritonGPUToLLVM/PatternTritonGPUOpToLLVM.h\t2025-03-25 07:48:50.000000000 -0700\n-+++ b/include/triton/Conversion/TritonGPUToLLVM/PatternTritonGPUOpToLLVM.h\t2025-06-26 09:20:47.000000000 -0700\n-@@ -95,7 +95,8 @@\n- void populateFuncOpConversionPattern(LLVMTypeConverter &typeConverter,\n-                                      RewritePatternSet &patterns,\n-                                      const TargetInfoBase &targetInfo,\n--                                     PatternBenefit benefit);\n-+                                     PatternBenefit benefit,\n-+                                     SymbolTableCollection *symbolTables);\n- \n- void populatePrintOpToLLVMPattern(LLVMTypeConverter &typeConverter,\n-                                   RewritePatternSet &patterns,\n-\n---- a/lib/Conversion/TritonGPUToLLVM/FuncOpToLLVM.cpp\t2025-04-25 05:19:43.000000000 -0700\n-+++ b/lib/Conversion/TritonGPUToLLVM/FuncOpToLLVM.cpp\t2025-06-26 09:20:48.000000000 -0700\n-@@ -7,7 +7,8 @@\n- FailureOr<LLVM::LLVMFuncOp>\n- convertFuncOpToLLVMFuncOp(FunctionOpInterface funcOp,\n-                           ConversionPatternRewriter &rewriter,\n--                          const LLVMTypeConverter &converter);\n-+                          const LLVMTypeConverter &converter,\n-+                          SymbolTableCollection *symbolTables);\n- }\n- \n- namespace {\n-@@ -33,8 +34,10 @@\n- /// information.\n- struct FuncOpConversion : public ConvertOpToLLVMPattern<triton::FuncOp> {\n-   FuncOpConversion(LLVMTypeConverter &converter,\n--                   const TargetInfoBase &targetInfo, PatternBenefit benefit)\n--      : ConvertOpToLLVMPattern(converter, benefit), targetInfo(targetInfo) {}\n-+                   const TargetInfoBase &targetInfo, PatternBenefit benefit,\n-+                   SymbolTableCollection *symbolTables)\n-+      : ConvertOpToLLVMPattern(converter, benefit), targetInfo(targetInfo),\n-+        symbolTables(symbolTables) {}\n- \n-   /// Only retain those attributes that are not constructed by\n-   /// `LLVMFuncOp::build`. If `filterArgAttrs` is set, also filter out argument\n-@@ -152,7 +155,7 @@\n- \n-     FailureOr<LLVM::LLVMFuncOp> maybeNewFuncOp =\n-         mlir::convertFuncOpToLLVMFuncOp(amendedFuncOp, rewriter,\n--                                        *getTypeConverter());\n-+                                        *getTypeConverter(), symbolTables);\n-     if (failed(maybeNewFuncOp)) {\n-       return failure();\n-     }\n-@@ -202,12 +205,16 @@\n- \n- private:\n-   const TargetInfoBase &targetInfo;\n-+  // Store a pointer to the single, pass-wide symbol table\n-+  SymbolTableCollection *symbolTables;\n- };\n- \n- } // namespace\n- \n- void mlir::triton::populateFuncOpConversionPattern(\n-     LLVMTypeConverter &typeConverter, RewritePatternSet &patterns,\n--    const TargetInfoBase &targetInfo, PatternBenefit benefit) {\n--  patterns.add<FuncOpConversion>(typeConverter, targetInfo, benefit);\n-+    const TargetInfoBase &targetInfo, PatternBenefit benefit,\n-+    SymbolTableCollection *symbolTables) {\n-+  patterns.add<FuncOpConversion>(typeConverter, targetInfo, benefit,\n-+                                 symbolTables);\n- }\n-\n---- a/third_party/amd/lib/TritonAMDGPUToLLVM/TritonGPUToLLVM.cpp\t2025-06-02 05:51:09.000000000 -0700\n-+++ b/third_party/amd/lib/TritonAMDGPUToLLVM/TritonGPUToLLVM.cpp\t2025-06-26 09:20:48.000000000 -0700\n-@@ -110,7 +110,8 @@\n-       TritonLLVMFunctionConversionTarget funcTarget(*context);\n-       RewritePatternSet funcPatterns(context);\n-       mlir::triton::populateFuncOpConversionPattern(\n--          typeConverter, funcPatterns, targetInfo, patternBenefitDefault);\n-+          typeConverter, funcPatterns, targetInfo, patternBenefitDefault,\n-+          /*symTable=*/nullptr);\n-       mlir::cf::populateControlFlowToLLVMConversionPatterns(typeConverter,\n-                                                             funcPatterns);\n-       if (failed(\n-\n---- a/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/TritonGPUToLLVM.cpp\t2025-04-11 01:29:32.000000000 -0700\n-+++ b/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/TritonGPUToLLVM.cpp\t2025-06-26 09:20:48.000000000 -0700\n-@@ -79,6 +79,7 @@\n-   void runOnOperation() override {\n-     MLIRContext *context = &getContext();\n-     ModuleOp mod = getOperation();\n-+\n-     TargetInfo targetInfo(computeCapability, ptxVersion);\n- \n-     // Allocate shared memory and set barrier\n-@@ -94,7 +95,8 @@\n-     TritonLLVMFunctionConversionTarget funcTarget(*context);\n-     RewritePatternSet funcPatterns(context);\n-     mlir::triton::populateFuncOpConversionPattern(\n--        typeConverter, funcPatterns, targetInfo, patternBenefitDefault);\n-+        typeConverter, funcPatterns, targetInfo, patternBenefitDefault,\n-+        /*symTable=*/nullptr);\n-     mlir::cf::populateControlFlowToLLVMConversionPatterns(typeConverter,\n-                                                           funcPatterns);\n-     if (failed("
        },
        {
            "sha": "5d6498d902ffb325445409382be204a60b3a4de2",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl789494309.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl789494309.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl789494309.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl789494309.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,20 +0,0 @@\n-\n---- a/third_party/amd/include/TritonAMDGPUToLLVM/Passes.h\t2025-06-02 05:51:09.000000000 -0700\n-+++ b/third_party/amd/include/TritonAMDGPUToLLVM/Passes.h\t2025-07-31 15:53:03.000000000 -0700\n-@@ -1,13 +1,14 @@\n- #ifndef TRITON_THIRD_PARTY_AMD_INCLUDE_TRITONAMDGPUTOLLVM_PASSES_H_\n- #define TRITON_THIRD_PARTY_AMD_INCLUDE_TRITONAMDGPUTOLLVM_PASSES_H_\n- \n-+#include <memory>\n-+\n-+#include \"llvm/IR/Function.h\"\n- #include \"mlir/Conversion/LLVMCommon/TypeConverter.h\"\n- #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n- #include \"mlir/Pass/Pass.h\"\n- #include \"mlir/Transforms/DialectConversion.h\"\n- \n--#include <memory>\n--\n- namespace mlir {\n- \n- class ModuleOp;"
        },
        {
            "sha": "409aeb6a0ae232a9ae87ea7edd2f82c023df5ca6",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl791659411.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl791659411.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl791659411.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl791659411.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,12 +0,0 @@\n-diff --git a/BUILD b/BUILD\n-index 246fe7e5f..6dba44973 100644\n---- a/BUILD\n-+++ b/BUILD\n-@@ -951,6 +951,7 @@ cc_library(\n-         \":triton_conversion_triton_to_triton_gpu_passes_inc_gen\",\n-         \":triton_nvidia_gpu_transforms_inc_gen\",\n-         \"@llvm-project//mlir:AllPassesAndDialects\",\n-+        \"@llvm-project//mlir:RegisterAllPasses\",\n-         \"@triton//test:TritonTestAnalysis\",\n-         \"@triton//test:TritonTestDialect\",\n-         \"@triton//third_party/amd:TritonAMDGPU\","
        },
        {
            "sha": "560286b054bafaf64b45ad158beecc15a61a5c34",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl793679540.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 95,
            "changes": 95,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl793679540.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl793679540.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl793679540.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,95 +0,0 @@\n-\n---- a/test/Conversion/tritongpu_to_llvm_hopper.mlir\t2025-07-31 00:13:23.000000000 -0700\n-+++ b/test/Conversion/tritongpu_to_llvm_hopper.mlir\t2025-08-11 09:50:34.000000000 -0700\n-@@ -285,7 +285,7 @@\n- // CHECK-LABEL: distribute_to_shared_st_matrix_local_store\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @distribute_to_shared_st_matrix_local_store(%a: tensor<64x128xf16, #linear>) {\n--    // CHECK-COUNT-8: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<col>}\n-+    // CHECK-COUNT-8: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<col>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<64x128xf16, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<64x128xf16, #linear> -> !ttg.memdesc<64x128xf16, #shared, #smem, mutable>\n-@@ -317,7 +317,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_local_store\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_local_store(%a: tensor<64x32xf16, #linear>) {\n--    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<row>}\n-+    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<row>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<64x32xf16, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<64x32xf16, #linear> -> !ttg.memdesc<64x32xf16, #shared, #smem, mutable>\n-@@ -339,7 +339,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_local_store\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_local_store(%a: tensor<32x32xf16, #linear>) {\n--    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<row>}\n-+    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<row>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<32x32xf16, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<32x32xf16, #linear> -> !ttg.memdesc<32x32xf16, #shared, #smem, mutable>\n-@@ -355,7 +355,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_x2_local_store_fp8\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_x2_local_store_fp8(%a: tensor<64x16xf8E4M3FNUZ, #linear>) {\n--    // CHECK-COUNT-1: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<row>} :\n-+    // CHECK-COUNT-1: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<row>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>} :\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<64x16xf8E4M3FNUZ, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<64x16xf8E4M3FNUZ, #linear> -> !ttg.memdesc<64x16xf8E4M3FNUZ, #shared, #smem, mutable>\n-@@ -371,7 +371,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_local_store_fp32\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_local_store_fp32(%a: tensor<64x16xf32, #linear>) {\n--    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<row>}\n-+    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<row>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<64x16xf32, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<64x16xf32, #linear> -> !ttg.memdesc<64x16xf32, #shared, #smem, mutable>\n-@@ -388,7 +388,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_trans_local_store\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_trans_local_store(%a: tensor<64x32xf16, #linear>) {\n--    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<col>}\n-+    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<col>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<64x32xf16, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<64x32xf16, #linear> -> !ttg.memdesc<64x32xf16, #shared, #smem, mutable>\n-@@ -410,7 +410,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_trans_local_store\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_trans_local_store(%a: tensor<16x32xf16, #linear>) {\n--    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<col>}\n-+    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<col>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<16x32xf16, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<16x32xf16, #linear> -> !ttg.memdesc<16x32xf16, #shared, #smem, mutable>\n-\n---- a/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/MemoryOpToLLVM.cpp\t2025-07-31 00:13:23.000000000 -0700\n-+++ b/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/MemoryOpToLLVM.cpp\t2025-08-11 09:50:35.000000000 -0700\n-@@ -220,7 +220,9 @@\n-         }\n-         inputs.push_back(b.bitcast(input, i32_ty));\n-       }\n--      rewriter.create<NVVM::StMatrixOp>(loc, vecAddr, inputs, layout);\n-+      auto shapeAttr = NVVM::LdStMatrixShapeAttr::get(ctx, /*m=*/8, /*n=*/8);\n-+      rewriter.create<NVVM::StMatrixOp>(loc, vecAddr, inputs, layout, shapeAttr,\n-+                                        NVVM::LdStMatrixEltType::B16);\n-     } else {\n-       Type matTy = nVecs == 1\n-                        ? i32_ty\n-\n---- a/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/TargetInfo.cpp\t2025-07-31 00:13:23.000000000 -0700\n-+++ b/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/TargetInfo.cpp\t2025-08-11 09:50:35.000000000 -0700\n-@@ -550,7 +550,10 @@\n-     }\n-     inputs.push_back(b.bitcast(input, i32_ty));\n-   }\n--  rewriter.create<NVVM::StMatrixOp>(loc, ptr, inputs, NVVM::MMALayout::row);\n-+  auto shapeAttr =\n-+      NVVM::LdStMatrixShapeAttr::get(rewriter.getContext(), /*m=*/8, /*n=*/8);\n-+  rewriter.create<NVVM::StMatrixOp>(loc, ptr, inputs, NVVM::MMALayout::row,\n-+                                    shapeAttr, NVVM::LdStMatrixEltType::B16);\n- }\n- \n- std::string TargetInfo::getMulhiFuncName(Type resultElementTy) const {"
        },
        {
            "sha": "bef272c563b2ada8e669cd7b3ed82b6c78e0bd6a",
            "filename": "third_party/xla/third_party/triton/llvm_integration/mem_sync_scope_agent_to_device.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fmem_sync_scope_agent_to_device.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fmem_sync_scope_agent_to_device.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fmem_sync_scope_agent_to_device.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,24 +0,0 @@\n-b/433429549: Fix the issue where AtomicRMWOp with 2 bf16 elements was not being\n-translated correctly. The sync scope for NV should be device, not agent.\n-\n-diff --git a/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/LoadStoreOpToLLVM.cpp b/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/LoadStoreOpToLLVM.cpp\n---- a/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/LoadStoreOpToLLVM.cpp\n-+++ b/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/LoadStoreOpToLLVM.cpp\n-@@ -923,7 +923,7 @@ struct AtomicRMWOpConversion\n-         Value atom = rewriter\n-                          .create<LLVM::AtomicRMWOp>(\n-                              loc, *llvmAtomicBinOp, rmwPtr, valElements[i],\n--                             *llvmAtomicMemOrdering, StringRef(\"agent\"))\n-+                             *llvmAtomicMemOrdering, StringRef(\"device\"))\n-                          .getResult();\n-         // Handle the 2 bf16 case\n-         if (packed == 2 && valueElemNBits == 16) {\n-@@ -931,7 +931,7 @@ struct AtomicRMWOpConversion\n-                             .create<LLVM::AtomicRMWOp>(\n-                                 loc, *llvmAtomicBinOp, ptrElements[i + 1],\n-                                 valElements[i + 1], *llvmAtomicMemOrdering,\n--                                StringRef(\"agent\"))\n-+                                StringRef(\"device\"))\n-                             .getResult();\n-           auto vecTy = vec_ty(valueElemTy, vec);\n-           auto tmp ="
        },
        {
            "sha": "64504cb7208283181079c09b6ae1b68843094a6f",
            "filename": "third_party/xla/third_party/triton/llvm_integration/tritongpu-to-ptx-mmav3.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 33,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Ftritongpu-to-ptx-mmav3.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Ftritongpu-to-ptx-mmav3.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Ftritongpu-to-ptx-mmav3.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,33 +0,0 @@\n-The PTX generated for this test is sensitive to the LLVM version. Newer versions\n-of the NVPTX backend may use 'prmt.b32' instead of 'bfe.u32' for byte extraction\n-and 'setp.eq.b32' instead of 'setp.eq.s32' for equality comparisons. A later\n-update (probably https://github.com/llvm/llvm-project/commit/f480e1b8258eac3565b3ffaf3f8ed0f77eb87fee)\n-optimized the number of prmt instructions generated for this code, so the\n-number of 'prmt.b32' instructions went from 64 to 48.\n-  The checks below have been updated to match the internal codegen as we think\n-  that they are just optimizations.\n-\n---- a/test/Conversion/tritongpu_to_ptx_mmav3.mlir\t2025-07-31 05:01:16.000000000 -0700\n-+++ b/test/Conversion/tritongpu_to_ptx_mmav3.mlir\t2025-08-06 05:43:00.000000000 -0700\n-@@ -57,7 +57,7 @@\n- \n-     // CHECK: mov.u32       [[TID:%.*]], %tid.x;\n-     // CHECK: and.b32       [[L0_VAL:%.*]], [[TID]], 1;\n--    // CHECK: setp.eq.s32   [[L0_OFF:%.*]], [[L0_VAL]], 0;\n-+    // CHECK: setp.eq.b32   [[L0_OFF:%.*]], [[L0_VAL]], 0;\n- \n-     // This is used to perform 16 independent selects in stage 1.\n- \n-@@ -106,10 +106,10 @@\n-     // the predicate (step 3).\n- \n-     // CHECK-DAG: and.b32           [[L1_VAL:%.*]], [[TID]], 2;\n--    // CHECK-DAG: setp.eq.s32       [[L1_OFF:%.*]], [[L1_VAL]], 0;\n-+    // CHECK-DAG: setp.eq.b32       [[L1_OFF:%.*]], [[L1_VAL]], 0;\n-     // CHECK-COUNT-16: selp.b32     {{.*}}, {{.*}}, [[L1_OFF]];\n- \n--    // CHECK-COUNT-64: bfe.u32\n-+    // CHECK-COUNT-48: prmt.b32\n-     // CHECK-COUNT-64: st.volatile.global.b8\n- \n-     %0 = ttg.convert_layout %arg0 : tensor<128x64xf8E5M2, #mma> -> tensor<128x64xf8E5M2, #dot_op>"
        },
        {
            "sha": "6ce6392617228c7e9f46ebd95e315fb13970b209",
            "filename": "third_party/xla/third_party/triton/temporary/add_set_insertion_point.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Ftemporary%2Fadd_set_insertion_point.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Ftemporary%2Fadd_set_insertion_point.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Ftemporary%2Fadd_set_insertion_point.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,29 +0,0 @@\n-// Remove once it is upstreamed. Tracking bug: b/440003867\n---- a/lib/Dialect/TritonNvidiaGPU/Transforms/InterleaveTMem.cpp\t2025-07-31 05:01:16.000000000 -0700\n-+++ b/lib/Dialect/TritonNvidiaGPU/Transforms/InterleaveTMem.cpp\t2025-08-19 22:42:39.000000000 -0700\n-@@ -63,6 +63,7 @@\n- std::pair<Value, AccessRange>\n- findBufferAccessMemdescSubview(Operation *subview) {\n-   OpBuilder builder(subview->getContext());\n-+  builder.setInsertionPoint(subview);\n-   Location loc = subview->getLoc();\n-   TypedValue<ttg::MemDescType> src;\n-   SmallVector<int64_t> shape;\n-\n---- a/test/TritonNvidiaGPU/interleave_tmem.mlir\t2025-07-31 05:01:16.000000000 -0700\n-+++ b/test/TritonNvidiaGPU/interleave_tmem.mlir\t2025-08-19 22:57:53.000000000 -0700\n-@@ -124,12 +124,12 @@\n-   %subview0 = ttg.memdesc_index %alloc0, %c0 : !ttg.memdesc<1x128x128xf32, #tmem, #ttng.tensor_memory, mutable> -> !ttg.memdesc<128x128xf32, #tmem, #ttng.tensor_memory, mutable>\n-   // CHECK: [[ALLOC1:%.+]] = ttng.tmem_alloc\n-   %alloc1 = ttng.tmem_alloc : () -> !ttg.memdesc<1x128x128xf32, #tmem, #ttng.tensor_memory, mutable>\n--  // CHECK-NEXT: [[SUBVIEW1:%.+]] = ttg.memdesc_index [[ALLOC1]]\n-+  // CHECK: [[SUBVIEW1:%.+]] = ttg.memdesc_index [[ALLOC1]]\n-   %subview1 = ttg.memdesc_index %alloc1, %c0 : !ttg.memdesc<1x128x128xf32, #tmem, #ttng.tensor_memory, mutable> -> !ttg.memdesc<128x128xf32, #tmem, #ttng.tensor_memory, mutable>\n-   // CHECK-NEXT: tmem_store %arg0, [[SUBVIEW1]]\n-   ttng.tmem_store %arg0, %subview1, %true : tensor<128x128xf32, #blocked> -> !ttg.memdesc<128x128xf32, #tmem, #ttng.tensor_memory, mutable>\n-   // CHECK-NEXT: [[ALLOC0:%.+]] = ttng.tmem_alloc\n--  // CHECK-NEXT: [[SUBVIEW0:%.+]] = ttg.memdesc_index [[ALLOC0]]\n-+  // CHECK: [[SUBVIEW0:%.+]] = ttg.memdesc_index [[ALLOC0]]\n-   // CHECK-NEXT: tmem_store %arg0, [[SUBVIEW0]]\n-   ttng.tmem_store %arg0, %subview0, %true : tensor<128x128xf32, #blocked> -> !ttg.memdesc<128x128xf32, #tmem, #ttng.tensor_memory, mutable>\n-   tt.return"
        },
        {
            "sha": "3c00850fcae0e07f75abf69315bcffed05506b62",
            "filename": "third_party/xla/third_party/triton/temporary/ws_fix.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 22,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Ftemporary%2Fws_fix.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Ftemporary%2Fws_fix.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Ftemporary%2Fws_fix.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,22 +0,0 @@\n-Upstreamed in https://github.com/triton-lang/triton/pull/7796\n-\n-diff --git a/third_party/nvidia/hopper/lib/Transforms/WarpSpecialization/WSLowerToken.cpp b/third_party/nvidia/hopper/lib/Transforms/WarpSpecialization/WSLowerToken.cpp\n---- a/third_party/nvidia/hopper/lib/Transforms/WarpSpecialization/WSLowerToken.cpp\n-+++ b/third_party/nvidia/hopper/lib/Transforms/WarpSpecialization/WSLowerToken.cpp\n-@@ -13,6 +13,7 @@\n- #include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n- #include \"triton/Dialect/TritonGPU/Transforms/Utility.h\"\n- #include \"triton/Dialect/TritonNvidiaGPU/IR/Dialect.h\"\n-+#include \"llvm/ADT/STLExtras.h\"\n- \n- namespace tt = mlir::triton;\n- namespace ttg = mlir::triton::gpu;\n-@@ -266,7 +267,7 @@ void lowerTokenOperations(Operation *par\n-     if (auto tokenOp = dyn_cast<ttnvws::CreateTokenOp>(op)) {\n-       // Check to see if it is used by warpSpec. If yes, eraseOperand and\n-       // eraseArgument.\n--      for (OpOperand &use : tokenOp->getUses()) {\n-+      for (OpOperand &use : llvm::make_early_inc_range(tokenOp->getUses())) {\n-         Operation *user = use.getOwner();\n-         if (auto wsOp = dyn_cast<ttg::WarpSpecializeOp>(user)) {\n-           unsigned opndNum = use.getOperandNumber();"
        },
        {
            "sha": "7fb3c6eb8daed564e8860ed522df6820d3e9b8cd",
            "filename": "third_party/xla/third_party/triton/temporary/ws_ub_fix.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 59,
            "changes": 59,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Ftemporary%2Fws_ub_fix.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Ftemporary%2Fws_ub_fix.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Ftemporary%2Fws_ub_fix.patch?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,59 +0,0 @@\n-Being upstreamed in https://github.com/triton-lang/triton/pull/7828\n-\n-diff --git a/third_party/nvidia/hopper/lib/Transforms/WarpSpecialization/WSCodePartition.cpp b/third_party/nvidia/hopper/lib/Transforms/WarpSpecialization/WSCodePartition.cpp\n---- a/third_party/nvidia/hopper/lib/Transforms/WarpSpecialization/WSCodePartition.cpp\n-+++ b/third_party/nvidia/hopper/lib/Transforms/WarpSpecialization/WSCodePartition.cpp\n-@@ -359,25 +359,16 @@ void groupChannels(\n- \n-   // Reorder channels associated with one entry based on program order of the\n-   // producers.\n--  for (auto &kv : consumerChannels) {\n--    if (kv.second.size() > 1) {\n--      auto &allOps = kv.second.front()->getSrcOp()->getBlock()->getOperations();\n--      std::sort(\n--          kv.second.begin(), kv.second.end(), [&](Channel *a, Channel *b) {\n--            auto itrA =\n--                std::find_if(allOps.begin(), allOps.end(), [&](Operation &op) {\n--                  Operation *opPointer = &op;\n--                  return opPointer == a->getSrcOp();\n--                });\n--            auto itrB =\n--                std::find_if(allOps.begin(), allOps.end(), [&](Operation &op) {\n--                  Operation *opPointer = &op;\n--                  return opPointer == b->getSrcOp();\n--                });\n--            assert(itrA != allOps.end() && itrB != allOps.end());\n--            return std::distance(itrA, itrB) < 0;\n--          });\n-+  for (auto &group : make_second_range(consumerChannels)) {\n-+    auto &allOps = group.front()->getSrcOp()->getBlock()->getOperations();\n-+    DenseMap<Operation *, size_t> opIdx;\n-+    opIdx.reserve(allOps.size());\n-+    for (auto [idx, op] : enumerate(allOps)) {\n-+      opIdx[&op] = idx;\n-     }\n-+    sort(group, [&](Channel *a, Channel *b) {\n-+      return opIdx[a->getSrcOp()] < opIdx[b->getSrcOp()];\n-+    });\n-   }\n- \n-   // Switch to using channel as the key instead of ops as ops can be volatile.\n-@@ -587,6 +578,18 @@ void createToken(\n-   DenseMap<ttng::TCGen5MMAOp, Channel *> gen5Barriers;\n-   for (auto *key : orderedChannels) {\n-     auto it = channelsGroupedByConsumers.find(key);\n-+    LLVM_DEBUG({\n-+      LDBG(\"createToken key:\");\n-+      LDBG(\"consumer: \");\n-+      key->getDstOp()->dump();\n-+\n-+      LDBG(\"createToken channelsGroupedByConsumers:\");\n-+      for (auto map_key : make_first_range(channelsGroupedByConsumers)) {\n-+        LDBG(\"representative consumer: \");\n-+        map_key->getDstOp()->dump();\n-+      }\n-+    });\n-+    assert(it != channelsGroupedByConsumers.end());\n-     Channel *channel = it->second.front();\n- \n-     CommChannel commChannel;"
        },
        {
            "sha": "42379d8283772b591b560fdacfaa7d6c5fcf1ad4",
            "filename": "third_party/xla/third_party/triton/workspace.bzl",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Ftriton%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fthird_party%2Ftriton%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fworkspace.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -3,7 +3,6 @@\n load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n load(\"//third_party/triton:llvm_integration/series.bzl\", \"llvm_patch_list\")\n load(\"//third_party/triton:temporary/series.bzl\", \"temporary_patch_list\")\n-load(\"//third_party/triton:xla_extensions/series.bzl\", \"extensions_files_patch_list\")\n \n def repo():\n     \"\"\"Imports Triton.\"\"\"\n@@ -15,5 +14,5 @@ def repo():\n         sha256 = TRITON_SHA256,\n         strip_prefix = \"triton-\" + TRITON_COMMIT,\n         urls = tf_mirror_urls(\"https://github.com/openxla/triton/archive/{}.tar.gz\".format(TRITON_COMMIT)),\n-        patch_file = extensions_files_patch_list + llvm_patch_list + temporary_patch_list,\n+        patch_file = llvm_patch_list + temporary_patch_list,\n     )"
        },
        {
            "sha": "6076783281a740de19b228a82914feacdf75f701",
            "filename": "third_party/xla/third_party/triton/xla_extensions/series.bzl",
            "status": "removed",
            "additions": 0,
            "deletions": 11,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fxla_extensions%2Fseries.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fthird_party%2Ftriton%2Fxla_extensions%2Fseries.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fxla_extensions%2Fseries.bzl?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,11 +0,0 @@\n-\"\"\"\n-Provides the list of long-term patches applied to openxla/xla that are not possible to be\n-applied in the previous copybara workflow.\n-\n-IMPORTANT: This is a temporary hack while we are figuring out the proper way to handle extensions\n-(b/335420963). Please do not add any patches to this list before confirming it with gflegar@.\n-\"\"\"\n-\n-extensions_files_patch_list = [\n-    # Add new patches just above this line\n-]"
        },
        {
            "sha": "23d9fccae09e97967aac7d32092912bbb66ad1ec",
            "filename": "third_party/xla/workspace0.bzl",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fworkspace0.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fworkspace0.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fworkspace0.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -140,10 +140,10 @@ def workspace():\n     if \"rules_ml_toolchain\" not in native.existing_rules():\n         http_archive(\n             name = \"rules_ml_toolchain\",\n-            sha256 = \"9a3e9b3e1f5e8368ab5dfa7d4ec17688810ceeb521b637c975c53d8ade65d513\",\n-            strip_prefix = \"rules_ml_toolchain-087c24520fa94fcded738b8a3cd1113566629140\",\n+            sha256 = \"e7e44c4e349a1c1f31398bd2257c51432e73ea0e7e24cce67090b68b0b50007e\",\n+            strip_prefix = \"rules_ml_toolchain-55dcd0a52c7e0f9eec9927a32512229c09ac3b3e\",\n             urls = [\n-                \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/087c24520fa94fcded738b8a3cd1113566629140.tar.gz\",\n+                \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/55dcd0a52c7e0f9eec9927a32512229c09ac3b3e.tar.gz\",\n             ],\n         )\n "
        },
        {
            "sha": "5897e325e4ed737e2ab866da454f382914d76dca",
            "filename": "third_party/xla/workspace2.bzl",
            "status": "modified",
            "additions": 23,
            "deletions": 18,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fworkspace2.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fworkspace2.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fworkspace2.bzl?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -12,6 +12,7 @@ load(\"//third_party/dlpack:workspace.bzl\", dlpack = \"repo\")\n load(\"//third_party/ducc:workspace.bzl\", ducc = \"repo\")\n load(\"//third_party/eigen3:workspace.bzl\", eigen3 = \"repo\")\n load(\"//third_party/farmhash:workspace.bzl\", farmhash = \"repo\")\n+load(\"//third_party/fmt:workspace.bzl\", fmt = \"repo\")\n load(\"//third_party/FP16:workspace.bzl\", FP16 = \"repo\")\n load(\"//third_party/gemmlowp:workspace.bzl\", gemmlowp = \"repo\")\n load(\"//third_party/git:git_configure.bzl\", \"git_configure\")\n@@ -21,6 +22,7 @@ load(\"//third_party/gpus:sycl_configure.bzl\", \"sycl_configure\")\n load(\"//third_party/highwayhash:workspace.bzl\", highwayhash = \"repo\")\n load(\"//third_party/hwloc:workspace.bzl\", hwloc = \"repo\")\n load(\"//third_party/implib_so:workspace.bzl\", implib_so = \"repo\")\n+load(\"//third_party/kokkos:workspace.bzl\", kokkos = \"repo\")\n load(\"//third_party/llvm:workspace.bzl\", llvm = \"repo\")\n load(\"//third_party/mpitrampoline:workspace.bzl\", mpitrampoline = \"repo\")\n load(\"//third_party/nanobind:workspace.bzl\", nanobind = \"repo\")\n@@ -30,8 +32,12 @@ load(\"//third_party/py:python_configure.bzl\", \"python_configure\")\n load(\"//third_party/py/ml_dtypes:workspace.bzl\", ml_dtypes = \"repo\")\n load(\"//third_party/pybind11_abseil:workspace.bzl\", pybind11_abseil = \"repo\")\n load(\"//third_party/pybind11_bazel:workspace.bzl\", pybind11_bazel = \"repo\")\n+load(\"//third_party/raft:workspace.bzl\", raft = \"repo\")\n+load(\"//third_party/rapids_logger:workspace.bzl\", rapids_logger = \"repo\")\n+load(\"//third_party/rmm:workspace.bzl\", rmm = \"repo\")\n load(\"//third_party/robin_map:workspace.bzl\", robin_map = \"repo\")\n load(\"//third_party/shardy:workspace.bzl\", shardy = \"repo\")\n+load(\"//third_party/spdlog:workspace.bzl\", spdlog = \"repo\")\n load(\"//third_party/stablehlo:workspace.bzl\", stablehlo = \"repo\")\n load(\"//third_party/tensorrt:tensorrt_configure.bzl\", \"tensorrt_configure\")\n load(\"//third_party/tensorrt:workspace.bzl\", tensorrt = \"repo\")\n@@ -54,20 +60,26 @@ def _initialize_third_party():\n     ducc()\n     eigen3()\n     farmhash()\n+    fmt()\n     gemmlowp()\n     gloo()\n     highwayhash()\n     hwloc()\n     implib_so()\n+    kokkos()\n     ml_dtypes()\n     mpitrampoline()\n     nanobind()\n     nasm()\n     nvshmem()\n     pybind11_abseil()\n     pybind11_bazel()\n+    raft()\n+    rapids_logger()\n+    rmm()\n     robin_map()\n     shardy()\n+    spdlog()\n     stablehlo()\n     tensorrt()\n     triton()\n@@ -193,33 +205,26 @@ def _tf_repositories():\n         name = \"mkl_dnn_acl_compatible\",\n         build_file = \"//third_party/mkl_dnn:mkldnn_acl.BUILD\",\n         patch_file = [\n-            \"//third_party/mkl_dnn:onednn_acl_threadcap.patch\",\n-            \"//third_party/mkl_dnn:onednn_acl_reorder.patch\",\n-            \"//third_party/mkl_dnn:onednn_acl_thread_local_scheduler.patch\",\n-            \"//third_party/mkl_dnn:onednn_acl_fp32_bf16_reorder.patch\",\n-            \"//third_party/mkl_dnn:onednn_acl_bf16_capability_detection_for_ubuntu20.04.patch\",\n-            \"//third_party/mkl_dnn:onednn_acl_indirect_conv.patch\",\n-            \"//third_party/mkl_dnn:onednn_acl_allow_blocked_weight_format_for_matmul_primitive.patch\",\n-            \"//third_party/mkl_dnn:onednn_acl_fix_segfault_during_postop_execute.patch\",\n-            \"//third_party/mkl_dnn:onednn_acl_add_bf16_platform_support_check.patch\",\n-            \"//third_party/mkl_dnn:onednn_acl_add_sbgemm_matmul_primitive_definition.patch\",\n+            \"//third_party/mkl_dnn:onednn_acl_lock_fixed_format_matmul.patch\",\n+            \"//third_party/mkl_dnn:onednn_acl_threadpool_default_max.patch\",\n         ],\n-        sha256 = \"2f76b407ef8893cca71340f88cd800019a1f14f8ac1bbdbb89a84be1370b52e3\",\n-        strip_prefix = \"oneDNN-3.2.1\",\n-        urls = tf_mirror_urls(\"https://github.com/oneapi-src/oneDNN/archive/refs/tags/v3.2.1.tar.gz\"),\n+        sha256 = \"5792cbc07764c6e25c459ff68efb5cfcd7f4a0ba66dca6a4a2c681cd7a644596\",\n+        strip_prefix = \"oneDNN-3.7\",\n+        urls = tf_mirror_urls(\"https://github.com/oneapi-src/oneDNN/archive/refs/tags/v3.7.zip\"),\n     )\n \n     tf_http_archive(\n         name = \"compute_library\",\n         patch_file = [\n+            \"//third_party/compute_library:acl_gemm_scheduling_heuristic.patch\",\n+            \"//third_party/compute_library:acl_stateless_gemm_workspace.patch\",\n             \"//third_party/compute_library:compute_library.patch\",\n-            \"//third_party/compute_library:acl_thread_local_scheduler.patch\",\n             \"//third_party/compute_library:exclude_omp_scheduler.patch\",\n             \"//third_party/compute_library:include_string.patch\",\n         ],\n-        sha256 = \"c4ca329a78da380163b2d86e91ba728349b6f0ee97d66e260a694ef37f0b0d93\",\n-        strip_prefix = \"ComputeLibrary-23.05.1\",\n-        urls = tf_mirror_urls(\"https://github.com/ARM-software/ComputeLibrary/archive/v23.05.1.tar.gz\"),\n+        sha256 = \"8273f68cd0bb17e9231a11a6618d245eb6d623884ae681c00e7a4eabca2dad42\",\n+        strip_prefix = \"ComputeLibrary-24.12\",\n+        urls = tf_mirror_urls(\"https://github.com/ARM-software/ComputeLibrary/archive/refs/tags/v24.12.tar.gz\"),\n     )\n \n     tf_http_archive(\n@@ -312,7 +317,7 @@ def _tf_repositories():\n \n     tf_http_archive(\n         name = \"com_google_protobuf\",\n-        patch_file = [\"//third_party/protobuf:protobuf-6.31.1.patch\"],\n+        patch_file = [\"//third_party/protobuf:protobuf.patch\"],\n         sha256 = \"6e09bbc950ba60c3a7b30280210cd285af8d7d8ed5e0a6ed101c72aff22e8d88\",\n         strip_prefix = \"protobuf-6.31.1\",\n         urls = tf_mirror_urls(\"https://github.com/protocolbuffers/protobuf/archive/refs/tags/v6.31.1.zip\"),"
        },
        {
            "sha": "bb59a46744e32a8ddd0c30bbfce443bded3bf94e",
            "filename": "third_party/xla/xla/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -264,7 +264,6 @@ xla_cc_test(\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test_main\",\n         \"@com_google_absl//absl/base:log_severity\",\n-        \"@com_google_absl//absl/log:log_sink\",\n         \"@com_google_absl//absl/log:scoped_mock_log\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n@@ -867,8 +866,7 @@ cc_library(\n     visibility = internal_visibility([\":friends\"]),\n     deps = [\n         \":array\",\n-        \":types\",\n-        \"//xla/tsl/platform:logging\",\n+        \":util\",\n     ],\n )\n "
        },
        {
            "sha": "f75dbd38ed65a30c4a7e580056f800d672dd35c9",
            "filename": "third_party/xla/xla/array2d.h",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Farray2d.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Farray2d.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Farray2d.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -18,17 +18,12 @@ limitations under the License.\n \n #include <algorithm>\n #include <cstdint>\n-#include <functional>\n #include <initializer_list>\n-#include <iterator>\n #include <memory>\n-#include <random>\n #include <vector>\n \n #include \"absl/functional/function_ref.h\"\n-#include \"absl/strings/str_cat.h\"\n #include \"xla/array.h\"\n-#include \"xla/types.h\"\n #include \"xla/util.h\"\n \n namespace xla {"
        },
        {
            "sha": "e5b5eac65c4897a932371aece5bf5cb3c2a303b4",
            "filename": "third_party/xla/xla/array3d.h",
            "status": "modified",
            "additions": 16,
            "deletions": 8,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Farray3d.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Farray3d.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Farray3d.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -16,17 +16,12 @@ limitations under the License.\n #ifndef XLA_ARRAY3D_H_\n #define XLA_ARRAY3D_H_\n \n-#include <algorithm>\n-#include <functional>\n+#include <cstdint>\n #include <initializer_list>\n-#include <iterator>\n-#include <memory>\n-#include <numeric>\n-#include <random>\n+#include <vector>\n \n #include \"xla/array.h\"\n-#include \"xla/tsl/platform/logging.h\"\n-#include \"xla/types.h\"\n+#include \"xla/util.h\"\n \n namespace xla {\n \n@@ -66,6 +61,19 @@ class Array3D : public Array<T> {\n   int64_t n1() const { return this->dim(0); }\n   int64_t n2() const { return this->dim(1); }\n   int64_t n3() const { return this->dim(2); }\n+\n+  void FillUnique(T start_value = 0) {\n+    int shift2 = Log2Ceiling<uint64_t>(n2());\n+    int shift3 = Log2Ceiling<uint64_t>(n3());\n+    for (int64_t i0 = 0; i0 < n1(); ++i0) {\n+      for (int64_t i1 = 0; i1 < n2(); ++i1) {\n+        for (int64_t i2 = 0; i2 < n3(); ++i2) {\n+          (*this)(i0, i1, i2) =\n+              ((i0 << (shift3 + shift2)) | (i1 << shift2) | i2) + start_value;\n+        }\n+      }\n+    }\n+  }\n };\n \n }  // namespace xla"
        },
        {
            "sha": "738559e8eb4ad64bfe5c56e087b25c1bd28aac78",
            "filename": "third_party/xla/xla/backends/autotuner/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -81,6 +81,7 @@ xla_cc_test(\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/time\",\n+        \"@com_google_absl//absl/types:optional\",\n         \"@com_google_googletest//:gtest_main\",\n         \"@local_tsl//tsl/platform:path\",\n     ] + if_google([\"@com_google_protobuf//:any_cc_proto\"]),"
        },
        {
            "sha": "b1494809b45f39f106015554af43705483469e06",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.cc",
            "status": "modified",
            "additions": 37,
            "deletions": 8,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -201,7 +201,12 @@ absl::StatusOr<Autotuner::Config> Autotuner::ProfileAndPickBest(\n     return absl::InternalError(\"No executables to profile!\");\n   }\n   VLOG(1) << \"Profiling \" << candidates.size() << \" executable candidates.\";\n-  Config best_config{nullptr, nullptr};\n+  struct ConfigAndScratchBytes {\n+    Config* config;\n+    int scratch_bytes;\n+  };\n+  std::vector<ConfigAndScratchBytes> top_configs_and_scratch_bytes;\n+  Config* min_duration_config = nullptr;\n   absl::Duration min_duration = absl::InfiniteDuration();\n \n   TF_ASSIGN_OR_RETURN(\n@@ -237,22 +242,46 @@ absl::StatusOr<Autotuner::Config> Autotuner::ProfileAndPickBest(\n       }\n     }\n \n-    if (profile_result.value().duration < min_duration) {\n-      min_duration = profile_result.value().duration;\n-      best_config = std::move(candidates[i].config);\n+    absl::Duration duration = profile_result.value().duration;\n+    if (autotune_config_.optimize_scratch_bytes &&\n+        duration <\n+            min_duration + absl::Microseconds(\n+                               autotune_config_.scratch_bytes_window_size_us)) {\n+      top_configs_and_scratch_bytes.push_back(\n+          {&candidates[i].config, profile_result.value().scratch_bytes});\n+    }\n+    if (duration < min_duration) {\n+      min_duration = duration;\n+      min_duration_config = &candidates[i].config;\n     }\n   }\n-  if (best_config.codegen_backend == nullptr) {\n+  if (min_duration_config == nullptr) {\n     return absl::InternalError(\"No valid config found!\");\n   }\n \n+  Config* best_config = min_duration_config;\n+  if (autotune_config_.optimize_scratch_bytes) {\n+    Config* best_scratch_bytes_config = nullptr;\n+    int min_scratch_bytes = -1;\n+    for (auto& config_and_scratch : top_configs_and_scratch_bytes) {\n+      if (best_scratch_bytes_config == nullptr ||\n+          config_and_scratch.scratch_bytes < min_scratch_bytes) {\n+        best_scratch_bytes_config = config_and_scratch.config;\n+        min_scratch_bytes = config_and_scratch.scratch_bytes;\n+      }\n+    }\n+    if (best_scratch_bytes_config != nullptr) {\n+      best_config = best_scratch_bytes_config;\n+    }\n+  }\n+\n   AutotunerCacheEntry cache_entry;\n-  cache_entry.set_codegen_backend(best_config.codegen_backend->name());\n-  *cache_entry.mutable_backend_config() = *best_config.backend_config;\n+  cache_entry.set_codegen_backend(min_duration_config->codegen_backend->name());\n+  *cache_entry.mutable_backend_config() = *best_config->backend_config;\n   if (cache_) {\n     TF_RETURN_IF_ERROR(cache_->Insert(instr, cache_entry));\n   }\n-  return best_config;\n+  return std::move(*best_config);\n }\n \n absl::StatusOr<ScopedShapedBuffer> Autotuner::GetReferenceOutput("
        },
        {
            "sha": "e9ff4780142773c985cab9bed68b2cadf7099f4f",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.h",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -47,6 +47,14 @@ struct AutotuneConfig {\n   float relative_tolerance = 1e-6;\n   // Whether to crash the process on check failure.\n   bool crash_on_check_failure = false;\n+  // If true, in addition to the duration, the best algorithm will be chosen\n+  // based on the scratch bytes. This is only useful if backends use scratch\n+  // space for temporary tensors. The best config will be the one with the\n+  // smallest scratch space among top minimum duration configs in\n+  // scratch_bytes_window_size_us window.\n+  bool optimize_scratch_bytes = false;\n+  // Window size in microseconds to consider for scratch bytes optimization.\n+  int scratch_bytes_window_size_us = 4;\n };\n \n class Autotuner {"
        },
        {
            "sha": "b61d0ddeab1d02aece6215291a7af7eb7cb3e151",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner_test.cc",
            "status": "modified",
            "additions": 45,
            "deletions": 0,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -453,5 +453,50 @@ TEST_F(AutotunerTest, AutotuneWithBufferCheck) {\n   auto dummy_instr = HloInstruction::CreateConstant(LiteralUtil::CreateR0(1));\n   EXPECT_THAT(autotuner->Autotune(dummy_instr.get()), IsOk());\n }\n+\n+TEST_F(AutotunerTest, AutotuneWithScratchBytesOptimization) {\n+  std::vector<std::unique_ptr<BackendConfig>> configs;\n+  configs.push_back(GetTestConfig(\"config_more_time_less_scratch\"));\n+  configs.push_back(GetTestConfig(\"config_less_time_more_scratch\"));\n+  auto backend_1 = std::make_unique<MockCodegenBackend>();\n+  EXPECT_CALL(*backend_1, GetSupportedConfigs)\n+      .WillOnce(Return(std::move(configs)));\n+  EXPECT_CALL(*backend_1, Compile(_, _))\n+      .WillOnce(Return(std::unique_ptr<Executable>()))\n+      .WillOnce(Return(std::unique_ptr<Executable>()));\n+\n+  EXPECT_CALL(*backend_1,\n+              ApplyConfig(_, ConfigMatcher(\"config_more_time_less_scratch\")))\n+      .Times(1)\n+      .WillRepeatedly(Return(absl::OkStatus()));\n+\n+  auto profiler = std::make_unique<MockProfiler>();\n+  EXPECT_CALL(*profiler, CreateInputBuffers(_))\n+      .WillOnce(Return(std::make_unique<InputBuffers>()));\n+  EXPECT_CALL(*profiler, Profile(_, _))\n+      .WillOnce(Return(ProfileResult({\n+          /*duration=*/absl::Microseconds(2),\n+          /*output_buffer=*/std::nullopt,\n+          /*scratch_bytes=*/100,\n+      })))\n+      .WillOnce(Return(ProfileResult({\n+          /*duration=*/absl::Microseconds(1),\n+          /*output_buffer=*/std::nullopt,\n+          /*scratch_bytes=*/200,\n+      })));\n+\n+  std::vector<std::unique_ptr<CodegenBackend>> backends;\n+  backends.push_back(std::move(backend_1));\n+  AutotuneConfig config;\n+  config.optimize_scratch_bytes = true;\n+  config.scratch_bytes_window_size_us = 2;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto autotuner,\n+      Autotuner::Create(std::move(backends), std::move(profiler), config,\n+                        std::make_unique<MockAutotunerCache>()));\n+  auto dummy_instr = HloInstruction::CreateConstant(LiteralUtil::CreateR0(1));\n+  EXPECT_THAT(autotuner->Autotune(dummy_instr.get()), IsOk());\n+}\n+\n }  // namespace\n }  // namespace xla"
        },
        {
            "sha": "2112f467e9b4b89d0f9e0fd2de98b3ffbb32885f",
            "filename": "third_party/xla/xla/backends/autotuner/profiler.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fprofiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fprofiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fprofiler.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -35,15 +35,15 @@ struct ProfileOptions {\n   // Whether to initialize the buffers with random data or leave them\n   // uninitialized.\n   bool should_init_buffers = false;\n-  // Whether to populate the output_buffer in the ProfileResult with the result\n-  // of the execution. This is to avoid data copies if the caller doesn't need\n-  // the output buffer.\n-  bool should_populate_output_buffer = true;\n };\n \n struct ProfileResult {\n+  // The duration of the executable run.\n   absl::Duration duration = absl::ZeroDuration();\n+  // The output buffer of the executable., only captures the first buffer if\n+  // the output is a tuple.\n   std::optional<ScopedShapedBuffer> output_buffer = std::nullopt;\n+  // The scratch bytes used by the executable, if any.\n   int scratch_bytes = 0;\n };\n "
        },
        {
            "sha": "3753691a8a7ecbe374c89f69747f1faad81c2b84",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/cpu_profiler.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -71,8 +71,6 @@ absl::StatusOr<std::unique_ptr<InputBuffers>> CpuProfiler::CreateInputBuffers(\n }\n \n std::unique_ptr<Profiler> CpuProfiler::Create(ProfileOptions options) {\n-  CHECK(options.should_populate_output_buffer == false)\n-      << \"Output buffer is not supported on CPU.\";\n   return absl::WrapUnique(new CpuProfiler(options));\n }\n "
        },
        {
            "sha": "66ecc5d4506d036d90ea6487ddd0e8763146e1a0",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/cpu_profiler_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -50,7 +50,7 @@ absl::StatusOr<std::unique_ptr<Executable>> CompileHloModule(\n \n class CpuProfilerTest : public HloHardwareIndependentTestBase {\n  public:\n-  CpuProfilerTest() { profile_options_.should_populate_output_buffer = false; }\n+  CpuProfilerTest() = default;\n   ProfileOptions profile_options_;\n };\n "
        },
        {
            "sha": "19aaf862bbe705494de6fc76ef9f85acc3914a5b",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/llvm_kernel_autotuner.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_autotuner.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -45,9 +45,7 @@ absl::StatusOr<bool> LlvmKernelAutotuner::Run(\n   TF_ASSIGN_OR_RETURN(auto compiler,\n                       CpuCodegenBackend::CreateBackendCompiler());\n   TF_ASSIGN_OR_RETURN(auto backend, LlvmKernelBackend::Create(compiler.get()));\n-  ProfileOptions profile_options;\n-  profile_options.should_populate_output_buffer = false;\n-  std::unique_ptr<Profiler> profiler = CpuProfiler::Create(profile_options);\n+  std::unique_ptr<Profiler> profiler = CpuProfiler::Create(ProfileOptions());\n \n   std::vector<std::unique_ptr<CodegenBackend>> codegen_backends;\n   codegen_backends.push_back(std::move(backend));"
        },
        {
            "sha": "8e81c25b6ff04d2ec48394610082c331f9706ae9",
            "filename": "third_party/xla/xla/backends/cpu/codegen/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -65,6 +65,7 @@ cc_library(\n         \"//xla:util\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/codegen:intrinsic_lib\",\n+        \"//xla/codegen/intrinsic\",\n         \"//xla/codegen/intrinsic:intrinsic_compiler_lib\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service/cpu:backend_config_proto_cc\","
        },
        {
            "sha": "288d5e6ce7bff9ad358b24cb6b9088c166635627",
            "filename": "third_party/xla/xla/backends/cpu/codegen/ir_compiler.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 3,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Fir_compiler.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -66,6 +66,7 @@ limitations under the License.\n #include \"xla/backends/cpu/codegen/cpu_features.h\"\n #include \"xla/backends/cpu/codegen/kernel_api_ir_builder.h\"\n #include \"xla/backends/cpu/codegen/polynomial_approximations.h\"\n+#include \"xla/codegen/intrinsic/intrinsic.h\"\n #include \"xla/codegen/intrinsic/intrinsic_compiler_lib.h\"\n #include \"xla/codegen/intrinsic_lib.h\"\n #include \"xla/service/cpu/backend_config.pb.h\"\n@@ -345,10 +346,30 @@ llvm::Error IrCompiler::RunIrPasses(llvm::Module& module,\n       std::make_unique<llvm::TargetLibraryInfoImpl>(target_triple);\n   target_library_info_impl->addVectorizableFunctions(\n       PolynomialApproximationsVectorization());\n+\n+  xla::codegen::intrinsics::DeviceType device_type;\n+  if (target_triple.isX86()) {\n+    // As a heuristic, we check for SSE4a to determine if we are on AMD.\n+    // This feature was added in 2007 and is set on all AMD CPUs since then, and\n+    // no intel cpus. This is a bit of a hack though, as there is no strict link\n+    // between increased precision and SSE4a; Intel could decide to add it in\n+    // the future but they are very unlikely to do so as they haven't in the\n+    // past 18 years.\n+    if (target_machine->getTargetFeatureString().contains(\"+sse4a\")) {\n+      device_type = xla::codegen::intrinsics::DeviceType::kAmdCpu;\n+    } else {\n+      device_type = xla::codegen::intrinsics::DeviceType::kIntelCpu;\n+    }\n+  } else if (target_triple.isAArch64() || target_triple.isARM()) {\n+    device_type = xla::codegen::intrinsics::DeviceType::kArmCpu;\n+  } else {\n+    LOG(FATAL) << \"Unsupported CPU type: \" << target_triple.str();\n+  }\n+\n   codegen::IntrinsicFunctionLib intrinsic_lib(\n-      {target_machine->getTargetFeatureString().str(),\n-       /*disable_platform_dependent_math=*/options_\n-           .disable_platform_dependent_math});\n+      {target_machine->getTargetFeatureString().str(), device_type,\n+       /*disable_platform_dependent_math=*/\n+       options_.disable_platform_dependent_math});\n   target_library_info_impl->addVectorizableFunctions(\n       intrinsic_lib.Vectorizations());\n "
        },
        {
            "sha": "7d2589edc96a89b3c0c5f82a4f289dae310d3428",
            "filename": "third_party/xla/xla/backends/cpu/nanort/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -111,6 +111,7 @@ cc_library(\n         \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/base:dynamic_annotations\",\n         \"@com_google_absl//absl/container:fixed_array\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/memory\","
        },
        {
            "sha": "31e0a8c616f32a5ae605d964e7a62ccbc9b4c699",
            "filename": "third_party/xla/xla/backends/cpu/nanort/ifrt_client.cc",
            "status": "modified",
            "additions": 102,
            "deletions": 54,
            "changes": 156,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -51,6 +51,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/ir/hlo_sharding.h\"\n #include \"xla/layout.h\"\n+#include \"xla/layout_util.h\"\n #include \"xla/pjrt/mlir_to_hlo.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_executable.h\"\n@@ -158,29 +159,38 @@ class NanoValue : public llvm::RTTIExtends<Self, Base> {\n // multiple existing shards.\n class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n  public:\n-  // A pointer to the underlying buffer. We use a shared_ptr because for some\n-  // operations (like disassembly) we can just alias the memory, but we still\n-  // need to support deletion of the NanoArray that created the buffer.\n-  using DataPtr = std::shared_ptr<void>;\n+  // An owning pointer to the underlying buffer (can be allocated for NanoArray,\n+  // or \"owned\" via the `on_done_with_host_buffer` callback passed by the user).\n+  //\n+  // We use a shared_ptr because for some operations (like disassembly) we can\n+  // just alias the memory, but we still need to support deletion of the\n+  // NanoArray that created the buffer.\n+  //\n+  // For non-owned buffers, we simply use a `void*` pointer, that we got from\n+  // the user, and we expect that the user will keep it alive as long as needed.\n+  using OwnedDataPtr = std::shared_ptr<void>;\n \n+  // Creates a NanoArray that owns underlying data.\n   NanoArray(NanoIfrtClient* client, ifrt::DType dtype, const ifrt::Shape& shape,\n-            DataPtr data, ifrt::ShardingRef sharding)\n-      : NanoValue<NanoArray, ifrt::Array>(client),\n-        dtype_(dtype),\n-        shape_(shape),\n-        data_(std::move(data)),\n-        sharding_(std::move(sharding)) {}\n+            OwnedDataPtr owned_data, ifrt::ShardingRef sharding)\n+      : NanoArray(client, dtype, shape, owned_data.get(), std::move(owned_data),\n+                  std::move(sharding)) {}\n+\n+  // Creates a NanoArray that does not own underlying data.\n+  NanoArray(NanoIfrtClient* client, ifrt::DType dtype, const ifrt::Shape& shape,\n+            void* data, ifrt::ShardingRef sharding)\n+      : NanoArray(client, dtype, shape, data, nullptr, std::move(sharding)) {}\n \n   // Allocates a new array of the given type and shape.\n   static absl::StatusOr<tsl::RCReference<NanoArray>> Allocate(\n       NanoIfrtClient* client, ifrt::DType dtype, const ifrt::Shape& shape,\n       ifrt::ShardingRef sharding) {\n     TF_RET_CHECK(dtype.byte_size().has_value());\n     TF_ASSIGN_OR_RETURN(\n-        DataPtr data_ptr,\n+        OwnedDataPtr owned_data,\n         AllocateData(dtype.byte_size().value() * shape.num_elements()));\n-    return tsl::TakeRef(new NanoArray(client, dtype, shape, std::move(data_ptr),\n-                                      std::move(sharding)));\n+    return tsl::TakeRef(new NanoArray(\n+        client, dtype, shape, std::move(owned_data), std::move(sharding)));\n   }\n \n   // Creates an array from a host buffer. The buffer will be used directly\n@@ -191,8 +201,6 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n       const ifrt::Shape& shape, ifrt::ShardingRef sharding,\n       std::optional<absl::Span<const int64_t>> byte_strides, bool make_copy,\n       std::function<void()> on_done_with_host_buffer) {\n-    DataPtr data_ptr;\n-\n     bool layout_compatible = LayoutCompatible(dtype, shape, byte_strides);\n     bool aligned = reinterpret_cast<uintptr_t>(data) % MinAlign() == 0;\n \n@@ -202,16 +210,16 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n       int64_t size = dtype.byte_size().value_or(0) * shape.num_elements();\n       TF_RET_CHECK(size > 0);\n \n-      TF_ASSIGN_OR_RETURN(data_ptr, AllocateData(size));\n+      TF_ASSIGN_OR_RETURN(OwnedDataPtr owned_data, AllocateData(size));\n       if (layout_compatible) {\n         // Input has a compatible layout, so we can just do a memcpy.\n-        memcpy(data_ptr.get(), data, size);\n+        memcpy(owned_data.get(), data, size);\n       } else {\n         // Input has an incompatible layout, so we need to copy it with an\n         // appropriate stride.\n         TF_ASSIGN_OR_RETURN(auto dense_strides, DenseByteStrides(dtype, shape));\n         TF_RETURN_IF_ERROR(CopyWithByteStrides(\n-            reinterpret_cast<std::byte*>(data_ptr.get()), dense_strides,\n+            reinterpret_cast<std::byte*>(owned_data.get()), dense_strides,\n             reinterpret_cast<std::byte*>(data),\n             byte_strides.value_or(dense_strides), shape.dims(),\n             dtype.byte_size().value()));\n@@ -221,23 +229,29 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n       if (on_done_with_host_buffer) {\n         on_done_with_host_buffer();\n       }\n-    } else {\n-      // We're allowed to keep the input buffer, and it's dense and row major,\n-      // so we can just use it directly.\n-      data_ptr = DataPtr(\n-          data, [done = std::move(on_done_with_host_buffer)](void* ptr) {\n-            if (done) {\n-              done();\n-            }\n-          });\n+\n+      return tsl::TakeRef(new NanoArray(\n+          client, dtype, shape, std::move(owned_data), std::move(sharding)));\n     }\n \n-    DCHECK(data_ptr) << \"data_ptr should be allocated\";\n-    return tsl::TakeRef(new NanoArray(client, dtype, shape, std::move(data_ptr),\n-                                      std::move(sharding)));\n+    // We can create a view into the user's buffer, but we must take ownership\n+    // of it via the provided callback.\n+    if (ABSL_PREDICT_FALSE(on_done_with_host_buffer)) {\n+      return tsl::TakeRef(new NanoArray(\n+          client, dtype, shape,\n+          OwnedDataPtr(data, [done = std::move(on_done_with_host_buffer)](\n+                                 void* ptr) { done(); }),\n+          std::move(sharding)));\n+    }\n+\n+    // User didn't pass a callback, so we can assume that it will keep the data\n+    // alive for as long as it needs to be.\n+    return tsl::TakeRef(\n+        new NanoArray(client, dtype, shape, data, std::move(sharding)));\n   }\n \n-  const DataPtr& data() const { return data_; }\n+  void* data() const { return data_; }\n+  const OwnedDataPtr& owned_data() const { return owned_data_; }\n \n   // Copies a sub-array of the given size from src to dst. The dst array must\n   // already be allocated and of the correct type and shape. Values outside of\n@@ -295,7 +309,7 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n         stride *= array.shape().dims()[i];\n       }\n       offset *= element_size;\n-      return static_cast<std::byte*>(array.data().get()) + offset;\n+      return static_cast<std::byte*>(array.data()) + offset;\n     };\n \n     // Get the pointers to the start of the rows we're copying.\n@@ -327,9 +341,9 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n       for (auto* device : sharding().devices()->devices()) {\n         auto one_device_sharding = ifrt::SingleDeviceSharding::Create(\n             device, sharding().memory_kind());\n-        shards.push_back(\n-            tsl::TakeRef(new NanoArray(nano_client(), dtype_, shape_, data_,\n-                                       std::move(one_device_sharding))));\n+        shards.push_back(tsl::TakeRef(\n+            new NanoArray(nano_client(), dtype_, shape_, data_, owned_data_,\n+                          std::move(one_device_sharding))));\n       }\n       return shards;\n     }\n@@ -362,28 +376,31 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n \n   NanoRtExecutable::Argument AsArgument() {\n     return NanoRtExecutable::Argument(\n-        reinterpret_cast<std::byte*>(data_.get()),\n+        reinterpret_cast<std::byte*>(data_),\n         dtype_.byte_size().value() * shape_.num_elements());\n   }\n \n   NanoRtExecutable::Result AsResult() {\n     return NanoRtExecutable::Result(\n-        reinterpret_cast<std::byte*>(data_.get()),\n+        reinterpret_cast<std::byte*>(data_),\n         dtype_.byte_size().value() * shape_.num_elements());\n   }\n \n   std::string DebugString() const override {\n     return absl::StrCat(\"NanoArray(\", dtype_.DebugString(), \", \",\n                         shape_.DebugString(), \", @\",\n-                        reinterpret_cast<uintptr_t>(data_.get()), \")\");\n+                        reinterpret_cast<uintptr_t>(data_), \")\");\n   }\n \n   ifrt::Future<> Delete() override {\n     data_ = nullptr;\n+    owned_data_ = nullptr;\n     return Ready();\n   }\n \n-  bool IsDeleted() const override { return data_ == nullptr; }\n+  bool IsDeleted() const override {\n+    return data_ == nullptr && owned_data_ == nullptr;\n+  }\n \n   ifrt::DType dtype() const override { return dtype_; }\n \n@@ -396,7 +413,8 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n   absl::StatusOr<std::shared_ptr<const PjRtLayout>> pjrt_layout()\n       const override {\n     TF_RETURN_IF_ERROR(ValidateNotDeleted());\n-    return std::make_shared<PjRtLayout>(Layout(shape().dims()));\n+    return std::make_shared<PjRtLayout>(\n+        LayoutUtil::MakeDescendingLayout(shape().dims().size()));\n   }\n \n   absl::StatusOr<std::vector<ifrt::ArrayRef>> DisassembleIntoSingleDeviceArrays(\n@@ -425,15 +443,15 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n       if (ABSL_PREDICT_TRUE(!byte_strides.has_value() ||\n                             HasMajorToMinorLayout(xla_dtype, shape().dims(),\n                                                   *byte_strides))) {\n-        memcpy(data, data_.get(),\n+        memcpy(data, data_,\n                dtype().byte_size().value() * shape().num_elements());\n       } else {\n         TF_ASSIGN_OR_RETURN(auto in_strides,\n                             DenseByteStrides(dtype(), shape()));\n         TF_RETURN_IF_ERROR(CopyWithByteStrides(\n             reinterpret_cast<std::byte*>(data), *byte_strides,\n-            reinterpret_cast<std::byte*>(data_.get()), in_strides,\n-            shape().dims(), dtype().byte_size().value()));\n+            reinterpret_cast<std::byte*>(data_), in_strides, shape().dims(),\n+            dtype().byte_size().value()));\n       }\n       return absl::OkStatus();\n     }());\n@@ -442,6 +460,22 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n   static char ID;  // NOLINT\n \n  private:\n+  friend class ::xla::cpu::NanoIfrtClient;\n+\n+  NanoArray(NanoIfrtClient* client, ifrt::DType dtype, const ifrt::Shape& shape,\n+            void* data, OwnedDataPtr owned_data, ifrt::ShardingRef sharding)\n+      : NanoValue<NanoArray, ifrt::Array>(client),\n+        dtype_(dtype),\n+        shape_(shape),\n+        data_(data),\n+        owned_data_(std::move(owned_data)),\n+        sharding_(std::move(sharding)) {\n+    if (owned_data_) {\n+      DCHECK_EQ(data_, owned_data_.get())\n+          << \"`data_` must point to the buffer owned by `owned_data_`\";\n+    }\n+  }\n+\n   // Returns true if the given data type, shape, and strides are compatible\n   // with NanoArray (we can either use this memory directly or memcpy it into\n   // our own memory).\n@@ -475,18 +509,18 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n   }\n \n   // Allocates an aligned buffer of the given size.\n-  static absl::StatusOr<DataPtr> AllocateData(size_t size) {\n-    DataPtr data_ptr(\n+  static absl::StatusOr<OwnedDataPtr> AllocateData(size_t size) {\n+    OwnedDataPtr owned_data(\n         tsl::port::AlignedMalloc(std::max<size_t>(size, Align()), Align()),\n         [](void* ptr) { tsl::port::AlignedFree(ptr); });\n-    if (ABSL_PREDICT_FALSE(data_ptr == nullptr)) {\n+    if (ABSL_PREDICT_FALSE(owned_data.get() == nullptr)) {\n       return Internal(\"Failed to allocate memory for NanoArray. Errno: %s\",\n                       strerror(errno));\n     }\n     // Suppress msan warnings for memory that will be initialized by the\n     // jit-compiled code.\n-    ABSL_ANNOTATE_MEMORY_IS_INITIALIZED(data_ptr.get(), size);\n-    return data_ptr;\n+    ABSL_ANNOTATE_MEMORY_IS_INITIALIZED(owned_data.get(), size);\n+    return owned_data;\n   }\n \n   // Copies data between two buffers that represent the same shape but have\n@@ -517,7 +551,13 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n \n   ifrt::DType dtype_;\n   ifrt::Shape shape_;\n-  DataPtr data_;\n+\n+  // A pointer to the data buffer. This is either owned by `owned_data_` or\n+  // directly owned by the user. Owned data is null if NanoArray is a zero\n+  // copy view of an external array with a lifetime managed by the user.\n+  void* data_;\n+  OwnedDataPtr owned_data_;\n+\n   ifrt::ShardingRef sharding_;\n };\n \n@@ -1312,17 +1352,17 @@ absl::StatusOr<std::vector<ifrt::ArrayRef>> NanoIfrtClient::CopyArrays(\n     TF_ASSIGN_OR_RETURN(auto sharding, array->sharding().WithDeviceAssignment(\n                                            devices, memory_kind));\n     if (auto nano_array = llvm::dyn_cast_or_null<NanoArray>(array.get())) {\n-      copy = tsl::TakeRef(new NanoArray(this, nano_array->dtype(),\n-                                        nano_array->shape(), nano_array->data(),\n-                                        std::move(sharding)));\n+      copy = tsl::TakeRef(new NanoArray(\n+          this, nano_array->dtype(), nano_array->shape(), nano_array->data(),\n+          nano_array->owned_data(), std::move(sharding)));\n     } else if (auto sharded_nano_array =\n                    llvm::dyn_cast_or_null<ShardedNanoArray>(array.get())) {\n       std::vector<tsl::RCReference<NanoArray>> shards_copy;\n       shards_copy.reserve(sharded_nano_array->shards().size());\n       for (const auto& shard : sharded_nano_array->shards()) {\n         shards_copy.push_back(tsl::TakeRef(\n             new NanoArray(this, shard->dtype(), shard->shape(), shard->data(),\n-                          shard->shared_ptr_sharding())));\n+                          shard->owned_data(), shard->shared_ptr_sharding())));\n       }\n       TF_ASSIGN_OR_RETURN(\n           copy, ShardedNanoArray::FromShards(this, sharded_nano_array->shape(),\n@@ -1344,6 +1384,13 @@ absl::StatusOr<std::vector<ifrt::ArrayRef>> NanoIfrtClient::RemapArrays(\n   return absl::UnimplementedError(\"RemapArrays is not implemented.\");\n }\n \n+absl::StatusOr<std::vector<xla::ifrt::ArrayRef>> NanoIfrtClient::ReshardArrays(\n+    absl::Span<xla::ifrt::ArrayRef> arrays,\n+    absl::Span<const xla::ifrt::ArraySpec> specs,\n+    xla::ifrt::ArrayCopySemantics semantics) {\n+  return absl::UnimplementedError(\"ReshardArrays is not implemented.\");\n+}\n+\n ifrt::Future<> NanoIfrtClient::GetReadyFuture(\n     absl::Span<const ifrt::ValueRef> values) {\n   return Ready();\n@@ -1444,7 +1491,8 @@ NanoIfrtClient::GetDefaultPjRtLayout(ifrt::DType dtype,\n                                      absl::Span<const int64_t> dims,\n                                      ifrt::Device* device,\n                                      ifrt::MemoryKind memory_kind) const {\n-  return std::make_shared<PjRtLayout>(Layout(dims));\n+  return std::make_shared<PjRtLayout>(\n+      LayoutUtil::MakeDescendingLayout(dims.size()));\n }\n \n NanoIfrtClient::NanoIfrtClient(int32_t num_devices,"
        },
        {
            "sha": "a34e4c9b9c459a1e7cd0f5d45d5307b1adc1590a",
            "filename": "third_party/xla/xla/backends/cpu/nanort/ifrt_client.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -147,6 +147,11 @@ class NanoIfrtClient : public llvm::RTTIExtends<NanoIfrtClient, ifrt::Client> {\n       const ifrt::RemapPlan& plan, absl::Span<ifrt::ArrayRef> arrays,\n       ifrt::ArrayCopySemantics semantics) override;\n \n+  absl::StatusOr<std::vector<xla::ifrt::ArrayRef>> ReshardArrays(\n+      absl::Span<xla::ifrt::ArrayRef> arrays,\n+      absl::Span<const xla::ifrt::ArraySpec> specs,\n+      xla::ifrt::ArrayCopySemantics semantics) override;\n+\n   ifrt::Future<> GetReadyFuture(\n       absl::Span<const ifrt::ValueRef> values) override;\n "
        },
        {
            "sha": "92fc31db0b1bc63bfe757664524d9c83a1a2440e",
            "filename": "third_party/xla/xla/backends/cpu/nanort/ifrt_client_test.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 2,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -147,7 +147,7 @@ static absl::StatusOr<ifrt::ArrayRef> MakeArrayFromLiteral(\n       ifrt::Shape(literal.shape().dimensions()),\n       /*byte_strides=*/std::nullopt, std::move(sharding),\n       ifrt::Client::HostBufferSemantics::kImmutableZeroCopy,\n-      /*on_done_with_host_buffer=*/{});\n+      /*on_done_with_host_buffer=*/nullptr);\n }\n \n static void BM_IfRtAddScalars(benchmark::State& state) {\n@@ -320,7 +320,17 @@ int main(int argc, char** argv) {\n       \"ArrayImplTest.\"\n       \"MakeArraysFromHostBufferShardsAndCopyToHostBufferWithString:\"\n       // `MakeErrorArrays` is not supported in NanoIfrtClient.\n-      \"ArrayImplTest.MakeErrorArrays\";\n+      \"ArrayImplTest.MakeErrorArrays:\"\n+      // Sub-byte types are not supported in NanoIfrtClient.\n+      \"ArrayImplTest.HostBufferInt4:\"\n+      // NanoRT does not handle zero-sized buffers correctly.\n+      \"ArrayImplTest.MakeAndCopyZeroSizedBuffers:\"\n+      // Executable returns a wrong number of devices.\n+      \"LoadedExecutableImplTest.Properties:\"\n+      // Incorrect deleted state of donated inputs.\n+      \"LoadedExecutableImplTest.Donation:\"\n+      // Analysis methods are not implemented.\n+      \"LoadedExecutableImplTest.Analysis\";\n   xla::ifrt::test_util::SetTestFilterIfNotUserSpecified(kFilter);\n \n   for (int i = 1; i < argc; i++) {"
        },
        {
            "sha": "490f61433086d7b55953525da90a1d2c55812a1a",
            "filename": "third_party/xla/xla/backends/cpu/nanort/nanort_executable.h",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fnanort_executable.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/base/dynamic_annotations.h\"\n #include \"absl/container/fixed_array.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/types/span.h\"\n@@ -155,7 +156,9 @@ class NanoRtExecutable {\n   template <size_t n>\n   class ManagedTemp {\n    public:\n-    explicit ManagedTemp(size_t size) : data_(size) {}\n+    explicit ManagedTemp(size_t size) : data_(size) {\n+      ABSL_ANNOTATE_MEMORY_IS_INITIALIZED(data_.data(), data_.memsize());\n+    }\n \n     ManagedTemp(const ManagedTemp&) = delete;\n     ManagedTemp& operator=(const ManagedTemp&) = delete;"
        },
        {
            "sha": "1818ad9ab1cee0a1061bd8362710a76287e90dee",
            "filename": "third_party/xla/xla/backends/cpu/runtime/collective_thunk.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fcollective_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fcollective_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fcollective_thunk.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -133,6 +133,10 @@ class CollectiveThunk : public Thunk {\n \n   const Shape& destination_shape(int64_t index) const;\n \n+  // Collective operations are typically completed asynchronously on the IO\n+  // thread pool, owned by the underlying collective implementation.\n+  bool ExecutesOnExternalThreadPool() const final { return true; }\n+\n  private:\n   OpParams op_params_;\n   OpBuffers op_buffers_;"
        },
        {
            "sha": "feba693e0bdd39cb2da825a82e9fd65cd6df8832",
            "filename": "third_party/xla/xla/backends/cpu/runtime/onednn/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -90,6 +90,7 @@ onednn_graph_cc_library(\n onednn_graph_cc_test(\n     name = \"onednn_threadpool_test\",\n     srcs = [\"onednn_threadpool_test.cc\"],\n+    copts = tsl_copts(),\n     deps = [\n         \":onednn_interop\",\n         \":onednn_threadpool\","
        },
        {
            "sha": "f2a4faf2c9a4c236bcde5ce2e63e5844941296b7",
            "filename": "third_party/xla/xla/backends/cpu/runtime/onednn/onednn_threadpool.h",
            "status": "modified",
            "additions": 62,
            "deletions": 13,
            "changes": 75,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_threadpool.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_threadpool.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_threadpool.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include <cstdint>\n #include <functional>\n \n+#include \"dnnl_threadpool.hpp\"\n #include \"oneapi/dnnl/dnnl_threadpool_iface.hpp\"\n #include \"xla/backends/cpu/runtime/work_queue.h\"\n \n@@ -28,34 +29,72 @@ limitations under the License.\n \n namespace xla::cpu {\n \n+static tsl::AsyncValueRef<tsl::Chain> OkDoneEventSingleton() {\n+  static tsl::AsyncValueOwningRef<tsl::Chain>* singleton = [] {\n+    auto* storage = new tsl::internal::AsyncValueStorage<tsl::Chain>();\n+    return new tsl::AsyncValueOwningRef<tsl::Chain>(\n+        tsl::MakeAvailableAsyncValueRef<tsl::Chain>(*storage));\n+  }();\n+  return singleton->AsRef();\n+}\n+\n class OneDnnThreadPool final\n     : public dnnl::threadpool_interop::threadpool_iface {\n  public:\n-  explicit OneDnnThreadPool(Eigen::ThreadPoolInterface* thread_pool)\n-      : thread_pool_(thread_pool) {}\n+  explicit OneDnnThreadPool(Eigen::ThreadPoolInterface* thread_pool,\n+                            bool is_async = false)\n+      : thread_pool_(thread_pool), is_async_(is_async) {\n+    if (is_async_) {\n+      done_event_ = OkDoneEventSingleton();\n+      dnnl_threadpool_interop_set_max_concurrency(thread_pool_->NumThreads());\n+    }\n+  }\n \n   int get_num_threads() const final { return thread_pool_->NumThreads(); }\n \n   bool get_in_parallel() const final {\n+    if (is_async_) {\n+      // TODO(intel-tf): this is a temporary fix without which oneDNN runs\n+      // single-threaded.\n+      return false;\n+    }\n     return thread_pool_->CurrentThreadId() >= 0;\n   }\n \n-  uint64_t get_flags() const final { return 0; }\n+  uint64_t get_flags() const final { return is_async_ ? ASYNCHRONOUS : 0; }\n \n #ifdef ENABLE_ONEDNN_ASYNC\n-  // This is a placeholder implementation for the wait method, as we\n-  // need to satisfy the interface requirements of the\n-  // dnnl::threadpool_interop::threadpool_iface with the experimental\n-  // asynchronous runtime support in oneDNN.\n-  // TODO(intel-tf): Implement proper wait logic when thunk runtime\n-  // with oneDNN is enabled.\n-  void wait() final {}\n+  // The wait() method only exists with oneDNN's experimental support for\n+  // asynchronous execution determined by the ENABLE_ONEDNN_ASYNC.\n+  void wait() override {\n+    if (is_async_) {\n+      // While performing asynchronous execution, wait() method is needed to\n+      // notify the user that the output is ready. oneDNN will not call wait()\n+      // inside the library to avoid deadlock.\n+      tsl::BlockUntilReady(done_event_);\n+    }\n+  }\n #endif  // ENABLE_ONEDNN_ASYNC\n \n   void parallel_for(int n, const std::function<void(int, int)>& fn) final {\n-    // It is perfectly safe to block here as Worker implements work stealing\n-    // that guarantees forward progress and deadlock freedom, even if we are\n-    // running in the same thread pool as the Eigen thread_pool.\n+    if (is_async_) {\n+      // If we are using oneDNN with async support, we need to schedule the\n+      // parallel loop using the done_event_. This allows us to return\n+      // immediately and not block the caller thread.\n+      auto parallelize = [this, n, fn](tsl::Chain) {\n+        return Worker::Parallelize(\n+            thread_pool_, thread_pool_->NumThreads(), n,\n+            [fn, n](size_t i) { fn(static_cast<int>(i), n); });\n+      };\n+\n+      done_event_ = done_event_.FlatMap(parallelize);\n+      return;\n+    }\n+\n+    // If we are not using oneDNN with async support, it is perfectly safe to\n+    // block here as Worker implements work stealing that guarantees forward\n+    // progress and deadlock freedom, even if we are running in the same thread\n+    // pool as the Eigen thread_pool.\n     tsl::BlockUntilReady(Worker::Parallelize(thread_pool_,\n                                              thread_pool_->NumThreads(), n,\n                                              [fn, n](size_t i) { fn(i, n); }));\n@@ -65,8 +104,18 @@ class OneDnnThreadPool final\n     thread_pool_ = thread_pool;\n   }\n \n+  tsl::AsyncValueRef<tsl::Chain> done_event() const { return done_event_; }\n+\n  private:\n   Eigen::ThreadPoolInterface* thread_pool_;\n+\n+  // Indicates if we are using oneDNN with async support. TODO(intel-tf): Remove\n+  // this flag when oneDNN supports asynchronous execution by default.\n+  bool is_async_ = false;\n+\n+  // Async value that signals completion of the last scheduled parallel loop.\n+  // This is used only when is_async_ is true.\n+  tsl::AsyncValueRef<tsl::Chain> done_event_;\n };\n \n }  // namespace xla::cpu"
        },
        {
            "sha": "8a204377b5fd987e0d840a313bb93fe9e98999e6",
            "filename": "third_party/xla/xla/backends/cpu/runtime/onednn/onednn_threadpool_test.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_threadpool_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_threadpool_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_threadpool_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -53,7 +53,12 @@ static absl::StatusOr<dnnl::graph::graph> CreateExpGraph(\n \n TEST(OneDnnThreadPoolTest, Binary) {\n   tsl::thread::ThreadPool threads(tsl::Env::Default(), \"test\", 32);\n+\n+#ifdef ENABLE_ONEDNN_ASYNC\n+  OneDnnThreadPool threadpool(threads.AsEigenThreadPool(), /*is_async=*/true);\n+#else\n   OneDnnThreadPool threadpool(threads.AsEigenThreadPool());\n+#endif  // ENABLE_ONEDNN_ASYNC\n \n   int64_t d0 = 100;\n   int64_t d1 = 1000;\n@@ -100,6 +105,10 @@ TEST(OneDnnThreadPoolTest, Binary) {\n   // Execute compiled oneDNN graph on the CPU stream.\n   compiled_partitions[0].execute(stream, {src}, {dst});\n \n+#ifdef ENABLE_ONEDNN_ASYNC\n+  stream.wait();\n+#endif\n+\n   for (int i = 0; i < num_elements; ++i) {\n     EXPECT_NEAR(dst_data[i], std::exp(1.0f), 1e-5);\n   }"
        },
        {
            "sha": "2e2e364d6e6cc17363ff4a05a5879393b09b9eb8",
            "filename": "third_party/xla/xla/backends/cpu/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -56,6 +56,7 @@ xla_cc_test(\n         \"//xla/hlo/utils:hlo_query\",\n         \"//xla/tests:xla_internal_test_main\",\n         \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/base:no_destructor\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/strings\","
        },
        {
            "sha": "aae721bdfe710161276825f33bb7a83352ee7598",
            "filename": "third_party/xla/xla/backends/cpu/transforms/collectives/BUILD",
            "status": "added",
            "additions": 52,
            "deletions": 0,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,52 @@\n+load(\"//xla:xla.default.bzl\", \"xla_cc_test\")\n+load(\"//xla/tsl/platform:rules_cc.bzl\", \"cc_library\")\n+\n+package(\n+    # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n+    default_visibility = [\":friends\"],\n+    licenses = [\"notice\"],\n+)\n+\n+package_group(\n+    name = \"friends\",\n+    includes = [\n+        \"//xla:friends\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"all_reduce_combiner\",\n+    srcs = [\"all_reduce_combiner.cc\"],\n+    hdrs = [\"all_reduce_combiner.h\"],\n+    deps = [\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/pass:hlo_pass\",\n+        \"//xla/hlo/transforms/collectives:all_reduce_combiner\",\n+        \"//xla/service:hlo_domain_map\",\n+        \"//xla/service/gpu:backend_configs_cc\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"all_reduce_combiner_test\",\n+    srcs = [\"all_reduce_combiner_test.cc\"],\n+    deps = [\n+        \":all_reduce_combiner\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:filecheck\",\n+        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/hlo/utils:hlo_matchers\",\n+        \"//xla/service:collective_utils\",\n+        \"//xla/tsl/platform:status_matchers\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)"
        },
        {
            "sha": "105ad861eff106faa556ddc17403059235d22fb3",
            "filename": "third_party/xla/xla/backends/cpu/transforms/collectives/all_reduce_combiner.cc",
            "status": "added",
            "additions": 33,
            "deletions": 0,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2Fall_reduce_combiner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2Fall_reduce_combiner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2Fall_reduce_combiner.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,33 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/cpu/transforms/collectives/all_reduce_combiner.h\"\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/transforms/collectives/all_reduce_combiner.h\"\n+\n+namespace xla::cpu {\n+\n+absl::StatusOr<bool> CpuAllReduceCombiner::Run(\n+    HloModule* module,\n+    const absl::flat_hash_set<absl::string_view>& execution_threads) {\n+  return RunWithKeyCombiner(module, execution_threads,\n+                            AllReduceCombiner::CombineKey);\n+}\n+\n+}  // namespace xla::cpu"
        },
        {
            "sha": "85d8560337e325962dc78a0ef42860009bbfe674",
            "filename": "third_party/xla/xla/backends/cpu/transforms/collectives/all_reduce_combiner.h",
            "status": "added",
            "additions": 44,
            "deletions": 0,
            "changes": 44,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2Fall_reduce_combiner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2Fall_reduce_combiner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2Fall_reduce_combiner.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,44 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_CPU_TRANSFORMS_COLLECTIVES_ALL_REDUCE_COMBINER_H_\n+#define XLA_BACKENDS_CPU_TRANSFORMS_COLLECTIVES_ALL_REDUCE_COMBINER_H_\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/pass/hlo_pass_interface.h\"\n+#include \"xla/hlo/transforms/collectives/all_reduce_combiner.h\"\n+\n+namespace xla::cpu {\n+\n+// Combines `AllReduce` ops into a single larger `AllReduce` op to maximize\n+// network bandwidth usage.\n+class CpuAllReduceCombiner : public AllReduceCombiner {\n+ public:\n+  using AllReduceCombiner::AllReduceCombiner;\n+\n+  absl::string_view name() const override { return \"cpu-all-reduce-combiner\"; }\n+\n+  using HloPassInterface::Run;\n+  absl::StatusOr<bool> Run(\n+      HloModule* module,\n+      const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n+};\n+\n+}  // namespace xla::cpu\n+\n+#endif  // XLA_BACKENDS_CPU_TRANSFORMS_COLLECTIVES_ALL_REDUCE_COMBINER_H_"
        },
        {
            "sha": "8f3422bc405940009fc0d24720be5f6e9f9bce2f",
            "filename": "third_party/xla/xla/backends/cpu/transforms/collectives/all_reduce_combiner_test.cc",
            "status": "added",
            "additions": 103,
            "deletions": 0,
            "changes": 103,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2Fall_reduce_combiner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2Fall_reduce_combiner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fcollectives%2Fall_reduce_combiner_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,103 @@\n+/* Copyright 2024 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+\n+You may obtain a copy of the License at\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/cpu/transforms/collectives/all_reduce_combiner.h\"\n+\n+#include <cstdint>\n+#include <limits>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status_matchers.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_print_options.h\"\n+#include \"xla/hlo/testlib/filecheck.h\"\n+#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla::cpu {\n+namespace {\n+\n+using CpuAllReduceCombinerTest = HloHardwareIndependentTestBase;\n+\n+absl::StatusOr<bool> RunCombiner(HloModule* module) {\n+  return CpuAllReduceCombiner(std::numeric_limits<int64_t>::max(),\n+                              std::numeric_limits<int64_t>::max())\n+      .Run(module);\n+}\n+\n+TEST_F(CpuAllReduceCombinerTest, CombinesCollectivesUpToSpecifiedThreshold) {\n+  constexpr absl::string_view kHloString = R\"(\n+HloModule m\n+\n+add {\n+  a = f32[] parameter(0)\n+  b = f32[] parameter(1)\n+  ROOT add = f32[] add(a, b)\n+}\n+\n+ENTRY main {\n+  p0 = f32[16,256,8,128]{3,2,1,0} parameter(0)\n+  p1 = f32[32,256,2,128]{3,2,1,0} parameter(1)\n+  p2 = f32[16,8,128,256]{3,2,1,0} parameter(2)\n+  p3 = f32[32,256,3072]{2,1,0} parameter(3)\n+  p4 = f32[16,3072,256]{2,1,0} parameter(4)\n+  p5 = f32[66,1024]{1,0} parameter(5)\n+  p6 = f32[2,32768,256]{2,1,0} parameter(6)\n+  r0 = f32[16,256,8,128]{3,2,1,0} all-reduce(p0), channel_id=1, replica_groups={{0,1,2,3}}, use_global_device_ids=true, to_apply=add\n+  r1 = f32[32,256,2,128]{3,2,1,0} all-reduce(p1), channel_id=2, replica_groups={{0,1,2,3}}, use_global_device_ids=true, to_apply=add\n+  r2 = f32[16,8,128,256]{3,2,1,0} all-reduce(p2), channel_id=3, replica_groups={{0,1,2,3}}, use_global_device_ids=true, to_apply=add\n+  r3 = f32[32,256,3072]{2,1,0} all-reduce(p3), channel_id=4, replica_groups={{0,1,2,3}}, use_global_device_ids=true, to_apply=add\n+  r4 = f32[16,3072,256]{2,1,0} all-reduce(p4), channel_id=5, replica_groups={{0,1,2,3}}, use_global_device_ids=true, to_apply=add\n+  r5 = f32[66,1024]{1,0} all-reduce(p5), channel_id=6, replica_groups={{0,1,2,3}}, use_global_device_ids=true, to_apply=add\n+  r6 = f32[2,32768,256]{2,1,0} all-reduce(p6), channel_id=7, replica_groups={{0,1,2,3}}, use_global_device_ids=true, to_apply=add\n+  ROOT tuple = tuple(r0, r1, r2, r3, r4, r5, r6)\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(kHloString));\n+  EXPECT_THAT(RunCombiner(module.get()), absl_testing::IsOkAndHolds(true));\n+\n+  constexpr absl::string_view kExpected = R\"('\n+    // CHECK:      ENTRY\n+    // CHECK-DAG:  %[[P0:.*]] = parameter(0)\n+    // CHECK-DAG:  %[[P1:.*]] = parameter(1)\n+    // CHECK-DAG:  %[[P2:.*]] = parameter(2)\n+    // CHECK-DAG:  %[[P3:.*]] = parameter(3)\n+    // CHECK-DAG:  %[[P4:.*]] = parameter(4)\n+    // CHECK-DAG:  %[[P5:.*]] = parameter(5)\n+    // CHECK-DAG:  %[[P6:.*]] = parameter(6)\n+    // CHECK:      all-reduce(%[[P0]], %[[P1]], %[[P2]], %[[P3]], %[[P4]], %[[P5]], %[[P6]])\n+    // CHECK-SAME: channel_id=1,\n+    // CHECK-SAME: replica_groups={\n+    // CHECK-SAME:   {0,1,2,3}\n+    // CHECK-SAME: },\n+    // CHECK-SAME: use_global_device_ids=true,\n+    // CHECK-SAME: to_apply=%add\n+  )\";\n+\n+  EXPECT_TRUE(*RunFileCheck(\n+      module->ToString(HloPrintOptions()\n+                           .set_print_operand_index_annotation_interval(false)\n+                           .set_print_operand_shape(false)\n+                           .set_print_result_shape(false)),\n+      kExpected));\n+}\n+\n+}  // namespace\n+}  // namespace xla::cpu"
        },
        {
            "sha": "9a349bc5224eb19d9e76439da4ae8458b071269a",
            "filename": "third_party/xla/xla/backends/cpu/transforms/dot_library_rewriter.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 8,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -199,19 +199,24 @@ void DotLibraryRewriter::AddFusionCandidates(\n   }\n }\n \n-absl::Status DotLibraryRewriter::MergeFusionInstructions(\n-    HloFusionInstruction* main, HloFusionInstruction* neighbor,\n-    FusionDirection dir) {\n+absl::StatusOr<HloFusionInstruction*>\n+DotLibraryRewriter::MergeFusionInstructions(HloFusionInstruction* main,\n+                                            HloFusionInstruction* neighbor,\n+                                            FusionDirection dir) {\n   VLOG(3) << \"  \" << FusionDirectionToString(dir)\n           << \": Fusing with: \" << neighbor->ToString();\n   if (dir == FusionDirection::kUp) {\n     main->MergeFusionInstruction(neighbor);\n     TF_RETURN_IF_ERROR(main->parent()->RemoveInstruction(neighbor));\n-  } else if (dir == FusionDirection::kDown) {\n+    return main;\n+  }\n+  if (dir == FusionDirection::kDown) {\n     neighbor->MergeFusionInstruction(main);\n     TF_RETURN_IF_ERROR(neighbor->parent()->RemoveInstruction(main));\n+    return neighbor;\n   }\n-  return absl::OkStatus();\n+  return InvalidArgument(\"Invalid fusion direction: %s\",\n+                         FusionDirectionToString(dir));\n }\n \n absl::StatusOr<HloInstruction*> DotLibraryRewriter::GrowFusion(\n@@ -246,15 +251,17 @@ absl::Status DotLibraryRewriter::FuseNeighbors(HloFusionInstruction* fusion,\n     auto [instr, dir] = frontier.front();\n     frontier.pop();\n     if (dir != FusionDirection::kUp && dir != FusionDirection::kDown) {\n-      return InvalidArgument(\"Invalid travel direction: %c\", dir);\n+      return InvalidArgument(\"Invalid travel direction: %s\",\n+                             FusionDirectionToString(dir));\n     }\n \n     // If `instr` is another fusion of the same library type, fuse it.\n     // We don't need to add its neighbors to the frontier because anything that\n     // can be fused would have already been fused into `instr`.\n     if (IsCustomFusionWithKind(instr, lib->fusion_kind())) {\n-      TF_RETURN_IF_ERROR(MergeFusionInstructions(\n-          fusion, Cast<HloFusionInstruction>(instr), dir));\n+      TF_ASSIGN_OR_RETURN(fusion,\n+                          MergeFusionInstructions(\n+                              fusion, Cast<HloFusionInstruction>(instr), dir));\n       continue;\n     }\n "
        },
        {
            "sha": "c92670049ab7117a97b543ef1ebfc0aceb95fbcb",
            "filename": "third_party/xla/xla/backends/cpu/transforms/dot_library_rewriter.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -94,9 +94,9 @@ class DotLibraryRewriter : public HloModulePass {\n   // Merges two fusions `main` and `neighbor` together. `main` is the current\n   // fusion instruction we are growing. `neighbor` is a neighboring fusion node\n   // found through BFS from `main`.\n-  absl::Status MergeFusionInstructions(HloFusionInstruction* main,\n-                                       HloFusionInstruction* neighbor,\n-                                       FusionDirection dir);\n+  absl::StatusOr<HloFusionInstruction*> MergeFusionInstructions(\n+      HloFusionInstruction* main, HloFusionInstruction* neighbor,\n+      FusionDirection dir);\n \n   // Fuses `to_fuse` into the fusion `fusion` based on the specified direction.\n   // Returns the pointer to the new `to_fuse` node in the fusion region."
        },
        {
            "sha": "180b1ec647743876b023214de23f85cc06c4b0dd",
            "filename": "third_party/xla/xla/backends/cpu/transforms/dot_library_rewriter_test.cc",
            "status": "modified",
            "additions": 46,
            "deletions": 8,
            "changes": 54,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include <vector>\n \n #include <gtest/gtest.h>\n+#include \"absl/base/no_destructor.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/log/log.h\"\n #include \"absl/strings/match.h\"\n@@ -61,6 +62,12 @@ class CpuLibraryTest : public TargetMachineTestBase {\n     bool changed;\n   };\n \n+  static const DotRewriteTestSpec& GetDefaultTestSpec() {\n+    static const absl::NoDestructor<DotRewriteTestSpec> kDefaultTestSpec(\n+        {\"xnn\", \"f32\", \"f32\", \"znver3\", \"+avx,+avx2\", \"dot\"});\n+    return *kDefaultTestSpec;\n+  }\n+\n   virtual void RunTest(absl::string_view hlo_template,\n                        FusionProperties expected) {}\n \n@@ -399,21 +406,16 @@ class CpuLibraryFusionTypeTest\n       public ::testing::WithParamInterface<std::string> {\n  public:\n   static std::string Name(const ::testing::TestParamInfo<std::string>& info) {\n-    return absl::StrCat(kLib, \"_\", info.param, \"_\", kDType, \"_\", kCpuName);\n+    return info.param;\n   }\n \n  protected:\n   void RunTest(absl::string_view hlo_template,\n                FusionProperties expected) override {\n-    DotRewriteTestSpec spec = {std::string(kLib),      std::string(kDType),\n-                               std::string(kDType),    std::string(kCpuName),\n-                               std::string(kFeatures), GetParam()};\n+    DotRewriteTestSpec spec = GetDefaultTestSpec();\n+    spec.fusion_mode = GetParam();\n     RunTestInternal(spec, hlo_template, expected);\n   }\n-  static constexpr absl::string_view kLib = \"xnn\";\n-  static constexpr absl::string_view kDType = \"f32\";\n-  static constexpr absl::string_view kCpuName = \"znver3\";\n-  static constexpr absl::string_view kFeatures = \"+avx,+avx2\";\n };\n \n TEST_P(CpuLibraryFusionTypeTest, AllEltwiseFusion) {\n@@ -521,5 +523,41 @@ INSTANTIATE_TEST_SUITE_P(CpuLibraryFusionTypeTestSuite,\n                                               std::string(\"greedy\")}),\n                          CpuLibraryFusionTypeTest::Name);\n \n+TEST_F(CpuLibraryTest, UpdateFusion) {\n+  //                      c\n+  //                       \\\n+  //   b ------------------ dot2\n+  //    \\                       \\\n+  // a -- sub1 -- add1 -- dot1 -- add2\n+  //\n+  // In \"dot\" mode, `dot2` + `add2` get fused first (call this `fusion2`). Then\n+  // `dot1` will create a new fusion (`fusion1`), fuse with `add1, and try to\n+  // fuse with `fusion2`. Since fusions are merged by updating the consumer\n+  // fusion, `fusion1` will get absorbed into `fusion2`. When we continue\n+  // growing the fusion around `dot1`, we need to use `fusion2` instead of\n+  // `fusion1`. This test will fail if the old `fusion1` is used (`sub1` will\n+  // not recognize `fusion1` as its user).\n+  const absl::string_view hlo_template = R\"(\n+    HloModule matmul\n+\n+    ENTRY %main {\n+      %a = $in_dtype[64,64] parameter(0)\n+      %b = $in_dtype[64,64] parameter(1)\n+      %c = $in_dtype[64,64] parameter(2)\n+      %sub1 = $in_dtype[64,64] subtract(%a, %b)\n+      %add1 = $in_dtype[64,64] add(%a, %sub1)\n+      %dot1 = $in_dtype[64,64] dot(%add1, %b), lhs_contracting_dims={1},\n+                                            rhs_contracting_dims={0}\n+      %dot2 = $in_dtype[64,64] dot(%b, %c), lhs_contracting_dims={1},\n+                                            rhs_contracting_dims={0}\n+      ROOT %add2 = $in_dtype[64,64] add(%dot1, %dot2)\n+    })\";\n+\n+  DotRewriteTestSpec spec = GetDefaultTestSpec();\n+  spec.fusion_mode = \"dot\";\n+  RunTestInternal(spec, hlo_template,\n+                  FusionProperties{HloOpcode::kAdd, 3, 8, true});\n+}\n+\n }  // namespace\n }  // namespace xla::cpu"
        },
        {
            "sha": "7e92e5d44e97a8b2eb5d252f4a23892e3b47b301",
            "filename": "third_party/xla/xla/backends/cpu/transforms/xnn_graph_fusion.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 9,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_graph_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_graph_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_graph_fusion.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -131,16 +131,8 @@ bool XnnGraphFusion::IsOpSupported(const HloInstruction* instr) {\n   switch (instr->opcode()) {\n     case HloOpcode::kBitcast:\n       return IsBitcastOpSupportedByXnn(instr);\n-    case HloOpcode::kBroadcast: {\n-      if (instr->GetModule()\n-              ->config()\n-              .debug_options()\n-              .xla_cpu_experimental_xnn_graph_fusion_mode() !=\n-          DebugOptions::XNN_GRAPH_FUSION_MODE_GREEDY_SLINKY) {\n-        return false;\n-      }\n+    case HloOpcode::kBroadcast:\n       return IsBroadcastOpSupportedByXnn(instr);\n-    }\n     case HloOpcode::kReduce:\n       return IsReduceOpSupportedByXnn(instr);\n     default:"
        },
        {
            "sha": "6750a8495247413f368b9fa63d859085cadcdfb7",
            "filename": "third_party/xla/xla/backends/cpu/xnn_gemm_config.cc",
            "status": "modified",
            "additions": 47,
            "deletions": 47,
            "changes": 94,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_gemm_config.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_gemm_config.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_gemm_config.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -149,7 +149,7 @@ static constexpr GemmFilter BF16BF16F32GemmFilter{\n };\n \n static constexpr GemmFilter AMDRomeGemmFilter{\n-  /*input_range=*/{16, 2048},\n+  /*input_range=*/{16, 4096},\n   /*lhs_dtype=*/PrimitiveType::F32,\n   /*rhs_dtype=*/PrimitiveType::F32,\n   /*out_dtype=*/PrimitiveType::F32,\n@@ -158,53 +158,53 @@ static constexpr GemmFilter AMDRomeGemmFilter{\n static constexpr Net AMDRomeNet{\n   /*scaler=*/{\n     /*mean=*/\n-    {{ 1018.0043402777778, 1023.5008680555555, 1025.861328125, 6.616354874682953, 6.620083771919308, 6.63456382646144 }},\n+    {{ 2031.4479060265578, 2036.3171603677222, 2062.2170582226763, 7.29227087924762, 7.308301476602625, 7.331674465299577 }},\n     /*scale=*/\n-    {{ 590.632963260763, 593.7150826714844, 588.1463320809286, 0.9965492348670616, 1.0053835765793744, 0.9754062267657724 }}\n+    {{ 1188.2177375470617, 1178.7350461452038, 1179.7790996965598, 1.0416890873676914, 1.0053399234375506, 0.9757991392501179 }},\n   },\n   /*hidden_layer_1=*/{\n     /*weights=*/{{\n-      {{ 1.005891244892035, -0.11072959330426384, -0.968046373485514, -4.921521725424851, -0.13899276332759042, -1.226293159684938 }},\n-      {{ -1.2502714170922153, -1.1765486776310423, 0.4888716998554182, 0.5172335453177302, -0.593110373636639, 0.1209811095977735 }},\n-      {{ -0.18095204827877465, -0.06060134530184746, -0.3750576441489519, 0.8188111073502161, 0.3576805251431741, 1.4968701417615413 }},\n-      {{ -0.05111798751008719, 0.07769076545705815, 0.6207635489778949, 3.6101378942470967, -0.05282332398428117, 1.7854763674893495 }},\n-      {{ 0.747350403236783, 0.04930450878767915, 0.8777099456443157, 1.4990255665580505, 0.08212232867228593, -1.9843375290758656 }},\n-      {{ 0.5541966277545818, -0.33159380874523126, -0.3194666063636952, 1.6816423644238223, 0.1017686813844035, 3.1265875450394813 }},\n-      {{ 0.7345608720339312, 1.5974970323865725, -2.2148504671311953, 0.5363830361034387, 0.3700332861259481, 0.9331234440564571 }},\n-      {{ 1.4423494345704555, 0.289382200477869, 1.5110082992053955, 1.418682530523278, -0.5749656156984766, 2.684031259217246 }},\n+      {{ 0.5255922128957278, -0.8065013670906714, -0.5264014380189966, -1.2772498330118651, 1.3840216299823802, 0.7322759674330881 }},\n+      {{ -0.7597171548555842, -1.2571169773685882, -0.32518437620636936, 1.0212806356673838, 0.9165371224616725, -0.19250317971610814 }},\n+      {{ -2.3497882574965994, 0.23878289300722322, -2.5867259166595944, 0.8432052252434499, -0.7374592701571068, 0.6061228206232958 }},\n+      {{ 0.3412638507438349, 0.009127030753615727, -0.43271581733053577, 0.3058216852138156, 0.4132978840654225, 0.08892908864656021 }},\n+      {{ -0.3843556431761765, -0.5398088470059381, -2.0478454682095735, -1.9041927205327738, -1.0368295384919808, -0.1653666006655781 }},\n+      {{ 0.9415170642828504, -0.4671602009419241, -2.594401365132767, 0.5011818371933664, 2.6743454901058725, 1.090931094328555 }},\n+      {{ -2.030867525769208, 0.9360281369657524, -2.179490537456837, 0.6315631977398317, -0.2797813498393135, 1.1780045163240112 }},\n+      {{ 2.026780502536945, 1.1382782700184098, 0.7076892737809293, -0.5003242829913847, 1.7337823655903326, 0.676979521067241 }},\n     }},\n     /*biases=*/{\n-      { 1.0309774603375907, 0.6465236073322296, 3.553393762532912, -0.8185749009865861, -0.12955426436728715, 0.8031554507587597, -1.5785991424170187, -0.39445212677049063 }\n+      { 2.827760670625431, -0.9347274494671962, 1.7748650815163647, -0.5102747570142624, 1.1443725632238269, 2.0573020231014616, 0.33721201132380757, 2.7437956980307643 },\n     }\n   },\n   /*hidden_layer_2=*/{\n     /*weights=*/{{\n-      {{ 0.5283786603352238, -0.056889406800860146, 0.6606078794503449, 0.48144968239995534, 0.010554846273878095, -0.14799959162846965, 0.20457525406298369, -0.12661568456264205 }},\n-      {{ -0.9534585055098438, -0.10012840023501332, -0.5795955688342004, 1.9348789870642515, 0.21271731229957186, 0.1557077642737526, 1.5288709351139655, -0.7002696129400411 }},\n-      {{ 2.1906088364770784, 0.07703067791952263, 2.1646753484073655, -0.32251840895547773, 0.6850197180505169, 0.30061421444806946, 1.0728025841881765, -0.8100244450669523 }},\n-      {{ 0.8106365294738354, -0.3410735969241413, 0.7910924608271775, -0.07017938451436888, 0.16051916138347214, 0.3004275708609215, 0.7729045870717262, -0.2332237341201925 }},\n-      {{ 0.07246756191918226, -0.05758991153686244, 0.911745169839482, 1.2510377533921035, -1.182537901423303, -1.295182969102456, -1.904956642808503, 0.007010431897136803 }},\n-      {{ -0.8733376736355871, 0.157671979745821, -1.0372041545921873, 3.3000069112365584, 0.25551941086911717, 0.9589328110123956, -0.23856740081287128, -2.0315351809352586 }},\n-      {{ -1.9337567589656532, 1.4676259894002257, 1.4886721579905993, -1.5705845737356183, 0.48937401463732866, 1.083620050144208, -1.0031665521883135, -1.2660789079048749 }},\n-      {{ 2.4310441535271687, 0.49189784223311395, 0.31483156395428413, -0.0865355927145238, 0.7631527157107736, -2.7077958375575055, -0.9228446079924654, -0.7391110100336947 }}\n+      {{ 2.571821311709108, 0.16869445337763503, 0.3541411973512104, 0.31040383433531593, -1.9138308971941267, 1.577267326066108, 1.0358680188904088, -0.48597239908310547 }},\n+      {{ -0.3168524372865204, -0.8109707535168992, -0.6883758912881943, 0.20041683878416458, 0.29562419861502953, 2.9699371941875183, -0.06378706528945598, -1.2627270412739198 }},\n+      {{ 1.2121865841893051, 0.4324679330555888, 0.5756742637802713, -0.3965637421226802, -0.8316876650525071, 1.4267737797853521, 0.6590628275882154, 1.0969896994507335 }},\n+      {{ 0.08152092107879703, 0.987281670566132, 2.711801967605775, 0.03262333498333622, -0.24851434369301018, 0.5857580261361529, -0.14172228489696118, 1.0096244465236095 }},\n+      {{ -1.099617291565094, -0.96182176932886, 1.1198642662894356, 0.09569259551658717, 0.9865508260397995, -1.7073686127591108, 0.8545686868857858, 1.276785903326864 }},\n+      {{ 0.6284115174399925, -0.5692706408214737, -0.3776497427936689, 0.2850473804130665, 0.5611912673866001, 0.7074167980672433, 1.3602397130866593, -2.4641849404042104 }},\n+      {{ -0.2235255127724266, -0.6066818030776572, 2.098453748102861, -0.551860833640914, -0.6607678541967575, -1.0968858307838945, -3.097129404864497, 1.22936241411423 }},\n+      {{ -0.35359032516179434, 0.16659401401800453, 0.7409562527506246, 0.12880569714035928, 1.6235584538175323, 0.35055754805485, -0.5085408039033421, 0.03832167245213557 }},\n     }},\n     /*biases=*/{\n-      { 0.3486705866196229, 2.2776343748673153, 0.10764831721796844, 0.09166185120840216, -1.0034214854612917, -0.927160996221299, 1.5172112381212808, 0.4772212967805247 }\n+      { -0.9650088973529635, 0.18404512445819377, -1.1301082618712814, -0.4114680200097482, -2.16829227705252, -0.792693003568079, 2.0186809343196432, 0.6651750830570318 },\n     }\n   },\n   /*output_layer=*/{\n     /*weights=*/{{\n-      {{ -0.5896335640757622, 2.3283855361577914, -1.9754605319484158, -0.6632271049751296, 1.9086390756642784, 3.7433099466616238, 1.824432545010804, 2.09625742741301 }}\n+      {{ -3.4950798141841886, 3.052869401349734, -1.9332425183341917, -2.4468455334890375, 3.1182134156177734, 2.662143418701658, 3.609609051057281, -1.6114776062537006 }},\n     }},\n     /*biases=*/{\n-      { -0.04977871506692414 }\n+      { -0.8627209596023582 },\n     }\n   },\n   /*threshold=*/0.03,\n };\n \n static constexpr GemmFilter AMDGenoaGemmFilter{\n-  /*input_range=*/{16, 2048},\n+  /*input_range=*/{16, 4096},\n   /*lhs_dtype=*/PrimitiveType::F32,\n   /*rhs_dtype=*/PrimitiveType::F32,\n   /*out_dtype=*/PrimitiveType::F32,\n@@ -213,49 +213,49 @@ static constexpr GemmFilter AMDGenoaGemmFilter{\n static constexpr Net AMDGenoaNet {\n   /*scaler=*/{\n     /*mean=*/\n-    {{ 1002.1257625527921, 1040.082590333177, 1029.2266541529798, 6.598251685888309, 6.6404292804559635, 6.654739928938151 }},\n+    {{ 2048.487742594484, 2032.4805924412667, 2042.0275791624106, 7.311636506981553, 7.331182177414692, 7.324348610024091 }},\n     /*scale=*/\n-    {{ 594.7876923848536, 596.4073362076931, 579.6412706089599, 0.9806421276088567, 1.0047695259963145, 0.9426741875163773 }}\n+    {{ 1191.317145630777, 1166.4230415375375, 1162.7572402044934, 1.0130577584567735, 0.9372130582909888, 0.9819331632142719 }},\n   },\n   /*hidden_layer_1=*/{\n     /*weights=*/{{\n-      {{ -1.8525957121690557, -0.12363449157789586, -0.8386369273170659, -3.3954448946951414, 0.33886983245776847, -0.9317201523227778 }},\n-      {{ 0.5120871227810689, -1.5214338320394882, -0.7274651337778577, 1.3200335397974383, 0.5923648903998096, 1.7241300558638806 }},\n-      {{ -1.8962086199924455, -1.7249686491398133, -0.15047446639707035, 1.1356266853003538, 2.70970817913586, 0.7154911861570797 }},\n-      {{ -0.0020642101422613684, 0.14097136562712495, -0.09163191463561046, -0.02820803725731568, 0.03955304538877561, 0.16661173026752624 }},\n-      {{ -2.001943294276495, 1.4970193262821043, 0.7777143265827485, 2.4639584696544814, -2.5991183905189827, -1.7850169579413313 }},\n-      {{ 1.447549192320386, 1.361173224199936, -0.43481695242532376, 0.8671054211799711, -0.25280176689036743, 2.5275631466098756 }},\n-      {{ -0.1441737229514477, -0.3347815066193075, -0.4611605626954958, 2.181799166007114, 1.6323192872442907, 0.15928222502988382 }},\n-      {{ -2.4693645353916667, 2.0428513209522623, 1.749924045625967, 1.7019213519700969, 1.142024009890298, 0.8079292507334053 }},\n+      {{ -0.3975566315544443, 0.5914998393825349, 0.6099048505253704, -2.2657754130482575, 0.36614796953745665, -0.9019941522654611 }},\n+      {{ -1.634528631004246, -1.0247790097319367, 0.7441596497436759, 1.1627072134985457, 0.05409335988074912, -0.12091065051829138 }},\n+      {{ 0.38395072299848293, 0.6541884828037803, 0.417837898603066, -0.9405446354332785, 2.184810649384631, -0.36876630139170674 }},\n+      {{ 1.4311717327837925, 0.9019482519954495, 0.010222966815173684, 0.3734603575926762, -0.48722286699557477, 0.6097423536728197 }},\n+      {{ -0.7136793187709407, -1.9428210404652928, 0.4274609198312262, 0.7241649472475438, 0.7127139917668667, -0.17169269406677637 }},\n+      {{ 0.7274093691413374, 1.5619764328746881, 0.3132760663502329, 0.1150444561729908, 0.2015964262316955, -1.6488397218364703 }},\n+      {{ -0.2753144111803734, 0.851664634951511, -0.7668837132534746, 0.8536953128922471, 0.5346385907475031, -0.3903852123459044 }},\n+      {{ -0.33049518181245935, -0.1445885038395346, 0.33671360297244707, 0.19923558301288513, 0.47714692266995923, 2.673625950077934 }},\n     }},\n     /*biases=*/{\n-      { 1.5113512311183828, 1.1809617131571573, 0.4478042727248335, -0.7947383308647096, 0.9825820925820611, 2.3808221280278645, -0.4758496641489877, -0.17036794796484162 }\n+      { 1.8781920773242509, 0.6510580145727756, 1.3641835181490685, -1.237083419397511, 0.09563962519162661, 1.0633713668067988, -0.2750294272946441, 0.4082406241441991 },\n     }\n   },\n   /*hidden_layer_2=*/{\n     /*weights=*/{{\n-      {{ 0.35014293742424724, -0.5476873131211425, 2.120121365055135, 0.2526392749218728, -0.9407987661758053, -0.9846910595845514, 0.48052568401528156, 0.3180570478836074 }},\n-      {{ -0.7150926363558526, -0.8982987199655207, 1.5360045616379934, 0.1803870098694977, -3.472436216409119, 1.0044744229912244, 0.4335209413598261, 1.041064125260285 }},\n-      {{ 0.8966091979738551, 2.227321493016081, -1.4494415364024744, 0.0254402271585605, 1.537814361721512, 1.3889169541326774, -0.16388027659485285, 1.7176584253327756 }},\n-      {{ -0.0597193070244571, -2.5061384854500623, 2.124958864280429, 0.020011322193699232, 0.48193219767756923, 1.323504600240459, 1.9316400738347115, 0.9369893381605147 }},\n-      {{ 0.032699385072007786, -0.9107111450265581, 0.5333081096223299, -0.03148698112648736, -0.16377114190322742, -1.6085833510134837, 0.7968443974614786, 2.238778726588351 }},\n-      {{ -1.5463140026380815, 1.5303232342633923, 1.3050928202993113, 0.17310173303944465, -0.9857258240351916, -0.9550401224056498, -0.0071639117187034555, -0.7976265480773017 }},\n-      {{ -2.2035284133385966, -0.9376946654220445, 1.3260159557423135, -0.406540234329094, 0.9533782897195586, 2.4910588396009277, -1.3676852361286786, 0.6322307655713885 }},\n-      {{ 0.32147827378305643, 0.26619936190034904, -1.200452781975383, 0.00920972156405369, 2.8156283745109, -1.229898728424551, 1.3389598114381762, 1.7166384524807266 }},\n+      {{ 1.482788775138106, -0.5911919348052194, -0.35265948412831416, 0.5693173975201452, 0.08299331485534553, -1.0926309595949408, 0.334160671733911, -0.8259113265483281 }},\n+      {{ -0.7244072332431708, 1.7167578358580047, -0.4425799291591407, 0.38193961610444616, -0.3131049026459214, 0.7057668457879581, -0.8977670579096759, -1.1564071580034785 }},\n+      {{ 0.2358887563481682, 0.845047198622242, 0.3965633248481624, -0.9292260319808021, 0.38780851270938177, 0.9073719197977955, 0.8942857890487362, 2.2078844573893486 }},\n+      {{ 0.7588397006376895, 0.39649528525833017, 1.1922103753418032, -0.2623025347145879, -1.8688404509544276, 0.23950836230216038, 0.15018196046213705, 1.1091046070474726 }},\n+      {{ -0.06639877236719088, 0.09408482409872725, 0.08853697547037886, -0.027191640785169502, -0.025050403848262424, -0.14821218627938373, -0.05119778874800481, -0.003846457076482196 }},\n+      {{ -1.3626737341753659, -0.509211567650967, -1.3709529389911908, 0.8181695565961004, -0.9154056938786789, 1.6786394527771, -0.38910973671573107, 0.6109302318778375 }},\n+      {{ -0.9490250745418807, -0.22890259271729135, -0.7669763564967859, -1.2378100390537607, 0.9325554827865082, -0.7707072257516585, -0.6101643395959798, 0.6438447441624673 }},\n+      {{ 1.1581876959277013, 1.4439015663052703, -1.4659507082977212, 1.0425420146162472, -0.20891484120663645, 0.3292514803046433, 0.38947771607697135, 0.06588859566944062 }},\n     }},\n     /*biases=*/{\n-      { 0.9699621387917686, 0.5909615635903002, 1.427690501080743, 0.8892984037070786, -0.8768819880157831, 3.2935191809063777, 1.8570755726618182, -1.0853011858156631 }\n+      { 2.0991435035679293, 0.9220598032166089, 0.001237522670163396, -0.2035381110666839, -0.7214610628375114, -2.275782698263265, 3.2572710355363337, -1.309956720253099 },\n     }\n   },\n   /*output_layer=*/{\n     /*weights=*/{{\n-      {{ 2.253756860038231, 2.6258281376128605, -1.6079113669729557, -4.006565437256236, -2.8600538503590087, 2.808280959332861, 2.8146068804622777, 2.604358926679522 }},\n+      {{ -2.214950317234679, 2.3173207097966624, -2.4148863077632057, 2.440952250974181, 0.016504153668811035, 3.00219780922754, 2.454200734592688, 2.444832006369846 }},\n     }},\n     /*biases=*/{\n-      { 0.26142347527936727 }\n+      { -0.2538826384470055 },\n     }\n   },\n-  /*threshold=*/0.03,\n+  /*threshold=*/0.05,\n };\n \n // clang-format on"
        },
        {
            "sha": "a27df279a24a293b331d44e94c002d4c4397282e",
            "filename": "third_party/xla/xla/backends/cpu/xnn_support.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_support.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_support.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_support.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -81,6 +81,11 @@ absl::StatusOr<bool> IsDotSupportedByXnn(\n   if (!AreDtypesSupported(lhs_shape, rhs_shape, out_shape, cpu_features)) {\n     return false;\n   }\n+  if (!IsLayoutSupportedByXnn(lhs_shape) ||\n+      !IsLayoutSupportedByXnn(rhs_shape) ||\n+      !IsLayoutSupportedByXnn(out_shape)) {\n+    return false;\n+  }\n \n   // Check shapes.\n   TF_ASSIGN_OR_RETURN(DotShape dot_shape, GetDotShape(dot_dimensions, lhs_shape,"
        },
        {
            "sha": "ba3197e1c1f08b6ba0f04be14ef81291715dcdab",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/BUILD",
            "status": "modified",
            "additions": 55,
            "deletions": 7,
            "changes": 62,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -127,6 +127,7 @@ cc_library(\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor:stream_executor_memory_allocator\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n+        \"//xla/stream_executor/gpu:gpu_blas_lt\",\n         \"//xla/stream_executor/gpu:redzone_allocator\",\n         \"//xla/tools:hlo_decomposer_lib\",\n         \"//xla/tsl/lib/gtl:iterator_range\",\n@@ -187,6 +188,7 @@ cc_library(\n     deps = [\n         \":gpu_codegen_backend\",\n         \"//xla:autotuning_proto_cc\",\n+        \"//xla:shape_util\",\n         \"//xla:util\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:codegen_backend\",\n@@ -195,11 +197,9 @@ cc_library(\n         \"//xla/service/gpu:backend_configs_cc\",\n         \"//xla/service/gpu:cublas_cudnn\",\n         \"//xla/service/gpu:matmul_utils\",\n-        \"//xla/service/gpu/autotuning:redzone_buffers\",\n         \"//xla/stream_executor:blas\",\n         \"//xla/stream_executor:device_description\",\n-        \"//xla/stream_executor:device_memory\",\n-        \"//xla/stream_executor:device_memory_allocator\",\n+        \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor:stream_executor_memory_allocator\",\n         \"//xla/stream_executor/gpu:gpu_blas_lt\",\n@@ -451,17 +451,14 @@ xla_test(\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:filecheck\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n-        \"//xla/service:compiler\",\n-        \"//xla/service:hlo_module_util\",\n         \"//xla/service:platform_util\",\n-        \"//xla/service/gpu:gpu_device_info_for_tests\",\n         \"//xla/service/gpu:nvptx_compiler_impl\",\n         \"//xla/stream_executor:device_description_proto_cc\",\n-        \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest_main\",\n@@ -561,6 +558,7 @@ cc_library(\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor:stream_executor_memory_allocator\",\n         \"//xla/stream_executor/gpu:redzone_allocator\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n@@ -575,6 +573,56 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"native_emitter\",\n+    srcs = [\"native_emitter.cc\"],\n+    hdrs = [\"native_emitter.h\"],\n+    deps = [\n+        \":gpu_codegen_backend\",\n+        \"//xla:autotuning_proto_cc\",\n+        \"//xla:xla_proto_cc\",\n+        \"//xla/backends/autotuner:codegen_backend\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:compiler\",\n+        \"//xla/service/gpu:backend_configs_cc\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/base:nullability\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+    ],\n+)\n+\n+xla_test(\n+    name = \"native_emitter_test\",\n+    srcs = [\"native_emitter_test.cc\"],\n+    backends = [\n+        \"a100\",\n+        \"h100\",\n+        \"b200\",\n+    ],\n+    tags = [\n+        \"cuda-only\",\n+        \"no_mac\",\n+    ],\n+    deps = [\n+        \":native_emitter\",\n+        \"//xla/backends/autotuner:codegen_backend\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/service:platform_util\",\n+        \"//xla/service/gpu:backend_configs_cc\",\n+        \"//xla/service/gpu:nvptx_compiler\",\n+        \"//xla/service/gpu:nvptx_compiler_impl\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n cc_library(\n     name = \"factory_cuda\",\n     srcs = [\"factory_cuda.cc\"],"
        },
        {
            "sha": "0f2ee8b773cea1302f23e0b4f5a098ceff3a9981",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/autotuner_main.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fautotuner_main.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fautotuner_main.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fautotuner_main.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -107,7 +107,7 @@ absl::Status Autotune(HloModule& module, const std::string& autotune_cache_dir,\n       std::make_unique<stream_executor::StreamExecutorMemoryAllocator>(\n           stream_executor);\n   auto profiler =\n-      GpuProfiler::Create(stream_executor, allocator.get(), ProfileOptions());\n+      GpuProfiler::Create(stream_executor, ProfileOptions(), allocator.get());\n   if (profiler == nullptr) {\n     return absl::InternalError(\"Failed to create profiler\");\n   }"
        },
        {
            "sha": "63d032944562f4a8301980165cabc741a3468a72",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/block_level_emitter.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -242,6 +242,17 @@ void ExtendConfigsWithTma(\n \n absl::StatusOr<std::vector<std::unique_ptr<BackendConfig>>>\n BlockLevelEmitterBackend::GetSupportedConfigs(const HloInstruction& instr) {\n+  // When use_default_config_ is true, we only return a single config for the\n+  // autotuner to use. It is expected that the default config exists already\n+  // in the HLO fusion and therefore fails if a default config cannot be\n+  // constructed.\n+  if (use_default_config_) {\n+    TF_ASSIGN_OR_RETURN(auto config, GetDefaultConfig(instr));\n+    std::vector<std::unique_ptr<BackendConfig>> configs;\n+    configs.push_back(std::move(config));\n+    return configs;\n+  }\n+\n   if (!IsSupported(instr)) {\n     return std::vector<std::unique_ptr<BackendConfig>>();\n   }"
        },
        {
            "sha": "ed40e420e976039e2bf2c159f1dfb89cee8d79a0",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/block_level_emitter.h",
            "status": "modified",
            "additions": 11,
            "deletions": 2,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -42,9 +42,10 @@ class BlockLevelEmitterBackend : public GpuCodegenBackend {\n   explicit BlockLevelEmitterBackend(\n       stream_executor::StreamExecutor* absl_nonnull stream_executor,\n       const DebugOptions* absl_nonnull debug_options,\n-      Compiler* absl_nonnull compiler)\n+      Compiler* absl_nonnull compiler, bool use_default_config = false)\n       : GpuCodegenBackend(\"BlockLevelEmitter\", stream_executor, debug_options,\n-                          compiler) {}\n+                          compiler),\n+        use_default_config_(use_default_config) {}\n \n   // Returns all supported block-level tiling configurations for the given\n   // instruction.\n@@ -61,6 +62,14 @@ class BlockLevelEmitterBackend : public GpuCodegenBackend {\n \n   // Determines whether the given HLO instruction is supported by this backend.\n   bool IsSupported(const HloInstruction& instr);\n+\n+ private:\n+  // If true, the backend will return a single default configuration in\n+  // GetSupportedConfigs instead of generating all supported configurations.\n+  // This is useful to autotune between different backends without increasing\n+  // compile time by too much. It will use the default config, likely already\n+  // assigned by the cost model.\n+  bool use_default_config_;\n };\n \n }  // namespace gpu"
        },
        {
            "sha": "4dbf510fbc9438964a4d85c5a452988ffa26b6e1",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/block_level_emitter_test.cc",
            "status": "modified",
            "additions": 52,
            "deletions": 0,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -531,5 +531,57 @@ ENTRY %main {\n   EXPECT_THAT(executable, absl_testing::IsOk());\n }\n \n+TEST_F(TritonBlockLevelFusionEmitterBackendTest, UseDefaultConfigFlag) {\n+  auto backend = BlockLevelEmitterBackend(\n+      PlatformUtil::GetDefaultPlatform().value()->ExecutorForDevice(0).value(),\n+      &debug_options_, &compiler_, /*use_default_config=*/true);\n+  // Parse an HLO module containing a kCustom Triton fusion with a backend\n+  // config that includes block-level tiling parameters.\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+HloModule m\n+%wrapped_transpose_computation {\n+  %param_0 = f32[16,64]{1,0} parameter(0)\n+  ROOT %transpose.3.1 = f32[64,16]{1,0} transpose(%param_0), dimensions={1,0}\n+}\n+\n+ENTRY %main {\n+  %p0 = f32[16,64]{1,0} parameter(0), metadata={op_name=\"a\"}\n+  ROOT %wrapped_transpose = f32[64,16]{1,0} fusion(%p0), kind=kCustom,\n+  calls=%wrapped_transpose_computation,\n+  metadata={op_name=\"a\"},\n+  backend_config={\n+  \"fusion_backend_config\": {\n+    \"kind\": \"__triton\",\n+    \"block_level_fusion_config\": {\n+      \"output_tiles\": [\n+        {\"sizes\": [\"4\",\"16\"]}\n+      ],\n+      \"num_warps\": \"2\",\n+      \"num_ctas\": 1,\n+      \"num_stages\": 1\n+    }\n+  }}\n+}\n+)\"));\n+  // Call GetSupportedConfigs on the root instruction (the fusion op).`\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::vector<std::unique_ptr<BackendConfig>> configs,\n+      backend.GetSupportedConfigs(\n+          *(module->entry_computation()->root_instruction())));\n+  // With the use_default_config flag set to true, we expect a single config\n+  // to be returned.\n+  ASSERT_EQ(configs.size(), 1);\n+  // We expect this config to be equal to the one in the HLO instruction.\n+  BlockLevelFusionConfig block_level_fusion_config;\n+  ASSERT_TRUE(configs[0]->UnpackTo(&block_level_fusion_config));\n+  EXPECT_THAT(block_level_fusion_config, EqualsProto(R\"pb(\n+                output_tiles { sizes: 4 sizes: 16 }\n+                num_warps: 2\n+                num_ctas: 1\n+                num_stages: 1\n+              )pb\"));\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "c51ceb43bfff4fbf9b28fcd29736a0d88fc94a3b",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cublas.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 17,
            "changes": 49,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -27,8 +27,6 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/utils/hlo_query.h\"\n-#include \"xla/service/compiler.h\"\n-#include \"xla/service/gpu/autotuning/redzone_buffers.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/cublas_cudnn.h\"\n #include \"xla/service/gpu/matmul_utils.h\"\n@@ -40,7 +38,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n-#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/stream_executor/gpu/gpu_blas_lt.h\"\n #include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -74,27 +72,44 @@ CublasBackend::GetSupportedConfigs(const HloInstruction& instr) {\n           &instr, backend_config,\n           target_config().device_description.gpu_compute_capability()));\n \n-  TF_ASSIGN_OR_RETURN(RedzoneBuffers rz_buffers,\n-                      RedzoneBuffers::FromInstruction(\n-                          instr, allocator.get(), stream,\n-                          RedzoneBuffers::kAllInputsAllOutputs, true, true,\n-                          instr.GetModule()\n-                              ->config()\n-                              .debug_options()\n-                              .xla_gpu_redzone_padding_bytes()));\n-\n+  auto create_matrix_desc = [](const se::gpu::MatrixLayout& layout)\n+      -> absl::StatusOr<se::gpu::MatrixDescriptor> {\n+    TF_ASSIGN_OR_RETURN(se::blas::DataType type,\n+                        se::gpu::AsBlasDataType(layout.dtype));\n+    return se::gpu::MatrixDescriptor{\n+        /*data=*/se::DeviceMemoryBase(), layout.leading_dim_stride,\n+        layout.batch_stride, type,\n+        // BLAS is column-major by default.\n+        (layout.order == se::gpu::MatrixLayout::Order::kColumnMajor\n+             ? se::blas::Transpose::kNoTranspose\n+             : se::blas::Transpose::kTranspose)};\n+  };\n+\n+  TF_ASSIGN_OR_RETURN(se::gpu::MatrixDescriptor lhs_desc,\n+                      create_matrix_desc(gemm_config.lhs_layout));\n+  TF_ASSIGN_OR_RETURN(se::gpu::MatrixDescriptor rhs_desc,\n+                      create_matrix_desc(gemm_config.rhs_layout));\n+  TF_ASSIGN_OR_RETURN(se::gpu::MatrixDescriptor output_desc_base,\n+                      create_matrix_desc(gemm_config.output_layout));\n+\n+  se::gpu::OutputMatrixDescriptor out_desc(std::move(output_desc_base));\n+  out_desc.batch_size = gemm_config.output_layout.batch_size;\n+  out_desc.m = gemm_config.output_layout.num_rows;\n+  out_desc.n = gemm_config.output_layout.num_cols;\n+  out_desc.k = gemm_config.lhs_layout.num_cols;\n   TF_ASSIGN_OR_RETURN(\n-      GemmConfig::DescriptorsTuple desc,\n-      gemm_config.GetMatrixDescriptors(rz_buffers.input_buffers().at(0),\n-                                       rz_buffers.input_buffers().at(1),\n-                                       rz_buffers.output_buffers().at(0)));\n+      out_desc.compute_type,\n+      se::gpu::GetBlasComputationType(\n+          gemm_config.precision_algorithm, gemm_config.lhs_layout.dtype,\n+          gemm_config.output_layout.dtype, gemm_config.compute_precision));\n \n   se::blas::BlasSupport* blas = stream_executor()->AsBlas();\n   if (blas == nullptr) {\n     return absl::InternalError(\"Failed to getBlas support.\");\n   }\n   std::vector<se::blas::AlgorithmType> algorithms;\n-  blas->GetBlasGemmAlgorithms(stream, desc.lhs, desc.rhs, &desc.output,\n+\n+  blas->GetBlasGemmAlgorithms(stream, lhs_desc, rhs_desc, &out_desc,\n                               &gemm_config.alpha, &gemm_config.beta,\n                               &algorithms);\n "
        },
        {
            "sha": "ef03149115ccbfa838c8c766435c4cd710f15242",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cublaslt.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 26,
            "changes": 47,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublaslt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublaslt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublaslt.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include \"xla/backends/gpu/autotuner/cublaslt.h\"\n \n+#include <cstdint>\n #include <memory>\n #include <utility>\n #include <vector>\n@@ -26,17 +27,15 @@ limitations under the License.\n #include \"xla/backends/autotuner/codegen_backend.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/service/compiler.h\"\n-#include \"xla/service/gpu/autotuning/redzone_buffers.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/cublas_cudnn.h\"\n #include \"xla/service/gpu/matmul_utils.h\"\n+#include \"xla/shape.h\"\n+#include \"xla/shape_util.h\"\n #include \"xla/stream_executor/blas.h\"\n #include \"xla/stream_executor/device_description.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/gpu/gpu_blas_lt.h\"\n-#include \"xla/stream_executor/stream_executor.h\"\n-#include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n+#include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n@@ -99,30 +98,26 @@ CublasLtBackend::GetSupportedConfigs(const HloInstruction& instr) {\n   TF_ASSIGN_OR_RETURN(BlasLt::Epilogue epilogue,\n                       AsBlasLtEpilogue(backend_config.epilogue()));\n \n-  auto allocator =\n-      std::make_unique<se::StreamExecutorMemoryAllocator>(stream_executor());\n-  TF_ASSIGN_OR_RETURN(\n-      se::Stream * stream,\n-      allocator->GetStream(stream_executor()->device_ordinal()));\n+  TF_ASSIGN_OR_RETURN(std::unique_ptr<se::Stream> stream,\n+                      stream_executor()->CreateStream());\n \n   TF_ASSIGN_OR_RETURN(\n       std::unique_ptr<BlasLt::MatmulPlan> plan,\n-      se::gpu::BlasLt::GetMatmulPlan(stream, gemm_config, epilogue));\n-\n-  TF_ASSIGN_OR_RETURN(RedzoneBuffers rz_buffers,\n-                      RedzoneBuffers::FromInstruction(\n-                          instr, allocator.get(), stream,\n-                          RedzoneBuffers::kAllInputsAllOutputs, true, true,\n-                          instr.GetModule()\n-                              ->config()\n-                              .debug_options()\n-                              .xla_gpu_redzone_padding_bytes()));\n-  se::DeviceMemoryBase workspace_buffer =\n-      rz_buffers.output_buffers().at(instr.shape().tuple_shapes().size() - 1);\n-\n-  TF_ASSIGN_OR_RETURN(std::vector<BlasLt::MatmulAlgorithm> algorithms,\n-                      plan->GetAlgorithms(stream, GemmConfig::kNumAlgorithms,\n-                                          workspace_buffer.size()));\n+      se::gpu::BlasLt::GetMatmulPlan(stream.get(), gemm_config, epilogue));\n+\n+  const Shape& output_shape = instr.shape();\n+  if (!output_shape.IsTuple() || output_shape.tuple_shapes().empty()) {\n+    return Internal(\n+        \"Invalid shape for CublasLt matmul: output is not a non-empty tuple.\");\n+  }\n+  // The last element of the output tuple is the workspace.\n+  const int64_t workspace_size =\n+      ShapeUtil::ByteSizeOf(output_shape.tuple_shapes().back());\n+\n+  TF_ASSIGN_OR_RETURN(\n+      std::vector<BlasLt::MatmulAlgorithm> algorithms,\n+      plan->GetAlgorithms(stream.get(), GemmConfig::kNumAlgorithms,\n+                          workspace_size));\n   int num_algorithms = algorithms.size();\n   std::vector<std::unique_ptr<BackendConfig>> configs;\n   configs.reserve(num_algorithms);"
        },
        {
            "sha": "a0e4e1d54ba83861d21fc9d6faa8cbd0113ca3ee",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/fission.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -241,6 +241,7 @@ FissionBackend::GetSupportedConfigs(const HloInstruction& instr) {\n         std::vector<std::unique_ptr<BackendConfig>> cublas_configs,\n         GetCublasConfigs(cublas_backend_, std::move(cublas_hlo_module),\n                          stream_executor()));\n+    VLOG(2) << \"Found \" << cublas_configs.size() << \" cublas configs.\";\n     configs.insert(configs.end(),\n                    std::make_move_iterator(cublas_configs.begin()),\n                    std::make_move_iterator(cublas_configs.end()));\n@@ -255,6 +256,7 @@ FissionBackend::GetSupportedConfigs(const HloInstruction& instr) {\n         std::vector<std::unique_ptr<BackendConfig>> cublaslt_configs,\n         GetCublasLtConfigs(cublaslt_backend_, std::move(cublaslt_hlo_module),\n                            stream_executor()));\n+    VLOG(2) << \"Found \" << cublaslt_configs.size() << \" cublasLt configs.\";\n     configs.insert(configs.end(),\n                    std::make_move_iterator(cublaslt_configs.begin()),\n                    std::make_move_iterator(cublaslt_configs.end()));\n@@ -269,6 +271,8 @@ FissionBackend::GetSupportedConfigs(const HloInstruction& instr) {\n         GetCustomKernelConfigs(custom_kernel_backend_,\n                                std::move(custom_kernel_hlo_module),\n                                stream_executor()));\n+    VLOG(2) << \"Found \" << custom_kernel_configs.size()\n+            << \" custom kernel configs. \";\n     configs.insert(configs.end(),\n                    std::make_move_iterator(custom_kernel_configs.begin()),\n                    std::make_move_iterator(custom_kernel_configs.end()));"
        },
        {
            "sha": "6590facbd624dd465d5d7d2c35405cd0991075d6",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/fission_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 7,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/autotuning.pb.h\"\n@@ -32,7 +33,6 @@ limitations under the License.\n #include \"xla/service/gpu/nvptx_compiler.h\"\n #include \"xla/service/platform_util.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n-#include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -116,8 +116,7 @@ TEST_F(FissionBackendTest, GetSupportedConfigsForUnsupportedInstructionFails) {\n   absl::StatusOr<std::vector<std::unique_ptr<BackendConfig>>> configs =\n       backend_.GetSupportedConfigs(\n           (*module->entry_computation()->root_instruction()));\n-  EXPECT_THAT(configs.status(),\n-              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+  EXPECT_THAT(configs.status(), StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n TEST_F(FissionBackendTest, GetDefaultConfigFails) {\n@@ -127,8 +126,7 @@ TEST_F(FissionBackendTest, GetDefaultConfigFails) {\n   absl::StatusOr<std::unique_ptr<BackendConfig>> config =\n       backend_.GetDefaultConfig(\n           (*module->entry_computation()->root_instruction()));\n-  EXPECT_THAT(config.status(),\n-              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+  EXPECT_THAT(config.status(), StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n TEST_F(FissionBackendTest, ApplyCublasConfigToFusionInstruction) {\n@@ -142,7 +140,7 @@ TEST_F(FissionBackendTest, ApplyCublasConfigToFusionInstruction) {\n       *hlo_module->entry_computation()->root_instruction(), any));\n   EXPECT_THAT(RunFileCheck(hlo_module->ToString(),\n                            \"CHECK: \\\"selected_algorithm\\\":\\\"3\\\"\"),\n-              absl_testing::IsOkAndHolds(true));\n+              IsOkAndHolds(true));\n }\n \n TEST_F(FissionBackendTest, ApplyCustomKernelConfigToFusionInstruction) {\n@@ -155,7 +153,7 @@ TEST_F(FissionBackendTest, ApplyCustomKernelConfigToFusionInstruction) {\n   TF_EXPECT_OK(backend_.ApplyConfig(\n       *hlo_module->entry_computation()->root_instruction(), any));\n   EXPECT_THAT(RunFileCheck(hlo_module->ToString(), \"CHECK: \\\"kernel_index\\\":3\"),\n-              absl_testing::IsOkAndHolds(true));\n+              IsOkAndHolds(true));\n }\n \n }  // namespace"
        },
        {
            "sha": "9242580db8ca4e8256f74c7703bea0074c60a641",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 5,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -41,6 +41,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/gpu/redzone_allocator.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"tsl/platform/casts.h\"\n@@ -88,14 +89,24 @@ int GetScratchBytes(const Executable* executable) {\n }  // namespace\n \n std::unique_ptr<GpuProfiler> GpuProfiler::Create(\n-    se::StreamExecutor* stream_executor, se::DeviceMemoryAllocator* allocator,\n-    ProfileOptions options) {\n+    se::StreamExecutor* stream_executor, ProfileOptions options,\n+    se::DeviceMemoryAllocator* external_allocator) {\n+  std::unique_ptr<se::DeviceMemoryAllocator> owned_allocator;\n+  se::DeviceMemoryAllocator* active_allocator = external_allocator;\n+\n+  if (active_allocator == nullptr) {\n+    owned_allocator =\n+        std::make_unique<se::StreamExecutorMemoryAllocator>(stream_executor);\n+    active_allocator = owned_allocator.get();\n+  }\n+\n   auto stream = stream_executor->CreateStream();\n   if (!stream.ok()) {\n     LOG(ERROR) << \"Failed to create stream: \" << stream.status();\n     return nullptr;\n   }\n-  return absl::WrapUnique(new GpuProfiler(stream_executor, allocator,\n+  return absl::WrapUnique(new GpuProfiler(stream_executor, active_allocator,\n+                                          std::move(owned_allocator),\n                                           std::move(stream.value()), options));\n }\n \n@@ -148,9 +159,14 @@ absl::StatusOr<ProfileResult> GpuProfiler::Profile(\n       Execute(executable, std::move(execution_inputs), &profile));\n \n   result.duration = absl::Nanoseconds(profile.compute_time_ns());\n-  if (options_.should_populate_output_buffer) {\n-    result.output_buffer = execution_output.Commit().ConsumeResult();\n+  ScopedShapedBuffer output_buffers = execution_output.Commit().ConsumeResult();\n+  if (output_buffers.on_device_shape().IsTuple() &&\n+      !output_buffers.on_device_shape().tuple_shapes().empty()) {\n+    result.output_buffer = output_buffers.TakeSubTree({0});\n+  } else {\n+    result.output_buffer = std::move(output_buffers);\n   }\n+\n   return result;\n }\n "
        },
        {
            "sha": "42f42dd17ca029027b4bbc2bd7e0a6fbb673693e",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler.h",
            "status": "modified",
            "additions": 8,
            "deletions": 6,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -41,8 +41,8 @@ struct GpuInputBuffers : public InputBuffers {\n class GpuProfiler : public Profiler {\n  public:\n   static std::unique_ptr<GpuProfiler> Create(\n-      stream_executor::StreamExecutor* stream_executor,\n-      se::DeviceMemoryAllocator* allocator, ProfileOptions options);\n+      stream_executor::StreamExecutor* stream_executor, ProfileOptions options,\n+      se::DeviceMemoryAllocator* external_allocator = nullptr);\n \n   // The input buffers shapes are taken from the attatched HloModule to the\n   // executable.\n@@ -60,12 +60,13 @@ class GpuProfiler : public Profiler {\n                                  float rtol) override;\n \n  private:\n-  explicit GpuProfiler(se::StreamExecutor* stream_executor,\n-                       se::DeviceMemoryAllocator* allocator,\n-                       std::unique_ptr<se::Stream> stream,\n-                       ProfileOptions options)\n+  explicit GpuProfiler(\n+      se::StreamExecutor* stream_executor, se::DeviceMemoryAllocator* allocator,\n+      std::unique_ptr<se::DeviceMemoryAllocator> owned_allocator,\n+      std::unique_ptr<se::Stream> stream, ProfileOptions options)\n       : stream_executor_(stream_executor),\n         allocator_(allocator),\n+        owned_allocator_(std::move(owned_allocator)),\n         stream_(std::move(stream)),\n         options_(options) {}\n \n@@ -75,6 +76,7 @@ class GpuProfiler : public Profiler {\n \n   se::StreamExecutor* stream_executor_;\n   se::DeviceMemoryAllocator* allocator_;\n+  std::unique_ptr<se::DeviceMemoryAllocator> owned_allocator_;\n   std::unique_ptr<se::Stream> stream_;\n   ProfileOptions options_;\n };"
        },
        {
            "sha": "9f7e5a340cf109f230e6d915f173578ac8874361",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler_test.cc",
            "status": "modified",
            "additions": 34,
            "deletions": 79,
            "changes": 113,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -17,7 +17,6 @@ limitations under the License.\n \n #include <cstdint>\n #include <memory>\n-#include <optional>\n #include <utility>\n #include <vector>\n \n@@ -57,12 +56,7 @@ namespace gpu {\n \n namespace {\n \n-using absl_testing::IsOkAndHolds;\n using absl_testing::StatusIs;\n-using ::testing::ElementsAre;\n-using ::testing::Eq;\n-using ::testing::Field;\n-using ::testing::Ne;\n \n class MockExecutable : public Executable {\n  public:\n@@ -81,8 +75,9 @@ class MockExecutable : public Executable {\n     if (profile != nullptr) {\n       profile->set_compute_time_ns(duration_ns_);\n     }\n-    return ExecutionOutput(ShapeUtil::MakeTupleShape({}),\n-                           ShapeUtil::MakeTupleShape({}),\n+    const Shape& result_shape =\n+        module().entry_computation()->root_instruction()->shape();\n+    return ExecutionOutput(result_shape, result_shape,\n                            run_options->run_options().allocator(),\n                            run_options->run_options().device_ordinal());\n   }\n@@ -122,40 +117,7 @@ class GpuProfilerTest : public HloHardwareIndependentTestBase {\n   std::unique_ptr<se::DeviceMemoryAllocator> allocator_;\n };\n \n-TEST_F(GpuProfilerTest, ProfileWithSharedBuffersWithoutOutputBuffer) {\n-  constexpr absl::string_view kHloModule = R\"(\n-    HloModule module\n-    ENTRY main {\n-      ROOT c = s32[] constant(1)\n-    }\n-  )\";\n-  TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<HloModule> module,\n-                          ParseAndReturnVerifiedModule(kHloModule));\n-  std::vector<std::unique_ptr<Executable>> executables;\n-  executables.push_back(std::make_unique<MockExecutable>(module, 1000));\n-  executables.push_back(std::make_unique<MockExecutable>(module, 2000));\n-\n-  ProfileOptions options;\n-  options.should_populate_output_buffer = false;\n-  auto profiler = GpuProfiler::Create(stream_exec_, allocator_.get(), options);\n-  TF_ASSERT_OK_AND_ASSIGN(auto profiles, profiler->ProfileWithSharedBuffers(\n-                                             std::move(executables)));\n-  EXPECT_EQ(profiles.size(), 2);\n-  TF_ASSERT_OK(profiles[0].status());\n-  TF_ASSERT_OK(profiles[1].status());\n-  EXPECT_THAT(profiles,\n-              ElementsAre(IsOkAndHolds(Field(&ProfileResult::duration,\n-                                             absl::Nanoseconds(1000))),\n-                          IsOkAndHolds(Field(&ProfileResult::duration,\n-                                             absl::Nanoseconds(2000)))));\n-  EXPECT_THAT(profiles,\n-              ElementsAre(IsOkAndHolds(Field(&ProfileResult::output_buffer,\n-                                             Eq(std::nullopt))),\n-                          IsOkAndHolds(Field(&ProfileResult::output_buffer,\n-                                             Eq(std::nullopt)))));\n-}\n-\n-TEST_F(GpuProfilerTest, ProfileWithSharedBuffers) {\n+TEST_F(GpuProfilerTest, CreateInputBuffersAndProfile) {\n   constexpr absl::string_view kHloModule = R\"(\n     HloModule module\n     ENTRY main {\n@@ -164,47 +126,40 @@ TEST_F(GpuProfilerTest, ProfileWithSharedBuffers) {\n   )\";\n   TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(kHloModule));\n-  std::vector<std::unique_ptr<Executable>> executables;\n-  executables.push_back(std::make_unique<MockExecutable>(module, 1));\n-\n+  MockExecutable mock_executable(module, 1000);\n   auto profiler =\n-      GpuProfiler::Create(stream_exec_, allocator_.get(), ProfileOptions());\n-  TF_ASSERT_OK_AND_ASSIGN(auto profiles, profiler->ProfileWithSharedBuffers(\n-                                             std::move(executables)));\n-  EXPECT_THAT(profiles, ElementsAre(IsOkAndHolds(Field(\n-                            &ProfileResult::output_buffer, Ne(std::nullopt)))));\n+      GpuProfiler::Create(stream_exec_, ProfileOptions(), allocator_.get());\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<InputBuffers> buffers,\n+                          profiler->CreateInputBuffers(&mock_executable));\n+  TF_ASSERT_OK_AND_ASSIGN(ProfileResult profile,\n+                          profiler->Profile(&mock_executable, *buffers));\n+  EXPECT_EQ(profile.duration, absl::Nanoseconds(1000));\n+  EXPECT_EQ(profile.output_buffer->on_device_shape(),\n+            ShapeUtil::MakeShape(S32, {}));\n+  EXPECT_EQ(profile.scratch_bytes, 0);\n }\n \n-TEST_F(GpuProfilerTest, FailingExecutablesReturnStatus) {\n+TEST_F(GpuProfilerTest, ProfileWithTupleOutput) {\n   constexpr absl::string_view kHloModule = R\"(\n     HloModule module\n     ENTRY main {\n-      ROOT c = s32[] constant(1)\n+      ROOT c = (s32[], s32[]) tuple(s32[] constant(1), s32[] constant(2))\n     }\n   )\";\n   TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(kHloModule));\n-  std::vector<std::unique_ptr<Executable>> executables;\n-  executables.push_back(std::make_unique<MockExecutable>(module, 1000));\n-  executables.push_back(\n-      std::make_unique<MockExecutable>(module, 2000, /*should_fail=*/true));\n-  executables.push_back(std::make_unique<MockExecutable>(module, 3000));\n-\n+  MockExecutable mock_executable(module, 1000);\n   auto profiler =\n-      GpuProfiler::Create(stream_exec_, allocator_.get(), ProfileOptions());\n-  TF_ASSERT_OK_AND_ASSIGN(auto profiles, profiler->ProfileWithSharedBuffers(\n-                                             std::move(executables)));\n-  EXPECT_EQ(profiles.size(), 3);\n-  TF_ASSERT_OK(profiles[0].status());\n-  EXPECT_FALSE(profiles[1].ok());\n-  TF_ASSERT_OK(profiles[2].status());\n-  EXPECT_THAT(profiles[0], IsOkAndHolds(Field(&ProfileResult::duration,\n-                                              absl::Nanoseconds(1000))));\n-  EXPECT_THAT(profiles[2], IsOkAndHolds(Field(&ProfileResult::duration,\n-                                              absl::Nanoseconds(3000))));\n+      GpuProfiler::Create(stream_exec_, ProfileOptions(), allocator_.get());\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<InputBuffers> buffers,\n+                          profiler->CreateInputBuffers(&mock_executable));\n+  TF_ASSERT_OK_AND_ASSIGN(ProfileResult profile,\n+                          profiler->Profile(&mock_executable, *buffers));\n+  EXPECT_EQ(profile.output_buffer->on_device_shape(),\n+            ShapeUtil::MakeShape(S32, {}));\n }\n \n-TEST_F(GpuProfilerTest, CreateInputBuffersAndProfile) {\n+TEST_F(GpuProfilerTest, FailingExecutablesReturnStatus) {\n   constexpr absl::string_view kHloModule = R\"(\n     HloModule module\n     ENTRY main {\n@@ -213,15 +168,15 @@ TEST_F(GpuProfilerTest, CreateInputBuffersAndProfile) {\n   )\";\n   TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(kHloModule));\n-  MockExecutable mock_executable(module, 1000);\n+  MockExecutable mock_executable(module, /*duration_ns=*/0,\n+                                 /*should_fail=*/true);\n \n   auto profiler =\n-      GpuProfiler::Create(stream_exec_, allocator_.get(), ProfileOptions());\n+      GpuProfiler::Create(stream_exec_, ProfileOptions(), allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<InputBuffers> buffers,\n                           profiler->CreateInputBuffers(&mock_executable));\n-  TF_ASSERT_OK_AND_ASSIGN(ProfileResult profile,\n-                          profiler->Profile(&mock_executable, *buffers));\n-  EXPECT_EQ(profile.duration, absl::Nanoseconds(1000));\n+  EXPECT_THAT(profiler->Profile(&mock_executable, *buffers),\n+              StatusIs(absl::StatusCode::kInternal));\n }\n \n class GpuProfilerTestWithRedzonePadding\n@@ -240,7 +195,7 @@ TEST_P(GpuProfilerTestWithRedzonePadding, CheckInputBuffers) {\n   MockExecutable mock_executable(module, 1000);\n   ProfileOptions options;\n   options.redzone_padding_bytes = GetParam();\n-  auto profiler = GpuProfiler::Create(stream_exec_, allocator_.get(), options);\n+  auto profiler = GpuProfiler::Create(stream_exec_, options, allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<InputBuffers> buffers,\n                           profiler->CreateInputBuffers(&mock_executable));\n   TF_EXPECT_OK(profiler->CheckInputBuffers(*buffers));\n@@ -252,7 +207,7 @@ INSTANTIATE_TEST_SUITE_P(GpuProfilerTestWithRedzonePadding,\n \n TEST_F(GpuProfilerTest, CheckOutputBufferWhenBuffersAreSame) {\n   ProfileOptions options;\n-  auto profiler = GpuProfiler::Create(stream_exec_, allocator_.get(), options);\n+  auto profiler = GpuProfiler::Create(stream_exec_, options, allocator_.get());\n \n   TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_exec_->CreateStream());\n   auto allocator =\n@@ -270,7 +225,7 @@ TEST_F(GpuProfilerTest, CheckOutputBufferWhenBuffersAreSame) {\n \n TEST_F(GpuProfilerTest, CheckOutputBufferWhenBuffersAreDifferent) {\n   ProfileOptions options;\n-  auto profiler = GpuProfiler::Create(stream_exec_, allocator_.get(), options);\n+  auto profiler = GpuProfiler::Create(stream_exec_, options, allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_exec_->CreateStream());\n   auto allocator =\n       std::make_unique<stream_executor::StreamExecutorMemoryAllocator>(\n@@ -311,7 +266,7 @@ ENTRY %entry_computation (transpose.562: bf16[32,120,6,512], Arg_1.2: f32[3072,5\n                           compiler.RunBackend(std::move(module), stream_exec_,\n                                               GpuCompiler::CompileOptions()));\n   auto profiler =\n-      GpuProfiler::Create(stream_exec_, allocator_.get(), ProfileOptions());\n+      GpuProfiler::Create(stream_exec_, ProfileOptions(), allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<InputBuffers> buffers,\n                           profiler->CreateInputBuffers(gpu_executable.get()));\n   TF_ASSERT_OK_AND_ASSIGN(ProfileResult profile,"
        },
        {
            "sha": "68d4ee6392b8057670e3bc234d397749687de629",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/native_emitter.cc",
            "status": "added",
            "additions": 84,
            "deletions": 0,
            "changes": 84,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,84 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/autotuner/native_emitter.h\"\n+\n+#include <memory>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"xla/autotuning.pb.h\"\n+#include \"xla/backends/autotuner/codegen_backend.h\"\n+#include \"xla/hlo/ir/hlo_casting_utils.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/service/gpu/backend_configs.pb.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/xla.pb.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+bool IsSupported(const HloInstruction& instr) {\n+  return instr.opcode() == HloOpcode::kFusion &&\n+         // TODO: b/440062644 - Support multi-output fusions.\n+         !Cast<HloFusionInstruction>(&instr)->IsMultiOutputFusion();\n+}\n+\n+absl::StatusOr<std::vector<std::unique_ptr<BackendConfig>>>\n+NativeEmitterBackend::GetSupportedConfigs(const HloInstruction& instr) {\n+  std::vector<std::unique_ptr<BackendConfig>> configs;\n+  if (!IsSupported(instr)) {\n+    return configs;\n+  }\n+  auto config = GetDefaultConfig(instr);\n+  if (config.ok()) {\n+    configs.push_back(std::move(config.value()));\n+  }\n+  return configs;\n+}\n+\n+absl::StatusOr<std::unique_ptr<BackendConfig>>\n+NativeEmitterBackend::GetDefaultConfig(const HloInstruction& instr) {\n+  NativeEmitterBackendConfig config;\n+  auto any = std::make_unique<google::protobuf::Any>();\n+  any->PackFrom(config);\n+  return any;\n+}\n+\n+absl::Status NativeEmitterBackend::ApplyConfig(HloInstruction& instr,\n+                                               const BackendConfig& config) {\n+  NativeEmitterBackendConfig native_emitter_fusion_config;\n+  if (!config.UnpackTo(&native_emitter_fusion_config)) {\n+    return absl::InvalidArgumentError(\n+        \"Invalid backend config type for NativeEmitterBackendConfig.\");\n+  }\n+  auto fusion_instr = Cast<HloFusionInstruction>(&instr);\n+  fusion_instr->set_fusion_kind(HloInstruction::FusionKind::kInput);\n+  TF_ASSIGN_OR_RETURN(GpuBackendConfig gpu_backend_config,\n+                      instr.backend_config<GpuBackendConfig>());\n+  *gpu_backend_config.mutable_native_emitter_backend_config() =\n+      native_emitter_fusion_config;\n+  TF_RETURN_IF_ERROR(fusion_instr->set_backend_config(gpu_backend_config));\n+  return absl::OkStatus();\n+}\n+\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "2431df9196b96a990b6eff83d0fbc0df230183b7",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/native_emitter.h",
            "status": "added",
            "additions": 64,
            "deletions": 0,
            "changes": 64,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,64 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_AUTOTUNER_NATIVE_EMITTER_H_\n+#define XLA_BACKENDS_GPU_AUTOTUNER_NATIVE_EMITTER_H_\n+\n+#include <memory>\n+#include <vector>\n+\n+#include \"absl/base/nullability.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"xla/backends/autotuner/codegen_backend.h\"\n+#include \"xla/backends/gpu/autotuner/gpu_codegen_backend.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/service/compiler.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/xla.pb.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+// Codegen backend for XLA's native fusion emitters.\n+//\n+// This backend enables us to autotune XLA's native emitters against other\n+// backends.\n+class NativeEmitterBackend : public GpuCodegenBackend {\n+ public:\n+  explicit NativeEmitterBackend(\n+      stream_executor::StreamExecutor* absl_nonnull stream_executor,\n+      const DebugOptions* absl_nonnull debug_options,\n+      Compiler* absl_nonnull compiler)\n+      : GpuCodegenBackend(\"NativeEmitter\", stream_executor, debug_options,\n+                          compiler) {}\n+\n+  // Returns all supported configurations for the given instruction.\n+  absl::StatusOr<std::vector<std::unique_ptr<BackendConfig>>>\n+  GetSupportedConfigs(const HloInstruction& instr) override;\n+\n+  // Returns a default configuration for the instruction.\n+  absl::StatusOr<std::unique_ptr<BackendConfig>> GetDefaultConfig(\n+      const HloInstruction& instr) override;\n+\n+  // Applies a given fusion config to the instruction.\n+  absl::Status ApplyConfig(HloInstruction& instr,\n+                           const BackendConfig& config) override;\n+};\n+\n+}  // namespace gpu\n+}  // namespace xla\n+\n+#endif  // XLA_BACKENDS_GPU_AUTOTUNER_NATIVE_EMITTER_H_"
        },
        {
            "sha": "79699e4aaab49f0e574d5a5f9938d752454208a7",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/native_emitter_test.cc",
            "status": "added",
            "additions": 188,
            "deletions": 0,
            "changes": 188,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,188 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/autotuner/native_emitter.h\"\n+\n+#include <memory>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n+#include \"xla/backends/autotuner/codegen_backend.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/service/gpu/backend_configs.pb.h\"\n+#include \"xla/service/gpu/nvptx_compiler.h\"\n+#include \"xla/service/platform_util.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla {\n+namespace gpu {\n+namespace {\n+\n+const char kReductionFusionHlo[] = R\"(\n+HloModule m\n+\n+%func (lhs: f32[], rhs: f32[]) -> f32[] {\n+  %rhs = f32[] parameter(1)\n+  %lhs = f32[] parameter(0)\n+  ROOT %sum = f32[] add(%lhs, %rhs)\n+}\n+\n+%fused_reduce.clone (param_0: f32[32,4096,2048]) -> f32[32,2048] {\n+  %param_0 = f32[32,4096,2048]{2,1,0} parameter(0)\n+  %c0 = f32[] constant(0)\n+  ROOT %reduce = f32[32,2048]{1,0} reduce(%param_0, %c0), dimensions={1},\n+    to_apply=%func\n+}\n+\n+ENTRY %entry_computation (p0: f32[32,4096,2048]) -> f32[32,2048] {\n+  %p0 = f32[32,4096,2048]{2,1,0} parameter(0)\n+  ROOT %reduce_fusion = f32[32,2048]{1,0} fusion(%p0), kind=kCustom,\n+    calls=%fused_reduce.clone,\n+    backend_config={ \"fusion_backend_config\": {\n+      \"kind\":\"__triton\",\n+      \"block_level_fusion_config\":{\n+        \"num_warps\":\"8\",\"output_tiles\":[{\"sizes\":[\"1\",\"4\"]}],\n+        \"num_ctas\":1,\"num_stages\":1,\"is_tma_allowed\":false\n+      }\n+    }}\n+})\";\n+\n+const char kMultiOutputFusionHlo[] = R\"(\n+HloModule m\n+\n+%fused_add_and_sub (p0: f32[32,16], p1: f32[32,16]) -> (f32[32,16], f32[32,16]) {\n+  %p0 = f32[32,16]{1,0} parameter(0)\n+  %p1 = f32[32,16]{1,0} parameter(1)\n+  %add = f32[32,16]{1,0} add(%p0, %p1)\n+  %sub = f32[32,16]{1,0} subtract(%p0, %p1)\n+  ROOT %tuple = (f32[32,16]{1,0}, f32[32,16]{1,0}) tuple(%add, %sub)\n+}\n+\n+ENTRY %entry_computation (p0: f32[32,16], p1: f32[32,16]) -> (f32[32,16], f32[32,16]) {\n+  %p0 = f32[32,16]{1,0} parameter(0)\n+  %p1 = f32[32,16]{1,0} parameter(1)\n+  ROOT %reduce_fusion = (f32[32,16]{1,0}, f32[32,16]{1,0}) fusion(%p0, %p1), kind=kCustom,\n+    calls=%fused_add_and_sub,\n+    backend_config={ \"fusion_backend_config\": {\n+      \"kind\":\"__triton\",\n+      \"block_level_fusion_config\":{\n+        \"num_warps\":\"1\",\"output_tiles\":[{\"sizes\":[\"1\",\"4\"]}],\n+        \"num_ctas\":1,\"num_stages\":1,\"is_tma_allowed\":false\n+      }\n+    }}\n+})\";\n+\n+class NativeEmitterBackendTest : public HloHardwareIndependentTestBase {\n+ protected:\n+  NativeEmitterBackendTest()\n+      : backend_(PlatformUtil::GetDefaultPlatform()\n+                     .value()\n+                     ->ExecutorForDevice(0)\n+                     .value(),\n+                 &debug_options_, &compiler_) {}\n+\n+  DebugOptions debug_options_;\n+  NVPTXCompiler compiler_;\n+  NativeEmitterBackend backend_;\n+};\n+\n+TEST_F(NativeEmitterBackendTest, GetDefaultConfig) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto reduction_module,\n+                          ParseAndReturnVerifiedModule(kReductionFusionHlo));\n+  auto fusion = reduction_module->entry_computation()->root_instruction();\n+  // Call GetDefaultConfig on the fusion instruction.\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<BackendConfig> config,\n+                          backend_.GetDefaultConfig(*(fusion)));\n+  // Verify the returned config is a native emitter config.\n+  NativeEmitterBackendConfig native_emitter_config;\n+  ASSERT_TRUE(config->UnpackTo(&native_emitter_config));\n+}\n+\n+TEST_F(NativeEmitterBackendTest, GetSupportedConfigs) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto reduction_module,\n+                          ParseAndReturnVerifiedModule(kReductionFusionHlo));\n+  auto fusion = reduction_module->entry_computation()->root_instruction();\n+  // Call GetSupportedConfigs on the fusion instruction.\n+  TF_ASSERT_OK_AND_ASSIGN(std::vector<std::unique_ptr<BackendConfig>> configs,\n+                          backend_.GetSupportedConfigs(*(fusion)));\n+  // There should only be a single config for the native emitter backend.\n+  ASSERT_EQ(configs.size(), 1);\n+  // Verify the returned config is a native emitter config.\n+  NativeEmitterBackendConfig native_emitter_config;\n+  ASSERT_TRUE(configs[0]->UnpackTo(&native_emitter_config));\n+}\n+\n+TEST_F(NativeEmitterBackendTest,\n+       GetSupportedConfigsDoesNotSupportMultiOutputFusions) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(kMultiOutputFusionHlo));\n+  auto fusion_instruction = module->entry_computation()->root_instruction();\n+  // Call GetSupportedConfigs on the fusion instruction.\n+  TF_ASSERT_OK_AND_ASSIGN(std::vector<std::unique_ptr<BackendConfig>> configs,\n+                          backend_.GetSupportedConfigs(*(fusion_instruction)));\n+  // GetSupportedConfigs should return an empty vector as it doesn't support\n+  // multi-output fusions.\n+  ASSERT_TRUE(configs.empty());\n+}\n+\n+TEST_F(NativeEmitterBackendTest, ApplyConfig) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto reduction_module,\n+                          ParseAndReturnVerifiedModule(kReductionFusionHlo));\n+  auto fusion = reduction_module->entry_computation()->root_instruction();\n+  // Call ApplyConfig on the fusion instruction.\n+  NativeEmitterBackendConfig native_emitter_config;\n+  BackendConfig config;\n+  config.PackFrom(native_emitter_config);\n+  ASSERT_THAT(backend_.ApplyConfig(*(fusion), config), absl_testing::IsOk());\n+  // Verify the fusion instruction is now a kInput fusion.\n+  ASSERT_EQ(fusion->fusion_kind(), HloInstruction::FusionKind::kInput);\n+  // Verify the fusion instruction has a native emitter backend config.\n+  ASSERT_TRUE(fusion->has_backend_config());\n+  TF_ASSERT_OK_AND_ASSIGN(GpuBackendConfig gpu_backend_config,\n+                          fusion->backend_config<GpuBackendConfig>());\n+  ASSERT_TRUE(gpu_backend_config.has_native_emitter_backend_config());\n+}\n+\n+TEST_F(NativeEmitterBackendTest, ApplyConfigFailsForUnsupportedConfig) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto reduction_module,\n+                          ParseAndReturnVerifiedModule(kReductionFusionHlo));\n+  auto fusion = reduction_module->entry_computation()->root_instruction();\n+  BlockLevelFusionConfig block_level_fusion_config;\n+  BackendConfig config;\n+  config.PackFrom(block_level_fusion_config);\n+  ASSERT_THAT(backend_.ApplyConfig(*(fusion), config),\n+              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+}\n+\n+TEST_F(NativeEmitterBackendTest, CompileForDefaultConfig) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto reduction_module,\n+                          ParseAndReturnVerifiedModule(kReductionFusionHlo));\n+  auto fusion = reduction_module->entry_computation()->root_instruction();\n+  // Call GetDefaultConfig on the fusion instruction.\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<BackendConfig> config,\n+                          backend_.GetDefaultConfig(*(fusion)));\n+  // Attempt to compile the fusion using the retrieved backend config.\n+  auto maybe_executable = backend_.Compile(*fusion, *config);\n+  // Verify that compilation succeeded and returned a valid executable.\n+  EXPECT_THAT(maybe_executable, absl_testing::IsOk());\n+}\n+\n+}  // namespace\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "a1b83f18289d4b6ba62082d9474778686dea99c9",
            "filename": "third_party/xla/xla/backends/gpu/codegen/custom.cc",
            "status": "modified",
            "additions": 93,
            "deletions": 76,
            "changes": 169,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcustom.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcustom.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcustom.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -209,17 +209,9 @@ std::optional<HloInstruction*> GetParentWhileOp(const HloInstruction& op,\n // hard checks for the conditions on this here, because these conditions are\n // ensured before fusing in\n // `dynamic_slice_fusion_rewriter.cc:IsValueFunctionOfLoopInductionVariable`.\n+// indvar_idx is the tuple index of the induction variable in the while body.\n std::unique_ptr<HloModule> ExtractOffsetModule(\n-    const HloInstruction* offset_value,\n-    std::optional<const HloInstruction*> while_op) {\n-  if (while_op == std::nullopt) return nullptr;\n-\n-  // First we check that we can get the indvar index.\n-  std::optional<int64_t> indvar_idx = GetLoopInductionVarTupleIdx(*while_op);\n-  CHECK(indvar_idx != std::nullopt)\n-      << \"Unable to get tuple idx for offset value: \"\n-      << (*while_op)->ToString();\n-\n+    const HloInstruction* offset_value, int64_t indvar_idx) {\n   // Extract offset as a function of parameter to while body.\n   std::unique_ptr<HloModule> extracted_offset = ExtractModule(\n       /*instruction=*/offset_value, /*height=*/-1,\n@@ -245,11 +237,11 @@ std::unique_ptr<HloModule> ExtractOffsetModule(\n       extracted_offset->entry_computation()->parameter_instruction(0)->users(),\n       [indvar_idx](const HloInstruction* instr) {\n         return instr->opcode() == HloOpcode::kGetTupleElement &&\n-               instr->tuple_index() == *indvar_idx;\n+               instr->tuple_index() == indvar_idx;\n       }))\n       << \"Extracted offset module does not have all operations on the \"\n          \"parameter as get-tuple-element for index \"\n-      << *indvar_idx << \": \" << extracted_offset->ToString();\n+      << indvar_idx << \": \" << extracted_offset->ToString();\n \n   // We simply replace the parameter with the get-tuple-element instruction as\n   // the parameter.\n@@ -265,27 +257,21 @@ std::unique_ptr<HloModule> ExtractOffsetModule(\n // variable. There are hard checks for the conditions on this here, because\n // these conditions are ensured before fusing in\n // `dynamic_slice_fusion_rewriter.cc:IsValueFunctionOfLoopInductionVariable`.\n+// indvar_idx is the tuple index of the induction variable in the while body.\n std::unique_ptr<HloModule> ExtractWhileUpdateModule(\n-    const HloInstruction* while_op) {\n-  std::optional<int64_t> tuple_idx = GetLoopInductionVarTupleIdx(while_op);\n-  if (tuple_idx == std::nullopt) {\n-    return nullptr;\n-  }\n+    const HloInstruction* while_op, int64_t indvar_idx) {\n   const HloInstruction* update =\n-      while_op->while_body()->root_instruction()->operand(*tuple_idx);\n-  return ExtractOffsetModule(update, while_op);\n+      while_op->while_body()->root_instruction()->operand(indvar_idx);\n+  return ExtractOffsetModule(update, indvar_idx);\n }\n \n // Extracts the while induction variable initialization module. This must have\n // no parameters and this condition was ensured before fusing in\n // `dynamic_slice_fusion_rewriter.cc:IsValueFunctionOfLoopInductionVariable`.\n+// indvar_idx is the tuple index of the induction variable in the while body.\n std::unique_ptr<HloModule> ExtractWhileInitModule(\n-    const HloInstruction* while_op) {\n-  std::optional<int64_t> tuple_idx = GetLoopInductionVarTupleIdx(while_op);\n-  if (tuple_idx == std::nullopt) {\n-    return nullptr;\n-  }\n-  const HloInstruction* init = while_op->operand(0)->operand(*tuple_idx);\n+    const HloInstruction* while_op, int64_t indvar_idx) {\n+  const HloInstruction* init = while_op->operand(0)->operand(indvar_idx);\n   std::unique_ptr<HloModule> init_module = ExtractModule(\n       /*instruction=*/init, /*height=*/-1, /*extract_selector=*/nullptr,\n       /*replace_type_selector=*/nullptr, /*cross_computation=*/false,\n@@ -301,6 +287,14 @@ bool IsDynamicSliceOrDynamicUpdateSlice(const HloInstruction* instr) {\n           instr->opcode() == HloOpcode::kDynamicUpdateSlice);\n }\n \n+// Collects the slice info for the argument `arg_idx` of the fusion\n+// `fusion_instr`. can_compute_indvar_on_host is true if the induction variable\n+// can be computed on host. while_op is the possible while op surrounding the\n+// fusion. indvar_idx is the possible tuple index of the induction variable in\n+// the while body.\n+// Note that when there is a wrapping while loop, we may not have an index\n+// variable for the loop, in case when the loop count is not naively controlled\n+// by a single loop index, so we will have the while op but no indvar_idx.\n absl::Status CollectSliceInfo(\n     const BufferAssignment& buffer_assignment,\n     const HloInstruction& fusion_instr,\n@@ -311,7 +305,8 @@ absl::Status CollectSliceInfo(\n     std::vector<std::optional<uint64_t>>& offset_byte_sizes,\n     std::vector<std::unique_ptr<HloModule>>& extracted_offset_modules,\n     unsigned arg_idx, bool can_compute_indvar_on_host,\n-    std::optional<const HloInstruction*> while_op) {\n+    std::optional<const HloInstruction*> while_op,\n+    std::optional<int64_t> indvar_idx) {\n   if (!IsDynamicSliceOrDynamicUpdateSlice(slice_instrs[arg_idx])) {\n     return absl::OkStatus();\n   }\n@@ -347,10 +342,10 @@ absl::Status CollectSliceInfo(\n             absl::StrCat(\"Unsupported constant offset shape: \",\n                          offset_literal->shape().ToString()));\n       }\n-\n-    } else if (std::unique_ptr<HloModule> offset_module =\n-                   ExtractOffsetModule(offset_value, while_op);\n-               (can_compute_indvar_on_host && offset_module != nullptr)) {\n+    } else if (indvar_idx != std::nullopt && can_compute_indvar_on_host) {\n+      std::unique_ptr<HloModule> offset_module =\n+          ExtractOffsetModule(offset_value, indvar_idx.value());\n+      CHECK(offset_module != nullptr) << \"Failed to extract slice module\";\n       extracted_offset_modules.push_back(std::move(offset_module));\n       arg_offsets.emplace_back() = extracted_offset_modules.back().get();\n     } else {\n@@ -406,9 +401,9 @@ absl::StatusOr<BufferAllocation::Slice> GetResultSlice(\n     return GetAllocationSlice(buffer_assignment, &fusion_instr, shape_idx);\n   }\n \n-  // Walk through ShapeIndex to find the real \"user\" (i.e. not get-tuple-element\n-  // user). Otherwise one sliced element will mark all buffers of all other\n-  // elements \"sliced\" too.\n+  // Walk through ShapeIndex to find the real \"user\" (i.e. not\n+  // get-tuple-element user). Otherwise one sliced element will mark all\n+  // buffers of all other elements \"sliced\" too.\n   if (start->shape().IsTuple()) {\n     for (auto [index_nesting_level, index_in_shape] :\n          llvm::enumerate(shape_idx)) {\n@@ -483,8 +478,8 @@ absl::StatusOr<BufferAllocation::Slice> GetResultSlice(\n   // computation. There are two options; either, the root is a tuple, or it is\n   // not.\n   //\n-  // If the root is not a tuple, we can simply get the buffer slice assigned to\n-  // the fusion itself---there is nothing else to choose from.\n+  // If the root is not a tuple, we can simply get the buffer slice assigned\n+  // to the fusion itself---there is nothing else to choose from.\n   if (fusion_instr.shape().IsArray()) {\n     HloInstruction* root = fusion_instr.fused_expression_root();\n     if (root->opcode() == HloOpcode::kDynamicUpdateSlice &&\n@@ -502,7 +497,8 @@ absl::StatusOr<BufferAllocation::Slice> GetResultSlice(\n   do {\n     TF_RET_CHECK(current_hlo->user_count() == 1);\n     HloInstruction* user = current_hlo->users().front();\n-    // We may encounter three ops here: dynamic-update-slice, tuple, or bitcast.\n+    // We may encounter three ops here: dynamic-update-slice, tuple, or\n+    // bitcast.\n     switch (user->opcode()) {\n       case HloOpcode::kBitcast:\n         break;\n@@ -547,44 +543,50 @@ absl::StatusOr<FusionEmissionResult> EmitGemm(\n   std::optional<HloInstruction*> while_op =\n       GetParentWhileOp(fusion, call_graph);\n   std::unique_ptr<HloModule> init_module, update_module;\n+  std::optional<int64_t> indvar_idx;\n   if (while_op != std::nullopt) {\n     CHECK(while_op.value() != nullptr)\n         << \"GetWhileOp is not expected to return nullptr.\";\n-    init_module = ExtractWhileInitModule(*while_op);\n-    update_module = ExtractWhileUpdateModule(*while_op);\n+    indvar_idx = GetLoopInductionVarTupleIdx(*while_op);\n+    if (indvar_idx != std::nullopt) {\n+      init_module = ExtractWhileInitModule(*while_op, indvar_idx.value());\n+      update_module = ExtractWhileUpdateModule(*while_op, indvar_idx.value());\n+    }\n   }\n   bool can_compute_indvar_on_host =\n       (init_module != nullptr && update_module != nullptr);\n \n   unsigned arg_idx = 0;\n-  TF_ASSIGN_OR_RETURN(BufferAllocation::Slice lhs_slice,\n-                      GetOperandSlice(buffer_assignment, adaptor, fusion,\n-                                      *custom_call.operand(arg_idx),\n-                                      slice_instrs, /*shape_idx=*/{}, arg_idx));\n+  TF_ASSIGN_OR_RETURN(\n+      BufferAllocation::Slice lhs_slice,\n+      GetOperandSlice(buffer_assignment, adaptor, fusion,\n+                      *custom_call.operand(arg_idx), slice_instrs,\n+                      /*shape_idx=*/{}, arg_idx));\n   TF_RETURN_IF_ERROR(CollectSliceInfo(\n       buffer_assignment, fusion, absl::Span<HloInstruction*>(slice_instrs),\n       offset_buffer_indices, orig_shapes, sliced_shapes, offset_byte_sizes,\n-      extracted_offset_modules, arg_idx++, can_compute_indvar_on_host,\n-      while_op));\n+      extracted_offset_modules, arg_idx++, can_compute_indvar_on_host, while_op,\n+      indvar_idx));\n \n-  TF_ASSIGN_OR_RETURN(BufferAllocation::Slice rhs_slice,\n-                      GetOperandSlice(buffer_assignment, adaptor, fusion,\n-                                      *custom_call.operand(arg_idx),\n-                                      slice_instrs, /*shape_idx=*/{}, arg_idx));\n+  TF_ASSIGN_OR_RETURN(\n+      BufferAllocation::Slice rhs_slice,\n+      GetOperandSlice(buffer_assignment, adaptor, fusion,\n+                      *custom_call.operand(arg_idx), slice_instrs,\n+                      /*shape_idx=*/{}, arg_idx));\n   TF_RETURN_IF_ERROR(CollectSliceInfo(\n       buffer_assignment, fusion, absl::Span<HloInstruction*>(slice_instrs),\n       offset_buffer_indices, orig_shapes, sliced_shapes, offset_byte_sizes,\n-      extracted_offset_modules, arg_idx++, can_compute_indvar_on_host,\n-      while_op));\n+      extracted_offset_modules, arg_idx++, can_compute_indvar_on_host, while_op,\n+      indvar_idx));\n \n   BufferAllocation::Slice output;\n   std::optional<BufferAllocation::Slice> workspace = std::nullopt;\n   std::optional<BufferAllocation::Slice> slice_workspace_fake = std::nullopt;\n \n   // Handling cases where multiple operands share the same buffer, with\n-  // different offset by creating new fake allocations so each operand will have\n-  // a different buffer index. The slices can thus always start at offset 0.\n-  // DynamicSliceThunk will take care of the offset adjustment.\n+  // different offset by creating new fake allocations so each operand will\n+  // have a different buffer index. The slices can thus always start at offset\n+  // 0. DynamicSliceThunk will take care of the offset adjustment.\n   std::vector<std::unique_ptr<BufferAllocation>> fake_allocations(4);\n   if (fusion.shape().IsArray()) {\n     TF_ASSIGN_OR_RETURN(\n@@ -593,8 +595,8 @@ absl::StatusOr<FusionEmissionResult> EmitGemm(\n     TF_RETURN_IF_ERROR(CollectSliceInfo(\n         buffer_assignment, fusion, absl::Span<HloInstruction*>(slice_instrs),\n         offset_buffer_indices, orig_shapes, sliced_shapes, offset_byte_sizes,\n-        extracted_offset_modules, arg_idx, can_compute_indvar_on_host,\n-        while_op));\n+        extracted_offset_modules, arg_idx, can_compute_indvar_on_host, while_op,\n+        indvar_idx));\n   } else {\n     TF_ASSIGN_OR_RETURN(\n         output,\n@@ -605,7 +607,7 @@ absl::StatusOr<FusionEmissionResult> EmitGemm(\n         buffer_assignment, fusion, absl::Span<HloInstruction*>(slice_instrs),\n         offset_buffer_indices, orig_shapes, sliced_shapes, offset_byte_sizes,\n         extracted_offset_modules, arg_idx++, can_compute_indvar_on_host,\n-        while_op));\n+        while_op, indvar_idx));\n \n     // TODO(vuson): If we want to support slices of workspace, we'd need to\n     // start `HloFindIf` with `get-tuple-element` with the right index.\n@@ -615,8 +617,8 @@ absl::StatusOr<FusionEmissionResult> EmitGemm(\n     TF_RETURN_IF_ERROR(CollectSliceInfo(\n         buffer_assignment, fusion, absl::Span<HloInstruction*>(slice_instrs),\n         offset_buffer_indices, orig_shapes, sliced_shapes, offset_byte_sizes,\n-        extracted_offset_modules, arg_idx, can_compute_indvar_on_host,\n-        while_op));\n+        extracted_offset_modules, arg_idx, can_compute_indvar_on_host, while_op,\n+        indvar_idx));\n     fake_allocations[arg_idx] = std::make_unique<BufferAllocation>(\n         /*index=*/arg_idx, workspace->size(), /*color=*/0);\n     slice_workspace_fake = BufferAllocation::Slice(\n@@ -683,7 +685,8 @@ absl::StatusOr<FusionEmissionResult> EmitGemm(\n           DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata{\n               /*indvar_init=*/std::move(init_module),\n               /*indvar_update=*/std::move(update_module),\n-              /*extracted_offset_modules=*/std::move(extracted_offset_modules)};\n+              /*extracted_offset_modules=*/\n+              std::move(extracted_offset_modules)};\n     }\n     thunk = std::make_unique<DynamicSliceThunk>(\n         thunk_info, std::make_unique<ThunkSequence>(std::move(seq)),\n@@ -753,11 +756,15 @@ absl::StatusOr<FusionEmissionResult> EmitCustomCall(\n   std::optional<HloInstruction*> while_op =\n       GetParentWhileOp(fusion, call_graph);\n   std::unique_ptr<HloModule> init_module, update_module;\n+  std::optional<int64_t> indvar_idx = std::nullopt;\n   if (while_op != std::nullopt) {\n     CHECK(while_op.value() != nullptr)\n         << \"GetWhileOp is not expected to return nullptr.\";\n-    init_module = ExtractWhileInitModule(*while_op);\n-    update_module = ExtractWhileUpdateModule(*while_op);\n+    indvar_idx = GetLoopInductionVarTupleIdx(*while_op);\n+    if (indvar_idx != std::nullopt) {\n+      init_module = ExtractWhileInitModule(*while_op, indvar_idx.value());\n+      update_module = ExtractWhileUpdateModule(*while_op, indvar_idx.value());\n+    }\n   }\n   bool can_compute_indvar_on_host =\n       (init_module != nullptr && update_module != nullptr);\n@@ -784,7 +791,7 @@ absl::StatusOr<FusionEmissionResult> EmitCustomCall(\n               buffer_assignment, fusion,\n               absl::Span<HloInstruction*>(slice_instrs), offsets, orig_shapes,\n               sliced_shapes, offset_byte_sizes, extracted_offset_modules,\n-              arg_idx++, can_compute_indvar_on_host, while_op));\n+              arg_idx++, can_compute_indvar_on_host, while_op, indvar_idx));\n \n           operands.push_back(CustomCallThunk::Slice{slice, subshape});\n           arguments.push_back(slice);\n@@ -811,7 +818,7 @@ absl::StatusOr<FusionEmissionResult> EmitCustomCall(\n             buffer_assignment, fusion,\n             absl::Span<HloInstruction*>(slice_instrs), offsets, orig_shapes,\n             sliced_shapes, offset_byte_sizes, extracted_offset_modules,\n-            arg_idx++, can_compute_indvar_on_host, while_op));\n+            arg_idx++, can_compute_indvar_on_host, while_op, indvar_idx));\n \n         results.push_back(CustomCallThunk::Slice{slice, subshape});\n         arguments.push_back(slice);\n@@ -831,8 +838,8 @@ absl::StatusOr<FusionEmissionResult> EmitCustomCall(\n   CustomCallThunk::CustomCallTarget custom_call_target;\n \n   // For XLA FFI handlers we decode opaque backend config into attributes map\n-  // at IR emission time, so that we do not need to parse MLIR at run time. For\n-  // FFI handlers backend config must be a compatible MLIR dictionary.\n+  // at IR emission time, so that we do not need to parse MLIR at run time.\n+  // For FFI handlers backend config must be a compatible MLIR dictionary.\n   CustomCallThunk::AttributesMap attributes;\n \n   // For information about this calling convention, see\n@@ -982,7 +989,8 @@ absl::StatusOr<FusionEmissionResult> EmitCustomCall(\n           DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata{\n               /*indvar_init=*/std::move(init_module),\n               /*indvar_update=*/std::move(update_module),\n-              /*extracted_offset_modules=*/std::move(extracted_offset_modules)};\n+              /*extracted_offset_modules=*/\n+              std::move(extracted_offset_modules)};\n     }\n     thunk = std::make_unique<DynamicSliceThunk>(\n         thunk_info, std::make_unique<ThunkSequence>(std::move(seq)),\n@@ -1055,11 +1063,18 @@ CollectSliceArgumentMetadataForCollectives(\n   SliceDataForCollectives slice_data(num_args);\n   std::optional<HloInstruction*> while_op =\n       GetParentWhileOp(fusion_instr, call_graph);\n+\n+  std::optional<int64_t> indvar_idx = std::nullopt;\n   if (while_op != std::nullopt) {\n     CHECK(while_op.value() != nullptr)\n         << \"GetParentWhileOp is not expected to return nullptr.\";\n-    slice_data.init_module = ExtractWhileInitModule(*while_op);\n-    slice_data.update_module = ExtractWhileUpdateModule(*while_op);\n+    indvar_idx = GetLoopInductionVarTupleIdx(*while_op);\n+    if (indvar_idx != std::nullopt) {\n+      slice_data.init_module =\n+          ExtractWhileInitModule(*while_op, indvar_idx.value());\n+      slice_data.update_module =\n+          ExtractWhileUpdateModule(*while_op, indvar_idx.value());\n+    }\n   }\n   slice_data.can_compute_indvar_on_host = (slice_data.init_module != nullptr &&\n                                            slice_data.update_module != nullptr);\n@@ -1078,7 +1093,7 @@ CollectSliceArgumentMetadataForCollectives(\n         /*offsets=*/slice_data.offset_buffer_indices, slice_data.orig_shapes,\n         slice_data.sliced_shapes, slice_data.offset_byte_sizes,\n         slice_data.extracted_offset_modules, arg_idx,\n-        slice_data.can_compute_indvar_on_host, while_op));\n+        slice_data.can_compute_indvar_on_host, while_op, indvar_idx));\n     arg_idx++;\n   }\n \n@@ -1104,7 +1119,7 @@ CollectSliceArgumentMetadataForCollectives(\n         /*offsets=*/slice_data.offset_buffer_indices, slice_data.orig_shapes,\n         slice_data.sliced_shapes, slice_data.offset_byte_sizes,\n         slice_data.extracted_offset_modules, arg_idx,\n-        slice_data.can_compute_indvar_on_host, while_op));\n+        slice_data.can_compute_indvar_on_host, while_op, indvar_idx));\n     arg_idx++;\n   }\n \n@@ -1130,8 +1145,8 @@ CollectSliceArgumentMetadataForCollectives(\n       << \"Dynamic index operation found in a fusion instruction that is not \"\n          \"labelled dynamic_address_computation\";\n   if (slice_data.isDynamic) {\n-    // Provide fake allocations for inputs and outputs. The dynamic-slice thunk\n-    // will own these allocations.\n+    // Provide fake allocations for inputs and outputs. The dynamic-slice\n+    // thunk will own these allocations.\n     unsigned fake_arg_idx = 0;\n     for (HloInstruction* operand : instr->operands()) {\n       int64_t operand_byte_size = ShapeUtil::ByteSizeOf(operand->shape());\n@@ -1157,7 +1172,8 @@ CollectSliceArgumentMetadataForCollectives(\n       int64_t out_fake_byte_size = ShapeUtil::ByteSizeOf(user->shape());\n       slice_data.fake_allocations[fake_arg_idx] =\n           std::make_unique<BufferAllocation>(\n-              /*index=*/fake_arg_idx, /*size=*/out_fake_byte_size, /*color=*/0);\n+              /*index=*/fake_arg_idx, /*size=*/out_fake_byte_size,\n+              /*color=*/0);\n       BufferAllocation::Slice fake_slice(\n           /*allocation=*/slice_data.fake_allocations[fake_arg_idx].get(),\n           /*offset=*/0, /*size=*/out_fake_byte_size);\n@@ -1237,7 +1253,8 @@ absl::StatusOr<FusionEmissionResult> EmitCollective(\n       std::optional<BufferAllocation::Slice> dst =\n           slice_data.args()[idx + instr->operand_count()];\n       TF_RET_CHECK(src.has_value() && dst.has_value())\n-          << \"Expected source and destination to be present for non-degenerate \"\n+          << \"Expected source and destination to be present for \"\n+             \"non-degenerate \"\n              \"collective\";\n       buffers.push_back(CollectiveThunk::Buffer{\n           /*element_count=*/ShapeUtil::ElementsIn(src_shape),\n@@ -1272,8 +1289,8 @@ absl::StatusOr<FusionEmissionResult> EmitCollective(\n     return implementable_status;\n   }\n \n-  // Depending on whether this is a dynamic fusion or not, we wrap the thunk(s)\n-  // within a dynamic-slice thunk.\n+  // Depending on whether this is a dynamic fusion or not, we wrap the\n+  // thunk(s) within a dynamic-slice thunk.\n   if (slice_data.isDynamic) {\n     std::optional<DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata>\n         offset_modules_metadata = std::nullopt;"
        },
        {
            "sha": "c5e3efc066783be62e3380fa6a493222affe190d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/dynamic_update_slice/bitcast.hlo",
            "status": "removed",
            "additions": 0,
            "deletions": 10,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fbitcast.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fbitcast.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fbitcast.hlo?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,10 +0,0 @@\n-// RUN: gpu_test_correctness %s\n-\n-fusion {\n-  in = f32[20,30] parameter(0)\n-  updates = f32[5,6] parameter(1)\n-  i0 = s32[] parameter(2)\n-  i1 = s32[] parameter(3)\n-  updated = f32[20,30] dynamic-update-slice(in, updates, i0, i1)\n-  ROOT bitcast = f32[600] bitcast(updated)\n-}\n\\ No newline at end of file"
        },
        {
            "sha": "d74ea7bcf72ebc87cccdf112552a32484ca4cb2d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/dynamic_update_slice/int4.hlo",
            "status": "removed",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fint4.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fint4.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fint4.hlo?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,14 +0,0 @@\n-// RUN: fusion_to_mlir %s | emitters_opt -xla-test-optimize \\\n-// RUN:   -xla-gpu-test-transform-loops | FileCheck %s\n-// RUN: gpu_test_correctness %s --bijection_inputs=dus:1\n-\n-f {\n-  input = s4[100,9] parameter(0)\n-  slice = s4[100,6] parameter(1)\n-  c0 = s32[] constant(0)\n-  ROOT dus = s4[100,9] dynamic-update-slice(input, slice, c0, c0)\n-}\n-\n-// CHECK: vector.transfer_read\n-// CHECK: tensor.insert\n-// CHECK: tensor.insert"
        },
        {
            "sha": "e9b99eed0439cbf8a6c3a0357ddb380746d010bd",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/dynamic_update_slice/mof.hlo",
            "status": "removed",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fmof.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fmof.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fmof.hlo?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,16 +0,0 @@\n-// RUN: gpu_test_correctness %s\n-\n-fusion {\n-  p0 = f32[10,11,12] parameter(0)\n-  p1 = f32[1,11,12] parameter(1)\n-  p2 = f32[8,11,12] parameter(2)\n-  p3 = f32[1,11,12] parameter(3)\n-  p4 = s32[] parameter(4)\n-  c0 = s32[] constant(0)\n-  cmp = pred[] compare(p4, c0), direction=EQ\n-  broadcast = pred[1,11,12] broadcast(cmp), dimensions={}\n-  select = f32[1,11,12] select(broadcast, p1, p3)\n-  dus0 = f32[10,11,12] dynamic-update-slice(p0, select, c0, c0, c0)\n-  dus1 = f32[8,11,12] dynamic-update-slice(p2, select, c0, c0, c0)\n-  ROOT tuple = (f32[10,11,12], f32[8,11,12]) tuple(dus0, dus1)\n-}\n\\ No newline at end of file"
        },
        {
            "sha": "bed56339c92be1ce1f633ef6835fe656f0b08321",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/dynamic_update_slice/vectorize_x1_too_small.hlo",
            "status": "removed",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x1_too_small.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x1_too_small.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x1_too_small.hlo?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,14 +0,0 @@\n-// RUN: fusion_to_mlir %s | emitters_opt -xla-test-optimize \\\n-// RUN:   -xla-gpu-test-transform-loops | FileCheck %s\n-// RUN: gpu_test_correctness %s --bijection_inputs=dus:1\n-\n-dus {\n-  %input = f32[40,40,300] parameter(0)\n-  %update = f32[1,1,40] parameter(1)\n-  %idx = s32[] parameter(2)\n-  %zero = s32[] constant(0)\n-  ROOT dus = f32[40,40,300] dynamic-update-slice(%input, %update, %idx, %zero, %zero)\n-}\n-\n-// CHECK-NOT: vector.transfer_read {{.*}} vector<4xf32>\n-// CHECK-NOT: vector.transfer_write {{.*}} vector<4xf32>"
        },
        {
            "sha": "4ab04fd3313e22aa01ad1d308d852fc47548526d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/dynamic_update_slice/vectorize_x4.hlo",
            "status": "removed",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x4.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/66940b914c1c41f8793e9eb2da013a2f73fd9769/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x4.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x4.hlo?ref=66940b914c1c41f8793e9eb2da013a2f73fd9769",
            "patch": "@@ -1,14 +0,0 @@\n-// RUN: fusion_to_mlir %s | emitters_opt -xla-test-optimize \\\n-// RUN:   -xla-gpu-test-transform-loops | FileCheck %s\n-// RUN: gpu_test_correctness %s --bijection_inputs=dus:1\n-\n-dus {\n-  %input = f32[40,40,300] parameter(0)\n-  %update = f32[20,40,300] parameter(1)\n-  %idx = s32[] parameter(2)\n-  %zero = s32[] constant(0)\n-  ROOT dus = f32[40,40,300] dynamic-update-slice(%input, %update, %idx, %zero, %zero)\n-}\n-\n-// CHECK: vector.transfer_read {{.*}} vector<4xf32>\n-// CHECK: vector.transfer_write {{.*}} vector<4xf32>"
        },
        {
            "sha": "d7ac2f92e82ef61aa2a42a2786f8a2f800d48ced",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/compilation_pipeline_cuda.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline_cuda.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline_cuda.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline_cuda.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -145,13 +145,15 @@ absl::Status CreateTritonPipeline(\n   pm->addPass(mt::gpu::createTritonGPUCombineTensorSelectAndIf());\n   pm->addPass(mt::gpu::createTritonGPUAllocateWarpGroups());\n   pm->addPass(mlir::createSCFToControlFlowPass());\n-  pm->addPass(mt::createAllocateSharedMemoryNvPass(ccAsInt));\n+  pm->addPass(mt::createAllocateSharedMemoryNvPass(\n+      ccAsInt, mlir::triton::AllocateSharedMemoryNvOptions{}.ptxVersion));\n   pm->addPass(ttng::createTritonTensorMemoryAllocationPass());\n   // We could add a flag to XLA to optionally enable the following pass:\n   // pm->addPass(mt::instrument::createTritonInstrumentConcurrencySanitizer());\n   pm->addPass(mt::gpu::createTritonGPUGlobalScratchAllocationPass());\n   pm->addPass(ttng::createTritonGPUProxyFenceInsertion({ccAsInt}));\n-  pm->addPass(mt::createConvertTritonGPUToLLVMPass(ccAsInt));\n+  pm->addPass(mt::createConvertTritonGPUToLLVMPass(\n+      ccAsInt, mlir::triton::ConvertTritonGPUToLLVMOptions{}.ptxVersion));\n   pm->addPass(mlir::createCanonicalizerPass());\n   pm->addPass(mlir::createCSEPass());\n   pm->addPass(mt::createConvertNVGPUToLLVM());"
        },
        {
            "sha": "8babe2f4506f779afc7eaa34b6e904fcba5bea47",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 53,
            "deletions": 30,
            "changes": 83,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -774,40 +774,63 @@ absl::StatusOr<Value> MaskDotOperand(EmitterLocOpBuilder& b,\n   int64_t tile_size = tile_shape[contraction_dimension_index];\n \n   if (contracting_dimension_size % tile_size != 0) {\n-    // When the contracting dimension is not divisible by the tile size, we\n-    // need to mask out the last tile. We do this with the following logic:\n-    //\n-    // indices =\n-    //   contracting_dimension_tile_index * tile_size + range(0, tile_size)\n-    // mask = indices < contracting_dimension_size\n-    // operand = select(broadcast(mask, operand.shape), operand, 0)\n-    Value range = Range(b, tile_size).UnwrapTensor();\n+    // Only mask out tiles that we know to go beyond boundaries of the\n+    // contracting dimension---i.e. tiles whose index exceeds the number of\n+    // full tiles (tiles without padding).\n+    Type result_type = dot_operand_value.getType();\n     Value tile_size_value =\n         CreateConst(b, b.getI32Type(), tile_size, {}).UnwrapScalar();\n-    Value tile_offset = b.create<arith::MulIOp>(\n-        contracting_dimension_tile_index, tile_size_value);\n-    Value broadcasted_tile_offset =\n-        Splat(b, ScalarOrTensor(tile_offset), {tile_size}).UnwrapTensor();\n-    Value indices = b.create<arith::AddIOp>(range, broadcasted_tile_offset);\n-\n-    Value boundary =\n-        CreateConst(b, b.getI32Type(), contracting_dimension_size, {tile_size})\n-            .UnwrapTensor();\n-\n-    Value mask =\n-        b.create<arith::CmpIOp>(arith::CmpIPredicate::slt, indices, boundary);\n-\n-    mask = BroadcastInDims(b, ScalarOrTensor(mask), tile_shape,\n-                           {contraction_dimension_index})\n-               .UnwrapTensor();\n-    TF_ASSIGN_OR_RETURN(\n-        auto element_type,\n-        TritonType(b, dot_operand.hlo()->shape().element_type()));\n+    Value num_full_tiles = b.create<arith::DivSIOp>(\n+        CreateConst(b, b.getI32Type(), contracting_dimension_size, {})\n+            .UnwrapScalar(),\n+        tile_size_value);\n+    // if tile_index >= num_full_tiles...\n+    auto cond = b.create<arith::CmpIOp>(arith::CmpIPredicate::sge,\n+                                        contracting_dimension_tile_index,\n+                                        num_full_tiles);\n+    auto if_op = b.create<mlir::scf::IfOp>(mlir::TypeRange(result_type), cond,\n+                                           /*withElseRegion=*/true);\n+    // then ...\n+    {\n+      b.setInsertionPointToStart(if_op.thenBlock());\n+      // indices =\n+      //   contracting_dimension_tile_index * tile_size + range(0, tile_size)\n+      // mask = indices < contracting_dimension_size\n+      // operand = select(broadcast(mask, operand.shape), operand, 0)\n+      Value tile_offset = b.create<arith::MulIOp>(\n+          contracting_dimension_tile_index, tile_size_value);\n+      Value range = Range(b, tile_size).UnwrapTensor();\n+      Value broadcasted_tile_offset =\n+          Splat(b, ScalarOrTensor(tile_offset), {tile_size}).UnwrapTensor();\n+      Value indices = b.create<arith::AddIOp>(range, broadcasted_tile_offset);\n+\n+      Value boundary = CreateConst(b, b.getI32Type(),\n+                                   contracting_dimension_size, {tile_size})\n+                           .UnwrapTensor();\n+\n+      Value mask =\n+          b.create<arith::CmpIOp>(arith::CmpIPredicate::slt, indices, boundary);\n+\n+      mask = BroadcastInDims(b, ScalarOrTensor(mask), tile_shape,\n+                             {contraction_dimension_index})\n+                 .UnwrapTensor();\n+      TF_ASSIGN_OR_RETURN(\n+          auto element_type,\n+          TritonType(b, dot_operand.hlo()->shape().element_type()));\n \n-    ScalarOrTensor zero = CreateConst(b, element_type, 0.0f, tile_shape);\n+      ScalarOrTensor zero = CreateConst(b, element_type, 0.0f, tile_shape);\n \n-    return b.create<arith::SelectOp>(mask, dot_operand_value,\n-                                     zero.UnwrapTensor());\n+      Value masked_dot_operand = b.create<arith::SelectOp>(\n+          mask, dot_operand_value, zero.UnwrapTensor());\n+      b.create<mlir::scf::YieldOp>(masked_dot_operand);\n+    }\n+    // else ...\n+    {\n+      b.setInsertionPointToStart(if_op.elseBlock());\n+      b.create<mlir::scf::YieldOp>(dot_operand_value);\n+    }\n+    b.setInsertionPointAfter(if_op);\n+    return if_op.getResult(0);\n   }\n \n   return dot_operand_value;"
        },
        {
            "sha": "c4dc3ba1215b6ec4d3d14bf740ae3a23e7fc0f59",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 1,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -59,7 +59,6 @@ limitations under the License.\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n-#include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n #include \"xla/types.h\"\n@@ -2981,6 +2980,18 @@ ENTRY entry {\n           \"num_ctas\":\"1\",\n           \"num_stages\":\"1\"}}}\n })\";\n+\n+  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText, \"fdot\", R\"(\n+  // Ensure that masking is applied only conditionally to both operands.\n+  CHECK:      %[[MASKED_OPERAND0:.*]] = scf.if\n+  CHECK:        %[[SELECT0:.*]] = arith.select\n+  CHECK-NEXT:   scf.yield %[[SELECT0]]\n+  CHECK:      %[[MASKED_OPERAND1:.*]] = scf.if\n+  CHECK:        %[[SELECT1:.*]] = arith.select\n+  CHECK-NEXT:   scf.yield %[[SELECT1]]\n+  CHECK:      tt.dot %[[MASKED_OPERAND0]], %[[MASKED_OPERAND1]]\n+)\"));\n+\n   EXPECT_TRUE(RunAndCompareNoHloPasses(\n       kHloText, ErrorSpec{/*aabs=*/1e-4, /*arel=*/1e-6}));\n }\n@@ -3677,6 +3688,27 @@ INSTANTIATE_TEST_SUITE_P(\n                        ::testing::ValuesIn(AllXlaDataTypes())),\n     DotUnsetAlgorithmEmitterTest::ParamToString);\n \n+TEST_F(TritonEmitterTest, ScaledDotIsSupportedByReferencePlatform) {\n+  if (!std::get_if<se::CudaComputeCapability>(&GpuComputeCapability())) {\n+    GTEST_SKIP() << \"Ignore scaled dot test on ROCM.\";\n+  }\n+  constexpr absl::string_view kHloText = R\"(\n+    HloModule ScaledDotIsSupportedByReferencePlatform\n+\n+    ENTRY entry {\n+     lhs = bf16[4,4] parameter(0)\n+     lhs_scale = bf16[1,1] parameter(1)\n+     rhs = bf16[4,4] parameter(2)\n+     rhs_scale = bf16[1,1] parameter(3)\n+     ROOT dot = bf16[4,4] scaled-dot(lhs, lhs_scale, rhs, rhs_scale),\n+         lhs_contracting_dims={1},\n+         rhs_contracting_dims={1}\n+    }\n+  )\";\n+\n+  EXPECT_TRUE(RunAndCompare(kHloText, ErrorSpec{/*aabs=*/1e-3, /*arel=*/1e-3}));\n+}\n+\n TEST_F(TritonEmitterTest, RocmWarpSizeIsSetCorrectly) {\n   if (std::get_if<se::CudaComputeCapability>(&GpuComputeCapability())) {\n     GTEST_SKIP() << \"Warp size is always 32 on CUDA\";"
        },
        {
            "sha": "8b66a7eec546d710c644241a27b3916fbba74fee",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_int4_device_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -58,9 +58,10 @@ class TritonTest : public GpuCodegenTest {\n         .set_xla_gpu_experimental_enable_subchannel_dequantisation_fusion(true);\n     // TODO(b/393299275): remove this once flag is on by default and test is\n     // updated.\n-    // Note that we do NOT set\n-    // xla_gpu_unsupported_generic_triton_emitter_opts1 here as test\n-    // will run the pass forcefully later.\n+    // Note that we clear\n+    // xla_gpu_unsupported_generic_triton_emitter_opts here to disable\n+    // nest gemm fusion pass as test will run the pass manually.\n+    debug_options.clear_xla_gpu_unsupported_generic_triton_emitter_features();\n     return debug_options;\n   }\n "
        },
        {
            "sha": "f543963f090ed2b4d689a24d4891a26fe946e105",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_parametrized_legacy_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_parametrized_legacy_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_parametrized_legacy_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_parametrized_legacy_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -75,6 +75,9 @@ class MixedTypeTest : public GpuCodegenTest,\n     debug_options.set_xla_gpu_cublas_fallback(false);\n     // Always rewrite Gemms with Triton regardless of size.\n     debug_options.set_xla_gpu_gemm_rewrite_size_threshold(0);\n+    // That is a test for legacy Triton emitter that is being replaced by the\n+    // generic Triton emitter.\n+    debug_options.clear_xla_gpu_unsupported_generic_triton_emitter_features();\n     return debug_options;\n   }\n };"
        },
        {
            "sha": "bfb3c271d7b671d89db2e470f37e0e80423390c6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 101,
            "deletions": 0,
            "changes": 101,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1,3 +1,4 @@\n+load(\"@local_config_cuda//cuda:build_defs.bzl\", \"cuda_library\")\n load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n load(\"//xla:xla.default.bzl\", \"xla_cc_test\", \"xla_internal\")\n load(\"//xla/tests:build_defs.bzl\", \"xla_test\")\n@@ -861,6 +862,106 @@ xla_cc_test(\n     ],\n )\n \n+cuda_library(\n+    name = \"select_k_exec_raft\",\n+    srcs = [\"select_k_exec_raft.cc\"],\n+    hdrs = [\"select_k_exec.h\"],\n+    copts = [\n+        \"-fexceptions\",\n+        \"-DLIBCUDACXX_ENABLE_EXPERIMENTAL_MEMORY_RESOURCE\",\n+    ],\n+    tags = [\"cuda-only\"],\n+    textual_hdrs = [\"raft_vectorized_bf16.h\"],\n+    deps = [\n+        \"//xla:status_macros\",\n+        \"//xla:types\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:device_memory_allocator\",\n+        \"//xla/stream_executor:scratch_allocator\",\n+        \"//xla/stream_executor:stream\",\n+        \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@local_config_cuda//cuda:cuda_headers\",\n+        \"@raft//:raft_matrix\",\n+    ],\n+)\n+\n+cuda_library(\n+    name = \"select_k_exec_stub\",\n+    srcs = [\"select_k_exec_stub.cc\"],\n+    hdrs = [\"select_k_exec.h\"],\n+    deps = [\n+        \"//xla:types\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:device_memory_allocator\",\n+        \"//xla/stream_executor:stream\",\n+        \"@com_google_absl//absl/status\",\n+    ],\n+)\n+\n+xla_test(\n+    name = \"select_k_exec_raft_test\",\n+    srcs = [\"select_k_exec_raft_test.cc\"],\n+    backends = [\n+        \"gpu\",\n+    ],\n+    tags = [\n+        \"cuda-only\",\n+    ],\n+    deps = [\n+        \":select_k_exec_raft\",\n+        \"//xla:types\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla:xla_proto_cc\",\n+        \"//xla/service:platform_util\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:platform\",\n+        \"//xla/stream_executor:platform_manager\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor:stream_executor_memory_allocator\",\n+        \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/base\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/random\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"select_k_thunk\",\n+    srcs = [\"select_k_thunk.cc\"],\n+    hdrs = [\"select_k_thunk.h\"],\n+    tags = [\"gpu\"],\n+    deps = [\n+        \":thunk\",\n+        \":thunk_proto_cc\",\n+        \"//xla:shape_util\",\n+        \"//xla:types\",\n+        \"//xla/codegen/emitters:kernel_arguments\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:device_memory_allocator\",\n+        \"//xla/stream_executor:stream\",\n+        \"@com_google_absl//absl/container:inlined_vector\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/strings\",\n+    ] + if_cuda_is_configured(\n+        [\":select_k_exec_raft\"],\n+        no_cuda = [\":select_k_exec_stub\"],\n+    ),\n+)\n+\n cc_library(\n     name = \"memset_thunk\",\n     srcs = [\"memset_thunk.cc\"],"
        },
        {
            "sha": "7df1b2ad7d0c35431f423a7dc9265e9d77a54483",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -283,7 +283,7 @@ absl::StatusOr<bool> CollectivePermuteStartThunk::RunCollective(\n                         comm_handle.comm->NumRanks());\n \n     auto rendezvous_name = absl::StrFormat(\n-        \"rendezvous before calling collective-permute; run_id=%d; op id:%d; \"\n+        \"rendezvous before calling collective-permute; run_id=%ld; op id:%d; \"\n         \"num_local_participants:%d\",\n         params.collective_params->run_id.ToInt(), config_.config.op_id,\n         num_local_participants);\n@@ -325,7 +325,7 @@ absl::StatusOr<bool> CollectivePermuteStartThunk::RunCollective(\n                         comm_handle.comm->NumRanks());\n \n     auto rendezvous_name = absl::StrFormat(\n-        \"rendezvous after calling collective-permute; run_id=%d; op id:%d; \"\n+        \"rendezvous after calling collective-permute; run_id=%ld; op id:%d; \"\n         \"num_local_participants:%d\",\n         params.collective_params->run_id.ToInt(), config_.config.op_id,\n         num_local_participants);"
        },
        {
            "sha": "176de04d629506b9e640411f73c38ec723df1a50",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -518,7 +518,7 @@ absl::Status CollectiveThunk::ExecuteOnStream(const ExecuteParams& params) {\n \n     auto rendezvous_key = FirstCallRendezvousKey{std::move(clique_key)};\n     auto rendezvous_name = absl::StrFormat(\n-        \"first call to collective operation %d; run_id=%d\", config().op_id,\n+        \"first call to collective operation %d; run_id=%ld\", config().op_id,\n         params.collective_params->run_id.ToInt());\n \n     const xla::DebugOptions debug_options = xla::GetDebugOptionsFromFlags();"
        },
        {
            "sha": "74a593b58d58f8d5aae7d7af0ce5e6a27e5603fb",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 149,
            "deletions": 72,
            "changes": 221,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -237,32 +237,155 @@ namespace {\n // execution graph from a command sequence.\n class CommandOperation : public ExecutionGraph::Operation {\n  public:\n-  explicit CommandOperation(const CommandBufferCmd* cmd)\n+  explicit CommandOperation(CommandBufferCmd::BufferUseVector buffers,\n+                            ResourceUseVector resources,\n+                            const CommandBufferCmd* cmd)\n       : name_(absl::StrFormat(\"cmd %s: %s\", cmd->ToString(),\n                               cmd->profile_annotation())),\n-        buffers_(cmd->buffers()),\n-        resources_(cmd->resources()) {}\n+        buffers_(std::move(buffers)),\n+        resources_(std::move(resources)),\n+        cmd_(cmd),\n+        token_(Resource::Create(Resource::Kind::kToken)) {\n+    resources_.push_back(ResourceUse::Write(token_));\n+  }\n \n   absl::string_view name() const final { return name_; }\n   absl::Span<const BufferUse> BufferUses() const final { return buffers_; }\n   absl::Span<const ResourceUse> ResourceUses() const final {\n     return resources_;\n   }\n+  void add_resouce_use(ResourceUse resource_use) {\n+    resources_.push_back(resource_use);\n+  }\n+\n+  std::shared_ptr<Resource> token() const { return token_; }\n+  const CommandBufferCmd* cmd() const { return cmd_; }\n+\n+  std::string ToString() const final {\n+    std::vector<std::string> resource_reprs;\n+    resource_reprs.reserve(resources_.size());\n+    for (const ResourceUse& use : resources_) {\n+      absl::string_view access =\n+          use.access() == ResourceUse::kRead ? \"read\" : \"write\";\n+      absl::string_view kind = Resource::ToString(use.resource()->kind());\n+      resource_reprs.push_back(\n+          absl::StrFormat(\"%s@%p(%s)\", kind, use.resource().get(), access));\n+    }\n+\n+    return absl::StrFormat(\"%s resources=[%s]\", cmd_->ToString(),\n+                           absl::StrJoin(resource_reprs, \", \"));\n+  }\n \n  private:\n   std::string name_;\n   CommandBufferCmd::BufferUseVector buffers_;\n   ResourceUseVector resources_;\n+  const CommandBufferCmd* cmd_;\n+\n+  // The token resource is used to specify dependency other than buffer data\n+  // flow, e.g, LHS topology will use token resouce to specify dependency across\n+  // commands.\n+  std::shared_ptr<Resource> token_;\n };\n }  // namespace\n \n static std::vector<CommandOperation> CreateCommandOperations(\n-    const CommandBufferCmdSequence& commands) {\n+    const CommandBufferCmdSequence& commands,\n+    CommandBufferCmdExecutor::SynchronizationMode synchronization_mode) {\n   std::vector<CommandOperation> operations;\n   operations.reserve(commands.size());\n-  for (const std::unique_ptr<CommandBufferCmd>& cmd : commands) {\n-    operations.emplace_back(cmd.get());\n+  VLOG(3) << \"CreateCommandOperations with synchronization mode: \"\n+          << (synchronization_mode ==\n+                      CommandBufferCmdExecutor::SynchronizationMode::kConcurrent\n+                  ? \"Concurrent\"\n+                  : \"LHS\");\n+  if (synchronization_mode ==\n+      CommandBufferCmdExecutor::SynchronizationMode::kConcurrent) {\n+    // For concurrent synchronization mode, pass in buffer and resouces for\n+    // dependency inference.\n+    for (const std::unique_ptr<CommandBufferCmd>& cmd : commands) {\n+      operations.emplace_back(cmd->buffers(), cmd->resources(), cmd.get());\n+    }\n   }\n+\n+  if (synchronization_mode ==\n+      CommandBufferCmdExecutor::SynchronizationMode::kLHS) {\n+    // For LHS mode, don't pass in buffers.\n+    // Will use token resource to specify dependency across commands.\n+    for (const std::unique_ptr<CommandBufferCmd>& cmd : commands) {\n+      operations.emplace_back(CommandBufferCmd::BufferUseVector{},\n+                              cmd->resources(), cmd.get());\n+    }\n+\n+    auto is_async_start = [](const CommandOperation& op) -> bool {\n+      auto* collective_cmd = dynamic_cast<const CollectiveCmd*>(op.cmd());\n+      return (collective_cmd && collective_cmd->IsAsync());\n+    };\n+\n+    auto is_async_done = [](const CommandOperation& op) -> bool {\n+      auto* async_done_cmd = dynamic_cast<const AsyncDoneCmd*>(op.cmd());\n+      return (async_done_cmd && async_done_cmd->IsAsync());\n+    };\n+\n+    auto find_async_start_cmd_id = [&](int64_t async_done_cmd_id) -> int64_t {\n+      auto* async_done_cmd = dynamic_cast<const AsyncDoneCmd*>(\n+          operations[async_done_cmd_id].cmd());\n+      CHECK(async_done_cmd);\n+      for (int64_t j = async_done_cmd_id - 1; j >= 0; --j) {\n+        if (is_async_start(operations[j])) {\n+          auto* async_start_cmd =\n+              dynamic_cast<const CollectiveCmd*>(operations[j].cmd());\n+          if (async_start_cmd->IsAsync() &&\n+              async_start_cmd->async_events() ==\n+                  async_done_cmd->async_events()) {\n+            return j;\n+          }\n+        }\n+      }\n+      return -1;\n+    };\n+\n+    for (int64_t i = 0; i < operations.size(); ++i) {\n+      if (is_async_start(operations[i])) {\n+        for (int64_t j = i - 1; j >= 0; --j) {\n+          if (is_async_start(operations[j])) {\n+            continue;\n+          }\n+          operations[i].add_resouce_use(\n+              ResourceUse::Read(operations[j].token()));\n+          break;\n+        }\n+      } else if (is_async_done(operations[i])) {\n+        int64_t async_start_cmd_id = find_async_start_cmd_id(i);\n+        CHECK_NE(async_start_cmd_id, -1);\n+        operations[i].add_resouce_use(\n+            ResourceUse::Read(operations[async_start_cmd_id].token()));\n+        CHECK_GT(i, 0);\n+        if ((i - 1) != async_start_cmd_id) {\n+          operations[i].add_resouce_use(\n+              ResourceUse::Read(operations[i - 1].token()));\n+        }\n+      } else {\n+        for (int64_t j = i - 1; j >= 0; --j) {\n+          if (is_async_start(operations[j])) {\n+            // The first command in the async group does not depend on the async\n+            // command\n+            continue;\n+          }\n+          operations[i].add_resouce_use(\n+              ResourceUse::Read(operations[j].token()));\n+          break;\n+        }\n+      }\n+    }\n+  }\n+\n+  if (VLOG_IS_ON(2)) {\n+    for (const CommandOperation& op : operations) {\n+      VLOG(2) << op.ToString();\n+    }\n+  }\n+\n   return operations;\n }\n \n@@ -274,10 +397,11 @@ absl::StatusOr<CommandBufferCmdExecutor> CommandBufferCmdExecutor::Create(\n   // In automatic synchronization mode construct an execution graph for the\n   // sequence of commands and derive the structure of command dependencies\n   // from the buffer use conflicts.\n-  if (synchronization_mode == SynchronizationMode::kConcurrent) {\n-    auto operations = CreateCommandOperations(commands);\n+  if (synchronization_mode != SynchronizationMode::kSerialize) {\n+    auto operations = CreateCommandOperations(commands, synchronization_mode);\n     TF_ASSIGN_OR_RETURN(execution_graph,\n                         ExecutionGraph::Create<CommandOperation>(operations));\n+    VLOG(3) << \"Execution graph: \" << execution_graph->ToString();\n   }\n \n   return CommandBufferCmdExecutor(synchronization_mode, std::move(commands),\n@@ -369,7 +493,8 @@ CommandBufferCmdExecutor::RecordCreate(\n     return std::vector<const se::CommandBuffer::Command*>{};\n   }\n \n-  // Keep a state associated with commands in the sequence in the state manager.\n+  // Keep a state associated with commands in the sequence in the state\n+  // manager.\n   CommandBufferCmd::StateManager& state = record_params.state;\n \n   // Collect sink commands while recording the command sequence.\n@@ -396,9 +521,9 @@ CommandBufferCmdExecutor::RecordCreate(\n     std::vector<const se::CommandBuffer::Command*> command_dependencies =\n         Dependencies(record_params, command_buffer, id);\n \n-    // Source command must depend on external dependencies passed by the caller,\n-    // internal commands dependencies are defined by the command sequence\n-    // structure (buffer and resource dependencies).\n+    // Source command must depend on external dependencies passed by the\n+    // caller, internal commands dependencies are defined by the command\n+    // sequence structure (buffer and resource dependencies).\n     auto record_action =\n         IsSource(id) ? CommandBufferCmd::RecordCreate{dependencies}\n                      : CommandBufferCmd::RecordCreate{command_dependencies};\n@@ -439,7 +564,8 @@ absl::Status CommandBufferCmdExecutor::RecordUpdate(\n     return absl::OkStatus();\n   }\n \n-  // Keep a state associated with commands in the sequence in the state manager.\n+  // Keep a state associated with commands in the sequence in the state\n+  // manager.\n   CommandBufferCmd::StateManager& state = record_params.state;\n \n   // Check if command `id` has to be updated based on the buffer allocations\n@@ -544,7 +670,6 @@ CommandBufferCmdExecutor::Dependencies(const RecordParams& record_params,\n                                        se::CommandBuffer* command_buffer,\n                                        CommandId id) const {\n   // Source commands have no dependencies.\n-  VLOG(2) << \"CommandSequence is :\\n\" << commands_.ToString();\n   if (IsSource(id)) {\n     VLOG(2) << \"Command ID \" << id\n             << \" is a source command, empty dependencies\";\n@@ -558,54 +683,6 @@ CommandBufferCmdExecutor::Dependencies(const RecordParams& record_params,\n          execution_graph_->in_edges(id)) {\n       dependencies_ids.push_back(in_edge.id);\n     }\n-  } else if (synchronization_mode_ == SynchronizationMode::kLHS) {\n-    CHECK(id < commands_.size());\n-    auto is_async_start = [](const CommandBufferCmd* cmd) -> bool {\n-      return cmd->command_type() == CommandBufferCmdType::kAllGatherCmd ||\n-             cmd->command_type() == CommandBufferCmdType::kAllReduceCmd ||\n-             cmd->command_type() == CommandBufferCmdType::kReduceScatterCmd ||\n-             cmd->command_type() == CommandBufferCmdType::kAllToAllCmd;\n-    };\n-\n-    auto find_async_start_cmd_id =\n-        [&](const AsyncDoneCmd* async_done_cmd) -> CommandId {\n-      CHECK(async_done_cmd->async_events() != nullptr);\n-      for (CommandId i = id - 1; i >= 0; --i) {\n-        if (is_async_start(commands_[i].get()) &&\n-            static_cast<const CollectiveCmd*>(commands_[i].get())\n-                    ->async_events() == async_done_cmd->async_events()) {\n-          return i;\n-        }\n-      }\n-      return -1;\n-    };\n-\n-    if (commands_[id]->command_type() == CommandBufferCmdType::kAsyncDone) {\n-      // Add dependency on the async start command.\n-      auto async_start_cmd_id = find_async_start_cmd_id(\n-          static_cast<const AsyncDoneCmd*>(commands_[id].get()));\n-      CHECK_NE(async_start_cmd_id, -1);\n-      dependencies_ids.push_back(async_start_cmd_id);\n-\n-      // Add dependency on the last command in async region.\n-      for (CommandId i = id - 1; i > async_start_cmd_id; --i) {\n-        if (is_async_start(commands_[i].get()) &&\n-            static_cast<const CollectiveCmd*>(commands_[i].get())->IsAsync()) {\n-          continue;\n-        }\n-        dependencies_ids.push_back(i);\n-        break;\n-      }\n-    } else {\n-      for (CommandId i = id - 1; i >= 0; --i) {\n-        if (is_async_start(commands_[i].get()) &&\n-            static_cast<const CollectiveCmd*>(commands_[i].get())->IsAsync()) {\n-          continue;\n-        }\n-        dependencies_ids.push_back(i);\n-        break;\n-      }\n-    }\n   } else {\n     dependencies_ids.push_back(id - 1);\n   }\n@@ -620,10 +697,10 @@ CommandBufferCmdExecutor::Dependencies(const RecordParams& record_params,\n \n     if (record_state->command == nullptr) {\n       // Some commands might end up not recording anything into the command\n-      // buffer, e.g. memcpy commands where source and destination are the same.\n-      // We have to follow dependencies of such commands to find the real\n-      // dependencies, so we don't record a command that is immediately ready to\n-      // execute, as it will create data races.\n+      // buffer, e.g. memcpy commands where source and destination are the\n+      // same. We have to follow dependencies of such commands to find the\n+      // real dependencies, so we don't record a command that is immediately\n+      // ready to execute, as it will create data races.\n       auto deps = Dependencies(record_params, command_buffer, dependency_id);\n       dependencies.insert(dependencies.end(), deps.begin(), deps.end());\n     } else {\n@@ -650,13 +727,13 @@ absl::StatusOr<std::string> CommandBufferCmdExecutor::RenderExecutionGraph() {\n     return Unimplemented(\"No execution graph renderer registered\");\n   }\n \n-  if (synchronization_mode_ != SynchronizationMode::kConcurrent) {\n+  if (synchronization_mode_ == SynchronizationMode::kSerialize) {\n     return Unimplemented(\n         \"Execution graph rendering is only supported for \"\n-        \"concurrent synchronization mode\");\n+        \"concurrent/LHS synchronization mode\");\n   }\n \n-  auto operations = CreateCommandOperations(commands_);\n+  auto operations = CreateCommandOperations(commands_, synchronization_mode_);\n   absl::InlinedVector<const ExecutionGraph::Operation*, 32> operations_ptrs;\n   operations_ptrs.reserve(operations.size());\n   for (const auto& operation : operations) {\n@@ -737,9 +814,9 @@ absl::StatusOr<se::CommandBuffer*> TracedCommandBuffer::GetOrTraceCommandBuffer(\n     }\n   }\n \n-  // Create a new entry by calling a user-provided tracing function, replace the\n-  // last entry with it, move it to front and return a pointer to cached command\n-  // buffer.\n+  // Create a new entry by calling a user-provided tracing function, replace\n+  // the last entry with it, move it to front and return a pointer to cached\n+  // command buffer.\n   TF_ASSIGN_OR_RETURN(\n       entries_[capacity_ - 1].command_buffer,\n       se::TraceCommandBufferFactory::Create(executor, stream, trace));"
        },
        {
            "sha": "360802e02a27a3d22b85f64f05caac78aa9e37bc",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_thunk_test.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -120,7 +120,11 @@ bool IsAtLeastCuda12300(const se::StreamExecutor* stream_executor) {\n   const auto* cuda_cc = std::get_if<se::CudaComputeCapability>(\n       &device_description.gpu_compute_capability());\n   if (cuda_cc != nullptr) {\n-    if (device_description.driver_version() >=\n+    // We need a recent driver to support the feature at runtime and we need a\n+    // recent version of the toolkit at compile time, so that we have access to\n+    // the driver's headers.\n+    if (std::min(device_description.driver_version(),\n+                 device_description.compile_time_toolkit_version()) >=\n         stream_executor::SemanticVersion(12, 3, 0)) {\n       return true;\n     }\n@@ -134,7 +138,11 @@ bool IsAtLeastCuda12900(const se::StreamExecutor* stream_executor) {\n   const auto* cuda_cc = std::get_if<se::CudaComputeCapability>(\n       &device_description.gpu_compute_capability());\n   if (cuda_cc != nullptr) {\n-    if (device_description.driver_version() >=\n+    // We need a recent driver to support the feature at runtime and we need a\n+    // recent version of the toolkit at compile time, so that we have access to\n+    // the driver's headers.\n+    if (std::min(device_description.driver_version(),\n+                 device_description.compile_time_toolkit_version()) >=\n         stream_executor::SemanticVersion(12, 9, 0)) {\n       return true;\n     }"
        },
        {
            "sha": "11af99c8f8958ce171c9186d9289c3e412b37257",
            "filename": "third_party/xla/xla/backends/gpu/runtime/cudnn_thunk.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcudnn_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcudnn_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcudnn_thunk.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -52,8 +52,13 @@ CuDnnThunk::CuDnnThunk(std::string fingerprint, ThunkInfo thunk_info,\n \n absl::Status CuDnnThunk::Initialize(const InitializeParams& params) {\n   absl::Status ret = absl::OkStatus();\n+  // Calling AsDnn outside call_once ensures that cuDNN handles get created for\n+  // all GPUs in programs using cuDNN during the executable initialization\n+  // phase. It's sufficient to deserialize the graph once using just one of\n+  // them.\n+  se::dnn::DnnSupport* dnn = params.stream->parent()->AsDnn();\n   absl::call_once(once_flag_, [&] {\n-    auto result = params.stream->parent()->AsDnn()->DeserializeGraph(\n+    auto result = dnn->DeserializeGraph(\n         *params.stream, params.src.dnn_compiled_graphs.at(fingerprint_));\n     std::string().swap(fingerprint_);\n     if (result.ok()) {"
        },
        {
            "sha": "13920c71beef38d9a18ebc82ac4c8267ed515188",
            "filename": "third_party/xla/xla/backends/gpu/runtime/raft_vectorized_bf16.h",
            "status": "added",
            "additions": 56,
            "deletions": 0,
            "changes": 56,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fraft_vectorized_bf16.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fraft_vectorized_bf16.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fraft_vectorized_bf16.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,56 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_RAFT_VECTORIZED_BF16_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_RAFT_VECTORIZED_BF16_H_\n+\n+#pragma once\n+#include \"third_party/gpus/cuda/include/cuda_bf16.h\"\n+#include \"raft/util/vectorized.cuh\"\n+\n+namespace raft {\n+\n+template <>\n+struct IOType<__nv_bfloat16, 1> {\n+  typedef __nv_bfloat16 Type;\n+};\n+template <>\n+struct IOType<__nv_bfloat16, 2> {\n+  typedef __nv_bfloat162 Type;\n+};\n+template <>\n+struct IOType<__nv_bfloat16, 4> {\n+  typedef uint2 Type;\n+};\n+template <>\n+struct IOType<__nv_bfloat16, 8> {\n+  typedef uint4 Type;\n+};\n+template <>\n+struct IOType<__nv_bfloat162, 1> {\n+  typedef __nv_bfloat162 Type;\n+};\n+template <>\n+struct IOType<__nv_bfloat162, 2> {\n+  typedef uint2 Type;\n+};\n+template <>\n+struct IOType<__nv_bfloat162, 4> {\n+  typedef uint4 Type;\n+};\n+\n+}  // namespace raft\n+\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_RAFT_VECTORIZED_BF16_H_"
        },
        {
            "sha": "931b3f52a0a5b1b2cb7b931377aa34932df57cd7",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_exec.h",
            "status": "added",
            "additions": 55,
            "deletions": 0,
            "changes": 55,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,55 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_SELECT_K_EXEC_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_SELECT_K_EXEC_H_\n+\n+#include <cstdint>\n+\n+#include \"absl/status/status.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/stream.h\"\n+\n+namespace xla::gpu {\n+\n+// Launches a Top-K selection on GPU for a batch of matrices.\n+//\n+// Args:\n+//   device_ordinal: GPU device index to run the operation on.\n+//   allocator: StreamExecutor memory allocator for device buffers.\n+//   stream: StreamExecutor stream for the GPU operations.\n+//   data_in: Device memory containing input matrices (batch  n).\n+//   data_out: Device memory to store top-k values (batch  k).\n+//   indices_out: Device memory to store top-k indices (batch  k).\n+//   batch: Number of rows (matrices) in the batch.\n+//   n: Number of columns (elements per row) in input matrices.\n+//   k: Number of top elements to select per row.\n+//\n+// Returns:\n+//   absl::Status indicating success or failure of the operation.\n+template <typename T>\n+absl::Status select_k_exec(int device_ordinal,\n+                           ::stream_executor::DeviceMemoryAllocator* allocator,\n+                           ::stream_executor::Stream* stream,\n+                           ::stream_executor::DeviceMemoryBase data_in,\n+                           ::stream_executor::DeviceMemoryBase data_out,\n+                           ::stream_executor::DeviceMemoryBase indices_out,\n+                           std::uint32_t batch, std::uint32_t n,\n+                           std::uint32_t k);\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_SELECT_K_EXEC_H_"
        },
        {
            "sha": "3b1abda8626dc4ff215217ff75cd3265868cd16b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_exec_raft.cc",
            "status": "added",
            "additions": 333,
            "deletions": 0,
            "changes": 333,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,333 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <exception>\n+#include <memory>\n+#include <optional>\n+#include <string>\n+#include <utility>\n+\n+#include \"absl/base/optimization.h\"\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"third_party/gpus/cuda/include/cuda_bf16.h\"\n+#include \"raft/core/device_mdspan.hpp\"\n+#include \"raft/core/mdspan_types.hpp\"\n+#include \"raft/core/resource/cuda_stream.hpp\"\n+#include \"raft/core/resource/device_memory_resource.hpp\"\n+#include \"raft/core/resources.hpp\"\n+#include \"raft/matrix/select_k.cuh\"\n+#include \"raft/matrix/select_k_types.hpp\"\n+#include \"xla/backends/gpu/runtime/select_k_exec.h\"\n+// NOTE: This include is required for vectorized BF16 GPU runtime support.\n+// It will no longer be needed after upgrading to raft v25.10.00.\n+#include \"xla/backends/gpu/runtime/raft_vectorized_bf16.h\"\n+#include \"xla/status_macros.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/scratch_allocator.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/types.h\"\n+\n+namespace xla::gpu {\n+namespace se = ::stream_executor;\n+using raft::matrix::SelectAlgo;\n+\n+namespace {\n+\n+// Simple RAII wrapper to manage temporary device memory allocations\n+class OwningScratchAllocator {\n+ public:\n+  OwningScratchAllocator(int device_ordinal,\n+                         se::DeviceMemoryAllocator* allocator)\n+      : device_ordinal_(device_ordinal), allocator_(allocator) {}\n+\n+  OwningScratchAllocator(OwningScratchAllocator&&) = default;\n+  OwningScratchAllocator& operator=(OwningScratchAllocator&&) = default;\n+\n+  // Allocate memory and track ownership\n+  absl::StatusOr<se::DeviceMemory<uint8_t>> AllocateBytes(int64_t byte_size) {\n+    TF_ASSIGN_OR_RETURN(se::OwningDeviceMemory buffer,\n+                        allocator_->Allocate(device_ordinal_, byte_size,\n+                                             /*retry_on_failure=*/false));\n+\n+    se::DeviceMemory<uint8_t> res = *buffer;\n+    void* raw_ptr = res.opaque();\n+    buffers_.emplace(raw_ptr, std::move(buffer));\n+    return res;\n+  }\n+\n+  // Deallocate tracked memory; safe no-op if pointer not found\n+  absl::Status DeallocateBytes(void* ptr) {\n+    auto it = buffers_.find(ptr);\n+    if (it != buffers_.end()) {\n+      buffers_.erase(it);  // RAII frees memory\n+      return absl::OkStatus();\n+    }\n+    return absl::NotFoundError(\"Pointer not found\");\n+  }\n+\n+ private:\n+  int device_ordinal_;\n+  se::DeviceMemoryAllocator* allocator_;\n+  // key = raw device pointer, value = owning memory object\n+  absl::flat_hash_map<void*, se::OwningDeviceMemory> buffers_;\n+};\n+\n+// Custom RMM memory resource backed by StreamExecutor allocator\n+class XlaDeviceMemoryResource : public rmm::mr::device_memory_resource {\n+ public:\n+  XlaDeviceMemoryResource(int device_ordinal,\n+                          se::DeviceMemoryAllocator* allocator)\n+      : scratch_allocator_(device_ordinal, allocator) {}\n+\n+ protected:\n+  void* do_allocate(std::size_t bytes, rmm::cuda_stream_view stream) override {\n+    auto mem = scratch_allocator_.AllocateBytes(bytes);\n+    if (!mem.ok()) {\n+      // RMM expects exceptions\n+      throw rmm::bad_alloc(std::string(mem.status().ToString()));\n+    }\n+    return mem->opaque();\n+  }\n+\n+  void do_deallocate(void* ptr, std::size_t bytes,\n+                     rmm::cuda_stream_view stream) override {\n+    auto status = scratch_allocator_.DeallocateBytes(ptr);\n+    if (!status.ok()) {\n+      // do_deallocate should be noexcept. Dont throw; just log.\n+      LOG(ERROR) << \"Scratch Deallocation failed: \" << status;\n+    }\n+  }\n+\n+ private:\n+  OwningScratchAllocator scratch_allocator_;\n+};\n+\n+// RAII wrapper for RAFT resources bound to a CUDA stream\n+struct RaftStreamResource : public se::Stream::Resource {\n+  raft::resources res;\n+\n+  // Factory to create a RaftStreamResource tied to a CUDA stream.\n+  // Sets up `raft::resources` with a custom XlaDeviceMemoryResource\n+  // using the given allocator and binds it to the provided stream.\n+  //\n+  // Args:\n+  //   device_ordinal: Device index.\n+  //   allocator: StreamExecutor memory allocator.\n+  //   cuda_stream: CUDA stream to bind.\n+  // Returns:\n+  //   Unique pointer to an initialized RaftStreamResource.\n+  static std::unique_ptr<RaftStreamResource> Create(\n+      int device_ordinal, se::DeviceMemoryAllocator* allocator,\n+      cudaStream_t cuda_stream) {\n+    // Assign our custom AllocatorForRaft for this device\n+    auto handle = std::make_unique<RaftStreamResource>();\n+    raft::resource::set_workspace_resource(\n+        handle->res,\n+        std::make_shared<XlaDeviceMemoryResource>(device_ordinal, allocator));\n+    // Set Cuda Stream\n+    raft::resource::set_cuda_stream(handle->res,\n+                                    rmm::cuda_stream_view{cuda_stream});\n+    return handle;\n+  }\n+};\n+\n+// ============================================================================\n+// choose_select_k_algorithm\n+//\n+// Purpose:\n+//   Heuristic-based selection of the optimal \"select k\" algorithm depending on\n+//   problem shape (rows, cols, k). The decision is based on benchmark data.\n+//\n+// How the heuristic is generated:\n+//\n+//   1. Build the benchmark module:\n+//        raft/cpp/bench/prims/matrix\n+//\n+//   2. Collect performance data by running microbenchmarks:\n+//\n+//        From the RAFT project root:\n+//          ./cpp/build/bench/prims/MATRIX_BENCH \\\n+//            --benchmark_filter=Select \\\n+//            --benchmark_out_format=json \\\n+//            --benchmark_out=select_k_times.json\n+//\n+//        Output:\n+//          - Benchmark results are written to `select_k_times.json`\n+//\n+//   3. Generate the heuristic using the provided notebook:\n+//\n+//        ./cpp/scripts/heuristics/select_k/generate_heuristic.ipynb\n+//\n+//        The notebook consumes `select_k_times.json`, analyzes performance\n+//        trade-offs, and produces the decision tree implemented here.\n+//\n+// Notes:\n+//   - To generate performance data for BFloat16,\n+//     modify cpp/bench/prims/matrix/select_k.cu  and register nv_bfloat16 type\n+//     using SELECTION_REGISTER mactos.\n+// ============================================================================\n+\n+template <typename T>\n+SelectAlgo choose_select_k_algorithm(uint32_t rows, uint32_t cols, uint32_t k) {\n+  static_assert(sizeof(T) == 0,\n+                \"choose_select_k_algorithm<T>: Unsupported type\");\n+  ABSL_UNREACHABLE();\n+}\n+\n+template <>\n+SelectAlgo choose_select_k_algorithm<float>(uint32_t rows, uint32_t cols,\n+                                            uint32_t k) {\n+  if (k > 256) {\n+    return SelectAlgo::kRadix11bits;\n+  } else if (k > 3) {\n+    if (cols > 55000) {\n+      return SelectAlgo::kWarpDistributedShm;\n+    } else {\n+      if (cols > 5250) {\n+        if (k > 192) {\n+          return SelectAlgo::kRadix11bits;\n+        } else {\n+          return SelectAlgo::kWarpDistributedShm;\n+        }\n+      } else {\n+        return SelectAlgo::kWarpDistributedShm;\n+      }\n+    }\n+  } else {\n+    return SelectAlgo::kWarpImmediate;\n+  }\n+}\n+\n+template <>\n+SelectAlgo choose_select_k_algorithm<nv_bfloat16>(uint32_t rows, uint32_t cols,\n+                                                  uint32_t k) {\n+  if (k > 256) {\n+    return SelectAlgo::kRadix11bits;\n+  } else if (k > 3) {\n+    if (cols > 5250 && k > 192) {\n+      return SelectAlgo::kRadix11bits;\n+    } else {\n+      return SelectAlgo::kWarpDistributedShm;\n+    }\n+  } else {\n+    return SelectAlgo::kWarpImmediate;\n+  }\n+}\n+\n+}  // namespace\n+\n+// Host-side entry point for raft select_k\n+template <typename T>\n+absl::Status select_k_exec(int device_ordinal,\n+                           se::DeviceMemoryAllocator* allocator,\n+                           se::Stream* stream, se::DeviceMemoryBase data_in,\n+                           se::DeviceMemoryBase data_out,\n+                           se::DeviceMemoryBase indices_out,\n+                           std::uint32_t batch, std::uint32_t n,\n+                           std::uint32_t k) {\n+  // Pick the most suitable algorithm\n+  SelectAlgo algo = choose_select_k_algorithm<T>(batch, n, k);\n+  VLOG(3) << \"select_k_exec_raft: \"\n+          << \"device_ordinal: \" << device_ordinal << \", \"\n+          << \"data_in: \" << data_in.opaque() << \" (\" << data_in.size() << \"B)\"\n+          << \", data_out: \" << data_out.opaque() << \" (\" << data_out.size()\n+          << \"B)\"\n+          << \", indices_out: \" << indices_out.opaque() << \" (\"\n+          << indices_out.size() << \"B)\"\n+          << \", batch: \" << batch << \", n: \" << n << \", k: \" << k\n+          << \", algo: \" << algo;\n+\n+  // Retrieve or create RAFT resource for this stream\n+  cudaStream_t cuda_stream =\n+      reinterpret_cast<cudaStream_t>(stream->platform_specific_handle().stream);\n+  TF_RET_CHECK(cuda_stream != nullptr)\n+      << \"Failed to cast se::Stream to cudaStream_t.\";\n+  RaftStreamResource* resContainer =\n+      stream->GetOrCreateResource<RaftStreamResource>(\n+          [device_ordinal, allocator, cuda_stream] {\n+            return RaftStreamResource::Create(device_ordinal, allocator,\n+                                              cuda_stream);\n+          });\n+  TF_RET_CHECK(resContainer != nullptr)\n+      << \"Failed to create or retrieve RaftStreamResource\";\n+\n+  try {\n+    // Wrap raw device pointers in RAFT matrix views\n+    auto input_view =\n+        raft::make_device_matrix_view<const T, uint32_t, raft::row_major>(\n+            reinterpret_cast<const T*>(data_in.opaque()), batch, n);\n+\n+    auto output_values_view =\n+        raft::make_device_matrix_view<T, uint32_t, raft::row_major>(\n+            reinterpret_cast<T*>(data_out.opaque()), batch, k);\n+\n+    auto output_indices_view =\n+        raft::make_device_matrix_view<uint32_t, uint32_t, raft::row_major>(\n+            reinterpret_cast<uint32_t*>(indices_out.opaque()), batch, k);\n+\n+    // Call RAFT select_k kernel\n+    raft::matrix::select_k<T, uint32_t>(\n+        resContainer->res, input_view,\n+        std::nullopt,  // d_input_indices can be omitted\n+        output_values_view, output_indices_view,\n+        /*select_min=*/false,\n+        /*sorted=*/true,\n+        /*algo=*/algo);\n+\n+    return absl::OkStatus();\n+  } catch (const std::exception& e) {\n+    return absl::InternalError(absl::StrCat(\"select_k failed: \", e.what()));\n+  } catch (...) {\n+    return absl::InternalError(\"select_k failed with unknown exception\");\n+  }\n+}\n+\n+// Explicit instantiations for supported types\n+template absl::Status select_k_exec<float>(int, se::DeviceMemoryAllocator*,\n+                                           se::Stream*, se::DeviceMemoryBase,\n+                                           se::DeviceMemoryBase,\n+                                           se::DeviceMemoryBase, std::uint32_t,\n+                                           std::uint32_t, std::uint32_t);\n+\n+template absl::Status select_k_exec<nv_bfloat16>(\n+    int, se::DeviceMemoryAllocator*, se::Stream*, se::DeviceMemoryBase,\n+    se::DeviceMemoryBase, se::DeviceMemoryBase, std::uint32_t, std::uint32_t,\n+    std::uint32_t);\n+\n+// Explicit specializations for xla::bfloat16\n+template <>\n+absl::Status select_k_exec<::xla::bfloat16>(\n+    int device_ordinal, se::DeviceMemoryAllocator* allocator,\n+    se::Stream* stream, se::DeviceMemoryBase data_in,\n+    se::DeviceMemoryBase data_out, se::DeviceMemoryBase indices_out,\n+    std::uint32_t batch, std::uint32_t n, std::uint32_t k) {\n+  // Sanity check: Eigen::bfloat16 and nv_bfloat16 must be binary-compatible\n+  static_assert(sizeof(::xla::bfloat16) == sizeof(nv_bfloat16),\n+                \"xla::bfloat16 and nv_bfloat16 must have the same size\");\n+\n+  // Just forward to the nv_bfloat16 instantiation\n+  return select_k_exec<nv_bfloat16>(device_ordinal, allocator, stream, data_in,\n+                                    data_out, indices_out, batch, n, k);\n+}\n+\n+}  // namespace xla::gpu"
        },
        {
            "sha": "940acd1c9805a0558709094b7a6bd0d5d7131f76",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_exec_raft_test.cc",
            "status": "added",
            "additions": 156,
            "deletions": 0,
            "changes": 156,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,156 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <cstring>\n+#include <functional>\n+#include <memory>\n+#include <vector>\n+\n+#include <gtest/gtest.h>\n+#include \"absl/base/casts.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/random/random.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/ascii.h\"\n+#include \"absl/types/span.h\"\n+#include \"xla/backends/gpu/runtime/select_k_exec.h\"\n+#include \"xla/service/platform_util.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/platform.h\"\n+#include \"xla/stream_executor/platform_manager.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n+#include \"xla/tsl/lib/core/status_test_util.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/types.h\"\n+#include \"xla/xla.pb.h\"\n+#include \"xla/xla_data.pb.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+// Returns the first GPU StreamExecutor\n+se::StreamExecutor* GpuExecutor() {\n+  auto name =\n+      absl::AsciiStrToUpper(PlatformUtil::CanonicalPlatformName(\"gpu\").value());\n+  auto* platform = se::PlatformManager::PlatformWithName(name).value();\n+  CHECK(platform != nullptr);\n+  CHECK_OK(platform->ExecutorForDevice(0));\n+  return platform->ExecutorForDevice(0).value();\n+}\n+\n+// Trait: map Data type to Mask type and a default kStartBits\n+template <typename T>\n+struct MaskFor;\n+\n+template <>\n+struct MaskFor<float> {\n+  using type = uint32_t;\n+  static constexpr type kStartBits = 0x3C000000;  // float32: 1/128\n+};\n+\n+template <>\n+struct MaskFor<::xla::bfloat16> {\n+  using type = uint16_t;\n+  static constexpr type kStartBits = 0x3C00;  // bfloat16: 1/128\n+};\n+\n+// Fills vector with unique values using bit patterns starting from kStartBits\n+template <typename T>\n+void append_unique_numbers(size_t count, std::vector<T>& arr) {\n+  using Traits = MaskFor<T>;\n+  using MaskT = typename Traits::type;\n+  MaskT bits = Traits::kStartBits;\n+\n+  for (size_t i = 0; i < count; ++i, ++bits) {\n+    T val = absl::bit_cast<T>(bits);\n+    arr.push_back(val);\n+  }\n+}\n+\n+}  // namespace\n+\n+// Template test function for raft select_k\n+template <typename T>\n+void RunSelectKTest() {\n+  se::StreamExecutor* stream_executor = GpuExecutor();\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_executor->CreateStream());\n+  int device_ordinal = stream_executor->device_ordinal();\n+  se::StreamExecutorMemoryAllocator allocator(stream_executor);\n+\n+  std::uint32_t batch = 4;\n+  std::uint32_t n = 4096;\n+  std::uint32_t k = 32;\n+  absl::BitGen gen;\n+\n+  // Prepare unique values for Top-K testing\n+  std::vector<T> topk;\n+  topk.reserve(n);\n+  append_unique_numbers<T>(n, topk);\n+\n+  // Populate input matrix (batch x n) with shuffled topk values\n+  std::vector<T> h_data_in(batch * n);\n+  for (int j = 0; j < batch; ++j) {\n+    std::shuffle(topk.begin(), topk.end(), gen);\n+    std::copy(topk.begin(), topk.end(), h_data_in.begin() + j * n);\n+  }\n+\n+  // Compute golden Top-K values for verification\n+  std::sort(topk.begin(), topk.end(), std::greater<T>());\n+  topk.resize(k);\n+\n+  // Allocate device memory for input and outputs\n+  se::DeviceMemory<T> d_data_in =\n+      stream_executor->AllocateArray<T>(batch * n, 0);\n+  se::DeviceMemory<T> d_data_out =\n+      stream_executor->AllocateArray<T>(batch * k, 0);\n+  se::DeviceMemory<uint32_t> d_indices_out =\n+      stream_executor->AllocateArray<uint32_t>(batch * k, 0);\n+\n+  // Copy host to device\n+  TF_ASSERT_OK(stream->MemcpyH2D(absl::Span<const T>(h_data_in), &d_data_in));\n+\n+  // Run raft select_k\n+  TF_ASSERT_OK(select_k_exec<T>(device_ordinal, &allocator, stream.get(),\n+                                d_data_in, d_data_out, d_indices_out, batch, n,\n+                                k));\n+\n+  // Copy results back to host\n+  std::vector<T> h_data_out(batch * k);\n+  std::vector<uint32_t> h_indices_out(batch * k);\n+  TF_ASSERT_OK(stream->MemcpyD2H(d_data_out, absl::Span<T>(h_data_out)));\n+  TF_ASSERT_OK(\n+      stream->MemcpyD2H(d_indices_out, absl::Span<uint32_t>(h_indices_out)));\n+  TF_ASSERT_OK(stream->BlockHostUntilDone());\n+\n+  // Verify Top-K values and corresponding indices\n+  for (int j = 0; j < batch; ++j) {\n+    for (int i = 0; i < k; ++i) {\n+      EXPECT_EQ(h_data_out[j * k + i], topk[i]) << \"batch=\" << j << \" i=\" << i;\n+      auto idx = h_indices_out[j * k + i];\n+      EXPECT_EQ(h_data_in[j * n + idx], topk[i]) << \"batch=\" << j << \" i=\" << i;\n+    }\n+  }\n+}\n+\n+TEST(RaftSelectKExecTest, SelectKFloat) { RunSelectKTest<float>(); }\n+\n+TEST(RaftSelectKExecTest, SelectKBFloat16) {\n+  RunSelectKTest<::xla::bfloat16>();\n+}\n+\n+}  // namespace xla::gpu"
        },
        {
            "sha": "6094f3a0215210c5c3831731d18dbb4cae6b736c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_exec_stub.cc",
            "status": "added",
            "additions": 52,
            "deletions": 0,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_stub.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_stub.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_stub.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,52 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdint>\n+\n+#include \"absl/status/status.h\"\n+#include \"xla/backends/gpu/runtime/select_k_exec.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/types.h\"\n+\n+namespace xla::gpu {\n+namespace se = ::stream_executor;\n+\n+template <typename T>\n+absl::Status select_k_exec(int device_ordinal,\n+                           se::DeviceMemoryAllocator* allocator,\n+                           se::Stream* stream, se::DeviceMemoryBase data_in,\n+                           se::DeviceMemoryBase data_out,\n+                           se::DeviceMemoryBase indices_out,\n+                           std::uint32_t batch, std::uint32_t n,\n+                           std::uint32_t k) {\n+  return absl::UnimplementedError(\n+      \"select_k_exec is not implemented on this platform\");\n+}\n+\n+// Explicit instantiations for supported dtypes.\n+template absl::Status select_k_exec<float>(int, se::DeviceMemoryAllocator*,\n+                                           se::Stream*, se::DeviceMemoryBase,\n+                                           se::DeviceMemoryBase,\n+                                           se::DeviceMemoryBase, std::uint32_t,\n+                                           std::uint32_t, std::uint32_t);\n+\n+template absl::Status select_k_exec<::xla::bfloat16>(\n+    int, se::DeviceMemoryAllocator*, se::Stream*, se::DeviceMemoryBase,\n+    se::DeviceMemoryBase, se::DeviceMemoryBase, std::uint32_t, std::uint32_t,\n+    std::uint32_t);\n+\n+}  // namespace xla::gpu"
        },
        {
            "sha": "055ecc4baf88d5a1c3cf454e49f214be03b66f7c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_thunk.cc",
            "status": "added",
            "additions": 102,
            "deletions": 0,
            "changes": 102,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,102 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/select_k_thunk.h\"\n+\n+#include <cstdint>\n+#include <string>\n+\n+#include \"absl/container/inlined_vector.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"xla/backends/gpu/runtime/select_k_exec.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/codegen/emitters/kernel_arguments.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/primitive_util.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/types.h\"\n+\n+namespace xla::gpu {\n+\n+//===----------------------------------------------------------------------===//\n+// SelectKThunk\n+//===----------------------------------------------------------------------===//\n+\n+SelectKThunk::SelectKThunk(const HloInstruction* inst, std::uint32_t batch_size,\n+                           std::uint32_t num_elements, std::uint32_t k,\n+                           xla::PrimitiveType dtype,\n+                           const emitters::KernelArguments& kernel_arguments)\n+    : Thunk(Kind::kSelectK, Thunk::ThunkInfo::WithProfileAnnotation(inst)),\n+      batch_size_(batch_size),\n+      num_elements_(num_elements),\n+      k_(k),\n+      dtype_(dtype),\n+      args_(kernel_arguments.GetArgumentBufferSlices()) {\n+  CHECK_EQ(args_.size(), 3)\n+      << \"SelectKThunk expects exactly 3 buffer arguments \"\n+         \"(input_data, output_data, output_indices)\";\n+}\n+\n+std::string SelectKThunk::ToString(int indent) const {\n+  const std::string indent_str(indent * 2, ' ');\n+  return absl::StrCat(indent_str, \"SelectKThunk(batch_size=\", batch_size_,\n+                      \", num_elements=\", num_elements_, \", k=\", k_,\n+                      \", dtype=\", dtype_, \")\");\n+}\n+\n+// Execute the TopK operation on the GPU stream.\n+// Maps kernel arguments to device memory and dispatches the appropriate\n+// select_k_exec implementation based on the platform and data type.\n+absl::Status SelectKThunk::ExecuteOnStream(const ExecuteParams& params) {\n+  VLOG(3) << \"Launching \" << ToString(0);\n+\n+  // Map buffer slices to device memory.\n+  absl::InlinedVector<se::DeviceMemoryBase, 3> buffer_args;\n+  for (const BufferAllocation::Slice& arg : args_) {\n+    se::DeviceMemoryBase buf = params.buffer_allocations->GetDeviceAddress(arg);\n+    VLOG(3) << \"  Arg: alloc #\" << arg.index() << \", offset: \" << arg.offset()\n+            << \": \" << buf.opaque() << \" (\" << buf.size() << \"B)\";\n+    buffer_args.push_back(buf);\n+  }\n+\n+  int device_ordinal = params.buffer_allocations->device_ordinal();\n+  se::DeviceMemoryAllocator* allocator =\n+      params.buffer_allocations->memory_allocator();\n+  se::Stream* stream = params.stream;\n+\n+  // Dispatch to the correct typed implementation based on dtype.\n+  switch (dtype_) {\n+    case PrimitiveType::F32:\n+      return select_k_exec<float>(\n+          device_ordinal, allocator, stream, buffer_args[0], buffer_args[1],\n+          buffer_args[2], batch_size_, num_elements_, k_);\n+    case PrimitiveType::BF16:\n+      return select_k_exec<::xla::bfloat16>(\n+          device_ordinal, allocator, stream, buffer_args[0], buffer_args[1],\n+          buffer_args[2], batch_size_, num_elements_, k_);\n+    default:\n+      return absl::UnimplementedError(\n+          absl::StrCat(\"SelectKThunk: Unsupported dtype: \",\n+                       primitive_util::LowercasePrimitiveTypeName(dtype_)));\n+  }\n+}\n+}  // namespace xla::gpu"
        },
        {
            "sha": "f4164a80e566eeb4c2a61150104b01faabc84fcc",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_thunk.h",
            "status": "added",
            "additions": 76,
            "deletions": 0,
            "changes": 76,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,76 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_SELECT_K_THUNK_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_SELECT_K_THUNK_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <string>\n+#include <vector>\n+\n+#include \"absl/status/status.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/codegen/emitters/kernel_arguments.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/types.h\"  // IWYU pragma: keep\n+\n+namespace xla::gpu {\n+\n+//===----------------------------------------------------------------------===//\n+// SelectKThunk\n+//===----------------------------------------------------------------------===//\n+\n+// SelectKThunk executes the select_k operation on the provided inputs\n+class SelectKThunk : public Thunk {\n+ public:\n+  // Constructor.\n+  // Parameters:\n+  //   inst             - The HLO instruction that generated this thunk.\n+  //   batch_size       - Number of batches in the input tensor.\n+  //   num_elements     - Number of elements in each batch.\n+  //   k                - Number of top elements to select.\n+  //   dtype            - Data type of elements (e.g., F32, BF16).\n+  //   kernel_arguments - Kernel arguments holding buffer slices for\n+  //                      inputs/outputs.\n+  SelectKThunk(const HloInstruction* inst, std::uint32_t batch_size,\n+               std::uint32_t num_elements, std::uint32_t k,\n+               xla::PrimitiveType dtype,\n+               const emitters::KernelArguments& kernel_arguments);\n+\n+  std::string ToString(int indent) const override;\n+\n+  // Executes the TopK operation on the given stream.\n+  absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n+\n+  const std::vector<BufferAllocation::Slice>& arguments() const {\n+    return args_;\n+  }\n+\n+ private:\n+  std::uint32_t batch_size_;\n+  std::uint32_t num_elements_;\n+  std::uint32_t k_;\n+  xla::PrimitiveType dtype_;\n+\n+  // Buffer slices passed to the kernel as arguments.\n+  std::vector<BufferAllocation::Slice> args_;\n+};\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_SELECT_K_THUNK_H_"
        },
        {
            "sha": "b0dcda96cc07f65b257afd0a1102ca32ee05e61e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -309,6 +309,7 @@ Thunk::ExecuteParams::ExecuteParams(\n     CASE(kReduceScatterDone);\n     CASE(kReduceScatterStart);\n     CASE(kReplicaId);\n+    CASE(kSelectK);\n     CASE(kSend);\n     CASE(kSendDone);\n     CASE(kSequential);"
        },
        {
            "sha": "aff6cba8f1addf9a4d7ff1b4c2d47e2a1696a830",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -190,6 +190,7 @@ class Thunk {\n     kReduceScatterDone,\n     kReduceScatterStart,\n     kReplicaId,\n+    kSelectK,\n     kSend,\n     kSendDone,\n     kSequential,"
        },
        {
            "sha": "11f92d82804ae18cbf8b1e440ad3c80e64e7c32f",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/bitcast.hlo",
            "status": "added",
            "additions": 22,
            "deletions": 0,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fbitcast.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fbitcast.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fbitcast.hlo?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,22 @@\n+// RUN: gpu_test_correctness %s\n+// RUN: cpu_test_correctness %s\n+\n+fusion {\n+  in = f32[20,30] parameter(0)\n+  updates = f32[5,6] parameter(1)\n+  i0 = s32[] parameter(2)\n+  i1 = s32[] parameter(3)\n+  updated = f32[20,30] dynamic-update-slice(in, updates, i0, i1)\n+  ROOT bitcast = f32[600] bitcast(updated)\n+}\n+\n+ENTRY main {\n+  %param_0 = f32[20,30] parameter(0)\n+  %param_1 = f32[5,6] parameter(1)\n+  %param_2 = s32[] parameter(2)\n+  %param_3 = s32[] parameter(3)\n+  // On CPU the input/output alias, this is resulting in a double free so we\n+  // need to copy the input.\n+  %param_0_copy = f32[20,30] copy(%param_0)\n+  ROOT %fusion = f32[600] fusion(%param_0_copy, %param_1, %param_2, %param_3), kind=kLoop, calls=fusion\n+}"
        },
        {
            "sha": "f366cd9acd71078878967c3416f14dc3d365e2b5",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/int4.hlo",
            "status": "added",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fint4.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fint4.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fint4.hlo?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,24 @@\n+// RUN: gpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize \\\n+// RUN:   -xla-gpu-test-transform-loops | FileCheck %s\n+// RUN: gpu_test_correctness %s --bijection_inputs=dus:1\n+// RUN: cpu_test_correctness %s\n+\n+fusion {\n+  input = s4[100,9] parameter(0)\n+  slice = s4[100,6] parameter(1)\n+  c0 = s32[] constant(0)\n+  ROOT dus = s4[100,9] dynamic-update-slice(input, slice, c0, c0)\n+}\n+\n+ENTRY main {\n+  %param_0 = s4[100,9] parameter(0)\n+  %param_1 = s4[100,6] parameter(1)\n+  // On CPU the input/output alias, this is resulting in a double free so we\n+  // need to copy the input.\n+  %param_0_copy = s4[100,9] copy(%param_0)\n+  ROOT %fusion = s4[100,9] fusion(%param_0_copy, %param_1), kind=kLoop, calls=fusion\n+}\n+\n+// CHECK: vector.transfer_read\n+// CHECK: tensor.insert\n+// CHECK: tensor.insert"
        },
        {
            "sha": "bde51c5ba35193ab067079bb76c18ff76cb4d40c",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/mof.hlo",
            "status": "added",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fmof.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fmof.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fmof.hlo?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,30 @@\n+// RUN: gpu_test_correctness %s\n+// b/435101580: Add CPU test once DUS is migrated.\n+\n+fusion {\n+  p0 = f32[10,11,12] parameter(0)\n+  p1 = f32[1,11,12] parameter(1)\n+  p2 = f32[8,11,12] parameter(2)\n+  p3 = f32[1,11,12] parameter(3)\n+  p4 = s32[] parameter(4)\n+  c0 = s32[] constant(0)\n+  cmp = pred[] compare(p4, c0), direction=EQ\n+  broadcast = pred[1,11,12] broadcast(cmp), dimensions={}\n+  select = f32[1,11,12] select(broadcast, p1, p3)\n+  dus0 = f32[10,11,12] dynamic-update-slice(p0, select, c0, c0, c0)\n+  dus1 = f32[8,11,12] dynamic-update-slice(p2, select, c0, c0, c0)\n+  ROOT tuple = (f32[10,11,12], f32[8,11,12]) tuple(dus0, dus1)\n+}\n+\n+ENTRY main {\n+  %param_0 = f32[10,11,12] parameter(0)\n+  %param_1 = f32[1,11,12] parameter(1)\n+  %param_2 = f32[8,11,12] parameter(2)\n+  %param_3 = f32[1,11,12] parameter(3)\n+  %param_4 = s32[] parameter(4)\n+  // On CPU the input/output alias, this is resulting in a double free so we\n+  // need to copy the input.\n+  %param_0_copy = f32[10,11,12] copy(%param_0)\n+  %param_2_copy = f32[8,11,12] copy(%param_2)\n+  ROOT %fusion = (f32[10,11,12], f32[8,11,12]) fusion(%param_0_copy, %param_1, %param_2_copy, %param_3, %param_4), kind=kLoop, calls=fusion\n+}"
        },
        {
            "sha": "4f155ff9fbe498679aa9767ad69fa59193a095ca",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/operand_subgraph_two_roots.hlo",
            "status": "renamed",
            "additions": 14,
            "deletions": 1,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Foperand_subgraph_two_roots.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Foperand_subgraph_two_roots.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Foperand_subgraph_two_roots.hlo?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1,6 +1,7 @@\n-// RUN: fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n+// RUN: gpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n // RUN:   FileCheck %s\n // RUN: gpu_test_correctness %s\n+// RUN: cpu_test_correctness %s\n \n fusion {\n   param_0.8 = f32[512,512]{1,0} parameter(0)\n@@ -15,6 +16,18 @@ fusion {\n   ROOT dynamic-update-slice.5.1 = f32[512,512]{1,0} dynamic-update-slice(\n     param_0.8, param_1.10, param_2_plus_one, param_3_plus_one)\n }\n+\n+ENTRY main {\n+  %param_0 = f32[512,512]{1,0} parameter(0)\n+  %param_1 = f32[128,128]{1,0} parameter(1)\n+  %param_2 = s32[] parameter(2)\n+  %param_3 = s32[] parameter(3)\n+  // On CPU the input/output alias, this is resulting in a double free so we\n+  // need to copy the input.\n+  %param_0_copy = f32[512,512]{1,0} copy(%param_0)\n+  ROOT %fusion = f32[512,512]{1,0} fusion(%param_0_copy, %param_1, %param_2, %param_3), kind=kLoop, calls=fusion\n+}\n+\n // CHECK:     func.func @main(\n // CHECK-SAME:  %[[ARG0:[^:]+]]: tensor<512x512xf32>\n // CHECK-SAME:  , %[[ARG1:[^:]+]]: tensor<128x128xf32>",
            "previous_filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/dynamic_update_slice/operand_subgraph_two_roots.hlo"
        },
        {
            "sha": "46cc3b4f8e19e02e81c5b39c8fc1afb28b1604b3",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/out_of_bounds.hlo",
            "status": "renamed",
            "additions": 14,
            "deletions": 1,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fout_of_bounds.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fout_of_bounds.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fout_of_bounds.hlo?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1,6 +1,7 @@\n-// RUN: fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n+// RUN: gpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n // RUN:   FileCheck %s\n // RUN: gpu_test_correctness %s\n+// RUN: cpu_test_correctness %s\n \n fusion {\n   in = f32[7,8] parameter(0)\n@@ -9,6 +10,18 @@ fusion {\n   i1 = s32[] parameter(3)\n   ROOT updated = f32[7,8] dynamic-update-slice(in, updates, i0, i1)\n }\n+\n+ENTRY main {\n+  %param_0 = f32[7,8] parameter(0)\n+  %param_1 = f32[2,3] parameter(1)\n+  %param_2 = s32[] parameter(2)\n+  %param_3 = s32[] parameter(3)\n+  // On CPU the input/output alias, this is resulting in a double free so we\n+  // need to copy the input.\n+  %param_0_copy = f32[7,8] copy(%param_0)\n+  ROOT %fusion = f32[7,8] fusion(%param_0_copy, %param_1, %param_2, %param_3), kind=kLoop, calls=fusion\n+}\n+\n // CHECK:     func.func @main\n // CHECK-SAME:  %arg0: tensor<7x8xf32>\n // CHECK-SAME:  %arg1: tensor<2x3xf32>",
            "previous_filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/dynamic_update_slice/out_of_bounds.hlo"
        },
        {
            "sha": "c265d813f86b1de9136c769f7664d10114591836",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/simple.hlo",
            "status": "renamed",
            "additions": 14,
            "deletions": 1,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fsimple.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fsimple.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fsimple.hlo?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1,6 +1,7 @@\n-// RUN: fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n+// RUN: gpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize |\\\n // RUN:   FileCheck %s\n // RUN: gpu_test_correctness %s --bijection_inputs=updated:1\n+// RUN: cpu_test_correctness %s\n \n fusion {\n   in = f32[20,30] parameter(0)\n@@ -9,6 +10,18 @@ fusion {\n   i1 = s32[] parameter(3)\n   ROOT updated = f32[20,30] dynamic-update-slice(in, updates, i0, i1)\n }\n+\n+ENTRY main {\n+  %param_0 = f32[20,30] parameter(0)\n+  %param_1 = f32[5,6] parameter(1)\n+  %param_2 = s32[] parameter(2)\n+  %param_3 = s32[] parameter(3)\n+  // On CPU the input/output alias, this is resulting in a double free so we\n+  // need to copy the input.\n+  %param_0_copy = f32[20,30] copy(%param_0)\n+  ROOT %fusion = f32[20,30] fusion(%param_0_copy, %param_1, %param_2, %param_3), kind=kLoop, calls=fusion\n+}\n+\n // CHECK:     func.func @main\n // CHECK-SAME:  %arg0: tensor<20x30xf32>\n // CHECK-SAME:  %arg1: tensor<5x6xf32>",
            "previous_filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/dynamic_update_slice/simple.hlo"
        },
        {
            "sha": "8f9533cb3b281ca4163c796b7a1d351da537030f",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/vectorize_x1_too_small.hlo",
            "status": "added",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x1_too_small.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x1_too_small.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x1_too_small.hlo?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,25 @@\n+// RUN: gpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize \\\n+// RUN:   -xla-gpu-test-transform-loops | FileCheck %s\n+// RUN: gpu_test_correctness %s --bijection_inputs=dus:1\n+// RUN: cpu_test_correctness %s\n+\n+fusion {\n+  %input = f32[40,40,300] parameter(0)\n+  %update = f32[1,1,40] parameter(1)\n+  %idx = s32[] parameter(2)\n+  %zero = s32[] constant(0)\n+  ROOT dus = f32[40,40,300] dynamic-update-slice(%input, %update, %idx, %zero, %zero)\n+}\n+\n+ENTRY main {\n+  %param_0 = f32[40,40,300] parameter(0)\n+  %param_1 = f32[1,1,40] parameter(1)\n+  %param_2 = s32[] parameter(2)\n+  // On CPU the input/output alias, this is resulting in a double free so we\n+  // need to copy the input.\n+  %param_0_copy = f32[40,40,300] copy(%param_0)\n+  ROOT %fusion = f32[40,40,300] fusion(%param_0_copy, %param_1, %param_2), kind=kLoop, calls=fusion\n+}\n+\n+// CHECK-NOT: vector.transfer_read {{.*}} vector<4xf32>\n+// CHECK-NOT: vector.transfer_write {{.*}} vector<4xf32>"
        },
        {
            "sha": "86b7bbc03820f13285d9222f19e0c7e67dfbb7f0",
            "filename": "third_party/xla/xla/codegen/emitters/tests/dynamic_update_slice/vectorize_x4.hlo",
            "status": "added",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x4.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x4.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftests%2Fdynamic_update_slice%2Fvectorize_x4.hlo?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,25 @@\n+// RUN: gpu_fusion_to_mlir %s | emitters_opt -xla-test-optimize \\\n+// RUN:   -xla-gpu-test-transform-loops | FileCheck %s\n+// RUN: gpu_test_correctness %s --bijection_inputs=dus:1\n+// RUN: cpu_test_correctness %s\n+\n+fusion {\n+  %input = f32[40,40,300] parameter(0)\n+  %update = f32[20,40,300] parameter(1)\n+  %idx = s32[] parameter(2)\n+  %zero = s32[] constant(0)\n+  ROOT dus = f32[40,40,300] dynamic-update-slice(%input, %update, %idx, %zero, %zero)\n+}\n+\n+ENTRY main {\n+  %param_0 = f32[40,40,300] parameter(0)\n+  %param_1 = f32[20,40,300] parameter(1)\n+  %param_2 = s32[] parameter(2)\n+  // On CPU the input/output alias, this is resulting in a double free so we\n+  // need to copy the input.\n+  %param_0_copy = f32[40,40,300] copy(%param_0)\n+  ROOT %fusion = f32[40,40,300] fusion(%param_0_copy, %param_1, %param_2), kind=kLoop, calls=fusion\n+}\n+\n+// CHECK: vector.transfer_read {{.*}} vector<4xf32>\n+// CHECK: vector.transfer_write {{.*}} vector<4xf32>"
        },
        {
            "sha": "96ca56cc111d7c677f7461dbe12a1a96e242aa19",
            "filename": "third_party/xla/xla/codegen/intrinsic/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -393,8 +393,8 @@ xla_cc_test(\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/tsl/platform:test_benchmark\",\n         \"//xla/tsl/platform:test_main\",\n+        \"@com_google_absl//absl/strings\",\n         \"@llvm-project//llvm:Target\",\n-        \"@llvm-project//llvm:TargetParser\",\n         \"@llvm-project//llvm:ir_headers\",\n     ],\n )"
        },
        {
            "sha": "c8b1c19575a4fea13202b1c8aad6c4fba6d2d4f7",
            "filename": "third_party/xla/xla/codegen/intrinsic/intrinsic.h",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fintrinsic.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -99,9 +99,20 @@ class Type : public std::variant<Scalar, Vec> {\n   static Type FromName(absl::string_view name);\n };\n \n+enum class DeviceType {\n+  kAmdCpu,\n+  kIntelCpu,\n+  kArmCpu,\n+  kNvidiaGpu,\n+  kAmdGpu,\n+};\n+\n struct IntrinsicOptions {\n   // CPU features available on the target machine.\n   std::string features;\n+\n+  // The type of device the target machine is running on.\n+  DeviceType device_type;\n   // Disables math functions that do not have the same results across e.g.\n   // AMD vs. Intel CPUs.\n   bool disable_platform_dependent_math = false;"
        },
        {
            "sha": "25d1975dd261e86065accf76d8909c37540ea335",
            "filename": "third_party/xla/xla/codegen/intrinsic/rsqrt.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -200,13 +200,7 @@ absl::StatusOr<llvm::Function*> Rsqrt::CreateDefinition(\n       options.Contains(\"+avx512f\") &&\n       (type.element_type() == F64 ||\n        (type.element_type() == F32 && type.vector_width().value_or(1) > 8));\n-  // As a heuristic, we check for SSE4a to determine if we are on AMD.\n-  // This feature was added in 2007 and is set on all AMD CPUs since then, and\n-  // no intel cpus. This is a bit of a hack though, as there is no strict link\n-  // between increased precision and SSE4a; Intel could decide to add it in the\n-  // future but they are very unlikely to do so as they haven't in the past 18\n-  // years.\n-  const bool is_amd = options.Contains(\"+sse4a\");\n+  const bool is_amd = options.device_type == DeviceType::kAmdCpu;\n   const size_t num_steps = (is_amd && !using_avx512) ? 1 : 2;\n   llvm::Value* refined_result =\n       NewtonRaphsonRsqrtIteration(builder, x, y_approx, input_type, num_steps);"
        },
        {
            "sha": "c98b8d56264349083426632615e9de8308e381a5",
            "filename": "third_party/xla/xla/codegen/intrinsic/rsqrt_benchmark_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_benchmark_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_benchmark_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_benchmark_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -19,6 +19,7 @@ limitations under the License.\n #include <string>\n #include <utility>\n \n+#include \"absl/strings/match.h\"\n #include \"llvm/IR/BasicBlock.h\"\n #include \"llvm/IR/Constants.h\"\n #include \"llvm/IR/DerivedTypes.h\"\n@@ -41,6 +42,7 @@ limitations under the License.\n \n namespace xla::codegen::intrinsic {\n \n+using ::xla::codegen::intrinsics::DeviceType;\n using ::xla::codegen::intrinsics::Rsqrt;\n using ::xla::codegen::intrinsics::Type;\n \n@@ -65,10 +67,13 @@ JitRunner CreateJitRunnerWithRsqrt(Type type) {\n   auto module = std::make_unique<llvm::Module>(\"test_module\", *context);\n   std::unique_ptr<llvm::TargetMachine> target_machine =\n       xla::codegen::intrinsic::CreateHostTargetMachine();\n+  const auto features = target_machine->getTargetFeatureString().str();\n+  DeviceType device_type = absl::StrContains(features, \"+sse4a\")\n+                               ? DeviceType::kAmdCpu\n+                               : DeviceType::kIntelCpu;\n   llvm::Function* rsqrt_func =\n-      Rsqrt::CreateDefinition(\n-          module.get(), {target_machine->getTargetFeatureString().str(), false},\n-          type)\n+      Rsqrt::CreateDefinition(module.get(), {features, device_type, false},\n+                              type)\n           .value();\n   rsqrt_func->setLinkage(llvm::Function::ExternalLinkage);\n   CreateOneOverSqrt(*context, *module, Type::TypeToIrType(type, *context));"
        },
        {
            "sha": "3c7640a16ddf70a425252c6c1c0066f5e9cc44b5",
            "filename": "third_party/xla/xla/codegen/intrinsic/rsqrt_test.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 8,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Frsqrt_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -73,17 +73,25 @@ void AddOneOverSqrt(llvm::LLVMContext& context, llvm::Module& module,\n   builder.CreateRet(one_over_sqrt);\n }\n \n+llvm::StringMap<bool> GetHostCPUFeatures() {\n+  static const absl::NoDestructor<llvm::StringMap<bool>> features(\n+      llvm::sys::getHostCPUFeatures());\n+  return *features;\n+}\n+bool isAmd() { return GetHostCPUFeatures().lookup(\"sse4a\"); }\n JitRunner CreateJitRunnerWithRsqrt(\n     Type type, bool disable_platform_dependent_math = false) {\n   auto context = std::make_unique<llvm::LLVMContext>();\n   auto module = std::make_unique<llvm::Module>(\"test_module\", *context);\n \n   std::unique_ptr<llvm::TargetMachine> target_machine =\n       xla::codegen::intrinsic::CreateHostTargetMachine();\n+  DeviceType device_type =\n+      isAmd() ? DeviceType::kAmdCpu : DeviceType::kIntelCpu;\n   llvm::Function* rsqrt_func =\n       Rsqrt::CreateDefinition(module.get(),\n                               {target_machine->getTargetFeatureString().str(),\n-                               disable_platform_dependent_math},\n+                               device_type, disable_platform_dependent_math},\n                               type)\n           .value();\n   rsqrt_func->setLinkage(llvm::Function::ExternalLinkage);\n@@ -93,15 +101,8 @@ JitRunner CreateJitRunnerWithRsqrt(\n   return JitRunner(std::move(module), std::move(context));\n }\n \n-llvm::StringMap<bool> GetHostCPUFeatures() {\n-  static const absl::NoDestructor<llvm::StringMap<bool>> features(\n-      llvm::sys::getHostCPUFeatures());\n-  return *features;\n-}\n-\n bool hasAvx() { return GetHostCPUFeatures().lookup(\"avx\"); }\n bool hasAvx512Support() { return GetHostCPUFeatures().lookup(\"avx512f\"); }\n-bool isAmd() { return GetHostCPUFeatures().lookup(\"sse4a\"); }\n \n TEST(FeaturesTest, HostFeatures) {\n   std::cout << \"CPU: \" << llvm::sys::getHostCPUName().str() << \"\\n\";"
        },
        {
            "sha": "8fbb39fa06448d31a2739b202dfacc0e7fb41d8e",
            "filename": "third_party/xla/xla/codegen/intrinsic/tanh.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 9,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ftanh.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ftanh.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ftanh.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -31,19 +31,17 @@ namespace xla::codegen::intrinsics {\n \n namespace {\n \n-// Handles +/- infinity cases for tanh, returning +/- 1.0 respectively.\n-// For any other input, returns the given `result`.\n-llvm::Value* HandleInfinity(llvm::IRBuilderBase* b, llvm::Value* input,\n-                            llvm::Value* result) {\n+llvm::Value* HandleLargeInputs(llvm::IRBuilderBase* b, llvm::Value* input,\n+                               llvm::Value* result) {\n   llvm::Type* type = input->getType();\n   llvm::Value* abs_input =\n       llvm_ir::EmitCallToIntrinsic(llvm::Intrinsic::fabs, {input}, {type}, b);\n-  llvm::Value* is_inf_mask =\n-      b->CreateFCmpOEQ(abs_input, llvm::ConstantFP::getInfinity(type, false));\n+  llvm::Value* is_large_mask =\n+      b->CreateFCmpOGE(abs_input, llvm::ConstantFP::get(type, 20.0));\n   llvm::Value* one = llvm::ConstantFP::get(type, 1.0);\n   llvm::Value* inf_result = llvm_ir::EmitCallToIntrinsic(\n       llvm::Intrinsic::copysign, {one, input}, {type}, b);\n-  return b->CreateSelect(is_inf_mask, inf_result, result);\n+  return b->CreateSelect(is_large_mask, inf_result, result);\n }\n \n llvm::Value* EmitFastTanh(llvm::IRBuilderBase* b, llvm::Value* input,\n@@ -103,7 +101,7 @@ llvm::Value* EmitFastTanh(llvm::IRBuilderBase* b, llvm::Value* input,\n   llvm::Value* result =\n       b->CreateSelect(use_aprox, input, b->CreateFDiv(numerator, denominator));\n \n-  return HandleInfinity(b, input, result);\n+  return HandleLargeInputs(b, input, result);\n }\n \n llvm::Value* EmitFastTanhF64(llvm::IRBuilderBase* b, llvm::Value* input,\n@@ -160,7 +158,7 @@ llvm::Value* EmitFastTanhF64(llvm::IRBuilderBase* b, llvm::Value* input,\n   // Divide the numerator by the denominator.\n   llvm::Value* result = b->CreateFDiv(numerator, denominator);\n \n-  return HandleInfinity(b, input, result);\n+  return HandleLargeInputs(b, input, result);\n }\n \n }  // namespace"
        },
        {
            "sha": "efa2b4fc0999698ae90d395295f73d9a25a050d1",
            "filename": "third_party/xla/xla/codegen/intrinsic/tanh_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ftanh_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ftanh_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ftanh_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -108,8 +108,11 @@ TEST(TanhTest, EmitTanhF64) {\n                    std::numeric_limits<double>::infinity(),\n                    std::numeric_limits<double>::quiet_NaN()};\n   auto* fn = jit.GetScalarFn<double(double)>(Tanh::Name(type));\n-  EXPECT_THAT(fn(std::numeric_limits<double>::infinity()),\n-              NearUlps<double>(1.0, 0));\n+  auto inf = std::numeric_limits<double>::infinity();\n+  EXPECT_THAT(fn(inf), NearUlps<double>(1.0, 0));\n+  EXPECT_THAT(fn(-inf), NearUlps<double>(-1.0, 0));\n+  EXPECT_THAT(fn(20), NearUlps<double>(1.0, 0));\n+  EXPECT_THAT(std::tanh(20), NearUlps<double>(1.0, 0));\n   for (double val : vals) {\n     double actual = fn(val);\n     double expected = std::tanh(val);"
        },
        {
            "sha": "6f5ee2662cf1cb0171d676c9f6e5ad6f088c2c2e",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 5,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -444,6 +444,7 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n   opts.set_xla_hlo_pass_fix_detect_cycles(false);\n   opts.set_xla_gpu_experimental_enable_heuristic_collective_combining(true);\n   opts.set_xla_unsupported_crash_on_hlo_pass_silent_hlo_change(false);\n+  opts.set_xla_disable_automatic_host_compute_offload(false);\n   opts.set_xla_unsupported_crash_on_hlo_pass_noop_change(false);\n   opts.set_xla_gpu_experimental_enable_split_k_rewrite(false);\n   opts.set_xla_gpu_experimental_enable_triton_tma(false);\n@@ -2491,6 +2492,13 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n       \"If non empty will interpret this variable as a path for performance \"\n       \"tables for collectives. Expects `xla.gpu.DeviceHloInstructionProfiles` \"\n       \"proto.\"));\n+  flag_list->push_back(tsl::Flag(\n+      \"xla_unsupported_crash_on_hlo_pass_noop_change\",\n+      bool_setter_for(\n+          &DebugOptions::set_xla_unsupported_crash_on_hlo_pass_noop_change),\n+      debug_options->xla_unsupported_crash_on_hlo_pass_noop_change(),\n+      \"Crash if a pass reports that it did change the HLO but in fact it \"\n+      \"did not.\"));\n   flag_list->push_back(tsl::Flag(\n       \"xla_unsupported_crash_on_hlo_pass_silent_hlo_change\",\n       bool_setter_for(\n@@ -2500,12 +2508,12 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n       \"Crash if a pass reports that it did not change the HLO but in fact it \"\n       \"did.\"));\n   flag_list->push_back(tsl::Flag(\n-      \"xla_unsupported_crash_on_hlo_pass_noop_change\",\n+      \"xla_disable_automatic_host_compute_offload\",\n       bool_setter_for(\n-          &DebugOptions::set_xla_unsupported_crash_on_hlo_pass_noop_change),\n-      debug_options->xla_unsupported_crash_on_hlo_pass_noop_change(),\n-      \"Crash if a pass reports that it did change the HLO but in fact it \"\n-      \"did not.\"));\n+          &DebugOptions::set_xla_disable_automatic_host_compute_offload),\n+      debug_options->xla_disable_automatic_host_compute_offload(),\n+      \"Return an error if HostOffloader would have automatically offloaded some\"\n+      \" compute to the host.\"));\n   flag_list->push_back(tsl::Flag(\n       \"xla_gpu_experimental_matmul_perf_table_path\",\n       string_setter_for("
        },
        {
            "sha": "a5597b18e103e3770c44f463b3b499892922bd43",
            "filename": "third_party/xla/xla/hlo/analysis/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -643,7 +643,6 @@ cc_library(\n         \"//xla/hlo/utils:hlo_traversal\",\n         \"//xla/service:matmul_indexing_utils\",\n         \"@com_google_absl//absl/algorithm:container\",\n-        \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/container:inlined_vector\","
        },
        {
            "sha": "1abd4b4f500c7009a0c9d7e74bea59ccfc2df270",
            "filename": "third_party/xla/xla/hlo/analysis/indexing_analysis.cc",
            "status": "modified",
            "additions": 67,
            "deletions": 15,
            "changes": 82,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -331,10 +331,9 @@ HloInstructionIndexing ComputeOutputToInputFusionOpIndexing(\n   return fusion_indexing;\n }\n \n-HloInstructionIndexing ComputeOutputToInputDotOpIndexing(\n-    const HloDotInstruction* dot, MLIRContext* mlir_context) {\n-  CHECK_NE(dot, nullptr);\n-  const DotDimensionNumbers& dim_numbers = dot->dot_dimension_numbers();\n+std::pair<IndexingMap, IndexingMap> ComputeDotOperandsIndexingImpl(\n+    const Shape& lhs_shape, const Shape& rhs_shape, const Shape& output_shape,\n+    const DotDimensionNumbers& dim_numbers, MLIRContext* mlir_context) {\n   absl::Span<const int64_t> lhs_contracting_dims(\n       dim_numbers.lhs_contracting_dimensions());\n   absl::Span<const int64_t> rhs_contracting_dims =\n@@ -343,8 +342,6 @@ HloInstructionIndexing ComputeOutputToInputDotOpIndexing(\n   absl::Span<const int64_t> lhs_batch_dims = dim_numbers.lhs_batch_dimensions();\n   absl::Span<const int64_t> rhs_batch_dims = dim_numbers.rhs_batch_dimensions();\n \n-  const Shape& lhs_shape = dot->operand(0)->shape();\n-  const Shape& rhs_shape = dot->operand(1)->shape();\n   // According to the StableHLO specification, the dimensions of the output\n   // shape are ordered as follows:\n   //   lhs_batch_dims | lhs_non_contracting_dims | rhs_non_contracting_dims\n@@ -396,17 +393,69 @@ HloInstructionIndexing ComputeOutputToInputDotOpIndexing(\n     input_dim_sizes.push_back(lhs_shape.dimensions(lhs_contracting_dim));\n   }\n \n-  IndexingMap lhs_indexing_map = IndexingMap::FromTensorSizes(\n-      AffineMap::get(dot->shape().dimensions().size(), input_dim_sizes.size(),\n-                     lhs_exprs, mlir_context),\n-      dot->shape().dimensions(), input_dim_sizes);\n+  int64_t output_rank = output_shape.dimensions().size();\n+  return std::make_pair(IndexingMap::FromTensorSizes(\n+                            AffineMap::get(output_rank, input_dim_sizes.size(),\n+                                           lhs_exprs, mlir_context),\n+                            output_shape.dimensions(), input_dim_sizes),\n+                        IndexingMap::FromTensorSizes(\n+                            AffineMap::get(output_rank, input_dim_sizes.size(),\n+                                           rhs_exprs, mlir_context),\n+                            output_shape.dimensions(), input_dim_sizes));\n+}\n+\n+// Returns the new map with the results scaled by (operand_shape / scale_shape).\n+IndexingMap RescaleIndexingMap(const IndexingMap& operand_map,\n+                               const Shape& operand_shape,\n+                               const Shape& scale_shape) {\n+  SmallVector<AffineExpr> exprs;\n+  exprs.reserve(operand_shape.dimensions().size());\n+  AffineMap affine_map = operand_map.GetAffineMap();\n+  for (const auto& [scale_dim, operand_dim, expr] :\n+       llvm::zip(scale_shape.dimensions(), operand_shape.dimensions(),\n+                 affine_map.getResults())) {\n+    CHECK_EQ(operand_dim % scale_dim, 0)\n+        << \"Scale dimension must divide the operand dimension.\";\n+    exprs.push_back(scale_dim == operand_dim\n+                        ? expr\n+                        : expr.floorDiv(operand_dim / scale_dim));\n+  }\n+  return IndexingMap{\n+      AffineMap::get(affine_map.getNumDims(), affine_map.getNumSymbols(), exprs,\n+                     affine_map.getContext()),\n+      operand_map.GetDimVars(), operand_map.GetRangeVars(),\n+      operand_map.GetRTVars()};\n+}\n+\n+HloInstructionIndexing ComputeOutputToInputDotOpIndexing(\n+    const HloDotInstruction* dot, MLIRContext* mlir_context) {\n+  const Shape& lhs_shape = dot->operand(0)->shape();\n+  const Shape& rhs_shape = dot->operand(1)->shape();\n+\n+  auto [lhs_map, rhs_map] = ComputeDotOperandsIndexingImpl(\n+      lhs_shape, rhs_shape, dot->shape(), dot->dot_dimension_numbers(),\n+      mlir_context);\n+  return HloInstructionIndexing::FromIndexingMaps({lhs_map, rhs_map});\n+}\n+\n+HloInstructionIndexing ComputeOutputToInputScaledDotOpIndexing(\n+    const HloScaledDotInstruction* scaled_dot, MLIRContext* mlir_context) {\n+  const Shape& lhs_shape = scaled_dot->operand(0)->shape();\n+  const Shape& lhs_scale_shape = scaled_dot->operand(1)->shape();\n+  const Shape& rhs_shape = scaled_dot->operand(2)->shape();\n+  const Shape& rhs_scale_shape = scaled_dot->operand(3)->shape();\n+\n+  auto [lhs_map, rhs_map] = ComputeDotOperandsIndexingImpl(\n+      lhs_shape, rhs_shape, scaled_dot->shape(),\n+      scaled_dot->dot_dimension_numbers(), mlir_context);\n+\n+  IndexingMap lhs_scale_map =\n+      RescaleIndexingMap(lhs_map, lhs_shape, lhs_scale_shape);\n+  IndexingMap rhs_scale_map =\n+      RescaleIndexingMap(rhs_map, rhs_shape, rhs_scale_shape);\n \n-  IndexingMap rhs_indexing_map = IndexingMap::FromTensorSizes(\n-      AffineMap::get(dot->shape().dimensions().size(), input_dim_sizes.size(),\n-                     rhs_exprs, mlir_context),\n-      dot->shape().dimensions(), input_dim_sizes);\n   return HloInstructionIndexing::FromIndexingMaps(\n-      {lhs_indexing_map, rhs_indexing_map});\n+      {lhs_map, lhs_scale_map, rhs_map, rhs_scale_map});\n }\n \n HloInstructionIndexing ComputeOutputToInputDynamicSliceOpIndexing(\n@@ -1598,6 +1647,9 @@ HloInstructionIndexing ComputeOutputToInputIndexing(const HloInstruction* instr,\n   if (auto reverse = DynCast<HloReverseInstruction>(instr)) {\n     return ComputeReverseOpIndexing(reverse, ctx);\n   }\n+  if (auto scaled_dot = DynCast<HloScaledDotInstruction>(instr)) {\n+    return ComputeOutputToInputScaledDotOpIndexing(scaled_dot, ctx);\n+  }\n   if (auto slice = DynCast<HloSliceInstruction>(instr)) {\n     return ComputeOutputToInputSliceOpIndexing(slice, ctx);\n   }"
        },
        {
            "sha": "7916966ac5ba238094a0924b99321a61ac81304d",
            "filename": "third_party/xla/xla/hlo/analysis/indexing_analysis_test.cc",
            "status": "modified",
            "additions": 41,
            "deletions": 0,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -2455,6 +2455,47 @@ TEST_F(IndexingAnalysisTest, DotOp) {\n               )\"));\n }\n \n+TEST_F(IndexingAnalysisTest, ScaledDotOp) {\n+  auto input_indexing = GetOutputToInputIndexing(ParseAndGetRoot(R\"(\n+    HloModule m\n+    ENTRY e {\n+      a = f32[2,10] parameter(0)\n+      b = f32[10,2] parameter(1)\n+      a_scale = f32[2,2] parameter(2)\n+      b_scale = f32[2,2] parameter(3)\n+      ROOT dot = f32[2,2] scaled-dot(a, a_scale, b, b_scale),\n+        lhs_contracting_dims={1},\n+        rhs_contracting_dims={0}\n+    }\n+  )\"));\n+  EXPECT_THAT(input_indexing.ToString(), MatchIndexingString(R\"(\n+    operand id = 0\n+      (d0, d1)[s0] -> (d0, s0),\n+      domain:\n+      d0 in [0, 1],\n+      d1 in [0, 1],\n+      s0 in [0, 9]\n+    operand id = 1\n+      (d0, d1)[s0] -> (d0, s0 floordiv 5),\n+      domain:\n+      d0 in [0, 1],\n+      d1 in [0, 1],\n+      s0 in [0, 9]\n+    operand id = 2\n+      (d0, d1)[s0] -> (s0, d1),\n+      domain:\n+      d0 in [0, 1],\n+      d1 in [0, 1],\n+      s0 in [0, 9]\n+    operand id = 3\n+      (d0, d1)[s0] -> (s0 floordiv 5, d1),\n+      domain:\n+      d0 in [0, 1],\n+      d1 in [0, 1],\n+      s0 in [0, 9]\n+  )\"));\n+}\n+\n TEST_F(IndexingAnalysisTest, UnsupportedOps) {\n   auto root = ParseAndGetRoot(R\"(\n     HloModule m"
        },
        {
            "sha": "e702828f3f178a9823232eba57c9fe4f6e533933",
            "filename": "third_party/xla/xla/hlo/builder/xla_builder.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 6,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -4976,12 +4976,8 @@ absl::StatusOr<XlaOp> XlaBuilder::AddInstruction(\n       absl::string_view name = (last_slash_pos == absl::string_view::npos)\n                                    ? op_name\n                                    : op_name.substr(last_slash_pos + 1);\n-      // Further strip any numeric identifier suffixes.\n-      if (absl::StrContains(name, kNameSeparator)) {\n-        instr.set_name(GetBaseName(std::string(name), kNameSeparator));\n-      } else {\n-        instr.set_name(name);\n-      }\n+      instr.set_name(\n+          xla::SanitizeOpName(std::string(name), kNameSeparator, \"_\"));\n     } else {\n       instr.set_name(instr.opcode());\n     }"
        },
        {
            "sha": "0766070a142349442db770e624404d98bf07f9a2",
            "filename": "third_party/xla/xla/hlo/builder/xla_builder_test.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -4018,5 +4018,18 @@ TEST(XlaBuilderTest, InstructionNameFromMetadata) {\n             \"sin\");\n }\n \n+TEST(XlaBuilderTest, InstructionNameFromMetadataWithDot) {\n+  XlaBuilder b(TestName());\n+  OpMetadata metadata;\n+  metadata.set_op_name(\"inputs.x\");\n+  XlaScopedOpMetadataAssignment op_metadata(&b, metadata);\n+  ConstantR0<float>(&b, 1.0f);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module, BuildHloModule(b));\n+  HloInstruction* constant = module->entry_computation()->root_instruction();\n+  EXPECT_EQ(constant->name().substr(0, constant->name().find_first_of('.')),\n+            \"inputs_x\");\n+}\n+\n }  // namespace\n }  // namespace xla"
        },
        {
            "sha": "2420a3bdbc3f606478197db46a253b9585c872b4",
            "filename": "third_party/xla/xla/hlo/evaluator/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -105,6 +105,7 @@ cc_library(\n         \"@eigen_archive//:eigen3\",\n         \"@local_tsl//tsl/platform:ml_dtypes\",\n         \"@local_tsl//tsl/platform:platform_port\",\n+        \"@local_tsl//tsl/platform:protobuf\",\n     ],\n )\n "
        },
        {
            "sha": "d47bbe46ff530c45ad0eab7681a83126dfa2876e",
            "filename": "third_party/xla/xla/hlo/evaluator/hlo_evaluator.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1128,6 +1128,31 @@ absl::StatusOr<Literal> HloEvaluator::EvaluateDotOp(\n   return Evaluate(cloned_instruction.get());\n }\n \n+absl::StatusOr<Literal> HloEvaluator::EvaluateScaledDotOp(\n+    const DotDimensionNumbers& dim_numbers,\n+    const PrecisionConfig& precision_config, const Literal& lhs,\n+    const Literal& lhs_scale, const Literal& rhs, const Literal& rhs_scale) {\n+  std::unique_ptr<HloInstruction> lhs_instr =\n+      HloInstruction::CreateConstant(lhs.Clone());\n+  std::unique_ptr<HloInstruction> lhs_scale_instr =\n+      HloInstruction::CreateConstant(lhs_scale.Clone());\n+  std::unique_ptr<HloInstruction> rhs_instr =\n+      HloInstruction::CreateConstant(rhs.Clone());\n+  std::unique_ptr<HloInstruction> rhs_scale_instr =\n+      HloInstruction::CreateConstant(rhs_scale.Clone());\n+\n+  TF_ASSIGN_OR_RETURN(\n+      Shape dot_shape,\n+      ShapeInference::InferDotOpShape(lhs.shape(), rhs.shape(), dim_numbers,\n+                                      /*preferred_element_type=*/std::nullopt));\n+\n+  std::unique_ptr<HloInstruction> cloned_instruction =\n+      HloInstruction::CreateScaledDot(\n+          dot_shape, lhs_instr.get(), lhs_scale_instr.get(), rhs_instr.get(),\n+          rhs_scale_instr.get(), dim_numbers, precision_config);\n+  return Evaluate(cloned_instruction.get());\n+}\n+\n absl::Status HloEvaluator::EvaluateParameterFromCallerArgument(\n     const HloInstruction* parameter, const ShapeIndex& shape_index,\n     PrecomputedAnalyses analyses) {"
        },
        {
            "sha": "3e9755627d39f09ac46701df73624c4214d14e1d",
            "filename": "third_party/xla/xla/hlo/evaluator/hlo_evaluator.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -193,6 +193,10 @@ class HloEvaluator : public ConstDfsHloVisitorWithDefault,\n   absl::StatusOr<Literal> EvaluateDotOp(const DotDimensionNumbers& dim_numbers,\n                                         const PrecisionConfig& precision_config,\n                                         const Literal& lhs, const Literal& rhs);\n+  absl::StatusOr<Literal> EvaluateScaledDotOp(\n+      const DotDimensionNumbers& dim_numbers,\n+      const PrecisionConfig& precision_config, const Literal& lhs,\n+      const Literal& lhs_scale, const Literal& rhs, const Literal& rhs_scale);\n \n   void set_dynamic_dimension_inference(\n       DynamicDimensionInference* dynamic_dimension_inference) override {"
        },
        {
            "sha": "05f671e5e3b46ef101a2adc8c1169aa994cd75a0",
            "filename": "third_party/xla/xla/hlo/evaluator/hlo_evaluator_test.cc",
            "status": "modified",
            "additions": 180,
            "deletions": 0,
            "changes": 180,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1260,6 +1260,186 @@ TEST_F(HloEvaluatorTest, RaggedDotNonContractingWithBatchDimensions) {\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected, result));\n }\n \n+HloInstruction* BF16Array2D(HloComputation::Builder& b, int rows, int cols,\n+                            float value) {\n+  auto array = std::make_unique<Array2D<float>>(rows, cols);\n+  array->FillUnique(value);\n+  auto literal = LiteralUtil::CreateR2FromArray2D<float>(*array);\n+  auto bf16_literal = LiteralUtil::ConvertF32ToBF16(literal);\n+  return b.AddInstruction(\n+      HloInstruction::CreateConstant(std::move(bf16_literal)));\n+}\n+\n+HloInstruction* BF16Array3D(HloComputation::Builder& b, int batch, int rows,\n+                            int cols, float value) {\n+  auto array = std::make_unique<Array3D<float>>(batch, rows, cols);\n+  array->FillUnique(value);\n+  auto literal = LiteralUtil::CreateR3FromArray3D<float>(*array);\n+  auto bf16_literal = LiteralUtil::ConvertF32ToBF16(literal);\n+  return b.AddInstruction(\n+      HloInstruction::CreateConstant(std::move(bf16_literal)));\n+}\n+\n+TEST_F(HloEvaluatorTest, ScaledDot) {\n+  HloComputation::Builder b(TestName());\n+\n+  auto lhs_instr = BF16Array2D(b, 1, 4, 1.0f);\n+  auto lhs_scale_instr = BF16Array2D(b, 1, 2, 2.0f);\n+  auto rhs_instr = BF16Array2D(b, 4, 1, 1.0f);\n+  auto rhs_scale_instr = BF16Array2D(b, 2, 1, 3.0f);\n+\n+  Shape shape = ShapeUtil::MakeShape(BF16, {1, 1});\n+  DotDimensionNumbers dot_dnums;\n+  dot_dnums.add_lhs_contracting_dimensions(1);\n+  dot_dnums.add_rhs_contracting_dimensions(0);\n+  b.AddInstruction(HloInstruction::CreateScaledDot(\n+      shape, lhs_instr, lhs_scale_instr, rhs_instr, rhs_scale_instr, dot_dnums,\n+      DefaultPrecisionConfig(4)));\n+  m_->AddEntryComputation(b.Build());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Evaluate());\n+\n+  // lhs[1,4] = {{1, 2, 3, 4}}\n+  // lhs_scale[1,2] = {{2, 3}}\n+  // rhs[4,1] = {\n+  //   {1},\n+  //   {2},\n+  //   {3},\n+  //   {4}\n+  // }\n+  // rhs_scale[2,1] = {\n+  //   {3},\n+  //   {4}\n+  // }\n+\n+  // lhs * lhs_scale * rhs * rhs_scale\n+  // 1 * 2 * 1 * 3 = 6\n+  // 2 * 2 * 2 * 3 = 24\n+  // 3 * 3 * 3 * 4 = 108\n+  // 4 * 3 * 4 * 4 = 192\n+  //           sum = 330\n+  auto expected_array = Array2D<float>({{330.f}});\n+  auto expected = LiteralUtil::CreateR2FromArray2D<float>(expected_array);\n+  auto expected_bf16 = LiteralUtil::ConvertF32ToBF16(expected);\n+  EXPECT_TRUE(LiteralTestUtil::Equal(expected_bf16, result));\n+}\n+\n+TEST_F(HloEvaluatorTest, ScaledDotWithOneMissingScale) {\n+  HloComputation::Builder b(TestName());\n+\n+  auto lhs_instr = BF16Array2D(b, 1, 4, 1.0f);\n+  auto lhs_scale_instr = b.AddInstruction(\n+      HloInstruction::CreateConstant(LiteralUtil::CreateR0(BF16, 1.0f)));\n+  auto rhs_instr = BF16Array2D(b, 4, 1, 1.0f);\n+  auto rhs_scale_instr = BF16Array2D(b, 2, 1, 3.0f);\n+\n+  Shape shape = ShapeUtil::MakeShape(BF16, {1, 1});\n+  DotDimensionNumbers dot_dnums;\n+  dot_dnums.add_lhs_contracting_dimensions(1);\n+  dot_dnums.add_rhs_contracting_dimensions(0);\n+  b.AddInstruction(HloInstruction::CreateScaledDot(\n+      shape, lhs_instr, lhs_scale_instr, rhs_instr, rhs_scale_instr, dot_dnums,\n+      DefaultPrecisionConfig(4)));\n+  m_->AddEntryComputation(b.Build());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Evaluate());\n+\n+  // lhs[1,4] = {{1, 2, 3, 4}}\n+  // lhs_scal = 1.0f\n+  // rhs[4,1] = {\n+  //   {1},\n+  //   {2},\n+  //   {3},\n+  //   {4}\n+  // }\n+  // rhs_scale[2,1] = {\n+  //   {3},\n+  //   {4}\n+  // }\n+\n+  // lhs * lhs_scale * rhs * rhs_scale\n+  // 1 * 1 * 1 * 3 = 3\n+  // 2 * 1 * 2 * 3 = 12\n+  // 3 * 1 * 3 * 4 = 36\n+  // 4 * 1 * 4 * 4 = 64\n+  //           sum = 115\n+  auto expected_array = Array2D<float>({{115.f}});\n+  auto expected = LiteralUtil::CreateR2FromArray2D<float>(expected_array);\n+  auto expected_bf16 = LiteralUtil::ConvertF32ToBF16(expected);\n+  EXPECT_TRUE(LiteralTestUtil::Equal(expected_bf16, result));\n+}\n+\n+TEST_F(HloEvaluatorTest, ScaledDotWithBatchDim) {\n+  HloComputation::Builder b(TestName());\n+\n+  auto lhs_instr = BF16Array3D(b, 2, 1, 4, 1.0f);\n+  auto lhs_scale_instr = b.AddInstruction(\n+      HloInstruction::CreateConstant(LiteralUtil::CreateR0(BF16, 1.0f)));\n+  auto rhs_instr = BF16Array3D(b, 2, 4, 1, 1.0f);\n+  auto rhs_scale_instr = BF16Array3D(b, 1, 2, 1, 3.0f);\n+\n+  Shape shape = ShapeUtil::MakeShape(BF16, {2, 1, 1});\n+  DotDimensionNumbers dot_dnums;\n+  dot_dnums.add_lhs_batch_dimensions(0);\n+  dot_dnums.add_rhs_batch_dimensions(0);\n+\n+  dot_dnums.add_lhs_contracting_dimensions(2);\n+  dot_dnums.add_rhs_contracting_dimensions(1);\n+  b.AddInstruction(HloInstruction::CreateScaledDot(\n+      shape, lhs_instr, lhs_scale_instr, rhs_instr, rhs_scale_instr, dot_dnums,\n+      DefaultPrecisionConfig(4)));\n+  m_->AddEntryComputation(b.Build());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Evaluate());\n+  // lhs[2,1,4] = {\n+  //   {{ 1, 2, 3, 4 }},\n+  //   {{ 5, 6, 7, 8 }}\n+  // }\n+\n+  // rhs[2,4,1] = {\n+  //   {\n+  //     {1},\n+  //     {5},\n+  //     {9},\n+  //     {13}\n+  //   },\n+  //   {\n+  //     {5},\n+  //     {5},\n+  //     {13},\n+  //     {13}\n+  //   }\n+  // }\n+  // rhs_scale[2,2,1] = {\n+  //   {\n+  //     {3},\n+  //     {5}\n+  //   },\n+  //   {\n+  //     {3},\n+  //     {5}\n+  //   }\n+  // }\n+  // 1 * 1 * 1 * 3 = 3\n+  // 2 * 1 * 5 * 3 = 30\n+  // 3 * 1 * 9 * 5 = 135\n+  // 4 * 1 * 13 * 5 = 260\n+  // result_val: 428\n+  //\n+  // 5 * 1 * 5 * 3 = 75\n+  // 6 * 1 * 5 * 3 = 90\n+  // 7 * 1 * 13 * 5 = 455\n+  // 8 * 1 * 13 * 5 = 520\n+  // result_val: 1140\n+\n+  // The expectation does not match exact value the result due to the rounding\n+  // to bf16.\n+  auto expected_array = Array3D<float>({{{428.f}}, {{1136.f}}});\n+  auto expected = LiteralUtil::CreateR3FromArray3D<float>(expected_array);\n+  auto expected_bf16 = LiteralUtil::ConvertF32ToBF16(expected);\n+  EXPECT_TRUE(LiteralTestUtil::Equal(expected_bf16, result));\n+}\n+\n TEST_P(HloEvaluatorBf16Test, DotRank2AndRank1) {\n   HloComputation::Builder b(TestName());\n "
        },
        {
            "sha": "01b162696976f93b3d4621ec4f144f04b12a74b7",
            "filename": "third_party/xla/xla/hlo/evaluator/hlo_evaluator_typed_visitor.h",
            "status": "modified",
            "additions": 224,
            "deletions": 1,
            "changes": 225,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_typed_visitor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_typed_visitor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_typed_visitor.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -28,11 +28,11 @@ limitations under the License.\n #include <memory>\n #include <optional>\n #include <random>\n+#include <tuple>\n #include <type_traits>\n #include <utility>\n #include <vector>\n \n-#include \"absl/algorithm/container.h\"\n #include \"absl/base/attributes.h\"\n #include \"absl/base/casts.h\"\n #include \"absl/log/check.h\"\n@@ -59,6 +59,7 @@ limitations under the License.\n #include \"xla/types.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n+#include \"tsl/platform/protobuf.h\"  // IWYU pragma: keep\n \n namespace xla {\n \n@@ -1456,6 +1457,228 @@ class HloEvaluatorTypedVisitor : public ConstDfsHloVisitorWithDefault {\n                       gs_literal.Convert(PrimitiveType::S64).value()));\n   }\n \n+  absl::Status HandleScaledDot(const HloInstruction* dot) override {\n+    auto lhs = dot->operand(0);\n+    auto lhs_scale = dot->operand(1);\n+    auto rhs = dot->operand(2);\n+    auto rhs_scale = dot->operand(3);\n+    CHECK(dot->shape().IsArray());\n+    CHECK(lhs->shape().IsArray());\n+    CHECK(rhs->shape().IsArray());\n+    CHECK(lhs_scale->shape().IsArray());\n+    CHECK(rhs_scale->shape().IsArray());\n+    CHECK(lhs_scale->shape().dimensions().size() == 0 ||\n+          lhs_scale->shape().dimensions().size() ==\n+              lhs->shape().dimensions().size());\n+    CHECK(rhs_scale->shape().dimensions().size() == 0 ||\n+          rhs_scale->shape().dimensions().size() ==\n+              rhs->shape().dimensions().size());\n+    TF_ASSIGN_OR_RETURN(const Literal lhs_literal,\n+                        parent_->GetEvaluatedLiteralFor(lhs).Convert(\n+                            dot->shape().element_type()));\n+    TF_ASSIGN_OR_RETURN(const Literal rhs_literal,\n+                        parent_->GetEvaluatedLiteralFor(rhs).Convert(\n+                            dot->shape().element_type()));\n+\n+    // If the scale is a scalar, we can just use 1.0. Otherwise, we need to\n+    // evaluate the scale.\n+    auto evaluate_scale =\n+        [&](const HloInstruction* operand,\n+            const HloInstruction* scale) -> absl::StatusOr<Literal> {\n+      if (scale->shape().IsArray() && scale->shape().dimensions().size() > 0) {\n+        TF_ASSIGN_OR_RETURN(Literal scale_literal,\n+                            parent_->GetEvaluatedLiteralFor(scale).Convert(\n+                                dot->shape().element_type()));\n+        return scale_literal;\n+      }\n+      std::vector<int64_t> ones(operand->shape().dimensions().size(), 1);\n+      Shape scale_shape =\n+          ShapeUtil::MakeShape(dot->shape().element_type(), ones);\n+      Literal scale_literal = Literal::CreateFromShape(scale_shape);\n+      scale_literal.PopulateWithValue(static_cast<ReturnT>(1.0f));\n+      return scale_literal;\n+    };\n+    TF_ASSIGN_OR_RETURN(Literal lhs_scale_literal,\n+                        evaluate_scale(lhs, lhs_scale));\n+    TF_ASSIGN_OR_RETURN(Literal rhs_scale_literal,\n+                        evaluate_scale(rhs, rhs_scale));\n+    return HandleScaledDotSlowPathWithLiterals(\n+        dot, lhs_literal, lhs_scale_literal, rhs_literal, rhs_scale_literal);\n+  }\n+\n+ private:\n+  struct ShapeInfo {\n+    static std::pair<DimensionVector, DimensionVector> dims(\n+        const DimensionVector& dim_indexes, const Shape& literal_shape,\n+        const Shape& scale_shape) {\n+      DimensionVector dim_sizes;\n+      DimensionVector dim_scale_divisors;\n+      for (int64_t i = 0; i < dim_indexes.size(); ++i) {\n+        dim_sizes.push_back(literal_shape.dimensions(dim_indexes[i]));\n+        dim_scale_divisors.push_back(literal_shape.dimensions(dim_indexes[i]) /\n+                                     scale_shape.dimensions(dim_indexes[i]));\n+      }\n+      return {dim_sizes, dim_scale_divisors};\n+    }\n+\n+    ShapeInfo(\n+        const Literal& literal, const Literal& scale_literal,\n+        const tsl::protobuf::RepeatedField<int64_t>& contracting_dims_field,\n+        const tsl::protobuf::RepeatedField<int64_t>& batch_dims_field)\n+        : rank(literal.shape().dimensions().size()) {\n+      batch_dim_indexes =\n+          DimensionVector(batch_dims_field.begin(), batch_dims_field.end());\n+      std::tie(batch_dim_sizes, batch_dim_scale_divisors) =\n+          dims(batch_dim_indexes, literal.shape(), scale_literal.shape());\n+\n+      non_contracting_dim_indexes =\n+          GetNonContractingDims(rank, contracting_dims_field, batch_dims_field);\n+      std::tie(non_contracting_dim_sizes, non_contracting_dim_scale_divisors) =\n+          dims(non_contracting_dim_indexes, literal.shape(),\n+               scale_literal.shape());\n+\n+      contracting_dim_indexes = DimensionVector(contracting_dims_field.begin(),\n+                                                contracting_dims_field.end());\n+      std::tie(contracting_dim_sizes, contracting_dim_scale_divisors) =\n+          dims(contracting_dim_indexes, literal.shape(), scale_literal.shape());\n+    }\n+\n+    const int64_t rank;\n+    DimensionVector batch_dim_indexes;\n+    DimensionVector batch_dim_sizes;\n+    DimensionVector batch_dim_scale_divisors;\n+\n+    DimensionVector non_contracting_dim_indexes;\n+    DimensionVector non_contracting_dim_sizes;\n+    DimensionVector non_contracting_dim_scale_divisors;\n+\n+    DimensionVector contracting_dim_indexes;\n+    DimensionVector contracting_dim_sizes;\n+    DimensionVector contracting_dim_scale_divisors;\n+  };\n+\n+  absl::Status HandleScaledDotSlowPathWithLiterals(\n+      const HloInstruction* dot, const Literal& lhs_literal,\n+      const Literal& lhs_scale_literal, const Literal& rhs_literal,\n+      const Literal& rhs_scale_literal) {\n+    const auto& dnums = dot->dot_dimension_numbers();\n+    CHECK(ShapeUtil::SameElementType(lhs_literal.shape(), rhs_literal.shape()));\n+    CHECK(ShapeUtil::SameElementType(lhs_literal.shape(), dot->shape()));\n+\n+    CHECK_EQ(dnums.lhs_batch_dimensions_size(),\n+             dnums.rhs_batch_dimensions_size());\n+\n+    ShapeInfo lhs_info(lhs_literal, lhs_scale_literal,\n+                       dnums.lhs_contracting_dimensions(),\n+                       dnums.lhs_batch_dimensions());\n+    ShapeInfo rhs_info(rhs_literal, rhs_scale_literal,\n+                       dnums.rhs_contracting_dimensions(),\n+                       dnums.rhs_batch_dimensions());\n+    const int64_t total_contraction_size =\n+        Product(lhs_info.contracting_dim_sizes);\n+    Shape dot_shape = GetShapeWithLayout(dot->shape());\n+\n+    TF_ASSIGN_OR_RETURN(Literal result, Literal::Make(dot_shape));\n+    TF_RETURN_IF_ERROR(result.PopulateParallel<ReturnT>(\n+        [&](absl::Span<const int64_t> result_index, int /*thread_id*/) {\n+          // Locations in LHS and RHS that we read from.\n+          DimensionVector lhs_index(lhs_info.rank);\n+          DimensionVector lhs_scale_index(lhs_info.rank);\n+          DimensionVector rhs_index(rhs_info.rank);\n+          DimensionVector rhs_scale_index(rhs_info.rank);\n+\n+          // First come the batch dimensions.\n+          int64_t idx = 0;\n+          for (int64_t i = 0; i < dnums.lhs_batch_dimensions_size(); i++) {\n+            lhs_index[dnums.lhs_batch_dimensions(i)] = result_index[idx];\n+            rhs_index[dnums.rhs_batch_dimensions(i)] = result_index[idx];\n+            lhs_scale_index[dnums.lhs_batch_dimensions(i)] =\n+                result_index[idx] / lhs_info.batch_dim_scale_divisors[i];\n+            rhs_scale_index[dnums.rhs_batch_dimensions(i)] =\n+                result_index[idx] / rhs_info.batch_dim_scale_divisors[i];\n+            idx++;\n+          }\n+\n+          // Next we have non-contracting dimensions, if any.\n+          for (int64_t i = 0; i < lhs_info.non_contracting_dim_indexes.size();\n+               i++) {\n+            lhs_index[lhs_info.non_contracting_dim_indexes[i]] =\n+                result_index[idx];\n+            lhs_scale_index[lhs_info.non_contracting_dim_indexes[i]] =\n+                result_index[idx] /\n+                lhs_info.non_contracting_dim_scale_divisors[i];\n+            idx++;\n+          }\n+          for (int64_t i = 0; i < rhs_info.non_contracting_dim_indexes.size();\n+               i++) {\n+            rhs_index[rhs_info.non_contracting_dim_indexes[i]] =\n+                result_index[idx];\n+            rhs_scale_index[rhs_info.non_contracting_dim_indexes[i]] =\n+                result_index[idx] /\n+                rhs_info.non_contracting_dim_scale_divisors[i];\n+            idx++;\n+          }\n+\n+          auto get_val = [](const Literal& literal,\n+                            const DimensionVector& index) {\n+            return ToArithmeticSafeType(\n+                static_cast<ElementwiseT>(literal.Get<ReturnT>(index)));\n+          };\n+          // Accumulate resulting product along the contracting dimensions.\n+          ElementwiseT result_val = static_cast<ElementwiseT>(0);\n+          for (int64_t k = 0; k < total_contraction_size; k++) {\n+            const auto lhs = get_val(lhs_literal, lhs_index);\n+            const auto lhs_scale = get_val(lhs_scale_literal, lhs_scale_index);\n+            const auto rhs = get_val(rhs_literal, rhs_index);\n+            const auto rhs_scale = get_val(rhs_scale_literal, rhs_scale_index);\n+            result_val += lhs * lhs_scale * rhs * rhs_scale;\n+\n+            if (parent_->trace_mac_handler_ != nullptr) {\n+              const int64_t result_linear_index =\n+                  IndexUtil::MultidimensionalIndexToLinearIndex(dot_shape,\n+                                                                result_index);\n+              const int64_t lhs_linear_index =\n+                  IndexUtil::MultidimensionalIndexToLinearIndex(\n+                      lhs_literal.shape(), lhs_index);\n+              const int64_t rhs_linear_index =\n+                  IndexUtil::MultidimensionalIndexToLinearIndex(\n+                      rhs_literal.shape(), rhs_index);\n+\n+              parent_->trace_mac_handler_(result_linear_index, lhs_linear_index,\n+                                          rhs_linear_index);\n+            }\n+\n+            // If there are no contracting dimensions, do not try to count down\n+            // from -1 to 0; that's an infinite loop.\n+            if (!lhs_info.contracting_dim_sizes.empty()) {\n+              for (int64_t i = lhs_info.contracting_dim_sizes.size() - 1;\n+                   i >= 0; --i) {\n+                lhs_index[lhs_info.contracting_dim_indexes[i]]++;\n+                lhs_scale_index[lhs_info.contracting_dim_indexes[i]] =\n+                    lhs_index[lhs_info.contracting_dim_indexes[i]] /\n+                    lhs_info.contracting_dim_scale_divisors[i];\n+                rhs_index[rhs_info.contracting_dim_indexes[i]]++;\n+                rhs_scale_index[rhs_info.contracting_dim_indexes[i]] =\n+                    rhs_index[rhs_info.contracting_dim_indexes[i]] /\n+                    rhs_info.contracting_dim_scale_divisors[i];\n+                if (lhs_index[lhs_info.contracting_dim_indexes[i]] !=\n+                    lhs_info.contracting_dim_sizes[i]) {\n+                  break;\n+                }\n+                lhs_index[lhs_info.contracting_dim_indexes[i]] = 0;\n+                rhs_index[rhs_info.contracting_dim_indexes[i]] = 0;\n+              }\n+            }\n+          }\n+\n+          return static_cast<ReturnT>(result_val);\n+        }));\n+\n+    parent_->SetEvaluatedLiteralFor(dot, std::move(result));\n+    return absl::OkStatus();\n+  }\n+\n+ public:\n   absl::Status HandlePad(const HloInstruction* pad) override {\n     CHECK(pad->operand(0)->shape().IsArray());\n     // Padding value must be scalar."
        },
        {
            "sha": "f1c76862ac47e5f9f92b3f536f1d73b27d2f94cf",
            "filename": "third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -3559,7 +3559,8 @@ absl::StatusOr<bool> AutoShardingImplementation::RunAutoSharding(\n   TF_ASSIGN_OR_RETURN(\n       bool changed,\n       ProcessShardingInstruction(\n-          module, execution_threads, /*replace_sharding_with_copy=*/true,\n+          module, execution_threads,\n+          /*replace_sharding_with_copy=*/option_.replace_sharding_with_copy,\n           &unspecified_dims, /*saved_root_shardings=*/nullptr,\n           /*saved_parameter_shardings=*/nullptr,\n           /*instruction_to_shard_group_id=*/nullptr,\n@@ -3824,7 +3825,8 @@ absl::StatusOr<bool> AutoShardingImplementation::RunAutoSharding(\n       CHECK(instruction->has_sharding());\n       CHECK(instruction->sharding().IsManual());\n       CHECK(instruction->operand(0)->has_sharding());\n-      CHECK(!instruction->operand(0)->sharding().IsManual());\n+      CHECK(spmd::IsShardingCustomCall(instruction->operand(0)) ||\n+            !instruction->operand(0)->sharding().IsManual());\n     } else if (spmd::IsSPMDShardToFullShapeCustomCall(instruction)) {\n       CHECK(instruction->has_sharding());\n       CHECK(!instruction->sharding().IsManual());"
        },
        {
            "sha": "2db2beb0bece3ed68328d75dbf4f918f678c9bb8",
            "filename": "third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_option.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_option.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_option.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_option.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -208,6 +208,11 @@ struct AutoShardingOption {\n   // ops in a principled manner.\n   bool insert_resharding_reshapes_for_non_dot_ops = false;\n \n+  // When folding the sharding attribute to its operand, if the module is\n+  // transformed to Shardy in later steps, we should not replace the sharding\n+  // custom call with copy.\n+  bool replace_sharding_with_copy = true;\n+\n   // The number of slices used\n   std::optional<int64_t> num_dcn_slices = std::nullopt;\n "
        },
        {
            "sha": "03333a03f75c41547a8f121d285ab7afe8144c8a",
            "filename": "third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_stablehlo_pass.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_stablehlo_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_stablehlo_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_stablehlo_pass.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -130,6 +130,7 @@ class AutoShardingWrapperPass\n     option.device_mesh_shape = device_mesh_shape;\n     // Keep the mesh shape unchanged.\n     option.allow_mixed_mesh_shape = false;\n+    option.replace_sharding_with_copy = false;\n     // TODO(hanruobing): Add an option to control whether to keep the original\n     // sharding or not. The current behavior is to keep the original sharding.\n     // TODO(b/424109294): Figure out whether we need to pass backend-specific"
        },
        {
            "sha": "fcb6911eeff5168979c4bf840bc019137fe571cc",
            "filename": "third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_strategy.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_strategy.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_strategy.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_strategy.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -957,6 +957,8 @@ BuildStrategyAndCost(\n                 \"annotation.\");\n           }\n           generate_non_following_strategies(false);\n+        } else if (IsShardingCustomCall(ins)) {\n+          generate_non_following_strategies(false);\n         } else if (IsTopKCustomCall(ins)) {\n           generate_non_following_strategies(false, {0});\n         } else if (IsPartialReduceCustomCall(ins)) {"
        },
        {
            "sha": "14f7b738100c7e52be137afc1498cea875e6d178",
            "filename": "third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_util.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -63,6 +63,10 @@ inline bool IsSPMDShardToFullShapeCustomCall(const HloInstruction* ins) {\n   return ins->IsCustomCall(\"SPMDShardToFullShape\");\n }\n \n+inline bool IsShardingCustomCall(const HloInstruction* ins) {\n+  return ins->IsCustomCall(\"Sharding\");\n+}\n+\n inline std::pair<int, int> ParseMeshDims(const std::string& strategy_name) {\n   if (absl::StrContains(strategy_name, \"{0,1}\")) {\n     return {0, 1};"
        },
        {
            "sha": "f83403746d13fa86ca8896c2dd96b55ded3948fd",
            "filename": "third_party/xla/xla/hlo/ir/BUILD",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -77,12 +77,14 @@ cc_library(\n         \"//xla:side_effect_util\",\n         \"//xla:sort_json\",\n         \"//xla:status_macros\",\n+        \"//xla:tuple_tree\",\n         \"//xla:types\",\n         \"//xla:util\",\n         \"//xla:window_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/hlo/parser:hlo_lexer\",\n+        \"//xla/hlo/utils:pointer_utils\",\n         \"//xla/service:compilation_environments\",\n         \"//xla/service:computation_layout\",\n         \"//xla/service:computation_placer_hdr\",\n@@ -397,3 +399,18 @@ xla_cc_test(\n         \"@com_google_googletest//:gtest\",\n     ],\n )\n+\n+xla_cc_test(\n+    name = \"hlo_original_value_test\",\n+    srcs = [\"hlo_original_value_test.cc\"],\n+    deps = [\n+        \":hlo\",\n+        \"//xla:shape_util\",\n+        \"//xla:tuple_tree\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/hash:hash_testing\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)"
        },
        {
            "sha": "bd4ff48e154c89082e6c62d1e1f392ec7e66db40",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -2700,6 +2700,7 @@ std::unique_ptr<HloInstruction> HloInstruction::CloneWithNewOperands(\n     case HloOpcode::kIota:\n     case HloOpcode::kDot:\n     case HloOpcode::kRaggedDot:\n+    case HloOpcode::kScaledDot:\n     case HloOpcode::kDomain:\n     case HloOpcode::kGetDimensionSize:\n     case HloOpcode::kSetDimensionSize:\n@@ -5902,10 +5903,14 @@ void HloInstruction::set_async_execution_thread(\n }\n \n void HloInstruction::set_called_computations_execution_thread(\n-    absl::string_view async_execution_thread,\n-    bool skip_async_execution_thread_overwrite) {\n+    absl::string_view async_execution_thread) {\n+  if (GetInstructionCallContext(this->opcode()) == CallContext::kEmbedded) {\n+    // There is no need to set the thread name for embedded computations\n+    // recursively, because they cannot be executed asynchronously.\n+    return;\n+  }\n   Cast<HloCallableInstruction>(this)->RecursivelySetComputationsThreadName(\n-      async_execution_thread, skip_async_execution_thread_overwrite);\n+      async_execution_thread);\n }\n \n std::optional<int> HloInstruction::cross_program_prefetch_index() const {"
        },
        {
            "sha": "fb6c4ddadf2e2227d16cc527d7e1764e605c721a",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction.h",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -2391,8 +2391,7 @@ class HloInstruction {\n   // Delegates to\n   // HloCallableInstruction::RecursivelySetComputationsThreadName().\n   void set_called_computations_execution_thread(\n-      absl::string_view async_execution_thread,\n-      bool skip_async_execution_thread_overwrite);\n+      absl::string_view async_execution_thread);\n \n   // Delegates to HloCopyStartInstruction::is_cross_program_prefetch_index().\n   std::optional<int> cross_program_prefetch_index() const;"
        },
        {
            "sha": "b3bf81d16839de56a59a56b8ce432342fb9aa8aa",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction_test.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -146,6 +146,24 @@ ENTRY main {\n   TF_EXPECT_OK(module->schedule().Verify());\n }\n \n+TEST_F(HloInstructionTest, CloneImplCollectivePermuteOp) {\n+  constexpr absl::string_view kHlo = R\"(\n+HloModule main\n+\n+ENTRY main {\n+  arg.0 = f32[32,32]{1,0} parameter(0)\n+  ROOT collective-permute.0 = (f32[32,32]{1,0}, f32[32,32]{1,0}) collective-permute(arg.0, arg.0), channel_id=388, source_target_pairs={{0,0},{4,1}}\n+})\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(kHlo));\n+\n+  HloInstruction* cp = module->entry_computation()->root_instruction();\n+  ASSERT_EQ(cp->opcode(), HloOpcode::kCollectivePermute);\n+  auto clone = cp->CloneWithNewOperands(cp->shape(), cp->operands());\n+  EXPECT_EQ(clone->operand_count(), 2);\n+}\n+\n TEST_F(HloInstructionTest, ComparatorWorksWith64BitUniqueIds) {\n   std::unique_ptr<HloInstruction> param1 =\n       HloInstruction::CreateParameter(0, Shape(F32, {4}), \"param1\");"
        },
        {
            "sha": "349570f337590853fde9fa265bc5b84c3994e8d4",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instructions.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 19,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -112,22 +112,17 @@ void PrintPrecisionConfig(HloInstruction::AttributePrinter& printer,\n }\n \n void SetThreadName(HloComputation* called_computation,\n-                   absl::string_view execution_thread,\n-                   bool skip_async_execution_thread_overwrite) {\n+                   absl::string_view execution_thread) {\n   called_computation->SetExecutionThread(execution_thread);\n   for (HloInstruction* instr : called_computation->instructions()) {\n     if (instr->IsAsynchronous()) {\n-      if (!skip_async_execution_thread_overwrite) {\n-        // Set async instruction thread name and also recursively set async\n-        // computations.\n-        instr->set_async_execution_thread(execution_thread);\n-      }\n-      continue;\n+      // Set async instruction thread name and also recursively set async\n+      // computations.\n+      instr->set_async_execution_thread(execution_thread);\n     }\n     for (HloComputation* nested_called_computation :\n          instr->called_computations()) {\n-      SetThreadName(nested_called_computation, execution_thread,\n-                    skip_async_execution_thread_overwrite);\n+      SetThreadName(nested_called_computation, execution_thread);\n     }\n   }\n }\n@@ -423,8 +418,7 @@ HloInstruction* HloAsyncStartInstruction::AddCallOperand(\n void HloAsyncStartInstruction::set_async_execution_thread(\n     absl::string_view async_execution_thread) {\n   async_execution_thread_ = std::string(async_execution_thread);\n-  SetThreadName(async_wrapped_computation(), async_execution_thread,\n-                /*skip_async_execution_thread_overwrite=*/false);\n+  SetThreadName(async_wrapped_computation(), async_execution_thread);\n }\n \n HloInstructionProto HloAsyncStartInstruction::ToProto() const {\n@@ -1364,9 +1358,7 @@ HloCollectivePermuteInstruction::CloneWithNewOperandsImpl(\n     HloCloneContext* /*context*/) const {\n   if (dynamic_slice_sizes_list().empty()) {\n     return std::make_unique<HloCollectivePermuteInstruction>(\n-        opcode(), shape,\n-        absl::Span<HloInstruction* const>(new_operands.subspan(0, 1)),\n-        source_target_pairs(), channel_id());\n+        opcode(), shape, new_operands, source_target_pairs(), channel_id());\n   }\n   return std::make_unique<HloCollectivePermuteInstruction>(\n       opcode(), shape, new_operands[0], new_operands[1], new_operands[2],\n@@ -2181,11 +2173,9 @@ HloCallableInstruction::GetOrCloneCalledComputations(\n }\n \n void HloCallableInstruction::RecursivelySetComputationsThreadName(\n-    absl::string_view execution_thread,\n-    bool skip_async_execution_thread_overwrite) {\n+    absl::string_view execution_thread) {\n   for (HloComputation* comp : called_computations()) {\n-    SetThreadName(comp, execution_thread,\n-                  skip_async_execution_thread_overwrite);\n+    SetThreadName(comp, execution_thread);\n   }\n }\n "
        },
        {
            "sha": "a1f7694a6921ec2370ea4d213f4ef61e361297e4",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instructions.h",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1432,12 +1432,10 @@ class HloCallableInstruction : public HloInstruction {\n   HloInstruction* called_computation_root() const;\n \n   // Recursively sets all nested called computation to have thread name as\n-  // `execution_thread`. if `skip_async_execution_thread_overwrite` is true,\n-  // skip overwrite async instruction and its comptuations thread name\n-  // overwriting.\n-  void RecursivelySetComputationsThreadName(\n-      absl::string_view execution_thread,\n-      bool skip_async_execution_thread_overwrite);\n+  // `execution_thread`. Embedded computation (as opposed to ControlFlow)\n+  // computations thread name overwriting is skipped since callsite decides the\n+  // thread name.\n+  void RecursivelySetComputationsThreadName(absl::string_view execution_thread);\n \n   static bool ClassOf(const HloInstruction* hlo) {\n     return hlo->opcode() == HloOpcode::kFusion ||"
        },
        {
            "sha": "4324a2934fc7acfa45ed0e8d0670247395be44e9",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 8,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -144,6 +144,11 @@ HloModule::StackFrame HloModule::get_stack_frame(int id) const {\n   return stack_frame;\n }\n \n+void HloModule::Finalize() {\n+  instruction_name_uniquer_.reset();\n+  computation_name_uniquer_.reset();\n+}\n+\n HloComputation* HloModule::AddComputationInternal(\n     std::unique_ptr<HloComputation> computation, bool is_entry,\n     bool uniquify_identifiers, bool preserve_entry_layouts) {\n@@ -166,9 +171,9 @@ HloComputation* HloModule::AddComputationInternal(\n   }\n \n   if (uniquify_identifiers) {\n-    computation->UniquifyName(&computation_name_uniquer_);\n+    computation->UniquifyName(&computation_name_uniquer());\n     for (auto* instruction : computation->instructions()) {\n-      instruction->UniquifyName(&instruction_name_uniquer_);\n+      instruction->UniquifyName(&instruction_name_uniquer());\n     }\n \n     // Pick unique IDs for each instruction.\n@@ -185,9 +190,9 @@ HloComputation* HloModule::AddComputationInternal(\n     // for computations and instructions created later. Also, set the\n     // next_unique_id_ to the one greater than the max unique id of any\n     // instruction (or the computation) to avoid ID collisions.\n-    computation_name_uniquer_.GetUniqueName(computation->name());\n+    computation_name_uniquer().GetUniqueName(computation->name());\n     for (auto* instruction : computation->instructions()) {\n-      instruction_name_uniquer_.GetUniqueName(instruction->name());\n+      instruction_name_uniquer().GetUniqueName(instruction->name());\n       next_unique_id_ =\n           std::max(next_unique_id_, instruction->unique_id_64_bits() + 1);\n     }\n@@ -302,9 +307,9 @@ void HloModule::MoveComputationsFrom(HloModule* module,\n         /*uniquify_identifiers=*/false,\n         /*preserve_entry_layouts=*/false);\n     if (make_names_unique) {\n-      computation_raw_ptr->UniquifyName(&computation_name_uniquer_);\n+      computation_raw_ptr->UniquifyName(&computation_name_uniquer());\n       for (auto* instruction : computation_raw_ptr->instructions()) {\n-        instruction->UniquifyName(&instruction_name_uniquer_);\n+        instruction->UniquifyName(&instruction_name_uniquer());\n       }\n     }\n     // Pick unique IDs for each instruction.\n@@ -1498,8 +1503,10 @@ void AddEntryToOriginalValueRecoveryTable(\n     std::shared_ptr<OriginalValue> old_original_value,\n     std::shared_ptr<OriginalValue> new_original_value,\n     std::unique_ptr<HloModule> recovery_module) {\n-  original_value_recovery_table[*old_original_value->leaf_begin()->second] = {\n-      *new_original_value->leaf_begin()->second, std::move(recovery_module)};\n+  original_value_recovery_table\n+      [*old_original_value->original_arrays().begin()->second] = {\n+          *new_original_value->original_arrays().begin()->second,\n+          std::move(recovery_module)};\n }\n }  // namespace\n "
        },
        {
            "sha": "be54282ec73bdb2f698b0a9f37ce579560df1f11",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module.h",
            "status": "modified",
            "additions": 21,
            "deletions": 7,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -498,10 +498,18 @@ class HloModule {\n   uint64_t RandomNew64() const;\n \n   // Returns the NameUniquer for uniquing instruction names in this module.\n-  NameUniquer& instruction_name_uniquer() { return instruction_name_uniquer_; }\n+  NameUniquer& instruction_name_uniquer() {\n+    DCHECK(computation_name_uniquer_.has_value())\n+        << \"Can't get instruction name uniquer after HloModule was finalized\";\n+    return *instruction_name_uniquer_;\n+  }\n \n   // Returns the NameUniquer for uniquing computation names in this module.\n-  NameUniquer& computation_name_uniquer() { return computation_name_uniquer_; }\n+  NameUniquer& computation_name_uniquer() {\n+    DCHECK(computation_name_uniquer_.has_value())\n+        << \"Can't get computation name uniquer after HloModule was finalized\";\n+    return *computation_name_uniquer_;\n+  }\n \n   // Assign a new unique dense id for an instruction\n   int64_t NewUniqueInstructionId() {\n@@ -569,13 +577,13 @@ class HloModule {\n \n   void SetAndUniquifyInstrName(HloInstruction* instr, absl::string_view name) {\n     instr->SetAndSanitizeName(name);\n-    instr->UniquifyName(&instruction_name_uniquer_);\n+    instr->UniquifyName(&instruction_name_uniquer());\n   }\n \n   void SetAndUniquifyComputationName(HloComputation* computation,\n                                      absl::string_view name) {\n     computation->SetAndSanitizeName(name);\n-    computation->UniquifyName(&computation_name_uniquer_);\n+    computation->UniquifyName(&computation_name_uniquer());\n   }\n \n   absl::Status CheckUniqueNamesAndIdsForComputationsAndInstructions() const;\n@@ -736,6 +744,12 @@ class HloModule {\n   // Getter for the specific stack frame. Argument is a 1-based index.\n   StackFrame get_stack_frame(int id) const;\n \n+  // Finalizes this module by destroying internal data structures that might be\n+  // used for building or modifying the module. It is undefined behavior to\n+  // modify the module (add computations or instructions) after the call. Should\n+  // be called once, after HLO module is compiled to executable.\n+  void Finalize();\n+\n  private:\n   friend class HloComputation;\n \n@@ -766,9 +780,9 @@ class HloModule {\n   mutable absl::Mutex rng_mutex_;\n \n   // Unique name generator for computation and instruction names, which are\n-  // unique per module.\n-  NameUniquer computation_name_uniquer_{/*separator=*/\".\"};\n-  NameUniquer instruction_name_uniquer_{/*separator=*/\".\"};\n+  // unique per module. Will be reset to nullopt when Finalize() is called.\n+  std::optional<NameUniquer> computation_name_uniquer_{/*separator=*/\".\"};\n+  std::optional<NameUniquer> instruction_name_uniquer_{/*separator=*/\".\"};\n   int64_t next_unique_id_ = 0;\n \n   // Used to keep track of the next unique module id that should be assigned."
        },
        {
            "sha": "09fdaa298987f1e3df3568b7a9b7b1cf87558c94",
            "filename": "third_party/xla/xla/hlo/ir/hlo_opcode.cc",
            "status": "modified",
            "additions": 44,
            "deletions": 0,
            "changes": 44,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_opcode.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_opcode.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_opcode.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n \n #include <cstdint>\n #include <optional>\n+#include <ostream>\n #include <string>\n \n #include \"absl/container/flat_hash_map.h\"\n@@ -62,4 +63,47 @@ std::optional<int8_t> HloOpcodeArity(HloOpcode opcode) {\n   }\n }\n \n+std::string CallContextToString(CallContext context) {\n+  switch (context) {\n+    case CallContext::kNone:\n+      return \"kNone\";\n+    case CallContext::kControlFlow:\n+      return \"kControlFlow\";\n+    case CallContext::kEmbedded:\n+      return \"kEmbedded\";\n+    case CallContext::kBoth:\n+      return \"kBoth\";\n+  }\n+}\n+\n+std::ostream& operator<<(std::ostream& out, const CallContext& context) {\n+  out << CallContextToString(context);\n+  return out;\n+}\n+\n+CallContext GetInstructionCallContext(HloOpcode opcode) {\n+  switch (opcode) {\n+    case HloOpcode::kCall:\n+    case HloOpcode::kConditional:\n+    case HloOpcode::kWhile:\n+    case HloOpcode::kAsyncStart:\n+    case HloOpcode::kAsyncUpdate:\n+    case HloOpcode::kAsyncDone:\n+      return CallContext::kControlFlow;\n+    case HloOpcode::kAllReduce:\n+    case HloOpcode::kReduceScatter:\n+    case HloOpcode::kAllReduceStart:\n+    case HloOpcode::kMap:\n+    case HloOpcode::kReduce:\n+    case HloOpcode::kReduceWindow:\n+    case HloOpcode::kScatter:\n+    case HloOpcode::kSelectAndScatter:\n+    case HloOpcode::kSort:\n+    case HloOpcode::kFusion:\n+    case HloOpcode::kCustomCall:\n+      return CallContext::kEmbedded;\n+    default:\n+      return CallContext::kNone;\n+  }\n+}\n }  // namespace xla"
        },
        {
            "sha": "c7fe2de3774ed29ff2cdb21804ca7dbeb1353775",
            "filename": "third_party/xla/xla/hlo/ir/hlo_opcode.h",
            "status": "modified",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_opcode.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_opcode.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_opcode.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -237,6 +237,30 @@ static_assert(HloOpcodeCount() < 256,\n               \"HloOpcode is a uint8_t. You need to increase its size before \"\n               \"adding new op codes.\");\n \n+// The context in which a computation is called by another computation. This is\n+// decided by the opcode of the callsite instruction.\n+enum class CallContext : std::uint8_t {\n+  // In an embedded call context, the body of the function cannot allocate\n+  // buffers.\n+  kEmbedded,\n+\n+  // A control flow call context can allocate buffers.\n+  kControlFlow,\n+\n+  // A computation is called from both an embedded and control flow context.\n+  kBoth,\n+\n+  // During call graph construction kNone is used to indicate that the context\n+  // has not been determined. This is the top value for the context\n+  // lattice. After construction, no call sites or call graph nodes should have\n+  // this value.\n+  kNone\n+};\n+\n+std::string CallContextToString(CallContext context);\n+std::ostream& operator<<(std::ostream& out, const CallContext& context);\n+\n+CallContext GetInstructionCallContext(HloOpcode opcode);\n }  // namespace xla\n \n #endif  // XLA_HLO_IR_HLO_OPCODE_H_"
        },
        {
            "sha": "9a1a3795492d4c74c9c201b22a1aa73ddab37956",
            "filename": "third_party/xla/xla/hlo/ir/hlo_opcode_test.cc",
            "status": "modified",
            "additions": 38,
            "deletions": 0,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_opcode_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_opcode_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_opcode_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -57,6 +57,44 @@ TEST_P(HloOpcodeTestP, OpcodePropertiesNew) {\n   }\n }\n \n+TEST_F(HloOpcodeTestP, ControlFlowCallContext) {\n+  EXPECT_EQ(CallContext::kControlFlow,\n+            GetInstructionCallContext(HloOpcode::kCall));\n+  EXPECT_EQ(CallContext::kControlFlow,\n+            GetInstructionCallContext(HloOpcode::kConditional));\n+  EXPECT_EQ(CallContext::kControlFlow,\n+            GetInstructionCallContext(HloOpcode::kWhile));\n+  EXPECT_EQ(CallContext::kControlFlow,\n+            GetInstructionCallContext(HloOpcode::kAsyncStart));\n+  EXPECT_EQ(CallContext::kControlFlow,\n+            GetInstructionCallContext(HloOpcode::kAsyncUpdate));\n+  EXPECT_EQ(CallContext::kControlFlow,\n+            GetInstructionCallContext(HloOpcode::kAsyncDone));\n+}\n+\n+TEST_F(HloOpcodeTestP, EmbeddedCallContext) {\n+  EXPECT_EQ(CallContext::kEmbedded,\n+            GetInstructionCallContext(HloOpcode::kAllReduce));\n+  EXPECT_EQ(CallContext::kEmbedded,\n+            GetInstructionCallContext(HloOpcode::kReduceScatter));\n+  EXPECT_EQ(CallContext::kEmbedded,\n+            GetInstructionCallContext(HloOpcode::kAllReduceStart));\n+  EXPECT_EQ(CallContext::kEmbedded, GetInstructionCallContext(HloOpcode::kMap));\n+  EXPECT_EQ(CallContext::kEmbedded,\n+            GetInstructionCallContext(HloOpcode::kReduce));\n+  EXPECT_EQ(CallContext::kEmbedded,\n+            GetInstructionCallContext(HloOpcode::kReduceWindow));\n+  EXPECT_EQ(CallContext::kEmbedded,\n+            GetInstructionCallContext(HloOpcode::kScatter));\n+  EXPECT_EQ(CallContext::kEmbedded,\n+            GetInstructionCallContext(HloOpcode::kSelectAndScatter));\n+  EXPECT_EQ(CallContext::kEmbedded,\n+            GetInstructionCallContext(HloOpcode::kSort));\n+  EXPECT_EQ(CallContext::kEmbedded,\n+            GetInstructionCallContext(HloOpcode::kFusion));\n+  EXPECT_EQ(CallContext::kEmbedded,\n+            GetInstructionCallContext(HloOpcode::kCustomCall));\n+}\n INSTANTIATE_TEST_SUITE_P(HloOpcodeTestSuite, HloOpcodeTestP,\n                          testing::ValuesIn(GetAllCodes()));\n "
        },
        {
            "sha": "0229042175c29d3b852e22372c5a42d86bc94dcf",
            "filename": "third_party/xla/xla/hlo/ir/hlo_original_value.cc",
            "status": "modified",
            "additions": 60,
            "deletions": 53,
            "changes": 113,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -19,17 +19,23 @@ limitations under the License.\n #include <memory>\n #include <optional>\n #include <string>\n+#include <utility>\n #include <vector>\n \n #include \"absl/container/flat_hash_set.h\"\n+#include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_join.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/utils/pointer_utils.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/tuple_tree.h\"\n #include \"xla/xla_data.pb.h\"\n \n namespace xla {\n@@ -56,76 +62,76 @@ OriginalArray OriginalArray::FromProto(\n           ShapeIndex(original_array_proto.shape_index())};\n }\n \n-std::string OriginalValueToString(const OriginalValue& original_value,\n-                                  const Shape& shape,\n-                                  std::vector<int64_t>& shape_index) {\n-  std::string result;\n-  if (shape.IsTuple()) {\n-    if (shape.tuple_shapes().empty()) {\n-      return \"()\";\n-    }\n-    shape_index.push_back(0);\n-    absl::StrAppend(&result, \"(\",\n-                    OriginalValueToString(original_value, shape.tuple_shapes(0),\n-                                          shape_index));\n-    shape_index.pop_back();\n-    for (int64_t i = 1; i < shape.tuple_shapes().size(); ++i) {\n-      shape_index.push_back(i);\n-      absl::StrAppend(&result, \", \",\n-                      OriginalValueToString(\n-                          original_value, shape.tuple_shapes(i), shape_index));\n-      shape_index.pop_back();\n+namespace {\n+using Node = TupleTree<std::optional<OriginalArray>>::Node;\n+\n+std::string NodeToString(const Node& node) {\n+  if (node.IsLeaf()) {\n+    const std::optional<OriginalArray>& leaf_val = node.value();\n+    if (leaf_val.has_value()) {\n+      return absl::StrCat(\"{\", leaf_val->ToString(), \"}\");\n     }\n-    absl::StrAppend(&result, \")\");\n-    return result;\n+    return \"{}\";\n   }\n \n-  const auto& leaf = original_value.element(shape_index);\n-  if (leaf.has_value()) {\n-    absl::StrAppend(&result, \"{\", leaf->ToString(), \"}\");\n-  } else {\n-    absl::StrAppend(&result, \"{}\");\n+  if (node.children().empty()) {\n+    return \"()\";\n   }\n-  return result;\n+\n+  std::vector<std::string> children_str;\n+  for (const auto& child : node.children()) {\n+    children_str.push_back(NodeToString(child));\n+  }\n+\n+  return absl::StrCat(\"(\", absl::StrJoin(children_str, \", \"), \")\");\n }\n+}  // namespace\n \n std::string OriginalValue::ToString() const {\n-  std::vector<int64_t> shape_index;\n-  return OriginalValueToString(*this, shape(), shape_index);\n+  auto node_or = tree_.ToNode();\n+  CHECK_OK(node_or.status());\n+  return NodeToString(*node_or);\n }\n \n OriginalValueProto OriginalValue::ToProto() const {\n   OriginalValueProto original_value_proto;\n-  *original_value_proto.mutable_shape() = shape().ToProto();\n-  for (const auto& leaf : leaves()) {\n-    OriginalValueNodeProto* original_value_node_proto =\n-        original_value_proto.add_leaves();\n-    for (const auto& index : leaf.first) {\n-      original_value_node_proto->add_shape_index(index);\n+  tree_.ForEachElement([&original_value_proto](\n+                           const ShapeIndex& index,\n+                           const std::optional<OriginalArray>& value) {\n+    OriginalValueElementProto* original_value_node_proto =\n+        original_value_proto.add_elements();\n+    for (const auto& i : index) {\n+      original_value_node_proto->add_shape_index(i);\n     }\n-    *original_value_node_proto->mutable_original_array() =\n-        leaf.second->ToProto();\n-  }\n+    if (value.has_value()) {\n+      *original_value_node_proto->mutable_original_array() = value->ToProto();\n+    }\n+  });\n   return original_value_proto;\n }\n \n std::shared_ptr<OriginalValue> OriginalValue::FromProto(\n     const xla::OriginalValueProto& original_value_proto) {\n-  xla::Shape original_value_shape(\n-      Shape::FromProto(original_value_proto.shape()).value_or(Shape()));\n-  auto original_value = std::make_shared<OriginalValue>(original_value_shape);\n-\n-  for (const auto& leaf : original_value_proto.leaves()) {\n-    *original_value->mutable_element(ShapeIndex(leaf.shape_index())) =\n-        OriginalArray::FromProto(leaf.original_array());\n+  std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>> nodes;\n+  for (const auto& leaf : original_value_proto.elements()) {\n+    ShapeIndex index(leaf.shape_index());\n+    if (leaf.has_original_array()) {\n+      nodes.emplace_back(index,\n+                         OriginalArray::FromProto(leaf.original_array()));\n+    } else {\n+      // This case should not happen based on ToProto, but handling defensively.\n+      nodes.emplace_back(index, std::nullopt);\n+    }\n   }\n-  return original_value;\n+  return std::make_shared<OriginalValue>(\n+      TupleTree<std::optional<OriginalArray>>(absl::MakeSpan(nodes)));\n }\n \n std::shared_ptr<OriginalValue> OriginalValue::CreateFromInstruction(\n     const HloInstruction* instruction, absl::string_view prefix) {\n   std::shared_ptr<OriginalValue> original_value =\n-      std::make_shared<OriginalValue>(instruction->shape());\n+      std::make_shared<OriginalValue>(\n+          TupleTree<std::optional<OriginalArray>>(instruction->shape()));\n \n   if (instruction->opcode() == HloOpcode::kGetTupleElement) {\n     const auto* tuple = instruction->operand(0);\n@@ -148,7 +154,7 @@ std::shared_ptr<OriginalValue> OriginalValue::CreateFromInstruction(\n                                       {operand_number});\n     }\n   } else {\n-    for (auto& leaf : original_value->leaves()) {\n+    for (auto& leaf : original_value->mutable_original_arrays()) {\n       leaf.second = {absl::StrCat(prefix, instruction->name()), leaf.first};\n     }\n   }\n@@ -178,23 +184,24 @@ void CopyOriginalValue(const HloInstruction* src_instruction,\n   }\n \n   std::shared_ptr<OriginalValue> original_value_clone =\n-      std::make_shared<OriginalValue>(original_value->shape());\n+      std::make_shared<OriginalValue>();\n   original_value_clone->CopySubtreeFrom(*original_value, {}, {});\n   dest_instruction->set_original_value(original_value_clone);\n }\n \n void DeduplicateOriginalValues(HloModule* module) {\n-  absl::flat_hash_set<OriginalValuePointer> unique_original_values;\n+  absl::flat_hash_set<std::shared_ptr<OriginalValue>,\n+                      PointeeHash<OriginalValue>, PointeeEqual<OriginalValue>>\n+      unique_original_values;\n   for (HloComputation* computation : module->computations()) {\n     for (HloInstruction* instruction : computation->instructions()) {\n       if (std::shared_ptr<OriginalValue> original_value =\n               instruction->original_value()) {\n-        OriginalValuePointer original_value_ptr(original_value);\n-        auto p = unique_original_values.insert(original_value_ptr);\n+        auto p = unique_original_values.insert(original_value);\n         if (!p.second) {\n           // Reassign the pointer with the existing identical object and release\n           // the duplicate.\n-          instruction->set_original_value(p.first->original_value);\n+          instruction->set_original_value(*p.first);\n         }\n       }\n     }"
        },
        {
            "sha": "35359b60aadae0460c1f477b918f14461797a58f",
            "filename": "third_party/xla/xla/hlo/ir/hlo_original_value.h",
            "status": "modified",
            "additions": 47,
            "deletions": 51,
            "changes": 98,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -16,12 +16,16 @@ limitations under the License.\n #ifndef XLA_HLO_IR_HLO_ORIGINAL_VALUE_H_\n #define XLA_HLO_IR_HLO_ORIGINAL_VALUE_H_\n \n+#include <algorithm>\n+#include <memory>\n #include <optional>\n #include <string>\n #include <utility>\n \n-#include \"xla/shape_tree.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/tuple_tree.h\"\n+#include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n \n namespace xla {\n@@ -56,71 +60,63 @@ struct OriginalArray {\n \n // The information of an HLO value produced by an instruction in an unoptimized\n // HLO module.\n-class OriginalValue : public ShapeTree<std::optional<OriginalArray>> {\n+class OriginalValue {\n  public:\n-  explicit OriginalValue(Shape shape) : ShapeTree(std::move(shape)) {}\n+  OriginalValue() = default;\n+  explicit OriginalValue(\n+      TupleTree<std::optional<OriginalArray>>::Node&& root_node)\n+      : tree_(std::move(root_node)) {}\n+  explicit OriginalValue(TupleTree<std::optional<OriginalArray>>&& tree)\n+      : tree_(std::move(tree)) {}\n   std::string ToString() const;\n   OriginalValueProto ToProto() const;\n   static std::shared_ptr<OriginalValue> FromProto(\n       const xla::OriginalValueProto& original_value_proto);\n   static std::shared_ptr<OriginalValue> CreateFromInstruction(\n       const HloInstruction* instruction, absl::string_view prefix = \"\");\n-};\n \n-struct OriginalValuePointer {\n-  OriginalValuePointer() = default;\n-  explicit OriginalValuePointer(\n-      std::shared_ptr<xla::OriginalValue> original_value) {\n-    this->original_value = std::move(original_value);\n+  const std::optional<OriginalArray>& original_array(\n+      ShapeIndexView index) const {\n+    return tree_.element(index);\n+  }\n+  std::optional<OriginalArray>* mutable_original_array(ShapeIndexView index) {\n+    return tree_.mutable_element(index);\n   }\n \n-  friend bool operator==(const OriginalValuePointer& lhs,\n-                         const OriginalValuePointer& rhs) {\n-    // Returns if any original value is empty.\n-    if (!lhs.original_value || !rhs.original_value) {\n-      return !lhs.original_value == !rhs.original_value;\n-    }\n-    // Returns if the original values have different shapes.\n-    if (!xla::ShapeUtil::Compatible(lhs.original_value->shape(),\n-                                    rhs.original_value->shape())) {\n-      return false;\n-    }\n-    // Compares nodes.\n-    for (auto& leaf : lhs.original_value->leaves()) {\n-      xla::ShapeIndex index = leaf.first;\n-      std::optional<const xla::OriginalArray> lhs_original_array = leaf.second;\n-      std::optional<const xla::OriginalArray> rhs_original_array =\n-          rhs.original_value->element(index);\n-      if (!lhs_original_array.has_value() || !rhs_original_array.has_value() ||\n-          *lhs_original_array != *rhs_original_array) {\n-        return false;\n-      }\n-    }\n-    return true;\n+  // Returns a const iterator over the pairs of ShapeIndex and\n+  // std::optional<OriginalArray>.\n+  auto original_arrays() const { return tree_.leaves(); }\n+  // Returns a non-const iterator over the pairs of ShapeIndex and\n+  // std::optional<OriginalArray>.\n+  auto mutable_original_arrays() { return tree_.leaves(); }\n+\n+  void CopySubtreeFrom(const OriginalValue& other, const ShapeIndex& src_index,\n+                       const ShapeIndex& dst_index) {\n+    tree_.CopySubtreeFrom(other.tree_, src_index, dst_index);\n+  }\n+\n+  bool operator==(const OriginalValue& other) const {\n+    auto this_original_arrays = original_arrays();\n+    auto other_original_arrays = other.original_arrays();\n+    return std::equal(this_original_arrays.begin(), this_original_arrays.end(),\n+                      other_original_arrays.begin(),\n+                      other_original_arrays.end());\n+  }\n+\n+  bool operator!=(const OriginalValue& other) const {\n+    return !(*this == other);\n   }\n \n   template <typename H>\n-  friend H AbslHashValue(H h, const OriginalValuePointer& value) {\n-    // Ignore layout information, which is added to shapes during the HLO\n-    // transformation.\n-    h = xla::Shape::template Hash<H, false /*kIsLayoutSensitive*/>(\n-        std::move(h), value.original_value->shape());\n-    value.original_value->ForEachElement(\n-        [&h, &value](const xla::ShapeIndex& shape_index,\n-                     const std::optional<xla::OriginalArray>& original_array) {\n-          if (!value.original_value->IsLeaf(shape_index)) {\n-            return;\n-          }\n-          if (!original_array) {\n-            return;\n-          }\n-          h = H::combine(std::move(h), original_array->instruction_name,\n-                         original_array->shape_index);\n-        });\n-    return std::move(h);\n+  friend H AbslHashValue(H h, const OriginalValue& value) {\n+    for (const auto& leaf : value.original_arrays()) {\n+      h = H::combine(std::move(h), leaf.first, leaf.second);\n+    }\n+    return h;\n   }\n \n-  std::shared_ptr<xla::OriginalValue> original_value = nullptr;\n+ private:\n+  TupleTree<std::optional<OriginalArray>> tree_;\n };\n \n // Copies the original value of the source to the destination instruction. This"
        },
        {
            "sha": "47854f989027fcb25fa7c8c6b14edd092bce0ccb",
            "filename": "third_party/xla/xla/hlo/ir/hlo_original_value_test.cc",
            "status": "added",
            "additions": 329,
            "deletions": 0,
            "changes": 329,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,329 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/hlo/ir/hlo_original_value.h\"\n+\n+#include <memory>\n+#include <optional>\n+#include <utility>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/hash/hash_testing.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/shape_util.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tuple_tree.h\"\n+#include \"xla/xla_data.pb.h\"\n+\n+namespace xla {\n+namespace {\n+\n+using ::testing::ElementsAre;\n+using ::testing::Eq;\n+using ::testing::Optional;\n+using Node = TupleTree<std::optional<OriginalArray>>::Node;\n+\n+TEST(OriginalArrayTest, ToString) {\n+  OriginalArray array1{\"inst1\", {}};\n+  EXPECT_EQ(array1.ToString(), \"\\\"inst1\\\"\");\n+\n+  OriginalArray array2{\"inst2\", {1, 2}};\n+  EXPECT_EQ(array2.ToString(), \"\\\"inst2\\\" {1,2}\");\n+}\n+\n+TEST(OriginalArrayTest, ProtoSerde) {\n+  OriginalArray array1{\"inst1\", {}};\n+  OriginalArrayProto proto1 = array1.ToProto();\n+  EXPECT_EQ(proto1.instruction_name(), \"inst1\");\n+  EXPECT_TRUE(proto1.shape_index().empty());\n+  OriginalArray array1_from_proto = OriginalArray::FromProto(proto1);\n+  EXPECT_EQ(array1_from_proto, array1);\n+\n+  OriginalArray array2{\"inst2\", {1, 2}};\n+  OriginalArrayProto proto2 = array2.ToProto();\n+  EXPECT_EQ(proto2.instruction_name(), \"inst2\");\n+  EXPECT_THAT(proto2.shape_index(), ElementsAre(1, 2));\n+  OriginalArray array2_from_proto = OriginalArray::FromProto(proto2);\n+  EXPECT_EQ(array2_from_proto, array2);\n+}\n+\n+TEST(OriginalArrayTest, EqualityAndHashing) {\n+  OriginalArray array1{\"inst1\", {}};\n+  OriginalArray array2{\"inst1\", {}};\n+  OriginalArray array3{\"inst2\", {}};\n+  OriginalArray array4{\"inst1\", {1}};\n+  OriginalArray array5{\"inst1\", {1}};\n+\n+  EXPECT_EQ(array1, array2);\n+  EXPECT_NE(array1, array3);\n+  EXPECT_NE(array1, array4);\n+  EXPECT_EQ(array4, array5);\n+\n+  EXPECT_TRUE(absl::VerifyTypeImplementsAbslHashCorrectly({\n+      array1,\n+      array2,\n+      array3,\n+      array4,\n+      array5,\n+  }));\n+}\n+\n+TEST(OriginalValueTest, ToStringScalar) {\n+  OriginalValue value(Node::Leaf(OriginalArray{\"inst1\", {}}));\n+  EXPECT_EQ(value.ToString(), \"{\\\"inst1\\\"}\");\n+}\n+\n+TEST(OriginalValueTest, ToStringTuple) {\n+  OriginalValue value(\n+      Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                   Node::Leaf(OriginalArray{\"inst2\", {2}}),\n+                   Node::Tuple({Node::Leaf(OriginalArray{\"inst3\", {3}}),\n+                                Node::Leaf(std::nullopt)})}));\n+  EXPECT_EQ(value.ToString(),\n+            \"({\\\"inst1\\\" {1}}, {\\\"inst2\\\" {2}}, ({\\\"inst3\\\" {3}}, {}))\");\n+}\n+\n+TEST(OriginalValueTest, ProtoSerde) {\n+  OriginalValue value(Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                                   Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n+\n+  OriginalValueProto proto = value.ToProto();\n+  std::shared_ptr<OriginalValue> value_from_proto =\n+      OriginalValue::FromProto(proto);\n+  EXPECT_EQ(*value_from_proto, value);\n+\n+  // Test with nullopt\n+  OriginalValue value_with_null(Node::Tuple(\n+      {Node::Leaf(OriginalArray{\"inst1\", {1}}), Node::Leaf(std::nullopt)}));\n+  OriginalValueProto proto_with_null = value_with_null.ToProto();\n+  std::shared_ptr<OriginalValue> value_with_null_from_proto =\n+      OriginalValue::FromProto(proto_with_null);\n+  EXPECT_EQ(value_with_null_from_proto->ToString(), value_with_null.ToString());\n+  EXPECT_EQ(*value_with_null_from_proto, value_with_null);\n+}\n+\n+TEST(OriginalValueTest, ElementAccess) {\n+  OriginalValue value(Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                                   Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n+\n+  EXPECT_THAT(value.original_array({0}),\n+              Optional(Eq(OriginalArray{\"inst1\", {1}})));\n+  EXPECT_THAT(value.original_array({1}),\n+              Optional(Eq(OriginalArray{\"inst2\", {2}})));\n+\n+  *value.mutable_original_array({1}) = OriginalArray{\"inst3\", {3}};\n+  EXPECT_THAT(value.original_array({1}),\n+              Optional(Eq(OriginalArray{\"inst3\", {3}})));\n+}\n+\n+TEST(OriginalValueTest, Elements) {\n+  OriginalValue value(\n+      Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                   Node::Tuple({Node::Leaf(OriginalArray{\"inst2\", {2}})}),\n+                   Node::Leaf(OriginalArray{\"inst3\", {3}})}));\n+\n+  std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>> elements;\n+  for (const auto& element : value.mutable_original_arrays()) {\n+    elements.push_back(element);\n+  }\n+\n+  EXPECT_EQ(elements.size(), 3);\n+  EXPECT_EQ(elements[0].first, ShapeIndex({0}));\n+  EXPECT_THAT(elements[0].second, Optional(Eq(OriginalArray{\"inst1\", {1}})));\n+  EXPECT_EQ(elements[1].first, ShapeIndex({1, 0}));\n+  EXPECT_THAT(elements[1].second, Optional(Eq(OriginalArray{\"inst2\", {2}})));\n+  EXPECT_EQ(elements[2].first, ShapeIndex({2}));\n+  EXPECT_THAT(elements[2].second, Optional(Eq(OriginalArray{\"inst3\", {3}})));\n+}\n+\n+TEST(OriginalValueTest, CopySubtreeFrom) {\n+  OriginalValue src(\n+      Node::Tuple({Node::Leaf(OriginalArray{\"src1\", {1}}),\n+                   Node::Tuple({Node::Leaf(OriginalArray{\"src2\", {2}}),\n+                                Node::Leaf(OriginalArray{\"src3\", {3}})})}));\n+\n+  OriginalValue dst;\n+  dst.CopySubtreeFrom(src, {1}, {});\n+  EXPECT_EQ(dst.ToString(), \"({\\\"src2\\\" {2}}, {\\\"src3\\\" {3}})\");\n+\n+  dst.CopySubtreeFrom(src, {0}, {});\n+  EXPECT_EQ(dst.ToString(), \"{\\\"src1\\\" {1}}\");\n+}\n+\n+TEST(OriginalValueTest, EqualityAndHashing) {\n+  OriginalValue value1(Node::Leaf(OriginalArray{\"inst1\", {}}));\n+  OriginalValue value2(Node::Leaf(OriginalArray{\"inst1\", {}}));\n+  OriginalValue value3(Node::Leaf(OriginalArray{\"inst2\", {}}));\n+  OriginalValue value4(Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                                    Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n+  OriginalValue value5(Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                                    Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n+\n+  EXPECT_EQ(value1, value2);\n+  EXPECT_NE(value1, value3);\n+  EXPECT_NE(value1, value4);\n+  EXPECT_EQ(value4, value5);\n+\n+  EXPECT_TRUE(absl::VerifyTypeImplementsAbslHashCorrectly({\n+      value1,\n+      value2,\n+      value3,\n+      value4,\n+      value5,\n+  }));\n+}\n+\n+using OriginalValueHloTest = HloHardwareIndependentTestBase;\n+\n+TEST_F(OriginalValueHloTest, CreateFromInstruction) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  p0 = f32[] parameter(0)\n+  p1 = f32[] parameter(1)\n+  ROOT tuple = (f32[], f32[]) tuple(p0, p1)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = module->entry_computation()->parameter_instruction(0);\n+  HloInstruction* p1 = module->entry_computation()->parameter_instruction(1);\n+  HloInstruction* tuple = module->entry_computation()->root_instruction();\n+\n+  p0->set_original_value(OriginalValue::CreateFromInstruction(p0, \"prefix_\"));\n+  p1->set_original_value(OriginalValue::CreateFromInstruction(p1, \"prefix_\"));\n+  tuple->set_original_value(OriginalValue::CreateFromInstruction(tuple));\n+\n+  EXPECT_EQ(p0->original_value()->ToString(), \"{\\\"prefix_p0\\\"}\");\n+  EXPECT_EQ(p1->original_value()->ToString(), \"{\\\"prefix_p1\\\"}\");\n+  EXPECT_EQ(tuple->original_value()->ToString(),\n+            \"({\\\"prefix_p0\\\"}, {\\\"prefix_p1\\\"})\");\n+}\n+\n+TEST_F(OriginalValueHloTest, CreateFromInstructionGTE) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  p0 = f32[] parameter(0)\n+  p1 = f32[] parameter(1)\n+  tuple = (f32[], f32[]) tuple(p0, p1)\n+  ROOT gte = f32[] get-tuple-element(tuple), index=1\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = module->entry_computation()->parameter_instruction(0);\n+  HloInstruction* p1 = module->entry_computation()->parameter_instruction(1);\n+  HloInstruction* tuple = FindInstruction(module.get(), \"tuple\");\n+  HloInstruction* gte = module->entry_computation()->root_instruction();\n+\n+  p0->set_original_value(OriginalValue::CreateFromInstruction(p0));\n+  p1->set_original_value(OriginalValue::CreateFromInstruction(p1));\n+  tuple->set_original_value(OriginalValue::CreateFromInstruction(tuple));\n+  gte->set_original_value(OriginalValue::CreateFromInstruction(gte));\n+\n+  EXPECT_EQ(gte->original_value()->ToString(), \"{\\\"p1\\\"}\");\n+}\n+\n+TEST_F(OriginalValueHloTest, CreateFromInstructionTuple) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+ ROOT p0 = (f32[], f32[]) parameter(0)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = module->entry_computation()->parameter_instruction(0);\n+  p0->set_original_value(OriginalValue::CreateFromInstruction(p0));\n+\n+  EXPECT_EQ(p0->original_value()->ToString(), \"({\\\"p0\\\" {0}}, {\\\"p0\\\" {1}})\");\n+}\n+\n+TEST_F(OriginalValueHloTest, CopyOriginalValue) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  ROOT p0 = f32[] parameter(0)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = module->entry_computation()->parameter_instruction(0);\n+  p0->set_original_value(OriginalValue::CreateFromInstruction(p0));\n+\n+  std::unique_ptr<HloInstruction> clone = p0->Clone();\n+\n+  CopyOriginalValue(p0, clone.get(), /*clone=*/false);\n+  EXPECT_EQ(p0->original_value(), clone->original_value());\n+\n+  CopyOriginalValue(p0, clone.get(), /*clone=*/true);\n+  EXPECT_NE(p0->original_value(), clone->original_value());\n+  EXPECT_EQ(*p0->original_value(), *clone->original_value());\n+}\n+\n+TEST_F(OriginalValueHloTest, DeduplicateOriginalValues) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  p0 = f32[] parameter(0)\n+  p1 = f32[] parameter(1)\n+  n0 = f32[] negate(p0)\n+  n1 = f32[] negate(p1)\n+  ROOT add = f32[] add(n0, n1)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n+  HloInstruction* p1 = FindInstruction(module.get(), \"p1\");\n+  HloInstruction* n0 = FindInstruction(module.get(), \"n0\");\n+  HloInstruction* n1 = FindInstruction(module.get(), \"n1\");\n+\n+  auto value1 =\n+      std::make_shared<OriginalValue>(Node::Leaf(OriginalArray{\"instA\", {}}));\n+  auto value2 =\n+      std::make_shared<OriginalValue>(Node::Leaf(OriginalArray{\"instB\", {}}));\n+  auto value1_dup =\n+      std::make_shared<OriginalValue>(Node::Leaf(OriginalArray{\"instA\", {}}));\n+\n+  p0->set_original_value(value1);\n+  p1->set_original_value(value2);\n+  n0->set_original_value(value1_dup);\n+  n1->set_original_value(value2);  // Intentional same shared_ptr\n+\n+  EXPECT_NE(p0->original_value(),\n+            n0->original_value());  // Different shared_ptr\n+  EXPECT_EQ(*p0->original_value(), *n0->original_value());  // Same value\n+  EXPECT_EQ(p1->original_value(), n1->original_value());    // Same shared_ptr\n+\n+  DeduplicateOriginalValues(module.get());\n+\n+  EXPECT_EQ(p0->original_value(),\n+            n0->original_value());  // Should be same shared_ptr now\n+  EXPECT_EQ(p1->original_value(), n1->original_value());\n+  EXPECT_NE(p0->original_value(), p1->original_value());\n+}\n+\n+}  // namespace\n+}  // namespace xla"
        },
        {
            "sha": "828fa836f853dec7626d0c57c8d7878067fe33cc",
            "filename": "third_party/xla/xla/hlo/ir/hlo_sharding.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -912,6 +912,9 @@ absl::Status HloSharding::ValidateNonTuple(\n   if (proto.type() == OpSharding::MANUAL) {\n     return std::move(Manual(metadata).SetShardGroupFromProto(proto));\n   }\n+  if (proto.type() == OpSharding::UNREDUCED) {\n+    return std::move(Unreduced(metadata).SetShardGroupFromProto(proto));\n+  }\n   if (proto.type() == OpSharding::UNKNOWN) {\n     return std::move(Unknown(metadata).SetShardGroupFromProto(proto));\n   }\n@@ -1040,6 +1043,8 @@ OpSharding HloSharding::ToProto() const {\n     result.set_type(OpSharding::MAXIMAL);\n   } else if (IsManual()) {\n     result.set_type(OpSharding::MANUAL);\n+  } else if (IsUnreduced()) {\n+    result.set_type(OpSharding::UNREDUCED);\n   } else if (IsUnknown()) {\n     result.set_type(OpSharding::UNKNOWN);\n   } else {"
        },
        {
            "sha": "05f85c9472fb72b1da613fce99ad4f26294775ac",
            "filename": "third_party/xla/xla/hlo/ir/hlo_sharding.h",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -522,6 +522,15 @@ class HloSharding {\n     return -1;\n   }\n \n+  // Returns the unreduced subgroup dim, or -1 if it doesn't exist.\n+  int64_t SubgroupUnreducedDim() const {\n+    auto it = absl::c_find(subgroup_types_, OpSharding::UNREDUCED);\n+    if (it != subgroup_types_.end()) {\n+      return (it - subgroup_types_.begin()) + TiledDataRank();\n+    }\n+    return -1;\n+  }\n+\n   // Returns the data rank for tiled sharding. It doesn't include subgroup dims.\n   int64_t TiledDataRank() const {\n     CHECK(IsTiled());"
        },
        {
            "sha": "4b534ff3fe1de22cf478d9db56bbb7717349e838",
            "filename": "third_party/xla/xla/hlo/parser/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -33,6 +33,7 @@ cc_library(\n         \"//xla:literal_util\",\n         \"//xla:shape_layout\",\n         \"//xla:shape_util\",\n+        \"//xla:tuple_tree\",\n         \"//xla:types\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n@@ -77,15 +78,13 @@ xla_cc_test(\n         \"//xla:window_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/builder:xla_builder\",\n-        \"//xla/hlo/ir:collective_op_group_mode\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:pattern_matcher_gmock\",\n         \"//xla/hlo/testlib:verified_hlo_module\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service:pattern_matcher\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:errors\",\n-        \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n         \"//xla/tsl/platform:test_main\","
        },
        {
            "sha": "ff8a5adfb735c30c327394f29fbbe6d41446cdb7",
            "filename": "third_party/xla/xla/hlo/parser/hlo_parser.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 22,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -80,6 +80,7 @@ limitations under the License.\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/logging.h\"\n #include \"xla/tsl/platform/status.h\"\n+#include \"xla/tuple_tree.h\"\n #include \"xla/types.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -270,8 +271,7 @@ class HloParserImpl : public HloParser {\n   absl::StatusOr<std::vector<Shape>> ParseShapeListOnly();\n   absl::StatusOr<Layout> ParseLayoutOnly();\n   absl::StatusOr<HloSharding> ParseShardingOnly();\n-  absl::StatusOr<std::shared_ptr<OriginalValue>> ParseOriginalValueOnly(\n-      Shape shape);\n+  absl::StatusOr<std::shared_ptr<OriginalValue>> ParseOriginalValueOnly();\n   absl::StatusOr<FrontendAttributes> ParseFrontendAttributesOnly();\n   absl::StatusOr<StatisticsViz> ParseStatisticsVizOnly();\n   absl::StatusOr<std::vector<bool>> ParseParameterReplicationOnly();\n@@ -592,7 +592,9 @@ class HloParserImpl : public HloParser {\n                   uint64_t lexer_skip_mask = kNoneMask);\n   bool ParseUnsignedIntegerType(PrimitiveType* primitive_type);\n   bool ParseOriginalArray(OriginalArray& original_array);\n-  bool ParseOriginalValue(std::shared_ptr<OriginalValue>& original_value);\n+  bool ParseOriginalValueArrays(\n+      std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>>&\n+          original_value_arrays);\n   bool ParseOriginalValueRecoveryTable(\n       OriginalValueRecoveryTable& original_value_recovery_table);\n   bool ParseCollectiveOpGroupMode(CollectiveOpGroupMode* result);\n@@ -5237,16 +5239,12 @@ bool HloParserImpl::ParseAttributeHelper(\n         return true;\n       }\n       case AttrTy::kOriginalValue: {\n-        // By the time this attribute is added, the instruction shape should\n-        // have been inferred.\n-        if (!shape) {\n-          return TokenError(\"expects instruction shape\");\n-        }\n-        std::shared_ptr<OriginalValue> result =\n-            std::make_shared<OriginalValue>(*shape);\n-        if (!ParseOriginalValue(result)) {\n+        std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>> arrays;\n+        if (!ParseOriginalValueArrays(arrays)) {\n           return false;\n         }\n+        auto result = std::make_shared<OriginalValue>(\n+            TupleTree<std::optional<OriginalArray>>(absl::MakeSpan(arrays)));\n         static_cast<optional<std::shared_ptr<OriginalValue>>*>(attr_out_ptr)\n             ->emplace(std::move(result));\n         return true;\n@@ -6627,8 +6625,9 @@ bool HloParserImpl::ParseOriginalArray(OriginalArray& original_array) {\n }\n \n // original_value ::= '{' '('* original_array [','] ')'* | original_value '}'\n-bool HloParserImpl::ParseOriginalValue(\n-    std::shared_ptr<OriginalValue>& original_value) {\n+bool HloParserImpl::ParseOriginalValueArrays(\n+    std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>>&\n+        original_value_arrays) {\n   VLOG(kDebugLevel) << \"ParseOriginalValue\";\n \n   if (!ParseToken(TokKind::kLbrace, \"Expects '{'\")) {\n@@ -6651,13 +6650,15 @@ bool HloParserImpl::ParseOriginalValue(\n       if (!ParseOriginalArray(original_array)) {\n         return false;\n       }\n-      if (!original_array.instruction_name.empty()) {\n-        *original_value->mutable_element(leaf_shape_index) = original_array;\n-      } else {\n+      if (original_array.instruction_name.empty()) {\n         // The original value is not expected to have any leaf without values.\n         // However we should not fail the execution here. This should\n         // be done in HloVerifier instead.\n         LOG(WARNING) << \"Found an empty leaf node in an original value\";\n+        original_value_arrays.emplace_back(leaf_shape_index, std::nullopt);\n+      } else {\n+        original_value_arrays.emplace_back(leaf_shape_index,\n+                                           std::move(original_array));\n       }\n     } else {\n       return false;\n@@ -7319,13 +7320,14 @@ absl::StatusOr<HloSharding> HloParserImpl::ParseShardingOnly() {\n }\n \n absl::StatusOr<std::shared_ptr<OriginalValue>>\n-HloParserImpl::ParseOriginalValueOnly(Shape shape) {\n+HloParserImpl::ParseOriginalValueOnly() {\n   lexer_.Lex();\n-  std::shared_ptr<OriginalValue> original_value =\n-      std::make_shared<OriginalValue>(shape);\n-  if (!ParseOriginalValue(original_value)) {\n+  std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>> arrays;\n+  if (!ParseOriginalValueArrays(arrays)) {\n     return InvalidArgument(\"Syntax error:\\n%s\", GetError());\n   }\n+  auto original_value = std::make_shared<OriginalValue>(\n+      TupleTree<std::optional<OriginalArray>>(absl::MakeSpan(arrays)));\n   if (lexer_.GetKind() != TokKind::kEof) {\n     return InvalidArgument(\"Syntax error:\\nExtra content after original value\");\n   }\n@@ -7526,9 +7528,9 @@ absl::StatusOr<HloSharding> ParseSharding(absl::string_view str) {\n }\n \n absl::StatusOr<std::shared_ptr<OriginalValue>> ParseOriginalValue(\n-    absl::string_view str, const Shape& shape) {\n+    absl::string_view str) {\n   HloParserImpl parser(str);\n-  return parser.ParseOriginalValueOnly(shape);\n+  return parser.ParseOriginalValueOnly();\n }\n \n absl::StatusOr<FrontendAttributes> ParseFrontendAttributes("
        },
        {
            "sha": "9e53d4da4bc0918de95fc8efbb77a93d48a91c68",
            "filename": "third_party/xla/xla/hlo/parser/hlo_parser.h",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -83,10 +83,9 @@ absl::StatusOr<std::unique_ptr<HloModule>> ParseAndReturnUnverifiedModule(\n // \"{replicated}\".\n absl::StatusOr<HloSharding> ParseSharding(absl::string_view str);\n \n-// Parses original value from str. The shape is used to initialize the original\n-// value.\n+// Parses original value from str.\n absl::StatusOr<std::shared_ptr<OriginalValue>> ParseOriginalValue(\n-    absl::string_view str, const Shape& shape);\n+    absl::string_view str);\n \n // Parses frontend attributes from str. str is supposed to contain the body of\n // the frontend attributes , i.e. just the rhs of the"
        },
        {
            "sha": "8c73736af3ae8dda01cf53b20211b2b29e9f6f22",
            "filename": "third_party/xla/xla/hlo/parser/hlo_parser_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -53,7 +53,6 @@ limitations under the License.\n #include \"xla/shape_util.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/errors.h\"\n-#include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n #include \"xla/tsl/util/proto/proto_matchers.h\"\n@@ -5646,9 +5645,11 @@ ENTRY %test {\n \n \n )\";\n-  EXPECT_THAT(ParseAndReturnUnverifiedModule(hlo_string).status(),\n-              absl_testing::StatusIs(tsl::error::INVALID_ARGUMENT,\n-                                     HasSubstr(\"expects instruction shape\")));\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnUnverifiedModule(hlo_string));\n+\n+  ExpectHasSubstr(module->ToString(HloPrintOptions::ShortParsable()),\n+                  \"origin={{\\\"v\\\"}}\");\n }\n \n TEST_F(HloParserTest, EmptyLeafInOriginalValue) {"
        },
        {
            "sha": "cf20a636125ce46c6a39915d9e92538198c7deef",
            "filename": "third_party/xla/xla/hlo/tools/hlo_diff/render/hlo_gumgraph_html_renderer.cc",
            "status": "modified",
            "additions": 126,
            "deletions": 12,
            "changes": 138,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Frender%2Fhlo_gumgraph_html_renderer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Frender%2Fhlo_gumgraph_html_renderer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Frender%2Fhlo_gumgraph_html_renderer.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -219,6 +219,7 @@ std::string PrintCss() {\n \n     span.hlo-instruction {\n       display: inline-block;\n+      cursor: pointer;\n     }\n     span.hlo-instruction:hover {\n       border: 2px solid #4285F4;\n@@ -239,7 +240,12 @@ std::string PrintCss() {\n     span.temp-highlight {\n       background-color: #a8c7fa;\n       opacity: 0.7;\n-      transition: background-color 0.5s ease-out;\n+      animation: breathe-highlight 1s infinite alternate;\n+    }\n+    @keyframes breathe-highlight {\n+      0% { opacity: 0.7; }\n+      50% { opacity: 0.9; }\n+      100% { opacity: 0.7; }\n     }\n \n     .hlo-instruction.hidden {\n@@ -259,6 +265,38 @@ std::string PrintCss() {\n       transform: translateY(-1px) scale(1.02);\n     }\n \n+    /* Styles for the system message pop-up */\n+    .system-message-container {\n+        /* Position fixed at the bottom of the viewport */\n+        position: fixed;\n+        bottom: 7px;\n+        left: 50%;\n+        transform: translateX(-50%) translateY(100%);\n+\n+        /* Appearance and transitions */\n+        background-color: #F5F3FF;\n+        border: 2px solid #8B5CF6;\n+        opacity: 0;\n+        visibility: hidden;\n+        transition: transform 0.3s ease-in-out, opacity 0.3s ease-in-out, visibility 0s 0.3s;\n+        z-index: 1000;\n+    }\n+\n+    /* Class to show the message */\n+    .system-message-container.show-message {\n+        transform: translateX(-50%) translateY(0);\n+        opacity: 1;\n+        visibility: visible;\n+        transition: transform 0.3s ease-in-out, opacity 0.3s ease-in-out;\n+    }\n+\n+    .system-message-container.show-message span {\n+      color: #4C1D95;\n+      font-weight: 500;\n+      font-size: 16px;\n+      padding: 1.5rem;\n+    }\n+\n     </style>\n   )html\";\n }\n@@ -282,11 +320,26 @@ std::string PrintJavascript() {\n std::string PrintJavascriptForHoverEvent() {\n   return R\"html(\n   <script>\n+  function ShowSystemMessage(message) {\n+      const messageContainer = document.getElementById('system-message');\n+      const messageText = messageContainer.querySelector('span');\n+      messageText.textContent = message;\n+\n+      // Show the message pop-up\n+      messageContainer.classList.add('show-message');\n+\n+      // Automatically hide the message after 3 seconds\n+      setTimeout(() => {\n+      messageContainer.classList.remove('show-message');\n+      }, 3000);\n+  }\n+\n   const allSpans = document.querySelectorAll('span[data-diffid]');\n   allSpans.forEach(span => {\n       span.addEventListener('mouseover', handleMouseOver);\n       span.addEventListener('mouseout', handleMouseOut);\n       span.addEventListener('click', handleSpanClick);\n+      span.addEventListener('dblclick', handleSpanDoubleClick);\n   });\n   function handleMouseOver(event) {\n       const diffId = event.target.getAttribute('data-diffid');\n@@ -352,7 +405,62 @@ std::string PrintJavascriptForHoverEvent() {\n               targetSpan.classList.add('temp-highlight');\n               setTimeout(() => {\n                   targetSpan.classList.remove('temp-highlight');\n-              }, 1500); // Remove highlight after 1.5 seconds\n+              }, 2000); // Remove highlight after 2 seconds\n+          } else {\n+              ShowSystemMessage(\"Corresponding instruction is in another computation, double click to jump to it.\");\n+          }\n+      }\n+  }\n+\n+  function handleSpanDoubleClick(event) {\n+      const diffId = event.target.getAttribute('data-diffid');\n+      if (!diffId) {\n+          return;\n+      }\n+\n+      const clickedSpan = event.target;\n+      const clickedPre = clickedSpan.closest('.hlo-textbox').querySelector('pre');\n+      if (!clickedPre) return;\n+\n+      const idParts = clickedPre.id.split('-');\n+      const fingerprint = idParts[0];\n+      const isLeft = idParts[1] === 'left';\n+      const siblingPreId = fingerprint + '-' + (isLeft ? 'right' : 'left');\n+      const siblingPre = document.getElementById(siblingPreId);\n+\n+      if (siblingPre) {\n+          const targetSpan = siblingPre.querySelector(`span[data-diffid=\"${diffId}\"]`);\n+          if (!targetSpan) {\n+              // Case 2: Corresponding span NOT found in siblingPre.\n+              // Search for the span with the same diffId in other hlo-textbox-pairs.\n+              const allMatchingSpans = document.querySelectorAll(`span[data-diffid=\"${diffId}\"]`);\n+              let foundSpanInOtherPre = null;\n+              allMatchingSpans.forEach(span => {\n+                  if (span !== clickedSpan) {\n+                      foundSpanInOtherPre = span;\n+                  }\n+              });\n+\n+              if (foundSpanInOtherPre) {\n+                  const foundPre = foundSpanInOtherPre.closest('.hlo-textbox').querySelector('pre');\n+                  if (foundPre) {\n+                      // Find ancestor detail and open it.\n+                      let parentDetails = foundSpanInOtherPre.closest('details');\n+                      while (parentDetails) {\n+                          parentDetails.open = true;\n+                          parentDetails = parentDetails.parentElement ? parentDetails.parentElement.closest('details') : null;\n+                      }\n+\n+                      // Scroll the foundPre to make the foundSpanInOtherPre visible.\n+                      foundSpanInOtherPre.scrollIntoView({ behavior: 'smooth', block: 'center' });\n+\n+                      // Temporarily highlight the found span\n+                      foundSpanInOtherPre.classList.add('temp-highlight');\n+                      setTimeout(() => {\n+                          foundSpanInOtherPre.classList.remove('temp-highlight');\n+                      }, 3000);\n+                  }\n+              }\n           }\n       }\n   }\n@@ -408,9 +516,11 @@ std::string EscapeStringForHtmlAttribute(absl::string_view str) {\n \n // Prints the div html block.\n std::string PrintDiv(absl::string_view content,\n-                     absl::Span<const absl::string_view> class_names) {\n-  return absl::StrFormat(R\"html(<div class=\"%s\">%s</div>)html\",\n-                         absl::StrJoin(class_names, \" \"), content);\n+                     absl::Span<const absl::string_view> class_names,\n+                     absl::string_view id = \"\") {\n+  std::string div_id = id.empty() ? \"\" : absl::StrCat(\" id=\\\"\", id, \"\\\"\");\n+  return absl::StrFormat(R\"html(<div class=\"%s\"%s>%s</div>)html\",\n+                         absl::StrJoin(class_names, \" \"), div_id, content);\n }\n \n // Print the span html block.\n@@ -441,6 +551,12 @@ std::string PrintSectionWithHeader(absl::string_view header,\n                   {\"section\"});\n }\n \n+// Prints a system message placeholder.\n+std::string PrintSystemMessagePlaceholder() {\n+  return PrintDiv(PrintSpan(\"System message placeholder\", {}),\n+                  {\"system-message-container\"}, \"system-message\");\n+}\n+\n // Prints a list of items.\n std::string PrintList(absl::Span<const std::string> items) {\n   return PrintDiv(absl::StrJoin(items, \"\",\n@@ -496,13 +612,10 @@ std::string PrintTextbox(absl::string_view title, absl::string_view content,\n                          absl::string_view id = \"\") {\n   return absl::StrCat(\n       PrintDiv(title, {\"title\"}),\n-      PrintDiv(\n-          absl::StrCat(\n-              absl::StrFormat(\n-                  R\"html(<pre onscroll=\"TextboxOnScroll(event)\" id=\"%s\">%s</pre>)html\",\n-                  id, content),\n-              PrintClickToCopyButton(\"\", content)),\n-          {\"textbox\"}));\n+      PrintDiv(absl::StrCat(absl::StrFormat(R\"html(<pre id=\"%s\">%s</pre>)html\",\n+                                            id, content),\n+                            PrintClickToCopyButton(\"\", content)),\n+               {\"textbox\"}));\n }\n \n /*** Summary logic ***/\n@@ -1193,6 +1306,7 @@ void RenderHtml(const DiffResult& diff_result, const DiffSummary& diff_summary,\n               PrintChangedInstructions(\n                   filtered_diff_result.changed_instructions, url_generator))));\n \n+  out << PrintSystemMessagePlaceholder();\n   out << PrintJavascriptForHoverEvent();\n   out << PrintJavascriptForToggleButton();\n }"
        },
        {
            "sha": "a524561bb2d27da7b379738f3099950490bb92b4",
            "filename": "third_party/xla/xla/hlo/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -340,6 +340,7 @@ xla_cc_test(\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest\","
        },
        {
            "sha": "9bac9fcde4f1983af84e412321f3286b9ddddb6f",
            "filename": "third_party/xla/xla/hlo/transforms/collectives/infeed_token_propagation.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 5,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcollectives%2Finfeed_token_propagation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcollectives%2Finfeed_token_propagation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcollectives%2Finfeed_token_propagation.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -172,8 +172,10 @@ absl::StatusOr<HloInstruction*> InsertTokenIntoTuple(HloInstruction* tuple,\n   HloInstruction* original_tuple = TupleUtil::Duplicate(tuple);\n   for (HloInstruction* original_user : original_users) {\n     for (int64_t idx : original_user->operand_indices(tuple)) {\n+      // We expect the shape to be same, but checking that it is the same is\n+      // expensive.\n       TF_RETURN_IF_ERROR(\n-          original_user->ReplaceOperandWith(idx, original_tuple));\n+          original_user->ReplaceOperandWithDifferentShape(idx, original_tuple));\n     }\n   }\n \n@@ -231,8 +233,10 @@ absl::Status CanonicalizeConditionalInstruction(HloInstruction* conditional) {\n     // insert tokens into the input tuple.\n     if (branch_tuple->opcode() == HloOpcode::kParameter) {\n       branch_tuple = TupleUtil::Duplicate(branch_tuple);\n-      TF_RETURN_IF_ERROR(\n-          conditional->ReplaceOperandWith(branch_operand_idx, branch_tuple));\n+      // We expect the shape to be same, but checking that it is the same is\n+      // expensive.\n+      TF_RETURN_IF_ERROR(conditional->ReplaceOperandWithDifferentShape(\n+          branch_operand_idx, branch_tuple));\n     }\n \n     // Explicitly make the root of the branch a tuple.\n@@ -326,7 +330,9 @@ absl::Status CanonicalizeWhileInstruction(HloInstruction* loop) {\n   // insert tokens into the input tuple.\n   if (loop_tuple->opcode() == HloOpcode::kParameter) {\n     loop_tuple = TupleUtil::Duplicate(loop_tuple);\n-    TF_RETURN_IF_ERROR(loop->ReplaceOperandWith(0, loop_tuple));\n+    // We expect the shape to be same, but checking that it is the same is\n+    // expensive.\n+    TF_RETURN_IF_ERROR(loop->ReplaceOperandWithDifferentShape(0, loop_tuple));\n   }\n \n   // Explicitly make the root of the body a tuple.\n@@ -466,7 +472,10 @@ absl::Status InfeedTokenPropagation::PropagateToken(\n           // Parent outfeed happens after child infeed. Stitch via parent input\n           // token.\n           CHECK_EQ(begin->opcode(), HloOpcode::kOutfeed);\n-          TF_RETURN_IF_ERROR(begin->ReplaceOperandWith(1, output_token_));\n+          // We expect the shape to be same, but checking that it is the same\n+          // is expensive.\n+          TF_RETURN_IF_ERROR(\n+              begin->ReplaceOperandWithDifferentShape(1, output_token_));\n           output_token_ = end;\n         } else {\n           LOG(WARNING) << absl::StrFormat("
        },
        {
            "sha": "bae9c065b7f3bde54da711a6642ec998c9d90cca",
            "filename": "third_party/xla/xla/hlo/transforms/host_offloader.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -280,6 +280,13 @@ absl::StatusOr<bool> HostOffloader::WalkDownHostMemoryOffloadPaths(\n           \"to move the inputs to the device so that computation happens on the \"\n           \"device.\",\n           instruction->name());\n+      if (instruction->GetModule()\n+              ->config()\n+              .debug_options()\n+              .xla_disable_automatic_host_compute_offload()) {\n+        return absl::InvalidArgumentError(\n+            \"Automatic host compute offloading is disabled.\");\n+      }\n       host_offload_utils::SetHostComputeFrontendAttribute(*instruction);\n     }\n     if (!already_saved_buffer) {"
        },
        {
            "sha": "e69c664222b65d32286ae24fa5bde0308f8fda33",
            "filename": "third_party/xla/xla/hlo/transforms/host_offloader_test.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 3,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -25,6 +25,7 @@ limitations under the License.\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/hlo/analysis/alias_info.h\"\n@@ -53,7 +54,7 @@ namespace {\n \n class HostOffloaderTest : public HloHardwareIndependentTestBase {\n  protected:\n-  absl::StatusOr<bool> RunHostOffloader(HloModule* module) {\n+  absl::StatusOr<bool> RunHostOffloader(HloModule* module) const {\n     TF_EXPECT_OK(verifier().Run(module).status());\n     if (module->has_schedule()) {\n       return absl::InternalError(\"Expected a non-scheduled module\");\n@@ -68,12 +69,13 @@ class HostOffloaderTest : public HloHardwareIndependentTestBase {\n     return changed;\n   }\n \n-  void TestShapeHasMemorySpace(const Shape& shape, int64_t memory_space) {\n+  static void TestShapeHasMemorySpace(const Shape& shape,\n+                                      int64_t memory_space) {\n     ASSERT_TRUE(shape.has_layout());\n     EXPECT_EQ(shape.layout().memory_space(), memory_space);\n   }\n \n-  bool HaveRemainingOffloadAnnotations(const HloModule* module) {\n+  static bool HaveRemainingOffloadAnnotations(const HloModule* module) {\n     for (const HloComputation* computation : module->computations()) {\n       for (const HloInstruction* instruction : computation->instructions()) {\n         if (instruction->IsCustomCall(\n@@ -86,6 +88,12 @@ class HostOffloaderTest : public HloHardwareIndependentTestBase {\n     return false;\n   }\n \n+  static void DisableAutomaticHostComputeOffload(HloModule* module) {\n+    module->mutable_config()\n+        .mutable_debug_options()\n+        .set_xla_disable_automatic_host_compute_offload(true);\n+  }\n+\n   AliasInfo alias_info_;\n };\n \n@@ -4528,6 +4536,27 @@ ENTRY main.39_spmd (param.2: f32[16,16,16]) -> (f32[16,16,16], f32[16,16,16]) {\n   EXPECT_EQ(default_memory_space_count, 1);\n }\n \n+TEST_F(HostOffloaderTest, AutomaticHostComputeOffloadDisabled) {\n+  const absl::string_view hlo_string = R\"(\n+    HloModule module, entry_computation_layout={(f32[1024]{0})->f32[1024]{0}}\n+\n+    ENTRY main {\n+      param = f32[1024]{0} parameter(0)\n+      to_host = f32[1024]{0} custom-call(param), custom_call_target=\"MoveToHost\"\n+      tanh = f32[1024]{0} tanh(to_host)\n+      ROOT to_device = f32[1024]{0} custom-call(tanh), custom_call_target=\"MoveToDevice\"\n+    })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  DisableAutomaticHostComputeOffload(module.get());\n+  // Normally, the tanh will be offloaded to host compute, but because we have\n+  // disabled automatic host compute offloading, we expect an error.\n+  absl::StatusOr<bool> changed = RunHostOffloader(module.get());\n+  EXPECT_THAT(changed,\n+              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+}\n+\n }  // namespace\n \n }  // namespace xla"
        },
        {
            "sha": "f0f9e09f90a561d5d213d181bc42f4a087dc4165",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/float_normalization.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Ffloat_normalization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Ffloat_normalization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Ffloat_normalization.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -595,6 +595,7 @@ absl::Status FloatNormalizationVisitor::DefaultAction(HloInstruction* hlo) {\n       hlo->opcode() == HloOpcode::kWhile ||            //\n       hlo->opcode() == HloOpcode::kConditional ||      //\n       hlo->opcode() == HloOpcode::kBitcastConvert ||   //\n+      hlo->opcode() == HloOpcode::kBitcast ||          //\n       hlo->opcode() == HloOpcode::kAsyncStart ||       //\n       hlo->opcode() == HloOpcode::kAsyncDone ||        //\n       hlo->HasSideEffectNoRecurse()) {"
        },
        {
            "sha": "dcd8cd6a4f9b41eb33e804a063d02205d8f704e2",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/float_normalization_test.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Ffloat_normalization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Ffloat_normalization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Ffloat_normalization_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -583,6 +583,16 @@ TEST_F(FloatNormalizationTest, DoNotChangeBitcastConvert) {\n   EXPECT_EQ(root->operand(0)->shape().element_type(), U16);\n }\n \n+TEST_F(FloatNormalizationTest, DoNotChangeBitcast) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+m {\n+  a = s4[4,2]{1,0:E(4)} parameter(0)\n+  b = s8[4] bitcast(a)\n+})\"));\n+  EXPECT_FALSE(Normalize(module.get(), S4));\n+}\n+\n TEST_P(FloatNormalizationF8Test, ResolveIfUnsupportedF8) {\n   PrimitiveType f8_type = GetParam();\n   auto builder = HloComputation::Builder(TestName());"
        },
        {
            "sha": "6aef931e0fa1d88371103b160e8b414b415d931d",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -176,6 +176,7 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla:types\",\n+        \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/builder:xla_builder\",\n         \"//xla/hlo/builder:xla_computation\","
        },
        {
            "sha": "3789f45457801e983a92a18590312af79d1ece9b",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/attribute_exporter.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -355,11 +355,10 @@ std::optional<xla::OpSharding> ConvertSharding(llvm::StringRef sharding) {\n }\n \n std::optional<xla::OriginalValueProto> ConvertOriginalValue(\n-    llvm::StringRef original_value, const xla::Shape& shape) {\n+    llvm::StringRef original_value) {\n   absl::StatusOr<std::shared_ptr<xla::OriginalValue>> hlo_original_value =\n       xla::ParseOriginalValue(\n-          absl::string_view(original_value.data(), original_value.size()),\n-          shape);\n+          absl::string_view(original_value.data(), original_value.size()));\n   if (!hlo_original_value.ok()) {\n     return std::nullopt;\n   }"
        },
        {
            "sha": "deefdd4e71397d9d1236e8e3d5ef8e12eb0e28b7",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/attribute_exporter.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -99,7 +99,7 @@ std::optional<xla::OpSharding> ExtractShardyResultShardingFromFrontendAttrs(\n // Returns an OriginalValueProto that represents a value in the unoptimized HLO\n // graph.\n std::optional<xla::OriginalValueProto> ConvertOriginalValue(\n-    llvm::StringRef original_value, const xla::Shape& shape);\n+    llvm::StringRef original_value);\n \n std::optional<xla::HloInputOutputAliasProto> ConvertInputOutputAlias(\n     llvm::ArrayRef<mlir::Attribute> aliasing);"
        },
        {
            "sha": "b3f3c0ff538cde5b3909172e56c1b9ac93c46a50",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 8,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -113,6 +113,7 @@ limitations under the License.\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/types.h\"\n+#include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n \n #define DEBUG_TYPE \"xla-translate\"\n@@ -6013,6 +6014,11 @@ xla::OpMetadata GetOpNameMetadataFromLocation(Value value) {\n   return m;\n }\n \n+std::string SanitizeOpName(std::string name) {\n+  name = llvm::sys::path::filename(name);\n+  return xla::SanitizeOpName(name, '.', \"_\");\n+}\n+\n }  // namespace\n \n LogicalResult ConvertToHloModule::LowerBasicBlockAsFunction(\n@@ -6114,7 +6120,7 @@ LogicalResult ConvertToHloModule::LowerBasicBlockAsFunction(\n         // otherwise use the default prefix.\n         std::string name = mhlo::GetDebugNameFromLocation(arg.getLoc());\n         if (!name.empty()) {\n-          name = llvm::sys::path::stem(name);\n+          name = SanitizeOpName(name);\n         } else {\n           name = kArgPrefix;\n         }\n@@ -6146,7 +6152,7 @@ LogicalResult ConvertToHloModule::LowerBasicBlockAsFunction(\n         // otherwise use the default prefix.\n         std::string name = mhlo::GetDebugNameFromLocation(arg.getLoc());\n         if (!name.empty()) {\n-          name = llvm::sys::path::stem(name);\n+          name = SanitizeOpName(name);\n         } else {\n           name = absl::StrCat(kArgPrefix, num);\n         }\n@@ -6444,12 +6450,7 @@ std::optional<xla::OriginalValueProto> CreateOriginalValueFromOp(\n   if (!original_value_attr) {\n     return std::nullopt;\n   }\n-  mlir::FailureOr<xla::Shape> shape_or = ExtractXlaShape(op);\n-  if (failed(shape_or)) {\n-    return std::nullopt;\n-  }\n-  return xla::ConvertOriginalValue(original_value_attr.getValue(),\n-                                   shape_or.value());\n+  return xla::ConvertOriginalValue(original_value_attr.getValue());\n }\n \n }  // namespace mlir"
        },
        {
            "sha": "afab2d6fbde6e7afaa3089b3e5e52a678db02e5b",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/tests/location_to_op_metadata.mlir",
            "status": "modified",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Flocation_to_op_metadata.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Flocation_to_op_metadata.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Flocation_to_op_metadata.mlir?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -148,3 +148,23 @@ func.func @main(%arg0: tensor<1x2xf32>, %arg1: tensor<1x2xf32>) -> tensor<1x2xf3\n }\n \n // CHECK: my_add{{.*}}, metadata={op_name=\"my_add\"}\n+\n+// -----\n+\n+// CHECK-LABEL: %main\n+func.func @main(%arg0: tensor<2xf32> loc(\"inputs.x\"), %arg1: tensor<2xf32> loc(\"inputs.y\")) -> tensor<2xf32> {\n+  %0 = \"mhlo.add\"(%arg0, %arg1) : (tensor<2xf32>, tensor<2xf32>) -> tensor<2xf32> loc(\"my_add\")\n+  func.return %0 : tensor<2xf32>\n+}\n+\n+// CHECK: inputs_x{{.*}}, metadata={op_name=\"inputs.x\"}\n+\n+// -----\n+\n+// CHECK-LABEL: %main\n+func.func @main(%arg0: tensor<2xf32> loc(\"Arg_0.1\"), %arg1: tensor<2xf32> loc(\"Arg_1.1\")) -> tensor<2xf32> {\n+  %0 = \"mhlo.add\"(%arg0, %arg1) : (tensor<2xf32>, tensor<2xf32>) -> tensor<2xf32> loc(\"my_add\")\n+  func.return %0 : tensor<2xf32>\n+}\n+\n+// CHECK: Arg_0{{.*}}, metadata={op_name=\"Arg_0.1\"}"
        },
        {
            "sha": "4a3069676807526b9a069875671f01de209a3c75",
            "filename": "third_party/xla/xla/hlo/utils/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -280,6 +280,12 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"pointer_utils\",\n+    hdrs = [\"pointer_utils.h\"],\n+    deps = [\"@com_google_absl//absl/hash\"],\n+)\n+\n xla_cc_test(\n     name = \"hlo_traversal_test\",\n     srcs = [\"hlo_traversal_test.cc\"],"
        },
        {
            "sha": "d18998c8c947b5d417efa906fd6eba124889e5d9",
            "filename": "third_party/xla/xla/hlo/utils/pointer_utils.h",
            "status": "added",
            "additions": 53,
            "deletions": 0,
            "changes": 53,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2Fpointer_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2Fpointer_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2Fpointer_utils.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -0,0 +1,53 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_HLO_UTILS_POINTER_UTILS_H_\n+#define XLA_HLO_UTILS_POINTER_UTILS_H_\n+\n+#include <cstddef>\n+#include <memory>\n+\n+#include \"absl/hash/hash.h\"\n+\n+namespace xla {\n+// Hash functor for std::shared_ptr<T>, hashing the value of the pointee.\n+template <typename T>\n+struct PointeeHash {\n+  size_t operator()(const std::shared_ptr<T>& value) const {\n+    if (!value) {\n+      return absl::Hash<int>()(0);  // Hash for nullptr\n+    }\n+    return absl::Hash<T>()(*value);\n+  }\n+};\n+\n+// Equality functor for std::shared_ptr<T>, comparing the values of the\n+// pointees.\n+template <typename T>\n+struct PointeeEqual {\n+  bool operator()(const std::shared_ptr<T>& lhs,\n+                  const std::shared_ptr<T>& rhs) const {\n+    if (!lhs && !rhs) {\n+      return true;\n+    }\n+    if (!lhs || !rhs) {\n+      return false;\n+    }\n+    return *lhs == *rhs;\n+  }\n+};\n+}  // namespace xla\n+\n+#endif  // XLA_HLO_UTILS_POINTER_UTILS_H_"
        },
        {
            "sha": "8963fa3f6ae8614f01d701c24195d42e032f7f4e",
            "filename": "third_party/xla/xla/lazy.h",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Flazy.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Flazy.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Flazy.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #ifndef XLA_LAZY_H_\n #define XLA_LAZY_H_\n \n+#include <memory>\n #include <variant>\n \n #include \"absl/functional/any_invocable.h\"\n@@ -24,22 +25,24 @@ namespace xla {\n \n template <typename T>\n class Lazy {\n+  using Value = std::unique_ptr<T>;\n+\n  public:\n-  explicit Lazy(absl::AnyInvocable<T() &&> func)\n-      : maybe_value_(std::move(func)) {}\n+  using Initializer = absl::AnyInvocable<T() &&>;\n+\n+  explicit Lazy(Initializer init) : data_(std::move(init)) {}\n \n-  bool has_value() const { return std::holds_alternative<T>(maybe_value_); }\n+  bool has_value() const { return std::holds_alternative<Value>(data_); }\n \n   const T& get() const {\n-    if (!std::holds_alternative<T>(maybe_value_)) {\n-      maybe_value_ =\n-          std::move(std::get<absl::AnyInvocable<T() &&>>(maybe_value_))();\n+    if (!has_value()) {\n+      data_ = std::make_unique<T>(std::move(std::get<Initializer>(data_))());\n     }\n-    return std::get<T>(maybe_value_);\n+    return *std::get<Value>(data_);\n   }\n \n  private:\n-  mutable std::variant<absl::AnyInvocable<T() &&>, T> maybe_value_;\n+  mutable std::variant<Initializer, Value> data_;\n };\n \n }  // namespace xla"
        },
        {
            "sha": "8de507a46188c4ac2b1144d0ec212450023a9dd5",
            "filename": "third_party/xla/xla/pjrt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -634,6 +634,7 @@ cc_library(\n         \"//xla/hlo/builder:xla_computation\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/pjrt/distributed:protocol_proto_cc\",\n+        \"//xla/pjrt/dump\",\n         \"//xla/pjrt/profiling:device_time_measurement\",\n         \"//xla/pjrt/profiling:profiling_context\",\n         \"//xla/service:buffer_assignment\","
        },
        {
            "sha": "23a095352335e09b46a23128a5fd492c1f3b244f",
            "filename": "third_party/xla/xla/pjrt/c/pjrt_c_api.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -593,6 +593,7 @@ typedef enum {\n // TODO: mwhittaker - Add the remaining fields from\n // tensorflow::CoordinatedTaskStateInfo.\n struct PJRT_ProcessInfo {\n+  size_t struct_size;\n   int task_id;\n   uint64_t incarnation_id;\n   PJRT_ProcessState state;"
        },
        {
            "sha": "57144b9ceb5448add49034d8d6e30780e3a31db1",
            "filename": "third_party/xla/xla/pjrt/cpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -163,7 +163,6 @@ cc_library(\n         \"//xla/hlo/builder:xla_computation\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/ir:hlo_module_group\",\n-        \"//xla/pjrt:abstract_tracked_device_buffer\",\n         \"//xla/pjrt:async_work_runner\",\n         \"//xla/pjrt:common_pjrt_client\",\n         \"//xla/pjrt:device_event\",\n@@ -182,6 +181,7 @@ cc_library(\n         \"//xla/pjrt:thread_pool_async_work_runner\",\n         \"//xla/pjrt:transpose\",\n         \"//xla/pjrt:utils\",\n+        \"//xla/pjrt/dump\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_client_options\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_execute_options\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_topology\","
        },
        {
            "sha": "3d79837b0b954b086eb36073582a1b799f734da3",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -74,6 +74,7 @@ limitations under the License.\n #include \"xla/pjrt/cpu/raw_buffer.h\"\n #include \"xla/pjrt/cpu/tracked_cpu_device_buffer.h\"\n #include \"xla/pjrt/device_event.h\"\n+#include \"xla/pjrt/dump/dump.h\"\n #include \"xla/pjrt/host_callback.h\"\n #include \"xla/pjrt/host_memory_spaces.h\"\n #include \"xla/pjrt/host_to_device_transfer_manager.h\"\n@@ -589,6 +590,8 @@ static absl::StatusOr<std::unique_ptr<xla::Executable>> CompileAheadOfTime(\n \n absl::StatusOr<std::unique_ptr<PjRtLoadedExecutable>>\n PjRtCpuClient::CompileAndLoad(mlir::ModuleOp module, CompileOptions options) {\n+  TF_RETURN_IF_ERROR(pjrt::MaybeDumpCompileInputs(options, module, topology_));\n+\n   XlaComputation xla_computation;\n   ExecutableBuildOptions& exec_build_options = options.executable_build_options;\n   TF_RETURN_IF_ERROR(MlirToXlaComputation(\n@@ -851,7 +854,7 @@ absl::StatusOr<std::unique_ptr<PjRtBuffer>> PjRtCpuClient::CreateErrorBuffer(\n           absl::InlinedVector<tsl::AsyncValueRef<CpuEvent>, 4>{\n               tsl::AsyncValueRef<CpuEvent>(\n                   tsl::MakeErrorAsyncValueRef(std::move(error)))}),\n-      *device->default_memory_space());\n+      memory_space);\n }\n \n absl::StatusOr<std::unique_ptr<PjRtClient::AsyncHostToDeviceTransferManager>>\n@@ -1321,7 +1324,8 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n     TrackedCpuDeviceBuffer* tracked_buffer;\n     auto get_buffer = [&](int i) -> absl::Status {\n       bool must_donate = donate_it != parameters_that_must_be_donated_.end() &&\n-                         *donate_it == i;\n+                         *donate_it == i &&\n+                         !options.non_donatable_input_indices.contains(i);\n       TF_RETURN_IF_ERROR(TestBufferDonationClashes(\n           cpu_buffer, donation_clashes, must_donate, i, replica, partition));\n       if (must_donate) {"
        },
        {
            "sha": "30f95fb9b0e72d4a47daa002bab16552ba2a3cf3",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client_test.cc",
            "status": "modified",
            "additions": 61,
            "deletions": 6,
            "changes": 67,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -166,6 +166,58 @@ ENTRY DonationWithExecutionError() -> f32[2, 2] {\n               HasSubstr(\"buffer has been deleted or donated.\"));\n }\n \n+TEST(PjRtCpuClientTest, RuntimeDonationDenial) {\n+  static constexpr char kProgram[] =\n+      R\"(\n+HloModule RuntimeDonationDenial,\n+          input_output_alias={ {}: (0, {}, must-alias) }\n+\n+ENTRY RuntimeDonationDenial() -> f32[2, 2] {\n+    ROOT %param = f32[2, 2] parameter(0)\n+})\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto client, GetPjRtCpuClient(CpuClientOptions()));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto hlo_module,\n+                          ParseAndReturnUnverifiedModule(kProgram, {}));\n+  XlaComputation xla_computation(hlo_module->ToProto());\n+  TF_ASSERT_OK_AND_ASSIGN(auto pjrt_executable,\n+                          client->CompileAndLoad(xla_computation, {}));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto fingerprint,\n+                          pjrt_executable->FingerprintExecutable());\n+  ASSERT_TRUE(!fingerprint.empty());\n+\n+  std::vector<float> data(4, 0);\n+  Shape shape = ShapeUtil::MakeShape(F32, {2, 2});\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto buffer,\n+      client->BufferFromHostBuffer(\n+          data.data(), shape.element_type(), shape.dimensions(),\n+          /*byte_strides=*/std::nullopt,\n+          PjRtClient::HostBufferSemantics::kImmutableOnlyDuringCall, nullptr,\n+          client->memory_spaces()[0], /*device_layout=*/nullptr));\n+\n+  {\n+    ExecuteOptions options;\n+    options.non_donatable_input_indices.insert(0);\n+    auto result = pjrt_executable->Execute(\n+        /*argument_handles=*/{{buffer.get()}}, options);\n+    TF_ASSERT_OK(result);\n+\n+    EXPECT_FALSE(buffer->IsDeleted());\n+  }\n+\n+  {\n+    ExecuteOptions options;\n+    auto result = pjrt_executable->Execute(\n+        /*argument_handles=*/{{buffer.get()}}, options);\n+    TF_ASSERT_OK(result);\n+\n+    EXPECT_TRUE(buffer->IsDeleted());\n+  }\n+}\n+\n TEST(PjRtCpuClientTest, HloSnapshot) {\n   static constexpr char kProgram[] = R\"(\n     HloModule add\n@@ -484,12 +536,15 @@ TEST(PjRtCpuClientTest, AsyncTransferSetBufferError) {\n TEST(PjRtCpuClientTest, CreateErrorBuffer) {\n   TF_ASSERT_OK_AND_ASSIGN(auto client, GetPjRtCpuClient(CpuClientOptions()));\n   xla::Shape shape = ShapeUtil::MakeShape(U32, {3, 2});\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto buffer, client->CreateErrorBuffer(Internal(\"foobar\"), shape,\n-                                             client->memory_spaces()[0]));\n-  EXPECT_THAT(\n-      buffer->ToLiteralSync(),\n-      absl_testing::StatusIs(tsl::error::INTERNAL, HasSubstr(\"foobar\")));\n+  for (PjRtMemorySpace* memory_space : client->memory_spaces()) {\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto buffer,\n+        client->CreateErrorBuffer(Internal(\"foobar\"), shape, memory_space));\n+    EXPECT_THAT(\n+        buffer->ToLiteralSync(),\n+        absl_testing::StatusIs(tsl::error::INTERNAL, HasSubstr(\"foobar\")));\n+    EXPECT_EQ(buffer->memory_space(), memory_space);\n+  }\n }\n \n TEST(PjRtCpuClientTest, AsyncTransferRawDataToSubBuffer) {"
        },
        {
            "sha": "c282b1a243548216aeafdc77fd13166c116bab31",
            "filename": "third_party/xla/xla/pjrt/distributed/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -74,6 +74,8 @@ cc_library(\n         \"//xla/tsl/distributed_runtime/coordination:coordination_client\",\n         \"//xla/tsl/distributed_runtime/coordination:coordination_service_agent\",\n         \"//xla/tsl/distributed_runtime/rpc/coordination:grpc_coordination_client\",\n+        \"//xla/tsl/platform:env\",\n+        \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/protobuf:coordination_config_proto_cc\",\n         \"//xla/tsl/protobuf:coordination_service_proto_cc\",\n         \"@com_google_absl//absl/log\","
        },
        {
            "sha": "254a50bbe9ac4ec4251ccce4bbdd784435b47ae3",
            "filename": "third_party/xla/xla/pjrt/distributed/client.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fclient.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fclient.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fclient.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -34,9 +34,9 @@ limitations under the License.\n #include \"xla/tsl/distributed_runtime/coordination/coordination_client.h\"\n #include \"xla/tsl/distributed_runtime/coordination/coordination_service_agent.h\"\n #include \"xla/tsl/distributed_runtime/rpc/coordination/grpc_coordination_client.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/protobuf/coordination_config.pb.h\"\n #include \"xla/tsl/protobuf/coordination_service.pb.h\"\n-#include \"tsl/platform/statusor.h\"\n \n namespace xla {\n \n@@ -55,6 +55,8 @@ class DistributedRuntimeCoordinationServiceClient\n   absl::StatusOr<std::string> BlockingKeyValueGet(\n       absl::string_view key, absl::Duration timeout) override;\n   absl::StatusOr<std::string> KeyValueTryGet(absl::string_view key) override;\n+  absl::StatusOr<int64_t> KeyValueIncrement(absl::string_view key,\n+                                            int64_t increment) override;\n   absl::StatusOr<std::vector<std::pair<std::string, std::string>>>\n   KeyValueDirGet(absl::string_view key) override;\n   absl::Status KeyValueSet(absl::string_view key,\n@@ -153,6 +155,12 @@ DistributedRuntimeCoordinationServiceClient::KeyValueTryGet(\n   return coord_agent_->TryGetKeyValue(key);\n }\n \n+absl::StatusOr<int64_t>\n+DistributedRuntimeCoordinationServiceClient::KeyValueIncrement(\n+    absl::string_view key, int64_t increment) {\n+  return coord_agent_->IncrementKeyValue(key, increment);\n+}\n+\n absl::StatusOr<std::vector<std::pair<std::string, std::string>>>\n DistributedRuntimeCoordinationServiceClient::KeyValueDirGet(\n     absl::string_view key) {"
        },
        {
            "sha": "f6d2a412a471ae3090a523d860d4c12a9a7048e9",
            "filename": "third_party/xla/xla/pjrt/distributed/client.h",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fclient.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fclient.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fclient.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -32,7 +32,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"grpcpp/channel.h\"\n #include \"xla/pjrt/distributed/key_value_store_interface.h\"\n-#include \"tsl/platform/env.h\"\n+#include \"xla/tsl/platform/env.h\"\n \n namespace tsl {\n class CoordinationServiceAgent;\n@@ -91,7 +91,7 @@ class DistributedRuntimeClient {\n     bool poll_for_error_from_service_at_startup = true;\n \n     // If true, a multi-controller JAX job can continue even if this client\n-    // fails. Otherwise, the job will fail when the task failes.\n+    // fails. Otherwise, the job will fail when the task fails.\n     bool recoverable = false;\n   };\n \n@@ -119,6 +119,11 @@ class DistributedRuntimeClient {\n   // Returns `NotFoundError` immediately if the key is not found.\n   virtual absl::StatusOr<std::string> KeyValueTryGet(absl::string_view key) = 0;\n \n+  // Returns `FailedPreconditionError` if the corresponding value is not int\n+  // convertible.\n+  virtual absl::StatusOr<int64_t> KeyValueIncrement(absl::string_view key,\n+                                                    int64_t increment) = 0;\n+\n   // Get all key-value pairs under a directory (key).\n   // A value is considered to be in the directory if its key is prefixed with\n   // the directory."
        },
        {
            "sha": "9d8ac4c5290bbf96dd680fdd4fcbcf16884e9521",
            "filename": "third_party/xla/xla/pjrt/distributed/client_server_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 1,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fclient_server_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fclient_server_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fclient_server_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -61,7 +61,8 @@ using ::testing::Matches;\n using ::testing::Pair;\n using ::testing::UnorderedElementsAre;\n using ::tsl::proto_testing::EqualsProto;\n-using tsl::testing::StatusIs;\n+using ::tsl::testing::IsOkAndHolds;\n+using ::tsl::testing::StatusIs;\n \n constexpr absl::Duration kHeartbeatTimeout = absl::Milliseconds(2500);\n constexpr absl::Duration kBarrierTimeout = absl::Milliseconds(200);\n@@ -1087,6 +1088,15 @@ TEST_F(ClientServerTest, KeyValueTryGet) {\n   EXPECT_EQ(result.value(), \"value\");\n }\n \n+TEST_F(ClientServerTest, KeyValueIncrement) {\n+  StartService(/*num_nodes=*/1);\n+  auto client = GetClient(/*node_id=*/0);\n+  TF_ASSERT_OK(client->Connect());\n+  TF_ASSERT_OK(client->KeyValueSet(\"test_key\", \"10\"));\n+  EXPECT_THAT(client->KeyValueIncrement(\"test_key\", 1), IsOkAndHolds(11));\n+  EXPECT_THAT(client->KeyValueTryGet(\"test_key\"), IsOkAndHolds(\"11\"));\n+}\n+\n TEST_F(ClientServerTest, KeyValueDelete) {\n   StartService(/*num_nodes=*/1);\n   auto client = GetClient(/*node_id=*/0);"
        },
        {
            "sha": "c7b2b097a61da88ff3f2260ec42831f4405bf897",
            "filename": "third_party/xla/xla/pjrt/dump/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -1,6 +1,6 @@\n load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n load(\"//xla:xla.default.bzl\", \"xla_cc_test\")\n-load(\"//xla/tsl:tsl.default.bzl\", \"get_compatible_with_libtpu_portable\")\n+load(\"//xla/tsl:tsl.default.bzl\", \"get_compatible_with_libtpu_portable\", \"get_compatible_with_portable\")\n \n package(\n     # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n@@ -12,7 +12,7 @@ cc_library(\n     name = \"dump\",\n     srcs = [\"dump.cc\"],\n     hdrs = [\"dump.h\"],\n-    compatible_with = get_compatible_with_libtpu_portable(),\n+    compatible_with = (get_compatible_with_libtpu_portable() + get_compatible_with_portable()),\n     deps = [\n         \":mlir\",\n         \"//xla/pjrt:pjrt_compiler\",\n@@ -62,7 +62,7 @@ cc_library(\n     name = \"mlir\",\n     srcs = [\"mlir.cc\"],\n     hdrs = [\"mlir.h\"],\n-    compatible_with = get_compatible_with_libtpu_portable(),\n+    compatible_with = (get_compatible_with_libtpu_portable() + get_compatible_with_portable()),\n     deps = [\n         \"//xla/tsl/platform:env\",\n         \"@com_google_absl//absl/status\",\n@@ -74,7 +74,7 @@ cc_library(\n xla_cc_test(\n     name = \"mlir_test\",\n     srcs = [\"mlir_test.cc\"],\n-    compatible_with = get_compatible_with_libtpu_portable(),\n+    compatible_with = (get_compatible_with_libtpu_portable() + get_compatible_with_portable()),\n     deps = [\n         \":mlir\",\n         \"//xla/mlir_hlo\","
        },
        {
            "sha": "53fa62c1630539f848e7e077ac5c6d9c298338d7",
            "filename": "third_party/xla/xla/pjrt/dump/dump.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -102,4 +102,31 @@ absl::Status DumpCompileInputs(absl::string_view dump_to_path,\n   return absl::OkStatus();\n }\n \n+absl::Status MaybeDumpCompileInputs(\n+    xla::CompileOptions compile_options, mlir::ModuleOp module,\n+    const xla::PjRtTopologyDescription& topology) {\n+  LOG(INFO) << \"[MaybeDumpCompileInputs] Dumping PJRT inputs for module: \"\n+            << module.getName().value_or(\"unknown_module\").str();\n+\n+  // Dump compile inputs to the specified path if populated.\n+  const auto& executable_build_options =\n+      compile_options.executable_build_options;\n+  if (!executable_build_options.has_debug_options()) {\n+    LOG(INFO) << \"  Debug options not set, skipping dump.\";\n+    return absl::OkStatus();\n+  }\n+  std::string dump_path(executable_build_options.debug_options().xla_dump_to());\n+  if (dump_path.empty()) {\n+    LOG(INFO) << \"  Dump path not set via xla_dump_to, skipping dump.\";\n+    return absl::OkStatus();\n+  }\n+  LOG(INFO) << \"  Dumping compile inputs to \" << dump_path;\n+  auto dump_status =\n+      pjrt::DumpCompileInputs(dump_path, compile_options, module, topology);\n+  if (!dump_status.ok()) {\n+    LOG(WARNING) << \"  Failed to dump compile inputs: \" << dump_status;\n+  }\n+  return absl::OkStatus();\n+}\n+\n }  // namespace pjrt"
        },
        {
            "sha": "2080c314a8b5357686132645a36d85d47a6f539a",
            "filename": "third_party/xla/xla/pjrt/dump/dump.h",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -42,6 +42,14 @@ absl::Status DumpCompileInputs(absl::string_view path,\n                                mlir::ModuleOp module,\n                                const xla::PjRtTopologyDescription& topology);\n \n+// Dumps the compile inputs (module, options, topology) to the specified\n+// path if the compile options specify a dump path via `xla_dump_to`.\n+//\n+// Does nothing if the compile options does not set `xla_dump_to`.\n+absl::Status MaybeDumpCompileInputs(\n+    xla::CompileOptions compile_options, mlir::ModuleOp module,\n+    const xla::PjRtTopologyDescription& topology);\n+\n }  // namespace pjrt\n \n #endif  // XLA_PJRT_DUMP_DUMP_H_"
        },
        {
            "sha": "52936b2fee047da240e08448d3f5747cc1c7c5eb",
            "filename": "third_party/xla/xla/pjrt/dump/dump_test.cc",
            "status": "modified",
            "additions": 61,
            "deletions": 0,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdump%2Fdump_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -158,4 +158,65 @@ TEST(DumpTest, DumpCompileInputs) {\n                                             HasSubstr(\"topology.pb\")));\n }\n \n+TEST(MaybeDumpCompileInputsTest, XlaDumpToNotSet) {\n+  const std::string temp_test_dir = tsl::testing::TmpDir();\n+  const std::string temp_test_subdir =\n+      tsl::io::JoinPath(temp_test_dir, \"compile_maybe_dump_test\",\n+                        absl::StrCat(absl::ToUnixMillis(absl::Now())));\n+  TF_ASSERT_OK(tsl::Env::Default()->RecursivelyCreateDir(temp_test_subdir));\n+  xla::CompileOptions compile_options;\n+  mlir::MLIRContext context;\n+  mlir::OpBuilder builder(&context);\n+  mlir::OwningOpRef<mlir::ModuleOp> module =\n+      builder.create<mlir::ModuleOp>(builder.getUnknownLoc());\n+  auto topology = std::make_unique<TestTopology>();\n+\n+  // xla_dump_to not set\n+  TF_ASSERT_OK(\n+      pjrt::MaybeDumpCompileInputs(compile_options, *module, *topology.get()));\n+\n+  std::vector<std::string> no_files;\n+  TF_ASSERT_OK(tsl::Env::Default()->GetMatchingPaths(\n+      tsl::io::JoinPath(temp_test_subdir, \"*\"), &no_files));\n+\n+  ASSERT_EQ(no_files.size(), 0);\n+}\n+\n+TEST(MaybeDumpCompileInputsTest, XlaDumpToSet) {\n+  const std::string temp_test_dir = tsl::testing::TmpDir();\n+  const std::string temp_test_subdir =\n+      tsl::io::JoinPath(temp_test_dir, \"compile_maybe_dump_test\",\n+                        absl::StrCat(absl::ToUnixMillis(absl::Now())));\n+  TF_ASSERT_OK(tsl::Env::Default()->RecursivelyCreateDir(temp_test_subdir));\n+  xla::CompileOptions compile_options;\n+  mlir::MLIRContext context;\n+  mlir::OpBuilder builder(&context);\n+  mlir::OwningOpRef<mlir::ModuleOp> module =\n+      builder.create<mlir::ModuleOp>(builder.getUnknownLoc());\n+  auto topology = std::make_unique<TestTopology>();\n+\n+  // Set xla_dump_to and dump compile inputs.\n+  compile_options.executable_build_options.mutable_debug_options()\n+      ->set_xla_dump_to(temp_test_subdir);\n+\n+  TF_ASSERT_OK(\n+      pjrt::MaybeDumpCompileInputs(compile_options, *module, *topology.get()));\n+  std::vector<std::string> files;\n+  TF_ASSERT_OK(tsl::Env::Default()->GetMatchingPaths(\n+      tsl::io::JoinPath(temp_test_subdir, \"*\"), &files));\n+\n+  ASSERT_EQ(files.size(), 1);\n+  std::string dump_subdir = files[0];\n+  EXPECT_THAT(tsl::Env::Default()->IsDirectory(dump_subdir), IsOk());\n+\n+  std::vector<std::string> dump_files;\n+  TF_ASSERT_OK(tsl::Env::Default()->GetMatchingPaths(\n+      tsl::io::JoinPath(dump_subdir, \"*\"), &dump_files));\n+  EXPECT_EQ(dump_files.size(), 3);\n+  EXPECT_THAT(dump_files,\n+              testing::UnorderedElementsAre(HasSubstr(\"module.mlir\"),\n+                                            HasSubstr(\"compile_options.pb\"),\n+                                            HasSubstr(\"topology.pb\")));\n+}\n+\n }  // namespace"
        },
        {
            "sha": "0d722443000de26cab80a825af1b2bd230295983",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 1,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -264,9 +264,26 @@ ENTRY main.5 {\n }\n #endif  // defined(GOOGLE_CUDA) || defined(TENSORFLOW_USE_ROCM)\n \n+TEST(StreamExecutorGpuClientTest, CreateErrorBuffer) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto client,\n+                          GetStreamExecutorGpuClient(DefaultOptions()));\n+\n+  xla::Shape shape = ShapeUtil::MakeShape(U32, {3, 2});\n+  for (PjRtMemorySpace* memory_space : client->memory_spaces()) {\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto buffer,\n+        client->CreateErrorBuffer(Internal(\"foobar\"), shape, memory_space));\n+    EXPECT_THAT(\n+        buffer->ToLiteralSync(),\n+        absl_testing::StatusIs(tsl::error::INTERNAL, HasSubstr(\"foobar\")));\n+    EXPECT_EQ(buffer->memory_space(), memory_space);\n+  }\n+}\n+\n TEST(StreamExecutorGpuClientTest, PropagateError) {\n   TF_ASSERT_OK_AND_ASSIGN(auto client,\n                           GetStreamExecutorGpuClient(DefaultOptions()));\n+\n   auto shape = xla::ShapeUtil::MakeScalarShape(xla::F32);\n   absl::Status input_error = absl::InvalidArgumentError(\"input error\");\n   TF_ASSERT_OK_AND_ASSIGN(\n@@ -2657,7 +2674,8 @@ absl::Status ShardedAutotuningWorksTestBody(const int node_id,\n \n   const std::string optimized_hlo =\n       executable->GetExecutable()->GetHloModules()->front()->ToString();\n-  TF_RET_CHECK(absl::StrContains(optimized_hlo, \"triton_gemm\"))\n+  TF_RET_CHECK(absl::StrContains(optimized_hlo, \"triton_gemm\") ||\n+               absl::StrContains(optimized_hlo, \"__triton_nested_gemm_fusion\"))\n       << optimized_hlo;\n \n   return absl::OkStatus();"
        },
        {
            "sha": "891eb5fec501284cbef71a18b1da596728df9c41",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -75,6 +75,7 @@ cc_library(\n         \"//xla/pjrt/distributed:key_value_store_interface\",\n         \"//xla/pjrt/distributed:protocol_proto_cc\",\n         \"//xla/pjrt/distributed:topology_util\",\n+        \"//xla/pjrt/dump\",\n         \"//xla/pjrt/gpu:gpu_helpers\",\n         \"//xla/pjrt/gpu:gpu_topology\",\n         \"//xla/pjrt/gpu:gpu_topology_proto_cc\","
        },
        {
            "sha": "06559facb289cda37b06b452527015c37532d01e",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_client.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -58,6 +58,7 @@ limitations under the License.\n #include \"xla/pjrt/distributed/in_memory_key_value_store.h\"\n #include \"xla/pjrt/distributed/key_value_store_interface.h\"\n #include \"xla/pjrt/distributed/protocol.pb.h\"\n+#include \"xla/pjrt/dump/dump.h\"\n #include \"xla/pjrt/gpu/gpu_helpers.h\"\n #include \"xla/pjrt/gpu/gpu_topology.h\"\n #include \"xla/pjrt/gpu/gpu_topology.pb.h\"\n@@ -330,6 +331,7 @@ absl::StatusOr<std::unique_ptr<PjRtExecutable>> TfrtGpuClient::CompileInternal(\n \n absl::StatusOr<std::unique_ptr<PjRtExecutable>> TfrtGpuClient::Compile(\n     mlir::ModuleOp module, CompileOptions options) {\n+  TF_RETURN_IF_ERROR(pjrt::MaybeDumpCompileInputs(options, module, topology_));\n   return Compile(module, options, /*lookup_addressable_devices=*/false);\n }\n "
        },
        {
            "sha": "0b359ad7cae05e9c699e0461c8688e3e89cf3be0",
            "filename": "third_party/xla/xla/pjrt/pjrt_c_api_client.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 34,
            "changes": 67,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_c_api_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_c_api_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_c_api_client.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -380,6 +380,7 @@ void PjRtCApiClient::UpdateGlobalProcessInfo(\n   std::vector<PJRT_ProcessInfo> process_infos;\n   for (const tensorflow::CoordinatedTaskStateInfo& info : infos) {\n     PJRT_ProcessInfo process_info;\n+    process_info.struct_size = PJRT_ProcessInfo_STRUCT_SIZE;\n     process_info.task_id = info.task().task_id();\n     process_info.incarnation_id = info.incarnation();\n     process_info.state = translate_state(info.state());\n@@ -805,34 +806,34 @@ absl::Status PjRtCApiClient::DmaUnmap(void* data) {\n }\n \n PJRT_Transfers_CrossHostRecvNotifierInfo CppCrossHostRecvNotifierToC(\n-    const PJRT_Api* c_api, const xla::PjRtCrossHostRecvNotifier& cpp_notifier,\n-    PjRtCApiClient::CrossHostRecvNotifierFunction* notifier_function) {\n-  *notifier_function = [&cpp_notifier, c_api](\n-                           PJRT_Error* error,\n-                           const char** serialized_descriptors,\n-                           size_t* descriptors_sizes, size_t num_descriptors) {\n-    if (error != nullptr) {\n-      absl::Status state = ::pjrt::PjrtErrorToStatus(error, c_api);\n-      return cpp_notifier(std::move(state));\n-    }\n-    xla::PjRtCrossHostRecvState state;\n-    state.descriptors.reserve(num_descriptors);\n-    for (int i = 0; i < num_descriptors; ++i) {\n-      xla::PjRtCrossHostRecvDescriptors descriptors;\n-      descriptors.serialized_descriptors.push_back(\n-          std::string(serialized_descriptors[i], descriptors_sizes[i]));\n-      state.descriptors.push_back(std::move(descriptors));\n-    }\n-\n-    // TODO(emilyaf): Support cancellation.\n-    xla::PjRtCrossHostSendCancelNotifier cancel_notifier =\n-        [](absl::string_view, absl::Status, std::function<void(absl::Status)>) {\n-          LOG(FATAL) << \"MakeCrossHostReceiveBuffers: Cancellation is not \"\n-                        \"supported in PJRT C API.\";\n-        };\n-    state.cancel_notifier = cancel_notifier;\n-    return cpp_notifier(std::move(state));\n-  };\n+    const PJRT_Api* c_api, xla::PjRtCrossHostRecvNotifier cpp_notifier) {\n+  auto notifier_function = new PjRtCApiClient::CrossHostRecvNotifierFunction(\n+      [cpp_notifier = std::move(cpp_notifier), c_api](\n+          PJRT_Error* error, const char** serialized_descriptors,\n+          size_t* descriptors_sizes, size_t num_descriptors) {\n+        if (error != nullptr) {\n+          absl::Status state = ::pjrt::PjrtErrorToStatus(error, c_api);\n+          return cpp_notifier(std::move(state));\n+        }\n+        xla::PjRtCrossHostRecvState state;\n+        state.descriptors.reserve(num_descriptors);\n+        for (int i = 0; i < num_descriptors; ++i) {\n+          xla::PjRtCrossHostRecvDescriptors descriptors;\n+          descriptors.serialized_descriptors.push_back(\n+              std::string(serialized_descriptors[i], descriptors_sizes[i]));\n+          state.descriptors.push_back(std::move(descriptors));\n+        }\n+\n+        // TODO(emilyaf): Support cancellation.\n+        xla::PjRtCrossHostSendCancelNotifier cancel_notifier =\n+            [](absl::string_view, absl::Status,\n+               std::function<void(absl::Status)>) {\n+              LOG(FATAL) << \"MakeCrossHostReceiveBuffers: Cancellation is not \"\n+                            \"supported in PJRT C API.\";\n+            };\n+        state.cancel_notifier = cancel_notifier;\n+        return cpp_notifier(std::move(state));\n+      });\n   return PJRT_Transfers_CrossHostRecvNotifierInfo{\n       /*user_arg=*/notifier_function,\n       /*notifier=*/\n@@ -841,8 +842,9 @@ PJRT_Transfers_CrossHostRecvNotifierInfo CppCrossHostRecvNotifierToC(\n         PjRtCApiClient::CrossHostRecvNotifierFunction* notifier_fn =\n             reinterpret_cast<PjRtCApiClient::CrossHostRecvNotifierFunction*>(\n                 user_arg);\n-        return (*notifier_fn)(error, serialized_descriptors, descriptors_sizes,\n-                              num_descriptors);\n+        (*notifier_fn)(error, serialized_descriptors, descriptors_sizes,\n+                       num_descriptors);\n+        delete notifier_fn;\n       }};\n }\n \n@@ -893,9 +895,7 @@ PjRtCApiClient::MakeCrossHostReceiveBuffers(\n   args.element_types = element_type_list.data();\n   args.layouts = layout_list.data();\n \n-  CrossHostRecvNotifierFunction notifier_function;\n-  args.notifier =\n-      CppCrossHostRecvNotifierToC(c_api, notifier, &notifier_function);\n+  args.notifier = CppCrossHostRecvNotifierToC(c_api, std::move(notifier));\n   args.device = tensorflow::down_cast<PjRtCApiDevice*>(device)->c_device();\n \n   std::vector<PJRT_Buffer*> temp_buffers(shapes.size());\n@@ -908,7 +908,6 @@ PjRtCApiClient::MakeCrossHostReceiveBuffers(\n   for (int i = 0; i < args.num_buffers; ++i) {\n     buffers.emplace_back(std::unique_ptr<PjRtBuffer>(\n         std::make_unique<PjRtCApiBuffer>(this, args.buffers[i])));\n-    buffers.back()->GetReadyFuture().Await();\n   }\n   return buffers;\n }"
        },
        {
            "sha": "42beb3e8b1a04053f8fd0474d8674eb51d6d665c",
            "filename": "third_party/xla/xla/pjrt/pjrt_executable.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_executable.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -87,7 +87,9 @@ absl::StatusOr<CompileOptionsProto> CompileOptions::ToProto() const {\n                       executable_build_options.ToProto());\n   output.set_compile_portable_executable(compile_portable_executable);\n   output.set_profile_version(profile_version);\n-  if (multi_slice_config != nullptr) {\n+  if (!serialized_multi_slice_config.empty()) {\n+    output.set_serialized_multi_slice_config(serialized_multi_slice_config);\n+  } else if (multi_slice_config != nullptr) {\n     output.set_serialized_multi_slice_config(multi_slice_config->Serialize());\n   }\n   for (auto& env_option_override : env_option_overrides) {"
        },
        {
            "sha": "d6a81823dc92e87ff699dd8719b8f8426f995b26",
            "filename": "third_party/xla/xla/pjrt/pjrt_phase_compile_extension_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_phase_compile_extension_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_phase_compile_extension_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_phase_compile_extension_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -63,10 +63,11 @@ constexpr absl::string_view kStablehloModuleStr = R\"(\n   }\n   )\";\n \n+constexpr absl::string_view kStablehloBytecodeFormat = \"bytecode\";\n constexpr absl::string_view kPhaseName = \"stablehlo_to_optimized_stablehlo\";\n \n std::vector<xla::PjRtPartialProgramProto> PrepareInputPartialPrograms(\n-    const std::string& next_phase, size_t program_format) {\n+    const std::string& next_phase, const absl::string_view program_format) {\n   std::string program_code{kStablehloModuleStr};\n \n   mlir::MLIRContext context;\n@@ -210,8 +211,7 @@ TEST_F(PhaseCompileExtensionTest, RunPhases) {\n   // Prepare the input programs.\n   auto partial_programs_in = PrepareInputPartialPrograms(\n       /*next_phase=*/std::string(kPhaseName),\n-      /*program_format=*/0);  // 0 expresses StableHLO bytecode per the\n-                              // sample plugin used in this test.\n+      /*program_format=*/kStablehloBytecodeFormat);\n \n   // Run the partial compile phase.\n   std::vector<std::string> phases_to_run = {std::string(kPhaseName)};\n@@ -237,7 +237,7 @@ TEST_F(PhaseCompileExtensionTest,\n   // Prepare the input programs.\n   auto partial_programs_in =\n       PrepareInputPartialPrograms(/*next_phase=*/std::string(kPhaseName),\n-                                  /*program_format=*/0);\n+                                  /*program_format=*/kStablehloBytecodeFormat);\n \n   // Run the partial compile phase.\n   std::vector<std::string> phases_to_run = {};\n@@ -257,7 +257,7 @@ TEST_F(PhaseCompileExtensionTest,\n   // Prepare the input programs.\n   auto partial_programs_in =\n       PrepareInputPartialPrograms(/*next_phase=*/std::string(kPhaseName),\n-                                  /*program_format=*/0);\n+                                  /*program_format=*/kStablehloBytecodeFormat);\n \n   // Run the partial compile phase.\n   std::vector<std::string> phases_to_run = {\"IllegalPhaseName\"};"
        },
        {
            "sha": "66bf9a3748fffaddee8fc4b104ba85a13ffb5612",
            "filename": "third_party/xla/xla/pjrt/pjrt_phase_compile_sample_plugin.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_phase_compile_sample_plugin.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_phase_compile_sample_plugin.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_phase_compile_sample_plugin.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -88,7 +88,7 @@ absl::StatusOr<std::string> StablehloTypeSerialization::Serialize(\n \n namespace {\n \n-enum SamplePartialProgramFormat { kStablehloBytecode = 0, kUnknown = -1 };\n+constexpr absl::string_view kStablehloBytecodeFormat = \"bytecode\";\n \n constexpr absl::string_view kNextPhaseName = \"some_next_phase\";\n \n@@ -99,8 +99,7 @@ absl::Status PhaseValidator(\n   }\n \n   for (const auto& input_program : input_programs) {\n-    if (input_program.program_format() !=\n-        SamplePartialProgramFormat::kStablehloBytecode) {\n+    if (input_program.program_format() != kStablehloBytecodeFormat) {\n       return absl::InvalidArgumentError(\n           \"Input programs are not in expected format.\");\n     }\n@@ -151,8 +150,7 @@ absl::StatusOr<std::vector<xla::PjRtPartialProgramProto>> PhaseCompiler(\n \n     xla::PjRtPartialProgramProto serialized_output_object;\n     serialized_output_object.set_program(serialized_output_status.value());\n-    serialized_output_object.set_program_format(\n-        static_cast<size_t>(SamplePartialProgramFormat::kStablehloBytecode));\n+    serialized_output_object.set_program_format(kStablehloBytecodeFormat);\n     serialized_output_object.set_generating_phase(kPhaseName);\n     serialized_output_object.add_next_phases({std::string(kNextPhaseName)});\n     serialized_output_object.set_version(\"1.0\");"
        },
        {
            "sha": "cc701a3b3f6ff98414f0246099ce81ad98a681c5",
            "filename": "third_party/xla/xla/pjrt/pjrt_phase_compiler_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 8,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_phase_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_phase_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_phase_compiler_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -60,8 +60,10 @@ constexpr absl::string_view kStablehloModuleStr = R\"(\n   }\n   )\";\n \n+constexpr absl::string_view kStablehloBytecodeFormat = \"bytecode\";\n+\n std::vector<xla::PjRtPartialProgramProto> PrepareInputPartialPrograms(\n-    const std::string& next_phase, size_t program_format) {\n+    const std::string& next_phase, absl::string_view program_format) {\n   std::string program_code{kStablehloModuleStr};\n \n   mlir::MLIRContext context;\n@@ -136,7 +138,7 @@ TEST_F(SamplePhaseCompilerTest, TestSamplePhaseCompilerRunPhases) {\n   // Prepare the input programs.\n   auto partial_programs_in = PrepareInputPartialPrograms(\n       /*next_phase=*/std::string(phase_compile_sample_plugin::kPhaseName),\n-      /*program_format=*/0);\n+      /*program_format=*/kStablehloBytecodeFormat);\n \n   // Run the partial compile phase.\n   std::vector<std::string> phases_to_run = {\n@@ -165,7 +167,7 @@ TEST_F(SamplePhaseCompilerTest,\n   std::vector<xla::PjRtPartialProgramProto> partial_programs_in =\n       PrepareInputPartialPrograms(\n           /*next_phase=*/std::string(phase_compile_sample_plugin::kPhaseName),\n-          /*program_format=*/0);\n+          /*program_format=*/kStablehloBytecodeFormat);\n \n   // Run the partial compile phase.\n   std::vector<std::string> phases_to_run = {};\n@@ -189,7 +191,7 @@ TEST_F(SamplePhaseCompilerTest,\n   std::vector<xla::PjRtPartialProgramProto> partial_programs_in =\n       PrepareInputPartialPrograms(\n           /*next_phase=*/std::string(phase_compile_sample_plugin::kPhaseName),\n-          /*program_format=*/0);\n+          /*program_format=*/kStablehloBytecodeFormat);\n \n   // Run the partial compile phase.\n   std::vector<std::string> phases_to_run = {\"unregistered_phase_name\"};\n@@ -226,10 +228,7 @@ TEST_F(SamplePhaseCompilerTest, PluginSpecificValidationWithUnexpectedFormat) {\n   std::vector<xla::PjRtPartialProgramProto> partial_programs_in =\n       PrepareInputPartialPrograms(\n           /*next_phase=*/std::string(phase_compile_sample_plugin::kPhaseName),\n-          /*program_format=*/1  // 1 expresses some format which is not expected\n-                                // by the sample plugin for the kPhaseName\n-                                // phase.\n-      );\n+          /*program_format=*/\"unexpected_format\");\n \n   // Run the partial compile phase.\n   std::vector<std::string> phases_to_run = {"
        },
        {
            "sha": "992998f60fdcc28b93901dd42c5b464cb1abf604",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 304,
            "deletions": 36,
            "changes": 340,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -109,6 +109,7 @@ limitations under the License.\n #include \"xla/pjrt/abstract_tracked_device_buffer.h\"\n #include \"xla/pjrt/device_event.h\"\n #include \"xla/pjrt/distributed/protocol.pb.h\"\n+#include \"xla/pjrt/dump/dump.h\"\n #include \"xla/pjrt/event_pool.h\"\n #include \"xla/pjrt/host_callback.h\"\n #include \"xla/pjrt/host_memory_spaces.h\"\n@@ -607,56 +608,95 @@ AllocateDestinationBuffer(const Shape& on_host_shape, PjRtDevice* device,\n         \"Cannot allocate a PjRtStreamExecutorBuffer for a tuple.\");\n   }\n \n+  PjRtMemorySpace* default_memory_space =\n+      device->default_memory_space().value_or(nullptr);\n   if (!memory_space) {\n-    memory_space = device->default_memory_space().value_or(nullptr);\n+    memory_space = default_memory_space;\n+  }\n+  bool is_pinned_host_memory =\n+      memory_space && (memory_space->kind() == PinnedHostMemorySpace::kKind);\n+  // Only allow pinned host memory or device memory.\n+  if (memory_space != default_memory_space && !is_pinned_host_memory) {\n+    return InvalidArgument(\"Buffer allocation: invalid memory space\");\n   }\n \n-  TF_ASSIGN_OR_RETURN(\n-      Shape on_device_shape,\n-      client->MakeDefaultShapeForMemorySpace(\n-          memory_space, on_host_shape,\n-          on_host_shape.has_layout() ? &on_host_shape.layout() : nullptr));\n-  TF_ASSIGN_OR_RETURN(\n-      size_t on_device_bytes_count,\n-      client->GetOnDeviceBytesCount(memory_space, on_device_shape));\n-  TF_ASSIGN_OR_RETURN(\n-      tsl::RCReference<CommonPjRtRawBuffer> raw_buffer,\n-      client->AllocateRawBuffer(memory_space, on_device_bytes_count,\n-                                /*retry_on_oom=*/true,\n-                                /*allocate_after=*/{}));\n+  auto* se_client = tensorflow::down_cast<PjRtStreamExecutorClient*>(client);\n+  TransferManager* transfer_manager =\n+      se_client->client()->backend().transfer_manager();\n+\n+  // Communicate the desired memory space to the allocator via the shape\n+  // callback.\n+  auto memory_space_shape_fn = [is_pinned_host_memory,\n+                                transfer_manager](const Shape& shape) {\n+    Shape result = transfer_manager->HostShapeToDeviceShape(shape);\n+    if (is_pinned_host_memory) {\n+      result.mutable_layout()->set_memory_space(Layout::kHostMemorySpace);\n+    }\n+    return result;\n+  };\n \n-  absl::InlinedVector<tsl::RCReference<PjRtDeviceEvent>, 4> definition_events;\n-  // Record the caller's definition event.\n-  if (definition_event) {\n-    definition_events.push_back(tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(\n-        std::move(definition_event)));\n+  TF_ASSIGN_OR_RETURN(\n+      ScopedShapedBuffer dst_buffer,\n+      transfer_manager->AllocateScopedShapedBuffer(\n+          on_host_shape, se_client->allocator(),\n+          local_device->local_device_id().value(),\n+          local_device->local_hardware_id().value(), memory_space_shape_fn));\n+  if (local_device->allocation_model() ==\n+      LocalDeviceState::kComputeSynchronized) {\n+    if (copy_stream == nullptr) {\n+      CHECK(is_uninitialized_create);\n+    } else {\n+      CHECK(copy_stream->WaitFor(local_device->compute_stream()).ok());\n+    }\n+  } else {\n+    DCHECK(transfer_manager->CanShapedBufferBeAccessedNow(\n+        local_device->compute_stream()->parent(), dst_buffer));\n   }\n+  Shape on_device_shape = dst_buffer.on_device_shape();\n+\n+  absl::InlinedVector<BufferSequencingEventRef, 2> definition_events;\n   if (is_uninitialized_create) {\n     // There is not going to be any copy into the buffer so in general we don't\n     // need a definition event.\n     // But if the caller provided a definition event then we record that. Also\n     // put it as the first definition event so that we can guarantee only the\n     // first one might not have event recorded.\n+    if (definition_event) {\n+      definition_events.push_back(definition_event);\n+    }\n     if (local_device->allocation_model() ==\n         LocalDeviceState::kComputeSynchronized) {\n-      TF_ASSIGN_OR_RETURN(auto allocation_ready_event,\n-                          raw_buffer->MakeAllocationReadyEvent());\n-      definition_events.push_back(std::move(allocation_ready_event));\n+      // The allocation is not valid until the compute stream passes this point,\n+      // so add a definition event in the compute stream.\n+      definition_events.emplace_back(\n+          BufferSequencingEvent::Create(client->thread_pool()));\n+      TF_RETURN_IF_ERROR(\n+          client->AllocateAndRecordEvent(definition_events.back(), local_device,\n+                                         local_device->compute_stream()));\n     }\n   } else {\n-    client->WaitForAllocation(copy_stream, *raw_buffer);\n-    // Callers expect at least one event.\n-    if (definition_events.empty()) {\n+    // We have at least one definition event, for the copy completing to\n+    // the device buffers.\n+    if (definition_event) {\n+      definition_events.push_back(definition_event);\n+    } else {\n       definition_events.emplace_back(\n-          tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(\n-              BufferSequencingEvent::Create(client->thread_pool())));\n+          BufferSequencingEvent::Create(client->thread_pool()));\n     }\n   }\n-  TF_ASSIGN_OR_RETURN(\n-      auto buffer, client->DefineBuffer(on_device_shape, std::move(raw_buffer),\n-                                        std::move(definition_events), true));\n-  return std::unique_ptr<PjRtStreamExecutorBuffer>(\n-      tensorflow::down_cast<PjRtStreamExecutorBuffer*>(buffer.release()));\n+\n+  auto mem = RawSEDeviceMemory::Create(dst_buffer.buffer({}),\n+                                       device->local_device_id(),\n+                                       dst_buffer.memory_allocator());\n+  dst_buffer.clear();\n+\n+  auto dst_device_buffer = std::make_unique<TrackedDeviceBuffer>(\n+      device, std::move(mem), definition_events);\n+\n+  auto py_buffer = std::make_unique<PjRtStreamExecutorBuffer>(\n+      on_device_shape, std::move(dst_device_buffer), client, device,\n+      memory_space);\n+  return py_buffer;\n }\n \n void PjRtStreamExecutorBuffer::ScopedHold::ConvertUsageHold(\n@@ -1030,6 +1070,232 @@ PjRtStreamExecutorClient::LinearizeHostBufferInto(\n   return definition_event;\n }\n \n+// BufferFromHostBuffer() is used to create a buffer either for a device, or\n+// for a host memory, depending on `memory_space`. The memory copy is needed\n+// for both cases, either from the unpinned host memory to device, or from\n+// the unpinned host memory to the pinned host memory.\n+absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n+PjRtStreamExecutorClient::BufferFromHostBufferInternal(\n+    const void* data, PrimitiveType type, absl::Span<int64_t const> dims,\n+    std::optional<absl::Span<int64_t const>> byte_strides,\n+    HostBufferSemantics host_buffer_semantics,\n+    absl::AnyInvocable<void() &&> on_done_with_host_buffer, PjRtDevice* device,\n+    const Layout* device_layout, PjRtMemorySpace* memory_space) {\n+  tsl::profiler::TraceMe traceme(\n+      \"PjRtStreamExecutorClient::BufferFromHostBuffer\");\n+  Shape device_shape = ShapeUtil::MakeShape(type, dims);\n+  VLOG(1) << \"PjRtStreamExecutorClient::BufferFromHostBuffer: shape: \"\n+          << device_shape.ToString() << \" device: \" << device->DebugString();\n+  TF_ASSIGN_OR_RETURN(LocalDeviceState * local_device,\n+                      tensorflow::down_cast<PjRtStreamExecutorDevice*>(device)\n+                          ->GetLocalDeviceState());\n+\n+  absl::InlinedVector<int64_t, 4> tmp_strides;\n+  if (!byte_strides) {\n+    tmp_strides.resize(dims.size());\n+    TF_RETURN_IF_ERROR(\n+        ShapeUtil::ByteStrides(device_shape, absl::MakeSpan(tmp_strides)));\n+    byte_strides = tmp_strides;\n+  }\n+  int64_t size = ShapeUtil::ByteSizeOf(device_shape);\n+\n+  TransferManager* transfer_manager = client()->backend().transfer_manager();\n+  if (device_layout != nullptr) {\n+    *(device_shape.mutable_layout()) = *device_layout;\n+  } else {\n+    TF_ASSIGN_OR_RETURN(\n+        device_shape,\n+        transfer_manager->ChooseCompactLayoutForShape(device_shape));\n+  }\n+  absl::InlinedVector<int64_t, 4> shape_strides(\n+      device_shape.dimensions().size());\n+  TF_RETURN_IF_ERROR(\n+      ShapeUtil::ByteStrides(device_shape, absl::MakeSpan(shape_strides)));\n+  bool host_and_device_strides_equal =\n+      (size == 0 || *byte_strides == shape_strides);\n+\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<PjRtStreamExecutorBuffer> py_buffer,\n+      AllocateDestinationBuffer(device_shape, device, local_device,\n+                                local_device->host_to_device_stream(),\n+                                /*is_uninitialized_create=*/false, this,\n+                                /*definition_event=*/nullptr, memory_space));\n+\n+  PjRtStreamExecutorBuffer::ScopedHold device_buffer(\n+      py_buffer->GetBufferWithUsageHold());\n+  CHECK(device_buffer.ok());\n+\n+  std::shared_ptr<TransposePlan> transpose;\n+  if (!host_and_device_strides_equal) {\n+    absl::InlinedVector<int64_t, 4> permutation(dims.size());\n+    absl::c_reverse_copy(device_shape.layout().minor_to_major(),\n+                         permutation.begin());\n+    TransposePlan::Options options;\n+    options.elem_size_in_bytes = primitive_util::ByteWidth(type);\n+    options.dims = dims;\n+    options.permutation = permutation;\n+    options.input_layout = TransposePlan::Striding{*byte_strides};\n+    absl::MutexLock lock(&transpose_mu_);\n+    TF_ASSIGN_OR_RETURN(transpose, transpose_cache_.GetOrCreate(options));\n+  }\n+\n+  bool should_pack = primitive_util::IsSubByteNonPredType(type) &&\n+                     transfer_manager->PackSubbyteTypes();\n+  int64_t packed_size;\n+  if (should_pack) {\n+    packed_size =\n+        CeilOfRatio<int64_t>(size, 8 / primitive_util::BitWidth(type));\n+  } else {\n+    packed_size = size;\n+  }\n+\n+  // If necessary, allocate a host-side buffer for staging host-to-device\n+  // transfers. On GPU this is a buffer in pinned memory.\n+  std::shared_ptr<void> staging_buffer;\n+  bool must_use_staging_buffer =\n+      host_buffer_semantics == HostBufferSemantics::kImmutableOnlyDuringCall ||\n+      !host_and_device_strides_equal || packed_size != size;\n+  // Allocating multigigabyte pinned buffers can be very slow. In that case,\n+  // using a staging buffer is probably worse than not using one.\n+  // TODO(phawkins): add chunking for transfers.\n+  if (must_use_staging_buffer || (!IsDmaMapped(data, packed_size) &&\n+                                  (should_stage_host_to_device_transfers() &&\n+                                   packed_size < (int64_t{1} << 30)))) {\n+    void* ptr = host_memory_allocator()->AllocateRaw(\n+        tsl::Allocator::kAllocatorAlignment, transpose ? size : packed_size);\n+    staging_buffer = std::shared_ptr<void>(\n+        ptr, [host_memory_allocator = host_memory_allocator()](void* ptr) {\n+          host_memory_allocator->DeallocateRaw(ptr);\n+        });\n+  }\n+\n+  // Copy the buffer into a staging buffer before returning control to the\n+  // caller if the caller only guaranteed that the buffer is valid for the\n+  // duration of the call. Otherwise, we stage (if necessary) on a separate\n+  // thread.\n+  if (host_buffer_semantics == HostBufferSemantics::kImmutableOnlyDuringCall) {\n+    if (transpose) {\n+      transpose->Execute(data, staging_buffer.get());\n+      if (should_pack) {\n+        primitive_util::PackIntN(\n+            type,\n+            absl::MakeConstSpan(static_cast<const char*>(staging_buffer.get()),\n+                                size),\n+            absl::MakeSpan(static_cast<char*>(staging_buffer.get()),\n+                           packed_size));\n+      }\n+    } else {\n+      if (should_pack) {\n+        primitive_util::PackIntN(\n+            type, absl::MakeConstSpan(static_cast<const char*>(data), size),\n+            absl::MakeSpan(static_cast<char*>(staging_buffer.get()),\n+                           packed_size));\n+      } else {\n+        std::memcpy(staging_buffer.get(), data, size);\n+      }\n+    }\n+    if (on_done_with_host_buffer) {\n+      std::move(on_done_with_host_buffer)();\n+      on_done_with_host_buffer = nullptr;\n+    }\n+  }\n+\n+  BufferSequencingEventRef event = device_buffer->definition_events()[0];\n+\n+  // The host to device transfer is performed on a thread pool, mostly because\n+  // it includes linearization that may be slow. It is OK to capture the\n+  // py_buffer pointer because the py_buffer can't be deleted until all the\n+  // usage holds have gone away.\n+  // TODO(misard) assess if it would be preferable to introduce a heuristic to\n+  // put the transfer into the calling thread for small literals.\n+  auto transfer_h2d =\n+      [this, local_client = client(), local_device, data, size, type,\n+       packed_size, event, device_memory_owned = device_buffer->device_memory(),\n+       device_shape, should_pack, py_buffer{py_buffer.get()},\n+       on_device_shape{py_buffer->on_device_shape()},\n+       staging_buffer{std::move(staging_buffer)},\n+       on_done_with_host_buffer =\n+           on_done_with_host_buffer\n+               ? std::make_shared<absl::AnyInvocable<void() &&>>(\n+                     std::move(on_done_with_host_buffer))\n+               : nullptr,\n+       host_buffer_semantics, transpose{std::move(transpose)}]() mutable {\n+        // This function uses TF_CHECK_OK and value() since we have no way\n+        // to report failures from a callback. However, the operations here are\n+        // unlikely to fail and not recoverable even if we were to fail: DMAs to\n+        // memory that has already been allocated, and a possible Event\n+        // allocation.\n+\n+        se::DeviceMemoryBase device_memory = device_memory_owned->mem();\n+\n+        // If applicable on the backend, stage the transfer via host memory\n+        // allocated via the host_memory_allocator. On GPU, this is pinned\n+        // memory.\n+        if (staging_buffer) {\n+          // If we didn't already copy the input buffer into the staging buffer,\n+          // do so now.\n+          if (host_buffer_semantics !=\n+              HostBufferSemantics::kImmutableOnlyDuringCall) {\n+            if (transpose) {\n+              transpose->Execute(data, staging_buffer.get());\n+              if (should_pack) {\n+                primitive_util::PackIntN(\n+                    type,\n+                    absl::MakeConstSpan(\n+                        static_cast<const char*>(staging_buffer.get()), size),\n+                    absl::MakeSpan(static_cast<char*>(staging_buffer.get()),\n+                                   packed_size));\n+              }\n+            } else {\n+              if (should_pack) {\n+                primitive_util::PackIntN(\n+                    type,\n+                    absl::MakeConstSpan(static_cast<const char*>(data), size),\n+                    absl::MakeSpan(static_cast<char*>(staging_buffer.get()),\n+                                   packed_size));\n+              } else {\n+                std::memcpy(staging_buffer.get(), data, size);\n+              }\n+            }\n+          }\n+          TF_CHECK_OK(local_device->host_to_device_stream()->Memcpy(\n+              &device_memory, staging_buffer.get(), packed_size));\n+        } else {\n+          TF_CHECK_OK(local_device->host_to_device_stream()->Memcpy(\n+              &device_memory, data, packed_size));\n+        }\n+\n+        TF_CHECK_OK(AddDestinationBufferSynchronization(\n+            this, local_device, event, local_device->host_to_device_stream()));\n+\n+        event.AndThen([device_memory_owned = std::move(device_memory_owned),\n+                       staging_buffer{std::move(staging_buffer)},\n+                       on_done_with_host_buffer{\n+                           std::move(on_done_with_host_buffer)}]() mutable {\n+          if (on_done_with_host_buffer) {\n+            std::move (*on_done_with_host_buffer)();\n+          }\n+        });\n+      };\n+  thread_pool()->Schedule(WrapClosureAsCopyable(std::move(transfer_h2d)));\n+  RecordUsage(std::move(device_buffer), local_device, local_device, event,\n+              local_device->host_to_device_stream());\n+  return std::unique_ptr<PjRtBuffer>(std::move(py_buffer));\n+}\n+\n+absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n+PjRtStreamExecutorClient::BufferFromHostBuffer(\n+    const void* data, PrimitiveType type, absl::Span<int64_t const> dims,\n+    std::optional<absl::Span<int64_t const>> byte_strides,\n+    HostBufferSemantics host_buffer_semantics,\n+    absl::AnyInvocable<void() &&> on_done_with_host_buffer,\n+    PjRtMemorySpace* memory_space, const Layout* device_layout) {\n+  return BufferFromHostBufferInternal(\n+      data, type, dims, byte_strides, host_buffer_semantics,\n+      std::move(on_done_with_host_buffer), memory_space->devices()[0],\n+      device_layout, memory_space);\n+}\n+\n absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n PjRtStreamExecutorClient::CreateUninitializedBuffer(\n     const Shape& shape, PjRtMemorySpace* memory_space) {\n@@ -1093,10 +1359,8 @@ PjRtStreamExecutorClient::CreateErrorBuffer(absl::Status error,\n       device, tsl::RCReference<RawSEDeviceMemory>(),\n       absl::MakeSpan(&definition_event, 1));\n \n-  auto py_buffer = std::make_unique<PjRtStreamExecutorBuffer>(\n-      shape, std::move(dummy_device_buffer), this, device,\n-      device->default_memory_space().value_or(nullptr));\n-  return py_buffer;\n+  return std::make_unique<PjRtStreamExecutorBuffer>(\n+      shape, std::move(dummy_device_buffer), this, device, memory);\n }\n \n absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n@@ -3618,6 +3882,10 @@ PjRtStreamExecutorClient::Compile(mlir::ModuleOp module,\n absl::StatusOr<std::unique_ptr<PjRtExecutable>>\n PjRtStreamExecutorClient::Compile(mlir::ModuleOp module, CompileOptions options,\n                                   bool lookup_addressable_devices) {\n+  TF_ASSIGN_OR_RETURN(const PjRtTopologyDescription* topology,\n+                      GetTopologyDescription());\n+  TF_RETURN_IF_ERROR(pjrt::MaybeDumpCompileInputs(options, module, *topology));\n+\n   XlaComputation xla_computation;\n   ExecutableBuildOptions& exec_build_options = options.executable_build_options;\n   TF_RETURN_IF_ERROR(MlirToXlaComputation("
        },
        {
            "sha": "391bd23d31252625a6747f8c53e7367ec182e7bb",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.h",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -331,6 +331,13 @@ class PjRtStreamExecutorClient : public CommonPjRtClient {\n   absl::StatusOr<std::unique_ptr<PjRtBuffer>> CreateErrorBuffer(\n       absl::Status error, const Shape& shape, PjRtMemorySpace* memory) override;\n \n+  absl::StatusOr<std::unique_ptr<PjRtBuffer>> BufferFromHostBuffer(\n+      const void* data, PrimitiveType type, absl::Span<int64_t const> dims,\n+      std::optional<absl::Span<int64_t const>> byte_strides,\n+      HostBufferSemantics host_buffer_semantics,\n+      absl::AnyInvocable<void() &&> on_done_with_host_buffer,\n+      PjRtMemorySpace* memory_space, const Layout* device_layout) override;\n+\n   using PjRtClient::BufferFromHostLiteral;\n   absl::StatusOr<std::unique_ptr<PjRtBuffer>> BufferFromHostLiteral(\n       const LiteralSlice& literal, PjRtMemorySpace* memory_space,\n@@ -510,6 +517,14 @@ class PjRtStreamExecutorClient : public CommonPjRtClient {\n       std::vector<std::unique_ptr<LocalExecutable>> local_executables,\n       CompileOptions compile_options, bool dump);\n \n+  absl::StatusOr<std::unique_ptr<PjRtBuffer>> BufferFromHostBufferInternal(\n+      const void* data, PrimitiveType type, absl::Span<int64_t const> dims,\n+      std::optional<absl::Span<int64_t const>> byte_strides,\n+      HostBufferSemantics host_buffer_semantics,\n+      absl::AnyInvocable<void() &&> on_done_with_host_buffer,\n+      PjRtDevice* device, const Layout* device_layout,\n+      PjRtMemorySpace* memory_space);\n+\n   const PjRtPlatformId platform_id_;\n   const std::string platform_name_;\n   LocalClient* client_;"
        },
        {
            "sha": "0da21ef7d37e8471b379a5d66416b394f3063e67",
            "filename": "third_party/xla/xla/pjrt/proto/pjrt_partial_program.proto",
            "status": "modified",
            "additions": 10,
            "deletions": 5,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fproto%2Fpjrt_partial_program.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Fproto%2Fpjrt_partial_program.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fproto%2Fpjrt_partial_program.proto?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -11,11 +11,11 @@ message PjRtPartialProgramProto {\n   // The serialized program data. This field holds the actual program content\n   // in a specific format (e.g., StableHLO bytecode, HLOProto).\n   bytes program = 1;\n-  // An integer identifying the format of the `program` data.\n-  // This format is interpreted by the plugin (e.g., 0 for StableHLO Bytecode,\n-  // or a custom value for HLOProto). It assists in plugin-specific validation\n-  // to ensure a phase consumes compatible inputs.\n-  int32 program_format = 2;\n+  // A string identifying the format of the `program` data.\n+  // This format is interpreted by the plugin. It assists in plugin-specific\n+  // validation to ensure a phase consumes compatible inputs. It can be used\n+  // along with `program_name` to identify the program.\n+  string program_format = 2;\n   // The name of the compilation phase that generated this partial program\n   // artifact.\n   string generating_phase = 3;\n@@ -27,4 +27,9 @@ message PjRtPartialProgramProto {\n   // The version of the program format. This can be used for compatibility\n   // checks if program formats evolve over time.\n   string version = 5;\n+  // Optional. if it is set, it must be set for all output programs of that\n+  // phase, and {`program_name`, `program_format`} must be unique.\n+  // Example use case: `program_name` can be used to tie together two programs\n+  // with different `program_format` during the next phase compilation.\n+  string program_name = 6;\n }"
        },
        {
            "sha": "d41115b2a99676e33cb6da9d062e523d923dbeac",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer.cc",
            "status": "modified",
            "additions": 38,
            "deletions": 47,
            "changes": 85,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -52,39 +52,34 @@ namespace xla {\n \n void BufferSequencingEvent::SetSequencingEvent(EventPool::Handle event,\n                                                se::Stream* stream) {\n-  {\n-    absl::MutexLock lock(&mu_);\n-    CHECK(!event_.event());\n-    event_ = std::move(event);\n-    CHECK(streams_defined_on_.empty());\n-    streams_defined_on_.push_back(stream);\n-    sequence_number_.store(event_.sequence_number(), std::memory_order_seq_cst);\n-  }\n-  defined_status_.emplace(absl::OkStatus());\n+  EventState state;\n+  state.event = std::move(event);\n+  state.definition_stream = stream;\n+  event_.emplace(std::move(state));\n }\n \n void BufferSequencingEvent::SetDefinedStatus(absl::Status status) {\n   CHECK(!status.ok());\n-  defined_status_.emplace(status);\n-}\n-\n-bool BufferSequencingEvent::EventHasBeenRecorded() const {\n-  return event_.event() != nullptr;\n+  event_.SetError(status);\n }\n \n uint64_t BufferSequencingEvent::sequence_number() const {\n-  uint64_t seq = sequence_number_.load(std::memory_order_seq_cst);\n-  return seq;\n+  return event_->event.sequence_number();\n }\n \n void BufferSequencingEvent::WaitForEventOnStream(se::Stream* stream) {\n-  absl::MutexLock lock(&mu_);\n-\n   // We cannot wait for an event until ThenRecordEvent has been called; on GPU\n   // newly created events are deemed to have already happened past.\n-  mu_.Await(\n-      absl::Condition(this, &BufferSequencingEvent::EventHasBeenRecorded));\n+  tsl::BlockUntilReady(event_);\n+\n+  if (event_.IsError()) {\n+    return;\n+  }\n+  if (event_->definition_stream == stream) {\n+    return;\n+  }\n \n+  absl::MutexLock lock(&mu_);\n   // The set of defined streams is expected to be very small indeed (usually\n   // 1-2), so a simple linear scan should be fast enough.\n   if (std::find(streams_defined_on_.begin(), streams_defined_on_.end(),\n@@ -93,31 +88,30 @@ void BufferSequencingEvent::WaitForEventOnStream(se::Stream* stream) {\n     return;\n   }\n \n-  stream->WaitFor(event_.event()).IgnoreError();\n+  stream->WaitFor(event_->event.event()).IgnoreError();\n   streams_defined_on_.push_back(stream);\n }\n \n absl::Status BufferSequencingEvent::WaitForEventOnExternalStream(\n     std::intptr_t stream) {\n-  absl::MutexLock lock(&mu_);\n-\n-  // We cannot wait for an event until ThenRecordEvent has been called; on GPU\n-  // newly created events are deemed to have already happened past.\n-  // TODO(skyewm): do we need this? WaitForEventOnExternalStream is only\n-  // implemented for GPU.\n-  mu_.Await(\n-      absl::Condition(this, &BufferSequencingEvent::EventHasBeenRecorded));\n-\n-  return event_.event()->WaitForEventOnExternalStream(stream);\n+  tsl::BlockUntilReady(event_);\n+  if (const auto* error = event_.GetErrorIfPresent()) {\n+    return *error;\n+  }\n+  return event_->event.event()->WaitForEventOnExternalStream(stream);\n }\n \n bool BufferSequencingEvent::IsPredeterminedErrorOrDefinedOn(\n     se::Stream* stream) {\n-  tsl::BlockUntilReady(defined_status_);\n-  CHECK(defined_status_.IsConcrete());\n+  tsl::BlockUntilReady(event_);\n+  CHECK(event_.IsAvailable());\n \n   // IsPredeterminedError\n-  if (!defined_status_->ok()) {\n+  if (event_.IsError()) {\n+    return true;\n+  }\n+\n+  if (event_->definition_stream == stream) {\n     return true;\n   }\n \n@@ -128,14 +122,12 @@ bool BufferSequencingEvent::IsPredeterminedErrorOrDefinedOn(\n }\n \n bool BufferSequencingEvent::IsComplete() {\n-  absl::MutexLock lock(&mu_);\n-\n-  // We cannot wait for an event until ThenRecordEvent has been called; on\n-  // GPU newly created events are deemed to have already happened past.\n-  mu_.Await(\n-      absl::Condition(this, &BufferSequencingEvent::EventHasBeenRecorded));\n+  tsl::BlockUntilReady(event_);\n+  if (event_.IsError()) {\n+    return true;\n+  }\n \n-  return event_.event()->PollForStatus() == se::Event::Status::kComplete;\n+  return event_->event.event()->PollForStatus() == se::Event::Status::kComplete;\n }\n \n void BufferSequencingEvent::ExecuteOrAddToFutureTasks(\n@@ -154,10 +146,9 @@ void BufferSequencingEvent::ExecuteOrAddToFutureTasks(\n \n   // Execute the `task` when definition event becomes available. If it's already\n   // available, the task will be executed immediately.\n-  defined_status_.AndThen(\n-      [this, traced_task = std::move(traced_task)]() mutable {\n-        thread_pool_->Schedule(std::move(traced_task));\n-      });\n+  event_.AndThen([this, traced_task = std::move(traced_task)]() mutable {\n+    thread_pool_->Schedule(std::move(traced_task));\n+  });\n }\n \n ShapedBuffer RawSEDeviceMemory::AsShapedBuffer(\n@@ -273,15 +264,15 @@ void TrackedDeviceBuffer::AddUsageEvent(se::Stream* usage_stream,\n \n   // If the event is 0, it means that the event is not recorded yet and the task\n   // related to this event is deferred, so just add it.\n-  if (*event == 0) {\n+  if (!event->IsDefined()) {\n     usage_events_.push_back({usage_stream, event, reference_held});\n     return;\n   }\n \n   for (auto& existing : usage_events_) {\n     // If the existing event is 0, it means that the event is not recorded yet\n     // and the task related to this event is deferred, so don't replace it.\n-    if (*existing.event == 0) continue;\n+    if (!existing.event->IsDefined()) continue;\n     if (existing.stream == usage_stream) {\n       if (*existing.event < *event) {\n         existing.event = event;"
        },
        {
            "sha": "092f77c3128c281d482f8f2aea5d3d76372ecdbd",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer.h",
            "status": "modified",
            "additions": 20,
            "deletions": 26,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -78,7 +78,7 @@ class BufferSequencingEvent : tsl::AsyncPayload::KeepOnError {\n  public:\n   explicit BufferSequencingEvent(tsl::thread::ThreadPool* thread_pool)\n       : thread_pool_(thread_pool),\n-        defined_status_(tsl::MakeUnconstructedAsyncValueRef<absl::Status>()) {}\n+        event_(tsl::MakeUnconstructedAsyncValueRef<EventState>()) {}\n \n   static tsl::AsyncValueRef<BufferSequencingEvent> Create(\n       tsl::thread::ThreadPool* thread_pool) {\n@@ -124,29 +124,26 @@ class BufferSequencingEvent : tsl::AsyncPayload::KeepOnError {\n     return !(*this < rhs);\n   }\n \n-  inline bool operator==(int number) const {\n-    return sequence_number() == number;\n-  }\n-\n   // Executes the `task` if the event is ready; otherwise adds the `task`\n-  // callback to `defined_status_` async value, to be executed when it becomes\n+  // callback to `event_` async value, to be executed when it becomes\n   // available.\n   void ExecuteOrAddToFutureTasks(const std::string& task_name,\n                                  std::function<void()> task);\n \n-  bool IsDefined() { return defined_status_.IsConcrete(); }\n+  bool IsDefined() { return event_.IsAvailable(); }\n \n   // Do not call directly. Use PjRtStreamExecutorClient::SetEventAsError.\n   void SetDefinedStatus(absl::Status status);\n \n   absl::Status GetDefinedStatus() {\n-    CHECK(defined_status_.IsConcrete());\n-    return *defined_status_;\n+    CHECK(event_.IsAvailable());\n+    if (const auto* error = event_.GetErrorIfPresent()) {\n+      return *error;\n+    }\n+    return absl::OkStatus();\n   }\n \n-  bool IsPredeterminedError() {\n-    return defined_status_.IsConcrete() && !defined_status_->ok();\n-  }\n+  bool IsPredeterminedError() { return event_.IsError(); }\n \n   // Returns true if either:\n   // 1. The event IsPredeterminedError\n@@ -156,21 +153,18 @@ class BufferSequencingEvent : tsl::AsyncPayload::KeepOnError {\n   // blocks the calling thread until either of those 2 happens.\n   bool IsPredeterminedErrorOrDefinedOn(se::Stream* stream);\n \n- private:\n-  bool EventHasBeenRecorded() const ABSL_EXCLUSIVE_LOCKS_REQUIRED(mu_);\n-  uint64_t sequence_number() const;\n+  struct EventState {\n+    // An event that is triggered when the content of one or more buffers has\n+    // been read or written. If this event is used as a definition event and is\n+    // nullptr, it is assumed that the buffer's content is always defined for\n+    // example because it uses storage borrowed from elsewhere.\n+    EventPool::Handle event;\n \n-  // An event that is triggered when the content of one or more buffers has been\n-  // read or written. If this event is used as a definition event and is\n-  // nullptr, it is assumed that the buffer's content is always defined for\n-  // example because it uses storage borrowed from elsewhere.\n-  EventPool::Handle event_;\n+    se::Stream* definition_stream;\n+  };\n \n-  // Cache of event_->sequence_number that avoids synchronization overhead.\n-  // TODO(phawkins): In fact, event_->sequence_number is unused beyond the\n-  // initial population of sequence_number_, and we could remove it if we\n-  // refactored the EventPool API.\n-  std::atomic<uint64_t> sequence_number_{0};\n+ private:\n+  uint64_t sequence_number() const;\n \n   mutable absl::Mutex mu_;\n   // A list of all streams for which the buffer's content is known to be defined\n@@ -181,7 +175,7 @@ class BufferSequencingEvent : tsl::AsyncPayload::KeepOnError {\n \n   // Indicates if the buffer is in an error status. And error status is used to\n   // propagate the error to the buffer consumers.\n-  tsl::AsyncValueRef<absl::Status> defined_status_;\n+  tsl::AsyncValueRef<EventState> event_;\n };\n \n using BufferSequencingEventRef = tsl::AsyncValueRef<BufferSequencingEvent>;"
        },
        {
            "sha": "4efca0f4d3926dcd1053eba74c9812b47bf6fd58",
            "filename": "third_party/xla/xla/python/compile_only_ifrt/client.h",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fcompile_only_ifrt%2Fclient.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fcompile_only_ifrt%2Fclient.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fcompile_only_ifrt%2Fclient.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -256,6 +256,14 @@ class CompileOnlyIfRtClient final\n     return Unimplemented(\"RemapArrays not available with compile-only client.\");\n   }\n \n+  absl::StatusOr<std::vector<xla::ifrt::ArrayRef>> ReshardArrays(\n+      absl::Span<xla::ifrt::ArrayRef> arrays,\n+      absl::Span<const xla::ifrt::ArraySpec> specs,\n+      xla::ifrt::ArrayCopySemantics semantics) override {\n+    return Unimplemented(\n+        \"ReshardArrays not available with compile-only client.\");\n+  }\n+\n   ifrt::Future<> GetReadyFuture(\n       absl::Span<const ifrt::ValueRef> values) override {\n     return ifrt::Future<>(Unimplemented("
        },
        {
            "sha": "828ba1aea80fbc19e0077eea44bd4a471aff6fb6",
            "filename": "third_party/xla/xla/python/ifrt/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -475,10 +475,11 @@ cc_library(\n         \":ifrt\",\n         \":test_util\",\n         \":user_context\",\n+        \"//xla:shape_util\",\n+        \"//xla/pjrt:pjrt_layout\",\n         \"//xla/python/ifrt/ir:sharding_param\",\n         \"//xla/tsl/concurrency:ref_count\",\n         \"//xla/tsl/lib/core:status_test_util\",\n-        \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n         \"@com_google_absl//absl/algorithm:container\","
        },
        {
            "sha": "5a178b0ee5286dc54b151f3df770cf59aefccbba",
            "filename": "third_party/xla/xla/python/ifrt/array_impl_test_lib.cc",
            "status": "modified",
            "additions": 288,
            "deletions": 25,
            "changes": 313,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Farray_impl_test_lib.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Farray_impl_test_lib.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Farray_impl_test_lib.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -30,12 +30,15 @@ limitations under the License.\n #include \"absl/time/clock.h\"\n #include \"absl/time/time.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/layout_util.h\"\n+#include \"xla/pjrt/pjrt_layout.h\"\n #include \"xla/python/ifrt/array.h\"\n #include \"xla/python/ifrt/array_spec.h\"\n #include \"xla/python/ifrt/client.h\"\n #include \"xla/python/ifrt/device.h\"\n #include \"xla/python/ifrt/device_list.h\"\n #include \"xla/python/ifrt/dtype.h\"\n+#include \"xla/python/ifrt/future.h\"\n #include \"xla/python/ifrt/ir/sharding_param.h\"\n #include \"xla/python/ifrt/memory.h\"\n #include \"xla/python/ifrt/shape.h\"\n@@ -45,20 +48,19 @@ limitations under the License.\n #include \"xla/python/ifrt/value.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n-#include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n \n namespace xla {\n namespace ifrt {\n namespace {\n \n+using ::absl_testing::StatusIs;\n using ::testing::_;\n using ::testing::ElementsAre;\n using ::testing::ElementsAreArray;\n using ::testing::HasSubstr;\n using ::testing::SizeIs;\n-using ::tsl::testing::StatusIs;\n \n // Returns a list of non-addressable devices in the client.\n std::vector<Device*> GetNonAddressableDevices(Client* client) {\n@@ -127,10 +129,10 @@ TEST(ArrayImplTest,\n   devices.push_back(client->addressable_devices().at(0));\n   TF_ASSERT_OK_AND_ASSIGN(DeviceListRef device_list,\n                           client->MakeDeviceList(devices));\n-  ShardingRef sharding = xla::ifrt::ConcreteEvenSharding::Create(\n-      std::move(device_list), xla::ifrt::MemoryKind(), shape,\n-      /*shard_shape=*/shape,\n-      /*is_fully_replicated=*/true);\n+  ShardingRef sharding =\n+      ConcreteEvenSharding::Create(std::move(device_list), MemoryKind(), shape,\n+                                   /*shard_shape=*/shape,\n+                                   /*is_fully_replicated=*/true);\n   UserContextScope user_context_scope(test_util::MakeUserContext(100));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n@@ -287,6 +289,36 @@ TEST(ArrayImplTest, MakeArrayFromHostBufferZeroCopy) {\n   // There should be no use-after-free.\n }\n \n+TEST(ArrayImplTest, MakeArrayFromHostBufferDefaultLayout) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n+\n+  DType dtype(DType::kF32);\n+  Shape shape({2, 3});\n+  std::vector<float> data(6);\n+  std::iota(data.begin(), data.end(), 0);\n+  Device* device = client->addressable_devices()[0];\n+\n+  for (Memory* const memory : device->Memories()) {\n+    SCOPED_TRACE(absl::StrCat(memory->Kind()));\n+\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto default_layout,\n+        client->GetDefaultLayout(dtype, shape.dims(), device, memory->Kind()));\n+\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto array,\n+        client->MakeArrayFromHostBuffer(\n+            data.data(), dtype, shape, /*byte_strides=*/std::nullopt,\n+            SingleDeviceSharding::Create(device, memory->Kind()),\n+            Client::HostBufferSemantics::kImmutableOnlyDuringCall,\n+            /*on_done_with_host_buffer=*/nullptr));\n+    TF_ASSERT_OK(array->GetReadyFuture().Await());\n+\n+    TF_ASSERT_OK_AND_ASSIGN(auto layout, array->layout());\n+    EXPECT_EQ(*layout, *default_layout);\n+  }\n+}\n+\n TEST(ArrayImplTest, MakeArrayFromHostBufferAndCopyToHostBuffer) {\n   TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n \n@@ -339,6 +371,37 @@ TEST(ArrayImplTest, MakeArrayFromHostBufferWithByteStridesAndCopyToHostBuffer) {\n   EXPECT_THAT(out_data, ElementsAreArray(expected_out_data));\n }\n \n+TEST(ArrayImplTest, MakeArrayFromHostBufferWithNonCompactByteStrides) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      DeviceListRef device_list,\n+      client->MakeDeviceList(client->addressable_devices()));\n+  ASSERT_GT(device_list->size(), 1);\n+\n+  DType dtype(DType::kS8);\n+  Shape shape({2, 2});\n+  std::vector<int8_t> data = {0, -1, 1, -1, 2, -1, 3, -1};\n+  std::vector<int64_t> byte_strides = {2, 4};\n+  ShardingRef sharding = ConcreteEvenSharding::Create(\n+      device_list, MemoryKind(), shape, /*shard_shape=*/shape,\n+      /*is_fully_replicated=*/true);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      ArrayRef array, client->MakeArrayFromHostBuffer(\n+                          data.data(), dtype, shape, byte_strides, sharding,\n+                          Client::HostBufferSemantics::kImmutableOnlyDuringCall,\n+                          /*on_done_with_host_buffer=*/nullptr));\n+  TF_ASSERT_OK(array->GetReadyFuture().Await());\n+\n+  std::vector<int8_t> out_data(4);\n+  Future<> future =\n+      array->CopyToHostBuffer(out_data.data(), /*byte_strides=*/std::nullopt,\n+                              ArrayCopySemantics::kAlwaysCopy);\n+  TF_ASSERT_OK(future.Await());\n+  EXPECT_THAT(out_data, ElementsAre(0, 2, 1, 3));\n+}\n+\n TEST(ArrayImplTest, MakeArrayFromHostBufferAndCopyToHostBufferWithByteStrides) {\n   TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n \n@@ -548,8 +611,7 @@ TEST(ArrayImplTest, MakeArraysFromHostBufferShardsWithDifferentDevices) {\n   } else {\n     status = result.status();\n   }\n-  EXPECT_THAT(status,\n-              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+  EXPECT_THAT(status, StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n TEST(ArrayImplTest, MakeArraysFromHostBufferShardsWithDifferentMemoryKinds) {\n@@ -605,8 +667,50 @@ TEST(ArrayImplTest, MakeArraysFromHostBufferShardsWithDifferentMemoryKinds) {\n   } else {\n     status = result.status();\n   }\n-  EXPECT_THAT(status,\n-              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+  EXPECT_THAT(status, StatusIs(absl::StatusCode::kInvalidArgument));\n+}\n+\n+TEST(ArrayImplTest, MakeArraysFromHostBufferShardsWithLayout) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n+\n+  DType dtype(DType::kF32);\n+  Shape shape({2, 3});\n+  std::vector<float> data(6);\n+  std::iota(data.begin(), data.end(), 0);\n+  Device* device = client->addressable_devices()[0];\n+\n+  auto layout = std::make_shared<xla::PjRtLayout>(\n+      xla::LayoutUtil::MakeDescendingLayout(shape.dims().size()));\n+\n+  ArrayRef array;\n+  {\n+    Client::HostBuffer host_buffer = {\n+        /*data=*/data.data(),\n+        /*dtype=*/dtype,\n+        /*shape=*/shape,\n+    };\n+    Client::MakeArraysFromHostBufferShardsSpec spec = {\n+        /*buffers=*/{{{0}, host_buffer}},\n+        /*array_spec=*/\n+        {\n+            /*dtype=*/dtype,\n+            /*shape=*/shape,\n+            /*sharding=*/\n+            SingleDeviceSharding::Create(device, MemoryKind()),\n+            /*layout=*/layout,\n+        },\n+    };\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        std::vector<ArrayRef> arrays,\n+        client->MakeArraysFromHostBufferShards(\n+            absl::MakeSpan(&spec, 1),\n+            Client::HostBufferSemantics::kImmutableOnlyDuringCall));\n+    array = std::move(arrays.front());\n+  }\n+\n+  TF_ASSERT_OK(array->GetReadyFuture().Await());\n+  TF_ASSERT_OK_AND_ASSIGN(auto result_layout, array->layout());\n+  EXPECT_EQ(*result_layout, *layout);\n }\n \n TEST(ArrayImplTest, MakeArrayFromHostBufferAndCopyToHostBufferWithString) {\n@@ -767,33 +871,103 @@ TEST(ArrayImplTest,\n   }\n }\n \n+TEST(ArrayImplTest, HostBufferRoundTripAllMemoryKinds) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n+\n+  DType dtype(DType::kF32);\n+  Shape shape({2, 3});\n+  std::vector<float> data(6);\n+  std::iota(data.begin(), data.end(), 0);\n+  Device* device = client->addressable_devices()[0];\n+\n+  for (Memory* const memory : device->Memories()) {\n+    SCOPED_TRACE(absl::StrCat(memory->Kind()));\n+\n+    ShardingRef sharding = SingleDeviceSharding::Create(device, memory->Kind());\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        auto array,\n+        client->MakeArrayFromHostBuffer(\n+            data.data(), dtype, shape, /*byte_strides=*/std::nullopt, sharding,\n+            Client::HostBufferSemantics::kImmutableOnlyDuringCall,\n+            /*on_done_with_host_buffer=*/nullptr));\n+\n+    EXPECT_EQ(array->dtype(), dtype);\n+    EXPECT_EQ(array->shape(), shape);\n+    EXPECT_EQ(array->sharding(), *sharding);\n+    TF_ASSERT_OK(array->GetReadyFuture().Await());\n+\n+    std::vector<float> new_data(6);\n+    Future<> future = array->CopyToHostBuffer(\n+        static_cast<void*>(new_data.data()), /*byte_strides=*/std::nullopt,\n+        ArrayCopySemantics::kReuseInput);\n+    TF_ASSERT_OK(future.Await());\n+    EXPECT_THAT(new_data, ElementsAreArray(data));\n+  }\n+}\n+\n+TEST(ArrayImplTest, HostBufferInt4) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      DeviceListRef device_list,\n+      client->MakeDeviceList(client->addressable_devices()));\n+  ASSERT_GT(device_list->size(), 1);\n+\n+  DType dtype(DType::kS4);\n+  Shape shape({2, 2});\n+  std::vector<int8_t> data = {1, 2, 3, 4};\n+\n+  for (Memory* const memory : device_list->devices().front()->Memories()) {\n+    SCOPED_TRACE(absl::StrCat(memory->Kind()));\n+\n+    ShardingRef sharding = ConcreteEvenSharding::Create(\n+        device_list, memory->Kind(), shape,\n+        /*shard_shape=*/shape, /*is_fully_replicated=*/true);\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        ArrayRef array,\n+        client->MakeArrayFromHostBuffer(\n+            data.data(), dtype, shape,\n+            /*byte_strides=*/std::nullopt, sharding,\n+            Client::HostBufferSemantics::kImmutableOnlyDuringCall,\n+            /*on_done_with_host_buffer=*/nullptr));\n+    TF_ASSERT_OK(array->GetReadyFuture().Await());\n+\n+    std::vector<int8_t> out_data(4);\n+    Future<> future =\n+        array->CopyToHostBuffer(out_data.data(), /*byte_strides=*/std::nullopt,\n+                                ArrayCopySemantics::kAlwaysCopy);\n+    TF_ASSERT_OK(future.Await());\n+    EXPECT_THAT(out_data, ElementsAreArray(data));\n+  }\n+}\n+\n TEST(ArrayImplTest, MakeErrorArrays) {\n   TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n   TF_ASSERT_OK_AND_ASSIGN(\n-      xla::ifrt::DeviceListRef device_list,\n+      DeviceListRef device_list,\n       client->MakeDeviceList(client->addressable_devices()));\n \n   Shape shape({2, 2});\n   ArraySpec array_spec = {\n-      /*dtype=*/xla::ifrt::DType(xla::ifrt::DType::kS8),\n+      /*dtype=*/DType(DType::kS8),\n       /*shape=*/shape,\n       /*sharding=*/\n-      xla::ifrt::ConcreteEvenSharding::Create(\n-          device_list, xla::ifrt::MemoryKind(), shape, /*shard_shape=*/shape,\n-          /*is_fully_replicated=*/true),\n+      ConcreteEvenSharding::Create(device_list, MemoryKind(), shape,\n+                                   /*shard_shape=*/shape,\n+                                   /*is_fully_replicated=*/true),\n   };\n \n   const absl::Status error = absl::InternalError(\"injected error\");\n   UserContextScope user_context_scope(test_util::MakeUserContext(100));\n   TF_ASSERT_OK_AND_ASSIGN(\n-      const std::vector<xla::ifrt::ArrayRef> arrays,\n+      const std::vector<ArrayRef> arrays,\n       client->MakeErrorArrays(error, {array_spec, array_spec}));\n   ASSERT_EQ(arrays.size(), 2);\n \n   EXPECT_THAT(arrays[0]->GetReadyFuture().Await(),\n-              absl_testing::StatusIs(_, HasSubstr(\"injected error\")));\n+              StatusIs(_, HasSubstr(\"injected error\")));\n   EXPECT_THAT(arrays[1]->GetReadyFuture().Await(),\n-              absl_testing::StatusIs(_, HasSubstr(\"injected error\")));\n+              StatusIs(_, HasSubstr(\"injected error\")));\n   EXPECT_EQ(arrays[0]->user_context()->Fingerprint(), 100);\n   EXPECT_EQ(arrays[1]->user_context()->Fingerprint(), 100);\n }\n@@ -819,21 +993,21 @@ TEST(ArrayImplTest, MakeErrorArraysWithAddressableAndNonAddressableDevice) {\n       std::move(device_list), MemoryKind(), shape, /*shard_shape=*/shape,\n       /*is_fully_replicated=*/true);\n \n-  ArraySpec array_spec = {/*dtype=*/xla::ifrt::DType(xla::ifrt::DType::kS8),\n+  ArraySpec array_spec = {/*dtype=*/DType(DType::kS8),\n                           /*shape=*/shape,\n                           /*sharding=*/sharding};\n \n   const absl::Status error = absl::InternalError(\"injected error\");\n   UserContextScope user_context_scope(test_util::MakeUserContext(100));\n   TF_ASSERT_OK_AND_ASSIGN(\n-      const std::vector<xla::ifrt::ArrayRef> arrays,\n+      const std::vector<ArrayRef> arrays,\n       client->MakeErrorArrays(error, {array_spec, array_spec}));\n   ASSERT_EQ(arrays.size(), 2);\n \n   EXPECT_THAT(arrays[0]->GetReadyFuture().Await(),\n-              absl_testing::StatusIs(_, HasSubstr(\"injected error\")));\n+              StatusIs(_, HasSubstr(\"injected error\")));\n   EXPECT_THAT(arrays[1]->GetReadyFuture().Await(),\n-              absl_testing::StatusIs(_, HasSubstr(\"injected error\")));\n+              StatusIs(_, HasSubstr(\"injected error\")));\n   EXPECT_EQ(arrays[0]->user_context()->Fingerprint(), 100);\n   EXPECT_EQ(arrays[1]->user_context()->Fingerprint(), 100);\n }\n@@ -1148,7 +1322,7 @@ TEST(ArrayImplTest, CopyToDifferentDevice) {\n             SingleDeviceShardSemantics::kAddressableShards));\n   }\n \n-  absl::InlinedVector<xla::ifrt::Device*, 1> new_devices;\n+  absl::InlinedVector<Device*, 1> new_devices;\n   for (auto it = devices->devices().rbegin(); it != devices->devices().rend();\n        ++it) {\n     new_devices.push_back(*it);\n@@ -1210,7 +1384,7 @@ TEST(ArrayImplTest, CopyMixedSourceDevices) {\n                   ->CopyArrays(absl::MakeSpan(arrays), std::move(device_list),\n                                MemoryKind(), ArrayCopySemantics::kAlwaysCopy)\n                   .status(),\n-              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+              StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n TEST(ArrayImplTest, CopyMixedSourceMemoryKind) {\n@@ -1244,7 +1418,96 @@ TEST(ArrayImplTest, CopyMixedSourceMemoryKind) {\n                   ->CopyArrays(absl::MakeSpan(arrays), std::move(device_list),\n                                MemoryKind(), ArrayCopySemantics::kAlwaysCopy)\n                   .status(),\n-              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+              StatusIs(absl::StatusCode::kInvalidArgument));\n+}\n+\n+TEST(ArrayImplTest, CopyPreservesDefaultLayouts) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n+\n+  DType dtype(DType::kF32);\n+  Shape shape({2, 3});\n+  std::vector<float> data(6);\n+  std::iota(data.begin(), data.end(), 0);\n+  Device* device = client->addressable_devices()[0];\n+\n+  for (Memory* const src_memory : device->Memories()) {\n+    for (Memory* const dst_memory : device->Memories()) {\n+      SCOPED_TRACE(\n+          absl::StrCat(src_memory->Kind(), \" -> \", dst_memory->Kind()));\n+\n+      ShardingRef sharding =\n+          SingleDeviceSharding::Create(device, src_memory->Kind());\n+      TF_ASSERT_OK_AND_ASSIGN(\n+          auto array,\n+          client->MakeArrayFromHostBuffer(\n+              data.data(), dtype, shape, /*byte_strides=*/std::nullopt,\n+              sharding, Client::HostBufferSemantics::kImmutableOnlyDuringCall,\n+              /*on_done_with_host_buffer=*/nullptr));\n+      TF_ASSERT_OK(array->GetReadyFuture().Await());\n+\n+      TF_ASSERT_OK_AND_ASSIGN(auto src_layout, array->layout());\n+      TF_ASSERT_OK_AND_ASSIGN(\n+          auto src_default_layout,\n+          client->GetDefaultLayout(dtype, shape.dims(), device,\n+                                   src_memory->Kind()));\n+      EXPECT_EQ(*src_layout, *src_default_layout);\n+\n+      TF_ASSERT_OK_AND_ASSIGN(\n+          auto new_arrays, client->CopyArrays(absl::MakeSpan(&array, 1),\n+                                              std::nullopt, dst_memory->Kind(),\n+                                              ArrayCopySemantics::kAlwaysCopy));\n+      ASSERT_THAT(new_arrays, SizeIs(1));\n+      TF_ASSERT_OK_AND_ASSIGN(auto dst_layout, new_arrays[0]->layout());\n+      TF_ASSERT_OK_AND_ASSIGN(\n+          auto dst_default_layout,\n+          client->GetDefaultLayout(dtype, shape.dims(), device,\n+                                   dst_memory->Kind()));\n+      EXPECT_EQ(*dst_layout, *dst_default_layout);\n+    }\n+  }\n+}\n+\n+TEST(ArrayImplTest, MakeAndCopyZeroSizedBuffers) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n+\n+  Device* const device = client->addressable_devices().front();\n+  TF_ASSERT_OK_AND_ASSIGN(DeviceListRef device_list,\n+                          client->MakeDeviceList({device}));\n+\n+  DType dtype(DType::kF32);\n+  Shape shape({0, 1});\n+\n+  for (Memory* const memory : device->Memories()) {\n+    SCOPED_TRACE(absl::StrCat(memory->Kind()));\n+\n+    ShardingRef sharding = ConcreteEvenSharding::Create(\n+        device_list, memory->Kind(), shape,\n+        /*shard_shape=*/shape, /*is_fully_replicated=*/true);\n+    TF_ASSERT_OK_AND_ASSIGN(\n+        ArrayRef array,\n+        client->MakeArrayFromHostBuffer(\n+            nullptr, dtype, shape,\n+            /*byte_strides=*/std::nullopt, sharding,\n+            Client::HostBufferSemantics::kImmutableOnlyDuringCall,\n+            /*on_done_with_host_buffer=*/nullptr));\n+    TF_ASSERT_OK(array->GetReadyFuture().Await());\n+\n+    for (Device* const device : client->addressable_devices()) {\n+      TF_ASSERT_OK_AND_ASSIGN(DeviceListRef single_device_list,\n+                              client->MakeDeviceList({device}));\n+      TF_ASSERT_OK_AND_ASSIGN(\n+          auto copied,\n+          client->CopyArrays(absl::MakeSpan(&array, 1),\n+                             std::move(single_device_list), std::nullopt,\n+                             ArrayCopySemantics::kReuseInput));\n+      TF_ASSERT_OK(copied[0]->GetReadyFuture().Await());\n+\n+      Future<> future =\n+          copied[0]->CopyToHostBuffer(nullptr, /*byte_strides=*/std::nullopt,\n+                                      ArrayCopySemantics::kAlwaysCopy);\n+      TF_ASSERT_OK(future.Await());\n+    }\n+  }\n }\n \n TEST(ArrayImplTest, GetReadyFuture) {"
        },
        {
            "sha": "4d2f2b0c6520a65ac518f0f8f2af74a15f18ade6",
            "filename": "third_party/xla/xla/python/ifrt/client.h",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fclient.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fclient.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fclient.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -253,6 +253,16 @@ class Client : public llvm::RTTIExtends<Client, llvm::RTTIRoot> {\n       const RemapPlan& plan, absl::Span<xla::ifrt::ArrayRef> arrays,\n       ArrayCopySemantics semantics) = 0;\n \n+  // Reshards arrays to new arrays according to the given specs.\n+  //\n+  // If destination specs have the layout specifications, applies it to the\n+  // output arrays, if not, uses the device-default layout.\n+  //\n+  // NOTE: `ArrayCopySemantics::kReuseInput` is not allowed.\n+  virtual absl::StatusOr<std::vector<ArrayRef>> ReshardArrays(\n+      absl::Span<ArrayRef> arrays, absl::Span<const ArraySpec> specs,\n+      ArrayCopySemantics semantics) = 0;\n+\n   // Returns a future that becomes ready once all of the values become ready.\n   //\n   // Timing and error semantics:"
        },
        {
            "sha": "e25f96e51defd47e338c600afafae3cb4960fb7c",
            "filename": "third_party/xla/xla/python/ifrt/mock.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fmock.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fmock.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fmock.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -153,6 +153,12 @@ MockClient::MockClient(std::unique_ptr<xla::ifrt::Client> delegated)\n                             ArrayCopySemantics semantics) {\n         return delegated_->RemapArrays(plan, arrays, semantics);\n       });\n+  ON_CALL(*this, ReshardArrays)\n+      .WillByDefault([this](absl::Span<ArrayRef> arrays,\n+                            absl::Span<const ArraySpec> specs,\n+                            ArrayCopySemantics semantics) {\n+        return delegated_->ReshardArrays(arrays, specs, semantics);\n+      });\n   ON_CALL(*this, GetReadyFuture)\n       .WillByDefault([this](absl::Span<const ValueRef> values) {\n         return delegated_->GetReadyFuture(values);"
        },
        {
            "sha": "e7d300e850553dc2688c64e6493dd290109ebf1a",
            "filename": "third_party/xla/xla/python/ifrt/mock.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fmock.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fmock.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fmock.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -147,6 +147,10 @@ class MockClient : public llvm::RTTIExtends<MockClient, Client> {\n               (const RemapPlan& plan, absl::Span<ArrayRef> arrays,\n                ArrayCopySemantics semantics),\n               (final));\n+  MOCK_METHOD(absl::StatusOr<std::vector<ArrayRef>>, ReshardArrays,\n+              (absl::Span<ArrayRef> arrays, absl::Span<const ArraySpec> specs,\n+               ArrayCopySemantics semantics),\n+              (final));\n   MOCK_METHOD(Future<>, GetReadyFuture, (absl::Span<const ValueRef> values),\n               (final));\n   MOCK_METHOD(absl::StatusOr<tsl::RCReference<Tuple>>, MakeTuple,"
        },
        {
            "sha": "54cdf4bfd11522e17d0f81331c8f0e5f850369ba",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2FBUILD?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -214,15 +214,15 @@ ifrt_proxy_cc_test(\n         \"//xla/python/ifrt_proxy/common:types\",\n         \"//xla/service:computation_placer_hdr\",\n         \"//xla/tsl/concurrency:ref_count\",\n-        \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n         \"@com_google_googletest//:gtest_main\",\n         \"@llvm-project//llvm:Support\",\n-        \"@local_tsl//tsl/platform\",\n         \"@local_tsl//tsl/platform:protobuf\",\n     ],\n )\n@@ -485,7 +485,9 @@ cc_library(\n     srcs = [\"grpc_host_buffer.cc\"],\n     hdrs = [\"grpc_host_buffer.h\"],\n     deps = [\n+        \":global_flags\",\n         \":host_buffer\",\n+        \"//xla/pjrt:semaphore\",\n         \"//xla/pjrt/distributed:util\",\n         \"//xla/python/ifrt\",\n         \"//xla/python/ifrt_proxy/common:grpc_ifrt_service_cc_grpc_proto\","
        },
        {
            "sha": "0337f7f97a730abcb037880d2f95c80770275df4",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/client.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -96,6 +96,13 @@ class Client final : public llvm::RTTIExtends<Client, xla::ifrt::Client> {\n       const RemapPlan& plan, absl::Span<xla::ifrt::ArrayRef> arrays,\n       ArrayCopySemantics semantics) override;\n \n+  absl::StatusOr<std::vector<xla::ifrt::ArrayRef>> ReshardArrays(\n+      absl::Span<ArrayRef> arrays, absl::Span<const ArraySpec> specs,\n+      ArrayCopySemantics semantics) override {\n+    return absl::UnimplementedError(\n+        \"ReshardArrays is not supported for the IFRT proxy client.\");\n+  }\n+\n   xla::ifrt::Future<> GetReadyFuture(\n       absl::Span<const ValueRef> values) override;\n "
        },
        {
            "sha": "a5de0be104876cd713b75af6c3ce843695de0496",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/client_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 14,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fclient_test.cc?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -22,6 +22,7 @@\n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n@@ -49,9 +50,8 @@\n #include \"xla/python/ifrt_proxy/common/types.h\"\n #include \"xla/service/computation_placer.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n-#include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n-#include \"tsl/platform/platform.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n #include \"tsl/platform/protobuf.h\"  // IWYU pragma: keep\n \n namespace xla {\n@@ -66,13 +66,9 @@ using ::testing::Pointee;\n using ::testing::Return;\n using ::testing::SizeIs;\n using ::testing::UnorderedElementsAre;\n-using ::tsl::testing::IsOk;\n-using ::tsl::testing::IsOkAndHolds;\n \n-#if defined(PLATFORM_GOOGLE)\n-using ::testing::EquivToProto;\n-using ::testing::proto::Partially;\n-#endif\n+using ::tsl::proto_testing::EquivToProto;\n+using ::tsl::proto_testing::Partially;\n \n class ClientTest : public ::testing::TestWithParam</*protocol_version=*/int> {\n  protected:\n@@ -430,8 +426,6 @@ TEST_P(ClientTest, CopyArraysCustomLayoutSuccess) {\n       layout_2_->ToString());\n }\n \n-// TODO(b/315809436): Test needs rewrite because protobuf matchers are not OSS\n-#if defined(PLATFORM_GOOGLE)\n TEST_P(ClientTest, GetDefaultDeviceAssignmentSuccess) {\n   IfrtResponse response;\n   xla::DeviceAssignment assignment(1, 3);\n@@ -453,10 +447,7 @@ TEST_P(ClientTest, GetDefaultDeviceAssignmentSuccess) {\n   EXPECT_EQ(assignment_got.replica_count(), 1);\n   EXPECT_EQ(assignment_got.computation_count(), 3);\n }\n-#endif\n \n-// TODO(b/315809436): Test needs rewrite because protobuf matchers are not OSS\n-#if defined(PLATFORM_GOOGLE)\n TEST_P(ClientTest, GetDefaultDeviceAssignmentFailure) {\n   EXPECT_CALL(*session_, Enqueue(Pointee(Partially(EquivToProto(\n                              R\"pb(\n@@ -471,7 +462,6 @@ TEST_P(ClientTest, GetDefaultDeviceAssignmentFailure) {\n   EXPECT_THAT(client_->GetDefaultDeviceAssignment(1, 3),\n               Not(absl_testing::IsOk()));\n }\n-#endif\n \n INSTANTIATE_TEST_SUITE_P(\n     ClientTestWithAllVersions, ClientTest,"
        },
        {
            "sha": "6b68f40d910e42a768fb98f78bd179afb96ef07e",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/global_flags.h",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fglobal_flags.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad9939c08bd52f957e78d0b93484d700882b265e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fglobal_flags.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fglobal_flags.h?ref=ad9939c08bd52f957e78d0b93484d700882b265e",
            "patch": "@@ -36,6 +36,10 @@ struct GlobalClientFlags {\n \n   // TODO(b/393445969): Implement faster is_delete without needing a hack.\n   bool array_is_deleted_hack;\n+\n+  // Zero or negative values are interpreted as no maximum.\n+  int grpc_max_ongoing_host_buffer_stores;\n+  int grpc_max_ongoing_host_buffer_lookups;\n };\n \n GlobalClientFlags* GetGlobalClientFlags();\n@@ -44,7 +48,11 @@ inline std::ostream& operator<<(std::ostream& os, GlobalClientFlags flags) {\n   return os << \"xla::ifrt::proxy::GlobalClientFlags{\"\n             << \"synchronous_host_buffer_store=\"\n             << flags.synchronous_host_buffer_store << \",\"\n-            << \"array_is_deleted_hack=\" << flags.array_is_deleted_hack << \"}\";\n+            << \"array_is_deleted_hack=\" << flags.array_is_deleted_hack << \",\"\n+            << \"grpc_max_ongoing_host_buffer_stores=\"\n+            << flags.grpc_max_ongoing_host_buffer_stores << \",\"\n+            << \"grpc_max_ongoing_host_buffer_lookups=\"\n+            << flags.grpc_max_ongoing_host_buffer_lookups << \"}\";\n }\n \n }  // namespace proxy"
        }
    ],
    "stats": {
        "total": 21590,
        "additions": 15088,
        "deletions": 6502
    }
}