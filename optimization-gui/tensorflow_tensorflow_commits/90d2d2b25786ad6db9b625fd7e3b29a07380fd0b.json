{
    "author": "seantalts",
    "message": "[XLA:CPU] Add CPP->LLVM IR build rules\n\nPiperOrigin-RevId: 812791562",
    "sha": "90d2d2b25786ad6db9b625fd7e3b29a07380fd0b",
    "files": [
        {
            "sha": "c88181cc17dd549bf70749bdd3690b67cc29c3f2",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/BUILD",
            "status": "added",
            "additions": 77,
            "deletions": 0,
            "changes": 77,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2FBUILD?ref=90d2d2b25786ad6db9b625fd7e3b29a07380fd0b",
            "patch": "@@ -0,0 +1,77 @@\n+load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n+load(\"//xla:xla.default.bzl\", \"xla_cc_test\")\n+load(\":cc_to_llvm_ir.bzl\", \"cc_to_llvm_ir\")\n+\n+package(\n+    # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n+    default_visibility = [\":friends\"],\n+    licenses = [\"notice\"],\n+)\n+\n+package_group(\n+    name = \"friends\",\n+    includes = [\n+        \"//xla:friends\",\n+    ],\n+)\n+\n+# This empty target provides the C++ compilation context for the C++ source file.\n+cc_library(\n+    name = \"cpp_context_provider\",\n+    srcs = [],\n+)\n+\n+cc_library(\n+    name = \"tanh\",\n+    srcs = [\"tanh.cc\"],\n+    hdrs = [\"tanh.h\"],\n+    deps = [\n+        \":vector_ops\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"vector_ops\",\n+    hdrs = [\"vector_ops.h\"],\n+)\n+\n+cc_to_llvm_ir(\n+    name = \"tanh_ir_file\",\n+    src = \"tanh.cc\",\n+    out = \"tanh.ll\",\n+    deps = [\n+        \":cpp_context_provider\",\n+        \":tanh\",\n+        \":vector_ops\",\n+    ],\n+)\n+\n+genrule(\n+    name = \"tanh_ll_header\",\n+    srcs = [\":tanh_ir_file\"],\n+    outs = [\"tanh_ll.h\"],\n+    # This command wraps the IR text in a C++ raw string literal.\n+    cmd = \"\"\"\n+        echo 'constexpr const char* tanh_ir_string = R\"gen_ir(' > $@ && \\\\\n+        cat $(location :tanh_ir_file) >> $@ && \\\\\n+        echo ')gen_ir\";' >> $@\n+    \"\"\",\n+)\n+\n+cc_library(\n+    name = \"tanh_ll_header_lib\",\n+    hdrs = [\":tanh_ll_header\"],\n+)\n+\n+xla_cc_test(\n+    name = \"tanh_test\",\n+    srcs = [\"tanh_test.cc\"],\n+    deps = [\n+        \":tanh\",\n+        \":tanh_ll_header_lib\",\n+        \":vector_ops\",\n+        \"@com_google_googletest//:gtest_main\",\n+        \"@local_tsl//tsl/platform:status_matchers\",\n+        \"@local_tsl//tsl/platform:test\",\n+    ],\n+)"
        },
        {
            "sha": "2b1ba5a444def481f552b3eb1edb276c933814cf",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/cc_to_llvm_ir.bzl",
            "status": "added",
            "additions": 75,
            "deletions": 0,
            "changes": 75,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fcc_to_llvm_ir.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fcc_to_llvm_ir.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fcc_to_llvm_ir.bzl?ref=90d2d2b25786ad6db9b625fd7e3b29a07380fd0b",
            "patch": "@@ -0,0 +1,75 @@\n+\"\"\"\n+Starlark rule for compiling a C++ file to LLVM IR (.ll) in a hermetic way.\n+\"\"\"\n+\n+load(\"@rules_cc//cc:find_cc_toolchain.bzl\", \"find_cc_toolchain\", \"use_cc_toolchain\")\n+load(\"@rules_cc//cc/common:cc_common.bzl\", \"cc_common\")\n+load(\"//xla/tsl:package_groups.bzl\", \"DEFAULT_LOAD_VISIBILITY\")\n+\n+visibility(DEFAULT_LOAD_VISIBILITY)\n+\n+def _cc_to_llvm_ir_impl(ctx):\n+    cc_toolchain = find_cc_toolchain(ctx)\n+\n+    feature_configuration = cc_common.configure_features(\n+        ctx = ctx,\n+        cc_toolchain = cc_toolchain,\n+    )\n+    dep_compilation_contexts = [\n+        dep[CcInfo].compilation_context\n+        for dep in ctx.attr.deps\n+    ]\n+\n+    compilation_outputs = cc_common.compile(\n+        actions = ctx.actions,\n+        feature_configuration = feature_configuration,\n+        cc_toolchain = cc_toolchain,\n+        srcs = [ctx.file.src],\n+        cxx_flags = [\n+            \"-S\",\n+            \"-emit-llvm\",\n+        ],\n+        name = \"cc_to_llvm_ir\",\n+        compilation_contexts = dep_compilation_contexts,\n+    )\n+\n+    # The compile action produces an output file. Even though we requested\n+    # LLVM IR, the filename will likely end in \".o\" or \".pic.o\".\n+    # We take the first (and only) object file from the outputs.\n+    intermediate_ll_file = compilation_outputs[1].pic_objects[0]\n+    final_ll_file = ctx.outputs.out\n+\n+    ctx.actions.run_shell(\n+        inputs = [intermediate_ll_file],\n+        outputs = [final_ll_file],\n+        command = \"cp %s %s\" % (intermediate_ll_file.path, final_ll_file.path),\n+        progress_message = \"Copying LLVM IR for %s\" % ctx.label.name,\n+        mnemonic = \"CopyLlvmIr\",\n+    )\n+\n+    return [DefaultInfo(files = depset([final_ll_file]))]\n+\n+cc_to_llvm_ir = rule(\n+    implementation = _cc_to_llvm_ir_impl,\n+    attrs = {\n+        \"src\": attr.label(\n+            allow_single_file = True,\n+            mandatory = True,\n+            doc = \"The C++ source file to compile.\",\n+        ),\n+        \"out\": attr.output(\n+            mandatory = True,\n+            doc = \"The output .ll (LLVM IR) file.\",\n+        ),\n+        \"deps\": attr.label_list(\n+            providers = [CcInfo],\n+            mandatory = True,\n+            doc = \"A cc_library target to provide the C++ compilation context. You MUST specify at least one cc_library dependency here so this rule can leech the C++ context required for compilation.\",\n+        ),\n+        \"_cc_toolchain\": attr.label(default = \"@bazel_tools//tools/cpp:current_cc_toolchain\"),\n+    },\n+    # This declares that the rule needs a C++ toolchain to be present.\n+    toolchains = use_cc_toolchain(),\n+    doc = \"Compiles a single C++ file to LLVM IR (.ll) using the C++ toolchain.\",\n+    fragments = [\"cpp\"],\n+)"
        },
        {
            "sha": "b1220f2f4341ed590f0617c2bef35c6b59aca8d7",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/tanh.cc",
            "status": "added",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh.cc?ref=90d2d2b25786ad6db9b625fd7e3b29a07380fd0b",
            "patch": "@@ -0,0 +1,24 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/codegen/intrinsic/cpp/tanh.h\"\n+\n+namespace xla {\n+namespace codegen {\n+\n+template Vec4f FastTanhf<Vec4f>(Vec4f);\n+\n+}  // namespace codegen\n+}  // namespace xla"
        },
        {
            "sha": "8a1eb61a7ea0ddcf64d06c5c37ea1eace1964f61",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/tanh.h",
            "status": "added",
            "additions": 70,
            "deletions": 0,
            "changes": 70,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh.h?ref=90d2d2b25786ad6db9b625fd7e3b29a07380fd0b",
            "patch": "@@ -0,0 +1,70 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_CODEGEN_INTRINSIC_CPP_TANH_H_\n+#define XLA_CODEGEN_INTRINSIC_CPP_TANH_H_\n+\n+#include <array>\n+\n+#include \"xla/codegen/intrinsic/cpp/vector_ops.h\"\n+\n+namespace xla {\n+namespace codegen {\n+\n+template <typename T>\n+T FastTanhf(T x) {\n+  T abs_x = BitwiseAbs<T>(x);\n+  T large_result = BitwiseCopysign<T>(T{1.0f}, x);\n+  auto is_large = abs_x >= T{20.0f};\n+\n+  // For small inputs, tanh(x) is approximately x.\n+  constexpr float kSmallValueThreshold = 0.0004f;\n+  auto is_small = abs_x < kSmallValueThreshold;\n+\n+  constexpr float kPlusClamp = 7.99881172180175781f;\n+  T clamped_x = Clamp(x, -kPlusClamp, kPlusClamp);\n+\n+  static constexpr std::array<float, 7> kNumeratorCoeffs = {\n+      -2.76076847742355e-16f, 2.00018790482477e-13f, -8.60467152213735e-11f,\n+      5.12229709037114e-08f,  1.48572235717979e-05f, 6.37261928875436e-04f,\n+      4.89352455891786e-03f};\n+  static constexpr std::array<float, 4> kDenominatorCoeffs = {\n+      1.19825839466702e-06f, 1.18534705686654e-04f, 2.26843463243900e-03f,\n+      4.89352518554385e-03f};\n+\n+  // Evaluate the polynomial using Horner's method.\n+  T x2 = clamped_x * clamped_x;\n+  T numerator = T{kNumeratorCoeffs[0]};\n+  for (int i = 1; i < 7; ++i) {\n+    numerator = numerator * x2 + T{kNumeratorCoeffs[i]};\n+  }\n+  numerator = clamped_x * numerator;\n+\n+  T denominator = T{kDenominatorCoeffs[0]};\n+  for (int i = 1; i < 4; ++i) {\n+    denominator = denominator * x2 + T{kDenominatorCoeffs[i]};\n+  }\n+\n+  T poly_result = numerator / denominator;\n+\n+  // The ternary operator `?:` compiles to a branchless `select` instruction.\n+  T small_or_poly = is_small ? x : poly_result;\n+  return is_large ? large_result : small_or_poly;\n+}\n+\n+}  // namespace codegen\n+}  // namespace xla\n+\n+#endif  // XLA_CODEGEN_INTRINSIC_CPP_TANH_H_"
        },
        {
            "sha": "e17265e8dd7930df6f12bca27c22a9cf699f115b",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/tanh_test.cc",
            "status": "added",
            "additions": 36,
            "deletions": 0,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh_test.cc?ref=90d2d2b25786ad6db9b625fd7e3b29a07380fd0b",
            "patch": "@@ -0,0 +1,36 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <string>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"xla/codegen/intrinsic/cpp/tanh_ll.h\"\n+\n+namespace xla {\n+namespace codegen {\n+using ::testing::ContainsRegex;\n+\n+namespace {\n+\n+TEST(TanhTest, FloatTanhVectorized) {\n+  std::string ir = tanh_ir_string;\n+  EXPECT_THAT(ir, ContainsRegex(\"fmul <4 x float>\"));\n+  EXPECT_THAT(\n+      ir, ContainsRegex(\"fcmp olt <4 x float>.*float 0x3F3A36E2E0000000.*\"));\n+}\n+}  // namespace\n+}  // namespace codegen\n+}  // namespace xla"
        },
        {
            "sha": "8928d7ffa9e90f1f8f6275c6f921ec379b3db6bb",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/vector_ops.h",
            "status": "added",
            "additions": 117,
            "deletions": 0,
            "changes": 117,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fvector_ops.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/90d2d2b25786ad6db9b625fd7e3b29a07380fd0b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fvector_ops.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fvector_ops.h?ref=90d2d2b25786ad6db9b625fd7e3b29a07380fd0b",
            "patch": "@@ -0,0 +1,117 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_CODEGEN_INTRINSIC_CPP_VECTOR_OPS_H_\n+#define XLA_CODEGEN_INTRINSIC_CPP_VECTOR_OPS_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <type_traits>\n+\n+namespace xla {\n+namespace codegen {\n+// Float types\n+typedef float Vec4f __attribute__((vector_size(16)));\n+typedef float Vec8f __attribute__((vector_size(32)));\n+typedef double Vec2d __attribute__((vector_size(16)));\n+typedef double Vec4d __attribute__((vector_size(32)));\n+\n+// Corresponding integer types\n+typedef uint32_t Vec4i __attribute__((vector_size(16)));\n+typedef uint32_t Vec8i __attribute__((vector_size(32)));\n+typedef uint64_t Vec2q __attribute__((vector_size(16)));\n+typedef uint64_t Vec4q __attribute__((vector_size(32)));\n+\n+namespace internal {\n+// Helper type to select the corresponding integer vector type.\n+template <typename ScalarInt, size_t Width>\n+struct MakeIntVec;\n+\n+template <>\n+struct MakeIntVec<uint32_t, 4> {\n+  using type = Vec4i;\n+};\n+template <>\n+struct MakeIntVec<uint32_t, 8> {\n+  using type = Vec8i;\n+};\n+template <>\n+struct MakeIntVec<uint64_t, 2> {\n+  using type = Vec2q;\n+};\n+template <>\n+struct MakeIntVec<uint64_t, 4> {\n+  using type = Vec4q;\n+};\n+\n+// This trait takes a float vector and provides its integer vector partner.\n+template <typename FloatVec>\n+struct CorrespondingIntVector {\n+ private:\n+  using ScalarFloat = decltype(FloatVec{}[0]);\n+  static constexpr size_t kWidth = sizeof(FloatVec) / sizeof(ScalarFloat);\n+  using ScalarInt =\n+      std::conditional_t<sizeof(ScalarFloat) == 4, uint32_t, uint64_t>;\n+\n+ public:\n+  using type = typename MakeIntVec<ScalarInt, kWidth>::type;\n+};\n+}  // namespace internal\n+\n+// Computes the absolute value of a vector using bitwise operations.\n+// FloatVec: The floating-point vector type (e.g., Vec4f).\n+// x: The input vector.\n+// Returns a new vector containing the absolute value of each element in x.\n+template <typename FloatVec>\n+FloatVec BitwiseAbs(FloatVec x) {\n+  using IntVec = typename internal::CorrespondingIntVector<FloatVec>::type;\n+  // Get the underlying scalar integer type (e.g., int from Vec4i).\n+  using ScalarInt = decltype(IntVec{}[0]);\n+\n+  // Create a mask to clear the sign bit (e.g., 0x7FFFFFFF for int).\n+  // This is a vector where every element is the mask.\n+  const IntVec abs_mask =\n+      IntVec{~(static_cast<ScalarInt>(1) << (sizeof(ScalarInt) * 8 - 1))};\n+\n+  // Reinterpret float as int, apply the mask, and reinterpret back.\n+  return __builtin_bit_cast(FloatVec, __builtin_bit_cast(IntVec, x) & abs_mask);\n+}\n+\n+// Copies the sign of one vector to the value of another.\n+// FloatVec: The floating-point vector type (e.g., Vec4f).\n+// value: The vector providing the magnitude.\n+// sign_source: The vector providing the sign.\n+// Returns a new vector with the magnitude of `value` and the sign of\n+// `sign_source`.\n+template <typename FloatVec>\n+FloatVec BitwiseCopysign(FloatVec value, FloatVec sign_source) {\n+  using IntVec = typename internal::CorrespondingIntVector<FloatVec>::type;\n+  using ScalarInt = decltype(IntVec{}[0]);\n+  const IntVec sign_mask =\n+      IntVec{static_cast<ScalarInt>(1) << (sizeof(ScalarInt) * 8 - 1)};\n+  FloatVec value_abs = BitwiseAbs<FloatVec>(value);\n+  IntVec sign_bits = __builtin_bit_cast(IntVec, sign_source) & sign_mask;\n+  return __builtin_bit_cast(FloatVec,\n+                            __builtin_bit_cast(IntVec, value_abs) | sign_bits);\n+}\n+\n+template <typename Vec, typename Scalar>\n+Vec Clamp(Vec x, Scalar min, Scalar max) {\n+  return x < min ? min : x > max ? max : x;\n+}\n+}  // namespace codegen\n+}  // namespace xla\n+\n+#endif  // XLA_CODEGEN_INTRINSIC_CPP_VECTOR_OPS_H_"
        }
    ],
    "stats": {
        "total": 399,
        "additions": 399,
        "deletions": 0
    }
}