{
    "author": "chsigg",
    "message": "Remove default backend config fields from test HLO strings.\n\nThis change removes `operation_queue_id: \"0\"`, `wait_on_operation_queues: []`, and other fields like `force_earliest_schedule: false`, `sliding_window_length: 0`, and `force_deterministic: false` from the `backend_config` in various test HLO strings. These fields are being removed because they represent default values and do not need to be explicitly specified.\n\nPiperOrigin-RevId: 838017400",
    "sha": "bd9db275b3c65e5758dae8a8be968c623c39b62b",
    "files": [
        {
            "sha": "d338cabb561e48563ba47b712076cb59481c5926",
            "filename": "third_party/xla/xla/backends/gpu/codegen/dynamic_slice_fusion_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fdynamic_slice_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fdynamic_slice_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fdynamic_slice_fusion_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -2886,7 +2886,7 @@ TEST_F(DynamicSliceFusionTest, ReduceScatterDUSConstant) {\n     %param_1.1 = f16[128,128]{1,0} parameter(1)\n     %constant_20 = u32[] constant(20)\n     %constant_0 = u32[] constant(0)\n-    ROOT %dynamic-slice-fusion = f16[128,128]{1,0} fusion(%param_0.1, %param_1.1, %constant_20, %constant_0), kind=kCustom, calls=%dynamic-slice-fusion, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"fusion_backend_config\":{\"kind\":\"__custom_fusion\",\"custom_fusion_config\":{\"name\":\"dynamic_address_computation\"}},\"force_earliest_schedule\":false}\n+    ROOT %dynamic-slice-fusion = f16[128,128]{1,0} fusion(%param_0.1, %param_1.1, %constant_20, %constant_0), kind=kCustom, calls=%dynamic-slice-fusion, backend_config={\"fusion_backend_config\":{\"kind\":\"__custom_fusion\",\"custom_fusion_config\":{\"name\":\"dynamic_address_computation\"}},\"force_earliest_schedule\":false}\n   })\";\n \n   ErrorSpec error_spec{/*aabs=*/1e-3, /*arel=*/1e-3};\n@@ -2937,7 +2937,7 @@ TEST_F(DynamicSliceFusionTest, ReduceScatterDUSParameterOffset) {\n     %param_1 = f16[128,128]{1,0} parameter(1)\n     %param_2 = u32[] parameter(2)\n     %constant_0 = u32[] constant(0)\n-    ROOT %dynamic-slice-fusion = f16[128,128]{1,0} fusion(%param_0, %param_1, %param_2, %constant_0), kind=kCustom, calls=%dynamic-slice-fusion, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"fusion_backend_config\":{\"kind\":\"__custom_fusion\",\"custom_fusion_config\":{\"name\":\"dynamic_address_computation\"}},\"force_earliest_schedule\":false}\n+    ROOT %dynamic-slice-fusion = f16[128,128]{1,0} fusion(%param_0, %param_1, %param_2, %constant_0), kind=kCustom, calls=%dynamic-slice-fusion, backend_config={\"fusion_backend_config\":{\"kind\":\"__custom_fusion\",\"custom_fusion_config\":{\"name\":\"dynamic_address_computation\"}},\"force_earliest_schedule\":false}\n   })\";\n \n   ErrorSpec error_spec{/*aabs=*/1e-3, /*arel=*/1e-3};"
        },
        {
            "sha": "a03aaa8fcd81ef15ac8dc100120ccd96962b3eba",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/dot_algorithms_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -916,8 +916,6 @@ TEST_F(TritonAlgorithmTest, Dot_BF16_X6_WithConst) {\n         kind=kCustom,\n         calls=triton_fusion_dot,\n         backend_config={\n-          \"operation_queue_id\":\"0\",\n-          \"wait_on_operation_queues\":[],\n           \"fusion_backend_config\":{\n             \"kind\":\"__triton_nested_gemm_fusion\",\n             \"block_level_fusion_config\":{"
        },
        {
            "sha": "cc56b0764c8d5f2900e3d5930cf273e96ecc6a02",
            "filename": "third_party/xla/xla/service/gpu/alias_info_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Falias_info_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Falias_info_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Falias_info_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -859,7 +859,7 @@ ENTRY main {\n   p0 = f32[8,8]{1,0} parameter(0)\n   p1 = f32[128]{0} parameter(1)\n   p2 = f32[256]{0} parameter(2)\n-  ROOT %address_computation = (f32[8]{0}, (f32[128]{0}, f32[256]{0})) fusion(p0, p1, p2), kind=kCustom, calls=%dynamic-slice-fusion, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"fusion_backend_config\":{\"kind\":\"__custom_fusion\",\"custom_fusion_config\":{\"name\":\"address_computation\",\"kernel_index\":0}},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n+  ROOT %address_computation = (f32[8]{0}, (f32[128]{0}, f32[256]{0})) fusion(p0, p1, p2), kind=kCustom, calls=%dynamic-slice-fusion, backend_config={\"fusion_backend_config\":{\"kind\":\"__custom_fusion\",\"custom_fusion_config\":{\"name\":\"address_computation\",\"kernel_index\":0}},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n }\n )\";\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,"
        },
        {
            "sha": "15d9886be4869e5183cd83efcc39aaf4b09a1e99",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -682,7 +682,7 @@ gemm_fusion {\n ENTRY main {\n   p0 = f8e4m3fn[64,6144]{1,0} parameter(0)\n   p1 = f8e4m3fn[64,6144]{1,0} parameter(1)\n-  ROOT %dot.0 = f32[64,64]{1,0} fusion(p0, p1), kind=kCustom, calls=gemm_fusion, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n+  ROOT %dot.0 = f32[64,64]{1,0} fusion(p0, p1), kind=kCustom, calls=gemm_fusion, backend_config={\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n })\";\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n@@ -964,7 +964,7 @@ ENTRY e {\n         RunFileCheck(\n             module->ToString(HloPrintOptions{}.set_print_operand_shape(false)),\n             R\"(\n-// CHECK: backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"fusion_backend_config\":{\"kind\":\"__triton_gemm\",\"triton_gemm_config\":{\"block_m\":\"16\",\"block_n\":\"16\",\"block_k\":\"16\",\"split_k\":\"1\",\"num_stages\":\"1\",\"num_warps\":\"2\",\"num_ctas\":\"1\"\n+// CHECK: \"triton_gemm_config\":{\"block_m\":\"16\",\"block_n\":\"16\",\"block_k\":\"16\",\"split_k\":\"1\",\"num_stages\":\"1\",\"num_warps\":\"2\",\"num_ctas\":\"1\"\n             )\"));\n     EXPECT_TRUE(filecheck_matches);\n   } else {\n@@ -1103,7 +1103,7 @@ HloModule module\n ENTRY entry {\n   %p0 = f8e5m2[256,256]{1,0} parameter(0)\n   %p1 = f8e4m3fn[128,256]{1,0} parameter(1)\n-  ROOT r = f8e5m2[256,128]{1,0} fusion(f8e5m2[256,256]{1,0} %p0, f8e4m3fn[128,256]{1,0} %p1), kind=kCustom, calls=%gemm_fusion_dot_computation, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n+  ROOT r = f8e5m2[256,128]{1,0} fusion(f8e5m2[256,256]{1,0} %p0, f8e4m3fn[128,256]{1,0} %p1), kind=kCustom, calls=%gemm_fusion_dot_computation, backend_config={\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n })\")\n                                                   .value();\n   GemmFusionAutotunerImpl::BackendConfigs configs;\n@@ -1140,7 +1140,7 @@ TEST_F(GemmFusionAutotunerTest, CreatesCustomKernelFusionConfigs) {\n   ENTRY main {\n     %p0 = bf16[1024,1024]{1,0} parameter(0)\n     %p1 = bf16[1024,1024]{1,0} parameter(1)\n-    ROOT %gemm_fusion_r = f32[1024,1024]{1,0} fusion(%p0, %p1), kind=kCustom, calls=gemm_fusion_r_computation, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n+    ROOT %gemm_fusion_r = f32[1024,1024]{1,0} fusion(%p0, %p1), kind=kCustom, calls=gemm_fusion_r_computation, backend_config={\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n   })\";\n \n   std::unique_ptr<VerifiedHloModule> module =\n@@ -1182,7 +1182,7 @@ TEST_F(GemmFusionAutotunerTest, GeneratesTwoConfigsForUpcastGemmWithPrologue) {\n     %p1 = bf16[1,4,16,4096] parameter(1)\n     ROOT %gemm_fusion_r = f32[256,4096] fusion(%p0, %p1), kind=kCustom,\n     calls=gemm_fusion_r_computation,\n-    backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n+    backend_config={\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n   }\n )\";\n \n@@ -1228,7 +1228,7 @@ TEST_F(GemmFusionAutotunerTest, GeneratesOneConfigForUpcastGemmWithPrologue) {\n     %p1 = bf16[1,4,32,4096] parameter(1)\n     ROOT %gemm_fusion_r = f32[256,4096] fusion(%p0, %p1), kind=kCustom,\n     calls=gemm_fusion_r_computation,\n-    backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n+    backend_config={\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n   }\n )\";\n \n@@ -1277,7 +1277,7 @@ TEST_F(GemmFusionAutotunerTest,\n     %p1 = bf16[1,4,16,4096] parameter(1)\n     ROOT %gemm_fusion_r = bf16[1048576] fusion(%p0, %p1), kind=kCustom,\n     calls=gemm_fusion_r_computation,\n-    backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n+    backend_config={\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n   }\n )\";\n \n@@ -1565,7 +1565,7 @@ TEST_F(GemmFusionAutotunerTest, RewritesGemmFusionToCustomKernelFusion) {\n   ENTRY main {\n     %p0 = bf16[1024,1024]{1,0} parameter(0)\n     %p1 = bf16[1024,1024]{1,0} parameter(1)\n-    ROOT %gemm_fusion_r = f32[1024,1024]{1,0} fusion(%p0, %p1), kind=kCustom, calls=gemm_fusion_r_computation, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n+    ROOT %gemm_fusion_r = f32[1024,1024]{1,0} fusion(%p0, %p1), kind=kCustom, calls=gemm_fusion_r_computation, backend_config={\"fusion_backend_config\":{\"kind\":\"__triton_gemm\"},\"force_earliest_schedule\":false}\n   }\n )\";\n "
        },
        {
            "sha": "3ce6f9e9ed0b57e30cbcd065334d6511a401e46b",
            "filename": "third_party/xla/xla/service/gpu/execution_stream_assignment_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fexecution_stream_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fexecution_stream_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fexecution_stream_assignment_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -243,14 +243,14 @@ TEST_F(ExecutionStreamAssignmentTest, ExplicitStreams) {\n   %gemm1 (x: f32[2048,2048], y: f32[2048,2048]) -> f32[2048,2048] {\n     %y = f32[2048,2048]{1,0} parameter(1)\n     %x = f32[2048,2048]{1,0} parameter(0)\n-    %custom-call.1 = (f32[2048,2048]{1,0}, s8[33554432]{0}) custom-call(f32[2048,2048]{1,0} %x, f32[2048,2048]{1,0} %y), custom_call_target=\"__cublas$gemm\", backend_config={\"gemm_backend_config\":{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"],\"algorithm\":\"ALG_UNSET\"},\"epilogue\":\"DEFAULT\",\"damax_output\":false,\"lhs_stride\":\"4194304\",\"rhs_stride\":\"4194304\",\"grad_x\":false,\"grad_y\":false},\"force_earliest_schedule\":false}\n+    %custom-call.1 = (f32[2048,2048]{1,0}, s8[33554432]{0}) custom-call(f32[2048,2048]{1,0} %x, f32[2048,2048]{1,0} %y), custom_call_target=\"__cublas$gemm\", backend_config={\"gemm_backend_config\":{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"],\"algorithm\":\"ALG_UNSET\"},\"epilogue\":\"DEFAULT\",\"damax_output\":false,\"lhs_stride\":\"4194304\",\"rhs_stride\":\"4194304\",\"grad_x\":false,\"grad_y\":false}}\n     ROOT %get-tuple-element = f32[2048,2048]{1,0} get-tuple-element((f32[2048,2048]{1,0}, s8[33554432]{0}) %custom-call.1), index=0\n   }\n \n   %gemm2 (x: f32[2048,2048], y: f32[2048,2048]) -> f32[2048,2048] {\n     %y = f32[2048,2048]{1,0} parameter(1)\n     %x = f32[2048,2048]{1,0} parameter(0)\n-    %custom-call.2 = (f32[2048,2048]{1,0}, s8[33554432]{0}) custom-call(f32[2048,2048]{1,0} %x, f32[2048,2048]{1,0} %y), custom_call_target=\"__cublas$gemm\", backend_config={\"gemm_backend_config\":{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"],\"algorithm\":\"ALG_UNSET\"},\"epilogue\":\"DEFAULT\",\"damax_output\":false,\"lhs_stride\":\"4194304\",\"rhs_stride\":\"4194304\",\"grad_x\":false,\"grad_y\":false},\"force_earliest_schedule\":false}\n+    %custom-call.2 = (f32[2048,2048]{1,0}, s8[33554432]{0}) custom-call(f32[2048,2048]{1,0} %x, f32[2048,2048]{1,0} %y), custom_call_target=\"__cublas$gemm\", backend_config={\"gemm_backend_config\":{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"],\"algorithm\":\"ALG_UNSET\"},\"epilogue\":\"DEFAULT\",\"damax_output\":false,\"lhs_stride\":\"4194304\",\"rhs_stride\":\"4194304\",\"grad_x\":false,\"grad_y\":false}}\n     ROOT %get-tuple-element = f32[2048,2048]{1,0} get-tuple-element((f32[2048,2048]{1,0}, s8[33554432]{0}) %custom-call.2), index=0\n   }\n "
        },
        {
            "sha": "e91260e0fc802cf0be99d0bdcbd98655c6a9eba7",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -1389,7 +1389,7 @@ async_call {\n   p0 = f32[32,32] parameter(0)\n   p1 = f32[32,32] parameter(1)\n   gemm = (f32[32,32], s8[8192]) custom-call(p0, p1), custom_call_target=\"__cublas$gemm\",\n-    backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\n+    backend_config={\n       \"gemm_backend_config\":{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\n       \"dot_dimension_numbers\":\n         {\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"]},\n@@ -1405,8 +1405,7 @@ ENTRY main {\n     to_apply=async_call,\n     frontend_attributes={_xla_stream_annotation=\"1\"}\n   ROOT call-done = f32[32,32]{1,0} call-done(call-start),\n-    frontend_attributes={_xla_stream_annotation=\"1\"},\n-    backend_config={\"operation_queue_id\":\"0\"}\n+    frontend_attributes={_xla_stream_annotation=\"1\"}\n })\";\n   auto module = ParseAndReturnVerifiedModule(hlo_text).value();\n \n@@ -1445,7 +1444,7 @@ async_call {\n   p0 = f32[32,32] parameter(0)\n   p1 = f32[32,32] parameter(1)\n   gemm = (f32[32,32], s8[8192]) custom-call(p0, p1), custom_call_target=\"__cublas$gemm\",\n-    backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\n+    backend_config={\n       \"gemm_backend_config\":{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\n       \"dot_dimension_numbers\":\n         {\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"]},\n@@ -1461,8 +1460,7 @@ ENTRY main {\n     to_apply=async_call,\n     frontend_attributes={_xla_stream_annotation=\"1\"}\n   ROOT call-done = f32[32,32]{1,0} call-done(call-start),\n-    frontend_attributes={_xla_stream_annotation=\"1\"},\n-    backend_config={\"operation_queue_id\":\"0\"}\n+    frontend_attributes={_xla_stream_annotation=\"1\"}\n })\";\n \n   const absl::string_view fdo_profile = R\"pb("
        },
        {
            "sha": "92d8b6dda72e6518662c0ca785257b76a17255b1",
            "filename": "third_party/xla/xla/service/gpu/model/matmul_interpolator_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_interpolator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_interpolator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_interpolator_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -712,8 +712,6 @@ TEST_F(MatmulInterpolatorTest, SupportsCublasCustomCalls) {\n       ROOT _ =  (bf16[1024,1024], s8[2097152]{0}) custom-call(p0,p1),\n         custom_call_target=\"__cublas$gemm\",\n         backend_config={\n-          \"operation_queue_id\":\"0\",\n-          \"wait_on_operation_queues\":[],\n           \"gemm_backend_config\":{\n             \"alpha_real\":1,\n             \"beta\":1,\n@@ -750,8 +748,6 @@ TEST_F(MatmulInterpolatorTest, SupportsDotTritonFusion) {\n         kind=kCustom,\n         calls=comp,\n         backend_config={\n-          \"operation_queue_id\":\"0\",\n-          \"wait_on_operation_queues\":[],\n           \"fusion_backend_config\": {\n             \"kind\":\"__triton_gemm\",\n             \"triton_gemm_config\":{"
        },
        {
            "sha": "4f3400a46cbaf92b300043abe6dd4c980bce7d1c",
            "filename": "third_party/xla/xla/service/gpu/model/matmul_ptable_stats_collection_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -127,8 +127,6 @@ TEST_F(MatmulStatsCollectionTest,\n       ROOT dot =  (bf16[1024,1024], s8[2097152]{0}) custom-call(p0,p1),\n         custom_call_target=\"__cublas$gemm\",\n         backend_config={\n-          \"operation_queue_id\":\"0\",\n-          \"wait_on_operation_queues\":[],\n           \"gemm_backend_config\":{\n             \"alpha_real\":1,\n             \"beta\":1,\n@@ -180,8 +178,6 @@ TEST_F(MatmulStatsCollectionTest,\n         kind=kCustom,\n         calls=comp,\n         backend_config={\n-          \"operation_queue_id\":\"0\",\n-          \"wait_on_operation_queues\":[],\n           \"fusion_backend_config\": {\n             \"kind\":\"__triton_gemm\",\n             \"triton_gemm_config\":{"
        },
        {
            "sha": "703d068dae6ee436ef25b246ff5182aba5a772e2",
            "filename": "third_party/xla/xla/service/gpu/model/sol_latency_estimator_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_latency_estimator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_latency_estimator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_latency_estimator_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -322,8 +322,6 @@ ENTRY e {\n     kind=kCustom,\n     calls=comp,\n     backend_config={\n-      \"operation_queue_id\":\"0\",\n-      \"wait_on_operation_queues\":[],\n       \"fusion_backend_config\": {\n         \"kind\":\"__triton_gemm\",\n         \"triton_gemm_config\":{\n@@ -354,8 +352,6 @@ ENTRY e {\n   ROOT _ =  (bf16[1024,1024], s8[2097152]{0}) custom-call(p0,p1),\n     custom_call_target=\"__cublas$gemm\",\n     backend_config={\n-      \"operation_queue_id\":\"0\",\n-      \"wait_on_operation_queues\":[],\n       \"gemm_backend_config\":{\n         \"alpha_real\":1,\n         \"beta\":1,\n@@ -384,8 +380,6 @@ ENTRY e {\n   ROOT _ =  (bf16[1024,1024], s8[2097152]{0}) custom-call(p0,p1),\n     custom_call_target=\"__cublas$lt$matmul$f8\",\n     backend_config={\n-      \"operation_queue_id\":\"0\",\n-      \"wait_on_operation_queues\":[],\n       \"gemm_backend_config\":{\n         \"alpha_real\":1,\n         \"beta\":1,\n@@ -414,8 +408,6 @@ ENTRY e {\n   ROOT _ =  (bf16[1024,1024], s8[2097152]{0}) custom-call(p0,p1),\n     custom_call_target=\"__cublas$lt$matmul$f8\",\n     backend_config={\n-      \"operation_queue_id\":\"0\",\n-      \"wait_on_operation_queues\":[],\n       \"gemm_backend_config\":{\n         \"alpha_real\":1,\n         \"beta\":1,\n@@ -444,8 +436,6 @@ ENTRY e {\n   ROOT _ =  (bf16[1024,1024], s8[2097152]{0}) custom-call(p0,p1),\n     custom_call_target=\"__cublas$lt$matmul$f8\",\n     backend_config={\n-      \"operation_queue_id\":\"0\",\n-      \"wait_on_operation_queues\":[],\n       \"gemm_backend_config\":{\n         \"alpha_real\":1,\n         \"beta\":1,\n@@ -474,8 +464,6 @@ ENTRY e {\n   ROOT _ =  (bf16[1024,1024], s8[2097152]{0}) custom-call(p0,p1),\n     custom_call_target=\"__cublas$lt$matmul$f8\",\n     backend_config={\n-      \"operation_queue_id\":\"0\",\n-      \"wait_on_operation_queues\":[],\n       \"gemm_backend_config\":{\n         \"alpha_real\":1,\n         \"beta\":1,"
        },
        {
            "sha": "153e4b8676c97008b0aeb9607f11286629f1d9ea",
            "filename": "third_party/xla/xla/service/gpu/nvptx_alias_info_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_alias_info_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_alias_info_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_alias_info_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -71,7 +71,7 @@ ENTRY main {\n   lhs = f32[20,20]{1,0} parameter(0)\n   rhs = f32[20,30]{1,0} parameter(1)\n   bias = f32[20,30]{1,0} parameter(2)\n-  ROOT cublas-lt-matmul = (f32[20,30]{1,0}, s8[33554432]{0}) custom-call(lhs, rhs, bias), custom_call_target=\"__cublas$lt$matmul\", frontend_attributes={grad_x=\"false\",grad_y=\"false\"}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"gemm_backend_config\":{\"selected_algorithm\":\"0\",\"alpha_real\":1,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"HIGHEST\",\"HIGHEST\"],\"algorithm\":\"ALG_UNSET\"},\"epilogue\":\"DEFAULT\",\"lhs_stride\":\"400\",\"rhs_stride\":\"600\",\"grad_x\":false,\"grad_y\":false,\"damax_output\":false},\"force_earliest_schedule\":false,\"reification_cost\":[],\"device_type\":\"DEVICE_TYPE_INVALID\"}\n+  ROOT cublas-lt-matmul = (f32[20,30]{1,0}, s8[33554432]{0}) custom-call(lhs, rhs, bias), custom_call_target=\"__cublas$lt$matmul\", frontend_attributes={grad_x=\"false\",grad_y=\"false\"}, backend_config={\"gemm_backend_config\":{\"selected_algorithm\":\"0\",\"alpha_real\":1,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"HIGHEST\",\"HIGHEST\"],\"algorithm\":\"ALG_UNSET\"},\"epilogue\":\"DEFAULT\",\"lhs_stride\":\"400\",\"rhs_stride\":\"600\",\"grad_x\":false,\"grad_y\":false,\"damax_output\":false},\"force_earliest_schedule\":false,\"reification_cost\":[],\"device_type\":\"DEVICE_TYPE_INVALID\"}\n }\n )\";\n \n@@ -90,7 +90,7 @@ HloModule m\n ENTRY main {\n   lhs = f32[20,20]{1,0} parameter(0)\n   rhs = f32[20,30]{1,0} parameter(1)\n-  ROOT cublas-lt-matmul = (f32[20,30]{1,0}, s8[33554432]{0}) custom-call(lhs, rhs, rhs), custom_call_target=\"__cublas$lt$matmul\", frontend_attributes={grad_x=\"false\",grad_y=\"false\"}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"gemm_backend_config\":{\"selected_algorithm\":\"0\",\"alpha_real\":1,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"HIGHEST\",\"HIGHEST\"],\"algorithm\":\"ALG_UNSET\"},\"epilogue\":\"DEFAULT\",\"lhs_stride\":\"400\",\"rhs_stride\":\"600\",\"grad_x\":false,\"grad_y\":false,\"damax_output\":false},\"force_earliest_schedule\":false,\"reification_cost\":[],\"device_type\":\"DEVICE_TYPE_INVALID\"}\n+  ROOT cublas-lt-matmul = (f32[20,30]{1,0}, s8[33554432]{0}) custom-call(lhs, rhs, rhs), custom_call_target=\"__cublas$lt$matmul\", frontend_attributes={grad_x=\"false\",grad_y=\"false\"}, backend_config={\"gemm_backend_config\":{\"selected_algorithm\":\"0\",\"alpha_real\":1,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"HIGHEST\",\"HIGHEST\"],\"algorithm\":\"ALG_UNSET\"},\"epilogue\":\"DEFAULT\",\"lhs_stride\":\"400\",\"rhs_stride\":\"600\",\"grad_x\":false,\"grad_y\":false,\"damax_output\":false},\"force_earliest_schedule\":false,\"reification_cost\":[],\"device_type\":\"DEVICE_TYPE_INVALID\"}\n }\n )\";\n "
        },
        {
            "sha": "36175d37a8cd074d1deade71b7528cc494d6985a",
            "filename": "third_party/xla/xla/service/gpu/tests/dynamic_slice_fusion_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fdynamic_slice_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fdynamic_slice_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fdynamic_slice_fusion_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -125,8 +125,7 @@ TEST_F(DynamicSliceFusionTest, GemmSlice) {\n       p2 = f16[4,8,8]{2,1,0} parameter(2)\n       address_computation = (f16[4,8,8]{2,1,0}, s8[256]{0}) fusion(p0, c1_s32, c0_s32, p1, p2),\n         kind=kCustom, calls=dynamic-slice-fusion,\n-        backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\n-                        \"fusion_backend_config\":{\n+        backend_config={\"fusion_backend_config\":{\n                           \"kind\":\"__custom_fusion\",\n                           \"custom_fusion_config\":{\n                             \"name\":\"dynamic_address_computation\"\n@@ -208,8 +207,7 @@ TEST_F(DynamicSliceFusionTest, CustomCallSlice) {\n       c0_s32 = s32[] constant(0)\n       ROOT address_computation = f16[4,8,8]{2,1,0} fusion(p0, c1_s32, c0_s32, p1),\n         kind=kCustom, calls=dynamic-slice-fusion,\n-        backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\n-                        \"fusion_backend_config\":{\n+        backend_config={\"fusion_backend_config\":{\n                           \"kind\":\"__custom_fusion\",\n                           \"custom_fusion_config\":{\n                             \"name\":\"dynamic_address_computation\""
        },
        {
            "sha": "3e984387001e6fe6ce6c9ed09e828e0f920562c6",
            "filename": "third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc",
            "status": "modified",
            "additions": 30,
            "deletions": 40,
            "changes": 70,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fgpu_fused_mha_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fgpu_fused_mha_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fgpu_fused_mha_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b"
        },
        {
            "sha": "40a6c717deab8124c0bffc6fb1d238800c520284",
            "filename": "third_party/xla/xla/service/gpu/transforms/stream_attribute_annotator_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_annotator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_annotator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_annotator_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -67,7 +67,7 @@ TEST_F(StreamAttributeAnnotatorTest, AllUsersAreAnnotated) {\n   ENTRY entry {\n     p1_32 = f32[1] parameter(0)\n     p2_32 = f32[1] parameter(1)\n-    add_32 = f32[1] add(p1_32, p2_32), backend_config={\"operation_queue_id\":\"1\", \"wait_on_operation_queues\":[]}\n+    add_32 = f32[1] add(p1_32, p2_32), backend_config={\"operation_queue_id\":\"1\"}\n     exp_32 = f32[1] exponential(add_32)\n \n     neg32 = f32[1] negate(add_32)\n@@ -100,8 +100,8 @@ TEST_F(StreamAttributeAnnotatorTest, MultipleStreamsAreCombined) {\n   ENTRY entry {\n     p1_32 = f32[1] parameter(0)\n     p2_32 = f32[1] parameter(1)\n-    add_32 = f32[1] add(p1_32, p2_32), backend_config={\"operation_queue_id\":\"1\", \"wait_on_operation_queues\":[]}\n-    exp_32 = f32[1] exponential(p2_32), backend_config={\"operation_queue_id\":\"2\", \"wait_on_operation_queues\":[]}\n+    add_32 = f32[1] add(p1_32, p2_32), backend_config={\"operation_queue_id\":\"1\"}\n+    exp_32 = f32[1] exponential(p2_32), backend_config={\"operation_queue_id\":\"2\"}\n \n     ROOT add_out_32 = f32[1] add(add_32, exp_32)\n   }\n@@ -135,7 +135,7 @@ TEST_F(StreamAttributeAnnotatorTest, GTEUserIsAnnotated) {\n     p1_32 = f32[16,32] parameter(0)\n     p2_32 = f32[32,16] parameter(1)\n \n-    custom-call.3 = (f32[16,16], s8[1028]{0}) custom-call(p1_32, p2_32), custom_call_target=\"__cublas$gemm\", backend_config={\"operation_queue_id\":\"1\",\"wait_on_operation_queues\":[],\"gemm_backend_config\":{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\",\"grad_x\":false,\"grad_y\":false}}\n+    custom-call.3 = (f32[16,16], s8[1028]{0}) custom-call(p1_32, p2_32), custom_call_target=\"__cublas$gemm\", backend_config={\"operation_queue_id\":\"1\",\"gemm_backend_config\":{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\",\"grad_x\":false,\"grad_y\":false}}\n     get-tuple-element.24 = f32[16,16] get-tuple-element(custom-call.3), index=0\n \n     exp_32 = f32[16,16] exponential(get-tuple-element.24)\n@@ -167,7 +167,7 @@ TEST_F(StreamAttributeAnnotatorTest, GTENoUserIsHandled) {\n     p1_32 = f32[16,32] parameter(0)\n     p2_32 = f32[32,16] parameter(1)\n \n-    custom-call.3 = (f32[16,16], s8[1028]{0}) custom-call(p1_32, p2_32), custom_call_target=\"__cublas$gemm\", backend_config={\"operation_queue_id\":\"1\",\"wait_on_operation_queues\":[],\"gemm_backend_config\":{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\",\"grad_x\":false,\"grad_y\":false}}\n+    custom-call.3 = (f32[16,16], s8[1028]{0}) custom-call(p1_32, p2_32), custom_call_target=\"__cublas$gemm\", backend_config={\"operation_queue_id\":\"1\",\"gemm_backend_config\":{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\",\"grad_x\":false,\"grad_y\":false}}\n     ROOT get-tuple-element.24 = f32[16,16] get-tuple-element(custom-call.3), index=0\n   }\n   )\";\n@@ -188,7 +188,7 @@ TEST_F(StreamAttributeAnnotatorTest, FusionIsAnnotated) {\n   fused_computation.1 {\n     fusion_p0_32 = f32[16,16] parameter(0)\n     fusion_p2_32 = f32[16,16] parameter(1)\n-    ROOT add = f32[16,16] add(fusion_p0_32, fusion_p2_32), backend_config={\"operation_queue_id\":\"1\",\"wait_on_operation_queues\":[]}\n+    ROOT add = f32[16,16] add(fusion_p0_32, fusion_p2_32), backend_config={\"operation_queue_id\":\"1\"}\n   }\n \n   ENTRY entry {"
        },
        {
            "sha": "d924dcef523fa43a4e8c0ecb8fa91c3cde7c064f",
            "filename": "third_party/xla/xla/service/gpu/transforms/stream_attribute_async_wrapper_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_async_wrapper_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd9db275b3c65e5758dae8a8be968c623c39b62b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_async_wrapper_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_async_wrapper_test.cc?ref=bd9db275b3c65e5758dae8a8be968c623c39b62b",
            "patch": "@@ -40,8 +40,8 @@ TEST_F(StreamAttributeAsyncWrapperTest, NonDefaultOpIsWrapped) {\n   ENTRY entry {\n     p1_32 = f32[1] parameter(0)\n     p2_32 = f32[1] parameter(1)\n-    add_32 = f32[1] add(p1_32, p2_32), backend_config={\"operation_queue_id\":\"1\", \"wait_on_operation_queues\":[], \"force_earliest_schedule\":true}\n-    ROOT exp_32 = f32[1] exponential(add_32), backend_config={\"operation_queue_id\":\"0\", \"wait_on_operation_queues\":[1]}\n+    add_32 = f32[1] add(p1_32, p2_32), backend_config={\"operation_queue_id\":\"1\", \"force_earliest_schedule\":true}\n+    ROOT exp_32 = f32[1] exponential(add_32)\n   }\n   )\";\n "
        }
    ],
    "stats": {
        "total": 154,
        "additions": 59,
        "deletions": 95
    }
}