{
    "author": "unknown",
    "message": "[XLA:GPU] Change SDC names to more descriptive ones\n\nAnd dump the log proto into file called buffer_debug_log rather than sdc_log\n\nChanges to implementation details:\n- Renames:\n  - SdcLogProto -> BufferDebugLogProto\n  - SdcLog -> BufferDebugLog\n  - SdcBufferId -> ThunkBufferId\n  - SdcThunk -> BuffersChecksumThunk\n  - SdcXorChecksumKernel -> BufferDebugXorChecksumKernel\n- move BufferDebugLog to stream_executor/gpu from stream_executor/cuda as it's not CUDA-specific\n\nPiperOrigin-RevId: 820186034",
    "sha": "373e68f60c1616f255af1a638dfc7ad6c4d990b4",
    "files": [
        {
            "sha": "cbf36a5f55833a79e4c706aaa43b93f4a7a1b10f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 27,
            "deletions": 27,
            "changes": 54,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -2895,11 +2895,11 @@ cc_library(\n     srcs = [\"thunk_checksum_tracing_pass.cc\"],\n     hdrs = [\"thunk_checksum_tracing_pass.h\"],\n     deps = [\n+        \":buffers_checksum_thunk\",\n         \":custom_call_thunk\",\n-        \":sdc_buffer_id\",\n-        \":sdc_thunk\",\n         \":sequential_thunk\",\n         \":thunk\",\n+        \":thunk_buffer_id\",\n         \":thunk_pass_pipeline\",\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n@@ -2911,7 +2911,7 @@ cc_library(\n         \"//xla/service:dump\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:stream\",\n-        \"//xla/stream_executor/cuda:sdc_log\",\n+        \"//xla/stream_executor/gpu:buffer_debug_log\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/base:nullability\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n@@ -2927,11 +2927,11 @@ xla_cc_test(\n     name = \"thunk_checksum_tracing_pass_test\",\n     srcs = [\"thunk_checksum_tracing_pass_test.cc\"],\n     deps = [\n+        \":buffers_checksum_thunk\",\n         \":custom_call_thunk\",\n-        \":sdc_buffer_id\",\n-        \":sdc_thunk\",\n         \":sequential_thunk\",\n         \":thunk\",\n+        \":thunk_buffer_id\",\n         \":thunk_checksum_tracing_pass\",\n         \":thunk_id\",\n         \":thunk_pass_pipeline\",\n@@ -2994,21 +2994,21 @@ xla_test(\n )\n \n cc_library(\n-    name = \"sdc_thunk\",\n-    srcs = [\"sdc_thunk.cc\"],\n-    hdrs = [\"sdc_thunk.h\"],\n+    name = \"buffers_checksum_thunk\",\n+    srcs = [\"buffers_checksum_thunk.cc\"],\n+    hdrs = [\"buffers_checksum_thunk.h\"],\n     deps = [\n-        \":sdc_buffer_id\",\n         \":thunk\",\n+        \":thunk_buffer_id\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:launch_dim\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/stream_executor/cuda:cuda_platform_id\",\n-        \"//xla/stream_executor/cuda:sdc_log\",\n+        \"//xla/stream_executor/gpu:buffer_debug_log\",\n+        \"//xla/stream_executor/gpu:buffer_debug_xor_checksum_kernel\",\n         \"//xla/stream_executor/gpu:gpu_kernel_registry\",\n-        \"//xla/stream_executor/gpu:sdc_xor_checksum_kernel\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n@@ -3020,18 +3020,18 @@ cc_library(\n )\n \n xla_test(\n-    name = \"sdc_thunk_test\",\n-    srcs = [\"sdc_thunk_test.cc\"],\n+    name = \"buffers_checksum_thunk_test\",\n+    srcs = [\"buffers_checksum_thunk_test.cc\"],\n     backends = [\"gpu\"],\n     tags = [\n         \"cuda-only\",\n         \"gpu\",\n     ],\n     deps = [\n-        \":sdc_buffer_id\",\n-        \":sdc_log_structs\",\n-        \":sdc_thunk\",\n+        \":buffer_debug_log_structs\",\n+        \":buffers_checksum_thunk\",\n         \":thunk\",\n+        \":thunk_buffer_id\",\n         \":thunk_id\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:executable\",\n@@ -3042,21 +3042,21 @@ xla_test(\n         \"//xla/stream_executor:platform_manager\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_memory_allocator\",\n-        \"//xla/stream_executor/cuda:sdc_log\",\n+        \"//xla/stream_executor/gpu:buffer_debug_log\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )\n \n tf_proto_library(\n-    name = \"sdc_proto\",\n-    srcs = [\"sdc.proto\"],\n+    name = \"buffer_debug_log_proto\",\n+    srcs = [\"buffer_debug_log.proto\"],\n )\n \n cc_library(\n-    name = \"sdc_buffer_id\",\n-    hdrs = [\"sdc_buffer_id.h\"],\n+    name = \"thunk_buffer_id\",\n+    hdrs = [\"thunk_buffer_id.h\"],\n     compatible_with = get_compatible_with_portable(),\n     deps = [\n         \":thunk_id\",\n@@ -3067,10 +3067,10 @@ cc_library(\n )\n \n xla_cc_test(\n-    name = \"sdc_buffer_id_test\",\n-    srcs = [\"sdc_buffer_id_test.cc\"],\n+    name = \"thunk_buffer_id_test\",\n+    srcs = [\"thunk_buffer_id_test.cc\"],\n     deps = [\n-        \":sdc_buffer_id\",\n+        \":thunk_buffer_id\",\n         \":thunk_id\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/status\",\n@@ -3080,10 +3080,10 @@ xla_cc_test(\n )\n \n cc_library(\n-    name = \"sdc_log_structs\",\n-    hdrs = [\"sdc_log_structs.h\"],\n+    name = \"buffer_debug_log_structs\",\n+    hdrs = [\"buffer_debug_log_structs.h\"],\n     compatible_with = get_compatible_with_portable(),\n     deps = [\n-        \":sdc_buffer_id\",\n+        \":thunk_buffer_id\",\n     ],\n )"
        },
        {
            "sha": "a4cb355671d7b3dcd2510d0e1c858f787bba4289",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffer_debug_log.proto",
            "status": "renamed",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log.proto?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -17,7 +17,7 @@ syntax = \"proto3\";\n \n package xla.gpu;\n \n-message SdcLogEntryProto {\n+message BufferDebugLogEntryProto {\n   // The ID of the thunk that produced this entry, as returned by\n   // ThunkInfo::thunk_id().\n   uint64 thunk_id = 1;\n@@ -30,7 +30,8 @@ message SdcLogEntryProto {\n   uint32 checksum = 3;\n }\n \n-message SdcLogProto {\n-  // The list of entries in the SDC log.\n-  repeated SdcLogEntryProto entries = 1;\n+// A dump of a `BufferDebugLog` contents.\n+message BufferDebugLogProto {\n+  // The list of entries in the log.\n+  repeated BufferDebugLogEntryProto entries = 1;\n }",
            "previous_filename": "third_party/xla/xla/backends/gpu/runtime/sdc.proto"
        },
        {
            "sha": "a8940f2ba907464d3f893e772d68be376bb38bac",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffer_debug_log_structs.h",
            "status": "renamed",
            "additions": 22,
            "deletions": 20,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -13,57 +13,59 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#ifndef XLA_BACKENDS_GPU_RUNTIME_SDC_LOG_STRUCTS_H_\n-#define XLA_BACKENDS_GPU_RUNTIME_SDC_LOG_STRUCTS_H_\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_BUFFER_DEBUG_LOG_STRUCTS_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_BUFFER_DEBUG_LOG_STRUCTS_H_\n \n #include <cstddef>\n #include <cstdint>\n #include <tuple>\n \n-#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n \n namespace xla::gpu {\n \n-struct SdcLogEntry {\n+struct BufferDebugLogEntry {\n   // An ID that uniquely identifies a thunk and its specific input or output\n   // buffer.\n-  SdcBufferId entry_id;\n+  ThunkBufferId entry_id;\n   uint32_t checksum;\n \n   template <typename Sink>\n-  friend void AbslStringify(Sink& sink, const SdcLogEntry& entry) {\n+  friend void AbslStringify(Sink& sink, const BufferDebugLogEntry& entry) {\n     absl::Format(&sink, \"{entry_id: %v, checksum: %u}\", entry.entry_id,\n                  entry.checksum);\n   }\n \n-  bool operator==(const SdcLogEntry& other) const {\n+  bool operator==(const BufferDebugLogEntry& other) const {\n     return std::tie(entry_id, checksum) ==\n            std::tie(other.entry_id, other.checksum);\n   }\n \n-  bool operator!=(const SdcLogEntry& other) const { return !(*this == other); }\n+  bool operator!=(const BufferDebugLogEntry& other) const {\n+    return !(*this == other);\n+  }\n };\n \n // The struct layout must match on both host and device.\n-static_assert(_Alignof(SdcLogEntry) == _Alignof(uint32_t));\n-static_assert(sizeof(SdcLogEntry) == sizeof(uint32_t) * 2);\n-static_assert(offsetof(SdcLogEntry, entry_id) == 0);\n-static_assert(offsetof(SdcLogEntry, checksum) == sizeof(uint32_t));\n+static_assert(_Alignof(BufferDebugLogEntry) == _Alignof(uint32_t));\n+static_assert(sizeof(BufferDebugLogEntry) == sizeof(uint32_t) * 2);\n+static_assert(offsetof(BufferDebugLogEntry, entry_id) == 0);\n+static_assert(offsetof(BufferDebugLogEntry, checksum) == sizeof(uint32_t));\n \n-struct SdcLogHeader {\n-  // The first entry in `SdcLogEntry` following the header that has not\n+struct BufferDebugLogHeader {\n+  // The first entry in `BufferDebugLogEntry` following the header that has not\n   // been written to. May be bigger than `capacity` if the log was truncated.\n   uint32_t write_idx;\n-  // The number of `SdcLogEntry` structs the log can hold.\n+  // The number of `BufferDebugLogEntry` structs the log can hold.\n   uint32_t capacity;\n };\n \n // The struct layout must match on both host and device.\n-static_assert(_Alignof(SdcLogHeader) == _Alignof(uint32_t));\n-static_assert(sizeof(SdcLogHeader) == sizeof(uint32_t) * 2);\n-static_assert(offsetof(SdcLogHeader, write_idx) == 0);\n-static_assert(offsetof(SdcLogHeader, capacity) == sizeof(uint32_t));\n+static_assert(_Alignof(BufferDebugLogHeader) == _Alignof(uint32_t));\n+static_assert(sizeof(BufferDebugLogHeader) == sizeof(uint32_t) * 2);\n+static_assert(offsetof(BufferDebugLogHeader, write_idx) == 0);\n+static_assert(offsetof(BufferDebugLogHeader, capacity) == sizeof(uint32_t));\n \n }  // namespace xla::gpu\n \n-#endif  // XLA_BACKENDS_GPU_RUNTIME_SDC_LOG_STRUCTS_H_\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_BUFFER_DEBUG_LOG_STRUCTS_H_",
            "previous_filename": "third_party/xla/xla/backends/gpu/runtime/sdc_log_structs.h"
        },
        {
            "sha": "4823094b5f2e86a735b210745d516e9244880346",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_checksum_thunk.cc",
            "status": "renamed",
            "additions": 24,
            "deletions": 21,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.cc?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -13,7 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include \"xla/backends/gpu/runtime/sdc_thunk.h\"\n+#include \"xla/backends/gpu/runtime/buffers_checksum_thunk.h\"\n \n #include <cstdint>\n #include <string>\n@@ -24,10 +24,10 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n-#include \"xla/stream_executor/cuda/sdc_log.h\"\n #include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_log.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_xor_checksum_kernel.h\"\n #include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n-#include \"xla/stream_executor/gpu/sdc_xor_checksum_kernel.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -37,63 +37,66 @@ namespace xla::gpu {\n \n namespace se = stream_executor;\n \n-absl::Status SdcThunk::Initialize(const InitializeParams& params) {\n+absl::Status BuffersDebugChecksumThunk::Initialize(\n+    const InitializeParams& params) {\n   if (params.executor->GetPlatform()->id() != se::cuda::kCudaPlatformId) {\n-    VLOG(1) << \"[SDC LOG] Not supported on non-CUDA platforms, skipping\";\n+    VLOG(1)\n+        << \"Buffer checksumming not supported on non-CUDA platforms, skipping\";\n     return absl::OkStatus();\n   }\n   if (!params.executor->GetDeviceDescription()\n            .cuda_compute_capability()\n            .IsAtLeastPascal()) {\n-    VLOG(1) << \"[SDC LOG] Not supported on CUDA architectures older than \"\n-               \"Pascal due to missing atomic fetch_add with system scope, \"\n-               \"skipping\";\n+    VLOG(1)\n+        << \"Buffer checksumming not supported on CUDA architectures older than \"\n+           \"Pascal due to missing atomic fetch_add with system scope, skipping\";\n     return absl::OkStatus();\n   }\n \n   se::gpu::GpuKernelRegistry registry =\n       se::gpu::GpuKernelRegistry::GetGlobalRegistry();\n   TF_ASSIGN_OR_RETURN(\n-      kernel_,\n-      registry.LoadKernel<se::gpu::SdcXorChecksumKernel>(params.executor));\n+      kernel_, registry.LoadKernel<se::gpu::BufferDebugXorChecksumKernel>(\n+                   params.executor));\n \n-  VLOG(1) << \"[SDC LOG] SDC kernel loaded\";\n+  VLOG(1) << \"Checksum kernel loaded\";\n   return absl::OkStatus();\n }\n \n-absl::Status SdcThunk::ExecuteOnStream(const ExecuteParams& params) {\n+absl::Status BuffersDebugChecksumThunk::ExecuteOnStream(\n+    const ExecuteParams& params) {\n   se::StreamExecutor* executor = params.stream->parent();\n   if (!kernel_.has_value()) {\n     // Initialize didn't load the kernel. This can happen when we're running on\n     // an unsupported platform.\n-    VLOG(1) << \"[SDC LOG] SDC kernel not loaded, skipping\";\n+    VLOG(1) << \"Checksum kernel not loaded, skipping\";\n     return absl::OkStatus();\n   }\n \n-  VLOG(1) << \"[SDC LOG] SdcThunk::ExecuteOnStream\";\n+  VLOG(1) << \"BuffersDebugChecksumThunk::ExecuteOnStream\";\n \n   const se::ThreadDim thread_dim(\n       executor->GetDeviceDescription().threads_per_block_limit(), 1, 1);\n \n   se::DeviceMemory<uint8_t> log_ptr(\n       params.buffer_allocations->GetDeviceAddress(log_slice_));\n-  se::cuda::SdcLog sdc_log =\n-      se::cuda::SdcLog::FromDeviceMemoryUnchecked(log_ptr);\n+  se::cuda::BufferDebugLog buffer_debug_log =\n+      se::cuda::BufferDebugLog::FromDeviceMemoryUnchecked(log_ptr);\n \n   for (const auto& [entry_id, buffer] : buffers_) {\n     se::DeviceMemory<uint8_t> device_buffer(\n         params.buffer_allocations->GetDeviceAddress(buffer));\n \n-    TF_RETURN_IF_ERROR(\n-        kernel_->Launch(thread_dim, se::BlockDim(1, 1, 1), params.stream,\n-                        entry_id, device_buffer, device_buffer.size(),\n-                        sdc_log.GetDeviceHeader(), sdc_log.GetDeviceEntries()));\n+    TF_RETURN_IF_ERROR(kernel_->Launch(\n+        thread_dim, se::BlockDim(1, 1, 1), params.stream, entry_id,\n+        device_buffer, device_buffer.size(), buffer_debug_log.GetDeviceHeader(),\n+        buffer_debug_log.GetDeviceEntries()));\n   }\n \n   return absl::OkStatus();\n }\n \n-std::string SdcThunk::ToString(int indent) const {\n+std::string BuffersDebugChecksumThunk::ToString(int indent) const {\n   std::string result;\n   absl::StrAppend(&result, \", buffers = \", buffers_.size());\n   for (const auto& [buffer_id, buffer] : buffers_) {",
            "previous_filename": "third_party/xla/xla/backends/gpu/runtime/sdc_thunk.cc"
        },
        {
            "sha": "71f4ee186b4faad1d050eea5f4499e1adcf1ab5a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_checksum_thunk.h",
            "status": "renamed",
            "additions": 13,
            "deletions": 12,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk.h?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -13,8 +13,8 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#ifndef XLA_BACKENDS_GPU_RUNTIME_SDC_THUNK_H_\n-#define XLA_BACKENDS_GPU_RUNTIME_SDC_THUNK_H_\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_BUFFERS_CHECKSUM_THUNK_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_BUFFERS_CHECKSUM_THUNK_H_\n \n #include <optional>\n #include <string>\n@@ -23,19 +23,19 @@ limitations under the License.\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n-#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n #include \"xla/service/buffer_assignment.h\"\n-#include \"xla/stream_executor/gpu/sdc_xor_checksum_kernel.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_xor_checksum_kernel.h\"\n \n namespace xla::gpu {\n \n-class SdcThunk : public Thunk {\n+class BuffersDebugChecksumThunk : public Thunk {\n  public:\n-  explicit SdcThunk(\n+  explicit BuffersDebugChecksumThunk(\n       ThunkInfo info, BufferAllocation::Slice log_slice,\n-      absl::flat_hash_map<SdcBufferId, BufferAllocation::Slice> buffers)\n-      : Thunk(Thunk::Kind::kSdc, std::move(info)),\n+      absl::flat_hash_map<ThunkBufferId, BufferAllocation::Slice> buffers)\n+      : Thunk(Thunk::Kind::kBuffersDebugChecksum, std::move(info)),\n         log_slice_(log_slice),\n         buffers_(std::move(buffers)) {}\n \n@@ -49,18 +49,19 @@ class SdcThunk : public Thunk {\n     return {};\n   }\n \n-  const absl::flat_hash_map<SdcBufferId, BufferAllocation::Slice>&\n+  const absl::flat_hash_map<ThunkBufferId, BufferAllocation::Slice>&\n   buffer_slices() const {\n     return buffers_;\n   }\n \n  private:\n   // Loaded in Initialize.\n-  std::optional<stream_executor::gpu::SdcXorChecksumKernel::KernelType> kernel_;\n+  std::optional<stream_executor::gpu::BufferDebugXorChecksumKernel::KernelType>\n+      kernel_;\n   BufferAllocation::Slice log_slice_;\n-  absl::flat_hash_map<SdcBufferId, BufferAllocation::Slice> buffers_;\n+  absl::flat_hash_map<ThunkBufferId, BufferAllocation::Slice> buffers_;\n };\n \n }  // namespace xla::gpu\n \n-#endif  // XLA_BACKENDS_GPU_RUNTIME_SDC_THUNK_H_\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_BUFFERS_CHECKSUM_THUNK_H_",
            "previous_filename": "third_party/xla/xla/backends/gpu/runtime/sdc_thunk.h"
        },
        {
            "sha": "863b43c8aa9f0971eb41bc9cfc93f5fd67021e27",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_checksum_thunk_test.cc",
            "status": "renamed",
            "additions": 33,
            "deletions": 29,
            "changes": 62,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -13,7 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include \"xla/backends/gpu/runtime/sdc_thunk.h\"\n+#include \"xla/backends/gpu/runtime/buffers_checksum_thunk.h\"\n \n #include <cstddef>\n #include <cstdint>\n@@ -23,16 +23,16 @@ limitations under the License.\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n-#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n-#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/gpu/resource_requests.h\"\n #include \"xla/service/service_executable_run_options.h\"\n-#include \"xla/stream_executor/cuda/sdc_log.h\"\n #include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_log.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n #include \"xla/stream_executor/stream.h\"\n@@ -45,10 +45,10 @@ namespace {\n \n namespace se = stream_executor;\n \n-using ::stream_executor::cuda::SdcLog;\n+using ::stream_executor::cuda::BufferDebugLog;\n using ::testing::UnorderedElementsAre;\n \n-class SdcThunkTest : public ::testing::Test {\n+class BuffersDebugChecksumThunkTest : public ::testing::Test {\n  protected:\n   void SetUp() override {\n     TF_ASSERT_OK_AND_ASSIGN(platform_,\n@@ -61,8 +61,10 @@ class SdcThunkTest : public ::testing::Test {\n     if (!executor_->GetDeviceDescription()\n              .cuda_compute_capability()\n              .IsAtLeastPascal()) {\n-      GTEST_SKIP() << \"SDC checksumming is not supported on CUDA architectures \"\n-                      \"older than Pascal due to missing atomic fetch_add\";\n+      GTEST_SKIP()\n+          << \"buffer checksumming is not supported on CUDA architectures \"\n+             \"older than Pascal due to missing atomic fetch_add with \"\n+             \"system scope\";\n     }\n   }\n \n@@ -72,8 +74,8 @@ class SdcThunkTest : public ::testing::Test {\n   std::unique_ptr<se::StreamExecutorMemoryAllocator> allocator_;\n };\n \n-TEST_F(SdcThunkTest, CalculatesChecksums) {\n-  static constexpr size_t kLogSize = SdcLog::RequiredSizeForEntries(10);\n+TEST_F(BuffersDebugChecksumThunkTest, CalculatesChecksums) {\n+  static constexpr size_t kLogSize = BufferDebugLog::RequiredSizeForEntries(10);\n   static constexpr size_t kInputSize = 1024;\n   static constexpr size_t kInputCount = 2;\n   static constexpr size_t kTotalDeviceMemoryBytes =\n@@ -95,9 +97,9 @@ TEST_F(SdcThunkTest, CalculatesChecksums) {\n   se::DeviceMemoryBase inputs0_mem = allocations.GetDeviceAddress(inputs[0]);\n   se::DeviceMemoryBase inputs1_mem = allocations.GetDeviceAddress(inputs[1]);\n   // Initialize the log in device memory\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      SdcLog device_log,\n-      SdcLog::CreateOnDevice(*stream_, se::DeviceMemory<uint8_t>(log_mem)));\n+  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n+                          BufferDebugLog::CreateOnDevice(\n+                              *stream_, se::DeviceMemory<uint8_t>(log_mem)));\n   // Fill inputs with some data\n   std::vector<uint32_t> zeros(1024, 0);\n   zeros[123] = 12341234;  // expected checksum for inputs_mem[0]\n@@ -114,27 +116,29 @@ TEST_F(SdcThunkTest, CalculatesChecksums) {\n       /*command_buffer_trace_stream=*/stream_.get(),\n       /*collective_params=*/nullptr, /*collective_cliques=*/nullptr);\n \n-  SdcThunk thunk(Thunk::ThunkInfo(), log_slice,\n-                 {{SdcBufferId::Create(ThunkId(123), 4).value(), inputs[0]},\n-                  {SdcBufferId::Create(ThunkId(456), 8).value(), inputs[1]}});\n+  BuffersDebugChecksumThunk thunk(\n+      Thunk::ThunkInfo(), log_slice,\n+      {{ThunkBufferId::Create(ThunkId(123), 4).value(), inputs[0]},\n+       {ThunkBufferId::Create(ThunkId(456), 8).value(), inputs[1]}});\n   TF_ASSERT_OK(thunk.Initialize(init_params));\n   TF_ASSERT_OK(thunk.Prepare(Thunk::PrepareParams{}, resource_requests));\n   TF_ASSERT_OK(thunk.ExecuteOnStream(execute_params));\n-  TF_ASSERT_OK_AND_ASSIGN(std::vector<SdcLogEntry> entries,\n+  TF_ASSERT_OK_AND_ASSIGN(std::vector<BufferDebugLogEntry> entries,\n                           device_log.ReadFromDevice(*stream_));\n \n-  // SdcThunk launches a kernel for each input buffer, they may complete in any\n-  // order.\n-  EXPECT_THAT(entries,\n-              UnorderedElementsAre(\n-                  SdcLogEntry{\n-                      /*entry_id=*/SdcBufferId::Create(ThunkId(123), 4).value(),\n-                      /*checksum=*/12341234,\n-                  },\n-                  SdcLogEntry{\n-                      /*entry_id=*/SdcBufferId::Create(ThunkId(456), 8).value(),\n-                      /*checksum=*/56785678,\n-                  }));\n+  // BuffersDebugChecksumThunk launches a kernel for each input buffer, they may\n+  // complete in any order.\n+  EXPECT_THAT(\n+      entries,\n+      UnorderedElementsAre(\n+          BufferDebugLogEntry{\n+              /*entry_id=*/ThunkBufferId::Create(ThunkId(123), 4).value(),\n+              /*checksum=*/12341234,\n+          },\n+          BufferDebugLogEntry{\n+              /*entry_id=*/ThunkBufferId::Create(ThunkId(456), 8).value(),\n+              /*checksum=*/56785678,\n+          }));\n }\n \n }  // namespace",
            "previous_filename": "third_party/xla/xla/backends/gpu/runtime/sdc_thunk_test.cc"
        },
        {
            "sha": "57581bed877d1ee9b0f33549320694c294a390b6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -259,6 +259,7 @@ Thunk::ExecuteParams::ExecuteParams(\n     CASE(kAllToAll);\n     CASE(kAllToAllDone);\n     CASE(kAllToAllStart);\n+    CASE(kBuffersDebugChecksum);\n     CASE(kCholesky);\n     CASE(kCollectiveBroadcast);\n     CASE(kCollectiveBroadcastDone);\n@@ -314,7 +315,6 @@ Thunk::ExecuteParams::ExecuteParams(\n     CASE(kReduceScatterDone);\n     CASE(kReduceScatterStart);\n     CASE(kReplicaId);\n-    CASE(kSdc);\n     CASE(kSelectK);\n     CASE(kSend);\n     CASE(kSendDone);"
        },
        {
            "sha": "a2e21293553c015ee69e6e6fb952b2977acd3045",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -137,6 +137,7 @@ class Thunk {\n     kAllToAll,\n     kAllToAllDone,\n     kAllToAllStart,\n+    kBuffersDebugChecksum,\n     kCholesky,\n     kCollectiveBroadcast,\n     kCollectiveBroadcastDone,\n@@ -192,7 +193,6 @@ class Thunk {\n     kReduceScatterDone,\n     kReduceScatterStart,\n     kReplicaId,\n-    kSdc,\n     kSelectK,\n     kSend,\n     kSendDone,"
        },
        {
            "sha": "95ae27c31f6a2b9ddb6b954a6f81388b8babc7a4",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_id.h",
            "status": "renamed",
            "additions": 24,
            "deletions": 22,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_id.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_id.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_id.h?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -13,8 +13,8 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#ifndef XLA_BACKENDS_GPU_RUNTIME_SDC_BUFFER_ID_H_\n-#define XLA_BACKENDS_GPU_RUNTIME_SDC_BUFFER_ID_H_\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_THUNK_BUFFER_ID_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_THUNK_BUFFER_ID_H_\n \n #include <cstddef>\n #include <cstdint>\n@@ -29,30 +29,30 @@ namespace xla::gpu {\n // An ID that identifies a buffer within a program. It's a combination of the\n // thunk ID and the buffer index within the thunk.\n //\n-// A single buffer can be referred to by multiple SdcBufferIds, when it's being\n-// used in different thunks.\n-class SdcBufferId {\n+// A single buffer can be referred to by multiple ThunkBufferIds, when it's\n+// being used in different thunks.\n+class ThunkBufferId {\n  public:\n-  SdcBufferId() = default;\n+  ThunkBufferId() = default;\n \n-  // Creates a SdcBufferId that represents the `buffer_idx`-th buffer of a thunk\n-  // with `thunk_info`.\n+  // Creates a ThunkBufferId that represents the `buffer_idx`-th buffer of a\n+  // thunk with `thunk_info`.\n   //\n   // Returns an error if `buffer_idx` is too large to be represented in a\n-  // SdcBufferId.\n-  static absl::StatusOr<SdcBufferId> Create(ThunkId thunk_id,\n-                                            size_t buffer_idx) {\n+  // ThunkBufferId.\n+  static absl::StatusOr<ThunkBufferId> Create(ThunkId thunk_id,\n+                                              size_t buffer_idx) {\n     if (buffer_idx >= (1 << kBitsReservedForBufferIndex)) {\n       return absl::InvalidArgumentError(absl::StrFormat(\n-          \"Buffer index (%u) is too large to be represented in a SdcBufferId \"\n+          \"Buffer index (%u) is too large to be represented in a ThunkBufferId \"\n           \"(max = %u)\",\n           buffer_idx, (1 << kBitsReservedForBufferIndex) - 1));\n     }\n \n     const uint32_t value = (static_cast<uint32_t>(thunk_id.value())\n                             << kBitsReservedForBufferIndex) |\n                            static_cast<uint32_t>(buffer_idx);\n-    return SdcBufferId(value);\n+    return ThunkBufferId(value);\n   }\n \n   ThunkId thunk_id() const {\n@@ -62,38 +62,40 @@ class SdcBufferId {\n     return value_ & ((1 << kBitsReservedForBufferIndex) - 1);\n   }\n \n-  // Raw numeric value of the ID, for use in SdcLogEntry::entry_id.\n+  // Raw numeric value of the ID, for use in BufferDebugLogEntry::entry_id.\n   uint32_t value() const { return value_; }\n \n-  bool operator==(const SdcBufferId& other) const {\n+  bool operator==(const ThunkBufferId& other) const {\n     return value_ == other.value_;\n   }\n-  bool operator!=(const SdcBufferId& other) const { return !(*this == other); }\n+  bool operator!=(const ThunkBufferId& other) const {\n+    return !(*this == other);\n+  }\n \n   template <typename Sink>\n-  friend void AbslStringify(Sink& sink, const SdcBufferId& buffer_id) {\n+  friend void AbslStringify(Sink& sink, const ThunkBufferId& buffer_id) {\n     absl::Format(&sink, \"{thunk_id: %u, buffer_idx: %u}\",\n                  buffer_id.thunk_id().value(), buffer_id.buffer_idx());\n   }\n \n   template <typename H>\n-  friend H AbslHashValue(H h, const SdcBufferId& buffer_id) {\n+  friend H AbslHashValue(H h, const ThunkBufferId& buffer_id) {\n     return H::combine(std::move(h), buffer_id.value_);\n   }\n \n  private:\n-  // Out of 32 bits available in SDC entry id, reserve that much for the\n-  // buffer index. This limits us to:\n+  // Out of 32 bits available in id, reserve that much for the buffer index.\n+  // This limits us to:\n   // - 2^kBitsReservedForBufferIndex max buffers per thunk\n   // - 2^(32-kBitsReservedForBufferIndex) max thunks\n   // Which hopefully is enough.\n   static constexpr size_t kBitsReservedForBufferIndex = 8;\n \n-  explicit SdcBufferId(uint32_t value) : value_(value) {}\n+  explicit ThunkBufferId(uint32_t value) : value_(value) {}\n \n   uint32_t value_ = 0;\n };\n \n }  // namespace xla::gpu\n \n-#endif  // XLA_BACKENDS_GPU_RUNTIME_SDC_BUFFER_ID_H_\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_THUNK_BUFFER_ID_H_",
            "previous_filename": "third_party/xla/xla/backends/gpu/runtime/sdc_buffer_id.h"
        },
        {
            "sha": "5627c3ac9256314666c8aa837b2df41d3289e328",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_id_test.cc",
            "status": "renamed",
            "additions": 12,
            "deletions": 11,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_id_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_id_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_id_test.cc?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -13,7 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n@@ -24,22 +24,23 @@ limitations under the License.\n \n namespace {\n \n-TEST(SdcBufferIdTest, CreateFailsForLargeBufferIndex) {\n-  EXPECT_THAT(xla::gpu::SdcBufferId::Create(xla::gpu::ThunkId(123),\n-                                            /*buffer_idx=*/256),\n+TEST(ThunkBufferIdTest, CreateFailsForLargeBufferIndex) {\n+  EXPECT_THAT(xla::gpu::ThunkBufferId::Create(xla::gpu::ThunkId(123),\n+                                              /*buffer_idx=*/256),\n               absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n-TEST(SdcBufferIdTest, CreateSucceedsForSmallBufferIndex) {\n-  EXPECT_THAT(xla::gpu::SdcBufferId::Create(xla::gpu::ThunkId(123),\n-                                            /*buffer_idx=*/255),\n+TEST(ThunkBufferIdTest, CreateSucceedsForSmallBufferIndex) {\n+  EXPECT_THAT(xla::gpu::ThunkBufferId::Create(xla::gpu::ThunkId(123),\n+                                              /*buffer_idx=*/255),\n               absl_testing::IsOk());\n }\n \n-TEST(SdcBufferIdTest, CorrectlyStoresAndExtractsThunkIdAndBufferIndex) {\n-  TF_ASSERT_OK_AND_ASSIGN(xla::gpu::SdcBufferId buffer_id,\n-                          xla::gpu::SdcBufferId::Create(xla::gpu::ThunkId(123),\n-                                                        /*buffer_idx=*/45));\n+TEST(ThunkBufferIdTest, CorrectlyStoresAndExtractsThunkIdAndBufferIndex) {\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      xla::gpu::ThunkBufferId buffer_id,\n+      xla::gpu::ThunkBufferId::Create(xla::gpu::ThunkId(123),\n+                                      /*buffer_idx=*/45));\n \n   EXPECT_THAT(buffer_id.thunk_id(), xla::gpu::ThunkId(123));\n   EXPECT_THAT(buffer_id.buffer_idx(), 45);",
            "previous_filename": "third_party/xla/xla/backends/gpu/runtime/sdc_buffer_id_test.cc"
        },
        {
            "sha": "c77614aeeafe15a48011890d53b21711a28bba7c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_checksum_tracing_pass.cc",
            "status": "modified",
            "additions": 57,
            "deletions": 54,
            "changes": 111,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -27,11 +27,11 @@ limitations under the License.\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"xla/backends/gpu/runtime/buffers_checksum_thunk.h\"\n #include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n-#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n-#include \"xla/backends/gpu/runtime/sdc_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n #include \"xla/backends/gpu/runtime/thunk_pass_pipeline.h\"\n #include \"xla/ffi/api/c_api.h\"\n #include \"xla/ffi/ffi.h\"\n@@ -41,8 +41,8 @@ limitations under the License.\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/dump.h\"\n #include \"xla/shape.h\"\n-#include \"xla/stream_executor/cuda/sdc_log.h\"\n #include \"xla/stream_executor/device_description.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_log.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -51,16 +51,16 @@ namespace xla::gpu {\n \n namespace se = stream_executor;\n \n-// With SdcLogEntry size of 8 bytes, this is enough to hold ~8K entries.\n+// With BufferDebugLogEntry size of 8 bytes, this is enough to hold ~8K entries.\n constexpr size_t kLogSizeBytes = 64 * 1024;\n \n namespace {\n \n // If the thunk has any interesting buffers to check, turns it into a sequence\n // of:\n-// - SdcThunk checking the buffers before execution\n+// - BuffersDebugChecksumThunk checking the buffers before execution\n // - The original thunk\n-// - SdcThunk checking the buffers after execution\n+// - BuffersDebugChecksumThunk checking the buffers after execution\n //\n // If the thunk got wrapped, the data dependencies between the thunks will be\n // configured to ensure `predecessor_thunk` executes before the wrapped thunk\n@@ -73,14 +73,14 @@ absl::StatusOr<std::unique_ptr<Thunk>> WrapThunk(\n     return thunk;\n   }\n \n-  absl::flat_hash_map<SdcBufferId, BufferAllocation::Slice>\n+  absl::flat_hash_map<ThunkBufferId, BufferAllocation::Slice>\n       buffers_to_check_before;\n-  absl::flat_hash_map<SdcBufferId, BufferAllocation::Slice>\n+  absl::flat_hash_map<ThunkBufferId, BufferAllocation::Slice>\n       buffers_to_check_after;\n \n   for (size_t buffer_idx = 0; buffer_idx < thunk_buffers.size(); ++buffer_idx) {\n-    absl::StatusOr<SdcBufferId> buffer_id =\n-        SdcBufferId::Create(thunk->thunk_info().thunk_id, buffer_idx);\n+    absl::StatusOr<ThunkBufferId> buffer_id =\n+        ThunkBufferId::Create(thunk->thunk_info().thunk_id, buffer_idx);\n     if (!buffer_id.ok()) {\n       LOG(WARNING) << \"Skipping buffer \" << buffer_idx << \" in thunk \"\n                    << thunk->thunk_info().thunk_id << \": \"\n@@ -103,20 +103,21 @@ absl::StatusOr<std::unique_ptr<Thunk>> WrapThunk(\n \n   std::vector<std::unique_ptr<Thunk>> thunk_and_checks;\n   if (!buffers_to_check_before.empty()) {\n-    auto sdc_before_thunk = std::make_unique<SdcThunk>(\n-        Thunk::ThunkInfo(), log_slice, std::move(buffers_to_check_before));\n-    thunk->add_control_predecessor(sdc_before_thunk.get());\n-    thunk_and_checks.push_back(std::move(sdc_before_thunk));\n+    auto buffer_debug_before_thunk =\n+        std::make_unique<BuffersDebugChecksumThunk>(\n+            Thunk::ThunkInfo(), log_slice, std::move(buffers_to_check_before));\n+    thunk->add_control_predecessor(buffer_debug_before_thunk.get());\n+    thunk_and_checks.push_back(std::move(buffer_debug_before_thunk));\n   }\n \n   Thunk* thunk_ptr = thunk.get();\n   thunk_and_checks.push_back(std::move(thunk));\n \n   if (!buffers_to_check_after.empty()) {\n-    auto sdc_after_thunk = std::make_unique<SdcThunk>(\n+    auto buffer_debug_after_thunk = std::make_unique<BuffersDebugChecksumThunk>(\n         Thunk::ThunkInfo(), log_slice, std::move(buffers_to_check_after));\n-    sdc_after_thunk->add_control_predecessor(thunk_ptr);\n-    thunk_and_checks.push_back(std::move(sdc_after_thunk));\n+    buffer_debug_after_thunk->add_control_predecessor(thunk_ptr);\n+    thunk_and_checks.push_back(std::move(buffer_debug_after_thunk));\n   }\n \n   auto wrapped_thunk = std::make_unique<SequentialThunk>(\n@@ -129,8 +130,8 @@ absl::StatusOr<std::unique_ptr<Thunk>> WrapThunk(\n XLA_FFI_DEFINE_HANDLER_SYMBOL(\n     kDebugLogInitHandler,\n     [](se::Stream* absl_nonnull stream, xla::ffi::Buffer<U8> log_buffer) {\n-      return se::cuda::SdcLog::CreateOnDevice(*stream,\n-                                              log_buffer.device_memory())\n+      return se::cuda::BufferDebugLog::CreateOnDevice(\n+                 *stream, log_buffer.device_memory())\n           .status();\n     },\n     xla::ffi::Ffi::Bind().Ctx<xla::ffi::Stream>().Arg<xla::ffi::Buffer<U8>>());\n@@ -139,21 +140,22 @@ XLA_FFI_DEFINE_HANDLER_SYMBOL(\n     kDebugLogDumpHandler,\n     [](se::Stream* stream, const HloComputation* absl_nonnull hlo_computation,\n        xla::ffi::Buffer<U8> log_buffer) {\n-      VLOG(1) << \"[SDC LOG] HLO computation ptr: \" << hlo_computation;\n+      VLOG(1) << \"HLO computation ptr: \" << hlo_computation;\n       const HloModule* hlo_module = hlo_computation->parent();\n-      VLOG(1) << \"[SDC LOG] HLO module ptr: \" << hlo_module;\n-      VLOG(1) << \"[SDC LOG] HLO module name: \" << hlo_module->name();\n+      VLOG(1) << \"HLO module ptr: \" << hlo_module;\n+      VLOG(1) << \"HLO module name: \" << hlo_module->name();\n       CHECK(hlo_module != nullptr);\n       const DebugOptions& debug_options = hlo_module->config().debug_options();\n \n-      se::cuda::SdcLog sdc_log = se::cuda::SdcLog::FromDeviceMemoryUnchecked(\n-          log_buffer.device_memory());\n-      TF_ASSIGN_OR_RETURN(xla::gpu::SdcLogProto sdc_log_proto,\n-                          sdc_log.ReadProto(*stream));\n-      VLOG(1) << \"[SDC LOG] read \" << sdc_log_proto.entries_size()\n-              << \" entries\";\n-      DumpPerExecutionProtobufToFile(*hlo_module, sdc_log_proto, debug_options,\n-                                     \"sdc_log\", nullptr);\n+      se::cuda::BufferDebugLog buffer_debug_log =\n+          se::cuda::BufferDebugLog::FromDeviceMemoryUnchecked(\n+              log_buffer.device_memory());\n+      TF_ASSIGN_OR_RETURN(xla::gpu::BufferDebugLogProto buffer_debug_log_proto,\n+                          buffer_debug_log.ReadProto(*stream));\n+      VLOG(1) << \"read \" << buffer_debug_log_proto.entries_size() << \" entries\";\n+      DumpPerExecutionProtobufToFile(*hlo_module, buffer_debug_log_proto,\n+                                     debug_options, \"buffer_debug_log\",\n+                                     nullptr);\n       return absl::OkStatus();\n     },\n     xla::ffi::Ffi::Bind()\n@@ -168,11 +170,11 @@ absl::StatusOr<bool> ThunkChecksumTracingPass::Run(\n     const HloModule* absl_nullable hlo_module,\n     const se::DeviceDescription& device_info,\n     ThunkPassBufferAllocator& allocator) {\n-  VLOG(1) << \"[SDC LOG] ThunkChecksumTracingPass running\";\n+  VLOG(1) << \"ThunkChecksumTracingPass running\";\n   if (hlo_module == nullptr) {\n-    // We need the HLO module to dump the SDC log proto to a file. If it's not\n-    // available, there's no point in doing extra work.\n-    VLOG(1) << \"[SDC LOG] HLO module is null, skipping\";\n+    // We need the HLO module to dump the buffer debug log proto to a file. If\n+    // it's not available, there's no point in doing extra work.\n+    VLOG(1) << \"HLO module is null, skip buffer checksumming\";\n     return false;\n   }\n \n@@ -184,35 +186,36 @@ absl::StatusOr<bool> ThunkChecksumTracingPass::Run(\n       /*shape=*/Shape(PrimitiveType::U8, /*dimensions=*/{log_alloc->size()}),\n   };\n \n-  XLA_FFI_Handler_Bundle sdc_init_bundle{};\n-  sdc_init_bundle.execute = kDebugLogInitHandler;\n+  XLA_FFI_Handler_Bundle buffer_debug_init_bundle{};\n+  buffer_debug_init_bundle.execute = kDebugLogInitHandler;\n   TF_ASSIGN_OR_RETURN(\n-      auto sdc_init_thunk,\n-      CustomCallThunk::Create(Thunk::ThunkInfo(), \"xla_gpu_sdc_log_init\",\n-                              sdc_init_bundle, /*operands=*/{shaped_log_slice},\n-                              /*results=*/{}, /*attributes=*/{},\n-                              hlo_module->entry_computation()));\n-\n-  XLA_FFI_Handler_Bundle sdc_dump_bundle{};\n-  sdc_dump_bundle.execute = kDebugLogDumpHandler;\n-  TF_ASSIGN_OR_RETURN(\n-      auto sdc_dump_thunk,\n+      auto buffer_debug_init_thunk,\n       CustomCallThunk::Create(\n-          Thunk::ThunkInfo(), \"xla_gpu_sdc_log_dump\", sdc_dump_bundle,\n-          /*operands=*/{shaped_log_slice},\n+          Thunk::ThunkInfo(), \"xla_gpu_buffer_debug_log_init\",\n+          buffer_debug_init_bundle, /*operands=*/{shaped_log_slice},\n           /*results=*/{}, /*attributes=*/{}, hlo_module->entry_computation()));\n \n+  XLA_FFI_Handler_Bundle buffer_debug_dump_bundle{};\n+  buffer_debug_dump_bundle.execute = kDebugLogDumpHandler;\n+  TF_ASSIGN_OR_RETURN(auto buffer_debug_dump_thunk,\n+                      CustomCallThunk::Create(Thunk::ThunkInfo(),\n+                                              \"xla_gpu_buffer_debug_log_dump\",\n+                                              buffer_debug_dump_bundle,\n+                                              /*operands=*/{shaped_log_slice},\n+                                              /*results=*/{}, /*attributes=*/{},\n+                                              hlo_module->entry_computation()));\n+\n   ThunkSequence& thunks = root_thunk->thunks();\n   for (auto& thunk : thunks) {\n-    TF_ASSIGN_OR_RETURN(thunk,\n-                        WrapThunk(std::move(thunk), log_slice,\n-                                  /*predecessor_thunk=*/*sdc_init_thunk.get(),\n-                                  /*successor_thunk=*/*sdc_dump_thunk.get()));\n+    TF_ASSIGN_OR_RETURN(\n+        thunk, WrapThunk(std::move(thunk), log_slice,\n+                         /*predecessor_thunk=*/*buffer_debug_init_thunk.get(),\n+                         /*successor_thunk=*/*buffer_debug_dump_thunk.get()));\n   }\n \n   thunks.reserve(thunks.size() + 2);\n-  thunks.insert(thunks.begin(), std::move(sdc_init_thunk));\n-  thunks.push_back(std::move(sdc_dump_thunk));\n+  thunks.insert(thunks.begin(), std::move(buffer_debug_init_thunk));\n+  thunks.push_back(std::move(buffer_debug_dump_thunk));\n \n   return true;\n }"
        },
        {
            "sha": "4a10ec8d8198b38cd07dde892208d35df887e4ff",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_checksum_tracing_pass_test.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 23,
            "changes": 48,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass_test.cc?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -24,11 +24,11 @@ limitations under the License.\n #include <gtest/gtest.h>\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"xla/backends/gpu/runtime/buffers_checksum_thunk.h\"\n #include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n-#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n-#include \"xla/backends/gpu/runtime/sdc_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/backends/gpu/runtime/thunk_pass_pipeline.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n@@ -109,7 +109,7 @@ TEST(ThunkChecksumTracingPassTest, IsNoOpWhenHloModuleIsNull) {\n   EXPECT_THAT(root_thunk->thunks(), ElementsAre(Pointer(fake_thunk_ptr)));\n }\n \n-TEST(ThunkChecksumTracingPassTest, InsertsSdcThunks) {\n+TEST(ThunkChecksumTracingPassTest, InsertsBuffersDebugChecksumThunks) {\n   static constexpr ThunkId kTestThunkId = ThunkId(123);\n   DebugOptions debug_options;\n   debug_options.set_xla_gpu_experimental_enable_checksum_tracing_on_thunks(\n@@ -159,48 +159,50 @@ TEST(ThunkChecksumTracingPassTest, InsertsSdcThunks) {\n   EXPECT_TRUE(changed);\n \n   // Expected thunk structure after the pass:\n-  // 1. CustomCallThunk (SDC init)\n+  // 1. CustomCallThunk (buffer debug log init)\n   // 2. SequentialThunk\n-  //    1. SdcThunk (SDC checks on input buffers)\n+  //    1. BuffersDebugChecksumThunk (checksum input buffers)\n   //    2. FakeThunk\n-  //    3. SdcThunk (SDC checks on output buffers)\n-  // 3. CustomCallThunk (SDC dump)\n+  //    3. BuffersDebugChecksumThunk (checksum output buffers)\n+  // 3. CustomCallThunk (buffer debug log dump)\n   const std::vector<std::unique_ptr<Thunk>>& new_thunks = root_thunk->thunks();\n   EXPECT_THAT(new_thunks, SizeIs(3));\n   EXPECT_EQ(new_thunks[0]->kind(), Thunk::Kind::kCustomCall);\n   EXPECT_EQ(new_thunks[1]->kind(), Thunk::Kind::kSequential);\n   EXPECT_EQ(new_thunks[2]->kind(), Thunk::Kind::kCustomCall);\n \n-  const CustomCallThunk& sdc_init_thunk =\n+  const CustomCallThunk& buffer_debug_init_thunk =\n       static_cast<const CustomCallThunk&>(*new_thunks[0]);\n-  EXPECT_EQ(sdc_init_thunk.target_name(), \"xla_gpu_sdc_log_init\");\n+  EXPECT_EQ(buffer_debug_init_thunk.target_name(),\n+            \"xla_gpu_buffer_debug_log_init\");\n \n-  const CustomCallThunk& sdc_dump_thunk =\n+  const CustomCallThunk& buffer_debug_dump_thunk =\n       static_cast<const CustomCallThunk&>(*new_thunks[2]);\n-  EXPECT_EQ(sdc_dump_thunk.target_name(), \"xla_gpu_sdc_log_dump\");\n+  EXPECT_EQ(buffer_debug_dump_thunk.target_name(),\n+            \"xla_gpu_buffer_debug_log_dump\");\n \n   const std::vector<std::unique_ptr<Thunk>>& sub_thunks =\n       static_cast<const SequentialThunk&>(*new_thunks[1]).thunks();\n   EXPECT_THAT(sub_thunks, SizeIs(3));\n-  EXPECT_EQ(sub_thunks[0]->kind(), Thunk::Kind::kSdc);\n+  EXPECT_EQ(sub_thunks[0]->kind(), Thunk::Kind::kBuffersDebugChecksum);\n   EXPECT_THAT(sub_thunks[1], Pointer(fake_thunk_ptr));\n-  EXPECT_EQ(sub_thunks[2]->kind(), Thunk::Kind::kSdc);\n+  EXPECT_EQ(sub_thunks[2]->kind(), Thunk::Kind::kBuffersDebugChecksum);\n \n-  const SdcThunk& sdc_before_fake_thunk =\n-      static_cast<const SdcThunk&>(*sub_thunks[0]);\n+  const BuffersDebugChecksumThunk& buffer_debug_before_fake_thunk =\n+      static_cast<const BuffersDebugChecksumThunk&>(*sub_thunks[0]);\n   EXPECT_THAT(\n-      sdc_before_fake_thunk.buffer_slices(),\n+      buffer_debug_before_fake_thunk.buffer_slices(),\n       UnorderedElementsAre(\n-          Pair(SdcBufferId::Create(kTestThunkId, 0).value(), slice_i),\n-          Pair(SdcBufferId::Create(kTestThunkId, 2).value(), slice_io)));\n+          Pair(ThunkBufferId::Create(kTestThunkId, 0).value(), slice_i),\n+          Pair(ThunkBufferId::Create(kTestThunkId, 2).value(), slice_io)));\n \n-  const SdcThunk& sdc_after_fake_thunk =\n-      static_cast<const SdcThunk&>(*sub_thunks[2]);\n+  const BuffersDebugChecksumThunk& buffer_debug_after_fake_thunk =\n+      static_cast<const BuffersDebugChecksumThunk&>(*sub_thunks[2]);\n   EXPECT_THAT(\n-      sdc_after_fake_thunk.buffer_slices(),\n+      buffer_debug_after_fake_thunk.buffer_slices(),\n       UnorderedElementsAre(\n-          Pair(SdcBufferId::Create(kTestThunkId, 1).value(), slice_o),\n-          Pair(SdcBufferId::Create(kTestThunkId, 2).value(), slice_io)));\n+          Pair(ThunkBufferId::Create(kTestThunkId, 1).value(), slice_o),\n+          Pair(ThunkBufferId::Create(kTestThunkId, 2).value(), slice_io)));\n }\n \n }  // namespace"
        },
        {
            "sha": "dddaec8e969cd41c2adf539f14952b899610e30b",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 13,
            "deletions": 56,
            "changes": 69,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -422,64 +422,21 @@ cuda_library(\n     ],\n )\n \n-cc_library(\n-    name = \"sdc_log\",\n-    srcs = [\"sdc_log.cc\"],\n-    hdrs = [\"sdc_log.h\"],\n-    deps = [\n-        \"//xla/backends/gpu/runtime:sdc_log_structs\",\n-        \"//xla/backends/gpu/runtime:sdc_proto_cc\",\n-        \"//xla/stream_executor:device_memory\",\n-        \"//xla/stream_executor:device_memory_allocator\",\n-        \"//xla/stream_executor:stream\",\n-        \"//xla/tsl/platform:errors\",\n-        \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/status:statusor\",\n-        \"@com_google_absl//absl/strings:str_format\",\n-    ],\n-)\n-\n-xla_test(\n-    name = \"sdc_log_test\",\n-    srcs = [\"sdc_log_test.cc\"],\n-    backends = [\"gpu\"],\n-    deps = [\n-        \":sdc_log\",\n-        \"//xla/backends/gpu/runtime:sdc_buffer_id\",\n-        \"//xla/backends/gpu/runtime:sdc_log_structs\",\n-        \"//xla/backends/gpu/runtime:thunk_id\",\n-        \"//xla/stream_executor:device_memory\",\n-        \"//xla/stream_executor:platform\",\n-        \"//xla/stream_executor:platform_manager\",\n-        \"//xla/stream_executor:stream\",\n-        \"//xla/stream_executor:stream_executor_h\",\n-        \"//xla/stream_executor:stream_executor_memory_allocator\",\n-        \"//xla/tsl/lib/core:status_test_util\",\n-        \"//xla/tsl/platform:statusor\",\n-        \"//xla/tsl/util/proto:proto_matchers\",\n-        \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/status:status_matchers\",\n-        \"@com_google_absl//absl/types:span\",\n-        \"@com_google_googletest//:gtest_main\",\n-    ],\n-)\n-\n cuda_library(\n-    name = \"sdc_xor_checksum_kernel_cuda\",\n-    srcs = [\"sdc_xor_checksum_kernel_cuda.cu.cc\"],\n+    name = \"buffer_debug_xor_checksum_kernel_cuda\",\n+    srcs = [\"buffer_debug_xor_checksum_kernel_cuda.cu.cc\"],\n     # copybara:uncomment compatible_with = [\"//buildenv/target:non_prod\"],\n     tags = [\n         \"cuda-only\",\n         \"gpu\",\n     ],\n     deps = [\n         \":cuda_platform\",\n-        \"//xla/backends/gpu/runtime:sdc_buffer_id\",\n-        \"//xla/backends/gpu/runtime:sdc_log_structs\",\n+        \"//xla/backends/gpu/runtime:buffer_debug_log_structs\",\n+        \"//xla/backends/gpu/runtime:thunk_buffer_id\",\n         \"//xla/stream_executor:kernel_spec\",\n+        \"//xla/stream_executor/gpu:buffer_debug_xor_checksum_kernel\",\n         \"//xla/stream_executor/gpu:gpu_kernel_registry\",\n-        \"//xla/stream_executor/gpu:sdc_xor_checksum_kernel\",\n         \"//xla/tsl/platform:logging\",\n         \"@com_google_absl//absl/base\",\n         \"@local_config_cuda//cuda:cuda_headers\",\n@@ -488,15 +445,14 @@ cuda_library(\n )\n \n xla_test(\n-    name = \"sdc_xor_checksum_kernel_cuda_test\",\n-    srcs = [\"sdc_xor_checksum_kernel_cuda_test.cc\"],\n+    name = \"buffer_debug_xor_checksum_kernel_cuda_test\",\n+    srcs = [\"buffer_debug_xor_checksum_kernel_cuda_test.cc\"],\n     backends = [\"gpu\"],\n     tags = [\"cuda-only\"],\n     deps = [\n-        \":sdc_log\",\n-        \":sdc_xor_checksum_kernel_cuda\",\n-        \"//xla/backends/gpu/runtime:sdc_buffer_id\",\n-        \"//xla/backends/gpu/runtime:sdc_log_structs\",\n+        \":buffer_debug_xor_checksum_kernel_cuda\",\n+        \"//xla/backends/gpu/runtime:buffer_debug_log_structs\",\n+        \"//xla/backends/gpu/runtime:thunk_buffer_id\",\n         \"//xla/backends/gpu/runtime:thunk_id\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:launch_dim\",\n@@ -506,8 +462,9 @@ xla_test(\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor:stream_executor_memory_allocator\",\n         \"//xla/stream_executor:typed_kernel_factory\",\n+        \"//xla/stream_executor/gpu:buffer_debug_log\",\n+        \"//xla/stream_executor/gpu:buffer_debug_xor_checksum_kernel\",\n         \"//xla/stream_executor/gpu:gpu_kernel_registry\",\n-        \"//xla/stream_executor/gpu:sdc_xor_checksum_kernel\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n@@ -1277,6 +1234,7 @@ cc_library(\n     deps = [\n         \":all_reduce_kernel_cuda\",\n         \":buffer_comparator_kernel_cuda\",\n+        \":buffer_debug_xor_checksum_kernel_cuda\",\n         \":cublas_plugin\",\n         \":cuda_platform\",\n         \":cuda_solver_context\",\n@@ -1286,7 +1244,6 @@ cc_library(\n         \":ragged_all_to_all_kernel_cuda\",\n         \":redzone_allocator_kernel_cuda\",\n         \":repeat_buffer_kernel_cuda\",\n-        \":sdc_xor_checksum_kernel_cuda\",\n         \":topk_kernel_cuda\",\n         \"//xla/tsl/cuda:cusolver\",\n         \"//xla/tsl/cuda:cusparse\","
        },
        {
            "sha": "45e71cb4e06925306a7cae77c1aef6420e5564bb",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_xor_checksum_kernel_cuda.cu.cc",
            "status": "renamed",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda.cu.cc?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -19,11 +19,11 @@ limitations under the License.\n \n #include \"absl/base/casts.h\"\n #include \"third_party/gpus/cuda/include/cuda/atomic\"\n-#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n-#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n #include \"xla/stream_executor/cuda/cuda_platform.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_xor_checksum_kernel.h\"\n #include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n-#include \"xla/stream_executor/gpu/sdc_xor_checksum_kernel.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n #include \"xla/tsl/platform/logging.h\"\n \n@@ -117,10 +117,10 @@ __device__ void ReduceXor(const uint32_t* input, uint64_t input_size,\n // LIMITATIONS:\n // - Only a single thread block is supported.\n // - Block dimensions must be a power of 2.\n-__global__ void AppendChecksum(xla::gpu::SdcBufferId entry_id,\n+__global__ void AppendChecksum(xla::gpu::ThunkBufferId entry_id,\n                                const uint8_t* input, uint64_t input_size,\n-                               xla::gpu::SdcLogHeader* log_header,\n-                               xla::gpu::SdcLogEntry* log_entries) {\n+                               xla::gpu::BufferDebugLogHeader* log_header,\n+                               xla::gpu::BufferDebugLogEntry* log_entries) {\n   const uint32_t block_size = blockDim.x * blockDim.y * blockDim.z;\n   const uint32_t* input_u32 = reinterpret_cast<const uint32_t*>(input);\n   const uint64_t input_u32_size = input_size / sizeof(uint32_t);\n@@ -196,15 +196,15 @@ __global__ void AppendChecksum(xla::gpu::SdcBufferId entry_id,\n   }\n }\n \n-absl::StatusOr<se::KernelLoaderSpec> GetSdcXorChecksumKernelSpec() {\n+absl::StatusOr<se::KernelLoaderSpec> GetChecksumKernelSpec() {\n   return se::KernelLoaderSpec::CreateInProcessSymbolSpec(\n-      absl::bit_cast<void*>(&AppendChecksum), \"SdcXorChecksumKernel\",\n+      absl::bit_cast<void*>(&AppendChecksum), \"BufferDebugXorChecksumKernel\",\n       /*arity=*/5);\n }\n \n }  // namespace\n \n GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(\n-    SdcXorChecksumKernel, se::gpu::SdcXorChecksumKernel,\n+    BufferDebugXorChecksumKernel, se::gpu::BufferDebugXorChecksumKernel,\n     se::cuda::kCudaPlatformId,\n-    ([](size_t _arity) { return GetSdcXorChecksumKernelSpec().value(); }));\n+    ([](size_t _arity) { return GetChecksumKernelSpec().value(); }));",
            "previous_filename": "third_party/xla/xla/stream_executor/cuda/sdc_xor_checksum_kernel_cuda.cu.cc"
        },
        {
            "sha": "476c847da73d55582da9d49939ba9d6304a1743d",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_xor_checksum_kernel_cuda_test.cc",
            "status": "renamed",
            "additions": 49,
            "deletions": 39,
            "changes": 88,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -26,13 +26,13 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n-#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n-#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n-#include \"xla/stream_executor/cuda/sdc_log.h\"\n #include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_log.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_xor_checksum_kernel.h\"\n #include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n-#include \"xla/stream_executor/gpu/sdc_xor_checksum_kernel.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n@@ -49,9 +49,9 @@ namespace se = stream_executor;\n namespace stream_executor::cuda {\n namespace {\n \n-using xla::gpu::SdcBufferId;\n-using xla::gpu::SdcLogEntry;\n-using xla::gpu::SdcLogHeader;\n+using xla::gpu::BufferDebugLogEntry;\n+using xla::gpu::BufferDebugLogHeader;\n+using xla::gpu::ThunkBufferId;\n using xla::gpu::ThunkId;\n \n class ChecksumKernelTest : public ::testing::Test {\n@@ -67,8 +67,9 @@ class ChecksumKernelTest : public ::testing::Test {\n     if (!executor_->GetDeviceDescription()\n              .cuda_compute_capability()\n              .IsAtLeastPascal()) {\n-      GTEST_SKIP() << \"SDC checksumming is not supported on CUDA architectures \"\n-                      \"older than Pascal due to missing atomic fetch_add\";\n+      GTEST_SKIP()\n+          << \"Buffer checksumming is not supported on CUDA architectures older \"\n+             \"than Pascal due to missing atomic fetch_add with system scope\";\n     }\n   }\n \n@@ -84,13 +85,15 @@ class ChecksumKernelTest : public ::testing::Test {\n \n   template <typename T>\n   absl::Status AppendChecksumOnDevice(\n-      SdcBufferId entry_id, const T& input, se::cuda::SdcLog& sdc_log,\n+      ThunkBufferId entry_id, const T& input,\n+      se::cuda::BufferDebugLog& buffer_debug_log,\n       stream_executor::ThreadDim dim = stream_executor::ThreadDim(1, 1, 1)) {\n     // Load kernel\n     gpu::GpuKernelRegistry registry =\n         gpu::GpuKernelRegistry::GetGlobalRegistry();\n     TF_ASSIGN_OR_RETURN(\n-        auto kernel, registry.LoadKernel<gpu::SdcXorChecksumKernel>(executor_));\n+        auto kernel,\n+        registry.LoadKernel<gpu::BufferDebugXorChecksumKernel>(executor_));\n \n     // Setup device buffers\n     TF_ASSIGN_OR_RETURN(se::DeviceMemory<uint8_t> device_input,\n@@ -103,13 +106,14 @@ class ChecksumKernelTest : public ::testing::Test {\n     // Call kernel\n     TF_RETURN_IF_ERROR(stream_->Memcpy(&device_input, input.data(),\n                                        input.size() * sizeof(input[0])));\n-    TF_RETURN_IF_ERROR(\n-        kernel.Launch(dim, stream_executor::BlockDim(1, 1, 1), stream_.get(),\n-                      entry_id, device_input, device_input.ElementCount(),\n-                      sdc_log.GetDeviceHeader(), sdc_log.GetDeviceEntries()));\n+    TF_RETURN_IF_ERROR(kernel.Launch(dim, stream_executor::BlockDim(1, 1, 1),\n+                                     stream_.get(), entry_id, device_input,\n+                                     device_input.ElementCount(),\n+                                     buffer_debug_log.GetDeviceHeader(),\n+                                     buffer_debug_log.GetDeviceEntries()));\n     TF_RETURN_IF_ERROR(stream_->BlockHostUntilDone());\n \n-    // The result gets stored in `sdc_log`.\n+    // The result gets stored in `buffer_debug_log`.\n     return absl::OkStatus();\n   }\n \n@@ -130,10 +134,11 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumForMultipleOf32Bit) {\n   input[1003] ^= 0x12;\n   constexpr uint32_t kExpectedChecksum = 0x12345678;\n \n-  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n-                          se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      se::cuda::BufferDebugLog device_log,\n+      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n-  TF_EXPECT_OK(AppendChecksumOnDevice(SdcBufferId(), input, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(ThunkBufferId(), input, device_log));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n@@ -144,10 +149,11 @@ TEST_F(ChecksumKernelTest,\n        PadsMostSignifantBitsOfIncomplete32BitInputWordWithZeros) {\n   se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(1024);\n   const std::vector<uint8_t> kInput = std::vector<uint8_t>(1023, 0x55);\n-  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n-                          se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      se::cuda::BufferDebugLog device_log,\n+      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n-  TF_EXPECT_OK(AppendChecksumOnDevice(SdcBufferId(), kInput, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(ThunkBufferId(), kInput, device_log));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n@@ -162,10 +168,11 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallel) {\n   // Xor with the expected checksum value.\n   input[1000] ^= 0x12345678;\n   constexpr uint32_t kExpectedChecksum = 0x12345678;\n-  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n-                          se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      se::cuda::BufferDebugLog device_log,\n+      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n-  TF_EXPECT_OK(AppendChecksumOnDevice(SdcBufferId(), input, device_log,\n+  TF_EXPECT_OK(AppendChecksumOnDevice(ThunkBufferId(), input, device_log,\n                                       se::ThreadDim(2, 4, 8)));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n@@ -180,10 +187,11 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallelWithMaxThreads) {\n   // Xor with the expected checksum value.\n   input[1000] ^= 0x12345678;\n   constexpr uint32_t kExpectedChecksum = 0x12345678;\n-  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n-                          se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      se::cuda::BufferDebugLog device_log,\n+      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n-  TF_EXPECT_OK(AppendChecksumOnDevice(SdcBufferId(), input, device_log,\n+  TF_EXPECT_OK(AppendChecksumOnDevice(ThunkBufferId(), input, device_log,\n                                       se::ThreadDim(128, 4, 2)));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n@@ -193,14 +201,15 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallelWithMaxThreads) {\n \n TEST_F(ChecksumKernelTest, AppendsChecksumsToLog) {\n   se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(1024);\n-  SdcBufferId kId123 = SdcBufferId::Create(ThunkId(123), 0).value();\n-  SdcBufferId kId456 = SdcBufferId::Create(ThunkId(456), 0).value();\n-  SdcBufferId kId789 = SdcBufferId::Create(ThunkId(789), 0).value();\n+  ThunkBufferId kId123 = ThunkBufferId::Create(ThunkId(123), 0).value();\n+  ThunkBufferId kId456 = ThunkBufferId::Create(ThunkId(456), 0).value();\n+  ThunkBufferId kId789 = ThunkBufferId::Create(ThunkId(789), 0).value();\n   constexpr std::array<uint32_t, 1> kInput123 = {0x01230123};\n   constexpr std::array<uint32_t, 1> kInput456 = {0x04560456};\n   constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n-  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n-                          se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      se::cuda::BufferDebugLog device_log,\n+      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(kId123, kInput123, device_log));\n   TF_EXPECT_OK(AppendChecksumOnDevice(kId456, kInput456, device_log));\n@@ -218,15 +227,16 @@ TEST_F(ChecksumKernelTest, AppendsChecksumsToLog) {\n \n TEST_F(ChecksumKernelTest, DiscardsOverflowingChecksums) {\n   se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(\n-      sizeof(SdcLogHeader) + sizeof(SdcLogEntry) * 2);\n-  SdcBufferId kId123 = SdcBufferId::Create(ThunkId(123), 0).value();\n-  SdcBufferId kId456 = SdcBufferId::Create(ThunkId(456), 0).value();\n-  SdcBufferId kId789 = SdcBufferId::Create(ThunkId(789), 0).value();\n+      sizeof(BufferDebugLogHeader) + sizeof(BufferDebugLogEntry) * 2);\n+  ThunkBufferId kId123 = ThunkBufferId::Create(ThunkId(123), 0).value();\n+  ThunkBufferId kId456 = ThunkBufferId::Create(ThunkId(456), 0).value();\n+  ThunkBufferId kId789 = ThunkBufferId::Create(ThunkId(789), 0).value();\n   constexpr std::array<uint32_t, 1> kInput123 = {0x01230123};\n   constexpr std::array<uint32_t, 1> kInput456 = {0x04560456};\n   constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n-  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n-                          se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      se::cuda::BufferDebugLog device_log,\n+      se::cuda::BufferDebugLog::CreateOnDevice(*stream_, mem));\n \n   TF_EXPECT_OK(AppendChecksumOnDevice(kId123, kInput123, device_log));\n   TF_EXPECT_OK(AppendChecksumOnDevice(kId456, kInput456, device_log));",
            "previous_filename": "third_party/xla/xla/stream_executor/cuda/sdc_xor_checksum_kernel_cuda_test.cc"
        },
        {
            "sha": "75de21c7cb5ec5f13e0a0cd98263ba38ee0764c6",
            "filename": "third_party/xla/xla/stream_executor/cuda/sdc_log.h",
            "status": "removed",
            "additions": 0,
            "deletions": 112,
            "changes": 112,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/deac36865fcc2e11e7eb96bf3f90fa9a30c475d7/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/deac36865fcc2e11e7eb96bf3f90fa9a30c475d7/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log.h?ref=deac36865fcc2e11e7eb96bf3f90fa9a30c475d7",
            "patch": "@@ -1,112 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_STREAM_EXECUTOR_CUDA_SDC_LOG_H_\n-#define XLA_STREAM_EXECUTOR_CUDA_SDC_LOG_H_\n-\n-#include <cstddef>\n-#include <cstdint>\n-#include <vector>\n-\n-#include \"absl/status/statusor.h\"\n-#include \"xla/backends/gpu/runtime/sdc.pb.h\"\n-#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/stream.h\"\n-\n-namespace stream_executor::cuda {\n-\n-// A device memory buffer that holds a SdcLogHeader and a variable number of\n-// SdcLogEntry structs.\n-class SdcLog {\n- public:\n-  // Returns the number of bytes required to store a log with `entries`\n-  // entries.\n-  static constexpr size_t RequiredSizeForEntries(size_t entries) {\n-    return sizeof(xla::gpu::SdcLogHeader) +\n-           sizeof(xla::gpu::SdcLogEntry) * entries;\n-  }\n-\n-  // Initializes an empty `SdcLog` using a `log_buffer` allocated in device\n-  // memory.\n-  //\n-  // `log_buffer` must be allocated in memory of the same device `stream` is\n-  // associated with. `log_buffer` must outlive the returned `SdcLog`.\n-  //\n-  // Contents of the log can be retrieved with `SdcLog::ReadFromDevice`.\n-  //\n-  // Fails with `absl::StatusCode::kInvalidArgument` if `log_buffer` is too\n-  // small to hold any entries.\n-  static absl::StatusOr<SdcLog> CreateOnDevice(\n-      Stream& stream, DeviceMemory<uint8_t> log_buffer);\n-\n-  // Creates a `SdcLog` from an already initialized device memory buffer.\n-  //\n-  // `log_buffer` must contain an initialized `SdcLogHeader`.\n-  static SdcLog FromDeviceMemoryUnchecked(DeviceMemory<uint8_t> log_buffer) {\n-    return SdcLog(log_buffer);\n-  }\n-\n-  // Reads the header from the device log.\n-  //\n-  // `stream` must be associated with the same device as the one used to create\n-  // the log.\n-  absl::StatusOr<xla::gpu::SdcLogHeader> ReadHeaderFromDevice(\n-      Stream& stream) const;\n-\n-  // Reads all entries from the device log into host memory.\n-  //\n-  // Returned vector contains all initialized entries. If the log overflowed,\n-  // excess elements are silently discarded.\n-  //\n-  // `stream` must be associated with the same device as the one used to create\n-  // the log.\n-  absl::StatusOr<std::vector<xla::gpu::SdcLogEntry>> ReadFromDevice(\n-      Stream& stream) const;\n-\n-  // Reads all entries from the device log into a proto dump.\n-  //\n-  // `stream` must be associated with the same device as the one used to create\n-  // the log.\n-  absl::StatusOr<xla::gpu::SdcLogProto> ReadProto(Stream& stream) const;\n-\n-  // Returns a view of the `SdcLogHeader`.\n-  //\n-  // The returned `DeviceMemory` gets invalidated when the `SdcLog` is\n-  // destroyed.\n-  DeviceMemory<xla::gpu::SdcLogHeader> GetDeviceHeader() const {\n-    return DeviceMemory<xla::gpu::SdcLogHeader>(\n-        memory_.GetByteSlice(0, sizeof(xla::gpu::SdcLogHeader)));\n-  }\n-\n-  // Returns a view of the `SdcLogEntry` array.\n-  //\n-  // The returned `DeviceMemory` gets invalidated when the `SdcLog` is\n-  // destroyed.\n-  DeviceMemory<xla::gpu::SdcLogEntry> GetDeviceEntries() const {\n-    return DeviceMemory<xla::gpu::SdcLogEntry>(\n-        memory_.GetByteSlice(sizeof(xla::gpu::SdcLogHeader),\n-                             memory_.size() - sizeof(xla::gpu::SdcLogHeader)));\n-  }\n-\n- private:\n-  explicit SdcLog(DeviceMemory<uint8_t> memory) : memory_(memory) {}\n-\n-  DeviceMemory<uint8_t> memory_;\n-};\n-\n-}  // namespace stream_executor::cuda\n-\n-#endif  // XLA_STREAM_EXECUTOR_CUDA_SDC_LOG_H_"
        },
        {
            "sha": "655e157687a4b79805c31c81206faac364c4b15c",
            "filename": "third_party/xla/xla/stream_executor/gpu/BUILD",
            "status": "modified",
            "additions": 47,
            "deletions": 4,
            "changes": 51,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -943,11 +943,54 @@ xla_cc_test(\n )\n \n cc_library(\n-    name = \"sdc_xor_checksum_kernel\",\n-    hdrs = [\"sdc_xor_checksum_kernel.h\"],\n+    name = \"buffer_debug_log\",\n+    srcs = [\"buffer_debug_log.cc\"],\n+    hdrs = [\"buffer_debug_log.h\"],\n     deps = [\n-        \"//xla/backends/gpu/runtime:sdc_buffer_id\",\n-        \"//xla/backends/gpu/runtime:sdc_log_structs\",\n+        \"//xla/backends/gpu/runtime:buffer_debug_log_proto_cc\",\n+        \"//xla/backends/gpu/runtime:buffer_debug_log_structs\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:device_memory_allocator\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+    ],\n+)\n+\n+xla_test(\n+    name = \"buffer_debug_log_test\",\n+    srcs = [\"buffer_debug_log_test.cc\"],\n+    backends = [\"gpu\"],\n+    deps = [\n+        \":buffer_debug_log\",\n+        \"//xla/backends/gpu/runtime:buffer_debug_log_structs\",\n+        \"//xla/backends/gpu/runtime:thunk_buffer_id\",\n+        \"//xla/backends/gpu/runtime:thunk_id\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:platform\",\n+        \"//xla/stream_executor:platform_manager\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor:stream_executor_memory_allocator\",\n+        \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"buffer_debug_xor_checksum_kernel\",\n+    hdrs = [\"buffer_debug_xor_checksum_kernel.h\"],\n+    deps = [\n+        \"//xla/backends/gpu/runtime:buffer_debug_log_structs\",\n+        \"//xla/backends/gpu/runtime:thunk_buffer_id\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:kernel\",\n     ],"
        },
        {
            "sha": "ccf4a5f2b1552d89f939a6d0cc0d2972d907762e",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log.cc",
            "status": "renamed",
            "additions": 27,
            "deletions": 23,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -13,7 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include \"xla/stream_executor/cuda/sdc_log.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_log.h\"\n \n #include <algorithm>\n #include <cstdint>\n@@ -24,7 +24,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_format.h\"\n-#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n@@ -33,17 +33,17 @@ limitations under the License.\n \n namespace stream_executor::cuda {\n \n-using ::xla::gpu::SdcLogEntry;\n-using ::xla::gpu::SdcLogHeader;\n+using ::xla::gpu::BufferDebugLogEntry;\n+using ::xla::gpu::BufferDebugLogHeader;\n \n-absl::StatusOr<SdcLog> SdcLog::CreateOnDevice(\n+absl::StatusOr<BufferDebugLog> BufferDebugLog::CreateOnDevice(\n     Stream& stream, DeviceMemory<uint8_t> log_buffer) {\n   if (log_buffer.is_null()) {\n     return absl::InvalidArgumentError(\"Log buffer must be non-null\");\n   }\n \n   static constexpr size_t kMinBufferSize =\n-      sizeof(SdcLogHeader) + sizeof(SdcLogEntry);\n+      sizeof(BufferDebugLogHeader) + sizeof(BufferDebugLogEntry);\n   if (log_buffer.size() < kMinBufferSize) {\n     return absl::InvalidArgumentError(\n         absl::StrFormat(\"Log buffer size %u is too small to hold any log \"\n@@ -52,57 +52,61 @@ absl::StatusOr<SdcLog> SdcLog::CreateOnDevice(\n   }\n \n   const uint32_t max_entries =\n-      (log_buffer.size() - sizeof(SdcLogHeader)) / sizeof(SdcLogEntry);\n-  const SdcLogHeader empty_header{\n+      (log_buffer.size() - sizeof(BufferDebugLogHeader)) /\n+      sizeof(BufferDebugLogEntry);\n+  const BufferDebugLogHeader empty_header{\n       /*write_idx=*/0,\n       /*capacity=*/max_entries,\n   };\n   TF_RETURN_IF_ERROR(\n       stream.Memcpy(&log_buffer, &empty_header, sizeof(empty_header)));\n-  return SdcLog(log_buffer);\n+  return BufferDebugLog(log_buffer);\n }\n \n-absl::StatusOr<SdcLogHeader> SdcLog::ReadHeaderFromDevice(\n+absl::StatusOr<BufferDebugLogHeader> BufferDebugLog::ReadHeaderFromDevice(\n     Stream& stream) const {\n-  SdcLogHeader header;\n+  BufferDebugLogHeader header;\n   TF_RETURN_IF_ERROR(stream.Memcpy(&header, memory_, sizeof(header)));\n   TF_RETURN_IF_ERROR(stream.BlockHostUntilDone());\n   return header;\n }\n \n-absl::StatusOr<std::vector<SdcLogEntry>> SdcLog::ReadFromDevice(\n+absl::StatusOr<std::vector<BufferDebugLogEntry>> BufferDebugLog::ReadFromDevice(\n     Stream& stream) const {\n   std::vector<uint8_t> buffer(memory_.size());\n   TF_RETURN_IF_ERROR(stream.Memcpy(buffer.data(), memory_, memory_.size()));\n   TF_RETURN_IF_ERROR(stream.BlockHostUntilDone());\n \n-  SdcLogHeader header;\n+  BufferDebugLogHeader header;\n   memcpy(&header, buffer.data(), sizeof(header));\n \n-  const uint32_t max_entries =\n-      (memory_.size() - sizeof(SdcLogHeader)) / sizeof(SdcLogEntry);\n+  const uint32_t max_entries = (memory_.size() - sizeof(BufferDebugLogHeader)) /\n+                               sizeof(BufferDebugLogEntry);\n   const size_t initialized_entries =\n       std::min(max_entries, std::min(header.capacity, header.write_idx));\n-  std::vector<SdcLogEntry> entries(initialized_entries);\n+  std::vector<BufferDebugLogEntry> entries(initialized_entries);\n   memcpy(entries.data(), buffer.data() + sizeof(header),\n-         initialized_entries * sizeof(SdcLogEntry));\n+         initialized_entries * sizeof(BufferDebugLogEntry));\n \n   return entries;\n }\n \n-absl::StatusOr<xla::gpu::SdcLogProto> SdcLog::ReadProto(Stream& stream) const {\n-  TF_ASSIGN_OR_RETURN(std::vector<SdcLogEntry> entries, ReadFromDevice(stream));\n+absl::StatusOr<xla::gpu::BufferDebugLogProto> BufferDebugLog::ReadProto(\n+    Stream& stream) const {\n+  TF_ASSIGN_OR_RETURN(std::vector<BufferDebugLogEntry> entries,\n+                      ReadFromDevice(stream));\n \n-  xla::gpu::SdcLogProto sdc_log_proto;\n-  sdc_log_proto.mutable_entries()->Reserve(entries.size());\n+  xla::gpu::BufferDebugLogProto buffer_debug_log_proto;\n+  buffer_debug_log_proto.mutable_entries()->Reserve(entries.size());\n   for (const auto& entry : entries) {\n-    xla::gpu::SdcLogEntryProto* entry_proto = sdc_log_proto.add_entries();\n+    xla::gpu::BufferDebugLogEntryProto* entry_proto =\n+        buffer_debug_log_proto.add_entries();\n     entry_proto->set_thunk_id(entry.entry_id.thunk_id().value());\n     entry_proto->set_buffer_idx(entry.entry_id.buffer_idx());\n     entry_proto->set_checksum(entry.checksum);\n   }\n \n-  return sdc_log_proto;\n+  return buffer_debug_log_proto;\n }\n \n }  // namespace stream_executor::cuda",
            "previous_filename": "third_party/xla/xla/stream_executor/cuda/sdc_log.cc"
        },
        {
            "sha": "5024ede81416c43376e71114bb75b5c26aa7f31c",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log.h",
            "status": "added",
            "additions": 117,
            "deletions": 0,
            "changes": 117,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -0,0 +1,117 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_STREAM_EXECUTOR_GPU_BUFFER_DEBUG_LOG_H_\n+#define XLA_STREAM_EXECUTOR_GPU_BUFFER_DEBUG_LOG_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"absl/status/statusor.h\"\n+#include \"xla/backends/gpu/runtime/buffer_debug_log.pb.h\"\n+#include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/stream.h\"\n+\n+namespace stream_executor::cuda {\n+\n+// A wrapper over a device memory buffer used to store debug info about contents\n+// of buffers (e.g. checksums).\n+//\n+// It holds a BufferDebugLogHeader and a variable number of BufferDebugLogEntry\n+// structs.\n+class BufferDebugLog {\n+ public:\n+  // Returns the number of bytes required to store a log with `entries`\n+  // entries.\n+  static constexpr size_t RequiredSizeForEntries(size_t entries) {\n+    return sizeof(xla::gpu::BufferDebugLogHeader) +\n+           sizeof(xla::gpu::BufferDebugLogEntry) * entries;\n+  }\n+\n+  // Initializes an empty `BufferDebugLog` using a `log_buffer` allocated in\n+  // device memory.\n+  //\n+  // `log_buffer` must be allocated in memory of the same device `stream` is\n+  // associated with. `log_buffer` must outlive the returned `BufferDebugLog`.\n+  //\n+  // Contents of the log can be retrieved with `BufferDebugLog::ReadFromDevice`.\n+  //\n+  // Fails with `absl::StatusCode::kInvalidArgument` if `log_buffer` is too\n+  // small to hold any entries.\n+  static absl::StatusOr<BufferDebugLog> CreateOnDevice(\n+      Stream& stream, DeviceMemory<uint8_t> log_buffer);\n+\n+  // Creates a `BufferDebugLog` from an already initialized device memory\n+  // buffer.\n+  //\n+  // `log_buffer` must contain an initialized `BufferDebugLogHeader`.\n+  static BufferDebugLog FromDeviceMemoryUnchecked(\n+      DeviceMemory<uint8_t> log_buffer) {\n+    return BufferDebugLog(log_buffer);\n+  }\n+\n+  // Reads the header from the device log.\n+  //\n+  // `stream` must be associated with the same device as the one used to create\n+  // the log.\n+  absl::StatusOr<xla::gpu::BufferDebugLogHeader> ReadHeaderFromDevice(\n+      Stream& stream) const;\n+\n+  // Reads all entries from the device log into host memory.\n+  //\n+  // Returned vector contains all initialized entries. If the log overflowed,\n+  // excess elements are silently discarded.\n+  //\n+  // `stream` must be associated with the same device as the one used to create\n+  // the log.\n+  absl::StatusOr<std::vector<xla::gpu::BufferDebugLogEntry>> ReadFromDevice(\n+      Stream& stream) const;\n+\n+  // Reads all entries from the device log into a proto dump.\n+  //\n+  // `stream` must be associated with the same device as the one used to create\n+  // the log.\n+  absl::StatusOr<xla::gpu::BufferDebugLogProto> ReadProto(Stream& stream) const;\n+\n+  // Returns a view of the `BufferDebugLogHeader`.\n+  //\n+  // The returned `DeviceMemory` gets invalidated when the `BufferDebugLog` is\n+  // destroyed.\n+  DeviceMemory<xla::gpu::BufferDebugLogHeader> GetDeviceHeader() const {\n+    return DeviceMemory<xla::gpu::BufferDebugLogHeader>(\n+        memory_.GetByteSlice(0, sizeof(xla::gpu::BufferDebugLogHeader)));\n+  }\n+\n+  // Returns a view of the `BufferDebugLogEntry` array.\n+  //\n+  // The returned `DeviceMemory` gets invalidated when the `BufferDebugLog` is\n+  // destroyed.\n+  DeviceMemory<xla::gpu::BufferDebugLogEntry> GetDeviceEntries() const {\n+    return DeviceMemory<xla::gpu::BufferDebugLogEntry>(memory_.GetByteSlice(\n+        sizeof(xla::gpu::BufferDebugLogHeader),\n+        memory_.size() - sizeof(xla::gpu::BufferDebugLogHeader)));\n+  }\n+\n+ private:\n+  explicit BufferDebugLog(DeviceMemory<uint8_t> memory) : memory_(memory) {}\n+\n+  DeviceMemory<uint8_t> memory_;\n+};\n+\n+}  // namespace stream_executor::cuda\n+\n+#endif  // XLA_STREAM_EXECUTOR_GPU_BUFFER_DEBUG_LOG_H_"
        },
        {
            "sha": "c80215de2a308da971481a072d4b99cf12bcd85d",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log_test.cc",
            "status": "renamed",
            "additions": 41,
            "deletions": 37,
            "changes": 78,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -13,7 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include \"xla/stream_executor/cuda/sdc_log.h\"\n+#include \"xla/stream_executor/gpu/buffer_debug_log.h\"\n \n #include <cstddef>\n #include <cstdint>\n@@ -27,8 +27,8 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/status_matchers.h\"\n #include \"absl/types/span.h\"\n-#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n-#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/platform.h\"\n@@ -44,13 +44,13 @@ namespace stream_executor::cuda {\n namespace {\n \n using ::tsl::proto_testing::EqualsProto;\n-using ::xla::gpu::SdcBufferId;\n-using ::xla::gpu::SdcLogEntry;\n-using ::xla::gpu::SdcLogHeader;\n-using ::xla::gpu::SdcLogProto;\n+using ::xla::gpu::BufferDebugLogEntry;\n+using ::xla::gpu::BufferDebugLogHeader;\n+using ::xla::gpu::BufferDebugLogProto;\n+using ::xla::gpu::ThunkBufferId;\n using ::xla::gpu::ThunkId;\n \n-class SdcLogTest : public ::testing::Test {\n+class BufferDebugLogTest : public ::testing::Test {\n  protected:\n   void SetUp() override {\n     TF_ASSERT_OK_AND_ASSIGN(platform_,\n@@ -67,66 +67,69 @@ class SdcLogTest : public ::testing::Test {\n   std::unique_ptr<StreamExecutorMemoryAllocator> allocator_;\n };\n \n-TEST_F(SdcLogTest, CreateSdcLogOnDevice_InitializesEmptyLog) {\n+TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_InitializesEmptyLog) {\n   DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(1024);\n \n-  TF_ASSERT_OK_AND_ASSIGN(SdcLog device_log,\n-                          SdcLog::CreateOnDevice(*stream_, log_buffer));\n+  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n+                          BufferDebugLog::CreateOnDevice(*stream_, log_buffer));\n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n \n   EXPECT_EQ(host_log.size(), 0);\n }\n \n-TEST_F(SdcLogTest, CreateSdcLogOnDevice_InitializesLogWithCorrectCapacity) {\n+TEST_F(BufferDebugLogTest,\n+       CreateBufferDebugLogOnDevice_InitializesLogWithCorrectCapacity) {\n   constexpr size_t kMaxEntries = 10;\n-  constexpr size_t kExpectedHeaderSize = sizeof(SdcLogHeader);\n-  constexpr size_t kExpectedEntriesSize = sizeof(SdcLogEntry) * kMaxEntries;\n+  constexpr size_t kExpectedHeaderSize = sizeof(BufferDebugLogHeader);\n+  constexpr size_t kExpectedEntriesSize =\n+      sizeof(BufferDebugLogEntry) * kMaxEntries;\n   DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n       kExpectedHeaderSize + kExpectedEntriesSize);\n \n-  TF_ASSERT_OK_AND_ASSIGN(SdcLog device_log,\n-                          SdcLog::CreateOnDevice(*stream_, log_buffer));\n+  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n+                          BufferDebugLog::CreateOnDevice(*stream_, log_buffer));\n \n   EXPECT_EQ(device_log.GetDeviceHeader().size(), kExpectedHeaderSize);\n   EXPECT_EQ(device_log.GetDeviceEntries().size(), kExpectedEntriesSize);\n }\n \n-TEST_F(SdcLogTest, CreateSdcLogOnDevice_InitializesHeader) {\n+TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_InitializesHeader) {\n   constexpr size_t kMaxEntries = 123;\n   DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n-      SdcLog::RequiredSizeForEntries(kMaxEntries));\n+      BufferDebugLog::RequiredSizeForEntries(kMaxEntries));\n \n-  TF_ASSERT_OK_AND_ASSIGN(SdcLog device_log,\n-                          SdcLog::CreateOnDevice(*stream_, log_buffer));\n-  TF_ASSERT_OK_AND_ASSIGN(SdcLogHeader header,\n+  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n+                          BufferDebugLog::CreateOnDevice(*stream_, log_buffer));\n+  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLogHeader header,\n                           device_log.ReadHeaderFromDevice(*stream_));\n \n   EXPECT_EQ(header.write_idx, 0);\n   EXPECT_EQ(header.capacity, kMaxEntries);\n }\n \n-TEST_F(SdcLogTest, CreateSdcLogOnDevice_FailsForNullBuffer) {\n-  EXPECT_THAT(SdcLog::CreateOnDevice(*stream_, DeviceMemory<uint8_t>()),\n+TEST_F(BufferDebugLogTest, CreateBufferDebugLogOnDevice_FailsForNullBuffer) {\n+  EXPECT_THAT(BufferDebugLog::CreateOnDevice(*stream_, DeviceMemory<uint8_t>()),\n               absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n-TEST_F(SdcLogTest, CreateSdcLogOnDevice_FailsForTooSmallBuffer) {\n-  DeviceMemory<uint8_t> log_buffer =\n-      executor_->AllocateArray<uint8_t>(SdcLog::RequiredSizeForEntries(1) - 1);\n+TEST_F(BufferDebugLogTest,\n+       CreateBufferDebugLogOnDevice_FailsForTooSmallBuffer) {\n+  DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n+      BufferDebugLog::RequiredSizeForEntries(1) - 1);\n \n-  EXPECT_THAT(SdcLog::CreateOnDevice(*stream_, log_buffer),\n+  EXPECT_THAT(BufferDebugLog::CreateOnDevice(*stream_, log_buffer),\n               absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n-TEST_F(SdcLogTest, ReadAsProto) {\n-  DeviceMemory<uint8_t> log_buffer =\n-      executor_->AllocateArray<uint8_t>(SdcLog::RequiredSizeForEntries(10));\n-  const SdcLogHeader header = {/*write_idx=*/2,\n-                               /*capacity=*/10};\n-  const SdcLogEntry entries[] = {\n-      {/*entry_id=*/SdcBufferId::Create(ThunkId(123), 4).value(),\n+TEST_F(BufferDebugLogTest, ReadAsProto) {\n+  DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n+      BufferDebugLog::RequiredSizeForEntries(10));\n+  const BufferDebugLogHeader header = {/*write_idx=*/2,\n+                                       /*capacity=*/10};\n+  const BufferDebugLogEntry entries[] = {\n+      {/*entry_id=*/ThunkBufferId::Create(ThunkId(123), 4).value(),\n        /*checksum=*/12341234},\n-      {/*entry_id=*/SdcBufferId::Create(ThunkId(567), 8).value(),\n+      {/*entry_id=*/ThunkBufferId::Create(ThunkId(567), 8).value(),\n        /*checksum=*/56785678},\n   };\n   std::vector<uint8_t> log_data(sizeof(header) + sizeof(entries));\n@@ -135,8 +138,9 @@ TEST_F(SdcLogTest, ReadAsProto) {\n   TF_ASSERT_OK(stream_->MemcpyH2D(absl::MakeConstSpan(log_data), &log_buffer));\n   TF_ASSERT_OK(stream_->BlockHostUntilDone());\n \n-  SdcLog device_log = SdcLog::FromDeviceMemoryUnchecked(log_buffer);\n-  TF_ASSERT_OK_AND_ASSIGN(SdcLogProto log_proto,\n+  BufferDebugLog device_log =\n+      BufferDebugLog::FromDeviceMemoryUnchecked(log_buffer);\n+  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLogProto log_proto,\n                           device_log.ReadProto(*stream_));\n \n   EXPECT_THAT(log_proto, EqualsProto(R\"pb(",
            "previous_filename": "third_party/xla/xla/stream_executor/cuda/sdc_log_test.cc"
        },
        {
            "sha": "c9c7656faf162de31a72e4e4a3a1057a544c8920",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_xor_checksum_kernel.h",
            "status": "renamed",
            "additions": 11,
            "deletions": 10,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_xor_checksum_kernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/373e68f60c1616f255af1a638dfc7ad6c4d990b4/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_xor_checksum_kernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_xor_checksum_kernel.h?ref=373e68f60c1616f255af1a638dfc7ad6c4d990b4",
            "patch": "@@ -13,28 +13,29 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#ifndef XLA_STREAM_EXECUTOR_GPU_SDC_XOR_CHECKSUM_KERNEL_H_\n-#define XLA_STREAM_EXECUTOR_GPU_SDC_XOR_CHECKSUM_KERNEL_H_\n+#ifndef XLA_STREAM_EXECUTOR_GPU_BUFFER_DEBUG_XOR_CHECKSUM_KERNEL_H_\n+#define XLA_STREAM_EXECUTOR_GPU_BUFFER_DEBUG_XOR_CHECKSUM_KERNEL_H_\n \n #include <cstdint>\n \n-#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n-#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/kernel.h\"\n \n namespace stream_executor::gpu {\n \n // Trait for a kernel that computes the checksum of given input buffer and\n-// appends it to the SDC log.\n+// appends it to the buffer debug log.\n //\n // This kernel MUST execute on a single thread block.\n-struct SdcXorChecksumKernel {\n-  using KernelType = TypedKernel<xla::gpu::SdcBufferId, DeviceMemory<uint8_t>,\n-                                 uint64_t, DeviceMemory<xla::gpu::SdcLogHeader>,\n-                                 DeviceMemory<xla::gpu::SdcLogEntry>>;\n+struct BufferDebugXorChecksumKernel {\n+  using KernelType =\n+      TypedKernel<xla::gpu::ThunkBufferId, DeviceMemory<uint8_t>, uint64_t,\n+                  DeviceMemory<xla::gpu::BufferDebugLogHeader>,\n+                  DeviceMemory<xla::gpu::BufferDebugLogEntry>>;\n };\n \n }  // namespace stream_executor::gpu\n \n-#endif  // XLA_STREAM_EXECUTOR_GPU_SDC_XOR_CHECKSUM_KERNEL_H_\n+#endif  // XLA_STREAM_EXECUTOR_GPU_BUFFER_DEBUG_XOR_CHECKSUM_KERNEL_H_",
            "previous_filename": "third_party/xla/xla/stream_executor/gpu/sdc_xor_checksum_kernel.h"
        }
    ],
    "stats": {
        "total": 1075,
        "additions": 559,
        "deletions": 516
    }
}