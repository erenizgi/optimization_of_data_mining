{
    "author": "metaflow",
    "message": "[XLA:GPU] add triton-xla-unswitch-loops pass\n\nunlike codegen/emitters/transforms/unswitch_loops.cc, this pass also rewrites when there are other ops present in\nthe loop. To prevent potential code bloat it does nothing if there are multiple conditions present.\n\nThe goal of the pass is to remove a conditional introduced by concat op out of the loop as it causes significant regressions.\n\nPiperOrigin-RevId: 810761031",
    "sha": "4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8",
    "files": [
        {
            "sha": "8ea7198264d644011e68cd8e381ca32cf23acb10",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/BUILD",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD?ref=4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8",
            "patch": "@@ -139,6 +139,7 @@ cc_library(\n         \"//xla/backends/gpu/codegen/emitters/transforms:passes\",\n         \"//xla/backends/gpu/codegen/triton/transforms:passes\",\n         \"//xla/codegen/emitters/transforms:convert_pure_call_ops_pass\",\n+        \"//xla/codegen/emitters/transforms:passes\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service/gpu:matmul_utils\",\n         \"//xla/stream_executor:device_description\",\n@@ -174,6 +175,20 @@ cc_library(\n     ],\n )\n \n+xla_cc_test(\n+    name = \"compilation_pipeline_test\",\n+    srcs = [\"compilation_pipeline_test.cc\"],\n+    tags = [\"gpu\"],\n+    deps = [\n+        \":compilation_pipeline\",\n+        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_googletest//:gtest_main\",\n+        \"@llvm-project//mlir:IR\",\n+        \"@llvm-project//mlir:Pass\",\n+    ],\n+)\n+\n cc_library(\n     name = \"fusion_emitter\",\n     # Using if_cuda_or_rocm_is_configured guard to prevent sycl target build / link errors."
        },
        {
            "sha": "ad1ecdc0c4cf6951406912d778169bd4c8fddce1",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/compilation_pipeline.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline.cc?ref=4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8",
            "patch": "@@ -19,6 +19,7 @@ limitations under the License.\n \n #include \"mlir/Conversion/AffineToStandard/AffineToStandard.h\"\n #include \"mlir/Pass/PassManager.h\"\n+#include \"mlir/Transforms/Passes.h\"\n #include \"xla/backends/gpu/codegen/emitters/transforms/passes.h\"\n #include \"xla/backends/gpu/codegen/triton/transforms/passes.h\"\n #include \"xla/codegen/emitters/transforms/passes.h\"\n@@ -56,6 +57,10 @@ void CreateTritonXlaPipeline(\n   // Lower xla_gpu.apply_indexing into arithmetic ops.\n   pm->addPass(emitters::CreateSimplifyAffinePass());\n   pm->addPass(CreateConvertIndexTypePass());\n+  // We need LICM before unswitching loops because loop unswitcher relies on\n+  // having loop invariant code to be outside of the loop.\n+  pm->addPass(mlir::createLoopInvariantCodeMotionPass());\n+  pm->addPass(mlir::triton::xla::CreateTritonXLAUnswitchLoopsPass());\n }\n \n void CreateTritonCudaPipeline("
        },
        {
            "sha": "f5b04bbe916a298991cd2acac91ec24af9831f6b",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/compilation_pipeline_test.cc",
            "status": "added",
            "additions": 67,
            "deletions": 0,
            "changes": 67,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fcompilation_pipeline_test.cc?ref=4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8",
            "patch": "@@ -0,0 +1,67 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/codegen/triton/compilation_pipeline.h\"\n+\n+#include <algorithm>\n+#include <iterator>\n+#include <string>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/strings/str_join.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/Pass/PassManager.h\"\n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+using ::testing::Contains;\n+\n+TEST(CompilationPipelineTest, UnswitchLoopsAfterLICM) {\n+  // As the loop unswitcher relies on loop invariant code to be outside of the\n+  // loop, we need to check that LICM runs before the loop unswitcher.\n+  mlir::MLIRContext ctx;\n+  mlir::PassManager pm(&ctx);\n+\n+  CreateTritonXlaPipeline(&pm, stream_executor::CudaComputeCapability(),\n+                          /*rewrite_int4=*/false, /*allow_tma=*/true,\n+                          /*convert_unsupported_types=*/true);\n+\n+  std::vector<std::string> pass_names;\n+  for (const mlir::Pass& pass : pm.getPasses()) {\n+    pass_names.push_back(pass.getName().str());\n+  }\n+  ASSERT_THAT(pass_names, Contains(\"LoopInvariantCodeMotion\"));\n+  ASSERT_THAT(pass_names, Contains(\"TritonXLAUnswitchLoopsPass\"));\n+  int licm_index = std::distance(pass_names.begin(),\n+                                 std::find(pass_names.begin(), pass_names.end(),\n+                                           \"LoopInvariantCodeMotion\"));\n+  int unswitch_index = std::distance(\n+      pass_names.begin(), std::find(pass_names.begin(), pass_names.end(),\n+                                    \"TritonXLAUnswitchLoopsPass\"));\n+  // There is no hard requirement to run LICM **immediately** before the loop\n+  // unswitcher but you should consider if the newly added pass might interact\n+  // with the loop unswitcher.\n+  EXPECT_EQ(unswitch_index, licm_index + 1)\n+      << \"TritonXLAUnswitchLoopsPass is expected to run right after \"\n+         \"LoopInvariantCodeMotionPass. Got passes: \"\n+      << absl::StrJoin(pass_names, \", \");\n+}\n+\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "e30a37e1582d76126c75ebe0f4ba7e88f1446787",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD?ref=4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8",
            "patch": "@@ -43,6 +43,7 @@ cc_library(\n         \"triton_xla_lower_get_tid_pass.cc\",\n         \"triton_xla_lower_remote_access_pass.cc\",\n         \"triton_xla_squeeze_dims_pass.cc\",\n+        \"triton_xla_unswitch_loops_pass.cc\",\n     ],\n     hdrs = [\"passes.h\"],\n     deps = [\n@@ -54,8 +55,6 @@ cc_library(\n         \"//xla/codegen:emitter_loc_op_builder\",\n         \"//xla/codegen/emitters/ir:xla\",\n         \"//xla/service/llvm_ir:llvm_util\",\n-        \"//xla/stream_executor:device_description\",\n-        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/stream_executor/gpu:tma_metadata\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/log\",\n@@ -73,6 +72,7 @@ cc_library(\n         \"@llvm-project//mlir:LLVMDialect\",\n         \"@llvm-project//mlir:NVVMDialect\",\n         \"@llvm-project//mlir:Pass\",\n+        \"@llvm-project//mlir:Rewrite\",\n         \"@llvm-project//mlir:SCFDialect\",\n         \"@llvm-project//mlir:SCFTransforms\",\n         \"@llvm-project//mlir:Support\","
        },
        {
            "sha": "0e1cff15d6592056791004e9ca94b75241564d55",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/passes.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h?ref=4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8",
            "patch": "@@ -39,6 +39,7 @@ std::unique_ptr<mlir::Pass> CreateInt4ToPackedInt4RewritePass(\n     bool enable_bf16x2);\n std::unique_ptr<mlir::Pass> CreateRoundF32ToTF32ForTf32DotRewritePass();\n std::unique_ptr<mlir::Pass> CreateExtractTmaInfoPass();\n+std::unique_ptr<mlir::Pass> CreateTritonXLAUnswitchLoopsPass();\n std::unique_ptr<mlir::Pass> CreateTritonXLALowerGetTidPass();\n std::unique_ptr<mlir::Pass> CreateTritonXLALowerAtomicsPass();\n std::unique_ptr<mlir::Pass> CreateTritonXLALowerBlockBarrierPass();"
        },
        {
            "sha": "5c28f666a037dbda1fa0d2845dc610f4f80d30b8",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/passes.td",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td?ref=4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8",
            "patch": "@@ -173,4 +173,21 @@ def TritonXLALowerRemoteAccessPass\n   let constructor = \"CreateTritonXLALowerRemoteAccessPass()\";\n }\n \n+def TritonXLAUnswitchLoopsPass :\n+   Pass<\"triton-xla-unswitch-loops\", \"mlir::ModuleOp\"> {\n+  let summary = \"Hoists scf.if out of scf.for.\";\n+\n+  let description = [{\n+      Hoists a single scf.if out of scf.for when the condition is loop invariant.\n+      That removes the conditional from the loop body but increases the code size.\n+      Pass expects to run after loop-invariant-code-motion.\n+  }];\n+\n+  let dependentDialects = [\n+    \"mlir::func::FuncDialect\", \"mlir::scf::SCFDialect\"\n+  ];\n+\n+  let constructor = \"CreateTritonXLAUnswitchLoopsPass()\";\n+}\n+\n #endif  // XLA_BACKENDS_GPU_CODEGEN_TRITON_PASSES_TD_"
        },
        {
            "sha": "5dd8e8d9824c0a722dd241e82d8a41e7c7b411fb",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_unswitch_loops.mlir",
            "status": "added",
            "additions": 255,
            "deletions": 0,
            "changes": 255,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_unswitch_loops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_unswitch_loops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_unswitch_loops.mlir?ref=4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8",
            "patch": "@@ -0,0 +1,255 @@\n+// RUN: xla-opt %s --triton-xla-unswitch-loops | FileCheck %s\n+\n+// CHECK-LABEL: func @single_if\n+func.func @single_if(%arg0: i32, %cond: i1) -> i32 {\n+    %c0 = arith.constant 0 : index\n+    %c1 = arith.constant 1 : index\n+    %c2 = arith.constant 2 : index\n+    %for = scf.for %i = %c0 to %c2 step %c1 iter_args(%iter = %arg0) -> i32 {\n+      %result = scf.if %cond -> i32 {\n+        %set_3 = arith.addi %iter, %arg0: i32\n+        scf.yield %set_3 : i32\n+      } else {\n+        %set_4 = arith.subi %iter, %arg0: i32\n+        scf.yield %set_4 : i32\n+      }\n+      scf.yield %result : i32\n+    }\n+    func.return %for : i32\n+    // CHECK: scf.if\n+    // CHECK: scf.for\n+    // CHECK: scf.for\n+}\n+\n+// CHECK-LABEL: func @for_if_for_if\n+func.func @for_if_for_if(%arg0: i32, %condA: i1, %condB: i1) -> i32 {\n+    %c0 = arith.constant 0 : index\n+    %c1 = arith.constant 1 : index\n+    %c2 = arith.constant 2 : index\n+    %cst10 = arith.constant 10 : i32\n+    %cst20 = arith.constant 20 : i32\n+    %cst30 = arith.constant 30 : i32\n+    %cst40 = arith.constant 40 : i32\n+\n+    %for1 = scf.for %i = %c0 to %c2 step %c1 iter_args(%iter1 = %arg0) -> i32 {\n+      %if1_res = scf.if %condA -> i32 {\n+        %add1 = arith.addi %iter1, %cst10 : i32\n+        scf.yield %add1 : i32\n+      } else {\n+        %sub1 = arith.subi %iter1, %cst20 : i32\n+        scf.yield %sub1 : i32\n+      }\n+\n+      %for2 = scf.for %j = %c0 to %c2 step %c1 iter_args(%iter2 = %if1_res) -> i32 {\n+        %if2_res = scf.if %condB -> i32 {\n+          %add2 = arith.addi %iter2, %cst30 : i32\n+          scf.yield %add2 : i32\n+        } else {\n+          %sub2 = arith.subi %iter2, %cst40 : i32\n+          scf.yield %sub2 : i32\n+        }\n+        scf.yield %if2_res : i32\n+      }\n+      scf.yield %for2 : i32\n+    }\n+    func.return %for1 : i32\n+    // CHECK: scf.if\n+    // CHECK: scf.for\n+    // CHECK: scf.if\n+    // CHECK: scf.for\n+}\n+\n+// CHECK-LABEL: func @iter_arg_in_if_cond_unmodified\n+func.func @iter_arg_in_if_cond_unmodified(%arg0: i32, %arg1: i32) -> i32 {\n+    %c0 = arith.constant 0 : index\n+    %c1 = arith.constant 1 : index\n+    %c2 = arith.constant 2 : index\n+    %cst3 = arith.constant 3 : i32\n+    %cst4 = arith.constant 4 : i32\n+    %for = scf.for %i = %c0 to %c2 step %c1 iter_args(%iter = %arg0) -> i32 {\n+      // The condition depends on the %iter, so we can't unswitch.\n+      %cond = arith.cmpi eq, %iter, %arg1 : i32\n+      %result = scf.if %cond -> i32 {\n+        %set_3 = arith.addi %iter, %cst3 : i32\n+        scf.yield %set_3 : i32\n+      } else {\n+        %set_4 = arith.subi %iter, %cst4 : i32\n+        scf.yield %set_4 : i32\n+      }\n+      scf.yield %result : i32\n+    }\n+    func.return %for : i32\n+    // CHECK: scf.for\n+    // CHECK-NEXT: arith.cmpi eq\n+    // CHECK-NEXT: scf.if\n+}\n+\n+// CHECK-LABEL: func @outer_loop_condition\n+func.func @outer_loop_condition(%arg0: i32) -> i32 {\n+    %c0 = arith.constant 0 : index\n+    %c1 = arith.constant 1 : index\n+    %c2 = arith.constant 2 : index\n+    %cst10 = arith.constant 10 : i32\n+    %cst20 = arith.constant 20 : i32\n+\n+    %outer = scf.for %i = %c0 to %c2 step %c1 iter_args(%iter_arg0 = %arg0) -> i32 {\n+      %cond = arith.cmpi eq, %i, %c1 : index\n+      %inner = scf.for %j = %c0 to %c2 step %c1 iter_args(%iter_arg1 = %iter_arg0) -> i32 {\n+        %if_res = scf.if %cond -> i32 {\n+          %added = arith.addi %iter_arg1, %cst10 : i32\n+          scf.yield %added : i32\n+        } else {\n+          %subbed = arith.subi %iter_arg1, %cst20 : i32\n+          scf.yield %subbed : i32\n+        }\n+        scf.yield %if_res : i32\n+      }\n+      scf.yield %inner : i32\n+    }\n+    func.return %outer : i32\n+    // CHECK: scf.for\n+    // CHECK-NEXT: arith.cmpi eq\n+    // CHECK-NEXT: scf.if\n+    // CHECK-NEXT: scf.for\n+    // CHECK: else\n+    // CHECK-NEXT: scf.for\n+}\n+\n+// CHECK-LABEL: func @ops_before_and_after_if\n+func.func @ops_before_and_after_if(%arg0: i32, %arg1: i32) -> i32 {\n+    %c0 = arith.constant 0 : index\n+    %c1 = arith.constant 1 : index\n+    %c2 = arith.constant 2 : index\n+    %cst4 = arith.constant 4 : i32\n+    %cst5 = arith.constant 5 : i32\n+    %cond = arith.cmpi sle, %arg1, %cst4 : i32\n+    %for = scf.for %i = %c0 to %c2 step %c1 iter_args(%iter = %arg0) -> i32 {\n+      %before_if = arith.addi %iter, %cst5 : i32\n+      %if_res = scf.if %cond -> i32 {\n+        %set_3 = arith.addi %before_if, %cst4 : i32\n+        scf.yield %set_3 : i32\n+      } else {\n+        %set_4 = arith.subi %before_if, %cst4 : i32\n+        scf.yield %set_4 : i32\n+      }\n+      %after_if = arith.addi %if_res, %if_res : i32\n+      scf.yield %after_if : i32\n+    }\n+    func.return %for : i32\n+    // CHECK: scf.if\n+    // CHECK: scf.for\n+    // CHECK-NEXT: arith.addi\n+    // CHECK: arith.addi\n+    // CHECK: arith.addi\n+    // CHECK: else\n+    // CHECK: scf.for\n+    // CHECK-NEXT: arith.addi\n+    // CHECK: arith.subi\n+    // CHECK: arith.addi\n+}\n+\n+// CHECK-LABEL: func @loop_var_in_if_cond_unmodified\n+func.func @loop_var_in_if_cond_unmodified(%arg0: i32) -> i32 {\n+    %c0 = arith.constant 0 : index\n+    %c1 = arith.constant 1 : index\n+    %c2 = arith.constant 2 : index\n+    %cst3 = arith.constant 3 : i32\n+    %cst4 = arith.constant 4 : i32\n+    %for = scf.for %i = %c0 to %c2 step %c1 iter_args(%iter = %arg0) -> i32 {\n+      %cond = arith.cmpi sle, %i, %c1 : index\n+      // We can't unswitch this loop because the induction variable is used in\n+      // the condition of the if.\n+      %result = scf.if %cond -> i32 {\n+        %set_3 = arith.addi %iter, %cst3 : i32\n+        scf.yield %set_3 : i32\n+      } else {\n+        %set_4 = arith.subi %iter, %cst4 : i32\n+        scf.yield %set_4 : i32\n+      }\n+      scf.yield %result : i32\n+    }\n+    func.return %for : i32\n+    // CHECK: scf.for\n+    // CHECK-NEXT: arith.cmpi sle\n+    // CHECK-NEXT: scf.if\n+}\n+\n+// CHECK-LABEL: func @nested_loops\n+func.func @nested_loops(%arg0: i32, %cond: i1) -> i32 {\n+    %c0 = arith.constant 0 : index\n+    %c1 = arith.constant 1 : index\n+    %c2 = arith.constant 2 : index\n+    %cst10 = arith.constant 10 : i32\n+    %cst20 = arith.constant 20 : i32\n+\n+    %outer = scf.for %i = %c0 to %c2 step %c1 iter_args(%iter_arg0 = %arg0) -> i32 {\n+      %inner = scf.for %j = %c0 to %c2 step %c1 iter_args(%iter_arg1 = %iter_arg0) -> i32 {\n+        %result = scf.if %cond -> i32 {\n+          %added = arith.addi %iter_arg1, %cst10 : i32\n+          scf.yield %added : i32\n+        } else {\n+          %subbed = arith.subi %iter_arg1, %cst20 : i32\n+          scf.yield %subbed : i32\n+        }\n+        scf.yield %result : i32\n+      }\n+      scf.yield %inner : i32\n+    }\n+    func.return %outer : i32\n+    // CHECK: scf.if\n+    // CHECK: scf.for\n+    // CHECK: scf.for\n+    // CHECK: else\n+    // CHECK: scf.for\n+    // CHECK: scf.for\n+}\n+\n+// CHECK-LABEL: func @for_if_for_if_for_if\n+// As we only unswitch if there are less than 3 nested loops, we expect that\n+// outermost loop will be kept.\n+func.func @for_if_for_if_for_if(%arg0: i32, %condA: i1, %condB: i1, %condC: i1) -> i32 {\n+    %c0 = arith.constant 0 : index\n+    %c1 = arith.constant 1 : index\n+    %c2 = arith.constant 2 : index\n+    %cst10 = arith.constant 10 : i32\n+    %cst20 = arith.constant 20 : i32\n+    %cst30 = arith.constant 30 : i32\n+    %cst40 = arith.constant 40 : i32\n+    %cst50 = arith.constant 50 : i32\n+    %cst60 = arith.constant 60 : i32\n+\n+    %for1 = scf.for %i = %c0 to %c2 step %c1 iter_args(%iter1 = %arg0) -> i32 {\n+      %if1_res = scf.if %condA -> i32 {\n+        %add1 = arith.addi %iter1, %cst10 : i32\n+        scf.yield %add1 : i32\n+      } else {\n+        %sub1 = arith.subi %iter1, %cst20 : i32\n+        scf.yield %sub1 : i32\n+      }\n+\n+      %for2 = scf.for %j = %c0 to %c2 step %c1 iter_args(%iter2 = %if1_res) -> i32 {\n+        %if2_res = scf.if %condB -> i32 {\n+          %add2 = arith.addi %iter2, %cst30 : i32\n+          scf.yield %add2 : i32\n+        } else {\n+          %sub2 = arith.subi %iter2, %cst40 : i32\n+          scf.yield %sub2 : i32\n+        }\n+\n+        %for3 = scf.for %k = %c0 to %c2 step %c1 iter_args(%iter3 = %if2_res) -> i32 {\n+          %if3_res = scf.if %condC -> i32 {\n+            %add3 = arith.addi %iter3, %cst50 : i32\n+            scf.yield %add3 : i32\n+          } else {\n+            %sub3 = arith.subi %iter3, %cst60 : i32\n+            scf.yield %sub3 : i32\n+          }\n+          scf.yield %if3_res : i32\n+        }\n+        scf.yield %for3 : i32\n+      }\n+      scf.yield %for2 : i32\n+    }\n+    func.return %for1 : i32\n+    // CHECK-COUNT-9: scf.for\n+}"
        },
        {
            "sha": "5f7f763a70853032088f48f5a6a9315238320308",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_unswitch_loops_pass.cc",
            "status": "added",
            "additions": 116,
            "deletions": 0,
            "changes": 116,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_unswitch_loops_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_unswitch_loops_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_unswitch_loops_pass.cc?ref=4482c6c8dfb2ce25c8ec44dff5b935cf1d8f4aa8",
            "patch": "@@ -0,0 +1,116 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+#include <memory>\n+#include <utility>\n+\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/Dialect/SCF/IR/SCF.h\"\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/IRMapping.h\"\n+#include \"mlir/IR/Matchers.h\"\n+#include \"mlir/IR/Operation.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Rewrite/FrozenRewritePatternSet.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Support/LogicalResult.h\"\n+#include \"mlir/Support/WalkResult.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"xla/backends/gpu/codegen/triton/transforms/passes.h\"\n+\n+namespace mlir::triton::xla {\n+\n+#define GEN_PASS_DEF_TRITONXLAUNSWITCHLOOPSPASS\n+#include \"xla/backends/gpu/codegen/triton/transforms/passes.h.inc\"\n+\n+namespace {\n+\n+LogicalResult UnswitchLoop(mlir::scf::ForOp for_op,\n+                           mlir::PatternRewriter& rewriter) {\n+  // Walk the body of the loop, including nested blocks, and count all scf::IfOp\n+  // instances.\n+  scf::IfOp if_op;\n+  int if_count = 0;\n+  int max_if_count = 2;\n+  for_op->walk([&](scf::IfOp op) -> WalkResult {\n+    if (matchPattern(op.getCondition(), m_Constant())) {\n+      // Do not match if with constant conditions - they are left from\n+      // our previous transformations and will be optimized away later.\n+      return WalkResult::advance();\n+    }\n+    if (!for_op.isDefinedOutsideOfLoop(op.getCondition())) {\n+      // Condition is not loop invariant.\n+      // We rely on loop-invariant-code-motion pass to run before and\n+      // hoist the condition out of the loop.\n+      return WalkResult::advance();\n+    }\n+    if_op = op;\n+    ++if_count;\n+    return failure(if_count > max_if_count);\n+  });\n+  if (if_count > max_if_count) {\n+    // We don't want to explode the code size too much by unswitching\n+    // multiple times. 2 is the current need for cases we have seen\n+    // for two concats used in dot. You might want to increase this\n+    // number. In this case it might make sense to make it a parameter\n+    // of the pass.\n+    return rewriter.notifyMatchFailure(\n+        for_op, \"more than 2 ifs are found inside the loop\");\n+  }\n+  if (!if_op) {\n+    return rewriter.notifyMatchFailure(for_op, \"no if found inside the loop\");\n+  }\n+\n+  scf::IfOp new_if = scf::IfOp::create(\n+      rewriter, for_op.getLoc(), for_op.getResultTypes(), if_op.getCondition(),\n+      /*addThenBlock=*/true, /*addElseBlock=*/true);\n+  for (int body_index : {0, 1}) {\n+    auto builder = OpBuilder::atBlockEnd(new_if.getBody(body_index),\n+                                         rewriter.getListener());\n+    arith::ConstantOp condition = builder.create<arith::ConstantOp>(\n+        for_op.getLoc(),\n+        rewriter.getIntegerAttr(rewriter.getI1Type(), body_index == 0));\n+    IRMapping mapping;\n+    mapping.map(if_op.getCondition(), condition);\n+    Operation* new_for = builder.clone(*for_op, mapping);\n+    builder.create<scf::YieldOp>(for_op.getLoc(), new_for->getResults());\n+  }\n+  rewriter.replaceOp(for_op, new_if);\n+  return success();\n+}\n+\n+class TritonXLAUnswitchLoopsPass\n+    : public impl::TritonXLAUnswitchLoopsPassBase<TritonXLAUnswitchLoopsPass> {\n+ public:\n+  void runOnOperation() override {\n+    mlir::RewritePatternSet patterns(&getContext());\n+    patterns.add(UnswitchLoop);\n+    mlir::scf::ForOp::getCanonicalizationPatterns(patterns, &getContext());\n+    mlir::scf::IfOp::getCanonicalizationPatterns(patterns, &getContext());\n+    if (mlir::failed(\n+            mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {\n+      signalPassFailure();\n+    }\n+  }\n+};\n+\n+}  // namespace\n+\n+std::unique_ptr<mlir::Pass> CreateTritonXLAUnswitchLoopsPass() {\n+  return std::make_unique<TritonXLAUnswitchLoopsPass>();\n+}\n+\n+}  // namespace mlir::triton::xla"
        }
    ],
    "stats": {
        "total": 480,
        "additions": 478,
        "deletions": 2
    }
}