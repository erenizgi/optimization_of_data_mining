{
    "author": "akuegel",
    "message": "[XLA:GPU] Add additional check for operand sharing of Bias Matmul\n\nIf the bias operand is also used as other operand for the Matmul, we should not\nshare.\n\nPiperOrigin-RevId: 829423168",
    "sha": "feda04abd7b377dcbf9662c2e9067811bda3f4e0",
    "files": [
        {
            "sha": "80cfb0713e2a65f1910d4a2ed09832fd3f59515e",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 22,
            "deletions": 1,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/feda04abd7b377dcbf9662c2e9067811bda3f4e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/feda04abd7b377dcbf9662c2e9067811bda3f4e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=feda04abd7b377dcbf9662c2e9067811bda3f4e0",
            "patch": "@@ -38,7 +38,7 @@ package_group(\n     ],\n )\n \n-# Filegroup used to collect source files for dependency checking.\n+#Filegroup used to collect source files for dependency checking.\n filegroup(\n     name = \"c_srcs\",\n     data = glob([\n@@ -2816,10 +2816,31 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/stream_executor:device_description\",\n+        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/strings\",\n     ],\n )\n \n+xla_cc_test(\n+    name = \"nvptx_alias_info_test\",\n+    srcs = [\"nvptx_alias_info_test.cc\"],\n+    deps = [\n+        \":gpu_device_info_for_tests\",\n+        \":nvptx_alias_info\",\n+        \"//xla:shape_util\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/hlo/testlib:test\",\n+        \"//xla/hlo/testlib:test_helpers\",\n+        \"//xla/service:copy_insertion\",\n+        \"//xla/stream_executor:device_description\",\n+        \"//xla/tests:xla_internal_test_main\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@local_tsl//tsl/platform:statusor\",\n+    ],\n+)\n+\n cc_library(\n     name = \"gpu_fusible\",\n     srcs = [\"gpu_fusible.cc\"],"
        },
        {
            "sha": "1987adcc4aede31c5ec347853d13b0ce3a9d5dd4",
            "filename": "third_party/xla/xla/service/gpu/nvptx_alias_info.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/feda04abd7b377dcbf9662c2e9067811bda3f4e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_alias_info.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/feda04abd7b377dcbf9662c2e9067811bda3f4e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_alias_info.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_alias_info.cc?ref=feda04abd7b377dcbf9662c2e9067811bda3f4e0",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n #include <optional>\n #include <utility>\n \n+#include \"absl/algorithm/container.h\"\n #include \"absl/strings/match.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n@@ -51,7 +52,8 @@ std::optional<bool> NVPTXAliasInfo::MayAlias(\n         GemmBackendConfig config =\n             std::move(user->backend_config<GpuBackendConfig>())\n                 ->gemm_backend_config();\n-        return (config.beta() != 0.) && user->operand(2) == operand;\n+        return (config.beta() != 0.) && operand == user->operand(2) &&\n+               absl::c_count(user->operands(), operand) == 1;\n       }\n       // The operand of cholesky can be shared with the first output.\n       if (user->custom_call_target() == kCusolverCholeskyCallTarget) {"
        },
        {
            "sha": "0535ccd3968e297dfe2b564f84490e94b68ba05c",
            "filename": "third_party/xla/xla/service/gpu/nvptx_alias_info_test.cc",
            "status": "added",
            "additions": 106,
            "deletions": 0,
            "changes": 106,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/feda04abd7b377dcbf9662c2e9067811bda3f4e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_alias_info_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/feda04abd7b377dcbf9662c2e9067811bda3f4e0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_alias_info_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_alias_info_test.cc?ref=feda04abd7b377dcbf9662c2e9067811bda3f4e0",
            "patch": "@@ -0,0 +1,106 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/nvptx_alias_info.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <optional>\n+\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/hlo/testlib/test.h\"\n+#include \"xla/hlo/testlib/test_helpers.h\"\n+#include \"xla/service/copy_insertion.h\"\n+#include \"xla/service/gpu/gpu_device_info_for_tests.h\"\n+#include \"xla/shape_util.h\"\n+#include \"xla/stream_executor/device_description.h\"\n+#include \"tsl/platform/statusor.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+void ExpectOptionalTrue(std::optional<bool> value) {\n+  EXPECT_TRUE(value.has_value());\n+  CHECK(value.has_value());\n+  EXPECT_TRUE(*value);\n+}\n+\n+void ExpectOptionalFalse(std::optional<bool> value) {\n+  EXPECT_TRUE(value.has_value());\n+  CHECK(value.has_value());\n+  EXPECT_FALSE(*value);\n+}\n+\n+class NVPTXAliasInfoTest : public HloHardwareIndependentTestBase {\n+ public:\n+  std::optional<bool> MayAlias(const HloInstruction* user,\n+                               const HloInstruction* operand,\n+                               const ShapeIndex& user_index) {\n+    return alias_info_.MayAlias(operand, {}, user, user_index);\n+  }\n+\n+ private:\n+  const se::DeviceDescription device_description_{\n+      xla::gpu::TestGpuDeviceInfo::RTXH100SXMDeviceInfo()};\n+  NVPTXAliasInfo alias_info_{device_description_};\n+};\n+\n+TEST_F(NVPTXAliasInfoTest, BufferCanBeSharedForBiasMatmul) {\n+  const char* const kModuleString = R\"(\n+HloModule m\n+\n+ENTRY main {\n+  lhs = f32[20,20]{1,0} parameter(0)\n+  rhs = f32[20,30]{1,0} parameter(1)\n+  bias = f32[20,30]{1,0} parameter(2)\n+  ROOT cublas-lt-matmul = (f32[20,30]{1,0}, s8[33554432]{0}) custom-call(lhs, rhs, bias), custom_call_target=\"__cublas$lt$matmul\", frontend_attributes={grad_x=\"false\",grad_y=\"false\"}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"gemm_backend_config\":{\"selected_algorithm\":\"0\",\"alpha_real\":1,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"HIGHEST\",\"HIGHEST\"],\"algorithm\":\"ALG_UNSET\"},\"epilogue\":\"DEFAULT\",\"lhs_stride\":\"400\",\"rhs_stride\":\"600\",\"grad_x\":false,\"grad_y\":false,\"damax_output\":false},\"force_earliest_schedule\":false,\"reification_cost\":[],\"device_type\":\"DEVICE_TYPE_INVALID\"}\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,\n+                          ParseAndReturnVerifiedModule(kModuleString));\n+  HloInstruction* matmul = module->entry_computation()->root_instruction();\n+  ExpectOptionalFalse(MayAlias(matmul, matmul->operand(0), {0}));\n+  ExpectOptionalFalse(MayAlias(matmul, matmul->operand(1), {0}));\n+  ExpectOptionalTrue(MayAlias(matmul, matmul->operand(2), {0}));\n+}\n+\n+TEST_F(NVPTXAliasInfoTest, DuplicateOperandBufferCannotBeSharedForBiasMatmul) {\n+  const char* const kModuleString = R\"(\n+HloModule m\n+\n+ENTRY main {\n+  lhs = f32[20,20]{1,0} parameter(0)\n+  rhs = f32[20,30]{1,0} parameter(1)\n+  ROOT cublas-lt-matmul = (f32[20,30]{1,0}, s8[33554432]{0}) custom-call(lhs, rhs, rhs), custom_call_target=\"__cublas$lt$matmul\", frontend_attributes={grad_x=\"false\",grad_y=\"false\"}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"gemm_backend_config\":{\"selected_algorithm\":\"0\",\"alpha_real\":1,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"HIGHEST\",\"HIGHEST\"],\"algorithm\":\"ALG_UNSET\"},\"epilogue\":\"DEFAULT\",\"lhs_stride\":\"400\",\"rhs_stride\":\"600\",\"grad_x\":false,\"grad_y\":false,\"damax_output\":false},\"force_earliest_schedule\":false,\"reification_cost\":[],\"device_type\":\"DEVICE_TYPE_INVALID\"}\n+}\n+)\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,\n+                          ParseAndReturnVerifiedModule(kModuleString));\n+  HloInstruction* matmul = module->entry_computation()->root_instruction();\n+  ExpectOptionalFalse(MayAlias(matmul, matmul->operand(0), {0}));\n+  ExpectOptionalFalse(MayAlias(matmul, matmul->operand(1), {0}));\n+  ExpectOptionalFalse(MayAlias(matmul, matmul->operand(2), {0}));\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        }
    ],
    "stats": {
        "total": 133,
        "additions": 131,
        "deletions": 2
    }
}