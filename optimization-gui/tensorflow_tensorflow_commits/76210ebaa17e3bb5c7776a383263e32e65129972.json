{
    "author": "apivovarov",
    "message": "[ASAN] Initialize Thunk::PrepareParams with all members in tests.\n\nThis change ensures that Thunk::PrepareParams is fully initialized in thunk tests, including collective-related parameters, using a designated initializer list.\n\nIt fixes asan runtime error: _Nonnull binding to null pointer of type 'CollectiveMultimemRegistry * _Nonnull'\n\nPiperOrigin-RevId: 848237961",
    "sha": "76210ebaa17e3bb5c7776a383263e32e65129972",
    "files": [
        {
            "sha": "5b57b09dffc68d9b7b9aeafdc631d3d9d1f3f22d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 13,
            "deletions": 1,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=76210ebaa17e3bb5c7776a383263e32e65129972",
            "patch": "@@ -280,6 +280,7 @@ xla_test(\n         \"gpu\",\n     ],\n     deps = [\n+        \":collective_multimem_registry\",\n         \":custom_call_thunk\",\n         \":dynamic_slice_thunk\",\n         \":dynamic_slice_thunk_proto_cc\",\n@@ -297,6 +298,7 @@ xla_test(\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/parser:hlo_parser\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/runtime:device_id\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:executable\",\n         \"//xla/service:platform_util\",\n@@ -757,6 +759,7 @@ xla_test(\n     srcs = [\"custom_call_thunk_test.cc\"],\n     backends = [\"gpu\"],\n     deps = [\n+        \":collective_multimem_registry\",\n         \":custom_call_thunk\",\n         \":shaped_slice\",\n         \":thunk\",\n@@ -768,6 +771,7 @@ xla_test(\n         \"//xla/ffi:ffi_api\",\n         \"//xla/ffi:type_registry\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:device_id\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:custom_call_status_public_headers\",\n         \"//xla/service:custom_call_target_registry\",\n@@ -1337,6 +1341,7 @@ xla_test(\n     },\n     backends = [\"h100\"],\n     deps = [\n+        \":collective_clique_requests\",\n         \":collective_kernel_thunk\",\n         \":collective_multimem_registry\",\n         \":collective_params\",\n@@ -1345,7 +1350,6 @@ xla_test(\n         \"//xla:array\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n-        \"//xla/backends/gpu/runtime:collective_clique_requests\",\n         \"//xla/core/collectives:reduction_kind\",\n         \"//xla/pjrt:worker_thread\",\n         \"//xla/runtime:device_id\",\n@@ -3574,8 +3578,12 @@ xla_test(\n         \":buffer_debug_log_entry_metadata_store\",\n         \":buffer_debug_log_structs\",\n         \":buffers_checksum_thunk\",\n+        \":collective_clique_requests\",\n+        \":collective_multimem_registry\",\n+        \":collective_params\",\n         \":thunk\",\n         \":thunk_id\",\n+        \"//xla/runtime:device_id\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:executable\",\n         \"//xla/service/gpu:buffer_allocations\",\n@@ -3647,9 +3655,13 @@ xla_test(\n         \":buffer_debug_log_entry_metadata_store\",\n         \":buffer_debug_log_structs\",\n         \":buffers_float_check_thunk\",\n+        \":collective_clique_requests\",\n+        \":collective_multimem_registry\",\n+        \":collective_params\",\n         \":thunk\",\n         \":thunk_id\",\n         \"//xla:types\",\n+        \"//xla/runtime:device_id\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:executable\",\n         \"//xla/service/gpu:buffer_allocations\","
        },
        {
            "sha": "3eb51302f049fc814354168667306cdc4f3f2070",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_checksum_thunk_test.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 2,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc?ref=76210ebaa17e3bb5c7776a383263e32e65129972",
            "patch": "@@ -28,8 +28,12 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"xla/backends/gpu/runtime/buffer_debug_log_entry_metadata_store.h\"\n #include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/collective_clique_requests.h\"\n+#include \"xla/backends/gpu/runtime/collective_multimem_registry.h\"\n+#include \"xla/backends/gpu/runtime/collective_params.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n+#include \"xla/runtime/device_id.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/service_executable_run_options.h\"\n@@ -147,11 +151,26 @@ TEST_F(BuffersDebugChecksumThunkTest, CalculatesChecksums) {\n   TF_ASSERT_OK(stream_->Memcpy(&inputs0_mem, zeros.data(), zeros.size()));\n   zeros[123] = 56785678;  // expected checksum for inputs_mem[1]\n   TF_ASSERT_OK(stream_->Memcpy(&inputs1_mem, zeros.data(), zeros.size()));\n+\n   // Setup parameters for Initialize/Prepare/ExecuteOnStream\n   Thunk::InitializeParams init_params;\n   init_params.executor = executor_;\n   init_params.stream = stream_.get();\n-  auto execute_params = Thunk::ExecuteParams::Create(\n+\n+  ServiceExecutableRunOptions run_options;\n+  run_options.mutable_run_options()->set_stream(stream_.get());\n+  ASSERT_OK_AND_ASSIGN(\n+      CollectiveParams collective_params,\n+      CollectiveParams::Create(run_options, /*async_streams=*/{},\n+                               LocalDeviceId(executor_->device_ordinal())));\n+  CollectiveCliqueRequests clique_requests;\n+  CollectiveMultimemRegistry multimem_registry(\n+      executor_, collective_params.global_device_id);\n+  Thunk::PrepareParams prepare_params{&collective_params, &clique_requests,\n+                                      &multimem_registry, executor_,\n+                                      &allocations};\n+\n+  Thunk::ExecuteParams execute_params = Thunk::ExecuteParams::Create(\n       ServiceExecutableRunOptions(), allocations, stream_.get(),\n       /*command_buffer_trace_stream=*/stream_.get(),\n       /*collective_params=*/nullptr, /*collective_cliques=*/nullptr);\n@@ -163,7 +182,7 @@ TEST_F(BuffersDebugChecksumThunkTest, CalculatesChecksums) {\n       {{/*buffer_idx=*/0, inputs[0]}, {/*buffer_idx=*/1, inputs[1]}},\n       /*runs_before_checked_thunk=*/true, metadata_store);\n   TF_ASSERT_OK(thunk.Initialize(init_params));\n-  TF_ASSERT_OK(thunk.Prepare(Thunk::PrepareParams{}));\n+  TF_ASSERT_OK(thunk.Prepare(prepare_params));\n   TF_ASSERT_OK(thunk.ExecuteOnStream(execute_params));\n   TF_ASSERT_OK_AND_ASSIGN(std::vector<BufferDebugLogEntry> entries,\n                           device_log.ReadFromDevice(*stream_));"
        },
        {
            "sha": "977e2500f76f686b363f85784623ffc34bd64c06",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_float_check_thunk_test.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 2,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc?ref=76210ebaa17e3bb5c7776a383263e32e65129972",
            "patch": "@@ -28,8 +28,12 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"xla/backends/gpu/runtime/buffer_debug_log_entry_metadata_store.h\"\n #include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/collective_clique_requests.h\"\n+#include \"xla/backends/gpu/runtime/collective_multimem_registry.h\"\n+#include \"xla/backends/gpu/runtime/collective_params.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n+#include \"xla/runtime/device_id.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/service_executable_run_options.h\"\n@@ -153,7 +157,21 @@ TEST_F(BuffersDebugFloatCheckThunkTest, CalculatesNanCounts) {\n   Thunk::InitializeParams init_params;\n   init_params.executor = executor_;\n   init_params.stream = stream_.get();\n-  auto execute_params = Thunk::ExecuteParams::Create(\n+\n+  ServiceExecutableRunOptions run_options;\n+  run_options.mutable_run_options()->set_stream(stream_.get());\n+  ASSERT_OK_AND_ASSIGN(\n+      CollectiveParams collective_params,\n+      CollectiveParams::Create(run_options, /*async_streams=*/{},\n+                               LocalDeviceId(executor_->device_ordinal())));\n+  CollectiveCliqueRequests clique_requests;\n+  CollectiveMultimemRegistry multimem_registry(\n+      executor_, collective_params.global_device_id);\n+  Thunk::PrepareParams prepare_params{&collective_params, &clique_requests,\n+                                      &multimem_registry, executor_,\n+                                      &allocations};\n+\n+  Thunk::ExecuteParams execute_params = Thunk::ExecuteParams::Create(\n       ServiceExecutableRunOptions(), allocations, stream_.get(),\n       /*command_buffer_trace_stream=*/stream_.get(),\n       /*collective_params=*/nullptr, /*collective_cliques=*/nullptr);\n@@ -166,7 +184,7 @@ TEST_F(BuffersDebugFloatCheckThunkTest, CalculatesNanCounts) {\n       {{/*buffer_idx=*/0, inputs[0]}, {/*buffer_idx=*/1, inputs[1]}},\n       metadata_store);\n   TF_ASSERT_OK(thunk.Initialize(init_params));\n-  TF_ASSERT_OK(thunk.Prepare(Thunk::PrepareParams{}));\n+  TF_ASSERT_OK(thunk.Prepare(prepare_params));\n   TF_ASSERT_OK(thunk.ExecuteOnStream(execute_params));\n   TF_ASSERT_OK_AND_ASSIGN(std::vector<BufferDebugFloatCheckEntry> entries,\n                           device_log.ReadFromDevice(*stream_));"
        },
        {
            "sha": "15f1fdd20c33cd58ab0b43b409af2caccd4e7dc8",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 7,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc?ref=76210ebaa17e3bb5c7776a383263e32e65129972",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n@@ -254,7 +255,7 @@ absl::StatusOr<se::DeviceAddressBase> RunCollectiveKernelThunk(\n       &gpu_options);\n \n   TF_ASSIGN_OR_RETURN(\n-      auto collective_params,\n+      CollectiveParams collective_params,\n       CollectiveParams::Create(run_options, /*async_streams=*/{},\n                                LocalDeviceId(executor->device_ordinal())));\n   std::vector<se::DeviceAddressBase> allocated_buffers = {\n@@ -276,15 +277,12 @@ absl::StatusOr<se::DeviceAddressBase> RunCollectiveKernelThunk(\n     TF_RETURN_IF_ERROR(stream->BlockHostUntilDone());\n   }\n \n-  Thunk::PrepareParams prepare_params;\n   CollectiveMultimemRegistry multimem_registry(\n       executor, collective_params.global_device_id);\n   CollectiveCliqueRequests clique_requests;\n-  prepare_params.executor = executor;\n-  prepare_params.buffer_allocations = &buffer_allocations;\n-  prepare_params.collective_params = &collective_params;\n-  prepare_params.clique_requests = &clique_requests;\n-  prepare_params.multimem_registry = &multimem_registry;\n+  Thunk::PrepareParams prepare_params{&collective_params, &clique_requests,\n+                                      &multimem_registry, executor,\n+                                      &buffer_allocations};\n   TF_RETURN_IF_ERROR(metadata.thunk->Prepare(prepare_params));\n \n   TF_RETURN_IF_ERROR(multimem_registry.Build());"
        },
        {
            "sha": "82440516d6338149c1352cf66a000f1591d3e7f2",
            "filename": "third_party/xla/xla/backends/gpu/runtime/custom_call_thunk_test.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 3,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk_test.cc?ref=76210ebaa17e3bb5c7776a383263e32e65129972",
            "patch": "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"absl/status/status_matchers.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/backends/gpu/runtime/collective_multimem_registry.h\"\n #include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/executable_run_options.h\"\n@@ -43,6 +44,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/runtime/device_id.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/custom_call_status.h\"\n #include \"xla/service/custom_call_target_registry.h\"\n@@ -286,9 +288,22 @@ TEST(CustomCallThunkTest, CustomCallWithOwnedHandlers) {\n     ++execute_calls;\n     return absl::OkStatus();\n   });\n+\n+  ServiceExecutableRunOptions run_options;\n+  run_options.mutable_run_options()->set_stream(stream.get());\n+  ASSERT_OK_AND_ASSIGN(\n+      CollectiveParams collective_params,\n+      CollectiveParams::Create(run_options, /*async_streams=*/{},\n+                               LocalDeviceId(executor->device_ordinal())));\n+  CollectiveCliqueRequests clique_requests;\n+  CollectiveMultimemRegistry multimem_registry(\n+      executor, collective_params.global_device_id);\n   se::StreamExecutorMemoryAllocator allocator(executor);\n-  Thunk::PrepareParams prepare_params = Thunk::PrepareParams{};\n   BufferAllocations buffer_allocations({}, 0, &allocator);\n+  Thunk::PrepareParams prepare_params{&collective_params, &clique_requests,\n+                                      &multimem_registry, executor,\n+                                      &buffer_allocations};\n+\n   Thunk::InitializeParams initialize_params;\n   initialize_params.stream = stream.get();\n   initialize_params.buffer_allocations = &buffer_allocations;\n@@ -337,10 +352,23 @@ TEST(CustomCallThunkTest, CustomCallWithOwnedHandlersWithoutOptionalOnes) {\n     ++execute_calls;\n     return absl::OkStatus();\n   });\n+\n+  ServiceExecutableRunOptions run_options;\n+  run_options.mutable_run_options()->set_stream(stream.get());\n+  ASSERT_OK_AND_ASSIGN(\n+      CollectiveParams collective_params,\n+      CollectiveParams::Create(run_options, /*async_streams=*/{},\n+                               LocalDeviceId(executor->device_ordinal())));\n+  CollectiveCliqueRequests clique_requests;\n+  CollectiveMultimemRegistry multimem_registry(\n+      executor, collective_params.global_device_id);\n   se::StreamExecutorMemoryAllocator allocator(executor);\n-  Thunk::PrepareParams prepare_params = Thunk::PrepareParams{};\n-  Thunk::InitializeParams initialize_params = Thunk::InitializeParams{};\n   BufferAllocations buffer_allocations({}, 0, &allocator);\n+  Thunk::PrepareParams prepare_params{&collective_params, &clique_requests,\n+                                      &multimem_registry, executor,\n+                                      &buffer_allocations};\n+\n+  Thunk::InitializeParams initialize_params = Thunk::InitializeParams{};\n   Thunk::ExecuteParams execute_params = Thunk::ExecuteParams::Create(\n       ServiceExecutableRunOptions(), buffer_allocations, stream.get(),\n       stream.get(), nullptr, nullptr);"
        },
        {
            "sha": "7c8913b737f2ed48c58220eb5167f33370245e7b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/dynamic_slice_thunk_test.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 3,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76210ebaa17e3bb5c7776a383263e32e65129972/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk_test.cc?ref=76210ebaa17e3bb5c7776a383263e32e65129972",
            "patch": "@@ -31,6 +31,7 @@ limitations under the License.\n #include \"absl/strings/ascii.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/ffi.h\"\n+#include \"xla/backends/gpu/runtime/collective_multimem_registry.h\"\n #include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n #include \"xla/backends/gpu/runtime/dynamic_slice_thunk.pb.h\"\n #include \"xla/backends/gpu/runtime/gemm_thunk.h\"\n@@ -44,6 +45,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/parser/hlo_parser.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/runtime/device_id.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/gpu/matmul_utils.h\"\n@@ -1940,12 +1942,21 @@ TEST_F(DynamicSliceThunkTest,\n \n   // Preparing parameters for thunk execution.\n   ServiceExecutableRunOptions run_options;\n+  run_options.mutable_run_options()->set_stream(stream.get());\n+  ASSERT_OK_AND_ASSIGN(\n+      CollectiveParams collective_params,\n+      CollectiveParams::Create(run_options, /*async_streams=*/{},\n+                               LocalDeviceId(executor->device_ordinal())));\n+  CollectiveCliqueRequests clique_requests;\n+  CollectiveMultimemRegistry multimem_registry(\n+      executor, collective_params.global_device_id);\n   se::StreamExecutorMemoryAllocator allocator(executor);\n   BufferAllocations allocations(/*buffers=*/{lhs, rhs, out, workspace},\n-                                /*device_ordinal=*/0,\n+                                /*device_ordinal=*/executor->device_ordinal(),\n                                 /*memory_allocator=*/&allocator);\n-\n-  Thunk::PrepareParams prepare_params{};\n+  Thunk::PrepareParams prepare_params{&collective_params, &clique_requests,\n+                                      &multimem_registry, executor,\n+                                      &allocations};\n \n   Thunk::ExecuteParams params = Thunk::ExecuteParams::Create(\n       run_options, /*buffer_allocations=*/allocations, stream.get(),"
        }
    ],
    "stats": {
        "total": 122,
        "additions": 104,
        "deletions": 18
    }
}