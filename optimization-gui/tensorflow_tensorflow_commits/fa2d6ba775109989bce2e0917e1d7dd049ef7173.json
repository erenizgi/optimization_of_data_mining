{
    "author": "tensorflower-gardener",
    "message": "Reverts f1050d735b1045fca794059bbc0bc9db823b8339\n\nPiperOrigin-RevId: 803988333",
    "sha": "fa2d6ba775109989bce2e0917e1d7dd049ef7173",
    "files": [
        {
            "sha": "1fdae4968864c883a3c7194541f44d5db01ee799",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/llvm_kernel_backend.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_backend.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_backend.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_backend.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -100,7 +100,7 @@ absl::Status LlvmKernelBackend::ApplyConfig(HloInstruction& instr,\n \n   *backend_config.mutable_llvm_kernel_options() = llvm_kernel_config;\n \n-  instr.set_backend_config(backend_config);\n+  TF_RETURN_IF_ERROR(instr.set_backend_config(backend_config));\n \n   return absl::OkStatus();\n }"
        },
        {
            "sha": "5a801d053f41c5b102da34ae3c4f65dc7090d448",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/xnnpack_backend.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -116,7 +116,7 @@ absl::Status XnnpackBackend::ApplyConfig(HloInstruction& instr,\n   *backend_config.mutable_fusion_config()->mutable_xnn_fusion_config() =\n       xnn_config;\n \n-  instr.set_backend_config(backend_config);\n+  TF_RETURN_IF_ERROR(instr.set_backend_config(backend_config));\n \n   return absl::OkStatus();\n }"
        },
        {
            "sha": "f433053d478022ad239e35b31a57a699d27570ba",
            "filename": "third_party/xla/xla/backends/cpu/transforms/dot_library_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fdot_library_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -76,7 +76,7 @@ absl::StatusOr<HloFusionInstruction*> CreateLibraryFusion(\n   BackendConfig backend_config;\n   FusionBackendConfig* fusion_config = backend_config.mutable_fusion_config();\n   fusion_config->set_kind(fusion_kind);\n-  fusion->set_backend_config(backend_config);\n+  TF_RETURN_IF_ERROR(fusion->set_backend_config(backend_config));\n \n   // Replace the instruction.\n   TF_RETURN_IF_ERROR("
        },
        {
            "sha": "7e92e5d44e97a8b2eb5d252f4a23892e3b47b301",
            "filename": "third_party/xla/xla/backends/cpu/transforms/xnn_graph_fusion.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_graph_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_graph_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fxnn_graph_fusion.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -91,7 +91,7 @@ HloInstruction* XnnGraphFusion::Fuse(HloInstruction* producer,\n   FusionBackendConfig* fusion_config = backend_config.mutable_fusion_config();\n   fusion_config->set_kind(std::string{kXnnFusionKind});\n   CHECK(backend_config.has_fusion_config());\n-  fusion->set_backend_config(backend_config);\n+  TF_CHECK_OK(fusion->set_backend_config(backend_config));\n   return fusion;\n }\n "
        },
        {
            "sha": "981421f5bb6ce7f9a2ec3c2d470670ccf7b0523a",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/block_level_emitter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -386,7 +386,7 @@ absl::Status BlockLevelEmitterBackend::ApplyConfig(\n   *backend_config.mutable_block_level_fusion_config() =\n       block_level_fusion_config;\n   // Re-attach the modified GPU config back to the instruction.\n-  instr.set_backend_config(std::move(gpu_backend_config));\n+  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_backend_config)));\n   instr.set_fusion_kind(HloInstruction::FusionKind::kCustom);\n   return absl::OkStatus();\n }"
        },
        {
            "sha": "c51ceb43bfff4fbf9b28fcd29736a0d88fc94a3b",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cublas.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublas.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -193,7 +193,7 @@ absl::Status CublasBackend::ApplyConfig(HloInstruction& instr,\n                       instr.backend_config<GpuBackendConfig>());\n   GemmBackendConfig& backend_config = *gpu_config.mutable_gemm_backend_config();\n   backend_config.set_selected_algorithm(gemm_key.algorithm());\n-  instr.set_backend_config(std::move(gpu_config));\n+  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_config)));\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "ef03149115ccbfa838c8c766435c4cd710f15242",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cublaslt.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublaslt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublaslt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcublaslt.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -157,7 +157,7 @@ absl::Status CublasLtBackend::ApplyConfig(HloInstruction& instr,\n                       instr.backend_config<GpuBackendConfig>());\n   GemmBackendConfig& backend_config = *gpu_config.mutable_gemm_backend_config();\n   backend_config.set_selected_algorithm(gemm_key.algorithm());\n-  instr.set_backend_config(std::move(gpu_config));\n+  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_config)));\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "465f0cbbd877cb5b9b7ddf28574f8bace7ebedb2",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cudnn.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -91,7 +91,7 @@ absl::Status ApplyConfigAndUpdateWorkspaceInOutputTuple(\n   CudnnConvBackendConfig* cudnn_conv_config =\n       gpu_backend_config.mutable_cudnn_conv_backend_config();\n   *cudnn_conv_config->mutable_algorithm() = config;\n-  new_call->set_backend_config(gpu_backend_config);\n+  TF_RETURN_IF_ERROR(new_call->set_backend_config(gpu_backend_config));\n \n   std::vector<HloInstruction*> new_tuple_elements;\n   new_tuple_elements.reserve(new_call->shape().tuple_shapes().size() - 1);\n@@ -290,7 +290,7 @@ absl::Status ApplyConfigToCudnnFusion(HloInstruction& instr,\n   FusionBackendConfig* backend_config =\n       gpu_config.mutable_fusion_backend_config();\n   backend_config->mutable_cudnn_fusion_config()->set_plan_id(config.algo_id());\n-  instr.set_backend_config(std::move(gpu_config));\n+  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_config)));\n   return absl::OkStatus();\n }\n \n@@ -304,7 +304,7 @@ absl::Status ApplyConfigToCudnnCustomCall(HloInstruction& instr,\n   CudnnConvBackendConfig* cudnn_conv_config =\n       gpu_config.mutable_cudnn_conv_backend_config();\n   *cudnn_conv_config->mutable_algorithm() = config;\n-  instr.set_backend_config(std::move(gpu_config));\n+  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_config)));\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "1b8d3e4bd8a24b3608889d17ccbd25595d575551",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/custom_kernel.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcustom_kernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcustom_kernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcustom_kernel.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -146,7 +146,7 @@ absl::Status CustomKernelBackend::ApplyConfig(HloInstruction& instr,\n       gpu_config.mutable_fusion_backend_config();\n   backend_config->mutable_custom_fusion_config()->set_kernel_index(\n       custom_kernel_config.kernel_index());\n-  instr.set_backend_config(std::move(gpu_config));\n+  TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_config)));\n \n   return absl::OkStatus();\n }"
        },
        {
            "sha": "f3828419f64e4b4e3ea277a989db8c11ef0dc2aa",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/native_emitter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -85,7 +85,7 @@ absl::Status NativeEmitterBackend::ApplyConfig(HloInstruction& instr,\n                       instr.backend_config<GpuBackendConfig>());\n   *gpu_backend_config.mutable_native_emitter_backend_config() =\n       native_emitter_fusion_config;\n-  fusion_instr->set_backend_config(gpu_backend_config);\n+  TF_RETURN_IF_ERROR(fusion_instr->set_backend_config(gpu_backend_config));\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "6a7985506c04517fbf14e98b03214db1dceb3b08",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/triton.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -176,7 +176,7 @@ absl::Status TritonBackend::ApplyConfig(HloInstruction& instr,\n       *gpu_config.mutable_fusion_backend_config();\n \n   *backend_config.mutable_triton_gemm_config() = triton_config_proto;\n-  instr.set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(instr.set_backend_config(gpu_config));\n \n   TF_ASSIGN_OR_RETURN(TritonGemmConfig triton_config,\n                       TritonGemmConfig::FromProto(triton_config_proto));"
        },
        {
            "sha": "10ffb4b2b43036631462efd4ecd48ceda55456f3",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -715,7 +715,7 @@ ENTRY entry {\n   config.set_num_warps(8);\n   config.set_num_stages(4);\n \n-  triton_dot_fusion->set_backend_config(backend_config);\n+  TF_ASSERT_OK(triton_dot_fusion->set_backend_config(backend_config));\n \n   BlockLevelParameters block_level_parameters;\n   block_level_parameters.num_ctas = 1;\n@@ -733,7 +733,7 @@ ENTRY entry {\n   config.set_block_n(128);\n   config.set_block_k(128);\n   block_level_parameters.num_stages = 1;\n-  triton_dot_fusion->set_backend_config(backend_config);\n+  TF_ASSERT_OK(triton_dot_fusion->set_backend_config(backend_config));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       const auto result,\n@@ -1310,7 +1310,7 @@ ENTRY entry {\n   config.set_num_ctas(1);\n   config.set_num_stages(1);\n   config.set_num_warps(2);\n-  triton_dot_fusion->set_backend_config(backend_config);\n+  TF_ASSERT_OK(triton_dot_fusion->set_backend_config(backend_config));\n \n   BlockLevelParameters block_level_parameters;\n   block_level_parameters.num_ctas = 1;\n@@ -1327,7 +1327,7 @@ ENTRY entry {\n   config.set_block_m(32);\n   config.set_block_n(32);\n   config.set_block_k(32);\n-  triton_dot_fusion->set_backend_config(backend_config);\n+  TF_ASSERT_OK(triton_dot_fusion->set_backend_config(backend_config));\n \n   TF_ASSERT_OK(TritonWrapper(\"test_fn\", triton_dot_fusion, CudaAmpereOrRocm(),\n                              dev_info, block_level_parameters, &llvm_module,"
        },
        {
            "sha": "8b66a7eec546d710c644241a27b3916fbba74fee",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_int4_device_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -144,8 +144,7 @@ class TritonTest : public GpuCodegenTest {\n     triton_gemm_key->set_num_stages(1);\n     triton_gemm_key->set_num_warps(2);\n     triton_gemm_key->set_num_ctas(1);\n-    fusion->set_backend_config(gpu_config);\n-    return absl::OkStatus();\n+    return fusion->set_backend_config(gpu_config);\n   }\n \n  protected:"
        },
        {
            "sha": "8be55479f93ea88fbb7a827dd5838b387124ca5c",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/test_utils.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftest_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftest_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftest_utils.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -262,7 +262,7 @@ absl::Status ConvertEntryToTritonFusion(HloModule* module,\n     gpu_config.mutable_fusion_backend_config()->set_kind(\n         std::string(kTritonFusionKind));\n   }\n-  fusion->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(fusion->set_backend_config(gpu_config));\n \n   auto new_entry =\n       module->AddComputationAndUnifyNamesAndIds(builder.Build(),"
        },
        {
            "sha": "8f43ddc1534bc69d136ea741f07cb532711ed00b",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.h?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -2035,8 +2035,9 @@ class HloInstruction {\n     return proto;\n   }\n \n-  void set_backend_config(const tsl::protobuf::Message& proto) {\n+  absl::Status set_backend_config(const tsl::protobuf::Message& proto) {\n     backend_config_ = BackendConfigWrapper(proto);\n+    return absl::OkStatus();\n   }\n \n   // Getter/setter for raw JSON-encoded backend config.  Prefer the"
        },
        {
            "sha": "9ed713d6473a1739021840a81872ffc7dcf6e145",
            "filename": "third_party/xla/xla/hlo/transforms/while_loop_trip_count_annotator.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fwhile_loop_trip_count_annotator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fwhile_loop_trip_count_annotator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fwhile_loop_trip_count_annotator.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -67,7 +67,7 @@ absl::StatusOr<bool> WhileLoopTripCountAnnotator::Run(\n           config.mutable_known_trip_count()->set_n(*trip_count);\n         }\n \n-        instr->set_backend_config(config);\n+        TF_RETURN_IF_ERROR(instr->set_backend_config(config));\n         changed = true;\n       }\n     }"
        },
        {
            "sha": "6bbd30b01561c3dfd435f7787252344133c2ef01",
            "filename": "third_party/xla/xla/service/cpu/onednn_contraction_rewriter.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 9,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_contraction_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -579,7 +579,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n     bool transpose_b = (rhs_dim_k != rhs_shape.dimensions_size() - 2);\n     matmul_config->set_transpose_a(transpose_a);\n     matmul_config->set_transpose_b(transpose_b);\n-    matmul_call->set_backend_config(backend_config);\n+    TF_RETURN_IF_ERROR(matmul_call->set_backend_config(backend_config));\n     TF_RETURN_IF_ERROR(ReplaceInstruction(dot_instr, matmul_call));\n     return absl::OkStatus();\n   }\n@@ -645,7 +645,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n             output_shape, {conv->mutable_operand(0), conv->mutable_operand(1)},\n             \"__onednn$convolution\"));\n \n-    custom_call->set_backend_config(backend_config);\n+    TF_RETURN_IF_ERROR(custom_call->set_backend_config(backend_config));\n     TF_RETURN_IF_ERROR(ReplaceInstruction(conv, custom_call));\n     return absl::OkStatus();\n   }\n@@ -815,7 +815,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n       if (optional_addend_broadcast) {\n         optimization_config->set_bias_broadcast(true);\n       }\n-      custom_call->set_backend_config(*backend_config);\n+      TF_RETURN_IF_ERROR(custom_call->set_backend_config(*backend_config));\n \n       HloInstruction* new_instr;\n       // If matched pattern has custom-call -> bitcast -> add, then we need to\n@@ -1010,7 +1010,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n       // handling.\n       fusions_config->add_alpha_typecast(\n           *(reinterpret_cast<int32_t*>(&constant_value.value())));\n-      custom_call->set_backend_config(*backend_config);\n+      TF_RETURN_IF_ERROR(custom_call->set_backend_config(*backend_config));\n       HloInstruction* new_instr;\n       if (optional_convert != nullptr &&\n           optional_convert->opcode() == HloOpcode::kConvert) {\n@@ -1070,7 +1070,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n       auto matmul_call = Cast<HloCustomCallInstruction>(\n           custom_call->AddInstruction(custom_call->CloneWithNewOperands(\n               copy->shape(), custom_call->mutable_operands())));\n-      matmul_call->set_backend_config(*backend_config);\n+      TF_RETURN_IF_ERROR(matmul_call->set_backend_config(*backend_config));\n       TF_RETURN_IF_ERROR(ReplaceInstruction(copy, matmul_call));\n     }\n     return absl::OkStatus();\n@@ -1084,7 +1084,7 @@ class OneDnnContractionRewriteVisitor : public DfsHloRewriteVisitor {\n     auto backend_config = contraction->backend_config<BackendConfig>();\n     auto fusions_config = GetFusionsConfig(&backend_config);\n     fusions_config->add_ops(kind);\n-    contraction->set_backend_config(*backend_config);\n+    TF_RETURN_IF_ERROR(contraction->set_backend_config(*backend_config));\n     std::unique_ptr<HloInstruction> output = contraction->Clone();\n     if (optional_bitcast != nullptr &&\n         optional_bitcast->opcode() == HloOpcode::kBitcast) {\n@@ -1274,7 +1274,7 @@ class OneDnnPostRewriteVisitor : public DfsHloRewriteVisitor {\n       auto matmul_call = Cast<HloCustomCallInstruction>(\n           contraction->AddInstruction(contraction->CloneWithNewOperands(\n               contraction->shape(), new_ops)));\n-      matmul_call->set_backend_config(*backend_config);\n+      TF_RETURN_IF_ERROR(matmul_call->set_backend_config(*backend_config));\n       TF_RETURN_IF_ERROR(ReplaceInstruction(contraction, matmul_call));\n       return HandleCustomCallInternal<dnnl::matmul::primitive_desc>(\n           matmul_call);\n@@ -1449,8 +1449,7 @@ EMIT_GET_BACKEND_CONFIG_SPECIALIZATION(\n                         custom_call->backend_config<BackendConfig>());         \\\n     CONFIG_TYPE* config = backend_config.mutable_##CONFIG();                   \\\n     config->mutable_##SUB_CONFIG()->set_##FIELD(value);                        \\\n-    custom_call->set_backend_config(backend_config);                           \\\n-    return absl::OkStatus();                                                   \\\n+    return custom_call->set_backend_config(backend_config);                    \\\n   }\n \n EMIT_SET_BACKEND_CONFIG_SPECIALIZATION(SetWeightsPrepack,"
        },
        {
            "sha": "08a5fd33f133e97cf30b806ee7186fe72c24f65a",
            "filename": "third_party/xla/xla/service/cpu/onednn_ops_rewriter.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_ops_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_ops_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fonednn_ops_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -506,7 +506,7 @@ class OneDnnOpsRewriterVisitor : public DfsHloRewriteVisitor {\n         backend_config.mutable_onednn_layer_norm_config();\n     ln_config->set_rescale(OneDnnNormConfig::SCALE_AND_SHIFT);\n     ln_config->set_epsilon_typecast(*(reinterpret_cast<int32_t*>(&eps)));\n-    ln_call->set_backend_config(backend_config);\n+    TF_RETURN_IF_ERROR(ln_call->set_backend_config(backend_config));\n \n     if (convert_instr != nullptr && is_bf16orfp16_convert &&\n         is_producer_bf16orfp16) {\n@@ -568,7 +568,7 @@ class OneDnnOpsRewriterVisitor : public DfsHloRewriteVisitor {\n     OneDnnSoftmaxConfig* softmax_config =\n         backend_config.mutable_onednn_softmax_config();\n     softmax_config->set_softmax_axis(axis);\n-    softmax_call->set_backend_config(backend_config);\n+    TF_RETURN_IF_ERROR(softmax_call->set_backend_config(backend_config));\n     TF_RETURN_IF_ERROR(ReplaceInstruction(divide_instr, softmax_call));\n \n     return absl::OkStatus();"
        },
        {
            "sha": "9e8dc4861f7dbbf9a075a84600d5a46dadd80209",
            "filename": "third_party/xla/xla/service/cpu/parallel_task_assignment.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -286,7 +286,7 @@ bool ParallelTaskAssigner::AssignParallelTasksHelper(\n     absl::c_copy(dim_partition_counts,\n                  tsl::protobuf::RepeatedFieldBackInserter(\n                      backend_config.mutable_outer_dimension_partitions()));\n-    instruction->set_backend_config(backend_config);\n+    TF_CHECK_OK(instruction->set_backend_config(backend_config));\n \n     VLOG(2) << \"Assigned parallel task count: \" << total_partition_count\n             << \" to instruction: \" << instruction->name();"
        },
        {
            "sha": "1cb3dfb96129143aa90177e60e83610bdb42f1d1",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_pass_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass_test.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -224,7 +224,8 @@ TEST_F(AutotunerPassTest, CublasGemmIsAutotunedAndCached) {\n   gemm_config.clear_selected_algorithm();\n   *gpu_backend_config_before_second_run.mutable_gemm_backend_config() =\n       gemm_config;\n-  custom_call->set_backend_config(gpu_backend_config_before_second_run);\n+  TF_ASSERT_OK(\n+      custom_call->set_backend_config(gpu_backend_config_before_second_run));\n \n   // Run the pass for the second time, this should hit the cache.\n   {"
        },
        {
            "sha": "b642886f8be9e1f9ebf206b1eb0b688f0e972fa5",
            "filename": "third_party/xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fconv_algorithm_picker.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -1119,7 +1119,7 @@ absl::StatusOr<bool> GpuConvAlgorithmPicker::RunOnInstruction(\n   VLOG(3) << \"Replacing convolution \" << instr->ToString() << \" with \"\n           << new_call->ToString();\n \n-  new_call->set_backend_config(gpu_backend_config);\n+  TF_RETURN_IF_ERROR(new_call->set_backend_config(gpu_backend_config));\n \n   std::vector<HloInstruction*> new_tuple_elements;\n   new_tuple_elements.reserve(new_call->shape().tuple_shapes().size() - 1);"
        },
        {
            "sha": "05613318419ca063190f94f2a058319f36524126",
            "filename": "third_party/xla/xla/service/gpu/autotuning/custom_kernel_fusion_autotuner.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fcustom_kernel_fusion_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fcustom_kernel_fusion_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fcustom_kernel_fusion_autotuner.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -64,7 +64,7 @@ absl::StatusOr<std::unique_ptr<HloModule>> ExtractFusionModule(\n   gpu_config.mutable_fusion_backend_config()\n       ->mutable_custom_fusion_config()\n       ->set_kernel_index(kernel_index);\n-  instruction->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(instruction->set_backend_config(gpu_config));\n \n   return hlo_module;\n }\n@@ -129,7 +129,7 @@ absl::Status UpdateFusionInstructionKernelIndex(\n   gpu_config.mutable_fusion_backend_config()\n       ->mutable_custom_fusion_config()\n       ->set_kernel_index(kernel_index);\n-  fusion_instruction->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(fusion_instruction->set_backend_config(gpu_config));\n \n   return absl::OkStatus();\n }"
        },
        {
            "sha": "ae59872da4d9cd58e45224733f0ef1e2b8f7ef61",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -291,7 +291,7 @@ absl::StatusOr<std::unique_ptr<HloModule>> TritonGemmAutotuneExtractor(\n       *gpu_config.mutable_fusion_backend_config();\n \n   *backend_config.mutable_triton_gemm_config() = config.ToProto();\n-  cloned_dot_fusion->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(cloned_dot_fusion->set_backend_config(gpu_config));\n \n   if (config.split_k > 1) {\n     TF_RETURN_IF_ERROR(MakeDotSplitKBatch(cloned_dot_fusion, config));\n@@ -361,7 +361,7 @@ absl::Status UpdateFusionInstructionKernelIndex(\n   gpu_config.mutable_fusion_backend_config()\n       ->mutable_custom_fusion_config()\n       ->set_kernel_index(kernel_index);\n-  fusion_instruction->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(fusion_instruction->set_backend_config(gpu_config));\n \n   return absl::OkStatus();\n }\n@@ -415,8 +415,9 @@ absl::StatusOr<std::unique_ptr<HloModule>> CuDnnFusionExtractor(\n   backend_config.set_kind(std::string(kCuDnnFusionKind));\n   // Provided a plan ID the autotuner just compiles one plan.\n   backend_config.mutable_cudnn_fusion_config()->set_plan_id(plan_id);\n-  module->entry_computation()->root_instruction()->set_backend_config(\n-      gpu_config);\n+  TF_RETURN_IF_ERROR(\n+      module->entry_computation()->root_instruction()->set_backend_config(\n+          gpu_config));\n   return module;\n }\n \n@@ -694,7 +695,7 @@ absl::Status GemmFusionAutotunerRewriterVisitor::HandleFusion(\n   if (autotune_result.has_triton()) {\n     *fusion_backend_config.mutable_triton_gemm_config() =\n         autotune_result.triton();\n-    fusion_instr->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(fusion_instr->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(HandleTritonGemm(fusion_instr, fusion_backend_config));\n     MarkAsChanged();\n     return absl::OkStatus();\n@@ -719,7 +720,7 @@ absl::Status GemmFusionAutotunerRewriterVisitor::HandleFusion(\n   fusion_backend_config.set_kind(std::string(kCuDnnFusionKind));\n   fusion_backend_config.mutable_cudnn_fusion_config()->set_plan_id(\n       autotune_result.algorithm().algo_id());\n-  fusion_instr->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(fusion_instr->set_backend_config(gpu_config));\n   MarkAsChanged();\n   return absl::OkStatus();\n }"
        },
        {
            "sha": "f09ef9a9cd23e5b7704c2aff8e7159de36349e0d",
            "filename": "third_party/xla/xla/service/gpu/backend_configs_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbackend_configs_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbackend_configs_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbackend_configs_test.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -131,7 +131,8 @@ TEST_F(BackendConfigsTest, DefaultGpuBackendConfigSetOpQueue) {\n   EXPECT_FALSE(add->has_backend_config());\n   GpuBackendConfig gpu_backend_config;\n   gpu_backend_config.set_operation_queue_id(2);\n-  add->set_backend_config(gpu_backend_config);\n+  EXPECT_THAT(add->set_backend_config(gpu_backend_config),\n+              absl_testing::IsOk());\n   EXPECT_THAT(\n       add->raw_backend_config_string(),\n       HasSubstr(\"{\\\"operation_queue_id\\\":\\\"2\\\",\\\"wait_on_operation_queues\\\":[],\"\n@@ -159,7 +160,8 @@ TEST_F(BackendConfigsTest, DefaultGpuBackendConfigSetWaitOnQueue) {\n   // Wait on queues {0, 1}\n   gpu_backend_config.mutable_wait_on_operation_queues()->Add(0);\n   gpu_backend_config.mutable_wait_on_operation_queues()->Add(1);\n-  add->set_backend_config(gpu_backend_config);\n+  EXPECT_THAT(add->set_backend_config(gpu_backend_config),\n+              absl_testing::IsOk());\n   EXPECT_THAT(\n       add->raw_backend_config_string(),\n       HasSubstr("
        },
        {
            "sha": "ba3bff99166c770e0bf67c1a79f2838036a32356",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -695,16 +695,15 @@ absl::Status SetHostDeviceType(HloInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(auto backend_config,\n                       instr->backend_config<GpuBackendConfig>());\n   backend_config.set_device_type(DEVICE_TYPE_HOST);\n-  instr->set_backend_config(backend_config);\n+  TF_RETURN_IF_ERROR(instr->set_backend_config(backend_config));\n   return absl::OkStatus();\n }\n \n absl::Status ClearBackendConfigDeviceType(HloInstruction* instr) {\n   TF_ASSIGN_OR_RETURN(auto backend_config,\n                       instr->backend_config<GpuBackendConfig>());\n   backend_config.clear_device_type();\n-  instr->set_backend_config(backend_config);\n-  return absl::OkStatus();\n+  return instr->set_backend_config(backend_config);\n }\n \n bool BackendConfigDeviceTypeIsHost(HloInstruction* instr) {"
        },
        {
            "sha": "052db1fefeb56ba00f2b3ee6586df8fe800b6102",
            "filename": "third_party/xla/xla/service/gpu/gpu_float_support_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_float_support_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_float_support_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_float_support_test.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -137,7 +137,7 @@ class FloatSupportTest : public HloHardwareIndependentTestBase {\n     GpuBackendConfig config;\n     config.mutable_fusion_backend_config()->set_kind(\n         std::string(kTritonGemmFusionKind));\n-    fusion->set_backend_config(config);\n+    CHECK_OK(fusion->set_backend_config(config));\n \n     module->AddEntryComputation(builder.Build());\n "
        },
        {
            "sha": "722a64e79c314c8c29d6717e038fcb79f1884a31",
            "filename": "third_party/xla/xla/service/gpu/model/collective_ptable_stats_collection.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_ptable_stats_collection.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_ptable_stats_collection.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_ptable_stats_collection.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -99,7 +99,7 @@ absl::StatusOr<bool> CollectivePerfTableStatsCollection::Run(\n         reification_cost->set_exec_time_us(\n             absl::ToDoubleMicroseconds(exec_time));\n         *reification_cost->mutable_name() = name();\n-        instr->set_backend_config(*gpu_config);\n+        TF_CHECK_OK(instr->set_backend_config(*gpu_config));\n       });\n \n   return false;"
        },
        {
            "sha": "f1283e2c30723a73fe091dc9cb776711c03a3d31",
            "filename": "third_party/xla/xla/service/gpu/model/gpu_performance_model.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fgpu_performance_model.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fgpu_performance_model.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fgpu_performance_model.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -303,7 +303,7 @@ void GpuPerformanceModel::RecordEstimatedRunTime(\n       absl::ToDoubleMicroseconds(data.read_time + data.write_time));\n   reification_cost->set_exec_time_us(\n       absl::ToDoubleMicroseconds(data.exec_time));\n-  instruction->set_backend_config(*gpu_config);\n+  TF_CHECK_OK(instruction->set_backend_config(*gpu_config));\n \n   VLOG(8) << \"RecordEstimatedRunTime: \" << instruction->ToString();\n }"
        },
        {
            "sha": "cc56701049c3a6858d383d14fa481beff89ab4da",
            "filename": "third_party/xla/xla/service/gpu/model/matmul_ptable_stats_collection.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -103,8 +103,7 @@ absl::Status SetReificationCost(HloInstruction& instr, absl::Duration exec_time,\n   ReificationCost& reification_cost = *gpu_config.add_reification_cost();\n   reification_cost.set_exec_time_us(absl::ToDoubleMicroseconds(exec_time));\n   *reification_cost.mutable_name() = reification_name;\n-  instr.set_backend_config(gpu_config);\n-  return absl::OkStatus();\n+  return instr.set_backend_config(gpu_config);\n }\n \n // Computes the runtime estimation via analytical GEMM cost model and adds a"
        },
        {
            "sha": "1f36aa572b6ac5b6f10740c87bba3d137fc2cc11",
            "filename": "third_party/xla/xla/service/gpu/model/sol_gpu_cost_model_stats_collection.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model_stats_collection.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model_stats_collection.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsol_gpu_cost_model_stats_collection.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -62,8 +62,7 @@ bool SetReificationCost(HloInstruction* instr, double cost_us) {\n   auto reification_cost = gpu_config->add_reification_cost();\n   reification_cost->set_exec_time_us(cost_us);\n   reification_cost->set_name(\"sol\");\n-  instr->set_backend_config(*gpu_config);\n-  return true;\n+  return instr->set_backend_config(*gpu_config).ok();\n }\n \n // Returns true if reification cost has been successfully recorded."
        },
        {
            "sha": "4a045bb8f364df4503133c744f0c50d1692d2303",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/async_collective_annotator.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fasync_collective_annotator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fasync_collective_annotator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fasync_collective_annotator.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -43,7 +43,7 @@ absl::StatusOr<bool> AsyncCollectiveAnnotator::Run(\n                           instruction->backend_config<GpuBackendConfig>());\n       gpu_config.mutable_collective_backend_config()->set_is_sync(\n           !is_collective_async_(instruction));\n-      instruction->set_backend_config(gpu_config);\n+      TF_RETURN_IF_ERROR(instruction->set_backend_config(gpu_config));\n       changed = true;\n     }\n   }"
        },
        {
            "sha": "344e399448c1488b77b9ccb104cf5df7a7cb7e9e",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_backend_assigner.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -112,7 +112,7 @@ absl::StatusOr<bool> CollectiveBackendAssigner::Run(\n       VLOG(1) << \"CollectiveBackendAssigner: setting backend to NVSHMEM for \"\n               << instr->name();\n \n-      instr->set_backend_config(gpu_config);\n+      TF_RETURN_IF_ERROR(instr->set_backend_config(gpu_config));\n       changed = true;\n     }\n   }"
        },
        {
            "sha": "8d34319a2b59cb358b451eca1b5a80ce55f44838",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/convert_async_collectives_to_sync.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fconvert_async_collectives_to_sync.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fconvert_async_collectives_to_sync.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fconvert_async_collectives_to_sync.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -52,7 +52,7 @@ absl::Status GpuConvertAsyncCollectivesToSync::ConvertAsyncInstructionsToSync(\n     TF_ASSIGN_OR_RETURN(GpuBackendConfig gpu_config,\n                         async_start->backend_config<GpuBackendConfig>());\n     gpu_config.mutable_collective_backend_config()->set_is_sync(true);\n-    async_start->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(async_start->set_backend_config(gpu_config));\n     replaced_ops[async_start] = nullptr;\n     replaced_ops[async_done] = async_start;\n   }"
        },
        {
            "sha": "a2ffad9025363571c78f647612cb4239fdef4ff5",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/gpu_collective_combiner_utils.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fgpu_collective_combiner_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fgpu_collective_combiner_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fgpu_collective_combiner_utils.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -34,8 +34,7 @@ absl::Status AppendPipelinedInstruction(HloInstruction* instr,\n   TF_ASSIGN_OR_RETURN(auto config,\n                       instr->backend_config<gpu::GpuBackendConfig>());\n   config.mutable_collective_backend_config()->set_is_pipelined(true);\n-  instr->set_backend_config(config);\n-  return absl::OkStatus();\n+  return instr->set_backend_config(config);\n }\n \n bool IsPipelinedCollective(const HloInstruction& instr) {"
        },
        {
            "sha": "b96853ca3108ec76409b2fb25302357bee092226",
            "filename": "third_party/xla/xla/service/gpu/transforms/conv_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fconv_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fconv_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fconv_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -826,7 +826,7 @@ absl::StatusOr<bool> RunOnInstruction(HloInstruction* conv,\n   GpuBackendConfig gpu_backend_config;\n   *gpu_backend_config.mutable_cudnn_conv_backend_config() =\n       GetDefaultBackendConfig();\n-  custom_call->set_backend_config(gpu_backend_config);\n+  TF_RETURN_IF_ERROR(custom_call->set_backend_config(gpu_backend_config));\n \n   VLOG(1) << \"Replacing convolution \" << conv->ToString() << \" with \"\n           << custom_call->ToString();"
        },
        {
            "sha": "ac4c08bdbe12247979535bf4b6eb44ba8c42acaf",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_custom_call_compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_compiler.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -307,7 +307,7 @@ absl::StatusOr<se::gpu::CudnnGraph> BuildGraphForCustomCallToBackwardFMHA(\n   const bool force_deterministic =\n       RequireDeterminism(custom_call->GetModule()->config());\n   config.set_force_deterministic(force_deterministic);\n-  custom_call->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(custom_call->set_backend_config(gpu_config));\n \n   TF_ASSIGN_OR_RETURN(\n       MatmulTensorDescriptor q,\n@@ -432,7 +432,7 @@ absl::StatusOr<se::gpu::CudnnGraph> BuildGraphForCustomCallToBackwardFMHAF8(\n   // 3 gradients, 4 amaxs and one workspace\n   TF_RET_CHECK(8 == custom_call->shape().tuple_shapes().size());\n \n-  custom_call->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(custom_call->set_backend_config(gpu_config));\n \n   TF_ASSIGN_OR_RETURN(CudnnfMHAMaskKind cudnn_mask_type,\n                       AsCudnnFmhaMaskKind(config.mask_type()));"
        },
        {
            "sha": "71ed08c41fab7b8e56bf6127f13b5a570e791602",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_custom_call_converter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_converter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_converter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_custom_call_converter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -47,7 +47,7 @@ class CustomCallVisitor : public DfsHloRewriteVisitor {\n     FusionBackendConfig &backend_config =\n         *gpu_config.mutable_fusion_backend_config();\n     backend_config.set_kind(hlo->custom_call_target());\n-    fusion->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(fusion->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(ReplaceInstruction(hlo, fusion));\n     return absl::OkStatus();\n   }"
        },
        {
            "sha": "ee7b9c91398d0e4bc40243203a938b4b4adfb7c8",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_fused_conv_rewriter.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fused_conv_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fused_conv_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fused_conv_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -355,7 +355,7 @@ absl::StatusOr<bool> FuseConvAlpha(HloComputation* comp) {\n \n     TF_ASSIGN_OR_RETURN(Literal alpha_f64, alpha->literal().Convert(F64));\n     config.set_conv_result_scale(alpha_f64.GetFirstElement<double>());\n-    conv->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(conv->parent()->ReplaceInstruction(instr, gte));\n \n     changed = true;\n@@ -943,7 +943,7 @@ absl::StatusOr<bool> F8GraphConv(HloComputation* comp,\n               ShapeUtil::MakeTupleShape(output_shapes), operands));\n \n       new_convolution->set_custom_call_target(kCudnnConvForwardGraphCallTarget);\n-      new_convolution->set_backend_config(gpu_config);\n+      TF_RETURN_IF_ERROR(new_convolution->set_backend_config(gpu_config));\n       TF_ASSIGN_OR_RETURN(HloInstruction * new_gte,\n                           MakeGetTupleElementHlo(new_convolution, 0));\n       TF_RETURN_IF_ERROR(comp->ReplaceInstruction(final_instr, new_gte));\n@@ -1055,7 +1055,7 @@ absl::StatusOr<bool> FuseBiasOrSideInput(HloComputation* comp) {\n     HloInstruction* new_conv = comp->AddInstruction(\n         conv->CloneWithNewOperands(conv->shape(), new_operands));\n     comp->parent()->SetAndUniquifyInstrName(new_conv, conv->name());\n-    new_conv->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(new_conv->set_backend_config(gpu_config));\n     TF_ASSIGN_OR_RETURN(HloInstruction * new_instr,\n                         MakeGetTupleElementHlo(new_conv, 0));\n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, new_instr));\n@@ -1173,7 +1173,7 @@ absl::StatusOr<bool> FuseSideInputAlpha(HloComputation* comp) {\n \n     TF_ASSIGN_OR_RETURN(Literal alpha_f64, alpha->literal().Convert(F64));\n     config.set_side_input_scale(alpha_f64.GetFirstElement<double>());\n-    new_conv->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(new_conv->set_backend_config(gpu_config));\n \n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(conv, new_conv));\n     changed = true;\n@@ -1238,7 +1238,7 @@ absl::StatusOr<bool> FuseElu(HloComputation* comp,\n     }\n     TF_ASSIGN_OR_RETURN(conv, EnsureIsConvBiasActivation(conv));\n     config.set_activation_mode(se::dnn::kElu);\n-    conv->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, gte1));\n     changed = true;\n   }\n@@ -1275,7 +1275,7 @@ absl::StatusOr<bool> FuseRelu(HloComputation* comp) {\n     }\n     TF_ASSIGN_OR_RETURN(conv, EnsureIsConvBiasActivation(conv));\n     config.set_activation_mode(se::dnn::kRelu);\n-    conv->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, gte));\n     changed = true;\n   }\n@@ -1324,7 +1324,7 @@ absl::StatusOr<bool> FuseRelu6(HloComputation* comp,\n     }\n     TF_ASSIGN_OR_RETURN(conv, EnsureIsConvBiasActivation(conv));\n     config.set_activation_mode(se::dnn::kRelu6);\n-    conv->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, gte));\n     changed = true;\n   }\n@@ -1385,7 +1385,7 @@ absl::StatusOr<bool> FuseLeakyRelu(HloComputation* comp,\n     config.set_activation_mode(se::dnn::kLeakyRelu);\n     TF_ASSIGN_OR_RETURN(Literal alpha_f64, alpha->literal().Convert(F64));\n     config.set_leakyrelu_alpha(alpha_f64.GetFirstElement<double>());\n-    conv->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(comp->ReplaceInstruction(instr, gte1));\n     changed = true;\n   }"
        },
        {
            "sha": "d3287bb27e4f8f707b5a5428f42992465971c649",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_fusion_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -709,7 +709,7 @@ class CuDnnFusionVisitor : public DfsHloRewriteVisitor {\n             gpu_config.mutable_fusion_backend_config()\n                 ->mutable_cudnn_fusion_config();\n         cudnn_config->set_plan_id(plan_id);\n-        hlo->set_backend_config(gpu_config);\n+        TF_RETURN_IF_ERROR(hlo->set_backend_config(gpu_config));\n       }\n       return graph;\n     };"
        },
        {
            "sha": "6780846350a3dd0d5f7c671dede45c5868794855",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_norm_rewriter.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_norm_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_norm_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_norm_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -1058,7 +1058,7 @@ class CudnnNormRewriterVisitor : public DfsHloRewriteVisitor {\n           instr->AddInstruction(HloInstruction::CreateCustomCall(\n               custom_call_shape, {x_reshape, scale_reshape, bias_reshape},\n               kCudnnNormCallTarget));\n-      custom_call->set_backend_config(gpu_backend_config);\n+      TF_RETURN_IF_ERROR(custom_call->set_backend_config(gpu_backend_config));\n \n       TF_ASSIGN_OR_RETURN(HloInstruction * gte,\n                           MakeGetTupleElementHlo(custom_call, 0));\n@@ -1174,7 +1174,8 @@ class CudnnNormRewriterVisitor : public DfsHloRewriteVisitor {\n       const int64_t workspace_size = (2 * c_constant * (4 + 256)) + 32;\n       backend_config.mutable_algorithm()->mutable_workspace_size()->set_value(\n           workspace_size);\n-      new_custom_call->set_backend_config(gpu_backend_config);\n+      TF_RETURN_IF_ERROR(\n+          new_custom_call->set_backend_config(gpu_backend_config));\n \n       auto replace_with_new_cc = [new_custom_call, this](\n                                      HloInstruction* old_instr,\n@@ -1455,7 +1456,7 @@ class CudnnNormRewriterVisitor : public DfsHloRewriteVisitor {\n               {x.instr(), scale.instr(), reshaped_dy, fused_expectation.instr(),\n                fused_norm_factor.instr()},\n               kCudnnNormCallTarget));\n-      custom_call->set_backend_config(gpu_backend_config);\n+      TF_RETURN_IF_ERROR(custom_call->set_backend_config(gpu_backend_config));\n \n       auto replace_with_cc = [custom_call, norm_metadata, transposed_dy, this](\n                                  HloInstruction* old_instr,"
        },
        {
            "sha": "33ef6df65dbc9cd3d414fa7b2e681c62c59ccfbe",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_vectorize_convolutions.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -283,7 +283,7 @@ absl::Status ReorderInt8NchwVect(HloCustomCallInstruction* conv,\n   CudnnConvBackendConfig& config =\n       *gpu_config.mutable_cudnn_conv_backend_config();\n   config.set_reordered_int8_nchw_vect(true);\n-  conv->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n \n   // Reorder the filter.\n   TF_ASSIGN_OR_RETURN(Shape filter_shape, builder->GetShape(operands[1]));"
        },
        {
            "sha": "223b0338c3c38b56db741ad6a63c7c09e4491a3a",
            "filename": "third_party/xla/xla/service/gpu/transforms/custom_kernel_fusion_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcustom_kernel_fusion_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcustom_kernel_fusion_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcustom_kernel_fusion_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -176,7 +176,7 @@ absl::StatusOr<HloInstruction*> CreateFusionInstruction(\n   backend_config.set_kind(\"__custom_fusion\");\n   *backend_config.mutable_custom_fusion_config() = match.config();\n   backend_config.mutable_custom_fusion_config()->set_kernel_index(kernel_index);\n-  fusion->set_backend_config(std::move(gpu_config));\n+  TF_RETURN_IF_ERROR(fusion->set_backend_config(std::move(gpu_config)));\n \n   // If we don't have workspace we can return constructed fusion instruction.\n   if (match.workspace_size_bytes() == 0) return fusion;"
        },
        {
            "sha": "3a6d2425d5e0bd9ba57828e12062931617ac3d24",
            "filename": "third_party/xla/xla/service/gpu/transforms/double_buffer_loop_unrolling.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdouble_buffer_loop_unrolling.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdouble_buffer_loop_unrolling.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdouble_buffer_loop_unrolling.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -376,7 +376,7 @@ absl::StatusOr<bool> FullyUnroll(HloInstruction* while_instr,\n \n   WhileLoopBackendConfig new_config;\n   new_config.mutable_known_trip_count()->set_n(1);\n-  while_instr->set_backend_config(new_config);\n+  TF_RETURN_IF_ERROR(while_instr->set_backend_config(new_config));\n \n   return changed;\n }\n@@ -532,7 +532,7 @@ absl::StatusOr<bool> DoubleBufferingUnroll(HloInstruction* while_instr,\n         config.known_init_step().init() + (peel_one_iteration ? step : 0));\n   }\n \n-  while_instr->set_backend_config(new_config);\n+  TF_RETURN_IF_ERROR(while_instr->set_backend_config(new_config));\n   return true;  // changed\n }\n "
        },
        {
            "sha": "cd6afabd44c7e6aea5e644355b0bfc64d6f8cc5d",
            "filename": "third_party/xla/xla/service/gpu/transforms/dynamic_slice_fusion_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdynamic_slice_fusion_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdynamic_slice_fusion_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fdynamic_slice_fusion_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -235,7 +235,7 @@ absl::StatusOr<HloInstruction*> CreateFusionInstruction(\n       dynamic ? kDynamicSliceFusionWithDynamicAddressComputationConfigName\n               : kDynamicSliceFusionWithStaticAddressComputationConfigName));\n   *backend_config.mutable_custom_fusion_config() = config;\n-  fusion->set_backend_config(std::move(gpu_config));\n+  TF_RETURN_IF_ERROR(fusion->set_backend_config(std::move(gpu_config)));\n \n   return fusion;\n }"
        },
        {
            "sha": "1555e48a4d6bd8b797f44d13efd5c7653d4776a4",
            "filename": "third_party/xla/xla/service/gpu/transforms/explicit_stream_annotation_async_wrapper.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fexplicit_stream_annotation_async_wrapper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fexplicit_stream_annotation_async_wrapper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fexplicit_stream_annotation_async_wrapper.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -69,7 +69,7 @@ static absl::StatusOr<bool> AsynchronizeInstruction(HloInstruction* instr) {\n   // Set earliest schedule of done op to be false so it can be scheduled\n   // far apart from start.\n   gpu_config.set_force_earliest_schedule(false);\n-  done->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(done->set_backend_config(gpu_config));\n   VLOG(5) << \"Created async instruction: \" << done->ToString();\n   return true;\n }"
        },
        {
            "sha": "b4cffdcf48d46f9a55805f721579c50167012009",
            "filename": "third_party/xla/xla/service/gpu/transforms/fusion_block_level_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -229,7 +229,7 @@ absl::StatusOr<bool> ProcessFusionInstruction(\n        ->mutable_block_level_fusion_config() =\n       tiled_runtime_data.block_level_parameters.ToBlockLevelFusionConfig();\n   backend_config.mutable_fusion_backend_config()->set_kind(kTritonFusionKind);\n-  fusion_instruction->set_backend_config(backend_config);\n+  TF_RETURN_IF_ERROR(fusion_instruction->set_backend_config(backend_config));\n   fusion_instruction->set_fusion_kind(HloInstruction::FusionKind::kCustom);\n   return true;\n }"
        },
        {
            "sha": "fb1e4b4d99a3919d3c71e97389b9b114109353c6",
            "filename": "third_party/xla/xla/service/gpu/transforms/fusion_dynamic_memcpy_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_dynamic_memcpy_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_dynamic_memcpy_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_dynamic_memcpy_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -293,7 +293,7 @@ absl::StatusOr<bool> FusionDynamicMemcpyRewriter::Run(\n       }\n     }\n \n-    fusion->set_backend_config(backend_config);\n+    TF_RETURN_IF_ERROR(fusion->set_backend_config(backend_config));\n     has_changed = true;\n   }\n "
        },
        {
            "sha": "dceb042dfd7443141cc8aa81068787e4965babd5",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_broadcast_folding_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_broadcast_folding_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_broadcast_folding_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_broadcast_folding_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -95,7 +95,7 @@ class GemmBroadcastFoldingVisitor : public DfsHloRewriteVisitor {\n       }\n       TF_RETURN_IF_ERROR(existing_gemm->ReplaceOperandWithDifferentShape(\n           bcast_operand_index, bcast->mutable_operand(0)));\n-      existing_gemm->set_backend_config(gpu_config);\n+      TF_RETURN_IF_ERROR(existing_gemm->set_backend_config(gpu_config));\n       MarkAsChanged();\n     }\n     return absl::OkStatus();"
        },
        {
            "sha": "e078b6cf816b4d98f04a3021b267b41fc4ed9a72",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_fusion.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -806,7 +806,7 @@ class GemmFusionVisitor : public DfsHloRewriteVisitor {\n     FusionBackendConfig& backend_config =\n         *gpu_config.mutable_fusion_backend_config();\n     backend_config.set_kind(std::string(kTritonGemmFusionKind));\n-    dot_fusion->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(dot_fusion->set_backend_config(gpu_config));\n \n     if (fusion_output->IsRoot()) {\n       fusion_output->parent()->set_root_instruction(dot_fusion);\n@@ -849,7 +849,7 @@ class GemmFusionVisitor : public DfsHloRewriteVisitor {\n     FusionBackendConfig& backend_config =\n         *gpu_config.mutable_fusion_backend_config();\n     backend_config.set_kind(\"__triton_ragged_dot\");\n-    dot_fusion->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(dot_fusion->set_backend_config(gpu_config));\n \n     TF_RETURN_IF_ERROR(ReplaceInstruction(ragged_dot, dot_fusion));\n     MarkAsChanged();\n@@ -890,7 +890,7 @@ class GemmFusionVisitor : public DfsHloRewriteVisitor {\n     FusionBackendConfig& backend_config =\n         *gpu_config.mutable_fusion_backend_config();\n     backend_config.set_kind(kTritonScaledDotFusionKind);\n-    fusion->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(fusion->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(ReplaceInstruction(scaled_dot, fusion));\n     MarkAsChanged();\n     return absl::OkStatus();"
        },
        {
            "sha": "d23e1205d3a65e99b466d0105a802156d5d3240d",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_rewriter.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -688,7 +688,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n                   output_shape,\n                   {instr->mutable_operand(0), instr->mutable_operand(1)},\n                   gemm_custom_call_target));\n-          gemm_call->set_backend_config(gpu_backend_config);\n+          TF_RETURN_IF_ERROR(gemm_call->set_backend_config(gpu_backend_config));\n           TF_RETURN_IF_ERROR(ReplaceInstruction(instr, gemm_call));\n         }\n       } break;\n@@ -715,7 +715,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n     HloInstruction *gemm_call =\n         instr->AddInstruction(HloInstruction::CreateCustomCall(\n             output_shape, {lhs_convert, rhs_convert}, gemm_custom_call_target));\n-    gemm_call->set_backend_config(gpu_backend_config);\n+    TF_RETURN_IF_ERROR(gemm_call->set_backend_config(gpu_backend_config));\n     TF_RETURN_IF_ERROR(ReplaceInstruction(instr, gemm_call));\n     return absl::OkStatus();\n   }\n@@ -741,7 +741,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n             *alpha->literal().GetAsComplex128({}) * prev_alpha;\n         config.set_alpha_real(new_alpha.real());\n         config.set_alpha_imag(new_alpha.imag());\n-        existing_gemm->set_backend_config(gpu_config);\n+        TF_RETURN_IF_ERROR(existing_gemm->set_backend_config(gpu_config));\n         return ReplaceInstruction(instr, existing_gemm);\n       }\n     }\n@@ -1408,7 +1408,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n                 instr->shape().element_type(), new_output_shape.dimensions(),\n                 instr->shape().layout().minor_to_major()),\n             operands_list, kCublasLtMatmulF8CallTarget));\n-    new_custom_call->set_backend_config(gpu_backend_config);\n+    TF_RETURN_IF_ERROR(new_custom_call->set_backend_config(gpu_backend_config));\n     TF_RETURN_IF_ERROR(SetName(instr->GetModule(), new_custom_call));\n \n     // Slice the result of the GEMM if the operands were padded.\n@@ -1611,7 +1611,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n                         gemm_and_damax->backend_config<GpuBackendConfig>());\n     GemmBackendConfig &config = *gpu_config.mutable_gemm_backend_config();\n     config.set_damax_output(true);\n-    gemm_and_damax->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(gemm_and_damax->set_backend_config(gpu_config));\n \n     // Obtain D and DAmax separately from the output tuple.\n     HloInstruction *d =\n@@ -1724,7 +1724,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n         gemm->CloneWithNewOperands(gemm->shape(), operands);\n     // set output shape to bias shape if mix type\n     fused_op->mutable_shape()->set_element_type(bias->shape().element_type());\n-    fused_op->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(fused_op->set_backend_config(gpu_config));\n \n     // Choose whether the bias must alias the output. Legacy cublas GEMMs must\n     // operate in place and alias the bias with the output, whereas with\n@@ -1878,7 +1878,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n     HloInstruction *result = computation->AddInstruction(\n         gemm->CloneWithNewOperands(gemm->shape(), operands));\n \n-    result->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(result->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(SetName(gemm->GetModule(), result));\n     if (slice) {\n       result = computation->AddInstruction(\n@@ -1922,7 +1922,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n \n     HloComputation *computation = gemm->parent();\n     HloInstruction *result = computation->AddInstruction(gemm->Clone());\n-    result->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(result->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(SetName(gemm->GetModule(), result));\n \n     if (slice_or_bitcast) {\n@@ -1970,7 +1970,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n     std::unique_ptr<HloInstruction> output = gemm->CloneWithNewShape(\n         has_aux ? ShapeUtil::MakeTupleShape({gemm->shape(), gemm->shape()})\n                 : gemm->shape());\n-    output->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(output->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(SetName(multiply->GetModule(), output.get()));\n \n     if (slice_or_bitcast) {\n@@ -2024,7 +2024,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n     std::unique_ptr<HloInstruction> output = gemm->CloneWithNewShape(\n         has_aux ? ShapeUtil::MakeTupleShape({gemm->shape(), gemm->shape()})\n                 : gemm->shape());\n-    output->set_backend_config(gpu_config);\n+    TF_RETURN_IF_ERROR(output->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(SetName(multiply->GetModule(), output.get()));\n \n     if (slice_or_bitcast) {"
        },
        {
            "sha": "fa582eb58adfea7170055c5dad0387080b10604c",
            "filename": "third_party/xla/xla/service/gpu/transforms/gpusolver_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgpusolver_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgpusolver_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgpusolver_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -105,7 +105,7 @@ absl::StatusOr<HloInstruction*> CreateCholesky(\n       computation->AddInstruction(HloInstruction::CreateCustomCall(\n           call_shape, {operand}, kCusolverCholeskyCallTarget, {a_shape}));\n   custom_call->set_metadata(metadata);\n-  custom_call->set_backend_config(options);\n+  TF_RETURN_IF_ERROR(custom_call->set_backend_config(options));\n   HloInstruction* out = computation->AddInstruction(\n       HloInstruction::CreateGetTupleElement(a_shape, custom_call, 0));\n   HloInstruction* info = computation->AddInstruction("
        },
        {
            "sha": "ab265ea2715a815da9ec702451d3c492d0bd7f9b",
            "filename": "third_party/xla/xla/service/gpu/transforms/nest_gemm_fusion.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -144,7 +144,7 @@ absl::Status FuseInstructionsForConsumer(HloInstruction& root,\n                       fusion->backend_config<GpuBackendConfig>());\n   gpu_config.mutable_fusion_backend_config()->set_kind(\n       std::string(kTritonNestedGemmFusionKind));\n-  fusion->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(fusion->set_backend_config(gpu_config));\n \n   for (int64_t operand_index : consumer.OperandIndices(&root)) {\n     TF_RETURN_IF_ERROR(consumer.ReplaceOperandWith(operand_index, fusion));\n@@ -197,7 +197,7 @@ absl::Status AnnotateDotOperandNestedFusionImpl(\n   *gpu_config.mutable_fusion_backend_config()\n        ->mutable_block_level_fusion_config() =\n       block_level_parameters.ToBlockLevelFusionConfig();\n-  nested_fusion.set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(nested_fusion.set_backend_config(gpu_config));\n \n   return absl::OkStatus();\n }\n@@ -298,7 +298,7 @@ absl::Status MakeNestedFusionFromGemmFusion(HloFusionInstruction* fusion,\n \n   *backend_config.mutable_block_level_fusion_config() =\n       block_level_parameters.ToBlockLevelFusionConfig();\n-  fusion->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(fusion->set_backend_config(gpu_config));\n \n   return absl::OkStatus();\n }"
        },
        {
            "sha": "b52ad2d5721377e2676fbec83020dfc8c675ee1d",
            "filename": "third_party/xla/xla/service/gpu/transforms/priority_fusion.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fpriority_fusion.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -1197,8 +1197,8 @@ absl::StatusOr<bool> PriorityFusion::Run(\n             Fuse(producer, consumer, use_multi_output_fusion);\n         auto backend_config_it = block_level_parameters_map.find(consumer);\n         if (backend_config_it != block_level_parameters_map.end()) {\n-          fusion_instruction->set_backend_config(\n-              GetTritonGpuBackendConfig(backend_config_it->second));\n+          TF_RETURN_IF_ERROR(fusion_instruction->set_backend_config(\n+              GetTritonGpuBackendConfig(backend_config_it->second)));\n           fusion_instruction->set_fusion_kind(\n               HloInstruction::FusionKind::kCustom);\n         }"
        },
        {
            "sha": "45d23fcabd10d02562a1f4110ccc06ed2ed30671",
            "filename": "third_party/xla/xla/service/gpu/transforms/softmax_rewriter_triton.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsoftmax_rewriter_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsoftmax_rewriter_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsoftmax_rewriter_triton.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -254,7 +254,7 @@ absl::StatusOr<HloFusionInstruction*> MakeFusionForDiamond(\n   FusionBackendConfig& backend_config =\n       *gpu_config.mutable_fusion_backend_config();\n   backend_config.set_kind(std::string(kTritonFusionKind));\n-  normalization_fusion->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(normalization_fusion->set_backend_config(gpu_config));\n   return xla::Cast<HloFusionInstruction>(normalization_fusion);\n }\n \n@@ -386,7 +386,7 @@ DecideIfShouldFuseAndMaybeSetBlockLevelParameters(\n   *backend_config.mutable_fusion_backend_config()\n        ->mutable_block_level_fusion_config() =\n       tiled_runtime_data.block_level_parameters.ToBlockLevelFusionConfig();\n-  normalization_fusion->set_backend_config(backend_config);\n+  TF_RETURN_IF_ERROR(normalization_fusion->set_backend_config(backend_config));\n   VLOG(2) << \"Fusing with backend config: \" << backend_config.DebugString();\n \n   return FusionDecision::Allow();"
        },
        {
            "sha": "4fb3098533609eaa600f2f118140eda5fd964079",
            "filename": "third_party/xla/xla/service/gpu/transforms/sort_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsort_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsort_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fsort_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -530,7 +530,7 @@ absl::StatusOr<bool> SortRewriter::RunOnInstruction(\n \n   xla::SortOptions backend_config;\n   backend_config.set_descending(sort_analysis.descending);\n-  custom_call->set_backend_config(backend_config);\n+  TF_RETURN_IF_ERROR(custom_call->set_backend_config(backend_config));\n \n   // Build the replacement instruction.\n   HloInstruction* replacement;"
        },
        {
            "sha": "ce05ad0b770e33fcc72f6cd94289e5a7327e8735",
            "filename": "third_party/xla/xla/service/gpu/transforms/stream_attribute_annotator.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_annotator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_annotator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_annotator.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -87,7 +87,7 @@ absl::StatusOr<bool> AnnotateStreamAttributesForInstruction(\n       comp_root_gpu_config->operation_queue_id());\n   *instr_gpu_config.mutable_wait_on_operation_queues() =\n       comp_root_gpu_config->wait_on_operation_queues();\n-  instr->set_backend_config(instr_gpu_config);\n+  TF_RETURN_IF_ERROR(instr->set_backend_config(instr_gpu_config));\n   return true;\n }\n \n@@ -100,7 +100,7 @@ absl::StatusOr<bool> AnnotateStreamAttributesForCopyStart(\n     return false;\n   }\n   instr_gpu_config.set_operation_queue_id(channel_id);\n-  instr->set_backend_config(instr_gpu_config);\n+  TF_RETURN_IF_ERROR(instr->set_backend_config(instr_gpu_config));\n   VLOG(3) << \"Add copy-start's backend config: \" << channel_id;\n   return true;\n }\n@@ -139,7 +139,7 @@ absl::StatusOr<bool> WrapIntoFusionAndAnnotateStreamAttributes(\n   TF_RETURN_IF_ERROR(computation->RemoveInstruction(instruction));\n \n   instr_gpu_config.set_operation_queue_id(channel_id);\n-  fusion_instruction->set_backend_config(instr_gpu_config);\n+  TF_RETURN_IF_ERROR(fusion_instruction->set_backend_config(instr_gpu_config));\n   VLOG(3) << \"Add async stream \" << channel_id << \" and wrapped instruction \"\n           << instruction->ToString();\n   VLOG(3) << \"  Fusion wrapper: \" << fusion_instruction->ToString();\n@@ -168,7 +168,7 @@ absl::StatusOr<bool> AnnotateStreamAttributesForUsers(\n     if (it == gpu_config.wait_on_operation_queues().end() &&\n         gpu_config.operation_queue_id() != stream_id) {\n       gpu_config.mutable_wait_on_operation_queues()->Add(stream_id);\n-      user->set_backend_config(gpu_config);\n+      TF_RETURN_IF_ERROR(user->set_backend_config(gpu_config));\n       changed = true;\n     }\n   }"
        },
        {
            "sha": "6390a9f05f2432a77b6c0a0fbb63f945ee6ef062",
            "filename": "third_party/xla/xla/service/gpu/transforms/stream_attribute_async_wrapper.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_async_wrapper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_async_wrapper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fstream_attribute_async_wrapper.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -48,7 +48,7 @@ static absl::StatusOr<bool> AsynchronizeInstruction(HloInstruction* instr) {\n   // Set the false delay of done op to be false so it can be scheduled\n   // far apart from start.\n   gpu_config.set_force_earliest_schedule(false);\n-  done->set_backend_config(gpu_config);\n+  TF_RETURN_IF_ERROR(done->set_backend_config(gpu_config));\n   VLOG(5) << \"Created async instruction: \" << done->ToString();\n   return true;\n }"
        },
        {
            "sha": "d4562437b0d03ed447088cf0feb816a658c913b5",
            "filename": "third_party/xla/xla/service/gpu/transforms/triangular_solve_rewriter.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriangular_solve_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriangular_solve_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriangular_solve_rewriter.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -68,7 +68,8 @@ absl::StatusOr<bool> TriangularSolveRewriter::Run(\n           comp->AddInstruction(HloInstruction::CreateCustomCall(\n               new_shape, instr->operands(), kTriangularSolveCallTarget));\n       module->SetAndUniquifyInstrName(custom_call, \"triangular-solve\");\n-      custom_call->set_backend_config(instr->triangular_solve_options());\n+      TF_RETURN_IF_ERROR(\n+          custom_call->set_backend_config(instr->triangular_solve_options()));\n \n       // Preserve metadata from `instr`.\n       custom_call->set_metadata(instr->metadata());"
        },
        {
            "sha": "a5945af3c1ca043dac58b135d3d8d7f6eb3c085f",
            "filename": "third_party/xla/xla/service/gpu/transforms/windowed_einsum_handler.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fwindowed_einsum_handler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fwindowed_einsum_handler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fwindowed_einsum_handler.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -331,8 +331,8 @@ absl::Status UpdateDotAndConsumerConfig(HloInstruction* dot,\n     updater_gpu_config->mutable_wait_on_operation_queues()->Add(stream_id);\n   }\n \n-  dot->set_backend_config(dot_gpu_config.value());\n-  updater->set_backend_config(updater_gpu_config.value());\n+  TF_RETURN_IF_ERROR(dot->set_backend_config(dot_gpu_config.value()));\n+  TF_RETURN_IF_ERROR(updater->set_backend_config(updater_gpu_config.value()));\n   return absl::OkStatus();\n }\n \n@@ -342,7 +342,7 @@ absl::Status SetForceDelayForInstruction(HloInstruction* instr,\n \n   gpu_config->set_force_earliest_schedule(force_delay);\n \n-  instr->set_backend_config(gpu_config.value());\n+  TF_RETURN_IF_ERROR(instr->set_backend_config(gpu_config.value()));\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "9390db1dbc6c8e157c401634fd9d0ada70465bf3",
            "filename": "third_party/xla/xla/service/hlo_instruction_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_instruction_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_instruction_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_instruction_test.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -2555,7 +2555,7 @@ TEST_F(HloInstructionTest, BackendConfigCanContainNonFiniteFloats) {\n       *gpu_config.mutable_gemm_backend_config();\n   orig_config.set_alpha_real(std::numeric_limits<double>::infinity());\n   orig_config.set_alpha_imag(std::numeric_limits<double>::quiet_NaN());\n-  dot->set_backend_config(gpu_config);\n+  TF_ASSERT_OK(dot->set_backend_config(gpu_config));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto new_gpu_config,\n                           dot->backend_config<gpu::GpuBackendConfig>());\n@@ -2868,7 +2868,7 @@ TEST_F(HloInstructionTest, BackendConfigCopiedToDerived) {\n \n   gpu::GpuBackendConfig gpu_config;\n   gpu_config.set_operation_queue_id(2);\n-  add->set_backend_config(gpu_config);\n+  TF_ASSERT_OK(add->set_backend_config(gpu_config));\n   auto add2 = b.AddInstruction(\n       HloInstruction::CreateBinary(shape, HloOpcode::kAdd, p0, p0));\n   add->SetupDerivedInstruction(add2);\n@@ -2887,7 +2887,7 @@ TEST_F(HloInstructionTest, BackendConfigNotCopiedToDerivedWithDiffOpcode) {\n \n   gpu::GpuBackendConfig gpu_config;\n   gpu_config.set_operation_queue_id(2);\n-  or1->set_backend_config(gpu_config);\n+  TF_ASSERT_OK(or1->set_backend_config(gpu_config));\n   auto add2 = b.AddInstruction(\n       HloInstruction::CreateBinary(shape, HloOpcode::kAdd, p0, p1));\n   or1->SetupDerivedInstruction(add2);\n@@ -2907,10 +2907,10 @@ TEST_F(HloInstructionTest, BackendConfigNotCopiedToDerivedWithConfig) {\n   gpu_config0.set_operation_queue_id(2);\n   gpu_config1.set_operation_queue_id(3);\n \n-  add->set_backend_config(gpu_config0);\n+  TF_ASSERT_OK(add->set_backend_config(gpu_config0));\n   auto add2 = b.AddInstruction(\n       HloInstruction::CreateBinary(shape, HloOpcode::kAdd, p0, p0));\n-  add2->set_backend_config(gpu_config1);\n+  TF_ASSERT_OK(add2->set_backend_config(gpu_config1));\n \n   add->SetupDerivedInstruction(add2);\n   auto backend_config = add2->backend_config<gpu::GpuBackendConfig>();"
        },
        {
            "sha": "509554d5d268c1608c9e001721d6f2257f45f333",
            "filename": "third_party/xla/xla/tests/hlo_runner_agnostic_test_base.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 5,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Ftests%2Fhlo_runner_agnostic_test_base.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fa2d6ba775109989bce2e0917e1d7dd049ef7173/third_party%2Fxla%2Fxla%2Ftests%2Fhlo_runner_agnostic_test_base.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fhlo_runner_agnostic_test_base.cc?ref=fa2d6ba775109989bce2e0917e1d7dd049ef7173",
            "patch": "@@ -459,8 +459,9 @@ ::testing::AssertionResult HloRunnerAgnosticTestBase::Run(\n     // Set backend configuration if it is given.\n     HloInstruction* instruction =\n         (*module)->entry_computation()->root_instruction();\n-    instruction->set_backend_config(*backend_config);\n-    return ::testing::AssertionSuccess();\n+    absl::Status s = instruction->set_backend_config(*backend_config);\n+    return s.ok() ? ::testing::AssertionSuccess()\n+                  : ::testing::AssertionFailure() << s.message();\n   }\n \n   if (const absl::Status status = PreprocessModuleForTestRunner(module->get());\n@@ -499,7 +500,10 @@ ::testing::AssertionResult HloRunnerAgnosticTestBase::RunReplicated(\n     // Set backend configuration if it is given.\n     HloInstruction* instruction =\n         (*module)->entry_computation()->root_instruction();\n-    instruction->set_backend_config(*backend_config);\n+    if (const absl::Status s = instruction->set_backend_config(*backend_config);\n+        !s.ok()) {\n+      return ::testing::AssertionFailure() << s.message();\n+    }\n     return ::testing::AssertionSuccess();\n   }\n \n@@ -544,8 +548,9 @@ ::testing::AssertionResult HloRunnerAgnosticTestBase::RunMultipleTimes(\n       // Set backend configuration if it is given.\n       HloInstruction* instruction =\n           (*module)->entry_computation()->root_instruction();\n-      instruction->set_backend_config(*backend_config);\n-      return ::testing::AssertionSuccess();\n+      absl::Status s = instruction->set_backend_config(*backend_config);\n+      return s.ok() ? ::testing::AssertionSuccess()\n+                    : ::testing::AssertionFailure() << s.message();\n     }\n \n     if (const absl::Status status ="
        }
    ],
    "stats": {
        "total": 260,
        "additions": 133,
        "deletions": 127
    }
}