{
    "author": "beckerhe",
    "message": "Remove `constexpr` from `DeviceDescription` methods.\n\nThe methods `l1_cache_size_per_SM`, `dram_to_l2_transaction_size_bytes`, and `memory_transactions_per_clock` depend on runtime-determined GPU capabilities, making them unsuitable for `constexpr`.\n\nFixes: #34850\nPiperOrigin-RevId: 840742913",
    "sha": "7de40a9d05c042030020d5880a965d4a37ac8b84",
    "files": [
        {
            "sha": "4174d557438e7b16c57264ae66b6aa720126aef0",
            "filename": "third_party/xla/xla/stream_executor/device_description.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7de40a9d05c042030020d5880a965d4a37ac8b84/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7de40a9d05c042030020d5880a965d4a37ac8b84/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h?ref=7de40a9d05c042030020d5880a965d4a37ac8b84",
            "patch": "@@ -260,7 +260,7 @@ class DeviceDescription {\n   // configured as shared memory; there is no easy way to query its actual size;\n   // also we do not count what occupies cache, but rather claim that what is\n   // much smaller than the cache size will likely stay in it.\n-  constexpr int64_t l1_cache_size_per_SM() const {\n+  int64_t l1_cache_size_per_SM() const {\n     if (auto* capability = gpu_compute_capability_.rocm_compute_capability()) {\n       // MI100 and MI200 has 16KB L1 cache per CU.\n       if (capability->gfx9_mi100() || capability->gfx9_mi200()) {\n@@ -275,7 +275,7 @@ class DeviceDescription {\n     return 2 * 1024;\n   }\n \n-  constexpr int64_t dram_to_l2_transaction_size_bytes() const {\n+  int64_t dram_to_l2_transaction_size_bytes() const {\n     if (auto* capability = gpu_compute_capability_.rocm_compute_capability()) {\n       // DRAM->L2 bus is 128 Byte width for MI300.\n       if (capability->gfx9_mi300_series()) {\n@@ -291,7 +291,7 @@ class DeviceDescription {\n     return 64;\n   }\n \n-  constexpr int64_t memory_transactions_per_clock() const {\n+  int64_t memory_transactions_per_clock() const {\n     if (auto* capability = gpu_compute_capability_.rocm_compute_capability()) {\n       // 16 works well on MI300.\n       if (capability->gfx9_mi300_series()) {"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}