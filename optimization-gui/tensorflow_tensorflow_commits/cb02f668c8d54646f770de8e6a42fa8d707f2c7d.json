{
    "author": "nurmukhametov",
    "message": "PR #34173: [ROCm][XLA:GPU] Rename warp to shmem_group in PackedTranspose\n\nImported from GitHub PR https://github.com/openxla/xla/pull/34173\n\nRename `warp` to `shmem_group` in `PackedTranspose`.\n\nAlso calculate their count as `kNumThreadsPerBlock / kNumShmemBanks` to avoid inconsistency when manually specified.\n\nThis change is NFC for any GPU in upstream. However, it fixes a performance regression in downstream for AMD GPUs caused by inconsistency between `shmem_group size`, `kNumThreadsPerBlock` and `kNumShmemBanks`. It ended up in a situation downstream where half of the launched threads per block were not utilized at all.\n\nUpdate packed transpose tests to verify correct thread utilization.\nCopybara import of the project:\n\n--\n3a0584e21fddb4876c362879b067f1a63248bf66 by Aleksei Nurmukhametov <anurmukh@amd.com>:\n\n[XLA:GPU] Rename warp to shmem_group in PackedTranspose\n\nAlso calculate their count as kNumThreadsPerBlock / kNumShmemBanks to\navoid inconsistency when manually specified.\n\nThis change is NFC for any GPU in upstream. However, it fixes a\nperformance regression in downstream for AMD GPUs caused by\ninconsistency between shmem_group size, kNumThreadsPerBlock and\nkNumShmemBanks. It ended up in a situation downstream where half of the\nlaunched threads per block were not utilized at all.\n\nUpdate packed transpose tests to verify correct thread utilization.\n\nMerging this change closes #34173\n\nPiperOrigin-RevId: 838772668",
    "sha": "cb02f668c8d54646f770de8e6a42fa8d707f2c7d",
    "files": [
        {
            "sha": "b74462c0f40b2c2ed7c7b35e7792b81521b37649",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/transpose/packed_transpose_bf16.hlo",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_bf16.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_bf16.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_bf16.hlo?ref=cb02f668c8d54646f770de8e6a42fa8d707f2c7d",
            "patch": "@@ -6,4 +6,6 @@ fusion {\n   p0 = bf16[30,16,30] parameter(0)\n   ROOT transpose = bf16[30,16,30] transpose(p0), dimensions={2,1,0}\n }\n-// CHECK:  xla_gpu.allocate_shared : tensor<64x64xbf16>\n\\ No newline at end of file\n+// CHECK: #indexing_map{{.*}}domain:{{.*}}th_x in [0, [[N_THREADS:[0-9]+]]]\n+// CHECK: %thread_id_x = gpu.thread_id  x {xla.range = [0 : index, [[N_THREADS]] : index]}\n+// CHECK:  xla_gpu.allocate_shared : tensor<64x64xbf16>"
        },
        {
            "sha": "53f083a500c3836f8818b42fc52e8258a3fe9870",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/transpose/packed_transpose_f16.hlo",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_f16.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_f16.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_f16.hlo?ref=cb02f668c8d54646f770de8e6a42fa8d707f2c7d",
            "patch": "@@ -6,4 +6,6 @@ fusion {\n   p0 = f16[28,2,6,32] parameter(0)\n   ROOT transpose = f16[2,32,6,28] transpose(p0), dimensions={1,3,2,0}\n }\n+// CHECK: #indexing_map{{.*}}domain:{{.*}}th_x in [0, [[N_THREADS:[0-9]+]]]\n+// CHECK: %thread_id_x = gpu.thread_id  x {xla.range = [0 : index, [[N_THREADS]] : index]}\n // CHECK:  xla_gpu.allocate_shared : tensor<64x64xf16>"
        },
        {
            "sha": "4b9a0ef6ebf2cdfb5c485f34d9bb275e5f921641",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/transpose/packed_transpose_s4.hlo",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_s4.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_s4.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_s4.hlo?ref=cb02f668c8d54646f770de8e6a42fa8d707f2c7d",
            "patch": "@@ -7,4 +7,6 @@ fusion {\n   ROOT %transpose= s4[128, 32, 8, 256] transpose(%param_0),\n     dimensions={0,3,2,1}\n }\n+// CHECK: #indexing_map{{.*}}domain:{{.*}}th_x in [0, [[N_THREADS:[0-9]+]]]\n+// CHECK: %thread_id_x = gpu.thread_id  x {xla.range = [0 : index, [[N_THREADS]] : index]}\n // CHECK: xla_gpu.allocate_shared : tensor<256x256xi4>"
        },
        {
            "sha": "f8f309951dfe21df5f4eb1713276f18da28cac7a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/transpose/packed_transpose_s8.hlo",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_s8.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_s8.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_s8.hlo?ref=cb02f668c8d54646f770de8e6a42fa8d707f2c7d",
            "patch": "@@ -6,4 +6,6 @@ fusion {\n   p0 = s8[8,64,68] parameter(0)\n   ROOT transpose = s8[8,68,64] transpose(p0), dimensions={0, 2, 1}\n }\n-// CHECK:  xla_gpu.allocate_shared : tensor<128x128xi8>\n\\ No newline at end of file\n+// CHECK: #indexing_map{{.*}}domain:{{.*}}th_x in [0, [[N_THREADS:[0-9]+]]]\n+// CHECK: %thread_id_x = gpu.thread_id  x {xla.range = [0 : index, [[N_THREADS]] : index]}\n+// CHECK:  xla_gpu.allocate_shared : tensor<128x128xi8>"
        },
        {
            "sha": "3b8cd150b0eb08f8717aefc415c921aaefc6bfc5",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/transpose.cc",
            "status": "modified",
            "additions": 45,
            "deletions": 36,
            "changes": 81,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftranspose.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftranspose.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftranspose.cc?ref=cb02f668c8d54646f770de8e6a42fa8d707f2c7d",
            "patch": "@@ -546,21 +546,22 @@ std::vector<int64_t> GetBlockCounts(absl::Span<const int64_t> shape,\n PackedTranspose::PackedTranspose(const HloFusionAnalysis& analysis,\n                                  const TransposeSpec& spec,\n                                  absl::Span<const int64_t> output_block_tile,\n-                                 int64_t num_warps, MLIRContext* mlir_context)\n+                                 int64_t num_shmem_groups,\n+                                 MLIRContext* mlir_context)\n     : TransposeFusionBase(analysis, mlir_context),\n       spec_(spec),\n       output_tile_(output_block_tile.begin(), output_block_tile.end()),\n       input_tile_(Permute(output_tile_, spec_.canonical_inv_permutation)),\n       block_counts_(GetBlockCounts(spec_.canonical_output_shape, output_tile_)),\n-      num_warps_per_block_(num_warps),\n+      num_shmem_groups_per_block_(num_shmem_groups),\n       tile_size_t1_(input_tile_[spec_.dim_T1_input_id()]),\n       tile_size_a_(input_tile_[spec_.dim_A_id()]),\n       tile_size_t2_(input_tile_[spec_.dim_T2_input_id()]),\n       populated_shmem_cols_(tile_size_a_ * tile_size_t1_),\n       populated_shmem_rows_(tile_size_t2_) {\n   VLOG(5) << \"Transpose spec: \" << spec.ToString()\n           << \"Output block tile: \" << absl::StrJoin(output_block_tile, \", \")\n-          << \"\\nNumber of warps: \" << num_warps << \"\\n\";\n+          << \"\\nNumber of shmem groups: \" << num_shmem_groups << \"\\n\";\n   auto bits_per_element = GetBitwidth(spec_.elem_type());\n   vector_size_ = kBankBitwidth / bits_per_element;\n   CHECK_GE(vector_size_, 1);\n@@ -815,25 +816,27 @@ IndexingMap PackedTranspose::GetInputIndexing(MLIRContext* mlir_context) const {\n       KernelFusionInterface::kIndexingMapThreadIdxDims[0], mlir_context);\n   auto block_id = getAffineDimExpr(\n       KernelFusionInterface::kIndexingMapBlockIdxDims[0], mlir_context);\n-  auto warp_size = kNumShmemBanks;\n-  auto lane_id = thread_id % warp_size;\n-  auto warp_id = thread_id.floorDiv(warp_size);\n-  std::vector<IndexingMap::Variable> dim_vars = DimVarsFromGPUGrid(\n-      {num_warps_per_block_ * warp_size, 1, 1, Product(block_counts_), 1, 1});\n+  auto shmem_group_size = kNumShmemBanks;\n+  auto lane_id = thread_id % shmem_group_size;\n+  auto shmem_group_id = thread_id.floorDiv(shmem_group_size);\n+  std::vector<IndexingMap::Variable> dim_vars =\n+      DimVarsFromGPUGrid({num_shmem_groups_per_block_ * shmem_group_size, 1, 1,\n+                          Product(block_counts_), 1, 1});\n \n   // Range variables.\n   auto loop = getAffineSymbolExpr(0, mlir_context);\n   auto vector_element_id = getAffineSymbolExpr(1, mlir_context);\n   std::vector<IndexingMap::Variable> range_vars = RangeVarsFromTensorSizes(\n-      {{CeilOfRatio(tile_size_t2_, num_warps_per_block_), vector_size_}});\n+      {{CeilOfRatio(tile_size_t2_, num_shmem_groups_per_block_),\n+        vector_size_}});\n \n   // Block offsets.\n   auto block_ids = DelinearizeInBoundsIndex(block_id, block_counts_);\n   absl::c_copy(Permute(block_ids, spec_.canonical_inv_permutation),\n                block_ids.begin());\n \n   // Shmem expressions.\n-  auto shmem_row = loop * num_warps_per_block_ + warp_id;\n+  auto shmem_row = loop * num_shmem_groups_per_block_ + shmem_group_id;\n   auto shmem_col = lane_id * vector_size_ + vector_element_id;\n \n   // Offsets within the block.\n@@ -876,20 +879,21 @@ IndexingMap PackedTranspose::GetShmemWriteIndexing(\n   // Dimensions variables.\n   auto thread_id = getAffineDimExpr(\n       KernelFusionInterface::kIndexingMapThreadIdxDims[0], mlir_context);\n-  auto warp_size = kNumShmemBanks;\n-  auto lane_id = thread_id % warp_size;\n-  auto warp_id = thread_id.floorDiv(warp_size);\n-  std::vector<IndexingMap::Variable> dim_vars = DimVarsFromGPUGrid(\n-      {num_warps_per_block_ * warp_size, 1, 1, Product(block_counts_), 1, 1});\n+  auto shmem_group_size = kNumShmemBanks;\n+  auto lane_id = thread_id % shmem_group_size;\n+  auto shmem_group_id = thread_id.floorDiv(shmem_group_size);\n+  std::vector<IndexingMap::Variable> dim_vars =\n+      DimVarsFromGPUGrid({num_shmem_groups_per_block_ * shmem_group_size, 1, 1,\n+                          Product(block_counts_), 1, 1});\n \n   // Range variables.\n   auto loop = getAffineSymbolExpr(0, mlir_context);\n   auto vector_element_id = getAffineSymbolExpr(1, mlir_context);\n   std::vector<IndexingMap::Variable> range_vars = RangeVarsFromTensorSizes(\n-      {CeilOfRatio(tile_size_t2_, num_warps_per_block_), vector_size_});\n+      {CeilOfRatio(tile_size_t2_, num_shmem_groups_per_block_), vector_size_});\n \n   // Shmem expressions.\n-  auto shmem_row = loop * num_warps_per_block_ + warp_id;\n+  auto shmem_row = loop * num_shmem_groups_per_block_ + shmem_group_id;\n   auto shmem_col = lane_id * vector_size_ + vector_element_id;\n   llvm::SmallVector<std::pair<AffineExpr, Interval>> constraints{\n       {shmem_col, Interval{0, populated_shmem_cols_ - 1}},\n@@ -908,25 +912,27 @@ IndexingMap PackedTranspose::GetShmemReadIndexing(\n   // Dimensions variables.\n   auto thread_id = getAffineDimExpr(\n       KernelFusionInterface::kIndexingMapThreadIdxDims[0], mlir_context);\n-  auto warp_size = kNumShmemBanks;\n-  auto lane_id = thread_id % warp_size;\n-  auto warp_id = thread_id.floorDiv(warp_size);\n-  std::vector<IndexingMap::Variable> dim_vars = DimVarsFromGPUGrid(\n-      {num_warps_per_block_ * warp_size, 1, 1, Product(block_counts_), 1, 1});\n+  auto shmem_group_size = kNumShmemBanks;\n+  auto lane_id = thread_id % shmem_group_size;\n+  auto shmem_group_id = thread_id.floorDiv(shmem_group_size);\n+  std::vector<IndexingMap::Variable> dim_vars =\n+      DimVarsFromGPUGrid({num_shmem_groups_per_block_ * shmem_group_size, 1, 1,\n+                          Product(block_counts_), 1, 1});\n \n   // Range variables.\n   auto loop = getAffineSymbolExpr(0, mlir_context);\n   auto vector_horizontal = getAffineSymbolExpr(1, mlir_context);\n   auto vector_vertical = getAffineSymbolExpr(2, mlir_context);\n   std::vector<IndexingMap::Variable> range_vars = RangeVarsFromTensorSizes(\n       {CeilOfRatio(populated_shmem_cols_,\n-                   (vector_size_ * num_warps_per_block_)),\n+                   (vector_size_ * num_shmem_groups_per_block_)),\n        vector_size_, vector_size_});\n \n   // Shmem expressions.\n   auto shmem_row = lane_id * vector_size_ + vector_vertical;\n-  auto shmem_col = (loop * num_warps_per_block_ + warp_id) * vector_size_ +\n-                   vector_horizontal;\n+  auto shmem_col =\n+      (loop * num_shmem_groups_per_block_ + shmem_group_id) * vector_size_ +\n+      vector_horizontal;\n   llvm::SmallVector<std::pair<AffineExpr, Interval>> constraints{\n       {shmem_col, Interval{0, populated_shmem_cols_ - 1}},\n       {shmem_row, Interval{0, populated_shmem_rows_ - 1}}};\n@@ -946,26 +952,29 @@ IndexingMap PackedTranspose::GetOutputIndexing(\n       KernelFusionInterface::kIndexingMapThreadIdxDims[0], mlir_context);\n   auto block_id = getAffineDimExpr(\n       KernelFusionInterface::kIndexingMapBlockIdxDims[0], mlir_context);\n-  auto warp_size = kNumShmemBanks;\n-  auto lane_id = thread_id % warp_size;\n-  auto warp_id = thread_id.floorDiv(warp_size);\n-  std::vector<IndexingMap::Variable> dim_vars = DimVarsFromGPUGrid(\n-      {num_warps_per_block_ * warp_size, 1, 1, Product(block_counts_), 1, 1});\n+  auto shmem_group_size = kNumShmemBanks;\n+  auto lane_id = thread_id % shmem_group_size;\n+  auto shmem_group_id = thread_id.floorDiv(shmem_group_size);\n+  std::vector<IndexingMap::Variable> dim_vars =\n+      DimVarsFromGPUGrid({num_shmem_groups_per_block_ * shmem_group_size, 1, 1,\n+                          Product(block_counts_), 1, 1});\n \n   // Range variables.\n   auto loop = getAffineSymbolExpr(0, mlir_context);\n   auto vector_horizontal = getAffineSymbolExpr(1, mlir_context);\n   auto vector_vertical = getAffineSymbolExpr(2, mlir_context);\n   std::vector<IndexingMap::Variable> range_vars = RangeVarsFromTensorSizes(\n-      {CeilOfRatio(populated_shmem_cols_, vector_size_ * num_warps_per_block_),\n+      {CeilOfRatio(populated_shmem_cols_,\n+                   vector_size_ * num_shmem_groups_per_block_),\n        vector_size_, vector_size_});\n \n   // Block offsets.\n   auto block_ids = DelinearizeInBoundsIndex(block_id, block_counts_);\n \n   // Shmem expressions.\n-  auto shmem_col = (loop * num_warps_per_block_ + warp_id) * vector_size_ +\n-                   vector_horizontal;\n+  auto shmem_col =\n+      (loop * num_shmem_groups_per_block_ + shmem_group_id) * vector_size_ +\n+      vector_horizontal;\n   auto shmem_row = lane_id * vector_size_ + vector_vertical;\n \n   // Offsets within the block.\n@@ -1008,9 +1017,9 @@ std::unique_ptr<EmitterBase> CreateTransposeFusion(\n       Cast<HloTransposeInstruction>(analysis.tiled_transpose().instr));\n   auto packed_transpose_tile = GetPackedTransposeTileSizes(spec);\n   if (packed_transpose_tile.ok()) {\n-    return std::make_unique<PackedTranspose>(analysis, spec,\n-                                             *packed_transpose_tile,\n-                                             /* num_warps= */ 4, mlir_context);\n+    return std::make_unique<PackedTranspose>(\n+        analysis, spec, *packed_transpose_tile,\n+        kNumThreadsPerBlock / kNumShmemBanks, mlir_context);\n   }\n   return std::make_unique<TransposeFusion>(analysis, mlir_context);\n }"
        },
        {
            "sha": "e3a8091c07f95f1aa552ff9466251feb18307386",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/transpose.h",
            "status": "modified",
            "additions": 20,
            "deletions": 12,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftranspose.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb02f668c8d54646f770de8e6a42fa8d707f2c7d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftranspose.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftranspose.h?ref=cb02f668c8d54646f770de8e6a42fa8d707f2c7d",
            "patch": "@@ -199,19 +199,24 @@ class TransposeFusion : public TransposeFusionBase {\n //    slice of shared memory.\n //\n // 5. Every GPU block gets a single 64 x 10 x 6 x bf16 tile.\n-//    The tile is read by `num_warps_per_block` warps.\n-//    Let's assume that there are 4 warps per block. In this case, on every\n-//    iteration each warp will read 10 x 6 x bf16 elements, i.e. every thread\n-//    (30 out of 32) performs a vector load of 2 x bf16 and stores it to the\n-//    shared memory. In total, there will be 16 iterations performed by each\n-//    block.\n+//    The tile is read by `num_shmem_groups_per_block` shmem groups.\n+//    Let's assume that there are 4 shmem groups per block. In this case, on\n+//    every iteration each shmem group will read 10 x 6 x bf16 elements, i.e.\n+//    every thread (30 out of 32) performs a vector load of 2 x bf16 and stores\n+//    it to the shared memory. In total, there will be 16 iterations performed\n+//    by each block.\n+//\n+//    Note: When the hardware warp size equals kNumShmemBanks (32), then\n+//    num_shmem_groups_per_block equals the number of warps per block. This is\n+//    the case for NVIDIA GPUs, but not always for AMD GPUs where warp size\n+//    can differ (64).\n //\n //    The following code snippet shows how the data is read from the input\n //    tensor into the shared memory:\n //\n-//    for I = 0 to CEIL(shmem_rows, num_warps_per_block):\n+//    for I = 0 to CEIL(shmem_rows, num_shmem_groups_per_block):\n //      for J = 0 to VECTOR_SIZE:\n-//        ROW = WARP_ID + NUM_WARPS * I\n+//        ROW = SHMEM_GROUP_ID + NUM_SHMEM_GROUPS * I\n //        COL = LANE_ID * VECTOR_SIZE + J\n //        SHMEM[ROW, COL] = INPUT[ROW, COL / 10, COL % 10]\n //\n@@ -220,7 +225,7 @@ class TransposeFusion : public TransposeFusionBase {\n // 6. Each thread reads a VECTOR_SIZE x VECTOR_SIZE x bf16 tile from the shared\n //    memory and performs the write of each of the columns of the tile.\n //\n-//    for I = 0 to CEIL(shmem_cols, VECTOR_SIZE * num_warps_per_block):\n+//    for I = 0 to CEIL(shmem_cols, VECTOR_SIZE * num_shmem_groups_per_block):\n //      VECTOR_2D = arith.constant dense<0>\n //        : vector<VECTOR_SIZE x VECTOR_SIZE x bf16>\n //      for J = 0 to VECTOR_SIZE:\n@@ -234,7 +239,8 @@ class PackedTranspose : public TransposeFusionBase {\n   explicit PackedTranspose(const HloFusionAnalysis& analysis,\n                            const TransposeSpec& spec,\n                            absl::Span<const int64_t> output_block_tile,\n-                           int64_t num_warps, mlir::MLIRContext* mlir_context);\n+                           int64_t num_shmem_groups,\n+                           mlir::MLIRContext* mlir_context);\n \n   LaunchDimensions launch_dimensions() const override;\n \n@@ -281,8 +287,10 @@ class PackedTranspose : public TransposeFusionBase {\n   // Vector size in elements.\n   int64_t vector_size_;\n \n-  // Number of warps per block.\n-  int64_t num_warps_per_block_;\n+  // Number of shmem groups per block. Each shmem group consists of 32 threads\n+  // (kNumShmemBanks), chosen to match the number of shared memory banks for\n+  // optimal memory access patterns. This is independent of hardware warp size.\n+  int64_t num_shmem_groups_per_block_;\n \n   // Tile sizes for the canonicalical dimensions\n   // [T2, A, T1, 1] -> [T1, A, T2, 1]."
        }
    ],
    "stats": {
        "total": 125,
        "additions": 75,
        "deletions": 50
    }
}