{
    "author": "penpornk",
    "message": "[xla:cpu:ynn] Enable rewriting elementwise op fusions with YNNPACK.\n\n+ Update library_rewriter_test to match.\n\nPiperOrigin-RevId: 843473334",
    "sha": "a3d2213eb0da1387b15ce781d62e550b6839f864",
    "files": [
        {
            "sha": "d1d0503dc032b88457df47d898e3fda4b82200e6",
            "filename": "third_party/xla/xla/backends/cpu/transforms/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3d2213eb0da1387b15ce781d62e550b6839f864/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3d2213eb0da1387b15ce781d62e550b6839f864/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD?ref=a3d2213eb0da1387b15ce781d62e550b6839f864",
            "patch": "@@ -22,7 +22,7 @@ cc_library(\n     name = \"library_rewriter\",\n     srcs = [\"library_rewriter.cc\"],\n     hdrs = [\"library_rewriter.h\"],\n-    defines = if_graph_api([\"XLA_ONEDNN_USE_GRAPH_API=1\"]),\n+    defines = if_graph_api([\"XLA_ONEDNN_USE_GRAPH_API=1\"]) + if_ynnpack([\"XLA_YNNPACK\"]),\n     deps = [\n         \":library_matcher\",\n         \":onednn_matcher\",\n@@ -49,7 +49,7 @@ cc_library(\n xla_cc_test(\n     name = \"library_rewriter_test\",\n     srcs = [\"library_rewriter_test.cc\"],\n-    local_defines = if_graph_api([\"XLA_ONEDNN_USE_GRAPH_API=1\"]),\n+    local_defines = if_graph_api([\"XLA_ONEDNN_USE_GRAPH_API=1\"]) + if_ynnpack([\"XLA_YNNPACK\"]),\n     deps = [\n         \":library_rewriter\",\n         \"//xla:xla_data_proto_cc\","
        },
        {
            "sha": "4d050182773bd671574d0c867be33a91eefaecad",
            "filename": "third_party/xla/xla/backends/cpu/transforms/library_rewriter_test.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 23,
            "changes": 54,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3d2213eb0da1387b15ce781d62e550b6839f864/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_rewriter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3d2213eb0da1387b15ce781d62e550b6839f864/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_rewriter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_rewriter_test.cc?ref=a3d2213eb0da1387b15ce781d62e550b6839f864",
            "patch": "@@ -64,7 +64,7 @@ class CpuLibraryTest : public TargetMachineTestBase {\n \n   static const DotRewriteTestSpec& GetDefaultTestSpec() {\n     static const absl::NoDestructor<DotRewriteTestSpec> kDefaultTestSpec(\n-        {\"xnn\", \"f32\", \"f32\", \"znver3\", \"+avx,+avx2\", \"dot\"});\n+        {\"ynn\", \"f32\", \"f32\", \"znver3\", \"+avx,+avx2\", \"dot\"});\n     return *kDefaultTestSpec;\n   }\n \n@@ -158,15 +158,22 @@ class CpuLibraryFullParamTest\n     RunTestInternal(GetParam(), hlo_template, expected);\n   }\n \n+  // Manually update expected dtype support for each library.\n   bool IsDotEnabledOnCPU() {\n     DotRewriteTestSpec spec = GetParam();\n-    bool bf16_dot_supported = absl::StrContains(spec.features, \"+avx512bf16\");\n-    bool fp16_dot_supported = absl::StrContains(spec.features, \"+avx512fp16\");\n+    EXPECT_TRUE(spec.lib == \"onednn\" || spec.lib == \"ynn\");\n+\n+    if (spec.lib == \"ynn\") {\n+      return (spec.in_dtype == \"f32\" || spec.in_dtype == \"bf16\");\n+    }\n+\n     if (spec.in_dtype == \"bf16\") {\n-      return bf16_dot_supported;\n+      return absl::StrContains(spec.features, \"+avx512bf16\") ||\n+             absl::StrContains(spec.features, \"+amx_bf16\");\n     }\n     if (spec.in_dtype == \"f16\") {\n-      return fp16_dot_supported;\n+      return absl::StrContains(spec.features, \"+avx512fp16\") ||\n+             absl::StrContains(spec.features, \"+amx_fp16\");\n     }\n     return true;\n   }\n@@ -259,7 +266,7 @@ TEST_P(CpuLibraryFullParamTest, MatMulDimSizeUnqual) {\n \n   DotRewriteTestSpec spec = GetParam();\n   FusionProperties expected = {HloOpcode::kDot, 0, 0, false};\n-  if (spec.lib == \"xnn\" && IsDotEnabledOnCPU()) {\n+  if (spec.lib == \"ynn\" && IsDotEnabledOnCPU()) {\n     expected = FusionProperties{HloOpcode::kDot, 2, 3, true};\n   }\n   RunTest(hlo_template, expected);\n@@ -307,8 +314,8 @@ TEST_P(CpuLibraryFullParamTest, MatMulAddSubMulSameInputs) {\n   DotRewriteTestSpec spec = GetParam();\n   FusionProperties expected = {HloOpcode::kMultiply, 0, 0, false};\n   if (IsDotEnabledOnCPU()) {\n-    // {Dot, Add, Sub, Mul} for XNN, {Dot, Add} for oneDNN.\n-    expected = spec.lib == \"xnn\"\n+    // {Dot, Add, Sub, Mul} for YNN, {Dot, Add} for oneDNN.\n+    expected = spec.lib == \"ynn\"\n                    ? FusionProperties{HloOpcode::kMultiply, 3, 7, true}\n                    : FusionProperties{HloOpcode::kAdd, 3, 5, true};\n   } else if (spec.fusion_mode == \"greedy\") {\n@@ -338,8 +345,8 @@ TEST_P(CpuLibraryFullParamTest, MatMulAddSubMulDifferentInputs) {\n   DotRewriteTestSpec spec = GetParam();\n   FusionProperties expected = {HloOpcode::kMultiply, 0, 0, false};\n   if (IsDotEnabledOnCPU()) {\n-    // {Dot, Add, Sub, Mul} for XNN, {Dot, Add} for oneDNN.\n-    expected = spec.lib == \"xnn\"\n+    // {Dot, Add, Sub, Mul} for YNN, {Dot, Add} for oneDNN.\n+    expected = spec.lib == \"ynn\"\n                    ? FusionProperties{HloOpcode::kMultiply, 5, 9, true}\n                    : FusionProperties{HloOpcode::kAdd, 3, 5, true};\n   } else if (spec.fusion_mode == \"greedy\") {\n@@ -373,12 +380,12 @@ TEST_P(CpuLibraryFullParamTest, MatMulAddMinExpSort) {\n                      dimensions={0}, to_apply=compare\n     })\";\n \n-  // Sort is not supported by xnn_emitter and should not be in the fusion.\n+  // Sort is not supported by ynn_emitter and should not be in the fusion.\n   DotRewriteTestSpec spec = GetParam();\n   FusionProperties expected = {HloOpcode::kExp, 0, 0, false};\n   if (IsDotEnabledOnCPU()) {\n-    // {Dot, Add, Min, Exp} for XNN, {Dot, Add} for oneDNN.\n-    expected = spec.lib == \"xnn\"\n+    // {Dot, Add, Min, Exp} for YNN, {Dot, Add} for oneDNN.\n+    expected = spec.lib == \"ynn\"\n                    ? FusionProperties{HloOpcode::kExp, 4, 8, true}\n                    : FusionProperties{HloOpcode::kAdd, 3, 5, true};\n   } else if (spec.fusion_mode == \"greedy\") {\n@@ -430,23 +437,23 @@ std::vector<DotRewriteTestSpec> GetDotRewriteTestSpecs() {\n   absl::flat_hash_map<std::string, std::string> cpu_to_features = {\n       {\"znver3\", \"+avx,+avx2\"},\n       {\"sapphirerapids\",\n-       \"+avx512vnni,+avx512bf16,+amx-bf16,+avx512fp16,+amx-int8,+amx-tile,+amx-\"\n-       \"transpose\"},\n+       \"+avx512vnni,+avx512bf16,+amx-bf16,+avx512fp16,+amx-int8,+amx-tile\"},\n   };\n \n   // Input and output data types to test per each library + CPU combination.\n   using StrPair = std::pair<std::string, std::string>;\n   absl::flat_hash_map<StrPair, std::vector<StrPair>> dtype_map = {\n-      {{\"xnn\", \"znver3\"}, {{\"f32\", \"f32\"}, {\"bf16\", \"f32\"}}},\n-      {{\"xnn\", \"sapphirerapids\"},\n-       {{\"f32\", \"f32\"}, {\"bf16\", \"f32\"}, {\"bf16\", \"bf16\"}}},\n+      {{\"ynn\", \"znver3\"}, {{\"f32\", \"f32\"}, {\"bf16\", \"f32\"}}},\n+      {{\"ynn\", \"sapphirerapids\"}, {{\"f32\", \"f32\"}, {\"bf16\", \"f32\"}}},\n   };\n \n   // Fusion modes to test for each library.\n-  // We temporarily use XNN_GRAPH_FUSION_MODE_DISABLED to denote the dot fusion\n-  // mode (starting fusion nodes with dots).\n-  absl::flat_hash_map<std::string, std::vector<std::string>> fusion_modes = {\n-      {\"xnn\", {\"dot\", \"greedy\"}}};\n+  absl::flat_hash_map<std::string, std::vector<std::string>> fusion_modes;\n+\n+#if XLA_YNNPACK\n+  // Don't test YNNPACK if we don't build with it.\n+  fusion_modes[\"ynn\"] = {\"dot\", \"greedy\"};\n+#endif\n \n #if XLA_ONEDNN_USE_GRAPH_API\n   // Don't test oneDNN if we don't build with it.\n@@ -595,7 +602,8 @@ TEST_P(CpuLibraryFusionTypeTest, JoiningFusions) {\n   }\n }\n \n-TEST_P(CpuLibraryFusionTypeTest, Reduce) {\n+// TODO(penporn): Re-enable this test when YNNPACK supports reduce.\n+TEST_P(CpuLibraryFusionTypeTest, DISABLED_Reduce) {\n   const absl::string_view hlo_template = R\"(\n     HloModule reduce\n "
        },
        {
            "sha": "843e96ab9ab445eae7fc49e523cadec5a7a5281a",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3d2213eb0da1387b15ce781d62e550b6839f864/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3d2213eb0da1387b15ce781d62e550b6839f864/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=a3d2213eb0da1387b15ce781d62e550b6839f864",
            "patch": "@@ -1007,9 +1007,8 @@ absl::Status CpuCompiler::RunHloPassesAfterLayoutAssn(\n   // XNNPACK ops availability checks depend on the layout information,\n   // so until another solution is developed the passes creating XNNPACK fusions\n   // have to run after layout assignment.\n-  const bool use_ynnpack = absl::c_linear_search(\n-      debug_options.xla_cpu_experimental_ynn_fusion_type(),\n-      DebugOptions::LIBRARY_FUSION_TYPE_REDUCE);\n+  const bool use_ynnpack =\n+      !debug_options.xla_cpu_experimental_ynn_fusion_type().empty();\n   LibraryRewriterOptions options = {\n       /*use_onednn=*/debug_options.xla_cpu_use_onednn(),\n       /*use_xnnpack=*/debug_options.xla_cpu_use_xnnpack(),"
        }
    ],
    "stats": {
        "total": 63,
        "additions": 35,
        "deletions": 28
    }
}