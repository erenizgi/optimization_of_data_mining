{
    "author": "ermilovmaxim",
    "message": "[XLA:GPU] Add proto serialization for InfeedThunk\n\nPiperOrigin-RevId: 807800866",
    "sha": "ac25dfa9d2a9762a00afa394db7b4a5cf27f1573",
    "files": [
        {
            "sha": "18aaa44b2141f7dd3e1ac7571a324ed9caa826cc",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 22,
            "deletions": 2,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=ac25dfa9d2a9762a00afa394db7b4a5cf27f1573",
            "patch": "@@ -792,16 +792,35 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla:util\",\n+        \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/service/gpu:gpu_transfer_manager\",\n         \"//xla/service/gpu:io_feed_manager\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:device_memory_handle\",\n-        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n-        \"@local_tsl//tsl/platform:errors\",\n+        \"@com_google_absl//absl/types:span\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"infeed_thunk_test\",\n+    srcs = [\"infeed_thunk_test.cc\"],\n+    deps = [\n+        \":infeed_thunk\",\n+        \":thunk\",\n+        \":thunk_proto_cc\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_googletest//:gtest_main\",\n+        \"@local_tsl//tsl/platform:protobuf\",\n     ],\n )\n \n@@ -2132,6 +2151,7 @@ cc_library(\n         \":copy_thunk\",\n         \":cudnn_thunk\",\n         \":gemm_thunk\",\n+        \":infeed_thunk\",\n         \":kernel_thunk\",\n         \":memset_thunk\",\n         \":replica_id_thunk\","
        },
        {
            "sha": "12ed3e0311cae39df4635738cad8ed3b1add56c3",
            "filename": "third_party/xla/xla/backends/gpu/runtime/infeed_thunk.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 2,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk.cc?ref=ac25dfa9d2a9762a00afa394db7b4a5cf27f1573",
            "patch": "@@ -16,13 +16,16 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/infeed_thunk.h\"\n \n #include <cstddef>\n+#include <memory>\n #include <utility>\n #include <vector>\n \n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/gpu/gpu_transfer_manager.h\"\n #include \"xla/service/gpu/infeed_manager.h\"\n@@ -32,9 +35,10 @@ limitations under the License.\n #include \"xla/status_macros.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_handle.h\"\n-#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n-#include \"tsl/platform/errors.h\"\n \n namespace xla {\n namespace gpu {\n@@ -85,5 +89,32 @@ absl::Status InfeedThunk::ExecuteOnStream(const ExecuteParams& params) {\n   return absl::OkStatus();\n }\n \n+absl::StatusOr<std::unique_ptr<InfeedThunk>> InfeedThunk::FromProto(\n+    ThunkInfo thunk_info, const InfeedThunkProto& thunk_proto,\n+    absl::Span<const BufferAllocation> buffer_allocations) {\n+  std::vector<ShapedSlice> dest_slices(thunk_proto.dest_slices_size());\n+\n+  for (int i = 0; i < dest_slices.size(); i++) {\n+    TF_ASSIGN_OR_RETURN(\n+        dest_slices[i],\n+        ShapedSlice::FromProto(thunk_proto.dest_slices(i), buffer_allocations));\n+  }\n+\n+  return std::make_unique<InfeedThunk>(std::move(thunk_info),\n+                                       std::move(dest_slices));\n+}\n+\n+absl::StatusOr<ThunkProto> InfeedThunk::ToProto() const {\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+\n+  InfeedThunkProto* thunk_proto = proto.mutable_infeed_thunk();\n+  for (int i = 0; i < dest_slices_.size(); i++) {\n+    TF_ASSIGN_OR_RETURN(*thunk_proto->add_dest_slices(),\n+                        dest_slices_[i].ToProto());\n+  }\n+  return proto;\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "00fd8c29368bd494e4181c896ceb408dff13faa8",
            "filename": "third_party/xla/xla/backends/gpu/runtime/infeed_thunk.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk.h?ref=ac25dfa9d2a9762a00afa394db7b4a5cf27f1573",
            "patch": "@@ -38,6 +38,12 @@ class InfeedThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  static absl::StatusOr<std::unique_ptr<InfeedThunk>> FromProto(\n+      ThunkInfo thunk_info, const InfeedThunkProto& thunk_proto,\n+      absl::Span<const BufferAllocation> buffer_allocations);\n+\n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n  private:\n   const std::vector<ShapedSlice> dest_slices_;\n };"
        },
        {
            "sha": "22e2da9206addde7937794d306ee021b6701d305",
            "filename": "third_party/xla/xla/backends/gpu/runtime/infeed_thunk_test.cc",
            "status": "added",
            "additions": 74,
            "deletions": 0,
            "changes": 74,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk_test.cc?ref=ac25dfa9d2a9762a00afa394db7b4a5cf27f1573",
            "patch": "@@ -0,0 +1,74 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/infeed_thunk.h\"\n+\n+#include <memory>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/log/check.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n+#include \"tsl/platform/protobuf.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+using ::tsl::proto_testing::EqualsProto;\n+\n+TEST(InfeedThunkTest, ProtoRoundTrip) {\n+  ThunkProto proto;\n+  CHECK(tsl::protobuf::TextFormat::ParseFromString(\n+      R\"pb(\n+        thunk_info {\n+          profile_annotation: \"partition_id_profile_annotation\"\n+          execution_stream_id: 2\n+        }\n+        infeed_thunk {\n+          dest_slices {\n+            slice { offset: 0 size: 4 buffer_allocation_index: 0 }\n+            shape {\n+              dimensions: 8\n+              element_type: F32\n+              is_dynamic_dimension: false\n+            }\n+          }\n+        }\n+      )pb\",\n+      &proto));\n+  std::vector<BufferAllocation> buffer_allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/4, /*color=*/0)};\n+\n+  Thunk::ThunkInfo thunk_info;\n+  thunk_info.profile_annotation = proto.thunk_info().profile_annotation();\n+  thunk_info.execution_stream_id = xla::gpu::ExecutionStreamId{\n+      static_cast<xla::gpu::ExecutionStreamId::ValueType>(\n+          proto.thunk_info().execution_stream_id())};\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<InfeedThunk> thunk,\n+      InfeedThunk::FromProto(thunk_info, proto.infeed_thunk(),\n+                             buffer_allocations));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(ThunkProto round_trip_proto, thunk->ToProto());\n+  EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        },
        {
            "sha": "f84d83d754630a65b0f77ff15b8a0dbc2d93eac7",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc?ref=ac25dfa9d2a9762a00afa394db7b4a5cf27f1573",
            "patch": "@@ -41,6 +41,7 @@ limitations under the License.\n #include \"xla/executable_run_options.h\"\n #include \"xla/ffi/execution_context.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/global_device_id.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n@@ -429,5 +430,24 @@ ThunkInfoProto Thunk::ThunkInfo::ToProto() const {\n   proto.set_execution_stream_id(execution_stream_id.value());\n   return proto;\n }\n+\n+absl::StatusOr<ShapedSlice> ShapedSlice::FromProto(\n+    const ShapedSliceProto& proto,\n+    absl::Span<const BufferAllocation> buffer_allocations) {\n+  ShapedSlice shaped_slice;\n+  TF_ASSIGN_OR_RETURN(\n+      shaped_slice.slice,\n+      BufferAllocation::Slice::FromProto(proto.slice(), buffer_allocations));\n+  TF_ASSIGN_OR_RETURN(shaped_slice.shape, Shape::FromProto(proto.shape()));\n+  return shaped_slice;\n+}\n+\n+absl::StatusOr<ShapedSliceProto> ShapedSlice::ToProto() const {\n+  ShapedSliceProto proto;\n+  TF_ASSIGN_OR_RETURN(*proto.mutable_slice(), slice.ToProto());\n+  *proto.mutable_shape() = shape.ToProto();\n+  return proto;\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "f5f8e361aabd38dc3edf4f7fd4c0639b38ab2d1c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h?ref=ac25dfa9d2a9762a00afa394db7b4a5cf27f1573",
            "patch": "@@ -582,6 +582,11 @@ std::ostream& operator<<(std::ostream& os, Thunk::Kind kind);\n struct ShapedSlice {\n   BufferAllocation::Slice slice;\n   Shape shape;\n+\n+  static absl::StatusOr<ShapedSlice> FromProto(\n+      const ShapedSliceProto& proto,\n+      absl::Span<const BufferAllocation> buffer_allocations);\n+  absl::StatusOr<ShapedSliceProto> ToProto() const;\n };\n \n // Returns if the thunk implements a reduction collective (all-reduce or"
        },
        {
            "sha": "1017787155f468b7357e3fd1afdf2538db5ee23b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=ac25dfa9d2a9762a00afa394db7b4a5cf27f1573",
            "patch": "@@ -133,6 +133,15 @@ message MemzeroThunkProto {\n   xla.buffer_assignment.BufferAllocationSliceProto dest_buffer = 1;\n }\n \n+message ShapedSliceProto {\n+  xla.buffer_assignment.BufferAllocationSliceProto slice = 1;\n+  xla.ShapeProto shape = 2;\n+}\n+\n+message InfeedThunkProto {\n+  repeated ShapedSliceProto dest_slices = 1;\n+}\n+\n message ThunkProto {\n   ThunkInfoProto thunk_info = 1;\n \n@@ -155,6 +164,7 @@ message ThunkProto {\n     HostExecuteDoneThunkProto host_execute_done_thunk = 17;\n     DynamicSliceThunkProto dynamic_slice_thunk = 18;\n     MemzeroThunkProto memzero_thunk = 19;\n+    InfeedThunkProto infeed_thunk = 21;\n   }\n }\n "
        },
        {
            "sha": "f500a9a247557cf41ba32da86b26121779e9d10f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ac25dfa9d2a9762a00afa394db7b4a5cf27f1573/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc?ref=ac25dfa9d2a9762a00afa394db7b4a5cf27f1573",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/copy_thunk.h\"\n #include \"xla/backends/gpu/runtime/cudnn_thunk.h\"\n #include \"xla/backends/gpu/runtime/gemm_thunk.h\"\n+#include \"xla/backends/gpu/runtime/infeed_thunk.h\"\n #include \"xla/backends/gpu/runtime/kernel_thunk.h\"\n #include \"xla/backends/gpu/runtime/memset_thunk.h\"\n #include \"xla/backends/gpu/runtime/replica_id_thunk.h\"\n@@ -145,6 +146,10 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProto(\n     return MemzeroThunk::FromProto(\n         std::move(thunk_info), thunk_proto.memzero_thunk(), buffer_allocations);\n   }\n+  if (thunk_proto.has_infeed_thunk()) {\n+    return InfeedThunk::FromProto(\n+        std::move(thunk_info), thunk_proto.infeed_thunk(), buffer_allocations);\n+  }\n \n   std::optional<absl::string_view> unsupported_thunk_type =\n       GetStoredThunkTypeName(thunk_proto);"
        }
    ],
    "stats": {
        "total": 179,
        "additions": 175,
        "deletions": 4
    }
}