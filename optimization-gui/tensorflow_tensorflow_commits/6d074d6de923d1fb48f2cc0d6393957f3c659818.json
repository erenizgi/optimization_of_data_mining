{
    "author": "junwhanahn",
    "message": "Replace IFRT futures/promises with TSL futures/promises\n\nIFRT futures/promises have been deprecated in favor of TSL futures/promises.\n\nPiperOrigin-RevId: 812391721",
    "sha": "6d074d6de923d1fb48f2cc0d6393957f3c659818",
    "files": [
        {
            "sha": "4edc49eba34f72ad66c36fcf8138197947ba68a9",
            "filename": "tensorflow/core/tfrt/ifrt/BUILD",
            "status": "modified",
            "additions": 9,
            "deletions": 4,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2FBUILD?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -169,6 +169,7 @@ cc_library(\n         \"@local_xla//xla/python/pjrt_ifrt\",\n         \"@local_xla//xla/service:computation_placer_hdr\",\n         \"@local_xla//xla/service:dump\",\n+        \"@local_xla//xla/tsl/concurrency:future\",\n         \"@local_xla//xla/tsl/concurrency:ref_count\",\n         \"@local_xla//xla/tsl/framework:serving_device_selector\",\n         \"@local_xla//xla/tsl/platform:env\",\n@@ -211,7 +212,7 @@ cc_library(\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/synchronization\",\n-        \"@local_xla//xla/python/ifrt\",\n+        \"@local_xla//xla/tsl/concurrency:future\",\n     ],\n )\n \n@@ -251,6 +252,7 @@ cc_library(\n         \"@com_google_absl//absl/synchronization\",\n         \"@local_xla//xla/hlo/ir:hlo\",\n         \"@local_xla//xla/python/ifrt\",\n+        \"@local_xla//xla/tsl/concurrency:future\",\n         \"@local_xla//xla/tsl/concurrency:ref_count\",\n         \"@local_xla//xla/tsl/platform:statusor\",\n     ],\n@@ -347,6 +349,7 @@ cc_library(\n         \"@local_xla//xla/hlo/ir:hlo\",\n         \"@local_xla//xla/python/ifrt\",\n         \"@local_xla//xla/python/pjrt_ifrt:xla_ifrt\",\n+        \"@local_xla//xla/tsl/concurrency:future\",\n         \"@local_xla//xla/tsl/concurrency:ref_count\",\n         \"@local_xla//xla/tsl/platform:env\",\n         \"@local_xla//xla/tsl/platform:errors\",\n@@ -373,6 +376,7 @@ cc_library(\n         \"@com_google_absl//absl/types:span\",\n         \"@local_xla//xla/hlo/ir:hlo\",\n         \"@local_xla//xla/python/ifrt\",\n+        \"@local_xla//xla/tsl/concurrency:future\",\n         \"@local_xla//xla/tsl/concurrency:ref_count\",\n         \"@local_xla//xla/tsl/platform:env\",\n         \"@local_xla//xla/tsl/platform:errors\",\n@@ -465,7 +469,7 @@ tf_cc_test(\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_googletest//:gtest_main\",\n-        \"@local_xla//xla/python/ifrt\",\n+        \"@local_xla//xla/tsl/concurrency:future\",\n         \"@local_xla//xla/tsl/lib/core:status_test_util\",\n         \"@local_xla//xla/tsl/platform:status_matchers\",\n         \"@local_xla//xla/tsl/platform:statusor\",\n@@ -494,6 +498,7 @@ tf_cc_test(\n         \"@local_xla//xla/python/ifrt\",\n         \"@local_xla//xla/python/ifrt:test_util\",\n         \"@local_xla//xla/python/pjrt_ifrt:tfrt_cpu_client_test_lib\",\n+        \"@local_xla//xla/tsl/concurrency:future\",\n         \"@local_xla//xla/tsl/concurrency:ref_count\",\n         \"@local_xla//xla/tsl/lib/core:status_test_util\",\n         \"@local_xla//xla/tsl/platform:env\",\n@@ -597,9 +602,9 @@ tf_cc_test(\n         \"@com_google_absl//absl/types:span\",\n         \"@com_google_googletest//:gtest_main\",\n         \"@local_tsl//tsl/platform:tstring\",\n-        \"@local_xla//xla/python/ifrt\",\n         \"@local_xla//xla/python/ifrt:test_util\",\n         \"@local_xla//xla/python/pjrt_ifrt:tfrt_cpu_client_test_lib\",\n+        \"@local_xla//xla/tsl/concurrency:future\",\n         \"@local_xla//xla/tsl/framework:serving_device_selector\",\n         \"@local_xla//xla/tsl/framework/test_util:mock_serving_device_selector\",\n         \"@local_xla//xla/tsl/platform:statusor\",\n@@ -692,7 +697,7 @@ cc_library(\n         \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//mlir:IR\",\n         \"@local_tsl//tsl/platform:tstring\",\n-        \"@local_xla//xla/python/ifrt\",\n+        \"@local_xla//xla/tsl/concurrency:future\",\n         \"@local_xla//xla/tsl/platform:errors\",\n         \"@local_xla//xla/tsl/platform:statusor\",\n         \"@tf_runtime//:hostcontext\","
        },
        {
            "sha": "dbbcb9fc07d2e329006c67daa7799888ab632404",
            "filename": "tensorflow/core/tfrt/ifrt/checkpoint_loader.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fcheckpoint_loader.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fcheckpoint_loader.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fcheckpoint_loader.cc?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -29,7 +29,7 @@ limitations under the License.\n #include \"mlir/IR/BuiltinOps.h\"  // from @llvm-project\n #include \"mlir/IR/OwningOpRef.h\"  // from @llvm-project\n #include \"tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_types.h\"\n-#include \"xla/python/ifrt/future.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"tensorflow/core/common_runtime/process_function_library_runtime.h\"\n@@ -89,7 +89,7 @@ struct AsyncState {\n   const tensorflow::ProcessFunctionLibraryRuntime&\n       process_function_library_runtime;\n \n-  std::vector<xla::ifrt::Promise<tensorflow::Tensor>> results;\n+  std::vector<tsl::Promise<tensorflow::Tensor>> results;\n };\n \n // Returns a casted tensor if successful.\n@@ -245,8 +245,7 @@ absl::Status RunShard(RestoreVariableShard shard,\n       fallback_request_state.process_function_library_runtime());\n \n   for (int i = 0; i < num_outputs; ++i) {\n-    auto [promise, future] =\n-        xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+    auto [promise, future] = tsl::Future<tensorflow::Tensor>::MakePromise();\n     const ResourceHandle& var_handle =\n         shard.var_handles[i].tensor().scalar<tensorflow::ResourceHandle>()();\n "
        },
        {
            "sha": "4ff43877e92b0f5066d9e5f4898d53cba482611c",
            "filename": "tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_registry.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_loaded_variable_registry.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_loaded_variable_registry.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_loaded_variable_registry.h?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -30,7 +30,7 @@ limitations under the License.\n #include \"absl/synchronization/mutex.h\"\n #include \"xla/hlo/ir/hlo_sharding.h\"\n #include \"xla/python/ifrt/array.h\"\n-#include \"xla/python/ifrt/future.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n \n namespace tensorflow {\n@@ -69,7 +69,7 @@ class IfrtLoadedVariableRegistry {\n   };\n \n   struct LoadedVariable {\n-    xla::ifrt::Future<xla::ifrt::ArrayRef> array;\n+    tsl::Future<xla::ifrt::ArrayRef> array;\n   };\n   using LoadedVariableConstructor =\n       absl::AnyInvocable<absl::StatusOr<LoadedVariable>() const>;"
        },
        {
            "sha": "8267e9615e69976f4686b3d519f828df36b68be8",
            "filename": "tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_utils.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_loaded_variable_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_loaded_variable_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_loaded_variable_utils.cc?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -29,7 +29,7 @@ limitations under the License.\n #include \"tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_types.h\"\n #include \"xla/python/ifrt/array.h\"\n #include \"xla/python/ifrt/client.h\"\n-#include \"xla/python/ifrt/future.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -104,14 +104,14 @@ absl::Status AsyncLoadRestoredTensorAsIfrtLoadedVariable(\n     return absl::OkStatus();\n   }\n \n-  xla::ifrt::Future<tensorflow::Tensor> restored_tensor_future =\n+  tsl::Future<tensorflow::Tensor> restored_tensor_future =\n       restore_tensor_registry.GetRestoredTensor(tensor_name);\n   if (!restored_tensor_future.IsValid()) {\n     return absl::InternalError(absl::StrCat(\n         \"LoadVariableOp: failed to fetch variable tensor: \", tensor_name));\n   }\n   auto [loaded_variable_promise, loaded_variable_future] =\n-      xla::ifrt::Future<xla::ifrt::ArrayRef>::MakePromise();\n+      tsl::Future<xla::ifrt::ArrayRef>::MakePromise();\n   TF_ASSIGN_OR_RETURN(\n       absl::StatusOr<ifrt_serving::DtypeAndShape> dtype_and_shape,\n       restore_tensor_registry.GetDtypeAndShape(tensor_name));"
        },
        {
            "sha": "55322d7f142becd2f57ab68c1b44de240b2a5c67",
            "filename": "tensorflow/core/tfrt/ifrt/ifrt_loaded_variable_utils_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_loaded_variable_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_loaded_variable_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_loaded_variable_utils_test.cc?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -28,8 +28,8 @@ limitations under the License.\n #include \"xla/python/ifrt/array.h\"\n #include \"xla/python/ifrt/client.h\"\n #include \"xla/python/ifrt/device.h\"\n-#include \"xla/python/ifrt/future.h\"\n #include \"xla/python/ifrt/test_util.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/env.h\"\n@@ -83,7 +83,7 @@ TEST(ShardingUtilsTest, ShardTensorToIfrtLoadedVariableNotFoundWrongName) {\n       .hlo_sharding = xla::HloSharding::Replicate(),\n   };\n \n-  auto [promise, future] = xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+  auto [promise, future] = tsl::Future<tensorflow::Tensor>::MakePromise();\n \n   IfrtRestoreTensorRegistry::RestoredTensorInfo restored_tensor_info = {\n       false,\n@@ -127,7 +127,7 @@ TEST(ShardingUtilsTest, ShardTensorToIfrtLoadedVariableSucceed) {\n       .hlo_sharding = xla::HloSharding::Replicate(),\n   };\n \n-  auto [promise, future] = xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+  auto [promise, future] = tsl::Future<tensorflow::Tensor>::MakePromise();\n \n   IfrtRestoreTensorRegistry::RestoredTensorInfo restored_tensor_info = {\n       false,"
        },
        {
            "sha": "6e167c690ec0519900d241a1e0aa0ef6ea902e81",
            "filename": "tensorflow/core/tfrt/ifrt/ifrt_restore_tensor_registry.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_restore_tensor_registry.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_restore_tensor_registry.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_restore_tensor_registry.cc?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -25,7 +25,7 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_types.h\"\n-#include \"xla/python/ifrt/future.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n \n namespace tensorflow {\n@@ -43,12 +43,12 @@ absl::Status IfrtRestoreTensorRegistry::TryRegister(\n   return absl::OkStatus();\n }\n \n-xla::ifrt::Future<tensorflow::Tensor>\n-IfrtRestoreTensorRegistry::GetRestoredTensor(absl::string_view name) const {\n+tsl::Future<tensorflow::Tensor> IfrtRestoreTensorRegistry::GetRestoredTensor(\n+    absl::string_view name) const {\n   absl::MutexLock lock(mutex_);\n   auto it = restored_tensors_.find(name);\n   if (it == restored_tensors_.end()) {\n-    return xla::ifrt::Future<tensorflow::Tensor>(\n+    return tsl::Future<tensorflow::Tensor>(\n         absl::NotFoundError(absl::StrCat(\"Variable '\", name, \"' not found.\")));\n   }\n \n@@ -69,7 +69,7 @@ absl::Status IfrtRestoreTensorRegistry::SetUsedByHost(absl::string_view name) {\n \n void IfrtRestoreTensorRegistry::Freeze() {\n   absl::MutexLock lock(mutex_);\n-  xla::ifrt::Future<tensorflow::Tensor> release_tensor_future(\n+  tsl::Future<tensorflow::Tensor> release_tensor_future(\n       absl::UnavailableError(\"Tensor is already release.\"));\n   for (auto& [name, info] : restored_tensors_) {\n     if (!info.used_by_host) {"
        },
        {
            "sha": "96ab7b68f1a21b9e4a7aed9427906a82aa7658b8",
            "filename": "tensorflow/core/tfrt/ifrt/ifrt_restore_tensor_registry.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_restore_tensor_registry.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_restore_tensor_registry.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_restore_tensor_registry.h?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -24,7 +24,7 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_types.h\"\n-#include \"xla/python/ifrt/future.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n #include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/types.pb.h\"\n@@ -38,15 +38,15 @@ class IfrtRestoreTensorRegistry {\n   struct RestoredTensorInfo {\n     bool used_by_host = false;\n     DtypeAndShape dtype_and_shape;\n-    xla::ifrt::Future<tensorflow::Tensor> tensor_future;\n+    tsl::Future<tensorflow::Tensor> tensor_future;\n   };\n   // Tries to register a loaded variable with the given name.\n   // Returns an error if the named tensor already exists.\n   absl::Status TryRegister(absl::string_view name,\n                            RestoredTensorInfo restored_tensor_info)\n       ABSL_LOCKS_EXCLUDED(mutex_);\n \n-  xla::ifrt::Future<tensorflow::Tensor> GetRestoredTensor(\n+  tsl::Future<tensorflow::Tensor> GetRestoredTensor(\n       absl::string_view name) const ABSL_LOCKS_EXCLUDED(mutex_);\n \n   // Sets the tensor as used by the host. To ensure a tensor's host memory"
        },
        {
            "sha": "e7ebad15cb9070c1ea5f9d56c632e89e7009d2aa",
            "filename": "tensorflow/core/tfrt/ifrt/ifrt_restore_tensor_registry_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 9,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_restore_tensor_registry_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_restore_tensor_registry_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_restore_tensor_registry_test.cc?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -21,7 +21,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/status_matchers.h\"\n #include \"tensorflow/compiler/mlir/tfrt/transforms/ifrt/ifrt_types.h\"\n-#include \"xla/python/ifrt/future.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -56,7 +56,7 @@ TEST(IfrtRestoreTensorRegistryTest, SetNonExistedTensorAsUsedByHostFails) {\n TEST(IfrtRestoreTensorRegistryTest, RegisteredExistedTensorFails) {\n   auto input_tensor =\n       test::AsTensor<int32_t>({1, 2, 3, 4}, tensorflow::TensorShape({2, 2}));\n-  auto [promise, future] = xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+  auto [promise, future] = tsl::Future<tensorflow::Tensor>::MakePromise();\n \n   IfrtRestoreTensorRegistry::RestoredTensorInfo restored_tensor_info = {\n       .used_by_host = false,\n@@ -75,7 +75,7 @@ TEST(IfrtRestoreTensorRegistryTest, RegisteredExistedTensorFails) {\n }\n \n TEST(IfrtRestoreTensorRegistryTest, SetTensorAsUsedByHost) {\n-  auto [promise, future] = xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+  auto [promise, future] = tsl::Future<tensorflow::Tensor>::MakePromise();\n   IfrtRestoreTensorRegistry::RestoredTensorInfo restored_tensor_info = {\n       .used_by_host = false,\n       .dtype_and_shape =\n@@ -93,7 +93,7 @@ TEST(IfrtRestoreTensorRegistryTest, SetTensorAsUsedByHost) {\n TEST(IfrtRestoreTensorRegistryTest, RegisteredTensorCanBeRetrieved) {\n   auto input_tensor =\n       test::AsTensor<int32_t>({1, 2, 3, 4}, tensorflow::TensorShape({2, 2}));\n-  auto [promise, future] = xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+  auto [promise, future] = tsl::Future<tensorflow::Tensor>::MakePromise();\n \n   IfrtRestoreTensorRegistry::RestoredTensorInfo restored_tensor_info = {\n       .used_by_host = false,\n@@ -121,7 +121,7 @@ TEST(IfrtRestoreTensorRegistryTest,\n      RegisteredTensorDTypeAndShapeCanBeRetrieved) {\n   auto input_tensor =\n       test::AsTensor<int32_t>({1, 2, 3, 4}, tensorflow::TensorShape({2, 2}));\n-  auto [promise, future] = xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+  auto [promise, future] = tsl::Future<tensorflow::Tensor>::MakePromise();\n \n   IfrtRestoreTensorRegistry::RestoredTensorInfo restored_tensor_info = {\n       .used_by_host = false,\n@@ -144,10 +144,8 @@ TEST(IfrtRestoreTensorRegistryTest,\n TEST(IfrtRestoreTensorRegistryTest, FeezeTensorRegistry) {\n   auto input_tensor =\n       test::AsTensor<int32_t>({1, 2, 3, 4}, tensorflow::TensorShape({2, 2}));\n-  auto [promise1, future1] =\n-      xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n-  auto [promise2, future2] =\n-      xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+  auto [promise1, future1] = tsl::Future<tensorflow::Tensor>::MakePromise();\n+  auto [promise2, future2] = tsl::Future<tensorflow::Tensor>::MakePromise();\n \n   IfrtRestoreTensorRegistry::RestoredTensorInfo restored_tensor_info1 = {\n       .used_by_host = false,"
        },
        {
            "sha": "454f345bc3113bd3972a34ea6104ce1905c06122",
            "filename": "tensorflow/core/tfrt/ifrt/ifrt_serving_executable.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_serving_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_serving_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_serving_executable.cc?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -66,7 +66,6 @@ limitations under the License.\n #include \"xla/python/ifrt/device.h\"\n #include \"xla/python/ifrt/device_list.h\"\n #include \"xla/python/ifrt/executable.h\"\n-#include \"xla/python/ifrt/future.h\"\n #include \"xla/python/ifrt/hlo/hlo_program.h\"\n #include \"xla/python/ifrt/host_callback.h\"\n #include \"xla/python/ifrt/program.h\"\n@@ -76,6 +75,7 @@ limitations under the License.\n #include \"xla/service/computation_placer.h\"\n #include \"xla/service/dump.h\"\n #include \"xla/shape.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/framework/serving_device_selector.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -568,7 +568,7 @@ IfrtServingExecutable::CreateExecutableSynchronously(\n   return executable_bundle;\n }\n \n-xla::ifrt::Future<IfrtServingExecutable::SharedCachedExecutableBundle>\n+tsl::Future<IfrtServingExecutable::SharedCachedExecutableBundle>\n IfrtServingExecutable::LookUpOrCreateExecutable(\n     const tensorflow::tpu::TPUCompileMetadataProto& compile_metadata,\n     absl::Span<const DtypeAndShape> dtypes_and_shapes,\n@@ -579,8 +579,8 @@ IfrtServingExecutable::LookUpOrCreateExecutable(\n   }\n   Key key = {.input_shapes = std::move(input_shapes)};\n \n-  xla::ifrt::Promise<SharedCachedExecutableBundle> promise;\n-  xla::ifrt::Future<SharedCachedExecutableBundle> future;\n+  tsl::Promise<SharedCachedExecutableBundle> promise;\n+  tsl::Future<SharedCachedExecutableBundle> future;\n   mlir::OwningOpRef<mlir::ModuleOp> module_copy;\n   {\n     absl::MutexLock lock(mutex_);\n@@ -591,7 +591,7 @@ IfrtServingExecutable::LookUpOrCreateExecutable(\n     }\n \n     if (is_frozen_) {\n-      xla::ifrt::Future<SharedCachedExecutableBundle> frozen_future(\n+      tsl::Future<SharedCachedExecutableBundle> frozen_future(\n           absl::FailedPreconditionError(\n               \"Cannot compile for new input shapes after the executable is \"\n               \"already frozen.\"));\n@@ -600,7 +600,7 @@ IfrtServingExecutable::LookUpOrCreateExecutable(\n \n     // Only create promise and future when cache missed.\n     std::tie(promise, future) =\n-        xla::ifrt::Future<SharedCachedExecutableBundle>::MakePromise();\n+        tsl::Future<SharedCachedExecutableBundle>::MakePromise();\n \n     executable_bundles_.emplace(key, future);\n     // Clone the module to avoid race condition between Freeze() and\n@@ -790,7 +790,7 @@ absl::StatusOr<std::vector<tensorflow::Tensor>> IfrtServingExecutable::Execute(\n         \" but got \", execution_result->outputs.size(), \" outputs\"));\n   }\n \n-  std::vector<xla::ifrt::Future<tensorflow::Tensor>> output_futures;\n+  std::vector<tsl::Future<tensorflow::Tensor>> output_futures;\n   output_futures.reserve(execution_result->outputs.size());\n   for (int i = 0; i < execution_result->outputs.size(); ++i) {\n     tensorflow::TensorShape tensor_shape;"
        },
        {
            "sha": "c47f256d6a9867cc98b28399f01a358d24d6c665",
            "filename": "tensorflow/core/tfrt/ifrt/ifrt_serving_executable.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_serving_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_serving_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_serving_executable.h?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -43,9 +43,9 @@ limitations under the License.\n #include \"xla/python/ifrt/device.h\"\n #include \"xla/python/ifrt/device_list.h\"\n #include \"xla/python/ifrt/executable.h\"\n-#include \"xla/python/ifrt/future.h\"\n #include \"xla/python/ifrt/shape.h\"\n #include \"xla/python/ifrt/sharding.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -206,7 +206,7 @@ class IfrtServingExecutable {\n       compilation_env_or_overrides_;  // proto is NOT OWNED. can be nullptr.\n \n   mutable absl::Mutex mutex_;\n-  absl::flat_hash_map<Key, xla::ifrt::Future<SharedCachedExecutableBundle>>\n+  absl::flat_hash_map<Key, tsl::Future<SharedCachedExecutableBundle>>\n       executable_bundles_ ABSL_GUARDED_BY(mutex_);\n \n   bool is_frozen_ ABSL_GUARDED_BY(mutex_) = false;\n@@ -232,7 +232,7 @@ class IfrtServingExecutable {\n       const xla::ifrt::DeviceListRef& device_list,\n       const xla::OpSharding& sharding);\n \n-  xla::ifrt::Future<SharedCachedExecutableBundle> LookUpOrCreateExecutable(\n+  tsl::Future<SharedCachedExecutableBundle> LookUpOrCreateExecutable(\n       const tensorflow::tpu::TPUCompileMetadataProto& compile_metadata,\n       absl::Span<const DtypeAndShape> dtypes_and_shapes,\n       absl::Span<const int> variable_arg_indices);"
        },
        {
            "sha": "65382766e6b1d790359d7632b79cc99d04c01b3f",
            "filename": "tensorflow/core/tfrt/ifrt/ifrt_serving_executable_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_serving_executable_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_serving_executable_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fifrt_serving_executable_test.cc?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -29,8 +29,8 @@ limitations under the License.\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n-#include \"xla/python/ifrt/future.h\"\n #include \"xla/python/ifrt/test_util.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/framework/serving_device_selector.h\"\n #include \"xla/tsl/framework/test_util/mock_serving_device_selector.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n@@ -300,7 +300,7 @@ TEST_P(VariableInputTest, InterleaveVariable) {\n   for (int i = 0; i < GetParam().in_tensors.size(); i++) {\n     if (GetParam().is_variable[i]) {\n       auto [input_tensor_promise, input_tensor_future] =\n-          xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+          tsl::Future<tensorflow::Tensor>::MakePromise();\n       IfrtRestoreTensorRegistry::RestoredTensorInfo restore_tensor_info = {\n           .dtype_and_shape{.dtype = GetParam().in_tensors[i].dtype(),\n                            .shape = GetParam().in_tensors[i].shape()},"
        },
        {
            "sha": "80975b68448b8abe0023279d2e1e2c214fdef5b5",
            "filename": "tensorflow/core/tfrt/ifrt/sharding_utils.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fsharding_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fsharding_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fsharding_utils.cc?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -40,7 +40,6 @@ limitations under the License.\n #include \"xla/python/ifrt/device.h\"\n #include \"xla/python/ifrt/device_list.h\"\n #include \"xla/python/ifrt/dtype.h\"\n-#include \"xla/python/ifrt/future.h\"\n #include \"xla/python/ifrt/index.h\"\n #include \"xla/python/ifrt/index_domain.h\"\n #include \"xla/python/ifrt/memory.h\"\n@@ -49,6 +48,7 @@ limitations under the License.\n #include \"xla/python/pjrt_ifrt/xla_sharding.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -464,7 +464,7 @@ absl::StatusOr<xla::ifrt::ArrayRef> MakeAssembledArrayFromHostBuffer(\n       xla::ifrt::ArrayCopySemantics::kDonateInput);\n }\n \n-absl::StatusOr<xla::ifrt::Future<tensorflow::Tensor>> MakeTensorFromArrayHelper(\n+absl::StatusOr<tsl::Future<tensorflow::Tensor>> MakeTensorFromArrayHelper(\n     xla::ifrt::Client& ifrt_client, xla::ifrt::Array& input_array,\n     const xla::HloSharding& hlo_sharding,\n     const xla::ifrt::DeviceListRef& device_list,\n@@ -477,7 +477,7 @@ absl::StatusOr<xla::ifrt::Future<tensorflow::Tensor>> MakeTensorFromArrayHelper(\n           << hlo_sharding.ToString();\n \n   auto [promise, output_tensor_future] =\n-      xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+      tsl::Future<tensorflow::Tensor>::MakePromise();\n \n   if (hlo_sharding.IsReplicated()) {\n     VLOG(1) << \"Fast path for replication\";\n@@ -599,7 +599,7 @@ absl::StatusOr<xla::ifrt::Future<tensorflow::Tensor>> MakeTensorFromArrayHelper(\n         {index_domains[i], disassembled_array[i]});\n   }\n \n-  std::vector<xla::ifrt::Future<>> arrays_copy_status;\n+  std::vector<tsl::Future<>> arrays_copy_status;\n   std::vector<tensorflow::Tensor> input_tensors;\n   input_tensors.reserve(index_domain_device_arrays.size());\n   arrays_copy_status.reserve(index_domain_device_arrays.size());\n@@ -609,7 +609,7 @@ absl::StatusOr<xla::ifrt::Future<tensorflow::Tensor>> MakeTensorFromArrayHelper(\n                         ToTensorDataType(array->dtype()));\n     tensorflow::Tensor tensor(dtype, tensor_shape);\n     input_tensors.push_back(tensor);\n-    xla::ifrt::Future<> copy_status = array->CopyToHostBuffer(\n+    tsl::Future<> copy_status = array->CopyToHostBuffer(\n         tensor.data(), GetByteStrides(dtype, tensor_shape),\n         xla::ifrt::ArrayCopySemantics::kAlwaysCopy);\n     copy_status.OnReady([tensor](absl::Status status) {\n@@ -619,7 +619,7 @@ absl::StatusOr<xla::ifrt::Future<tensorflow::Tensor>> MakeTensorFromArrayHelper(\n     arrays_copy_status.push_back(std::move(copy_status));\n   }\n \n-  xla::ifrt::JoinFutures(absl::MakeSpan(arrays_copy_status))\n+  tsl::JoinFutures(absl::MakeSpan(arrays_copy_status))\n       .OnReady([promise = std::move(promise), &ifrt_client,\n                 input_tensors = std::move(input_tensors), num_concats,\n                 data_type, tensor_shape,\n@@ -645,16 +645,16 @@ absl::StatusOr<xla::ifrt::Future<tensorflow::Tensor>> MakeTensorFromArrayHelper(\n \n }  // namespace\n \n-xla::ifrt::Future<tensorflow::Tensor> MakeTensorFromArray(\n+tsl::Future<tensorflow::Tensor> MakeTensorFromArray(\n     xla::ifrt::Client& ifrt_client, xla::ifrt::Array& input_array,\n     const xla::HloSharding& hlo_sharding,\n     const xla::ifrt::DeviceListRef& device_list,\n     tsl::thread::ThreadPool& thread_pool) {\n-  absl::StatusOr<xla::ifrt::Future<tensorflow::Tensor>> output_tensor_future =\n+  absl::StatusOr<tsl::Future<tensorflow::Tensor>> output_tensor_future =\n       MakeTensorFromArrayHelper(ifrt_client, input_array, hlo_sharding,\n                                 device_list, thread_pool);\n   if (!output_tensor_future.ok()) {\n-    return xla::ifrt::Future<tensorflow::Tensor>(\n+    return tsl::Future<tensorflow::Tensor>(\n         std::move(output_tensor_future).status());\n   }\n   return *std::move(output_tensor_future);"
        },
        {
            "sha": "d9e57f5a2e7a9b73678da4b007dc974de8c49398",
            "filename": "tensorflow/core/tfrt/ifrt/sharding_utils.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fsharding_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fsharding_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fifrt%2Fsharding_utils.h?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -27,7 +27,7 @@ limitations under the License.\n #include \"xla/python/ifrt/client.h\"\n #include \"xla/python/ifrt/device.h\"\n #include \"xla/python/ifrt/device_list.h\"\n-#include \"xla/python/ifrt/future.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n@@ -63,7 +63,7 @@ absl::StatusOr<xla::ifrt::ArrayRef> MakeArrayFromTensor(\n // device_list: list of devices that is aligned with the order of device buffers\n // in the `input_array`.\n //\n-xla::ifrt::Future<tensorflow::Tensor> MakeTensorFromArray(\n+tsl::Future<tensorflow::Tensor> MakeTensorFromArray(\n     xla::ifrt::Client& ifrt_client, xla::ifrt::Array& input_array,\n     const xla::HloSharding& hlo_sharding,\n     const xla::ifrt::DeviceListRef& device_list,"
        },
        {
            "sha": "5b11a2be9846ba5321bb71ecd88d7ae43fd0b1c4",
            "filename": "tensorflow/core/tfrt/mlrt/kernel/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fmlrt%2Fkernel%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fmlrt%2Fkernel%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fmlrt%2Fkernel%2FBUILD?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -92,7 +92,7 @@ cc_library(\n         \"@local_tsl//tsl/platform:errors\",\n         \"@local_tsl//tsl/platform:tstring\",\n         \"@local_xla//xla:xla_data_proto_cc\",\n-        \"@local_xla//xla/python/ifrt\",\n+        \"@local_xla//xla/tsl/concurrency:future\",\n     ],\n     alwayslink = 1,\n )\n@@ -275,6 +275,7 @@ tf_cc_shared_test(\n         \"@local_xla//xla/python/ifrt\",\n         \"@local_xla//xla/python/ifrt:test_util\",\n         \"@local_xla//xla/python/pjrt_ifrt:tfrt_cpu_client_test_lib\",\n+        \"@local_xla//xla/tsl/concurrency:future\",\n         \"@local_xla//xla/tsl/framework:serving_device_selector\",\n         \"@local_xla//xla/tsl/framework/test_util:mock_serving_device_selector\",\n         \"@local_xla//xla/tsl/lib/core:status_test_util\","
        },
        {
            "sha": "ef597d5c898944a5e557cf4f24b1c192bf784e04",
            "filename": "tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fmlrt%2Fkernel%2Fifrt_ops_kernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fmlrt%2Fkernel%2Fifrt_ops_kernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fmlrt%2Fkernel%2Fifrt_ops_kernel.cc?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -25,7 +25,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n-#include \"xla/python/ifrt/future.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/xla_data.pb.h\"\n #include \"tensorflow/core/framework/attr_value.pb.h\"\n #include \"tensorflow/core/framework/device_base.h\"\n@@ -242,7 +242,7 @@ absl::Status MlrtIfrtLoadVariableKernel::InvokeHelper() {\n \n   if (used_by_host()) {\n     if (ifrt_restore_tensor_registry.SetUsedByHost(runtime_name).ok()) {\n-      xla::ifrt::Future<tensorflow::Tensor> restored_tensor_future =\n+      tsl::Future<tensorflow::Tensor> restored_tensor_future =\n           ifrt_restore_tensor_registry.GetRestoredTensor(runtime_name);\n \n       restored_tensor_future.OnReady("
        },
        {
            "sha": "62ef0ba2f3924b4edec710963386bf1eabcd2bdb",
            "filename": "tensorflow/core/tfrt/mlrt/kernel/ifrt_ops_kernel_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fmlrt%2Fkernel%2Fifrt_ops_kernel_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/tensorflow%2Fcore%2Ftfrt%2Fmlrt%2Fkernel%2Fifrt_ops_kernel_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftfrt%2Fmlrt%2Fkernel%2Fifrt_ops_kernel_test.cc?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -30,8 +30,8 @@ limitations under the License.\n #include \"absl/synchronization/notification.h\"\n #include \"absl/types/span.h\"\n #include \"xla/python/ifrt/client.h\"\n-#include \"xla/python/ifrt/future.h\"\n #include \"xla/python/ifrt/test_util.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/framework/test_util/mock_serving_device_selector.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"tensorflow/core/framework/resource_var.h\"\n@@ -505,7 +505,7 @@ TEST_P(KernelTest, IfrtLoadVariableOp) {\n   TF_CHECK_OK(tensorflow::Tensor::BuildTensor(DT_INT32, {}, &input_tensor));\n   input_tensor.scalar<int32_t>()() = 1234;\n   auto [input_tensor_promise, input_tensor_future] =\n-      xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+      tsl::Future<tensorflow::Tensor>::MakePromise();\n   ifrt_serving::IfrtRestoreTensorRegistry::RestoredTensorInfo\n       restore_tensor_info{.dtype_and_shape = {.dtype = input_tensor.dtype(),\n                                               .shape = input_tensor.shape()},\n@@ -555,7 +555,7 @@ TEST_P(KernelTest, DuplicateIfrtLoadVariableOpShallSucceed) {\n   TF_CHECK_OK(tensorflow::Tensor::BuildTensor(DT_INT32, {}, &input_tensor));\n   input_tensor.scalar<int32_t>()() = 1234;\n   auto [input_tensor_promise, input_tensor_future] =\n-      xla::ifrt::Future<tensorflow::Tensor>::MakePromise();\n+      tsl::Future<tensorflow::Tensor>::MakePromise();\n   ifrt_serving::IfrtRestoreTensorRegistry::RestoredTensorInfo\n       restore_tensor_info{.dtype_and_shape = {.dtype = input_tensor.dtype(),\n                                               .shape = input_tensor.shape()},\n@@ -609,7 +609,7 @@ TEST_P(KernelTest, IfrtRestoreVariableOp) {\n \n   execution_context.AddUserContext(std::move(tf_context_));\n \n-  xla::ifrt::Future<tensorflow::Tensor> uninitialized_entry =\n+  tsl::Future<tensorflow::Tensor> uninitialized_entry =\n       ifrt_model_context_->GetRestoreTensorRegistry().GetRestoredTensor(\n           kVariableRuntimeName);\n   ASSERT_TRUE(uninitialized_entry.IsReady());\n@@ -645,7 +645,7 @@ TEST_P(KernelTest, IfrtRestoreVariableOp) {\n \n   TF_ASSERT_OK(execution_context.status());\n \n-  xla::ifrt::Future<tensorflow::Tensor> restored_future =\n+  tsl::Future<tensorflow::Tensor> restored_future =\n       ifrt_model_context_->GetRestoreTensorRegistry().GetRestoredTensor(\n           absl::StrCat(kVariableRuntimeName, 0));\n   absl::StatusOr<tensorflow::Tensor> restored_tensor = restored_future.Await();\n@@ -672,7 +672,7 @@ TEST_P(KernelTest, IfrtRestoreVariableOp4Variables) {\n \n   execution_context.AddUserContext(std::move(tf_context_));\n \n-  xla::ifrt::Future<tensorflow::Tensor> uninitialized_entry =\n+  tsl::Future<tensorflow::Tensor> uninitialized_entry =\n       ifrt_model_context_->GetRestoreTensorRegistry().GetRestoredTensor(\n           kVariableRuntimeName);\n   ASSERT_TRUE(uninitialized_entry.IsReady());\n@@ -712,30 +712,30 @@ TEST_P(KernelTest, IfrtRestoreVariableOp4Variables) {\n \n   TF_ASSERT_OK(execution_context.status());\n \n-  xla::ifrt::Future<tensorflow::Tensor> restored_future =\n+  tsl::Future<tensorflow::Tensor> restored_future =\n       ifrt_model_context_->GetRestoreTensorRegistry().GetRestoredTensor(\n           absl::StrCat(kVariableRuntimeName, 0));\n   absl::StatusOr<tensorflow::Tensor> restored_tensor = restored_future.Await();\n   TF_ASSERT_OK(restored_tensor.status());\n   EXPECT_THAT(*restored_tensor, TensorEq(AsTensor<int16_t>({1, 2, 3}, {3})));\n \n-  xla::ifrt::Future<tensorflow::Tensor> restored_future1 =\n+  tsl::Future<tensorflow::Tensor> restored_future1 =\n       ifrt_model_context_->GetRestoreTensorRegistry().GetRestoredTensor(\n           absl::StrCat(kVariableRuntimeName, 1));\n   absl::StatusOr<tensorflow::Tensor> restored_tensor1 =\n       restored_future1.Await();\n   TF_ASSERT_OK(restored_tensor1.status());\n   EXPECT_THAT(*restored_tensor1, TensorEq(AsTensor<int16_t>({4, 5, 6}, {3})));\n \n-  xla::ifrt::Future<tensorflow::Tensor> restored_future2 =\n+  tsl::Future<tensorflow::Tensor> restored_future2 =\n       ifrt_model_context_->GetRestoreTensorRegistry().GetRestoredTensor(\n           absl::StrCat(kVariableRuntimeName, 2));\n   absl::StatusOr<tensorflow::Tensor> restored_tensor2 =\n       restored_future2.Await();\n   TF_ASSERT_OK(restored_tensor2.status());\n   EXPECT_THAT(*restored_tensor2, TensorEq(AsTensor<int16_t>({7, 8, 9}, {3})));\n \n-  xla::ifrt::Future<tensorflow::Tensor> restored_future3 =\n+  tsl::Future<tensorflow::Tensor> restored_future3 =\n       ifrt_model_context_->GetRestoreTensorRegistry().GetRestoredTensor(\n           absl::StrCat(kVariableRuntimeName, 3));\n   absl::StatusOr<tensorflow::Tensor> restored_tensor3 =\n@@ -764,7 +764,7 @@ TEST_P(KernelTest, IfrtRestoreVariableOpInValidInput) {\n \n   execution_context.AddUserContext(std::move(tf_context_));\n \n-  xla::ifrt::Future<tensorflow::Tensor> uninitialized_entry =\n+  tsl::Future<tensorflow::Tensor> uninitialized_entry =\n       ifrt_model_context_->GetRestoreTensorRegistry().GetRestoredTensor(\n           kVariableRuntimeName);\n   ASSERT_TRUE(uninitialized_entry.IsReady());"
        },
        {
            "sha": "d445433b79051b7318621925f77f8e601473a008",
            "filename": "third_party/xla/xla/backends/cpu/nanort/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2FBUILD?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -167,6 +167,7 @@ cc_library(\n         \"//xla/python/pjrt_ifrt:xla_ifrt\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/tsl/concurrency:async_value\",\n+        \"//xla/tsl/concurrency:future\",\n         \"//xla/tsl/concurrency:ref_count\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\","
        },
        {
            "sha": "2e84d2abd068b701042a554fe89c306cfdf41fe5",
            "filename": "third_party/xla/xla/backends/cpu/nanort/ifrt_client.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 12,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.cc?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -68,7 +68,6 @@ limitations under the License.\n #include \"xla/python/ifrt/device_list.h\"\n #include \"xla/python/ifrt/dtype.h\"\n #include \"xla/python/ifrt/executable.h\"\n-#include \"xla/python/ifrt/future.h\"\n #include \"xla/python/ifrt/hlo/hlo_program.h\"\n #include \"xla/python/ifrt/index.h\"\n #include \"xla/python/ifrt/index_domain.h\"\n@@ -88,6 +87,7 @@ limitations under the License.\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -107,8 +107,8 @@ static const char kMemoryKind[] = \"\";\n \n // Returns a Future that is immediately ready with the given status. This is\n // mostly useful because everything NanoRT does is immediately ready.\n-ifrt::Future<> Ready(absl::Status status = absl::OkStatus()) {\n-  return ifrt::Future<>(std::move(status));\n+tsl::Future<> Ready(absl::Status status = absl::OkStatus()) {\n+  return tsl::Future<>(std::move(status));\n }\n \n // Base class for all value types. This class doesn't participate in the llvm\n@@ -129,10 +129,10 @@ class NanoValue : public llvm::RTTIExtends<Self, Base> {\n   ifrt::UserContextRef user_context() const override { return user_context_; }\n \n   // All nano values are immediately ready.\n-  ifrt::Future<> GetReadyFuture() const override { return Ready(); }\n+  tsl::Future<> GetReadyFuture() const override { return Ready(); }\n \n   // Subclasses must still implement Delete().\n-  ifrt::Future<> Delete() override = 0;\n+  tsl::Future<> Delete() override = 0;\n   bool IsDeleted() const override = 0;\n \n   // Helper that returns an error if this value is accessed after it has been\n@@ -392,7 +392,7 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n                         reinterpret_cast<uintptr_t>(data_), \")\");\n   }\n \n-  ifrt::Future<> Delete() override {\n+  tsl::Future<> Delete() override {\n     data_ = nullptr;\n     owned_data_ = nullptr;\n     return Ready();\n@@ -431,7 +431,7 @@ class NanoArray final : public NanoValue<NanoArray, ifrt::Array> {\n     return tsl::FormRef(this);\n   }\n \n-  ifrt::Future<> CopyToHostBuffer(\n+  tsl::Future<> CopyToHostBuffer(\n       void* data, std::optional<absl::Span<const int64_t>> byte_strides,\n       ifrt::ArrayCopySemantics semantics) override {\n     // Run everything in a lambda so we can use error macros and convert to a\n@@ -615,7 +615,7 @@ class ShardedNanoArray final : public NanoValue<ShardedNanoArray, ifrt::Array> {\n     return assemble_result_;\n   }\n \n-  ifrt::Future<> Delete() override {\n+  tsl::Future<> Delete() override {\n     // Sharded arrays are never borrowed like dense arrays are, so we can just\n     // clear the shards and let them be destroyed.\n     shards_.clear();\n@@ -662,7 +662,7 @@ class ShardedNanoArray final : public NanoValue<ShardedNanoArray, ifrt::Array> {\n     return tsl::FormRef(this);\n   }\n \n-  ifrt::Future<> CopyToHostBuffer(\n+  tsl::Future<> CopyToHostBuffer(\n       void* data, std::optional<absl::Span<const int64_t>> byte_strides,\n       ifrt::ArrayCopySemantics semantics) override {\n     return Ready(Internal(\"Cannot copy sharded array to host buffer.\"));\n@@ -749,7 +749,7 @@ class NanoTuple final : public NanoValue<NanoTuple, ifrt::Tuple> {\n       : NanoValue<NanoTuple, ifrt::Tuple>(client),\n         values_(values.begin(), values.end()) {}\n \n-  ifrt::Future<> Delete() override {\n+  tsl::Future<> Delete() override {\n     for (auto& value : values_) {\n       value->Delete();\n     }\n@@ -918,7 +918,7 @@ class NanoExecutable final\n \n   ifrt::UserContextRef user_context() const override { return user_context_; }\n \n-  ifrt::Future<> GetReadyFuture() const override { return Ready(); }\n+  tsl::Future<> GetReadyFuture() const override { return Ready(); }\n \n   int num_devices() const override { return 1; }\n \n@@ -1402,7 +1402,7 @@ absl::StatusOr<std::vector<xla::ifrt::ArrayRef>> NanoIfrtClient::ReshardArrays(\n   return absl::UnimplementedError(\"ReshardArrays is not implemented.\");\n }\n \n-ifrt::Future<> NanoIfrtClient::GetReadyFuture(\n+tsl::Future<> NanoIfrtClient::GetReadyFuture(\n     absl::Span<const ifrt::ValueRef> values) {\n   return Ready();\n }"
        },
        {
            "sha": "faf7006a56d7e34cb9b3fdc2e8395b9419988cca",
            "filename": "third_party/xla/xla/backends/cpu/nanort/ifrt_client.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fnanort%2Fifrt_client.h?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -37,7 +37,6 @@ limitations under the License.\n #include \"xla/python/ifrt/device.h\"\n #include \"xla/python/ifrt/device_list.h\"\n #include \"xla/python/ifrt/dtype.h\"\n-#include \"xla/python/ifrt/future.h\"\n #include \"xla/python/ifrt/memory.h\"\n #include \"xla/python/ifrt/remap_plan.h\"\n #include \"xla/python/ifrt/shape.h\"\n@@ -46,6 +45,7 @@ limitations under the License.\n #include \"xla/python/ifrt/tuple.h\"\n #include \"xla/python/ifrt/user_context.h\"\n #include \"xla/python/ifrt/value.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n \n namespace Eigen {\n@@ -152,7 +152,7 @@ class NanoIfrtClient : public llvm::RTTIExtends<NanoIfrtClient, ifrt::Client> {\n       absl::Span<const xla::ifrt::ArraySpec> specs,\n       xla::ifrt::ArrayCopySemantics semantics) override;\n \n-  ifrt::Future<> GetReadyFuture(\n+  tsl::Future<> GetReadyFuture(\n       absl::Span<const ifrt::ValueRef> values) override;\n \n   absl::StatusOr<tsl::RCReference<ifrt::Tuple>> MakeTuple("
        },
        {
            "sha": "943810b3b1f6470bb1f320b69cff03f69f3e0723",
            "filename": "third_party/xla/xla/python/compile_only_ifrt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/third_party%2Fxla%2Fxla%2Fpython%2Fcompile_only_ifrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/third_party%2Fxla%2Fxla%2Fpython%2Fcompile_only_ifrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fcompile_only_ifrt%2FBUILD?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -28,6 +28,7 @@ cc_library(\n         \"//xla/python/pjrt_ifrt:pjrt_attribute_map_util\",\n         \"//xla/python/pjrt_ifrt:pjrt_dtype\",\n         \"//xla/service:computation_placer_hdr\",\n+        \"//xla/tsl/concurrency:future\",\n         \"//xla/tsl/concurrency:ref_count\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/status\","
        },
        {
            "sha": "d14ada7a8ec213f50b3040f4ae3504aba3eed7e0",
            "filename": "third_party/xla/xla/python/compile_only_ifrt/client.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6d074d6de923d1fb48f2cc0d6393957f3c659818/third_party%2Fxla%2Fxla%2Fpython%2Fcompile_only_ifrt%2Fclient.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6d074d6de923d1fb48f2cc0d6393957f3c659818/third_party%2Fxla%2Fxla%2Fpython%2Fcompile_only_ifrt%2Fclient.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fcompile_only_ifrt%2Fclient.h?ref=6d074d6de923d1fb48f2cc0d6393957f3c659818",
            "patch": "@@ -45,7 +45,6 @@ limitations under the License.\n #include \"xla/python/ifrt/device_list.h\"\n #include \"xla/python/ifrt/dtype.h\"\n #include \"xla/python/ifrt/executable.h\"\n-#include \"xla/python/ifrt/future.h\"\n #include \"xla/python/ifrt/memory.h\"\n #include \"xla/python/ifrt/program.h\"\n #include \"xla/python/ifrt/remap_plan.h\"\n@@ -59,6 +58,7 @@ limitations under the License.\n #include \"xla/python/pjrt_ifrt/pjrt_dtype.h\"\n #include \"xla/python/pjrt_ifrt/pjrt_topology.h\"\n #include \"xla/service/computation_placer.h\"\n+#include \"xla/tsl/concurrency/future.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n@@ -270,9 +270,9 @@ class CompileOnlyIfRtClient final\n         \"ReshardArrays not available with compile-only client.\");\n   }\n \n-  ifrt::Future<> GetReadyFuture(\n+  tsl::Future<> GetReadyFuture(\n       absl::Span<const ifrt::ValueRef> values) override {\n-    return ifrt::Future<>(Unimplemented(\n+    return tsl::Future<>(Unimplemented(\n         \"GetReadyFuture not available with compile-only client.\"));\n   }\n "
        }
    ],
    "stats": {
        "total": 179,
        "additions": 92,
        "deletions": 87
    }
}