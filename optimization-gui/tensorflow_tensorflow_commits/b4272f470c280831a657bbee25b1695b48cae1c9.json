{
    "author": "ezhulenev",
    "message": "[xla:hlo] Do not depend on XLA:CPU implementation from HloEvaluator\n\nPiperOrigin-RevId: 828757915",
    "sha": "b4272f470c280831a657bbee25b1695b48cae1c9",
    "files": [
        {
            "sha": "9bfad6ee2758e7b8056995223ac4f051f5fb0778",
            "filename": "third_party/xla/xla/hlo/evaluator/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b4272f470c280831a657bbee25b1695b48cae1c9/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b4272f470c280831a657bbee25b1695b48cae1c9/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2FBUILD?ref=b4272f470c280831a657bbee25b1695b48cae1c9",
            "patch": "@@ -76,7 +76,6 @@ cc_library(\n         \"//xla/service:logical_buffer\",\n         \"//xla/service:pattern_matcher\",\n         \"//xla/service:shape_inference\",\n-        \"//xla/service/cpu:runtime_single_threaded_matmul\",\n         \"//xla/tsl/lib/core:bitmap\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\","
        },
        {
            "sha": "a1f935eda2f0ce5ba7ea96cdf69b29cf4e6b09f9",
            "filename": "third_party/xla/xla/hlo/evaluator/hlo_evaluator.cc",
            "status": "modified",
            "additions": 37,
            "deletions": 42,
            "changes": 79,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b4272f470c280831a657bbee25b1695b48cae1c9/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b4272f470c280831a657bbee25b1695b48cae1c9/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator.cc?ref=b4272f470c280831a657bbee25b1695b48cae1c9",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n #include \"xla/hlo/evaluator/hlo_evaluator.h\"\n \n #include <algorithm>\n+#include <array>\n #include <atomic>\n #include <cmath>\n #include <complex>\n@@ -69,7 +70,6 @@ limitations under the License.\n #include \"xla/literal_util.h\"\n #include \"xla/primitive_util.h\"\n #include \"xla/service/compilation_environments.h\"\n-#include \"xla/service/cpu/runtime_single_threaded_matmul.h\"\n #include \"xla/service/gather_scatter_utils.h\"\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/service/logical_buffer.h\"\n@@ -88,6 +88,13 @@ limitations under the License.\n #include \"xla/xla_data.pb.h\"\n #include \"tsl/platform/cpu_info.h\"\n \n+#define EIGEN_USE_THREADS\n+#include \"unsupported/Eigen/CXX11/Tensor\"\n+\n+#if defined(TENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL)\n+#include \"xla/tsl/framework/contraction/eigen_contraction_kernel.h\"\n+#endif\n+\n namespace xla {\n \n namespace {\n@@ -4891,76 +4898,68 @@ absl::Status HloEvaluator::Postprocess(const HloInstruction* hlo) {\n   return absl::OkStatus();\n }\n \n-namespace {\n template <typename T>\n-std::unique_ptr<Array2D<T>> MatmulArray2DImpl(\n-    const Array2D<T>& lhs, const Array2D<T>& rhs,\n-    const std::function<void(const void* run_options_ptr, T* out, T* lhs,\n-                             T* rhs, int64_t m, int64_t n, int64_t k,\n-                             int32_t transpose_lhs, int32_t transpose_rhs)>&\n-        impl_fn) {\n+static std::unique_ptr<Array2D<T>> MatmulArray2DImpl(const Array2D<T>& lhs,\n+                                                     const Array2D<T>& rhs) {\n   CHECK_EQ(lhs.width(), rhs.height());\n   int m = lhs.height();\n-  int n = rhs.width();\n   int k = lhs.width();\n+  int n = rhs.width();\n   auto result = std::make_unique<Array2D<T>>(m, n);\n-  // Because Eigen is a header-oriented library, make sure that the Eigen code\n-  // is the same as the code used by the CPU backend (otherwise the linker will\n-  // randomly pick *some* definition).\n-  impl_fn(\n-      /*run_options_ptr=*/nullptr, result->data(), rhs.data(), lhs.data(), n, m,\n-      k,\n-      /*transpose_lhs=*/0,\n-      /*transpose_rhs=*/0);\n+\n+  using ConstTensor = Eigen::Tensor<const T, 2, Eigen::RowMajor>;\n+  using Tensor = Eigen::Tensor<T, 2, Eigen::RowMajor>;\n+\n+  Eigen::TensorMap<ConstTensor> A(lhs.data(), m, k);\n+  Eigen::TensorMap<ConstTensor> B(rhs.data(), k, n);\n+  Eigen::TensorMap<Tensor> C(result->data(), m, n);\n+\n+  using DimPair = typename ConstTensor::DimensionPair;\n+  std::array<DimPair, 1> dims({DimPair(1, 0)});\n+\n+  C = A.contract(B, dims);\n+\n   return result;\n }\n-}  // namespace\n \n std::unique_ptr<Array2D<Eigen::half>> HloEvaluator::MatmulArray2D(\n     const Array2D<Eigen::half>& lhs, const Array2D<Eigen::half>& rhs) {\n-  return MatmulArray2DImpl<Eigen::half>(\n-      lhs, rhs, __xla_cpu_runtime_EigenSingleThreadedMatMulF16);\n+  return MatmulArray2DImpl<Eigen::half>(lhs, rhs);\n }\n \n std::unique_ptr<Array2D<float>> HloEvaluator::MatmulArray2D(\n     const Array2D<float>& lhs, const Array2D<float>& rhs) {\n-  return MatmulArray2DImpl<float>(\n-      lhs, rhs, __xla_cpu_runtime_EigenSingleThreadedMatMulF32);\n+  return MatmulArray2DImpl<float>(lhs, rhs);\n }\n \n std::unique_ptr<Array2D<double>> HloEvaluator::MatmulArray2D(\n     const Array2D<double>& lhs, const Array2D<double>& rhs) {\n-  return MatmulArray2DImpl<double>(\n-      lhs, rhs, __xla_cpu_runtime_EigenSingleThreadedMatMulF64);\n+  return MatmulArray2DImpl<double>(lhs, rhs);\n }\n \n std::unique_ptr<Array2D<std::complex<float>>> HloEvaluator::MatmulArray2D(\n     const Array2D<std::complex<float>>& lhs,\n     const Array2D<std::complex<float>>& rhs) {\n-  return MatmulArray2DImpl<std::complex<float>>(\n-      lhs, rhs, __xla_cpu_runtime_EigenSingleThreadedMatMulC64);\n+  return MatmulArray2DImpl<std::complex<float>>(lhs, rhs);\n }\n \n std::unique_ptr<Array2D<std::complex<double>>> HloEvaluator::MatmulArray2D(\n     const Array2D<std::complex<double>>& lhs,\n     const Array2D<std::complex<double>>& rhs) {\n-  return MatmulArray2DImpl<std::complex<double>>(\n-      lhs, rhs, __xla_cpu_runtime_EigenSingleThreadedMatMulC128);\n+  return MatmulArray2DImpl<std::complex<double>>(lhs, rhs);\n }\n \n std::unique_ptr<Array2D<int32_t>> HloEvaluator::MatmulArray2D(\n     const Array2D<int32_t>& lhs, const Array2D<int32_t>& rhs) {\n-  return MatmulArray2DImpl<int32_t>(\n-      lhs, rhs, __xla_cpu_runtime_EigenSingleThreadedMatMulS32);\n+  return MatmulArray2DImpl<int32_t>(lhs, rhs);\n }\n \n std::unique_ptr<Array2D<uint8_t>> HloEvaluator::MatmulArray2D(\n     const Array2D<uint8_t>& lhs, const Array2D<uint8_t>& rhs) {\n-  return MatmulArray2DImpl<uint8_t>(\n-      lhs, rhs, __xla_cpu_runtime_EigenSingleThreadedMatMulU8);\n+  return MatmulArray2DImpl<uint8_t>(lhs, rhs);\n }\n \n-/* static */ std::unique_ptr<Array2D<float>> Array2DF8E5M2ToF32(\n+std::unique_ptr<Array2D<float>> Array2DF8E5M2ToF32(\n     const Array2D<tsl::float8_e5m2>& input) {\n   auto result = std::make_unique<Array2D<float>>(input.height(), input.width());\n   for (int64_t rowno = 0; rowno < input.height(); ++rowno) {\n@@ -4971,7 +4970,7 @@ std::unique_ptr<Array2D<uint8_t>> HloEvaluator::MatmulArray2D(\n   return result;\n }\n \n-/* static */ std::unique_ptr<Array2D<float>> Array2DF8E4M3FNToF32(\n+std::unique_ptr<Array2D<float>> Array2DF8E4M3FNToF32(\n     const Array2D<tsl::float8_e4m3fn>& input) {\n   auto result = std::make_unique<Array2D<float>>(input.height(), input.width());\n   for (int64_t rowno = 0; rowno < input.height(); ++rowno) {\n@@ -4982,7 +4981,7 @@ std::unique_ptr<Array2D<uint8_t>> HloEvaluator::MatmulArray2D(\n   return result;\n }\n \n-/* static */ std::unique_ptr<Array2D<tsl::float8_e5m2>> Array2DF32ToF8E5M2(\n+std::unique_ptr<Array2D<tsl::float8_e5m2>> Array2DF32ToF8E5M2(\n     const Array2D<float>& input) {\n   auto result = std::make_unique<Array2D<tsl::float8_e5m2>>(input.height(),\n                                                             input.width());\n@@ -4995,7 +4994,7 @@ std::unique_ptr<Array2D<uint8_t>> HloEvaluator::MatmulArray2D(\n   return result;\n }\n \n-/* static */ std::unique_ptr<Array2D<tsl::float8_e4m3fn>> Array2DF32ToF8E4M3FN(\n+std::unique_ptr<Array2D<tsl::float8_e4m3fn>> Array2DF32ToF8E4M3FN(\n     const Array2D<float>& input) {\n   auto result = std::make_unique<Array2D<tsl::float8_e4m3fn>>(input.height(),\n                                                               input.width());\n@@ -5018,10 +5017,8 @@ std::unique_ptr<Array2D<tsl::float8_e5m2>> HloEvaluator::MatmulArray2D(\n     auto rhs_float = Array2DF8E5M2ToF32(rhs);\n     auto result = MatmulArray2D(*lhs_float, *rhs_float);\n     return Array2DF32ToF8E5M2(*result);\n-  } else {\n-    return MatmulArray2DImpl<tsl::float8_e5m2>(\n-        lhs, rhs, __xla_cpu_runtime_EigenSingleThreadedMatMulF8E5M2);\n   }\n+  return MatmulArray2DImpl<tsl::float8_e5m2>(lhs, rhs);\n }\n \n std::unique_ptr<Array2D<tsl::float8_e4m3fn>> HloEvaluator::MatmulArray2D(\n@@ -5032,10 +5029,8 @@ std::unique_ptr<Array2D<tsl::float8_e4m3fn>> HloEvaluator::MatmulArray2D(\n     auto rhs_float = Array2DF8E4M3FNToF32(rhs);\n     auto result = MatmulArray2D(*lhs_float, *rhs_float);\n     return Array2DF32ToF8E4M3FN(*result);\n-  } else {\n-    return MatmulArray2DImpl<tsl::float8_e4m3fn>(\n-        lhs, rhs, __xla_cpu_runtime_EigenSingleThreadedMatMulF8E4M3FN);\n   }\n+  return MatmulArray2DImpl<tsl::float8_e4m3fn>(lhs, rhs);\n }\n \n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 80,
        "additions": 37,
        "deletions": 43
    }
}