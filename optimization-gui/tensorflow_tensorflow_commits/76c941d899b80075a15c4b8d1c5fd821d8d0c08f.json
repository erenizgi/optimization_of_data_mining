{
    "author": "tensorflower-gardener",
    "message": "[Autotuner] Only capture first element of output_tuple.\n\n- Also capturing input by default now.\n\nPiperOrigin-RevId: 799586495",
    "sha": "76c941d899b80075a15c4b8d1c5fd821d8d0c08f",
    "files": [
        {
            "sha": "2112f467e9b4b89d0f9e0fd2de98b3ffbb32885f",
            "filename": "third_party/xla/xla/backends/autotuner/profiler.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fprofiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fprofiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fprofiler.h?ref=76c941d899b80075a15c4b8d1c5fd821d8d0c08f",
            "patch": "@@ -35,15 +35,15 @@ struct ProfileOptions {\n   // Whether to initialize the buffers with random data or leave them\n   // uninitialized.\n   bool should_init_buffers = false;\n-  // Whether to populate the output_buffer in the ProfileResult with the result\n-  // of the execution. This is to avoid data copies if the caller doesn't need\n-  // the output buffer.\n-  bool should_populate_output_buffer = true;\n };\n \n struct ProfileResult {\n+  // The duration of the executable run.\n   absl::Duration duration = absl::ZeroDuration();\n+  // The output buffer of the executable., only captures the first buffer if\n+  // the output is a tuple.\n   std::optional<ScopedShapedBuffer> output_buffer = std::nullopt;\n+  // The scratch bytes used by the executable, if any.\n   int scratch_bytes = 0;\n };\n "
        },
        {
            "sha": "3753691a8a7ecbe374c89f69747f1faad81c2b84",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/cpu_profiler.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler.cc?ref=76c941d899b80075a15c4b8d1c5fd821d8d0c08f",
            "patch": "@@ -71,8 +71,6 @@ absl::StatusOr<std::unique_ptr<InputBuffers>> CpuProfiler::CreateInputBuffers(\n }\n \n std::unique_ptr<Profiler> CpuProfiler::Create(ProfileOptions options) {\n-  CHECK(options.should_populate_output_buffer == false)\n-      << \"Output buffer is not supported on CPU.\";\n   return absl::WrapUnique(new CpuProfiler(options));\n }\n "
        },
        {
            "sha": "66ecc5d4506d036d90ea6487ddd0e8763146e1a0",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/cpu_profiler_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler_test.cc?ref=76c941d899b80075a15c4b8d1c5fd821d8d0c08f",
            "patch": "@@ -50,7 +50,7 @@ absl::StatusOr<std::unique_ptr<Executable>> CompileHloModule(\n \n class CpuProfilerTest : public HloHardwareIndependentTestBase {\n  public:\n-  CpuProfilerTest() { profile_options_.should_populate_output_buffer = false; }\n+  CpuProfilerTest() = default;\n   ProfileOptions profile_options_;\n };\n "
        },
        {
            "sha": "19aaf862bbe705494de6fc76ef9f85acc3914a5b",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/llvm_kernel_autotuner.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_autotuner.cc?ref=76c941d899b80075a15c4b8d1c5fd821d8d0c08f",
            "patch": "@@ -45,9 +45,7 @@ absl::StatusOr<bool> LlvmKernelAutotuner::Run(\n   TF_ASSIGN_OR_RETURN(auto compiler,\n                       CpuCodegenBackend::CreateBackendCompiler());\n   TF_ASSIGN_OR_RETURN(auto backend, LlvmKernelBackend::Create(compiler.get()));\n-  ProfileOptions profile_options;\n-  profile_options.should_populate_output_buffer = false;\n-  std::unique_ptr<Profiler> profiler = CpuProfiler::Create(profile_options);\n+  std::unique_ptr<Profiler> profiler = CpuProfiler::Create(ProfileOptions());\n \n   std::vector<std::unique_ptr<CodegenBackend>> codegen_backends;\n   codegen_backends.push_back(std::move(backend));"
        },
        {
            "sha": "9242580db8ca4e8256f74c7703bea0074c60a641",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc?ref=76c941d899b80075a15c4b8d1c5fd821d8d0c08f",
            "patch": "@@ -159,9 +159,14 @@ absl::StatusOr<ProfileResult> GpuProfiler::Profile(\n       Execute(executable, std::move(execution_inputs), &profile));\n \n   result.duration = absl::Nanoseconds(profile.compute_time_ns());\n-  if (options_.should_populate_output_buffer) {\n-    result.output_buffer = execution_output.Commit().ConsumeResult();\n+  ScopedShapedBuffer output_buffers = execution_output.Commit().ConsumeResult();\n+  if (output_buffers.on_device_shape().IsTuple() &&\n+      !output_buffers.on_device_shape().tuple_shapes().empty()) {\n+    result.output_buffer = output_buffers.TakeSubTree({0});\n+  } else {\n+    result.output_buffer = std::move(output_buffers);\n   }\n+\n   return result;\n }\n "
        },
        {
            "sha": "9f7e5a340cf109f230e6d915f173578ac8874361",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler_test.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 72,
            "changes": 99,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/76c941d899b80075a15c4b8d1c5fd821d8d0c08f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc?ref=76c941d899b80075a15c4b8d1c5fd821d8d0c08f",
            "patch": "@@ -17,7 +17,6 @@ limitations under the License.\n \n #include <cstdint>\n #include <memory>\n-#include <optional>\n #include <utility>\n #include <vector>\n \n@@ -57,12 +56,7 @@ namespace gpu {\n \n namespace {\n \n-using absl_testing::IsOkAndHolds;\n using absl_testing::StatusIs;\n-using ::testing::ElementsAre;\n-using ::testing::Eq;\n-using ::testing::Field;\n-using ::testing::Ne;\n \n class MockExecutable : public Executable {\n  public:\n@@ -81,8 +75,9 @@ class MockExecutable : public Executable {\n     if (profile != nullptr) {\n       profile->set_compute_time_ns(duration_ns_);\n     }\n-    return ExecutionOutput(ShapeUtil::MakeTupleShape({}),\n-                           ShapeUtil::MakeTupleShape({}),\n+    const Shape& result_shape =\n+        module().entry_computation()->root_instruction()->shape();\n+    return ExecutionOutput(result_shape, result_shape,\n                            run_options->run_options().allocator(),\n                            run_options->run_options().device_ordinal());\n   }\n@@ -122,40 +117,7 @@ class GpuProfilerTest : public HloHardwareIndependentTestBase {\n   std::unique_ptr<se::DeviceMemoryAllocator> allocator_;\n };\n \n-TEST_F(GpuProfilerTest, ProfileWithSharedBuffersWithoutOutputBuffer) {\n-  constexpr absl::string_view kHloModule = R\"(\n-    HloModule module\n-    ENTRY main {\n-      ROOT c = s32[] constant(1)\n-    }\n-  )\";\n-  TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<HloModule> module,\n-                          ParseAndReturnVerifiedModule(kHloModule));\n-  std::vector<std::unique_ptr<Executable>> executables;\n-  executables.push_back(std::make_unique<MockExecutable>(module, 1000));\n-  executables.push_back(std::make_unique<MockExecutable>(module, 2000));\n-\n-  ProfileOptions options;\n-  options.should_populate_output_buffer = false;\n-  auto profiler = GpuProfiler::Create(stream_exec_, options, allocator_.get());\n-  TF_ASSERT_OK_AND_ASSIGN(auto profiles, profiler->ProfileWithSharedBuffers(\n-                                             std::move(executables)));\n-  EXPECT_EQ(profiles.size(), 2);\n-  TF_ASSERT_OK(profiles[0].status());\n-  TF_ASSERT_OK(profiles[1].status());\n-  EXPECT_THAT(profiles,\n-              ElementsAre(IsOkAndHolds(Field(&ProfileResult::duration,\n-                                             absl::Nanoseconds(1000))),\n-                          IsOkAndHolds(Field(&ProfileResult::duration,\n-                                             absl::Nanoseconds(2000)))));\n-  EXPECT_THAT(profiles,\n-              ElementsAre(IsOkAndHolds(Field(&ProfileResult::output_buffer,\n-                                             Eq(std::nullopt))),\n-                          IsOkAndHolds(Field(&ProfileResult::output_buffer,\n-                                             Eq(std::nullopt)))));\n-}\n-\n-TEST_F(GpuProfilerTest, ProfileWithSharedBuffers) {\n+TEST_F(GpuProfilerTest, CreateInputBuffersAndProfile) {\n   constexpr absl::string_view kHloModule = R\"(\n     HloModule module\n     ENTRY main {\n@@ -164,47 +126,40 @@ TEST_F(GpuProfilerTest, ProfileWithSharedBuffers) {\n   )\";\n   TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(kHloModule));\n-  std::vector<std::unique_ptr<Executable>> executables;\n-  executables.push_back(std::make_unique<MockExecutable>(module, 1));\n-\n+  MockExecutable mock_executable(module, 1000);\n   auto profiler =\n       GpuProfiler::Create(stream_exec_, ProfileOptions(), allocator_.get());\n-  TF_ASSERT_OK_AND_ASSIGN(auto profiles, profiler->ProfileWithSharedBuffers(\n-                                             std::move(executables)));\n-  EXPECT_THAT(profiles, ElementsAre(IsOkAndHolds(Field(\n-                            &ProfileResult::output_buffer, Ne(std::nullopt)))));\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<InputBuffers> buffers,\n+                          profiler->CreateInputBuffers(&mock_executable));\n+  TF_ASSERT_OK_AND_ASSIGN(ProfileResult profile,\n+                          profiler->Profile(&mock_executable, *buffers));\n+  EXPECT_EQ(profile.duration, absl::Nanoseconds(1000));\n+  EXPECT_EQ(profile.output_buffer->on_device_shape(),\n+            ShapeUtil::MakeShape(S32, {}));\n+  EXPECT_EQ(profile.scratch_bytes, 0);\n }\n \n-TEST_F(GpuProfilerTest, FailingExecutablesReturnStatus) {\n+TEST_F(GpuProfilerTest, ProfileWithTupleOutput) {\n   constexpr absl::string_view kHloModule = R\"(\n     HloModule module\n     ENTRY main {\n-      ROOT c = s32[] constant(1)\n+      ROOT c = (s32[], s32[]) tuple(s32[] constant(1), s32[] constant(2))\n     }\n   )\";\n   TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(kHloModule));\n-  std::vector<std::unique_ptr<Executable>> executables;\n-  executables.push_back(std::make_unique<MockExecutable>(module, 1000));\n-  executables.push_back(\n-      std::make_unique<MockExecutable>(module, 2000, /*should_fail=*/true));\n-  executables.push_back(std::make_unique<MockExecutable>(module, 3000));\n-\n+  MockExecutable mock_executable(module, 1000);\n   auto profiler =\n       GpuProfiler::Create(stream_exec_, ProfileOptions(), allocator_.get());\n-  TF_ASSERT_OK_AND_ASSIGN(auto profiles, profiler->ProfileWithSharedBuffers(\n-                                             std::move(executables)));\n-  EXPECT_EQ(profiles.size(), 3);\n-  TF_ASSERT_OK(profiles[0].status());\n-  EXPECT_FALSE(profiles[1].ok());\n-  TF_ASSERT_OK(profiles[2].status());\n-  EXPECT_THAT(profiles[0], IsOkAndHolds(Field(&ProfileResult::duration,\n-                                              absl::Nanoseconds(1000))));\n-  EXPECT_THAT(profiles[2], IsOkAndHolds(Field(&ProfileResult::duration,\n-                                              absl::Nanoseconds(3000))));\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<InputBuffers> buffers,\n+                          profiler->CreateInputBuffers(&mock_executable));\n+  TF_ASSERT_OK_AND_ASSIGN(ProfileResult profile,\n+                          profiler->Profile(&mock_executable, *buffers));\n+  EXPECT_EQ(profile.output_buffer->on_device_shape(),\n+            ShapeUtil::MakeShape(S32, {}));\n }\n \n-TEST_F(GpuProfilerTest, CreateInputBuffersAndProfile) {\n+TEST_F(GpuProfilerTest, FailingExecutablesReturnStatus) {\n   constexpr absl::string_view kHloModule = R\"(\n     HloModule module\n     ENTRY main {\n@@ -213,15 +168,15 @@ TEST_F(GpuProfilerTest, CreateInputBuffersAndProfile) {\n   )\";\n   TF_ASSERT_OK_AND_ASSIGN(std::shared_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(kHloModule));\n-  MockExecutable mock_executable(module, 1000);\n+  MockExecutable mock_executable(module, /*duration_ns=*/0,\n+                                 /*should_fail=*/true);\n \n   auto profiler =\n       GpuProfiler::Create(stream_exec_, ProfileOptions(), allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<InputBuffers> buffers,\n                           profiler->CreateInputBuffers(&mock_executable));\n-  TF_ASSERT_OK_AND_ASSIGN(ProfileResult profile,\n-                          profiler->Profile(&mock_executable, *buffers));\n-  EXPECT_EQ(profile.duration, absl::Nanoseconds(1000));\n+  EXPECT_THAT(profiler->Profile(&mock_executable, *buffers),\n+              StatusIs(absl::StatusCode::kInternal));\n }\n \n class GpuProfilerTestWithRedzonePadding"
        }
    ],
    "stats": {
        "total": 124,
        "additions": 40,
        "deletions": 84
    }
}