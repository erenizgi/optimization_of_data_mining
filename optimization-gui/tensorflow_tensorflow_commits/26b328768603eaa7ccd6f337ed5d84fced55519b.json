{
    "author": "seantalts",
    "message": "[XLA:CPU] Use new generic Eigen intrinsics (but not plumbed through yet).\n\nPiperOrigin-RevId: 834520435",
    "sha": "26b328768603eaa7ccd6f337ed5d84fced55519b",
    "files": [
        {
            "sha": "ff297f4ffcf871e2d6a7ebdd56fcc5ffb2c5be3f",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 34,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2FBUILD?ref=26b328768603eaa7ccd6f337ed5d84fced55519b",
            "patch": "@@ -1,5 +1,5 @@\n-load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n load(\"//xla:xla.default.bzl\", \"xla_cc_test\")\n+load(\"//xla/tsl/platform:rules_cc.bzl\", \"cc_library\")\n load(\":cc_to_llvm_ir.bzl\", \"cc_ir_header\")\n \n package(\n@@ -33,29 +33,14 @@ cc_library(\n cc_library(\n     name = \"vector_ops\",\n     hdrs = [\"vector_ops.h\"],\n+    deps = [\n+        \"@eigen_archive//:eigen3\",\n+    ],\n )\n \n-cpu_features = select({\n-    \":is_x86_64\": {\n-        \"avx2\": [\n-            \"-mavx2\",\n-            \"-mno-avx512f\",\n-        ],\n-        \"avx512\": [\n-            \"-mavx2\",\n-            \"-mavx512f\",\n-        ],\n-    },\n-    \":is_aarch64\": {\n-        \"neon\": [],\n-    },\n-    \"//conditions:default\": {},\n-})\n-\n cc_ir_header(\n     name = \"tanh_ll\",\n     src = \"tanh.cc\",\n-    cpu_features = cpu_features,\n     deps = [\n         \":cpp_context_provider\",\n         \":tanh\",\n@@ -85,7 +70,6 @@ cc_library(\n cc_ir_header(\n     name = \"eigen_unary_ll\",\n     src = \"eigen_unary.cc\",\n-    cpu_features = cpu_features,\n     deps = [\n         \":cpp_context_provider\",\n         \":eigen_unary_lib\",\n@@ -97,21 +81,10 @@ xla_cc_test(\n     name = \"eigen_unary_test\",\n     srcs = [\"eigen_unary_test.cc\"],\n     deps = [\n+        \":eigen_unary_lib\",\n         \":eigen_unary_ll\",\n+        \":vector_ops\",\n+        \"//xla/codegen/intrinsic:test_matchers\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )\n-\n-config_setting(\n-    name = \"is_x86_64\",\n-    constraint_values = [\n-        \"@platforms//cpu:x86_64\",\n-    ],\n-)\n-\n-config_setting(\n-    name = \"is_aarch64\",\n-    constraint_values = [\n-        \"@platforms//cpu:aarch64\",\n-    ],\n-)"
        },
        {
            "sha": "84a21e4d8aefa3f716aaaa7a2e73f78848027427",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/cc_to_llvm_ir.bzl",
            "status": "modified",
            "additions": 40,
            "deletions": 51,
            "changes": 91,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fcc_to_llvm_ir.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fcc_to_llvm_ir.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fcc_to_llvm_ir.bzl?ref=26b328768603eaa7ccd6f337ed5d84fced55519b",
            "patch": "@@ -1,13 +1,12 @@\n \"\"\"\n-A rule to compile a C++ file to a header containing LLVM IR for various\n-CPU features on the host platform.\n+A rule to compile a C++ file to a header containing LLVM IR.\n \"\"\"\n \n-load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n load(\"@rules_cc//cc:find_cc_toolchain.bzl\", \"find_cc_toolchain\", \"use_cc_toolchain\")\n load(\"@rules_cc//cc/common:cc_common.bzl\", \"cc_common\")\n load(\"@rules_cc//cc/common:cc_info.bzl\", \"CcInfo\")\n load(\"//xla/tsl:package_groups.bzl\", \"DEFAULT_LOAD_VISIBILITY\")\n+load(\"//xla/tsl/platform:rules_cc.bzl\", \"cc_library\")\n \n visibility(DEFAULT_LOAD_VISIBILITY)\n \n@@ -26,47 +25,42 @@ def _cc_ir_header_impl(ctx):\n     compilation_contexts = [dep[CcInfo].compilation_context for dep in ctx.attr.deps]\n     output_header = ctx.outputs.out_header\n \n-    ir_files = []\n-    ir_definitions = []\n-\n-    for feature, flags in sorted(ctx.attr.cpu_features.items()):\n-        ir_file = ctx.actions.declare_file(\"{}{}.ll\".format(ctx.label.name, to_camel_case(feature)))\n-        ir_files.append(ir_file)\n-\n-        cxx_flags = list(flags) + [\"-S\", \"-emit-llvm\", \"-O3\"]\n-        compilation_outputs = cc_common.compile(\n-            actions = ctx.actions,\n-            feature_configuration = feature_configuration,\n-            cc_toolchain = cc_toolchain,\n-            srcs = ctx.files.src,\n-            compilation_contexts = compilation_contexts,\n-            cxx_flags = cxx_flags,\n-            name = \"{}_{}_compiler\".format(ctx.label.name, feature),\n-        )\n-\n-        # 3. Copy the compiler's output to our declared intermediate file.\n-        temp_ir_output = compilation_outputs[1].pic_objects[0]\n-        ctx.actions.run_shell(\n-            inputs = [temp_ir_output],\n-            outputs = [ir_file],\n-            command = \"cp {} {}\".format(temp_ir_output.path, ir_file.path),\n-            mnemonic = \"CopyLLVMIR{}\".format(to_camel_case(feature)),\n-        )\n-\n-        # 4. Prepare the C++ variable definition for the header.\n-        feature_camel_case = to_camel_case(feature)\n-        ir_definitions.append(\n-            'inline constexpr char k{base_name}{feature}Ir[] = R\"IR(\\\\n$(cat {input})\\\\n)IR\";'.format(\n-                base_name = to_camel_case(ctx.attr.base_name),\n-                feature = feature_camel_case,\n-                input = ir_file.path,\n-            ),\n-        )\n-\n-    # 5. Generate the final C++ header file.\n-    all_definitions = \"\\n\\n\".join(ir_definitions)\n+    ir_file = ctx.actions.declare_file(\"{}.ll\".format(ctx.label.name))\n+\n+    cxx_flags = [\n+        \"-S\",\n+        \"-emit-llvm\",\n+        \"-O3\",\n+        \"-DEIGEN_VECTORIZE_GENERIC\",\n+    ]\n+    compilation_outputs = cc_common.compile(\n+        actions = ctx.actions,\n+        feature_configuration = feature_configuration,\n+        cc_toolchain = cc_toolchain,\n+        srcs = ctx.files.src,\n+        compilation_contexts = compilation_contexts,\n+        cxx_flags = cxx_flags,\n+        name = \"{}_compiler\".format(ctx.label.name),\n+    )\n+\n+    # Copy the compiler's output to our declared intermediate file.\n+    temp_ir_output = compilation_outputs[1].pic_objects[0]\n+    ctx.actions.run_shell(\n+        inputs = [temp_ir_output],\n+        outputs = [ir_file],\n+        command = \"cp {} {}\".format(temp_ir_output.path, ir_file.path),\n+        mnemonic = \"CopyLLVMIR\",\n+    )\n+\n+    # Prepare the C++ variable definition for the header.\n+    ir_definition = 'inline constexpr char k{base_name}Ir[] = R\"IR($(cat {input}))IR\";'.format(\n+        base_name = to_camel_case(ctx.attr.base_name),\n+        input = ir_file.path,\n+    )\n+\n+    # Generate the final C++ header file.\n     ctx.actions.run_shell(\n-        inputs = ir_files,\n+        inputs = [ir_file],\n         outputs = [output_header],\n         mnemonic = \"EmbeddingLLVMIR\",\n         command = \"\"\"\n@@ -83,7 +77,7 @@ namespace {namespace} {{\n EOF\n \"\"\".format(\n             output = output_header.path,\n-            defs = all_definitions,\n+            defs = ir_definition,\n             namespace = ctx.attr.namespace,\n         ),\n         progress_message = \"Embedding LLVM IR into header for %s\" % ctx.label,\n@@ -106,10 +100,6 @@ _cc_ir_header_rule = rule(\n             mandatory = True,\n             doc = \"The output header file.\",\n         ),\n-        \"cpu_features\": attr.string_list_dict(\n-            mandatory = True,\n-            doc = \"A dictionary mapping feature names to lists of CXX flags. Use select() here.\",\n-        ),\n         \"base_name\": attr.string(\n             mandatory = True,\n             doc = \"The base name of the generated IR variables.\",\n@@ -124,14 +114,13 @@ _cc_ir_header_rule = rule(\n     fragments = [\"cpp\"],\n )\n \n-def cc_ir_header(name, src, deps, cpu_features, **kwargs):\n+def cc_ir_header(name, src, deps, **kwargs):\n     \"\"\"A macro that generates an IR header and wraps it in a cc_library.\n \n     Args:\n       name: The name of the generated cc_library.\n       src: The C++ source file to compile.\n       deps: The C++ dependencies of the source file.\n-      cpu_features: A dictionary mapping feature names to lists of CXX flags. Use select() here.\n       **kwargs: Additional arguments to pass to the generated cc_library.\n     \"\"\"\n     out_header = name + \".h\"\n@@ -143,8 +132,8 @@ def cc_ir_header(name, src, deps, cpu_features, **kwargs):\n         tags = [\"manual\"],\n         src = src,\n         deps = deps,\n-        cpu_features = cpu_features,\n         out_header = out_header,\n+        # copybara_removed compatible_with = [\"//buildenv/target:non_prod\"],\n         **kwargs\n     )\n "
        },
        {
            "sha": "248b760e32af71bad695904a74f7da5fb3d48510",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/eigen_unary.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 12,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Feigen_unary.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Feigen_unary.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Feigen_unary.cc?ref=26b328768603eaa7ccd6f337ed5d84fced55519b",
            "patch": "@@ -20,19 +20,28 @@ limitations under the License.\n \n namespace xla::codegen {\n \n-// Using Packet over a Map'd Array yields better llvm IR on ARM.\n-using Packet4f = Eigen::internal::Packet4f;\n-\n-Vec4f FastTanhf(const Vec4f x) {\n-  Packet4f packet = static_cast<Eigen::internal::Packet4f>(x);\n-  Packet4f res = Eigen::internal::ptanh_float(packet);\n-  return *static_cast<Vec4f*>(&res);\n+//===--------------------------------------------------------------------===//\n+// Generic conversion and operation\n+//===--------------------------------------------------------------------===//\n+\n+template <typename VecType>\n+inline VecType VectorTanh(const VecType x) {\n+  using ArrayType = typename ArrayMap<VecType>::type;\n+  ArrayType x_array = *reinterpret_cast<const ArrayType*>(&x);\n+  ArrayType result = x_array.tanh();\n+  return *reinterpret_cast<const VecType*>(&result);\n }\n \n-Vec8d FastRqsqrtf(const Vec8d x) {\n-  const Eigen::Map<const Eigen::Array<double, 8, 1>> x_arr((const double*)&x);\n-  const Eigen::Array<double, 8, 1> res = x_arr.rsqrt();\n-  return *(Vec8d*)res.data();\n-}\n+//===--------------------------------------------------------------------===//\n+// XLA entrypoints, renamed with asm in header file.\n+//===--------------------------------------------------------------------===//\n+\n+// Single precision\n+float tanh_f32(float x) { return Eigen::internal::ptanh_float(x); }\n+Vec16f tanh_v16f32(Vec16f x) { return VectorTanh(x); }\n+\n+// Double precision\n+double tanh_f64(double x) { return Eigen::internal::ptanh_double(x); }\n+Vec8d tanh_v8f64(Vec8d x) { return VectorTanh(x); }\n \n }  // namespace xla::codegen"
        },
        {
            "sha": "1248cde5ef117682cc1e05b0f6f2ef8347b0ac92",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/eigen_unary.h",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Feigen_unary.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Feigen_unary.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Feigen_unary.h?ref=26b328768603eaa7ccd6f337ed5d84fced55519b",
            "patch": "@@ -19,8 +19,13 @@ limitations under the License.\n \n namespace xla::codegen {\n \n-Vec4f FastTanhf(Vec4f x) asm(\"xla.tanh.v4f32\");\n-Vec8d FastRqsqrtf(Vec8d x) asm(\"xla.rsqrt.v8f64\");\n+// Single precision\n+float tanh_f32(float x) asm(\"xla.tanh.f32\");\n+Vec16f tanh_v16f32(Vec16f x) asm(\"xla.tanh.v16f32\");\n+\n+// Double precision\n+double tanh_f64(double x) asm(\"xla.tanh.f64\");\n+Vec8d tanh_v8f64(Vec8d x) asm(\"xla.tanh.v8f64\");\n \n }  // namespace xla::codegen\n "
        },
        {
            "sha": "eae40e857c50572eda519bf4b3e1af858f9ee306",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/eigen_unary_test.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 23,
            "changes": 56,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Feigen_unary_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Feigen_unary_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Feigen_unary_test.cc?ref=26b328768603eaa7ccd6f337ed5d84fced55519b",
            "patch": "@@ -13,41 +13,51 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include \"xla/codegen/intrinsic/cpp/eigen_unary.h\"\n+\n+#include <cmath>\n #include <string>\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"xla/codegen/intrinsic/cpp/eigen_unary_ll.h\"\n+#include \"xla/codegen/intrinsic/cpp/vector_ops.h\"\n+#include \"xla/codegen/intrinsic/test_matchers.h\"\n \n namespace xla::codegen {\n namespace {\n using ::testing::ContainsRegex;\n using ::testing::Not;\n+using ::xla::codegen::intrinsic::NearUlps;\n+\n+constexpr int kTanhUlps = 4;\n+\n+TEST(EigenUnaryTest, FastTanhfIsCorrect) {\n+  Vec16f x = {1.0f,  2.0f,  -1.0f, 4.0f,   8.0f,   16.0f,  32.0f, 64.0f,\n+              -2.0f, -4.0f, -8.0f, -16.0f, -32.0f, -64.0f, 0.0f,  0.5f};\n+  Vec16f y = tanh_v16f32(x);\n+  for (int i = 0; i < 16; ++i) {\n+    EXPECT_THAT(y[i], NearUlps(std::tanh(x[i]), kTanhUlps));\n+  }\n+}\n+\n+TEST(EigenUnaryTest, v8f64TanhIsCorrect) {\n+  Vec8d x = {1.0, 2.0, -1.0, 4.0, 8.0, 16.0, 32.0, 64.0};\n+  Vec8d y = tanh_v8f64(x);\n+  for (int i = 0; i < 8; ++i) {\n+    EXPECT_THAT(y[i], NearUlps(std::tanh(x[i]), kTanhUlps));\n+  }\n+}\n \n TEST(EigenUnaryTest, FastTanhfIsVectorized) {\n-#ifdef __x86_64__\n-  const std::string avx2 = llvm_ir::kEigenUnaryLlAvx2Ir;\n-  EXPECT_THAT(avx2, ContainsRegex(\"fmul <4 x float>\"));\n-  EXPECT_THAT(avx2, ContainsRegex(\"<4 x float>.*0x3E4DF2A3C0000000\"));\n-  EXPECT_THAT(avx2, ContainsRegex(\"llvm.x86\"));\n-  EXPECT_THAT(avx2, Not(ContainsRegex(\"llvm.aarch64\")));\n-  EXPECT_THAT(avx2, Not(ContainsRegex(\"llvm.fma.v4f32\")));\n-  EXPECT_THAT(avx2, ContainsRegex(\"xla.tanh.v4f32\"));\n-\n-  const std::string avx512 = llvm_ir::kEigenUnaryLlAvx512Ir;\n-  EXPECT_THAT(avx512, ContainsRegex(\"fmul <4 x float>\"));\n-  EXPECT_THAT(avx512, ContainsRegex(\"<4 x float>.*0x3E4DF2A3C0000000\"));\n-  EXPECT_THAT(avx512, ContainsRegex(\"llvm.x86\"));\n-  EXPECT_THAT(avx512, ContainsRegex(\"llvm.fma.v4f32\"));\n-#endif\n-\n-#ifdef __aarch64__\n-  const std::string neon = llvm_ir::kEigenUnaryLlNeonIr;\n-  EXPECT_THAT(neon, ContainsRegex(\"fmul <4 x float>\"));\n-  EXPECT_THAT(neon, ContainsRegex(\"<4 x float>.*0x3E4DF2A3C0000000\"));\n-  EXPECT_THAT(neon, ContainsRegex(\"llvm.aarch64.neon\"));\n-  EXPECT_THAT(neon, Not(ContainsRegex(\"llvm.x86\")));\n-#endif\n+  const std::string ir = llvm_ir::kEigenUnaryLlIr;\n+  EXPECT_THAT(ir, ContainsRegex(\"fmul <16 x float>\"));\n+  EXPECT_THAT(ir, ContainsRegex(\"fmul <8 x double>\"));\n+  EXPECT_THAT(ir, ContainsRegex(\"<16 x float>.*0x3E4DF2A3C0000000\"));\n+  EXPECT_THAT(ir, Not(ContainsRegex(\"llvm.x86\")));\n+  EXPECT_THAT(ir, Not(ContainsRegex(\"llvm.aarch64\")));\n+  EXPECT_THAT(ir, ContainsRegex(\"xla.tanh.v16f32\"));\n+  EXPECT_THAT(ir, ContainsRegex(\"xla.tanh.v8f64\"));\n }\n \n }  // namespace"
        },
        {
            "sha": "cc96deeaf53680d29981d409a8449b577f92ba27",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/tanh.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh.h?ref=26b328768603eaa7ccd6f337ed5d84fced55519b",
            "patch": "@@ -23,6 +23,9 @@ limitations under the License.\n namespace xla {\n namespace codegen {\n \n+// WARNING: This file exists right now purely as a proof-of-concept showing how\n+// to hand-code portable llvm ir intrinsics using C++.\n+\n template <typename T>\n T FastTanhf(T x) {\n   T abs_x = BitwiseAbs<T>(x);"
        },
        {
            "sha": "4085044ad642e36f857468be1bdbeaeea572cc61",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/tanh_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 9,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Ftanh_test.cc?ref=26b328768603eaa7ccd6f337ed5d84fced55519b",
            "patch": "@@ -26,18 +26,10 @@ using ::testing::ContainsRegex;\n namespace {\n \n TEST(TanhTest, FloatTanhVectorized) {\n-#ifdef __x86_64__\n-  std::string ir = llvm_ir::kTanhLlAvx2Ir;\n+  std::string ir = llvm_ir::kTanhLlIr;\n   EXPECT_THAT(ir, ContainsRegex(\"fmul <4 x float>\"));\n   EXPECT_THAT(\n       ir, ContainsRegex(\"fcmp olt <4 x float>.*float 0x3F3A36E2E0000000.*\"));\n-#endif\n-#ifdef __aarch64__\n-  std::string ir = llvm_ir::kTanhLlNeonIr;\n-  EXPECT_THAT(ir, ContainsRegex(\"fmul <4 x float>\"));\n-  EXPECT_THAT(\n-      ir, ContainsRegex(\"fcmp olt <4 x float>.*float 0x3F3A36E2E0000000.*\"));\n-#endif\n }\n }  // namespace\n }  // namespace codegen"
        },
        {
            "sha": "15c5505dbe4e22f89eca82496517011be3952972",
            "filename": "third_party/xla/xla/codegen/intrinsic/cpp/vector_ops.h",
            "status": "modified",
            "additions": 51,
            "deletions": 1,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fvector_ops.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/26b328768603eaa7ccd6f337ed5d84fced55519b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fvector_ops.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fcpp%2Fvector_ops.h?ref=26b328768603eaa7ccd6f337ed5d84fced55519b",
            "patch": "@@ -20,11 +20,20 @@ limitations under the License.\n #include <cstdint>\n #include <type_traits>\n \n+#include \"Eigen/Core\"\n+\n namespace xla {\n namespace codegen {\n-// Float types\n+// Half precision (float16)\n+typedef _Float16 Vec8h __attribute__((vector_size(16)));\n+typedef _Float16 Vec16h __attribute__((vector_size(32)));\n+\n+// Single precision (float32)\n typedef float Vec4f __attribute__((vector_size(16)));\n typedef float Vec8f __attribute__((vector_size(32)));\n+typedef float Vec16f __attribute__((vector_size(64)));\n+\n+// Double precision (float64)\n typedef double Vec2d __attribute__((vector_size(16)));\n typedef double Vec4d __attribute__((vector_size(32)));\n typedef double Vec8d __attribute__((vector_size(64)));\n@@ -76,6 +85,47 @@ struct CorrespondingIntVector {\n };\n }  // namespace internal\n \n+// ===--------------------------------------------------------------------===//\n+// Eigen Array type mapping\n+// ===--------------------------------------------------------------------===//\n+template <typename VecType>\n+struct ArrayMap;\n+\n+template <>\n+struct ArrayMap<Vec8h> {\n+  using type = Eigen::Array<Eigen::half, 8, 1>;\n+};\n+template <>\n+struct ArrayMap<Vec16h> {\n+  using type = Eigen::Array<Eigen::half, 16, 1>;\n+};\n+\n+template <>\n+struct ArrayMap<Vec4f> {\n+  using type = Eigen::Array<float, 4, 1>;\n+};\n+template <>\n+struct ArrayMap<Vec8f> {\n+  using type = Eigen::Array<float, 8, 1>;\n+};\n+template <>\n+struct ArrayMap<Vec16f> {\n+  using type = Eigen::Array<float, 16, 1>;\n+};\n+\n+template <>\n+struct ArrayMap<Vec2d> {\n+  using type = Eigen::Array<double, 2, 1>;\n+};\n+template <>\n+struct ArrayMap<Vec4d> {\n+  using type = Eigen::Array<double, 4, 1>;\n+};\n+template <>\n+struct ArrayMap<Vec8d> {\n+  using type = Eigen::Array<double, 8, 1>;\n+};\n+\n // Computes the absolute value of a vector using bitwise operations.\n // FloatVec: The floating-point vector type (e.g., Vec4f).\n // x: The input vector."
        }
    ],
    "stats": {
        "total": 295,
        "additions": 163,
        "deletions": 132
    }
}