{
    "author": "beckerhe",
    "message": "Fix GPU AOT Compilation test\n\nPiperOrigin-RevId: 808522209",
    "sha": "a617e7b3dcd9d6ebccb6ed3b09d99debf4be8148",
    "files": [
        {
            "sha": "198ef5d3cae6ec50e5c4c97c3fab383115766718",
            "filename": "third_party/xla/xla/service/gpu/nvptx_compiler.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a617e7b3dcd9d6ebccb6ed3b09d99debf4be8148/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a617e7b3dcd9d6ebccb6ed3b09d99debf4be8148/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.cc?ref=a617e7b3dcd9d6ebccb6ed3b09d99debf4be8148",
            "patch": "@@ -361,15 +361,18 @@ absl::Status NVPTXCompiler::AddConvAndGemmAutotuningPasses(\n           .debug_options()\n           .xla_gpu_experimental_disable_binary_libraries() ||\n       debug_options.xla_gpu_autotune_level() == 0 ||\n-      debug_options.xla_gpu_exclude_nondeterministic_ops() ||\n-      stream_exec == nullptr) {\n+      debug_options.xla_gpu_exclude_nondeterministic_ops()) {\n     return absl::OkStatus();\n   }\n \n   // TODO(b/407495801): Cached Gemm as well as Conv autotuning results are\n   // loaded in the GpuConvAlgorithmPicker but should be loaded in the autotuner.\n   pipeline->AddPass<GpuConvAlgorithmPicker>(autotune_config);\n \n+  if (stream_exec == nullptr) {\n+    return absl::OkStatus();\n+  }\n+\n   std::vector<std::unique_ptr<CodegenBackend>> backends;\n   backends.push_back(\n       std::make_unique<CublasBackend>(stream_exec, &debug_options, this));"
        },
        {
            "sha": "b41bed1ae6f96a29f968bb5e30052940554f36e0",
            "filename": "third_party/xla/xla/service/xla_aot_compile_test_autotune_results.txtpb",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a617e7b3dcd9d6ebccb6ed3b09d99debf4be8148/third_party%2Fxla%2Fxla%2Fservice%2Fxla_aot_compile_test_autotune_results.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a617e7b3dcd9d6ebccb6ed3b09d99debf4be8148/third_party%2Fxla%2Fxla%2Fservice%2Fxla_aot_compile_test_autotune_results.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fxla_aot_compile_test_autotune_results.txtpb?ref=a617e7b3dcd9d6ebccb6ed3b09d99debf4be8148",
            "patch": "@@ -17,7 +17,7 @@\n \n version: 3\n results {\n-  device: \"CUDA: 6.0, Cores: 56, GPU clock: 1.4805 GHz, Memory bandwidth: 732 GB/s, L2 cache: 4 MB\"\n+  device: \"CUDA: 6.0, Cores: 56, GPU clock: 1.4805 GHz, Memory bandwidth: 732 GB/s, L2 cache: 4 MB, DNN version: 0.0.0\"\n   hlo: \"(f32[3,3]{1,0}, s8[72]{0}) custom-call(f32[3,3]{1,0}, f32[3,3]{1,0}), custom_call_target=\\\"__cublas$gemm\\\", backend_config={\\\"force_earliest_schedule\\\":false,\\\"gemm_backend_config\\\":{\\\"alpha_imag\\\":0,\\\"alpha_real\\\":1,\\\"beta\\\":0,\\\"dot_dimension_numbers\\\":{\\\"lhs_batch_dimensions\\\":[],\\\"lhs_contracting_dimensions\\\":[\\\"1\\\"],\\\"rhs_batch_dimensions\\\":[],\\\"rhs_contracting_dimensions\\\":[\\\"0\\\"]},\\\"epilogue\\\":\\\"DEFAULT\\\",\\\"grad_x\\\":false,\\\"grad_y\\\":false,\\\"lhs_stride\\\":\\\"9\\\",\\\"precision_config\\\":{\\\"algorithm\\\":\\\"ALG_UNSET\\\",\\\"operand_precision\\\":[\\\"DEFAULT\\\",\\\"DEFAULT\\\"]},\\\"rhs_stride\\\":\\\"9\\\"},\\\"operation_queue_id\\\":\\\"0\\\",\\\"wait_on_operation_queues\\\":[]}\"\n   result {\n     gemm {\n@@ -26,7 +26,7 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 6.0, Cores: 56, GPU clock: 1.4805 GHz, Memory bandwidth: 732 GB/s, L2 cache: 4 MB\"\n+  device: \"CUDA: 6.0, Cores: 56, GPU clock: 1.4805 GHz, Memory bandwidth: 732 GB/s, L2 cache: 4 MB, DNN version: 0.0.0\"\n   hlo: \"(f32[1,1,2,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,2,4,4]{3,2,1,0}, f32[1,2,3,2]{3,2,1,0}), window={size=3x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\\\"__cudnn$convForward\\\", backend_config={\\\"cudnn_conv_backend_config\\\":{\\\"activation_mode\\\":\\\"kNone\\\",\\\"conv_result_scale\\\":1,\\\"leakyrelu_alpha\\\":0,\\\"side_input_scale\\\":0},\\\"device_type\\\":\\\"DEVICE_TYPE_INVALID\\\",\\\"force_earliest_schedule\\\":false,\\\"operation_queue_id\\\":\\\"0\\\",\\\"reification_cost\\\":[],\\\"wait_on_operation_queues\\\":[]}\"\n   result {\n     run_time {"
        }
    ],
    "stats": {
        "total": 11,
        "additions": 7,
        "deletions": 4
    }
}