{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Add abstract class for multicast memory to GpuExecutor.\n\nPiperOrigin-RevId: 820115707",
    "sha": "c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2",
    "files": [
        {
            "sha": "ab1d519981dae2c322e4d7e40b070553c3a4793f",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2",
            "patch": "@@ -1259,6 +1259,7 @@ xla_test(\n         \"//xla/stream_executor:platform_manager\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/gpu:gpu_init\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_googletest//:gtest_main\","
        },
        {
            "sha": "a43dc5521a23a32b7a08e1102040ddffd55dac84",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.cc",
            "status": "modified",
            "additions": 42,
            "deletions": 12,
            "changes": 54,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc?ref=c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2",
            "patch": "@@ -74,6 +74,7 @@ limitations under the License.\n #include \"xla/stream_executor/generic_memory_allocation.h\"\n #include \"xla/stream_executor/generic_memory_allocator.h\"\n #include \"xla/stream_executor/gpu/context.h\"\n+#include \"xla/stream_executor/gpu/gpu_executor.h\"\n #include \"xla/stream_executor/gpu/read_numa_node.h\"\n #include \"xla/stream_executor/gpu/scoped_activate_context.h\"\n #include \"xla/stream_executor/gpu/tma_metadata.h\"\n@@ -1747,7 +1748,25 @@ absl::StatusOr<TensorMap> CudaExecutor::CreateTensorMap(\n   return absl::bit_cast<TensorMap>(tensor_map);\n }\n \n-CudaExecutor::MulticastMemory::~MulticastMemory() {\n+absl::StatusOr<std::unique_ptr<GpuExecutor::MulticastMemory>>\n+CudaExecutor::CreateMulticastMemory(uint64_t size, int num_devices) {\n+  if (!is_multicast_supported_) {\n+    return absl::FailedPreconditionError(\n+        \"Multicast memory is not supported on this platform.\");\n+  }\n+  if (size == 0 || num_devices <= 1) {\n+    return absl::InvalidArgumentError(\n+        absl::StrCat(\"Multicast memory size must be > 0 and number of devices \"\n+                     \"must be greater than 1, but got size: \",\n+                     size, \" and num_devices: \", num_devices, \".\"));\n+  }\n+\n+  auto multicast_memory = std::make_unique<CudaMulticastMemory>();\n+  TF_RETURN_IF_ERROR(multicast_memory->Initialize(size, num_devices, this));\n+  return multicast_memory;\n+}\n+\n+CudaExecutor::CudaMulticastMemory::~CudaMulticastMemory() {\n   if (handle_ != 0) {\n     for (auto const& [device_ordinal, mapped_memory_ptr] : mapped_devices_) {\n       VLOG(3) << \"[\" << device_ordinal << \"] Unbind multicast: \" << handle_;\n@@ -1767,8 +1786,13 @@ CudaExecutor::MulticastMemory::~MulticastMemory() {\n   }\n }\n \n-absl::Status CudaExecutor::MulticastMemory::Initialize(\n-    uint64_t size, int num_devices, CudaExecutor& cuda_executor) {\n+absl::Status CudaExecutor::CudaMulticastMemory::Initialize(\n+    uint64_t size, int num_devices, GpuExecutor* gpu_executor) {\n+  CudaExecutor* cuda_executor = dynamic_cast<CudaExecutor*>(gpu_executor);\n+  if (cuda_executor == nullptr) {\n+    return absl::InvalidArgumentError(\"GpuExecutor is not a CudaExecutor.\");\n+  }\n+\n   if (handle_ != 0) {\n     return absl::FailedPreconditionError(\n         \"Multicast memory is already initialized.\");\n@@ -1781,7 +1805,7 @@ absl::Status CudaExecutor::MulticastMemory::Initialize(\n   }\n \n   CUmemAllocationProp properties = GetVmmAllocationProperties(\n-      cuda_executor.device_, cuda_executor.is_rdma_supported_);\n+      cuda_executor->device_, cuda_executor->is_rdma_supported_);\n   TF_RETURN_IF_ERROR(\n       stream_executor::cuda::ToStatus(cuMemGetAllocationGranularity(\n           &granularity_, &properties, CU_MEM_ALLOC_GRANULARITY_RECOMMENDED)));\n@@ -1791,15 +1815,16 @@ absl::Status CudaExecutor::MulticastMemory::Initialize(\n   TF_ASSIGN_OR_RETURN(CUmulticastObjectProp multicast_properties,\n                       CreateMulticastObjectProperties(num_devices_, size));\n \n-  VLOG(3) << \"[\" << static_cast<int>(cuda_executor.device_)\n+  VLOG(3) << \"[\" << static_cast<int>(cuda_executor->device_)\n           << \"] Create multicast memory: \" << static_cast<uint64_t>(handle_)\n           << \" size: \" << padded_size_ << \" with granularity: \" << granularity_\n           << \" for \" << num_devices_ << \" devices.\";\n   return stream_executor::cuda::ToStatus(\n       cuMulticastCreate(&handle_, &multicast_properties));\n }\n \n-absl::Status CudaExecutor::MulticastMemory::SubscribeDevice(int device_number) {\n+absl::Status CudaExecutor::CudaMulticastMemory::SubscribeDevice(\n+    int device_number) {\n   if (handle_ == 0) {\n     return absl::FailedPreconditionError(\n         \"Multicast memory is not initialized.\");\n@@ -1816,8 +1841,13 @@ absl::Status CudaExecutor::MulticastMemory::SubscribeDevice(int device_number) {\n   return absl::OkStatus();\n }\n \n-absl::StatusOr<void*> CudaExecutor::MulticastMemory::MapMemory(\n-    void* device_ptr, CudaExecutor& cuda_executor) {\n+absl::StatusOr<void*> CudaExecutor::CudaMulticastMemory::MapMemory(\n+    void* device_ptr, GpuExecutor* gpu_executor) {\n+  CudaExecutor* cuda_executor = dynamic_cast<CudaExecutor*>(gpu_executor);\n+  if (cuda_executor == nullptr) {\n+    return absl::InvalidArgumentError(\"GpuExecutor is not a CudaExecutor.\");\n+  }\n+\n   if (device_ptr == nullptr) {\n     return absl::InvalidArgumentError(\"Device pointer is null.\");\n   }\n@@ -1833,7 +1863,7 @@ absl::StatusOr<void*> CudaExecutor::MulticastMemory::MapMemory(\n \n   TF_ASSIGN_OR_RETURN(\n       stream_executor::gpu::CudaExecutor::VmmMemoryHandle memory_handle,\n-      cuda_executor.RetainVmmMemoryHandle(device_ptr));\n+      cuda_executor->RetainVmmMemoryHandle(device_ptr));\n \n   CUmemGenericAllocationHandle retained_memory_handle =\n       static_cast<CUmemGenericAllocationHandle>(memory_handle.handle());\n@@ -1843,7 +1873,7 @@ absl::StatusOr<void*> CudaExecutor::MulticastMemory::MapMemory(\n       cuMulticastBindMem(handle_, /*mcOffset=*/0, retained_memory_handle,\n                          /*memOffset=*/0, padded_size_, /*flags=*/0)));\n \n-  VLOG(3) << \"[\" << static_cast<int>(cuda_executor.device_)\n+  VLOG(3) << \"[\" << static_cast<int>(cuda_executor->device_)\n           << \"] Mapped multicast memory: \" << static_cast<uint64_t>(handle_)\n           << \" size: \" << padded_size_ << \" with granularity: \" << granularity_\n           << \" to address: \" << device_ptr;\n@@ -1857,12 +1887,12 @@ absl::StatusOr<void*> CudaExecutor::MulticastMemory::MapMemory(\n   TF_RETURN_IF_ERROR(stream_executor::cuda::ToStatus(\n       cuMemMap(multicast_device_ptr, padded_size_, 0, handle_, 0)));\n \n-  CUmemAccessDesc accessDesc = GetVmmAccessDescriptor(cuda_executor.device_);\n+  CUmemAccessDesc accessDesc = GetVmmAccessDescriptor(cuda_executor->device_);\n   TF_RETURN_IF_ERROR(stream_executor::cuda::ToStatus(\n       cuMemSetAccess(multicast_device_ptr, padded_size_, &accessDesc, 1)));\n \n   absl::MutexLock subscription_lock(mapped_devices_mu_);\n-  mapped_devices_.emplace(cuda_executor.device_, multicast_device_ptr);\n+  mapped_devices_.emplace(cuda_executor->device_, multicast_device_ptr);\n   return reinterpret_cast<void*>(multicast_device_ptr);\n }\n "
        },
        {
            "sha": "aae517cdc4f38cb1f959ff3e5897ea9b9a01c53f",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.h",
            "status": "modified",
            "additions": 12,
            "deletions": 9,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h?ref=c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2",
            "patch": "@@ -155,25 +155,25 @@ class CudaExecutor : public GpuExecutor {\n     uint64_t handle_;\n   };\n \n-  class MulticastMemory {\n+  class CudaMulticastMemory : public MulticastMemory {\n    public:\n-    MulticastMemory()\n+    CudaMulticastMemory()\n         : handle_(0),\n           padded_size_(0),\n           granularity_(0),\n           num_devices_(0),\n-          subscribed_devices_(0) {};\n-    ~MulticastMemory();\n+          subscribed_devices_(0) {}\n+    ~CudaMulticastMemory() override;\n \n-    absl::Status Initialize(uint64_t size, int num_devices,\n-                            CudaExecutor& cuda_executor);\n-\n-    absl::Status SubscribeDevice(int device_number);\n+    absl::Status SubscribeDevice(int device_number) override;\n \n     absl::StatusOr<void*> MapMemory(void* device_ptr,\n-                                    CudaExecutor& cuda_executor);\n+                                    GpuExecutor* gpu_executor) override;\n \n    private:\n+    friend class CudaExecutor;\n+    absl::Status Initialize(uint64_t size, int num_devices,\n+                            GpuExecutor* gpu_executor);\n     CUmemGenericAllocationHandle handle_;\n     uint64_t padded_size_;\n     uint64_t granularity_;\n@@ -184,6 +184,9 @@ class CudaExecutor : public GpuExecutor {\n     absl::Mutex mapped_devices_mu_;\n   };\n \n+  absl::StatusOr<std::unique_ptr<MulticastMemory>> CreateMulticastMemory(\n+      uint64_t size, int num_devices) override;\n+\n   // Returns a handle to the given memory if it was allocated with VMM API.\n   absl::StatusOr<VmmMemoryHandle> RetainVmmMemoryHandle(void* ptr);\n "
        },
        {
            "sha": "f49816ff3dd435c6d12b81dc215ad399dd205106",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor_multigpu_test.cc",
            "status": "modified",
            "additions": 35,
            "deletions": 79,
            "changes": 114,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor_multigpu_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor_multigpu_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor_multigpu_test.cc?ref=c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2",
            "patch": "@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include <cstdint>\n+#include <memory>\n #include <vector>\n \n #include <gmock/gmock.h>\n@@ -26,6 +27,7 @@ limitations under the License.\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n \n namespace stream_executor::gpu {\n namespace {\n@@ -41,65 +43,18 @@ StreamExecutor* GetGpuExecutor(int64_t device_ordinal) {\n   return platform->ExecutorForDevice(device_ordinal).value();\n }\n \n-TEST(CudaExecutorMultiGpuTest, MultimemCanBeInitializedOnce) {\n+TEST(CudaExecutorMultiGpuTest, CudaMulticastMemoryResubscriptionFails) {\n   std::vector<CudaExecutor*> executors = {\n       static_cast<CudaExecutor*>(GetGpuExecutor(0)),\n       static_cast<CudaExecutor*>(GetGpuExecutor(1))};\n   if (!executors[0]->is_multicast_supported()) {\n     GTEST_SKIP() << \"Test requires multicast support.\";\n   }\n-\n-  CudaExecutor::MulticastMemory multicast_memory;\n-  EXPECT_THAT(multicast_memory.Initialize(1024, 2, *executors[0]), IsOk());\n-  EXPECT_THAT(multicast_memory.Initialize(1024, 2, *executors[0]),\n-              StatusIs(absl::StatusCode::kFailedPrecondition,\n-                       \"Multicast memory is already initialized.\"));\n-}\n-\n-TEST(CudaExecutorMultiGpuTest, UnitializedMulticastCanNotBeSubscribed) {\n-  std::vector<CudaExecutor*> executors = {\n-      static_cast<CudaExecutor*>(GetGpuExecutor(0)),\n-      static_cast<CudaExecutor*>(GetGpuExecutor(1))};\n-  if (!executors[0]->is_multicast_supported()) {\n-    GTEST_SKIP() << \"Test requires multicast support.\";\n-  }\n-  CudaExecutor::MulticastMemory multicast_memory;\n-  EXPECT_THAT(\n-      multicast_memory.SubscribeDevice(0),\n-      absl::FailedPreconditionError(\"Multicast memory is not initialized.\"));\n-  EXPECT_THAT(multicast_memory.MapMemory(nullptr, *executors[0]),\n-              absl::InvalidArgumentError(\"Device pointer is null.\"));\n-  EXPECT_THAT(\n-      multicast_memory.MapMemory(reinterpret_cast<void*>(1), *executors[0]),\n-      StatusIs(absl::StatusCode::kFailedPrecondition,\n-               \"Multicast memory is not initialized.\"));\n-}\n-\n-TEST(CudaExecutorMultiGpuTest,\n-     MulticastMemoryCanNotBeInitializedWithOneDevice) {\n-  std::vector<CudaExecutor*> executors = {\n-      static_cast<CudaExecutor*>(GetGpuExecutor(0)),\n-      static_cast<CudaExecutor*>(GetGpuExecutor(1))};\n-  if (!executors[0]->is_multicast_supported()) {\n-    GTEST_SKIP() << \"Test requires multicast support.\";\n-  }\n-  CudaExecutor::MulticastMemory multicast_memory;\n-  EXPECT_THAT(multicast_memory.Initialize(1024, 1, *executors[0]),\n-              StatusIs(absl::StatusCode::kInvalidArgument,\n-                       \"Number of devices must be greater than 1, but got 1.\"));\n-}\n-\n-TEST(CudaExecutorMultiGpuTest, MulticastMemoryResubscriptionFails) {\n-  std::vector<CudaExecutor*> executors = {\n-      static_cast<CudaExecutor*>(GetGpuExecutor(0)),\n-      static_cast<CudaExecutor*>(GetGpuExecutor(1))};\n-  if (!executors[0]->is_multicast_supported()) {\n-    GTEST_SKIP() << \"Test requires multicast support.\";\n-  }\n-  CudaExecutor::MulticastMemory multicast_memory;\n-  EXPECT_THAT(multicast_memory.Initialize(1024, 2, *executors[0]), IsOk());\n-  EXPECT_THAT(multicast_memory.SubscribeDevice(0), IsOk());\n-  EXPECT_THAT(multicast_memory.SubscribeDevice(0),\n+  std::unique_ptr<CudaExecutor::MulticastMemory> multicast_memory;\n+  TF_ASSERT_OK_AND_ASSIGN(multicast_memory,\n+                          executors[0]->CreateMulticastMemory(1024, 2));\n+  EXPECT_THAT(multicast_memory->SubscribeDevice(0), IsOk());\n+  EXPECT_THAT(multicast_memory->SubscribeDevice(0),\n               StatusIs(absl::StatusCode::kInternal,\n                        \"CUDA error: : CUDA_ERROR_UNKNOWN: unknown error\"));\n }\n@@ -111,55 +66,57 @@ TEST(CudaExecutorMultiGpuTest, AllDevicesMustBeSubscribedBeforeMapping) {\n   if (!executors[0]->is_multicast_supported()) {\n     GTEST_SKIP() << \"Test requires multicast support.\";\n   }\n-  CudaExecutor::MulticastMemory multicast_memory;\n-  EXPECT_THAT(multicast_memory.Initialize(1024, 2, *executors[0]), IsOk());\n-  EXPECT_THAT(multicast_memory.SubscribeDevice(0), IsOk());\n+  std::unique_ptr<CudaExecutor::MulticastMemory> multicast_memory;\n+  TF_ASSERT_OK_AND_ASSIGN(multicast_memory,\n+                          executors[0]->CreateMulticastMemory(1024, 2));\n+  EXPECT_THAT(multicast_memory->SubscribeDevice(0), IsOk());\n   EXPECT_THAT(\n-      multicast_memory.MapMemory(reinterpret_cast<void*>(1), *executors[0]),\n+      multicast_memory->MapMemory(reinterpret_cast<void*>(1), executors[0]),\n       StatusIs(absl::StatusCode::kFailedPrecondition,\n                \"All devices should be subscribed.\"));\n   ;\n }\n \n-TEST(CudaExecutorMultiGpuTest, MulticastMemorySubscribeMoreDevices) {\n+TEST(CudaExecutorMultiGpuTest, CudaMulticastMemorySubscribeMoreDevices) {\n   std::vector<CudaExecutor*> executors = {\n       static_cast<CudaExecutor*>(GetGpuExecutor(0)),\n       static_cast<CudaExecutor*>(GetGpuExecutor(1))};\n   if (!executors[0]->is_multicast_supported()) {\n     GTEST_SKIP() << \"Test requires multicast support.\";\n   }\n-  CudaExecutor::MulticastMemory multicast_memory;\n-  EXPECT_THAT(multicast_memory.Initialize(1024, 2, *executors[0]), IsOk());\n-  EXPECT_THAT(multicast_memory.SubscribeDevice(0), IsOk());\n-  EXPECT_THAT(multicast_memory.SubscribeDevice(1), IsOk());\n-  EXPECT_THAT(multicast_memory.SubscribeDevice(2),\n+  std::unique_ptr<CudaExecutor::MulticastMemory> multicast_memory;\n+  TF_ASSERT_OK_AND_ASSIGN(multicast_memory,\n+                          executors[0]->CreateMulticastMemory(1024, 2));\n+  EXPECT_THAT(multicast_memory->SubscribeDevice(0), IsOk());\n+  EXPECT_THAT(multicast_memory->SubscribeDevice(1), IsOk());\n+  EXPECT_THAT(multicast_memory->SubscribeDevice(2),\n               StatusIs(absl::StatusCode::kInvalidArgument,\n                        \"All devices are already subscribed.\"));\n   ;\n }\n \n-TEST(CudaExecutorMultiGpuTest, MulticastMemoryUsingNonVmmMemory) {\n+TEST(CudaExecutorMultiGpuTest, CudaMulticastMemoryUsingNonVmmMemory) {\n   std::vector<CudaExecutor*> executors = {\n       static_cast<CudaExecutor*>(GetGpuExecutor(0)),\n       static_cast<CudaExecutor*>(GetGpuExecutor(1))};\n   if (!executors[0]->is_multicast_supported()) {\n     GTEST_SKIP() << \"Test requires multicast support.\";\n   }\n   const int64_t kNumDevices = 2;\n-  CudaExecutor::MulticastMemory multicast_memory;\n-  EXPECT_THAT(multicast_memory.Initialize(1024, kNumDevices, *executors[0]),\n-              IsOk());\n-  EXPECT_THAT(multicast_memory.SubscribeDevice(0), IsOk());\n-  EXPECT_THAT(multicast_memory.SubscribeDevice(1), IsOk());\n+  std::unique_ptr<CudaExecutor::MulticastMemory> multicast_memory;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      multicast_memory, executors[0]->CreateMulticastMemory(1024, kNumDevices));\n+  EXPECT_THAT(multicast_memory->SubscribeDevice(0), IsOk());\n+  EXPECT_THAT(multicast_memory->SubscribeDevice(1), IsOk());\n \n   DeviceMemoryBase device_memory = executors[0]->Allocate(1, 0);\n   EXPECT_THAT(\n-      multicast_memory.MapMemory(device_memory.opaque(), *executors[0]),\n+      multicast_memory->MapMemory(device_memory.opaque(), executors[0]),\n       StatusIs(absl::StatusCode::kInternal,\n                \"CUDA error: : CUDA_ERROR_INVALID_VALUE: invalid argument\"));\n }\n \n-TEST(CudaExecutorMultiGpuTest, MulticastMemoryUsingVmmMemory) {\n+TEST(CudaExecutorMultiGpuTest, CudaMulticastMemoryUsingVmmMemory) {\n   std::vector<CudaExecutor*> executors = {\n       static_cast<CudaExecutor*>(GetGpuExecutor(0)),\n       static_cast<CudaExecutor*>(GetGpuExecutor(1))};\n@@ -168,25 +125,24 @@ TEST(CudaExecutorMultiGpuTest, MulticastMemoryUsingVmmMemory) {\n   }\n   const int64_t kNumDevices = 2;\n   const int64_t kMemorySize = 1024;\n-  CudaExecutor::MulticastMemory multicast_memory;\n-  EXPECT_THAT(\n-      multicast_memory.Initialize(kMemorySize, kNumDevices, *executors[0]),\n-      IsOk());\n-  EXPECT_THAT(multicast_memory.SubscribeDevice(0), IsOk());\n-  EXPECT_THAT(multicast_memory.SubscribeDevice(1), IsOk());\n+  std::unique_ptr<CudaExecutor::MulticastMemory> multicast_memory;\n+  TF_ASSERT_OK_AND_ASSIGN(multicast_memory, executors[0]->CreateMulticastMemory(\n+                                                kMemorySize, kNumDevices));\n+  EXPECT_THAT(multicast_memory->SubscribeDevice(0), IsOk());\n+  EXPECT_THAT(multicast_memory->SubscribeDevice(1), IsOk());\n \n   stream_executor::DeviceMemoryBase first_device_memory =\n       executors[0]->Allocate(\n           kMemorySize, static_cast<int64_t>(stream_executor::MemoryType::kP2P));\n   EXPECT_THAT(\n-      multicast_memory.MapMemory(first_device_memory.opaque(), *executors[0]),\n+      multicast_memory->MapMemory(first_device_memory.opaque(), executors[0]),\n       IsOkAndHolds(NotNull()));\n \n   stream_executor::DeviceMemoryBase second_device_memory =\n       executors[1]->Allocate(\n           kMemorySize, static_cast<int64_t>(stream_executor::MemoryType::kP2P));\n   EXPECT_THAT(\n-      multicast_memory.MapMemory(second_device_memory.opaque(), *executors[1]),\n+      multicast_memory->MapMemory(second_device_memory.opaque(), executors[1]),\n       IsOkAndHolds(NotNull()));\n }\n "
        },
        {
            "sha": "875aefb58a47439fd2593f30056f2e3c76616fed",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_executor.h",
            "status": "modified",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_executor.h?ref=c1e8fc6dc4fe4fb38426e3b6fd8abddd2f4545d2",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n #define XLA_STREAM_EXECUTOR_GPU_GPU_EXECUTOR_H_\n \n #include <cstdint>\n+#include <memory>\n #include <utility>\n #include <variant>\n #include <vector>\n@@ -66,6 +67,29 @@ class GpuExecutor : public StreamExecutorCommon {\n \n   uint64_t GetArgumentLoggingMode() const { return argument_logging_mode_; }\n \n+  // Abstract class for multicast memory.\n+  class MulticastMemory {\n+   public:\n+    virtual ~MulticastMemory() = default;\n+\n+    MulticastMemory() = default;\n+\n+    virtual absl::Status SubscribeDevice(int device_number) {\n+      return absl::UnimplementedError(\"SubscribeDevice is not implemented.\");\n+    }\n+\n+    virtual absl::StatusOr<void*> MapMemory(void* device_ptr,\n+                                            GpuExecutor* gpu_executor) {\n+      return absl::UnimplementedError(\"MapMemory is not implemented.\");\n+    }\n+  };\n+\n+  virtual absl::StatusOr<std::unique_ptr<MulticastMemory>>\n+  CreateMulticastMemory(uint64_t size, int num_devices) {\n+    return absl::UnimplementedError(\n+        \"CreateMulticastMemory is not implemented.\");\n+  };\n+\n  private:\n   // The device ordinal value that this executor was initialized with; recorded\n   // for use in getting device metadata. Immutable post-initialization."
        }
    ],
    "stats": {
        "total": 214,
        "additions": 114,
        "deletions": 100
    }
}