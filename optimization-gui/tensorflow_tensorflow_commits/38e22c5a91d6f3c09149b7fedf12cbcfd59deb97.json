{
    "author": "yangustc07",
    "message": "#tf-data-service Clean up verbose code.\n\nPiperOrigin-RevId: 813339176",
    "sha": "38e22c5a91d6f3c09149b7fedf12cbcfd59deb97",
    "files": [
        {
            "sha": "746d7a9ec69c861bdeb34abac0d62944bdfa7873",
            "filename": "tensorflow/python/data/experimental/kernel_tests/service/coordinated_read_test.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/38e22c5a91d6f3c09149b7fedf12cbcfd59deb97/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fcoordinated_read_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/38e22c5a91d6f3c09149b7fedf12cbcfd59deb97/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fcoordinated_read_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fcoordinated_read_test.py?ref=38e22c5a91d6f3c09149b7fedf12cbcfd59deb97",
            "patch": "@@ -42,8 +42,7 @@ def testBasic(self, num_workers, num_consumers):\n     self.checkCoordinatedReadGroups(results, num_consumers)\n     cluster.stop_workers()\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testConsumerRestart(self):\n     cluster = data_service_test_base.TestCluster(num_workers=1)\n     num_consumers = 3"
        },
        {
            "sha": "18b4d77b66463c286bd0a28031a3b588bff40a86",
            "filename": "tensorflow/python/data/experimental/kernel_tests/service/cross_trainer_cache_ft_test.py",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/38e22c5a91d6f3c09149b7fedf12cbcfd59deb97/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fcross_trainer_cache_ft_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/38e22c5a91d6f3c09149b7fedf12cbcfd59deb97/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fcross_trainer_cache_ft_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fcross_trainer_cache_ft_test.py?ref=38e22c5a91d6f3c09149b7fedf12cbcfd59deb97",
            "patch": "@@ -28,8 +28,7 @@ class CrossTrainerCacheFtTest(data_service_test_base.TestBase,\n                               parameterized.TestCase):\n   \"\"\"Fault tolerance tests for tf.data service cross-trainer cache.\"\"\"\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testWorkerRestart(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()\n@@ -53,8 +52,7 @@ def testWorkerRestart(self):\n     elements = self._get_next(get_next, 100)\n     self.assertEqual(elements, list(range(1, 101)))\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testDispatcherRestart(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()"
        },
        {
            "sha": "243862993d6b5194d0ac8954992834ffd7bb957b",
            "filename": "tensorflow/python/data/experimental/kernel_tests/service/cross_trainer_cache_test.py",
            "status": "modified",
            "additions": 18,
            "deletions": 36,
            "changes": 54,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/38e22c5a91d6f3c09149b7fedf12cbcfd59deb97/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fcross_trainer_cache_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/38e22c5a91d6f3c09149b7fedf12cbcfd59deb97/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fcross_trainer_cache_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fcross_trainer_cache_test.py?ref=38e22c5a91d6f3c09149b7fedf12cbcfd59deb97",
            "patch": "@@ -30,8 +30,7 @@ class CrossTrainerCacheTest(data_service_test_base.TestBase,\n                             parameterized.TestCase):\n   \"\"\"Tests for sharing datasets across jobs using a cross-trainer cache.\"\"\"\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testEnableCrossTrainerCache(self):\n     \"\"\"Tests cross-trainer cache with `distribute`.\"\"\"\n     cluster = self._create_cluster(num_workers=1)\n@@ -53,8 +52,7 @@ def testEnableCrossTrainerCache(self):\n             trainer_id=\"Trainer 2\"))\n     self.assertDatasetProduces(dataset2.take(10), list(range(10)))\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testFromDatasetId(self):\n     \"\"\"Tests cross-trainer cache with `register_dataset`/`from_dataset_id`.\"\"\"\n     cluster = self._create_cluster(num_workers=1)\n@@ -83,8 +81,7 @@ def testFromDatasetId(self):\n             trainer_id=\"Trainer 2\"))\n     self.assertDatasetProduces(dataset2.take(10), list(range(10)))\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testDisableCrossTrainerCacheByDefault(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()\n@@ -97,8 +94,7 @@ def testDisableCrossTrainerCacheByDefault(self):\n     output = self.getDatasetOutput(dataset2.take(10))\n     self.assertGreaterEqual(output[0], 10)\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testConcurrentReaders(self):\n     # Fetching an element from the dataset will trigger prefetches of more\n     # elements, one per CPU core which will be placed in the cache.\n@@ -135,8 +131,7 @@ def testConcurrentReaders(self):\n       for j in range(num_readers):\n         self.assertEqual(self.evaluate(iterators[j]()), i)\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testSlowClientSkipsData(self):\n     cluster = self._create_cluster(\n         num_workers=1, cross_trainer_cache_size_bytes=500)\n@@ -163,8 +158,7 @@ def testSlowClientSkipsData(self):\n     self.assertGreater(output[0], 0)\n     self.assertLen(output, 200)\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testSmallCache(self):\n     cluster = self._create_cluster(\n         num_workers=1, cross_trainer_cache_size_bytes=500)\n@@ -184,8 +178,7 @@ def testSmallCache(self):\n       output = self.getDatasetOutput(distributed_dataset.take(200))\n       self.assertLen(output, 200)\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testShuffleDataset(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat().shuffle(\n@@ -207,8 +200,7 @@ def testShuffleDataset(self):\n     output2 = self.getDatasetOutput(dataset2.take(10))\n     self.assertEqual(output1, output2)\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testSameTrainerID(self):\n     # Jobs from the same training cluster do not reuse data from the cache.\n     cluster = self._create_cluster(num_workers=1)\n@@ -230,8 +222,7 @@ def testSameTrainerID(self):\n     output = self.getDatasetOutput(dataset2.take(10))\n     self.assertGreaterEqual(output[0], 10)\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testDifferentJobNames(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()\n@@ -251,8 +242,7 @@ def testDifferentJobNames(self):\n             trainer_id=\"Trainer 2\"))\n     self.assertDatasetProduces(dataset2.take(10), list(range(10)))\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testDynamicSharding(self):\n     cluster = self._create_cluster(num_workers=2)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()\n@@ -277,8 +267,7 @@ def testDynamicSharding(self):\n     # Verifies the intersection is non-empty.\n     self.assertTrue(set(output1) & set(output2))\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testNoCompression(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()\n@@ -300,8 +289,7 @@ def testNoCompression(self):\n             trainer_id=\"Trainer 2\"))\n     self.assertDatasetProduces(dataset2.take(10), list(range(10)))\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testCompressionMismatch(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()\n@@ -324,8 +312,7 @@ def testCompressionMismatch(self):\n               trainer_id=\"Trainer 1\"))\n       self.getDatasetOutput(dataset2)\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testRequiresJobName(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()\n@@ -358,8 +345,7 @@ def testRequiresInfiniteDataset(self, range_):\n                   trainer_id=\"Trainer ID\")))\n       self.getDatasetOutput(dataset)\n \n-  @combinations.generate(\n-      combinations.times(test_base.eager_only_combinations()))\n+  @combinations.generate(test_base.eager_only_combinations())\n   def testMultipleIterationsForOneDatasetEagerMode(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()\n@@ -379,8 +365,7 @@ def testMultipleIterationsForOneDatasetEagerMode(self):\n       self.getDatasetOutput(dataset1.take(10))\n       self.getDatasetOutput(dataset1.take(10))\n \n-  @combinations.generate(\n-      combinations.times(test_base.graph_only_combinations()))\n+  @combinations.generate(test_base.graph_only_combinations())\n   def testMultipleIterationsForOneDatasetGraphMode(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()\n@@ -410,8 +395,7 @@ def testMultipleIterationsForOneDatasetGraphMode(self):\n     output2 += self.getDatasetOutput(dataset2.take(10))\n     self.assertTrue(set(output1) & set(output2))\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testDisallowCoordinatedRead(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()\n@@ -428,8 +412,7 @@ def testDisallowCoordinatedRead(self):\n               trainer_id=\"Trainer 1\"))\n       self.getDatasetOutput(dataset)\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testNamedJobMismatch(self):\n     cluster = self._create_cluster(num_workers=1)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()\n@@ -448,8 +431,7 @@ def testNamedJobMismatch(self):\n           dataset, cluster, job_name=\"job\", cross_trainer_cache=None)\n       self.getDatasetOutput(dataset2)\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations()))\n+  @combinations.generate(test_base.default_test_combinations())\n   def testRequiresNonEmptyTrainerID(self):\n     cluster = self._create_cluster(num_workers=2)\n     dataset = dataset_ops.Dataset.range(10000000).repeat()"
        },
        {
            "sha": "cdf129f3b29ac0ce2a7e84c8551b7360561efc13",
            "filename": "tensorflow/python/data/experimental/kernel_tests/service/data_service_ops_test.py",
            "status": "modified",
            "additions": 3,
            "deletions": 9,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/38e22c5a91d6f3c09149b7fedf12cbcfd59deb97/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdata_service_ops_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/38e22c5a91d6f3c09149b7fedf12cbcfd59deb97/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdata_service_ops_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdata_service_ops_test.py?ref=38e22c5a91d6f3c09149b7fedf12cbcfd59deb97",
            "patch": "@@ -1200,9 +1200,7 @@ def key_func(x):\n         self.assertAllEqual(self.evaluate(get_next()), element)\n     self.assertEmpty(self.getIteratorOutput(get_next))\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations())\n-  )\n+  @combinations.generate(test_base.default_test_combinations())\n   def testDistributeLargeGraph(self):\n     cluster = self.make_test_cluster(\n         num_workers=1, work_dir=NO_WORK_DIR, fault_tolerant_mode=False\n@@ -1213,9 +1211,7 @@ def testDistributeLargeGraph(self):\n     ds = self.make_distributed_dataset(ds, cluster)\n     self.assertDatasetProduces(ds, [tensor])\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations())\n-  )\n+  @combinations.generate(test_base.default_test_combinations())\n   def testBatchDropsAllElements(self):\n     cluster = self.make_test_cluster(\n         num_workers=2, fault_tolerant_mode=False\n@@ -1226,9 +1222,7 @@ def testBatchDropsAllElements(self):\n     )\n     self.assertDatasetProduces(dataset, [])\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations())\n-  )\n+  @combinations.generate(test_base.default_test_combinations())\n   def testBatchDoesNotDropRemainder(self):\n     num_workers = 2\n     cluster = self.make_test_cluster("
        },
        {
            "sha": "a78002b335be77a9676549c439300001ac997652",
            "filename": "tensorflow/python/data/experimental/kernel_tests/service/multi_process_cluster_test.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/38e22c5a91d6f3c09149b7fedf12cbcfd59deb97/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fmulti_process_cluster_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/38e22c5a91d6f3c09149b7fedf12cbcfd59deb97/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fmulti_process_cluster_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fmulti_process_cluster_test.py?ref=38e22c5a91d6f3c09149b7fedf12cbcfd59deb97",
            "patch": "@@ -52,9 +52,7 @@ def testCluster(self, num_local_workers, num_remote_workers):\n         num_workers * list(range(num_elements)),\n         assert_items_equal=True)\n \n-  @combinations.generate(\n-      combinations.times(test_base.default_test_combinations())\n-  )\n+  @combinations.generate(test_base.default_test_combinations())\n   def testDistributeNonblockingWithStuckWorkers(self):\n     num_workers = 6\n     # Avoids using local workers because it will stall the teardown"
        }
    ],
    "stats": {
        "total": 79,
        "additions": 25,
        "deletions": 54
    }
}