{
    "author": "yangustc07",
    "message": "#tf-data-service Make `dataset_ops.apply_rewrite` available.\n\nPiperOrigin-RevId: 816312801",
    "sha": "63a76d0b8f6ea7be9caa1b5d08bff7ef6eeb5a77",
    "files": [
        {
            "sha": "caabf03dd837903a3aa3bebaef0119654ffb0126",
            "filename": "tensorflow/python/data/experimental/kernel_tests/service/dynamic_sharding_test.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63a76d0b8f6ea7be9caa1b5d08bff7ef6eeb5a77/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdynamic_sharding_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63a76d0b8f6ea7be9caa1b5d08bff7ef6eeb5a77/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdynamic_sharding_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdynamic_sharding_test.py?ref=63a76d0b8f6ea7be9caa1b5d08bff7ef6eeb5a77",
            "patch": "@@ -350,7 +350,7 @@ def testZipReplicateOnSplit(self):\n \n     ds1 = dataset_ops.Dataset.range(100, 1000, output_type=dtypes.int32)\n     ds2 = dataset_ops.Dataset.from_tensor_slices(range(0, 5))\n-    ds2 = dataset_ops._apply_rewrite(ds2, \"replicate_on_split\")\n+    ds2 = dataset_ops.apply_rewrite(ds2, \"replicate_on_split\")\n \n     ds = dataset_ops.Dataset.zip(ds1, ds2)\n     ds = ds.apply("
        },
        {
            "sha": "c5d45760460fd2ead84e4250f3fd2840f66ef5e9",
            "filename": "tensorflow/python/data/ops/choose_from_datasets_op.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63a76d0b8f6ea7be9caa1b5d08bff7ef6eeb5a77/tensorflow%2Fpython%2Fdata%2Fops%2Fchoose_from_datasets_op.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63a76d0b8f6ea7be9caa1b5d08bff7ef6eeb5a77/tensorflow%2Fpython%2Fdata%2Fops%2Fchoose_from_datasets_op.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fops%2Fchoose_from_datasets_op.py?ref=63a76d0b8f6ea7be9caa1b5d08bff7ef6eeb5a77",
            "patch": "@@ -45,8 +45,7 @@ def _choose_from_datasets(  # pylint: disable=unused-private-name\n   # Replicates the `choice_dataset` component so that each split makes choices\n   # independently. This avoids the need for prohibitively expensive\n   # cross-split coordination.\n-  # pylint: disable=protected-access\n-  choice_dataset = dataset_ops._apply_rewrite(\n+  choice_dataset = dataset_ops.apply_rewrite(\n       choice_dataset, \"replicate_on_split\"\n   )\n   return directed_interleave_op._directed_interleave(  # pylint: disable=protected-access"
        },
        {
            "sha": "06ed4275dcbb2e8907ee1e30b465ec8896f6adb6",
            "filename": "tensorflow/python/data/ops/dataset_ops.py",
            "status": "modified",
            "additions": 14,
            "deletions": 2,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63a76d0b8f6ea7be9caa1b5d08bff7ef6eeb5a77/tensorflow%2Fpython%2Fdata%2Fops%2Fdataset_ops.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63a76d0b8f6ea7be9caa1b5d08bff7ef6eeb5a77/tensorflow%2Fpython%2Fdata%2Fops%2Fdataset_ops.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fops%2Fdataset_ops.py?ref=63a76d0b8f6ea7be9caa1b5d08bff7ef6eeb5a77",
            "patch": "@@ -1413,7 +1413,7 @@ def enumerate(self, start=0, name=None) -> \"DatasetV2\":\n     # Replicate the range component so that each split is enumerated\n     # independently. This avoids the need for prohibitively expensive\n     # cross-split coordination.\n-    range_dataset = _apply_rewrite(range_dataset, \"replicate_on_split\")\n+    range_dataset = apply_rewrite(range_dataset, \"replicate_on_split\")\n     return Dataset.zip((range_dataset, self), name=name)\n \n   def shuffle(\n@@ -5181,7 +5181,19 @@ def _calculate_acceptance_probs_with_mixing(initial_probs, target_probs):\n   return a_i, m\n \n \n-def _apply_rewrite(dataset, rewrite):\n+def apply_rewrite(dataset, rewrite):\n+  \"\"\"Applies a rewrite to a dataset.\n+\n+  Args:\n+    dataset: A dataset object.\n+    rewrite: Name of the rewrite. Currently supports \"replicate_on_split\" that\n+      distributes small datasets across workers when using the tf.data service\n+      dynamic sharding mode and combining multiple datasets (for instance,\n+      with `zip`, `choose_from_datasets`, etc).\n+\n+  Returns:\n+    The rewritten dataset.\n+  \"\"\"\n   # pylint: disable=protected-access\n   return _VariantDataset(\n       gen_dataset_ops.rewrite_dataset(dataset._variant_tensor, rewrite,"
        }
    ],
    "stats": {
        "total": 21,
        "additions": 16,
        "deletions": 5
    }
}