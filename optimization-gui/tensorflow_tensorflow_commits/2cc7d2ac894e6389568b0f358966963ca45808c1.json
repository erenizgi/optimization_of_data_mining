{
    "author": "jingpu",
    "message": "Reverts 05c8cf7c132f310c8f8f2a022ba52d22b52e52c4\n\nPiperOrigin-RevId: 848205408",
    "sha": "2cc7d2ac894e6389568b0f358966963ca45808c1",
    "files": [
        {
            "sha": "60a7949138e9c13f3f626bf46c596719efe1a383",
            "filename": "tensorflow/compiler/tests/gather_nd_op_test.py",
            "status": "modified",
            "additions": 2,
            "deletions": 20,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2cc7d2ac894e6389568b0f358966963ca45808c1/tensorflow%2Fcompiler%2Ftests%2Fgather_nd_op_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2cc7d2ac894e6389568b0f358966963ca45808c1/tensorflow%2Fcompiler%2Ftests%2Fgather_nd_op_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftests%2Fgather_nd_op_test.py?ref=2cc7d2ac894e6389568b0f358966963ca45808c1",
            "patch": "@@ -24,14 +24,12 @@\n \n class GatherNdTest(xla_test.XLATestCase):\n \n-  def _runGather(self, params, indices, bad_indices_policy=\"\"):\n+  def _runGather(self, params, indices):\n     with self.session():\n       paramsp = array_ops.placeholder(params.dtype)\n       indicesp = array_ops.placeholder(indices.dtype)\n       with self.test_scope():\n-        gather_nd_t = array_ops.gather_nd(\n-            paramsp, indicesp, bad_indices_policy=bad_indices_policy\n-        )\n+        gather_nd_t = array_ops.gather_nd(paramsp, indicesp)\n       feed_dict = {paramsp: params, indicesp: indices}\n       return gather_nd_t.eval(feed_dict=feed_dict)\n \n@@ -141,22 +139,6 @@ def testHigherRankParamsAndIndices(self):\n     expected = params[tuple(indices.T)]\n     self.assertAllEqual(expected.reshape([10, 10, 20]), gather_nd_val)\n \n-  def testIgnoreBadIndices(self):\n-    shape = (3, 4, 5)\n-    params = np.arange(np.prod(shape), dtype=np.int32).reshape(shape)\n-    indices = np.array([[[0, 0], [-1, 3]], [[2, 4], [2, 3]]], dtype=np.int32)\n-    gather_nd_val = self._runGather(\n-        params, indices, bad_indices_policy=\"IGNORE\"\n-    )\n-    expected = np.array(\n-        [\n-            [[0, 1, 2, 3, 4], [0, 0, 0, 0, 0]],\n-            [[0, 0, 0, 0, 0], [55, 56, 57, 58, 59]],\n-        ],\n-        dtype=np.int32,\n-    )\n-    self.assertAllEqual(expected, gather_nd_val)\n-\n \n if __name__ == \"__main__\":\n   test.main()"
        },
        {
            "sha": "e94f74d1fed8ef0747b11ac87df241e46faacf9a",
            "filename": "tensorflow/compiler/tf2xla/kernels/gather_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 58,
            "changes": 59,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2cc7d2ac894e6389568b0f358966963ca45808c1/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fgather_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2cc7d2ac894e6389568b0f358966963ca45808c1/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fgather_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fgather_op.cc?ref=2cc7d2ac894e6389568b0f358966963ca45808c1",
            "patch": "@@ -15,7 +15,6 @@ limitations under the License.\n \n #include <cstdint>\n #include <optional>\n-#include <string>\n #include <vector>\n \n #include \"absl/log/check.h\"\n@@ -284,13 +283,7 @@ REGISTER_XLA_OP(Name(\"GatherV2\").CompileTimeConstantInput(\"axis\"), GatherOp);\n \n class GatherNdOp : public XlaOpKernel {\n  public:\n-  explicit GatherNdOp(OpKernelConstruction* context) : XlaOpKernel(context) {\n-    // Set batch_dims_ to 0 if the attribute does not exist.\n-    if (context->HasAttr(\"bad_indices_policy\")) {\n-      OP_REQUIRES_OK(context, context->GetAttr(\"bad_indices_policy\",\n-                                               &bad_indices_policy_));\n-    }\n-  }\n+  explicit GatherNdOp(OpKernelConstruction* context) : XlaOpKernel(context) {}\n \n   void Compile(XlaOpKernelContext* context) override {\n     DataType params_type = context->input_type(0);\n@@ -319,58 +312,8 @@ class GatherNdOp : public XlaOpKernel {\n                                       indices_shape, /*axis=*/0,\n                                       /*indices_are_nd=*/true, params_type,\n                                       indices_type, builder, &gather));\n-    // By default, XLA clips OOB indices, while \"IGNORE\" policy demands to fill\n-    // 0s to the output. The following code implements the \"IGNORE\" policy by\n-    // masking the gather result with the valid indices mask.\n-    if (bad_indices_policy_ == \"IGNORE\") {\n-      xla::XlaOp valid_mask;\n-      for (int i = 0; i < num_index_dims; ++i) {\n-        xla::XlaOp i_limit = XlaHelpers::IntegerLiteral(\n-            builder, indices_type, params_shape.dim_size(i));\n-        xla::XlaOp i_zero = XlaHelpers::Zero(builder, indices_type);\n-        xla::XlaOp indices_i =\n-            xla::SliceInDim(indices, i, i + 1, 1, indices_shape.dims() - 1);\n-\n-        xla::XlaOp indices_i_good =\n-            xla::And(xla::Ge(indices_i, i_zero), xla::Lt(indices_i, i_limit));\n-        if (i == 0) {\n-          valid_mask = indices_i_good;\n-        } else {\n-          valid_mask = xla::And(valid_mask, indices_i_good);\n-        }\n-      }\n-      auto gather_shape = builder->GetShape(gather);\n-      OP_REQUIRES_OK(context, gather_shape.status());\n-\n-      std::vector<int64_t> valid_mask_dims(\n-          gather_shape->dimensions().begin(),\n-          gather_shape->dimensions().end() - 1);\n-      valid_mask = xla::Reshape(valid_mask, valid_mask_dims);\n-      if (indices_shape.dims() != gather_shape->dimensions().size()) {\n-        OP_REQUIRES(\n-            context,\n-            gather_shape->dimensions().size() == indices_shape.dims() - 1,\n-            errors::InvalidArgument(\n-                \"Indices rank must be equal to output rank (with channel \"\n-                \"dimension) or 1 less (w/o channel dimension)\"));\n-      } else {\n-        std::vector<int64_t> broadcast_dims(valid_mask_dims.size(), 1);\n-        for (int i = 0; i < broadcast_dims.size(); ++i) {\n-          broadcast_dims[i] = i;\n-        }\n-        valid_mask = xla::BroadcastInDim(valid_mask, gather_shape->dimensions(),\n-                                         broadcast_dims);\n-      }\n-\n-      gather =\n-          xla::Select(valid_mask, gather,\n-                      xla::Broadcast(XlaHelpers::Zero(builder, params_type),\n-                                     gather_shape->dimensions()));\n-    }\n     context->SetOutput(0, gather);\n   }\n-\n-  std::string bad_indices_policy_;\n };\n \n REGISTER_XLA_OP(Name(\"GatherNd\"), GatherNdOp);"
        }
    ],
    "stats": {
        "total": 81,
        "additions": 3,
        "deletions": 78
    }
}