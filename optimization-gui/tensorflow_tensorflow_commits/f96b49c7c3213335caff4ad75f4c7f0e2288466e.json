{
    "author": "ezhulenev",
    "message": "[xla:cpu] Do not outline HLO instruction with parallel config into separate computations\n\nOutlining parallel HLO operations into separation function was needed in legacy codegen, with thunks it only adds run time and memory overheads.\n\nPiperOrigin-RevId: 797527747",
    "sha": "f96b49c7c3213335caff4ad75f4c7f0e2288466e",
    "files": [
        {
            "sha": "ce25c49ec6534fcd221f7a8c8eef1db15438e603",
            "filename": "third_party/xla/xla/backends/cpu/codegen/elemental/concatenate_kernel_emitter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f96b49c7c3213335caff4ad75f4c7f0e2288466e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Felemental%2Fconcatenate_kernel_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f96b49c7c3213335caff4ad75f4c7f0e2288466e/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Felemental%2Fconcatenate_kernel_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Felemental%2Fconcatenate_kernel_emitter.cc?ref=f96b49c7c3213335caff4ad75f4c7f0e2288466e",
            "patch": "@@ -48,9 +48,7 @@ limitations under the License.\n namespace xla::cpu {\n \n static absl::Status CanDoFastConcatenate(const HloInstruction* concatenate) {\n-  if (!concatenate->parent()\n-           ->root_instruction()\n-           ->template backend_config<BackendConfig>()\n+  if (!concatenate->backend_config<BackendConfig>()\n            ->outer_dimension_partitions()\n            .empty()) {\n     return absl::Status("
        },
        {
            "sha": "02d8f615935ac77154d7c397147148d7de6faab7",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f96b49c7c3213335caff4ad75f4c7f0e2288466e/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f96b49c7c3213335caff4ad75f4c7f0e2288466e/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=f96b49c7c3213335caff4ad75f4c7f0e2288466e",
            "patch": "@@ -1555,15 +1555,15 @@ cc_library(\n         \"//xla/hlo/pass:hlo_pass\",\n         \"//xla/service:hlo_cost_analysis\",\n         \"//xla/service/llvm_ir:dynamic_update_slice_util\",\n+        \"//xla/tsl/platform:status\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n-        \"@local_tsl//tsl/platform:logging\",\n         \"@local_tsl//tsl/platform:platform_port\",\n-        \"@local_tsl//tsl/platform:status\",\n     ],\n )\n \n@@ -1581,8 +1581,8 @@ xla_cc_test(\n         \"//xla/hlo/testlib:test\",\n         \"//xla/service:hlo_cost_analysis\",\n         \"//xla/tests:xla_internal_test_main\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/status:statusor\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n "
        },
        {
            "sha": "3047e5218ee3359975ed37347e5606c838507ee6",
            "filename": "third_party/xla/xla/service/cpu/dot_op_emitter.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f96b49c7c3213335caff4ad75f4c7f0e2288466e/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fdot_op_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f96b49c7c3213335caff4ad75f4c7f0e2288466e/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fdot_op_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fdot_op_emitter.cc?ref=f96b49c7c3213335caff4ad75f4c7f0e2288466e",
            "patch": "@@ -1463,14 +1463,6 @@ absl::StatusOr<DotOpWorkGroupDim> EmitDotOperation(\n     const HloModuleConfig& hlo_module_config,\n     const TargetMachineFeatures& target_machine_features,\n     bool allow_runtime_calls, bool allow_parallelism) {\n-  // This routine assumes that the dot operation is not in a parallelized\n-  // enclosing computation.\n-  CHECK(dot.parent()\n-            ->root_instruction()\n-            ->backend_config<BackendConfig>()\n-            ->outer_dimension_partitions()\n-            .empty());\n-\n   if (IsBatchDot(dot)) {\n     TF_RET_CHECK(addend_array == nullptr);\n     return EmitBatchDotOperation(dot, target_array, lhs_array, rhs_array,"
        },
        {
            "sha": "9e8dc4861f7dbbf9a075a84600d5a46dadd80209",
            "filename": "third_party/xla/xla/service/cpu/parallel_task_assignment.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 17,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f96b49c7c3213335caff4ad75f4c7f0e2288466e/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f96b49c7c3213335caff4ad75f4c7f0e2288466e/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment.cc?ref=f96b49c7c3213335caff4ad75f4c7f0e2288466e",
            "patch": "@@ -24,9 +24,9 @@ limitations under the License.\n \n #include \"absl/algorithm/container.h\"\n #include \"absl/container/flat_hash_set.h\"\n+#include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n-#include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/cpu/codegen/target_machine_features.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n@@ -38,14 +38,13 @@ limitations under the License.\n #include \"xla/service/cpu/ir_emission_utils.h\"\n #include \"xla/service/hlo_cost_analysis.h\"\n #include \"xla/service/llvm_ir/dynamic_update_slice_util.h\"\n+#include \"xla/shape.h\"\n #include \"xla/shape_partition.h\"\n+#include \"xla/tsl/platform/status.h\"\n #include \"xla/util.h\"\n #include \"tsl/platform/cpu_info.h\"\n-#include \"tsl/platform/logging.h\"  // IWYU pragma: keep\n-#include \"tsl/platform/status.h\"\n \n-namespace xla {\n-namespace cpu {\n+namespace xla::cpu {\n \n class SimpleCostModel : public ParallelCostModel {\n  public:\n@@ -283,22 +282,14 @@ bool ParallelTaskAssigner::AssignParallelTasksHelper(\n       continue;\n     }\n \n-    // Outline 'instruction' in 'computation' for parallel task assignment.\n-    auto* call = module->OutlineExpressionFromComputation(\n-        {instruction}, absl::StrCat(\"parallel_\", instruction->name()),\n-        computation);\n-\n-    // Set assigned dimension partitioning to 'instruction'.\n-    auto* new_root = call->to_apply()->root_instruction();\n     BackendConfig backend_config;\n     absl::c_copy(dim_partition_counts,\n                  tsl::protobuf::RepeatedFieldBackInserter(\n                      backend_config.mutable_outer_dimension_partitions()));\n-    TF_CHECK_OK(new_root->set_backend_config(backend_config));\n+    TF_CHECK_OK(instruction->set_backend_config(backend_config));\n \n     VLOG(2) << \"Assigned parallel task count: \" << total_partition_count\n-            << \" to instruction: \" << new_root->name()\n-            << \" parent: \" << new_root->parent()->name();\n+            << \" to instruction: \" << instruction->name();\n     changed = true;\n   }\n   return changed;\n@@ -324,5 +315,4 @@ void ParallelTaskAssigner::ComputeTargetParallelTasks(\n   }\n }\n \n-}  // namespace cpu\n-}  // namespace xla\n+}  // namespace xla::cpu"
        },
        {
            "sha": "bf77a1729a4e544d2e5e645e90ad606297ed7723",
            "filename": "third_party/xla/xla/service/cpu/parallel_task_assignment_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f96b49c7c3213335caff4ad75f4c7f0e2288466e/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f96b49c7c3213335caff4ad75f4c7f0e2288466e/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_task_assignment_test.cc?ref=f96b49c7c3213335caff4ad75f4c7f0e2288466e",
            "patch": "@@ -29,7 +29,7 @@ limitations under the License.\n #include \"xla/service/cpu/cpu_executable.h\"\n #include \"xla/service/cpu/target_machine_features_stub.h\"\n #include \"xla/service/hlo_cost_analysis.h\"\n-#include \"tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n \n namespace xla {\n namespace {"
        }
    ],
    "stats": {
        "total": 44,
        "additions": 12,
        "deletions": 32
    }
}