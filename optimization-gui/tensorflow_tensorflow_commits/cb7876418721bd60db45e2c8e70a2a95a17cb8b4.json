{
    "author": "ezhulenev",
    "message": "[xla:gpu] Remove redundant CommunicatorHandle\n\nChange RunCollective API to accept CliqueKey and Communicator\n\nPiperOrigin-RevId: 838956814",
    "sha": "cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
    "files": [
        {
            "sha": "31547a6f412937cbdcd73ec87ec58232e2eacb64",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -1211,6 +1211,7 @@ cc_library(\n         \":thunk\",\n         \"//xla:future\",\n         \"//xla:shape_util\",\n+        \"//xla/backends/gpu/collectives:gpu_clique_key\",\n         \"//xla/backends/gpu/collectives:gpu_collectives\",\n         \"//xla/backends/gpu/collectives:gpu_communicator\",\n         \"//xla/core/collectives:communicator\",\n@@ -1450,6 +1451,7 @@ cc_library(\n         \":thunk\",\n         \"//xla:future\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/backends/gpu/collectives:gpu_clique_key\",\n         \"//xla/backends/gpu/collectives:gpu_collectives\",\n         \"//xla/backends/gpu/collectives:gpu_communicator\",\n         \"//xla/core/collectives:communicator\",\n@@ -1511,6 +1513,7 @@ cc_library(\n         \":thunk\",\n         \"//xla:executable_run_options\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/backends/gpu/collectives:gpu_clique_key\",\n         \"//xla/backends/gpu/collectives:gpu_collectives\",\n         \"//xla/backends/gpu/collectives:gpu_communicator\",\n         \"//xla/core/collectives:communicator\",\n@@ -1777,11 +1780,13 @@ cc_library(\n         \":thunk\",\n         \"//xla:status_macros\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/backends/gpu/collectives:gpu_clique_key\",\n         \"//xla/backends/gpu/collectives:gpu_collectives\",\n         \"//xla/core/collectives:communicator\",\n         \"//xla/core/collectives:rank_id\",\n         \"//xla/hlo/ir:collective_op_group_mode\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:device_id\",\n         \"//xla/service:computation_placer\",\n         \"//xla/service:global_device_id\",\n         \"//xla/stream_executor:device_memory\",\n@@ -1806,11 +1811,13 @@ cc_library(\n         \":thunk\",\n         \"//xla:status_macros\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/backends/gpu/collectives:gpu_clique_key\",\n         \"//xla/backends/gpu/collectives:gpu_collectives\",\n         \"//xla/core/collectives:communicator\",\n         \"//xla/core/collectives:rank_id\",\n         \"//xla/hlo/ir:collective_op_group_mode\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:device_id\",\n         \"//xla/service:computation_placer\",\n         \"//xla/service:global_device_id\",\n         \"//xla/stream_executor:device_memory\",\n@@ -2812,6 +2819,7 @@ cc_library(\n     srcs = [\"nvshmem_collective_thunk.cc\"],\n     hdrs = [\"nvshmem_collective_thunk.h\"],\n     deps = [\n+        \":collective_execution\",\n         \":collective_thunk\",\n         \":thunk\",\n         \"//xla:shape_util\","
        },
        {
            "sha": "fd42f0b4c97843e861f2ea2b05ce3a88687f5551",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_gather_thunk.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n \n #include \"absl/status/status.h\"\n #include \"absl/strings/str_format.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/collectives/gpu_communicator.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n@@ -92,26 +93,25 @@ AllGatherStartThunk::AllGatherStartThunk(ThunkInfo thunk_info,\n }\n \n absl::StatusOr<bool> AllGatherStartThunk::RunCollective(\n-    const ExecuteParams& params, se::Stream& stream,\n-    CommunicatorHandle comm_handle) {\n+    const ExecuteParams& params, const GpuCliqueKey& clique_key,\n+    se::Stream& stream, Communicator& comm) {\n   TF_ASSIGN_OR_RETURN(\n       std::vector<DeviceBufferPair> device_buffers,\n       ConvertToDeviceBuffers(params, buffers_,\n                              config_.config.operand_element_type));\n-  TF_RETURN_IF_ERROR(\n-      xla::gpu::RunAllGather(device_buffers, stream, comm_handle.comm,\n-                             config_.config.use_symmetric_buffer));\n+  TF_RETURN_IF_ERROR(xla::gpu::RunAllGather(\n+      device_buffers, stream, comm, config_.config.use_symmetric_buffer));\n   return true;\n }\n \n absl::Status RunAllGather(std::vector<DeviceBufferPair>& buffers,\n-                          se::Stream& stream, Communicator* comm,\n+                          se::Stream& stream, Communicator& comm,\n                           bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n   VLOG(3) << \"[\" << device_ordinal << \"] Performing all-gather\";\n-  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n+  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, &comm,\n                                           use_symmetric_buffer));\n-  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(comm);\n+  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(&comm);\n   Future<> future = gpu_comm->GroupExecute(\n       [&buffers, &stream](GpuCommunicator* comm) -> absl::Status {\n         for (DeviceBufferPair& buffer : buffers) {"
        },
        {
            "sha": "422781194dc72c7e8cca2cb23b8d610700ccb9a0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_gather_thunk.h",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.h?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/core/collectives/communicator.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n@@ -55,16 +56,17 @@ class AllGatherStartThunk : public CollectiveThunk {\n \n  protected:\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n+                                     const GpuCliqueKey& clique_key,\n                                      se::Stream& stream,\n-                                     CommunicatorHandle comm) override;\n+                                     Communicator& comm) override;\n \n  private:\n   const AllGatherConfig config_;\n   const std::vector<Buffer> buffers_;\n };\n \n absl::Status RunAllGather(std::vector<DeviceBufferPair>& buffers,\n-                          se::Stream& stream, Communicator* comm,\n+                          se::Stream& stream, Communicator& comm,\n                           bool use_symmetric_buffer = false);\n \n }  // namespace gpu"
        },
        {
            "sha": "4fa1ec4ebc6f79bf0747775ea1481062273b48ef",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_reduce_thunk.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 14,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -85,14 +85,14 @@ AllReduceConfig GetAllReduceConfigInst(\n \n absl::Status RunAllReduce(ReductionKind reduction_kind,\n                           std::vector<DeviceBufferPair>& buffers,\n-                          se::Stream& stream, Communicator* comm,\n+                          se::Stream& stream, Communicator& comm,\n                           bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n   VLOG(3) << \"[\" << device_ordinal << \"] Performing all-reduce\";\n-  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n+  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, &comm,\n                                           use_symmetric_buffer));\n \n-  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(comm);\n+  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(&comm);\n   Future<> future =\n       gpu_comm->GroupExecute([reduction_kind, &buffers,\n                               &stream](GpuCommunicator* comm) -> absl::Status {\n@@ -162,16 +162,16 @@ absl::Status AllReduceStartThunk::Initialize(const InitializeParams& params) {\n }\n \n absl::StatusOr<bool> AllReduceStartThunk::RunCollective(\n-    const ExecuteParams& params, se::Stream& stream,\n-    CommunicatorHandle comm_handle) {\n+    const ExecuteParams& params, const GpuCliqueKey& clique_key,\n+    se::Stream& stream, Communicator& comm) {\n   TF_ASSIGN_OR_RETURN(\n       std::vector<DeviceBufferPair> device_buffers,\n       ConvertToDeviceBuffers(params, buffers_,\n                              config_.config.operand_element_type));\n \n   TF_ASSIGN_OR_RETURN(bool use_collective_kernel,\n                       collective_kernel_thunk_->IsSupported(\n-                          comm_handle.clique_key, params.collective_cliques));\n+                          clique_key, params.collective_cliques));\n \n   if (use_collective_kernel) {\n     TF_RETURN_IF_ERROR(collective_kernel_thunk_->ExecuteOnStream(params));\n@@ -180,7 +180,7 @@ absl::StatusOr<bool> AllReduceStartThunk::RunCollective(\n   }\n \n   TF_RETURN_IF_ERROR(RunAllReduce(config_.reduction_kind, device_buffers,\n-                                  stream, comm_handle.comm,\n+                                  stream, comm,\n                                   config_.config.use_symmetric_buffer));\n   return true;\n }\n@@ -206,30 +206,30 @@ ReduceScatterStartThunk::ReduceScatterStartThunk(\n }\n \n absl::StatusOr<bool> ReduceScatterStartThunk::RunCollective(\n-    const ExecuteParams& params, se::Stream& stream,\n-    CommunicatorHandle comm_handle) {\n+    const ExecuteParams& params, const GpuCliqueKey& clique_key,\n+    se::Stream& stream, Communicator& comm) {\n   TF_ASSIGN_OR_RETURN(\n       std::vector<DeviceBufferPair> device_buffers,\n       ConvertToDeviceBuffers(params, buffers_,\n                              config_.config.operand_element_type));\n   TF_RETURN_IF_ERROR(RunReduceScatter(config_.reduction_kind, device_buffers,\n-                                      stream, comm_handle.comm,\n+                                      stream, comm,\n                                       config_.config.use_symmetric_buffer));\n   return true;\n }\n \n absl::Status RunReduceScatter(ReductionKind reduction_kind,\n                               std::vector<DeviceBufferPair>& buffers,\n-                              se::Stream& stream, Communicator* comm,\n+                              se::Stream& stream, Communicator& comm,\n                               bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n   VLOG(3) << \"[\" << device_ordinal << \"] Performing reduce-scatter\";\n-  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n+  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, &comm,\n                                           use_symmetric_buffer));\n \n-  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm->NumRanks());\n+  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n \n-  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(comm);\n+  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(&comm);\n   Future<> future =\n       gpu_comm->GroupExecute([num_ranks, reduction_kind, &buffers,\n                               &stream](GpuCommunicator* comm) -> absl::Status {"
        },
        {
            "sha": "4825fc672ef6694d1e2dfecd1e3968aed33f5d98",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_reduce_thunk.h",
            "status": "modified",
            "additions": 7,
            "deletions": 4,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.h?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -23,6 +23,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/runtime/collective_kernel_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/core/collectives/communicator.h\"\n@@ -84,8 +85,9 @@ class AllReduceStartThunk : public AllReduceReduceScatterThunkBase {\n \n  protected:\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n+                                     const GpuCliqueKey& clique_key,\n                                      se::Stream& stream,\n-                                     CommunicatorHandle comm) override;\n+                                     Communicator& comm) override;\n \n  private:\n   std::unique_ptr<CollectiveKernelThunk> collective_kernel_thunk_;\n@@ -113,20 +115,21 @@ class ReduceScatterStartThunk : public AllReduceReduceScatterThunkBase {\n \n  protected:\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n+                                     const GpuCliqueKey& clique_key,\n                                      se::Stream& stream,\n-                                     CommunicatorHandle comm) override;\n+                                     Communicator& comm) override;\n };\n \n // -----------------------------------------------------------------------------\n \n absl::Status RunAllReduce(ReductionKind reduction_kind,\n                           std::vector<DeviceBufferPair>& buffers,\n-                          se::Stream& stream, Communicator* comm,\n+                          se::Stream& stream, Communicator& comm,\n                           bool use_symmetric_buffer = false);\n \n absl::Status RunReduceScatter(ReductionKind reduction_kind,\n                               std::vector<DeviceBufferPair>& buffers,\n-                              se::Stream& stream, Communicator* comm,\n+                              se::Stream& stream, Communicator& comm,\n                               bool use_symmetric_buffer = false);\n \n }  // namespace gpu"
        },
        {
            "sha": "dbf0376468ce996cb8f987098d6df1b8ea6d3979",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_to_all_thunk.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 17,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -213,8 +213,8 @@ absl::Status AllToAllStartThunk::Initialize(const InitializeParams& params) {\n }\n \n absl::StatusOr<bool> AllToAllStartThunk::RunCollective(\n-    const ExecuteParams& params, se::Stream& stream,\n-    CommunicatorHandle comm_handle) {\n+    const ExecuteParams& params, const GpuCliqueKey& clique_key,\n+    se::Stream& stream, Communicator& comm) {\n   TF_ASSIGN_OR_RETURN(\n       std::vector<DeviceBufferPair> device_buffers,\n       ConvertToDeviceBuffers(params, buffers_,\n@@ -228,7 +228,7 @@ absl::StatusOr<bool> AllToAllStartThunk::RunCollective(\n           receive_pointer_maps_[stream.parent()]->opaque());\n     }\n     std::optional<RankId> rank =\n-        comm_handle.clique_key.rank(params.collective_params->global_device_id);\n+        clique_key.rank(params.collective_params->global_device_id);\n     se::Event* event = nullptr;\n     {\n       absl::MutexLock lock(events_mutex_);\n@@ -241,13 +241,13 @@ absl::StatusOr<bool> AllToAllStartThunk::RunCollective(\n                         [](const auto& pair) { return pair.second.get(); });\n     }\n     TF_RETURN_IF_ERROR(xla::gpu::RunMemCpyAllToAll(\n-        config_.has_split_dimension, device_buffers, stream, comm_handle.comm,\n-        receive_pointer_map, comm_handle.clique_key, *rank, event, events));\n+        config_.has_split_dimension, device_buffers, stream, comm,\n+        receive_pointer_map, clique_key, *rank, event, events));\n     return false;\n   }\n-  TF_RETURN_IF_ERROR(xla::gpu::RunAllToAll(\n-      config_.has_split_dimension, device_buffers, stream, comm_handle.comm,\n-      config_.config.use_symmetric_buffer));\n+  TF_RETURN_IF_ERROR(\n+      xla::gpu::RunAllToAll(config_.has_split_dimension, device_buffers, stream,\n+                            comm, config_.config.use_symmetric_buffer));\n   return true;\n }\n \n@@ -273,16 +273,16 @@ bool AllToAllStartThunk::is_local() const {\n \n absl::Status RunAllToAll(bool has_split_dimension,\n                          std::vector<DeviceBufferPair>& buffers,\n-                         se::Stream& stream, Communicator* comm,\n+                         se::Stream& stream, Communicator& comm,\n                          bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n   VLOG(3) << \"[\" << device_ordinal\n           << \"] Performing all-to-all, has_split_dimension: \"\n           << has_split_dimension;\n-  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n+  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, &comm,\n                                           use_symmetric_buffer));\n \n-  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm->NumRanks());\n+  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n \n   PrimitiveType element_type = buffers[0].element_type;\n   int64_t element_count = buffers[0].element_count;\n@@ -322,7 +322,7 @@ absl::Status RunAllToAll(bool has_split_dimension,\n       }\n     }\n \n-    auto future = comm->AllToAll(\n+    auto future = comm.AllToAll(\n         std::move(send_buffers), std::move(recv_buffers), element_type,\n         chunk_element_count, GpuCollectives::On(stream));\n     TF_RETURN_IF_ERROR(future.Await());\n@@ -333,8 +333,8 @@ absl::Status RunAllToAll(bool has_split_dimension,\n     }\n \n     auto future =\n-        comm->AllToAll(std::move(send_buffers), std::move(recv_buffers),\n-                       element_type, element_count, GpuCollectives::On(stream));\n+        comm.AllToAll(std::move(send_buffers), std::move(recv_buffers),\n+                      element_type, element_count, GpuCollectives::On(stream));\n     TF_RETURN_IF_ERROR(future.Await());\n   }\n \n@@ -367,15 +367,15 @@ absl::Status SyncProgress(absl::string_view name,\n \n absl::Status RunMemCpyAllToAll(bool has_split_dimension,\n                                std::vector<DeviceBufferPair>& buffers,\n-                               se::Stream& stream, Communicator* comm,\n+                               se::Stream& stream, Communicator& comm,\n                                uint64_t receive_pointer_map[],\n                                const GpuCliqueKey& clique_key, RankId rank,\n                                se::Event* event,\n                                std::vector<se::Event*>& events) {\n   int device_ordinal = stream.parent()->device_ordinal();\n   VLOG(3) << \"[\" << device_ordinal << \"] Performing mem-copy-all-to-all\";\n-  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm));\n-  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm->NumRanks());\n+  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, &comm));\n+  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n   TF_RETURN_IF_ERROR(SyncProgress(\"before memcpy all-to-all\", clique_key, rank,\n                                   num_ranks, stream, event, events));\n "
        },
        {
            "sha": "4ced40fd1bff65349820f438aeaad94a134c4fe1",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_to_all_thunk.h",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.h?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -68,8 +68,9 @@ class AllToAllStartThunk : public CollectiveThunk {\n \n  protected:\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n+                                     const GpuCliqueKey& clique_key,\n                                      se::Stream& stream,\n-                                     CommunicatorHandle comm) override;\n+                                     Communicator& comm) override;\n \n   AsyncStreamKind GetAsyncStreamKind() const override;\n \n@@ -99,12 +100,12 @@ class AllToAllStartThunk : public CollectiveThunk {\n \n absl::Status RunAllToAll(bool has_split_dimension,\n                          std::vector<DeviceBufferPair>& buffers,\n-                         se::Stream& stream, Communicator* comm,\n+                         se::Stream& stream, Communicator& comm,\n                          bool use_symmetric_buffer = false);\n \n absl::Status RunMemCpyAllToAll(bool has_split_dimension,\n                                std::vector<DeviceBufferPair>& buffers,\n-                               se::Stream& stream, Communicator* comm,\n+                               se::Stream& stream, Communicator& comm,\n                                uint64_t receive_pointer_map[],\n                                const GpuCliqueKey& clique_key, RankId rank,\n                                se::Event* event,"
        },
        {
            "sha": "3047f79c3a55ae5028cefae538db957be1eecfbd",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_broadcast_thunk.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk.cc?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n \n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/collectives/gpu_communicator.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n@@ -62,19 +63,19 @@ CollectiveBroadcastStartThunk::CollectiveBroadcastStartThunk(\n }\n \n absl::StatusOr<bool> CollectiveBroadcastStartThunk::RunCollective(\n-    const ExecuteParams& params, se::Stream& stream,\n-    CommunicatorHandle comm_handle) {\n+    const ExecuteParams& params, const GpuCliqueKey& clique_key,\n+    se::Stream& stream, Communicator& comm) {\n   TF_ASSIGN_OR_RETURN(\n       std::vector<DeviceBufferPair> device_buffers,\n       ConvertToDeviceBuffers(params, buffers_, config_.operand_element_type));\n-  TF_RETURN_IF_ERROR(::xla::gpu::RunCollectiveBroadcast(device_buffers, stream,\n-                                                        comm_handle.comm));\n+  TF_RETURN_IF_ERROR(\n+      ::xla::gpu::RunCollectiveBroadcast(device_buffers, stream, comm));\n   return true;\n }\n \n absl::Status RunCollectiveBroadcast(std::vector<DeviceBufferPair>& buffers,\n-                                    se::Stream& stream, Communicator* comm) {\n-  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(comm);\n+                                    se::Stream& stream, Communicator& comm) {\n+  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(&comm);\n   Future<> future = gpu_comm->GroupExecute(\n       [&buffers, &stream](GpuCommunicator* comm) -> absl::Status {\n         for (auto buffer : buffers) {"
        },
        {
            "sha": "266bf989fdbefc6a80a533ecc5cdbbb0ab1fda1a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_broadcast_thunk.h",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk.h?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -1,3 +1,4 @@\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n /* Copyright 2024 The OpenXLA Authors. All Rights Reserved.\n \n Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -52,16 +53,17 @@ class CollectiveBroadcastStartThunk : public CollectiveThunk {\n \n  protected:\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n+                                     const GpuCliqueKey& clique_key,\n                                      se::Stream& stream,\n-                                     CommunicatorHandle comm_handle) override;\n+                                     Communicator& comm) override;\n \n  private:\n   const CollectiveConfig config_;\n   const std::vector<Buffer> buffers_;\n };\n \n absl::Status RunCollectiveBroadcast(std::vector<DeviceBufferPair>& buffers,\n-                                    se::Stream& stream, Communicator* comm);\n+                                    se::Stream& stream, Communicator& comm);\n \n }  // namespace xla::gpu\n "
        },
        {
            "sha": "bba7b4b9618833c8f1578e41bc57665c1da13b78",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_execution.h",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.h?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -16,25 +16,13 @@ limitations under the License.\n #ifndef XLA_BACKENDS_GPU_RUNTIME_COLLECTIVE_EXECUTION_H_\n #define XLA_BACKENDS_GPU_RUNTIME_COLLECTIVE_EXECUTION_H_\n \n-#include <utility>\n-\n #include \"absl/status/statusor.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/runtime/collective_params.h\"\n-#include \"xla/core/collectives/communicator.h\"\n \n namespace xla::gpu {\n \n-// Handle to a communicator object with corresponding clique key.\n-struct CommunicatorHandle {\n-  CommunicatorHandle(Communicator* comm, GpuCliqueKey clique_key)\n-      : comm(comm), clique_key(std::move(clique_key)) {}\n-\n-  Communicator* comm;       // communicator object\n-  GpuCliqueKey clique_key;  // clique key\n-};\n-\n // Returns a clique key for a collective operation executed for a given set of\n // replica groups, group mode and stream kind, based on the `params` argument\n // that identifies device that participates in the collective operation."
        },
        {
            "sha": "538e017e0746ae1e1a9578cf89184148b6c4b7cd",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 13,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/time/time.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/collectives/gpu_communicator.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n@@ -229,8 +230,8 @@ bool operator==(const CallRendezvousKey& a, const CallRendezvousKey& b) {\n }\n \n absl::StatusOr<bool> CollectivePermuteStartThunk::RunCollective(\n-    const ExecuteParams& params, se::Stream& stream,\n-    CommunicatorHandle comm_handle) {\n+    const ExecuteParams& params, const GpuCliqueKey& clique_key,\n+    se::Stream& stream, Communicator& comm) {\n   TF_ASSIGN_OR_RETURN(\n       std::vector<DeviceBufferPair> device_buffers,\n       ConvertToDeviceBuffers(params,\n@@ -263,8 +264,7 @@ absl::StatusOr<bool> CollectivePermuteStartThunk::RunCollective(\n       TF_RETURN_IF_ERROR(stream.RecordEvent(receiver_event->second.get()));\n     }\n \n-    TF_ASSIGN_OR_RETURN(size_t num_local_participants,\n-                        comm_handle.comm->NumRanks());\n+    TF_ASSIGN_OR_RETURN(size_t num_local_participants, comm.NumRanks());\n \n     auto rendezvous_name = absl::StrFormat(\n         \"rendezvous before calling collective-permute: run_id=%ld; \"\n@@ -288,9 +288,8 @@ absl::StatusOr<bool> CollectivePermuteStartThunk::RunCollective(\n   }\n \n   TF_RETURN_IF_ERROR(::xla::gpu::RunCollectivePermute(\n-      source_target, device_buffers, stream, comm_handle.comm, device_string,\n-      current_id, use_memcpy, &recv_ptr_map_,\n-      config_.config.use_symmetric_buffer));\n+      source_target, device_buffers, stream, comm, device_string, current_id,\n+      use_memcpy, &recv_ptr_map_, config_.config.use_symmetric_buffer));\n \n   if (use_memcpy) {\n     std::optional<int64_t> source_id = source_target.source;\n@@ -304,8 +303,7 @@ absl::StatusOr<bool> CollectivePermuteStartThunk::RunCollective(\n       TF_RETURN_IF_ERROR(stream.RecordEvent(sender_event->second.get()));\n     }\n \n-    TF_ASSIGN_OR_RETURN(size_t num_local_participants,\n-                        comm_handle.comm->NumRanks());\n+    TF_ASSIGN_OR_RETURN(size_t num_local_participants, comm.NumRanks());\n \n     auto rendezvous_name = absl::StrFormat(\n         \"rendezvous after calling collective-permute: run_id=%ld; \"\n@@ -334,7 +332,7 @@ absl::StatusOr<bool> CollectivePermuteStartThunk::RunCollective(\n absl::Status RunCollectivePermute(\n     P2PConfig::SourceTargetMapEntry source_target,\n     const std::vector<DeviceBufferPair>& buffers, se::Stream& stream,\n-    Communicator* comm, absl::string_view device_string, int64_t current_id,\n+    Communicator& comm, absl::string_view device_string, int64_t current_id,\n     bool use_memcpy,\n     const CollectivePermuteStartThunk::RecvPtrMap* recv_ptr_map,\n     bool use_symmetric_buffer) {\n@@ -400,15 +398,15 @@ absl::Status RunCollectivePermute(\n         const auto src_addr = src_addrs.at(idx);\n         const auto dest_addr = dest_addrs.at(idx);\n         const auto buffer = buffers.at(idx);\n-        auto future = comm->CollectivePermute(\n+        auto future = comm.CollectivePermute(\n             src_addr, dest_addr, buffer.element_type, buffer.element_count,\n             source_rank, target_ranks, GpuCollectives::On(stream));\n         TF_RETURN_IF_ERROR(future.Await());\n       }\n     } else {\n-      TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n+      TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, &comm,\n                                               use_symmetric_buffer));\n-      auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(comm);\n+      auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(&comm);\n       auto future = gpu_comm->GroupExecute(\n           [source_rank, &buffers, &src_addrs, &dest_addrs, &target_ranks,\n            &stream](GpuCommunicator* comm) -> absl::Status {"
        },
        {
            "sha": "964fcd7ea7526befa540bcfa55e37559fc9ba32b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.h",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.h?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -1,3 +1,4 @@\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n /* Copyright 2021 The OpenXLA Authors.\n \n Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -119,8 +120,9 @@ class CollectivePermuteStartThunk : public CollectiveThunk {\n \n  protected:\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n+                                     const GpuCliqueKey& clique_key,\n                                      se::Stream& stream,\n-                                     CommunicatorHandle comm_handle) override;\n+                                     Communicator& comm) override;\n \n  private:\n   const P2PConfig config_;\n@@ -138,7 +140,7 @@ class CollectivePermuteStartThunk : public CollectiveThunk {\n absl::Status RunCollectivePermute(\n     P2PConfig::SourceTargetMapEntry source_target,\n     const std::vector<DeviceBufferPair>& buffers, se::Stream& stream,\n-    Communicator* comm, absl::string_view device_string, int64_t current_id,\n+    Communicator& comm, absl::string_view device_string, int64_t current_id,\n     bool use_memcpy = false,\n     const CollectivePermuteStartThunk::RecvPtrMap* recv_ptr_map = nullptr,\n     bool use_symmetric_buffer = false);"
        },
        {
            "sha": "e181deb9cabc82e38399d5163edbe09d9499b3a0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -304,6 +304,7 @@ absl::Status CollectiveThunk::ExecuteOnStream(const ExecuteParams& params) {\n       Communicator * comm,\n       params.collective_cliques->GetComm(\n           clique_key, params.collective_params->global_device_id));\n+  DCHECK(comm) << \"Failed to get communicator for collective operation\";\n \n   se::StreamExecutor* executor = params.stream->parent();\n   int64_t async_stream_idx = static_cast<int64_t>(stream_kind);\n@@ -318,7 +319,7 @@ absl::Status CollectiveThunk::ExecuteOnStream(const ExecuteParams& params) {\n     TF_RETURN_IF_ERROR(async_stream.WaitFor(params.stream));\n \n     TF_ASSIGN_OR_RETURN(is_first_rendezvous_needed,\n-                        RunCollective(params, async_stream, clique_key, comm));\n+                        RunCollective(params, clique_key, async_stream, *comm));\n \n     // Record collective operation completion.\n     TF_ASSIGN_OR_RETURN(se::Event * event, async_events_->GetEvent(executor));\n@@ -328,7 +329,7 @@ absl::Status CollectiveThunk::ExecuteOnStream(const ExecuteParams& params) {\n     // Launch collective operation on a main stream.\n     TF_ASSIGN_OR_RETURN(\n         is_first_rendezvous_needed,\n-        RunCollective(params, *params.stream, clique_key, comm));\n+        RunCollective(params, clique_key, *params.stream, *comm));\n   }\n \n   // After a first execution of this instance of collective operation do a"
        },
        {
            "sha": "a767ea898979c61a311d231e6a9eb48c827a5b75",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.h",
            "status": "modified",
            "additions": 6,
            "deletions": 11,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -30,7 +30,6 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n-#include \"xla/backends/gpu/runtime/collective_execution.h\"\n #include \"xla/backends/gpu/runtime/collective_params.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n@@ -153,24 +152,20 @@ class CollectiveThunk : public Thunk {\n  protected:\n   // Run collective operation on a given stream and return if the first call\n   // rendezvous with other participants is needed.\n+  //\n   // A collective thunk is normally an independent operation in a sense that\n   // different instances of the same collective thunk communicate each other.\n   // The only exception are SendThunk and RecvThunk. Assume two devices are\n   // executing a program contains the following instructions, the Recv from\n   // device 1 will release the Send from device 0. Adding first call\n   // rendezvous on the SendThunk would cause a runtime deadlock.\n+  //\n   //  Send(src_target={0,1})\n   //  Recv(src_target={0,1})\n-  virtual absl::StatusOr<bool> RunCollective(\n-      const ExecuteParams& params, se::Stream& stream,\n-      CommunicatorHandle comm_handle) = 0;\n-\n-  absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n-                                     se::Stream& stream,\n-                                     const GpuCliqueKey& clique_key,\n-                                     Communicator* comm) {\n-    return RunCollective(params, stream, CommunicatorHandle(comm, clique_key));\n-  }\n+  virtual absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n+                                             const GpuCliqueKey& clique_key,\n+                                             se::Stream& stream,\n+                                             Communicator& comm) = 0;\n \n   virtual const CollectiveConfig& config() const = 0;\n   virtual AsyncStreamKind GetAsyncStreamKind() const { return stream_kind_; }"
        },
        {
            "sha": "ed1053c6317b198ffa2dfedfbe7a361fffd8be42",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -2164,7 +2164,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllReduceCmd::Record(\n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n       [&](se::Stream* stream) {\n-        return RunAllReduce(reduction_kind_, device_buffers, *stream, comm,\n+        return RunAllReduce(reduction_kind_, device_buffers, *stream, *comm,\n                             config().use_symmetric_buffer);\n       });\n }\n@@ -2232,7 +2232,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> ReduceScatterCmd::Record(\n                              command_buffer, [&](se::Stream* stream) {\n                                return RunReduceScatter(\n                                    reduction_kind_, device_buffers, *stream,\n-                                   comm, config().use_symmetric_buffer);\n+                                   *comm, config().use_symmetric_buffer);\n                              });\n }\n \n@@ -2299,7 +2299,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllToAllCmd::Record(\n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n       [&](se::Stream* stream) {\n-        return RunAllToAll(has_split_dimension_, device_buffers, *stream, comm,\n+        return RunAllToAll(has_split_dimension_, device_buffers, *stream, *comm,\n                            config().use_symmetric_buffer);\n       });\n }\n@@ -2363,7 +2363,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllGatherCmd::Record(\n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n       [&](se::Stream* stream) {\n-        return RunAllGather(device_buffers, *stream, comm,\n+        return RunAllGather(device_buffers, *stream, *comm,\n                             config().use_symmetric_buffer);\n       });\n }\n@@ -2428,7 +2428,7 @@ CollectiveBroadcastCmd::Record(const Thunk::ExecuteParams& execute_params,\n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n       [&](se::Stream* stream) {\n-        return RunCollectiveBroadcast(device_buffers, *stream, comm);\n+        return RunCollectiveBroadcast(device_buffers, *stream, *comm);\n       });\n }\n \n@@ -2506,7 +2506,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> CollectivePermuteCmd::Record(\n       execute_params, record_params, std::move(record_action), command_buffer,\n       [&](se::Stream* stream) {\n         return RunCollectivePermute(source_target, device_buffers, *stream,\n-                                    comm, device_string, current_id,\n+                                    *comm, device_string, current_id,\n                                     /*use_memcpy=*/false,\n                                     /*recv_ptr_map=*/nullptr,\n                                     use_symmetric_buffer);"
        },
        {
            "sha": "0a455b884de43df5ea13cf7f5ad1a52eb42f6b0b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/nvshmem_collective_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_thunk.cc?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -27,6 +27,7 @@ limitations under the License.\n #include \"absl/synchronization/mutex.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n+#include \"xla/backends/gpu/runtime/collective_execution.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/core/collectives/collectives.h\""
        },
        {
            "sha": "42eefe60357eb5e44c97c329351a0e416bf2a443",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all_thunk.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 17,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -109,10 +109,10 @@ absl::Status LoadRaggedTensorMetadata(\n absl::Status RunAllToAllOnIndexBuffer(\n     const se::DeviceMemoryBase& source_buffer, int64_t num_updates_per_replica,\n     const se::DeviceMemoryBase& destination_buffer, PrimitiveType element_type,\n-    se::Stream& stream, Communicator* comm) {\n-  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm->NumRanks());\n+    se::Stream& stream, Communicator& comm) {\n+  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n \n-  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(comm);\n+  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(&comm);\n   Future<> future = gpu_comm->GroupExecute(\n       [num_ranks, num_updates_per_replica, element_type, &source_buffer,\n        &destination_buffer, &stream](GpuCommunicator* comm) -> absl::Status {\n@@ -142,14 +142,14 @@ absl::Status RunAllToAllOnIndexBuffer(\n absl::Status RunRaggedAllToAll(\n     int64_t ragged_row_element_size, int64_t num_total_updates,\n     const std::vector<DeviceBufferPair>& original_buffers, se::Stream& stream,\n-    Communicator* comm, absl::Span<int64_t* const> ragged_metadata_allocs,\n+    Communicator& comm, absl::Span<int64_t* const> ragged_metadata_allocs,\n     const se::DeviceMemoryBase& output_offsets_device_buffer,\n     bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n   VLOG(3) << \"[\" << device_ordinal\n           << \"] Performing ragged-all-to-all from device ordinal: \"\n           << device_ordinal;\n-  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm->NumRanks());\n+  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n \n   std::vector<DeviceBufferPair> buffers = original_buffers;\n \n@@ -175,7 +175,7 @@ absl::Status RunRaggedAllToAll(\n   const int64_t* output_offsets = ragged_metadata_allocs[2];\n   const int64_t* recv_sizes = ragged_metadata_allocs[3];\n \n-  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(comm);\n+  auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(&comm);\n   Future<> future = gpu_comm->GroupExecute(\n       [num_updates_per_replica, num_ranks, input_offsets, send_sizes,\n        output_offsets, recv_sizes, ragged_row_element_size, &buffers,\n@@ -468,18 +468,18 @@ bool RaggedAllToAllStartThunk::is_local() const {\n }\n \n absl::StatusOr<bool> RaggedAllToAllStartThunk::RunCollective(\n-    const ExecuteParams& params, se::Stream& stream,\n-    CommunicatorHandle comm_handle) {\n+    const ExecuteParams& params, const GpuCliqueKey& clique_key,\n+    se::Stream& stream, Communicator& comm) {\n   TF_ASSIGN_OR_RETURN(\n       std::vector<DeviceBufferPair> device_buffers,\n       ConvertToDeviceBuffers(params, buffers_,\n                              config_.config.operand_element_type));\n \n-  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm_handle.comm->NumRanks());\n+  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n \n   TF_ASSIGN_OR_RETURN(\n       bool peer_access_enabled,\n-      params.collective_cliques->peer_access_enabled(comm_handle.clique_key));\n+      params.collective_cliques->peer_access_enabled(clique_key));\n \n   StreamState* state = nullptr;\n   {\n@@ -493,8 +493,8 @@ absl::StatusOr<bool> RaggedAllToAllStartThunk::RunCollective(\n                                       device_buffers[0].element_type);\n \n   if (should_use_one_shot_kernel) {\n-    TF_RETURN_IF_ERROR(RunOneShotRaggedAllToAll(comm_handle.clique_key, stream,\n-                                                *state, device_buffers));\n+    TF_RETURN_IF_ERROR(\n+        RunOneShotRaggedAllToAll(clique_key, stream, *state, device_buffers));\n     return false;\n   }\n \n@@ -507,11 +507,11 @@ absl::StatusOr<bool> RaggedAllToAllStartThunk::RunCollective(\n         reinterpret_cast<int64_t*>(state->host_buffer_allocs[i]->opaque()));\n   }\n \n-  TF_RETURN_IF_ERROR(RunRaggedAllToAll(\n-      config_.num_row_elements, config_.num_total_updates, device_buffers,\n-      stream, comm_handle.comm, ragged_metadata_allocs,\n-      state->output_offsets_device_buffer.memory(),\n-      config_.config.use_symmetric_buffer));\n+  TF_RETURN_IF_ERROR(\n+      RunRaggedAllToAll(config_.num_row_elements, config_.num_total_updates,\n+                        device_buffers, stream, comm, ragged_metadata_allocs,\n+                        state->output_offsets_device_buffer.memory(),\n+                        config_.config.use_symmetric_buffer));\n   return true;\n }\n "
        },
        {
            "sha": "609ecf35dd911476fee40fd99d0dd3f21c27b8ff",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all_thunk.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.h?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n+#include \"xla/core/collectives/communicator.h\"\n #include \"xla/core/collectives/rank_id.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/stream_executor/device_memory_handle.h\"\n@@ -74,8 +75,9 @@ class RaggedAllToAllStartThunk : public CollectiveThunk {\n \n  protected:\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n+                                     const GpuCliqueKey& clique_key,\n                                      se::Stream& stream,\n-                                     CommunicatorHandle comm) override;\n+                                     Communicator& comm) override;\n \n  private:\n   struct StreamState {"
        },
        {
            "sha": "8f42d4d2d5fd6c2fe7646cee3b1ba9e8ab07c053",
            "filename": "third_party/xla/xla/backends/gpu/runtime/recv_thunk.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 6,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -24,15 +24,17 @@ limitations under the License.\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/strings/str_format.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/p2p_thunk_common.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/core/collectives/communicator.h\"\n #include \"xla/core/collectives/rank_id.h\"\n #include \"xla/hlo/ir/collective_op_group_mode.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/runtime/device_id.h\"\n #include \"xla/service/computation_placer.h\"\n-#include \"xla/service/global_device_id.h\"\n #include \"xla/status_macros.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/stream.h\"\n@@ -67,8 +69,9 @@ absl::Status RecvThunk::Initialize(const InitializeParams& params) {\n }\n \n absl::StatusOr<bool> RecvThunk::RunCollective(const ExecuteParams& params,\n+                                              const GpuCliqueKey& clique_key,\n                                               se::Stream& stream,\n-                                              CommunicatorHandle comm_handle) {\n+                                              Communicator& comm) {\n   TF_ASSIGN_OR_RETURN(\n       std::vector<DeviceBufferPair> device_buffers,\n       ConvertToDeviceBuffers(params, {buffer_},\n@@ -131,10 +134,10 @@ absl::StatusOr<bool> RecvThunk::RunCollective(const ExecuteParams& params,\n     }\n     if (should_run) {\n       TF_RETURN_IF_ERROR(\n-          MaybeRegisterBuffers(stream.parent(), {buffer}, comm_handle.comm));\n-      auto future = comm_handle.comm->Recv(\n-          dest_addr, buffer.element_type, buffer.element_count,\n-          RankId(*source_id), GpuCollectives::On(stream));\n+          MaybeRegisterBuffers(stream.parent(), {buffer}, &comm));\n+      auto future =\n+          comm.Recv(dest_addr, buffer.element_type, buffer.element_count,\n+                    RankId(*source_id), GpuCollectives::On(stream));\n       TF_RETURN_IF_ERROR(future.Await());\n     } else {\n       VLOG(3) << \"[\" << device_ordinal << \"] Skipping Recv\";"
        },
        {
            "sha": "2d46d6ca6ab922153a101316c2f52508a401b005",
            "filename": "third_party/xla/xla/backends/gpu/runtime/recv_thunk.h",
            "status": "modified",
            "additions": 3,
            "deletions": 7,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.h?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -23,6 +23,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/p2p_thunk_common.h\"\n@@ -44,8 +45,9 @@ class RecvThunk : public CollectiveThunk {\n  protected:\n   const CollectiveConfig& config() const override { return config_.config; }\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n+                                     const GpuCliqueKey& clique_key,\n                                      se::Stream& stream,\n-                                     CommunicatorHandle comm_handle) override;\n+                                     Communicator& comm) override;\n \n  private:\n   const P2PConfig config_;\n@@ -54,12 +56,6 @@ class RecvThunk : public CollectiveThunk {\n   std::string hlo_name_;\n };\n \n-absl::Status RunRecv(GpuCollectives* collectives,\n-                     P2PConfig::SourceTargetMapEntry source_target,\n-                     DeviceBufferPair& buffer, se::Stream& stream,\n-                     Communicator* comm, absl::string_view device_string,\n-                     int64_t current_id);\n-\n }  // namespace gpu\n }  // namespace xla\n "
        },
        {
            "sha": "16e47ddd6d8c3446344be5a82e962b1f8bab52dc",
            "filename": "third_party/xla/xla/backends/gpu/runtime/send_thunk.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 5,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -25,13 +25,16 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/p2p_thunk_common.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/core/collectives/communicator.h\"\n #include \"xla/core/collectives/rank_id.h\"\n #include \"xla/hlo/ir/collective_op_group_mode.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/runtime/device_id.h\"\n #include \"xla/service/computation_placer.h\"\n #include \"xla/service/global_device_id.h\"\n #include \"xla/status_macros.h\"\n@@ -68,8 +71,9 @@ absl::Status SendThunk::Initialize(const InitializeParams& params) {\n }\n \n absl::StatusOr<bool> SendThunk::RunCollective(const ExecuteParams& params,\n+                                              const GpuCliqueKey&,\n                                               se::Stream& stream,\n-                                              CommunicatorHandle comm_handle) {\n+                                              Communicator& comm) {\n   TF_ASSIGN_OR_RETURN(\n       std::vector<DeviceBufferPair> device_buffers,\n       ConvertToDeviceBuffers(params, {buffer_},\n@@ -132,10 +136,10 @@ absl::StatusOr<bool> SendThunk::RunCollective(const ExecuteParams& params,\n \n     if (should_run) {\n       TF_RETURN_IF_ERROR(\n-          MaybeRegisterBuffers(stream.parent(), {buffer}, comm_handle.comm));\n-      auto future = comm_handle.comm->Send(\n-          src_addr, buffer.element_type, buffer.element_count,\n-          RankId(*target_id), GpuCollectives::On(stream));\n+          MaybeRegisterBuffers(stream.parent(), {buffer}, &comm));\n+      auto future =\n+          comm.Send(src_addr, buffer.element_type, buffer.element_count,\n+                    RankId(*target_id), GpuCollectives::On(stream));\n       TF_RETURN_IF_ERROR(future.Await());\n     } else {\n       VLOG(3) << \"[\" << device_ordinal << \"] Skipping Send\";"
        },
        {
            "sha": "e71b7b948f15b092ec8baf2c506bf2146e90af5b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/send_thunk.h",
            "status": "modified",
            "additions": 3,
            "deletions": 7,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cb7876418721bd60db45e2c8e70a2a95a17cb8b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.h?ref=cb7876418721bd60db45e2c8e70a2a95a17cb8b4",
            "patch": "@@ -23,6 +23,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/p2p_thunk_common.h\"\n@@ -44,8 +45,9 @@ class SendThunk : public CollectiveThunk {\n  protected:\n   const CollectiveConfig& config() const override { return config_.config; }\n   absl::StatusOr<bool> RunCollective(const ExecuteParams& params,\n+                                     const GpuCliqueKey& clique_key,\n                                      se::Stream& stream,\n-                                     CommunicatorHandle comm) override;\n+                                     Communicator& comm) override;\n \n  private:\n   const P2PConfig config_;\n@@ -54,12 +56,6 @@ class SendThunk : public CollectiveThunk {\n   std::string hlo_name_;\n };\n \n-absl::Status RunSend(GpuCollectives* collectives,\n-                     P2PConfig::SourceTargetMapEntry source_target,\n-                     DeviceBufferPair& buffer, se::Stream& stream,\n-                     Communicator* comm, absl::string_view device_string,\n-                     int64_t current_id);\n-\n }  // namespace gpu\n }  // namespace xla\n "
        }
    ],
    "stats": {
        "total": 293,
        "additions": 148,
        "deletions": 145
    }
}