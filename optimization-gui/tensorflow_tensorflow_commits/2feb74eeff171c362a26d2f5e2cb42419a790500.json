{
    "author": "majiddadashi",
    "message": "Add i4 support in tfl.slice\n\nPiperOrigin-RevId: 825217744",
    "sha": "2feb74eeff171c362a26d2f5e2cb42419a790500",
    "files": [
        {
            "sha": "6255a4a1d8679e9948c16f0b5cdf412b05f6eb58",
            "filename": "RELEASE.md",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2feb74eeff171c362a26d2f5e2cb42419a790500/RELEASE.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2feb74eeff171c362a26d2f5e2cb42419a790500/RELEASE.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/RELEASE.md?ref=2feb74eeff171c362a26d2f5e2cb42419a790500",
            "patch": "@@ -23,7 +23,9 @@\n     * Adds int8 and int16x8 support for SQRT operator.\n     * Adds int16x8 support for EQUAL and NOT_EQUAL operators.\n     * AddsÂ support for int2 type.\n-    * Adds support for int2/int4 in tfl.cast.\n+    * Adds support for int2/int4 in tfl.cast .\n+    * Adds support for SRQ int2 in tfl.fully_connected.\n+    * Adds support for int4 in tfl.slice.\n \n ### Bug Fixes and Other Changes\n "
        },
        {
            "sha": "e6b1e37eb6c68edc69febf3a4c0bd6243b29f29d",
            "filename": "tensorflow/compiler/mlir/lite/ir/tfl_ops.td",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td?ref=2feb74eeff171c362a26d2f5e2cb42419a790500",
            "patch": "@@ -2477,13 +2477,13 @@ equivalent to setting:\n   }];\n \n   let arguments = (ins\n-    TFL_TensorOf<[F32, I32, I64, I8, UI8, UI32, I1, TFL_Str, QI8, QUI8, TFL_Quint8, QI16]>:$input,\n+    TFL_TensorOf<[F32, I32, I64, QI4, I8, UI8, UI32, I1, TFL_Str, QI8, QUI8, TFL_Quint8, QI16]>:$input,\n     TFL_I32OrI64Tensor:$begin,\n     TFL_I32OrI64Tensor:$size\n   );\n \n   let results = (outs\n-    TFL_TensorOf<[F32, I32, I64, I8, UI8, UI32, I1, TFL_Str, QI8, QUI8, TFL_Quint8, QI16]>:$output\n+    TFL_TensorOf<[F32, I32, I64, QI4, I8, UI8, UI32, I1, TFL_Str, QI8, QUI8, TFL_Quint8, QI16]>:$output\n   );\n \n   let hasVerifier = 1;"
        },
        {
            "sha": "9ccda1d0c95e69de08eeab44f0f8ec55fef3a52c",
            "filename": "tensorflow/compiler/mlir/lite/tools/versioning/op_version.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftools%2Fversioning%2Fop_version.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftools%2Fversioning%2Fop_version.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftools%2Fversioning%2Fop_version.cc?ref=2feb74eeff171c362a26d2f5e2cb42419a790500",
            "patch": "@@ -468,6 +468,9 @@ int GetBuiltinOperatorVersion(const OpSignature& op_sig) {\n       return 1;\n \n     case BuiltinOperator_SLICE:\n+      if (op_sig.inputs.at(0).type == kTfLiteInt4) {\n+        return 7;\n+      }\n       if (op_sig.inputs.at(0).type == kTfLiteUInt32) {\n         return 6;\n       }\n@@ -477,7 +480,6 @@ int GetBuiltinOperatorVersion(const OpSignature& op_sig) {\n       if (op_sig.inputs.at(0).type == kTfLiteInt16) {\n         return 4;\n       }\n-      // Version 3 supports string input types.\n       if (op_sig.inputs.at(0).type == kTfLiteString) {\n         return 3;\n       }"
        },
        {
            "sha": "aca1b463878966722f1d8a6484df2f67ed4af50a",
            "filename": "tensorflow/compiler/mlir/lite/tools/versioning/runtime_version.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftools%2Fversioning%2Fruntime_version.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftools%2Fversioning%2Fruntime_version.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftools%2Fversioning%2Fruntime_version.cc?ref=2feb74eeff171c362a26d2f5e2cb42419a790500",
            "patch": "@@ -295,6 +295,7 @@ std::string FindMinimumRuntimeVersionForOp(tflite::BuiltinOperator op_code,\n               {{BuiltinOperator_SLICE, 4}, \"2.4.0\"},\n               {{BuiltinOperator_SLICE, 5}, \"2.5.0\"},\n               {{BuiltinOperator_SLICE, 6}, \"2.14.0\"},\n+              {{BuiltinOperator_SLICE, 7}, \"2.21.0\"},\n               {{BuiltinOperator_TANH, 1}, \"1.14.0\"},\n               {{BuiltinOperator_TANH, 2}, \"1.14.0\"},\n               {{BuiltinOperator_TANH, 3}, \"2.3.0\"},"
        },
        {
            "sha": "848b28f108adf3c67b5c2e038bb41ac3b93791db",
            "filename": "tensorflow/lite/core/kernels/register.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fcore%2Fkernels%2Fregister.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fcore%2Fkernels%2Fregister.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fcore%2Fkernels%2Fregister.cc?ref=2feb74eeff171c362a26d2f5e2cb42419a790500",
            "patch": "@@ -217,7 +217,7 @@ BuiltinOpResolver::BuiltinOpResolver() {\n              /* max_version = */ 2);\n   AddBuiltin(BuiltinOperator_SLICE, Register_SLICE(),\n              /* min_version = */ 1,\n-             /* max_version = */ 6);\n+             /* max_version = */ 7);\n   AddBuiltin(BuiltinOperator_SIN, Register_SIN());\n   AddBuiltin(BuiltinOperator_COS, Register_COS());\n   AddBuiltin(BuiltinOperator_TRANSPOSE_CONV, Register_TRANSPOSE_CONV(),"
        },
        {
            "sha": "6a3ec9f57e2a02548e55819f250c55e150f8456c",
            "filename": "tensorflow/lite/kernels/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fkernels%2FBUILD?ref=2feb74eeff171c362a26d2f5e2cb42419a790500",
            "patch": "@@ -2573,10 +2573,13 @@ cc_test(\n     ],\n     tags = [\"tflite_nnapi\"],\n     deps = [\n+        \":kernel_util\",\n         \":test_main\",\n         \":test_util\",\n         \"//tensorflow/lite:string\",\n         \"//tensorflow/lite/core/c:common\",\n+        \"//tensorflow/lite/kernels/internal:tensor_ctypes\",\n+        \"//tensorflow/lite/kernels/internal:tensor_utils_no_eigen\",\n         \"//tensorflow/lite/schema:schema_fbs\",\n         \"@com_google_googletest//:gtest\",\n         \"@eigen_archive//:eigen3\","
        },
        {
            "sha": "debdc5142e963db0399534a29dec238d18ae42a4",
            "filename": "tensorflow/lite/kernels/internal/optimized/optimized_ops.h",
            "status": "modified",
            "additions": 75,
            "deletions": 0,
            "changes": 75,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2Finternal%2Foptimized%2Foptimized_ops.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2Finternal%2Foptimized%2Foptimized_ops.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fkernels%2Finternal%2Foptimized%2Foptimized_ops.h?ref=2feb74eeff171c362a26d2f5e2cb42419a790500",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n #include <algorithm>\n #include <cmath>\n #include <cstdint>\n+#include <cstring>\n #include <limits>\n #include <memory>\n #include <tuple>\n@@ -34,6 +35,8 @@ limitations under the License.\n #include \"tensorflow/lite/kernels/internal/reference/add.h\"\n #include \"tensorflow/lite/kernels/internal/reference/mul.h\"\n #include \"tensorflow/lite/kernels/internal/reference/resize_nearest_neighbor.h\"\n+#include \"tensorflow/lite/kernels/internal/runtime_shape.h\"\n+#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n \n #if defined(TF_LITE_USE_CBLAS) && defined(__APPLE__)\n #include <Accelerate/Accelerate.h>\n@@ -4798,6 +4801,78 @@ inline void Slice(const tflite::SliceParams& op_params,\n   return Slice(op_params, input_shape, output_shape, &writer);\n }\n \n+// Iterates through the desired slice region and copies nibbles directly from\n+// the input to the output tensor.\n+inline void SliceInt4(const tflite::SliceParams& op_params,\n+                      const RuntimeShape& input_shape,\n+                      const TfLiteTensor* input,\n+                      const RuntimeShape& output_shape, TfLiteTensor* output) {\n+  ruy::profiler::ScopeLabel label(\"SliceInt4\");\n+\n+  const int8_t* input_data = GetTensorData<int8_t>(input);\n+  int8_t* output_data = GetTensorData<int8_t>(output);\n+\n+  // Clear output buffer, as we will be writing nibbles.\n+  const int output_byte_size = (output_shape.FlatSize() + 1) / 2;\n+  memset(output_data, 0, output_byte_size);\n+\n+  // Calculate the start and stop indices for each dimension of the slice.\n+  const RuntimeShape ext_input_shape =\n+      RuntimeShape::ExtendedShape(5, input_shape);\n+  TFLITE_DCHECK_LE(op_params.begin_count, 5);\n+  TFLITE_DCHECK_LE(op_params.size_count, 5);\n+  const int begin_count = op_params.begin_count;\n+  const int size_count = op_params.size_count;\n+  // We front-pad the begin and size vectors.\n+  int start[5];\n+  int stop[5];\n+  for (int i = 0; i < 5; ++i) {\n+    int padded_i = 5 - i;\n+    start[i] =\n+        begin_count < padded_i ? 0 : op_params.begin[begin_count - padded_i];\n+    stop[i] =\n+        (size_count < padded_i || op_params.size[size_count - padded_i] == -1)\n+            ? ext_input_shape.Dims(i)\n+            : start[i] + op_params.size[size_count - padded_i];\n+  }\n+\n+  // Loop over the slice region and copy nibbles.\n+  int output_nibble_idx = 0;\n+  for (int i0 = start[0]; i0 < stop[0]; ++i0) {\n+    for (int i1 = start[1]; i1 < stop[1]; ++i1) {\n+      for (int i2 = start[2]; i2 < stop[2]; ++i2) {\n+        for (int i3 = start[3]; i3 < stop[3]; ++i3) {\n+          for (int i4 = start[4]; i4 < stop[4]; ++i4) {\n+            const int input_nibble_idx =\n+                Offset(ext_input_shape, i0, i1, i2, i3, i4);\n+\n+            // Get nibble from input. Since int4 data is packed, two nibbles\n+            // share a byte.\n+            const int8_t input_byte = input_data[input_nibble_idx / 2];\n+            int8_t nibble;\n+            if (input_nibble_idx % 2 == 0) {  // low nibble\n+              // The `(val << 4) >> 4` trick is to sign-extend the 4-bit value.\n+              nibble = static_cast<int8_t>(input_byte << 4) >> 4;\n+            } else {  // high nibble\n+              nibble = input_byte >> 4;\n+            }\n+\n+            // Set nibble in output.\n+            if (output_nibble_idx % 2 == 0) {\n+              // First nibble of a byte. We simply set the lower 4 bits.\n+              output_data[output_nibble_idx / 2] = (nibble & 0x0F);\n+            } else {\n+              // Second nibble. OR with existing low nibble.\n+              output_data[output_nibble_idx / 2] |= (nibble << 4);\n+            }\n+            output_nibble_idx++;\n+          }\n+        }\n+      }\n+    }\n+  }\n+}\n+\n template <typename T>\n void Minimum(const RuntimeShape& input1_shape, const T* input1_data,\n              const T* input2_data, const RuntimeShape& output_shape,"
        },
        {
            "sha": "feddd639584c09f68d5998b6cd2f600f909b215b",
            "filename": "tensorflow/lite/kernels/internal/reference/slice.h",
            "status": "modified",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2Finternal%2Freference%2Fslice.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2Finternal%2Freference%2Fslice.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fkernels%2Finternal%2Freference%2Fslice.h?ref=2feb74eeff171c362a26d2f5e2cb42419a790500",
            "patch": "@@ -15,7 +15,14 @@ limitations under the License.\n #ifndef TENSORFLOW_LITE_KERNELS_INTERNAL_REFERENCE_SLICE_H_\n #define TENSORFLOW_LITE_KERNELS_INTERNAL_REFERENCE_SLICE_H_\n \n+#include <cstdint>\n+#include <vector>\n+\n+#include \"tensorflow/lite/core/c/common.h\"\n #include \"tensorflow/lite/kernels/internal/portable_tensor.h\"\n+#include \"tensorflow/lite/kernels/internal/portable_tensor_utils.h\"\n+#include \"tensorflow/lite/kernels/internal/runtime_shape.h\"\n+#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n #include \"tensorflow/lite/kernels/internal/types.h\"\n \n namespace tflite {\n@@ -74,6 +81,27 @@ inline void Slice(const tflite::SliceParams& op_params,\n   return Slice(op_params, input_shape, output_shape, &writer);\n }\n \n+inline void SliceInt4(const tflite::SliceParams& op_params,\n+                      const RuntimeShape& input_shape,\n+                      const TfLiteTensor* input,\n+                      const RuntimeShape& output_shape, TfLiteTensor* output) {\n+  const int num_input_elements = input_shape.FlatSize();\n+  std::vector<int8_t> unpacked_input(num_input_elements);\n+  tensor_utils::UnpackPackedIntToInt8(GetTensorData<int8_t>(input),\n+                                      num_input_elements, 4,\n+                                      unpacked_input.data());\n+\n+  const int num_output_elements = output_shape.FlatSize();\n+  std::vector<int8_t> unpacked_output(num_output_elements);\n+\n+  reference_ops::Slice<int8_t>(op_params, input_shape, unpacked_input.data(),\n+                               output_shape, unpacked_output.data());\n+\n+  tensor_utils::PackInt8IntoDenseInt(unpacked_output.data(),\n+                                     num_output_elements, 4,\n+                                     GetTensorData<int8_t>(output));\n+}\n+\n }  // namespace reference_ops\n }  // namespace tflite\n "
        },
        {
            "sha": "842a9dc99d2dd6ddc3785b5941c4b7e710d25510",
            "filename": "tensorflow/lite/kernels/register_ref.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2Fregister_ref.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2Fregister_ref.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fkernels%2Fregister_ref.cc?ref=2feb74eeff171c362a26d2f5e2cb42419a790500",
            "patch": "@@ -415,7 +415,7 @@ BuiltinRefOpResolver::BuiltinRefOpResolver() {\n   AddBuiltin(BuiltinOperator_SELECT_V2, Register_SELECT_V2());\n   AddBuiltin(BuiltinOperator_SLICE, Register_SLICE_REF(),\n              /* min_version = */ 1,\n-             /* max_version = */ 5);\n+             /* max_version = */ 7);\n   AddBuiltin(BuiltinOperator_SIN, Register_SIN());\n   AddBuiltin(BuiltinOperator_COS, Register_COS());\n   AddBuiltin(BuiltinOperator_TRANSPOSE_CONV, Register_TRANSPOSECONV_REF(),"
        },
        {
            "sha": "62b4ae9440668f88743305c2da34cad925a60a05",
            "filename": "tensorflow/lite/kernels/slice.cc",
            "status": "modified",
            "additions": 26,
            "deletions": 0,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2Fslice.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2Fslice.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fkernels%2Fslice.cc?ref=2feb74eeff171c362a26d2f5e2cb42419a790500",
            "patch": "@@ -13,6 +13,8 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include \"tensorflow/lite/kernels/internal/reference/slice.h\"\n+\n #include <stdint.h>\n \n #include <algorithm>\n@@ -206,6 +208,27 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   // The dimensions in the kernel used to be in reverse-order, and TFLite\n   // arranged the begins and sizes vectors accordingly. This macro incorporates\n   // the needed reversing.\n+#define TF_LITE_SLICE_INT4()                                            \\\n+  {                                                                     \\\n+    TF_LITE_ENSURE_EQ(context, begins.size(), kMaxDim);                 \\\n+    TF_LITE_ENSURE_EQ(context, sizes.size(), kMaxDim);                  \\\n+    tflite::SliceParams op_params;                                      \\\n+    op_params.begin_count = kMaxDim;                                    \\\n+    op_params.size_count = kMaxDim;                                     \\\n+    for (int i = 0; i < kMaxDim; ++i) {                                 \\\n+      op_params.begin[i] = begins[i];                                   \\\n+      op_params.size[i] = sizes[i];                                     \\\n+    }                                                                   \\\n+                                                                        \\\n+    if (kernel_type == kGenericOptimized) {                             \\\n+      optimized_ops::SliceInt4(op_params, GetTensorShape(input), input, \\\n+                               GetTensorShape(output), output);         \\\n+    } else {                                                            \\\n+      reference_ops::SliceInt4(op_params, GetTensorShape(input), input, \\\n+                               GetTensorShape(output), output);         \\\n+    }                                                                   \\\n+  }\n+\n #define TF_LITE_SLICE(data_type)                                               \\\n   {                                                                            \\\n     TF_LITE_ENSURE_EQ(context, begins.size(), kMaxDim);                        \\\n@@ -231,6 +254,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n     case kTfLiteFloat32:\n       TF_LITE_SLICE(float);\n       break;\n+    case kTfLiteInt4:\n+      TF_LITE_SLICE_INT4();\n+      break;\n     case kTfLiteInt32:\n       TF_LITE_SLICE(int32_t);\n       break;"
        },
        {
            "sha": "feb02c48d2f3aae5566d37be529e409e91b58265",
            "filename": "tensorflow/lite/kernels/slice_test.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2Fslice_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2feb74eeff171c362a26d2f5e2cb42419a790500/tensorflow%2Flite%2Fkernels%2Fslice_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fkernels%2Fslice_test.cc?ref=2feb74eeff171c362a26d2f5e2cb42419a790500",
            "patch": "@@ -16,11 +16,16 @@ limitations under the License.\n \n #include <initializer_list>\n #include <string>\n+#include <type_traits>\n #include <vector>\n \n #include \"Eigen/Core\"\n+#include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"tensorflow/lite/core/c/common.h\"\n+#include \"tensorflow/lite/kernels/internal/portable_tensor_utils.h\"\n+#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n+#include \"tensorflow/lite/kernels/kernel_util.h\"\n #include \"tensorflow/lite/kernels/test_util.h\"\n #include \"tensorflow/lite/schema/schema_generated.h\"\n #include \"tensorflow/lite/string_type.h\"\n@@ -67,6 +72,12 @@ class SliceOpModel : public SingleOpModel {\n   }\n \n   void SetInput(std::initializer_list<input_type> data) {\n+    if constexpr (std::is_same<input_type, int8_t>::value) {\n+      if (interpreter_->tensor(input_)->type == kTfLiteInt4) {\n+        PopulateTensor4bit(input_, 0, data.begin(), data.end());\n+        return;\n+      }\n+    }\n     PopulateTensor<input_type>(input_, data);\n   }\n   void SetStringInput(std::vector<string> data) {\n@@ -253,6 +264,22 @@ TEST_P(SliceOpTest, SliceInt8) {\n   EXPECT_THAT(m.GetOutput(), ElementsAreArray({3, 3, 3, 5, 5, 5}));\n }\n \n+TEST_P(SliceOpTest, SliceInt4) {\n+  SliceOpModel<int8_t, int32_t> m({3, 2, 3, 1}, {4}, {1, 0, 0, 0}, {4},\n+                                  {2, 1, -1, 1}, TensorType_INT32,\n+                                  TensorType_INT4, GetParam());\n+  m.SetInput({1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6});\n+  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n+  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({2, 1, 3, 1}));\n+  const TfLiteTensor* output_tensor = m.GetOutputTensor();\n+  int num_elements = NumElements(output_tensor);\n+  std::vector<int8_t> unpacked_output(num_elements);\n+  tensor_utils::UnpackPackedIntToInt8(GetTensorData<int8_t>(output_tensor),\n+                                      num_elements,\n+                                      /*bit_width=*/4, unpacked_output.data());\n+  EXPECT_THAT(unpacked_output, ElementsAreArray({3, 3, 3, 5, 5, 5}));\n+}\n+\n TEST_P(SliceOpTest, SliceInt16) {\n   SliceOpModel<int16_t, int32_t> m({3, 2, 3, 1}, {4}, {1, 0, 0, 0}, {4},\n                                    {2, 1, -1, 1}, TensorType_INT32,"
        }
    ],
    "stats": {
        "total": 176,
        "additions": 170,
        "deletions": 6
    }
}