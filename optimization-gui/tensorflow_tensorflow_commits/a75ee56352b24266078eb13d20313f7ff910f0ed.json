{
    "author": "ezhulenev",
    "message": "[xla:gpu] Do not create clique keys with trivial groups\n\nPiperOrigin-RevId: 831441152",
    "sha": "a75ee56352b24266078eb13d20313f7ff910f0ed",
    "files": [
        {
            "sha": "748746d82cc3e9eb02949cefd5cc881e4ccb74c6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a75ee56352b24266078eb13d20313f7ff910f0ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a75ee56352b24266078eb13d20313f7ff910f0ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=a75ee56352b24266078eb13d20313f7ff910f0ed",
            "patch": "@@ -255,10 +255,14 @@ absl::StatusOr<GpuCliqueKey> GetGpuCliqueKey(\n         \"using a tool designed for only one device like run_hlo_module.\");\n   }\n \n+  // Get the list of all devices that are participating in the collective\n+  // operation.\n   TF_ASSIGN_OR_RETURN(\n       std::vector<GlobalDeviceId> participants,\n       GetParticipatingDevices(global_device_id, *params.device_assn,\n                               replica_groups, group_mode));\n+\n+  // Get grouping of participating devices.\n   std::vector<std::vector<GlobalDeviceId>> participant_groups;\n   if (use_nccl) {\n     // If splitting is enabled, participating groups must match in order for a\n@@ -279,6 +283,13 @@ absl::StatusOr<GpuCliqueKey> GetGpuCliqueKey(\n           \"environment configuration.\");\n     }\n   }\n+\n+  // Remove trivial group that contains all participants, as we do not want to\n+  // create two sets of communicator handles for these cases.\n+  if (participant_groups.size() == 1 && participant_groups[0] == participants) {\n+    participant_groups.clear();\n+  }\n+\n   int64_t num_local_participants =\n       GetNumLocalParticipants(params, participants);\n "
        }
    ],
    "stats": {
        "total": 11,
        "additions": 11,
        "deletions": 0
    }
}