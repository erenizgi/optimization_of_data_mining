{
    "author": "mwhittaker",
    "message": "Remove unused `WaitForAllTasks` from coordination service\n\nPiperOrigin-RevId: 845973213",
    "sha": "07660093c8b57a104784200b3b590f0e43f9fd0f",
    "files": [
        {
            "sha": "39246d62754382dcb6fece033add431bfc7cc3d8",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/coordination_client.h",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_client.h?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -54,8 +54,6 @@ using tensorflow::ShutdownTaskRequest;\n using tensorflow::ShutdownTaskResponse;\n using tensorflow::TryGetKeyValueRequest;\n using tensorflow::TryGetKeyValueResponse;\n-using tensorflow::WaitForAllTasksRequest;\n-using tensorflow::WaitForAllTasksResponse;\n using tensorflow::WatchJobStateRequest;\n using tensorflow::WatchJobStateResponse;\n \n@@ -75,10 +73,6 @@ class CoordinationClient {\n                               HeartbeatResponse* response,\n                               tsl::StatusCallback done) = 0;\n \n-  virtual void WaitForAllTasksAsync(const WaitForAllTasksRequest* request,\n-                                    WaitForAllTasksResponse* response,\n-                                    tsl::StatusCallback done) = 0;\n-\n   virtual void ShutdownTaskAsync(tsl::CallOptions* call_opts,\n                                  const ShutdownTaskRequest* request,\n                                  ShutdownTaskResponse* response,"
        },
        {
            "sha": "73fbf4c0e04b07cc419d993e76439af1bf27c3a3",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/coordination_service.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 56,
            "changes": 56,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service.cc?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -670,31 +670,6 @@ void CoordinationService::RegisterTaskAsync(const CoordinatedTask& task,\n   done(error);\n }\n \n-void CoordinationService::WaitForAllTasks(const CoordinatedTask& task,\n-                                          const DeviceInfo& devices,\n-                                          tsl::StatusCallback done) {\n-  {\n-    absl::MutexLock l(state_mu_);\n-    if (ServiceHasStopped()) {\n-      done(MakeCoordinationError(absl::InternalError(\n-          \"Coordination service has stopped. WaitForAllTasks() failed.\")));\n-      return;\n-    }\n-    const auto& task_state = cluster_state_.find(GetTaskName(task));\n-    // Collect task device info for the first time that task\n-    // has called WaitForAllTasks(). This will be aggregated when the barrier\n-    // passes.\n-    if (task_state != cluster_state_.end() &&\n-        !task_state->second->DeviceInfoIsCollected()) {\n-      task_state->second->CollectDeviceInfo(devices);\n-    }\n-  }\n-  BarrierAsync(device_propagation_barrier_id_, kUniqueBarrierCounter,\n-               kDevicePropagationTimeout, task, {},\n-               [done = std::move(done)](const absl::Status& s,\n-                                        int64_t unused_counter) { done(s); });\n-}\n-\n void CoordinationService::ShutdownTaskAsync(const CoordinatedTask& task,\n                                             tsl::StatusCallback done) {\n   VLOG(3) << \"Task \" << GetTaskName(task) << \" invoked ShutdownTaskAsync()\";\n@@ -1278,7 +1253,6 @@ void CoordinationService::BarrierAsyncLocked(\n       task.recoverable() && counter == 0 &&\n       // Not a special once-only barrier.\n       barrier_id != kClusterRegisterBarrierId &&\n-      barrier_id != device_propagation_barrier_id_ &&\n       barrier_id != shutdown_barrier_id_) {\n     should_initialize_new_instance = true;\n     // Use the service's counter to initialize the new barrier.\n@@ -1415,9 +1389,6 @@ void CoordinationService::PassBarrier(BarrierState* barrier,\n   LOG(INFO) << \"Barrier(\" << BarrierName(*barrier)\n             << \") has passed with status: \" << result;\n   // Special hook for device propagation barrier to set global device ids.\n-  if (barrier->id == device_propagation_barrier_id_) {\n-    AggregateClusterDevices();\n-  }\n   for (const auto& task_at_barrier : barrier->tasks_at_barrier) {\n     // Clean up task state (used as error hooks).\n     const CoordinatedTask& task = task_at_barrier.first;\n@@ -1738,33 +1709,6 @@ void CoordinationService::ReachBarrier(BarrierState* barrier,\n   }\n };\n \n-void CoordinationService::AggregateClusterDevices() {\n-  assert(cluster_devices_.device_size() == 0);\n-  std::vector<CoordinatedTask> ordered_tasks;\n-  // Sort by task name to set deterministic order for cluster devices.\n-  ordered_tasks.reserve(cluster_state_.size());\n-  for (const auto& task : cluster_state_) {\n-    ordered_tasks.push_back(GetTaskFromName(task.first));\n-  }\n-  std::sort(ordered_tasks.begin(), ordered_tasks.end(),\n-            [](const CoordinatedTask& task1, const CoordinatedTask& task2) {\n-              if (task1.job_name() != task2.job_name()) {\n-                return task1.job_name() < task2.job_name();\n-              }\n-              return task1.task_id() < task2.task_id();\n-            });\n-\n-  // Aggregate to global device list.\n-  for (const auto& task : ordered_tasks) {\n-    cluster_devices_.MergeFrom(\n-        cluster_state_[GetTaskName(task)]->GetDeviceInfo());\n-  }\n-\n-  if (post_aggregate_device_fn_ != nullptr) {\n-    cluster_devices_ = post_aggregate_device_fn_(cluster_devices_);\n-  }\n-}\n-\n void CoordinationService::DisconnectAllNonRecoverableTasks() {\n   for (const auto& [task_name, state] : cluster_state_) {\n     if (state->IsRecoverable()) {"
        },
        {
            "sha": "c10c90fbbd758848b274a47369ddacc0516d2f64",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/coordination_service.h",
            "status": "modified",
            "additions": 0,
            "deletions": 19,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service.h?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -144,15 +144,6 @@ class CoordinationService {\n   void RegisterTaskAsync(const tensorflow::CoordinatedTask& task,\n                          IncarnationId incarnation, tsl::StatusCallback done);\n \n-  // Wait for all tasks to be up and running, and register local device\n-  // info. The callback is invoked when all tasks are up and registered, or some\n-  // error occurs.\n-  // Each task's local devices will be appended in a deterministic order, and\n-  // post-processed by the callback in SetDeviceAggregationFunction() (if set).\n-  void WaitForAllTasks(const tensorflow::CoordinatedTask& task,\n-                       const tensorflow::DeviceInfo& devices,\n-                       tsl::StatusCallback done);\n-\n   // Disconnects task from the service. If `shutdown_barrier_timeout_in_ms` is\n   // specified in the config, blocks until all tasks reach the barrier before\n   // disconnecting together.\n@@ -564,13 +555,6 @@ class CoordinationService {\n     // Sets the error and returns true if the task state is not ERROR.\n     // Otherwise, don't overwrite the error and return false.\n     bool SetError(const absl::Status& status);\n-    tensorflow::DeviceInfo GetDeviceInfo() { return devices_; }\n-    void CollectDeviceInfo(const tensorflow::DeviceInfo& devices) {\n-      devices_ = devices;\n-    }\n-    // Checks if task has called WaitForAllTasks() previously, which gathers the\n-    // local device info.\n-    bool DeviceInfoIsCollected() { return !devices_.device().empty(); }\n \n     // This is used to propagate state changes (disconnect, error) to ongoing\n     // barriers.\n@@ -601,7 +585,6 @@ class CoordinationService {\n     // accounts for the lag time between the service recording the state change\n     // and the agent stopping heartbeats/error polling.\n     uint64_t disconnect_grace_period_us_ = 0;\n-    tensorflow::DeviceInfo devices_;\n     // For now, we assume there won't be many simultaneous barriers so we simply\n     // use a set.\n     absl::flat_hash_set<std::string> ongoing_barriers_for_task_;\n@@ -654,8 +637,6 @@ class CoordinationService {\n   std::function<tensorflow::DeviceInfo(const tensorflow::DeviceInfo& devices)>\n       post_aggregate_device_fn_;\n \n-  const std::string device_propagation_barrier_id_ =\n-      absl::StrCat(\"WaitForAllTasks::\", service_incarnation_.value());\n   const std::string shutdown_barrier_id_ =\n       absl::StrCat(\"Shutdown::\", service_incarnation_.value());\n   std::vector<tensorflow::CoordinatedTask> shutdown_barrier_tasks_"
        },
        {
            "sha": "a883a870dc028c9447aae03abf6ec6570e264efd",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/coordination_service_agent.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 29,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_agent.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_agent.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_agent.cc?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -349,35 +349,6 @@ void CoordinationServiceAgent::PollForErrorAsync(tsl::StatusCallback done) {\n       });\n }\n \n-absl::Status CoordinationServiceAgent::WaitForAllTasks(\n-    const DeviceInfo& local_devices) {\n-  absl::Status agent_running_status = ValidateRunningAgent();\n-  if (!agent_running_status.ok()) {\n-    return agent_running_status;\n-  }\n-  WaitForAllTasksRequest request;\n-  *request.mutable_source_task() = task_;\n-  *request.mutable_device_info() = local_devices;\n-  VLOG(3) << \"WaitForAllTasksRequest: \" << request.DebugString();\n-  WaitForAllTasksResponse response;\n-  absl::Status status;\n-  absl::Notification n;\n-  leader_client_->WaitForAllTasksAsync(&request, &response,\n-                                       [&](const absl::Status& s) {\n-                                         status = s;\n-                                         n.Notify();\n-                                       });\n-  n.WaitForNotification();\n-  if (!status.ok()) {\n-    VLOG(3) << \"WaitForAllTasksResponse: \" << status;\n-    SetError(status);\n-    return status;\n-  }\n-  VLOG(3) << \"WaitForAllTasksResponse: \" << response.DebugString();\n-  cluster_devices_ = response.device_info();\n-  return absl::OkStatus();\n-}\n-\n const DeviceInfo& CoordinationServiceAgent::GetClusterDeviceInfo() {\n   return cluster_devices_;\n }"
        },
        {
            "sha": "3671f98aa11007c1f7b13ab7574149d12748afca",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/coordination_service_agent.h",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_agent.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_agent.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_agent.h?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -149,14 +149,6 @@ class CoordinationServiceAgent {\n   //              the configured timeout)\n   absl::Status Connect();\n \n-  // Wait for all tasks to be up and registered. The call blocks until all tasks\n-  // in the cluster are up, or some error occurs.\n-  // Possible service errors:\n-  //   - Internal: Coordination service has shut down.\n-  //   - FailedPrecondition: Agent is not in CONNECTED state.\n-  //   - InvalidArgument: Unexpected task request\n-  absl::Status WaitForAllTasks(const tensorflow::DeviceInfo& local_devices);\n-\n   // Get the device attributes of tasks from remote tasks in the cluster.\n   const tensorflow::DeviceInfo& GetClusterDeviceInfo();\n "
        },
        {
            "sha": "5e0f80b504d979b2eede8a31d75278abe29c5018",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/coordination_service_agent_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 10,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_agent_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_agent_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_agent_test.cc?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -136,16 +136,6 @@ class TestCoordinationClient : public CoordinationClient {\n               (tsl::CallOptions * call_opts, const PollForErrorRequest*,\n                PollForErrorResponse*, tsl::StatusCallback),\n               (override));\n-\n-#define UNIMPLEMENTED(method)                                              \\\n-  void method##Async(const method##Request* request,                       \\\n-                     method##Response* response, tsl::StatusCallback done) \\\n-      override {                                                           \\\n-    done(absl::UnimplementedError(#method \"Async\"));                       \\\n-  }\n-\n-  UNIMPLEMENTED(WaitForAllTasks);\n-#undef UNIMPLEMENTED\n };\n \n class CoordinationServiceAgentTest : public ::testing::Test {"
        },
        {
            "sha": "d07dd613bb7667c7fac48af626e84bab75625b13",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/coordination_service_rpc_handler.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_rpc_handler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_rpc_handler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_rpc_handler.cc?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -91,26 +91,6 @@ void CoordinationServiceRpcHandler::HeartbeatAsync(\n   done(absl::OkStatus());\n }\n \n-void CoordinationServiceRpcHandler::WaitForAllTasksAsync(\n-    const tensorflow::WaitForAllTasksRequest* request,\n-    tensorflow::WaitForAllTasksResponse* response, tsl::StatusCallback done) {\n-  absl::ReaderMutexLock l(mu_);\n-  if (service_ == nullptr) {\n-    done(MakeCoordinationError(\n-        absl::InternalError(\"Coordination service is not enabled.\")));\n-    return;\n-  }\n-  service_->WaitForAllTasks(\n-      request->source_task(), request->device_info(),\n-      [response, service = service_, done = std::move(done)](absl::Status s) {\n-        if (s.ok()) {\n-          service->state_mu_.AssertHeld();\n-          *response->mutable_device_info() = service->ListClusterDevices();\n-        }\n-        done(s);\n-      });\n-}\n-\n void CoordinationServiceRpcHandler::ShutdownTaskAsync(\n     const tensorflow::ShutdownTaskRequest* request,\n     tensorflow::ShutdownTaskResponse* response, tsl::StatusCallback done) {"
        },
        {
            "sha": "a5cf6bfea97288c0ed6b31f4fb3a79dba1649c1c",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/coordination_service_rpc_handler.h",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_rpc_handler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_rpc_handler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_rpc_handler.h?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -40,10 +40,6 @@ class CoordinationServiceRpcHandler {\n                       tensorflow::HeartbeatResponse* response,\n                       tsl::StatusCallback done);\n \n-  void WaitForAllTasksAsync(const tensorflow::WaitForAllTasksRequest* request,\n-                            tensorflow::WaitForAllTasksResponse* response,\n-                            tsl::StatusCallback done);\n-\n   void ShutdownTaskAsync(const tensorflow::ShutdownTaskRequest* request,\n                          tensorflow::ShutdownTaskResponse* response,\n                          tsl::StatusCallback done);"
        },
        {
            "sha": "2a31a73e68cab4e6e5465d84ceb3ceee51b9b436",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/coordination_service_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 187,
            "changes": 187,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fcoordination_service_test.cc?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -110,7 +110,6 @@ class TestCoordinationClient : public CoordinationClient {\n     done(absl::UnimplementedError(#method \"Async\"));                       \\\n   }\n \n-  UNIMPLEMENTED(WaitForAllTasks);\n   UNIMPLEMENTED(ResetTask);\n   UNIMPLEMENTED(GetTaskState);\n   UNIMPLEMENTED(InsertKeyValue);\n@@ -270,19 +269,8 @@ TEST_F(CoordinateTwoTasksTest, TestStandaloneService) {\n   task_2.set_task_id(2);\n \n   ASSERT_OK(coord_service_->RegisterTask(task_0_, incarnation_0_));\n-  absl::Notification wait_for_all;\n-  coord_service_->WaitForAllTasks(task_0_, {}, [&](absl::Status s) {\n-    ASSERT_OK(s);\n-    wait_for_all.Notify();\n-  });\n   // Not all tasks have registered, so must not be notified here.\n-  ASSERT_FALSE(wait_for_all.HasBeenNotified());\n   ASSERT_OK(coord_service_->RegisterTask(task_1_, incarnation_1_));\n-  coord_service_->WaitForAllTasks(task_1_, {},\n-                                  [&](absl::Status s) { ASSERT_OK(s); });\n-  // All tasks have registered.\n-  wait_for_all.WaitForNotification();\n-\n   ASSERT_OK(coord_service_->RecordHeartbeat(task_0_, incarnation_0_));\n   ASSERT_OK(coord_service_->RecordHeartbeat(task_1_, incarnation_1_));\n   EXPECT_THAT(coord_service_->RecordHeartbeat(task_2, IncarnationId(0)),\n@@ -295,64 +283,6 @@ TEST_F(CoordinateTwoTasksTest, TestStandaloneService) {\n               StatusIs(absl::StatusCode::kAborted));\n }\n \n-TEST(CoordinationServiceTest, TestCoordinatedJobs) {\n-  CoordinatedTask chief;\n-  chief.set_job_name(\"chief\");\n-  chief.set_task_id(0);\n-  CoordinatedTask task_0;\n-  task_0.set_job_name(\"worker\");\n-  task_0.set_task_id(0);\n-  CoordinatedTask task_1;\n-  task_1.set_job_name(\"worker\");\n-  task_1.set_task_id(1);\n-  CoordinatedTask evaluator;\n-  evaluator.set_job_name(\"evaluator\");\n-  evaluator.set_task_id(0);\n-\n-  CoordinationService::Config config;\n-  CoordinatedJob chief_job;\n-  chief_job.set_name(\"chief\");\n-  chief_job.set_num_tasks(1);\n-  config.coordinated_job_list.push_back(chief_job);\n-  CoordinatedJob worker_job;\n-  worker_job.set_name(\"worker\");\n-  worker_job.set_num_tasks(2);\n-  config.coordinated_job_list.push_back(worker_job);\n-\n-  auto coord_service =\n-      std::make_unique<CoordinationService>(tsl::Env::Default(), config);\n-\n-  // Each coordinated task registers and waits for other tasks.\n-  absl::Notification register_chief;\n-  ASSERT_OK(coord_service->RegisterTask(chief, IncarnationId(0)));\n-  coord_service->WaitForAllTasks(chief, {}, [&](absl::Status s) {\n-    ASSERT_OK(s);\n-    register_chief.Notify();\n-  });\n-  absl::Notification register_task0;\n-  ASSERT_OK(coord_service->RegisterTask(task_0, IncarnationId(0)));\n-  coord_service->WaitForAllTasks(task_0, {}, [&](absl::Status s) {\n-    ASSERT_OK(s);\n-    register_task0.Notify();\n-  });\n-  absl::Notification register_task1;\n-  ASSERT_OK(coord_service->RegisterTask(task_1, IncarnationId(0)));\n-  coord_service->WaitForAllTasks(task_1, {}, [&](absl::Status s) {\n-    ASSERT_OK(s);\n-    register_task1.Notify();\n-  });\n-  // All tasks in the coordinated jobs have registered.\n-  register_chief.WaitForNotification();\n-  register_task0.WaitForNotification();\n-  register_task1.WaitForNotification();\n-\n-  // Registering the evaluator task is unexpected\n-  absl::Status status =\n-      coord_service->RegisterTask(evaluator, IncarnationId(0));\n-\n-  EXPECT_THAT(status, StatusIs(absl::StatusCode::kInvalidArgument));\n-}\n-\n // RegisterTask() may succeed in the service, but the agent response times out.\n // In this case, the agent would retry Connect() and should succeed if it has\n // the same incarnation.\n@@ -960,123 +890,6 @@ TEST_F(CoordinateTwoTasksTest,\n \n }  // namespace\n \n-// Verify that coordination service can gather each task's device info and\n-// propagate the aggregated cluster device info correctly.\n-TEST(CoordinationServiceTest, ListClusterDevices_TfDevice) {\n-  const CoordinationService::Config config =\n-      GetCoordinationServiceConfig(/*num_tasks=*/3);\n-  CoordinatedTask task_0;\n-  task_0.set_job_name(\"worker\");\n-  task_0.set_task_id(0);\n-  CoordinatedTask task_1;\n-  task_1.set_job_name(\"worker\");\n-  task_1.set_task_id(1);\n-  CoordinatedTask task_2;\n-  task_2.set_job_name(\"worker\");\n-  task_2.set_task_id(2);\n-  absl::Status status = absl::OkStatus();\n-  std::unique_ptr<CoordinationService> coord_service =\n-      std::make_unique<CoordinationService>(tsl::Env::Default(), config);\n-  absl::Notification n;\n-  // Map fake devices to each task.\n-  DeviceInfo local_devices_0;\n-  DeviceInfo local_devices_1;\n-  DeviceInfo local_devices_2;\n-  local_devices_0.mutable_device()->Add()->PackFrom(\n-      CreateTestDevice(\"task0_device0\"));\n-  local_devices_0.mutable_device()->Add()->PackFrom(\n-      CreateTestDevice(\"task0_device1\"));\n-  local_devices_1.mutable_device()->Add()->PackFrom(\n-      CreateTestDevice(\"task1_device0\"));\n-  local_devices_2.mutable_device()->Add()->PackFrom(\n-      CreateTestDevice(\"task2_device0\"));\n-\n-  // Each task sends its device info.\n-  DeviceInfo cluster_devices;\n-  coord_service->WaitForAllTasks(task_0, local_devices_0,\n-                                 [&](absl::Status s) { ASSERT_OK(s); });\n-  coord_service->WaitForAllTasks(task_1, local_devices_1,\n-                                 [&](absl::Status s) { ASSERT_OK(s); });\n-  coord_service->WaitForAllTasks(task_2, local_devices_2, [&](absl::Status s) {\n-    ASSERT_OK(s);\n-    // Gather the cluster device info.\n-    coord_service->state_mu_.AssertHeld();\n-    cluster_devices = coord_service->ListClusterDevices();\n-    n.Notify();\n-  });\n-  n.WaitForNotification();\n-\n-  DeviceInfo expected_cluster_devices;\n-  auto expected_devices = expected_cluster_devices.mutable_device();\n-  expected_devices->Add(local_devices_0.device().begin(),\n-                        local_devices_0.device().end());\n-  expected_devices->Add(local_devices_1.device().begin(),\n-                        local_devices_1.device().end());\n-  expected_devices->Add(local_devices_2.device().begin(),\n-                        local_devices_2.device().end());\n-  EXPECT_THAT(cluster_devices, EqualsProto(expected_cluster_devices));\n-}\n-\n-// Task devices should not be added twice if same task calls WaitForAllDevices()\n-// twice.\n-TEST(CoordinationServiceTest, ListClusterDevices_DevicesAreNotAddedTwice) {\n-  const CoordinationService::Config config =\n-      GetCoordinationServiceConfig(/*num_tasks=*/2);\n-  CoordinatedTask task_0;\n-  task_0.set_job_name(\"worker\");\n-  task_0.set_task_id(0);\n-  CoordinatedTask task_1;\n-  task_1.set_job_name(\"worker\");\n-  task_1.set_task_id(1);\n-  absl::Status status = absl::OkStatus();\n-  absl::Status initial_wait_for_all_tasks_status;\n-  std::unique_ptr<CoordinationService> coord_service =\n-      std::make_unique<CoordinationService>(tsl::Env::Default(), config);\n-  absl::Notification n;\n-  // Map fake devices to each task.\n-  DeviceInfo local_devices_0;\n-  DeviceInfo local_devices_1;\n-  local_devices_0.mutable_device()->Add()->PackFrom(\n-      CreateTestDevice(\"task0_device0\"));\n-  local_devices_0.mutable_device()->Add()->PackFrom(\n-      CreateTestDevice(\"task0_device1\"));\n-  local_devices_1.mutable_device()->Add()->PackFrom(\n-      CreateTestDevice(\"task1_device0\"));\n-  // Task0 sends device info.\n-  DeviceInfo cluster_devices;\n-  coord_service->WaitForAllTasks(\n-      task_0, local_devices_0,\n-      [&initial_wait_for_all_tasks_status](absl::Status s) {\n-        initial_wait_for_all_tasks_status = s;\n-      });\n-\n-  // Task0 sends device info again.\n-  coord_service->WaitForAllTasks(task_0, local_devices_0,\n-                                 [](absl::Status s) { ASSERT_OK(s); });\n-  coord_service->WaitForAllTasks(task_1, local_devices_1,\n-                                 [coord_service = coord_service.get(),\n-                                  &cluster_devices, &n](absl::Status s) {\n-                                   ASSERT_OK(s);\n-                                   // Gather the cluster device info.\n-                                   coord_service->state_mu_.AssertHeld();\n-                                   cluster_devices =\n-                                       coord_service->ListClusterDevices();\n-                                   n.Notify();\n-                                 });\n-  n.WaitForNotification();\n-\n-  // No duplicates found.\n-  DeviceInfo expected_cluster_devices;\n-  auto expected_devices = expected_cluster_devices.mutable_device();\n-  expected_devices->Add(local_devices_0.device().begin(),\n-                        local_devices_0.device().end());\n-  expected_devices->Add(local_devices_1.device().begin(),\n-                        local_devices_1.device().end());\n-  EXPECT_THAT(cluster_devices, EqualsProto(expected_cluster_devices));\n-  EXPECT_THAT(initial_wait_for_all_tasks_status,\n-              StatusIs(absl::StatusCode::kCancelled));\n-}\n-\n TEST_F(CoordinationBarrierTest, Barrier) {\n   const std::string barrier_id = \"barrier_id\";\n   absl::Duration timeout = absl::Seconds(5);"
        },
        {
            "sha": "fda1f65f1c9947e954e6d3e60b23ff52cf5c6896",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/grpc_coordination_client.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fgrpc_coordination_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fgrpc_coordination_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fgrpc_coordination_client.cc?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -71,8 +71,6 @@ using tensorflow::ShutdownTaskRequest;\n using tensorflow::ShutdownTaskResponse;\n using tensorflow::TryGetKeyValueRequest;\n using tensorflow::TryGetKeyValueResponse;\n-using tensorflow::WaitForAllTasksRequest;\n-using tensorflow::WaitForAllTasksResponse;\n using tensorflow::WatchJobStateRequest;\n using tensorflow::WatchJobStateResponse;\n \n@@ -130,16 +128,6 @@ class GrpcCoordinationClient : public CoordinationClient {\n         &target_);\n   }\n \n-  void WaitForAllTasksAsync(const WaitForAllTasksRequest* request,\n-                            WaitForAllTasksResponse* response,\n-                            tsl::StatusCallback done) override {\n-    new tsl::RPCState<tsl::protobuf::Message>(\n-        &stub_, cq_, \"/tensorflow.CoordinationService/WaitForAllTasks\",\n-        *request, response, std::move(done), /*call_opts=*/nullptr,\n-        /*threadpool=*/nullptr, /*max_retries=*/0, /*fail_fast=*/true,\n-        &target_);\n-  }\n-\n   void ShutdownTaskAsync(tsl::CallOptions* call_opts,\n                          const ShutdownTaskRequest* request,\n                          ShutdownTaskResponse* response,"
        },
        {
            "sha": "c92026bd6d7b84c5cbd82927ad81193b1e7fe307",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/grpc_coordination_service_impl.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fgrpc_coordination_service_impl.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fgrpc_coordination_service_impl.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fgrpc_coordination_service_impl.cc?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -44,7 +44,6 @@ void GrpcCoordinationServiceImpl::HandleRPCsLoop() {\n                        &GrpcCoordinationServiceImpl::method##Handler, false); \\\n   } while (0)\n   ENQUEUE_REQUEST(RegisterTask);\n-  ENQUEUE_REQUEST(WaitForAllTasks);\n   ENQUEUE_REQUEST(ShutdownTask);\n   ENQUEUE_REQUEST(ResetTask);\n   ENQUEUE_REQUEST(Heartbeat);"
        },
        {
            "sha": "8a5e5a3e3070225a1471305c1d0c9d7f5b0b63e5",
            "filename": "third_party/xla/xla/pjrt/distributed/coordination/grpc_coordination_service_impl.h",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fgrpc_coordination_service_impl.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07660093c8b57a104784200b3b590f0e43f9fd0f/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fgrpc_coordination_service_impl.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdistributed%2Fcoordination%2Fgrpc_coordination_service_impl.h?ref=07660093c8b57a104784200b3b590f0e43f9fd0f",
            "patch": "@@ -85,7 +85,6 @@ class GrpcCoordinationServiceImpl : public tsl::AsyncServiceInterface {\n                        /*supports_cancel=*/false);                            \\\n   }\n   HANDLER(RegisterTask);\n-  HANDLER(WaitForAllTasks);\n   HANDLER(ShutdownTask);\n   HANDLER(ResetTask);\n   HANDLER(Heartbeat);"
        }
    ],
    "stats": {
        "total": 353,
        "additions": 0,
        "deletions": 353
    }
}