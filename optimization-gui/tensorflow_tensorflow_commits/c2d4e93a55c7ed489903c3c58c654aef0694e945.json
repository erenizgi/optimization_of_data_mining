{
    "author": "sohaibiftikhar",
    "message": "[XLA:GPU] Fix lowering of triton atomic passes.\n\n- Registers need to be scoped in inline PTX to prevent naming clashes.\n- Cross GPU block barrier needs a single GPU block barrier (__syncthreads) to\n  prevent races.\n\nPiperOrigin-RevId: 837066209",
    "sha": "c2d4e93a55c7ed489903c3c58c654aef0694e945",
    "files": [
        {
            "sha": "cc9bd2516950a2d434b8c1c2b9dc3f168b2bf744",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/ir/triton_xla_dialect.td",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_dialect.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_dialect.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_dialect.td?ref=c2d4e93a55c7ed489903c3c58c654aef0694e945",
            "patch": "@@ -28,6 +28,10 @@ def XlaTritonDialect : Dialect {\n \n   let cppNamespace = \"::mlir::triton::xla\";\n   let useDefaultAttributePrinterParser = 1;\n+  let dependentDialects = [\n+    \"mlir::triton::TritonDialect\",\n+    \"mlir::triton::gpu::TritonGPUDialect\"\n+  ];\n }\n \n #endif // XLA_BACKENDS_GPU_CODEGEN_TRITON_IR_TRITON_XLA_DIALECT_TD_"
        },
        {
            "sha": "ae5fc9397ba709d9172f675c7802f206b3159a24",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD?ref=c2d4e93a55c7ed489903c3c58c654aef0694e945",
            "patch": "@@ -71,7 +71,6 @@ cc_library(\n         \"//xla/stream_executor/gpu:tma_metadata\",\n         \"//xla/tsl/platform:errors\",\n         \"@com_google_absl//absl/algorithm:container\",\n-        \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\","
        },
        {
            "sha": "8401d447dfe220a781b4db8773834036254624a0",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_atomic_spin_wait.mlir",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_atomic_spin_wait.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_atomic_spin_wait.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_atomic_spin_wait.mlir?ref=c2d4e93a55c7ed489903c3c58c654aef0694e945",
            "patch": "@@ -5,12 +5,14 @@\n // CHECK-SAME:    %[[ARG1:.*]]: i32\n tt.func @nomask_kernel(%ptr : !tt.ptr<i32>, %expected : i32) {\n // CHECK-NEXT:  %[[RES:.+]] = tt.elementwise_inline_asm\n+// CHECK-SAME:  {\n // CHECK-SAME:  .reg .pred %p<1>;\n // CHECK-SAME:  .reg .b32 %r<1>;\n // CHECK-SAME:  wait:\n // CHECK-SAME:  ld.global.gpu.relaxed.u32 %r0, [$1];\n // CHECK-SAME:  setp.eq.u32 %p0, %r0, $2;\n // CHECK-SAME:  @%p0 bra wait;\n+// CHECK-SAME:  }\n // CHECK-SAME:  {constraints = \"=r,l,r\", packed_element = 1 : i32, pure = false}\n // CHECK-SAME:  %[[ARG0]], %[[ARG1]]\n // CHECK-SAME:  !tt.ptr<i32>, i32 -> i32\n@@ -28,6 +30,7 @@ tt.func @masked_kernel(\n   %expected: i32\n ) {\n // CHECK:         tt.elementwise_inline_asm\n+// CHECK-SAME:    {\n // CHECK-SAME:    .reg .pred %p<2>;\n // CHECK-SAME:    .reg .b32 %r<1>;\n // CHECK-SAME:    setp.ne.u32 %p0, $3, 0;\n@@ -37,6 +40,7 @@ tt.func @masked_kernel(\n // CHECK-SAME:    setp.lt.u32 %p1, %r0, $2;\n // CHECK-SAME:    @%p1 bra wait;\n // CHECK-SAME:    done:\n+// CHECK-SAME:    }\n // CHECK-SAME:    {constraints = \"=r,l,r,r\", packed_element = 1 : i32, pure = false}\n // CHECK-SAME:    %[[ARG0]], %[[ARG2]], %[[ARG1]]\n // CHECK-SAME:    tensor<4x!tt.ptr<i32>>, i32, tensor<4xi1> -> tensor<4xi32>"
        },
        {
            "sha": "e5e13eb0efde5b6e8238106855ce6d2c216d240e",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_atomic_write.mlir",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_atomic_write.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_atomic_write.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_atomic_write.mlir?ref=c2d4e93a55c7ed489903c3c58c654aef0694e945",
            "patch": "@@ -29,9 +29,11 @@ tt.func @nomask_vector_kernel(%ptr : tensor<8x!tt.ptr<i32>>, %value : i32) {\n // CHECK-SAME: (%[[ARG0:.+]]: tensor<4x!tt.ptr<i32>>, %[[ARG1:.+]]: i32, %[[ARG2:.+]]: tensor<4xi1>)\n tt.func @mask_kernel(%ptr : tensor<4x!tt.ptr<i32>>, %value : i32, %mask : tensor<4xi1>) {\n   // CHECK-NEXT: %[[RES:.+]] = tt.elementwise_inline_asm\n+  // CHECK-SAME: {\n   // CHECK-SAME: .reg .pred %p<>;\n   // CHECK-SAME: setp.ne.u32 %p<>, $3, 0;\n   // CHECK-SAME: @%p st.global.sys.release.u32 [$1], $2;\n+  // CHECK-SAME: }\n   // CHECK-SAME: {constraints = \"=r,l,r,r\", packed_element = 1 : i32, pure = false}\n   // CHECK-SAME: %[[ARG0]], %[[ARG1]], %[[ARG2]] : tensor<4x!tt.ptr<i32>>, i32, tensor<4xi1> -> tensor<4xi32>\n   triton_xla.atomic_write sys, release, %ptr,  %value, %mask:"
        },
        {
            "sha": "7f5d7a37f7ec3d1a2102bf2d8b621f22a97e18d6",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_block_barrier.mlir",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_block_barrier.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_block_barrier.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_block_barrier.mlir?ref=c2d4e93a55c7ed489903c3c58c654aef0694e945",
            "patch": "@@ -30,6 +30,7 @@ tt.func @block_barrier_kernel(\n   // CHECK-NEXT:   %[[ADD_PTR_5:.+]] = tt.addptr %[[SPLAT_ADD_PTR_4]], %[[RANGE]]\n   // CHECK-NEXT:   triton_xla.atomic_spin_wait sys, acquire, %[[ADD_PTR_5]], less_than, %[[SIGNAL_VALUE]]\n   // CHECK-NEXT: }\n+  // CHECK-NEXT:   ttg.local_barrier\n   // CHECK-NEXT: tt.return\n   triton_xla.block_barrier %ptr, %rank, %signal_value, { world_size = 8 : i32 } :\n     (!tt.ptr<!tt.ptr<i32>>, i32, i32) -> ()"
        },
        {
            "sha": "c3f34de45d0da69405169fbece52eeab496e0ba4",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_lower_atomics_pass.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_atomics_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_atomics_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_atomics_pass.cc?ref=c2d4e93a55c7ed489903c3c58c654aef0694e945",
            "patch": "@@ -103,9 +103,11 @@ LogicalResult LowerAtomicWriteOp(AtomicWriteOp atomic_write,\n   // Even though we don't care about result($0) in this case it must be there\n   // for ElementwiseInlineAsmOp verifiers to work\n   constexpr absl::string_view kAtomicWriteAsmWithMaskTemplate = R\"(\n+    {\n     .reg .pred %%p<>;\n     setp.ne.u32 %%p<>, $3, 0;\n     @%%p st.global.%s.%s.u32 [$1], $2;\n+    }\n   )\";\n   constexpr absl::string_view kAtomicWriteAsmTemplate = R\"(\n     st.global.%s.%s.u32 [$1], $2;\n@@ -159,14 +161,17 @@ LogicalResult LowerAtomicSpinWaitOp(AtomicSpinWaitOp atomic_wait,\n \n   absl::string_view comparator = GetComparatorStr(atomic_wait.getComparator());\n   constexpr absl::string_view kAtomicSpinWaitAsmTemplate = R\"(\n+    {\n     .reg .pred %%p<1>;\n     .reg .b32 %%r<1>;\n     wait:\n       ld.global.%s.%s.u32 %%r0, [$1];\n       setp.%s.u32 %%p0, %%r0, $2;\n       @%%p0 bra wait;\n+    }\n   )\";\n   constexpr absl::string_view kAtomicSpinWaitAsmWithMaskTemplate = R\"(\n+    {\n     .reg .pred %%p<2>;\n     .reg .b32 %%r<1>;\n     setp.ne.u32 %%p0, $3, 0;\n@@ -176,6 +181,7 @@ LogicalResult LowerAtomicSpinWaitOp(AtomicSpinWaitOp atomic_wait,\n       setp.%s.u32 %%p1, %%r0, $2;\n       @%%p1 bra wait;\n     done:\n+    }\n   )\";\n   mlir::Type result_type = GetResultType(ptr.getType(), rewriter);\n   Value mask = atomic_wait.getMask();"
        },
        {
            "sha": "5d83980a13e349c7b98fccb596b3881136b13df5",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_lower_block_barrier_pass.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_block_barrier_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2d4e93a55c7ed489903c3c58c654aef0694e945/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_block_barrier_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_block_barrier_pass.cc?ref=c2d4e93a55c7ed489903c3c58c654aef0694e945",
            "patch": "@@ -31,6 +31,7 @@ limitations under the License.\n #include \"xla/backends/gpu/codegen/triton/ir/triton_xla_ops.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n #include \"triton/Dialect/Triton/IR/Types.h\"\n+#include \"triton/Dialect/TritonGPU/IR/Dialect.h\"\n \n namespace mlir::triton::xla {\n \n@@ -182,6 +183,7 @@ LogicalResult LowerBlockBarrierOp(BlockBarrierOp block_barrier,\n         // Terminate the block.\n         mlir::scf::YieldOp::create(builder);\n       });\n+  builder.create<mlir::triton::gpu::LocalBarrierOp>();\n   rewriter.eraseOp(block_barrier);\n   return success();\n }"
        }
    ],
    "stats": {
        "total": 20,
        "additions": 19,
        "deletions": 1
    }
}