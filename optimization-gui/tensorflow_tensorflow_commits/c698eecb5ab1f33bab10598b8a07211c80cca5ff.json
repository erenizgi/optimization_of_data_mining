{
    "author": "GleasonK",
    "message": "[StableHLO] Update CHLO broadcast ops to use StableHLO bounded-dynamism-aware broadcasting for type inference.\n\nPiperOrigin-RevId: 846795035",
    "sha": "c698eecb5ab1f33bab10598b8a07211c80cca5ff",
    "files": [
        {
            "sha": "71f4c67bb1848b4f8ac4f7d3aac9baee8155e052",
            "filename": "third_party/xla/third_party/stablehlo/temporary.patch",
            "status": "modified",
            "additions": 560,
            "deletions": 0,
            "changes": 560,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c698eecb5ab1f33bab10598b8a07211c80cca5ff/third_party%2Fxla%2Fthird_party%2Fstablehlo%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c698eecb5ab1f33bab10598b8a07211c80cca5ff/third_party%2Fxla%2Fthird_party%2Fstablehlo%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fstablehlo%2Ftemporary.patch?ref=c698eecb5ab1f33bab10598b8a07211c80cca5ff",
            "patch": "@@ -1 +1,561 @@\n+diff --ruN a/stablehlo/BUILD.bazel b/stablehlo/BUILD.bazel\n+--- stablehlo/BUILD.bazel\n++++ stablehlo/BUILD.bazel\n+@@ -257,6 +257,7 @@\n+         \":chlo_enums_inc_gen\",\n+         \":chlo_ops_inc_gen\",\n+         \":stablehlo_assembly_format\",\n++        \":stablehlo_broadcast_lowering\",\n+         \":stablehlo_type_inference\",\n+         \"@llvm-project//llvm:Support\",\n+         \"@llvm-project//mlir:BytecodeOpInterface\",\n+diff --ruN a/stablehlo/stablehlo/dialect/Base.cpp b/stablehlo/stablehlo/dialect/Base.cpp\n+--- stablehlo/stablehlo/dialect/Base.cpp\n++++ stablehlo/stablehlo/dialect/Base.cpp\n+@@ -25,7 +25,6 @@\n+ #include <utility>\n+ \n+ #include \"llvm/ADT/APInt.h\"\n+-#include \"llvm/ADT/Hashing.h\"\n+ #include \"llvm/ADT/STLExtras.h\"\n+ #include \"llvm/ADT/Sequence.h\"\n+ #include \"llvm/ADT/SmallVector.h\"\n+@@ -47,7 +46,6 @@\n+ #include \"mlir/Interfaces/SideEffectInterfaces.h\"\n+ #include \"mlir/Support/LLVM.h\"\n+ #include \"mlir/Support/LogicalResult.h\"\n+-#include \"mlir/Support/TypeID.h\"\n+ \n+ // Include order matters\n+ #include \"stablehlo/dialect/BaseAttrInterfaces.cpp.inc\"\n+@@ -246,7 +244,7 @@\n+   if (boundsLen != rank)\n+     return emitError() << \"Bounds length is \" << boundsLen\n+                        << \", expected to be equal to rank(\" << rank\n+-                       << \") of the tensor\";\n++                       << \") of the tensor \" << type;\n+ \n+   for (int64_t dim = 0; dim < rank; ++dim) {\n+     int64_t bound = bounds[dim];\n+@@ -254,7 +252,8 @@\n+     if (bound != ShapedType::kDynamic && dimSize != ShapedType::kDynamic)\n+       return emitError() << \"Static dimension \" << dim\n+                          << \" cannot have a bound, use ShapedType::kDynamic to \"\n+-                            \"indicate a missing bound\";\n++                            \"indicate a missing bound in tensor \"\n++                         << type;\n+   }\n+ \n+   return success();\n+diff --ruN a/stablehlo/stablehlo/dialect/Base.h b/stablehlo/stablehlo/dialect/Base.h\n+--- stablehlo/stablehlo/dialect/Base.h\n++++ stablehlo/stablehlo/dialect/Base.h\n+@@ -486,9 +486,12 @@\n+                                 inferredReturnTypes)))\n+       return failure();\n+     if (inferredReturnTypes.size() != 1) return failure();\n+-    auto inferredReturnType = dyn_cast<ShapedType>(inferredReturnTypes[0]);\n++    auto inferredReturnType =\n++        dyn_cast<RankedTensorType>(inferredReturnTypes[0]);\n+     if (!inferredReturnType) return failure();\n+-    inferredReturnShapes.push_back(inferredReturnType);\n++    inferredReturnShapes.emplace_back(inferredReturnType.getShape(),\n++                                      inferredReturnType.getElementType(),\n++                                      inferredReturnType.getEncoding());\n+     return success();\n+   }\n+ };\n+diff --ruN a/stablehlo/stablehlo/dialect/ChloOps.cpp b/stablehlo/stablehlo/dialect/ChloOps.cpp\n+--- stablehlo/stablehlo/dialect/ChloOps.cpp\n++++ stablehlo/stablehlo/dialect/ChloOps.cpp\n+@@ -19,14 +19,14 @@\n+ #include <algorithm>\n+ #include <cassert>\n+ #include <cstdint>\n+-#include <iostream>\n+ #include <iterator>\n+ #include <optional>\n+ #include <string>\n+ \n+ #include \"llvm/ADT/STLExtras.h\"\n+ #include \"llvm/ADT/SmallVector.h\"\n+-#include \"llvm/ADT/TypeSwitch.h\"\n++#include \"llvm/ADT/TypeSwitch.h\"  // IWYU pragma: keep\n++#include \"llvm/Support/ErrorHandling.h\"\n+ #include \"mlir/Dialect/Complex/IR/Complex.h\"\n+ #include \"mlir/Dialect/Traits.h\"\n+ #include \"mlir/IR/Attributes.h\"\n+@@ -51,6 +51,7 @@\n+ #include \"stablehlo/dialect/BroadcastUtils.h\"\n+ #include \"stablehlo/dialect/ChloBytecode.h\"\n+ #include \"stablehlo/dialect/TypeInference.h\"\n++#include \"stablehlo/transforms/StablehloBroadcastLowering.h\"\n+ \n+ // Include order matters\n+ #include \"stablehlo/dialect/ChloEnums.cpp.inc\"\n+@@ -104,54 +105,95 @@\n+ //===----------------------------------------------------------------------===//\n+ \n+ namespace {\n++\n++bool isStaticOrBoundedDynamicTensor(RankedTensorType type) {\n++  return type.hasStaticShape() || hlo::isBoundedDynamic(type);\n++}\n++\n+ // Gets the resulting type from a broadcast between two types.\n+-ShapedTypeComponents getBroadcastType(\n+-    Type x, Type y, Type elementType,\n+-    std::optional<ArrayRef<int64_t>> broadcastDimensionsAttr) {\n+-  auto xRanked = dyn_cast<RankedTensorType>(x);\n+-  auto yRanked = dyn_cast<RankedTensorType>(y);\n+-  if (!xRanked || !yRanked) return {elementType};\n+-\n+-  auto shapeX = xRanked.getShape();\n+-  auto shapeY = yRanked.getShape();\n+-\n+-  // If no broadcast dimensions, assume \"numpy\" broadcasting.\n+-  if (shapeX.size() == shapeY.size() || !broadcastDimensionsAttr.has_value()) {\n+-    llvm::SmallVector<int64_t, 4> outShape;\n+-    if (!mlir::OpTrait::util::getBroadcastedShape(shapeX, shapeY, outShape)) {\n++ShapedTypeComponents getNumpyBroadcastType(ArrayRef<Value> operands,\n++                                           Type elementType) {\n++  if (operands.empty())\n++    llvm::report_fatal_error(\"Called getNumpyBroadcastType with no operands\");\n++\n++  // Handle unranked tensors\n++  if (llvm::any_of(operands,\n++                   [](Value v) { return !isa<RankedTensorType>(v.getType()); }))\n++    return {elementType};\n++\n++  // All static or bounded, use bounded dynamic aware broadcasting.\n++  bool allStaticOrBounded = llvm::all_of(operands, [](Value v) {\n++    return isStaticOrBoundedDynamicTensor(cast<RankedTensorType>(v.getType()));\n++  });\n++  if (allStaticOrBounded) {\n++    Location errorLoc = operands[0].getLoc();\n++    FailureOr<stablehlo::Dimensions> outShape =\n++        stablehlo::getNumpyBroadcastShape(errorLoc, operands);\n++    if (failed(outShape)) {\n+       // Signal illegal broadcast_dimensions as unranked.\n+       return {elementType};\n+     }\n+-    return {outShape, elementType};\n+-  }\n+-\n+-  auto shapeLarge = shapeX.size() > shapeY.size() ? shapeX : shapeY;\n+-  auto shapeSmall = shapeX.size() <= shapeY.size() ? shapeX : shapeY;\n++    RankedTensorType outType =\n++        stablehlo::getRankedTensorType(*outShape, elementType);\n++    return {outType.getShape(), outType.getElementType(),\n++            outType.getEncoding()};\n++  }\n++\n++  // Fall back to non-bounded dynamic aware broadcasting\n++  // Will pick more lenient output shapes `x . ? => ?`\n++  llvm::SmallVector<int64_t, 4> outShape =\n++      llvm::to_vector(cast<RankedTensorType>(operands[0].getType()).getShape());\n++  for (Value operand : operands) {\n++    // Make a copy of current shape since `getBroadcastedShape` will modify it.\n++    llvm::SmallVector<int64_t, 4> currentShape = outShape;\n++    auto operandShape = cast<RankedTensorType>(operand.getType()).getShape();\n++    if (!mlir::OpTrait::util::getBroadcastedShape(currentShape, operandShape,\n++                                                  outShape)) {\n++      return {elementType};\n++    }\n++  }\n++  return {outShape, elementType};\n++}\n++\n++ShapedTypeComponents getBroadcastTypeWithBroadcastDimensions(\n++    Value x, Value y, Type elementType,\n++    std::optional<ArrayRef<int64_t>> broadcastDimensionsAttr) {\n++  if (!broadcastDimensionsAttr.has_value())\n++    return getNumpyBroadcastType({x, y}, elementType);\n++\n++  // Only support two operands if broadcast_dimensions is specified.\n++  auto shapeX = dyn_cast<RankedTensorType>(x.getType());\n++  auto shapeY = dyn_cast<RankedTensorType>(y.getType());\n++\n++  // Handle unranked tensors\n++  if (!shapeX || !shapeY) return {elementType};\n++\n++  auto shapeLarge = shapeX.getRank() > shapeY.getRank() ? shapeX : shapeY;\n++  auto shapeSmall = shapeX.getRank() <= shapeY.getRank() ? shapeX : shapeY;\n+ \n+   auto broadcastDimensions = broadcastDimensionsAttr.value();\n+-  if (broadcastDimensions.size() != shapeSmall.size()) {\n++  if (broadcastDimensions.size() != shapeSmall.getRank()) {\n+     // Signal illegal broadcast_dimensions as unranked.\n+     return {elementType};\n+   }\n+   llvm::SmallVector<int64_t, 4> shapeLargeFiltered;\n+-  shapeLargeFiltered.reserve(shapeSmall.size());\n++  shapeLargeFiltered.reserve(shapeSmall.getRank());\n+   for (const auto& dim : broadcastDimensions) {\n+-    if (dim >= static_cast<int64_t>(shapeLarge.size())) return {elementType};\n+-    shapeLargeFiltered.push_back(shapeLarge[dim]);\n++    if (dim >= static_cast<int64_t>(shapeLarge.getRank())) return {elementType};\n++    shapeLargeFiltered.push_back(shapeLarge.getDimSize(dim));\n+   }\n+   llvm::SmallVector<int64_t, 4> outShapeFiltered;\n+-  if (!mlir::OpTrait::util::getBroadcastedShape(shapeSmall, shapeLargeFiltered,\n+-                                                outShapeFiltered))\n++  if (!mlir::OpTrait::util::getBroadcastedShape(\n++          shapeSmall.getShape(), shapeLargeFiltered, outShapeFiltered))\n+     // Signal illegal broadcast_dimensions as unranked.\n+     return {elementType};\n+ \n+   // Update according to the broadcast dimensions.\n+-  llvm::SmallVector<int64_t, 4> outShape(shapeLarge.begin(), shapeLarge.end());\n++  llvm::SmallVector<int64_t, 4> outShape(shapeLarge.getShape());\n+   for (const auto& indexPair : llvm::enumerate(broadcastDimensions)) {\n+     auto newValue = outShapeFiltered[indexPair.index()];\n+     outShape[indexPair.value()] = newValue;\n+   }\n+-\n+   return {outShape, elementType};\n+ }\n+ \n+@@ -160,6 +202,7 @@\n+     DictionaryAttr attributes, OpaqueProperties properties,\n+     std::optional<ArrayRef<int64_t>> broadcastDimensions, Type elementType,\n+     SmallVectorImpl<ShapedTypeComponents>& inferredReturnShapes) {\n++  // Handle unranked.\n+   ShapedType lhsType = cast<ShapedType>(operands[0].getType());\n+   ShapedType rhsType = cast<ShapedType>(operands[1].getType());\n+   if (!lhsType || !rhsType ||\n+@@ -167,8 +210,8 @@\n+           lhsType.getElementType(), rhsType.getElementType()))\n+     return emitOptionalError(location, \"mismatched operand types\");\n+   if (!elementType) elementType = lhsType.getElementType();\n+-  inferredReturnShapes.push_back(\n+-      getBroadcastType(lhsType, rhsType, elementType, broadcastDimensions));\n++  inferredReturnShapes.push_back(getBroadcastTypeWithBroadcastDimensions(\n++      operands[0], operands[1], elementType, broadcastDimensions));\n+   return success();\n+ }\n+ \n+@@ -397,7 +440,6 @@\n+     DictionaryAttr, OpaqueProperties, RegionRange,\n+     SmallVectorImpl<ShapedTypeComponents>& inferredReturnShapes) {\n+   BroadcastSelectOp::Adaptor op(operands.getValues());\n+-  auto predType = cast<ShapedType>(op.getPred().getType());\n+   auto onTrueType = cast<ShapedType>(op.getOnTrue().getType());\n+   auto onFalseType = cast<ShapedType>(op.getOnFalse().getType());\n+ \n+@@ -407,12 +449,8 @@\n+   Type elementType = onTrueType.getElementType();\n+ \n+   // Compute the result shape as two binary broadcasts.\n+-  ShapedTypeComponents& components = inferredReturnShapes.emplace_back(\n+-      getBroadcastType(onTrueType, onFalseType, elementType, std::nullopt));\n+-  if (components.hasRank())\n+-    components = getBroadcastType(\n+-        RankedTensorType::get(components.getDims(), elementType), predType,\n+-        elementType, std::nullopt);\n++  inferredReturnShapes.emplace_back(\n++      getNumpyBroadcastType(llvm::to_vector(op.getOperands()), elementType));\n+   return success();\n+ }\n+ \n+diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.cpp b/stablehlo/stablehlo/dialect/StablehloOps.cpp\n+--- stablehlo/stablehlo/dialect/StablehloOps.cpp\n++++ stablehlo/stablehlo/dialect/StablehloOps.cpp\n+@@ -1569,7 +1569,8 @@\n+ void ConvertOp::build(OpBuilder& builder, OperationState& result, Value operand,\n+                       Type resultElementTy) {\n+   auto rankedTy = cast<RankedTensorType>(operand.getType());\n+-  auto resultTy = RankedTensorType::get(rankedTy.getShape(), resultElementTy);\n++  auto resultTy = RankedTensorType::get(rankedTy.getShape(), resultElementTy,\n++                                        rankedTy.getEncoding());\n+   build(builder, result, resultTy, operand);\n+ }\n+ \n+diff --ruN a/stablehlo/stablehlo/dialect/TypeInference.cpp b/stablehlo/stablehlo/dialect/TypeInference.cpp\n+--- stablehlo/stablehlo/dialect/TypeInference.cpp\n++++ stablehlo/stablehlo/dialect/TypeInference.cpp\n+@@ -2013,12 +2013,12 @@\n+     MLIRContext* context, std::optional<Location>, Value lhs,\n+     SmallVectorImpl<ShapedTypeComponents>& inferredReturnShapes) {\n+   // compare_c1\n+-  ShapedTypeComponents& components =\n+-      inferredReturnShapes.emplace_back(IntegerType::get(context, /*width=*/1));\n+-  auto argTy = cast<ShapedType>(lhs.getType());\n++  ShapedTypeComponents& components = inferredReturnShapes.emplace_back();\n++  auto argTy = cast<RankedTensorType>(lhs.getType());\n++  auto resElementTy = IntegerType::get(context, /*width=*/1);\n+   // compare_c2\n+   components =\n+-      ShapedTypeComponents(argTy.getShape(), components.getElementType());\n++      ShapedTypeComponents(argTy.getShape(), resElementTy, argTy.getEncoding());\n+   return success();\n+ }\n+ \n+@@ -2119,9 +2119,10 @@\n+ LogicalResult inferConvertOp(\n+     std::optional<Location> location, Value operand,\n+     SmallVectorImpl<ShapedTypeComponents>& inferredReturnShapes) {\n+-  auto operandType = cast<ShapedType>(operand.getType());\n++  auto operandType = cast<RankedTensorType>(operand.getType());\n+   // convert_c1\n+-  inferredReturnShapes.emplace_back(operandType.getShape());\n++  inferredReturnShapes.emplace_back(operandType.getShape(), nullptr,\n++                                    operandType.getEncoding());\n+   return success();\n+ }\n+ \n+diff --ruN a/stablehlo/stablehlo/tests/chlo/chlo_legalize_to_stablehlo.mlir b/stablehlo/stablehlo/tests/chlo/chlo_legalize_to_stablehlo.mlir\n+--- stablehlo/stablehlo/tests/chlo/chlo_legalize_to_stablehlo.mlir\n++++ stablehlo/stablehlo/tests/chlo/chlo_legalize_to_stablehlo.mlir\n+@@ -3913,6 +3913,149 @@\n+ \n+ // -----\n+ \n++!bounded_type = tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK-LABEL:   func.func @erf_inv_bounded(\n++// CHECK-SAME:      %[[ARG0:.*]]: tensor<?x16xf32, #stablehlo.bounds<16, ?>>) {\n++// CHECK:           %[[NEGATE_0:.*]] = stablehlo.negate %[[ARG0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[MULTIPLY_0:.*]] = stablehlo.multiply %[[ARG0]], %[[NEGATE_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[LOG_PLUS_ONE_0:.*]] = stablehlo.log_plus_one %[[MULTIPLY_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[NEGATE_1:.*]] = stablehlo.negate %[[LOG_PLUS_ONE_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_0:.*]] = stablehlo.constant dense<5.000000e+00> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_0:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_0]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_0:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_0:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_0]], %[[GET_DIMENSION_SIZE_0]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[COMPARE_0:.*]] = stablehlo.compare  LT, %[[NEGATE_1]], %[[SET_DIMENSION_SIZE_0]] : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<?x16xi1, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_1:.*]] = stablehlo.constant dense<2.500000e+00> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_1:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_1]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_1:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_1:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_1]], %[[GET_DIMENSION_SIZE_1]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SUBTRACT_0:.*]] = stablehlo.subtract %[[NEGATE_1]], %[[SET_DIMENSION_SIZE_1]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SQRT_0:.*]] = stablehlo.sqrt %[[NEGATE_1]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_2:.*]] = stablehlo.constant dense<3.000000e+00> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_2:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_2]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_2:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_2:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_2]], %[[GET_DIMENSION_SIZE_2]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SUBTRACT_1:.*]] = stablehlo.subtract %[[SQRT_0]], %[[SET_DIMENSION_SIZE_2]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SELECT_0:.*]] = stablehlo.select %[[COMPARE_0]], %[[SUBTRACT_0]], %[[SUBTRACT_1]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_3:.*]] = stablehlo.constant dense<2.81022636E-8> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_3:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_3]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_3:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_3:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_3]], %[[GET_DIMENSION_SIZE_3]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_4:.*]] = stablehlo.constant dense<-2.00214257E-4> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_4:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_4]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_4:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_4:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_4]], %[[GET_DIMENSION_SIZE_4]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SELECT_1:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_3]], %[[SET_DIMENSION_SIZE_4]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_5:.*]] = stablehlo.constant dense<3.43273939E-7> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_5:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_5]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_5:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_5:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_5]], %[[GET_DIMENSION_SIZE_5]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_6:.*]] = stablehlo.constant dense<1.00950558E-4> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_6:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_6]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_6:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_6:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_6]], %[[GET_DIMENSION_SIZE_6]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SELECT_2:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_5]], %[[SET_DIMENSION_SIZE_6]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[MULTIPLY_1:.*]] = stablehlo.multiply %[[SELECT_1]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[ADD_0:.*]] = stablehlo.add %[[SELECT_2]], %[[MULTIPLY_1]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_7:.*]] = stablehlo.constant dense<-3.5233877E-6> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_7:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_7]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_7:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_7:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_7]], %[[GET_DIMENSION_SIZE_7]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_8:.*]] = stablehlo.constant dense<0.00134934322> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_8:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_8]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_8:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_8:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_8]], %[[GET_DIMENSION_SIZE_8]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SELECT_3:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_7]], %[[SET_DIMENSION_SIZE_8]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[MULTIPLY_2:.*]] = stablehlo.multiply %[[ADD_0]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[ADD_1:.*]] = stablehlo.add %[[SELECT_3]], %[[MULTIPLY_2]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_9:.*]] = stablehlo.constant dense<-4.39150654E-6> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_9:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_9]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_9:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_9:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_9]], %[[GET_DIMENSION_SIZE_9]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_10:.*]] = stablehlo.constant dense<-0.00367342844> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_10:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_10]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_10:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_10:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_10]], %[[GET_DIMENSION_SIZE_10]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SELECT_4:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_9]], %[[SET_DIMENSION_SIZE_10]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[MULTIPLY_3:.*]] = stablehlo.multiply %[[ADD_1]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[ADD_2:.*]] = stablehlo.add %[[SELECT_4]], %[[MULTIPLY_3]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_11:.*]] = stablehlo.constant dense<2.1858087E-4> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_11:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_11]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_11:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_11:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_11]], %[[GET_DIMENSION_SIZE_11]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_12:.*]] = stablehlo.constant dense<0.00573950773> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_12:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_12]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_12:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_12:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_12]], %[[GET_DIMENSION_SIZE_12]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SELECT_5:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_11]], %[[SET_DIMENSION_SIZE_12]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[MULTIPLY_4:.*]] = stablehlo.multiply %[[ADD_2]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[ADD_3:.*]] = stablehlo.add %[[SELECT_5]], %[[MULTIPLY_4]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_13:.*]] = stablehlo.constant dense<-0.00125372503> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_13:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_13]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_13:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_13:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_13]], %[[GET_DIMENSION_SIZE_13]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_14:.*]] = stablehlo.constant dense<-0.0076224613> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_14:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_14]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_14:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_14:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_14]], %[[GET_DIMENSION_SIZE_14]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SELECT_6:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_13]], %[[SET_DIMENSION_SIZE_14]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[MULTIPLY_5:.*]] = stablehlo.multiply %[[ADD_3]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[ADD_4:.*]] = stablehlo.add %[[SELECT_6]], %[[MULTIPLY_5]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_15:.*]] = stablehlo.constant dense<-0.00417768164> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_15:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_15]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_15:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_15:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_15]], %[[GET_DIMENSION_SIZE_15]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_16:.*]] = stablehlo.constant dense<0.00943887047> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_16:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_16]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_16:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_16:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_16]], %[[GET_DIMENSION_SIZE_16]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SELECT_7:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_15]], %[[SET_DIMENSION_SIZE_16]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[MULTIPLY_6:.*]] = stablehlo.multiply %[[ADD_4]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[ADD_5:.*]] = stablehlo.add %[[SELECT_7]], %[[MULTIPLY_6]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_17:.*]] = stablehlo.constant dense<0.246640727> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_17:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_17]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_17:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_17:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_17]], %[[GET_DIMENSION_SIZE_17]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_18:.*]] = stablehlo.constant dense<1.00167406> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_18:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_18]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_18:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_18:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_18]], %[[GET_DIMENSION_SIZE_18]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SELECT_8:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_17]], %[[SET_DIMENSION_SIZE_18]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[MULTIPLY_7:.*]] = stablehlo.multiply %[[ADD_5]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[ADD_6:.*]] = stablehlo.add %[[SELECT_8]], %[[MULTIPLY_7]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_19:.*]] = stablehlo.constant dense<1.50140941> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_19:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_19]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_19:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_19:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_19]], %[[GET_DIMENSION_SIZE_19]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_20:.*]] = stablehlo.constant dense<2.83297682> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_20:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_20]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_20:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_20:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_20]], %[[GET_DIMENSION_SIZE_20]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SELECT_9:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_19]], %[[SET_DIMENSION_SIZE_20]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[MULTIPLY_8:.*]] = stablehlo.multiply %[[ADD_6]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[ADD_7:.*]] = stablehlo.add %[[SELECT_9]], %[[MULTIPLY_8]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[MULTIPLY_9:.*]] = stablehlo.multiply %[[ADD_7]], %[[ARG0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[ABS_0:.*]] = stablehlo.abs %[[ARG0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_21:.*]] = stablehlo.constant dense<1.000000e+00> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_21:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_21]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_21:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_21:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_21]], %[[GET_DIMENSION_SIZE_21]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[COMPARE_1:.*]] = stablehlo.compare  EQ, %[[ABS_0]], %[[SET_DIMENSION_SIZE_21]] : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<?x16xi1, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[CONSTANT_22:.*]] = stablehlo.constant dense<0x7F800000> : tensor<f32>\n++// CHECK:           %[[BROADCAST_IN_DIM_22:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_22]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>\n++// CHECK:           %[[GET_DIMENSION_SIZE_22:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>\n++// CHECK:           %[[SET_DIMENSION_SIZE_22:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_22]], %[[GET_DIMENSION_SIZE_22]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[MULTIPLY_10:.*]] = stablehlo.multiply %[[ARG0]], %[[SET_DIMENSION_SIZE_22]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           %[[SELECT_10:.*]] = stablehlo.select %[[COMPARE_1]], %[[MULTIPLY_10]], %[[MULTIPLY_9]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>\n++// CHECK:           return\n++// CHECK:         }\n++func.func @erf_inv_bounded(%arg0 : !bounded_type) {\n++  %0 = chlo.erf_inv %arg0 : !bounded_type -> !bounded_type\n++  return\n++}\n++\n++// -----\n++\n+ // CHECK-LABEL:   @square_complex_f32(\n+ // CHECK-SAME:                                  %[[VAL_0:.*]]: tensor<complex<f32>>) -> tensor<complex<f32>> {\n+ // CHECK:           %[[VAL_1:.*]] = stablehlo.real %[[VAL_0]] : (tensor<complex<f32>>) -> tensor<f32>\n+diff --ruN a/stablehlo/stablehlo/tests/infer_chlo.mlir b/stablehlo/stablehlo/tests/infer_chlo.mlir\n+--- stablehlo/stablehlo/tests/infer_chlo.mlir\n++++ stablehlo/stablehlo/tests/infer_chlo.mlir\n+@@ -239,3 +239,41 @@\n+   %r17 = \"hlo_test_infer.get_return_types\"(%17) : (tensor<2xf32>) -> tensor<2xf32>\n+   func.return %r17 : tensor<2xf32>\n+ }\n++\n++// -----\n++\n++/////\n++// Bounded dynamic\n++\n++// [<=10] x [1] => [<=10]\n++// CHECK-LABEL: @bounded_dynamic_broadcast_scalar\n++func.func @bounded_dynamic_broadcast_scalar(%arg0: tensor<?xf64, #stablehlo.bounds<10>>, %arg1: tensor<f64>) -> tensor<?xf64, #stablehlo.bounds<10>> {\n++  %0 = chlo.broadcast_add %arg0, %arg1 : (tensor<?xf64, #stablehlo.bounds<10>>, tensor<f64>) -> tensor<?xf64, #stablehlo.bounds<10>>\n++  // CHECK: types0 = tensor<?xf64, #stablehlo.bounds<10>>\n++  %1 = \"hlo_test_infer.get_return_types\"(%0) : (tensor<?xf64, #stablehlo.bounds<10>>) -> tensor<?xf64, #stablehlo.bounds<10>>\n++  return %1 : tensor<?xf64, #stablehlo.bounds<10>>\n++}\n++\n++// -----\n++\n++// [<=10] x [?] => [?]\n++// CHECK-LABEL: @bounded_dynamic_broadcast_unbounded\n++!bounded_type = tensor<?xf64, #stablehlo.bounds<10>>\n++!unbounded_type = tensor<?xf64>\n++func.func @bounded_dynamic_broadcast_unbounded(%arg0: !bounded_type, %arg1: !unbounded_type) -> !unbounded_type {\n++  %0 = chlo.broadcast_add %arg0, %arg1 : (!bounded_type, !unbounded_type) -> !unbounded_type\n++  // CHECK: types0 = tensor<?xf64>\n++  %1 = \"hlo_test_infer.get_return_types\"(%0) : (!unbounded_type) -> !unbounded_type\n++  return %1 : !unbounded_type\n++}\n++\n++// -----\n++\n++// CHECK-LABEL: @broadcast_select_types_bounded\n++!bounded_type = tensor<?xf64, #stablehlo.bounds<10>>\n++func.func @broadcast_select_types_bounded(%arg0: tensor<i1>, %arg1: !bounded_type, %arg2: !bounded_type) -> !bounded_type {\n++  %0 = \"chlo.broadcast_select\"(%arg0, %arg1, %arg2) : (tensor<i1>, !bounded_type, !bounded_type) -> !bounded_type\n++  // CHECK: types0 = tensor<?xf64, #stablehlo.bounds<10>>\n++  %1 = \"hlo_test_infer.get_return_types\"(%0) : (!bounded_type) -> !bounded_type\n++  return %1: !bounded_type\n++}\n+diff --ruN a/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp b/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp\n+--- stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp\n++++ stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp\n+@@ -92,7 +92,6 @@\n+ \n+     // If both LHS and RHS are not 1, dim size must match.\n+     if (dim_a.size != dim_b.size) {\n+-      // FIXME\n+       return emitError(op.getLoc(), \"incompatible shapes for broadcasting \")\n+              << dim_a.size << \" and \" << dim_b.size;\n+     }\n+@@ -157,11 +156,10 @@\n+   return mlir::RankedTensorType::get(shape, element_type, encoding);\n+ }\n+ \n+-FailureOr<Dimensions> getNumpyBroadcastShape(OpBuilder& builder,\n++FailureOr<Dimensions> getNumpyBroadcastShape(Location loc,\n+                                              ArrayRef<Value> ops) {\n+   if (ops.empty())\n+-    return emitError(builder.getInsertionPoint()->getLoc(),\n+-                     \"requires at least one operand to broadcast\");\n++    return emitError(loc, \"requires at least one operand to broadcast\");\n+ \n+   Value first = ops[0];\n+   auto bcastShapeOrFail = getDimensions(first);\n+@@ -197,7 +195,8 @@\n+ FailureOr<SmallVector<Value>> numpyBroadcastIfNeeded(OpBuilder& builder,\n+                                                      ArrayRef<Value> operands) {\n+   // Figure out the broadcast shape\n+-  auto bcastShapeOrFail = getNumpyBroadcastShape(builder, operands);\n++  auto errLoc = builder.getInsertionPoint()->getLoc();\n++  auto bcastShapeOrFail = getNumpyBroadcastShape(errLoc, operands);\n+   if (failed(bcastShapeOrFail)) return failure();\n+   Dimensions bcastShape = std::move(*bcastShapeOrFail);\n+ \n+diff --ruN a/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h b/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h\n+--- stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h\n++++ stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h\n+@@ -22,6 +22,7 @@\n+ #include <string>\n+ \n+ #include \"mlir/IR/Builders.h\"\n++#include \"mlir/IR/Location.h\"\n+ #include \"mlir/IR/Value.h\"\n+ #include \"mlir/Support/LLVM.h\"\n+ \n+@@ -57,8 +58,7 @@\n+ \n+ // Returns the common shape these ops would broadcast to, or an error if the\n+ // ops are not broadcastable.\n+-FailureOr<Dimensions> getNumpyBroadcastShape(OpBuilder& builder,\n+-                                             ArrayRef<Value> ops);\n++FailureOr<Dimensions> getNumpyBroadcastShape(Location loc, ArrayRef<Value> ops);\n+ \n+ // Apply numpy broadcasting to the given operands, returning an error if any\n+ // operands are not broadcastable.\n "
        }
    ],
    "stats": {
        "total": 560,
        "additions": 560,
        "deletions": 0
    }
}