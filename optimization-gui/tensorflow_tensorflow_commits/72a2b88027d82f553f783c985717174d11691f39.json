{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Prepare fusion compiler to rely more on one-shot-bufferization.\n\nI am going to rewrite the tiled lowering pipeline to start taking advantage of destintation-passing style ops & bufferization, but first I need to ensure the fusion compiler works for it.\n\nPiperOrigin-RevId: 830849292",
    "sha": "72a2b88027d82f553f783c985717174d11691f39",
    "files": [
        {
            "sha": "d11b6b4a87ffefbf15ebd02243a03f95b9eaf882",
            "filename": "third_party/xla/xla/backends/cpu/codegen/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD?ref=72a2b88027d82f553f783c985717174d11691f39",
            "patch": "@@ -213,6 +213,7 @@ cc_library(\n         \"@llvm-project//mlir:AffineTransforms\",\n         \"@llvm-project//mlir:ArithDialect\",\n         \"@llvm-project//mlir:ArithTransforms\",\n+        \"@llvm-project//mlir:BufferizationPipelines\",\n         \"@llvm-project//mlir:BufferizationTransforms\",\n         \"@llvm-project//mlir:BuiltinToLLVMIRTranslation\",\n         \"@llvm-project//mlir:ComplexToStandard\",\n@@ -224,6 +225,8 @@ cc_library(\n         \"@llvm-project//mlir:LLVMDialect\",\n         \"@llvm-project//mlir:LLVMIRTransforms\",\n         \"@llvm-project//mlir:LLVMToLLVMIRTranslation\",\n+        \"@llvm-project//mlir:LinalgDialect\",\n+        \"@llvm-project//mlir:LinalgTransforms\",\n         \"@llvm-project//mlir:MathDialect\",\n         \"@llvm-project//mlir:MathToLLVM\",\n         \"@llvm-project//mlir:MemRefToLLVM\","
        },
        {
            "sha": "919e8b0fbd8093edd3f69df72ce6d64badc53957",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 50,
            "deletions": 8,
            "changes": 58,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=72a2b88027d82f553f783c985717174d11691f39",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"xla/backends/cpu/codegen/fusion_compiler.h\"\n \n #include <cstdint>\n+#include <limits>\n #include <memory>\n #include <optional>\n #include <string>\n@@ -50,7 +51,9 @@ limitations under the License.\n #include \"mlir/Dialect/Affine/IR/AffineOps.h\"\n #include \"mlir/Dialect/Affine/Passes.h\"\n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/Arith/Transforms/BufferDeallocationOpInterfaceImpl.h\"\n #include \"mlir/Dialect/Arith/Transforms/BufferizableOpInterfaceImpl.h\"\n+#include \"mlir/Dialect/Bufferization/Pipelines/Passes.h\"\n #include \"mlir/Dialect/Bufferization/Transforms/FuncBufferizableOpInterfaceImpl.h\"\n #include \"mlir/Dialect/Bufferization/Transforms/Passes.h\"\n #include \"mlir/Dialect/ControlFlow/IR/ControlFlow.h\"\n@@ -60,9 +63,13 @@ limitations under the License.\n #include \"mlir/Dialect/LLVMIR/LLVMAttrs.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"mlir/Dialect/LLVMIR/Transforms/InlinerInterfaceImpl.h\"\n+#include \"mlir/Dialect/Linalg/IR/Linalg.h\"\n+#include \"mlir/Dialect/Linalg/Transforms/BufferizableOpInterfaceImpl.h\"\n #include \"mlir/Dialect/Math/IR/Math.h\"\n+#include \"mlir/Dialect/MemRef/Transforms/AllocationOpInterfaceImpl.h\"\n #include \"mlir/Dialect/MemRef/Transforms/Passes.h\"\n #include \"mlir/Dialect/SCF/IR/SCF.h\"\n+#include \"mlir/Dialect/SCF/Transforms/BufferDeallocationOpInterfaceImpl.h\"\n #include \"mlir/Dialect/SCF/Transforms/BufferizableOpInterfaceImpl.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/Dialect/Tensor/Transforms/BufferizableOpInterfaceImpl.h\"\n@@ -271,17 +278,35 @@ static void AddScalarLoweringPasses(mlir::OpPassManager& pm,\n   AddGenericLoweringPasses(pm);\n }\n \n+static void AddBufferizationPasses(mlir::OpPassManager& pm) {\n+  pm.addPass(mlir::createCanonicalizerPass());\n+  pm.addPass(mlir::bufferization::createEmptyTensorEliminationPass());\n+  pm.addPass(mlir::bufferization::createOneShotBufferizePass());\n+  pm.addPass(mlir::createCanonicalizerPass());\n+  pm.addPass(mlir::createCSEPass());\n+  pm.addNestedPass<mlir::func::FuncOp>(\n+      mlir::bufferization::createBufferHoistingPass());\n+  pm.addPass(mlir::memref::createFoldMemRefAliasOpsPass());\n+  mlir::bufferization::PromoteBuffersToStackPassOptions\n+      buffer_promotion_options;\n+  // We don't want any heap allocation for now.\n+  buffer_promotion_options.maxAllocSizeInBytes =\n+      std::numeric_limits<unsigned>::max();\n+  pm.addNestedPass<mlir::func::FuncOp>(\n+      mlir::bufferization::createPromoteBuffersToStackPass(\n+          buffer_promotion_options));\n+  // This shouldn't be necessary as we promote everything to the stack, but we\n+  // leave it in for now while we are experimenting.\n+  mlir::bufferization::buildBufferDeallocationPipeline(\n+      pm, mlir::bufferization::BufferDeallocationPipelineOptions());\n+}\n+\n // Optimizations passes for the tiled emitter.\n // This is currently very simple but will grow to include tiled optimizations\n // such as transpose hoisting and dimension reduction.\n static void AddTiledOptimizationPasses(mlir::OpPassManager& pm) {\n   emitters::RegisterOptimizationPasses(pm);\n-}\n \n-// Lowering passes for the tiled emitter.\n-// The input IR is from the xtile dialect which uses tensors that are converted\n-// first to the vector dialect and then to LLVM.\n-static void AddTiledLoweringPasses(mlir::OpPassManager& pm) {\n   pm.addPass(CreateShloToVectorPass());\n   pm.addPass(CreateXTileToVectorPass());\n   pm.addPass(mlir::createCanonicalizerPass());\n@@ -292,8 +317,15 @@ static void AddTiledLoweringPasses(mlir::OpPassManager& pm) {\n       mlir::vector::createLowerVectorMultiReductionPass(\n           mlir::vector::VectorMultiReductionLowering::InnerParallel));\n   pm.addPass(CreateTensorOpsToVectorPass());\n-  pm.addPass(mlir::bufferization::createOneShotBufferizePass());\n-  pm.addPass(mlir::bufferization::createOwnershipBasedBufferDeallocationPass());\n+\n+  AddBufferizationPasses(pm);\n+}\n+\n+// Lowering passes for the tiled emitter.\n+// The input IR is from the xtile dialect which uses tensors that are converted\n+// first to the vector dialect and then to LLVM.\n+static void AddTiledLoweringPasses(mlir::OpPassManager& pm) {\n+  pm.addPass(cpu::CreateMemrefCopyToLoopsPass());\n   pm.addPass(cpu::createLowerToLLVMPass());\n   pm.addPass(mlir::createConvertVectorToSCFPass(\n       mlir::VectorTransferToSCFOptions().enableFullUnroll(false)));\n@@ -479,14 +511,21 @@ mlir::DialectRegistry FusionCompiler::CreateDialectRegistry(\n       mlir::math::MathDialect, xla::cpu::XlaCpuDialect, mlir::mhlo::MhloDialect,\n       mlir::scf::SCFDialect, mlir::LLVM::LLVMDialect,\n       mlir::tensor::TensorDialect, mlir::vector::VectorDialect, xla::XlaDialect,\n-      xla::xtile::XTileDialect, mlir::stablehlo::StablehloDialect>();\n+      xla::xtile::XTileDialect, mlir::stablehlo::StablehloDialect,\n+      mlir::linalg::LinalgDialect, mlir::memref::MemRefDialect>();\n \n   mlir::LLVM::registerInlinerInterface(registry);\n   mlir::func::registerInlinerExtension(registry);\n \n+  mlir::memref::registerAllocationOpInterfaceExternalModels(registry);\n+\n+  mlir::arith::registerBufferDeallocationOpInterfaceExternalModels(registry);\n+  mlir::scf::registerBufferDeallocationOpInterfaceExternalModels(registry);\n+\n   mlir::arith::registerBufferizableOpInterfaceExternalModels(registry);\n   mlir::bufferization::func_ext::registerBufferizableOpInterfaceExternalModels(\n       registry);\n+  mlir::linalg::registerBufferizableOpInterfaceExternalModels(registry);\n   mlir::scf::registerBufferizableOpInterfaceExternalModels(registry);\n   mlir::tensor::registerBufferizableOpInterfaceExternalModels(registry);\n   mlir::vector::registerBufferizableOpInterfaceExternalModels(registry);\n@@ -506,6 +545,9 @@ mlir::DialectRegistry FusionCompiler::CreateDialectRegistry(\n         \"Test pipeline of passes up to inlining. Intended to simplify IR in \"\n         \"tests.\",\n         &xla::emitters::RegisterOptimizationPasses);\n+    RegisterPassPipeline(\"xtile-cpu-bufferization\",\n+                         \"Run the bufferization pipeline for a tiled kernel.\",\n+                         &AddBufferizationPasses);\n   }\n \n   return registry;"
        },
        {
            "sha": "314ec5265b016b287ae99654e513630fe62d1700",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2FBUILD?ref=72a2b88027d82f553f783c985717174d11691f39",
            "patch": "@@ -14,7 +14,6 @@ py_strict_test(\n     ],\n     deps = [\n         \"//third_party/py/numpy\",\n-        \"//xla:xla_data_proto_py\",\n         \"//xla/backends/cpu/testlib\",\n         \"//xla/codegen/testlib\",\n         \"@absl_py//absl/testing:absltest\","
        },
        {
            "sha": "d3fd118e05f47dbde99463cb0a78df6b782bc43b",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD?ref=72a2b88027d82f553f783c985717174d11691f39",
            "patch": "@@ -50,6 +50,7 @@ cc_library(\n     srcs = [\n         \"elemental_tensor_to_vector.cc\",\n         \"lower_xtile_entry.cc\",\n+        \"memref_copy_to_loops.cc\",\n         \"rewrite_dynamic_vector_extract.cc\",\n         \"shlo_to_vector.cc\",\n         \"tensor_ops_to_vector.cc\",\n@@ -78,6 +79,7 @@ cc_library(\n         \"@llvm-project//mlir:MathDialect\",\n         \"@llvm-project//mlir:MathOpsIncGen\",\n         \"@llvm-project//mlir:MemRefDialect\",\n+        \"@llvm-project//mlir:MemRefUtils\",\n         \"@llvm-project//mlir:Pass\",\n         \"@llvm-project//mlir:SCFDialect\",\n         \"@llvm-project//mlir:SCFUtils\","
        },
        {
            "sha": "b28434c74c4423a60e56a0b696bc9f24b56901ab",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/memref_copy_to_loops.cc",
            "status": "added",
            "additions": 141,
            "deletions": 0,
            "changes": 141,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fmemref_copy_to_loops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fmemref_copy_to_loops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fmemref_copy_to_loops.cc?ref=72a2b88027d82f553f783c985717174d11691f39",
            "patch": "@@ -0,0 +1,141 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cassert>\n+#include <cstdint>\n+#include <memory>\n+#include <utility>\n+\n+#include \"llvm/ADT/SmallVector.h\"\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"  // IWYU pragma: keep\n+#include \"mlir/Dialect/MemRef/IR/MemRef.h\"\n+#include \"mlir/Dialect/MemRef/Utils/MemRefUtils.h\"\n+#include \"mlir/Dialect/SCF/IR/SCF.h\"\n+#include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n+#include \"mlir/IR/AffineExpr.h\"\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/BuiltinTypes.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/IR/OpDefinition.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/Value.h\"\n+#include \"mlir/IR/ValueRange.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"xla/backends/cpu/codegen/tiled/transforms/passes.h\"\n+\n+namespace xla::cpu {\n+\n+#define GEN_PASS_DECL_MEMREFCOPYTOLOOPSPASS\n+#define GEN_PASS_DEF_MEMREFCOPYTOLOOPSPASS\n+#include \"xla/backends/cpu/codegen/tiled/transforms/passes.h.inc\"\n+\n+namespace {\n+\n+// Super simple lowering of memref.copies that would otherwise be lowered to a\n+// external call by the default memref lowering.\n+// TODO(willfroom): look into vectorizing these.\n+struct LowerMemRefCopyPattern\n+    : public mlir::OpRewritePattern<mlir::memref::CopyOp> {\n+  using mlir::OpRewritePattern<mlir::memref::CopyOp>::OpRewritePattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      mlir::memref::CopyOp op, mlir::PatternRewriter& rewriter) const override {\n+    mlir::Location loc = op.getLoc();\n+    auto source =\n+        mlir::cast<mlir::TypedValue<mlir::MemRefType>>(op.getSource());\n+    auto dest = mlir::cast<mlir::TypedValue<mlir::MemRefType>>(op.getTarget());\n+\n+    mlir::MemRefType src_type = source.getType();\n+    mlir::MemRefType dest_type = dest.getType();\n+\n+    // These will be lowered by the default memref -> llvm pipeline to a memcpy\n+    // intrinsic.\n+    // TODO(willfroom): We should update the default memref lowering to allow\n+    // the same layout rather than requiring identity.\n+    if (mlir::memref::isStaticShapeAndContiguousRowMajor(src_type) &&\n+        mlir::memref::isStaticShapeAndContiguousRowMajor(dest_type)) {\n+      return rewriter.notifyMatchFailure(\n+          op, \"memref.copy will be lowered to a memcpy intrinsic\");\n+    }\n+\n+    int64_t rank = src_type.getRank();\n+\n+    llvm::SmallVector<mlir::Value> lbs, ubs, steps;\n+    lbs.reserve(rank);\n+    ubs.reserve(rank);\n+    steps.reserve(rank);\n+\n+    mlir::Value c1 = mlir::arith::ConstantIndexOp::create(rewriter, loc, 1);\n+    mlir::Value c0 = mlir::arith::ConstantIndexOp::create(rewriter, loc, 0);\n+\n+    for (int64_t idx = 0; idx < rank; ++idx) {\n+      lbs.push_back(c0);\n+      steps.push_back(c1);\n+\n+      // Source & destination must have the same shape as defined by the copy op\n+      // spec so we can just extract it from the source without checking the\n+      // destination.\n+      if (src_type.isDynamicDim(idx)) {\n+        ubs.push_back(mlir::memref::DimOp::create(rewriter, loc, source, idx));\n+      } else {\n+        ubs.push_back(mlir::arith::ConstantIndexOp::create(\n+            rewriter, loc, src_type.getDimSize(idx)));\n+      }\n+    }\n+\n+    // TODO(willfroom): We should ensure that the loop order is major-to-minor.\n+    mlir::scf::buildLoopNest(\n+        rewriter, loc, lbs, ubs, steps,\n+        [source, dest](mlir::OpBuilder& builder, mlir::Location loc,\n+                       mlir::ValueRange ivs) {\n+          mlir::Value element =\n+              mlir::memref::LoadOp::create(builder, loc, source, ivs);\n+          mlir::memref::StoreOp::create(builder, loc, element, dest, ivs);\n+        });\n+\n+    rewriter.eraseOp(op);\n+    return mlir::success();\n+  }\n+};\n+\n+class MemrefCopyToLoopsPass\n+    : public impl::MemrefCopyToLoopsPassBase<MemrefCopyToLoopsPass> {\n+ public:\n+  using MemrefCopyToLoopsPassBase::MemrefCopyToLoopsPassBase;\n+\n+  void runOnOperation() override {\n+    mlir::MLIRContext* context = &getContext();\n+    mlir::RewritePatternSet patterns(context);\n+    patterns.add<LowerMemRefCopyPattern>(context);\n+    if (mlir::failed(\n+            mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {\n+      signalPassFailure();\n+      return;\n+    }\n+  }\n+};\n+\n+}  // namespace\n+\n+std::unique_ptr<mlir::Pass> CreateMemrefCopyToLoopsPass() {\n+  return std::make_unique<MemrefCopyToLoopsPass>();\n+}\n+\n+}  // namespace xla::cpu"
        },
        {
            "sha": "9392d525c09bde925fa9d380cc5c159ad1c085ad",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/passes.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h?ref=72a2b88027d82f553f783c985717174d11691f39",
            "patch": "@@ -39,6 +39,7 @@ std::unique_ptr<mlir::Pass> CreateShloToVectorPass();\n std::unique_ptr<mlir::Pass> CreateXTileToVectorPass();\n std::unique_ptr<mlir::Pass> CreateTensorOpsToVectorPass();\n std::unique_ptr<mlir::Pass> CreateRewriteDynamicVectorExtractPass();\n+std::unique_ptr<mlir::Pass> CreateMemrefCopyToLoopsPass();\n \n #define GEN_PASS_REGISTRATION\n #include \"xla/backends/cpu/codegen/tiled/transforms/passes.h.inc\""
        },
        {
            "sha": "3e39419429810007ed2d96b0906a40a71e8d70fd",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/passes.td",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td?ref=72a2b88027d82f553f783c985717174d11691f39",
            "patch": "@@ -91,3 +91,13 @@ def RewriteDynamicVectorExtractPass : Pass<\"xtile-cpu-rewrite-dynamic-vector-ext\n     \"::mlir::memref::MemRefDialect\",\n   ];\n }\n+\n+def MemrefCopyToLoopsPass : Pass<\"xtile-cpu-memref-copy-to-loops\",\n+                                 \"mlir::ModuleOp\"> {\n+  let summary = \"Rewrite mmeref.copy to loops.\";\n+\n+  let dependentDialects = [\n+    \"::mlir::scf::SCFDialect\",\n+    \"::mlir::memref::MemRefDialect\",\n+  ];\n+}"
        },
        {
            "sha": "f305ddbfb4af45ee3b71c6ab4ff9afc601abb9d2",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tests/memref_copy_to_loops.mlir",
            "status": "added",
            "additions": 31,
            "deletions": 0,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fmemref_copy_to_loops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/72a2b88027d82f553f783c985717174d11691f39/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fmemref_copy_to_loops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fmemref_copy_to_loops.mlir?ref=72a2b88027d82f553f783c985717174d11691f39",
            "patch": "@@ -0,0 +1,31 @@\n+// RUN: fusion_compiler_opt %s \\\n+// RUN: -xtile-cpu-memref-copy-to-loops -split-input-file \\\n+// RUN: | FileCheck %s\n+\n+// CHECK-LABEL: @identity_copy_is_unchanged\n+func.func @identity_copy_is_unchanged(%arg0: memref<5xi32>, %arg1: memref<5xi32>) {\n+  // CHECK: memref.copy\n+  memref.copy %arg0, %arg1 : memref<5xi32> to memref<5xi32>\n+  func.return\n+}\n+\n+\n+// CHECK-LABEL: @non_default_layout_copy_to_loops\n+func.func @non_default_layout_copy_to_loops(\n+    %arg0: memref<5x2xf32, strided<[1, 5]>>,\n+    %arg1: memref<5x2xf32>) {\n+  // CHECK-DAG: %[[C0:.*]] = arith.constant 0 : index\n+  // CHECK-DAG: %[[C1:.*]] = arith.constant 1 : index\n+  // CHECK-DAG: %[[C2:.*]] = arith.constant 2 : index\n+  // CHECK-DAG: %[[C5:.*]] = arith.constant 5 : index\n+  // CHECK: scf.for %[[IDX0:.*]] = %[[C0]] to %[[C5]] step %[[C1]] {\n+  // CHECK:   scf.for %[[IDX1:.*]] = %[[C0]] to %[[C2]] step %[[C1]] {\n+  // CHECK:     %[[ELEMENT:.*]] = memref.load %arg0[%[[IDX0]], %[[IDX1]]]\n+  // CHECK-SAME: : memref<5x2xf32, strided<[1, 5]>>\n+  // CHECK:     memref.store %[[ELEMENT]], %arg1[%[[IDX0]], %[[IDX1]]]\n+  // CHECK-SAME: : memref<5x2xf32>\n+  // CHECK:   }\n+  // CHECK: }\n+  memref.copy %arg0, %arg1 : memref<5x2xf32, strided<[1, 5]>> to memref<5x2xf32>\n+  func.return\n+}"
        }
    ],
    "stats": {
        "total": 247,
        "additions": 238,
        "deletions": 9
    }
}