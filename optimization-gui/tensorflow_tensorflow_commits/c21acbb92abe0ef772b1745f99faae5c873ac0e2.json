{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 814973322",
    "sha": "c21acbb92abe0ef772b1745f99faae5c873ac0e2",
    "files": [
        {
            "sha": "6fc4e2e2c842e2f5d824fdcd4a2f35d4bb51611d",
            "filename": "third_party/xla/xla/service/allocation_tracker.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fallocation_tracker.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fallocation_tracker.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fallocation_tracker.cc?ref=c21acbb92abe0ef772b1745f99faae5c873ac0e2",
            "patch": "@@ -40,7 +40,7 @@ namespace xla {\n \n absl::StatusOr<GlobalDataHandle> AllocationTracker::Register(\n     ScopedShapedBuffer shaped_buffer, const std::string& tag) {\n-  absl::MutexLock lock(&mutex_);\n+  absl::MutexLock lock(mutex_);\n   VLOG(2) << \"Register\";\n   std::vector<ScopedShapedBuffer> replicated_buffers;\n   replicated_buffers.emplace_back(std::move(shaped_buffer));\n@@ -50,7 +50,7 @@ absl::StatusOr<GlobalDataHandle> AllocationTracker::Register(\n absl::StatusOr<GlobalDataHandle> AllocationTracker::RegisterReplicatedBuffers(\n     std::vector<ScopedShapedBuffer> replicated_buffers,\n     const std::string& tag) {\n-  absl::MutexLock lock(&mutex_);\n+  absl::MutexLock lock(mutex_);\n   VLOG(2) << \"RegisterReplicatedBuffers\";\n   return RegisterInternal(std::move(replicated_buffers), tag);\n }\n@@ -102,7 +102,7 @@ absl::StatusOr<GlobalDataHandle> AllocationTracker::RegisterInternal(\n }\n \n absl::Status AllocationTracker::Unregister(const GlobalDataHandle& data) {\n-  absl::MutexLock lock(&mutex_);\n+  absl::MutexLock lock(mutex_);\n   VLOG(2) << \"Unregister(\"\n           << \"handle: \" << data.handle() << \")\";\n   TF_ASSIGN_OR_RETURN(std::vector<const ShapedBuffer*> replicated_buffers,\n@@ -135,7 +135,7 @@ absl::Status AllocationTracker::Unregister(const GlobalDataHandle& data) {\n \n absl::StatusOr<std::vector<GlobalDataHandle>>\n AllocationTracker::DeconstructTuple(const GlobalDataHandle& data) {\n-  absl::MutexLock lock(&mutex_);\n+  absl::MutexLock lock(mutex_);\n \n   TF_ASSIGN_OR_RETURN(std::vector<const ShapedBuffer*> replicated_buffers,\n                       ResolveInternal(data));\n@@ -173,13 +173,13 @@ AllocationTracker::DeconstructTuple(const GlobalDataHandle& data) {\n \n absl::StatusOr<std::vector<const ShapedBuffer*>> AllocationTracker::Resolve(\n     const GlobalDataHandle& data) const {\n-  absl::MutexLock lock(&mutex_);\n+  absl::MutexLock lock(mutex_);\n   return AllocationTracker::ResolveInternal(data);\n }\n \n absl::StatusOr<const ShapedBuffer*> AllocationTracker::ResolveForReplica(\n     const GlobalDataHandle& data, int replica_id) const {\n-  absl::MutexLock lock(&mutex_);\n+  absl::MutexLock lock(mutex_);\n   TF_ASSIGN_OR_RETURN(std::vector<const ShapedBuffer*> replicated_buffers,\n                       ResolveInternal(data));\n   if (replica_id >= replicated_buffers.size()) {"
        },
        {
            "sha": "7e28cea0dd93070ce163f9e64852dfae91f6b036",
            "filename": "third_party/xla/xla/service/backend.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fbackend.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fbackend.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fbackend.cc?ref=c21acbb92abe0ef772b1745f99faae5c873ac0e2",
            "patch": "@@ -121,7 +121,7 @@ absl::StatusOr<StreamPool::Ptr> Backend::BorrowStream(\n \n absl::StatusOr<StreamPool::Ptr> Backend::BorrowStream(\n     se::StreamExecutor* executor, se::StreamPriority priority) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   if (!stream_pools_.contains(executor)) {\n     stream_pools_.emplace(executor, std::make_unique<StreamPool>(executor));\n   }\n@@ -130,7 +130,7 @@ absl::StatusOr<StreamPool::Ptr> Backend::BorrowStream(\n \n absl::StatusOr<std::vector<StreamPool::Ptr>> Backend::BorrowStreams(\n     int device_ordinal, int num_streams, se::StreamPriority priority) {\n-  absl::MutexLock l(&mu_);\n+  absl::MutexLock l(mu_);\n   TF_ASSIGN_OR_RETURN(auto executor, stream_executor(device_ordinal));\n   if (!stream_pools_.contains(executor)) {\n     stream_pools_.emplace(executor, std::make_unique<StreamPool>(executor));"
        },
        {
            "sha": "d85b2af66bcc00c8e475c9b8dc6486e51477820f",
            "filename": "third_party/xla/xla/service/channel_tracker.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fchannel_tracker.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fchannel_tracker.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fchannel_tracker.cc?ref=c21acbb92abe0ef772b1745f99faae5c873ac0e2",
            "patch": "@@ -26,7 +26,7 @@ absl::StatusOr<ChannelHandle> ChannelTracker::NewChannel(\n       type != ChannelHandle::DEVICE_TO_HOST) {\n     return InvalidArgument(\"Invalid channel type: %d\", type);\n   }\n-  absl::MutexLock lock(&channel_mutex_);\n+  absl::MutexLock lock(channel_mutex_);\n \n   // Create a new channel handle with a unique value.\n   ChannelHandle new_handle;"
        },
        {
            "sha": "86ed2e59d21fc02ca1607c6f688f7ae45d63ed9a",
            "filename": "third_party/xla/xla/service/compilation_cache.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fcompilation_cache.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fcompilation_cache.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcompilation_cache.cc?ref=c21acbb92abe0ef772b1745f99faae5c873ac0e2",
            "patch": "@@ -30,7 +30,7 @@ namespace {\n int64_t GetUniqueId() {\n   static absl::Mutex mu(absl::kConstInit);\n   static int64_t counter = 0;\n-  absl::MutexLock loc(&mu);\n+  absl::MutexLock loc(mu);\n   const int64_t id = counter++;\n   return id;\n }\n@@ -39,7 +39,7 @@ int64_t GetUniqueId() {\n \n ExecutionHandle CompilationCache::Insert(\n     std::unique_ptr<Executable> executable) {\n-  absl::MutexLock lock(&mutex_);\n+  absl::MutexLock lock(mutex_);\n \n   CacheKey key = GetUniqueId();\n   VLOG(2) << \"inserting cache key: \" << key;\n@@ -53,7 +53,7 @@ ExecutionHandle CompilationCache::Insert(\n \n absl::StatusOr<std::shared_ptr<Executable>> CompilationCache::LookUp(\n     const ExecutionHandle& handle) const {\n-  absl::MutexLock lock(&mutex_);\n+  absl::MutexLock lock(mutex_);\n \n   CacheKey key = handle.handle();\n   VLOG(2) << \"looking up cache key: \" << key;"
        },
        {
            "sha": "5bf2a56c53093b34238d8dc747e5bea6821b24b9",
            "filename": "third_party/xla/xla/service/compilation_environments.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fcompilation_environments.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fcompilation_environments.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcompilation_environments.cc?ref=c21acbb92abe0ef772b1745f99faae5c873ac0e2",
            "patch": "@@ -60,7 +60,7 @@ class GlobalCompEnvStats {\n   void DefaultEnvCreatedByCompilationEnvironments(absl::string_view env_type)\n       ABSL_LOCKS_EXCLUDED(mu_) {\n     {\n-      absl::MutexLock l(&mu_);\n+      absl::MutexLock l(mu_);\n       ++stats_[std::string(env_type)]\n             .default_env_created_by_compilation_environments;\n     }\n@@ -69,14 +69,14 @@ class GlobalCompEnvStats {\n \n   void EnvAdded(absl::string_view env_type) ABSL_LOCKS_EXCLUDED(mu_) {\n     {\n-      absl::MutexLock l(&mu_);\n+      absl::MutexLock l(mu_);\n       ++stats_[std::string(env_type)].env_added;\n     }\n     VLOG(1) << \"New GlobalCompEnvStats value: \" << ToString();\n   }\n \n   std::string ToString() const ABSL_LOCKS_EXCLUDED(mu_) {\n-    absl::ReaderMutexLock l(&mu_);\n+    absl::ReaderMutexLock l(mu_);\n     return absl::StrJoin(\n         stats_, \"; \",\n         [](std::string* out, const StatMap::value_type& env_stats_pair) {\n@@ -171,7 +171,7 @@ CompilationEnvironments::CreateFromProto(\n void CompilationEnvironments::RegisterProcessNewEnvFn(\n     const tsl::protobuf::Descriptor* descriptor,\n     ProcessNewEnvFn process_new_env) {\n-  absl::MutexLock l(&process_new_env_fns_mu);\n+  absl::MutexLock l(process_new_env_fns_mu);\n   if (process_new_env_fns == nullptr) {\n     process_new_env_fns =\n         new absl::flat_hash_map<const tsl::protobuf::Descriptor*,\n@@ -187,7 +187,7 @@ void CompilationEnvironments::RegisterProcessNewEnvFn(\n absl::Status CompilationEnvironments::InitializeAllKnownEnvs() {\n   std::vector<const tsl::protobuf::Descriptor*> descriptors;\n   {\n-    absl::MutexLock l(&process_new_env_fns_mu);\n+    absl::MutexLock l(process_new_env_fns_mu);\n     if (process_new_env_fns == nullptr) {\n       return absl::OkStatus();\n     }\n@@ -240,7 +240,7 @@ CompilationEnvironmentsProto CompilationEnvironments::ToProto() const {\n CompilationEnvironments::ProcessNewEnvFn\n CompilationEnvironments::GetProcessNewEnvFn(\n     const tsl::protobuf::Descriptor& descriptor) {\n-  absl::MutexLock l(&process_new_env_fns_mu);\n+  absl::MutexLock l(process_new_env_fns_mu);\n   if (process_new_env_fns == nullptr) {\n     return nullptr;\n   }"
        },
        {
            "sha": "7e64e0cb444fe26ef40bbbbd8bfbb2ea6662041c",
            "filename": "third_party/xla/xla/service/compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcompiler.cc?ref=c21acbb92abe0ef772b1745f99faae5c873ac0e2",
            "patch": "@@ -130,7 +130,7 @@ Compiler::GetPlatformCompilers() {\n \n /* static */ void Compiler::RegisterCompilerFactory(\n     se::Platform::Id platform_id, CompilerFactory compiler_factory) {\n-  absl::MutexLock lock(&platform_compiler_mutex_);\n+  absl::MutexLock lock(platform_compiler_mutex_);\n   auto* factories = GetPlatformCompilerFactories();\n   CHECK(factories->find(platform_id) == factories->end())\n       << \"Compiler factory already registered for platform\";\n@@ -139,7 +139,7 @@ Compiler::GetPlatformCompilers() {\n \n /* static */ absl::StatusOr<std::unique_ptr<Compiler>> Compiler::GetForPlatform(\n     const se::Platform* platform) {\n-  absl::MutexLock lock(&platform_compiler_mutex_);\n+  absl::MutexLock lock(platform_compiler_mutex_);\n \n   auto* factories = GetPlatformCompilerFactories();\n   auto it = factories->find(platform->id());"
        },
        {
            "sha": "65f9b0f652549627213bfe3bf37b5131ce106909",
            "filename": "third_party/xla/xla/service/computation_placer.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fcomputation_placer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fcomputation_placer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcomputation_placer.cc?ref=c21acbb92abe0ef772b1745f99faae5c873ac0e2",
            "patch": "@@ -178,7 +178,7 @@ PlacerFactoryMap& GetPlatformComputationPlacers() {\n /* static */\n void ComputationPlacer::RegisterComputationPlacer(\n     se::Platform::Id id, CreationFunction creation_function) {\n-  absl::MutexLock lock(&placer_mutex);\n+  absl::MutexLock lock(placer_mutex);\n   PlacerFactoryMap& placers = GetPlatformComputationPlacers();\n   if (placers.find(id) != placers.end()) {\n     LOG(WARNING) << \"Computation placer creation function is already \"\n@@ -190,7 +190,7 @@ void ComputationPlacer::RegisterComputationPlacer(\n /* static */\n absl::StatusOr<ComputationPlacer*> ComputationPlacer::GetForPlatform(\n     const se::Platform* platform) {\n-  absl::MutexLock lock(&placer_mutex);\n+  absl::MutexLock lock(placer_mutex);\n   PlacerFactoryMap& placers = GetPlatformComputationPlacers();\n \n   auto it = placers.find(platform->id());"
        },
        {
            "sha": "20d29f80276ebced8d5896bad832060305e65d4b",
            "filename": "third_party/xla/xla/service/custom_call_sharding_helper.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fcustom_call_sharding_helper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fcustom_call_sharding_helper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcustom_call_sharding_helper.cc?ref=c21acbb92abe0ef772b1745f99faae5c873ac0e2",
            "patch": "@@ -65,7 +65,7 @@ ABSL_CONST_INIT absl::Mutex partitioners_mutex(absl::kConstInit);\n \n const CustomCallPartitioner* GetCustomCallPartitioner(\n     const std::string& custom_call_target) {\n-  absl::MutexLock partitioners_lock(&partitioners_mutex);\n+  absl::MutexLock partitioners_lock(partitioners_mutex);\n   auto& partitioners = GetPartitioners();\n   auto it = partitioners.find(custom_call_target);\n   if (it == partitioners.end()) {\n@@ -77,7 +77,7 @@ const CustomCallPartitioner* GetCustomCallPartitioner(\n void RegisterCustomCallPartitioner(\n     absl::string_view custom_call_target,\n     std::unique_ptr<CustomCallPartitioner> partitioner) {\n-  absl::MutexLock partitioners_lock(&partitioners_mutex);\n+  absl::MutexLock partitioners_lock(partitioners_mutex);\n   auto& partitioners = GetPartitioners();\n   // Warn if something has already been registered. We prefer to keep the\n   // existing object as other threads are more likely to observe it."
        },
        {
            "sha": "6c6bc382e6c46394ec3e8b8cfd3c15e9c5bcb866",
            "filename": "third_party/xla/xla/service/dump.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fdump.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fdump.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fdump.cc?ref=c21acbb92abe0ef772b1745f99faae5c873ac0e2",
            "patch": "@@ -99,7 +99,7 @@ static auto& module_id_to_timestamp ABSL_GUARDED_BY(mu) =\n     *new absl::flat_hash_map<int64_t, uint64_t>();\n \n int64_t StepNumberForModule(const HloModule& module) {\n-  absl::MutexLock lock(&mu);\n+  absl::MutexLock lock(mu);\n   return module_id_to_step_number[module.unique_id()]++;\n }\n \n@@ -367,7 +367,7 @@ static std::optional<std::string> GetDumpFilePath(\n \n   // Make sure we are not going to dump more modules than the user has asked.\n   if (opts.dump_max_hlo_modules > 0) {\n-    absl::MutexLock lock(&mu);\n+    absl::MutexLock lock(mu);\n     if (module_id_to_timestamp.size() >= opts.dump_max_hlo_modules) {\n       LOG(ERROR) << \"Have already dumped \" << module_id_to_timestamp.size()\n                  << \" modules, more than the limit of \"\n@@ -424,7 +424,7 @@ static std::optional<std::string> DumpToFileInDirOrStdoutImpl(\n     const CanonicalDebugOptions& opts) {\n   // Dump to stdout if that's called for.\n   if (opts.dumping_to_stdout()) {\n-    absl::MutexLock lock(&stdout_dump_mutex);\n+    absl::MutexLock lock(stdout_dump_mutex);\n     std::cout << \"*** Begin \" << filename << \" ***\\n\"\n               << contents << \"\\n*** End \" << filename << \" ***\" << std::endl;\n     return std::nullopt;\n@@ -439,7 +439,7 @@ static std::optional<std::string> DumpToFileInDirOrStdoutImpl(\n     const CanonicalDebugOptions& opts) {\n   // Dump to stdout if that's called for.\n   if (opts.dumping_to_stdout()) {\n-    absl::MutexLock lock(&stdout_dump_mutex);\n+    absl::MutexLock lock(stdout_dump_mutex);\n     std::cout << \"*** Begin \" << filename << \" ***\\n\";\n     while (auto next_producer = data_producer.Next()) {\n       std::cout << next_producer();\n@@ -582,7 +582,7 @@ static std::vector<std::string> DumpHloModuleImpl(\n     LOG_FIRST_N(INFO, 1) << \"HloModule dump enabled with path prefix: \"\n                          << prefix << \", suffix: \" << suffix;\n     if (opts.dump_max_hlo_modules > 0) {\n-      absl::MutexLock lock(&mu);\n+      absl::MutexLock lock(mu);\n       // Try to record the time we dumped this module to keep track of total\n       // module count.\n       module_id_to_timestamp.try_emplace(module.unique_id(),\n@@ -643,7 +643,7 @@ std::string TimestampFor(const HloModule& module,\n   if (!opts.xla_dump_include_timestamp()) {\n     return \"\";\n   }\n-  absl::MutexLock lock(&mu);\n+  absl::MutexLock lock(mu);\n   auto timestamp_emplace = module_id_to_timestamp.try_emplace(\n       module.unique_id(), tsl::Env::Default()->NowMicros());\n   return std::to_string(timestamp_emplace.first->second);\n@@ -1056,7 +1056,7 @@ void DumpHloSnapshotIfEnabled(const HloModule& module,\n   {\n     static auto& module_id_to_execution_count ABSL_GUARDED_BY(mu) =\n         *new absl::flat_hash_map<int64_t, int64_t>();\n-    absl::MutexLock lock(&mu);\n+    absl::MutexLock lock(mu);\n     execution_count = module_id_to_execution_count[module.unique_id()]++;\n     auto timestamp_emplace = module_id_to_timestamp.try_emplace(\n         module.unique_id(), tsl::Env::Default()->NowMicros());\n@@ -1093,7 +1093,7 @@ void DumpHloSnapshotIfEnabled(const HloSnapshot& snapshot,\n   {\n     static auto& module_name_to_execution_count ABSL_GUARDED_BY(mu) =\n         *new absl::flat_hash_map<std::string, int64_t>();\n-    absl::MutexLock lock(&mu);\n+    absl::MutexLock lock(mu);\n     execution_count = module_name_to_execution_count[name]++;\n   }\n   std::string filename = StrFormat(\"module_%s.execution_%04d.hlo_snapshot.pb\",\n@@ -1128,7 +1128,7 @@ void DumpHloUnoptimizedSnapshotIfEnabled(\n     static absl::Mutex mu(absl::kConstInit);\n     static auto& module_id_to_execution_count ABSL_GUARDED_BY(mu) =\n         *new absl::flat_hash_map<int64_t, int64_t>();\n-    absl::MutexLock lock(&mu);\n+    absl::MutexLock lock(mu);\n     execution_count =\n         module_id_to_execution_count[hlo_snapshot.hlo_module().id()]++;\n   }"
        },
        {
            "sha": "4dfb0179c94c8fe98809fe0da87c1c499a4a42b6",
            "filename": "third_party/xla/xla/service/executable.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h?ref=c21acbb92abe0ef772b1745f99faae5c873ac0e2",
            "patch": "@@ -400,7 +400,7 @@ class Executable {\n     // Since both `hlo_proto()` and `buffer_assignment_proto()` return a\n     // pointer to hlo_proto_, having the mutex is not enough to make this\n     // function thread-safe.\n-    absl::MutexLock lock(&hlo_proto_mutex_);\n+    absl::MutexLock lock(hlo_proto_mutex_);\n     hlo_proto_ = std::move(hlo_proto);\n   }\n   bool dumping_snapshot() const {\n@@ -410,15 +410,15 @@ class Executable {\n   }\n \n   HloProto const* hlo_proto() const {\n-    absl::MutexLock lock(&hlo_proto_mutex_);\n+    absl::MutexLock lock(hlo_proto_mutex_);\n     if (hlo_proto_ != nullptr && !hlo_proto_->has_hlo_module()) {\n       *hlo_proto_->mutable_hlo_module() = module().ToProto();\n     }\n     return hlo_proto_.get();\n   }\n \n   const BufferAssignmentProto* buffer_assignment_proto() const {\n-    absl::MutexLock lock(&hlo_proto_mutex_);\n+    absl::MutexLock lock(hlo_proto_mutex_);\n     return hlo_proto_ != nullptr && hlo_proto_->has_buffer_assignment()\n                ? &hlo_proto_->buffer_assignment()\n                : nullptr;"
        },
        {
            "sha": "58534fd751547b5bba8fc776070e21fc8fcffe45",
            "filename": "third_party/xla/xla/service/execution_tracker.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fexecution_tracker.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c21acbb92abe0ef772b1745f99faae5c873ac0e2/third_party%2Fxla%2Fxla%2Fservice%2Fexecution_tracker.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fexecution_tracker.cc?ref=c21acbb92abe0ef772b1745f99faae5c873ac0e2",
            "patch": "@@ -50,7 +50,7 @@ ExecutionHandle ExecutionTracker::Register(Backend* backend,\n                                            std::vector<StreamPool::Ptr> streams,\n                                            const ExecutionProfile& profile,\n                                            GlobalDataHandle result) {\n-  absl::MutexLock lock(&execution_mutex_);\n+  absl::MutexLock lock(execution_mutex_);\n   int64_t handle = next_handle_++;\n   auto inserted = handle_to_execution_.emplace(\n       handle, std::make_unique<AsyncExecution>(backend, std::move(streams),\n@@ -63,7 +63,7 @@ ExecutionHandle ExecutionTracker::Register(Backend* backend,\n }\n \n absl::Status ExecutionTracker::Unregister(const ExecutionHandle& handle) {\n-  absl::MutexLock lock(&execution_mutex_);\n+  absl::MutexLock lock(execution_mutex_);\n   auto it = handle_to_execution_.find(handle.handle());\n   if (it == handle_to_execution_.end()) {\n     return NotFound(\"no execution record for execution handle: %d\",\n@@ -75,7 +75,7 @@ absl::Status ExecutionTracker::Unregister(const ExecutionHandle& handle) {\n \n absl::StatusOr<const AsyncExecution*> ExecutionTracker::Resolve(\n     const ExecutionHandle& handle) {\n-  absl::MutexLock lock(&execution_mutex_);\n+  absl::MutexLock lock(execution_mutex_);\n   auto it = handle_to_execution_.find(handle.handle());\n   if (it == handle_to_execution_.end()) {\n     return NotFound(\"no execution record for execution handle: %d\","
        }
    ],
    "stats": {
        "total": 78,
        "additions": 39,
        "deletions": 39
    }
}