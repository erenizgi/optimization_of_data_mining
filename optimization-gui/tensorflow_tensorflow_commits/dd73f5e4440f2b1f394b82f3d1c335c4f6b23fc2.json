{
    "author": "olegshyshkov",
    "message": "[XLA:GPU] Support arbitrary replica groups in RaggedAllToAlMultiHostDecomposer.\n\nThis change lifts the original restriction that ra2a should have only one iota replica group.\n\nPiperOrigin-RevId: 818996017",
    "sha": "dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2",
    "files": [
        {
            "sha": "6f9f6d22e5390b1218de209b2d9c98526a58f5ec",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2",
            "patch": "@@ -3220,6 +3220,7 @@ cc_library(\n         \"//xla/hlo/utils:hlo_query\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n@@ -3242,7 +3243,6 @@ xla_cc_test(\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n-        \"@com_google_absl//absl/log\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )"
        },
        {
            "sha": "f024681c9bd8670aa0bbbd69813521f5e5af8ba8",
            "filename": "third_party/xla/xla/service/gpu/transforms/ragged_all_to_all_multi_host_decomposer.cc",
            "status": "modified",
            "additions": 45,
            "deletions": 34,
            "changes": 79,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fragged_all_to_all_multi_host_decomposer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fragged_all_to_all_multi_host_decomposer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fragged_all_to_all_multi_host_decomposer.cc?ref=dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2",
            "patch": "@@ -16,9 +16,11 @@ limitations under the License.\n #include \"xla/service/gpu/transforms/ragged_all_to_all_multi_host_decomposer.h\"\n \n #include <cstdint>\n+#include <iterator>\n #include <optional>\n #include <vector>\n \n+#include \"absl/algorithm/container.h\"\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n@@ -54,16 +56,20 @@ using hlo_query::NextChannelId;\n HloInstruction* GetIntraHostMetadata(\n     HloRaggedAllToAllInstruction* ragged_all_to_all,\n     HloInstruction* metadata_operand, HloComputation* computation,\n-    const std::vector<ReplicaGroup>& replica_groups,\n-    int64_t num_updates_per_replica, int64_t fast_interconnect_slice_size,\n-    int64_t num_hosts, bool correct_offsets) {\n+    const std::vector<ReplicaGroup>& replica_groups, int64_t num_hosts,\n+    int64_t num_devices_in_replica, bool correct_offsets) {\n+  int64_t num_devices_in_replica_per_host = num_devices_in_replica / num_hosts;\n+\n+  int64_t num_updates_per_replica =\n+      metadata_operand->shape().dimensions(0) / num_devices_in_replica;\n+\n   Shape new_metadata_shape = ShapeUtil::MakeShape(\n       metadata_operand->shape().element_type(),\n-      {num_hosts, fast_interconnect_slice_size, num_updates_per_replica});\n+      {num_hosts, num_devices_in_replica_per_host, num_updates_per_replica});\n \n   Shape new_metadata_transposed_shape = ShapeUtil::MakeShape(\n       metadata_operand->shape().element_type(),\n-      {fast_interconnect_slice_size, num_hosts, num_updates_per_replica});\n+      {num_devices_in_replica_per_host, num_hosts, num_updates_per_replica});\n \n   HloInstruction* new_input_offsets = computation->AddInstruction(\n       HloInstruction::CreateReshape(new_metadata_shape, metadata_operand));\n@@ -129,11 +135,6 @@ absl::StatusOr<bool> DecomposeRaggedAllToAll(\n \n   auto replica_groups = ragged_all_to_all->replica_groups();\n \n-  // TODO(b/445380264): Support multiple replica groups.\n-  if (replica_groups.size() > 1) {\n-    return false;\n-  }\n-\n   // Replica groups can be empty in collective instruction. Empty replica groups\n   // mean that all devices are participating in the collective. This semantics\n   // is hard to handle in an HLO pass, because we don't have enough information\n@@ -144,18 +145,7 @@ absl::StatusOr<bool> DecomposeRaggedAllToAll(\n     return false;\n   }\n \n-  const auto& replica_ids = replica_groups[0].replica_ids();\n-\n-  for (int i = 0; i < replica_ids.size(); ++i) {\n-    if (i != replica_ids[i]) {\n-      return false;\n-    }\n-  }\n-\n-  HloInstruction* input_offsets = ragged_all_to_all->mutable_operand(2);\n-\n-  int64_t num_updates_per_replica =\n-      input_offsets->shape().dimensions(0) / replica_ids.size();\n+  int64_t num_devices_in_replica = replica_groups[0].replica_ids_size();\n \n   int64_t num_participating_devices = 0;\n   for (auto& replica_group : replica_groups) {\n@@ -175,18 +165,39 @@ absl::StatusOr<bool> DecomposeRaggedAllToAll(\n     return false;\n   }\n \n-  std::vector<ReplicaGroup> inter_host_replica_groups(\n-      fast_interconnect_slice_size);\n-  std::vector<ReplicaGroup> intra_host_replica_groups(num_hosts);\n+  // Decompose the replica groups into inter-host and intra-host replica groups.\n+  // For example, if the original replica groups were:\n+  //   {{0, 2, 4, 6, 8, 10, 12, 14}, {1, 3, 5, 7, 9, 11, 13, 15}}\n+  // Then the inter-host replica groups would be:\n+  //   {{0, 8}, {2, 10}, {4, 12}, {6, 14}, {1, 9}, {3, 11}, {5, 13}, {7, 15}}}\n+  // And the intra-host replica groups would be:\n+  //   {{0, 2, 4, 6}, {8, 10, 12, 14}, {1, 3, 5, 7}, {9, 11, 13, 15}}\n+  std::vector<ReplicaGroup> intra_host_replica_groups;\n+  std::vector<ReplicaGroup> inter_host_replica_groups;\n+\n+  for (const auto& replica_group : replica_groups) {\n+    std::vector<ReplicaGroup> intra_host_replica_group_split(num_hosts);\n+    for (int64_t replica_id : replica_group.replica_ids()) {\n+      int64_t host_id = replica_id / fast_interconnect_slice_size;\n+\n+      intra_host_replica_group_split[host_id].add_replica_ids(replica_id);\n+    }\n+\n+    absl::c_copy(intra_host_replica_group_split,\n+                 std::back_inserter(intra_host_replica_groups));\n+\n+    for (int64_t i = 0;\n+         i < intra_host_replica_group_split[0].replica_ids_size(); ++i) {\n+      ReplicaGroup inter_host_replica_group;\n \n-  for (int i = 0; i < fast_interconnect_slice_size; ++i) {\n-    inter_host_replica_groups[i].add_replica_ids(i);\n-    inter_host_replica_groups[i].add_replica_ids(fast_interconnect_slice_size +\n-                                                 i);\n+      inter_host_replica_group.mutable_replica_ids()->Reserve(num_hosts);\n+      for (int64_t host_id = 0; host_id < num_hosts; ++host_id) {\n+        inter_host_replica_group.add_replica_ids(\n+            intra_host_replica_group_split[host_id].replica_ids(i));\n+      }\n \n-    intra_host_replica_groups[0].add_replica_ids(i);\n-    intra_host_replica_groups[1].add_replica_ids(fast_interconnect_slice_size +\n-                                                 i);\n+      inter_host_replica_groups.push_back(inter_host_replica_group);\n+    }\n   }\n \n   std::vector<HloInstruction*> intra_host_metadata;\n@@ -220,8 +231,8 @@ absl::StatusOr<bool> DecomposeRaggedAllToAll(\n   for (int i = 2; i < 6; ++i) {\n     intra_host_metadata.push_back(GetIntraHostMetadata(\n         ragged_all_to_all, ragged_all_to_all->mutable_operand(i), computation,\n-        inter_host_replica_groups, num_updates_per_replica,\n-        fast_interconnect_slice_size, num_hosts, /*correct_offsets=*/i == 2));\n+        inter_host_replica_groups, num_hosts, num_devices_in_replica,\n+        /*correct_offsets=*/i == 2));\n   }\n \n   HloInstruction* new_ragged_all_to_all ="
        },
        {
            "sha": "706b3bc3ffea7be1cad280e87d8cf9a880261468",
            "filename": "third_party/xla/xla/service/gpu/transforms/ragged_all_to_all_multi_host_decomposer_test.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 4,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fragged_all_to_all_multi_host_decomposer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fragged_all_to_all_multi_host_decomposer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fragged_all_to_all_multi_host_decomposer_test.cc?ref=dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2",
            "patch": "@@ -124,7 +124,7 @@ ENTRY main {\n   EXPECT_FALSE(changed);\n }\n \n-TEST_F(RaggedAllToAllDecomposerTest, MultipleReplicaGroupsAreNotSupported) {\n+TEST_F(RaggedAllToAllDecomposerTest, MultipleReplicaGroupsAreSupported) {\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(R\"(\n HloModule module\n \n@@ -137,14 +137,24 @@ ENTRY main {\n     recv_sizes = s64[8] parameter(5)\n     ROOT ra2a = bf16[256] ragged-all-to-all(input, output, input_offsets,\n       send_sizes, output_offsets, recv_sizes),\n-      replica_groups={{0,1,2,3,4,5,6,7},{8,9,10,11,12,13,14,15}}\n+      replica_groups={{0,2,4,6,8,10,12,14},{1,3,5,7,9,11,13,15}}\n }\n )\"));\n \n   RaggedAllToAllMultiHostDecomposer decomposer(\n-      /*fast_interconnect_slice_size=*/4);\n+      /*fast_interconnect_slice_size=*/8);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, decomposer.Run(module.get(), {}));\n-  EXPECT_FALSE(changed);\n+  EXPECT_TRUE(changed);\n+\n+  TF_EXPECT_OK(VerifyHloModule(module.get(), true, true));\n+  TF_EXPECT_OK(HloDCE().Run(module.get()));\n+  TF_EXPECT_OK(HloCSE(true).Run(module.get()));\n+\n+  EXPECT_TRUE(*RunFileCheck(module->ToString(), R\"(\n+    // CHECK: all-gather{{.*}}, replica_groups={{[{]}}{0,8},{2,10},{4,12},{6,14},{1,9},{3,11},{5,13},{7,15}{{[}]}}\n+    // CHECK-COUNT-4: all-to-all{{.*}}, replica_groups={{[{]}}{0,8},{2,10},{4,12},{6,14},{1,9},{3,11},{5,13},{7,15}{{[}]}}\n+    // CHECK: ragged-all-to-all{{.*}}, replica_groups={{[{]}}{0,2,4,6},{8,10,12,14},{1,3,5,7},{9,11,13,15}{{[}]}}\n+  )\"));\n }\n \n TEST_F(RaggedAllToAllDecomposerTest, OnlyDecompositionForTwoHostsIsSupported) {"
        },
        {
            "sha": "f82e599a9fceb691d3f0640f2ce785b5314bf122",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test.cc",
            "status": "modified",
            "additions": 55,
            "deletions": 0,
            "changes": 55,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc?ref=dd73f5e4440f2b1f394b82f3d1c335c4f6b23fc2",
            "patch": "@@ -3668,6 +3668,61 @@ TEST_F(RaggedAllToAllMultiHostDecomposerTest, RaggedAllToAll_8GPUs_SliceSize4) {\n   }\n }\n \n+TEST_F(RaggedAllToAllMultiHostDecomposerTest,\n+       RaggedAllToAll_8GPUs_SliceSize4_2ReplicaGroups) {\n+  absl::string_view kModuleReplicatedStr = R\"(\n+  HloModule module, num_partitions=1\n+\n+  ENTRY entry {\n+    input = f32[512,5,32] parameter(0)\n+    output = f32[512,5,32] parameter(1)\n+    input_offsets = s32[32] parameter(2)\n+    send_sizes = s32[32] parameter(3)\n+    output_offsets = s32[32] parameter(4)\n+    recv_sizes = s32[32] parameter(5)\n+    ROOT ra2a = f32[512,5,32] ragged-all-to-all(input, output,\n+      input_offsets, send_sizes, output_offsets, recv_sizes), \n+      replica_groups={{0,2,4,6},{1,3,5,7}}\n+  })\";\n+\n+  const int64_t kNumReplicas = 8;\n+  const int64_t kNumReplicasPerGroup = 4;\n+  const int64_t kNumPartitions = 1;\n+  const int64_t kNumUpdatesPerReplica = 8;\n+  if (hlo_runner_->device_count() < kNumReplicas * kNumPartitions) {\n+    GTEST_SKIP() << \"Test requires at least \" << kNumReplicas * kNumPartitions\n+                 << \" devices (\" << hlo_runner_->device_count()\n+                 << \" available)\";\n+  }\n+\n+  HloModuleConfig config =\n+      GetModuleConfigForTest(/*replica_count=*/kNumReplicas * kNumPartitions);\n+\n+  config.mutable_debug_options()\n+      .set_xla_gpu_unsupported_override_fast_interconnect_slice_size(4);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto module, ParseAndReturnVerifiedModule(kModuleReplicatedStr, config));\n+\n+  Array<int64_t> input_sizes(\n+      {kNumReplicas, kNumReplicasPerGroup, kNumUpdatesPerReplica});\n+  input_sizes.FillRandomUniform(0, 10);\n+\n+  TF_ASSERT_OK(CreateRandomTestData(module.get(), input_sizes));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::vector<Literal> results,\n+      ExecuteReplicated(std::move(module), GetInputLiteralPtrs(),\n+                        /*device_assignment=*/nullptr,\n+                        /*num_replicas=*/kNumReplicas,\n+                        /*run_hlo_passes=*/true));\n+  ASSERT_EQ(results.size(), kNumReplicas);\n+\n+  for (int i = 0; i < kNumReplicas; ++i) {\n+    EXPECT_TRUE(LiteralTestUtil::Equal(expected_outputs_[i], results[i]));\n+  }\n+}\n+\n TEST_F(CollectiveOpsTestE2E, MemcpyP2pWhileLoopCorrectness) {\n   absl::string_view hlo_string = R\"(\n HloModule MemcpyP2pWhileLoopCorrectness, entry_computation_layout={(bf16[128,96]{1,0})->(bf16[32,384]{1,0}, bf16[32,384]{1,0})}, allow_spmd_sharding_propagation_to_output={true,true}, num_partitions=4"
        }
    ],
    "stats": {
        "total": 154,
        "additions": 115,
        "deletions": 39
    }
}