{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 845648967",
    "sha": "c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
    "files": [
        {
            "sha": "495743c8d64c0cb7e68376e4c96cb205efd40c4c",
            "filename": "tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fbase_rendezvous_mgr.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fbase_rendezvous_mgr.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fbase_rendezvous_mgr.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -257,9 +257,10 @@ void BaseRemoteRendezvous::SameWorkerRecvDone(\n                           recv_args.alloc_attrs.gpu_compatible());\n   Allocator* out_allocator = dst_device->GetAllocator(attr);\n   AllocationAttributes allocation_attr;\n-  uint64 safe_alloc_frontier = dst_device->SafeAllocFrontier(0);\n+  uint64_t safe_alloc_frontier = dst_device->SafeAllocFrontier(0);\n   bool sync_dst_compute = (safe_alloc_frontier == 0);\n-  std::function<uint64()> freed_by_func = [dst_device, &safe_alloc_frontier]() {\n+  std::function<uint64_t()> freed_by_func = [dst_device,\n+                                             &safe_alloc_frontier]() {\n     safe_alloc_frontier = dst_device->SafeAllocFrontier(safe_alloc_frontier);\n     return safe_alloc_frontier;\n   };"
        },
        {
            "sha": "3a2691b7cff22f47f749b501bd3625e4f535abcb",
            "filename": "tensorflow/core/distributed_runtime/cancellable_call.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcancellable_call.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcancellable_call.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fcancellable_call.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -27,8 +27,8 @@ namespace tensorflow {\n // registration with a CancellationManager.\n class CancellableCall {\n  public:\n-  CancellableCall(CancellationManager* cancel_mgr, const string& remote_worker,\n-                  WorkerCacheInterface* wc)\n+  CancellableCall(CancellationManager* cancel_mgr,\n+                  const std::string& remote_worker, WorkerCacheInterface* wc)\n       : is_cancelled_(false),\n         cancel_mgr_(cancel_mgr),\n         remote_worker_(remote_worker),\n@@ -51,7 +51,7 @@ class CancellableCall {\n   mutex mu_;\n   bool is_cancelled_;\n   CancellationManager* const cancel_mgr_;  // Not owned\n-  const string remote_worker_;\n+  const std::string remote_worker_;\n   WorkerCacheInterface* const wc_;  // Not owned\n   WorkerInterface* const wi_;       // Owned by wc_, must be released.\n   CallOptions opts_;"
        },
        {
            "sha": "c974bb4c520655fe1e889e5dbb87c732fddeb51f",
            "filename": "tensorflow/core/distributed_runtime/cluster_function_library_runtime.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 12,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcluster_function_library_runtime.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcluster_function_library_runtime.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fcluster_function_library_runtime.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -39,9 +39,9 @@ absl::Status ClusterFunctionLibraryRuntime::ConstructFunctionGraph(\n     const OpDef& sig, AttrSlice attrs,\n     const FunctionLibraryRuntime::InstantiateOptions& options,\n     const FunctionLibraryDefinition& flib_def, GraphDef* gdef,\n-    std::vector<string>* send_keys, std::vector<string>* recv_keys) {\n-  const string& target = options.target;\n-  const string& func_name = sig.name();\n+    std::vector<std::string>* send_keys, std::vector<std::string>* recv_keys) {\n+  const std::string& target = options.target;\n+  const std::string& func_name = sig.name();\n   const FunctionDef* func_def = flib_def.Find(sig.name());\n   if (func_def == nullptr) {\n     return errors::InvalidArgument(\"Function \", func_name,\n@@ -90,7 +90,7 @@ absl::Status ClusterFunctionLibraryRuntime::ConstructFunctionGraph(\n \n     // src_incarnation = 1 works because the transfer is across the same device.\n     // TODO(rohanj): Find the src_incarnation for the remote device and set it.\n-    const string& key = Rendezvous::CreateKey(\n+    const std::string& key = Rendezvous::CreateKey(\n         target, 1 /* src_incarnation */, target, in.name(), FrameAndIter(0, 0));\n     send_keys->push_back(key);\n     ++i;\n@@ -140,7 +140,7 @@ absl::Status ClusterFunctionLibraryRuntime::ConstructFunctionGraph(\n \n     g.AddEdge(function_node, i, output_node, 0);\n \n-    const string& key =\n+    const std::string& key =\n         Rendezvous::CreateKey(target, 1 /* src_incarnation */, target,\n                               out.name(), FrameAndIter(0, 0));\n     recv_keys->push_back(key);\n@@ -180,7 +180,7 @@ ClusterFunctionLibraryRuntime::~ClusterFunctionLibraryRuntime() {\n }\n \n void ClusterFunctionLibraryRuntime::Instantiate(\n-    const string& function_name, const FunctionLibraryDefinition& lib_def,\n+    const std::string& function_name, const FunctionLibraryDefinition& lib_def,\n     AttrSlice attrs, const FunctionLibraryRuntime::InstantiateOptions& options,\n     FunctionLibraryRuntime::LocalHandle* handle,\n     FunctionLibraryRuntime::DoneCallback done) {\n@@ -192,7 +192,7 @@ void ClusterFunctionLibraryRuntime::Instantiate(\n   WorkerInterface* wi = worker_cache->GetOrCreateWorker(target);\n \n   if (wi == nullptr) {\n-    std::vector<string> workers;\n+    std::vector<std::string> workers;\n     worker_session_->worker_cache()->ListWorkers(&workers);\n     done(errors::InvalidArgument(\n         \"Could not find worker with target: \", target,\n@@ -202,8 +202,8 @@ void ClusterFunctionLibraryRuntime::Instantiate(\n \n   // Make RPC and obtain a graph handle.\n   GraphDef gdef;\n-  auto* send_keys = new std::vector<string>;\n-  auto* recv_keys = new std::vector<string>;\n+  auto* send_keys = new std::vector<std::string>;\n+  auto* recv_keys = new std::vector<std::string>;\n   auto construct_graph_fn = [&](const FunctionLibraryDefinition* lib_def) {\n     const FunctionDef* fdef = lib_def->Find(function_name);\n     const OpDef& sig = fdef->signature();\n@@ -285,7 +285,7 @@ void ClusterFunctionLibraryRuntime::Run(\n     args[i].AsProtoTensorContent(send->mutable_tensor());\n     i++;\n   }\n-  const std::vector<string>& recv_keys = function_data->recv_keys;\n+  const std::vector<std::string>& recv_keys = function_data->recv_keys;\n   for (const auto& recv_key : recv_keys) {\n     req->add_recv_key(recv_key);\n   }\n@@ -308,7 +308,7 @@ void ClusterFunctionLibraryRuntime::Run(\n         if (!local_status->ok()) {\n           return;\n         }\n-        std::map<string, TensorProto*> mapped_recvs;\n+        std::map<std::string, TensorProto*> mapped_recvs;\n         for (auto& recv : *resp->mutable_recv()) {\n           mapped_recvs[recv.name()] = recv.mutable_tensor();\n         }\n@@ -363,7 +363,7 @@ void ClusterFunctionLibraryRuntime::Run(\n }\n \n void ClusterFunctionLibraryRuntime::CleanUp(\n-    uint64 step_id, FunctionLibraryRuntime::LocalHandle handle,\n+    uint64_t step_id, FunctionLibraryRuntime::LocalHandle handle,\n     FunctionLibraryRuntime::DoneCallback done) {\n   FunctionData* function_data = nullptr;\n   {"
        },
        {
            "sha": "2d66854ec8c2ca28ae1b0f23ce982f60aad3c7c4",
            "filename": "tensorflow/core/distributed_runtime/cluster_function_library_runtime.h",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcluster_function_library_runtime.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcluster_function_library_runtime.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fcluster_function_library_runtime.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -41,7 +41,7 @@ class ClusterFunctionLibraryRuntime : public DistributedFunctionLibraryRuntime {\n \n   ~ClusterFunctionLibraryRuntime() override;\n \n-  void Instantiate(const string& function_name,\n+  void Instantiate(const std::string& function_name,\n                    const FunctionLibraryDefinition& lib_def, AttrSlice attrs,\n                    const FunctionLibraryRuntime::InstantiateOptions& options,\n                    FunctionLibraryRuntime::LocalHandle* handle,\n@@ -57,7 +57,7 @@ class ClusterFunctionLibraryRuntime : public DistributedFunctionLibraryRuntime {\n            absl::Span<const FunctionArg> args, std::vector<FunctionRet>* rets,\n            FunctionLibraryRuntime::DoneCallback done) override;\n \n-  void CleanUp(uint64 step_id, FunctionLibraryRuntime::LocalHandle handle,\n+  void CleanUp(uint64_t step_id, FunctionLibraryRuntime::LocalHandle handle,\n                FunctionLibraryRuntime::DoneCallback done) override;\n \n   DeviceMgr* remote_device_mgr() const override { return remote_device_mgr_; }\n@@ -67,7 +67,7 @@ class ClusterFunctionLibraryRuntime : public DistributedFunctionLibraryRuntime {\n       const OpDef& sig, AttrSlice attrs,\n       const FunctionLibraryRuntime::InstantiateOptions& options,\n       const FunctionLibraryDefinition& flib_def, GraphDef* g,\n-      std::vector<string>* send_keys, std::vector<string>* recv_keys);\n+      std::vector<std::string>* send_keys, std::vector<std::string>* recv_keys);\n   friend class ClusterFunctionLibraryRuntimeTest;\n \n   mutable mutex mu_;\n@@ -77,19 +77,19 @@ class ClusterFunctionLibraryRuntime : public DistributedFunctionLibraryRuntime {\n   DeviceMgr* remote_device_mgr_;  // not owned.\n \n   struct FunctionData {\n-    const string graph_handle;\n-    const string target;\n+    const std::string graph_handle;\n+    const std::string target;\n     // Hold a shared pointer to the underlying worker cache to avoid it being\n     // deleted in potential cluster update.\n     const std::shared_ptr<WorkerCacheInterface> worker_cache;\n     WorkerInterface* wi = nullptr;\n-    const std::vector<string> send_keys;\n-    const std::vector<string> recv_keys;\n+    const std::vector<std::string> send_keys;\n+    const std::vector<std::string> recv_keys;\n \n-    FunctionData(const string& graph_handle, const string& target,\n+    FunctionData(const std::string& graph_handle, const std::string& target,\n                  std::shared_ptr<WorkerCacheInterface> worker_cache,\n-                 WorkerInterface* wi, const std::vector<string>& send_keys,\n-                 const std::vector<string>& recv_keys)\n+                 WorkerInterface* wi, const std::vector<std::string>& send_keys,\n+                 const std::vector<std::string>& recv_keys)\n         : graph_handle(graph_handle),\n           target(target),\n           worker_cache(std::move(worker_cache)),"
        },
        {
            "sha": "9be587fb48880cf4dc7143549c9016e8560a0c9c",
            "filename": "tensorflow/core/distributed_runtime/cluster_function_library_runtime_test.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 8,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcluster_function_library_runtime_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcluster_function_library_runtime_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fcluster_function_library_runtime_test.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -42,7 +42,7 @@ class ClusterFunctionLibraryRuntimeTest : public ::testing::Test {\n         &cluster_));\n     GrpcChannelSpec spec;\n \n-    std::map<int, string> host_ports;\n+    std::map<int, std::string> host_ports;\n     int i = 0;\n     for (const auto& target : cluster_->targets(\"localhost\")) {\n       host_ports[i++] = target;\n@@ -72,12 +72,13 @@ class ClusterFunctionLibraryRuntimeTest : public ::testing::Test {\n       const OpDef& sig, test::function::Attrs attrs,\n       const FunctionLibraryRuntime::InstantiateOptions& options,\n       const FunctionLibraryDefinition& lib_def, GraphDef* g,\n-      std::vector<string>* send_keys, std::vector<string>* recv_keys) {\n+      std::vector<std::string>* send_keys,\n+      std::vector<std::string>* recv_keys) {\n     return ClusterFunctionLibraryRuntime::ConstructFunctionGraph(\n         sig, attrs, options, lib_def, g, send_keys, recv_keys);\n   }\n \n-  void Instantiate(const string& function_name,\n+  void Instantiate(const std::string& function_name,\n                    const FunctionLibraryDefinition& lib_def,\n                    test::function::Attrs attrs,\n                    const FunctionLibraryRuntime::InstantiateOptions& options,\n@@ -88,8 +89,8 @@ class ClusterFunctionLibraryRuntimeTest : public ::testing::Test {\n   }\n \n   absl::Status InstantiateAndRun(\n-      const string& function_name, const FunctionLibraryDefinition& lib_def,\n-      test::function::Attrs attrs,\n+      const std::string& function_name,\n+      const FunctionLibraryDefinition& lib_def, test::function::Attrs attrs,\n       const FunctionLibraryRuntime::InstantiateOptions& options,\n       const std::vector<Tensor>& args, std::vector<Tensor*> rets) {\n     FunctionLibraryRuntime::LocalHandle handle;\n@@ -135,7 +136,7 @@ class ClusterFunctionLibraryRuntimeTest : public ::testing::Test {\n \n TEST_F(ClusterFunctionLibraryRuntimeTest, ConstructFunctionGraph) {\n   GraphDef actual;\n-  std::vector<string> send_keys, recv_keys;\n+  std::vector<std::string> send_keys, recv_keys;\n   FunctionDefLibrary proto;\n   *(proto.add_function()) = test::function::Swap();\n   FunctionLibraryDefinition lib_def(OpRegistry::Global(), proto);\n@@ -402,10 +403,10 @@ TEST_F(ClusterFunctionLibraryRuntimeTest, DISABLED_InstantiateAndRun) {\n   instantiate_opts.target = \"/job:localhost/replica:0/task:1/cpu:0\";\n \n   Tensor y;\n-  auto x = test::AsTensor<int32>({1, 2, 3, 4});\n+  auto x = test::AsTensor<int32_t>({1, 2, 3, 4});\n   TF_EXPECT_OK(InstantiateAndRun(\"XTimesTwoInt32\", lib_def, {},\n                                  instantiate_opts, {x}, {&y}));\n-  test::ExpectTensorEqual<int32>(y, test::AsTensor<int32>({2, 4, 6, 8}));\n+  test::ExpectTensorEqual<int32_t>(y, test::AsTensor<int32_t>({2, 4, 6, 8}));\n }\n \n TEST_F(ClusterFunctionLibraryRuntimeTest,"
        },
        {
            "sha": "5acf12ccea0f691091f251573003213b50ac9c3f",
            "filename": "tensorflow/core/distributed_runtime/collective_param_resolver_distributed.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 7,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_param_resolver_distributed.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_param_resolver_distributed.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_param_resolver_distributed.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -34,7 +34,7 @@ class CompleteGroupCall : public CancellableCall {\n   CompleteGroupCall(const CollGroupParams& group,\n                     const DeviceAttributes& device,\n                     CancellationManager* cancel_mgr,\n-                    const string& remote_worker, WorkerCacheInterface* wc)\n+                    const std::string& remote_worker, WorkerCacheInterface* wc)\n       : CancellableCall(cancel_mgr, remote_worker, wc) {\n     req_.set_group_key(group.group_key);\n     req_.set_group_size(group.group_size);\n@@ -55,9 +55,11 @@ class CompleteInstanceCall : public CancellableCall {\n  public:\n   CompleteInstanceCall(const CollGroupParams& group,\n                        const CollInstanceParams& instance,\n-                       const string& node_name, const string& device_name,\n-                       bool is_source, CancellationManager* cancel_mgr,\n-                       const string& remote_worker, WorkerCacheInterface* wc)\n+                       const std::string& node_name,\n+                       const std::string& device_name, bool is_source,\n+                       CancellationManager* cancel_mgr,\n+                       const std::string& remote_worker,\n+                       WorkerCacheInterface* wc)\n       : CancellableCall(cancel_mgr, remote_worker, wc) {\n     req_.set_name(node_name);\n     req_.set_type(instance.type);\n@@ -91,7 +93,7 @@ CollectiveParamResolverDistributed::CollectiveParamResolverDistributed(\n     const ConfigProto& config, const DeviceMgr* dev_mgr,\n     DeviceResolverDistributed* dev_resolver,\n     NcclCommunicatorInterface* nccl_communicator,\n-    WorkerCacheInterface* worker_cache, const string& task_name)\n+    WorkerCacheInterface* worker_cache, const std::string& task_name)\n     : CollectiveParamResolverLocal(config, dev_mgr, dev_resolver,\n                                    nccl_communicator, task_name),\n       worker_cache_(worker_cache),\n@@ -364,8 +366,8 @@ absl::Status CollectiveParamResolverDistributed::UpdateInstanceCache(\n }\n \n void CollectiveParamResolverDistributed::CompleteInstanceDistributed(\n-    const string& device, CollectiveParams* cp, CancellationManager* cancel_mgr,\n-    const StatusCallback& done) {\n+    const std::string& device, CollectiveParams* cp,\n+    CancellationManager* cancel_mgr, const StatusCallback& done) {\n   if (group_leader_.empty()) {\n     // This is the group leader so resolution is local.\n     return CompleteInstanceLocal(device, cp, done);"
        },
        {
            "sha": "d885fe0bb81a0e82ab8d82de3870dc2e37d31db8",
            "filename": "tensorflow/core/distributed_runtime/collective_param_resolver_distributed.h",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_param_resolver_distributed.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_param_resolver_distributed.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_param_resolver_distributed.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -32,7 +32,7 @@ class CollectiveParamResolverDistributed : public CollectiveParamResolverLocal {\n       const ConfigProto& config, const DeviceMgr* dev_mgr,\n       DeviceResolverDistributed* dev_resolver,\n       NcclCommunicatorInterface* nccl_communicator,\n-      WorkerCacheInterface* worker_cache, const string& task_name);\n+      WorkerCacheInterface* worker_cache, const std::string& task_name);\n \n   void CompleteParamsAsync(const DeviceAttributes& device, CollectiveParams* cp,\n                            CancellationManager* cancel_mgr,\n@@ -82,13 +82,14 @@ class CollectiveParamResolverDistributed : public CollectiveParamResolverLocal {\n   // Finish populating *cp.  Semantics are like those of\n   // CompleteInstanceLocal but will make a remote call to the group\n   // leader if necessary.\n-  void CompleteInstanceDistributed(const string& device, CollectiveParams* cp,\n+  void CompleteInstanceDistributed(const std::string& device,\n+                                   CollectiveParams* cp,\n                                    CancellationManager* cancel_mgr,\n                                    const StatusCallback& done)\n       TF_LOCKS_EXCLUDED(instance_mu_, group_mu_);\n \n   WorkerCacheInterface* worker_cache_;  // Not owned\n-  const string group_leader_;\n+  const std::string group_leader_;\n   CancellationManager abortion_cancel_mgr_;\n };\n "
        },
        {
            "sha": "2880d722f0efbfb4f1a524699038ab0fdac280f8",
            "filename": "tensorflow/core/distributed_runtime/collective_param_resolver_distributed_test.cc",
            "status": "modified",
            "additions": 42,
            "deletions": 37,
            "changes": 79,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_param_resolver_distributed_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_param_resolver_distributed_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_param_resolver_distributed_test.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -34,8 +34,8 @@ limitations under the License.\n namespace tensorflow {\n namespace {\n \n-static std::unique_ptr<Device> NewDevice(const string& type,\n-                                         const string& name) {\n+static std::unique_ptr<Device> NewDevice(const std::string& type,\n+                                         const std::string& name) {\n   class FakeDevice : public Device {\n    public:\n     explicit FakeDevice(const DeviceAttributes& attr) : Device(nullptr, attr) {}\n@@ -54,15 +54,16 @@ class FakeCache : public TestWorkerCache {\n  public:\n   // Override the Locality methods to actually pass through to the\n   // worker.\n-  bool GetDeviceLocalityNonBlocking(const string& device,\n+  bool GetDeviceLocalityNonBlocking(const std::string& device,\n                                     DeviceLocality* locality) override {\n     return false;\n   }\n \n-  void GetDeviceLocalityAsync(const string& device, DeviceLocality* locality,\n+  void GetDeviceLocalityAsync(const std::string& device,\n+                              DeviceLocality* locality,\n                               StatusCallback done) override {\n-    string task_name;\n-    string dev_part;\n+    std::string task_name;\n+    std::string dev_part;\n     if (!DeviceNameUtils::SplitDeviceName(device, &task_name, &dev_part)) {\n       done(errors::Internal(\"failed to parse device name\"));\n       return;\n@@ -94,7 +95,9 @@ class FakeCache : public TestWorkerCache {\n class FakeNcclCommunicator : public NcclCommunicatorInterface {\n  public:\n   // We only need to define GenerateCommunicatorKey().\n-  string GenerateCommunicatorKey() override { return \"mock-communicator-key\"; }\n+  std::string GenerateCommunicatorKey() override {\n+    return \"mock-communicator-key\";\n+  }\n \n   void Enqueue(std::shared_ptr<CollectiveContext> col_ctx,\n                StatusCallback done) override {\n@@ -114,15 +117,16 @@ class DeviceResDistTest : public ::testing::Test {\n \n  protected:\n   void DefineWorkers(int num_workers, int num_devices,\n-                     const string& device_type, bool nccl) {\n+                     const std::string& device_type, bool nccl) {\n     for (int w = 0; w < num_workers; ++w) {\n-      string name = absl::StrCat(\"/job:worker/replica:0/task:\", w);\n+      std::string name = absl::StrCat(\"/job:worker/replica:0/task:\", w);\n       DefineWorker(name, device_type, num_devices, nccl);\n     }\n   }\n \n-  void DefineWorker(const string& worker_name, const string& device_type,\n-                    int num_devices, bool nccl) {\n+  void DefineWorker(const std::string& worker_name,\n+                    const std::string& device_type, int num_devices,\n+                    bool nccl) {\n     ConfigProto config;\n     config.mutable_experimental()->set_collective_group_leader(\n         \"/job:worker/replica:0/task:0\");\n@@ -136,7 +140,7 @@ class DeviceResDistTest : public ::testing::Test {\n     }\n     device_mgrs_[worker_name] =\n         std::make_unique<StaticDeviceMgr>(std::move(devices));\n-    std::vector<string>* dv = &dev_by_task_[worker_name];\n+    std::vector<std::string>* dv = &dev_by_task_[worker_name];\n     dv->clear();\n     for (auto* d : device_mgrs_[worker_name]->ListDevices()) {\n       dv->push_back(d->name());\n@@ -160,14 +164,14 @@ class DeviceResDistTest : public ::testing::Test {\n   }\n \n   void DefineCollectiveParams(int num_workers, int num_devices,\n-                              const string& device_type,\n+                              const std::string& device_type,\n                               CollectiveType coll_type = REDUCTION_COLLECTIVE,\n                               int source_rank = 0) {\n     for (int wi = 0; wi < num_workers; ++wi) {\n-      string task_name = absl::StrCat(\"/job:worker/replica:0/task:\", wi);\n+      std::string task_name = absl::StrCat(\"/job:worker/replica:0/task:\", wi);\n       for (int di = 0; di < num_devices; ++di) {\n         int idx = wi * num_devices + di;\n-        string device_name =\n+        std::string device_name =\n             strings::StrCat(task_name, \"/device:\", device_type, \":\", di);\n         cp_[device_name] =\n             CreateCollectiveParams(num_workers, num_devices, device_type,\n@@ -177,7 +181,7 @@ class DeviceResDistTest : public ::testing::Test {\n   }\n \n   CollectiveParams* CreateCollectiveParams(int num_workers, int num_devices,\n-                                           const string& device_type,\n+                                           const std::string& device_type,\n                                            CollectiveType coll_type,\n                                            bool is_source) {\n     const int kGroupKey = 5;\n@@ -203,16 +207,16 @@ class DeviceResDistTest : public ::testing::Test {\n     }\n     int group_size = num_workers * num_devices;\n     for (int wi = 0; wi < num_workers; ++wi) {\n-      string task_name = absl::StrCat(\"/job:worker/replica:0/task:\", wi);\n+      std::string task_name = absl::StrCat(\"/job:worker/replica:0/task:\", wi);\n       for (int di = 0; di < num_devices; ++di) {\n-        string device_name = absl::StrCat(task_name, \"/device:CPU:\", di);\n+        std::string device_name = absl::StrCat(task_name, \"/device:CPU:\", di);\n         IssueRequest(task_name, device_name, group_size);\n       }\n     }\n   }\n \n-  void IssueRequest(const string& task_name, const string& device_name,\n-                    int group_size) {\n+  void IssueRequest(const std::string& task_name,\n+                    const std::string& device_name, int group_size) {\n     Device* device = nullptr;\n     TF_CHECK_OK(device_mgrs_[task_name]->LookupDevice(device_name, &device));\n     CollectiveParams* cp = cp_[device_name];\n@@ -243,11 +247,11 @@ class DeviceResDistTest : public ::testing::Test {\n     // Verify that all cp_ values get the same set of task and device\n     // names, with unique default_rank in the expected order.\n     const int dev_count = num_workers * num_devices;\n-    string dev0 = \"/job:worker/replica:0/task:0/device:CPU:0\";\n+    std::string dev0 = \"/job:worker/replica:0/task:0/device:CPU:0\";\n     for (int wi = 0; wi < num_workers; ++wi) {\n-      string task_name = absl::StrCat(\"/job:worker/replica:0/task:\", wi);\n+      std::string task_name = absl::StrCat(\"/job:worker/replica:0/task:\", wi);\n       for (int di = 0; di < num_devices; ++di) {\n-        string device_name = absl::StrCat(task_name, \"/device:CPU:\", di);\n+        std::string device_name = absl::StrCat(task_name, \"/device:CPU:\", di);\n         int idx = wi * num_devices + di;\n         TF_ASSERT_OK(status_[device_name]);\n         EXPECT_EQ(cp_[device_name]->default_rank, idx);\n@@ -270,7 +274,8 @@ class DeviceResDistTest : public ::testing::Test {\n     }\n   }\n \n-  void ValidateDeviceResolver(const CollectiveParams& cp, const string& task) {\n+  void ValidateDeviceResolver(const CollectiveParams& cp,\n+                              const std::string& task) {\n     for (const CollGroupMember& member : cp.group.members) {\n       DeviceAttributes attributes;\n       TF_ASSERT_OK(dev_resolvers_[task]->GetDeviceAttributes(\n@@ -279,14 +284,14 @@ class DeviceResDistTest : public ::testing::Test {\n   }\n \n   void RestartWorker(int worker_idx, int num_workers, int num_devices,\n-                     const string& device_type, bool nccl,\n+                     const std::string& device_type, bool nccl,\n                      CollectiveType coll_type = REDUCTION_COLLECTIVE,\n                      bool is_source = false) {\n-    string worker_name =\n+    std::string worker_name =\n         absl::StrCat(\"/job:worker/replica:0/task:\", worker_idx);\n     DefineWorker(worker_name, device_type, num_devices, nccl);\n     for (int i = 0; i < num_devices; ++i) {\n-      string device_name =\n+      std::string device_name =\n           strings::StrCat(worker_name, \"/device:\", device_type, \":\", i);\n       if (cp_.find(device_name) != cp_.end()) {\n         cp_[device_name]->Unref();\n@@ -301,18 +306,18 @@ class DeviceResDistTest : public ::testing::Test {\n   FakeNcclCommunicator nccl_communicator_;\n   CancellationManager cm_;\n   // Below are keyed by task names.\n-  absl::flat_hash_map<string, std::unique_ptr<DeviceMgr>> device_mgrs_;\n-  absl::flat_hash_map<string, std::unique_ptr<DeviceResolverDistributed>>\n+  absl::flat_hash_map<std::string, std::unique_ptr<DeviceMgr>> device_mgrs_;\n+  absl::flat_hash_map<std::string, std::unique_ptr<DeviceResolverDistributed>>\n       dev_resolvers_;\n-  absl::flat_hash_map<string,\n+  absl::flat_hash_map<std::string,\n                       std::unique_ptr<CollectiveParamResolverDistributed>>\n       cp_resolvers_;\n-  absl::flat_hash_map<string, std::vector<string>> dev_by_task_;\n-  absl::flat_hash_map<string, std::unique_ptr<WorkerEnv>> worker_envs_;\n-  absl::flat_hash_map<string, std::unique_ptr<Worker>> workers_;\n+  absl::flat_hash_map<std::string, std::vector<std::string>> dev_by_task_;\n+  absl::flat_hash_map<std::string, std::unique_ptr<WorkerEnv>> worker_envs_;\n+  absl::flat_hash_map<std::string, std::unique_ptr<Worker>> workers_;\n   // Below are keyed by device names;\n-  absl::flat_hash_map<string, CollectiveParams*> cp_;\n-  absl::flat_hash_map<string, absl::Status> status_;\n+  absl::flat_hash_map<std::string, CollectiveParams*> cp_;\n+  absl::flat_hash_map<std::string, absl::Status> status_;\n   mutex mu_;\n   int num_done_ TF_GUARDED_BY(mu_);\n   condition_variable done_;\n@@ -343,8 +348,8 @@ TEST_F(DeviceResDistTest, DifferentIncarnation) {\n   DefineCollectiveParams(num_workers, num_devices, \"CPU\");\n   IssueRequests(num_workers, num_devices);\n   RestartWorker(1, num_workers, num_devices, \"CPU\", /*nccl*/ false);\n-  const string task_name = \"/job:worker/replica:0/task:1\";\n-  const string device_name = absl::StrCat(task_name, \"/device:CPU:0\");\n+  const std::string task_name = \"/job:worker/replica:0/task:1\";\n+  const std::string device_name = absl::StrCat(task_name, \"/device:CPU:0\");\n   IssueRequest(task_name, device_name, num_workers * num_devices);\n   EXPECT_TRUE(absl::IsFailedPrecondition(status_[device_name]));\n }"
        },
        {
            "sha": "afab5707e58e4e7f4e8298459a52659eb7c39667",
            "filename": "tensorflow/core/distributed_runtime/collective_rma_distributed.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 10,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_rma_distributed.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_rma_distributed.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_rma_distributed.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -39,9 +39,9 @@ namespace {\n \n class RecvBufCall : public CancellableCall {\n  public:\n-  RecvBufCall(int64_t step_id, const string& peer_device,\n-              const string& peer_task, const string& key, Device* to_device,\n-              DeviceContext* to_device_ctx,\n+  RecvBufCall(int64_t step_id, const std::string& peer_device,\n+              const std::string& peer_task, const std::string& key,\n+              Device* to_device, DeviceContext* to_device_ctx,\n               const AllocatorAttributes& to_alloc_attr, Tensor* to_tensor,\n               const DeviceLocality& client_locality,\n               const DeviceAttributes& server_attributes,\n@@ -107,11 +107,12 @@ absl::Status PopulateTensorFromResponse(const RecvBufResponse& response,\n }  // namespace\n \n void CollectiveRemoteAccessDistributed::RecvFromPeer(\n-    const string& peer_device, const string& peer_task, bool peer_is_local,\n-    const string& key, Device* to_device, DeviceContext* to_device_ctx,\n-    const AllocatorAttributes& to_alloc_attr, Tensor* to_tensor,\n-    const DeviceLocality& client_locality, int dev_to_dev_stream_index,\n-    CancellationManager* cancellation_manager, const StatusCallback& done) {\n+    const std::string& peer_device, const std::string& peer_task,\n+    bool peer_is_local, const std::string& key, Device* to_device,\n+    DeviceContext* to_device_ctx, const AllocatorAttributes& to_alloc_attr,\n+    Tensor* to_tensor, const DeviceLocality& client_locality,\n+    int dev_to_dev_stream_index, CancellationManager* cancellation_manager,\n+    const StatusCallback& done) {\n   if (peer_is_local) {\n     CollectiveRemoteAccessLocal::RecvFromPeer(\n         peer_device, peer_task, peer_is_local, key, to_device, to_device_ctx,\n@@ -232,7 +233,7 @@ void CollectiveRemoteAccessDistributed::RecvFromPeer(\n }\n \n void CollectiveRemoteAccessDistributed::CheckPeerHealth(\n-    const string& peer_task, int64_t timeout_in_ms,\n+    const std::string& peer_task, int64_t timeout_in_ms,\n     const StatusCallback& done) {\n   if (peer_task == task_name_) {\n     // Fast path if the peer is the worker itself.\n@@ -265,7 +266,7 @@ void CollectiveRemoteAccessDistributed::CheckPeerHealth(\n           s = dev_resolver_->GetAllDeviceAttributes(peer_task, &cached_attrs);\n         }\n         if (s.ok()) {\n-          absl::flat_hash_set<uint64> remote_incarnations;\n+          absl::flat_hash_set<uint64_t> remote_incarnations;\n           for (const DeviceAttributes& da : resp->device_attributes()) {\n             remote_incarnations.insert(da.incarnation());\n           }"
        },
        {
            "sha": "4557e9b36ac2066290a14bd685d309c8ced4374e",
            "filename": "tensorflow/core/distributed_runtime/collective_rma_distributed.h",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_rma_distributed.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_rma_distributed.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_rma_distributed.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -29,24 +29,26 @@ class CollectiveRemoteAccessDistributed : public CollectiveRemoteAccessLocal {\n   CollectiveRemoteAccessDistributed(\n       const DeviceMgr* dev_mgr, DeviceResolverInterface* dev_resolver,\n       std::shared_ptr<UnboundedWorkQueue> work_queue,\n-      WorkerCacheInterface* worker_cache, int64_t step_id, string task_name)\n+      WorkerCacheInterface* worker_cache, int64_t step_id,\n+      std::string task_name)\n       : CollectiveRemoteAccessLocal(dev_mgr, dev_resolver, step_id),\n         worker_cache_(worker_cache),\n         work_queue_(std::move(work_queue)),\n         task_name_(std::move(task_name)) {}\n \n   ~CollectiveRemoteAccessDistributed() override {}\n \n-  void RecvFromPeer(const string& peer_device, const string& peer_task,\n-                    bool peer_is_local, const string& key, Device* to_device,\n+  void RecvFromPeer(const std::string& peer_device,\n+                    const std::string& peer_task, bool peer_is_local,\n+                    const std::string& key, Device* to_device,\n                     DeviceContext* to_device_ctx,\n                     const AllocatorAttributes& to_alloc_attr, Tensor* to_tensor,\n                     const DeviceLocality& client_locality,\n                     int dev_to_dev_stream_index,\n                     CancellationManager* cancellation_manager,\n                     const StatusCallback& done) override;\n \n-  void CheckPeerHealth(const string& peer_task, int64_t timeout_in_ms,\n+  void CheckPeerHealth(const std::string& peer_task, int64_t timeout_in_ms,\n                        const StatusCallback& done) override;\n \n   void StartAbort(const absl::Status& s) override;\n@@ -57,7 +59,7 @@ class CollectiveRemoteAccessDistributed : public CollectiveRemoteAccessLocal {\n   // `CollectiveExecutorMgr`.\n   std::shared_ptr<UnboundedWorkQueue> work_queue_;\n   CancellationManager abortion_cancel_mgr_;\n-  string task_name_;\n+  std::string task_name_;\n };\n \n }  // namespace tensorflow"
        },
        {
            "sha": "4d626cb9f49a9c7cb9af870295f8a619192e694e",
            "filename": "tensorflow/core/distributed_runtime/collective_rma_distributed_test.cc",
            "status": "modified",
            "additions": 34,
            "deletions": 29,
            "changes": 63,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_rma_distributed_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_rma_distributed_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fcollective_rma_distributed_test.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -50,14 +50,16 @@ namespace {\n \n class FakeAllocator : public Allocator {\n  public:\n-  string Name() override { return \"fake\"; }\n+  std::string Name() override { return \"fake\"; }\n   void* AllocateRaw(size_t alignment, size_t num_bytes) override {\n-    return port::AlignedMalloc(num_bytes, alignment);\n+    return tsl::port::AlignedMalloc(num_bytes,\n+                                    static_cast<std::align_val_t>(alignment));\n   }\n   void DeallocateRaw(void* ptr) override { return port::AlignedFree(ptr); }\n };\n \n-static std::unique_ptr<Device> NewDevice(const string& type, const string& name,\n+static std::unique_ptr<Device> NewDevice(const std::string& type,\n+                                         const std::string& name,\n                                          Allocator* allocator) {\n   class FakeDevice : public Device {\n    public:\n@@ -81,7 +83,7 @@ static int64_t kStepId = 123;\n \n class FakeWorker : public TestWorkerInterface {\n  public:\n-  FakeWorker(const string& name, DeviceMgr* dev_mgr,\n+  FakeWorker(const std::string& name, DeviceMgr* dev_mgr,\n              DeviceResolverDistributed* dres, bool is_failed,\n              bool set_tensor_in_extra)\n       : name_(name),\n@@ -144,7 +146,7 @@ class FakeWorker : public TestWorkerInterface {\n               // Since this is not really RDMA into pre-allocated memory send\n               // the bytes in the response.\n               RecvBufRespExtra extra;\n-              extra.add_tensor_content(string(\n+              extra.add_tensor_content(std::string(\n                   reinterpret_cast<const char*>(DMAHelper::base(h->prod_value)),\n                   num_bytes));\n               response->mutable_transport_options()->PackFrom(extra);\n@@ -164,7 +166,7 @@ class FakeWorker : public TestWorkerInterface {\n   }\n \n  private:\n-  string name_;\n+  std::string name_;\n   DeviceMgr* device_mgr_;\n   DeviceResolverDistributed* device_resolver_;\n   BufRendezvous buf_rendezvous_;\n@@ -176,15 +178,16 @@ class FakeCache : public TestWorkerCache {\n  public:\n   // Override the Locality methods to actually pass through to the\n   // worker.\n-  bool GetDeviceLocalityNonBlocking(const string& device,\n+  bool GetDeviceLocalityNonBlocking(const std::string& device,\n                                     DeviceLocality* locality) override {\n     return false;\n   }\n \n-  void GetDeviceLocalityAsync(const string& device, DeviceLocality* locality,\n+  void GetDeviceLocalityAsync(const std::string& device,\n+                              DeviceLocality* locality,\n                               StatusCallback done) override {\n-    string task_name;\n-    string dev_part;\n+    std::string task_name;\n+    std::string dev_part;\n     if (!DeviceNameUtils::SplitDeviceName(device, &task_name, &dev_part)) {\n       done(errors::Internal(\"failed to parse device name\"));\n       return;\n@@ -246,10 +249,10 @@ class CollRMADistTest\n   void SetUp() override {\n     const int num_workers = 2;\n     const int num_devices = 1;\n-    string device_type = \"CPU\";\n-    string dev0_worker_name;\n+    std::string device_type = \"CPU\";\n+    std::string dev0_worker_name;\n     for (int w = 0; w < num_workers; ++w) {\n-      string name = absl::StrCat(\"/job:worker/replica:0/task:\", w);\n+      std::string name = absl::StrCat(\"/job:worker/replica:0/task:\", w);\n       if (w == 0) {\n         dev0_worker_name = name;\n       }\n@@ -288,8 +291,9 @@ class CollRMADistTest\n     }\n   }\n \n-  void DefineWorker(const string& worker_name, const string& device_type,\n-                    int num_devices, bool is_failed = false) {\n+  void DefineWorker(const std::string& worker_name,\n+                    const std::string& device_type, int num_devices,\n+                    bool is_failed = false) {\n     std::vector<std::unique_ptr<Device>> devices;\n     for (int i = 0; i < num_devices; ++i) {\n       devices.push_back(NewDevice(\n@@ -316,8 +320,9 @@ class CollRMADistTest\n     wc_.AddWorker(worker_name, fw);\n   }\n \n-  void RestartWorker(const string& worker_name, const string& device_type,\n-                     int num_devices, bool is_failed = false) {\n+  void RestartWorker(const std::string& worker_name,\n+                     const std::string& device_type, int num_devices,\n+                     bool is_failed = false) {\n     auto it = dev_resolvers_.find(worker_name);\n     if (it != dev_resolvers_.end()) {\n       delete it->second;\n@@ -354,8 +359,8 @@ class CollRMADistTest\n   FakeCache wc_;\n   CancellationManager cm_;\n   std::vector<DeviceMgr*> device_mgrs_;\n-  std::unordered_map<string, DeviceResolverDistributed*> dev_resolvers_;\n-  std::unordered_map<string, std::vector<DeviceAttributes>> dev_by_task_;\n+  std::unordered_map<std::string, DeviceResolverDistributed*> dev_resolvers_;\n+  std::unordered_map<std::string, std::vector<DeviceAttributes>> dev_by_task_;\n   std::shared_ptr<UnboundedWorkQueue> work_queue_;\n   std::vector<FakeWorker*> workers_;\n   std::unique_ptr<CollectiveRemoteAccessDistributed> rma_;\n@@ -379,7 +384,7 @@ TEST_P(CollRMADistTest, ProdFirstOK) {\n   absl::Status consumer_status;\n   absl::Status producer_status;\n   FakeWorker* wi = workers_[1];\n-  const string kBufKey = \"fake_buf_key\";\n+  const std::string kBufKey = \"fake_buf_key\";\n   wi->buf_rendezvous()->ProvideBuf(\n       kBufKey, nullptr /*device*/, nullptr /*dev_ctx*/, &expected_value_,\n       AllocatorAttributes(),\n@@ -389,7 +394,7 @@ TEST_P(CollRMADistTest, ProdFirstOK) {\n       },\n       nullptr /*cancellation_manager*/);\n   Device* dst_device = nullptr;\n-  string dev_name = \"CPU:0\";\n+  std::string dev_name = \"CPU:0\";\n   TF_EXPECT_OK(device_mgrs_[0]->LookupDevice(dev_name, &dst_device));\n   DeviceContext* to_device_ctx = nullptr;\n   MaybeSetGPUDevice(dst_device);\n@@ -418,9 +423,9 @@ TEST_P(CollRMADistTest, ConsFirstOK) {\n   absl::Status consumer_status;\n   absl::Status producer_status;\n   FakeWorker* wi = workers_[1];\n-  const string kBufKey = \"fake_buf_key\";\n+  const std::string kBufKey = \"fake_buf_key\";\n   Device* dst_device = nullptr;\n-  string dev_name = \"CPU:0\";\n+  std::string dev_name = \"CPU:0\";\n   TF_EXPECT_OK(device_mgrs_[0]->LookupDevice(dev_name, &dst_device));\n   MaybeSetGPUDevice(dst_device);\n   DeviceContext* to_device_ctx = nullptr;\n@@ -454,9 +459,9 @@ TEST_P(CollRMADistTest, ConsFirstAbort) {\n   ResolveDeviceAttributes();\n   absl::Notification consumer_note;\n   absl::Status consumer_status;\n-  const string kBufKey = \"fake_buf_key\";\n+  const std::string kBufKey = \"fake_buf_key\";\n   Device* dst_device = nullptr;\n-  string dev_name = \"CPU:0\";\n+  std::string dev_name = \"CPU:0\";\n   TF_EXPECT_OK(device_mgrs_[0]->LookupDevice(dev_name, &dst_device));\n   MaybeSetGPUDevice(dst_device);\n   DeviceContext* to_device_ctx = nullptr;\n@@ -483,7 +488,7 @@ TEST_P(CollRMADistTest, ResponseTooLarge) {\n   absl::Status consumer_status;\n   absl::Status producer_status;\n   FakeWorker* wi = workers_[1];\n-  const string kBufKey = \"fake_buf_key\";\n+  const std::string kBufKey = \"fake_buf_key\";\n   wi->buf_rendezvous()->ProvideBuf(\n       kBufKey, nullptr /*device*/, nullptr /*dev_ctx*/, &large_response_,\n       AllocatorAttributes(),\n@@ -493,7 +498,7 @@ TEST_P(CollRMADistTest, ResponseTooLarge) {\n       },\n       nullptr /*cancellation_manager*/);\n   Device* dst_device = nullptr;\n-  string dev_name = \"CPU:0\";\n+  std::string dev_name = \"CPU:0\";\n   TF_EXPECT_OK(device_mgrs_[0]->LookupDevice(dev_name, &dst_device));\n   DeviceContext* to_device_ctx = nullptr;\n   MaybeSetGPUDevice(dst_device);\n@@ -523,9 +528,9 @@ TEST_P(CollRMADistTest, WorkerRestart) {\n   absl::Status consumer_status;\n   absl::Status producer_status;\n   FakeWorker* wi = workers_[1];\n-  const string buf_key = \"fake_buf_key\";\n+  const std::string buf_key = \"fake_buf_key\";\n   Device* dst_device = nullptr;\n-  string dev_name = \"CPU:0\";\n+  std::string dev_name = \"CPU:0\";\n   TF_EXPECT_OK(device_mgrs_[0]->LookupDevice(dev_name, &dst_device));\n   MaybeSetGPUDevice(dst_device);\n   DeviceContext* to_device_ctx = nullptr;"
        },
        {
            "sha": "3de97cc08726ff5f75d801bd0325756333116cee",
            "filename": "tensorflow/core/distributed_runtime/device_resolver_distributed.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fdevice_resolver_distributed.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fdevice_resolver_distributed.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fdevice_resolver_distributed.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -28,7 +28,7 @@ DeviceResolverDistributed::DeviceResolverDistributed(const DeviceMgr* dev_mgr) {\n }\n \n absl::Status DeviceResolverDistributed::GetDeviceAttributes(\n-    const string& device, DeviceAttributes* attributes) {\n+    const std::string& device, DeviceAttributes* attributes) {\n   mutex_lock l(mu_);\n   auto it = attr_table_.find(device);\n   if (it == attr_table_.end()) {\n@@ -39,11 +39,11 @@ absl::Status DeviceResolverDistributed::GetDeviceAttributes(\n }\n \n absl::Status DeviceResolverDistributed::GetAllDeviceAttributes(\n-    const string& task, std::vector<DeviceAttributes>* attributes) {\n+    const std::string& task, std::vector<DeviceAttributes>* attributes) {\n   mutex_lock l(mu_);\n   attributes->clear();\n   for (const auto& it : attr_table_) {\n-    const string& device_name = it.first;\n+    const std::string& device_name = it.first;\n     if (DeviceNameUtils::IsSameAddressSpace(task, device_name)) {\n       attributes->push_back(it.second);\n     }"
        },
        {
            "sha": "3bf6cfa813fe2fe61a9fd5c17e6342dc374a8297",
            "filename": "tensorflow/core/distributed_runtime/device_resolver_distributed.h",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fdevice_resolver_distributed.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fdevice_resolver_distributed.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fdevice_resolver_distributed.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -31,19 +31,21 @@ class DeviceResolverDistributed : public DeviceResolverInterface {\n  public:\n   explicit DeviceResolverDistributed(const DeviceMgr* dev_mgr);\n \n-  absl::Status GetDeviceAttributes(const string& device,\n+  absl::Status GetDeviceAttributes(const std::string& device,\n                                    DeviceAttributes* attributes) override;\n \n   absl::Status GetAllDeviceAttributes(\n-      const string& task, std::vector<DeviceAttributes>* attributes) override;\n+      const std::string& task,\n+      std::vector<DeviceAttributes>* attributes) override;\n \n   absl::Status UpdateDeviceAttributes(\n       const std::vector<DeviceAttributes>& attributes) override;\n \n  protected:\n-  const string task_name_;\n+  const std::string task_name_;\n   mutex mu_;\n-  absl::flat_hash_map<string, DeviceAttributes> attr_table_ TF_GUARDED_BY(mu_);\n+  absl::flat_hash_map<std::string, DeviceAttributes> attr_table_\n+      TF_GUARDED_BY(mu_);\n };\n \n }  // namespace tensorflow"
        },
        {
            "sha": "8a3245ce2ee3e5b15828e12c543a49d2c10a7843",
            "filename": "tensorflow/core/distributed_runtime/device_resolver_distributed_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fdevice_resolver_distributed_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fdevice_resolver_distributed_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fdevice_resolver_distributed_test.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -34,7 +34,8 @@ using ::testing::UnorderedElementsAre;\n \n // Create a fake 'Device' whose only interesting attribute is a non-default\n // DeviceLocality and incarnation.\n-std::unique_ptr<Device> NewDevice(const string& type, const string& name) {\n+std::unique_ptr<Device> NewDevice(const std::string& type,\n+                                  const std::string& name) {\n   class FakeDevice : public Device {\n    public:\n     explicit FakeDevice(const DeviceAttributes& attr) : Device(nullptr, attr) {}"
        },
        {
            "sha": "507915a74152be09d114e5c269c658921045743f",
            "filename": "tensorflow/core/distributed_runtime/graph_mgr.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fgraph_mgr.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fgraph_mgr.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fgraph_mgr.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -337,7 +337,7 @@ absl::Status GraphMgr::Register(const std::string& handle, const GraphDef& gdef,\n   {\n     mutex_lock l(mu_);\n     *graph_handle =\n-        strings::Printf(\"%016llx\", static_cast<long long>(++next_id_));\n+        absl::StrFormat(\"%016llx\", static_cast<long long>(++next_id_));\n     item->handle = *graph_handle;\n     CHECK(table_.insert({*graph_handle, item}).second);\n   }"
        },
        {
            "sha": "af41d4ad1d4b498c50f045de79119923fd5be010",
            "filename": "tensorflow/core/distributed_runtime/local_master.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Flocal_master.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Flocal_master.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Flocal_master.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -223,23 +223,23 @@ struct MasterInfo {\n       : master(master), default_timeout_in_ms(default_timeout_in_ms) {}\n };\n \n-typedef std::unordered_map<string, MasterInfo> LocalMasterRegistry;\n+typedef std::unordered_map<std::string, MasterInfo> LocalMasterRegistry;\n LocalMasterRegistry* local_master_registry() {\n   static LocalMasterRegistry* local_master_registry_ = new LocalMasterRegistry;\n   return local_master_registry_;\n }\n }  // namespace\n \n /* static */\n-void LocalMaster::Register(const string& target, Master* master,\n+void LocalMaster::Register(const std::string& target, Master* master,\n                            int64_t default_timeout_in_ms) {\n   mutex_lock l(*get_local_master_registry_lock());\n   local_master_registry()->insert(\n       {target, MasterInfo(master, default_timeout_in_ms)});\n }\n \n /* static */\n-std::unique_ptr<LocalMaster> LocalMaster::Lookup(const string& target) {\n+std::unique_ptr<LocalMaster> LocalMaster::Lookup(const std::string& target) {\n   std::unique_ptr<LocalMaster> ret;\n   mutex_lock l(*get_local_master_registry_lock());\n   auto iter = local_master_registry()->find(target);"
        },
        {
            "sha": "b9fe78e8591f1722e91e5ebfb57704bfcb1bc69b",
            "filename": "tensorflow/core/distributed_runtime/local_master.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Flocal_master.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Flocal_master.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Flocal_master.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -89,12 +89,12 @@ class LocalMaster : public MasterInterface {\n   // any LocalMaster objects that may wrap this master. There is no\n   // corresponding deregister method, since clean server shutdown is\n   // not currently implemented for any server type.\n-  static void Register(const string& target, Master* master,\n+  static void Register(const std::string& target, Master* master,\n                        int64_t default_timeout_in_ms);\n \n   // Returns a pointer to the local master associated with the given\n   // `target`, or nullptr if none exists.\n-  static std::unique_ptr<LocalMaster> Lookup(const string& target);\n+  static std::unique_ptr<LocalMaster> Lookup(const std::string& target);\n \n  private:\n   Master* master_impl_;  // Not owned."
        },
        {
            "sha": "bc7fa3c80bb67839da17385f1c1655e5cae90eae",
            "filename": "tensorflow/core/distributed_runtime/master.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 28,
            "changes": 57,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -102,7 +102,7 @@ void Master::GC() {\n     if (shutdown_) {\n       break;\n     }\n-    std::vector<string> handles;\n+    std::vector<std::string> handles;\n     const int64_t num_micros =\n         static_cast<int64_t>(session_gc_seconds_ * 1000000);\n     for (const auto& entry : sessions_) {\n@@ -124,7 +124,7 @@ void Master::GC() {\n   }\n }\n \n-MasterSession* Master::FindMasterSession(const string& handle) {\n+MasterSession* Master::FindMasterSession(const std::string& handle) {\n   MasterSession* session = nullptr;\n   {\n     mutex_lock l(mu_);\n@@ -139,8 +139,8 @@ MasterSession* Master::FindMasterSession(const string& handle) {\n class DeviceFinder {\n  public:\n   static absl::Status GetRemoteDevices(\n-      const protobuf::RepeatedPtrField<string>& device_filters, MasterEnv* env,\n-      WorkerCacheInterface* worker_cache,\n+      const protobuf::RepeatedPtrField<std::string>& device_filters,\n+      MasterEnv* env, WorkerCacheInterface* worker_cache,\n       std::vector<std::unique_ptr<Device>>* out_remote) {\n     DeviceFinder finder(device_filters, env, worker_cache);\n     finder.Start();\n@@ -150,62 +150,63 @@ class DeviceFinder {\n   }\n \n   static void GetRemoteWorkers(\n-      const protobuf::RepeatedPtrField<string>& device_filters, MasterEnv* env,\n-      WorkerCacheInterface* worker_cache, std::vector<string>* workers) {\n+      const protobuf::RepeatedPtrField<std::string>& device_filters,\n+      MasterEnv* env, WorkerCacheInterface* worker_cache,\n+      std::vector<std::string>* workers) {\n     DeviceFinder finder(device_filters, env, worker_cache);\n     *workers = finder.targets_;\n   }\n \n  private:\n   explicit DeviceFinder(\n-      const protobuf::RepeatedPtrField<string>& device_filters, MasterEnv* env,\n-      WorkerCacheInterface* worker_cache)\n+      const protobuf::RepeatedPtrField<std::string>& device_filters,\n+      MasterEnv* env, WorkerCacheInterface* worker_cache)\n       : env_(env), worker_cache_(worker_cache) {\n     CHECK(worker_cache) << \"Worker cache was null!\";\n-    auto process_filter = [this](const string& filter) {\n+    auto process_filter = [this](const std::string& filter) {\n       DeviceNameUtils::ParsedName parsed;\n       if (DeviceNameUtils::ParseFullName(filter, &parsed)) {\n         filters_.push_back(parsed);\n       } else {\n         LOG(FATAL) << \"Skipping invalid filter: \" << filter;\n       }\n     };\n-    for (const string& filter : device_filters) {\n+    for (const std::string& filter : device_filters) {\n       process_filter(filter);\n     }\n     // Enumerates all known workers' target. A target name is a\n     // prefix of a device name. E.g., /job:mnist/replica:0/task:10.\n     if (filters_.empty()) {\n       // If no filters were specified, we list all known workers in\n       // `worker_cache`.\n-      std::vector<string> workers;\n+      std::vector<std::string> workers;\n       worker_cache->ListWorkers(&workers);\n       std::swap(workers, targets_);\n     } else {\n       // When applying filters, we must include the local worker, even if it\n       // does not match any of the filters.\n       CHECK_GT(env_->local_devices.size(), 0) << \"No local devices provided.\";\n-      const string& local_device_name = env_->local_devices[0]->name();\n+      const std::string& local_device_name = env_->local_devices[0]->name();\n       DeviceNameUtils::ParsedName local_parsed_name;\n       CHECK(DeviceNameUtils::ParseFullName(local_device_name,\n                                            &local_parsed_name));\n       bool all_filters_have_job = true;\n-      std::unordered_set<string> filter_job_names({local_parsed_name.job});\n+      std::unordered_set<std::string> filter_job_names({local_parsed_name.job});\n       for (const DeviceNameUtils::ParsedName& filter : filters_) {\n         all_filters_have_job = all_filters_have_job && filter.has_job;\n         if (filter.has_job) {\n           filter_job_names.insert(filter.job);\n         }\n       }\n \n-      std::vector<string> workers;\n+      std::vector<std::string> workers;\n       if (all_filters_have_job) {\n         // If all of the device filters have a job specified, then we only need\n         // to list the workers in the jobs named in the filter, because a worker\n         // in any other job would not match any filter.\n-        for (const string& job_name : filter_job_names) {\n+        for (const std::string& job_name : filter_job_names) {\n           VLOG(2) << \"Selectively listing workers in job: \" << job_name;\n-          std::vector<string> workers_in_job;\n+          std::vector<std::string> workers_in_job;\n           worker_cache->ListWorkersInJob(job_name, &workers_in_job);\n           workers.insert(workers.end(), workers_in_job.begin(),\n                          workers_in_job.end());\n@@ -218,13 +219,13 @@ class DeviceFinder {\n         if (device_filters.empty()) {\n           VLOG(2) << \"- <NO FILTERS>\";\n         } else {\n-          for (const string& filter : device_filters) {\n+          for (const std::string& filter : device_filters) {\n             VLOG(2) << \"- \" << filter;\n           }\n         }\n         worker_cache->ListWorkers(&workers);\n       }\n-      for (const string& name : workers) {\n+      for (const std::string& name : workers) {\n         if (MatchFilters(name) ||\n             DeviceNameUtils::IsSameAddressSpace(name, local_device_name)) {\n           targets_.push_back(name);\n@@ -263,7 +264,7 @@ class DeviceFinder {\n   // Every `kLoggingPeriodMs`, while the DeviceFinder is still waiting\n   // to hear from workers, log a list of the workers who have not\n   // responded.\n-  const int32 kLoggingPeriodMs = 10 * 1000;\n+  const int32_t kLoggingPeriodMs = 10 * 1000;\n \n   absl::Status Wait() {\n     mutex_lock l(mu_);\n@@ -287,11 +288,11 @@ class DeviceFinder {\n   // The caller takes the ownership of returned remote devices.\n   void GetRemoteDevices(const std::vector<Device*>& local,\n                         std::vector<std::unique_ptr<Device>>* remote) {\n-    std::unordered_set<string> names(local.size());\n+    std::unordered_set<std::string> names(local.size());\n     for (Device* dev : local) names.insert(dev->name());\n     mutex_lock l(mu_);\n     for (Device* dev : found_) {\n-      const string& name = dev->name();\n+      const std::string& name = dev->name();\n       if (names.insert(name).second && MatchFilters(name)) {\n         remote->push_back(std::unique_ptr<Device>(dev));\n       } else {\n@@ -313,7 +314,7 @@ class DeviceFinder {\n   // List of targets to be contacted by this DeviceFinder. The\n   // respective `bool` in `seen_targets_` indicates whether we have\n   // heard from this target or not.\n-  std::vector<string> targets_;\n+  std::vector<std::string> targets_;\n   std::vector<bool> seen_targets_ TF_GUARDED_BY(mu_);\n   absl::Status status_;\n \n@@ -347,7 +348,7 @@ class DeviceFinder {\n   }\n \n   // Returns true iff 'name' matches one of the filters_.\n-  bool MatchFilters(const string& name) {\n+  bool MatchFilters(const std::string& name) {\n     if (filters_.empty()) return true;\n     DeviceNameUtils::ParsedName x;\n     if (DeviceNameUtils::ParseFullName(name, &x)) {\n@@ -386,7 +387,7 @@ void Master::CreateSession(const CreateSessionRequest* req,\n     if (!cluster_def.job().empty()) {\n       worker_cache_factory_options.cluster_def = cluster_def;\n       // If the target starts with gRPC protocol prefix, remove the prefix\n-      string normalized_string(req->target());\n+      std::string normalized_string(req->target());\n       RE2::Replace(&normalized_string, kGrpcPrefixRegex, \"\");\n \n       // Set the server_def's job_name and task_index fields.\n@@ -472,7 +473,7 @@ void Master::CreateSession(const CreateSessionRequest* req,\n     options.config.mutable_experimental()\n         ->set_disable_optimize_for_static_graph(true);\n \n-    std::vector<string> filtered_worker_list;\n+    std::vector<std::string> filtered_worker_list;\n     DeviceFinder::GetRemoteWorkers(req->config().device_filters(), env_,\n                                    worker_cache, &filtered_worker_list);\n \n@@ -555,7 +556,7 @@ void Master::RunStep(CallOptions* opts, const RunStepRequestWrapper* req,\n   SchedClosure([this, start_time, session, opts, req, resp, done]() {\n     absl::Status status = session->Run(opts, *req, resp);\n     session->Unref();\n-    uint64 done_time = env_->env->NowMicros();\n+    uint64_t done_time = env_->env->NowMicros();\n     done(status);\n     mutex_lock l(mu_);\n     last_1000_steps_.AddValue((done_time - start_time) / 1e9);\n@@ -624,7 +625,7 @@ void Master::ListDevices(const ListDevicesRequest* req,\n }\n \n void Master::CleanupWorkers(const ResetRequest& reset) {\n-  std::vector<string> worker_names;\n+  std::vector<std::string> worker_names;\n   DeviceFinder::GetRemoteWorkers(reset.device_filters(), env_,\n                                  env_->worker_cache, &worker_names);\n   if (!worker_names.empty()) {\n@@ -635,7 +636,7 @@ void Master::CleanupWorkers(const ResetRequest& reset) {\n     std::vector<CleanupAllResponse> resp(num_workers);\n     int c = 0;\n     for (int i = 0; i < num_workers; ++i) {\n-      const string& worker_name = worker_names[i];\n+      const std::string& worker_name = worker_names[i];\n       auto worker = env_->worker_cache->GetOrCreateWorker(worker_name);\n       if (worker) {\n         worker->CleanupAllAsync("
        },
        {
            "sha": "f39fd34d0a5900f54189a10c6b387589d7fb44c5",
            "filename": "tensorflow/core/distributed_runtime/master.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -84,7 +84,7 @@ class Master {\n   Thread* gc_thread_;\n \n   // Maps session handles to sessions.\n-  std::unordered_map<string, MasterSession*> sessions_ TF_GUARDED_BY(mu_);\n+  std::unordered_map<std::string, MasterSession*> sessions_ TF_GUARDED_BY(mu_);\n \n   // Moving average of step times.\n   MovingAverage last_1000_steps_ TF_GUARDED_BY(mu_);\n@@ -107,7 +107,7 @@ class Master {\n \n   // Find master session by session handle, and increments the reference count\n   // on the returned MasterSession if not null.\n-  MasterSession* FindMasterSession(const string& handle);\n+  MasterSession* FindMasterSession(const std::string& handle);\n \n   Master(const Master&) = delete;\n   void operator=(const Master&) = delete;"
        },
        {
            "sha": "5845a96836f9131947aca59f04bf9edf9c1d23ec",
            "filename": "tensorflow/core/distributed_runtime/master_env.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_env.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_env.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_env.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -41,7 +41,7 @@ class OpRegistryInterface;\n // Options passed to the worker_cache_factory function.\n struct WorkerCacheFactoryOptions {\n   ClusterDef cluster_def;\n-  string job_name;\n+  std::string job_name;\n   int task_index;\n   int replica_index = 0;\n   RPCOptions rpc_options;\n@@ -96,7 +96,7 @@ struct MasterEnv {\n       std::unique_ptr<std::vector<std::unique_ptr<Device>>>,\n       std::unique_ptr<WorkerCacheInterface>,\n       std::unique_ptr<DeviceSet> device_set,\n-      std::vector<string> filtered_worker_list)>\n+      std::vector<std::string> filtered_worker_list)>\n       master_session_factory;\n \n   std::function<absl::Status(const WorkerCacheFactoryOptions&,"
        },
        {
            "sha": "b24bdc24a765c8f277c3efd27035f9fca8155906",
            "filename": "tensorflow/core/distributed_runtime/master_session.cc",
            "status": "modified",
            "additions": 96,
            "deletions": 93,
            "changes": 189,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_session.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_session.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_session.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -75,7 +75,7 @@ namespace tensorflow {\n // TODO(zhifengc): Cleanup this class. It's becoming messy.\n class MasterSession::ReffedClientGraph : public core::RefCounted {\n  public:\n-  ReffedClientGraph(const string& handle, const BuildGraphOptions& bopts,\n+  ReffedClientGraph(const std::string& handle, const BuildGraphOptions& bopts,\n                     std::unique_ptr<ClientGraph> client_graph,\n                     const SessionOptions& session_opts,\n                     const StatsPublisherFactory& stats_publisher_factory,\n@@ -122,7 +122,7 @@ class MasterSession::ReffedClientGraph : public core::RefCounted {\n \n   int64_t collective_graph_key() { return collective_graph_key_; }\n \n-  std::unique_ptr<ProfileHandler> GetProfileHandler(uint64 step,\n+  std::unique_ptr<ProfileHandler> GetProfileHandler(uint64_t step,\n                                                     int64_t execution_count,\n                                                     const RunOptions& ropts) {\n     return stats_publisher_->GetProfileHandler(step, execution_count, ropts);\n@@ -239,7 +239,7 @@ class MasterSession::ReffedClientGraph : public core::RefCounted {\n                             GraphExecutionState* execution_state);\n \n  private:\n-  const string session_handle_;\n+  const std::string session_handle_;\n   const BuildGraphOptions bg_opts_;\n \n   // NOTE(mrry): This pointer will be null after `RegisterPartitions()` returns.\n@@ -250,13 +250,13 @@ class MasterSession::ReffedClientGraph : public core::RefCounted {\n   WorkerCacheInterface* const worker_cache_;  // Not owned.\n \n   struct NodeDetails {\n-    explicit NodeDetails(string type_string, string detail_text)\n+    explicit NodeDetails(std::string type_string, std::string detail_text)\n         : type_string(std::move(type_string)),\n           detail_text(std::move(detail_text)) {}\n-    const string type_string;\n-    const string detail_text;\n+    const std::string type_string;\n+    const std::string detail_text;\n   };\n-  std::unordered_map<string, NodeDetails> name_to_node_details_;\n+  std::unordered_map<std::string, NodeDetails> name_to_node_details_;\n \n   const bool should_deregister_;\n   const int64_t collective_graph_key_;\n@@ -265,20 +265,20 @@ class MasterSession::ReffedClientGraph : public core::RefCounted {\n   // Graph partitioned into per-location subgraphs.\n   struct Part {\n     // Worker name.\n-    string name;\n+    std::string name;\n \n     // Maps feed names to rendezvous keys. Empty most of the time.\n-    std::unordered_map<string, string> feed_key;\n+    std::unordered_map<std::string, std::string> feed_key;\n \n     // Maps rendezvous keys to fetch names. Empty most of the time.\n-    std::unordered_map<string, string> key_fetch;\n+    std::unordered_map<std::string, std::string> key_fetch;\n \n     // The interface to the worker. Owned.\n     WorkerInterface* worker = nullptr;\n \n     // After registration with the worker, graph_handle identifies\n     // this partition on the worker.\n-    string graph_handle;\n+    std::string graph_handle;\n \n     Part() : feed_key(3), key_fetch(3) {}\n   };\n@@ -300,14 +300,15 @@ class MasterSession::ReffedClientGraph : public core::RefCounted {\n \n   std::unique_ptr<StatsPublisherInterface> stats_publisher_;\n \n-  string DetailText(const NodeDetails& details, const NodeExecStats& stats) {\n+  std::string DetailText(const NodeDetails& details,\n+                         const NodeExecStats& stats) {\n     int64_t tot = 0;\n     for (auto& no : stats.output()) {\n       tot += no.tensor_description().allocation_description().requested_bytes();\n     }\n-    string bytes;\n+    std::string bytes;\n     if (tot >= 0.1 * 1048576.0) {\n-      bytes = strings::Printf(\"[%.1fMB] \", tot / 1048576.0);\n+      bytes = absl::StrFormat(\"[%.1fMB] \", tot / 1048576.0);\n     }\n     return strings::StrCat(bytes, stats.node_name(), \" = \", details.type_string,\n                            details.detail_text);\n@@ -322,10 +323,10 @@ class MasterSession::ReffedClientGraph : public core::RefCounted {\n   // The actual graph partitioning and registration implementation.\n   absl::Status DoBuildPartitions(\n       PartitionOptions popts, ClientGraph* client_graph,\n-      std::unordered_map<string, GraphDef>* out_partitions);\n+      std::unordered_map<std::string, GraphDef>* out_partitions);\n   absl::Status DoRegisterPartitions(\n       const PartitionOptions& popts,\n-      std::unordered_map<string, GraphDef> graph_partitions);\n+      std::unordered_map<std::string, GraphDef> graph_partitions);\n \n   // Prepares a number of calls to workers. One call per partition.\n   // This is a generic method that handles Run, PartialRun, and RunCallable.\n@@ -359,7 +360,7 @@ absl::Status MasterSession::ReffedClientGraph::RegisterPartitions(\n       std::unique_ptr<ClientGraph> client_graph;\n       std::swap(client_graph_before_register_, client_graph);\n       mu_.unlock();\n-      std::unordered_map<string, GraphDef> graph_defs;\n+      std::unordered_map<std::string, GraphDef> graph_defs;\n       popts.flib_def = client_graph->flib_def.get();\n       absl::Status s =\n           DoBuildPartitions(popts, client_graph.get(), &graph_defs);\n@@ -390,9 +391,9 @@ absl::Status MasterSession::ReffedClientGraph::RegisterPartitions(\n   }\n }\n \n-static string SplitByWorker(const Node* node) {\n-  string task;\n-  string device;\n+static std::string SplitByWorker(const Node* node) {\n+  std::string task;\n+  std::string device;\n   CHECK(DeviceNameUtils::SplitDeviceName(node->assigned_device_name(), &task,\n                                          &device))\n       << \"node: \" << node->name() << \" dev: \" << node->assigned_device_name();\n@@ -413,17 +414,17 @@ void MasterSession::ReffedClientGraph::TrackFeedsAndFetches(\n       bool client_terminated;\n       TF_CHECK_OK(GetNodeAttr(ndef, \"client_terminated\", &client_terminated));\n       if (client_terminated) {\n-        string name;\n+        std::string name;\n         TF_CHECK_OK(GetNodeAttr(ndef, \"tensor_name\", &name));\n-        string send_device;\n+        std::string send_device;\n         TF_CHECK_OK(GetNodeAttr(ndef, \"send_device\", &send_device));\n-        string recv_device;\n+        std::string recv_device;\n         TF_CHECK_OK(GetNodeAttr(ndef, \"recv_device\", &recv_device));\n-        uint64 send_device_incarnation;\n+        uint64_t send_device_incarnation;\n         TF_CHECK_OK(\n             GetNodeAttr(ndef, \"send_device_incarnation\",\n                         reinterpret_cast<int64_t*>(&send_device_incarnation)));\n-        const string& key =\n+        const std::string& key =\n             Rendezvous::CreateKey(send_device, send_device_incarnation,\n                                   recv_device, name, FrameAndIter(0, 0));\n \n@@ -439,7 +440,7 @@ void MasterSession::ReffedClientGraph::TrackFeedsAndFetches(\n \n absl::Status MasterSession::ReffedClientGraph::DoBuildPartitions(\n     PartitionOptions popts, ClientGraph* client_graph,\n-    std::unordered_map<string, GraphDef>* out_partitions) {\n+    std::unordered_map<std::string, GraphDef>* out_partitions) {\n   if (popts.need_to_record_start_times) {\n     CostModel cost_model(true);\n     cost_model.InitFromGraph(client_graph->graph);\n@@ -455,7 +456,7 @@ absl::Status MasterSession::ReffedClientGraph::DoBuildPartitions(\n \n absl::Status MasterSession::ReffedClientGraph::DoRegisterPartitions(\n     const PartitionOptions& popts,\n-    std::unordered_map<string, GraphDef> graph_partitions) {\n+    std::unordered_map<std::string, GraphDef> graph_partitions) {\n   partitions_.reserve(graph_partitions.size());\n   absl::Status s;\n   for (auto& name_def : graph_partitions) {\n@@ -524,7 +525,7 @@ class RunManyGraphs {\n   // Returns the index-th call.\n   struct Call {\n     CallOptions opts;\n-    const string* worker_name;\n+    const std::string* worker_name;\n     std::atomic<bool> done{false};\n     std::unique_ptr<MutableRunGraphRequestWrapper> req;\n     std::unique_ptr<MutableRunGraphResponseWrapper> resp;\n@@ -625,27 +626,29 @@ class RunManyGraphs {\n \n absl::Status AddSendFromClientRequest(const RunStepRequestWrapper& client_req,\n                                       MutableRunGraphRequestWrapper* worker_req,\n-                                      size_t index, const string& send_key) {\n+                                      size_t index,\n+                                      const std::string& send_key) {\n   return worker_req->AddSendFromRunStepRequest(client_req, index, send_key);\n }\n \n absl::Status AddSendFromClientRequest(const RunCallableRequest& client_req,\n                                       MutableRunGraphRequestWrapper* worker_req,\n-                                      size_t index, const string& send_key) {\n+                                      size_t index,\n+                                      const std::string& send_key) {\n   return worker_req->AddSendFromRunCallableRequest(client_req, index, send_key);\n }\n \n // TODO(mrry): Add a full-fledged wrapper that avoids TensorProto copies for\n // in-process messages.\n struct RunCallableResponseWrapper {\n   RunCallableResponse* resp;  // Not owned.\n-  std::unordered_map<string, TensorProto> fetch_key_to_protos;\n+  std::unordered_map<std::string, TensorProto> fetch_key_to_protos;\n \n   RunMetadata* mutable_metadata() { return resp->mutable_metadata(); }\n \n   absl::Status AddTensorFromRunGraphResponse(\n-      const string& tensor_name, MutableRunGraphResponseWrapper* worker_resp,\n-      size_t index) {\n+      const std::string& tensor_name,\n+      MutableRunGraphResponseWrapper* worker_resp, size_t index) {\n     return worker_resp->RecvValue(index, &fetch_key_to_protos[tensor_name]);\n   }\n };\n@@ -709,18 +712,18 @@ absl::Status MasterSession::ReffedClientGraph::RunPartitionsHelper(\n     // inadvertently slowing down the normal run path.\n     if (is_partial_) {\n       for (const auto& name_index : feeds) {\n-        const auto iter = part.feed_key.find(string(name_index.first));\n+        const auto iter = part.feed_key.find(std::string(name_index.first));\n         if (iter == part.feed_key.end()) {\n           // The provided feed must be for a different partition.\n           continue;\n         }\n-        const string& key = iter->second;\n+        const std::string& key = iter->second;\n         TF_RETURN_IF_ERROR(AddSendFromClientRequest(req, c->req.get(),\n                                                     name_index.second, key));\n       }\n       // TODO(suharshs): Make a map from feed to fetch_key to make this faster.\n       // For now, we just iterate through partitions to find the matching key.\n-      for (const string& req_fetch : fetches) {\n+      for (const std::string& req_fetch : fetches) {\n         for (const auto& key_fetch : part.key_fetch) {\n           if (key_fetch.second == req_fetch) {\n             c->req->add_recv_key(key_fetch.first);\n@@ -730,8 +733,8 @@ absl::Status MasterSession::ReffedClientGraph::RunPartitionsHelper(\n       }\n     } else {\n       for (const auto& feed_key : part.feed_key) {\n-        const string& feed = feed_key.first;\n-        const string& key = feed_key.second;\n+        const std::string& feed = feed_key.first;\n+        const std::string& key = feed_key.second;\n         auto iter = feeds.find(feed);\n         if (iter == feeds.end()) {\n           return errors::Internal(\"No feed index found for feed: \", feed);\n@@ -741,7 +744,7 @@ absl::Status MasterSession::ReffedClientGraph::RunPartitionsHelper(\n             AddSendFromClientRequest(req, c->req.get(), feed_index, key));\n       }\n       for (const auto& key_fetch : part.key_fetch) {\n-        const string& key = key_fetch.first;\n+        const std::string& key = key_fetch.first;\n         c->req->add_recv_key(key);\n       }\n     }\n@@ -790,7 +793,7 @@ absl::Status MasterSession::ReffedClientGraph::RunPartitionsHelper(\n                                        run_graph_resp->recv_key(j)));\n         break;\n       }\n-      const string& fetch = iter->second;\n+      const std::string& fetch = iter->second;\n       status.Update(\n           resp->AddTensorFromRunGraphResponse(fetch, run_graph_resp, j));\n       if (!status.ok()) {\n@@ -834,7 +837,7 @@ absl::Status MasterSession::ReffedClientGraph::RunPartitions(\n     }\n   }\n \n-  std::vector<string> fetches;\n+  std::vector<std::string> fetches;\n   fetches.reserve(req.num_fetches());\n   for (size_t i = 0; i < req.num_fetches(); ++i) {\n     fetches.push_back(req.fetch_name(i));\n@@ -870,7 +873,7 @@ absl::Status MasterSession::ReffedClientGraph::RunPartitions(\n       call_opts, req, &wrapped_resp, cm, false /* is_last_partial_run */));\n \n   // Collects fetches.\n-  for (const string& fetch : callable_opts_.fetch()) {\n+  for (const std::string& fetch : callable_opts_.fetch()) {\n     TensorProto* fetch_proto = resp->mutable_fetch()->Add();\n     auto iter = wrapped_resp.fetch_key_to_protos.find(fetch);\n     if (iter == wrapped_resp.fetch_key_to_protos.end()) {\n@@ -1001,7 +1004,7 @@ void MasterSession::ReffedClientGraph::ProcessStats(int64_t step_id,\n \n void MasterSession::ReffedClientGraph::ProcessDeviceStats(\n     ProfileHandler* ph, const DeviceStepStats& ds, bool is_rpc) {\n-  const string& dev_name = ds.device();\n+  const std::string& dev_name = ds.device();\n   VLOG(1) << \"Device \" << dev_name << \" reports stats for \"\n           << ds.node_stats_size() << \" nodes\";\n   for (const auto& ns : ds.node_stats()) {\n@@ -1026,9 +1029,9 @@ void MasterSession::ReffedClientGraph::ProcessDeviceStats(\n         }\n         continue;\n       }\n-      const string& optype =\n+      const std::string& optype =\n           found_node_in_graph ? iter->second.type_string : ns.node_name();\n-      string details;\n+      std::string details;\n       if (!ns.timeline_label().empty()) {\n         details = ns.timeline_label();\n       } else if (found_node_in_graph) {\n@@ -1055,7 +1058,7 @@ absl::Status MasterSession::ReffedClientGraph::CheckFetches(\n     // Skip if already fed.\n     if (input.second) continue;\n     TensorId id(ParseTensorName(input.first));\n-    const Node* n = execution_state->get_node_by_name(string(id.first));\n+    const Node* n = execution_state->get_node_by_name(std::string(id.first));\n     if (n == nullptr) {\n       return errors::NotFound(\"Feed \", input.first, \": not found\");\n     }\n@@ -1069,9 +1072,9 @@ absl::Status MasterSession::ReffedClientGraph::CheckFetches(\n   // Initialize the stack with the fetch nodes.\n   std::vector<const Node*> stack;\n   for (size_t i = 0; i < req.num_fetches(); ++i) {\n-    const string& fetch = req.fetch_name(i);\n+    const std::string& fetch = req.fetch_name(i);\n     const TensorId id(ParseTensorName(fetch));\n-    const Node* n = execution_state->get_node_by_name(string(id.first));\n+    const Node* n = execution_state->get_node_by_name(std::string(id.first));\n     if (n == nullptr) {\n       return errors::NotFound(\"Fetch \", fetch, \": not found\");\n     }\n@@ -1120,7 +1123,7 @@ void MasterSession::ReffedClientGraph::DeregisterPartitions() {\n       // NOTE(mrry): We must capture `worker_cache_` since `this`\n       // could be deleted before the callback is called.\n       WorkerCacheInterface* worker_cache = worker_cache_;\n-      const string name = part.name;\n+      const std::string name = part.name;\n       WorkerInterface* w = part.worker;\n       CHECK_NOTNULL(w);\n       auto cb = [worker_cache, c, name, w](const absl::Status& s) {\n@@ -1138,10 +1141,10 @@ void MasterSession::ReffedClientGraph::DeregisterPartitions() {\n }\n \n namespace {\n-void CopyAndSortStrings(size_t size,\n-                        const std::function<string(size_t)>& input_accessor,\n-                        protobuf::RepeatedPtrField<string>* output) {\n-  std::vector<string> temp;\n+void CopyAndSortStrings(\n+    size_t size, const std::function<std::string(size_t)>& input_accessor,\n+    protobuf::RepeatedPtrField<std::string>* output) {\n+  std::vector<std::string> temp;\n   temp.reserve(size);\n   for (size_t i = 0; i < size; ++i) {\n     output->Add(input_accessor(i));\n@@ -1194,40 +1197,40 @@ void BuildBuildGraphOptions(const PartialRunSetupRequest& req,\n   // TODO(cais): Add TFDBG support to partial runs.\n }\n \n-uint64 HashBuildGraphOptions(const BuildGraphOptions& opts) {\n-  uint64 h = 0x2b992ddfa23249d6ull;\n-  for (const string& name : opts.callable_options.feed()) {\n+uint64_t HashBuildGraphOptions(const BuildGraphOptions& opts) {\n+  uint64_t h = 0x2b992ddfa23249d6ull;\n+  for (const std::string& name : opts.callable_options.feed()) {\n     h = Hash64(name.c_str(), name.size(), h);\n   }\n-  for (const string& name : opts.callable_options.target()) {\n+  for (const std::string& name : opts.callable_options.target()) {\n     h = Hash64(name.c_str(), name.size(), h);\n   }\n-  for (const string& name : opts.callable_options.fetch()) {\n+  for (const std::string& name : opts.callable_options.fetch()) {\n     h = Hash64(name.c_str(), name.size(), h);\n   }\n \n   const DebugOptions& debug_options =\n       opts.callable_options.run_options().debug_options();\n   if (!debug_options.debug_tensor_watch_opts().empty()) {\n-    const string watch_summary =\n+    const std::string watch_summary =\n         SummarizeDebugTensorWatches(debug_options.debug_tensor_watch_opts());\n     h = Hash64(watch_summary.c_str(), watch_summary.size(), h);\n   }\n \n   return h;\n }\n \n-string BuildGraphOptionsString(const BuildGraphOptions& opts) {\n-  string buf;\n-  for (const string& name : opts.callable_options.feed()) {\n+std::string BuildGraphOptionsString(const BuildGraphOptions& opts) {\n+  std::string buf;\n+  for (const std::string& name : opts.callable_options.feed()) {\n     absl::StrAppend(&buf, \" FdE: \", name);\n   }\n   absl::StrAppend(&buf, \"\\n\");\n-  for (const string& name : opts.callable_options.target()) {\n+  for (const std::string& name : opts.callable_options.target()) {\n     absl::StrAppend(&buf, \" TN: \", name);\n   }\n   absl::StrAppend(&buf, \"\\n\");\n-  for (const string& name : opts.callable_options.fetch()) {\n+  for (const std::string& name : opts.callable_options.fetch()) {\n     absl::StrAppend(&buf, \" FeE: \", name);\n   }\n   if (opts.collective_graph_key != BuildGraphOptions::kNoCollectiveGraphKey) {\n@@ -1242,7 +1245,7 @@ MasterSession::MasterSession(\n     std::unique_ptr<std::vector<std::unique_ptr<Device>>> remote_devs,\n     std::unique_ptr<WorkerCacheInterface> worker_cache,\n     std::unique_ptr<DeviceSet> device_set,\n-    std::vector<string> filtered_worker_list,\n+    std::vector<std::string> filtered_worker_list,\n     StatsPublisherFactory stats_publisher_factory)\n     : session_opts_(opt),\n       env_(env),\n@@ -1301,12 +1304,12 @@ absl::Status MasterSession::Create(GraphDef&& graph_def,\n \n absl::Status MasterSession::CreateWorkerSessions(\n     const ClusterDef& cluster_def) {\n-  const std::vector<string> worker_names = filtered_worker_list_;\n+  const std::vector<std::string> worker_names = filtered_worker_list_;\n   WorkerCacheInterface* worker_cache = get_worker_cache();\n \n   struct WorkerGroup {\n     // The worker name. (Not owned.)\n-    const string* name;\n+    const std::string* name;\n \n     // The worker referenced by name. (Not owned.)\n     WorkerInterface* worker = nullptr;\n@@ -1328,8 +1331,8 @@ absl::Status MasterSession::CreateWorkerSessions(\n     }\n   });\n \n-  string task_name;\n-  string local_device_name;\n+  std::string task_name;\n+  std::string local_device_name;\n   DeviceNameUtils::SplitDeviceName(devices_->client_device()->name(),\n                                    &task_name, &local_device_name);\n   const int64_t client_device_incarnation =\n@@ -1435,11 +1438,11 @@ absl::Status MasterSession::CreateWorkerSessions(\n \n absl::Status MasterSession::DeleteWorkerSessions() {\n   WorkerCacheInterface* worker_cache = get_worker_cache();\n-  const std::vector<string>& worker_names = filtered_worker_list_;\n+  const std::vector<std::string>& worker_names = filtered_worker_list_;\n \n   struct WorkerGroup {\n     // The worker name. (Not owned.)\n-    const string* name;\n+    const std::string* name;\n \n     // The worker referenced by name. (Not owned.)\n     WorkerInterface* worker = nullptr;\n@@ -1554,7 +1557,7 @@ absl::Status MasterSession::StartStep(const BuildGraphOptions& opts,\n                                       bool is_partial,\n                                       ReffedClientGraph** out_rcg,\n                                       int64_t* out_count) {\n-  const uint64 hash = HashBuildGraphOptions(opts);\n+  const uint64_t hash = HashBuildGraphOptions(opts);\n   {\n     mutex_lock l(mu_);\n     // TODO(suharshs): We cache partial run graphs and run graphs separately\n@@ -1599,12 +1602,12 @@ void MasterSession::ClearRunsTable(std::vector<ReffedClientGraph*>* to_unref,\n   rcg_map->clear();\n }\n \n-uint64 MasterSession::NewStepId(int64_t graph_key) {\n+uint64_t MasterSession::NewStepId(int64_t graph_key) {\n   if (graph_key == BuildGraphOptions::kNoCollectiveGraphKey) {\n     // StepId must leave the most-significant 7 bits empty for future use.\n     return random::New64() & (((1uLL << 56) - 1) | (1uLL << 56));\n   } else {\n-    uint64 step_id = env_->collective_executor_mgr->NextStepId(graph_key);\n+    uint64_t step_id = env_->collective_executor_mgr->NextStepId(graph_key);\n     int32_t retry_count = 0;\n     while (static_cast<int64_t>(step_id) == CollectiveExecutor::kInvalidId) {\n       absl::Notification note;\n@@ -1631,7 +1634,7 @@ uint64 MasterSession::NewStepId(int64_t graph_key) {\n \n absl::Status MasterSession::PartialRunSetup(const PartialRunSetupRequest* req,\n                                             PartialRunSetupResponse* resp) {\n-  std::vector<string> inputs, outputs, targets;\n+  std::vector<std::string> inputs, outputs, targets;\n   for (const auto& feed : req->feed()) {\n     inputs.push_back(feed);\n   }\n@@ -1642,7 +1645,7 @@ absl::Status MasterSession::PartialRunSetup(const PartialRunSetupRequest* req,\n     targets.push_back(target);\n   }\n \n-  string handle = std::to_string(partial_run_handle_counter_.fetch_add(1));\n+  std::string handle = std::to_string(partial_run_handle_counter_.fetch_add(1));\n \n   ReffedClientGraph* rcg = nullptr;\n \n@@ -1706,11 +1709,11 @@ absl::Status MasterSession::BuildAndRegisterPartitions(ReffedClientGraph* rcg) {\n   // The closures popts.{new_name,get_incarnation} are called synchronously in\n   // RegisterPartitions() below, so do not need a Ref()/Unref() pair to keep\n   // \"this\" alive during the closure.\n-  popts.new_name = [this](const string& prefix) {\n+  popts.new_name = [this](const std::string& prefix) {\n     mutex_lock l(mu_);\n     return absl::StrCat(prefix, \"_S\", next_node_id_++);\n   };\n-  popts.get_incarnation = [this](const string& name) -> int64 {\n+  popts.get_incarnation = [this](const std::string& name) -> int64_t {\n     Device* d = devices_->FindDeviceByName(name);\n     if (d == nullptr) {\n       return PartitionOptions::kIllegalIncarnation;\n@@ -1746,7 +1749,7 @@ absl::Status MasterSession::DoPartialRun(CallOptions* opts,\n                                          const RunStepRequestWrapper& req,\n                                          MutableRunStepResponseWrapper* resp) {\n   auto cleanup = gtl::MakeCleanup([this] { MarkRunCompletion(); });\n-  const string& prun_handle = req.partial_run_handle();\n+  const std::string& prun_handle = req.partial_run_handle();\n   RunState* run_state = nullptr;\n   {\n     mutex_lock l(mu_);\n@@ -1802,7 +1805,7 @@ absl::Status MasterSession::DoPartialRun(CallOptions* opts,\n \n   // Make sure that this is a new set of feeds that are still pending.\n   for (size_t i = 0; i < req.num_feeds(); ++i) {\n-    const string& feed = req.feed_name(i);\n+    const std::string& feed = req.feed_name(i);\n     auto it = run_state->pending_inputs.find(feed);\n     if (it == run_state->pending_inputs.end()) {\n       return errors::InvalidArgument(\n@@ -1814,7 +1817,7 @@ absl::Status MasterSession::DoPartialRun(CallOptions* opts,\n   }\n   // Check that this is a new set of fetches that are still pending.\n   for (size_t i = 0; i < req.num_fetches(); ++i) {\n-    const string& fetch = req.fetch_name(i);\n+    const std::string& fetch = req.fetch_name(i);\n     auto it = run_state->pending_outputs.find(fetch);\n     if (it == run_state->pending_outputs.end()) {\n       return errors::InvalidArgument(\n@@ -1879,17 +1882,17 @@ absl::Status MasterSession::CreateDebuggerState(\n   TF_RETURN_IF_ERROR(\n       DebuggerStateRegistry::CreateState(debug_options, debugger_state));\n \n-  std::vector<string> input_names;\n+  std::vector<std::string> input_names;\n   input_names.reserve(req.num_feeds());\n   for (size_t i = 0; i < req.num_feeds(); ++i) {\n     input_names.push_back(req.feed_name(i));\n   }\n-  std::vector<string> output_names;\n+  std::vector<std::string> output_names;\n   output_names.reserve(req.num_fetches());\n   for (size_t i = 0; i < req.num_fetches(); ++i) {\n     output_names.push_back(req.fetch_name(i));\n   }\n-  std::vector<string> target_names;\n+  std::vector<std::string> target_names;\n   target_names.reserve(req.num_targets());\n   for (size_t i = 0; i < req.num_targets(); ++i) {\n     target_names.push_back(req.target_name(i));\n@@ -1908,7 +1911,7 @@ absl::Status MasterSession::CreateDebuggerState(\n \n void MasterSession::FillPerStepState(MasterSession::ReffedClientGraph* rcg,\n                                      const RunOptions& run_options,\n-                                     uint64 step_id, int64_t count,\n+                                     uint64_t step_id, int64_t count,\n                                      PerStepState* out_pss,\n                                      std::unique_ptr<ProfileHandler>* out_ph) {\n   out_pss->collect_timeline =\n@@ -1935,7 +1938,7 @@ void MasterSession::FillPerStepState(MasterSession::ReffedClientGraph* rcg,\n }\n \n absl::Status MasterSession::PostRunCleanup(\n-    MasterSession::ReffedClientGraph* rcg, uint64 step_id,\n+    MasterSession::ReffedClientGraph* rcg, uint64_t step_id,\n     const RunOptions& run_options, PerStepState* pss,\n     const std::unique_ptr<ProfileHandler>& ph, const absl::Status& run_status,\n     RunMetadata* out_run_metadata) {\n@@ -2004,7 +2007,7 @@ absl::Status MasterSession::DoRunWithLocalExecution(\n \n   // Keeps the highest 8 bits 0x01: we reserve some bits of the\n   // step_id for future use.\n-  uint64 step_id = NewStepId(rcg->collective_graph_key());\n+  uint64_t step_id = NewStepId(rcg->collective_graph_key());\n   TRACEPRINTF(\"stepid %llu\", step_id);\n \n   std::unique_ptr<ProfileHandler> ph;\n@@ -2054,7 +2057,7 @@ absl::Status MasterSession::MakeCallable(const MakeCallableRequest& req,\n     return s;\n   }\n \n-  uint64 handle;\n+  uint64_t handle;\n   {\n     mutex_lock l(mu_);\n     handle = next_callable_handle_++;\n@@ -2077,7 +2080,7 @@ absl::Status MasterSession::DoRunCallable(CallOptions* opts,\n   // Prepare.\n   int64_t count = rcg->get_and_increment_execution_count();\n \n-  const uint64 step_id = NewStepId(rcg->collective_graph_key());\n+  const uint64_t step_id = NewStepId(rcg->collective_graph_key());\n   TRACEPRINTF(\"stepid %llu\", step_id);\n \n   const RunOptions& run_options = rcg->callable_options().run_options();\n@@ -2176,10 +2179,10 @@ void MasterSession::GarbageCollect() {\n   Unref();\n }\n \n-MasterSession::RunState::RunState(const std::vector<string>& input_names,\n-                                  const std::vector<string>& output_names,\n-                                  ReffedClientGraph* rcg, const uint64 step_id,\n-                                  const int64_t count)\n+MasterSession::RunState::RunState(const std::vector<std::string>& input_names,\n+                                  const std::vector<std::string>& output_names,\n+                                  ReffedClientGraph* rcg,\n+                                  const uint64_t step_id, const int64_t count)\n     : rcg(rcg), step_id(step_id), count(count) {\n   // Initially all the feeds and fetches are pending.\n   for (auto& name : input_names) {"
        },
        {
            "sha": "b22953547b8f7c513ff0f8e1280236dfc1f8c8e1",
            "filename": "tensorflow/core/distributed_runtime/master_session.h",
            "status": "modified",
            "additions": 21,
            "deletions": 18,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_session.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_session.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_session.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -52,19 +52,21 @@ class MasterSession : public core::RefCounted {\n       std::unique_ptr<std::vector<std::unique_ptr<Device>>> remote_devs,\n       std::unique_ptr<WorkerCacheInterface> worker_cache,\n       std::unique_ptr<DeviceSet> device_set,\n-      std::vector<string> filtered_worker_list,\n+      std::vector<std::string> filtered_worker_list,\n       StatsPublisherFactory stats_publisher_factory);\n \n   // Initialize the MasterSession for \"def\".  Must be called before Extend(),\n   // Run(), or Close().\n   absl::Status Create(GraphDef&& def, const ClusterDef& cluster_def);\n \n   // Returns the session handle.\n-  const string& handle() const { return handle_; }\n+  const std::string& handle() const { return handle_; }\n \n   // Returns the last access time (the number of micro-seconds since\n   // some fixed point in time) of this session.\n-  uint64 last_access_time_usec() const { return last_access_time_usec_.load(); }\n+  uint64_t last_access_time_usec() const {\n+    return last_access_time_usec_.load();\n+  }\n \n   // Attempt to extend the graph according to the given \"req\".\n   // (See master.proto for details of valid extensions.)\n@@ -117,7 +119,7 @@ class MasterSession : public core::RefCounted {\n   const MasterEnv* env_;\n \n   // The opaque session handle.\n-  const string handle_;\n+  const std::string handle_;\n \n   std::unique_ptr<std::vector<std::unique_ptr<Device>>> remote_devs_;\n \n@@ -132,15 +134,15 @@ class MasterSession : public core::RefCounted {\n \n   // The (partial device) names of remote worker tasks that this\n   // session will contact.\n-  const std::vector<string> filtered_worker_list_;\n+  const std::vector<std::string> filtered_worker_list_;\n \n   StatsPublisherFactory stats_publisher_factory_;\n \n   std::atomic_ulong last_access_time_usec_;\n \n   std::atomic<int64_t> partial_run_handle_counter_ = {0};\n \n-  uint64 NewStepId(int64_t graph_key);\n+  uint64_t NewStepId(int64_t graph_key);\n \n   mutex mu_;\n   std::unique_ptr<GraphExecutionState> execution_state_ TF_GUARDED_BY(mu_);\n@@ -152,7 +154,7 @@ class MasterSession : public core::RefCounted {\n   // before a new substitute has been created, Variables can go out of\n   // scope and lose their state.\n   class ReffedClientGraph;\n-  typedef std::unordered_map<uint64, ReffedClientGraph*> RCGMap;\n+  typedef std::unordered_map<uint64_t, ReffedClientGraph*> RCGMap;\n   RCGMap run_graphs_ TF_GUARDED_BY(mu_);\n   RCGMap partial_run_graphs_ TF_GUARDED_BY(mu_);\n   int64_t next_callable_handle_ TF_GUARDED_BY(mu_) = 0;\n@@ -172,35 +174,36 @@ class MasterSession : public core::RefCounted {\n   };\n \n   struct RunState {\n-    std::unordered_map<string, bool> pending_inputs;   // true if fed\n-    std::unordered_map<string, bool> pending_outputs;  // true if fetched\n+    std::unordered_map<std::string, bool> pending_inputs;   // true if fed\n+    std::unordered_map<std::string, bool> pending_outputs;  // true if fetched\n     ReffedClientGraph* rcg = nullptr;\n-    uint64 step_id;\n+    uint64_t step_id;\n     int64_t collective_graph_key;\n     int64_t count = 0;\n     PerStepState pss;\n     std::unique_ptr<ProfileHandler> ph;\n     bool step_started = false;\n \n-    RunState(const std::vector<string>& input_names,\n-             const std::vector<string>& output_names, ReffedClientGraph* rcg,\n-             const uint64 step_id, const int64_t count);\n+    RunState(const std::vector<std::string>& input_names,\n+             const std::vector<std::string>& output_names,\n+             ReffedClientGraph* rcg, const uint64_t step_id,\n+             const int64_t count);\n \n     bool PendingDone() const;\n \n     ~RunState();\n   };\n-  std::unordered_map<string, std::unique_ptr<RunState>> partial_runs_\n+  std::unordered_map<std::string, std::unique_ptr<RunState>> partial_runs_\n       TF_GUARDED_BY(mu_);\n \n   // Active RunStep calls.\n   condition_variable num_running_is_zero_;\n-  int32 num_running_ TF_GUARDED_BY(mu_) = 0;\n+  int32_t num_running_ TF_GUARDED_BY(mu_) = 0;\n \n   bool closed_ TF_GUARDED_BY(mu_) = false;\n   bool garbage_collected_ TF_GUARDED_BY(mu_) = false;\n \n-  std::unordered_map<uint64, int64_t> subgraph_execution_counts_\n+  std::unordered_map<uint64_t, int64_t> subgraph_execution_counts_\n       TF_GUARDED_BY(mu_);\n \n   // We need to ensure that certain nodes added (e.g., send and recv\n@@ -228,7 +231,7 @@ class MasterSession : public core::RefCounted {\n   void ClearRunsTable(std::vector<ReffedClientGraph*>* to_unref,\n                       RCGMap* rcg_map) TF_EXCLUSIVE_LOCKS_REQUIRED(mu_);\n   void FillPerStepState(MasterSession::ReffedClientGraph* rcg,\n-                        const RunOptions& run_options, uint64 step_id,\n+                        const RunOptions& run_options, uint64_t step_id,\n                         int64_t count, PerStepState* out_pss,\n                         std::unique_ptr<ProfileHandler>* out_ph);\n   absl::Status DoRunWithLocalExecution(CallOptions* opts,\n@@ -240,7 +243,7 @@ class MasterSession : public core::RefCounted {\n                              const RunCallableRequest& req,\n                              RunCallableResponse* resp);\n   absl::Status PostRunCleanup(MasterSession::ReffedClientGraph* rcg,\n-                              uint64 step_id, const RunOptions& run_options,\n+                              uint64_t step_id, const RunOptions& run_options,\n                               PerStepState* pss,\n                               const std::unique_ptr<ProfileHandler>& ph,\n                               const absl::Status& run_status,"
        },
        {
            "sha": "8269f1dca201cd72f35d5eb2a923b4e418da8fd3",
            "filename": "tensorflow/core/distributed_runtime/master_test.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 17,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fmaster_test.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -44,7 +44,7 @@ namespace tensorflow {\n class MasterTest : public ::testing::Test {\n  protected:\n   MasterTest() {\n-    std::vector<string> targets;\n+    std::vector<std::string> targets;\n     SessionOptions options;\n     (*options.config.mutable_device_count())[\"CPU\"] = 1;\n     (*options.config.mutable_device_count())[\"GPU\"] = 0;\n@@ -64,7 +64,7 @@ class MasterTest : public ::testing::Test {\n   // Helpers for MasterService.{CreateSession,RunStep,CloseSession}\n   // rpc calls.\n \n-  absl::Status CreateSession(const GraphDef& def, string* handle,\n+  absl::Status CreateSession(const GraphDef& def, std::string* handle,\n                              int64_t* initial_version) {\n     ::grpc::ClientContext ctx;\n     CreateSessionRequest req;\n@@ -81,7 +81,7 @@ class MasterTest : public ::testing::Test {\n     return s;\n   }\n \n-  absl::Status ExtendSession(const string& handle, const GraphDef& def,\n+  absl::Status ExtendSession(const std::string& handle, const GraphDef& def,\n                              int64_t current_version, int64_t* new_version) {\n     ::grpc::ClientContext ctx;\n     ExtendSessionRequest req;\n@@ -98,21 +98,21 @@ class MasterTest : public ::testing::Test {\n   }\n \n   absl::Status RunStep(\n-      const string& handle,\n-      const std::vector<std::pair<string, const Tensor*> >& feed,\n-      const std::map<string, Tensor*>& fetch) {\n+      const std::string& handle,\n+      const std::vector<std::pair<std::string, const Tensor*> >& feed,\n+      const std::map<std::string, Tensor*>& fetch) {\n     ::grpc::ClientContext ctx;\n     RunStepRequest req;\n     req.set_session_handle(handle);\n     for (const auto& p : feed) {\n-      const string& feed_name = p.first;\n+      const std::string& feed_name = p.first;\n       const Tensor* feed_tensor = p.second;\n       auto f = req.add_feed();\n       f->set_name(feed_name);\n       feed_tensor->AsProtoTensorContent(f->mutable_tensor());\n     }\n     for (const auto& p : fetch) {\n-      const string& fetch_name = p.first;\n+      const std::string& fetch_name = p.first;\n       req.add_fetch(fetch_name);\n     }\n     RunStepResponse resp;\n@@ -127,7 +127,7 @@ class MasterTest : public ::testing::Test {\n     return s;\n   }\n \n-  absl::Status CloseSession(const string& handle) {\n+  absl::Status CloseSession(const std::string& handle) {\n     ::grpc::ClientContext ctx;\n     CloseSessionRequest req;\n     req.set_session_handle(handle);\n@@ -145,7 +145,7 @@ class MasterTest : public ::testing::Test {\n \n TEST_F(MasterTest, CreateClose) {\n   GraphDef def;  // Empty.\n-  string handle;\n+  std::string handle;\n   int64_t initial_version;\n   TF_ASSERT_OK(CreateSession(def, &handle, &initial_version));\n   EXPECT_TRUE(absl::IsAborted(CloseSession(\"randombits\")));\n@@ -164,7 +164,7 @@ TEST_F(MasterTest, ListDevices) {\n \n TEST_F(MasterTest, Reset) {\n   GraphDef def;  // Empty.\n-  string s1, s2;\n+  std::string s1, s2;\n   int64_t initial_version1, initial_version2;\n   TF_ASSERT_OK(CreateSession(def, &s1, &initial_version1));\n   TF_ASSERT_OK(CreateSession(def, &s2, &initial_version2));\n@@ -175,7 +175,7 @@ TEST_F(MasterTest, Reset) {\n \n TEST_F(MasterTest, Extend) {\n   GraphDef def_0;  // Empty.\n-  string handle;\n+  std::string handle;\n   int64_t initial_version;\n   TF_ASSERT_OK(CreateSession(def_0, &handle, &initial_version));\n \n@@ -216,7 +216,7 @@ TEST_F(MasterTest, Extend) {\n \n TEST_F(MasterTest, ExtendUpdateStatefulFails) {\n   GraphDef def_0;  // Empty.\n-  string handle;\n+  std::string handle;\n   int64_t initial_version;\n   TF_ASSERT_OK(CreateSession(def_0, &handle, &initial_version));\n \n@@ -235,7 +235,7 @@ TEST_F(MasterTest, ExtendUpdateStatefulFails) {\n \n TEST_F(MasterTest, ExtendTwiceFails) {\n   GraphDef def_0;  // Empty.\n-  string handle;\n+  std::string handle;\n   int64_t initial_version;\n   TF_ASSERT_OK(CreateSession(def_0, &handle, &initial_version));\n \n@@ -254,7 +254,7 @@ TEST_F(MasterTest, ExtendTwiceFails) {\n \n TEST_F(MasterTest, ConcurrentExtendOnlyOneSucceeds) {\n   GraphDef def_0;  // Empty.\n-  string handle;\n+  std::string handle;\n   int64_t initial_version;\n   TF_ASSERT_OK(CreateSession(def_0, &handle, &initial_version));\n \n@@ -306,7 +306,7 @@ TEST_F(MasterTest, ConcurrentExtendAndRun) {\n   GraphDef def_0;\n   test::graph::ToGraphDef(&graph_0, &def_0);\n \n-  string handle;\n+  std::string handle;\n   int64_t initial_version;\n   TF_ASSERT_OK(CreateSession(def_0, &handle, &initial_version));\n \n@@ -388,7 +388,7 @@ TEST_F(MasterTest, EigenProblem) {\n   GraphDef def;\n   test::graph::ToGraphDef(&graph, &def);\n \n-  string handle;\n+  std::string handle;\n   int64_t initial_version;\n   TF_CHECK_OK(CreateSession(def, &handle, &initial_version));\n "
        },
        {
            "sha": "7eabcadcc173bf05bd34a5712d7fbcca69e17304",
            "filename": "tensorflow/core/distributed_runtime/message_wrappers.cc",
            "status": "modified",
            "additions": 67,
            "deletions": 62,
            "changes": 129,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmessage_wrappers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmessage_wrappers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fmessage_wrappers.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -38,24 +38,24 @@ bool ParseTensorProtoToTensor(const TensorProto& tensor_proto,\n   return false;\n }\n \n-const string& InMemoryRunStepRequest::session_handle() const {\n+const std::string& InMemoryRunStepRequest::session_handle() const {\n   return session_handle_;\n }\n \n-void InMemoryRunStepRequest::set_session_handle(const string& handle) {\n+void InMemoryRunStepRequest::set_session_handle(const std::string& handle) {\n   session_handle_ = handle;\n }\n \n-const string& InMemoryRunStepRequest::partial_run_handle() const {\n+const std::string& InMemoryRunStepRequest::partial_run_handle() const {\n   return partial_run_handle_;\n }\n \n-void InMemoryRunStepRequest::set_partial_run_handle(const string& handle) {\n+void InMemoryRunStepRequest::set_partial_run_handle(const std::string& handle) {\n   partial_run_handle_ = handle;\n }\n \n size_t InMemoryRunStepRequest::num_feeds() const { return feeds_.size(); }\n-const string& InMemoryRunStepRequest::feed_name(size_t i) const {\n+const std::string& InMemoryRunStepRequest::feed_name(size_t i) const {\n   return feeds_[i].first;\n }\n \n@@ -71,23 +71,24 @@ absl::Status InMemoryRunStepRequest::FeedValue(size_t i,\n   return absl::OkStatus();\n }\n \n-void InMemoryRunStepRequest::add_feed(const string& name, const Tensor& value) {\n+void InMemoryRunStepRequest::add_feed(const std::string& name,\n+                                      const Tensor& value) {\n   feeds_.emplace_back(name, value);\n }\n \n size_t InMemoryRunStepRequest::num_fetches() const { return fetches_.size(); }\n-const string& InMemoryRunStepRequest::fetch_name(size_t i) const {\n+const std::string& InMemoryRunStepRequest::fetch_name(size_t i) const {\n   return fetches_[i];\n }\n-void InMemoryRunStepRequest::add_fetch(const string& name) {\n+void InMemoryRunStepRequest::add_fetch(const std::string& name) {\n   fetches_.push_back(name);\n }\n \n size_t InMemoryRunStepRequest::num_targets() const { return targets_.size(); }\n-const string& InMemoryRunStepRequest::target_name(size_t i) const {\n+const std::string& InMemoryRunStepRequest::target_name(size_t i) const {\n   return targets_[i];\n }\n-void InMemoryRunStepRequest::add_target(const string& name) {\n+void InMemoryRunStepRequest::add_target(const std::string& name) {\n   targets_.push_back(name);\n }\n \n@@ -108,7 +109,7 @@ void InMemoryRunStepRequest::set_store_errors_in_response_body(\n   store_errors_in_response_body_ = store_errors;\n }\n \n-string InMemoryRunStepRequest::DebugString() const {\n+std::string InMemoryRunStepRequest::DebugString() const {\n   return ToProto().DebugString();\n }\n \n@@ -133,24 +134,25 @@ const RunStepRequest& InMemoryRunStepRequest::ToProto() const {\n   return *proto_version_;\n }\n \n-const string& MutableProtoRunStepRequest::session_handle() const {\n+const std::string& MutableProtoRunStepRequest::session_handle() const {\n   return request_.session_handle();\n }\n-void MutableProtoRunStepRequest::set_session_handle(const string& handle) {\n+void MutableProtoRunStepRequest::set_session_handle(const std::string& handle) {\n   request_.set_session_handle(handle);\n }\n \n-const string& MutableProtoRunStepRequest::partial_run_handle() const {\n+const std::string& MutableProtoRunStepRequest::partial_run_handle() const {\n   return request_.partial_run_handle();\n }\n-void MutableProtoRunStepRequest::set_partial_run_handle(const string& handle) {\n+void MutableProtoRunStepRequest::set_partial_run_handle(\n+    const std::string& handle) {\n   request_.set_partial_run_handle(handle);\n }\n \n size_t MutableProtoRunStepRequest::num_feeds() const {\n   return request_.feed_size();\n }\n-const string& MutableProtoRunStepRequest::feed_name(size_t i) const {\n+const std::string& MutableProtoRunStepRequest::feed_name(size_t i) const {\n   return request_.feed(i).name();\n }\n absl::Status MutableProtoRunStepRequest::FeedValue(size_t i,\n@@ -168,7 +170,7 @@ absl::Status MutableProtoRunStepRequest::FeedValue(\n   return absl::OkStatus();\n }\n \n-void MutableProtoRunStepRequest::add_feed(const string& name,\n+void MutableProtoRunStepRequest::add_feed(const std::string& name,\n                                           const Tensor& value) {\n   NamedTensorProto* feed = request_.add_feed();\n   feed->set_name(name);\n@@ -180,22 +182,22 @@ size_t MutableProtoRunStepRequest::num_fetches() const {\n   return request_.fetch_size();\n }\n \n-const string& MutableProtoRunStepRequest::fetch_name(size_t i) const {\n+const std::string& MutableProtoRunStepRequest::fetch_name(size_t i) const {\n   return request_.fetch(i);\n }\n-void MutableProtoRunStepRequest::add_fetch(const string& name) {\n+void MutableProtoRunStepRequest::add_fetch(const std::string& name) {\n   request_.add_fetch(name);\n }\n \n size_t MutableProtoRunStepRequest::num_targets() const {\n   return request_.target_size();\n }\n \n-const string& MutableProtoRunStepRequest::target_name(size_t i) const {\n+const std::string& MutableProtoRunStepRequest::target_name(size_t i) const {\n   return request_.target(i);\n }\n \n-void MutableProtoRunStepRequest::add_target(const string& name) {\n+void MutableProtoRunStepRequest::add_target(const std::string& name) {\n   request_.add_target(name);\n }\n \n@@ -220,7 +222,7 @@ int64_t MutableProtoRunStepRequest::request_id() const {\n   return request_.request_id();\n }\n \n-string MutableProtoRunStepRequest::DebugString() const {\n+std::string MutableProtoRunStepRequest::DebugString() const {\n   return request_.DebugString();\n }\n \n@@ -231,17 +233,17 @@ const RunStepRequest& MutableProtoRunStepRequest::ToProto() const {\n ProtoRunStepRequest::ProtoRunStepRequest(const RunStepRequest* request)\n     : request_(request) {}\n \n-const string& ProtoRunStepRequest::session_handle() const {\n+const std::string& ProtoRunStepRequest::session_handle() const {\n   return request_->session_handle();\n }\n \n-const string& ProtoRunStepRequest::partial_run_handle() const {\n+const std::string& ProtoRunStepRequest::partial_run_handle() const {\n   return request_->partial_run_handle();\n }\n \n size_t ProtoRunStepRequest::num_feeds() const { return request_->feed_size(); }\n \n-const string& ProtoRunStepRequest::feed_name(size_t i) const {\n+const std::string& ProtoRunStepRequest::feed_name(size_t i) const {\n   return request_->feed(i).name();\n }\n \n@@ -264,15 +266,15 @@ size_t ProtoRunStepRequest::num_fetches() const {\n   return request_->fetch_size();\n }\n \n-const string& ProtoRunStepRequest::fetch_name(size_t i) const {\n+const std::string& ProtoRunStepRequest::fetch_name(size_t i) const {\n   return request_->fetch(i);\n }\n \n size_t ProtoRunStepRequest::num_targets() const {\n   return request_->target_size();\n }\n \n-const string& ProtoRunStepRequest::target_name(size_t i) const {\n+const std::string& ProtoRunStepRequest::target_name(size_t i) const {\n   return request_->target(i);\n }\n \n@@ -288,33 +290,33 @@ int64_t ProtoRunStepRequest::request_id() const {\n   return request_->request_id();\n }\n \n-string ProtoRunStepRequest::DebugString() const {\n+std::string ProtoRunStepRequest::DebugString() const {\n   return request_->DebugString();\n }\n \n const RunStepRequest& ProtoRunStepRequest::ToProto() const { return *request_; }\n \n-const string& InMemoryRunGraphRequest::session_handle() const {\n+const std::string& InMemoryRunGraphRequest::session_handle() const {\n   return session_handle_;\n }\n \n bool InMemoryRunGraphRequest::create_worker_session_called() const {\n   return create_worker_session_called_;\n }\n \n-void InMemoryRunGraphRequest::set_session_handle(const string& handle) {\n+void InMemoryRunGraphRequest::set_session_handle(const std::string& handle) {\n   session_handle_ = handle;\n }\n \n void InMemoryRunGraphRequest::set_create_worker_session_called(bool called) {\n   create_worker_session_called_ = called;\n }\n \n-const string& InMemoryRunGraphRequest::graph_handle() const {\n+const std::string& InMemoryRunGraphRequest::graph_handle() const {\n   return graph_handle_;\n }\n \n-void InMemoryRunGraphRequest::set_graph_handle(const string& handle) {\n+void InMemoryRunGraphRequest::set_graph_handle(const std::string& handle) {\n   graph_handle_ = handle;\n }\n \n@@ -334,7 +336,7 @@ ExecutorOpts* InMemoryRunGraphRequest::mutable_exec_opts() {\n \n size_t InMemoryRunGraphRequest::num_sends() const { return sends_.size(); }\n \n-const string& InMemoryRunGraphRequest::send_key(size_t i) const {\n+const std::string& InMemoryRunGraphRequest::send_key(size_t i) const {\n   return sends_[i].first;\n }\n \n@@ -346,7 +348,7 @@ absl::Status InMemoryRunGraphRequest::SendValue(size_t i,\n \n absl::Status InMemoryRunGraphRequest::AddSendFromRunStepRequest(\n     const RunStepRequestWrapper& run_step_request, size_t i,\n-    const string& send_key) {\n+    const std::string& send_key) {\n   Tensor tensor;\n   TF_RETURN_IF_ERROR(run_step_request.FeedValue(i, &tensor));\n   sends_.emplace_back(send_key, std::move(tensor));\n@@ -355,7 +357,7 @@ absl::Status InMemoryRunGraphRequest::AddSendFromRunStepRequest(\n \n absl::Status InMemoryRunGraphRequest::AddSendFromRunCallableRequest(\n     const RunCallableRequest& run_callable_request, size_t i,\n-    const string& send_key) {\n+    const std::string& send_key) {\n   Tensor tensor;\n   if (!ParseTensorProtoToTensor(run_callable_request.feed(i), &tensor)) {\n     return errors::InvalidArgument(\"Invalid TensorProto for feed value \", i);\n@@ -366,11 +368,11 @@ absl::Status InMemoryRunGraphRequest::AddSendFromRunCallableRequest(\n \n size_t InMemoryRunGraphRequest::num_recvs() const { return recvs_.size(); }\n \n-const string& InMemoryRunGraphRequest::recv_key(size_t i) const {\n+const std::string& InMemoryRunGraphRequest::recv_key(size_t i) const {\n   return recvs_[i];\n }\n \n-void InMemoryRunGraphRequest::add_recv_key(const string& recv_key) {\n+void InMemoryRunGraphRequest::add_recv_key(const std::string& recv_key) {\n   recvs_.push_back(recv_key);\n }\n \n@@ -430,11 +432,12 @@ const RunGraphRequest& InMemoryRunGraphRequest::ToProto() const {\n   return *proto_version_;\n }\n \n-const string& MutableProtoRunGraphRequest::session_handle() const {\n+const std::string& MutableProtoRunGraphRequest::session_handle() const {\n   return request_.session_handle();\n }\n \n-void MutableProtoRunGraphRequest::set_session_handle(const string& handle) {\n+void MutableProtoRunGraphRequest::set_session_handle(\n+    const std::string& handle) {\n   request_.set_session_handle(handle);\n }\n \n@@ -447,11 +450,11 @@ void MutableProtoRunGraphRequest::set_create_worker_session_called(\n   request_.set_create_worker_session_called(called);\n }\n \n-const string& MutableProtoRunGraphRequest::graph_handle() const {\n+const std::string& MutableProtoRunGraphRequest::graph_handle() const {\n   return request_.graph_handle();\n }\n \n-void MutableProtoRunGraphRequest::set_graph_handle(const string& handle) {\n+void MutableProtoRunGraphRequest::set_graph_handle(const std::string& handle) {\n   request_.set_graph_handle(handle);\n }\n \n@@ -475,7 +478,7 @@ size_t MutableProtoRunGraphRequest::num_sends() const {\n   return request_.send_size();\n }\n \n-const string& MutableProtoRunGraphRequest::send_key(size_t i) const {\n+const std::string& MutableProtoRunGraphRequest::send_key(size_t i) const {\n   return request_.send(i).name();\n }\n \n@@ -490,7 +493,7 @@ absl::Status MutableProtoRunGraphRequest::SendValue(size_t i,\n \n absl::Status MutableProtoRunGraphRequest::AddSendFromRunStepRequest(\n     const RunStepRequestWrapper& run_step_request, size_t i,\n-    const string& send_key) {\n+    const std::string& send_key) {\n   NamedTensorProto* send = request_.add_send();\n   send->set_name(send_key);\n   TF_RETURN_IF_ERROR(run_step_request.FeedValue(i, send->mutable_tensor()));\n@@ -499,7 +502,7 @@ absl::Status MutableProtoRunGraphRequest::AddSendFromRunStepRequest(\n \n absl::Status MutableProtoRunGraphRequest::AddSendFromRunCallableRequest(\n     const RunCallableRequest& run_callable_request, size_t i,\n-    const string& send_key) {\n+    const std::string& send_key) {\n   NamedTensorProto* send = request_.add_send();\n   send->set_name(send_key);\n   *send->mutable_tensor() = run_callable_request.feed(i);\n@@ -510,11 +513,11 @@ size_t MutableProtoRunGraphRequest::num_recvs() const {\n   return request_.recv_key_size();\n }\n \n-const string& MutableProtoRunGraphRequest::recv_key(size_t i) const {\n+const std::string& MutableProtoRunGraphRequest::recv_key(size_t i) const {\n   return request_.recv_key(i);\n }\n \n-void MutableProtoRunGraphRequest::add_recv_key(const string& recv_key) {\n+void MutableProtoRunGraphRequest::add_recv_key(const std::string& recv_key) {\n   request_.add_recv_key(recv_key);\n }\n \n@@ -559,15 +562,15 @@ const RunGraphRequest& MutableProtoRunGraphRequest::ToProto() const {\n ProtoRunGraphRequest::ProtoRunGraphRequest(const RunGraphRequest* request)\n     : request_(request) {}\n \n-const string& ProtoRunGraphRequest::session_handle() const {\n+const std::string& ProtoRunGraphRequest::session_handle() const {\n   return request_->session_handle();\n }\n \n bool ProtoRunGraphRequest::create_worker_session_called() const {\n   return request_->create_worker_session_called();\n }\n \n-const string& ProtoRunGraphRequest::graph_handle() const {\n+const std::string& ProtoRunGraphRequest::graph_handle() const {\n   return request_->graph_handle();\n }\n \n@@ -579,7 +582,7 @@ const ExecutorOpts& ProtoRunGraphRequest::exec_opts() const {\n \n size_t ProtoRunGraphRequest::num_sends() const { return request_->send_size(); }\n \n-const string& ProtoRunGraphRequest::send_key(size_t i) const {\n+const std::string& ProtoRunGraphRequest::send_key(size_t i) const {\n   return request_->send(i).name();\n }\n \n@@ -596,7 +599,7 @@ size_t ProtoRunGraphRequest::num_recvs() const {\n   return request_->recv_key_size();\n }\n \n-const string& ProtoRunGraphRequest::recv_key(size_t i) const {\n+const std::string& ProtoRunGraphRequest::recv_key(size_t i) const {\n   return request_->recv_key(i);\n }\n \n@@ -620,7 +623,7 @@ const RunGraphRequest& ProtoRunGraphRequest::ToProto() const {\n \n size_t InMemoryRunGraphResponse::num_recvs() const { return recvs_.size(); }\n \n-const string& InMemoryRunGraphResponse::recv_key(size_t i) const {\n+const std::string& InMemoryRunGraphResponse::recv_key(size_t i) const {\n   return recvs_[i].first;\n }\n \n@@ -635,7 +638,8 @@ absl::Status InMemoryRunGraphResponse::RecvValue(size_t i, Tensor* out_tensor) {\n   return absl::OkStatus();\n }\n \n-void InMemoryRunGraphResponse::AddRecv(const string& key, const Tensor& value) {\n+void InMemoryRunGraphResponse::AddRecv(const std::string& key,\n+                                       const Tensor& value) {\n   recvs_.emplace_back(key, value);\n }\n \n@@ -679,7 +683,7 @@ size_t OwnedProtoRunGraphResponse::num_recvs() const {\n   return response_.recv_size();\n }\n \n-const string& OwnedProtoRunGraphResponse::recv_key(size_t i) const {\n+const std::string& OwnedProtoRunGraphResponse::recv_key(size_t i) const {\n   return response_.recv(i).name();\n }\n \n@@ -698,7 +702,7 @@ absl::Status OwnedProtoRunGraphResponse::RecvValue(size_t i,\n   }\n }\n \n-void OwnedProtoRunGraphResponse::AddRecv(const string& key,\n+void OwnedProtoRunGraphResponse::AddRecv(const std::string& key,\n                                          const Tensor& value) {\n   NamedTensorProto* recv = response_.add_recv();\n   recv->set_name(key);\n@@ -752,7 +756,7 @@ size_t NonOwnedProtoRunGraphResponse::num_recvs() const {\n   return response_->recv_size();\n }\n \n-const string& NonOwnedProtoRunGraphResponse::recv_key(size_t i) const {\n+const std::string& NonOwnedProtoRunGraphResponse::recv_key(size_t i) const {\n   return response_->recv(i).name();\n }\n \n@@ -771,7 +775,7 @@ absl::Status NonOwnedProtoRunGraphResponse::RecvValue(size_t i,\n   }\n }\n \n-void NonOwnedProtoRunGraphResponse::AddRecv(const string& key,\n+void NonOwnedProtoRunGraphResponse::AddRecv(const std::string& key,\n                                             const Tensor& value) {\n   NamedTensorProto* recv = response_->add_recv();\n   recv->set_name(key);\n@@ -823,7 +827,7 @@ MutableRunStepResponseWrapper::~MutableRunStepResponseWrapper() {}\n \n size_t InMemoryRunStepResponse::num_tensors() const { return tensors_.size(); }\n \n-const string& InMemoryRunStepResponse::tensor_name(size_t i) const {\n+const std::string& InMemoryRunStepResponse::tensor_name(size_t i) const {\n   return tensors_[i].first;\n }\n \n@@ -838,7 +842,8 @@ const RunMetadata& InMemoryRunStepResponse::metadata() const {\n }\n \n absl::Status InMemoryRunStepResponse::AddTensorFromRunGraphResponse(\n-    const string& name, MutableRunGraphResponseWrapper* wrapper, size_t i) {\n+    const std::string& name, MutableRunGraphResponseWrapper* wrapper,\n+    size_t i) {\n   Tensor tensor;\n   TF_RETURN_IF_ERROR(wrapper->RecvValue(i, &tensor));\n   tensors_.emplace_back(name, tensor);\n@@ -866,7 +871,7 @@ size_t OwnedProtoRunStepResponse::num_tensors() const {\n   return response_.tensor_size();\n }\n \n-const string& OwnedProtoRunStepResponse::tensor_name(size_t i) const {\n+const std::string& OwnedProtoRunStepResponse::tensor_name(size_t i) const {\n   return response_.tensor(i).name();\n }\n \n@@ -884,7 +889,7 @@ const RunMetadata& OwnedProtoRunStepResponse::metadata() const {\n }\n \n absl::Status OwnedProtoRunStepResponse::AddTensorFromRunGraphResponse(\n-    const string& name, MutableRunGraphResponseWrapper* run_graph_response,\n+    const std::string& name, MutableRunGraphResponseWrapper* run_graph_response,\n     size_t i) {\n   NamedTensorProto* response_tensor = response_.add_tensor();\n   response_tensor->set_name(name);\n@@ -919,7 +924,7 @@ size_t NonOwnedProtoRunStepResponse::num_tensors() const {\n   return response_->tensor_size();\n }\n \n-const string& NonOwnedProtoRunStepResponse::tensor_name(size_t i) const {\n+const std::string& NonOwnedProtoRunStepResponse::tensor_name(size_t i) const {\n   return response_->tensor(i).name();\n }\n \n@@ -937,7 +942,7 @@ const RunMetadata& NonOwnedProtoRunStepResponse::metadata() const {\n }\n \n absl::Status NonOwnedProtoRunStepResponse::AddTensorFromRunGraphResponse(\n-    const string& name, MutableRunGraphResponseWrapper* run_graph_response,\n+    const std::string& name, MutableRunGraphResponseWrapper* run_graph_response,\n     size_t i) {\n   NamedTensorProto* response_tensor = response_->add_tensor();\n   response_tensor->set_name(name);"
        },
        {
            "sha": "b911d23245b4addc74e86f08ff2c82fe1674e326",
            "filename": "tensorflow/core/distributed_runtime/message_wrappers.h",
            "status": "modified",
            "additions": 101,
            "deletions": 101,
            "changes": 202,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmessage_wrappers.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmessage_wrappers.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fmessage_wrappers.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -53,15 +53,15 @@ class RunStepRequestWrapper {\n \n   // REQUIRED: session_handle must be returned by a CreateSession call\n   // to the same master service.\n-  virtual const string& session_handle() const = 0;\n+  virtual const std::string& session_handle() const = 0;\n \n   // Partial run handle (optional). If specified, this will be a partial run\n   // execution, run up to the specified fetches.\n-  virtual const string& partial_run_handle() const = 0;\n+  virtual const std::string& partial_run_handle() const = 0;\n \n   // Tensors to be fed in the step. Each feed is a named tensor.\n   virtual size_t num_feeds() const = 0;\n-  virtual const string& feed_name(size_t i) const = 0;\n+  virtual const std::string& feed_name(size_t i) const = 0;\n \n   // Stores the content of the feed value at index `i` in `tensor`.\n   virtual absl::Status FeedValue(size_t i, Tensor* out_tensor) const = 0;\n@@ -71,12 +71,12 @@ class RunStepRequestWrapper {\n   // be returned for each fetch[i] (see RunStepResponse.tensor). The\n   // order of specified fetches does not change the execution order.\n   virtual size_t num_fetches() const = 0;\n-  virtual const string& fetch_name(size_t i) const = 0;\n+  virtual const std::string& fetch_name(size_t i) const = 0;\n \n   // Target Nodes. A list of node names. The named nodes will be run\n   // to but their outputs will not be fetched.\n   virtual size_t num_targets() const = 0;\n-  virtual const string& target_name(size_t i) const = 0;\n+  virtual const std::string& target_name(size_t i) const = 0;\n \n   // Options for the run call.\n   virtual const RunOptions& options() const = 0;\n@@ -94,7 +94,7 @@ class RunStepRequestWrapper {\n   virtual int64_t request_id() const = 0;\n \n   // Returns a human-readable representation of this message for debugging.\n-  virtual string DebugString() const = 0;\n+  virtual std::string DebugString() const = 0;\n \n   // Returns the wrapped data as a protocol buffer message.\n   virtual const RunStepRequest& ToProto() const = 0;\n@@ -105,11 +105,11 @@ class RunStepRequestWrapper {\n // See `RunStepRequestWrapper` above for a description of the fields.\n class MutableRunStepRequestWrapper : public RunStepRequestWrapper {\n  public:\n-  virtual void set_session_handle(const string& handle) = 0;\n-  virtual void set_partial_run_handle(const string& handle) = 0;\n-  virtual void add_feed(const string& name, const Tensor& value) = 0;\n-  virtual void add_fetch(const string& name) = 0;\n-  virtual void add_target(const string& name) = 0;\n+  virtual void set_session_handle(const std::string& handle) = 0;\n+  virtual void set_partial_run_handle(const std::string& handle) = 0;\n+  virtual void add_feed(const std::string& name, const Tensor& value) = 0;\n+  virtual void add_fetch(const std::string& name) = 0;\n+  virtual void add_target(const std::string& name) = 0;\n   virtual RunOptions* mutable_options() = 0;\n   virtual void set_store_errors_in_response_body(bool store_errors) = 0;\n };\n@@ -119,37 +119,37 @@ class MutableRunStepRequestWrapper : public RunStepRequestWrapper {\n class InMemoryRunStepRequest : public MutableRunStepRequestWrapper {\n  public:\n   // RunStepRequestWrapper methods.\n-  const string& session_handle() const override;\n-  const string& partial_run_handle() const override;\n+  const std::string& session_handle() const override;\n+  const std::string& partial_run_handle() const override;\n   size_t num_feeds() const override;\n-  const string& feed_name(size_t i) const override;\n+  const std::string& feed_name(size_t i) const override;\n   absl::Status FeedValue(size_t i, Tensor* out_tensor) const override;\n   absl::Status FeedValue(size_t i, TensorProto* out_tensor) const override;\n   size_t num_fetches() const override;\n-  const string& fetch_name(size_t i) const override;\n+  const std::string& fetch_name(size_t i) const override;\n   size_t num_targets() const override;\n-  const string& target_name(size_t i) const override;\n+  const std::string& target_name(size_t i) const override;\n   const RunOptions& options() const override;\n-  string DebugString() const override;\n+  std::string DebugString() const override;\n   const RunStepRequest& ToProto() const override;\n   bool store_errors_in_response_body() const override;\n   int64_t request_id() const override;\n \n   // MutableRunStepRequestWrapper methods.\n-  void set_session_handle(const string& handle) override;\n-  void set_partial_run_handle(const string& handle) override;\n-  void add_feed(const string& name, const Tensor& value) override;\n-  void add_fetch(const string& name) override;\n-  void add_target(const string& name) override;\n+  void set_session_handle(const std::string& handle) override;\n+  void set_partial_run_handle(const std::string& handle) override;\n+  void add_feed(const std::string& name, const Tensor& value) override;\n+  void add_fetch(const std::string& name) override;\n+  void add_target(const std::string& name) override;\n   RunOptions* mutable_options() override;\n   void set_store_errors_in_response_body(bool store_errors) override;\n \n  private:\n-  string session_handle_;\n-  string partial_run_handle_;\n-  absl::InlinedVector<std::pair<string, Tensor>, 4UL> feeds_;\n-  absl::InlinedVector<string, 4UL> fetches_;\n-  absl::InlinedVector<string, 4UL> targets_;\n+  std::string session_handle_;\n+  std::string partial_run_handle_;\n+  absl::InlinedVector<std::pair<std::string, Tensor>, 4UL> feeds_;\n+  absl::InlinedVector<std::string, 4UL> fetches_;\n+  absl::InlinedVector<std::string, 4UL> targets_;\n   RunOptions options_;\n   bool store_errors_in_response_body_ = false;\n \n@@ -170,28 +170,28 @@ class InMemoryRunStepRequest : public MutableRunStepRequestWrapper {\n class MutableProtoRunStepRequest : public MutableRunStepRequestWrapper {\n  public:\n   // RunStepRequestWrapper methods.\n-  const string& session_handle() const override;\n-  const string& partial_run_handle() const override;\n+  const std::string& session_handle() const override;\n+  const std::string& partial_run_handle() const override;\n   size_t num_feeds() const override;\n-  const string& feed_name(size_t i) const override;\n+  const std::string& feed_name(size_t i) const override;\n   absl::Status FeedValue(size_t i, Tensor* out_tensor) const override;\n   absl::Status FeedValue(size_t i, TensorProto* out_tensor) const override;\n   size_t num_fetches() const override;\n-  const string& fetch_name(size_t i) const override;\n+  const std::string& fetch_name(size_t i) const override;\n   size_t num_targets() const override;\n-  const string& target_name(size_t i) const override;\n+  const std::string& target_name(size_t i) const override;\n   const RunOptions& options() const override;\n-  string DebugString() const override;\n+  std::string DebugString() const override;\n   const RunStepRequest& ToProto() const override;\n   bool store_errors_in_response_body() const override;\n   int64_t request_id() const override;\n \n   // MutableRunStepRequestWrapper methods.\n-  void set_session_handle(const string& handle) override;\n-  void set_partial_run_handle(const string& handle) override;\n-  void add_feed(const string& name, const Tensor& value) override;\n-  void add_fetch(const string& name) override;\n-  void add_target(const string& name) override;\n+  void set_session_handle(const std::string& handle) override;\n+  void set_partial_run_handle(const std::string& handle) override;\n+  void add_feed(const std::string& name, const Tensor& value) override;\n+  void add_fetch(const std::string& name) override;\n+  void add_target(const std::string& name) override;\n   RunOptions* mutable_options() override;\n   void set_store_errors_in_response_body(bool store_errors) override;\n \n@@ -211,18 +211,18 @@ class ProtoRunStepRequest : public RunStepRequestWrapper {\n   ProtoRunStepRequest(const RunStepRequest* request);\n \n   // RunStepRequestWrapper methods.\n-  const string& session_handle() const override;\n-  const string& partial_run_handle() const override;\n+  const std::string& session_handle() const override;\n+  const std::string& partial_run_handle() const override;\n   size_t num_feeds() const override;\n-  const string& feed_name(size_t i) const override;\n+  const std::string& feed_name(size_t i) const override;\n   absl::Status FeedValue(size_t i, Tensor* out_tensor) const override;\n   absl::Status FeedValue(size_t i, TensorProto* out_tensor) const override;\n   size_t num_fetches() const override;\n-  const string& fetch_name(size_t i) const override;\n+  const std::string& fetch_name(size_t i) const override;\n   size_t num_targets() const override;\n-  const string& target_name(size_t i) const override;\n+  const std::string& target_name(size_t i) const override;\n   const RunOptions& options() const override;\n-  string DebugString() const override;\n+  std::string DebugString() const override;\n   const RunStepRequest& ToProto() const override;\n   bool store_errors_in_response_body() const override;\n   int64_t request_id() const override;\n@@ -254,14 +254,14 @@ class RunGraphRequestWrapper {\n \n   // The session handle used to register the graph. If empty, a single global\n   // namespace is used.\n-  virtual const string& session_handle() const = 0;\n+  virtual const std::string& session_handle() const = 0;\n \n   // Set to true if `CreateWorkerSession` was called for `session_handle`.\n   virtual bool create_worker_session_called() const = 0;\n \n   // REQUIRED: graph_handle must be returned by a RegisterGraph call\n   // to the same WorkerService.\n-  virtual const string& graph_handle() const = 0;\n+  virtual const std::string& graph_handle() const = 0;\n \n   // A unique ID to distinguish different runs of the same graph.\n   //\n@@ -276,12 +276,12 @@ class RunGraphRequestWrapper {\n \n   // Sends the tensors in \"send\" into the graph before the run.\n   virtual size_t num_sends() const = 0;\n-  virtual const string& send_key(size_t i) const = 0;\n+  virtual const std::string& send_key(size_t i) const = 0;\n   virtual absl::Status SendValue(size_t i, Tensor* out_tensor) const = 0;\n \n   // Fetches the keys into `RunGraphResponse.recv` after the run.\n   virtual size_t num_recvs() const = 0;\n-  virtual const string& recv_key(size_t i) const = 0;\n+  virtual const std::string& recv_key(size_t i) const = 0;\n \n   // True if the RunGraphRequest is a partial run request.\n   virtual bool is_partial() const = 0;\n@@ -307,22 +307,22 @@ class RunGraphRequestWrapper {\n // See `RunGraphRequestWrapper` above for a description of the fields.\n class MutableRunGraphRequestWrapper : public RunGraphRequestWrapper {\n  public:\n-  virtual void set_session_handle(const string& handle) = 0;\n+  virtual void set_session_handle(const std::string& handle) = 0;\n   virtual void set_create_worker_session_called(bool called) = 0;\n-  virtual void set_graph_handle(const string& handle) = 0;\n+  virtual void set_graph_handle(const std::string& handle) = 0;\n   virtual void set_step_id(int64_t step_id) = 0;\n   virtual ExecutorOpts* mutable_exec_opts() = 0;\n \n   // Stores the i^{th} feed value in `run_step_request` in this\n   // request with the given `send_key`.\n   virtual absl::Status AddSendFromRunStepRequest(\n       const RunStepRequestWrapper& run_step_request, size_t i,\n-      const string& send_key) = 0;\n+      const std::string& send_key) = 0;\n   virtual absl::Status AddSendFromRunCallableRequest(\n       const RunCallableRequest& run_callable_request, size_t i,\n-      const string& send_key) = 0;\n+      const std::string& send_key) = 0;\n \n-  virtual void add_recv_key(const string& recv_key) = 0;\n+  virtual void add_recv_key(const std::string& recv_key) = 0;\n   virtual void set_is_partial(bool is_partial) = 0;\n   virtual void set_is_last_partial_run(bool is_last_partial_run) = 0;\n   virtual void set_store_errors_in_response_body(bool store_errors) = 0;\n@@ -332,48 +332,48 @@ class MutableRunGraphRequestWrapper : public RunGraphRequestWrapper {\n class InMemoryRunGraphRequest : public MutableRunGraphRequestWrapper {\n  public:\n   // RunGraphRequestWrapper methods.\n-  const string& session_handle() const override;\n-  const string& graph_handle() const override;\n+  const std::string& session_handle() const override;\n+  const std::string& graph_handle() const override;\n   bool create_worker_session_called() const override;\n   int64_t step_id() const override;\n   const ExecutorOpts& exec_opts() const override;\n   size_t num_sends() const override;\n-  const string& send_key(size_t i) const override;\n+  const std::string& send_key(size_t i) const override;\n   absl::Status SendValue(size_t i, Tensor* out_tensor) const override;\n   size_t num_recvs() const override;\n-  const string& recv_key(size_t i) const override;\n+  const std::string& recv_key(size_t i) const override;\n   bool is_partial() const override;\n   bool is_last_partial_run() const override;\n   const RunGraphRequest& ToProto() const override;\n   bool store_errors_in_response_body() const override;\n   int64_t request_id() const override;\n \n   // MutableRunGraphRequestWrapper methods.\n-  void set_session_handle(const string& handle) override;\n+  void set_session_handle(const std::string& handle) override;\n   void set_create_worker_session_called(bool called) override;\n-  void set_graph_handle(const string& handle) override;\n+  void set_graph_handle(const std::string& handle) override;\n   void set_step_id(int64_t step_id) override;\n   ExecutorOpts* mutable_exec_opts() override;\n   absl::Status AddSendFromRunStepRequest(\n       const RunStepRequestWrapper& run_step_request, size_t i,\n-      const string& send_key) override;\n+      const std::string& send_key) override;\n   absl::Status AddSendFromRunCallableRequest(\n       const RunCallableRequest& run_callable_request, size_t i,\n-      const string& send_key) override;\n-  void add_recv_key(const string& recv_key) override;\n+      const std::string& send_key) override;\n+  void add_recv_key(const std::string& recv_key) override;\n   void set_is_partial(bool is_partial) override;\n   void set_is_last_partial_run(bool is_last_partial_run) override;\n   void set_store_errors_in_response_body(bool store_errors) override;\n   void set_request_id(int64_t request_id) override;\n \n  private:\n-  string session_handle_;\n+  std::string session_handle_;\n   bool create_worker_session_called_ = false;\n-  string graph_handle_;\n+  std::string graph_handle_;\n   int64_t step_id_;\n   ExecutorOpts exec_opts_;\n-  absl::InlinedVector<std::pair<string, Tensor>, 4UL> sends_;\n-  absl::InlinedVector<string, 4UL> recvs_;\n+  absl::InlinedVector<std::pair<std::string, Tensor>, 4UL> sends_;\n+  absl::InlinedVector<std::string, 4UL> recvs_;\n   bool is_partial_ = false;\n   bool is_last_partial_run_ = false;\n   bool store_errors_in_response_body_ = false;\n@@ -392,35 +392,35 @@ class InMemoryRunGraphRequest : public MutableRunGraphRequestWrapper {\n class MutableProtoRunGraphRequest : public MutableRunGraphRequestWrapper {\n  public:\n   // RunGraphRequestWrapper methods.\n-  const string& session_handle() const override;\n+  const std::string& session_handle() const override;\n   bool create_worker_session_called() const override;\n-  const string& graph_handle() const override;\n+  const std::string& graph_handle() const override;\n   int64_t step_id() const override;\n   const ExecutorOpts& exec_opts() const override;\n   size_t num_sends() const override;\n-  const string& send_key(size_t i) const override;\n+  const std::string& send_key(size_t i) const override;\n   absl::Status SendValue(size_t i, Tensor* out_tensor) const override;\n   size_t num_recvs() const override;\n-  const string& recv_key(size_t i) const override;\n+  const std::string& recv_key(size_t i) const override;\n   bool is_partial() const override;\n   bool is_last_partial_run() const override;\n   bool store_errors_in_response_body() const override;\n   int64_t request_id() const override;\n   const RunGraphRequest& ToProto() const override;\n \n   // MutableRunGraphRequestWrapper methods.\n-  void set_session_handle(const string& handle) override;\n+  void set_session_handle(const std::string& handle) override;\n   void set_create_worker_session_called(bool called) override;\n-  void set_graph_handle(const string& handle) override;\n+  void set_graph_handle(const std::string& handle) override;\n   void set_step_id(int64_t step_id) override;\n   ExecutorOpts* mutable_exec_opts() override;\n   absl::Status AddSendFromRunStepRequest(\n       const RunStepRequestWrapper& run_step_request, size_t i,\n-      const string& send_key) override;\n+      const std::string& send_key) override;\n   absl::Status AddSendFromRunCallableRequest(\n       const RunCallableRequest& run_callable_request, size_t i,\n-      const string& send_key) override;\n-  void add_recv_key(const string& recv_key) override;\n+      const std::string& send_key) override;\n+  void add_recv_key(const std::string& recv_key) override;\n   void set_is_partial(bool is_partial) override;\n   void set_is_last_partial_run(bool is_last_partial_run) override;\n   void set_store_errors_in_response_body(bool store_errors) override;\n@@ -435,16 +435,16 @@ class ProtoRunGraphRequest : public RunGraphRequestWrapper {\n   ProtoRunGraphRequest(const RunGraphRequest* request);\n \n   // RunGraphRequestWrapper methods.\n-  const string& session_handle() const override;\n+  const std::string& session_handle() const override;\n   bool create_worker_session_called() const override;\n-  const string& graph_handle() const override;\n+  const std::string& graph_handle() const override;\n   int64_t step_id() const override;\n   const ExecutorOpts& exec_opts() const override;\n   size_t num_sends() const override;\n-  const string& send_key(size_t i) const override;\n+  const std::string& send_key(size_t i) const override;\n   absl::Status SendValue(size_t i, Tensor* out_tensor) const override;\n   size_t num_recvs() const override;\n-  const string& recv_key(size_t i) const override;\n+  const std::string& recv_key(size_t i) const override;\n   bool is_partial() const override;\n   bool is_last_partial_run() const override;\n   bool store_errors_in_response_body() const override;\n@@ -480,12 +480,12 @@ class MutableRunGraphResponseWrapper {\n   // A list of tensors corresponding to those requested by\n   // `RunGraphRequest.recv_key`.\n   virtual size_t num_recvs() const = 0;\n-  virtual const string& recv_key(size_t i) const = 0;\n+  virtual const std::string& recv_key(size_t i) const = 0;\n   // NOTE: The following methods may perform a destructive read, for\n   // efficiency.\n   virtual absl::Status RecvValue(size_t i, TensorProto* out_tensor) = 0;\n   virtual absl::Status RecvValue(size_t i, Tensor* out_tensor) = 0;\n-  virtual void AddRecv(const string& key, const Tensor& value) = 0;\n+  virtual void AddRecv(const std::string& key, const Tensor& value) = 0;\n \n   // Submessages that store performance statistics about the subgraph\n   // execution, if necessary.\n@@ -520,10 +520,10 @@ class InMemoryRunGraphResponse : public MutableRunGraphResponseWrapper {\n  public:\n   // MutableRunGraphResponseWrapper methods.\n   size_t num_recvs() const override;\n-  const string& recv_key(size_t i) const override;\n+  const std::string& recv_key(size_t i) const override;\n   absl::Status RecvValue(size_t i, TensorProto* out_tensor) override;\n   absl::Status RecvValue(size_t i, Tensor* out_tensor) override;\n-  void AddRecv(const string& key, const Tensor& value) override;\n+  void AddRecv(const std::string& key, const Tensor& value) override;\n   StepStats* mutable_step_stats() override;\n   CostGraphDef* mutable_cost_graph() override;\n   size_t num_partition_graphs() const override;\n@@ -539,7 +539,7 @@ class InMemoryRunGraphResponse : public MutableRunGraphResponseWrapper {\n   RunGraphResponse* get_proto() override;\n \n  private:\n-  absl::InlinedVector<std::pair<string, Tensor>, 4UL> recvs_;\n+  absl::InlinedVector<std::pair<std::string, Tensor>, 4UL> recvs_;\n   StepStats step_stats_;\n   CostGraphDef cost_graph_;\n   std::vector<GraphDef> partition_graphs_;\n@@ -553,10 +553,10 @@ class OwnedProtoRunGraphResponse : public MutableRunGraphResponseWrapper {\n  public:\n   // MutableRunGraphResponseWrapper methods.\n   size_t num_recvs() const override;\n-  const string& recv_key(size_t i) const override;\n+  const std::string& recv_key(size_t i) const override;\n   absl::Status RecvValue(size_t i, TensorProto* out_tensor) override;\n   absl::Status RecvValue(size_t i, Tensor* out_tensor) override;\n-  void AddRecv(const string& key, const Tensor& value) override;\n+  void AddRecv(const std::string& key, const Tensor& value) override;\n   StepStats* mutable_step_stats() override;\n   CostGraphDef* mutable_cost_graph() override;\n   size_t num_partition_graphs() const override;\n@@ -580,10 +580,10 @@ class NonOwnedProtoRunGraphResponse : public MutableRunGraphResponseWrapper {\n \n   // MutableRunGraphResponseWrapper methods.\n   size_t num_recvs() const override;\n-  const string& recv_key(size_t i) const override;\n+  const std::string& recv_key(size_t i) const override;\n   absl::Status RecvValue(size_t i, TensorProto* out_tensor) override;\n   absl::Status RecvValue(size_t i, Tensor* out_tensor) override;\n-  void AddRecv(const string& key, const Tensor& value) override;\n+  void AddRecv(const std::string& key, const Tensor& value) override;\n   StepStats* mutable_step_stats() override;\n   CostGraphDef* mutable_cost_graph() override;\n   size_t num_partition_graphs() const override;\n@@ -628,14 +628,14 @@ class MutableRunStepResponseWrapper {\n   // NOTE: The order of the returned tensors may or may not match\n   // the fetch order specified in RunStepRequest.\n   virtual size_t num_tensors() const = 0;\n-  virtual const string& tensor_name(size_t i) const = 0;\n+  virtual const std::string& tensor_name(size_t i) const = 0;\n   virtual absl::Status TensorValue(size_t i, Tensor* out_tensor) const = 0;\n \n   // Stores the i^{th} recv value in `run_graph_response` in this\n   // response with the given `name`.\n   virtual absl::Status AddTensorFromRunGraphResponse(\n-      const string& name, MutableRunGraphResponseWrapper* run_graph_response,\n-      size_t i) = 0;\n+      const std::string& name,\n+      MutableRunGraphResponseWrapper* run_graph_response, size_t i) = 0;\n \n   // Returned metadata if requested in the options.\n   virtual const RunMetadata& metadata() const = 0;\n@@ -666,11 +666,11 @@ class InMemoryRunStepResponse : public MutableRunStepResponseWrapper {\n  public:\n   // MutableRunStepResponseWrapper methods.\n   size_t num_tensors() const override;\n-  const string& tensor_name(size_t i) const override;\n+  const std::string& tensor_name(size_t i) const override;\n   absl::Status TensorValue(size_t i, Tensor* out_tensor) const override;\n   absl::Status AddTensorFromRunGraphResponse(\n-      const string& name, MutableRunGraphResponseWrapper* run_graph_response,\n-      size_t i) override;\n+      const std::string& name,\n+      MutableRunGraphResponseWrapper* run_graph_response, size_t i) override;\n   const RunMetadata& metadata() const override;\n   RunMetadata* mutable_metadata() override;\n   absl::Status status() const override;\n@@ -683,7 +683,7 @@ class InMemoryRunStepResponse : public MutableRunStepResponseWrapper {\n   RunStepResponse* get_proto() override;\n \n  private:\n-  absl::InlinedVector<std::pair<string, Tensor>, 4UL> tensors_;\n+  absl::InlinedVector<std::pair<std::string, Tensor>, 4UL> tensors_;\n   RunMetadata metadata_;\n   // Store the code and message separately so that they can be updated\n   // independently by setters.\n@@ -695,11 +695,11 @@ class OwnedProtoRunStepResponse : public MutableRunStepResponseWrapper {\n  public:\n   // MutableRunStepResponseWrapper methods.\n   size_t num_tensors() const override;\n-  const string& tensor_name(size_t i) const override;\n+  const std::string& tensor_name(size_t i) const override;\n   absl::Status TensorValue(size_t i, Tensor* out_tensor) const override;\n   absl::Status AddTensorFromRunGraphResponse(\n-      const string& name, MutableRunGraphResponseWrapper* run_graph_response,\n-      size_t i) override;\n+      const std::string& name,\n+      MutableRunGraphResponseWrapper* run_graph_response, size_t i) override;\n   const RunMetadata& metadata() const override;\n   RunMetadata* mutable_metadata() override;\n   absl::Status status() const override;\n@@ -720,11 +720,11 @@ class NonOwnedProtoRunStepResponse : public MutableRunStepResponseWrapper {\n \n   // MutableRunStepResponseWrapper methods.\n   size_t num_tensors() const override;\n-  const string& tensor_name(size_t i) const override;\n+  const std::string& tensor_name(size_t i) const override;\n   absl::Status TensorValue(size_t i, Tensor* out_tensor) const override;\n   absl::Status AddTensorFromRunGraphResponse(\n-      const string& name, MutableRunGraphResponseWrapper* run_graph_response,\n-      size_t i) override;\n+      const std::string& name,\n+      MutableRunGraphResponseWrapper* run_graph_response, size_t i) override;\n   const RunMetadata& metadata() const override;\n   RunMetadata* mutable_metadata() override;\n   absl::Status status() const override;"
        },
        {
            "sha": "9f0af827eee5916e25a4f6b893fcb90e388c186f",
            "filename": "tensorflow/core/distributed_runtime/message_wrappers_test.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmessage_wrappers_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fmessage_wrappers_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fmessage_wrappers_test.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -27,13 +27,13 @@ namespace {\n \n Tensor TensorA() {\n   Tensor a_tensor(DT_INT32, TensorShape({2, 2}));\n-  test::FillValues<int32>(&a_tensor, {3, 2, -1, 0});\n+  test::FillValues<int32_t>(&a_tensor, {3, 2, -1, 0});\n   return a_tensor;\n }\n \n Tensor TensorB() {\n   Tensor b_tensor(DT_INT32, TensorShape({1, 2}));\n-  test::FillValues<int32>(&b_tensor, {1, 2});\n+  test::FillValues<int32_t>(&b_tensor, {1, 2});\n   return b_tensor;\n }\n \n@@ -57,9 +57,9 @@ void CheckRunStepRequest(const RunStepRequestWrapper& request) {\n   EXPECT_EQ(\"feed_b:0\", request.feed_name(1));\n   Tensor val;\n   TF_EXPECT_OK(request.FeedValue(0, &val));\n-  test::ExpectTensorEqual<int32>(TensorA(), val);\n+  test::ExpectTensorEqual<int32_t>(TensorA(), val);\n   TF_EXPECT_OK(request.FeedValue(1, &val));\n-  test::ExpectTensorEqual<int32>(TensorB(), val);\n+  test::ExpectTensorEqual<int32_t>(TensorB(), val);\n \n   EXPECT_EQ(2, request.num_fetches());\n   EXPECT_EQ(\"fetch_x:0\", request.fetch_name(0));\n@@ -92,9 +92,9 @@ void CheckRunGraphRequest(const RunGraphRequestWrapper& request) {\n   EXPECT_EQ(2, request.num_sends());\n   Tensor val;\n   TF_EXPECT_OK(request.SendValue(0, &val));\n-  test::ExpectTensorEqual<int32>(TensorA(), val);\n+  test::ExpectTensorEqual<int32_t>(TensorA(), val);\n   TF_EXPECT_OK(request.SendValue(1, &val));\n-  test::ExpectTensorEqual<int32>(TensorB(), val);\n+  test::ExpectTensorEqual<int32_t>(TensorB(), val);\n   EXPECT_TRUE(request.is_partial());\n   EXPECT_FALSE(request.is_last_partial_run());\n }\n@@ -117,9 +117,9 @@ void CheckRunGraphResponse(MutableRunGraphResponseWrapper* response) {\n   EXPECT_EQ(\"recv_3\", response->recv_key(1));\n   Tensor val;\n   TF_EXPECT_OK(response->RecvValue(0, &val));\n-  test::ExpectTensorEqual<int32>(TensorA(), val);\n+  test::ExpectTensorEqual<int32_t>(TensorA(), val);\n   TF_EXPECT_OK(response->RecvValue(1, &val));\n-  test::ExpectTensorEqual<int32>(TensorB(), val);\n+  test::ExpectTensorEqual<int32_t>(TensorB(), val);\n   ASSERT_EQ(1, response->mutable_step_stats()->dev_stats_size());\n   EXPECT_EQ(\"/cpu:0\", response->mutable_step_stats()->dev_stats(0).device());\n   ASSERT_EQ(1, response->mutable_cost_graph()->node_size());\n@@ -152,9 +152,9 @@ void CheckRunStepResponse(const MutableRunStepResponseWrapper& response) {\n   EXPECT_EQ(\"fetch_y:0\", response.tensor_name(1));\n   Tensor val;\n   TF_EXPECT_OK(response.TensorValue(0, &val));\n-  test::ExpectTensorEqual<int32>(TensorA(), val);\n+  test::ExpectTensorEqual<int32_t>(TensorA(), val);\n   TF_EXPECT_OK(response.TensorValue(1, &val));\n-  test::ExpectTensorEqual<int32>(TensorB(), val);\n+  test::ExpectTensorEqual<int32_t>(TensorB(), val);\n   ASSERT_EQ(1, response.metadata().step_stats().dev_stats_size());\n   EXPECT_EQ(\"/cpu:0\", response.metadata().step_stats().dev_stats(0).device());\n   ASSERT_EQ(1, response.metadata().partition_graphs_size());"
        },
        {
            "sha": "f98da9aa19629e39d8be1e69782a2bc01f7e15f1",
            "filename": "tensorflow/core/distributed_runtime/recent_request_ids.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Frecent_request_ids.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Frecent_request_ids.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Frecent_request_ids.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -61,7 +61,7 @@ bool RecentRequestIds::Insert(int64_t request_id) {\n }\n \n absl::Status RecentRequestIds::TrackUnique(int64_t request_id,\n-                                           const string& method_name,\n+                                           const std::string& method_name,\n                                            const protobuf::Message& request) {\n   if (Insert(request_id)) {\n     return absl::OkStatus();"
        },
        {
            "sha": "0299d3d92891182397c9e57e2508fd977d74aafe",
            "filename": "tensorflow/core/distributed_runtime/recent_request_ids.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Frecent_request_ids.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Frecent_request_ids.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Frecent_request_ids.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -60,11 +60,11 @@ class RecentRequestIds {\n   // num_tracked_request_ids insertions. For backwards compatibility, this\n   // always returns OK for request_id 0. The method_name and the request's\n   // ShortDebugString are added to returned errors.\n-  absl::Status TrackUnique(int64_t request_id, const string& method_name,\n+  absl::Status TrackUnique(int64_t request_id, const std::string& method_name,\n                            const protobuf::Message& request);\n   // Overloaded version of the above function for wrapped protos.\n   template <typename RequestWrapper>\n-  absl::Status TrackUnique(int64_t request_id, const string& method_name,\n+  absl::Status TrackUnique(int64_t request_id, const std::string& method_name,\n                            const RequestWrapper* wrapper);\n \n  private:\n@@ -88,7 +88,7 @@ class RecentRequestIds {\n \n template <typename RequestWrapper>\n absl::Status RecentRequestIds::TrackUnique(int64_t request_id,\n-                                           const string& method_name,\n+                                           const std::string& method_name,\n                                            const RequestWrapper* wrapper) {\n   if (Insert(request_id)) {\n     return absl::OkStatus();"
        },
        {
            "sha": "5bcf27d54abd1c082cc673c4dce6567647710301",
            "filename": "tensorflow/core/distributed_runtime/remote_device.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fremote_device.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fremote_device.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fremote_device.cc?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -53,7 +53,7 @@ class RemoteDevice : public Device {\n   bool IsRemoteCallAllowed() const override { return true; }\n \n  private:\n-  const string local_dev_name_;\n+  const std::string local_dev_name_;\n \n   RemoteDevice(const RemoteDevice&) = delete;\n   void operator=(const RemoteDevice&) = delete;\n@@ -78,7 +78,8 @@ void AsRemoteDevices(\n }\n \n void NewRemoteDevices(Env* env, WorkerCacheInterface* worker_cache,\n-                      const string& worker_name, NewRemoteDevicesDone done) {\n+                      const std::string& worker_name,\n+                      NewRemoteDevicesDone done) {\n   WorkerInterface* wi = worker_cache->GetOrCreateWorker(worker_name);\n   if (wi == nullptr) {\n     std::vector<Device*> empty;"
        },
        {
            "sha": "806123ed71b205d97fac401c5ef1ae8e0c9105ad",
            "filename": "tensorflow/core/distributed_runtime/remote_device.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fremote_device.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c3f05a1f6ffca60dd699bc9ae48481011c9ad571/tensorflow%2Fcore%2Fdistributed_runtime%2Fremote_device.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdistributed_runtime%2Fremote_device.h?ref=c3f05a1f6ffca60dd699bc9ae48481011c9ad571",
            "patch": "@@ -62,7 +62,8 @@ void AsRemoteDevices(\n typedef std::function<void(const absl::Status&, std::vector<Device*>*)>\n     NewRemoteDevicesDone;\n void NewRemoteDevices(Env* env, WorkerCacheInterface* worker_cache,\n-                      const string& worker_name, NewRemoteDevicesDone done);\n+                      const std::string& worker_name,\n+                      NewRemoteDevicesDone done);\n \n // Create Remote Device based on the given attributes.\n std::unique_ptr<Device> NewRemoteDevice(Env* env,"
        }
    ],
    "stats": {
        "total": 995,
        "additions": 515,
        "deletions": 480
    }
}