{
    "author": "basioli-k",
    "message": "[XLA:GPU] Run GPU compiler passes only on the main execution thread for AMD\n\nMissed this in the previous PR\n\nPiperOrigin-RevId: 798125938",
    "sha": "0724da0bfdbd65eed45ad0efed44ebdb68b69ac0",
    "files": [
        {
            "sha": "727936e99717e68ad109d8f2a92e07ec875ab18e",
            "filename": "third_party/xla/xla/service/gpu/amdgpu_compiler.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 3,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0724da0bfdbd65eed45ad0efed44ebdb68b69ac0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Famdgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0724da0bfdbd65eed45ad0efed44ebdb68b69ac0/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Famdgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Famdgpu_compiler.cc?ref=0724da0bfdbd65eed45ad0efed44ebdb68b69ac0",
            "patch": "@@ -172,7 +172,11 @@ absl::Status AMDGPUCompiler::OptimizeHloConvolutionCanonicalization(\n   // CudnnConvPadForTensorCores may add instructions which can be simplified\n   // by constant folding.\n   pipeline.AddPass<HloConstantFolding>();\n-  TF_RETURN_IF_ERROR(pipeline.Run(hlo_module).status());\n+  TF_RETURN_IF_ERROR(\n+      pipeline\n+          .Run(hlo_module,\n+               /*execution_threads=*/{HloInstruction::kMainExecutionThread})\n+          .status());\n \n   return absl::OkStatus();\n }\n@@ -195,7 +199,11 @@ absl::Status AMDGPUCompiler::OptimizeHloPostLayoutAssignment(\n   // Padding a gemm operand that's a constant results in pad(constant).  Run\n   // constant-folding to simplify this into a new constant.\n   pre_pipeline.AddPass<HloConstantFolding>();\n-  TF_RETURN_IF_ERROR(pre_pipeline.Run(hlo_module).status());\n+  TF_RETURN_IF_ERROR(\n+      pre_pipeline\n+          .Run(hlo_module,\n+               /*execution_threads=*/{HloInstruction::kMainExecutionThread})\n+          .status());\n \n   TF_RETURN_IF_ERROR(GpuCompiler::OptimizeHloPostLayoutAssignment(\n       hlo_module, stream_exec, options, gpu_target_config, alias_info,\n@@ -207,7 +215,11 @@ absl::Status AMDGPUCompiler::OptimizeHloPostLayoutAssignment(\n   // memory.\n   post_pipeline.AddPass<TriangularSolveRewriter>();\n \n-  TF_RETURN_IF_ERROR(post_pipeline.Run(hlo_module).status());\n+  TF_RETURN_IF_ERROR(\n+      post_pipeline\n+          .Run(hlo_module,\n+               /*execution_threads=*/{HloInstruction::kMainExecutionThread})\n+          .status());\n \n   return absl::OkStatus();\n }"
        }
    ],
    "stats": {
        "total": 18,
        "additions": 15,
        "deletions": 3
    }
}