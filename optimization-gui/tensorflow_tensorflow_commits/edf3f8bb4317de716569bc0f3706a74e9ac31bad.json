{
    "author": "bchetioui",
    "message": "[XLA] Implement a `TiledHloSchedule` that transposes the iteration order over the non-contracting dimensions of a `dot`.\n\nA concrete use case when such a schedule is useful is when we have a matrix\nmultiplication such that a chunk of shape `(block_m, k)` of the left-hand\nside argument fully fits into L2. The transposed iteration order will step\nthrough the `n` dimension first, allowing to hit L2 cache more often when\nloading tiles of the left-hand side.\n\nThis schedule is intentionally restricted at the moment in order to unblock\nlaunching the generic Triton emitter for GEMMs.\n\nPiperOrigin-RevId: 820214481",
    "sha": "edf3f8bb4317de716569bc0f3706a74e9ac31bad",
    "files": [
        {
            "sha": "6906bc4b0779798b4843f29dc235eb57f60d2ee5",
            "filename": "third_party/xla/xla/codegen/tiling/BUILD",
            "status": "modified",
            "additions": 14,
            "deletions": 0,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/edf3f8bb4317de716569bc0f3706a74e9ac31bad/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/edf3f8bb4317de716569bc0f3706a74e9ac31bad/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2FBUILD?ref=edf3f8bb4317de716569bc0f3706a74e9ac31bad",
            "patch": "@@ -118,12 +118,18 @@ cc_library(\n     srcs = [\"tiled_hlo_schedule.cc\"],\n     hdrs = [\"tiled_hlo_schedule.h\"],\n     deps = [\n+        \":tiling_specification\",\n         \"//xla:util\",\n         \"//xla/hlo/analysis:indexing_analysis\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/service/gpu/model/experimental:symbolic_expr\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//llvm:Support\",\n@@ -135,15 +141,23 @@ xla_cc_test(\n     name = \"tiled_hlo_schedule_test\",\n     srcs = [\"tiled_hlo_schedule_test.cc\"],\n     deps = [\n+        \":symbolic_tile_analysis\",\n         \":tiled_hlo_schedule\",\n+        \":tiling_specification\",\n         \"//xla/hlo/analysis:indexing_analysis\",\n         \"//xla/hlo/analysis:interval\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/hlo/testlib:verified_hlo_module\",\n         \"//xla/service/gpu/model/experimental:symbolic_expr\",\n+        \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:status_matchers\",\n+        \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest_main\",\n+        \"@llvm-project//llvm:Support\",\n         \"@llvm-project//mlir:IR\",\n     ],\n )"
        },
        {
            "sha": "4a6dde771b8ad97fede46598084d18decca99a4a",
            "filename": "third_party/xla/xla/codegen/tiling/tiled_hlo_schedule.cc",
            "status": "modified",
            "additions": 151,
            "deletions": 10,
            "changes": 161,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/edf3f8bb4317de716569bc0f3706a74e9ac31bad/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2Ftiled_hlo_schedule.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/edf3f8bb4317de716569bc0f3706a74e9ac31bad/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2Ftiled_hlo_schedule.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2Ftiled_hlo_schedule.cc?ref=edf3f8bb4317de716569bc0f3706a74e9ac31bad",
            "patch": "@@ -18,25 +18,37 @@ limitations under the License.\n #include <cstdint>\n #include <vector>\n \n+#include \"absl/algorithm/container.h\"\n #include \"absl/log/check.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_format.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"llvm/ADT/STLExtras.h\"\n #include \"mlir/IR/AffineExpr.h\"\n #include \"mlir/IR/AffineMap.h\"\n #include \"mlir/IR/MLIRContext.h\"\n+#include \"xla/codegen/tiling/tiling_specification.h\"\n #include \"xla/hlo/analysis/indexing_analysis.h\"\n #include \"xla/hlo/analysis/indexing_map.h\"\n+#include \"xla/hlo/ir/hlo_casting_utils.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/service/gpu/model/experimental/symbolic_expr.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n \n namespace xla {\n \n-absl::StatusOr<IndexingMap> MajorToMinorTiledHloSchedule::Schedule(\n-    const IndexingMap& tile_offsets_indexing, IterationSpace iteration_space,\n-    gpu::SymbolicExprContext* symbolic_expr_context) const {\n-  mlir::MLIRContext* mlir_context = symbolic_expr_context->GetMLIRContext();\n+namespace {\n+\n+// Helper to validate that an iteration space is compatible with a tile offsets\n+// indexing map.\n+absl::Status ValidateIterationSpace(const IterationSpace& iteration_space,\n+                                    const IndexingMap& tile_offsets_indexing) {\n   if (iteration_space.size() != tile_offsets_indexing.GetDimVarsCount()) {\n     return absl::InvalidArgumentError(absl::StrFormat(\n         \"Expected iteration space to have exactly as many dimensions as there \"\n@@ -45,6 +57,30 @@ absl::StatusOr<IndexingMap> MajorToMinorTiledHloSchedule::Schedule(\n         iteration_space.size(), tile_offsets_indexing.GetDimVarsCount()));\n   }\n \n+  std::vector<int64_t> iteration_space_dims;\n+  iteration_space_dims.reserve(iteration_space.size());\n+\n+  for (const auto& [dim_id, dim_size] : iteration_space) {\n+    if (dim_id >= tile_offsets_indexing.GetDimVarsCount() || dim_id < 0) {\n+      return absl::InvalidArgumentError(absl::StrFormat(\n+          \"Dimension id %d is out of bounds for tile offsets indexing map with \"\n+          \"%d dimensions. This can happen if \",\n+          dim_id, tile_offsets_indexing.GetDimVarsCount()));\n+    }\n+\n+    if (absl::c_linear_search(iteration_space_dims, dim_id)) {\n+      return absl::InvalidArgumentError(absl::StrFormat(\n+          \"Iteration space contains multiple dimensions with id %d.\", dim_id));\n+    }\n+    iteration_space_dims.push_back(dim_id);\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::StatusOr<IndexingMap> MajorToMinorScheduleImpl(\n+    const IndexingMap& tile_offsets_indexing, IterationSpace iteration_space,\n+    gpu::SymbolicExprContext* symbolic_expr_context) {\n+  mlir::MLIRContext* mlir_context = symbolic_expr_context->GetMLIRContext();\n   mlir::AffineExpr program_id = mlir::getAffineDimExpr(0, mlir_context);\n \n   std::vector<int64_t> iteration_space_sizes;\n@@ -60,12 +96,6 @@ absl::StatusOr<IndexingMap> MajorToMinorTiledHloSchedule::Schedule(\n   for (auto [dim_info, tile_expr] : llvm::zip(\n            iteration_space, DelinearizeIndex(iteration_space_sizes, program_id,\n                                              symbolic_expr_context))) {\n-    if (dim_info.dimension_id >= tile_exprs.size()) {\n-      return absl::InvalidArgumentError(absl::StrFormat(\n-          \"Dimension id %d is out of bounds for tile offsets indexing map with \"\n-          \"%d dimensions. This can happen if \",\n-          dim_info.dimension_id, tile_exprs.size()));\n-    }\n     tile_exprs[dim_info.dimension_id] = tile_expr;\n   }\n   std::vector<IndexingMap::Variable> dim_vars{\n@@ -81,5 +111,116 @@ absl::StatusOr<IndexingMap> MajorToMinorTiledHloSchedule::Schedule(\n   scheduled_indexing.RemoveUnusedSymbols();\n   return scheduled_indexing;\n }\n+}  // namespace\n+\n+absl::StatusOr<IndexingMap> MajorToMinorTiledHloSchedule::Schedule(\n+    const IndexingMap& tile_offsets_indexing, IterationSpace iteration_space,\n+    gpu::SymbolicExprContext* ctx) const {\n+  TF_RETURN_IF_ERROR(\n+      ValidateIterationSpace(iteration_space, tile_offsets_indexing));\n+  return MajorToMinorScheduleImpl(tile_offsets_indexing, iteration_space, ctx);\n+}\n+\n+absl::StatusOr<TransposedDotTiledHloSchedule>\n+TransposedDotTiledHloSchedule::Create(\n+    const TilingSpecification& tiling_specification) {\n+  const TilingSpecification::ParameterMapping& parameter_mapping =\n+      tiling_specification.parameter_mapping();\n+  CHECK(!parameter_mapping.empty());\n+  const HloDotInstruction* dot =\n+      ::xla::DynCast<HloDotInstruction>(parameter_mapping.front().instruction);\n+  if (dot == nullptr) {\n+    return absl::InvalidArgumentError(\n+        absl::StrCat(\"TransposedDotTiledHloSchedule expects its root to be a \"\n+                     \"dot instruction \"\n+                     \"but got \",\n+                     parameter_mapping.front().instruction->ToString()));\n+  }\n+  if (absl::c_any_of(absl::MakeSpan(parameter_mapping).subspan(1),\n+                     [](const auto& param) {\n+                       return param.instruction->opcode() == HloOpcode::kDot;\n+                     })) {\n+    return absl::InvalidArgumentError(\n+        \"TransposedDotTiledHloSchedule is only supported for \"\n+        \"TilingSpecifications specifying tiling for a single dot \"\n+        \"instruction.\");\n+  }\n+\n+  int64_t num_lhs_non_contracting_dims =\n+      dot->operand(0)->shape().dimensions().size() -\n+      dot->dot_dimension_numbers().lhs_contracting_dimensions().size() -\n+      dot->dot_dimension_numbers().lhs_batch_dimensions().size();\n+\n+  int64_t num_rhs_non_contracting_dims =\n+      dot->operand(1)->shape().dimensions().size() -\n+      dot->dot_dimension_numbers().rhs_contracting_dimensions().size() -\n+      dot->dot_dimension_numbers().rhs_batch_dimensions().size();\n+\n+  constexpr absl::string_view kErrorFormat =\n+      \"TransposedDotTiledHloSchedule is only supported for dot instructions \"\n+      \"with a single non-contracting dimension, but got %d non-contracting \"\n+      \"dimensions on the %s operand of %s.\";\n+\n+  if (num_lhs_non_contracting_dims != 1) {\n+    return absl::InvalidArgumentError(absl::StrFormat(\n+        kErrorFormat, num_lhs_non_contracting_dims, \"lhs\", dot->ToString()));\n+  }\n+\n+  if (num_rhs_non_contracting_dims != 1) {\n+    return absl::InvalidArgumentError(absl::StrFormat(\n+        kErrorFormat, num_rhs_non_contracting_dims, \"rhs\", dot->ToString()));\n+  }\n+\n+  // The shape of the dot's output is now known to always be of the form\n+  // [..., m, n]. This is because batch dimensions precede non-contracting\n+  // dimensions, the lhs non-contracting dimensions precede the rhs\n+  // non-contracting dimensions, and there is exactly one such dimension on\n+  // each side.\n+  //\n+  // Figure out the parameter index of the m and n dimensions within the op.\n+  int64_t m_local_parameter_index =\n+      parameter_mapping.front().num_tiling_parameters - 2;\n+  int64_t n_local_parameter_index =\n+      parameter_mapping.front().num_tiling_parameters - 1;\n+\n+  // Using the local parameter index, we can compute the global parameter index\n+  // (i.e. the parameter index within the sequence of all tiling parameters).\n+  TF_ASSIGN_OR_RETURN(int64_t m_dim_id, tiling_specification.ParameterIndex(\n+                                            dot, m_local_parameter_index));\n+  TF_ASSIGN_OR_RETURN(int64_t n_dim_id, tiling_specification.ParameterIndex(\n+                                            dot, n_local_parameter_index));\n+\n+  return TransposedDotTiledHloSchedule(tiling_specification, m_dim_id,\n+                                       n_dim_id);\n+}\n+\n+absl::StatusOr<IndexingMap> TransposedDotTiledHloSchedule::Schedule(\n+    const IndexingMap& tile_offsets_indexing, IterationSpace iteration_space,\n+    gpu::SymbolicExprContext* ctx) const {\n+  CHECK_EQ(iteration_space.size(), tiling_specification_.num_parameters());\n+  TF_RETURN_IF_ERROR(\n+      ValidateIterationSpace(iteration_space, tile_offsets_indexing));\n+\n+  DimensionInfo m_dim_info = iteration_space[m_dim_id_];\n+  DimensionInfo n_dim_info = iteration_space[n_dim_id_];\n+\n+  if (m_dim_info.dimension_id != m_dim_id_) {\n+    return absl::InvalidArgumentError(absl::StrFormat(\n+        \"Expected dimension at offset %d to have id %d but got %d.\", m_dim_id_,\n+        m_dim_id_, m_dim_info.dimension_id));\n+  }\n+  if (n_dim_info.dimension_id != n_dim_id_) {\n+    return absl::InvalidArgumentError(absl::StrFormat(\n+        \"Expected dimension at offset %d to have id %d but got %d.\", n_dim_id_,\n+        n_dim_id_, n_dim_info.dimension_id));\n+  }\n+\n+  std::vector<DimensionInfo> transposed_iteration_space(iteration_space.begin(),\n+                                                        iteration_space.end());\n+  transposed_iteration_space[m_dim_id_] = n_dim_info;\n+  transposed_iteration_space[n_dim_id_] = m_dim_info;\n+  return MajorToMinorScheduleImpl(tile_offsets_indexing,\n+                                  transposed_iteration_space, ctx);\n+}\n \n }  // namespace xla"
        },
        {
            "sha": "fdd87b117eddb6ff62932118c9d69cb752964ce4",
            "filename": "third_party/xla/xla/codegen/tiling/tiled_hlo_schedule.h",
            "status": "modified",
            "additions": 41,
            "deletions": 2,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/edf3f8bb4317de716569bc0f3706a74e9ac31bad/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2Ftiled_hlo_schedule.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/edf3f8bb4317de716569bc0f3706a74e9ac31bad/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2Ftiled_hlo_schedule.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2Ftiled_hlo_schedule.h?ref=edf3f8bb4317de716569bc0f3706a74e9ac31bad",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n \n #include \"absl/status/statusor.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/codegen/tiling/tiling_specification.h\"\n #include \"xla/hlo/analysis/indexing_map.h\"\n #include \"xla/service/gpu/model/experimental/symbolic_expr.h\"\n \n@@ -68,7 +69,7 @@ class TiledHloSchedule {\n   //     themselves);\n   virtual absl::StatusOr<IndexingMap> Schedule(\n       const IndexingMap& tile_offsets_indexing, IterationSpace iteration_space,\n-      gpu::SymbolicExprContext* symbolic_expr_context) const = 0;\n+      gpu::SymbolicExprContext* ctx) const = 0;\n };\n \n // The indexing map returned by this schedule iterates over the iteration space\n@@ -79,7 +80,45 @@ class MajorToMinorTiledHloSchedule : public TiledHloSchedule {\n  public:\n   absl::StatusOr<IndexingMap> Schedule(\n       const IndexingMap& tile_offsets_indexing, IterationSpace iteration_space,\n-      gpu::SymbolicExprContext* symbolic_expr_context) const override;\n+      gpu::SymbolicExprContext* ctx) const override;\n+};\n+\n+// Given a `TilingSpecification` where some of the output tile sizes are\n+// provided by a `dot` operation with one left-hand-side and one\n+// right-hand-side non-contracting dimensions, this schedule transposes the\n+// iteration pattern over these output dimensions.\n+//\n+// This schedule is only constructible when the underlying `TilingSpecification`\n+// contains a single `dot` node.\n+//\n+// TODO(b/417977182): this is implemented as a very bespoke pattern to unblock\n+// the launch of the generic emitter. We probably will want to subsume this with\n+// a more flexible approach for user-specified transposed schedules (that don't\n+// rely on the \"dot\" instruction being at the root).\n+class TransposedDotTiledHloSchedule : public TiledHloSchedule {\n+ public:\n+  absl::StatusOr<IndexingMap> Schedule(\n+      const IndexingMap& tile_offsets_indexing, IterationSpace iteration_space,\n+      gpu::SymbolicExprContext* ctx) const override;\n+\n+  static absl::StatusOr<TransposedDotTiledHloSchedule> Create(\n+      const TilingSpecification& tiling_specification);\n+\n+ private:\n+  TransposedDotTiledHloSchedule(const TilingSpecification& tiling_specification,\n+                                int64_t m_dim_id, int64_t n_dim_id)\n+      : tiling_specification_(tiling_specification),\n+        m_dim_id_(m_dim_id),\n+        n_dim_id_(n_dim_id) {}\n+\n+  // The `TilingSpecification` used to construct this schedule.\n+  TilingSpecification tiling_specification_;\n+  // The index of the `m` dimension within the parameter mapping of the\n+  // `TilingSpecification`.\n+  int64_t m_dim_id_;\n+  // The index of the `n` dimension within the parameter mapping of the\n+  // `TilingSpecification`.\n+  int64_t n_dim_id_;\n };\n \n // TODO(b/417977182): implement the `PlanarSnakeTiledHloSchedule` schedule."
        },
        {
            "sha": "424fb6647bc307c1b8913a96e6518f69add8051f",
            "filename": "third_party/xla/xla/codegen/tiling/tiled_hlo_schedule_test.cc",
            "status": "modified",
            "additions": 280,
            "deletions": 0,
            "changes": 280,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/edf3f8bb4317de716569bc0f3706a74e9ac31bad/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2Ftiled_hlo_schedule_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/edf3f8bb4317de716569bc0f3706a74e9ac31bad/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2Ftiled_hlo_schedule_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Ftiling%2Ftiled_hlo_schedule_test.cc?ref=edf3f8bb4317de716569bc0f3706a74e9ac31bad",
            "patch": "@@ -16,25 +16,38 @@ limitations under the License.\n #include \"xla/codegen/tiling/tiled_hlo_schedule.h\"\n \n #include <cstdint>\n+#include <memory>\n+#include <utility>\n+#include <variant>\n #include <vector>\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n+#include \"absl/log/check.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/status_matchers.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"llvm/ADT/STLExtras.h\"\n+#include \"llvm/ADT/SmallVector.h\"\n #include \"mlir/IR/AffineExpr.h\"\n #include \"mlir/IR/MLIRContext.h\"\n+#include \"xla/codegen/tiling/symbolic_tile_analysis.h\"\n+#include \"xla/codegen/tiling/tiling_specification.h\"\n #include \"xla/hlo/analysis/indexing_map.h\"\n #include \"xla/hlo/analysis/indexing_map_serialization.h\"\n #include \"xla/hlo/analysis/interval.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/hlo/testlib/verified_hlo_module.h\"\n #include \"xla/service/gpu/model/experimental/symbolic_expr.h\"\n+#include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/statusor.h\"\n \n namespace xla {\n namespace {\n \n using ::absl_testing::StatusIs;\n+using ::mlir::AffineExpr;\n using ::testing::HasSubstr;\n \n class TiledHloScheduleTest : public HloHardwareIndependentTestBase {\n@@ -115,5 +128,272 @@ TEST_F(MajorToMinorTiledHloScheduleTest,\n                        HasSubstr(\"Dimension id 2 is out of bounds\")));\n }\n \n+class TransposedDotTiledHloScheduleTest : public TiledHloScheduleTest {\n+ public:\n+  absl::StatusOr<TilingSpecification> TilingSpecificationForModule(\n+      HloModule* module) {\n+    SymbolicTileAnalysisOrError analysis_or_error =\n+        SymbolicTileAnalysis::AnalyzeComputation(\n+            *module->entry_computation()\n+                 ->root_instruction()\n+                 ->fused_instructions_computation(),\n+            &symbolic_expr_context_,\n+            /*emitter_specific_constraints_builder=*/nullptr);\n+\n+    if (!std::holds_alternative<SymbolicTileAnalysis>(analysis_or_error)) {\n+      return absl::InvalidArgumentError(\n+          \"SymbolicTileAnalysis expected to be present\");\n+    }\n+    return std::get<SymbolicTileAnalysis>(std::move(analysis_or_error))\n+        .GetTilingSpecification();\n+  }\n+};\n+\n+TEST_F(TransposedDotTiledHloScheduleTest,\n+       CanBeCreatedForFusionRootedInSingleDot) {\n+  constexpr absl::string_view kSupportedFusionHlo = R\"(\n+lhs {\n+  ROOT p0 = bf16[2,3,8192,256] parameter(0)\n+}\n+\n+rhs {\n+  ROOT p0 = bf16[2,3,256,512] parameter(0)\n+}\n+\n+dot {\n+  p0 = bf16[2,3,8192,256] parameter(0)\n+  p1 = bf16[2,3,256,512] parameter(1)\n+\n+  lhs = bf16[2,3,8192,256] fusion(p0), kind=kCustom, calls=lhs\n+  rhs = bf16[2,3,256,512] fusion(p1), kind=kCustom, calls=rhs\n+\n+  ROOT dot = bf16[2,3,8192,512] dot(lhs, rhs),\n+    lhs_batch_dims={0,1}, rhs_batch_dims={0,1},\n+    lhs_contracting_dims={3}, rhs_contracting_dims={2}\n+}\n+\n+ENTRY main {\n+  p0 = bf16[2,3,8192,256] parameter(0)\n+  p1 = bf16[2,3,256,512] parameter(1)\n+  ROOT fusion = bf16[2,3,8192,512] fusion(p0, p1), kind=kCustom, calls=dot\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(kSupportedFusionHlo));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(TilingSpecification tiling_specification,\n+                          TilingSpecificationForModule(module.get()));\n+\n+  TF_EXPECT_OK(TransposedDotTiledHloSchedule::Create(tiling_specification));\n+}\n+\n+TEST_F(TransposedDotTiledHloScheduleTest,\n+       CanNotBeCreatedForFusionRootedInNonDot) {\n+  constexpr absl::string_view kUnsupportedNonDotHlo = R\"(\n+dot {\n+  ROOT p0 = bf16[128] parameter(0)\n+}\n+\n+ENTRY main {\n+  p0 = bf16[128] parameter(0)\n+  ROOT fusion = bf16[128] fusion(p0), kind=kCustom, calls=dot\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(kUnsupportedNonDotHlo));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(TilingSpecification tiling_specification,\n+                          TilingSpecificationForModule(module.get()));\n+  EXPECT_THAT(TransposedDotTiledHloSchedule::Create(tiling_specification),\n+              StatusIs(absl::StatusCode::kInvalidArgument,\n+                       HasSubstr(\"expects its root to be a dot\")));\n+}\n+\n+TEST_F(TransposedDotTiledHloScheduleTest, CanNotBeCreatedForMultiDotFusion) {\n+  constexpr absl::string_view kUnsupportedMultiDotHlo = R\"(\n+lhs {\n+  ROOT p0 = bf16[64,64] parameter(0)\n+}\n+\n+nested_lhs {\n+  ROOT p0 = bf16[64,64] parameter(0)\n+}\n+\n+nested_rhs {\n+  ROOT p0 = bf16[64,64] parameter(0)\n+}\n+\n+rhs {\n+  p0 = bf16[64,64] parameter(0)\n+  lhs = bf16[64,64] fusion(p0), kind=kCustom, calls=nested_lhs\n+  rhs = bf16[64,64] fusion(p0), kind=kCustom, calls=nested_rhs\n+  ROOT dot = bf16[64,64] dot(lhs, rhs),\n+    lhs_batch_dims={}, rhs_batch_dims={},\n+    lhs_contracting_dims={0}, rhs_contracting_dims={1}\n+}\n+\n+dot {\n+  p0 = bf16[64,64] parameter(0)\n+  p1 = bf16[64,64] parameter(1)\n+\n+  lhs = bf16[64,64] fusion(p0), kind=kCustom, calls=lhs\n+  rhs = bf16[64,64] fusion(p1), kind=kCustom, calls=rhs\n+  ROOT dot = bf16[64,64] dot(lhs, rhs),\n+    lhs_batch_dims={}, rhs_batch_dims={},\n+    lhs_contracting_dims={0}, rhs_contracting_dims={1}\n+}\n+\n+ENTRY main {\n+  p0 = bf16[64,64] parameter(0)\n+  p1 = bf16[64,64] parameter(1)\n+  ROOT fusion = bf16[64,64] fusion(p0, p1), kind=kCustom, calls=dot\n+})\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<VerifiedHloModule> module,\n+      ParseAndReturnVerifiedModule(kUnsupportedMultiDotHlo));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(TilingSpecification tiling_specification,\n+                          TilingSpecificationForModule(module.get()));\n+\n+  EXPECT_THAT(\n+      TransposedDotTiledHloSchedule::Create(tiling_specification),\n+      StatusIs(absl::StatusCode::kInvalidArgument,\n+               HasSubstr(\n+                   \"only supported for \"\n+                   \"TilingSpecifications specifying tiling for a single dot\")));\n+}\n+\n+TEST_F(TransposedDotTiledHloScheduleTest,\n+       CanNotBeCreatedForDotWithMultipleNonContractingDimensions) {\n+  constexpr absl::string_view kSupportedFusionHlo = R\"(\n+lhs {\n+  ROOT p0 = bf16[2,8192,256] parameter(0)\n+}\n+\n+rhs {\n+  ROOT p0 = bf16[256,512] parameter(0)\n+}\n+\n+dot {\n+  p0 = bf16[2,8192,256] parameter(0)\n+  p1 = bf16[256,512] parameter(1)\n+\n+  lhs = bf16[2,8192,256] fusion(p0), kind=kCustom, calls=lhs\n+  rhs = bf16[256,512] fusion(p1), kind=kCustom, calls=rhs\n+\n+  ROOT dot = bf16[2,8192,512] dot(lhs, rhs),\n+    lhs_contracting_dims={2}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY main {\n+  p0 = bf16[2,8192,256] parameter(0)\n+  p1 = bf16[256,512] parameter(1)\n+  ROOT fusion = bf16[2,8192,512] fusion(p0, p1), kind=kCustom, calls=dot\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(kSupportedFusionHlo));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(TilingSpecification tiling_specification,\n+                          TilingSpecificationForModule(module.get()));\n+\n+  EXPECT_THAT(TransposedDotTiledHloSchedule::Create(tiling_specification),\n+              StatusIs(absl::StatusCode::kInvalidArgument,\n+                       HasSubstr(\"only supported for dot instructions with a \"\n+                                 \"single non-contracting dimension\")));\n+}\n+\n+TEST_F(\n+    TransposedDotTiledHloScheduleTest,\n+    SchedulingProducesTransposedIterationSpaceOfDotNonContractingDimensions) {\n+  constexpr absl::string_view kSupportedFusionHlo = R\"(\n+lhs {\n+  ROOT p0 = bf16[1,3,1024,256] parameter(0)\n+}\n+\n+rhs {\n+  ROOT p0 = bf16[1,3,256,512] parameter(0)\n+}\n+\n+dot {\n+  p0 = bf16[1,3,1024,256] parameter(0)\n+  p1 = bf16[1,3,256,512] parameter(1)\n+\n+  lhs = bf16[1,3,1024,256] fusion(p0), kind=kCustom, calls=lhs\n+  rhs = bf16[1,3,256,512] fusion(p1), kind=kCustom, calls=rhs\n+\n+  ROOT dot = bf16[1,3,1024,512] dot(lhs, rhs),\n+    lhs_batch_dims={0,1}, rhs_batch_dims={0,1},\n+    lhs_contracting_dims={3}, rhs_contracting_dims={2}\n+}\n+\n+ENTRY main {\n+  p0 = bf16[1,3,1024,256] parameter(0)\n+  p1 = bf16[1,3,256,512] parameter(1)\n+  ROOT fusion = bf16[1,3,1024,512] fusion(p0, p1), kind=kCustom, calls=dot\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(kSupportedFusionHlo));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(TilingSpecification tiling_specification,\n+                          TilingSpecificationForModule(module.get()));\n+\n+  MajorToMinorTiledHloSchedule major_to_minor_scheduler;\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      TransposedDotTiledHloSchedule transposed_scheduler,\n+      TransposedDotTiledHloSchedule::Create(tiling_specification));\n+\n+  IndexingMap offsets_indexing = *ParseIndexingMap(R\"(\n+      (d0, d1, d2, d3, d4) -> (d1, d2, d3, d4),\n+      domain: d0 in [0, 0], d1 in [0, 1], d2 in [0, 1], d3 in [0, 3],\n+              d4 in [0, 7])\",\n+                                                   &symbolic_expr_context_);\n+\n+  std::vector<DimensionInfo> iteration_space;\n+  iteration_space.reserve(offsets_indexing.GetDimVarsCount());\n+  int64_t linear_iteration_space_size = 1;\n+  for (const auto& [i, dim_var] :\n+       llvm::enumerate(offsets_indexing.GetDimVars())) {\n+    int64_t bound = offsets_indexing.GetDimensionBound(i).upper + 1;\n+    iteration_space.push_back({/*dimension_id=*/static_cast<int64_t>(i),\n+                               /*dimension_size=*/bound});\n+    linear_iteration_space_size *= bound;\n+  }\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      IndexingMap major_to_minor_scheduled_indexing,\n+      major_to_minor_scheduler.Schedule(offsets_indexing, iteration_space,\n+                                        &symbolic_expr_context_));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      IndexingMap transposed_scheduled_indexing,\n+      transposed_scheduler.Schedule(offsets_indexing, iteration_space,\n+                                    &symbolic_expr_context_));\n+\n+  int64_t m_bound = iteration_space[3].dimension_size;\n+  int64_t n_bound = iteration_space[4].dimension_size;\n+\n+  // Check that evaluating the scheduled indexing map yields a transposed\n+  // schedule across the non-contracting dimensions of the dot.\n+  for (int64_t i = 0; i < linear_iteration_space_size; ++i) {\n+    mlir::AffineExpr pid = mlir::getAffineConstantExpr(i, &mlir_context_);\n+    llvm::SmallVector<int64_t> major_to_minor_indices =\n+        major_to_minor_scheduled_indexing.Evaluate({pid}, {});\n+    llvm::SmallVector<int64_t> transposed_indices =\n+        transposed_scheduled_indexing.Evaluate({pid}, {});\n+\n+    // The first two dimensions should be identical.\n+    EXPECT_EQ(major_to_minor_indices[0], transposed_indices[0]);\n+    EXPECT_EQ(major_to_minor_indices[1], transposed_indices[1]);\n+    // The last two dimensions should be transposed!\n+    int64_t expected_major_to_minor_m_index = (i / n_bound) % m_bound;\n+    int64_t expected_major_to_minor_n_index = i % n_bound;\n+    EXPECT_EQ(major_to_minor_indices[2], expected_major_to_minor_m_index);\n+    EXPECT_EQ(major_to_minor_indices[3], expected_major_to_minor_n_index);\n+\n+    int64_t expected_transposed_m_index = i % m_bound;\n+    int64_t expected_transposed_n_index = (i / m_bound) % n_bound;\n+    EXPECT_EQ(transposed_indices[2], expected_transposed_m_index);\n+    EXPECT_EQ(transposed_indices[3], expected_transposed_n_index);\n+  }\n+}\n+\n }  // namespace\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 498,
        "additions": 486,
        "deletions": 12
    }
}