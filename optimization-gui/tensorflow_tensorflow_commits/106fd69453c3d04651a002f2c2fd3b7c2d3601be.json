{
    "author": "tensorflower-gardener",
    "message": "Refactor to use a walk on func ops instead of dialect conversion for sdy shard map import.\n\nIt is to prepare for ShardMapImport pass to subsume CloneManualComputations pass.\n\nPiperOrigin-RevId: 810014315",
    "sha": "106fd69453c3d04651a002f2c2fd3b7c2d3601be",
    "files": [
        {
            "sha": "84409c312131b0e718b5b67aef53cf1636e70bc3",
            "filename": "third_party/xla/xla/service/spmd/shardy/sdy_round_trip/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/106fd69453c3d04651a002f2c2fd3b7c2d3601be/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Fsdy_round_trip%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/106fd69453c3d04651a002f2c2fd3b7c2d3601be/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Fsdy_round_trip%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Fsdy_round_trip%2FBUILD?ref=106fd69453c3d04651a002f2c2fd3b7c2d3601be",
            "patch": "@@ -104,6 +104,7 @@ cc_library(\n         \"//xla/service/spmd/shardy:utils\",\n         \"@com_google_absl//absl/log:check\",\n         \"@llvm-project//llvm:Support\",\n+        \"@llvm-project//mlir:Analysis\",\n         \"@llvm-project//mlir:FuncDialect\",\n         \"@llvm-project//mlir:IR\",\n         \"@llvm-project//mlir:Pass\","
        },
        {
            "sha": "dc1eb2e610eb14f6be77d864f09d90e73214b43d",
            "filename": "third_party/xla/xla/service/spmd/shardy/sdy_round_trip/shard_map_import.cc",
            "status": "modified",
            "additions": 148,
            "deletions": 141,
            "changes": 289,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/106fd69453c3d04651a002f2c2fd3b7c2d3601be/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Fsdy_round_trip%2Fshard_map_import.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/106fd69453c3d04651a002f2c2fd3b7c2d3601be/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Fsdy_round_trip%2Fshard_map_import.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Fsdy_round_trip%2Fshard_map_import.cc?ref=106fd69453c3d04651a002f2c2fd3b7c2d3601be",
            "patch": "@@ -20,9 +20,12 @@ limitations under the License.\n #include <utility>\n \n #include \"absl/log/check.h\"\n+#include \"llvm/ADT/DenseSet.h\"\n+#include \"llvm/ADT/PostOrderIterator.h\"\n #include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/StringRef.h\"\n #include \"llvm/Support/ErrorHandling.h\"\n+#include \"mlir/Analysis/CallGraph.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n@@ -64,146 +67,127 @@ using ::mlir::stablehlo::CustomCallOp;\n \n namespace sdy = ::mlir::sdy;\n \n-// Converts a CallOp calling a @local_xla.sdy.manual_computation_body func with in/out\n-// shardings and manual axes as frontend attrs, wrapped with custom calls that\n-// change the shape of the arguments/results to a `ManualComputationOp`. See\n-// `SdyRoundTripShardMapExportPass` for its counterpart.\n-class ManualComputationPattern : public OpConversionPattern<CallOp> {\n- public:\n-  explicit ManualComputationPattern(MLIRContext* context,\n-                                    const SymbolTable& symbolTable)\n-      : OpConversionPattern<CallOp>(context), symbolTable(symbolTable) {}\n+mlir::LogicalResult rewriteManualComputation(\n+    CallOp callOp, mlir::IRRewriter& rewriter,\n+    const mlir::SymbolTable& symbolTable,\n+    llvm::SmallDenseSet<StringRef>& manualComputationCalleeNames) {\n+  if (manualComputationCalleeNames.contains(callOp.getCallee())) {\n+    return callOp->emitOpError(\n+        \"expected a unique FuncOp per @local_xla.sdy.manual_computation_body call. \"\n+        \"Were functions maybe somehow shared/de-duped between two \"\n+        \"ManualComputations?\");\n+  }\n+  auto shmapBodyFunc = symbolTable.lookup<FuncOp>(callOp.getCallee());\n \n-  mlir::LogicalResult matchAndRewrite(\n-      CallOp callOp, OpAdaptor adaptor,\n-      mlir::ConversionPatternRewriter& rewriter) const override {\n-    if (!callOp.getCallee().contains(kManualComputationFuncName)) {\n-      return mlir::failure();\n-    }\n+  // If the callOp has no uses, but has at least one result, then it means\n+  // all its results have a dimension of size 0 (i.e. 0 num-elements), and\n+  // therefore they were replaced with constants of the same shape. In which\n+  // case, we can safely erase the callOp and the manual computation body\n+  // function.\n+  if (callOp.use_empty() && !callOp->getResults().empty()) {\n+    rewriter.eraseOp(callOp);\n+    rewriter.eraseOp(shmapBodyFunc);\n+    return mlir::success();\n+  }\n \n-    auto shmapBodyFunc = symbolTable.lookup<FuncOp>(callOp.getCallee());\n-    if (shmapBodyFunc.empty()) {\n-      return callOp->emitOpError(\n-          \"expected a unique FuncOp per @local_xla.sdy.manual_computation_body call. \"\n-          \"Were functions maybe somehow shared/de-duped between two \"\n-          \"ManualComputations?\");\n+  // NOTE: if the original `ManualComputationOp` had no operands (results),\n+  // then a @GlobalToLocalShape (@LocalToGlobalShape) custom call won't be\n+  // present. So we have to take the operands/results of the newly created\n+  // `ManualComputationOp` differently depending on whether the original had\n+  // operands/results.\n+  CustomCallOp globalToLocalShape;\n+  mlir::ValueRange operands = callOp.getOperands();\n+  if (!operands.empty()) {\n+    // An input to `sdy.manual_computation` can have a dimension of size 0\n+    // (i.e. 0 num-elements), in which case, the corresponding result of\n+    // `GlobalToLocalShape` custom call would be replaced with a constant of\n+    // the same shape. Therefore, we skip such operands until we find the\n+    // first one that is produced by the custom call.\n+    auto customCallResIt = llvm::find_if(operands, [](mlir::Value operand) {\n+      return operand.getDefiningOp<CustomCallOp>();\n+    });\n+    if (customCallResIt == operands.end()) {\n+      return callOp->emitOpError(\"expected at least one operand of \")\n+             << callOp.getCalleeAttr() << \" to be produced by a \"\n+             << kGlobalToLocalShapeCallTargetName << \" CustomCallOp\";\n     }\n+    globalToLocalShape = (*customCallResIt).getDefiningOp<CustomCallOp>();\n+    CHECK(globalToLocalShape.getCallTargetName() ==\n+          kGlobalToLocalShapeCallTargetName);\n+    operands = globalToLocalShape->getOperands();\n+  }\n \n-    // If the callOp has no uses, but has at least one result, then it means\n-    // all its results have a dimension of size 0 (i.e. 0 num-elements), and\n-    // therefore they were replaced with constants of the same shape. In which\n-    // case, we can safely erase the callOp and the manual computation body\n-    // function.\n-    if (callOp.use_empty() && !callOp->getResults().empty()) {\n-      rewriter.eraseOp(callOp);\n-      rewriter.eraseOp(shmapBodyFunc);\n-      return mlir::success();\n+  mlir::TypeRange resultTypes = callOp->getResultTypes();\n+  CustomCallOp localToGlobalShape;\n+  if (!resultTypes.empty()) {\n+    // Same as above, a result of `sdy.manual_computation` can have a\n+    // dimension of size 0, in which case, the corresponding result of\n+    // `@local_xla.sdy.manual_computation_body` call would be replaced with a\n+    // constant. Therefore, we check the first use rather than first result.\n+    CHECK(!callOp->use_empty());\n+    localToGlobalShape = mlir::dyn_cast<CustomCallOp>(*callOp->user_begin());\n+    if (!localToGlobalShape) {\n+      return callOp->emitOpError(\"expected the first use of \")\n+             << callOp.getCalleeAttr() << \" to be a \"\n+             << kLocalToGlobalShapeCallTargetName << \" CustomCallOp\";\n     }\n+    CHECK(localToGlobalShape.getCallTargetName() ==\n+          kLocalToGlobalShapeCallTargetName);\n+    resultTypes = localToGlobalShape->getResultTypes();\n+  }\n \n-    // NOTE: if the original `ManualComputationOp` had no operands (results),\n-    // then a @GlobalToLocalShape (@LocalToGlobalShape) custom call won't be\n-    // present. So we have to take the operands/results of the newly created\n-    // `ManualComputationOp` differently depending on whether the original had\n-    // operands/results.\n-    CustomCallOp globalToLocalShape;\n-    mlir::ValueRange operands = adaptor.getOperands();\n-    if (!operands.empty()) {\n-      // An input to `sdy.manual_computation` can have a dimension of size 0\n-      // (i.e. 0 num-elements), in which case, the corresponding result of\n-      // `GlobalToLocalShape` custom call would be replaced with a constant of\n-      // the same shape. Therefore, we skip such operands until we find the\n-      // first one that is produced by the custom call.\n-      auto customCallResIt = llvm::find_if(operands, [](mlir::Value operand) {\n-        return operand.getDefiningOp<CustomCallOp>();\n-      });\n-      if (customCallResIt == operands.end()) {\n-        return callOp->emitOpError(\"expected at least one operand of \")\n-               << callOp.getCalleeAttr() << \" to be produced by a \"\n-               << kGlobalToLocalShapeCallTargetName << \" CustomCallOp\";\n-      }\n-      globalToLocalShape = (*customCallResIt).getDefiningOp<CustomCallOp>();\n-      CHECK(globalToLocalShape.getCallTargetName() ==\n-            kGlobalToLocalShapeCallTargetName);\n-      operands = globalToLocalShape->getOperands();\n+  MLIRContext* context = rewriter.getContext();\n+  sdy::TensorShardingPerValueAttr inShardings =\n+      sdy::TensorShardingPerValueAttr::get(context, {});\n+  sdy::TensorShardingPerValueAttr outShardings =\n+      sdy::TensorShardingPerValueAttr::get(context, {});\n+  sdy::ManualAxesAttr manualAxes = sdy::ManualAxesAttr::get(context, {});\n+  bool newCodePath = false;\n+\n+  auto setShardingAttrs = [&newCodePath, &manualAxes](\n+                              CustomCallOp customCallOp,\n+                              sdy::TensorShardingPerValueAttr& shardings,\n+                              llvm::StringRef shardingAttrName) {\n+    if (!customCallOp) {\n+      return;\n     }\n-    mlir::TypeRange resultTypes = callOp->getResultTypes();\n-    CustomCallOp localToGlobalShape;\n-    if (!resultTypes.empty()) {\n-      // Same as above, a result of `sdy.manual_computation` can have a\n-      // dimension of size 0, in which case, the corresponding result of\n-      // `@local_xla.sdy.manual_computation_body` call would be replaced with a\n-      // constant. Therefore, we check the first use rather than first result.\n-      CHECK(!callOp->use_empty());\n-      localToGlobalShape = mlir::dyn_cast<CustomCallOp>(*callOp->user_begin());\n-      if (!localToGlobalShape) {\n-        return callOp->emitOpError(\"expected the first use of \")\n-               << callOp.getCalleeAttr() << \" to be a \"\n-               << kLocalToGlobalShapeCallTargetName << \" CustomCallOp\";\n+    if (mlir::DictionaryAttr frontendAttrs = getFrontendAttrs(customCallOp)) {\n+      newCodePath = true;\n+      shardings = parseStringAttr<sdy::TensorShardingPerValueAttr>(\n+          frontendAttrs, shardingAttrName);\n+      if (manualAxes.empty()) {\n+        manualAxes =\n+            parseStringAttr<sdy::ManualAxesAttr>(frontendAttrs, kManualAxes);\n       }\n-      CHECK(localToGlobalShape.getCallTargetName() ==\n-            kLocalToGlobalShapeCallTargetName);\n-      resultTypes = localToGlobalShape->getResultTypes();\n     }\n+  };\n \n-    MLIRContext* context = rewriter.getContext();\n-    sdy::TensorShardingPerValueAttr inShardings =\n-        sdy::TensorShardingPerValueAttr::get(context, {});\n-    sdy::TensorShardingPerValueAttr outShardings =\n-        sdy::TensorShardingPerValueAttr::get(context, {});\n-    sdy::ManualAxesAttr manualAxes = sdy::ManualAxesAttr::get(context, {});\n-    bool newCodePath = false;\n-\n-    auto setShardingAttrs = [&newCodePath, &manualAxes](\n-                                CustomCallOp customCallOp,\n-                                sdy::TensorShardingPerValueAttr& shardings,\n-                                llvm::StringRef shardingAttrName) {\n-      if (!customCallOp) {\n-        return;\n-      }\n-      if (mlir::DictionaryAttr frontendAttrs = getFrontendAttrs(customCallOp)) {\n-        newCodePath = true;\n-        shardings = parseStringAttr<sdy::TensorShardingPerValueAttr>(\n-            frontendAttrs, shardingAttrName);\n-        if (manualAxes.empty()) {\n-          manualAxes =\n-              parseStringAttr<sdy::ManualAxesAttr>(frontendAttrs, kManualAxes);\n-        }\n-      }\n-    };\n-\n-    setShardingAttrs(globalToLocalShape, inShardings, kInShardings);\n-    setShardingAttrs(localToGlobalShape, outShardings, kOutShardings);\n-    // TODO(b/410499196): Code to handle loading an old checkpoint. Remove after\n-    // 6 months of cl/745735176 being submitted.\n-    mlir::DictionaryAttr callOpFrontendAttrs = getFrontendAttrs(callOp);\n-    if (!newCodePath && callOpFrontendAttrs &&\n-        callOpFrontendAttrs.contains(kManualAxes)) {\n-      inShardings = parseStringAttr<sdy::TensorShardingPerValueAttr>(\n-          callOpFrontendAttrs, kInShardings);\n-      outShardings = parseStringAttr<sdy::TensorShardingPerValueAttr>(\n-          callOpFrontendAttrs, kOutShardings);\n-      manualAxes = parseStringAttr<sdy::ManualAxesAttr>(callOpFrontendAttrs,\n-                                                        kManualAxes);\n-    }\n-    auto manualComputationOp =\n-        rewriter.replaceOpWithNewOp<sdy::ManualComputationOp>(\n-            callOp, resultTypes, operands, inShardings, outShardings,\n-            manualAxes);\n-    sdy::inlineRegionAndConvertTerminatorOp<sdy::ReturnOp>(\n-        shmapBodyFunc.getBody(), manualComputationOp.getRegion(), rewriter);\n-    rewriter.eraseOp(shmapBodyFunc);\n-    if (globalToLocalShape) {\n-      rewriter.eraseOp(globalToLocalShape);\n-    }\n-    if (localToGlobalShape) {\n-      rewriter.replaceOp(localToGlobalShape, manualComputationOp->getResults());\n-    }\n-    return mlir::success();\n+  setShardingAttrs(globalToLocalShape, inShardings, kInShardings);\n+  setShardingAttrs(localToGlobalShape, outShardings, kOutShardings);\n+  // TODO(b/410499196): Code to handle loading an old checkpoint. Remove after\n+  // 6 months of cl/745735176 being submitted.\n+  mlir::DictionaryAttr callOpFrontendAttrs = getFrontendAttrs(callOp);\n+  if (!newCodePath && callOpFrontendAttrs &&\n+      callOpFrontendAttrs.contains(kManualAxes)) {\n+    inShardings = parseStringAttr<sdy::TensorShardingPerValueAttr>(\n+        callOpFrontendAttrs, kInShardings);\n+    outShardings = parseStringAttr<sdy::TensorShardingPerValueAttr>(\n+        callOpFrontendAttrs, kOutShardings);\n+    manualAxes =\n+        parseStringAttr<sdy::ManualAxesAttr>(callOpFrontendAttrs, kManualAxes);\n   }\n-\n- private:\n-  const SymbolTable& symbolTable;\n-};\n+  manualComputationCalleeNames.insert(callOp.getCallee());\n+  auto manualComputationOp =\n+      rewriter.replaceOpWithNewOp<sdy::ManualComputationOp>(\n+          callOp, resultTypes, operands, inShardings, outShardings, manualAxes);\n+  sdy::inlineRegionAndConvertTerminatorOp<sdy::ReturnOp>(\n+      shmapBodyFunc.getBody(), manualComputationOp.getRegion(), rewriter);\n+  if (localToGlobalShape) {\n+    rewriter.replaceAllUsesWith(localToGlobalShape.getResults(),\n+                                manualComputationOp->getResults());\n+  }\n+  return mlir::success();\n+}\n \n class SdyRoundTripShardMapImportPass\n     : public mlir::PassWrapper<SdyRoundTripShardMapImportPass,\n@@ -216,20 +200,38 @@ class SdyRoundTripShardMapImportPass\n     ModuleOp module = getOperation();\n     mlir::SymbolTableCollection symbolTableCollection;\n     SymbolTable& symbolTable = symbolTableCollection.getSymbolTable(module);\n-    MLIRContext& context = getContext();\n-    mlir::ConversionTarget target(context);\n-    target.addDynamicallyLegalOp<CallOp>([](CallOp op) {\n-      return !op.getCallee().contains(kManualComputationFuncName);\n-    });\n-    target.addLegalOp<sdy::ManualComputationOp, sdy::ReturnOp, CustomCallOp>();\n-    mlir::RewritePatternSet patterns(&context);\n-    patterns.add<ManualComputationPattern>(&context, symbolTable);\n-    if (mlir::failed(mlir::applyPartialConversion(module, target,\n-                                                  std::move(patterns)))) {\n-      return signalPassFailure();\n+    mlir::IRRewriter rewriter(module);\n+    llvm::SmallDenseSet<StringRef> manualComputationCalleeNames;\n+\n+    mlir::CallGraph callGraph(module);\n+    llvm::ReversePostOrderTraversal<const mlir::CallGraph*> rpo(&callGraph);\n+    for (mlir::CallGraphNode* node : llvm::reverse(rpo)) {\n+      if (node->isExternal()) continue;\n+      if (node->getCallableRegion()\n+              ->walk([&](CallOp callOp) {\n+                if (!callOp.getCallee().contains(kManualComputationFuncName)) {\n+                  return mlir::WalkResult::advance();\n+                }\n+                rewriter.setInsertionPoint(callOp);\n+                if (mlir::failed(rewriteManualComputation(\n+                        callOp, rewriter, symbolTable,\n+                        manualComputationCalleeNames))) {\n+                  callOp.emitError(\n+                      \"failed to rewrite func.call to manual computation\");\n+                  return mlir::WalkResult::interrupt();\n+                }\n+                return mlir::WalkResult::advance();\n+              })\n+              .wasInterrupted()) {\n+        return signalPassFailure();\n+      }\n     }\n \n-    // At this point, there may be stray `xla.sdy.GlobalToLocalShape` and\n+    // Erase all `xla.sdy.GlobalToLocalShape` and `xla.sdy.LocalToGlobalShape`\n+    // custom calls.\n+    //\n+    // NOTE: In addition to the ones that were used by calls, at this point,\n+    // there may be stray `xla.sdy.GlobalToLocalShape` and\n     // `xla.sdy.LocalToGlobalShape`, if the `@local_xla.sdy.manual_computation_body`\n     // call was eliminated through DCE and the custom call uses were replaced\n     // with constants as they had 0 elements, then it's safe to erase.\n@@ -240,6 +242,11 @@ class SdyRoundTripShardMapImportPass\n         op.erase();\n       }\n     });\n+\n+    // Erase all manual computation func ops that now have no call ops.\n+    for (StringRef calleeName : manualComputationCalleeNames) {\n+      symbolTable.erase(symbolTable.lookup(calleeName));\n+    }\n   }\n \n   StringRef getArgument() const override {"
        },
        {
            "sha": "bd008c173ecd3908720b7b02593ffff5d0a77510",
            "filename": "third_party/xla/xla/service/spmd/shardy/test/sdy_round_trip_shard_map_import_failure.mlir",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/106fd69453c3d04651a002f2c2fd3b7c2d3601be/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Ftest%2Fsdy_round_trip_shard_map_import_failure.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/106fd69453c3d04651a002f2c2fd3b7c2d3601be/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Ftest%2Fsdy_round_trip_shard_map_import_failure.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Ftest%2Fsdy_round_trip_shard_map_import_failure.mlir?ref=106fd69453c3d04651a002f2c2fd3b7c2d3601be",
            "patch": "@@ -6,7 +6,7 @@ func.func @using_same_body_func(%arg0: tensor<8x8xf32>) -> tensor<8x8xf32> {\n   %2 = stablehlo.custom_call @local_xla.sdy.LocalToGlobalShape(%1) : (tensor<2x8xf32>) -> (tensor<8x8xf32>)\n   %3 = stablehlo.custom_call @local_xla.sdy.GlobalToLocalShape(%2) : (tensor<8x8xf32>) -> (tensor<2x8xf32>)\n   // expected-error @+2 {{'func.call' op expected a unique FuncOp per @local_xla.sdy.manual_computation_body call}}\n-  // expected-error @+1 {{failed to legalize operation 'func.call'}}\n+  // expected-error @+1 {{failed to rewrite func.call to manual computation}}\n   %4 = call @local_xla.sdy.manual_computation_body(%3) {mhlo.frontend_attributes = {xla.sdy.in_shardings = \"#sdy.sharding_per_value<[<@mesh, [{\\\\\\22a\\\\\\22}, {\\\\\\22b\\\\\\22}]>]>\", xla.sdy.manual_axes = \"#sdy<manual_axes{\\\\\\22a\\\\\\22, \\\\\\22b\\\\\\22}>\", xla.sdy.out_shardings = \"#sdy.sharding_per_value<[<@mesh, [{\\\\\\22a\\\\\\22}, {}], replicated={\\\\\\22b\\\\\\22}>]>\"}} : (tensor<2x8xf32>) -> (tensor<2x8xf32>)\n   %5 = stablehlo.custom_call @local_xla.sdy.LocalToGlobalShape(%4) : (tensor<2x8xf32>) -> (tensor<8x8xf32>)\n   return %5 : tensor<8x8xf32>\n@@ -21,7 +21,7 @@ func.func @local_xla.sdy.manual_computation_body(%arg0: tensor<2x8xf32>) -> tens\n func.func @manual_computation_missing_global_to_local_shape(%arg0: tensor<0x16xf32>) -> (tensor<0x16xf32>) {\n   %c = stablehlo.constant dense<0.000000e+00> : tensor<0x8xf32>\n   // expected-error @+2 {{'func.call' op expected at least one operand of @local_xla.sdy.manual_computation_body to be produced by a xla.sdy.GlobalToLocalShape CustomCallOp}}\n-  // expected-error @+1 {{failed to legalize operation 'func.call'}}\n+  // expected-error @+1 {{failed to rewrite func.call to manual computation}}\n   %0 = call @local_xla.sdy.manual_computation_body(%c) : (tensor<0x8xf32>) -> tensor<0x8xf32>\n   %1 = stablehlo.custom_call @local_xla.sdy.LocalToGlobalShape(%0) {mhlo.frontend_attributes = {xla.sdy.manual_axes = \"#sdy<manual_axes{\\22b\\22}>\", xla.sdy.out_shardings = \"#sdy.sharding_per_value<[<@mesh, [{}, {\\22b\\22}]>]>\"}} : (tensor<0x8xf32>) -> (tensor<0x16xf32>)\n   return %1 : tensor<0x16xf32>\n@@ -36,7 +36,7 @@ func.func @local_xla.sdy.manual_computation_body(%arg0: tensor<0x8xf32>) -> tens\n func.func @manual_computation_missing_local_to_global_shape(%arg0: tensor<0x16xf32>) -> (tensor<0x8xf32>) {\n   %0 = stablehlo.custom_call @local_xla.sdy.GlobalToLocalShape(%arg0) {mhlo.frontend_attributes = {xla.sdy.manual_axes = \"#sdy<manual_axes{\\22b\\22}>\", xla.sdy.in_shardings = \"#sdy.sharding_per_value<[<@mesh, [{}, {\\22b\\22}]>]>\"}} : (tensor<0x16xf32>) -> tensor<0x8xf32>\n   // expected-error @+2 {{'func.call' op expected the first use of @local_xla.sdy.manual_computation_body to be a xla.sdy.LocalToGlobalShape CustomCallOp}}\n-  // expected-error @+1 {{failed to legalize operation 'func.call'}}\n+  // expected-error @+1 {{failed to rewrite func.call to manual computation}}\n   %1 = call @local_xla.sdy.manual_computation_body(%0) : (tensor<0x8xf32>) -> tensor<0x8xf32>\n   return %1 : tensor<0x8xf32>\n }"
        }
    ],
    "stats": {
        "total": 296,
        "additions": 152,
        "deletions": 144
    }
}