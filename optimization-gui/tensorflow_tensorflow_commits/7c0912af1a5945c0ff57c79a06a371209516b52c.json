{
    "author": "bixia1",
    "message": "Extend HLO to MHLO conversion to handle buffer types and recognize buffer specific custom-call targets.\n\nPiperOrigin-RevId: 797883363",
    "sha": "7c0912af1a5945c0ff57c79a06a371209516b52c",
    "files": [
        {
            "sha": "7f721b48c30960ebd908a397d4a3bdc9dfaa4bb7",
            "filename": "third_party/xla/xla/hlo/translate/hlo_to_mhlo/hlo_function_importer.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 8,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7c0912af1a5945c0ff57c79a06a371209516b52c/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Fhlo_function_importer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7c0912af1a5945c0ff57c79a06a371209516b52c/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Fhlo_function_importer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Fhlo_function_importer.cc?ref=7c0912af1a5945c0ff57c79a06a371209516b52c",
            "patch": "@@ -1163,10 +1163,21 @@ absl::StatusOr<mlir::Operation*> HloFunctionImporter::ImportInstructionImpl(\n         attributes.push_back(builder_->getNamedAttr(\n             \"api_version\", mlir::mhlo::CustomCallApiVersionAttr::get(\n                                builder_->getContext(), mlir_api_version)));\n-        attributes.push_back(builder_->getNamedAttr(\n-            \"output_operand_aliases\",\n-            ConvertOutputOperandAliasing(instruction->output_operand_aliasing(),\n-                                         builder_)));\n+        // We consider the output operand alias associated with Pin and Unpin\n+        // an XLA/HLO implementation detail, such as to tell copy insertion that\n+        // if there is a needed we can copy the operand of Pin and the result of\n+        // Unpin, but can't copy the result of Pin and the operand of Unpin.\n+        // The Pin and Unpin operand and result aren't alias from users's\n+        // perspective, and they don't have the same types. For these reasons,\n+        // we don't want to expose this implementation detail to MHLO/StableHLO\n+        // users.\n+        if (!custom_call->IsCustomCall(kPinCustomCallTarget) &&\n+            !custom_call->IsCustomCall(kUnpinCustomCallTarget)) {\n+          attributes.push_back(builder_->getNamedAttr(\n+              \"output_operand_aliases\",\n+              ConvertOutputOperandAliasing(\n+                  instruction->output_operand_aliasing(), builder_)));\n+        }\n         // XLA Feature - MHLO Only\n         return func_builder\n             ->create<mlir::mhlo::CustomCallOp>(loc, result_type, operands,\n@@ -1181,10 +1192,13 @@ absl::StatusOr<mlir::Operation*> HloFunctionImporter::ImportInstructionImpl(\n       attributes.push_back(builder_->getNamedAttr(\n           \"api_version\", mlir::stablehlo::CustomCallApiVersionAttr::get(\n                              builder_->getContext(), mlir_api_version)));\n-      attributes.push_back(builder_->getNamedAttr(\n-          \"output_operand_aliases\",\n-          stablehlo::ConvertOutputOperandAliasing(\n-              instruction->output_operand_aliasing(), builder_)));\n+      if (!custom_call->IsCustomCall(kPinCustomCallTarget) &&\n+          !custom_call->IsCustomCall(kUnpinCustomCallTarget)) {\n+        attributes.push_back(builder_->getNamedAttr(\n+            \"output_operand_aliases\",\n+            stablehlo::ConvertOutputOperandAliasing(\n+                instruction->output_operand_aliasing(), builder_)));\n+      }\n       return func_builder\n           ->create<mlir::stablehlo::CustomCallOp>(loc, result_type, operands,\n                                                   attributes)"
        },
        {
            "sha": "a6efa24c72aa8beaa0d937b59a6e0ebedfd06abf",
            "filename": "third_party/xla/xla/hlo/translate/hlo_to_mhlo/hlo_utils.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7c0912af1a5945c0ff57c79a06a371209516b52c/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Fhlo_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7c0912af1a5945c0ff57c79a06a371209516b52c/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Fhlo_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Fhlo_utils.h?ref=7c0912af1a5945c0ff57c79a06a371209516b52c",
            "patch": "@@ -127,6 +127,11 @@ static absl::StatusOr<mlir::Type> ConvertShapeToType(const Shape& shape,\n   if (shape.IsToken()) {\n     return mlir::stablehlo::TokenType::get(builder.getContext());\n   }\n+  if (shape.IsBuffer()) {\n+    return ConvertTensorShapeToType<mlir::MemRefType>(shape.buffer_shape(),\n+                                                      builder);\n+  }\n+\n   return ConvertTensorShapeToType<TypeT>(shape, builder);\n }\n "
        },
        {
            "sha": "b8efc09c5ef6bbc41b108109310fa060b872a1f6",
            "filename": "third_party/xla/xla/hlo/translate/hlo_to_mhlo/tests/custom_call.hlo",
            "status": "modified",
            "additions": 35,
            "deletions": 0,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7c0912af1a5945c0ff57c79a06a371209516b52c/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Ftests%2Fcustom_call.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7c0912af1a5945c0ff57c79a06a371209516b52c/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Ftests%2Fcustom_call.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Ftests%2Fcustom_call.hlo?ref=7c0912af1a5945c0ff57c79a06a371209516b52c",
            "patch": "@@ -68,3 +68,38 @@ test_custom_call_ragged_all_to_all {\n   %Arg_5.6 = s32[3] parameter(5)\n   ROOT %custom-call.7 = f32[6] ragged-all-to-all(f32[6] %Arg_0.1, f32[6] %Arg_1.2, s32[3] %Arg_2.3, s32[3] %Arg_3.4, s32[3] %Arg_4.5, /*index=5*/s32[3] %Arg_5.6), channel_id=1, replica_groups={{0,1,2}}\n }\n+\n+// CHECK-LABEL:  func private @test_custom_call_create_buffer\n+//  CHECK-SAME:  () -> memref<2x4xf32>\n+//  CHECK-NEXT: mhlo.custom_call @CreateBuffer()\n+//   CHECK-NOT:  output_to_operand_aliasing\n+test_custom_call_create_buffer {\n+  ROOT %custom-call.2 = b(f32[2,4]) custom-call(), custom_call_target=\"CreateBuffer\", api_version=API_VERSION_TYPED_FFI\n+}\n+\n+// CHECK-LABEL:  func private @test_custom_call_pin\n+//  CHECK-SAME:  (%[[Arg:.*]]: tensor<4x16xf32>) -> memref<4x16xf32>\n+//  CHECK-NEXT: mhlo.custom_call @Pin(%[[Arg]])\n+//   CHECK-NOT:  output_to_operand_aliasing\n+test_custom_call_pin {\n+  %Arg_0.1 = f32[4, 16] parameter(0)\n+  ROOT %custom-call.2 = b(f32[4, 16]) custom-call(%Arg_0.1), custom_call_target=\"Pin\", output_to_operand_aliasing={{}: (0, {})}, api_version=API_VERSION_TYPED_FFI\n+}\n+\n+// CHECK-LABEL:  func private @test_custom_call_unpin\n+//  CHECK-SAME:  (%[[Arg:.*]]: memref<4x16xf32>) -> tensor<4x16xf32>\n+//  CHECK-NEXT: mhlo.custom_call @Unpin(%[[Arg]])\n+//   CHECK-NOT:  output_to_operand_aliasing\n+test_custom_call_unpin {\n+  %Arg_0.1 = b(f32[4, 16]) parameter(0)\n+  ROOT %custom-call.2 = f32[4, 16] custom-call(%Arg_0.1), custom_call_target=\"Unpin\", output_to_operand_aliasing={{}: (0, {})}, api_version=API_VERSION_TYPED_FFI\n+}\n+\n+// CHECK-LABEL:  func private @test_custom_call_other_with_buffers\n+//  CHECK-SAME:  (%[[Arg:.*]]: memref<4x16xf32>) -> memref<4x16xf32>\n+//  CHECK-NEXT: mhlo.custom_call @foo(%[[Arg]])\n+//  CHECK-SAME:  output_operand_aliases = [#mhlo.output_operand_alias<output_tuple_indices = [], operand_index = 0, operand_tuple_indices = []>]\n+test_custom_call_other_with_buffers {\n+  %Arg_0.1 = b(f32[4, 16]) parameter(0)\n+  ROOT %custom-call.2 = b(f32[4, 16]) custom-call(%Arg_0.1), custom_call_target=\"foo\", output_to_operand_aliasing={{}: (0, {})}, api_version=API_VERSION_TYPED_FFI\n+}"
        },
        {
            "sha": "6d91759abac0bf68d2db8ecbc740207e33e43392",
            "filename": "third_party/xla/xla/hlo/translate/hlo_to_mhlo/tests/types.hlo",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7c0912af1a5945c0ff57c79a06a371209516b52c/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Ftests%2Ftypes.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7c0912af1a5945c0ff57c79a06a371209516b52c/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Ftests%2Ftypes.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fhlo_to_mhlo%2Ftests%2Ftypes.hlo?ref=7c0912af1a5945c0ff57c79a06a371209516b52c",
            "patch": "@@ -7,6 +7,10 @@ ENTRY %tfcompile.1 {\n   // CHECK-NEXT: %[[VAL_0:.*]] = mhlo.constant dense<1.000000e+00> : tensor<f32>\n   %constant.0 = f32[] constant(1)\n \n+  // CHECK-NEXT: %[[VAL_9:.*]] = mhlo.custom_call @Pin(%[[VAL_0]])\n+  // CHECK-SAME:(tensor<f32>) -> memref<f32>\n+  %custom-call.0 = b(f32[]) custom-call(%constant.0), custom_call_target=\"Pin\", output_to_operand_aliasing={{}: (0, {})}, api_version=API_VERSION_TYPED_FFI\n+\n   // CHECK-NEXT: %[[VAL_1:.*]] = mhlo.constant dense<1.000000e+00> : tensor<f64>\n   %constant.1 = f64[] constant(1)\n "
        }
    ],
    "stats": {
        "total": 74,
        "additions": 66,
        "deletions": 8
    }
}