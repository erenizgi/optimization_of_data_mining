{
    "author": "tensorflower-gardener",
    "message": "Set DNN version in DeviceDescription for autotuner cache.\n\nThe dnn_version in device_description was not set, cl/816579045 fixed it for old autotuner infra, this change ports that change to the new autotuner infra.\n\nPiperOrigin-RevId: 821728904",
    "sha": "458995b35d6bd20fd95120eabd16b47b36cf8522",
    "files": [
        {
            "sha": "f390ec6001fb68fe8950e4a3e5257593453450dc",
            "filename": "third_party/xla/xla/service/gpu/autotuning/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458995b35d6bd20fd95120eabd16b47b36cf8522/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458995b35d6bd20fd95120eabd16b47b36cf8522/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD?ref=458995b35d6bd20fd95120eabd16b47b36cf8522",
            "patch": "@@ -725,6 +725,7 @@ cc_library(\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/pass:hlo_pass\",\n         \"//xla/service:compiler\",\n+        \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/tsl/platform:env\","
        },
        {
            "sha": "fea639e7996d7f74af4d173c5a50a7bc2d9d1085",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_pass.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 1,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/458995b35d6bd20fd95120eabd16b47b36cf8522/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/458995b35d6bd20fd95120eabd16b47b36cf8522/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc?ref=458995b35d6bd20fd95120eabd16b47b36cf8522",
            "patch": "@@ -35,6 +35,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/service/compiler.h\"\n+#include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -101,11 +102,17 @@ absl::StatusOr<std::unique_ptr<AutotunerPass>> AutotunerPass::Create(\n                                    GetProfileOptions(debug_options), allocator);\n   }\n \n+  se::DeviceDescription device_description = target_config->device_description;\n+  device_description.set_dnn_version(\n+      {static_cast<unsigned>(target_config->dnn_version_info.major_version()),\n+       static_cast<unsigned>(target_config->dnn_version_info.minor_version()),\n+       static_cast<unsigned>(target_config->dnn_version_info.patch())});\n+\n   std::unique_ptr<AutotunerCacheInterface> cache =\n       std::make_unique<LegacyCache>(\n           debug_options.xla_gpu_experimental_autotuner_cache_dir(),\n           debug_options.xla_gpu_experimental_autotune_cache_mode(),\n-          target_config->device_description);\n+          device_description);\n \n   TF_ASSIGN_OR_RETURN(\n       std::unique_ptr<Autotuner> autotuner,"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 9,
        "deletions": 1
    }
}