{
    "author": "beckerhe",
    "message": "Provide the module name via a dedicated getter in xla::Executable\n\nWe access `Executable::hlo_module` in many places to retrieve the `HloModule::name()`. But that's a problem because `Executable::hlo_module` is (theoretically) optional and might not be present in every `Executable`.\n\nIn addition `GpuExecutable` keeps a separate module name in a string which is identical to the HloModule's module name.\n\nSo this change introduces a virtual getter function `Executable::name()`. The default implementation queries the HloModule if it's available. `GpuExecutable` overwrites this getter and returns the string that it stores anyway.\n\nPiperOrigin-RevId: 802445832",
    "sha": "5184044000f13f370d95ab4d7ef6c7c15af3503f",
    "files": [
        {
            "sha": "5612b7b26e521fb2d3e0425676e1652827047e07",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=5184044000f13f370d95ab4d7ef6c7c15af3503f",
            "patch": "@@ -1847,9 +1847,8 @@ StreamExecutorGpuClient::RunAsync(\n                                  ? run_options->device_ordinal()\n                                  : executor->device_ordinal();\n \n-  XLA_SCOPED_LOGGING_TIMER(\n-      absl::StrCat(\"GpuExecutable::ExecuteAsyncOnStreamImpl(\",\n-                   gpu_exec->module_name(), \")\"));\n+  XLA_SCOPED_LOGGING_TIMER(absl::StrCat(\n+      \"GpuExecutable::ExecuteAsyncOnStreamImpl(\", gpu_exec->name(), \")\"));\n \n   // GpuExecutable always bound to a single GpuContext during its execution, so\n   // we activate it once to skip expensive context activations later."
        },
        {
            "sha": "0b86952bbfb7c416fea347547ca9c93a658207c9",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 10,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=5184044000f13f370d95ab4d7ef6c7c15af3503f",
            "patch": "@@ -2562,12 +2562,7 @@ absl::Status PjRtStreamExecutorLoadedExecutable::SetUpDonation(\n }\n \n absl::string_view PjRtStreamExecutorLoadedExecutable::name() const {\n-  Executable* executable = executables_[0]->executable();\n-  if (executable->has_module()) {\n-    return executable->module().name();\n-  } else {\n-    return \"<unknown executable>\";\n-  }\n+  return executables_[0]->executable()->name();\n }\n \n absl::Span<int const>\n@@ -3091,8 +3086,8 @@ PjRtStreamExecutorLoadedExecutable::EnqueueExecution(\n           << \", run_id=\" << run_options.run_id().ToInt();\n \n   if (VLOG_IS_ON(2)) {\n-    auto executable_name =\n-        executables_[executable_idx]->executable()->module().name();\n+    absl::string_view executable_name =\n+        executables_[executable_idx]->executable()->name();\n     absl::Status host_callback_status = run_options.stream()->DoHostCallback(\n         [executable_name, launch_id(run_options.run_id().ToInt()), device]() {\n           VLOG(2) << \"Start device execution for \" << executable_name\n@@ -3111,8 +3106,8 @@ PjRtStreamExecutorLoadedExecutable::EnqueueExecution(\n                         std::move(execution_inputs), run_options);\n \n   if (VLOG_IS_ON(2)) {\n-    auto executable_name =\n-        executables_[executable_idx]->executable()->module().name();\n+    absl::string_view executable_name =\n+        executables_[executable_idx]->executable()->name();\n     absl::Status host_callback_status = run_options.stream()->DoHostCallback(\n         [executable_name, launch_id(run_options.run_id().ToInt()), device]() {\n           VLOG(2) << \"Finish device execution for \" << executable_name"
        },
        {
            "sha": "b5ecc6bc89e0c683f15d7f0af79cae9e6454cba5",
            "filename": "third_party/xla/xla/service/executable.h",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h?ref=5184044000f13f370d95ab4d7ef6c7c15af3503f",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/log/check.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n@@ -378,6 +379,13 @@ class Executable {\n     return hlo_module_->compute_computation_layout();\n   }\n \n+  virtual absl::string_view name() const {\n+    if (has_module()) {\n+      return module().name();\n+    }\n+    return \"<unknown executable>\";\n+  }\n+\n   // Returns the size of the executable in bytes. Returns -1 if this query is\n   // not supported by the executable.\n   //"
        },
        {
            "sha": "0842e2fb678f66bebd6c8393260e9d79c30755a5",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h?ref=5184044000f13f370d95ab4d7ef6c7c15af3503f",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/annotation.h\"\n@@ -120,7 +121,7 @@ class GpuExecutable : public Executable {\n   // This should be called after set_ir_module_string.\n   const std::string& ir_module_string() const { return ir_module_string_; }\n \n-  const std::string& module_name() const { return module_name_; }\n+  absl::string_view name() const override { return module_name_; }\n \n   xla::Shape result_shape() const override { return program_shape_.result(); }\n "
        },
        {
            "sha": "983bda47d5a7af2866dec082bfaf7cac98e008f1",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc?ref=5184044000f13f370d95ab4d7ef6c7c15af3503f",
            "patch": "@@ -174,5 +174,16 @@ TEST(GpuExecutableTest, ComputeComputationLayout) {\n             ShapeLayout(ShapeUtil::MakeShape(F64, {2})));\n }\n \n+TEST(GpuExecutableTest, ExecutableName) {\n+  GpuExecutable::Params params;\n+  params.module_name = \"test_module\";\n+  params.executable =\n+      std::make_unique<SequentialThunk>(Thunk::ThunkInfo{}, ThunkSequence{});\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<GpuExecutable> executable,\n+                          GpuExecutable::Create(std::move(params)));\n+  EXPECT_THAT(executable->name(), \"test_module\");\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "1b8157ba6ce700409f811fb07dd7c418990cb661",
            "filename": "third_party/xla/xla/service/service.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 6,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fservice%2Fservice.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5184044000f13f370d95ab4d7ef6c7c15af3503f/third_party%2Fxla%2Fxla%2Fservice%2Fservice.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fservice.cc?ref=5184044000f13f370d95ab4d7ef6c7c15af3503f",
            "patch": "@@ -15,7 +15,6 @@ limitations under the License.\n \n #include \"xla/service/service.h\"\n \n-#include <algorithm>\n #include <cstddef>\n #include <cstdint>\n #include <functional>\n@@ -74,11 +73,7 @@ limitations under the License.\n #include \"xla/util.h\"\n #include \"xla/xla.pb.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/errors.h\"\n-#include \"tsl/platform/logging.h\"\n #include \"tsl/platform/protobuf.h\"\n-#include \"tsl/platform/status.h\"\n-#include \"tsl/platform/statusor.h\"\n #include \"tsl/profiler/lib/scoped_annotation.h\"\n \n namespace xla {\n@@ -910,7 +905,7 @@ absl::StatusOr<std::unique_ptr<GlobalData>> Service::Execute(\n       ExecuteAndRegisterResult(\n           executable.get(), replicated_arguments, execute_backend_.get(),\n           SingleComputationDeviceHandle(),\n-          \"result of \" + executable->module().name(), execution_profile));\n+          absl::StrCat(\"result of \", executable->name()), execution_profile));\n \n   if (executable->dumping_snapshot()) {\n     TF_ASSIGN_OR_RETURN(const ShapedBuffer* result_buffer,"
        }
    ],
    "stats": {
        "total": 49,
        "additions": 29,
        "deletions": 20
    }
}