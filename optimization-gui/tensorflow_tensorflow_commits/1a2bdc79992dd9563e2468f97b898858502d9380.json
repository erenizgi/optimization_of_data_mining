{
    "author": "tensorflower-gardener",
    "message": "Integrate LLVM at llvm/llvm-project@0812f41cd68d\n\nUpdates LLVM usage to match\n[0812f41cd68d](https://github.com/llvm/llvm-project/commit/0812f41cd68d)\n\nPiperOrigin-RevId: 850116111",
    "sha": "1a2bdc79992dd9563e2468f97b898858502d9380",
    "files": [
        {
            "sha": "7972fe35b8fccf6baa5a367ae13d4e9344126c17",
            "filename": "third_party/xla/third_party/llvm/generated.patch",
            "status": "modified",
            "additions": 1782,
            "deletions": 140,
            "changes": 1922,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch?ref=1a2bdc79992dd9563e2468f97b898858502d9380",
            "patch": "@@ -1,152 +1,1794 @@\n Auto generated patch. Do not edit or delete it, even if empty.\n-diff -ruN --strip-trailing-cr a/clang/lib/Serialization/ASTReaderDecl.cpp b/clang/lib/Serialization/ASTReaderDecl.cpp\n---- a/clang/lib/Serialization/ASTReaderDecl.cpp\n-+++ b/clang/lib/Serialization/ASTReaderDecl.cpp\n-@@ -2107,8 +2107,9 @@\n-     auto *Def = DD.Definition;\n-     DD = std::move(MergeDD);\n-     DD.Definition = Def;\n--    for (auto *D : Def->redecls())\n--      cast<CXXRecordDecl>(D)->DefinitionData = &DD;\n-+    for (auto *R = Reader.getMostRecentExistingDecl(Def); R;\n-+         R = R->getPreviousDecl())\n-+      cast<CXXRecordDecl>(R)->DefinitionData = &DD;\n-     return;\n-   }\n+diff -ruN --strip-trailing-cr a/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h b/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\n+--- a/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\n++++ b/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\n+@@ -1,122 +0,0 @@\n+-//===- ACCSpecializePatterns.h - Common ACC Specialization Patterns ------===//\n+-//\n+-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+-// See https://llvm.org/LICENSE.txt for license information.\n+-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+-//\n+-//===----------------------------------------------------------------------===//\n+-//\n+-// This file contains common rewrite pattern templates used by both\n+-// ACCSpecializeForHost and ACCSpecializeForDevice passes.\n+-//\n+-// The patterns provide the following transformations:\n+-//\n+-// - ACCOpReplaceWithVarConversion<OpTy>: Replaces a data entry operation\n+-//   with its var operand. Used for ops like acc.copyin, acc.create, etc.\n+-//\n+-// - ACCOpEraseConversion<OpTy>: Simply erases an operation. Used for\n+-//   data exit ops like acc.copyout, acc.delete, and runtime ops.\n+-//\n+-// - ACCRegionUnwrapConversion<OpTy>: Inlines the region of an operation\n+-//   and erases the wrapper. Used for structured data constructs\n+-//   (acc.data, acc.host_data) and compute constructs (acc.parallel, etc.)\n+-//\n+-// - ACCDeclareEnterOpConversion: Erases acc.declare_enter and its\n+-//   associated acc.declare_exit operation.\n+-//\n+-//===----------------------------------------------------------------------===//\n+-\n+-#ifndef MLIR_DIALECT_OPENACC_TRANSFORMS_ACCSPECIALIZEPATTERNS_H\n+-#define MLIR_DIALECT_OPENACC_TRANSFORMS_ACCSPECIALIZEPATTERNS_H\n+-\n+-#include \"mlir/Dialect/OpenACC/OpenACC.h\"\n+-#include \"mlir/IR/PatternMatch.h\"\n+-\n+-namespace mlir {\n+-namespace acc {\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Generic pattern templates for ACC specialization\n+-//===----------------------------------------------------------------------===//\n+-\n+-/// Pattern to replace an ACC op with its var operand.\n+-/// Used for data entry ops like acc.copyin, acc.create, acc.attach, etc.\n+-template <typename OpTy>\n+-class ACCOpReplaceWithVarConversion : public OpRewritePattern<OpTy> {\n+-  using OpRewritePattern<OpTy>::OpRewritePattern;\n+-\n+-public:\n+-  LogicalResult matchAndRewrite(OpTy op,\n+-                                PatternRewriter &rewriter) const override {\n+-    // Replace this op with its var operand; it's possible the op has no uses\n+-    // if the op that had previously used it was already converted.\n+-    if (op->use_empty())\n+-      rewriter.eraseOp(op);\n+-    else\n+-      rewriter.replaceOp(op, op.getVar());\n+-    return success();\n+-  }\n+-};\n+-\n+-/// Pattern to simply erase an ACC op (for ops with no results).\n+-/// Used for data exit ops like acc.copyout, acc.delete, acc.detach, etc.\n+-template <typename OpTy>\n+-class ACCOpEraseConversion : public OpRewritePattern<OpTy> {\n+-  using OpRewritePattern<OpTy>::OpRewritePattern;\n+-\n+-public:\n+-  LogicalResult matchAndRewrite(OpTy op,\n+-                                PatternRewriter &rewriter) const override {\n+-    assert(op->getNumResults() == 0 && \"expected op with no results\");\n+-    rewriter.eraseOp(op);\n+-    return success();\n+-  }\n+-};\n+-\n+-/// Pattern to unwrap a region from an ACC op and erase the wrapper.\n+-/// Moves the region's contents to the parent block and removes the wrapper op.\n+-/// Used for structured data constructs (acc.data, acc.host_data,\n+-/// acc.kernel_environment, acc.declare) and compute constructs (acc.parallel,\n+-/// acc.serial, acc.kernels).\n+-template <typename OpTy>\n+-class ACCRegionUnwrapConversion : public OpRewritePattern<OpTy> {\n+-  using OpRewritePattern<OpTy>::OpRewritePattern;\n+-\n+-public:\n+-  LogicalResult matchAndRewrite(OpTy op,\n+-                                PatternRewriter &rewriter) const override {\n+-    assert(op.getRegion().hasOneBlock() && \"expected one block\");\n+-    Block *block = &op.getRegion().front();\n+-    // Erase the terminator (acc.yield or acc.terminator) before unwrapping\n+-    rewriter.eraseOp(block->getTerminator());\n+-    rewriter.inlineBlockBefore(block, op);\n+-    rewriter.eraseOp(op);\n+-    return success();\n+-  }\n+-};\n+-\n+-/// Pattern to erase acc.declare_enter and its associated acc.declare_exit.\n+-/// The declare_enter produces a token that is consumed by declare_exit.\n+-class ACCDeclareEnterOpConversion\n+-    : public OpRewritePattern<acc::DeclareEnterOp> {\n+-  using OpRewritePattern<acc::DeclareEnterOp>::OpRewritePattern;\n+-\n+-public:\n+-  LogicalResult matchAndRewrite(acc::DeclareEnterOp op,\n+-                                PatternRewriter &rewriter) const override {\n+-    // If the enter token is used by an exit, erase exit first.\n+-    if (!op->use_empty()) {\n+-      assert(op->hasOneUse() && \"expected one use\");\n+-      auto exitOp = dyn_cast<acc::DeclareExitOp>(*op->getUsers().begin());\n+-      assert(exitOp && \"expected declare exit op\");\n+-      rewriter.eraseOp(exitOp);\n+-    }\n+-    rewriter.eraseOp(op);\n+-    return success();\n+-  }\n+-};\n+-\n+-} // namespace acc\n+-} // namespace mlir\n+-\n+-#endif // MLIR_DIALECT_OPENACC_TRANSFORMS_ACCSPECIALIZEPATTERNS_H\n+diff -ruN --strip-trailing-cr a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h\n+--- a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h\n++++ b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h\n+@@ -12,7 +12,6 @@\n+ #include \"mlir/Dialect/Arith/IR/Arith.h\"\n+ #include \"mlir/Dialect/MemRef/IR/MemRef.h\"\n+ #include \"mlir/Dialect/OpenACC/OpenACC.h\"\n+-#include \"mlir/Dialect/SCF/IR/SCF.h\"\n+ #include \"mlir/Pass/Pass.h\"\n  \n-diff -ruN --strip-trailing-cr a/libc/src/__support/FPUtil/x86_64/fenv_mxcsr_utils.h b/libc/src/__support/FPUtil/x86_64/fenv_mxcsr_utils.h\n---- a/libc/src/__support/FPUtil/x86_64/fenv_mxcsr_utils.h\n-+++ b/libc/src/__support/FPUtil/x86_64/fenv_mxcsr_utils.h\n-@@ -61,14 +61,14 @@\n- LIBC_INLINE static void write_mxcsr(uint32_t w) { _mm_setcsr(w); }\n+ namespace mlir {\n+@@ -23,40 +22,9 @@\n  \n- LIBC_INLINE static void clear_except(uint16_t excepts) {\n--  uint32_t mxcsr = _MM_GET_EXCEPTION_STATE();\n-+  uint32_t mxcsr = get_mxcsr();\n-   mxcsr &= ~static_cast<uint32_t>(excepts);\n--  _MM_SET_EXCEPTION_STATE(mxcsr);\n-+  write_mxcsr(mxcsr);\n- }\n+ namespace acc {\n  \n- LIBC_INLINE static uint16_t test_except(uint16_t excepts) {\n-   uint32_t mxcsr = get_mxcsr();\n--  return static_cast<uint16_t>(excepts & mxcsr);\n-+  return static_cast<uint16_t>(excepts & ExceptionFlags::ALL_F & mxcsr);\n- }\n+-class OpenACCSupport;\n+-\n+ #define GEN_PASS_DECL\n+ #include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n  \n- LIBC_INLINE static uint16_t get_except() {\n-@@ -83,9 +83,9 @@\n+-//===----------------------------------------------------------------------===//\n+-// ACCSpecializeForDevice patterns\n+-//===----------------------------------------------------------------------===//\n+-\n+-/// Populates all patterns for device specialization.\n+-/// In specialized device code (such as specialized acc routine), many ACC\n+-/// operations do not make sense because they are host-side constructs. This\n+-/// function adds patterns to remove or transform them.\n+-void populateACCSpecializeForDevicePatterns(RewritePatternSet &patterns);\n+-\n+-//===----------------------------------------------------------------------===//\n+-// ACCSpecializeForHost patterns\n+-//===----------------------------------------------------------------------===//\n+-\n+-/// Populates patterns for converting orphan ACC operations to host.\n+-/// All patterns check that the operation is NOT inside or associated with a\n+-/// compute region before converting.\n+-/// @param enableLoopConversion Whether to convert orphan acc.loop operations.\n+-void populateACCOrphanToHostPatterns(RewritePatternSet &patterns,\n+-                                     OpenACCSupport &accSupport,\n+-                                     bool enableLoopConversion = true);\n+-\n+-/// Populates all patterns for host fallback path (when `if` clause evaluates\n+-/// to false). In this mode, ALL ACC operations should be converted or removed.\n+-/// @param enableLoopConversion Whether to convert orphan acc.loop operations.\n+-void populateACCHostFallbackPatterns(RewritePatternSet &patterns,\n+-                                     OpenACCSupport &accSupport,\n+-                                     bool enableLoopConversion = true);\n+-\n+ /// Generate the code for registering conversion passes.\n+ #define GEN_PASS_REGISTRATION\n+ #include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n+diff -ruN --strip-trailing-cr a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td\n+--- a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td\n++++ b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td\n+@@ -194,62 +194,4 @@\n+   ];\n  }\n  \n- LIBC_INLINE static void raise_except(uint16_t excepts) {\n--  uint32_t mxcsr = _MM_GET_EXCEPTION_STATE();\n--  mxcsr |= excepts;\n--  _MM_SET_EXCEPTION_STATE(mxcsr);\n-+  uint32_t mxcsr = get_mxcsr();\n-+  mxcsr |= excepts & ExceptionFlags::ALL_F;\n-+  write_mxcsr(mxcsr);\n- #ifdef LIBC_TRAP_ON_RAISE_FP_EXCEPT\n-   // We will try to trigger the SIGFPE if floating point exceptions are not\n-   // masked.  Since we already set all the floating point exception flags, we\n-diff -ruN --strip-trailing-cr a/libcxx/include/__flat_map/flat_map.h b/libcxx/include/__flat_map/flat_map.h\n---- a/libcxx/include/__flat_map/flat_map.h\n-+++ b/libcxx/include/__flat_map/flat_map.h\n-@@ -465,13 +465,13 @@\n-   }\n+-def ACCSpecializeForDevice : Pass<\"acc-specialize-for-device\", \"mlir::func::FuncOp\"> {\n+-  let summary = \"Strip OpenACC constructs inside device code\";\n+-  let description = [{\n+-    In a specialized acc routine or compute construct, many OpenACC operations\n+-    do not make sense because they are host-side constructs. This pass removes\n+-    or transforms these operations appropriately.\n+-\n+-    The following operations are handled:\n+-    - Data entry ops (replaced with var): acc.attach, acc.copyin, acc.create,\n+-      acc.declare_device_resident, acc.declare_link, acc.deviceptr,\n+-      acc.get_deviceptr, acc.nocreate, acc.present, acc.update_device,\n+-      acc.use_device\n+-    - Data exit ops (erased): acc.copyout, acc.delete, acc.detach,\n+-      acc.update_host\n+-    - Structured data (inline region): acc.data, acc.host_data,\n+-      acc.kernel_environment\n+-    - Unstructured data (erased): acc.enter_data, acc.exit_data, acc.update,\n+-      acc.declare_enter, acc.declare_exit\n+-    - Compute constructs (inline region): acc.parallel, acc.serial, acc.kernels\n+-    - Runtime ops (erased): acc.init, acc.shutdown, acc.set, acc.wait\n+-  }];\n+-  let dependentDialects = [\"mlir::acc::OpenACCDialect\"];\n+-}\n+-\n+-def ACCSpecializeForHost : Pass<\"acc-specialize-for-host\", \"mlir::func::FuncOp\"> {\n+-  let summary = \"Convert OpenACC operations for host execution\";\n+-  let description = [{\n+-    This pass converts OpenACC operations to host-compatible representations.\n+-    It serves as a conversion pass that transforms ACC constructs to enable\n+-    execution on the host rather than on accelerator devices.\n+-\n+-    There are two modes of operation:\n+-\n+-    1. Default mode (orphan operations only): Only orphan operations that are\n+-       not allowed outside compute regions are converted. Structured/unstructured\n+-       data constructs, compute constructs, and their associated data operations\n+-       are NOT removed.\n+-\n+-    2. Host fallback mode (enableHostFallback=true): ALL ACC operations within\n+-       the region are converted to host equivalents. This is used when the `if`\n+-       clause evaluates to false at runtime.\n+-\n+-    The following operations are handled:\n+-    - Atomic ops: converted to load/store operations\n+-    - Loop ops: converted to scf.for or scf.execute_region\n+-    - Data entry ops (orphan): replaced with var operand\n+-    - In host fallback mode: all data, compute, and runtime ops are removed\n+-  }];\n+-  let dependentDialects = [\"mlir::acc::OpenACCDialect\",\n+-      \"mlir::scf::SCFDialect\"];\n+-  let options = [\n+-    Option<\"enableHostFallback\", \"enable-host-fallback\", \"bool\", \"false\",\n+-           \"Enable host fallback mode which converts ALL ACC operations, \"\n+-           \"not just orphan operations. Use this when the `if` clause \"\n+-           \"evaluates to false.\">\n+-  ];\n+-}\n+-\n+ #endif // MLIR_DIALECT_OPENACC_TRANSFORMS_PASSES\n+diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp\n+--- a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp\n++++ b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp\n+@@ -1,172 +0,0 @@\n+-//===- ACCSpecializeForDevice.cpp -----------------------------------------===//\n+-//\n+-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+-// See https://llvm.org/LICENSE.txt for license information.\n+-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+-//\n+-//===----------------------------------------------------------------------===//\n+-//\n+-// This pass strips OpenACC constructs that are invalid or unnecessary inside\n+-// device code (specialized acc routines or compute construct regions).\n+-//\n+-// Overview:\n+-// ---------\n+-// In a specialized acc routine or compute construct, many OpenACC operations\n+-// do not make sense because they are host-side constructs. This pass removes\n+-// or transforms these operations appropriately:\n+-//\n+-// - Data operations that manage device memory from host perspective\n+-// - Compute constructs that launch kernels (we're already on device)\n+-// - Runtime operations like init/shutdown/set/wait\n+-//\n+-// Transformations:\n+-// ----------------\n+-// The pass applies the following transformations:\n+-//\n+-// 1. Data Entry Ops (replaced with var operand):\n+-//    acc.attach, acc.copyin, acc.create, acc.declare_device_resident,\n+-//    acc.declare_link, acc.deviceptr, acc.get_deviceptr, acc.nocreate,\n+-//    acc.present, acc.update_device, acc.use_device\n+-//\n+-// 2. Data Exit Ops (erased):\n+-//    acc.copyout, acc.delete, acc.detach, acc.update_host\n+-//\n+-// 3. Structured Data/Compute Constructs (region inlined):\n+-//    acc.data, acc.host_data, acc.kernel_environment, acc.parallel,\n+-//    acc.serial, acc.kernels\n+-//\n+-// 4. Unstructured Data Ops (erased):\n+-//    acc.enter_data, acc.exit_data, acc.update, acc.declare_enter,\n+-//    acc.declare_exit\n+-//\n+-// 5. Runtime Ops (erased):\n+-//    acc.init, acc.shutdown, acc.set, acc.wait\n+-//\n+-// Scope of Application:\n+-// ---------------------\n+-// - For functions with `acc.specialized_routine` attribute: patterns are\n+-//   applied to the entire function body.\n+-// - For non-specialized functions: patterns are applied only to ACC\n+-//   operations INSIDE compute constructs (parallel, serial, kernels),\n+-//   not to the compute constructs themselves or their data operands.\n+-//\n+-// Note: acc.cache, acc.private, acc.reduction, acc.firstprivate are NOT\n+-// transformed by this pass as they are valid in device code.\n+-//\n+-//===----------------------------------------------------------------------===//\n+-\n+-#include \"mlir/Dialect/OpenACC/Transforms/Passes.h\"\n+-\n+-#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+-#include \"mlir/Dialect/OpenACC/OpenACC.h\"\n+-#include \"mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\"\n+-#include \"mlir/IR/PatternMatch.h\"\n+-#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+-\n+-namespace mlir {\n+-namespace acc {\n+-#define GEN_PASS_DEF_ACCSPECIALIZEFORDEVICE\n+-#include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n+-} // namespace acc\n+-} // namespace mlir\n+-\n+-using namespace mlir;\n+-using namespace mlir::acc;\n+-\n+-namespace {\n+-\n+-class ACCSpecializeForDevice\n+-    : public acc::impl::ACCSpecializeForDeviceBase<ACCSpecializeForDevice> {\n+-public:\n+-  using ACCSpecializeForDeviceBase<\n+-      ACCSpecializeForDevice>::ACCSpecializeForDeviceBase;\n+-\n+-  void runOnOperation() override {\n+-    func::FuncOp func = getOperation();\n+-\n+-    RewritePatternSet patterns(&getContext());\n+-    acc::populateACCSpecializeForDevicePatterns(patterns);\n+-    GreedyRewriteConfig config;\n+-    config.setUseTopDownTraversal(true);\n+-\n+-    if (acc::isSpecializedAccRoutine(func)) {\n+-      // For specialized acc routines, apply patterns to the entire function\n+-      (void)applyPatternsGreedily(func, std::move(patterns), config);\n+-    } else {\n+-      // For non-specialized functions, apply patterns only to ACC operations\n+-      // inside compute constructs (not to the compute constructs themselves).\n+-      SmallVector<Operation *> opsToTransform;\n+-      func.walk([&](Operation *op) {\n+-        if (isa<ACC_COMPUTE_CONSTRUCT_OPS>(op)) {\n+-          // Walk inside the compute construct and collect ACC ops\n+-          op->walk([&](Operation *innerOp) {\n+-            // Skip the compute construct itself\n+-            if (innerOp == op)\n+-              return;\n+-            if (isa<acc::OpenACCDialect>(innerOp->getDialect()))\n+-              opsToTransform.push_back(innerOp);\n+-          });\n+-        }\n+-      });\n+-      if (!opsToTransform.empty())\n+-        (void)applyOpPatternsGreedily(opsToTransform, std::move(patterns),\n+-                                      config);\n+-    }\n+-  }\n+-};\n+-\n+-} // namespace\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Pattern population functions\n+-//===----------------------------------------------------------------------===//\n+-\n+-void mlir::acc::populateACCSpecializeForDevicePatterns(\n+-    RewritePatternSet &patterns) {\n+-  MLIRContext *context = patterns.getContext();\n+-\n+-  // Declare patterns - erase declare_enter and its associated declare_exit\n+-  patterns.insert<ACCDeclareEnterOpConversion>(context);\n+-\n+-  // Data entry ops - replaced with their var operand\n+-  // Note: acc.cache, acc.private, acc.reduction, acc.firstprivate are NOT\n+-  // included here - they are valid in device code\n+-  patterns.insert<ACCOpReplaceWithVarConversion<acc::AttachOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::CopyinOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::CreateOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::DeclareDeviceResidentOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::DeclareLinkOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::DevicePtrOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::GetDevicePtrOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::NoCreateOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::PresentOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::UpdateDeviceOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::UseDeviceOp>>(context);\n+-\n+-  // Data exit ops - simply erased (no results)\n+-  patterns.insert<ACCOpEraseConversion<acc::CopyoutOp>,\n+-                  ACCOpEraseConversion<acc::DeleteOp>,\n+-                  ACCOpEraseConversion<acc::DetachOp>,\n+-                  ACCOpEraseConversion<acc::UpdateHostOp>>(context);\n+-\n+-  // Structured data constructs - unwrap their regions\n+-  patterns.insert<ACCRegionUnwrapConversion<acc::DataOp>,\n+-                  ACCRegionUnwrapConversion<acc::HostDataOp>,\n+-                  ACCRegionUnwrapConversion<acc::KernelEnvironmentOp>>(context);\n+-\n+-  // Compute constructs - unwrap their regions\n+-  patterns.insert<ACCRegionUnwrapConversion<acc::ParallelOp>,\n+-                  ACCRegionUnwrapConversion<acc::SerialOp>,\n+-                  ACCRegionUnwrapConversion<acc::KernelsOp>>(context);\n+-\n+-  // Unstructured data operations - erase them\n+-  patterns.insert<ACCOpEraseConversion<acc::EnterDataOp>,\n+-                  ACCOpEraseConversion<acc::ExitDataOp>,\n+-                  ACCOpEraseConversion<acc::UpdateOp>>(context);\n+-\n+-  // Runtime operations - erase them\n+-  patterns.insert<\n+-      ACCOpEraseConversion<acc::InitOp>, ACCOpEraseConversion<acc::ShutdownOp>,\n+-      ACCOpEraseConversion<acc::SetOp>, ACCOpEraseConversion<acc::WaitOp>>(\n+-      context);\n+-}\n+diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp\n+--- a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp\n++++ b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp\n+@@ -1,471 +0,0 @@\n+-//===- ACCSpecializeForHost.cpp -------------------------------------------===//\n+-//\n+-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+-// See https://llvm.org/LICENSE.txt for license information.\n+-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+-//\n+-//===----------------------------------------------------------------------===//\n+-//\n+-// This pass converts OpenACC operations to host-compatible representations,\n+-// enabling execution on the host rather than on accelerator devices.\n+-//\n+-// Overview:\n+-// ---------\n+-// The pass operates in two modes depending on the `enableHostFallback` option:\n+-//\n+-// 1. Default Mode (Orphan Operations Only):\n+-//    Only converts \"orphan\" ACC operations that are not inside or attached to\n+-//    compute regions. This is used for host routines (acc routine marked for\n+-//    host) where structured/unstructured data constructs, compute constructs,\n+-//    and their associated data operations should be preserved.\n+-//\n+-// 2. Host Fallback Mode (enableHostFallback=true):\n+-//    Converts ALL ACC operations within the region to host equivalents. This\n+-//    is used when the `if` clause evaluates to false at runtime and the\n+-//    entire ACC region needs to fall back to host execution.\n+-//\n+-// Transformations (Orphan Mode):\n+-// ------------------------------\n+-// The following orphan operations are converted:\n+-//\n+-// 1. Atomic Ops (converted to load/store):\n+-//    acc.atomic.update -> load + compute + store\n+-//    acc.atomic.read -> load + store (copy)\n+-//    acc.atomic.write -> store\n+-//    acc.atomic.capture -> inline region contents\n+-//\n+-// 2. Loop Ops (converted to SCF):\n+-//    acc.loop (structured) -> scf.for\n+-//    acc.loop (unstructured) -> scf.execute_region\n+-//\n+-// 3. Orphan Data Entry Ops (replaced with var operand):\n+-//    acc.cache, acc.private, acc.firstprivate, acc.reduction\n+-//    (only if NOT connected to compute constructs or loop)\n+-//\n+-// Transformations (Host Fallback Mode):\n+-// -------------------------------------\n+-// In addition to orphan transformations, ALL of the following are converted:\n+-//\n+-// 1. Data Entry Ops (replaced with var operand):\n+-//    acc.copyin, acc.create, acc.attach, acc.present, acc.deviceptr,\n+-//    acc.get_deviceptr, acc.nocreate, acc.declare_device_resident,\n+-//    acc.declare_link, acc.use_device, acc.update_device\n+-//\n+-// 2. Data Exit Ops (erased):\n+-//    acc.copyout, acc.delete, acc.detach, acc.update_host\n+-//\n+-// 3. Structured Data/Compute Constructs (region inlined):\n+-//    acc.data, acc.host_data, acc.kernel_environment, acc.declare,\n+-//    acc.parallel, acc.serial, acc.kernels\n+-//\n+-// 4. Unstructured Data Ops (erased):\n+-//    acc.enter_data, acc.exit_data, acc.update\n+-//\n+-// 5. Declare Ops (erased):\n+-//    acc.declare_enter, acc.declare_exit\n+-//\n+-// 6. Runtime Ops (erased):\n+-//    acc.init, acc.shutdown, acc.set, acc.wait, acc.terminator\n+-//\n+-// Requirements:\n+-// -------------\n+-// For atomic operation conversion, variables must implement the\n+-// `acc::PointerLikeType` interface to enable generating load/store operations.\n+-//\n+-// The pass uses `OpenACCSupport::emitNYI()` to report unsupported cases.\n+-//\n+-//===----------------------------------------------------------------------===//\n+-\n+-#include \"mlir/Dialect/OpenACC/Transforms/Passes.h\"\n+-\n+-#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+-#include \"mlir/Dialect/OpenACC/Analysis/OpenACCSupport.h\"\n+-#include \"mlir/Dialect/OpenACC/OpenACC.h\"\n+-#include \"mlir/Dialect/OpenACC/OpenACCUtilsLoop.h\"\n+-#include \"mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\"\n+-#include \"mlir/IR/BuiltinAttributes.h\"\n+-#include \"mlir/IR/BuiltinOps.h\"\n+-#include \"mlir/IR/BuiltinTypes.h\"\n+-#include \"mlir/IR/Operation.h\"\n+-#include \"mlir/IR/PatternMatch.h\"\n+-#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+-\n+-namespace mlir {\n+-namespace acc {\n+-#define GEN_PASS_DEF_ACCSPECIALIZEFORHOST\n+-#include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n+-} // namespace acc\n+-} // namespace mlir\n+-\n+-#define DEBUG_TYPE \"acc-specialize-for-host\"\n+-\n+-using namespace mlir;\n+-using namespace mlir::acc;\n+-\n+-/// Check if an operation is inside an ACC compute construct.\n+-static bool isInsideACCComputeConstruct(Operation *op) {\n+-  while ((op = op->getParentOp()))\n+-    if (isa<ACC_COMPUTE_CONSTRUCT_OPS>(op))\n+-      return true;\n+-  return false;\n+-}\n+-\n+-namespace {\n+-\n+-// Lower orphan acc.atomic.update by: load from addr, clone region expr with\n+-// the loaded value, then store the computed result back to addr.\n+-// Only matches if NOT inside a compute region.\n+-class ACCOrphanAtomicUpdateOpConversion\n+-    : public OpRewritePattern<acc::AtomicUpdateOp> {\n+-public:\n+-  ACCOrphanAtomicUpdateOpConversion(MLIRContext *ctx, OpenACCSupport &support)\n+-      : OpRewritePattern<acc::AtomicUpdateOp>(ctx), accSupport(support) {}\n+-\n+-  LogicalResult matchAndRewrite(acc::AtomicUpdateOp atomicUpdateOp,\n+-                                PatternRewriter &rewriter) const override {\n+-    // Only convert if this op is not inside an ACC compute construct\n+-    if (isInsideACCComputeConstruct(atomicUpdateOp))\n+-      return failure();\n+-\n+-    Value x = atomicUpdateOp.getX();\n+-    Type type = x.getType();\n+-    auto ptrLikeType = dyn_cast<acc::PointerLikeType>(type);\n+-    if (ptrLikeType) {\n+-      auto xTyped = cast<TypedValue<acc::PointerLikeType>>(x);\n+-      rewriter.setInsertionPointAfter(atomicUpdateOp);\n+-      Value loadOp =\n+-          ptrLikeType.genLoad(rewriter, atomicUpdateOp.getLoc(), xTyped, {});\n+-      if (!loadOp) {\n+-        accSupport.emitNYI(atomicUpdateOp.getLoc(),\n+-                           \"failed to generate load for atomic update\");\n+-        return failure();\n+-      }\n+-      IRMapping mapping;\n+-      mapping.map(atomicUpdateOp.getRegion().front().getArgument(0), loadOp);\n+-      Operation *expr = rewriter.clone(*atomicUpdateOp.getFirstOp(), mapping);\n+-      if (!ptrLikeType.genStore(rewriter, atomicUpdateOp.getLoc(),\n+-                                expr->getResult(0), xTyped)) {\n+-        accSupport.emitNYI(atomicUpdateOp.getLoc(),\n+-                           \"failed to generate store for atomic update\");\n+-        return failure();\n+-      }\n+-      rewriter.eraseOp(atomicUpdateOp);\n+-    } else {\n+-      accSupport.emitNYI(atomicUpdateOp.getLoc(),\n+-                         \"unsupported type for atomic update\");\n+-      return failure();\n+-    }\n+-    return success();\n+-  }\n+-\n+-private:\n+-  OpenACCSupport &accSupport;\n+-};\n+-\n+-// Lower orphan acc.atomic.read by: load from src, then store into dst.\n+-// Only matches if NOT inside an ACC compute construct.\n+-class ACCOrphanAtomicReadOpConversion\n+-    : public OpRewritePattern<acc::AtomicReadOp> {\n+-public:\n+-  ACCOrphanAtomicReadOpConversion(MLIRContext *ctx, OpenACCSupport &support)\n+-      : OpRewritePattern<acc::AtomicReadOp>(ctx), accSupport(support) {}\n+-\n+-  LogicalResult matchAndRewrite(acc::AtomicReadOp readOp,\n+-                                PatternRewriter &rewriter) const override {\n+-    // Only convert if this op is not inside an ACC compute construct\n+-    if (isInsideACCComputeConstruct(readOp))\n+-      return failure();\n+-\n+-    Value x = readOp.getX();\n+-    Value v = readOp.getV();\n+-    auto xPtrType = dyn_cast<acc::PointerLikeType>(x.getType());\n+-    auto vPtrType = dyn_cast<acc::PointerLikeType>(v.getType());\n+-    if (xPtrType && vPtrType) {\n+-      auto xTyped = cast<TypedValue<acc::PointerLikeType>>(x);\n+-      auto vTyped = cast<TypedValue<acc::PointerLikeType>>(v);\n+-      rewriter.setInsertionPointAfter(readOp);\n+-\n+-      // Use genCopy which does load + store\n+-      if (!xPtrType.genCopy(rewriter, readOp.getLoc(), vTyped, xTyped, {})) {\n+-        accSupport.emitNYI(readOp.getLoc(),\n+-                           \"failed to generate copy for atomic read\");\n+-        return failure();\n+-      }\n+-      rewriter.eraseOp(readOp);\n+-    } else {\n+-      accSupport.emitNYI(readOp.getLoc(), \"unsupported type for atomic read\");\n+-      return failure();\n+-    }\n+-    return success();\n+-  }\n+-\n+-private:\n+-  OpenACCSupport &accSupport;\n+-};\n+-\n+-// Lower orphan acc.atomic.write by: store value into addr.\n+-// Only matches if NOT inside an ACC compute construct.\n+-class ACCOrphanAtomicWriteOpConversion\n+-    : public OpRewritePattern<acc::AtomicWriteOp> {\n+-public:\n+-  ACCOrphanAtomicWriteOpConversion(MLIRContext *ctx, OpenACCSupport &support)\n+-      : OpRewritePattern<acc::AtomicWriteOp>(ctx), accSupport(support) {}\n+-\n+-  LogicalResult matchAndRewrite(acc::AtomicWriteOp writeOp,\n+-                                PatternRewriter &rewriter) const override {\n+-    // Only convert if this op is not inside an ACC compute construct\n+-    if (isInsideACCComputeConstruct(writeOp))\n+-      return failure();\n+-\n+-    Value x = writeOp.getX();\n+-    Value expr = writeOp.getExpr();\n+-    auto ptrLikeType = dyn_cast<acc::PointerLikeType>(x.getType());\n+-    if (ptrLikeType) {\n+-      auto xTyped = cast<TypedValue<acc::PointerLikeType>>(x);\n+-      rewriter.setInsertionPointAfter(writeOp);\n+-      if (!ptrLikeType.genStore(rewriter, writeOp.getLoc(), expr, xTyped)) {\n+-        accSupport.emitNYI(writeOp.getLoc(),\n+-                           \"failed to generate store for atomic write\");\n+-        return failure();\n+-      }\n+-      rewriter.eraseOp(writeOp);\n+-    } else {\n+-      accSupport.emitNYI(writeOp.getLoc(), \"unsupported type for atomic write\");\n+-      return failure();\n+-    }\n+-    return success();\n+-  }\n+-\n+-private:\n+-  OpenACCSupport &accSupport;\n+-};\n+-\n+-// Lower orphan acc.atomic.capture by: unwrap the capture region and erase the\n+-// wrapper; inner ops are lowered in-order (e.g., read+update becomes load/store\n+-// to dst then load/compute/store to addr).\n+-// Only matches if NOT inside an ACC compute construct.\n+-class ACCOrphanAtomicCaptureOpConversion\n+-    : public OpRewritePattern<acc::AtomicCaptureOp> {\n+-  using OpRewritePattern<acc::AtomicCaptureOp>::OpRewritePattern;\n+-\n+-  LogicalResult matchAndRewrite(acc::AtomicCaptureOp captureOp,\n+-                                PatternRewriter &rewriter) const override {\n+-    // Only convert if this op is not inside an ACC compute construct\n+-    if (isInsideACCComputeConstruct(captureOp))\n+-      return failure();\n+-\n+-    assert(captureOp.getRegion().hasOneBlock() && \"expected one block\");\n+-    Block *block = &captureOp.getRegion().front();\n+-    // Remove the terminator before inlining\n+-    rewriter.eraseOp(block->getTerminator());\n+-    rewriter.inlineBlockBefore(block, captureOp);\n+-    rewriter.eraseOp(captureOp);\n+-    return success();\n+-  }\n+-};\n+-\n+-// Convert orphan acc.loop to scf.for or scf.execute_region.\n+-// Only matches if NOT inside an ACC compute construct.\n+-class ACCOrphanLoopOpConversion : public OpRewritePattern<acc::LoopOp> {\n+-  using OpRewritePattern<acc::LoopOp>::OpRewritePattern;\n+-\n+-  LogicalResult matchAndRewrite(acc::LoopOp loopOp,\n+-                                PatternRewriter &rewriter) const override {\n+-    // Only convert if this op is not inside an ACC compute construct\n+-    if (isInsideACCComputeConstruct(loopOp))\n+-      return failure();\n+-\n+-    if (loopOp.getUnstructured()) {\n+-      auto executeRegion =\n+-          acc::convertUnstructuredACCLoopToSCFExecuteRegion(loopOp, rewriter);\n+-      if (!executeRegion)\n+-        return failure();\n+-      rewriter.replaceOp(loopOp, executeRegion);\n+-    } else {\n+-      auto forOp =\n+-          acc::convertACCLoopToSCFFor(loopOp, /*enableCollapse=*/false);\n+-      if (!forOp)\n+-        return failure();\n+-      rewriter.replaceOp(loopOp, forOp);\n+-    }\n+-    return success();\n+-  }\n+-};\n+-\n+-/// Check if an operation is used by a compute construct or loop op\n+-static bool isUsedByComputeOrLoop(Operation *op) {\n+-  for (auto *user : op->getUsers())\n+-    if (isa<acc::ParallelOp, acc::SerialOp, acc::KernelsOp, acc::LoopOp>(user))\n+-      return true;\n+-  return false;\n+-}\n+-\n+-/// Orphan data entry ops - only match if NOT connected to compute/loop and\n+-/// NOT inside a compute region. Used for acc.cache, acc.private,\n+-/// acc.firstprivate, acc.reduction.\n+-template <typename OpTy>\n+-class ACCOrphanDataEntryConversion : public OpRewritePattern<OpTy> {\n+-  using OpRewritePattern<OpTy>::OpRewritePattern;\n+-\n+-  LogicalResult matchAndRewrite(OpTy op,\n+-                                PatternRewriter &rewriter) const override {\n+-    // Only convert if this op is not used by a compute construct or loop,\n+-    // and not inside an ACC compute construct.\n+-    if (isUsedByComputeOrLoop(op) || isInsideACCComputeConstruct(op))\n+-      return failure();\n+-\n+-    if (op->use_empty())\n+-      rewriter.eraseOp(op);\n+-    else\n+-      rewriter.replaceOp(op, op.getVar());\n+-    return success();\n+-  }\n+-};\n+-\n+-class ACCSpecializeForHost\n+-    : public acc::impl::ACCSpecializeForHostBase<ACCSpecializeForHost> {\n+-public:\n+-  using ACCSpecializeForHostBase<\n+-      ACCSpecializeForHost>::ACCSpecializeForHostBase;\n+-\n+-  void runOnOperation() override {\n+-    LLVM_DEBUG(llvm::dbgs() << \"Enter ACCSpecializeForHost()\\n\");\n+-\n+-    func::FuncOp funcOp = getOperation();\n+-    if (!acc::isSpecializedAccRoutine(funcOp)) {\n+-      // Convert orphan operations to host, or all ACC operations if\n+-      // host fallback patterns are enabled.\n+-      auto *context = &getContext();\n+-      RewritePatternSet patterns(context);\n+-      OpenACCSupport &accSupport = getAnalysis<OpenACCSupport>();\n+-      if (enableHostFallback)\n+-        populateACCHostFallbackPatterns(patterns, accSupport);\n+-      else\n+-        populateACCOrphanToHostPatterns(patterns, accSupport);\n+-      GreedyRewriteConfig config;\n+-      config.setUseTopDownTraversal(true);\n+-      if (failed(applyPatternsGreedily(funcOp, std::move(patterns), config)))\n+-        signalPassFailure();\n+-    }\n+-\n+-    LLVM_DEBUG(llvm::dbgs() << \"Exit ACCSpecializeForHost()\\n\");\n+-  }\n+-};\n+-} // namespace\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Pattern population functions\n+-//===----------------------------------------------------------------------===//\n+-\n+-void mlir::acc::populateACCOrphanToHostPatterns(RewritePatternSet &patterns,\n+-                                                OpenACCSupport &accSupport,\n+-                                                bool enableLoopConversion) {\n+-  MLIRContext *context = patterns.getContext();\n+-\n+-  // For host routines (acc routine marked for host), we only convert orphan\n+-  // operations that are not allowed outside compute regions. All patterns\n+-  // here check that the operation is NOT inside a compute region before\n+-  // converting:\n+-  // - acc.atomic.* -> load/store operations\n+-  // - acc.loop -> scf.for or scf.execute_region\n+-  // - acc.cache -> replaced with var\n+-  // - acc.private, acc.reduction, acc.firstprivate -> replaced with var\n+-  //   (only if NOT connected to compute constructs or loop)\n+-  //\n+-  // We do NOT remove structured/unstructured data constructs, compute\n+-  // constructs, or their associated data operations - those are valid\n+-  // in host routines and will be processed by other passes.\n+-\n+-  // Loop conversion (orphan only)\n+-  if (enableLoopConversion)\n+-    patterns.insert<ACCOrphanLoopOpConversion>(context);\n+-\n+-  // Atomic operations - convert to non-atomic load/store (orphan only)\n+-  patterns.insert<ACCOrphanAtomicUpdateOpConversion>(context, accSupport);\n+-  patterns.insert<ACCOrphanAtomicReadOpConversion>(context, accSupport);\n+-  patterns.insert<ACCOrphanAtomicWriteOpConversion>(context, accSupport);\n+-  patterns.insert<ACCOrphanAtomicCaptureOpConversion>(context);\n+-\n+-  // Orphan data entry ops - only convert if NOT connected to compute/loop\n+-  // and NOT inside a compute region\n+-  patterns.insert<ACCOrphanDataEntryConversion<acc::CacheOp>,\n+-                  ACCOrphanDataEntryConversion<acc::PrivateOp>,\n+-                  ACCOrphanDataEntryConversion<acc::FirstprivateOp>,\n+-                  ACCOrphanDataEntryConversion<acc::ReductionOp>>(context);\n+-}\n+-\n+-void mlir::acc::populateACCHostFallbackPatterns(RewritePatternSet &patterns,\n+-                                                OpenACCSupport &accSupport,\n+-                                                bool enableLoopConversion) {\n+-  MLIRContext *context = patterns.getContext();\n+-\n+-  // For host fallback path (when `if` clause evaluates to false), ALL ACC\n+-  // operations within the region should be converted to host equivalents.\n+-  // This includes structured/unstructured data, compute constructs, and\n+-  // their associated data operations.\n+-\n+-  // Loop conversion - OK to use the orphan loop conversion pattern here\n+-  // because the parent compute constructs will also be converted.\n+-  if (enableLoopConversion)\n+-    patterns.insert<ACCOrphanLoopOpConversion>(context);\n+-\n+-  // Atomic operations - convert to non-atomic load/store. OK to use the orphan\n+-  // atomic conversion patterns here because the parent compute constructs will\n+-  // also be converted.\n+-  patterns.insert<ACCOrphanAtomicUpdateOpConversion>(context, accSupport);\n+-  patterns.insert<ACCOrphanAtomicReadOpConversion>(context, accSupport);\n+-  patterns.insert<ACCOrphanAtomicWriteOpConversion>(context, accSupport);\n+-  patterns.insert<ACCOrphanAtomicCaptureOpConversion>(context);\n+-\n+-  // acc.cache - convert ALL cache ops (including those inside compute regions)\n+-  patterns.insert<ACCOpReplaceWithVarConversion<acc::CacheOp>>(context);\n+-\n+-  // Privatization ops - convert ALL (including those attached to compute/loop)\n+-  patterns.insert<ACCOpReplaceWithVarConversion<acc::PrivateOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::FirstprivateOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::ReductionOp>>(context);\n+-\n+-  // Data entry ops - replaced with their var operand\n+-  patterns.insert<ACCOpReplaceWithVarConversion<acc::CopyinOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::CreateOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::AttachOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::PresentOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::DevicePtrOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::GetDevicePtrOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::NoCreateOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::DeclareDeviceResidentOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::DeclareLinkOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::UseDeviceOp>,\n+-                  ACCOpReplaceWithVarConversion<acc::UpdateDeviceOp>>(context);\n+-\n+-  // Data exit ops - simply erased (no results)\n+-  patterns.insert<ACCOpEraseConversion<acc::CopyoutOp>,\n+-                  ACCOpEraseConversion<acc::DeleteOp>,\n+-                  ACCOpEraseConversion<acc::DetachOp>,\n+-                  ACCOpEraseConversion<acc::UpdateHostOp>>(context);\n+-\n+-  // Structured data constructs - unwrap their regions\n+-  patterns.insert<ACCRegionUnwrapConversion<acc::DataOp>,\n+-                  ACCRegionUnwrapConversion<acc::HostDataOp>,\n+-                  ACCRegionUnwrapConversion<acc::KernelEnvironmentOp>>(context);\n+-\n+-  // Declare ops\n+-  patterns.insert<ACCDeclareEnterOpConversion,\n+-                  ACCRegionUnwrapConversion<acc::DeclareOp>>(context);\n+-\n+-  // Unstructured data operations - erase them\n+-  patterns.insert<ACCOpEraseConversion<acc::EnterDataOp>,\n+-                  ACCOpEraseConversion<acc::ExitDataOp>,\n+-                  ACCOpEraseConversion<acc::UpdateOp>>(context);\n+-\n+-  // Runtime operations - erase them\n+-  patterns.insert<\n+-      ACCOpEraseConversion<acc::InitOp>, ACCOpEraseConversion<acc::ShutdownOp>,\n+-      ACCOpEraseConversion<acc::SetOp>, ACCOpEraseConversion<acc::WaitOp>,\n+-      ACCOpEraseConversion<acc::TerminatorOp>>(context);\n+-\n+-  // Compute constructs - unwrap their regions\n+-  patterns.insert<ACCRegionUnwrapConversion<acc::ParallelOp>,\n+-                  ACCRegionUnwrapConversion<acc::SerialOp>,\n+-                  ACCRegionUnwrapConversion<acc::KernelsOp>>(context);\n+-}\n+diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt b/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt\n+--- a/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt\n++++ b/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt\n+@@ -4,8 +4,6 @@\n+   ACCImplicitDeclare.cpp\n+   ACCImplicitRoutine.cpp\n+   ACCLegalizeSerial.cpp\n+-  ACCSpecializeForDevice.cpp\n+-  ACCSpecializeForHost.cpp\n+   LegalizeDataValues.cpp\n  \n-   // [flat.map.access], element access\n--  [[nodiscard]] _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](const key_type& __x)\n-+  _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](const key_type& __x)\n-     requires is_constructible_v<mapped_type>\n-   {\n-     return try_emplace(__x).first->second;\n+   ADDITIONAL_HEADER_DIRS\n+@@ -28,7 +26,6 @@\n+   MLIRFuncDialect\n+   MLIRIR\n+   MLIRPass\n+-  MLIRSCFDialect\n+   MLIRSupport\n+   MLIRTransforms\n+ )\n+diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp b/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp\n+--- a/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp\n++++ b/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp\n+@@ -31,27 +31,6 @@\n    }\n+ };\n  \n--  [[nodiscard]] _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](key_type&& __x)\n-+  _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](key_type&& __x)\n-     requires is_constructible_v<mapped_type>\n-   {\n-     return try_emplace(std::move(__x)).first->second;\n-@@ -480,7 +480,7 @@\n-   template <class _Kp>\n-     requires(__is_compare_transparent && is_constructible_v<key_type, _Kp> && is_constructible_v<mapped_type> &&\n-              !is_convertible_v<_Kp &&, const_iterator> && !is_convertible_v<_Kp &&, iterator>)\n--  [[nodiscard]] _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](_Kp&& __x) {\n-+  _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](_Kp&& __x) {\n-     return try_emplace(std::forward<_Kp>(__x)).first->second;\n+-struct CollapseShapeOpInterface\n+-    : public ValueBoundsOpInterface::ExternalModel<CollapseShapeOpInterface,\n+-                                                   CollapseShapeOp> {\n+-  void populateBoundsForShapedValueDim(Operation *op, Value value, int64_t dim,\n+-                                       ValueBoundsConstraintSet &cstr) const {\n+-    auto collapseOp = cast<CollapseShapeOp>(op);\n+-    assert(value == collapseOp.getResult() && \"invalid value\");\n+-\n+-    // Multiply the expressions for the dimensions in the reassociation group.\n+-    const ReassociationIndices &reassocIndices =\n+-        collapseOp.getReassociationIndices()[dim];\n+-    AffineExpr productExpr =\n+-        cstr.getExpr(collapseOp.getSrc(), reassocIndices[0]);\n+-    for (size_t i = 1; i < reassocIndices.size(); ++i) {\n+-      productExpr =\n+-          productExpr * cstr.getExpr(collapseOp.getSrc(), reassocIndices[i]);\n+-    }\n+-    cstr.bound(value)[dim] == productExpr;\n+-  }\n+-};\n+-\n+ struct DimOpInterface\n+     : public ValueBoundsOpInterface::ExternalModel<DimOpInterface, DimOp> {\n+   void populateBoundsForIndexValue(Operation *op, Value value,\n+@@ -78,17 +57,6 @@\n    }\n+ };\n  \n-diff -ruN --strip-trailing-cr a/libcxx/include/map b/libcxx/include/map\n---- a/libcxx/include/map\n-+++ b/libcxx/include/map\n-@@ -1092,9 +1092,9 @@\n-   [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI size_type size() const _NOEXCEPT { return __tree_.size(); }\n-   [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI size_type max_size() const _NOEXCEPT { return __tree_.max_size(); }\n- \n--  [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](const key_type& __k);\n-+  _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](const key_type& __k);\n- #  ifndef _LIBCPP_CXX03_LANG\n--  [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](key_type&& __k);\n-+  _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](key_type&& __k);\n- #  endif\n- \n-   template <class _Arg,\n-diff -ruN --strip-trailing-cr a/libcxx/include/unordered_map b/libcxx/include/unordered_map\n---- a/libcxx/include/unordered_map\n-+++ b/libcxx/include/unordered_map\n-@@ -1262,9 +1262,9 @@\n-   }\n- #  endif // _LIBCPP_STD_VER >= 20\n- \n--  [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](const key_type& __k);\n-+  _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](const key_type& __k);\n- #  ifndef _LIBCPP_CXX03_LANG\n--  [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](key_type&& __k);\n-+  _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](key_type&& __k);\n- #  endif\n- \n-   [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI mapped_type& at(const key_type& __k);\n-diff -ruN --strip-trailing-cr a/libcxx/test/libcxx/diagnostics/flat_map.nodiscard.verify.cpp b/libcxx/test/libcxx/diagnostics/flat_map.nodiscard.verify.cpp\n---- a/libcxx/test/libcxx/diagnostics/flat_map.nodiscard.verify.cpp\n-+++ b/libcxx/test/libcxx/diagnostics/flat_map.nodiscard.verify.cpp\n-@@ -66,9 +66,9 @@\n-   TransparentKey<int> tkey;\n- \n-   std::flat_map<int, int> nfm;\n--  nfm[key];            // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n--  fm[std::move(key)];  // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n--  fm[std::move(tkey)]; // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n-+  nfm[key];            // no-warning\n-+  fm[std::move(key)];  // no-warning\n-+  fm[std::move(tkey)]; // no-warning\n- \n-   fm.at(key);   // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n-   cfm.at(key);  // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n-diff -ruN --strip-trailing-cr a/libcxx/test/libcxx/diagnostics/map.nodiscard.verify.cpp b/libcxx/test/libcxx/diagnostics/map.nodiscard.verify.cpp\n---- a/libcxx/test/libcxx/diagnostics/map.nodiscard.verify.cpp\n-+++ b/libcxx/test/libcxx/diagnostics/map.nodiscard.verify.cpp\n-@@ -55,8 +55,8 @@\n- \n-   int key = 0;\n- \n--  m[key];            // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n--  m[std::move(key)]; // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n-+  m[key];            // no-warning\n-+  m[std::move(key)]; // no-warning\n- \n- #if TEST_STD_VER >= 14\n-   std::map<std::string, int, std::less<>> strMap;\n-diff -ruN --strip-trailing-cr a/libcxx/test/libcxx/diagnostics/unordered_map.nodiscard.verify.cpp b/libcxx/test/libcxx/diagnostics/unordered_map.nodiscard.verify.cpp\n---- a/libcxx/test/libcxx/diagnostics/unordered_map.nodiscard.verify.cpp\n-+++ b/libcxx/test/libcxx/diagnostics/unordered_map.nodiscard.verify.cpp\n-@@ -81,8 +81,8 @@\n-   ctm.equal_range(tkey); // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n- #endif\n- \n--  m[key];            // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n--  m[std::move(key)]; // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n-+  m[key];            // no-warning\n-+  m[std::move(key)]; // no-warning\n- \n-   m.at(key);  // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n-   cm.at(key); // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+-struct ExpandShapeOpInterface\n+-    : public ValueBoundsOpInterface::ExternalModel<ExpandShapeOpInterface,\n+-                                                   ExpandShapeOp> {\n+-  void populateBoundsForShapedValueDim(Operation *op, Value value, int64_t dim,\n+-                                       ValueBoundsConstraintSet &cstr) const {\n+-    auto expandOp = cast<ExpandShapeOp>(op);\n+-    assert(value == expandOp.getResult() && \"invalid value\");\n+-    cstr.bound(value)[dim] == expandOp.getMixedOutputShape()[dim];\n+-  }\n+-};\n+-\n+ struct ExtractSliceOpInterface\n+     : public ValueBoundsOpInterface::ExternalModel<ExtractSliceOpInterface,\n+                                                    ExtractSliceOp> {\n+@@ -149,12 +117,8 @@\n+     DialectRegistry &registry) {\n+   registry.addExtension(+[](MLIRContext *ctx, tensor::TensorDialect *dialect) {\n+     tensor::CastOp::attachInterface<tensor::CastOpInterface>(*ctx);\n+-    tensor::CollapseShapeOp::attachInterface<tensor::CollapseShapeOpInterface>(\n+-        *ctx);\n+     tensor::DimOp::attachInterface<tensor::DimOpInterface>(*ctx);\n+     tensor::EmptyOp::attachInterface<tensor::EmptyOpInterface>(*ctx);\n+-    tensor::ExpandShapeOp::attachInterface<tensor::ExpandShapeOpInterface>(\n+-        *ctx);\n+     tensor::ExtractSliceOp::attachInterface<tensor::ExtractSliceOpInterface>(\n+         *ctx);\n+     tensor::PadOp::attachInterface<tensor::PadOpInterface>(*ctx);\n+diff -ruN --strip-trailing-cr a/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir b/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir\n+--- a/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir\n++++ b/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir\n+@@ -1,204 +0,0 @@\n+-// RUN: mlir-opt %s -acc-specialize-for-device | FileCheck %s\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Data entry ops in specialized routines\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_0 func(@attach) seq\n+-// CHECK-LABEL: func.func @attach\n+-// CHECK-NOT:   acc.attach\n+-func.func @attach(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_0, <seq>, \"attach\">} {\n+-  %c0 = arith.constant 0 : i32\n+-  %0 = acc.attach varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  memref.store %c0, %0[] : memref<i32>\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_1 func(@copyin) seq\n+-// CHECK-LABEL: func.func @copyin\n+-// CHECK-NOT:   acc.copyin\n+-func.func @copyin(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_1, <seq>, \"copyin\">} {\n+-  %c0 = arith.constant 0 : i32\n+-  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  memref.store %c0, %0[] : memref<i32>\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_2 func(@create) seq\n+-// CHECK-LABEL: func.func @create\n+-// CHECK-NOT:   acc.create\n+-func.func @create(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_2, <seq>, \"create\">} {\n+-  %c0 = arith.constant 0 : i32\n+-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  memref.store %c0, %0[] : memref<i32>\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_3 func(@present) seq\n+-// CHECK-LABEL: func.func @present\n+-// CHECK-NOT:   acc.present\n+-func.func @present(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_3, <seq>, \"present\">} {\n+-  %c0 = arith.constant 0 : i32\n+-  %0 = acc.present varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  memref.store %c0, %0[] : memref<i32>\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Data entry ops INSIDE compute constructs (non-specialized functions)\n+-//===----------------------------------------------------------------------===//\n+-\n+-// CHECK-LABEL: func.func @copyin_inside_parallel\n+-// CHECK:       acc.parallel\n+-// CHECK-NOT:   acc.copyin\n+-// CHECK:       acc.yield\n+-func.func @copyin_inside_parallel(%arg0 : memref<i32>) {\n+-  %c0 = arith.constant 0 : i32\n+-  acc.parallel {\n+-    %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-    memref.store %c0, %0[] : memref<i32>\n+-    acc.yield\n+-  }\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Data entry ops OUTSIDE compute constructs should NOT be removed\n+-//===----------------------------------------------------------------------===//\n+-\n+-// CHECK-LABEL: func.func @copyin_outside_parallel\n+-// CHECK:       acc.copyin\n+-// CHECK:       acc.parallel\n+-func.func @copyin_outside_parallel(%arg0 : memref<i32>) {\n+-  %c0 = arith.constant 0 : i32\n+-  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  acc.parallel dataOperands(%0 : memref<i32>) {\n+-    memref.store %c0, %0[] : memref<i32>\n+-    acc.yield\n+-  }\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Data exit ops in specialized routines\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_copyout func(@copyout) worker\n+-// CHECK-LABEL: func.func @copyout\n+-// CHECK-NOT:   acc.copyout\n+-func.func @copyout(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_copyout, <worker>, \"copyout\">} {\n+-  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  acc.copyout accPtr(%0 : memref<i32>) to varPtr(%arg0 : memref<i32>)\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_delete func(@delete) worker\n+-// CHECK-LABEL: func.func @delete\n+-// CHECK-NOT:   acc.delete\n+-func.func @delete(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_delete, <worker>, \"delete\">} {\n+-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  acc.delete accPtr(%0 : memref<i32>)\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Erase ops (unstructured data and runtime ops)\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_enter_data func(@enter_data) worker\n+-// CHECK-LABEL: func.func @enter_data\n+-// CHECK-NOT:   acc.enter_data\n+-func.func @enter_data(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_enter_data, <worker>, \"enter_data\">} {\n+-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  acc.enter_data dataOperands(%0 : memref<i32>)\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_init func(@init_op) worker\n+-// CHECK-LABEL: func.func @init_op\n+-// CHECK-NOT:   acc.init\n+-func.func @init_op() attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_init, <worker>, \"init_op\">} {\n+-  acc.init\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_wait func(@wait_op) worker\n+-// CHECK-LABEL: func.func @wait_op\n+-// CHECK-NOT:   acc.wait\n+-func.func @wait_op() attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_wait, <worker>, \"wait_op\">} {\n+-  acc.wait\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Region unwrap (structured data and compute constructs)\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_data func(@data_construct) worker\n+-// CHECK-LABEL: func.func @data_construct\n+-// CHECK-NOT:   acc.data\n+-// CHECK:       arith.constant 42\n+-func.func @data_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_data, <worker>, \"data_construct\">} {\n+-  %d = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  acc.data dataOperands(%d : memref<i32>) {\n+-    %c42 = arith.constant 42 : i32\n+-    memref.store %c42, %arg0[] : memref<i32>\n+-    acc.terminator\n+-  }\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_parallel func(@parallel_construct) worker\n+-// CHECK-LABEL: func.func @parallel_construct\n+-// CHECK-NOT:   acc.parallel\n+-// CHECK:       arith.constant 44\n+-func.func @parallel_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_parallel, <worker>, \"parallel_construct\">} {\n+-  acc.parallel {\n+-    %c44 = arith.constant 44 : i32\n+-    memref.store %c44, %arg0[] : memref<i32>\n+-    acc.yield\n+-  }\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_serial func(@serial_construct) worker\n+-// CHECK-LABEL: func.func @serial_construct\n+-// CHECK-NOT:   acc.serial\n+-// CHECK:       arith.constant 45\n+-func.func @serial_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_serial, <worker>, \"serial_construct\">} {\n+-  acc.serial {\n+-    %c45 = arith.constant 45 : i32\n+-    memref.store %c45, %arg0[] : memref<i32>\n+-    acc.yield\n+-  }\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_kernels func(@kernels_construct) worker\n+-// CHECK-LABEL: func.func @kernels_construct\n+-// CHECK-NOT:   acc.kernels\n+-// CHECK:       arith.constant 46\n+-func.func @kernels_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_kernels, <worker>, \"kernels_construct\">} {\n+-  acc.kernels {\n+-    %c46 = arith.constant 46 : i32\n+-    memref.store %c46, %arg0[] : memref<i32>\n+-    acc.terminator\n+-  }\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Declare enter/exit strip in device routines\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_declare func(@dev_routine_declare) worker\n+-// CHECK-LABEL: func.func @dev_routine_declare\n+-// CHECK-NOT: acc.declare_enter\n+-// CHECK-NOT: acc.declare_exit\n+-func.func @dev_routine_declare() attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_declare, <worker>, \"dev_routine_declare\">} {\n+-  %var = memref.alloca() : memref<f32>\n+-  %c = acc.create varPtr(%var : memref<f32>) -> memref<f32>\n+-  %t = acc.declare_enter dataOperands(%c : memref<f32>)\n+-  acc.declare_exit token(%t) dataOperands(%c : memref<f32>)\n+-  return\n+-}\n+diff -ruN --strip-trailing-cr a/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir b/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir\n+--- a/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir\n++++ b/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir\n+@@ -1,157 +0,0 @@\n+-// RUN: mlir-opt %s --pass-pipeline='builtin.module(func.func(acc-specialize-for-host{enable-host-fallback=true}))' | FileCheck %s\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Data entry ops - replaced with var (host fallback)\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_create func(@create) seq\n+-// CHECK-LABEL: func.func @create\n+-// CHECK-NOT:   acc.create\n+-func.func @create(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_create]>} {\n+-  %c0 = arith.constant 0 : i32\n+-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  memref.store %c0, %0[] : memref<i32>\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_copyin func(@copyin) seq\n+-// CHECK-LABEL: func.func @copyin\n+-// CHECK-NOT:   acc.copyin\n+-func.func @copyin(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_copyin]>} {\n+-  %c0 = arith.constant 0 : i32\n+-  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  memref.store %c0, %0[] : memref<i32>\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_present func(@present) seq\n+-// CHECK-LABEL: func.func @present\n+-// CHECK-NOT:   acc.present\n+-func.func @present(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_present]>} {\n+-  %c0 = arith.constant 0 : i32\n+-  %0 = acc.present varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  memref.store %c0, %0[] : memref<i32>\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Data exit ops - erased (host fallback)\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_copyout func(@copyout) seq\n+-// CHECK-LABEL: func.func @copyout\n+-// CHECK-NOT:   acc.copyout\n+-func.func @copyout(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_copyout]>} {\n+-  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  acc.copyout accPtr(%0 : memref<i32>) to varPtr(%arg0 : memref<i32>)\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_delete func(@delete) seq\n+-// CHECK-LABEL: func.func @delete\n+-// CHECK-NOT:   acc.delete\n+-func.func @delete(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_delete]>} {\n+-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  acc.delete accPtr(%0 : memref<i32>)\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Runtime operations - erased (host fallback)\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_init func(@init_op) seq\n+-// CHECK-LABEL: func.func @init_op\n+-// CHECK-NOT:   acc.init\n+-func.func @init_op() attributes {acc.routine_info = #acc.routine_info<[@acc_routine_init]>} {\n+-  acc.init\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_shutdown func(@shutdown_op) seq\n+-// CHECK-LABEL: func.func @shutdown_op\n+-// CHECK-NOT:   acc.shutdown\n+-func.func @shutdown_op() attributes {acc.routine_info = #acc.routine_info<[@acc_routine_shutdown]>} {\n+-  acc.shutdown\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_wait func(@wait_op) seq\n+-// CHECK-LABEL: func.func @wait_op\n+-// CHECK-NOT:   acc.wait\n+-func.func @wait_op() attributes {acc.routine_info = #acc.routine_info<[@acc_routine_wait]>} {\n+-  acc.wait\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Structured data and compute constructs - unwrap regions (host fallback)\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_data func(@data_construct) seq\n+-// CHECK-LABEL: func.func @data_construct\n+-// CHECK-NOT:   acc.data\n+-// CHECK:       arith.constant 42\n+-func.func @data_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_data]>} {\n+-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  acc.data dataOperands(%0 : memref<i32>) {\n+-    %c42 = arith.constant 42 : i32\n+-    memref.store %c42, %arg0[] : memref<i32>\n+-    acc.terminator\n+-  }\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_parallel func(@parallel_construct) seq\n+-// CHECK-LABEL: func.func @parallel_construct\n+-// CHECK-NOT:   acc.parallel\n+-// CHECK:       arith.constant 44\n+-func.func @parallel_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_parallel]>} {\n+-  acc.parallel {\n+-    %c44 = arith.constant 44 : i32\n+-    memref.store %c44, %arg0[] : memref<i32>\n+-    acc.yield\n+-  }\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_serial func(@serial_construct) seq\n+-// CHECK-LABEL: func.func @serial_construct\n+-// CHECK-NOT:   acc.serial\n+-// CHECK:       arith.constant 45\n+-func.func @serial_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_serial]>} {\n+-  acc.serial {\n+-    %c45 = arith.constant 45 : i32\n+-    memref.store %c45, %arg0[] : memref<i32>\n+-    acc.yield\n+-  }\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_kernels func(@kernels_construct) seq\n+-// CHECK-LABEL: func.func @kernels_construct\n+-// CHECK-NOT:   acc.kernels\n+-// CHECK:       arith.constant 46\n+-func.func @kernels_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_kernels]>} {\n+-  acc.kernels {\n+-    %c46 = arith.constant 46 : i32\n+-    memref.store %c46, %arg0[] : memref<i32>\n+-    acc.terminator\n+-  }\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Declare enter/exit - erased (host fallback)\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_declare func(@declare_enter_exit) seq\n+-// CHECK-LABEL: func.func @declare_enter_exit\n+-// CHECK-NOT:   acc.declare_enter\n+-// CHECK-NOT:   acc.declare_exit\n+-func.func @declare_enter_exit(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_declare]>} {\n+-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  %token = acc.declare_enter dataOperands(%0 : memref<i32>)\n+-  acc.declare_exit token(%token) dataOperands(%0 : memref<i32>)\n+-  return\n+-}\n+diff -ruN --strip-trailing-cr a/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir b/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir\n+--- a/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir\n++++ b/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir\n+@@ -1,404 +0,0 @@\n+-// RUN: mlir-opt %s -acc-specialize-for-host | FileCheck %s\n+-\n+-// Recipe definitions\n+-acc.private.recipe @privatization_memref_i32 : memref<i32> init {\n+-^bb0(%arg0: memref<i32>):\n+-  %0 = memref.alloca() : memref<i32>\n+-  acc.yield %0 : memref<i32>\n+-}\n+-\n+-acc.firstprivate.recipe @firstprivatization_memref_i32 : memref<i32> init {\n+-^bb0(%arg0: memref<i32>):\n+-  %0 = memref.alloca() : memref<i32>\n+-  acc.yield %0 : memref<i32>\n+-} copy {\n+-^bb0(%arg0: memref<i32>, %arg1: memref<i32>):\n+-  %0 = memref.load %arg0[] : memref<i32>\n+-  memref.store %0, %arg1[] : memref<i32>\n+-  acc.terminator\n+-}\n+-\n+-acc.reduction.recipe @reduction_add_memref_i32 : memref<i32> reduction_operator <add> init {\n+-^bb0(%arg0: memref<i32>):\n+-  %c0_i32 = arith.constant 0 : i32\n+-  %0 = memref.alloca() : memref<i32>\n+-  memref.store %c0_i32, %0[] : memref<i32>\n+-  acc.yield %0 : memref<i32>\n+-} combiner {\n+-^bb0(%arg0: memref<i32>, %arg1: memref<i32>):\n+-  %0 = memref.load %arg0[] : memref<i32>\n+-  %1 = memref.load %arg1[] : memref<i32>\n+-  %2 = arith.addi %0, %1 : i32\n+-  memref.store %2, %arg0[] : memref<i32>\n+-  acc.yield %arg0 : memref<i32>\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Orphan data entry ops - replaced with var\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_private func(@private) seq\n+-// CHECK-LABEL: func.func @private\n+-// CHECK-NOT:   acc.private\n+-func.func @private(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_private]>} {\n+-  %c0 = arith.constant 0 : i32\n+-  %0 = acc.private varPtr(%arg0 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n+-  memref.store %c0, %0[] : memref<i32>\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_cache func(@cache) seq\n+-// CHECK-LABEL: func.func @cache\n+-// CHECK-NOT:   acc.cache\n+-func.func @cache(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_cache]>} {\n+-  %c0 = arith.constant 0 : i32\n+-  %0 = acc.cache varPtr(%arg0 : memref<i32>) -> memref<i32>\n+-  memref.store %c0, %0[] : memref<i32>\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Orphan atomic operations - converted to load/store\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_atomic func(@orphan_atomic_update) seq\n+-// CHECK-LABEL: func.func @orphan_atomic_update\n+-// CHECK-NOT:   acc.atomic.update\n+-// CHECK:       memref.load\n+-// CHECK:       arith.addi\n+-// CHECK:       memref.store\n+-func.func @orphan_atomic_update(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic]>} {\n+-  acc.atomic.update %arg0 : memref<i32> {\n+-  ^bb0(%arg1: i32):\n+-    %c1 = arith.constant 1 : i32\n+-    %1 = arith.addi %arg1, %c1 : i32\n+-    acc.yield %1 : i32\n+-  }\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_atomic_read func(@orphan_atomic_read) seq\n+-// CHECK-LABEL: func.func @orphan_atomic_read\n+-// CHECK-NOT:   acc.atomic.read\n+-// CHECK:       memref.copy %arg0, %arg1\n+-func.func @orphan_atomic_read(%arg0 : memref<i32>, %arg1 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_read]>} {\n+-  acc.atomic.read %arg1 = %arg0 : memref<i32>, memref<i32>, i32\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_atomic_write func(@orphan_atomic_write) seq\n+-// CHECK-LABEL: func.func @orphan_atomic_write\n+-// CHECK-NOT:   acc.atomic.write\n+-// CHECK:       memref.store %arg1, %arg0[]\n+-func.func @orphan_atomic_write(%arg0 : memref<i32>, %arg1 : i32) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_write]>} {\n+-  acc.atomic.write %arg0 = %arg1 : memref<i32>, i32\n+-  return\n+-}\n+-\n+-acc.routine @acc_routine_atomic_capture func(@orphan_atomic_capture) seq\n+-// CHECK-LABEL: func.func @orphan_atomic_capture\n+-// CHECK-NOT:   acc.atomic.capture\n+-// CHECK:       memref.copy %arg0, %arg1\n+-// CHECK:       [[LOAD:%.*]] = memref.load %arg0[]\n+-// CHECK:       [[INC:%.*]] = arith.addi [[LOAD]]\n+-// CHECK:       memref.store [[INC]], %arg0[]\n+-func.func @orphan_atomic_capture(%arg0 : memref<i32>, %arg1 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_capture]>} {\n+-  %c1_i32 = arith.constant 1 : i32\n+-  acc.atomic.capture {\n+-    acc.atomic.read %arg1 = %arg0 : memref<i32>, memref<i32>, i32\n+-    acc.atomic.update %arg0 : memref<i32> {\n+-    ^bb0(%v: i32):\n+-      %r = arith.addi %v, %c1_i32 : i32\n+-      acc.yield %r : i32\n+-    }\n+-    acc.terminator\n+-  }\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Negative tests - ops that should NOT be converted\n+-//===----------------------------------------------------------------------===//\n+-\n+-// acc.private attached to acc.parallel should NOT be removed\n+-acc.routine @acc_routine_private_parallel func(@private_attached_to_parallel) seq\n+-// CHECK-LABEL: func.func @private_attached_to_parallel\n+-// CHECK:       acc.private\n+-// CHECK:       acc.parallel\n+-func.func @private_attached_to_parallel(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_private_parallel]>} {\n+-  %0 = acc.private varPtr(%arg0 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n+-  acc.parallel private(%0 : memref<i32>) {\n+-    %c1 = arith.constant 1 : i32\n+-    memref.store %c1, %0[] : memref<i32>\n+-    acc.yield\n+-  }\n+-  return\n+-}\n+-\n+-// acc.atomic.update inside acc.parallel should NOT be converted\n+-acc.routine @acc_routine_atomic_parallel func(@atomic_inside_parallel) seq\n+-// CHECK-LABEL: func.func @atomic_inside_parallel\n+-// CHECK:       acc.parallel\n+-// CHECK:       acc.atomic.update\n+-func.func @atomic_inside_parallel(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_parallel]>} {\n+-  acc.parallel {\n+-    acc.atomic.update %arg0 : memref<i32> {\n+-    ^bb0(%arg1: i32):\n+-      %c1 = arith.constant 1 : i32\n+-      %1 = arith.addi %arg1, %c1 : i32\n+-      acc.yield %1 : i32\n+-    }\n+-    acc.yield\n+-  }\n+-  return\n+-}\n+-\n+-// acc.loop inside acc.parallel should NOT be converted\n+-acc.routine @acc_routine_loop_parallel func(@loop_inside_parallel) seq\n+-// CHECK-LABEL: func.func @loop_inside_parallel\n+-// CHECK:       acc.parallel\n+-// CHECK:       acc.loop\n+-func.func @loop_inside_parallel(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_loop_parallel]>} {\n+-  %c0 = arith.constant 0 : index\n+-  %c10 = arith.constant 10 : index\n+-  %c1 = arith.constant 1 : index\n+-  acc.parallel {\n+-    acc.loop control(%iv : index) = (%c0 : index) to (%c10 : index) step (%c1 : index) {\n+-      %c5 = arith.constant 5 : i32\n+-      memref.store %c5, %arg0[] : memref<i32>\n+-      acc.yield\n+-    } attributes {inclusiveUpperbound = array<i1: true>, seq = [#acc.device_type<none>]}\n+-    acc.yield\n+-  }\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Positive tests - orphan ops attached to orphan loop (both should convert)\n+-//===----------------------------------------------------------------------===//\n+-\n+-// acc.private attached to orphan acc.loop - BOTH should be removed\n+-acc.routine @acc_routine_private_loop func(@private_attached_to_loop) seq\n+-// CHECK-LABEL: func.func @private_attached_to_loop\n+-// CHECK-NOT:   acc.private\n+-// CHECK-NOT:   acc.loop\n+-// CHECK:       scf.for\n+-func.func @private_attached_to_loop(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_private_loop]>} {\n+-  %c0 = arith.constant 0 : i32\n+-  %c10 = arith.constant 10 : i32\n+-  %c1 = arith.constant 1 : i32\n+-  %0 = acc.private varPtr(%arg0 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n+-  acc.loop private(%0 : memref<i32>) control(%iv : i32) = (%c0 : i32) to (%c10 : i32) step (%c1 : i32) {\n+-    %c1_i32 = arith.constant 1 : i32\n+-    memref.store %c1_i32, %0[] : memref<i32>\n+-    acc.yield\n+-  } attributes {inclusiveUpperbound = array<i1: true>, seq = [#acc.device_type<none>]}\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Orphan loop conversion tests\n+-//===----------------------------------------------------------------------===//\n+-\n+-// Orphan acc.loop should be converted to scf.for\n+-acc.routine @acc_routine_loop func(@orphan_loop) seq\n+-// CHECK-LABEL: func.func @orphan_loop\n+-// CHECK-NOT:   acc.loop\n+-// CHECK:       scf.for\n+-func.func @orphan_loop(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_loop]>} {\n+-  %c0 = arith.constant 0 : i32\n+-  %c10 = arith.constant 10 : i32\n+-  %c1 = arith.constant 1 : i32\n+-  acc.loop control(%iv : i32) = (%c0 : i32) to (%c10 : i32) step (%c1 : i32) {\n+-    memref.store %iv, %arg0[] : memref<i32>\n+-    acc.yield\n+-  } attributes {inclusiveUpperbound = array<i1: true>, seq = [#acc.device_type<none>]}\n+-  return\n+-}\n+-\n+-// Nested orphan acc.loop should be converted to nested scf.for\n+-acc.routine @acc_routine_nested_loop func(@nested_orphan_loop) seq\n+-// CHECK-LABEL: func.func @nested_orphan_loop\n+-// CHECK-NOT:   acc.loop\n+-// CHECK:       scf.for\n+-// CHECK:       scf.for\n+-func.func @nested_orphan_loop(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_nested_loop]>} {\n+-  %c0 = arith.constant 0 : i32\n+-  %c10 = arith.constant 10 : i32\n+-  %c1 = arith.constant 1 : i32\n+-  acc.loop control(%iv0 : i32, %iv1 : i32) = (%c0, %c0 : i32, i32) to (%c10, %c10 : i32, i32) step (%c1, %c1 : i32, i32) {\n+-    %sum = arith.addi %iv0, %iv1 : i32\n+-    memref.store %sum, %arg0[] : memref<i32>\n+-    acc.yield\n+-  } attributes {inclusiveUpperbound = array<i1: true, true>, seq = [#acc.device_type<none>]}\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Unstructured orphan loop - converted to scf.execute_region\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_unstructured func(@orphan_unstructured_loop) seq\n+-// CHECK-LABEL: func.func @orphan_unstructured_loop\n+-// CHECK-NOT:   acc.loop\n+-// CHECK-NOT:   acc.private\n+-// CHECK:       scf.execute_region\n+-// CHECK:       ^bb{{[0-9]+}}:\n+-// CHECK:       cf.cond_br\n+-// CHECK:       scf.yield\n+-func.func @orphan_unstructured_loop(%arg0 : memref<32xi32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_unstructured]>} {\n+-  %c32_i32 = arith.constant 32 : i32\n+-  %c2_i32 = arith.constant 2 : i32\n+-  %c0_i32 = arith.constant 0 : i32\n+-  %c1_i32 = arith.constant 1 : i32\n+-  %iter_var = memref.alloca() : memref<i32>\n+-  %priv = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n+-  acc.loop private(%priv : memref<i32>) {\n+-    %limit = memref.alloca() : memref<i32>\n+-    memref.store %c32_i32, %limit[] : memref<i32>\n+-    memref.store %c1_i32, %priv[] : memref<i32>\n+-    cf.br ^bb1\n+-  ^bb1:\n+-    %count = memref.load %limit[] : memref<i32>\n+-    %cond = arith.cmpi sgt, %count, %c0_i32 : i32\n+-    cf.cond_br %cond, ^bb2, ^bb3\n+-  ^bb2:\n+-    %idx = memref.load %priv[] : memref<i32>\n+-    %idx_idx = arith.index_cast %idx : i32 to index\n+-    %val = memref.load %arg0[%idx_idx] : memref<32xi32>\n+-    %new_val = arith.divsi %val, %c2_i32 : i32\n+-    memref.store %new_val, %arg0[%idx_idx] : memref<32xi32>\n+-    %new_count = arith.subi %count, %c1_i32 : i32\n+-    memref.store %new_count, %limit[] : memref<i32>\n+-    %new_idx = arith.addi %idx, %c1_i32 : i32\n+-    memref.store %new_idx, %priv[] : memref<i32>\n+-    cf.br ^bb1\n+-  ^bb3:\n+-    acc.yield\n+-  } attributes {independent = [#acc.device_type<none>], unstructured}\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Orphan loop with reduction - both converted\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_loop_reduction func(@orphan_loop_with_reduction) seq\n+-// CHECK-LABEL: func.func @orphan_loop_with_reduction\n+-// CHECK-NOT:   acc.loop\n+-// CHECK-NOT:   acc.reduction\n+-// CHECK-NOT:   acc.private\n+-// CHECK:       scf.for\n+-func.func @orphan_loop_with_reduction(%arg0 : memref<i32>, %arg1 : memref<100xi32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_loop_reduction]>} {\n+-  %c100_i32 = arith.constant 100 : i32\n+-  %c1_i32 = arith.constant 1 : i32\n+-  %iter_var = memref.alloca() : memref<i32>\n+-  %red = acc.reduction varPtr(%arg0 : memref<i32>) recipe(@reduction_add_memref_i32) -> memref<i32>\n+-  %priv = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n+-  acc.loop vector private(%priv : memref<i32>) reduction(%red : memref<i32>) control(%arg2 : i32) = (%c1_i32 : i32) to (%c100_i32 : i32) step (%c1_i32 : i32) {\n+-    memref.store %arg2, %priv[] : memref<i32>\n+-    %idx = memref.load %priv[] : memref<i32>\n+-    %idx_cast = arith.index_cast %idx : i32 to index\n+-    %elem = memref.load %arg1[%idx_cast] : memref<100xi32>\n+-    %r_val = memref.load %arg0[] : memref<i32>\n+-    %new_r = arith.addi %r_val, %elem : i32\n+-    memref.store %new_r, %arg0[] : memref<i32>\n+-    acc.yield\n+-  } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Orphan loop with variable bounds\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.routine @acc_routine_var_bounds func(@orphan_loop_variable_bounds) seq\n+-// CHECK-LABEL: func.func @orphan_loop_variable_bounds\n+-// CHECK-NOT:   acc.loop\n+-// CHECK:       [[LB:%.*]] = memref.load %arg0[]\n+-// CHECK:       [[UB:%.*]] = memref.load %arg1[]\n+-// CHECK:       scf.for\n+-func.func @orphan_loop_variable_bounds(%arg0 : memref<i32>, %arg1 : memref<i32>, %arg2 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_var_bounds]>} {\n+-  %c1 = arith.constant 1 : i32\n+-  %lb = memref.load %arg0[] : memref<i32>\n+-  %ub = memref.load %arg1[] : memref<i32>\n+-  acc.loop vector control(%iv : i32) = (%lb : i32) to (%ub : i32) step (%c1 : i32) {\n+-    memref.store %iv, %arg2[] : memref<i32>\n+-    acc.yield\n+-  } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n+-  return\n+-}\n+-\n+-//===----------------------------------------------------------------------===//\n+-// Orphan loop between compute regions - only orphan converted\n+-//===----------------------------------------------------------------------===//\n+-\n+-acc.reduction.recipe @reduction_mul_memref_i32 : memref<i32> reduction_operator <mul> init {\n+-^bb0(%arg0: memref<i32>):\n+-  %c1_i32 = arith.constant 1 : i32\n+-  %0 = memref.alloca() : memref<i32>\n+-  memref.store %c1_i32, %0[] : memref<i32>\n+-  acc.yield %0 : memref<i32>\n+-} combiner {\n+-^bb0(%arg0: memref<i32>, %arg1: memref<i32>):\n+-  %0 = memref.load %arg0[] : memref<i32>\n+-  %1 = memref.load %arg1[] : memref<i32>\n+-  %2 = arith.muli %0, %1 : i32\n+-  memref.store %2, %arg0[] : memref<i32>\n+-  acc.yield %arg0 : memref<i32>\n+-}\n+-\n+-// Orphan loop sandwiched between compute regions - only orphan should convert\n+-// CHECK-LABEL: func.func @orphan_between_compute_regions\n+-// CHECK:       acc.parallel\n+-// CHECK:       acc.yield\n+-// CHECK-NOT:   acc.private varPtr\n+-// CHECK-NOT:   acc.reduction varPtr\n+-// CHECK:       scf.for\n+-// CHECK:       acc.parallel\n+-func.func @orphan_between_compute_regions(%arg0 : memref<i32>, %arg1 : memref<8xi32>, %arg2 : memref<i32>) {\n+-  %c2_i32 = arith.constant 2 : i32\n+-  %c8_i32 = arith.constant 8 : i32\n+-  %c1_i32 = arith.constant 1 : i32\n+-  %iter_var = memref.alloca() : memref<i32>\n+-\n+-  // First compute region - should NOT be converted\n+-  acc.parallel combined(loop) {\n+-    %priv1 = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n+-    acc.loop combined(parallel) private(%priv1 : memref<i32>) control(%iv : i32) = (%c1_i32 : i32) to (%c8_i32 : i32) step (%c1_i32 : i32) {\n+-      memref.store %iv, %priv1[] : memref<i32>\n+-      %idx = arith.index_cast %iv : i32 to index\n+-      memref.store %c1_i32, %arg1[%idx] : memref<8xi32>\n+-      acc.yield\n+-    } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n+-    acc.yield\n+-  }\n+-\n+-  // Orphan loop - SHOULD be converted\n+-  %priv_orphan = acc.private varPtr(%arg2 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n+-  %red_orphan = acc.reduction varPtr(%arg0 : memref<i32>) recipe(@reduction_mul_memref_i32) -> memref<i32>\n+-  %priv_iv = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n+-  acc.loop private(%priv_orphan, %priv_iv : memref<i32>, memref<i32>) reduction(%red_orphan : memref<i32>) control(%iv : i32) = (%c1_i32 : i32) to (%c8_i32 : i32) step (%c1_i32 : i32) {\n+-    memref.store %iv, %priv_iv[] : memref<i32>\n+-    %idx = arith.index_cast %iv : i32 to index\n+-    %elem = memref.load %arg1[%idx] : memref<8xi32>\n+-    memref.store %elem, %priv_orphan[] : memref<i32>\n+-    %t = memref.load %priv_orphan[] : memref<i32>\n+-    %mul = arith.muli %t, %c2_i32 : i32\n+-    memref.store %mul, %arg0[] : memref<i32>\n+-    acc.yield\n+-  } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n+-\n+-  // Second compute region - should NOT be converted\n+-  acc.parallel combined(loop) {\n+-    %priv2 = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n+-    acc.loop combined(parallel) private(%priv2 : memref<i32>) control(%iv : i32) = (%c1_i32 : i32) to (%c8_i32 : i32) step (%c1_i32 : i32) {\n+-      memref.store %iv, %priv2[] : memref<i32>\n+-      %idx = arith.index_cast %iv : i32 to index\n+-      memref.store %iv, %arg1[%idx] : memref<8xi32>\n+-      acc.yield\n+-    } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n+-    acc.yield\n+-  }\n+-  return\n+-}\n+diff -ruN --strip-trailing-cr a/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir b/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir\n+--- a/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir\n++++ b/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir\n+@@ -230,35 +230,3 @@\n+   %1 = \"test.reify_bound\"(%padded) {dim = 1, constant} : (tensor<1x?x64xf32>) -> (index)\n+   return\n+ }\n+-\n+-// -----\n+-\n+-//       CHECK: #[[$MAP:.+]] = affine_map<()[s0] -> (s0 * 2)>\n+-// CHECK-LABEL: func @tensor_collapse(\n+-//  CHECK-SAME:     %[[sz0:.*]]: index\n+-//   CHECK-DAG:   %[[c2:.*]] = arith.constant 2 : index\n+-//   CHECK-DAG:   %[[c12:.*]] = arith.constant 12 : index\n+-//       CHECK:   %[[dim:.*]] = tensor.dim %{{.*}}, %[[c2]] : tensor<3x4x?x2xf32>\n+-//       CHECK:   %[[mul:.*]] = affine.apply #[[$MAP]]()[%[[dim]]]\n+-//       CHECK:   return %[[c12]], %[[mul]]\n+-func.func @tensor_collapse(%sz0: index) -> (index, index) {\n+-  %0 = tensor.empty(%sz0) : tensor<3x4x?x2xf32>\n+-  %1 = tensor.collapse_shape %0 [[0, 1], [2, 3]] : tensor<3x4x?x2xf32> into tensor<12x?xf32>\n+-  %2 = \"test.reify_bound\"(%1) {dim = 0} : (tensor<12x?xf32>) -> (index)\n+-  %3 = \"test.reify_bound\"(%1) {dim = 1} : (tensor<12x?xf32>) -> (index)\n+-  return %2, %3 : index, index\n+-}\n+-\n+-// -----\n+-\n+-// CHECK-LABEL: func @tensor_expand(\n+-//  CHECK-SAME:     %[[t:[a-zA-Z0-9]+]]: tensor<?xf32>\n+-//  CHECK-SAME:     %[[sz:[a-zA-Z0-9]+]]: index\n+-//       CHECK:   %[[c4:.*]] = arith.constant 4 : index\n+-//       CHECK:   return %[[c4]], %[[sz]]\n+-func.func @tensor_expand(%t: tensor<?xf32>, %sz: index) -> (index, index) {\n+-  %0 = tensor.expand_shape %t [[0, 1]] output_shape [4, %sz] : tensor<?xf32> into tensor<4x?xf32>\n+-  %1 = \"test.reify_bound\"(%0) {dim = 0} : (tensor<4x?xf32>) -> (index)\n+-  %2 = \"test.reify_bound\"(%0) {dim = 1} : (tensor<4x?xf32>) -> (index)\n+-  return %1, %2 : index, index\n+-}"
        },
        {
            "sha": "55a1ce3a37fb8df2b5d4680d07e245ce7a7ffba9",
            "filename": "third_party/xla/third_party/llvm/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl?ref=1a2bdc79992dd9563e2468f97b898858502d9380",
            "patch": "@@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n \n def repo(name):\n     \"\"\"Imports LLVM.\"\"\"\n-    LLVM_COMMIT = \"7d381f2a5634d1e41b61299839d652cc4a021898\"\n-    LLVM_SHA256 = \"f1641918fd3f5e1667d39afb9c261da39ed9f74e30f1c2f98031d6d609a8de15\"\n+    LLVM_COMMIT = \"0812f41cd68d63d10a4c3a02271b0ea8276dbe57\"\n+    LLVM_SHA256 = \"c5bbfd7e6accbb4bfbeeb990666aa64654a667c6569366e90aa1f8d8b28dbf8c\"\n \n     tf_http_archive(\n         name = name,"
        },
        {
            "sha": "ae0685ad8a10438c09916e96f7d9377e92ff5f39",
            "filename": "third_party/xla/third_party/shardy/temporary.patch",
            "status": "modified",
            "additions": 1954,
            "deletions": 0,
            "changes": 1954,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch?ref=1a2bdc79992dd9563e2468f97b898858502d9380",
            "patch": "@@ -0,0 +1,1954 @@\n+diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch\n+index f82404c..7972fe3 100644\n+--- a/third_party/llvm/generated.patch\n++++ b/third_party/llvm/generated.patch\n+@@ -1,152 +1,1794 @@\n+ Auto generated patch. Do not edit or delete it, even if empty.\n+-diff -ruN --strip-trailing-cr a/clang/lib/Serialization/ASTReaderDecl.cpp b/clang/lib/Serialization/ASTReaderDecl.cpp\n+---- a/clang/lib/Serialization/ASTReaderDecl.cpp\n+-+++ b/clang/lib/Serialization/ASTReaderDecl.cpp\n+-@@ -2107,8 +2107,9 @@\n+-     auto *Def = DD.Definition;\n+-     DD = std::move(MergeDD);\n+-     DD.Definition = Def;\n+--    for (auto *D : Def->redecls())\n+--      cast<CXXRecordDecl>(D)->DefinitionData = &DD;\n+-+    for (auto *R = Reader.getMostRecentExistingDecl(Def); R;\n+-+         R = R->getPreviousDecl())\n+-+      cast<CXXRecordDecl>(R)->DefinitionData = &DD;\n+-     return;\n+-   }\n++diff -ruN --strip-trailing-cr a/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h b/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\n++--- a/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\n+++++ b/mlir/include/mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\n++@@ -1,122 +0,0 @@\n++-//===- ACCSpecializePatterns.h - Common ACC Specialization Patterns ------===//\n++-//\n++-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n++-// See https://llvm.org/LICENSE.txt for license information.\n++-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n++-//\n++-//===----------------------------------------------------------------------===//\n++-//\n++-// This file contains common rewrite pattern templates used by both\n++-// ACCSpecializeForHost and ACCSpecializeForDevice passes.\n++-//\n++-// The patterns provide the following transformations:\n++-//\n++-// - ACCOpReplaceWithVarConversion<OpTy>: Replaces a data entry operation\n++-//   with its var operand. Used for ops like acc.copyin, acc.create, etc.\n++-//\n++-// - ACCOpEraseConversion<OpTy>: Simply erases an operation. Used for\n++-//   data exit ops like acc.copyout, acc.delete, and runtime ops.\n++-//\n++-// - ACCRegionUnwrapConversion<OpTy>: Inlines the region of an operation\n++-//   and erases the wrapper. Used for structured data constructs\n++-//   (acc.data, acc.host_data) and compute constructs (acc.parallel, etc.)\n++-//\n++-// - ACCDeclareEnterOpConversion: Erases acc.declare_enter and its\n++-//   associated acc.declare_exit operation.\n++-//\n++-//===----------------------------------------------------------------------===//\n++-\n++-#ifndef MLIR_DIALECT_OPENACC_TRANSFORMS_ACCSPECIALIZEPATTERNS_H\n++-#define MLIR_DIALECT_OPENACC_TRANSFORMS_ACCSPECIALIZEPATTERNS_H\n++-\n++-#include \"mlir/Dialect/OpenACC/OpenACC.h\"\n++-#include \"mlir/IR/PatternMatch.h\"\n++-\n++-namespace mlir {\n++-namespace acc {\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Generic pattern templates for ACC specialization\n++-//===----------------------------------------------------------------------===//\n++-\n++-/// Pattern to replace an ACC op with its var operand.\n++-/// Used for data entry ops like acc.copyin, acc.create, acc.attach, etc.\n++-template <typename OpTy>\n++-class ACCOpReplaceWithVarConversion : public OpRewritePattern<OpTy> {\n++-  using OpRewritePattern<OpTy>::OpRewritePattern;\n++-\n++-public:\n++-  LogicalResult matchAndRewrite(OpTy op,\n++-                                PatternRewriter &rewriter) const override {\n++-    // Replace this op with its var operand; it's possible the op has no uses\n++-    // if the op that had previously used it was already converted.\n++-    if (op->use_empty())\n++-      rewriter.eraseOp(op);\n++-    else\n++-      rewriter.replaceOp(op, op.getVar());\n++-    return success();\n++-  }\n++-};\n++-\n++-/// Pattern to simply erase an ACC op (for ops with no results).\n++-/// Used for data exit ops like acc.copyout, acc.delete, acc.detach, etc.\n++-template <typename OpTy>\n++-class ACCOpEraseConversion : public OpRewritePattern<OpTy> {\n++-  using OpRewritePattern<OpTy>::OpRewritePattern;\n++-\n++-public:\n++-  LogicalResult matchAndRewrite(OpTy op,\n++-                                PatternRewriter &rewriter) const override {\n++-    assert(op->getNumResults() == 0 && \"expected op with no results\");\n++-    rewriter.eraseOp(op);\n++-    return success();\n++-  }\n++-};\n++-\n++-/// Pattern to unwrap a region from an ACC op and erase the wrapper.\n++-/// Moves the region's contents to the parent block and removes the wrapper op.\n++-/// Used for structured data constructs (acc.data, acc.host_data,\n++-/// acc.kernel_environment, acc.declare) and compute constructs (acc.parallel,\n++-/// acc.serial, acc.kernels).\n++-template <typename OpTy>\n++-class ACCRegionUnwrapConversion : public OpRewritePattern<OpTy> {\n++-  using OpRewritePattern<OpTy>::OpRewritePattern;\n++-\n++-public:\n++-  LogicalResult matchAndRewrite(OpTy op,\n++-                                PatternRewriter &rewriter) const override {\n++-    assert(op.getRegion().hasOneBlock() && \"expected one block\");\n++-    Block *block = &op.getRegion().front();\n++-    // Erase the terminator (acc.yield or acc.terminator) before unwrapping\n++-    rewriter.eraseOp(block->getTerminator());\n++-    rewriter.inlineBlockBefore(block, op);\n++-    rewriter.eraseOp(op);\n++-    return success();\n++-  }\n++-};\n++-\n++-/// Pattern to erase acc.declare_enter and its associated acc.declare_exit.\n++-/// The declare_enter produces a token that is consumed by declare_exit.\n++-class ACCDeclareEnterOpConversion\n++-    : public OpRewritePattern<acc::DeclareEnterOp> {\n++-  using OpRewritePattern<acc::DeclareEnterOp>::OpRewritePattern;\n++-\n++-public:\n++-  LogicalResult matchAndRewrite(acc::DeclareEnterOp op,\n++-                                PatternRewriter &rewriter) const override {\n++-    // If the enter token is used by an exit, erase exit first.\n++-    if (!op->use_empty()) {\n++-      assert(op->hasOneUse() && \"expected one use\");\n++-      auto exitOp = dyn_cast<acc::DeclareExitOp>(*op->getUsers().begin());\n++-      assert(exitOp && \"expected declare exit op\");\n++-      rewriter.eraseOp(exitOp);\n++-    }\n++-    rewriter.eraseOp(op);\n++-    return success();\n++-  }\n++-};\n++-\n++-} // namespace acc\n++-} // namespace mlir\n++-\n++-#endif // MLIR_DIALECT_OPENACC_TRANSFORMS_ACCSPECIALIZEPATTERNS_H\n++diff -ruN --strip-trailing-cr a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h\n++--- a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h\n+++++ b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.h\n++@@ -12,7 +12,6 @@\n++ #include \"mlir/Dialect/Arith/IR/Arith.h\"\n++ #include \"mlir/Dialect/MemRef/IR/MemRef.h\"\n++ #include \"mlir/Dialect/OpenACC/OpenACC.h\"\n++-#include \"mlir/Dialect/SCF/IR/SCF.h\"\n++ #include \"mlir/Pass/Pass.h\"\n+  \n+-diff -ruN --strip-trailing-cr a/libc/src/__support/FPUtil/x86_64/fenv_mxcsr_utils.h b/libc/src/__support/FPUtil/x86_64/fenv_mxcsr_utils.h\n+---- a/libc/src/__support/FPUtil/x86_64/fenv_mxcsr_utils.h\n+-+++ b/libc/src/__support/FPUtil/x86_64/fenv_mxcsr_utils.h\n+-@@ -61,14 +61,14 @@\n+- LIBC_INLINE static void write_mxcsr(uint32_t w) { _mm_setcsr(w); }\n++ namespace mlir {\n++@@ -23,40 +22,9 @@\n+  \n+- LIBC_INLINE static void clear_except(uint16_t excepts) {\n+--  uint32_t mxcsr = _MM_GET_EXCEPTION_STATE();\n+-+  uint32_t mxcsr = get_mxcsr();\n+-   mxcsr &= ~static_cast<uint32_t>(excepts);\n+--  _MM_SET_EXCEPTION_STATE(mxcsr);\n+-+  write_mxcsr(mxcsr);\n+- }\n++ namespace acc {\n+  \n+- LIBC_INLINE static uint16_t test_except(uint16_t excepts) {\n+-   uint32_t mxcsr = get_mxcsr();\n+--  return static_cast<uint16_t>(excepts & mxcsr);\n+-+  return static_cast<uint16_t>(excepts & ExceptionFlags::ALL_F & mxcsr);\n+- }\n++-class OpenACCSupport;\n++-\n++ #define GEN_PASS_DECL\n++ #include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n+  \n+- LIBC_INLINE static uint16_t get_except() {\n+-@@ -83,9 +83,9 @@\n++-//===----------------------------------------------------------------------===//\n++-// ACCSpecializeForDevice patterns\n++-//===----------------------------------------------------------------------===//\n++-\n++-/// Populates all patterns for device specialization.\n++-/// In specialized device code (such as specialized acc routine), many ACC\n++-/// operations do not make sense because they are host-side constructs. This\n++-/// function adds patterns to remove or transform them.\n++-void populateACCSpecializeForDevicePatterns(RewritePatternSet &patterns);\n++-\n++-//===----------------------------------------------------------------------===//\n++-// ACCSpecializeForHost patterns\n++-//===----------------------------------------------------------------------===//\n++-\n++-/// Populates patterns for converting orphan ACC operations to host.\n++-/// All patterns check that the operation is NOT inside or associated with a\n++-/// compute region before converting.\n++-/// @param enableLoopConversion Whether to convert orphan acc.loop operations.\n++-void populateACCOrphanToHostPatterns(RewritePatternSet &patterns,\n++-                                     OpenACCSupport &accSupport,\n++-                                     bool enableLoopConversion = true);\n++-\n++-/// Populates all patterns for host fallback path (when `if` clause evaluates\n++-/// to false). In this mode, ALL ACC operations should be converted or removed.\n++-/// @param enableLoopConversion Whether to convert orphan acc.loop operations.\n++-void populateACCHostFallbackPatterns(RewritePatternSet &patterns,\n++-                                     OpenACCSupport &accSupport,\n++-                                     bool enableLoopConversion = true);\n++-\n++ /// Generate the code for registering conversion passes.\n++ #define GEN_PASS_REGISTRATION\n++ #include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n++diff -ruN --strip-trailing-cr a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td\n++--- a/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td\n+++++ b/mlir/include/mlir/Dialect/OpenACC/Transforms/Passes.td\n++@@ -194,62 +194,4 @@\n++   ];\n+  }\n+  \n+- LIBC_INLINE static void raise_except(uint16_t excepts) {\n+--  uint32_t mxcsr = _MM_GET_EXCEPTION_STATE();\n+--  mxcsr |= excepts;\n+--  _MM_SET_EXCEPTION_STATE(mxcsr);\n+-+  uint32_t mxcsr = get_mxcsr();\n+-+  mxcsr |= excepts & ExceptionFlags::ALL_F;\n+-+  write_mxcsr(mxcsr);\n+- #ifdef LIBC_TRAP_ON_RAISE_FP_EXCEPT\n+-   // We will try to trigger the SIGFPE if floating point exceptions are not\n+-   // masked.  Since we already set all the floating point exception flags, we\n+-diff -ruN --strip-trailing-cr a/libcxx/include/__flat_map/flat_map.h b/libcxx/include/__flat_map/flat_map.h\n+---- a/libcxx/include/__flat_map/flat_map.h\n+-+++ b/libcxx/include/__flat_map/flat_map.h\n+-@@ -465,13 +465,13 @@\n+-   }\n++-def ACCSpecializeForDevice : Pass<\"acc-specialize-for-device\", \"mlir::func::FuncOp\"> {\n++-  let summary = \"Strip OpenACC constructs inside device code\";\n++-  let description = [{\n++-    In a specialized acc routine or compute construct, many OpenACC operations\n++-    do not make sense because they are host-side constructs. This pass removes\n++-    or transforms these operations appropriately.\n++-\n++-    The following operations are handled:\n++-    - Data entry ops (replaced with var): acc.attach, acc.copyin, acc.create,\n++-      acc.declare_device_resident, acc.declare_link, acc.deviceptr,\n++-      acc.get_deviceptr, acc.nocreate, acc.present, acc.update_device,\n++-      acc.use_device\n++-    - Data exit ops (erased): acc.copyout, acc.delete, acc.detach,\n++-      acc.update_host\n++-    - Structured data (inline region): acc.data, acc.host_data,\n++-      acc.kernel_environment\n++-    - Unstructured data (erased): acc.enter_data, acc.exit_data, acc.update,\n++-      acc.declare_enter, acc.declare_exit\n++-    - Compute constructs (inline region): acc.parallel, acc.serial, acc.kernels\n++-    - Runtime ops (erased): acc.init, acc.shutdown, acc.set, acc.wait\n++-  }];\n++-  let dependentDialects = [\"mlir::acc::OpenACCDialect\"];\n++-}\n++-\n++-def ACCSpecializeForHost : Pass<\"acc-specialize-for-host\", \"mlir::func::FuncOp\"> {\n++-  let summary = \"Convert OpenACC operations for host execution\";\n++-  let description = [{\n++-    This pass converts OpenACC operations to host-compatible representations.\n++-    It serves as a conversion pass that transforms ACC constructs to enable\n++-    execution on the host rather than on accelerator devices.\n++-\n++-    There are two modes of operation:\n++-\n++-    1. Default mode (orphan operations only): Only orphan operations that are\n++-       not allowed outside compute regions are converted. Structured/unstructured\n++-       data constructs, compute constructs, and their associated data operations\n++-       are NOT removed.\n++-\n++-    2. Host fallback mode (enableHostFallback=true): ALL ACC operations within\n++-       the region are converted to host equivalents. This is used when the `if`\n++-       clause evaluates to false at runtime.\n++-\n++-    The following operations are handled:\n++-    - Atomic ops: converted to load/store operations\n++-    - Loop ops: converted to scf.for or scf.execute_region\n++-    - Data entry ops (orphan): replaced with var operand\n++-    - In host fallback mode: all data, compute, and runtime ops are removed\n++-  }];\n++-  let dependentDialects = [\"mlir::acc::OpenACCDialect\",\n++-      \"mlir::scf::SCFDialect\"];\n++-  let options = [\n++-    Option<\"enableHostFallback\", \"enable-host-fallback\", \"bool\", \"false\",\n++-           \"Enable host fallback mode which converts ALL ACC operations, \"\n++-           \"not just orphan operations. Use this when the `if` clause \"\n++-           \"evaluates to false.\">\n++-  ];\n++-}\n++-\n++ #endif // MLIR_DIALECT_OPENACC_TRANSFORMS_PASSES\n++diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp\n++--- a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp\n+++++ b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForDevice.cpp\n++@@ -1,172 +0,0 @@\n++-//===- ACCSpecializeForDevice.cpp -----------------------------------------===//\n++-//\n++-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n++-// See https://llvm.org/LICENSE.txt for license information.\n++-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n++-//\n++-//===----------------------------------------------------------------------===//\n++-//\n++-// This pass strips OpenACC constructs that are invalid or unnecessary inside\n++-// device code (specialized acc routines or compute construct regions).\n++-//\n++-// Overview:\n++-// ---------\n++-// In a specialized acc routine or compute construct, many OpenACC operations\n++-// do not make sense because they are host-side constructs. This pass removes\n++-// or transforms these operations appropriately:\n++-//\n++-// - Data operations that manage device memory from host perspective\n++-// - Compute constructs that launch kernels (we're already on device)\n++-// - Runtime operations like init/shutdown/set/wait\n++-//\n++-// Transformations:\n++-// ----------------\n++-// The pass applies the following transformations:\n++-//\n++-// 1. Data Entry Ops (replaced with var operand):\n++-//    acc.attach, acc.copyin, acc.create, acc.declare_device_resident,\n++-//    acc.declare_link, acc.deviceptr, acc.get_deviceptr, acc.nocreate,\n++-//    acc.present, acc.update_device, acc.use_device\n++-//\n++-// 2. Data Exit Ops (erased):\n++-//    acc.copyout, acc.delete, acc.detach, acc.update_host\n++-//\n++-// 3. Structured Data/Compute Constructs (region inlined):\n++-//    acc.data, acc.host_data, acc.kernel_environment, acc.parallel,\n++-//    acc.serial, acc.kernels\n++-//\n++-// 4. Unstructured Data Ops (erased):\n++-//    acc.enter_data, acc.exit_data, acc.update, acc.declare_enter,\n++-//    acc.declare_exit\n++-//\n++-// 5. Runtime Ops (erased):\n++-//    acc.init, acc.shutdown, acc.set, acc.wait\n++-//\n++-// Scope of Application:\n++-// ---------------------\n++-// - For functions with `acc.specialized_routine` attribute: patterns are\n++-//   applied to the entire function body.\n++-// - For non-specialized functions: patterns are applied only to ACC\n++-//   operations INSIDE compute constructs (parallel, serial, kernels),\n++-//   not to the compute constructs themselves or their data operands.\n++-//\n++-// Note: acc.cache, acc.private, acc.reduction, acc.firstprivate are NOT\n++-// transformed by this pass as they are valid in device code.\n++-//\n++-//===----------------------------------------------------------------------===//\n++-\n++-#include \"mlir/Dialect/OpenACC/Transforms/Passes.h\"\n++-\n++-#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n++-#include \"mlir/Dialect/OpenACC/OpenACC.h\"\n++-#include \"mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\"\n++-#include \"mlir/IR/PatternMatch.h\"\n++-#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n++-\n++-namespace mlir {\n++-namespace acc {\n++-#define GEN_PASS_DEF_ACCSPECIALIZEFORDEVICE\n++-#include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n++-} // namespace acc\n++-} // namespace mlir\n++-\n++-using namespace mlir;\n++-using namespace mlir::acc;\n++-\n++-namespace {\n++-\n++-class ACCSpecializeForDevice\n++-    : public acc::impl::ACCSpecializeForDeviceBase<ACCSpecializeForDevice> {\n++-public:\n++-  using ACCSpecializeForDeviceBase<\n++-      ACCSpecializeForDevice>::ACCSpecializeForDeviceBase;\n++-\n++-  void runOnOperation() override {\n++-    func::FuncOp func = getOperation();\n++-\n++-    RewritePatternSet patterns(&getContext());\n++-    acc::populateACCSpecializeForDevicePatterns(patterns);\n++-    GreedyRewriteConfig config;\n++-    config.setUseTopDownTraversal(true);\n++-\n++-    if (acc::isSpecializedAccRoutine(func)) {\n++-      // For specialized acc routines, apply patterns to the entire function\n++-      (void)applyPatternsGreedily(func, std::move(patterns), config);\n++-    } else {\n++-      // For non-specialized functions, apply patterns only to ACC operations\n++-      // inside compute constructs (not to the compute constructs themselves).\n++-      SmallVector<Operation *> opsToTransform;\n++-      func.walk([&](Operation *op) {\n++-        if (isa<ACC_COMPUTE_CONSTRUCT_OPS>(op)) {\n++-          // Walk inside the compute construct and collect ACC ops\n++-          op->walk([&](Operation *innerOp) {\n++-            // Skip the compute construct itself\n++-            if (innerOp == op)\n++-              return;\n++-            if (isa<acc::OpenACCDialect>(innerOp->getDialect()))\n++-              opsToTransform.push_back(innerOp);\n++-          });\n++-        }\n++-      });\n++-      if (!opsToTransform.empty())\n++-        (void)applyOpPatternsGreedily(opsToTransform, std::move(patterns),\n++-                                      config);\n++-    }\n++-  }\n++-};\n++-\n++-} // namespace\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Pattern population functions\n++-//===----------------------------------------------------------------------===//\n++-\n++-void mlir::acc::populateACCSpecializeForDevicePatterns(\n++-    RewritePatternSet &patterns) {\n++-  MLIRContext *context = patterns.getContext();\n++-\n++-  // Declare patterns - erase declare_enter and its associated declare_exit\n++-  patterns.insert<ACCDeclareEnterOpConversion>(context);\n++-\n++-  // Data entry ops - replaced with their var operand\n++-  // Note: acc.cache, acc.private, acc.reduction, acc.firstprivate are NOT\n++-  // included here - they are valid in device code\n++-  patterns.insert<ACCOpReplaceWithVarConversion<acc::AttachOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::CopyinOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::CreateOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::DeclareDeviceResidentOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::DeclareLinkOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::DevicePtrOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::GetDevicePtrOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::NoCreateOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::PresentOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::UpdateDeviceOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::UseDeviceOp>>(context);\n++-\n++-  // Data exit ops - simply erased (no results)\n++-  patterns.insert<ACCOpEraseConversion<acc::CopyoutOp>,\n++-                  ACCOpEraseConversion<acc::DeleteOp>,\n++-                  ACCOpEraseConversion<acc::DetachOp>,\n++-                  ACCOpEraseConversion<acc::UpdateHostOp>>(context);\n++-\n++-  // Structured data constructs - unwrap their regions\n++-  patterns.insert<ACCRegionUnwrapConversion<acc::DataOp>,\n++-                  ACCRegionUnwrapConversion<acc::HostDataOp>,\n++-                  ACCRegionUnwrapConversion<acc::KernelEnvironmentOp>>(context);\n++-\n++-  // Compute constructs - unwrap their regions\n++-  patterns.insert<ACCRegionUnwrapConversion<acc::ParallelOp>,\n++-                  ACCRegionUnwrapConversion<acc::SerialOp>,\n++-                  ACCRegionUnwrapConversion<acc::KernelsOp>>(context);\n++-\n++-  // Unstructured data operations - erase them\n++-  patterns.insert<ACCOpEraseConversion<acc::EnterDataOp>,\n++-                  ACCOpEraseConversion<acc::ExitDataOp>,\n++-                  ACCOpEraseConversion<acc::UpdateOp>>(context);\n++-\n++-  // Runtime operations - erase them\n++-  patterns.insert<\n++-      ACCOpEraseConversion<acc::InitOp>, ACCOpEraseConversion<acc::ShutdownOp>,\n++-      ACCOpEraseConversion<acc::SetOp>, ACCOpEraseConversion<acc::WaitOp>>(\n++-      context);\n++-}\n++diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp\n++--- a/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp\n+++++ b/mlir/lib/Dialect/OpenACC/Transforms/ACCSpecializeForHost.cpp\n++@@ -1,471 +0,0 @@\n++-//===- ACCSpecializeForHost.cpp -------------------------------------------===//\n++-//\n++-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n++-// See https://llvm.org/LICENSE.txt for license information.\n++-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n++-//\n++-//===----------------------------------------------------------------------===//\n++-//\n++-// This pass converts OpenACC operations to host-compatible representations,\n++-// enabling execution on the host rather than on accelerator devices.\n++-//\n++-// Overview:\n++-// ---------\n++-// The pass operates in two modes depending on the `enableHostFallback` option:\n++-//\n++-// 1. Default Mode (Orphan Operations Only):\n++-//    Only converts \"orphan\" ACC operations that are not inside or attached to\n++-//    compute regions. This is used for host routines (acc routine marked for\n++-//    host) where structured/unstructured data constructs, compute constructs,\n++-//    and their associated data operations should be preserved.\n++-//\n++-// 2. Host Fallback Mode (enableHostFallback=true):\n++-//    Converts ALL ACC operations within the region to host equivalents. This\n++-//    is used when the `if` clause evaluates to false at runtime and the\n++-//    entire ACC region needs to fall back to host execution.\n++-//\n++-// Transformations (Orphan Mode):\n++-// ------------------------------\n++-// The following orphan operations are converted:\n++-//\n++-// 1. Atomic Ops (converted to load/store):\n++-//    acc.atomic.update -> load + compute + store\n++-//    acc.atomic.read -> load + store (copy)\n++-//    acc.atomic.write -> store\n++-//    acc.atomic.capture -> inline region contents\n++-//\n++-// 2. Loop Ops (converted to SCF):\n++-//    acc.loop (structured) -> scf.for\n++-//    acc.loop (unstructured) -> scf.execute_region\n++-//\n++-// 3. Orphan Data Entry Ops (replaced with var operand):\n++-//    acc.cache, acc.private, acc.firstprivate, acc.reduction\n++-//    (only if NOT connected to compute constructs or loop)\n++-//\n++-// Transformations (Host Fallback Mode):\n++-// -------------------------------------\n++-// In addition to orphan transformations, ALL of the following are converted:\n++-//\n++-// 1. Data Entry Ops (replaced with var operand):\n++-//    acc.copyin, acc.create, acc.attach, acc.present, acc.deviceptr,\n++-//    acc.get_deviceptr, acc.nocreate, acc.declare_device_resident,\n++-//    acc.declare_link, acc.use_device, acc.update_device\n++-//\n++-// 2. Data Exit Ops (erased):\n++-//    acc.copyout, acc.delete, acc.detach, acc.update_host\n++-//\n++-// 3. Structured Data/Compute Constructs (region inlined):\n++-//    acc.data, acc.host_data, acc.kernel_environment, acc.declare,\n++-//    acc.parallel, acc.serial, acc.kernels\n++-//\n++-// 4. Unstructured Data Ops (erased):\n++-//    acc.enter_data, acc.exit_data, acc.update\n++-//\n++-// 5. Declare Ops (erased):\n++-//    acc.declare_enter, acc.declare_exit\n++-//\n++-// 6. Runtime Ops (erased):\n++-//    acc.init, acc.shutdown, acc.set, acc.wait, acc.terminator\n++-//\n++-// Requirements:\n++-// -------------\n++-// For atomic operation conversion, variables must implement the\n++-// `acc::PointerLikeType` interface to enable generating load/store operations.\n++-//\n++-// The pass uses `OpenACCSupport::emitNYI()` to report unsupported cases.\n++-//\n++-//===----------------------------------------------------------------------===//\n++-\n++-#include \"mlir/Dialect/OpenACC/Transforms/Passes.h\"\n++-\n++-#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n++-#include \"mlir/Dialect/OpenACC/Analysis/OpenACCSupport.h\"\n++-#include \"mlir/Dialect/OpenACC/OpenACC.h\"\n++-#include \"mlir/Dialect/OpenACC/OpenACCUtilsLoop.h\"\n++-#include \"mlir/Dialect/OpenACC/Transforms/ACCSpecializePatterns.h\"\n++-#include \"mlir/IR/BuiltinAttributes.h\"\n++-#include \"mlir/IR/BuiltinOps.h\"\n++-#include \"mlir/IR/BuiltinTypes.h\"\n++-#include \"mlir/IR/Operation.h\"\n++-#include \"mlir/IR/PatternMatch.h\"\n++-#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n++-\n++-namespace mlir {\n++-namespace acc {\n++-#define GEN_PASS_DEF_ACCSPECIALIZEFORHOST\n++-#include \"mlir/Dialect/OpenACC/Transforms/Passes.h.inc\"\n++-} // namespace acc\n++-} // namespace mlir\n++-\n++-#define DEBUG_TYPE \"acc-specialize-for-host\"\n++-\n++-using namespace mlir;\n++-using namespace mlir::acc;\n++-\n++-/// Check if an operation is inside an ACC compute construct.\n++-static bool isInsideACCComputeConstruct(Operation *op) {\n++-  while ((op = op->getParentOp()))\n++-    if (isa<ACC_COMPUTE_CONSTRUCT_OPS>(op))\n++-      return true;\n++-  return false;\n++-}\n++-\n++-namespace {\n++-\n++-// Lower orphan acc.atomic.update by: load from addr, clone region expr with\n++-// the loaded value, then store the computed result back to addr.\n++-// Only matches if NOT inside a compute region.\n++-class ACCOrphanAtomicUpdateOpConversion\n++-    : public OpRewritePattern<acc::AtomicUpdateOp> {\n++-public:\n++-  ACCOrphanAtomicUpdateOpConversion(MLIRContext *ctx, OpenACCSupport &support)\n++-      : OpRewritePattern<acc::AtomicUpdateOp>(ctx), accSupport(support) {}\n++-\n++-  LogicalResult matchAndRewrite(acc::AtomicUpdateOp atomicUpdateOp,\n++-                                PatternRewriter &rewriter) const override {\n++-    // Only convert if this op is not inside an ACC compute construct\n++-    if (isInsideACCComputeConstruct(atomicUpdateOp))\n++-      return failure();\n++-\n++-    Value x = atomicUpdateOp.getX();\n++-    Type type = x.getType();\n++-    auto ptrLikeType = dyn_cast<acc::PointerLikeType>(type);\n++-    if (ptrLikeType) {\n++-      auto xTyped = cast<TypedValue<acc::PointerLikeType>>(x);\n++-      rewriter.setInsertionPointAfter(atomicUpdateOp);\n++-      Value loadOp =\n++-          ptrLikeType.genLoad(rewriter, atomicUpdateOp.getLoc(), xTyped, {});\n++-      if (!loadOp) {\n++-        accSupport.emitNYI(atomicUpdateOp.getLoc(),\n++-                           \"failed to generate load for atomic update\");\n++-        return failure();\n++-      }\n++-      IRMapping mapping;\n++-      mapping.map(atomicUpdateOp.getRegion().front().getArgument(0), loadOp);\n++-      Operation *expr = rewriter.clone(*atomicUpdateOp.getFirstOp(), mapping);\n++-      if (!ptrLikeType.genStore(rewriter, atomicUpdateOp.getLoc(),\n++-                                expr->getResult(0), xTyped)) {\n++-        accSupport.emitNYI(atomicUpdateOp.getLoc(),\n++-                           \"failed to generate store for atomic update\");\n++-        return failure();\n++-      }\n++-      rewriter.eraseOp(atomicUpdateOp);\n++-    } else {\n++-      accSupport.emitNYI(atomicUpdateOp.getLoc(),\n++-                         \"unsupported type for atomic update\");\n++-      return failure();\n++-    }\n++-    return success();\n++-  }\n++-\n++-private:\n++-  OpenACCSupport &accSupport;\n++-};\n++-\n++-// Lower orphan acc.atomic.read by: load from src, then store into dst.\n++-// Only matches if NOT inside an ACC compute construct.\n++-class ACCOrphanAtomicReadOpConversion\n++-    : public OpRewritePattern<acc::AtomicReadOp> {\n++-public:\n++-  ACCOrphanAtomicReadOpConversion(MLIRContext *ctx, OpenACCSupport &support)\n++-      : OpRewritePattern<acc::AtomicReadOp>(ctx), accSupport(support) {}\n++-\n++-  LogicalResult matchAndRewrite(acc::AtomicReadOp readOp,\n++-                                PatternRewriter &rewriter) const override {\n++-    // Only convert if this op is not inside an ACC compute construct\n++-    if (isInsideACCComputeConstruct(readOp))\n++-      return failure();\n++-\n++-    Value x = readOp.getX();\n++-    Value v = readOp.getV();\n++-    auto xPtrType = dyn_cast<acc::PointerLikeType>(x.getType());\n++-    auto vPtrType = dyn_cast<acc::PointerLikeType>(v.getType());\n++-    if (xPtrType && vPtrType) {\n++-      auto xTyped = cast<TypedValue<acc::PointerLikeType>>(x);\n++-      auto vTyped = cast<TypedValue<acc::PointerLikeType>>(v);\n++-      rewriter.setInsertionPointAfter(readOp);\n++-\n++-      // Use genCopy which does load + store\n++-      if (!xPtrType.genCopy(rewriter, readOp.getLoc(), vTyped, xTyped, {})) {\n++-        accSupport.emitNYI(readOp.getLoc(),\n++-                           \"failed to generate copy for atomic read\");\n++-        return failure();\n++-      }\n++-      rewriter.eraseOp(readOp);\n++-    } else {\n++-      accSupport.emitNYI(readOp.getLoc(), \"unsupported type for atomic read\");\n++-      return failure();\n++-    }\n++-    return success();\n++-  }\n++-\n++-private:\n++-  OpenACCSupport &accSupport;\n++-};\n++-\n++-// Lower orphan acc.atomic.write by: store value into addr.\n++-// Only matches if NOT inside an ACC compute construct.\n++-class ACCOrphanAtomicWriteOpConversion\n++-    : public OpRewritePattern<acc::AtomicWriteOp> {\n++-public:\n++-  ACCOrphanAtomicWriteOpConversion(MLIRContext *ctx, OpenACCSupport &support)\n++-      : OpRewritePattern<acc::AtomicWriteOp>(ctx), accSupport(support) {}\n++-\n++-  LogicalResult matchAndRewrite(acc::AtomicWriteOp writeOp,\n++-                                PatternRewriter &rewriter) const override {\n++-    // Only convert if this op is not inside an ACC compute construct\n++-    if (isInsideACCComputeConstruct(writeOp))\n++-      return failure();\n++-\n++-    Value x = writeOp.getX();\n++-    Value expr = writeOp.getExpr();\n++-    auto ptrLikeType = dyn_cast<acc::PointerLikeType>(x.getType());\n++-    if (ptrLikeType) {\n++-      auto xTyped = cast<TypedValue<acc::PointerLikeType>>(x);\n++-      rewriter.setInsertionPointAfter(writeOp);\n++-      if (!ptrLikeType.genStore(rewriter, writeOp.getLoc(), expr, xTyped)) {\n++-        accSupport.emitNYI(writeOp.getLoc(),\n++-                           \"failed to generate store for atomic write\");\n++-        return failure();\n++-      }\n++-      rewriter.eraseOp(writeOp);\n++-    } else {\n++-      accSupport.emitNYI(writeOp.getLoc(), \"unsupported type for atomic write\");\n++-      return failure();\n++-    }\n++-    return success();\n++-  }\n++-\n++-private:\n++-  OpenACCSupport &accSupport;\n++-};\n++-\n++-// Lower orphan acc.atomic.capture by: unwrap the capture region and erase the\n++-// wrapper; inner ops are lowered in-order (e.g., read+update becomes load/store\n++-// to dst then load/compute/store to addr).\n++-// Only matches if NOT inside an ACC compute construct.\n++-class ACCOrphanAtomicCaptureOpConversion\n++-    : public OpRewritePattern<acc::AtomicCaptureOp> {\n++-  using OpRewritePattern<acc::AtomicCaptureOp>::OpRewritePattern;\n++-\n++-  LogicalResult matchAndRewrite(acc::AtomicCaptureOp captureOp,\n++-                                PatternRewriter &rewriter) const override {\n++-    // Only convert if this op is not inside an ACC compute construct\n++-    if (isInsideACCComputeConstruct(captureOp))\n++-      return failure();\n++-\n++-    assert(captureOp.getRegion().hasOneBlock() && \"expected one block\");\n++-    Block *block = &captureOp.getRegion().front();\n++-    // Remove the terminator before inlining\n++-    rewriter.eraseOp(block->getTerminator());\n++-    rewriter.inlineBlockBefore(block, captureOp);\n++-    rewriter.eraseOp(captureOp);\n++-    return success();\n++-  }\n++-};\n++-\n++-// Convert orphan acc.loop to scf.for or scf.execute_region.\n++-// Only matches if NOT inside an ACC compute construct.\n++-class ACCOrphanLoopOpConversion : public OpRewritePattern<acc::LoopOp> {\n++-  using OpRewritePattern<acc::LoopOp>::OpRewritePattern;\n++-\n++-  LogicalResult matchAndRewrite(acc::LoopOp loopOp,\n++-                                PatternRewriter &rewriter) const override {\n++-    // Only convert if this op is not inside an ACC compute construct\n++-    if (isInsideACCComputeConstruct(loopOp))\n++-      return failure();\n++-\n++-    if (loopOp.getUnstructured()) {\n++-      auto executeRegion =\n++-          acc::convertUnstructuredACCLoopToSCFExecuteRegion(loopOp, rewriter);\n++-      if (!executeRegion)\n++-        return failure();\n++-      rewriter.replaceOp(loopOp, executeRegion);\n++-    } else {\n++-      auto forOp =\n++-          acc::convertACCLoopToSCFFor(loopOp, /*enableCollapse=*/false);\n++-      if (!forOp)\n++-        return failure();\n++-      rewriter.replaceOp(loopOp, forOp);\n++-    }\n++-    return success();\n++-  }\n++-};\n++-\n++-/// Check if an operation is used by a compute construct or loop op\n++-static bool isUsedByComputeOrLoop(Operation *op) {\n++-  for (auto *user : op->getUsers())\n++-    if (isa<acc::ParallelOp, acc::SerialOp, acc::KernelsOp, acc::LoopOp>(user))\n++-      return true;\n++-  return false;\n++-}\n++-\n++-/// Orphan data entry ops - only match if NOT connected to compute/loop and\n++-/// NOT inside a compute region. Used for acc.cache, acc.private,\n++-/// acc.firstprivate, acc.reduction.\n++-template <typename OpTy>\n++-class ACCOrphanDataEntryConversion : public OpRewritePattern<OpTy> {\n++-  using OpRewritePattern<OpTy>::OpRewritePattern;\n++-\n++-  LogicalResult matchAndRewrite(OpTy op,\n++-                                PatternRewriter &rewriter) const override {\n++-    // Only convert if this op is not used by a compute construct or loop,\n++-    // and not inside an ACC compute construct.\n++-    if (isUsedByComputeOrLoop(op) || isInsideACCComputeConstruct(op))\n++-      return failure();\n++-\n++-    if (op->use_empty())\n++-      rewriter.eraseOp(op);\n++-    else\n++-      rewriter.replaceOp(op, op.getVar());\n++-    return success();\n++-  }\n++-};\n++-\n++-class ACCSpecializeForHost\n++-    : public acc::impl::ACCSpecializeForHostBase<ACCSpecializeForHost> {\n++-public:\n++-  using ACCSpecializeForHostBase<\n++-      ACCSpecializeForHost>::ACCSpecializeForHostBase;\n++-\n++-  void runOnOperation() override {\n++-    LLVM_DEBUG(llvm::dbgs() << \"Enter ACCSpecializeForHost()\\n\");\n++-\n++-    func::FuncOp funcOp = getOperation();\n++-    if (!acc::isSpecializedAccRoutine(funcOp)) {\n++-      // Convert orphan operations to host, or all ACC operations if\n++-      // host fallback patterns are enabled.\n++-      auto *context = &getContext();\n++-      RewritePatternSet patterns(context);\n++-      OpenACCSupport &accSupport = getAnalysis<OpenACCSupport>();\n++-      if (enableHostFallback)\n++-        populateACCHostFallbackPatterns(patterns, accSupport);\n++-      else\n++-        populateACCOrphanToHostPatterns(patterns, accSupport);\n++-      GreedyRewriteConfig config;\n++-      config.setUseTopDownTraversal(true);\n++-      if (failed(applyPatternsGreedily(funcOp, std::move(patterns), config)))\n++-        signalPassFailure();\n++-    }\n++-\n++-    LLVM_DEBUG(llvm::dbgs() << \"Exit ACCSpecializeForHost()\\n\");\n++-  }\n++-};\n++-} // namespace\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Pattern population functions\n++-//===----------------------------------------------------------------------===//\n++-\n++-void mlir::acc::populateACCOrphanToHostPatterns(RewritePatternSet &patterns,\n++-                                                OpenACCSupport &accSupport,\n++-                                                bool enableLoopConversion) {\n++-  MLIRContext *context = patterns.getContext();\n++-\n++-  // For host routines (acc routine marked for host), we only convert orphan\n++-  // operations that are not allowed outside compute regions. All patterns\n++-  // here check that the operation is NOT inside a compute region before\n++-  // converting:\n++-  // - acc.atomic.* -> load/store operations\n++-  // - acc.loop -> scf.for or scf.execute_region\n++-  // - acc.cache -> replaced with var\n++-  // - acc.private, acc.reduction, acc.firstprivate -> replaced with var\n++-  //   (only if NOT connected to compute constructs or loop)\n++-  //\n++-  // We do NOT remove structured/unstructured data constructs, compute\n++-  // constructs, or their associated data operations - those are valid\n++-  // in host routines and will be processed by other passes.\n++-\n++-  // Loop conversion (orphan only)\n++-  if (enableLoopConversion)\n++-    patterns.insert<ACCOrphanLoopOpConversion>(context);\n++-\n++-  // Atomic operations - convert to non-atomic load/store (orphan only)\n++-  patterns.insert<ACCOrphanAtomicUpdateOpConversion>(context, accSupport);\n++-  patterns.insert<ACCOrphanAtomicReadOpConversion>(context, accSupport);\n++-  patterns.insert<ACCOrphanAtomicWriteOpConversion>(context, accSupport);\n++-  patterns.insert<ACCOrphanAtomicCaptureOpConversion>(context);\n++-\n++-  // Orphan data entry ops - only convert if NOT connected to compute/loop\n++-  // and NOT inside a compute region\n++-  patterns.insert<ACCOrphanDataEntryConversion<acc::CacheOp>,\n++-                  ACCOrphanDataEntryConversion<acc::PrivateOp>,\n++-                  ACCOrphanDataEntryConversion<acc::FirstprivateOp>,\n++-                  ACCOrphanDataEntryConversion<acc::ReductionOp>>(context);\n++-}\n++-\n++-void mlir::acc::populateACCHostFallbackPatterns(RewritePatternSet &patterns,\n++-                                                OpenACCSupport &accSupport,\n++-                                                bool enableLoopConversion) {\n++-  MLIRContext *context = patterns.getContext();\n++-\n++-  // For host fallback path (when `if` clause evaluates to false), ALL ACC\n++-  // operations within the region should be converted to host equivalents.\n++-  // This includes structured/unstructured data, compute constructs, and\n++-  // their associated data operations.\n++-\n++-  // Loop conversion - OK to use the orphan loop conversion pattern here\n++-  // because the parent compute constructs will also be converted.\n++-  if (enableLoopConversion)\n++-    patterns.insert<ACCOrphanLoopOpConversion>(context);\n++-\n++-  // Atomic operations - convert to non-atomic load/store. OK to use the orphan\n++-  // atomic conversion patterns here because the parent compute constructs will\n++-  // also be converted.\n++-  patterns.insert<ACCOrphanAtomicUpdateOpConversion>(context, accSupport);\n++-  patterns.insert<ACCOrphanAtomicReadOpConversion>(context, accSupport);\n++-  patterns.insert<ACCOrphanAtomicWriteOpConversion>(context, accSupport);\n++-  patterns.insert<ACCOrphanAtomicCaptureOpConversion>(context);\n++-\n++-  // acc.cache - convert ALL cache ops (including those inside compute regions)\n++-  patterns.insert<ACCOpReplaceWithVarConversion<acc::CacheOp>>(context);\n++-\n++-  // Privatization ops - convert ALL (including those attached to compute/loop)\n++-  patterns.insert<ACCOpReplaceWithVarConversion<acc::PrivateOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::FirstprivateOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::ReductionOp>>(context);\n++-\n++-  // Data entry ops - replaced with their var operand\n++-  patterns.insert<ACCOpReplaceWithVarConversion<acc::CopyinOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::CreateOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::AttachOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::PresentOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::DevicePtrOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::GetDevicePtrOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::NoCreateOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::DeclareDeviceResidentOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::DeclareLinkOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::UseDeviceOp>,\n++-                  ACCOpReplaceWithVarConversion<acc::UpdateDeviceOp>>(context);\n++-\n++-  // Data exit ops - simply erased (no results)\n++-  patterns.insert<ACCOpEraseConversion<acc::CopyoutOp>,\n++-                  ACCOpEraseConversion<acc::DeleteOp>,\n++-                  ACCOpEraseConversion<acc::DetachOp>,\n++-                  ACCOpEraseConversion<acc::UpdateHostOp>>(context);\n++-\n++-  // Structured data constructs - unwrap their regions\n++-  patterns.insert<ACCRegionUnwrapConversion<acc::DataOp>,\n++-                  ACCRegionUnwrapConversion<acc::HostDataOp>,\n++-                  ACCRegionUnwrapConversion<acc::KernelEnvironmentOp>>(context);\n++-\n++-  // Declare ops\n++-  patterns.insert<ACCDeclareEnterOpConversion,\n++-                  ACCRegionUnwrapConversion<acc::DeclareOp>>(context);\n++-\n++-  // Unstructured data operations - erase them\n++-  patterns.insert<ACCOpEraseConversion<acc::EnterDataOp>,\n++-                  ACCOpEraseConversion<acc::ExitDataOp>,\n++-                  ACCOpEraseConversion<acc::UpdateOp>>(context);\n++-\n++-  // Runtime operations - erase them\n++-  patterns.insert<\n++-      ACCOpEraseConversion<acc::InitOp>, ACCOpEraseConversion<acc::ShutdownOp>,\n++-      ACCOpEraseConversion<acc::SetOp>, ACCOpEraseConversion<acc::WaitOp>,\n++-      ACCOpEraseConversion<acc::TerminatorOp>>(context);\n++-\n++-  // Compute constructs - unwrap their regions\n++-  patterns.insert<ACCRegionUnwrapConversion<acc::ParallelOp>,\n++-                  ACCRegionUnwrapConversion<acc::SerialOp>,\n++-                  ACCRegionUnwrapConversion<acc::KernelsOp>>(context);\n++-}\n++diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt b/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt\n++--- a/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt\n+++++ b/mlir/lib/Dialect/OpenACC/Transforms/CMakeLists.txt\n++@@ -4,8 +4,6 @@\n++   ACCImplicitDeclare.cpp\n++   ACCImplicitRoutine.cpp\n++   ACCLegalizeSerial.cpp\n++-  ACCSpecializeForDevice.cpp\n++-  ACCSpecializeForHost.cpp\n++   LegalizeDataValues.cpp\n+  \n+-   // [flat.map.access], element access\n+--  [[nodiscard]] _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](const key_type& __x)\n+-+  _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](const key_type& __x)\n+-     requires is_constructible_v<mapped_type>\n+-   {\n+-     return try_emplace(__x).first->second;\n++   ADDITIONAL_HEADER_DIRS\n++@@ -28,7 +26,6 @@\n++   MLIRFuncDialect\n++   MLIRIR\n++   MLIRPass\n++-  MLIRSCFDialect\n++   MLIRSupport\n++   MLIRTransforms\n++ )\n++diff -ruN --strip-trailing-cr a/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp b/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp\n++--- a/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp\n+++++ b/mlir/lib/Dialect/Tensor/IR/ValueBoundsOpInterfaceImpl.cpp\n++@@ -31,27 +31,6 @@\n+    }\n++ };\n+  \n+--  [[nodiscard]] _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](key_type&& __x)\n+-+  _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](key_type&& __x)\n+-     requires is_constructible_v<mapped_type>\n+-   {\n+-     return try_emplace(std::move(__x)).first->second;\n+-@@ -480,7 +480,7 @@\n+-   template <class _Kp>\n+-     requires(__is_compare_transparent && is_constructible_v<key_type, _Kp> && is_constructible_v<mapped_type> &&\n+-              !is_convertible_v<_Kp &&, const_iterator> && !is_convertible_v<_Kp &&, iterator>)\n+--  [[nodiscard]] _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](_Kp&& __x) {\n+-+  _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX26 mapped_type& operator[](_Kp&& __x) {\n+-     return try_emplace(std::forward<_Kp>(__x)).first->second;\n++-struct CollapseShapeOpInterface\n++-    : public ValueBoundsOpInterface::ExternalModel<CollapseShapeOpInterface,\n++-                                                   CollapseShapeOp> {\n++-  void populateBoundsForShapedValueDim(Operation *op, Value value, int64_t dim,\n++-                                       ValueBoundsConstraintSet &cstr) const {\n++-    auto collapseOp = cast<CollapseShapeOp>(op);\n++-    assert(value == collapseOp.getResult() && \"invalid value\");\n++-\n++-    // Multiply the expressions for the dimensions in the reassociation group.\n++-    const ReassociationIndices &reassocIndices =\n++-        collapseOp.getReassociationIndices()[dim];\n++-    AffineExpr productExpr =\n++-        cstr.getExpr(collapseOp.getSrc(), reassocIndices[0]);\n++-    for (size_t i = 1; i < reassocIndices.size(); ++i) {\n++-      productExpr =\n++-          productExpr * cstr.getExpr(collapseOp.getSrc(), reassocIndices[i]);\n++-    }\n++-    cstr.bound(value)[dim] == productExpr;\n++-  }\n++-};\n++-\n++ struct DimOpInterface\n++     : public ValueBoundsOpInterface::ExternalModel<DimOpInterface, DimOp> {\n++   void populateBoundsForIndexValue(Operation *op, Value value,\n++@@ -78,17 +57,6 @@\n+    }\n++ };\n+  \n+-diff -ruN --strip-trailing-cr a/libcxx/include/map b/libcxx/include/map\n+---- a/libcxx/include/map\n+-+++ b/libcxx/include/map\n+-@@ -1092,9 +1092,9 @@\n+-   [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI size_type size() const _NOEXCEPT { return __tree_.size(); }\n+-   [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI size_type max_size() const _NOEXCEPT { return __tree_.max_size(); }\n+- \n+--  [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](const key_type& __k);\n+-+  _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](const key_type& __k);\n+- #  ifndef _LIBCPP_CXX03_LANG\n+--  [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](key_type&& __k);\n+-+  _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](key_type&& __k);\n+- #  endif\n+- \n+-   template <class _Arg,\n+-diff -ruN --strip-trailing-cr a/libcxx/include/unordered_map b/libcxx/include/unordered_map\n+---- a/libcxx/include/unordered_map\n+-+++ b/libcxx/include/unordered_map\n+-@@ -1262,9 +1262,9 @@\n+-   }\n+- #  endif // _LIBCPP_STD_VER >= 20\n+- \n+--  [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](const key_type& __k);\n+-+  _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](const key_type& __k);\n+- #  ifndef _LIBCPP_CXX03_LANG\n+--  [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](key_type&& __k);\n+-+  _LIBCPP_HIDE_FROM_ABI mapped_type& operator[](key_type&& __k);\n+- #  endif\n+- \n+-   [[__nodiscard__]] _LIBCPP_HIDE_FROM_ABI mapped_type& at(const key_type& __k);\n+-diff -ruN --strip-trailing-cr a/libcxx/test/libcxx/diagnostics/flat_map.nodiscard.verify.cpp b/libcxx/test/libcxx/diagnostics/flat_map.nodiscard.verify.cpp\n+---- a/libcxx/test/libcxx/diagnostics/flat_map.nodiscard.verify.cpp\n+-+++ b/libcxx/test/libcxx/diagnostics/flat_map.nodiscard.verify.cpp\n+-@@ -66,9 +66,9 @@\n+-   TransparentKey<int> tkey;\n+- \n+-   std::flat_map<int, int> nfm;\n+--  nfm[key];            // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+--  fm[std::move(key)];  // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+--  fm[std::move(tkey)]; // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+-+  nfm[key];            // no-warning\n+-+  fm[std::move(key)];  // no-warning\n+-+  fm[std::move(tkey)]; // no-warning\n+- \n+-   fm.at(key);   // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+-   cfm.at(key);  // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+-diff -ruN --strip-trailing-cr a/libcxx/test/libcxx/diagnostics/map.nodiscard.verify.cpp b/libcxx/test/libcxx/diagnostics/map.nodiscard.verify.cpp\n+---- a/libcxx/test/libcxx/diagnostics/map.nodiscard.verify.cpp\n+-+++ b/libcxx/test/libcxx/diagnostics/map.nodiscard.verify.cpp\n+-@@ -55,8 +55,8 @@\n+- \n+-   int key = 0;\n+- \n+--  m[key];            // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+--  m[std::move(key)]; // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+-+  m[key];            // no-warning\n+-+  m[std::move(key)]; // no-warning\n+- \n+- #if TEST_STD_VER >= 14\n+-   std::map<std::string, int, std::less<>> strMap;\n+-diff -ruN --strip-trailing-cr a/libcxx/test/libcxx/diagnostics/unordered_map.nodiscard.verify.cpp b/libcxx/test/libcxx/diagnostics/unordered_map.nodiscard.verify.cpp\n+---- a/libcxx/test/libcxx/diagnostics/unordered_map.nodiscard.verify.cpp\n+-+++ b/libcxx/test/libcxx/diagnostics/unordered_map.nodiscard.verify.cpp\n+-@@ -81,8 +81,8 @@\n+-   ctm.equal_range(tkey); // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+- #endif\n+- \n+--  m[key];            // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+--  m[std::move(key)]; // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+-+  m[key];            // no-warning\n+-+  m[std::move(key)]; // no-warning\n+- \n+-   m.at(key);  // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n+-   cm.at(key); // expected-warning {{ignoring return value of function declared with 'nodiscard' attribute}}\n++-struct ExpandShapeOpInterface\n++-    : public ValueBoundsOpInterface::ExternalModel<ExpandShapeOpInterface,\n++-                                                   ExpandShapeOp> {\n++-  void populateBoundsForShapedValueDim(Operation *op, Value value, int64_t dim,\n++-                                       ValueBoundsConstraintSet &cstr) const {\n++-    auto expandOp = cast<ExpandShapeOp>(op);\n++-    assert(value == expandOp.getResult() && \"invalid value\");\n++-    cstr.bound(value)[dim] == expandOp.getMixedOutputShape()[dim];\n++-  }\n++-};\n++-\n++ struct ExtractSliceOpInterface\n++     : public ValueBoundsOpInterface::ExternalModel<ExtractSliceOpInterface,\n++                                                    ExtractSliceOp> {\n++@@ -149,12 +117,8 @@\n++     DialectRegistry &registry) {\n++   registry.addExtension(+[](MLIRContext *ctx, tensor::TensorDialect *dialect) {\n++     tensor::CastOp::attachInterface<tensor::CastOpInterface>(*ctx);\n++-    tensor::CollapseShapeOp::attachInterface<tensor::CollapseShapeOpInterface>(\n++-        *ctx);\n++     tensor::DimOp::attachInterface<tensor::DimOpInterface>(*ctx);\n++     tensor::EmptyOp::attachInterface<tensor::EmptyOpInterface>(*ctx);\n++-    tensor::ExpandShapeOp::attachInterface<tensor::ExpandShapeOpInterface>(\n++-        *ctx);\n++     tensor::ExtractSliceOp::attachInterface<tensor::ExtractSliceOpInterface>(\n++         *ctx);\n++     tensor::PadOp::attachInterface<tensor::PadOpInterface>(*ctx);\n++diff -ruN --strip-trailing-cr a/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir b/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir\n++--- a/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir\n+++++ b/mlir/test/Dialect/OpenACC/acc-specialize-for-device.mlir\n++@@ -1,204 +0,0 @@\n++-// RUN: mlir-opt %s -acc-specialize-for-device | FileCheck %s\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Data entry ops in specialized routines\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_0 func(@attach) seq\n++-// CHECK-LABEL: func.func @attach\n++-// CHECK-NOT:   acc.attach\n++-func.func @attach(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_0, <seq>, \"attach\">} {\n++-  %c0 = arith.constant 0 : i32\n++-  %0 = acc.attach varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  memref.store %c0, %0[] : memref<i32>\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_1 func(@copyin) seq\n++-// CHECK-LABEL: func.func @copyin\n++-// CHECK-NOT:   acc.copyin\n++-func.func @copyin(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_1, <seq>, \"copyin\">} {\n++-  %c0 = arith.constant 0 : i32\n++-  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  memref.store %c0, %0[] : memref<i32>\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_2 func(@create) seq\n++-// CHECK-LABEL: func.func @create\n++-// CHECK-NOT:   acc.create\n++-func.func @create(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_2, <seq>, \"create\">} {\n++-  %c0 = arith.constant 0 : i32\n++-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  memref.store %c0, %0[] : memref<i32>\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_3 func(@present) seq\n++-// CHECK-LABEL: func.func @present\n++-// CHECK-NOT:   acc.present\n++-func.func @present(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_3, <seq>, \"present\">} {\n++-  %c0 = arith.constant 0 : i32\n++-  %0 = acc.present varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  memref.store %c0, %0[] : memref<i32>\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Data entry ops INSIDE compute constructs (non-specialized functions)\n++-//===----------------------------------------------------------------------===//\n++-\n++-// CHECK-LABEL: func.func @copyin_inside_parallel\n++-// CHECK:       acc.parallel\n++-// CHECK-NOT:   acc.copyin\n++-// CHECK:       acc.yield\n++-func.func @copyin_inside_parallel(%arg0 : memref<i32>) {\n++-  %c0 = arith.constant 0 : i32\n++-  acc.parallel {\n++-    %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-    memref.store %c0, %0[] : memref<i32>\n++-    acc.yield\n++-  }\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Data entry ops OUTSIDE compute constructs should NOT be removed\n++-//===----------------------------------------------------------------------===//\n++-\n++-// CHECK-LABEL: func.func @copyin_outside_parallel\n++-// CHECK:       acc.copyin\n++-// CHECK:       acc.parallel\n++-func.func @copyin_outside_parallel(%arg0 : memref<i32>) {\n++-  %c0 = arith.constant 0 : i32\n++-  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  acc.parallel dataOperands(%0 : memref<i32>) {\n++-    memref.store %c0, %0[] : memref<i32>\n++-    acc.yield\n++-  }\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Data exit ops in specialized routines\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_copyout func(@copyout) worker\n++-// CHECK-LABEL: func.func @copyout\n++-// CHECK-NOT:   acc.copyout\n++-func.func @copyout(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_copyout, <worker>, \"copyout\">} {\n++-  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  acc.copyout accPtr(%0 : memref<i32>) to varPtr(%arg0 : memref<i32>)\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_delete func(@delete) worker\n++-// CHECK-LABEL: func.func @delete\n++-// CHECK-NOT:   acc.delete\n++-func.func @delete(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_delete, <worker>, \"delete\">} {\n++-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  acc.delete accPtr(%0 : memref<i32>)\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Erase ops (unstructured data and runtime ops)\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_enter_data func(@enter_data) worker\n++-// CHECK-LABEL: func.func @enter_data\n++-// CHECK-NOT:   acc.enter_data\n++-func.func @enter_data(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_enter_data, <worker>, \"enter_data\">} {\n++-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  acc.enter_data dataOperands(%0 : memref<i32>)\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_init func(@init_op) worker\n++-// CHECK-LABEL: func.func @init_op\n++-// CHECK-NOT:   acc.init\n++-func.func @init_op() attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_init, <worker>, \"init_op\">} {\n++-  acc.init\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_wait func(@wait_op) worker\n++-// CHECK-LABEL: func.func @wait_op\n++-// CHECK-NOT:   acc.wait\n++-func.func @wait_op() attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_wait, <worker>, \"wait_op\">} {\n++-  acc.wait\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Region unwrap (structured data and compute constructs)\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_data func(@data_construct) worker\n++-// CHECK-LABEL: func.func @data_construct\n++-// CHECK-NOT:   acc.data\n++-// CHECK:       arith.constant 42\n++-func.func @data_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_data, <worker>, \"data_construct\">} {\n++-  %d = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  acc.data dataOperands(%d : memref<i32>) {\n++-    %c42 = arith.constant 42 : i32\n++-    memref.store %c42, %arg0[] : memref<i32>\n++-    acc.terminator\n++-  }\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_parallel func(@parallel_construct) worker\n++-// CHECK-LABEL: func.func @parallel_construct\n++-// CHECK-NOT:   acc.parallel\n++-// CHECK:       arith.constant 44\n++-func.func @parallel_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_parallel, <worker>, \"parallel_construct\">} {\n++-  acc.parallel {\n++-    %c44 = arith.constant 44 : i32\n++-    memref.store %c44, %arg0[] : memref<i32>\n++-    acc.yield\n++-  }\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_serial func(@serial_construct) worker\n++-// CHECK-LABEL: func.func @serial_construct\n++-// CHECK-NOT:   acc.serial\n++-// CHECK:       arith.constant 45\n++-func.func @serial_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_serial, <worker>, \"serial_construct\">} {\n++-  acc.serial {\n++-    %c45 = arith.constant 45 : i32\n++-    memref.store %c45, %arg0[] : memref<i32>\n++-    acc.yield\n++-  }\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_kernels func(@kernels_construct) worker\n++-// CHECK-LABEL: func.func @kernels_construct\n++-// CHECK-NOT:   acc.kernels\n++-// CHECK:       arith.constant 46\n++-func.func @kernels_construct(%arg0 : memref<i32>) attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_kernels, <worker>, \"kernels_construct\">} {\n++-  acc.kernels {\n++-    %c46 = arith.constant 46 : i32\n++-    memref.store %c46, %arg0[] : memref<i32>\n++-    acc.terminator\n++-  }\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Declare enter/exit strip in device routines\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_declare func(@dev_routine_declare) worker\n++-// CHECK-LABEL: func.func @dev_routine_declare\n++-// CHECK-NOT: acc.declare_enter\n++-// CHECK-NOT: acc.declare_exit\n++-func.func @dev_routine_declare() attributes {acc.specialized_routine = #acc.specialized_routine<@acc_routine_declare, <worker>, \"dev_routine_declare\">} {\n++-  %var = memref.alloca() : memref<f32>\n++-  %c = acc.create varPtr(%var : memref<f32>) -> memref<f32>\n++-  %t = acc.declare_enter dataOperands(%c : memref<f32>)\n++-  acc.declare_exit token(%t) dataOperands(%c : memref<f32>)\n++-  return\n++-}\n++diff -ruN --strip-trailing-cr a/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir b/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir\n++--- a/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir\n+++++ b/mlir/test/Dialect/OpenACC/acc-specialize-for-host-fallback.mlir\n++@@ -1,157 +0,0 @@\n++-// RUN: mlir-opt %s --pass-pipeline='builtin.module(func.func(acc-specialize-for-host{enable-host-fallback=true}))' | FileCheck %s\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Data entry ops - replaced with var (host fallback)\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_create func(@create) seq\n++-// CHECK-LABEL: func.func @create\n++-// CHECK-NOT:   acc.create\n++-func.func @create(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_create]>} {\n++-  %c0 = arith.constant 0 : i32\n++-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  memref.store %c0, %0[] : memref<i32>\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_copyin func(@copyin) seq\n++-// CHECK-LABEL: func.func @copyin\n++-// CHECK-NOT:   acc.copyin\n++-func.func @copyin(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_copyin]>} {\n++-  %c0 = arith.constant 0 : i32\n++-  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  memref.store %c0, %0[] : memref<i32>\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_present func(@present) seq\n++-// CHECK-LABEL: func.func @present\n++-// CHECK-NOT:   acc.present\n++-func.func @present(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_present]>} {\n++-  %c0 = arith.constant 0 : i32\n++-  %0 = acc.present varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  memref.store %c0, %0[] : memref<i32>\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Data exit ops - erased (host fallback)\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_copyout func(@copyout) seq\n++-// CHECK-LABEL: func.func @copyout\n++-// CHECK-NOT:   acc.copyout\n++-func.func @copyout(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_copyout]>} {\n++-  %0 = acc.copyin varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  acc.copyout accPtr(%0 : memref<i32>) to varPtr(%arg0 : memref<i32>)\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_delete func(@delete) seq\n++-// CHECK-LABEL: func.func @delete\n++-// CHECK-NOT:   acc.delete\n++-func.func @delete(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_delete]>} {\n++-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  acc.delete accPtr(%0 : memref<i32>)\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Runtime operations - erased (host fallback)\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_init func(@init_op) seq\n++-// CHECK-LABEL: func.func @init_op\n++-// CHECK-NOT:   acc.init\n++-func.func @init_op() attributes {acc.routine_info = #acc.routine_info<[@acc_routine_init]>} {\n++-  acc.init\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_shutdown func(@shutdown_op) seq\n++-// CHECK-LABEL: func.func @shutdown_op\n++-// CHECK-NOT:   acc.shutdown\n++-func.func @shutdown_op() attributes {acc.routine_info = #acc.routine_info<[@acc_routine_shutdown]>} {\n++-  acc.shutdown\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_wait func(@wait_op) seq\n++-// CHECK-LABEL: func.func @wait_op\n++-// CHECK-NOT:   acc.wait\n++-func.func @wait_op() attributes {acc.routine_info = #acc.routine_info<[@acc_routine_wait]>} {\n++-  acc.wait\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Structured data and compute constructs - unwrap regions (host fallback)\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_data func(@data_construct) seq\n++-// CHECK-LABEL: func.func @data_construct\n++-// CHECK-NOT:   acc.data\n++-// CHECK:       arith.constant 42\n++-func.func @data_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_data]>} {\n++-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  acc.data dataOperands(%0 : memref<i32>) {\n++-    %c42 = arith.constant 42 : i32\n++-    memref.store %c42, %arg0[] : memref<i32>\n++-    acc.terminator\n++-  }\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_parallel func(@parallel_construct) seq\n++-// CHECK-LABEL: func.func @parallel_construct\n++-// CHECK-NOT:   acc.parallel\n++-// CHECK:       arith.constant 44\n++-func.func @parallel_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_parallel]>} {\n++-  acc.parallel {\n++-    %c44 = arith.constant 44 : i32\n++-    memref.store %c44, %arg0[] : memref<i32>\n++-    acc.yield\n++-  }\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_serial func(@serial_construct) seq\n++-// CHECK-LABEL: func.func @serial_construct\n++-// CHECK-NOT:   acc.serial\n++-// CHECK:       arith.constant 45\n++-func.func @serial_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_serial]>} {\n++-  acc.serial {\n++-    %c45 = arith.constant 45 : i32\n++-    memref.store %c45, %arg0[] : memref<i32>\n++-    acc.yield\n++-  }\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_kernels func(@kernels_construct) seq\n++-// CHECK-LABEL: func.func @kernels_construct\n++-// CHECK-NOT:   acc.kernels\n++-// CHECK:       arith.constant 46\n++-func.func @kernels_construct(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_kernels]>} {\n++-  acc.kernels {\n++-    %c46 = arith.constant 46 : i32\n++-    memref.store %c46, %arg0[] : memref<i32>\n++-    acc.terminator\n++-  }\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Declare enter/exit - erased (host fallback)\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_declare func(@declare_enter_exit) seq\n++-// CHECK-LABEL: func.func @declare_enter_exit\n++-// CHECK-NOT:   acc.declare_enter\n++-// CHECK-NOT:   acc.declare_exit\n++-func.func @declare_enter_exit(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_declare]>} {\n++-  %0 = acc.create varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  %token = acc.declare_enter dataOperands(%0 : memref<i32>)\n++-  acc.declare_exit token(%token) dataOperands(%0 : memref<i32>)\n++-  return\n++-}\n++diff -ruN --strip-trailing-cr a/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir b/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir\n++--- a/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir\n+++++ b/mlir/test/Dialect/OpenACC/acc-specialize-for-host.mlir\n++@@ -1,404 +0,0 @@\n++-// RUN: mlir-opt %s -acc-specialize-for-host | FileCheck %s\n++-\n++-// Recipe definitions\n++-acc.private.recipe @privatization_memref_i32 : memref<i32> init {\n++-^bb0(%arg0: memref<i32>):\n++-  %0 = memref.alloca() : memref<i32>\n++-  acc.yield %0 : memref<i32>\n++-}\n++-\n++-acc.firstprivate.recipe @firstprivatization_memref_i32 : memref<i32> init {\n++-^bb0(%arg0: memref<i32>):\n++-  %0 = memref.alloca() : memref<i32>\n++-  acc.yield %0 : memref<i32>\n++-} copy {\n++-^bb0(%arg0: memref<i32>, %arg1: memref<i32>):\n++-  %0 = memref.load %arg0[] : memref<i32>\n++-  memref.store %0, %arg1[] : memref<i32>\n++-  acc.terminator\n++-}\n++-\n++-acc.reduction.recipe @reduction_add_memref_i32 : memref<i32> reduction_operator <add> init {\n++-^bb0(%arg0: memref<i32>):\n++-  %c0_i32 = arith.constant 0 : i32\n++-  %0 = memref.alloca() : memref<i32>\n++-  memref.store %c0_i32, %0[] : memref<i32>\n++-  acc.yield %0 : memref<i32>\n++-} combiner {\n++-^bb0(%arg0: memref<i32>, %arg1: memref<i32>):\n++-  %0 = memref.load %arg0[] : memref<i32>\n++-  %1 = memref.load %arg1[] : memref<i32>\n++-  %2 = arith.addi %0, %1 : i32\n++-  memref.store %2, %arg0[] : memref<i32>\n++-  acc.yield %arg0 : memref<i32>\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Orphan data entry ops - replaced with var\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_private func(@private) seq\n++-// CHECK-LABEL: func.func @private\n++-// CHECK-NOT:   acc.private\n++-func.func @private(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_private]>} {\n++-  %c0 = arith.constant 0 : i32\n++-  %0 = acc.private varPtr(%arg0 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n++-  memref.store %c0, %0[] : memref<i32>\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_cache func(@cache) seq\n++-// CHECK-LABEL: func.func @cache\n++-// CHECK-NOT:   acc.cache\n++-func.func @cache(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_cache]>} {\n++-  %c0 = arith.constant 0 : i32\n++-  %0 = acc.cache varPtr(%arg0 : memref<i32>) -> memref<i32>\n++-  memref.store %c0, %0[] : memref<i32>\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Orphan atomic operations - converted to load/store\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_atomic func(@orphan_atomic_update) seq\n++-// CHECK-LABEL: func.func @orphan_atomic_update\n++-// CHECK-NOT:   acc.atomic.update\n++-// CHECK:       memref.load\n++-// CHECK:       arith.addi\n++-// CHECK:       memref.store\n++-func.func @orphan_atomic_update(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic]>} {\n++-  acc.atomic.update %arg0 : memref<i32> {\n++-  ^bb0(%arg1: i32):\n++-    %c1 = arith.constant 1 : i32\n++-    %1 = arith.addi %arg1, %c1 : i32\n++-    acc.yield %1 : i32\n++-  }\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_atomic_read func(@orphan_atomic_read) seq\n++-// CHECK-LABEL: func.func @orphan_atomic_read\n++-// CHECK-NOT:   acc.atomic.read\n++-// CHECK:       memref.copy %arg0, %arg1\n++-func.func @orphan_atomic_read(%arg0 : memref<i32>, %arg1 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_read]>} {\n++-  acc.atomic.read %arg1 = %arg0 : memref<i32>, memref<i32>, i32\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_atomic_write func(@orphan_atomic_write) seq\n++-// CHECK-LABEL: func.func @orphan_atomic_write\n++-// CHECK-NOT:   acc.atomic.write\n++-// CHECK:       memref.store %arg1, %arg0[]\n++-func.func @orphan_atomic_write(%arg0 : memref<i32>, %arg1 : i32) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_write]>} {\n++-  acc.atomic.write %arg0 = %arg1 : memref<i32>, i32\n++-  return\n++-}\n++-\n++-acc.routine @acc_routine_atomic_capture func(@orphan_atomic_capture) seq\n++-// CHECK-LABEL: func.func @orphan_atomic_capture\n++-// CHECK-NOT:   acc.atomic.capture\n++-// CHECK:       memref.copy %arg0, %arg1\n++-// CHECK:       [[LOAD:%.*]] = memref.load %arg0[]\n++-// CHECK:       [[INC:%.*]] = arith.addi [[LOAD]]\n++-// CHECK:       memref.store [[INC]], %arg0[]\n++-func.func @orphan_atomic_capture(%arg0 : memref<i32>, %arg1 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_capture]>} {\n++-  %c1_i32 = arith.constant 1 : i32\n++-  acc.atomic.capture {\n++-    acc.atomic.read %arg1 = %arg0 : memref<i32>, memref<i32>, i32\n++-    acc.atomic.update %arg0 : memref<i32> {\n++-    ^bb0(%v: i32):\n++-      %r = arith.addi %v, %c1_i32 : i32\n++-      acc.yield %r : i32\n++-    }\n++-    acc.terminator\n++-  }\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Negative tests - ops that should NOT be converted\n++-//===----------------------------------------------------------------------===//\n++-\n++-// acc.private attached to acc.parallel should NOT be removed\n++-acc.routine @acc_routine_private_parallel func(@private_attached_to_parallel) seq\n++-// CHECK-LABEL: func.func @private_attached_to_parallel\n++-// CHECK:       acc.private\n++-// CHECK:       acc.parallel\n++-func.func @private_attached_to_parallel(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_private_parallel]>} {\n++-  %0 = acc.private varPtr(%arg0 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n++-  acc.parallel private(%0 : memref<i32>) {\n++-    %c1 = arith.constant 1 : i32\n++-    memref.store %c1, %0[] : memref<i32>\n++-    acc.yield\n++-  }\n++-  return\n++-}\n++-\n++-// acc.atomic.update inside acc.parallel should NOT be converted\n++-acc.routine @acc_routine_atomic_parallel func(@atomic_inside_parallel) seq\n++-// CHECK-LABEL: func.func @atomic_inside_parallel\n++-// CHECK:       acc.parallel\n++-// CHECK:       acc.atomic.update\n++-func.func @atomic_inside_parallel(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_atomic_parallel]>} {\n++-  acc.parallel {\n++-    acc.atomic.update %arg0 : memref<i32> {\n++-    ^bb0(%arg1: i32):\n++-      %c1 = arith.constant 1 : i32\n++-      %1 = arith.addi %arg1, %c1 : i32\n++-      acc.yield %1 : i32\n++-    }\n++-    acc.yield\n++-  }\n++-  return\n++-}\n++-\n++-// acc.loop inside acc.parallel should NOT be converted\n++-acc.routine @acc_routine_loop_parallel func(@loop_inside_parallel) seq\n++-// CHECK-LABEL: func.func @loop_inside_parallel\n++-// CHECK:       acc.parallel\n++-// CHECK:       acc.loop\n++-func.func @loop_inside_parallel(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_loop_parallel]>} {\n++-  %c0 = arith.constant 0 : index\n++-  %c10 = arith.constant 10 : index\n++-  %c1 = arith.constant 1 : index\n++-  acc.parallel {\n++-    acc.loop control(%iv : index) = (%c0 : index) to (%c10 : index) step (%c1 : index) {\n++-      %c5 = arith.constant 5 : i32\n++-      memref.store %c5, %arg0[] : memref<i32>\n++-      acc.yield\n++-    } attributes {inclusiveUpperbound = array<i1: true>, seq = [#acc.device_type<none>]}\n++-    acc.yield\n++-  }\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Positive tests - orphan ops attached to orphan loop (both should convert)\n++-//===----------------------------------------------------------------------===//\n++-\n++-// acc.private attached to orphan acc.loop - BOTH should be removed\n++-acc.routine @acc_routine_private_loop func(@private_attached_to_loop) seq\n++-// CHECK-LABEL: func.func @private_attached_to_loop\n++-// CHECK-NOT:   acc.private\n++-// CHECK-NOT:   acc.loop\n++-// CHECK:       scf.for\n++-func.func @private_attached_to_loop(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_private_loop]>} {\n++-  %c0 = arith.constant 0 : i32\n++-  %c10 = arith.constant 10 : i32\n++-  %c1 = arith.constant 1 : i32\n++-  %0 = acc.private varPtr(%arg0 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n++-  acc.loop private(%0 : memref<i32>) control(%iv : i32) = (%c0 : i32) to (%c10 : i32) step (%c1 : i32) {\n++-    %c1_i32 = arith.constant 1 : i32\n++-    memref.store %c1_i32, %0[] : memref<i32>\n++-    acc.yield\n++-  } attributes {inclusiveUpperbound = array<i1: true>, seq = [#acc.device_type<none>]}\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Orphan loop conversion tests\n++-//===----------------------------------------------------------------------===//\n++-\n++-// Orphan acc.loop should be converted to scf.for\n++-acc.routine @acc_routine_loop func(@orphan_loop) seq\n++-// CHECK-LABEL: func.func @orphan_loop\n++-// CHECK-NOT:   acc.loop\n++-// CHECK:       scf.for\n++-func.func @orphan_loop(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_loop]>} {\n++-  %c0 = arith.constant 0 : i32\n++-  %c10 = arith.constant 10 : i32\n++-  %c1 = arith.constant 1 : i32\n++-  acc.loop control(%iv : i32) = (%c0 : i32) to (%c10 : i32) step (%c1 : i32) {\n++-    memref.store %iv, %arg0[] : memref<i32>\n++-    acc.yield\n++-  } attributes {inclusiveUpperbound = array<i1: true>, seq = [#acc.device_type<none>]}\n++-  return\n++-}\n++-\n++-// Nested orphan acc.loop should be converted to nested scf.for\n++-acc.routine @acc_routine_nested_loop func(@nested_orphan_loop) seq\n++-// CHECK-LABEL: func.func @nested_orphan_loop\n++-// CHECK-NOT:   acc.loop\n++-// CHECK:       scf.for\n++-// CHECK:       scf.for\n++-func.func @nested_orphan_loop(%arg0 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_nested_loop]>} {\n++-  %c0 = arith.constant 0 : i32\n++-  %c10 = arith.constant 10 : i32\n++-  %c1 = arith.constant 1 : i32\n++-  acc.loop control(%iv0 : i32, %iv1 : i32) = (%c0, %c0 : i32, i32) to (%c10, %c10 : i32, i32) step (%c1, %c1 : i32, i32) {\n++-    %sum = arith.addi %iv0, %iv1 : i32\n++-    memref.store %sum, %arg0[] : memref<i32>\n++-    acc.yield\n++-  } attributes {inclusiveUpperbound = array<i1: true, true>, seq = [#acc.device_type<none>]}\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Unstructured orphan loop - converted to scf.execute_region\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_unstructured func(@orphan_unstructured_loop) seq\n++-// CHECK-LABEL: func.func @orphan_unstructured_loop\n++-// CHECK-NOT:   acc.loop\n++-// CHECK-NOT:   acc.private\n++-// CHECK:       scf.execute_region\n++-// CHECK:       ^bb{{[0-9]+}}:\n++-// CHECK:       cf.cond_br\n++-// CHECK:       scf.yield\n++-func.func @orphan_unstructured_loop(%arg0 : memref<32xi32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_unstructured]>} {\n++-  %c32_i32 = arith.constant 32 : i32\n++-  %c2_i32 = arith.constant 2 : i32\n++-  %c0_i32 = arith.constant 0 : i32\n++-  %c1_i32 = arith.constant 1 : i32\n++-  %iter_var = memref.alloca() : memref<i32>\n++-  %priv = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n++-  acc.loop private(%priv : memref<i32>) {\n++-    %limit = memref.alloca() : memref<i32>\n++-    memref.store %c32_i32, %limit[] : memref<i32>\n++-    memref.store %c1_i32, %priv[] : memref<i32>\n++-    cf.br ^bb1\n++-  ^bb1:\n++-    %count = memref.load %limit[] : memref<i32>\n++-    %cond = arith.cmpi sgt, %count, %c0_i32 : i32\n++-    cf.cond_br %cond, ^bb2, ^bb3\n++-  ^bb2:\n++-    %idx = memref.load %priv[] : memref<i32>\n++-    %idx_idx = arith.index_cast %idx : i32 to index\n++-    %val = memref.load %arg0[%idx_idx] : memref<32xi32>\n++-    %new_val = arith.divsi %val, %c2_i32 : i32\n++-    memref.store %new_val, %arg0[%idx_idx] : memref<32xi32>\n++-    %new_count = arith.subi %count, %c1_i32 : i32\n++-    memref.store %new_count, %limit[] : memref<i32>\n++-    %new_idx = arith.addi %idx, %c1_i32 : i32\n++-    memref.store %new_idx, %priv[] : memref<i32>\n++-    cf.br ^bb1\n++-  ^bb3:\n++-    acc.yield\n++-  } attributes {independent = [#acc.device_type<none>], unstructured}\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Orphan loop with reduction - both converted\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_loop_reduction func(@orphan_loop_with_reduction) seq\n++-// CHECK-LABEL: func.func @orphan_loop_with_reduction\n++-// CHECK-NOT:   acc.loop\n++-// CHECK-NOT:   acc.reduction\n++-// CHECK-NOT:   acc.private\n++-// CHECK:       scf.for\n++-func.func @orphan_loop_with_reduction(%arg0 : memref<i32>, %arg1 : memref<100xi32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_loop_reduction]>} {\n++-  %c100_i32 = arith.constant 100 : i32\n++-  %c1_i32 = arith.constant 1 : i32\n++-  %iter_var = memref.alloca() : memref<i32>\n++-  %red = acc.reduction varPtr(%arg0 : memref<i32>) recipe(@reduction_add_memref_i32) -> memref<i32>\n++-  %priv = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n++-  acc.loop vector private(%priv : memref<i32>) reduction(%red : memref<i32>) control(%arg2 : i32) = (%c1_i32 : i32) to (%c100_i32 : i32) step (%c1_i32 : i32) {\n++-    memref.store %arg2, %priv[] : memref<i32>\n++-    %idx = memref.load %priv[] : memref<i32>\n++-    %idx_cast = arith.index_cast %idx : i32 to index\n++-    %elem = memref.load %arg1[%idx_cast] : memref<100xi32>\n++-    %r_val = memref.load %arg0[] : memref<i32>\n++-    %new_r = arith.addi %r_val, %elem : i32\n++-    memref.store %new_r, %arg0[] : memref<i32>\n++-    acc.yield\n++-  } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Orphan loop with variable bounds\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.routine @acc_routine_var_bounds func(@orphan_loop_variable_bounds) seq\n++-// CHECK-LABEL: func.func @orphan_loop_variable_bounds\n++-// CHECK-NOT:   acc.loop\n++-// CHECK:       [[LB:%.*]] = memref.load %arg0[]\n++-// CHECK:       [[UB:%.*]] = memref.load %arg1[]\n++-// CHECK:       scf.for\n++-func.func @orphan_loop_variable_bounds(%arg0 : memref<i32>, %arg1 : memref<i32>, %arg2 : memref<i32>) attributes {acc.routine_info = #acc.routine_info<[@acc_routine_var_bounds]>} {\n++-  %c1 = arith.constant 1 : i32\n++-  %lb = memref.load %arg0[] : memref<i32>\n++-  %ub = memref.load %arg1[] : memref<i32>\n++-  acc.loop vector control(%iv : i32) = (%lb : i32) to (%ub : i32) step (%c1 : i32) {\n++-    memref.store %iv, %arg2[] : memref<i32>\n++-    acc.yield\n++-  } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n++-  return\n++-}\n++-\n++-//===----------------------------------------------------------------------===//\n++-// Orphan loop between compute regions - only orphan converted\n++-//===----------------------------------------------------------------------===//\n++-\n++-acc.reduction.recipe @reduction_mul_memref_i32 : memref<i32> reduction_operator <mul> init {\n++-^bb0(%arg0: memref<i32>):\n++-  %c1_i32 = arith.constant 1 : i32\n++-  %0 = memref.alloca() : memref<i32>\n++-  memref.store %c1_i32, %0[] : memref<i32>\n++-  acc.yield %0 : memref<i32>\n++-} combiner {\n++-^bb0(%arg0: memref<i32>, %arg1: memref<i32>):\n++-  %0 = memref.load %arg0[] : memref<i32>\n++-  %1 = memref.load %arg1[] : memref<i32>\n++-  %2 = arith.muli %0, %1 : i32\n++-  memref.store %2, %arg0[] : memref<i32>\n++-  acc.yield %arg0 : memref<i32>\n++-}\n++-\n++-// Orphan loop sandwiched between compute regions - only orphan should convert\n++-// CHECK-LABEL: func.func @orphan_between_compute_regions\n++-// CHECK:       acc.parallel\n++-// CHECK:       acc.yield\n++-// CHECK-NOT:   acc.private varPtr\n++-// CHECK-NOT:   acc.reduction varPtr\n++-// CHECK:       scf.for\n++-// CHECK:       acc.parallel\n++-func.func @orphan_between_compute_regions(%arg0 : memref<i32>, %arg1 : memref<8xi32>, %arg2 : memref<i32>) {\n++-  %c2_i32 = arith.constant 2 : i32\n++-  %c8_i32 = arith.constant 8 : i32\n++-  %c1_i32 = arith.constant 1 : i32\n++-  %iter_var = memref.alloca() : memref<i32>\n++-\n++-  // First compute region - should NOT be converted\n++-  acc.parallel combined(loop) {\n++-    %priv1 = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n++-    acc.loop combined(parallel) private(%priv1 : memref<i32>) control(%iv : i32) = (%c1_i32 : i32) to (%c8_i32 : i32) step (%c1_i32 : i32) {\n++-      memref.store %iv, %priv1[] : memref<i32>\n++-      %idx = arith.index_cast %iv : i32 to index\n++-      memref.store %c1_i32, %arg1[%idx] : memref<8xi32>\n++-      acc.yield\n++-    } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n++-    acc.yield\n++-  }\n++-\n++-  // Orphan loop - SHOULD be converted\n++-  %priv_orphan = acc.private varPtr(%arg2 : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n++-  %red_orphan = acc.reduction varPtr(%arg0 : memref<i32>) recipe(@reduction_mul_memref_i32) -> memref<i32>\n++-  %priv_iv = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n++-  acc.loop private(%priv_orphan, %priv_iv : memref<i32>, memref<i32>) reduction(%red_orphan : memref<i32>) control(%iv : i32) = (%c1_i32 : i32) to (%c8_i32 : i32) step (%c1_i32 : i32) {\n++-    memref.store %iv, %priv_iv[] : memref<i32>\n++-    %idx = arith.index_cast %iv : i32 to index\n++-    %elem = memref.load %arg1[%idx] : memref<8xi32>\n++-    memref.store %elem, %priv_orphan[] : memref<i32>\n++-    %t = memref.load %priv_orphan[] : memref<i32>\n++-    %mul = arith.muli %t, %c2_i32 : i32\n++-    memref.store %mul, %arg0[] : memref<i32>\n++-    acc.yield\n++-  } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n++-\n++-  // Second compute region - should NOT be converted\n++-  acc.parallel combined(loop) {\n++-    %priv2 = acc.private varPtr(%iter_var : memref<i32>) recipe(@privatization_memref_i32) -> memref<i32>\n++-    acc.loop combined(parallel) private(%priv2 : memref<i32>) control(%iv : i32) = (%c1_i32 : i32) to (%c8_i32 : i32) step (%c1_i32 : i32) {\n++-      memref.store %iv, %priv2[] : memref<i32>\n++-      %idx = arith.index_cast %iv : i32 to index\n++-      memref.store %iv, %arg1[%idx] : memref<8xi32>\n++-      acc.yield\n++-    } attributes {inclusiveUpperbound = array<i1: true>, independent = [#acc.device_type<none>]}\n++-    acc.yield\n++-  }\n++-  return\n++-}\n++diff -ruN --strip-trailing-cr a/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir b/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir\n++--- a/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir\n+++++ b/mlir/test/Dialect/Tensor/value-bounds-op-interface-impl.mlir\n++@@ -230,35 +230,3 @@\n++   %1 = \"test.reify_bound\"(%padded) {dim = 1, constant} : (tensor<1x?x64xf32>) -> (index)\n++   return\n++ }\n++-\n++-// -----\n++-\n++-//       CHECK: #[[$MAP:.+]] = affine_map<()[s0] -> (s0 * 2)>\n++-// CHECK-LABEL: func @tensor_collapse(\n++-//  CHECK-SAME:     %[[sz0:.*]]: index\n++-//   CHECK-DAG:   %[[c2:.*]] = arith.constant 2 : index\n++-//   CHECK-DAG:   %[[c12:.*]] = arith.constant 12 : index\n++-//       CHECK:   %[[dim:.*]] = tensor.dim %{{.*}}, %[[c2]] : tensor<3x4x?x2xf32>\n++-//       CHECK:   %[[mul:.*]] = affine.apply #[[$MAP]]()[%[[dim]]]\n++-//       CHECK:   return %[[c12]], %[[mul]]\n++-func.func @tensor_collapse(%sz0: index) -> (index, index) {\n++-  %0 = tensor.empty(%sz0) : tensor<3x4x?x2xf32>\n++-  %1 = tensor.collapse_shape %0 [[0, 1], [2, 3]] : tensor<3x4x?x2xf32> into tensor<12x?xf32>\n++-  %2 = \"test.reify_bound\"(%1) {dim = 0} : (tensor<12x?xf32>) -> (index)\n++-  %3 = \"test.reify_bound\"(%1) {dim = 1} : (tensor<12x?xf32>) -> (index)\n++-  return %2, %3 : index, index\n++-}\n++-\n++-// -----\n++-\n++-// CHECK-LABEL: func @tensor_expand(\n++-//  CHECK-SAME:     %[[t:[a-zA-Z0-9]+]]: tensor<?xf32>\n++-//  CHECK-SAME:     %[[sz:[a-zA-Z0-9]+]]: index\n++-//       CHECK:   %[[c4:.*]] = arith.constant 4 : index\n++-//       CHECK:   return %[[c4]], %[[sz]]\n++-func.func @tensor_expand(%t: tensor<?xf32>, %sz: index) -> (index, index) {\n++-  %0 = tensor.expand_shape %t [[0, 1]] output_shape [4, %sz] : tensor<?xf32> into tensor<4x?xf32>\n++-  %1 = \"test.reify_bound\"(%0) {dim = 0} : (tensor<4x?xf32>) -> (index)\n++-  %2 = \"test.reify_bound\"(%0) {dim = 1} : (tensor<4x?xf32>) -> (index)\n++-  return %1, %2 : index, index\n++-}\n+diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl\n+index 29af0ff..55a1ce3 100644\n+--- a/third_party/llvm/workspace.bzl\n++++ b/third_party/llvm/workspace.bzl\n+@@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n+ \n+ def repo(name):\n+     \"\"\"Imports LLVM.\"\"\"\n+-    LLVM_COMMIT = \"7d381f2a5634d1e41b61299839d652cc4a021898\"\n+-    LLVM_SHA256 = \"f1641918fd3f5e1667d39afb9c261da39ed9f74e30f1c2f98031d6d609a8de15\"\n++    LLVM_COMMIT = \"0812f41cd68d63d10a4c3a02271b0ea8276dbe57\"\n++    LLVM_SHA256 = \"c5bbfd7e6accbb4bfbeeb990666aa64654a667c6569366e90aa1f8d8b28dbf8c\"\n+ \n+     tf_http_archive(\n+         name = name,"
        },
        {
            "sha": "9b85a43c74684440fe97879ef42401f334947ca5",
            "filename": "third_party/xla/third_party/shardy/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl?ref=1a2bdc79992dd9563e2468f97b898858502d9380",
            "patch": "@@ -3,8 +3,8 @@\n load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n \n def repo():\n-    SHARDY_COMMIT = \"89db8f8a60c810205365b1117e6c27ac99aa40f3\"\n-    SHARDY_SHA256 = \"a5d33fa1af43f162e62a7bdff411cda7ca0a4992c6c304ac2e3344524c30e65d\"\n+    SHARDY_COMMIT = \"f85456da1c024627acfafcf5a1d9ee304973fb1b\"\n+    SHARDY_SHA256 = \"c47596ff0fa418964f6159ecd87471200499d0502a6b46ac13b8cf87d51b70a4\"\n \n     tf_http_archive(\n         name = \"shardy\","
        },
        {
            "sha": "0edab77c455927c78d83c0561c60d38d0a0fbedb",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl849816812.patch",
            "status": "added",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl849816812.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl849816812.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl849816812.patch?ref=1a2bdc79992dd9563e2468f97b898858502d9380",
            "patch": "@@ -0,0 +1,24 @@\n+\n+--- a/python/BUILD\t2025-12-11 07:03:23.000000000 -0800\n++++ b/python/BUILD\t2025-12-28 14:18:51.000000000 -0800\n+@@ -55,6 +55,7 @@\n+         \"@llvm-project//llvm:Linker\",\n+         \"@llvm-project//llvm:MC\",\n+         \"@llvm-project//llvm:Passes\",\n++        \"@llvm-project//llvm:Plugins\",\n+         \"@llvm-project//llvm:Support\",\n+         \"@llvm-project//llvm:Target\",\n+         \"@llvm-project//mlir:BuiltinToLLVMIRTranslation\",\n+\n+--- a/python/src/llvm.cc\t2025-11-12 02:33:41.000000000 -0800\n++++ b/python/src/llvm.cc\t2025-12-28 14:18:51.000000000 -0800\n+@@ -14,8 +14,8 @@\n+ #include \"llvm/Pass.h\"\n+ #include \"llvm/Passes/OptimizationLevel.h\"\n+ #include \"llvm/Passes/PassBuilder.h\"\n+-#include \"llvm/Passes/PassPlugin.h\"\n+ #include \"llvm/Passes/StandardInstrumentations.h\"\n++#include \"llvm/Plugins/PassPlugin.h\"\n+ #include \"llvm/Support/CodeGen.h\"\n+ #include \"llvm/Support/Signals.h\"\n+ #include \"llvm/Support/SourceMgr.h\""
        },
        {
            "sha": "c1d371f8853deb7606b714cbcf5fedf9283056bd",
            "filename": "third_party/xla/third_party/triton/llvm_integration/series.bzl",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1a2bdc79992dd9563e2468f97b898858502d9380/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl?ref=1a2bdc79992dd9563e2468f97b898858502d9380",
            "patch": "@@ -8,5 +8,6 @@ LLVM nor MLIR integrator, please do not add any patches to this list.\n \"\"\"\n \n llvm_patch_list = [\n+    \"//third_party/triton:llvm_integration/cl849816812.patch\",\n     # Add new patches just above this line\n ]"
        }
    ],
    "stats": {
        "total": 3909,
        "additions": 3765,
        "deletions": 144
    }
}