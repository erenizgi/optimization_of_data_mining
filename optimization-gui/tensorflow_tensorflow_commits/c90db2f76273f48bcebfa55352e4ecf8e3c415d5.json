{
    "author": "metaflow",
    "message": "[XLA:GPU] restrict max tile size for dot operands in generic Triton emitter to 256\n\nBigger tile sizes lead to register spilling, compilation took multiple minutes in such cases.\n\nPiperOrigin-RevId: 812691389",
    "sha": "c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
    "files": [
        {
            "sha": "0a4251a839a672470dc8c1a611c769a2f45e9ea0",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/triton.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -210,8 +210,7 @@ absl::StatusOr<std::unique_ptr<HloModule>> TritonBackend::RunHloPasses(\n   FusionWrapper fusion_wrapper(gpu_device_info);\n   TF_RETURN_IF_ERROR(fusion_wrapper.Run(hlo_module.get()).status());\n \n-  NestGemmFusion nest_gemm_fusion(gpu_device_info.gpu_compute_capability(),\n-                                  mlir_context_);\n+  NestGemmFusion nest_gemm_fusion(gpu_device_info, mlir_context_);\n   TF_RETURN_IF_ERROR(nest_gemm_fusion.Run(hlo_module.get()).status());\n   return hlo_module;\n }"
        },
        {
            "sha": "df6a919566385a9cdc1ddd92614408ab40552b0d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_port_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -128,9 +128,9 @@ class TritonTest : public GpuCodegenTest {\n   GetModuleAndNestedFusionMetadata(absl::string_view hlo_text) {\n     TF_ASSIGN_OR_RETURN(std::unique_ptr<VerifiedHloModule> module,\n                         ParseAndReturnVerifiedModule(hlo_text));\n-    TF_ASSIGN_OR_RETURN(bool fusion_was_nested,\n-                        NestGemmFusion(GpuComputeCapability(), &mlir_context_)\n-                            .Run(module.get()));\n+    TF_ASSIGN_OR_RETURN(\n+        bool fusion_was_nested,\n+        NestGemmFusion(device_desc(), &mlir_context_).Run(module.get()));\n     if (!fusion_was_nested) {\n       return absl::InternalError(\"Failed to nest the GEMM fusion.\");\n     }\n@@ -508,7 +508,7 @@ ENTRY entry {\n })\";\n   TF_ASSERT_OK_AND_ASSIGN(ModuleAndNestedFusionMetadata module1_and_metadata,\n                           GetModuleAndNestedFusionMetadata(absl::Substitute(\n-                              kHloTextTemplate, 16, 32, 512, 8)));\n+                              kHloTextTemplate, 256, 256, 256, 8)));\n \n   const HloFusionInstruction* fusion1 = Cast<HloFusionInstruction>(\n       module1_and_metadata.computation->FusionInstruction());"
        },
        {
            "sha": "e3509cd3976e51b4d8970456482f544e0d8fbad3",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_int4_device_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_int4_device_test.cc?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -111,8 +111,7 @@ class TritonTest : public GpuCodegenTest {\n     emitter_opts->Add(\n         DebugOptions::GENERIC_TRITON_EMITTER_ALLOW_ALL_GEMM_SHAPES);\n     absl::StatusOr<bool> nested_or =\n-        NestGemmFusion(device_desc().gpu_compute_capability(), &mlir_context_)\n-            .Run(module.get());\n+        NestGemmFusion(device_desc(), &mlir_context_).Run(module.get());\n     if (!nested_or.ok()) {\n       return ::testing::AssertionFailure() << nested_or.status().message();\n     }"
        },
        {
            "sha": "5898f31204d7e3469257edce4fda203daca69735",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -318,8 +318,7 @@ absl::StatusOr<std::unique_ptr<HloModule>> TritonGemmAutotuneExtractor(\n     TF_RETURN_IF_ERROR(fusion_wrapper.Run(new_module.get()).status());\n   }\n \n-  NestGemmFusion nest_gemm_fusion(gpu_device_info.gpu_compute_capability(),\n-                                  mlir_context);\n+  NestGemmFusion nest_gemm_fusion(gpu_device_info, mlir_context);\n   TF_RETURN_IF_ERROR(nest_gemm_fusion.Run(new_module.get()).status());\n   return new_module;\n }"
        },
        {
            "sha": "2ec6224df94b0d9037d1ad2a60b85d0f48ab0e98",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -1867,9 +1867,8 @@ absl::Status GpuCompiler::OptimizeHloPostLayoutAssignment(\n \n   // Match the location of this pass in `gemm_fusion_autotuner.cc` to make sure\n   // that there is no discrepancy.\n-  pipeline.AddPass<NestGemmFusion>(\n-      gpu_target_config.device_description.gpu_compute_capability(),\n-      &mlir_context_);\n+  pipeline.AddPass<NestGemmFusion>(gpu_target_config.device_description,\n+                                   &mlir_context_);\n \n   // Clean up new_tuple described above.\n   pipeline.AddPass<TupleSimplifier>();"
        },
        {
            "sha": "8c7ba32c95baaabb9d93437cea2773a8b8e66347",
            "filename": "third_party/xla/xla/service/gpu/model/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2FBUILD?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -867,15 +867,16 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:util\",\n         \"//xla/hlo/analysis:indexing_analysis\",\n+        \"//xla/hlo/analysis:interval\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/utils:hlo_traversal\",\n         \"//xla/stream_executor:device_description\",\n         \"@com_google_absl//absl/algorithm:container\",\n-        \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/memory\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//llvm:Support\",\n         \"@llvm-project//mlir:IR\",\n@@ -899,6 +900,7 @@ xla_cc_test(\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n         \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_googletest//:gtest_main\",\n         \"@llvm-project//mlir:IR\",\n     ],"
        },
        {
            "sha": "159d05e56ac0b58b100141be7a943a67bd0e1278",
            "filename": "third_party/xla/xla/service/gpu/model/matmul_ptable_stats_collection.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fmatmul_ptable_stats_collection.cc?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -93,7 +93,8 @@ HloDotInstruction* GetTritonGemmInstruction(const HloInstruction& dot_fusion) {\n absl::StatusOr<BlockLevelParameters> GetBlockLevelParams(\n     HloDotInstruction& dot, TritonGemmConfig& config) {\n   mlir::MLIRContext ctx;\n-  return ::xla::gpu::detail::FindBlockLevelParameters(&dot, config, &ctx);\n+  return ::xla::gpu::detail::FindBlockLevelParameters(&dot, config, &ctx,\n+                                                      se::DeviceDescription());\n }\n \n absl::Status SetReificationCost(HloInstruction& instr, absl::Duration exec_time,"
        },
        {
            "sha": "d9bc7eb28342a296fdbf59eccbd7ab5da75acbfc",
            "filename": "third_party/xla/xla/service/gpu/model/triton_emitter_constraints.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Ftriton_emitter_constraints.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Ftriton_emitter_constraints.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Ftriton_emitter_constraints.cc?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"absl/log/log.h\"\n #include \"absl/memory/memory.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_join.h\"\n #include \"absl/types/span.h\"\n #include \"llvm/ADT/DenseSet.h\"\n #include \"llvm/ADT/STLExtras.h\"\n@@ -36,6 +37,8 @@ limitations under the License.\n #include \"mlir/IR/MLIRContext.h\"\n #include \"xla/hlo/analysis/indexing_analysis.h\"\n #include \"xla/hlo/analysis/indexing_map.h\"\n+#include \"xla/hlo/analysis/indexing_map_serialization.h\"\n+#include \"xla/hlo/analysis/interval.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/utils/hlo_traversal.h\"\n@@ -61,6 +64,10 @@ using ::mlir::MLIRContext;\n // elements, otherwise it will fail to compile. (See `TRITON_MAX_TENSOR_NUMEL`\n // in the Triton codebase.)\n constexpr int64_t kMaxTensorNumElements = 1048576;\n+// For dot operations we don't want to tile the contracting dimension to a size\n+// larger than this as that leads to a large number of registers being used.\n+// Also for MMA instruction we don't want tiles greater than 256.\n+constexpr int64_t kMaxMMADimSize = 256;\n \n llvm::SmallVector<int64_t> GetPaddedTileSizes(\n     llvm::SmallVector<int64_t> tile_sizes) {\n@@ -88,6 +95,23 @@ TritonEmitterConstraints::DeriveCustomConstraints(\n       continue;\n     }\n \n+    if (hlo->opcode() == HloOpcode::kDot) {\n+      auto ctx = instruction->symbolic_tile().size_map().getContext();\n+      AffineMap identity_map = AffineMap::getMultiDimIdentityMap(\n+          instruction->symbolic_tile().size_map().getNumDims(), ctx);\n+      for (const auto& operand : instruction->operands()) {\n+        for (AffineExpr tile_size :\n+             operand->symbolic_tile().size_map().getResults()) {\n+          // TODO(393299275): There is also a lower bound limit for Triton\n+          // on what is accepted for dimension size (both contracting and free).\n+          ConstraintExpression dim_constraint(ConstraintExpression::Constraint{\n+              tile_size, Interval{1, kMaxMMADimSize}});\n+          result.push_back(CustomConstraints{identity_map, dim_constraint});\n+        }\n+      }\n+      continue;\n+    }\n+\n     // Construct custom constraints for parameters of bitcasts and reshapes\n     // within `instructions`.\n     if (hlo->opcode() == HloOpcode::kReshape ||\n@@ -275,7 +299,12 @@ absl::StatusOr<bool> TritonEmitterConstraints::ParametersSatisfyConstraints(\n   //\n   // TODO(b/365727080): get rid of this once tiling is using power of twos\n   // everywhere, including when propagating into the prologue of reductions.\n+  VLOG(5) << \"Checking custom constraints for tile parameters: \"\n+          << absl::StrJoin(tile_parameters, \", \");\n   for (const auto& custom_constraint : custom_constraints_) {\n+    VLOG(5) << \"Checking custom constraint: transform  \"\n+            << xla::ToString(custom_constraint.tile_parameters_transform)\n+            << \" constraints \" << custom_constraint.constraints.ToString();\n     llvm::SmallVector<int64_t> transformed_tile_parameters =\n         EvaluateAffineMap(custom_constraint.tile_parameters_transform,\n                           /*dim_values=*/tile_parameters);"
        },
        {
            "sha": "97b2aacf91828a658f5f2a6b574adfca66f9bdb3",
            "filename": "third_party/xla/xla/service/gpu/model/triton_emitter_constraints_test.cc",
            "status": "modified",
            "additions": 34,
            "deletions": 3,
            "changes": 37,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Ftriton_emitter_constraints_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Ftriton_emitter_constraints_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Ftriton_emitter_constraints_test.cc?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -23,6 +23,7 @@ limitations under the License.\n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/log/log.h\"\n+#include \"absl/status/status_matchers.h\"\n #include \"mlir/IR/MLIRContext.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n@@ -34,16 +35,13 @@ limitations under the License.\n #include \"xla/service/gpu/model/symbolic_tile_analysis.h\"\n #include \"xla/service/instruction_fusion.h\"\n #include \"xla/stream_executor/device_description.h\"\n-#include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n \n namespace xla {\n namespace gpu {\n namespace {\n \n-using ::tsl::testing::IsOkAndHolds;\n-\n class TritonEmitterConstraintsTest : public HloHardwareIndependentTestBase {\n  public:\n   std::optional<SymbolicTileAnalysis> TryAnalyzeModule(\n@@ -125,6 +123,39 @@ ENTRY entry_computation {\n               absl_testing::IsOkAndHolds(false));\n }\n \n+TEST_F(TritonEmitterConstraintsTest, DotOperandSizeConstraintIsEnforced) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+HloModule m\n+\n+fused_computation {\n+  p0 = f32[4,5376] parameter(0)\n+  p1 = f32[32768,5376] parameter(1)\n+  ROOT dot = f32[4,32768] dot(p0, p1), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n+}\n+\n+ENTRY entry_computation {\n+  param_0 = f32[4,5376] parameter(0)\n+  param_1 =  f32[32768,5376] parameter(1)\n+  ROOT fusion = f32[4,32768] fusion(param_0, param_1), kind=kCustom, calls=fused_computation, backend_config={\"fusion_backend_config\":{\"kind\":\"__triton\"}}\n+}\n+)\"));\n+\n+  std::optional<SymbolicTileAnalysis> analysis = TryAnalyzeModule(module.get());\n+  ASSERT_TRUE(analysis.has_value());\n+  const HloInstruction* fusion_root =\n+      module->entry_computation()->root_instruction()->fused_expression_root();\n+\n+  EXPECT_THAT(analysis->ParametersSatisfyConstraints(\n+                  Tiling({{fusion_root, FlatTiling({4, 4, 4})}})),\n+              absl_testing::IsOkAndHolds(true));\n+\n+  // Having any tile larger than 256 is not allowed for dots.\n+  EXPECT_THAT(analysis->ParametersSatisfyConstraints(\n+                  Tiling({{fusion_root, FlatTiling({512, 4, 4})}})),\n+              absl_testing::IsOkAndHolds(false));\n+}\n+\n TEST_F(TritonEmitterConstraintsTest, TooManyBlocksConstraintIsEnforced) {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n                           ParseAndReturnVerifiedModule(R\"("
        },
        {
            "sha": "d3f0e8defbd74b19b381d22a0b443058e02156f6",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -2042,6 +2042,7 @@ cc_library(\n         \"//xla/service/gpu/model:symbolic_tile_analysis\",\n         \"//xla/service/gpu/model:symbolic_tiled_hlo_instruction\",\n         \"//xla/service/gpu/model:tiled_hlo_instruction_or_computation\",\n+        \"//xla/service/gpu/model:triton_emitter_constraints\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/tools:hlo_decomposer_lib\",\n         \"//xla/tools:hlo_extractor\","
        },
        {
            "sha": "1279c26bfb85a4702a97432c13fe184df7d4cb50",
            "filename": "third_party/xla/xla/service/gpu/transforms/nest_gemm_fusion.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 15,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -60,6 +60,7 @@ limitations under the License.\n #include \"xla/service/gpu/model/symbolic_tile_analysis.h\"\n #include \"xla/service/gpu/model/symbolic_tiled_hlo_instruction.h\"\n #include \"xla/service/gpu/model/tiled_hlo_computation.h\"\n+#include \"xla/service/gpu/model/triton_emitter_constraints.h\"\n #include \"xla/service/instruction_fusion.h\"\n #include \"xla/service/matmul_indexing_utils.h\"\n #include \"xla/shape.h\"\n@@ -265,9 +266,9 @@ absl::Status FuseAndAnnotateConcatOperands(HloComputation* computation) {\n \n // Transforms a fusion into an equivalent nested fusion if it has a single dot.\n // Returns ok if the transformation was successful.\n-absl::Status MakeNestedFusionFromGemmFusion(HloFusionInstruction* fusion,\n-                                            HloInstruction* dot,\n-                                            mlir::MLIRContext* ctx) {\n+absl::Status MakeNestedFusionFromGemmFusion(\n+    HloFusionInstruction* fusion, HloInstruction* dot, mlir::MLIRContext* ctx,\n+    const se::DeviceDescription& device_description) {\n   TF_RETURN_IF_ERROR(IsDot(*dot));\n   const bool is_scaled_dot = dot->opcode() == HloOpcode::kScaledDot;\n   const int lhs = 0;\n@@ -324,9 +325,9 @@ absl::Status MakeNestedFusionFromGemmFusion(HloFusionInstruction* fusion,\n   backend_config.clear_triton_gemm_config();\n   backend_config.set_kind(kTritonNestedGemmFusionKind);\n \n-  TF_ASSIGN_OR_RETURN(\n-      BlockLevelParameters block_level_parameters,\n-      ::xla::gpu::detail::FindBlockLevelParameters(dot, config, ctx));\n+  TF_ASSIGN_OR_RETURN(BlockLevelParameters block_level_parameters,\n+                      ::xla::gpu::detail::FindBlockLevelParameters(\n+                          dot, config, ctx, device_description));\n \n   *backend_config.mutable_block_level_fusion_config() =\n       block_level_parameters.ToBlockLevelFusionConfig();\n@@ -1114,10 +1115,10 @@ class NestGemmFusionVisitor : public DfsHloRewriteVisitor {\n  public:\n   explicit NestGemmFusionVisitor(\n       mlir::MLIRContext* ctx, CallGraph* call_graph,\n-      const se::GpuComputeCapability compute_capability)\n+      const se::DeviceDescription& device_description)\n       : ctx_(ctx),\n         call_graph_(call_graph),\n-        compute_capability_(compute_capability) {}\n+        device_description_(device_description) {}\n \n  private:\n   absl::Status AcceptDotOperand(const HloInstruction* operand,\n@@ -1243,7 +1244,8 @@ class NestGemmFusionVisitor : public DfsHloRewriteVisitor {\n \n     TF_RETURN_IF_ERROR(\n         TryHoistBitcastsInComputationToCallers(instr, call_graph));\n-    TF_RETURN_IF_ERROR(MakeNestedFusionFromGemmFusion(fusion, instr, ctx_));\n+    TF_RETURN_IF_ERROR(MakeNestedFusionFromGemmFusion(fusion, instr, ctx_,\n+                                                      device_description_));\n \n     MarkAsChanged();\n     bool scaled_dot_enabled =\n@@ -1252,7 +1254,8 @@ class NestGemmFusionVisitor : public DfsHloRewriteVisitor {\n             .debug_options()\n             .xla_gpu_experimental_scaled_dot_with_triton();\n     if (CodegenDecision can_codegen_computation = IsTritonSupportedComputation(\n-            *fusion->called_computation(), compute_capability_);\n+            *fusion->called_computation(),\n+            device_description_.gpu_compute_capability());\n         !scaled_dot_enabled && !can_codegen_computation) {\n       return absl::InternalError(absl::StrCat(\n           \"Computation of fusion \", fusion->ToString(),\n@@ -1323,7 +1326,7 @@ class NestGemmFusionVisitor : public DfsHloRewriteVisitor {\n  private:\n   mlir::MLIRContext* ctx_;\n   CallGraph* call_graph_;\n-  const se::GpuComputeCapability compute_capability_;\n+  const se::DeviceDescription& device_description_;\n };\n \n }  // namespace\n@@ -1336,7 +1339,7 @@ absl::StatusOr<bool> NestGemmFusion::RunOnModule(\n   for (HloComputation* computation :\n        module->MakeNonfusionComputations(execution_threads)) {\n     NestGemmFusionVisitor visitor(mlir_context_, call_graph.get(),\n-                                  compute_capability_);\n+                                  device_description_);\n     TF_RETURN_IF_ERROR(computation->Accept(&visitor));\n     changed |= visitor.changed();\n   }\n@@ -1365,14 +1368,16 @@ absl::StatusOr<bool> NestGemmFusion::Run(\n namespace detail {\n \n absl::StatusOr<BlockLevelParameters> FindBlockLevelParameters(\n-    HloInstruction* dot, const TritonGemmConfig& config,\n-    mlir::MLIRContext* ctx) {\n+    HloInstruction* dot, const TritonGemmConfig& config, mlir::MLIRContext* ctx,\n+    const se::DeviceDescription& device_description) {\n   TF_RETURN_IF_ERROR(IsDot(*dot));\n   HloComputation* computation = dot->parent();\n   VLOG(3) << \"FindOutputTileSizesForEpilogue of computation: \"\n           << computation->ToString();\n   SymbolicTileAnalysisOrError analysis_or =\n-      SymbolicTileAnalysis::AnalyzeComputation(*computation, ctx);\n+      SymbolicTileAnalysis::AnalyzeComputation(\n+          *computation, ctx,\n+          TritonEmitterConstraints::GetBuilder(device_description));\n   if (std::holds_alternative<FusionDecision>(analysis_or)) {\n     std::unique_ptr<HloModule> extracted_computation_module =\n         ExtractModule(computation->FusionInstruction());"
        },
        {
            "sha": "376a21c961322b9561b6e920abd64e60887d5620",
            "filename": "third_party/xla/xla/service/gpu/transforms/nest_gemm_fusion.h",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.h?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -46,9 +46,9 @@ namespace xla::gpu {\n // nested fusions, each with their own BlockLevelFusionConfig.\n class NestGemmFusion : public HloModulePass {\n  public:\n-  explicit NestGemmFusion(const se::GpuComputeCapability& compute_capability,\n+  explicit NestGemmFusion(const se::DeviceDescription& device_description,\n                           mlir::MLIRContext* mlir_context)\n-      : compute_capability_(compute_capability), mlir_context_(mlir_context) {}\n+      : device_description_(device_description), mlir_context_(mlir_context) {}\n \n   absl::string_view name() const override { return \"nest_gemm_fusion\"; }\n \n@@ -58,7 +58,7 @@ class NestGemmFusion : public HloModulePass {\n       const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n \n  private:\n-  const se::GpuComputeCapability compute_capability_;\n+  const se::DeviceDescription device_description_;\n   mlir::MLIRContext* mlir_context_;\n   absl::StatusOr<bool> RunOnModule(\n       HloModule* module,\n@@ -77,8 +77,8 @@ namespace detail {\n // function can be removed once `GpuDotFusionCostModel::EstimateRunTimeForDotOp`\n // is implemented.\n absl::StatusOr<BlockLevelParameters> FindBlockLevelParameters(\n-    HloInstruction* dot, const TritonGemmConfig& config,\n-    mlir::MLIRContext* ctx);\n+    HloInstruction* dot, const TritonGemmConfig& config, mlir::MLIRContext* ctx,\n+    const se::DeviceDescription& device_description);\n \n }  // namespace detail\n "
        },
        {
            "sha": "fee36e1cf4fe1540f8bf50ec95d9fcd022c98e6a",
            "filename": "third_party/xla/xla/service/gpu/transforms/nest_gemm_fusion_test.cc",
            "status": "modified",
            "additions": 36,
            "deletions": 36,
            "changes": 72,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c90db2f76273f48bcebfa55352e4ecf8e3c415d5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion_test.cc?ref=c90db2f76273f48bcebfa55352e4ecf8e3c415d5",
            "patch": "@@ -72,9 +72,9 @@ MATCHER_P(OutputTileSizesIs, matcher, \"\") {\n \n class NestGemmFusionTest : public HloHardwareIndependentTestBase {\n  protected:\n-  const se::GpuComputeCapability compute_capability_{\n-      TestGpuDeviceInfo::RTXA6000DeviceInfo(se::CudaComputeCapability::Ampere())\n-          .gpu_compute_capability()};\n+  const se::DeviceDescription device_description_{\n+      TestGpuDeviceInfo::RTXA6000DeviceInfo(\n+          se::CudaComputeCapability::Ampere())};\n   mlir::MLIRContext mlir_context_;\n \n   DebugOptions GetDebugOptionsForTest() const override {\n@@ -116,7 +116,7 @@ ENTRY entry {\n \n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(hlo));\n   ASSERT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n \n@@ -175,7 +175,7 @@ ENTRY e {\n })\";\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(hlo));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   HloComputation* fusion_computation = module->entry_computation()\n@@ -239,7 +239,7 @@ ENTRY e {\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(hlo));\n   TF_ASSERT_OK_AND_ASSIGN(\n       bool updated,\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()));\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()));\n   EXPECT_TRUE(updated);\n   HloInstruction* root = module->entry_computation()->root_instruction();\n   EXPECT_EQ(root->opcode(), HloOpcode::kTuple);\n@@ -293,7 +293,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   ASSERT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n \n@@ -340,7 +340,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   ASSERT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n \n@@ -387,7 +387,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n }\n@@ -422,7 +422,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n }\n@@ -456,7 +456,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   EXPECT_THAT(\n       RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n@@ -502,7 +502,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n }\n@@ -538,7 +538,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   EXPECT_THAT(\n       RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n@@ -582,7 +582,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n }\n@@ -621,7 +621,7 @@ ENTRY entry_computation {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n }\n@@ -657,7 +657,7 @@ ENTRY entry_computation {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n }\n@@ -692,7 +692,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n }\n@@ -724,7 +724,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(\n@@ -769,7 +769,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   // We can nest the fusion including the broadcast.\n-  EXPECT_TRUE(NestGemmFusion(compute_capability_, &mlir_context_)\n+  EXPECT_TRUE(NestGemmFusion(device_description_, &mlir_context_)\n                   .Run(module.get())\n                   .ok());\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n@@ -811,7 +811,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   // We can nest the fusion including the broadcast.\n-  EXPECT_TRUE(NestGemmFusion(compute_capability_, &mlir_context_)\n+  EXPECT_TRUE(NestGemmFusion(device_description_, &mlir_context_)\n                   .Run(module.get())\n                   .ok());\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n@@ -855,7 +855,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(\n@@ -895,7 +895,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n@@ -946,7 +946,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n@@ -997,7 +997,7 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(\n@@ -1033,7 +1033,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(\n@@ -1070,7 +1070,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(\n@@ -1107,7 +1107,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n@@ -1146,7 +1146,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   // Checks that transpose is on rank 3 tensor from hoisting bitcast1, not rank\n@@ -1185,7 +1185,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(\n@@ -1221,7 +1221,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(\n@@ -1258,7 +1258,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n@@ -1293,7 +1293,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(\n@@ -1330,7 +1330,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   TF_ASSERT_OK(verifier().Run(module.get()).status());\n   EXPECT_THAT(\n@@ -1371,7 +1371,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   EXPECT_THAT(\n       RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n@@ -1422,7 +1422,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   EXPECT_THAT(\n       RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n@@ -1470,7 +1470,7 @@ ENTRY e {\n                           ParseAndReturnVerifiedModule(\n                               absl::Substitute(hlo, HloOpcodeString(opcode))));\n   EXPECT_THAT(\n-      NestGemmFusion(compute_capability_, &mlir_context_).Run(module.get()),\n+      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   EXPECT_THAT(\n       RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"("
        }
    ],
    "stats": {
        "total": 213,
        "additions": 139,
        "deletions": 74
    }
}