{
    "author": "olegshyshkov",
    "message": "[XLA:GPU] Fix b_scale shape in dot_scaled.\n\nPiperOrigin-RevId: 834304041",
    "sha": "a25e51c3cae99ba9f76a1423b48ce0d8a4be43ba",
    "files": [
        {
            "sha": "6ccec39cc26835f982d4d54e5b4590aef78a5df7",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_convert_unsupported_types.mlir",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a25e51c3cae99ba9f76a1423b48ce0d8a4be43ba/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_unsupported_types.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a25e51c3cae99ba9f76a1423b48ce0d8a4be43ba/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_unsupported_types.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_unsupported_types.mlir?ref=a25e51c3cae99ba9f76a1423b48ce0d8a4be43ba",
            "patch": "@@ -25,7 +25,8 @@ module {\n     // CHECK: %[[arg_3:.*]] = xtile.extract %arg3[%[[C_0]], %[[C_0]]] [1, 16] [1, 1] : memref<16x64xi8, #triton_xla.layout<[1, 0]>> -> tensor<1x16xi8>\n     %16 = arith.bitcast %extracted_tile_0 : tensor<16x1xf8E8M0FNU> to tensor<16x1xi8>\n     %17 = arith.bitcast %extracted_tile_2 : tensor<1x16xf8E8M0FNU> to tensor<1x16xi8>\n-    %18 = tt.dot_scaled %extracted_tile scale %16, %extracted_tile_1 scale %17, %cst lhs = e4m3 rhs = e4m3 {fastMath = true} : tensor<16x32xf8E4M3FN>, tensor<16x1xi8> * tensor<32x16xf8E4M3FN>, tensor<1x16xi8> -> tensor<16x16xf32>\n+    %18 = tt.trans %17 {order = array<i32: 1, 0>} : tensor<1x16xi8> -> tensor<16x1xi8>\n+    %19 = tt.dot_scaled %extracted_tile scale %16, %extracted_tile_1 scale %18, %cst lhs = e4m3 rhs = e4m3 {fastMath = true} : tensor<16x32xf8E4M3FN>, tensor<16x1xi8> * tensor<32x16xf8E4M3FN>, tensor<16x1xi8> -> tensor<16x16xf32>\n     xtile.return\n   }\n }"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}