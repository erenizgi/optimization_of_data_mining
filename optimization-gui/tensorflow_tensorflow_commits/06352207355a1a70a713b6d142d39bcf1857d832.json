{
    "author": "tensorflower-gardener",
    "message": "Integrate LLVM at llvm/llvm-project@f3b712f6e4e9\n\nUpdates LLVM usage to match\n[f3b712f6e4e9](https://github.com/llvm/llvm-project/commit/f3b712f6e4e9)\n\nPiperOrigin-RevId: 808676531",
    "sha": "06352207355a1a70a713b6d142d39bcf1857d832",
    "files": [
        {
            "sha": "7d392b5bd2999cd2527f0624e4d0dc53ab08dddb",
            "filename": "tensorflow/compiler/mlir/lite/integrations/python/mlir/_mlir_libs/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 13,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06352207355a1a70a713b6d142d39bcf1857d832/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fintegrations%2Fpython%2Fmlir%2F_mlir_libs%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06352207355a1a70a713b6d142d39bcf1857d832/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fintegrations%2Fpython%2Fmlir%2F_mlir_libs%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fintegrations%2Fpython%2Fmlir%2F_mlir_libs%2FBUILD?ref=06352207355a1a70a713b6d142d39bcf1857d832",
            "patch": "@@ -38,22 +38,9 @@ pybind_extension(\n         \"@llvm-project//mlir:lib/Bindings/Python/MainModule.cpp\",\n     ],\n     copts = COPTS,\n-    pytype_srcs = [\n-        \":_mlirPyi\",\n-    ],\n     deps = [\n         \"@llvm-project//mlir:MLIRBindingsPythonCore\",\n         \"@llvm-project//mlir:MLIRBindingsPythonNanobindHeaders\",\n         \"@nanobind\",\n     ],\n )\n-\n-symlink_files(\n-    name = \"_mlirPyi\",\n-    srcs = [\n-        \"@llvm-project//mlir/python:IRPyIFiles\",\n-        \"@llvm-project//mlir/python:PassManagerPyIFiles\",\n-    ],\n-    dst = \"_mlir\",\n-    flatten = True,\n-)"
        },
        {
            "sha": "0ef880db89fd6830157857ed463e4d6e72180b65",
            "filename": "tensorflow/compiler/mlir/lite/transforms/lower_quant_annotations_pass.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06352207355a1a70a713b6d142d39bcf1857d832/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Flower_quant_annotations_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06352207355a1a70a713b6d142d39bcf1857d832/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Flower_quant_annotations_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Flower_quant_annotations_pass.cc?ref=06352207355a1a70a713b6d142d39bcf1857d832",
            "patch": "@@ -109,7 +109,6 @@ class RewriteQuantizeCompositeOp\n                                 /*qtype=*/TypeAttr::get(output_type));\n \n     rewriter.replaceAllOpUsesWith(op, tfl_quantize_op.getOutput());\n-    rewriter.eraseOp(op);\n     return success();\n   }\n };\n@@ -247,7 +246,6 @@ class RewriteDequantizeCompositeOp\n         TFL::DequantizeOp::create(rewriter, composite_op.getLoc(), output_type,\n                                   /*input=*/tfl_quantize_input);\n     rewriter.replaceAllOpUsesWith(composite_op, tfl_dequantize_op.getOutput());\n-    rewriter.eraseOp(composite_op);\n \n     return success();\n   }\n@@ -321,8 +319,6 @@ class RewriteFakeQuantCompositeOp\n         rewriter, op.getLoc(), output_type, /*input=*/tfl_quantize_op);\n \n     rewriter.replaceAllOpUsesWith(op, tfl_dequantize_op.getOutput());\n-    rewriter.eraseOp(op);\n-\n     return success();\n   }\n };\n@@ -333,7 +329,6 @@ class RemovePreventGradient : public OpRewritePattern<TF::PreventGradientOp> {\n   LogicalResult matchAndRewrite(TF::PreventGradientOp op,\n                                 PatternRewriter& rewriter) const final {\n     rewriter.replaceAllOpUsesWith(op, op.getInput());\n-    rewriter.eraseOp(op);\n     return success();\n   }\n };\n@@ -344,7 +339,6 @@ class RemoveIdentity : public OpRewritePattern<TF::IdentityOp> {\n   LogicalResult matchAndRewrite(TF::IdentityOp op,\n                                 PatternRewriter& rewriter) const final {\n     rewriter.replaceAllOpUsesWith(op, op.getInput());\n-    rewriter.eraseOp(op);\n     return success();\n   }\n };"
        },
        {
            "sha": "a7198bd2aa210e363b63547989b77d85652c7ab0",
            "filename": "third_party/xla/third_party/llvm/generated.patch",
            "status": "modified",
            "additions": 364,
            "deletions": 1151,
            "changes": 1515,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch?ref=06352207355a1a70a713b6d142d39bcf1857d832",
            "patch": "@@ -1,1001 +1,394 @@\n Auto generated patch. Do not edit or delete it, even if empty.\n-diff -ruN --strip-trailing-cr a/clang/include/clang/Analysis/FlowSensitive/StorageLocation.h b/clang/include/clang/Analysis/FlowSensitive/StorageLocation.h\n---- a/clang/include/clang/Analysis/FlowSensitive/StorageLocation.h\n-+++ b/clang/include/clang/Analysis/FlowSensitive/StorageLocation.h\n-@@ -17,7 +17,6 @@\n- #include \"clang/AST/Decl.h\"\n- #include \"clang/AST/Type.h\"\n- #include \"llvm/ADT/DenseMap.h\"\n--#include \"llvm/ADT/StringRef.h\"\n- #include \"llvm/Support/Debug.h\"\n- #include <cassert>\n+diff -ruN --strip-trailing-cr a/clang/lib/CodeGen/CGExpr.cpp b/clang/lib/CodeGen/CGExpr.cpp\n+--- a/clang/lib/CodeGen/CGExpr.cpp\n++++ b/clang/lib/CodeGen/CGExpr.cpp\n+@@ -6496,11 +6496,8 @@\n+     SanitizerDebugLocation SanScope(this, {CheckOrdinal}, CheckHandler);\n+     EmitSanitizerStatReport(llvm::SanStat_CFI_ICall);\n+ \n+-    llvm::Metadata *MD;\n+-    if (CGM.getCodeGenOpts().SanitizeCfiICallGeneralizePointers)\n+-      MD = CGM.CreateMetadataIdentifierGeneralized(QualType(FnType, 0));\n+-    else\n+-      MD = CGM.CreateMetadataIdentifierForType(QualType(FnType, 0));\n++    llvm::Metadata *MD =\n++        CGM.CreateMetadataIdentifierForFnType(QualType(FnType, 0));\n+ \n+     llvm::Value *TypeId = llvm::MetadataAsValue::get(getLLVMContext(), MD);\n+ \n+diff -ruN --strip-trailing-cr a/clang/lib/CodeGen/CodeGenModule.cpp b/clang/lib/CodeGen/CodeGenModule.cpp\n+--- a/clang/lib/CodeGen/CodeGenModule.cpp\n++++ b/clang/lib/CodeGen/CodeGenModule.cpp\n+@@ -2339,12 +2339,28 @@\n+   return llvm::ConstantInt::get(Int64Ty, llvm::MD5Hash(MDS->getString()));\n+ }\n  \n-@@ -153,11 +152,6 @@\n-     return {SyntheticFields.begin(), SyntheticFields.end()};\n-   }\n+-// Generalize pointer types to a void pointer with the qualifiers of the\n+-// originally pointed-to type, e.g. 'const char *' and 'char * const *'\n+-// generalize to 'const void *' while 'char *' and 'const char **' generalize to\n+-// 'void *'.\n+-static QualType GeneralizeType(ASTContext &Ctx, QualType Ty) {\n+-  if (!Ty->isPointerType())\n++static QualType GeneralizeTransparentUnion(QualType Ty) {\n++  const RecordType *UT = Ty->getAsUnionType();\n++  if (!UT)\n++    return Ty;\n++  const RecordDecl *UD = UT->getOriginalDecl()->getDefinitionOrSelf();\n++  if (!UD->hasAttr<TransparentUnionAttr>())\n++    return Ty;\n++  for (const auto *it : UD->fields()) {\n++    return it->getType();\n++  }\n++  return Ty;\n++}\n++\n++// If `GeneralizePointers` is true, generalizes types to a void pointer with the\n++// qualifiers of the originally pointed-to type, e.g. 'const char *' and 'char *\n++// const *' generalize to 'const void *' while 'char *' and 'const char **'\n++// generalize to 'void *'.\n++static QualType GeneralizeType(ASTContext &Ctx, QualType Ty,\n++                               bool GeneralizePointers) {\n++  Ty = GeneralizeTransparentUnion(Ty);\n++\n++  if (!GeneralizePointers || !Ty->isPointerType())\n+     return Ty;\n  \n--  /// Add a synthetic field, if none by that name is already present.\n--  void addSyntheticField(llvm::StringRef Name, StorageLocation &Loc) {\n--    SyntheticFields.insert({Name, &Loc});\n--  }\n--\n-   /// Changes the child storage location for a field `D` of reference type.\n-   /// All other fields cannot change their storage location and always retain\n-   /// the storage location passed to the `RecordStorageLocation` constructor.\n-@@ -170,11 +164,6 @@\n-     Children[&D] = Loc;\n-   }\n+   return Ctx.getPointerType(\n+@@ -2353,26 +2369,29 @@\n+ }\n  \n--  /// Add a child storage location for a field `D`, if not already present.\n--  void addChild(const ValueDecl &D, StorageLocation *Loc) {\n--    Children.insert({&D, Loc});\n--  }\n--\n-   llvm::iterator_range<FieldToLoc::const_iterator> children() const {\n-     return {Children.begin(), Children.end()};\n-   }\n-diff -ruN --strip-trailing-cr a/clang/lib/Analysis/FlowSensitive/Transfer.cpp b/clang/lib/Analysis/FlowSensitive/Transfer.cpp\n---- a/clang/lib/Analysis/FlowSensitive/Transfer.cpp\n-+++ b/clang/lib/Analysis/FlowSensitive/Transfer.cpp\n-@@ -20,17 +20,14 @@\n- #include \"clang/AST/OperationKinds.h\"\n- #include \"clang/AST/Stmt.h\"\n- #include \"clang/AST/StmtVisitor.h\"\n--#include \"clang/AST/Type.h\"\n- #include \"clang/Analysis/FlowSensitive/ASTOps.h\"\n- #include \"clang/Analysis/FlowSensitive/AdornedCFG.h\"\n- #include \"clang/Analysis/FlowSensitive/DataflowAnalysisContext.h\"\n- #include \"clang/Analysis/FlowSensitive/DataflowEnvironment.h\"\n- #include \"clang/Analysis/FlowSensitive/NoopAnalysis.h\"\n- #include \"clang/Analysis/FlowSensitive/RecordOps.h\"\n--#include \"clang/Analysis/FlowSensitive/StorageLocation.h\"\n- #include \"clang/Analysis/FlowSensitive/Value.h\"\n- #include \"clang/Basic/Builtins.h\"\n--#include \"clang/Basic/LLVM.h\"\n- #include \"clang/Basic/OperatorKinds.h\"\n- #include \"llvm/Support/Casting.h\"\n- #include <assert.h>\n-@@ -290,7 +287,7 @@\n-     }\n+ // Apply type generalization to a FunctionType's return and argument types\n+-static QualType GeneralizeFunctionType(ASTContext &Ctx, QualType Ty) {\n++static QualType GeneralizeFunctionType(ASTContext &Ctx, QualType Ty,\n++                                       bool GeneralizePointers) {\n+   if (auto *FnType = Ty->getAs<FunctionProtoType>()) {\n+     SmallVector<QualType, 8> GeneralizedParams;\n+     for (auto &Param : FnType->param_types())\n+-      GeneralizedParams.push_back(GeneralizeType(Ctx, Param));\n++      GeneralizedParams.push_back(\n++          GeneralizeType(Ctx, Param, GeneralizePointers));\n+ \n+-    return Ctx.getFunctionType(GeneralizeType(Ctx, FnType->getReturnType()),\n+-                               GeneralizedParams, FnType->getExtProtoInfo());\n++    return Ctx.getFunctionType(\n++        GeneralizeType(Ctx, FnType->getReturnType(), GeneralizePointers),\n++        GeneralizedParams, FnType->getExtProtoInfo());\n    }\n  \n--  void VisitCastExpr(const CastExpr *S) {\n-+  void VisitImplicitCastExpr(const ImplicitCastExpr *S) {\n-     const Expr *SubExpr = S->getSubExpr();\n-     assert(SubExpr != nullptr);\n+   if (auto *FnType = Ty->getAs<FunctionNoProtoType>())\n+     return Ctx.getFunctionNoProtoType(\n+-        GeneralizeType(Ctx, FnType->getReturnType()));\n++        GeneralizeType(Ctx, FnType->getReturnType(), GeneralizePointers));\n  \n-@@ -320,60 +317,6 @@\n-       break;\n-     }\n- \n--    case CK_BaseToDerived: {\n--      // This is a cast of (single-layer) pointer or reference to a record type.\n--      // We should now model the fields for the derived type.\n--\n--      // Get the RecordStorageLocation for the record object underneath.\n--      RecordStorageLocation *Loc = nullptr;\n--      if (S->getType()->isPointerType()) {\n--        auto *PV = Env.get<PointerValue>(*SubExpr);\n--        assert(PV != nullptr);\n--        if (PV == nullptr)\n--          break;\n--        Loc = cast<RecordStorageLocation>(&PV->getPointeeLoc());\n--      } else {\n--        assert(S->getType()->isRecordType());\n--        if (SubExpr->isGLValue()) {\n--          Loc = Env.get<RecordStorageLocation>(*SubExpr);\n--        } else {\n--          Loc = &Env.getResultObjectLocation(*SubExpr);\n--        }\n--      }\n--      if (!Loc) {\n--        // Nowhere to add children or propagate from, so we're done.\n--        break;\n--      }\n--\n--      // Get the derived record type underneath the reference or pointer.\n--      QualType Derived = S->getType().getNonReferenceType();\n--      if (Derived->isPointerType()) {\n--        Derived = Derived->getPointeeType();\n--      }\n--\n--      // Add children to the storage location for fields (including synthetic\n--      // fields) of the derived type and initialize their values.\n--      for (const FieldDecl *Field :\n--           Env.getDataflowAnalysisContext().getModeledFields(Derived)) {\n--        assert(Field != nullptr);\n--        QualType FieldType = Field->getType();\n--        if (FieldType->isReferenceType()) {\n--          Loc->addChild(*Field, nullptr);\n--        } else {\n--          Loc->addChild(*Field, &Env.createStorageLocation(FieldType));\n--        }\n--\n--        for (const auto &Entry :\n--             Env.getDataflowAnalysisContext().getSyntheticFields(Derived)) {\n--          Loc->addSyntheticField(Entry.getKey(),\n--                                 Env.createStorageLocation(Entry.getValue()));\n--        }\n--      }\n--      Env.initializeFieldsWithValues(*Loc, Derived);\n--\n--      // Fall through to propagate SubExpr's StorageLocation to the CastExpr.\n--      [[fallthrough]];\n--    }\n-     case CK_IntegralCast:\n-       // FIXME: This cast creates a new integral value from the\n-       // subexpression. But, because we don't model integers, we don't\n-@@ -381,9 +324,10 @@\n-       // modeling is added, then update this code to create a fresh location and\n-       // value.\n-     case CK_UncheckedDerivedToBase:\n--    case CK_DerivedToBase:\n-     case CK_ConstructorConversion:\n-     case CK_UserDefinedConversion:\n-+      // FIXME: Add tests that excercise CK_UncheckedDerivedToBase,\n-+      // CK_ConstructorConversion, and CK_UserDefinedConversion.\n-     case CK_NoOp: {\n-       // FIXME: Consider making `Environment::getStorageLocation` skip noop\n-       // expressions (this and other similar expressions in the file) instead\n-@@ -740,6 +684,15 @@\n-     propagateValue(*SubExpr, *S, Env);\n-   }\n+   llvm_unreachable(\"Encountered unknown FunctionType\");\n+ }\n  \n-+  void VisitCXXStaticCastExpr(const CXXStaticCastExpr *S) {\n-+    if (S->getCastKind() == CK_NoOp) {\n-+      const Expr *SubExpr = S->getSubExpr();\n-+      assert(SubExpr != nullptr);\n-+\n-+      propagateValueOrStorageLocation(*SubExpr, *S, Env);\n-+    }\n-+  }\n+ llvm::ConstantInt *CodeGenModule::CreateKCFITypeId(QualType T, StringRef Salt) {\n+-  if (getCodeGenOpts().SanitizeCfiICallGeneralizePointers)\n+-    T = GeneralizeFunctionType(getContext(), T);\n++  T = GeneralizeFunctionType(\n++      getContext(), T, getCodeGenOpts().SanitizeCfiICallGeneralizePointers);\n+   if (auto *FnType = T->getAs<FunctionProtoType>())\n+     T = getContext().getFunctionType(\n+         FnType->getReturnType(), FnType->getParamTypes(),\n+@@ -3041,9 +3060,14 @@\n+   if (isa<CXXMethodDecl>(FD) && !cast<CXXMethodDecl>(FD)->isStatic())\n+     return;\n+ \n+-  llvm::Metadata *MD = CreateMetadataIdentifierForType(FD->getType());\n++  QualType FnType = GeneralizeFunctionType(getContext(), FD->getType(),\n++                                           /*GeneralizePointers=*/false);\n++  llvm::Metadata *MD = CreateMetadataIdentifierForType(FnType);\n+   F->addTypeMetadata(0, MD);\n+-  F->addTypeMetadata(0, CreateMetadataIdentifierGeneralized(FD->getType()));\n +\n-   void VisitConditionalOperator(const ConditionalOperator *S) {\n-     const Environment *TrueEnv = StmtToEnv.getEnvironment(*S->getTrueExpr());\n-     const Environment *FalseEnv = StmtToEnv.getEnvironment(*S->getFalseExpr());\n-diff -ruN --strip-trailing-cr a/clang/lib/AST/ASTContext.cpp b/clang/lib/AST/ASTContext.cpp\n---- a/clang/lib/AST/ASTContext.cpp\n-+++ b/clang/lib/AST/ASTContext.cpp\n-@@ -5316,7 +5316,8 @@\n-   }\n- \n-   llvm::FoldingSetNodeID ID;\n--  TypedefType::Profile(ID, Keyword, Qualifier, Decl, UnderlyingType);\n-+  TypedefType::Profile(ID, Keyword, Qualifier, Decl,\n-+                       *TypeMatchesDeclOrNone ? QualType() : UnderlyingType);\n- \n-   void *InsertPos = nullptr;\n-   if (FoldingSetPlaceholder<TypedefType> *Placeholder =\n-diff -ruN --strip-trailing-cr a/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp b/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp\n---- a/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp\n-+++ b/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp\n-@@ -9,25 +9,17 @@\n- #include \"TestingSupport.h\"\n- #include \"clang/AST/ASTContext.h\"\n- #include \"clang/AST/Decl.h\"\n--#include \"clang/AST/Expr.h\"\n--#include \"clang/AST/ExprCXX.h\"\n--#include \"clang/AST/OperationKinds.h\"\n--#include \"clang/ASTMatchers/ASTMatchFinder.h\"\n- #include \"clang/ASTMatchers/ASTMatchers.h\"\n--#include \"clang/Analysis/FlowSensitive/DataflowAnalysis.h\"\n- #include \"clang/Analysis/FlowSensitive/DataflowAnalysisContext.h\"\n- #include \"clang/Analysis/FlowSensitive/DataflowEnvironment.h\"\n- #include \"clang/Analysis/FlowSensitive/NoopAnalysis.h\"\n--#include \"clang/Analysis/FlowSensitive/NoopLattice.h\"\n- #include \"clang/Analysis/FlowSensitive/RecordOps.h\"\n- #include \"clang/Analysis/FlowSensitive/StorageLocation.h\"\n- #include \"clang/Analysis/FlowSensitive/Value.h\"\n- #include \"clang/Basic/LangStandard.h\"\n- #include \"clang/Testing/TestAST.h\"\n- #include \"llvm/ADT/SmallVector.h\"\n--#include \"llvm/ADT/StringMap.h\"\n- #include \"llvm/ADT/StringRef.h\"\n--#include \"llvm/Support/Casting.h\"\n- #include \"llvm/Testing/Support/Error.h\"\n- #include \"gmock/gmock.h\"\n- #include \"gtest/gtest.h\"\n-@@ -35,7 +27,6 @@\n- #include <string>\n- #include <string_view>\n- #include <utility>\n--#include <vector>\n- \n- namespace clang {\n- namespace dataflow {\n-@@ -3550,7 +3541,7 @@\n-   testFunction(Code, \"noexceptTarget\");\n++  QualType GenPtrFnType = GeneralizeFunctionType(getContext(), FD->getType(),\n++                                                 /*GeneralizePointers=*/true);\n++  F->addTypeMetadata(0, CreateMetadataIdentifierGeneralized(GenPtrFnType));\n+ \n+   // Emit a hash-based bit set entry for cross-DSO calls.\n+   if (CodeGenOpts.SanitizeCfiCrossDso)\n+@@ -7934,6 +7958,15 @@\n+   return InternalId;\n  }\n  \n--TEST(TransferTest, StaticCastNoOp) {\n-+TEST(TransferTest, StaticCast) {\n-   std::string Code = R\"(\n-     void target(int Foo) {\n-       int Bar = static_cast<int>(Foo);\n-@@ -3570,13 +3561,6 @@\n-         const ValueDecl *BarDecl = findValueDecl(ASTCtx, \"Bar\");\n-         ASSERT_THAT(BarDecl, NotNull());\n- \n--        const auto *Cast = ast_matchers::selectFirst<CXXStaticCastExpr>(\n--            \"cast\",\n--            ast_matchers::match(ast_matchers::cxxStaticCastExpr().bind(\"cast\"),\n--                                ASTCtx));\n--        ASSERT_THAT(Cast, NotNull());\n--        ASSERT_EQ(Cast->getCastKind(), CK_NoOp);\n--\n-         const auto *FooVal = Env.getValue(*FooDecl);\n-         const auto *BarVal = Env.getValue(*BarDecl);\n-         EXPECT_TRUE(isa<IntegerValue>(FooVal));\n-@@ -3585,268 +3569,6 @@\n-       });\n++llvm::Metadata *CodeGenModule::CreateMetadataIdentifierForFnType(QualType T) {\n++  assert(isa<FunctionType>(T));\n++  T = GeneralizeFunctionType(\n++      getContext(), T, getCodeGenOpts().SanitizeCfiICallGeneralizePointers);\n++  if (getCodeGenOpts().SanitizeCfiICallGeneralizePointers)\n++    return CreateMetadataIdentifierGeneralized(T);\n++  return CreateMetadataIdentifierForType(T);\n++}\n++\n+ llvm::Metadata *CodeGenModule::CreateMetadataIdentifierForType(QualType T) {\n+   return CreateMetadataIdentifierImpl(T, MetadataIdMap, \"\");\n+ }\n+@@ -7944,8 +7977,8 @@\n  }\n  \n--TEST(TransferTest, StaticCastBaseToDerived) {\n--  std::string Code = R\"cc(\n--    struct Base {\n--      char C;\n--    };\n--    struct Intermediate : public Base {\n--      bool B;\n--    };\n--    struct Derived : public Intermediate {\n--      int I;\n--    };\n--    Base& getBaseRef();\n--    void target(Base* BPtr) {\n--      Derived* DPtr = static_cast<Derived*>(BPtr);\n--      DPtr->C;\n--      DPtr->B;\n--      DPtr->I;\n--      Derived& DRef = static_cast<Derived&>(*BPtr);\n--      DRef.C;\n--      DRef.B;\n--      DRef.I;\n--      Derived& DRefFromFunc = static_cast<Derived&>(getBaseRef());\n--      DRefFromFunc.C;\n--      DRefFromFunc.B;\n--      DRefFromFunc.I;\n--      // [[p]]\n--    }\n--  )cc\";\n--  runDataflow(\n--      Code,\n--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,\n--         ASTContext &ASTCtx) {\n--        ASSERT_THAT(Results.keys(), UnorderedElementsAre(\"p\"));\n--        const Environment &Env = getEnvironmentAtAnnotation(Results, \"p\");\n--\n--        const ValueDecl *BPtrDecl = findValueDecl(ASTCtx, \"BPtr\");\n--        ASSERT_THAT(BPtrDecl, NotNull());\n--\n--        const ValueDecl *DPtrDecl = findValueDecl(ASTCtx, \"DPtr\");\n--        ASSERT_THAT(DPtrDecl, NotNull());\n--\n--        const ValueDecl *DRefDecl = findValueDecl(ASTCtx, \"DRef\");\n--        ASSERT_THAT(DRefDecl, NotNull());\n--\n--        const ValueDecl *DRefFromFuncDecl =\n--            findValueDecl(ASTCtx, \"DRefFromFunc\");\n--        ASSERT_THAT(DRefFromFuncDecl, NotNull());\n--\n--        const auto *Cast = ast_matchers::selectFirst<CXXStaticCastExpr>(\n--            \"cast\",\n--            ast_matchers::match(ast_matchers::cxxStaticCastExpr().bind(\"cast\"),\n--                                ASTCtx));\n--        ASSERT_THAT(Cast, NotNull());\n--        ASSERT_EQ(Cast->getCastKind(), CK_BaseToDerived);\n--\n--        EXPECT_EQ(Env.getValue(*BPtrDecl), Env.getValue(*DPtrDecl));\n--        EXPECT_EQ(&Env.get<PointerValue>(*BPtrDecl)->getPointeeLoc(),\n--                  Env.getStorageLocation(*DRefDecl));\n--        // For DRefFromFunc, not crashing when analyzing the field accesses is\n--        // enough.\n--      });\n--}\n--\n--TEST(TransferTest, ExplicitDerivedToBaseCast) {\n--  std::string Code = R\"cc(\n--    struct Base {};\n--    struct Derived : public Base {};\n--    void target(Derived D) {\n--      (Base*)&D;\n--      // [[p]]\n--    }\n--)cc\";\n--  runDataflow(\n--      Code,\n--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,\n--         ASTContext &ASTCtx) {\n--        ASSERT_THAT(Results.keys(), UnorderedElementsAre(\"p\"));\n--        const Environment &Env = getEnvironmentAtAnnotation(Results, \"p\");\n--\n--        auto *Cast = ast_matchers::selectFirst<ImplicitCastExpr>(\n--            \"cast\", ast_matchers::match(\n--                        ast_matchers::implicitCastExpr().bind(\"cast\"), ASTCtx));\n--        ASSERT_THAT(Cast, NotNull());\n--        ASSERT_EQ(Cast->getCastKind(), CK_DerivedToBase);\n--\n--        auto *AddressOf = ast_matchers::selectFirst<UnaryOperator>(\n--            \"addressof\",\n--            ast_matchers::match(ast_matchers::unaryOperator().bind(\"addressof\"),\n--                                ASTCtx));\n--        ASSERT_THAT(AddressOf, NotNull());\n--        ASSERT_EQ(AddressOf->getOpcode(), UO_AddrOf);\n--\n--        EXPECT_EQ(Env.getValue(*Cast), Env.getValue(*AddressOf));\n--      });\n--}\n--\n--TEST(TransferTest, ConstructorConversion) {\n--  std::string Code = R\"cc(\n--    struct Base {};\n--    struct Derived : public Base {};\n--    void target(Derived D) {\n--      Base B = (Base)D;\n--      // [[p]]\n--    }\n--)cc\";\n--  runDataflow(\n--      Code,\n--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,\n--         ASTContext &ASTCtx) {\n--        ASSERT_THAT(Results.keys(), UnorderedElementsAre(\"p\"));\n--        const Environment &Env = getEnvironmentAtAnnotation(Results, \"p\");\n--\n--        auto *Cast = ast_matchers::selectFirst<CStyleCastExpr>(\n--            \"cast\", ast_matchers::match(\n--                        ast_matchers::cStyleCastExpr().bind(\"cast\"), ASTCtx));\n--        ASSERT_THAT(Cast, NotNull());\n--        ASSERT_EQ(Cast->getCastKind(), CK_ConstructorConversion);\n--\n--        auto &DLoc = getLocForDecl<StorageLocation>(ASTCtx, Env, \"D\");\n--        auto &BLoc = getLocForDecl<StorageLocation>(ASTCtx, Env, \"B\");\n--        EXPECT_NE(&BLoc, &DLoc);\n--      });\n--}\n--\n--TEST(TransferTest, UserDefinedConversion) {\n--  std::string Code = R\"cc(\n--    struct To {};\n--    struct From {\n--        operator To();\n--    };\n--    void target(From F) {\n--        To T = (To)F;\n--        // [[p]]\n--    }\n--)cc\";\n--  runDataflow(\n--      Code,\n--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,\n--         ASTContext &ASTCtx) {\n--        ASSERT_THAT(Results.keys(), UnorderedElementsAre(\"p\"));\n--        const Environment &Env = getEnvironmentAtAnnotation(Results, \"p\");\n--\n--        auto *Cast = ast_matchers::selectFirst<ImplicitCastExpr>(\n--            \"cast\", ast_matchers::match(\n--                        ast_matchers::implicitCastExpr().bind(\"cast\"), ASTCtx));\n--        ASSERT_THAT(Cast, NotNull());\n--        ASSERT_EQ(Cast->getCastKind(), CK_UserDefinedConversion);\n--\n--        auto &FLoc = getLocForDecl<StorageLocation>(ASTCtx, Env, \"F\");\n--        auto &TLoc = getLocForDecl<StorageLocation>(ASTCtx, Env, \"T\");\n--        EXPECT_NE(&TLoc, &FLoc);\n--      });\n--}\n--\n--TEST(TransferTest, ImplicitUncheckedDerivedToBaseCast) {\n--  std::string Code = R\"cc(\n--    struct Base {\n--      void method();\n--    };\n--    struct Derived : public Base {};\n--    void target(Derived D) {\n--      D.method();\n--      // [[p]]\n--    }\n--)cc\";\n--  runDataflow(\n--      Code,\n--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,\n--         ASTContext &ASTCtx) {\n--        ASSERT_THAT(Results.keys(), UnorderedElementsAre(\"p\"));\n--        const Environment &Env = getEnvironmentAtAnnotation(Results, \"p\");\n--\n--        auto *Cast = ast_matchers::selectFirst<ImplicitCastExpr>(\n--            \"cast\", ast_matchers::match(\n--                        ast_matchers::implicitCastExpr().bind(\"cast\"), ASTCtx));\n--        ASSERT_THAT(Cast, NotNull());\n--        ASSERT_EQ(Cast->getCastKind(), CK_UncheckedDerivedToBase);\n--\n--        auto &DLoc = getLocForDecl<StorageLocation>(ASTCtx, Env, \"D\");\n--        EXPECT_EQ(Env.getStorageLocation(*Cast), &DLoc);\n--      });\n--}\n--\n--TEST(TransferTest, ImplicitDerivedToBaseCast) {\n--  std::string Code = R\"cc(\n--    struct Base {};\n--    struct Derived : public Base {};\n--    void target() {\n--      Base* B = new Derived();\n--      // [[p]]\n--    }\n--)cc\";\n--  runDataflow(\n--      Code,\n--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,\n--         ASTContext &ASTCtx) {\n--        ASSERT_THAT(Results.keys(), UnorderedElementsAre(\"p\"));\n--        const Environment &Env = getEnvironmentAtAnnotation(Results, \"p\");\n--\n--        auto *Cast = ast_matchers::selectFirst<ImplicitCastExpr>(\n--            \"cast\", ast_matchers::match(\n--                        ast_matchers::implicitCastExpr().bind(\"cast\"), ASTCtx));\n--        ASSERT_THAT(Cast, NotNull());\n--        ASSERT_EQ(Cast->getCastKind(), CK_DerivedToBase);\n--\n--        auto *New = ast_matchers::selectFirst<CXXNewExpr>(\n--            \"new\", ast_matchers::match(ast_matchers::cxxNewExpr().bind(\"new\"),\n--                                       ASTCtx));\n--        ASSERT_THAT(New, NotNull());\n--\n--        EXPECT_EQ(Env.getValue(*Cast), Env.getValue(*New));\n--      });\n--}\n--\n--TEST(TransferTest, ReinterpretCast) {\n--  std::string Code = R\"cc(\n--    struct S {\n--        int I;\n--    };\n--\n--    void target(unsigned char* Bytes) {\n--        S& SRef = reinterpret_cast<S&>(Bytes);\n--        SRef.I;\n--        S* SPtr = reinterpret_cast<S*>(Bytes);\n--        SPtr->I;\n--        // [[p]]\n--    }\n--  )cc\";\n--  runDataflow(Code, [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>>\n--                           &Results,\n--                       ASTContext &ASTCtx) {\n--    ASSERT_THAT(Results.keys(), UnorderedElementsAre(\"p\"));\n--    const Environment &Env = getEnvironmentAtAnnotation(Results, \"p\");\n--    const ValueDecl *I = findValueDecl(ASTCtx, \"I\");\n--    ASSERT_THAT(I, NotNull());\n--\n--    // No particular knowledge of I's value is modeled, but for both casts,\n--    // the fields of S are modeled.\n--\n--    {\n--      auto &Loc = getLocForDecl<RecordStorageLocation>(ASTCtx, Env, \"SRef\");\n--      std::vector<const ValueDecl *> Children;\n--      for (const auto &Entry : Loc.children()) {\n--        Children.push_back(Entry.getFirst());\n--      }\n--\n--      EXPECT_THAT(Children, UnorderedElementsAre(I));\n--    }\n--\n--    {\n--      auto &Loc = cast<RecordStorageLocation>(\n--          getValueForDecl<PointerValue>(ASTCtx, Env, \"SPtr\").getPointeeLoc());\n--      std::vector<const ValueDecl *> Children;\n--      for (const auto &Entry : Loc.children()) {\n--        Children.push_back(Entry.getFirst());\n--      }\n--\n--      EXPECT_THAT(Children, UnorderedElementsAre(I));\n--    }\n--  });\n--}\n--\n- TEST(TransferTest, IntegralCast) {\n-   std::string Code = R\"(\n-     void target(int Foo) {\n-diff -ruN --strip-trailing-cr a/llvm/include/llvm/Linker/IRMover.h b/llvm/include/llvm/Linker/IRMover.h\n---- a/llvm/include/llvm/Linker/IRMover.h\n-+++ b/llvm/include/llvm/Linker/IRMover.h\n-@@ -10,6 +10,7 @@\n- #define LLVM_LINKER_IRMOVER_H\n+ llvm::Metadata *CodeGenModule::CreateMetadataIdentifierGeneralized(QualType T) {\n+-  return CreateMetadataIdentifierImpl(GeneralizeFunctionType(getContext(), T),\n+-                                      GeneralizedMetadataIdMap, \".generalized\");\n++  return CreateMetadataIdentifierImpl(T, GeneralizedMetadataIdMap,\n++                                      \".generalized\");\n+ }\n  \n- #include \"llvm/ADT/ArrayRef.h\"\n-+#include \"llvm/ADT/DenseMap.h\"\n- #include \"llvm/ADT/DenseSet.h\"\n- #include \"llvm/ADT/FunctionExtras.h\"\n- #include \"llvm/Support/Compiler.h\"\n-@@ -19,6 +20,8 @@\n- class Error;\n- class GlobalValue;\n- class Metadata;\n-+class MDNode;\n-+class NamedMDNode;\n- class Module;\n- class StructType;\n- class TrackingMDRef;\n-@@ -67,6 +70,8 @@\n-   using LazyCallback =\n-       llvm::unique_function<void(GlobalValue &GV, ValueAdder Add)>;\n+ /// Returns whether this module needs the \"all-vtables\" type identifier.\n+diff -ruN --strip-trailing-cr a/clang/lib/CodeGen/CodeGenModule.h b/clang/lib/CodeGen/CodeGenModule.h\n+--- a/clang/lib/CodeGen/CodeGenModule.h\n++++ b/clang/lib/CodeGen/CodeGenModule.h\n+@@ -1623,6 +1623,9 @@\n+   /// Generate a KCFI type identifier for T.\n+   llvm::ConstantInt *CreateKCFITypeId(QualType T, StringRef Salt);\n  \n-+  using NamedMDNodesT = DenseMap<const NamedMDNode *, DenseSet<const MDNode *>>;\n++  /// Create a metadata identifier for the given function type.\n++  llvm::Metadata *CreateMetadataIdentifierForFnType(QualType T);\n +\n-   /// Move in the provide values in \\p ValuesToLink from \\p Src.\n-   ///\n-   /// - \\p AddLazyFor is a call back that the IRMover will call when a global\n-@@ -86,6 +91,7 @@\n-   Module &Composite;\n-   IdentifiedStructTypeSet IdentifiedStructTypes;\n-   MDMapT SharedMDs; ///< A Metadata map to use for all calls to \\a move().\n-+  NamedMDNodesT NamedMDNodes; ///< Cache for IRMover::linkNamedMDNodes().\n- };\n- \n- } // End llvm namespace\n-diff -ruN --strip-trailing-cr a/llvm/lib/Linker/IRMover.cpp b/llvm/lib/Linker/IRMover.cpp\n---- a/llvm/lib/Linker/IRMover.cpp\n-+++ b/llvm/lib/Linker/IRMover.cpp\n-@@ -293,7 +293,7 @@\n-   std::unique_ptr<Module> SrcM;\n- \n-   // Lookup table to optimize IRMover::linkNamedMDNodes().\n--  DenseMap<StringRef, DenseSet<MDNode *>> NamedMDNodes;\n-+  IRMover::NamedMDNodesT &NamedMDNodes;\n- \n-   /// See IRMover::move().\n-   IRMover::LazyCallback AddLazyFor;\n-@@ -440,10 +440,12 @@\n-   IRLinker(Module &DstM, MDMapT &SharedMDs,\n-            IRMover::IdentifiedStructTypeSet &Set, std::unique_ptr<Module> SrcM,\n-            ArrayRef<GlobalValue *> ValuesToLink,\n--           IRMover::LazyCallback AddLazyFor, bool IsPerformingImport)\n--      : DstM(DstM), SrcM(std::move(SrcM)), AddLazyFor(std::move(AddLazyFor)),\n--        TypeMap(Set), GValMaterializer(*this), LValMaterializer(*this),\n--        SharedMDs(SharedMDs), IsPerformingImport(IsPerformingImport),\n-+           IRMover::LazyCallback AddLazyFor, bool IsPerformingImport,\n-+           IRMover::NamedMDNodesT &NamedMDNodes)\n-+      : DstM(DstM), SrcM(std::move(SrcM)), NamedMDNodes(NamedMDNodes),\n-+        AddLazyFor(std::move(AddLazyFor)), TypeMap(Set),\n-+        GValMaterializer(*this), LValMaterializer(*this), SharedMDs(SharedMDs),\n-+        IsPerformingImport(IsPerformingImport),\n-         Mapper(ValueMap, RF_ReuseAndMutateDistinctMDs | RF_IgnoreMissingLocals,\n-                &TypeMap, &GValMaterializer),\n-         IndirectSymbolMCID(Mapper.registerAlternateMappingContext(\n-@@ -1138,7 +1140,7 @@\n- \n-     NamedMDNode *DestNMD = DstM.getOrInsertNamedMetadata(NMD.getName());\n+   /// Create a metadata identifier for the given type. This may either be an\n+   /// MDString (for external identifiers) or a distinct unnamed MDNode (for\n+   /// internal identifiers).\n+diff -ruN --strip-trailing-cr a/clang/test/CodeGen/cfi-icall-generalize.c b/clang/test/CodeGen/cfi-icall-generalize.c\n+--- a/clang/test/CodeGen/cfi-icall-generalize.c\n++++ b/clang/test/CodeGen/cfi-icall-generalize.c\n+@@ -15,5 +15,21 @@\n+   fp(0, 0);\n+ }\n  \n--    auto &Inserted = NamedMDNodes[DestNMD->getName()];\n-+    auto &Inserted = NamedMDNodes[DestNMD];\n-     if (Inserted.empty()) {\n-       // Must be the first module, copy everything from DestNMD.\n-       Inserted.insert(DestNMD->operands().begin(), DestNMD->operands().end());\n-@@ -1683,6 +1685,6 @@\n-                     LazyCallback AddLazyFor, bool IsPerformingImport) {\n-   IRLinker TheIRLinker(Composite, SharedMDs, IdentifiedStructTypes,\n-                        std::move(Src), ValuesToLink, std::move(AddLazyFor),\n--                       IsPerformingImport);\n-+                       IsPerformingImport, NamedMDNodes);\n-   return TheIRLinker.run();\n++union Union {\n++  char *c;\n++  long *n;\n++} __attribute__((transparent_union));\n++\n++// CHECK: define{{.*}} void @uni({{.*}} !type [[TYPE2:![0-9]+]] !type [[TYPE2_GENERALIZED:![0-9]+]]\n++void uni(void (*fn)(union Union), union Union arg1) {\n++  // UNGENERALIZED: call i1 @llvm.type.test(ptr {{.*}}, metadata !\"_ZTSFvPcE\")\n++  // GENERALIZED: call i1 @llvm.type.test(ptr {{.*}}, metadata !\"_ZTSFvPvE.generalized\")\n++    fn(arg1);\n++}\n++\n+ // CHECK: [[TYPE]] = !{i64 0, !\"_ZTSFPPiPKcPS2_E\"}\n+ // CHECK: [[TYPE_GENERALIZED]] = !{i64 0, !\"_ZTSFPvPKvS_E.generalized\"}\n++\n++// CHECK: [[TYPE2]] = !{i64 0, !\"_ZTSFvPFv5UnionEPcE\"}\n++// CHECK: [[TYPE2_GENERALIZED]] = !{i64 0, !\"_ZTSFvPvS_E.generalized\"}\n++\n+diff -ruN --strip-trailing-cr a/clang/test/CodeGen/cfi-icall-normalize2.c b/clang/test/CodeGen/cfi-icall-normalize2.c\n+--- a/clang/test/CodeGen/cfi-icall-normalize2.c\n++++ b/clang/test/CodeGen/cfi-icall-normalize2.c\n+@@ -24,6 +24,20 @@\n+     fn(arg1, arg2, arg3);\n  }\n-diff -ruN --strip-trailing-cr a/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp b/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp\n---- a/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp\n-+++ b/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp\n-@@ -5574,7 +5574,23 @@\n-       if (auto *SD = dyn_cast<ScheduleData>(Data)) {\n-         SD->setScheduled(/*Scheduled=*/true);\n-         LLVM_DEBUG(dbgs() << \"SLP:   schedule \" << *SD << \"\\n\");\n--        ProcessBundleMember(SD, {});\n-+        SmallVector<std::unique_ptr<ScheduleBundle>> PseudoBundles;\n-+        SmallVector<ScheduleBundle *> Bundles;\n-+        Instruction *In = SD->getInst();\n-+        if (R.isVectorized(In)) {\n-+          ArrayRef<TreeEntry *> Entries = R.getTreeEntries(In);\n-+          for (TreeEntry *TE : Entries) {\n-+            if (!isa<ExtractValueInst, ExtractElementInst, CallBase>(In) &&\n-+                In->getNumOperands() != TE->getNumOperands())\n-+              continue;\n-+            auto &BundlePtr =\n-+                PseudoBundles.emplace_back(std::make_unique<ScheduleBundle>());\n-+            BundlePtr->setTreeEntry(TE);\n-+            BundlePtr->add(SD);\n-+            Bundles.push_back(BundlePtr.get());\n-+          }\n-+        }\n-+        ProcessBundleMember(SD, Bundles);\n-       } else {\n-         ScheduleBundle &Bundle = *cast<ScheduleBundle>(Data);\n-         Bundle.setScheduled(/*Scheduled=*/true);\n-@@ -20772,6 +20788,14 @@\n-           continue;\n-         }\n-         auto *SD = cast<ScheduleData>(SE);\n-+        if (SD->hasValidDependencies() &&\n-+            (!S.areInstructionsWithCopyableElements() ||\n-+             !S.isCopyableElement(SD->getInst())) &&\n-+            !getScheduleCopyableData(SD->getInst()).empty() && EI.UserTE &&\n-+            EI.UserTE->hasState() &&\n-+            (!EI.UserTE->hasCopyableElements() ||\n-+             !EI.UserTE->isCopyableElement(SD->getInst())))\n-+          SD->clearDirectDependencies();\n-         for (const Use &U : SD->getInst()->operands()) {\n-           unsigned &NumOps =\n-               UserOpToNumOps\n-@@ -20853,23 +20877,7 @@\n-   for (Value *V : VL) {\n-     if (S.isNonSchedulable(V))\n-       continue;\n--    // For copybales with parent nodes, which do not need to be scheduled, the\n--    // parents should not be commutative, otherwise may incorrectly handle deps\n--    // because of the potential reordering of commutative operations.\n--    if ((S.isCopyableElement(V) && EI.UserTE && !EI.UserTE->isGather() &&\n--         EI.UserTE->hasState() && EI.UserTE->doesNotNeedToSchedule() &&\n--         any_of(EI.UserTE->Scalars,\n--                [&](Value *V) {\n--                  if (isa<PoisonValue>(V))\n--                    return false;\n--                  auto *I = dyn_cast<Instruction>(V);\n--                  return isCommutative(\n--                      (I && EI.UserTE->isAltShuffle())\n--                          ? EI.UserTE->getMatchingMainOpOrAltOp(I)\n--                          : EI.UserTE->getMainOp(),\n--                      V);\n--                })) ||\n--        !extendSchedulingRegion(V, S)) {\n-+    if (!extendSchedulingRegion(V, S)) {\n-       // If the scheduling region got new instructions at the lower end (or it\n-       // is a new region for the first bundle). This makes it necessary to\n-       // recalculate all dependencies.\n-@@ -21889,6 +21897,10 @@\n-     return TryProcessInstruction(BitWidth);\n-   case Instruction::ZExt:\n-   case Instruction::SExt:\n-+    if (E.UserTreeIndex.UserTE && E.UserTreeIndex.UserTE->hasState() &&\n-+        E.UserTreeIndex.UserTE->getOpcode() == Instruction::BitCast &&\n-+        E.UserTreeIndex.UserTE->getMainOp()->getType()->isFPOrFPVectorTy())\n-+      return false;\n-     IsProfitableToDemote = true;\n-     return TryProcessInstruction(BitWidth);\n  \n-diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll b/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll\n---- a/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll\n-+++ b/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll\n-@@ -4,20 +4,15 @@\n- define i64 @test(ptr %a) {\n- ; CHECK-LABEL: define i64 @test(\n- ; CHECK-SAME: ptr [[A:%.*]]) #[[ATTR0:[0-9]+]] {\n--; CHECK-NEXT:    [[TMP1:%.*]] = add i64 0, 0\n- ; CHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr [[A]], align 4\n--; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[TMP2]], 0\n--; CHECK-NEXT:    [[TMP4:%.*]] = add i64 1, [[TMP1]]\n--; CHECK-NEXT:    [[TMP5:%.*]] = ashr i64 0, 1\n--; CHECK-NEXT:    [[TMP6:%.*]] = ashr i64 0, 0\n-+; CHECK-NEXT:    [[TMP7:%.*]] = insertelement <4 x i64> <i64 poison, i64 0, i64 0, i64 0>, i64 [[TMP2]], i32 0\n-+; CHECK-NEXT:    [[TMP3:%.*]] = add <4 x i64> zeroinitializer, [[TMP7]]\n-+; CHECK-NEXT:    [[TMP4:%.*]] = add <4 x i64> <i64 0, i64 0, i64 0, i64 1>, [[TMP3]]\n-+; CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <4 x i64> [[TMP4]], <4 x i64> poison, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison>\n-+; CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <6 x i64> [[TMP5]], <6 x i64> <i64 0, i64 0, i64 undef, i64 undef, i64 undef, i64 undef>, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 6, i32 7>\n- ; CHECK-NEXT:    br label %[[BB7:.*]]\n- ; CHECK:       [[BB7]]:\n--; CHECK-NEXT:    [[TMP8:%.*]] = phi i64 [ [[TMP3]], [[TMP0:%.*]] ]\n--; CHECK-NEXT:    [[TMP9:%.*]] = phi i64 [ 0, [[TMP0]] ]\n--; CHECK-NEXT:    [[TMP10:%.*]] = phi i64 [ [[TMP6]], [[TMP0]] ]\n--; CHECK-NEXT:    [[TMP11:%.*]] = phi i64 [ [[TMP5]], [[TMP0]] ]\n--; CHECK-NEXT:    [[TMP12:%.*]] = phi i64 [ 0, [[TMP0]] ]\n--; CHECK-NEXT:    [[TMP13:%.*]] = phi i64 [ [[TMP4]], [[TMP0]] ]\n-+; CHECK-NEXT:    [[TMP8:%.*]] = phi <6 x i64> [ [[TMP6]], [[TMP0:%.*]] ]\n- ; CHECK-NEXT:    ret i64 0\n- ;\n-   %1 = add i64 0, 0\n-diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll b/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll\n---- a/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll\n-+++ b/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll\n-@@ -0,0 +1,89 @@\n-+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5\n-+; RUN: opt -S --passes=slp-vectorizer -mtriple=x86_64-unknown-linux-gnu -slp-threshold=-10 < %s | FileCheck %s\n++union Union {\n++  char *c;\n++  long *n;\n++} __attribute__((transparent_union));\n +\n-+define void @test(ptr %0, i32 %1, i32 %2) {\n-+; CHECK-LABEL: define void @test(\n-+; CHECK-SAME: ptr [[TMP0:%.*]], i32 [[TMP1:%.*]], i32 [[TMP2:%.*]]) {\n-+; CHECK-NEXT:  [[ENTRY:.*:]]\n-+; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[TMP0]], i64 48\n-+; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP0]], i64 56\n-+; CHECK-NEXT:    [[TMP7:%.*]] = and i32 [[TMP2]], [[TMP1]]\n-+; CHECK-NEXT:    [[ADD_NARROWED_I_I:%.*]] = shl i32 [[TMP1]], 1\n-+; CHECK-NEXT:    [[TMP10:%.*]] = lshr i32 [[TMP7]], 1\n-+; CHECK-NEXT:    [[TMP18:%.*]] = zext i32 [[ADD_NARROWED_I_I]] to i64\n-+; CHECK-NEXT:    [[TMP19:%.*]] = add i64 [[TMP18]], -1\n-+; CHECK-NEXT:    [[TMP21:%.*]] = trunc i64 [[TMP19]] to i32\n-+; CHECK-NEXT:    [[TMP28:%.*]] = insertelement <2 x i32> poison, i32 [[TMP21]], i32 0\n-+; CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x i32> [[TMP28]], <2 x i32> poison, <2 x i32> zeroinitializer\n-+; CHECK-NEXT:    [[TMP12:%.*]] = and <2 x i32> [[TMP11]], splat (i32 -2)\n-+; CHECK-NEXT:    [[TMP13:%.*]] = insertelement <2 x i32> <i32 poison, i32 -2>, i32 [[TMP1]], i32 0\n-+; CHECK-NEXT:    [[TMP14:%.*]] = or <2 x i32> [[TMP13]], [[TMP12]]\n-+; CHECK-NEXT:    [[TMP15:%.*]] = xor <2 x i32> [[TMP13]], [[TMP12]]\n-+; CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> [[TMP15]], <2 x i32> <i32 0, i32 3>\n-+; CHECK-NEXT:    [[TMP17:%.*]] = load <2 x i32>, ptr [[TMP5]], align 8\n-+; CHECK-NEXT:    [[TMP32:%.*]] = insertelement <2 x i32> <i32 1, i32 poison>, i32 [[TMP1]], i32 1\n-+; CHECK-NEXT:    [[TMP33:%.*]] = and <2 x i32> [[TMP17]], [[TMP32]]\n-+; CHECK-NEXT:    call void @llvm.stackrestore.p0(ptr null)\n-+; CHECK-NEXT:    [[TMP20:%.*]] = shufflevector <2 x i32> [[TMP33]], <2 x i32> poison, <2 x i32> <i32 poison, i32 0>\n-+; CHECK-NEXT:    [[TMP34:%.*]] = insertelement <2 x i32> [[TMP20]], i32 [[TMP10]], i32 0\n-+; CHECK-NEXT:    [[TMP22:%.*]] = zext <2 x i32> [[TMP34]] to <2 x i64>\n-+; CHECK-NEXT:    [[TMP23:%.*]] = zext <2 x i32> [[TMP33]] to <2 x i64>\n-+; CHECK-NEXT:    [[TMP35:%.*]] = shl <2 x i64> [[TMP23]], splat (i64 1)\n-+; CHECK-NEXT:    [[TMP25:%.*]] = or <2 x i64> [[TMP35]], [[TMP22]]\n-+; CHECK-NEXT:    [[TMP26:%.*]] = trunc <2 x i64> [[TMP25]] to <2 x i32>\n-+; CHECK-NEXT:    [[TMP27:%.*]] = trunc <2 x i64> [[TMP25]] to <2 x i32>\n-+; CHECK-NEXT:    [[TMP24:%.*]] = tail call i32 asm sideeffect \"\", \"=r,0,~{dirflag},~{fpsr},~{flags}\"(i32 0)\n-+; CHECK-NEXT:    store <2 x i32> [[TMP16]], ptr [[TMP3]], align 16\n-+; CHECK-NEXT:    [[TMP29:%.*]] = shufflevector <2 x i32> [[TMP32]], <2 x i32> poison, <2 x i32> <i32 1, i32 1>\n-+; CHECK-NEXT:    [[TMP30:%.*]] = and <2 x i32> [[TMP29]], [[TMP26]]\n-+; CHECK-NEXT:    [[TMP31:%.*]] = or <2 x i32> [[TMP30]], [[TMP27]]\n-+; CHECK-NEXT:    store <2 x i32> [[TMP31]], ptr [[TMP5]], align 8\n-+; CHECK-NEXT:    ret void\n-+;\n-+entry:\n-+  %3 = getelementptr i8, ptr %0, i64 48\n-+  %4 = getelementptr i8, ptr %0, i64 52\n-+  %5 = getelementptr i8, ptr %0, i64 56\n-+  %6 = getelementptr i8, ptr %0, i64 60\n-+  %.pre21.i = load i32, ptr %5, align 8\n-+  %.pre23.i = load i32, ptr %6, align 4\n-+  %7 = and i32 %2, %1\n-+  %8 = and i32 %.pre21.i, 1\n-+  %9 = and i32 %1, %.pre23.i\n-+  call void @llvm.stackrestore.p0(ptr null)\n-+  %add.narrowed.i.i = shl i32 %1, 1\n-+  %10 = lshr i32 %7, 1\n-+  %11 = zext i32 %10 to i64\n-+  %12 = zext i32 %8 to i64\n-+  %reass.add1.i = shl i64 %12, 1\n-+  %13 = or i64 %reass.add1.i, %11\n-+  %14 = trunc i64 %13 to i32\n-+  %15 = zext i32 %9 to i64\n-+  %reass.add2.i = shl i64 %15, 1\n-+  %16 = or i64 %reass.add2.i, %12\n-+  %17 = trunc i64 %16 to i32\n-+  %18 = zext i32 %add.narrowed.i.i to i64\n-+  %19 = add i64 %18, -1\n-+  %20 = trunc i64 %19 to i32\n-+  %21 = trunc i64 %19 to i32\n-+  %22 = trunc i64 %13 to i32\n-+  %23 = trunc i64 %16 to i32\n-+  %24 = tail call i32 asm sideeffect \"\", \"=r,0,~{dirflag},~{fpsr},~{flags}\"(i32 0)\n-+  %25 = and i32 %20, -2\n-+  %26 = or i32 %1, %25\n-+  store i32 %26, ptr %3, align 16\n-+  %27 = and i32 %21, -2\n-+  %28 = xor i32 %27, -2\n-+  store i32 %28, ptr %4, align 4\n-+  %29 = and i32 %1, %14\n-+  %30 = or i32 %29, %22\n-+  store i32 %30, ptr %5, align 8\n-+  %31 = and i32 %1, %17\n-+  %32 = or i32 %31, %23\n-+  store i32 %32, ptr %6, align 4\n-+  ret void\n++void uni(void (*fn)(union Union), union Union arg1) {\n++    // CHECK-LABEL: define{{.*}}uni\n++    // CHECK-SAME: {{.*}}!type ![[TYPE4:[0-9]+]] !type !{{[0-9]+}}\n++    // CHECK: call i1 @llvm.type.test({{i8\\*|ptr}} {{%f|%0}}, metadata !\"_ZTSFvPu2i8E.normalized\")\n++    fn(arg1);\n +}\n +\n-+declare void @llvm.stackrestore.p0(ptr) #0\n+ // CHECK: ![[TYPE1]] = !{i64 0, !\"_ZTSFvPFvu3i32ES_E.normalized\"}\n+ // CHECK: ![[TYPE2]] = !{i64 0, !\"_ZTSFvPFvu3i32S_ES_S_E.normalized\"}\n+ // CHECK: ![[TYPE3]] = !{i64 0, !\"_ZTSFvPFvu3i32S_S_ES_S_S_E.normalized\"}\n++// CHECK: ![[TYPE4]] = !{i64 0, !\"_ZTSFvPFv5UnionEPu2i8E.normalized\"}\n +\n-+attributes #0 = { nocallback nofree nosync nounwind willreturn }\n-diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll b/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll\n---- a/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll\n-+++ b/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll\n-@@ -0,0 +1,36 @@\n-+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5\n-+; RUN: opt -S --passes=slp-vectorizer -mtriple=x86_64-unknown-linux-gnu < %s | FileCheck %s\n+diff -ruN --strip-trailing-cr a/clang/test/CodeGen/kcfi-generalize.c b/clang/test/CodeGen/kcfi-generalize.c\n+--- a/clang/test/CodeGen/kcfi-generalize.c\n++++ b/clang/test/CodeGen/kcfi-generalize.c\n+@@ -26,8 +26,23 @@\n+   fp(0, 0);\n+ }\n+ \n++union Union {\n++  char *c;\n++  long *n;\n++} __attribute__((transparent_union));\n +\n-+define i1 @test(i32 %0) {\n-+; CHECK-LABEL: define i1 @test(\n-+; CHECK-SAME: i32 [[TMP0:%.*]]) {\n-+; CHECK-NEXT:  [[ENTRY:.*:]]\n-+; CHECK-NEXT:    [[CONV22_I_I:%.*]] = sext i32 [[TMP0]] to i64\n-+; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i64 [[CONV22_I_I]] to double\n-+; CHECK-NEXT:    [[TMP2:%.*]] = fadd double [[TMP1]], 0.000000e+00\n-+; CHECK-NEXT:    [[ADD_I_I_I:%.*]] = select i1 false, double 0.000000e+00, double [[TMP2]]\n-+; CHECK-NEXT:    [[TMP3:%.*]] = bitcast double [[ADD_I_I_I]] to i64\n-+; CHECK-NEXT:    [[CMP3998_I_I:%.*]] = icmp ne i64 [[TMP3]], [[CONV22_I_I]]\n-+; CHECK-NEXT:    [[CONV22_1_I_I:%.*]] = sext i32 0 to i64\n-+; CHECK-NEXT:    [[TMP4:%.*]] = bitcast i64 [[CONV22_1_I_I]] to double\n-+; CHECK-NEXT:    [[TMP5:%.*]] = fadd double [[TMP4]], 0.000000e+00\n-+; CHECK-NEXT:    [[ADD_I_1_I_I:%.*]] = select i1 false, double 0.000000e+00, double [[TMP5]]\n-+; CHECK-NEXT:    [[TMP6:%.*]] = bitcast double [[ADD_I_1_I_I]] to i64\n-+; CHECK-NEXT:    [[CMP3998_1_I_I:%.*]] = icmp ne i64 [[TMP6]], [[CONV22_1_I_I]]\n-+; CHECK-NEXT:    ret i1 [[CMP3998_1_I_I]]\n-+;\n-+entry:\n-+  %conv22.i.i = sext i32 %0 to i64\n-+  %1 = bitcast i64 %conv22.i.i to double\n-+  %2 = fadd double %1, 0.000000e+00\n-+  %add.i.i.i = select i1 false, double 0.000000e+00, double %2\n-+  %3 = bitcast double %add.i.i.i to i64\n-+  %cmp3998.i.i = icmp ne i64 %3, %conv22.i.i\n-+  %conv22.1.i.i = sext i32 0 to i64\n-+  %4 = bitcast i64 %conv22.1.i.i to double\n-+  %5 = fadd double %4, 0.000000e+00\n-+  %add.i.1.i.i = select i1 false, double 0.000000e+00, double %5\n-+  %6 = bitcast double %add.i.1.i.i to i64\n-+  %cmp3998.1.i.i = icmp ne i64 %6, %conv22.1.i.i\n-+  ret i1 %cmp3998.1.i.i\n++// CHECK: define{{.*}} void @uni({{.*}} !kcfi_type [[TYPE4:![0-9]+]]\n++void uni(void (*fn)(union Union), union Union arg1) {\n++  // UNGENERALIZED: call {{.*}} [ \"kcfi\"(i32 -587217045) ]\n++  // GENERALIZED: call {{.*}} [ \"kcfi\"(i32 2139530422) ]\n++    fn(arg1);\n +}\n-diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll b/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll\n---- a/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll\n-+++ b/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll\n-@@ -0,0 +1,172 @@\n-+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5\n-+; RUN: opt -S --passes=slp-vectorizer -S -mtriple=i686-unknown-linux-android29 -mattr=+sse2 < %s | FileCheck %s\n +\n-+define void @test(ptr %0, i64 %1, i64 %2, i1 %3, i64 %4, i64 %5) {\n-+; CHECK-LABEL: define void @test(\n-+; CHECK-SAME: ptr [[TMP0:%.*]], i64 [[TMP1:%.*]], i64 [[TMP2:%.*]], i1 [[TMP3:%.*]], i64 [[TMP4:%.*]], i64 [[TMP5:%.*]]) #[[ATTR0:[0-9]+]] {\n-+; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP0]], i32 240\n-+; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP0]], i32 128\n-+; CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> poison, i64 [[TMP1]], i32 0\n-+; CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i64> [[TMP9]], <4 x i64> poison, <4 x i32> zeroinitializer\n-+; CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> <i64 1, i64 1, i64 1, i64 poison>, i64 [[TMP2]], i32 3\n-+; CHECK-NEXT:    [[TMP12:%.*]] = add <4 x i64> [[TMP10]], [[TMP11]]\n-+; CHECK-NEXT:    [[TMP13:%.*]] = load <2 x i64>, ptr [[TMP7]], align 4\n-+; CHECK-NEXT:    [[TMP14:%.*]] = load i64, ptr null, align 4\n-+; CHECK-NEXT:    [[TMP15:%.*]] = load <2 x i64>, ptr [[TMP8]], align 4\n-+; CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <2 x i64> [[TMP13]], <2 x i64> [[TMP15]], <6 x i32> <i32 0, i32 1, i32 poison, i32 3, i32 2, i32 2>\n-+; CHECK-NEXT:    [[TMP17:%.*]] = insertelement <6 x i64> poison, i64 [[TMP14]], i32 0\n-+; CHECK-NEXT:    [[TMP18:%.*]] = shufflevector <6 x i64> [[TMP17]], <6 x i64> poison, <6 x i32> <i32 poison, i32 poison, i32 0, i32 poison, i32 poison, i32 poison>\n-+; CHECK-NEXT:    [[TMP19:%.*]] = shufflevector <6 x i64> [[TMP16]], <6 x i64> [[TMP18]], <6 x i32> <i32 0, i32 1, i32 8, i32 3, i32 4, i32 5>\n-+; CHECK-NEXT:    [[TMP20:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> poison, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 0>\n-+; CHECK-NEXT:    [[TMP21:%.*]] = shufflevector <6 x i64> [[TMP20]], <6 x i64> <i64 0, i64 0, i64 0, i64 0, i64 0, i64 poison>, <6 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 0>\n-+; CHECK-NEXT:    [[TMP22:%.*]] = add <6 x i64> [[TMP19]], [[TMP21]]\n-+; CHECK-NEXT:    [[TMP23:%.*]] = shufflevector <2 x i64> [[TMP13]], <2 x i64> poison, <4 x i32> <i32 0, i32 1, i32 0, i32 1>\n-+; CHECK-NEXT:    [[TMP24:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> [[TMP23]], <4 x i32> <i32 0, i32 1, i32 4, i32 5>\n-+; CHECK-NEXT:    [[TMP25:%.*]] = sub <4 x i64> zeroinitializer, [[TMP24]]\n-+; CHECK-NEXT:    [[TMP26:%.*]] = sub <6 x i64> zeroinitializer, [[TMP22]]\n-+; CHECK-NEXT:    [[TMP27:%.*]] = shufflevector <6 x i64> [[TMP19]], <6 x i64> poison, <2 x i32> <i32 2, i32 2>\n-+; CHECK-NEXT:    [[TMP28:%.*]] = add <2 x i64> [[TMP27]], splat (i64 1)\n-+; CHECK-NEXT:    [[TMP29:%.*]] = ashr <2 x i64> [[TMP28]], splat (i64 14)\n-+; CHECK-NEXT:    [[TMP30:%.*]] = shufflevector <6 x i64> [[TMP26]], <6 x i64> poison, <14 x i32> <i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 poison, i32 poison>\n-+; CHECK-NEXT:    [[TMP31:%.*]] = shufflevector <4 x i64> [[TMP12]], <4 x i64> poison, <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>\n-+; CHECK-NEXT:    [[TMP32:%.*]] = shufflevector <14 x i64> [[TMP30]], <14 x i64> [[TMP31]], <14 x i32> <i32 14, i32 15, i32 16, i32 17, i32 poison, i32 poison, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 poison, i32 poison>\n-+; CHECK-NEXT:    [[TMP33:%.*]] = shufflevector <4 x i64> [[TMP25]], <4 x i64> poison, <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>\n-+; CHECK-NEXT:    [[TMP34:%.*]] = shufflevector <14 x i64> [[TMP32]], <14 x i64> [[TMP33]], <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 14, i32 15, i32 16, i32 17, i32 8, i32 9, i32 10, i32 11, i32 poison, i32 poison>\n-+; CHECK-NEXT:    [[TMP35:%.*]] = shufflevector <2 x i64> [[TMP29]], <2 x i64> poison, <14 x i32> <i32 0, i32 1, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>\n-+; CHECK-NEXT:    [[TMP36:%.*]] = shufflevector <14 x i64> [[TMP34]], <14 x i64> [[TMP35]], <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 14, i32 15>\n-+; CHECK-NEXT:    br i1 [[TMP3]], label %[[BB52:.*]], label %[[BB37:.*]]\n-+; CHECK:       [[BB37]]:\n-+; CHECK-NEXT:    [[TMP38:%.*]] = add <4 x i64> [[TMP10]], splat (i64 1)\n-+; CHECK-NEXT:    [[TMP39:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> poison, <2 x i32> zeroinitializer\n-+; CHECK-NEXT:    [[TMP40:%.*]] = add <2 x i64> [[TMP39]], splat (i64 1)\n-+; CHECK-NEXT:    [[TMP41:%.*]] = lshr <2 x i64> [[TMP39]], splat (i64 1)\n-+; CHECK-NEXT:    [[TMP42:%.*]] = add <2 x i64> [[TMP40]], [[TMP41]]\n-+; CHECK-NEXT:    [[TMP43:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> [[TMP11]], <10 x i32> <i32 0, i32 7, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>\n-+; CHECK-NEXT:    [[TMP44:%.*]] = insertelement <10 x i64> [[TMP43]], i64 [[TMP4]], i32 6\n-+; CHECK-NEXT:    [[TMP45:%.*]] = insertelement <10 x i64> [[TMP44]], i64 [[TMP5]], i32 7\n-+; CHECK-NEXT:    [[TMP46:%.*]] = shufflevector <4 x i64> [[TMP38]], <4 x i64> poison, <10 x i32> <i32 poison, i32 poison, i32 poison, i32 poison, i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison>\n-+; CHECK-NEXT:    [[TMP47:%.*]] = shufflevector <2 x i64> [[TMP42]], <2 x i64> poison, <10 x i32> <i32 0, i32 1, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>\n-+; CHECK-NEXT:    [[TMP48:%.*]] = shufflevector <10 x i64> [[TMP46]], <10 x i64> [[TMP47]], <10 x i32> <i32 poison, i32 poison, i32 poison, i32 poison, i32 4, i32 5, i32 6, i32 7, i32 10, i32 11>\n-+; CHECK-NEXT:    [[TMP49:%.*]] = shufflevector <10 x i64> [[TMP48]], <10 x i64> [[TMP45]], <10 x i32> <i32 10, i32 11, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 8, i32 9>\n-+; CHECK-NEXT:    [[TMP50:%.*]] = shufflevector <10 x i64> [[TMP49]], <10 x i64> poison, <14 x i32> <i32 0, i32 1, i32 0, i32 2, i32 0, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 0, i32 0>\n-+; CHECK-NEXT:    [[TMP51:%.*]] = ashr <14 x i64> [[TMP50]], splat (i64 2)\n-+; CHECK-NEXT:    br label %[[BB52]]\n-+; CHECK:       [[BB52]]:\n-+; CHECK-NEXT:    [[TMP53:%.*]] = phi <14 x i64> [ [[TMP51]], %[[BB37]] ], [ [[TMP36]], [[TMP6:%.*]] ]\n-+; CHECK-NEXT:    [[TMP54:%.*]] = extractelement <14 x i64> [[TMP53]], i32 0\n-+; CHECK-NEXT:    [[TMP55:%.*]] = extractelement <14 x i64> [[TMP53]], i32 13\n-+; CHECK-NEXT:    [[TMP56:%.*]] = or i64 [[TMP54]], [[TMP55]]\n-+; CHECK-NEXT:    [[TMP57:%.*]] = extractelement <14 x i64> [[TMP53]], i32 4\n-+; CHECK-NEXT:    [[TMP58:%.*]] = extractelement <14 x i64> [[TMP53]], i32 12\n-+; CHECK-NEXT:    [[TMP59:%.*]] = or i64 [[TMP57]], [[TMP58]]\n-+; CHECK-NEXT:    [[TMP60:%.*]] = extractelement <14 x i64> [[TMP53]], i32 1\n-+; CHECK-NEXT:    [[TMP61:%.*]] = extractelement <14 x i64> [[TMP53]], i32 2\n-+; CHECK-NEXT:    [[TMP62:%.*]] = or i64 [[TMP60]], [[TMP61]]\n-+; CHECK-NEXT:    [[TMP63:%.*]] = or i64 [[TMP59]], [[TMP56]]\n-+; CHECK-NEXT:    [[TMP64:%.*]] = extractelement <14 x i64> [[TMP53]], i32 5\n-+; CHECK-NEXT:    [[TMP65:%.*]] = extractelement <14 x i64> [[TMP53]], i32 8\n-+; CHECK-NEXT:    [[TMP66:%.*]] = or i64 [[TMP64]], [[TMP65]]\n-+; CHECK-NEXT:    [[TMP67:%.*]] = extractelement <14 x i64> [[TMP53]], i32 3\n-+; CHECK-NEXT:    [[TMP68:%.*]] = or i64 [[TMP67]], [[TMP62]]\n-+; CHECK-NEXT:    [[TMP69:%.*]] = extractelement <14 x i64> [[TMP53]], i32 9\n-+; CHECK-NEXT:    [[TMP70:%.*]] = or i64 [[TMP69]], [[TMP66]]\n-+; CHECK-NEXT:    [[TMP71:%.*]] = extractelement <14 x i64> [[TMP53]], i32 6\n-+; CHECK-NEXT:    [[TMP72:%.*]] = or i64 [[TMP71]], [[TMP70]]\n-+; CHECK-NEXT:    [[TMP73:%.*]] = or i64 [[TMP63]], [[TMP72]]\n-+; CHECK-NEXT:    [[TMP74:%.*]] = extractelement <14 x i64> [[TMP53]], i32 10\n-+; CHECK-NEXT:    [[TMP75:%.*]] = or i64 [[TMP74]], [[TMP73]]\n-+; CHECK-NEXT:    store i64 [[TMP68]], ptr [[TMP0]], align 4\n-+; CHECK-NEXT:    [[TMP76:%.*]] = extractelement <14 x i64> [[TMP53]], i32 11\n-+; CHECK-NEXT:    store i64 [[TMP76]], ptr null, align 4\n-+; CHECK-NEXT:    [[TMP77:%.*]] = extractelement <14 x i64> [[TMP53]], i32 7\n-+; CHECK-NEXT:    store i64 [[TMP77]], ptr [[TMP0]], align 4\n-+; CHECK-NEXT:    store i64 [[TMP75]], ptr null, align 4\n-+; CHECK-NEXT:    ret void\n-+;\n-+  %7 = getelementptr i8, ptr %0, i32 248\n-+  %8 = load i64, ptr %7, align 4\n-+  %9 = getelementptr i8, ptr %0, i32 240\n-+  %10 = load i64, ptr %9, align 4\n-+  %11 = load i64, ptr null, align 4\n-+  %12 = add i64 %1, 1\n-+  %13 = add i64 %1, 1\n-+  %14 = add i64 %1, %2\n-+  %15 = getelementptr i8, ptr %0, i32 136\n-+  %16 = load i64, ptr %15, align 4\n-+  %17 = getelementptr i8, ptr %0, i32 128\n-+  %18 = load i64, ptr %17, align 4\n-+  %19 = add i64 %18, %1\n-+  %20 = sub i64 0, %18\n-+  %21 = sub i64 0, %16\n-+  %22 = sub i64 0, %11\n-+  %23 = add i64 %1, 1\n-+  %24 = sub i64 0, %1\n-+  %25 = sub i64 0, %1\n-+  %26 = sub i64 0, %10\n-+  %27 = sub i64 0, %8\n-+  %28 = sub i64 0, %19\n-+  %29 = add i64 %11, 1\n-+  %30 = ashr i64 %29, 14\n-+  %31 = add i64 %11, 1\n-+  %32 = ashr i64 %31, 14\n-+  br i1 %3, label %58, label %33\n+ // UNGENERALIZED: [[TYPE]] = !{i32 1296635908}\n+ // GENERALIZED: [[TYPE]] = !{i32 -49168686}\n+ \n+ // UNGENERALIZED: [[TYPE3]] = !{i32 874141567}\n+ // GENERALIZED: [[TYPE3]] = !{i32 954385378}\n +\n-+33:\n-+  %34 = ashr i64 %2, 2\n-+  %35 = ashr i64 %1, 2\n-+  %36 = add i64 %1, 1\n-+  %37 = ashr i64 %36, 2\n-+  %38 = add i64 %1, 1\n-+  %39 = lshr i64 %1, 1\n-+  %40 = add i64 %38, %39\n-+  %41 = ashr i64 %40, 2\n-+  %42 = add i64 %1, 1\n-+  %43 = lshr i64 %1, 1\n-+  %44 = add i64 %42, %43\n-+  %45 = ashr i64 %44, 2\n-+  %46 = ashr i64 %5, 2\n-+  %47 = ashr i64 %4, 2\n-+  %48 = ashr i64 %1, 2\n-+  %49 = ashr i64 %1, 2\n-+  %50 = ashr i64 %1, 2\n-+  %51 = ashr i64 %1, 2\n-+  %52 = add i64 %1, 1\n-+  %53 = ashr i64 %52, 2\n-+  %54 = add i64 %1, 1\n-+  %55 = ashr i64 %54, 2\n-+  %56 = add i64 %1, 1\n-+  %57 = ashr i64 %56, 2\n-+  br label %58\n++// UNGENERALIZED: [[TYPE4]] = !{i32 -1619636625}\n++// GENERALIZED: [[TYPE4]] = !{i32 -125078496}\n+diff -ruN --strip-trailing-cr a/clang/test/CodeGen/kcfi-normalize.c b/clang/test/CodeGen/kcfi-normalize.c\n+--- a/clang/test/CodeGen/kcfi-normalize.c\n++++ b/clang/test/CodeGen/kcfi-normalize.c\n+@@ -1,5 +1,5 @@\n+-// RUN: %clang_cc1 -triple x86_64-unknown-linux-gnu -emit-llvm -fsanitize=kcfi -fsanitize-cfi-icall-experimental-normalize-integers -o - %s | FileCheck %s\n+-// RUN: %clang_cc1 -triple x86_64-unknown-linux-gnu -emit-llvm -fsanitize=kcfi -fsanitize-cfi-icall-experimental-normalize-integers -x c++ -o - %s | FileCheck %s\n++// RUN: %clang_cc1 -triple x86_64-unknown-linux-gnu -emit-llvm -fsanitize=kcfi -fsanitize-cfi-icall-experimental-normalize-integers -o - %s | FileCheck %s --check-prefixes=CHECK,C\n++// RUN: %clang_cc1 -triple x86_64-unknown-linux-gnu -emit-llvm -fsanitize=kcfi -fsanitize-cfi-icall-experimental-normalize-integers -x c++ -o - %s | FileCheck %s --check-prefixes=CHECK,CPP\n+ #if !__has_feature(kcfi)\n+ #error Missing kcfi?\n+ #endif\n+@@ -28,7 +28,22 @@\n+     fn(arg1, arg2, arg3);\n+ }\n+ \n++union Union {\n++  char *c;\n++  long *n;\n++} __attribute__((transparent_union));\n +\n-+58:\n-+  %59 = phi i64 [ %51, %33 ], [ %24, %6 ]\n-+  %60 = phi i64 [ %50, %33 ], [ %32, %6 ]\n-+  %61 = phi i64 [ %53, %33 ], [ %25, %6 ]\n-+  %62 = phi i64 [ %55, %33 ], [ %26, %6 ]\n-+  %63 = phi i64 [ %57, %33 ], [ %27, %6 ]\n-+  %64 = phi i64 [ %49, %33 ], [ %30, %6 ]\n-+  %65 = phi i64 [ %48, %33 ], [ %23, %6 ]\n-+  %66 = phi i64 [ %47, %33 ], [ %22, %6 ]\n-+  %67 = phi i64 [ %46, %33 ], [ %21, %6 ]\n-+  %68 = phi i64 [ %45, %33 ], [ %20, %6 ]\n-+  %69 = phi i64 [ %41, %33 ], [ %28, %6 ]\n-+  %70 = phi i64 [ %34, %33 ], [ %12, %6 ]\n-+  %71 = phi i64 [ %35, %33 ], [ %13, %6 ]\n-+  %72 = phi i64 [ %37, %33 ], [ %14, %6 ]\n-+  %73 = or i64 %65, %64\n-+  %74 = or i64 %59, %60\n-+  %75 = or i64 %70, %71\n-+  %76 = or i64 %74, %73\n-+  %77 = or i64 %61, %66\n-+  %78 = or i64 %72, %75\n-+  %79 = or i64 %67, %77\n-+  %80 = or i64 %62, %79\n-+  %81 = or i64 %76, %80\n-+  %82 = or i64 %68, %81\n-+  store i64 %78, ptr %0, align 4\n-+  store i64 %69, ptr null, align 4\n-+  store i64 %63, ptr %0, align 4\n-+  store i64 %82, ptr null, align 4\n-+  ret void\n++void uni(void (*fn)(union Union), union Union arg1) {\n++    // CHECK-LABEL: define{{.*}}uni\n++    // CHECK-SAME: {{.*}}!kcfi_type ![[TYPE4:[0-9]+]]\n++    // C: call void %0(ptr %1) [ \"kcfi\"(i32 1819770848) ]\n++    // CPP: call void %0(ptr %1) [ \"kcfi\"(i32 -1430221633) ]\n++    fn(arg1);\n +}\n +\n+ // CHECK: ![[#]] = !{i32 4, !\"cfi-normalize-integers\", i32 1}\n+ // CHECK: ![[TYPE1]] = !{i32 -1143117868}\n+ // CHECK: ![[TYPE2]] = !{i32 -460921415}\n+ // CHECK: ![[TYPE3]] = !{i32 -333839615}\n++// C: ![[TYPE4]] = !{i32 -650530463}\n++// CPP: ![[TYPE4]] = !{i32 1766237188}\n+diff -ruN --strip-trailing-cr a/lldb/source/Plugins/Process/elf-core/ProcessElfCore.cpp b/lldb/source/Plugins/Process/elf-core/ProcessElfCore.cpp\n+--- a/lldb/source/Plugins/Process/elf-core/ProcessElfCore.cpp\n++++ b/lldb/source/Plugins/Process/elf-core/ProcessElfCore.cpp\n+@@ -952,7 +952,7 @@\n+         return status.ToError();\n+       thread_data.name.assign (prpsinfo.pr_fname, strnlen (prpsinfo.pr_fname, sizeof (prpsinfo.pr_fname)));\n+       SetID(prpsinfo.pr_pid);\n+-      m_executable_name = prpsinfo.pr_fname;\n++      m_executable_name = thread_data.name;\n+       break;\n+     }\n+     case ELF::NT_SIGINFO: {\n+diff -ruN --strip-trailing-cr a/llvm/lib/Analysis/ScalarEvolution.cpp b/llvm/lib/Analysis/ScalarEvolution.cpp\n+--- a/llvm/lib/Analysis/ScalarEvolution.cpp\n++++ b/llvm/lib/Analysis/ScalarEvolution.cpp\n+@@ -3217,26 +3217,18 @@\n+       }\n+ \n+       // Try to fold (C1 * D /u C2) -> C1/C2 * D, if C1 and C2 are powers-of-2,\n+-      // D is a multiple of C2, and C1 is a multiple of C2. If C2 is a multiple\n+-      // of C1, fold to (D /u (C2 /u C1)).\n++      // D is a multiple of C2, and C1 is a multiple of C2.\n+       const SCEV *D;\n+       APInt C1V = LHSC->getAPInt();\n+-      // (C1 * D /u C2) == -1 * -C1 * D /u C2 when C1 != INT_MIN. Don't treat -1\n+-      // as -1 * 1, as it won't enable additional folds.\n+-      if (C1V.isNegative() && !C1V.isMinSignedValue() && !C1V.isAllOnes())\n++      // (C1 * D /u C2) == -1 * -C1 * D /u C2 when C1 != INT_MIN.\n++      if (C1V.isNegative() && !C1V.isMinSignedValue())\n+         C1V = C1V.abs();\n+       const SCEVConstant *C2;\n+       if (C1V.isPowerOf2() &&\n+           match(Ops[1], m_scev_UDiv(m_SCEV(D), m_SCEVConstant(C2))) &&\n+-          C2->getAPInt().isPowerOf2() &&\n++          C2->getAPInt().isPowerOf2() && C1V.uge(C2->getAPInt()) &&\n+           C1V.logBase2() <= getMinTrailingZeros(D)) {\n+-        const SCEV *NewMul;\n+-        if (C1V.uge(C2->getAPInt())) {\n+-          NewMul = getMulExpr(getUDivExpr(getConstant(C1V), C2), D);\n+-        } else {\n+-          assert(C1V.ugt(1) && \"C1 <= 1 should have been folded earlier\");\n+-          NewMul = getUDivExpr(D, getUDivExpr(C2, getConstant(C1V)));\n+-        }\n++        const SCEV *NewMul = getMulExpr(getUDivExpr(getConstant(C1V), C2), D);\n+         return C1V == LHSC->getAPInt() ? NewMul : getNegativeSCEV(NewMul);\n+       }\n+     }\n+diff -ruN --strip-trailing-cr a/llvm/test/Analysis/ScalarEvolution/mul-udiv-folds.ll b/llvm/test/Analysis/ScalarEvolution/mul-udiv-folds.ll\n+--- a/llvm/test/Analysis/ScalarEvolution/mul-udiv-folds.ll\n++++ b/llvm/test/Analysis/ScalarEvolution/mul-udiv-folds.ll\n+@@ -21,7 +21,7 @@\n+ ; CHECK-NEXT:    %gep.8 = getelementptr i8, ptr %A, i64 %iv\n+ ; CHECK-NEXT:    --> {(((zext i32 %start to i64) /u 4) + %A),+,1}<%loop> U: full-set S: full-set Exits: (((zext i32 %start to i64) /u 2) + %A) LoopDispositions: { %loop: Computable }\n+ ; CHECK-NEXT:    %gep.16 = getelementptr i16, ptr %A, i64 %iv\n+-; CHECK-NEXT:    --> {(((zext i32 %start to i64) /u 2) + %A),+,2}<%loop> U: full-set S: full-set Exits: ((zext i32 %start to i64) + %A) LoopDispositions: { %loop: Computable }\n++; CHECK-NEXT:    --> {((2 * ((zext i32 %start to i64) /u 4))<nuw><nsw> + %A),+,2}<%loop> U: full-set S: full-set Exits: ((zext i32 %start to i64) + %A) LoopDispositions: { %loop: Computable }\n+ ; CHECK-NEXT:    %gep.32 = getelementptr i32, ptr %A, i64 %iv\n+ ; CHECK-NEXT:    --> {((zext i32 %start to i64) + %A),+,4}<%loop> U: full-set S: full-set Exits: ((2 * (zext i32 %start to i64))<nuw><nsw> + %A) LoopDispositions: { %loop: Computable }\n+ ; CHECK-NEXT:    %gep.40 = getelementptr <{ i32, i8 }>, ptr %A, i64 %iv\n+diff -ruN --strip-trailing-cr a/llvm/test/Transforms/LoopStrengthReduce/duplicated-phis.ll b/llvm/test/Transforms/LoopStrengthReduce/duplicated-phis.ll\n+--- a/llvm/test/Transforms/LoopStrengthReduce/duplicated-phis.ll\n++++ b/llvm/test/Transforms/LoopStrengthReduce/duplicated-phis.ll\n+@@ -18,7 +18,8 @@\n+ ; CHECK:       [[FOR_BODY_PREHEADER_NEW]]:\n+ ; CHECK-NEXT:    [[UNROLL_ITER:%.*]] = and i64 [[MUL]], -4\n+ ; CHECK-NEXT:    [[TMP4:%.*]] = add i64 [[UNROLL_ITER]], -4\n+-; CHECK-NEXT:    [[TMP3:%.*]] = lshr i64 [[TMP4]], 1\n++; CHECK-NEXT:    [[TMP5:%.*]] = lshr i64 [[TMP4]], 2\n++; CHECK-NEXT:    [[TMP3:%.*]] = shl nuw nsw i64 [[TMP5]], 1\n+ ; CHECK-NEXT:    [[LSR_IV_NEXT:%.*]] = sub i64 -3, [[TMP3]]\n+ ; CHECK-NEXT:    br label %[[FOR_BODY:.*]]\n+ ; CHECK:       [[FOR_BODY]]:\n+diff -ruN --strip-trailing-cr a/llvm/test/Verifier/llvm.loop.estimated_trip_count.ll b/llvm/test/Verifier/llvm.loop.estimated_trip_count.ll\n+--- a/llvm/test/Verifier/llvm.loop.estimated_trip_count.ll\n++++ b/llvm/test/Verifier/llvm.loop.estimated_trip_count.ll\n+@@ -26,36 +26,43 @@\n+ \n+ ; No value.\n+ ; RUN: cp %s %t\n++; RUN: chmod u+w %t\n+ ; RUN: echo '!1 = !{!\"llvm.loop.estimated_trip_count\"}' >> %t\n+ ; RUN: not %{RUN} TOO-FEW\n+ \n+ ; i16 value.\n+ ; RUN: cp %s %t\n++; RUN: chmod u+w %t\n+ ; RUN: echo '!1 = !{!\"llvm.loop.estimated_trip_count\", i16 5}' >> %t\n+ ; RUN: %{RUN} GOOD\n+ \n+ ; i32 value.\n+ ; RUN: cp %s %t\n++; RUN: chmod u+w %t\n+ ; RUN: echo '!1 = !{!\"llvm.loop.estimated_trip_count\", i32 5}' >> %t\n+ ; RUN: %{RUN} GOOD\n+ \n+ ; i64 value.\n+ ; RUN: cp %s %t\n++; RUN: chmod u+w %t\n+ ; RUN: echo '!1 = !{!\"llvm.loop.estimated_trip_count\", i64 5}' >> %t\n+ ; RUN: not %{RUN} BAD-VALUE\n+ \n+ ; MDString value.\n+ ; RUN: cp %s %t\n++; RUN: chmod u+w %t\n+ ; RUN: echo '!1 = !{!\"llvm.loop.estimated_trip_count\", !\"5\"}' >> %t\n+ ; RUN: not %{RUN} BAD-VALUE\n+ \n+ ; MDNode value.\n+ ; RUN: cp %s %t\n++; RUN: chmod u+w %t\n+ ; RUN: echo '!1 = !{!\"llvm.loop.estimated_trip_count\", !2}' >> %t\n+ ; RUN: echo '!2 = !{i32 5}' >> %t\n+ ; RUN: not %{RUN} BAD-VALUE\n+ \n+ ; Too many values.\n+ ; RUN: cp %s %t\n++; RUN: chmod u+w %t\n+ ; RUN: echo '!1 = !{!\"llvm.loop.estimated_trip_count\", i32 5, i32 5}' >> %t\n+ ; RUN: not %{RUN} TOO-MANY\n+diff -ruN --strip-trailing-cr a/mlir/include/mlir/Tools/mlir-opt/MlirOptMain.h b/mlir/include/mlir/Tools/mlir-opt/MlirOptMain.h\n+--- a/mlir/include/mlir/Tools/mlir-opt/MlirOptMain.h\n++++ b/mlir/include/mlir/Tools/mlir-opt/MlirOptMain.h\n+@@ -264,7 +264,7 @@\n+   bool allowUnregisteredDialectsFlag = false;\n+ \n+   /// Remark format\n+-  RemarkFormat remarkFormatFlag;\n++  RemarkFormat remarkFormatFlag = REMARK_FORMAT_STDOUT;\n+   /// Remark file to output to\n+   std::string remarksOutputFileFlag = \"\";\n+   /// Remark filters\n diff -ruN --strip-trailing-cr a/mlir/lib/Bindings/Python/IRCore.cpp b/mlir/lib/Bindings/Python/IRCore.cpp\n --- a/mlir/lib/Bindings/Python/IRCore.cpp\n +++ b/mlir/lib/Bindings/Python/IRCore.cpp\n@@ -1050,52 +443,23 @@ diff -ruN --strip-trailing-cr a/mlir/lib/Bindings/Python/IRCore.cpp b/mlir/lib/B\n  }\n  \n  nb::object PyModule::createFromCapsule(nb::object capsule) {\n-@@ -2019,7 +2034,7 @@\n- // PyInsertionPoint.\n- //------------------------------------------------------------------------------\n- \n--PyInsertionPoint::PyInsertionPoint(PyBlock &block) : block(block) {}\n-+PyInsertionPoint::PyInsertionPoint(const PyBlock &block) : block(block) {}\n- \n- PyInsertionPoint::PyInsertionPoint(PyOperationBase &beforeOperationBase)\n-     : refOperation(beforeOperationBase.getOperation().getRef()),\n-@@ -2073,6 +2088,19 @@\n-   return PyInsertionPoint{block, std::move(terminatorOpRef)};\n+@@ -2084,6 +2099,8 @@\n+   return PyInsertionPoint{block, std::move(nextOpRef)};\n  }\n  \n-+PyInsertionPoint PyInsertionPoint::after(PyOperationBase &op) {\n-+  PyOperation &operation = op.getOperation();\n-+  PyBlock block = operation.getBlock();\n-+  MlirOperation nextOperation = mlirOperationGetNextInBlock(operation);\n-+  if (mlirOperationIsNull(nextOperation))\n-+    return PyInsertionPoint(block);\n-+  PyOperationRef nextOpRef = PyOperation::forOperation(\n-+      block.getParentOperation()->getContext(), nextOperation);\n-+  return PyInsertionPoint{block, std::move(nextOpRef)};\n-+}\n-+\n +size_t PyMlirContext::getLiveModuleCount() { return liveModules.size(); }\n +\n  nb::object PyInsertionPoint::contextEnter(nb::object insertPoint) {\n    return PyThreadContextEntry::pushInsertionPoint(insertPoint);\n  }\n-@@ -2912,6 +2940,7 @@\n+@@ -2923,6 +2940,7 @@\n               PyMlirContextRef ref = PyMlirContext::forContext(self.get());\n               return ref.releaseObject();\n             })\n +      .def(\"_get_live_module_count\", &PyMlirContext::getLiveModuleCount)\n        .def_prop_ro(MLIR_PYTHON_CAPI_PTR_ATTR, &PyMlirContext::getCapsule)\n        .def(MLIR_PYTHON_CAPI_FACTORY_ATTR, &PyMlirContext::createFromCapsule)\n        .def(\"__enter__\", &PyMlirContext::contextEnter)\n-@@ -3861,6 +3890,8 @@\n-                   nb::arg(\"block\"), \"Inserts at the beginning of the block.\")\n-       .def_static(\"at_block_terminator\", &PyInsertionPoint::atBlockTerminator,\n-                   nb::arg(\"block\"), \"Inserts before the block terminator.\")\n-+      .def_static(\"after\", &PyInsertionPoint::after, nb::arg(\"operation\"),\n-+                  \"Inserts after the operation.\")\n-       .def(\"insert\", &PyInsertionPoint::insert, nb::arg(\"operation\"),\n-            \"Inserts an operation.\")\n-       .def_prop_ro(\n diff -ruN --strip-trailing-cr a/mlir/lib/Bindings/Python/IRModule.h b/mlir/lib/Bindings/Python/IRModule.h\n --- a/mlir/lib/Bindings/Python/IRModule.h\n +++ b/mlir/lib/Bindings/Python/IRModule.h\n@@ -1125,108 +489,6 @@ diff -ruN --strip-trailing-cr a/mlir/lib/Bindings/Python/IRModule.h b/mlir/lib/B\n    bool emitErrorDiagnostics = false;\n  \n    MlirContext context;\n-@@ -821,7 +833,7 @@\n- public:\n-   /// Creates an insertion point positioned after the last operation in the\n-   /// block, but still inside the block.\n--  PyInsertionPoint(PyBlock &block);\n-+  PyInsertionPoint(const PyBlock &block);\n-   /// Creates an insertion point positioned before a reference operation.\n-   PyInsertionPoint(PyOperationBase &beforeOperationBase);\n- \n-@@ -829,6 +841,9 @@\n-   static PyInsertionPoint atBlockBegin(PyBlock &block);\n-   /// Shortcut to create an insertion point before the block terminator.\n-   static PyInsertionPoint atBlockTerminator(PyBlock &block);\n-+  /// Shortcut to create an insertion point to the node after the specified\n-+  /// operation.\n-+  static PyInsertionPoint after(PyOperationBase &op);\n- \n-   /// Inserts an operation.\n-   void insert(PyOperationBase &operationBase);\n-diff -ruN --strip-trailing-cr a/mlir/test/python/ir/insertion_point.py b/mlir/test/python/ir/insertion_point.py\n---- a/mlir/test/python/ir/insertion_point.py\n-+++ b/mlir/test/python/ir/insertion_point.py\n-@@ -63,6 +63,34 @@\n- run(test_insert_before_operation)\n- \n- \n-+# CHECK-LABEL: TEST: test_insert_after_operation\n-+def test_insert_after_operation():\n-+    ctx = Context()\n-+    ctx.allow_unregistered_dialects = True\n-+    with Location.unknown(ctx):\n-+        module = Module.parse(\n-+            r\"\"\"\n-+      func.func @foo() -> () {\n-+        \"custom.op1\"() : () -> ()\n-+        \"custom.op2\"() : () -> ()\n-+      }\n-+    \"\"\"\n-+        )\n-+        entry_block = module.body.operations[0].regions[0].blocks[0]\n-+        custom_op1 = entry_block.operations[0]\n-+        custom_op2 = entry_block.operations[1]\n-+        InsertionPoint.after(custom_op1).insert(Operation.create(\"custom.op3\"))\n-+        InsertionPoint.after(custom_op2).insert(Operation.create(\"custom.op4\"))\n-+        # CHECK: \"custom.op1\"\n-+        # CHECK: \"custom.op3\"\n-+        # CHECK: \"custom.op2\"\n-+        # CHECK: \"custom.op4\"\n-+        module.operation.print()\n-+\n-+\n-+run(test_insert_after_operation)\n-+\n-+\n- # CHECK-LABEL: TEST: test_insert_at_block_begin\n- def test_insert_at_block_begin():\n-     ctx = Context()\n-@@ -111,14 +139,24 @@\n-     \"\"\"\n-         )\n-         entry_block = module.body.operations[0].regions[0].blocks[0]\n-+        return_op = entry_block.operations[1]\n-         ip = InsertionPoint.at_block_terminator(entry_block)\n-         assert ip.block == entry_block\n--        assert ip.ref_operation == entry_block.operations[1]\n--        ip.insert(Operation.create(\"custom.op2\"))\n-+        assert ip.ref_operation == return_op\n-+        custom_op2 = Operation.create(\"custom.op2\")\n-+        ip.insert(custom_op2)\n-+        InsertionPoint.after(custom_op2).insert(Operation.create(\"custom.op3\"))\n-         # CHECK: \"custom.op1\"\n-         # CHECK: \"custom.op2\"\n-+        # CHECK: \"custom.op3\"\n-         module.operation.print()\n- \n-+        try:\n-+            InsertionPoint.after(return_op).insert(Operation.create(\"custom.op4\"))\n-+        except IndexError as e:\n-+            # CHECK: ERROR: Cannot insert operation at the end of a block that already has a terminator.\n-+            print(f\"ERROR: {e}\")\n-+\n- \n- run(test_insert_at_terminator)\n- \n-@@ -187,10 +225,16 @@\n-         with InsertionPoint(entry_block):\n-             Operation.create(\"custom.op2\")\n-             with InsertionPoint.at_block_begin(entry_block):\n--                Operation.create(\"custom.opa\")\n-+                custom_opa = Operation.create(\"custom.opa\")\n-                 Operation.create(\"custom.opb\")\n-             Operation.create(\"custom.op3\")\n-+            with InsertionPoint.after(custom_opa):\n-+                Operation.create(\"custom.op4\")\n-+                Operation.create(\"custom.op5\")\n-+\n-         # CHECK: \"custom.opa\"\n-+        # CHECK: \"custom.op4\"\n-+        # CHECK: \"custom.op5\"\n-         # CHECK: \"custom.opb\"\n-         # CHECK: \"custom.op1\"\n-         # CHECK: \"custom.op2\"\n diff -ruN --strip-trailing-cr a/mlir/test/python/ir/module.py b/mlir/test/python/ir/module.py\n --- a/mlir/test/python/ir/module.py\n +++ b/mlir/test/python/ir/module.py\n@@ -1267,52 +529,3 @@ diff -ruN --strip-trailing-cr a/mlir/test/python/ir/module.py b/mlir/test/python\n      module_dup = None\n      gc.collect()\n +    assert ctx._get_live_module_count() == 0\n-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/libc/BUILD.bazel b/utils/bazel/llvm-project-overlay/libc/BUILD.bazel\n---- a/utils/bazel/llvm-project-overlay/libc/BUILD.bazel\n-+++ b/utils/bazel/llvm-project-overlay/libc/BUILD.bazel\n-@@ -3749,6 +3749,14 @@\n- )\n- \n- libc_math_function(\n-+    name = \"fmodbf16\",\n-+    additional_deps = [\n-+        \":__support_fputil_bfloat16\",\n-+        \":__support_fputil_generic_fmod\",\n-+    ],\n-+)\n-+\n-+libc_math_function(\n-     name = \"fmodf\",\n-     additional_deps = [\n-         \":__support_fputil_generic_fmod\",\n-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel b/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel\n---- a/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel\n-+++ b/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel\n-@@ -739,6 +739,16 @@\n- )\n- \n- math_test(\n-+    name = \"fmodbf16\",\n-+    hdrs = [\n-+        \"FModTest.h\",\n-+    ],\n-+    deps = [\n-+        \"//libc:__support_fputil_bfloat16\",\n-+    ],\n-+)\n-+\n-+math_test(\n-     name = \"fmodf\",\n-     hdrs = [\"FModTest.h\"],\n- )\n-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel b/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel\n---- a/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel\n-+++ b/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel\n-@@ -2223,7 +2223,6 @@\n-             \"lib/Target/AArch64/AArch64GenDisassemblerTables.inc\": [\n-                 \"-gen-disassembler\",\n-                 \"-ignore-non-decodable-operands\",\n--                \"-ignore-fully-defined-operands\",\n-             ],\n-             \"lib/Target/AArch64/AArch64GenSystemOperands.inc\": [\"-gen-searchable-tables\"],\n-             \"lib/Target/AArch64/AArch64GenExegesis.inc\": [\"-gen-exegesis\"],"
        },
        {
            "sha": "3bdff1c2d54c110d56a21a89e782243a66d9441d",
            "filename": "third_party/xla/third_party/llvm/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl?ref=06352207355a1a70a713b6d142d39bcf1857d832",
            "patch": "@@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n \n def repo(name):\n     \"\"\"Imports LLVM.\"\"\"\n-    LLVM_COMMIT = \"a1de9aca1150bd749a3cdad1d1e26eb6a8855fe2\"\n-    LLVM_SHA256 = \"4b99bf2c212bcd27ac90315f6d8ce82f2d0aeaea257c9b49ddf29ef7a1bba175\"\n+    LLVM_COMMIT = \"f3b712f6e4e9afed735962c6b96e0a2cadb03dc1\"\n+    LLVM_SHA256 = \"3c1a7a3156635a35e33da13a93a4dd8f2e48ac7280b5674061a951a4aa8475c3\"\n \n     tf_http_archive(\n         name = name,"
        },
        {
            "sha": "f6aa9c62012bb9c538f808c8f96a44aa06b83e20",
            "filename": "third_party/xla/third_party/shardy/temporary.patch",
            "status": "modified",
            "additions": 2514,
            "deletions": 1553,
            "changes": 4067,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch?ref=06352207355a1a70a713b6d142d39bcf1857d832"
        },
        {
            "sha": "8777f4db00bfe3b8f7c34d9bea9e7735427f1d24",
            "filename": "third_party/xla/third_party/shardy/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl?ref=06352207355a1a70a713b6d142d39bcf1857d832",
            "patch": "@@ -3,8 +3,8 @@\n load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n \n def repo():\n-    SHARDY_COMMIT = \"3c58c0b99d9842432f330a6b173f79bdad0c1a39\"\n-    SHARDY_SHA256 = \"807469420030067bf93f88ffb06cb303a4735170cc7cc99cc618aaf2bf0cecb4\"\n+    SHARDY_COMMIT = \"134831223aee15cab3a188d864530323b5570b14\"\n+    SHARDY_SHA256 = \"e377109ff7d0f8404d737acb520ae749144cf505b918f7f02b48b9bb9ec5188c\"\n \n     tf_http_archive(\n         name = \"shardy\","
        },
        {
            "sha": "4c83d2aa840a6703be78a305c8815032cf4eb496",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl808150672.patch",
            "status": "added",
            "additions": 45,
            "deletions": 0,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl808150672.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl808150672.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl808150672.patch?ref=06352207355a1a70a713b6d142d39bcf1857d832",
            "patch": "@@ -0,0 +1,45 @@\n+\n+--- a/test/Conversion/tritongpu_to_llvm.mlir\t2025-08-22 04:02:56.000000000 -0700\n++++ b/test/Conversion/tritongpu_to_llvm.mlir\t2025-09-17 07:59:30.000000000 -0700\n+@@ -1,4 +1,7 @@\n+-// RUN: triton-opt %s -split-input-file --allocate-shared-memory-nv --convert-triton-gpu-to-llvm 2>/dev/null | FileCheck %s --dump-input-context 20\n++// RUN: triton-opt %s -split-input-file \\\n++// RUN:   --allocate-shared-memory-nv --convert-triton-gpu-to-llvm \\\n++// RUN:   --reconcile-unrealized-casts 2>/dev/null \\\n++// RUN:   | FileCheck %s --dump-input-context 20\n+ \n+ module attributes {\"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32} {\n+   // CHECK: llvm.func @test_empty_kernel(%arg0: i32, %arg1: !llvm.ptr<1>, %arg2: !llvm.ptr<1>)\n+\n+--- a/test/Conversion/tritonnvidiagpu_to_llvm.mlir\t2025-07-31 00:13:23.000000000 -0700\n++++ b/test/Conversion/tritonnvidiagpu_to_llvm.mlir\t2025-09-17 07:59:30.000000000 -0700\n+@@ -1,4 +1,7 @@\n+-// RUN: triton-opt %s -split-input-file --convert-triton-gpu-to-llvm=compute-capability=90 | FileCheck %s\n++// RUN: triton-opt %s -split-input-file \\\n++// RUN: --convert-triton-gpu-to-llvm=compute-capability=90 \\\n++// RUN: --reconcile-unrealized-casts \\\n++// RUN: | FileCheck %s\n+ \n+ #shared0 = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [0], CTAsPerCGA = [1], CTASplitNum = [1], CTAOrder = [0]}>\n+ #smem = #ttg.shared_memory\n+\n+--- a/third_party/amd/lib/TritonAMDGPUTransforms/CanonicalizePointers.cpp\t2025-07-31 00:13:23.000000000 -0700\n++++ b/third_party/amd/lib/TritonAMDGPUTransforms/CanonicalizePointers.cpp\t2025-09-17 07:59:30.000000000 -0700\n+@@ -1415,7 +1415,7 @@\n+     if (auto integerAttr =\n+             llvm::dyn_cast_or_null<mlir::IntegerAttr>(maybeAttr)) {\n+       if (integerAttr.getValue() == 0) {\n+-        rewriter.replaceAllUsesWith(castOp.getResult(0), fatPtrBase);\n++        rewriter.RewriterBase::replaceAllUsesWith(castOp.getResult(0), fatPtrBase);\n+         rewriter.eraseOp(castOp);\n+         return success();\n+       }\n+@@ -1425,7 +1425,7 @@\n+         fatPtrs.at({fatPtrBase, fatPtrOffset});\n+     auto newPtr = createTensorPointer(rewriter, fatPtrBase, fatPtrOffset,\n+                                       castOp.getLoc(), fatPtrAttrs);\n+-    rewriter.replaceAllUsesWith(newPtr, fatPtrBase);\n++    rewriter.RewriterBase::replaceAllUsesWith(newPtr, fatPtrBase);\n+     rewriter.eraseOp(castOp);\n+     return success();\n+   }"
        },
        {
            "sha": "33059c4da72eb67c3cada563a444bd17405313a5",
            "filename": "third_party/xla/third_party/triton/llvm_integration/series.bzl",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl?ref=06352207355a1a70a713b6d142d39bcf1857d832",
            "patch": "@@ -9,5 +9,6 @@ LLVM nor MLIR integrator, please do not add any patches to this list.\n \n llvm_patch_list = [\n     \"//third_party/triton:llvm_integration/cl801607173.patch\",\n+    \"//third_party/triton:llvm_integration/cl808150672.patch\",\n     # Add new patches just above this line\n ]"
        },
        {
            "sha": "49d17680f8d9e11a507f6c1682de9c550ebbaada",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/lower_tensors.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Flower_tensors.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Flower_tensors.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Flower_tensors.cc?ref=06352207355a1a70a713b6d142d39bcf1857d832",
            "patch": "@@ -121,7 +121,7 @@ Value GetDestinationBuffer(Value dest) {\n       break;\n     } else if (auto transfer_write =\n                    dest.getDefiningOp<vector::TransferWriteOp>()) {\n-      dest = transfer_write.getSource();\n+      dest = transfer_write.getBase();\n     } else {\n       dest.getDefiningOp()->emitOpError(\"unsupported dest type\");\n       return nullptr;\n@@ -441,8 +441,8 @@ struct RewriteTransferRead : OpRewritePattern<vector::TransferReadOp> {\n       mlir::PatternRewriter& rewriter) const override {\n     assert(IsSupportedTransfer(op));\n \n-    auto source = mlir::dyn_cast<mlir::TypedValue<mlir::RankedTensorType>>(\n-        op.getSource());\n+    auto source =\n+        mlir::dyn_cast<mlir::TypedValue<mlir::RankedTensorType>>(op.getBase());\n     mlir::Type source_element_type = source.getType().getElementType();\n \n     mlir::ImplicitLocOpBuilder b(op.getLoc(), rewriter);\n@@ -465,7 +465,7 @@ struct RewriteTransferRead : OpRewritePattern<vector::TransferReadOp> {\n     mlir::LLVMTypeConverter converter(b.getContext());\n     auto llvm_vector_type = converter.convertType(vector_type);\n     auto load = b.create<ml::LoadOp>(llvm_vector_type, gep);\n-    if (auto alignment = GetAlignmentFromArg(op.getSource(), op.getIndices())) {\n+    if (auto alignment = GetAlignmentFromArg(op.getBase(), op.getIndices())) {\n       load.setAlignment(*alignment);\n     } else {\n       auto data_layout = mlir::DataLayout::closest(op);\n@@ -592,7 +592,7 @@ struct RewriteTransferWrite : OpRewritePattern<vector::TransferWriteOp> {\n       vector::TransferWriteOp op,\n       mlir::PatternRewriter& rewriter) const override {\n     assert(IsSupportedTransfer(op));\n-    Value dest = GetDestinationBuffer(op.getSource());\n+    Value dest = GetDestinationBuffer(op.getBase());\n \n     mlir::ImplicitLocOpBuilder b(op.getLoc(), rewriter);\n     auto tensor_dest = mlir::cast<TypedValue<mlir::RankedTensorType>>(dest);\n@@ -619,7 +619,7 @@ struct RewriteTransferWrite : OpRewritePattern<vector::TransferWriteOp> {\n     vector_value = b.create<UnrealizedConversionCastOp>(llvm_type, vector_value)\n                        .getResult(0);\n     auto store = b.create<ml::StoreOp>(vector_value, gep);\n-    if (auto alignment = GetAlignmentFromArg(op.getSource(), op.getIndices())) {\n+    if (auto alignment = GetAlignmentFromArg(op.getBase(), op.getIndices())) {\n       store.setAlignment(*alignment);\n     } else {\n       auto data_layout = mlir::DataLayout::closest(op);\n@@ -630,7 +630,7 @@ struct RewriteTransferWrite : OpRewritePattern<vector::TransferWriteOp> {\n           data_layout.getTypePreferredAlignment(vector_element_type));\n     }\n \n-    rewriter.replaceOp(op, mlir::ValueRange{op.getSource()});\n+    rewriter.replaceOp(op, mlir::ValueRange{op.getBase()});\n     return success();\n   }\n };"
        },
        {
            "sha": "b84cbfac8c0fcc1fbfad7c38a832b1b9ec95b8ba",
            "filename": "third_party/xla/xla/mlir/tools/mlir_interpreter/dialects/vector.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fxla%2Fmlir%2Ftools%2Fmlir_interpreter%2Fdialects%2Fvector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fxla%2Fmlir%2Ftools%2Fmlir_interpreter%2Fdialects%2Fvector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir%2Ftools%2Fmlir_interpreter%2Fdialects%2Fvector.cc?ref=06352207355a1a70a713b6d142d39bcf1857d832",
            "patch": "@@ -760,8 +760,7 @@ llvm::SmallVector<InterpreterValue> TransferWrite(\n              src_view.num_dimensions() &&\n          \"expected matching number of results\");\n \n-  dst =\n-      mlir::isa<TensorType>(transfer.getSource().getType()) ? dst.Clone() : dst;\n+  dst = mlir::isa<TensorType>(transfer.getBase().getType()) ? dst.Clone() : dst;\n   auto dst_slice = ExtractMemorySlice(state, transfer.getPermutationMap(), dst,\n                                       src, offsets, transfer.getInBounds());\n   if (!dst_slice) {"
        },
        {
            "sha": "961c1661d0065d4576681d0768b1056c67db9735",
            "filename": "third_party/xla/xla/mlir_hlo/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fxla%2Fmlir_hlo%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06352207355a1a70a713b6d142d39bcf1857d832/third_party%2Fxla%2Fxla%2Fmlir_hlo%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2FBUILD?ref=06352207355a1a70a713b6d142d39bcf1857d832",
            "patch": "@@ -32,7 +32,6 @@ td_library(\n     deps = [\n         \"@llvm-project//mlir:BuiltinDialectTdFiles\",\n         \"@llvm-project//mlir:ControlFlowInterfacesTdFiles\",\n-        \"@llvm-project//mlir:CopyOpInterfaceTdFiles\",\n         \"@llvm-project//mlir:InferTypeOpInterfaceTdFiles\",\n         \"@llvm-project//mlir:LoopLikeInterfaceTdFiles\",\n         \"@llvm-project//mlir:MemRefOpsTdFiles\",\n@@ -707,7 +706,6 @@ cc_library(\n         \"@llvm-project//mlir:ComplexToLLVM\",\n         \"@llvm-project//mlir:ControlFlowDialect\",\n         \"@llvm-project//mlir:ControlFlowToLLVM\",\n-        \"@llvm-project//mlir:CopyOpInterface\",\n         \"@llvm-project//mlir:DialectUtils\",\n         \"@llvm-project//mlir:FuncDialect\",\n         \"@llvm-project//mlir:FuncToLLVM\","
        }
    ],
    "stats": {
        "total": 5674,
        "additions": 2936,
        "deletions": 2738
    }
}