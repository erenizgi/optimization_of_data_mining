{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Format device ordinal logging\n\nPiperOrigin-RevId: 802548783",
    "sha": "5f9b1cc917f4542e6a174c7d853a0e27c0241023",
    "files": [
        {
            "sha": "c444a04436b471857e8bc182a829f5fbc4fb1f6e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5f9b1cc917f4542e6a174c7d853a0e27c0241023/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5f9b1cc917f4542e6a174c7d853a0e27c0241023/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc?ref=5f9b1cc917f4542e6a174c7d853a0e27c0241023",
            "patch": "@@ -288,8 +288,9 @@ absl::Status CollectiveKernelThunk::ExecuteOnStream(\n       AllReduceLaunchDimensions(buffer.element_count, kNumRanks, strategy);\n   // In case of two-shot we want to increment in multiples of 2.\n   state->invocation_count += 1 + static_cast<uint32_t>(strategy);\n-  VLOG(3) << \"Performing one-shot all-reduce from device ordinal: \"\n-          << device_ordinal << \" for clique \" << clique_key.ToString();\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Performing one-shot all-reduce for clique \"\n+          << clique_key.ToString();\n   // TODO(b/407736956): Change this to emitted kernel.\n   return RunAllReduceKernel(\n       /*stream=*/stream,"
        },
        {
            "sha": "328f150947075125f7fe985cb0a387a1c3667a33",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5f9b1cc917f4542e6a174c7d853a0e27c0241023/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5f9b1cc917f4542e6a174c7d853a0e27c0241023/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc?ref=5f9b1cc917f4542e6a174c7d853a0e27c0241023",
            "patch": "@@ -380,8 +380,8 @@ absl::Status RunCollectivePermute(\n   //\n \n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing collective permute from device ordinal: \"\n-          << device_ordinal << \" current_id \" << current_id;\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Performing collective permute, current_id \" << current_id;\n \n   std::optional<int64_t> source_id = source_target.source;\n   std::optional<int64_t> target_id = source_target.target;"
        }
    ],
    "stats": {
        "total": 9,
        "additions": 5,
        "deletions": 4
    }
}