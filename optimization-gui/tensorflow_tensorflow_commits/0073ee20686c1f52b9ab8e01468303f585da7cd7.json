{
    "author": "basioli-k",
    "message": "[XLA:GPU][host offloading] Fix flakey execution caused by destroying the se::Event object from a host callback.\n\nThis should enable us to turn on compute offloading jax tests.\n\nPiperOrigin-RevId: 813657812",
    "sha": "0073ee20686c1f52b9ab8e01468303f585da7cd7",
    "files": [
        {
            "sha": "01b9018b2d67c1dddd70e7124b2bcb62f6ce6e33",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_execute_thunk.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 6,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0073ee20686c1f52b9ab8e01468303f585da7cd7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0073ee20686c1f52b9ab8e01468303f585da7cd7/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc?ref=0073ee20686c1f52b9ab8e01468303f585da7cd7",
            "patch": "@@ -485,7 +485,10 @@ absl::Status HostExecuteStartThunk::ExecuteOnStream(\n       std::make_shared<HostExecuteCallFrame>(std::move(tmp_call_frame));\n \n   auto execute = [this, call_frame = std::move(call_frame), params,\n-                  shared_execute_event = std::move(execute_event)]() mutable {\n+                  // We skip reference counting because destroying the event\n+                  // would trigger a CUDA API call which is not allowed in host\n+                  // callbacks.\n+                  execute_event_ptr = execute_event.AsPtr()]() mutable {\n     tsl::profiler::TraceMe trace(\n         \"HostExecuteStartThunk::ExecuteOnStream::execute (host_callback)\");\n     HostOffloadingExecutable::ExecuteOptions execute_options{\n@@ -503,23 +506,23 @@ absl::Status HostExecuteStartThunk::ExecuteOnStream(\n \n       tsl::BlockUntilReady(execute_event);\n       if (execute_event.IsError()) {\n-        shared_execute_event.SetError(execute_event.GetError());\n+        execute_event_ptr.SetError(execute_event.GetError());\n         return;\n       }\n     }\n     auto publish_result_status = std::move(*call_frame).PublishResult();\n     if (!publish_result_status.ok()) {\n-      shared_execute_event.SetError(publish_result_status);\n+      execute_event_ptr.SetError(publish_result_status);\n       return;\n     }\n     auto record_event_status = params.host_to_device_stream->RecordEvent(\n-        shared_execute_event.get().get());\n+        execute_event_ptr.get().get());\n     if (!record_event_status.ok()) {\n-      shared_execute_event.SetError(record_event_status);\n+      execute_event_ptr.SetError(record_event_status);\n       return;\n     }\n \n-    shared_execute_event.SetStateConcrete();\n+    execute_event_ptr.SetStateConcrete();\n   };\n \n   TF_RETURN_IF_ERROR(device_to_host_stream->DoHostCallbackWithStatus(\n@@ -571,6 +574,9 @@ absl::Status HostExecuteDoneThunk::ExecuteOnStream(\n   if (event.IsError()) {\n     return event.GetError();\n   }\n+\n+  // We queue this event on the compute stream so that the host to device copy\n+  // finishes before the consumer of the data can start.\n   TF_RETURN_IF_ERROR(stream->WaitFor(event.get().get()));\n \n   return absl::OkStatus();"
        }
    ],
    "stats": {
        "total": 18,
        "additions": 12,
        "deletions": 6
    }
}