{
    "author": "subhankarshah",
    "message": "[XLA:MSA] Allow block prefetching for values that have aliased uses -\n* Extend alternate memory chunk reservations for aliased uses.\n* Add pinned allocations in alternate memory for aliased uses.\n* Mark all aliased allocations as colocated.\n\nPin all values aliased to the left of the source hlo value being block prefetched to default memory, values aliased to the right of the source hlo value will be pinned to default memory in all cases except - when a scheduling a new prefetch is successful.\n* For source values, if a pinned allocation exists and adding uses to the allocation is required.\n* For other (aliased) values finalizing the value suffices.\n\nMisc:\n* When creating colocated aliased allocations in alternate memory, do not rely on getting the first colocated block from the back of the list.\n* Code cleanup.\nPiperOrigin-RevId: 825302368",
    "sha": "a7fb82d82dd7afb032cef8ce3e879b0ce7ec3443",
    "files": [
        {
            "sha": "ea05f541771a386b44cf3f7174cbfa39d2128db2",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.cc",
            "status": "modified",
            "additions": 190,
            "deletions": 66,
            "changes": 256,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a7fb82d82dd7afb032cef8ce3e879b0ce7ec3443/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a7fb82d82dd7afb032cef8ce3e879b0ce7ec3443/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc?ref=a7fb82d82dd7afb032cef8ce3e879b0ce7ec3443",
            "patch": "@@ -1323,8 +1323,8 @@ void MsaAlgorithm::IdentifyAndOptimizeMemoryBoundLoops() {\n               << \" loop end: \" << loop_end_idx\n               << \" num iterations: \" << num_iterations;\n \n-      TF_CHECK_OK(OptimizeMemoryBoundLoop(loop_start_idx, loop_end_idx,\n-                                          loop_size_candidate));\n+      CHECK_OK(OptimizeMemoryBoundLoop(loop_start_idx, loop_end_idx,\n+                                       loop_size_candidate));\n     }\n   }\n }\n@@ -2089,11 +2089,6 @@ std::optional<int64_t> MsaAlgorithm::EarliestBlockPrefetchStartTime(\n \n namespace {\n \n-struct UseInterval {\n-  int64_t first_use_time;\n-  int64_t last_use_time;\n-};\n-\n absl::flat_hash_map<const HloValue*, UseInterval> GetUseIntervals(\n     const std::vector<const HloValue*>& values,\n     const absl::flat_hash_map<const HloInstruction*, int64_t>&\n@@ -2133,6 +2128,19 @@ absl::flat_hash_set<HloPosition> GetParameterInstructionsAliasedToOutput(\n   return aliased_parameter_positions;\n }\n \n+// Marks all RepackAllocationBlocks in the list as colocated, forming a circular\n+// linked list, representing colocated allocations.\n+void MarkRepackAllocationBlocksColocated(\n+    std::vector<AllocationBlock*>& colocations) {\n+  if (colocations.empty()) {\n+    return;\n+  }\n+  for (size_t i = 0; i < colocations.size() - 1; ++i) {\n+    colocations[i]->next_colocated = colocations[i + 1];\n+  }\n+  colocations.back()->next_colocated = colocations.front();\n+}\n+\n void PopulateExistingBlockPrefetchedValues(\n     const Options& options, const HloAliasAnalysis& alias_analysis,\n     std::vector<const HloValue*>& block_prefetched_values,\n@@ -2387,20 +2395,14 @@ absl::Status MsaAlgorithm::CreateNewBlockPrefetches() {\n     const HloValue* value =\n         &alias_analysis_.dataflow_analysis().GetUniqueValueAt(\n             position.instruction, position.index);\n-    const HloBuffer& buffer = alias_analysis_.GetBufferContainingValue(*value);\n-    if (!aliased_parameter_positions.contains(value->defining_position()) &&\n-        buffer.values().size() == 1) {\n+    if (!aliased_parameter_positions.contains(value->defining_position())) {\n       block_prefetched_values.push_back(value);\n-    } else if (aliased_parameter_positions.contains(position)) {\n+    } else {\n       // TODO(b/441344194): Add support for block allocations for parameters\n       // that are aliased to outputs.\n       LOG(WARNING) << \"Skipping block prefetch for value: \"\n                    << position.ToString()\n                    << \" because it is aliased to a program output.\";\n-    } else {\n-      LOG(WARNING) << \"Skipping block prefetch for value: \"\n-                   << position.ToString()\n-                   << \" because it is aliased to multiple values.\";\n     }\n \n     // As mentioned above, we also track slices of block prefetched values.\n@@ -2409,14 +2411,6 @@ absl::Status MsaAlgorithm::CreateNewBlockPrefetches() {\n         const HloValue* slice_value =\n             &alias_analysis_.dataflow_analysis().GetUniqueValueAt(\n                 use.instruction, {});\n-        const HloBuffer& buffer =\n-            alias_analysis_.GetBufferContainingValue(*slice_value);\n-        if (buffer.values().size() > 1) {\n-          VLOG(1) << \"Skipping block prefetch for value: \"\n-                  << value->defining_position().ToString()\n-                  << \" because it is aliased to multiple values.\";\n-          continue;\n-        }\n         block_prefetched_values.push_back(slice_value);\n         sliced_value_to_original_value[slice_value] = value;\n       }\n@@ -2496,11 +2490,16 @@ absl::Status MsaAlgorithm::CreateNewBlockPrefetches() {\n   // 2. Update the operands in alternate memory map.\n   // 3. Add the value to the finalized values set.\n   // 4. Add a repack allocation block to the repack allocation blocks list.\n+  // 5. If the block prefetched value is aliased with other values that come\n+  //    after it in the schedule, colocate and finalize the aliased values.\n   // Outside the loop:\n-  // 5. Finalize the original sources of the sliced values that have not yet\n-  //    been finalized, so we don't try to process those sources again, outside\n-  //    of block prefetching.\n-  // 6. Clear the pending chunks after the loop.\n+  // 6. Finalize the prefetch source and its aliases that come before it in the\n+  //    schedule, to default memory. If source value was successfully block\n+  //    prefetched, the aliased values that come after in the schedule are\n+  //    already colocated with the prefetch and finalized to the alternate\n+  //    memory. If the block prefetch failed, finalize source and its aliases\n+  //    to default memory.\n+  // 7. Clear the pending chunks after the loop.\n   for (const HloValue* maybe_sliced_value : block_prefetched_values) {\n     UseInterval use_interval = value_to_use_intervals.at(maybe_sliced_value);\n     int64_t first_use_time = use_interval.first_use_time;\n@@ -2609,27 +2608,163 @@ absl::Status MsaAlgorithm::CreateNewBlockPrefetches() {\n         allocations_->back().get()));\n     repack_allocation_blocks_.back().next_colocated =\n         &(repack_allocation_blocks_.back());\n-  }\n \n-  // 5. Finalize the original sources of the sliced values that have not yet\n-  //    been finalized, so we don't try to process those sources again, outside\n-  //    of block prefetching.\n-  for (auto [_, original_value] : sliced_value_to_original_value) {\n-    if (finalized_values_.contains(original_value)) {\n-      continue;\n-    }\n-    Allocation* allocation = value_to_pinned_allocation[original_value];\n-    for (const HloUse& use : original_value->GetUses()) {\n-      allocation->AddUse(use);\n+    const HloBuffer& buffer =\n+        alias_analysis_.GetBufferContainingValue(*maybe_sliced_value);\n+    // 5. If the block prefetched value is aliased with other values that come\n+    //    after it in the schedule, colocate and finalize the aliased values.\n+    if (buffer.values().size() > 1) {\n+      ColocateAndFinalizeValuesAliasedToNewBlockPrefetches(\n+          maybe_sliced_value, buffer, chunk_candidate, buffer_size,\n+          &repack_allocation_blocks_.back(), instruction_schedule,\n+          value_to_use_intervals, prefetch_end_times);\n+    }\n+  }\n+\n+  // 6. Finalize the prefetch source and its aliases that come before it in the\n+  //    schedule, to default memory. If source value was successfully block\n+  //    prefetched, the aliased values that come after in the schedule are\n+  //    already colocated with the prefetch and finalized to the alternate\n+  //    memory. If the block prefetch failed, finalize source and its aliases\n+  //    to default memory.\n+  for (const HloValue* original_value : block_prefetched_values) {\n+    // Note: We do not need to add pinned allocations for the aliased values,\n+    // just finalizing them is sufficient to ensure that they will be served\n+    // from default memory.\n+    const HloBuffer& buffer =\n+        alias_analysis_.GetBufferContainingValue(*original_value);\n+    for (const HloValue* aliased_value : buffer.values()) {\n+      if (finalized_values_.contains(aliased_value)) {\n+        continue;\n+      }\n+      // If a pinned allocation already exists for the aliased value, add the\n+      // uses of the original value to the pinned allocation.\n+      auto it = value_to_pinned_allocation.find(aliased_value);\n+      if (it != value_to_pinned_allocation.end()) {\n+        Allocation* allocation = it->second;\n+        for (const HloUse& use : original_value->GetUses()) {\n+          allocation->AddUse(use);\n+        }\n+      }\n+      finalized_values_.insert(aliased_value);\n     }\n-    finalized_values_.insert(original_value);\n   }\n \n-  // 6. Clear the pending chunks.\n+  // 7. Clear the pending chunks.\n   ClearPendingChunks();\n   return absl::OkStatus();\n }\n \n+void MsaAlgorithm::ColocateAndFinalizeValuesAliasedToNewBlockPrefetches(\n+    const HloValue* maybe_sliced_value, const HloBuffer& buffer,\n+    const Chunk& chunk_candidate, int64_t buffer_size,\n+    AllocationBlock* first_colocated_repack_allocation,\n+    const absl::flat_hash_map<const HloInstruction*, int64_t>&\n+        instruction_schedule,\n+    const absl::flat_hash_map<const HloValue*, UseInterval>&\n+        value_to_use_intervals,\n+    std::vector<int64_t>& prefetch_end_times) {\n+  VLOG(1) << \"HloBuffer for block prefetched value: \"\n+          << maybe_sliced_value->ToShortString()\n+          << \" aliases with: \" << (buffer.values().size() - 1)\n+          << \" other values\";\n+\n+  int64_t maybe_sliced_value_definition_time =\n+      instruction_schedule.at(maybe_sliced_value->defining_instruction());\n+  std::vector<const HloValue*> colocated_values;\n+\n+  // We want to process only those values that are aliased to the right of the\n+  // block prefetched value. What is aliased to the left will be pinned to the\n+  // default memory.\n+  for (const HloValue* aliased_value : buffer.values()) {\n+    if (instruction_schedule.at(aliased_value->defining_instruction()) >\n+        maybe_sliced_value_definition_time) {\n+      colocated_values.push_back(aliased_value);\n+    }\n+  }\n+\n+  if (colocated_values.empty()) {\n+    return;\n+  }\n+\n+  absl::c_sort(colocated_values, [&](const HloValue* a, const HloValue* b) {\n+    return instruction_schedule.at(a->defining_instruction()) <\n+           instruction_schedule.at(b->defining_instruction());\n+  });\n+\n+  int64_t prev_last_use_time =\n+      value_to_use_intervals.at(maybe_sliced_value).last_use_time;\n+\n+  std::vector<AllocationBlock*> colocations;\n+  colocations.push_back(first_colocated_repack_allocation);\n+\n+  // For each of the colocated values that follow the block prefetched value,\n+  // extend the chunk candidate to the right and add a pinned allocation in\n+  // the alternate memory.\n+  for (int i = 0; i < colocated_values.size(); ++i) {\n+    const HloValue* aliased_value = colocated_values[i];\n+    CHECK(!finalized_values_.contains(aliased_value));\n+    int64_t aliased_value_definition_time =\n+        instruction_schedule.at(aliased_value->defining_instruction());\n+    CHECK_LT(maybe_sliced_value_definition_time, aliased_value_definition_time);\n+    // The last use time of the previous value in the colocated values list\n+    // should be the definition time of the current value in the colocated\n+    // values list. This is because only the last use of a value can be\n+    // aliased.\n+    CHECK_EQ(prev_last_use_time, aliased_value_definition_time);\n+    int64_t aliased_value_last_use_time = std::numeric_limits<int64_t>::min();\n+    for (const HloUse& use : aliased_value->GetUses()) {\n+      aliased_value_last_use_time =\n+          std::max(aliased_value_last_use_time,\n+                   instruction_schedule.at(use.instruction));\n+    }\n+    prev_last_use_time = aliased_value_last_use_time;\n+\n+    MsaBufferInterval aliased_interval = MsaBufferInterval{\n+        /*buffer=*/aliased_value,\n+        /*size=*/buffer_size,\n+        /*start=*/aliased_value_definition_time +\n+            1,  // We need to add 1 because a chunk is already reserved till\n+                // the prev_last_use_time which is equal to the\n+                // aliased_value_definition_time.\n+        /*end=*/aliased_value_last_use_time,\n+        /*colocations=*/{},\n+        /*need_allocation=*/true};\n+    Chunk aliased_chunk_candidate = FindChunkCandidate(\n+        aliased_interval, /*preferred_offset=*/chunk_candidate.offset);\n+    // The aliased chunk candidate should be the same as the chunk candidate,\n+    // since they are colocated and aliased. We are in principle extending the\n+    // same chunk candidate to the right and we should always be able to do\n+    // that because we are processing the values from left to right and we\n+    // have checked that the prefetched value is only aliased to the right.\n+    CHECK_EQ(aliased_chunk_candidate, chunk_candidate);\n+    allocations_->push_back(std::make_unique<PinnedAllocation>(\n+        aliased_value->defining_position(), MemorySpace::kAlternate,\n+        aliased_chunk_candidate, aliased_value_definition_time,\n+        aliased_value_last_use_time));\n+    AddToPendingChunks(aliased_interval, aliased_chunk_candidate);\n+    for (const HloUse& use : aliased_value->GetUses()) {\n+      allocations_->back()->AddUse(use);\n+      operands_in_alternate_memory_map_[use.instruction].insert(\n+          std::make_pair(use.operand_number, use.operand_index));\n+    }\n+    auto const sorted_position =\n+        std::lower_bound(prefetch_end_times.begin(), prefetch_end_times.end(),\n+                         aliased_value_last_use_time);\n+    prefetch_end_times.insert(sorted_position, aliased_value_last_use_time);\n+    finalized_values_.insert(aliased_value);\n+    repack_allocation_blocks_.push_back(MakeRepackAllocationBlock(\n+        aliased_value_definition_time, aliased_value_last_use_time,\n+        aliased_chunk_candidate.size, aliased_chunk_candidate.offset,\n+        allocations_->back().get()));\n+    repack_allocation_blocks_.back().next_colocated =\n+        &(repack_allocation_blocks_.back());\n+    colocations.push_back(&repack_allocation_blocks_.back());\n+  }\n+  // Mark repack allocation blocks as colocated.\n+  MarkRepackAllocationBlocksColocated(colocations);\n+}\n+\n absl::StatusOr<HeapSimulator::Result<HloValue>> MsaAlgorithm::Finish() {\n   // Note: Memory Space Assignment creates a HeapSimulator and passes an\n   // MsaAlgorithm object to it. buffer_intervals_ is populated by calling the\n@@ -4069,19 +4204,19 @@ AllocationRequest MsaAlgorithm::CreateAllocationRequest(\n             options_.preferred_prefetch_overrides, allocation_value.size(),\n             hlo_use, instruction_schedule, live_range_start_time,\n             latest_prefetch_time);\n-    TF_CHECK_OK(overridden_preferred_prefetch_time.status());\n+    CHECK_OK(overridden_preferred_prefetch_time.status());\n     if (overridden_preferred_prefetch_time.value().has_value()) {\n-      LOG(INFO) << \"Overriding preferred prefetch for \"\n-                << hlo_use.instruction->name() << \" operand number \"\n-                << hlo_use.operand_number << \" operand index \"\n-                << hlo_use.operand_index.ToString() << \" size \"\n-                << allocation_value.size() << \" live range (\"\n-                << live_range_start_time << \", \" << latest_prefetch_time\n-                << \") from \"\n-                << (preferred_prefetch_time.has_value()\n-                        ? preferred_prefetch_time.value()\n-                        : -1)\n-                << \" to \" << overridden_preferred_prefetch_time.value().value();\n+      VLOG(1) << \"Overriding preferred prefetch for \"\n+              << hlo_use.instruction->name() << \" operand number \"\n+              << hlo_use.operand_number << \" operand index \"\n+              << hlo_use.operand_index.ToString() << \" size \"\n+              << allocation_value.size() << \" live range (\"\n+              << live_range_start_time << \", \" << latest_prefetch_time\n+              << \") from \"\n+              << (preferred_prefetch_time.has_value()\n+                      ? preferred_prefetch_time.value()\n+                      : -1)\n+              << \" to \" << overridden_preferred_prefetch_time.value().value();\n       preferred_prefetch_time = overridden_preferred_prefetch_time.value();\n     }\n \n@@ -4782,13 +4917,7 @@ void MsaAlgorithm::AllocateCrossProgramPrefetchBuffer(\n       colocations.push_back(&repack_allocation_blocks_.back());\n     }\n   }\n-  for (int i = 0; i < colocations.size() - 1; ++i) {\n-    colocations[i]->next_colocated = colocations[i + 1];\n-  }\n-  if (!colocations.empty()) {\n-    colocations.back()->next_colocated = colocations.front();\n-  }\n-\n+  MarkRepackAllocationBlocksColocated(colocations);\n   ClearPendingChunks();\n }\n \n@@ -5596,12 +5725,7 @@ void MsaAlgorithm::FinalizeAllocations(\n           colocated_allocation->chunk().offset, colocated_allocation));\n       colocations.push_back(&repack_allocation_blocks_.back());\n     }\n-    for (int i = 0; i < colocations.size() - 1; ++i) {\n-      colocations[i]->next_colocated = colocations[i + 1];\n-    }\n-    if (!colocations.empty()) {\n-      colocations.back()->next_colocated = colocations.front();\n-    }\n+    MarkRepackAllocationBlocksColocated(colocations);\n   }\n   ClearPendingChunks();\n }\n@@ -6948,7 +7072,7 @@ absl::Status MsaAlgorithm::WindowPrefetch() {\n   // Remove the cloned instructions.\n   for (auto [_, cloned] : cloned_insts) {\n     HloComputation* computation = cloned->parent();\n-    TF_CHECK_OK(computation->RemoveInstruction(cloned));\n+    CHECK_OK(computation->RemoveInstruction(cloned));\n     computation->Cleanup();\n   }\n   return absl::OkStatus();"
        },
        {
            "sha": "4b869f151aa17cdb1f7abbc980d4158eb46806fb",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.h",
            "status": "modified",
            "additions": 33,
            "deletions": 0,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a7fb82d82dd7afb032cef8ce3e879b0ce7ec3443/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a7fb82d82dd7afb032cef8ce3e879b0ce7ec3443/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h?ref=a7fb82d82dd7afb032cef8ce3e879b0ce7ec3443",
            "patch": "@@ -46,6 +46,7 @@ limitations under the License.\n #include \"xla/service/heap_simulator/allocation_block.h\"\n #include \"xla/service/heap_simulator/heap_simulator.h\"\n #include \"xla/service/hlo.pb.h\"\n+#include \"xla/service/hlo_buffer.h\"\n #include \"xla/service/hlo_value.h\"\n #include \"xla/service/memory_space_assignment/allocation.h\"\n #include \"xla/service/memory_space_assignment/allocation_value.h\"\n@@ -60,6 +61,13 @@ limitations under the License.\n \n namespace xla {\n namespace memory_space_assignment {\n+\n+// A struct representing use intervals.\n+struct UseInterval {\n+  int64_t first_use_time;\n+  int64_t last_use_time;\n+};\n+\n // A struct representing an asynchronous copy with its logical start and end\n // time (time that copy done is scheduled), the resource this copy would use,\n // its destination memory space, and a unique ID.\n@@ -338,6 +346,19 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n   // in one pass within a block of memory space in the alternate memory. This\n   // guarantees FIFO ordering of all prefetches and allows for more aggressive\n   // prefetching i.e. allowing for bandwidth saturation.\n+  //\n+  // 1) Prefetches are copy-like operations and generate a new HloValue.\n+  // 2) For compiler-inserted block prefetches:\n+  //    A) The prefetch done, and everything that aliases with the prefetch\n+  //       source and comes after the prefetch done will now alias with the new\n+  //       HloValue and get alternate memory.\n+  //    B) Everything that aliases with the prefetch source and comes before the\n+  //       prefetch done will get default memory.\n+  // 3) For user-inserted block prefetches:\n+  //    A) The prefetch done and everything that aliases with it will get\n+  //       alternate memory.\n+  //    B) Everything that aliases with the source of the prefetch will get\n+  //       default memory.\n \n   // Processes existing, explicit block prefetched copy start/done instructions.\n   // Such instructions are inserted before MSA. MSA just needs to schedule them.\n@@ -352,6 +373,18 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n   //           is called.\n   absl::Status CreateNewBlockPrefetches();\n \n+  // Creates colocated allocations for values aliased to the new block\n+  // prefetches and finalizes them.\n+  void ColocateAndFinalizeValuesAliasedToNewBlockPrefetches(\n+      const HloValue* maybe_sliced_value, const HloBuffer& buffer,\n+      const Chunk& chunk_candidate, int64_t buffer_size,\n+      AllocationBlock* first_colocated_repack_allocation,\n+      const absl::flat_hash_map<const HloInstruction*, int64_t>&\n+          instruction_schedule,\n+      const absl::flat_hash_map<const HloValue*, UseInterval>&\n+          value_to_use_intervals,\n+      std::vector<int64_t>& prefetch_end_times);\n+\n   // Returns the maximum amount of scoped memory that is reserved at any time in\n   // the program.\n   int64_t MaxScopedMemoryOffset();"
        },
        {
            "sha": "dba0b2499d06cc786eaae5c64986e4bac88e6e56",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc",
            "status": "modified",
            "additions": 185,
            "deletions": 0,
            "changes": 185,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a7fb82d82dd7afb032cef8ce3e879b0ce7ec3443/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a7fb82d82dd7afb032cef8ce3e879b0ce7ec3443/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc?ref=a7fb82d82dd7afb032cef8ce3e879b0ce7ec3443",
            "patch": "@@ -14855,6 +14855,72 @@ ENTRY entry {\n       /*operand_memory_space=*/kAlternateMemorySpace);\n }\n \n+TEST_F(MemorySpaceAssignmentTest, TestBlockPrefetchingWithAlisedUses) {\n+  absl::string_view hlo_string = R\"(\n+HloModule module, is_scheduled=true\n+\n+ENTRY entry {\n+  p0 = f32[2,3]{1,0} parameter(0)\n+  p1 = f32[2,3]{1,0} parameter(1)\n+  p2 = f32[2,3]{1,0} parameter(2)\n+  p3 = f32[2,3]{1,0} parameter(3)\n+  p4 = f32[2,3]{1,0} parameter(4)\n+  p5 = f32[2,3]{1,0} parameter(5)\n+  custom_call0 = f32[2,3]{1,0} custom-call(p0), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate1 = f32[2,3]{1,0} negate(custom_call0)\n+  negate2 = f32[2,3]{1,0} negate(negate1)\n+  add3 = f32[2,3]{1,0} add(p1, negate2)\n+  negate4 = f32[2,3]{1,0} negate(add3)\n+  negate5 = f32[2,3]{1,0} negate(negate4)\n+  add6 = f32[2,3]{1,0} add(p2, negate5)\n+  negate7 = f32[2,3]{1,0} negate(add6)\n+  negate8 = f32[2,3]{1,0} negate(negate7)\n+  add9 = f32[2,3]{1,0} add(p3, negate8)\n+  negate10 = f32[2,3]{1,0} negate(add9)\n+  negate11 = f32[2,3]{1,0} negate(negate10)\n+  add12 = f32[2,3]{1,0} add(p4, negate11)\n+  custom_call13 = f32[2,3]{1,0} custom-call(custom_call0, add12), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate14 = f32[2,3]{1,0} negate(custom_call13)\n+  ROOT add15 = f32[2,3]{1,0} add(p5, negate14)\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  Options memory_space_options = DefaultMemorySpaceOptions();\n+  memory_space_options.max_size_in_bytes = 24;\n+  memory_space_options.reserved_bytes_for_block_prefetches = 24;\n+  memory_space_options.max_outstanding_block_prefetches = 10;\n+  memory_space_options.max_outstanding_prefetches = 0;\n+\n+  memory_space_options.block_prefetched_positions = GetHloPositions(\n+      /*module=*/module.get(),\n+      /*instruction_names=*/{\"p0\", \"p1\", \"p2\", \"p3\", \"p4\", \"p5\"});\n+\n+  XLA_LOG_LINES(INFO, \"Before MSA: \\n\" + module->ToString());\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n+  XLA_LOG_LINES(INFO, \"After MSA: \\n\" + module->ToString());\n+\n+  std::vector<std::string> prefetched_uses = {\"custom_call0\", \"add15\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/prefetched_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kCopyDone,\n+      /*operand_memory_space=*/kAlternateMemorySpace);\n+\n+  std::vector<std::string> aliased_uses = {\"negate1\", \"custom_call13\",\n+                                           \"negate14\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/aliased_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kCustomCall,\n+      /*operand_memory_space=*/kAlternateMemorySpace);\n+\n+  std::vector<std::string> default_memory_uses = {\"add3\", \"add6\", \"add9\",\n+                                                  \"add12\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/default_memory_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kParameter,\n+      /*operand_memory_space=*/kDefaultMemorySpace);\n+}\n+\n TEST_F(MemorySpaceAssignmentTest,\n        TestBlockPrefetchingWithInputOutputAliasConfig) {\n   absl::string_view hlo_string = R\"(\n@@ -15037,6 +15103,125 @@ ENTRY entry {\n   EXPECT_EQ(add3->operand(0), add13->operand(0));\n }\n \n+TEST_F(MemorySpaceAssignmentTest, TestBlockPrefetchSourceValueAliased) {\n+  // In this test, the source value of the block prefetch aliases to the left.\n+  // custom_call1 and custom_call3 alias to the left, we test that all aliases\n+  // to the left should be pinned to default memory space.\n+  // custom_call3 also aliases to the right, which should be pinned to\n+  // alternate memory space.\n+  absl::string_view hlo_string = R\"(\n+HloModule module, is_scheduled=true\n+\n+ENTRY entry {\n+  p0 = f32[2,3]{1,0} parameter(0)\n+  p1 = f32[2,3]{1,0} parameter(1)\n+  p2 = f32[2,3]{1,0} parameter(2)\n+  p3 = f32[2,3]{1,0} parameter(3)\n+  p4 = f32[2,3]{1,0} parameter(4)\n+  p5 = f32[2,3]{1,0} parameter(5)\n+\n+  custom_call0 = f32[2,3]{1,0} custom-call(p0), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate_cc0 = f32[2,3]{1,0} negate(custom_call0)\n+  negate_cc1 = f32[2,3]{1,0} negate(negate_cc0)\n+  custom_call1 = f32[2,3]{1,0} custom-call(custom_call0 ,negate_cc1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate_cc2 = f32[2,3]{1,0} negate(custom_call1)\n+  negate_cc3 = f32[2,3]{1,0} negate(negate_cc2)\n+\n+  custom_call2 = f32[2,3]{1,0} custom-call(p1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate_cc4 = f32[2,3]{1,0} negate(custom_call2)\n+  negate_cc5 = f32[2,3]{1,0} negate(negate_cc4)\n+  custom_call3 = f32[2,3]{1,0} custom-call(custom_call2 ,negate_cc5), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate_cc6 = f32[2,3]{1,0} negate(custom_call3)\n+  negate_cc7 = f32[2,3]{1,0} negate(negate_cc6)\n+\n+  add0 = f32[2,3]{1,0} add(custom_call1, negate_cc3)\n+  add1 = f32[2,3]{1,0} add(add0, negate_cc7)\n+  negate2 = f32[2,3]{1,0} negate(add1)\n+  add3 = f32[2,3]{1,0} add(custom_call3, negate2)\n+  negate4 = f32[2,3]{1,0} negate(add3)\n+  negate5 = f32[2,3]{1,0} negate(negate4)\n+  add6 = f32[2,3]{1,0} add(p2, negate5)\n+  negate7 = f32[2,3]{1,0} negate(add6)\n+  negate8 = f32[2,3]{1,0} negate(negate7)\n+  add9 = f32[2,3]{1,0} add(p3, negate8)\n+  negate10 = f32[2,3]{1,0} negate(add9)\n+  negate11 = f32[2,3]{1,0} negate(negate10)\n+  add12 = f32[2,3]{1,0} add(p4, negate11)\n+  custom_call13 = f32[2,3]{1,0} custom-call(custom_call3, add12), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  add14 = f32[2,3]{1,0} add(custom_call1, add12)\n+  add15 = f32[2,3]{1,0} add(custom_call13, add14)\n+  ROOT add16 = f32[2,3]{1,0} add(p5, add15)\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  Options memory_space_options = DefaultMemorySpaceOptions();\n+  memory_space_options.max_size_in_bytes = 400;\n+  memory_space_options.reserved_bytes_for_block_prefetches = 400;\n+  memory_space_options.max_outstanding_block_prefetches = 10;\n+  memory_space_options.max_outstanding_prefetches = 0;\n+\n+  memory_space_options.block_prefetched_positions = GetHloPositions(\n+      /*module=*/module.get(),\n+      /*instruction_names=*/{\"custom_call1\", \"custom_call3\", \"p2\", \"p3\", \"p4\",\n+                             \"p5\"});\n+\n+  const std::string text_proto = R\"pb(\n+    overrides {\n+      hlo_position_matcher {\n+        instruction_name_regex: \"custom_call0|custom_call1|custom_call2|custom_call3\"\n+      }\n+      override_options { assign_first: true }\n+    })pb\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto msa_sort_order_overrides,\n+                          ParseTextProto<MsaSortOrderOverrides>(text_proto));\n+  memory_space_options.msa_sort_order_overrides =\n+      std::move(msa_sort_order_overrides);\n+\n+  XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n+  XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n+\n+  // Check uses of block prefetche are from alternate memory space.\n+  std::vector<std::string> alternate_memory_uses = {\n+      \"negate_cc2\", \"negate_cc6\", \"add0\",          \"add3\",  \"add6\",\n+      \"add9\",       \"add12\",      \"custom_call13\", \"add14\", \"add16\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/alternate_memory_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kCopyDone,\n+      /*operand_memory_space=*/kAlternateMemorySpace);\n+\n+  // Check that the uses of the values aliased to the right of prefetched value\n+  // are from alternate memory space.\n+  std::vector<std::string> alt_memory_uses_from_aliased_pinned_values = {\n+      \"add15\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(),\n+      /*instruction_names=*/alt_memory_uses_from_aliased_pinned_values,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kCustomCall,\n+      /*operand_memory_space=*/kAlternateMemorySpace);\n+\n+  HloInstruction* add0 = FindInstruction(module.get(), \"add0\");\n+  HloInstruction* add3 = FindInstruction(module.get(), \"add3\");\n+  HloInstruction* custom_call13 =\n+      FindInstruction(module.get(), \"custom_call13\");\n+  HloInstruction* add14 = FindInstruction(module.get(), \"add14\");\n+  // Check that the prefetch of p0 is reused for add14.\n+  EXPECT_EQ(add0->operand(0), add14->operand(0));\n+  // Check that the prefetch of p1 is reused for custom_call13.\n+  EXPECT_EQ(add3->operand(0), custom_call13->operand(0));\n+\n+  // Check that all the uses of the hlo values that alias to the left of the\n+  // prefetched hlo value (custom_call1, custom_call3) are from default memory\n+  // space even though they are higher in the sort order.\n+  std::vector<std::string> default_memory_uses = {\"negate_cc0\", \"custom_call1\",\n+                                                  \"negate_cc4\", \"custom_call3\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/default_memory_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kCustomCall,\n+      /*operand_memory_space=*/kDefaultMemorySpace);\n+}\n+\n TEST_F(MemorySpaceAssignmentTest,\n        TestBlockPrefetchingDoubleBufferedWithColoring) {\n   absl::string_view hlo_string = R\"("
        }
    ],
    "stats": {
        "total": 474,
        "additions": 408,
        "deletions": 66
    }
}