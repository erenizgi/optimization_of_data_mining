{
    "author": "akuegel",
    "message": "Reverts c426951a52545e7bb289752e2f473b91174d4699\n\nPiperOrigin-RevId: 806239581",
    "sha": "2ec3e01bccf8adad51789c9d392c889e22aff213",
    "files": [
        {
            "sha": "0f58582360a8fbdf04116c0773871a76633f9dac",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2ec3e01bccf8adad51789c9d392c889e22aff213/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2ec3e01bccf8adad51789c9d392c889e22aff213/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=2ec3e01bccf8adad51789c9d392c889e22aff213",
            "patch": "@@ -682,21 +682,6 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n         return true;\n       };\n \n-  // Custom \"sub-parser\" lambda for xla_gpu_graph_level.\n-  auto setter_for_xla_gpu_graph_level = [debug_options](const int32_t level) {\n-    debug_options->clear_xla_gpu_enable_command_buffer();\n-    if (level >= 1) {\n-      debug_options->add_xla_gpu_enable_command_buffer(DebugOptions::FUSION);\n-    }\n-    if (level >= 2) {\n-      debug_options->add_xla_gpu_enable_command_buffer(DebugOptions::CUBLAS);\n-    }\n-    if (level >= 3) {\n-      debug_options->add_xla_gpu_enable_command_buffer(DebugOptions::CUDNN);\n-    }\n-    return true;\n-  };\n-\n   auto command_types_to_string =\n       [](tsl::protobuf::RepeatedField<int> command_types) -> std::string {\n     struct Formatter {\n@@ -1609,11 +1594,6 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n           &DebugOptions::set_xla_gpu_collectives_use_persistent_cliques),\n       debug_options->xla_gpu_collectives_use_persistent_cliques(),\n       \"Use persistent per-process XLA:GPU collectives cliques\"));\n-  flag_list->push_back(tsl::Flag(\n-      \"xla_gpu_graph_level\", setter_for_xla_gpu_graph_level, 1,\n-      \"The legacy flag for setting GPU graph level. Use \"\n-      \"xla_gpu_enable_command_buffer in new use cases. 0 = off; 1 = capture \"\n-      \"fusions and memcpys; 2 = capture gemms; 3 = capture convolutions.\"));\n   flag_list->push_back(tsl::Flag(\n       \"xla_gpu_enable_command_buffer\",\n       SetterForRepeatedEnum<DebugOptions::CommandBufferCmdType>("
        }
    ],
    "stats": {
        "total": 20,
        "additions": 0,
        "deletions": 20
    }
}