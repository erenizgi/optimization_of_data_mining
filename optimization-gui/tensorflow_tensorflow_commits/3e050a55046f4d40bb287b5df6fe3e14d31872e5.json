{
    "author": "penpornk",
    "message": "[xla:cpu:onednn] Remove INTEL_MKL ifdef guards around `onednn_op_thunk`\n\n+ Minor ClangTidy/Linter errors/warnings fixes.\n\nPiperOrigin-RevId: 813668718",
    "sha": "3e050a55046f4d40bb287b5df6fe3e14d31872e5",
    "files": [
        {
            "sha": "088942549e726e24ef09f67f1c6402c4e0a71400",
            "filename": "third_party/xla/xla/backends/cpu/runtime/onednn/BUILD",
            "status": "modified",
            "additions": 14,
            "deletions": 9,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e050a55046f4d40bb287b5df6fe3e14d31872e5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e050a55046f4d40bb287b5df6fe3e14d31872e5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2FBUILD?ref=3e050a55046f4d40bb287b5df6fe3e14d31872e5",
            "patch": "@@ -1,8 +1,8 @@\n-load(\"//xla:xla.default.bzl\", \"xla_cc_test\")\n load(\"//xla/tsl:tsl.bzl\", \"tsl_copts\")\n load(\"//xla/tsl:tsl.default.bzl\", \"get_compatible_with_portable\")\n load(\n     \"//xla/tsl/mkl:graph.bzl\",\n+    \"onednn_cc_test\",\n     \"onednn_graph_cc_library\",\n     \"onednn_graph_cc_test\",\n )\n@@ -123,42 +123,47 @@ cc_library(\n     visibility = [\"//visibility:public\"],\n     deps = [\n         \":onednn_threadpool\",\n-        \"//xla:status_macros\",\n+        \"//xla:shape_util\",\n         \"//xla/backends/cpu/runtime:thunk\",\n         \"//xla/runtime:buffer_use\",\n-        \"//xla/runtime:object_pool\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/service/cpu:onednn_config_proto_cc\",\n         \"//xla/service/cpu:onednn_matmul\",\n         \"//xla/service/cpu:onednn_memory_util\",\n-        \"//xla/service/cpu:onednn_util\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/mkl:onednn\",\n         \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/base\",\n-        \"@com_google_absl//absl/container:inlined_vector\",\n-        \"@com_google_absl//absl/functional:function_ref\",\n+        \"@com_google_absl//absl/base:dynamic_annotations\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/memory\",\n+        \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/types:span\",\n+        \"@eigen_archive//:eigen3\",\n     ],\n )\n \n-xla_cc_test(\n+onednn_cc_test(\n     name = \"onednn_op_thunk_test\",\n     srcs = [\"onednn_op_thunk_test.cc\"],\n     copts = tsl_copts(),\n-    fail_if_no_test_linked = False,  # NOLINT=No tests if we don't build with oneDNN.\n-    fail_if_no_test_selected = False,  # NOLINT=No tests to select if we don't build with oneDNN.\n     deps = [\n         \":onednn_op_thunk\",\n+        \"//xla:array2d\",\n+        \"//xla:literal\",\n         \"//xla:literal_util\",\n         \"//xla:shape_util\",\n+        \"//xla/backends/cpu/runtime:buffer_allocations\",\n+        \"//xla/backends/cpu/runtime:thunk\",\n         \"//xla/backends/cpu/runtime:thunk_testlib\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:env\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/platform:test\",\n         \"@com_google_googletest//:gtest_main\",\n         \"@eigen_archive//:eigen3\",\n     ],"
        },
        {
            "sha": "6b8c76e47068979951955a3b2157f0a26324cd1f",
            "filename": "third_party/xla/xla/backends/cpu/runtime/onednn/onednn_op_thunk.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e050a55046f4d40bb287b5df6fe3e14d31872e5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e050a55046f4d40bb287b5df6fe3e14d31872e5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk.cc?ref=3e050a55046f4d40bb287b5df6fe3e14d31872e5",
            "patch": "@@ -13,29 +13,31 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#ifdef INTEL_MKL\n-\n #include \"xla/backends/cpu/runtime/onednn/onednn_op_thunk.h\"\n \n #include <cstddef>\n+#include <cstdint>\n #include <memory>\n+#include <string>\n #include <utility>\n #include <vector>\n \n #include \"absl/base/call_once.h\"\n-#include \"absl/container/inlined_vector.h\"\n-#include \"absl/functional/function_ref.h\"\n+#include \"absl/base/dynamic_annotations.h\"\n #include \"absl/log/check.h\"\n #include \"absl/memory/memory.h\"\n+#include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/types/span.h\"\n+#include \"Eigen/ThreadPool\"\n+#include \"oneapi/dnnl/dnnl_common.hpp\"\n #include \"oneapi/dnnl/dnnl_threadpool.hpp\"\n #include \"xla/backends/cpu/runtime/onednn/onednn_threadpool.h\"\n #include \"xla/backends/cpu/runtime/thunk.h\"\n #include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/cpu/onednn_matmul.h\"\n-#include \"xla/status_macros.h\"\n+#include \"xla/service/cpu/onednn_memory_util.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/platform/logging.h\"\n@@ -45,7 +47,7 @@ namespace xla::cpu {\n \n // oneDNN runtime instantiated for the oneDNN operation.\n struct OneDnnOpThunk::OneDnnRuntime {\n-  OneDnnRuntime(Eigen::ThreadPoolInterface* thread_pool);\n+  explicit OneDnnRuntime(Eigen::ThreadPoolInterface* thread_pool);\n \n   OneDnnRuntime(OneDnnRuntime&&) = default;\n   OneDnnRuntime& operator=(OneDnnRuntime&&) = default;\n@@ -194,4 +196,3 @@ tsl::AsyncValueRef<OneDnnOpThunk::ExecuteEvent> OneDnnOpThunk::Execute(\n \n }  // namespace xla::cpu\n \n-#endif  // INTEL_MKL"
        },
        {
            "sha": "e2978b924505dfd572a9d782f91aca29151bc945",
            "filename": "third_party/xla/xla/backends/cpu/runtime/onednn/onednn_op_thunk.h",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e050a55046f4d40bb287b5df6fe3e14d31872e5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e050a55046f4d40bb287b5df6fe3e14d31872e5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk.h?ref=3e050a55046f4d40bb287b5df6fe3e14d31872e5",
            "patch": "@@ -16,18 +16,16 @@ limitations under the License.\n #ifndef XLA_BACKENDS_CPU_RUNTIME_ONEDNN_ONEDNN_OP_THUNK_H_\n #define XLA_BACKENDS_CPU_RUNTIME_ONEDNN_ONEDNN_OP_THUNK_H_\n \n-#ifdef INTEL_MKL\n-\n #include <memory>\n #include <string>\n+#include <variant>\n #include <vector>\n \n #include \"absl/status/statusor.h\"\n-#include \"absl/types/span.h\"\n #include \"xla/backends/cpu/runtime/thunk.h\"\n-#include \"xla/runtime/object_pool.h\"\n-#include \"xla/service/cpu/onednn_memory_util.h\"\n-#include \"xla/service/cpu/onednn_util.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/cpu/onednn_config.pb.h\"\n+#include \"xla/shape.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n \n namespace xla::cpu {\n@@ -72,5 +70,4 @@ class OneDnnOpThunk : public Thunk {\n \n }  // namespace xla::cpu\n \n-#endif  // INTEL_MKL\n #endif  // XLA_BACKENDS_CPU_RUNTIME_ONEDNN_ONEDNN_OP_THUNK_H_"
        },
        {
            "sha": "60c38b2846899c2e629b5dabebbdd899afbdfcda",
            "filename": "third_party/xla/xla/backends/cpu/runtime/onednn/onednn_op_thunk_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 7,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e050a55046f4d40bb287b5df6fe3e14d31872e5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e050a55046f4d40bb287b5df6fe3e14d31872e5/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk_test.cc?ref=3e050a55046f4d40bb287b5df6fe3e14d31872e5",
            "patch": "@@ -13,24 +13,30 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#ifdef INTEL_MKL\n-\n #include \"xla/backends/cpu/runtime/onednn/onednn_op_thunk.h\"\n \n-#include \"gtest/gtest.h\"\n+#include <vector>\n+\n+// #include \"gtest/gtest.h\"\n+#include \"xla/array2d.h\"\n+#include \"xla/backends/cpu/runtime/buffer_allocations.h\"\n+#include \"xla/backends/cpu/runtime/thunk.h\"\n #include \"xla/backends/cpu/runtime/thunk_testlib.h\"\n+#include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n+#include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n+#include \"xla/tsl/platform/env.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/test.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n \n #define EIGEN_USE_THREADS\n #include \"unsupported/Eigen/CXX11/Tensor\"\n \n namespace xla::cpu {\n namespace {\n-using dnnl::engine;\n-using dnnl::stream;\n \n TEST(OneDnnOpThunkTest, SimpleOneDnnMatMulThunk) {\n   // Set up a thread pool for parallel execution\n@@ -108,5 +114,3 @@ TEST(OneDnnOpThunkTest, SimpleOneDnnMatMulThunk) {\n \n }  // namespace\n }  // namespace xla::cpu\n-\n-#endif  // INTEL_MKL"
        }
    ],
    "stats": {
        "total": 67,
        "additions": 37,
        "deletions": 30
    }
}