{
    "author": "unknown",
    "message": "[XLA] Remove BufferUse::k{Read,Write}\n\nInsted use BufferUse::{Read,Write}() when applicable, and\nBufferUse::MemoryUse::k{Read,Write} otherwise.\nPiperOrigin-RevId: 816719231",
    "sha": "03d5e36f3f748bc2684771f170df8e71a6dbc781",
    "files": [
        {
            "sha": "91d68bb0312ddf205d50775f8b05c4bd2486f58a",
            "filename": "third_party/xla/xla/backends/cpu/runtime/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -1000,7 +1000,6 @@ cc_library(\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/base:config\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/memory\",\n@@ -1127,7 +1126,6 @@ cc_library(\n         \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/stream_executor:device_memory\",\n-        \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/container:inlined_vector\","
        },
        {
            "sha": "bf3a6f224ee92e35366887145114a81bc2399c5e",
            "filename": "third_party/xla/xla/backends/cpu/runtime/copy_thunk.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fcopy_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fcopy_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fcopy_thunk.h?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -46,7 +46,7 @@ class CopyThunk final : public Thunk {\n   tsl::AsyncValueRef<ExecuteEvent> Execute(const ExecuteParams& params) final;\n \n   BufferUses buffer_uses() const final {\n-    return {{src_buffer_, BufferUse::kRead}, {dst_buffer_, BufferUse::kWrite}};\n+    return {BufferUse::Read(src_buffer_), BufferUse::Write(dst_buffer_)};\n   }\n \n   const Shape& src_shape() const { return src_shape_; }"
        },
        {
            "sha": "b27ba96f926bd56ff7d9098613d3746c27c57bdf",
            "filename": "third_party/xla/xla/backends/cpu/runtime/custom_call_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fcustom_call_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fcustom_call_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fcustom_call_thunk.cc?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -397,10 +397,10 @@ tsl::AsyncValueRef<Thunk::ExecuteEvent> CustomCallThunk::CallUntypedAPI(\n CustomCallThunk::BufferUses CustomCallThunk::buffer_uses() const {\n   BufferUses buffer_uses;\n   for (const auto& argument : op_buffers_.arguments_buffers) {\n-    buffer_uses.emplace_back(argument, BufferUse::kRead);\n+    buffer_uses.emplace_back(BufferUse::Read(argument));\n   }\n   for (const auto& result : op_buffers_.results_buffers) {\n-    buffer_uses.emplace_back(result, BufferUse::kWrite);\n+    buffer_uses.emplace_back(BufferUse::Write(result));\n   }\n   return buffer_uses;\n }"
        },
        {
            "sha": "2345f997f5a609069bdf972cf58a6e081a2cc573",
            "filename": "third_party/xla/xla/backends/cpu/runtime/fft_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Ffft_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Ffft_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Ffft_thunk.cc?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -197,8 +197,7 @@ tsl::AsyncValueRef<Thunk::ExecuteEvent> FftThunk::Execute(\n }\n \n Thunk::BufferUses FftThunk::buffer_uses() const {\n-  return {{input_buffer_, BufferUse::kRead},\n-          {output_buffer_, BufferUse::kWrite}};\n+  return {BufferUse::Read(input_buffer_), BufferUse::Write(output_buffer_)};\n }\n \n }  // namespace xla::cpu"
        },
        {
            "sha": "ce7c1299e30f605ce5128bca5e85a80c30c78879",
            "filename": "third_party/xla/xla/backends/cpu/runtime/infeed_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Finfeed_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Finfeed_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Finfeed_thunk.cc?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -99,7 +99,7 @@ tsl::AsyncValueRef<Thunk::ExecuteEvent> InfeedThunk::Execute(\n InfeedThunk::BufferUses InfeedThunk::buffer_uses() const {\n   BufferUses buffer_uses;\n   for (const InfeedBuffer& infeed_buffer : infeed_buffers_) {\n-    buffer_uses.emplace_back(infeed_buffer.slice, BufferUse::kWrite);\n+    buffer_uses.emplace_back(BufferUse::Write(infeed_buffer.slice));\n   }\n   return buffer_uses;\n }"
        },
        {
            "sha": "efa44a13fde7f1480e540a2d914df1326416bbaa",
            "filename": "third_party/xla/xla/backends/cpu/runtime/kernel_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fkernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fkernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fkernel_thunk.cc?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -102,10 +102,10 @@ static Thunk::BufferUses KernelBufferUses(\n     absl::Span<const BufferAllocation::Slice> results_buffers) {\n   Thunk::BufferUses buffer_uses;\n   for (const BufferAllocation::Slice& buffer : arguments_buffers) {\n-    buffer_uses.emplace_back(buffer, BufferUse::kRead);\n+    buffer_uses.emplace_back(BufferUse::Read(buffer));\n   }\n   for (const BufferAllocation::Slice& buffer : results_buffers) {\n-    buffer_uses.emplace_back(buffer, BufferUse::kWrite);\n+    buffer_uses.emplace_back(BufferUse::Write(buffer));\n   }\n   return buffer_uses;\n }"
        },
        {
            "sha": "e4536323c26b6414108f87abf4e966a64d267731",
            "filename": "third_party/xla/xla/backends/cpu/runtime/onednn/onednn_op_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fonednn%2Fonednn_op_thunk.cc?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -143,10 +143,10 @@ OneDnnOpThunk::~OneDnnOpThunk() = default;\n OneDnnOpThunk::BufferUses OneDnnOpThunk::buffer_uses() const {\n   BufferUses buffer_uses;\n   for (const auto& argument : op_buffers_.arguments_buffers) {\n-    buffer_uses.emplace_back(argument, BufferUse::kRead);\n+    buffer_uses.emplace_back(BufferUse::Read(argument));\n   }\n   for (const auto& result : op_buffers_.results_buffers) {\n-    buffer_uses.emplace_back(result, BufferUse::kWrite);\n+    buffer_uses.emplace_back(BufferUse::Write(result));\n   }\n   return buffer_uses;\n }"
        },
        {
            "sha": "e5c49b7b3a720ca61982b8b3c1faa724c1e2388f",
            "filename": "third_party/xla/xla/backends/cpu/runtime/outfeed_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Foutfeed_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Foutfeed_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Foutfeed_thunk.cc?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -99,7 +99,7 @@ tsl::AsyncValueRef<Thunk::ExecuteEvent> OutfeedThunk::Execute(\n OutfeedThunk::BufferUses OutfeedThunk::buffer_uses() const {\n   BufferUses buffer_uses;\n   for (const OutfeedBuffer& outfeed_buffer : outfeed_buffers_) {\n-    buffer_uses.emplace_back(outfeed_buffer.slice, BufferUse::kRead);\n+    buffer_uses.emplace_back(BufferUse::Read(outfeed_buffer.slice));\n   }\n   return buffer_uses;\n }"
        },
        {
            "sha": "c4c1d3368d757c529b35d215f7f5675432c405e0",
            "filename": "third_party/xla/xla/backends/cpu/runtime/rng_state_thunk.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Frng_state_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Frng_state_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Frng_state_thunk.h?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -40,7 +40,7 @@ class RngGetAndUpdateStateThunk final : public Thunk {\n   tsl::AsyncValueRef<ExecuteEvent> Execute(const ExecuteParams& params) final;\n \n   BufferUses buffer_uses() const final {\n-    return {{state_buffer_, BufferUse::kWrite}};\n+    return {BufferUse::Write(state_buffer_)};\n   }\n \n   int64_t delta() const { return rng_state_.delta(); }"
        },
        {
            "sha": "b477b8b1ad75e43c2848a55fb9709d568dcdd7b5",
            "filename": "third_party/xla/xla/backends/cpu/runtime/while_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fwhile_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fwhile_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fwhile_thunk.cc?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -273,7 +273,7 @@ tsl::AsyncValueRef<WhileThunk::ExecuteEvent> WhileThunk::ExecuteAsyncWhileLoop(\n }\n \n WhileThunk::BufferUses WhileThunk::buffer_uses() const {\n-  BufferUses buffer_uses = {{cond_buffer_, BufferUse::kWrite}};\n+  BufferUses buffer_uses = {BufferUse::Write(cond_buffer_)};\n \n   BufferUses cond_uses = cond_executor_.buffer_uses();\n   buffer_uses.insert(buffer_uses.end(), cond_uses.begin(), cond_uses.end());"
        },
        {
            "sha": "fe85aaa811a145df695e13583ed4033e71f26837",
            "filename": "third_party/xla/xla/backends/cpu/testlib/kernel_runner_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fkernel_runner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fkernel_runner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fkernel_runner_test.cc?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -75,8 +75,10 @@ TEST(KernelRunnerTest, Add) {\n \n   constexpr int64_t kNumElements = 8;\n   constexpr size_t kArgSizeBytes = kNumElements * sizeof(int32_t);\n-  LlvmTestKernelEmitter::KernelArg read_arg{kArgSizeBytes, BufferUse::kRead};\n-  LlvmTestKernelEmitter::KernelArg write_arg{kArgSizeBytes, BufferUse::kWrite};\n+  LlvmTestKernelEmitter::KernelArg read_arg{kArgSizeBytes,\n+                                            BufferUse::MemoryAccess ::kRead};\n+  LlvmTestKernelEmitter::KernelArg write_arg{kArgSizeBytes,\n+                                             BufferUse::MemoryAccess::kWrite};\n   LlvmTestKernelEmitter emitter(kLlvmAddI32, \"LlvmAddI32\",\n                                 NumWorkGroups{kNumElements},\n                                 {read_arg, read_arg, write_arg});"
        },
        {
            "sha": "9eedd0656e758e73cf044874cdcb5724db47db77",
            "filename": "third_party/xla/xla/backends/cpu/testlib/llvm_ir_kernel_emitter_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fllvm_ir_kernel_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fllvm_ir_kernel_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fllvm_ir_kernel_emitter_test.cc?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -45,7 +45,7 @@ TEST(LlvmIrKernelEmitterTest, ParseLlvmIr) {\n     }\n   )\";\n \n-  LlvmTestKernelEmitter::KernelArg arg{1024, BufferUse::kWrite};\n+  LlvmTestKernelEmitter::KernelArg arg{1024, BufferUse::MemoryAccess::kWrite};\n   LlvmTestKernelEmitter emitter(kLlvmIr, \"noop\", {}, {arg});\n \n   TF_ASSERT_OK_AND_ASSIGN(KernelDefinition kernel_definition,"
        },
        {
            "sha": "c1c4726d5ae82b5430fccaa459bd63ffcb636a99",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 35,
            "deletions": 37,
            "changes": 72,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -969,7 +969,7 @@ ComputationIdCmd::ComputationIdCmd(BufferAllocation::Slice dest, Kind kind)\n       kind_(kind) {}\n \n CommandBufferCmd::BufferUseVector ComputationIdCmd::buffers() const {\n-  return {{dest_, MemoryAccess::kWrite}};\n+  return {BufferUse::Write(dest_)};\n }\n \n absl::StatusOr<const se::CommandBuffer::Command*> ComputationIdCmd::Record(\n@@ -1241,7 +1241,7 @@ MemcpyDeviceToDeviceCmd::Record(const Thunk::ExecuteParams& execute_params,\n }\n \n CommandBufferCmd::BufferUseVector MemcpyDeviceToDeviceCmd::buffers() const {\n-  return {{dst_, MemoryAccess::kWrite}, {src_, MemoryAccess::kRead}};\n+  return {BufferUse::Write(dst_), BufferUse::Read(src_)};\n }\n \n //===----------------------------------------------------------------------===//\n@@ -1280,7 +1280,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> MemzeroCmd::Record(\n }\n \n CommandBufferCmd::BufferUseVector MemzeroCmd::buffers() const {\n-  return {{dst_, MemoryAccess::kWrite}};\n+  return {BufferUse::Write(dst_)};\n }\n \n //===----------------------------------------------------------------------===//\n@@ -1322,7 +1322,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> Memset32Cmd::Record(\n }\n \n CommandBufferCmd::BufferUseVector Memset32Cmd::buffers() const {\n-  return {{dst_, MemoryAccess::kWrite}};\n+  return {BufferUse::Write(dst_)};\n }\n \n //===----------------------------------------------------------------------===//\n@@ -1439,7 +1439,7 @@ bool CaseCmd::force_update() {\n \n CommandBufferCmd::BufferUseVector CaseCmd::buffers() const {\n   absl::flat_hash_set<BufferUse> buffers;\n-  buffers.emplace(index_, MemoryAccess::kRead);\n+  buffers.emplace(BufferUse::Read(index_));\n   for (auto& branch : branches_) {\n     buffers.insert(branch.buffers().begin(), branch.buffers().end());\n   }\n@@ -1567,7 +1567,7 @@ bool WhileCmd::force_update() {\n \n CommandBufferCmd::BufferUseVector WhileCmd::buffers() const {\n   absl::flat_hash_set<BufferUse> buffers;\n-  buffers.emplace(pred_, MemoryAccess::kWrite);\n+  buffers.emplace(BufferUse::Write(pred_));\n   buffers.insert(cond_commands_.buffers().begin(),\n                  cond_commands_.buffers().end());\n   buffers.insert(body_commands_.buffers().begin(),\n@@ -1627,10 +1627,8 @@ absl::StatusOr<const se::CommandBuffer::Command*> GemmCmd::Record(\n }\n \n CommandBufferCmd::BufferUseVector GemmCmd::buffers() const {\n-  return {{lhs_buffer_, MemoryAccess::kRead},\n-          {rhs_buffer_, MemoryAccess::kRead},\n-          {output_buffer_, MemoryAccess::kWrite},\n-          {workspace_, MemoryAccess::kWrite}};\n+  return {BufferUse::Read(lhs_buffer_), BufferUse::Read(rhs_buffer_),\n+          BufferUse::Write(output_buffer_), BufferUse::Write(workspace_)};\n }\n \n //===----------------------------------------------------------------------===//\n@@ -1680,32 +1678,32 @@ absl::StatusOr<const se::CommandBuffer::Command*> CublasLtCmd::Record(\n CommandBufferCmd::BufferUseVector CublasLtCmd::buffers() const {\n   BufferUseVector buffer_usage;\n   buffer_usage.reserve(13);\n-  buffer_usage.push_back({a_, MemoryAccess::kRead});\n-  buffer_usage.push_back({b_, MemoryAccess::kRead});\n-  buffer_usage.push_back({c_, MemoryAccess::kRead});\n-  buffer_usage.push_back({d_, MemoryAccess::kWrite});\n-  buffer_usage.push_back({*workspace_, MemoryAccess::kWrite});\n+  buffer_usage.push_back(BufferUse::Read(a_));\n+  buffer_usage.push_back(BufferUse::Read(b_));\n+  buffer_usage.push_back(BufferUse::Read(c_));\n+  buffer_usage.push_back(BufferUse::Write(d_));\n+  buffer_usage.push_back(BufferUse::Write(*workspace_));\n \n   if (bias_.allocation() != nullptr) {\n-    buffer_usage.push_back({bias_, MemoryAccess::kRead});\n+    buffer_usage.push_back(BufferUse::Read(bias_));\n   }\n   if (a_scale_.allocation() != nullptr) {\n-    buffer_usage.push_back({a_scale_, MemoryAccess::kRead});\n+    buffer_usage.push_back(BufferUse::Read(a_scale_));\n   }\n   if (b_scale_.allocation() != nullptr) {\n-    buffer_usage.push_back({b_scale_, MemoryAccess::kRead});\n+    buffer_usage.push_back(BufferUse::Read(b_scale_));\n   }\n   if (c_scale_.allocation() != nullptr) {\n-    buffer_usage.push_back({c_scale_, MemoryAccess::kRead});\n+    buffer_usage.push_back(BufferUse::Read(c_scale_));\n   }\n   if (d_scale_.allocation() != nullptr) {\n-    buffer_usage.push_back({d_scale_, MemoryAccess::kRead});\n+    buffer_usage.push_back(BufferUse::Read(d_scale_));\n   }\n   if (aux_.allocation() != nullptr) {\n-    buffer_usage.push_back({aux_, MemoryAccess::kWrite});\n+    buffer_usage.push_back(BufferUse::Write(aux_));\n   }\n   if (d_amax_.allocation() != nullptr) {\n-    buffer_usage.push_back({d_amax_, MemoryAccess::kRead});\n+    buffer_usage.push_back(BufferUse::Read(d_amax_));\n   }\n   return buffer_usage;\n }\n@@ -1771,9 +1769,9 @@ CommandBufferCmd::BufferUseVector CuDnnCmd::buffers() const {\n   CommandBufferCmd::BufferUseVector buffer_usage;\n   buffer_usage.reserve(args_.size());\n   for (int i = 0; i < args_.size() - 1; ++i) {\n-    buffer_usage.push_back({args_[i], MemoryAccess::kRead});\n+    buffer_usage.push_back(BufferUse::Read(args_[i]));\n   }\n-  buffer_usage.push_back({args_.back(), MemoryAccess::kWrite});\n+  buffer_usage.push_back(BufferUse::Write(args_.back()));\n   return buffer_usage;\n }\n \n@@ -1951,7 +1949,7 @@ CommandBufferCmd::BufferUseVector CustomCallCmd::buffers() const {\n   for (auto& slices : {operands_, results_}) {\n     for (const std::optional<Slice>& slice : slices) {\n       if (slice.has_value()) {\n-        buffer_usage.push_back({slice->slice, MemoryAccess::kWrite});\n+        buffer_usage.push_back(BufferUse::Write(slice->slice));\n       }\n     }\n   }\n@@ -2069,8 +2067,8 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllReduceCmd::Record(\n CommandBufferCmd::BufferUseVector AllReduceCmd::buffers() const {\n   BufferUseVector buffer_usage;\n   for (auto& buffer : buffers_) {\n-    buffer_usage.emplace_back(buffer.source_buffer, MemoryAccess::kRead);\n-    buffer_usage.emplace_back(buffer.destination_buffer, MemoryAccess::kWrite);\n+    buffer_usage.emplace_back(BufferUse::Read(buffer.source_buffer));\n+    buffer_usage.emplace_back(BufferUse::Write(buffer.destination_buffer));\n   }\n   return buffer_usage;\n }\n@@ -2135,8 +2133,8 @@ absl::StatusOr<const se::CommandBuffer::Command*> ReduceScatterCmd::Record(\n CommandBufferCmd::BufferUseVector ReduceScatterCmd::buffers() const {\n   BufferUseVector buffer_usage;\n   for (auto& buffer : buffers_) {\n-    buffer_usage.emplace_back(buffer.source_buffer, MemoryAccess::kRead);\n-    buffer_usage.emplace_back(buffer.destination_buffer, MemoryAccess::kWrite);\n+    buffer_usage.emplace_back(BufferUse::Read(buffer.source_buffer));\n+    buffer_usage.emplace_back(BufferUse::Write(buffer.destination_buffer));\n   }\n   return buffer_usage;\n }\n@@ -2199,8 +2197,8 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllToAllCmd::Record(\n CommandBufferCmd::BufferUseVector AllToAllCmd::buffers() const {\n   BufferUseVector buffer_usage;\n   for (auto& buffer : buffers_) {\n-    buffer_usage.emplace_back(buffer.source_buffer, MemoryAccess::kRead);\n-    buffer_usage.emplace_back(buffer.destination_buffer, MemoryAccess::kWrite);\n+    buffer_usage.emplace_back(BufferUse::Read(buffer.source_buffer));\n+    buffer_usage.emplace_back(BufferUse::Write(buffer.destination_buffer));\n   }\n   return buffer_usage;\n }\n@@ -2261,8 +2259,8 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllGatherCmd::Record(\n CommandBufferCmd::BufferUseVector AllGatherCmd::buffers() const {\n   BufferUseVector buffer_usage;\n   for (auto& buffer : buffers_) {\n-    buffer_usage.emplace_back(buffer.source_buffer, MemoryAccess::kRead);\n-    buffer_usage.emplace_back(buffer.destination_buffer, MemoryAccess::kWrite);\n+    buffer_usage.emplace_back(BufferUse::Read(buffer.source_buffer));\n+    buffer_usage.emplace_back(BufferUse::Write(buffer.destination_buffer));\n   }\n   return buffer_usage;\n }\n@@ -2324,8 +2322,8 @@ CollectiveBroadcastCmd::Record(const Thunk::ExecuteParams& execute_params,\n CommandBufferCmd::BufferUseVector CollectiveBroadcastCmd::buffers() const {\n   BufferUseVector buffer_usage;\n   for (auto& buffer : buffers_) {\n-    buffer_usage.emplace_back(buffer.source_buffer, MemoryAccess::kRead);\n-    buffer_usage.emplace_back(buffer.destination_buffer, MemoryAccess::kWrite);\n+    buffer_usage.emplace_back(BufferUse::Read(buffer.source_buffer));\n+    buffer_usage.emplace_back(BufferUse::Write(buffer.destination_buffer));\n   }\n   return buffer_usage;\n }\n@@ -2660,8 +2658,8 @@ DynamicSliceCopyFusionCmd::Record(const Thunk::ExecuteParams& execute_params,\n \n CommandBufferCmd::BufferUseVector DynamicSliceCopyFusionCmd::buffers() const {\n   CommandBufferCmd::BufferUseVector buffers;\n-  buffers.emplace_back(source_buffer_, MemoryAccess::kRead);\n-  buffers.emplace_back(destination_buffer_, MemoryAccess::kWrite);\n+  buffers.emplace_back(BufferUse::Read(source_buffer_));\n+  buffers.emplace_back(BufferUse::Write(destination_buffer_));\n   return buffers;\n }\n "
        },
        {
            "sha": "d090887418a6529dcd62f7952a3ed9b42eb05771",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd_test.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 17,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -164,8 +164,8 @@ TEST(CommandBufferCmdTest, SerializeExecution) {\n   auto slice1 = BufferAllocation::Slice(&alloc0, 50, 100);\n \n   // Reads from overlapping slices do not require barriers by default.\n-  auto use0 = BufferUse(slice0, BufferUse::kRead);\n-  auto use1 = BufferUse(slice1, BufferUse::kRead);\n+  auto use0 = BufferUse::Read(slice0);\n+  auto use1 = BufferUse::Read(slice1);\n \n   CommandBufferCmdSequence commands;\n   commands.Emplace<TestOnlyCommandBufferCmd>(BufferUseVector{use0});\n@@ -184,8 +184,8 @@ TEST(CommandBufferCmdTest, NoReadBarrier) {\n   auto slice1 = BufferAllocation::Slice(&alloc0, 50, 100);\n \n   // Reads from overlapping slices do not require barriers.\n-  auto use0 = BufferUse(slice0, BufferUse::kRead);\n-  auto use1 = BufferUse(slice1, BufferUse::kRead);\n+  auto use0 = BufferUse::Read(slice0);\n+  auto use1 = BufferUse::Read(slice1);\n \n   CommandBufferCmdSequence commands;\n   commands.Emplace<TestOnlyCommandBufferCmd>(BufferUseVector{use0});\n@@ -204,8 +204,8 @@ TEST(CommandBufferCmdTest, NoWriteBarrier) {\n   auto slice0 = BufferAllocation::Slice(&alloc0, 0, 100);\n   auto slice1 = BufferAllocation::Slice(&alloc0, 200, 100);\n \n-  auto use0 = BufferUse(slice0, BufferUse::kWrite);\n-  auto use1 = BufferUse(slice1, BufferUse::kWrite);\n+  auto use0 = BufferUse::Write(slice0);\n+  auto use1 = BufferUse::Write(slice1);\n \n   CommandBufferCmdSequence commands;\n   commands.Emplace<TestOnlyCommandBufferCmd>(BufferUseVector{use0});\n@@ -225,9 +225,9 @@ TEST(CommandBufferCmdTest, WriteConflictBarrier) {\n \n   // Reads from overlapping slices can be done in parallel, and before a write\n   // into overlapping slice we need to insert a barrier.\n-  auto use0 = BufferUse(slice0, BufferUse::kRead);\n-  auto use1 = BufferUse(slice0, BufferUse::kRead);\n-  auto use2 = BufferUse(slice1, BufferUse::kWrite);\n+  auto use0 = BufferUse::Read(slice0);\n+  auto use1 = BufferUse::Read(slice0);\n+  auto use2 = BufferUse::Write(slice1);\n \n   CommandBufferCmdSequence commands;\n   commands.Emplace<TestOnlyCommandBufferCmd>(BufferUseVector{use0});\n@@ -322,7 +322,8 @@ TEST(CommandBufferCmdTest, LaunchCmd) {\n   BufferAllocation::Slice slice_b(&alloc_b, 0, byte_length);\n \n   auto args = {slice_a, slice_a, slice_b};  // b = a + a\n-  auto args_access = {BufferUse::kRead, MemoryAccess::kRead, BufferUse::kWrite};\n+  auto args_access = {MemoryAccess::kRead, MemoryAccess::kRead,\n+                      MemoryAccess::kWrite};\n \n   // Prepare commands sequence for constructing command buffer.\n   CommandBufferCmdSequence commands;\n@@ -393,7 +394,8 @@ TEST(CommandBufferCmdTest, LaunchCmdWithPriority) {\n   BufferAllocation::Slice slice_b(&alloc_b, 0, byte_length);\n \n   auto args = {slice_a, slice_a, slice_b};  // b = a + a\n-  auto args_access = {BufferUse::kRead, MemoryAccess::kRead, BufferUse::kWrite};\n+  auto args_access = {MemoryAccess::kRead, MemoryAccess::kRead,\n+                      MemoryAccess::kWrite};\n \n   // Prepare commands sequence for constructing command buffer.\n   CommandBufferCmdSequence commands;\n@@ -513,8 +515,8 @@ TEST(TracedCommandBuffer, GetOrUpdateCommandBuffer) {\n     BufferAllocation alloc1(/*index=*/1, /*size=*/1024, /*color=*/0);\n \n     CommandBufferCmd::BufferUseVector buffers = {\n-        {BufferAllocation::Slice(&alloc0, 0, 1024), BufferUse::kRead},\n-        {BufferAllocation::Slice(&alloc1, 0, 1024), BufferUse::kWrite}};\n+        BufferUse::Read(BufferAllocation::Slice(&alloc0, 0, 1024)),\n+        BufferUse::Write(BufferAllocation::Slice(&alloc1, 0, 1024))};\n \n     TracedCommandBuffer traced_cmd_buffer(&traced_cmd, buffers,\n                                           /*capacity=*/trace_cache_size);\n@@ -635,8 +637,8 @@ TEST(CommandBufferCmdTest, RecordExecutorsWithDependencies) {\n   CommandBufferCmdSequence seq_b;\n   {\n     auto args = {slice_a, slice_a, slice_b};\n-    auto args_access = {BufferUse::kRead, MemoryAccess::kRead,\n-                        BufferUse::kWrite};\n+    auto args_access = {MemoryAccess::kRead, MemoryAccess::kRead,\n+                        MemoryAccess::kWrite};\n     seq_b.Emplace<LaunchCmd>(\"AddI32\", args, args_access,\n                              LaunchDimensions(1, 4), /*shmem_bytes=*/0);\n   }\n@@ -853,8 +855,8 @@ static void BM_GetOrTraceCommandBuffer(benchmark::State& state) {\n   BufferAllocation alloc1(/*index=*/1, /*size=*/1024, /*color=*/0);\n \n   CommandBufferCmd::BufferUseVector buffers = {\n-      {BufferAllocation::Slice(&alloc0, 0, 1024), BufferUse::kRead},\n-      {BufferAllocation::Slice(&alloc1, 0, 1024), BufferUse::kWrite}};\n+      BufferUse::Read(BufferAllocation::Slice(&alloc0, 0, 1024)),\n+      BufferUse::Write(BufferAllocation::Slice(&alloc1, 0, 1024))};\n \n   se::DeviceMemoryBase mem0(reinterpret_cast<void*>(0x01234567));\n   se::DeviceMemoryBase mem1(reinterpret_cast<void*>(0x12345670));"
        },
        {
            "sha": "b1811150d77437bedcf0d09d670c72bf931e5dd9",
            "filename": "third_party/xla/xla/runtime/buffer_use.h",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fruntime%2Fbuffer_use.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/03d5e36f3f748bc2684771f170df8e71a6dbc781/third_party%2Fxla%2Fxla%2Fruntime%2Fbuffer_use.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fruntime%2Fbuffer_use.h?ref=03d5e36f3f748bc2684771f170df8e71a6dbc781",
            "patch": "@@ -40,9 +40,6 @@ class BufferUse {\n     kWrite,\n   };\n \n-  static constexpr MemoryAccess kRead = MemoryAccess::kRead;\n-  static constexpr MemoryAccess kWrite = MemoryAccess::kWrite;\n-\n   // Flags that indicate whether the contents of a buffer are defined before and\n   // after execution of a thunk.\n   enum class ContentValidity : uint32_t {"
        }
    ],
    "stats": {
        "total": 146,
        "additions": 71,
        "deletions": 75
    }
}