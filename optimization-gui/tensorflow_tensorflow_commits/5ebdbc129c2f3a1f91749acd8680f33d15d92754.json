{
    "author": "WillFroom",
    "message": "[XLA:GPU][XTile] Move reshape scalar logic to triton lowering.\n\nThe previous logic emitted code that was specific to triton, the CPU -> vector lowering works directly so move this code to triton specific lowering.\n\nIt also means that we add another op that supports 0D tensors.\n\nPiperOrigin-RevId: 828381998",
    "sha": "5ebdbc129c2f3a1f91749acd8680f33d15d92754",
    "files": [
        {
            "sha": "fd8d302b006b51453a30106a2d94319f011a5442",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 28,
            "deletions": 63,
            "changes": 91,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=5ebdbc129c2f3a1f91749acd8680f33d15d92754",
            "patch": "@@ -602,56 +602,24 @@ SmallVector<Value> GetRuntimeValues(\n   return runtime_values;\n }\n \n-// Reshapes a non-0D tensor of shape [1, 1, 1, ...] to a scalar.\n-ScalarOrTensor ReshapeTensorToScalar(EmitterLocOpBuilder b, Value input) {\n-  auto element_type = mlir::cast<ShapedType>(input.getType()).getElementType();\n-  auto shaped_type = mlir::cast<ShapedType>(input.getType());\n-\n-  SmallVector<Value> zero_indices;\n-  zero_indices.assign(shaped_type.getRank(),\n-                      b.create<mlir::arith::ConstantIndexOp>(0));\n-\n-  return ScalarOrTensor(\n-      b.create<mlir::tensor::ExtractOp>(element_type, input, zero_indices));\n-}\n-\n-absl::StatusOr<ScalarOrTensor> EmitTiledReshape(EmitterLocOpBuilder b,\n-                                                ArrayRef<int64_t> tile_sizes,\n-                                                ScalarOrTensor input) {\n+absl::StatusOr<TensorValue> EmitTiledReshape(EmitterLocOpBuilder b,\n+                                             ArrayRef<int64_t> tile_sizes,\n+                                             TensorValue input) {\n+  mlir::RankedTensorType input_type = input.getType();\n   SmallVector<int64_t> padded_tile_sizes = GetPaddedTileSizes(tile_sizes);\n \n-  if (input.IsScalar()) {\n-    if (tile_sizes.empty()) {\n-      // Nothing to do.\n-      return input;\n-    }\n-    // Convert the scalar to a tensor.\n-    return Splat(b, input, padded_tile_sizes);\n-  }\n-\n-  // At this point we know that the input is a non-0D tensor.\n-  auto input_shaped_type = mlir::cast<ShapedType>(input.getType());\n-\n-  // Handle the case of reshaping [1,1,1...] to a scalar.\n-  if (tile_sizes.empty()) {\n-    return ReshapeTensorToScalar(b, input.UnwrapTensor());\n-  }\n-\n   // At this point we know that neither the input nor the output are 0D tensors.\n   auto output_tensor_type = mlir::RankedTensorType::get(\n-      padded_tile_sizes, input_shaped_type.getElementType());\n+      padded_tile_sizes, input_type.getElementType());\n \n-  if (input_shaped_type.getNumElements() !=\n-      output_tensor_type.getNumElements()) {\n+  if (input_type.getNumElements() != output_tensor_type.getNumElements()) {\n     return absl::InvalidArgumentError(\n         absl::StrCat(\"Reshape input and output shapes must be the same, got \",\n-                     absl::StrJoin(input_shaped_type.getShape(), \"x\"), \" -> \",\n+                     absl::StrJoin(input_type.getShape(), \"x\"), \" -> \",\n                      absl::StrJoin(output_tensor_type.getShape(), \"x\")));\n   }\n \n-  auto reshape =\n-      b.create<stablehlo::ReshapeOp>(output_tensor_type, input.UnwrapUnsafe());\n-  return ScalarOrTensor(reshape.getResult());\n+  return b.create<stablehlo::ReshapeOp>(output_tensor_type, input);\n }\n \n Value EmitTiledTranspose(EmitterLocOpBuilder b, ArrayRef<int64_t> tile_sizes,\n@@ -730,20 +698,19 @@ absl::StatusOr<ScalarOrTensor> EmitTiledBitcast(\n   if (ShapeUtil::Equal(trt->transpose1_shape, trt->reshape_shape)) {\n     normalized_reshape = normalized_input;\n   } else {\n-    TF_ASSIGN_OR_RETURN(auto reshape,\n+    TF_ASSIGN_OR_RETURN(normalized_reshape,\n                         EmitTiledReshape(b, reshape_tile_sizes,\n-                                         ScalarOrTensor(normalized_input)));\n-    normalized_reshape = reshape.UnwrapUnsafe();\n+                                         MakeTensor(b, normalized_input)));\n   }\n \n   // The final transpose simply uses the tile sizes computed for the original\n   // bitcast by the tiling analysis.\n-  return ScalarOrTensor{\n-      trt->IsTranspose2Identity()\n-          ? normalized_reshape\n-          : EmitTiledTranspose(b, tiled_bitcast.tile_sizes(),\n-                               llvm::to_vector(trt->transpose2_dims),\n-                               normalized_reshape)};\n+  return MakeScalarOrTensor(\n+      b, trt->IsTranspose2Identity()\n+             ? normalized_reshape\n+             : EmitTiledTranspose(b, tiled_bitcast.tile_sizes(),\n+                                  llvm::to_vector(trt->transpose2_dims),\n+                                  normalized_reshape));\n }\n \n absl::StatusOr<std::vector<ScalarOrTensor>> EmitTiledComputation(\n@@ -913,10 +880,8 @@ absl::StatusOr<Value> CanonicalizeDotOperand(\n   }\n \n   if (shape.size() != shape_without_unit_dims.size()) {\n-    TF_ASSIGN_OR_RETURN(\n-        ScalarOrTensor wrapped_operand,\n-        EmitTiledReshape(b, shape_without_unit_dims, ScalarOrTensor(operand)));\n-    operand = wrapped_operand.UnwrapTensor();\n+    TF_ASSIGN_OR_RETURN(operand, EmitTiledReshape(b, shape_without_unit_dims,\n+                                                  MakeTensor(b, operand)));\n   }\n \n   int expected_contracting_dim_position = side == DotOperandSide::kLhs ? 1 : 0;\n@@ -1094,12 +1059,10 @@ absl::StatusOr<ScalarOrTensor> EmitDot(\n \n   if (padded_tile_sizes.size() != padded_tile_sizes_no_unit_dims.size()) {\n     TF_ASSIGN_OR_RETURN(\n-        ScalarOrTensor wrapped_result,\n-        EmitTiledReshape(b, padded_tile_sizes, ScalarOrTensor(result)));\n-    result = wrapped_result.UnwrapTensor();\n+        result, EmitTiledReshape(b, padded_tile_sizes, MakeTensor(b, result)));\n   }\n \n-  return ScalarOrTensor(result);\n+  return MakeScalarOrTensor(b, result);\n }\n \n absl::StatusOr<ScalarOrTensor> EmitScaledDot(\n@@ -1248,12 +1211,10 @@ absl::StatusOr<ScalarOrTensor> EmitScaledDot(\n \n   if (padded_tile_sizes.size() != padded_tile_sizes_no_unit_dims.size()) {\n     TF_ASSIGN_OR_RETURN(\n-        ScalarOrTensor wrapped_result,\n-        EmitTiledReshape(b, padded_tile_sizes, ScalarOrTensor(result)));\n-    result = wrapped_result.UnwrapTensor();\n+        result, EmitTiledReshape(b, padded_tile_sizes, MakeTensor(b, result)));\n   }\n \n-  return ScalarOrTensor(result);\n+  return MakeScalarOrTensor(b, result);\n }\n \n absl::StatusOr<ScalarOrTensor> EmitConcatenate(\n@@ -1534,8 +1495,12 @@ absl::StatusOr<ScalarOrTensor> EmitTiledHloInstruction(\n   }\n \n   if (hlo->opcode() == HloOpcode::kReshape) {\n-    return EmitTiledReshape(b, tiled_hlo.tile_sizes(),\n-                            values[tiled_hlo.operand(0)]);\n+    TF_ASSIGN_OR_RETURN(\n+        TensorValue reshaped_value,\n+        EmitTiledReshape(\n+            b, tiled_hlo.tile_sizes(),\n+            MakeTensor(b, values[tiled_hlo.operand(0)].UnwrapUnsafe())));\n+    return MakeScalarOrTensor(b, reshaped_value);\n   }\n \n   if (hlo->opcode() == HloOpcode::kBitcast) {"
        },
        {
            "sha": "0cb618f1b9216671c525c480cb76c29f3269f6c1",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=5ebdbc129c2f3a1f91749acd8680f33d15d92754",
            "patch": "@@ -3083,8 +3083,7 @@ ENTRY entry_computation {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto xtile_module_and_hlo_module,\n       CreateXTileIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n-CHECK:     tensor.extract %{{.*}}[%{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}] : tensor<1x1x1x1xf32>\n-CHECK:     tensor.extract %{{.*}}[%{{.*}}] : tensor<1xf32>\n+CHECK:     stablehlo.reshape {{.*}} : (tensor<1x1x1x1xf32>) -> tensor<f32>\n CHECK:     xtile.insert {{.*}} : tensor<f32>\n )\"));\n "
        },
        {
            "sha": "e78f16e3abbc0f18d3262390b7bc06673f77c3b9",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/stablehlo_lower_to_triton.cc",
            "status": "modified",
            "additions": 65,
            "deletions": 2,
            "changes": 67,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc?ref=5ebdbc129c2f3a1f91749acd8680f33d15d92754",
            "patch": "@@ -21,9 +21,7 @@ limitations under the License.\n #include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/SmallVector.h\"\n #include \"llvm/Support/Casting.h\"\n-#include \"llvm/Support/raw_ostream.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n-#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/Diagnostics.h\"\n@@ -253,13 +251,78 @@ class LowerReshape : public mlir::OpRewritePattern<stablehlo::ReshapeOp> {\n  private:\n   mlir::LogicalResult matchAndRewrite(\n       stablehlo::ReshapeOp op, mlir::PatternRewriter& rewriter) const override {\n+    bool input_is_0d = op.getOperand().getType().getRank() == 0;\n+    bool output_is_0d = op.getType().getRank() == 0;\n+\n+    if (input_is_0d && output_is_0d) {\n+      rewriter.replaceAllUsesWith(op, op.getOperand());\n+      return mlir::success();\n+    }\n+\n+    if (input_is_0d) {\n+      auto to_scalar = ::xla::xtile::ToScalarOp::create(rewriter, op->getLoc(),\n+                                                        op.getOperand());\n+      rewriter.replaceOpWithNewOp<ttir::SplatOp>(op, op.getType(), to_scalar);\n+      return mlir::success();\n+    }\n+\n+    if (output_is_0d) {\n+      // We know the input dimensions must be all 1s as reshape input-output\n+      // must have the same number of elements.\n+      return LowerRank0ToReduce(op, rewriter);\n+    }\n+\n     // Conservatively prevent Triton from reordering elements within the tile.\n     // TODO(b/353637689): see if this restriction can be lifted.\n     bool allow_reorder = false;\n     rewriter.replaceOpWithNewOp<ttir::ReshapeOp>(\n         op, op.getResult().getType(), op.getOperand(), allow_reorder);\n     return mlir::success();\n   }\n+\n+  static mlir::LogicalResult LowerRank0ToReduce(\n+      stablehlo::ReshapeOp op, mlir::PatternRewriter& rewriter) {\n+    auto input_tensor_type = op.getOperand().getType();\n+\n+    // First, reshape to a 1D tensor if not already the case. This is needed\n+    // because triton::ReduceOp can only reduce 1 dimension at a time.\n+    auto single_dim_tensor = op.getOperand();\n+    if (input_tensor_type.getRank() > 1) {\n+      Type output_tensor_type =\n+          mlir::RankedTensorType::get({1}, input_tensor_type.getElementType());\n+      single_dim_tensor = ttir::ReshapeOp::create(\n+          rewriter, op.getLoc(), output_tensor_type, single_dim_tensor,\n+          /*allow_reorder=*/true);\n+    }\n+\n+    // Second, reduce to a scalar.\n+    ttir::ReduceOp reduction = ttir::ReduceOp::create(\n+        rewriter, op.getLoc(), single_dim_tensor, /*axis=*/0);\n+\n+    auto element_type = input_tensor_type.getElementType();\n+    mlir::Location loc = op.getLoc();\n+    mlir::Block* reducer =\n+        rewriter.createBlock(&reduction->getRegion(0), /*insertPt=*/{},\n+                             /*argTypes=*/\n+                             {element_type, element_type},\n+                             /*locs=*/{loc, loc});\n+\n+    rewriter.setInsertionPointToStart(reducer);\n+    auto create_binary_op = [&](auto op_type) -> Value {\n+      return op_type.create(rewriter, reducer->getArgument(0).getLoc(),\n+                            reducer->getArgument(0), reducer->getArgument(1));\n+    };\n+    Value result = mlir::isa<mlir::IntegerType>(element_type)\n+                       ? create_binary_op(arith::AddIOp())\n+                       : create_binary_op(arith::AddFOp());\n+    ttir::ReduceReturnOp::create(rewriter, result.getLoc(), {result});\n+\n+    rewriter.setInsertionPointAfter(reduction);\n+    rewriter.replaceOpWithNewOp<::xla::xtile::ToTensorOp>(\n+        op, reduction.getResult());\n+\n+    return mlir::success();\n+  }\n };\n \n class StableHLOLowerToTritonPass"
        },
        {
            "sha": "02daf07fe1751ad1ee9afbf0681b05642115b9fe",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tensor_lower_to_triton.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 69,
            "changes": 70,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftensor_lower_to_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftensor_lower_to_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftensor_lower_to_triton.cc?ref=5ebdbc129c2f3a1f91749acd8680f33d15d92754",
            "patch": "@@ -13,17 +13,12 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include <cstdint>\n #include <memory>\n #include <utility>\n \n-#include \"absl/algorithm/container.h\"\n-#include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n-#include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/Diagnostics.h\"\n-#include \"mlir/IR/Location.h\"\n #include \"mlir/IR/PatternMatch.h\"\n #include \"mlir/Pass/Pass.h\"\n #include \"mlir/Support/LLVM.h\"\n@@ -54,68 +49,6 @@ class LowerBitcast : public mlir::OpRewritePattern<tensor::BitcastOp> {\n   }\n };\n \n-class LowerExtractOnOneElementTensorToReshapeReduce\n-    : public mlir::OpRewritePattern<tensor::ExtractOp> {\n- public:\n-  using OpRewritePattern::OpRewritePattern;\n-\n- private:\n-  mlir::LogicalResult matchAndRewrite(\n-      tensor::ExtractOp op, mlir::PatternRewriter& rewriter) const override {\n-    auto input_tensor_type = op.getTensor().getType();\n-    auto input_tensor_shape = input_tensor_type.getShape();\n-\n-    if (input_tensor_shape.empty() ||\n-        !absl::c_all_of(input_tensor_shape,\n-                        [](int64_t dim) { return dim == 1; })) {\n-      return rewriter.notifyMatchFailure(\n-          op,\n-          \"Extract will only be lowered for tensors with all dimensions equal \"\n-          \"to 1.\");\n-    }\n-\n-    // First, reshape to a 1D tensor if not already the case. This is needed\n-    // because triton::ReduceOp can only reduce 1 dimension at a time.\n-    auto single_dim_tensor = op.getTensor();\n-    if (input_tensor_type.getRank() > 1) {\n-      Type output_tensor_type =\n-          mlir::RankedTensorType::get({1}, input_tensor_type.getElementType());\n-      single_dim_tensor = ttir::ReshapeOp::create(\n-          rewriter, op.getLoc(), output_tensor_type, single_dim_tensor,\n-          /*allow_reorder=*/true);\n-    }\n-\n-    // Second, reduce to a scalar.\n-    ttir::ReduceOp reduction = ttir::ReduceOp::create(\n-        rewriter, op.getLoc(), single_dim_tensor, /*axis=*/0);\n-\n-    auto element_type = input_tensor_type.getElementType();\n-    mlir::Location loc = op.getLoc();\n-    mlir::Block* reducer =\n-        rewriter.createBlock(&reduction->getRegion(0), /*insertPt=*/{},\n-                             /*argTypes=*/\n-                             {element_type, element_type},\n-                             /*locs=*/{loc, loc});\n-\n-    rewriter.setInsertionPointToStart(reducer);\n-    Value result = mlir::isa<mlir::IntegerType>(element_type)\n-                       ? arith::AddIOp::create(\n-                             rewriter, reducer->getArgument(0).getLoc(),\n-                             reducer->getArgument(0), reducer->getArgument(1))\n-                             .getResult()\n-                       : arith::AddFOp::create(\n-                             rewriter, reducer->getArgument(0).getLoc(),\n-                             reducer->getArgument(0), reducer->getArgument(1))\n-                             .getResult();\n-    ttir::ReduceReturnOp::create(rewriter, result.getLoc(),\n-                                 SmallVector<Value>({result}));\n-    rewriter.setInsertionPointAfter(reduction);\n-    rewriter.replaceOp(op, reduction);\n-\n-    return mlir::success();\n-  }\n-};\n-\n // TODO(basioli): Consider fusing this with the stablehlo lowering pass into a\n // single xtile to triton lowering pass.\n class TensorLowerToTritonPass\n@@ -124,8 +57,7 @@ class TensorLowerToTritonPass\n   void runOnOperation() override {\n     mlir::MLIRContext* mlir_context = &getContext();\n     mlir::RewritePatternSet patterns(mlir_context);\n-    patterns.add<LowerBitcast, LowerExtractOnOneElementTensorToReshapeReduce>(\n-        mlir_context);\n+    patterns.add<LowerBitcast>(mlir_context);\n \n     if (mlir::failed(\n             mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {"
        },
        {
            "sha": "eb939634ffac85d6da1f20b6360e1188ce36cf75",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/stable_hlo_to_triton_lowering.mlir",
            "status": "modified",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir?ref=5ebdbc129c2f3a1f91749acd8680f33d15d92754",
            "patch": "@@ -135,3 +135,32 @@ func.func @lower_reshape(%arg0: tensor<2x4x8xf32>) -> tensor<8x2x4xf32> {\n   return %0 : tensor<8x2x4xf32>\n }\n \n+// CHECK-LABEL: @reshape_0d_to_0d_folds(%arg0: tensor<f32>)\n+func.func @reshape_0d_to_0d_folds(%arg0: tensor<f32>) -> tensor<f32> {\n+  %0 = stablehlo.reshape %arg0 : (tensor<f32>) -> tensor<f32>\n+  // CHECK: return %arg0 : tensor<f32>\n+  return %0 : tensor<f32>\n+}\n+\n+// CHECK-LABEL: @reshape_0d_to_2d_splats(%arg0: tensor<f32>)\n+func.func @reshape_0d_to_2d_splats(%arg0: tensor<f32>) -> tensor<1x1xf32> {\n+  // CHECK: %[[SCALAR:.*]] = xtile.to_scalar %arg0 : tensor<f32>\n+  // CHECK: %[[SPLAT:.*]] = tt.splat %[[SCALAR]] : f32 -> tensor<1x1xf32>\n+  %0 = stablehlo.reshape %arg0 : (tensor<f32>) -> tensor<1x1xf32>\n+  // CHECK: return %[[SPLAT]]\n+  return %0 : tensor<1x1xf32>\n+}\n+\n+// CHECK-LABEL: @reshape_2d_to_0d_reduces(%arg0: tensor<1x1xf32>)\n+func.func @reshape_2d_to_0d_reduces(%arg0: tensor<1x1xf32>) -> tensor<f32> {\n+  // CHECK: %[[RESHAPE:.*]] = tt.reshape %arg0 allow_reorder : tensor<1x1xf32> -> tensor<1xf32>\n+  // CHECK: %[[REDUCE:.*]] = \"tt.reduce\"(%[[RESHAPE]]) <{axis = 0 : i32}> ({\n+  // CHECK:  ^bb0(%arg1: f32, %arg2: f32):\n+  // CHECK:    %[[ADD:.*]] = arith.addf %arg1, %arg2 : f32\n+  // CHECK:    tt.reduce.return %[[ADD]] : f32\n+  // CHECK:  }) : (tensor<1xf32>) -> f32\n+  // CHECK:  %[[TO_TENSOR:.*]] = xtile.to_tensor %[[REDUCE]] : f32\n+  %0 = stablehlo.reshape %arg0 : (tensor<1x1xf32>) -> tensor<f32>\n+  // CHECK: return %[[TO_TENSOR]]\n+  return %0 : tensor<f32>\n+}"
        },
        {
            "sha": "6ce9f505c8f41d75f0be39f66bb5c49cdb0c8cee",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/tensor_to_triton_lowering.mlir",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftensor_to_triton_lowering.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ebdbc129c2f3a1f91749acd8680f33d15d92754/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftensor_to_triton_lowering.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftensor_to_triton_lowering.mlir?ref=5ebdbc129c2f3a1f91749acd8680f33d15d92754",
            "patch": "@@ -11,27 +11,3 @@ func.func @lower_bitcast(%arg0: tensor<2x4x8xf32>) -> tensor<2x4x8xi32> {\n   // CHECK: return %[[RES]] : tensor<2x4x8xi32>\n   return %0 : tensor<2x4x8xi32>\n }\n-\n-// CHECK: func @lower_extract_on_one_element_tensor(%[[ARG:.*]]: tensor<1x1x1xf32>) -> f32\n-func.func @lower_extract_on_one_element_tensor(%arg0: tensor<1x1x1xf32>) -> f32 {\n-  %c0 = arith.constant 0 : index\n-  // CHECK: %[[RESHAPE:.*]] = tt.reshape %[[ARG]] allow_reorder : tensor<1x1x1xf32> -> tensor<1xf32>\n-  // CHECK: %[[RES:.*]] = \"tt.reduce\"(%[[RESHAPE]]) <{axis = 0 : i32}> ({\n-  // CHECK:   ^bb0(%[[ARG1:.*]]: f32, %[[ARG2:.*]]: f32):\n-  // CHECK:     %[[ADD:.*]] = arith.addf %[[ARG1]], %[[ARG2]] : f32\n-  // CHECK:     tt.reduce.return %[[ADD]] : f32\n-  // CHECK:   }) : (tensor<1xf32>) -> f32 \n-  %0 = tensor.extract %arg0[%c0, %c0, %c0] : tensor<1x1x1xf32>\n-  // CHECK: return %[[RES]] : f32\n-  return %0 : f32\n-}\n-\n-\n-// CHECK: func @lower_extract_on_multiple_element_tensor_falls_back_to_tensor(%[[ARG:.*]]: tensor<1x1x3xf32>) -> f32\n-func.func @lower_extract_on_multiple_element_tensor_falls_back_to_tensor(%arg0: tensor<1x1x3xf32>) -> f32 {\n-  %c0 = arith.constant 0 : index\n-  // CHECK: %[[RES:.*]] = tensor.extract %[[ARG]][%c0, %c0, %c0] : tensor<1x1x3xf32>\n-  %0 = tensor.extract %arg0[%c0, %c0, %c0] : tensor<1x1x3xf32>\n-  // CHECK: return %[[RES]] : f32\n-  return %0 : f32\n-}\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 284,
        "additions": 124,
        "deletions": 160
    }
}