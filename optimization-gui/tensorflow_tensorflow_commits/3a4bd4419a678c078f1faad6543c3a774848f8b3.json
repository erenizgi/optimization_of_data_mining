{
    "author": "tensorflower-gardener",
    "message": "Reverts 335be54cf16896a093589c755dd9ee7d012216b6\n\nPiperOrigin-RevId: 836408290",
    "sha": "3a4bd4419a678c078f1faad6543c3a774848f8b3",
    "files": [
        {
            "sha": "ee7a7c00b8e4c2503b585fc4d7328b9c9f8becc8",
            "filename": "third_party/xla/xla/backends/cpu/codegen/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -706,7 +706,6 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:util\",\n         \"//xla/backends/cpu:alignment\",\n-        \"//xla/backends/cpu/codegen/tiled:tiled_fusion_emitter\",\n         \"//xla/codegen:hlo_fusion_spec\",\n         \"//xla/codegen:ir_emission_utils\",\n         \"//xla/codegen:kernel_definition\","
        },
        {
            "sha": "80d6f4444b536a10b7e0e40ab417157f79e91079",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -331,9 +331,6 @@ static void AddTiledOptimizationPasses(mlir::OpPassManager& pm) {\n   AddBufferizationPasses(pm);\n \n   pm.addPass(CreateLinalgElementwiseToVectorPass());\n-\n-  pm.addPass(mlir::createCanonicalizerPass());\n-  pm.addPass(mlir::createCSEPass());\n }\n \n // Lowering passes for the tiled emitter."
        },
        {
            "sha": "930911b3d6850487f8eecee3afefaba5d4945cce",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_emitter.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 15,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.cc?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -18,7 +18,6 @@ limitations under the License.\n #include <cstdint>\n #include <functional>\n #include <memory>\n-#include <optional>\n #include <string>\n #include <utility>\n \n@@ -37,7 +36,6 @@ limitations under the License.\n #include \"xla/backends/cpu/alignment.h\"\n #include \"xla/backends/cpu/codegen/kernel_api_ir_builder.h\"\n #include \"xla/backends/cpu/codegen/symbol_name_util.h\"\n-#include \"xla/backends/cpu/codegen/tiled/tiled_fusion_emitter.h\"\n #include \"xla/codegen/emitters/concatenate_kernel_emitter.h\"\n #include \"xla/codegen/emitters/dynamic_update_slice_kernel_emitter.h\"\n #include \"xla/codegen/emitters/ir/xla_ops.h\"\n@@ -285,20 +283,9 @@ EmitDynamicUpdateSliceFusionKernel(MLIRContext& context,\n \n absl::StatusOr<KernelDefinition<MlirKernelSource>> EmitFusionKernel(\n     MLIRContext& mlir_context, const HloFusionInstruction& fusion,\n-    const BufferAssignment* buffer_assignment, bool use_unique_c_name,\n-    bool enable_tiled_emitter) {\n-  TF_ASSIGN_OR_RETURN(std::string name, GetName(fusion, use_unique_c_name));\n-\n-  if (enable_tiled_emitter) {\n-    if (auto tiling_or = GetTilingIfSupported(mlir_context, fusion);\n-        tiling_or.ok()) {\n-      return EmitTiledFusionKernel(mlir_context, fusion, buffer_assignment,\n-                                   name, GetWorkGroupCount(fusion),\n-                                   std::move(*tiling_or));\n-    }\n-  }\n-\n+    const BufferAssignment* buffer_assignment, bool use_unique_c_name) {\n   if (fusion.fusion_kind() == HloFusionInstruction::FusionKind::kLoop) {\n+    TF_ASSIGN_OR_RETURN(std::string name, GetName(fusion, use_unique_c_name));\n     const HloInstruction& hero =\n         FindNonTrivialHero(*fusion.fused_expression_root());\n     if (hero.opcode() == HloOpcode::kConcatenate) {"
        },
        {
            "sha": "bf5b791d8367ae82f91adb4349bb514cc3ea25c1",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_emitter.h",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter.h?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -31,8 +31,7 @@ emitters::KernelArguments::BufferAlignment GetDefaultBufferAlignment();\n \n absl::StatusOr<KernelDefinition<MlirKernelSource>> EmitFusionKernel(\n     mlir::MLIRContext& mlir_context, const HloFusionInstruction& fusion,\n-    const BufferAssignment* buffer_assignment, bool use_unique_c_name,\n-    bool enable_tiled_emitter);\n+    const BufferAssignment* buffer_assignment, bool use_unique_c_name);\n \n }  // namespace xla::cpu\n "
        },
        {
            "sha": "54567125487887193cce5b7eea84b2e95de996b6",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_emitter_test.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_emitter_test.py?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -57,7 +57,6 @@ def test_basic_add_sub(self):\n         mlir_context,\n         hlo_module.get_root_instruction(),\n         buffer_assignment,\n-        False,\n     )\n \n     kernel_runner = testlib_cpu.KernelRunner.create(\n@@ -118,7 +117,6 @@ def test_convert_f32_bf16_f32(self):\n         mlir_context,\n         hlo_module.get_root_instruction(),\n         buffer_assignment,\n-        False,\n     )\n \n     kernel_runner = testlib_cpu.KernelRunner.create(\n@@ -174,7 +172,6 @@ def test_convert_f32_bf16_f32_nan(self):\n         mlir_context,\n         hlo_module.get_root_instruction(),\n         buffer_assignment,\n-        False,\n     )\n \n     kernel_runner = testlib_cpu.KernelRunner.create(\n@@ -227,7 +224,6 @@ def test_constant_with_layout(self):\n         mlir_context,\n         hlo_module.get_root_instruction(),\n         buffer_assignment,\n-        False,\n     )\n \n     kernel_runner = testlib_cpu.KernelRunner.create(\n@@ -277,7 +273,6 @@ def test_exp_nan_dce(self):\n         mlir_context,\n         hlo_module.get_root_instruction(),\n         buffer_assignment,\n-        False,\n     )\n \n     kernel_runner = testlib_cpu.KernelRunner.create("
        },
        {
            "sha": "314ec5265b016b287ae99654e513630fe62d1700",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 47,
            "changes": 47,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2FBUILD?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -1,9 +1,4 @@\n load(\"//xla:py_strict.bzl\", \"py_strict_test\")\n-load(\n-    \"//xla/stream_executor:build_defs.bzl\",\n-    \"if_cuda_or_rocm_is_configured\",\n-)\n-load(\"//xla/tsl/platform:rules_cc.bzl\", \"cc_library\")\n \n package(\n     # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n@@ -24,45 +19,3 @@ py_strict_test(\n         \"@absl_py//absl/testing:absltest\",\n     ],\n )\n-\n-cc_library(\n-    name = \"tiled_fusion_emitter\",\n-    # As the tiled emitter currently depends on GPU code we need to add a stub in the case that CUDA\n-    # or ROCm is not enabled (in effect this is non-Linux builds).\n-    srcs = if_cuda_or_rocm_is_configured(\n-        [\"tiled_fusion_emitter.cc\"],\n-        [\"tiled_fusion_emitter_stub.cc\"],\n-    ),\n-    hdrs = [\"tiled_fusion_emitter.h\"],\n-    visibility = [\"//xla/backends/cpu/codegen:__pkg__\"],\n-    deps = [\n-        \"//xla:shape_util\",\n-        \"//xla:util\",\n-        \"//xla/backends/cpu/codegen:kernel_api_ir_builder\",\n-        \"//xla/codegen:kernel_definition\",\n-        \"//xla/codegen:kernel_spec\",\n-        \"//xla/codegen:mlir_kernel_source\",\n-        \"//xla/codegen/emitters:kernel_api_builder\",\n-        \"//xla/codegen/emitters/ir:xla\",\n-        \"//xla/codegen/tiling:symbolic_tile_analysis\",\n-        \"//xla/codegen/tiling:tiling_specification\",\n-        \"//xla/codegen/xtile/ir:xtile\",\n-        \"//xla/hlo/analysis:symbolic_expr\",\n-        \"//xla/hlo/ir:hlo\",\n-        \"//xla/runtime:work_dimensions\",\n-        \"//xla/service:buffer_assignment\",\n-        \"//xla/service:instruction_fusion\",\n-        \"//xla/service/gpu/model:block_level_parameters\",\n-        \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/log:check\",\n-        \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/status:statusor\",\n-        \"@com_google_absl//absl/strings\",\n-        \"@com_google_absl//absl/strings:string_view\",\n-        \"@com_google_absl//absl/types:span\",\n-        \"@llvm-project//llvm:Support\",\n-        \"@llvm-project//mlir:IR\",\n-    ] + if_cuda_or_rocm_is_configured([\n-        \"//xla/backends/gpu/codegen/triton:fusion_emitter\",\n-    ]),\n-)"
        },
        {
            "sha": "ef29eb2231841adaf279738fc727702728530699",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/tiled_fusion_emitter.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 242,
            "changes": 242,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3ed1e7a0e28efd0e77fd9fabca604a66d3bfe328/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3ed1e7a0e28efd0e77fd9fabca604a66d3bfe328/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.cc?ref=3ed1e7a0e28efd0e77fd9fabca604a66d3bfe328",
            "patch": "@@ -1,242 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/backends/cpu/codegen/tiled/tiled_fusion_emitter.h\"\n-\n-#include <algorithm>\n-#include <cstdint>\n-#include <cstdlib>\n-#include <limits>\n-#include <utility>\n-#include <variant>\n-#include <vector>\n-\n-#include \"absl/log/check.h\"\n-#include \"absl/status/statusor.h\"\n-#include \"absl/strings/str_cat.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"absl/types/span.h\"\n-#include \"llvm/ADT/ArrayRef.h\"\n-#include \"llvm/ADT/STLExtras.h\"\n-#include \"mlir/IR/BuiltinAttributes.h\"\n-#include \"mlir/IR/MLIRContext.h\"\n-#include \"xla/backends/cpu/codegen/kernel_api_ir_builder.h\"\n-#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n-#include \"xla/codegen/emitters/ir/xla_ops.h\"\n-#include \"xla/codegen/emitters/kernel_api_builder.h\"\n-#include \"xla/codegen/kernel_definition.h\"\n-#include \"xla/codegen/kernel_spec.h\"\n-#include \"xla/codegen/mlir_kernel_source.h\"\n-#include \"xla/codegen/tiling/symbolic_tile_analysis.h\"\n-#include \"xla/codegen/tiling/tiling_specification.h\"\n-#include \"xla/codegen/xtile/ir/xtile_attrs.h\"\n-#include \"xla/codegen/xtile/ir/xtile_ops.h\"\n-#include \"xla/hlo/ir/hlo_instruction.h\"\n-#include \"xla/hlo/ir/hlo_instructions.h\"\n-#include \"xla/hlo/ir/hlo_opcode.h\"\n-#include \"xla/layout.h\"\n-#include \"xla/primitive_util.h\"\n-#include \"xla/runtime/work_dimensions.h\"\n-#include \"xla/service/buffer_assignment.h\"\n-#include \"xla/service/gpu/model/block_level_parameters.h\"\n-#include \"xla/service/instruction_fusion.h\"\n-#include \"xla/shape.h\"\n-#include \"xla/shape_util.h\"\n-#include \"xla/tsl/platform/statusor.h\"\n-#include \"xla/util.h\"\n-\n-namespace xla::cpu {\n-\n-absl::StatusOr<std::vector<FlatTiling>> GetTiling(\n-    mlir::MLIRContext& context, const HloFusionInstruction& fusion) {\n-  auto symbolic_tile_analysis_or = SymbolicTileAnalysis::AnalyzeComputation(\n-      *fusion.fused_instructions_computation(), &context);\n-  if (std::holds_alternative<FusionDecision>(symbolic_tile_analysis_or)) {\n-    return Internal(\n-        \"Unsupported fusion in EmitGeneric: %s\",\n-        std::get<FusionDecision>(symbolic_tile_analysis_or).Explain());\n-  }\n-\n-  const auto& symbolic_tile_analysis =\n-      std::get<SymbolicTileAnalysis>(symbolic_tile_analysis_or);\n-\n-  TF_ASSIGN_OR_RETURN(auto valid_tilings,\n-                      symbolic_tile_analysis.GetValidTilings());\n-  if (valid_tilings.empty()) {\n-    return Internal(\"No valid tilings found for fusion: %s\", fusion.name());\n-  }\n-\n-  // TODO(willfroom): Improve this heuristic.\n-  constexpr int64_t kTargetDimSize = 8;\n-\n-  auto l1_distance = [&](llvm::ArrayRef<int64_t> tile_sizes) {\n-    int64_t distance = 0;\n-    for (auto [dim, tile_size] :\n-         llvm::zip(fusion.shape().dimensions(), tile_sizes)) {\n-      auto target_dim = std::min<int64_t>(dim, kTargetDimSize);\n-      distance += std::abs(target_dim - tile_size);\n-    }\n-    return distance;\n-  };\n-\n-  auto root_hlo = fusion.fused_instructions_computation()->root_instruction();\n-  std::vector<int64_t> filtered_tilings;\n-  int64_t best_distance = std::numeric_limits<int64_t>::max();\n-  FlatTiling best_tile_sizes;\n-  for (const auto& tiling : valid_tilings) {\n-    auto tile_sizes = tiling.tile_sizes().at(root_hlo);\n-    auto distance_to_target = l1_distance(tile_sizes);\n-\n-    if (distance_to_target < best_distance) {\n-      best_distance = distance_to_target;\n-      best_tile_sizes.assign(tile_sizes.begin(), tile_sizes.end());\n-    }\n-  }\n-\n-  std::vector<FlatTiling> result{best_tile_sizes};\n-  return result;\n-}\n-\n-// We don't currently support sub-byte types in the tiled CPU emitter.\n-static bool IsSupportedType(PrimitiveType type) {\n-  if (type == PRED) {\n-    return true;\n-  }\n-\n-  if (primitive_util::BitWidth(type) < 8) {\n-    return false;\n-  }\n-\n-  if (primitive_util::IsUnsignedIntegralType(type)) {\n-    return false;\n-  }\n-\n-  if (primitive_util::IsComplexType(type)) {\n-    return false;\n-  }\n-\n-  return true;\n-}\n-\n-static bool IsSupportedShape(const Shape& shape) {\n-  bool is_supported = true;\n-  ShapeUtil::ForEachSubshape(\n-      shape, [&](const Shape& subshape, const ShapeIndex& index) {\n-        if (subshape.IsArray()) {\n-          if (!IsSupportedType(subshape.element_type())) {\n-            is_supported = false;\n-          }\n-        }\n-      });\n-\n-  return is_supported;\n-}\n-\n-static bool IsSupportedInstruction(const HloInstruction& inst) {\n-  HloOpcode opcode = inst.opcode();\n-  switch (opcode) {\n-    case xla::HloOpcode::kBitcast:\n-    case xla::HloOpcode::kIota:\n-    case xla::HloOpcode::kReshape:\n-    case xla::HloOpcode::kTranspose:\n-    case xla::HloOpcode::kParameter:\n-    case xla::HloOpcode::kConstant:\n-      return true;\n-    case xla::HloOpcode::kBitcastConvert:\n-      return false;\n-      break;\n-    default:\n-      return inst.IsElementwise();\n-  }\n-}\n-\n-absl::StatusOr<std::vector<FlatTiling>> GetTilingIfSupported(\n-    mlir::MLIRContext& context, const HloFusionInstruction& fusion) {\n-  // TODO(willfroom): Support multi-output fusions.\n-  if (!fusion.shape().IsArray()) {\n-    return Internal(\n-        \"Multi-output fusions are not supported by the tiled CPU emitter.\");\n-  }\n-\n-  for (const HloInstruction* operand : fusion.operands()) {\n-    if (!operand->shape().IsArray()) {\n-      return Internal(\n-          \"Non-array operands are not supported by the tiled CPU emitter.\");\n-    }\n-  }\n-\n-  for (const HloInstruction* inst : fusion.fused_instructions()) {\n-    if (!IsSupportedShape(inst->shape())) {\n-      return Internal(\n-          \"Instruction %s has a type, which is not supported by the \"\n-          \"tiled CPU emitter.\",\n-          inst->ToString());\n-    }\n-\n-    if (!IsSupportedInstruction(*inst)) {\n-      return Internal(\n-          \"Instruction %s is not supported by the tiled CPU emitter.\",\n-          inst->ToString());\n-    }\n-  }\n-\n-  return GetTiling(context, fusion);\n-}\n-\n-absl::StatusOr<KernelDefinition<MlirKernelSource>> EmitTiledFusionKernel(\n-    mlir::MLIRContext& context, const HloFusionInstruction& fusion,\n-    const BufferAssignment* buffer_assignment, absl::string_view name,\n-    int64_t num_work_groups, absl::Span<const FlatTiling> tiling) {\n-  gpu::BlockLevelParameters block_level_parameters;\n-  for (const auto& tile_sizes : tiling) {\n-    block_level_parameters.output_tile_sizes.emplace_back(tile_sizes.begin(),\n-                                                          tile_sizes.end());\n-  }\n-\n-  TF_ASSIGN_OR_RETURN(\n-      auto module,\n-      gpu::ir_emitter_triton_internal::EmitXTileModule(\n-          name, nullptr, &fusion, block_level_parameters, context));\n-  module->setName(absl::StrCat(\"__compute_module\", \"_\", name));\n-\n-  int64_t num_tiles = 1;\n-  for (auto [dim, tile_size] :\n-       llvm::zip(fusion.shape().dimensions(),\n-                 block_level_parameters.output_tile_sizes.front())) {\n-    num_tiles *= CeilOfRatio(dim, tile_size);\n-  }\n-  int64_t tiles_per_workgroup =\n-      CeilOfRatio<int64_t>(num_tiles, num_work_groups);\n-  module->walk([&](xtile::EntryFuncOp op) {\n-    auto info = xtile::TilingInfoAttr::get(op->getContext(), num_tiles,\n-                                           tiles_per_workgroup);\n-    op->setAttr(\"xtile.tiling_info\", info);\n-  });\n-\n-  module->getOperation()->setAttr(\n-      xla::CpuMemoryRegionNameAttr::name,\n-      mlir::StringAttr::get(\n-          &context, BuildModuleMemoryRegionName(\"tiled_emitter\", &fusion)));\n-\n-  WorkDimensions work_dimensions;\n-  work_dimensions.num_work_groups.x = num_work_groups;\n-  TF_ASSIGN_OR_RETURN(KernelSpec kernel_spec,\n-                      emitters::GetKernelSpec(name, fusion, buffer_assignment,\n-                                              work_dimensions));\n-  return KernelDefinition<MlirKernelSource>(\n-      std::move(kernel_spec), MlirKernelSource(std::move(module)));\n-}\n-\n-}  // namespace xla::cpu"
        },
        {
            "sha": "d2f88d17d85b744a71b5d0a0bee0fdfd17564b52",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/tiled_fusion_emitter.h",
            "status": "removed",
            "additions": 0,
            "deletions": 45,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3ed1e7a0e28efd0e77fd9fabca604a66d3bfe328/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3ed1e7a0e28efd0e77fd9fabca604a66d3bfe328/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter.h?ref=3ed1e7a0e28efd0e77fd9fabca604a66d3bfe328",
            "patch": "@@ -1,45 +0,0 @@\n-#include <cstdint>\n-\n-#include \"absl/types/span.h\"\n-#include \"mlir/IR/MLIRContext.h\"\n-#include \"xla/codegen/kernel_definition.h\"\n-#include \"xla/codegen/tiling/tiling_specification.h\"\n-#include \"xla/service/buffer_assignment.h\"\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_BACKENDS_CPU_CODEGEN_TILED_TILED_FUSION_EMITTER_H_\n-#define XLA_BACKENDS_CPU_CODEGEN_TILED_TILED_FUSION_EMITTER_H_\n-\n-#include <vector>\n-\n-#include \"absl/status/statusor.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"xla/codegen/mlir_kernel_source.h\"\n-#include \"xla/hlo/ir/hlo_instructions.h\"\n-\n-namespace xla::cpu {\n-\n-absl::StatusOr<std::vector<FlatTiling>> GetTilingIfSupported(\n-    mlir::MLIRContext& context, const HloFusionInstruction& fusion);\n-\n-absl::StatusOr<KernelDefinition<MlirKernelSource>> EmitTiledFusionKernel(\n-    mlir::MLIRContext& context, const HloFusionInstruction& fusion,\n-    const BufferAssignment* buffer_assignment, absl::string_view name,\n-    int64_t num_work_groups, absl::Span<const FlatTiling> tiling);\n-\n-}  // namespace xla::cpu\n-\n-#endif  // XLA_BACKENDS_CPU_CODEGEN_TILED_TILED_FUSION_EMITTER_H_"
        },
        {
            "sha": "37f2abadb37ce4c47304277a67b7e51d10165da3",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/tiled_fusion_emitter_stub.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 45,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3ed1e7a0e28efd0e77fd9fabca604a66d3bfe328/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter_stub.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3ed1e7a0e28efd0e77fd9fabca604a66d3bfe328/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter_stub.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_fusion_emitter_stub.cc?ref=3ed1e7a0e28efd0e77fd9fabca604a66d3bfe328",
            "patch": "@@ -1,45 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include <cstdint>\n-#include <vector>\n-\n-#include \"absl/status/status.h\"\n-#include \"absl/status/statusor.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"absl/types/span.h\"\n-#include \"mlir/IR/MLIRContext.h\"\n-#include \"xla/backends/cpu/codegen/tiled/tiled_fusion_emitter.h\"\n-#include \"xla/codegen/kernel_definition.h\"\n-#include \"xla/codegen/mlir_kernel_source.h\"\n-#include \"xla/codegen/tiling/tiling_specification.h\"\n-#include \"xla/hlo/ir/hlo_instructions.h\"\n-#include \"xla/service/buffer_assignment.h\"\n-\n-namespace xla::cpu {\n-\n-absl::StatusOr<std::vector<FlatTiling>> GetTilingIfSupported(\n-    mlir::MLIRContext& context, const HloFusionInstruction& fusion) {\n-  return absl::UnimplementedError(\"not supported for this build configuration\");\n-}\n-\n-absl::StatusOr<KernelDefinition<MlirKernelSource>> EmitTiledFusionKernel(\n-    mlir::MLIRContext& context, const HloFusionInstruction& fusion,\n-    const BufferAssignment* buffer_assignment, absl::string_view name,\n-    int64_t num_work_groups, absl::Span<const FlatTiling> tiling) {\n-  return absl::UnimplementedError(\"not supported for this build configuration\");\n-}\n-\n-}  // namespace xla::cpu"
        },
        {
            "sha": "c455737533765d79da73d3f3cab8426f1474e9ca",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tools/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2FBUILD?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -85,8 +85,8 @@ xla_cc_binary(\n     deps = [\n         \"//xla/backends/cpu/codegen:fusion_compiler\",\n         \"//xla/backends/cpu/codegen:fusion_emitter\",\n-        \"//xla/codegen:kernel_definition\",\n         \"//xla/codegen/tools:test_lib\",\n+        \"//xla/hlo/analysis:symbolic_expr\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log:check\","
        },
        {
            "sha": "08f99af10781cc5a90409d5795eedbde55b7b5fa",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tools/fusion_to_mlir.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2Ffusion_to_mlir.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2Ffusion_to_mlir.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftools%2Ffusion_to_mlir.cc?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -21,8 +21,8 @@ limitations under the License.\n #include \"llvm/Support/raw_ostream.h\"\n #include \"xla/backends/cpu/codegen/fusion_compiler.h\"\n #include \"xla/backends/cpu/codegen/fusion_emitter.h\"\n-#include \"xla/codegen/kernel_definition.h\"\n #include \"xla/codegen/tools/test_lib.h\"\n+#include \"xla/hlo/analysis/symbolic_expr.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -36,9 +36,8 @@ absl::Status Run(const std::string& filename) {\n   auto fusion = DynCast<HloFusionInstruction>(\n       module->entry_computation()->root_instruction());\n   fusion->SetAndSanitizeName(\"main\");\n-  TF_ASSIGN_OR_RETURN(\n-      KernelDefinition kernel_definition,\n-      EmitFusionKernel(*mlir_context, *fusion, nullptr, false, false));\n+  TF_ASSIGN_OR_RETURN(KernelDefinition kernel_definition,\n+                      EmitFusionKernel(*mlir_context, *fusion, nullptr, false));\n   llvm::outs() << kernel_definition.source().ToString();\n   return absl::OkStatus();\n }"
        },
        {
            "sha": "a11fd17a2c73b5f40886a560b3fc299ed66a3e94",
            "filename": "third_party/xla/xla/backends/cpu/testlib/kernel_runner_extension.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fkernel_runner_extension.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fkernel_runner_extension.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftestlib%2Fkernel_runner_extension.cc?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -200,10 +200,9 @@ NB_MODULE(_extension, kernel_runner_module) {\n   kernel_runner_module.def(\n       \"emit_fusion_kernel\",\n       [](mlir::MLIRContext& mlir_context, const HloFusionInstruction& fusion,\n-         const BufferAssignment* buffer_assignment, bool enable_tiled_emitter) {\n+         const BufferAssignment* buffer_assignment) {\n         auto kernel_definition =\n-            EmitFusionKernel(mlir_context, fusion, buffer_assignment, false,\n-                             enable_tiled_emitter);\n+            EmitFusionKernel(mlir_context, fusion, buffer_assignment, false);\n         if (!kernel_definition.ok()) {\n           throw std::runtime_error(kernel_definition.status().ToString());\n         }"
        },
        {
            "sha": "03106fd196640c47edb2dca7d6d3d5ed7746c7a1",
            "filename": "third_party/xla/xla/service/cpu/cpu_options.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.cc?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -161,10 +161,4 @@ bool UseMultiOutputFusion(const HloModuleConfig& config) {\n   return extra_options_map.count(kUseMultiOutputFusion) > 0;\n }\n \n-bool EnableTiledEmitter(const HloModuleConfig& config) {\n-  const auto& extra_options_map =\n-      config.debug_options().xla_backend_extra_options();\n-  return extra_options_map.count(kEnableTiledEmitter) > 0;\n-}\n-\n }  // namespace xla::cpu::options"
        },
        {
            "sha": "c5f4db39ae26100f294c3f15450aaace43c865c6",
            "filename": "third_party/xla/xla/service/cpu/cpu_options.h",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_options.h?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -52,8 +52,6 @@ inline constexpr absl::string_view kUseMultiOutputFusion =\n     \"xla_cpu_use_multi_output_fusion\";\n inline constexpr absl::string_view kDisablePlatformDependentMath =\n     \"xla_cpu_disable_platform_dependent_math\";\n-inline constexpr absl::string_view kEnableTiledEmitter =\n-    \"xla_cpu_enable_tiled_emitter\";\n \n bool OptimizeForSizeRequested(const HloModuleConfig& config);\n bool VectorizedReduceDisabled(const HloModuleConfig& config);\n@@ -70,7 +68,6 @@ absl::StatusOr<int64_t> SmallWhileLoopByteThreshold(\n bool UseExperimentalLoopFusion(const HloModuleConfig& config);\n bool FlattenAfterFusion(const HloModuleConfig& config);\n bool UseMultiOutputFusion(const HloModuleConfig& config);\n-bool EnableTiledEmitter(const HloModuleConfig& config);\n \n }  // namespace xla::cpu::options\n "
        },
        {
            "sha": "0c857ea6c08a5d91dceea0b5f919c36481eb5c4d",
            "filename": "third_party/xla/xla/service/cpu/parallel_fusion_emitter.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.cc?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -143,14 +143,12 @@ ParallelFusionEmitter::FusionCompilerPool::GetNestedHooks() const {\n ParallelFusionEmitter::ParallelFusionEmitter(\n     tsl::thread::ThreadPool& thread_pool, FusionCompiler::Options options,\n     FusionCompiler::CompilationHooks hooks,\n-    const BufferAssignment* buffer_assignment, bool use_unique_c_name,\n-    bool enable_tiled_emitter)\n+    const BufferAssignment* buffer_assignment, bool use_unique_c_name)\n     : thread_pool_(thread_pool),\n       fusion_compiler_pool_(\n           std::make_unique<FusionCompilerPool>(options, std::move(hooks))),\n       buffer_assignment_(buffer_assignment),\n-      use_unique_c_name_(use_unique_c_name),\n-      enable_tiled_emitter_(enable_tiled_emitter) {}\n+      use_unique_c_name_(use_unique_c_name) {}\n \n ParallelFusionEmitter::~ParallelFusionEmitter() {\n   absl::MutexLock lock(kernels_mutex_);\n@@ -169,8 +167,7 @@ absl::StatusOr<KernelSpec> ParallelFusionEmitter::AddFusion(\n   TF_ASSIGN_OR_RETURN(\n       KernelDefinition mlir_kernel_definition,\n       EmitFusionKernel(*compiler_instance->mlir_context, *fusion,\n-                       buffer_assignment_, use_unique_c_name_,\n-                       enable_tiled_emitter_));\n+                       buffer_assignment_, use_unique_c_name_));\n \n   {\n     absl::MutexLock lock(kernels_mutex_);"
        },
        {
            "sha": "033f196dac2bdc9162a51074e5145f9ce59b5a0f",
            "filename": "third_party/xla/xla/service/cpu/parallel_fusion_emitter.h",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter.h?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -44,7 +44,7 @@ class ParallelFusionEmitter {\n                         FusionCompiler::Options options,\n                         FusionCompiler::CompilationHooks hooks,\n                         const BufferAssignment* buffer_assignment,\n-                        bool use_unique_c_name, bool enable_tiled_emitter);\n+                        bool use_unique_c_name);\n \n   ~ParallelFusionEmitter();\n \n@@ -69,7 +69,6 @@ class ParallelFusionEmitter {\n   std::unique_ptr<FusionCompilerPool> fusion_compiler_pool_;\n   const BufferAssignment* buffer_assignment_;\n   bool use_unique_c_name_;\n-  bool enable_tiled_emitter_;\n \n   absl::Mutex kernels_mutex_;\n   int64_t outstanding_kernels_ ABSL_GUARDED_BY(kernels_mutex_) = 0;"
        },
        {
            "sha": "28e03fde26bd5fabd36d68aec39a5f69bd24803a",
            "filename": "third_party/xla/xla/service/cpu/parallel_fusion_emitter_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter_test.cc?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -116,8 +116,7 @@ TEST_F(ParallelFusionEmitterTest, HappyPathSingleFusion) {\n   tsl::thread::ThreadPool thread_pool(tsl::Env::Default(), \"test_pool\", 4);\n \n   xla::cpu::ParallelFusionEmitter fussion_emitter(\n-      thread_pool, CreateDefaultOptions(), CreateMockHooks(1), nullptr, false,\n-      false);\n+      thread_pool, CreateDefaultOptions(), CreateMockHooks(1), nullptr, false);\n \n   TF_ASSERT_OK_AND_ASSIGN(auto kernel_spec, fussion_emitter.AddFusion(fusion));\n   EXPECT_EQ(kernel_spec.name(), expected_name);\n@@ -171,8 +170,7 @@ TEST_F(ParallelFusionEmitterTest, FusionsAreSorted) {\n \n   xla::cpu::ParallelFusionEmitter fussion_emitter(\n       thread_pool, CreateDefaultOptions(), CreateMockHooks(2),\n-      /*buffer_assignment=*/nullptr, /*use_unique_c_name=*/false,\n-      /*enable_tiled_emitter=*/false);\n+      /*buffer_assignment=*/nullptr, /*use_unique_c_name=*/false);\n \n   // Add the fusions in reverse order.\n   TF_ASSERT_OK_AND_ASSIGN(auto kernel_spec_1,\n@@ -216,8 +214,7 @@ TEST_F(ParallelFusionEmitterTest, Error) {\n \n   tsl::thread::ThreadPool thread_pool(tsl::Env::Default(), \"test_pool\", 4);\n   xla::cpu::ParallelFusionEmitter fussion_emitter(\n-      thread_pool, CreateDefaultOptions(), CreateMockHooks(0), nullptr, false,\n-      false);\n+      thread_pool, CreateDefaultOptions(), CreateMockHooks(0), nullptr, false);\n \n   EXPECT_THAT(fussion_emitter.AddFusion(fusion), Not(IsOk()));\n }"
        },
        {
            "sha": "9662c8ccd52e955650c7e114e95e21a178e9a67a",
            "filename": "third_party/xla/xla/service/cpu/thunk_emitter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a4bd4419a678c078f1faad6543c3a774848f8b3/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc?ref=3a4bd4419a678c078f1faad6543c3a774848f8b3",
            "patch": "@@ -214,8 +214,7 @@ ThunkEmitter::ThunkEmitter(IrEmitter2& ir_emitter,\n           thread_pool, FusionCompilerOptions(hlo_module_config_),\n           FusionCompilerHooks(hlo_module), &buffer_assignment,\n           hlo_module_config_.debug_options()\n-              .xla_cpu_generate_unique_c_style_kernel_entry_points(),\n-          options::EnableTiledEmitter(hlo_module_config_)) {}\n+              .xla_cpu_generate_unique_c_style_kernel_entry_points()) {}\n \n static Thunk::Info ThunkInfo(const HloInstruction* instruction) {\n   const HloModule* module = instruction->GetModule();"
        }
    ],
    "stats": {
        "total": 455,
        "additions": 17,
        "deletions": 438
    }
}