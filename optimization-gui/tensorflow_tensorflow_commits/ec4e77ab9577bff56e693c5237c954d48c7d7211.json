{
    "author": "ermilovmaxim",
    "message": "Update :xla_aot_compile_gpu_test to use a newer GPU\n\nPiperOrigin-RevId: 810575107",
    "sha": "ec4e77ab9577bff56e693c5237c954d48c7d7211",
    "files": [
        {
            "sha": "7a9535be13607890e54153815b1a9b9e53600927",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 7,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ec4e77ab9577bff56e693c5237c954d48c7d7211/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ec4e77ab9577bff56e693c5237c954d48c7d7211/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=ec4e77ab9577bff56e693c5237c954d48c7d7211",
            "patch": "@@ -5818,34 +5818,34 @@ xla_aot_compile_cpu(\n xla_aot_compile_gpu(\n     name = \"xla_aot_compile_test_gpu_executable\",\n     autotune_results = \"xla_aot_compile_test_autotune_results.txtpb\",\n-    gpu_target_config = \"xla_aot_compile_test_gpu_target_config.txtpb\",\n+    gpu_target_config = \"//xla/tools/hlo_opt:gpu_specs/h100_sxm.txtpb\",\n     module = \"xla_aot_compile_test.mlir\",\n )\n \n xla_aot_compile_gpu(\n     name = \"xla_aot_compile_test_gpu_executable_hlo\",\n     autotune_results = \"xla_aot_compile_test_autotune_results.txtpb\",\n-    gpu_target_config = \"xla_aot_compile_test_gpu_target_config.txtpb\",\n+    gpu_target_config = \"//xla/tools/hlo_opt:gpu_specs/h100_sxm.txtpb\",\n     module = \"xla_aot_compile_test.hlo\",\n )\n \n xla_aot_compile_gpu(\n     name = \"xla_aot_compile_test_gpu_executable_constant\",\n     autotune_results = \"xla_aot_compile_test_autotune_results.txtpb\",\n-    gpu_target_config = \"xla_aot_compile_test_gpu_target_config.txtpb\",\n+    gpu_target_config = \"//xla/tools/hlo_opt:gpu_specs/h100_sxm.txtpb\",\n     module = \"xla_aot_compile_test_constant.mlir\",\n )\n \n xla_aot_compile_gpu(\n     name = \"xla_aot_compile_test_gpu_executable_convolution\",\n     autotune_results = \"xla_aot_compile_test_autotune_results.txtpb\",\n-    gpu_target_config = \"xla_aot_compile_test_gpu_target_config.txtpb\",\n+    gpu_target_config = \"//xla/tools/hlo_opt:gpu_specs/h100_sxm.txtpb\",\n     module = \"xla_aot_compile_test_convolution.mlir\",\n )\n \n xla_aot_compile_gpu_runtime_autotuning(\n     name = \"xla_aot_compile_test_gpu_executable_convolution_runtime_autotuning\",\n-    gpu_target_config = \"xla_aot_compile_test_gpu_target_config.txtpb\",\n+    gpu_target_config = \"//xla/tools/hlo_opt:gpu_specs/h100_sxm.txtpb\",\n     module = \"xla_aot_compile_test_convolution.mlir\",\n )\n \n@@ -5919,8 +5919,7 @@ xla_cc_test(\n         \"cuda-only\",\n         \"gpu\",\n         \"no_oss\",\n-        \"nomsan\",  # Pulls in precompiled NVIDIA libraries which cause false positives in msan.\n-        \"requires-gpu-sm60-only\",\n+        \"requires-gpu-sm90-only\",\n     ],\n     deps = [\n         \":gpu_plugin_impl\","
        },
        {
            "sha": "ecccb69ad7665e20186d3e867e1c2c209145e1b9",
            "filename": "third_party/xla/xla/service/xla_aot_compile_test_autotune_results.txtpb",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ec4e77ab9577bff56e693c5237c954d48c7d7211/third_party%2Fxla%2Fxla%2Fservice%2Fxla_aot_compile_test_autotune_results.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ec4e77ab9577bff56e693c5237c954d48c7d7211/third_party%2Fxla%2Fxla%2Fservice%2Fxla_aot_compile_test_autotune_results.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fxla_aot_compile_test_autotune_results.txtpb?ref=ec4e77ab9577bff56e693c5237c954d48c7d7211",
            "patch": "@@ -17,7 +17,7 @@\n \n version: 3\n results {\n-  device: \"CUDA: 6.0, Cores: 56, GPU clock: 1.4805 GHz, Memory bandwidth: 732 GB/s, L2 cache: 4 MB, DNN version: 0.0.0\"\n+  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB, DNN version: 0.0.0\"\n   hlo: \"(f32[3,3]{1,0}, s8[72]{0}) custom-call(f32[3,3]{1,0}, f32[3,3]{1,0}), custom_call_target=\\\"__cublas$gemm\\\", backend_config={\\\"force_earliest_schedule\\\":false,\\\"gemm_backend_config\\\":{\\\"alpha_imag\\\":0,\\\"alpha_real\\\":1,\\\"beta\\\":0,\\\"dot_dimension_numbers\\\":{\\\"lhs_batch_dimensions\\\":[],\\\"lhs_contracting_dimensions\\\":[\\\"1\\\"],\\\"rhs_batch_dimensions\\\":[],\\\"rhs_contracting_dimensions\\\":[\\\"0\\\"]},\\\"epilogue\\\":\\\"DEFAULT\\\",\\\"grad_x\\\":false,\\\"grad_y\\\":false,\\\"lhs_stride\\\":\\\"9\\\",\\\"precision_config\\\":{\\\"algorithm\\\":\\\"ALG_UNSET\\\",\\\"operand_precision\\\":[\\\"DEFAULT\\\",\\\"DEFAULT\\\"]},\\\"rhs_stride\\\":\\\"9\\\"},\\\"operation_queue_id\\\":\\\"0\\\",\\\"wait_on_operation_queues\\\":[]}\"\n   result {\n     gemm {\n@@ -26,8 +26,8 @@ results {\n   }\n }\n results {\n-  device: \"CUDA: 6.0, Cores: 56, GPU clock: 1.4805 GHz, Memory bandwidth: 732 GB/s, L2 cache: 4 MB, DNN version: 0.0.0\"\n-  hlo: \"(f32[1,1,2,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,2,4,4]{3,2,1,0}, f32[1,2,3,2]{3,2,1,0}), window={size=3x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\\\"__cudnn$convForward\\\", backend_config={\\\"cudnn_conv_backend_config\\\":{\\\"activation_mode\\\":\\\"kNone\\\",\\\"conv_result_scale\\\":1,\\\"leakyrelu_alpha\\\":0,\\\"side_input_scale\\\":0},\\\"device_type\\\":\\\"DEVICE_TYPE_INVALID\\\",\\\"force_earliest_schedule\\\":false,\\\"operation_queue_id\\\":\\\"0\\\",\\\"reification_cost\\\":[],\\\"wait_on_operation_queues\\\":[]}\"\n+  device: \"CUDA: 9.0, Cores: 132, GPU clock: 1.98 GHz, Memory bandwidth: 3352 GB/s, L2 cache: 50 MB, DNN version: 0.0.0\"\n+  hlo: \"(f32[1,2,3,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,4,4,2]{3,2,1,0}, f32[1,3,2,2]{3,2,1,0}), window={size=3x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\\\"__cudnn$convForward\\\", backend_config={\\\"cudnn_conv_backend_config\\\":{\\\"activation_mode\\\":\\\"kNone\\\",\\\"conv_result_scale\\\":1,\\\"leakyrelu_alpha\\\":0,\\\"side_input_scale\\\":0},\\\"device_type\\\":\\\"DEVICE_TYPE_INVALID\\\",\\\"force_earliest_schedule\\\":false,\\\"operation_queue_id\\\":\\\"0\\\",\\\"reification_cost\\\":[],\\\"wait_on_operation_queues\\\":[]}\"\n   result {\n     run_time {\n       nanos: 8192"
        },
        {
            "sha": "fa8a9df0a24ed72f258ecef3a4d7a9fffe9b04b9",
            "filename": "third_party/xla/xla/service/xla_aot_compile_test_gpu_target_config.txtpb",
            "status": "removed",
            "additions": 0,
            "deletions": 43,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e7096820e4314cefe579090b468a377a19b54ffe/third_party%2Fxla%2Fxla%2Fservice%2Fxla_aot_compile_test_gpu_target_config.txtpb",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e7096820e4314cefe579090b468a377a19b54ffe/third_party%2Fxla%2Fxla%2Fservice%2Fxla_aot_compile_test_gpu_target_config.txtpb",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fxla_aot_compile_test_gpu_target_config.txtpb?ref=e7096820e4314cefe579090b468a377a19b54ffe",
            "patch": "@@ -1,43 +0,0 @@\n-# Copyright 2022 The OpenXLA Authors.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#    http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-\n-# proto-file: third_party/tensorflow/compiler/xla/stream_executor/device_description.proto\n-# proto-message: stream_executor.GpuTargetConfigProto\n-\n-gpu_device_info {\n-  cuda_compute_capability {\n-    major: 6\n-  }\n-  threads_per_block_limit: 1024\n-  threads_per_warp: 32\n-  shared_memory_per_block: 49152\n-  shared_memory_per_core: 65536\n-  threads_per_core_limit: 2048\n-  core_count: 56\n-  fpus_per_core: 64\n-  block_dim_limit_x: 2147483647\n-  block_dim_limit_y: 65535\n-  block_dim_limit_z: 65535\n-  memory_bandwidth: 732160000000\n-  l2_cache_size: 4194304\n-  clock_rate_ghz: 1.4805\n-  device_memory_size: 17071734784\n-}\n-platform_name: \"CUDA\"\n-dnn_version_info {\n-  major: 8\n-  minor: 3\n-  patch: 2\n-}\n-device_description_str: \"sm_6.0 with 17071734784B RAM, 56 cores, 1480500KHz clock, 715000KHz mem clock, 4194304B L2$\""
        },
        {
            "sha": "297d068766ea41bc2b47005adf54c4daa26c37e7",
            "filename": "third_party/xla/xla/tools/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ec4e77ab9577bff56e693c5237c954d48c7d7211/third_party%2Fxla%2Fxla%2Ftools%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ec4e77ab9577bff56e693c5237c954d48c7d7211/third_party%2Fxla%2Fxla%2Ftools%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2FBUILD?ref=ec4e77ab9577bff56e693c5237c954d48c7d7211",
            "patch": "@@ -1076,8 +1076,8 @@ xla_test(\n     ],\n     data = [\n         \":data/add.hlo\",\n-        \"//xla/service:xla_aot_compile_test_gpu_target_config.txtpb\",\n         \"//xla/service/gpu:gpu_compiler_test_autotune_db.textproto\",\n+        \"//xla/tools/hlo_opt:gpu_specs/h100_sxm.txtpb\",\n     ],\n     deps = [\n         \":xla_compile_lib\","
        },
        {
            "sha": "51f07ca4d145b310a2a07340e0ff17055902362e",
            "filename": "third_party/xla/xla/tools/xla_gpu_compile_lib_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ec4e77ab9577bff56e693c5237c954d48c7d7211/third_party%2Fxla%2Fxla%2Ftools%2Fxla_gpu_compile_lib_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ec4e77ab9577bff56e693c5237c954d48c7d7211/third_party%2Fxla%2Fxla%2Ftools%2Fxla_gpu_compile_lib_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fxla_gpu_compile_lib_test.cc?ref=ec4e77ab9577bff56e693c5237c954d48c7d7211",
            "patch": "@@ -72,9 +72,8 @@ TEST_F(XlaCompileLibTest, CompilesForGpuWithDevice) {\n }\n \n TEST_F(XlaCompileLibTest, CompilesForGpuWithoutDevice) {\n-  const std::string target_config_path =\n-      tsl::io::JoinPath(tsl::testing::XlaSrcRoot(), \"service\",\n-                        \"xla_aot_compile_test_gpu_target_config.txtpb\");\n+  const std::string target_config_path = tsl::io::JoinPath(\n+      tsl::testing::XlaSrcRoot(), \"tools/hlo_opt/gpu_specs\", \"h100_sxm.txtpb\");\n   stream_executor::GpuTargetConfigProto target_config;\n   TF_ASSERT_OK(tsl::ReadTextProto(tsl::Env::Default(), target_config_path,\n                                   &target_config));"
        }
    ],
    "stats": {
        "total": 69,
        "additions": 12,
        "deletions": 57
    }
}