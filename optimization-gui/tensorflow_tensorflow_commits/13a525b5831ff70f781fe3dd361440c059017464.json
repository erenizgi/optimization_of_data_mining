{
    "author": "ezhulenev",
    "message": "[xla:pjrt] Migrate to se::DeviceMemoryAddress\n\nPiperOrigin-RevId: 842253793",
    "sha": "13a525b5831ff70f781fe3dd361440c059017464",
    "files": [
        {
            "sha": "954225f6a10310f51bdd0edeb506262c22b68dac",
            "filename": "third_party/xla/xla/pjrt/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -194,7 +194,7 @@ xla_cc_test(\n         \"//xla/client:local_client\",\n         \"//xla/hlo/testlib:test\",\n         \"//xla/service:cpu_plugin\",\n-        \"//xla/stream_executor:device_memory_allocator\",\n+        \"//xla/stream_executor:device_address_allocator\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/concurrency:ref_count\",\n         \"//xla/tsl/platform:statusor\",\n@@ -225,7 +225,7 @@ cc_library(\n         \":worker_thread\",\n         \"//xla:util\",\n         \"//xla/client:local_client\",\n-        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:device_address\",\n         \"//xla/stream_executor:event\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n@@ -717,8 +717,8 @@ cc_library(\n         \"//xla/service:shaped_buffer\",\n         \"//xla/service:transfer_manager\",\n         \"//xla/service/gpu:gpu_executable_run_options\",\n-        \"//xla/stream_executor:device_memory\",\n-        \"//xla/stream_executor:device_memory_allocator\",\n+        \"//xla/stream_executor:device_address\",\n+        \"//xla/stream_executor:device_address_allocator\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/concurrency:ref_count\","
        },
        {
            "sha": "0756d7beac73bba4e7a574acf469a76c5218e9db",
            "filename": "third_party/xla/xla/pjrt/cpu/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -73,7 +73,7 @@ cc_library(\n         \"//xla/service:shaped_buffer\",\n         \"//xla/service/cpu:cpu_executable\",\n         \"//xla/service/cpu:cpu_xfeed\",\n-        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:device_address\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/concurrency:ref_count\",\n         \"//xla/tsl/platform:env\",\n@@ -208,7 +208,7 @@ cc_library(\n         \"//xla/service/cpu:cpu_executable_run_options\",\n         \"//xla/service/cpu:executable_proto_cc\",\n         \"//xla/service/llvm_ir:llvm_command_line_options\",\n-        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:device_address\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/concurrency:ref_count\",\n         \"//xla/tsl/platform:env\","
        },
        {
            "sha": "f330c75ca62e13840e1a813b80e24a4de7360e1e",
            "filename": "third_party/xla/xla/pjrt/cpu/abstract_cpu_buffer.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fabstract_cpu_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fabstract_cpu_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fabstract_cpu_buffer.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -53,7 +53,7 @@ limitations under the License.\n #include \"xla/shape.h\"\n #include \"xla/shape_tree.h\"\n #include \"xla/shape_util.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_address.h\"\n #include \"xla/tsl/concurrency/async_value.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\""
        },
        {
            "sha": "55690711a5fc405236207de1132355fb0e30b2a3",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -117,7 +117,7 @@ limitations under the License.\n #include \"xla/service/maybe_owning_device_address.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_address.h\"\n #include \"xla/tsl/concurrency/async_value.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n@@ -1275,7 +1275,7 @@ static absl::StatusOr<BufferInfo> MemoryForAllocation(\n \n   } else if (allocation.is_constant() &&\n              allocation.index() < constants.size()) {\n-    se::DeviceMemoryBase constant =\n+    se::DeviceAddressBase constant =\n         constants[allocation.index()].AsDeviceMemoryBase();\n     buffer_info.buffer = CpuDeviceMemory::CreateConstantMemory(\n         constant.opaque(), constant.size());\n@@ -1624,8 +1624,8 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n       buffer_device_mem.reserve(buffer_table.size());\n       for (const auto& buffer_info : buffer_table) {\n         buffer_device_mem.emplace_back(\n-            se::DeviceMemoryBase(buffer_info.buffer->untyped_data(),\n-                                 buffer_info.buffer->size_bytes()));\n+            se::DeviceAddressBase(buffer_info.buffer->untyped_data(),\n+                                  buffer_info.buffer->size_bytes()));\n       }\n \n       cpu::BufferAllocations allocations(buffer_device_mem);\n@@ -1768,8 +1768,8 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n             buffer_device_mem.reserve(buffer_table.size());\n             for (const auto& buffer_info : buffer_table) {\n               buffer_device_mem.emplace_back(\n-                  se::DeviceMemoryBase(buffer_info.buffer->untyped_data(),\n-                                       buffer_info.buffer->size_bytes()));\n+                  se::DeviceAddressBase(buffer_info.buffer->untyped_data(),\n+                                        buffer_info.buffer->size_bytes()));\n             }\n \n             cpu::BufferAllocations allocations(buffer_device_mem);"
        },
        {
            "sha": "1b082cc7a37f5fddcc861948c361c4c288c469e8",
            "filename": "third_party/xla/xla/pjrt/gpu/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -116,9 +116,9 @@ cc_library(\n         \"//xla/service:transfer_manager\",\n         \"//xla/service/gpu:gpu_executable_run_options\",\n         \"//xla/service/gpu:gpu_memory_space_assignment\",\n+        \"//xla/stream_executor:device_address\",\n+        \"//xla/stream_executor:device_address_allocator\",\n         \"//xla/stream_executor:device_description\",\n-        \"//xla/stream_executor:device_memory\",\n-        \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n@@ -246,7 +246,7 @@ xla_test(\n         \"//xla/pjrt/proto:compile_options_proto_cc\",\n         \"//xla/service:platform_util\",\n         \"//xla/service/gpu:gpu_memory_space_assignment\",\n-        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:device_address\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/tests:literal_test_util\","
        },
        {
            "sha": "e210a480bc74ddf71c0b6e4654804e9707e5ad0a",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 12,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -102,9 +102,9 @@ limitations under the License.\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/device_description.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -206,7 +206,7 @@ static absl::flat_hash_map<std::string, PjRtDeviceAttribute> GetAttrsForDevices(\n StreamExecutorGpuClient::StreamExecutorGpuClient(\n     std::string platform_name, LocalClient* client,\n     std::vector<std::unique_ptr<PjRtStreamExecutorDevice>> devices,\n-    int process_index, std::unique_ptr<se::DeviceMemoryAllocator> allocator,\n+    int process_index, std::unique_ptr<se::DeviceAddressAllocator> allocator,\n     std::unique_ptr<tsl::Allocator> host_memory_allocator,\n     bool should_stage_host_to_device_transfers,\n     std::unique_ptr<gpu::GpuExecutableRunOptions> gpu_run_options,\n@@ -1414,7 +1414,7 @@ BuildLocalDeviceStates(LocalClient* xla_client) {\n \n // Constructs a GPU device memory allocator to use, according to the allocator\n // configuration the client requested.\n-absl::StatusOr<std::unique_ptr<se::DeviceMemoryAllocator>>\n+absl::StatusOr<std::unique_ptr<se::DeviceAddressAllocator>>\n GetStreamExecutorGpuDeviceAllocator(\n     se::Platform* platform, const GpuAllocatorConfig& allocator_config,\n     const std::map<int, std::unique_ptr<LocalDeviceState>>&\n@@ -1849,7 +1849,7 @@ std::vector<std::unique_ptr<PjRtStreamExecutorDevice>> BuildLocalDevices(\n \n #if defined(GOOGLE_CUDA) || defined(TENSORFLOW_USE_ROCM)\n static absl::Status CheckAlignment(const BufferAllocation& allocation,\n-                                   se::DeviceMemoryBase buffer, int arg_idx) {\n+                                   se::DeviceAddressBase buffer, int arg_idx) {\n   const int64_t expected_alignment = [&] {\n     if (allocation.is_entry_computation_parameter()) {\n       return gpu::kEntryParameterAlignBytes;\n@@ -1887,7 +1887,7 @@ StreamExecutorGpuClient::RunAsync(\n   auto* gpu_exec =\n       tensorflow::down_cast<xla::gpu::GpuExecutable*>(exec.executable());\n   const ServiceExecutableRunOptions* run_options = &options_and_stream.first;\n-  se::DeviceMemoryAllocator* const memory_allocator = run_options->allocator();\n+  se::DeviceAddressAllocator* const memory_allocator = run_options->allocator();\n \n   se::StreamExecutor* executor = run_options->stream()->parent();\n \n@@ -1932,17 +1932,17 @@ StreamExecutorGpuClient::RunAsync(\n   absl::Span<const BufferAllocation* const> allocations =\n       gpu_exec->GetAllocations();\n \n-  std::vector<se::DeviceMemoryBase> buffers(allocations.size());\n+  std::vector<se::DeviceAddressBase> buffers(allocations.size());\n   {\n     tsl::profiler::TraceMe hlo_module_activity(\n         [&] { return std::string(\"Build buffer allocations\"); },\n         tsl::profiler::TraceMeLevel::kInfo);\n     const int64_t num_buffers = allocations.size();\n     for (int64_t i = 0; i < num_buffers; ++i) {\n       const BufferAllocation& allocation = *allocations[i];\n-      se::DeviceMemoryBase& buffer = buffers[i];\n+      se::DeviceAddressBase& buffer = buffers[i];\n       if (allocation.is_thread_local()) {\n-        // buffer = se::DeviceMemoryBase{};\n+        // buffer = se::DeviceAddressBase{};\n       } else if (allocation.is_entry_computation_parameter()) {\n         int64_t param_no = allocation.parameter_number();\n         buffer = [&] {\n@@ -1985,7 +1985,7 @@ StreamExecutorGpuClient::RunAsync(\n   XLA_VLOG_DEVICE(3, device_ordinal)\n       << \"Buffer allocations: \" << buffer_allocations.ToString();\n \n-  std::set<se::DeviceMemoryBase> buffers_in_result;\n+  std::set<se::DeviceAddressBase> buffers_in_result;\n \n   xla::ShapeTree<tsl::AsyncValueRef<RawSEDeviceMemory>> results(\n       gpu_exec->result_shape());\n@@ -1999,7 +1999,7 @@ StreamExecutorGpuClient::RunAsync(\n         gpu_exec->output_info().at(index);\n     const BufferAllocation* allocation =\n         allocations[output_info.allocation_index];\n-    se::DeviceMemoryBase result_buffer;\n+    se::DeviceAddressBase result_buffer;\n \n     XLA_VLOG_DEVICE(4, device_ordinal)\n         << \"Looking at: allocation \" << output_info.allocation_index\n@@ -2043,7 +2043,7 @@ StreamExecutorGpuClient::RunAsync(\n           return gpu_exec->VerboseAllocationError(allocated_buffer.status());\n         }\n         result_buffer = allocated_buffer->Release();\n-        se::DeviceMemoryBase& aliased_buffer =\n+        se::DeviceAddressBase& aliased_buffer =\n             buffer_allocations.GetMutableDeviceAddress(\n                 output_info.allocation_index);\n         CHECK_EQ(aliased_buffer.size(), result_buffer.size());"
        },
        {
            "sha": "c56d5757a3c929cc9fb251f28035fe7382343cb8",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -58,8 +58,8 @@ limitations under the License.\n #include \"xla/service/gpu/gpu_executable_run_options.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_tree.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/device_description.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/framework/allocator.h\"\n #include \"xla/tsl/protobuf/coordination_service.pb.h\"\n@@ -109,7 +109,7 @@ class StreamExecutorGpuClient : public xla::PjRtStreamExecutorClient {\n   StreamExecutorGpuClient(\n       std::string platform_name, LocalClient* client,\n       std::vector<std::unique_ptr<PjRtStreamExecutorDevice>> devices,\n-      int process_index, std::unique_ptr<se::DeviceMemoryAllocator> allocator,\n+      int process_index, std::unique_ptr<se::DeviceAddressAllocator> allocator,\n       std::unique_ptr<tsl::Allocator> host_memory_allocator,\n       bool should_stage_host_to_device_transfers,\n       std::unique_ptr<gpu::GpuExecutableRunOptions> gpu_run_options,"
        },
        {
            "sha": "787f43b0691a211ea56ab35156f87215de0aec5d",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -92,7 +92,7 @@ limitations under the License.\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tests/literal_test_util.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n@@ -510,7 +510,7 @@ static absl::Status MemsetFromValue(\n   uint32_t pattern;\n   std::memcpy(&pattern, &memset_value->value, sizeof(pattern));\n \n-  se::DeviceMemoryBase base = result->device_memory();\n+  se::DeviceAddressBase base = result->device_memory();\n   return stream->Memset32(&base, pattern, base.size());\n }\n \n@@ -559,7 +559,7 @@ static absl::Status MemsetFromAttr(\n   uint32_t pattern;\n   std::memcpy(&pattern, &attr, sizeof(pattern));\n \n-  se::DeviceMemoryBase base = result->device_memory();\n+  se::DeviceAddressBase base = result->device_memory();\n   return stream->Memset32(&base, pattern, base.size());\n }\n "
        },
        {
            "sha": "7cb5b0892be3777cafd8ef17137b9f5cc6e9294f",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2FBUILD?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -104,10 +104,10 @@ cc_library(\n         \"//xla/service:shaped_buffer\",\n         \"//xla/service:transfer_manager\",\n         \"//xla/service/gpu:gpu_executable_run_options\",\n+        \"//xla/stream_executor:device_address\",\n+        \"//xla/stream_executor:device_address_allocator\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:device_description_proto_cc\",\n-        \"//xla/stream_executor:device_memory\",\n-        \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n@@ -217,8 +217,8 @@ xla_test(\n         \"//xla/pjrt/plugin/xla_gpu:xla_gpu_client_options\",\n         \"//xla/pjrt/proto:compile_options_proto_cc\",\n         \"//xla/service:platform_util\",\n+        \"//xla/stream_executor:device_address\",\n         \"//xla/stream_executor:device_description\",\n-        \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n@@ -272,8 +272,8 @@ cc_library(\n         \"//xla:util\",\n         \"//xla/pjrt:pjrt_client\",\n         \"//xla/service:shaped_buffer\",\n-        \"//xla/stream_executor:device_memory\",\n-        \"//xla/stream_executor:device_memory_allocator\",\n+        \"//xla/stream_executor:device_address\",\n+        \"//xla/stream_executor:device_address_allocator\",\n         \"//xla/stream_executor:event\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/tsl/concurrency:async_value\",\n@@ -317,8 +317,8 @@ xla_cc_test(\n         \"//xla/pjrt:pjrt_common\",\n         \"//xla/service:gpu_plugin\",\n         \"//xla/service:shaped_buffer\",\n+        \"//xla/stream_executor:device_address\",\n         \"//xla/stream_executor:device_address_allocator\",\n-        \"//xla/stream_executor:device_memory\",\n         \"//xla/tsl/concurrency:async_value\",\n         # copybara:uncomment \"//xla/tsl/framework:allocator\",\n         \"//xla/tsl/platform:env\","
        },
        {
            "sha": "44031d7249faa5b3f7ecce677041a359cbccc380",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_async_host_to_device_transfer_manager.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_async_host_to_device_transfer_manager.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_async_host_to_device_transfer_manager.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_async_host_to_device_transfer_manager.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -54,9 +54,9 @@ limitations under the License.\n #include \"xla/service/transfer_manager.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/platform/logging.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -275,7 +275,7 @@ TfrtGpuAsyncHostToDeviceTransferManager::TransferRawDataToSubBuffer(\n     staging_buffer = host_memory_allocator->Allocate(transfer_size);\n   }\n \n-  se::DeviceMemoryBase sub_buffer;\n+  se::DeviceAddressBase sub_buffer;\n   {\n     absl::MutexLock l(mu_);\n     DCHECK_LT(buffer_index, buffer_ptrs_.size());"
        },
        {
            "sha": "6c043547ed5e60f2fcd4d53da56943a52c5fdfb8",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_buffer.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_buffer.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -57,9 +57,9 @@ limitations under the License.\n #include \"xla/service/transfer_manager.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/tsl/concurrency/async_value.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/framework/allocator.h\"\n@@ -583,7 +583,7 @@ Future<> TfrtGpuBuffer::CopyRawToHostFuture(Future<void*> dst_future,\n       promise.Set(device_buffer->definition_event().GetError());\n       return;\n     }\n-    se::DeviceMemoryBase device_memory = device_buffer->buffer()->buffer();\n+    se::DeviceAddressBase device_memory = device_buffer->buffer()->buffer();\n     if (offset < 0 || offset > device_memory.size() ||\n         device_memory.size() - offset < transfer_size) {\n       LOG(ERROR) << \"Copy raw buffer called on buffer size \"\n@@ -596,7 +596,7 @@ Future<> TfrtGpuBuffer::CopyRawToHostFuture(Future<void*> dst_future,\n       return;\n     }\n \n-    se::DeviceMemoryBase sub_buffer;\n+    se::DeviceAddressBase sub_buffer;\n     if (transfer_size < device_memory.size()) {\n       sub_buffer = device_memory.GetByteSlice(offset, transfer_size);\n     } else {\n@@ -824,7 +824,7 @@ absl::StatusOr<std::unique_ptr<PjRtBuffer>> TfrtGpuBuffer::CopyToMemorySpace(\n \n         auto stream = dst_device->stream();\n \n-        se::DeviceMemoryBase dst(allocated_dst_buffer->buffer());\n+        se::DeviceAddressBase dst(allocated_dst_buffer->buffer());\n         VLOG(3) << \"D2D copy: \" << src_buffer->buffer().opaque() << \" -> \"\n                 << dst.opaque() << \" (\" << src_buffer->buffer().size()\n                 << \" bytes)\";"
        },
        {
            "sha": "f63c05f5aa8b7718445f9e2c789309cd0e9ff414",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_client.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -94,9 +94,9 @@ limitations under the License.\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n@@ -148,7 +148,7 @@ TfrtGpuClient::TfrtGpuClient(\n     std::vector<std::unique_ptr<TfrtGpuDevice>> devices,\n     bool should_stage_host_to_device_transfers,\n     bool abort_collectives_on_failure,\n-    MaybeOwning<se::DeviceMemoryAllocator> allocator,\n+    MaybeOwning<se::DeviceAddressAllocator> allocator,\n     std::unique_ptr<tsl::Allocator> host_memory_allocator,\n     std::unique_ptr<gpu::GpuExecutableRunOptions> gpu_run_options,\n     std::shared_ptr<KeyValueStoreInterface> kv_store,\n@@ -437,7 +437,7 @@ TfrtGpuClient::CreateViewOfDeviceBuffer(\n   CHECK_EQ(memory_space->devices().size(), 1);\n   auto* device = memory_space->devices().front();\n   size_t byte_size = ShapeUtil::ByteSizeOf(shape);\n-  se::DeviceMemoryBase device_memory(device_ptr, byte_size);\n+  se::DeviceAddressBase device_memory(device_ptr, byte_size);\n   auto non_owning_buffer = GpuDeviceMemory(device_memory);\n   auto buffer_async_value_ref =\n       tsl::MakeAvailableAsyncValueRef<GpuDeviceMemory>(\n@@ -972,7 +972,7 @@ absl::StatusOr<std::unique_ptr<PjRtBuffer>> TfrtGpuClient::BufferFromHostBuffer(\n     });\n     auto stream = device->stream();\n \n-    se::DeviceMemoryBase dest = gpu_buffer->buffer();\n+    se::DeviceAddressBase dest = gpu_buffer->buffer();\n     VLOG(3) << \"H2D copy: \" << src_buf << \" -> \" << dest.opaque() << \" (\"\n             << packed_size << \" bytes) on device \" << device->DebugString();\n "
        },
        {
            "sha": "88bed1881f355f0c5b630bdd5199e531a4cf22c7",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_client.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client.h?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -63,7 +63,7 @@ limitations under the License.\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/service/hlo_cost_analysis.h\"\n #include \"xla/shape.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/tsl/framework/allocator.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n #include \"xla/xla.pb.h\"\n@@ -119,7 +119,7 @@ class TfrtGpuClient final : public PjRtClient {\n                 std::vector<std::unique_ptr<TfrtGpuDevice>> devices,\n                 bool should_stage_host_to_device_transfers,\n                 bool abort_collectives_on_failure,\n-                MaybeOwning<se::DeviceMemoryAllocator> allocator,\n+                MaybeOwning<se::DeviceAddressAllocator> allocator,\n                 std::unique_ptr<tsl::Allocator> host_memory_allocator,\n                 std::unique_ptr<gpu::GpuExecutableRunOptions> gpu_run_options,\n                 std::shared_ptr<KeyValueStoreInterface> kv_store,\n@@ -156,7 +156,7 @@ class TfrtGpuClient final : public PjRtClient {\n \n   xla::LocalClient* xla_client() const { return xla_client_; }\n \n-  se::DeviceMemoryAllocator* allocator() { return allocator_.get_mutable(); }\n+  se::DeviceAddressAllocator* allocator() { return allocator_.get_mutable(); }\n \n   bool should_stage_host_to_device_transfers() const {\n     return should_stage_host_to_device_transfers_;\n@@ -337,7 +337,7 @@ class TfrtGpuClient final : public PjRtClient {\n   // Device memory allocator. If owned, the allocator must outlive the devices,\n   // because it is the device destructor that waits for any outstanding work to\n   // complete.\n-  MaybeOwning<se::DeviceMemoryAllocator> allocator_;\n+  MaybeOwning<se::DeviceAddressAllocator> allocator_;\n   // Allocator to be used for staging memory transfers to devices.\n   std::unique_ptr<HostMemoryAllocator> host_memory_allocator_;\n "
        },
        {
            "sha": "c078751882b00c05947f70b46a7d3816364f87e1",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_client_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_client_test.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -77,8 +77,8 @@ limitations under the License.\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+#include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/device_description.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tests/literal_test_util.h\"\n@@ -386,7 +386,7 @@ static absl::Status MemsetFromValue(\n   uint32_t pattern;\n   std::memcpy(&pattern, &memset_value->value, sizeof(pattern));\n \n-  se::DeviceMemoryBase base = result->device_memory();\n+  se::DeviceAddressBase base = result->device_memory();\n   return stream->Memset32(&base, pattern, base.size());\n }\n \n@@ -434,7 +434,7 @@ static absl::Status MemsetFromAttr(\n   uint32_t pattern;\n   std::memcpy(&pattern, &attr, sizeof(pattern));\n \n-  se::DeviceMemoryBase base = result->device_memory();\n+  se::DeviceAddressBase base = result->device_memory();\n   return stream->Memset32(&base, pattern, base.size());\n }\n "
        },
        {
            "sha": "96204308bc2384f148ec984a44c44d94569ef321",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_device.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_device.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_device.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_device.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -55,8 +55,8 @@ limitations under the License.\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/service/transfer_manager.h\"\n #include \"xla/status_macros.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/integrations/tf_allocator_adapter.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream_executor.h\""
        },
        {
            "sha": "97707c3690fb062129a032c0b9ceccc709456e6f",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_device.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_device.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_device.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_device.h?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -46,7 +46,7 @@ limitations under the License.\n #include \"xla/pjrt/semaphore.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/service/transfer_manager.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\""
        },
        {
            "sha": "5e84506057c524c5b8d8a016b8903416c5447586",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tfrt_gpu_executable.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftfrt_gpu_executable.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -76,9 +76,9 @@ limitations under the License.\n #include \"xla/shape_layout.h\"\n #include \"xla/shape_tree.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/tsl/concurrency/async_value.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n@@ -110,7 +110,7 @@ namespace xla {\n class TfrtGpuCopyToDeviceStream : public CopyToDeviceStream {\n  public:\n   TfrtGpuCopyToDeviceStream(int64_t channel_id, se::Stream* stream,\n-                            se::DeviceMemoryBase dst,\n+                            se::DeviceAddressBase dst,\n                             tsl::AsyncValueRef<std::unique_ptr<se::Event>> done)\n       : CopyToDeviceStream(dst.size(), /*granule_bytes=*/1),\n         channel_id_(channel_id),\n@@ -146,7 +146,7 @@ class TfrtGpuCopyToDeviceStream : public CopyToDeviceStream {\n       return Future<>(done_.GetError());\n     }\n \n-    se::DeviceMemoryBase dst(\n+    se::DeviceAddressBase dst(\n         reinterpret_cast<std::byte*>(dst_.opaque()) + current_bytes_,\n         dst_.size() - current_bytes_);\n \n@@ -190,7 +190,7 @@ class TfrtGpuCopyToDeviceStream : public CopyToDeviceStream {\n  private:\n   int64_t channel_id_;\n   se::Stream* stream_;\n-  se::DeviceMemoryBase dst_;\n+  se::DeviceAddressBase dst_;\n \n   // Async value will become available after we'll submit the last memcpy\n   // operation, and the event will be recorded on the stream.\n@@ -771,21 +771,21 @@ absl::StatusOr<PjRtLoadedExecutable::Result> TfrtGpuExecutable::ExecuteHelper(\n         if (result_is_tuple) {\n           for (int i = 0; i < output_buffers.size(); ++i) {\n             ScopedShapedBuffer tuple_buffer = output.TakeSubTree({i});\n-            stream_executor::DeviceMemoryBase* elem =\n+            stream_executor::DeviceAddressBase* elem =\n                 tuple_buffer.buffers().mutable_element({});\n             VLOG(3) << \"untuple: output_buffers[\" << i\n                     << \"].emplace: \" << elem->opaque();\n             output_buffers[i].emplace(stream_executor::OwningDeviceMemory(\n                 *elem, device->local_device_id().value(), client->allocator()));\n-            *elem = se::DeviceMemoryBase();\n+            *elem = se::DeviceAddressBase();\n           }\n         } else {\n           CHECK_EQ(output_buffers.size(), 1);\n           auto* elem = output.buffers().mutable_element({});\n           VLOG(3) << \"output_buffers[0].emplace: \" << elem->opaque();\n           output_buffers.front().emplace(stream_executor::OwningDeviceMemory(\n               *elem, device->local_device_id().value(), client->allocator()));\n-          *elem = se::DeviceMemoryBase();\n+          *elem = se::DeviceAddressBase();\n         }\n \n         // Set the scheduled event to concrete to indicate that the scheduling"
        },
        {
            "sha": "3d49f9d7a168232f3c7bb29951df01d849559126",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tracked_gpu_device_buffer.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftracked_gpu_device_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftracked_gpu_device_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftracked_gpu_device_buffer.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -28,8 +28,8 @@ limitations under the License.\n #include \"xla/service/shaped_buffer.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_tree.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/event.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n@@ -44,7 +44,7 @@ ShapedBuffer GpuDeviceMemory::AsShapedBuffer(const Shape& on_device_shape,\n                                              const PjRtDevice* device) const {\n   ShapedBuffer shaped_buffer(on_device_shape, device->local_device_id().value(),\n                              device->local_hardware_id().value());\n-  ShapeTree<se::DeviceMemoryBase>::iterator iterator =\n+  ShapeTree<se::DeviceAddressBase>::iterator iterator =\n       shaped_buffer.buffers().begin();\n   CHECK(iterator != shaped_buffer.buffers().end());\n   iterator->second = buffer_;\n@@ -60,19 +60,19 @@ void GpuDeviceMemory::SetUnOwned() {\n }\n \n absl::StatusOr<GpuDeviceMemory> GpuDeviceMemory::Allocate(\n-    se::DeviceMemoryAllocator* allocator, int device_ordinal, size_t size) {\n+    se::DeviceAddressAllocator* allocator, int device_ordinal, size_t size) {\n   return Allocate(allocator, device_ordinal, size,\n                   static_cast<int>(se::MemoryType::kDevice));\n }\n \n absl::StatusOr<GpuDeviceMemory> GpuDeviceMemory::Allocate(\n-    se::DeviceMemoryAllocator* allocator, int device_ordinal, size_t size,\n+    se::DeviceAddressAllocator* allocator, int device_ordinal, size_t size,\n     int64_t memory_space) {\n   if (size == 0) {\n-    return GpuDeviceMemory(se::DeviceMemoryBase());\n+    return GpuDeviceMemory(se::DeviceAddressBase());\n   }\n   TF_ASSIGN_OR_RETURN(\n-      stream_executor::OwningDeviceMemory memory,\n+      stream_executor::ScopedDeviceAddress<uint8_t> memory,\n       allocator->Allocate(device_ordinal, size, /*retry_on_failure=*/true,\n                           memory_space));\n   return GpuDeviceMemory(std::move(memory));"
        },
        {
            "sha": "71abf7139016dd82c027f0d11d6762394695ca29",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tracked_gpu_device_buffer.h",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftracked_gpu_device_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftracked_gpu_device_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftracked_gpu_device_buffer.h?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -29,8 +29,8 @@ limitations under the License.\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/service/shaped_buffer.h\"\n #include \"xla/shape.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/event.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n \n@@ -47,11 +47,11 @@ class GpuDeviceMemory {\n   GpuDeviceMemory& operator=(GpuDeviceMemory&& other) = default;\n \n   // Creates non-owning GPU device memory from a raw data pointer.\n-  explicit GpuDeviceMemory(stream_executor::DeviceMemoryBase buffer)\n+  explicit GpuDeviceMemory(stream_executor::DeviceAddressBase buffer)\n       : buffer_(buffer) {}\n \n   // Creates owning GPU device memory from an owned data pointer.\n-  explicit GpuDeviceMemory(stream_executor::OwningDeviceMemory buffer)\n+  explicit GpuDeviceMemory(stream_executor::ScopedDeviceAddress<uint8_t> buffer)\n       : owning_buffer_(std::move(buffer)), buffer_(*owning_buffer_) {}\n \n   ShapedBuffer AsShapedBuffer(const Shape& on_device_shape,\n@@ -62,19 +62,19 @@ class GpuDeviceMemory {\n \n   // Allocates raw owning memory.\n   static absl::StatusOr<GpuDeviceMemory> Allocate(\n-      se::DeviceMemoryAllocator* allocator, int device_ordinal, size_t size);\n+      se::DeviceAddressAllocator* allocator, int device_ordinal, size_t size);\n \n   static absl::StatusOr<GpuDeviceMemory> Allocate(\n-      se::DeviceMemoryAllocator* allocator, int device_ordinal, size_t size,\n+      se::DeviceAddressAllocator* allocator, int device_ordinal, size_t size,\n       int64_t memory_space);\n \n-  stream_executor::DeviceMemoryBase buffer() const { return buffer_; }\n+  stream_executor::DeviceAddressBase buffer() const { return buffer_; }\n   size_t size_bytes() const { return buffer_.size(); }\n   bool owns_data() const { return !owning_buffer_.is_null(); }\n \n  private:\n-  stream_executor::OwningDeviceMemory owning_buffer_;\n-  se::DeviceMemoryBase buffer_;\n+  stream_executor::ScopedDeviceAddress<uint8_t> owning_buffer_;\n+  se::DeviceAddressBase buffer_;\n };\n \n // Class that represents a GPU buffer. It optionally owns the buffer. It also"
        },
        {
            "sha": "7961f01d17b4393764634a4e9e527ab77499b243",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/tracked_gpu_device_buffer_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftracked_gpu_device_buffer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftracked_gpu_device_buffer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Ftracked_gpu_device_buffer_test.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -39,8 +39,8 @@ limitations under the License.\n #include \"xla/service/shaped_buffer.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/device_address_allocator.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n #include \"xla/tsl/concurrency/async_value.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/platform/env.h\"\n@@ -65,11 +65,11 @@ class TestAllocator : public se::DeviceAddressAllocator {\n   absl::StatusOr<stream_executor::ScopedDeviceAddress<uint8_t>> Allocate(\n       int device_ordinal, uint64_t size, bool retry_on_failure,\n       int64_t memory_space) override {\n-    const se::DeviceMemoryBase base(kOpaque, size);\n+    const se::DeviceAddressBase base(kOpaque, size);\n     return stream_executor::ScopedDeviceAddress<uint8_t>(base, 0, this);\n   }\n   absl::Status Deallocate(int device_ordinal,\n-                          se::DeviceMemoryBase mem) override {\n+                          se::DeviceAddressBase mem) override {\n     return absl::OkStatus();\n   }\n   absl::StatusOr<se::Stream*> GetStream(int device_ordinal) override {"
        },
        {
            "sha": "a59dd22155ddb6cc19fa0be78c5b2ee851b69ae6",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/utils.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 12,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -83,10 +83,10 @@ limitations under the License.\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/integrations/tf_allocator_adapter.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -307,7 +307,7 @@ absl::flat_hash_map<std::string, PjRtDeviceAttribute> GetAttrsForDevices(\n class TfrtGpuCopyToDeviceStream : public CopyToDeviceStream {\n  public:\n   TfrtGpuCopyToDeviceStream(int64_t channel_id, se::Stream* stream,\n-                            se::DeviceMemoryBase dst,\n+                            se::DeviceAddressBase dst,\n                             tsl::AsyncValueRef<std::unique_ptr<se::Event>> done)\n       : CopyToDeviceStream(dst.size(), /*granule_bytes=*/1),\n         channel_id_(channel_id),\n@@ -343,7 +343,7 @@ class TfrtGpuCopyToDeviceStream : public CopyToDeviceStream {\n       return Future<>(done_.GetError());\n     }\n \n-    se::DeviceMemoryBase dst(\n+    se::DeviceAddressBase dst(\n         reinterpret_cast<std::byte*>(dst_.opaque()) + current_bytes_,\n         dst_.size() - current_bytes_);\n \n@@ -387,7 +387,7 @@ class TfrtGpuCopyToDeviceStream : public CopyToDeviceStream {\n  private:\n   int64_t channel_id_;\n   se::Stream* stream_;\n-  se::DeviceMemoryBase dst_;\n+  se::DeviceAddressBase dst_;\n \n   // Async value will become available after we'll submit the last memcpy\n   // operation, and the event will be recorded on the stream.\n@@ -401,7 +401,7 @@ SendDeviceMemoryFunction ConvertSendCallbacksToSendFunction(\n   // Check if we have callbacks registered for the given replica.\n   if (replica >= options.send_callbacks.size()) {\n     return [replica](int64_t channel_id, se::Stream*, const Shape&,\n-                     const se::DeviceMemoryBase&,\n+                     const se::DeviceAddressBase&,\n                      const absl::flat_hash_map<std::string, std::string>&) {\n       return Internal(\n           \"Don't send a buffer to the channel_id=%d, there was no send \"\n@@ -415,7 +415,7 @@ SendDeviceMemoryFunction ConvertSendCallbacksToSendFunction(\n \n   return [callbacks, thread_pool](\n              int64_t channel_id, se::Stream* stream, const Shape& shape,\n-             const se::DeviceMemoryBase& src,\n+             const se::DeviceAddressBase& src,\n              const absl::flat_hash_map<std::string, std::string>&)\n              -> absl::StatusOr<tsl::AsyncValueRef<std::unique_ptr<se::Event>>> {\n     VLOG(4) << \"Send \" << src.size() << \" bytes to channel #\" << channel_id\n@@ -490,7 +490,7 @@ RecvDeviceMemoryFunction ConvertRecvCallbacksToRecvFunction(\n   // Check if we have callbacks registered for the given replica.\n   if (replica >= options.send_callbacks.size()) {\n     return [replica](int64_t channel_id, se::Stream*, const Shape&,\n-                     se::DeviceMemoryBase*,\n+                     se::DeviceAddressBase*,\n                      const absl::flat_hash_map<std::string, std::string>&) {\n       return InvalidArgument(\n           \"Failed to receive a buffer from the channel_id=%d, there was no \"\n@@ -503,7 +503,7 @@ RecvDeviceMemoryFunction ConvertRecvCallbacksToRecvFunction(\n   absl::Span<const RecvCallback> callbacks = options.recv_callbacks[replica];\n \n   return [callbacks](int64_t channel_id, se::Stream* stream, const Shape& shape,\n-                     se::DeviceMemoryBase* dst,\n+                     se::DeviceAddressBase* dst,\n                      const absl::flat_hash_map<std::string, std::string>&)\n              -> absl::StatusOr<tsl::AsyncValueRef<std::unique_ptr<se::Event>>> {\n     VLOG(4) << \"Recv from channel #\" << channel_id\n@@ -650,7 +650,7 @@ absl::StatusOr<std::unique_ptr<tsl::Allocator>> CreateAllocatorForDevice(\n   }\n }\n \n-absl::StatusOr<MaybeOwning<se::DeviceMemoryAllocator>> CreateDeviceAllocator(\n+absl::StatusOr<MaybeOwning<se::DeviceAddressAllocator>> CreateDeviceAllocator(\n     LocalClient* xla_client, const GpuAllocatorConfig& allocator_config,\n     const std::vector<std::unique_ptr<TfrtGpuDevice>>& devices) {\n   if (allocator_config.kind == GpuAllocatorConfig::Kind::kPlatform) {\n@@ -660,7 +660,7 @@ absl::StatusOr<MaybeOwning<se::DeviceMemoryAllocator>> CreateDeviceAllocator(\n           << \"collective_memory_size is non-zero, but allocator kind is set \"\n              \"to \\\"platform\\\". Collective memory will not be allocated.\";\n     }\n-    return MaybeOwning<se::DeviceMemoryAllocator>(\n+    return MaybeOwning<se::DeviceAddressAllocator>(\n         xla_client->backend().memory_allocator());\n   }\n \n@@ -697,7 +697,7 @@ absl::StatusOr<MaybeOwning<se::DeviceMemoryAllocator>> CreateDeviceAllocator(\n         /*memory_space=*/static_cast<int>(se::MemoryType::kHost),\n         executor->device_ordinal(), executor->GetPlatform());\n   }\n-  return MaybeOwning<se::DeviceMemoryAllocator>(\n+  return MaybeOwning<se::DeviceAddressAllocator>(\n       std::make_unique<se::MultiDeviceAdapter>(xla_client->platform(),\n                                                std::move(allocators)));\n }"
        },
        {
            "sha": "c7599bd4967d97394937498f7935a5263128793e",
            "filename": "third_party/xla/xla/pjrt/gpu/tfrt/utils.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Ftfrt%2Futils.h?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -53,7 +53,7 @@ limitations under the License.\n #include \"xla/service/gpu/gpu_executable_run_options.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/shape.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -154,7 +154,7 @@ std::vector<std::unique_ptr<PjRtMemorySpace>> InitializeMemorySpaces(\n absl::StatusOr<std::unique_ptr<tsl::Allocator>> CreateAllocatorForDevice(\n     se::StreamExecutor* executor, const GpuAllocatorConfig& allocator_config);\n \n-absl::StatusOr<MaybeOwning<se::DeviceMemoryAllocator>> CreateDeviceAllocator(\n+absl::StatusOr<MaybeOwning<se::DeviceAddressAllocator>> CreateDeviceAllocator(\n     LocalClient* xla_client, const GpuAllocatorConfig& allocator_config,\n     const std::vector<std::unique_ptr<TfrtGpuDevice>>& devices);\n "
        },
        {
            "sha": "a1812c63ec19a0e69fd985fae673d6b1fb9fc16c",
            "filename": "third_party/xla/xla/pjrt/local_device_state.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -34,7 +34,7 @@ limitations under the License.\n #include \"xla/client/local_client.h\"\n #include \"xla/pjrt/buffer_sequencing_event.h\"\n #include \"xla/pjrt/worker_thread.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -177,7 +177,7 @@ absl::Status LocalDeviceState::SynchronizeAllActivity() {\n \n absl::Status LocalDeviceState::ThenMemcpyDeviceToDevice(\n     se::Stream* transfer_stream, se::Stream* dst_stream,\n-    se::DeviceMemoryBase src_buffer, se::DeviceMemoryBase dst_buffer) {\n+    se::DeviceAddressBase src_buffer, se::DeviceAddressBase dst_buffer) {\n   // The default implementation simply calls MemcpyD2D, and assumes that\n   // the buffer addresses identify the devices. This does not work\n   // on all platforms; this method is virtual so it can be overridden."
        },
        {
            "sha": "38ca812e589c74eb23130b93c2874934591dced1",
            "filename": "third_party/xla/xla/pjrt/local_device_state.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.h?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -168,7 +168,7 @@ class LocalDeviceState {\n   // Enqueues a copy of `src_buffer` to `dst_buffer` onto `transfer_stream`.\n   virtual absl::Status ThenMemcpyDeviceToDevice(\n       se::Stream* transfer_stream, se::Stream* dst_stream,\n-      se::DeviceMemoryBase src_buffer, se::DeviceMemoryBase dst_buffer);\n+      se::DeviceAddressBase src_buffer, se::DeviceAddressBase dst_buffer);\n \n   WorkerThread* execute_thread() const { return execute_thread_.get(); }\n "
        },
        {
            "sha": "e342a5868630019a52a161d8cee21607173afd62",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 15,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -147,8 +147,8 @@ limitations under the License.\n #include \"xla/shape.h\"\n #include \"xla/shape_tree.h\"\n #include \"xla/shape_util.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n@@ -275,7 +275,7 @@ PjRtStreamExecutorClient::PjRtStreamExecutorClient(\n     std::vector<std::unique_ptr<PjRtStreamExecutorDevice>> devices,\n     int process_index,\n     std::vector<std::unique_ptr<PjRtMemorySpace>> memory_spaces,\n-    std::unique_ptr<se::DeviceMemoryAllocator> allocator,\n+    std::unique_ptr<se::DeviceAddressAllocator> allocator,\n     std::unique_ptr<tsl::Allocator> host_memory_allocator,\n     bool should_stage_host_to_device_transfers,\n     std::unique_ptr<gpu::GpuExecutableRunOptions> gpu_run_options)\n@@ -730,7 +730,7 @@ PjRtStreamExecutorClient::LinearizeHostBufferInto(\n         // memory that has already been allocated, and a possible Event\n         // allocation.\n \n-        se::DeviceMemoryBase device_memory =\n+        se::DeviceAddressBase device_memory =\n             tensorflow::down_cast<PjRtStreamExecutorRawBuffer*>(\n                 raw_buffer.get())\n                 ->device_buffer()\n@@ -904,7 +904,7 @@ PjRtStreamExecutorClient::CreateViewOfDeviceBuffer(\n   auto* device = memory_space->devices().front();\n \n   auto buffer = RawSEDeviceMemory::CreateForeign(\n-      se::DeviceMemoryBase(device_ptr, ShapeUtil::ByteSizeOf(shape)),\n+      se::DeviceAddressBase(device_ptr, ShapeUtil::ByteSizeOf(shape)),\n       std::move(on_delete_callback));\n \n   TF_ASSIGN_OR_RETURN(LocalDeviceState * local_device,\n@@ -1139,7 +1139,7 @@ MakeTupleHelper(PjRtStreamExecutorClient* client,\n                 absl::Span<PjRtBuffer* const> py_buffers,\n                 absl::Span<const CommonPjRtBuffer::ScopedHold> device_buffers,\n                 int device_ordinal) {\n-  se::DeviceMemoryAllocator* allocator = client->allocator();\n+  se::DeviceAddressAllocator* allocator = client->allocator();\n   TransferManager* transfer_manager =\n       client->client()->backend().transfer_manager();\n \n@@ -1190,7 +1190,7 @@ MakeTupleHelper(PjRtStreamExecutorClient* client,\n   }\n   CHECK(input_iterator == iterator_end);\n \n-  std::vector<se::DeviceMemoryBase> elements;\n+  std::vector<se::DeviceAddressBase> elements;\n   size_t num_elements = ShapeUtil::TupleElementCount(tupled_parameter_shape);\n   elements.reserve(num_elements);\n   for (int64_t i = 0; i < num_elements; ++i) {\n@@ -1442,7 +1442,7 @@ static SendDeviceMemoryFunction ConvertSendCallbacksToSendFunction(\n   // Check if we have callbacks registered for the given replica.\n   if (replica >= options.send_callbacks.size()) {\n     return [replica](int64_t channel_id, se::Stream*, const Shape&,\n-                     const se::DeviceMemoryBase&,\n+                     const se::DeviceAddressBase&,\n                      const absl::flat_hash_map<std::string, std::string>&) {\n       return Internal(\n           \"Don't send a buffer to the channel_id=%d, there was no send \"\n@@ -1456,7 +1456,7 @@ static SendDeviceMemoryFunction ConvertSendCallbacksToSendFunction(\n \n   return [callbacks, thread_pool](\n              int64_t channel_id, se::Stream* stream, const Shape& shape,\n-             const se::DeviceMemoryBase& src,\n+             const se::DeviceAddressBase& src,\n              const absl::flat_hash_map<std::string, std::string>&)\n              -> absl::StatusOr<AsyncValueRef<std::unique_ptr<se::Event>>> {\n     VLOG(3) << \"Send \" << src.size() << \" bytes to channel #\" << channel_id\n@@ -1525,7 +1525,7 @@ namespace {\n class StreamExecutorCopyToDeviceStream : public CopyToDeviceStream {\n  public:\n   StreamExecutorCopyToDeviceStream(\n-      int64_t channel_id, se::Stream* stream, se::DeviceMemoryBase dst,\n+      int64_t channel_id, se::Stream* stream, se::DeviceAddressBase dst,\n       AsyncValueRef<std::unique_ptr<se::Event>> done)\n       : CopyToDeviceStream(dst.size(), /*granule_bytes=*/1),\n         channel_id_(channel_id),\n@@ -1562,7 +1562,7 @@ class StreamExecutorCopyToDeviceStream : public CopyToDeviceStream {\n       return Future<>(done_.GetError());\n     }\n \n-    se::DeviceMemoryBase dst(\n+    se::DeviceAddressBase dst(\n         reinterpret_cast<std::byte*>(dst_.opaque()) + current_bytes_,\n         dst_.size() - current_bytes_);\n \n@@ -1602,7 +1602,7 @@ class StreamExecutorCopyToDeviceStream : public CopyToDeviceStream {\n  private:\n   int64_t channel_id_;\n   se::Stream* stream_;\n-  se::DeviceMemoryBase dst_;\n+  se::DeviceAddressBase dst_;\n \n   // Async value will become available after we'll submit the last memcpy\n   // operation, and the event will be recorded on the stream.\n@@ -1615,7 +1615,7 @@ static RecvDeviceMemoryFunction ConvertRecvCallbacksToRecvFunction(\n   // Check if we have callbacks registered for the given replica.\n   if (replica >= options.send_callbacks.size()) {\n     return [replica](int64_t channel_id, se::Stream*, const Shape&,\n-                     se::DeviceMemoryBase*,\n+                     se::DeviceAddressBase*,\n                      const absl::flat_hash_map<std::string, std::string>&) {\n       return InvalidArgument(\n           \"Failed to receive a buffer from the channel_id=%d, there was no \"\n@@ -1628,7 +1628,7 @@ static RecvDeviceMemoryFunction ConvertRecvCallbacksToRecvFunction(\n   absl::Span<const RecvCallback> callbacks = options.recv_callbacks[replica];\n \n   return [callbacks](int64_t channel_id, se::Stream* stream, const Shape& shape,\n-                     se::DeviceMemoryBase* dst,\n+                     se::DeviceAddressBase* dst,\n                      const absl::flat_hash_map<std::string, std::string>&)\n              -> absl::StatusOr<AsyncValueRef<std::unique_ptr<se::Event>>> {\n     VLOG(3) << \"Recv from channel #\" << channel_id\n@@ -1691,7 +1691,7 @@ PjRtStreamExecutorClient::RunAsync(\n   xla::ShapeTree<tsl::AsyncValueRef<RawSEDeviceMemory>> results(\n       ssb.on_device_shape());\n   auto it = results.begin();\n-  se::DeviceMemoryAllocator* allocator = ssb.memory_allocator();\n+  se::DeviceAddressAllocator* allocator = ssb.memory_allocator();\n   ShapedBuffer released_ssb = ssb.release();\n   for (auto& buf : released_ssb.buffers()) {\n     CHECK(it != results.end());"
        },
        {
            "sha": "4b656c48fc2517244fc0db8bda49a3d10b465b0f",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.h",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.h?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -66,7 +66,7 @@ limitations under the License.\n #include \"xla/service/hlo_cost_analysis.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_tree.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/framework/allocator.h\"\n@@ -237,7 +237,7 @@ class PjRtStreamExecutorClient : public CommonPjRtClient {\n       std::vector<std::unique_ptr<PjRtStreamExecutorDevice>> devices,\n       int process_index,\n       std::vector<std::unique_ptr<PjRtMemorySpace>> memory_spaces,\n-      std::unique_ptr<se::DeviceMemoryAllocator> allocator,\n+      std::unique_ptr<se::DeviceAddressAllocator> allocator,\n       std::unique_ptr<tsl::Allocator> host_memory_allocator,\n       bool should_stage_host_to_device_transfers,\n       std::unique_ptr<gpu::GpuExecutableRunOptions> gpu_run_options);\n@@ -340,7 +340,7 @@ class PjRtStreamExecutorClient : public CommonPjRtClient {\n                 ->local_device_state();\n   }\n   LocalClient* client() const { return client_; }\n-  se::DeviceMemoryAllocator* allocator() const { return allocator_; }\n+  se::DeviceAddressAllocator* allocator() const { return allocator_; }\n   tsl::Allocator* host_memory_allocator() const {\n     return host_memory_allocator_.get();\n   }\n@@ -488,8 +488,8 @@ class PjRtStreamExecutorClient : public CommonPjRtClient {\n   // Device memory allocator. If owned, the allocator must outlive the devices,\n   // because it is the device destructor that waits for any outstanding work to\n   // complete.\n-  se::DeviceMemoryAllocator* allocator_;\n-  std::unique_ptr<se::DeviceMemoryAllocator> owned_allocator_;\n+  se::DeviceAddressAllocator* allocator_;\n+  std::unique_ptr<se::DeviceAddressAllocator> owned_allocator_;\n \n   // Includes all devices, including non-local devices on multi-host platforms.\n   std::vector<std::unique_ptr<PjRtStreamExecutorDevice>> owned_devices_;"
        },
        {
            "sha": "4ba31cb16cb1d9ef261c4416fc39f8d5b89bc75c",
            "filename": "third_party/xla/xla/pjrt/se_raw_buffer.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -43,7 +43,7 @@ limitations under the License.\n #include \"xla/primitive_util.h\"\n #include \"xla/service/generic_transfer_manager.h\"\n #include \"xla/shape_util.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n@@ -136,7 +136,7 @@ PjRtStreamExecutorRawBuffer::CopyRawHostToDeviceAndReturnEvent(\n                                     local_device = local_device_, stream, src,\n                                     offset, transfer_size,\n                                     buf = tsl::FormRef(this)]() mutable {\n-    se::DeviceMemoryBase sub_buffer = buf->device_buffer_->mem();\n+    se::DeviceAddressBase sub_buffer = buf->device_buffer_->mem();\n     if (transfer_size < sub_buffer.size()) {\n       sub_buffer = sub_buffer.GetByteSlice(offset, transfer_size);\n     }\n@@ -196,7 +196,7 @@ PjRtStreamExecutorRawBuffer::CopyRawDeviceToHostAndReturnEvent(\n                                     local_device = local_device_, stream, dst,\n                                     offset, transfer_size,\n                                     buf = tsl::FormRef(this)]() mutable {\n-    se::DeviceMemoryBase sub_buffer = buf->device_buffer_->mem();\n+    se::DeviceAddressBase sub_buffer = buf->device_buffer_->mem();\n     if (transfer_size < sub_buffer.size()) {\n       sub_buffer = sub_buffer.GetByteSlice(offset, transfer_size);\n     }\n@@ -248,7 +248,7 @@ ShapedBuffer PjRtStreamExecutorRawBuffer::AsShapedBuffer(\n   auto* device = memory_space()->devices()[0];\n   ShapedBuffer shaped_buffer(shape, device->local_device_id().value(),\n                              device->local_hardware_id().value());\n-  ShapeTree<se::DeviceMemoryBase>::iterator iterator =\n+  ShapeTree<se::DeviceAddressBase>::iterator iterator =\n       shaped_buffer.buffers().begin();\n   if (device_buffer_) {\n     CHECK(iterator != shaped_buffer.buffers().end());"
        },
        {
            "sha": "31f668f7baf51d4a48fef9639149ff4ea0639135",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -42,8 +42,8 @@ limitations under the License.\n #include \"xla/service/shaped_buffer.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_tree.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/tsl/concurrency/async_value.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n@@ -57,7 +57,7 @@ ShapedBuffer RawSEDeviceMemory::AsShapedBuffer(\n     PjRtDevice* device, const Shape& on_device_shape) const {\n   ShapedBuffer shaped_buffer(on_device_shape, device->local_device_id().value(),\n                              device->local_hardware_id().value());\n-  ShapeTree<se::DeviceMemoryBase>::iterator iterator =\n+  ShapeTree<se::DeviceAddressBase>::iterator iterator =\n       shaped_buffer.buffers().begin();\n   CHECK(iterator != shaped_buffer.buffers().end());\n   iterator->second = mem();\n@@ -68,9 +68,9 @@ ShapedBuffer RawSEDeviceMemory::AsShapedBuffer(\n \n class AllocatedRawSEDeviceMemory : public RawSEDeviceMemory {\n  public:\n-  AllocatedRawSEDeviceMemory(se::DeviceMemoryBase value,\n+  AllocatedRawSEDeviceMemory(se::DeviceAddressBase value,\n                              LocalDeviceState* local_device,\n-                             se::DeviceMemoryAllocator* allocator)\n+                             se::DeviceAddressAllocator* allocator)\n       : RawSEDeviceMemory(value),\n         allocator_(allocator),\n         local_device_(local_device) {\n@@ -103,21 +103,21 @@ class AllocatedRawSEDeviceMemory : public RawSEDeviceMemory {\n   }\n \n  private:\n-  se::DeviceMemoryAllocator* allocator_;\n+  se::DeviceAddressAllocator* allocator_;\n   LocalDeviceState* local_device_;\n   size_t sync_point_ = std::numeric_limits<size_t>::max();\n };\n \n tsl::AsyncValueRef<RawSEDeviceMemory> RawSEDeviceMemory::Create(\n-    se::DeviceMemoryBase value, LocalDeviceState* local_device,\n-    se::DeviceMemoryAllocator* allocator) {\n+    se::DeviceAddressBase value, LocalDeviceState* local_device,\n+    se::DeviceAddressAllocator* allocator) {\n   return tsl::MakeAvailableAsyncValueRef<AllocatedRawSEDeviceMemory>(\n       value, local_device, allocator);\n }\n \n class ForeignRawSEDeviceMemory : public RawSEDeviceMemory {\n  public:\n-  ForeignRawSEDeviceMemory(se::DeviceMemoryBase value,\n+  ForeignRawSEDeviceMemory(se::DeviceAddressBase value,\n                            absl::AnyInvocable<void() &&> on_delete_callback)\n       : RawSEDeviceMemory(value),\n         on_delete_callback_(std::move(on_delete_callback)) {}\n@@ -133,7 +133,7 @@ class ForeignRawSEDeviceMemory : public RawSEDeviceMemory {\n };\n \n tsl::AsyncValueRef<RawSEDeviceMemory> RawSEDeviceMemory::CreateForeign(\n-    se::DeviceMemoryBase value,\n+    se::DeviceAddressBase value,\n     absl::AnyInvocable<void() &&> on_delete_callback) {\n   return tsl::MakeAvailableAsyncValueRef<ForeignRawSEDeviceMemory>(\n       value, std::move(on_delete_callback));"
        },
        {
            "sha": "7bce98bf6fa0a812037aa7bdb684f0e72784e49b",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer.h",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -43,8 +43,8 @@ limitations under the License.\n #include \"xla/service/shaped_buffer.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_tree.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/device_address.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n@@ -53,11 +53,11 @@ namespace xla {\n \n class RawSEDeviceMemory {\n  public:\n-  explicit RawSEDeviceMemory(se::DeviceMemoryBase value) : value_(value) {}\n+  explicit RawSEDeviceMemory(se::DeviceAddressBase value) : value_(value) {}\n \n   virtual ~RawSEDeviceMemory() = default;\n \n-  const se::DeviceMemoryBase& mem() const { return value_; }\n+  const se::DeviceAddressBase& mem() const { return value_; }\n \n   void* opaque() const { return value_.opaque(); }\n \n@@ -70,10 +70,10 @@ class RawSEDeviceMemory {\n                               const Shape& on_device_shape) const;\n \n   static tsl::AsyncValueRef<RawSEDeviceMemory> Create(\n-      se::DeviceMemoryBase value, LocalDeviceState* local_device,\n-      se::DeviceMemoryAllocator* allocator);\n+      se::DeviceAddressBase value, LocalDeviceState* local_device,\n+      se::DeviceAddressAllocator* allocator);\n   static tsl::AsyncValueRef<RawSEDeviceMemory> CreateForeign(\n-      se::DeviceMemoryBase value,\n+      se::DeviceAddressBase value,\n       absl::AnyInvocable<void() &&> on_delete_callback);\n \n   // Returns a definition event (or nullptr if the definition is known to be in\n@@ -84,7 +84,7 @@ class RawSEDeviceMemory {\n   }\n \n  private:\n-  se::DeviceMemoryBase value_;\n+  se::DeviceAddressBase value_;\n };\n \n // Class that represents a tuple of device buffers. Like a ScopedShapedBuffer it\n@@ -124,7 +124,7 @@ class TrackedDeviceBuffer : public AbstractTrackedDeviceBuffer {\n       ShapeTree<MaybeOwningDeviceAddress>::iterator* iterator,\n       const ShapeTree<MaybeOwningDeviceAddress>::iterator& end,\n       ExecutionInput* execution_input,\n-      se::DeviceMemoryAllocator* allocator) const;\n+      se::DeviceAddressAllocator* allocator) const;\n \n   const absl::InlinedVector<BufferSequencingEventRef, 2>& definition_events()\n       const {"
        },
        {
            "sha": "d5bec6ba2869779c15d3a2cea2f9b4ae37820c11",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13a525b5831ff70f781fe3dd361440c059017464/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer_test.cc?ref=13a525b5831ff70f781fe3dd361440c059017464",
            "patch": "@@ -34,7 +34,7 @@ limitations under the License.\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -114,7 +114,7 @@ TEST(TrackedDeviceBufferTest, AsShapedBuffer) {\n   TF_ASSERT_OK_AND_ASSIGN(auto b_buffer, MakeArray(b_shape, client));\n   TF_ASSERT_OK_AND_ASSIGN(auto c_buffer, MakeArray(c_shape, client));\n \n-  std::vector<se::DeviceMemoryBase> expected_buffer_sequence = {\n+  std::vector<se::DeviceAddressBase> expected_buffer_sequence = {\n       a_buffer->mem(), b_buffer->mem(), c_buffer->mem()};\n   ShapedBuffer shaped_a = a_buffer->AsShapedBuffer(\n       &device,"
        }
    ],
    "stats": {
        "total": 300,
        "additions": 150,
        "deletions": 150
    }
}