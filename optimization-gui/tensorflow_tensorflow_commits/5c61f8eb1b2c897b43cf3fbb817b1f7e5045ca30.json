{
    "author": "basioli-k",
    "message": "[XLA:GPU][host offloading] Add tests that verify host execute thunk works with managed memory.\n\nPiperOrigin-RevId: 817330922",
    "sha": "5c61f8eb1b2c897b43cf3fbb817b1f7e5045ca30",
    "files": [
        {
            "sha": "b43fade7529019ca752e67f0cd43ba840144fa19",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_execute_thunk_test.cc",
            "status": "modified",
            "additions": 75,
            "deletions": 0,
            "changes": 75,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5c61f8eb1b2c897b43cf3fbb817b1f7e5045ca30/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5c61f8eb1b2c897b43cf3fbb817b1f7e5045ca30/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk_test.cc?ref=5c61f8eb1b2c897b43cf3fbb817b1f7e5045ca30",
            "patch": "@@ -321,6 +321,81 @@ TEST(HostExecuteStartThunkTest, ArgAndResultPinnedOnHost) {\n   EXPECT_EQ(*static_cast<int32_t*>(result_memory_allocation->opaque()), 10);\n }\n \n+TEST(HostExecuteStartThunkTest, ArgAndResultInSharedMemory) {\n+  se::StreamExecutor* stream_executor = GpuExecutor();\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_executor->CreateStream());\n+\n+  static constexpr char const* kHloModule = R\"(\n+    HloModule module\n+    ENTRY add_inplace {\n+      p0 = s32[] parameter(0)\n+      ROOT add = s32[] add(p0, p0)\n+    }\n+  )\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto hlo_module,\n+                          ParseAndReturnUnverifiedModule(kHloModule, {}));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto unified_memory_allocator,\n+                          stream_executor->CreateMemoryAllocator(\n+                              stream_executor::MemoryType::kUnified));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto arg_memory_allocation,\n+      unified_memory_allocator->Allocate(1 * sizeof(int32_t)));\n+\n+  constexpr int32_t kArgValue = 5;\n+  std::memcpy(arg_memory_allocation->opaque(), &kArgValue, sizeof(kArgValue));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto result_memory_allocation,\n+      unified_memory_allocator->Allocate(1 * sizeof(int32_t)));\n+\n+  se::DeviceMemoryBase arg(arg_memory_allocation->opaque(),\n+                           arg_memory_allocation->size());\n+  se::DeviceMemoryBase result(result_memory_allocation->opaque(),\n+                              result_memory_allocation->size());\n+\n+  // Prepare buffer allocations for recording command buffer.\n+  BufferAllocation alloc_arg(/*index=*/0, 4, /*color=*/0);\n+  BufferAllocation alloc_result(/*index=*/1, 4, /*color=*/0);\n+\n+  BufferAllocation::Slice slice_arg(&alloc_arg, 0, 4);\n+  BufferAllocation::Slice slice_result(&alloc_result, 0, 4);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto thunk,\n+                          CreateHostExecuteStartThunk(\n+                              Thunk::ThunkInfo(), *hlo_module,\n+                              {{slice_arg, ShapeUtil::MakeShape(S32, {})}},\n+                              {{slice_result, ShapeUtil::MakeShape(S32, {})}}));\n+\n+  se::StreamExecutorMemoryAllocator allocator(stream_executor);\n+  ExecutableRunOptions executable_run_options;\n+  executable_run_options.set_device_to_host_stream(stream.get());\n+  executable_run_options.set_host_to_device_stream(stream.get());\n+  ServiceExecutableRunOptions service_executable_run_options(\n+      executable_run_options);\n+  BufferAllocations allocations({arg, result}, 0, &allocator);\n+\n+  Thunk::ExecuteParams params = Thunk::ExecuteParams::Create(\n+      service_executable_run_options, allocations, stream.get(), stream.get(),\n+      nullptr, nullptr);\n+\n+  TF_ASSERT_OK(\n+      thunk->Initialize(Thunk::InitializeParams{/*executor=*/stream_executor}));\n+  TF_ASSERT_OK(thunk->ExecuteOnStream(params));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto execute_event,\n+                          thunk->async_events()->ExtractEvent(\n+                              stream_executor, RunId(params.execution_id)));\n+  tsl::BlockUntilReady(execute_event);\n+  EXPECT_FALSE(execute_event.IsError());\n+  TF_ASSERT_OK(stream->WaitFor(execute_event.get().get()));\n+  TF_ASSERT_OK(stream->BlockHostUntilDone());\n+\n+  EXPECT_EQ(*static_cast<int32_t*>(result_memory_allocation->opaque()), 10);\n+}\n+\n TEST(HostExecuteStartThunkTest, ArgAndResultNonRegisteredHostMemory) {\n   se::StreamExecutor* stream_executor = GpuExecutor();\n   TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_executor->CreateStream());"
        }
    ],
    "stats": {
        "total": 75,
        "additions": 75,
        "deletions": 0
    }
}