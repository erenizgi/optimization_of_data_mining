{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 826725010",
    "sha": "09f85795bae3db9228cfa99751613805945a37d5",
    "files": [
        {
            "sha": "25dfae3ec7be3e70279e1ce16e765f55a05433c7",
            "filename": "tensorflow/core/grappler/optimizers/data/auto_shard.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 32,
            "changes": 65,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fauto_shard.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fauto_shard.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fauto_shard.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -268,9 +268,9 @@ absl::Status AddShardNode(MutableGraphView* graph, const NodeDef& add_before,\n \n absl::Status AddShuffleDataset(MutableGraphView* graph,\n                                const NodeDef& add_before,\n-                               const string& buffer_size_node,\n-                               const string& seed_node,\n-                               const string& seed2_node,\n+                               const std::string& buffer_size_node,\n+                               const std::string& seed_node,\n+                               const std::string& seed2_node,\n                                bool reshuffle_each_iteration) {\n   NodeDef* add_after = graph->GetNode(add_before.input(0));\n   NodeDef new_node;\n@@ -299,8 +299,8 @@ absl::Status AddShuffleDataset(MutableGraphView* graph,\n \n absl::Status AddShuffleDatasetV2(MutableGraphView* graph,\n                                  const NodeDef& add_before,\n-                                 const string& buffer_size_node,\n-                                 const string& seed_generator_node) {\n+                                 const std::string& buffer_size_node,\n+                                 const std::string& seed_generator_node) {\n   NodeDef* add_after = graph->GetNode(add_before.input(0));\n   NodeDef new_node;\n   new_node.set_op(kShuffleDatasetV2OpName);\n@@ -323,10 +323,10 @@ absl::Status AddShuffleDatasetV2(MutableGraphView* graph,\n \n absl::Status AddShuffleDatasetV3(MutableGraphView* graph,\n                                  const NodeDef& add_before,\n-                                 const string& buffer_size_node,\n-                                 const string& seed_node,\n-                                 const string& seed2_node,\n-                                 const string& seed_generator_node,\n+                                 const std::string& buffer_size_node,\n+                                 const std::string& seed_node,\n+                                 const std::string& seed2_node,\n+                                 const std::string& seed_generator_node,\n                                  bool reshuffle_each_iteration) {\n   NodeDef* add_after = graph->GetNode(add_before.input(0));\n   NodeDef new_node;\n@@ -373,11 +373,11 @@ bool ReaderOpInFunction(const NodeDef& node,\n   return false;\n }\n \n-absl::Status RemoveShuffleDataset(MutableGraphView* graph, const NodeDef& node,\n-                                  absl::flat_hash_set<string>* nodes_to_delete,\n-                                  string* op_name, string* buffer_size_node,\n-                                  string* seed_node, string* seed2_node,\n-                                  bool* reshuffle_each_iteration) {\n+absl::Status RemoveShuffleDataset(\n+    MutableGraphView* graph, const NodeDef& node,\n+    absl::flat_hash_set<std::string>* nodes_to_delete, std::string* op_name,\n+    std::string* buffer_size_node, std::string* seed_node,\n+    std::string* seed2_node, bool* reshuffle_each_iteration) {\n   if (node.op() == kShuffleDatasetOpName) {\n     *op_name = node.op();\n     *buffer_size_node = node.input(1);\n@@ -400,8 +400,8 @@ absl::Status RemoveShuffleDataset(MutableGraphView* graph, const NodeDef& node,\n \n absl::Status RemoveShuffleDatasetV2(\n     MutableGraphView* graph, const NodeDef& node,\n-    absl::flat_hash_set<string>* nodes_to_delete, string* op_name,\n-    string* buffer_size_node, string* seed_generator_node) {\n+    absl::flat_hash_set<std::string>* nodes_to_delete, std::string* op_name,\n+    std::string* buffer_size_node, std::string* seed_generator_node) {\n   if (node.op() == kShuffleDatasetV2OpName) {\n     *op_name = node.op();\n     *buffer_size_node = node.input(1);\n@@ -422,9 +422,10 @@ absl::Status RemoveShuffleDatasetV2(\n \n absl::Status RemoveShuffleDatasetV3(\n     MutableGraphView* graph, const NodeDef& node,\n-    absl::flat_hash_set<string>* nodes_to_delete, string* op_name,\n-    string* buffer_size_node, string* seed_node, string* seed2_node,\n-    string* seed_generator_node, bool* reshuffle_each_iteration) {\n+    absl::flat_hash_set<std::string>* nodes_to_delete, std::string* op_name,\n+    std::string* buffer_size_node, std::string* seed_node,\n+    std::string* seed2_node, std::string* seed_generator_node,\n+    bool* reshuffle_each_iteration) {\n   if (node.op() == kShuffleDatasetV3OpName) {\n     *op_name = node.op();\n     *buffer_size_node = node.input(1);\n@@ -448,13 +449,13 @@ absl::Status RemoveShuffleDatasetV3(\n \n absl::Status ProcessDatasetSourceNode(\n     MutableGraphView* graph, const NodeDef& node,\n-    absl::flat_hash_set<string>* nodes_to_delete, int64_t num_workers,\n+    absl::flat_hash_set<std::string>* nodes_to_delete, int64_t num_workers,\n     int64_t index) {\n-  string shuffle_op_name = \"\";\n-  string buffer_size_node = \"\";\n-  string seed_node = \"\";\n-  string seed2_node = \"\";\n-  string seed_generator_node = \"\";\n+  std::string shuffle_op_name = \"\";\n+  std::string buffer_size_node = \"\";\n+  std::string seed_node = \"\";\n+  std::string seed2_node = \"\";\n+  std::string seed_generator_node = \"\";\n   bool reshuffle_each_iteration;\n \n   TF_RETURN_IF_ERROR(AddShardNode(graph, node, num_workers, index));\n@@ -492,7 +493,7 @@ absl::Status ProcessDatasetSourceNode(\n const NodeDef* FindFuncAndTensorSliceDataset(\n     const NodeDef* node, int64_t num_workers, int64_t index,\n     FunctionLibraryDefinition* flib, MutableGraphView* graph,\n-    absl::flat_hash_set<string>* nodes_to_delete) {\n+    absl::flat_hash_set<std::string>* nodes_to_delete) {\n   if (IsDatasetNodeOfType(*node, kFuncDatasetOps)) {\n     const NodeDef* input_node = graph_utils::GetInputNode(*node, *graph, 0);\n     if (input_node->op() == kTensorSliceDatasetOpName ||\n@@ -550,10 +551,10 @@ DropRemainderValue GetDropRemainder(const MutableGraphView& graph,\n                               : DropRemainderValue::kFalse;\n }\n \n-absl::Status RecursivelyHandleOp(const NodeDef& node, int64_t num_workers,\n-                                 int64_t index, FunctionLibraryDefinition* flib,\n-                                 MutableGraphView* graph,\n-                                 absl::flat_hash_set<string>* nodes_to_delete) {\n+absl::Status RecursivelyHandleOp(\n+    const NodeDef& node, int64_t num_workers, int64_t index,\n+    FunctionLibraryDefinition* flib, MutableGraphView* graph,\n+    absl::flat_hash_set<std::string>* nodes_to_delete) {\n   if (node.op() == kAssertCardinalityDatasetOpName) {\n     LOG(WARNING) << \"The `assert_cardinality` transformation is currently not \"\n                     \"handled by the auto-shard rewrite and will be removed.\";\n@@ -664,7 +665,7 @@ absl::Status RecursivelyHandleOp(const NodeDef& node, int64_t num_workers,\n absl::Status ShardByFile(const NodeDef& sink_node, int64_t num_workers,\n                          int64_t index, FunctionLibraryDefinition* flib,\n                          MutableGraphView* graph) {\n-  absl::flat_hash_set<string> nodes_to_delete;\n+  absl::flat_hash_set<std::string> nodes_to_delete;\n   TF_RETURN_IF_ERROR(RecursivelyHandleOp(sink_node, num_workers, index, flib,\n                                          graph, &nodes_to_delete));\n   return graph->DeleteNodes(nodes_to_delete);\n@@ -818,7 +819,7 @@ absl::Status OptimizeGraph(const GrapplerItem& item, int64_t num_workers,\n \n   // id for telemetry purpose. item.id is always the same so we use the address\n   // of the output as id.\n-  string id = absl::StrCat(reinterpret_cast<uint64>(output));\n+  std::string id = absl::StrCat(reinterpret_cast<uint64_t>(output));\n   // Only record metrics on the first shard to avoid duplication.\n   if (index == 0) {\n     std::vector<std::string> ineligible_reason;"
        },
        {
            "sha": "c1901ebb251abfae6d39c89d724dfd2a73b01296",
            "filename": "tensorflow/core/grappler/optimizers/data/auto_shard.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fauto_shard.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fauto_shard.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fauto_shard.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -32,7 +32,7 @@ class AutoShard : public TFDataOptimizerBase {\n   AutoShard() = default;\n   ~AutoShard() override = default;\n \n-  string name() const override { return \"tf_auto_shard\"; }\n+  std::string name() const override { return \"tf_auto_shard\"; }\n \n   bool UsesFunctionLibrary() const override { return true; }\n "
        },
        {
            "sha": "60ef5aece2ce7dab3657d7e10f2f9c29e31f4300",
            "filename": "tensorflow/core/grappler/optimizers/data/auto_shard_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fauto_shard_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fauto_shard_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fauto_shard_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -44,7 +44,7 @@ using ::testing::UnorderedElementsAre;\n \n // Adds a MapDataset, a RebatchDataset, a PrefetchDataset and a fake sink that\n // are common to all graphs; and sets the fetch node to the fake sink.\n-void FinishItem(GrapplerItem* item, const string& input_node_name) {\n+void FinishItem(GrapplerItem* item, const std::string& input_node_name) {\n   *item->graph.add_node() =\n       NDef(\"map_before_rebatch\", \"MapDataset\", {input_node_name},\n            {{\"f\", \"__inference_Dataset_map_normalize_8232\"},"
        },
        {
            "sha": "de186866b83957e5bdecbec3e21c656944ea365b",
            "filename": "tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fautotune_buffer_sizes.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fautotune_buffer_sizes.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fautotune_buffer_sizes.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -63,7 +63,7 @@ absl::Status AutotuneBufferSizes::OptimizeAndCollectStats(\n   NodeDef* autotune_value =\n       graph_utils::AddScalarConstNode(data::model::kAutotune, &graph);\n \n-  absl::flat_hash_set<string> already_prefetched;\n+  absl::flat_hash_set<std::string> already_prefetched;\n \n   // 1) Collect about all existing `PrefetchDataset` nodes, replacing\n   // `prefetch(N)` with `prefetch(AUTOTUNE, buffer_size_min=N)` for all N !=-1."
        },
        {
            "sha": "3174a3ee853abd0d69bc48473f4d1bde458154d1",
            "filename": "tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fautotune_buffer_sizes.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fautotune_buffer_sizes.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fautotune_buffer_sizes.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -39,15 +39,15 @@ class AutotuneBufferSizes : public TFDataOptimizerBase {\n   AutotuneBufferSizes() = default;\n   ~AutotuneBufferSizes() override = default;\n \n-  string name() const override { return \"autotune_buffer_sizes\"; };\n+  std::string name() const override { return \"autotune_buffer_sizes\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n \n   absl::Status Init(\n       const tensorflow::RewriterConfig_CustomGraphOptimizer* config) override {\n     if (!config) return absl::OkStatus();\n \n-    const string& autotune = config->parameter_map().at(kAutotune).s();\n+    const std::string& autotune = config->parameter_map().at(kAutotune).s();\n     if (autotune == \"true\") {\n       autotune_ = true;\n     } else if (autotune == \"false\") {"
        },
        {
            "sha": "de9d5d93ad14342e0a9a981933bfdcc554b01267",
            "filename": "tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes_test.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fautotune_buffer_sizes_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fautotune_buffer_sizes_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fautotune_buffer_sizes_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -41,10 +41,10 @@ absl::Status OptimizeWithAutotuneBufferSizes(const GrapplerItem &item,\n   return optimizer.Optimize(nullptr, item, output);\n }\n \n-class SimpleInject : public ::testing::TestWithParam<string> {};\n+class SimpleInject : public ::testing::TestWithParam<std::string> {};\n \n TEST_P(SimpleInject, AutotuneBufferSizesTest) {\n-  const string async_dataset = GetParam();\n+  const std::string async_dataset = GetParam();\n   using test::function::NDef;\n   GrapplerItem item;\n   if (async_dataset == \"map\") {\n@@ -162,20 +162,20 @@ TEST_P(MultipleNodes, AutotuneBufferSizesTest) {\n   NodeDef *stop_val = graph_utils::AddScalarConstNode<int64_t>(10, &graph);\n   NodeDef *step_val = graph_utils::AddScalarConstNode<int64_t>(1, &graph);\n \n-  std::vector<string> range_inputs(3);\n+  std::vector<std::string> range_inputs(3);\n   range_inputs[0] = start_val->name();\n   range_inputs[1] = stop_val->name();\n   range_inputs[2] = step_val->name();\n-  std::vector<std::pair<string, AttrValue>> range_attrs;\n+  std::vector<std::pair<std::string, AttrValue>> range_attrs;\n   NodeDef *range_node = graph_utils::AddNode(\"range\", \"RangeDataset\",\n                                              range_inputs, range_attrs, &graph);\n \n   NodeDef *parallelism_val =\n       graph_utils::AddScalarConstNode<int64_t>(1, &graph);\n-  std::vector<string> map_inputs1(2);\n+  std::vector<std::string> map_inputs1(2);\n   map_inputs1[0] = range_node->name();\n   map_inputs1[1] = parallelism_val->name();\n-  std::vector<std::pair<string, AttrValue>> map_attrs(4);\n+  std::vector<std::pair<std::string, AttrValue>> map_attrs(4);\n   AttrValue attr_val;\n   SetAttrValue(\"value\", &attr_val);\n   map_attrs[0] = std::make_pair(\"f\", attr_val);\n@@ -187,10 +187,10 @@ TEST_P(MultipleNodes, AutotuneBufferSizesTest) {\n \n   NodeDef *buffer_size_val =\n       graph_utils::AddScalarConstNode<int64_t>(initial_buffer_size, &graph);\n-  std::vector<string> prefetch_inputs(2);\n+  std::vector<std::string> prefetch_inputs(2);\n   prefetch_inputs[0] = map_node1->name();\n   prefetch_inputs[1] = buffer_size_val->name();\n-  std::vector<std::pair<string, AttrValue>> prefetch_attrs(4);\n+  std::vector<std::pair<std::string, AttrValue>> prefetch_attrs(4);\n   AttrValue legacy_autotune_attr;\n   SetAttrValue(legacy_autotune, &legacy_autotune_attr);\n   AttrValue buffer_size_min_attr;\n@@ -202,13 +202,13 @@ TEST_P(MultipleNodes, AutotuneBufferSizesTest) {\n   NodeDef *prefetch_node = graph_utils::AddNode(\n       \"prefetch\", \"PrefetchDataset\", prefetch_inputs, prefetch_attrs, &graph);\n \n-  std::vector<string> map_inputs2(2);\n+  std::vector<std::string> map_inputs2(2);\n   map_inputs2[0] = prefetch_node->name();\n   map_inputs2[1] = parallelism_val->name();\n   NodeDef *map_node2 = graph_utils::AddNode(\"map2\", \"ParallelMapDatasetV2\",\n                                             map_inputs2, map_attrs, &graph);\n \n-  std::vector<string> map_inputs3(1);\n+  std::vector<std::string> map_inputs3(1);\n   map_inputs3[0] = map_node2->name();\n   graph_utils::AddNode(\"map3\", \"MapDataset\", map_inputs3, map_attrs, &graph);\n "
        },
        {
            "sha": "4d20fdb698d1373aff6a188b094c35c349a442a4",
            "filename": "tensorflow/core/grappler/optimizers/data/batch_parallelization.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fbatch_parallelization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fbatch_parallelization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fbatch_parallelization.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -34,7 +34,7 @@ namespace {\n constexpr char kBatchDataset[] = \"BatchDatasetV2\";\n constexpr char kParallelBatchDataset[] = \"ParallelBatchDataset\";\n \n-NodeDef MakeParallelBatch(const string& name, MutableGraphView* graph) {\n+NodeDef MakeParallelBatch(const std::string& name, MutableGraphView* graph) {\n   // The inputs of the node to be parallelized could be changed by the\n   // optimization pass, so we need to look it up in the modified graph.\n   int index = graph_utils::FindGraphNodeWithName(name, *graph->graph());\n@@ -46,7 +46,7 @@ NodeDef MakeParallelBatch(const string& name, MutableGraphView* graph) {\n   parallel_batch.set_op(kParallelBatchDataset);\n   auto* num_parallel_calls =\n       graph_utils::AddScalarConstNode(data::model::kAutotune, graph);\n-  string drop_remainder_name = parallel_batch.input(2);\n+  std::string drop_remainder_name = parallel_batch.input(2);\n   parallel_batch.set_input(2, num_parallel_calls->name());\n   parallel_batch.add_input(drop_remainder_name);\n \n@@ -72,7 +72,7 @@ absl::Status BatchParallelization::OptimizeAndCollectStats(\n   if (graph_utils::IsItemDerivedFromFunctionDef(item, graph))\n     return absl::OkStatus();\n \n-  absl::flat_hash_set<string> nodes_to_delete;\n+  absl::flat_hash_set<std::string> nodes_to_delete;\n   FunctionLibraryDefinition function_library(OpRegistry::Global(),\n                                              item.graph.library());\n   auto get_batch_node = [](const NodeDef& node) -> const NodeDef* {"
        },
        {
            "sha": "8d2f6895c322e2520c7eba1fc359b5847cb9c044",
            "filename": "tensorflow/core/grappler/optimizers/data/batch_parallelization.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fbatch_parallelization.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fbatch_parallelization.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fbatch_parallelization.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -30,15 +30,15 @@ class BatchParallelization : public TFDataOptimizerBase {\n   BatchParallelization() = default;\n   ~BatchParallelization() override = default;\n \n-  string name() const override { return \"batch_parallelization\"; };\n+  std::string name() const override { return \"batch_parallelization\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n \n   absl::Status Init(\n       const tensorflow::RewriterConfig_CustomGraphOptimizer* config) override {\n     if (!config) return absl::OkStatus();\n \n-    const string& autotune = config->parameter_map().at(kAutotune).s();\n+    const std::string& autotune = config->parameter_map().at(kAutotune).s();\n     if (autotune == \"true\") {\n       autotune_ = true;\n     } else if (autotune == \"false\") {"
        },
        {
            "sha": "426400737db8aa974db36cb6a396e83d580e8e08",
            "filename": "tensorflow/core/grappler/optimizers/data/batch_parallelization_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fbatch_parallelization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fbatch_parallelization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fbatch_parallelization_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -75,10 +75,10 @@ TEST_P(AutotuneSetting, BatchParallelizationTest) {\n \n INSTANTIATE_TEST_SUITE_P(Test, AutotuneSetting, ::testing::Values(false, true));\n \n-class FromFunctionDef : public ::testing::TestWithParam<string> {};\n+class FromFunctionDef : public ::testing::TestWithParam<std::string> {};\n \n TEST_P(FromFunctionDef, BatchParallelizationTest) {\n-  const string op = GetParam();\n+  const std::string op = GetParam();\n   bool from_function_def = (op == \"_Retval\");\n \n   using test::function::NDef;"
        },
        {
            "sha": "b48d799f03c6c3085bd5086f646cc1f5704bc17b",
            "filename": "tensorflow/core/grappler/optimizers/data/disable_intra_op_parallelism.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fdisable_intra_op_parallelism.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fdisable_intra_op_parallelism.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fdisable_intra_op_parallelism.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -27,7 +27,7 @@ class DisableIntraOpParallelism : public TFDataOptimizerBase {\n   DisableIntraOpParallelism() = default;\n   ~DisableIntraOpParallelism() override = default;\n \n-  string name() const override { return \"disable_intra_op_parallelism\"; };\n+  std::string name() const override { return \"disable_intra_op_parallelism\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n "
        },
        {
            "sha": "3fbf47b9cc205d87374041b5eda1adfae88a9654",
            "filename": "tensorflow/core/grappler/optimizers/data/disable_intra_op_parallelism_test.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fdisable_intra_op_parallelism_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fdisable_intra_op_parallelism_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fdisable_intra_op_parallelism_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -32,10 +32,10 @@ using test::function::NDef;\n \n // If the user manually sets intra op parallelism, we don't insert the op.\n class IntraOpAlreadySetTest\n-    : public ::testing::TestWithParam<std::tuple<string, int64_t>> {};\n+    : public ::testing::TestWithParam<std::tuple<std::string, int64_t>> {};\n \n TEST_P(IntraOpAlreadySetTest, IntraOpParallelism) {\n-  const string op = std::get<0>(GetParam());\n+  const std::string op = std::get<0>(GetParam());\n   const int64_t value = std::get<1>(GetParam());\n \n   GrapplerItem item;\n@@ -44,26 +44,26 @@ TEST_P(IntraOpAlreadySetTest, IntraOpParallelism) {\n   NodeDef *start_val = graph_utils::AddScalarConstNode<int64_t>(0, &graph);\n   NodeDef *stop_val = graph_utils::AddScalarConstNode<int64_t>(10, &graph);\n   NodeDef *step_val = graph_utils::AddScalarConstNode<int64_t>(1, &graph);\n-  std::vector<string> range_inputs(3);\n+  std::vector<std::string> range_inputs(3);\n   range_inputs[0] = start_val->name();\n   range_inputs[1] = stop_val->name();\n   range_inputs[2] = step_val->name();\n-  std::vector<std::pair<string, AttrValue>> range_attrs;\n+  std::vector<std::pair<std::string, AttrValue>> range_attrs;\n   NodeDef *range_node = graph_utils::AddNode(\"range\", \"RangeDataset\",\n                                              range_inputs, range_attrs, &graph);\n \n   NodeDef *parallelism_val =\n       graph_utils::AddScalarConstNode<int64_t>(value, &graph);\n-  std::vector<string> parallelism_inputs(2);\n+  std::vector<std::string> parallelism_inputs(2);\n   parallelism_inputs[0] = range_node->name();\n   parallelism_inputs[1] = parallelism_val->name();\n-  std::vector<std::pair<string, AttrValue>> parallelism_attrs;\n+  std::vector<std::pair<std::string, AttrValue>> parallelism_attrs;\n   NodeDef *parallelism_node = graph_utils::AddNode(\n       \"max_parallelism\", op, parallelism_inputs, parallelism_attrs, &graph);\n \n-  std::vector<string> sink_inputs(1);\n+  std::vector<std::string> sink_inputs(1);\n   sink_inputs[0] = parallelism_node->name();\n-  std::vector<std::pair<string, AttrValue>> sink_attrs;\n+  std::vector<std::pair<std::string, AttrValue>> sink_attrs;\n   NodeDef *sink_node =\n       graph_utils::AddNode(\"Sink\", \"Identity\", sink_inputs, sink_attrs, &graph);\n   item.fetch.push_back(sink_node->name());\n@@ -97,10 +97,10 @@ INSTANTIATE_TEST_SUITE_P(\n // If we can not find the sink node or sink node op is \"_Retval\", we don't apply\n // the optimization; otherwise, we insert the op to disable intra op\n // parallelism.\n-class IntraOpNotSetTest : public ::testing::TestWithParam<string> {};\n+class IntraOpNotSetTest : public ::testing::TestWithParam<std::string> {};\n \n TEST_P(IntraOpNotSetTest, IntraOpParallelism) {\n-  const string op = GetParam();\n+  const std::string op = GetParam();\n   GrapplerItem item;\n \n   item.graph = test::function::GDef("
        },
        {
            "sha": "225a652c05265cdbcb250aef4fd0be0259c7086f",
            "filename": "tensorflow/core/grappler/optimizers/data/disable_prefetch_legacy_autotune.h",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fdisable_prefetch_legacy_autotune.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fdisable_prefetch_legacy_autotune.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fdisable_prefetch_legacy_autotune.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -30,15 +30,17 @@ class DisablePrefetchLegacyAutotune : public TFDataOptimizerBase {\n   DisablePrefetchLegacyAutotune() = default;\n   ~DisablePrefetchLegacyAutotune() override = default;\n \n-  string name() const override { return \"disable_prefetch_legacy_autotune\"; };\n+  std::string name() const override {\n+    return \"disable_prefetch_legacy_autotune\";\n+  };\n \n   bool UsesFunctionLibrary() const override { return false; }\n \n   absl::Status Init(\n       const tensorflow::RewriterConfig_CustomGraphOptimizer* config) override {\n     if (!config) return absl::OkStatus();\n \n-    const string& autotune = config->parameter_map().at(kAutotune).s();\n+    const std::string& autotune = config->parameter_map().at(kAutotune).s();\n     if (autotune == \"true\") {\n       autotune_ = true;\n     } else if (autotune == \"false\") {"
        },
        {
            "sha": "257d2893afb54751b7c0dd842e1cb35507e0261a",
            "filename": "tensorflow/core/grappler/optimizers/data/enable_gradient_descent.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fenable_gradient_descent.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fenable_gradient_descent.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fenable_gradient_descent.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -30,15 +30,15 @@ class EnableGradientDescent : public TFDataOptimizerBase {\n   EnableGradientDescent() = default;\n   ~EnableGradientDescent() override = default;\n \n-  string name() const override { return \"enable_gradient_descent\"; };\n+  std::string name() const override { return \"enable_gradient_descent\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n \n   absl::Status Init(\n       const tensorflow::RewriterConfig_CustomGraphOptimizer* config) override {\n     if (!config) return absl::OkStatus();\n \n-    const string& autotune = config->parameter_map().at(kAutotune).s();\n+    const std::string& autotune = config->parameter_map().at(kAutotune).s();\n     if (autotune == \"true\") {\n       autotune_ = true;\n     } else if (autotune == \"false\") {"
        },
        {
            "sha": "432cf04516a4d5a5b439e616a7de7d8e1638f603",
            "filename": "tensorflow/core/grappler/optimizers/data/enable_gradient_descent_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fenable_gradient_descent_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fenable_gradient_descent_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fenable_gradient_descent_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -43,12 +43,13 @@ absl::Status OptimizeWithEnableGradientDescent(const GrapplerItem &item,\n }\n \n class SimpleRewrite\n-    : public ::testing::TestWithParam<std::tuple<bool, int64_t, string>> {};\n+    : public ::testing::TestWithParam<std::tuple<bool, int64_t, std::string>> {\n+};\n \n TEST_P(SimpleRewrite, EnableGradientDescentTest) {\n   const bool autotune = std::get<0>(GetParam());\n   const int64_t algorithm_index = std::get<1>(GetParam());\n-  const string op = std::get<2>(GetParam());\n+  const std::string op = std::get<2>(GetParam());\n \n   using test::function::NDef;\n   GrapplerItem item;"
        },
        {
            "sha": "9a9a774223cd346d8d7832b2ebde9651a04907fa",
            "filename": "tensorflow/core/grappler/optimizers/data/filter_fusion.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_fusion.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -70,7 +70,7 @@ absl::Status FilterFusion::OptimizeAndCollectStats(Cluster* cluster,\n   *output = sorted_old_graph;\n \n   MutableGraphView graph(output);\n-  absl::flat_hash_set<string> nodes_to_delete;\n+  absl::flat_hash_set<std::string> nodes_to_delete;\n   FunctionLibraryDefinition function_library(OpRegistry::Global(),\n                                              output->library());\n "
        },
        {
            "sha": "59a1f3a3748709a1485c7f866c4fceb508a300e4",
            "filename": "tensorflow/core/grappler/optimizers/data/filter_fusion.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_fusion.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_fusion.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_fusion.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -27,7 +27,7 @@ class FilterFusion : public TFDataOptimizerBase {\n   FilterFusion() = default;\n   ~FilterFusion() override = default;\n \n-  string name() const override { return \"filter_fusion\"; };\n+  std::string name() const override { return \"filter_fusion\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n "
        },
        {
            "sha": "92a627bf4902496af8fd043c287b51dd9e2a09a8",
            "filename": "tensorflow/core/grappler/optimizers/data/filter_parallelization.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_parallelization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_parallelization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_parallelization.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -34,7 +34,7 @@ namespace {\n constexpr char kFilterDataset[] = \"FilterDataset\";\n constexpr char kParallelFilterDataset[] = \"ParallelFilterDataset\";\n \n-NodeDef MakeParallelFilter(const string& name, MutableGraphView* graph) {\n+NodeDef MakeParallelFilter(const std::string& name, MutableGraphView* graph) {\n   // The inputs of the node to be parallelized could be changed by the\n   // optimization pass, so we need to look it up in the modified graph.\n   int index = graph_utils::FindGraphNodeWithName(name, *graph->graph());\n@@ -71,7 +71,7 @@ absl::Status FilterParallelization::OptimizeAndCollectStats(\n   if (graph_utils::IsItemDerivedFromFunctionDef(item, graph))\n     return absl::OkStatus();\n \n-  absl::flat_hash_set<string> nodes_to_delete;\n+  absl::flat_hash_set<std::string> nodes_to_delete;\n   FunctionLibraryDefinition function_library(OpRegistry::Global(),\n                                              item.graph.library());\n   auto get_filter_node = [](const NodeDef& node) -> const NodeDef* {"
        },
        {
            "sha": "2d64ca051204ccc88d3eed648654deb5dac12e84",
            "filename": "tensorflow/core/grappler/optimizers/data/filter_parallelization.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_parallelization.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_parallelization.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_parallelization.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -30,15 +30,15 @@ class FilterParallelization : public TFDataOptimizerBase {\n   FilterParallelization() = default;\n   ~FilterParallelization() override = default;\n \n-  string name() const override { return \"filter_parallelization\"; };\n+  std::string name() const override { return \"filter_parallelization\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n \n   absl::Status Init(\n       const tensorflow::RewriterConfig_CustomGraphOptimizer* config) override {\n     if (!config) return absl::OkStatus();\n \n-    const string& autotune = config->parameter_map().at(kAutotune).s();\n+    const std::string& autotune = config->parameter_map().at(kAutotune).s();\n     if (autotune == \"true\") {\n       autotune_ = true;\n     } else if (autotune == \"false\") {"
        },
        {
            "sha": "7a10b7762acac9f938ab7e6c69105653b12d4d74",
            "filename": "tensorflow/core/grappler/optimizers/data/filter_parallelization_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_parallelization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_parallelization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffilter_parallelization_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -77,10 +77,10 @@ TEST_P(AutotuneSetting, FilterParallelizationTest) {\n \n INSTANTIATE_TEST_SUITE_P(Test, AutotuneSetting, ::testing::Values(false, true));\n \n-class FromFunctionDef : public ::testing::TestWithParam<string> {};\n+class FromFunctionDef : public ::testing::TestWithParam<std::string> {};\n \n TEST_P(FromFunctionDef, FilterParallelizationTest) {\n-  const string op = GetParam();\n+  const std::string op = GetParam();\n   bool from_function_def = (op == \"_Retval\");\n \n   using test::function::NDef;"
        },
        {
            "sha": "0d0c2eab1428f74c4cb66c66c46360af73a8a597",
            "filename": "tensorflow/core/grappler/optimizers/data/function_utils.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 17,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffunction_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffunction_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffunction_utils.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -24,13 +24,14 @@ namespace tensorflow {\n namespace grappler {\n namespace function_utils {\n \n-FunctionDefTensorDesc::FunctionDefTensorDesc(const string& node_name,\n-                                             const string& output, int position)\n+FunctionDefTensorDesc::FunctionDefTensorDesc(const std::string& node_name,\n+                                             const std::string& output,\n+                                             int position)\n     : node_name(node_name), node_output(output), position(position) {\n   full_str = strings::StrCat(node_name, \":\", node_output, \":\", position);\n }\n \n-FunctionDefTensorDesc::FunctionDefTensorDesc(const string& input) {\n+FunctionDefTensorDesc::FunctionDefTensorDesc(const std::string& input) {\n   // Parses node_name:node_output:position string into its components.\n   full_str = input;\n   absl::string_view capture;\n@@ -41,7 +42,7 @@ FunctionDefTensorDesc::FunctionDefTensorDesc(const string& input) {\n           .One(strings::Scanner::LETTER_DIGIT_DOT_UNDERSCORE)\n           .Any(strings::Scanner::LETTER_DIGIT_DASH_DOT_SLASH_UNDERSCORE)\n           .GetResult(&remaining, &capture)) {\n-    node_name = string(capture.data(), capture.size());\n+    node_name = std::string(capture.data(), capture.size());\n   }\n \n   // Parse \"node_output\" if it exists\n@@ -51,7 +52,7 @@ FunctionDefTensorDesc::FunctionDefTensorDesc(const string& input) {\n           .One(strings::Scanner::LETTER)\n           .Any(strings::Scanner::LETTER_DIGIT_UNDERSCORE)\n           .GetResult(&remaining, &capture)) {\n-    node_output = string(capture.data(), capture.size());\n+    node_output = std::string(capture.data(), capture.size());\n   }\n \n   // Parse \"position\" if it exists\n@@ -71,7 +72,7 @@ FunctionDefTensorDesc::FunctionDefTensorDesc(const string& input) {\n // Note that we're not using GrapplerFunctionItem because it doesn't cover\n // some of our desired uses (eg changing the outputs of a function), and the\n // FunctionDef -> GraphDef conversion isn't really necessary in this case.\n-void ReplaceReferences(const string& from, const string& to,\n+void ReplaceReferences(const std::string& from, const std::string& to,\n                        FunctionDef* func) {\n   for (NodeDef& n : *func->mutable_node_def()) {\n     std::replace(n.mutable_input()->begin(), n.mutable_input()->end(), from,\n@@ -88,7 +89,7 @@ void ReplaceReferences(const string& from, const string& to,\n void AddFunctionOutputWithUniqueName(absl::string_view prefix,\n                                      absl::string_view output_tensor_name,\n                                      FunctionDef* fdef, DataType dtype) {\n-  string name = string(prefix);\n+  std::string name = std::string(prefix);\n   int id = fdef->signature().output_arg_size();\n   while (ContainsFunctionOutputWithName(name, *fdef)) {\n     name = absl::StrCat(prefix, \"/_\", id);\n@@ -98,10 +99,10 @@ void AddFunctionOutputWithUniqueName(absl::string_view prefix,\n   output->set_name(name);\n   output->set_type(dtype);\n \n-  (*fdef->mutable_ret())[name] = string(output_tensor_name);\n+  (*fdef->mutable_ret())[name] = std::string(output_tensor_name);\n }\n \n-OpDef_ArgDef* AddFunctionInput(const string& name, FunctionDef* fdef,\n+OpDef_ArgDef* AddFunctionInput(const std::string& name, FunctionDef* fdef,\n                                DataType dtype) {\n   auto* input_arg = fdef->mutable_signature()->mutable_input_arg()->Add();\n   input_arg->set_type(dtype);\n@@ -110,18 +111,19 @@ OpDef_ArgDef* AddFunctionInput(const string& name, FunctionDef* fdef,\n   return input_arg;\n }\n \n-NodeDef* AddNode(absl::string_view name, absl::string_view op,\n-                 const std::vector<string>& inputs,\n-                 const std::vector<std::pair<string, AttrValue>>& attributes,\n-                 FunctionDef* fd) {\n+NodeDef* AddNode(\n+    absl::string_view name, absl::string_view op,\n+    const std::vector<std::string>& inputs,\n+    const std::vector<std::pair<std::string, AttrValue>>& attributes,\n+    FunctionDef* fd) {\n   NodeDef* node = fd->add_node_def();\n   if (!name.empty()) {\n-    node->set_name(string(name));\n+    node->set_name(name);\n   } else {\n     SetUniqueFunctionNodeName(op, fd, node);\n   }\n-  node->set_op(string(op));\n-  for (const string& input : inputs) {\n+  node->set_op(op);\n+  for (const std::string& input : inputs) {\n     node->add_input(input);\n   }\n   for (const auto& attr : attributes) {\n@@ -174,7 +176,7 @@ int FindFunctionNodeWithOp(absl::string_view op, const FunctionDef& function) {\n \n void SetUniqueFunctionNodeName(absl::string_view prefix, FunctionDef* function,\n                                NodeDef* node) {\n-  string name = string(prefix);\n+  std::string name = std::string(prefix);\n   int id = function->node_def_size();\n   while (ContainsFunctionNodeWithName(name, *function)) {\n     name = absl::StrCat(prefix, \"/_\", id);"
        },
        {
            "sha": "b4e58c4646690c85915edc2093d5309a8d39e3ae",
            "filename": "tensorflow/core/grappler/optimizers/data/function_utils.h",
            "status": "modified",
            "additions": 13,
            "deletions": 11,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffunction_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffunction_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffunction_utils.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -42,23 +42,24 @@ namespace function_utils {\n struct FunctionDefTensorDesc {\n   FunctionDefTensorDesc() = default;\n \n-  FunctionDefTensorDesc(const string& node_name, const string& output,\n+  FunctionDefTensorDesc(const std::string& node_name, const std::string& output,\n                         int position);\n \n   // Parses node_name:node_output:position string into its components.\n-  explicit FunctionDefTensorDesc(const string& input);\n+  explicit FunctionDefTensorDesc(const std::string& input);\n \n   // TODO(rachelim): Add provisions to deal with special formats, like how\n   // GrapplerFunctionItem expands node output range if position is not defined\n-  string full_str;\n-  string node_name;\n-  string node_output;\n+  std::string full_str;\n+  std::string node_name;\n+  std::string node_output;\n   int position = -1;\n };\n \n // Replaces all references to `from` tensor in func's nodes' inputs and retvals\n // to `to` tensor. This is similar to `MutableGraphView::ReplaceInputs`.\n-void ReplaceReferences(const string& from, const string& to, FunctionDef* func);\n+void ReplaceReferences(const std::string& from, const std::string& to,\n+                       FunctionDef* func);\n \n // Adds a function output to the function def, ensuring that the output key\n // is unique, and maps to output_tensor_name in the ret dict.\n@@ -67,14 +68,15 @@ void AddFunctionOutputWithUniqueName(absl::string_view prefix,\n                                      FunctionDef* fdef, DataType dtype);\n \n // Adds an input to a FunctionDef.\n-OpDef_ArgDef* AddFunctionInput(const string& name, FunctionDef* fdef,\n+OpDef_ArgDef* AddFunctionInput(const std::string& name, FunctionDef* fdef,\n                                DataType dtype);\n \n // Adds a node to a FunctionDef.\n-NodeDef* AddNode(absl::string_view name, absl::string_view op,\n-                 const std::vector<string>& inputs,\n-                 const std::vector<std::pair<string, AttrValue>>& attributes,\n-                 FunctionDef* fd);\n+NodeDef* AddNode(\n+    absl::string_view name, absl::string_view op,\n+    const std::vector<std::string>& inputs,\n+    const std::vector<std::pair<std::string, AttrValue>>& attributes,\n+    FunctionDef* fd);\n \n // Checks whether the function contains a node with the given name.\n bool ContainsFunctionNodeWithName(absl::string_view name,"
        },
        {
            "sha": "110f49c85921e8fb0f8e442405de73b8852b7e04",
            "filename": "tensorflow/core/grappler/optimizers/data/function_utils_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffunction_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffunction_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffunction_utils_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -145,7 +145,7 @@ TEST(FunctionUtilsTest, AddNodeToFunctionDef) {\n   EXPECT_EQ(node1.input_size(), 0);\n   EXPECT_EQ(node1.attr_size(), 0);\n \n-  const std::vector<string> inputs({\"input1\", \"input2\"});\n+  const std::vector<std::string> inputs({\"input1\", \"input2\"});\n   AddNode(\"\", op_name, inputs, {}, &func);\n   const NodeDef& node2 =\n       func.node_def(FindFunctionNodeWithName(\"xxx/_2\", func));\n@@ -159,7 +159,7 @@ TEST(FunctionUtilsTest, AddNodeToFunctionDef) {\n   AttrValue a1, a2;\n   a1.set_type(DT_INT32);\n   a2.set_type(DT_INT64);\n-  const std::vector<std::pair<string, AttrValue>> attrs(\n+  const std::vector<std::pair<std::string, AttrValue>> attrs(\n       {{\"attr1\", a1}, {\"attr2\", a2}});\n   AddNode(\"\", op_name, {}, attrs, &func);\n   const NodeDef& node3 ="
        },
        {
            "sha": "17f0e72afa4634b745dad59cc71de9111e6b486d",
            "filename": "tensorflow/core/grappler/optimizers/data/fusion_utils.cc",
            "status": "modified",
            "additions": 59,
            "deletions": 57,
            "changes": 116,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffusion_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffusion_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffusion_utils.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -52,36 +52,36 @@ namespace {\n // See the comment for the proto field `tensorflow.NodeDef.input`.\n constexpr char kControlInputPrefix[] = \"^\";\n \n-bool IsControlInput(const string& node_input) {\n+bool IsControlInput(const std::string& node_input) {\n   return absl::StartsWith(node_input, kControlInputPrefix);\n }\n \n-string StripControlInputNotation(const string& node_input) {\n-  return string(absl::StripPrefix(node_input, kControlInputPrefix));\n+std::string StripControlInputNotation(const std::string& node_input) {\n+  return std::string(absl::StripPrefix(node_input, kControlInputPrefix));\n }\n \n-string AddControlInputNotation(const string& node_input) {\n+std::string AddControlInputNotation(const std::string& node_input) {\n   return absl::StrCat(kControlInputPrefix, node_input);\n }\n \n // Returns e.g. `\"node\"` given `\"node:out\"` or `\"node:out:0\"`. See the comment\n // for the proto field `tensorflow.FunctionDef.node_def`.\n-string ParseNodeConnection(const string& name) {\n+std::string ParseNodeConnection(const std::string& name) {\n   return name.substr(0, name.find(':'));\n }\n \n-string ParseOutputNode(const string& name) {\n-  if (name.find(':') == string::npos) return {};\n-  return name.substr(name.find(':'), string::npos);\n+std::string ParseOutputNode(const std::string& name) {\n+  if (name.find(':') == std::string::npos) return {};\n+  return name.substr(name.find(':'), std::string::npos);\n }\n \n-string GetOutputNode(const FunctionDef& function, int output_idx) {\n+std::string GetOutputNode(const FunctionDef& function, int output_idx) {\n   const auto& ret_output_name =\n       function.signature().output_arg(output_idx).name();\n   return function.ret().at(ret_output_name);\n }\n \n-string& GetMutableOutputNode(FunctionDef* function, int output_idx) {\n+std::string& GetMutableOutputNode(FunctionDef* function, int output_idx) {\n   const auto& ret_output_name =\n       function->signature().output_arg(output_idx).name();\n   return function->mutable_ret()->at(ret_output_name);\n@@ -96,10 +96,10 @@ StringCollection GetNames(const Iterable& iterable, int allocate_size) {\n }\n \n template <typename Iterable>\n-gtl::FlatSet<string> GetNodeNamesSet(const Iterable& nodes) {\n+gtl::FlatSet<std::string> GetNodeNamesSet(const Iterable& nodes) {\n   // NOTE(prazek): Cases where the set is not modified after construction\n   // could use sorted vector with binary_search instead, to make it faster.\n-  gtl::FlatSet<string> names;\n+  gtl::FlatSet<std::string> names;\n   for (const auto& node : nodes) {\n     CHECK(gtl::InsertIfNotPresent(&names, node.name()))\n         << \"Functions should have unique node names. Node with name \"\n@@ -109,16 +109,16 @@ gtl::FlatSet<string> GetNodeNamesSet(const Iterable& nodes) {\n }\n \n template <typename Iterable>\n-gtl::FlatMap<string, string> GetUniqueNames(const Iterable& first_iterable,\n-                                            const Iterable& second_iterable) {\n-  gtl::FlatMap<string, string> changed_node_names;\n+gtl::FlatMap<std::string, std::string> GetUniqueNames(\n+    const Iterable& first_iterable, const Iterable& second_iterable) {\n+  gtl::FlatMap<std::string, std::string> changed_node_names;\n   const auto first_names = GetNodeNamesSet(first_iterable);\n   auto second_names = GetNodeNamesSet(first_iterable);\n   int id = second_iterable.size();\n \n   for (const auto& node : second_iterable) {\n-    string name_before = node.name();\n-    string name = name_before;\n+    std::string name_before = node.name();\n+    std::string name = name_before;\n     bool changed_name = false;\n \n     while (first_names.count(name) ||\n@@ -143,14 +143,14 @@ gtl::FlatMap<string, string> GetUniqueNames(const Iterable& first_iterable,\n void RenameFunctionNodes(\n     const FunctionDef& first_function,\n     protobuf::RepeatedPtrField<NodeDef>* nodes_to_fuse,\n-    protobuf::Map<string, string>* rets_to_fuse,\n-    protobuf::Map<string, string>* control_rets_to_fuse,\n-    protobuf::RepeatedPtrField<string>* control_outputs_to_fuse) {\n-  const gtl::FlatMap<string, string> changed_node_names =\n+    protobuf::Map<std::string, std::string>* rets_to_fuse,\n+    protobuf::Map<std::string, std::string>* control_rets_to_fuse,\n+    protobuf::RepeatedPtrField<std::string>* control_outputs_to_fuse) {\n+  const gtl::FlatMap<std::string, std::string> changed_node_names =\n       GetUniqueNames(first_function.node_def(), *nodes_to_fuse);\n \n-  auto updated_name = [&changed_node_names](const string& input) {\n-    string input_node = ParseNodeConnection(input);\n+  auto updated_name = [&changed_node_names](const std::string& input) {\n+    std::string input_node = ParseNodeConnection(input);\n     auto iter = changed_node_names.find(input_node);\n     if (iter != changed_node_names.end()) {\n       return iter->second + ParseOutputNode(input);\n@@ -159,12 +159,12 @@ void RenameFunctionNodes(\n   };\n \n   for (NodeDef& function_node : *nodes_to_fuse) {\n-    if (const string* new_name =\n+    if (const std::string* new_name =\n             gtl::FindOrNull(changed_node_names, function_node.name())) {\n       function_node.set_name(*new_name);\n     }\n \n-    for (string& input : *function_node.mutable_input()) {\n+    for (std::string& input : *function_node.mutable_input()) {\n       input = updated_name(input);\n     }\n   }\n@@ -179,10 +179,10 @@ void RenameFunctionNodes(\n   // `FunctionDef.signature.control_output` elements with these new values.\n   // The old keys and elements are ignored; these keys and elements serve only\n   // to look up one another.\n-  protobuf::Map<string, string> new_control_rets_to_fuse;\n-  protobuf::RepeatedPtrField<string> new_control_outputs_to_fuse;\n+  protobuf::Map<std::string, std::string> new_control_rets_to_fuse;\n+  protobuf::RepeatedPtrField<std::string> new_control_outputs_to_fuse;\n   for (const auto& [unused, control_ret_node] : *control_rets_to_fuse) {\n-    string updated_control_ret_node = updated_name(control_ret_node);\n+    std::string updated_control_ret_node = updated_name(control_ret_node);\n     new_control_rets_to_fuse.insert(\n         {updated_control_ret_node, updated_control_ret_node});\n     *new_control_outputs_to_fuse.Add() = updated_control_ret_node;\n@@ -199,38 +199,39 @@ StringCollection GetFunctionInputs(const FunctionDef& function) {\n // This function produces signature having names that do not conflict with\n // `first_signature`.  The input of returns and nodes that will be fused are\n // updated to use new names.\n-OpDef GetUniqueSignature(const OpDef& first_signature,\n-                         const OpDef& second_signature,\n-                         protobuf::Map<string, string>* rets_to_fuse,\n-                         protobuf::Map<string, string>* control_rets_to_fuse,\n-                         protobuf::RepeatedPtrField<NodeDef>* nodes_to_fuse) {\n-  const gtl::FlatMap<string, string> changed_input_names =\n+OpDef GetUniqueSignature(\n+    const OpDef& first_signature, const OpDef& second_signature,\n+    protobuf::Map<std::string, std::string>* rets_to_fuse,\n+    protobuf::Map<std::string, std::string>* control_rets_to_fuse,\n+    protobuf::RepeatedPtrField<NodeDef>* nodes_to_fuse) {\n+  const gtl::FlatMap<std::string, std::string> changed_input_names =\n       GetUniqueNames(first_signature.input_arg(), second_signature.input_arg());\n   OpDef signature;\n   signature.set_name(second_signature.name());\n \n   for (const auto& input_arg : second_signature.input_arg()) {\n     auto& input = *signature.add_input_arg();\n     input = input_arg;\n-    if (const string* new_name =\n+    if (const std::string* new_name =\n             gtl::FindOrNull(changed_input_names, input.name())) {\n       input.set_name(*new_name);\n     }\n   }\n-  const gtl::FlatMap<string, string> changed_output_names = GetUniqueNames(\n-      first_signature.output_arg(), second_signature.output_arg());\n+  const gtl::FlatMap<std::string, std::string> changed_output_names =\n+      GetUniqueNames(first_signature.output_arg(),\n+                     second_signature.output_arg());\n \n   for (const auto& output_arg : second_signature.output_arg()) {\n     auto& output = *signature.add_output_arg();\n     output = output_arg;\n-    if (const string* new_name =\n+    if (const std::string* new_name =\n             gtl::FindOrNull(changed_output_names, output.name())) {\n       output.set_name(*new_name);\n     }\n   }\n \n-  auto new_rets = [&](const protobuf::Map<string, string>& old_rets) {\n-    protobuf::Map<string, string> new_rets;\n+  auto new_rets = [&](const protobuf::Map<std::string, std::string>& old_rets) {\n+    protobuf::Map<std::string, std::string> new_rets;\n     for (const auto& ret : old_rets) {\n       const auto& key = changed_output_names.count(ret.first)\n                             ? changed_output_names.at(ret.first)\n@@ -253,7 +254,7 @@ OpDef GetUniqueSignature(const OpDef& first_signature,\n       bool is_control_input = IsControlInput(node_input);\n       const auto& input =\n           ParseNodeConnection(StripControlInputNotation(node_input));\n-      if (const string* new_name =\n+      if (const std::string* new_name =\n               gtl::FindOrNull(changed_input_names, input)) {\n         node_input = *new_name + ParseOutputNode(node_input);\n         if (is_control_input) {\n@@ -304,7 +305,7 @@ void FuseReturns(const StringCollection& first_inputs,\n                  const StringCollection& second_inputs,\n                  const StringCollection& first_outputs,\n                  const SetInputFn& set_input,\n-                 protobuf::Map<string, string>* fused_ret) {\n+                 protobuf::Map<std::string, std::string>* fused_ret) {\n   for (auto& ret : *fused_ret) {\n     auto return_input = ParseNodeConnection(ret.second);\n     auto input_it =\n@@ -381,9 +382,9 @@ bool CanCompose(const OpDef& first_signature, const OpDef& second_signature) {\n   return first_signature.output_arg_size() == second_signature.input_arg_size();\n }\n \n-string ComposeInput(const StringCollection& first_inputs,\n-                    const StringCollection& second_inputs,\n-                    const StringCollection& first_outputs, int arg_num) {\n+std::string ComposeInput(const StringCollection& first_inputs,\n+                         const StringCollection& second_inputs,\n+                         const StringCollection& first_outputs, int arg_num) {\n   // Take corresponding parent output.\n   return first_outputs.at(arg_num);\n }\n@@ -412,9 +413,9 @@ void ComposeSignature(const OpDef& first_signature,\n       second_signature.control_output().end());\n }\n \n-void ComposeOutput(const protobuf::Map<string, string>& first_ret,\n-                   const protobuf::Map<string, string>& second_ret,\n-                   protobuf::Map<string, string>* fused_ret) {\n+void ComposeOutput(const protobuf::Map<std::string, std::string>& first_ret,\n+                   const protobuf::Map<std::string, std::string>& second_ret,\n+                   protobuf::Map<std::string, std::string>* fused_ret) {\n   *fused_ret = second_ret;\n }\n \n@@ -429,16 +430,16 @@ void CombineSignature(const OpDef& first_signature,\n       second_signature.output_arg());\n }\n \n-void CombineOutput(const protobuf::Map<string, string>& first_ret,\n-                   const protobuf::Map<string, string>& second_ret,\n-                   protobuf::Map<string, string>* fused_ret) {\n+void CombineOutput(const protobuf::Map<std::string, std::string>& first_ret,\n+                   const protobuf::Map<std::string, std::string>& second_ret,\n+                   protobuf::Map<std::string, std::string>* fused_ret) {\n   *fused_ret = first_ret;\n   fused_ret->insert(second_ret.begin(), second_ret.end());\n }\n \n-string SameInput(const StringCollection& first_inputs,\n-                 const StringCollection& second_inputs,\n-                 const StringCollection& first_outputs, int arg_num) {\n+std::string SameInput(const StringCollection& first_inputs,\n+                      const StringCollection& second_inputs,\n+                      const StringCollection& first_outputs, int arg_num) {\n   return first_inputs.at(arg_num);\n }\n \n@@ -498,9 +499,10 @@ void LazyConjunctionNodes(const FunctionDef& first_function,\n   GetMutableOutputNode(fused_function, 0) = if_node->name() + \":output:0\";\n }\n \n-void LazyConjunctionOutput(const protobuf::Map<string, string>& first_ret,\n-                           const protobuf::Map<string, string>& second_ret,\n-                           protobuf::Map<string, string>* fused_ret) {\n+void LazyConjunctionOutput(\n+    const protobuf::Map<std::string, std::string>& first_ret,\n+    const protobuf::Map<std::string, std::string>& second_ret,\n+    protobuf::Map<std::string, std::string>* fused_ret) {\n   CHECK_EQ(first_ret.size(), 1);\n   CHECK_EQ(second_ret.size(), 1);\n   // Temporarily copy returns from first_ret.  We are going to change the"
        },
        {
            "sha": "3f86bfc63c4a38fcbacc83cc95375445f21edc0f",
            "filename": "tensorflow/core/grappler/optimizers/data/fusion_utils.h",
            "status": "modified",
            "additions": 25,
            "deletions": 24,
            "changes": 49,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffusion_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffusion_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffusion_utils.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -34,7 +34,7 @@ using SetFunctionSignatureFn = std::function<void(\n     const OpDef& first_function_signature,\n     const OpDef& second_function_signature, OpDef* fused_function_signature)>;\n \n-using StringCollection = absl::InlinedVector<string, 2UL>;\n+using StringCollection = absl::InlinedVector<std::string, 2UL>;\n \n // These functions are invoked with nodes from second function that were\n // previously taking arguments as input. The `arg_num` tells which\n@@ -43,17 +43,17 @@ using StringCollection = absl::InlinedVector<string, 2UL>;\n // would be called on the first and third input with arg_num equal 1 and 4.\n // It should set up inputs based on first function inputs or outputs or\n // second function inputs.\n-using SetInputFn =\n-    std::function<string(const StringCollection& first_function_inputs,\n-                         const StringCollection& second_function_inputs,\n-                         const StringCollection& parent_outputs, int arg_num)>;\n+using SetInputFn = std::function<std::string(\n+    const StringCollection& first_function_inputs,\n+    const StringCollection& second_function_inputs,\n+    const StringCollection& parent_outputs, int arg_num)>;\n \n // This function is invoked with first and second function ret. It is used to\n // set up returns of fused function.\n-using SetOutputFn =\n-    std::function<void(const protobuf::Map<string, string>& parent_ret,\n-                       const protobuf::Map<string, string>& second_function_ret,\n-                       protobuf::Map<string, string>* fused_ret)>;\n+using SetOutputFn = std::function<void(\n+    const protobuf::Map<std::string, std::string>& parent_ret,\n+    const protobuf::Map<std::string, std::string>& second_function_ret,\n+    protobuf::Map<std::string, std::string>* fused_ret)>;\n \n using SetNodesFn = std::function<void(\n     const FunctionDef& first_function, const FunctionDef& second_function,\n@@ -69,15 +69,15 @@ bool CanCompose(const OpDef& first_signature, const OpDef& second_signature);\n void ComposeSignature(const OpDef& first_signature,\n                       const OpDef& second_signature, OpDef* fused_signature);\n \n-string ComposeInput(const StringCollection& first_inputs,\n-                    const StringCollection& second_inputs,\n-                    const StringCollection& first_outputs, int arg_num);\n+std::string ComposeInput(const StringCollection& first_inputs,\n+                         const StringCollection& second_inputs,\n+                         const StringCollection& first_outputs, int arg_num);\n \n // Sets output to the composition of first and second function:\n // second_function(first_function(args...)).\n-void ComposeOutput(const protobuf::Map<string, string>& first_ret,\n-                   const protobuf::Map<string, string>& second_ret,\n-                   protobuf::Map<string, string>* fused_ret);\n+void ComposeOutput(const protobuf::Map<std::string, std::string>& first_ret,\n+                   const protobuf::Map<std::string, std::string>& second_ret,\n+                   protobuf::Map<std::string, std::string>* fused_ret);\n \n // Set input signature to `first_function_signature` and output signature\n // to `first_function_signature` + `second_function_signature`\n@@ -87,9 +87,9 @@ void CombineSignature(const OpDef& first_signature,\n // Apart from first function returns, return values from second function as\n // extra returns like:\n // return *first_function(...), *second_function(...)\n-void CombineOutput(const protobuf::Map<string, string>& first_ret,\n-                   const protobuf::Map<string, string>& second_ret,\n-                   protobuf::Map<string, string>* fused_ret);\n+void CombineOutput(const protobuf::Map<std::string, std::string>& first_ret,\n+                   const protobuf::Map<std::string, std::string>& second_ret,\n+                   protobuf::Map<std::string, std::string>* fused_ret);\n \n // Returns true if both signatures have the same number of input and output\n // args.\n@@ -101,15 +101,16 @@ void SameSignature(const OpDef& first_signature, const OpDef& second_signature,\n                    OpDef* fused_signature);\n \n // Take the same input as first function.\n-string SameInput(const StringCollection& first_inputs,\n-                 const StringCollection& second_inputs,\n-                 const StringCollection& first_outputs, int arg_num);\n+std::string SameInput(const StringCollection& first_inputs,\n+                      const StringCollection& second_inputs,\n+                      const StringCollection& first_outputs, int arg_num);\n \n // Create a fused function that computes the short-circuit logical AND of the\n // result of the first function and the result of the second function.\n-void LazyConjunctionOutput(const protobuf::Map<string, string>& first_ret,\n-                           const protobuf::Map<string, string>& second_ret,\n-                           protobuf::Map<string, string>* fused_ret);\n+void LazyConjunctionOutput(\n+    const protobuf::Map<std::string, std::string>& first_ret,\n+    const protobuf::Map<std::string, std::string>& second_ret,\n+    protobuf::Map<std::string, std::string>* fused_ret);\n \n void LazyConjunctionNodes(const FunctionDef& first_function,\n                           const FunctionDef& second_function,"
        },
        {
            "sha": "21df6afab30497095d86e8faebad3da9a970ff47",
            "filename": "tensorflow/core/grappler/optimizers/data/fusion_utils_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffusion_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffusion_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Ffusion_utils_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -35,22 +35,22 @@ namespace grappler {\n namespace fusion_utils {\n namespace {\n \n-string ParseNodeConnection(const string& name) {\n+std::string ParseNodeConnection(const std::string& name) {\n   return name.substr(0, name.find(':'));\n }\n \n void CheckUniqueNames(const FunctionDef& function) {\n-  std::unordered_set<string> inputs;\n+  std::unordered_set<std::string> inputs;\n   for (const auto& input_arg : function.signature().input_arg())\n     inputs.insert(input_arg.name());\n   EXPECT_EQ(inputs.size(), function.signature().input_arg_size());\n \n-  std::unordered_set<string> outputs;\n+  std::unordered_set<std::string> outputs;\n   for (const auto& output_arg : function.signature().output_arg())\n     outputs.insert(output_arg.name());\n   EXPECT_EQ(outputs.size(), function.signature().output_arg_size());\n \n-  std::unordered_set<string> nodes;\n+  std::unordered_set<std::string> nodes;\n   for (const auto& node : function.node_def()) nodes.insert(node.name());\n \n   EXPECT_EQ(nodes.size(), function.node_def_size());\n@@ -147,8 +147,8 @@ TEST(FusionUtilsTest, FuseFunctionWithControlOutputs) {\n                     fusion_utils::MergeNodes, graph.mutable_library());\n \n   EXPECT_EQ(fused_function->signature().control_output_size(), 2);\n-  string control_output_1 = fused_function->signature().control_output(0);\n-  string control_output_2 = fused_function->signature().control_output(1);\n+  std::string control_output_1 = fused_function->signature().control_output(0);\n+  std::string control_output_2 = fused_function->signature().control_output(1);\n   EXPECT_NE(control_output_1, control_output_2);\n   EXPECT_EQ(fused_function->control_ret_size(), 2);\n   EXPECT_TRUE(fused_function->control_ret().contains(control_output_1));"
        },
        {
            "sha": "3f54ccedf2ce2ac3fd4b564ec275bd77da3e7166",
            "filename": "tensorflow/core/grappler/optimizers/data/graph_test_utils.cc",
            "status": "modified",
            "additions": 50,
            "deletions": 44,
            "changes": 94,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_test_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_test_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_test_utils.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -32,8 +32,8 @@ NodeDef MakeBatchV2Node(absl::string_view name,\n                         bool parallel_copy) {\n   return test::function::NDef(\n       name, \"BatchDatasetV2\",\n-      {string(input_node_name), string(batch_size_node_name),\n-       string(drop_remainder_node_name)},\n+      {std::string(input_node_name), std::string(batch_size_node_name),\n+       std::string(drop_remainder_node_name)},\n       {{\"parallel_copy\", parallel_copy},\n        {\"output_shapes\", absl::Span<const TensorShape>{}},\n        {\"output_types\", absl::Span<const DataType>{}}});\n@@ -47,11 +47,12 @@ NodeDef MakeParallelBatchNode(absl::string_view name,\n                               absl::string_view deterministic) {\n   return test::function::NDef(\n       name, \"ParallelBatchDataset\",\n-      {string(input_node_name), string(batch_size_node_name),\n-       string(num_parallel_calls_node_name), string(drop_remainder_node_name)},\n+      {std::string(input_node_name), std::string(batch_size_node_name),\n+       std::string(num_parallel_calls_node_name),\n+       std::string(drop_remainder_node_name)},\n       {{\"output_shapes\", absl::Span<const TensorShape>{}},\n        {\"output_types\", absl::Span<const DataType>{}},\n-       {\"deterministic\", string(deterministic)}});\n+       {\"deterministic\", std::string(deterministic)}});\n }\n \n NodeDef MakeCacheV2Node(absl::string_view name,\n@@ -61,9 +62,9 @@ NodeDef MakeCacheV2Node(absl::string_view name,\n   return test::function::NDef(\n       name, \"CacheDatasetV2\",\n       {\n-          string(input_node_name),\n-          string(filename_node_name),\n-          string(cache_node_name),\n+          std::string(input_node_name),\n+          std::string(filename_node_name),\n+          std::string(cache_node_name),\n       },\n       {\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n@@ -75,8 +76,9 @@ NodeDef MakeFilterNode(absl::string_view name,\n                        absl::string_view input_node_name,\n                        absl::string_view function_name) {\n   return test::function::NDef(\n-      name, \"FilterDataset\", {string(input_node_name)},\n-      {{\"predicate\", FunctionDefHelper::FunctionRef(string(function_name))},\n+      name, \"FilterDataset\", {std::string(input_node_name)},\n+      {{\"predicate\",\n+        FunctionDefHelper::FunctionRef(std::string(function_name))},\n        {\"Targuments\", {}},\n        {\"output_shapes\", absl::Span<const TensorShape>{}},\n        {\"output_types\", absl::Span<const DataType>{}}});\n@@ -90,9 +92,10 @@ NodeDef MakeMapAndBatchNode(absl::string_view name,\n                             absl::string_view function_name) {\n   return test::function::NDef(\n       name, \"MapAndBatchDataset\",\n-      {string(input_node_name), string(batch_size_node_name),\n-       string(num_parallel_calls_node_name), string(drop_remainder_node_name)},\n-      {{\"f\", FunctionDefHelper::FunctionRef(string(function_name))},\n+      {std::string(input_node_name), std::string(batch_size_node_name),\n+       std::string(num_parallel_calls_node_name),\n+       std::string(drop_remainder_node_name)},\n+      {{\"f\", FunctionDefHelper::FunctionRef(std::string(function_name))},\n        {\"Targuments\", {}},\n        {\"output_shapes\", absl::Span<const TensorShape>{}},\n        {\"output_types\", absl::Span<const DataType>{}}});\n@@ -101,8 +104,8 @@ NodeDef MakeMapAndBatchNode(absl::string_view name,\n NodeDef MakeMapNode(absl::string_view name, absl::string_view input_node_name,\n                     absl::string_view function_name) {\n   return test::function::NDef(\n-      name, \"MapDataset\", {string(input_node_name)},\n-      {{\"f\", FunctionDefHelper::FunctionRef(string(function_name))},\n+      name, \"MapDataset\", {std::string(input_node_name)},\n+      {{\"f\", FunctionDefHelper::FunctionRef(std::string(function_name))},\n        {\"Targuments\", {}},\n        {\"output_shapes\", absl::Span<const TensorShape>{}},\n        {\"output_types\", absl::Span<const DataType>{}}});\n@@ -116,10 +119,11 @@ NodeDef MakeParallelInterleaveV2Node(\n     absl::string_view function_name, bool sloppy) {\n   return test::function::NDef(\n       name, \"ParallelInterleaveDatasetV2\",\n-      {string(input_node_name), string(cycle_length_node_name),\n-       string(block_length_node_name), string(num_parallel_calls_node_name)},\n+      {std::string(input_node_name), std::string(cycle_length_node_name),\n+       std::string(block_length_node_name),\n+       std::string(num_parallel_calls_node_name)},\n       {\n-          {\"f\", FunctionDefHelper::FunctionRef(string(function_name))},\n+          {\"f\", FunctionDefHelper::FunctionRef(std::string(function_name))},\n           {\"Targuments\", {}},\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n           {\"output_types\", absl::Span<const DataType>{}},\n@@ -135,14 +139,15 @@ NodeDef MakeParallelInterleaveV4Node(\n     absl::string_view function_name, absl::string_view deterministic) {\n   return test::function::NDef(\n       name, \"ParallelInterleaveDatasetV4\",\n-      {string(input_node_name), string(cycle_length_node_name),\n-       string(block_length_node_name), string(num_parallel_calls_node_name)},\n+      {std::string(input_node_name), std::string(cycle_length_node_name),\n+       std::string(block_length_node_name),\n+       std::string(num_parallel_calls_node_name)},\n       {\n-          {\"f\", FunctionDefHelper::FunctionRef(string(function_name))},\n+          {\"f\", FunctionDefHelper::FunctionRef(std::string(function_name))},\n           {\"Targuments\", {}},\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n           {\"output_types\", absl::Span<const DataType>{}},\n-          {\"deterministic\", string(deterministic)},\n+          {\"deterministic\", std::string(deterministic)},\n       });\n }\n \n@@ -154,14 +159,14 @@ NodeDef MakeInterleaveNode(absl::string_view name,\n                            absl::string_view deterministic) {\n   return test::function::NDef(\n       name, \"InterleaveDataset\",\n-      {string(input_node_name), string(cycle_length_node_name),\n-       string(block_length_node_name)},\n+      {std::string(input_node_name), std::string(cycle_length_node_name),\n+       std::string(block_length_node_name)},\n       {\n-          {\"f\", FunctionDefHelper::FunctionRef(string(function_name))},\n+          {\"f\", FunctionDefHelper::FunctionRef(std::string(function_name))},\n           {\"Targuments\", {}},\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n           {\"output_types\", absl::Span<const DataType>{}},\n-          {\"deterministic\", string(deterministic)},\n+          {\"deterministic\", std::string(deterministic)},\n       });\n }\n \n@@ -171,9 +176,9 @@ NodeDef MakeParallelMapNode(absl::string_view name,\n                             absl::string_view function_name, bool sloppy) {\n   return test::function::NDef(\n       name, \"ParallelMapDataset\",\n-      {string(input_node_name), string(num_parallel_calls_node_name)},\n+      {std::string(input_node_name), std::string(num_parallel_calls_node_name)},\n       {\n-          {\"f\", FunctionDefHelper::FunctionRef(string(function_name))},\n+          {\"f\", FunctionDefHelper::FunctionRef(std::string(function_name))},\n           {\"Targuments\", {}},\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n           {\"output_types\", absl::Span<const DataType>{}},\n@@ -189,13 +194,13 @@ NodeDef MakeParallelMapV2Node(absl::string_view name,\n                               bool use_unbounded_threadpool) {\n   return test::function::NDef(\n       name, \"ParallelMapDatasetV2\",\n-      {string(input_node_name), string(num_parallel_calls_node_name)},\n+      {std::string(input_node_name), std::string(num_parallel_calls_node_name)},\n       {\n-          {\"f\", FunctionDefHelper::FunctionRef(string(function_name))},\n+          {\"f\", FunctionDefHelper::FunctionRef(std::string(function_name))},\n           {\"Targuments\", {}},\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n           {\"output_types\", absl::Span<const DataType>{}},\n-          {\"deterministic\", string(deterministic)},\n+          {\"deterministic\", std::string(deterministic)},\n           {\"use_unbounded_threadpool\", use_unbounded_threadpool},\n       });\n }\n@@ -206,7 +211,7 @@ NodeDef MakeParseExampleNode(absl::string_view name,\n                              bool sloppy) {\n   return test::function::NDef(\n       name, \"ParseExampleDataset\",\n-      {string(input_node_name), string(num_parallel_calls_node_name)},\n+      {std::string(input_node_name), std::string(num_parallel_calls_node_name)},\n       {\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n           {\"output_types\", absl::Span<const DataType>{}},\n@@ -221,9 +226,9 @@ NodeDef MakeShuffleV2Node(absl::string_view name,\n   return test::function::NDef(\n       name, \"ShuffleDatasetV2\",\n       {\n-          string(input_node_name),\n-          string(buffer_size_node_name),\n-          string(seed_generator_node_name),\n+          std::string(input_node_name),\n+          std::string(buffer_size_node_name),\n+          std::string(seed_generator_node_name),\n       },\n       {\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n@@ -236,8 +241,8 @@ NodeDef MakeTakeNode(absl::string_view name, absl::string_view input_node_name,\n   return test::function::NDef(\n       name, \"TakeDataset\",\n       {\n-          string(input_node_name),\n-          string(count_node_name),\n+          std::string(input_node_name),\n+          std::string(count_node_name),\n       },\n       {\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n@@ -251,7 +256,7 @@ NodeDef MakeTensorSliceNode(absl::string_view name,\n   return test::function::NDef(\n       name, \"TensorSliceDataset\",\n       {\n-          string(tensor_node_name),\n+          std::string(tensor_node_name),\n       },\n       {\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n@@ -265,8 +270,8 @@ NodeDef MakeSkipNode(absl::string_view name, absl::string_view input_node_name,\n   return test::function::NDef(\n       name, \"SkipDataset\",\n       {\n-          string(input_node_name),\n-          string(count_node_name),\n+          std::string(input_node_name),\n+          std::string(count_node_name),\n       },\n       {\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n@@ -280,9 +285,9 @@ NodeDef MakeShardNode(absl::string_view name, absl::string_view input_node_name,\n   return test::function::NDef(\n       name, \"ShardDataset\",\n       {\n-          string(input_node_name),\n-          string(num_shards_node_name),\n-          string(index_node_name),\n+          std::string(input_node_name),\n+          std::string(num_shards_node_name),\n+          std::string(index_node_name),\n       },\n       {\n           {\"output_shapes\", absl::Span<const TensorShape>{}},\n@@ -294,7 +299,8 @@ NodeDef MakePrefetchNode(absl::string_view name,\n                          absl::string_view input_node_name,\n                          absl::string_view buffer_size) {\n   return test::function::NDef(\n-      name, \"PrefetchDataset\", {string(input_node_name), string(buffer_size)},\n+      name, \"PrefetchDataset\",\n+      {std::string(input_node_name), std::string(buffer_size)},\n       {{\"output_shapes\", absl::Span<const TensorShape>{}},\n        {\"output_types\", absl::Span<const DataType>{}},\n        {\"slack_period\", 0},"
        },
        {
            "sha": "760d55da080b3563985e3dc90c7fa721abccd734",
            "filename": "tensorflow/core/grappler/optimizers/data/graph_utils.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 27,
            "changes": 58,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_utils.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -60,7 +60,7 @@ std::vector<int> GetElementIndicesWithPredicate(const Predicate& predicate,\n }\n \n std::vector<int> CreateNameIndex(const GraphDef& graph) {\n-  std::map<string, int> names;\n+  std::map<std::string, int> names;\n   for (int i = 0; i < graph.node_size(); ++i) {\n     names[graph.node(i).name()] = i;\n   }\n@@ -73,7 +73,7 @@ std::vector<int> CreateNameIndex(const GraphDef& graph) {\n }\n \n std::vector<int> CreateInputIndex(const NodeDef& node) {\n-  std::map<string, int> inputs;\n+  std::map<std::string, int> inputs;\n   for (int i = 0; i < node.input_size(); ++i) {\n     inputs[node.input(i)] = i;\n   }\n@@ -117,18 +117,19 @@ NodeDef* AddScalarPlaceholder(DataType dtype, MutableGraphView* graph) {\n   return graph->AddNode(std::move(node));\n }\n \n-NodeDef* AddNode(absl::string_view name, absl::string_view op,\n-                 const std::vector<string>& inputs,\n-                 const std::vector<std::pair<string, AttrValue>>& attributes,\n-                 MutableGraphView* graph) {\n+NodeDef* AddNode(\n+    absl::string_view name, absl::string_view op,\n+    const std::vector<std::string>& inputs,\n+    const std::vector<std::pair<std::string, AttrValue>>& attributes,\n+    MutableGraphView* graph) {\n   NodeDef node;\n   if (!name.empty()) {\n-    node.set_name(string(name));\n+    node.set_name(name);\n   } else {\n     SetUniqueGraphNodeName(op, graph->graph(), &node);\n   }\n-  node.set_op(string(op));\n-  for (const string& input : inputs) {\n+  node.set_op(op);\n+  for (const std::string& input : inputs) {\n     node.add_input(input);\n   }\n   for (const auto& attr : attributes) {\n@@ -278,7 +279,7 @@ int FindGraphNodeWithOp(absl::string_view op, const GraphDef& graph) {\n       [&op](const NodeDef& node) { return node.op() == op; }, graph.node());\n }\n \n-std::vector<int> FindAllGraphNodesWithOp(const string& op,\n+std::vector<int> FindAllGraphNodesWithOp(const std::string& op,\n                                          const GraphDef& graph) {\n   return GetElementIndicesWithPredicate(\n       [&op](const NodeDef& node) { return node.op() == op; }, graph.node());\n@@ -300,7 +301,7 @@ NodeDef* GetInputNode(const NodeDef& node, const MutableGraphView& graph,\n absl::Status GetDatasetOutputTypesAttr(const NodeDef& node,\n                                        DataTypeVector* output_types) {\n   // We don't name the output_types attr consistently, so should check for both.\n-  for (const string& attr_name : {\"output_types\", \"Toutput_types\"}) {\n+  for (const std::string& attr_name : {\"output_types\", \"Toutput_types\"}) {\n     if (node.attr().contains(attr_name)) {\n       return GetNodeAttr(node, attr_name, output_types);\n     }\n@@ -311,10 +312,10 @@ absl::Status GetDatasetOutputTypesAttr(const NodeDef& node,\n \n void SetUniqueGraphNodeName(absl::string_view prefix, GraphDef* graph,\n                             NodeDef* node) {\n-  string name = string(prefix);\n+  std::string name = std::string(prefix);\n   int id = graph->node_size();\n   while (ContainsGraphNodeWithName(name, *graph)) {\n-    if (name.rfind(\"_generated\") != string::npos &&\n+    if (name.rfind(\"_generated\") != std::string::npos &&\n         (name.rfind(\"_generated\") == (name.size() - strlen(\"_generated\")))) {\n       name.insert(name.rfind(\"_generated\"), absl::StrCat(\"/_\", id));\n     } else {\n@@ -328,7 +329,7 @@ void SetUniqueGraphNodeName(absl::string_view prefix, GraphDef* graph,\n void SetUniqueGraphFunctionName(absl::string_view prefix,\n                                 const FunctionDefLibrary* library,\n                                 FunctionDef* function) {\n-  string name = string(prefix);\n+  std::string name = std::string(prefix);\n   int id = library->function_size();\n   while (ContainsGraphFunctionWithName(name, *library)) {\n     name = absl::StrCat(prefix, \"/_\", id);\n@@ -337,13 +338,14 @@ void SetUniqueGraphFunctionName(absl::string_view prefix,\n   function->mutable_signature()->set_name(std::move(name));\n }\n \n-void CopyAttribute(const string& attribute_name, const NodeDef& from,\n+void CopyAttribute(const std::string& attribute_name, const NodeDef& from,\n                    NodeDef* to_node) {\n   (*to_node->mutable_attr())[attribute_name] = from.attr().at(attribute_name);\n }\n \n-void ConcatAttributeList(const string& attribute_name, const NodeDef& first,\n-                         const NodeDef& second, NodeDef* to_node) {\n+void ConcatAttributeList(const std::string& attribute_name,\n+                         const NodeDef& first, const NodeDef& second,\n+                         NodeDef* to_node) {\n   CopyAttribute(attribute_name, first, to_node);\n   (*to_node->mutable_attr())\n       .at(attribute_name)\n@@ -353,12 +355,12 @@ void ConcatAttributeList(const string& attribute_name, const NodeDef& first,\n \n absl::Status EnsureNodeNamesUnique(Graph* g) {\n   // Modeled after Scope::Impl::GetUniqueName\n-  std::unordered_map<string, int> name_map;\n+  std::unordered_map<std::string, int> name_map;\n \n   for (auto node : g->op_nodes()) {\n-    const string& prefix = node->name();\n+    const std::string& prefix = node->name();\n     if (auto entry = gtl::FindOrNull(name_map, prefix)) {\n-      string unique_name;\n+      std::string unique_name;\n       do {\n         unique_name = absl::StrCat(prefix, \"_\", ++*entry);\n       } while (name_map.find(unique_name) != name_map.end());\n@@ -409,7 +411,7 @@ void MaybeSetFusedMetadata(const NodeDef& node1, const NodeDef& node2,\n     metadata2.ParseFromString(node2.attr().at(\"metadata\").s());\n   }\n   data::Metadata fused_metadata;\n-  auto normalize_name = [](const string& name) {\n+  auto normalize_name = [](const std::string& name) {\n     return name.empty() ? \"?\" : name;\n   };\n   *fused_metadata.mutable_name() =\n@@ -433,18 +435,18 @@ bool CopyShapesAndTypesAttrs(const NodeDef& from, NodeDef* to_node) {\n }\n \n namespace {\n-const auto* kSloppyAttrOps = new absl::flat_hash_set<string>{\n+const auto* kSloppyAttrOps = new absl::flat_hash_set<std::string>{\n     \"ParallelInterleaveDatasetV2\",\n     \"ParallelMapDataset\",\n     \"ParseExampleDataset\",\n };\n \n-const auto* kReplicateOnSplitAttrOps = new absl::flat_hash_set<string>{\n+const auto* kReplicateOnSplitAttrOps = new absl::flat_hash_set<std::string>{\n     \"TensorSliceDataset\",\n     \"RangeDataset\",\n };\n \n-const auto* kDeterministicAttrOps = new absl::flat_hash_set<string>{\n+const auto* kDeterministicAttrOps = new absl::flat_hash_set<std::string>{\n     \"LegacyParallelInterleaveDatasetV2\",\n     \"ParallelInterleaveDatasetV3\",\n     \"ParallelInterleaveDatasetV4\",\n@@ -453,13 +455,15 @@ const auto* kDeterministicAttrOps = new absl::flat_hash_set<string>{\n };\n }  // anonymous namespace\n \n-bool HasSloppyAttr(const string& op) { return kSloppyAttrOps->contains(op); }\n+bool HasSloppyAttr(const std::string& op) {\n+  return kSloppyAttrOps->contains(op);\n+}\n \n-bool HasReplicateOnSplitAttr(const string& op) {\n+bool HasReplicateOnSplitAttr(const std::string& op) {\n   return kReplicateOnSplitAttrOps->contains(op);\n }\n \n-bool HasDeterministicAttr(const string& op) {\n+bool HasDeterministicAttr(const std::string& op) {\n   return kDeterministicAttrOps->contains(op);\n }\n "
        },
        {
            "sha": "78cc5e2818254c08600c6f035ba2803aa752e97c",
            "filename": "tensorflow/core/grappler/optimizers/data/graph_utils.h",
            "status": "modified",
            "additions": 13,
            "deletions": 11,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_utils.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -49,10 +49,11 @@ int GetFirstElementIndexWithPredicate(const Predicate& predicate,\n }\n \n // Adds a node to the graph.\n-NodeDef* AddNode(absl::string_view name, absl::string_view op,\n-                 const std::vector<string>& inputs,\n-                 const std::vector<std::pair<string, AttrValue>>& attributes,\n-                 MutableGraphView* graph);\n+NodeDef* AddNode(\n+    absl::string_view name, absl::string_view op,\n+    const std::vector<std::string>& inputs,\n+    const std::vector<std::pair<std::string, AttrValue>>& attributes,\n+    MutableGraphView* graph);\n \n // Adds Placeholder node for given type.\n NodeDef* AddScalarPlaceholder(DataType dtype, MutableGraphView* graph);\n@@ -134,7 +135,7 @@ absl::Status GetDatasetOutputTypesAttr(const NodeDef& node,\n \n // Returns the list of indices of all nodes with the given op or empty list if\n // no such node exists.\n-std::vector<int> FindAllGraphNodesWithOp(const string& op,\n+std::vector<int> FindAllGraphNodesWithOp(const std::string& op,\n                                          const GraphDef& graph);\n \n // Sets the node name using `prefix` as a prefix while guaranteeing the name\n@@ -150,13 +151,14 @@ void SetUniqueGraphFunctionName(absl::string_view prefix,\n \n // Copies attribute having name `attribute_name` from node `from` to node\n // `to_node`.\n-void CopyAttribute(const string& attribute_name, const NodeDef& from,\n+void CopyAttribute(const std::string& attribute_name, const NodeDef& from,\n                    NodeDef* to_node);\n \n // Concatenates list attribute having name `attribute_name` from `first` and\n // `second` node, setting it to `to_node`.\n-void ConcatAttributeList(const string& attribute_name, const NodeDef& first,\n-                         const NodeDef& second, NodeDef* to_node);\n+void ConcatAttributeList(const std::string& attribute_name,\n+                         const NodeDef& first, const NodeDef& second,\n+                         NodeDef* to_node);\n \n // Checks that all nodes in the graphs have unique names, and sets their names\n // to be unique if they are not already.  This is necessary as Graph does not\n@@ -195,13 +197,13 @@ void MaybeSetFusedMetadata(const NodeDef& node1, const NodeDef& node2,\n bool CopyShapesAndTypesAttrs(const NodeDef& from, NodeDef* to_node);\n \n // Checks whether the op has a \"sloppy\" attribute.\n-bool HasSloppyAttr(const string& op);\n+bool HasSloppyAttr(const std::string& op);\n \n // Checks whether the op has a \"replicate_on_split\" attribute.\n-bool HasReplicateOnSplitAttr(const string& op);\n+bool HasReplicateOnSplitAttr(const std::string& op);\n \n // Checks whether the op has a \"deterministic\" attribute.\n-bool HasDeterministicAttr(const string& op);\n+bool HasDeterministicAttr(const std::string& op);\n \n // Sets the `name` as the metadata name of the `node`. It returns an error if\n // the `node` already has a metadata name."
        },
        {
            "sha": "b381f31ea92145b07088d4866500ca5139d0adcc",
            "filename": "tensorflow/core/grappler/optimizers/data/graph_utils_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fgraph_utils_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -314,7 +314,7 @@ TEST(GraphUtilsTest, EnsureNodeNamesUnique) {\n \n   // Arbitrary const\n   Tensor tensor(DT_INT32, {});\n-  tensor.scalar<int32>()() = 5;\n+  tensor.scalar<int32_t>()() = 5;\n \n   for (auto node : {&const_0, &const_1}) {\n     TF_EXPECT_OK(NodeBuilder(\"Const\", \"Const\")"
        },
        {
            "sha": "c603bcb7cf470ea441b3fde098ff9360b9a9f0fe",
            "filename": "tensorflow/core/grappler/optimizers/data/make_deterministic.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 10,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_deterministic.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_deterministic.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_deterministic.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -158,7 +158,7 @@ absl::flat_hash_map<absl::string_view, const NodeDef*> NameToNode(\n   return name_to_node;\n }\n \n-NodeDef* GetMutableNode(const string& node_name, MutableGraphView* graph) {\n+NodeDef* GetMutableNode(const std::string& node_name, MutableGraphView* graph) {\n   int index = graph_utils::FindGraphNodeWithName(node_name, *graph->graph());\n   DCHECK_NE(index, -1) << \"Failed to find node \" << node_name\n                        << \" in the optimized graph.\";\n@@ -167,7 +167,7 @@ NodeDef* GetMutableNode(const string& node_name, MutableGraphView* graph) {\n \n // Converts a ParallelInterleaveDataset or ParallelMapDataset to the equivalent\n // non-parallel version, to make it deterministic.\n-absl::Status ConvertMapOrInterleave(const string& node_name,\n+absl::Status ConvertMapOrInterleave(const std::string& node_name,\n                                     MutableGraphView* graph) {\n   NodeDef* node = GetMutableNode(node_name, graph);\n \n@@ -257,7 +257,7 @@ absl::flat_hash_set<absl::string_view> GetAllTransitiveDependencies(\n // separate Map and MapAndBatch ops. All the nondeterministic nodes and their\n // dependencies are moved to the Map node.\n absl::Status SplitMap(\n-    const FunctionLibraryDefinition& library, const string& map_node_name,\n+    const FunctionLibraryDefinition& library, const std::string& map_node_name,\n     MutableGraphView* graph,\n     const absl::flat_hash_set<absl::string_view>& nondeterministic_nodes) {\n   NodeDef* map_node = GetMutableNode(map_node_name, graph);\n@@ -344,7 +344,7 @@ absl::Status SplitMap(\n   NodeDef* second_map_node_ptr;\n   {\n     NodeDef second_map_node;\n-    string node_name =\n+    std::string node_name =\n         map_node->op() == kMapAndBatchOp ? \"map_and_batch\" : \"parallel_map\";\n     graph_utils::SetUniqueGraphNodeName(\n         absl::StrCat(\"make_deterministic_parallel_\", node_name, \"/\",\n@@ -384,7 +384,8 @@ absl::Status SplitMap(\n \n // Converts a ParallalBatch dataset to a Batch dataset, to make it\n // deterministic.\n-absl::Status ConvertBatch(const string& node_name, MutableGraphView* graph) {\n+absl::Status ConvertBatch(const std::string& node_name,\n+                          MutableGraphView* graph) {\n   NodeDef* node = GetMutableNode(node_name, graph);\n   node->set_op(kBatchV2Op);\n   std::string num_parallel_calls_input = node->input(2);\n@@ -398,7 +399,7 @@ absl::Status ConvertBatch(const string& node_name, MutableGraphView* graph) {\n // deterministic. Caller should delete the MapAndBatch node afterwards.\n // TODO(reedwm): Handle 'metadata' attribute. Currently the Map node and Batch\n // node will have an empty 'metadata' attribute.\n-absl::Status ConvertMapAndBatch(const string& node_name,\n+absl::Status ConvertMapAndBatch(const std::string& node_name,\n                                 MutableGraphView* graph) {\n   int index = graph_utils::FindGraphNodeWithName(node_name, *graph->graph());\n   DCHECK_NE(index, -1) << \"Failed to find node \" << node_name\n@@ -479,7 +480,8 @@ absl::Status ConvertMapAndBatch(const string& node_name,\n \n // Change the buffer_size of a Prefetch node to zero, effectively disabling it,\n // to make it deterministic.\n-absl::Status ConvertPrefetch(const string& node_name, MutableGraphView* graph) {\n+absl::Status ConvertPrefetch(const std::string& node_name,\n+                             MutableGraphView* graph) {\n   NodeDef* node = GetMutableNode(node_name, graph);\n   constexpr int buffer_size_index = 1;\n   node->add_input(absl::StrCat(\"^\", node->input(buffer_size_index)));\n@@ -548,7 +550,7 @@ bool FunctionMayIntroduceNondeterminism(\n bool FunctionMayIntroduceNondeterminism(\n     const FunctionLibraryDefinition& library, const std::string& function_name,\n     NondeterminismType nondeterminism_type) {\n-  absl::flat_hash_set<string> functions_processed;\n+  absl::flat_hash_set<std::string> functions_processed;\n   return FunctionMayIntroduceNondeterminism(library, function_name,\n                                             nondeterminism_type,\n                                             &functions_processed, nullptr);\n@@ -652,7 +654,7 @@ bool GraphMayHaveAsyncNondeterminism(const FunctionLibraryDefinition& library,\n       return true;\n     }\n   }\n-  for (const string& function_name : library.ListFunctionNames()) {\n+  for (const std::string& function_name : library.ListFunctionNames()) {\n     const FunctionDef* function_def = library.Find(function_name);\n     CHECK(function_def);  // Crash Ok\n     for (const NodeDef& node : function_def->node_def()) {\n@@ -673,7 +675,7 @@ absl::Status MakeDeterministic::OptimizeAndCollectStats(\n   MutableGraphView graph(output);\n   FunctionLibraryDefinition function_library(OpRegistry::Global(),\n                                              item.graph.library());\n-  absl::flat_hash_set<string> nodes_to_delete;\n+  absl::flat_hash_set<std::string> nodes_to_delete;\n   bool remove_async_nodes =\n       GraphMayHaveAsyncNondeterminism(function_library, item.graph);\n "
        },
        {
            "sha": "6971e5cf277e6560c558d16ca40bc6f22f00099d",
            "filename": "tensorflow/core/grappler/optimizers/data/make_deterministic.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_deterministic.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_deterministic.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_deterministic.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -56,7 +56,7 @@ class MakeDeterministic : public TFDataOptimizerBase {\n   MakeDeterministic() = default;\n   ~MakeDeterministic() override = default;\n \n-  string name() const override { return \"make_deterministic\"; };\n+  std::string name() const override { return \"make_deterministic\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n "
        },
        {
            "sha": "430d95f2162bb0751247da02ef8dbd9b45e48e1f",
            "filename": "tensorflow/core/grappler/optimizers/data/make_deterministic_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_deterministic_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_deterministic_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_deterministic_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -34,8 +34,8 @@ namespace tensorflow {\n namespace grappler {\n namespace {\n \n-std::vector<string> GetNodeNames(const FunctionDef& func) {\n-  std::vector<string> node_names;\n+std::vector<std::string> GetNodeNames(const FunctionDef& func) {\n+  std::vector<std::string> node_names;\n   for (const NodeDef& node : func.node_def()) {\n     node_names.push_back(node.name());\n   }"
        },
        {
            "sha": "ce3d3c8cbd5202297967059ecabc0c22aae2403b",
            "filename": "tensorflow/core/grappler/optimizers/data/make_sloppy.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_sloppy.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_sloppy.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmake_sloppy.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -26,7 +26,7 @@ class MakeSloppy : public TFDataOptimizerBase {\n   MakeSloppy() = default;\n   ~MakeSloppy() override = default;\n \n-  string name() const override { return \"make_sloppy\"; }\n+  std::string name() const override { return \"make_sloppy\"; }\n \n   bool UsesFunctionLibrary() const override { return false; }\n "
        },
        {
            "sha": "55f5190c223f75a40ccd1d65e0538b99856135a3",
            "filename": "tensorflow/core/grappler/optimizers/data/map_and_batch_fusion.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_batch_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_batch_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_batch_fusion.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -110,7 +110,7 @@ absl::Status MapAndBatchFusion::OptimizeAndCollectStats(\n     OptimizationStats* stats) {\n   *output = item.graph;\n   MutableGraphView graph(output);\n-  absl::flat_hash_set<string> nodes_to_delete;\n+  absl::flat_hash_set<std::string> nodes_to_delete;\n   for (const NodeDef& node : item.graph.node()) {\n     if (node.op() != \"BatchDataset\" && node.op() != \"BatchDatasetV2\") {\n       continue;"
        },
        {
            "sha": "d9f99dfcc0f423b6d157ad80d8c053453458b6e8",
            "filename": "tensorflow/core/grappler/optimizers/data/map_and_batch_fusion.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_batch_fusion.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_batch_fusion.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_batch_fusion.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -26,7 +26,7 @@ class MapAndBatchFusion : public TFDataOptimizerBase {\n   MapAndBatchFusion() = default;\n   ~MapAndBatchFusion() override = default;\n \n-  string name() const override { return \"map_and_batch_fusion\"; };\n+  std::string name() const override { return \"map_and_batch_fusion\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n "
        },
        {
            "sha": "b42376ddee4d7311203a017e62a5161b10acea73",
            "filename": "tensorflow/core/grappler/optimizers/data/map_and_batch_fusion_test.cc",
            "status": "modified",
            "additions": 34,
            "deletions": 34,
            "changes": 68,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_batch_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_batch_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_batch_fusion_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -33,22 +33,22 @@ TEST(MapAndBatchFusionTest, FuseMapAndBatchNodesIntoOne) {\n   NodeDef *stop_node = graph_utils::AddScalarConstNode<int64_t>(10, &graph);\n   NodeDef *step_node = graph_utils::AddScalarConstNode<int64_t>(1, &graph);\n \n-  std::vector<string> range_inputs(3);\n+  std::vector<std::string> range_inputs(3);\n   range_inputs[0] = start_node->name();\n   range_inputs[1] = stop_node->name();\n   range_inputs[2] = step_node->name();\n-  std::vector<std::pair<string, AttrValue>> range_attrs;\n+  std::vector<std::pair<std::string, AttrValue>> range_attrs;\n   NodeDef *range_node = graph_utils::AddNode(\"\", \"RangeDataset\", range_inputs,\n                                              range_attrs, &graph);\n   NodeDef *captured_input_node =\n       graph_utils::AddScalarConstNode<absl::string_view>(\"hello\", &graph);\n \n   NodeDef *map_node;\n   {\n-    std::vector<string> map_inputs(2);\n+    std::vector<std::string> map_inputs(2);\n     map_inputs[0] = range_node->name();\n     map_inputs[1] = captured_input_node->name();\n-    std::vector<std::pair<string, AttrValue>> map_attrs(2);\n+    std::vector<std::pair<std::string, AttrValue>> map_attrs(2);\n     AttrValue f_attr;\n     SetAttrValue(\"f\", &f_attr);\n     map_attrs[0] = std::make_pair(\"f\", f_attr);\n@@ -63,10 +63,10 @@ TEST(MapAndBatchFusionTest, FuseMapAndBatchNodesIntoOne) {\n       graph_utils::AddScalarConstNode<int64_t>(5, &graph);\n   NodeDef *batch_node;\n   {\n-    std::vector<string> batch_inputs(2);\n+    std::vector<std::string> batch_inputs(2);\n     batch_inputs[0] = map_node->name();\n     batch_inputs[1] = batch_size_node->name();\n-    std::vector<std::pair<string, AttrValue>> batch_attrs(2);\n+    std::vector<std::pair<std::string, AttrValue>> batch_attrs(2);\n     AttrValue shapes_attr;\n     SetAttrValue(\"output_shapes\", &shapes_attr);\n     batch_attrs[0] = std::make_pair(\"output_shapes\", shapes_attr);\n@@ -116,22 +116,22 @@ TEST(MapAndBatchFusionTest, FuseMapAndBatchV2NodesIntoOne) {\n   NodeDef *stop_node = graph_utils::AddScalarConstNode<int64_t>(10, &graph);\n   NodeDef *step_node = graph_utils::AddScalarConstNode<int64_t>(1, &graph);\n \n-  std::vector<string> range_inputs(3);\n+  std::vector<std::string> range_inputs(3);\n   range_inputs[0] = start_node->name();\n   range_inputs[1] = stop_node->name();\n   range_inputs[2] = step_node->name();\n-  std::vector<std::pair<string, AttrValue>> range_attrs;\n+  std::vector<std::pair<std::string, AttrValue>> range_attrs;\n   NodeDef *range_node = graph_utils::AddNode(\"\", \"RangeDataset\", range_inputs,\n                                              range_attrs, &graph);\n   NodeDef *captured_input_node =\n       graph_utils::AddScalarConstNode<absl::string_view>(\"hello\", &graph);\n \n   NodeDef *map_node;\n   {\n-    std::vector<string> map_inputs(2);\n+    std::vector<std::string> map_inputs(2);\n     map_inputs[0] = range_node->name();\n     map_inputs[1] = captured_input_node->name();\n-    std::vector<std::pair<string, AttrValue>> map_attrs(2);\n+    std::vector<std::pair<std::string, AttrValue>> map_attrs(2);\n     AttrValue f_attr;\n     SetAttrValue(\"f\", &f_attr);\n     map_attrs[0] = std::make_pair(\"f\", f_attr);\n@@ -148,11 +148,11 @@ TEST(MapAndBatchFusionTest, FuseMapAndBatchV2NodesIntoOne) {\n       graph_utils::AddScalarConstNode<bool>(true, &graph);\n   NodeDef *batch_node;\n   {\n-    std::vector<string> batch_inputs(3);\n+    std::vector<std::string> batch_inputs(3);\n     batch_inputs[0] = map_node->name();\n     batch_inputs[1] = batch_size_node->name();\n     batch_inputs[2] = drop_remainder_node->name();\n-    std::vector<std::pair<string, AttrValue>> batch_attrs(2);\n+    std::vector<std::pair<std::string, AttrValue>> batch_attrs(2);\n     AttrValue shapes_attr;\n     SetAttrValue(\"output_shapes\", &shapes_attr);\n     batch_attrs[0] = std::make_pair(\"output_shapes\", shapes_attr);\n@@ -200,11 +200,11 @@ TEST(MapAndBatchFusionTest, FuseParallelMapAndBatchNodesIntoOne) {\n   NodeDef *stop_node = graph_utils::AddScalarConstNode<int64_t>(10, &graph);\n   NodeDef *step_node = graph_utils::AddScalarConstNode<int64_t>(1, &graph);\n \n-  std::vector<string> range_inputs(3);\n+  std::vector<std::string> range_inputs(3);\n   range_inputs[0] = start_node->name();\n   range_inputs[1] = stop_node->name();\n   range_inputs[2] = step_node->name();\n-  std::vector<std::pair<string, AttrValue>> range_attrs;\n+  std::vector<std::pair<std::string, AttrValue>> range_attrs;\n   NodeDef *range_node = graph_utils::AddNode(\"\", \"RangeDataset\", range_inputs,\n                                              range_attrs, &graph);\n   NodeDef *captured_input_node =\n@@ -214,11 +214,11 @@ TEST(MapAndBatchFusionTest, FuseParallelMapAndBatchNodesIntoOne) {\n \n   NodeDef *map_node;\n   {\n-    std::vector<string> map_inputs(3);\n+    std::vector<std::string> map_inputs(3);\n     map_inputs[0] = range_node->name();\n     map_inputs[1] = captured_input_node->name();\n     map_inputs[2] = num_parallel_calls_node->name();\n-    std::vector<std::pair<string, AttrValue>> map_attrs(2);\n+    std::vector<std::pair<std::string, AttrValue>> map_attrs(2);\n     AttrValue f_attr;\n     SetAttrValue(\"f\", &f_attr);\n     map_attrs[0] = std::make_pair(\"f\", f_attr);\n@@ -233,10 +233,10 @@ TEST(MapAndBatchFusionTest, FuseParallelMapAndBatchNodesIntoOne) {\n       graph_utils::AddScalarConstNode<int64_t>(5, &graph);\n   NodeDef *batch_node;\n   {\n-    std::vector<string> batch_inputs(2);\n+    std::vector<std::string> batch_inputs(2);\n     batch_inputs[0] = map_node->name();\n     batch_inputs[1] = batch_size_node->name();\n-    std::vector<std::pair<string, AttrValue>> batch_attrs(2);\n+    std::vector<std::pair<std::string, AttrValue>> batch_attrs(2);\n     AttrValue shapes_attr;\n     SetAttrValue(\"output_shapes\", &shapes_attr);\n     batch_attrs[0] = std::make_pair(\"output_shapes\", shapes_attr);\n@@ -286,11 +286,11 @@ TEST(MapAndBatchFusionTest, FuseParallelMapV2AndBatchNodesIntoOne) {\n   NodeDef *stop_node = graph_utils::AddScalarConstNode<int64_t>(10, &graph);\n   NodeDef *step_node = graph_utils::AddScalarConstNode<int64_t>(1, &graph);\n \n-  std::vector<string> range_inputs(3);\n+  std::vector<std::string> range_inputs(3);\n   range_inputs[0] = start_node->name();\n   range_inputs[1] = stop_node->name();\n   range_inputs[2] = step_node->name();\n-  std::vector<std::pair<string, AttrValue>> range_attrs;\n+  std::vector<std::pair<std::string, AttrValue>> range_attrs;\n   NodeDef *range_node = graph_utils::AddNode(\"\", \"RangeDataset\", range_inputs,\n                                              range_attrs, &graph);\n   NodeDef *captured_input_node =\n@@ -300,11 +300,11 @@ TEST(MapAndBatchFusionTest, FuseParallelMapV2AndBatchNodesIntoOne) {\n \n   NodeDef *map_node;\n   {\n-    std::vector<string> map_inputs(3);\n+    std::vector<std::string> map_inputs(3);\n     map_inputs[0] = range_node->name();\n     map_inputs[1] = captured_input_node->name();\n     map_inputs[2] = num_parallel_calls_node->name();\n-    std::vector<std::pair<string, AttrValue>> map_attrs(2);\n+    std::vector<std::pair<std::string, AttrValue>> map_attrs(2);\n     AttrValue f_attr;\n     SetAttrValue(\"f\", &f_attr);\n     map_attrs[0] = std::make_pair(\"f\", f_attr);\n@@ -319,10 +319,10 @@ TEST(MapAndBatchFusionTest, FuseParallelMapV2AndBatchNodesIntoOne) {\n       graph_utils::AddScalarConstNode<int64_t>(5, &graph);\n   NodeDef *batch_node;\n   {\n-    std::vector<string> batch_inputs(2);\n+    std::vector<std::string> batch_inputs(2);\n     batch_inputs[0] = map_node->name();\n     batch_inputs[1] = batch_size_node->name();\n-    std::vector<std::pair<string, AttrValue>> batch_attrs(2);\n+    std::vector<std::pair<std::string, AttrValue>> batch_attrs(2);\n     AttrValue shapes_attr;\n     SetAttrValue(\"output_shapes\", &shapes_attr);\n     batch_attrs[0] = std::make_pair(\"output_shapes\", shapes_attr);\n@@ -373,20 +373,20 @@ TEST(MapAndBatchFusionTest, NoChange) {\n   NodeDef *stop_node = graph_utils::AddScalarConstNode<int64_t>(10, &graph);\n   NodeDef *step_node = graph_utils::AddScalarConstNode<int64_t>(1, &graph);\n \n-  std::vector<string> range_inputs(3);\n+  std::vector<std::string> range_inputs(3);\n   range_inputs[0] = start_node->name();\n   range_inputs[1] = stop_node->name();\n   range_inputs[2] = step_node->name();\n-  std::vector<std::pair<string, AttrValue>> range_attrs;\n+  std::vector<std::pair<std::string, AttrValue>> range_attrs;\n   NodeDef *range_node = graph_utils::AddNode(\"\", \"RangeDataset\", range_inputs,\n                                              range_attrs, &graph);\n \n   NodeDef *batch_size_node =\n       graph_utils::AddScalarConstNode<int64_t>(5, &graph);\n-  std::vector<string> batch_inputs(2);\n+  std::vector<std::string> batch_inputs(2);\n   batch_inputs[0] = range_node->name();\n   batch_inputs[1] = batch_size_node->name();\n-  std::vector<std::pair<string, AttrValue>> batch_attrs(2);\n+  std::vector<std::pair<std::string, AttrValue>> batch_attrs(2);\n   AttrValue shapes_attr;\n   SetAttrValue(\"output_shapes\", &shapes_attr);\n   batch_attrs[0] = std::make_pair(\"output_shapes\", shapes_attr);\n@@ -409,11 +409,11 @@ TEST(MapAndBatchFusionTest, NoChange_UnboundedThreadpoolParallelMap) {\n   NodeDef *stop_node = graph_utils::AddScalarConstNode<int64_t>(10, &graph);\n   NodeDef *step_node = graph_utils::AddScalarConstNode<int64_t>(1, &graph);\n \n-  std::vector<string> range_inputs(3);\n+  std::vector<std::string> range_inputs(3);\n   range_inputs[0] = start_node->name();\n   range_inputs[1] = stop_node->name();\n   range_inputs[2] = step_node->name();\n-  std::vector<std::pair<string, AttrValue>> range_attrs;\n+  std::vector<std::pair<std::string, AttrValue>> range_attrs;\n   NodeDef *range_node = graph_utils::AddNode(\"\", \"RangeDataset\", range_inputs,\n                                              range_attrs, &graph);\n   NodeDef *captured_input_node =\n@@ -423,11 +423,11 @@ TEST(MapAndBatchFusionTest, NoChange_UnboundedThreadpoolParallelMap) {\n \n   NodeDef *map_node;\n   {\n-    std::vector<string> map_inputs(3);\n+    std::vector<std::string> map_inputs(3);\n     map_inputs[0] = range_node->name();\n     map_inputs[1] = captured_input_node->name();\n     map_inputs[2] = num_parallel_calls_node->name();\n-    std::vector<std::pair<string, AttrValue>> map_attrs(3);\n+    std::vector<std::pair<std::string, AttrValue>> map_attrs(3);\n     AttrValue f_attr;\n     SetAttrValue(\"f\", &f_attr);\n     map_attrs[0] = std::make_pair(\"f\", f_attr);\n@@ -446,10 +446,10 @@ TEST(MapAndBatchFusionTest, NoChange_UnboundedThreadpoolParallelMap) {\n       graph_utils::AddScalarConstNode<int64_t>(5, &graph);\n   NodeDef *batch_node;\n   {\n-    std::vector<string> batch_inputs(2);\n+    std::vector<std::string> batch_inputs(2);\n     batch_inputs[0] = map_node->name();\n     batch_inputs[1] = batch_size_node->name();\n-    std::vector<std::pair<string, AttrValue>> batch_attrs(2);\n+    std::vector<std::pair<std::string, AttrValue>> batch_attrs(2);\n     AttrValue shapes_attr;\n     SetAttrValue(\"output_shapes\", &shapes_attr);\n     batch_attrs[0] = std::make_pair(\"output_shapes\", shapes_attr);"
        },
        {
            "sha": "b974f083e24bbf64041af5d14224553f09bfd813",
            "filename": "tensorflow/core/grappler/optimizers/data/map_and_filter_fusion.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_filter_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_filter_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_filter_fusion.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -168,7 +168,7 @@ absl::Status MapAndFilterFusion::OptimizeAndCollectStats(\n   *output = sorted_old_graph;\n \n   MutableGraphView graph(output);\n-  absl::flat_hash_set<string> nodes_to_delete;\n+  absl::flat_hash_set<std::string> nodes_to_delete;\n   FunctionLibraryDefinition function_library(OpRegistry::Global(),\n                                              item.graph.library());\n   auto get_map_node = [](const NodeDef& node) -> const NodeDef* {"
        },
        {
            "sha": "3c4543c31d80d495c800a9474027be3db8e36b96",
            "filename": "tensorflow/core/grappler/optimizers/data/map_and_filter_fusion.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_filter_fusion.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_filter_fusion.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_and_filter_fusion.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -35,7 +35,7 @@ class MapAndFilterFusion : public TFDataOptimizerBase {\n   MapAndFilterFusion() = default;\n   ~MapAndFilterFusion() override = default;\n \n-  string name() const override { return \"map_and_filter_fusion\"; };\n+  std::string name() const override { return \"map_and_filter_fusion\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n "
        },
        {
            "sha": "4b8321514880f961ab77f129e296129f85f6fcde",
            "filename": "tensorflow/core/grappler/optimizers/data/map_fusion.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_fusion.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -48,7 +48,8 @@ constexpr char kValueAttr[] = \"value\";\n constexpr int kAutotuneValue = -1;\n \n // Returns true if it is a `tf.data.AUTOTUNE` node.\n-bool IsAutotuneNode(const string& node_name, const MutableGraphView& graph) {\n+bool IsAutotuneNode(const std::string& node_name,\n+                    const MutableGraphView& graph) {\n   const NodeDef* node = graph.GetNode(node_name);\n   if (!node) return false;\n   if (node->op() != kConstOp) return false;\n@@ -91,10 +92,10 @@ bool SameDeterministicAttr(const NodeDef& parallel_map_node,\n // optimizing each function in that graph and later aggregating any new\n // functions introduced during these individual optimizations into that single\n // graph's collective function library).\n-string GetFusedName(const NodeDef& parent, const NodeDef& child) {\n+std::string GetFusedName(const NodeDef& parent, const NodeDef& child) {\n   return absl::StrCat(\"map_fusion_nodes/\", parent.name(), \"/\", child.name());\n }\n-string GetFusedName(const FunctionDef& parent, const FunctionDef& child) {\n+std::string GetFusedName(const FunctionDef& parent, const FunctionDef& child) {\n   return absl::StrCat(\"map_fusion_funcs/\", parent.signature().name(), \"/\",\n                       child.signature().name());\n }\n@@ -171,7 +172,7 @@ absl::Status MapFusion::OptimizeAndCollectStats(Cluster* cluster,\n   }\n \n   MutableGraphView graph(output);\n-  absl::flat_hash_set<string> nodes_to_delete;\n+  absl::flat_hash_set<std::string> nodes_to_delete;\n   FunctionLibraryDefinition function_library(OpRegistry::Global(),\n                                              item.graph.library());\n "
        },
        {
            "sha": "26068eadf16a7ef39d96ae0013f91dabcc1e20fa",
            "filename": "tensorflow/core/grappler/optimizers/data/map_fusion.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_fusion.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_fusion.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_fusion.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -30,15 +30,15 @@ class MapFusion : public TFDataOptimizerBase {\n   MapFusion() = default;\n   ~MapFusion() override = default;\n \n-  string name() const override { return \"map_fusion\"; };\n+  std::string name() const override { return \"map_fusion\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n \n   absl::Status Init(\n       const tensorflow::RewriterConfig_CustomGraphOptimizer* config) override {\n     if (!config) return absl::OkStatus();\n \n-    const string& autotune = config->parameter_map().at(kAutotune).s();\n+    const std::string& autotune = config->parameter_map().at(kAutotune).s();\n     if (autotune == \"true\") {\n       autotune_ = true;\n     } else if (autotune == \"false\") {"
        },
        {
            "sha": "6a0a10926c3d5d07774f769d28bf82da4900ea48",
            "filename": "tensorflow/core/grappler/optimizers/data/map_parallelization.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_parallelization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_parallelization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_parallelization.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -34,7 +34,7 @@ namespace {\n constexpr char kMapDataset[] = \"MapDataset\";\n constexpr char kParallelMapDataset[] = \"ParallelMapDatasetV2\";\n \n-NodeDef MakeParallelMap(const string& name, MutableGraphView* graph) {\n+NodeDef MakeParallelMap(const std::string& name, MutableGraphView* graph) {\n   // The inputs of the node to be parallelized could be changed by the\n   // optimization pass, so we need to look it up in the modified graph.\n   int index = graph_utils::FindGraphNodeWithName(name, *graph->graph());\n@@ -72,7 +72,7 @@ absl::Status MapParallelization::OptimizeAndCollectStats(\n   if (graph_utils::IsItemDerivedFromFunctionDef(item, graph))\n     return absl::OkStatus();\n \n-  absl::flat_hash_set<string> nodes_to_delete;\n+  absl::flat_hash_set<std::string> nodes_to_delete;\n   FunctionLibraryDefinition function_library(OpRegistry::Global(),\n                                              item.graph.library());\n   auto get_map_node = [](const NodeDef& node) -> const NodeDef* {"
        },
        {
            "sha": "54bc5bd56327048298a36fcb71aa86048867138f",
            "filename": "tensorflow/core/grappler/optimizers/data/map_parallelization.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_parallelization.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_parallelization.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_parallelization.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -30,15 +30,15 @@ class MapParallelization : public TFDataOptimizerBase {\n   MapParallelization() = default;\n   ~MapParallelization() override = default;\n \n-  string name() const override { return \"map_parallelization\"; };\n+  std::string name() const override { return \"map_parallelization\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n \n   absl::Status Init(\n       const tensorflow::RewriterConfig_CustomGraphOptimizer* config) override {\n     if (!config) return absl::OkStatus();\n \n-    const string& autotune = config->parameter_map().at(kAutotune).s();\n+    const std::string& autotune = config->parameter_map().at(kAutotune).s();\n     if (autotune == \"true\") {\n       autotune_ = true;\n     } else if (autotune == \"false\") {"
        },
        {
            "sha": "2bfa7363da18253f11ca6f083ae5734062784b32",
            "filename": "tensorflow/core/grappler/optimizers/data/map_parallelization_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_parallelization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_parallelization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmap_parallelization_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -75,10 +75,10 @@ TEST_P(AutotuneSetting, MapParallelizationTest) {\n \n INSTANTIATE_TEST_SUITE_P(Test, AutotuneSetting, ::testing::Values(false, true));\n \n-class FromFunctionDef : public ::testing::TestWithParam<string> {};\n+class FromFunctionDef : public ::testing::TestWithParam<std::string> {};\n \n TEST_P(FromFunctionDef, MapParallelizationTest) {\n-  const string op = GetParam();\n+  const std::string op = GetParam();\n   bool from_function_def = (op == \"_Retval\");\n \n   using test::function::NDef;"
        },
        {
            "sha": "18787fc4be25b5a34721d34daf4c5c17d8bfeb13",
            "filename": "tensorflow/core/grappler/optimizers/data/meta_optimizer.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmeta_optimizer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmeta_optimizer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmeta_optimizer.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -35,7 +35,7 @@ namespace grappler {\n namespace {\n \n using ConfigMap =\n-    std::map<string, tensorflow::RewriterConfig_CustomGraphOptimizer>;\n+    std::map<std::string, tensorflow::RewriterConfig_CustomGraphOptimizer>;\n \n // tf.data optimizations, in the order we want to perform them.\n // clang-format off\n@@ -76,17 +76,17 @@ absl::Status ToConfigMap(\n   for (const auto& option_string : options) {\n     // The option string has the format\n     // <optimizer_name>:<config_key>:<config_value>\n-    std::vector<string> split = absl::StrSplit(option_string, ':');\n+    std::vector<std::string> split = absl::StrSplit(option_string, ':');\n     if (split.size() != 3) {\n       return errors::Internal(\n           \"Wrong format for optimizer options. Expect <optimizer name>:<config \"\n           \"key>:<config value>, received: \",\n           option_string);\n     }\n \n-    const string& optimizer_name = split[0];\n-    const string& config_key = split[1];\n-    const string& config_value = split[2];\n+    const std::string& optimizer_name = split[0];\n+    const std::string& config_key = split[1];\n+    const std::string& config_value = split[2];\n \n     auto optimizer_config = gtl::FindOrNull(*result, optimizer_name);\n     if (!optimizer_config) {\n@@ -168,7 +168,7 @@ absl::Status TFDataMetaOptimizer::Optimize(Cluster* cluster,\n   return absl::OkStatus();\n }\n \n-absl::Status TFDataMetaOptimizer::ApplyOptimization(const string& name,\n+absl::Status TFDataMetaOptimizer::ApplyOptimization(const std::string& name,\n                                                     Cluster* cluster,\n                                                     GrapplerItem* item) const {\n   GRAPPLER_RETURN_IF_DEADLINE_EXCEEDED();"
        },
        {
            "sha": "ac1c819bc326695dc21ccaae6fc37bac74e6861a",
            "filename": "tensorflow/core/grappler/optimizers/data/meta_optimizer.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmeta_optimizer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmeta_optimizer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fmeta_optimizer.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -29,7 +29,7 @@ class TFDataMetaOptimizer : public CustomGraphOptimizer {\n   TFDataMetaOptimizer() = default;\n   ~TFDataMetaOptimizer() override = default;\n \n-  string name() const override { return \"tf_data_meta_optimizer\"; };\n+  std::string name() const override { return \"tf_data_meta_optimizer\"; };\n \n   bool UsesFunctionLibrary() const override { return true; }\n \n@@ -40,12 +40,12 @@ class TFDataMetaOptimizer : public CustomGraphOptimizer {\n                         GraphDef* output) override;\n \n  private:\n-  absl::flat_hash_map<string, std::unique_ptr<GraphOptimizer>>\n+  absl::flat_hash_map<std::string, std::unique_ptr<GraphOptimizer>>\n       enabled_optimizers_;\n \n   // Applies an optimization with the specified name on `item`, and stores\n   // the result in `item.graph`\n-  absl::Status ApplyOptimization(const string& name, Cluster* cluster,\n+  absl::Status ApplyOptimization(const std::string& name, Cluster* cluster,\n                                  GrapplerItem* item) const;\n };\n "
        },
        {
            "sha": "ad8a3755dd3a2fd168a1dc37caec94804286fabf",
            "filename": "tensorflow/core/grappler/optimizers/data/noop_elimination.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fnoop_elimination.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fnoop_elimination.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fnoop_elimination.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -70,8 +70,9 @@ bool IsShardOne(const NodeDef& shard_node, const MutableGraphView& graph) {\n   return IsConstNodeWithValue(*graph.GetNode(shard_node.input(1)), 1);\n }\n \n-bool IsOutputIdentityOfInput(const FunctionDef& fdef, const string& output_arg,\n-                             const string& input_arg) {\n+bool IsOutputIdentityOfInput(const FunctionDef& fdef,\n+                             const std::string& output_arg,\n+                             const std::string& input_arg) {\n   if (!fdef.ret().contains(output_arg)) {\n     LOG(WARNING)\n         << \"Malformed FunctionDef: ret dict does not contain output arg key.\";\n@@ -146,7 +147,7 @@ absl::Status NoOpElimination::OptimizeAndCollectStats(\n     OptimizationStats* stats) {\n   *output = item.graph;\n   MutableGraphView graph(output);\n-  absl::flat_hash_set<string> nodes_to_delete;\n+  absl::flat_hash_set<std::string> nodes_to_delete;\n   FunctionLibraryDefinition function_library(OpRegistry::Global(),\n                                              graph.graph()->library());\n   for (const NodeDef& node : item.graph.node()) {"
        },
        {
            "sha": "8d7e5a9e6973e1b0d46ca716893c2faa015a5b08",
            "filename": "tensorflow/core/grappler/optimizers/data/noop_elimination.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fnoop_elimination.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fnoop_elimination.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fnoop_elimination.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -28,7 +28,7 @@ class NoOpElimination : public TFDataOptimizerBase {\n   NoOpElimination() = default;\n   ~NoOpElimination() override = default;\n \n-  string name() const override { return \"noop_elimination\"; };\n+  std::string name() const override { return \"noop_elimination\"; };\n \n   bool UsesFunctionLibrary() const override { return false; }\n "
        },
        {
            "sha": "eadd19ed929b5c22401b919693d8bf2794bc60e2",
            "filename": "tensorflow/core/grappler/optimizers/data/noop_elimination_test.cc",
            "status": "modified",
            "additions": 47,
            "deletions": 42,
            "changes": 89,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fnoop_elimination_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fnoop_elimination_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fnoop_elimination_test.cc?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -25,39 +25,39 @@ namespace tensorflow {\n namespace grappler {\n namespace {\n \n-std::vector<std::pair<string, AttrValue>> GetCommonAttributes() {\n+std::vector<std::pair<std::string, AttrValue>> GetCommonAttributes() {\n   AttrValue shapes_attr, types_attr;\n   SetAttrValue(\"output_shapes\", &shapes_attr);\n   SetAttrValue(\"output_types\", &types_attr);\n-  std::vector<std::pair<string, AttrValue>> commonAttributes = {\n+  std::vector<std::pair<std::string, AttrValue>> commonAttributes = {\n       {\"output_shapes\", shapes_attr}, {\"output_types\", types_attr}};\n \n   return commonAttributes;\n }\n \n-NodeDef *MakeNode(absl::string_view node_type, std::vector<int> params,\n-                  string input_node, MutableGraphView *graph) {\n+NodeDef* MakeNode(absl::string_view node_type, std::vector<int> params,\n+                  std::string input_node, MutableGraphView* graph) {\n   std::vector<NodeDef *> node_params;\n   for (int param : params) {\n     node_params.push_back(\n         graph_utils::AddScalarConstNode<int64_t>(param, graph));\n   }\n-  std::vector<string> inputs = {input_node};\n+  std::vector<std::string> inputs = {input_node};\n   for (int i = 0; i < node_params.size(); i++) {\n     inputs.push_back(node_params[i]->name());\n   }\n   return graph_utils::AddNode(\"\", node_type, inputs, GetCommonAttributes(),\n                               graph);\n }\n \n-NodeDef *MakeNonConstNode(absl::string_view node_type,\n-                          std::vector<DataType> param_dtypes, string input_node,\n-                          MutableGraphView *graph) {\n+NodeDef* MakeNonConstNode(absl::string_view node_type,\n+                          std::vector<DataType> param_dtypes,\n+                          std::string input_node, MutableGraphView* graph) {\n   std::vector<NodeDef *> node_params;\n   for (DataType dtype : param_dtypes) {\n     node_params.push_back(graph_utils::AddScalarPlaceholder(dtype, graph));\n   }\n-  std::vector<string> inputs = {input_node};\n+  std::vector<std::string> inputs = {input_node};\n   for (int i = 0; i < node_params.size(); i++) {\n     inputs.push_back(node_params[i]->name());\n   }\n@@ -66,7 +66,7 @@ NodeDef *MakeNonConstNode(absl::string_view node_type,\n                               graph);\n }\n \n-NodeDef *MakeCacheNode(string input_node, MutableGraphView *graph) {\n+NodeDef* MakeCacheNode(std::string input_node, MutableGraphView* graph) {\n   NodeDef *node_filename =\n       graph_utils::AddScalarConstNode<absl::string_view>(\"\", graph);\n   return graph_utils::AddNode(\"\", \"CacheDataset\",\n@@ -79,23 +79,24 @@ NodeDef *MakeRangeNode(MutableGraphView *graph) {\n   auto *stop_node = graph_utils::AddScalarConstNode<int64_t>(10, graph);\n   auto *step_node = graph_utils::AddScalarConstNode<int64_t>(1, graph);\n \n-  std::vector<string> range_inputs = {start_node->name(), stop_node->name(),\n-                                      step_node->name()};\n+  std::vector<std::string> range_inputs = {\n+      start_node->name(), stop_node->name(), step_node->name()};\n \n   return graph_utils::AddNode(\"\", \"RangeDataset\", range_inputs,\n                               GetCommonAttributes(), graph);\n }\n \n struct NoOpLastEliminationTest\n-    : ::testing::TestWithParam<std::tuple<string, std::vector<int>, bool>> {};\n+    : ::testing::TestWithParam<\n+          std::tuple<std::string, std::vector<int>, bool>> {};\n \n // This test checks whether the no-op elimination correctly handles\n // transformations at the end of the pipeline.\n TEST_P(NoOpLastEliminationTest, EliminateLastNoOpNode) {\n   GrapplerItem item;\n   MutableGraphView graph(&item.graph);\n \n-  const string &node_type = std::get<0>(GetParam());\n+  const std::string& node_type = std::get<0>(GetParam());\n   const std::vector<int> node_params = std::get<1>(GetParam());\n   const bool should_keep_node = std::get<2>(GetParam());\n \n@@ -127,15 +128,16 @@ INSTANTIATE_TEST_CASE_P(\n         std::make_tuple(\"ShardDataset\", std::vector<int>({2, 0}), true)));\n \n struct NoOpMiddleEliminationTest\n-    : ::testing::TestWithParam<std::tuple<string, std::vector<int>, bool>> {};\n+    : ::testing::TestWithParam<\n+          std::tuple<std::string, std::vector<int>, bool>> {};\n \n // This test checks whether the no-op elimination correctly handles\n // transformations int the middle of the pipeline.\n TEST_P(NoOpMiddleEliminationTest, EliminateMiddleNoOpNode) {\n   GrapplerItem item;\n   MutableGraphView graph(&item.graph);\n \n-  const string &node_type = std::get<0>(GetParam());\n+  const std::string& node_type = std::get<0>(GetParam());\n   const std::vector<int> node_params = std::get<1>(GetParam());\n   const bool should_keep_node = std::get<2>(GetParam());\n \n@@ -176,8 +178,8 @@ INSTANTIATE_TEST_CASE_P(\n         std::make_tuple(\"ShardDataset\", std::vector<int>({1, 0}), false),\n         std::make_tuple(\"ShardDataset\", std::vector<int>({2, 0}), true)));\n \n-using NodesTypes = std::tuple<std::pair<string, std::vector<int>>,\n-                              std::pair<string, std::vector<int>>>;\n+using NodesTypes = std::tuple<std::pair<std::string, std::vector<int>>,\n+                              std::pair<std::string, std::vector<int>>>;\n struct NoOpMultipleEliminationTest : ::testing::TestWithParam<NodesTypes> {};\n \n // This test checks whether the no-op elimination correctly removes\n@@ -188,13 +190,13 @@ TEST_P(NoOpMultipleEliminationTest, EliminateMultipleNoOpNode) {\n \n   static_assert(std::tuple_size<NodesTypes>::value == 2,\n                 \"Make sure to include everything in the test\");\n-  const std::vector<std::pair<string, std::vector<int>>> noop_nodes = {\n+  const std::vector<std::pair<std::string, std::vector<int>>> noop_nodes = {\n       std::get<0>(GetParam()), std::get<1>(GetParam())};\n \n   NodeDef *range_node = MakeRangeNode(&graph);\n \n   NodeDef *previous = range_node;\n-  std::vector<string> nodes_to_remove;\n+  std::vector<std::string> nodes_to_remove;\n   nodes_to_remove.reserve(noop_nodes.size());\n \n   for (const auto &noop_node : noop_nodes) {\n@@ -223,14 +225,14 @@ TEST_P(NoOpMultipleEliminationTest, EliminateMultipleNoOpNode) {\n   EXPECT_EQ(cache_node_out.input(0), range_node->name());\n }\n \n-const auto *const kTakeNode =\n-    new std::pair<string, std::vector<int>>{\"TakeDataset\", {-1}};\n-const auto *const kSkipNode =\n-    new std::pair<string, std::vector<int>>{\"SkipDataset\", {0}};\n-const auto *const kRepeatNode =\n-    new std::pair<string, std::vector<int>>{\"RepeatDataset\", {1}};\n-const auto *const kShardNode =\n-    new std::pair<string, std::vector<int>>{\"ShardDataset\", {1, 0}};\n+const auto* const kTakeNode =\n+    new std::pair<std::string, std::vector<int>>{\"TakeDataset\", {-1}};\n+const auto* const kSkipNode =\n+    new std::pair<std::string, std::vector<int>>{\"SkipDataset\", {0}};\n+const auto* const kRepeatNode =\n+    new std::pair<std::string, std::vector<int>>{\"RepeatDataset\", {1}};\n+const auto* const kShardNode =\n+    new std::pair<std::string, std::vector<int>>{\"ShardDataset\", {1, 0}};\n \n INSTANTIATE_TEST_CASE_P(\n     BasicRemovalTest, NoOpMultipleEliminationTest,\n@@ -240,19 +242,19 @@ INSTANTIATE_TEST_CASE_P(\n \n struct NoOpPlaceholdersTest\n     : ::testing::TestWithParam<\n-          std::tuple<std::pair<string, std::vector<DataType>>,\n-                     std::pair<string, std::vector<DataType>>>> {};\n+          std::tuple<std::pair<std::string, std::vector<DataType>>,\n+                     std::pair<std::string, std::vector<DataType>>>> {};\n \n TEST_P(NoOpPlaceholdersTest, NonConstNoOpNode) {\n   GrapplerItem item;\n   MutableGraphView graph(&item.graph);\n \n   static_assert(std::tuple_size<NodesTypes>::value == 2,\n                 \"Make sure to include everything in the test\");\n-  const std::vector<std::pair<string, std::vector<DataType>>> noop_nodes = {\n-      std::get<0>(GetParam()), std::get<1>(GetParam())};\n+  const std::vector<std::pair<std::string, std::vector<DataType>>> noop_nodes =\n+      {std::get<0>(GetParam()), std::get<1>(GetParam())};\n   NodeDef *range_node = MakeRangeNode(&graph);\n-  std::vector<string> nodes_to_keep;\n+  std::vector<std::string> nodes_to_keep;\n   nodes_to_keep.reserve(noop_nodes.size());\n   NodeDef *previous = range_node;\n \n@@ -270,15 +272,18 @@ TEST_P(NoOpPlaceholdersTest, NonConstNoOpNode) {\n     EXPECT_TRUE(graph_utils::ContainsGraphNodeWithName(noop_node_name, output));\n }\n \n-const auto *const kNonConstTakeNode =\n-    new std::pair<string, std::vector<DataType>>{\"TakeDataset\", {DT_INT32}};\n-const auto *const kNonConstSkipNode =\n-    new std::pair<string, std::vector<DataType>>{\"SkipDataset\", {DT_INT32}};\n-const auto *const kNonConstRepeatNode =\n-    new std::pair<string, std::vector<DataType>>{\"RepeatDataset\", {DT_INT32}};\n-const auto *const kNonConstShardNode =\n-    new std::pair<string, std::vector<DataType>>{\"ShardDataset\",\n-                                                 {DT_INT32, DT_INT32}};\n+const auto* const kNonConstTakeNode =\n+    new std::pair<std::string, std::vector<DataType>>{\"TakeDataset\",\n+                                                      {DT_INT32}};\n+const auto* const kNonConstSkipNode =\n+    new std::pair<std::string, std::vector<DataType>>{\"SkipDataset\",\n+                                                      {DT_INT32}};\n+const auto* const kNonConstRepeatNode =\n+    new std::pair<std::string, std::vector<DataType>>{\"RepeatDataset\",\n+                                                      {DT_INT32}};\n+const auto* const kNonConstShardNode =\n+    new std::pair<std::string, std::vector<DataType>>{\"ShardDataset\",\n+                                                      {DT_INT32, DT_INT32}};\n \n INSTANTIATE_TEST_CASE_P(\n     DoNotRemovePlaceholders, NoOpPlaceholdersTest,"
        },
        {
            "sha": "a201a2108165109d2c8b516fb94bc7979f4fce8c",
            "filename": "tensorflow/core/grappler/optimizers/data/parallel_batch.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fparallel_batch.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fparallel_batch.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fparallel_batch.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -29,7 +29,7 @@ class ParallelBatch : public TFDataOptimizerBase {\n   ParallelBatch() = default;\n   ~ParallelBatch() override = default;\n \n-  string name() const override { return \"parallel_batch\"; }\n+  std::string name() const override { return \"parallel_batch\"; }\n \n   bool UsesFunctionLibrary() const override { return false; }\n "
        },
        {
            "sha": "d1e56fa3afb6af0a7201fe3e061ef259d1be3c00",
            "filename": "tensorflow/core/grappler/optimizers/data/remove_compression_map.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fremove_compression_map.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/09f85795bae3db9228cfa99751613805945a37d5/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fremove_compression_map.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdata%2Fremove_compression_map.h?ref=09f85795bae3db9228cfa99751613805945a37d5",
            "patch": "@@ -26,7 +26,7 @@ class RemoveCompressionMap : public TFDataOptimizerBase {\n   RemoveCompressionMap() = default;\n   ~RemoveCompressionMap() override = default;\n \n-  string name() const override { return \"remove_compression_map\"; }\n+  std::string name() const override { return \"remove_compression_map\"; }\n \n   bool UsesFunctionLibrary() const override { return false; }\n "
        }
    ],
    "stats": {
        "total": 832,
        "additions": 432,
        "deletions": 400
    }
}